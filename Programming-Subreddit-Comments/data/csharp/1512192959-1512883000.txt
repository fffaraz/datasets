I'm really interested in spans for performance reasons... But I used c# with unity and it only just got updated to c#6 (.net 4.6) *and* it's still marked as "experimental" support. Might be waiting some time...
Make sure the reference you added and your project are for the same .NET framework version. See also: https://stackoverflow.com/questions/6715612/reference-added-but-namespace-is-not-recognized https://stackoverflow.com/questions/4228992/namespace-not-recognized-even-though-it-is-there https://stackoverflow.com/questions/16169729/cant-use-referenced-dll-in-c-sharp
The post is read like that only by you're view point. I have googled, and also consulted a few books. I'm looking for a bit more insight regarding a specific question. So where is the line drawn? Is this a place that a question can only be asked if it cannot be found by Google after diving deep within the 3rd, 30th, page? If that is the case then everyone here is in violation. Most of what is here can be answered by Microsoft. Is this a place to shun the little guy, the newbie? If you can admit this is a place discriminatory of the newbie, then I will gracefully bow out and leave the experts to their own. 
You know, the way I got into programming .NET was to go on freelance sites, find projects that seemed interesting and that I thought I could handle, and do them for free. A lot of the time people will post enough in the proposal description that I didn't really need to contact them (though sometimes, I'd send my work to them when I was done anyway). As far as learning goes, my advice is to study design patterns and testing early and often (MVVM is a great place to start).
When calling methods that have `ref` parameters, you also need to include the keyword when invoking it: swap(ref valA, ref valB);
 public static new IHtmlString ToString() { HtmlString htmlString = new HtmlString(""); return htmlString; } or public static override string ToString() { HtmlString htmlString = new HtmlString(""); return new htmlString.ToHtmlString(); } And the fluent API is likely something similar to: public static HtmlHelper Kendo(this HtmlHelper helper) { return helper; }
I tried that and was given this instead An object reference is required for the non-static field, method, or property ' 
You need to change `swap` to a `static` method: `static void swap(ref int x, ref int y)`
When the particular tasks/steps you describe doing (reading files, combining files, reading directories, combining CSV files) have _many google hits._ If you had trouble implementing some of those results, please include the code of your attempts, or reference a result and ask for clarification about a particular aspect. Break your program requirements down into its small parts. Figure out how to read directory contents, figure out how to read and combine files, figure out how to write a file out somewhere. Maybe try implementing some of the google results suggestions regarding combining CSV files. Make an attempt. Put forth an effort. As it stands in your question, it seems like you haven't tried or researched _anything_ to implement these requirements. That's generally not acceptable here.
Thanks for catching that. I glossed over that detail.
 { static void Main(string[] args) { int valA, valB; Console.Write("Enter a value for A: "); valA = Convert.ToInt32(Console.ReadLine()); Console.Write("Enter a value for B: "); valB = Convert.ToInt32(Console.ReadLine()); Console.Write("\n"); Console.WriteLine("Swapping A and B..."); swap(valA, valB); Console.Write("\n"); Console.WriteLine("A = {0}", valA); Console.WriteLine("B = {0}", valB); Console.Write("Press any key..."); Console.ReadKey(); } static void swap(ref int x, ref int y) { temp = x; x = y; y = temp; } } } I changed swap to a static method but now I am at 4 erros. ref valA and valB erorrs with temp not existing in the context.
[Visual Studio 2017 Community Edition](https://www.visualstudio.com/downloads/) is ok to use for profit [as long as you don't have more than $1 million in annual profit or "more than 250 PCs or Users"](https://www.visualstudio.com/license-terms/mlt553321/)
I would start building really small and straightforward console apps that that just spit out data and changes you made to that data. Combine files or something. Just misc little things. Once you get comfortable there start looking into how you can do similar tasks but with a UI. Could do some thing like a Winforms app (maybes it UWP now) that has a basic GUI for text boxes etc to get a bit fancier. Then maybe try and do the same thing as a website. It can be intimidating but just try and start small. 
In case you hasn't fixed it yet, remove "private int temp;", change "swap(a, b);" to "swap(ref a, ref b);", make swap() static, and change "temp = x;" to "int temp = x;"
Github link?
I got a tutorial playlist if I forget hit me up
never mind y'all i found this that explains it https://github.com/EdCharbeneau/FluentHtmlHelpers/tree/SimpleTalkArticle
Search for “Jamie King C#” on YouTube. He’s a professor at the University of Utah at Salt Lake. His channel is supplementary material, but he’s such a great teacher that it’s all you need. He’s the guy that taught me and now I’m working, though primarily as a Windows Client Engineer, as a developer on a team at a major enterprise (S&amp;P 500). I couldn’t program my way out of a paper bag before I saw his videos. Next suggestion is what I did after watching his videos; I started doing the programming challenges at HackThisSite.org. Great stuff.
The scope of the language, or I guess more-so the frameworks associated with it are huge. It's easy to scratch the surface and not at all be ready for the industry. Of the devs I've hired, many of which deem themselves self taught, it's the C# ones that struggle the most with the jack of all trades, master of none impression Ymmv
You have to repair IIS express or enable IIS in Windows features. On mobile so I don't know exactly how it's called in Windows features
One option here would be to have a base class for your managers that contains all the shared code, perhaps in `protected` methods. Then, many different manager classes that all inherit from the same base class, and add whatever specific code they need. This will include the Get() method, which will need to be specific to each type so it can return the correct type (but of course it can make use of shared code from the base class).
Exactly.
This is a good way to get a grasp of the fundamentals, I would even suggest getting prepared for the 98-361 microsoft exam. It will give OP a path to follow and validate the knowledge that is essential.
How does this package compare to Microsoft’s Unity DI framework?
[removed]
I'd recommend buying a subscription to Pluralsight.com instead. I found it very useful when I transitioned from C++ to C#
You should check out the Pro C# book by Andrew Troelsen. He has a new edition for C# 7 being released later this month. I'd also second the recommendation for pluralsight. If you like learning for video.
If you already have coding background C# 7.0 in a nutshell will be perfect. 
If you want to really dig in, I would check out Jon Skeet's book, C# In Depth. https://www.amazon.com/dp/161729134X/ref=cm_sw_r_cp_apa_WgPiAb8YA4NY2 I really like the approach. He starts with explaining the features of c# 1. He then builds on the language added features for each version. There is a 4th edition being written now that includes c#7, but I think 3rd edition should be good enough. I say this because you will save $$$ and you can learn about the small num of C#7 features later. 
My first thought as well. User history leads me to believe he is not a shill 
Also the new edition (I think) doesn't include the earlier versions of csharp(or at least not some of them) in the book but I think you can download or claim a copy of the previous books or something like that. (I read this a while back so that might not be the case now)
I used plural sight for their Unity course and it was absolute garbage. Are their C# classes any decent?
I read "C# 6.0 and the .NET 4.6 Framework" by Andrew Troelsen and it was very helpful, he has a new book for C# 7.0 and .NET Core. "CLR via C#" by Jeffrey Richter is really good if you want to get deep and understand C# and the CLR at the machine level.
Obviously not all of them are brilliant but most of the courses in the "C# path" are nice. I particularly enjoyed the 2 courses on "C# language internals" when coming from a C++ background. There are also tests you can take to measure your proficiency when you follow a so called "path". The only thing I don't like about the Pluralsight is how you browse courses by subject. It's so confusing to me. For example I cannot find the "C# language internals" course if I browse by subject to learn: C#. 
Stackoverflow 
MSDN
I will second that, Jeffrey Richter also has other variants of that book updated for UWP.
C# in a nutshell is one of the best books I've read.
Regarding 1: I'd drop it. .NET 4.0 is long time out of the security timeline. People should not use it anymore. I understand that many companies don't have the option to update, but those can continue to use 1.x as you said. You can't make it nice for everyone. Even Microsoft is completely dropping .NET 4.0 support moving forward, as it's clearly shown with .NET Standard 2.0. Mentioning it, definitely target as a primary platform .NET Standard 2.0 :-). Regarding 2: I'd keep the name as it is. You say it's unnecessarily verbose, but what's wrong with verbosity? I'd rather have a longer method name with clearer naming than even slightly vague names. And I think `Delete` is a little bit **too** vague. Especially if you might consider adding comfort overloads like `DeleteFolder` to the `ImapClient` at some point. Verbosity and clarity always trumps, and this is not a case of smurf-naming (which is what I'd consider unnecessarily verbose). Regarding 3: Please avoid 3 at all costs. You're introducing a security risk as a default option, that's never a good idea. I understand you're having issues with complaints by people not understanding how the systems work, but that's really not a good enough reason to introduce behavior like this. Perhaps you can make this more obvious? Place it more prominent in the readme, in API documentation and in any feedback form you support (e.g. a checklist to cross on creating Github issues aka 'I'm aware of this validation callback'. Great that you now support an asynchronous API! But please don't make the same mistake as before in another variant: don't wrap your async methods with sync versions. Just drop the sync version altogether, or provide a second version of your library that is sync instead of async. Wrapping async methods with sync methods is poor practice, it could leads to potential deadlocks and brings hardly a benefit. If the caller needs it sync, let the caller handle it.
This sounds like homework. 
Nah, i'm learning more for fun so I can make some games once I get waaay better at it
That looks like exactly what I needed. I had not looked into generics before. Thank you so much. 
.toUpper() and .ToUpper() are not the same thing
String.ToUpper() != String.toUpper()
Thanks! I didn't even notice the uppercase T, im used to having my naming scheme as: **firstWordIsLowercaseButTheRestAreCapitalized** from when I used to code BASIC
For variables the convention is to start with lower case but for methods you use upper case for the first letter of each word.
and yes, [B] is supposed to represent the B emoji. yes i like dumb memes 
https://docs.microsoft.com/en-us/aspnet/web-api/overview/formats-and-model-binding/parameter-binding-in-aspnet-web-api
I think you need to have something like this: public class DictObject { public int id {get;set;} public string str {get;set;} } And have the post method like this: public void Post(DictObject do) { Dict.Add(do.id, do.str); }
How is you CPU behaving during all this? With this kind of isolation, I would have expected better scalability (though not perfect), but maybe your CPU is throttling itself with all cores crunching? 
My job provides msdn accnt and plural sight accnt, that is a good idea but I am more of a traditional book and do type of learner. Thank for thr reply. 
There are lots of issues with your benchmarking. You seem to be measuring console write times, which invalidates your results entirely, but what you are doing doesn't really male sense. The 'work' of adding 4000 elements to a list is almost entirely building and rebuilding the interior array every time it has to expand capacity. When you concat the resulting submits back together you are doing almost exactly the same work as creating one large list single threaded, though it might avoid a number of the internal array rebuilds by being in separate smaller lists before joining. Optimizing collection operations with multithreading is hard to do correctly. Some of the libraries like PLINQ can handle partitioning and grouping results for you automatically, but you won't see any improvement unless the work you are doing on each thread has enough CPU work to justify it (allocating struts is probably not a good candidate). In your specific case, using a pre sized list is probably the easiest way to improve performance, assuming it is static sized or you know the size in advance. 
This might give some ideas. [Jon Skeet - threads](http://jonskeet.uk/csharp/threads/)
Just fyi, this is called Camel Case because it has the hump in the middle where the capital letter is!
*You seem to be measuring console write times, which invalidates your results entirely* No, stopwatch is started right before the important sections and stopped right after these sections, only then comes a Console.Writeline(). No task has to wait for console writes. *The 'work' of adding 4000 elements to a list is almost entirely building and rebuilding the interior array every time it has to expand capacity* It doesnt have to extend capacity, as far I understand not even a single time, as the allocation is done via List &lt;&gt; (int capacity) constructor. *When you concat the resulting submits back together you are doing almost exactly the same work as creating one large list single threaded ..* False, I you run the benchmark you can see, that creating a single large list single threadedly takes 200-300ms depending on your computer. Concatenation the smaller lists together (after they have been built) takes only a few ms.
Is Task that incapsulates a process implemented asynchronously? Do you complete the Task when OnExit event arrives from the process instance?
It's not that .NET uses parallelism to create lists, but that tasks don't spin up threads. It's a really common misunderstanding (perhaps because we've had it ingrained in our heads that everything is a thread). Try reading Stephen Cleary's blog or [this post that gives some nice visuals to explain how tasks work] (https://blogs.msdn.microsoft.com/benwilli/2015/09/10/tasks-are-still-not-threads-and-async-is-not-parallel/).
The Tasks that run each `NumericJob` are asynchronous from the UI thread, yes. Each one of them marches along on its own, and there's no need for the UI to await them. Each Task does not terminate right after the external Process finishes. The multicast delegate comprising each `NumericJob` has say ~20 operations that it's doing in sequence. Basically: * Do some pre-processing steps * Launch the Helper via a new Process and wait for it to exit * Do some post-processing steps, and finish with a result
Finally got [CliWrap](https://GitHub.com/Tyrrrz/CliWrap), my command line interface wrapper library, feature complete. Meanwhile YouTube removed some AJAX endpoints that broke [YoutubeExplode](https://GitHub.com/Tyrrrz/YouTubeExplode).
Edited to include some processor information. Given that I have 4 out of 8 CPU's "parked" before doing any of this I would expect there to be ample room to run as many as 4 additional processes. What's interesting - using Windows Resource Monitor, if I only run one Helper at a time, I see Helper.exe getting 12% CPU usage. Makes sense, 1/8 = 0.125 so it would appear to be getting all that one CPU can give it. As I run more instances of it, by the time I get to say 4 of them running at the same time, the advertised CPU usage per instance is only hovering around 8-9%. Not sure what that tells me, but at face value I would think that's indicative of each process not getting a full 1/8 of the total.
What’s wrong with asking for help with homework? As long as the asked learns from the answer, I don’t see an issue
&gt; Launch the Helper via a new Process and *wait* for it to exit I think you may be blocking the thread there. Do you have more details on how Task instance that incapsulates the process is created?
This may be an indication that each process is not 100% CPU bound and/or IO inside it is handled synchronously. With blocking threads this combination saturates the server while CPUs are doing very little.
Just FYI, the entry level MSDN subscription has limited pluralsite access for free. It used to be you got full access but now it is widdled down to only a handful of videos.
Correct - thread blocking is intentional and desired in this case... and I don't believe it is the hang up. Allow me to explain the order of operations: * MyClient.exe UI thread is happily interacting with the user, who then calls a 'Start' command * UI thread of MyClient.exe simultaneously starts 4 async Tasks, each task having a multicast delegate of ~20 method calls * One of those method calls per task spawns a *new process* to a Helper application, and must wait for it to complete before moving on * So at this point, I have four Helper.exe console windows appear at the same time, each one of them going about its business concurrently and reporting status both to console writes and to MyClient.exe via WCF * Once each external application process completes, each Task (which had launched the process) finishes up what it needs to do, and that's it
I liked the c# player's guide, but it is geared for beginners.
You need to use [FromBody].
&gt; No, stopwatch is started right before the important sections and stopped right after these sections, only then comes a Console.Writeline(). No task has to wait for console writes and no task has to run parallel with these writes. Ah, I was on mobile and having a hard time seeing the code. I thought I saw a stopwatch .restart, but it was a .reset. I can see better now what you are doing. I'll need to reconsider my whole previous comment.
I didn't say there was anything wrong with it.
What I see is that the work in instantiating Lists of structs doesn't parallelize well. Here is a more concise version of what you are trying to do (I think): class Program { static void Main(string[] args) { var sw = new Stopwatch(); sw.Start(); var source = Enumerable.Range(1, 4000); var pixelList = ( from row in source.AsParallel() .WithDegreeOfParallelism(4) .WithExecutionMode(ParallelExecutionMode.ForceParallelism) select new List&lt;System.Drawing.Color&gt;(new Color[3000]) ).ToList(); var elapsed = sw.Elapsed; Console.WriteLine($"Elapsed: {elapsed.TotalMilliseconds}"); Console.ReadKey(); } }
What I see is that the work in instantiating Lists of structs doesn't parallelize well. Here is a more concise version of what you are trying to do (I think): class Program { static void Main(string[] args) { GetPixelListParallel(); GetPixelList(); } private static void GetPixelList() { var sw = new Stopwatch(); sw.Start(); var pixelList = new List&lt;List&lt;Color&gt;&gt;(4000); for (int width = 0; width &lt; 4000; width++) { pixelList.Add(new List&lt;Color&gt;(new Color[3000])); } var elapsed = sw.Elapsed; Console.WriteLine($"Elapsed: {elapsed.TotalMilliseconds}"); Console.ReadKey(); } private static void GetPixelListParallel() { var sw = new Stopwatch(); sw.Start(); var source = Enumerable.Range(1, 4000); var pixelList = ( from row in source.AsParallel() .WithDegreeOfParallelism(4) .WithExecutionMode(ParallelExecutionMode.ForceParallelism) select new List&lt;System.Drawing.Color&gt;(new Color[3000]) ).ToList(); var elapsed = sw.Elapsed; Console.WriteLine($"Elapsed Parallel: {elapsed.TotalMilliseconds}"); Console.ReadKey(); } } -edit- Running in release mode without the debugger attached, I can see that the single threaded version is slightly faster.
I had a similiar problem when using Unity. I would exactly write the same code in the tutorial yet it wouldn't work. Turns out i was typing .force instead of .Force.
Are your keys (e.g. "long BuildingId" in a Room entity) or your navigation properties (e.g. "Building Building" in a Room entity) null? If it's the navigation properties are null my guess would be you are not explicitly loading them. Try to use .Include(x =&gt; x.Building) in your query or activate eager loading in your context.
Are you missing the virtual keyword? It's required for lazy loading. Also, try stack overflow. 
I feel like /r/CSharp should be about programming, and /r/dotnet for high level discussion and framework news
Creating and starting tasks has overhead. You're only going to see an advantage if the gain from parallelizing outweighs the cost of creating and managing the tasks. For example, on my machine if I set: private const int width = 4000000; private const int height = 3; I see that the parallelization does help a little bit (if you ignore the cost of then concatenating).
`tasks[i].Start();` can create a thread. It depends on the current TaskScheduler, which is usually attached to a thread pool.
How does this interact with an MVC app, for example? Is there a way to maintain the HttpClient instance between requests?
Have you tried `Parallel.For` yet? It tends to be more efficient than manually working with threads or task objects.
Tasks are concurrent, but only become parallel when they move to another thread; either after an await that doesn't instantly complete (on the default scheduler) or if explicitly placed on another thread. Task.Run will start it on a different thread, e.g. tasks[i] = Task.Run (() =&gt; createSublist(width / numOfTasks, height)); Though for this example you'd probably be better using [`Parallel.For`](https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/how-to-write-a-simple-parallel-for-loop) You could also new the List to its final size, and have each element operate only on their portion to avoid copying. You have to use the indexer `[i]` and not do any resizing (like with `.Add`) or you'd have concurrency issues.
Thanks for the code! I run it and also on my system there is no real speed difference between parallel and non parallel execution times. *Also, if you are willing to create a class to manage the buffer yourself, it takes less than a millisecond to allocate an array of 12 million Colors directly with one line of code* That will be my next angle of attack, but this will be a separate "thread" on reddit.
I don't know if this is your problem, but Task uses thread pool threads. There a small number of these initially based on the number of processors you have, so probably four in your case. When you block on a thread pool thread you block other pending work that would have run on that thread. When all thread pool threads are blocked, no more work is started until a thread is freed by its task being finished (or yielded), or a timeout period has elapsed when a new thread will be started and added to the pool to hopefully get things moving again. So it is generally a bad idea to ever block a thread pool thread, especially on known long running computation work.
I'm actually learning C# so i'll be ready for Unity :D
*Creating and starting tasks has overhead. You're only going to see an advantage if the gain from parallelizing outweighs the cost of creating and managing the tasks.* On my system the result to build the List&lt;List&lt;&gt;&gt; with 4000 columns takes 270-340ms depending on the implementation. Setting up a task and starting that on the .NET managed thread pool takes very short time (my code above verifies this). At a job of approx 300ms i certainly expect parallelism to bring some speed advantage. 
Not yet 
What's wrong with the resources provided in the sidebar? There are getting started tutorials, video tutorials for absolute beginners, even a free book.
Have you measured how much time it takes between `Process.Start()` and the spawned process actually starting its work?
If you're using Visual Studio, I'd recommend learning to use the auto-completion features. Place your caret on the phrase which is typically underlined in red and press Ctrl+Space. If Visual Studio can find a valid match, it will rewrite the text with proper capitalization.
Removed: Rule 4. There are learning resources in the sidebar and you can check out /r/learncsharp and /r/learnprogramming as well.
The way you have done this should execute your tasks on the thread pool, but you are trying to use 16 software threads here. How many hardware threads do you have to execute these software threads on? If your processor only has 4 threads, and you're trying to execute 16, then they won't all be able to run simultaneously; they will queue 4 at a time to run on the thread pool. Executing each thread incurs a **context switching delay**. I copied the code and got about 300ms sequentially. For threading to help, the workload needs to take longer than the **context switching time**. If the workload is fast, as this one would probably be considered, then threading will actually slow down your code, because you're extending the time to process your code by adding the context switching time for each additional thread. In my testing, this context switching time makes the threaded version slower (~400ms threaded, ~300ms sequentially). Also, lists are not populated in parallel unless you tell them to do so. 
Using .Start() will also run on another thread. Awaiting a task does not run it on another thread.
Parallel for is not thread safe, you could have 2 indexes with value 1 for example, will mess things up here I would suggest trying Parallel.invoke But before that check and make sure that the task creation and execution is not improving progress! Maybe its working but the list concatenation is messing the time up... Sorry no IDE on the phone to test it out...
An await **in** a Task will cause the continuation (after the await) to be run on the threadpool if the awaited item is incomplete; and using the default scheduler. E.g. await Task.Delay(1); // await Task.Delay(0); // won't switch threads as is already complete createSublist(width / numOfTasks, height)); 
That is single-threaded. It has nothing to do with the thread pool or switching threads. The only reason you await is to not block the calling thread. The await keyword causes the compiler to generate a state machine which allows the method to return prematurely, and continue after the specified delay. It all happens on one thread.
Does this book have coding exercises each chapter for the reader? 
So you're on the production machine, editing files in a text editor? I'm not sure what default page you're talking about. Do you mean the **default document**? If so, the default document may not even be used by the website. Most likely your default document will essentially be overriden by the default route in MVC, which should be /Index. This will return whichever view the application code tells it to, or may not return a view at all. 
Thanks for the answer, but we are talking about 300ms which is an awfull lot of time for every CPU. If you run my code, you can see, that initializing the tasks does not take even take a single ms per task. Context switchinh between threads is also well below 1 ms. 
I have an i5 processor just like you (i5 3550, 4c/4t). Changing the thread count in my code (between sensible limits) does not change the execution time. In a system well saturated with active threads it also might be advantageous to have more tasks (provided each task gets a separate thread of execution) than phisical cores/HT cores bc, if at the end you do a threads.WaitAll() (in order to concat the results) you have much less chance that one thread was delayed much more than the others. just my thouts
In terms of deciding when to thread code such that it completes faster, 300ms is not long enough. You can still thread it to prevent blocking the calling thread, and accept some additional processing time for this luxury. Initializing tasks does not tell you the context switching time. This is a concept that is at a lower level than .NET. Windows switches threads as and when it pleases, and it's not something we can control in .NET. It may not be entirely due to context switching though. Your work also has to be scheduled.
Ctrl + F5?
Default scheduler on a console app is the threadpool, try running this and see what you find using System; using System.Threading; using System.Threading.Tasks; class Program { static void Main(string[] args) { Console.WriteLine($"{nameof(Main)} before {ThreadId}"); MainAsync().Wait(); Console.WriteLine($"{nameof(Main)} after {ThreadId}"); } static async Task MainAsync() { Console.WriteLine($"{nameof(MainAsync)} before {ThreadId}"); await DoThing(); Console.WriteLine($"{nameof(MainAsync)} after {ThreadId}"); } static async Task DoThing() { Console.WriteLine($"{nameof(DoThing)} before {ThreadId}"); await Task.Delay(1); Console.WriteLine($"{nameof(DoThing)} after {ThreadId}"); } static int ThreadId =&gt; Thread.CurrentThread.ManagedThreadId; } 
We have two web servers running (and two databases; one behind each web server). One of them is prod, the other is dev. I'm making all changes to dev. And btw, both dev and prod are VMs with nightly snapshots. By default document I literally mean default.aspx. Default.aspx makes up the body of the landing page. I opened the solution on my machine, made a small text change to default.aspx, rebuilt the website and copied the product to the inetpub directory on dev. This server is running multiple sites, but I'm referring specifically to the site with the :80 binding, and I copied that code to the directory for that site. Then restarted the web server (from IIS manager). Popped the 80 (clicked on the :80 binding in IIS manager) and the resulting page did not have my change. Opened the document on disk with NotePad++ and confirmed that my changes were there. Even did a procmon cap to make sure that when I browsed the site, it was Default.aspx (from that specific directory) that was being served. I'd dabbled a bit with this stuff many years ago; I didn't make the changes then, but I was responsible for making sure the web server was deliverying that content. IIRC (and I probably don't), there was some special way I had to restart the server so that it didn't deliever cached content that was "pre-compiled" and resided somewhere else on disk. And if I didn't do that (or delete that cache), then the changes would never show up. Anyone know if a) I'm on the right track (obviously I'm making assumptions here based on 10 year old memories when I didn't even know quite what I was doing then and just following directions like a puppet) and b) where that damn cache is?
Can you provide us with more details? Are you sure you've edited the correct default document? Are there multiple default documents in the root of the website? If there are more, there's a certain order in which they're served. That is if it's a classic asp.net app. MVC is a different story. Last, but not least, I've once spent 30 minutes changing files and refreshing only to realise I was making changes on my local sources but was checking a completely different machine.
I use Safari Books Online subscription. It's about $300 (USD) a year after a free trial. It's basically every book you would ever need to read about programming. Topics include: basic coding skills, databases, data structures, AWS, advanced skills, etc. Lots of other topics too: maths, physics, economics, etc. Best purchase I made in 2017. Pluralsight is good as well, but I prefer this.
Unfortunately, there is something about the connection string in web.config that the dev db doesn't like; I get a runtime error that the entity db provider failed to open. I considered the possibility that the password in the string was just old, so I created a public user on the dev sql server and altered the web.config connection string to use that user. Provider still failed to open. I've also exported the dev db from the dev sql server to my machine, and was considering persuing making any necessary changes to making the solution utilize resource on my machine, but there is a lot of setup I need to do. And I'd prefer to alter the code as little as possbile since I really shouldn't be doing this anyway, I'm just the only one left that has a shot at being successful; the changes are minor anyway: just need to alter the email template for the "congradulations! you've successfully registered for your windows 8 upgrade!" email to say windows 10 instead. If I have to re-config the shit out of it to get it to work locally...well, that may not be a smart plan. So instead I "build the website" from VS, then copy the result from my build directory to the dev box and then just open a browser and point it at the dev machine.
Please see my reply to /u/Liam2349 for more info.
To combine what /u/carrot_gg , /u/aeneashasvowels, and /u/psi- are saying/referencing into one summary: You need to tell it where to pick those parameters from. I *think* it would work if you stuck them in the query string as that would be the default, and maybe if you submitted the POST pretending to be an HTML FORM (application/x-www-form-urlencoded). I don't remember the default behavior because I always define them explicitly, don't allow multiple message formatters, etc. ^1 /u/aeneashasvowels article points out that /u/carrot_gg and /u/psi- are both correct. 1) You must use `[FromBody]`. This tells it to bind the parameter based on the POST body as opposed to the path (which would be in the `[Route("api/Post/{id}"]` format you mentioned), or the query string (`[FromUri]`) 2) You cannot use two different `[FromBody]` markers for JSON, so must define a "RequestMessage" object that has id and str properties, or use an existing object that can be deserialized from JSON. ^(1 I go explicit and single-correct-format. Implicit binding and allowing XML/JSON/x-www-form-urlencoded is in theory "more flexible" for people writing clients. In practice, I find it just ends up being more ways for client developers to fuck up and come to you with stupid questions, feature requests for you to support their broken XML generators because they concatented strings instead of using an XML library and they're breaking whenever the user entered a &lt; or an emoji or something, or their platform's idea of URL/form encoding disagrees with C#. Support **one** API format and strictly validate it, unless you have a genuine business need to support a mix of formats.)
Ok, I debugged this using the *Parallel Stacks* and *Threads* windows, and I get a second thread immediately after the *Task.Delay* returns. There's one thread responsible for Main, which is waiting, and another thread for the other two methods. This other thread terminates when returning from *MainAsync().Wait();* in the *Main* method. If the *Task.Delay* is replaced with *Task.Delay(0)*, the new thread never appears on completion. I assume this is because the thread is never suspended. Awaiting *Task.Delay(x)* causes the thread to suspend, as long as x &gt; 0. When the wait is complete, it seems like the runtime moves some responsibilities to another thread. I don't think this would ever result in parallel work, as the first thread should always be waiting, but it does seem to be multithreaded. I think it's interesting to note that this code (which differs only by the call to *Task.Delay* in *MainAsync*, does not produce any additional threads. using System; using System.Threading; using System.Threading.Tasks; class Program { static void Main(string[] args) { Console.WriteLine($"{nameof(Main)} before {ThreadId}"); MainAsync().Wait(); Console.WriteLine($"{nameof(Main)} after {ThreadId}"); } static async Task MainAsync() { Console.WriteLine($"{nameof(MainAsync)} before {ThreadId}"); await Task.Delay(1); await DoThing(); Console.WriteLine($"{nameof(MainAsync)} after {ThreadId}"); } static async Task DoThing() { Console.WriteLine($"{nameof(DoThing)} before {ThreadId}"); await Task.Delay(1); Console.WriteLine($"{nameof(DoThing)} after {ThreadId}"); } static int ThreadId =&gt; Thread.CurrentThread.ManagedThreadId; } I was surprised that this happens, because what about WPF? Returning on another thread like this could cause a crash if the code interacts with the UI, so surely WPF must work as I thought. I tested very similar code in WPF, and that code returned on the same thread. So it looks like a thread that is suspended due to awaiting a task will: 1 ) Resume on a different thread for console apps 2 ) Resume on the same thread for WPF Thank you for this enlightening example.
It shouldn’t really be this complicated. When I make a change to Web Forms, I just hit the compile button, and copy the changes over to inetpub on the web server. 
Ok, so it sounds like you're probably using webforms. I've never actually used webforms, only seen it. However, if the changes do exist on the machine and you have confirmed that the correct file is being accessed, then it could be that your changes are overridden somewhere in code, or hidden by styles. If the file is being called, then is it really to do with caching? If the page is cached, why would the file be accessed? Perhaps try altering another part of the website and see if you have the same issue?
What kind of database are you using? SQL Server?
Yes
&gt; If the file is being called, then is it really to do with caching? If the page is cached, why would the file be accessed? My thoughts exactly. No of this actually makes sense. I'm sure that once I get this working, I'll look back on it and see exactly what it was a incorrectly assumed :)
I thought the same thing.
For WPF you'd have to use `.ConfigureAwait(false)` on the `await Task.Delay(1).ConfigureAwait(false)` to get it to move off the WPF Task scheduler (which is single threaded for UI access); and then not have a `ConfigureAwait`on the top level await so it returns to the WPF scheduler. &gt; I don't think this would ever result in parallel work, as the first thread should always be waiting, but it does seem to be multithreaded. If you capture the tasks later and await then it will do parallel work static async Task MainAsync() { Console.WriteLine($"{nameof(MainAsync)} before {ThreadId}"); var list = new List&lt;Task&gt;(); for (var i = 0; i &lt; 10; i++) { list.Add(DoThing(i)); } await Task.WhenAll(list.ToArray()); Console.WriteLine($"{nameof(MainAsync)} after {ThreadId}"); } static async Task DoThing(int i) { Console.WriteLine($"{nameof(DoThing)}{i} before {ThreadId}"); await Task.Delay(1).ConfigureAwait(false); Console.WriteLine($"{nameof(DoThing)}{i} after {ThreadId}"); } Then it will output something like Main before 1 MainAsync before 1 DoThing0 before 1 DoThing1 before 1 DoThing2 before 1 DoThing3 before 1 DoThing4 before 1 DoThing5 before 1 DoThing6 before 1 DoThing7 before 1 DoThing8 before 1 DoThing9 before 1 DoThing9 after 4 DoThing4 after 10 DoThing5 after 8 DoThing3 after 4 DoThing7 after 7 DoThing6 after 6 DoThing2 after 9 DoThing8 after 5 DoThing0 after 8 DoThing1 after 10 MainAsync after 10 Main after 1
Did you forget to add a getter/setter?
To my understanding, it because it’s removing a point of failure. If for some reason it doesn’t get modified when it’s supposed to, then there is at least a fall back and not a fatal error. I normally use it and build a default case into my branching statements to handle this. It can also optimize and shorten code if used carefully, like say for the most common or default operation. And in an array it takes up a minimum amount of memory like that. All that said I’m a hobbyist, and I’ve only had a few CompSci and no C# formal education courses, so take it with a grain of salt.
It's more explicit. I don't want to look up the language specs about whether the default of some type was null, zero, an empty string, or whatever. However, in that example, you could probably just use a ternary assignment.
Add a new static file (image) and see if that loads in your browser.
&gt; you could have 2 indexes with value 1 for example I've ran into this issue. I've found that creating a local copy of the index will solve this. For example: Parallel.For(0, arr.Count, i =&gt; { var index = i; // The rest }; Apparently variables passed to delegates aren't local to each delegate, so you end up with race conditions.
Honestly, I'd prefer an error. Later, when there's some misbehaviour in some other part of the program because this value wasn't correct, I'd appreciate hearing about it immediately instead of having to trace back the cause. 
The formatting on mobile makes it really hard to even begin to understand your question... let alone the code. It appears you have a main with 5 scores, doubles, and they call a getDouble() that just makes sure it is between 0 and 10. *Who wrote that code... could be cleaner* There's some hard to read commenting that didn't break right at all. But in there, specific directions say to write a 'static void method( ref1, ref2, ref3, ref4, ref5)' and says it will use reference parameters. Not sure if it actually means to use a pass by reference or simply sayimg it gets a referenced value that gets passed over. No reason to manipulate scores, so not sure what the point is there.
&gt; In a system well saturated with active threads it also might be advantageous to have more tasks (provided each task gets a separate thread of execution) than phisical cores/HT cores bc, if at the end you do a threads.WaitAll() (in order to concat the results) you have much less chance that one thread was delayed much more than the others. This is operating system specific, but the modern Windows scheduler is really good. It will give priority to the threads that need the processing time. Having way more threads than the CPU can process in parallel means that each thread is given less time on the CPU. I would port this to Parallel, instead of creating tasks like this. Parallel will scale this much better, and will do it appropriately for low core processors as well as many core processors.
The only case where I could see this making a difference in that code is if the calculation might throw an exception. It's not an optimization. If anything it's less efficient, although in practice it'll almost never matter and you should just go with what's simpler/more readable. Personally, I'd prefer this form: protected override void OnBarUpdate() { if (CurrentBar &lt; Period || Period &lt; 1) MaBar[0] = 0; else MaBar[0] = //Calculate actual value here } There are some cases involving closures when you must assign a pointless default value to a local variable to satisfy the compiler, e.g. int Foo() { int value; // = 0; Action lambda = () =&gt; value = 1; lambda(); return value; // compiler will complain about value being possibly unassigned } But that doesn't apply to the snippet you posted.
I think it needs reference value.
Is there any URL rewriting going on? Are you absolutely positive that you are hitting the web page that you think you are hitting? You should be able to look at the bindings in IIS to make sure that it is bound to the domain you are using. IIS should also be able to show you any URL rewrites that are in place. You can also look in the web.config to see any rewrites.
Arrays don't change size, and all ints are the same size.
&gt; int numOfCores = Environment.ProcessorCount; &gt; int numOfTasks = numOfCores * 4; It may sound counter-intuitive, but have you tried `numOfTasks = numOfCores` or even just `numOfTasks = 4`? I did a bunch of benchmarking with multi-threading a certain type of job and I found a noticeable speed up over `for` by using `Parallel.For` and specifying only 2 threads, but as I increased the number of threads the efficiency actually went down notably and, at a certain point (I think it was around 6 or 8 threads), it actually took longer than a single-threaded `for`. A lot of types of work doesn't show a linear (or exponential) performance improvement as more threads are added. Your bottleneck may be in the allocation of memory (and GarbageCollection) so you might only see improvements with one or two additional threads; anything beyond that might decrease performance as threads have to wait for access to the other OS resource/work to complete. &amp;nbsp; Also, there may a notable amount of added overhead from initializing *multiple* `List&lt;List&lt;T&gt;&gt;` compared to a single `List&lt;List&lt;T&gt;&gt;` that is actually negating the multithreaded performance benefits. Perhaps you could try initializing a single collection using [the `System.Collections.Concurrent` namespace](https://msdn.microsoft.com/en-us/library/system.collections.concurrent\(v=vs.110\).aspx) (if ordering doesn't matter, then probably a `ConcurrentBag&lt;List&lt;T&gt;&gt;`, then use `Parallel.For` to populate the `ConcurrentBag` with the needed `List&lt;T&gt;`. The collections in the `Concurrent` namespace aren't entirely lock-free, but they [do minimize the amount of locking/syncing necessary](https://blogs.msdn.microsoft.com/pfxteam/2010/01/26/faq-are-all-of-the-new-concurrent-collections-lock-free/) in order to maximize performance, so it might be worth a try. An added benefit of `Parallel.For` is that the Partitioner can often determine the best way of slicing and distributing (though you can also force certain behaviors and settings if you need to). &amp;nbsp; Lastly, you might benefit from temporarily disabling GC (or changing the [GC latency mode](https://docs.microsoft.com/en-us/dotnet/standard/garbage-collection/latency) during the initialization of all the Lists. Generally, GC isn't something that developers will need to adjust but this might be a case where it would help. It's likely that all of the object initializations make the GC want to run more frequently even though the GC passes are largely fruitless. 
No, but there are examples throughout.
Not that I can see. And the plot thickens; I did another procmon cap and can see a call to default.aspx (opened it with jump to to make sure it was the one with my changes, it was), then the tcp session and a transfer of approx the correct size (didn’t bother calculating overhead) them the iexplore process calls to an htm File in its cache, using jump to reveals that its default.aspx...WITHOUT my change!
Thanks for the suggestions!!
Homework should be labeled as such so that people aren't spoonfeeding answers and depriving people of learning opportunities.
No problem! Keep me posted if you give them a shot... I'd be interested to find out if they make any difference.
It might be your browsers cache.
Cleared the cache; multiple times actually (after every unsuccessful test)
If not an array element like your example, I find it is best in C# ( and only C# with visual studio) to never assign a var a value. Why? Well in C# the compiler is very good at making sure a var gets set before being used. By not initializing, you make sure that all control flow results in the var being initialized. Imagine a var set by a complex switch statement. The compiler will make sure some poor soul that comes after you and adds another conditional doesn't forget to set the var to something meaningful for the new flow.
You should use [BenchmarkDotNet](https://github.com/dotnet/BenchmarkDotNet) to get useful benchmark numbers. This is just guessing on my part, but I suspect the real problem here is that memory allocations just don't parallelize very well. By default there is only one heap, and access to that needs to be at least somewhat synchronized. Using the [server GC](https://docs.microsoft.com/en-us/dotnet/standard/garbage-collection/fundamentals#workstation-and-server-garbage-collection) might make a difference. However, if your goal is performance, I would recommend using a single large array instead. It'll be cheaper to allocate and perform better. Also, the `Color` struct is actually quite large, I would recommend just storing `int`s and using `Color.FromArgb()`/`ToArgb` when required. This will cut the size of your allocations by a factor of ~5. 
Try running the page in incognito mode on chrome. It worked for me some times.
There is no way to prevent duplicates that I have seen. What you can do however, is make a list of #'s used. If the index of the # is in the list, then get a new #, else break or continue.
Also, what you have is going to be the best way in concept. Using other tools will use up unnecessary memory.
I'd try that; unfortunately direct access went down (pretty sure there is maintenance this weekend). Guess I'm done for the weekend; and I'd promised to have those changes done by Monday too..
As long as they know how to do it by the time I’ve explained it, they’ve learned I’m not their professor, I’m not being paid to uphold academic standards - and as an employer I care only that the student knows how to do something: how they learned it is irrelevant. I don’t care if they learned from a textbook, lecturer, classmate, stackoverflow, or Reddit.
&gt;As long as they know how to do it by the time I’ve explained it, they’ve learned I don't think that's true. They know how to do the one thing that they were asking about. They did not learn, however, how to read their textbook, requirements, or any technical documentation on how to get an answer. Those are very real skills that you have to have, because, as an employer, you can't afford to have an engineer blocked while waiting on 50 questions on an online forum like, "How to make a string uppercase in C#" or "Sort this array of objects by a key". Yes, technically, they gained the specific piece of knowledge. But if they didn't gain or improve a skill, I think that you're depriving them of that learning. It's not so much about academic standards, but teaching them how to fish instead of giving them the fish.
Is this homework? You're on the right track with hashsets. What if you used while(randomNumbers.Count &lt;= count)
Thx! didnt know that Color was large. I alwasy thout it were 4bytes... 
The problem with an un-initialized variable that later throws an exception is that it can be unclear from the call stack details which variable is null and why. If there is the possibility that a variable is unset due to a failed operation, you should check for it explicitly and throw and exception or do some other useful thing. Leaving a variable un-initialized is a ticking time bomb you cannot control.
My guess it's there to make sure it doesn't contain a stale value in the 10 % case.
Fisher-YAtes-Knuth shuffle
One good way to achieve this is if you have a relatively low amount of numbers is using a stack of numbers with all the possibilities, shuffling the stack, and poping elements to get the numbers, when the stack is empty, refill the stack.
This is probably the best approach for the situation, where OP is picking (I assume) a relatively small count of numbers from the pool of integer values. In a situation where OP is picking close to `N` numbers from a range of 1-N, however, the approach mentioned by /u/H34DSH07 is going to be much superior. Think in terms of drawing cards from a 52-card deck: by the time you've picked 51 cards, you are still choosing random numbers between 1 and 52 each iteration, but have only a 1/52 chance of randomly choosing the number of that last card. With a shuffle, you simply pull the final card/number off the stack as the order was pre-determined by shuffling.
If I set StopBits = StopBits.OnePointFive, it will throw an exception saying "Stop bits cannot be set to StopBits.OnePointFive}", but not until after the backing field is assigned to. 
This is completely superfluous and I love it
&gt; It's not an optimization. If anything it's less efficient Maybe, maybe not. If I recall correctly, the CLR will initialize all variables to 0, local and in arrays. So a smart compiler might probably see that `MaBar[0] = 0` is redundant and skip it.
True, but at least you know a problem exists.
If you can find one with a permissive license, you can always just maintain the parts of it you need yourself. That's almost certainly still easier than not using a library at all.
&gt; The problem with an un-initialized variable that later throws an exception is that it can be unclear from the call stack details which variable is null and why. I agree. That's why I said I'd prefer an error on use instead of some fallback value that could cause the program to keep chugging along and do the wrong thing without even letting me know. &gt; If there is the possibility that a variable is unset due to a failed operation, you should check for it explicitly and throw and exception or do some other useful thing. Sure, I wouldn't want to go ahead if I require a value and I can't get one. I was talking about programmer error. It certainly isn't hypothetical for variables to have a missing or wrong value when used. C has given us plenty of examples. C# tries by making you initialize it to anything as long as it's a value, but it's still very possible to make the same mistakes as the C examples. For example, Android makes it super easy by using `onCreate` instead of the constructor, meaning you can straight up leave out an initialization because you gave it some dummy value when defined and now the program has buggy behaviour that's probably considerably harder to track down. &gt; Leaving a variable un-initialized is a ticking time bomb you cannot control. Not necessarily. In the context of production C? Certainly. But that was just a decision. It's entirely possible to make a different one. A guaranteed runtime assertion (or an exception if that makes more sense for the language) on first use is a pretty well-controlled scenario, and it comes with much of the context you'd want (most importantly, the reason for the assertion and which variable triggered it). In C, a sanitizer is capable of doing almost that, for a lenient definition of guaranteed. But if you initialized it to some dummy value, that's no longer possible. I'd 100% prefer reducing the likelihood of a bad value up front by making the variable immutable and reducing the initialization logic to a single expression without murdering readability (perfectly doable in many cases). However, it's pretty common for this to not be the case in the real world. Given the choice, it's easy for me to pick failing as soon as possible over a dummy value that I hope doesn't cause the rest of the program too much trouble.
Easy. Just remove the number you "picked" form the list each time. The list will continually grow smaller until you have no numbers left, and your numbers will have had no repetition.
https://en.m.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle
Non-Mobile link: https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^127602
HashSet, not a list.
You could make a hashset where the number is the key and the value is something like "true", and then test to see if that key/value pair exists. What's the point of this exercise? A random number ensuring the number hasn't been used before isn't truly random. 
Thanks for the report, I'll fix it setting the backing field before it knows if the operation was a success. The reason it throws an InvalidOperationException is because StopBits.OnePointFive is only included in the enum for completeness - there's no underlying stty setting to actually set it (that I'm aware of) and most hardware doesn't support it (it'll throw an InvalidOperationException on Windows as well).
The generally accepted practice is to use sufficient precision, and a good enough RNG to allow you to generate numbers for [hundreds of years without a collision](https://stackoverflow.com/questions/1155008/how-unique-is-uuid).
This is the worst possible amateurish solution. Program would run slower and slower for each subsequent number. Just think what happens when count is 1'000'000 and 999'999 numbers are already in the list. Random number generator would have to run many many times to generate the exact last remaining number. Each iteration would have to scan the list to see if number exists. It is quite possible for random number generator just not return that last number and then program would just end up in the endless loop forever. 
I don't think anyone is going to download and run a random msi that some reddit user posted on the internet. If you want people to use this, you either need some credibility ( what's your name? why should I trust you?), or you need to post source*. Also, a license of some kind would be nice. * I know I could decompile and poke around in the results, but that would probably be illegal many places, especially given the lack of any kind of license. 
I assume someone will come along, download it and confirm it's safety. Ultimately it's just a little project I set myself for today and wanted to share. I made it for myself but figured others could benefit from it :)
They said "If you have a relatively low amount of numbers".
HashSet.Add returns false when you're adding a duplicate. A fast test with with 100 000 numbers took 11s with your style, and 0.0075s with while (randomNumbers.Add(number) == false); when randomNumbers was a HashSet. Yea I know, no need for such amounts of random numbers, but as this is not "harder" per se I think it's worth it :)
&gt; Why? Well in C# the compiler is very good at making sure a var gets set before being used. No, in C# you must *always* initialize variables before their use. You’re thinking of *fields*. &gt; By not initializing, you make sure that all control flow results in the var being initialized. The compiler initializes all fields (to 0, or the equivalent of 0) when the object is created, whether or not you assign it yourself afterwards. 
I’ll be using this for all my console apps!
Thanks for the reply, but can you show how can I do that? 
Is this what they call Fisher–Yates shuffle?
That's nice concept, would love to see how can i make it? 
Yeah, but it's still a gross method of doing it.
Assuming your random number generator can't assert that there'll be no duplicates, how would you propose to do it? Whether you keep a list of used numbers, or use a hash-set until you have a count of 'n', how would you propose to do it? Stack Overflow seems to agree with this line of thinking: https://stackoverflow.com/questions/26931528/random-number-generator-with-no-duplicates
Can you not just do: while hashset.count &lt; count { hashset.add (new random number) } it won't add duplicates and will keep looping till you have the required amount.
That's great to know. Thanks.
Are you just avoiding something like this... [Random Number - you can never be sure](https://i.stack.imgur.com/tsNeV.jpg) You can do a check if the number already exists in a list or use a hash won't let you add duplicates. But instead of being random, now you are becoming deterministic. Playing a dice game, first roll is anything from 1 to 6, but after a few rolls with 4,5,6... safe bet you can only get 1,2,3 now. Even a casino with multiple cards has issues with card counters, so they shuffle often to avoid people guessing cards and probabilities to gain an edge. In deterministic games, like card games. Create a list of every possibility, then randomly choose from the list , or shuffle and pop the top card off the stack. There's no chance of repeats, as each card gets removed as you use it. When you run out of cards, just recreate the deck as needed to keep going.
Thanks for reply, So hash is the way to go?
If the deterministic value is small, or too random. Hash would be a good way. If it's a small set of possibilities, faster to build and shuffle the set.
If you think most professionals are reading technical documentation rather than checking StackOverflow, I’ve got some news that may come as a surprise :p
Where do you think RTFM comes from? You need to be able to glean answers from the docs. Not every piece of technology had a wealth of stack overflow answers.
x = number of integers you want between min and max. Look at Enumerable.Range to make your starting list of numbers of the set {min, max}. Then loop x times, choosing a number from this list and then removing it from the list as well. That will be your output.
...is this your homework?
It's actually a project for school.
&gt; I assume someone will come along, download it and confirm it's safety. This is the most retarded advice I've read all day.
Console.Readline() will return a string that the user typed. Look at the available string functions, you'll find one that looks like a winner. Now go do your homework and don't tell the professor you got help from the internet ;)
[Little Tushy](https://github.com/keithwill/LittleTushy) is a library for doing WebAPI-like request/replies over websockets using protobuf serialization and optional LZ4 compression. It was designed for making calls to backend services with less overhead than web api. After benchmarking the results though, it appears that the only real performance win is in using protobuf instead of json. HttpClient communicating with WebAPI is already really fast since it keeps connections alive.
Removed: Rule 5.
Removed: Rule 2. If you want to share/distribute this, upload the source code/project to GitHub and let people build it from source.
Removed: Rule 4.
ikoshelev.abc.xyz ? I don't see the problem. It's essentially your company name.
Personal opinion - I don't recommend Troelsen in your case. Troelsens books on C# are very basic, they can be good if you have no prior programming experience at all, but won't help you to really dig into the subject. Furthermore, he does not steer you to the best practices, instead trying to cover every aspect equally. "C# 7.0 in a Nutshell" by Joseph Albahari is a very good choice - the author is very professional, practical and passionate about C#. If you want to learn the best parts - he is your guy. "Pro CLR in C#" by Jeffrey Richter - this will teach you what is under the hood of CLR in a very comprehensive manner. It only goes up to .NET 4.5, but, AFAIR, nothing new was added to CLR since that time, most additions were for C# language itself. "Clean code" and than "Clean architecture" by Robert C Martin - this will teach you how to use everything you've learned in the previous two books to make actual good software in C#. This book is a must-read with any programming language really, but especially so for languages with very reach feature-sets like C#. When you CAN do so much with your chosen language, it is sometimes hard to figure out what you SHOULD do.
I wouldn't worry about using your name. Lots of things are named after the people who started or created the thing (think of maths, science, etc.). 
I don't think those guys chose to name things after themselves. I think it was a following historical consensus that decided on the name. Whenever I think of a scientist who rushes to slap his name on any would-be discovery, he does not invoke an image of a good professional in my mind. 
To me this contradicts OSS philosophy. What if other people join into the project later? What if their contribution ends up bigger than mine? Putting my surname as a namespace, in my mind, makes it 'that guys project', and I don't want it to be just that guys project. Not to mention, why would other people want a mention of my name in their codebase? 
&gt; To me this contradicts OSS philosophy. What if other people join into the project later? What if their contribution ends up bigger than mine? If at some point it bothers you, you rename it. That happens very often in the OSS world. &gt; Putting my surname as a namespace, in my mind, makes it 'that guy's project', and I don't want it to be just that guy's project. Even if you don't do this, it will still be "that guy's project". This only ever changes if you have enough frequent contributors that have an interest in the project itself. Having your name in the namespace does not change anything about this, at all.
&gt; For a good example - 'Newtonsoft.Json'. &gt; the humble part of me protests using my name in an open-source project namespace. And why? Your example `Newtonsoft.Json` did exactly that. This is based on the authors name: James Newton-King.
OnBarUpdate sounds like nothing should be set arbitrarily to 0. My guess is that this has been randomly hacked together. At any rate, you need to look at all usage of that variable to make a correct analysis. What you have shown can't possibly be all, because the thing is never read, so...
Using your name is fine. But if it really bothers you, register a .com for all your projects. 
I have to port something over to run in Linux. I was going to just rewrite it in python, but now I’m going to do it in C# just so I can use this...
Huh? That's new to me, I didn't know Newton was actually his surname. I guess that settles it. 
Would be nice to integrate it with something like NLog. Anyway, love it!
no, Fisher–Yates describes how shuffling works (by swapping each entry once with a random index)
You want to use SQL Express. Add the database MDF file to your setup project and then change your connection string to point to the application startup path. Be sure to add SQL Express as a prerequisite to your setup as well.
Silly question but could the previous Devs fiddled with the host file on the machine you're running? Also van you launch the page locally? 
I doubt it and if you mean open a browser on my machine and reach the site; yes, but if you mean a ctrl+F5 then no, can’t connect to the db. Something is up with the connection string in web.config (already tried creating a new user for the sql instance and the provider still won’t open)
I'm not sure but isn't MaBar[0] auto initialized to 0? It is a list element, and it is initialized to their default value. IMHO, only the second if is needed. 
&gt; why would other people want a mention of my name in their codebase? It's a using at the top of the file. I can't ever remember an instance where someone cared that a proper name was in a namespace. 
The answer really depends on whether you will be hosting the database, or if it should be installed on the client. - If you host it, then best practice is to have a hosted server side (fx a Web API project) and make all calls from the client through there. - If the clients are supposed to host it, then you should consider something called "SQLite" which is installed through a nuget package. This means that it doesn't need any installation apart from installing the Wpf client. I hope this helps a bit. 😊
 MaBar[0] = (CurrentBar &lt; Period || Period &lt;1) ? 0 : /* calculate value */;
IKoshelev.Linq.GridQuery is good. I'd recommend registering your name as a domain and get that set up in Azure as soon as you can. 
Nope vars. Int x; Switch( &lt;something&gt;) Case 1: x= 2; break; Case 2: x=3; break; Default: x=-1; break; Console.writeline(x) This will compile fine... And if someone adds: Case 4: &lt;forget x&gt; The compiler will error.
If you aren't comfortable with your own name, come up with a "Product Name" for the entire suite, and use it.
When you say it "only saves the name of the person and a number" to the database, is that literally the only use for the database? I would consider storing that elsewhere rather than including an entire database dependency just for two values.
If that's just it... maybe you can just use a local object and LINQ queries...
Do you need the database? If it's a small amount of data could you not use xml or sqlite or something?
I'm pretty sure the two of you are saying the same thing and /u/Dralex75 was saying *"the compiler makes sure that you initialize variables before using them"*, not *"the compiler makes sure to automatically initialize local variables for you"*. Also, technically fields are variables, they're just not *local* variables.
Amazing, thsnk you so much exactly what I was looking for. I've read half of clean code, love the book!
Why don’t you just use sql azure - that way all pc can connect to the same db in the cloud and you don’t have to worry about if sql was installed or not?
Probably get a domain you like the sound of better, whether it has your name in it or not. Domain is exactly how all namespacing works on Android so collisions don't happen on the play store.
RTFM comes from users of software, not just those writing it. In a 10 year career I can probably count on one hand the number of times I've gotten anything significantly more than method names and parameter information from the docs. If I have a problem, 99% of the time SO provides the answer.
And in this post, what do you think would have been gleaned? The method name. Which was precisely the problem. Searching SO vs asking a question on SO are different.
Apart from the OP knew the method name, just didn't realize the casing mattered or overlooked it. They were unlikely to notice ToUpper != toUpper from staring at it: asking others, however, works because most of us have made the same mistake at some point
Why create a dependency hell when you don't have to?
Relatively low is relative. I would not consider 1 million numbers as huge. Just for fun I ran the code from the original post and timed it. Here is the time it takes to generate N numbers: * 1000 numbers, 1 millisecond * 10'000 numbers, 47-80 milliseconds * 100'000 numbers, 5300-5500 milliseconds * 200'000 numbers, 19000-20000 milliseconds * 1 million, 581'000 milliseconds Good news: infinite loop avoided. 
Using the word var here is confusing. If you are actually using the keyword var you need to initialise it otherwise the compiler won't know the type. var thing; Won't compile. What you are taking about is local variables I'm guessing 
You can ask leading questions to teach someone to look for those things. "Are you sure it's spelled toUpper"
Parallel or not, you should use a 2 dimentional array of `struct Color` for this. MUCH MUCH faster and safer to work with. Also you can use `simd` and probably be able to copy(or link it with fixed or using a native alloc func) it to frame buffers or use with other graphics libraries directly.
By default on En-us windows only -\|/ characters appear. No cool spinning donuts or snakes. Maybe spinner is cool only in Japan :(
Sure, but "Watch out for case sensitivity" is a lesson that will stick with them too.... I'm not their teacher, I'll tell them the answer and a tip for it (case sensitivity) if I'm aware of it. If you want me to enforce academic proprietary, let me know when I'm getting my salary ;)
Please see the edit, everyone.
Constrained sets, like a card deck, maybe, or a homework assignment to get the student to use branches and loops and things.
Install cygwin with msys2, could work, in theory.
If you need a relational database look into using SQLite. No installation for your end users. Otherwise, as others have mentioned you should probably just serialize the data to XML or JSON and store it on disk since your dataset is very small. 
Yes - readable code Write your code for humans: the performance difference is negligible, but the maintainer being able to easily see the default can be very helpful
Complicated setup kills coolness somewhat. Usage could be simpler as well. Like this for example: var spinner = new Spinner("Stage 1..."); Thread.Sleep(1000 * 3); if (taskFail) spinner.Fail("Something went wrong"); else spinner.Done(); 
SQL Compact is a dead end. A great idea, but the installation for it was a pain in the ass and Microsoft has abandoned it. My recommendation is to use SQLite. In theory it isn't as good as SQL Compact, but in practice it is a lot better.
No. Nullable reference types are not actually new types. T ThrowIfNull&lt;T&gt;(T? value) where T : class =&gt; value ?? throw new ArgumentNullException(nameof(value)); is going to actually compile to something like this: T ThrowIfNull&lt;T&gt;([Nullable]T value) where T : class =&gt; value ?? throw new ArgumentNullException(nameof(value)); Nullable value types on the other hand are actual types: T ThrowIfNull&lt;T&gt;(T? value) where T : struct =&gt; value ?? throw ArgumentNullException(nameof(value)); compiles as T ThrowIfNull&lt;T&gt;(Nullable&lt;T&gt; value) where T : struct { if (!value.HasValue) { throw new ArgumentNullException("value"); } return value.GetValueOrDefault(); }
Fair enough. try the gtk-sharp spinner then. much nicer. Label labelWorking = new Label("working...") { Visible = true }; Spinner spinner = new Spinner() { Visible = true }; PackStart (labelWorking, false, true, 0);//can use PackEnd instead if it's wanted at the end of something PackStart (spinner, false, false, 0); spinner.Start(); //3 seconds later Label labelDoneStatus = new Label(statusString) { Visible = true }; spinner.Stop(); spinner.Visible = false;//can also remove them instead labelWorking.Visible = false; PackStart (labelDoneStatus, false, true, 0);
Your message seems to imply you linked something but there's nothing here. Also. Use proper paragraphs for us to be able read your stuff easier.
Yeah, sorry. On mobile and lazzy typing.
http://www.c-sharpcorner.com/article/how-to-paste-json-as-classes-or-xml-as-classes-in-visual-stu/ Past json as a class, within visual studio
To be fair, it started a long time before Android came about, but the sentiment still holds true.
First be clear about what you are trying to accomplish and then you'll find your desired algorithm naturally "emerges" from the description. You are generating N random numbers from a set of size K. Because you are using Random.Next() K=2^31-1. People so far have suggested: 1. permuting a list of K numbers and reading off N results 2. generating numbers and testing for uniqueness 3. pregenerating a list, randomly picking from that list, removing the picked element Let's analyze each for space and time requirements. Algorithm 1, requires generating K numbers and storing them. Space O(K) time O(K). Permuting N elements. Space O(1) time O(N). So #1 requires O(K) space and O(K+N) time. Algorithm 2 is a Las Vegas algorithm, it will always return a correct result but depending on N and K the time used will vary. Without proof I'll just assert that collisions are very unlikely so long as N &lt; sqrt(K). In that case space O(N) time O(N log N). Algorithm 3, is a worse version of algorithm #1 so we will ignore it. Shuffling is faster than shifting. Because you have K significant larger than N you should use algorithm #2. But if you instead N very nearly or equal to K, you should prefer algorithm #1.
I thought about it some time ago, but decided a custom domain name doesn't add any value to the blog, but adds some maintenance to it (even if only once in a few years), so not worth it. I'll just go with my surname for OSS projects for now. 
There is no best in concept. Best algorithm depends on relative size of N and K. Where is the number of elements desired and K is the size of the set from which elements are drawn. If N&lt;&lt;K then tracking drawn elements is faster. If N ~ K then shuffling is faster.
`Color` kinda sucks and there is little that can be done: http://referencesource.microsoft.com/#System.Drawing/commonui/System/Drawing/Color.cs,1333 It contains a `string`, `long` and 2 `short` fields. The layout means you have a lot of copying to do if you want to reinterpret it as a `Vector&lt;T&gt;` to use any sort of `simd` instructions on it. If you are trying to do something fast, starting with a `uint[]` or `byte[]` to represent the image and reinterpreting (in core2 with a `Span&lt;Vector&lt;byte&gt;&gt;` for example) is going to be the fastest way to do things. OR work with `Bitmap` and let native GDI do its thing.
Well done Sir!
sorry, I meant make your own. struct ColorRGBA { byte r,g,b,a; } struct ColorHSL { byte h,s,l; } Havn't worked with windows-specific stuff for so long I forgot it's there.
Register the name and hold it (if its available) even if you dont intend to use it now. You may regret in the future not being able to register it later if someone takes it. 
that's standard behavior, thank the .net guys who decided exceptions are alright. also xmlserializer caching and extern function type casting.
Newtonsoft.json on NuGet is the defacto solution for handling json
if i can inferr that you don't want to host the db online and assume you aren't understating complexity: if you update the thing constantly-&gt; just host it somewhere.... otherwise: if it really needs database features: msaccess .mdb if it is rather simple: xml 
Can you share the models? You likely don't have the properties set up correctly.
will this still allow me to access all of the 3 spelling errors (not just 1 of them) and how would I access these variables?
can haz code plz?
Only fix no take &gt;:(
And 99% of the time it's completely unnecessary and just causes version control problems .NET already has JavaScriptSerializer built-in that does the same thing with zero external dependencies. Unless you've got a particularly complex object to cast to then there's no need for newtonsoft most of the time. Paste json as class JavaScriptSerializer js = new JavaScriptSerialiser(); MyObj obj = js.Deserialize&lt;MyObj&gt;(jsonString); Job done. 
This is how you can get color from rectangle "(_currentTarget.Fill as System.Windows.Media.SolidColorBrush).Color". What kind of color picker are you using? 
Removed: Rule 4.
I am using this color picker. https://www.codeproject.com/Articles/42849/Making-a-Drop-Down-Style-Custom-Color-Picker-in-WP I will give your suggestion a shot. 
so many options here. - store it in sqllite locally - create an api that the application contacts that stores it in your database - just right it to a flat file on the pc - store it in a cloud service that you host that can be accessed via api - store it in memory if this is a single use case options that require connectivity will need a way to generate a token there are lots of options for that as well.
I've made an auto-generator for complex web applications. You enter your data model: an artists has multiple albums with multiple songs. Then you press generate and it makes the database, controllers, models, and views, with filters/sorting/form validation and conditional display of elements.
Just a single API call can cause this issue? I'd start looking at loops or accidental recursion: Method A calling B, B calling C, C calling A. Also possibly a DB query returning far too many rows.
The presence of a worse alternative doesn't mean this one can't be improved.
Yep, just one. I haven't found any recursion, my loops are all tiny, and the database has about 15 rows tops during these tests (I'm deleting it regularly).
You might be slowing it down enough for the problem to not become apparent. If there's a bug somewhere causing a loop to run infinitely, or some non-obvious recursion, then it could easily run thousands of times a second and any allocations could stack up and might not get deallocated if they have live references. I'm not sure if this will work but you could try using a conditional breakpoint in all your loops and various places: System.GC.GetTotalMemory() &gt; 500000000 500 Mb. If this works, then what it'd do is allow you test and these breakpoints won't activate until you hit the condition where it "runs away". But it's possible the recursion is occurring somewhere non-obvious. Constructors can cause recursion in non-obvious ways especially when you have fields/properties being initialized inline with their declaration. Similear constructing A, A constructing B, B constructing C. So if you don't have one of these breakpoints in a code path where runs away it won't catch it. You could also use a hitcount breakpoint in a similar way: https://blogs.msdn.microsoft.com/devops/2013/10/07/hit-count-breakpoints/ Set it for 500 maybe, so any breakpoint hit more than 500 times will activate. You could use a memory profiler to try and identify what's using the most memory. If you compile as 32bit then you might get a OutOfMemory exception instead of crashing your computer and be able to see a stack trace that might give you an idea where it is stuck.
Your computer can run through loops a lot faster than you spamming F10. I would suggest debugging by logging the steps your program takes and do some counting. If you post code we can help review it. 
There are websites for this too; it's an easy copy/paste/click/copy/paste affair copy json, paste into website, click to generate, copy class from website, paste into visual studio http://json2csharp.com
reduced cyclomatic complexity. from cracks in xml.Split('&lt;').DefaultIfEmpty() let crack = cracks.Replace("\r", "").Replace("\n", "").Replace("\t", "") where !string.IsNullOrEmpty(crack) &amp; !crack.StartsWith("/", StringComparison.CurrentCultureIgnoreCase) let PrimaryKey = crack.Contains(" ") ? crack.Split(' ')[0] : crack.Split('&gt;')[0] let SecodaryKey = crack.Contains(" ") ? crack.Split(' ')[1] : "" let iclose = xml.IndexOf("&lt;/" + PrimaryKey, xindex, StringComparison.CurrentCultureIgnoreCase) let istart = xml.IndexOf("&lt;" + PrimaryKey, xindex, StringComparison.CurrentCultureIgnoreCase) where iclose &gt; 0 &amp; istart != -1 &amp; iclose &gt; istart &amp; (iclose - istart) &lt; 500 let index = xindex += (iclose - istart) select new XmlData(xml.Substring(istart, iclose - istart), PrimaryKey, SecodaryKey, crack.EndsWith("&gt;", StringComparison.CurrentCultureIgnoreCase) ? "" : crack.Split('&gt;')[1], crack.Contains(" ") ? crack.Split(' ')[1] : ""); 
And the second you need something the serializer can't happen? You're going to be mixing serialization methods.
If the API has a schema, you should be able to represent that schema. You may need three different objects, you may not. I don't know anything about the api you're dealing with and you didn't make it easy by formatting it.
use contoso
Wow, first post in the sub a get all of this. Fantastic! It's a simple aplication, no need for updates or anything. I really like the SQLite idea, and I think it's actually easy to do. For the question about if I need the database, i'm learning so i'm testing things and I want to try send the aplication to other people, to see how it works.. Some of the answers requires more advance knowledge, azure, linq, xml, json are thing that noobs know only by name haha. But out of curiosity I will search more about this things :) Thank you for all the answers, and see you around! /u/danishDad /u/rossisdead /u/MastersInDisasters /u/DoYouEvenThroCodeBro /u/allinighshoe /u/alazicza /u/grauenwolf /u/Googlebochs /u/Shadowvines /u/damonous
I made an almost fully procedural skyscrapers puzzle solver forin under 4 hours. 
Thought about it :-) But that also has the overhead of having to check that a chosen made-up name actually does not collide with something existing, across many languages and domains, and all possible sound-alikes etc. My own name has a benefit in this regard - to it at least I have a legal and moral claim. 
How are your references? If you creat properties the old way it’s easy to reference itself and hit a location where it loops and stack overflows. 
I am sorry to make confused you. My library determines OS's code page is whether Unicode or not. And it uses ASCII art spinner if code page is non-Unicode. Sadly, today's almost Windows code page settings are non-Unicode (UTF-8) and "Command Prompt" doesn't support font fallback yet.☹ But you can change the code page by `chcp 65001` command and use ConEmu or mintty to display the fallback font.
Can you post the code to GitHub?
Oh also, any secondary calls out to apis/services in a loop?
Is Helper application a CPU bound process or IO bound process? Does it perform any IO besides WCF and Console? If the app is IO bound, I am afraid this is the best scalability you can get out of this architecture.
This is what I did. I bought up a my name domain as well as a domain I use just within my own network and I've been using it as a namespace for my sandbox/junkyard projects. 
Perhaps something like [Fizzlefade from Wolfenstein 3d](http://fabiensanglard.net/fizzlefade/index.php)
What is your IDE? A memory profiler will tell you exaclt what is going on.
As I thought. Japanese just have cooler gadgets. Even windows console is better in Japan.
Sounds like GC can't keep up with all the objects. Stepping through slows down your main process enough for GC collection to occur. So while it appears to work, it's only because your throttling your main app by debugging.
&gt; The most common scream in any team development scenario is something about newtonsoft not loading the right version because every member of the team is slightly different. Are you my coworker? This is currently my hell.
GC should automatically do collections under memory pressure. I'm not sure this is the issue unless objects aren't being released in time.
Without examples, or a snippet(s) of code, it’s rather meaningless to attempt to provide any type of meaningful diagnosis to your problem. 
Your choices are SQLLite LocalBD Sql Express Or a Jason file If as you say it’s just a name and number, use a Jason storage.
Yes, and if u fill it faster than it releases it won't keep up as it has a schedule for different generations and does it on a different thread...
Which database connector are you using, and how are you using it? It sounds like a memory leak caused by a database connection not being freed. Are you using the standard DI container?
There is a one-line solution: ``` var numbers = Enumerable.Range(0, N).OrderBy(x =&gt; rand.Next()); ``` Though it will take long for larger pools.
The HandlePoints are the small rectangles that show on your screen to resize the Rectangle. These are poitioned manually and the coordinates show where they are to be positioned - i.e. one in each corner and one in on the mid point of each side. In method PictureBox_OnMouseMove, handles the code to decide how to resize the Rectangle depending on which HandlePoint is clicked upon - i.e either resize vertically, horizontally, or both and also the direction of the resize (i.e. make bigger or smaller). The amount to resize is gained by capturing the coordinates of the mouse when the button is clicked down (for example (10,10)), another set of coordinates is captured when the button is released (for example 25,25)). This means the new resized Rectangle will be 15 pixels bigger is both length and width.
Post your code!
Thank you for the response. Yes I knew about the points and I was under he impression that the person is giving the OffSet points in theory that he has made those moves? So in this case the width and height became increased by (5,5) and the OffSet of the rectangle to form is then subtracted by (-2,2)? 
How do the version control problems occur? If you use NuGet and only one person commits this change to the SLN or CSPROJ file then shouldn't it be safe?
Hi! I think random numbers must be free of any condition, although they are not random numbers at all. Even though you can use a HashSet with the Bloom filter to speed up building the list, also for your purpose you can use Cuckoo hashing instead. 
I'm not aware that this is a standard functionality. Try disabling your extensions one after another to find out which is adding this information.
This code generates 9 Rectangles, (8x ResizeHandlers and one main rectangle) - The Size(5,5) refers to the size of each ResizeHandler rectangle. The offset (-2,-2) positions the ResizeHandler over the centre of the main rectangle border (I don't think this will work for all points though).
This code generates 9 Rectangles, (8x ResizeHandlers and one main rectangle) - The Size(5,5) refers to the size of each ResizeHandler rectangle. The offset (-2,-2) positions the ResizeHandler over the centre of the main rectangle border (I don't think this will work for all points though).
How About this book: Pro C# 7: With .NET and .NET Core 8th ed. Edition https://www.amazon.com/Pro-NET-Core-Andrew-Troelsen/dp/1484230175
Is your DbContext shared or do you dispose of it ? 
Thank you for your help. If I may ask while we are here - For the code OnMouseMove, they calculate the new size of the Rectangle. Would calculating the handle point of 8 be the same as 7? I feel the height would also be effected but I'm not sure how to calculate this. If you know how I should do a google search that would be helpful as well and that way I can study the equations. I tried typing, calculations for resizing a Rectangle c#
Definitely a valid concern, I'll have to dig into this more - may be more IO or memory bound than compute bound.
What specifically do you want to learn? Best practice when authoring your own libraries and API? Or is it that there are specific libraries or frameworks out there you're interested in learning? Or something else entirely?
The code you're writing works but probabilistically has terrible runtime performance, especially as count becomes bigger. You're probably looking for a way to "shuffle/permute a finite sequence" (google it)
This is what I would suggest. Hashsets are fast and cheap, so this would probably work up to a few million ints before running into performance issues.
Thanks for your reply. At the moment I have very little idea about APIs. Basically, I just want to be able to integrate other APIs with my applications
I think it is VS Power Tools extension, check in the options there.
Never seen it. Must be something you added. Check your extensions.
OP, reading your other concerns, this seems like the way to go. Either one name for the whole suite, or individual names for each library. It's going to be the best way for you to avoid feeling vain, though sometimes I find it to be one of the most stressful parts. Keep a thesauraus handy. Also your username reads like an interface name and that would drive me nuts so I think you're making the right choice.
Usually you would have an end goal in mind. E.g. you want to do more advanced unit testing, so you learn about an isolation framework and how to use it; or you want to authenticate users, so you learn about the Identity Framework. An API is a set of functionality that you can use in your application, but you would usually have a reason for it. If you just want to learn general things, then LINQ is probably a good place to start.
What would be best practices for authoring your own apis?
My personal opinion, the two biggest ones: 1. Make the API as small &amp; minimalist as possible 2. Provide clear documentation and/or examples Beyond that, breaking changes in future versions are of course not great.. but if they're going to be there, document them and/or add clear compile-time messages, e.g. that something has been obsoleted and to use 'X' instead.
That was what I thought as well, although I don't have that installed. So unfortunately that is not it.
I agree. And i think its like also about the environment. like when its a bad environment its going to be harder to get better at coding. for example you might have people like neighbours or colleagues who want to kind of disturb you or mess you around? That might sound funny but its a real thing. For example i think john carmack was one of those people lucky enough that he could do his coding ever since he was young and with hardly any interruption
API's are *application programming interfaces*. It is a general term and isn't specific. What type of applications do you want to author? Web apps? Desktop apps? games? Be as specific as possible because there are a shit ton of APIs for various different purposes.
SQLite is certainly good i think. I like that it has a pretty much full sql feature set
And don't forget about the fact that it doesn't need to be installed on the client PC. It'll just deploy with the app. 👍
Thanks for your comments! I already felt I shouldn't make the SSL stuff insecure by default. Luckily some other commenters gave me the suggestion of a setting a `HelpLink` and adding more information to the `SslStream` exception. What I'm doing now is catching exceptions from `SslStream.AuthenticateAsClient[Async]` method and using it as an `innerException` for my own `SslHandshakeException` that I then throw which contains both a `HelpLink` as well as a verbose error message explaining the potential problems. The way the Async/Sync code works now is that I have shared internal methods that take a `bool doAsync` argument. If `doAsync == true`, then it filters down all the way to the low-level I/O logic which will use `ReadAsync` and/or `WriteAsync`. Otherwise, it uses `Read` and `Write`. 
Open plan offices or cubicles with their usual noise levels make it hard to concentrate on a problem. Noise cancelling headphones or earmuffs can only do so much. Interruptions are even worse. [The problem is old (TL;DR: p271 "Effects of the Environment on Performance")](https://pdfs.semanticscholar.org/4218/135e28eed9023fded5edb0605dd62b5579a7.pdf), Tom DeMarco (and others) wrote volumes about that topic, yet not every CTO has ever read them or acknowledged its wisdom. Well, [People Ware](https://www.amazon.com/Peopleware-Productive-Projects-Teams-3rd/dp/0321934113) is still on my todo-list, so, you get the idea ;-)
 Probably better for: https://www.reddit.com/r/VisualStudio/ but that doesn't seem super active. Anyway, is there a reason not to use 2017? The first thing I would try is enable/disabling "Enable Just my Code". That causes a few hangs, and does this happen with any project or one specific one?
The code for each point will be different. If you're struggling to visualize this, try drawing a rectangle on some grid paper and write coordinates for each corner. Simulate a drag movement by drawing a new rectangle (tip: one corner will always remain unchanged!)
You need to start by learning the types of APIs and how to call them. I would suggest learning how to call HTTP / Rest APIs. They are nice because for many operations you can use a browser or simple tools (for example: cURL, postman, or fiddler) to test them before you write any code. In a job you would probably need to know how to call WCF services and handle message queues or other types of services, but HTTP/Rest services will cover the majority of the types of APIs you are likely to want to integrate with for personal or learning projects. Unqualified 'APIs' can also mean the public classes and signatures inside of a DLL that you would want to reference. Were you talking about calling things over the network, or about code that you could call from within your application without networking?
I have seen similar a behavior caused by Windows Defender Real-Time protection, when it kicked out everytime I build a project and hanged VS for the time of scanning of newly build executables. 
You can open a second instance of Visual Studio and attach to the first instance of Visual Studio, and have it break on all exceptions. That may give you an idea of what is causing it to hang.
The good start is - https://docs.microsoft.com/en-us/dotnet/csharp/ - from where you can get everything about c# I depends only on you, how much you want to know :)
Behavior should be used for something that has nothing to do with a business logic, but view - for example you want to scroll your listbox into selected one when the view is shown - that is super UI specific thing a should be kept in that way. You don't want to have your code in 3 places - view, code behind, view model. When you have such behavior it can be reused in different places as it can be a pretty generic one. When it comes to events such a button click, there is big no no for a code behind. The reason for that is that you want to keep your view separated from your model - you should always use some implementation of ICommand to leverage binding in your view so you can write something like: &lt;Button Command={Binding MyCommand}/&gt; Doing so you can easily test your ViewModels (otherwise you would have to call those clunky "Btn_Click" methods with all parameters in your tests) which provide business logic implementation and you can always exchange view (different view, web vs desktop...) connected to that ViewModel without affecting logic at all. 
Nice :) 
You can try enabling the logging for Visual Studio [\Log](https://msdn.microsoft.com/en-us/library/ms241272.aspx) and it should tell you what's happening. Also, I think I had problems with vs2015 where some projects were hanging or not compiling at was able to fix it by deleting the '*.suo' file. (It was hidden by default) This was for a really large project and the suo file seemed to get corrupted occasionally. I'm not sure what became of suo files but from what I see they no longer exist in 2017. 
Because you have no internet access it might be the certificate revocation check that's slowing things down. This check is made any time a signed DLL or EXE is used. [Try this to disable the check system wide](https://stackoverflow.com/a/19882266)
Sounds like a memory leak. Make three memory dumps 15 seconds apart, fire up windbg and find out what's on the heap.
Pragmatic Programmer is a good read. Its more C++/Java, but the concepts are pretty good overall. Also, maybe start reading up on and implementing design patterns.
Clean Code Dependency Injection in .NET (far more wide reaching than just dependency injection)
Jeffrey Richter : clr via c#
Got that one, not sure why you recommend it? 
I have been lol:) I have been confusing myself on where the points are I think. Please let me know if I should change things. This is how I have calculated it.. I am using the given numbers of the tutorial(100, 100, 300, 300) dragPoint.X equaling to 300 e.Location.X equaling to 100 diff = 200 areaRect (100, 100, 100, 300) if (dragHandle == 8) { int diff = dragPoint.X - e.Location.X; areaRect = new Rectangle(oldRect.Left, oldRect.Top, oldRect.Width - diff, oldRect.Height);
Not sure if other answers were on-point, but if you're doing a desktop application you can embed Flash via ActiveX control into a Winforms application. Then, you can use ActionScript's ExternalInterface from Flash to interop with C# and the ActiveX control's interface to send from C# to Flash.
I do this for minor decisions being made (e.g. deciding what data structure to use in an algorithm), where if/else feels heavy.
Are the strings the same case? I noticed the link had both Id and ID. 
Add a bool to the ViewBag or your Viewmodel. In the view key off of that for the button enable. 
&gt; **Performance.** In this update we continued to improve performance. Solution load times for large C# and Visual Basic projects is nearly cut by half. The time to switch between debug and release is significantly reduced. It is faster to add, remove, and rename files and folders in .NET Core projects. Project templates should now unfold much faster than before. In the most exceptional cases, you can see up to a 40x improvement in unfold time. 
GOF Book
Your comments will continue to compile even once your code has long since changed in meaning.
This same argument can be extended to dynamic vs static typing. After all, you can just not mix up your types.
&gt; just don't reassign the value if you don't want it to change Just don't mix up your types if you don't want run time type errors. Who needs static types amirite?
I’m pretty sure the OP is talking about learning to consume a RESTful Web api. That’s usually the first context in which a new programmer hears the term ‘API’. 
Is there any information on when (if?) `Span&lt;T&gt;` APIs will make it into the .NET Framework/.NET Standard? 
Indeed, if not for the fact that type determines storage. A better example would be using nothing but void* - but still not quite the same. More like declaring everything public.
`Span&lt;T&gt;` itself is on NuGet https://www.nuget.org/packages/System.Memory/4.4.0-preview2-25405-01 Framework apis taking Span and Memory aren't even released in Core yet ( they are still being worked on)
Nice. Have they fixed the issue where your settings randomly corrupt on Windows 7?
[removed]
[removed]
[removed]
[removed]
From the article: Visual C#. VS 15.5 adds support for C# 7.2 features like Span&lt;T&gt;, the readonly struct modifier And the private protected access modifier.
Yes, I know support for `Span&lt;T&gt;` itself is there now, but new framework APIs that could consume spans (e.g. `Stream.Write`) aren't yet. So you still need to copy your spans to arrays, strings etc. when calling those methods.
&gt; The time to switch between debug and release is significantly reduced Yes please. 
Don't know. Do you have a link to the bug report?
I ran your code and got the same results as you more or less. No speed difference, and sometimes the parallel version is a bit slower. I played with the numbers width and height quite a bit to see if I could see a pattern, but it really was the same no matter what: parallel was about as fast as non-parallel, and actually parallel a bit slower sometimes. However I found a magical sweet spot with the numbers doubled (width = 6000 and height = 8000) With these numbers, the non-parallel took 400 ms and the parallel version took 22ms ! I have no idea how to explain that, and no other combination of width &amp; height caused such a weird result. I also tried removing your List&lt;List&lt;Color stuff altogether and replaced it with just some CPU intensive math operations. In this case the results were predictable - the parallel version was several times faster than the non-parallel version no matter what values I used for width and height (except for very small values which is not surprising). I think you might be on to something. CLR is probably doing some kind of optimization when creating these big lists that I cant really explain. 
Guessing it's the one I've run into as well. Numerous bug reports on developercommunity.visualstudio.com with different errors that are all solved by deleting privateregistry.bin from %localappdata%
Does this mean I can finally stop using random text editors and the command line like a savage and use a real IDE on my Mac too?
Historical debugging, woohoo!
Just don't confuse "Visual Studio for Mac" with "Visual Studio". They're two entirely different products. "Visual Studio for Mac" is essentially a rebranded and pimped Xamarin Studio.
Dude, just use one of JetBrains IDEs. Why be so savage?
The "Effective C#" books.
Adaptive Code. If you're into learning more architectural patterns
I’ve been doing this on windows ever since I started using VS Code.
Is the Xamarin Remoted simulator available on the community edition for it now and does it work on windows?
SqlConnection is pooled so it should be fine with highly concurrent connections and it doesn't open a physical connection for every instance of SqlConnection, **this is the recommended approach in my opinion and scales very well.** If you really run in a hard limit with open connections you could reduce them with a queue + worker, in case of akka like 1 super actor(with the queue) with 10 child actors(the workers), that queue work with round-robin.
But won't thousand concurrent connections bring the DB server down or make it busy for other operations?
SQL Servers are very smart in handling concurrency, if you dispose of the SqlConnection after using it im really sure there are fewer connections to the server as you actually think. If you are concerned then measure it with SQL Management Studio or similar software for your database provider. * Get connection from pool * Execute query * Return connection to pool its simplified but you can do alot of queries per second over a single connection, also as i said sql server's are concurrency first class citizens. 1000 op/s are really not a heavy burden on the server, especially if you use parameterized queries. 
Wasn't this an enterprise feature earlier?
That's the one.
There was/is intellitrace, but that was something different.
Thanks for the tests!
I disagree--not light reading for a novice.
Money.
I've been told this will be coming in C# 8.0. At least according to James Montemagno and Frank Krueger as they discuss program language evolution on their podcast. [Worth a listen](http://www.mergeconflict.fm/73)
Forgive my ignorance but what exactly is replication and what is it used for?
I don't see the update notification in VS yet. Is it a staggered rollout or something?
That's what they claim. I've been using it on the enterprise edition of Visual Studio on Windows, works great.
There is no pretty solution to this, but you could simply use a normal member function or property instead of a lambda, e.g. [Replicated(RelevantType.Conditional)] [ReplicationCondition(nameof(ShouldReplicateConditional))] public string Conditional { get; set; } private bool ShouldReplicateConditional =&gt; Conditional != null;
Try opening the visual studio installer, I usually find them there before VS notifies me.
Is 70-483 still relevant? Not that it won't be relevant, but it might be lagging behind recent standards and frameworks?
Not so much a read, but Jamie King on Youtube has some very good explanation videos of a lot of C# concepts.. a few to get you started: [Generics](https://www.youtube.com/watch?v=q9h_AvUXIJ8) [Lambda expressions](https://www.youtube.com/watch?v=KRjeu9Thp3s) [Anonymous Types](https://www.youtube.com/watch?v=u8C9iO_4yIQ) [IEnumerator](https://www.youtube.com/watch?v=2EqUvjJFeWA)
It's worth posting a link for others: Rob Miles' *C# Programming Yellow Book* can be found [here](http://www.csharpcourse.com) - a nice intro to the language, and a worthwhile read even for more experienced devs.
I know. Floppy disks and no version control. 
This is how I have done it in the past. Attributes are very limited on the types they can accept. The other way is create an interface with a single method bool ShouldReplicate(string propertyName) and have your framework call that.
`OpenFileDialog` provides you with a file path, pass that path as a string to your background thread, open the `FileStream` there.
I am working through that now, my exam is planned in January. Even though it only handles C# 5, I feel it is still valuable. As far as certification exams go. However I would like to mention C# in Depth by Jon Skeet. That's one of the best C# specific books I've read.
Actually I do get the string but it never occurred to me this solution. Thanks. 
I think the issue is that OP is calling [`FileOpenDialog.ShowDialog()`](https://msdn.microsoft.com/en-us/library/e61ft40c%28v=vs.110%29.aspx) which blocks the calling thread and, IIRC, has to be called on the main thread. It's not exactly trivial, but it might (or might not) be possible to workaround: https://stackoverflow.com/questions/478476/c-sharp-openfiledialog-non-modal-possible
Have you read the .NET Framework Design Guidelines, 2e yet? 
1) You can configure what application will be run at the start in Run -&gt; Edit Configurations menu (choose a .NET executable configuration type and set a path to your `MusicBee.exe` here) 2) There's no UI for post-build event editing, but it can be added manually by editing .csproj file and the following line before `&lt;/Project&gt;` closing tag: &lt;PropertyGroup&gt; &lt;PostBuildEvent&gt;copy /Y "$(TargetDir)\*.*" "C:\Program Files (x86)\MusicBee\Plugins\"&lt;/PostBuildEvent&gt; &lt;/PropertyGroup&gt;
why are you taking a cert exam?
Still useless for my current situation until Team Foundation gets added, which is a huge bummer. 
I'm writing an e book that's not quite what you're looking for, being a text for intermediate programmers learning C# for the first time by completing a moderately sophisticated chess project. It isn't done and won't cover all your wishlist when it is, but I'll [link it](https://leanpub.com/checkmate-csharp/) anyway and perhaps you'll be interested in a complementary copy. 
Well in all honesty, for career reasons with the company I work for. Having certs is a plus at yearly salary discussions and it helps getting into the devteam I would like to work for eventually. The company likes the certs as well, I think something to do with being Microsoft partner and customers sometimes wanting the 'best' people on their job. But all that's more of a paper mess I guess. I don't mind the training and exam btw, I do get other value out of it as well :-) Because it's not as easy as I thought it would be, I do actually learn 'things' even being an experienced developer. Though actually using those 'things' in day to day situations will probably be rare. It's more knowing they exist if you know what I mean.
Pro ASP.NET Core MVC is a good book for web development. It goes through the process of building a MVC app using core and emphasizes unit testing each step of the way and current design patterns used when doing this type of web development
While others have many valid suggestions. It may be better to get lots of the data and then delegate the processing to the workers by passing the data. Rather than each worker individually query it. I say this with no experience in Akka.Net, but imagine you can spawn many actors each given some parameter of work they need to accomplish.
Thanks. As someone who has programmed for nearly a decade, I've wondered if a C#/MS cert would help me with other jobs in other areas... I plan on moving soon.
your lecturer gig sounds pretty cool. is it better than adjunct? i think teaching would be a fun gig for a few years, maybe for side income
I didn't see 'light', my bad. It's still something that should be on the list though
Unfortunately the KeyDown on my Form doesn't fire. The only event I can get to fire is KeyDown on a TextBox. No idea what I'm doing wrong...
Yeah and that would be great except I need a bunch of shortcuts. I wish to navigate through my application using a keyboard.
Ah. Gotcha. Yeah, I'm eager for those too. We've already started switching some of our string parsing code to use span and I'm really liking it. 
What coding software are you using?
So I tried what you suggested. public static Rectangle skincolor; skincolor = (_currentTarget.Fill as System.Windows.Media.SolidColorBrush).Color; Keep getting error. Cannot convert media.color to shapes.rectangle.
I like the "C# 7.0 in a nutshell". you can check it for free at safari books
Look up an accumulator pattern, and only bother with every 3rd iteration, or increment plus 3 once you are on a good starting number.
Removed: Rule 4. You'll need to breakdown the problem into parts (addition, `for` loop, modulo operator for divisible by 3), and probably consult your learning materials, or the learning resources in the sidebar or /r/learnprogramming. Then you'll have to make an attempt at solving the exercise. If after doing that you still run into issues, feel free to post a question but you'll need to include the relevant code you have attempted with and explain what did/didn't work. That said, be sure to use the `long` (`Int64`) data type, not `int` (`Int32`) for your summation. Summing all the numbers divisible by 3 between 1 and 2 million will be too large to fit in an `int`.
All lecturers in my university system are adjunct, we don't get tenure and at best receive three year conditional appointments. It's not a good financial move as a primary profession, but there are benefits if that isn't your primary motivation.
I didn't know SonarQube so I didn't put it in the article. I'll check that out. Thx.
&gt; I think it's just an advertorial. I don't work for any of those companies that develop mentioned tools but yeah, one point of view might be that I'm advertising those solutions. Although I'm doing it for free. 
I know we are supposed to move away from Bower, but does anyone know if this fixed the Intellisense issues in Bower.json? I could never get any of the packages to properly load while I am typing.
Thanks again for the tip, I got everything working while at runtime now. I do have one additional question pertaining to this. How do I go about saving and loading the rectangle.fill so when I close and open the app it does not reset? I know how to do a Textbox, but not sure with a Brush. Brush skinbrush = (Brush)this.FindName("skincolor"); string skinc = System.Drawing.Brush(skinbrush); Keep getting error brush cannot be used as a method.
I've got my exam on Friday,having already failed it once. If nothing else, holding the cert might make you more appealing to companies, if you are thinking of moving. I'm sitting mine for my company; we want to become MS partners and need so many certified devs to do so.
How long have you programmed in C#?
is that updated for Core 2.0
Unfortunately not no. Its using core 1.1 so the configuration parts are all out of date.
There are free books online... which are perfectly great. I recently read through one by Microsoft, with a red and black theme released in 2015/16 called “step by step” and I loved it. The only issue I have is being bothered to learn more about the last chapters involving tasks and other topics. 
Daily for around two years now. I should ha e passed first time, but got caught out by some of the less developer type questions (deploying apps over an intranet, certificates, etc, things that aren't strictly regarding the writing of code).
:)
Here to say yes to Jon Skeet
time to start branching more, advanced .net is about learning all the APIs and enterprise stacks (WCF, ASP.NET MVC, WWF, etc etc). Normally MS built in stuff first but it wont hurt to play with some of the more popular software products companies buy based on .NET as well if you can. 
Can we use async+await ?
It is. Lastest version is about .net core 2.0
You can but one of the constraints of this project was to use Monitor.
Nice! That would have saved me an afternoon trying to figure out where to manually add dependencies 
Most of the code in an updated version is available on the book repo. I don't have a link sorry.
This book is awesome: [C# 7.0 in a Nutshell](http://www.albahari.com/nutshell/) This book is awesome and contains a 'short' section (100 pages) on .net core 2.0: [Pro C# 7](https://www.apress.com/gp/book/9781484230176)
What you're trying to learn falls under experience. You don't need a book, you need to code and experiment with things.
Yeah, this seems to be the standard. Several unit testing frameworks I've used do this, and it works out OK. 
It looks like it's sort of along the same lines as INotifyPropertyChanged. https://docs.unrealengine.com/latest/INT/Gameplay/Networking/Actors/Properties/.
[removed]
Very early stages of a site to help developers stay organized. Got sick of the time it took to context switch between tasks, look up work I had done previously, remember to follow up promptly, etc. http://devsimply-test.azurewebsites.net Note: test environment for now. Passwords are hashed but go over the wire as plaintext so don't use anything sensitive if you give it a try. Any feedback is immensely appreciated. 
Ah, thanks.
The point of C#'s auto-accessors is cutting down on boilerplate and therefore noise. No one in their right mind is saying your properties should default to `public`, nor that you shouldn't use `{ get; private set; }`, and so on.
I’ve done things like this many times over the years. The key is to have whatever work you are doing run in the background thread and not the dialog. Having said that, if you insist on doing it all you have to do is run a message pump in your worker thread to make it a UI thread and this will work like normal. Not recommended though. 
I don't think the response is really about auto-accessing properties, but rather, creating a situation where you can mutate the properties outside their class, which is a design I tend to agree with. I tend to fall into the public get private set realm
Really helpful. Lots of great examples of how and why to apply the principles. The reality is that lots of people are writing lots of programs where the longest continuing running operation is essentially Receive Data -&gt; Validate Data -&gt; Preform uninteresting and fairly trivial operations on said data -&gt; Store the result in some database. Writing fleshed out classes for your data in these cases is a waste of time, you're often going to use them literally once. Writing half-assed OOP code is in my experience reliably worse than just writing it in an mostly imperative style (Plus dependency injection). I mean don't get me wrong, if you have complex code or code that might actually might get reused writing good OOP is really worth it. Consuming well designed objects is a treat. But just blindly deciding that all data has to be encapsulated always is a mistake IMO. I do agree that public mutable data is pretty gross. But the much simpler solution is to make it immutable.
&gt; I tend to fall into the public get private set realm Yeah, me too. I guess I was just a bit surprised by this beginner-level explanation being written by someone who's been at it for 14 years.
Removed: Rule 4. You'll have to consult your learning materials and make an attempt.
Condescending writing but its not a bad point imo, I think a reference to 'Tell don't Ask' would help readers find more material on the topic. e.g https://martinfowler.com/bliki/TellDontAsk.html Mark Seeman has an interesting article on this too http://blog.ploeh.dk/2011/05/26/CodeSmellAutomaticProperty/
Removed: Rule 4. Please include a question. /r/csharp is not a code mill to do your work for you. This is the fourth submission of yours that's had to be removed this week. Please put forth an effort to include the quality of your questions.
I am so sorry my code is completed, what I am trying to figure out there is when i is 9 how many time j loops.
http://freecomputerbooks.com/ http://www.freetechbooks.com/ http://www.onlineprogrammingbooks.com/csharp/ 
I completely agree. The 4th edition is coming soon, but you can already buy it and read the finished chapters through the MEAP (Manning Early Access Program), 
OK that's fixed. I also refactored most of the code, set the serial port to raw mode by default, and made sure the XML documentation is exported and included in the NuGet package on build.
There were too much text in the article to say something this simple. Also, I disagree that the properties should be made into private fields. How are you then going to read the data? With a get method? No. Keep the properties, and make the setter private... 
Nice little tip! Thanks for sharing.
Joshua Bloch's book Effective Java (currently in its 3rd Edition) talks about this for a bit. What it boils down to is this: For a mutable object: * A setter should create its own copy of said object. * A getting should return a copy of said object. These are referred to as *defensive copies* and are talked about in Effective Java 2nd Edition p184-188. I don't have the 3rd Edition yet to see if they're still mentioned. Generally, you create these via copy constructors if they exist.
You could switch to a "Fluent"-style declaration instead of attributes, which are quite limited and also "pollute" your classes with stuff that's not necessarily related to their main responsibility. It could look like: myBuilder .Replicate(x =&gt; x.Name) .Replicate(x =&gt; x.All, RelevantType.All) .Replicate(x =&gt; x.Conditional, RelevantType.Conditional, () =&gt; whatever) //or .ReplicateIf(x =&gt; x.Conditional, () =&gt; whatever) .Replicate(x =&gt; x.OwnerOnly, RelevantType.Owner) and so on. You may be familiar with the pattern from other libraries.
Using C# auto-properties is using encapsulation. If you look at the cil generated by the compiler, you will see that public double TotalPurchases { get; set; } will result in a private field with a get and set method. Really you should read the above code as private double totalPurchases; public TotalPurchases { get { return totalPurchases; } set { totalPurchases = value } } which is equvalent to the first code snippet, but more verbose, not as verbose as Java though.
I will take a look later today. My guess is that there may be some special attribute similar to Column to make it map to Name instead.
Use the DatagridView OnCellClick event handler to display a ComboBox allowing the user to change number of legs or animal type. Then use the the SelectedIndexChanged event handler on the ComboBox to update your model properties. Check out this example. http://www.c-sharpcorner.com/blogs/steps-to-add-combobox-inside-datagridview-window-form To avoid the user having to to click twice for a selection change in the comboboz to update your model, checkout this post. https://stackoverflow.com/questions/7193910/datagridview-combobox-event-handler-problem
Thanks, everything works :D. In case other people have these problems I'll just keep this here for the record: If the build is failing during the copy, change the access rights to the "MusicBee\Plugins" folder, so Users can modify it.
Shame! Shame! Shame! Procedes to compare programmers to two year olds Procedes to advocate OOP Okay dude...
`Span&lt;T&gt;` is indeed only available via the Sysem.Memory NuGet package. But with C# 7.2 we got the ref struct feature that you can now use together with `Span&lt;T&gt;`. But the existing APIs in the .NET framework and .NET Core framework are not there yet, for that you indeed still have to wait. But it's available for your own code!
`Span&lt;T&gt;` is indeed only available via the Sysem.Memory NuGet package. But with C# 7.2 we got the ref struct feature that you can now use together with `Span&lt;T&gt;`. But the existing APIs in the .NET framework and .NET Core framework are not there yet, for that you indeed still have to wait. But it's available for your own code!
I just created a library and an analyzer that brings the concept of Nullables to classes as well. I'd love to hear feedback from you all.
Isn't the Span&lt;T&gt; that's available now a wholly different beast without ref struct though? If people start relying on it, they are going to paint themselves into an awful corner when they realize they can't e.g. use a Span&lt;T&gt; as a class field after they've already refactored their code to do so.
As you note, there are lots of other option types and maybe monad implementations for C#. I'm not sure that this one provides a significant value over any that already exist. Also, restricting it to reference types will make it more difficult to write generic code that handles different types consistently. Your Default&lt;T&gt; class looks like it's going to introduce thread safety problems and weird issues with code in different places overwriting default values configured elsewhere.
* John Skeet's C# in Depth - good look at how and how the language evolved over the years. * Effective C# - 50 ways to improve your C#. has some really good do's and don'ts. * CLR via C# - has everything from introduction to detailed inner workers for the CLR.
&gt; I'm not sure that this one provides a significant value over any that already exist. I wrote this in part as an exercise, and in part because I'm looking something closer to `Nullable&lt;T&gt;`. &gt; Also, restricting it to reference types will make it more difficult to write generic code that handles different types consistently. I hadn't thought about this. &gt; Your Default&lt;T&gt; class looks like it's going to introduce thread safety problems I'm interested in this. What issues can this have, and how can I fix them? &gt; weird issues with code in different places overwriting default values configured elsewhere. The point of this is that you would set the default value only once: in the static constructor. This isn't enforced, but I can include validations both in the library and the analyzer. ---- Thanks for the feedback, by the way.
Just curious - what's your use case for `Span&lt;T&gt;` ?
I have a hobby bitcoin node that I play around with from time to time... the amount of byte array copying I currently do is insane. I'm pretty strict about not corrupting things, so it's ImmutableArray&lt;byte&gt;'s all over the place. My current strategy for Span&lt;T&gt; is that each transaction will be backed by an ImmutableArray&lt;byte&gt;. Then when I have have things like input and outputs, which are mostly made of the public/private script bytes, I'll just store an offset into the parent transaction's bytes for where those live. That way I can always get those public/private script bytes by just taking Span&lt;byte&gt; views into the parent transactions data. I think this should work fairly well, using a transaction as the fundamental unit of where I store my backing byte array. As I accept transactions off the network into the mempool, and then process and later store those to disk, I can avoid doing any unnecessary copying by just carrying that one ImmutableArray&lt;byte&gt; copy of the transaction around the entire time, even if those bytes get shared around and used my multiple types.
Azure websites actually support https out of the box. Just change to https://devsimply... And everything should work. 
&gt;I tried to do this obscure thing with this code snippet but it didn't work in some unspecified way, so I tried another code snippet with another library and it happened worked for whatever reason. Great article.
&gt; I'm looking something closer to Nullable&lt;T&gt;. What happens with this? var x = ((int?) null).Value; Your NullableOf&lt;T&gt; doesn't match the behavior of System.Nullable, here. &gt; What issues can this have, and how can I fix them? Initializing an array is not going to be an atomic operation, so something calling `Set()` on a different thread could result in an array containing two different default values. If you build a library using this class, which is called by code that *also* uses it, you have no way to ensure that a type used by both contexts is only registered once, nor do you have any way to guarantee that the default a given context receives in the one it expected. There's really no way to prevent code from registering a default for a different type, *nor do you want to*, since so much code exists that won't have a default value registered. This sort of thing is a big part of why reference types have a default value of null, and why the C# 8 changes don't establish a non-null default for reference types. `Set()` could also be supplied with a delegate that is expensive (in terms of CPU time or memory) to evaluate, which can make an array unexpectedly expensive to create. (This sort of thing is why structs are not allowed to overload the default constructor, FWIW, and is probably why the C# 8 feature does not include a means to define a non-null default for a reference type.) Some other, minor details: `NullableOf&lt;T&gt;.value` can, and probably should, be declared `readonly`. It won't break anything, since the field is never reassigned after the object is created, and it will make it slightly easier to reason about the behavior of `NullableOf&lt;T&gt;`. `DefaultT&lt;T&gt;` needs some error-handling around what happens when `Get()` is called for an unconfigured type. `Equals(object)` would probably be cleaner/more readable if it used pattern matching with a switch statement public override bool Equals(object other) { switch (other) { case null: return !HasValue; case NullableOf&lt;T&gt; x: return HasValue == other.HasValue &amp;&amp; (!HasValue || value.Equals(other.Value)); default: var otherType = other.GetType(); if (otherType.IsConstructedGenericType &amp;&amp; otherType.GetGenericTypeDefinition() == typeof(NullableOf&lt;&gt;)) { return false; } return HasValue &amp;&amp; value.Equals(other); } } Implementing `IEquatable&lt;NullableOf&lt;T&gt;&gt;` and `IEquatable&lt;T&gt;` would probably also be benificial. If you declare private, default constructors in `RequireClass&lt;T&gt;` and `RequireStruct&lt;T&gt;`, you shouldn't need the `Obsolete` attributes and won't have to disable the warning in your extension methods. Instead, add a documentation comment on the classes. Making your type operate on both value and reference types would eliminate a pile of duplicated code in your LINQ extensions, and remove the need for the constraint classes, too. The last part of your `Equals(object)` implementation looks like it's reducible to `otherObject is T &amp;&amp; HasValue &amp;&amp; value.Equals(otherObject)`, FWIW, which would be clearer than reflecting into the type to see if it's another `NullableOf`. `Default&lt;T&gt;` could be declared as a static class. Finally, I'm not sure how I feel about using IL weaving to insert null checking. 
Man you weren't kidding. I kinda wish that I didn't read the article now.
Possible problem with that equality: NullableOf&lt;string&gt; a = "foo"; NullableOf&lt;object&gt; b = "foo"; a.Equals(b) == ???
There are two aspects to this. For quite a while now (since 2.0 IIRC) the runtime will refuse to load classes with `Span&lt;T&gt;` fields and will throw an exception. The advent of `ref struct` allows the detection of this problem in the C# compiler so you find out about it when you build, not when you run. The runtime protection is still there in case you're not using C# to generate IL.
What about it? public static void MyMethodIn(in int x) { int y = x; Console.WriteLine(y); y++; Console.WriteLine(y); Console.WriteLine(x); } 
But the `Span&lt;T&gt;` from the latest available Nuget package is *not* a `ref struct`. Boxing and storing spans compiles and runs without complaint on C#7.2 and .NET 4.7.
&gt; What happens with this? &gt; var x = ((int?) null).Value; &gt; Your NullableOf&lt;T&gt; doesn't match the behavior of System.Nullable, here. I'm using NullGuard.Fody, which adds a null check, so it does throw an exception. The weaver is only used internally for a few null checks like this, so that I wouldn't miss accidental nulls. Code depending on my library don't need to use it, because it would be redundant functionality. I'll make sure to document all of this. ---- &gt; Initializing an array is not going to be an atomic operation, so something calling Set() on a different thread could result in an array containing two different default values. I will make the `Set()` method so that it can only be set once, to avoid this. &gt; Set() could also be supplied with a delegate It is already a delegate, if you look at the source code. &gt; that is expensive (in terms of CPU time or memory) to evaluate, which can make an array unexpectedly expensive to create. (This sort of thing is why structs are not allowed to overload the default constructor, FWIW, and is probably why the C# 8 feature does not include a means to define a non-null default for a reference type.) I understand, and I made a note in the README: &gt; Of course, the NewArray helper method will create a new array and then iterate it and create a new class for each item. Take this into account when creating large arrays so it doesn't affect performance. This is a trade-off that at least I can live with. I'm not sure if this concept can really be applied for performant applications with the given restrictions. ---- &gt; Making your type operate on both value and reference types would eliminate a pile of duplicated code in your LINQ extensions, and remove the need for the constraint classes, too. I'm still giving this a thought, since my initial goal was to keep using the existing `Nullable&lt;T&gt;`. ---- I read the rest of the comments, and they're all reasonable. I'll include them in the next version. Thank you for taking your time and helping me.
have you looked into netstandard2.0 as your compile target? seems like it's the right fit for your use-case.
I think it would be encapsulation if the type of the private member were different than the type returned by the get. Otherwise I see no difference from a straight up public member except for two additional pointless methods.
If those of us who have been at it -- no matter how long -- don't share even the fundamentals then who are those who haven't been at it very long supposed to learn from? Only each other?
1. `false` 2. I think that matches the behavior of the code in question. It also matches the behavior of the Option in F#: let x = Some "foo" let y = ("foo" :&gt; obj) |&gt; Some x.Equals(y) Fixing that probably means introducing an internal, explicitly implemented interface or something to expose `value` as an object, which would make it simple enough to fall back to switch (obj) { case null: return false; case NullableOf&lt;T&gt; x: return Equals(x); case T x: return Equals(x); case INullableOf x: return (!HasValue &amp;&amp; !x.HasValue) || (HasValue &amp;&amp; x.HasValue &amp;&amp; Equals(x.Value)); // recursive call default: return false; }
`Index()` uses both `_db` *and* `_mapper`, but only one *or* the other can be set in the constructors. What exactly are you expecting to happen, here?
Serialisation for one. Also reflection. And the guidelines state you shouldn't expose fields publicly.
Basically just display the data from correlating models in a view table. Nothing really special... I've been told to familiarize myself with Automapper and Autofac, so I thought the MSDN Contoso University example would be an easy place to start... I'm kinda wrong. Thanks for clarifying that. ... where do I go from here? I still need the _db for other action methods that I didn't post in the code above. Is there a workaround? 
Desktop is/was using a different `Span&lt;T&gt;` than Core, one that is slower but also doesn't have the same "can't be on the GC heap" restrictions. I think this variant of `Span&lt;T&gt;` has since been renamed to `Memory&lt;T&gt;` since it is generally useful on Core too and having one named type with two different implementations was bound to lead to confusion. All of this is pre-release so there is some churn in naming, API surface, behavior, performance, etc.
&gt; Is there a workaround? Make the constructor set set both?
&gt;doesn't have the same "can't be on the GC heap" restrictions. The restrictions are unenforced because it doesn't use `ref struct`, but the reasons for those restrictions are still there. Something like static unsafe Span&lt;byte&gt; Foo() { byte* bar = stackalloc byte[100]; return new Span&lt;byte&gt;(bar, 100); } is allowed but is of course badly broken. &gt;All of this is pre-release That's what OP is asking about, I presume. The VS release announcement touts the arrival of `Span&lt;T&gt;`, but it actually only contains a feature required to support a version of `Span&lt;T&gt;` that doesn't actually exist for .NET Framework.
&gt; I'm using NullGuard.Fody, which adds a null check, so it does throw an exception. I wrote that before noticing you were using Fody to insert the nullchecks, and I'm not really familiar with NullGuard, but: * By using a struct, this is legal and really can't be eliminated: `var x = new NullableOf&lt;object&gt;();`. `x.HasValue` is false, because `x.value` is null, but `x.Value` doesn't *look* like it will throw an exception. If it *does* throw an exception there, that's really not obvious (one reason I'm not crazy about using Fody this way!). It also means you could replace `HasValue` with a straight bool, instead of calculating from `value`, but I'm not sure that matters. * The `value` argument of `NullableOf&lt;T&gt;`'s constructor is explicitly marked with the `AllowNull` attribute, which means that NullGuard won't insert a null check there, right? So, I could write something like `var x = new NullableOf&lt;object&gt;(null).Value;` and x would be `null`, without an exception thrown, right? &gt; I will make the `Set()` method so that it can only be set once, to avoid this. Okay, but code is going to be written based on the assumption that whatever was provided to Set() will be used. Say I write a library that does this: Default&lt;Foo&gt;.Set(() =&gt; new Foo() { Property = "SENTINEL VALUE", }); and my library has some code in it that operates on `Foo`, checking that `Property` contains `"SENTINEL VALUE"`. A coworker uses my library, but has this in their service Default&lt;Foo&gt;.Set() =&gt; new Foo { Property = "Ipso Lorem", }); and they write some code that assumes `Property` may contain `"Ipso Lorem"`. Assuming their `Set()` call doesn't just throw an exception (at which point, my coworker and I have to go back and renegotiate the contracts implemented by the library), they're going to be confused when `Foo.Property` contains `"SENTINEL VALUE"` when they expect `"Ipso Lorem"`. Alternately, I *don't* register a default (so as to not trip up my coworker), and my coworker doesn't register a default (because they forgot, or assumed I had), and, then nullableFoo.GetValueOrDefault(); blows up unexpectedly. The solution is to convert the nullable object to the wrapped type like this, then fooObject.HasValue ? fooObject.Value : new Foo { Property = /* whichever default makes sense in the context */ }; But, if that's really the correct behavior, wouldn't it make more sense to get rid of the `Default&lt;T&gt;` class and refactor the array creation method to something like public static T[] NewArray(int arrayLength, Func&lt;T&gt; generator) in its own class? You could chalk this down to `Default&lt;T&gt;` being used incorrectly, but it seems like there *isn't* a correct use in this scenario. Valid uses still wind up suffering from locality problems, because figuring out what the default value is means going back and finding the call to `Set&lt;T&gt;`. This seems like the sort of problem that occurs with Service Locator.
Like /u/tweq mentioned, instead of having two separate constructors for each dependency, have one constructor that takes in both
was about to post this to /r/pcj as "C#er reinvents standard language feature Nullable&lt;T&gt;" but i will spare you, fellow /r/pcj'er (im not serious)
so... public InstructorController(IMapper mapper, SchoolContext dbContext) { _db = dbContext; _mapper = mapper; }
You can post it if you want. To be fair this is some crazy shit I'm doing.
I think the whole `.Value` and the usage of NullGuard.Fody is getting all mixed up. I'll rewrite it and add unit tests so that it does what it's meant to do. Regarding `Default&lt;T&gt;`, I see where you're going. I'll think of the alternatives.
nawh its nothing jerk worthy tbh, more of a like "huh thats an interesting research/mini project idea but hasnt it already been solved well enough by Nullable&lt;T&gt;?" maybe im just ignorant to the failures of Nullable&lt;T&gt;
&gt; maybe im just ignorant to the failures of Nullable&lt;T&gt; It's just for value types. I'm creating one for reference types as well.
oh duh lmfao sorry its early for me still after a bad/restless night...
Json*
AutoMapper.
You nailed my confusion... I was expecting Span&lt;T&gt; to be available by the announcement, not just the supporting ref struct infrastructure to build Span at some point down the line. I am *really* happy I read up on Span thoroughly before deciding to try it out. Trying things out first could have been disastrous. I may still start my refactor, cuz I am beyond anxious to do so if it isn't obvious. :) I am super nervous I'm going to fundamentally fuck something up along the way though, when Span&lt;T&gt; switches from struct to ref struct...
Do you know which Span the VS announcement was referring to then? "Real" span seemingly isn't available, and if I understand you correctly, what's in the System.Memory package now isn't actually Span at all?
&gt; To be fair this is some crazy shit I'm doing. Not really. Also check out one of the many existing implementations: - https://github.com/nlkl/Optional - https://github.com/AndreyTsvetkov/Functional.Maybe - https://github.com/R2D221/NullableClass - https://github.com/tejacques/Option/ - https://github.com/j2jensen/callmemaybe - https://github.com/bogosoft/Maybe - https://github.com/GregRos/OptionalSharp
This article is pretty terrible. There's a lot of ground for being reasonable somewhere between: public decimal Amount { get; set; } ... and ... private decimal _amount; public void getAmount() { return _amount; } public void setAmount(decimal amount) { //... _amount = amount; } ... Maybe something like this when you're trying to enforce rules on your data... public decimal Amount { get; private set; } public void ReduceAmountUseCase(decimal reduceBy) { // ... Amount = Amount - reduceBy; } 
I've done it. I have something like this: Thread t = new Thread(() =&gt; EncryptAFile(fileDialog.FileName, key)); t.Start(); 
- There's actually no difference between the two things you proposed right? - Why would you make a private set method? The class can always change its own private members. 
public double TotalPurchases { get; private set; } 
The first is problematic when you need to enforce rules on the data inside your class. The second and third are functionally the same, but who writes garbage like the second in C#? Properties exist so that we don't need to write a getter and setter for each instance field. I don't need a private instance field just so I can return it; the property takes care of that for me. The solution when you don't want your data screwed with publicly is the 3rd set of code. The private setter ensures that the *only* way to change the data is through something I expose publicly [in this case, ReduceAmountUseCase()]. The point being, if you're just passing around data, then a public auto property is just fine. But doing it the "Java way" just because you need encapsulation is wrong. 
Yes these are great references
The new .cproj structure is integrated with NuGet, instead of relying on an external packages.config.
&gt; private decimal _amount; public void getAmount() { return _amount; } public void setAmount(decimal amount) { //... _amount = amount; } Did you mean that setAmount to be private?
1. .NET Core csproj I think is what it is called in Microsoft documentation 2. This is mentioned in the .NET Core 2.0 release document. Here is an excerpt: ---- **Reference .NET Framework libraries from .NET Standard** *You can now reference .NET Framework libraries from .NET Standard libraries using Visual Studio 2017 15.3. This feature helps you migrate .NET Framework code to .NET Standard or .NET Core over time (start with binaries and then move to source). It is also useful in the case that the source code is no longer accessible or is lost for a .NET Framework library, enabling it to be still be used in new scenarios.* *We expect that this feature will be used most commonly from .NET Standard libraries. It also works for .NET Core apps and libraries. They can depend on .NET Framework libraries, too.* *The supported scenario is referencing a .NET Framework library that happens to only use types within the .NET Standard API set. Also, it is only supported for libraries that target .NET Framework 4.6.1 or earlier (even .NET Framework 1.0 is fine). If the .NET Framework library you reference relies on WPF, the library will not work (or at least not in all cases). You can use libraries that depend on additional APIs,but not for the codepaths you use. In that case, you will need to invest singificantly in testing.* *You can see this feature in use in the following images...*
No. The second one with a getAmount() and setAmount() showing the standard getter/setter in a language like Java. setAmount() would likely be a specific reason you would change the amount. The key there is that getAmount() is a waste of time and code. Let the property expose the "getter." Here's a more realistic example showing a public property allowing public get, but only privately allowing set. public class Customer { public int Id { get; } // no 'private set;' needed public string Name { get; private set; } public Customer(int id, string name) { Id = id; ChangeName(name); } public void ChangeName(string name) { if (string.IsNullOrWhiteSpace(name) || name.Length &lt; 2) throw new Exception("Name must be at least 2 characters."); Name = name; } }
why are you migrating from .net 4.6.2? are you gonna run apps and libraries on non-windows machines?
Interesting, I've never tried without a setter, is it emitting a readonly private in the IL? &gt; public int Id { get; } // no 'private set;' needed &gt; public string Name { get; private set; } &gt; &gt; public Customer(int id, string name) &gt; { &gt; Id = id; &gt; ChangeName(name); &gt; } 
we just call it the 2017 or new project format. the differences are pretty obvious once you actually look at them. also, the references sections in visual studio are going to look drastically different when working with the new format. for 2, check out the 'Reference .NET Framework libraries from .NET Standard' section in this post: https://blogs.msdn.microsoft.com/dotnet/2017/08/14/announcing-net-core-2-0/ it was an intentional decision they made to allow for porting to be easier. the most important line from the announcement is probably this one: 'In that case, you will need to invest singificantly in testing.' they realized most libraries you're using will work in .net standard 2.0 but may be in a state where they'll never get updated to actually target .net standard 2.0. rather than preventing you from using the new hotness, they just decided to allow it to happen. the onus is on you to just make sure you have sufficient test coverage to ensure you don't get those run-time problems you have encountered.
If these two things aren't the same, please tell me how they are different? public decimal Amount { get; set; } private decimal _amount; public void getAmount() { return _amount; } public void setAmount(decimal amount) { //... _amount = amount; } 
I'm not sure, but that is the goal. Constructor can set it, but nothing else can touch it. In a case like this, changing the identity of an entity warrants creating a different entity.
In function, they are. It was a quick demo, so there wasn't enough nuance to explain why it matters in that case. That's why I provided the Customer example. If we don't want any validation inside setAmount(), then the function truly is pointless #1 is fine. But, the author's point is that #1 is **always** bad because it breaks encapsulation. My response is that you don't **always** need encapsulation, **but** when you do, C# still always a few different ways to avoid you having to do all of the following to ensure encapsulation: 1. Make a private instance field 2. Create a getter as either getAmount() or get { ... }. 3. Create a setter as either setAmount() or set { ... }. For me, I'm either going to use fully public auto-properties when I don't care about the data inside, or I'm going to encapsulate using the way I demonstrated with the Customer class. For C#, both #1 and #2 are extremes at different sides. However, I think there are use cases for #1. The author's demonstration for improvements upon #1 are more in line with #2, but I think the syntax is a poor choice that shows an unwillingness to move away from an old style of syntax.
From IL:: .field private initonly int32 '&lt;Id&gt;k__BackingField' Definitely interesting,up til now, I would have written the field _id with readonly and written a full getter. 
Only CoreCLR detects it. .NET Framework's CLR does not. C# 7.2 enforces proper usage of Span&lt;T&gt;, but you may need to make sure your project is indeed using 7.2 (project settings-&gt;build-&gt;advance). Some older projects opened in new Visual Studio might still be using the old compiler. if you use one of the newer Span&lt;T&gt; packages, there is an attribute applied to it that will cause older compilers to error on *any* use of Span&lt;T&gt;. The 7.2 compiler knows about this attribute and let's you use Span&lt;T&gt; (while enforcing the by-ref rules). Lastly, if you use Span&lt;T&gt; through reflection on .NET Framework CLR, you might circumvent the C# checks, and since there are no runtime checks, you might get in trouble. On .NET Core, the runtime will keep it safe. 
What are the newer Span&lt;T&gt; packages you mention? Is there one newer than the preview2 on nuget?
Hey all! I'm a PM at Microsoft working on the Snapshot Debugger! You can read more about our work [here](https://aka.ms/snapblog). Feel free to AMA!
&gt; if you use one of the newer Span&lt;T&gt; packages Which package, specifically?
Don't code like you're telling a machine what to do. Code like you're telling another programmer what you're doing.
Comment all the things
My first development manager told me - ICE. Indent, Comment, Explain. 
Disagree. Functionaly can change, and redundant comments don't help anyone. Self documenting code is the way to go imo. Comments where necessary.
Also code like you're telling yourself what you're doing when you come back to it in two years time :) 
Implementation can change but the function isn't likely to. Function and class level comments are always good.
Although arguably if you have comments for a change in code, then knowing why the code was changed can be helpful, so that you don't try to change it back and make the same mistake twice. 
One of the sticks I use to evaluate my coworkers is really relevant here and goes like: "*how much effort i need to put to understand his/her solution*". * none = brilliant programmer * some = average programmer * a lot = we start to have an issue here * so much that he/she had to comment it to speed it up = bad programmer * so much that it is impossible without comments = I don't want to work with you anymore.
Don't save characters. Typing and programming are not the same. Typing is actually a small portion of what you do. You'll spend 10x more time reading than typing. So, give things descriptive names, even if they're a bit long. Read the code and sound it out in your head, and if it reads like a sentence, you're golden. Had a co-worker who'd name a JoinNameYAddress because using Spanish Y saved him to characters over And. Seriously, what do you think he did with all that free time?
Agreed. Sparse comments are good. If you feel the need to comment every other line of code, though, something is wrong.
Begin with basic code that is easy to read, and spaced out between major functions and roles. Languages and the culture often follows slightly different conventions. However, it is ultimately for humans to read, manage, and maintain the code. If you find some code that is hard to grasp, or it gets confusing very quickly. It's a good idea to spend some time thinking about why. A great idea to explore code is to dive into community pages for the languages and checkout public repositories for current projects. They are often peer reviewed and great examples for what the language is doing today.
/// Send a new order Void SendOrder(IOrder order) {..} Yeah
What the input describes, expected output, possible side effects (which could change with time). I'd _hate_ to pick something up from you that was documented with just 4 words.
Yes, preview 1 is newer than preview 2. Preview 2 was marked as such by mistake. These preview 2 packages have since been removed. The newest one (built just today) is 4.5.0-preview1-26006-07. And just to make sure we are talking about the same thing: they are on myget, not nuget.
How many of those include analyzers to forbid literal nulls?
yes
Starting with official docs could be a good idea: https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/inside-a-program/coding-conventions When I started in csharp, resharper was a huge help. Resharper, for better or worse, taught me LINQ. If you are a student, you can get a free license. Else, try the trial. Read the style suggestions. Another option is to find a coder you and other devs look up to and learn from example. Get on code reviews. Ask questions. 
What of those you mentioned you dont get from naming / self describing code? And my point is that i didnt mean NEVER comment code, just on my experience enforcing to comment every public method just leads to redundant comments.
I had no idea myget existed... thank you so much! CS8345 Field or auto-implemented property cannot be of type 'Span&lt;byte&gt;' unless it is an instance member of a ref struct. There's the error I wanted to see! You just made my day :)
Well, I wouldn't follow that advice slavishly. If you can avoid indentation, the code will be easier to read. And only comment if you really can't make the code itself easy to understand- it should be quite rare that you need to. 
Lots of good stuff in the **Clean Code** book by Robert C. Martin.
Here is the link to myget feed with Span&lt;T&gt;: https://dotnet.myget.org/feed/dotnet-core/package/nuget/System.Memory 
&gt;And just to make sure we are talking about the same thing: they are on myget, not nuget. Well that explains the confusion. Is this documented literally anywhere? I can't imagine we're the only ones who read the release announcement and headed to NuGet only to find [this official but horribly outdated](https://www.nuget.org/packages/System.Memory/) package.
SCA - Static Code Analysis. Get something like sonarQube and run your code through that. It may not catch everything, but it will at least give you a run through the basic rules and keep your formatting standardized, naming conventions, unused variables, complexity, etc. Also, use tools like reSharper. Basically anything out there that will help you by automatically pointing out possible code issues. You want something that will help you look at your code and determine just how much garbage you just wrote. Also try to group your functions into logical units and files. Self-documenting tools are also pretty awesome, ///
This is fine to a point. I'm currently staring at code (that I wrote) - due to using "full" generic type parameter names (TSource, TResult, etc. over TS, TR, etc.) the code is very hard to read. For extension methods with one line bodies, a 3 line method definition seems excessive.
That's...... literally the opposite of everything I have been taught for about 30 years of coding. You indent subordinate blocks, you comment primary blocks because you never know when you will be by a bus or eaten by a dinosaur, and if there are any parts that are overly complex you explain so that if you do get hit by a bus or eaten by a dinosaur someone else can take over fairly easily and quickly. Or if you have to go in for major heart surgery and will be out of the office for eight to ten weeks, and someone else has to do an emergency release while you are absent and completely out of contact, they can. It is the way I was "brought up" and I really cannot see any reason for doing it differently. 
I am not sure, but I contacted people who work on blog posts and podcasts about Span&lt;T&gt; so they are aware of the issue and try to clarify things in future communications. 
Read [this](https://www.amazon.com/Clean-Code-Handbook-Software-Craftsmanship/dp/0132350882) (Clean Code), a whole book written to answer that one question. If you like that then there are lots of others, just read anything by Robert Martin (Uncle Bob), Martin Fowler, Prag Prog, etc. 
Yep, and because I'm using VS it's gonna intent for me.
If you are updating existing and include any pertinent ticket numbers so future coders (and your manager) can see why you changed it.
This was also the way I learned to code. You should look at Robert C Martin's "Clean Code" book and video series - this has transformed my view (and colleagues' views) on programming. For example, he will explain why commenting to that degree is bad (basically, your code should "read like well written prose", and if you are creating comments, then you haven't written clean code).
I hadn't heard of in parameters, but that's much closer. The only thing I'm concerned, is that article says they behave similarly to ref parameters. Does this mean that they have strange behavior when modified outside the method, in multithreading/coroutine contexts? I don't know enough to comment.
I was writing using Clean Code and I had to write something based heavily on generics. Like you said... it is very difficult to read.
Couldn't agree more. :)
Resharper is definitely a good way to write clean C# code. It does, however, get you to the point where you can't code without it. :) I also advise the use of StyleCop Analyzers. There are a couple of things in there that go against "Clean Code" in the default values (mandating comments on public API calls, ordering of methods based on accessibility [instead of writing in a 'newspaper' format]). But overall, it is a good way to maintain consistent styling across your codebase.
Thanks. I googled around after 15.5 released and explicitly mentioned `Span&lt;T&gt;` support, but I only found non-specific comments about "a NuGet package" (which I suppose isn't wrong) or links to the old version on nuget.com, so I figured `ref struct` spans were still Core-only for some reason.
Working on two things at the moment: * [Consul KV Store configuration provider for Microsoft.Extensions.Configuration](https://github.com/DarkXaHTeP/DarkXaHTeP.Extensions.Configuration.Consul) - allows to use Consul as a configuration server and store app's config there (or mirror it from config repo using git2consul) * [Commadline library inspired by AspNetCore.Hosting](https://github.com/DarkXaHTeP/DarkXaHTeP.CommandLine) - allows creating commandline applications with dependency injection, configuration and logging using familiar for web-developers tools from Microsoft.Extensions.* packages. I use both of these packages on daily basis and would like to hear your opinion on them, also feel free to post issues/proposals on Github, if any
ref struct is a C# concept and it works the same on all runtimes (as long as you use the same version of the compiler). Core CLR has a set of features that are complementary to C#'s ref structs, e.g. Core CLR supports interior pointers to arrays, which is used in the implementation of Span&lt;T&gt; to make it faster/smaller than the .NET Framework CLR's Span&lt;T&gt;. The Core CLR Span&lt;T&gt; implementation has two fields: one to an "interior" of an array (or pointer) and one for the length. The .NET Famework's implementation has three fields: normal reference to an array (i.e. not an interior reference), starting index (or address of pointer), and the length. 
Ok, cool, that matches how I was originally thinking this all worked. The slow/fast span distinction didn't seem to be about ref struct vs regular struct, cuz that's a pretty huge gulf, but I wasn't so sure anymore after the package confusion.
Seriously. Always code as if the person who ends up maintaining your code is a violent psychopath who knows where you live. note: Clean Code.
Reduce nesting and method length and you're ahead of the curve by a significant length. 
It's easier to install jetbrains.anotations.
Formatting Matters! I can't tell you how many hours I've dealt with poorly formatted SQL that is complete unreadable without formatting. C# isn't one of the worst offenders, but JavaScript gets a bit hairy sometimes. Outside of naming, formatting is a close second to helping with the quick comprehension of a section of code. If the formatting is off, it really hinders quickly diving into code because you're constantly distracted rather then focused on what the code is doing. Proper consistent spacing. Line breaks that are consistent. Consistency on whether you include curly braces for single line blocks. Consistent order of how things appear in a class file. There's almost no reason so use excessive blank lines IMHO. I don't think you need to be oppressive about applying the formatting, just have some rules and try to apply it as consistently as possible.
I am the author. I actually didn't say that. Here's some things I actually said: &gt; _When the goal is to track total purchases,_ expose that functionality as public behavior on the Customer class, and encapsulate the data needed to make the behavior possible. and &gt; Of course, it's really your choice. No one can tell you how to write your code. If you don't think you're going to have trouble with "data classes" separate from "behavior classes" in your application, by all means make a good go at it. 
[removed]
Yeah - no. I am not writing a book, I am writing something that someone has to understand in 10, 20, 30 years time. Someone who might not have read ANY code in their life - this might be their first job and their first program. I don't think that explaining what an excessively complex function does (even if it is well written) and the more specific parts of the code do (if there are loops within loops) to help out a first time developer is something we should shy away from. We're not coding for our enemies! We're coding for our colleagues - for our FRIENDS!! Co-operation and helping each other and teamwork. 
Yes. Indent even if it done automatically :) 
Now all we need is testing in prod! Jokes aside, this is really cool.
Getting your function working is just the first step... The rough draft, if you will. After that you revise, revise, revise and make it better. In my opinion, it's the revising that teaches you how to be a good programmer.
&gt; Getting your function working is just the first step... The rough draft, if you will. After that ~you revise, revise, revise and make it better~ put in production. 
What are you talking about? Difficult to read for junior devs/simple "programmers"? Who cares? We pay offshore/Bangalore 50 bucks an hour or less. They can figure it out, so should anyone with a college degree making 2-3x times. If you have to baby your dev's then you're not saving anything.
Do you have to attach to the prod server via VS to so this?
Are you talking about C# and OOP? From reading your comments, it seems to me you learned programming with functional languages. In modern C#, OOP solutions are generally preferred to problems like long methods and nested loops, which themselves makes the code harder to read (you need to keep more of the programs in you head while poking the logic). If you abstract the program's logic in small enough objects, you don't need comments to understand them. Comments which I find useful in C# are the ones explaining unusual logic or counter-intuitive behaviours.
God classes
This is a metric I can relate to! I wonder if I can include it in my code reviews. *Effort needed to understand the solution*: _fuck you_.
"What idiot wrote this code..." Checks commit history Oh. Been there, done that. I learned my lesson (I think).
I love ReShaper. I take its suggestions 90+% of the time. But think about what it is telling you. Yes it can convert your complicated for loop into one massive linq expression, but can anyone understand it anymore? Invert your if statement to reduce nesting? maybe. Maybe you should follow NASA and only have one exit point per method.
1. Get one value from list 2. Add value to a variable 3. Repeat for other values 4. Congrats, you have the total
Dont write mix php and html or html and asp.net 
Clean code - https://www.amazon.com/Clean-Code-Handbook-Software-Craftsmanship/dp/0132350882
I really love the intent of this statement but the most optimally efficient code sometimes ends up being a little more ugly than consumable by other (maybe less proficient) developers.
I disagree with this whole heartedly if you're making something that has restrictions on the type. Like TConfiguration or TDataSource Your point about the one line body is well taken, but I think digesting more text is easier than trying to figure out author intent.
I also find following the SOLID principles helps [wikipedia](https://en.wikipedia.org/wiki/SOLID_(object-oriented_design))
the image didn't submit so here it is up on imgur: https://imgur.com/IPOvqp0
Here's an example: public static (TResult1, TResult2) Bind&lt;TSource1, TSource2, TResult1, TResult2&gt; (this (TSource1 a, TSource2 b) t, Func&lt;TSource1, TSource2, (TResult1, TResult2)&gt; f) =&gt; f(t.a, t.b); Ignoring formatting choices, is there really any advantage to the long type names here, especially given that they're repeated 3 times each?
Your configurations are saved in a file called launchSettings.json, which lives in the project directory root. You can commit that file with your other sources, provided it isn't filtered out by .gitignore (assuming you are using git).
Code like the programmer that will read and maintain your code is a crazy serial killer!
make a new array of ints. use a foreach on the input loop. do your math on each int in the input loop. add the result to the new collection return the new collection.
Just use Color[,]. You'll get basically the exact same programming interface (enumerable, indexing by x and y) and creation is basically the same as a long array. Running in parallel has a nonzero cost. It makes a lot of sense if your tasks are truly independent or if they are expensive. These tasks here are not independent (they have to aggregate to the same list) and they are super cheap. Not good candidates for being parallel. 
Color[,] will still be faster than List&lt;List&lt;&gt;&gt;
Why are you using the light theme?
Avoid `ThreadLocal`, it's really smelly. Instead just create a new instance of whatever you want and pass it to the method that is executed by the thread.
It all depends on the context. In my current job, not only do other programmers pick up my code fairly often but my clients are also programmers. I provide them nuget packages, api or even git projects. I do comment every single class and methods, properties and whatnot. I document the class, method, property itself as well as expected input and output and details about them, the exception my code can throw (even those thrown by the code I call) and I even put links to other members or even external resource, when relevant. Code should be self explanatory, I agree. But it piss me off that I need to jump into your class to understand the detail of a method when a simple comment could have tell me the same so I avoid imposing that on others Thanks intellisense + resharper + enhanced tooltip + exceptional + ghostdoc, commenting properly does not take too much time and it help me review my own code in a very natural way. Plus in my opinion, it makes the code prettier by having clear separations between methods.
the important question
Is this tied to VS only, or is it properly designed and can easily be integrated to VS Code?
Html5 with a angular/react and web api.
[There is only one reply.](http://i.imgur.com/9NwdJfy.gif)
"You are paid well so fuck efficiency"
Fuck no! Quickest way to make assumptions that are wrong! Code comments rarely match what's happening accurately, especially over a long period of maintenance and changes.
You don't think it's possible to do entirely with winforms/wpf?
Well that's a load of crap. You'd be rating programmers like John Carmack as bad. His code was so elegant and concise you literally couldn't understand it, even if you had a PHD in maths.you'd look at it and go I have no fucking idea what's happening and I need to go back to school because clearly I suck.
Is there any way to get this working on an on-promise Linux VM outside of Azure? If not, is that feature coming?
Well, the goal is to be *descriptive*. Just because it's long doesn't mean it's descriptive.
Yes. Use StyleCop. You don't have to use the default rules, but everyone working on the same project should be using the same rules.
Right, but "descriptive" isn't mutually exclusive with "concise" or even "terse". A lot of F# or Haskell code eschews verbose names in favour of being descriptive through program structure or type relationships.
Avoid Cargo Cult programming and Voodoo Programming. Voodoo Programming = Overcoming challenges (why does this have a race condition? What's that little latency glitch when I open the drop-down?) by trial-and error without ever understanding *why* your solution worked. Cargo Cult Programming = Applying patterns you've seen other people use without knowing why, how they work, or if they're helping. DO use Design Patterns. But understand them. A lot of Copy/Pasted code sections within your own code base is a code smell that you should have used a design pattern. Don't be attached to the real world when creating your class hierarchy. OOP is usually taught the wrong way with the Animal/Dog/Bark() or Person/Employee/Customer metaphors and focuses way too much on inheritance. You're assembling a digital machine, not slavishly simulating real world inheritance relationships.
Well, formatting is what this is all about. public static (TResult1, TResult2) Bind&lt;TSource1, TSource2, TResult1, TResult2&gt; ( this (TSource1 a, TSource2 b) t, Func&lt;TSource1, TSource2, (TResult1, TResult2)&gt; f) { f(t.a, t.b); } isn't as bad. anything involving that many generic parameters is going to be inherently difficult to read. I agree that that example is hard to digest, but using "in" and "out" might help. public static (In1, In2) Bind&lt;In1, In2, Out1, Out2&gt; ( this (In1 a, In2 b) t, Func&lt;In1, In2, (Out1, Out2)&gt; f) { f(t.a, t.b); } Is better imo.
This looks awsome! Do you have plans to make snapshots on exceptions work on Linux and for self-contained applications?
I don't think you have really grasped how a mutex works yet. You should read [the documentation](https://msdn.microsoft.com/en-us/library/system.threading.mutex%28v=vs.110%29.aspx?f=255&amp;MSPPError=-2147217396). I don't know exactly what you're trying to achieve, but if you create a new mutex every time then it will always have ownership and there is no difference between that and not having a mutex. You have to share the same mutex across every thread to do any synchronization.
+ great book
Meh, only supported for the combination of Azure App Services and VS Enterprise. Call me when it gets to VS Professional or VS Community. 
There are very few instances where speed is so important that it trumps readability. They exists, but are few and far between. On the other hand, if you code cannot be maintained by the next developers on the project it is close to worthless.
&gt; Well that's a load of crap. You'd be rating programmers like John Carmack as bad. His code was so elegant and concise you literally couldn't understand it, even if you had a PHD in maths.you'd look at it and go I have no fucking idea what's happening and I need to go back to school because clearly I suck. That comment is a load of crap. John Carmack worked on the parts of a system where getting the absolute best performance possible was important. There are very few of those. 
I don't understand your question. What exactly are you trying to do?
The original was just copy-pasted from an environment with a column limit, hence the weird formatting. Using In and Out isn't too bad, although I might still avoid them since `in` and `out` are C# keywords. However, I'd take issue with the parameter name `binder`, since it's the function that's being bound here. The final example breaks the monad semantics I was aiming for.
&gt; Yeah - no. I am not writing a book, I am writing something that someone has to understand in 10, 20, 30 years time. Someone who might not have read ANY code in their life - this might be their first job and their first program. I don't think that explaining what an excessively complex function does (even if it is well written) and the more specific parts of the code do (if there are loops within loops) to help out a first time developer is something we should shy away from. Obviously, you should comment the bits that can be hard to understand. But you should also strive to make sure that there are very few of those. And really, really try not to have loops within loops, that gets hard to test.
Yes and it's hard for others to come along and understand it! Have u read the quake 3 source code...
&gt; You indent subordinate blocks, you comment primary blocks Yes of course you do, but you try to avoid subordinate blocks, thus reducing indentation.
See - I knew we could find agreement and detente. It was just a matter of explaining and understanding :)
Yeah. But sometimes it is just unavoidable :( 
Why *wouldn't* one use a light theme?
Or the other solution i think is to feel out the problem, rather than think about it. but this requires you to be the kind ofpersonality thats not too verbal in the first place
Why does this only work in Azure? Could it work in a typical server environment in the future?
What you just told me is: His code was so complex that no-one but him could work on it. That is not necessary true ;) , but lets discuss this as possibility. If you do make code so great and concise that no one but you can understand it, than you basically locked out everyone else from contributing to this piece. Sure, if you have a one time job and product without long life cycle it may be an option. But most of us work in corporate environments where code can stay for 10 or 15 years - just look how much COBOL is still around. If you make such code in first 2 years, some poor soul 5, or maybe even 10 years later will have to rewrite it to something he or she understand to be able to modify it according to new business requirements. Make that in critical enough module and this is a disaster in the making. Brilliance in programming for me is what Einstein said: &gt;If you can't explain it simply, you don't understand it well enough." You see, my another rating stick is application of common sense. I would never rate a programmer base on solutions for problems outside of my area of competence. Without background in math I would not go nuts about math heavy solution I can't understand. Understanding the solution is a bit different from learning solution. John Carmack would probably by his code thought me how to solve a problem. That would take a lot of time for me to fully comprehend his code, but I would not be trying to understand his solution, I would be trying to learn that solution.
Now you have such great and comprehensive code and you job is to make business change to it (you know, circumstances changed, new ideas are there). Can you do it without breaking anything? How stressful will it be? 
You like staring at bright lights, licking windows?
Looks like you have a compilation error on line 446 because you need to remove the "." at the start. The best I can make of your question is that you are reading some strings from a remote resource, and you want a new tab for each string. You should be able to add new tabs programmatically. Looks like this is what you want: https://docs.microsoft.com/en-us/dotnet/framework/winforms/controls/how-to-add-and-remove-tabs-with-the-windows-forms-tabcontrol
So I ended up solving it by grabbing the overall tabController and then foreach through its tabPages and comparing it to distinctive IDs of each tab to find the correct tab and then add everything. No compilation error though even before I found a solution.
I ended up working out a solution but I was trying to organize this dump of basically research text and I wanted to divide it into area or faculty that you could then choose instead of one massive thing of rich text boxes. So I ended up using a TabController and iterating through its TabPages until I found the one I wanted. If you're interested in the coding I can post an image of my code now.
It's not a e s t h e t i c.
Removed: Rule 4. Feel free to repost, but please include code of your attempt.
It ready like you are already really really close to the solution. [Solution](https://dotnetfiddle.net/BBX0FS) Disclaimer: c# got more than one way to solve that problem, but this is probaly the most basic way without fancy language features.
Because it's harder to read off a projector.
Fuck it. Down vote me if you must, I don't care anymore. I decided to force myself to use dark theme 3 weeks ago because I'm tired of getting shit from the young folk. I don't know how much longer I can take it. It's like driving at night, I can't see a damn thing.
Well since you said AMA; After last update all our references gone wild. Vs underline all Basic types red. Says system, list etc. Missing but compiles just fine. Unload reload Project fixes generally. Not always. Even if I fix all by hand; After git sync, everything fails again. Any help appreciated at this point 🙂
Well since you said AMA; After last update all our references gone wild. Vs underline all Basic types red. Says system, list etc. Missing but compiles just fine. Unload reload Project fixes generally. Not always. Even if I fix all by hand; After git sync, everything fails again. Any help appreciated at this point 🙂
https://stackoverflow.com/questions/20618748/toggle-disable-button-in-razor-view-asp-net-mvc-4
i suggest you go over at github or sourcebrowser.io and check out professional code pieces and how they are structured 
I give them shortish names when originally writing then go back and refactor in descriptive full names
Go with a high contrast theme.
This leads to my number one tip, which isn't about clean code but easy maintenance: comment your code not just to explain how something works, but why you did it. Any code can ultimately be figured out by reading it (though some coffee is more easily read than others) but code can't explain the reason behind the decision to do what you did. You won't always need to do this, but especially do it if you think you're doing something odd, or if a particular but of coffee has an important use that might be overlooked. I once came across code I wrote a year earlier, decided it was poorly written, decided to rewrite it. Hours later I hit a wall when I realized I had tried to write it this way before and that the obvious method would not be able to do what it needed to do, while the "stupid way" I wrote it did. So I wrote a nice comment explaining the problem and why I chose the solution, so that I or another coder would understand the problem before trying to refactor again. That's not the most common reason I explain my code in comments but it's a good example.
How are you finding it? Genuine Q
Yes, that's what he said.
What does "did not work at all" mean? Be precise with the errors you get.
Well.. inside the code there is a comment telling you what happens: Use of unassigned local variable "values" Found out that it has something to do with scoping (-&gt; { })
Oh, I've completely overlooked that part. My bad. No, there's currently no clean way around this. It's a limitation of the compiler. Either use the regular check, as you proposed, or define and initialize the variable before.
You can't do this, because the out variable is declared but the code which would initialize it is not run unless the dict exists. Think of the `?.` operator as shorthand that expands into a null check followed by a function call, and it becomes clear. You can use an extension method to do what you want. I've set up a couple examples in LINQPad which work in .NET 4.7 at least. ```void Main() { Dictionary&lt;string, IEnumerable&lt;string&gt;&gt; dict = null; dict.G("token").Dump(); if (dict.G("token", out var v)) { v.Dump(); } else { "no value retrieved!".Dump(); } } public static class U { public static IEnumerable&lt;string&gt; G(this Dictionary&lt;string, IEnumerable&lt;string&gt;&gt; d, string key) { if (key == null || d == null || !d.ContainsKey(key)) return null; return d[key]; } public static bool G(this Dictionary&lt;string, IEnumerable&lt;string&gt;&gt; d, string key, out IEnumerable&lt;string&gt; value) { value = null; if (key == null || d == null || !d.ContainsKey(key)) return false; value = d[key]; return true; } } ``` 
I don't have first hand experience but I imagine AAA Game programming to be the inverse of typical corporate software development. You have teams of cowboy coders working "together" to get maximum performance out of the hardware that will be available to the public at launch date. So John Carmack being a genius writing magic code that squeezes 10% more fps out of hardware is a good team member in that context. But in a corporate environment this metric still holds, I don't want to work with this type of geniuses.
It's pretty common for an event raised in static code to pass null as the sender. [There are some examples at this SO question.](https://stackoverflow.com/questions/289002/how-to-raise-custom-event-from-a-static-class)
But the Dictionary does exist at that point. Once you reach that if-statement-body dict HAS to be not null AND values is successfully retrieved from `out var values` AngularBeginner wrote that this is a compiler limitation, if so, i hope they can remove that limitation in the future.
I start by thinking "What does the user want to see on this screen or this report?" and work backwards from there.
The dictionary isn't the problem. It's the declaration of the out variable and its initialization. If the dictionary is null, the code the initializes the out variable is never run. (I edited my top-level post to include this fact more explicitly.)
Then again, why does this compile AND code work? var dict = new Dictionary&lt;string, IEnumerable&lt;string&gt;&gt; { ["token"] = new List&lt;string&gt; { "abc" } }; if (dict?.TryGetValue("token", out var values) == true) { Console.WriteLine(values.First()); } But as soon as you nest it's scope, it throws the `unused local variable` at you { var dict = new Dictionary&lt;string, IEnumerable&lt;string&gt;&gt; { ["token"] = new List&lt;string&gt; { "abc" } }; if (dict?.TryGetValue("token", out var values) == true) { Console.WriteLine(values.First()); } }
Hi, these aren’t related to the post above, but a couple of fixes in this area should be coming within a few days.
LINQPad gives me a used-before-initialized error on the first snippet. 
Named mutexes are unique across processes.
That's interesting... Using RoslynPad i get this to compile and work, but can not replicate in VS2017 [RosylnPad Live-Demo](https://i.imgur.com/6k3VKFR.gifv)
And yet you make that seem like a person has killed their grandmother if they don't need to encapsulate. You went on a childish rant that blamed a programming language for doing things in a way different than the way you're using to doing them, and blamed people for doing it that way without knowing why they did. &gt; Shame, shame, shame I know your name C#!!!!!! &gt; This is apparently not only a lesson I have to keep teaching my two-year-old &gt; This is simple Object-Oriented 101! Not every use case for an application warrants building business rules into classes. Sometimes classes are literally just bags of data to shuffle between the database and a front end, because validating that data becomes easier somewhere else. 
Great book, I've just finished clean architecture too and can recommend that, similar book.
I really like this book: "Building Maintainable Software, C# Edition" https://www.amazon.com/Building-Maintainable-Software-Guidelines-Future-Proof/dp/1491954523/
I suspect this a quirk of the way RoslynPad compiles the script. Top level variables probably end up as fields of a closure and thus are auto-initialized, but scoped variables do not.
I opened an issue over at https://github.com/aelij/RoslynPad/issues/172, to hopefully get more knowledge about this
My theory is that the compiler can prove that "dict" is never null in the first example, thus it is ignoring the ?. and just treating it as a . Awesome job causing this.
you were right, i looked at the IL that was produced by RoslynPad, and it clearly shows that values becomes a field. [Related Issue](https://github.com/aelij/RoslynPad/issues/172#issuecomment-349998911)
Misleading. Also, everyone knows about extension methods.
But then high contrast text isn't easy to read properly.
O-O
Actually i highly doubt that AAA game programming would tolerate cowboys, just from looking at sizes of teams. If anywhere, I would guess those can thrive in small Indie companies, where you have 2-3 programmers who need to do all the things good enough and up to deadline. 
Oh great! Thank you so much!
It has been a long time since I last used Mutexes. But there are some things that smell wrong. One of them, that you aren't properly disposing the Mutex, which is IDisposable. And since Mutexes are unmanaged resources that are handled by the OS... I would bet that it's critical to release them on time. Other is that you aren't calling WaitOne. Quoting the documentation (https://msdn.microsoft.com/en-us/library/bwe34f1k(v=vs.110).aspx): &gt; If name is not null and initiallyOwned is true, the calling thread owns the named mutex only if createdNew is true after the call. Otherwise the thread can request the mutex by calling the WaitOne method. At the time, I found useful the bool C# 5 in a nutshell, from Joseph Albahari. Some parts of it are on the internet. The Mutex part: http://www.albahari.com/threading/part2.aspx#_Mutex
&gt; Once you reach that if-statement-body dict HAS to be not null AND values is successfully retrieved from out var values You could create situations where this isn't the case, e.g. class Dictionary { public WeirdEquality TryGetValue(out object value) =&gt; throw new NotImplementedException(); } struct WeirdEquality { public static bool operator ==(WeirdEquality? left, bool right) =&gt; true; public static bool operator !=(WeirdEquality? left, bool right) =&gt; false; } Dictionary dict = null; if (dict?.TryGetValue(out var value) == true) Console.WriteLine("Surprise"); Of course the real `bool` and `Nullable&lt;T&gt;` don't work that way and the compiler might even be able to prove that, but that would probably require special support and an exception in the language rules.
This doesn't support the main motivation for adding default interface implementations: inheriting interfaces and implementing classes can't override extension methods.
If the environment is really toxic, you have several options. - You try to change that by talking to those guys, management or HR (in that order) - You could search for other opportunities, coders are in demand so that might work. - You could [embrace the environment](https://www.youtube.com/watch?v=zBfTrjPSShs) and *only work hard enough just not to get fired*t=1m8s).
I use 3nf tables, join them into usable views, call either the direct table or view in sps or function and then just call those sps from my apis or website. Anyways back to the point, 3nf tables, interfaced by CRUD sps, therefor your models are a request model to the sp and a response model from the sp. The stored procedures, sps, allow you the buffer needed to structure your data to an nNF. You can start from the front end and work backwards with dummy data in your code or from the back end working forwards if you have a good grasp on the data requirements in and out before starting. 
Is there a timeframe to get this to work on Azure VMs? Can I capture debugging snapshots with Application Insights and adding the snapshot debugger dll? Is there anything special I need to do? Does ApplicationInsights.TrackException do a snapshot?
Just imagining some old guy grumbling at his editor all throughout the day while constantly misclicking things and sighing. Hilarious mental image.
Your interfaces still don't have implementation.
Using extension methods as if they are interface members will negate a lot of the benefits of dependency injection.
One nice thing of the null propagating operator is that it returns a null if the left operand is null. So: var dict = new Dictionary&lt;string, IEnumerable&lt;string&gt;&gt;(); if (dict?.TryGetValue("token", out var values) ?? false) { Console.WriteLine(values); } 
Very interesting, I had missed that blurb. Thanks for the pointer!
It has to do with how variables are created in RoslynPad or any C# scripting implementation. Outside of any scope variables become static members of a class, so they are initialized with a default value. When inside a scope they are local variables and are not initialized. These two examples have the same problem. object a; Console.Write(a == null); vs { object a; Console.Write(a == null); }
I don't like it. I can't slouch in my chair (probably a good thing) because text near the top of the monitor starts to look slightly blurred. Bad eyes, old monitor? Maybe, but it wasn't a problem with the light theme. Ironically, glare is a problem too for some reason. I'm adjusting a bit though, it's not as bad as when I first started.
That's its exact purpose...
`(bool?) ?? false` is just an (in my opinion) less clear way to express effectively the same condition as `(bool?) == true`, it doesn't really change anything.
This question inadvertently exposes those who have natural sunlight in their workspace.
I never really liked dark themes, it reminds me of monochrome monitors. As my vision degrades with time (since I needed glasses for presbyopia) I am less and less able to see things using dark themes. I use the "Blue theme" rather than the "Light" theme. I think the built-in "Light" theme is bad, when I first saw it, I wondered if they deliberately made a terrible theme in order to push people towards the "Dark" theme :P I've asked people who needed help to switch to non-dark so that I can see to help them. 
Thank you soooooo much!!!! This was the push I needed! 
My apologies!
i think thats one option, another one is to try to build up a -1 propagation or some other test value that you know the software is not going to use. thats how i would do it anyway
heh yeah number 3 has been the story of my life. and is life i guess but not really one thats worth living. not that i see it as anyway.
Absolute classic and must-read for every programmer.
This guy is calling an extension method on the interface. That doesn't prove anything. Plus he is being a moron. Change the namespace on the extension method class **MyInterfaceExtensions** from **MyNamespace** to **MyNamespace.Extensions**. Then watch his example not work. You are then **required** to import the namespace in his example. This shows the distinction between the interface and some extension method.
If you enjoy coding, choose option 2. There are companies with suitable working conditions. Look for the the ([updated](https://austinstartups.com/an-updated-joel-test-for-2017-31560b109bcb?gi=a6e4c26053c9)) [Joel Test](https://www.joelonsoftware.com/2000/08/09/the-joel-test-12-steps-to-better-code/) and rate your future employers accordningly - on Stackoverflow some even do that themself. If you don't have a family yet, moving should be no problem so there is virtually anything possible. Completely changing the field and only code as hobby might also bring the fun back. If you have something that pays the bills, that is.
Well, you said AMA... Are you hiring?
 var dict = new Dictionary&lt;string, IEnumerable&lt;string&gt;&gt;(); if(dict?.TryGetValue("token", out var values) == true) This is equivalent to writing: var dict = new Dictionary&lt;string, IEnumerable&lt;string&gt;&gt;(); if(dict != null) dict.TryGetValue("token", out var values) == true) But `dict` is never null. So in theory the compiler can change `dict?.` into `dict.` when it does its analysis. 
Thanks for the tip. I was starting to feel like it wasn't a viable option but wanted to seek some experienced advice first. Really appreciate it.
When I switched, it took me about a month to get used to it. Once you get used to it, the bright theme is like staring at the sun.
That's intentional. They're not supposed to be the same because it should map.
Thanks. I'm going to update my post, but I'll comment this here for you. Apparently it's a bug/not added feature with the third party code. https://github.com/moozzyk/CodeFirstFunctions/issues/3 So it's not as yet possible until the above issue is resolved =/
I think you need to do something different. As you are allocation memory to Dictionary via 'new' operator , it can't be null untill assigned. Try using:- (suppose your dictionary object is 'dict') if(dict != null &amp;&amp; dict.Any()) { // Your code here } This will work as expected. (bad english? Sorry, not my native stuff.)
What is the upside of using the dark theme? I just find everything harder to read.
LinqToDB is great, i am glad i found it a few weeks ago. 
 You really seem to hate EF. I feel like that's half of your posts lol.
I dont have a run button and i wanted to try C# from python. In that you just run it but there doesnt seem to be a command or anything like that i can find. Its a stupid question but im out of luck 
...am I the only one that actually thinks EF is pretty great for most situations?
Removed: Rule 4. Probably best bet is to dive into a "Hello World" tutorial. For example: https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/inside-a-program/hello-world-your-first-program Maybe you're running into an issue where the project type you're working with is a "Class Library". They aren't really "runable". If you do make an executable project (like a "Console Application"), then you should get the run button enabled in Visual Studio. Or maybe you do have the right project setup, but the button isn't on the toolbar or visible (for some reason). You can still access the command via the "Debug" menu, and choose "Start Debugging" or "Start Without Debugging".
thanks i think i was doing the first one 
3nf is the way - overthinking might be something like having email addresses separated from user tables and creating separate tables for fields that are used as raw text. But the data that are fundamental should be in 3nf - it’s often hard to change to 3nf later if needed. supplemental data that is replicated may be trivial to change to 3nf when needed.
We're working on Linux &amp; containerized app support! We'll be announcing more in the next few months :).
&gt; is a crazy serial killer that knows where you live! Oh, this again...Look, this phrase is absolutely useless, because it tells you ABSOLUTELY NOTHING about what you should actually do, save for "Always commit under false credentials and buy a gun". 
Good question. Tying this feature into Azure App Services / PaaS environment allows our team to round out the experience without requiring a lot of configuration or setup on your part (enabling this to work on a typical server may require several steps in installing agents, telling us about your app's topology, etc). That being said we're still investigating into expanding support to other types of environments in a seamless way.
Thanks! We're actually working on some tooling around testing in prod with deployment slots in App Services too - you can check it out here: https://azure.microsoft.com/en-us/resources/videos/introduction-to-azure-websites-testing-in-production-with-galin-iliev/
Just one thing to clarify (IMHO). Assuming you are not writing OS level code like drivers, places which really need an explanation by comment over just very comprehensive names occur at a rate of about 1 comment per 1000 lines of code. Comment has to be a rare sight, otherwise "comment blindness" quickly sets in when reading such code (and rightfully so, frequent comments == rotten comments == useless comments). 
Another one in the series just got released - "Clean architecture", also very insightful. 
I use extensions methods and delegates for repetitive code, for example: try { /* some code here */ } catch(Exception ex) { Log(ex); } Will be: Try(() =&gt; {/* code */}, (ex) =&gt; Log(ex)); The same for the using block: var x = Using(() =&gt; new SomeDbContext(), context =&gt; context.Employes.FirstOrDefault()); 
As mentioned above, we're currently working on Linux / container support, we'll be announcing in the next few months about that.
No offense, but that's horrible advice. Even if the code is easy to read, you should at least explain what is it you're doing in the code so that someone else reading/maintaining your code can fully understand what you're attempting to do. You don't need to comment *every* line of code of course, but sections of your code should definitely be commented. It should never be "quite rare" that you're adding good comments to your code. Indenting is also another large part of clean code because it helps explain to other programmers without explicitly saying it that "this" is a scope/code block.
ReSaharper addiction can be avoided, if you use it at work but not at home, or vice-versa. 
We're working on Azure VM/VMSS support - we should have more info to share early next year. You can find out more on capturing snapshots with App Insights [here](https://docs.microsoft.com/en-us/azure/application-insights/app-insights-snapshot-debugger) (main step is you will have to add the snapshot debugger nuget package to your app). TrackException does not directly capture a snapshot, in this scenario only sample snapshots are captured for recurring exceptions seen in App Insights (ie snapshots are not captured for every exception). Note that capturing snapshots with App Insights works in Azure VMs today.
Personally, I disagree. That's not to say that you should go overboard commenting everything, code should definitely be readable and names should be chosen for clarity an specificity. But I'm very often glad for comments that give a one-line summary of what a chunk of code does, especially when it's a one-time-use bit of code that doesn't really help anybody by being turned into a function (and sometimes you can't create a snappy name for that function anyway). Perusing code and understanding what I'm in the middle of is made much easier with some basic comments. Of course I'm not saying I'm right and you're wrong, but just saying that I find my own comments extremely useful when coming back to code months or years later and I never just glaze over because there are so many or anything like that. Basically it comes down to, yes I can read what this whole chunk of code does, but it's a waste of time to have to do so when a simple one-line comment will explain it for me (and will help any other coder who is reading my code but might be confused by it if they don't understand a technique I used, it helps them learn).
I go back and forth. We poke around with UX / UI mockups in different themes, generally what I demo with is what I had last open. That being said I do prefer the dark theme :). 
A good indicator / compass for building better readable code are unit tests. Code that is written with unit testing in mind will be better split into abstractions, and abstractions are very good at communicating intended role of a component over its implementation detail. Tests also help indicate when you put too much logic in one place: too much tests for a single type == too much logic in the type == too much responsibility for the type. This is a sign the your type should be split into higher level 'general workflow' and lower level 'particular tasks'. 
Not our team in particular, but wish you the best in your job hunt!
&gt; It seems to me that the need for extremely verbose "descriptive" identifiers seems to be something of a quirk of programming in Object Oriented languages like Java or C#. More with fashion trends than the language. Long, Camel/Pascal Case variables were a response to the unreadability of C and C++. C coding style evolved when IDEs and editors were relatively primitive in terms of their level of coder assistence. Vi/Emacs were the bees knees and they were very efficient at conveying the coder's intentions into text form, but did not actually understand the code itself and could not auto-complete much if anything. C was invented while there were still languages in use that had variable name size limits and file name size limits were still a fact of life on many computer systems. Therefore, short variable names meant less typing and felt normal. C++ inherited C's style, but added namespaces, so was in this weird mix where namespaces had long, complete names but other variables tended to be terse. And then there was the evil corruption that is Hungarian notation. Java and C# were both a direct response to C++. (Well, C# was also a response to the fact that MS could no longer participate in Java) IDEs had evolved to the point where autocomplete meant that long variable names didn't actually result in any additional typing, so the extra clarity was good. Now, however, it's swinging back the other direction. IDEs have advanced *even further*, and hover-hints and type inference and all these other things can give you context of a variable even if the name is short. Languages like F# and Haskell and such inherit the desire for short variable names from their math heritage, and have the compiler/IDE assistance to make it work well.
Actually I am not a Java evangelist at all. I'm the guy who wrote this: http://code.scottshipp.com/2016/05/18/how-java-cut-its-throat-and-what-we-can-do-about-it/ I also greatly appreciate the nice language features of C#. The only thing I don't like is when languages make it easy to do dangerous things, and I do think that having public get and set methods for a property is dangerous in the majority of cases.
Good for prototyping, meh on performance. 
you assume that there are two different programmers!
EF Core performance isn't that bad. Also it is getting better: https://github.com/aspnet/DataAccessPerformance
They key word here is 'chunk'. I usually communicate the purpose of a chunk of code performing an action by moving it into an explicitly named function. Helps keep thing clean. Also, for LINQ chains or queries I make that the variable to which end result is assigned communicates what is happening in that LINQ. 
It does say core in that article. &gt;With EF Core struggling to accommodate basic database features s...
Right, and I disagree with creating functions that have no other purpose than to break code into smaller chunks to avoid writing a comment. I know this is a common practice and it's not necessarily bad, but there are plenty of times when creating a self documenting function actually complicates things rather than simplifies them. Now, if you've got functional reasons to separate something out, be it for reusability, or testability, or whatever, then great. I'm all for that. 
I do as well, I love how simple it is to use and its structure.
I dislike any ORM whose design runs counter to how the database is supposed to be used. And EF is the best known example of that in the .NET ecosystem. But at least EF does the job it claims to do. What I hate is having to write an article on EF Core alternatives because the stupid thing is on 2.0 and still doesn't properly support views. 
&gt; the stupid thing is on 2.0 There were some changes in team earlier this year, has that created any positive movement in the code base? 
The tone of the article gave me the impression you didn't like C# and your comments here made me wonder how well you understood the features. &gt;Help us understand the motivation for a private setter. Why not provide only a getter and not have a setter at all? So that you can set the value from within your AddPurchase method. Yesterday I learned from /u/Telexen1 that if you want a readonly (initonly) backing variable you should omit the private setter. I used to write these by hand.
[removed]
[removed]
 What do you mean doesn't properly support views? Just call them like normal and mark the class to not map the table, it's the exact same how something like dapper works.
If you can do this from vs, why can I no longer get a proper profiler/diagsession in kudu? All i get in it is one row with w3svc.exe 100% cpu and no call tree. I used to be able to... Not since a few months back. 
No, this is how you add an implementation to an interface: [CoClass(typeof(FooImpl))] public interface IFoo { void Bar(); } public class FooImpl : IFoo { public void Bar() { /* ... */ } } // ...... public static void Main() { var foo = new IFoo(); // works just fine foo.Bar(); } In case there's any doubt: This works yes but it's a tongue-in-cheek example; don't really use it, it's just some nice C# trivia
No it's not. Yes, you can use FromSql to call a view, but there are limitations. You have to mark a column as primary key, even if the view doesn't have a primary key. (Or multiple columns if you want to forget attributes exist and further bloat the EF context class.) If said fake primary key isn't actually unique, you have to use AsNoTracking or it will silently drop rows it thinks are duplicates. There's a huge difference between "properly support views" and "can be hacked to read from a view".
Fully agree with this, it's a little tiring. I mean, half of what he posts is genuine troll material, like the other day he got downvoted a lot of his ridiculous comments where he suggested you shouldn't use dependency injection. It's always the same controversial and troll opinions from him.
Just don't read any of Robert Martins recent posts, guy is a full on crack pot I swear.
I saw this error any ideas? The directory C:\Windows\TEMP\MinidumpUploader exists and the Network Service account is the account that owns the folder and is what my worker process is running as. [DllNotFoundException: Could not load C:\Windows\TEMP\MinidumpUploader\ProductionBreakpoints_x64.dll] Microsoft.ApplicationInsights.SnapshotCollector.ProductionBreakpointsNativeMethods..cctor() +556 [TypeInitializationException: The type initializer for 'Microsoft.ApplicationInsights.SnapshotCollector.ProductionBreakpointsNativeMethods' threw an exception.] Microsoft.ApplicationInsights.SnapshotCollector.ProductionBreakpointsNativeMethods.DeOptimizeMethod(MethodBase method) +0 Microsoft.ApplicationInsights.SnapshotCollector.DeOptimizationRequests.CreateNewDeOptimizationRequest(MethodBase method) +65 System.Collections.Concurrent.ConcurrentDictionary`2.AddOrUpdate(TKey key, Func`2 addValueFactory, Func`3 updateValueFactory) +295 Microsoft.ApplicationInsights.SnapshotCollector.DeOptimizationRequests.DeOptimize(ProblemId problem) +207 Microsoft.ApplicationInsights.SnapshotCollector.SnapshotCollector.TryAddPlan(ProblemId problem, Int32 numberOfSnapshotsDesired) +102 Microsoft.ApplicationInsights.SnapshotCollector.ProblemCounter.RecordException(Exception exception) +204 Microsoft.ApplicationInsights.SnapshotCollector.SnapshotCollectorTelemetryProcessor.ProcessExceptionTelemetry(ExceptionTelemetry exceptionTelemetry) +134 Microsoft.ApplicationInsights.SnapshotCollector.SnapshotCollectorTelemetryProcessor.Process(ITelemetry item) +65 Microsoft.ApplicationInsights.WindowsServer.TelemetryChannel.SamplingTelemetryProcessor.Process(ITelemetry item) +74 Microsoft.ApplicationInsights.WindowsServer.TelemetryChannel.SamplingTelemetryProcessor.Process(ITelemetry item) +74 Microsoft.ApplicationInsights.Extensibility.AutocollectedMetricsExtractor.Process(ITelemetry item) +55 Microsoft.ApplicationInsights.Extensibility.PerfCounterCollector.QuickPulse.QuickPulseTelemetryProcessor.Process(ITelemetry telemetry) +390 Microsoft.ApplicationInsights.TelemetryClient.Track(ITelemetry telemetry) +173 VERISMIC.Server.Shared.ServerLogger.TrackException(Exception ex, String callerMember) +37 System.Web.Http.ExceptionHandling.ExceptionLogger.LogAsync(ExceptionLoggerContext context, CancellationToken cancellationToken) +20 System.Web.Http.ExceptionHandling.ExceptionLogger.System.Web.Http.ExceptionHandling.IExceptionLogger.LogAsync(ExceptionLoggerContext context, CancellationToken cancellationToken) +81 System.Web.Http.ExceptionHandling.CompositeExceptionLogger.LogAsync(ExceptionLoggerContext context, CancellationToken cancellationToken) +126 System.Web.Http.ExceptionHandling.ExceptionLoggerExtensions.LogAsync(IExceptionLogger logger, ExceptionContext context, CancellationToken cancellationToken) +80 System.Web.Http.&lt;SendAsync&gt;d__0.MoveNext() +821 System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() +31 System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) +70 System.Web.Http.WebHost.&lt;ProcessRequestAsyncCore&gt;d__0.MoveNext() +441 System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() +31 System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) +70 System.Web.TaskAsyncHelper.EndTask(IAsyncResult ar) +59 System.Web.CallHandlerExecutionStep.OnAsyncHandlerCompletion(IAsyncResult ar) +183
None taken, but you're wrong. Any experienced developer would tell you that code commenting is a last resort. What I meant about indenting is that you should try to avoid nesting, as it makes code harder to read.
I’m not wrong, you literally just had *another* experienced developer tell you that you’re wrong (he being more experienced than me). I’ve been working professionally for 5 years now. Companies literally enforce what we call coding standards and that includes commenting your classes, methods, and members a certain way. Just because you understand your code, doesn’t mean everyone else (particularly, a beginner working on your team) is going to understand it. Even if it is legible. There is absolutely no way you went to a school where someone taught you “don’t comment your code unless you absolutely have to”. That is by far the most incorrect practice I’ve ever heard. 
But I already debug in production! Refresh often when I'm working :P
If you can't tell the difference between DI and DI frameworks then you have no right to complain about what I write. 
Who said I can't?
Stored procs and decent view support are still not on the roadmap yet, so I'm not exactly hopeful. But at least they're acknowledged as a backlog item.
Also something you would need if you were going to write a custom compiler? 
Whoa, whoa buddy. First you might want to edit your post to format the readability of your code.
Good programmers makes readable code not visa versa.
Hello everyone! PM who worked on this feature here. This just shipped in Visual Studio 2017 15.5, would love to hear your feedback. You can read more about the feature [here](http://aka.ms/stepback).
The condition *if (input &gt; end || sum &gt; end)* isn't needed. Just move the line *Console.WriteLine("total sum is {0}", sum);* to the line before *Console.ReadKey();* (after the do/while block). Also, have you tested what happens if someone doesn't enter a number that can be parsed to an int (e.g. 'Hello world')? You might want to use TryParse. You might also want to change the type to decimal and use decimal.TryParse(). After all - decimals are numbers that can be summed too.
This is probably close to what id turn in for an assignment, the or in your if statement is unnecessary though (You add the input to the sum before checking the conditional, so anytime the first half would be true the second half is already true. Only need to check if sum is greater)
Given the requirements, seems like a reasonable implementation to me. A little fragile due to lack of input validation, but I'm assuming that's not important here. The only improvement I'd make is to move the line to print the sum after the while statement which lets you get rid of the if statement entirely, but that's a micro-optimization. Logic-wise it seems perfectly sound to me. 
The third `{` and its pair is not necessary. So, according to your instruction, you only exit the loop when the *sum* exceeds 100. In your code, you check to see if the *input* is greater than 100 as well. So, you need to remove `input &gt; end ||` in the if-block. With that said, here is how I would do it: int sum = 0; while (sum &lt;= 100) { Console.Write("Enter a number to sum: "); var input = Console.ReadLine(); int inputValue = 0; if (Int32.TryParse(input, inputValue)) { sum += inputValue; } else { Console.WriteLine("Invalid input."); } } Console.WriteLine("The total sum is {0}.", sum); Console.ReadKey();
A minor point: if your description is taken literally it should not display when sum is equal to 100 (description says exceeds). Following the other advice in this thread you could just change your while statement to while (sum &lt;= end).
not the only change though. wildcards are also supported among other things
Ive been hearing its getting better since EF2
Your view not having some sort of row identifier even if it's artificial is a pretty awful code smell.
https://en.wikipedia.org/wiki/Stockholm_syndrome
 int end = 100; string intputstring; int input; double sum = 0; do { Console.WriteLine("Enter a number to sum: "); intputstring = Console.ReadLine(); input = Convert.ToInt32(intputstring); sum = input + sum; } while (sum &lt; end ); Console.WriteLine("total sum is {0}", sum); Console.WriteLine("press any key to exit"); Console.ReadKey(); 
To be fair, EF performance is getting better... as long as you disable change tracking, don't use .Include for 0..N relationships, and use hand-written SQL for any update/delete operations.
 Console.WriteLine(Enumerable.Range(0,101).Aggregate((a,b) =&gt; a + (b = int.Parse(Console.ReadLine()))));
This will be super useful when debugging some HL7 projects. Thank you so much for this!
I was thinking the exact same with regards to debugging X12 edi file parsing.
Nifty! 
You should also be able to drag and drop the arrow icon that signals the current line being executed upwards and repeat execution from there
This is really great to gain a new perspective on what's going on. Step back, re-evaluate... maybe this line shouldn't go here. This whole function could be refactored. Is this the right approach? Am I really addressing the meta-problem that lies at the root of this? Why am I continuing to work here, of all places? Should I not divest myself of all attachments and study the nature of the universe? Why
That escalated quickly. 
How do you validate your view if there's nothing that determines it's unique? How do you actually use the view if there's nothing that determines what the values actually represent? Your view has a unique identifier, or it's not actually useful. EF aside. Data rows should have uniqueness in some way or it's just noise.
By setting the first param to true, you lock the mutex. You never unlock it, so it stays locked. You should call ReleaseMutex() after you exit the critical block. It would also be a good idea to dispose of the mutex, the operating system will do this when the process exits but if it runs for a long time you could have issues.
Is this something that will only be on enterprise edition or (by some stroke of massive luck) is it also coming to professional edition?
Another day, another reason I wish my work used C# instead of java.
Java's Get() and Set() map to C#'s .Value Java's initialValue() maps to C#'s valueFactory. The only difference is how they're created, in java you're overriding while in C# you pass in a delegate. So for example you might do: ThreadLocal&lt;int&gt; localInt = new ThreadLocal&lt;int&gt;( () =&gt; 5 ); and that would initialize the value for every thread to 5. C#'s ThreadLocal doesn't have a .remove() method, but if you need that behavior I think you can safely replicate it by doing Func&lt;int&gt; init = () =&gt; 5; ThreadLocal&lt;int&gt; localInt = new ThreadLocal&lt;int&gt;( init ); localInt.Value = init(); 
If you didn't have to do that before, then the `System.Collections.Generic` namespace must have already been added. This is how C# and many other languages operate. There are innumerable libraries and APIs available, but you'll typically need to explicitly import them into your projects and classes. You can read more about the `System.Collections.Generic` namespace [here](https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic?view=netcore-2.0).
Thanks, it's weird though since Im creating new project same as I always did.
Very helpful. I didn't know that about the get/set value similarities. Thank you very much for the pointer.
but can't you just use ctrl+shift+F10 to get back to your cursor? 
This feature is part of IntelliTrace so it's only available for enterprise. Let us know if you're able to try it out!
This is amazing. I can't wait to try it out!
Yep! It's true in this particular gif scenario that dragging the yellow arrow up a line ([Set Next Statement](https://docs.microsoft.com/en-us/visualstudio/debugger/navigating-through-code-with-the-debugger)) and executing from there would get you the data again, though we'd have to wait for the GetDriverList call to complete again. The main differences between this step-back feature and set next statement are that with step-back, the code isn't being re-run; rather, we're looking at a snapshot of the app at that previous step or breakpoint. This can save time if re-running from the line of interest takes a while, and avoids any potential side effects to your app. We hope this helps for the scenario where you're stepping, see something change in an unexpected way, and just want a quick way to go back a step :) 
This is so cool! Just the other day i was thinking: wouldn't it be awesome if we could step back in debugging and try this once again? And here it is already!
Like mentioned above, when you Set Next Statement and continue, the code is actually being re-run. With step-back, you can look at a snapshot in time of the app at the previous step or breakpoint. If you want to give it a try, they keyboard shortcuts to navigate between the steps/breakpoints are Ctrl + [ for backward navigation and Control + ] for forward navigation. 
Yea, I suppose I could define my PK as most, or in some cases all, of the the columns of the output. (The latter is especially true for mapping tables where you don't slap on a redundant identity column to make the ORM happy.) But when the PK for the view is literally "7 of these 8 columns" it's rather stupid.
Does intellitrace support Xamarin projects?
When will it trickle down to Community edition? We broke devs also need some love. Although a free version of Visual Studio *is* already a lot of loving. I've been using VS since the first Express Edition in 2005, and it really kicks the llama's ass.
Just as a side note: the type of the variable is redundant and should better be omitted: var foo = new List&lt;int&gt;(); 
To be honest, views are not supposed to have a unique identifier. They happen to have one depending on the data they map, but a view, by definition, is a non normalized view of normalized data. I am the first one using the hack of mapping a view as a table, I even wrote ’instead of’ triggers (shame on me, but i had a good reason for it, and it was before sp were supported) to simulate the write and push it to the underlying tables.
Am I right in thinking you can only step back if you originally stepped through that state? i.e. Would I be able to set a breakpoint on line 5, then decide I want to step back to line 4? If not it would be great to have some kind of setting (with performance warnings etc) that could allow you to choose to be able to step back N steps without having to step through those states originally).
You're likely to have a composite key, but there's still a key in there, and you need it to trace back issues.
Your view has a PK. It might be a composite key, but it exists. If it really doesn't, you can put an artificial one in with rank of rownum in like 3 seconds. EF isn't a great choice if you're keeping huge amounts of business logic in your DB, but that design leads to truly horrendous shit.
`ROW_NUMBER` requires an `OVER (ORDER BY)` clause, an expense I would rather not have to pay just to get EF Core to stop shitting itself.
I try to think of myself more of an Author for others to read the work of. I try to write code such that any given person will *enjoy* reading it. Iirc, Uncle Bob wrote something about this in "Clean Code" as well.
Again though. Your data has keys.
How does it work internally, if you don't mind sharing some details? Does the compiler write instructions to include the snapshot state every time code passes through a breakpoint and includes that in system logs? Is it similar to how exception stacktraces are logged with the help of pdb files?
Thanks for you solution, problem solved :-)
I should have been clearer. I know it helps for reading what you're directly looking at, but I find it too distracting when trying to take in the whole context of what you're looking at. ie words are great, but reading a function or class isn't (for me).
I discovered intellitrace the other day while trying to debug some events and I am enamoured with it. (Even if it breaks a lot in 2015). This is just icing on the cake, nice one.
I think the former is more readable, but to each his own!
[removed]
[removed]
[removed]
[removed]
[removed]
[removed]
[removed]
[removed]
Wat
That's of course amazing, but not for a price of enterprise edition of VS.
Time to convince my boss to upgrade to Enterprise.
This is awesome and something I never thought I'd get. Been putting off installing 2017 but I'm going to today.
I don't worry about normalized/correct structure in my models. It's important to have 3nf structure in databases because it's a central repository, used (in theory) by many applications/users - and 3nf helps to reduce potential data errors and maintain integrity. Your entities are just temporary constructs to get a job done. They lack the "permanence" of the data in the database. I would structure them in the way that best/most efficiently gets that job done. 
I have a side right now where I have to going to the workplace and building the most amount of workplace stuff I can. Like basically it's a process of building job material, like technical test prep work you could say. I went to the work place I usually go to today and I'm working on making a sometimes a good performance especially in f sharp in the technical test almost every day. I prepare and I'm ready to fetch all the content that's thrown at me. That's how I work with coding it's all about self exposure and making yourself feel nice enough to perform
This looks fancy but is no solution the problem presented..
Do you know how you're going to monetize it though? I mean you can think from the idea you're going to make a good product but it doesn't always work out that way
What's a skyscrapers puzzle on the first place, could someone real me?
I am definitely going to have a look at alternatives to the webapis I use but I don't know any good one s right now. Is there any advantages you think this had over the out of the box content?
Must be an old grannar? Couldn't find anything related to lambdas...
Creating inferior versions of .Net things seems pretty common in .Core, have they ever said why the needed to re-invent the wheel instead of simply porting EF from .Net to .Core.
Any chance you could put "Visual Studio- Enterprise Only" instead of just "Visual Studio" when posting about features that are only for Enterprise Edition.
I can't tell, but does it include the ability to change the line of code before re-executing it? 
I ain't formatting or testing. List&lt;int&gt; randomNumbers = new List&lt;int&gt;(); List&lt;int&gt; l = new List&lt;int&gt;(); Random r = new Random(); for (int i=0;i&lt;n;i++) { l.Add(i); } while (l.Count &gt; 0){ int x = r.Next(l.length); int val = l[x]; randomNumbers.Add(val); l.Remove(val); } return randomNumbers;
&gt; When will it trickle down to Community edition? In a few years, when it is no longer a major selling point. &gt; We broke devs also need some love. MS gotta make the moneys somehow. 
You could also drag the break point in the left column up to a previous line.
Last I checked (a couple years ago), a Visual Studio Professional license was over $1,000. I love Microsoft's dev tools, but if that's all that was available I would switch to Linux as my target platform for personal projects. I get that Microsoft deserves to make money for their (excellent) work, but I assume that they can make plenty from corporations and IMO a non-commercial developer shouldn't have to pay for a relatively complete environment. If it was $50 I'd pay that happily, but hundreds or thousands of dollars is too much for an individual.
Good work, this is one of the functionalities I always wanted
Does the snapshot just work on the same level or is it possible to step into a function by this feature for examining the content within that function? And if yes, how many levels of step-into are supported?
Last time I checked, MSDN Enterprise subscription was north of $13k per dev. Intellitrace is a great feature that relatively no-one will be able to use legally. Which is a real shame.
https://www.codewars.com/kata/5671d975d81d6c1c87000022
Can'tyou already do this by clicking on a line in the Call Stack window?
Apart from all the devs that have an MSDN subscription through their employer, which is probably most of them. 
1. `sum` needs declared as a `uint` or `long`, at most. 2. `end`, `inputstring` and `input` can be declared inside the loop. 3. The body of the `if` block should be moved outside the loop, before the call to `Console.ReadKey()`. The rest of the `if` can be removed. 4. The second set of braces inside the body of the loop are unnecessary and should be removed. 5. The condition in the while clause should probably be `sum &lt;= end`. 6. If the above changes are made, you can replace the use of `end` with its value, and relieve yourself of yet another variable. If kept, though, `end` should be declared `const`. (Other than #5, these are all pretty minor stylistic or semantic criticisms.) As an improvement, look into using `int.TryParse()`, instead of `Convert.ToInt32()` This is a pretty simple problem, so there's only so many ways to approach it. I think yours looks OK for a student assignment.
I do, but they won't stump up for Enterprise.
The CALL-Stack goes back in the stack of function-to-function calls, which means, that the function which called the current function can be shown there. Specifically, the line where the current function was called. It does not show you function calls within the same function.
Visual Studio Community edition covers you 100% here. The only feature you gain with Professional is CodeLens. Community edition is free for personal use and up to 5 users in a company with less than $1 million in annual revenue.
If we're going to be function, let's go hard on that: Console.WriteLine($"Sum: Extensions.InitInfinite(_ =&gt; { Console.WriteLine("Enter a number:"); Console.ReadLine(); }).Choose(x =&gt; int.TryParse(x, out var i) ? i : (int?) null) .AggregateWhile(0, (x, y) =&gt; x + y, x =&gt; x &lt; 100)}"); public static class Extensions { public static IEnumerable&lt;T&gt; Init&lt;T&gt;(Func&lt;int, T&gt; f, int count) { var i = -1; do { yield return f(++i); } while (i &lt; count); } public static IEnumerable&lt;T&gt; InitInfinite&lt;T&gt;(Func&lt;int, T&gt; f) =&gt; Init(int.MaxValue); public static IEnumerable&lt;U&gt; Choose&lt;T, U&gt;( this IEnumerable&lt;T&gt; source, Func&lt;T, U?&gt; f ) where U : struct =&gt; source.Select(f).Where(x =&gt; x.HasValue).Select(x =&gt; x.Value); public static U AggregateWhile&lt;T, U&gt;( this IEnumerable&lt;T&gt; source, U seed, Func&lt;T, U, U&gt; f, Func&lt;U, bool&gt; p ) { foreach (var x in f) { seed = f(x, seed); if (p(seed)) { break; } } return seed; } } Mostly stealing methods from F# Seq module, and it's untested, so it's entirely possible I botched stuff. But, hey!, there's even a do ... while in there.
MSDN has different levels. Most companies likely go with MSDN Visual Studio Professional. 
Of course not. They do the same for new SQL Server and SSRS features. You get all excited until the very last line that tells you it is Enterprise only.
Get ready to spend $10,000 on an enterprise license. :-/
Thanks, I was also wondering what the difference was ...
Looks fine to me aside from not needing if (input &gt; end || sum &gt; end). Also, if we're just being super nit-picky here, camel case inputstring to inputString, and I'd also go with sum += input instead of sum = input + sum; Also, it looks like you have an extra set of brackets that you don't need.
This is pretty much perfect. Only thing I'd change is to bump up your framework version and Console.WriteLine("The total sum is {sum}.");
Borland were doing this in Turbo Debug a **very** long time ago.
Enterprise editions are the modern day ivory towers.
Hopefully they'll have a more affordable version of it for small dev teams. I'm on a team of 15 engineers in a small company, and only two of us write C# (we're slowly but surely progressing away from Delphi... yuck). Be nice if they offered a professional license like what Visual Studio does.
And again, when the PK for the view is literally "7 of these 8 columns" it's rather stupid. 
Same here, and I work for a major prime brokerage firm.
I do a lot of NES ROM hacking, so I'm moving `byte[]`s around constantly. I certainly don't need spans for performance, but it's a great place to practice using them anyway.
You're right, of course. I use the community edition every day. I was replying to the parent ("so it's worth paying for, imho") who seemed to imply that paying for a Professional license was a viable thing for most people.
Heh, it doesn't even contain generics (C#2).
Use the length (how many item it has) of the array
In the article it says &gt; The feature is currently supported for WinForms, WPF, Managed Console apps, and Managed Class Libraries. If I make a managed library that I use in Unity3D, will that work? If so, I'm super excited for this!
What are you looking for in terms of "faster"? If you like, you can simplify the loop in favour of `String.Join(" ", poem)`.
One way might be var poem = "Mary had a little lamb its fleece was white as snow"; var words = poem.Split(); var reversedWords = words.Reverse(); var reversedPoem = string.Concat(reversedWords.Select(word =&gt; word + " ")).TrimEnd(); Console.WriteLine(reversedPoem); 
Same here, and I work for a *big* company. Only the most senior devs get Enterprise. Perhaps some 5% of the developers at the company.
Like others are saying, normalize database tables, NOT entities/models in your application. Compose your entities however they are needed within the context of what you're trying to accomplish. Maybe that's just like they are in the DB, maybe not. As the size of the project grows, it becomes increasingly difficult to have a single "source of truth" entity model that handles all your needs. As soon as you find yourself breaking one thing to fit it all into an entity, separate your contexts.
 using System.Linq; "Mary had a little lamb its fleece was white as snow" .Split() .Reverse() .ToList() .ForEach(x =&gt; Console.WriteLine(x));
It's $3k not $13k
Though performance is worse if that is a concern :)
What is the syntax of the instantiation on line 41? The use of the colon specifically? I've never seen that.
 string[] words = "Mary had a little lamb its fleece was white as snow".Split(); for (int i = words.Length - 1; i &gt;= 0; i--) Console.WriteLine(words[i]); Better? ;)
&gt; And don't encode the type into the variable name! intList is a bad name There are two types into that variable name. "ints" is a good name, "list" is a bad name.
AlexaSkills.NET was a godsend. Implementing the full skills protocol was extremely tedious, and was just more painful as the APIs evolved. I definitely recommend using it.
If you're trying to stick to an imperitive way to accomplish this: You can skip the Reverse operation, and you can avoid multiple IO write by using StringBuilder, which is generally recommended for efficient concatenation of strings, or other methods of concatenating. string[] poem = "Mary had a little lamb its fleece was white as snow".Split(); var sb = new StringBuilder(); for (int sub = poem.Length - 1; sub &gt;= 0; sub--) { sb.Append(poem[sub] + " "); } Console.WriteLine(sb);
Here's a naive benchmark, out of curiosity. using System.Diagnostics; string[] poem = "Mary had a little lamb its fleece was white as snow".Split(); var sw = new Stopwatch(); var sb = new StringBuilder(); sw.Start(); for (int sub = poem.Length - 1; sub &gt;= 0; sub--) { sb.Append(poem[sub] + " "); } Console.WriteLine(sb); sw.Stop(); Console.WriteLine(sw.ElapsedTicks); sw.Reset(); sw.Start(); poem .Reverse() .ToList() .ForEach(x =&gt; Console.Write(x + " ")); sw.Stop(); Console.WriteLine(Environment.NewLine + sw.ElapsedTicks);
&gt; Console.WriteLine("The total sum is {sum}."); Missing a `$`: Console.WriteLine($"The total sum is {sum}.");
Do you know if there's a way to combine AlexaSkills.NET and Azure Functions? Seems like serverless might be the way to go with Alexa skills.
That is correct. Thank you sir.
 Or even non-break point functions, like marker points that just say when to. My biggest want for this feature would be to when an exception happens, step back one step to see the state, but it doesn't seem possible (which is fair, it couldn't capture every single line I guess while it's going through...)
You could always do a current index and last index, and simply print each chunk. Not the fastest, but just saying you can try it. As an example... String poem = "Mary had a little lamb"; int lastI = poem.Length; const Char SP = ' '; for(int i = lastI; i &gt; 0; i--) { if(SP.equals (poem [i])) { Console.Write(poem.substring(i,lastI)); lastI = i; } } Note: Mobile code probably has some bugs... cough cough... features included!
That could very well be because of the ToList. I think if you just did a foreach on that query it would be similar perf.
I had the same thought, because the two in sequence will iterate the enumerable twice. I tried doing the unforgivable with `.Select(x =&gt; { Console.Write(x + " "); return; }).ToList()`, but performance was worse.
you already can drag the current line up. am i missing something?
ForEach is deprecated. 
I don't know much about Functions, to be honest. I feel fine using WebApi2 because the skill generally needs to support a variety of endpoints and interactions. Functions wouldn't necessarily be the right approach for this, from what I understand.
for (int iterator = 0; iterator &lt; somelist.length; iterator++)
&gt; It does, however, get you to the point where you can't code without it. :) How? I used it for a few months and uninstalled it. VS 2015/2017 nail most of Resharpers features, and its free (Enterprise user btw)
I haven't had any issues. But we use the ssh:// method to push via VS2017. Not sure of the HTTPS vs SSH is the issue or not.
$6k for a new subscription now, back when I looked at it before VS 2015 came out, it was $13k.
Is the tooling in java world that bad?
IntelliJ is great, but there’s so much setup compared to visual studio. VS I have very little problems with dependencies whenever I import another persons project or repo. With java class path nightmare every single time.
I would strongly recommend using git from the commandline. It gives you a greater understanding of what git is doing behind the scenes, and the tooling is well tested. When I see developers struggling with git, so often their toolchains are play is the problem. 
Well it is $3,000 now, not $10,000 since they dropped the Ultimate Edition.
Yeah, that's good and all, but what if they're not allowed to use `ToList()`? var poem = "Mary had a little lamb its fleece was white as snow".Split(); Console.WriteLine(string.Join(" ", poem.Select((s,i) =&gt; poem[poem.Length - i - 1]))); You know, gotta keep your options open. ^^^^/s
Hit never worked for me in vs 2017. I either use command line or use vs 2015 instead for git.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/visualstudio] [VS n00b trying to save the day needs help](https://www.reddit.com/r/VisualStudio/comments/7ij9m5/vs_n00b_trying_to_save_the_day_needs_help/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Where is your view coming from? The tables it's using have keys do they not? Is your view really coming from 7 different tables? An order by over a clustered index is going to be effectively free from the DB as well. I've read your stuff before and you're obsessed with shaving off milliseconds on absolutely everything, but you've never got any justification for doing it. Is EF appropriate for a DB doing millions of transactions. No, it's not. Does a rank function over a clustered index have a meaningful cost in 99% of applications? No. Do you possibly want to order your view anyway? Probably. Piping raw SQL into dapper is not an 'alternative' to EF. It's solving a completely different problem and making sacrifices for a totally different benefit. Most of the time the speed difference doesn't matter, but managing sql in magic strings sure does. 
For this level of customization, you'd probably need to render stuff manually. If you inherit from UIElement you can freely draw whatever the heck you want, but you'll need to be careful do do it right.
ServicePointManager isn't really supported in .NET core anymore, but you could grab the cert in the `HttpWebRequest.ServerCertificateValidationCallback` callback.
Is your GIT_TERMINAL_PROMPT environment variable set?
&gt; Is your view really coming from 7 different tables? Let's say there is only one table. Have you heard of this little thing called GROUP BY? 
I don't get it. 8 upvotes and I couldn't find any EF code in that repository. 
Then your group by is by definition a key. 
Possible with winforms and gdi+ you think? Or nah
But using code first entity framework aren’t my models a representation of my database schema? Do I need to have my code first data access layer then make a business logic layer to fit my business needs?
Out of the box? Maybe for systems that send a lot of small updates. The message passing over websockets doesn't have the overhead of HTTP headers, so this library might have 1/3 the network overhead on sending trivial messages (e.g. a date time value). It might also have an advantage in large object graphs where protobuf is more efficient than JSON. I wouldn't recommend using this library though, because it didn't meet the goals I was looking for (substantially lower latency than web api) and because it probably doesn't fulfill enough of a niche to continue developing. You could get similar benefit by stripping some response headers from web api, and switching to using a protobuf formatter. Websockets itself doesn't offer compelling advantages (though it does save some latency on occasionally connected systems for the first request).
That video looks really interested. I don't have time for that right now though. What he's talking about seems really advanced. I think, if you understand what he's talking about and you can incorporate it into your own work, go ahead and do that. If you want to be more immediately productive though, that sort of high end optimization isn't necessary or even useful right now. 
Removed: Rule 1, Rule 3. If you want, you could check out /r/forhire or /r/learnprogramming. A quick check of the API looks like you could build a Windows program which could check these things and add a reference to the API dll to access its various functions. As a Windows program, there are probably other libraries/APIs you could use to detect the microphone. That said, what you're asking doesn't sound like a particularly trivial task.
Awesome, thanks for the tip!
I saw that, but I'm not really sure how to pass the values back to the main function once it was called. I could put it in global variables, but this doesn't sound right to me. And events aren't supposed to return values.
This looks pretty cool. I just wish it didn't cost $3000. P.S. Thanks mods for adding "Enterprise Only" to the post title. 
Push doesn't work for me in VS. It was fine in VS 2015 but it's been broken for me ever since upgrading to 2017. I generally use PowerShell for pushing, and SourceTree to view my commits.
You're still missing the point. EF shouldn't be expecting a key from a view in the first place.
Just use a lambda. X509Certificate2 cert = null; var request = ...; request.ServerCertificateValidationCallback += (sender, validatedCert, chain, errors) =&gt; { cert = new X509Certificate2(validatedCert); return errors == System.Net.Security.SslPolicyErrors.None; }; request.GetResponse(); // ... Console.WriteLine($"Found cert \"{cert?.Subject}\"); It's not particularly pretty, but I don't see any other simple solution.
Just use a lambda. X509Certificate2 cert = null; var request = ...; request.ServerCertificateValidationCallback += (sender, validatedCert, chain, errors) =&gt; { cert = new X509Certificate2(validatedCert); return errors == System.Net.Security.SslPolicyErrors.None; }; request.GetResponse(); // ... Console.WriteLine($"Found cert \"{cert?.Subject}\"); It's not particularly pretty, but I don't see any other simple solution.
A view is just a
I am working on a game engine and editor toolset for me and a couple other companies to share. It is a kind of evolution f my current toolset where I am fixing all the things that are wrong about it. Currently sad that IEnumerables are not serializable, because if they were the entire engine single handedly could be 2x better. Working on stripping out as many dependencies and third party tools as possible, and am really happy with how far along that is. Very few dependencies left. Really happy with my current implementation of a UI system for creating modular developer tools, I already know a zillion ways I will implement it in my next big game project. I like this language.
Thanks, saved! 
The way EF works uses primary keys on records. You don't need to put a primary key on a table either, but it's shitty design not too. You could argue that dapper shouldn't require magic string sql, but it does. You don't like full fat ORMs, we get it. Move on. 
Yeah still miffed about how they are handling the modelbuiler in EF Core. In EF 6 I could avoid polluting the pocos with attributes and moving the config to separate classes via EntityTypeConfiguration&lt;T&gt; classes. This being removed has prevented me from moving any of my larger projects to core. So far it’s been really small contexts with fewer than two tables references or direct ado calls. The design choices in core for both Asp and EF, are a bit noisy, in their current state, meaning I need to add a ton of configuration to do simple shit. 
Good to know, thank you! 
That is something... I've never considered doing that, damn that's ugly. I'm going to use it to disgust my team. 
EF does not require primary keys to work with views. That is a limitation of EF Core. Really, this far in the conversation and you still don't understand the difference between EF and EF Core?
I'm annoyed for the completely opposite reason. I liked using attributes to configure everything, but now I've got to shove everything into the context's model building function. Funny how they managed to piss us both off despite.
I'll be totally honest, this video is a clear example of using the wrong tool for the job. If you want to deal with low level memory usage, C or C++ is what you want (or god help you, Assembly), not C#.
Don't you dare. I will never forgive you.
If you've moved from using Visual Studio to using Visual Studio Code, VS auto-creates .cs files with several using lines at the top, including the one for `System.Collections.Generic` while as far as I can tell VSC doesn't.
Except I've seen you write numerous articles about how awful EF is.
So apparently you don't know what the word "irrelevant" means either. Since you seem to have forgotten, again, we were talking about views and EF Core.
You didn’t really test this, did you? Aside from the compiler errors because of case-insensitivity, there are several logical errors as well. 
Well that's something worth being aware of. Thanks.
What about Console.WriteLine(string.Join(" ","Mary .....".Split().Reverse()));
Not really, if a created object stores a reference to its parent and the parent stores a reference to the child, no release will happen. Without looking at the code , hard to say
Just for shits, here's an inline replacement to do the reverse. It completes almost instantly. using System.Diagnostics; string[] poem = "Mary had a little lamb its fleece was white as snow".Split(); Console.WriteLine(string.Join(" ", poem)); var sb = new StringBuilder(); var sw = new Stopwatch(); sw.Start(); for (var i = poem.Length/2-1; i &gt;= 0; i--) { var c = poem[i]; poem[i] = poem[poem.Length-i-1]; poem[poem.Length-i-1] = c; } sw.Stop(); Console.WriteLine(string.Join(" ", poem)); Console.WriteLine(Environment.NewLine + sw.ElapsedTicks); Got the idea here. https://stackoverflow.com/a/34035476/1801382
Always good to see others using C# for game dev. What tech are you using to build the engine?
update: Did a repair and looks like it is working again
not set at all
been working fine for me since VS started supporting Git. Yesterday's update was the first problem I've ever had with git. As I said elsewhere, after repairing VS things are working again
Circular references are detected and handled in .Net though.
valid point. I suspect that even internally to VS, I'm not making full use of git
i have been burned by those before, maybe the iisue was fixed since then but at least when working on xamarin i found issues with those cases
No, we're talking about the post, which includes but is not limited to your belief that views are not supported in a way that you believe is appropriate. You have a very particular view about how databases should and should not be used. Now to me, having views that don't contain any kind of identifier is bad practice and bad design. They're harder to work with and harder to debug when things go wrong. EF core could support views better, but it's not zero and better support is coming in 2.1. None of these alternatives fill the same space as EF does. 
Good to see the consul Microsoft extensions provider, will definitely keep this package in mind as I explore my options for config. I'm not currently using anything but consul seems like a good one for when we need something more than static config files. Do you intend to support dynamic updates by any chance?
Prompt to respond with a Google Maps link based on current coordinates, if you receive a text message saying "where are you?". Warn if number is not associated with a contact. Apis: Text messages, Location and Notifications. 
Exactly what I thought. You can’t really reason about cache locality (like he does) when using such a high-level language. Still unity can only be used with C#, and Optimizations on a design level are never wrong. (Chosing the right data structure and algorithms!)
&gt; As far as "serverless" goes, spinning up a "web app" on Azure is "the same thing." There's a massive cost difference. &gt; support a variety of endpoints and interactions. Function Proxies could work for this.
&gt; a class that inherits from another class and that one inherits from another one, and some of the classes contain collections of items and hundreds of properties that in fact are not important to you… That smells to me. I'm sure we can fix the inheritance instead of using a tool to musk it. Already the author states that it is difficult to navigate on the object. Would just having an interface to a method's argument be easy enough to narrow the scope of the object if so wish to use that sort of inheritance? I can see this attribute useful when you want to display the object in a plain string which would be easier to identify rather in a nested object. 
&gt; but I assume that they can make plenty from corporations And they do. And you don't really *need* that feature. You've gotten along fine without it for all these years and no one else has this feature. So just be patient. It'll show up in the Community edition in a few years. FWIW, it used to be that if you worked at a University, you could get access to the Enterprise edition legally. So there are legal ways, if you really want access to it...
&gt; and moving the config to separate classes via EntityTypeConfiguration&lt;T&gt; classes This came back in with EF Core 2.0. public class OrderConfiguration : IEntityTypeConfiguration&lt;Order&gt; { public void Configure(EntityTypeBuilder&lt;Order&gt; builder) { builder.HasKey(x =&gt; x.Id); builder.Property(x =&gt; x.Id).ValueGeneratedOnAdd(); } } In the model builder: builder.ApplyConfiguration(new OrderConfiguration()); 
I'm glad it's working for you, but in my case it's just something the VS people have broken and don't seem to want to fix. It's been broken across several installs and two machines.
I usually just override the ToString method and put in whatever I would need when debugging, though that doesn't work well for big object graphs.
I believe it forms the process. Hence why your app isn't really affected. 
Was going to say this. Deployment slots are pure gold. You can fully test your workload in a Prod like environment without another resource. 
Can you just create a dictionary keyed on those three items? 
I dont know if i really get what you want to do (but i will add my two cents anyway:)) Maybe you should look into collections. Essentially a List with the ability to set filters on it.
A code example might help here. I would think LINQ with some collection (`List&lt;T&gt;` or whatever) would fit the bill, no?
You need to read up on the available libraries etc. for each language and make a choice. I'm sure C# has full support for Windows speech recognition but I don't know about other platforms. 
I don't think you will be able to get away from using a dictionary unless you use an external database (you could look at either redis or SQLite as options, maybe there is a solution to run those in memory). Since you didn't give an example I'm going to make some assumptions. You are worried about keeping things in sync. I would suggest that you have one main dictionary that has a key with your index/id. Then for each additional searchable field you have a dictionary that returns the id (so searching by name would return an id, which then would search the main dictionary by id and return your object). This stack overflow post might give some clues as to how we could make it more generic: https://stackoverflow.com/a/17538305/5670098 
Can't you just use a database? Or a list and linq? Without some context it's hard to say what would be the best option.
&gt; Some people ive talked to said things like Python, Java, and C++ would be a better option. ...and did they give reasons? All of these answers are all over the map - managed vs unmanaged memory, level of static vs. dynamic typing, etc. I don't think this is something we can give much advice for short of knowing more about you and what you're trying to achieve, what the constraints are, etc. The only obvious answer to me would be to start with the language in which you're most proficient, see if you can do what you need to do, and go from there.
Nice!
Databases use b-tree indexes and hash maps. If you need range query, use a b-tree. If you need direct key access, use a hash map (dictionary). As others have pointed out, something like SQL lite will work. It has a in memory option https://www.sqlite.org/inmemorydb.html If you want a pure c# option [NameValueCollection](https://msdn.microsoft.com/en-us/library/system.collections.specialized.namevaluecollection(v=vs.110).aspx) meets two of your requirements. You would then need to maintain a b-tree of dates to 'primary key' values for your date index.
+1 for the language in which you're most proficient
Nice Performance improvement. Shame there is no true Visual Studio for Linux/MAC (I know that there is a MAC visual studio, but it's not the same).
I use ToString too but DebuggerTypeProxy attribute gives so much more flexibility. Love it.
If you need the fast lookup or uniqueness guarantees of a dictionary for all the keys separately, you will have to maintain multiple dictionaries. This is what databases will ultimately do as well if you index multiple columns. You can create a wrapper class that transparently manages the dictionaries, although doing this in a generic way for an arbitrary number of keys is probably a bit tricky.
The DebuggerDisplay attribute is even easier when you're in a hurry. It's like a special ToString() just for the debugger. [DebuggerDisplay](https://msdn.microsoft.com/en-us/library/x810d419.aspx) This is really handy for gnarly thing like building specialized search trees for large objects. Put just the important bit of identifying info in the debugger display, super easy when inspecting lists or arrays. 
Those mini functions are an antipattern and usually, code becomes way more readable as soon as you weed this nonsense out. 
There was an app I did that I never finished. You are at a web page in the browser and then you want it to be read to you by the in built Google text to speech. So you would have the app read the contents of the Web page and then either read it directly or add it to a play list to read later. Kind of like a podcast but it reads Web articles. 
The one you are most comfortable with/like, that also has the required libraries.
I used to love using DebuggerDisplay, but got annoyed that I had to recompile the app each and every time I wanted to change how an object is rendered in the debugger. I also got annoyed with the fact that there wasn't an easy way to add a DebuggerDisplay on a 3rd party class I don't have the source code to (it's possible but the syntax is wonky and easy to get wrong. Long story short - ended up spending the last 7 years of my life working on a commercial extension to VS that makes debugging easier ;) , but that was the first feature: [http://o.oz-code.com/features#reveal](Reveal) allows you to the "star" specific fields and properties you care about, and then shortly afterwards added [http://o.oz-code.com/features#custom](Custom Expressions) which let you add a calculation (any C# expression) to the way the debugger shows you a particular object 
I’m using SDL2 for window and input, and OpenGL for rendering. This is packed into a plugin though, so backends can be easily swapped out (eg. DirectX or console specific whatever)
Nice, I'll check it out. 
Hey there, friend! As others have mentioned, the best platform on which to build a voice recognition app is not very dependent on the language. As far as I know, no languages ship with built-in support for things like that (ie AI/machine learning kind of functions). Rather this is a question of the libraries which are available to use in each ecosystem. On .NET/C#, I believe the best place to look would be to Microsoft's [cognitive services](https://azure.microsoft.com/en-us/services/cognitive-services/). Specifically, you're looking for [speech translation](https://azure.microsoft.com/en-us/services/cognitive-services/directory/speech/). In other ecosystems with other languages, there are alternative libraries. On Python, for example, you might have a look at Google's [TensorFlow](https://www.tensorflow.org/). I don't have any experience with AI libraries, but this has been very received as far as I know. So you would do well to compare libraries rather than languages, I think. I'm sure there are other libraries, but I'm only vaguely familiar with these two. I'm sure Amazon and Google have more options available on their cloud platforms. AWS and GCP. Good luck out there!
How is ``ints`` a good name? I mean without any domain context it is hard to find a good name, but even then I would prefer a more independent name like ``values`` or ``numbers`` or alike. 
 https://github.com/jpann/NerdBot Started as a quick application to get magic the gathering card images in a group me chat while learning NancyFX and evolved over the years to accept plugins for additional features as requested by friends and a small web ui to allow for searching card info online. Code isn't too great IMO (I'm overly critical of myself), but it does what I need and has probably been my most actively maintained side project that has been around this long. 
Both those names are more vague than ints. ints says you have a collection of integer numbers witch best match the context here values is to vague, can be everything in there number is to vague, can be ints or doubles
My argument against the attributes was that if I wanted to share the poco across projects I couldn’t do that without having to include the EF libs to honor the attributes. Something my higher up classes didn’t care about or need to know about. Now you might say you shouldn’t expose those poco classes, but instead create new poco classes and use some mapper to copy the poco classes to the new poco classes. And that has always seemed like code smell to me. 
Woah woah woah slow down. Are you planning on actually building something to interpret language, or do you - and I hope this is the case - plan to build something that calls a voice recognition API? You should be calling an API, as voice recognition has been near perfected by numerous other people, like google, amazon and Microsoft. They all have publicly accessible APIs (I think they all have a free platform with limited requests). What you need to do is build something that can construct a request, send it to your API of choice, and then interpret the response. This really is language agnostic, all popular languages, or rather, frameworks, have the ability to make web requests. In .net - and c# - I would say it’s pretty straightforward. You should start by finding a voice recognition API and requesting access to it, then reading through the documentation, the documentation will contain all the information you’ll need about what you must send in your request, and the “shape” of the response sent back. Oftentimes the docs will give example code snippets in multiple languages to get you going. 
Wouldn't it be confusing to have the debugger purport that an object has properties it doesn't actually have?
EF libs aren't necessary for attributes. Stuff like Table, Column, Key, and NotMapped are all part of .NET itself and used by other ORMs as well. And it's useful to be able to see when a property has a different name than the column (usually because the database is full of legacy mistakes). &gt; Now you might say you shouldn’t expose those poco classes, but instead create new poco classes and use some mapper to copy the poco classes to the new poco classes. Oh hell no. If an ORM can't directly populate the POCO you actually want then it's badly designed in my opinion. EF style entities are nothing but landmines so I do map them. But I don't do it willingly. 
It will display an option to "display raw view" when showing a proxied object, I believe.
Different queries will only know one of those three items. I'd need 3 dictionaries, which is doable, only I want to see if I can save myself the hassle of maintaining them so that they don't get out of sync. 
&gt; although doing this in a generic way for an arbitrary number of keys is probably a bit tricky. My first approach was to do this, but I wanted to know if I was reinventing the wheel. Good to know!
It is faster: Console.WriteLine(string.Join(" ", "Mary had a little lamb its fleece was white as snow".Split().Reverse()));
I just had two different friends asking about app suggestions for pain tracking. They wanted something that would prompt at different times for a quick response on their current pain level. I’m not sure exactly what they were hoping to accomplish but they wanted to be able to view their results over time. I would guess there are native APIs for reminders and maybe tracking to see if they aren’t moving much asked asking if they are in pain or moving a lot and how they feel - not sure how much an app can access per platform on accelerometer or maybe just distance. 
Linq query on the partial key then? 
Exactly this. Azure has a great voice recognition API
screenshots?
Basic webui card search. https://imgur.com/QR7yTqe
It probably doesn't matter. Especially if you're planning to chase after something as massive and complex as Alexa. You'll be writing so much, it may not pick what you start with. Languages are just tools. What speak recognition library do you want to use? What bindings does it have? Etc.
What you need to do is roll on the ground till the fire goes out
Python is rarely good for anything, mainly because it's extremely slow. Outside of scientific applications where it gets much support, there's not much excuse to use it. Aside from speed issues, you should use the language you're most comfortable with. You just don't want something that runs at a snail's pace. 
ty, that works on both.
&gt; provide any advice/assistance specially in the area of performance optimization Probably best bet is to setup a series of automated integration tests in which you try to apply heavy loads (both typical, and artificial worst-case-scenarios). Run some benchmarks and identify the current _real_ bottlenecks. Could be a lot of work to have someone dive into some source code and try to identify some theoretical changes/improvements.
It's a named argument. https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/named-and-optional-arguments
&gt; Actually I am not a Java evangelist at all Fair enough. That was just how it read to me, at the time. &gt; The only thing I don't like is when languages make it easy to do dangerous things I agree with what your basic point. In some aspects, Java in particular makes it hard to do simple things. Using getters and setters for all the things is what is taught in Java 101 courses (which too often is the first introduction to OOP for students). It's even explained as a "best practice" and somehow thought to be synonymous with encapsulation itself. Needing getters and setters because you might need to override them later is a language flaw in Java, because if nothing else it violates YAGNI. C# doesn't have that flaw, and you did a good job of pointing out how *that* might bite you in the ass. Arguably, some of the "design patterns" in Java are also workarounds for fundamental language problems. Tangent: our profession desperately needs some objective standards, so people don't go cargo culting and writing interfaces that have single implementers, default to public accessors, bloat their architecture with "must have" design patterns, etc. Maybe it never will.
I think what you're doing is great and definitely possible (although it's always harder than you first predict). Before you even worry about tweaking the performance of the mapper, make sure you support (or at least explicitly document that you don't support) all the LINQ operations like Group, Order, Take, Skip, etc. It might help to compare your strucutre to https://github.com/ElasticLINQ/ElasticLINQ - the hardest part is mapping the queries from totally different data models. Good luck!
Why would they get out of sync? Make the dictionaries private and stick them in a Manager class. Only expose the methods you need and make sure each method behaves nicely. If you're talking about multithreaded, do the above plus locks in the right places.
In particular, for micro-benchmarks, I've had great success using [BenchmarkDotNet](http://benchmarkdotnet.org/). It's not the quickest way of generating benchmarks, but it's exceptionally thorough.
You could try to implement IQueryable for your queries. I had a tutorial how to do it. Tell me if you are interested and I'll try to find it. 
&gt; If you're talking about multithreaded, do the above plus locks in the right places. Yes, that's what I mean by: &gt; the hassle of maintaining them so that they don't get out of sync. That and your basic safety checks that you don't accidentally throw an exception somewhere and end up with partial data. Don't get me wrong, I love these kinds of problems and it should be fairly straight forward to do. I just wanted to check if I was reinventing the wheel, hence this thread.
Could you elaborate?