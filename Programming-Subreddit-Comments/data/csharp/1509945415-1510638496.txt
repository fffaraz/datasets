tfw you only know BASIC but you gotta write some C
While I agree that putting the enum in its own file is often good practice, I think it's also acceptable to put an enum wherever it is most closely related, even if it is used in multiple places. I do this in Java.
And they can still be useful.
Some off my best teachers were programmers looking for extra cash at night. 
&gt;aside from the fact that it is the future &gt;this is a new project and everyone is kinda using it I think you've answered your own question
Roslyn would be the most robust. You can probably pull it in as a nuget package or something. You can get there with a regex if you have some guarantees about the formatting of the declarations--you'd need access modifiers to reliably distinguish field declarations from local variable declarations, and being able to make assumptions about ordering would make your life easier--a run through a code formatter would probably take care of those, though. If you can get that much, it's really just a matter of verifying that the declaration includes a direct assignment or no body/assignment at all, and you should be pretty much home free. If not, well ... you can probably pull Roslyn in as a nuget package and write an analyzer.
No reason to choose ASP.NET over ASP.NET Core, but definitely reason to choose .NET over .NET Core. And luckily ASP.NET Core can run on .NET. API support in .NET is still larger than in .NET Core, e.g. .NET Core does not support Active Directory or AppDomains (and the last it never will).
&gt;Professors just aren't engineers. To be fair, their are a lot of great professor's out there that absolutely could be or are engineers. This is not one of them but let's not scapegoat.
That's how I used to do it, but I was self-taught. I wince at my older projects now.
You know, I got my degree without design patterns ever being mentioned. My degree was CSE instead of CS but still, I bet a lot of straight CS programs never mention it either or only mention it in passing. It's appalling.
Divine sort: assume your collection has already been sorted by divine intervention. Clearly the fastest.
So what exactly is your question? 
I actually managed to get Roslyn working with nuget. Quite a bit to digest with the API in-terms of creating syntax transformations. I'm mulling over other people's examples of transforming symbols from the syntax tree but I haven't quite figured out how to decorate member variables with an attribute as of this time. I'll just have to read more into their samples on how to do this. Appreciate the response.
If you want to call the `SaveToXml` method of your `HighSvoreCollection` class you need to have an instance of it. If you want to save only one highscore it might be better to implement the saving in `HighScore`, then you can call it directly. 
Absolutely, so when I wrote this post, I was reflecting on my experience using prism and MVVM light for two different crud applications. It ended up being very time consuming, and was a major draw on development. My opinion on this issue has changed since I wrote this because I have been playing with caliburn.micro, which has been nothing but a pleasure to work with. So what I would take away from me is to use the right tool for the job, so use prism when your app is large enough, but if you don't need it, keep it simple. The pattern itself is perfect, but the implementation takes time, and sometimes that's wasted if you could have gotten the same results but in less time. My perspective on stuff like this, is that no matter how pure the design is, if it is going to waste time it's out the window. That includes perspective refactors (see gold plating) So rambling over, MVVM is awesome, sometimes the tooling doesn't make it worth it. If you find the right tooling for the size of your app, you will have an awesome time 
I had an earlier edition and it taught me all I needed on XML serialisation a huge problem on the project I was working on. That said I’ve never been to been one to read a book cover to cover.
&gt; Winforms is not as bad as people said In my experience, it's pretty bad. Aside from the VS designer constantly freezing and crashing, it tends to generate a lot of bogus "changes" to generated files (lines moving around for no reason), even from just opening and re-saving the same form, causing a huge amount of useless noise (and if left in, merge conflicts) in commits unless you manually de-noise them yourself. In the case of WPF, on the other hand, the designer is pretty much rock stable (as much as anything in VS is at least) and there are no generated files that will generate noise, as it uses XML for the layout rather than code.
What if it has triple spaces?
&gt;anyone considering community college, do it! It really really depends on where you live and what you take.
If he already knows all this stuff why is he taking the classes?
http://www.introprogramming.info/english-intro-csharp-book/ Terrible English, great exercises.
&gt;And luckily ASP.NET Core can run on .NET At the moment, no guarantees going forward though. So there absolutely is a reason to choose ASP.NET over ASP.NET Core, to ensure .NET support.
I've done something similar a few times. Using raw Roslyn, it's pretty complicated, especially the white space handling which will easily end taking up half the code :p. Example: If you create a using-statement with Roslyn, you don't automatically get white space between the word `using` and the namespace, so when you turn it into a string, it won't parse.
Just need to populate the trivia preceding/following the tokens yeah?
In my use case, whitespace isn't terribly important since I'm going to immediately strip out the attributes after a buildstep is done.
You can look at these [UT patterns1](https://www.typemock.com/unit-test-patterns-for-net2) and [2](https://www.typemock.com/unit-test-patterns-for-net#Patterns), and this [YT video](https://www.youtube.com/watch?v=Oy-Ny1Op6PY) as well.
Plenty of reasons. In general, tooling for Core is not as good as tooling for the full Framework. Just look at the regressions in bundling of files and the Entity Framework designer (there isn't one!). Core still feels like a beta to me. There are huge, huge changes with every launch. Breaking changes even. It's not stable yet. Once it's matured, it will hopefully be more usable. 
Because it sounds like an entry level course that can't be tested out of. Which is likely a prerequisite for more advanced CS classes. It's similar at my university. Coming in with some programming experience and want to take courses on unix, data structures, etc? Gotta take a 101 class to learn how to use the most basic html, css, and for loops in javascript. 
Right, but you need enough white space to compile, and that doesn’t come automatically in all cases :p
Yeah. Easy in principle. 
Huh wha?
API support, though it is getting better with time. Corporates will choose regular over core due to the maturity of the platform, but again, that'll change over time as the platform matures
 My general rules for partials is this Generated code (DB models and such)? Use partials to make adding functionality easy. The class getting fairly long and has functionality that can easily be distinguished into groups. Each partial should be in it's own file and the thought process I follow is that if I delete any partial file then all of that logic will be gone and the application should compile and run without any problem. This doesn't happen often, but I've had to do it for a few legacy WebApi and MVC controllers
This is true. I skim / speed read them, every once in a while you stumble across something gold.
Huh, professors promoting bad practices? Who knew. From what I've seen in college, they really don't know much... It's pathetic.
Code first, grt with the program.
I suggest you read this amazing book: http://www.wrox.com/WileyCDA/WroxTitle/Professional-C-6-and-NET-Core-1-0.productCd-111909660X.html Wrox, They are the best, the way they advance with the concepts they introduce, the way the wrote about C# thoroughly is just awesome!
You should do your own school work. Not ask other to do it for you.
you forgot to mention that you are using JSon.net library. so they give example from their website : string json = @"{ 'Name': 'Bad Boys', 'ReleaseDate': '1995-4-7T00:00:00', 'Genres': [ 'Action', 'Comedy' ] }"; Movie m = JsonConvert.DeserializeObject&lt;Movie&gt;(json);
Gist is so under used :(
are you using JSon.net ?? i don't know any other library containing JArray class. if not, you should, that is the best Json library in .net. Movie m = JsonConvert.DeserializeObject&lt;Movie&gt;(json); using (StreamReader r = new StreamReader("ide_besede.json")) { json = r.ReadToEnd(); } JArray array = json.Token(name, exceptionMessage) as JArray; foreach (JToken token in array) { MyObject obj = JsonConvert.DeserializeObject&lt;MyObject&gt;(json); }
I think you need to look into storing data into list with class, like this. https://stackoverflow.com/questions/8391885/storing-data-into-list-with-class You can then save list to xml file like this. https://stackoverflow.com/questions/8334527/c-sharp-save-listt-to-xml-file You can also search your list using linq https://stackoverflow.com/questions/1175645/find-an-item-in-list-by-linq This should help you on your way to a solution.
&gt; Entity Framework designer That wouldn't even matter unless you're using the long-deprecated (even for classic EF) .edmx format for generating models. You should not really be using that today with either EF implementation, and especially not in a new project.
you forgot to mention you are using Json.net. using (StreamReader r = new StreamReader("ide_besede.json")) { json = r.ReadToEnd(); } foreach (JObject jObject in JArray.Parse(json)) { string name = p.Name; list_skupin.Add(name); string value = (string)p.Value; Console.WriteLine(name); }
At work we have a file that's all enums
You should use "[dotnet run](https://docs.microsoft.com/en-us/dotnet/core/tools/dotnet-run?tabs=netcore2x)" command in your project folder to compile and run app from source. Also there is "[dotnet publish](https://docs.microsoft.com/en-us/dotnet/core/tools/dotnet-publish?tabs=netcore2x)" command which packs app and dependencies into a folder so you can deploy it in other system.
Check out [dotnet publich](https://docs.microsoft.com/en-us/dotnet/core/tools/dotnet-publish?tabs=netcore2x). 
If that's `OnModelCreating` then that can be broken up per-table, but I guess you have some policy against single-call functions or somesuch.
publish operation is for websites \ webApps
Delivery specifications, or hosting provider limitations will always affect what code you end up using. 
Well I use my extensions as a nuget package so...
If you want a book specifically, I would highly recommend the Player's Guide. Written quite conversationally, as opposed to some of the dry textbooks out there. http://starboundsoftware.com/books/c-sharp/
Yeah, I do it a lot myself. Subtracting points on an assignment and then creating a ridiculous stereotype based on nothing but confirmation bias is where this professor loses me. IMO C# developers under class and under file. See how that works? You can say whatever you want to match your argument. I expect more out of our higher education system. 
If you are in a mostly Windows shop it probably makes sense to use ASP.NET. However you can still run cross platform via Mono. ASP.NET Core is no way mature enough for most scenarios IMHO. I still do the majority of my development using VS2010.
I worked on loads of projects that still use it. Just because Microsoft says it dead it doesn't mean it is.
Don't know about console app, but I have deployed .Net Core websites to Linux (developed on windows) and its easy just a few lines, use kestrel instead of IIS.
You use the dotnet cli tools and vs code.
They pretty much need the dotnet runtime, much like you need a Python, Ruby, or Java runtime installed to run their respective programs. However, you can use `dotnet publish` to package it up for them to use... once they install the runtime.
How? And don't say "manually break it up into smaller functions, then list each by hand in the original function".
Having the runtime installed on the target machine is the easiest way and then you will also have the smallest app (and it will run on any platform); you'd want to publish it in release mode then copy the output dotnet publish -c Release However, you can also create a standalone app; but you need to target the specific OS family with an RID https://docs.microsoft.com/en-us/dotnet/core/rid-catalog e.g. dotnet publish -c Release -r rhel.7.4-x64 Then copy the output from the `rhel.7.4-x64` directory to the target machine (if you were targeting rhel.7.4-x64; change to match target OS) 
CLR Via C# is a pretty good book. I always recommend it as the .NET bible!
The Apress C# 6.0 and the .NET 4.6 Framework, it takes you to a journey. I still also get materials from other sources, though, here and there.
I've used the "select-text" and "Ctrl-." -&gt; "Extract method" to great effect when cleaning up long dumps. It does require sequential model definitions, which somehow was almost perfect even for our haphazard ways..
It seems quite comprehensive, I'll take a look at it. Thank you.
Do you want to do all the tests to see if there is another sitution where it gives an unexepcted result?
That seems exactly like what I want. Downloading the demo to check it out. Thank you! :)
That seems quite advanced for me. But thank you anyway.
Maybe as a follow up, then :)
Both seems in line with what I want. Downloading the Yellow Book to take a look. Thank you.
Didn't knew about this publisher. Just did some exploring in their website, they have a pretty good amount of content on .NET. Awesome!
Then you make more enums!!!!1!
And the next time you need to rerun the scaffolding to pick up new tables? All you're doing is making an overly long file even longer.
Sounds like you want to be using the [TPL Dataflow](https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/dataflow-task-parallel-library) library ([simple example](http://blog.i3arnon.com/2016/05/23/tpl-dataflow/)). More specifically, you'll probably want to have a look at [this example](https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/walkthrough-using-batchblock-and-batchedjoinblock-to-improve-efficiency#buffering) from the docs. It's sounds like what you're trying to accomplish.
If you are not coming from a .Net background then .Core is a good choice. 
If Microsoft says that something is dead then it must be really dead. I would be more suspicious of things that they say are fine when they look dead (eg. Windows Mobile). 
You honestly sound like you have bigger problems than file and folder structuring. What you mention should not have the problems you claim unless you truly have no idea what you are doing.
It is a problem when working in organizations. For solo projects, having a file with one enum and nothing else is merely frivolous.
I work in organizations. What you describe does not happen under version control unless catastrophic distributed data loss is at play, which is why I am incredulous.
Work there longer.
You need to read up on Covariance/Contraviance/Invariance. `CCS` doesn't implement `IApiModel&lt;INotable&gt;`. It actually implements `IApiModel&lt;CSSServer&gt;`. You'll notice in your code, `CSS` has access to `List&lt;CSSServer&gt;`. If it actually implemented `IApiModel&lt;INotable&gt;`, this property would be `List&lt;INotable&gt;`. You're correct in pointing out that `CSSServer` implements `INotable`, but inheritence gets a little funny when discussing parameterized types (hence covariant/contravariant). With your current code, your method needs to be something like: class Locker { void CompileServers&lt;T, S&gt;(IEnumerable&lt;string&gt; names) where T : IApiModel&lt;S&gt;, new() where S : INotable { } } You can now correctly constraint your input when calling the method: List&lt;String&gt; servernames = GetServernames(); Locker.CompileServers&lt;CSS, CSSServer&gt;(servernames);
`CCS` is an `IAPIModel&lt;CCServer&gt;`, which is not the same as the required `IAPIModel&lt;INotable&gt;`. If it was, you could add *any* `INotable` to `CCS.Server`, just just `CCSServer`. Look up covariance.
Only one - being forced to write WCF service.
No. I've been working with .NET since 2004. Some of us work with a lot of so called "legacy tech". I have load of projects that still work fine that are were written for .NET 3.5 and are running something like MVC 2 or 3. These sites are running on Azure fine. Some of us don't want to have to spend relearning and upgrading libraries and toolkits that work perfectly fine because Microsoft/Joyent/Facebook is pushing some new toolkit which happens to be flavour of the month. Tech like EDMX is great for RAD prototyping and getting something up and running for the client. I suggest you read [this](https://hackernoon.com/the-boring-stack-the-best-way-to-build-interesting-things-9f54420f683e).
Iff that were to happen you have far more grievous problems than you file and folder structuring. What I am saying is that your claims does not follow from your arguments.
Core. It’s the future of asp. Microsoft is really pushing it 
I mean, some can. I had a professor grade a project as an A on something that didn't even work because she was impressed with how ambitious the attempt was. I learned to set reasonable goals and didn't have to bomb my grade for the course in the process. There are some really good professors out there.
I think you should understand that the processor would choose anything arbitrarily. This professor is trying to curve the grading scale by marking your son down. It has nothing to do with the issue that was brought up. 
Is your startup object set?
In a production environment you should use a reverse proxy like nginx and create a systemd service for your app. &gt;Kestrel is great for serving dynamic content from ASP.NET Core; however, the web serving parts aren’t as feature rich as servers like IIS, Apache, or Nginx. A reverse proxy server can offload work like serving static content, caching requests, compressing requests, and SSL termination from the HTTP server. https://docs.microsoft.com/en-us/aspnet/core/publishing/linuxproduction?tabs=aspnetcore2x
If you want to send this to other users I would go with self contained app. You will end up with more files to deploy (bigger app) and you'll need to publish for each different OS target, but your users won't have to install Net core. 
I like StackOverflow, but I sort of miss the days when MSDN included (E)BNF of language syntax and stuff. It also tended to have examples of how to use stuff, but! they had an unfortunate tendency to be not-quite-correct or misleadingly incomplete, IIRC. One reason MSDN doesn't have that sort of thing, now.
Is VS2010 even supported on win10/2016?!
&gt; depreciated deprecated btw
It was, but I fixed the issue. 3 R's of Microsoft Troubleshooting Reboot, Retry, Reinstall. First R Fixed it. 
MSDN; man pages; books from Microsoft Press, Addison-Wesley, Manning, O'Reilly, etc; and also things like Experts Exchange, Tek Tips, etc. Depends a bit on the topic, but, mostly, you shelled out for books more often and did more reading and experimentation. This had some advantages, in terms of discovery of language/system/platform features. Since you had to spend more time going through the manual, you were a little more likely to stumble across topics or features that were adjacent in either the source page or index. You also needed to be a bit more up to speed on some of the foundational material, since you couldn't copy and paste the solution *quite* as easily. There are some things I miss about some of that, but Google+StackOverflow has made it *much* less common to wind up in the position of being unable to solve the problem because you don't know the right vocabulary to look the damned thing up in the index.
As a non linux user, I'm curios - what will the differences be across distros? (for a console / web app)
Thanks
If you're rerunning scaffolding anyways (why?), then just rename it as .Designer.cs and quit fretting about it. We have mostly manually created model adjustment that doesn't have all that much science in it (simple-ish relations that are however vastly more complicated than the blog examples..). Creation/migration of DB is through sql scripts because migrations were plain waste of time and nerves so there isn't anything related to that madness.
I guess if you want to run in on a Linux server or in a Docker container, your only choice is Core. Other than that, not really
I can't make any meaningful recommendations for statistical libraries but at the moment I'm using OxyPlot to make an analysis tab for a WPF app. The official documentation ranges from lacking to abysmal, but the samples are easy to learn from and it's quite intuitive. For something like presenting a bunch of charts in a grid layout it would be relatively simple to set up (since the axis labels are handled by the plots so you barely need to know anything about actually using WPF) and quite pretty.
Yes VS2010 is supported on Win10, installed it some weeks ago. Download size was like 100MB, after 2 minutes everything was installed. Would be good if VS17 have that speed of an installation.
Can he not change "CCS : APIModel&lt;CCServer&gt;" to "CCS : APIModel&lt;INotable&gt;"?
You iterate each character in input. In each iteration you add to a value if there is a space anywhere in the string. Results should always equal either , # of characters in string (when there is at least a single space) or 0 when there is no space. You can't count the number of spaces to count words anyway, because even if this was doing what you thought it was (Which i think would be if(input[i]==' ') counter+=1; you would still have an incorrect value when you tried to count the number of words in either "This" or "This String" and "This String" The first string "This" would return 0, even though there is one word "This String" would return 1 even though there are two words and "This String" would return 3 even though there are two words. 
In .net core 1.1 the compiled library file set (.so files) was different; with .net core 2.0 it covers the whole api surface as far as i understand.
You can use any supervisor, doesn't have to be systemd (i use `immortal` at work). Also, the whole web server thing applies only if you try building 'mvc' apps with core which is a questionable thing to do. When you build a react/angular app you best do that completely outside vs or .net core; package separately and host separately (and yes, here via nginx/apache/whatever)
There is a `--self-contained` flag so the final app runs without runtime (don't forget `chmod +x`)
Because EF sucks and I need to hand tweak what the scaffolding generates.
There is also an option for XML too.
when i read clr via c# back in the day i found it very readable and engaging, unlike a reference book. that's because for my money it targets the right kind of programmer (i.e. not too advanced or novice), explains down to the correct level of detail for working with c# in 99% of cases, and uses a relatively conversational style. then again, there are a million good answers here and on stack overflow.
Based on the requirements you've listed, I'm not sure I (personally) would look to the Actor Model *first* to accomplish the core things you want to accomplish in your first paragraph. The Actor Model requires a different mindset than you might be used to than simply interacting with a database for your basic CRUD operations. It doesn't really give you anything new in terms of notifications via WebSockets either. That's not to say don't learn what the Actor Model is all about though. It revolves around asynchronous message processing, focusing you on the fact that your standard OOP "objects" can do what they need to do autonomously and then communicate with the world outside of them via messages. This is what allows this kind of system to be distributed more easily than a traditionally-designed system. When you take the system that you might be used to and try to distribute it, you run into problems with sharing data across components (look up the dining philosophers problem as an example). This is when you discover that message passing is a better way to share data. Since Actors live in isolation except for the messages they pass to each other, you're designing the system up-front to be ready for distribution. However, scaling by distributing *everything* shouldn't be your first decision when you need to scale. Locking your whole application into a framework for distributed systems might take you down that road. Why design up-front to be completely distributed when only one small part needs to be? I'd build something like this with what you already know and do well, and then measure as much as you can to decide what needs to be scaled. If some small part of the app looks like it would benefit from scaling horizontally because of numbers that you have measured, then you might think about breaking that part off into something based on Akka. Otherwise, I'd stay comfortable with CRUD and web services and look for better design decisions around that if there are issues with performance. Overall, Akka is a big investment and a big lock-in once you commit to it.
Array starts at...?
The tooling and maturity is there, but all my new projects have been in ASP.NET core. 
Why is building mvc apps with core questionable? 
They all work fine down to VS 2005. You have to do custom install and remove crap like crystal reports and the SQL Server CE version that is bundled. https://imgur.com/a/EVgbd
When MSDN doesn't give you enough information, go to the source: sourceof.net
Zero.
I own that book and sometimes I feel it's a little hard to follow along.
That one is by far my favorite. It is very comprehensive but it's material you'll read through overtime... I certainly haven't finished it in the last chapters like on ASP.NET. Fortunately, they are just about to come out with [C# 7.0](http://www.apress.com/us/book/9781484230176) along with .Net Core chapters just next month. IMO, what makes this book great is the many examples they have. They break down a complex problem into exercises that you can follow along with.
Indeed that would work, but his implementing code might need to access members in CSSServer, not just those in INotable
nah, we're on good terms. he teaches me stuff, i teach him stuff, it's good to have someone to learn with :)
I know the feeling. Trust me, learn WPF and start teaching him. WinForms has its place, and it probably isn’t what you’re using it for.
if it's stupid, but it works, it ain't stupid. i have a telnet class that will throw an exception on ending. can't figure out why, so i wrapped it in a try with a blank catch, and now it runs with no issues :S
RIP json2csharp.com
Not a real book, but I recommend the original Unity course on Udemy.com by Ben Tristem
It'd have to be a book, I want to work my own base without any pressure. Also trying to read and type code is fairly difficult without 2 monitors.
There's nothing wrong with database first. Even with code first for an existing database, I believe there's a designer on the full framework. Core requires the command line which is a backwards step in the user experience.
&gt; I can't seem to find what will cover everything You're better off getting two books - one to cover the C# language and another to cover whichever part of the .NET Framework that you want to work with - Unity, in your case. If you want a single book because you're tight on cash, you can look for cheap used books targeting .NET 3.5 or 4.0, since Unity uses a version of Mono that is based on an older version of the .NET Framework (you'd have to check which).
Lots of things have been considered, although I don't think sum types are anywhere close to actually making it into the language at the moment. You can find many of these discussions on the [csharplang repo](https://github.com/dotnet/csharplang) (and sometimes other related repos like roslyn, coreclr, corefx etc.). For example: https://github.com/dotnet/csharplang/issues/75 https://github.com/dotnet/csharplang/issues/399 https://github.com/dotnet/csharplang/issues/113 https://github.com/dotnet/roslyn/issues/8729
I would love there to be a way to just include a url to a direct file source in .csproject files. Something like: &lt;refUrl&gt; mycode.net/common/extensions.cs &lt;/refurl&gt; Not even sure if possible but it should be.
Because why would you build an app with postback interface? SPA provides for a smoother ux, is easier to turn into a progressive app and can provide a fully offline mode
It would be far more complex, but here is the gist of it. public static int CountWords(this string input) { StringBuilder builder = new StringBuilder(); for (int i = 0; i &lt; input.Length; i++) { if (i != 0 &amp;&amp; input[i--] == ' ' &amp; input[i++] == ' ') { continue; } builder.Append(input[i]); } int padding = 1; if (builder[builder.Length - 1] == ' ') { builder.Remove(builder.Length,-1); padding = 0; } return builder.ToString().Count(c =&gt; c == ' ')+padding; }
I'm working on a build system. Currently looking for people who would like to try it in their open source projects.
Uhh yeah, the correct answer to this question is: "What does the code standard for the project say?" Intro courses really should set code standards just to get people used to following them.
How far into the book did you get? Once you get past the chapters that focus on the framework I thought it was pretty good.
Just in case, but I'm sure you have: have you checked out the online reference Programming the Blockchain in C#? It details NBitcoin's implementation and goes into detail on generating keys of all sorts. The theory works in other libraries. Of course the book Mastering Bitcoin, as well, despite being in C++. 
I liked the C# Pocket Reference (about $12). It was a helpful survey of the language features. R. Scott Allen's videos on PluralSight are beyond excellent. You can watch for free if you have MSDN.
 If you want to remove more than one space you would have to iterate through each character and check to see if the previous iteration was a space as well. public static int CountWords(this string input) { var builder = new StringBuilder(); for (int i = 0; i &lt; input.Length; i++) { if(i != 0 &amp;&amp; input[i-1] == ' ' &amp;&amp; input[i] == ' ') { continue; } builder.Append(input[i]); } if(builder[builder.Length-1] == ' ') { builder.Remove(builder.Length-1, 1); } return builder.ToString().Count(s =&gt; s == ' ')+1; } That will return the word count even if there are thousands of spaces.
Yeah I mean a few lines before publish to a folder then copy the files to the Linux server, I'm using nginx on the Linux server, and of course you have to have dotnet on the server and probably Node if you are using it.
Wow, Thanks! I'm thinking on Akka.net because the clients will need to connect and receive notifications from not only internal network, and it looks like it is "easy" to send/receive messages to/from remote actors. I'm still deciding the tools I'll use in the project.
Personally hate those kinds of 'varients'. Just make separate classes.
That is what I did want to use yes =) I ended up patching together a very rudimentary (probably badly executed) homemade queue and using Tasks, but your examples seem to be very helpful so I might finally achieve using TPL =) Thanks mate!
Speaking from not knowing Roslyn, if I had to do this without that level of integration I would probably use something like reflection plus some post processing. Its essentially a poor mans roslyn. IE you reflect over the classes to find all the *fields*, record their names, then have a post process step that actually loads the source code file, iterates over the found fields, and add your attributes.
When you want a central authoritative data repository with thin client user interfaces.
I remember reading an article that showed an example using generics but I couldn't find it. This article shows how to do it with structs and the field offset attribute. http://jacksondunstan.com/articles/3325
Legacy tech is lottery. Some people felt safe with Java browser plugin too. Now plugin support is going away and workaround is not a minor API change. It is a complete rewrite on a totally new stack. 
I was just actually planning on learning how to do this in c# within the next few days. Just saved me some time
The following is the article I was thinking of or close too it. https://stackoverflow.com/questions/3151702/discriminated-union-in-c-sharp
Udemy is at your own pace....no deadlines or anything. You may be thinking of MOOCs like on Coursera that have a timeline. Udemy is a good choice for really good self paced courses on all sorts of subjects. The C# ones by Mosh Hamedani are really good. You can usually get the courses on a sale for $10 or $15 and they are worth every penny. Now the two monitor situation I can't help with other than to say I actually worked through a lot of the Udemy courses I mentioned above on a single 1080p monitor with visual studio and the course side by side. It was not always comfortable, but was doable. Now throw working with Unity in there and things could get hard. 
Inheritance expresses sum types. By default, these sums are over an open family of types, which I think is unfortunate, but that's what we have in C# and VB.NET. To ensure that a given superclass represents the sum over a closed set of types, we make the constructor for that superclass private, and the subclasses become inner classes of the superclass. This is basically what F# does to represent sum types on the CLR. public abstract class Animal { private Animal() {} public class Cat : Animal { public Cat() {} } public class Dog : Animal { public Dog() {} } public TResult Match&lt;TResult&gt;(Func&lt;Animal.Cat, TResult&gt; catFunc, Func&lt;Animal.Dog, TResult&gt; dogFunc) { if (this is Animal.Cat) return catFunc(this as Animal.Cat); if (this is Animal.Dog) return dogFunc(this as Animal.Dog); throw System.Exception("unreachable"); } } 
I don't think I understand the benefit of sum types: what do they offer, that polymorphism doesn't? Don't they just amount to an object, who's behavior changes depending on a flag? Wouldn't this be considered code smell in OOP?
It basically means you can have enums where each variant is individually typed. This allows for fantastic pattern matching - and for eliminating null, because you can return `Option.Some&lt;T&gt;` or `Option.None`, where Option is the enum.
I was just pointing out that your solution was very specific to a single scenario. This solution on the other hand is far too complex for the task. Also, as far as I can tell this will count one word too much if the string starts with a space. Look at the simplicity of the highest voted comment in this thread.
Just ask about why. Our professor wants everything in one file because his system for reviewing our code can only take one file. It can’t handle tabs properly either so he asks that we don’t use that. I have a script fixing that for me, so I don’t have to worry about it.
I'm using this pattern currently. It would be great to be able to use structs instead of classes though.
Not really. They aren't comparable in anyway. NPAPI / Browser plugins were fundamentally flawed piece of tech that nobody liked and was full of security holes. Using an older library or toolkit in .NET is a completely different kettle of fish. Entity Framework is just a library that happens to have some tooling in Visual Studio to generate the XML files that define the mapping between your code and your database (I am sure it is more complicated than that, but it is close enough for the purpose of this). WinForms has apparently been dead since WPF in 2009 and almost 9 years later I can still go New Project &gt; Windows Classic Desktop &gt; Windows Form App. This isn't the JavaScript community where once a framework is over a week old it is forgotten and left to languish in the depths of github. If something works fine, isn't fundamentally flawed (unlike your NPAPI plugin example) and it is productive then I see no problem with using it. It isn't like someone is advocating for creating a new web app with Cold Fusion, Classic ASP or some sort of delphi monstrosity. 
[removed]
&gt; There's nothing wrong with database first. True, but you're probably better off using tooling that isn't officially deprecated for managing it. &gt;Core requires the command line which is a backwards step in the user experience. The commandline (or specifically, Package Manager Console) is only used for creating migrations - this is the same for both classic EF and EF Core. Defining the models is done entirely in code. They're just plain C# classes.
Paket does something like that if I remember correctly
For database first, you need to use the command line to generate the models. This is a backwards step if you prefer that approach.
Ah, not familiar with that approach then. I didn't think EF Core supported anything other than code-first for migrations. I wouldn't want to auto-generate the models from database anyway, though. If I wasn't using EF migrations, I'd probably use something like DbUp (which I haven't tested yet, but it looks interesting and I will probably try it out at some point) for managing migrations using plain SQL scripts and just create the models manually.
And having a postback interface and page load times will help with that how?
&gt; I still do the majority of my development using VS2010 Why? In my experience, opening existing projects in newer VS versions has never been much of an issue. I believe VS2010 to VS2012+ required an upgrade, which VS did automatically, but since VS2013 at least it hasn't even been necessary to perform an upgrade. Hence, I've never seen any reason to ever use an old version of Visual Studio for actual C# development.
* I prefer the interface. It was before they starting making everything flat, changing the icons for no reason what so ever. * No really irritating bugs. * It also isn't a resource hog. I am a full stack web developer so while I am pretty good with C#, I am far from an expert and I rarely even bother looking up the newer features. * Sometimes I work with other developers than are still using VS2010 + Windows 7. If I use the same IDE version you don't run into incompatibilities with newer project types.
I'm not sure what migrations are tbh, but what you do with database first, is you develop your database in SSMS and your models are generated in Visual Studio from that. To make changes, you alter your models in SSMS and then re-generate them in Visual Studio.
Ive been eyeing little color management system for a project of mine: http://www.littlecms.com/ Haven't touched it yet, but it looks promising. 
Please check out my library https://github.com/Jagged/OneOf We forked the original, and released as "DiscU" on NuGet. There is also a big speed improvement coming up soon, just got the code merged in. We basically provide extremely fast, fluent-interface driven Match and Switch functions, which accept as their inputs any function with the parameter of the type you're matching on. It's quite easy to use, highly optimized, and minimal - it doesn't try to do what many of these other functional libraries tries to do by providing the kitchen sink - it just gives you good Sum Types/Discriminated Unions.
Migrations are just a way of generating schema updates based on Entity Framework models. Database-first doesn't necessarily imply generating models at all, just that you don't generate the database schema based on code models. You could still just create the database in SSMS or manual SQL scripts and use EF by creating the models manually. Or alternatively, you could not use EF at all, and use something like Dapper with manual SQL queries instead.
&gt; Random lockups for no reason. If you're having lockups, it's unlikely that VS itself is the reason. I've had issues like that before, and they were always caused by my anti-virus murdering IO by real-time scanning VS files and cache files. They went away completely after excluding the VS installation directory and my source code directories from real-time scans.
Database first is the opposite of code first. You create C# models from your database schema. I've heard that code first can also work with an existing database, but I've never tried it.
If I ever bother using it on my machine at home again, I might try that but it doesn't happen in any other IDE (which if it was an I/O problem it wouldn't just affect VS). As I've said I been using Python for a lot of new projects.
So what's her first programming language? Every language I have used it's more a rule than a suggestion. Why on earth would you want the enum defined in a class? Might as wel use private static string than. Has hshe ever had any colleagues while programming?
F# has discriminated unions, so it's possible in the CLR (with some be hind the scenes trickery). I haven't heard any rumors about supporting them in C# anytime soon though. That said, if you want a functional language in .Net give F# a try. I highly recommend www.fsharpforfunandprofit.com 
&gt; Also it not when saving, it just happens for no apparent reason. I did not have the issue when saving either. It was mostly when loading a solution or installing/updating nuget packages. The biggest trigger from what I recall was opening a solution that contains projects with missing references. That would cause VS to just completely implode on itself, freezing for minutes at a time. I also didn't have the issue before a certain point (possibly VS2013 or one of its updates), so Microsoft probably changed something that made it more affected by the real-time scan, but excluding VS and the source repositories fixes it anyway.
&gt; I've heard that code first can also work with an existing database, but I've never tried it. It can, but at that point it isn't really code-first anymore. You write models manually to match the existing database's columns (the ones you need, anyway) and use them in the same way you would if you were using true code-first approach with migrations. I've done that before, and it's what I would still do if I was using EF with a project that doesn't use migrations for managing the database.
My first guess is that `temp` is already the `CBezier`, but I can't see how you're creating `temp` so I don't know
Remove `invoke` and see what happens
http://prntscr.com/h7bbee
Hmm okay it seems `UnityEvent` must be invoked manually. Normal `event`s can be invoked without `.Invoke`. If you want consistency you could also call the `Action` delegate with `.Invoke`. .. Invoke
also, for completeness, words can be delimited by more than just spaces - commas, periods, new lines, etc 
Think about what somebody would need to know in order to answer your question. Now ask yourself if you have provided that in your post.
found out that XElement _start = pointsList[i].Element("Start"); works, so I dont need to get inside "CBezier" tag.
looks like it!
I have got some info about blockchain and its technology some time ago especially in Bitcoin and learned a lot about that. I have now found a very nice library exactly for my purposes, so my question was solved. Thank you for help. 
Yea, it is easy to send/receive messages to/from remote actors. But, there is also the need to nail down the deployment and configuration of remote actor systems too. Sending messages from disparate sources to a single "collector" could also be achieved with a pub/sub message bus, without having to change your app's entire programming model to the Actor Model.
So basically C# knows about real delegates like Action and gives you a shortcut (but you can use invoke if you want). But it doesn't know about Unity's fake delegate so you need to use the long version.
Almost, `UniyEvent` is equal to the build-in `event`, not `Action`, which is a `delegate`
The second one, OnFingerHeldDown, is an event. OnFingerHeldDown(finger) and OnFingerHeldDown.Invoke(finger) do the same. The former is shorthand. They will result in the same code after compilation. The first one, onFingerHeldDown is a UnityEvent. This is Unity's way to emulate similar functionality to C# events, but with some Unity specific functionality. The main reason to use these is that they let you subscribe to UnityEvents in the editor. It does not have the fancy shorthand of "real" events, because it is just a regular Type with it's own Invoke() method. 
I would say generally the Nutshell books should are not really for learning C#, and are not really meant to be read in full. They are more meant to be a reference source while you are coding. 
I once had a teachet give me a 60 on a practical because I didn't do something. No where on the practical's specs did he request that we do that something. He insisted on the 60, I got in touch with the dean, and it ended up being converted to a 100. Other students who couldn't even get their program to compile got 80s and 90s. They were black, I was white, the teacher was black. Took a few more issues with the same teacher before I realized what was going on.
And yes, this little silly mistake made me wasting around one hour for enchancing the rest of code. But thank you for all answers and I'm confident, that I will use these informations in the future. Thanks again! :D
`event` is just syntax sugar for exposing delegate members.
Right, but a delegate alone can't use sugar functionalities like += so i like to consider them different parts of the same thing
Sure they can: public Action PseudoEvent; PseudoEvent += () =&gt; Debug.Print("foo"); PseudoEvent(); The only thing `event` adds here is encapsulation (can't invoke the delegate from outside the event's declaring type) and thread safety in the add/remove methods.
Sry i edited my comment, but you are right
Neat, reminds me of ozcode but free. I'll have to give this a go.
You can achieve this in C# by using Flags attribute on enum and by setting enum values with power of two. [Flags] enum Directions { None = 0, Up = 1, Down = 2, Left = 4, Right = 8 } Now you can create combined enums like this: var upLeft = Directions.Up | Directions.Left; // Up | Left var downRight = Directions.Down | Directions.Right; // Down | Right Combine these combinations var allDirections = upLeft | downRight; // Up | Left | Down | Right Check for enum/flag if(upLeft.HasFlag(Directions.Left)) Toggle values allDirections ^= Directions.Up; // Left | Down | Right allDirections ^= Directions.Up; // Up | Left | Down | Right
Yeah that makes sense, and it was in fact being used from editor, thanks a lot.
I believe it's depicting called "outside", altough I don't know very much about that place. 
Are you copying the .config file to the same destination that the .exe is going?
"The Art Of Unit Testing" by Roy Osherove is a pretty good primer. Buy the book, it's worth it. Dependency injection is a very important concept as well and will help you effectively unit test more complex systems. There are a number of books out there but Mark Seeman's "Dependency Injection in .Net" is probably the one to recommend. 
What is this "outside" you speak of?
ah no - is there anyway to compile it with the .exe
You could use resources and embed them in the assembly. https://support.microsoft.com/en-us/help/319292/how-to-embed-and-access-resources-by-using-visual-c
Thanks!
Read up on TDD and dependency injection.
+1 to all of this
On top of xUnit you could e.g. use [Fluent Assertions](http://fluentassertions.com/). This makes assertions easier to read and gives more meaningful failure messages. Disclaimer : I'm a contributor to the project, so I'm pretty excited about it. 
If you are a company located in the EU, I'd refrain from using this library. Logging the environment variables is a potential issue regarding information privacy. And with the upcoming changes in the law and the heavily increased penalties this is nothing to joke with.
It just looks good...
I don't think that's quite what they mean. A [sum type](https://en.wikipedia.org/wiki/Tagged_union) is a type that can contain a value of type A or type B, but not both. It's not an enum or flag.
Yeah.. Classic "after successful IDE installation" outside.. 
TDD and unit testing are not necessarily the same thing.
It could be reference to [2011 Future Vision](https://youtu.be/a6cNdhOKwi0?t=267)
I too can be a pedant
Looks cool, I’ll have a play, thanks!
Not what I’m referring to I’m afraid! You might want to have a read of the link I posted :)
Nothing like a camping trip after a VS update! 
What env variables is this a concern with? The multinational company I work for logs everything about the environment, and this is not a concern for us.
What if this is executed when the user selects a menu? Is that legal? 
Would there be an issue if it was not automatically collected? Presumably if the app stored it locally, and the user had a way to submit diagnostic data for troubleshooting (with the ability to review the data ahead of time), wouldn't be it fine?
This looks pretty useful. Ill be installing this later.
You forgot two commas, then.
Cool, will check it out and try it. 
It's now time to explore! 
Thanks again! Then, do you recommend to implement message notifications using SignalR? 
Yes, an event is like a property: sugar for some methods, in this case add and remove which are again sugared to += and -=. Contrary to properties, they are default implemented to just combine and uncombine delegates. 
Focus on the methods with lots of branching logic, or methods which do heavy calculations. Frankly, unit tests (e.g. xUnit) work best in a test-driven development environment where the developer writes the test prior to writing the method that implements it. If the method is going to be tricky or intricate or data driven, then coding it without creating tests first is just foolish (i.e. how will you know that it works?). Good reference book: Professional Test Driven Development with C# by James Bender and Jeff McWherter. Secondary possibility is xUnit Test Patterns by Gerard Meszaros.
While I think that the particular library you're mentioning is overkill, I completely agree that you're right on the button with the need to capture relevant data. I utilise Azure App Services for all of our production work. Each one has Application Insights enabled, and I trace a shit load of additional data on top of that for all mission critical functions and methods. As you mention, the data is invaluable for debugging live environments. The only thing you need to worry about is the legality of storing that data, but that's not an issue if your legal policies are comprehensive and your region of operation allows you to do so. Good post 👍
If "outside" has birds that large I don't want to go there.
If "outside" has birds that large I don't want to go there.
I have several forms with a lot of controls and it is working fine. 
Community edition depicting your communion with nature or some such.
Generally you dont want to do that. The config is explicitly in a separate file so that configuration can easily be changed without recompiling and redeploying the binaries.
doesn't work vs2015 it just crashes on install 
It says in the requirements it needs 2017 version 15.3
That bird is huuuge. It's the Last Boss. The cup with the green plus sign is Health. Check the tent for weapons, otherwise you'll have to fight try to hit it with your bike. If you succeed, you may get a job offer from Microsoft. Either that or Bing Points.
Cheers, this looks cool, but won't be able to use it at work without 2015 support :( Otherwise love the look of it.
&gt; That bird is huuuge and tasty let's call her Tasticle
Do they log it on their servers, or on customer servers though?
Down with 2015. Long live 2017!
Wowza, that code would smell like the pits of hell. Good luck with it haha, thanks for your comment!
Thank you, this is very helpful!
This is the future of coding
oomkay thank you, this is a much more hardcore way of structuring than anything I've done, are all of the classes still contained in your .csproj?
I get a message saying "The extension cannot be installed due to prerequisites that can not be resolved" It dosn't tell me what the pre-requisites are. VS Pro 2017
It's not exactly like I have control over the situation.
Yep
Yes you do. Just open it in 2017 and click that upgrade button... Screw any "risk" or "work" reasons. ☺️
The think I didn't like about OzCode is the new subscription model as well as ReSharper, that's why I drop both of them and now I'm looking for small addons like this to get a better experience on VS2017 :). Another good extension is Roslynator 2017.
Our product is all SaaS, so our servers. However, the data doesn't leave the country it originated in.
Resharper sucks, but the subscription model is way easier for corporate clients and with VS getting yearly releases now the old model didn't really work anyway. 
For a MVC solution, we usually have a handful of projects in the git repo - src/Host or src/Website which houses the controllers, views, view models, startup - src/Migrations project (FluentMigrator) sets up the database makes changes to the database as the models change (we do not use EF migrations) - tests/Host contains unit tests for the models and some of the business logic, there may be some integration tests there that exercise complicated controllers (or helper methods), but most dependencies are mocked out - src/Core, sometimes a project is complex enough to need a "core" project, but it's rare unless there is both a website (MVC) project and a WebAPI project in the same solution - src/Client for when we do an API and want a client Nuget package to make it easier to consume, all classes and constants that the client would have to recreate in order to consume the API in .NET are placed in the Client package We're not dogmatic about any of this, especially the folder structure. We try to keep the structure as shallow as possible. So unless we go over a dozen views, all of the views are in the Views/ folder. Naming of classes is something where we are a bit more dogmatic. All controllers end in "Controller". Views end in "View", view models in "ViewModel". XYZService is something that calls the XYZ API. But even there, as long as you can give a good reason to go outside the norm to the others on the team, it's okay. Refactoring is relatively low risk for us, especially in business logic that is protected with lots of unit tests (and some mocked integration tests). So even if we get the naming wrong up front, or the folder structure wrong, renaming / moving classes with Resharper makes it easy and the unit tests guard us.
It looks like it replaces just a very small subset of OzCode.
Locking a resource during an await is a very bad idea. You have no idea how long the wait will be, which can lock out other processes, and you can cause deadlocks.
It may be less common on Windows but I know a lot of people store passwords and other secrets in environment variables so that they aren't present in config files. I would be very hesitant to collect that data, but I love the idea in general.
R u making a .exe file of your program or is it a web application 
That is a *lot* of text to ask the user to review before sending. They aren't reading the EULA and they probably won't read this either. Additionally, remember that it might not be the user who put sensitive data in the environment variables - even if they scrolled through, the average user may not be able to identify what is and is not sensitive.
Most startups nowadays throw everything in heroku, add a few logging and analytics addons to their app, and *boom* you’ve got multiple companies which already have full access to your application logs and environment. Then add in Rollbar, Sentry, or whatever the flavor of the month is for exception handling, and that library logs all of your environment variables to their server as well. It has become increasingly ridiculous common practice to (unintentionally/negligently) hand out access to your app secrets like candy.
I think locking resources inside awaits is incredibly common, and necessary in a lot of cases. I'm curious to know what your alternative to locking would be. This post is meant to build on top of some already existing async/await locking implementations and add some (I think) new functionality.
Those are all very reasonable points. But is that a GDPR issue at that point?
I'm afraid I know nothing about EU regulations. Either way, even if it's "legal" it's probably not a smart idea for security/privacy purposes.
This doesn't mean I can't AJAX shit around.
Not enough error handling. You're always subject to unpredictable race conditions with this stuff that need to be managed. Windows can close in-between getting the handle and obtaining the information, window titles can get longer after you obtained the size etc.
Is this a legal concern? I thought the EU was only concerned with PII and similar data. Application data is not that.
This is not a legal issue, which is what I'm trying to learn more about.
&gt; What env variables is this a concern with? Multiple issues. A folder name can be PII very easily, especially if a program expanded %UserProfile% rather than leaving it as a variable. "C:\Users\Juliano McFarthenberg" Oh look, you just deanonymized the user. You have no idea what some other program might be putting in environment variables and filenames can themselves be PII because they are potentially user input. BANKMGRAPP_DEFAULT_ACCOUNT=%UserProfile%\AccountNumIs66988323andPasswordIsIDDQDIDKFA1982.dat The mere *existence* of other environment variables can be sensitive information. PORN_MANAGER_FAVORITES_FILE=\\\20TBNas\important\myporn.favorites
It's the rectangular portal that provides access to Amazon packages.
Well, that's not a problem, since you're leaking your own information, not someone else's information.
Tested opening an old version of a project with a bunch of forms in VS2017 now, and it does seem like they've improved it. I was able to open a whole bunch of forms without it crashing or generating any useless line-reshuffling changes.
If you are running this on your own server, then this is likely not such a big issue. But if you run this on a clients system (e.g. WPF apps) and automatically transfer this diagnostic data, then this is a minefield. You don't control what is part of the environment variables, it could contain sensitive data that should never enter your system.
Environment variables are not application data. They are whatever the user has configured on their system, and assuming your application runs on the users system you don't have control over that.
I'm working on a revamped version of my 3D graphics library [Veldrid](https://github.com/mellinoe/veldrid). It provides an abstraction layer over Direct3D, Vulkan, and OpenGL, letting you target a bunch of different systems using a single library. The new version has a bunch of features that I've wanted to add for a while, as well as a better redesigned API.
A lot of comments seem to be concerned about logging env variables. Whether you should be storing sensitive data in your env variables is subject to another post but if you have apps running on the client don't forget you can use the library to generate partial reports therefore excluding the env variables.
/r/outside
any plans to include WixToolSet designer like the one with setup project? 
My workplace doesn't official support VS2017 either, but I use it anyway. Of about 100 projects (a dozen solutions) there were two that didn't play nice with 2017. A quick .csproj update and they now all work on both platforms. 
Looks great!
If you’re working with .NET 4.5+ I generally view locking a last resort option. Lazy&lt;T&gt; is an exceptionally useful thread-safe way to perform one-time initializations. Combine Lazy with ConcurrentDictionary and you have a lightweight, thread-safe cache that can be lazily initialized. Curious, what are some common situations you’ve found locking necessary? If you need async locking, I’d suggest looking into SemaphoreSlim as well.
Is this supported for UWP apps?
Right, it's not perfect. This is from Process.cs in the most recent .net release. public string MainWindowTitle { get { if (mainWindowTitle == null) { IntPtr handle = MainWindowHandle; if (handle == (IntPtr)0) { mainWindowTitle = String.Empty; } else { int length = NativeMethods.GetWindowTextLength(new HandleRef(this, handle)) * 2; StringBuilder builder = new StringBuilder(length); NativeMethods.GetWindowText(new HandleRef(this, handle), builder, builder.Capacity); mainWindowTitle = builder.ToString(); } } return mainWindowTitle; } } It seems they increase max length to account for possible change and check for the handle to be valid, and thats really it. Not too much etc from what I can tell, but the first two points seem perfectly valid. 
So you have a budget constraint that is solved by sacrificing user experience?
&gt; You would not ordinarily implement any logic "in" (belonging to) a sum type Actually a great use case I've seen for them is when you need to perform actions based on state. Ex: You can add/update/delete users, but only delete if they are not an admin account. So you set up classes - `addUser` only has an `add` method, `modifyUser` has `update` and `delete` methods, `modifyAdmin` only has an `update` method. Then you set up union type of `user` containing `addUser`, `modifyUser`, and `modifyAdmin`. When your logic needs to perform an action it has to match to the correct type to do anything, so it would be impossible to add an existing user or delete an admin account.
Thanks for all the feedback! It was great to see many people liked it. We have got few voices opting for VS 2015 support. We are a small team and we all use the latest VS so it wasn't on our radar but we'll look into it.
How does this compare to OData? From the description there appears to be overlap.
What I'm really looking for is an Alive clone. Seems crazy to me that Microsoft acquired the talent but let the plugin die.
Reminds me of the Chrome Developer Tools
If you get a response stream (curResponse.GetResponseStream), the FTP server have responded with the asked for DirectoryListing. I would guess that you would get a CommandOK instead of LoggedInProceed in that instance. Maybe you confusion comes from forgetting that you are actually asking for list of files?
&gt; Maybe you confusion comes from forgetting that you are actually asking for list of files? Maybe. But I still get OpeningData as a result. I might want to change the question: Is it a proof of availability if I get no exception when calling curResponse.GetResponseStream? Or do I need to cover all failure results?
I think he is alluding at the fact there are no time outs. Your code could wait forever.
I think popcorn stays at the API level for subqueries with some parameters substitution based on data returned from the main call. OData works with a data DSL meaning external entities kind of need to know your schema. Sounds like they are well on their way to reinvent OData. Their implementation isn't as tied to linq/EF as Microsoft's OData lib is. Though, I think you could model your REST API as the OData schema and achieve a similar response. Just going to be some work to unravel the LINQ mess with built in OData stuff. 
There are no proofs of anything, unfortunately. You can try downloading a file, but that doesn't guarantee that it will still be there when you need it. I think that reading the DirectoryListing from the stream would be your best bet. If you can read that, everything should be just fine.
Setting the values as settings in the application are automatically include them in the code. The .config file can then overwrite the properties. Right click the project and choose properties and then choose settings on the left. If they do needed to be changed at a later date you just drop the .config and they are changed the next time the application starts up.
Can I somehow check if the DirectoryList has loaded?
It will contain a list of the files you can download. You can parse it and check that it looks sane. But just the fact that the stream is readable should do the trick. If there is a readable stream, there has been contact with the server.
Hey thanks for pointing out Odata - we're writing up a compare/contrast with graph and json-api right now, so we'll add it in. I think the short is that popcorn is (currently) simpler. If you're using a web API/mvc stack on .net, it's a drop-in upgrade to add filtering &amp; sorting. If you use entity framework, it'll take advantage of it, but it isn't required. It looks like restier is the closest comparison, being an actual .Net implementation of the OData standard. We'll have to check it out some more!
I hope we don't reinvent something! For us, Popcorn hits a sweet spot because we got some immediate benefits (using less data &amp; making less calls to the server) without having to radically redesign our server implementation or our client application. 
I'll be keeping an eye on this. I think our API might be heading this way. Thanks for contributing to the community!
Care to point out how one can get 2017 Pro (or above) edition legally if workplace won't buy it?
Seems this is another attempt at OData And Graphql. There’s already at least one C# implementation of graphql.
IMO the re-entrancy detection is broken because `CallContext` flows into child-threads which can run in parallel. Consider this (contrived) example: static async void Foo() { await asyncLock.DoWithLock(async () =&gt; { var t1 = HoldLockForever(); var t2 = HoldLockForever(); await Task.WhenAll(t1, t2); }); } static async Task HoldLockForever() { await asyncLock.DoWithLock(async () =&gt; { await Task.Delay(100).ConfigureAwait(false); Console.WriteLine("This should only happen once"); Thread.Sleep(-1); // access shared resource }); } Same thing will happen for more explicit parallel threads within a held lock like `Task.Run` and `Thread.Start`, but also other less obvious things that might implicitly involve the thread pool.
Anything involving shared resources in an async context, really. For example, in a current project I have various services that write events to a single web socket and need to synchronize access to that. This article uses `SemaphoreSlim`, but on its own it's not re-entrant, which the OP attempts to change.
Great! We're pretty actively developing on GitHub so drop us a note when you think you want to check it out and we'll give you the VIP service!
Great! We're developing pretty actively on GitHub so drop us a note when you want to try it out and we'll give you the VIP service!
Try adding in at the end the line: Console.ReadLine(); The program is exiting after reading the inputs since it has no reason to stay running. Adding the above line after printing the results will keep the program running waiting on the enter key to be pressed. Hope this helps. 
It's a command line app, right? If you're running it by hitting F5 in VS, the command line window is closed as soon as the program exits. You can either open a command line shell and run the exe directly, or you can add a prompt for input at the end to keep the app from exiting immediately after it's finished.
Add a Console.ReadKey(); to the end, that will wait for user input instead of immediately closing
works fine. the console window is probably closing before you see the results. put a Console.ReadKey(); at the end to see the output when you run the .exe or in visual studio, just run the program in debug mode.
It did, thank you!
Thank you, I did the latter, Console.Readline();! 
Thanks!
Thank you~
I think your project has great merit. I'm in the same situation with a built out API and adding an OData endpoint seems to have all the downsides you mentioned. There is always room to solve similar problems with different approaches. Keep up the good work.
You already have the answer at this point, but I would like to say that this is probably the first problem most of us encounter when running a console app from the IDE lol. You are in good company. :)
I introduce popcorn to myself fairly often.
Totally! We are putting together a comparison blog post right now on how we view some of the pros/cons of few different implementation options.
/r/bossfight
Unless it is for Audit data of file access and file transference locations as maybe required in the GDPR. Then it should be protected or encrypted. I keep all Audit data encrypted and only decrypt in a viewer after a password verification.
Not really sure why I’d use this over webpack
I once wrote some classes that used a base with this sort of constraint. Its not really inheritance, but the user profile class will have a static Get that returns the correct type without specifying the T again. This is some minimal code I sent myself when I had the initial idea. public class ProfileCore { private int myVar; public int MyProperty { get { return myVar; } set { myVar = value; } } } public class ProfileBase&lt;T&gt; : ProfileCore where T : ProfileBase&lt;T&gt; { public static T Get() { return null; } public static int GetInt() { return 1; } } public class UserProfile : ProfileBase&lt;UserProfile&gt; { //new public static int Get() //{ // return 1; //} } class Tester { public Tester() { UserProfile u = UserProfile.Get(); u.MyProperty = 1; } }
Even if it is encrypted, you are still transferring and storing this data. Encrypting and protecting does not except you from those laws.
What I've gathered thusfar, from your, and /u/AngularBeginner's comments, is that the concern exists when this information is logged to client servers, but more specifically when it's unprotected. Is this true? Using the user name as an example (I'll call it a "client account), I'm having a hard time understanding why, in a "cloud" product, it would be a problem logging what account caused a crash. The fact that account exists is already exposed by the infrastructure, or data contained within databases, etc. Hell, it might be exposed with the existance of Google results; or a reverse DNS, or AXFR DNS query. Your examples are fine and make sense, but can you point me to the laws that make this an issue? I'm not talking security here, and I'm not trying to be a pedant. I genuinely want to understand the issues.
In the event of a breach if the data is encrypted you still have to report the breach but if the data is encrypted no personal data is at risk. You can keep personal data for a given period provided you have a reason and the user gives their permission.
Yeah definitely this solution could be expanded to pass a timeout to SemaphoreSlim. Theoretically such time outs are not needed, but in practice yeah it's definitely a simple way to avoid deadlock that is the result of incorrect design.
The concern is that when you're collecting this information from *other people's* machines, especially Joe Average Consumer's desktop. Collecting any PII, even accidentally, without the user's proper consent, is a problem. "Proper consent" and what constitutes sensitive information varies wildly by jurisdiction and country. A cloud account on your own servers is no problem for environment variables, because any information leaked is your own information The article wasn't limited to cloud accounts. It was what "***every*** .NET App Should Be Logging at Startup". Applications distributed to end user / Joe Consumer computers should not blindly dump environment variables. An enterprise app can use the EULA / support contract to make it OK. Cloud apps or anything running on your own machines is no problem.
That's an awesome catch. I'm trying to consider solutions to this problem and am thinking about generating a sort of `CallContext` specific `SemaphoreSlim`. Each successive `DoWithLock` could produce a new `SemaphoreSlim` that children in its body can contend over. Alternatively maybe there isn't a good solution to this problem and we have to live with non-reentrant async locks.
&gt; When you combine these two, the way you have done, something interesting happens. The type `Outer&lt;T&gt;.Inner` is not the same type as `Outer&lt;T&gt;.Inner.Inner`. `Outer&lt;T&gt;.Inner` is a subclass of `Outer&lt;Outer&lt;T&gt;.Inner&gt;` while `Outer&lt;T&gt;.Inner.Inner` is a subclass of `Outer&lt;Outer&lt;Outer&lt;T&gt;.Inner&gt;.Inner&gt;`, which we established before as being different from `Outer&lt;T&gt;.Inner`. So `Outer&lt;T&gt;.Inner.Inner` and `Outer&lt;T&gt;.Inner` are referring to different types. https://i.imgflip.com/nl9dq.jpg
By the way `AsyncLocal&lt;T&gt;` should behave the same as `CallContext.LogicalSetData`, but is more convenient to use (and probably a bit faster).
Yeah I had to walk away from my computer and come back to make sure I wasn't having a stroke after reading that.
omg, this soo good, Android Studio always had a feature like this, and since then i was looking for similar in VS. Thanks!
no problem, also if you are learning C#, please use Visual Studio (its free) and learn a little bit about basic debugging - setting breakpoints, watches, etc. it will really help you learn.
Im sorry, I must have forgot my original comment lol Yeah, the algorithms are pretty separate from the UI...Hmm, maybe I can just port it to WPF or UWP pretty easily then. I didnt think of this, as long as casting from whatever Image object they have to Bitmap 24byteRGB format works well.
Got it, makes perfect sense. So, not quite every .NET app. ;)
Sounds like you just need to re-keybind lots of things. TBH I think VisualStudio 2017 has everything ReSharper was "good" for, because VisualStudio has gotten a shit ton of improvements since VS 2008 and VS 2010, which ReSharper was good for IMO ReSharper is only good for a few code suggestions - like "oh hey there might be a null reference here! use the `?` operator, etc
Glad it wasn't just me!!
My initial thought was "oh this is just like .upper or .lower in Python" but it just kept going and going and going. Like when you over explain something to the point of it not making any sense.
If you don't like it go and make your own IDE, with common sense keyboard shortcuts, and hookers! 
Sounds like you are just used to things working a certain way. I think VS2017 is brilliant and a pleasure to work with, but each to their own. I don't use resharper so perhaps I'm just happy with my rock while you are used to your sharpened flint. Either way in about 3 weeks of use you'll accustom yourself to it I'm sure.
 * Duplicate a line: [Duplicate Selection](https://marketplace.visualstudio.com /items?itemName=ctlajoie.DuplicateSelection) extension. * Toggle comments: [Toggle Comment](https://marketplace.visualstudio.com/items?itemName=munyabe.ToggleComment) extension. (This one I personally rebound to CTRL+K / CTRL+U, though now that I know about the extension, I might give it a go.) * Auto insert parenthesis: Could be because _in theory_ you can do more with a method than just invoke it. But regardless, there is an option at "Tools -&gt; Options -&gt; Text Editor -&gt; All Languages -&gt; Automatic brace completion", but that's only the closing parenthesis; you'd still have to type the opening one. * Ctrl+clicking: [Ctrl+Click Go To Definition](https://marketplace.visualstudio.com/items?itemName=VisualStudioProductTeam.CtrlClickGoToDefinition) extension. (this you do point out, figured I'd link to it.) Older versions (IIRC) are in the Productivity Power Tools extension (or other 3rd party extensions). * Mouse back button: I think this is bound to `View.NavigateBackwards` and `View.NavigateForwards`, but I could be wrong. It seems to do that for me; where is is misbehaving for you? * Class suggestions: Part of this is to (I assume) reduce clutter in the auto-complete. That said, if you do type the class, you can press `Ctrl+.` on it and it should suggest the appropriate `using` statement. (Most of the time all is needed is to type the class, then `Ctrl+.`, then `Enter`) But yeah, it might be nice to invoke or command the autocomplete to look at all types available in the solution, perhaps not unlike what you get with `Ctrl+,` I would say that developers should take a dive into the extensions that are available. There's definitely a lot to be added to the base vanilla Visual Studio IDE and there's rarely any reason to avoid using extensions, especially the free ones. That said, I wouldn't classify vanilla Visual Studio as "unusable" without extensions.
For duplicating a line you can highlight it and Ctrl+drag is where ever you want it and you get a duplicate while maintaining your clip board content. You can also setup/change keybindings for most of the other stuff. The defaults seem to suck. 
This is an awesome post, thank you 
I agree with these two: * Intellisense doesn't insert parenthesis - Whenever I choose a method that gets suggested, VS doesn't insert the parenthesis. Why not?! * Doesn't suggest classes if they're not already imported. I really miss them. But the with the rest... it's replaceable. 
Which version are you using? Visual Studio 2017 Version 15.4 has ctrl clicking (https://blogs.msdn.microsoft.com/visualstudio/2017/10/10/visual-studio-2017-version-15-4-released/), and ctrl+. has for some time even suggested Nuget packages with the class under the cursor as well as extension methods.
I think I just found the person that originally wrote our code base.
not sure exactly what your types are, but this is not valid: adminCreateUserRequest.DesiredDeliveryMediums = new[] { new { "EMAIL" }.ToList(); First you don't have an equal number of curly braces. And to my knowledge you can't do a ToList() on a curly brace.
I keep solution wide analysis turned off for performance (&gt;100 projects in the solution, SSD disk). I still get R# inline suggestions, and the colours in the scrollbar highlighting lines with suggestions. Before code review/check-in - I use R# -&gt; Inspect -&gt; 'Inspect This' to analyse each file. I also have SonarLint installed (because we have a SonarQube server). It uses more blocky scrollbar colouring so I can differentiate between R# and SonarLint issue lines. I'll keep R# installed, as long as solution wide is turned off.
Ctrl+d duplicates a line, if I'm not mistaken. Ctrl+Shift+L deletes a line.
I updated the implementation to solve the problem you pointed out, and also to use `AsyncLocal&lt;T&gt;` instead of `CallContext`. I really appreciate the time you spent to look over this code already and would definitely appreciate more feedback on the new method. I credited your Reddit user on the page but am happy to remove it or point it to your blog or something if you prefer.
My favourite part of the article is after that whole confusion where they go "Clear? Good!!"
The most useful R# feature for me is search. By class/method/property or full text. It works way faster than VS's and can find by substring and only capital letters.
jesus I thought 15.3 just came out like yesterday... some fast releasing here.
VS2015+ does the later. Even maybe 2012/2013
Use that Drone project to submit to the Department of Defense :) (they probably had this tech years ago, but one of my professors way back in college had a friend who was doing this kind of image detection for satellite images, and got picked up by the DoD for shittons of money)
On the contrary my friend, there is no sacrifice on user interface. This is a fully responsive mobile web app using JQuery, Bootstrap, and some awesome open source JQuery ecosystem tools.
Check out [Making ConcurrentDictionary GetOrAdd thread safe using Lazy](https://andrewlock.net/making-getoradd-on-concurrentdictionary-thread-safe-using-lazy/). Essentially, your ConcurrentDictionary contains a Lazy instead of the actual value. While ConcurrentDictionary.GetOrAdd is thread-safe by itself, this approach ensures that the ValueFactory is only called once for a given key. Very useful if that ValueFactory has side effects. I wrapped it in my own class, which is similar to [this LazyCache implementation](https://github.com/alastairtree/LazyCache). I was a bit worried of the Lazy overhead, but it's performed well in my testing. Way better than the ObjectCache it replaced, with a lighter code footprint to boot.
I'm trying to engage my son in experiments around fruit fly eradication: apple cider vinegar vs red wine vs white wine, with or without dish soap, with or without a cover. If we do it, it will be his first exposure to experimental design and a little statistics. The typical experimental outcome is a transparent cup containing a half inch of wine (etc) and some dozens of dead fruit flies. I would love to implement a methodology for *counting* the fruit flies -- e.g. take a photo and estimate the number by analyzing the photo. I have a decade of C# experience, but it's all business applications. I know squat about image processing. Can anyone get me started? I confess that I have not googled on the subject. Given the popularity of fruit flies in science, I wouldn't be that surprised if there's a FruitFlySharp library out there. ;)
It's post like this that I was hoping to find when I subscribed to this subreddit. Thank you!
but Silverlight and WCF were `future` at some point. I am not even considering .NET Core because I can't even access Oracle on it, and I imagine there are tons of libraries missing still 
Honestly I would store them completely separately. Having the type system very aware of the difference between an approved / validated foo and an unapproved/unvalidated foo is extremely valuable in preventing bugs relating to things accidentally by passing process.
You could look at the module source and see how they do it https://github.com/dfinke/ImportExcel
 &lt;ListView Margin="10" Name="UsersListView" ItemsSource="{Binding}"&gt; &lt;GridView&gt; &lt;GridViewColumn Header="Name" Width="120"&gt;&lt;/GridViewColumn&gt; &lt;/GridView&gt; &lt;/ListView&gt; This is actually adding the `GridView` to UsersListView's items. You probably meant to set the `ListView.View` property like this:
Thank you! That makes the list display without errors. My name column, however, does not have the correct names in it. How do I go about binding those?
You would use the `DisplayMemberBinding` property for that &lt;ListView Margin="10" Name="UsersListView" ItemsSource="{Binding}"&gt; &lt;ListView.View&gt; &lt;GridView&gt; &lt;GridViewColumn Header="Name" Width="120" DisplayMemberBinding= "{Binding Path=Name}"&gt;&lt;/GridViewColumn&gt; &lt;/GridView&gt; &lt;/ListView.View&gt; &lt;/ListView&gt; easy right? databinding is great :D [Here's a full example for defining a GridView view mode for a ListView control.](https://docs.microsoft.com/en-us/dotnet/framework/wpf/controls/how-to-display-listview-contents-by-using-a-gridview)
I've used the same thing in my own code. It's nice when you have multiple specialized classes within an interface and want the developer to be able to choose between using common operations or specialized ones (such as cross-platform stuff with additional unique features per-platform). void Main() { ICommon common = new Windows(); var cn = common.NewSelf(); // Another ICommon - can use crossplatform options cn.CommonOperation(); Windows win = new Windows(); var wn = win.NewSelf(); wn.OpenOutlook(); // Can use Windows-specific options Linux lnx = new Linux(); var ln = lnx.NewSelf(); ln.CompileKernel(); } public interface ICommon { bool CommonOperation(); ICommon NewSelf(); } public abstract class Common&lt;T&gt; : ICommon where T : Common&lt;T&gt;, new() { public bool CommonOperation() { return true; } ICommon ICommon.NewSelf() { return NewSelf(); } public T NewSelf() { return new T(); } } public class Windows : Common&lt;Windows&gt; { public void OpenOutlook() { // stuff } } public class Linux : Common&lt;Linux&gt; { public void CompileKernel() { // stuff } }
Going for captain obvious here but if latency is super important than UDP is THE way to go (with your own protocol on top). TCP waits to much and you might do better with redundancy. For example, instead of waiting for a confirmation on packet-received you send old/redundant data until the other end confirms it received something. Improving latency but increasing bandwidth. Just throwing this out, maybe not suitable for you.
That library actually reads pretty well!.. Not sure of your choice of word Should() though... It really doesn't sound very sure about itself. It's barely one step up from Maybe() and Perhaps() 
You can also take a look at the OpenXML format to write Excel documents without Excel being installed: https://msdn.microsoft.com/en-us/library/office/cc861607.aspx?f=255&amp;MSPPError=-2147217396 Nuget package: https://www.nuget.org/packages/DocumentFormat.OpenXml/
I’ve been using Rider myself for the last few months, and I think it’s much better than Visual Studio with or without ReSharper. 
Helpful for debugging, sure, but annoying for an actual program. 
Now, what’s the minimum of 100001, 100002, 100003, 100004, and 100005? ;)
Yeah, because you never need to work with legacy code..
And by .NET you mean “.NET Framework”. Stupid Microsoft naming. 
Except the whole page reloads when user switches the views?
On the last point (Class suggestions) I use this extension: https://marketplace.visualstudio.com/items?itemName=Dreamescaper.IntelliSenseExtender
It's probably okay to keep it in a legacy project until it gets removed completely from VS, but using a long-officially-deprecated system in new projects is probably a bad idea.
Gave up reading as page jumps around a lot while scrolling (on mobile).
Resharper does that fluidly, you don't have to press anything. 
This is great, thanks!
I couldn't think of any other response!! Even after reading it through several times, I don't think I *really get it!!
A tangential solution might be to relocate the web service you're calling, or extract the non communications related part and house a copy of that inside your calling service. My worry is that while you can make good gains swapping something verbose with something concise it only scales so far. You know your system, I don't, so is this a stop gap solution until the system needs to scale more? Another option might be caching the web service responses locally (appropriate for statics not dynamics obviously). Have a look at Akka.net remotes too. That's reasonably fast. They used to use their own socket server code but swapped it out for netty (?) as MS maintain a port of it. If Akka.Net is too much of a shift, perhaps look at how they use Netty. RabbitMQ is nice, lots of options for how reliable delivery is which affects performance. Might not be fast enough for you but it would be easy enough to code up a PoC. Try and slim your messages down too. Make sure you're not sending stuff you don't need. Compress them, avoid textual representations of data, etc. On message delivery, you mention not using reliable messaging which is great (not relying on it). Someone else talks about UDP, I'll expand on that architecturally and say you should do your best to avoid any case of "exactly once messaging". We describe UDP as unreliable because you can't rely on it, but in reality message loss is a relatively rare occurrence so it makes sense to move the handling of that into the client/server code and out of the communications code. I put it in quotes because it's a well defined concept and easy to google. Other tech, Tibco EMS and RV. RV is fast (udp again) EMS is reliable and still quite fast. Both are stupid expensive and have a steeper learning curve because it's so elitist. Don't touch MSMQ, that way only pain lies. Plain old WCF can be pretty fast when configured properly for the scenario. Some don't like it for its legacy feel and heavyweight features but it's still worth considering. I'll cap all that off with the disclaimer that I don't know what you consider low latency or what volume of traffic you expect or growth plans or network topology or a dozen other things. For some of the high speed algo trading stuff they won't use c# at all because of the overhead of GC (This is mitigated to some extent with the newer versions which give you more control over GC).
One thing you didn't get into is why the latency is causing an issue as what are the requirements that dictate lower latency to begin with. I put that out there because this could be anything from C# being the wrong technology to needing to scale the service better. Obviously those are two separate paths to find a solution. If it's not a scaling issue and you're not pounding the service, then I'm not sure that there are many good options other than working with TCP sockets directly. UDP might be an option, but it doesn't sound like you can deal with dropped packets. I think you'll be surprised that WCF or web API add a fair amount of overhead and working directly with the sockets will show some improvement even though it's still TCP. If it is a scaling issue, then I'd stand up a reverse proxy and see if you can balance the load across more instances of the service. Message queuing could help here, but not necessarily with the latency. ZeroMQ would probably be your most performant queuing option, but does require you to work at a far lower level. After all that, i don't think C# is the right solution, but you've got a long way to go before that's definitive.
In my suggested strategy the type system would be aware, because they would be separate concrete entity types each inheriting from an abstract type, mapped to concrete types based on the discriminator. But they would not be stored separately, so direct SQL queries would still need to be aware.
Are you running your api on top of IIS? That has a fair amount of overhead as well
Nice! Would also love it if it evaluated properties! :)
Sure, you could get your pocket book out and buy a personal copy so you can take advantage of new shit and be baller. Then, reevaluate life choices to decide if this company really is worth working for if that won't invest in employee productivity. ... Mostly joking I understand that purchase restrictions exist especially when new 2017 features don't necessarily impact any brown field application development you might be stuck in.
You should ask yourself whether you really need Excel, or if it's sufficient to simply export CSV. The latter is _way_ simpler.
Yep. OP should use int.MaxValue instead of 99999.
There doesn't appear to be a great framework for making server to server calls using UDP on .NET. Does everyone that uses UDP roll their own solution for each project? That seems tedious and like a waste of time for when the solution required is not unique. If you wanted to load balance that solution you would have to use a custom load balancer? How typical is DTSL support?
I may be misunderstanding the problem, but wouldn't it be simpler to make an ObservableCollection&lt;MySpecialObject&gt; where MySpecial object has an int and and object property? You can bind this to the grid like normal and then if you want to find your object by the special int identifier you just use a linq query in the ViewModel on your ObservableCollection&lt;MySpecialObject&gt; to get it. Let me know if I'm misunderstanding or need more info.
Haha bad prof is bad.
Use [EPPlus](https://www.nuget.org/packages/EPPlus/) and you can create Excel files and send the entire array of data to the worksheet. void CreateWorksheet(object[,] cellData) { using (var package = new ExcelPackage()) { var worksheet = package.Workbook.Worksheets.Add("[WorkbookName]"); worksheet.Cells = cellData; package.SaveAs(new FileInfo("[FilePath")); } }
TypeScript is pretty refreshing. Check it out if you haven't :).
Sorry, I might have been unclear in my post. By the int/object thing, I meant that the int would be the key in the dictionary, and the value the object. The key would be a unique ID that each object has. The actual data I’m interested in binding to is in the object. I wanted to use a dictionary so that I could just do something like if (ExampleDict.ContainsKey(ExampleKey) {...} instead of having to iterate over the entire collection to check if a key exists. That way, the time it takes to check for a key would be constant and not scale with the size of the collection. I’m not exactly an expert on C# and most of my experience comes from C++, would using a LINQ query be a better way of doing this? Thanks.
&gt; or extract the non communications related part and house a copy of that inside your calling service. Without getting into too many specific, that is what we have now for three solutions...an application that runs some common code which translates a request, fetches data from ElasticSearch, and then translates the response. The common code requires ~6gb of RAM and a much longer startup time. Since we have to call to our ElasticSearch instance anyways, we want to move the common code onto that server as a stand alone service since we are already eating a networking hop. &gt; Another option might be caching the web service responses locally (appropriate for statics not dynamics obviously). Its not applicable in this case, but in general we'd probably use Redis if we found the need to cache across multiple solutions. We already do a fair bit of caching on the web application and web api solutions. &gt; Plain old WCF can be pretty fast when configured properly for the scenario. We plan to use .net core on the side hosting the service, otherwise that would probably work well. I find the envelope framing of WCF to be kind of heavy, but at least it is a well known solution. &gt; I'll cap all that off with the disclaimer that I don't know what you consider low latency I should have specified low latency for serving web applications and web apis. We aren't doing 'algo tradingstuff'. Right now we can return results for this service down to the client in about 50ms (for fast internet connections). We want to move the backend portion of this service to another tier without going above ~60ms latency to serve requests down to the client. That sounds like foppish pre-optimization, but our testing has shown it has a noticeable affect on our sites UX when this service takes more than 100ms to call (we use it to load product data for search results, carts, and user defined lists. It needs to be fast). 
Playing devil's advocate here, but have you actually profiled the app? Throwing out "low latency server communication" then saying Web API is adding latency is what raised my eyebrow. Then your list of tech you've evaluated seems to hint you need to be making synchronous requests. My vote - profile your app, make sure that the Web API framework is what is adding "latency' to the requests. If you are requesting server requests and replies synchronously that makes me think you are doing some sort of DB or I/O work. That'll be your hotspot no matter what you've got on the frontend.
&gt; One thing you didn't get into is why the latency is causing an issue as what are the requirements that dictate lower latency to begin with. I was more interested in what other C# developers are doing 'in general' when they have the need for lower latency. But in general we don't need to scale the service better, we just want lower latency. &gt; I think you'll be surprised that WCF or web API add a fair amount of overhead and working directly with the sockets will show some improvement even though it's still TCP. My testing has shown this to me. The latency for the service I am working on through Web API was much higher than I expected. The primary culprits are Web API itself, and the JSON serialization it uses. I can improve the second, but the first one is still an issue. We don't want to use WCF directly because we would prefer to make this a .net core service. &gt; Message queuing could help here, but not necessarily with the latency. ZeroMQ would probably be your most performant queuing option, but does require you to work at a far lower level. I tried using NetMQ, but found the performance to be worse than I expected. It used a high amount of CPU as well for its poller. I don't think trying to marry NetMQ with asynchronous or multithreaded code is fun or productive, though I'll wager there are easy ways to make it high performance if you are willing to live with those restrictions.
Its still in planning, but it would be asp.net core running on .net core with kestrel. This would only be a backend service and wouldn't need to be hardened, so running on kestrel directly is fine.
The only one I can relate to is the first one about the clipboard, but I think that's more about having use for a clipboard history. I'm always wanting to have multiple things on my clipboard, and have a shared clipboard between devices, which is why I'm developing Clipboard Everywhere: https://api.clipboardeverywhere.com/ It's not launched yet, which is why the subdomain is not www, but if you want access to the beta then let me know and this may help you with part of it. It's not launched yet, it's still under development, and not yet available for purchase, but I think this is relevant so hopefully it's ok to post here.
We have profiled the timings, and adding an additional web api call adds more latency than we are comfortable with...it affects the UX of one of the solutions. That said, I was asking for more general experience other developers have had in the past. I have tried some things and want to hear what others have tried. I didn't post here to get a specific solution. I just want opinions and anecdotes.
I'm just going to spew out a few thoughts off the top of my head because I'm short on time, but I may come back and clean this post up later. If you went the ObservableCollection&lt;MySpecialObject&gt; route, you would be using ExampleDict.Where(mso =&gt; mso.id == theIdIWant).SingleOrDefault(); Regarding speed, the linq method would most likely be slower, unless there is lots of data in the grid. My initial thoughts are that grids usually have a high volume of data and dictionaries are meant for speed, not storage, so this seems like a mismatch for what you're looking for. Also, how would seemingly simple tasks like grid sort and filter behave with the dictionary implementation? It may work out of the box, it may not, but either way this could be more work for you to implement for what could be a negligible performance gain (at the end of the day you'd have to performance test with the amount of data you expect the grid to have on average). If you want to implement something like this is suspect a place to start would be making you ObservableDictionary class implement a variety of things such as INotifyPropertyChanged for the Key and Value properties, INotifyCollectionChanged, IDictionary&lt;TKey,TValue&gt;, IEnumerable&lt;KeyValuePair&lt;TKey,TValue&gt;&gt;, ICollection&lt;KeyValuePair&lt;TKey,TValue&gt;&gt; for starters. Hope my unorganized rambling helps.
Thank you for your reply, yea I dont know how to work with c# syntax. In python its just: DesiredDeliveryMediums=[ 'EMAIL', ] DesiredDeliveryMediums's type is a System.Collections.Generic.List&lt;System.String&gt; and I want to pass "Email" as a parameter. I tried making a list and adding email as a parameter I dont think its working
Windows Workflow (WF 4) is a true stateful workflow that can be database driven. You can implement your own or you can implement a full featured existing workflow. To specifically answer your question, just add a method on the base entity to get the derived concrete type (approved / pending) and call this method when you need it.
Not everything needs a framework. UDP is pretty straightforward. If you want low latency, then frameworks will just slow your down. You need to answer a bunch of questions though. 1. Is it okay to loose data? 2. Is it okay for data to arrive out of order? 3. Do you need to resend lost data? 4. What is the network topology of your machines?
Hey, thanks for letting us know. Do you mind if I ask what device / browser you are using? Seems to work fine on my s8 with chrome.
Here is the syntax you are looking for: UserAttributes = new List&lt;AttributeType&gt; { new AttributeType { Name = "preferred_username", Value = user.Username } } From: https://github.com/aws/aws-sdk-net/issues/761 
see, that's where the plot thickens. I just the default valuecontroller in the webapi stack - the old one, not the newer faster one. I'm getting about 10ms for the [simple ValueController](https://imgur.com/a/elzcN) which should show more or less the latency WebAPI is adding. When you say there are UX concerns due to the latency that leads me to believe we aren't talking milliseconds anymore. I'm not saying WebAPI is perfect (especially the non-Core version) by any sense of the imagination. I'm just suggesting you need to dial in your concerns a bit more. I'd say 99 out of 100 times when someone has issues with WebAPI being slow the concern has really been 1 or a combination of these things 1. They're using EntityFramework in a less than ideal way 2. Heavy SQL queries 3. Returning large amounts of JSON that is slow to serialize and transmit over the wire 
Design by convention.
Yeah, I have a semi-old phone so it could just be that, Samsung Galaxy Note 4, using Chrome.
Can't give you proper advice on this because you're more experienced than me. Though I doubt that many would jump to write their own stack; more a last resort.
Not entirely related, but I worked with programming servo motor earlier. We didn't have ordering issues since this was on RS485 or RS232, but we had significant packet loss issues. As I remember it what we did was we had a two-layer protocol. It was fairly simple. There was an outer segment protocol which dealt with packets, interleaving and error correction ([Reed-Solomon](https://en.wikipedia.org/wiki/Reed%E2%80%93Solomon_error_correction)) and an inner protocol that dealt application protocols. Basically, we had two protocols that the outer layer interleaved: our controller software's protocol and GDB. The GDB part was cool because it allowed us to debug (or update) the firmware by simply attaching GDB to a port the PC controller software was listening on (which was written in C#; it was a WPF application). The outer layer was also used to potentially resolve packet errors, or if all else failed, at least get it back on track. It worked fairly well and had a very low overhead. However on IP networks, you would have to deal with message ordering as well. We just had crippling noise levels when the power supply reached maximum capacity. This was on a circuit board the size of a small coin. This also taught me how incredibly sensitive to noise some USB controllers are :P
You are my hero. thank you!
&gt; I just profiled the default valuecontroller in the webapi stack - the old one, not the newer faster one. I'm getting about 10ms for the simple ValueController...3. Returning large amounts of JSON that is slow to serialize and transmit over the wire That matches what I was seeing when testing localhost, (and worse from a remote machine). The JSON serialization *is* slow for our object graph. Its the data we want, but serializing and deserializing it an additional time takes as long as the network time. I should profile the asp.net core running on .net core...if its substantially less latency then much of my original interest may be moot.
The reason I posted this is because I ran into the need for it and started wrapping up the WebSockets library into a client / server library that acts like web api but uses multiple WebSocket connections to handle sending and receiving with protobuf serialization and optional lz4net compression. I'd rather not build a library out if someone already has an existing useful solution that is easy to incorporate into a project.
That is quite a bit lower level that I would want to deal with on the web server side, but thanks for posting about your experience, that's interesting.
Assuming it has tasks and dependencies like Make, I actually recently developed an algorithm to support post-dependencies, if you're interested. Post-dependencies: They're like normal dependencies, but executed afterward. As an example, you could make a common clean up task that all build tasks must be followed by, without requiring it to be preceded by any particular build task.
I agree with you. I do low latency, real time risk management applications for investment banks. My team has done all sorts of esoteric techniques to reduce latency in standard network stacks. But we spent months optimizing our code else where in the server before doing any of that because 95% of the time latency in your server process is cause by something other than your network stack. Touching the disk is slow, talking to another service on another box is slow. Some serializers are significantly slower than others. Doing IEnumerable.Where(...) repeatedly is slower than indexing your data once into a Dictionary. There is a world of optimizations that need to be looked at before its worth investigating your network stack. 
If you think that the delay is caused by the JSON serialization, maybe you could try using protobuff instead: https://www.nuget.org/packages/WebApiContrib.Core.Formatter.Protobuf/ In certain scenarios that can give a significant performance boost: https://auth0.com/blog/beating-json-performance-with-protobuf/
1. No 2. Yes, but no processing will occur until a whole message is received 3. Yes, whole messages must be received 4. Client / Server. Not always on the same local network. Sometimes across site to site VPN.
On the subject of naming things, that's where Domain-Driven Design can help you feel more *right* about your naming. Regardless of if you have a formal "Domain Model" or not, it's beneficial to name things closely to how the domain experts speak to each other in human language, i.e. the Ubiquitous Language. That's not to say it's wrong to call things `Summary` or `Details`, but the Read Model is part of your domain - it is how the users get feedback about what's going on with the Domain Model. Anyway, nothing wrong with `SalesOrderHeader`, `SalesOrderDetails` etc. if the users think that way (the software can become assimilated into their Ubiquitous Language, e.g. an ERP they've used for years) but for other use cases it can help to fit more closely to them. Something else to check out: EventStorming. It's a powerful way to work with users to come up with names.
Try opening an issue on GitHub in the repos https://github.com/dotnet/roslyn -&gt; The official repo for Roslyn which provides open-source C# and Visual Basic compilers with rich code analysis APIs. https://github.com/dotnet/csharplang -&gt; The official repo for C# language design. This is where new C# language features are developed, adopted and specified.
You could use something with a binary protocol/serialization like protocol buffers + zmq
Don't worry about preoptimisation, it's an affliction of the ignorant (bit blunt I know). You sound reasonably experienced so planning for future capacity/maintaining current capacity should be in your roadmap. Someone mentioned protobuf, it's a good suggestion. I'd recommend akka.net again because it helps reason about distributed code as well as being quite quick. And if you do want to build a socket server, MS manage a port of Netty which is a solid Berkeley sockets API that deals with a lot of the crap you would otherwise have to learn how to do. It does sound like you're going to reach your scalability limits fairly soon. These are examples of vertical scalability rather than horizontal so it will only go so far. I'd put in a request for more server ram (unless you've hit the max for your hardware). It will be the cheapest short term fix as you can then bung another 6gig service locally. Then spend the saved time working out how to scale outwards. 
What is the size of your response data? If you're sending 3MB of data, JSON over a different protocol isn't going to fix much. Protobuf might work or you could write your own binary serializer over webAPI and keep a lot of your existing code. If you really want speed, though, as someone else mentioned you can't do much better than UDP. [This is a great guide](http://beej.us/guide/bgnet/output/html/multipage/index.html) - even though the examples are in C, the C# UDP wrapper is thin enough that the API is fairly similar.
At least the first issue sounds more like an error on his/her side (like permissions), but if not I think it's more of a framework bug and should go into https://github.com/dotnet/corefx And List.Sort most likely (github search not working great on mobile) should be implemented in https://github.com/dotnet/coreclr
What we have seen is that the serialization is fairly slow for JSON, but web api itself is fairly slow too. Maybe the latency is better with asp.net core on .net core with kestrel. I'm trying to get a feel for what approaches people have taken in the past. I'm open to critique to my mindset, but I'd rather hear more about general experiences other C# developers have had in this area.
Per your second issue, don't expect to see any changes. It is working as designed and documented. If you need a stable sort, you'll have to implement it yourself (or find a nuget package that does). https://msdn.microsoft.com/en-us/library/b0zbh7b6.aspx &gt; This method uses the Array.Sort method [...] This implementation performs an unstable sort; that is, if two elements are equal, their order might not be preserved.
Does UDP give you much benefit if you need reliable whole messages before you can process a reply? That guide looks interesting, I'll give it a look. Thanks!
The opinions I'm getting here are that serialization tends to be as big or a bigger issue than the network stack for many solutions.
^ this. If you bind your item list to a Grid (or something similar) anyways, you won't gain much from implementing an ObservableDictionary (you can look at implementations on stackoverflow though). Also as long as you don't plan on having more than a few hundred entries, performance shouldn't really be of concern.
Neither of those are C# related, those are issues with the base class library.
I hear you on this one. Let's just say I did not know/contemplate that it is going to be a nightmare and told someone it will be xlsx as a finished product. 
We are planning to use protobuf for the new backend service, it seemed the obvious choice. MessagePack and proprietary formats were also considered, but the protobuf-net library seemed mature and better supported.
&gt; those are issues with the base class library... of C#. Where else was I supposed to go, since Microsoft didn't offer any straightforward advice on how to submit feedback?
Thank you!
UDP probably isn't your friend. If you can't deal with dropped data or out of order data, then you will have to implement a protocol on top that allows for re-sending data, etc. At that point, you've pretty much re-written TCP. Instead, I would write a test app. Serialize your data to JSON as you would then send it across a raw TCP connection. Your protocol should basically be the length of your serialized, UTF-8 encoded string in binary followed by the byte array itself. Your client reads the first 4 or 8 bytes (you need to decided if you will be using a 32 bit Integer or 64 bit for the length) then read the bytes, then convert it back to a string. This is your best case scenario. Profile each stage of your process. Doing this will take about a day if you aren't very familiar with TCP.
This is when you write your own File.Move and List.Sort
&gt; At least the first issue sounds more like an error on his/her side (like permissions), but if not I think it's more of a framework bug and should go into https://github.com/dotnet/corefx It's documented by Microsoft &gt; This method works across disk volumes, and it does not throw an exception if the source and destination are the same. Note that if you attempt to replace a file by moving a file of the same name into that directory, you get an IOException. You cannot use the Move method to overwrite an existing file.
Of .NET, not of C#. I'm not just nitpicking for the hell of it here - it's just that if you are to have any hope of getting things looked at, you need to be sure you're in the right place. I don't know where it is, and honestly I wouldn't make any major bets on it getting fixed, either. My advice would be to work around those issues.
I need more numbers. 1. How long, from the client, is it taking to send the request then get the response. What is the round trip time. 2. On the server, how long does it take to do each of the following: deserialize the request, perform the business logic, serialize the response, send it back. I'm a C# developer. I do low latency work, but I do have web services too. From my experience, WebAPI and other frameworks don't add that much over head. If you have latency from the client perspective, it is likely else where in your system. 
Yeah, I tend to agree. Without a lot more information, these sound like questions for SO before reporting them as bugs.
&gt;I was more interested in what other C# developers are doing 'in general' when they have the need for lower latency. But in general we don't need to scale the service better, we just want lower latency. In general, C# is not a language that's generally described or used in situations where latency is a high priority. There are other languages, such as C, C++, Erlang, and others, that are more suited to this use case. If it's after the fact, then not much else will help other than hardware and faster networks. &gt;The latency for the service I am working on through Web API was much higher than I expected. The primary culprits are Web API itself, and the JSON serialization it uses. I can improve the second, but the first one is still an issue. I would build out a test of TCP sockets communicating via byte arrays. No web API, and about as minimal C# overhead as you could get. If that doesn't get you where you need to go, then either UDP or looking at another language would be the only other options. There are more tradeoffs with UDP vs TCP though and I wouldn't use it unless it was more of a "streaming" type of application. 
You can bind to any `IEnumerable`, but for change notifications you need something implementing `INotifyCollectionChanged`. I do not believe there is a dictionary implementing that in the framework, so you'd have to find a third-party implementation or write your own. This is just conjecture, but I suspect the main difficulty will be that even though it's not required, `INotifyCollectionChanged` works best when used with indexes, so the binding control can easily look up which rows need to be updated. Items in dictionaries/hash tables don't have stable indexes, however. So either you have a performant key lookup in the dictionary but slow databinding, or the other way around. Another solution might be to do write a collection that maintains both an internal list and a dictionary so both means of access are possible, but then you'd still need to write code to reliably keep the two collections in sync.
They're both working as described in the documentation. I just think that they're bad design decisions, especially since the Windows command line *does* let you overwrite files.
Isn’t file move ultimately a win32 call?
I think consistently is important. That way you can build up a predictable pattern about how these objects are being used in your code. I see you aren't over lapping any of the data in the models. This points to clear different uses. I would maybe may the MyEntityMicroSummary just MyEntity, as this model defines the entity with the ID. How I image using a query model is that it would return all the attributes of the model and then I could select what I wanted (thinking in an Entity Framework and Linq manner). var data = entity.GetByID(0).Select(x =&gt; new { i x.d, x.title, x.data1, x.data2}); Now I have data which is just what I want for my view or what ever, it could be just the ID, the whole object or anything in between. By using some lazy loading you could reduce calls to your data source. If it doesn't need to be high performance then you can just return the full object each time. 
Can you not just do something like this? var destPath = "path:\\to\\your\\dest.file"; var sourcePath = "path:\\to\\your\\source.file"; if (File.Exists(destPath)) { File.Delete(destPath); } File.Move(sourcePath,destPath);
Sounds like u need Aggregate function from Linq
Not by itself. If you need reliability, you will have to implement it yourself. Basically, you would use UDP rewrite the parts of TCP that you need (which will speed things up a lot because you can leave a lot of TCP out). For your purposes, I would suggest adding three bytes to each UDP message you send: 1. Session byte. Each user gets a unique session (up to 255), this allows the backend to multiplex requests on a single port, identifying them by the session byte. 2. Total number of messages. Assuming you know beforehand how much data you are sending, calculate the total number of messages so the backend knows when the message is complete.* 3. A sequence number (assuming you can send all your data in ~255 packets or fewer). This allows the backend to put the data in the correct order and, when combined with the total number, identify when the whole message for a user has been received. After those three bytes, send the portion of actual data corresponding to that sequence number. Your backend will need to send a response acknowledging *each* sequence number, otherwise after a short time your user should begin re-sending sequences that it had sent before until that sequence id is acknowledged. \* there are other options, like sending the total size once and waiting for an acknowledge from the server (may add some latency) or sending a final message with a specific pattern + a sequence number one greater than the final part of the data (backend will not know how much data it needs to store until it receives this packet). Depends on how complex you want to build it.
Technically, but it'd be more difficult, because I'm encountering this problem through Cake.
&gt; As for List.Sort, writing a sorting algorithm is pretty easy to find on google. Yeah, I've done it before. I actually beat LINQ's sorting algorithm in benchmarking. Still annoying, though.
Hmm, OK, I've no experience in Cake, in fact never heard about it until I just did a cursory Google for it, but it seems you should still be able to do similar: [FileExists](https://cakebuild.net/api/Cake.Common.IO/FileAliases/747870D2) [DeleteFile](https://cakebuild.net/api/Cake.Common.IO/FileAliases/9E01B1BD) Apologies if I'm way off the mark with that!
1. Depends on how you count latency, but from request to reply from the browser to the server I think the latency was about 80ms on average, if I pick one example endpoint. 2. I don't have those numbers right now, but they would be the first thing I would check before attempting any implementation on the change we are considering / planning. I think when I checked months ago the mix was something like 30% serialization, 20% networking, 50% business logic or other backend services, which is fine for us. If we added another Web API hop in the middle, then serialization and networking became greater than the business logic in overall latency. The obvious solution would be to look at serialization first (moving to protobuf from JSON seems like a no brainer), but I wanted to know about networking options. Shaving off 50% of the networking latency while reducing the serialization work would mostly pay for the extra network hop, but I'm not sure if going from a web api framing to persistent TCP connection, UDP, NetMQ, or some other networking approach would allow me to expect reducing the networking time by half.
cmd.exe is not using the CLR to implement **move**. Historically, Microsoft doesn't make changes to the CLR that you're asking for. They will only add new methods, and then only if there is a compelling case for it. Previously written code may be taking advantage of the current implementation. For example, there might be code out there wanting to do a nondestructive File.Move, and catches **IOException** if the file exists.
At some level, I'm sure it'd have to be. It seems logical for the framework to do more than just pipe the calls through in a lot of cases, though.
Don't say that in an interview. Linq is slow
Possible an alternative, IEnumerable&lt;T&gt;.OrderBy performs a stable sort: https://msdn.microsoft.com/en-us/library/bb534966.aspx
Again, technically, but they also (quite reasonably) use their MoveFile method to implement MoveFile**s**, so if any file in the glob already exists, the entire method throws an exception.
Then... implement your own method that mimics the example I gave above, but loops through a list of files! There is always a workaround :)
If I understand your numbers correctly, the client is seeing, on average, 80ms round trip. That means in 80 ms the following happens 1. Timing starts 2. HTTP Request is serialized 3. serialized request is sent over TCP connection to web server 4. Web server deserializes request and routes it to the correct handler 5. handler deserializers payload from JSON 6. handler invokes business logic 7. handler serializes result to JSON 8. HTTP response is serialized 9. Web server sends response over TCP back to client 10. Client deserializes HTTP response 11. JSON payload is deserialized 12. Timing ends. 1 through 12 takes 80 ms on average, but only only 16 ms is spent in steps 2,3,4,8,9,10. the ping time between the client and server will tell you approximately how much time is spend in steps 3 and 9, i.e. network latency. for my corporate network, I see about .2 ms between VMs running on the same host. I see up to 20 ms between my desktop and server. Changing your framework will only affect steps 4 and 8 and honestly and I'd bet you are only spending 2 or 3 ms in those steps. That doesn't really give you much wiggle room for improvement. having a faster serialization and a more efficient serialization (smaller message) will have a much large impact on your latency than improving 2 or 3 ms to 1 or 2 ms. 
Thanks, that's good advice on naming things and it's been a while since I've looked at DDD so i'll definately have to check out EventStorming. Although I use this naming strategy on most projects, the one I'm using it on at the moment is a CMS where the apis are consumed by developers and so has to be fairly generalist (on the query side at least) without bloating out models to try and fit every use-case. When looking at the naming of entities themselves I think we need to look to other popular CMS products as inevitably this is where the ubiquitous language will come from.
I just checked it is, I don’t know from my experience there are a lot of times that’s all they do. Lol 
Or say: I often write my own methods for certain functions if the performance of existing methods is lacking. Always put a positive spin on things.
The problem with 'fixing' this seemingly braindead design decision is that somewhere someone is working with code that relies on this behavior. It would be one thing if the functionality was different than what was described in the docs, but changing a function so widely implemented as File.Move() because you wanted to pretty up the design of the library... that's just narcissistic. We've all run into weird issues like this. Mine was Random.Next(int minValue, int maxValue) will return values between minValue and (maxValue -1). Was I annoyed when I realized my mistake? Absolutely. Did I think the design was awful? Absolutely. But it was my mistake, it was my responsibility to read the docs for the libraries I'm using. 
You are wrong, each instance of readline would be independent, So Delete the console.readline that you currently have, copy in your saved variable version. make sure to declare those variables though. Then write the line to test it.
&gt; write a collection that maintains both an internal list and a dictionary I'm pretty sure that I've done that in the past. It's a right pain in the ass to fully unit test, but you've got to do it because it's so easy to make a mistake.
Is there any issue keeping the collection as an ObservableCollection, and then whenever you need validation, call *ToDictionary(o =&gt; o.Id)*?
File.Copy also accepts an additional flag that allows you to specify overwrite behavior. That seems like a better argument than what the command line does.
These servers are not on the same VM host. They are on different subnets in the same data center. We have an endpoint on our Web API that does nothing but echo back the current Date Time. It looks like it takes ~8ms for that call on average if we call it from one of our other servers in a similar networking configuration. Isn't ping based on IP packets (without TCP). Wouldn't you pay the cost equivilent of a ping several times to transfer data using TCP? E.g. at least for the syn/synack, and again for the fin/finack?
ZeroMQ
Hey! Also saw your feathub vote. I think that needs some more discussion. Could you maybe join the gitter channel sometimes? Or ping me on skype: ithrowexceptions
Ping will give you an idea of network latency. Literally the absolute fastest time it would take a packet to go between hosts. If your ping is 8ms then that means 50% of communication related latency is outside of your control. So 8ms of your 16ms WebAPI latency is in the NICs, switches, routers, etc. 8ms latency in WebAPI is pretty good. Maybe you can shave a millisecond or 2 switching frameworks, or rolling your own protocol over UDP, but it won't be a big win.
Are you using NetMQ, or are you using a wrapper around ZeroMQ?
Hence my suggestion to use a binary serializer rather than json or some other format. Obviously it's very specific to your use case and no amount of suggestions will compare to just profiling different scenarios.
Each `Console.ReadLine()` call blocks until the user actually writes a line, so yes, the results of repeatedly calling this method can be different granted the user inputs different things. The first problem that you need to solve, is that the `ReadLine` method returns a `string`. This is normal since the user can type anything. So you would have to do something like string wageInput = Console.ReadLine(); and then you need to parse it as an integer with something like int wage = int.Parse(wageInput); // as per your request, but I would suggest using decimal instead Note that this can fail if the user didn't enter a valid number, so you might look into using `int.TryParse`.
Stop procrastinating. Just read a book, have it on your phone if needs be, it really doesn't matter. Any book even remotely linked to programming.. or just do anything other than finding spurious reasons not to do anything. Reading and programming is difficult without two monitors? Pah! Suck it up and get on with it. #programmingishard
Packets sent over an active TCP connection from two servers in the environment in question take less than 1ms to get a response. I have tested that part.
While what infamusfiend has said is true in essence, there is still going to be an issue if you just do: int wage=Console.ReadLine(); Since Console.ReadLine() returns a string, you can't just plop it into an int. First, he'll have to parse it. To do this, there are two options: Int32.Parse() and Int32.TryParse(). I will discuss both. First we have Int32.Parse(). This method takes a string and returns an int. For instance: string s="76"; int i=Int32.Parse(s); At the end of this code, i will have the value 76. Awesome. But there's going to be a problem when I make a small change: string s="7s"; int i=Int32.Parse(s); Now what? The input cannot be parsed into a string, so an exception will be thrown. And your program will crash. This is where Int32.TryParse comes in. This returns a boolean (ie true or false), which tells you if the parsing succeeded. So if you did: string s="76"; int i; bool success=Int32.TryParse(s, out i); Then i will contain the value 76 and success xill be true. Similarly: string s="76s"; int i; bool success=Int32.TryParse(s, out i); Will set success to false and i to 0. This can be useful in order to force people to enter a correct value: int wage; bool success=Int32.TryParse(Console.ReadLine(),out wage); while (!success) { Console.WriteLine("An error has occurred. Enter the wage again."); success = Int32.TryParse(Console.ReadLine(),out wage); } And then do something similar for taxes. Also, please note that in your variable names you can't use spaces. So int social tax Won't work. Use socialTax, social_tax or whatever else is handy (I'm going to get flak foe this since naming conventions can be a hotly contested topic, but don't use spaces is the essence). Another thing I'd like to talk about is your usage of int. An int represents an integer, so if your wage is 300.76, there's going to be an issue. The same applies for the tax rate. There are also going to be other side effects. For instance: int wage=512; int tax=30; // taxes in percent int net=wage\*(100-tax)/100; You expect net to be 358.4 (=512\*0.7), but in reality, it's going to be 358 (I believe). So perhaps an int isn't the best choice, maybe a double is what you need? Double also has the Parse and TryParse functions, just replace Int32 with double.
I did it like this (Note, each questions are in Latvian, but the 1st one is wage, 2nd one is social tax and so on and on). Works perfectly and exactly how I wanted it to. Console.WriteLine("Cik liela ir Bruto alga? (Alga uz papīra)"); int brutoAlga = int.Parse(Console.ReadLine()); Console.WriteLine("Cik procentu liels ir sociālais nodoklis? (ievadiet skaitli bez procentu zīmes)"); int sociālaisNodoklisProcentos = int.Parse(Console.ReadLine()); Console.WriteLine("cik liels ir neapliekamais daudzums?"); int neapliekamaisDaudzums = int.Parse(Console.ReadLine()); Console.WriteLine("Cik liels ir apgādāto atlikums?"); int apgādātoAtlikums = int.Parse(Console.ReadLine()); Console.WriteLine("Cik daudz ir apgādāto?"); int apgādātoDadzums = int.Parse(Console.ReadLine()); Console.WriteLine("Cik procentu liels ir iedzīvotāju ienākumu nodoklis? (ievadiet skaitli bez procentu zīmes)"); int iedzīvotājuIenākumuNodoklisProcenti = int.Parse(Console.ReadLine()); 
I change the int to decimal in every line of code I had before (in comments below somewhere) : decimal brutoAlga = decimal.Parse(Console.ReadLine()); yet when I type in 960.46, for example, it still tells me that an unexpected problem has arrised. wasn't the decimal supposed to fix this issue?
After a minute of Googling, I found this ObservableConcurrentDictionary implementation published by Microsoft: https://code.msdn.microsoft.com/windowsdesktop/Samples-for-Parallel-b4b76364/sourcecode?fileId=44488&amp;pathId=197768125 
Careful with parse, as the user could still type anything. Use tryparse instead. decimal wage = 0; if(decimal.TryParse(wageInput, out wage)) Console.WriteLine($"{wage.ToString()}"); else Console.WriteLine($"{wageInput} is not a valid decimal"); 
To be fair exclusive and inclusive limits are fucked up in nearly every framework in at least some functions, but yeah I guess there is no hope of them fixing File.Move because it's been in .NET forever in this way (an exception would be nice but also a breaking change).
&gt;Thinking about it, in some cases having the upper limit exclusive can even make things more convenient var randItem = list[Random.Next(0, list.length)] for example. Yep, that was the conclusion I came to as well, that simply dropping a 0-indexed property into the maxValue field was the reason this function was designed as it was.
Well actually im not in c# for that project, but i can at least say the python side of things is pretty good (sorry, didnt see the sub name)
This is pretty cool, I've shared it with some of my co-workers and they all liked it. It would be awesome if there was a way to toggle it on and off though.
Have you looked at DotNetty?
No. Is that the netty port that Microsoft created? If so, that sounds interesting. I know ElasticSearch uses or used to use Netty, and it always seemed to have great latency.
You need to change your variable types if you want to use decimal / double values. decimal wage = decimal.Parse(Console.ReadLine()) 850.62 is not an integer (whole number, no decimal points) so int.Parse() will not work here. You need to identify the type of data you're asking for input and then use the appropriate type. For example, if you're asking for a wage, that's currency. Currency usually has two decimal points so you'll need to use a type that can hold that. See: https://docs.microsoft.com/en-us/dotnet/csharp/tour-of-csharp/types-and-variables 
it expects a comma as a decimal sign
I might have a few thousand entries at most in theory, but as long as checking if an item is in the database doesn’t take an unreasonable amount of time then it shouldn’t be a huge deal. Could I run into any problems like this with ObservableCollection?
Thanks! We're working on [v5](https://github.com/fluentassertions/fluentassertions/releases). It seems most assertion frameworks use "should" rather than "must. I'm not sure how to explain it, but to me "must" is like giving an order and an assertion can't give orders only verify intentions. Maybe or Perhaps can't be used as it needs to be a verb to form a readable sentence. 
Avalonia
Excuse the late reply, we actually had a meeting about the architecture today, so I am a lot more clued up than I was. The macro files themselves are fairly flexible. We have a proscribed file structure that has an Execute method, what gets passed in and returned is up to the macro developer. The file itself can contain any valid class / method really, but the macro runner will be looking for the Execute method. In the macro file the dev will have access to our API methods. When the macro is triggered (via other processes/automation in our interface etc), it goes through our internal systems and the session is generated, which is required to use any of our API endpoints. When the dev submits the macro through our portal, we throw it out to a compiler and see what sticks. We restrict access to a lot of libraries, given that this passed through our servers at some point in it's journey. Assuming it compiles OK, it will be available to run, barring a couple of other hurdles to do with our developer/customer interactions. When the macro is triggered, we package it up and send it off to amazon lambda. Dev/customer are then charged for run time. Hope this was useful! 
Whats that saying? There are 2 hard problems in computer science cache invalidation, naming things and off-by-1 errors. n.b. I use a lot of fluent in setting up test cases and structuring the domain, it reads a lot better.
Honestly, there just isn't one yet. There are few GUI libraries that work on Core at all, and most of those are still experimental/alpha versions. Avalonia seems like the most promising one right now, but it's explicitly still in alpha. 
I just watched a couple of videos of him, buying the book as well. Thanks!
Thanks. Probably TDD won't happen on this team, but it's an interesting concept for sure.
Interesting, thanks!
Early in 2018, Xamarin Forms will be released for WPF, MacOS, and Linux. 
Unfortunately it's not up to me to make the development cycle decisions. I just have to play along. As of right now, I have to write Unit Tests for some API calls (a few GETs, PUTs, POSTs, and DELETEs). My biggest doubt so far is... what to test? Just that method is working? Since all I did until now is manual testing, my first instinct is try to make it fail, which may be exactly the opposite of what I should be doing now. Oh well, a long road ahead and lots to learn! Thanks for the suggestions!
QtSharp can be coded with only C# and .net: https://github.com/ddobrev/QtSharp I used it for my last 3 programs and it works great.
wxWidgets https://www.wxwidgets.org/
It's a rather crude implementation of `INotifyCollectionChanged`, as it just issues a reset notification for the entire collection when a single item is changed. I don't think it's possible to do much better in a concurrent scenario, but unless concurrency is required that seems like a big price to pay.
There are also mixed solutions, for example dotNetify, using MVVM pattern, ViewModel in the backend, and Views in the frontend.
there are no gui frameworks slated for official .net core development; the current focus is on web with asp.net core. once they get all of that in a good place, they said they'll probably take a look at developing a desktop gui framework, but yeah. we're probably not going to see anything going on there for quite some time. as others have said, there are some third-party projects in the works, but all are in extremely early stages.
I understand that, C# is just a fantastic language and my whole team has finally started moving towards it over C++. Everything we need is in Core except for GUI development and I'm trying to get some applications running in Linux so we can stop paying out extra money for Windows volume licensing. I suppose I wouldn't be opposed to running the main program logic as a daemon (is that possible with Core?) and writing an entirely separate GUI program to stimulate it and display data. SPAs like React or something would be alright too, I just have never been very fond of web development. 
Maybe look at xamarin stuff. I think they just added MacOS UI support and windows is in the works I believe and I also think they xamarin forms is going to work with .net core as well.
Innnnteresting. I hadn't considered approaching this from a "FaaS wrapper" perspective. Thanks for the insight and inspiration. 
i don't think shoehorning something is really what you'd want to do. but take a look at what you're making. most desktop apps these days really have no need to be desktop apps. a lot would actually benefit from being web apps, especially if you're talking about enterprise stuff. you could run core console apps as daemons (i think they fixed support for system signals). but yeah, sounds like you'd be making your app way more complex for next to no benefit. if your app would benefit from being a web app, you could just make a restful web service using asp.net core and then send http requests from whatever front-end client you want. granted your client would still have some logic in it, but all interaction with a database or something could be handled via c# code that way.
Electron
I read this as "Is Visual Studio borderline unusable with ReSharper?" and was about to comment "fuck yea it is!" ReSharper, at this point, is largely a resource hog that provides no-to-little advantage over Visual Studio itself.
Electron might be an unpopular opinion in programming subreddits, but it's a fast way to get a cross-platform GUI application to production and when you use TypeScript (which is for the most parts similar enough to c#) it's actually not a bad experience from a developers perspective.
&gt; No foreign key properties on model Maybe I'm wrong but what about using the ForeignKey attrib? 
I was looking to get some experience with dotnet core, so I started working on an online game using Unity3D as a client. The game server is written in dotnet core, ported Lidgren so I could use that. Currently working on an Admin site where you can see the game world in 2D, for admin &amp; debugging purposes . The backend is made using ASP.net core with signalR (Browser -&gt; SignalR / ASP.net core -&gt; Game server). The frontend is a simple Vue.js site with SVG.js for drawing the map. The projects are automatically build with a CI pipeline in my Gitlab server. The documentation (Mkdocs) is also automatically build &amp; deployed to a nightly environment hosted in Azure. Still looking for ideas how to deploy the application itself. Thinking about using Docker compose to get it all running on my own server. It should look something like this: * 1+ Game servers * 1+ Game server DBs (holding state per Game server) * 1 authentication server * 1 authentication server db (holding character &amp; login information) * 1 admin site I'm also looking for ways to do some proper logging. This should include text based logging and statistics (Exceptions per x-time, totals players connected, total disconnects, etc). Anyone has some advice? Some pictures: * [Admin site, login page](https://i.imgur.com/5UloOtq.png) * [Admin site, list of active maps on server](https://i.imgur.com/9YEmjqp.png) * [Admin site, map detail view](https://i.imgur.com/TKtvior.jpg) * [Game, very early stages](https://i.imgur.com/q6CALCt.png) Doing this all while travelling South &amp; Central America for 5 months! 
You could try this - I've been meaning to give it a shot: https://github.com/ElectronNET/Electron.NET
I've been learning from this book - http://adaptiveart.eecs.umich.edu/2011/wp-content/uploads/2011/09/The-pocket-handbook-of-image-processing-algorithms-in-C.pdf Although Im tempted to buy a book on actual image processing, but they are like 200$ or so 
University of Michigan, my alma mater! I'll check it out, thanks!
Write your Electron app in C# using Bridge.NET and Retyped. https://blog.bridge.net/widgetoko-a-node-js-and-electron-application-written-in-c-1a2be480e4f9 Works awesome and Electron has a lot of momentum behind it right now with various teams working on performance optimizations and enhancements.
Another more flexible and powerful option for writing a C# based Electron app is [Bridge](https://blog.bridge.net/widgetoko-a-node-js-and-electron-application-written-in-c-1a2be480e4f9).
Sounds very interesting! I've heard of Bridge.Net before but always thought of it more as a concept/experiment, but for a more controlled environment like Electron it might actually be a really good fid.
[Here's an extension with plenty of refactorings and analysers.](https://github.com/JosefPihrt/Roslynator)
I'd advise against developing for future specs. If windows is a requirement and "Windows is in the works" for Xamarin then you shouldn't pick Xamarin as a dependency for your project. 
They will be releasing a new minor every 6 weeks according to the [Release Rhythm page](https://www.visualstudio.com/en-us/productinfo/vs2017-release-rhythm)!
true. worth checking out at least.
It depends what you're doing, but if the front end is basically just needs to display fields and let the user submit forms, you pretty easily can make a browser GUI. You can pretty much totally guarantee your app will work everywhere then, since if you have to you can set up a server. There is of course some overhead to doing this, and it also presents some fun security consideration, but .Net core is basically designed to be used this way so there's excellent library support.
Pipe the csv into power shell and export-excel in the background? 
Use NAudio: https://github.com/naudio/NAudio/blob/master/Docs/PlayAudioFileConsoleApp.md
Try out `SourceCache&lt;TObject, TKey&gt;` from https://github.com/RolandPheasant/DynamicData. I had a good experience using it for something similar.
We're nearing a beta.
As someone who's pretty out of the loop when it comes to desktop frontends what happened to WPF? 
It's still around. However, OP is asking about desktop UI frameworks for .NET *Core*, not .NET *Framework*. Core doesn't support WPF and has no official desktop UI frameworks yet.
Xamarin.Mac has been around for a few years at this point. You could also look into Xamarin.Forms which does support Windows and macOS I believe. 
Source for this?
What makes Bridge *more* powerful and flexible than Electron.NET? As far as I can tell, Bridge only supports the limited set of features that have been ported over to Javascript while Electron.NET supports *anything* Core supports, given that it's running a Core webserver underneath.
[Gtk3-Sharp-Core](https://github.com/ASoftTech/Gtk3-Sharp-Core)
There's. Net for electron. Electron itself is pretty solid. 
See the roadmap here: https://forums.xamarin.com/discussion/85747/xamarin-forms-feature-roadmap/p1 Work is being done to target macOS, WPF for Windows, and GTK# for Linux.
Yep, it is pretty solid in taking all the RAM and CPU available.
This is how Rider works I believe. A back end in .net and front end in Java.
 decimal input; Console.WriteLine("Enter a decimal:"); while (!decimal.TryParse(Console.ReadLine(), out input)) Console.WriteLine($"{input} is not a valid decimal\n\nEnter a decimal:"); Console.WriteLine($"{input} is a valid decimal");
You could use mono for now. They have GtkSharp http://www.mono-project.com/docs/gui/gtksharp/ It works on Mac and Linux, I have done small apps and seems ok. Of course, if you are planning on doing a big app you should wait for something more official. 
Why not a web app? 
Not supported in .Net Core
It remained windows-only.
I won't doubt that at all. 
there are some great answers already but i'll just provide one extra comment about duplicate line overriding your clipboard. Is what's on your clipboard generally something you copied in VS? if so, are you familiar with the "clipboard ring"? it's built in, and been there forever, basically in Visual Studio you can use Ctrl + Shift + V to cycle through the things you previously pasted from your clipboard. It will of course now solve all the problems of the world, but it's a pretty handy feature, and definitely worth using consistently.
Good overall. But you have a confusing text command prompt. You should drop &gt;/home/liam - since a beginner is going to struggle to understand what that is about. Just show the commands to type. And perhaps have the usual "$" prompt in the extended examples.
Nice!
Great point. Will do that now. 
That's awesome!
It should be disclosed that the author is marketing his own build system. 
So a while ago, as a hobby and then later as an attempt to start a business, I made an Excel plugin for using SQL in Excel. I've now added the capability to use C# in Excel, using Roslyn. Sort of like Linqpad in Excel. This lets it work with Excel tables, fiddle with formatting, and automate stuff. Some of the practical applications: - processing data in Excel (LINQ) - getting data from various sources into Excel (REST, databases, files, active directory, whatever) - building interactive dashboards - building prototypes applications (you write logic in C# and use Excel as the UI and data storage) Here's the [introduction](http://querystorm.com/documentation.html). There's also a [short video](https://vimeo.com/242216594) for a brief intro. I charge for the plugin but it's freemium. If you don't want intellisense, error squigglies and so on, you don't need a license. So... what do you think?
I admit I only glanced at the article, but hasn't Excel had support for C# since Office 2010 or so?
That and all I gleaned from this adv...article, was ":)".
Yeah, and what about TeamCity or Jenkins? 
my thought the whole time except I was thinking about VSTS build and release which at this point is simply amazing.
They are CI solutions, not build systems. Completely different things.
I agree that msbuild is a total abomination. It's not even, as far as .msbuild (.csproj etc.) files go, a real build system. It can only build one assembly. At the same time it manages to be incredibly verbose, especially in the back end. Trying to understand what it actually does behind the scenes...
Not sure you need to implement IProgress&amp;lt;T&amp;gt; yourself, there is a concrete implementation provided by the framework https://docs.microsoft.com/en-us/dotnet/api/system.progress-1?view=netframework-4.7.1. You would just register the events to process your UI update. 
I saw this requires Visual Studio, is that absolutely necessary? I like developing on the platform I'm going to run in, in this case I'm trying to get to Linux.
That's a neat idea! I'll try it out later today.
100%. But they put a nice, warm, gooey interface between yourself and the xml configuration required, for msbuild anyway, that the author complains about.
Use \\ to escape the character, so your code would look like this: string _two = "\\"WSO-000000\""
Thanks! Let me know how you like it
How can I do that to the below line instead: string _three = string.Format("{0}"+"{1}", _one,_two); I tried the below and it doesnt work: string _three = string.Format("{0}"+"\"{1}\"", _one,_two);
String.Format have a character limt?
AFAIK, it doesn't.
&gt;But they put a nice, warm, gooey interface between yourself and the xml configuration required Not familiar with doing that, so I couldn't say. Normally, CI solutions just trigger whatever build system the repository is using, typically a batch or powershell script that either directly performs the build process or bootstraps and launches another executable (such as Nuke, Fake, Cake, etc.) to do so. Regardless, chances are you'll want to be able to version the build process as well, which you wouldn't be able to do if it just exists as configuration on a CI server. By having a build script in the repository, you get the build process fully vesioned along with the project, and you have the ability to just run the build script locally to build setups, packages, etc. quickly.
How does it "not work"? Seems fine to me. Also, if you're building SQL, perhaps you should use single quotes/apostrophes instead for wrapping strings/values. Also, maybe look into using SqlCommands with parameters instead (http://csharp-station.com/Tutorial/AdoDotNet/Lesson06) to avoid SQL injection and simply just make your life easier.
Yes, I also thought that, but the OP said it. Looked into the Referencesource of mscorlib, but doesn't find anything (other than a cached StringBuilder is used for length &lt;= 360). http://referencesource.microsoft.com/#mscorlib/system/string.cs,2972
&gt; AFAIK When I put my actual SQL string all in one string.format it gave me an error saying i have exceeded the 128 character limit
Could be a limit in the SQL query, not the `String.Format` call. Your code, when I run it, I get: string _one = "SELECT * FROM [dbo].[Test] WHERE [Test] ="; string _two = "WSO-000000"; string _three = string.Format("{0}"+"\"{1}\"", _one,_two); Console.WriteLine(_three); And it outputs: &gt; SELECT * FROM [dbo].[Test] WHERE [Test] ="WSO-000000" So the problem may be in the way you're feeding that string into your SQL provider.
Easiest way would be like this: string _three = string.Format("{0}\"{1}\"", _one, _two); or with string interpolation: string _three = $"{_one}\"{_two}\"";
TeamCity and Jenkins are build servers, not build systems. At least that's my definition. Will try to make this more clear. About the "advertisement". It's rather not the intent to do advertisement here, but rather to explain my journey through using different systems, and what I thought was wrong with them. But anyway, will try to put this in TLDR as well.
Not of the above gives quotes :(
I am following everything your saying. Look at my image below. https://imgur.com/a/AV7z8 I am feeling the string like this command.CommandText = _three; 
This is very cool. I'm impressed with the auto complete and code editing area. It is indeed kind of like a LINQPad in Excel. Are the scripts saved into the xlsx file somehow? For example, can I have someone else install QueryStorm and send them an xlsx file that contains some C# scripts they can run?
Where are the quotes? When I run this code: string _one = "SELECT * FROM [dbo].[Test] WHERE [Test] ="; string _two = "WSO-000000"; string _three = string.Format("{0}"+"\"{1}\"", _one,_two); Console.WriteLine(_three); // SELECT * FROM [dbo].[Test] WHERE [Test] ="WSO-000000" SqlCommand command = new SqlCommand(); command.CommandText = _three; I get no errors. That said, I'm not executing the command either.
Yes, they both do. Perhaps the issue is how you're displaying/validating the text string.
Part of the TL;DR now.
Try this one then: string _three = $"{_one}'{_two}'"
It's a matter of how complex your build can be. Some arguments that speak for a build system are: - Fast feedback cycle - Execute locally - No CI server lock-in You can still (and should) use a CI server.
Well, MSBuild can still compile multiple solutions, for different platforms, etc... what you usually end up doing, is to invoke a nested MSBuild... I've seen stuff like that, and it's painful :/
Agree, my good mood is a little distracting.. removed that. Thx!
Hey, thanks! To answer your questions (yes to all three): - Yes, scripts are saved into the workbook (xlsx files have a place for this sort of thing called "custom xml parts"). - Yes, if you save a csx into the workbook, and send the workbook to someone else who has QueryStorm installed, they will see your script and will be able to run it manually or automatically (if you set up automation) - Yes, there's an automation feature, and you can set up many kinds of triggers, e.g. cell changed, activex button clicked, timer... When you get a chance, you can check out the two videos, I show how it works there.
Definitely not trying to bash, but I got to the end of the article feeling like it was spin for your system. If it had been presented up front, I don't think I would have felt that way. In any case, thanks for the reply. 
I've accomplished the same thing by versioning my Team City build configs. Not an out of the box solution by any means, but accomplished the same goal. 
[dood](https://imgur.com/oVyYav9) think about us with our 1386xsomething resolutions D:
["Let us redefine progress to mean that just because we can do a thing it does not necessarily follow that we must do that thing." ](http://vignette4.wikia.nocookie.net/startrek/images/e/e6/KhitomerConference.jpg)
Yeah, sorry about that:) Give it a reload, I've removed disqus side panel temporarily.
I am curious what tasks you were doing in your build that were so challenging? We have a TFS build server and just use the built in build templates with a powershell script that runs after completion. This script moves some configs, deploys an EXE outside of the build output, creates release notes (from Trello cards, using markdown, LaTex, and pandox) and emails that out to interested parties (internal). Granted it did take me a while to get this all working how I needed it; but that was due more to having to actually do work and not just automate my builds!
Thanks!
Looks real nice. A question about performances: I guess it's compiled on the fly by Roslyn; is it so for each execution of the script? If so, would it be possible to maybe cache the compiled CLR for further executions? I don't have much knowledge about C# compilation process, maybe it's silly.
No worries. It's okay, that's why I edited the article. I got so many questions like "why another one?" that I felt like being forced to write something like that. But I also didn't want to make a direct comparison, because that's even more biased. Anyway, thanks gor the comment!
It's a good question. Performance shouldn't really be a problem. Roslyn takes about ~15ms to compile a script. Even for hundreds of lines of code, it still takes roughly the same amount so it shouldn't be an issue. If the script was called in a loop, than definitely it would make sense to cache it, but I can only think of one use case where it would be in a loop: I enabled calling into C# from QueryStorm's SQLite engine, so user defined functions can be defined via C# and called from SQL.
&gt; So... what do you think? Insanely cool. 
I believe it's only required for the visual XAML editor. You can write it all manually since it's just XML. This isn't a huge loss because most of the time you'll be writing the XML anyway, even with the editor.
What about looping through hundreds of sheets?
This is impressive, I am excited to try it out. I have a couple of questions, if you don't mind. 1. I see it "integrates with databases" - is this done through the existing "External Data Connections" feature of Excel (used for pivot tables, etc) or something custom for your plugin? 2. In the demo video you typed the cell "P3" to insert the datetime. Do you have a "range picker" that would let me select a range in the excel document and automatically populate the script with its range (sort of like when creating native charts in Excel)?
Totally depends. The reasons why I prefer to not only instrument a build server, is because it implies very long feedback cycles. Also, during debugging you're occupying that particular machine. And third, you're coupling yourself to the particular vendor. I still need build servers for the CI experience, and other infrastructure, but it's almost 100% the same experience as if you would execute the build locally.
Yeah, the pricing needs more work as does the website in general (documentation, license management for customers, examples...). I made a note of your comment in my todo list. For now, I'll answer here: - Hm, I'd say a sole proprietorship qualifies for the individual license, but I'll have to figure out how to word this. - Renewal hasn't yet been an issue, but I agree, this needs to be explicit up front. To me it seems 50% of the full price is reasonable. - Monthly subscription might be a good idea. It would make it easier to try out, and also to opt in an out as necessary. I'll think about this. Thanks for the thoughtful comment! 
True. It's so much memorization though, and having the visual editor is super helpful. I'm not a great GUI developer haha
With proper marketing, you got a serious business on your hands.
You mean if each sheet has a trigger that calls the same script at roughly the same time? I haven't tried it, but I see your point. It would be pretty easy to save the IL at the moment of embedding the script into the workbook. If the script compile times turns out to be an issue, this would definitely be a good way to fix it, and pretty elegant. Thanks for the comment, I'm adding this to my notes!
We're working on a new previewer. We had to get a lot of infrastructure in place to get started on it. /u/kekekeks is developing it.
Versioning your team city build configs? One of my big problems is how much team city is driven by the GUI (and it is very difficult to manage this way). Are you using a better way?
Glad to answer. 1. It has it's own connections to external databases. These allow for a two way flow of data. When connecting, the excel tables that you select get copied as temp tables into the target database. You can import them into permanent tables from there, or combine their data with data from permanent tables in your queries. The query preprocessor allows using cell values as parameters. The editor also offers all the advanced features when writing queries, and you can easily get results from queries into Excel, rather than just tables and views. 2. No "range picker" yet, but it would make sense to include it, not so much for the editor, but definitely for the QuickQueries feature. Do let me know if you have any questions or suggestions when you try it out, please.
Thanks, I hope so... Hopefully I make good business decisions or at least partner up well with someone who does:)
&gt;I was told my many people and many users on reddit that C# isn't that great of a language (compared to Java or other OOP) I like Reddit but it is INCREDIBLY liberal to the point of being borderline communist at times. One side effect of that is a general distaste for large corporations, and you don't really get any larger than Microsoft. With that out of the way, I wrote some stuff in Java to solve a problem we were having at work. It worked nicely but was rejected because you couldn't work on the code in Visual Studio. So I huffed and puffed and learned C# (this was NOT a good place to use C++) and lo and behold... I loved C#. It's better than Java in every measurable way. I won't get into the details because if you already know Java and start learning C#, you'll start seeing why it's better very quickly.
Just use ASP.Net Core and your choice if front end (Razor, or an SPA frontend)
Curious to know what professions require a person to know both Excel and .NET. I'm guessing it could be an investment banking role at tiny shop where your primary duty is financial analysis with spreadsheets but necessitates you doing development work as a secondary function.
Well in business, Excel is all over the place. For one thing, it helps being able to deal with it easily when Excel files come your way. On the flipside, business people tend to interact with data through Excel so it's a good medium to send data their way. If IT can use C# in Excel (and automate Excel workbooks with it) it means happier IT guys and better flow of data to business guys. That's my theory at least.
You can use the built-in InputBox as a range picker. It has it's limitations, but it works in a pinch. // xlApp - whatever reference you have to the Excel Application // "Default: address" is optional var selection = xlApp.InputBox(Prompt: prompt, Title: title, Default: address, Type: 8) as Excel.Range;
This is so cool. I'm curious, what did you use for this add in. And do you have any learning resources?
If you are constructing a SQL query, why not use SQL command parameters. Its really not safe to construct SQL queries like this!
Thanks! Oh, I used a bunch of stuff. For the C# engine, I used Roslyn to analyze and compile the user's code. The text editor is AvalonEdit. The plugin is an Excel VSTO addin. For learning Roslyn I user Josh Varty's blog, RoslynPad by Aelij and the Roslyn github page. The links are at the end of the document that this thread refers to. I plan on writing about the development soon. If I do write something up, I can send you a link when it's out, if you want? 
Hm, it looks like just the thing I need! I gave it a quick and dirty try just now, it seems to be giving me the value of the cell rather than the range object, even though I'm passing 8 as the type parameter. I'll have to play around with it some more. Thanks for the suggestion.
This is aching to be parameterized.
teach me!
&gt; I suppose I wouldn't be opposed to running the main program logic as a daemon (is that possible with Core?) and writing an entirely separate GUI program in something like Java to stimulate it and display data. If that's all you're up to then you could use something like [curses](https://maxwolf.github.io/WolfCurses/) to get the job done.
Well I'd be perfectly happy with a command line interface if I was the only person using this stuff, and curses would be fine if I was distributing to other people and needed something a little more interactive, but this is stuff that will ultimately end up in the hands of people who are not "computer people." It will need to be a full blown GUI, and Windows is cheap enough that I'm not really THAT concerned with paying the volume licensing fees. I'll stay on Windows and use WPF before I go that route. But Linux offers me a lot in the industrial setting that I'm not getting from Windows, so eventually I would like to extract logic from .NET Framework to put in Core and run on Linux machines. I'll just wait for now.
&gt; It will need to be a full blown GUI Alas we can't all be making stuff in an industrial setting where "Tough. Get used to it," is an acceptable substitute for a user manual. :)
FYI, whatever URL it's using to validate the trial key is blocked by my work. Is there a way to test it out without that connection?
I only work on one project that absolutely needs a GUI, and that's what customers directly interact with as the front end to the whole system for controlling our machines. The rest of it could honestly run in the background and log its activity and no one would ever know the difference except us developers. But my boss, while good at what he does (or has been doing), is unfortunately incompetent as a modern programmer because he refuses to learn anything he doesn't already know. He's afraid of C# because he doesn't trust garbage collectors even though his code is full of memory leaks, and I almost quit over trying to get the company to use VS 2017 when he thought upgrading from pre-Visual Studio C++ to VS2012 was the best plan. This is the guy that *requires* everything to have a GUI, because he simply does not know how to use a command line for anything except ping.
My edit includes a simple example.
It's trying to reach my licensing server (keystodian). I had planned an option for offline licensing via email, but I never got around to doing it. If you're up for it, maybe we can give it a try on Monday over email (antonio at querystorm.com), with a few manual steps on your end (dropping a file into a folder)? 
I vaguely remember having that problem, and I think (in my case) it had to do with the Default value and the variable declaration. * Default: The documentation states that it can be a Range object or an range address string. I looked up some of my old code, and it passed a string. Again, Default can be omitted. * Declaration: The InputBox return type is `dynamic`, so I explicitly declared my variable as `Excel.Range` instead of `var` as I did above. (I'm not actually sure if the declaration affects how a dynamic call is returned, but just to be safe...) InputBox is ugly and won't let you select a range on another worksheet, so I ended writing my own RefEdit that sinked the SheetActivate and SheetSelectionChange events.
Sure thing, I'll drop you an email. Thanks!
I would make whatever changes I needed to make in the UI and commit the config xml file. I had a method devised for a trigger system to automatically commit the changes at the end of a sprint, etc, but left that job before I got the chance. 
Business people use excel for everything. Currently I'm working at a job where Excel is used for almost the entire time sheet processing system. When all you have is a hammer everything looks like a nail.
What configuration xml file? I just want to use the gui less. 
This is incredible work!
I forget exactly how to get to it, but there's a way to interact with it via xml. 
That would be awesome. I wanted to look into VSOT for a while, but I was not certain that it is possible to extend the UI and functionality that far.
I love this! ...I'm buying a license out of sheer appreciation for the effort! Great work! 
&gt; This is incredible work! Thanks a lot!
Hey thanks a lot, I really appreciate that!!
I do back end development mostly in .NET, and I'm constantly tasked with creating reports anytime there is some new analysis that is needed. So medium sided businesses I expect there are lots of people who have overlapping responsibilities where this would be useful. I'm going to give it a try.
Any reason why you want the _percent_ difference between binary files? Are you planning on patching _portions_ of the binary files rather than just outright replacing them?
Due to legal issues with Bethesda, the files cannot be replaced as that would mean the files would be available for download. The only way to distribute the mod is to patch the files into the modded ones. And the only way I could figure out how to patch one file to another, without the patch essentially being the new file itself, is to get the most similar file and patch that. 
take a look at [octodiff](https://github.com/OctopusDeploy/Octodiff) its a variant of the RDiff algorithm (you can use that one as well, or if you don't want to wait many minutes per file, maybe "FastSync" which is quite a bit faster). this will allow you to create signature files, patch files, and do the actual patching using source file + patch file. it will also give you something better than just a difference in %. It will give you the actual binary deltas: The patch files it creates are binary (obviously), but they are not hard to understand (if you're a programmer), and they tell you what to "take over" from the source file, and what new information to write.
Oh, there's a fuzzy hashing algorithm that does exactly that. It was designed to detect illegal images that have been slightly altered (Google is known to use it against email attachments in GMail). I want to say there was even a dotNet library, because I was looking into it for a project. Although, this was years ago, can't remember the algorithm name.
You're telling me it doesn't do that already with Intellisense?
Unfortunately, that looks too complicated for my level. I would have to iterate through every file, save each individual delta output, load every delta into memory, and somehow convert the list of instructions to a percentage difference. Octodiff looks very cool, as it uses instructions for the patcher rather than sheer raw data, but it's too low level for my experience.
Google'd, and found this: https://github.com/s3curitybug/similarity-uniform-fuzzy-hash That actually sounds exactly like what I'm looking for, but from what I've read in the Github, it's only usable for images. I'll fire the dev a message, see if it's actually got a broader use.
Thanks so much for posting something like this. While we're on the topic, DAE James McCaffrey's ["Test Run" column](https://msdn.microsoft.com/en-us/magazine/mt149362?author=james+mccaffrey) in MSDN mag is like...the best thing evar?! I love reading the articles and piecing together my own implementations based on whatever ML/AI/stats concept he's demo-ing and the code snippets, then I compare my code against his. Totes informative, occasionally useful, and way fun maaan.
What is the "difference" between to binary files for you? If you have a file where every single byte is different, what's the percentage? If you have a file where every single byte is the same, but it has 900 additional 'a' bytes, what's the percentage?
`SwaggerResponse`?
Visual Studio Code is written to target it. Despite all the circle jerking in the programming sub about Electron being heavy, the user experience in VS Code has been excellent.
My guess is that Microsoft will try to hire you in 3, 2, ... Awesome work! I think is the best thing I have seen in a long time. Excel hasn’t really evolved that much during the last 10 years, that’s why I think Microsoft will give you a call, seriously. I have been creating a few addins the last weeks, With this one I could just had written a few linq queries and that’s all... for me the best part is that your intellisense is better than working with excel from Visual Studio.
It doesn’t.
This is the solution. Ignore everything else said on this thread. You should be using parameters. Or even better stored procedures. 
The indexoutofrangeexcpetion is due to no rows in the table. Not due to the value or format of the string representing the total. 
A few of those objects implement IDisposable if I recall correctly. You should put them in a using block if they do. Just press F12 on them and see if they 'inherit' IDisposable or if any of the classes they inherit do. 
Honestly. I don’t know what to do with this information 
Heh, my job pays for resharper for me and I don't use it. I tried it and it was infuriating how much it guess I wanted to do and did its own way that I got rid of it. I posted some of my problems in the forum first but no one replied to fix them so I just uninstalled. 
That's what I thought. Not sure why op didn't look through the keyboard shortcuts window before posting. 
You know you can ctrl+shift+v to cycle through your clipboard history in VS?
I'm not sure why you'd want to "ctrl+click" to go to definition either. I don't want to have to click *anything*! Ctrl+f12 does just fine. Also ctrl+k+c and ctrl+k+u are very easy to remember. After using vs for a while these commands become second nature. Though I do love reshaper I worked for years without it and never really had an issue with vs.
Yeah, I certainly don't want a toggle comment/uncomment. Suppose you had one line commented and one uncommented, andd you highlighted them both and used the toggle comment, what should it do? Toggle them? Comment both? Comment neither? Do nothing? I prefer the explicit comment or uncomment bindings. I don't want VS to guess I want it to be easy to tell it what to do but resharper feels like VS guessing what I want instead of following instructions. 
Thats when you do a readkey(true) with an appropriate "press the any key to continue" message.
To say nothing of that one butterfly
Also: ditch old school ASP.NET for anything else asap
No, when you have Excel, everything IS a nail!
TC has [support](https://confluence.jetbrains.com/display/TCD10/Storing+Project+Settings+in+Version+Control) for this built-in (for certain VCS types)
If a class implements IDisposable, that means that when using it, it will create something that the C# garbage collector won't know to clean up automatically. Fortunately, all classes that do this are forced by IDisposable to have a simple method called .Dispose() which will clean up whatever it needs to, so just call that when you're done if you're using a class that has it. The thing is, what if your code fails before it reaches the point where .Dispose() is called? You could use a try catch, but they're ugly and a code smell. C# comes to our rescue again, with the using block. Simple wrap each of your objects in a using block and .Dispose() will 99% of the time be called for you.* Example: using (StreamReader outFile = new StreamReader(outputFile.OpenRead())) using (StreamReader expFile = new StreamReader(expectedFile.OpenRead())) { ///... } * 99% of the time because it isn't called for a small number of exceptions like out of memory or stack overflow. Also won't be called if there is a power cut while executing the using block code, for obvious reasons. In these cases you have bigger problems than memory leaks etc.
I'd suggest thinking about this as a priority. Anything that won't operate through a corporate firewall, or requires manual proxy configuration wouldn't fly in my organisation (financial) Nice work btw. It's a good solution well articulated.
you can directly edit the files in the server's data directory, it's /config/projects or something
I did not know that. I'm not developing my app specifically for VS though, I'm developing it so my clipboard is shared between all my applications and devices.
We've got some progress on integrating our new previewer with [AvalonStudio](https://github.com/VitalElement/AvalonStudio), here the video of what's currently working on XAML-support development branch: https://www.youtube.com/watch?v=htXsM8APW_A We expect AvalonStudio to be released this winter. I'm also currently working on VSCode extension, which is a bit troublesome because, well, it's electron, HTML and javascript, out-of-process plugin and the lack of the access to project system information (I basically have to load solution and run MSBuild manually). I hope to release a preview version of the extension soon-ish though, most of the infrastructure work is done. No news for Rider support, unfortunately, they still haven't released a proper SDK.
How exactly does that work? As in why does the functions all work but as soon as I add the WHERE clause, it gives the error. And this was part of a School assignment but I've seen far more MVC information floating around as opposed to .NET, something that I'll definitely look into once we're done with .net / if we move to MVC. I'll look into SILVR ASP.NET Lifecycle as well, thanks. 
Mvc is still .net If you're confused about why its failing, break it down i to individual lines. var rows = view.Table.Rows; var thisRow = rows[0]; var inventoryValue = thisRow["TotalInventory"]; var invertoryValString = inventoryValue.ToString(); var intVal = int.Parse(inventoryValString): This will let you set a breakpoint and see exactly what everything contains and why its failing. maxQuantity = int.Parse(view.Table.Rows[0]["TotalInventory"].ToString());
Great, you made the least maintainable code you could have done.
This feels more aggressive then I'd prefer but I want a book that covers everything as reference, something off the computer. I'm already learning basics of C# from a course that I do lessons from daily.
I would also be interested in it, if you don't mind :)
https://www.w3resource.com/csharp-exercises/
Not sure why you're being downvoted. Good for you for taking the initiative to fill in the gaps in your knowledge. There are lots of basic C# tutorials on the web that you've probably already found, so the benefit of asking here is getting ideas you wouldn't necessarily know to Google. For example, have you used GitHub? Browsing the C# projects there would be a great way to learn. You can look at people's code without even downloading anything, and then if you want you can clone it to your computer and play around with it. A fairly simple project that you could get started with is [Soltys.CaseChange](https://github.com/soltys/Soltys.ChangeCase), which lets you change the case of strings. Like, say you have a spreadsheet with a bunch of headers like "First Name", "Last Name", etc. CaseChange lets you instantly convert them into other case formats, like snake ("first_name"), camel ("firstName"), etc.
You could take a butcher's at the [C# Programming Yellow Book](http://www.csharpcourse.com/).
Including VS in the title is not at all necessary. 
The Rows[0] is giving you problems. You have to check if there are any rows first. If there aren't, then then when your code tries to pull a non-existent row at position 0, an index-out-of-range exception is thrown. if(view.Table.Rows.Count &gt; 0){ maxQuantity = int.Parse(view.Table.Rows[0]["TotalInventory"].ToString()); }
Have u debugged and looked at the values? Is that what u expected?
Oh god, I hope you don’t use all those vars in production code. 
Two off-topics tips: 1) You can shorten your float initialization: public float weight = 0f; (no need for the .0 since you already say f) 2) You call GameObject.Find("WorldInformation") each frame. Assuming the GameObject "WorldInformation" is not being destroyed and reconstructed very often, this is a wasteful call. You probably want to have a private variable for that class which holds that object and just assign it once in Start(). If WorldInformation is being destroyed and reconstructed, and if there should only be max *one* instance of that object at any time, you could use the [Singleton pattern](https://en.wikipedia.org/wiki/Singleton_pattern). As for your main question, I don't know. What types and values do the variables *weight* and *maxWeight* have in line 33 and 34?
Is `maxWeight` being assigned a value of `0` in the Unity inspector?
Dividing zero by something? Have you tried a weight value greater than zero?
Okay after I debugged the values it seems maxWeight is 0.. I'm not sure what caused this. Since I don't mention maxWeight till the actual problem.
First of all. Thanks for the tips. the float temperature is being changed quite often. So that's why I put it into the update function. And for the actual problem. maxWeight is 0 at line 33 and 34.. Not sure how because I don't mention maxWeight till those lines. So it makes sense it states NaN now because 0/0 doesn't really work that well.. x)
0/165 = 0 which is supposed to be that way. Because it should only make the thirst/healthDecrease bigger when you are actually carrying something. I printed hungerDecrease and thirstDecrease. And they both display NaN
I see only one line where a value is assigned to maxWeight: Line 8 assigns 150f. If it turns out to be 0f later on I guess there are other lines which change the value of maxWeight which we don't see. You can do Debug.Log(maxWeight); in Start() and Update() to see if it is correctly initialized to 150f and when the change to 0f happens if you cannot manually find the line which sets maxWeight to 0f.
Figured it out.. Unity wasn't reading the variables for some reason. So after a quick restart it did it's magic. Sorry for wasting your time looking into this..
Get in the habit of protecting any division. This is a "correctness" vs. "efficiency" argument, but it would've caught this. In not-game code, where we want robustness and not performance, we might: if (maxWeight == 0.0) { throw new YourGameException("maxWeight should not be zero."); } In code more worried about performance, we might instead: Debug.Assert(maxWeight != 0.0, "maxWeight should not be zero."); That won't compile into release code so it doesn't impact release performance. You could also consider writing functions like this to always fudge it, if for some reason maxWeight can reasonably be a zero value: thirstDecrease = maxWeight == 0.0f ? 2.0f : (weight / maxWeight) + 2.0f; Some people gripe about the teeny performance cost, but it is what it is. If 0.0 can be a valid value for maxWeight, you have to work around "? / 0 is always NaN". 
&gt; the float temperature is being changed quite often Oh, that's no problem. You have one object WorldInformation. This object has variables, one of them being WorldInformation.temperature. But no matter how often you change that variable, the object (it's ID and references to that object and so on) stay the same. I mean, GameObject.Find() only *finds* that object, it does not construct or change it. If you found it once, there is no need to find it again. Unless, of course, you destroy and reconstruct it somewhere else. But even then, calling Find() each frame might not be the best choice. Maybe [this page](http://carlosschults.net/en/value-reference-types-in-csharp/) helps in understanding reference types. The example is in the middle of that page, the "person" object.
Ohh wow. I didn't know this. That actually helps alot. Thanks.
No worries, you're welcome.
Thats. Really weird, actually. I was just working in a cshtml file and it was doing exactly that with Intellisense. Do you have Intellisense turned on?
parameterisation helps avoid sql injection attacks. Something to be very aware of as it could make your database extremely vulnerable to malicious attacks. Give sql injection a quick google.
Not at all:) Will dm you once I have something ready
Haha right. People, use var only when the type is clearly identified on the right please.
Noted. I don't know how big of an issue it is, but finding out seems to be more work than actually solving the problem:) 
That would be pretty cool. I actually passed on a job offer from them to work on this:) The position was unrelated to this, but I wanted to give this a shot. Really glad you find the plugin useful, and thanks for saying so!
Thanks for the tips. Will definetly implement that into my code. I'm quite new to C# (previously did PHP) and am trying to get all the help I can get :).
I wrote a free C# tutorial. PM if interested.
Be wary of offering a solution where the user enters their proxy details and credentials. This is a nono for most of us as the credentials are our network credentials :/ Hope it works out though, and do a blog post on how you solve the proxy issue to save us figuring it out ;) 
How can i check it? :)
Run the debugger and verify that the various width/height values you're feeding into the bitmap are the expected values.
These are pretty good names. I’ve also used -ListItem as a suffix, instead of -Summary, 
Make a calculator app.
OK, ran it and I am getting what I expect in the Width and Height all the way through. 361x468.
So I started messing around with the Stretch property and it is def moving things around. I think that is the issue. Uniform to Fill makes it the correct size, but moves it way out of its canvas etc etc. I will play with that value. Thanks! 
OK, so it was def an issue with the Stretch, I set it to Uniform Fill and the image is the correct size on the canvas. However now it takes the position of the canvas and moves it to the center of the screen. Is there a way to lock the position?
This is a very exciting project. It would be easier to use/groom with some work on the readme.md Thank you!
Yes this a great resource for nailing the building blocks. I keep coming back to this and doing them when I feel I need a refresh.
A while(true) loop accessing server resources is also called a DOS attack. Not to mention issues you will have with local resources (CPU) For now use a inteval timer. Quartz. NET Makes a good framework. As your needs grow you can look in to responding to email as they arrive using the push notification framework of (Imap idle) https://stackoverflow.com/questions/7358322/notify-c-sharp-client-when-smtp-server-receive-a-new-email 
Head First C# is a great practical guide too. Plenty of programs in there to build.
There is a pretty wide gap between repeating something as often as possible and doing it every three minutes. Why not every minute? Or every 30 seconds or whatever? Anyway, since you're using IMAP you probably don't need to constantly poll for new messages. The "proper" way to do this is using the IMAP IDLE feature to maintain a persistent connection to the server and receive push notifications as soon as a message arrives. How exactly this works depends on whatever IMAP library you're using.
This looks really promising. I really like it. What bugs me tho is one minor detail: As it stands the Demistify Method is an extension (this) method to the Exception class. Although i understand that to provide a full stacktrace demistified including the inner exception,... it really doesnt feel well that the Demistify is called on the Exception Class instead of the StackTrace by itself. It makes it look like it is a operation on the exception itself rather than the stacktrace. Are you open for community feedback as in Pull Requests? Cause your code looks really fun and i have some things in mind that i can't really express in text
Probably for that horrific spelling of 'beginners'
The differences are in many shapes and sizes. For example, there is a file with the extension .nif, which typically has a mesh, a collision mesh, and metadata (texture paths, shader properties, skinning data, etc). The changes to these can just be a fixed texture path, to a completely new collision mesh. The reason why I want the percentage difference, is to create the smallest patch possible; there are 10GB of files that need to be sorted through. If there's a file where every single byte is different, the percentage difference would be 100%. Or to put it another way, the percentage of similarity is 0%. If there's a file that is 10KB, and there is another file that has another KB of data, the percentage difference would be 10%. Percentage similarity would be 90%.
Why wouldn't you just have the application listening for subscribed events that are triggered auto-magically by received emails?
Maybe it's the use of lowercase 'i's.
*shrugs* You scare people
Don't feel bad. You've earned valuable experience.
I think they should perhaps update the stack traces to account for modern code.
Will this unwind single exception AggregateExceptions?
Googling the title of this post would have taken a fraction of the time it took to write it and wait for an answer.
Honestly i am bad at googling for coding problems.. 😂
I might not end up having to use the idle feature since when an email is "read" by the program it is moved to a custom folder for archiving purposes, and each time the for loop loops back to check if it needs to run again the inbox.Count property is run so it updates new emails then. When the program finishes there will be zero emails in the inbox and it won't run again unless the inbox.Count is not equal to zero. All the idle feature does in the library I'm using essentially checks if the count has changed which is exactly what my for loop does. Unless I'm completely overlooking the benefit that is.
Removed: Rule 4. Do some searching around and make an attempt. Check out `Double.Parse`.
Then that's absolutely something you should work on, ASAP. Google is the single greatest resource for any developer.
Why not just post it somewhere and give us the link? That way the C# community can say whether it's worth anything (no point leading a beginner down a bad path)
Take a look at blocking collections. I use this in places like in finance where you don't want any lag on position updates but they come semi irregularly
Im also experiencing jittering while scrolling. iPhone 6 user
Hey mate, since you were askin' bout this, i released 1.0 this afternoon, give it a try if you haven't yet if you want. :)
http://www.apress.com/gp/book/9781484213339 maybe this one?
You can get a softcover version so its not digital.
Agreed; been working on that, has some async client up in next version of .NET Core https://github.com/dotnet/coreclr/pull/14652 &gt; Does this have any performance impact or affect anything fragile? Performance will likely be dominated by catching the exception in the first place - its not fast (i.e. don't use exceptions for flow control) Likely won't work for AoT/UWP/Xamarin type things
&gt; It makes it look like it is a operation on the exception itself rather than the stacktrace. It does, `exception.Demistify()` mutates the exception filling in its stack trace string; this is so the exception type remains the same. On the other hand you can also do `new EnhancedStackTrace(exception)` to get a improved stack trace without mutating the exception. &gt; Are you open for community feedback as in Pull Requests? Yes &gt; Any chance that C# isn't the language you grew up with? Any reason? Has code from various repos (e.g. roslyn, aspnet) so that style mashup may look weird?
Yeah. Some of the code I see really looks more like c++ code than c#. I notice that with my coworkers who did Pascal or c++ first that although they write perfectly fine c# code, the will never get over the style they grew up with. You see it in every step of their syntax. It's fascinating
I was getting demands on twitter; so haven't had time to niceify it :) The level of reflection is something new for me; I generally stay away from reflection as its too slow for my liking - but... stack trace output is currently more horrible than reflection is slow ;)
No thanks, I don’t need to see the exact type, or rarely at least, so we tend to use var all the time. It’s a matter of taste. 
could you post a more complete code example that we can compile? or a project zip?
I would say they are both different products but share some common ground. Bridge converts C# to javascript, whereas Electron.NET is electron, but programmed in C# So i guess Bridge is more flexible because you can plug the generated JS into Electron? Maybe? That's the only way i would interpret that
My code: using System; using System.Text; using System.IO; namespace ReadTextFile { class Program { static void Main(string[] args) { string text = File.ReadAllText(@"c:\gentle.txt", Encoding.UTF8); string lowertext = text.ToLower(); Console.WriteLine(lowertext); } } } 
Any code written in C# is compiled on-the-fly in a virtual environment called the *CLR* which stands for *Common Language Runtime*. The CLR virtual environment can run on many different platforms, and translate your code into machine code that the system understands.
What country are you from? Just curious - since you said Highschool. I wish I could have gone to a tech oriented Highschool...but i live in the USA and we dont do highschool that way (gen ed)
Look into .NET Core and Mono. If you're interested in mobile development, look at Xamarin. For video game development, check out Unity.
Adding on, with .NET Core you can even build self contained applications that don't require the runtime to be installed on the machine.
Adding on, with .NET Core you can even build self contained applications that don't require the runtime to be installed on the machine.
&gt; Which was good until I stopped returning the object and started returning an IHttpActionResult Why did you do that? I know we do that in ASP.NET Core because Core sucks balls and doesn't support HttpException out of the box. But the only time I've seen a need to return IHttpActionResult directly was when I was returning a file, which of course doesn't need a Swagger response definition.
P.S. This is an anti-pattern: public IActionResult GetA(string a) { return Json(a); } 1. You never need to specify that you are retuning JSON. What could happen if you didn't? The client asks for XML and you give it XML? Not really a problem. 2. That's akin to returning `object` or `dynamic`, basically an untyped response. Throwing away type safety should be a last resort.
I didn't know about that, are you saying I'm better off just returning the object itself rather than Ok(object)? What do you mean by doesn't support httpException out of the box? Could you please elaborate?
Personally, I stick with Visual Studio since it fulfills all my requirements (and it's the devil I know), but Rider seems like a perfectly reasonable option for an IDE - especially for those who write code on platforms other than Windows.
&gt; I didn't know about that, are you saying I'm better off just returning the object itself rather than Ok(object)? Yes. &gt; What do you mean by doesn't support httpException out of the box? It doesn't exist in ASP.NET Core. So you can't do things like `throw new HttpException(NotFound)`. Fortunately there is a NuGet package that adds it: https://github.com/ASP-NET-Core-Boilerplate/Framework
&gt; Yes, you should just return the object. Do you have a source I could look at for that recommendation? Not that I don't believe you, but I have a tech lead to convince :)
No, I don't have a source. But we shouldn't need one to justify using standard C# code. Rather, someone should have to prove that returning `IActionResult` is justifiable deviation. But I know that won't necessarily help you, so here are my arguments: * It uses idiomatic C# code * Normal reflection works. * Easier to unit test the controllers * Return values are type checked * All IDL generators (e.g. Swagger) understand it. * No risk of the Produces attribute not matching the actual return type (which can happen because of copy-paste errors or code drift over time). Benefits of using `IActionResult` * You get fine-grained control over the response, which is needed when returning raw files * (Core only) you don't have to implement HttpException
&gt; which is needed when returning raw files I'm sorry for asking so many questions. What do you mean by this? Thanks for taking the time to reply btw. 
As in literally returning a PDF or Image from the hard drive instead of an object. &gt; Thanks for taking the time to reply btw. No problem. That's what I'm here for. (Well that and to bitch about ORMs.)
Looking forward to trying this out, thanks for making it. I'm trying to think of the best way to consume it for a typical asp net core app. I'm thinking maybe an extension method for the logging abstraction methods?
how is it for running tests?
The clr runtime itself only runs on windows devices. Other implementations provide support for other platforms. Eg, mono has it's own clr implementation. Unless you specifically meant .net core/mono's runtime, there is no singular *CLR virtual environment* that *can run on many different platforms*, correct?
It is using resharper for running tests, so if you used VS with resharper it's same (lightyears ahead of VS test runner).
I used it extensively a year ago and filed over 30 bugs I their tracker then stopped using it due to those bugs. After hearing it was GA I recently (a month ago) went back to try it again, but found that some of the important bugs still weren't fixed. One of these bugs was so bad that I immediately stopped using it again (step over in debugger didn't work). I've read that they have recently fixed that bug so I intend to give it another try.
So I've been using it on EAP program. Do note that I only stopped because my company doesn't buy it. Advantages: * It is fast * It reloads quickly and automatically when something is changed outside it (e.g. checking out different commit) * It is in Intelij infrastracture (many high quality plugins) * Debugging inside lambdas (why on earth does VS not support this?!) Disadvantages: * If your company uses custom builds/projects, they will probably only support it on VS. I hope it's not the case since I've seen it and it's terrible. * Might not have Azure publish (I think I have read about it but can't remember of they added it for sure recently) * Doesn't understand selectmany on non IEnumerable monads (resharper on VS will also show it as an error) tl;dr; Rider is resharper without Visual studio bloat. And I recommend it.
Sorry for the late response, I tried the TryParse beforehand but it still gave me the same error. However, this seems to works int maxQuantity = 0; if(view.Table.Rows.Count &gt; 0){ maxQuantity = int.Parse(view.Table.Rows[0] ["TotalInventory"].ToString()); } However some of the product names aren't getting any quantities to be displayed. So I guess the error that there weren't any rows is still there just now it doesn't display the IndexOutOfRange error, it just doesn't have any quantities. I know it has a quantity when I check it on the SQL database but when I run it, it won't select anything other than 0. It also seems fairly random in terms of what has a dropdown list of all the quantities and what doesn't. 
Ah alright, that makes a lot more sense. Thanks. 
I like it because I like Resharper. I find it's quicker than VS2017+Resharper which is a bonus, but I'd be lying if I said I'm using it for anything other than developing on Debian. For Windows I'd stick to VS2017 because it's what outlets team uses and so helping others with debugging etc means it's helpful if we all know how to use the same IDE. 
What add ons etc are you running in vs? For me it's usually ReSharper that is slowing me down. 
VS is a huge resource hog, especially with Resharper. If you're already on the edge resourcewise it grinds the whole system to a halt. If it does have the resources it functions great tho. Hot tip: hide any node_modules folders in your project so VS doesn't try to index them. 
C# is not compiled on-the-fly. C# is compiled to IL, and the IL is then compiled on-the-fly to machine code.
Honestly I didn't find it that useful. Sure it loads faster but so does VS code and I prefer that over Rider. Mind you I was never a huge fan of ReSharper and done most of my work without it.
I stand corrected
&gt; Debugging inside lambdas (why on earth does VS not support this?!) It does.
I want to love it. I really do. Like I love using Resharper. But I find it's just not quite ready to be a VS replacement yet. It's fast... And has some great features. It lacks a few features I took for granted in VS, but I'm happy to overlook that... But it still has some bugs which ultimately cause me to keep returning to VS.
How?
What are these bugs?
I've frequently had it hang during builds. Or fail to deploy (I do a lot of mobile development). Those are the showstoppers for me at the moment. But I prefer using it as a code editor.... So I sometimes have both Rider and VS open and use one to edit and one to build &amp; deploy (ridiculous I know).
I tried it and while some things are less than ideal (no package manager console functionality for instance), it makes up for it in the support for javascript and typescript in my opinion. Just the formatting, highlighting, smart code completion for those is so good in the IDEA clones. It's that and the 'complete statement' shortcut which I use religiously which VS just doesn't have in the same capacity. It does have something similar but it works in half of the situations in which it work for Rider/IDEA.
Just step into or set a breakpoint. Not sure what your issue is.
[VS](https://i.imgur.com/HTm5vJV.gifv) [Rider](https://i.imgur.com/ivGYt5f.gifv) Maybe I am doing something wrong? VS won't allow me to actually put breakpoint or step into lambda. [Here's an article about lambda debugging](https://blog.jetbrains.com/dotnet/2017/10/30/lambda-expression-breakpoints-debugger-watches-rider/)
I think it's positively excellent and beats the crap out of VS for C# development. It's an incredible boon for xplat development, too, as it runs on Mac and Linux just the same as it does Windows. 
Through my professional experience I learned it is always a better experience to stay with the tools of the platform owner. Rider might be a thing if we ever go cross platform with .NET, but even then there are Visual Studio for Mac and Visual Studio Code to consider, before customer IT ever pays for third party licenses.
I am from Serbia, we go to middle school 8 years with all the basics subjects and after we finish it we chose what we wanna specialize for. Also if you dont know what you want to be specialized for you can go to highschool with all the basic subjects + some more and after that you can go to any university while after you finish specialized school you can go to school that is oriented with you specialization. You will finish university much easier after you finish specialized highschool since you will have much more knowledge about what are you studying
The binary patches described above are the minimum patch. You don't need to convert them to percentages because they are already, quite literally, the exact difference between the new and the old version. You can't do any better and there's literally no reason to. The only percent difference that matters is zero. Anything else is going to require either a binary patch or downloading the file again. It doesn't matter if it's 2% or 100%. Changed is true or false. Binary patching is going to take a lot of work, and unless you're going to maintain diffs from every previous version to the latest version which is beyond insane, it's probably going to require anyone out of date to download more data than if you'd used the naive approach. **Don't do this, it won't work and you don't understand it well enough to not make things much worse. Beyond that, no mod manager will handle this.**. The minimum patch set for these mods is every file that has changed at all in a zip file. It's what everyone expects. Fucking do that. 
Use the shortcut F9 to set the breakpoint while the caret is within the lambda. That way you set a breakpoint in there, and not on the line itself. This is just a UI issue and I have to admit that the Rider UI solves this better. Stepping into does not work here, because the lambda is simply not executed. The execution of `.Select()` is deferred. If you add a `.ToList()` you force execution of your enumeraton, and it will actually start calling your lambda.
What features? 
Well, on iOS and UWP, is AOT.
 The only thing better with VS2017 is it looks better. Unlike the VS2017 + R# combo Rider doesn't crash and freezes regularly on my computer. Further more it's much faster, especially for searching and navigating in my projects. I believe Rider will work just fine for the vast majority of projects/solutions. 
TFS integration is broken at best. Otherwise it's the best Solution for *nix Users I found when developing C#.
Depends. It already works with UWP... What's in the works, is WPF.
Unfortunately there’s no dotCover for coverage or continuous testing, which is a deal breaker for me. 
I'll start with a bit of a shill for my blog, sorry. [I wrote about Rider](https://dotnetcore.gaprogman.com/2017/05/04/project-rider-a-challenger-appears/) when I was first picking up steam in its EAP build, and loved it then. [I've answered a bunch if questions for codeshare.co.uk]( http://www.codeshare.co.uk/blog/what-is-jetbrains-rider/) on it. Then when version 1 came out, [I wrote about it again](https://dotnetcore.gaprogman.com/2017/09/14/rider-reaches-release-candidate-and-why-you-should-try-it/). &lt;/shill&gt; I've been using it (along side VS Code) on my Mac and Ubuntu box since it was in EAP and I love it. It very quickly replaced VS Code for me, especially since 2017.2 came out (it now natively supports .NET Core 2.0). I still had to use VS Code when Rider was in EAP because JetBrains ran into a licensing issue with the official .NET Core debugger, but that has since been sorted out. It's now my daily driver IDE for all of my projects. Although I do have an issue getting Higher Module Swapping working with the latest version of it, but I think there's a bug logged for that. I don't use it for .NET stuff, because I'm rocking Unix/Linux at home. I do use VS Enterprise at work, but that's a business decision made b by the higher ups. I'm all for it, but I need to get some evidence and build a proposal, I think. In short: it's fabulous for .NET Core stuff. I haven't got that much experience using it with .NET stuff though.
Sounds good! &gt; its not fast (i.e. don't use exceptions for flow control) Agreed, just wondering if it affected just every day things like calling methods or newing things up.
Ooh cool will do!
Except .NET Native, but if I remember it correctly, this feature is for Windows 10 x64 only.
Like I said... Most of these I'm willing to workaround... But the features that immediately come to mind are the code templates for some file types (I'm sure I could create these myself in Rider, but my motivation to do so isn't high enough since VS has them) like ViewControllers and XIBs (don't make me create a code file, nested designer file, and XIB file manually). An interface builder for XIB files, or some integration with Xcode for this would be good. Same for Android, but not as important. Ability to set project and build properties (e.g. code signing and certificates) without having to hand edit the CSProj XML directly (Perhaps I just haven't figured this out yet). Get rid of the annoying "would you like to set the code signing certificate?" dialog in every run when I deliberately want no certificate set (I.e. automatic). Better feedback during deployment to devices/emulators. Mostly it just hangs or doesn't deploy... And I'm left guessing. I'm being pedantic now... But I prefer selecting the target device from a drop down before starting the build.... Rather that having the process halt while it waits for me to make a selection in a pop-up dialog (while I'm off making coffee). For reference... I do a lot of Xamarin development on a Mac (traditional native, not Xamarin Forms). So I'm mostly comparing against VS for Mac... Although almost all the above applies equally when comparing to VS for Windows.
Visual Studio for Mac is just a rebranded version of Xamarin Studio which is just a rebranded version of MonoDevelop with a few tools thrown on top (iirc). Having used Xamarin Studio and MonoDevelop in the past I must say that Rider is a fuckton better than MonoDevelop.
I switched to Rider for my .NET dev Pro: - fast - the editor stays responsive, no matter what. - in-IDE console. I personally don't use the CLI much, but it still turned out to be a great little helper - in-IDE VCS support is great - If you already know R#, you'll feel right at home, as all its features are there. - Things just work. No bloat. - Very customizable Cons: - As silly as it may sound, pressing F1 on a method doesn't give you the help on the method, and that's a bit cumbersome at times. There's likely a keyboard shortcut somewhere, haven't looked yet for that - No winforms/wpf editor. This holds me back on fully switching over as I have to work in the winforms editor sometimes. It can work on projects which are winforms tho, you can still write the code, you just can't design forms - I haven't found the custom startup settings for a project/debug. These likely are there perhaps, but I couldn't find them at first glance. This is a bit of a pain if you e.g. contribute to CoreFX and want to run a single unit test as you have to start xunit runner with specific commandline args. There are other minor things but all in all I really love it. To describe it better: I had to work with VS2017 15.3 to port our large codebase (LLBLGen Pro runtime) to .NET standard and especially the unittests (7000+ of them, in dual targeting projects) was a true pain to work with in vs2017. Everything was so slow, and the main/UI thread was constantly bogged down, which hurt even basic typing. When Rider went into public EAP I tried it and it made me like working on the code again, where vs2017 made me dread working with the new .NET Core tooling so much I basically hated everything about it. Rider is also very cheap if you have R# already. It costed me about 10$ for a year subscription. :)
Step over works fine? What's missing is step into specific (so a method call which gets a couple of properties passed in as arguments: if you want to step into the method, you first have to step into the property getters which is a bit of a pain.)
&gt; Through my professional experience I learned it is always a better experience to stay with the tools of the platform owner. Hmm, my professional experience told me that that isn't true. E.g. borland C++ was way better than VC++ at the time, and Rider is e.g. miles ahead to vs with respect to even the simplest things like typing in the editor and stay responsive. It lacks some enterprise tools but 10 to 1 you didn't use those in vs either. 
Serilog has created an Enricher for it [Serilog.Enrichers.Demystify](https://github.com/nblumhardt/serilog-enrichers-demystify) Might be something to look at (either to use, or to see what they are doing)
I'l using it since EAP 1 and i love it
Should only affect things after an exception is caught; everything else should be unaffected 
&gt; if we ever go cross platform with .NET, Or you know, full blown Visual Studio. Not sure why you'd stop using that for making .NET Core applications?
It’s not just a rebrand. They’ve been actively working to bring it to parity with Visual Studio. 
VS has never been slow for me. It responds to all commands instantly. However, I don't use resharper. seems like 9 out of 10 people with performance issues in VS are using resharper, which is notorious for bringing systems to a screeching halt :-)
It's not VS, it's Resharper. Resharper still doesn't use Roslyn so it's building a complete AST in addition to the one VS is already building. It's horrifically wasteful and completely inexcusable.
I guess you were one of the lucky ones. https://youtrack.jetbrains.com/issueMobile/RIDER-507
Depends what would be the development environment. Currently we are still ignoring .NET Core, our multi-platform projects are Java or C++ based, and Core still lacks full EF 6 compatibility and native GUIs.
Yeah, then Borland kind of went astray and we got f****. Former Turbo Pascal and C++ Builder user.
There are good reasons for that. You can always not use it. Anyway, Rider is much faster. 
I use it all the time at work (Windows .NET framework shop), and it’s fantastic. It’s faster than VS+ReSharper, but the main attraction is that it’s just a much better IDE. Everything is better organized from the menus to the buttons to the way windows are docked etc. Since we use Mercurial at work it’s also an added bonus that it has a very good Mercurial plugin shipping with it.
No, there aren't good reasons for that aside from bogging down visual studio. Roslyn has been in release for years and the betas were around for years before. Rider is literally only faster because resharper isn't there fucking it up. 
* Method help: try the Quick Documentation action (probably Ctrl+Q but depends on your keymap_ * WPF editor: WPF preview is currently in the works. WinForms will have to wait longer though * CoreFX: you mean [this workflow](https://github.com/dotnet/corefx/wiki/Build-and-run-tests#user-content-run-and-debug-single-test-in-visual-studio)? 
&gt; Rider is literally only faster because resharper isn't there fucking it up. Oh really. Rider is based on ReSharper, it uses the same engine as ReSharper but different UI.
Yes, but you don't then install another application that's stupidly doing all that work again. The issue isn't whether resharper is fast, it's that it's doing a metric fuck tonne of completely unnecessary work. Visual studio without resharper is quite quick and rider doesn't come close in feature parity. 
The history is weird. C3 has only been cross-platform recently, but you still have to pick a special definition of "cross-platform". Let's compare a few "cross-platform" environments to get an idea why I still don't buy it, and why you have to be real careful if you want "cross-platform" C#. # Java Java compiles to bytecode. The tools to execute that bytecode and a specific set of libraries are defined as "the Java Virtual Machine" or JVM. Anyone can implement a JVM for their platform, and that will allow Java to run on it. For some reason, Sun/Oracle have chosen to sue people for making successful JVMs. The JVM libraries include what is needed for console, GUI, and web server applications. JVMs exist for Windows, Linux, and Mac. Android is an implementation of a JVM that Oracle tried to sue Google for creating. No JVM exists for iOS. So Java can write all three major application types on all major desktop platforms, and it's runnable on just about every non-IOS device on the planet. # HTML/JS/CSS If it has a web browser, it can run these apps. That covers iOS/Android/BlackBerry/Windows/Mac/Linux and even more esoteric things. This is what "cross-platform" means. The problem is the JS/HTML/CSS specs are large and confusing, so minor differences can exist between platforms. Lots of effort on any project is spent hunting down these differences and adjusting for them, though on major platforms that's becoming a solved problem. # C\# . C# compiles to IL, which is like bytecode. Microsoft published the specifications for a "Common Language Runtime" (CLR) to represent an API, and tools for running IL. Microsoft only made a Windows CLR, but made a binding legal promise they wouldn't sue people for making other CLRs. For the most part, people didn't trust Microsoft. The CLR only has support for console applications, but it has enough pieces you could write your own framework for web applications. The primary GUI framework for .NET was Windows Forms for a long time, it has since been replaced with WPF, Silverlight, Silverlight Desktop, Metro, "we can't call it Metro", Modern Windows Applications, HTML5/JS with Windows Extensions, and UWP. None of these are part of the CLR, all are Windows-only, and some of them don't even work on all extant versions of Windows. Mono is a CLR for Linux/Mac OS/Windows. It implements a CLR and console applications written for a .NET CLR will work on Mac/Linux if run by Mono. There are some GUI frameworks for Mono like Gtk#, but they are not compatible with Windows Forms and for some reason not very popular. Xamarin is a project purchased by Microsoft that wraps native Android and iOS libraries so they are usable by C#, and can compile those programs to native iOS/Android applications. It also includes Xamarin Forms, a UI library that attempts to be unified between iOS/Android/UWP. Next year, there are rumblings Xamarin Forms will support Mac OS/Linux. That will make it runnable on iOS/Android/Windows 10/Mac/Linux. It's very expensive, so it's not very popular. .NET Standard is a new way to define "a CLR" for Microsoft. .NET Core is "a new CLR" for Microsoft that runs on Windows/Linux/Mac. For some reason, they decided Mono needed friendly competition from "the company who promised not to sue you". The nice thing about this is .NET Core defines ASP .NET libraries, so .NET Core web apps can be run from Windows/Mac/Linux. It doesn't make sense to try and run them from iOS/Android so it's OK that's not supported. So, in short: * C# console applications can run on any platform with a console **if** you target Mono or .NET Standard or .NET Core. * C# web applications can run on .NET Core platforms. * There are many incompatible, competing GUI frameworks for C# and no framework yet produces applications on every platform. The best, most popular frameworks only work on Windows. So it's "cross-platform" much like Mario is "a plumber".
Did you open any feature requests? I opened one for a web.config transform preview and they either addes it or are working on it in the next version. I haven't actually downloaded the latest version to find out yet.
Never used it. I don't see the point in paying for an IDE when VS is free.
macOS has a Visual Studio port
That's just a rebranded xamarin studio
My point was more about how to manage dependencies than Xamarin specifically. 
Sorry bub, that's not how this thing works. TTW repackages Fallout 3's content, fixes and changes it to work alongside New Vegas' content. In order to legally do this, the files have to be extracted, patched, and then repacked. You can find the old installer here: https://taleoftwowastelands.com/content/alpha-download-v294b The percent difference that matters is not zero; the size matters immensely. There are a huge number of files that need to be changed, and having the smallest patch possible is paramount. Which is why I need the percent differences; find the source files that need the least amount of data changed, and patch those.
I use K&amp;R C style in C#. Too dsmn old to change now :)
"Visual Studio" and "Visual Studio for Mac" are entirely different products.
Try resetting visual studio settings through import/export settings from tools. It should fix it for you.
This ☝️ Also op compared to the performance hit r# brings with it ( on a msi gs70 with 16 gb ram good cpu and ssd ) on big corporate solutions, i still turn it off from time to time to remember how fast and awesome visual studio is without it. Eve with the solution wide analysis turned off. If you think visual studio is bad maybe you should try android studio to see what a bad ide is like. ( at least it was like 2y ago)
Phrased a different way: Why would anyone use Rider? Rider lacks the debugging, project support, and performance tools in VS. The vast majority of "refactoring tools" are built-in to Visual Studio. If I wanted something light, I wouldn't kid myself with Rider. I'd whip open VS Code or VIM. Take the R# challenge. Consider your workflow and ask if the functionally is already built into Visual Studio. Run VS without R# and ask if the slow down is worth the features not in VS. The majority of people I talk with ditch R# within 15 minutes and never look back.
Thanks for that tip. Will make my life a bit easier. But damn MS UX team.
I've been using it for about 5-6 months now (for a [steampunk dungeon crawler game](http://store.steampowered.com/app/629690/Vaporum/)) and I don't see myself going back to VS any time soon. Rider makes me a lot more productive with the super-fast code navigation, refactoring tips (even teaches me a thing or two here and there), ergonomic hotkey scheme, very pleasant visuals and default theme, the expand selection function rocks, far superior autocomplete and intellisense, it's very fast overall, defaults are almost always sensibly set and all the tooling just makes sense. I will recommend Rider to anyone any day of the week.
&gt; Take the R# challenge. Consider your workflow and ask if the functionally is already built into Visual Studio. Run VS without R# and ask if the slow down is worth the features not in VS. &gt; I've tried VS2017 without R# and I feel totally handicapped. Clearly the people you've talked to have no clue how to use it. But don't trust my words on anything, instead install Resharper and walk through the included tutorial. I bet your principals wouldn't apply anymore. 
Feels like the most issues has to do with mobile development, right? These issues has not bothered me, but I appreciate the response. :)
Yes this is probably true.
Most of these are already on the feature request list.
I still use Visual Studio on Windows because I love it and am used to it. It also has all the plugins I love (not counting ReSharper because that's effectively included in Rider): OzCode, SQL Complete, NCrunch. On Mac I use Rider. It's as close to Visual Studio + ReSharper as you can get.
Package manager I’ve noticed is a lot faster than visual studio. But mass updates (of the same package across multiple projects in a solution) is not intuitive. Still it’s faster. Some other things like 3rd party plugins still need work. For example if you use Specflow you might need to add the codegen part of specflow to the build. But no nice built in editor. My suggestion is: try it and see for yourself. It’s free for a month. And draw your own conclusions. 
Yes, precisely that :) (I wrote that part in the wiki actually ;))
I’ve tried to like it and it’s pretty quick, I just find it an eyesore to use. xD While visuals really shouldn’t matter but if I’m going be looking at something all day I want to at least like what I’m looking at. VS2017 + RS I find isn’t that bad performance wise, at least not enough to annoy me. Though certain snippets of code like a large array init can really slow down VS. 
Just a show off post, interested if people are excited about this concept. Thx. 
Ok cool but do you have a github repo or an accompanying site with some more to look at?
Would be coming in the next 6-12 months as I finish the project. I've always wanted to have an open source project but considering the sheer number of hours I have into it i'd like to put some food on the table with it. I so far have in mind to post the code on github + some license which would be free for use for indie / non-commercial projects but charge for commercial use.
That's exactly what I need, better than I'd hoped for :D
If the data is in memory (not persisted to storage), and only about 1000 objects, which is rather small, than an multi-dim array would work fine, or another approach would be to create a class with properties corresponding to your data elements and appending items to a generic list. As for sorting and filtering, the System.Linq extension methods make it easy. See the Where and OrderBy/OrderByDescending methods.
Thanks for the help. Would the orderby work in a multidimensional array still? And would it just sort one column and leave the otherrs in the row unsorted? It's all a bit new to me and seems harder than I'd expected.
Yes, multidim arrays can be sorted by linq. Once you get the hang of the syntax, it's really easy and intuitive. var ordered_by_1st_column = arr.OrderBy(item =&gt; item[0]).ToArray(); var ordered_by_1st_then_2nd = arr.OrderBy(item =&gt; item[0]).OrderBy(item =&gt; item[1]).ToArray(); var filtered_by_1st_ordered_by_2nd = arr.Where(item =&gt; item[0] == "value").OrderBy(item =&gt; item[1]).ToArray();
You're a star, thank you.
This was my issue. Can't keep the thing running for more than 30 minutes without a crash of some sort. Also has problems opening some of our projects. When it works it's nice though.
I know exactly what it does. A file is changed or it's not. Period. You need to either update a file or redownload it whether it's 1% changed or 100% changed. It really doesn't matter. You can't just say this file is almost the same, so I'll leave it, it won't work. If you're working off fallout 3's content and you can guarantee a patch level for fallout 3, you can do a binary patch as above, but the actual percentage changed is still irrelevant. It's also going to be really complicated and buggy because binary patching just is. The smallest patch possible is literally the binary patch you said was too complicated. It's as small as you can possibly get. 
What kills people on that challenge is that resharper has different keyboard shortcuts so people feel really unproductive without it at first. Resharper has an average CPU profiler, and a average test runner and a better than average refractoring set. It's also a piece of shit that makes VS unusable because its developers want to sell rider for some reason. 
What kills people on that challenge is that resharper has different keyboard shortcuts so people feel really unproductive without it at first. Resharper has an average CPU profiler, and a average test runner and a better than average refractoring set. It's also a piece of shit that makes VS unusable because its developers want to sell rider for some reason. 
Install Roslynator and a navigation extension and take the time to relearn the terrible R# shortcuts and you'll be fine.
Shouldn't you use `ThenBy` after the initial `OrderBy`? 
If you want this to be a success then you should use GitHub from the get-go. All the big projects these days seem to be open source, and many developers won't even touch something unless they can view the source and contribute fixes. I think communities like JS/Node prove that openness and accepting contributions from others make more a better ecosystem, and if you really want to make money for commercial use, that doesn't necessarily preclude being open source. 
There's nothing wrong with keeping a project closed at the beginning, especially if you don't know for sure it will turn out. Being able to break everything is very important, and getting people involved too early can lead to design flaws being perpetuated. That said, if a project is at the point that you're demoing it to others, it's probably a good idea unless you have commercial aspirations. At the very least keeping visible even if you aren't yet accepting contributions can get people interested that may be able to give you information you weren't aware of or ask design questions that may reveal things you hadn't considered. It's also nice in case you decide to drop the project for some reason, so others can still benefit from your work. 
Yep. Good catch. 
&gt; What kills people on that challenge is that resharper has different keyboard shortcuts so people feel really unproductive without it at first. Only if people opted-in to using them at the start. I'll put up with the slowness of R# because it attempts to bring VS in line with other JetBrains products, I'd use Rider if I thought I could get away with it for day to day use, just because switching between multiple IDE's is a pain in the ass. I don't claim to be an expert on what VS can and can't do however, I just immediately felt lost switching to VS, and still do when it comes to MSBuild and NuGet.
Are you using Darcula? If Rider is anything like IntelliJ it should be very themeable.
VS isn't free for companies &gt; 5 people. (not that I expect it should be, just your comment sounds misleading)
LINQ is beautiful 
It sort of depends on your use case. If you use and like the rest of the jet brains infrastructure and you don't need the features VS has that VS doesn't that's fine. People should use the tool that works for them. My big beef though is that the resharper add I'm for VS deliberately doesn't use Roslyn and continues to use the old plugin architecture. This makes VS +R# painfully slow and horribly buggy which people then use as an excuse to plug Rider which has the advantage of not having a poorly written parasite making it unusable. If Jetbrains would use Roslyn they'd be back in the game as a product I'd want to use, but they won't and so they're shit. 
I tried this for about a month. Ended up going back to ReSharper for LINQ refactorings.
It looks like WinForms.
Yeah sure I completely understand the frustration, I just think it's defendable since R# is most likely a .net port of their Java code that works on multiple languages, and their team is well versed in using it, as well as having many years of research poured into it. If they havn't investigated using Roslyn for better performance they would be absolutely mad, but I understand that it's probably a fairly risky business decision on their part, especially when people are using it as a way to plug Rider...
Since this follows the React "functional" paradigm, will you be adding F# specific APIs?
Exactly this, thanks for posting. I have been doing all development in a github repo, just closed. I'll be opening it here in the next few months as I apply some final polish and work out the correct license. 
:), Winforms is hosting it but every pixel is drawn by the framwork suing SkiaSharp. Consider it the same level of flexibility as websites today have to style, a better designer will do more. 
The issue is that your visualizing the data as a table to begin with. You want to create a Person class, the store all your instances of that class in an array or List. Once you have that, sysyem.LINQ enumerable extensions will make it very easy to search or order data as needed. You don't usually want a multi-dimensional array unless you're dealing with something like a grid, mathematical matrix, etc.
No sorry, my current opinion is that F# is complicated jargon of a language. I feel that you can do functional style programming just fine in C#, without the doctorate in quantum mechanics. The idea behind functional style here is simply that you put the same props and state into a component and the component will render the same time, everytime. Its deterministic thinking that will results in well built and dependable UI. At least that is the React koolaid. 
:( Well maybe in the future someone (maybe me?) could write a wrapper library. This is still cool though Good job
Vote them up
Already have
CodeMaid might cover some of the features
Yea, that's what I've been leaning towards.
I have a resharper license from work but its code inspection is so horribly slow that I disabled it and use Roslynator instead. It is a set of Roslyn analyser which are way faster. https://github.com/JosefPihrt/Roslynator Another interesting Roslyn analyser is U2U Performance Analysers which checks your code for performance issues https://marketplace.visualstudio.com/items?itemName=vs-publisher-363830.U2UConsultPerformanceCodeAnalyzersforC7 Both these extensions are free. 
side note: skia engine is also used in fuchsia os and Flutter framework
As Contagion21 says you really should look into creating a Person class, and then store your data in List&lt;Person&gt; That method gives you some good options, not just the LINQ querys, also saving your data to files using [Serializable()]
Pro tip: Learn the power of the keyboard, start to rely less on the mouse.
Except it's not. Building an AST is language specific. It's not possible to do it any other way because it's literally a partial compilation of the code. Yes there's shared code between the add in and Rider, but making a competing product worse on purpose is pretty scummy behaviour, especially when the overwhelming majority of their revenue is coming from the add in. 
I know, one of the reasons I like rider is becuase it has usable vim emulation plugin. This was more of a discoverability problem.
Except it's not. Building an AST is language specific. It's not possible to do it any other way because it's literally a partial compilation of the code. Yes there's shared code between the add in and Rider, but making a competing product worse on purpose is pretty scummy behaviour, especially when the overwhelming majority of their revenue is coming from the add in. 
Some more information about the rules of the game would be useful.
Yes, I wanted to edit it sorry. Im updating it 
It's slow for most people because of working with either bigger projects and/or resharper. We use resharper because it insanely improves UX.
Sorry OP, but if I wanted HTML-like flexibility, I would use... HTML. Closed source, paid UI framework? Sorry, no.
updated! the rules are just like the original draughts
What's wrong with the shortcuts? If they're bad I can just rebind them. Anyway, installed Roslynator and it appears to have a pretty neat feature list. However, I'm still missing the alt + enter shortcut which works differently depending on context. For example, if i type: new ClassNamn(); + alt enter. I want my ide to fill a variable declaration like this: var className = new ClassName(); Further more i'm missing postfix templates. 
Straight from the horses mouth. :) https://blog.jetbrains.com/dotnet/2014/04/10/resharper-and-roslyn-qa/
https://blog.jetbrains.com/dotnet/2014/04/10/resharper-and-roslyn-qa/ Will ReSharper take advantage of Roslyn? The short answer to this tremendously popular question is, no, ReSharper will not use Roslyn. There are at least two major reasons behind this. The first reason is the effort it would take, in terms of rewriting, testing and stabilizing. We’ve been developing and evolving ReSharper for 10 years, and we have a very successful platform for implementing our inspections and refactorings. In many ways, Roslyn is very similar to the model we already have for ReSharper: we build abstract syntax trees of the code and create a semantic model for type resolution which we use to implement the many inspections and refactorings. Replacing that much code would take an enormous amount of time, and risk destabilizing currently working code. We’d rather concentrate on the functionality we want to add or optimize, rather than spend the next release cycle reimplementing what we’ve already got working. The second reason is architectural. Many things that ReSharper does cannot be supported with Roslyn, as they’re too dependent on concepts in our own code model. Examples of these features include Solution-Wide Error Analysis, code inspections requiring fast lookup of inheritors, and code inspections that require having the “big picture” such as finding unused public classes. In cases where Roslyn does provide suitable core APIs, they don’t provide the benefit of having years of optimization behind them: say, finding all derived types of a given type in Roslyn implies enumerating through all classes and checking whether each of them is derived. On the ReSharper side, this functionality belongs to the core and is highly optimized. The code model underlying ReSharper features is conceptually different from Roslyn’s code model. This is highlighted by drastically different approaches to processing and updating syntax trees. In contrast to ReSharper, Roslyn syntax trees are immutable, meaning that a new tree is built for every change. Another core difference is that Roslyn covers exactly two languages, C# and VB.NET, whereas ReSharper architecture is multilingual, supporting cross-language references and non-trivial language mixtures such as Razor. Moreover, ReSharper provides an internal feature framework that streamlines consistent feature coverage for each new supported language. This is something that Roslyn doesn’t have by definition.
Yeah I had changed all the colours around. Just the way a lot of the UI is rendered just doesn’t look as snazzy as VS. Looks quite dated. 
Thanks :)
&gt; my current opinion is that F# is complicated jargon of a language Ouch.
That is the most ignorant thing I've ever read about F#. Yes UI programming is easier in F#, but as a language I'd say that F# is a lot cleaner than C#.
Check ReSharper &gt; Options &gt; Code Inspection &gt; Settings. Is "Enable code analysis" on?
None of that says the AST code is reused, because fundamentally it can't be. Solution wide error analysis as an argument is a joke because you can't turn that feature on anything bigger than a toy project without grinding your PC to a halt. Resharper even tells you not to enable it. Visual studio also has no problems telling me whether classes are used. Mutable ASTs are not an advantage either. They can't be shared and they're horrifically complicated to maintain for limited performance benefits. This comment is from before there was even a public release of Roslyn, it may have been true then, it's not now. If I had a dollar for every company that thought Microsoft couldn't beat their lead I'd be Bill Gates, cause he does.
They're requesting quite a few features but you can definitely get it done in time if you put in the work. Whenever a programming problem appears too daunting and complex and you don't know where to start, start breaking it down in smaller problems. Eventually you get to the point where you can start solving these mini-problems one by one. For example, a first step could be to figure out a way to represent the board (perhaps a multi dimensional array?) and write a method to print the board to the console. Then maybe you create a class for the game pieces, and find a way to to make them appear on the board, and so on. You may still get stuck at points. That's completely fine! It is a lot easier to ask for help and search for information when you're working on these smaller problems instead of the big intimidating one. Hope that helps a little, feel free to ask if you have any questions. 
Thank you! This breaking it down strategy really works well, today I finally moved forward with my work. I started with a blank paper and a pen, then eventually I got 2 papers full with ideas and possible working methods. It works well in theory, can't wait to test it out in code.
It's really simple for me. Tell me where you use the word monad in your day you day language and I'd agree. F# might be a fine language, it's just not for me when I can do all I can imagine in c#. (C# fanboi here)
Thanks, I'll respectfully disagree. Thanks for taking a look though. Also I didn't mention it in the post but currently the plan is it will be going open source with commercial use license.
It's also used in the cross platform chrome browser. Which was the reason I gravitated to it.
List&lt;Person&gt; combined with LINQ, and possibly FileHelpers for data storage to/from CSVs (until you need a database) or Newtonsoft JSON for storing in a JSON format.
We've found that ReSharper has two main causes of slowdown: - Long fluent chains were a problem in past versions of ReSharper. These are common when using AutoMapper and you have a class with more than 50 properties. - Classes with over 50-100 properties. Common in the real world where it's not worth trying to create a dozen sub-objects that are all 1:1 with the parent object. I love ReSharper, but there's a lot of times that I have to run with it turned off (in VS options) because of the slowness caused by those two things. 
Did you ever try NCrunch for unit tests in VS? How did that compare?
&gt;That is the most ignorant thing I've ever read about F#. You can be ignorant of facts. But this isn't a fact, it's a subjective opinion and he's perfectly entitled to it. Tone it down a bit.
I think this will live or die based on how performant it is. Xamarin.Forms, which I guess this would be a kind of competitor for, certainly suffers some performance issues although they seem to be working hard to address some of these in recent releases. I guess since it's under heavy development that you haven't fully optimized the framework yet, but I'd be interested to see some metrics when it's nearer production ready. Bravo though, sir! Great effort so far. Looking forward to checking it out in the next 6-12 months.
Did you do this: "EDIT: Instead of referencing windows.winmd directly, a simpler and more thorough way to use WinRT from a desktop application is to install the UwpDesktop NuGet Package. Install this package in your newly created project."
Hi coreyfournier Yes i installed UwpDesktop which let me see the Windows namespace, but did not let mee see any classes of it. To solve this i unistalled UwpDesktop NuGet Package and added the reference to windows.winmd directly. which can be found in :C:\Program Files (x86)\Windows Kits\10\UnionMetadata\10.0.16299.0 
If you have classes with 50-100 properties ReSharper should be the least of your concerns. This is a major code smell in my opinion.
Depending on the industry, a product could easily have 10 identifiers, dimensions, shipping dimensions, ordering and shipping quantities, a handful of prices, and industry specific fields. Its not uncommon to have business entities with 50-100 fields, much less properties for related entities (like business rules, alternate products, and kits).
The previously mentioned https://github.com/Roemer/FlaUI can be used on CI servers (as long as it has a desktop session). We us it to run thousands of UI tests for our applications.
Thanks appreciate it. Mind if I ask you to clarify a bit more on performance concern. Is it startup performance or just views updating performance concern / animation performance concern? Note: I have developed with performance metrics in place from the get go and I'm under 16ms renders with a typical component hierarchy easily. My target will always be 16ms build, layout, render so I expect should be fine there but I have yet to push the system nor optimize the system. What I am concerned about is I built on top of xamarin.forms for the host layer for mobile. The con there is that I am subject to the same start load times as xamarin.forms which is a bummer and understand is an issue in the community right now. If I get unlazy perhaps this would be the reason to just build an iOS and Android host library without xamarin.forms (Was trying to take out two birds with one stone as I'm lazy) 
All those things should be separate entities and only be referenced by the specific product as a list or reference (like you would do in a relational database) in my opinion. And even then it doesn't make sense to have all those attribute available for all units of work. You most likely don't need to have a million classes just for the sake of it, but if it doesn't make sense for a View to access 20 shipping attributes then maybe think about not including them in this part of your code. Just because applications in an internal network are not as much affected by the amount of data you transfer or hold in memory, still doesn't mean it's a great idea to do so.
Promising framework and ambitious goals. will surely follow it's development.
Feel free to contact me on https://github.com/Roemer/FlaUI/issues or on https://gitter.im/FlaUI/Lobby in case you have problems getting FlaUI running.
You also have to make sure to add the right system.windows.runtime files.
No sorry, never used ncrunch
&gt; Next year, there are rumblings Xamarin Forms will support Mac OS/Linux. This is much more than rumblings/rumors - [it's a fact. It's already present in the XF preview builds.](https://blog.xamarin.com/preview-bringing-macos-to-xamarin-forms/)
Ironically, ReSharper has refactorings like Extract Class and Transform Parameters to take a bit of pain from addressing this issue.
That was really interesting! I did notice one minor mistake (I think) in the final version of `SimplifyDoubleNegativesn `: `n is NotNode n1 &amp;&amp; n1 is NotNode n2`. I think it should say `&amp;&amp; n1.Operand is NotNode n2`, right?
Oops, good catch! I've updated the post. Thanks!
Thanks! Between this and CodeMaid I might be covered. :)
Thanks for the clarification. I didn't want to make a concrete statement based off of "I saw a slide in a presentation a few months ago". 
Unless weight going below zero *should* throw an exception, I usually do something like this to ensure values zero or greater: private float _weight; public float Weight { get { return _weight; } set { _weight = Math.Max(0f, value); } } If `value` is negative, `weight` will be set to 0f.
From 3 years ago complaining that they're 10 years into development when MS made a ton of their work redundant and open source. Game plan to adopt the new shiny better way? Nah, stay the course.. Also struggling with slow but useful Resparper experience. Anyone have a good Roslyn based 'search everywhere' extension that searches files and AST nodes? That's usually what I miss most when toggling Resparper off.
It all depends! You can do that if you've carefully asked yourself whether all call sites that set Weight can and *should* return results less than zero. If they shouldn't, you're hiding bugs in those algorithms in much the same way NaN propagates through systems. It creates "the place where I realize things have gone wrong are very far from the place where things went wrong". That makes debugging a nightmare. I have to worry about correctness a lot, and while I might clamp like that in an upper-level type, at low levels of abstraction I really hate it when this isn't true: foo.Weight = something Debug.Assert(foo.Weight == something) 
What is wrong with System.Drawing.Image? If you mean that it doesn't exist in .NET Core 1/2 standard library, but it is possible to use CoreCompat.System.Drawing nuget package instead. In any way, you can use poppler tools instead of ghostscript (which requires a commercial license for redistribution/non-personal usage), it also has windows and linux builds. You can execute it from C# with System.Diagnostics.Process (or use existing wrapper like [PdfRenderer](https://www.nrecosite.com/pdf_to_image_renderer_net.aspx) but it is not free).
I've been recommend visual assist by a colleague https://www.wholetomato.com. I've yet to give it a try though but he swears by it. For context I tried resharper but had to disable it because of its slowness. I only use the code coverage and unit testing features of it (is a work provided licence) 
Thank you for letting us know! Adding to the list of things to check out
I haven't read the post yet (about to), but I just want to let you know that using PRs for comments is such an awesome idea.
Hasn't mono fully supported it for a while now?
&gt;Is it startup performance or just views updating performance concern / animation performance concern? I would say both. The former is certainly an ongoing issue for Xamarin.Forms. Given that you've basically got an entirely separate rendering system through skia which is doing pixel level drawing, I guess some of the classic issues with Forms like significant slowdowns when nesting certain layouts, or stuff like scrolling performance of listviews may not be so much of an issue. I think one area that would be good to see some demos of is transitions between different views. I've found Forms a bit clunky in that regard - a few more options and control over the type of transition would also be a nice to have. It sounds like you have your bases covered though.
Thanks! I can't take credit for the idea, I first saw it on [Mark Seemann's blog](http://blog.ploeh.dk/). I like it because a) it lets me use a static site generator and b) it encourages people to put a little bit more effort into their comments.
This is likely totally wrong and I'm not at a computer to check quick. I remember having an issue with VS configs before (used as user settings) where an update to the source didn't get updated during the build. Have you tried deleting the output file on disk and building again? Alternatively (this is the bit I may be clueless about) are you able to get access to it via code and call a reload similar to the user configs?
Those are some good points, but as you said, it depends. If the incoming value being negative is a symptom of another bug, then what I suggested would indeed hide the issue. It really does depend on the rest of the code base anx expected behaviors as to whether doing what I did is the best solution or not.
&gt;Yes, this is another good reason not to. It’s probably worth another 10 years before VS 13- releases become irrelevant. Does anyone use anything other than VS2017 for C# dev currently?
Given that he's a QA engineer, I imagine using TDD would require some time travel. 
I'm not sure. I'm using SkiaSharp for all my imaging. Only thing I seem to be stuck on is rasterizing the PDF.
PdfRenderer seems like exactly what I'm looking for. Thanks!
The Roslyn-say-it-again post was published in April 2014. Let's see what has been new in ReSharper releases since then (versions 9+): * Support for C# 6, 7 and 7.1 * Support for VB.NET 14 and 15 * Support for Visual Studio 2015, including merging Visual Studio's quick-fixes and context actions with Visual Studio's code actions in 2015 and onward * Support for Visual Studio 2017 and all its crazy updates, and including lightweight solution load * Support for .NET Core and ASP.NET Core 1.x-2.0 with code inspections, IntelliSense, navigation, unit testing * A ton of new refactorings, context actions, quick-fixes, code generation helpers, code formatting rules for a variety of JavaScript/ECMAScript and TypeScript versions * Support for Node.js, React's JSX syntax, Angular 2 and 4, JSON and JSON schemas, and JSDoc * ReSharper Build that sits on top of MSBuild to avoid rebuilding what doesn't need to be rebuilt * Find unresolved types on NuGet and install packages * Run configurations, including running, profiling or debugging individual static methods * New context actions and quick-fixes to revert order of iterations in for loops, check argument values for null/empty/whitespace/non-negative values etc, introduce fields and properties from unused parameters, convert interpolation to string.Format(), concatenation to interpolation, simplify nested interpolations, remove redundant verbatim identifiers, make string equality checks case-insensitive, insert arguments into string interpolation, comment and uncomment code selections, apply code style or reformat selections, split and join attribute sections, create type parts, add braces, convert XML in string literals to LINQ to XML objects, JSON in string literals to LINQ to XML objects, etc. * New large-scale refactorings: Invert Boolean Members, Extract Members to Partial, Transform Parameters * Optimize References and Remove Unused References refactorings reworked to understand NuGet references and be better compatible with dependency injection frameworks * Code inspections and quick-fixes around IEnumerable usage, XML documentation inheritance with inheritdoc, opportunities to use C# 6/7/7.1 language features etc. * A pack of WCF-specific inspections and quick-fixes around operation contracts in interfaces that are not service contracts, etc. * Fix in Scope extended to batch-apply dozens of ReSharper's quick-fixes in solution, project, folder, file or a custom scope * Showing warnings in addition to errors in Solution-Wide Analysis results * More code generation actions to add relational members, relational comparers and implement the Dispose pattern * Null checking preferences that let you choose what kinds of null checks you want to use any time ReSharper generates something for you * Entirely new postfix template engine, as well as reworked live/surround template engine * Way more code style settings, associated quick-fixes and cleanup actions related to named arguments, single nested statements, explicit or implicit access modifiers, order of modifiers, layout of attributes in a section, indenting parentheses, spaces around operators etc., as well a rewritten Code Cleanup UI, and integration of EditorConfig support into ReSharper's code style engine * A sane UI to define file layout preferences for C#, VB.NET, HTML, JavaScript, TypeScript, and apply the preferences per-solution for team-wide use * A way to configure code formatting settings based on a random selection of code * Smart Paste to auto-apply the right escaping when pasting text into string literals in C#, VB.NET, JavaScript, XML, XAML, HTML, and XML documentation * A set of C# typing assistants (auto-correcting @$ to $@, MethodName(.) to MethodName(). etc) * Support for UWP, including project model, code completion for API checks, support for new Win10-specific XAML syntax and device family-specific views * Support for regular expressions in C#, JavaScript and TypeScript: code completion, highlighitng, quick-fixes, validation utility * Code analysis, navigation and highlighting for HTML and regular expressions that are "injected" in C# or JavaScript string literals * Type Dependency Diagram and Assembly Dependency Diagram to visualize what code depends on a given type/assembly or what the type/assembly depends on itself * New contextual navigation actions, such as Navigate to Exposing APIs and Navigate to File Nearby * Ctrl+click that can not only guide you from a usage to the declaration but also loop you between them * Go to Action to search for every ReSharper action when you don't have a clue what shortcut it uses or where in the application menu it resides * Lots of effort into making the Find Usages process (as well as the related Find Code Issues) and the presentation of its results in the Find Results window asynchronous so that you can actually use the editor while a large search is being executed * More ways of grouping results in the Find Results window * Support for NUnit 3.x in the unit test runner, as well as native support for xUnit * Code inspection severity configuration from the Alt+Enter menu, as well as non-modal, Alt+Enter based Find Similar Issues experience * Go to Text for fast textual search with sane representation of results * Reworked Search Everywhere that supports searches in any order or exact searches, as well as search for extension methods for a given class * Structural navigation with Tab/Shirt+Tab between logical blocks of code * IL viewer: peek into IL behind your C# code * Process Explorer to find, decompile and explore assemblies of a running .NET process * Stack Trace Explorer rewritten from scatch * Support for CSS custom properties (variables) with code inspections, quick-fixes, code completion and navigation * Support for Google Protocol Buffers (okay, this is way niche, but was quite valid as a student project) * Feature suggestions to help users take advantage of more ReSharper features based on behavior patterns, as well as bundled interactive tutorials for onboarding * A certain IDE that reuses most of ReSharper's functionality Could all of this be implemented without switching to Roslyn? It could, and it was. Was it worth it to dump all of this and instead use these 3 years in a massive and seemingly endless migration to Roslyn APIs? The ReSharper team doesn't really think so. 
Thanks, Yep its on. 
I'm using VSCode right now at work as a pilot program to "prove" that we don't need MSDN licenses for all of our developers. ... it works. But it's kind of painful. So many of the tasks you take for granted in VS... you don't realise they're missing until they're gone. Although I do love how fast it opens. 
Try 0 30 */1 * * * It seems like 0 and * are somewhat interchangeable when it comes to this sort of thing.
Try 0 30 */1 * * * It seems like 0 and * are somewhat interchangeable when it comes to this sort of thing.
Noted thank you, I'll try that soon and reply whether it worked
This is going to produce a situation where ICoffee is practically a marker interface, and is implemented by all manner of things that aren't, in fact, coffee-related. This will make for really messy exception throwing around drip brewers, but will, conveniently enable things like Keurig and similar devices for common subsets of ICoffee's implementors.
&gt; Tell me where you use the word monad in your day you day language You can make that argument for almost any programming-specific term common to any paradigm or individual language, including words with programming specific meanings (pointer, object, type, etc). "It uses uncommon words I don't understand" is a completely asinine reason to not like something. If you have this much of a bone to pick with F# for being different to C-style OO languages, I'd pay money to see your reaction to Haskell.
I'm totally putting "5+ years JQL experience" on my resume.
Also, how are you supposed to wash this cup without getting compiler errors? Sounds like a terrible implementation to me.
Washing is probably handled through an inherited interface like IDish or something. Might be done with a visitor pattern.
Two more guesses then: 1. Code analysis could be off in a specific file. If it works elsewhere but the code analysis indicator on the top right of the editor is off in that specific file, try hitting Ctrl+Shift+Alt+8 in the file: this shortcut toggles ReSharper's code analysis per-file 2. You (or someone on your team) could have disabled that specific foreach to LINQ inspection. Try going to ReSharper options &gt; Inspection Severity, search for that inspection, and see if its severity is set to a value other than None. If none of these hints help, ping [ReSharper support](https://resharper-support.jetbrains.com/hc/en-us), they should help you out.
Yeah but either nobody wrote an implementation for washing, or someone made water implement ICoffee. Seems like someone just wrote the happy path of pouring a cup of coffee and drinking it. Rookie mistake to not worry about what comes after.
It's probably all framework code. Current implementation is almost certainly a nop, though.
I was aiming to do that - but just because I want to be able to say "I don't rely on VS, I use VSCode". VS sub is indispensable. Complimentary source control and package feeds for npm/nuget/maven. Pretty great.
CompareTo() is part of the IComparable or IComparable&lt;T&gt; interfaces, FWIW. You may want to implement IEquatable&lt;T&gt; to get rid of dealing with casting from System.Object. There really is no direct way to enforce that a List&lt;T&gt; contains only unique Ts. You'd need to create your collection type for that, which might be managed with a HashSet&lt;T&gt; for tracking uniqueness or something. In the meantime, you probably need to include other properties in your equality check and hash code implementation, if Name isn't guaranteed to be unique. If this were a conventional deck of playing cards, I'd recommend a combination of value (i. e. 1-13 or Ace, 2-9, Jack, Queen, King) and suit (Spades, Hearts, Clubs, Diamonds), but that may not adequately capture your use case (it wouldn't cover, say, Jokers being in the deck, especially as there are usually 2 of them).
If people are making ICoffee implementations that aren't related to Coffee, and using ICoffee as a marker interface, that's not a design problem, that's a dev problem. Don't be stupid, devs. /s 
It's a design problem, since the design doesn't adequately account for practical use. There's going to be a lot of wrappers created just to let things like water pretend to be coffee for the purpose of fitting into mugs like this.
No, you're using the API wrong. This is a clearly a *Coffee* cup, this is contracted by the where clause. If anyone is putting anything **other** than coffee in this cup, they're wrong. Instead, they should spin up a new MyCup&lt;T&gt; where T is whatever they want it to be. ILiquid, for instance. 
Checkers for those of in NA
What was the reason for supporting .NET Standard? The Win32 API is already Windows only.
I think we should add some sort of wrapper which will take some Water, or Pepsi or what ever you like and just add some Coffee to it making it ICoffee compatible. It will get the test to pass then someone else can worry about getting the coffee back out of the non Coffee drink in the next sprint. If you're doing Kanban there's a good chance no one will ever prioritise that, so that's even better :)
If you are set on using List, you would need to have your own CardList class that enforced the requirement that all items be unique. An alternative would be to use an ISet (HashSet or TreeSet) class.
What a generic joke.
"such that"
Feature request: Provide 100% support for the cool Windows Shell stuff, eg setting a progress bar on the taskbar icon, changing its colour, all the nice things like that?
You made me LOL, have an upvote
Goes To
Man wish I could up vote you more than once! That was all it was and it's now being invoked every hour on the thirty. Thanks again!
Delegated to
This would start a war in the UK.
Goes to. Also `[` = bracket `{` = brace `(` = paren, or parenthesis
I'm a mathematician by education, so I say "implies" for "=&gt;".
lambda or lambda operator
Ha! See what you did there. 
I agree its a matter of preference, but its much easier, clearer, and faster to read code when you can quickly see the types involved (versus having to hover the mouse over everything to see). Some things it can be quite obvious what the type is, but thats hardly always the case. And of course things like anonymous types from LINQ and stuff is perfectly fine. Using var everywhere can make refactoring easy, but it can also introduce unintended bugs when the types just happen to have the same methods and such.
Don't overthink it, just do not add duplicates to your list.
I like what Javascript is calling it: fat arrow. 
This is the most generic cup of coffee I've ever seen, and I usually see sharp.
I mean, you're not exactly wrong, but if the customer asked for a cup that can hold coffee, and we heard a cup that can *only* hold coffee, it's kind of on us to fix it when the customer fills it up with Coke and gets injured by when it explodes in a cloud of stack trace. We could decide, then, that ICoffee was really IFitsInACup, and backlog the rename.
I don't, but (given its use in C#), something like 'is/are applied to' might make sense.
What is '#'? Is it 'hash', 'pound', or 'octothorpe'?
The cup shouldn't implement ICoffee because some people don't drink coffee.
Where would go about buying a cup like this?
Shortcuts that do wildly different things depending on context are bad shortcuts. 
Yeah, it really should implement `IDisposable`, and have a coaster that surrounds the cup in a `using` block. GC can worry about what to do with it after the coffee's finished being useful.
Or how about your cup of C?
That sounds like premature optimisation to me.
Pound sign (point for short if you must) has worked great for years.
Used for other things as well now. I prefer arrow. 
Damn ppl, think before downvoting! A deck is a pretty well defined entity. You should not be able to add random cards to a deck, all cards in the deck should be initialized when you create the deck - if you do not agree then you do not need a deck class, you need a pile of cards class. Once you have a deck cards can be removed from it if the deck is not empty and cards can be added to it only if the deck is not full and only from removed cards. Based on the things mentioned before when implemented a deck you need to know all the possible cards that can be in the deck(your card list) and to know if a card is in the deck or not(you can implement another list that holds the state for each card) and then removing or adding cards from the deck is just updating the state of the card - no abuses or errors possible.
[ = square bracket { = curly bracket ( = bracket 
Surely '!' is either 'exclamation mark/point' in general use and 'not' in contexts like: if(!true) // if not true
What else in C# uses the same operator?
One way to get through a firewall is to use http over port 80. 
Expression bodied methods, which are basically the same thing
I didn't say I prefer models with 50-100 fields per entity, I said they were not uncommon. Unless you only work solo on greenfield projects, occasionally you are going to have to copy a large number of fields from or to a DTO at some point.
I spent 6 months learning c# in my spare time just so I could understand jokes like this on reddit :D
Reminds of a statement Microsoft released stating officially that nothing should be prefixed with `My*` as apparently some developers where citing their examples as evidence that it was an acceptable practice.
It is definitely fat-arrow.
Penis. I’ll just go ahead and start heading towards HR now...
A lot of people say "goes to", but I say "such that". e.g. x =&gt; x.FirstName == "Bob" "x such that FirstName is Bob", rather than "x goes to FirstName is Bob". I think it makes more sense. 
I'm stuck on 2015 at my job. Well maybe not stuck, haven't asked for an upgrade yet.
I always read it as "implies" in my head by I say "lambda" to other people so they don't think I'm weird
&gt; exclamation point You must hate pronouncing `#!/bin/bash`. And hey, we [could have had](http://www.catb.org/~esr/jargon/html/B/bang.html) `excl` or `shriek` instead of `bang`. I'm with you on `splat` - [Nathan Hale](http://foldoc.org/Nathan+Hale) is clearly the superior nomenclature.