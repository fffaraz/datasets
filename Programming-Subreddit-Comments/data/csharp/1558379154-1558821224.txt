The snarky answer to this question is "you can't". ICollection is an interface that only supports enumerating. You can't remove things from it. You can't add things to it. You can only read the items one at a time. But I think you're asking too vague a question. While ICollection might be the only thing in common between the two things you're using, they are definitely more concrete types. So start over and ask the real question. I bet it looks something like this: "I have items in a ListView that represent data. I'd like to write some code that looks for every checked item and moves it to a different control. I'm having trouble figuring out how to do this." This is *really easy* if you're writing code "the good way" with a pattern like MVVM. It's more difficult but possible if you're writing code "the bad way" and you're just cramming data into the controls with no models to represent it. Either way, the trick in UI Frameworks tends to be a surprise requirement. "Items inside controls that display collections care about their parent, and generally have rules about how you move them around." For example, IIRC ListViewItems know who their original parent was and don't like being moved. Solving that problem is easy. To move an item from ListViewA to ListViewB, you: 1. Create a new item using B as the parent. 2. Copy every sub-item from the item in A to the item in B. 3. Delete the item in A. So your general algorithm is going to look like this. var itemsToRemove = new List&lt;WhateverTypeTheItemsInControlAAre&gt;(); foreach (var item in controlA.Items) { var item = controlA.Items[i]; if (&lt;the item is checked&gt;) { var newItem = &lt;a new item for controlB&gt;; // &lt;copy the data from item to newItem&gt; itemsToRemove.Add(item); } } foreach (var toRemove in itemsToRemove) { controlA.Items.Remove(toRemove); } Depending on which controls you're using you'll have to tweak that some. You have to use two loops here, because if you try to remove items from ControlA while a foreach is iterating over it, that foreach will throw an exception. You *could* write it as one loop but I didn't feel like explaining the extra complexity of that approach.
The constructor of a Span requires a void\* (ie. a pointer) which cannot be used without an unsafe context.
right. there are apis that return a span to you. your example is the right call if you are writing apis to expose blocks of memory to otherwise managed code, but your said use case is for _speed and performance_. i'm making an assumption that you are trying to do something as fast as possible, without an api surface as a feature. with that in mind, i don't think span/memory is the right call, and it certainly isn't the intended use case. &gt; why should I choose to read/write data with Span over directly using Pointers i suppose i answered your question: when you intend to expose your functionality to managed code.
One of the constructors requires a pointer. The other two do not require it, and plenty of other types have extension methods to convert them into Spans
I think you are looking at old examples. It seems they moved their examples to a templates repository: [https://github.com/ChilliCream/hotchocolate-templates/blob/master/StarWars/content/StarWars/Startup.cs](https://github.com/ChilliCream/hotchocolate-templates/blob/master/StarWars/content/StarWars/Startup.cs) Slightly different syntax here. Hope this helps.
So I used DnSpy to decompile, and put a break point to find out that the program dynamically creates a dat module from which the program calls methods. Dat module is obfuscated, names all in unicode, unreadable. I tried to pull the module out of the memory, but DnSpy says "decompiler generated variables can't be evaluated." My goal is to remove a method from the program, so that it doesn't get executed. Have you ever experienced this issue, where you want to reverse-engineer an exe that dynamically decrypts an array of uint, and create dat file?
Decompilation is going to be difficult no matter what language it's in, or what experience you have. If it's an actual .NET exe, then use DotPeek, but it's not going to be easy to understand or easy to explore.
Do you need to do this programmatically? if not, (and i'm not sure if this is even what you're talking about) but digicert's utility has an option to export pfx with the full chain. https://www.digicert.com/util/
That templates repo is the old / original example source they had. I appreciate it though.
Yeah, this is almost entirely an exercise, so I'm trying to do this 100% programmatically. There's a good many ways to do this manually, the easiest of which being to simply install all certs in the chain into your current OS, install the PFX (with key) and then export to a PFX hitting the check mark to "include all certificates in chain". But I'm specifically trying to do this programmatically so something like this could be entirely automated. Imagine a large ***closed*** network where systems are set up and torn down on the fly constantly. Also, within this massive network are a series of intermediate and even sub-intermediate certificate "providers". (They get the quotes because currently those providers are manual.) If an authentication client certificate carried its own chain of certs, then the ONLY cert that would be REQUIRED to be on new boxes would be the root CA's. Beyond that, when a user wishes to stand up a new client, they may be able to say "this one needs a client authorization cert" in the automated system, and it would just request a single cert, install it (which automatically installs the intermediates) and everything's kosher. Now, what I COULD do is create my own CA and OCSP services - a massive pain in the ass - or I could have the service that's capable of setting up the boxes ALSO have a certificate that explicitly gives them intermediate CA to generate single-use client-side certificates for each new box. It would then install that client-cert to the new box, and everything would work. I could ALSO have the thing attempt to get some object/custom format (think how .PEMs are formatted) to manually check that the certs don't already exist, and attempt to install them, but I would think something like this would already be built in. Haven't really gotten that far yet, still in the "fooling around and prototyping" phase.
Could you elaborate on this? To elaborate exactly what I'm the functionality is, it's a small library specifically for writing data to and reading data from either a byte array or an IntPtr. And since I need this later for a network library, performance is critical.
If you want maximum performance and you're working with an array of blittable structs, allocate memory off the managed heap (`AllocHGlobal` or similar) and read/write to that. That way the CLR doesn't need to track the array at all. However this comes with the usual problems of unmanaged memory manipulation, i.e. fragmentation, memory leaks, etc. So it's best to allocate a buffer like this once to requirement at the start of the program and not dynamically.
This is what I'm doing, yes. Allocating some memory as an IntPtr and writing to that. I also want this same functionality for a byte array though.
In the real world you get to ask the person who wants a new system questions. &amp;#x200B; I'm not saying don't ask here, there's some great advice below, but if your sponsor (teacher) won't tell you stuff, they're an idiot. Do ask them for details, this is the most critical part of making software.
Thanks! Would really appreciate a solution
Short answer. It's not unusual to move code up and down. If you move the if down or 2 up the code would look very strange because you'd have two vars the same name. It's not allowed. UNLESS 2 is inside another block. In that cause it's two different vars that never exist at the same time even if you move it up or down. public void a(int b) { if (b == 3) { var something = 1; } { var something = 2; //ok } }
This is… a sample app? A project template?
I am developing a curriculum so I can begin teaching C# to people in my country who are interested. I have been documenting the planned coursework, and that has birthed a C# tutorials for beginners website - [https://wellsb.com/csharp/tutorials/beginners/](https://wellsb.com/csharp/tutorials/beginners/) &amp;#x200B; There is still much remaining, but I am trying to get one new lesson written each week. People here in West Africa have a lot of great ideas, and I am hoping this series will empower them to bring their ideas to fruition.
Its a sample app, just provide the environment and a connection string to a PostgreSQL database. The app creates the tables and seeds initial data. Copy and paste your way to a running example in a few minutes!
What have you tried, thought about, or considered?
We're not going to do your homework for you. What have you tried, or what approach do you think you should take?
Getting the span of a managed array is an implicit conversion: ``` byte[] buffer = existingBuffer; Span&lt;byte&gt; managedSpan = buffer; ``` If you are talking about a native array, you do havwe to get the address of the byte array, but that requires `unsafe` rather than `fixed`: ``` IntPtr nativeArray; int length; Span&lt;byte&gt; nativeSpan; unsafe { nativeSpan = new Span&lt;byte&gt;(native.ToPointer(), length); } ```
Alternatively, you could `stackalloc` your buffer of structs without using any unsafe code or heap allocations: ``` Span&lt;MyStruct&gt; buffer = stackalloc MyStruct[length]; ```
But this way, you can only use the span to write bytes. If you create a new span from an existing byte array with the fixed keyword, you can write any struct to the array. fixed (byte* ptr = &amp;dest[offset]) { Span&lt;decimal&gt; decSpan = new Span&lt;decimal&gt;(ptr, 1); decSpan[0] = value; }
There's a little bit of dogma involved. If you hate dogma, that's fine, but it's worth understanding why people adopt it. Unsafe code is hard to write properly. If you aren't careful, you can make things buggier *and* slower. You have to understand a lot about the GC, how pinning affects it, whether or not you should pin, where your memory is located, etc. It is inarguably fast. You can always customize how you use your pointers for your specific context and squeeze out the best possible performance. But it is very hard to be sure you did it right. `Span&lt;T&gt;` handles a lot of that complexity for you and does it in a way that is right every time. It's much faster than arrays for almost every context. It can't be tuned to do really smart things for specific contexts like unsafe code. The cases MS demonstrates Span&lt;T&gt; for tend to be buffer management and string parsing that aren't doing mangnificently complex things like mapping a virtual file in raw memory. They're dealing with stuff that used to be arrays of data types in a way that still looks like arrays of data types but doesn't have to deal with the things that make C# arrays slow in those cases. The reason to use `Span&lt;T&gt;` is because other people are (probably) going to maintain your code and: * 99% of people understand normal arrays. * Fewer than that but still most understand Span&lt;T&gt;. * Very few people are going to get unsafe code right, or even understand how to tell if it's right. If you're writing code that needs nanosecond performance improvements, then by all means use unsafe code. But most of the time "just" a 10x increase is more than enough to turn a problem from "expensive" to "manageable". That you can get 12x with unsafe pointers is often moot if it means you have to pay 50% more to maintain it. TL;DR: Span&lt;T&gt; is idiot-proof unsafe code. "Idiot-proof and fast" is usually acceptable. "Impossible to hire people who can maintain it but fast" isn't so desirable.
Ah, in this case you want to use [`MemoryMarshal.Cast&lt;T&gt;`](https://docs.microsoft.com/en-us/dotnet/api/system.runtime.interopservices.memorymarshal.cast?view=netcore-2.2) ``` Span&lt;decimal&gt; decSpan = MemoryMarshal.Cast(dest); decSpan = value; ```
PHP and Java have been around longer, and are unlikely to be going anywhere anytime soon. NodeJS, Rust and Go have large enough communities to ensure they're unlikely to go anywhere, either. In terms of language/framework, I can't really think of anything that got hugely popular that's not still around. Within the .NET Framework, Microsoft has a pretty terrible reputation for abandoning flagship elements of their ecosystem - Silverlight, Windows Mobile, and a plethora of ASP.NET project types. Now, sure, newer and better things came along to replace those - but if you were a business that had invested tens, or hundreds of millions into them - well, you've now got to spend a ton more rewriting them because Microsoft got bored.
Highly recommend switching to netcore and new csproj format. Sticking to older net framework is extremely limiting now a days and there is little to no reason to use it anymore.
When I look at this code, I see: * Stuff pertaining to the entire quiz. * Stuff pertaining to a single question. If I were to rewrite the above code, I would split it like above.
If you need a server and client interaction then you will need to do a web request to a server listening for that request. You can't save locally from javascript without having a file to download perhaps, and you can't have the C# 'signal' to the page in any way that I can think of currently.
``` var ratePowOwed = Math.Pow(rate,owed); var ratePowN = Math.Pow(rate,5); basecost*((ratePowOwed * (ratePowN - 1)/rate) - 1) ^ ^ ``` Explicitly adding implicit parens may help.
You are correct, assembly refers to the .dll file. But don't confuse it with namespaces. An assembly can contain any namespace. There's no correlation between the two.
No no, there is no server/client operation, like i said the html file is located on the pc itself not even web. Hmm if i can't save locally how can i make c# and the live html file intact with each other? About the signal thing.. Well i'll still will be looking for a way, maybe at least cefsharp has a command for that...
So ur saying this code doest make sense?
Right, but what you are describing is just that. HTML isn't really meant to interact with things local on your machine as that would be dangerous and as such you won't be able to access the local file system directly form the webpage for security reasons. The way you may C# and html interact with each other is a REST API or something like Razor (which may be more up your alley).
cefSharp is just a chromium implementation to run a webpage in a C# application, not to do any interop between the two. Even in something like Chromely you're still hosting a C# rest API to serve the content to the page and receive requests from the page
Lol im not asking anyone to do my homework. Just asking how should can I identify what classes can i make from this code
can you explain in more detail what you are asking?
I love how Jamie King explains things: [https://www.youtube.com/watch?v=-9YcKk5WqyQ&amp;list=PL9B5E4C37F7B234A8&amp;index=2](https://www.youtube.com/watch?v=-9YcKk5WqyQ&amp;list=PL9B5E4C37F7B234A8&amp;index=2)
OP: https://www.youtube.com/watch?v=G7RgN9ijwE4
From what i understood the rest api way over my league and requires me to rewrite the code but i'll look into that razer thing now. About the cefSharp thing, well... Crap. I'll ask in few forums just to be safe. Thank you
Essentially the only sort of two-way communication you can feasibly do over html is an HTTP request or WebSockets (which is even more complicated)
Are you asking about .net core?
This reminded me of [Little fluffy clouds](https://youtu.be/8Ecdn5SGT1E?t=26)
In order of highest to least concern: | A successful invoice export --,-- should send an email to the customer --,-- whose invoice was exported. What are suitable places for calling the SendEmail function? (Multiple choice) Delete the first two commas. With the first comma, the sentence is invalid: "A successful invoice export whose invoice was exported." is invalid. With the second comma, "whose invoice was exported" modifies the noun "export", not customer. I also disagree with the answer for that question. If sending the email is the responsibility of the export (as the question states), then the caller of `Export()` should not be required to remember to send the email. | ``` if (sum == 0) { Console.WriteLine("No sum."); } else { Console.WriteLine($"Sum ={sum}"); } ``` | answer: Console.WriteLine is repeated twice. Are you really suggesting ``` string message; if (sum == 0) { message = "No sum."; } else { message = $"Sum ={sum}"; } Console.WriteLine(message); ``` is cleaner? I would disagree. I am much more concerned that `sum == 0` is treated as a special case without any context of why it should be. | Which lines contain "Magic Numbers"?(Multiple choice) I understand you are trying to see if the test taker knows that 1 may or may not be magic, but line 33 is so nonsensical I could not tell. A comment like `// Add the foo value`, perhaps along with a second line `sum += 5; // Add the bar value` would help takers clue into what was happening. | Environment class contains properties such as a server name and database. You need to pass those two properties to LogDbInfo(..) method. What parameters will that method have? (Multiple choice) I don't think `LogDbInfo(environment)` looks that weird, especially if you include both overloads and implement like so: ``` public void LogDbInfo(Environment environment) { LogDbInfo(environment.serverName, environment.database); } ``` The one parameter method also has the benefit not not requiring writers to remember the order of the parameters. | What's wrong with a namespace called Console? I think we agree on the reasoning, but the only thing "reserved" are keywords, which Console is not.
Yep. You can call them from powershell or dos scriptts. So you could build a better interface to Git for example.
You should be able to do this with BouncyCastle. The library isn't particularly well documented, but you might find the source of [Pkcs12Store](https://github.com/kerryjiang/BouncyCastle.Crypto/blob/master/Crypto/pkcs/Pkcs12Store.cs) helpful.
UWP has a pretty big POS namespace that you can find with a [simple search](https://duckduckgo.com/?q=uwp+pos). I'm not sure if it's any better, and it would definitely restrict you to Windows 8.1+. Though some portions might be restricted to Windows 10+. It's free and it's designed for this sort of thing. No idea how good the hardware support is, though. And if you need older OS support, you'd have to abstract the switch. Don't forget you can update POS for .NET to 1.14.1. Not sure if that will help, but it might add additional device support if it's just a few devices that are your blocker. OPOS drivers are accessible through COM, so you can just do COM interop yourself if you need to. That's likely to be a lot of work though. Similarly, you can use JPOS drivers if you wrote a Java hardware host process and set up IPC. That opens you up to a wealth of java libraries, but then you'd have to engineer the communications, load IKVM.net, or port the libraries. Some of the hardware doesn't need vastly different implementations. OPOS printers are a good example, since most of the less popular ones also implement Epson's ESC/POS.
Ooo, also, if you build a windows service you can debug it if it's also a console app :)
This code makes sense. I was just trying to point out how you may want to turn it into classes.
Yeah I mis-typed I meant .Net Core
Well you actually remember your dreams?
let's just rule out the possibility that the directory will be deleted, my problem is that, if i run the function ReadFromFolder() when clicking the button, right before executing the watch event, the ReadFromFolder() will be executed but the watch event will just pass just like nothing happened. if i use async will it work?
The assembly is the DLL file. So even if you make a class that has the same namespace, it won't be in the same library thus can't access internal members.
Well, for starters you are supposed to enclose intrinsics with their associated IsSupported property (in your case Avx2.IsSupported) and optimally provide a fallback that works the same but without instrinsics. I recommend reading [this blog post](https://fiigii.com/2019/03/03/Hardware-intrinsic-in-NET-Core-3-0-Introduction/) as there are a lot of useful informations in it. :)
Removed: Spam. Please review and follow the [guidelines for self-promotion on reddit.](https://www.reddit.com/wiki/selfpromotion)
My guess is the fact that you have one question (#4) about PascalCase notation and naming convention and then another that ignores some naming convention in favor of simplifying (#8). And then #11, which I feel like intentionally misleads claiming a number of items wrong but honestly that's a whole method that would be cleaner to replace with System.Ling.Avg. For myself, I also disliked that you had questions that intentionally made all answers the right answers. And ones that are very open ended, like the one of just "What is wrong with this code". I feel like it becomes subjective at that point.
[.NET Rocks](https://dotnetrocks.com/) is a nice one because they always have interesting guests who know what they're talking about and help the listener learn.
Tried to use Avalonia on my Mac earlier this week and none of the samples would run. Such a shame as I had hoped I could use this for a little project I’ve got.
Coding Blocks is great!!
Hi! If you have some time, do chat us on our Gitter chatroom ([https://gitter.im/AvaloniaUI/Avalonia](https://gitter.im/AvaloniaUI/Avalonia)) so that we can help you out on whatever prevents Avalonia from running in your Mac :)
Sadly it is no longer focused on .net Used to be pretty good.
Heretic, you have blasphemed against the holy tenets, and now you must suffer the karma consequences! You are not going to get a constructive discussion here, because you have offended the religious beliefs of the guy you are talking to. He will find and assault any flaw in anything you say just to have a reason to attack you, and people who ~~think~~feel like he does will downvote you for the same reasons--no matter what you say. It is ironic, really, since Reddit votes are ostensibly meant to promote *constructive* comments (like discussing the details of features in C# as you are) while discouraging the *unconstructive* sort (like accusing people of running off on tangents for no meaningful reason, and so on). With people like that, all you can do is refuse to engage. FWIW, I applaud you wanting to know more about the language you are using, and I agree with the first guy you responded to in this particular comment chain.
First, thank you very much for your feedback. I don't understand how comma changes the point of a question so much. Export() should not send email and you can achieve this via an event (preferably) or via a subsequent function call after it. Calling Export() and SendEmail() one after another is just a two high level function calls, and the context will still do one thing. Event is a perfect decouple though. The example of console might be better, without ambiguity. Also, with a more dirty scenario. When you have duplicate code in 2 places you might not realise the smell of it. But when there is more repetition (I myself never leave something that repeats 3+ times,for 2 it depends ), then you refactor. If you suddenly decided to log to a file, you will change two places. Not so clean, right? Your argument is also valid, as the example is stupid and you can find more problems in it. Magic numbers- I agree! LogDbInfo(..) method illustrates the classic banana monkey jungle problem. In cases where you have a ton of input needed, I would agree that passing Environment would be better. But in this case we can show a clearer intention with requesting just the two parameters. Console - I agree.
It does! But that's why I take a look at it myself. BTW, for the question with avg you instantly get full points if you say that. For open questions I don't require my way of thinking, as long as something that makes sense is said, some or all or more than all points will be given.
thanks for sharing
Powershell's [Export-PfxCertificate](https://docs.microsoft.com/en-us/powershell/module/pkiclient/export-pfxcertificate) might do what you need with the `-ChainOption` parameter? I don't have a good way to verify that right now but if that does it you could either spawn powershell.exe or if you wanted to get really fancy, use `System.Management.Automation` to run a simple script
https://dotnetrocks.com/ https://cynicaldeveloper.com/ https://nodogmapodcast.bryanhogan.net/ https://www.codingblocks.net/
Have a link?
Ty I'll check them out!
This is a very clear cut answer and exactly what I needed Thanks!
https://www.dotnetbytes.fm/ is also on my list allthough they have not posted a new episode in over a month
Wouldn’t you expect it to throw ArgumentException?
I just started listening to _[Merge Conflict](https://www.mergeconflict.fm)_ this past week. I'm not sure yet if it is in my "top" list yet because I've only listened to one episode so far!
+1 for [CodingBlocks.NET](https://overcast.fm/itunes769189585/coding-blocks)
About the simd stuff: as someone said, yes you wrap around issupported. Don't use stream load here (non temporal). Also, avx2 basically has no overhead on unaligned loads so you won't gain anything from aligning here. And why not just use indexof or contains? I'm sure there some general "memcmp"-esque method that is already simd optimized. And why the gotos? Are they necessary for some specific optimization?
Thanks, I have been following performance reliability vlog...and actually picked up few good gems!
visual-studio-toolbox-hd-channel-9
thanks, nice resource
I'm currently using unifiedpos/OPOS. My market is small retail businesses, coffees, restaurants, etc.. that's why I have to support as much hardware as possible.
Would you mind sharing how much of a cost difference there was between your JS API, 'classic' ASP.Net Core API and serverless ASP.Net Core API?
I'd expect that, but I'd be disappointed
Span&lt;&gt; is currently required for some Vector&lt;&gt; constructors, which don't accept void pointers yet and Span&lt;&gt; also is more convenient for passing data around since void pointers don't have a Count/Length property. However, Span&lt;&gt; is not included in the regular .NET framework yet and won't be until 2020 or so (.NET 5). For low level stuff that doesn't pass data around or uses Vector&lt;&gt; there is no reason to use Span&lt;&gt;. Span&lt;&gt; is an extra level of indirection and will always be slightly slower than using void pointers directly (unless they purposely slow down void pointers, which is unlikely).
Base64?
Sure I get the IsSupported part, that is the easiest part though and I elided it here until I am sure I am using the right simd stuff. Do you have a reason to backup your claim about nontemporal and nonaligned? I have Benchmarks for every iteration I did, and having loads nontemporal as well as aligned bring a measurable performance benefit on larger workloads. There already was a naive implementation, but my benchmarks show ms beating the performance of the naive approach by the factor 4. For the naive approach it does not seem to generate simd instructions. Lastly, the gotos are necessary. With them the assembly is more straightforward as well as shorter, which brand a considerable benefit (also have benchmarks to backup perf difference)
Is there any side effects of updated. Such as incompatibility etc. ?
There's this: https://www.google.ca/amp/s/csharp.christiannagel.com/2019/01/30/lazyloading/amp/ It loads as a EF proxy and lets you lazy-load transparently, no Includes. Not sure about performance though.
&gt;However, Span&lt;&gt; is not included in the regular .NET framework yet and won't be until 2020 or so (.NET 5). Just to mention that **.NET 5** is not the "full framework" but rather **.NET Core**. They wanted to "clean up" the versioning mess.
I made a service to process jsons that get written to a subdirectory. In a while loop I check for subdirectories to create tasks. The tasks have a while loop to check for a 'nextfile'. Theres about 500 subdirectories with simple task.delay()s set to 2 seconds. I googled a bit about FileSystemWatcher missing events. Im sure youve checked [the filters](https://stackoverflow.com/a/22363609), [the event timing](https://stackoverflow.com/a/33048620), [the scope](https://stackoverflow.com/a/52517654).. Looking back at your code, how is '**private void Watch(string path)**' called? Your filesystemwatcher is in a using block and gets disposed.. hmm Either that or its some timing/buffer issue where the FSW simply doesnt work because of the thread it is running on, look at [SalizarMarxx's comment](https://www.reddit.com/r/csharp/comments/bpov8k/filesystemwatcher_how_to_watch_if_there_is_file/enwzkg7/). But if you're gonna thread the FSW.. you might want to look back at timers. Let me warn you about the [System.Forms.Timer](https://social.msdn.microsoft.com/Forums/vstudio/en-US/84b1bf62-129d-4e79-b45b-73ebf1b79434/systemwindowsformstimer-does-not-fire?forum=csharpgeneral), it also has a problem with events not firing. '**Application.DoEvents()**' is suggested. Tough if '**DoEvents()**' is needed, button click events shouldn't even be working. Looking back at '**private void btnHousekeep_Click(object sender, EventArgs e)**'.. It looks like your FSW is only running for a supershort time when pressing the housekeep button.. It should be created OnLoad of your window and kept in a *private* field. Your Housekeep button should dispose the current FSW and create a new FSW if you want to change the directory it watches. But if you had a timer which calls '**EnumerateFiles()**', you'd only change a '**private string path**' to change the directory it watches.
Awesome list, thanks!
I just release a presentation on the advantages of t shaped testing instead of pyramid testing: [https://www.youtube.com/watch?v=zdfw6oRGHOE](https://www.youtube.com/watch?v=zdfw6oRGHOE) and an open source nuget package to help you do better system testing: [https://github.com/AlanCS/SystemTestingTools](https://github.com/AlanCS/SystemTestingTools)
&gt; either a byte array or an IntPtr This sounds perfectly like a use-case for Span. You can make a single function that accepts Span, and user of your library can call it with whatever storage they use.
To add to what Kirides said, Span will never be in .NET Framework. Framework is basically dead after 4.8.
Love this one. It's usually more Xamarin / Mobile focused though.
Azure has a free tier for simple test websites. Besides that you will benefit most from serverless if it matches your architecture. If you just move classic APIs to serverless you won't benefit much from the capabilities of the technology, potentially even suffer due to the cold startups. An event based architecture works best with serverless, because then the functions run very short (just handling the event) and scale very well (the amount of running functions is always the amount of events to handle).
I've used [ExcelDataReader](https://github.com/ExcelDataReader/ExcelDataReader) for working with Excel files, so far I haven't run into any issues.
I will try the api.
Sure, deploying the api on an EC2 virtual machine running ASP.Net Core 1.0 was costing approximately $50/month. After going serverless, it costs next to nothing, like $3/month. I never really got off the ground on a JS Api.
PDF extraction is actually a really tough problem still. My last company worked with a number of the tools you've probably seen, but we found actually the best extractor was, by far, TIKA, which is a Java service. If you can, I'd recommend just putting it in a tiny Java microservice and calling it with PDFs you want the extraction from. Alternatively you can execute a Java application directly in your C# code, or you could use this NuGet package directly: https://www.nuget.org/packages/TikaOnDotNet/ Note, that last one works, and we used it at my last job, but it's built on IKVM, which is a jvm implementation inside of the CLR, and the project is dead and not getting migrated to dotnet core.
Thanks a lot !
I would prefer not to have to shell out to Powershell to accomplish this.
I'm unable to use 3rd party tools with this client.
Try PdfSharp for PDF and EPPlus for Excel
I love his channel, he is a great teacher
Thank you, I tried to focus on the lowering part... because the C# documentation does a great job of explaining how to use it
It should be still human readable. I just want to prevent XSS and similar attacks
Unsafe.As does what your reinterpret cast does
TikaOnDotNet works well - expect like 60MB of additional references. You can try PDFSharp but you need to put up the text from small pieces and this is not included in main library.
For Excel I'm using EPPlus. It's only for the newer xlsx format though.
Ok, that makes sense. &amp;#x200B; (also turns out that the maintainer didn't realize the published package was bad due to some planned/upcoming updates)
If you are running it through Visual Studio, under properties there is a launchSettings.json file, which defines the ports to run on when debugging.
Thats correct. But the setting is ignored, its always port 5000/5001
Singleton is tricky this way. It seems to have a valid use case. But I would caution you to think longer term. What if this requirement changes? That's a lot of places top update, breaking the single responsibility principle. How are you going to unit test this? It sounds like it would be turn into am integration test because of this. Instead, you should make it a singleton in that it is the only instance created but provide it as a parameter.
Do you need more than one? If not, go for it. Don't knock the singleton :) &amp;#x200B; If you're not doing DI yet, have a poke at that. Classes are commonly registered as either a singleton or instance, the former returning the same instance (duh) and the latter returning a new instance.
Yeah, but .NET 5/Core will pretty much be the new default .NET framework which is installed on everyone's computer. This makes Span&lt;&gt; and other .NET Core features a lot more attractive than they currently are.
 [https://dev.azure.com/bjth/\_git/DummyWindowsService](https://dev.azure.com/bjth/_git/DummyWindowsService) &amp;#x200B; That Repo seems to work for me, have set the port to 5005 / 5006
I don't think it'll be on everyone's computer. Where did you read that? Regardless, since apps can be shipped with their own run-time, it largely does not matter.
I personally wouldn't use a Singleton for something like this. I would use it for something discrete and static. Keep in mind that the only thing true about requirements is that they change.
PDF parsing: * [Pdfsharp (Apache 2.0)](https://github.com/empira/PDFsharp) * [PdfPig (Apache 2.0)](https://github.com/UglyToad/PdfPig) * [docnet (MIT)](https://github.com/GowenGit/docnet) * [iTextSharp v4 (LGPL)](https://github.com/VahidN/iTextSharp.LGPLv2.Core) * [iTextSharp v7 (AGPL + commercial)](https://github.com/itext/itext7-dotnet) Excel parsing: * [Open XML SDK (MIT)](https://github.com/OfficeDev/Open-XML-SDK) * [EPPlus](https://github.com/JanKallman/EPPlus)
A few blogs I haven't heard of before. Thank you.
I have been using ABCPDF for years. It is very affordable and works great. If you find a bug they will fix it fast.
To answer this question you have to answer, "Why would it be inappropriate to use a Singleton?" I don't like Singletons, but it's not good to use that as the reason. What I don't tend to like about Singletons is they complicate unit testing. Since they are shared state, you have to be much more careful about your test setup and cleanup than you would if it were an injected instance. Since they are (usually) static, you can't fake or mock them in a test environment. And it is much harder to answer the question, "What uses this type?" when it's a static singleton, because you can't just search for constructors that take it. On the other hand, some use cases are still acceptable with a singleton. Stuff that does "cross-cutting concerns" like logging are usually good candidates. You'll also note that logging is a service almost every type is likely to use. That's called a "cross-cutting" concern and it's a situation where static Singletons can work. Finally, logging isn't generally a thing we want to test so it doesn't really impact our test code. Also, keep in mind if it's "difficult to pass instances around" something is wrong. You might be able to use a DI container to assist with this. My applications have classes that sometimes need 5+ constructor parameters to do their job, but everything is resolved by the DI container so I never deal with those. That in and of itself has some rules and smells, but it hides singletons behind instance logic which can let you have the best of both worlds. **So what I would do in my project:** `Server` would be abstracted as `IServer`. I'd go ahead and commit to every class taking it as a parameter. I use ViewModel-first MVVM frameworks so I'll never know. At IoC bootstrapping time, I'd register Server as a single-instance concretion for the `IServer` abstraction. Then, in tests, if I need to mock `IServer` I can! To me the decision hinges on if you're writing unit tests for the things that use Server and want to mock it. In my opinion, you should write tests for that logic. I think that means you simply can't afford a static Singleton. The alternative is the only way to answer, "What does the application do if the server dies here?" is a string of recompiles with debug code that throws and manual tests.
Would a singleton manager class work? the class has the ability to manage several instances within itself but it it self is a singleton. I want to almost completely decouple all the server from the viewmodels.
Re IKVM, we're in the gap period where there's no good option for Core. NET 5 in Nov 2020 is supposed to come with Java interop.
[https://www.mergeconflict.fm/](https://www.mergeconflict.fm/) [https://www.codingblocks.net/](https://www.codingblocks.net/) [https://nodogmapodcast.bryanhogan.net/](https://nodogmapodcast.bryanhogan.net/) [https://msdevshow.com/](https://msdevshow.com/) [https://www.dotnetrocks.com/](https://www.dotnetrocks.com/)
The PDFs I extract data from are typically generated from templates, so the data I need is usually always in the same place. For that I use [PDFClown](https://pdfclown.org/). You can create a box with X,Y coordinates and extract the text in that box. For Excel I always end up using [ClosedXML](https://github.com/ClosedXML/ClosedXML).
If I'm reading RFCs right, the tokens in a content-disposition header are things you will be writing, and they are the only things that can't contain special characters. But the *values* for each thing are `quoted-string` in the grammar. That allows any character except `"`. So lets say your header is: Content-Disposition: form-data; name="field1"; filename="example.txt" I feel like the parts of this input that are defined by *you* and thus need no encoding are: * Content-Disposition: * form-data; * name= * filename= The parts that are user-supplied are: * field1 * example.txt But so long as those inputs don't contain quotes, any character is valid. If you call either UrlEncode or HtmlEncode, they'll escape quote characters. As far as I can tell in the RFCs, a plus sign is *not* invalid for a `quoted-string` value.
While already many great replies, it should also be very easy to generate [comma-seperated value](https://en.wikipedia.org/wiki/Comma-separated_values) files (CSVs). These are quite universal and can be opened by Excel and almost any other data management program (OpenOffice/SPSS etc).
I love Merge Conflict too. I don't do mobile development, but I learn a lot from these guys!
So you would use the IOC container to pass the single instance of the server interface to the viewmodels?
[6 Figure Developer Podcast](https://6figuredev.com) has pretty good .Net content. Terrible name though!
That sounds like the Service Locator pattern. It's doable but has it's own drawbacks. It's better than singleton in my opinion.
Too bad he hasn't posted new video's in a few years.
ClosedXML is quite good for Excel things.
I got mine working with a setup like this: ```xml &lt;Target Name="BuildVueFrontend" AfterTargets="Publish"&gt; &lt;Exec Command="yarn install" WorkingDirectory="Frontend"&gt;&lt;/Exec&gt; &lt;Exec Command="yarn build" WorkingDirectory="Frontend"&gt;&lt;/Exec&gt; &lt;ItemGroup&gt; &lt;MySourceFiles Include="Frontend\dist\**\*" /&gt; &lt;/ItemGroup&gt; &lt;Copy SourceFiles="@(MySourceFiles)" DestinationFolder="$(PublishDir)wwwroot\client\%(RecursiveDir)" OverwriteReadOnlyFiles="true" /&gt; &lt;/Target&gt; ``` That will run `yarn install`, followed by `yarn build` in the project's Frontend directory, then copy the newly-built files from Frontend/dist to the publish dir's wwwroot/client folder.
Follow up question, would it be better to have none of the viewmodels access the server directly and instead have it shoot events to viewmodels when a tag they are subscribed to changes?
Most IoC/DI containers allow you to register a 'Singleton' so yes.
copy and pasting my question i had to someone else would it be better to have none of the viewmodels access the server directly and instead have it shoot events to viewmodels when a tag they are subscribed to changes?
That's an interesting idea but would depend on your architecture. If your viewmodels are web pages this would require some kind of persistent connection (WebSocket/NServiceBus) in order to notify subscribers. If you are doing typical MVC then injecting the singleton is going to be easier.
Same person. See response below.
The viewmodels are WPF XAML. The OPC server already operates on tag changed events just the nature of the spec, as actually reading a tag is an expensive operation.
Why wouldn't it be? People will just install the new version once programs require it, like the current .NET framework. And sooner or later it will come included with the latest Windows version or Linux distribution. This isn't the case with the current .NET Core since they're always new versions coming out and shipping your programs with hundreds of extra dlls is not very attractive.
I think that’s honestly the only way. Apple just (hilariously) claimed they don’t have a monopoly with their App Store but you are required to use a Mac to develop for Apple devices, and you can only get apps from their App Store. You could use a VM but that’s also against their rules. So unfortunately unless you have a friend with a Mac or you get one cheap off craigslist you’re kinda screwed.
I really appreciated this. It is refreshing to see code screenshots and screenshots of the structure of a real world product. So many blogs and posts show snippets of code from an ideal use case of their library or example and not what its really like looking into the depths of a legacy codebase knowing you have to roll up your sleeves and refactor a huge chunk of it. And explaining the bugs that come as a result.
At least they stopped the 6 minutes of unskippable ads for music to code by. In a world where even youtube allows you to skip ads after 10 seconds, I'm not going to listen to a full infomercial before each podcast.
https://docs.microsoft.com/en-us/dotnet/api/microsoft.net.http.headers.contentdispositionheadervalue https://docs.microsoft.com/en-us/dotnet/api/system.net.http.headers.contentdispositionheadervalue
EPPlus is hands down awesome. Works great, simple to use, and faster than using the office interops.
&gt; People will just install the new version once programs require it They really won't. Maintaining a single shared framework in the OS is an anti-pattern. Presenters at BUILD have made this abundantly clear. People who maintain .NET Core binaries typically `publish` them with all dependencies bundled in. I've not yet seen one that ships just the `build` assets and expected you to have the right version of Core installed. In those scenarios, they're usually just shipping source code. Are you aware of any examples to the contrary? &gt; hundreds of extra dlls is not very attractive It's far less attractive than telling your end users to install something _else_ first before using your software.
I agree with the Craigslist idea. Look for a cheap Mac mini. You don't need much hardware but you can't build for iOS on the PC.
Re-iterating the other comments on here, iOS development is really difficult without owning a Mac. In order to run the Xamarin iOS project you will need to have XCode, which in turn will require Mac software. &amp;#x200B; You can get some good deals on used Mac products online, especially with Facebook Marketplace and Craiglist. You can get by with a Mac Mini, which will typically be the cheapest Mac product you'll find online.
Regardless what people think, Apple's market status doesn't represent a monopoly from law point of view.
Ensure you are not accidentally doing integer math when you expect to be doing floating point math.
You can use a VM.
I've used LINQ to just scrape the entire work into a giant dataset super quick and then query or parse through it from there. It seems a lot faster than interop but I definitely think both approaches have different advantages depending on how granular or inconsistent your data is.
&gt; It's far more attractive than telling your end users to install something else first before using your software. True, but using the standard framework that most users already have installed is even more attractive.
I really like Hanselminutes
I used to listen to that religiously but now every time I pull up an episode it's (a) something I don't care about (B) a bunch of references to people I don't know about and (C) a bunch of plugs for conferences and conventions I'm not attending.
.NET 5 is not going to go out as an update for current .NET Framework 4.8 users. I feel like there is some disconnect in this comment. .NET 5 is a new and (largely) incompatible product, which adopts .NET Core's approach of having developers install the SDKs/runtimes while end users just download/install a complete application package. Personally, I hope to never touch .NET Framework again. Core for life.
How does EPPlus compare to openXml ?
You didn't post the contents of your launchsettings.json file so I can't really comment on that. Just to make sure, you should be aware that there are usually two sections that set URLs in that file - one for running under IIS Express and one for running the app as a console using Kestrel. Speaking of - which configuration are you having this issue with? I'm assuming the IIS Express config so have you tried running it as a console app from Visual Studio? You should also be able to set the URL using the ASPNETCORE_URLS environment variable. You can specify both an HTTP and an HTTPS connection in this variable if appropriate. One final note: The certificate that IIS Express uses for HTTPS hosting only supports a limited set of ports - those from 44300 through 44399. Trying to host HTTPS traffic under IIS Express using anything other than a port from that set requires advanced settings.
If you are using Forms with very little to no iOS specific code you might be able to get away with using Microsoft's App Center. You only get 4hrs of build time for free, and you can't test and debug in real time. It would be a hassle and inconvenient, but as they say, "you get what you pay for". On the plus side you'd also then be able to get to integrate your build process with the iOS and Android stores reducing the amount of work you need to do.
Rule of thumb: If the code using the class needs to know it's a singleton, it shouldn't be a singleton. Rule of use: Singleton is **not** a substitute for static variables, and doesn't magically make it OK to use mutable static state. Singleton is common in the Dependency Injection pattern with constructor injection. Why? Because the consuming code doesn't need to know or care that it's a Singleton and you can change it in one place if it later becomes necessary. Things that start out as a Singleton often become "Doubletons" or shit-not-at-all-a-Singleton as the requirements evolve. If the consuming code assumes the instance is a Singleton, this is disastrous for your ability to update the code. A Singleton must be thread-safe in *all* situations. This is easy in initialize-once-then-read-only scenarios (like most Factory instances), but becomes incredibly difficult to do without performance-killing locking and/or subtle bugs as the state management complexity grows. RE: your specific case I'm not sure what your case is, from the description. Having a Singleton doesn't automatically make it possible to share a single connection with multiple views! You still have multi-threading contention to deal with. Maybe you can encapsulate all that logic into the Singleton instance, but you still have to deal with it.
Without better knowledge about what the game is, or the platforms it's running on, the safest bet is Unity: https://unity.com/ It has built-in networking libraries and a smorgasbord of free (or cheap) third party components that are mostly plug-and-play.
&gt; I don't understand how comma changes the point of a question so much. The commas, as written, simply make the sentence grammatically incorrect. The first comma separates the subject "export" and the verb "should". [A comma should not separate a subject from its verb](https://www.grammarly.com/blog/comma/#comma-subject-verb). The second comma separates the relative clause "whose invoice was exported" from the noun "customer". Because it defines which customer, rather than giving additional information about an already well defined customer, it is a [defining relative clause and should not be separated by a comma](https://www.ef.edu/english-resources/english-grammar/relative-clauses/). The problem with the answers is you don't have "right" and "wrong", you have three levels: 1 Inside Export() method, at the end of it * Wrong, violates the single responsibility principle 2 Outside Export() method, after it * Maybe? Properly separates concerns, but callers of Export() have to remember to also call SendEmail(). 3 Export() should fire OnInvoiceExportComplete and the event handled outside * Right. The test takers have to guess how strict about clean code the test wants, which means you are testing how well they guess, rather than how well they know clean code. If the question asked the taker to rank the alternatives, the answer would be clear, but just asking to select one, the answer is not clear.
[Set operations](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/concepts/linq/set-operations) class KeyValue { public string Letter { get; set; } public string Value { get; set; } public bool Equals(KeyValue other) { if (other is null) return false; return this.Letter == other.Letter &amp;&amp; this.Value == other.Value; } } var result = B.Except(A)
Thank you, that was exactly was I was hoping! Didn't seem right to me that you can only access that functionality with a method that breaks intellisense in visual studio!
Implement [`IEquatable&lt;T&gt;`](https://docs.microsoft.com/en-us/dotnet/api/system.iequatable-1) or write an [`IEqualityComparer&lt;T&gt;`](https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.iequalitycomparer-1) (and read the implementation nodes esp. for `GetHashCode`) to make methods like `Contains` work on arbitrary objects. Also [`Enumerable.Except`](https://docs.microsoft.com/en-us/dotnet/api/system.linq.enumerable.except) or `HashSet&lt;T&gt;` will be much more performant than `Where(!x.Contains)`.
&gt; So you would use the IOC container to pass the single instance of the server interface to the viewmodels? Yes, that is what I'd do. &gt; would it be better to have none of the viewmodels access the server directly and instead have it shoot events to viewmodels when a tag they are subscribed to changes? That is a different architecture, but it works! I would prefer to see it done with a mesage bus or some other Event Aggregator pattern. That satisfies testability because when you want to test, "If the server says this, this viewmodel updates that way", you can simulate that by calling the methods/sending the messages in a test.
What does serverless mean in this case, excuse my ignorance? Does it mean on web servers are used in building the web api, how is this possible or beneficial, what purposes does it serve?
sorry, but what does serverless mean? I mean obviously it's running on a server and cpu some where.
I should of specified that, sorry. I am using Windows Form in Visual Studio (not unity)
I understand .NET 5 is not compatible with .NET Framework 4 applications, like it was the case with .NET Framework 3 and 4. This didn't keep people from installing the newer version though. And if you currently target something like .NET 4.5 or 4.6 it will essentially run on every Windows PC, because even graphics drivers require these to be installed nowadays. As far as I understand from their blog posts, they also haven't decided on the preferred build model yet. But I'm pretty sure 70MB Hello World applications are not the goal. It's also not needed when there's only one new version each year, especially not in the case they make new versions backwards-compatible. This would make for a situation like we currently have with the regular .NET Framework.
What stops you from using Unity?
The book is only a reference, it was meant to be a guide for programmers when they have to lookup something. I think it's the wrong one if you want a practice-as-you-go approach. I think something like [this](https://www.oreilly.com/library/view/beginning-c-60/9781119096689/) would be more suited for you.
I can use the Unity network library with Windows Form? :o
No, I mean, what makes you use Windows Forms and not Unity if you want to make games?
WinForms isn't really made for any game larger in scope than a "simple" chess or minesweeper game. You'd be much better off using Unity, like FizxiMan said. There are a ton of tutorials online and you'll save yourself a lot of nerves choosing that instead of WinForms.
Cheapest legal way would be getting macos vps. The free not so legal way would be a virtual machine. Good luck
MonoGame maybe?
I know I'm late, but it's disappointing that Complete Developer Podcast hasn't been mentioned. It's very well done and we'll rounded touching on a lot of different topics that are useful for devs, not just pure .Net stuff.
Yes, this is using reflection, but it is possible. That is a big difference from Java, where it is not possible to find the type of `T` even with reflection.
For WPF look at messaging instead of events as it decouples the classes. DI is also really good for WPF.
You'd probably want to use web sockets or signalR
You could add any header you want to (as long as it isn't already reserved). Does it have to be content disposition?
This seems to assume that reference are always 64-bit wide, would probably make more sense to use `IntPtr` instead of `long`.
https://github.com/lidgren/lidgren-network-gen3
I'd be tempted to use SignalR in this case. One person is elected to be the "host" and the other connects. There is, of course, an entire lifetime of firewalls, routing and other networking concerns that your users will have to navigate to get connected though. This is a HARD problem.
Why would you be disappointed? Null is an invalid argument, hence the method should throw ArgumentException.
FYI - when you rebuild, inside your project solution folder is a 'bin' folder based on how you targeted the build (release or debug) it should have the required components etc required for the EXE to run where ever as well as the EXE.
Do not do \` Array errors = DeviceInfo.getErrors(); \` Rather, use the proper type used, such as \`Error\[\]\` (if it returned that) &amp;#x200B; Also, this seems a nasty SDK - was it hastily ported from a different lang? Doesn't look C#-y, I notice getters rather than properties
Wrap your try-catch in a 'using (var connection = new SqlConnection(connectionString) { your code here } This will handle disposing the SqlConnection so you don't have to worry about that. As for using separate connections, it really isn't a problem since they're being disposed. Where you start running into issues is when you have connections left open and your connection pool starts to fill up. If you need a reusable connection, instantiate 'connection' at the class level and use it throughout without the 'using' statement.
Depending on the type of game you are building, WinForms might not be your best bet. It might be like trying to fit a square peg in a round hole. If you plan to use any kind of graphics you will find WinForms to be extremely limiting and will fight you every step of the way. What is limiting you to WinForms?
Here is how I usually write it: &amp;#x200B; `internal void Select()` `{` `string quiery = "SELECT * from [dbo].[StudentsTable]";` `try` `{` `using (SqlConnection connection = new SqlConnection(connectionString))` `{` [`connection.Open`](https://connection.Open)`();` &amp;#x200B; `using (SqlCommand command = new SqlCommand(quiery, connection))` `{` `using (SqlDataReader reader = command.ExecuteReader())` `{` &amp;#x200B; `while (`[`reader.Read`](https://reader.Read)`())` `{` `Console.WriteLine($@"{reader.GetInt32(0)} \t` `{reader.GetString(1)} \t` `{reader.GetDateTime(2)}");` `}` `reader.Close();` `}` `}` `}` `}` `catch (SqlException ex)` `{` `Console.WriteLine(ex.Message);` `}` `}` &amp;#x200B; Notes: SqlConnection will pool existing database connection under the hood. Even calling [connection.Open](https://connection.Open)() many times, as long as your connection string doesn't change, it will internally reuse an already running connection. That also means that calling connection.Close() doesn't do much because it is internally keeping it opened. Use the "using" clause for each IDisposable objects.
...going to try this out this week
Honestly have no idea, and yeah the SDK is pretty terrible almost no documentation.
Awesome, found the application in the bin folder. Yeah, I wanted a way for the user to exit when the protocols finish running through the program.
The best options I've found so far is to buy a cheap 2011+ Mac Mini, or using something like MacinCloud services for around 20-50/ month, depending on your needs and use case. This is by far the most annoying part of being sold on a "Hybrid" framework, only to find Apple has made it impossible for developers to build without a legal copy of their MAC OS. Of note, some people have found a way to run MAC OS on their PC. Look into FrankinMacs, you might get lucky...
A couple of pointers: 1. Put things reading from db/writing to console in separate methods. 2. Inherit your class from IDisposable. Open the connection in the constructor and close/dispose it in the Dispose method 3. Create another class that represents the data you get from your database. Judging by what you have posted, you'd have a class which has an int, string and datetime properties. 4. Make use of overrides when outputting your objects from db to console. Something like [this](https://dotnetfiddle.net/dy3zFr). It's only a very basic example (\_connection.Open() shouldn't really be in constructor, for example) but I think taking baby steps is important when learning to code. You are basically on the right track with trying to keep things tidy, you just need to learn how to actually do that. Don't worry about mistakes, there is worse code out there than what you have. ;) Good luck.
Every time I've used singleton like things in a non-one-off situations, I've come to regret it. If you have dependency injection framework available, use it.
Similar to python, c# has 'scope'. When execution of a void function reaches the end it stops. The program would automatically exit.
I get what you're saying. So I included that so that the program only exited when the user was done reading through how each protocol ran so they can debug. Not sure if that's the best way of doing it which is why readkey() is there as well.
- Don't hardcode paths - trying to get the filecount from a folder? int dirLength = 0; System.IO.DirectoryInfo di = new System.IO.DirectoryInfo(protocolsPath); foreach (var fi in di.GetFiles()) { dirLength++; } Can be written as ´di.GetFiles().Length;´
How would you suggest grabbing the desired path?
Use [Environment.GetFolderPath](https://docs.microsoft.com/en-us/dotnet/api/system.environment.getfolderpath?redirectedfrom=MSDN&amp;view=netframework-4.8#System_Environment_GetFolderPath_System_Environment_SpecialFolder_)and [SpecialFolder](https://docs.microsoft.com/en-us/dotnet/api/system.environment.specialfolder?view=netframework-4.8)
Aspose is the best imo and worth the money.
Awesome, thank you!
Once they fix all the quirks with the Roslyn scripting functionality you potentially can code via the network straight on iOS and Android. You will need to compile and distribute via a Mac or build service but all the dev you can potentially do straight in device. So like Continuous on iPad but more robust (that experience is ok for playing around but nothing more). I have been waiting for this option since Xamarin was first released. I also see it as the only way that Xamarin won’t be made irrelevant by things like React Native and Flutter which have this functionality.
Because it is a school project for a c# course and because I am very advanced compared to other students I decided to learn and implement networking in my game. This is what I made so far (lag because of recording): [https://drive.google.com/file/d/1RjuIPxm6-LEKmK-FzCwUw0HkYi3yhOaW/view?usp=sharing](https://drive.google.com/file/d/1RjuIPxm6-LEKmK-FzCwUw0HkYi3yhOaW/view?usp=sharing) while the others are making small programs like flappy bird game.
i am looking at some examples and i have seen this a couple places and have no idea what this is supposed to accomplish. can someone explain this to me?
It's superfluous, and not needed. That app is done anyways.
Please insert the code into your post and format it properly, it's a pain to read or see anything on that photo.
Looks like an error.
That picture gives me a headache. Can you actually post code as text please
I made this with WinForms (lag because of recording): [https://drive.google.com/file/d/1RjuIPxm6-LEKmK-FzCwUw0HkYi3yhOaW/view?usp=sharing](https://drive.google.com/file/d/1RjuIPxm6-LEKmK-FzCwUw0HkYi3yhOaW/view?usp=sharing) looks more complex than chess or minesweeper ¯\\\_(ツ)\_/¯
I don't think you will find a library like that for Windows forms. Still what you did in Windows forms is impressive. I'm really curious how you did it.
If win forms is not the problem and you Just want to do a multiplayer game you can use a html server and connect to it and send request, process it etc, but if we are talking about real time, the only real time lib for network I know atm is signalR but like it was said Before, there is a lot of troubles in the configuration to take into account.
You mentioned that that SDK you are using isn't well documented, I would add lots of null checks. An awesome library called CLAP would make your application easily accept parameters, so less is hard coded. https://adrianaisemberg.github.io/CLAP/ You can use shortcuts for this Console.WriteLine(currentProtocol + " completed." + "\n"); to Console.WriteLine($"{currentProtocol} completed.\n");
Great I'll check it out. Is there a unit testing class?
I've used a VM for iOS development. Seems to work fine.
Ya I decided to use an IOC container
That's winforms? Impressive
In my particular case, I write JavaScript frontends that make async http requests to my C# backend for content. Before going serverless I would have to configure a physical or virtual machine to serve my websites' resources. It was costing me like $50 monthly to have that server running in the cloud (AWS EC2) and I honestly could not justify the cost. Dont get me wrong, my projects are cool but not that cool, lol. So I learned about serverless architecture back in 2017 whereby a cloud service (ex. AWS Lambda) can be called by making an http reqyest. I wondered if I could leverage this technology to contain my C# backend and only spin up when requests are made. Sure enough with the help of a template provided by AWS, I made it happen. Now I only get charged per http request and the savings have been huge.
Please see my explanation above.
Great work. I've toyed with serverless for simple contact forms on otherwise static websites on Azure. Nothing more than a proof of concept though.
This is what we use at work. But it's stupid expensive.
For future use, there are apps (like pocket casts) that let you set an auto skip per podcast; for instance, I have mine set up to skip the first 6 minutes of any joe rogans I listen to, or the first 45 seconds of a couple others.
What you did in windows forms is impressive. You should look into monogame
SqlConnection objects are pooled under the covers, so your information is incorrect. Best practices are to wrap them in a using block, and dispose of them as quickly as possible. That ensures they always get disposed. As a more broad piece of advice, consider using something like dapper to make the process of querying simpler, or even consider Entity Framework.
Do I understand you correctly, you eant to multiply a number n times and each time you multiply it by i+1? So you want to start with 1 for example and multiply it by 2, then you get 2, multiply that by 3 so you get 6, etc?
Yes, that's correct.
Then for(int i = 0; i &lt; target; i++){ value *= i; Console.writeLine(value); } Should do the job, nit entriely sure, its close to midnight and I had a travel day.
Your loop is multiplying 23 by what ever TimesWith is each time. You are wanting to multiply by the result of the last iteration. You will need to store the result of the multiplication each loop like you are storing TimesWith and then multiply those two together instead
You keep deleting your posts, which makes it unnecessarily difficult for others to look up the context of your questions and things you've already been told and tried, and also means that these discussions won't be of any help to others who may be searching for the same information.
Thanks guys actually I have solved it couple hours after i post and I hide the post didn't expect any reply lol ..thanks
I got it to work. Thank you.
I’ve had to implement a similar scheme for excluding multiple sets of 50,000+ records each. The simple yet performant solution I implemented was to override Equals and GetHashCode on my type, then transform one set into a HashSet&lt;T&gt;. You can then do constant time lookups to find what is in one set that isn’t in the other; this took my comparisons down from 1+ minute to near instantaneous on my machine.
Just do a `return`
the previous post was meaningless after a research, so I deleted it because it doesn't set any context
Just use a UdpClient there is not much too it and you can do Peer to Peer on the same network easily. If you are wanting it over the internet then create a server to act as the middle man.
Seconding the vote for EF and Dapper. Baby steps - EF makes it so easy to wrap your head around how models, context, and connections work
Do you have some reference/tutorials? How do I setup a server for free?
But .NET 5 isn't a continuation of .NET Framework... like at all. There are things in Framework that will not be ported to .NET 5. This is not a break in compatibility the same way earlier Framework versions were. This is an entirely different .NET with an incompatible feature set and incompatible APIs. &gt; But I'm pretty sure 70MB Hello World applications are not the goal. For the record, I don't approve of this either, but it is so low on the totem pole of issues that it hardly shows up on my radar of things to be addressed. The pros vastly outweigh the cons. Where I work, we happily ship these heavy payloads because not requiring .NET is a godsend on these customer machines with stupidly locked down permissions still running .NET 1.1 or 3.5 or whatever.
After pasting your code, you can highlight it and click on the code format button &lt;&gt; That will give you a code block like this
would literally do nothing and is essentially the same as Environment.Exit please tell me you dont end your `void` methods with a "return" before the closing curly bracket to end the method scope
Start with this example https://stackoverflow.com/a/19787486 Let me know if you need help getting it going. Raw sockets in .NET are simple and passing messages between clients is easy.
Thanks! :D
Not a real tip, but... Turn this: // Tells us if the device is if (HendrixAPI.Connect(port).getDeviceStatus().ToString() == "DEVICE_READY") { // Code segment A } else { // Code segment B } Into this: if (HendrixAPI.Connect(port).getDeviceStatus().ToString() != "DEVICE_READY") { // Code segment B return; } // Code segment A
I also dislike singletons and I never heard of RiPonts rule of thumb. However I will say 1) Singletons IMO are worse than gotos. At least gotos are only local to the function. 2) "Thread local storage" is very likely what you'd want. Write `[ThreadStatic]` (ex: `[ThreadStatic] public static int thing`) and that variable is a static variable but only for that thread. I recently changed code (about a dozen vars) that use `static` to thread local and my code almost worked right away (had to write more code to initialize the variables when I create a new thread). Had I use a singleton I'd have a harder time changing it all
If anything you gain more compatibility since you can now run your app on linux and mac as well as windows.
int sum = whateverInt; for (int i = 2; i &lt; 10; i++) { sum *= i; Console.Write(sum + "\n"); }
I've used MacInCloud, you can install usb network software to remotely debug from the server. Unlimited time on a 2014 mac mini is 45 a month. I think it's fine for seeing if it's something you want to do, but long term a cheap mac mini might be better
Like other people have said, HashSets are where it's at. The HashSet is geared towards efficiently answering the question "Is this already in here?"
Which version of Mono was it run against? AFAIK fast `Span&lt;T&gt;` implementation (intrinsics) was only added in version [5.16.0](https://www.mono-project.com/docs/about-mono/releases/5.16.0/).
I personally tend to summarise my use of singletons as: they’re fine when used for retrieving something immutable, or doing something where state doesn’t matter System config if your config is relatively static, language (internationalisation etc), logging and similar are use cases where I think they can make sense
SignalR is for ASP.NET real-time web-applications, not for native games. It's built on web-sockets which are unnecessary since OP can directly use TCP or UDP. Plus it by definition isn't peer-to-peer.
You don't want to do this because you are not making a web-application and this does not meet your requirement for being peer-to-peer.
It can easily be read front to back as a learning experience. It's best used with Linqpad, which contains some of the example code to test with and try things out.
LINQPad is kind of a companion to the book and it contains some of the examples in the samples tab of the applications.
 int TimesWith = 1; do { startnumber = startnumber * TimesWith; Console.WriteLine(startnumber); TimesWith = TimesWith + 1; } while (TimesWith &lt; 10)
I think his assignment was to write the code himself, not use an ORM. Essentially from what I gathered of his question he is being tasked to write an ORM.
The very latest. I downloaded the latest Unity version just for this.
Anybody can take a sledge hammer and slam a square peg into a round hole. It doesn't show you are more advanced. It shows you're an amateur. &amp;#x200B; Use the right tool for the job.
Usually when doing assignments you don't have the choice to use an ORM. I know when I was in school we weren't allowed to use an ORM, and if we did, we still had to provide code that showed we knew how to get along without it.
I've been reading a lot of comments on this thread and want to put my 2 cents worth in on the whole conversation. Using a singleton is fine here for a couple of reasons: 1) Whether you are hosting 1 connection or a dozen is irrelevant. You should use some kind of pool to host the connections which is/would be itself a singleton. Going with a Singleton up front saves you from writing a custom connection pool, just keep the instances in the appropriate Concurrent data structures and you're thread safe unless you do something really stupid. 2) You can use DI to provide the instance of the Singleton in your app. No need for a custom factory method or Instance property. As was said, use an Interface to define the singleton and only access its members through the Interface. In this way your app will never know if the singleton changes to another pattern. 3) Using a ConcurrentQueue in your singleton will allow you to accept requests for the single connection and service them in order in a thread safe manner. The consumer of the connection (ie. your ViewModel) should expose an Interface such as IReceiveSpecialConnection that has a method that the singleton would call when pulling the instance from the ConcurrentQueue. 4) If you want to cache the data of the connection, do so in an ObservableCollection and expose the collection instead of the connection (I'm assuming the data's domain is fairly constrained within the app and it is shared among multiple ViewModels). Then when an instance class receives your singleton (via pull from IOC or push to constructor) it subscribes to the event of the ObservableCollection to get notifications of changed data. 5) As was noted before about testing, having an Interface for your singleton allows you to mock your singleton so that you aren't testing the ViewModel and the singleton at the same time. On the flip side, testing a singleton by mocking messages should be done, but in a repeatable manner. If you expect up to 5 concurrent usages of the singleton, then test with at least 5 threads hitting it concurrently. You will find out really quickly if your code is thread safe. Avoid everything in System.Collections and System.Collections.Generic and only use the data structures in System.Collections.Concurrent. Remember, you're not condensing the application into a single class, you are writing a class to manage access to an instance of your connection. If the connection is short lived, then you don't want your ViewModels having to figure out when to instantiate a new one and how to do it. This fits neatly into Separation of Concerns and encapsulating this logic into a singleton makes sense. I use Singletons a lot in WPF and UWP applications as it's a natural fit with the application's lifecycle. They are very useful when they have a very specific problem domain and aren't catch-all application management objects.
When I'm back home :) Some links/domains are blocked at my job (pastebin being one of the those for obvious reasons), so i can't read your code.
&gt; Edit 2: My currently assembly is .NetStandard2.0 since I was planning to use parts of this both inside and outside of Unity. That does mean that I have the supposed slow, portable version of Span. No, it doesn’t technically mean *anything*. .NET Standard is just a spec. What matters for Span is the *runtime*. .NET Framework will likely never get a runtime-optimized version of Span. .NET Core did in 2.2(?). Mono apparently did in 5.16. Your assembly may be .NET Standard (that’s typical/encouraged with libraries), but the process that *runs* it won’t be. So, jury’s out!
Just use the default console app project in visual studio and compile your code with latest .net core? Unity is great and all but you don't need it to do simple tests like this, as there's too much involved that can affect results.
Makes sense. But how do I know which runtime runs my .Net Standard assembly? In case of Unity, that's clear, but what about outside applications?
Why not in a separate class? (IDisposable.Dispose() closes the connection)
&gt; In case of Unity, that’s clear, but what about outside applications? Your code always runs within an application. In the case of BenchmarkDotNet, you can configure what the test runner looks like: https://benchmarkdotnet.org/articles/configs/jobs.html#environment
6 figures could mean starving intern in San Francisco :)
Gotta use unity bro
You can also check out GemBox components: * [GemBox.Pdf](https://www.gemboxsoftware.com/pdf/examples/c-sharp-vb-net-pdf-library/101) for a really easy and extremely fast extraction of [text](https://www.gemboxsoftware.com/pdf/examples/c-sharp-vb-net-read-pdf/205) or [images](https://www.gemboxsoftware.com/pdf/examples/export-images/206) from PDF files. * [GemBox.Spreadsheet](https://www.gemboxsoftware.com/spreadsheet/examples/c-sharp-vb-net-excel-library/601) for simple, efficient and memory optimized [exporting](https://www.gemboxsoftware.com/spreadsheet/examples/c-sharp-export-excel-to-datatable/502) of spreadsheet data from Excel files. These are not open source libraries, but they have free and commercial versions. Nevertheless, we've been working with GemBox.Spreadsheet for years now and I'm happy with how easy its API is to use. Also, we have recently started to use GemBox.Pdf, found it's able to read PDF files surprisingly fast.
Try to do positive checks when possible. From the time we learn about `if`blocks, we learn that if something is *true*, do something. Mentally switching the context to if something is *false*, then do something can lead to accidents if someone is quickly glancing at the code.
I solved the problem. Seems like localuser doesnt have the permissions. Im jow running the service under my user and it works. Thank you everyone who took time for my problem.
Span has it's full compiler backend support in .NET Core 3, although you can use it in other versions, it doesn't perform at maximum potential.
No, i didn't check the code, I'm just saying to exit in a non final scope you'd use return not env exit
Have you tried to use a class inheriting from applicationUser?
Posting here because i want to read back
You would need to programmatically set the visible property on Word on document open event, the challenge would be defining the logic. Something like if document path contains x Visible property = false Else Visible property = true Its been a while since I've had to write a word addin, what I can't remember is if you can set it per word instance or not.
Order status and avaliable statuses to go from current e.g {"New", new List&lt;Type&gt;{"Removed", "Accepted", "Rejected"}}
I barely use list. I use plain array or dictionaries.
I'm just saying that there are better books out there suited for learning how to code. You can use pretty much any book as a learning experience, doesn't mean you will get as much out of it than a book that was specifically written for such a purpose.
Well, you’d use dictionaries when you want the index of the array to be something else than int. For example you want to implement your custom translation solution for the application you have. You build the interface using English. Then in some text files you include the translations. You load them into the dictionary so that you can do something like: Textbook,Text = dictionary[“Hello World”] Another example is when you want to link two controls together, in case you want to edit them. As such dictionary[control1] = control2. And sure you could create a class to enclose them and have a list of such enclosing classes, but that’s extra work and the lookup for the object that you want wouldn’t be O(1) like in the case of the dictionary. In conclusion, dictionary is a hashmap implementation and is used mainly when you want fast lookup in an array but you want your index to be something else than int.
A dictionary is useful whenever you have a kind of mapping relation between a unique value (the key) and some other object (the value). I mostly use them when loading some data in a cache (whether it is persistent during the application lifetime or just for the duration of an algorithm) so that fetching the data multiple times is very cheap. Dictionary can also be used instead of list, when you expect data to be fetched, added, removed, inserted frequently (in no particular order), but you never need to iterate the collection in order. It is a good compromise compared to a List (cheap retrieval using an index, expensive insertion/removal) or a LinkedList (expensive retrieval, insertion/removal can be cheap if you have the node). Trade-off is that it occupies more memory and is a bit less efficient when retrieving (still 0(1) in most cases, but more indirections than an array or a list).
&gt;Task.Factory.StartNew “wraps” the result of a given delegate into the task, and if the delegate itself returns a task, then the result is a task that creates a task. у меня мозговая аневризма
You won't be able to use it to measure that. Instead you should use BenchmarkDotNet.
A lot of impressive 0$ bounties.
&gt; Well, you’d use dictionaries when you want the index of the array to be something else than int. You use dictionaries also when the key is an `int`.
"When do you use dictionaries?" - "I barely use them. I use arrays or dictionaries."
ензам нзгв оира!!!!
I think you misread me. Would you like to try again?
I mean sure you can of course. The key can be whatever you want it to be. I guess you could use that if you want to access by integer index but you don’t want all the index values to be continuous as in from 0 to max value. I’ve never done it myself but surely it’s possible and in some cases it may be preferred.
[Benchmark.Net's Memory Diagnoser uses GC.GetAllocatedBytesForCurrentThread](https://benchmarkdotnet.org/articles/configs/diagnosers.html)
I'd create a separate class for doing anything related to actually talking to the database. That class can have a single method which has the using statement which manages the connection. The single method takes a parameter which is a query string. Then you execute that query in the connection and do the while loop which you've got. Rather than logging it out to console there, add each IDataRecord to a list and return that. Then in whichever class uses that SQL connector class you'll be able to read out the data and do what you want with it. Try and keep your SQL class so it can work with any query on any table in your dB and you'll make your life easier because you'll have a class that can be used anywhere and you won't have to keep duplicating that logic. If your determined to only keep one connection then I'd use the suggestion of opening the connection in the constructor and closing it in an IDisposable method. However in a console app this probably isn't a good idea because all the time that object is in scope you'll be keeping a connection open. Since console apps typically run on looped menus there's a good chance you might put that connection into scope for a long time and this wouldn't be good. You may also have the same problem if you were to use dependency injection. The issue is that if a lot of people were to be running your app at the same time you'd have lots of connections open which weren't in use - imagine if every teacher in the school used it at the same time like end of period for reporting attendance. You're better off with the using statement that most people are advocating.
I did not check it, but I would assume it provides a custom task scheduler that will take care of tracking memory across threads in async scenarios. Probably worth checking.
Array and dictionary are completely different types that are not comparable. An array is a large block of elements, and with the indexer you just say which element you want. A dictionary is a growing structure in which you can use arbitrary keys. In some rare cases they can be used interchangeably from a code point of view, but they can't be from a semantic and performance point of view.
"When do you use dictionaries over other collection types?" - "I don't use &lt;other collection type 1&gt;. I use &lt;other collection type 2&gt; and dictionaries."
Dictionaries are great for storing data against a key. I use them when I have multilingual data so I can store a translation against a language code. I also use them to store data attributes when I have an object which is essentially the same thing but has a set of attributes which are subject to change. This means that I won't have a load of null properties on an object so I'm not having to write a million null guards. It also means I can add an attribute without having to add another property to the object. Both of these are really useful because you can potentially add languages or attributes with fewer code changes depending on how you've built an app. Be careful though, it's very important to understand that dictionaries unlike lists have no inherent ordering, they're designed to retrieve data values by key not by index and so if you loop through a dictionary there is always a chance the data will come back in a different order
Of course. I’m not currently explaining what they or even their actual implementation, OP asked use cases and I’ve provided use cases. Although I don’t know where you took the array to dictionary comparison. If you were to compare, you’d rather compare dictionaries with lists. Arrays are one of the basic and fundamental data structures and in fact, some hashmap or dictionary implementations are based on arrays themselves. But of course they are not the same thing in implementation, not even close. One last thing. Don’t compare performances of an array versus a dictionary. It’s completely redundant because the most performant dictionaries are still based on arrays and as such they’ll never surpass an array in performance.
Fairly new to tasks and the such, but isn’t Task.Run the preferred method over Task.Factory.StartNew anyway?
Of course man but the whole point is that's not what it does, go try it out in interactive
Oh I thought you meant you’d be disappointed if it behaved that way. My bad.
Perhaps it's me but to me it looks like two things are mixed here: parallel programming and concurrent programming. The code starts with 'let's run stuff in parallel' but then tries to do that using a concurrent programming mechanism, namely async/await. the whole point of a long running task is that it's simply doing its thing on a separate thread, in parallel. If you use an await there, what's awaiting it? There's no calling thread, it's on its own. so to have things run in parallel, just run a task that does that work, or several tasks if your work can be chopped up in multiple sub parts that can run in parallel. These tasks will run on their own thread (from the threadpool), scheduled by the default task scheduler. If there are more tasks than threads (according to the scheduler), it will queue up the tasks and when a thread is done with a task it will get a new task to work on. This is a great way to do things in parallel without much, if any, overhead for yourself. The TPL contains several schedulers you can choose from, each with their own characteristics. No need for async/await.
Yes, and it's mentioned at the end of the article.
Using of guard clauses is a part of defensive programming, so unless there is no problem with defensive programming design itself, I don't see any problem :/ Also it virtually reads as "If device status isn't ready, report it"
&gt; This is an entirely different .NET with an incompatible feature set and incompatible APIs. In my experience .NET Core still is mostly the same and easy to port to. When I tried it out I just had to make a few minor changes and to make all my .NET Framework code work on Core. I expect many programmers will switch to it once it is the new standard. &gt; Where I work, we happily ship these heavy payloads because not requiring .NET is a godsend on these customer machines with stupidly locked down permissions still running .NET 1.1 or 3.5 or whatever. Yeah, I guess it always depends on the target audience. For business your approach is definitely better. I have the luxury of targeting gamers and content creators, which tend to be up-to-date in terms of hardware and software.
You could get away with a single constructor with a default guid parameter.
Question 1: Totally normal to initialize that Guid in the constructor and fine to have multiple constructors. &amp;#x200B; Question 2: I think it's fine to have in the constructor
So a default parameter would look like the following?: public Enemy(int health, int mana, Guid enemyId = System.Guid.NewGuid()) { this.health = health; this.mana = mana; this.enemyId = enemyId; } How about my original questions? 1) Is it OK to initialize properties in the constructor that are not affected by the parameters? 2) Is it OK to use logic in a constructor? Thanks for you help.
1. Yes 2. Yes, anyway in the example given that logic makes more sense in a setter of the property than the constructor.
Thanks for your help. I can get back to it now :)
Yeah I just threw an example together. I agree it would be better to put that logic in a setter. Thanks!
More on the subject: https://blog.stephencleary.com/2013/08/startnew-is-dangerous.html
I'm not /u/jlnazario but yup that looks right. As to your original questions they already answered when they said : &gt;Some logic is ok, just don't call anything external like read from the web or disk. I agree with this in theory. But in practice, I'd caution against what I would call 'business logic' in the constructor as it's just going to get confusing. That is, it's OK to have some logic around making sure everything is 'plumbed in' correctly, but generally speaking, clean and simple constructors are the way to go. For instance, if you have a rule like 'all enemies start with at least 50 health' that's basically a bit of business logic, and hiding it in the constructor is actually likely to cause confusion. Better to use a factory pattern or add some Debug.asserts to ensure you get initialized according to that logic. For your example, if you were to create an Enemy like this somewhere else in the code: `var weakEnemy3 = new Enemy(20, 4);` it's only going to be a cause of bugs if in fact 'weakEnemy3' actually has 50 health (when the calling code thought they had initialized it with 20 health.) Better to actually throw an exception on initialization, or use a factory pattern.
Hey thanks for your extra insight. Very helpful. Also, the reason I asked him about my original questions is because the answer originally only said " You could get away with a single constructor with a default guid parameter." You make some good points though, thanks.
Meh. Coding is dangerous when you don’t know what you’re doing. Prey tell how else we can unit test Task.Run() outside of fakes? (Which are not available under .Net core)
I'd like to know what you mean by "not available under .NET Core"? I'm unit testing a lot of async methods in NUnit in *Xamarin* right now, which is usually a very restrictive environment. But the real answer is "use Rx Extensions when you can because it was designed to be tested so long as you allow callers to specify a scheduler (which you should)".
i said ‘fakes are not available under .Net Core’, fakes is Microsoft Fakes framework. Suggesting Rx Extensions to UT Task.Run() is kind of like suggesting a microscope to hammer some nails...
There's nothing wrong with doing something in Winforms if you just want to learn or if that's what some teacher requires. It's only a problem if you want to invest many more resources to then eventually sell it.
I use dictionaries for everything. I want to give a list an object and it pops out another object, instead of doing .find on a list.
You can also use constructor chaining if you don't want a optional parameter. &amp;#x200B; `public class Enemy` `{` `private int health;` `private int mana;` `private Guid enemyId;` &amp;#x200B; `public Enemy(int health, int mana) : this(health, mana, System.Guid.NewGuid())` `{` `}` &amp;#x200B; `public Enemy(int health, int mana, string guid) : this(health, mana, System.Guid.Parse(guid))` `{` `}` &amp;#x200B; `private Enemy(int health, int mana, Guid guid)` `{` [`this.health`](https://this.health) `= health;` `this.mana = mana;` `enemyId = guid;` `}` `}`
I could see why people would be confused. Unqualified, the word fakes is a general testing concept and few people would assume you meant a specific library.
Last things I remember using it for was an easy way to access a list. I had a bunch of text to process and they have a user chosen text id (like how this sub is 'csharp'). IDs are not unique. So I parsed the text and threw each item in a list in a dictionary with the id \`Dictionary&lt;string, List&lt;ParseData&gt;&gt;\`
Making an analogy that makes no sense is not explaining yourself. It's like saying "I don't know what I mean and don't have a point."
Dictionaries compared to other "linear" collections are super fast in C# as they use Hast table to store and look up keys. I use dictionaries in places where its designed to be: where you have to match a key to a value.
The most common use for Task.Run in my experience is CPU intensive code. In that case, just run the unit test. If it is IO, mock the actual IO call and run the test. Worst case, call it an integration test and run the code as is.
Yes and yes. You did everything right. Good rule of thumb. A class should be able to call any public methods in any order without causing a problem. Usually to do this you may need logic in your constructor. It's not unusual to call a private method. This rule of thumb is traditionally broken when keeping compatibility with C library
Oh God I forgot about the Table Adapters and all that garbage.
This sounds like an X-Y sort of problem: I'm not sure why you'd be testing Task.Run() in the first place.
What you might find useful in case you have logic in a constructor is to create different factory functions that can future proof you in case you want to have different logic for different enemies: private Enemy(int health, int mana, string guid) { this.health = health; this.mana = mana; enemyId = System.Guid(guid); } public static Enemy BasicEnemy(int health, int mana) { // your stat checking logic here Enemy(health, mana); } This way if you decided to add an enemy that has at least 75hp or some logic related to mana for example, you'd just add another constructor function: public static Enemy MiniBoss(int health, int mana) { // your stat checking logic here Enemy(health, mana); }
Excellent advice! Thanks!
https://www.merriam-webster.com/dictionary/preferably
Care to elaborate on the solution you came up with?
Add a console project to the solution, add the reference to the DLL you created, call the dll from console, publish the console app.
That is a good idea, thank you. I will give this a try within the next week or so and let you know.
Not that it doesn't change the outcome of the article, but I don't think `StartNew()` was the biggest mistake here. If you want a dedicated thread for a method that runs "forever", the tool for that job is a dedicated thread. Don't reach for the API used to facilitate short-term I/O-bound tasks when you want a dedicated thread that runs forever. I don't care if it has knobs you can turn to *suggest* you want a long-running thread. Tasks are for "do this and tell me when it's done so I can do more things". When you use them for something else, it's no surprise you end up in trouble.
You’re absolutely correct in using defensive programming! :) My comment was not regarding the check, but regarding the negative check conditions themselves in general. As with any software design principle, there will be exceptions to it, so please use your best judgement. In this block however, it is representing a defensive check as it is reporting the incorrect state and exiting. In that case, one approach would be `if(state is not ready) { report(); return(); }`. This will allow you to have the check as another validation/null-type check, and remove the else state (from what I can tell from this snippet). The later part will also help in reducing tab-depth of code, making it easier to read and maintain.
They need to match. The model binder will not associate them automatically. Now there is an asterisk on this. If the route is all parameters that are null able, the endpoint will be hit even with the name mismatch, and then if you do desired, you could pull the parameters from the raw request body.
The property names should match, though I am not sure if capitalization matters -- many popular JSON serializers (i.e Newronsoft) will map the JSON property "foobar" to an object's property "Foobar" by default. However, I don't believe they will be able to map "charName" and "Name", as in your example. The strictness of the JSON format is entirely up to the API and as such, the answer might very well be that *it depends on the API you are calling*. Hell, there's ways to plugin custom serializers such that it would be able to map "charName" to "Name", but that code would be hosted in the API app and you'd have no control over it. As a general rule, if you know what the API expects, don't deviate from it with the *hopes* that it will accept the data.
Names can be in any order. Type must match as well. In JS if something expects a string and gets a number the number will be converted. But when using JSON the types matter
[Only on .NET Core &lt;3.0](https://github.com/dotnet/BenchmarkDotNet/blob/f54055a23bbf8490499166ea90947c966619c26c/src/BenchmarkDotNet/Engines/GcStats.cs#L134)
I missed this was a school assignment. Still good advice, just not usable here...
I think part of the problem is that Microsoft made some functionality only accessible using async methods, and using those from a non-async method it is very easy to get bugs. So if you want to use your own design for threads you have to jump through some hoops in exactly the right way, or else random deadlocks.
&gt; Prey tell It's ,'pray, tell'.
Why not make them public properties with private setters? Won't you want to know what those values are at some point outside of the class so you can display it? You can still set from constructor
?? What is even the purpose of `Task.Factory.StartNew` here? This is pretty clearly starting a wrapped task for some strange reason. Instead of _task = Task.Factory.StartNew(LoopAsync, TaskCreationOptions.LongRunning); Just do _task = LoopAsync();
It detracts from the credibility of the website, so I don't see why they would even allow those bounties.
I'd honestly never use PostSharp for anything like this.
Bone apple tea, my frend
I haven't; is there a reason that would be more likely to work?
I use it to track exceptions when ~30 or so remote work severs are all writing to the same event sourced time-line. It cuts out just shy of 50% of the code base for me. This example is the best I could do to compact it down without doubling the length of the article. Sorry if it come across as a bit obtuse! The criticisms are welcomed. 🙏
Yes, exactly. Our instructor told us we need to understand basics first.
Thank you guys very much for your advice. I really appreciate your help.
thanks! So the passed parameters going to the API Controller can be in any order, but the names and types must match.
https://dotnetfiddle.net/lNtv0K
Math.Pow should work. The *example* takes 2 and raises it to every power between 0 and 32.
Disagree, threads have the same amount, if not more ways, to shoot yourself in the face. No matter the solution, if you don't understand the tech you are using, then it does not matter if you are using tasks or threads. The reason to use tasks over threads is as you said, you want something done. The continue with syntax even works for long running threads, and you can abort if a task failed.
Written in C# with WPF : Working on a program to help you read and play sheetmusic, It gives you random chunks of notes and chords and you can play them using a midikeyboard. Working on chord stems atm, single notes work find chords are abit more tedious to render correctly.
[https://www.diogonunes.com/blog/webclient-vs-httpclient-vs-httpwebrequest/](https://www.diogonunes.com/blog/webclient-vs-httpclient-vs-httpwebrequest/) this gives a good explanation I think
var results = from r in routes group r by r.Scheduled into g select new { Foo = g.Key, Bar = [g.Select](https://g.Select)(x =&gt; $"{x.Scheduled}-{x.Employee}").ToList() }; Just is your data.
Yes. Almost all will use strict json but sometimes a lib might use an non strict one. So if `{hello: true}` works it doesn't mean that something else might not complain it's nost using quotes around the name (strictly speaking it should be `{"hello":true}`, whitespace is allowed in strict IIRC
DAE hate discord and use IRC instead. I feel like dinosaur.
Does it mean there is a reason to create a separate method to make the positive check?
Short answer: prefer `HttpClient` as it is the newest of those, and the others are effectively deprecated. Also have a look at `HttpClientFactory` (which works with `HttpClient` rather than replacing it)
I like it. To make it clearer it might be worth changing the second used p=&gt; for a different letter. It might not, but I had to double take to figure out whether somehow the p had propagated itself down the line :)
Are you asking why the Pythagorean theorem works for this, or is there a question about the code?
My main uses for dictionaries are a) Having an IEnumerable and wanting a simpler way to get an element repeatedly than `myList.First(e =&gt; e.Id == id)` or even more complex queries. b) Some kind of static map. Recently it was a relation of file size getting translated to sale prices var megaByteToPriceDict = new Dictionary&lt;int, decimal&gt; { { 200, 0.49 }, { 400, 0.59 }, … }
Threads shoot you in the face if you're trying to do a complicated thing. This is "a single loop that never terminates". I'm hyper-focusing on the example, but the discussion never ends if you try to cover every case. I know `ContinueWith()` works even with long-running tasks, but even though it works *in theory* with infinite-running threads, something has to complete for you to "continue".
Or penniless in Zimbabwe.
It's Euclidean distance. Everything that is less than the radius away from the center is inside the circle. That like basic math...
The distance between two points in Cartesian (x, y) coordinates forms the hypotenuse of a right triangle with the two other sides parallel to the x and y axes, with the lengths of the being the pairwise difference of the x and y coordinates of the two points.
I am asking why Pythagorean theorem works for this. I just don't get it.
I am really confused. Where there are circles?
Why does the Pythagorean theorem work? Because triangles, man. What is the distance between any 2 points (x1,y1) and (x2,y2) on a Cartesian Plane? The way to determine this is to draw an imaginary triangle. First, draw a line between the 2 points. Now draw a horizontal line at y1 and another at y2. Now a vertical line at x1, and another at x2. You'll note that the point(x1,y2) intersects at a right angle. This allows you to envision the triangle (x1,y1)-(x2,y2)-(x1,y2) Since we have a right angled triangle we can use the pythagorean theorem to determine the length of the 3 sides. You know that x1-x2 and y1-y2 are the lengths of 2 of the sides. (absolute value thereof) this leaves the third side's distance as sqrt((x1-x2)^2+(y1-y2)^2). So if you know a distance D, you can compare D^2 to (x1-x2)^2+(y1-y2)^2 with no nasty roots.
Thank you for your response! Sorry, but I am 7th grade, and it's difficult for me to understand. So, can you try to explain it to me with an example: so the **impact sell** is **(2, 3)** with **radius 2** and we want to check if **(row, col)** is within the radius. With what we should begin?
Yeah sorry I wrote that on mobile :)
So, if you want to know if your points are within a radius from a center point, the distance between those points and the center has to be equal to or less than the radius. So, if your center is (3, 4), then to find the distance between a point (x, y) and the center you would subtract the x coordinates to get the distance along the x-axis, and then subtract the y coordinates to get the distance along the y axis. Square each of them, add, and you get the square of the distance. You can either take the square root of that to get distance, or square the radius to compare.
You could read and write to a text file. Although it might be easier to create a class that holds the information for the job and serialize/deserialize to JSON.
I have never got the hang of doing a bit of code on mobile :) It always amazes me.
https://www.mathsisfun.com/algebra/circle-equations.html
I just pasted this into a text editor and refactored by hand (meaning some mistakes might be in this). But this is a semi-cleanedup version ``` cs using System; using System.Collections.Generic; using System.Linq; using System.Text; using System.Threading.Tasks; using System.IO; using HendrixLib; using HendrixLibHLL; using log4net; using Iesi.Collections; namespace ProtocolAutomation { public class Program { static void RunHendrixApi(){ var HendrixAPI = new HendrixHLLAPI(); var DeviceInfo = new DeviceInfo(); // File pathes var protocolsPath = @"C:\\Program Files (x86)\\Microsonic Systems\\protocols"; var baseProtocol = $@"{protocolsPath}\\320MixSettings-"; int dirLength = new DirectoryInfo(protocolsPath).GetFiles().Count(); var connectionPort = "COM4"; vas status = HendrixAPI.Connect(connectionPort).getDeviceStatus().ToString(); Console.WriteLine("Status:" + status); // Tells us if the device is ready if (status == "DEVICE\_READY") { for (int i = 1; i &lt;= dirLength; i++) { var currentProtocol = baseProtocol + (i) + ".prt"; Console.WriteLine($"Processessing {currentProtocol}."); Console.WriteLine("Loaded:" + HendrixAPI.LoadProtocol(currentProtocol)); var returnCode = HendrixAPI.StartMix(); var message = (returnCode == 0) ? "Successful" : "Failed"; Console.WriteLine(returnCode); Console.WriteLine(currentProtocol + " completed." + "\\n"); } Console.WriteLine("All protocols completed"); } else { Console.WriteLine("Device not ready, read status below"); foreach (var item in DeviceInfo.getErrors()) { Console.WriteLine(item.ToString()); } } } static void Main(string\[\] args) { RunHendrixApi(); Console.WriteLine("Press ENTER to EXIT"); Console.ReadKey(); } } } ```
Writting code.
Imagine you had a single line, and you had a point. You wanted to find out what side the point was on, or if it was on the line. To do this, you can subtract the point's position from the position of the line, giving you a value that can be used to determine whether The point is on the line, "outside" of the area below line (a positive number), or "inside" that area (a negative number). Now, we can bend the line, or add another line to ours, and do the same thing. Our equation gets a little different because now we need to check the point against any other sides we add. Or, we could close the line on itself and make a circle. The problem is that a circle has infinite sides, but we can plug in our point's position into the circle's area equation instead, and do the same process for a straight line
A circle is a radius times pi. You have a radius with a centre in your description of the problem.
Imagine a circle, centered at the impact cell, ie: x=targetColumn y=targetRow.
https://github.com/dotnet/roslyn
Try and fail a lot while trying to do a particular task. There is no quick route and you only get good through baptisms of fire where you constantly fail again and again until it clicks. That has been my experience anyway.
Dammit. Thank you, though
But can't I calculate the **distance** between the **points** using [this formula](https://www.mathplanet.com/education/algebra-2/conic-sections/distance-between-two-points-and-the-midpoint) and **compare** it with the **given radius**?
Thanks, that just directly flew over my head initially. I didn't realize that Roslyn was also a lexer (and not a compiler). Well, I've had some progress already done, but not much (really just detecting keywords, comments and strings). I don't think it matters though, if Roslyn can be implemented.
So what I suggested is right, isn't it? And I think it's **&lt;= radius**.
Yes , exactly. That is the better, more clear way to do it even though it takes more lines of code. Your original code does this implicitly and packs it all into one line of code, which is less desirable.
Roslyn is all of the compiler components between C# and IL, and more: https://github.com/dotnet/roslyn/wiki/Roslyn%20Overview#introduction
And in a team that would be even better. We offer group projects!
Haha!
I think HTTPWebRequest was the original (at least for me). Then I remember switching to WebClient, which made things a little simpler to use and piggybacked off of HttpWebRequest functionality. Finally, HttpClient came along, making things even easier and like OP said, provides important new async capabilities. It also offers more capabilities than WebClient(ie: accessing FTP locations). &amp;#x200B; I can't help with many low level details, but it is *usually* a good idea to hop onto the new client when it shows up.
Thanks! Already got the ConsoleClassifier sample project for examination, I think it'll do.
My apologies, but I’m not following. Can you elaborate your question a bit more?
A compiler would not work well without some sort of lexer :)
For more old school tools, look for things involving "[yacc](https://en.wikipedia.org/wiki/Yacc) and [lex](https://en.wikipedia.org/wiki/Lex_(software\))" e.g. https://www.nuget.org/packages?q=yacc
Let me know if my explanation helped, or if you have any more questions.
The framework has had 3 or 4 goes at this problem (depending on how you count, is `HttpClient with HttpClientFactory` number 4 or just 3 and a bit?) Each one fixes issues with the last one, and the remaining issues are less obvious. I like the design of `HttpClient` e.g. that it will give you a response if it possibly can, and _this is not an exception_ even if the response contains a 400 or 500 error_ - this isn't a remote procedure call, it _successfully_ gave you that data from the server. But if you want to do something quick, throw in a [EnsureSuccessStatusCode](https://docs.microsoft.com/en-us/dotnet/api/system.net.http.httpresponsemessage.ensuresuccessstatuscode)
Yeah, but as they described on the page, a compiler used to be a black magic box with no other output than assemblies. I didn't realize that Roslyn also outputs the intermediate results. Well, I now have more stuff to dig through I guess, and it saved me so much time now that I know it exists.
Thank you! I really appreciate your help! I found [this formula](https://www.mathplanet.com/education/algebra-2/conic-sections/distance-between-two-points-and-the-midpoint) and used it in my code: for (int row = 0; row &lt; rows; row++) { for (int col = 0; col &lt; columns; col++) { double distance = Math.Sqrt(Math.Pow(targetRow - row, 2) + Math.Pow(targetColumn - col, 2)); if (distance &lt;= radius) { matrix[row, col] = 1; } } } Maybe it's slow, but I understand it - we find the distance between the points (**impact** and **current cell**) and compare it with the **radius**. I think it's clear what I wanted to do. Thank you again! I appreciate it.
Thanks, fixed
Good deal, and good luck.
Yup, exceptions are meant for exceptional circumstances. In many scenarios a 4xx response is non-exceptional. The practical reason is exceptions have a large performance penalty due to walking and unwinding the call stack.
Use visual studio. You can easly see where all methods, classes and namespaces are used. And To see the declaration just press Ctrl+LeftClick
Thanks, I was looking to do something along the lines of a Visio so that I can use for a project overview with folks that don't need to see the code via VS necessarily. Visio seems a bit too general so wondering if there was anything more programmer friendly. thanks
I'd love to see some performance benchmarks
Any good C# channels ?
How big is your application? If its small, just use a singleton. If its big and complicated, probably IOC would be better suited.
yep
Over 1.7 million file additions. My God. I'm hoping that was a copy paste commit push. If not, they must've had some interesting PRs
Generated class diagrams are always nice. I've used it in the past
Singleton; much easier to unit test your code and the library you use to build the services will handle the injection for you.
Ironically I dont use IRC for anything programming related. Always just search the net for shit. I use IRC for other dumb shit tho
&gt; lol at the internals of this method `private static async Task&lt;IEnumerable&lt;T&gt;&gt; QueryAsync&lt;T&gt;(this IDbConnection cnn, Type effectiveType, CommandDefinition command)` BIG YIKES!
 [https://docs.microsoft.com/nb-no/visualstudio/modeling/map-dependencies-across-your-solutions?view=vs-2015#GenerateDGMLCommand](https://docs.microsoft.com/nb-no/visualstudio/modeling/map-dependencies-across-your-solutions?view=vs-2015#GenerateDGMLCommand)
A Singleton will make it easier to test? I thought they usually made it harder
How are you implementing the Singleton? With DI or are you just creating a Singleton pattern?
Currently I’m injecting the Singleton but I’m considering the pattern approach. I also like the multiple instance approach as that is far less coupling
Coupling isn't to do with instances it's to do with depency on other classes. You can have different levels of coupling but giving it multiple instances won't change coupling. If your using an interface that gets the object injected then I think you've already done this in the best possible way.
Ya that’s how i currently implemented it. Good to know i was on the right track
 [https://docs.microsoft.com/en-us/visualstudio/modeling/browse-and-rearrange-code-maps?view=vs-2019#Selecting](https://docs.microsoft.com/en-us/visualstudio/modeling/browse-and-rearrange-code-maps?view=vs-2019#Selecting)
Don't know yet if is useful (is 2AM here, time to sleep not to code review) but worst case scenario is a great example of NLP on dotnet which is what I was looking for :D Starred !
I declare that WinForums for WinForms should be an actual website aided in helping programming with WinForms.
Wow, Dapper has a shit ton of useless comments.
I assure you, it was not.
Are you talking about the documentation comments? They're used to provide hints in the IDE https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/language-specification/documentation-comments
I genuinely don't see the appeal of the builder pattern when all it is doing is duplicating the functionality of another class.
Hi guys, sorry for delayed reply. After publishing that I'm going to help people with C# I got like 200 messages. It was mission impossible to handle this load so I spent some time building the app that will help me with keeping track of who needs what, what is a skill level and background of the student and other details that will help me with context switching. Some other guys proposed help as well so my goal is to put together some tools that will help to organize this teaching squad and help more people. I don't want to do videos now as it's completely different game, the plan is still help 1:1 but in more agile way. I will keep you posted and will get back to you soon. Btw, are you using learning journals? Are you keeping track of what you are learning? If not and if you would like to try it, let me know. This is one of the tool that should make the collaboration more efficient.
No.
Also, you’re better off keeping values squared rather than taking a square root. Square root calculations are expensive on a cpu.
Basically it's "layers of abstraction" and "age of code". `HttpWebRequest
It's "layers of abstraction" and "age". `HttpWebRequest` was there first and was the lowest-level access to HTTP. As such, you write a lot more code to do anything with HWR than the other types. It's not bad, it's just sort of like cutting down a tree with a pocketknife. `WebClient` was the "easy mode" for HWR, sort of like how `File.ReadAllText()` is a shortcut for getting a Stream and using a StreamReader to read the contents. At that point in time, MS was pretty sure everyone was going to ignore REST and use SOAP, so they weren't super interested in helping people make random web requests. Eventually they gave up on that, and `HttpClient` was the result. They'd like you to use `HttpClient` instead of the two. It combines the configurability of `HttpWebRequest` with the ease of `WebClient`, and comes with bonus features like "If you treat it like an IDisposable you will have performance problems" and "it's impossible to describe how to configure timeouts in a way that works". They're still pretty bent on making you like SOAP. But `WebClient` is documented as obsolete and `HttpWebRequest` has too many moving parts. So your best bet is to either lean on something like `HttpClientFactory` or even the RestSharp library. In 15-20 years, MS will get around to letting .NET have a reasonable REST client.
&gt;To be more clear, we did a lot of work to run through the code and ensure it was ready for the open. This was done before the public PR. Sounds like me removing the comments // TODO: Hack to get this working.
Got a 2nd question for you. Alot of people have been making a big fuss regarding the lack of a UI that could be cross platform for Core. Specifically WPF not being ported over to Core. Just looking at the current code, I can tell that would be a huge undertaking. But is it something that your team discusses? I think there are some 3rd party solutions that attempt to do that. Like AvaloniaUI I believe. Would you try something like that?
is System.Configuration.ConfigurationManager not good enough for ya?
Newtonsoft does let you manually map class variables to property names with an attribute: [JsonProperty("uglyAndLongJsonName")] public int Size; Now doing this for everything is a manual process and both annoying and ugly, but you are free to do so if you want.
I really like this. I use LINQ a lot and this "just feels right".
Try Linq2Db
Builder pattern can be very nice for seed data as well as test data (that is, for unit/etc tests). Especially for complicated aggregates.
&gt; "it's impossible to describe how to configure timeouts in a way that works". How would you improve it, if you had the chance?
I'd like timeout to be a first-class citizen in the Task API, rather than "a feature of cancellation tokens". I don't think enough emphasis is placed on tokens, and it actually took me a long time to figure out `CancelAfter()` functionality existed. There's a lot of ways to define what I want "timeout" to mean. I *think* the current `Timeout` property only considers time to successful connection, with no regard to the data transfer phase. I think it would also be nice to surface a hard "I don't care what the status is, if it takes longer than this kill it." Sometimes, a user with a shaky 3G connection's receiving data at a rate that's going to tie up the phone for an hour. Sometimes, the user requirement is "if it's going to take longer than 60s, bail, because the user is a truck driver on the interstate and can't stop driving to force quit the application so they can keep running their compliance software". You can do that with cancellation tokens, but I sort of wish it were lower-hanging fruit. It's also possible I got HttpClient's behavior confused with something else's. I remember one of the APIs requires you to set a static property on some completely unrelated class? You repress memories like that.
I'll dig up the post (on mobile). Ef core vs dapper using direct queries (not going through dbset and entity tracking) is just as fast. The difference is so miniscule that a badly tuned query will mask any difference. Extra features don't come free though. Entity tracking, unit of work, super easy updates and inserts, lambda expressions for where clauses etc add overhead but are above and beyond what dapper does and was built to do.
I installed this today. The biggest improvement I found so far is when you click on a project that is no longer on your system, a message box is now show from the start page. &amp;#x200B; Up until yesterday the project would attempt to open, then you tell you it wasn't found.
I was discussing AvaloniaUI with my boss today. He said it doesn't sound worth it. It's using 3 different technologies for the UI. I guess that means a lot more work. I might try it myself, but not really in a professional setting.
WPF is being ported to Core, but that does not mean that it will be cross platform.
Having a WPF compatible library with an X11 backend would be pretty awesome. I don't think Microsoft is going to be investing it that directly however. With this code, community projects are in a much better position to start something like that should they wish (mono etc).
I wonder what they mean by "3 different technologies"? We have a flexible rendering interface but in practice we only use Skia (same 2d rendering engine as Chrome and Xamarin uses) for all platforms and optionally Direct2D for windows. And you don't have to bother with any platform-specific stuff because that is already abstracted from you. If you have further questions or needs assistance on your Avalonia project, do drop by on our Gitter chat ([https://gitter.im/AvaloniaUI/Avalonia](https://gitter.im/AvaloniaUI/Avalonia)) :)
Not sure if you're joking.. but a big corp releasing code without stepping on any licensing or patent mines is a feat in itself. Once small inclusion of an unintended 3rd party licensed code can result in mass-infractions, which is a huge liability to the author (Microsoft). Also, wherever there are 1st party code, Microsoft has to go through its legal and security team to verify that releasing said code has a proper open licence and doesn't expose unpatched security vulnerabilities in its deployed products.
I'm not against it, but on the website it said skia, got, and direct
Calm down. If you aren't sure if I'm joking then stop pontificating
Well yeah, of course we need to rely on platform's Windowing backend to do anything useful, those are Win32 (Windows), GTK (Only for native dialogs, we have X11 interface up for Linux) and OSX Cocoa. But like i said those are already abstracted away from you so you don't need to bother with those stuff :)
Yea abstraction is always great
Removed: Spam.
Removed: Rule 3, spam. Please review _and follow_ the [guidelines for self-promotion on reddit.](https://www.reddit.com/wiki/selfpromotion)
I love Avalonia, but two of my main issues are: \- Lack of support for RTL \- No DataGrid control
This is not self promotion. It holds no references to me. I just wanted a general discussion about it, help others and myself better understand solid by seeing what others think. Could you please let me know your reasoning?
https://youtu.be/ayp3tHEkRc0
/u/thestamp seems perfectly calm to me. Why are you dismissing their (rather informative) comment out of hand?
&gt; This is not self promotion You made the quiz. &gt; It holds no references to me. I just wanted a general discussion about it, help others and myself better understand solid by seeing what others think. From the guidelines I linked to: &gt; **But it's not spam! I worked hard on that, I make no money from it, it's original content! I'm not a spammer!** &gt; &gt; We're not making a judgement on your quality, just your behavior on reddit. Your stuff's probably amazing and someone would be really interested in it but... &gt; &gt; If you submit mostly your own links and your presence on reddit is mostly for your self-promotion of your brand, page, blog, app, or business, you are more likely to be a spammer than you think! Read the FAQ and make sure that you really understand that. You've already had a previous 30 day ban for discord spam, and have had 5 posts removed in the past for spam, so your account is already flagged and on thin ice. Especially for posts that are only tangentially related to C# (as this one, hence Rule 3) and posts that are to your own content. It doesn't help that this quiz suffers from the same issues as the quiz you posted a couple days ago (ambiguous questions/answers). And, as I said, the spam flag aside, it's still a violation of Rule 3.
Why is quiz = self promotion?
Hobby WPF coder here. Why not Core + HTML in place of xaml? Can be driven by a browser engine.
In the guidelines it mentions all the personal gain things. But.. I don't earn money to it, I don't advertise myself, nor any of my products. The quiz doesn't even have an author (just indirectly stating it in the post).
I will stop posting quizzes if you want, but I genuinely think it benefits others much more than me.
Understand that if this was the first instance of such a submission, then it wouldn't be considered spam. But your account, by far, is focused on your own content, and you've had several posts removed and even received a temp-ban. This puts your submissions on very thin ice and offers you very little leniency when judging your posts.
You state in the read me, that only one DbContext should be used. You then go ahead and write that DbContext isn't thread safe and shouldn't be shared across threads. And everything is built around async/await. Anything higher up using the same DbContext both awaiting a call is potentially running in two different threads and causing issues, just by using the methods as they are defined.
Previously we talked about posting lessons for clean code here, Twitch code reviews too. Is that okay to be posted?
The self promotion guidelines make it clear that personal/monetary gain are not requirements to have it considered spam.
They seem to be doing alright and haven't had user reports, and they're generally high-effort content, and generally very related to C#, so they're alright for now.
Okay. Then I will continue posting them. Thank you for clarification.
If you do, I recommend you: * do not post them as frequently as these two (that is, don't post multiple quizzes per week), * make sure the quizzes are _very_ C# related rather than on general programming, * and make sure the questions/answers are very clear and unambiguous. Quizzes/answers based on subjective opinion are not useful or beneficial to readers. I would also suggest you avoid delays in sending back results; let users get instant results. Leave it to the comments for discussion on more broad or subjective areas.
The thing is this is designed for a class that I teach and so I woukd like to see how others think, not just pick a b c. But I might make a different version for Internet, so that the evaluation can be automated and no free opinion given. Thank you for the tips.
There is a ton of tutorials on Sqlite and winforms. Working with Sqlite doesn't really change in the context of winforms. So don't search for a full package, rather look for one of the other in a more focused context.
So do you use the quiz results, feedback, and discussion to design the quizzes you use in the class you teach?
Yes. I use the feedback to improve quizzes, cover most common mistakes, brilliant answers and try to explain the what and why.
Mmmm WPF. I am just going to read the source. No idea why. I feel like I have to :)
Then you are gaining an undisclosed benefit to the people taking your quizzes on Reddit? Essentially data mining them to improve your teaching position without them knowing?
Wouldn't say so, as that is not the main point of it. I mean I want to share and help and give opportunity for others to learn as well and have a way to evaluate them. I think it's obvious that feedback will be taken in consideration and that's the way to go about it for everything independent on form.
All I do is use all the means possible to learn and share what I learned with others in ways I see most fit to deliver highest quality and least subjective content about subjective topics like SOLID. Data mining would indeed be more like spamming, where I gather and store results in a much bigger scope, which (subjectively) I don't.
Regarding RTL and Unicode text, we have an ongoing effort in making those possible ([https://github.com/AvaloniaUI/Avalonia/pull/1950](https://github.com/AvaloniaUI/Avalonia/pull/1950)). Text rendering might seem trivial but it is not. It's one of the most complicated things that a UI framework must support and i personally hope that we can make it as stable as we can in the following releases. We do have DataGrid since our last release, you just need to import \`Avalonia.Controls.DataGrid\` via NuGet and it has the same API as WPF's.
That's great to hear, thank you for the reply!
I can’t use VS2019 without Custom Document Well (tabs on the left). Has anyone found anything that will provide such functionality? Working with more than 5 files is a pain in regular VS...
it is called ElectronNet.
[CLR via C# by Richter](https://www.amazon.com/CLR-via-4th-Developer-Reference/dp/0735667454)
Microsoft clearly said several times that they will not create a cross-platform WPF. The cost does not outweigh the benefits at all. They will also not accept pull requests that add cross-platform support, because that would mean Microsoft has to support and maintain these additions.
I seem to recall that there are/can be performance benefits using the generic one, but not at all sure when you store everything as object. That being said, I would use the generic one and be explicit about the fact
Last time I checked Electron.Net was a one-man show. I wouldn't use it for anything productive.
I believe `IEnumerable&lt;Object&gt;` would be more convenient (e.g. LINQ), but if you actually have to consider using it, that's a huge code smell for me. Any chance you could elaborate why you would ever need it?
`IEnumerable&lt;T&gt;` avoids boxing value types which significantly improves performance, but not when `T` is `object`, an interface, etc.
It was more of a theory question. I thought to myself- why would I ever want a non generic collection? At this point I consider is being deprecated and fully replaced by the generic counterpart.
Productivity power tools
Not supported in 2019. It has maybe 3 of 15 tools and document well is not there
The only reason they exist is because C#1 didn't have generics, and they were never removed to preserve backwards-compatibility.
Seems pretty mild relative to much of the code I've seen when it comes to ORMs and other such things.
Hell, it can be super helpful for following and inversion of control pattern. If you have Entities, DTOs, and ViewModels. A solid builder pattern makes the actual use of the separation a breeze. I should share mine someday, it's super fast, has an API I painstakingly made as clean and easy as possible, and I've kinda fallen in love with how easy it is to utilize... I just have a few edge cases to sort out, some that C# 7.3 and soon 8 might make a bit easier.
You can install it with a workaround: https://superuser.com/questions/1421557/can-i-install-the-custom-document-well-vertical-tabs-extension-for-visual-stud It won't work anymore in 16.1, so you have to download 16.0 at http://my.visualstudio.com
There was a documentary on Netscape efforts to open source Mozilla, if anyone didn't realize the effort that goes into such things.
Care to explain how you would handle setup, edge cases and mapping ?
Almost right. We need the untyped version for dynamic typing scenarios such as working with WPF data binding. But besides that I would agree.
I was going to say WPF, but with variance (in/out type parameters) we technically don't need the untyped version for that either.
We have that, it's called Blazor, which uses Razor syntax that is essentially HTML + C#. It runs on Mono or in .NET Core (Server Side Blazor) and both can run on browser based stuff like Electron. Since Edge is going to be Chromium, I think we will have Chromium embedded inside Windows soon - which will reduce the app sizes compared to Electron.
VS has an option to create a “code map” that diagrams classes and methods
Very interresting!
Should one extract this condition: ``` !HendrixAPI.Connect(port).getDeviceStatus().ToString() == "DEVICE_READY" ``` into a separated method to call it in if-statement so it would be a positive check?
Great stuff, I love WPF. Is it wishful thinking to hope some writes an OpenGL renderer for this...
&gt; Over 4k file additions over 4k screamings happy cake day btw!
&gt; and the only reason they haven’t been removed is backwards compatibility. Although arrays aren’t inherently generic, and those are still necessary (for the framework).
Thank you!
Try right clicking the title bar.
Anyone here recommend upgrading to 2019? I'm still on 2017 and I'm wondering how much better 2019 is
I do, i find 2019 to be faster overall (especially on solution initial load)
2019 still locked up once per day on our (rather large) solution. It got worse after installing Reshaper (now about 3-4 times per day). The application stops becoming responsive and usually results in loss of work. 2017 was just as bad. I've not tried the newest update, but every update in the last 3 years has failed to make any difference, so I'm not holding my breath. Save and save often!
I was going to mention the same book. Definitely the best book on. Net I have read
2019 hosed all my other VS installs breaking everything.
I'm staying on 2017 for now, 2019 broke all my previous VS installed, broke vswhere, reinstalling did nothing. Had to run some PowerShell scripts on the vs dev forums to just get 2019 working, Linux support is broken, mobile sdk versions are broken as well (no more side by side SDKs work). Maybe in a few months after they fix most issues.
I've used the same asset pack for a semester work, lol
IEnumerable&lt;object&gt;
Why can't we just have a single Visual Studio with small updates going forward? By the time everything is stable, a new major version is on the horizon.
That'd be a question for the devteam, I'm very disappointed and upset over this myself, involved me reinstalling completely and just not installing 2019. First they broke Linux support on 2017, the devs told us to upgrade as they wouldn't be updating 2017 anymore (they pushed 2 updates since then), install 2019 and breaks everything 😑
[This helped me back in the day..](https://stackoverflow.com/questions/4291912/process-start-how-to-get-the-output)
Depends on what you have in mind. Validation is basically business logic anyway, albeit usually operationally tied to input. Start setting property names for JSON or XML exports and you’re potentially opening a pantera’s box of having to cater for every conceivable form of the data, but without the safety and flexibility of mapping to a DTO.
Thanks for the replies, all! I'll be sure to check them out.
 proc.Start(); while (!proc.StandardOutput.EndOfStream) { string line = proc.StandardOutput.ReadLine(); // do something with line } &amp;#x200B; Looks good! Hope it works, will try it out tomorrow. &amp;#x200B; Thanks man!
I had in mind attributes such as [Required] or [StringLeng(X)]
Like you, I am sticking with 2017 until they solve this issue.
That's a good point! I think I made the transition so smoothly I didn't even notice my document well isn't on the left anymore...
&gt; Why can’t we just have a single Visual Studio with small updates going forward? So the devs have the occasional chance to deprecate stuff and make significant rewrites. And so marketing can do presentations.
I personally just skip validation via annotations and use something like FluentValidator everywhere. My experience is that eventually you'll need more complex validation than annotations allow, and then you have two different places to do validation and that reduces code cohesion and understandability
Yes, that point is the thing that concerns me the most. It does make a lot of sense! Thank you🙂
Very nice!
I'm curious, where are non-generic collections used in WPF?
This is great, thanks for sharing. Do you have any base hardware requirements in terms of network speed or network adapter?
Using Roslyn is the way to go, especially since, as the language is updated, so is Roslyn. Using any other 3rd party lexer will most likely lag behind for future releases.
I agree. I also tend to use System.Data.Annotations on View Models for some basic form validations though.
```POCO is what models in domain should be.``` Should? I'm not a fan of POCO objects (unless I'm doing functional style, and then I want immutable objects, so not truly POCO)
Personally I hate them, but I've been bitten by crappy use of attributes before. The dependency sounds fine, but ask what you're getting in return. There are some simple cases they work well with IDataErrorInfo, but again, you don't need them, and they won't work in more complex situations. YMMV, but every time I use a website that makes the username box go red because I clicked off it to ender the password first makes me think they used their technologies version of this stuff.
No, you can have it in line. Over abstraction of code also just makes it harder to read. :)
I personally do not favor passing values in the constructor or have logic within the constructor. This because it makes it difficult for unit testing. And unit testing is more about making code testable than being able to write tests, so that the test stay maintainable. &amp;#x200B; In your example, unit tests for code which instantiates an Enemy object will be covering the constructor logic. In all these unit tests one would have to make sure to satisfy the logic, which makes tests unnecessarily heavy. Second is if you were to change this logic, these unit tests for other classes than Enemy class will fail, which does not satisfy the purpose of unit tests, making them more like integration tests. For this reason, I think it is better to define POCO's without any logic in them. Then have a class (let's call it EnemyInstantiator) that is responsible for instantiating objects of this type, where you can place the logic such as health must be greater than or equal to 50. This logic can now be unit tested as tests for EnemyInstantiator. Now the other classes that want to instantiate enemy objects can do so by implementation against the interface for EnemyInstantiator (let's call it IEnemyInstantiator). This makes code much easier to unit test. &amp;#x200B; Example: &amp;#x200B; public class Enemy { public int Health { get; set; } public int Mana { get; set; } public Guid EnemyId { get; set; } } public interface IEnemyInstantiator { Enemy Instantiate(int health, int mana); Enemy Instantiate(int health, int mana, string guid); } public class EnemyInstantiator : IEnemyInstantiator { public Enemy Instantiate(int health, int mana) { var id = System.Guid.NewGuid(); return Instantiate(health, mana, id); } public Enemy Instantiate(int health, int mana, string guid) { return new Enemy { Health = health &gt;= 50 ? health : 50, Mana = mana, EnemyId = System.Guid(guid); }; } } public class Program { private readonly IEnemyInstantiator _enemyInstantiator; public Program(IEnemyInstantiator enemyInstantiator) { _enemyInstantiator = enemyInstantiator; } public void DoSomething() { var enemy = _enemyInstantiator.Instantiate(...); // .... // .... } } Here the EnemyInstantiator's Instantiate methods as well as Program.DoSomething can be unit tested separately. If business logic would change, say the health should be 100 and above, tests for Program will not be effected.
Wow! MouseWithoutBorders here and even if I cannot live without it anymore there are many hard-edges and room for improvement here and there. Will try it out for sure. Plus it is dotnet!
All non-generic interfaces should be considered legacy and obsolete.
Moving the mouse and and spamming keys uses around 0.5mbps. Most of the bandwidth is TCP overhead, UDP would be a better choice for speed but I went with TCP for reliability so no inputs get lost.
Then perhaps, should there be introduced a variable holding the value, so it's a positive check again?
In theory, yes, you can have a method that does something like `IsDeviceNotReady()`. However, positive check shouldn’t come at the cost of code complexity. Remember, the goal of positive check is to make the code more intuitive to read so we don’t have bugs by misreading it. If having the negative code results in instances of simplified design, I’d support that.
Thanks for your reply. The results of your answer (for reference): 1 { Name = 10, Scheduled = 05/22/19 } 1 { Name = 20, Scheduled = 05/23/19 } 1 { Name = 20, Scheduled = 05/22/19 } A few more questions: * Is there a way to add the count to anonymous type? Something like `{ Name = 10, Scheduled = 05/22/19, Employees = 1 }`? * Is there a way to get a distinct list of all of the `Scheduled` values? * How would you enumerate the list of lists in a manner that it produced the cross-tabulation that I mention in my original question?
Which means that I wasn't wrong? Sorry for the long conversation, I'm just trying to wrap my head around the idea
I am sorry if it's dumb question, but what's the point of async-await in the given code example? If we have a dedicated thread for processing the queue anyway, I don't see any reason not to block it
Data binding, say attaching a list to a Combo box or Data grid. I'm not certain, but I believe that it can bind to anything that exposes IEnumerable or better.
Oh yeah, I think that's possible indeed. Never have done it myself though! And I believe that'd be really frowned upon.
Be aware that `ReadLine` requires the output to write a newline character.
In my experience, the attributes on POCOs in the domain usually end up tied to something in infrastructure or web. For example, entity framework attributes. In this case, it isn’t clean code. I would say that if your attributes’ functionality is contained within the domain project, then they are fine, otherwise find another way to implement.
You don't get a choice. The ItemsSource property is just Object. The decision about which interface is used is a hidden implementation detail. That's why I get pissed off when people return List&lt;T&gt; as IEnumerable&lt;T&gt;, saying that it "makes the collection readonly". No it fucking doesn't, WPF doesn't even know which interface you returned.
&gt; You don't get a choice. The ItemsSource property is just Object. The decision about which interface is used is a hidden implementation detail. Indeed, I mean I never used a non generic IEnumerable for binding. &gt; people return List&lt;T&gt; as IEnumerable&lt;T&gt;, saying that it "makes the collection readonly" People really do that? lol, yeah, that's not how it works indeed. WPF has its quirks, but what framework doesn't?
`IEnumerable&lt;T&gt;` is what I use for generics, should be better performance too
You’re right, this is unclear. Specifically it’s dealing with transactions that is currently thread unsafe. You run into issues with multiple active result sets. Normal database calls are actually thread safe. This is a defect that I need to work on. Thanks for the feedback.
Every UI toolkit needs to interact with an OS toolkit to draw and some window manager to manage the windows. Otherwise your apps can only be full screen and effectively have to reimplement X11 (and it would only work on platforms that allow that level of control such as Linux)
Can't believe I got downvoted for saying abstraction is great. It helps with extensibility and the management of your application.
Awsome job :) this is very useful.
It came off (at least to me) as snarky and not genuine. Sorry about the miscommunication.
You're welcome. I would suggest using something a slightly different pattern, where beginning a transactions returns a new "safe" context to use inside the scope of the transaction. using(var transContext = await _context.BeginTransactionAsync()) { var res1 = await transContext...Select(...); }
I dont understand it. C# is an Object Oriented Language, and what do people use? Some kind of mutable functional style programming. Of course it shouldn't be POCO's, your domain model should model your domain.
No I was being serious. My boss has recently been pushing abstraction and using SOLID a lot more.
Yes, just install it. Everything is better or same for me (comparing to 2017). Installation does not break anything for me. I was even surprised because I was debugging code on 2017, run 2019 download &amp; install. Installed vs 2019 opened, ready to work, out of nowhere. Just like that, in the middle of debugging. Works like a charm with R#. PS I'm working on dotnet core mainly.
&gt;Has anyone found anything that will provide such functionality? Try [Tabs Studio](https://tabsstudio.com/). I'm using it and works well. Not in vertical mode tho, but it also has that feature.
I'd recommend going over the Yellow Book first(its in the sidebar), go through at least half of it so that you can get a feel for the language. Afterwards just go through the pluralsight C# [path](https://www.pluralsight.com/paths/csharp)
\#1, #2: [https://dotnetfiddle.net/DeQNRP](https://dotnetfiddle.net/DeQNRP) &amp;#x200B; Your third question is about the displaying which I can't answer. Maybe someone else
I'm guessing it's more related to selling new professional/enterprise licenses.
Cool thanks for the advice on that :)
Yes and POCOs can contain behaviour. POCOs are not dtos. So it's fine. As long as it is bare bone without dependencies to outside.
I had one case where I had to use IEnumerable over IEnunerable&lt;object&gt;. It was when I needed to pass it into some old com component and IEnunerable&lt;T&gt; was not supported.
Get your hands dirty! Search for a C# hello world tutorial and dive in.
Yes, that as well (though MSDN subscriptions have been available for a long time, so I'm guessing non-subscription licenses of VS only make up… 10%-ish?). But even if you have subscriptions, a PHB somewhere might question why people keep paying for a subscription when there are only iterative improvements. With significant releases every few years, that's far easier to justify.
&gt; It got worse after installing Reshaper This is not new. Resharper has *always* been a resource pig. In my opinion, it became obsolete as soon as VS added "go to implementation." 2013 was pretty meh, but still an improvement over the "old" versions. 2015 was a hug improvement, but still not 100%. 2017 has been awesome for me. My only real complaint is that the Git integration isn't "quite there" yet (but it's close).
Yeah, I'm wondering the same. I have it installed, and have been updating it, but have not started using it yet. I tried when first installing, and it took ages to open/build a large solution (like, 3-4x what it took 2017 to do it). If that's fixed, I guess I can give it another go.
Awesome! I'm going to try this when I get home. Thank you for releasing the open source. As a side note, I've been using [Synergy](https://symless.com/synergy) for 10+ years. It used to be free, but is now paid. I've largely been very happy with it. However, these days I'm trying to prefer open-source code on my system over closed -- so thank you for your contribution!
Oké, guess I don't get what a poco is. Or what wouldn't be a poco. But sometimes your domain depends on your implementation. Like needing a private default constructor for your persistence layer to initialize your object.
&gt; People really do that? Yep. And they do it while screaming SOLID as if it were a religion, battle cry, and lover all at the same time.
Some Dtos are POCOs. If dto1 is plain with a bunch of properties made of primitives- that's Poco. If dto2 is decorated with attributes coming from EF or Postsharp, etc- that is still a DTO but no longer a Poco. Poco needs to be plain, without dependencies outside your domain.
I don't understand the link with SOLID. I meant people returning IEnumerable thinking it makes the list readonly. SOLID is almost always a good guideline to follow in anything but small programs. That being said, it's a guideline, not a religion indeed.
what? the code is just like 3-4 nested things and would probably be something that i would create in their situation, but it still makes it less "pretty" or nice from an outsider looking into their codebase.
&gt; ` /// &lt;param name="sql"&gt;The SQL to execute for the query.&lt;/param&gt;` caved in head wojak drooling tier comments here.
If you can think of any features/improvements that you'd want added, let me know, i'll see if it's possible.
OK, that is great. Congratulations on a great project and keep us updated with progress!
I’m taking C# in school currently. I would recommend Scott Allen courses. Just search for him by name. Pluralsight also offers a C# path you can see a lot of courses there
That's just another historical implementation detail from the time before generics, though. The language and runtime paper over most of that and for pretty much all intents and purposes arrays are generic unless they've been upcast.
\&gt; putting the link as text in the body instead of a url like how reddit was designed lol
RoutedUICommand.GetText() was one of the first functions I saw. Don't know what I expected.
Does it still work for core? I'm trying to move entirely over to core at this point.
Rx indeed has a very nice model, but it isn't without it's own warts. I think Task and cancellation being separate are good moves, though, because it gives more flexibility. You unfortunately pay for it with a little more boilerplate code sometimes. This really has nothing to do with HttpClient, though :-).
I'm generally horrified by this practice of fluent API's that mutate. At least with the original API's its clear in your code that the objects are being mutated. This, not so much.
I find the non-generic version quite useful for reflection, i.e. if (thing is IEnumerable enumerable) { var count = enumerable.Cast&lt;object&gt;().Count(); }
`GetValue` works the same as `SetValue`, you first call `OpenSubKey` with the path to the registry key and then call `GetValue` with just the name of the value.
Yeah been listening to a few of his vids and following along with some hello world. I did hear him mention on the video I watched that there was better videos in pluralsight for absolute beginners, that's why I was sort of fishing around for what he might have been talking about
Because you made it open source I will take a peek at the code and if not too lazy fork it or try to make some PR. I am a full stack dotnet programmer. Or hope to be one soon or late :-P
&gt; If you look at all the different ways HttpClient supports cancellation, it would be hard to boil it down to a single easy to use parameter. Right, that's kind of my problem. They gave it a single `Timeout` property, which implies there's a one-size-fits-all timeout. IMO there shouldn't be a property, but in the Remarks section there should be a nice discussion of how one might implement timeouts and examples of common cases. The idea being if people ask, "Why can't I set a timeout?" they'll go to the documentation (or SO, or reddit), ask, and get the answer.
I don't follow. Your code just casts back to the generic version, and it has nothing to do with reflection.
&gt; I don't understand the link with SOLID Neither did the people shouting about it, but that was their 'reason' for changing all the return types and breaking my unit tests.
Generally when developers say "POCO" they mean an object with only fields or properties and no methods. Plain 'Ol CLR Object. Beyond that, much terminology is up to interpretation and context. For me - "models" are objects with methods that make up your domain logic, "dtos" are basically POCOS - no methods on them, just organized data to move things through the system
How did I never imagine these things existed! Very impressed.
Listen to this podcast from the developer of xunit. He talks about nunit and the move. https://open.spotify.com/episode/5grB0FrnfNdoF1suIWI772?si=svav5XYaToWCaSksFziX1w
https://open.spotify.com/episode/5grB0FrnfNdoF1suIWI772?si=svav5XYaToWCaSksFziX1w
The Yellow Book and Bob Tabor's free C# beginner tutorials on MS Virtual Academy (also on Youtube) are a good start.
I make the domain models virtual then override them them for the specific application. The app override has data annotations and validation code. This allows different apps to handle validation differently on the same objects. I often run CRUD tools where different applications need different behavior for the same data, and this makes it easy to manage I use a similar approach for data connections. I use custom rolled DB tools (not EF). There is a core tool that defines all of the functionality, but applications can override it to force data validation at the DB controller - that way you always know that the objects being written are valid according to the application requirements.
Interesting reply. Thanks.
Read this: https://xunit.net/docs/why-did-we-build-xunit-1.0?utm_source=share&amp;utm_medium=ios_app
Well, the devil is in the detail, and I’ve often encountered it :p. But they are weird in other ways such as using mostly static members.
Theres a few options you can pick, I believe you can go by xPath, class or just use the querySelector.
perhaps you can write some javascript to dump the list of names into the console, copy paste that into a notepad then write a small C# program to parse that out notepad.txt contents to whatever you need
You're looking for the operator &amp;, try replacing the *
Hexadecimal numbers are just different representations of numbers in nearly all programming languages (like decimal, octal, binary, etc.). The operations don't change based on the representation you're using. "Binary multiplication" is a bit-wise AND operation, which is the &amp; operator in C#.
&gt; For me - "models" are objects with methods that make up your domain logic Yeah, this is all very opinion-based. For me, very little to no logic should live in a model. A model is just that: a data model.
Thank you very much 🙈
Yes. This book is about how how the internals of. Net work and not about syntax of c#. When I was trying to understand how async await works, this is the book that I finally learnt from. I would also highly recommend 'c# in depth' by Jon Skeet. This is a great book if you want to learn language features of c# in depth. Remember that asp.net core etc are just framework. Once you have fundamental understanding of c# and. Net, mastering them is just about reading their api
+1 for Bob Tabor, that's how I got in it. Also lookup a todo or task list project and follow a tutorial for that. Taught me some good foundations without diving TOO deep
Thanks for the advice, but sadly enough I didn't have the opportunity to further work on this. I think method overloading would have been the way to go.
I have a question on this as well -- how much do you need from the core c# classes to start doing web applications?
The issue is that you're dishonestly telling people they **must** pay in order to use the software, and that message does not agree with the license. You're misrepresenting the MIT license and effectively lying to people. You're free to choose a dual licensing model wherein those that have paid are granted the MIT license and all others are subject to GPLv3 or even 'all rights reserved'. There are any number of ways to do this without this deceit. &gt; So it was either find a way that i could justify the time required, or close down the project. Or... just stop working on it and leave it as is? Unmaintained projects get revived fairly regularly if there's great enough interest.
If you want to learn asp for web development. Please watch the following video. https://youtu.be/aIkpVzqLuhA Your service tier is here. This should be easy to follow for a beginner
What have you tried so far?
Webdrivers have a method called FindElementsByClassName you can use. This will give you a list IWebElement containing the username divs. Loop through this list and use .Text on the elements to get the usernames.
Do you not use view models?
I first recommend grabbing the UL element by: Webelement list = driver.findElement(by.ClassName("userList")); Then loop through that list, grabbing the &lt;li&gt; elements while doing something like so inside of it: element.getAttribute(data-username)
Which makes sense for the first few version updates, but at this point is honestly rather ridiculous.
I did the khan academy one in a day a few months ago. It doesn't cover all those topics but it'll get you started. It was really interesting. Some of the sorts are pretty simple if you can visualize them. Some are not.
I think SOLID is a good starting point, but like with most things, being dogmatic about it is not good.
Well, MS avoids making backwards-incompatible changes at all costs, and there is *a lot* of code out there depending on those types and interfaces, often unknowingly (e.g. looping over certain WinForms collections). I did hope they'd get rid of all the cruft in the language and framework with .NET Core since that was going to break compatibility anyway, but unfortunately we somehow ended up with the worst of both worlds.
What about ClientWebSocket?
They are like that because the intellisense metadata is created from them.
Start at 1, otherwise you'll multiply by 0 repeatedly.
Someone who started with the new stuff and skipped that; what's garbage about it? It's difficult as a "beginner" to get a proper overview of which old APIs or underlying libraries are still relevant and what is completely deprecated.
Roslyn does not expose the lexer class publicly. But if you just want to parse the tokens, then you can call SyntaxFactory.ParseTokens() API and it will invoke the lexer for you.
If you wish to insist on using pointers because of nanosecond performance is of utmost importance, so much that even nanosecond operation from managed code still isn't good enough for you (are you doing high frequency trading?), then just stick to c++ Pointers are unsafe, it's too easy to write shite code, slow development and maintenance costs outweigh the slight performance gains. It's not worth it.
Why do you think something being written in C# mean it is written by amateurs? Why do you think something that was dealing with I/O be that much faster in C++? Why do you think something that something written in C++ is more "reliable"? Dunno whether your post is trolling or just stupid tbh.
SQL Server, PostgreSQL, Redis, etc - as a rule they are all written in C++. And obviously it's faster than code executed by a runtime.
Check out Unity's recent blog posy about C# and performance it makes for interesting reading
So what if they are written in C++? It doesn't mean that something written in C# is written by amateurs or unreliable. As for performance well it really is swings and roundabouts whether C++ is that much faster than C#. Here is a more sensible discussion on the issue. [https://stackoverflow.com/questions/145110/c-performance-vs-java-c](https://stackoverflow.com/questions/145110/c-performance-vs-java-c). Still don't know if trolling or stupid.
I know too little about Event Sourcing and the related software stack. No trolling at all. SO tends to ban questions like this one. That's why I moved to reddit and asking questions to get the picture. No reason to be rude.
You come to csharp subreddit and call everyone amateurs and I am the one being rude? Unreal. Blocked.
\&gt; Posts to r/csharp \&gt; Calls people who write C# amateurs &gt;No reason to be rude Well done, sir.
What's the coding opportunity at work? It's always good to have a work project that needs some programming solution to get you started.
There are so many ways to solve this. Builder / Director pattern is one, where you have an IEnumerable of Builders that build your view model, one for the main attributes and one for the auth attributes who bails if user is not authorized. Or your view model can accept a isAuthorized parameter in the constructor with model and conditionally map some properties. You can also use conditional serialization. You'll have to make sure you're api serializes with json.net. https://www.newtonsoft.com/json/help/html/ConditionalProperties.htm
Why would AMATEUR be an offensive term? Compare resource consumption of iOS and Andoid and see where runtime is not helping you at all.
Removed: Rule 4.
Hey thanks for the pointers. That's kind of where I'm lost I think, I've done so much reading over the last few days my brain is just mush and I've got too many threads to pull on! I have looked at conditional serialization and have made some in-roads in to that approach using a custom ContractResolver. I'm analyzing the tagged attributes there to check whether the field should be published or not. The issue I'm having on that front is that I don't appear to have access to the object instance itself, so I can't probe the actual data. Admittedly I need to do a little more digging so that may be viable yet. Encouraging to know the overall approach isn't completely stupid though!
That works for some people, but the way OP describes their experience with Python suggests it's probably not going to be ideal for them
Hey thanks for the pointers. That's kind of where I'm lost I think, I've done so much reading over the last few days my brain is just mush and I've got too many threads to pull on! I have looked at conditional serialization and have made some in-roads in to that approach using a custom ContractResolver. I'm analyzing the tagged attributes there to check whether the field should be published or not. The issue I'm having on that front is that I don't appear to have access to the object instance itself, so I can't probe the actual data. Admittedly I need to do a little more digging so that may be viable yet. Encouraging to know the overall approach isn't completely stupid though!
What? And why does that project contain a DTO folder and a model folder? I think of DTOs as a type of model used for data transfer. Maybe they are really DAOs?
Literally print out the Wikipedia articles for each of those topics and read it twice
So the idea is that DTO classes are for mpped entities and only mapped entities. The model folder inside the DMZ project would be for classes that only live in the contoller/service universe... Fo example an ApiStatus type.
\[ Codewars s free \]([https://www.codewars.com/dashboard](https://www.codewars.com/dashboard)) It's very well; thoiughjt smnr upi hry trrfjsnsfl; \_[dfb;lgddf;ldfkldfkldfkldf \\v;ovl jrrsrsy](https://www.codewars.com/dashboard)
In that case I would put the DTO folder as a subfolder of the models folder. Pedantic, but these matter over the long term.
Also make sure your not trying to read a 32 bit location from a 64 app. Windows has separate registry hives for hklm for syswow64 and 32 bit apps so the different architectures can have different registry settings.
Why are they giving you a non-real-world test?
Great post. My goal is to learn as many things as possible. This makes for more creative problem solving. The great leaders of the world dont get there by staying in the rails. They wander off the tracks a bit and look around. What they learn by doing this helps in the long run.
It sounds like you might be facing the kind of company that gives /r/cscareeradvice fits. They call it "leetcode" interviews. I went through it and just did tons of Google searches, I never found any one site that seemed to be exceptional at explaining things. The book *Cracking the Coding Interview* is basically the script they use, but I feel like more than half of its later explanations are "Here's the code" without a real attempt to help you understand how you'd arrive at the conclusions intuitively. Good luck. If it's the hardmode leetcode interviews, they can be brutal, and often it's more important to have seen the puzzle before than to be good at solving problems. Let that really shape your opinion of if it's the kind of job you want.
I was asked to join the development team if I could get the basics of c# down, building web applications but I'm not sure on the full scope of what I would be getting into.
Awesome thanks!
Because they're using stupid interview tactics
This is interesting as I will have to do something similar in a near future. Please keep us posted on the route you take.
Try this http://www.gainlo.co/
I would call these Contracts. They are the external API contracts exposed by your service. It is also good to keep them in a separate assembly/project, as you have done.
&gt; pantera’s box Fuck yea! 🤘🏻
We implemented something similar using the IAuthorizationService provided by .net core. https://docs.microsoft.com/en-us/aspnet/core/security/authorization/resourcebased?view=aspnetcore-2.2
I did this years ago. I had a coding background, but it really starts at 0 and goes through the basics of the language. Generally I do like the MVA offerings and they're free! https://mva.microsoft.com/en-us/training-courses/c-fundamentals-for-absolute-beginners-16169
I know exactly what you need, go to edx.com, havard uploaded a computer science course on there called CS50, they have an entire around 2 hour episode just for searching algorithms and data structures, I watched it last week and it's very clear and well explained! I think that lecture was in week 3 of 4 if I remember right
Thanks for this. I did investigate that but it looked to be more oriented towards more granular access to specific resources. In this case, the user will \*always\* have access to the resource itself, I just want to limit some of the fields available to them at a granular level.
I am new with these patterns. I looked it up [here](https://www.dofactory.com/net/builder-design-pattern) and had some questions. The builder looks like its responsible for different parts of the product. So you wouldn't have a different builder per different part (attribute) right?
The models folder in the dmz project?
I have and have poked around with LaTeX and such. Do you think it's the best format/tool for the job? It looks like it's mainly used for math and science -- but I've heard of it often used back when I did some Linux stuff. I don't have a reason *not* to use it. Lately Markdown has been used. Any reason for one over the other?
No, but you'd have a builder that could augment your class with properties specific to authorized users. This wouldn't use attributes at all. So some of your class properties like taxOwed would be null after a single pass, then the second builder would be responsible for checking if user is auth and if so mapping those extra props.
Check the book "Algorithms Unlocked" by Thomas Cormen. It's like a summary of famous Algorithms by CLRS by the C of CLRS himself. It lists and explains basic algorithms like different sorting methods, string operations and graph building and traversal approaches. It'll be a reference book and you can try to implement them in c# as you read along. It's good for beginners and to get started with basics.
that penalty is very small compared to reissuing another request based on the result of the 404. so performance isn't really the issue, but code flow is.
Typically the companies that do that dont retain employees very well.
If you are asking this question, and have been using C# for about a year I am going to propose that you are asking the wrong question. Now, if you don't know how to use generics, interfaces, events/delegates, or extension methods you should look into those concepts. Otherwise you know everything you need to know about C#. The truth is, there is no such thing as "Advance C#". What you may not know at this point is more advance programming techniques and how to apply them in C#. For this you want to be looking for items on design patterns and clean code. My current favorite example of this is the chain of responsibility. The best scenarios I have encountered for this is in validation processes and filters. I believe this design pattern when applied to those scenarios epitomizes what good clean code should look like.
A good guy shared his slides with me https://drive.google.com/drive/mobile/folders/1KY3EDLTY8uq6Ya6jOa7l4VbnQjcNGZsx?usp=sharing
There's not enough info to know. Algorithms are important for certain types of work.
http://billion.dev.losttech.software:2095/song/1445674260 "This trial version of Gradient will expire in 28 days" Song lyric of the year right there.
Contracts... I like that. Thanks!
Thanks! I like hearing about practical applications of these patterns. It seems like it takes a lot of experience to know when to use a specific pattern.
What the f#
Some super quality songs here. Just generated this gem: "Untitled This trial version of Gradient will expire in 29 days. Please, download new version from NuGet. O come come come come to my door, Come come come come come to my door, Come come come come come to my door, Come come come come to my door, Come come come come to my door. Come come come to my door." http://billion.dev.losttech.software:2095/song/2395925127
edx.org The .com version is something else entirely.&gt; CS50
I do sometimes, but not always. Though I don't keep them with UI part. Should I not?
That's about twice the lexical diversity of Justin Bieber's "Baby"
It depends on your scale and bottlenecks. In a system with high CPU usage or where latency is important, you'd absolutely want to avoid a stack walk.
I'd aproach it this way: Have a Base ViewModel with all the public properties and derive one of it with the private ones. Have a model with all properties and use automapper. Now in the Action Method you return an ActionResult of the base VM and map your model accordingly to this.User.Claims (for instance).
Looks like your "start" method needs to be capitalized: `void Start()` It's a preset message that Unity will call and needs to match exactly, even the case! Hope that helps!
dont do this to me mate...now my monitor is full of coffee and my colleagues are looking disturbed
This actually works amazingly well, it is shocking! I could see some of them actually being songs with a few tweaks or corrections. I have gone, too far, I am the final survivor of my death I am the death of my father I am the death of my mother (I have gone, too far, I am the final survivor)
C'mon, don't be too harsh on it. Imagine what would you write, if you grew up listening to &amp;#x200B; Ah, Gucci, Gucci, Gucci Cartier, Cartier Gucci, Gucci, Gucci &amp;#x200B; Add it up, You multiplied and multiplied but what's it leading to? Add it up, The only thing subtracted is the love I had for you So add it up, oh Add it up, oh Add it up, oh Add it up, oh &amp;#x200B; (that's an actual lyrics from the original dataset)
That was before I fixed log output to go to STDERR instead of STDOUT. It caches songs, so that's what you see.
For every good looking text you should verify it is not googleable. The model could have overfitted, especially if the song was popular. &amp;#x200B; Surprisingly this one seems to be unique. Could not find "I am the death of my mother" anywhere else.
We storing DTO in DataContracts project and services interfaces in Contracts .
Looks nice, I'll give it a try, I've only experimented with the ConsoleClassifier sample so far (which uses Workspaces, Solutions, Projects, and Documents, and gets tokens with the Classifier.GetClassifiedSpansAsync() method). Is SyntaxFactory.ParseTokens() also useful for parses after small edits, or is there a different/better way to do it?
If I understood the problem correctly, you want column level data isolation. Here is something on row level isolation,there's 3 parts, but here's part 1: https://oncodedesign.com/data-isolation-and-sharing-in-multitenant-system-part1/ Maybe it would be possible to make the "private" columns a navigation property of the master object and configure EF core to load them depending on user authorization or apply DBContext filter (HasQueryFilter IIRC).
I'd go with separate DTOs and different endpoints. I see no value in having one endpoint return different data based on the user who calls it. It doesn't simplify things for the implementer or the client
Do I need to learn Health Level 7 (**HL7**) for this project?
The first song I loaded: [http://billion.dev.losttech.software:2095/song/2016745350](http://billion.dev.losttech.software:2095/song/2016745350) &amp;#x200B; **Untitled** I'm coming for ya I'm coming for ya I'm coming for ya I'm coming for ya I'm coming for ya I'm coming for ya I'm coming for ya &amp;#x200B; btw. Justin probably seen it already: [https://www.youtube.com/watch?v=5vYgfTETyc0](https://www.youtube.com/watch?v=5vYgfTETyc0)
That sounds like a death metal song tbh.
Worked! Thanks :)
The way we approached this was by using `Policy` in .NET Core Identity, and then building an `IQueryable` based on the access rights of the users. Once any access rights were administered to the `IQueryable`, we then fire the SQL and map the response. You may be able to achieve something cleaner/DRYer using Abstract classes and authorization. This felt hacky, but it worked out fairly well.
It's highly probable that something on the page executes allowing some sort of redirection to take place after you POST. My recommendation is to actually use something like Selenium or Chrome Headless for this. Example: https://testingbot.com/support/getting-started/csharp.html
Masterpiece. [http://billion.dev.losttech.software:2095/song/1641588537](http://billion.dev.losttech.software:2095/song/1641588537) &amp;#x200B; `I am not the same I am not the same I am not the same I am not the same I am not the same I am not the same`
When you bind a collection and you want updates of the collection to show up, then you need to implement and use `INotifyCollectionChanged`. WPF won't know that the collection changed, unless it's informed about it. Note that `ObservableCollection&lt;T&gt;` does this for you already.
I have it implemented in my InspectionViewModel like this: public event PropertyChangedEventHandler PropertyChanged; private void RaisePropertyChanged(string propertyName) { if (PropertyChanged != null) PropertyChanged(this, new PropertyChangedEventArgs(propertyName)); } I use it in setters of all FaultsCollectionViews and Inspection properties.
You implement `INotifyPropertyChanged`, which notifies when **properties** change. I said to implement `INotifyCollectionChanged`, which notifies when **collections** change (their content).
I call these Domain projects, as they usually contain objects that represent the domain you are working in. Multiple answers can be the right one though.
I meant the song. Lmao
You mean implementing it in my model Measurement and use in setter of Count property: private int? _count { get; set; } public int? Count { get { return _count; } set { if (_count == value) return; _count = value; RaisePropertyChanged("Count"); } } It still doesn't clear column.
Did you even read the documentation of `INotifyCollectionChanged`? Whatever type is behind your `IEnumerable&lt;T&gt;` must implement that interface.
Since I'm not getting trashed into oblivion I want to put 3 possibilities out there. Maybe they just want to test your knowledge of basic CS algorithms. It's *good* to have a firm basis in how things like sort algorithms work. It is sometimes helpful to know things like "MergeSort and QuickSort look the same on cheat sheets, but MS is usually faster than QS. However, it needs more memory than QS so you are making tradeoffs." It's common for just about everyone to test you know when to use a Dictionary over an array, or a List over an array, and so on. I don't consider asking questions or even asking you to implement very simple structures like linked lists a red flag, even though maybe you don't expect to ever do it yourself. The "leetcode" kind of company is looking for you to go beyond that. Most people never deal with datasets that have more than a few tens of millions of items. These companies deal deal with trillions and beyond. They can't use "just a linked list" or "just a Dictionary", their solutions tend to involve very esoteric, custom-designed data structures. Some need to hire people who write new database engines. Some need hardware-level optimizations. So in the end, what they need is much more on the "academic Computer Scientist" side than a general "software developer". This is only a red flag if you don't think chasing the speed leaderboards on HackerRank is fun. If this kind of work isn't your wheelhouse, it's not a good idea to try for a job that requires it. The *worst* kind of company is the one that could do just fine if they asked the questions from the first paragraph, but they think they need the kind of talent the second paragraph companies need. So their interview process is modeled after a company that wants people to create patentable new search algorithms, but they're a company that will never make back the R&amp;D investment that requires. This is a red flag. It tends to mean the company doesn't understand its position. It can mean either the technical management is misguided, or that a clueless extra layer of management has more influence over how software is written than the tecnical management. Think long and hard about a company with small data sets that asks you to solve "What if we had 500 petabytes of data?" kind of problems. You won't really know until you get into the interview, unless from what you know of the company you can discern how big their data sets are. If you think "bigger than hundreds of gigabytes", I'd probably expect the hard kind of interview where you might have to design new data structures on the spot based on knowledge of math papers from the 1700s. If you think "smaller than dozens of gigabytes", they should be asking you much more fundamental questions.
These are just lyrics though, right? No melodies or music?
[WE HAVE A WINNER.](https://media.giphy.com/media/l4q8cJzGdR9J8w3hS/giphy.gif)
Fergi? Is that you?
Stealing.
I'm not 100% sure I understand what "Response" means in this context, but I am going to make an assumption that what you are asking is... "Im looking for a way to enter a websites address and grab the html from the site". Short answer, there are plenty of ways. I made a view a few years back going over one of the ways (Using Selenium) https://www.youtube.com/watch?v=nLadf49S_i8 There is also using Web Client or HTMLAgilityPack.
I mean, it worked for Jack White: &amp;#x200B; I'm thinkin' about my doorbell When ya gonna ring it, when ya gonna ring it Yeah, I'm thinkin' about my doorbell When ya gonna ring it, when ya gonna ring it Yeah, I'm thinkin' about my doorbell When ya gonna ring it, when ya gonna ring it Yeah, I been thinkin' about my doorbell
Around the world, around the world Around the world, around the world Around the world, around the world Around the world, around the world Around the world, around the world Around the world, around the world Around the world, around the world Around the world, around the world Around the world, around the world Around the world, around the world Around the world, around the world Around the world, around the world Around the world, around the world Around the world, around the world Around the world, around the world Around the world, around the world Around the world, around the world Around the world, around the world Around the world, around the world Around the world, around the world Around the world, around the world Around the…
 [https://docs.microsoft.com/en-us/dotnet/framework/network-programming/how-to-request-data-using-the-webrequest-class](https://docs.microsoft.com/en-us/dotnet/framework/network-programming/how-to-request-data-using-the-webrequest-class)
Sorry, I'll try to elaborate- this is as simple an example as I could think of. If you imagine how this would be written using the Generic version of IEnumerable, you can probably see that it would be a fair bit more complicated. Using the non-generic version also comes with the benefit of working with old pre-generics .net code.
Well, either read the response or grab the html would work for my application, I can track down the IDs Im looking for if I can get them. Thank you!
I need to read more about this. Though I Know how to issue a request, in this case I don't know what the target page is to request with the info I should enter, since it's a component and the page address in the browser never changes. Thank you for the suggestion!
Try this out: [https://www.geeksforgeeks.org/](https://www.geeksforgeeks.org/)
Events are append only, so having one table for all events makes sense because they're all events. There are a bunch of optimisations that apply to RDMS schema that will also work here, but keeping it simple, an event is an event. "I opened a can" "I emptied the can" "I ate the contents of the can" &amp;#x200B; All events, all have a time they occurred and perhaps a bit of data. &amp;#x200B; The bit of data part is key here (no pun intended). Pre ES you'd update a patient record by saving a new copy of the patient record. All the unchanged bits and the changed bits. With ES you save the "Patient changed Surname" event with the new surname. &amp;#x200B; You then create projections based on these events, which just means taking the original patient record and applying all the events that occurred after and making it available in some aggregate or disaggregated form.
Are payments ever given a special status like "delayed"? Can they be cancelled? Can a cancelled payment be reinstated? If these are possible, then you may end up accumulating more DateTimes and flags on Payments. Then, if you are interested in the individual events, then each Payments row will correspond to several events. Or you could separate the possible events into their own tables and then there's a 1:1 correspondence between rows and events.
Ha! We do the same, and we put a blurb in the readme that anyone caught adding dependencies to this project will be tarred and feathered. Sidenote: are you using ServiceStack? This structure is very similar to theirs. ServiceStack is a DTO first API. We've been using it for a couple of years and absolutely love it.
 [https://channel9.msdn.com/Series/Developing-Universal-Windows-Apps-with-C-and-XAML](https://channel9.msdn.com/Series/Developing-Universal-Windows-Apps-with-C-and-XAML)
&gt;Good one. Thanks
Sort of tangential, but why is a *universally* unique ID only one third of your primary key?
Cool! This is the first I've heard of service stack ... This is just a mashup of CQRS and wanting to prevent devs from being sloppy and returning EF entities from contollers.
As someone new to ES this replaying to get the latest state thing always seemed like a major performance tradeoff. The more changes the longer and bigger and more complex the replaying would be to get to that final state to show on a UI or send in an email as a report, etc. I know caching would help but it sounds like you almost need a seperate view thats built over night or something and just updated with events after midnight? Seems complicated compared to a regular RDBMS.
This question can mean a lot of things and often spreads into the dubious. Sites that want you to be able to programmatically access their data tend to have an API. They might charge money for access to that API. Sometimes they have a website that lets you get the data for free, but is limited in some way. So people try to write programs to automate the website as a way to get access to the API for free. That's ethically wrong and, in some cases, illegal.So a lot of people really don't like answering these questions. Even if what your friend wants is honest, the same techniques that will help him enable other people to do dishonest things. If what you mean is "he just wants the body of the page he would get from accessing this URL", then all you need is `HttpClient`, or practically any REST API. Fetching a web page is just making a GET request. THe fanciest it gets is if you need to POST some form variables. There should be ample tutoirals available that can help your friend. If what you mean is, "No, he needs to load the page in the browser, let some JS execute, then put some data in form elements and submit them", you still mean "he just wants the body of a page. But the problem is now you're most definitely making some POST request. Your friend is going to have to figure out what is being sent where. Odds are he still needs the results of the JS data. This is where "just using `HttpClient` won't work. JavaScript is part of the page's body. There's not a way to execute arbitrary JavaScript in C#. It'd take an awful lot of work. If that's what your friend wants to do, they're in a shady place. The best I'm comfortable saying is if you do a search, there is a project to manipulate a "headless Chromium instance". That means it starts a specially-compiled version of Chromium that doesn't have any UI. Since it *is* Chromium, it can run JS when it loads a page. Normally it's a pain in the butt to automate another program, but the library I'm thinking of was designed to make this easy. But again, if your friend is trying to abuse a web page to access API data he'd normally have to pay for (or that the company providing it does not want to expose), you should not help them do bad things.
Hey man, I'm trying to move to Nez but when I try to restore it says "Project Nez is not compatible with netcoreapp2.0". Any idea how to get it work? Monogame alone works fine.
&gt; As someone new to ES this replaying to get the latest state thing always seemed like a major performance tradeoff. You can create snapshots for that. &gt; The more changes the longer and bigger and more complex the replaying would be to get to that final state to show on a UI or send in an email as a report, etc. Remember that it's always regarding an aggregate root, so the amount of events is limited. This is rarely an issue. &gt; Seems complicated compared to a regular RDBMS. Event sourcing is more complicated and has some drawbacks, but it also provides plenty of benefits that are very difficult to achieve with the traditional RDBMS approach.
 **wouldn't it be better to have a separate table per event type?** Nope. When you're doing event sourcing, you're storing a stream of events, which must be sequential. Separating the events into different tables would not serve any purpose, as you need to be able to query "Give me all events, for this given aggregateId (an "Account" aggregate, in your example, perhaps), in order by timestamp. The table is write-only (you only add new events, never delete or alter them). If you separated them by event type, you'd have to join and sort the tables, at a meaningful performance cost. I'm not sure what you would gain by having the events in different tables. **why have a table for the events at all**? I mean, because you're storing events... it's Event Sourcing. You're correct: a Payment table would, in fact, be storing essentially "PaymentMade" events for an "Account" aggregate. You can simply SUM the values and, assuming that your Account only had a "Balance" property, achieve basic EventSourcing. There's a reason Accounts/Debits/Payments are used as the example for EventSourcing - because they have been modeled using this system for a long time, and everyone understands the concept in this context: Accounts are the aggregates - Credits/Debits/etc. are the events. The Account is a sum (aggregate) of the event stream. It's already the case (and has already been the case) that any banking system (I pray for all account holder's sake) records all credits and debits, rather than just having a "balance" entry that is changed. **tend to invent a very convoluted DB Schema for Events**. I would strongly disagree. I think that most of these schemas, including the one you posted, are very concise, and contain only the data absolutely required to store and retrieve the event stream efficiently. It might be "convoluted" if your intent is to use SQL Server to query the stream and perform aggregate operations like getting the account balance, but that is not the intent - and in fact is the antithesis - of behavior that should exist in an EventSourced system. The code for the aggregate, in whatever language it's written, should contain all the logic for determining the state of the aggregate - a SQL Query should not be involved. If you are a fan of SQL Server, then looking at how this data is persisted is going to be somewhat antithetical - it's not normalized, it's not queryable by the payload, only by aggregates, and generally SQL's power is useless. But, that's by design. SQL Server is only serving as consistent storage for the event stream, with only a single check to make sure the stream version matches the version expected by the transaction adding new events to it. It's a job that can be done by almost any RDBMS or NoSQL system. It could easily be implemented in the file system, just adding files. **With tools like Entity Framework we can implement Audit** Sure. But Audit is 100% not the same thing. CreatedOn and UpdatedOn are not complete history of the aggregate, by far. They tell you the last time and entry was changed (not every time) and by whom (yet again, only for the most recent change). They don't tell you WHAT was changed, or what the state of the entry was before the change. So, an account is empty and the customer asks "WHAT HAPPENED!" Best case scenario: It says UserX changed it on Tuesday at 9:00. That's... I guess the start of an investigation? Go find UserX, and ask them what they did. Maybe restore a backup of the database from Monday and see what the balance was then? Audit fields are fine for some scenarios, but not the same as an event stream at all. **And I think this may be enough for Event Sourcing.** Not at all. It may be enough for some use cases - where you don't need event sourcing - but it's not on par. &amp;#x200B; I think you're struggling because you want to fit the event data into a fixed schema for the given event, which you can query in SQL. But, if you're trying to implement this pattern for a high-frequency system, you shouldn't be running any ad-hoc/informative queries on the data, which might affect the performance of the system. Event Sourcing is almost always coupled with the concept of CQRS - Command/Query Responsibility Separation. That your "Commands" (things which change state) should have their own backend, and that your "Queries" (like, displaying information on the account page) should be separated into different storage/services. Create/Update creates locks, and requires transactions. Read doesn't. So, in the case of the system you describe, there would be a database with the event table, and that does the state changes. But, there might be another database, kept updated by a service listening to the events, that stores the data in separate, normalized tables, that you can easily construct ad-hoc queries against. There could be many copies of this "read store", and the data might be stored there denormalized, and in the exact format it's meant to be used in - to avoid having to run queries at all. And, at the same time, it might be stored in a normalized manner in a warehouse database, so that analysts can run queries on it. But, the activity of all the users on those databases will not affect the performance of processing new transactions on the "write store" (and vice versa). This rolls into the idea of "eventual consistency", as well. &amp;#x200B; Basically, it seems like you're coming at this from the wrong direction - looking at how the events are stored - which is a tertiary consideration for Event Sourcing. Look into CQRS and Eventual Consistency, and understand the issues those are trying to solve, and then Event Sourcing's benefits of having a record of every state change for auditing, debugging, and resolution of issues.
Yeah, but I think music can be added too. I had an idea to collect MIDI karaoke files for training. (see [http://www.karawin.fr/defenst.php](http://www.karawin.fr/defenst.php)) And OpenAI recently proved it would actually work (at least for music): [https://openai.com/blog/musenet/](https://openai.com/blog/musenet/) Feel free to try mixing the two. A pool request would be welcome :)
&gt; Remember that it's always regarding an aggregate root, so the amount of events is limited. This is rarely an issue. Can you elaborate on this? Id imagine if a users record was updated every single day for a year you would potentially have thousands of changes to replay right?
Sure, but how often is a single user record updated? Why would it be updated every day?
 b /| / | / | / | a ---- What is the distance from cell a to cell b? Well, you first get the distance from a to b along the x axis. Then you do the same for the y axis. Then you use the pythagorean theorem to get the length of the hypotenuse. In your example, the x distance between any 2 cells is obtained by subtracting their column numbers, and the y distance by subtracting their row numbers. Once you have the x distance (# of columns apart) and y distance (# of rows apart), you can get the straight line distance by finding the hypotenuse.
A bank account for example. Finance software are one of the biggest reasons to use ES. MSDN uses an example of being able to introduce a promo or a different interest rate into someones accounts or mortgages and replace all the events but with that new number and see how it would have changed things. So I think its fair to say you could have an insane number of events coming through the system. This would make snapshots very time and resource consuming. And it could require all sorts of little workarounds and scheduled tasks to keep data in sync and UIs quick.
Coming back to this, I was able to write a Jquery function that calculated the total dynamically on keyup when a user input a value in any of my quantity inputs. This was done by using a hidden input variable with "value=aNumber", then multiplying that hidden input variable by the quantity entered into the quantity input. Not exactly the approach I thought to go at first, but thats the great thing about developing, so many possibilities : ) &amp;#x200B; **My Jquery:** &lt;script&gt; $(".pq").keyup(function () { total = $("#qty").val() * $("#price").val() + $("#qty8").val() * $("#price8").val() + $("#qty7").val() * $("#price7").val() + $("#qty6").val() * $("#price6").val() + $("#qty5").val() * $("#price5").val() + $("#qty4").val() * $("#price4").val() + $("#qty3").val() * $("#price3").val() + $("#qty2").val() * $("#price2").val() + $("#qty1").val() * $("#price1").val(); $("#total").val(total); }); &lt;/script&gt; **My HTML:** &lt;div class="col-md-8"&gt; &lt;label class="pd1" for="product-description"&gt; Variable Name &lt;/label&gt; &lt;/div&gt; &lt;div class="col-md-2"&gt; &lt;label class="pp1" for="product-price"&gt; $300 &lt;/label&gt; &lt;/div&gt; &lt;div class="col-md-2"&gt; &lt;label for="product-quantity"&gt; @Html.TextBoxFor(c =&gt; c.Variable, new { type = "text", @class = "pq", name = "qty", id = "qty" }) &lt;/label&gt; &lt;input name="price" id="price" type="hidden" value="300" /&gt; &lt;/div&gt; &lt;div class="clearfix"&gt;&lt;/div&gt; &lt;br /&gt;
Yeah, pretty much just parse the body, and get the result in a simpler way. It's not a paid service or anything, just a city page with public info. But he's an engineer and uses this quite a lot. I'll look into an API for it, and be sure to check all suggestions here. Thank you!
Even in banking you rarely have single accounts that have a million transactions. And you don't have to re-create a snapshot upon every event. You can get the current value by taking the last snapshot and apply every new event upon it. Snapshots and events both have a date, so it's trivial to do it.
So ask how would you solve this in a dbms? We've been doing this for decades. You build summary tables. You take a performance hit on write because there will be more reads. Right? Make it work, then make it fast, then make it small.
&gt; summary tables A view? &gt; You take a performance hit on write because there will be more reads. Right? Does this mean every write results in multiple reads? Im not following too well
&gt; You can get the current value by taking the last snapshot and apply every new event upon it. Well yeah I think thats what I was getting at [here](https://www.reddit.com/r/csharp/comments/bsi1v5/event_sourcing_rdbms/eonltvf/) when I said: "sounds like you almost need a separate view thats built over night or something and just updated with events after midnight?"
I don't see why that would be necessary. Just create it on-the-fly when needed. It's fast. Pre-building those is a waste of resources, because you won't always need every view for every single aggregate.
I have now implemented two CQRS/Event sourced systems. You use the term easier, Easier for whom? The developer? If the ease of developing the solution is your concern, then CQRS and Event sourcing is definitely not what you want. You're conflating your needs as a developer to the overall application/product's needs. I NEED my application to be replayable (IE at any point, i can take my event stream and send them to the app and it will end up in the correct state). I NEED my application to never lose data (When you update a record, what happens to the old data?). Those two statements, when you HAVE to have them, makes simple crud impossible (Or way more difficult than event sourcing is) So really, it depends on what you're trying to do, we use EventSourcing on systems where we have to be able to say, beyond a shadow of a doubt, what caused the system to be in the state it is currently in, and we can replay those causes (events) and see the same state result. This makes it super easy to debug. One of my favorite libraries is [Marten](http://jasperfx.github.io/marten/) and it does event sourcing VERY well.
I think I am confused by snapshot then, what exactly is a snapshot in the context of a big list of events? Are you saying to not use an snapshot and just replay the events to get the aggregate on-demand?
Wow, this is such a SUPERB explanation - way better than dozens of articles from the web! Thank you very much indeed! Someone recommended me this tool [https://eventstore.org](https://eventstore.org/) \- so it's written in C# and my main concern is performance. I don't believe in runtime code running as fast as native OS code written in C/C++. (I don't think any bank could allow using this tool.) &amp;#x200B; **I'm wondering if Redis can be used as event store?** The big plus of Redis is that it's backing up data on disk, you know... Also, are there any event store implementations written in C/C++? (I'm particularly interested in what software **banks prefer** for their systems).
&gt;What are your thoughts? My #1 thought is: Redux does event sourcing very well.
Wait, you have a pool? I request to visit your pool for swimming and relaxation.
if you use a DataTable as a source, use its column type
Are you wanting just the typeof(DataGridViewColumn) or an actual DataGridViewColumn instance in this property? If the former, I don't think you have a choice but to add code in the set accessor to check the value. If the latter, you could make the containing class a generic and add a where clause to the class definition, limiting the type to a DataGridViewCilumn or any of its deriviatives. In other words: public class DataGridViewHelper&lt;T&gt; where T: DataGridViewColumn { public T Column {get; set; } } If you need the actual Type of this property value, you could access it through Column.GetType().
I am not using a data table. My wrapper class is designed to help build DataGridViews that show data from lists of some arbitrary class. Each ColumnSpec object includes, among other things, the name of a public property in the class being displayed.
My C# is better, than my English :-P
Just messing with you. Great work on the project. No offense intended.
I'm considering going back to school for programming. Any advice would be much appreciated :) I'm thinking kn starting with c# or python.
You can use Redis for storage, as you can use just about every provider out there. Usually, when using a NoSQL backend for storage, there will only be a single table of "Aggregates" with the key being the "aggregateId". Remember, the Aggregate would be an "Account" in your example. So, the value stored for each aggregate id is often just a JSON array of all the events that have happened to that aggregate. So, in the account example, it would just be key: 123 =&gt; value: \[{eventId: 1, type: "credit", data: { amount: "$20" }}, {eventId: 2, type: "debit", data: { amount: "$10 }}\] The main consideration for storage is uptime and reliability. Even if you can work around it, you want storage that is atomic and scalable. SQL Server fits both those criteria, even if all its other features are overkill. I've used Redis a lot, for caching, but I can't tell you off the top of my head how it handles atomicity, or how reliable it is in, say, the case of a power outage - which is to say, does it actually store values on disk immediately, or does it store them eventually (even if it's just a few ms later). I've worked with some old banking systems, and they don't implement "EventStore" literally, but rather, they use the concept. They would have a "Transactions" table, which contains all the debits and credits. This is analogous to an event stream. The one I worked on used SQL for most of the logic, as you had mentioned. Their queries, when validating a requested debit, would always do a "SELECT SUM(amount) FROM Transactions" in order to get the current balance, rather than having an "Account" table, where they would have a "balance" field. They did, in fact, have an Account table, but it contained information like Account Number and stuff. The point is, the movement of money between accounts always only ever involves ADDING an entry to Transactions, never changing or deleting a Transaction, or updating a value in some other table. If there was an error, or something needed to be reversed, it was always done with a new transaction. So, if $20 was taken out by mistake, they didn't delete that, they'd add a new transaction to add $20 back in. That transaction would be like, type: Correction. That's the concept of "compensating events", which is another principle of Event Sourcing. I mean, fundamentally, the idea is that you treat the history of aggregates in your system the same way a bank would treat account transactions: always preserving everything that happened for auditing/forensic purposes. There are some other potential performance benefits. Personally, I've only legitimately used EventSourcing as a pattern on a project that involved industrial controls. We needed to be able to audit all the various commands/events passed around for forensic purposes, assuming something went wrong. I've only used one EventStore implementation, which was Jonathan Oliver's (he was probably the first person I saw publish one), which I think is here ([https://blog.jonathanoliver.com/cqrs-eventstore-v3-0/](https://blog.jonathanoliver.com/cqrs-eventstore-v3-0/)). That was in C#, and is basically just a repository for seriealizing/deserializing event streams. It has plugins for basically every db (with the required features) out there as a backend. I'm pretty sure Reddis is among them, along with
Selenium.
I need typeof(DataGridViewColumn). I hadn't considered generic classes. Thank you.
Edgy is everyone so hell bent on being on Discord. We tried IRC already, it sucked.
I always find myself going back to good old wpftutorial.net. Still as useful as it was 10 years ago: https://www.wpftutorial.net/DataBindingOverview.html
Thank you!
Like a view. But not a view. &amp;#x200B; There is always a performance hit when you do anything. I know this sounds condescending, but managing those hits is part of what we do. All code incurs a penalty, not all penalties are worth incurring :)
I write software for the real estate industry, and there is often the need that companies need share large amounts of data between different systems. This data needs to be matched regularly and the amount of data is huge. A naive approach in programming often leads to very long runtimes(could be weeks) for this process. So you need to be efficient and the O(1) access time of a dictionary comes in very handy for this. So i organize my data in dictionaries, hashsets and lists before i process it(but you need to be aware of ramlimitations) &amp;#x200B; There is a talk from Robert C.Martin on youtube where he talks about clean architecture and he states that organizing the data this way,will be standard once we overcome databases and replace it with persistent ram.
Isn't this the 100th discord we have related to C#
EF doesn't, but you can use something like: [https://docs.microsoft.com/en-us/dotnet/framework/data/adonet/sql/detecting-changes-with-sqldependency](https://docs.microsoft.com/en-us/dotnet/framework/data/adonet/sql/detecting-changes-with-sqldependency) And then query with EF when it is triggered
Maybe? There are some that do several posts to attract a lot of people
You said: &gt; My wrapper class is designed to help build DataGridViews And then, seperately: &gt; I need typeof(DataGridViewColumn) I'm not sure that you actually need a `Type` object here. I think a factory pattern could do what you need, and be a little cleaner. So, start off with: interface IDataGridViewColumnFactory { DataGridViewColumn GetColumn(); } Then, instead of your class taking a `Type`, it will take a `IDataGridViewColumnFactory`. And instead of creating a column of the relevant type itself (which is what I assume you're using the `Type` object for), you call the `GetColumn()` method of the factory you've been given. You would then declare as many factories as you need, which would look like this: class TextBoxColumnFactory : IDataGridViewColumnFactory { public DataGridViewColumn GetColumn() { return new DataGridViewTextBoxColumn(); } } And your client, instead of giving you a `Type`, will give you an instance of this factory class.
public Type ColumnType {get{ return typeof(T)}}
One advice as a bit of a burned out programmer is never forget to play around on your own time just for the joy of it. From my experience just playing around reinforced things that I've learned formally a lot and made me independent much quicker then some of my colleagues who only did "school learning". But good and structured school learning is also beneficial and important so its good to have a mix of both. Both python and c# are great.
That looks very good! Thanks!
Awesome,thank you I'lll give that a look
I was a developer on a system for the NHS that used Event Sourcing, specifically EventStore as the underlying technology. Others have given good explanations around the pros and cons of ES and I will affirm that it isn’t for the light hearted, most applications won’t need it. On EventStore in particular, we had no end of trouble with the stability of the system (nodes being ejected, performance problems etc!), now it may have been an issue with our hosting so I can’t completely blame EventStore. However it is good to get started with as ithe documentation is good and it’s relatively simple. We actually ripped out EventStore and replaced it with a SQL backend, storing the events as JSON in a table that could only be appended to and not edited. It worked well for us.
Cool just knowing a term to search for has found pretty much what i need [How to use SQLDependency to get the notification in Entity Framework](https://code.msdn.microsoft.com/How-to-use-SqlDependency-5c0da0b3)
Okay I'll do that. Any preference on what to do? Like make a simple snake game or something homework where I can learn step by step? Also thanks for the advice :)
Only the 4th I've joined😂
What you're doing here is making three completely unrelated \`DoSomething()\` implementations. I'm guessing that your code won't compile because \`class D\` doesn't actually implement \`IA.DoSomething()\`. Because it doesn't. \`IB.DoSomething()\` and \`IC.DoSomething()\` are completely unrelated to \`IA.DoSomething()\`. Did you forget to put \`IA.\` in front?
Just use an observable colle tion. No need to roll your own.
Says at the top course is being retired June, 2019. Not sure if that means removed or just another course being more up to date. No clue.
Loved the read. Would you consider turning it into a blog post?
Xml Mirror uses reflection to make is super simple to create C# / Xml Parsers and Writers. Xml Mirror is part of the Data Juggler Shared Repo, which is a large repository that contains all my open source projects. Data Juggler Shared Repo on Git Hub: [https://github.com/DataJuggler/Shared...](https://www.youtube.com/redirect?v=7oTPZCFGT1Y&amp;event=video_description&amp;redir_token=1f9v-HR-w2wHQEdig2pdbgqszMN8MTU1ODgzMDY3M0AxNTU4NzQ0Mjcz&amp;q=https%3A%2F%2Fgithub.com%2FDataJuggler%2FSharedRepo) Xml Mirror is available here: DataJuggler\\XmlMirror XmlMirror.RunTime is a light weight Dll (about 32 kb) that must be deployed with any project that uses XmlMirror. Sample Project Note Board DataJuggler\\XmlMirror\\Samples\\NoteBoard\\NoteBoard\\ NoteBoard.sln Note Board is a sample Windows Forms application that demonstrates how to use Xml as a backend, and leave your self notes about items on your to do list. If anyone ever wants a full walk thru let me know. Thanks
That would be disappointing if they got rid of it entirely. It's certainly older, but since it's pretty beginner level stuff, I think it's still relevant and valuable.
Awesome! Glad to find an informal place to chat or ask questions. I’m learning some on my own now and will be going back to school soon to get my degree.
For a web app for example you probably spend most of your time waiting on a database or external services. If you use async, the main thread is freed during those wait times to process other requests massively increasing scalability.
The point of asynchronous code (regardless of whether it's `await` or one of the older patterns) is to be able to reuse a thread while waiting for an operation to complete. The reasons for wanting to do that are typically either - the thread has an important function that mustn't be interrupted for too long, like the UI thread responsible for redrawing and keeping the GUI interactive - you have more concurrent operations than you reasonably can (or want to) start threads for since each thread is relatively expensive, for example a webserver that processes many requests at the same time In an application where that's not the case, writing asynchronous code indeed often doesn't have any advantages over synchronous and multi-threaded code, and it may even perform worse than synchronous code.
Scalability. &amp;#x200B; Lets say I want to serve 100,00 requests per second on a server. If each request waits 1 second for a database call (and a trivial amount of time to serialize the result that we will ignore for this purpose), then you would need 100,000 active threads at all times to meet your target. Each active thread has its own stack memory, and they are (relatively) expensive to allocate and switch between (which is why .NET uses a pool of them to begin with). At a certain point, your OS will spend almost all of its time managing threads, and almost all of its RAM will be tied up in threads as well. With async, while the OS is waiting for the IO operation to finish, there is no active thread...you might only need 50 active threads at any given moment to handle all of your 100,000 requests per second. Even more important than the throughput is the stability difference. Thread pools generally have a finite size. If your database suddenly starts taking 2 seconds to respond to calls, then your thread pool would need to double in size to support one thread for each request. Now imagine your web server loses connectivity to your database for four seconds...your web server will run out of memory and will max CPU as it tries to create 4 times as many threads...which are doing no useful work will they wait for the database to become accessible again. &amp;#x200B; In a console app there isn't much benefit for using async (unless you creating a complex queue processor console command, or something like that), but its a mainstay of desktop and web applications.
That's the final step I didn't think of! Yes, if OP combines the generic class idea I presented with yours, that does exactly what he/she asked for.
They likely already have large amounts of software written in Java and are too cheap to convert it. Also, how do you know their servers are Windows?
Beceuse Enterprise in Europe is only using Windows
That’s not true. What’s with the simplistic assertions?
Lots of operation are blocking, for instance, reading/writing to a file or waiting for a network connection/stream. With normal threads, during those wait times, the thread is suspended but still consumes some resources. And when the operation completes, a context switch must happen to wake up the thread and have it continue executing. Context switches are expensive operations (more than 1000 CPU cycles). With the task approach, when a task is awaiting (for those same I/O operations), the thread that was executing that task can continue doing useful work by picking up another task that for example just got the result of another I/O operation without switching context (there is still potentially some overhead with marshalling values in some cases). And when the first I/O operation that I mentioned completes, then an available thread can just pick it up and continue its execution. As someone else commented, the key is scalability. If you only have a few tasks, then it won't probably matter. It could even be worst in term of performance as Task abstraction does add a little cost. If you have 1000 of tasks, on the other hand, you don't need to start 1000 threads. The TaskScheduler will allocate the optimal number of threads (usually from the thread pool) to run those tasks while minimizing context switching.
There's a lot of good answers here, but I'm going to take a more abstract position. I'd argue that the point of async/await is to not have to worry about, or understand all the minute mechanics of, writing asynchronous code. As many stated, what you might need those asynchronous operations for might be something as straight forward as some disk I/O, a database call, a network call, or maybe even a long running computation of some sort. Without async/await, you're simply waiting for those to finish, rather than being able to switch contexts and do ~~something else~~. Maybe you don't need to, and that's fine. Not every application needs async calls, but chances are it can be useful to quite a large number of cases. Fundamentally, the threading model is simply too complex, full of far too many pitfalls, and far too inaccessible to be widely used and widely effective for the vast majority of .Net programmers. Async/await is a different approach to programming for concurrency that puts the onus on the framework itself, and with a little imposition on the programmer, allows the programming of concurrent operations that would be largely impossible for a lot of us. That is the advantage. Don't worry about threads, because as [Stephen Cleary](https://www.amazon.com/dp/1449367569) has said, once you write code with threads, it's already legacy code.
a huge collection of permissive, open source libraries, that do just about anything on every os
The sound on this video only comes through the left channel, and is infuriating to listen to with headphones on.
&gt; Separating the events into different tables would not serve any purpose, as you need to be able to query "Give me all events, for this given aggregateId (an "Account" aggregate, in your example, perhaps), in order by timestamp. The table is write-only (you only add new events, never delete or alter them). If you separated them by event type, you'd have to join and sort the tables, at a meaningful performance cost. I'm not sure what you would gain by having the events in different tables. I want to elaborate on this a bit. In an event sourced system I worked on two jobs ago, we usually had events observed by more than one entity. An event would update an Aggregate, then be observed by one or more Projections and what we called Workflows, which could respond to events by sending new commands. We didn't use SQL to store the events, but if we did, I can think of two strategies to maintain a many-to-one relationship between entities and events. The obvious one is to have a two-column table of EntityId, EventId, but this requires you to write the event and the set of entities that will observe it as a transaction. Alternatively, instead of querying by EntityId, you could store the AggregateId that emitted the event, and the WorkflowId that sent the command, since Workflows always observed events that were spawned from their own commands. Projections would query by EventType, since a Projection observes all events of a set of types. But I don't know how you would handle a Workflow that begins its lifecycle by observing an event without having another table, since a different Workflow would have sent the command that spawned the event. It's another many-to-one relationship.
I'd like to add that this isn't a golden bullet. In your scenario there will likely be a maximum number of database connections, meaning almost all of your requests will return with a connection timeout. Also there may be an underlying limit to other things like HTTP connections, so your queries could begin to impact other services as well, and incoming connections could be queued due to overall connection starvation. But it still gives your app the ability to fill the gaps of queries with other processing under normal load, which is infinitely useful, and the analogy is helpful. I like cooking analogies the best. If you could only boil rice, then grill chicken, life would stick. But you're able to do both at the same time, which is the effect that async has on your code.
Then don't listen with head phones. Problem solved. Sorry if I offended you, I am just trying to give free code away.
To add, the reason async saves CPU, is because network calls, etc use [IO Completion Ports](https://en.wikipedia.org/wiki/Input/output_completion_port) instead of a CPU thread. That's why async/await outside of GUI is useful: the CPU is free to do actual work instead of just waiting on network packets - the completion port will, essentially, callback the CPU once the network is ready.
I used to do this on IRC long before apps like Discord where a thing. I feel old.
I had the same thoughts years ago. Then I read this article. https://blog.stephencleary.com/2013/11/thereisnothread.HTML it had me rethink a lot of my assumptions. So I wrote a windows service and web api that both used async/await everywhere possible, and then wrote the same programs using multithreaded usual stuff. It was really surprising how much faster and easier to use the async was. Hope that helps.
To understand asynchronous you probably need to understand another model to compare it too. This usually comes up in system programming courses rather than UI stuff. Anyways, the answer is that asynchronous threading minimizes the creation of new threads by more fully saturating fewer threads. Thus it more fully saturates the hardware and causes less memory swapping.
You are one of the few people here that understood the question. Thank you very much for this excellent answer.
You're getting a lot of answers that I think are avoiding the core point of async/await. The purpose of async/await is to provide language sugar that allows you to express sequences of potentially-long-running operations as something OTHER than callbacks. Callbacks suck for a variety of reasons, but mainly because they're harder to read then what looks like linear code. var result1 = await DoLongRunningThing1(); ... validate result1 ... result2 = await DoLongRunningThing2(result1); .... validate result2 ... and so on .... Is simply easier to read and reason about than: StartLongRunningThing1((result1) =&gt; { ... validate result1 StartLongRunningThing2(result1, (result2) =&gt; { ... validate result2 }); // Notice how "arrow code-y" this is looking }); // And we still haven't "got" result2 somewhere usable... need another callback for that. Callbacks suck. The purpose of async/await is to allow the programmer to write code that looks linear and blocking and is easy to read and reason about, even if it ISN'T linear and blocking under the hood. Better still, for the most part, the programmer doesn't actually have to worry about what's happening under the hood, the implied promise is that a library author whose operation is running in an async function because it might take a lot of time, is going to sensibly yield somehow (either by calling ANOTHER asynchronous -- async/await-style -- operation, or by making use of threads and TaskCompletionSources -- let's say, there are probably other ways... oh yeah, and callbacks!). Some examples of long-running operations are provided in other answers... DB lookups, network API accesses, etc. It doesn't really matter what's happening under the hood, you as the writer/reader of the client-code to these async functions end up with something much more digestible.
Without a branching statement, checking a value is within range is kind of a useless operation. What are you trying to accomplish and why don't you want to use if/switch statements?
Maybe you could understand it if you're weren't a dumb fucking Nazi. For real, look at his post history, he spends a shocking amount of time defending Hitler and the Nazis. Gross.
The link goes to not found page.
servers mostly are on Linux. Docker, Kubernetes are using mostly in Linux environments too
We use c# but I feel like that's mostly because that's what the first in house software dev knew at the time. Works great for what we need at least, which is only a few stand alone helper apps and backend for html/Javascript pages (in house pages, not open web thank God)
We are not talking about WebDev
[There is no thread](https://blog.stephencleary.com/2013/11/there-is-no-thread.html)
https://blog.stephencleary.com/2013/11/there-is-no-thread.html
in this case I can suppose only: \- big legacy \- more developers, more options (languages, tools, libraries, etc) \- Java-based technologies look more "free" (SIC "look"), than NET/NET CORE, Huawei's case shows that USA becomes toxic for business, US technological lock increases risks and becomes political instrument
I can assure you that plenty of big German, Austrian, Portuguese, Spanish, Greek, Italian, French, Swiss, Croatian, Finn companies are using Windows servers and writing internal software in .NET. Many are well known brands even. After all they are our customers.
Without `if` or `switch`: bool isBetween = number &gt; 100 &amp;&amp; number &lt; 200;
Creating new threads is really expensive and slow and the more threads you have, the more overhead exists which bogs down the computer. The .NET threadpool will slowly create more threads if all the threads are used up. You want to avoid this. Async/await lets you efficiently tell the program that someone else can use the thread (instead of blocking it while waiting for a Task to finish) so no more threads need to be created.
At its core async/await is just a fancy abstraction for callbacks. As we all know, callbacks/events don't tie up threads until they are activated at completion. Also .NET just has way too many useful abstractions for anyone ever to be worrying about explicit thread management unless they are doing some edge case stuff (like COM with STA or something).
Not everything you do requires database connections, plus you have MARS. Http 2 also lets you share connections.
I was just referring to the example above, and adding that database connections can take up other resources required to make http connections and other network-based dependencies. No hate though the example above was a pretty good explanation.
In a game that I'm prototyping, I have this algorithm that generates ~100 islands for a sea. I use async to generate them concurrently instead of just doing it in order. When I made the switch from synchronous to async, the time that it took to complete went from 45+ seconds to under 2 seconds. There was no optimizing of the actual algorithm, I just made it start ~100 tasks all at once, and then I made a second loop to `await` them after they were all started.
You mean like, hit build and zip up the files?
Is there a specific reason you are using MonoDevelop?
There is no "main thread" though in ASP.NET Core. There is no SynchronizationContext. All continuations are randomly chosen on the thread pool.
Yeah, this guy gets it. Using async/await basically allows your app to expand horizontally across CPUs pretty easily.
I initially ready your comment with a "wtf". But then I see the post history, holy shit. Fuck this dude. Let him learn to program on his own.
Go fuck yourself. Learn to program yourself, you piece of shit.
"...no excuse me while I go continue being an asshole in every way imaginable." Go fuck yourself.
It is not very clear what you want to do when you get these notifications, but, depending on your use case, [Entity Signal](https://entitysignal.com/) may work for you.
Will that work for anyone? I feel like last time I tried that, I got an error on another computer where I had to have the .net code installed
Welp, just tried it on a different computer. No errors. I'll send it to a couple people and see if it works for them, thanks!
First, I've never been to mars. Second, sharding, everyone knows sharding is the secret ingredient in the web scale sauce.
Thank you :) any other good recommendations? 😁
I’ll have to check those out!!
You can hardcode the path of the ChromeDriver if I remember correctly, that way you can send the .zip with your tool (executable) including driver, which they have to nove to a certain path on their PC (Let's say C:/Selenium). Not the most ideal but I've had it work in the past.
In ASP.NET Core that's true, but quite a few people still use ASP.NET MVC on .NET Framework. Even so, that kind of misses the point, which is that threads are freed up while waiting for I/O.
Hmm, still not seeing why you mentioned reflection, though.
Couldn't the webserver just be more efficient with the request threads?
If you doesn't understand the answers it doesn't mean that all peoples doesn't understand your question.
Nice try liar, check my post history, I was telling one person that he actually believed the same things the Nazis believed and that they were horrible people because of it. You're pathetic for making that up, what a horrible and messed up person you are to tell a lie like that.
Oh cool, so it's like SignalR but for data, I'm sure I can find a use for this. Thanks
At the start a lot of people didn't read the question properly and just told me that async allows you to do something while you wait.... Since then there have been many good answers.
I run linux and visual studio doesn't work
* Already lots of software written in Java * Deployment targets are either Linux, Solaris or HP AIX * Open Source ecosystem is years old than .NET (maybe like 10 years older). * Eclipse etc are free / opensource
You're a liar. In a political post I called a guy a Nazi as an insult and he has been angry ever since. Are you that guy. Did you stalk me all this way with a different account?
You shouldn’t be able to do `if (txt)` because that doesn’t evaluate to a Boolean. You should be able to do this: `txt?.Text = "Foo";`
&gt; I did discover that I can do javascript-like null check: No, C# doesn’t support that.
&gt;then I made a second loop to await them after they were all started. Wouldn't you use `Task.WhenAll` in such a scenario as [this SO answer](https://stackoverflow.com/questions/18310996/why-should-i-prefer-single-await-task-whenall-over-multiple-awaits) recommends? (I could be wrong, am a bit new to C# and Asynchronous Programming)
This answer is the correct one. I can only add a few points. Almost all web server request handlers do something that involves getting data from another server, be it a sql or noSQL database, another http request or what, but here is where "the OS is waiting for the IO operation to finish" and it should be async, to free up a thread. You can't wait faster, but you can wait more efficiently. i.e. You can't speed up that database server by adding "async" to your code, you have to wait, but you can wait in an "async" way that frees up resources while you're not using them, for other threads. "Scalability" can also be performance. When a lot of requests come in at once, [they get queued up](https://blogs.msdn.microsoft.com/mert/2016/01/21/a-bit-of-clarity-for-iis-request-queueing/). If your server is processing requests 1 through to 100, and then it awaits a database instead of busy waits, this means that requests 101-200 can now start.
https://circleci.com/docs/2.0/building-docker-images/
.net core is open source, nothing prevents the companies from using .net core...
Both Java and .NET are cross platform technologies and it is perfectly fine to mix and match stuff.
What if txt was declared as dynamic?
&gt; Travis or Appveyor are the options we have so far. I would highly suggest using Azure Pipelines for CI/CD. A lot of .NET projects and .NET itself uses Azure Pipelines. Azure DevOps for open source projects gives you access to a really wide range of tools and for a project with 20+ people I think it is the most appropriate. [Azure Pipelines offers unlimited minutes for open source projects and 1800 minutes per user for private projects.](https://azure.microsoft.com/en-in/blog/announcing-azure-pipelines-with-unlimited-ci-cd-minutes-for-open-source/) I have CD using Azure App Service because I used it for a personal project, Azure Pipelines builds a docker image and pushes it to Docker Hub, which is set up with a webhook from Azure that will deploy the latest image to my Linux App Service (free tier) whenever the webhook is triggered.
Just use ObservableCollection&lt;Measurement&gt; for Inspection type, you should be good to go
I personally hate Jenkins, it looks awful and feels complicated. TeamCity is better imo. Other than that, Docerise everything. It will support local debugging and consistent deployments with no os components and tools being the wrong version or in the wrong place, or a path statement ... you get the idea.
Are you using Unity? If yes, you can use if(object) and you shouldn't use object?. or object ?? because they don't work like expected. However, it applies only to Unity classes, components, etc.. You can check in the Unity documentation if the class has a bool operator.
You can but you will get a [run-time exception](https://dotnetfiddle.net/p66i2Q) then. But it's possible to overload true and false operator to do null checks. Unity does this, because of underlying C++ objects.
You are absolutely correct. Create a list of tasks, add the tasks to the list, then wait for them all to complete.
I didn't know DevOps was free for open source. Would you recommend it?
&gt;You're conflating your needs as a developer to the overall application/product's needs. Common mistake, everyone does it. "We could it this way, but that's a fuckload of code. Let's just do this instead, it's easier to write, unit test, release, etc." Then the customer comes along "remember this wee thing we mentioned during requirements gathering, could we get that in?". I know there are bigger problems in this example, but when it comes to implementation the focus always has to come back to the application needs. I think it's a combination of a good BA who knows where to highlight critical functionality that could affect implementation/architecture (and knows when to ask the architect if it is).
https://sharplab.io/#v2:C4LgTgrgdgNAJiA1AHwAIAYAEqCMBuAWAChjUBmbHANmwCZKB2Ygb2M3ewtxtQBZMAsgEMAllAAUASjYdWRDgswA3IWEwAzCACNVmALyYoAUwDumAGLbVUwvMXsR6zOM06w0u/bn37uAJziAETAkEYA/ACEgZK2PpgAvjLsiUQppFz0lm4sSZyUNCIAtgAOADYiAMYiwJgA9sVGYELAtWpatbWl4lm66pL6AHyYIRBGtvFAA
&gt; You shouldn’t be able to do if (txt) because that doesn’t evaluate to a Boolean. https://sharplab.io/#v2:C4LgTgrgdgNAJiA1AHwAIAYAEqCMBuAWAChjUBmbHANmwCZKB2Ygb2M3ewtxtQBZMAsgEMAllAAUASjYdWRDgswA3IWEwAzCACNVmALyYoAUwDumAGLbVUwvMXsR6zOM06w0u/bn37uAJziAETAkEYA/ACEgZK2PpgAvjLsiUQppFz0lm4sSZyUNCIAtgAOADYiAMYiwJgA9sVGYELAtWpatbWl4lm66pL6AHyYIRBGtvFAA
Redux is just an in-memory state management library (for handling dispatch of events that change state). OP is asking about using a relational SQL database to persist messages that update state. Normally we use SQL databases to store data in a way that minimizes duplication whilst ensuring data integrity (updates and deletes only update and delete the data that needs to be updated and deleted and nothing else). Using SQL databases that were design for this requirement, to store a series of events (changes to data) has it's challenges (versus technologies that are designed to store a single stream of data like Redis) and that's what's being discussed here.
&gt;And when the operation completes, a context switch must happen to wake up the thread and have it continue executing. Context switches are expensive operations (more than 1000 CPU cycles). I'm new to this, so can you tell me what you mean by a context switch. The only thing I'm familiar is SynchronizationContext from the .NET library, but I thought that was just a tag so basically the code knows where it's at, so to speak. Why would this take 1000cpu cycles, or is a context switch something else?
That is literally what this person said as well and the point of async await.
Sure, if you want to create your own BCL that has this implicit cast for all types. :)
Some links to help you understand: * [Context switch](https://en.wikipedia.org/wiki/Context_switch) (Wikipedia) * [Context Switches](https://docs.microsoft.com/en-us/windows/desktop/procthread/context-switches) (Microsoft docs) * [A benchmark](https://devblogs.microsoft.com/premier-developer/the-cost-of-context-switches/) (not the best one, but does carry the meaning) * [A stackoverflow question](https://stackoverflow.com/a/39796872/2046539) with a detailed answer from Eric Lippert
Even if that were true (I did not bother to check), this has nothing to do with the current question.
Language
You can also catch OverflowException exception inside checked block
I've even been using async for a long time already, correctly I might add; watched tons of tutorials and explanations but these two comments finally cleared up the actual practical purposes, conceptually. You guys made it click for me, thank you so much.
They do write stuff in C#. You presume that if you didn't see it, it's not done, which is just ignorant.
I don't know, we are a MS developer company and we get lots of offers for projects that exclusively use .NET. I was contracted by a large German government agency that also mainly used .NET, although they also had a couple of Java webservices running. To me, it seems that .NET is alive and well and rising rapidly, at least here in Germany.
Are you using a controller? Im not really sure on what you are trying to do, but here is a work around i used in a project some time ago. private readonly nameContext db; //the context class public nameController(nameContext db) { this.db = db; } Now you can just use db.listfromcontext
I would suggest you to take a look at: https://docs.microsoft.com/en-us/ef/core/providers/in-memory/ The InMemory Provider is easy to use for testing purposes. You can also set a dependency in your test peojects only. Im also using Moq but the InMemory Provider for EF.
Thanks, I suppose what I want to do is call Setup(a =&gt; a.Blogs) inferring the Blogs object via the generic T parameter in my method, which I imagine I could do with expressions and reflection but I'm a bit unfamiliar with them
Try what i wrote (with the proper naming ofc) that worked for me. Think i had the same problem.
Async/await ***is*** just a way for a webserver to handle request threads more efficiently...by taking advantage of OS performance features (e.g. completion ports, or their equivalent).
I think he means people were telling him that the main purpose of async/await was to do work in parallel during a single request, as opposed to its scaling benefits based on how it handles threads.
This is a possible alternative https://entityframework-effort.net/ But it mainly depends on what you want to do. Mocking the db context is generally a bad thing to do as your implementation will differ from the actual implementation.
Was leaked in the first year...
I looked through his history, and I saw a lot of comments I don't agree with (some of them that are very intolerant), but from what I saw he wasn't trying to defend the Nazis, he is just a regular violator of [Godwin's Law](https://knowyourmeme.com/memes/godwins-law) and an armchair historian who is trying to relate Nazism to modern politics that he doesn't like.
txt?.text = "foo" ?? string.Empty;
I'm a junior dev at a small company, been programming about 2 years professionally. At work we use NHibernate (.NET version of the Hibernate ORM written in Java). I got bored one day and wondered how hard it would be to write something similar. Turns out it's very hard, but I have a thing: [https://github.com/callumg2895/DataTrack](https://github.com/callumg2895/DataTrack) There's some tests in the source code just so you can see how it's used. Pretty pleased with how it's turned out.
I am using Unity - ah, didn't know it was a Unity thing
OK, so you added an operator to a type that implicitly casts it. You can't do that for `string`. Part of playing "Well, actually..." is you have to be talking about the same thing.
Null is a non nullable value? That's the funniest thing I've read all month.
As soon as you start talking about reflection when talking about mocking and thus testing you are heading down a dark and dangerous path. &amp;#x200B; Anyway, looks like you're newing up the dbset twice, assigning the first, but configuring the one in the method.
I would recommend it. The suite of tools available under it allow you to do pretty much anything you can think of. If you have some time, watch this video from Ed Thomson https://mybuild.techcommunity.microsoft.com/sessions/77046?source=speakerdetail He goes over using the Azure pipeline feature to build/deploy an app to all sorts of places. Combine that with source code control, work tracking, and being free for open source and you have a pretty compelling argument.
Awesome thanks so much.
There aren't any stable releases for them yet. [Daily testing builds](https://github.com/dotnet/winforms/blob/master/Documentation/getting-started.md) are available.
That isn't what I asked and that isn't what this person was talking about. The point of this whole conversation is that before async many solution already existed to "do something while you wait". Obviously then async was not created because it "does something while you wait", but because it does it in a different way. My question, and this answer were about that difference.
Have you considered in memory database and seeding the required data
Well actually in his example txt is an object not a string. txt.Text is a string.
Thanks, that helps a bit but I am still unclear. I have .NET Core 3 preview installed and working. I can see in the sample packs that the csproj files all reference "microsoft.DesktopUI", but when I add that to my csproj, it is not found. Not clear how I get that.
First you start with cows, chickens and other farm animals. Then you advance to real-world examples, realize that fuck this shit, quit and become a gardener. &amp;#x200B; But in all seriousness, if you already have some programming experience, then just try to do the things you did with C++ in C#. Look at [this](https://docs.microsoft.com/en-us/previous-versions/visualstudio/visual-studio-2008/yyaad03b(v=vs.90)) page for a comparison of C++ and C#.
Error 404 when I click on the link :)
I'm curious to why you so readily recommend a docker deployment for a blazor build. Genuinely, no snark.
I don’t know how to solve your issue but you could try using Rider if you want something else than monodevelop. Works nicely on linux.
You *still* can't do that with `object`. Note the point is "Implicit operators are not a solution to the problem for types you can't modify."
Because you can use the built container on your local machine, on premises server, aws, heroku, etc. just using `docker pull`
“And are too cheap to convert it” Why does that make them cheap? That just sounds like a sensible business decision, to me - why the hell would you re-write software that is currently fulfilling your needs?
I went back and looked at your posts again and it's just really hard to understand your stupid points. Nazi or not, you're clearly fucking retarded. &gt;Gays in America are all rich, upper class, and successful. Once democrats get the absolute power they are looking for they will be throwing gays in concentration camps very quickly. That's some next level stupid. And for the record, I've been a professional software developer for nearly 20 years. I was just curious why the tone of your post was so hostile so I took a quick look at your post history. It's full of that shit. You're a shitty, hateful person.
It works for me. Strange.
https://docs.microsoft.com/en-us/previous-versions/visualstudio/visual-studio-2008/yyaad03b(v=vs.90) Because of Reddit formatting, a bracket was missing.
Your link doesn't have the ) in the actual link. It's just there as text. [reddit!](https://docs.microsoft.com/en-us/previous-versions/visualstudio/visual-studio-2008/yyaad03b(v=vs.90))
You should have figured this out, click his link and then add ) to the end of the URL in your browser.
You want to be using the SQLite provider in memory mode. That’s relational.
I don't think there is an easy way yet. What I'd do is create a throwaway project using `dotnet new winforms -o MyWinFormsApp` as stated in the docs there, and figure out which references to add to your existing project.
There's no way it worked for you if you clicked the link from reddit. You obviously didn't test the link.
Well first off C# is a managed language, so if you only have experience with C++ you'll notice that you have to do way less memory management. You don't explicitly allocate memory, you don't use pointers explicitly. You don't have move and copy constructors, but you have clear pass-by-value and pass-by-reference semantics. Which means that overall, you don't need to worry about where objects end up in memory or when they're freed as much. But you do have a garbage collector which periodically reaps memory, and while this is almost never an issue, it can be a problem in the performance-critical areas that C++ targets. C# provides an `unsafe` keyword that gives you full access to pointer types and memory management. However, unsafe blocks are considered an exception in C# and should be used in specific scenarios such as when you're calling external C code. Then there's the .NET Framework (and .NET Core) which, among other things, is what constitutes the standard library. C# targets the so-called .NET Common Language Runtime (CLR), which is the environment that actually runs your managed code. In fact, all .NET languages target the CLR - which means that they are compiled to the same bytecode behind the curtain, and that they all have access to the same library functions. Finally, there's [NuGet](https://www.nuget.org/) which is C#'s package manager. In the past, if you wanted to include a library you'd need to hunt down a DLL and add a reference to it in your project. Nowadays, you just type `Install-Package foo -Version X.Y.Z`. NuGet is integrated seamlessly within Visual Studio. This might sound overwhelming right now, but it's important to keep in mind: learning C# means learning the language itself, but also familiarizing with .NET as a whole, which, in turn, will make understanding and transitioning to other CLR languages easier. With that out of the way, I think that the best way to learn a language is to get down and dirty with it. If you're into making games, Unity has C# scripting. I've never done that, but it should be a great starting point to learn C#'s syntax and there are tons of tutorials and video tutorials aimed at Unity beginners. If you're feeling less adventurous, or if you simply don't care about a huge and overwhelming environment such as Unity, you could just try working on small projects on your own. That's how I started, at least. Syntax-wise, C# is pretty similar to C++ so it should feel fairly familiar. But C# tends to be a lot more concise overall, and has a lot of "syntactic sugar" (special keywords that replace common patterns) to help you write clean code. You'll be on MSDN and StackOverflow a lot. That's perfectly normal. I'd argue that the most important skill for a programmer is knowing how to ask questions and what questions to ask. And... That's pretty much all that I can list off the top of my head.
Yeah, but what was interesting to me, is that there isn't a thread in the background watching the callbacks and doing the bookwork. Instead it's passing the requests down to the OS and to the driver for whatever device is being used, then waits for the interrupt.
It works, it even shows the correct url when I hover above the link. Why would I say it works when I haven't tested it anyway lol.
Works for me, too, in the Narwhal app. I think some mobile apps handle bad links differently to the desktop website, so I wouldn't be too quick to say OP didn't test it.
The null conditional operator cannot appear on the left side of an assignment. What's supposed to happen if txt is null?
By using it! Pick some fun project and start trying. When you can't figure out what to do, hit google up. Rinse &amp; repeat. Books and courses can help, but the only way to truly learn (anything) is by doing it!
I really love that CircleCI allows you to choose the docker image with which to build your project. IMO, for this reason alone it is the best platform available.
You _can_ use the null coalescing operators, but generally not on things derived from unity object (includes monobehaviour), which are weird about how they become null. Serializable objects can also be problematic, as they have a habit of becoming non null without being explicitly created. But for things like invoking events and such, or accessing nested members, ?. Is pretty useful. I use them a lot here. But yes, you do need to be careful. Cheers
&gt; should Take it up with the language design committee.
Do you have some virgin blood and candles laying around? I know how to ..ahem "contact" a fella that can help you with this.
Honestly I find the is null check isn't enough, and generally use string.isnullorempty for most cases like this. It's not tighter, like you're asking for, but more useful
A couple of reasons a person might prefer Azure Devops: * You've got .NET Framework dependencies and don't want to build against mono (only AD and AppVeyor provide Windows builds, last I looked) * You're deploying to Azure * You prefer to configure things via a UI (instead of writing scripts) * You want your own NuGet repository for your artifacts * You don't care about lock-in (as much as your pipeline is subject to lock-in, which isn't much) If you just want something that will spin up an environment and run scripts there are better choices, namely Circle CI, Travis, or Appveyor. I personally prefer Circle CI because you can specify your own base Docker image for builds (meaning no scripting the installation of dependencies and increasing build times) and there's zero lock in; you script your builds and you can run them anywhere, including locally (HUGE benefits when debugging). At the end of the day, most of the available CI/CD platforms can be set up and running in a couple of hours tops. Try them all and see what meets your needs the best.
Consider preferring the clearest and most readable way to write something instead of the most condensed way. You might never share this particular bit of code with anyone else, but writing readable, clear code is a good habit to get into, especially since the performance gain is (usually) negligible.
This is great, thanks a lot! I think I want to start by doing my own small projects, what IDE should I use? Or in general where should I write and test my code?
Gonna echo this. I've dealt with both `Mock&lt;IDbContext&gt;` and InMemory provider and despite several hiccups with the in memory provider (usually around PKs and inconsistent use in tests), I'd highly recommend in memory.
Docker allows you to deploy pretty much anywhere and super easily. I can't think of a reason not to use it tbh.
&gt;synchronous Either approach will give about the same results - underneath the covers, a \`Task.WhenAll\` basically just adds a continuation to every task that adds the result into an array, and when they all give back a result it returns that array... essentially the same thing as doing an \`await\` on each in a loop. The major benefit of \`Task.WhenAll\` in my mind is better defined error behavior.
Teamcity is amazing. We use it with octopus at work and it's so effortless once it's setup.
We're using EventFlow with MsSql backend and it works well. It's a good solution if you are .net/MS shop. https://github.com/eventflow/EventFlow
I was asking specifically for blazor, not docker usage in general.
We had a great build guy who set it all up and I can't fault his choice :)
Why not just use json? It's much easier than all of this nonsense.
Txt. Text=txt. Text?? "foo"
I've recently found this lecture by Lucian Wischik, really helped me a while back. https://channel9.msdn.com/Events/TechEd/Europe/2013/DEV-B318
Warning about this. It doesn't support transactions. And for good tests, that can definitely be a requirement
Visual Studio is the standard IDE I’d say. It’s free. I’ve just upgraded to VS 2019 myself and it has some pretty cool improvements such as live code sharing that enables google docs like collaboration on your code. You could also use something more lightweight such as VS Code but if you are looking to do GUI apps in WPF I’d recommend VS 2019.
It's not clear what his type is, and I wanted to correct the statement that it's not possible. It may very well possible in some cases.
I recommend you start with what you want to do with it. Is is games, web back ends, mobile apps or what? Doing a simple game in Unity could be a fun way to learn and there are some excellent online courses.
Here's a video setting up tests with an in memory database provider https://youtu.be/AXu_5UBG2Qk
You'll need to start from the beginning. here are 15 episodes of C# [tutorials](https://www.youtube.com/watch?v=pSiIHe2uZ2w&amp;list=PLPV2KyIb3jR6ZkG8gZwJYSjnXxmfPAl51)
Thanks, then for mor advanced tutorial or course what suggest?
I'm still learning too... if I had one i would give it to you, but you can search C# tutorials for intermediate
You need to use VS 2019 preview to try NET Core 3 preview.
If you find you are doing this code a lot you could make a method or extension method. // Extension method in a static class public static void AssignIfNotNull(this Txt txt, string value) { if(null != txt) txt.Text = value; } Then you could use it like this. txt.AssignIfNotNull("abc");
Ok, thanks 👍
I would use Visual Studio Community Edition, but you can configure VS Code to run with .NET Core if you're more familiar with it. Visual Studio has a lot of debugging and profiling tools that will become very useful once you get the hang of things.
Sure. But having that thread pool thread consumed for the entire length of the request, vs only while not-waiting is still a huge huge deal
If you’re learning unity as well, the UFO tutorial is a great place as well.
I am visually impaired and cannot read JSON field value pairs compared to XML. If JSon works for you then enjoy it;, I do not consider something that might help someone else (for free) who wants to work with XML nonsense. I wrote this when I worked for a company that needed to parse lots of 3rd party data from an API written in XML.
I think you are a bit confused. Server Side Blazor (.NET Core 3.0) runs on an ASP.NET Core Server, it does not generate static assets like Client Side Blazor (NOT shipping in 3.0). My comment refers to Server Side Blazor, because I believe a lot of people will be shipping/building server side blazor right now since it will be RTM'd in September. I edited my comment around the same time as yours to mention about blob storage for static assets, maybe you read my old comment.
I was new to async as well, so i don't know that existed. Thanks for letting me know there's a better way
Moq in combintion with AutoFixture has an automoq customization. That might do the trick. As far as I know all interfaces are then replaced by Mock‘s. If you then register/inject the Mock you should get the right one from the property accessor. However I would really try to be as explicit as possible with my unit tests. Moq+AutoFixture+Automoq+GreedyConstructorCustomization is an amazing combination to replace DI but for me unit tests are documentation and if you remove explicit manipulations of your system under test it becomes less readable.
There is a proposal to allow the syntax you're asking for: [https://github.com/dotnet/csharplang/issues/1106](https://github.com/dotnet/csharplang/issues/1106) There's no guarantee it will happen, but you can upvote if you like. (A similar one for events: [https://github.com/dotnet/csharplang/issues/737](https://github.com/dotnet/csharplang/issues/737))
Azure DevOps also allows you to choose Ubuntu 1604 as a built host, you can run your entire build inside a custom docker container. I don't see how this is different from CircleCI?
Some things are designed to be used asynchronously. I've seen 10-fold throughput increase by switching from synchronous [ASP.NET](https://ASP.NET) handlers and Redis calls to async/await . The main reason for that was the Redis client that executed synchronous requests and batched async ones.
Just don't expect the InMemory provider to behave like a database.
The behavior you're describing as existing or not depends entirely on the implementation details of every individual async function. You cannot make the claims that you are here in a general sense.
&gt; I use async to generate them concurrently You might want to learn more about async and parallel programming in .Net because your understanding is incorrect. `async` is no guarantee that your tasks run concurrently.
I know. The way I set it up, it uses concurrency when possible, but still behaves fine if you happen to be on a single-core machine.
Just out of curiosity what makes json harder to read than xml when in the context of your visual impairment?
With `async`.. &gt; this algorithm that generates ~100 islands for a sea for CPU-bound work? If so, take that as reiteration of what I said above.
Start with Java then transition. The syntax is similar and the tutorials are way better.
Here's an option: \#1 Create a setter... public void SetText(string value) =&gt; this.text = value; \#2 Then use the setter using the null condition operator... txt?.SetText("foo");
Here's an option: \#1 Create a setter... `public void SetText(string value) =&gt; this.text = value;` \#2 Then use the setter using the null condition operator... `txt?.SetText("foo");`
Just be aware that your app won't be cross-platform compatible, it'll be Windows only.
I did an online series similar to this, then bought an O'Reilly book on C#. I find that videos simply cannot cover the type id in depth info in a book and will leave you with knowledge gaps.
Apologies. OP, I may have mislead you into thinking that there's never a background thread. I'm deeply sorry, I hope you can forgive me someday.
I recommend you read about [generations in garbage collection](https://docs.microsoft.com/en-us/dotnet/standard/garbage-collection/fundamentals#generations). Memory management practices in some other languages will have a negative effect on the .NET garbage collector. In general, stick to small memory foot print, short lived class instances as frequently as possible. Do your best to avoid things getting into gen 2 by understanding how things end up there in the first place. Once something gets to gen 2 it pretty much stays there until something triggers a collection at that level, but gen 0 and gen 1 get collected pretty frequently automatically. Allocations in gen 0 are considered really fast so it’s better to “new something up” frequently as needed than to hold onto something longer just to avoid allocations.
Well, you've already discovered the memory diagnostics. If you click on one of the snapshots, you can inspect the contents of the heap and see which objects exist of each type, where they are referenced, etc. However, since the heap and object count isn't significantly changing in your snapshots, the most likely explanation is that the source of the growing memory consumption is unmanaged memory. That would also explain why the GC isn't kicking in automatically, since it only sees managed memory. But if the GC does reduce the memory consumption when it is manually triggered, that most likely means the unmanaged memory is owned by managed objects and released by their finalizers. Are you perhaps allocating a lot of `Bitmap` objects in a loop or timer and not disposing them, or something along those lines?
It has to do with formatting; some JSon I have seen is all concatenated into one long string. I am sure there are formatting tools and all kinds of better ways of doing things that I am not aware of. When I have a client tell me both the request API and the response API has to be XML, which was the case at the time I wrote this, then that is why I used XML. I upgrade my application DB Compare which compares two instance of a SQL Server database to also have a remote compare feature where I export an entire database schema to XML for comparing the schema of a database on a remote virtual machine using XML Mirror and it didn't take very long to do with XML. &amp;#x200B; If it could have been done faster with JSon, then I guess I should invest in learning new skills. Programming is one of the only careers that after 20 years of experience, if you do not continually learn you get left behind. I am sure JSon is easier to work with, as I do know how to return field value pairs from a controller method (MVC) and I can just return a new JSonResult and no parsing is required. I am not familiar with object serialization / deserialization with JSon. I know the .Net serializer is very difficult to work with because the data can be corrupted. &amp;#x200B; Old dogs can still learn new tricks, they just take longer.
Your post history gives me CreepedOutExceptions.
Hey. I recently tried out the template on my Mac and it works fine for me. What platform are you building on?
txt is an object with a Text property here that he wants to assign if the object isn't null.
Don't worry about shortest it's not a great metric. Go for the clearest. That check literally reads if txt is not null set the Text property to foo. You get absolutely no gain by shortening stuff like that and may actually make your code harder to read.
Pluralsight has some really great courses, there is a C# path you can follow that will start you out with novice courses and increase in difficulty as you go. Yes, it is a subscription service, but it’s worth the money if your serious about learning.
Are there a lot of C# developers that use [test flight](https://developer.apple.com/testflight/)?
As an aside, [SmtpClient is essentially deprecated](https://github.com/dotnet/platform-compat/blob/master/docs/DE0005.md). &gt;The problem I'm having, is that Smtp is taking some time to send an email. Is it's speed dependent on cpu performance or internet speed? Should I multithread the process? Are there any faster libraries for doing this? You don't need to threading, because [SmtpClient _does_ support async](https://docs.microsoft.com/en-us/dotnet/api/system.net.mail.smtpclient.sendasync).
Linux, using source not the nuget package
Thank you! I'll check it out..
Seems to be a old/new -reddit issue. Works fine on new-reddit
I'll figures out how that works. Thanks!
The package they were talking about is this: https://www.nuget.org/packages/Microsoft.Windows.Compatibility But it only provides non-UI APIs. But... if you used Visual Studio 2019 to create a .NET Core 3 WinForms app, you shouldn't have it be missing. What does your project file look like? My test project looks like this: test.cproj: &lt;Project Sdk="Microsoft.NET.Sdk.WindowsDesktop"&gt; &lt;PropertyGroup&gt; &lt;OutputType&gt;WinExe&lt;/OutputType&gt; &lt;TargetFramework&gt;netcoreapp3.0&lt;/TargetFramework&gt; &lt;UseWindowsForms&gt;true&lt;/UseWindowsForms&gt; &lt;/PropertyGroup&gt; &lt;/Project&gt; Form1.cs: using System.Windows.Forms; namespace WindowsFormsApp1 { public partial class Form1 : Form { public Form1() { InitializeComponent(); new OpenFileDialog().ShowDialog(); } } }
The GC is also happy to do nothing until your application is under memory pressure. I suspect this is the case here because the OP stated that explicitly running the GC reduces the memory footprint. So, your app and the GC could be behaving normally.
At the moment I don't have so much money to spend for Pluralsight Course, for Udemy course maybe, thanks for the advice anyway
Did you try doing it via nuget? I don't have experience doing it from source on Linux myself, I'm afraid. https://stackoverflow.com/questions/38118548/how-to-install-nuget-from-command-line-on-linux#40209368
100% agree. There’s some serious bikeshedding going on here.
You're guess about Bitmap objects is spot on. Although I'm not allocating a lot, it is getting done very frequently. I get a screenshot, update a picture box in the application with that screenshot then look at the status of 20 or so pixels then made it = null. I changed the = null to .Dispose() which was not liked by the this.refresh() call. I then commented out the picture box update to focus on the Dispose() function. That seemed to do the trick keeping the application at &lt;28Mb. Now I need to figure out how to properly handle the picture box update. &amp;#x200B; Thanks for your insight on properly disposing them. I thought nullifying them was the same but apparently not.
Is System.Forms.OpenFileDialog the correct namespace? [Documentation](https://docs.microsoft.com/en-us/dotnet/api/system.windows.forms.openfiledialog?view=netcore-3.0) shows System.Windows.Forms.
Yeah, but there is "a thread pool" and "a theoretical maximum number of threads". So if your code was just synchronously connecting to a DB, getting some info, then displaying it, each request occupies 1 thread for that long. If you get 50 requests, you'll need 50 threads, even though a big chunk of each thread's time is spent blocked. But the way I/O is structured in the OS (this is my mental model, not 100% accurate), you can sort of say "hey do this for me" then yield the thread. When the I/O completes, the OS can grab the thread again to finish. That's more or less how async/await works. So in that model, if the DB fetch is async, you don't need 50 threads for 50 requests. When a thread is waiting on I/O, it can handle some other new request. That lets the threads have less blocked time and more productive time, which means better utilization of your system. The part I don't get is `async/await` didn't invent this. The original `IAsyncResult` pattern used this, as did the event-based patterns *so long as they were working with I/O*. People do like the straightforward nature of `async/await` code but danged if some of the pitfalls and considerations give me pause. But in a simple example where you're just awaiting some I/O so you can later return a response, most of those concerns don't matter. The trouble cases are when they await a method that awaits a method that awaits a method &lt;10 layers later&gt; that returns a value.
&gt; I changed the = null to .Dispose() which was not liked by the this.refresh() call. This is probably the reason, it's pretty common: `Dispose()` tells the `Bitmap` to destroy itself, but odds are the picture box is still displaying it. But now the `Bitmap` is invalid so when you call `Refresh()`, it tries to draw a disposed `Bitmap` and dies. The proper order for disposing of a `Bitmap` being displayed in a PictureBox is to do something like this: var oldImage = yourPictureBox.Image; yourPictureBox.Image = null; oldImage.Dispose(); That removes it from the PictureBox before it's disposed. (Also, `Refresh()` is usually a smell. I find in 95% of the cases it's being used because work is being done on the UI thread. Don't do things that take a long time on the UI thread!)
https://docs.microsoft.com/en-us/dotnet/standard/garbage-collection/unmanaged You could do something like var prevImage = pictureBox.Image; pictureBox.Image = nextImage; prevImage?.Dispose();
So first of all... &gt; Don't do things that take a long time on the UI thread! I'm so guilty. I know that threads are a thing and probably should invest some time into learning and implementing worker threads. this.Refresh() is something that was always taught within the first few lessons of any teach yourself book I picked up. &amp;#x200B; I tried your concept of getting rid of the old picture box image but an exception is thrown at the Dispose() call because it's already = null. I think at that point oldImage and yourPictureBox.Image are referencing the same address so nulling one would be like nulling the other. However I took your idea and ran with it. I added an if statement that said if the image != null then to just dispose it. Next I cloned the screenshot image and made it equal to the picturebox image then disposed of the screenshot properly like u/tweq pounded into me. &amp;#x200B; Now it's running constantly at 28Mb usage. Thanks for your help also. I'm gonna spend the next month working on background workers so I don't get roasted for calling Refresh()...after I read about some memory management.
Bob Tabor is the guy for c# beginner tutorials https://mva.microsoft.com/en-US/training-courses/c-fundamentals-for-absolute-beginners-16169?l=Lvld4EQIC_2706218949 . If you want to learn about entity Framework look for Julie Lerman. Both are great explainers
Could be worse, it could be the nazi sympathizer who posted yesterday.
&gt; I added an if statement that said if the image != null then to just dispose it. Right. This is the dumb tricky part. Even I forgot it. The first time, there's not an image yet. So you can't go trying to dispose it. So if that code can run when there's not an image in the PictureBox, you have to make sure you're not trying to call Dispose() against null beforehand. Don't talk yourself into believing "because I set one variable to null, the other was null too". That's not how it works.