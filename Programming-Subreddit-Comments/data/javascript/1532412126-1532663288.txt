Interesting. I've done some research since your comment, and I do understand some more about what you mentioned. What I don't understand is, for instance, in your Event example... Event has a Location. In JSON Schema you could define an Event roughly: { "type": "object", "properties": { "location": { "type": "https://myschemas.com/Location.json" } } } In the above example, if you had the schema for an Event, you could very easily identify what the location was, and by URL match that location to any other usage of a location in your system. If the JSON documents hosted by your server also somehow included that schema, Google could have used that to pull out the event location, no? So why would JSON-LD be needed if everyone used that approach (which would come with free schema validation)? In my usage, I am looking to use JSON Schema to host a url at (example) `https://myschemas.com/UserId.json` which contains the following: { "type": "string" } ... and allows me to treat all documents which have a property of the above URL type the same.
npm packages do not have to be JavaScript. The parent comment was suggesting that the OP could look beyond JS for a solution.
It might be having a look around some game engine's source code in order to see how it all hangs together. Here's [the source code for Phaser](https://github.com/photonstorm/phaser), get reading!
Previous edition: https://www.reddit.com/r/javascript/comments/7iy98o/a_20kb_js_tactical_turnbase_gamedev_competition/
In the article [Why Some Apps Use Fake Progress Bars](https://www.theatlantic.com/technology/archive/2017/02/why-some-apps-use-fake-progress-bars/517233/) there is an example where TurboTax intentionally delays the response since the user expects doing some tax optimization should take time and are less confident in the app if it returns to fast ;).
Not reinventing wheels. Looks like Nodejsland expects me to do everything the IKEA way, though. sigh 
I don't like how my local node_modules is degenerating into a poor replica of npmjs.com. Godwin's Law for Node.js: As your project evolves, the ratio of packages installed to # of packages registered on npm approaches 1.
Looks promising, but does it listen to changes on non-js files, too? The documentation seems to say no. I'm trying to run a small build script for some HTML/CSS w/o using full-blown task runners.
This looks promising! I will try it for sure.
Why would you not want to work with the data if it fails? What would be the purpose, besides heartbeats, in calling a promised function just to expect it to fail? Why not promise the data, and then data.catch() afterwards? I don't want to assume somethings going to fail (except in unit tests, such as expected 404 errors for example) and be left without being unable to work with data if it's successful. Fair point on the short scripts. That makes sense. I think I may have misread it initially and saw it as an overall statement applicable to all code. Handling errors using try catch can be done. If you want to nest try catch inside try, then you can. It's not something I'd recommend if there's a more elegant solution, but If you want to handle all errors differently, use a switch statement in your catch as this gives you the granularity of individual errors but the `default` to handle something that's unexpected.
Looks okay, though I was hoping for a pure js solution--something that runs on *nix and Windows w/o requiring a C build system (or any potential headaches) on the target machine.
I want to support target machines w/o having other language compilers / interpreters as extra install dependencies. Plus, Node.js has been out for, what, 7 years? Surely there is a usable pure-JS watcher implementation out there.
Packages are added to npm as your project evolves so that's not really true
Neither is the original Godwin's Law. I was hyperbolizing, but node_modules bloat is still a non-trivial concern.
Never knew about this tool so thanks!
I don't know. This seems a step back from the flux architecture rather than forward. Its more akin to pub/sub methodology. Granted, it looks like it can be factored into a Stores / Actions / \[Thunks/Sagas\] kind of layout, but I don't see what this framework offers over other already existing solutions. 
&gt; depends on \~130 packages. **NO.** So what? That's the Node.js/npm way
seems like there isn't an existing wheel for what you want. also isnt 'the ikea way' the opposite of reinventing the wheel? 
Hi, I don't have any project to showcase, but just want to say that I like madewithvuejs, did not know about react/laravel ones. Do you plan to make a madewithangular one ? Thanks for your work anyway :)
Don't you think Shallow rendering makes sense for Unit testing? (I'm still starting out and need to know) For integration tests there's absolutely no point in using Shallow rendering.
Nevermind im an idiot. I solved it by doing this... this.people = this.http.get&lt;any&gt; ('http://127.0.0.1:8000/url/link/'); const group = this.people group.forEach(element =&gt; { element.forEach(item =&gt; { console.log(item.city) }) }); 
You forgot to add async keyword in front of registerCoffeeUser function.
Hey, I've heard and checked these sites before. Nice work. Btw, I just checked some sites in [https://madewithreactjs.com](https://madewithreactjs.com) . Some of them doesn't show up as React build (doesn't lite up React dev tools. Are you sure all the projects are made with react or Vue as they claim ?
Thank you for the kind words! - no not planning it at the moment the other 3 are enough work for now üòÖ
Thanks! It solved the problem. I didn't know that you have to use async even if you just calling a await function. Well, I'm still learning haha. Thanks, again!
Some projects have their react app behind a login or just in an extension or anything - that could be the reason for that. other than that I try to be very accurate üòÖ ... also I guess some entries on madewithvuejs, for example, may already have relaunched over the last 1.5 years (in maybe another framework/language) - as everything is getting bigger its time for a "report"-Button I suppose üòï
Changed `const` to `var` and now is working.
The main problem always seems to be that all the good stuff drowns in a sea of mediocrity at best. It's usually better to have a shorter, curated list with higher quality.
Hey! Awesome sites, what tech stack did you use to build them? And are the sites making any money for you or are you simply running them as as hobby? 
That's true. Sometimes it is hard for me to draw the line on which outlines to exclude/include. On one side I want to grow my content but not only with Personal Portfolios or todo apps üòÖ - on the other hand - a new Developer should be able to show off a little thing he's proud of 
Thank you! :) I (tried) to build them with their respective tech-stack, but didn't completely (yet) üëâ https://MadeWithVueJs.com Laravel + Vue.js üëâ https://MadeWithReactJs.com Laravel + Plain-Js + Jquery (didn't want to get all the hate, so I scraped out Vue.js üòÖ) üëâ https://MadeWithLaravel.com Laravel + Vue.js All MadeWithX Pages (and https://hundezeugs.at - a Austrian dog blog my GF is maintaining üòÉ) are currently powered by a single Multimandant - Laravel App/Backend. .. I'm trying to monetise a bit (CarbonAds + some Affiliate links) - but its mostly hobby for now üòÑ 
Ah awesome man, keep at it! Fuck the haters, use whatever stack you're are most familiar with to get the job done ü§ô Can you share traffic figures? You've built a nice network/brand of sites man, if it takes off could sell for a good amount. How did you grow the sites to where they are?
Hmm I my have phrased that incorrectly. I was referring to IKEA as "self-assembly required" as opposed to off-the-shelf packages.
Footer should be ‚Äúbuilt with‚Äù
well done! thanks for following up - if someone sees this in two years, it'll be super helpful to see your resolution.
I just sent 2 projects last night ;D Cheers for the great websites!
If it fails, there is no data, because it failed. It's not making a request knowing it's going to fail, it's that it will fail eventually and you have to handle it. I think you misread.
It looks like you may want to use geojson
haha thank you! - queue is full at the moment üòÖ
haha - I'm trying to! Sure! June 2018: * MadeWithVuejs: Page Impressions: 142k Sessions: 52k * MadeWithLaravel: Page Impressions: 11k Sessions: 3,5k * MadeWithReactjs: Page Impressions: 10k Sessions: 4,2k Vue.js is by far the best performing one, but also about one year older :) - I hope to grow all of them substantially bigger - There should be potential to get bigger üòÄ It grew quite naturally to that point, and it was just about creating content *every week* for ~1.5 years now üòÖ
I fixed the fonts thing thank you
Wow Vue site is killing it! How did you go about adding content? Isn‚Äôt it dependent on people who know about your site? Like they have to know about your sites to share theirs and thus your site grows? Or did you manually find links around the internet and post them on the site? 
Yeah, I knew of some Vue.js pages, and others I found via Github - in the first month's everything was manual :) 
Awesome man congrats on your success! Would you be able to share revenue figures, approximately from all the sites? Just want to get an idea how much can be made with running these types of websites 
-&gt; https://www.indiehackers.com/forum/ask-ih-is-anyone-earning-money-on-their-side-projects-92a01fcfc5?commentId=-LGu20BFrQkE5OKhGcLH Have yet to figure out whats possible, or what to pursue next :)
Will have a read, thanks Armin ü§ô
You always have to put async in the function when you want to use await :)
Are these projects on the website open source ?
No not all of them - everything "made with" the respective tech counts :)
Lol we do the exact same thing at work for the same reason
On my iPad mini the text overlaps with the image. It is hard to read. It looks fine in portrait mode, it it breaks down after that
There is this thing called an "executable" that you can "install". I hear even Node is distributed that way!
What is const { data } ? Can you declare an object constant? I've never seen that syntax before
Hi! I didn't find where to submit on your site but here is a project of mine! (Only french) It was my last school project this year with 4 fellow camarades in the Symfony back end. http://mate.xlwlx.fr/ Made with Vue and Typescript, and no UI library nor Css Library! Github: https://github.com/victorgarciaesgi/Moving-Mate
Nice Project :) - could you add it here: https://madewithvuejs.com/submit ? Thank you!
would you mind to take a screenshot? 
Better yet find one you like without a CLI and patch one in yourself.
Why not try to rebrand into ‚Äúmadewith.com‚Äù and then have the platforms as filters? At that point you should halve your weekly workload since you are only maintaining one site and can mail everyone about new content in each section. Pretty cool resource though. Thanks for sharing. 
It it tough getting something to break down nicely for every screen size. I feel like there is always something that needs adjustment. 
That's destructuring assignment. https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Destructuring_assignment `const { data } = myObject` is similar to doing `const data = myObject.data`
Nice work! I've uploaded mine :) Thank you. 
Oh, hi! I already have my project [here](https://madewithreactjs.com/react-bolivianite-grid) but can you add tag #tables? Because this is what it is. Also, we still need search. And I'm thinking about one problem: all projects are adding manually and it is slow. What do you think to add ability to add projects automatically and have some sort of rating? Right now your project live only when you maintain it. If you will not approve/reject submission - project will be dead. You need to find a way when your websites can live without you.
I'm about to start a project that does an immediate API call based on a URL parameter and I've been debating how to handle the "loading screen." Thanks for sharing, this will be handy. I almost always do implement a loading spinner when something takes a noticeable time to load. As a user I personally like to see loading indicators, even if it's just very briefly; makes me feel like the dev or designer was thinking about the experience for those with slower connections.
i guess what i dont understand is, what's wrong with SparserLogic's approach?
you deff right. I fixed it though , it should work now (: 
Seeing all the downvotes, it seems that people learned nothing from the [left-pad fiasco](https://www.theregister.co.uk/2016/03/23/npm_left_pad_chaos/), [eslint-scope malicious publish](https://github.com/eslint/eslint-scope/issues/39), and the legendary [I‚Äôm harvesting credit card numbers and passwords from your site](https://hackernoon.com/im-harvesting-credit-card-numbers-and-passwords-from-your-site-here-s-how-9a8cb347c5b5).
I‚Äôm on mobile so can‚Äôt format properly but try moving the function to the variable. I.e. var obj = function(URL) etc etc
You can't access it out of scope like that. The code in that outside scope has already run as fetch is non-blocking. It goes something like this: // global scope code starts running // function fetchStuff is defined function fetchStuff(URLToFetch) { fetch(URLToFetch) .then (function(response){ return response.json(); }) .then(function(myJSON){ return myJSON; }) } // RHS: call fetchStuff, inside calls fetch // fetch spins up a background task to fetch the URL, lets remaining code run // fetchStuff returns nothing, implied undefined returned // LHS: variable obj created, assigned returned undefined var obj = fetchStuff(URL); // remaining global scope code runs to completion // LATER: fetch completes, calls then functions, resolving promise // returned by fetch (but never captured) In non-blocking, asynchronous code like this you have to handle additional code execution in functions. The global execution context has already run to completion and there's no way to capture asynchronous data there. You can still use variables created in that context, but as that code is running, it can't access data that doesn't exist yet, such as data loaded by fetch. Generally, with a function like `fetchStuff`, you would return the promise returned by `fetch` and call a `then` off of that in your outer context. function fetchStuff(URLToFetch) { return fetch(URLToFetch) // return here returns an unresolved promise .then (function(response){ return response.json(); }) .then(function(myJSON){ return myJSON; }) } var obj = fetchStuff(URL); // obj is now a promise, still no data obj.then(function(myJSON){ // function to handle asynchronous load of data // do stuff with myJSON // note that everything else in the outside context has already run })
The error message pretty much explains what's going on. Here's some more information about it here: https://webmasters.stackexchange.com/questions/50006/chrome-refused-to-execute-this-javascript-file/50017#50017
I believe this is due to a limitation put in place by GitHub to prevent exactly what you are trying to do - using GitHub as a CDN. As the error states, they set the MIME type as 'text/plain', which is not executable. If you try loading in scripts from a source where the MIME type is 'text/javascript', it will probably work fine.
Great site! Uploaded!
What about Angular?
Thank you! I finally understand why this happens. I will try to host it somehow else.
[removed]
Hi /u/AnecD, this post was removed. Please see our [posting guidelines](http://www.reddit.com/r/javascript/wiki/index).
There are a bunch out there, the biggest ones being GTmetrix, pingdom and webpagetest 
That worked! I can now see the JSON results! I have a follow on question. All of this is for a website on Wix.com. I have a hook that is called on a dataset after it has been queried. The object I am updating is one of the dataset items. How can I make the code wait so the item is updated before the global execution has finished? I hope that made sense?
thanks ! üôå
thank you :)
As good as it is, CKEditor 5 costs about $1 per user per month. If you have 1000 users you'd be paying about $12000 USD per year which is quite frankly ridiculous. https://ckeditor.com/ckeditor-5/pricing/
Thanks for the Feedback - I'm already thinking about merging :) but at the beginning it was just "oh madewithvuejs.com" is free üòÖ
Thanks for your Feedback! - Oh yeah forgot #tables - added it. And I added a feature to your project.. because your ARE CORRECT! üòÖ there are so many I areas I need to improve, but i don't want to step into "just scrape GitHub and look not so nice." And yes... Search - would only work when I would start scraping and filling up the site automatically - if not then you won't be able to find anything üòï
You can't make global execution wait. It's over pretty much immediately and there's not much you can do about it. If you need to wait for data, everything that depends on that data has to happen in the callback you get when that data is available. For example // local data (works) var userAnswer = "button-A"; var usersButton = document.getElementById(userAnswer); usersButton.style.backgroundColor = "green"; vs // remote data (won't work) var userAnswer; // to be loaded fetch(dataQuery) .then(function(data) { userAnser = data; }); var usersButton = document.getElementById(userAnswer); // undefined! usersButton.style.backgroundColor = "green"; // error! vs // remote data (works) var userAnswer; // to be loaded fetch(dataQuery) .then(function(data) { var userAnswer = data; // everything dependent on data must be in this callback // or another function called by this callback etc. var usersButton = document.getElementById(userAnswer); usersButton.style.backgroundColor = "green"; }); 
All 3 Sites are already so much work üòÖ - let's see
Hi /u/treyhuffine, this post was removed. Please see our [posting guidelines](http://www.reddit.com/r/javascript/wiki/index).
Hi /u/farcough187, For javascript help, please visit /r/LearnJavascript. Thank you!
Hi /u/daverave1212, For javascript help, please visit /r/LearnJavascript. Thank you!
Hi /u/You_Shall__Not_Pass, For javascript help, please visit /r/LearnJavascript. Thank you!
Hi /u/giocruz, For javascript help, please visit /r/LearnJavascript. Thank you!
Hi /u/Don-g9, For javascript help, please visit /r/LearnJavascript. Thank you!
Hi /u/wowthatsabigpotato, For javascript help, please visit /r/LearnJavascript. Thank you!
I‚Äôm confused about their licensing. They are GPLv2 so you could technically fork and bundle their code. Are you paying for the support, maintenance and copyright?
I'll check it out. Thank you /u/kenman
After the whole eslint-scope fiasco, I don‚Äôt understand why people aren‚Äôt for leaner node packages. It just makes sense. 
Check out redux-resource, we use it a ton at Netflix and it's general enough to work anywhere. https://github.com/jamesplease/redux-resource
I like react.rocks
I‚Äôd say it depends, honestly. If the landing page has some complicated logic that maybe drives graphs or user data, etc. then yes. I guess it boils down to how one defines application 
Those colours tho...
We have maybe 10-15 vue applications at our company and many more "widgets" that fit nicely into legacy applications. Most of these are for our student platforms, dashboards and things like that. Vue has been a very powerful enabler for us to get things done.
We were evaluating this for our writing platform but it lacked support for tables, which was something our content required. Ended up going with tinymce.
Do you know where I could get more information on this ? Because I don't really get it. Also, does this use JQuery, because if that's so, I can't use it.
&gt; GPLv2 so you could fork and bundle their code *If* your project is also covered by the GPL. Note that it doesn't state LGPL so I assume it is full GPL. This might be a problem for some projects, even other open source (but not GPL compatible) ones.
So... what is an application? ¬Ø\\\_(„ÉÑ)\_/¬Ø Let^me^show^myself^out
Yeah they're pricing model is insane. It would have cost us more to run ckeditor than our monthly aws budget.
I was working on this side project a couple months back [Mobile Reddit Client](https://github.com/TowhidKashem/reddit-client-app) but got bored after a while (lol) and now want to start a new project. So it's not fully polished by any means but since I'm not planning to finish it might as well put it up. It's definitely at a usable point. Any code feedback and suggestions greatly appreciated!! üôè
I was hoping that, if I was going to use npm scripts + watcher to run a build script whenever a file changes, then I wouldn't need to write another script just to glue things together. I'm starting to think he might be right; since a watcher script should be simple, maybe I should write one instead of looking for a CLI that satisfies my needs.
Thanks for the heads up. I‚Äôll see what I can do with this / compare it to our implantations
Have you thought about making them all the same website? They all look really similar, the only difference is branding and of course content.
Thank you! This explains a lot.
Oh forgot to mention, the `recursive` option doesn't work on linux, only macos and windows. So you'd have to basically implement your own for linux. So a more idempotent solution would be a directory walk + hash or `fs.stat()` mtime every couple seconds.
Wow there's an emoji in every one of your replies, lol! Anyway, awesome websites. They really look great, even on mobile 
üò±üôå
Yes, we've always encouraged people to [write their own abstractions for common behavior with Redux](https://redux.js.org/recipes/reducing-boilerplate). That's why there's plenty of [existing utilities for fetching and managing collections of data in a Redux app](https://github.com/markerikson/redux-ecosystem-links/blob/master/entity-collection-management.md).
Really good counter point; and the only one which is justified IMO. One of the principles of secure dev is minimising your attack surface and a large dep tree does the exact opposite. Mitigations but no real solutions: * mandating the recommendations of [eslint postmortem](https://eslint.org/blog/2018/07/postmortem-for-malicious-package-publishes) * ensuring best practices are followed. * never directly publish? Ensure releases are done via CI -- not sure if this is reasonable.
As a discussion: the list provided is crazy. This is exactly my point that instead of people writing one extensible library, everyone is writing their own with little quirks. I believe it would be better for everyone to work on one singular library and create a standard process for interacting with APIs / more eyes on code / better battle testing.
`+` is both the numeric add and the string concat operator. When you have both, strings win.
Dev tools integration can be disabled for production iirc.
Why? With any of the frameworks you can build any of 99,99% websites in the Internet :)
Spicy.
Idk how to install without copy pasting the install line at the top of npmjs. `npm install --save *`. [/sarcasm] That's honestly how I feel about some JS devs.
If either half of `+` is a string, it performs string concatenation. `-` is not a string operator, so it is always numeric.
Function add(a, b) { return a - (-b) }
When using + you should always assume it's going to concatenate, because in 9 out of 10 times, that's what + will do.
Thank you
I use Cypress for e2e/functional UI tests and love it. Such a breath of fresh air coming from Selenium. I think once it gains some traction in the testing community it'll totally replace Selenium as the go-to tool for UI testing
Perhaps categorize by size/quality? Anyway good job! Keep it up! 
&gt;MadeWithVue - Laravel + **Vue** &gt;MadeWithReact - Laravel + jQuery &gt;MadeWithLaravel - **Laravel** + Vue Hmm...
1 site, 1 filter, 3 domain names if u wish. :P
Thanks for mentioning this. I added my gamejam game I built with react ^^
didn't use them, bit as far as I know goggle's polymer uses them with polyfills. try it out
Or \`a + +b\`. Or just make sure you \`parseInt\`. If you're not sure what type of value you have at any point (red flag, IMO - you should always be sure), you can defensively parseInt a number and it will still work.
I'll post my laravel project that I've been keeping around for 6 years at this point. https://moardammit.com/ Shame you don't have a made with angular website, I much prefer it over vue or react at the current time.
Yeah I was being silly really
Shame on you. I will not stand for silliness on the internet!
Sounds like a better approach since they all are basically the same website.
Besides the multiple Domains - I am already managing all Content from 1 Backend :) I don't think every Vue.js or React.js developer wants to see the other stuff - the ones who want can look at both sites :)
CKEditor 5 supports tables since v10.1.0. Check out the demo: https://docs.ckeditor.com/ckeditor5/latest/features/table.html. 
Thanks for getting my site [bikeva.com](https://bikeva.com) up on there! Doing a project for our local mountain biking club in React, I'll make sure to post it on [madewithreactjs.com](https://madewithreactjs.com) ! Cheers!
Don‚Äôt think anyone is interested buddy. Looks like the pricing is too ridiculous. 
Oh no, my understanding is that you'd filter with the domain coming in.
Are you describing a diff of the content between e-mail A and e-mail B? [https://www.npmjs.com/package/diff](https://www.npmjs.com/package/diff)
I'll add that there are times Wappalyzer doesn't detect React, but devtools does, and vice versa. 
All engines are just a collection of functions, objects, methods, etc. that belong to the vanilla language. There is a lot of code to making a 3D object move from &lt;x1, y1, z1&gt; to &lt;x2, y2, z2&gt;. Game engines take code that is repeated a lot and give them convenient function names so that you type very little to accomplish a lot.
Especially when using Typescript, HOCs become annoying to type properly. The concept in general is complicated, hence why this article exists. A *much* simpler concept is to use a render-prop. Just let the component take a property named ‚Äúrender‚Äù, that is a function which handles the rendering. Any special data the component generates are just passed as arguments to this function. 
This pattern is not super recommended anymore, but if you are building a small rails app it's probably fine. Maybe take a look at https://github.com/airbnb/javascript. This is a very popular linting config that can help answer a lot of "best practice" type questions. It should be noted that these are opinions, and this is not the only popular linting config (standardjs is also very popular). Both of those recommend reserving PascalCase names for constructors. So, functions, objects, methods, whatever, are generally named using camelCase, and classes use PascalCase. 
What about build with Polymer?
I know there's no data because it's failed. That's not the issue I have with this. I'm trying to understand why you would call something only to catch it without even attempting to proceed if it's successful? Let's say I use the example there with fetch. If the call is successful, then I'm going to want to work with the data returned from fetch. Why would I make the call if I didn't intend to do anything with data that's returned (if it returns - if it doesn't, then catching that fact afterwards is better). If not, then I want to handle errors. What you're essentially saying is "OK, it failed, so there was an error", and that's all you're saying. You're not saying "I'm going to work with this data if it returns, but if it doesn't, that's ok because I can catch it when the fetch fails".
webpack
No, this is incorrect. What you are describing is just a higher order function whose each order is unary. Look at the definition for currying in mathematics. Currying is a transformation. The term is used specifically and only for the transformation. 
Wtf, at the pricing... 
&gt; JavaScript comes with a datatype called State `State` is from `crocks` not built in to javascript/node. This is even more confusing as that line is introduced before they even talk about `crocks`.
That is not what it's doing, try it in a console if you don't believe me.
Lol, and therein lies the problem üòâ
They do it so the only way you get it free is only if you release your own code as well. GPL is a virus.
i‚Äôve been using FCKEditor since ... 14 years ago? Happy to see it alive !
I‚Äôm honestly having a better time with the google maps API
that's fine, a tool exists ‚Äî i'm still saying it's a bad practice to use that tool ‚Äî which you might infer from the fact that `babel-preset-typescript` doesn't even receive [even 500 downloads a week](https://www.npmjs.com/package/babel-preset-typescript) the typescript compiler already does the important things that people think they need babel for ‚Äî such as emitting ES5 code for old fashioned browsers so, ultimately: - if you're writing typescript, use typescript - if you're not writing typescript, use babel
[Leaflet](https://leafletjs.com/) is really easy to use, though you have to find a separate source for the map tiles - [Mapbox](http://mapbox.com) is a pretty good option for that.
I always preferred the FuCKEditor name, rolled off the tongue nicely, looks like the new pricing model will bring a return to that classic name
In my experience compiling down is the norm. Webpack or browserify. I was curious about the future (like the next 5 years) and I‚Äôve heard some good arguments for keeping this system even when 99% of installed browsers support ES6 fully, which is handling a good amount of errors at compile (transpile) time.
Lowest common denominator. There's no reason to add the complexity of managing and serving multiple transpilations.
https://www.madewithangular.com/
Does Gatsby.js count‚ò∫Ô∏è?
I've been compiling Typescript to ES2017 for some kiosk projects. It allows some nice things like subclassing `Error` or `Promise`, not expanding async/await code.
seriously tho. at this point, if you are proposing switching out any of the established frameworks or tooling standards, the absolute first thing I want to see on your brochureware is WHY. 
Prpl server might interest you
Okay, I'll bite Why do these generate badges for existing services that have their own badge uris? Ex travis, coveralls, etc? Relying on an intermediary seems like a bad way to go. Also, since when did shields.io die?
I‚Äôm not sure tbh. What browser are you using in mobile vs desktop? I can nitpick but nothing stands out so much that modern JS compilers shouldn‚Äôt just take care for you. Ultimately you‚Äôre doing one Ajax call, and transforming the data arr into texts, that you ultimately assign to an innerHTML. Are you sure the slowness is from your code and not the network? 
I read this all on my phone and didn't try this out so it's hard to tell where exactly your issue is coming from, but the stuff you have in you map doesn't seem as crazy as you made it out to be. It is a good chunk of stuff though so it may be causing issues. If you hook your phone up to your computer you could do some debugging with a profiler to see the exact spots it's running into issues with. If you have Android and chrome it's super easy and I know you can do it with an iPhone and safari too. One thing I would look at is how long the async call to get the data is taking. Another problem area may be writing all of the HTML to the dom
I don‚Äôt really see the issue on mobile - maybe you could explain more? Runs fine to me. Anyway, I don‚Äôt see any reason why the .map aspect of this would cause problems. To me I‚Äôd be more concerned with how the async works, or how you are outputting the HTML.
I made an edit claiming that I'm using chrome for both desktop and mobile, that's obviously a crucial factor. And though I am currently staying in a hotel, my internet speed is different and I know my phone well enough (i'd like to think at least) to know that it isn't my phones connection.
No madewithmeteor üòÅ Cinematic is one that i spent some time on, a desktop GUI for pulling info about movies you have locally (potentially downloaded). 
Hooking up my phone to my computer (both apple products) is an interesting idea, I didn't know I could do that! I'm aware there's a simple way to see how long your async call takes, but I forget it exactly. How should I go about monitoring it's speed, would you say? And yeah, like I alluded to in my post, the html template literals got a bit dense. The inline bootstrap stylings certainly don't help anything either.
Can I ask what phone and browser you're using, friend?
Yep. Especially when they all (roughly/ideally) do the same thing.
[Mild plug](https://medium.com/dev-channel/es6-modules-in-chrome-canary-m60-ba588dfb8ab7). You can target pre-module browsers (where you can transpile everything away) with `&lt;script nomodule src="..."&gt;`. And even if you're not using ES6 modules, you can target that 'high water mark' of browsers by shipping maybe minified but not _transpiled_ code with `&lt;script type="module" src="..."&gt;`. This works because every browser that supports ES6 modules supports `async` + `await`, `fetch`, CSS variables etc, and `type="module"` is ignored by old browsers.
Network tab on chrome will tell you.
Well if is a commercial project, i think yes. If not, well fuck it, you dont deserve see this shit.
shields.io isn't dead...
If I had to take a stab, I would guess it's the preview content that you're loading into the page after selecting a subreddit. Some of these, software gore specifically, load 5 different images... perhaps this is a lot of stuff to download and your phone has some trouble with it? It would helpful to know what "wigs out" means. Do you get complete failure to launch? does it take a long time to load? The JS looks fine. Mild review : I would maybe not use an `if/else` construct there and maybe just include extra content if you find a useful preview image. The hardest bit to read for me was the link formatter. The parsing of the markdown is probably a necessary evil - but you can use the `URL` constructor passing it a string and pull out things like hostname/etc... so could be: const {href, hostname, pathname} = new URL(varname) return `&lt;a href="${href}"&gt;${hostname}${pathname}&lt;/a&gt;`
Ahh yes. Totally knew that. Thank you!
Not the guy you were asking but I poked around on there and loaded a couple different subs and nothing took more than a second or two. iPhone 6s running chrome 
Thank you for your feed back. I‚Äôll look into refactoring the function. I just wrote it today. Never occurred to me how many variations of links there can be. The regexes are completely my own. I found a sort of URL catch all regex but good god was it lengthy. I also know it isn‚Äôt the easiest thing to read. By wig out I merely mean not load all in one shot, with glitchy breaks in images that are choppy at first. You bring up a really good point though about having to load 5 images on the page at once being burdensome for mobile. 
Though I‚Äôm glad to hear that, that just perplexes me even further as to why I‚Äôm having issues with viewing it on my phone 
Yea I have no idea. Maybe try clearing the phones cache and run it again? Wish I could be more help
No worries man! Appreciate your feedback 
Wow, having to transpile separately for every major browser would be a giant pain in the neck for almost no actual value. I'm sure some sites out there must do it, but I've never heard of any normal "startup sized" (&lt;200) company doing it.
I wrote about it in the async section of my "Level Up" blog post: http://codefoster.com/levelup Hope it helps. 
Im quite fond of using [babel-preset-env](https://babeljs.io/docs/en/next/babel-preset-env.html) and thus only having to transpile the code that my target browsers don‚Äôt understand the syntax for (yet).
I have completely given up on trying to work around IE. When even edge still doesn't support stuff that has been supported by all the other browsers since version 1. They can just get a message telling them to use a modern browser
I think you are asking too much from template literals. If you need performance you'd be best to us `document.createElement` and `element.appendChild`, see [mdn](https://developer.mozilla.org/en-US/docs/Web/API/Document/createElement) but this is lower level coding.
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://developer.mozilla.org/en-US/docs/Web/API/Document/createElement) - Previous text "mdn" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20e2zhpuw) 
You can use the fact that modules and nomodule code can be served to every browser and the ones that can handle it will get the modules. That gives you an automatic check for all es6 features at least. Netflix also ran a small (200 bytes or so) script in an iframe that, if it ran completely, would set a flag. The code had one example of every major native feature they wanted to use. That flag could determine whether or not to load the modern or legacy version.
Hasn‚Äôt that been true for every piece of software that isn‚Äôt in a new category for all of computer history?
I haven't perf tested it recently, but as "children" is an array, it'll almost certainly be markedly faster to use an indexed for loop... at least forEach and for-in are WAY slower... most of the time this doesn't matter, especially not for 5-10 items (think 10,000 plus items) so... no good reason I can see right away that it's so slow, but I can warn against using innerHtml w/ user generated content... if someone put html into a post, it would be run on your page... possibly including script tags and silly things like marquee or... the frequently page-breaking... open-textarea tag... 
It‚Äôs worth noting that not all ES6+ features are transpilable. In my opinion, unless you know for a fact that you need specific old browsers, you should feel comfortable writing es6 without Babel to transpile it. 
iPhone 6s - Safari - iOS 11.3.1
&gt;bitovi.com/blog/s... Yes and it's still a valid question.
Honest question: why?
Also regarding whether or not I would use this - just make it mobile friendly by using a responsive layout. I assumed it wasn‚Äôt responsive because when I interact with the select input, it awkwardly zooms in to the input, then I have to zoom out to view the content. 
I was curious why this was considered a "successor" so I looked up the project and found the following the reasoning from the author: https://github.com/amio/badgen-service &gt; I had a good time with [shields.io](https://shields.io/)(and earlier [badge.fury.io](https://badge.fury.io/)), but as time goes by Shields gets slower, leaves more and more broken badges in READMEs. Badgen is trying to be a fast alternative with simplicity and flexibility. Its codebase is well structured and fun to develop - it is pretty easy to add badge(s) for new service(s).
Yeah I‚Äôm trying to look into a way that automatically zooms you back out to normal page zoom after selecting a sub. Not sure how I‚Äôm gonna do it yet 
I find them useful primarily for services that don't have their own badge URIs. I'm guessing covering existing services is to provide some consistency.
Lowest common denominator is indeed common and easiest to implement, but not the only option, or even the most optimal one. Meteor recently added evergreen bundle support. My team at Uber is looking into taking it one step further with browser-specific bundles for our React-based framework (because yes perf improvements are a perfectly valid reason to pursue this effort, and we are able to throw engineering time into the problem).
If you implemented a responsive layout, it wouldn‚Äôt zoom to begin with. ‚ÄúResponsive layout‚Äù is a specific term in front end development
I‚Äôm aware of responsive layout. I‚Äôm not sure what else I can do currently that would benefit considering I‚Äôve maxed out the width (i.e col-sm-12 for mobile). Any suggestions?
I‚Äôm on my phone so I haven‚Äôt looked at the markup, but it seems like its missing the necessary viewport meta tag - https://css-tricks.com/snippets/html/responsive-meta-tag/.
Wow normally VScode auto includes that for me. I must have messed with the head tag or something because I‚Äôm not seeing it. Thank you for catching/suggesting that!
Haha sure üòÑ
Why can't it be as simple as "is this browser ES compatible or not". Then either serve the Lowest common denominator if not compatible otherwise serve the ES6 version
Whole heatedly disagree. They're an alternative to webpack but are only on their 2nd release. If that was the same mindset throughout webpack would never have replaced gulp which replaced grunt etc. Having multiple tools is the way new products/ideas come about. Having a webpack alternative is great as it only introduces more options to the developer. If you don't like it don't use it but other ppl newer to the field might disagree
Whole heatedly disagree. They're an alternative to webpack but are only on their 2nd release. If that was the same mindset throughout webpack would never have replaced gulp which replaced grunt etc. Having multiple tools is the way new products/ideas come about. Having a webpack alternative is great as it only introduces more options to the developer. If you don't like it don't use it but other ppl newer to the field might disagree
That's what Meteor and my POC did. Honestly, even dual compilation is not that simple, which is why most people should probably stick w/ lowest common denominator. The reason we're exploring multiple compilation targets is that it isn't as much of a stretch to go from dual compilation to multiple compilation, than going from lowest common denominator to dual compilation.
This is some wizardry and an interesting use of template strings. So basically it takes the code you write, generates some glue C++, compiles this and then under the hood returns the `require(...)` of the compiled `.node` file. Pretty amazing proof-of-concept. Could be a neat way to get some decent performance for hot paths.
Having map return a big ol' string is not going to cause noticeable lag. That said, using `reduce` (single iteration) will be faster than `map().join()` (double iteration). I believe over twice as fast, if I remember correctly. `.map(f).join('')` =&gt; `.reduce((a, b) =&gt; a + f(b), '')`
The iteration itself is 100% not the cause of lags. The function iterates over 5 items! That's nothing! OP, before you try to optimize anything, take a look at the performance tab in Chrome (desktop) an run the profiler with throttled CPU and see for your self where exactly the browser starts to struggle. 
I did state that the map is not going to cause noticeable lag. _That said_, the information about reduce is an aside, because it's interesting and tangentially relevant.
what do you disagree with? that it's a bad idea to tell potential users what benefit they get over using an alternative? k.
He did mention Uber, do with that big an audience I'm guessing the task will produce valuable results that matter.
Just came here to see how many angular developers make comments.
What have you run into that's not transpilable?
There must be more code than this. Are you able to post it? The only theory I can come up with from what you have shown is that you somehow have misunderstood what groups do and remove `movingPassengers` after the animation is over.
I put it in an inline script tag after my mootools and prototype.js tags.
Yeah, this. Thanks to that modern browsers will have to fetch less kB 
I would suggest trying out some of the features provided by Chrome Dev Tools to see what is real causing your code to perform poorly. https://developers.google.com/web/tools/chrome-devtools/rendering-tools/ Generally, map() is not as performant as a for loop. Generally, layout recalculation and DOM manipulation are slow.
Did it a long time ago so it might not be super accurate, but when you connect your iPhone to your Mac you have to enable the dev mode for safari first, then you‚Äòll be able to select on what device you want to watch the current website. From my quick google search, seems legit: https://www.lifewire.com/activate-the-debug-console-in-safari-445798
Maybe checkout [watchman by Facebook](https://facebook.github.io/watchman/)
Noob, question, what do people use this for?
I know that there is no "best" language ^^ But javascript for example is a language u have much better chances to find a job with these days. I guess with ASP.NET u have not that good chances to find a job as with Python. But thx for your answer :)
Oh okay. Im not familar much with speed, security and co of a language so i cant say the reason WHY companies decide to use language XY. Thats why im asking you, here ^^
Everyone's already covered syntax, but in terms of polyfills there is https://polyfill.io
Often, companies use languages that are popular, languages known by the initial developers and/or languages for which they can find lots of employees. In an ideal world, companies would choose a language as if it is an implementation detail: based on the application's requirements and guarantees. 
webpack is just a new grunt, I'm waiting for a new gulp right now.
It might be worth looking at [https://polyfill.io/v2/docs/](https://polyfill.io/v2/docs/) I've not actually used it though and only found out about it yesterday in the this [video](https://www.youtube.com/watch?v=v9VPGvG2KiM) from kentcdodds
Yes but if you're compiling differently for different targets, you still have to define those targets ahead of time (unless you wanna try super slow dynamic transpilation), and figure out how to serve the appropriate bundle to the appropriate browser. Which I believe is more along the lines of what OP is asking.
Proxies are the only thing I can name off the top of my head, but there might be more.
Curious what kind of problems have you had with edge? Safari has been worse for me personally. 
Be sure to test the reliability of User-Agent sniffing. In the past, this was very unreliable and one of the reasons feature-sniffing (Modernizr) combined with polyfills were used.
Because sometimes, I want to create a script that uses C++ under the hood, but have no need in creating a package, building it as a separate step, etc.
I'm building an svg based web app. (Data viz stuff) There are countless times where I have tried to do something and just found that ie/edge Just flat out still doesn't support it. Of the top of my head edge doesn't support foreignobject which has been in chrome since like version 1
Wow, this is great stuff. Concised, nicely styled, good organization. Formidable.
Thx :)
If it's a commercial budget and they're paying you extra for IE support. 
What I try was generating two JS bundles. One for IE9/10/11 and other for the last 2/3 versions of FF/Chrome/Edge/Safari . So, you can isolate all the magic stuff that needs IE to get working from the rest of the stuff.
But *why* is it bad practice in your opinion? With babel-preset-typescript you are literally writing typescript, with the addition of features that typescript doesn't support, like optional chaining which I mentioned above.
I think you mean polyfillable, not transpilable.
So... is this a thing you really have to worry about? I've been in WebDev since 1996, so I'm nearly as old a fart as they come in WebDev, and I use polyfills when needed and ES5 generally. Transpilation just feels like a rickety step in the process to me and why bother if I can get done without it? But that might just be me yelling "GET OFF MY LAWN" to all you whipper snappers. I get it if you're targeting a specific browser (e.g. an internal system) or even building an App, but on the big bad web? So, does all this complexity in transpilation and grunting and whatever else you kids are doing now-a-days really get runs on the board? Or is it just what all the cool kids are doing? For the record... I build a single global variable and hang all of my data and functionality below it, kinda like how any OOP program is structured. I then import this one variable into any frameworks I need (e.g. `$scope.myGlobalVar = window.myGlobalVar;`) and access any bits and pieces I need (e.g. `myGlobalVar.app.feature.data.blah` and `myGlobalVar.app.feature.fn()`). A particular page doesn't need featureX? Don't include that featureX.js. YMMV, of course, but I haven't seen a reason to move on from this style of coding. So... what am I missing?
It looks great. ![Banner Image](https://user-images.githubusercontent.com/12299906/43127790-f06167ca-8f4d-11e8-809e-e21c6e358477.png)
You could check out the following three chapters I wrote: * Asynchronous programming: http://exploringjs.com/es6/ch_async.html * Promises for asynchronous programming: http://exploringjs.com/es6/ch_promises.html * Async functions: http://exploringjs.com/es2016-es2017/ch_async-functions.html
Nothing, just easier syntax to code and read. Especially with React but def doesnt sound like ur using it
With polyfills, you don't have the freedom to make use of development comfort. Also, polyfills only partially help. You can't polyfill language features. How do you handle async code? Do you still use callbacks? Embracing new technologies means possibly less code but more readable code. So you get a better experience when debugging. IMHO this is worth the effort
Nice try Google, still not falling for Polymer.
I want to go for "normal" developement. Normal applications like Discord, Skype and Co. Normal Software ppl are using on their pc. Otherwise I would like to work for a game. But I guess as a junior developer fresh from the education I cant afford to be choosy. Also im livin in Germany, Berlin so I cant just fly to america to work for Discord for example (even if working for Discord has always been a dream of mine.).
Thats why I asked for .NET Core aswell bcuz you can now run it on linux. \^\^
Yes, that's what I'm thinking. But how are you switching?
I have 2 asp.net core production apps running on their own Ubuntu boxes
There are plenty of tech companies in Berlin (e.g. in the Silicon Allee). You could check if you can pay them a visit and/or discuss what they are looking for -- for orientation's sake. The market segment of software you are describing, is best described as "business-to-consumer" or B2C. There is no such thing as "normal" software. I would like to emphasize that you have options as a junior developer and you should look for a company that wants to help you grow. Good luck!
Me too, but I have to support IE 11 :/ I wonder how many polyfills I'd need to straight up use es6?
&gt; So, does all this complexity in transpilation and grunting _DEFINITIVELY_ get off my lawn territory - I mean grunt hasn't been what the cool kids use for a good 5 years now... ;-) Sorry but I can't take seriously a dev that avoids all of ES6+ goodness (promises or async / await, if nothing else) just because "cool kids yaddah yaddah". I mean you can still write text documents in Wordstar, it doesn't mean it's a good idea to do so... 
You can't transpile code with no equivalent in the target language without polyfills, so one implies the other in this case.
Edge also has this shit bug in their fetch API, which means I have to polyfill it, but first I have to make fetch undefined in the window otherwise the polyfill won't be applied. Fuck MS and their whole IE team.
Huh. See, this is the first time when I've been assigning a const/let/var to something along a chain (e.g. `.catch`) and it's actually not been assigned to what I assumed it was from reading the code. Reading it, it appears as though `data` is equal to `.catch`. Trying it out, now I understand how it functions, and it's actually really useful and a lot cleaner than the try catch methods.
We are fully aware that not everyone can afford it. Writing software takes an incredible amount of time. Our team has currently 40 people, ¬æ of it is focused on writing software or supporting customers. Even though CKEditor is an Open Source project we pay them like any other company :) They have their own life, kids, dreams they deserve to be paid. You can write a ‚Äúrich text editor‚Äù in a week or you can write it for 4 years and be still in the middle of having a feature-complete editor, like we are. It‚Äôs not because we have incompetent developers. Rather the opposite. For years FCKeditor/CKEditor has been serving millions of users and has been used by many enterprise companies. Based on all the feedback and requirements we started working on a framework that will meet all the challenging expectations. As we maintain our software for 8+ years since its initial release date, it has be well-thought and robust. CKEditor 5 has a well-thought architecture, and it's heavily tested from day one (e.g. it has 100% code coverage, which meant writing 10k+ tests). That takes time and cost us money, as you may expect. But it's how software should be developed. Our component is included in many critical enterprise applications. Many times the editor is an important part of an application, where users spend 20% or even 50%+ of their time, writing manuals, transcriptions, books, articles and so on. They expect to have an efficient tool that they can count on at any moment. The comfort of such a user is worth $1/month, even much more than that. Think about the time your user may save and how much their time is worth. BTW, there is an interesting situation in IT that people have really good salaries, but at the same time some of them expect to get almost everything for free or at a bargain price. So from where the companies should take the money to produce software? Not everyone lives from selling ads or harvesting user data. Running an Open Source pet project in your free time and running a very complex software project, which has to earn money to keep going, are in fact two different things. I‚Äôm not saying that the pricing is perfect for everyone. If you have a non-commercial product, you can go ahead with GPL if that license fits you. If you have an Open Source project, we offer ‚ÄúFree for Open Source‚Äù license which will fit any OS license of your choice. If you‚Äôre a freelancer and doing some small sites, you can get the free for up to 5 users license for free. Last but not least, if the editor is just a tiny part of your application, you charge users less than $1/month for your application or in dozens of other scenarios, then indeed you may not be able to afford it. But then it means that the editing component in your commercial application is so irrelevant that you can use anything else. Then, depending on the users feedback, you may find out if you made the right choice or not. That being said, we also offer a negotiable option where for some use cases different terms can be discussed and accepted.
You don't need to save fetch to a variable to await it. You can directly save `await fetch` to `response`. Otherwise: good job. As @bobandalice said: createElement is more suitable for top performing rendering. But for starters, innerHTML gets the job done. Website runs fine btw on mobile. Chrome on android 6
It's not, and probably never will be. But it is constantly unreliable, slow and shows broken badges. Not to mention the codebase.
&gt; Yes but if you're compiling differently for different targets, Right, and that‚Äôs _if_ you want to do that. But if you don‚Äôt, which was the other option solicited for feedback in OP‚Äôs post, then babel-preset-env falls under being able to define a common denominator, IMO.
Consistency. Mostly. Not to mention the stability of Now. Even the famous services goes down or has some attacks. Now is perfect for such things and can have some thin layer for caching. \&gt; I find them useful primarily for services that don't have their own badge Yup.
Badges for all kind of services are all around GitHub readmes and even GitLab and others.
&gt; using a user agent sniffing library Be very careful with that. If you are server-side then the UA value really can't be trusted as both clients and proxies can be configured to fake or otherwise corrupt it. Even client-side I would not trust it as some browsers allow what is presented to your code to be altered there too. Of course once you have code running client-side then feature detection is the way to go, but you can't do that directly server-side. You could send over a lowest-common-denominator version initially and have part of its job be to run feature detection and set a cookie which the server can detect next time to know that it can send a different, potentially more efficient, version next time. This means that the user might not get the best version first time they visit but they get something that works and later get something better. There are other options: you could try live updating once you know a better browser is in control but that potentially adds complexity, or you could stub the code so the first little chunk requested does feature detection and requests the rest accordingly but that adds latency to the user's first visit (subsequent visits could short-circuit the check by reading a cookie value set last time).
Yea. Probably i should named it "alternative". Thanks for the suggestion, i'll look. Is the \`uri\` used for setting the right side of the badge?
But, what purpose does it normally serves?
We check the user agent of the client. If the user agent its from IE (or something pretending to be IE), then includes the IE javascript bundle.
Thank you. So its not a big problem to come in a company without much knwoledge? For example if they are working with js/python and im using js all the time, they will help me learning python from scratch? Or will they say "nah sorry, u need python knowledge aswell to work here".
i have been learning web dev for almost 7 months now? do i have to be worried for not knowing whats a polyfill is? 
[removed]
&gt;do i have to be worried for not knowing whats a polyfill is? probably not, but it depends on your attitude. what are you planning on doing about not knowing what a polyfill is? did you look it up or ask someone? or are you cool with being ignorant until someone educates you? in general, you shouldn't ever have to worry about not knowing something. imposter syndrome is rampant in our industry, and the people who can confidently say "i don't know" are way better than the ones who fake it. the ones who say "i dont know, but i can reason it out or do some research and find out" are the ones you want to work with. so i'd say you shouldn't worry about not knowing something. but if you're consistently finding you dont know something, and you don't do anything to cure your ignorance, it might be time to adjust your approach (still dont need to worry though).
They were asking if they *should* just serve a lowest common denominator version, not how they might do it, which is why I was unsure how that information is relevant. But as something tangentially related it's still useful to know about I guess \*shrug\*
We transpile to common denmnator es6, and use legacy code for legacy browsers.
https://developers.google.com/web/tools/chrome-devtools/network-performance/
http://kangax.github.io/compat-table/es6/ Traceur even says somewhere on their site that 100% coverage isn‚Äôt a goal because it‚Äôs not possible. 
I guess in advocating for that tool, I considered myself in the common denominator camp by default, but I felt it was important enough to lead with because it‚Äôs not just a straight ES6 -&gt; ES5 tool. It‚Äôs based on what the browsers you‚Äôre specifically targeting can handle, some of which may need no transpiration at all, which you would want to send as is to the user in that case.
I thought it was neither, mostly going by what the Babel docs say: &gt; Due to the limitations of ES5, Proxies cannot be transpiled or polyfilled. But I found this as a PoC so I guess you're right: https://github.com/krzkaczor/babel-plugin-proxy Makes sense that anything can be transpiled with enough effort (it just might not be performant).
You don't even need to connect your phone, the chrome devtools have a setting to throttle the CPU to emulate mobile performance. It's in the performance tab of the devtools. You can also use the devtools (sources tab then select your script) to set breakpoints and step through the code line by line to see where the issue occurs.
What is it about?
I'd add though, the lowest common denominator is often higher than people think. Very few sites support Internet Explorer &lt; 11, yet they all make a point of transpiling ES6 down that far.
As a tinkerer of all and (probably) master of none I can see the value in this right away. The only part I would want to play with is the "first time run it compiles" part of that and see how easy that compiled part is to share out to end users in a distro. One comment says that it compiles and returns the "require()" - I am assuming this means very easy and distros just use the require...but I have to see how that works. Thanks for the post.
Min info, max profit. Good
Right, it's a useful tool in any case. If you use the `&lt;script type="module"&gt;` trick then you can use [these targets](https://codepen.io/samthor/pen/MmvdOM) for the "modern" version if your bundle. And IE11 or whatever for the "legacy" version.
Looks decent, but little too much contrast for my eyes - but it is maybe just question of habit. Anyway, one note: why element, props and constructor have the same color? It is not very readable (not for me at least). &lt;blockquote class="imgur-embed-pub" lang="en" data-id="a/bdN9xfp"&gt;&lt;a href="//imgur.com/bdN9xfp"&gt;&lt;/a&gt;&lt;/blockquote&gt;&lt;script async src="//s.imgur.com/min/embed.js" charset="utf-8"&gt;&lt;/script&gt;
How do you figure? While Gulp and Grunt offer similar workflows (they are task runners) they do not compete in the module bundler space like webpack and parcel are intended for. If it‚Äôs implementation detail related; grunt was all file I/O. Gulp and webpack do their work in memory.
I‚Äôm not saying transpilation is always superior but here‚Äôs my perspective. Transpilation allows you use new language features not available in ES5. In the case of building Redux and React apps this is SUPER nice because the spread operator and JSX syntax are both very idiomatic in these libraries but not available natively in many browsers. The other thing about build processes is that it allows you to scope variables to the smallest scope possible instead of everything being globally available in window. 
According to a couple of compatibility tables I've come across there are versions of Opera in the same boat as Safari 10.1, do you know if this is true? If so, is it possible to add support for it in your snippet?
Shouldn‚Äôt feel rickety, small configs are a breeze and will be done in minutes and you can basically forget all about it after the initial setup. Larger configs for big projects take a while but bring big rewards, namely code splitting, tree shaking, using non-standard features like JSX and TypeScript, and most importantly you‚Äôre using all the newer features of the language that have really yanked JavaScript into the 21st century. It‚Äôs more than what the cool kids are doing, it‚Äôs the new standard. It‚Äôs the way things are done now and having worked on legacy projects and modern apps, I can safely say the new way of doing things is far more enjoyable and sane. It leads to a superior product, basically. Many of the old ways people used JS were essentially working around problems or bad features of the language, which is much less of an issue now that we have all these tools at our disposal. Also, OOP is falling out of favour and for web development, functional is the new king paradigm, reactive programming isn‚Äôt far behind either. OOP is too brittle, basically. You can make awesome apps with it, and it‚Äôs preferable when it comes to things like games, but having been taught on OOP at university and then picking up functional programming on the job, it‚Äôs been a real eye-opener for me. It sounds a bit like you‚Äôre stuck in your ways and maybe put off by the initial setup of modern JS projects now? I‚Äôd recommend trying something like Parcel, or another zero confit bundler, then just get cracking using new features and frameworks. I think you‚Äôll never want to go back, it‚Äôs night and day honestly :-)
The open source community I believe 
great
&gt;Sorry but I can't take seriously a dev that avoids all of ES6+ goodness Whilst I agree and love some of ES6's features, I have no qualms taking a dev seriously that wanted a simpler workflow at the cost of an elegance here and there, so long as it's a considered opinion and not an ignorant one. 
This is very interesting. I visited the site via the BaconReaders built in webview and it performed well, in fact stupid fast. I opened the link in mobile Firefox on my Android and it glitches like crazy. I'm going to debug this when I get to work today.
Aka: the logical thing if you have redux. Redux however is absent from the article 
Not sure what you mean by "the logical thing if you have Redux" - there's no need to use Redux in order to handle simple state transitions like this. 
Well of course. Redux is more a way to structure your logic than a library. And this article follows some of the ideas of redux just without mentioning it :) 
Thank you! I‚Äôd really appreciate that. A part of me is wondering if the glitchiness is a result of me forgetting to add the proper responsiveness to the head tag, as another commenter pointed out. I normally forget about these things because VScode automatically includes them but somewhere along the lifespan of this project they were removed from the head, that‚Äôs why clicking on the select drop down zooms you way in and not back out. Just haven‚Äôt had a chance to go back and fix it yet. Let me know what you find out though! Thanks again 
Vue and Angular would benefit from an adoption.
Oh, the services without their own URIs I understand. It's the ones that do that I don't. Maybe you have some URI or size based consistency, but since these badges are SVGs ans Github allows a lot of arbitrary HTML in things like markdown files, well, I'd rather use the URL at the source that is less likely to fuck up.
Are you the guy behind https://www.madewithangular.com too?
You can use this idea of having mutually exclusive states in Redux as well, but I'm not sure I follow your argument that this article relates to Redux. That being said - Redux is a great library, one which I use a lot - even in addition to local state like suggested in this article. 
It's just that this part of state you have and then the hoc reminded me of a reducer I had that I made into a higher order reducer that served the same purpose 
nope! but would take the domain :P
Ah I see. Yeah I see your point, making the state transitions into actions etc. It's a very solvable problem with Redux as well - this article outlines an alternative approach that solves the same problem in situations where you don't consider that particular state global - or if you don't use redux at all. 
&gt; DOES NOT mean that the variable is immutable For that I would deepFreeze() it. It isn't hard to write that method, but in an interview I think the concept how to write a deepFreeze() should be sufficient. (getOwnProperties -&gt; is property an object -&gt; then recursive else just freeze())
Is this essentially to reproduce Redux state management? What would be the advantages over it?
At the risk of sounding like an anti-react troll, I have only experienced state difficulties using redux middleware. In other frameworks where I treat state as just a model I directly mutate, and just handle asynch in a basic ways, I have never run into any trouble a state machine supposedly avoids. I think state machines are overkill for most web apps.
Nope. Transpile, make sure it works in IE11 and done. Managing multiple build targets isn‚Äôt worth it, something will break or act differently at some point.
I can't speak to best practice, but for the majority of things that need to be transpiled, it doesn't really make the code perform worse (just less readable/debuggable). So there's no real benefit to serving different code based on client capability. On the contrary, serving different assets makes everything more complex and error-prone, especially with caching. So I'd say either serve only translated scripts or only untranslated scripts.
transpilation to ES5. Frankly if one is going to use an asset pipeline I don't see why one would do any other way. A JS version per browser is a stupid waste of time, and you need a specialized server for that.
EventTarget constructor, CustomEvent constructor, not supported. This frankly basic shit, it's unbelievable Edge still does not support that. https://developer.microsoft.com/en-us/microsoft-edge/platform/status/ I can't believe I still need tons of polyfills with Edge...
yes, it means you are too lazy to google it instead if typing a much longer comment
"the new Microsoft is so great, so open so supportive of web techs" /s
In my experience redux needs a lot of discipline and the benefit even on a large project might not outweigh this. That‚Äôs why I like mobx. You can mutate directly and it still encourages the encapsulation for everything state related. 
I would recommend searching around on the subreddit and on google. This is not the first time the question has been asked.
Can you prove that your service is more reliable and faster than [shields.io](https://shields.io)? I only believe in hard data ;) I agree that the [shields.io](https://shields.io) badges are often broken in README. But you need more to convince me to switch.
I like this angle
 this doesn't use JQuery. Let's forget the example I gave you, it's a bad approach, I'm going to explain you the concept directly you see, the questions with different result generate a tree. choice 1 Question D choice 1 -&gt; Question B &lt; Question A &lt; choice 2 Question D choice 2 consider that each Question are objects, that contains values, and each arrows are references to the next Question object Imagine a Question object that : 1 an array containing the various choice / answer 2 an array that contains the Question object corresponding to the choice 3 a variable that stores the user answer 4 a method (function that is a member of the object) that process the 5 a method that generate the visual content. so in a loop, you navigate from reference to reference and execute the method that generate the interface for that question, and you bind the method that process the user answer on choice buttons. 
I was more or less joking, but the comparison I draw comes only looking at them as "build tools" and from the way you define your flow: Webpack used configuration-based definitions just like Grunt does - so it's a lot to learn an understand to do anything. Of course for simple scenarios you don't need to because of defaults, but in the end it's all configuration. I liked the way Gulp approaches this differently because your build flow is simply code: and it's declarative simple code (there are very few things to understand and know). It's easy to trace how files are transformed. Of course this is a long discussion, but I think very complex tools and too many transformations that are difficult to override ruin the spirit of JS development - I'd like to be able to run things straight from the browser without a tool.. and only use a built version when I want to (Gulp + SystemJS made this very easy and nice). I also don't think it's a good idea to make every resource you can encounter into a JS bundle.
It's possible, but it depends on the company and your overall knowledge and talents, of course. They will probably expect you to know the basics of one of the programming languages they use or offer you a traineeship. A new language is easier to learn once you are proficient in one language.
Was looking for the netflix comment. Actually what they did was quite interesting - they did not run browser detection but rather ran a script that would eval ES6+ features in a try/catch block and decide upon that.
redux is about the worst encoding of state machine i can imagine. If your actions are simple functions then redux is a beautiful thing. but if your actions are heavily conditional on the current state (ie a state machine) it quickly degenerates into awfulness. Admittedly, the example in the post is such a simple state machine that it would be better in redux.
Cool project. Just want to notify you that your whitespace/formatting is pretty inconsistent.
It doesn't even use promises.
Hi @grokify, Badgen author here, glad to hear from you :D I think there's more than one way to achieve this goal: **serve badge image base on any json/api source**: 1. The `uri`/`query`/`suffix` way, which is used on shields.io 2. Support reading result from RunKit endpoint, let RunKit scripts ([example](https://runkit.com/amio/hello-badgen)) do the dirty works, leave the url clean as `https://badgen.net/runkit/hello-badgen/:arg1/:arg2` 3. Use RunKit endpoint to response a 302 redirection to [static badge](https://badgen.net/badge/community/1111%20members/green), like [https://packagephobia.now.sh](https://packagephobia.now.sh/) does right now. Both (2) and (3) have these benefits: * Clean &amp; readable url * Read from more complex api source * Leverage the power of whole npm (thanks to RunKit) ü§Ø RunKit support is already [on the plan](https://github.com/amio/badgen-service/issues/24), it just delayed a little, many refinements/features are ongoing, hope I got more time to deliver things faster üòÖ
Thanks for sharing your open source project, but it looks like you haven't specified a license. &gt; When you make a creative work (which includes code), the work is under exclusive copyright by default. Unless you include a license that specifies otherwise, nobody else can use, copy, distribute, or modify your work without being at risk of take-downs, shake-downs, or litigation. Once the work has other contributors (each a copyright holder), ‚Äúnobody‚Äù starts including you. [choosealicense.com](https://choosealicense.com/) is a great resource to learn about open source software licensing. 
If someone is trying to trick you via UA spoof and they get a bundle they can't run that's on them. If the UA isn't in a known good set (evergreen) send the lowest common denominator, doesn't seem so tricky.
it has to be synchronous to be used in the same way you do require() calls
Honestly with stuff like `babel-env`, why not go all the way if you are doing this much. I dabbled in this a while back when I was trying to solve some perf issues with iOS devices and our web app. We needed to support iOS 7, but 8 and 9 were suffering for it with larger payloads and slower polyfills. So we experimented with compiling the bundle several times during deploy. One for just iOS 7, one for iOS 8, one for 9, one for last 2 chrome, one for last 2 firefox, one for android 4.4 webview, and another "lowest common denominator". Then it was as simple as a small nginx useragent sniffing script to attempt to grab one of the files if it existed for that useragent, and fallback to the "LCD" if we couldn't determine it. The end result was smaller payloads and faster load times for newer iOS platforms, and we even threw in a payload for IE 11 while we were at it even though we didn't officially support it (mainly because at that point the polyfills became a lot of weight to ship to all platforms). I'd love to make an nginx module that basically packages all this up and offers it for download for others that want to try it out, but in all honesty it was about a days work and a week or 2 of light testing/trial.
[removed]
This should be perfect for prototyping / getting acquainted with NAPI C++ bindings. Also can be used to programmatically generate C++ functions (in a similar way the GPU shaders are used)
Not just tree shaking, but code splitting too! Proper modules are a huge win over adding a bunch of scripts to the page and hoping your globals are all properly accessible
No he didn't.
I'm sorry Grandpa but they switched to gulp üòÇüòâ
Thanks for checking it out. Do you mean the readme or all the docs?
I mean the code, as that was what I looked through quickly.
Thank you so much for your reply. The way you say it makes it seem not that complicated really like its an 8-16 hours job if it's using client side agent detection
The \*best\* practice IMHO is to serve a "modern" JS bundle for modern browsers and a "lowest common denominator" bundle for everybody else. The packages modern browsers receive will be smaller and faster (parse and execution), and old browsers won't get kicked in the teeth any more than necessary. That being said, it's enough of a pain in the ass that I wouldn't bother with it unless your build tooling abstracts that away. Vue CLI 3 (webpack behind the scenes) can do it via the \[--modern\]([https://cli.vuejs.org/guide/browser-compatibility.html#modern-mode](https://cli.vuejs.org/guide/browser-compatibility.html#modern-mode)) flag on the build tool, no extra fuss required. It does the module/nomodule hat trick to manage JS loading. Build time will go up (it's building your bundles twice), but that's the only penalty I've run across.
Your code looks pretty decent, not bad at all for a beginner. One suggestion I have (sorry if someone else already suggested) would be to try to refactor your functions to be single-concern. For instance your `fetchTopFive` function does a lot more than just fetch the top five posts. It also contains the template (which could be it's own function) and renders to the DOM (which could also be its own function).
Yea, I looked into this. There are a few older versions of browsers that will fail with this method. I'm sure you could write a fallback to load the transpiled script if a method fails, buuuuut that's adding complexity.
Thanks man. Yeah I know that keeping functions as pure as possible and one-purpose-oriented is the way to go. This is really just my rough draft, there‚Äôs a lot of things I want to go through and rework. Appreciate the feedback though!
There are definitely ways to serve different files to different clients. Check out the `nomodule` attribute. However, any method like that is going to add complexity. 99.99% of the time Babel is probably going to handle the code just fine, but there is always the risk of the code behaving differently in both contexts. If the download payload is worth it, then I would try it out, but in my experience the gains would be too small to justify the added complexity. p.s. You should only need to support IE11 these days. Everything older is officially deprecated by Microsoft. 
&gt; I also don't think it's a good idea to make every resource you can encounter into a JS bundle. wat? webpack does not do this there are definitely multiple ways to use webpack, the configuration-driven way is only one of them. i prefer the approach of calling webpack within javascript, passing it the config you want, rather than calling webpack directly from the command line, because it makes the build process more explicit. this is the approach that `create-react-app` and `vue-cli` use behind the scenes, and it's pretty straightforward.
Yeah it turned out I was using the wrong serializer for the djangorestframework-gis extension. Now it is in the correct format ha. 
As much as I sympathize with you (been in web dev for 20 years), a library or framework that can easily cost as much as a full time developer will be a very hard pill to swallow for most projects. Even at half the price and without addons, it would cost $300,000 USD per year for only 50,000 users. Don't get me wrong, if this business model is working out for you it's great, but as a developer I really don't see where that price point could fit. Small projects or projects that only need "good enough" (eg: Wordpress) won't pay $1 per user per month, and bigger projects or ones that are built around a rich text editor can't afford to use an expensive third party.
Well we were in a really good position for it too, already having a well setup webpack config and using Babel env to it's fullest extent already. We also had experience doing the "use the file if it exists and a header says to" trick in nginx from when we pre-gzipped all static files during build (using zopfli!) And served them instead of re-zipping during each request. So it was really just a matter of plumbing it all together.
You can show an image on your site, e.g., http://badges.example/yourproject/status.png. This is not a "static" image like a cat picture. The image is dynamically generated basen on your project's automated testing results, or npm published version, or code coverage, etc. It's a nice quick way to show the health of a project. If I'm looking for widget implementations on npm, and I find two similar ones, I might pick the one with the green "tests pass" badge.
Wow, that's some dedication. We have source maps built for prod builds that we can load up for just these types of issues. It's a lot less of a hassle.
Right on. Been working on an open source repo of paid + free resources to learn vanilla JS, if that can be of any help. https://github.com/snipcart/learnvanillajs
Hi, I've created the project which allows to compare project Github starts history. You could take a look: [https://github-stars-history.netlify.com/](https://github-stars-history.netlify.com/) Enjoy!
Thanks \^\^
good to know!
It's not "my". I just made some contributions. As about proof. It's visible with naked eyes - in first place. Second, see both codebases and see https://now.sh to decide is custom express server somewhere (don't know where) is faster than _any_ now-based micro-service. I'm absolutely sure that Shields make at least couple of times more requests. Look the code base, i'm not from yesterday and remember it when it was 2k lines, nothing changed really since then, except more badges. Proof is in the quality behind Now, and more importantly behind Zeit products at all. It's battle-tested and production ready, it's proven that is is massively faster and more scalable, more realiable than any other Node.js based server out there, except `fastify` or such. If not all that - at least compare codebases. I'm not offensive, sorry if it sounds that way. I'm just saying.
https://stackoverflow.com/a/12991203 Have you tried adding `animation-fill-mode: forwards`?
[https://schema.org/](https://schema.org/) has an extensive collection of schemas available in **JSON-LD** format. Is there a similar site for **JSON Schema** .
parse-commit-message v2 was released last night: \- üíØ More spec compliant \- üêõ Cleaned few bugs \- üóíÔ∏è Better docs
as an avid user of Foreman, it's great to see a web dev related post from one of the maintainers. Bookmarked for reading later, thx for posting this!
This is pretty neat. I'd use a regular function instead of tagged literals though. That way you could do stuff like this: `compile(readFileSync('some/file.cpp'))` instead of: `compile\`${readFileSync('some/file.cpp')}\``
I don't think TDD requires validating parameter types that aren't intended. If your function supports null, test null. If your function supports numbers, test numbers. If your function doesn't support strings, don't test strings.
Check out the latest version ;)
The little secret of testing and assertions is there's no limit to how much you can refine your testing, and how many edge cases you will discover to test for. But, of course, your project's budget, people resources and time are not infinite. You need to strike a balance. Some very likely problems you might test for. Some tests you will add after a bug report. I know this doesn't fit the simple ideological mindset you might see by some TDD "experts" but no ideology survives contact with reality fully intact.
https://github.com/vshymanskyy/node-inline-cpp#api
It's only "callback hell" if you code it as such. I typically use the async library to make callback code clean and legible.
[removed]
And brilliant debugging tools. I'd say it's worth it to 1. Install Node, 2. Run `npx create-react-app my-app; cd my-app; npm start`. But then again, that may just be me. Works wonders when you remove react and react-dom from the equation too.
I love gulp but I don't think it's what the cool kids use anymore. Every time I run its npm WARN deprecated minimatch@2.0.10: Please update to minimatch 3.0.2 or higher to avoid a RegExp DoS issue npm WARN deprecated minimatch@2.0.10: Please update to minimatch 3.0.2 or higher to avoid a RegExp DoS issue npm WARN deprecated minimatch@2.0.10: Please update to minimatch 3.0.2 or higher to avoid a RegExp DoS issue npm WARN deprecated minimatch@2.0.10: Please update to minimatch 3.0.2 or higher to avoid a RegExp DoS issue 
* Personally, I hate mixing templates into my logic -- I'd declare them elsewhere (ideally outside the file as a stand-alone resource, or at the very least, as a constant string). * I would be very weary of injecting values directly into markup, mostly because of potential XSS/CSRF attacks. It's _probably_ not going to be a problem here, but I'd encourage you to learn about it to keep in mind for future work. Also, I feel obligated to inform you that you're technically interacting with reddit in an unintended way, and that you should probably be using reddit's API -- especially for your hosted version on github pages. * https://www.reddit.com/wiki/api * /r/redditdev (please don't shoot the messenger)
I‚Äôm not familiar with the async library, but anyway it‚Äôs another library. Is it any better than ES6 async functions in combination with Promises?
Finite state machines are a very common pattern in systems engineering and other low level programming. Redux is a pattern you are used to. Others may think using finite state machines. FSMs also have a lot of good tools out there for diagramming and are easy to communicate to other engineers 
Beware if you have to support internet explorer but are wanting to use async and await calls
You likely don't write automated test for your code. Being able to decorate a component with state and behavior makes it really easy to test components. It's also nice to write a separate unit test for state mutations. 
Awesome, I will look at it tonight.
I found out the problem. Turns out I was moving the individual elements in the group after the animation had finished. It seems like I need to remove the elements from the group after the animation is finished, so I can continue manipulating them. 
&gt; because yes perf improvements are a perfectly valid reason to pursue this effort How much of a measured performance improvement do you need to get to justify the initial engineering effort, the ongoing maintenance effort, and the increased risk of bugs?
The async library is still good (and Caolan is a fantastic individual and developer), but not required with async-await being available. In combination with Async and Promises, it's a better solution if in part because it doesn't require an additional library (but also because it is so clean to write and offers all the flexibility to chain requests into groups through a combination of the 2 features).
I see. I know I need to fix things up regarding formatting and presentations at a couple of places. Working through the list... Thanks for the comment.
Woops didn't see that before
Updated it just recently. I wanted to show off some basic functions, but it can obviously be made even smarter and more convenient ;)
Buy a book : HTML for dummies
A benchmark would be good to have, but right now it's not on first priority. Besides, Badgen is trying to be a faster alternative but not only faster, benchmark couldn't tell everything about Badgen. If you like Badgen that's awesome, if you are happy with Shields that's good too. Shields is not enemy of Badgen. PS, if Shields broken often while Badgen doesn't, noticeably, that would be convincing enough for me :D
I was asking both ("and if so how do you handle that") but in any case, it's a forum, we are allowed to expand the scope of a post! :-)
I love the designs of the both sites.
Wow, I'm actually surprised at how naive I was to think that I could just make my own mini, filtered reddit. Thank you for pointing this out to me. If I ever get to the point where I think this app will extend beyond my personal usage, I'll definitely spend time making sure I'm not violating any of Reddit's API usage terms. Good call. 
I think the main thing, which would get you in trouble, is making more than 30 API calls per minute -- stay below that and you probably won't draw any undue attention to yourself.
I hear you. Yeah I really don't intend to scale past where I'm currently at right now. Thanks for the advice 
...and then to webpack.
Got stung myself by that fucking browser + promises... 
Over 2 years old and this is still the optimal path: https://news.ycombinator.com/item?id=10950862
&gt;Uber I actually thought you were replying to [lhorie](https://www.reddit.com/user/lhorie) (he mentioned Uber) not the original poster and that was the context that I was replying to and now on my desktop I realize who were referring to someone else. Sorry man. ;)
[removed]
https://github.com/haljadooa/twitch-downloader üôÉ
Meh, not sure I get the big advantage over what I do today. At the basic implementation, is it really any better than a LOGOUT action where the top app component can change the state? True, state machines enforce a single place where that transition and state change happens, but I've rarely had any issue where multiple components adjust the ssme state data from 1 action, let alone in unpredictable ways. If you follow smart components pattern, then I usually only have one or two connected components at a time anyways, and they only change their branch of the graph.
Hi /u/Catch11, For javascript help, please visit /r/LearnJavascript. Thank you!
Some keys aren‚Äôt passed to the browser and are instead handled by the OS. This at least is the case for some games consoles and smart TVs. 
*woosh* Can you kids not take a joke today?
No React. We're stuck with AngularJS (mostly happily) and moving to VueJS due to the migration path. Just last night I reduced our dedicated AngularJS code (read: not templates, but filters, directives, controllers, etc) to less than 500 lines across a medium+ app.
Here is an async await example using try catch https://codesandbox.io/embed/p5rxnpmyj0?codemirror=1
Did I say "avoid"? No, no I did not. ES5 `promises` haven't failed us yet so I've seen no business case for `async` / `await` though I'm sure one day that will come.
Yes. Make it so the condition is clicks &lt;= 3
Ah gotcha, np.
Not being able to polyfill language features was the point of my query. So by that I take it you haven't had an issue with older clients, or do you just don't care?
Is there anyway around this? If it helps I'm using Electron (which uses the chromium engine)
Just insert the correct polyfills and you should be okay.
It was fun when it was needed, but my bug count was way greater.
Short answer: no Long answer: possibly in some cased unknown to me
Thank you for a well thought-out answer. OOP is the structure of the codebase only, the code itself is functional, async (as in threaded, not `async/await`) with a bit of events mixed in. As for import and the like, that too is used via RequireJS, generally fully wrapped so we can have an evergreen interface for a slider control (for example) and swap it out for another lib/tool without having to update every reference. As for stuck, that could be a fair assessment. I saw configuration hell in 2008-ish Java, where we had a team of 3 developers and 1 spent 80%+ of their time making sure the build tools weren't falling over. Now... this was 10 years ago in another language, but I just never saw the advantage of build tool hell. Things like Typescript sound great, but then you add in "compile" steps along with configuration. For a large team with young developers I can see the allure, but for a smaller team of seasoned developers I haven't as of yet.
You might iterate over the array and count the occurrences of each occupation. Then you can return a new array with all occupations with a count greater than one.
async/await is a language construct, not a polyfillable feature. You can transpile around it, but you can't polyfill it. 
For async/await, I agree. For promises, you can absolutely use polyfills.
The vtk.js library can be found here: [github](https://github.com/Kitware/vtk-js/)
You could use Lodash. https://snippettree.wordpress.com/2017/01/16/get-duplicate-object-fields-from-collection-using-lodash/
How have I never thought of that. Thanks for the help
Thank you for your answer! I scope variables with SEAF's as required, and only "pollute" `window` with a single variable (if that, actually). Its interesting to hear the toolsets handle this for you. What is the advantage of having the toolset do this work rather than SEAF/developer managed?
Before i try and solve this, i think i see a problem with your object, after the name attribute, you don't seem to close the parenthesis. What happens when you try fixing that ?
Oh, it's just typo. It's 2am here and I should probably get some sleep.
One way to count the number of occurrences of some value of a property with reduce is to make a map of the values with a count for the number of times each value has been encountered, as an example this can be achieved with this higher order function: function countPropery(property) { return function(result, current) { result[current[property]] = (result[current[property]] || 0) + 1; return result; }; } when used on your example data it nets the following result: goal.reduce(countProperty('occupation'), {}) // {engineer: 2, doctor: 2, actor: 1} you can then use Object.keys on the resulting object to get all the properties, but I'll leave that as an exercise for you.
```js function moreThanN(array, times) { const ordered = array.reduce((a, { occupation }) =&gt; { a[occupation] ? a[occupation]++ : (a[occupation] = 1); return a; }, {}); const moreThanNKeys = Object.entries(ordered).reduce( (a, [occ, freq]) =&gt; (freq &gt;= times ? a.concat(occ) : a), [] ); return array.filter(({ occupation }) =&gt; moreThanNKeys.includes(occupation)); } ``` Usage in this case would be: ```js console.log(moreThanN(goal, 2)); ```
anyway i got it to work, mind helping me with the formatting , i can't get it to look like a normal code in the comments. 
Thank you!
Hey i heard angular devs r getting paid alot these days due to everyone becoming react devs, good for u
yeah, i'd have to be working in a legacy project to put up with the async library. if you're still using it in 2018 you really need to drop the crutch and learn promises. 
Please don't
you are missing an /s... 
Well if you are using event listeners unless you go full reactive you don't have to the choice to use callbacks. And you never want to go full reactive in js. Aside from that have you ever used indexeddb? you can wrap it into promises all you want you have to use callbacks.
Material Components for Vue.js by integrating official google mdc-web in vue :) [https://github.com/matsp/material-components-vue](https://github.com/matsp/material-components-vue)
hey! [dodges incoming car] everyone [dodges incoming car] is gone crazy [dodges incoming car] and driving [dodges incoming car] on the wrong side [dodges incoming car] of the road!!!! [dodges incoming car]
You can use alert(); Or you can use appendChild() to add a div to the screen.
Being that I lived for 14 years in Australia, this is a real fear of mine :P
GET OFF MY LAWN!
COBOL pays well, too!
Can you share some code?Id like to try.
It's not a big/complicated thing, but it's mine: [https://fabio-laf.github.io/sorting-algorithms/](https://fabio-laf.github.io/sorting-algorithms/)
Why are there like 5 articles now on state machines? Is this the new async await article spam?
If (score === 100) { alert("you win"); }
 lbl = new Label("Score = 0"); lbl2 = new Label("Collect at least 500 Points worth of fruit coins to win."); lbl3 = new Label(" Watch out some fruit coins are fraudulent, and they will cost you." \+ " Good luck baby caterpillar :-)"); Label label = new Label(); DoubleProperty time = new SimpleDoubleProperty(); label.textProperty().bind(time.asString("%.3f seconds")); BooleanProperty running = new SimpleBooleanProperty(); AnimationTimer timer = new AnimationTimer() { private long startTime ; @Override public void start() { startTime = System.currentTimeMillis(); running.set(true); super.start(); } @Override public void stop() { running.set(false); super.stop(); } @Override public void handle(long timestamp) { long now = System.currentTimeMillis(); time.set((now - startTime) / 1000.0); } };
pane = new Pane(); pane.setMinSize(500, 500); GetGoldCoin(); HBox HB = new HBox(); HB.setPadding(new Insets(10, 10, 10, 10)); HB.setSpacing(7); HB.getChildren().addAll(startStop); VBox VB = new VBox(); VB.setPadding(new Insets(10, 10, 10, 10)); VB.setSpacing(7); VB.getChildren().addAll(pane, lbl2, lbl3, HB, lbl, label); VB.setAlignment([Pos.CENTER](https://Pos.CENTER)); Scene scene = new Scene(VB); stage.setWidth(660); stage.setHeight(700); stage.setScene(scene); [stage.show](https://stage.show)();
im going to try this and see if i can make it work thank you
i havent used alert before but im looking it up. i was at first attempting to create an additional panel but im not sure if i was doing it correctly
just found out about Git hub, mayb this will help? [**Fruit-Scramble**](https://github.com/Cris-p-cream27/Fruit-Scramble)/**README.md** 
Wait, I haven't got around trying parcel yet!
Async/await. 
Did you mean === or is it suppose to be == It gives me an error code for deletion of the additional =, maybe there's an input i'm missing?
This is java not javascript
\*Facepalm\* ......can you tell I'm new to this .....oops.
Why not just define an [issue template](https://blog.github.com/2016-02-17-issue-and-pull-request-templates/) in `.github/ISSUE_TEMPLATE.md`?
If you are just learning basic conditional if/else flow, alert should be good enough. As you learn more, alert will no longer be sophisticated enough to meet your needs. if ( userScore &gt; 50) { var parentDiv = document.getElementById("yourDiv"); var newHeading = document.createElement('h1'); newHeading.innerHTML = "You won!!!"; parentDiv.appendChild(newHeading); }
ES7 introduced async/await natively. As far as I know it is just promises but with a generator/yield type of syntax so it looks cleaner. Then you use try/catch to error handle (opinion, there‚Äôs other ways). I just rewrote some old tests to drop callbacks and use async/await instead. There doesn‚Äôt seem to be a performance boost one way or the other, but the code looks much cleaner. 
You could return early. clickup() { if (clicks &gt;= 3) return clicks++ } clickdown() { if (clicks === 0) return clicks-- } 
ive created an alert: Alert alert = new Alert(AlertType.INFORMATION); alert.setTitle("Winner!"); alert.setHeaderText("Congratulations!"); alert.setContentText("You've won!!!"); Should i be able to insert this alert into a if statement like yours above? Also thakn you for your input its all greatly apprecited!
I noticed there was another one out now too. On my part that was honestly a coincidence - I‚Äôve been using this pattern at work for the last few weeks, and wanted to write an article about it. That being said - fun coincidence!
Triple equal is what you shuld pretty much use always ,because it checks for type too Example 5 == "5" true 5 === "5" false 
You can transpile async/await to polyfilled promises.
No, none of these things inherently require an internet connection. You can run everything you need (Node, Mongo, etc.) on your computer for development purposes, rather than using a cloud service.
\&gt; but not required with async-await being available. It's often still necessary unless you want all of your async-await functions to execute serially.
TIL
gulp is the new grunt. and even that is not necessary anymore. webpack is not a task runner.
IE browser usage is down to around 7% on desktop machines, and essentially non-existent on other platforms. Thankfully most of us don't have to deal with that garbage anymore.
Adding reference to docs into this article would be much helpful [https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/async\_function](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/async_function)
I worked through the book 'Build Your Own Angular'. It was one of the best learning experiences I had while learning javascript.
It's a good practice for sure but like most web development projects they tend to "be used". Putting another framework out in the open. A good lesson for the individual but a riskful move for an ecosystem. I've worked on "legacy" projects before that used their own framework/ stale fork of library or boilerplate. I can recommend writing them yourself as an exercise, you can truly learn a lot. But please don't use them for anything else unless you have a good reason.
`Promise.all` usually solves that problem - I find that using async/await in combination with the more traditional promise patterns produces something that usually works fairly nicely. Of course, that doesn't solve the more complex problems (e.g. "run these promises with three concurrent promises going at any one time" etc) but for those I think you always need some sort of library, and there are plenty that are more suited to promise-based asynchronicity
algorithm, in words: create a hashmap (in javascript, an object). loop over the array. for each iteration of the array: check the object for the existence of the current occupation: if it exists, increment the value by 1; if it doesn't exist, set the value of that occupation in the object to 1; create an empty array loop over the keys of the object you just created add the value of the object at each key in the loop to the empty array you created return the array you created before the object keys loop
1. Since my code gets wrapped up SEAFs by Webpack, none of my code is actually concerned with how it gets run. Scoping follows module-based rules which I find easier to reason about, especially coming from Java and Python. Webpack also takes care of making sure your code only runs once it's dependencies are available. Another thing I don't have to worry about. 2. Testability. Because I can import and export functions using the module system, it is easy to isolate my logic into easily testable functions. I can also write tests right next to my source code and know that they will not end up in my bundle because Webpack will not ignore them (because the tests are not being imported by any other files).
You can do all of your development locally, without an internet connection; but if you need to install anything with NPM or are linking to any CDNs on the front end, you'll need to have an internet connection. Best advice, make sure you have all of your dependencies installed via NPM and then develop locally. Best of luck.
If you hover over `car` with your mouse, and hold down Ctrl (or probably Cmd) on a Mac, then VS Code will try to show a preview.
Awesome, that‚Äôs will make things much easier. Thx
Not to be too pedantic but your example isn't a polyfill but simply transpiling down. A polyfill actually implements code to implement a feature that a browser doesn't yet support. (i.e. An Array prototype method that is natively implemented in new implementations but not on older browsers)
As async-await is a simplification of something, I seldom hit problems that still need call-backs (or generators). Example: Async queues. The async lib has some powerful functional-y helpers which still make sense in some edge cases, even in 2018.
Quick follow up question: I noticed if I extend a class that it will only show me the extended values and not the original interface. I'm assuming this is by design and there is no way around this?
async/await works inside all "vanilla" JS control-flow statements. Whiles, Fors... It wont work if you use thinks like array#forEach.
I think you misunderstood what I was saying. Async/Await blocks execution of the next line until it's complete. You often don't want that.
What do you mean? Async/await allows for the same error/exception handling as promises and callbacks assuming you utilize it correctly.
then you'd use promise.all, like he said PS: serial + async was something quite tricky to write only with promises let promise = array.reduce((chain, item) =&gt; { return chain.then(item =&gt; { //do something with item }) }, Promise.resolve())
What are you talking about? Async/await was built off generators and came *after* the standardization of promises.
Every time I read comments in r/javascript I'm reminded why so few companies are able to adequately fill JS Engineer roles.
They're not talking about async/await, they're talking about `require('async')`.
Thanks so much, I‚Äôll try to get mongo set up for the 50th time lol.
Okay, thanks for the help!
I strongly disagree that was an improvement
They have been reported to the admins.
who hates callbacks?
&gt;Develop Blockchain Apps with Sidechain Technology Hello /u/kenman, I asked the mod from r/Asch_Platform to delete the link and he kindly did. Could this post made visible again in the r/javascript newsfeed? Thanks!
Uhm do you use any modern front end framework? Also setting up a transpiler takes like at most a couple hours your first time, then 5 minutes your 2..n-th time.
Callbacks are so fundamental to JavaScript and coding in general I really don't understand the negative sentiment. They're a tool, like anything else, if used properly they're a godsend. Otherwise they're a blight
There are a lot of us who work on internal enterprise software that have to deal with that garbage.
Affiliate advertising.
Well, that's not a medium+ app. That's a very small app. 
Just to keep it within reduce for this case - probably a little too messy for real use ``` const multiOccupation = (arr) =&gt; arr.reduce((acc, current, i) =&gt; { let occupation = current.occupation; if (acc[occupation] !== undefined) { acc[occupation]++; } else { acc[occupation] = 1; } if (i === arr.length - 1) { for (let i of Object.keys(acc)) { if (acc[i] &lt; 2) { delete acc[i]; } } } return acc; }, {}); ```
You can get to a point where you have so many callbacks that figuring out bugs takes longer.
 Sorry for the formatting, just typed this out on my phone. Haven‚Äôt tested it, give it a spin. `code` goal .reduce( (acc, n, i, a) =&gt; a.slice(i + 1) .filter( m =&gt; n.name === m.name &amp;&amp; n.occupation === m.occupation) .length ? [...acc, n] : acc, [] )
I have no idea why this user hasn't been banned yet, they put up a new link every few days. The Udemy affiliate agreement itself actually states that they don't want their affiliates to spam sites like Reddit in this manner.
Right, but as I pointed out earlier, don't you think it's insane that it would cost us more to use an, admittedly great, rich text editor than to run our entire enterprise application suite on aws?
What versions‚Äîjust the Safari 10.1 issue I mentioned in my post?
Even with promise syntax? With promises it doesn't nest and they're siblings of each other so I feel like it just looks like conventional code.
At least we‚Äôre on IE11. We‚Äôve firefox but barely anything runs properly on there lol
We actually do something like what you're describing in a project to seed test data into a database during development. `Promise.all` where some of the promises have chains that run `await` allows promises that are reliant on each other to run independently from the others. Promise 1 could be fetching data and then pulling JSON out and then sending some parts off to another server and then handling the response, while promise 2 could be running some sort of cache clean, while promise 3 could be updating your local database with some other data and returning a response from the DB. Each await in each promise chain will wait until the final await finishes, but the entire chain will run in parallel to the other 2 promise chains. The entire .all will only return once every part completes and it's surprising simple to write. More to the point, it avoids callback hell, and plays towards nodes strength in concurrency.
400,000 lines is small? Definitely not large, but small? You've been watching too much porn.
There is a large difference in connotation between "so fundamental" and "were the only option". In the same way `var` is "fundamental" it was absolute grabage not having `let` and standardized `const` for so long.
AngularJS, so ye...not really. Migrating to VueJS over the next 6 months but we're a small senior team so maybe that's a factor.
its 2018 why even worry about callbacks, just use async await
about time!
Not all of us are lucky enough to work on projects where that is available.
lmao what
Not that I know of, but I don't see why a website like that couldn't exist, and why merging some of the schema and data together wouldn't create one format that brings together the best of both worlds easily. My question is more why JSON-LD wasn't built on top of JSON Schema or integrate with it in some way.
Serious question: why is this a huge deal? I make an effort to write as much POJS as possible, but jQuery does speed up a *lot* of the DOM manipulation.
I‚Äôd be surprised if the polyfills and whatnot weigh in less than jquery 
That tends to fix the problem. But I still run across code that is nested callbacks.
They don't work well/at all with IE, which many enterprise applications have to support.
jQuery was a solution the cross-browser problem of the '00s. Marriage counseling is a solution to marital problems. The idea of needing either leaves a bad taste in many's mouths. Yes, jQuery does have nice DOM manipulation tools. But with modern browsers you can create similar helper functions in under 2 kilobytes.
Fair. I'm sort of a neophyte developer, so a lot of the... er, camps? tribes? in development have me kind of bewildered.
"If so" usually means you're referring to one branch of the conditional (to borrow programming terminology) implied by the question that came directly before. But I'll leave it there because communication is tricky etc. and this is obviously way off topic. Of course you're right about the other part.
Speeds up development but slows down the actual behavior in the browser.
Yea I was wondering that too. Another commenter above said it solves the problem of the '00s. But they replaced it with several other libraries + polyfills ... in order to solve the problem of the '00s, and as your screenshot shows and the fact that they dropped IE which jQuery works fine with, their new solution isn't necessarily better. I think they're just hopping on the bandwagon where it's trendy to shit on jQuery. Admittedly it's old AF in terms of the JS world.
It totally makes sense for unit testing. The whole point of unit testing is that you're testing one singular unit of code. The things that it uses are a black box, and the unit assumes that they work how they're supposed to. The unit doesn't care about the implementation details of the components that it uses, because those are different units that have their own unit test suite. In my opinion, this article is totally misguided in that it presents itself as an argument against shallow rendering but is more of an argument against unit testing in general. It demonstrates a clear misunderstanding of what the purpose of unit testing actually is, in that every complaint is about something unit testing can't do that integration testing handles perfectly.
This is an article about improving one‚Äôs skills, not best practices for a production web app.
It's not really about a camp or tribe for/against jQuery, it's more like bowers have fixed some of the frustrations jQuery addressed.
Um, you have heard of Babel, right? Because a/a is just sugar for promises which in turn are just standardized callbacks. So you sure as hell can have all that in IE6 if you need to. 
So what does Github use for their frontend?
&gt; but slows down the actual behavior in the browser. Are we *really* complaining about web page performance of *JQuery* in a world of dynamic "Web Application Frameworks" that are about 10x slower than normal web pages? See for example: New Reddit and my favorite whipping boy of terrible design, PayPal.
Yeah, haven't needed to use jQuery in years but starting to work in an industry with old browsers. I will welcome it back with open arms if it makes my life easier. 
What I'm describing is _literally_ [the definition of currying](https://en.wikipedia.org/wiki/Currying). Perhaps you're not quite clear on the concept of "function." Here's a function: `{ return a + b }` Here's that function without currying: `(a, b) =&gt; { return a + b }` Here's that _same_ function with currying: `(a) =&gt; (b) =&gt; { return a + b }` A higher-order function where "each order is unary" would be something more like this, which I agree is not an example of currying (well, the outer function is curried, but the inner function is not part of that currying): ``` const hoFun = (service) =&gt; (options) =&gt; { const config = { /* derive configuration from options */ } return (url) =&gt; service(url, config) } ``` However, again, this could be written as a curried function: ``` const curFun = (service) =&gt; (options) =&gt; (url) =&gt; { const config = { /* derive configuration from options */ } return service(url, config) } ``` Which can also be uncurried: ``` const unFun = (service, options, url) =&gt; { const config = { /* derive configuration from options */ } return service(url, config) } ``` Or maybe you're getting hung up on this "transform" bit. The transformation can be in writing the function another way, it does not require that you write an _n_ary function and then do something to it, although that's also applicable. Both valid examples of "currying": ``` // assuming curry() takes an nary function and curries it const uncurriedFun = (a, b) =&gt; a + b const curriedFun1 = (a) =&gt; (b) =&gt; a + b const curriedFun2 = curry(uncurriedFun) ```
I have a five part tutorial on this. First part is here: [http://wellpaidgeek.com/2017/07/26/mastering-asynchronous-javascript-part-1-callback-hell/](http://wellpaidgeek.com/2017/07/26/mastering-asynchronous-javascript-part-1-callback-hell/) It covers callbacks, promises, generators and async, and describes the pros and cons of each.
We've used the same version of browserify+Babel for over a year in our previous project without issues. Now starting a new project using webpack (because it's what the cool kids use now). There's no direct "business need" for almost anything in tech, but better tooling that improves programmer productivity and satisfaction translate to increasing business value. For me it's just incomprehensible how you would be fine with writing plain ES5 code. I guess if you haven't used modern JS with it's related tooling you don't really know what you are missing but to me old school JS is horrible to work with (and fortunately I don't have to! Also I would never accept a job that required me to). Do you consider seniority based on purely years of experience? Because, I hope this doesn't come off wrong, I don't really want to minimize your experience as a developer in general, but in my company (and many others I know of) your years of experience would be worthless if you don't know modern tooling and language features. Of course if you really are senior in skill and not only on years you would pick up that stuff very quickly, but anyone interviewing you would find it very weird that you have never seen the use for a transpiler/bundler or using ES6+ (I don't know a single JS developer who doesn't despise pre ES6 JavaScript)
Those frameworks are lightning quick if you know how to use them. jQuery is just a lot harder to fuck up performance-wise.
It wasn't just the slowness. (Which is becoming somewhat less relevant on modern mobile devices) It was the slowness combined with bad code that was easy to write such as multiple binding of ajax calls and such. It was the complicated and often logic you had to write to make sure that the DOM accurately matched the state of everything that was in memory. It was accidentally selecting more than you intended to by not writing precise DOM queries. Only to spend hours tracking down why something new you added was being affected you wrote a long time ago. It was trying to pull in some plugin that depended on a slightly different version of jQuery and when you tried to reconcile the versions all hell broke loose. Was it nice? Of course it was. At the time it was downright amazing and so easy to use. We've learned from the mistakes and issues of jQuery and moved on. That's not to say new frameworks are perfect but they bypass a lot of the issues jQuery has.
What‚Äôs the problem?
The website doesn't load for me... anyone else also see it broken?
I misunderstood you (thought it was a 500 LOC app).
Actually not that hard. A lot of people don't understand what `$(selector)` does under the hood.
&gt; fetch for ajax Had to look this up, when tf did this come out? https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API/Using_Fetch
CustomElements 
With es6
Not caching selectors is nothing compared to a steaming pile of poorly written full-stack JS though.
Why?
jQuery touches the DOM directly and it does not provide a decent way to manage any state of your DOM. This leads to slow responsiveness in the UI and a potential for many errors, due to bad coupling of the HTML and JS. It's not jQuery's fault per se; it certainly has its uses. It's more of a problem when we come to face the challenge of building large and more complex web applications. jQuery will still be a great tool for manipulating the DOM, if that's what you intend to do, but there's no question that as a simple drop-in library, it's going to get hairy real quickly.
I've had my own tooling since YUI :) Hell, I built client side SQL*Server-based type checking in 2005 (as in SQL*Server's double definition, etc.). Everything I've ever looked at, short of Typescript, tooling and type-wise was either too kludgey or added into my own toolset repo. AngularJS was an eyeopener and refreshing when we started a project with it back in 2012, but still most of the type-ish and tooling stuff was... not mature. Since I've been under that system with my (better at the time at least) tooling used across the team, but I know I'm out of the loop with the new stuff, hence my query. We have type checking, coercion but not in the automajic Typescript kinda way, so there is still condom coding being done. However we can also do have things like function overloading, partial classes and the like that I've not really seen elsewhere (so I guess our OOP isn't pruely structural, though these serve structural ends).
A few years ago now I think and support is getting better. A lot fo people still go for Axios to do AJAX, because native browser fetch() has limitations, like cancelling a request.
Why not is a better question 
For most sites, no it doesn't. Not noticeably anyway. And there's lots of things you can do to improve performance while using jquery. This is the problem with the JS world. Most people don't need react, Vue, or angular, but everyone thinks they do.
It's only good for really simple uses. Not as good as jquery or libraries like axios.
mate the tribes are morons, it's not because you're new. be open to new ways and keep learning things and you'll be better than the cultists of &lt;insert pet technology here&gt;
And no one wants to manage state in jquery 
I honestly can‚Äôt think of a solid use for jQuery in a new, non-legacy project.
"Popular JavaScript" is the trap people fall in - they learned jQuery without JavaScript, without debugging. Now it's Angular/React/Vue - they learn the toolkit/framework and say they know JavaScript, when they just know a subset/framework representation. 
Event Delegation. The same as React. Instead of attaching different events to different elements, they let the event bubble up till the top object and evaluate the target to fire the correct handler. The same as React. It‚Äôs performant because it‚Äôs expensive to listen to different elements each loop iteration.
Apparently github isn't one of those sites.
You should already have your app component created. In the app component html file do this &lt;button (click)=‚ÄúdoSomething()‚Äù&gt;do something&lt;/button&gt; Then in app component.ts Public doSomething() { // code logic here } You really should just look up some tutorial on YouTube though. They take you through everything step by step. 
We just use a small wrapper around fetch and have had no issues. Going native is a great feeling
so then what is this? I did it the way you mentioned but i came across and now i am confused lol https://docs.angularjs.org/guide/controller var myApp = angular.module('myApp',[]); myApp.controller('GreetingController', ['$scope', function($scope) { $scope.greeting = 'Hola!'; }]);
But is it also a one way flow like React? The whole value of React for developers is the one way flow.
Do they use Polymer/lit-html for CustomElements? If not, how else?
Fetch also still doesn't support progress events. Anyway, I never really understood what's so *foreboding* about just using XMLHttpRequest. It's a pretty straight forward API.
Broken for me, too.
why ask why is a even better question
Ahh I see the problem. You are using angular js which is a completely different framework from angular2+ Angular js was a great framework, but I don‚Äôt recommend learning it. Instead you should learn the current angular (angular6)
I'm a dinosaur. I started programming in the 1970's. I am in awe of the open source productivity tools that are available now. Just for JSON I have found a tool that will reverse engineer a schema on a JSON file, validation tools,a tool that will create a specialized editor based on a json schema. 
i did ng -v and it shows angular-cli 6.0.8. Maybe i am just utterly confusing myself with the versions and looking at the wrong one while working on a completely different one?
Sometimes better long term gains involve worse short term ones. 
Tl;dr jquery is bad because people are incompetent 
Angular cli != angular app. The cli is just a helpful tool to generate angular applications. To make a new app with the angular cli go into your terminal and type Ng new my-app The cd into the folder and type Ng serve Then in your browser go to local host 4200 You should have a app running 
Config hell is definitely a thing in a lot of modern projects. It wouldn‚Äôt be so bad if it didn‚Äôt effect the dev experience negatively but often it does. that being said you can avoid most of these pitfalls and still getting the benefits of these modern tools by KISS and guidelines &gt; configuration attitude. Definitely recommend using bundlers/transpilers (conservatively, KISS)
Which polyfills? Do they use Polymer for CustomElements?
Nope. It's a DOM API, not a language feature.
Webpack is confusing af to learn and get used to at first. Whatever build process you use (gulp, grunt, webpack, parcel etc etc) to shit on one just because you prefer another is dumb. Feature parity looks pretty similar and there's no telling what they might offer in a few months let alone years. Let the dev decide rather than have you spoon feed them all the info. I love using webpack too but when I first encountered it took forever to understand it's crazy looking syntax. Any dev looking for some build process will quickly find webpack. This is something more likely to be found by devs who are experienced and want to try out something new and see if it works better for them. Saying they shouldn't try and get the word out about their product is idiotic in the extreme. 
Why go to the effort to replace something you have which already works. Granted jquery is slow to load and I understand relying more on the pure JavaScript library, but it was already done. Going to the effort of replacing feels like more effort then it‚Äôs worth.
Why go to the effort to replace something you have which already works. Granted jquery is slow to load and I understand relying more on the pure JavaScript library, but it was already done. Going to the effort of replacing feels like more effort then it‚Äôs worth.
It's absolutely amazing. People building on some very simple standards (ie. JSON) and the ease of publishing and using open source tech has enabled some truly awesome results. Personally, a few days ago I had to make a UI editor which took in a few files in JSON Schema and rendered a whole bunch of pretty fields using React (some of which had to be custom such as a file uploader, which is not part of the JSON Schema spec but used a technique like my comment above). I got a rough version working in about a day total, which is 100% a testament to all the powerful tools and documentation I found along the way.
Because servers are expensive and slower request takes more servers, more servers require more money, and that‚Äôs why push to the limits trying optimized frontend
That would prevent any Town instances from being GCed.
But they replaced with yet more libraries
You actually don't need this technique, event delegation is just a "tool" but to not do spaguetti code, you just has to be vigilant every time, there is no magic trick, I can do ugly code inside a really nice event delegation. Event delegation are useful and faster WHEN you have to deal to an undefined number of item, because you can bind the event ONE time. And we can imagine that it could reduce the garbage collecting. And what is the "loop iteration"? are you refering to an inner browser thing?
It's certainly becoming less useful. I'm not sure it's entirely obsolete though.
Still much smaller than jquery, those libraries are like less than 100k
Have all your team-members been great coders? The more idiot-proof you make code, the better it will function. *Especially* a framework like Javascript where competency is an inch thick and a mile wide.
&gt; Both of those recommend reserving PascalCase names for constructors. So, functions, objects, methods, whatever, are generally named using camelCase, and classes use PascalCase. is a namespace deemed to be a class?
&gt;This leads to slow responsiveness in the UI I've worked with *terribly* written jQuery that somehow never hit performance issues. I can't imagine the level of dogshit one has to write before performance becomes noticeable.
They transpile down to generator functions, which are further transpiled to something that can be polyfilled. There was a [plugin to transpile to promises](https://github.com/babel/kneden) but it had issues
&gt; If you are server-side then the UA value really can't be trusted Well, in this case, it doesn't matter that much (at least not as much as it would in a security sense), since under normal circumstances we stay in the happy path. Going out of your way to spoof something more evergreen than you can actually handle as a client just results in triggering the fallback code to lazy load the lowest common denominator (i.e. a deoptimization). Going the other way around doesn't matter much either, you'd just get a bigger bundle than you would otherwise be able to handle. Also, there are two separate concerns to think about: syntax and polyfills. Syntax errors fail pretty much right away and can be handled as a deoptimization much more easily. The absolutely worst case scenario that can happen is you accidentally deploy broken code somehow and that triggers a deopt - in which case the deopt is the least of your worries. For polyfills, you can control how much polyfilling you want to live with. You may opt to spend effort into polyfilling Promise conditionally (e.g. in IE only), but keep Array.includes in all compilation targets to help maintain your sanity.
How many DOM touches are we talking? If it's a site without much interactivity, performance isn't really your main concern -- it's ease of updates and build chains and things like that.
Fetch kind of sucks though. No cancel. No progress. Need polyfills anyway.
For many coders, their projects are ephemeral. The approach to coding is drastically different between a coder who will work on a site for 2+ years, vs a coder that will work on a site for 2+ months. One is most interested in performance and maintainability, the other in deadlines. Frameworks make building a modern site VERY quick work; people forget shorter dev time is also a bonus.
 function reqListener () { console.log(this.responseText); } var oReq = new XMLHttpRequest(); oReq.addEventListener("load", reqListener); oReq.open("GET", "http://www.example.org/example.txt"); oReq.send(); vs fetch("http://www.example.org/example.txt") .then(x =&gt; x.text()) .then(console.log) I'll take fetch, thank you very much.
The irony of M$ dropping IE support
Nice :) I see that we could remove the parenthesis by doing this combinaison \`result\[current\[property\]\] + 1 || 1;\` But does a creation of a NaN value take more time than a well formated operation? \`undefined + 1\` vs \`0 + 1\`
Jquery is less than 100k too
Functions that accept callbacks already form a dopeass monad that's more powerful than any async library or abstraction I've ever seen: [https://gist.github.com/masaeedu/bd7f32c53ea8c34e30ad0f0f8a7948ca](https://gist.github.com/masaeedu/bd7f32c53ea8c34e30ad0f0f8a7948ca)
&gt; dope ass-monad *** ^(Bleep-bloop, I'm a bot. This comment was inspired by )^[xkcd#37](https://xkcd.com/37)
Certainly not me. Functions that accept callbacks already form a dopeass monad that's more powerful than any async library or abstraction I've ever seen: [https://gist.github.com/masaeedu/bd7f32c53ea8c34e30ad0f0f8a7948ca](https://gist.github.com/masaeedu/bd7f32c53ea8c34e30ad0f0f8a7948ca)
This just reminds me of a discussion i had earlier today over the "not invented here" syndrome. 
Hi /u/a1300, No.
What polyfills would they need to support IE9+? What portion of their userbase is using IE8-? How sustainable is their code when requiring compliance for (very) old browsers vs flexibility to move to better emergent technologies? How easy is it to hire new coders? How much more weight is added? Money spent? Are there security risks for allowing users to use old browsers? Is Microsoft trying to encourage users to upgrade to Edge?
Their browser is Edge, they have been distancing themselves from IE since windows 10 release.
I read through a lot of the replies to the tweet and it wasn‚Äôt mentioned that I saw 
I haven't thrown away my iPod. If I need jQuery I use jQuery. People need to stop treating JS like it's reality TV.
jQuery is just bloated and outdated. Was great when it first came out but it now does a lot of things that vanilla JS can do and usually does better. It also solves for a lot of problems and follow many paradigms that were a product of limitations at the time it was developed. This can slow down your app or complicate development pretty fast. It's not horrible in some situations, but it gets a bad reputation in modern JS development because it does not play nicely with how most frameworks handle the DOM now.
Can't you do that without a library? Just attach all event listeners to `document` and have them bubble, and then check the target.
Found the junior dev
Yes, but they have been traditionally adamant in keeping backward compatibility. 
Not in your example
Fuck that XMLHttpRequest bullshit I never got into learning that one. 
People are giving you BS answers...it's just a milestone. We shouldn't have needed jquery and now we don't (as much)
Ever hear of ES2015?
Well, in fairness, it‚Äôs a DOM api that is built on promises, which are an ES6 feature. 
Cool story, bro, you should submit this as a PR to their README.md
Fetch has cancel now and it looks like it's supported in all browsers except ie: https://developer.mozilla.org/en-US/docs/Web/API/AbortController/abort
Haha, agreed.
I wrote it once so I can remind myself that life could always be worse
Yeah but since fetch isn‚Äôt part of ES2015, I think maybe _you_ are the one not aware. 
Fetch supports download progress, but not upload progress.
It has cancellation now in recent browser versions, and it's been [implemented in GitHub's polyfill](https://github.com/github/fetch#aborting-requests) as well.
what naming convention should I use for my namespace?
Nothing ever works. It‚Äôll say stuff like use this command and it won‚Äôt work. In the end I can never figure it out. I want to use mean js but can‚Äôt figure that out either. I‚Äôm dumb. I wish there was an easy way. You‚Äôd probably just say follow some instructions... I just can never get it i don‚Äôt know why lol
https://fetch-progress.anthum.com/fetch-basic/ Should work in modern browsers, with the exception of Firefox (for now).
Would you buy an iPod today or get something a bit newer and sleeker?
I suppose if I needed it yes, but as I mentioned I still have my old ipod. Still works and has all the greatest hits of the mid 2000s already loaded. To your point, if i need the functionality of jquery I will use it. If I can use a more modern approach I will.
&gt; I'll take fetch, thank you very much. Most developers do, but my point wasn't wheather you *should* use Fetch or not, my point was to simply state that XHR isn't complicated and has more features, regardless of the downvotes.
Depends on my needs and budget.
It‚Äôs good for like 98% of use cases.
Microsoft tookvover hithub.com and have dropped support for thier own browser LOL
codecademy is a good start for those completely not sure what's what
javascript.info could do some good
chill with the snark
The huge deal is just about this toxic and irrational hatred towards jquery, nothing else! Frankly, I really don't understand what this is all about, purists want to write everything in pure JS or even web-assembly, that doesn't mean jquery is useless. It has sustained through decades of web development and probably powers 95% of websites out there, replacing it with more verbose code, polyfills and a bunch of other libraries doesn't make sense unless you just want to prove a point!
Man, I feel old. Xajax for php was a thing.. then prototype.. then jquery.. now all sorts of frameworks.. believe it, that anything you are doing in 2018 will be outdated in 10 years. You just can‚Äôt win. 
All JavaScript runtimes (browser, NodeJS, rhino, etc) runs an event loop that check for pending tasks. More about this in: https://hackernoon.com/understanding-js-the-event-loop-959beae3ac40
Yes. That‚Äôs exactly what we are talking about. Attach only one event in the global object (window in the browser) and dispatch the function based on the target. No need for libraries. That‚Äôs how React ‚ÄúSynthetic Events‚Äù work
Not necessarily a one way data flow. In vanilla JavaScript is the Developer‚Äôs responsibility to model and enforce the data flow.
Why would they support their crappy unsupported browser?
Udemy course by Andrew Mead is great.
jQuery free is the new gluten free.
I got a new project at work which consisted of creating a Vue.js embeddable widget (via HTML custom element tag) that acceps some props (to configure it from the outside HTML) and uses vuex, axios, local storage.. and the requirement was to have only one .js file and one .css file that you include on the external site which will be using the widget. I had to google a lot how to tweak the webpack cli settings (I'm not advanced in webpack configuration, or in any theoretical knowledge whatsoever) so the results are bundled in a single .js file or how to use [vue-custom-element](https://github.com/karol-f/vue-custom-element) by karol-f if you want to combine it with using store, local storage and stuff. It was a lot of pain until I got it all working, so I created a repository called [Vuidget](https://github.com/DJanoskova/Vuidget) which contains all the needed sources and configuration. I'd love some feedback, as I don't consider myself a "Rockstar developer".
&gt; What polyfills would they need to support IE9+? I don't know what Github specifically uses but here's IE9 support: https://caniuse.com/#compare=ie+8,ie+9 Other useful links (click show obsolete platforms): http://kangax.github.io/compat-table/es5 http://kangax.github.io/compat-table/es6 &gt; What portion of their userbase is using IE8-? Not enough to justify support, apparently. &gt; How sustainable is their code when requiring compliance for (very) old browsers vs flexibility to move to better emergent technologies? It seems they care more about "modern use" than legacy. &gt; How easy is it to hire new coders? How much more weight is added? Money spent? Who the fuck knows. Probably easier, since less polyfills and intricacies need to be handled &gt; Are there security risks for allowing users to use old browsers? Yes. Especially when it comes to things like documents that support CSS. Internet Explorer, for example, is notorious for allowing certain active x directives in certain css properties which allow for arbitrary code execution. Coincidentally, the fact that Reddit has chosen to keep supporting IE9 is why they don't allow certain properties to be used by mods. &gt; Is Microsoft trying to encourage users to upgrade to Edge? No. The dropping of support was announced ages ago, but only people using Github on IE saw it. It was done way before the acquisition, and was planned for months, if not a year or more.
Except MS doesn't actually control Github yet, and Github has been planning this since before the acquisition. But this is reddit, no one cares about reality.
I've never seen someone who knew React but not JavaScript. I'm not even sure how you could know React but not JavaScript. I can understand someone not knowing the document.(whatever) functions, but not the language itself. React is just a better way to manage the way the dom than element manipulation.
&gt;Beware if you have to support internet explorer but are wanting to use async and await calls &gt; &gt;https://caniuse.com/#feat=async-functions Looks like bable should be able to handle it [https://medium.com/@zwacky/add-es7-async-await-support-into-your-non-bleeding-edge-build-process-ad0dded0d002](https://medium.com/@zwacky/add-es7-async-await-support-into-your-non-bleeding-edge-build-process-ad0dded0d002)
Got to agree, I primarily use vanilla JS and have no issues with DOM manipulation. If your HTML is structured well then `querySelectorAll`, `closest` and a simple `forEach` helper function are your best friends.
Why are they so slow? 
So "delegated-events" in the tweet is a pattern, not a library? 
That is correct :) more info here: https://javascript.info/event-delegation
[removed]
I was speaking broadly, but I think you‚Äôre right - React is a toolkit, which requires you to know more about JavaScript, versus Angular which does a lot of heavy lifting for you. But it has been a while since I have delved into the world of tutorials, plugins and extensions, so it‚Äôs hard to say where it lies at the moment (from my perspective). Time for me to dive back in and see what they‚Äôre cranking out nowadays. 
Udemy: The Complete JavaScript Course 2018: Build Real Projects! - Jonas Schmedtmann. I‚Äôm doing it right now, it‚Äôs the best seller for learning JavaScript on Udemy.
An argument could be made that it's very easy to remove polyfills in future, and quite hard to suddenly not use jQuery if you keep writing for it.
Udemy: The Complete JavaScript Course 2018: Build Real Projects! - Jonas Schmedtmann. And there is also one by Andrew Mead also on Udemy. It goes over the theory, the language. And best of all practical examples, so you will create real world applications. If you are struggling for ideas think of it like this. Find a problem and then think of the tools required to solve it. For example an app for learning something like cooking a food? Something cool. Video game, movie, TV show database. Maybe something generic that can be rebranded? Etc...
Windows or macOS installation? I‚Äôm guess you are trying to install on a Mac? It‚Äôs a well known fact that it‚Äôs easier to get it working on windows. I have a Mac I also struggled with the install but I eventually got it working.
If AngularJS was an eye opener you should give React a try. I don't want to be an evangelist but for me React is the best framework by a very long mile, mainly because it's not really a framework (it's a library). However it might feel weird at first as it's way more based on Functional Programming methodologies than OOP, but React is 100% JavaScript without any magic (except JSX which is JavaScript with an XML like syntax to make writing UI more comfortable), do you can integrate it easily into pretty much anything. Obviously you shouldn't try it in your main application but if you do a small pet project in react as a test, with modern tooling I think you could start to see the massive benefits that it brings! It also makes business sense in the long term IMO to use react because Facebook, the react developers use it *heavily*, they depend on it. And it shows, where Angular makes random breaking changes without any upgrade paths (google doesn't really use angular much in their business critical applications) React has a sane deprecation system and they always release automated upgrading tools that work great (they use them themselves). 
Just write a wrapper around it, it's not hard
Start more simply. Learn JavaScript and HTML.
If you are OK with books ‚Äì I‚Äôve written mine with programmers in mind. They are free to read online: http://exploringjs.com
Tribes are dumb: people who deal in absolutes like "never use jquery" and "don't use callbacks in 2018" are either naiive or stupid. Everything a programmer has at their disposal is useful, and it's only through rigorous use of each tool that you can begin to understand the appropriate choices.
`===` is used in JavaScript. You're using Java.
No, just vanilla web components, the custom element part.
Vanilla Web Components, the custom element part.
Sure, I've made some wrappers myself, especially for the Web Worker API. Rather use axios though.
yh seriously if you can‚Äôt figure out how to use es6/7 on ie 
Interesting. I've been using this pattern without actually having a name for it üòä
Callbacks are not dead. Yet. Example practical use of callbacks in 2018: 1. as props in React components (`onClick` etc.) 2. as a pure function used for calculations (e.g. reducer in Redux. Yes, reducer is a callback passed to createStore. The same with `arr.map(callback)` etc.) 3. as arguments to all kind of higher computational abstractions. E.g. promise.then(callback); observable.subscribe(callback) eventEmitter.on(name, callback); dispatch(callback); // Redux with Redux-thunk etc. 4. or dozen of other things... Associating callbacks only with "callback hell" seems just so off. Callbacks are normal building blocks of advanced abstractions. Besides callbacks has a clear advantage over promises/await. They can be triggered multiple times (And a Promise can be resolved only ones). This way callbacks are more similar to observables rather than promises. 
Maybe they should've spent some time on code splitting instead. 98% of their 400kb+ style file is unused on the home page. https://i.imgur.com/B4W9SSN.png
avoid w3schools
How so?
I started getting into state machines a few months ago after seeing Sketch.systems, a mini-app for modelling state relationships from the Subform team. I‚Äôm a designer. Last year really pushed design into thinking in terms of systems and related components, but mostly only through a hierarchy of inheritance: lower order components (like icons) being consumed by higher order components (like buttons). A lot of the work these days is essentially ‚Äúcomponent design‚Äù, where instead of delivering big layouts for engineers to slice down and interpret into components, the designers themselves are delivering those components and making design decisions on a component level. One of the harder parts of that is identifying states and designing state transitions. What are this component‚Äôs states, what transitions are available at each stage, and what would cause each transition to occur while in a given state? In that space, state machines are a huge opportunity to give designers a way of thinking about state without using code. They‚Äôre easy to express in code (xState, etc) but they‚Äôre also human readable: easy to diagram, talk about, test and iterate over, just on a whiteboard. And they‚Äôre ultimately easier for developers to interpret and estimate against. They‚Äôre great for designers!
The point of transpilation is that you get new syntax to be turned into old-browser understandable code. Polyfills take care about making the Browser API available for old browsers. You can see a full list here: https://polyfill.io/v2/docs/features/ Of course older browsers can't run my source code, which is why I use polyfills AND transpilation. Apps usually need less polyfills/transpilation, because they run in their own app context, where you can partially define your own environment - e.g. via Electron - which is built on top of chromium.
I don't understand the downvotes frankly, it's a slightly verbose syntax sure but not particularly unergonomic and very simple. JavaScript developers often seem to confuse concision with elegance.
Not possible.
In modern JS engines, a `WeakSet` can be used to ensure that instances get garbage collected. const towns = new WeakSet(); class Town { constructor(name) { this.name = name; towns.add(this); } } const pleasantville = new Town('Pleasantville'); towns.length; // amount of Town instances towns.has(pleasantville); // true towns.delete(pleasantville); towns.has(pleasantville); // false towns.clear(); // empties the entire towns list A WeakSet can only contain distinct objects, and will free an object up for garbage collection if there are no longer any references to it. [MDN docs on WeakSet](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/WeakSet)
would you recommend reading Speaking Javascript first or diving right into ES6?
By using ajax whether it work
You can't do this without either posting the entire page or creating an endpoint for ajax.
Exactly, thr question directly before being "or do you serve different versions... etc" Are tou seriously trying to explain to me what the question I myself wrote mean? :-)
Or use an established wrapper around it. Like the fetch polyfill.
That‚Äôs half of the fun. 
Thanks for answering /u/kenman whats the reason?
True that. Without a challenge then what‚Äôs the point.
Sure, callbacks won‚Äôt ever be dead. This article is only about callbacks as a way of dealing with asynchronicity. Async/await just gives us a way to separate the code that implements asynchronicity via callbacks and promises from the code that implements the logic making the latter way easier to understand.
Yeah, Microsoft is a joke, dropping support for their own products. Visual Studio and Edge don't even support Windows 95.
Worse to short term gain than long term gain for the better, sometimes.
They have 400kb of css...? What the actual fuck
Speaking JS is probably better, because it starts at the beginning. As an experienced programmer, you can probably pick topics that interst you, via the TOC, and skip/postpone a lot.
I have a good example in the spirit of your iPodd: My old [Sansa](https://www.sandisk.com/home/mp3-players/clip-sport-plus). Tiny enough to fit in a pocket with other stuff, a real headphone jack, charges really fast, hard buttons so I don't have to take it out and look at it to use it, takes a micro-sd card so I can have multiple cards with multiple music libraries, FM tuner. It does the job better then the multiple generations of iPod Nano I went through before Apple dropped that line. Sure it can't connect to wifi or anything, but for doing the "old job" of playing my music library it's still the best portable device I own for the task. I've had a Sansa since before I ever got the first gen Nano (and I got every generation nano because I was tied to iTunes). I have a newer one now, but I only got that because I thought I had lost the old one (it was in a backpack in a closet). jQuery is like that - for specific use cases it's still pretty damned capable. One such case is when I run into a site with it loaded that I want to scrape, it's easy to whip up something on the console using the old familiar tools. I've done exactly that many times for fellow moderators here on Reddit - tabulating /r/GifTournament results for example. 
Here's a sneak peek of /r/GifTournament using the [top posts](https://np.reddit.com/r/GifTournament/top/?sort=top&amp;t=year) of the year! \#1: [What you've all been waiting for.... The round themes for Gif Tournament 9](https://i.imgur.com/zWCVl3s.gifv) | [43 comments](https://np.reddit.com/r/GifTournament/comments/7iuvd4/what_youve_all_been_waiting_for_the_round_themes/) \#2: [Gif Tournament IX themes will be announced tomorrow](https://i.imgur.com/hFGwuCS.gifv) | [7 comments](https://np.reddit.com/r/GifTournament/comments/7ir595/gif_tournament_ix_themes_will_be_announced/) \#3: [IX](https://i.imgur.com/FK7EnrE.gifv) | [18 comments](https://np.reddit.com/r/GifTournament/comments/7h5wba/ix/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/8wfgsm/blacklist/)
I had issues too. Windows was easy enough, Ubuntu server was easier, OS X not quite so easy (maybe this is where some of the undue Mongo hate springs from, I dunno). Back to the OP's question, everyone's just about covered the local dev stuff. With regards to mongo, 1 thing I recall that stumped me for a while was actually connecting to the server for the first time - it's like riding a bike in that you'll do it once and never forget how to fix any of the problems you come across. The default mongo install does provide a web-GUI that's OK for administration, but even better is a tool like robomongo (https://robomongo.org/) that's now known as Robo 3T that's visual and is very easy to work with (it's a viewer for your database, and you can run queries against it using the tool). If you need any help getting setup, just reply with some specific issues you're having and error messages and I'll also do what I can to assist.
It has all you need to track it yourself though, in the body stream you can read off the transfered bytes, in a post you can read the original size from the file in the get you can read the full size from the stream. Few lines of code and you can have progress updates quite easily.
Don't use TypeScript `module`, it's deprecated already. You should put your interfaces / classes in TypeScript files, for example `IAccounts` interface and `Accounts` class in `accounts.ts`, then in another file you can do `import { IAccounts, Accounts } from './accounts'`.
Fetch is built on promises, which are es2015
asynchronicity is not a point. These things need you to use some kind of callbacks for dealing with asynchronicity: - Promises - Observables - EventEmitters - React components (e.g. onClick) etc. These things allow you to skip callbacks: - async/await - generators - tricks like "throwing a promise" (React Suspension style) etc. And I think the real power of async/await lies not in the removing callbacks or Promises from the equation, but that you can write await everywhere, like in the middle of expression `console.log(await a + await + b);`(though I rarely use async/await myself). I also think that the real power of generators lies not in the removing callbacks, but that they allow you to pause and resume functions, and allow you for more control (and people can make libraries like Redux Saga using generators). I also think that plain old callbacks, though have uglier syntax are in some way more powerful than async/await because they can be "resolved" multiple times and you have subscribe to whole stream of values. It's some kind of "poor man's observable".
I'm guessing it depends on how complex your app is. Personally I think they seem like the ideal way to model UX flow clearly, but at this point I don't think I could justify making the jump, given that I'm much more familiar with the standard Redux pattern.
Nice. So there's no way to compile classes and interfaces together in one encapsulation?
I have already have some JS knowledge, but wanting to improve it. Do you still recommend speakingJS or could I just go with ExploringES6?
If you don't have to support ie there is no piece of jQuery that you can't do as easily in native js
You can put your class and interface in two separate file, or put them in the same file. It's up to you. You can use a build tool such as webpack to generate only one JS file that contains all your code, or change the webpack configuration to split the generated JS files into many files based on your own criteria.
10 years? I wish... Try 10 months
There's a lot of overlap - i.e the view listens for changes in state. State machines additionally describe graphs of state and enforce rules governing the transitions between nodes on that graph - i.e you cannot just change values without first meeting conditions. Of course, you can do this in your reducers anyway, but it's a more concrete abstraction that forces you to think in terms of possible states, rather than mushing responses into the state tree.
I don't know what "easier" means for you, but for me, verbosity of syntax is a major part of it, between `document.querySelectorAll("#someDiv")` and `$("#someDiv")`, I for one will surely choose the latter!
Enjoy your 100kb dependency to save 15 characters
While your question may be relevant to you, it's not particularly relevant to the rest of the subreddit and probably belongs much better in /r/LearnJavascript.
I would agree if OS companies (mobile ones especially (I mean Apple specifically...)) cared about keeping all their devices up to date as possible.
What if they used a CDN?
I mostly agree, but there are places where async is still useful. Recently I needed a service that would make a bunch of network requests, and I wanted to just make sure to keep the concurrency reasonable and maybe a little throttling. Without async, I would have had to do a whole bunch of annoying work grouping together a bunch of request promises and then running like ... await Promise.all(networkRequests, generateTimeoutPromise(throttleMinTimePerBatch)) inside of a loop. Gross.
&gt; jQuery was a solution the cross-browser problem of the '00s. jQuery is still a solution to the cross-browser problem of the '10s. I do agree that modern browser got better, but modern browser companies did not, especially Apple. Still 14% of Apple users have an outdated Safari, and we can't blame them not wanting to buy new iPads or iPhones, but we can blame Apple not maintaining Safari.
Yeah with http2 no need to bundle anymore. 
According to the tweet, removing jQuery has been a process that's been going on for years so this decision was made before Microsoft bought them 
Is there an example somewhere? Conceptually it makes sense, but I've yet to hear anyone (other than yourself) say that it's possible. It would make for a good blog post.
I've only recently gotten into web design, so all I've used is fetch()! At one point I looked into how to do requests without it and was like "good god, that looks like a pain in the ass"
Yeah, exactly. It‚Äôs not part of ES2015. Using part of the language and being part of the language are very different, and it‚Äôd be stupid to double down and try and claim it‚Äôs the same. 
If Microsoft won't even support IE, that's enough reason for me to be firm with every potential client that I won't support IE.
Enjoy your 800kb of extra load when you have to repeat those 15 characters several times in various parts of your code!
... and the () =&gt; {} for?
Listen for the `keydown` event of the `window` object. Do it before any other scripts.
I found it on SO, some guy was looking for a progress tracking for GET, I just updated the code slightly to hook it to my POST, for the post you need to read the file size from the file, but the progress is available in the stream. It updates randomly so its most testable with files at least a few mb in size. Did it about 6/7 weeks ago at my previous job, cant for the life of me recall in which file the code is in.
No, because actual function call is runtime matter, not syntax matter. But you can, and i think this is the path you want to take, have rule no-unused-vars.
The most common way is camelCase, like I said
It was not tested for JSX. That's what the case is. Future releases would make it better.
Lots of bold
I tried swapping ajax with fetch in a project but found it handles post variables in an abysmal way. Passing arrays seemed like a major PITA.
I think you mean in pre-transpilation.
Perception is reality
No, your shitty circlejerk isn't actual perception. Get some glasses.
Even without, no need to bundle.
Expressing `clickUp()` and `clickDown()` as functions acting on a parameter `n` whose value would be the current number of items of the given product to be added to an order, these will only return values between 0 and 3 as appropriate: clickUp = n =&gt; { return (n &gt;= 0 &amp;&amp; n &lt;= 2) ? (n + 1) : (n &lt; 0 ? 0 : 3); }; clickDown = n =&gt; { return (n &gt;= 1 &amp;&amp; n &lt;= 3) ? (n - 1) : (n &lt;= 0 ? 0 : 3); }; Alternatively, a looping counter removes the hassle of dealing with separate functions, given the small range over which the counter operates: clickLoop = n =&gt; { return (n + 1) % 4; };
the question is more about how to keep your code dry, not how much I should test :P
are you sure about this? you are talking about functions only used with programmer input correct? my problem is how do you know that will always be the case? how do you know that you will never use that function wrong?
Sorry, what I meant is that I want something (could be ESLint or another program) to make sure that a file has written this inside of it: registerFixture(); Do I need ESLint or some kind of compiler/transpiler/whatever?
Actually you do for performance. Http2 multiplexes the request in one tcp stream which makes it fast. In a way it's bundling by requesting assets in the same tcp connection. With http2 each request is a new tcp connection. And with how tcp works it has a slow start algorithm and so more connections slow it right down.
&gt;The huge deal is just about this toxic and irrational hatred towards jquery, nothing else! I don't understand why people seem to think jQuery is hated. It's not. jQuery **was** fantastic! But, the reason it existed isn't a reason to exist anymore. Everything it did for us can be done with native functionality that didn't exist when jQuery was created. What people hate is that some people refuse to learn new standards that have been out for over half a decade and claim jQuery is still needed. Nobody likes people in the office who hold back progress for superstitions.
You should be unit and integration testing the components that use that function too. If you used it wrong, your test will fail.
&gt;Enjoy your 800kb of extra load when you have to repeat those 15 characters several times in various parts of your code! If you are doing those 15 characters 53,333 times in a single page, then you need to find a new fucking career.
None of what you said requires bundling of resources. All it requires is correctly splitting up resources.
I'd love to give my 2 cents on keeping your code dry, but I feel the question is not specific enough. Can you elaborate? You want to keep validation code DRY, that's what you're asking?
The biggest blow comes in the end: "What did we replace it with? No framework whatsoever". Vanilla has come far far ahead, and I was waiting for someone to call "The king is naked" in this decade of frameworks, honestly.
Not sure I follow what you're trying to say? Resources normally start off unbundled. So why would you split a bundle and not just instead not use bundles?
I am sure, at some point jQuery or some other library will displace the native features of the language or extend them in a way that makes itself essential to development again. It is only a matter of time, everything is cyclical.
[https://github.com/Tvde1/object-autocorrect](https://github.com/Tvde1/object-autocorrect) If this isn't the most javascript-y thing I have ever made
yes, its eslint's rule https://eslint.org/docs/rules/no-unused-vars . Because function is variable too. (you might have to write functions as `var f = function(){}`)
You could use babel or \[insert JS parser like acorn or esprima] to traverse the AST and check if a module contains a function call where the callee is the identifier `registerFixture` and otherwise throw an error. This of course needs to be integrated into the build process. This is a syntactic check which means it can be tricked by e.g. the following: registerFixture = () =&gt; {}; registerFixture(); (Unless you check that such assignment never happens ‚Ä¶ you'll end up in a rabbit hole very quickly) 
I'm saying even without http2 bundling is not a necessity.
Literally the first sentence in the wiki entry claims that currying is the transformation from the nary to the nth order form which is what I was claiming all along. I don't see a sentence in that article that supports the idea that function written in the nth order form is curried if it wasn't transformed by currying. 
But it is for performance.
So, does it contradict to what‚Äôs written in the article? I think I‚Äôve lost the point. 
Yup. That‚Äôs where I‚Äôm at. My last job ran a report, and the most-used browser was IE 9. The third most used? I‚Äôm not even making this up: IE 7. We rewrote the whole thing in Angular 6 and were like, ‚ÄúYeah, those won‚Äôt work any more.‚Äù Literally millions of users were pissed that we wanted them to upgrade their browser from 2006! It‚Äôs been a good 12 years, I‚Äôm sure. But it‚Äôs time to upgrade.
This makes me wonder: where did the term _polyfill_ come from? I know what it means and whatnot, but I'm curious what the first feature that was a "polyfill" was.
It's a bot
Yes! I have ‚ÄújQuery‚Äù in my apps, but I call them my q‚Äôs: const q = ele =&gt; document.querySelectorAll(ele) const qi = is =&gt; document.getElementById(I‚Äôd) const qc = cls =&gt; document.getElementsByClass(cls) Pretty much always have these in everything I build.
Not if you effectively split up your resources to only fetch what is needed per page.
[removed]
Any of Kyle Simpson's (gedit on GitHub) repos are worth a look!
People are weird about their legacy stuff. With one of my freelance clients, I had to write in-house extensions for someone who still used XP. He didn't upgrade from it to Vista because Vista sucked, he didn't switch to 7 because he liked XP's UI more, he didn't upgrade to 8 because he *really* hated 8's UI, and didn't upgrade to 10 because he was privacy-paranoid and concerned that Windows 10 was going to sell all of his secrets. I was left writing extensions for Pale Moon *(because he didn't like the direction Firefox ended up taking)* running on Windows XP.
jQuery's mission is done. I loved it when I was developing for the era of pngfix.js. There is a difference between attachEvent and addEventListener; querySelector was non-existent that you need to do document.getElementsByTagName and do a loop; CSS positioning was so inconsistent across browsers you needed to use JavaScript to calculate positions but there were differences between all these clientHeight vs offsetHeight vs scrollHeight vs whatever height IE had to offer. It was a good tool and saved me tons of time. Now there are better tools, but I must salute what jQuery had done and how much time it had saved me for the last decade.
You're overly mad about this. Breathe.
You mean Apple, which forces updates to their users even if it's known to turn the phone into a brick?
It is a noob question probably, how did you find that coverage?
I'm not "overly mad" about one thing. I don't like negativity circlejerks that are highly unwarranted (at least as of now), so I'm calling it out like the bullshit it is. Not to mention the claim was literally factually incorrect.
I find reactiflux's typescript channel to be a bit more active
 No they were logged in users. And yeah, people are ridiculous. I mean, I understand to a point, because some people just aren‚Äôt good with computers, so when you get to a point where you know how to do everything, change is actually scary. These people use computers for their job, so they‚Äôre thinking that they don‚Äôt want to waste time on the job trying to figure out how to work a computer again. But I feel like after 12 years, maybe it‚Äôs time. Haha
Okay cool thanks
If that's literally your only complaint on it, just use a lambda. `$ = (ele) =&gt; document.querySelectorAll(ele)`
If you are doing Mac try doing it using homebrew
I‚Äôm on Windows :(
https://www.vojtechruzicka.com/measuring-javascript-and-css-coverage-with-google-chrome-developer-tools/
I don't think you understand. Each request outside of http2 forms a new tcp connection. Tcp uses a slow start algorithm so that means it starts off slow. Those extra slow connections are going to kill performance. With http2 it doesn't make new tcp connections but bundles the requests in the same tcp connection. 
You mean like this? Or am I misunderstanding ```javascript fetch('/api/...', { method: 'POST', body: JSON.stringify({ key: 'val' }) }) ```
&gt; I think I‚Äôve lost the point. Callbacks are just functions you pass to another functions. &gt; does it contradict what‚Äôs written in the article? This article says that instead of standard EventEmitter (with some additional cleanup code) you should write some hacky code which will replace callbacks with promises using hand made function, then call Promise.race and then try/catch and put bunch of ifs . I think it's overengineered at best. Although good proof of concept. But I think something in the very beginning of the code was wrong. All this removeListeners juggling (why not to just create new EE?). I think the interaction between this module and the rest of application was badly designed. Though this article doesn't show all the code anyway so I can only imagine. Maybe EventEmitter was not a right abstraction but why to wrap it in promises and then try/catch it instead of getting design right? 
Ramda is quite interesting to read. They also have some other interesting repos, such as ramda-fantasy or ramda-repl, but it's better to start from ramda first. Even if they are somewhat older codebases, jQuery's code is still interesting to read. If not the details, at least the core and general approach. And Zepto can be interesting too, as a way to compare approaches. HyperApp is... maybe a curiosity. The code itself doesn't appear _that_ interesting, but it is a nice example of how to keep a codebase small and focused and how you can do quite a lot with not that much. It is also interesting to compare the current version with the upcoming version 2 (in the V2 branch).
&gt; Ever hear of ES2015? Yep.
I don‚Äôt know any business that stops supporting millions of users so they could rewrite the front end and lose $. 
Yes, I know this, but I don't understand the relevance to bundling considering client side caches and cost per person is already low, sharing the same tcp connection won't be that much of an improvement for most sites.
It's not noob, never be ashamed to ask.
I don't remember off the top of my head, it just seems every time I go to use it, it doesn't support some thing that I need.
for namespaces?
You probably know this, but if selectors is all you need, then you can save quite a few bytes by swapping jQuery for sizzle.
It might be a scandinavian term. We use polyfill/polyfylla to fill holes in walls. 
Well they won't lose money, because the people *have* to use the site for their job. It's mandatory. And the people themselves aren't the ones that pay for the product: their employer is. So they aren't losing any clients or money.
let's say you have a server with /page/1 req.params.pageId === 1 now we have the function that handles the route /page/pageId the optimal flow(for performance) would be to check right away if it is valid and throw if it isn't before proceeding to other functions. what if we then have to call 3 asynchronous functions(with the parameter page id) in parallel after validating that the page id is valid. Should those 3 functions test that the page id is valid too?
make sense... what about the example in my other comment tho? how would you test for a user.login(username, password) function if in integration it is always used in a route where the parameters are already validated?
Its not just that, the thing is that I'm pretty much habitual to the jquery way of things? For instance, this is what I do at the beginning of almost all my javascript apps: $(document).load(function(){ //custom code }); And this is what I do when I want to do some quick get or post: $.get("/somedirectory", function(data){ //do stuff with data. }); And this is how I'm used to map my JS events: $("#mybutton").click(function(){ //do some stuff }); Now, whilst its possible to replace all of this with your own lambdas or functions, but then you'd be inventing your own jquery, isn't it? So, why not just use the canonical one?
Backbone might be considered ‚Äúdated‚Äù by some but it‚Äôs a solid library and has clean source code, they also have an annotated source on their website. http://backbonejs.org/docs/backbone.html
Yeah, you care too much about this
Let med know of you can think of any. It would be interesting to hear.
Thanks!
Thanks!!
Callbacks are just functions you pass to another functions. - Exactly. As I sad before, I don‚Äôt imply that we should never use callbacks. Perhaps, I should have stated it more clearly in the article. About wrapping EventEmitter in promises - the whole idea is to describe a flow (a sequence of events) in your code. For me it makes it easier understand what the code does exactly, especially for a developer who wasn‚Äôt the author of the code. I think, it‚Äôs worth using one hand made function. But maybe I‚Äôm missing something about using callbacks in asynchronous code. What would be a correct design with callbacks here?
Probably. Just skip generously in that book.
Habitual is pretty much the worst reason to give for why you refuse to adopt modern best practice.
Another option, if you are willing to wait a little (it‚Äôll be finished soon): 
Yeah, it's bugging me because I just ran into something not that long ago. I can't for the life of me remember though. However while we're on the topic, one thing that kind of annoys me about fetch is the verbose response chain. You have to first await a response, and then await the body. Pretty much every other library does this in one step.
Just trolling: Try to input your github username -&gt; [https://github.com/baumannzone/awesomico-css](https://github.com/baumannzone/awesomico-css) 
Some things are good sometimes 
Why not test your hypothesis? Why not try to consider the amount of a performance gain relative to other changes you could make to your program? For example, it could be that there would be a performance gain but most code isn‚Äôt passing arbitrary types around and so the vast majority of the time plain JavaScript is still allowing for correct branch prediction. It could be, alternatively, that even in the face of failed predictions that the performance gain is negligible.
To be honest I can't remember a of what I tried, but when my POST request was interpereted by PHP it did not work with something like $_POST['values'][0...]. I was trying to use it as a drop-in replacement, but it didn't play well with what I had set up already.
Can you give an example of a problem you‚Äôre trying to solve?
It's super easy to write a single wrapper function around it to return what you actually want. It is built this way because not all HTTP requests are meant to return JSON, so they give you lower level control over your requests. If you only want to return JSON, just write a function (or use a library like you said): ``` function request(url, options) { return fetch(url, options) .then(response =&gt; { return response.json() }) }
I read this four times and I still don't understand it.
I have an application built with CRA running in prod, and I support IE11. My polyfills are: * Set * Array.prototype.find * Array.prototype.includes * Array.from * String.prototype.includes * String.prototype.endsWith * Intl * Number.isNaN They are served based on feature detection. Only about 6% of my users run IE.
&gt; We use polyfill/polyfylla to fill holes in walls. Yes that‚Äôs exactly it. But it was first coined by a British guy (we also have Polyfilla here too). See https://en.m.wikipedia.org/wiki/Polyfill_(programming)
I personally think the API for passing through parameters and such is a lot saner in Axios.
&gt; https://twitter.com/rauschma/status/1013517348991586305 Will that be late 2018 or 2019? I am thinking about just skimming through SpeakingJS for now, on areas I am not too great with. Then move onto ExploringES6.
This is silly, pretty much everything you mention like ‚Äúselecting more than intended‚Äù can be done just as easily by incompetent devs using vanilla JS. 
Before you make an assumption like that. Do some measurements. Most of your assumptions are wrong.
You don‚Äôt always need to ‚Äúmanage‚Äù state. Often you just want to click a button and have it do the same thing every time (eg a calculator).
Thank you. :)
You're trying to solve the problem in the wrong place. You should look for a solution within your test framework. Specifically, look for setup and teardown. 
Erg,... How to put this. You need to reset how you think about programming. You are in a far more chaotic land. Your code looks like a Java App someone put through a converter. Sit through this video series : https://www.youtube.com/playlist?list=PL62E185BB8577B63D 
I think that may be because I‚Äôm using ES6 which makes it very easy to do this right?
It can, but my point is that other frameworks often don't have that problem because you're only operating on a localized component instead of having the entire DOM at your disposal.
Hi /u/yarivUX, For javascript help, please visit /r/LearnJavascript. Thank you!
You‚Äôve repeated yourself. We get it. We know how http2 works. If the packages are sufficiently small and minimal, you don‚Äôt need to bundle with 1.1, though. If you had 100s, sure, but most apps will have 10s, and you get all the benefits of caching.
First question I ask before joining a site is if they serve a jquery free version. If no I'm out the door. 
Thats part of it but not wholly why. You are using only the features that match classical OOP. You arent using `import` anywhere and all but one function are attached to classes. SingleCardDistribution.js exemplifies this. Here is what code looks like if you go way in the other direction : https://github.com/SalvationDevelopment/YGOPro-Salvation-Server/blob/master/src/engine_manual.js
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [SalvationDevelopment/YGOPro-Salvation-Server/.../**engine_manual.js** (master ‚Üí bb0cb6d)](https://github.com/SalvationDevelopment/YGOPro-Salvation-Server/blob/bb0cb6d6073a0a035bb6097629b3d33a444a311b/src/engine_manual.js) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply e32msug.)
the import and export is the very next thing that I will be adding to this.
Since you claim that the measurements are vastly different than what I am reasonably assuming, may you please point to something that proves me wrong? I don't have the ability to conduct a massive wide scale test.
&gt; For instance, this is what I do at the beginning of almost all my javascript apps: &gt; &gt; $(document).ready(function(){ &gt; //custom code &gt; }); This is bad, even in jQuery. Stop it. Put your code at the bottom of your damn project. 
I don't understand this feedback (also, I didn't look at the video). Is it just 'cause OP said 'factory' a lot?
facts
No, its because of the way the functions are organized onto objects and the general state management. 
Github's website is not a great example of a large JavaScript application. Sure it has many pages with sprinkled JS functionality, but in its essence it's still server rendered using Pjax (a TurboLinks like library). I think it uses Ruby on Rails server side, but I'm not completely sure about that. Anything big will use some kind of framework or library. Google for example uses its own [Closure library](https://developers.google.com/closure/library/) for Docs, Maps, etc. Apple uses D3 for online iWork, Ember for Apple Music, etc. Not sure what Microsoft uses for Office 365, probably something of their own too.
http://youmightnotneedjquery.com I just stripped it out of a project that for the most part, looked like the author didn't know much about JavaScript. Initial speed: 200 MS for 10 nodes, 50 edges, without jQuery.each loops: 20ms 100 nodes 500 edges just to get the profiling to register before it completed. IMO it's a crutch that's no longer needed.
His username is getify, fwiw. Gedit is so close it took me a minute to figure out what wasn‚Äôt right about it! [](https://github.com/getify)
Yea, just that version of Safari for macOS and iOS. I thought there was a version of Opera, too, but I guess not. https://caniuse.com/#feat=es6-module The thing is that that is the latest version of the browser for iOS 10, which is only last year's OS. Too recent for comfort for me without writing a good fallback.
Weird. Don't think I've ever used it with a php server so can't say
I understand lots of unique event handlers can increase memory usage, but how does this effect performance of the event loop? DOM events are dispatched even if there is no handler, just nothing is pushed to the call stack.
Great selection, thanks! I think it's valuable to include the curiosities and older codebases as well to see how it was done. Makes it interesting to dive into the *why* behind those decisions as well. I'll be adding those in!
Because the existing one also provides a ton of stuff you don't need. Implementing what you need is trivial with language builtins, so why send 80kb extra down the wire, 70kb of which you don't even use? You get literally all that functionality built in. Document.ready? `document.addEventListener("DOMContentLoaded", (e)=&gt;{...})`. Fetch and promises are just as good as the jQuery method, especially with a thin wrapper.
It actually works on my side (with chrome). Are you sure that your .js is in the good directory ? Do not forget to have a consistent coding-style ; you've forgotten the semicolon at the end of two functions.
Good call! I'm a big fan of the way backbone's docs are structured. Similar to [underscore's annotated source](https://underscorejs.org/docs/underscore.html), it's very helpful for reading through it.
Me too. When looking for a new job, first thing I ask is what medical insurance they have so I can research the provider. If I find out the medical provider uses jQuery on their website then I won't even consider the job. I figure any employer that would choose a medical insurance where the provider uses jQuery is too out of sync with reality to be a good fit for me. Come on, get with the times, duh. 
I have no idea. That sounds like a nightmare. Usually what that means is some confident developer created the 101st JavaScript framework just for their site. However maybe a better question is, are there any large single page applications that don‚Äôt use a JavaScript framework? I‚Äôl bet there are lots of apps that use micro-libraries but don‚Äôt choose to use a framework like React, angular, or ember. Seems terrifying to roll your own router, but I guess everything started out as vanilla js. 
&gt; How easy is it to hire new coders? I'm pretty sure any developer would be glad not to support `Internet Exploder`.
&gt; but in its essence it's still server rendered Are you saying that it's not a large Javascript app, because it's rendered on the server? Why cannot a server rendered app be large Javascript app? Closure Library has a nice concept of renderer and decorator on its components. The former renders on the client side, the latter makes server rendered html come to life as a component--this is what you call sprinkling Javascript. Features of Github and Gitlab are almost in par. Gitlab is now moving to Vue. Does that make Gitlab a large Javascript application, but not Github?
&gt; Seems terrifying to roll your own router They do not use a client side router, IMO that is good. Like another comment here suggested, they may use Pjax, but Pjax is based on jQuery and jQuery is removed from Github.
Yes, finally! I'm so tired of people supporting this kind of cruft. When my grandfather was in the hospital, they had him hooked up to a device for his pacemaker that was made by a corporation that uses jQuery not only on their public-facing site but also on all the admin dashboards for both the device and the hospital staff computers. I immediately asked to speak with a doctor when I found out and asked them to take him off of that machine. He ended up passing away shortly after but at least he didn't have to be attached to that tainted system for long.
Ugh, mobile safari is the worst. Safari is basically the new IE.
I'm just learning about Tensorflow and after looking at your source code, it looks like you're only using `flatten` and `dense` layers. Is there a reason you decided to not use convolution layers or down sampling with max pooling layers? Maybe I missed the other layers somewhere, but just curious and trying to learn.
I‚Äôm not sure that jQuery solves any of the issues caused the features Safari lacks right now.
Amazing initiative! As someone who learned to code by himself, this will be invaluable 
I think the issue was that everyone and their mother wrote a wrapper to handle requests with XHR, whereas you can use fetch out-of-the-box. Just like you *can* implement something using a ton of callbacks, and it‚Äôs not *difficult* to do so, but promises and async/await just makes it easier.
What are your requirements? Sure...building out a table with cells that contain the days of the week is one thing...but I could see this getting REALLY gnarly as you add more and more. What I‚Äôm getting at is, if this is all you‚Äôre doing, go for it. This isn‚Äôt hard to figure out. But if the responsibility gets larger than simply building a table with the days of the week, it‚Äôs going to get convoluted fast. 
What's the point of website with offline access? You can run in bunch of problems with service workers which author doesn't mention. Ie. Upgrading service woker can be pain in the ass.
What do you feel is working with state and in an object in the provided solution?
The solution you supplied has a class with over 1000 lines of code? Im asking for best practices, do you feel that javascript is exempt from best practices? Just because it is a loosely typed language doesnt mean it should be obfuscated and not adhering to any principles.
MS is a heavy user of React with MobX for state management within Office 365. I‚Äôm sure that‚Äôs part of the reason they released such a badass editor in VSCode. Plus they invented TypeScipt, so there‚Äôs that. 
Gedit is the text editor that comes default on gnome :)
It's basically a report in Calendar format, so there won't be any CRUD functionality tied to it. I'll be color coding entries in date blocks based on certain field values.
Not the guy you were replying to, but combining/concatenating scripts and style sheets was an accepted ‚Äúbest practice‚Äù until SPDY and http/2 came along. Here‚Äôs a few old links I was able to dig up: https://hacks.mozilla.org/2012/12/fantastic-front-end-performance-part-1-concatenate-compress-cache-a-node-js-holiday-season-part-4/ https://developers.google.com/web/fundamentals/performance/get-started/httprequests-5 https://developer.yahoo.com/performance/rules.html?guccounter=1 https://www.w3.org/Protocols/HTTP-NG/http-prob.html https://blog.cloudflare.com/combining-javascript-css-a-better-way/ 
Yeah. This tool is everywhere. Atlassian has a product called Crucible. Microsoft has Team Foundation Server. There‚Äôs others also that are free. 
Thank you!
Not binary per-se, but: http://bl.ocks.org/robschmuecker/7880033
I've never used Axios, but I can imagine how it could be more straight forward. When they announced `fetch()` as a better API to replace XmlHttpRequest is was expecting a lot more honestly. Gonna check out Axios next time I'm dealing with fetch directly.
That program is doing something with similar concept types (cards) and way more user cases to deal with. My point is that your program is to chopped up in a bunch of tiny pieces that takes jumping around to understand. You shouldnt need a state of the art IDE to guide you around the program. That might be ok in a more corporate setting but when reviewing online it just makes people not want to look at the code and makes it confusing. Additionally when its running in the browser and you are debugging it you wont have that luxury to find references. You have to use a search that is limited to the file. When I open the index file I see a long list of files I need to go and read and then come back and I wont understand how they relate to each other until I've finished everything else. I cant just read the code like a book and get a concept of what objects/struts its working with and how they flow through the system. I cant skip over things that have been "well abstracted". The given file I've used to teach students JS, by having them start at the top and read back their understanding of the codebase. What I learned in that process and then also in my professional career is that the body of people coming from JS and PHP as their first languages are very results oriented and have less patience. Their code is messy and minimum. People coming from C# and Java, I tend to notice a pattern of over abstraction and in extreme cases direct attempts to bend the language. Which I think is what you've done here. Here is a random file out of jquery : https://github.com/jquery/jquery/blob/master/src/manipulation.js Backbone.js is just a long file... https://github.com/jashkenas/backbone/blob/master/backbone.js then there is prototype... https://github.com/prototypejs/prototype/blob/master/src/prototype/dom/form.js https://github.com/pzuraq/ember.js/tree/master/packages/ember-runtime/lib/system Ember is smaller but notice everything is in the core object. 
GayQuery has been obsolete for years.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [prototypejs/prototype/.../**form.js** (master ‚Üí dee2f7d)](https://github.com/prototypejs/prototype/blob/dee2f7d8611248abce81287e1be4156011953c90/src/prototype/dom/form.js) * [jashkenas/backbone/.../**backbone.js** (master ‚Üí 27f7d41)](https://github.com/jashkenas/backbone/blob/27f7d41de1f64f6662a96f44531d7518953b1e07/backbone.js) * [jquery/jquery/.../**manipulation.js** (master ‚Üí 979809c)](https://github.com/jquery/jquery/blob/979809c5a80aaf26bf7e3406a2e361e809f9b132/src/manipulation.js) * [pzuraq/ember.js/.../**system** (master ‚Üí 38e9c89)](https://github.com/pzuraq/ember.js/tree/38e9c8965347e94ae9a081794cf2b5dcc0e8f978/packages/ember-runtime/lib/system) ---- 
Thanks for sharing your open source project, but it looks like you haven't specified a license. &gt; When you make a creative work (which includes code), the work is under exclusive copyright by default. Unless you include a license that specifies otherwise, nobody else can use, copy, distribute, or modify your work without being at risk of take-downs, shake-downs, or litigation. Once the work has other contributors (each a copyright holder), ‚Äúnobody‚Äù starts including you. [choosealicense.com](https://choosealicense.com/) is a great resource to learn about open source software licensing. 
There's nothing about an if statement that will prevent an alert or anything else from working, if it's not working there is some other problem with your code. Don't forget to open the js console in dev tools to see if you have runtime errors.
Explain the construction of a player and how they know their score to me.
If I have to explain it then I‚Äôve failed in not making it expressive enough but once I get home I‚Äôll sit down and explain what it does. 
well, yes. just like how C sets you up for a lot of bugs that Rust makes nearly impossible. you can jettison all nuance by calling it "bad", but that was your decision.
If your using the editors in Chrome, then it's still Chrome rendering it so it's not the issue. If your dragging the file into your browser and not using a server then it's most likely the path to `test.js` is incorrect. When your just viewing a HTML file in s browser, the path to files will be the absolute to the file on your computer. So if your test.js file is on your desktop, you would need to use the path for the desktop for example.
You may have needed to specify content type. headers: { "Content-Type": "application/json" }
It was recently added to Chrome dev tools. Only learned about it a couple of days ago myself. It's very handy because it actually highlights the unused code so you can go through and eliminate it.
Awesome, I am also learning myself! The actual training code leans heavily on the TFJS examples, in particular this code related to training (https://github.com/tensorflow/tfjs-examples/blob/master/webcam-transfer-learning/index.js#L72). The images you upload get run through a pretrained model, which by default is MobileNet (more info on that here https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md). So the code you see is only working on the activated output from the pretrained model. This makes training feasible in the browser, whereas if you tried to train from scratch it'd take a lot more compute power. Though if you do want to do that, like if you're working in Node, I set up the tool to accept a custom training model (https://github.com/thekevinscott/ml-classifier#parameters) too. I'm also learning and happy to hear about better approaches (or even better, accept PRs! :D ) 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [tensorflow/models/.../**mobilenet_v1.md** (master ‚Üí 2d7a0d6)](https://github.com/tensorflow/models/blob/2d7a0d6abba764b768d645947014492ade492385/research/slim/nets/mobilenet_v1.md) * [tensorflow/tfjs-examples/.../**index.js#L72** (master ‚Üí 4b8c5ea)](https://github.com/tensorflow/tfjs-examples/blob/4b8c5eacfaedc25cc465fc7eef4ec3a96f2711be/webcam-transfer-learning/index.js#L72) ---- 
At the first sight this looks to be big news. But when you think about it: GitHub's site is ugly and has barely any functionality.So... shrug 
I haven't tried to do exactly what you are doing (and I don't quite understand exactly what you're doing), but the parts of leaflet that I've used had the most convenient API of any mapping platform by far. (I.e., there may not be anything easier that's easy to find.) I'd try to find some sample code where someone did something similar to what you want.
Why use reflection? Why not simply function retry(backoff, max, f, num = 1){ console.log(`Attempt no. ${num} at ${Date.now()}`) return f(num).catch(err =&gt; { if(num === max) throw [err] return new Promise(res =&gt; setTimeout( () =&gt; res(retry(backoff, max, f, num + 1).catch(err2 =&gt; {throw [err, ...err2]})), backoff(num) )) }) }
also i cant tell how this thing is connected to the ui. But im sure i just missed something.
&gt; Are you saying that it's not a large Javascript app, because it's rendered on the server? Why cannot a server rendered app be large Javascript app? It's not because it's server rendered, but because what's running the show is not JavaScript. If it was a Node server then it could be considered a JavaScript application, but that's not the case. JavaScript is only used to add some functionality in some pages. The heavy lifting of the website is done in Ruby. [Here's an interview](https://medium.com/s-c-a-l-e/github-scaling-on-ruby-with-a-nomadic-tech-team-4db562b96dcd) with Sam Lambert who at the time was head of technology: &gt; The core of what you see and use as a GitHub user is a Ruby on Rails application. And then adds: &gt; We‚Äôve got core Ruby committers that work for us
My feelings exactly, and similar to how I felt about Firebug: you were there when there was nothing else, and you kicked a lot of ass. Thanks, and godspeed.
Overhead does not make code more performant. TypeScript does a "best guess" at what's performant, and it is only more performant for a developer who does not know how to be performant in the first place. I have seen it waste memory and clock cycles more times than not in its JavaScript transpilations, which is to be expected.
I use the mongoose npm module. Very easy to work with.
Yeah, this is very useful. I'm going to try this first thing tomorrow in office. 
Because I actually want to get stuff done, rather than ram my head against a wall every time TypeScript yells at me for some complex issue.
If you write your tests properly it will not be necessary to validate parameters of internal functions/methods. The ONE rule of testing, enforced by TDD methodology, is: Test behaviour, not implementation. I almost only write tests for the exposed interface of my program/library and avoid, as much as I can, to write tests for internal functions. Make variations of the inputs, and assert outputs (direct return) and side effects (database or filesystem operations, http calls, etc...), also avoid mocking as much as possible to keep the tests as close as possible to the production usage. Writing tests this way, you can see (actually see, in a code coverage tool, for instance) that a lot of defensive code, checking parameters in internal functions especially, is unnecessary because made redundant by parameters validation done upstream. Now, let say a developer misuse an internal function/method (for instance, pass an invalid parameter value) in a piece of code also purely internal to the program. Only two things can happen: \- It changes the behaviour of the program: Your test should pick it up, if not you probably missed a test case. \- It does not change the behaviour of the program: Does it matter then? In addition to be, most of the time, useless, validating every single parameters in every internal function has an obvious performance cost, and makes the code less readable (therefore error prone). 
https://bitbucket.org/doniseferi/blackjack-js/src/6ca1b116d793b4e45b16be8bd49788dd0d9c28d1/src/index.html?at=master&amp;fileviewer=file-view-default#index.html-36
For functional programming stuff I'd go with anything Dominic Tarr writes: https://github.com/dominictarr?tab=repositories Especially Pull Streams: https://github.com/pull-stream/pull-stream --- For large projects checkout Insomnia (electron + lerna + js + webpack + flow + docker): https://github.com/getinsomnia/insomnia --- I always liked this minimal monkey patcher: https://github.com/dtinth/ride &gt; Monkey patching is a technique to add, modify, or suppress the default behavior of a piece of code at runtime without changing its original source code --- 
&gt; wrapping EventEmitter in promises - the whole idea is to describe a &gt; flow (a sequence of events) in your code. Seems like a good candidate for use observables (if you don't mind adding additional dependency like Rx.js or similar library. Because dependency is also a cost. Though probably in Node applications you may not care too much about e.g. bundle size). But I still don't understand: 1. why listeners should be stopped on each pause/stop 2. why in the `await` example they don't need to be stopped anymore 3. what is the `func` or other magic variable showing in article that is not defined anywhere. These examples look like they were cut out from middle of some bigger project. And something is missing.
Try Reactiflux
Thanks!
Yep.
Discord.js is amazing!
Oh memories... I still remember I got a PDF certificate on installing Firefox 3 on day 1 and discovering the Firebug plugin on that same day. Then I was inspecting element on every web site I visit. People now take everything for granted and tell people jQuery sucks, not knowing how horrific web development in the past was.
I can totally understand! If my wife was in a hospital ICU and I found out the hospital was using jQuery on their website, I would immediately unplug her from everything and roll her out the front door. Seriously, any organization that is using jQuery is obviously causing way more harm than good and I probably just saved her life. Obviously, anyone using jQuery is just sick in the head and probably eats babies too.
This is awesome :)! i will go ahead and give this a shot this weekend, 
I think you and /u/dalore are talking about two separate things. They are already operating on the assumption that you‚Äôre only serving the required JS (for the most part at least). On http1 it‚Äôs still better to serve a bundle containing, say, ScriptA + ScriptB + ScriptC + ScriptD across the whole site than it is to serve scripts A, B and C separately on a page where ScriptD is not required. Of course there is a balance. Sometimes you have a large script that‚Äôs only used in one part of the site, so you wouldn‚Äôt include that in the main bundle.
looking at [this](https://bitbucket.org/doniseferi/blackjack-js/src/6ca1b116d793b4e45b16be8bd49788dd0d9c28d1/src/index.html?at=master&amp;fileviewer=file-view-default#index.html-39) entry point. i like the ioc / dependency injection nature of it with everything being created in your main function. i think that it will let you change around some rules and implementation details without affecting the state of the game, nice one on that. i'm not a fan of your factories being aware of the ui and the frontend. creating an object is in this model is extremely tightly coupled to the ui, and not just the ui, the DOM itself. like [cameron fry levels of tightness.](https://www.youtube.com/watch?v=O42K4EwVssQ) ideally you'd have your cards and games and players and factories go about their merry ways running the game simulation, then your ui would take that state and render itself with it. as it is now, there's no such thing as the state of the game outside of the DOM. if you wanted to port your game to nodejs and run it through a command line, you wouldn't be able to. that would be the first thing i would address i'm not a fan of this kind of call: [`bj.dealer.deal();`.](https://bitbucket.org/doniseferi/blackjack-js/src/6ca1b116d793b4e45b16be8bd49788dd0d9c28d1/src/index.html?at=master&amp;fileviewer=file-view-default#index.html-50) it's kind of a smell that it violates the [law of demeter.](https://en.wikipedia.org/wiki/Law_of_Demeter) the way it's built now, your main function (the script block in index.html) is fully aware that the blackjack game has a dealer and the dealer `deals`. the implementation is fully exposed. i think the following three functions: bj.dealer.deal(); summaryUpdater.update(bj.dealer.players, "scores"); tableUpdater.update(bj.dealer.players, "table"); should be abstracted away by the `BlackJack` object into a method like `startRound` or something along those lines. that way, the main function only knows that it wants to start a round, and it's not concerned with what that all means. the blackjack game should handle the logic of starting a new round. same thing with `updateButton`. the function of that method should be abstracted away by a method on the `BlackJack` object, not called individually by the main function. Those are two main issues: * coupling and confused separation of responsibilities (your model depends on the dom existing, and indeed a modern browser that implements `createElement` to function) * muddled abstractions due and weak boundaries. think of how a blackjack game functions and is structured and the flow of a game and the flow of each round and use that to design your `BlackJack` object's interface.
Yea, I'm aware of d3.js but it doesn't seem to have great support for elements like div as nodes.
Try d3. It's good for this kind of stuff and loads of help material and a well documented api reference. 
Possibly biased opinion here, but why not read code that‚Äôs in other languages than JS? I mean JS isn‚Äôt known for it‚Äôs processing prowess, and as such most interesting algorithms are going to be in something else. Read the linux kernel, image manipulation libraries, regex libraries, http libraries, anything. There‚Äôs so much cool stuff out there üòâ 
d3js.. mike bostock the author of d3 is an amazing guy and a brilliant dev. jquery.. jquery may not be the fashion right now but still its good to check out.. 
I usually use ES6 async await and I don't think it needs to be that complicated. function Sleep(millesecs) { return new Promise((resolve, reject) =&gt; { setTimeout(resolve, millesecs); }); } async function Retryable(func, maxAttempts = 1, sleep = 1000) { let attempts = 0; const errors = []; while(true) { try { return await func(); } catch(ex) { attempts++; errors.push(ex); if(attempts &gt;= maxAttempts) { throw errors; } if(sleep !== null) { await Sleep(sleep); } } } } How to use try { const result = await Retryable(() =&gt; { return new Promise((resolve, reject) =&gt; { reject("ERROR"); }); }, 3); console.log(result); } catch(ex) { console.error(ex); }
Conversely, caching selectors is one of the most obvious and easiest issues to resolve. 
Does it have support for div as nodes? I could find any docs about it.
My suggestion is the following. Clearly this is a function: buildCalendar(). Start making other functions. colorDay(), determineColor(), etc. whenever your functionality is. A good rule of thumb is that a function or method shouldn‚Äôt be more than 10 lines. It‚Äôs amazing how simply making your functions smaller will help you make better decisions. Basically my answer is, don‚Äôt be afraid to make lots of functions with single responsibilities. But everything you have so far will totally work. Post your progress on a Codepen and we can keep it working on it. Don‚Äôt be afraid to PM me. Now if you want to go further and start talking about classes...and making this more object oriented....don‚Äôt hesitate to ask!
"Jquery sucks, lol" "No, it doesn't. Here are 1 billion sites that use it." "Those sites are stupid." "No you are stupid and young and you don't know what you're talking about.js." There, I saved everybody the time they would have spent on yet another argument about wether or not to use jquery.
What if there was a more modern technique that is as good at the old iPods job and the new challenges though. No need to go through a codebase looking to replace working jquery code, but I don't think it'll be in anything I do green field from now on. 
D3 binds your data to html elements. So that you can manipulate your data and then change the DOM to match. It also gives you a load of functions to make that easy. Something like this should work fine d3.select('#main') .selectAll('div') .data(nodes) .enter() .append('div') That selects whatever element I have given the id main. And then for each item in nodes It will add a div element that is linked to each node. You can add subsequent elements by chaining .append() and you can manipulate them via things like .attr .style .classed. The only thing I don't know about is automatic layout. I'm not sure what d3 contains in terms of automatic layout as I use another library ontop of d3 to do the layout. 
No worries, Thanks for the effort
No worries. Feel free to ask
Its not as much a traditional map as a tile grid. I have a grid of squares, each square is the coordinate not an intersecting point, so for me an X, Y coordinate references a 10x10 pixel square, and the square next to it would be X+1, Y etc. Leaflet just seemed like there was too much customizing it away from the geo focus for something simple like this.
I would say lodash is quite good. I use less of it these days with some of the ES6 and beyond additions but it many cases it's still faster than native functions and has all kinds of handy utilities. [https://github.com/lodash/lodash](https://github.com/lodash/lodash)
Spectrum! It's a great example of a very modern JavaScript project. \- React+Apollo GraphQL frontend \- GraphQL Backend \- React Native mobile apps \- More fancy stuff. Take a look yourself :) [https://spectrum.chat/](https://spectrum.chat/?t=87593913-196e-45a2-9691-6c1b63354bdc) [https://github.com/withspectrum/spectrum](https://github.com/withspectrum/spectrum)
Write it has come a long way since I last used 2.0 beta.
Thank you for your feedback, this is absolutely brilliant and makes totally sense. The explanation of separating the state and the ui is what has given me a deeper eureka moment of JavaScript. The ui should tap into the state and update whereas the application should be core domain logic without any knowledge of the consuming party. In this instance it is ui. I will refactor this with all the points you made and hopefully when I‚Äôm done if you could have a quick look that would mean the world to me. The law of Demeter is absolutely broken the client shouldn‚Äôt know of the types internal types. Never call an object of an object. Silly mistake. This is the kind of strong feedback I was hoping to receive so I thank you. 
It's similar because Jeremy Ashkenas created both
Cool, yeah doesn't seem very map-like. Depending on how much zoom you want to support and how many objects you have, consider rendering everything too big and scaling it down with a css transform. Then you can animate zoom in (by modifying the transform) and it will run smoothly and the zoomed in result will be sharp. 
/r/lolangular 
D3 just uses SVG under the hood. You can use [foreignObject](https://developer.mozilla.org/en-US/docs/Web/SVG/Element/foreignObject) if you want to embed standard HTML into sections of your SVG
&gt; Literally the first sentence in the wiki entry claims that currying is the transformation from the nary to the nth order form which is what I was claiming all along. I don't see a sentence in that article that supports the idea that function written in the nth order form is curried if it wasn't transformed by currying. I see that you're having a little trouble with literacy. Let's start with that first sentence (numbers are mine, for reference): &gt; In mathematics and computer science, currying is the technique of translating the evaluation of a function that takes multiple arguments (or a tuple of arguments) into evaluating a sequence of functions, each with a single argument. As I've already explained, this is a function that takes multiple arguments: ``` const fun = (a, b) =&gt; a + b // or in es5, if that helps you understand the concept function fun(a, b) { return a + b } ``` This is that same function _translated_ into "a sequence of functions, each with a single argument": ``` const fun = (a) =&gt; (b) =&gt; a + b // again in es5, if that helps you understand the concept function fun(a) { return function (b) { return a + b } } ``` The work of the function is to return `a + b`. If the function is written to take `a`, return a function that takes `b`, which in turn returns the evaluation of `a + b`, that's currying. That's what it says on Wikipedia, because that's the definition of currying. There's absolutely no requirement that you first write a function that takes a tuple and then write another function on top of it that takes those arguments and then calls the first function. Not only is it not required to do that, but it's a really stupid thing to do if you have the option not to do it. 
I was waiting for this. Finally I will be able to use my favorite mobile UI framework with Vue. Cheer. 
I doubt you need to worry it's very fast see benchmarks: https://jsbench.github.io/#354ecd3cfa330effd23ad1335d5fd290
Not much really. You can try creating a for loop and instantiating 5000 objects with 3 and 4 properties with Math.random() data assigned as values.
You're wrong about how V8 optimizes functions at runtime, in general when a function is first invoked the types of the parameters given are assumed to be the common types and an in memory optimized function is created, this function is optimized for the types given, as long as the function is only called with the same types of parameters this optimized function is used, as soon as the function is called with parameters of other types the optimized function is discarded and a slower version (where the types are checked at each step) is used.
Assuming dalore thinks you're correct with your first statement, then you are, because I wasn't operating on that assumption.
Tests shouldn't be brittle, sure you're not pushing unit testing to the edge? You could write more general tests that target features/behaviours vs just testing a class &amp; its functions?
Yea I'm pretty excited by the fact that are using web components
That's a great question. This example was really just an example of what you can do with state machines. Where you really start unlocking their power is when you start using statecharts -- which is an extension of state machines that account for things like parallel states, hierarchical states, etc. There are a few points here that I think make state machines and statecharts a worthwhile endeavor in applications: - By defining all the possible states and transitions that your component can exist in, you can [easily and automatically generate tests](https://github.com/MicheleBertoli/react-automata/blob/master/src/testStatechart.js) that cycle your components through each of those states and take snapshots... making it easier to determine if a change breaks things. - As app complexity grows, so does the complexity of reading the code. By defining a finite, deterministic set of states that a component can exist in makes it easier for other people (and future-you) to reason about the code. - As mentioned in another comment, state machines and statecharts can help bridge the gap between design and development -- designers are typically already thinking about the different states that an application can be in... building things in the same way can help make that transition pretty linear. - As I mentioned in the article, state machines can help smooth out the logic when you find yourself writing a lot of `isSomething` boolean flags. But at the end of the day, to each their own... if you have a system that works for you, stick with it!
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [MicheleBertoli/react-automata/.../**testStatechart.js** (master ‚Üí 568b5dd)](https://github.com/MicheleBertoli/react-automata/blob/568b5dd5ae6afb51c2fe2919d9ea07f7fd07abcb/src/testStatechart.js) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply e338xzv.)
There aren't polyfills for CSS animations. I worked for a project for the TV in a subway system. It supports a very old version of Chromium. jQuery was basically the only choice.
Honestly I don't know why Backbone ends up at the top of these threads every time. I used Backbone for many years, and still have a lot of respect for how Collections / Models are set up, pretty solid API all around. That being said, I would definitely not recommend it anymore as an example of a really nicely architected project or clean code. One of my biggest grievances with this coming up as an example of a good project THE SOURCE IS A SINGLE, 2096 line js file. Even at the time, it could have been bundled, if not by grunt then a makefile, whatever. Take a look at newer projects like Ramda https://github.com/ramda/ramda, or lodash https://github.com/lodash/lodash and tell me you'd still recommend Backbone as a top example.
Thanks. Yes there was a reason everyone was bundling their scripts.
I got it to work. I just made an html file, copy/pasted the html in there, added a &lt;script&gt; block in the bottom of the body, and pasted the javascript inside that.
Something like this (https://stackoverflow.com/questions/19721439/download-json-object-as-a-file-from-browser) should work for saving.
Ah good point. I could imagine a really complicated and long entry process, like say TurboTax web app, being coded with a state machine. Thanks for the lightbulb. :)
Nice! I hadn't made the distinction between creating the file and saving it onto the user's machine (as such: https://stackoverflow.com/questions/3665115/create-a-file-in-memory-for-user-to-download-not-through-server). How would you approach the import feature?
Maybe a little, but the machine generated code spit out by the transpiler would lack the all the efficiencies a human programmer could put into the code if they wrote it in the target script in the first place.
You should look up 'the test pyramid'. Basically you cover as much of your logic, biz rules etc with unit tests. The amount of tests/testing should reduce higher up the pyramid you go. The better the quality AND coverage of your unit tests, the earlier you'll catch your bugs, helping to reduce the reliance on integration and E2E tests and also build confidence in your pipeline throughout the business.
YDKJS
Yes, thats why I rarely do them üòÇ
The react with mox thing came after the release of VSCode actually. Also in MS different business barely talk, so a vs product is rarely the result of investment in Office 
After being bit so many times by using other people's code in my projects, I've started reading the source to anything I include (as well as using bundlephobia to check the deps and size). I usually end up finding things I don't like, and either have the ability to send a PR, fork the project, or include the parts I like into my source code. Even if the code isn't considered "good", or popular it's worth reading.
It can be advantageous to keep the objects the same shape - as in the same set of properties. Not sure if it makes much difference between just the two that you have (but maybe?). Could be worth checking out. A recent video posted here talks about it more: https://youtu.be/5nmpokoRaZI?t=582
I *love* lodash's documentation and code It's all very explanatory and very understandable
Can someone write a sales spiel about why Ionic instead of nativescript-vue (which I'm using atm) or react native?
New favorite troll sub, thanks!
Then what are you talking about? It's been well-known for years that combining JS into one file is better for performance on HTTP/1.
If your tests are hard to maintain, that means that your code is probably doing too much. Try to create smaller units, with a single purpose. That way, units (classes, functions) are not changing, you are either write new code, delete old one, or build your existing units in different way. A lot of javascript developers forget about the construction layer of the app, and just uses global state. This will result in a code that is hard to read and maintain, thus brittle tests. Instead of doing this ``` const axios = require("axios"); class UserService { getUserById(id){ return axios.get(`user/${id}`); } } ``` Do this: ``` class UserService { constructor(httpGet){ this.get = httpGet; } getUserById(id){ return this.get(`user/${id}`); } } ``` That way, when testing you can mock axios, and your code will be agnostic to the implementation of "how" you do your "get" - meaning you can replace/decorate/enhance your client if needed without changing the service. Check out open-closed-principle and single-responsibility-principle. I hope this helps :)
&gt; For the most part, at least There are cases I've seen where it was actually more performant to serve some JS on only the pages that needed it.
Your right, I kept the file in a zip, I extracted the zip and it worked wonderfully. Thank you!
And I said as much in my answer. But you literally just said this isn't what you were talking about. Get your argument straight, otherwise I don't care.
Hey there! I almost exclusively use Bluebird. So `reflect` is very close at hand. I will note that your function is missing the args/apply part though it wouldn't be that difficult to add. I think this is a nice approach. Thanks for the input!
First thing to do is look up splice to see what it does so you can do the same: [splice](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/splice). In short it deletes and/or adds items to an existing array at a certain index (`start`), and returns anything removed. Any time you add or delete items to/from some arbitrary point in an array, you have to worry about the shift that will occur to those elements past that point in the array. So, for example, if we add 2 in the middle of [1, 3], the 3 element is going to move from index 1 to index 2, giving you: [1, 2, 3]. Thats a shift of one place forward, or the number of items added to the array. Same applies if 2 is removed from this new array going back to [1, 3]. 3 then shifts one place backward, or the number of items removed. Luckily, anything before that point (1) is unaffected. So the first thing you might want to do in your own splice command, is to start moving items in your array from the start location the number of places needed to handle the deletions/insertions. The number of places moved is the number of things added - the number of things removed. (Hint for moving these elements: use a loop that starts at the end of the array.) Once you do that, you fill in the additions at the start point and presto! You're done... almost! There's one more thing to consider, and that is what if you delete more than you add? Then your array's length might need to be lower than it started. When you add things to an array, this length is automatically updated, but it doesn't update when you remove things from an array - not unless you use methods like splice. But, one thing about arrays is that you can actually set the `length` property. So once you're done moving and adding things around you can set your array's `length = ` ... to whatever you expect your new array length to be, which should be the original length + the number of things added - the number of things removed.
Thanks for this version too! I hadn't thought about how I would do it with Async/Await. I tend to avoid it unless the codebase has already been using it. My personal opinion is that `try/catch` should be avoided if possible. Simply using `.catch()` as an asynchronous error handler is my preference.
Dependency Injection for the win! This is definitely the single most effective way to make things testable. For those who prefer the functional paradigm, you can just take advantage of functions being first class and return other functions: function createGetUserById(httpGet) { return function(id) { return httpGet(`user/${id}`); } } And es6 syntax makes this really concise: const createGetUserById = httpGet =&gt; id { return httpGet(`user/${id}`); } There are some nuances here, but they‚Äôre equivalent in most cases. Since we know that most users of our function won‚Äôt want to worry about bringing their own axios implementation, we can also export a ‚Äúpre-injected‚Äù version, but just test our creator function, since we can be confident that if one works so will the other.
Mine is straight, perhaps I'm just not communicating effectively though.
Not sure if this help, but have you looked at lodash zipwith method? https://lodash.com/docs/4.17.10#zipWith
Hey, so if you're using ES6, you can use the spread syntax like so. Sorry about the poor formatting, I'm writing this from my phone. var arr1 = [1, 2, 3] var arr2 = [3, 4, 5] var arr3 = [...arr1, ... arr2] Cheers
u can read my code I think it's pretty good. [https://github.com/fermidirak/foodsie](https://github.com/fermidirak/foodsie)
I have used the google maps api for this. There are tutorials for slicing a large image into a grid so the google maps engine can zoom/scroll quickly. It does not need to be a geo map; I have done large flowcharts and other non-geo content.
Ha, you're absolutely right. Thanks for the correction!
That is my preferred format, but it can't be used natively in any IE (Edge is fine). The ES5 equivalent is: var arr3 = arr1.concat(arr2); var arr3b = [].concat(arr1, arr2); Some people consider the format used for `arr3b` to be slightly more expressive while others think `arr3b` is slightly wasteful, but both are (roughly) equally performant.
Reading too much js might just give you brain damage.
If the arrays are: - The same length - Have the same days at the same index Then: const merged = obj.MessageCount.map((o, index) =&gt; ({ day: o.day, count: o.count, visits: obj.LinkCount[index].visits })) 
that's pretty stupid
he's trying to "zip" them, not concat
Yeah I noticed that, I didn't read the whole post at first lul. 
I understand you are talking about the past in the article, but now virtually all environments except IE have native promises now. By not relying on library-specific API you can reduce bloat, even if you need to support IE because you can use a slimmer polyfill. (Note that this is not criticism against Bluebird. But like jQuery, its time has mostly passed) If your async task function takes arguments, just use an anon function `retry(backoff, max, () =&gt; task(arg1, arg2))`
**What?**
May I recommend Airbnb's Javascript Style Guide? Not necessarily a codebase but very valuable as a resource!!
sweet, thanks. i've been wanting something like this for a long time!
[https://gitlab.com/wkrueger/auction-scan](https://gitlab.com/wkrueger/auction-scan) next.js website/service at ahscanner.bid
Login (which creates a session), then redirect to data.php? As long as it's on the same domain the session should still exist. 
There are many ways to merge arrays. Assuming: const arr1 = [1, 2, 3]; const arr2 = ["red", "blue", "green"]; These approaches give you a new array and don't touch the original. concat: const arr3 = [].concat(arr1, arr2); spread (es6): const arr3 = [...arr1, ...arr2]; These approaches modify one of the original arrays. loop/push (push arr2 onto arr1): for (let i = 0; i &lt; arr2.length; i += 1) { arr1.push(arr2[i]); }; forEach/push (push arr2 onto arr1): arr2.forEach(val =&gt; arr1.push(val)); apply/push (push arr2 onto arr1): [].push.apply(arr1, arr2); apply/unshift (unshift arr1 onto arr2): [].unshift.apply(arr2, arr1); Remember that apply takes the form of ```apply(thisArg, arrayOfArguments)```. Essentially the contents of the array (arr2 in this case) are spread out and provided as separate parameters to ```apply```. ```apply(arr1, [4, 5, 6])``` is basically the same as ```call(arr1, "red", "blue", "green")``` or ```call(arr1, ...arr2)```. If you were merging large arrays (as in tens of thousands of elements) this would not be a great choice for two reasons, firstly it would consume a lot of memory (may not be a issue) and secondly because there is a maximum amount of parameters that a function can take. The exact ammount differs based on the JS engine as does the behaviour when this limit is met (some engines fail silently, some throw an exception). For your use case it wouldn't matter much and it is a pretty concise way of merging arrays but I don't think anything can beat spread or concat for conciseness/expressiveness, they also leave the original arrays intact which is often desirable. Concat probably beats spread for clarity but that is up for debate.
No, we don't write any tests.
Yup angular is pretty stupid 
\&gt; experiencia awes√≥mica heuehuehuehuehuehuehu 
My assumption with VSCode is that they started investing heavily in TypeScript + React and realized that either VS (traditional) wasn't cutting it, or that the lack of standardization with their devs between Sublime, Atom, WebStorm, etc was creating a huge amount of friction across the org. This led to the development of VSCode, to provide a better internal tool for developing in the TypeScript + React ecosystem that they were pursuing. 
Greensock is just a JavaScript library like any other, it is no different to Barbajs in that respect. You may be able to create many of these animations using CSS Keyframe Animations but its hard to say how they would perform in a real world context. GreenSock (or GSAP) is built from the ground up for performance and usablility. Its very powerful and pretty easy to use when you get sued to the syntax. For a simple introduction to GreenSock[this tutorial](https://ihatetomatoes.net/simple-greensock-tutorial-your-first-steps-with-gsap/) is very good. Some of it might be out of date but the API hasn't changed much. Sara Soueidan has written extensively on SVGs and Web Animation and also wrote a [tutorial for GreenSock](https://www.creativebloq.com/web-design/supercharge-svg-animations-gsap-11618683). For more advanced usage Sarah Drasner (who has also written extensively on SVGs and Web Animation) wrote a series of tutorials a while back that are great (again they might be a little outdated but definitely still useful). [GSAP + SVG for Power Users](https://davidwalsh.name/gsap-svg). Sarah also has a course on FrontendMasters [Advanced SVG Animation](https://frontendmasters.com/courses/svg-animation/) (requires a subscription) which uses GreenSock. Some of these articles are focused on animating SVGs rather than the DOM but the prinicples are the same, with SVGs often being more complex/ having more idiosyncracies and if you want to animate text like in one of the examples you provided then will need to learn how to animate SVG paths. Most of what you learn about SVG animations will apply to the DOM (apart from the property names being different). Have fun! 
Just hoping by to hint that adding DI to javascript is mostly pointless for the TON of code bloat it adds, since \`require\` is easily mockable. This is javascript, not C#.
Kind of side note but I recently wrote the Three Little Pigs in JavaScript
If you are googling the wrong word, then you will find hard to find tuts. It's greenSOCK.
I'm pretty sure you knew I'm talking about your comment, but I can give you a benefit of a doubt...
I support the lodash recommendation. Have had a few interviews that just boiled down to "implement this function that lodash already does"
Maybe try doing a Fourier transform on the mp3s, this will give you the frequencies, then have like a hashtable with Frequency that maps to a the specific keys
Importing models in all of your files sounds like your code isn‚Äôt well factored. The code that actually needs to interact with or import your models should be pretty self contained. A custom logger could be imported in every file (it‚Äôs not that much work) or you could look into dependency injection.
Troll.
&gt;GSAP + SVG for Power Users thank you so much will check this out. 
If I remember correctly, a lot of third party guitar hero knock offs like Frets on Fire and Phase Shift stored al ot of the chart mappings in MIDI keyboard files. So maybe somehow matching a certain frequency and trying to map to a file there. The problem I ultimately see is that, unless you have separate files of each instrumental, you're going to get a lot of noise from the other instrumentals when you try mapping. Outside of official Guitar Hero/Rock Band rips, I don't know of any reasonable ways to get separated track files. That said, you *could* consider potentially finding MIDI rips of the songs by instrument, or even better, finding sheet music on a per instrument basis--and seeing if you can't somehow map that to a MIDI. That may allow for some interesting and capable charting. Check out the Phase Shift community if you can. It was the last, and best known one for the Guitar Hero/Rock band fan scene. Would be a great place to try your finished products as well
For your particular data, a list of objects isn‚Äôt really optimal. To look up any particular day, you might have to look through all items in the worst case (O(n)). Your data is ultimately a list of key value pairs, and will be much more efficient to read and write to as such (O(log n)), in a Map structure. A Map also has natural ways of being merged if the values do (the fancy way of saying this is that it‚Äôs Monoidal). And counts can be merged via addition. Let‚Äôs put this all together with the help of the ‚Äòimmutable‚Äô library: const { Map } = require(‚Äòimmutable‚Äô); // turn an object into something the Map constructor understands const toTuple = ({ day, count }) =&gt; [day, count]; // build our maps const likeMap = new Map(likes.map(toTuple)); const msgMap = new Map(msgs.map(toTuple)); // create a new map that has the sum of both counts by day const likeAndMsgMap = likeMap.mergeWith( (likeCount, msgCount) =&gt; likeCount + msgCount, msgMap ); If you needed to translate that back to your original structure you can as well (turn it to a list and map the list), but the Map is going to be a much more natural way to work with data like this. Our code does a lot with very little because we have the right structure. The code I wrote is pretty terse, so don‚Äôt hesitate to ask questions if you have them!
Looks great
check out the inversion of control pattern and dependency injection. the idea is, you have a module that creates all your dependencies and then you pass those created and ready to go dependencies into your application. what server application are you using? express? koa? a lot of node-based server software uses middleware which is another area to explore to reduce duplicatoin
You can use max/min heap. Also you can use QuickSelect algorithm which has O(n) complexity on average but O(n\^2) in the worst case. 
I'm guessing OP wants to improve their JS skills, in which case JS would probably be a safe bet. 
I guess that‚Äôs my point, you can improve your JS skills by reading code that is not written in JS üòâ 
 result = MessageCount.map((message)=&gt;Object.assign({}, message, LinkCount.findWhere((link)=&gt;link.day===message.day);
Where's the React part?
This is a really thorough answer to a question that wasn't what OP asked about :) OP is asking about "joining" but used the word "merge" by mistake.
Technically he's not trying to zip, either. He's trying to outer join them.
client/src/...
OH. Duh. Thanks!
Parcel
Wow really convenient and good boiler plate to start a MERN app! Thanks 
Looks like a license was added :)
In the Firefox root directory, there is a file called "[omni.ja](https://developer.mozilla.org/en-US/docs/Mozilla/About_omni.ja_\(formerly_omni.jar\))". Extract chrome\browser\content\browser\browser.js This is almost all of the js that makes Firefox's UI work. This isn't really your typical web js , but there is 292KB of really solid working class js. including some written by the inventor of Javascript himself.
This is a very odd question. Sorts are generally O(nlgn) on unsorted lists so I assume you are looking for something faster than that. Probably something in a single pass of the array. Best thing I could think of is the following. 1. Create another empty array with 9 indices. 2. Use insertion sort to fill this new array with the first 9 elements of your original list. At the end of this, the first element in the array of 9 should be the smallest number you've seen so far. 3. Now for the rest of your original array, compare each number with the number at the beginning of your 9 element array. If it is smaller than this number, do nothing and move on. If it's larger, than boot off the smallest number and insert this new number into the correct spot on your list of 9 maintaining order from smallest to largest. 4. After you have gone through the entire original array, your 9th largest number should be the first element in the 9 element array. All that said if your original array is around 9 numbers than this run time is O(n^2). Assuming the original list is large, this is essentially O(n) since all the insertions are O(9) and constants can be dropped. Hope this helps with your homework. 
The fuck is MERN now? 
You need to be cautious about responding to warnings blindly. It's more practical to know the reasons, and base your decisions on them. A global variable is hard to reason about. It can be modified from anywhere, at any time, so when future you reads the code, you have to go all over the place trying to trace down all the accesses. With a logging module, assuming you can make the reference to the module read only, you'd be safe, and you'd know you have consistent log files.
This is really great, thanks for sharing! One question. I've been learning MERN stack, and am used to setting up a proxy to my express server in my react client package.json file. Why are you not doing that here? I'm a bit new, and may just be missing something. Just trying to understand the best approach to a react/express setup. Thanks!
deconstructing! I learned this when I learned ReactJS ....