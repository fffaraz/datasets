I'm not on odd numbers today... 2) yes - if a variable is always set, then your new script might never fail until someone else runs it.... and worse, if it is set to something wrong - or, in Valve's case, a ["steam" cleaning](https://github.com/ValveSoftware/steam-for-linux/issues/3671) of user profiles was due to a variable being empty - and `rm -rf "$STEAMROOT/"*` being run when `STEAMROOT` was empty..... 4) I use `echo` whenever I am not doing something really simple, but if there are other `printf`s in the script, I will generally make everything a `printf`
You can try [expect](https://en.wikipedia.org/wiki/Expect) or one of it's alternatives.
**Expect** Expect, an extension to the TCL scripting language written by Don Libes. The program automates interactions with programs that expose a text terminal interface. Expect, originally written in 1990 for the Unix platform, has since become available for Microsoft Windows and other systems. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/bash/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
Can use grep directly for if condition. if `echo blah | grep -q bla` ; then meh ; else foo ; fi -q tells grep to not output the match.
Learn something new everyday...
I would like to share shell experience. I write heavily in bash as a daily driver, but use zsh in the terminal. Is there a "whisper" in reddit?
c++ isnt a scripting language
http://chaiscript.com/
1st, you need to indent "code" and "terminal" output with 4 spaces in Reddit for a readable post. 2nd, this stack trace comes from `python3`, not bash.
Yes click on the user's name to go to their profile then you can send a direct message
Yes , I know I should post indent code, so others can read it. But my problem is why it is not indented in my terminal, Someone told me because I use vim to open file, but I compile a debug-python, vim and my debug-python is incompatible.
`curl | grep` ?
&gt; Someone told me because I use vim to open file, but I compile a debug-python, vim and my debug-python is incompatible. Couldn't that be what's causing the error, then?
w3m and vim?
If not curl and grep, I’d recommend python and an html parsing library.
It is the first time I hear about 'whisper'. I have no idea, sorry.
scripting language /for/ c++
&gt;Couldn't that be what's causing the error, then I do not know the exactly reason, Someone only told me vim is depend on [libpythonxx.so](https://libpythonxx.so), this dynamic library is not compatible with my debug-python.
Cool, thanks! And how do I get that into the config.json file in the right places under the right key ("auths") with preserved formatting?
Involves pagination, so assuming the page number it's on the URL arguments a simple bash loop that iterates over it to wget each page. If the forum is a SPA that loads everything with javascript then Ctrl+K (firefox) Ctrl+I (chrome) and look at the network log to see what request it sends when loading a new page, then copy as cURL and use that on the loop.
As far as I know, cURL to get the page (--cookie &lt;file&gt; is your friend) then after assiging it to a variable you can call it to | grep | cut -d "keyword" -f # Awk can help you after cURL too.
Maybe escapedRsaKey=$(encode $rsaPublicKey)
Python + requests + re (if you want to search regex instead of just generic string searches. Pythonish-Pseudocode: base_url = “https://domain.tld/“ pages = [“page1”, “page2”, “page3” ... ] #can be generated automatically in Python if following a strict numbering scheme like the following line # pages = [“page” + num for num in range(1,100)] # then loop through and request all pages and search for page in pages: req = requests.get(base_url + page) if query in req.text: print(query + “ is found in “ + page) Should be about that easy if I understand your goal correctly.
I still don’t believe this guy is running CentOS, it looks so macOS ! Incredible! A fine tutorial to edit your $PS1, and after all an emoji could be a fun replacement for the $ prompt sign.
So then I think the thing you’re trying to be a semantic policeman about is interpreted vs compiled languages , im fairly certain that scripting is more a paradigm for putting different programs together and although its often a interpreted thing since most of the performance intensive work is done by compiled code I don’t really see how this isn’t still scripting.
ive barely any idea what im talking about, when i hear "scripting language" i usually think of "interpreted language". did i get that wrong?
where's the bash script to delete someone else's post?
lol. I promise it is CentOS 7. &amp;#x200B; I used a VM to make the tutorial. I SSH'd to the VM from my Mac. [https://www.iterm2.com/](https://www.iterm2.com/)
You don't think it will be helpful to anyone?
 #!/bin/bash /usr/bin/firefox --new-window https://www.youtube.com &amp; spotify &amp; disown -a exit 0
thanks bro, it worked. may i ask what the signs after firefox and spotify means, also what disown -a does? :)
Try setting `$TERM` to `xterm-256color` to get colors working
Bash waits for a command to finish before moving to the next command. The `&amp;` after a command makes the command run in the background, so bash will go on and run the next command. In an interactive prompt you can also use the `&amp;`, or first stop the 'foreground job' with `ctrl+z` and then run the `bg` command. This will continue the stopped command in the background and bash will give you a prompt.
That's cool and all that it can parse those too, but do you really want it? I prefer to let my scripts follow the same 'conventions' as (most) other scripts and commands (i.e. single hyphen for one-letter options and double for more letters.
Personally? No, I do not. It might make sense, if I'm emulating another CLI for familiarity, or something. I'm not sure why I even remember that option, actually.
Not really their basically synonymous my point was mostly its possible the op had something he could call a cpp script. Scripting is more of a task, like how you can use cpp for functional programming even though many would not call it a functional programming language
Just add `auths` to the key name. I edited the post. I don't now what you mean by "with preserved formatting". JSON isn't formatting sensitive. If you really feel you need to have "email" indented four spaces more than "auth" in the same block like in your code sample, things get a lot more awkward.
&gt; I've asked everyone in my office, no one knows what's going on. [ Google: Didn't bother](https://www.google.com/search?q="su%3A+Sorry")
all right, thanks for the explination :)
Thank you captain obvious. I did look at that. Most of the fix suggestions recommend sudoing the su command which i can't do cause i'm trying to switch to the admin account from a non admin account.
I can't give a 'intuitive, good' explanation for what `disown` does. I have never used it, but what it does is quite simple from this output (it has no manual): $ disown --help disown: disown \[-h\] \[-ar\] \[jobspec ... | pid ...\] Remove jobs from current shell. Removes each JOBSPEC argument from the table of active jobs. Without any JOBSPECs, the shell uses its notion of the current job. Options: -a remove all jobs if JOBSPEC is not supplied -h mark each JOBSPEC so that SIGHUP is not sent to the job if the shell receives a SIGHUP -r remove only running jobs Exit Status: Returns success unless an invalid option or JOBSPEC is given.
There is a pure `bash` method of creating directories using `bash`'s loadable builtins. ➜ enable -f /usr/lib/bash/mkdir mkdir ➜ type mkdir mkdir is a shell builtin These aren't guaranteed to be installed nor are they guaranteed to be in the same location but for personal scripts they work great. An `ls` of the above directory will show you what else you can load. They're kind of neat.
So you want to know if there's a way to redirect output to a directory that you make in the process of redirectoring the output?
Thank you very much for such a complete answer! But why aren't they loaded by default?
Doh, reddit ate my tildes, you get the idea..
Gotcha! Thanks!
It says ssh right in the center of the window bar
I don't get it. When you output data into a file you're writing standard out or error out to that file. What are you trying to do with a directory? Send data into a directory? The way I understand the issue I belive there are other ways to accomplish moving other files into a directory, then again I'm not sure what you're trying to do.
Hey, ZalgoNoise, just a quick heads-up: **belive** is actually spelled **believe**. You can remember it by **i before e**. Have a nice day! ^^^^The ^^^^parent ^^^^commenter ^^^^can ^^^^reply ^^^^with ^^^^'delete' ^^^^to ^^^^delete ^^^^this ^^^^comment.
Something like this? for i in {1..50} ; do alias="somebody" echo "Set-Mailbox mailboxName -EmailAddresses @{Add='$alias'$i'@yourdomain.com'}" &gt;&gt; file ; done
If I'm not mistaken this is terminal-access privilege level. You lack admin access to terminal, unallowing you to run the Su command. The proper way to troubleshoot this is to log in as an admin user and trying to run the Su command from there. Bare in mind if this is a work computer you might have filevault encryption enabled, not allowing you to access single user mode. Booting to single user mode would be the Mac equivalent to booting to tty with root previleges. If you do have filevault, you'll be requested the set firmware password. Anyway this is a Mac query, not a bash one...
Second line: [`als=alias$i@yourdomain.com`](mailto:als=alias$i@yourdomain.com) Mail function: `Set-Mailbox mailboxName -EmailAddresses @{Add='$als'}` You don't need '$' when declaring a variable and you wrote $1 instead of $i. In the mail function just add $als which is already the whole mail with the correct number. Next time can you please be more specific about what doesn't work and maybe post the output you get so is easier to help you out.
That's how important I am of lava, I thought the terminal window of my mac said it was bash. Whoops. As to the access rights, it was working til last Friday then just... Stopped working. Fnar
To understand where the problem is you might want to probe for su command access on other users namely admin. If you can boot to single user it's another check. But from that point on, I'd request Mac help.
Usually you can emulate simple typed commands through `STDIN`: `echo quit |config -s allow_remote True`
`sudo su -` inherits root environment (at least in Ubuntu) so you need to change root's .bashrc and not normal user. `sudo -s` is what sources the user `.bashrc` and inherit user's environment, so your code will work when you do `sudo -s` and not `sudo su -`.
If a simple pipe, as /u/bigfig suggested, doesn't work, you might want to consider using [Expect](https://core.tcl-lang.org/expect/index).
Got most of the way through answering exactly this way. But I wanted to be sure to add the note "here be dragons" to recommending expect. I've seen lots of naive approaches lead to tear when unexpected edge cases show up in production. Expect tends to be fragile and brittle in this way.
Bash, python, C++
This is the sort of thing bash is designed for. But here on /r/bash there may be some bias.
got it finally. `gsed -i "/bird/a \\\t\t\t\tELEPHANT" file.txt`
So during a bike ride, it occurred to my thick skull that essentially all I am trying to do is: 1. remove white space from everything that doesnt start with a hyphen 1. filter out everything that starts with a hyphen; flags, so they can still be passed on the command line. So I just used `tr` and `sed`: query=$( (echo "$@" | tr -d ' ' ) | sed 's/-fp/-fp /g;s/-n=0/-n=0 /g;s/-nosort/-nosort /g') gosearch -c -r -f $query | LS_COLORS="di=0;35:ex=1:" lscolors | fzf --ansi May not be the most elegant approach, but it does what it is supposed to do and I have not ran into any issues with it yet. Still open to better methods though, for education sake. Cheers.
This would have been the solution with awk: awk '{print} /bird/ {print "\t\t\t\tELEPHANT"}' file.txt
\&gt;or JavaScript (electron?) ha
`for` in bash is a bit fucky when it comes to spaces, and filenames with spaces are evil. Without actually sitting down and typing it out, my best guess is that `for` is seeing the space in what's returned from the `grep` pattern and splitting on that, resulting in your loop having the two iterations in your post. The first iteration echoes `blahblahblah:` and the second echoes `{`.
use `"$NAME"` instead of `$NAME`
The last price for Rightside Group, Ltd. (Nasdaq: NAME) was **$0.51** (as of 10:54 PM EST on Jun 13, 2019) The 52 week high is **$12.85** and 52 week low is **$7.17** Price action (weekly and monthly): **Weekly:** NAME made a weekly high of **$0.57** and a low of **$0.57** (for the week ending on Jun 07, 2019) **Monthly:** NAME made a monthly high of **$10.96** and a low of **$10.50** (for the month of May 2019) ^^I ^^am ^^a ^^new ^^bot ^^and ^^I'm ^^still ^^improving, ^^you ^^can ^^provide ^^feedback ^^by ^^DMing ^^me ^^your ^^suggestions!
use `"$NAME"` instead of `$NAME`
[https://zerobin.net/?b21e8f26dd4b7551#cINSKZDuba4In1Pw6q0VXwInpLSTqeG2878e0r7rDD4=](https://zerobin.net/?b21e8f26dd4b7551#cINSKZDuba4In1Pw6q0VXwInpLSTqeG2878e0r7rDD4=) &amp;#x200B; That's my original script, the `deluge-console` looks like this: [https://i.imgur.com/GHqzrqIl.png](https://i.imgur.com/GHqzrqIl.png) . It has a field at the bottom to enter commands. &amp;#x200B; I altered my script to: `deluge-console &amp;&amp; echo "config -s allow_remote True" &amp;&amp; echo "quit"` &amp;#x200B; But it just opens the deluge-console program with an empty field and shows the echo command results in terminal.
consider awk with printf. Awk allows for regex, and printf (instead of print) will give you absolute formatting control.
AutoHotKey is a macro program which will do these things much more easily than a real programming language. Why overcomplicate it?
Was having a look and turns out you can just use `deluge-client "config -s allow_remote True"`
I believe this is correct. Thank you. Still working on fixing it
No go, sadly
Assuming your pc is a Linux, yes, bash should be able to cover mostly of what you can do. JavaScript is not a back-end dev tool, so I think it's no good for automation..
Why not something like this? #!/usr/bin/env bash function help() { echo "Usage: $0 user min warning max invalid" exit 1 } [ -z $5 ] &amp;&amp; help echo "User: $1" echo "Min: $2" echo "Warning: $3" echo "Max: $4" echo "Invalid: $5" read -n 1 -r -p "Continue (Y/n)? " opt case $opt in Y|y) echo -e "\nYour code" #useradd -m $1 #passwd $1 -n $2 -x $3 -w $4 -i $5 exit 0 ;; *) echo -e "\nQuitting..." exit 1 ;; esac
That should be Captain Obvious.
Why not something like this? #!/usr/bin/env bash function help() { echo "Usage: $0 user min warning max invalid" exit 1 } [ -z $5 ] &amp;&amp; help echo "User: $1" echo "Min: $2" echo "Warning: $3" echo "Max: $4" echo "Invalid: $5" read -n 1 -r -p "Continue (Y/n)? " opt case $opt in Y|y) echo -e "\nYour code" #useradd -m $1 #passwd $1 -n $2 -x $3 -w $4 -i $5 exit 0 ;; *) echo -e "\nQuitting..." exit 1 ;; esac
AHK is Windows-only AFAIK, so it might not be the best recommendation for r/bash
click? you’re already not automated... lol
It all depends on the action you are attempting to automate. You are getting vague answers because you asked a vague general question, nobody knows the answer. If you had said something like, "I want to have an automation that runs this program and accomplishes these tasks" you would get more specific direction for that particular goal. Nobody can see whats in your head to give you a valid answer. Good luck.
How? Is it even possible to use JS or Electron to automate tasks?
Can you show a sample of what's in the files? And a sample of what you are hoping the output result will be?
 For ($i=0; $i -le 50; $i++) { als=alias$i@yourdomain.com Set-Mailbox mailboxName -EmailAddresses @{Add='$als'} } So thats what I got so far but Im just confused by what you meant by I the for needs (()). I just dont know where. als=alias$i@yourdomain.com : The term 'als=alias$i@yourdomain.com' is not recognized as the name of a cmdlet, function, script file, or operable program. Check the spelling of the name, or if a path was included, verify that the path is correct and try again. At line:2 char:1 + als=alias$i@yourdomain.com + ~~~~~~~~~~~~~~~~~~~~~~~~~~ + CategoryInfo : ObjectNotFound: (als=alias$i@yourdomain.com:String) [], CommandNotFoundException + FullyQualifiedErrorId : CommandNotFoundException
If you take off the `grep`, do you see the correct expected output of `awk`? (To avoid dumping a huge amount of data to your screen, replace the grep with head -10
I don't know what you're trying to do with the while loops because that doesn't match your first try at all. But if I understand your requirements correctly you want to extract lines that contains a word `foo`. This can all be done simply with awk alone awk -F, '/\&lt;foo\&gt;/{print $1","$2","$5","$6","$7}' /Path/of/my/directory/*.csv
I feel like ack could also be good here but I am but a padawan
Let's start from the beginning. By looking at your code I can see a few mistakes you made. \- I would not recommend to use **alias** as variable for a script because is already used by the system, use something like **als** &amp;#x200B; \- because we work in a **case-sensitive** environment **For** will give you error, write **for** instead, here an example of how it should be: for (($i=0; $i&lt;=50; $i++)); do # Insert your code here echo $i done \- when you declare the variable **alias** you don't need **$** because will give you an error, no need to space in between, no need to use **+** and you wrote **$1** instead of **$i**. Here's what how should like: als=alias$i@domain.com \- when you set the mail box name you don't need to write the whole email because is already set, you either use your variable or write the whole thing adding just the number in between with **$i** &amp;#x200B; Here's a full example: #!/usr/bin/env bash n=50 # Number of aliases name='alias' # Name of the alias domain='foobar.com' # Domain name # Loop for N times for ((a=1; a&lt;=$n; a++)); do echo $name$a@$domain Set-Mailbox mailboxName -EmailAddresses @{Add='$name$a@$domain'}" done
This is exactly what the `find` command was made for. find . -name "\*.csv" -exec grep "foo" {} \\;
Why not just: grep -h 'foo' *.csv or if you really need to only see those specific columns grep -h 'foo' *.csv | awk -F ',' '{print "$1","$2","$5","$6","$7}'
Hello ! :) I have already try to use find, but the result is : find: missing argument to \`-exec'
It works perfectly ! Thank U ! :)
Definately this.
See that last bit of the command? \`\\;\` That semicolon tells \`find\` here is the end of the command to be passed to \`-exec\`. However \`;\` has a meaning for \`bash\` as well. That's why it has to be "escaped" using \`\\\`. Without \`\\\` bash tries to process \`;\` as part of the command and strips it off before passing the rest of the line to \`find\`. With the escape character \`\\\`, \`find\` receives these arguments: . -name "\*.csv" -exec grep "foo" {} ; Wothout it, \`find\` receives this: . -name "\*.csv" -exec grep "foo" {} Now when we pass a command onto the \`-exec\` function within \`find\`, it could be any command, with any number of arguments. That means that \`find\` has no idea where to command to be sent to \`-exec\` ends. That's what the \`;\` does. So the error you're getting is probably saying "I don't know where the command I'm sending to \`-exec\` ends."
I was just thinking that! However like all things in IT, I've found that not being explicit gets me into trouble later down the line and recondite specifying the type. &amp;#x200B; e.g. `find /Path/of/your/directory/ -name "\*.csv" -type f -exec awk -F ',' '{print $1","$2","$5","$6","$7}' {} \; | grep "foo"`
Don't use "\*.csv". Because it's in quotes, the * doesn't need to be escaped. That means you're not searching for "*.csv". You're literally searching for "\*.csv", including the escape character in the file name. I'm not exactly sure what the `awk` statement is for. Is it just printing out the lines from the file? If so, use `grep` in the `-exec` portion instead. This appears to be the same thing but with extra steps and possibly unwanted side effects.
Node.js is a JavaScript runtime based on Chromes engine. You can use node to do many of the tasks as you would with a traditional scripting languages. I have scripts that move files, send emails, text messages, etc. Depending on your definition, most applications automate something no matter what language/framework they use.
Sounds like it doesn't know how to do your test statement. Run the script with debugging turned on (-x after !/bin/bash) and it will dump more info.
I'm trying to make a script that would notify me when my battery is low. I tried everything that I know but nothing seems to work. What did I do wrong?
Cant you use shellcheck to see of it's pure POSIX?
your tests are wrong, and variable pecentage contains "\[82", it should contain an integer I guess. it's should be : \[ $percentage -eq 100 \] or \[ "$percentage" == "100" \]
&gt;most applications automate something no matter what language/framework they use. True. Huh, Node.js. I might check it out later. Though I don't know Javascript.
Put a space after the builtin command \[ and another space before the closing \].
There should be a space after the opening square bracket and before the closing square bracket in all 3 if statements
It sounds like you want a scripting language. These are thinks like bash, batch, python, powershell, Ruby etc. You can start immediate with bash/python on Mac/Linux or Powershell on Windows. You can also install packages for most other languages on either platform. You can potentially automate things on your computer with JavaScript using node.js however you may prefer something like python. Electron is a technology that allows you to run full web applications as desktop apps. (Slack, visual studio code) If you are new to this area, check out "Automate the Boring Stuff with Python". The web version is absolutely free and the examples you gave are all explicitly covered by examples in the book. Good luck!
Yes the test statements do need to be consistent and relative to the output you expect to test against.
Thanks! Finally found the cause of error!
Thanks, I fixed it.
It is very cool. It is used regularly as the backend language in the MEAN/MERN (MongoDB Express.js Angular/React Node.js) web stacks. This allows developers to write their entire application in one language. Where Ruby has rails and python has Django/flask, node has express among others. I find modern JavaScript to be quite nice. I recommend learning it with a guide that uses ES6. (let instead of var, arrow functions).
Second line of ANY script in development should be: set -x Just saying, you will be able debug just about anything that way.
Does the `{}` just hold the results of `find`? Is it kind of like using `-` when piping? I've used `-exec foobar {} \;` many times, but never really looked into what was happening with the end there. I have been happily ignorant as long as the results were what I wanted.
Good points.
Yes, `{}` holds the output of the `find` command. Note it does it one at a time, so that the `-exec` command gets executed for each file that `find` finds satisfying the search criteria. Let's suppose the command find . -name "*.csv" -exec grep "foo" {} \; finds these files: A.csv B.csv D.csv Then `find` would actually execute these commands one at a time: grep "foo" A.csv grep "foo" B.csv grep "foo" C.csv
Man pages to the rescue my friend... &amp;#x200B; \# man find
Shell check is a linter that you will really help you learn. Most IDEs offer it as a plug-in. https://www.shellcheck.net
 while : do read -p "Enter username min warning max invalid:" us m w M i || exit [ -z "$i" ] &amp;&amp; continue echo "User \"$us\"" echo "Min \"$m\"" ... read -p "Continue? y/n" yn || exit [ "$yn" = y ] &amp;&amp; break done useradd -m $us passwd $us -n $m -x $M -w $w -i $i You were after that kind of "go back" ?
'\[' is actually a binary: &amp;#x200B; `$ which [` `/usr/bin/[`
Not OP but out of interest is that literally put in line two of the script file "set -x" without quotes?
Just a note because no one's mentioned it, but your script will only do a notify-send if the battery percentages are EXACTLY 100%, 15%, or 5%, not values less than or equal to the desired thresholds...
Yes
Teach the man to fish - get a bash linter. Thank me later
1. https://groups.google.com/forum/#!topic/comp.unix.programmer/PRgTboPl8NQ 2. I don't think there is a way to get a random number purely with built-ins. You have to use `od(1)` to read from /dev/urandom.
That's using parameters right? I wanted to create an interactive version with variables.
I have to read more bash to understand that lol What are the &amp;&amp; and the \"$ used for? Doesn't \ ignore the next command?
Yes. Or add "-x" to the hashbang, liks `#!/bin/bash -x`. Or call the script with `bash -x myscript.sh`
You must be using your shell script to do things they shouldn't be doing, if a 4x speedup is going to make any significant difference... Since you're new to this I'd suggest sticking with bash, since it's everywhere.
Arguments. I always try to use them as much as I can, makes everything quicker.
Yep. It will go through each step on screen as it goes through it and you will visualize where it failed.
For 1 you can either emulate it with `stty` but i think you can also enclose the time consuming thing in `{}` with stdin redirected to /dev/null. For 2 you'll have to use either /dev/random or `awk` which has a builtin `rand()` function. And speaking of awk, maybe that's a better thing to use depending on what you are doing, it has associative arrays too and is available on posix systems.
Shellcheck is very useful also.
Thanks for this my guy, gonna be truly helpful
What colorscheme is that?
I believe there is a list of these builtins in the manpage as well.
It is bash but bash is just the interpreter, because of POSIX standards things should work the same on Mac and other *nix operating systems but that isn't necessarily guaranteed
Do you know of any resources for learning more about handling jobs in bash?
Was going to ask the same thing plz let us know!
Both of my implementations pass shellcheck, but it's a syntax-only check. POSIX specifies more than just sh syntax, like standardized utility specifications such as [tput](https://pubs.opengroup.org/onlinepubs/009695399/utilities/tput.html) that need to be taken into account. For example, in my POSIX version I only make use of `tput clear` (POSIX specifies `tput [-T type] clear|init|reset`) but in my bash version I can replace the hardcoded vt100 sequence `printf '\033[1m%s\033[0m\n\n' "$PWD"` with the terminal agnostic `tput bold; echo -e "${PWD}\n"; tput sgr0` because I assume ncurses tput, not POSIX tput.
No worries. That is what OS is all about.
You could also just remove line 3 and change line 5 to `$precentage=$(acpi | cut -b 25-26)`, unless you're going to use `$bat_status` for something else later.
I'm just exited of its advantages, which isn't just speed which matters a lot, but also it is more secure and standardized.
I could be wrong, but it looks like dracula with incorrect term/vim settings (no 256 colors support, or no termguicolors?)
I got my (limited) knowledge of this from a CS course. We had the [book](https://www.barnesandnoble.com/w/practical-guide-to-linux-commands-editors-and-shell-programming-mark-g-sobell/1101635876) "A Practical Guide to Linux Commands, Editors, and Shell Programming" from Mark G. Sobell as guiding book. (It's long tho)
Thanks a lot for the help!!
"\[" is a real command name so you have to put spaces on both sides to make it understandable by bash
There are situations where you might not want keep your executables in the standard /bin etc directories -- or as a regular user you might not be allowed to on a multiuser system.
Whatever commands you type, they don't just come out of nowhere. When you type a command or just the name of a executable file the shell looks in your PATH directories for a file with that name. It can't just scan your whole file system for what file to execute. So for example I have `~/executables` in my PATH because that's where my custom scripts are.
Great follow through with the explanation!
$PATH is the directory where the system will look for binaries for programs that you run. In case the binaries for the programs that you run are not in $PATH, you will have to specify the directory where the binaries are stored everytime you run that program.
There's a debugger ( [https://medium.com/@faizanahemad/debugging-bash-shell-scripts-df52c5428235](https://medium.com/@faizanahemad/debugging-bash-shell-scripts-df52c5428235) ) and also you can get shellcheck both for vscode. &amp;#x200B; Bash is file-based, rather than object. Everything is a file. A directory is a file, a file is a file, a stream is a file. Your output is text from those files. You then use various stream editors/file manipulation tools like grep, sed, awk, etc. to grab the appropriate text from that output.
The purpose is so you don't have to type the absolute or relative path for each executable file that you wish to run. The `$PATH` variable is a `:` (colon) delimited string of directories on your file system that are searched to find executables. When you type a command on the command line and hit Enter, the shell searches the contents of your `$PATH` variable from left to right and uses the first match it finds. If it doesn't find a match, you'll receive a `command not found` error. For example if you have the following `$PATH` variable. ``` export PATH="/usr/local/bin:/usr/bin" ``` And you type this command. ``` $ myapp ``` The shell will try to find `/usr/local/bin/myapp`. If it exists it will execute it. If it doesn't exist the shell will try to find `/usr/bin/myapp`. If it exists it will execute it. If not it will move on to the next directory in `$PATH`. Since there's no more directories to search, the shell will return a `command not found` error.
It's dracula color scheme
You just set your variable like normal, for example: x=3 The variable will be created for your whole script, even if you do this from inside a function. Here's an experiment about this at the command line: $ foo() { x=3; } $ echo $x # nothing is printed here because the variable doesn't exist yet $ foo $ echo $x 3 What you see here is the default behavior in bash when you write to a variable from inside a function. If you want the opposite behavior and do not want your function to write into a global variable name, then there's the "local" keyword you need to use: $ foo() { local x; x=3; echo "x is $x in here"; } $ x=5 $ foo x is 3 in here $ echo $x 5 The last thing to know is the following, which is pretty strange about bash compared to other programming languages: When you use "local" inside a function to overlay over a global variable with the same name, then when your function calls another function, that other function will not see the global variable anymore. It will instead see the local variable from the first function. I don't know how to explain that better. Here is an experiment at the command line showing what I mean: $ foo() { local x=3; bar; } $ bar() { echo "x is set to $x"; } $ x=5 $ bar x is set to 5 $ foo x is set to 3 $ bar x is set to 5
Dash? Why Dash? Are you running scripts on a soviet calculator? In Linux it is only included for non-interactive system scripts to fasten boot times according to the official Debian and Ubuntu resources. It's obvously faster in some cases, but I have never actually seen use cases that really benefit the user, and the lack of many features just makes it worse.
Great advice! Been doing this as a professional for a long time, i still use tools like this, sometimes you miss things.
Excellent explanation, although I don't think that type of shadowing is strange. It makes the most sense given the two previous behaviors.
\[ condition \] &amp;&amp; action is just shorthand for if. Likewise,|| is if-not. continue and break affect the while loop. exits handle input errors, ssh disconnect for example. Not "$ but \\", to show quotes around each $variable.
ah man, just use python whenever out of your comfort zone imo. The bash will come. You're coming from the other side of the spectrum from most sysadmins.
`read -s -p “Password:” password` read takes user input, -s disables echoing of the input. -p provides the prompt.
Using extended seems like a reasonable approach. They're good for "custom metadata" like this. However, it might limit the way you can use these files. For instance, `find` does not have a predicate for extended attributes. Perhaps have _another_ directory containing symlinks or hard links to just the files you want to consider wallpapers?
&gt; you can use these files In Soviet Russia, these files can use **you**! ^(this post was made by a highly intelligent bot using the advanced yakov-smirnoff algorithm... okay, thats not a real algorithm. learn more on my profile.)
On Ubuntu, you can put them into `~/bin` and they are automatically in your path. Useful.
Yeah, but I don't think it is safe to store a password in a simple variable. Isn't there a way to call something like `sudo su` inside a script? I tried it but it doesn't prompt me to insert the password. Thanks again.
Prefer `type` over `which`. It will tell you there's an external command in addition to the builtin $ type -a [ [ is a shell builtin [ is /bin/[ Run `help type` for more.
For the last point, I think the word you want is "scope". It is totally normal and works like this in other languages. `local` is for the scope of the function and therefore its sub-functions.
I cant understand your question
You can get view count for each individual video in that playlist using this: `youtube-dl --ignore-config --get-filename -o "%(view_count)s" https://www.youtube.com/playlist?list=UUriIuQZpMi6gEt_2P7xKCww`
&gt; you can get view count In Soviet Russia, view count can get **you**! ^(this post was made by a highly intelligent bot using the advanced yakov-smirnoff algorithm... okay, thats not a real algorithm. learn more on my profile.)
 wget "https://www.youtube.com/playlist?list=UUriIuQZpMi6gEt_2P7xKCww" -O - | grep -oE '[0-9,]{1,6} views' | sed 's/[^0-9]//g' should do... I built in some slack, but doubt that that `6` will need to become a `7`...
&gt; yakov-smirnoff algorithm I think that you are confusing it with the Bogoff-smirnoff conjecture
 #!/bin/bash if [ "$UID" != 0 ]; then exec sudo "$0" "$@" fi # Do root stuff echo Hello root $UID
 curl -s https://www.youtube.com/playlist?list=UUriIuQZpMi6gEt_2P7xKCww | tr '&gt;' '\n' | grep views | cut -d ' ' -f1
Using it has really helped get rid of some old bad habits. Great tool
If you have already sudo-ed in your current session it won't prompt you again for 15 minutes (I think it's 15).
I don't think there is a way to call `sudo` commands in a script. If you need superuser in a script you're going to have to run the script as a superuser. However, you could just put in a simple check before the script or something to lock out those you don't want accessing the script. Have the password stored in a variable (lets say $password). Declare that the password is stored in a file that only the permitted user has RW access to. No one else should have either read or write to that file. So something like below (probably a shit ton of errors but I wrote this in 5 minutes): `password=$( cat /usr/BuyMyBackSide/password )` `read -sp "Password:\n" userPassword` `if [ "$password" = "$userPassword" ]` `then` \ `#stuff` `fi`
Silly question. Why not just make it only called through sudo? sudo mysillyquestion.sh Does stuff Returns whatever Or is it that you just want to have users enter a password to pass to the script?
You could also read the file \` /sys/class/power\_supply/BAT0/capacity \`. That would get you the number wihtout parsing.
Bash is old, so has none of the advanced conveniences as PowerShell. For what it's worth, you can run PowerShell on UNIX/Linux systems with project Mono, but I know that Bash is pretty universal so you'll probably need to learn it anyway. Bash does everything with strings, rather than objects, and there is no built-in JSON parsing. Bash can't really do computations on data any more complex than a CSV file, unless you are really a masochist. There are array data structures: SOME_ARRAY=( zero one two three ); ANOTHER_ARRAY=( "${SOME_ARRAY[@]}" four five six ); echo "${SOME_ARRAY[@]}"; #print the whole array echo "${SOME_ARRAY[3]}"; #print element 3 echo "${SOME_ARRAY[4]}"; #print element 4, undefined elements evaluate to a null string echo "${ANOTHER_ARRAY[4]}"; echo "${ANOTHER_ARRAY[@]}"; Integer arithmetic is built-in: X=5; let X="$X + 1"; expr "$X" \* 3; if (( X / 3 == 2 )); then echo YES; else echo NO; fi You can iterate over lists using `for` syntax, but you cannot easily pipe list data structures between Bash functions or to other commands and expect them to retain their list structure, because piping will convert the list back to a CSV-style string. In Bash, data travelling between pipes is always formatted as plain old strings separated by line breaks. You have to rely pretty heavily on regular expressions to extract structure from most of the Bash command output, so you must often make use of the `sed` and `awk` commands. Perl is good with regular expressions, but I find AWK to be sufficient 99% of the time. ### Debugging For debugging, the best thing you can do is set the `-x` flag, which will print each line of the script as it is evaluated, but with the variables expanded so you don't have to guess what is being evaluated. Write this line at the point in your script where you want to begin debugging. set -x #enable debugging ... commands to be debugged ... set +x #disable debugging or to debug everything an entire script file, write this at the top of the script file: #!/bin/bash -x
In a word: convenience
I think your post got reformatted by the markdown gremlins. Are you asking what the difference between back ticks and dollar-sign, parens is? X=$(echo test) Vs X=`echo test` Not really a difference (I think) but I find the first to be more readable
The first one is saying to grab the 25th and 26th column from the output of acpi, the second one is using regular expressions to find a matching pattern (it also seems like it would not work, possibly you made a mistake when pasting it) As /u/Erelde mentions in their comment, it would be both easier and less prone to error to read the data directly from the kernel device data i.e. the /sys/class location.
Safety-wise, your environment variables are only visible to your sub-processes if you export them. It's *not* visible to other users unless they already have root (note--this *could* be a security issue but if you don't trust the people you give root to you shouldn't have given it to them--there's a *lot* of other ways someone with that power can compromise your systems.) That said, what I would do is either just let sudo prompt for the password as it normally does, or make a script that does the exact specific thing you want to allow users to run as root and configure sudo to allow that without a password.
Pardon my limited experience but: how can you get that output if inside the for loop you are echoing the array using $1 as index instead of $i? &amp;#x200B; I do not have Deluge installed so I could not test it but, you can get the idea: #!/usr/bin/env bash D_USERNAME=test # deluged username D_PASSWORD=test # deluged password D_HOST=localhost # deluged host D_PORT=58846 # deluged port query=$(docker exec deluge deluge-console "connect $D_HOST:$D_PORT $D_USERNAME $D_PASSWORD ; info --sort=progress " | grep -e $ usage() { printf "\n Usage: $0 [-i info] [-c clean]\n" exit 1 } info() { for (( i=0; i&lt;${#query[@]}; i++ )) do echo "${query[$i]}" done } clean() { cur=$(echo $query[$i] | cut -f 1 -d '/' | cut -f 2 -d ' ') tot=$(echo $query[$i] | cut -f 2 -d '/' | cut -f 1 -d ' ') if [ "$cur" == "$tot" ]; then echo "Removing iso..." else echo "Not done yet!" fi } [ -z "$1" ] &amp;&amp; usage case $1 in -i) info ;; -c) clean ;; *) usage ;; esac
 acpi | cut -b 25-26 as the [manpage](http://man7.org/linux/man-pages/man1/cut.1.html) suggests cuts out bytes 25 to 26 of the output of `acpi` &gt; It works fine if the battery level is in double-digits. But when the battery is full or below 10% some numbers get cut out, because they are not in the right position. You evidently have not tried running it while you are charging..... Some numbers will get missed out when at 100% since you are only `cut`ting 2 characters.... 3 are required for "100" `acpi | grep -P -o '[0-9]+(?=%)' ` this `grep`s using `-P` [PCRE](https://perldoc.perl.org/perlre.html#Extended-Patterns) patterns for 1 or more occurrences of a digit followed by a `%`, but *excludes* the character from being returned in the results, and `-o` only printing the found pattern As you have probably figured, /u/erelde's suggestion to read a file containing nothing but the current percentage is probably easiest... But if you must use `cut`, a delimiter of a comma would let you choose a field containing the percentage, albeit terminated with a `%`
The difference between the two syntax that users should remember is "don't use the backticks syntax". The real difference has to do with subshell escaping : x="$(command2 $(command1 $var1))" # will escape all arguments correctly
Thanks a lot that'll be helpful to me :)
Unpredictable and should be the responsibility of the user to manually add paths that are desirable outside of the system defaults.
Assuming you want to write in a file your current path: &amp;#x200B; Echoing the system variable $PWD into the file foo.txt using '&gt;' echo $PWD &gt; foo.txt cat foo.txt &amp;#x200B; Result: /tmp
Yeah, this kind of behavior for scope does exist, but you have to be realistic here: which other languages might a person have seen where it works like this? I think I've seen it in a LISP a long time ago. Right now, it doesn't work like that in any language I can think of to try here. I thought maybe Javascript, but it doesn't, see here: js&gt; var x = "hello"; js&gt; function foo() { var x = "hey"; bar(); } js&gt; function bar() { console.log(x); } js&gt; foo(); hello That `bar()` function is seeing the global `x`, not the one from inside `foo()`. Perl is the same: $ perl -E 'my $x = "hello"; sub bar { say $x; }; sub foo { my $x = "hey"; bar; }; foo' hello Haskell is the same: λ&gt; let x = "hello" λ&gt; let bar = x λ&gt; let foo = bar where x = "hey" λ&gt; foo "hello" I think I've only seen the same behavior as in bash in some LISP in the past. Right now, in a LISP that was installed here it also doesn't work like that: scheme@(guile-user)&gt; (define x "hello") scheme@(guile-user)&gt; (define (bar) (display x) (newline)) scheme@(guile-user)&gt; (bar) hello scheme@(guile-user)&gt; (define (foo) (let ((x "hey")) (bar))) scheme@(guile-user)&gt; (foo) hello Here's LUA, it again doesn't work like in bash: &gt; x = "hello" &gt; function bar() print(x); end &gt; bar() hello &gt; function foo() local x="hey"; bar(); end &gt; foo() hello
The second one
even quicker: `pwd &gt; foo.txt`
I forgot to say I'm working with dash, however the condition would just be: if [ "${USER}" != "root" ]; then exec sudo "$0" "$@" fi Thank you very much!
I am not too invested in this, but your argument confuses me. The path **is** the Ubuntu system default, so the last part is not true. And unpredictable? How so? `~/bin` is the first thing in your path, and gets priority. Maybe unexpected if you didn't now about it, but absolutely predictable.
Caution: &gt; file sets the length of the file to zero.
You better explained my example, thank you.
Should've mentioned, thank you.
Thank you both for such a quick reply.
I am still curious though, how would one go about trying to do it the " | " pipe way ? Just curious.
What does it mean by "the length of the file" ? And why should I be cautious about it... I'm sorry for being an utter noob to all this.
`&gt; file` sets the length to zero every time (basically erase its content) `&gt;&gt; file` add the output at the end &amp;#x200B; Try it in the bash and see the results.
Actually you can, probably but not often because everybody's so used to `&gt;` &amp;#x200B; Pipe example: pwd | tee file.txt
Bash is really cool. I will try these right away on my computer.
Consider it to mean "overwrite."
Ok I see what you mean, because I tried it in python: x = 'hello' def foo(): x = 3 bar() def bar(): print("x is set to " + str(x)) foo() it prints `x is set to hello` because yes, in the scope of `bar` there is no `x` so it has to search it at the global. I think the bash specialty that you mentioned is that it seamlessly transfers env var to sub functions. (This might not be well put please enhance if you can)
Got it !
Have you looked through this? https://en.m.wikipedia.org/wiki/PATH_(variable) In short, it is used for .. &gt; specifying a set of directories where executable programs are located. In general, each executing process or user session has its own PATH setting. The page should also cover some of the answers already provided like placing commands in /bin, etc. Hope this helps..
**PATH (variable)** PATH is an environment variable on Unix-like operating systems, DOS, OS/2, and Microsoft Windows, specifying a set of directories where executable programs are located. In general, each executing process or user session has its own PATH setting. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/bash/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
Your script seems broken right now. Isn't that $query variable just a single text variable instead of an array with several elements? Your 'for' loop is probably doing nothing and the script is just running a single "echo" command, same as just doing `echo "$query"` instead of the whole 'for' loop. If the thing you have is really one large piece of text and not an array, then Awk and Perl have a "paragraph mode" where they read input text in multiple lines by splitting the input where there's empty lines. With awk, I don't know how to search around inside that kind of multi-line text, I only know for perl. For awk, you activate the paragraph mode by adding a `-v RS=` parameter, and in perl you do it by adding a `-00` parameter. About perl, here's an experiment about finding the interesting parts inside your example input: $ perl -n00E '($id) = /^ID: *(\S+)/m and ($x, $y) = /^Size: *(.*?)\/(.*?) *Ratio/m and say "x = $x, y = $y, id = $id"' testfile x = 1.2 GiB, y = 1.4 GiB, id = 44d7d1c6da6cb5f8992ac3b44b4695b2470536a6 x = 1.4 GiB, y = 1.4 GiB, id = 7a144ee9915350d0725775b73a38be6d15bcde08 Adding a text comparison for the two sizes to that looks like this: $ perl -n00E '($id) = /^ID: *(\S+)/m and ($x, $y) = /^Size: *(.*?)\/(.*?) *Ratio/m and $x eq $y and say $id' testfile 7a144ee9915350d0725775b73a38be6d15bcde08
Nice
~/bin is a system default on Ubuntu
Sometimes one might want to completely empty (i.e., 'zero out') a file but to not actually delete (i.e., remove) the file. There are cases where a file must exist but there is no requirement that there is any content at all in it. Pretty much like wanting an empty glass so you can pour the contents of your choice into it.
This is a lot to take in for me. I have the text string stored to a variable called query. However...your example shows a file instead. Is there a way to run this on query? When I run your example..the prompt just hangs.
This is getting close!! The problem is there are 2 isos with matching data and it outputs 1 item that is not 1 of the 2 with matching data counts. I need to read on these array things.
There is something wrong with your array I recon. Try to analyze the output you get from it and match it with the script I wrote.
Probably not very useful to note, but you could also do this with gawk `acpi | awk -F '[,: ]+' '{sub("%",""); print $4}'`
Take that command inside the `$(...)` on that line where you set your $query variable. Add the perl command line to the end using a `|`. Try to run that directly at the command line, don't do it inside your script. Experiment with what your command originally prints and what it print with the `| perl ...` added to the end. I can't really help and show an exact example of what you should try to run because you didn't actually show your full script in your original post. In your original post, that one line where you call docker and set your variable $query is cut off. You perhaps made a mistake with copy+paste from the terminal window where you worked here into the web browser.
&gt; I have tried so many combinations try [reading something](http://tldp.org/LDP/abs/html/comparison-ops.html) instead of trying random combinations.
Have you tried like this? if [ "$count" -eq 1 ]; then echo "exiting" exit 1 fi **Little suggestion:** when you get stuck like that try to echo the variable and isolate the part of the script where the error is. Check again the if statement and how it handles integer and strings. [Here](http://tldp.org/LDP/abs/html/comparison-ops.html).
I don’t think `(( ))` is what you are after. ``` ((expression)) The expression is evaluated according to the rules described below under ARITHMETIC EVALUATION. If the value of the expression is non-zero, the return status is 0; otherwise the return status is 1. This is exactly equivalent to let "expression". ```
VARIABLE=`command_with_output` Also for new style VARIABLE=$(command_with_output)
Naw, it's basic locking and atomic operations. What if something else spawns your script and does it a few times in rapid succession. Just add a lock file, and boom your done.
Yes, but that's using command substitution. I'm looking for something to redirect the output without using the command substitution method or a viable way to catch the name of the command inside the variable. For example: VAR=$(program command) After that I want to be able to catch the "command" name in another variable. I figured, I can just add another variable with the command name after that but I would have to do that for all the command substitution tasks and there are a lot. Thanks for your answer!
I hope the following works, I've not tested it much: script_name=${0##*/} if pgrep -x "$script_name" | grep -q -v $$; then echo "exiting: $script_name is already running." exit 1 fi That `${0##*/}` is `$0` with the path cut off so that just the file name is left over. That should then be the same as what's showing up in the output of `ps -e` in the name column. `pgrep` is a tool that I think is installed by default on most distros. It's a sort of combined ps and grep. What the tool prints is a list of process IDs that match your search. In the `grep -v $$` part of the line, the `$$` is a bash variable that holds the process ID of the current script. That `grep -v $$` command is deleting that ID out of the list that was printed by `pgrep`. This is so that the current process gets ignored in the search. The `if` will check the exit code of the `grep` part of this whole command line. And grep decides on its exit code by seeing if it could find a search result or not. This then makes it so you don't have to actually do any line counting or anything else with the actual search output of grep, you can just write `if grep` and you will know if there were results or not. About that `(( count = 1 ))`, that's an easy mistake to make. That `=` there actually isn't a comparison, it's an assignment. The comparison would be the `==` operator. When you used `=`, you were writing a "1" into the $count variable. The line was then always seen as "true" by the `if` because the true/false result of `((` is decided by the number result of it. A zero result means "false" and any other number means "true". Here's an experiment at the command line about what I tried to explain: $ x=hello $ echo $x hello $ if (( x = 12345 )); then echo true; else echo false; fi true $ echo $x 12345 In this experiment, that `=` inside `((` is overwriting the original value of $x. And then next because for `((` any number that's not zero means "true", the result of the `if` is "true".
&gt; Maybe unexpected if you didn't now about it Exactly. I'm saying IMO ~/bin as being part of $PATH shouldn't be a system default on Ubuntu. Most distros don't set it as part of $PATH and for good reason--$HOME should be allowed some freedom in customization. The inconsistency itself is problematic especially when the benefit it yields is so trivial. Users may decide to put scripts in /usr/local/bin, ~/scripts, ~/opt, ~/.bin, etc. and they should expect and experience the same thing as those who use ~/bin in their $PATH--that it is *not* in $PATH by default and is something they can add to it. `~/bin` is not a standard path or at least not as standard as say /usr/bin, so there is very little reason to have this as the system default and it being so is unexpected because of inconsistency with general conventions. I do use ~/bin as part of path but I prefer manually adding it to $PATH as a matter of principle.
Apparently you can use a range in the url like so: [http://example.com/file\[1-100:10\].txt](http://example.com/file[1-100:10].txt) &amp;#x200B; I keep getting back \`&lt;head&gt;&lt;title&gt;500 Internal Server Error&lt;/title&gt;&lt;/head&gt;\` though. I've been trying to use curl with cookies but no success so far. Am I at least on the right track?
Or set -x
Apparently you can use a range in the url like so: http://example.com/file[1-100:10].txt I keep getting back &lt;head&gt;&lt;title&gt;500 Internal Server Error&lt;/title&gt;&lt;/head&gt; though. I tried using cookies but I didn't even notice data being written to the cookie file I specified. I lucked out though and copied a working curl command from `developer tools&gt;network tab&gt;html&gt;copy as curl`. I then pruned the command until it wouldn't work any more. It seems that adding -H 'User-Agent: Mozilla/5.0 (Windows NT 6.1; rv:60.0) Gecko/20100101 Firefox/60.0' is necessary to avoid the 500 error. Is it possible for sites to block requests with curl as the header or something?
Just a note: There is a very nice command called pgrep . At minimum, it removes the need for grep -v grep. But it does a lot more than that. There is an unfortunate issue with it, they changed the command line parameters on the command. But it is still better than using ps -ef.
Are you trying to write a script that properly prints custom error messages? Or are you trying to troubleshoot/debug a script? You can tell BASH to print the line it is about to interpret: set -x Another option, could be to build the command up in an array, and then use `eval ${command[@]} &gt; /tmp/cmd.out` Check the return code, and if it is a failure, then display "${command[@]}" and exit. If the command was successful, then load the contents of the temp file into a variable: VARIABLE=$(cat /tmp/cmd.out)
Yes, I'm trying to print some custom error messages because my script is mostly a wrapper for a program but this program have multiple commands obviously, and I want to know what command failed if any. It also uses another tools like rsync so I made it so it could report if it is another tool like rsync, it will display "rsync" failed but if it is the main program it will say "command" failed. That is a great approach. Thanks!
To answer the question in the title and not consider other alternatives, you can do `program command | read -r variable`.
Wow, fuck off. There's nothing wrong with asking questions. How do toy now they didn't write the script themselves? Did you watch over their shoulder as they copy pasted it from stackoverflow? Not only that, why can't they learn bash with this script. Stop gatekeeping and start being helpful if you're going to post on this sub.
Turns out I was using the `if` statement incorrectly. The `*` apparently is supposed to be outside the quotes and because the end of the first part of the output is the name of the program, now I can do this: if [[ "$(echo $latest_cmd | awk '{print $1}')" = *"program" ]] ; then echo -e "There was a problem with [$cmd]... \n[$(echo $latest_cmd | awk '{print $2}')] failed with exit code $exit_code" fi It works correctly now. For example, I have this in my script: cmd="$1" trap 'prev_cmd=$this_cmd; this_cmd=$BASH_COMMAND' DEBUG variable=$(program command --flags options) latest_cmd=$prev_cmd exit_code="$?" latest_error if [[ "$(echo $latest_cmd | awk '{print $1}')" = *"program" ]] ; then echo -e "There was a problem with [$cmd]... \n[$(echo $latest_cmd | awk '{print $2}')] failed with exit code $exit_code" fi Now the output when there is an error is as follows: WARNING! There was a problem with [script_command] [program_command] failed with exit code 130 The script is too long to post it here. It has multiple functions which are the "script commands" and those functions wrap up sometimes a couple of programs for the program itself, to simplify the usage and for automation. Thanks a lot for the help!
I tried that and didn't work for me. Thanks for your answer!
`!=` does a glob match. You probably want `!~` there, since you've got a regular expression on the right-hand side.
Thank you for that explanation :) Very informative! Converting everything to globs does indeed work. `if [[ "$(file --dereference --mime "$FILE")" == *binary* &amp;&amp; $FILE != *.@(jpg|jpeg|png) ]]; then` I am still getting other issues, but I'll have to take a closer look at the rest of the script, I am thinking I probably screwed up the logic elsewhere. The goal here is too only display this text for binary files, but image files are being detected as binary, so I am trying to filter them out by extension. Although the message is still being printed for images. Not a big deal, may take another approach entirely or just settle with it as is. I will mark this as solved since the code is technically working as far as I understand, and say thanks for your time and teaching me something useful :) [image of result](https://imgur.com/a/YHMrA7A)
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/PKC4jqs.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme)^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20erb3tta)
You seem to trying to do a negate match on the second `[[` .You can do it by putting `!` before a match `=~` Here is an example that may help you: `[[ ! 'foo.png' =~ \.(jpe?g|png)$ ]] || echo "not a image"`
Hahaha wow, nice one. You failed harder than my script.
Hmm, I'm leaning towards the idea of symlinks. A problem is that files of the same name will get overwritten if I use the name of the symlink as the name of the actual file, e.g. if I want to symlink all files from ~/pictures/2018-tokyo-trip and ~/pictures/2016-hawaii-trip, then it is likely pictures are named 001.png, 002.png, etc. in each folder. Also, when I want to remove the wallpapers (but keep the files, so essentially just remove the symlink), I most likely want to remove all symlinks under a directory, e.g. I want to remove wallpapers from the 2018 Tokyo trip. Would it be too much of an effort to somehow rename symlinks in such a way that guarantees they are unique so not overwritten if I want to add wallpapers of collection of pictures from multiple directories? I was thinking perhaps prefixing the symlink name of all symlinked files with the name of the directory they are from, e.g. 2018-tokyo-trip-001.png. Then, if I want to remove all wallpapers from a collection, I can remove using e.g. `rm 2018-tokyo-trip*`. Honestly my bash/programming is terrible so not sure if this is the best approach or too hacky to implement. Right now the script looks like [this](https://pastebin.com/8fyQ7gsp) without implementing symlinks yet.
This script also incorporates a lock file. When the script starts it finds X amount of files (other scripts) that it executes. While doing so it has a locking file ("stop") that - should the script be executed again, will make sure it exits. I normally run this script from cron every 1 minute, which is the lowest time resolution. Instead I have now modified the script to run in a loop with a 1 second sleep. To make sure that the script is running though I would like cron to now start the script every 1 minute where it will automatically exit if it is already running. This way should it stop for whatever reason cron will make sure it starts again.
Thank you, and yes I had echoed the variable so I knew it had the right value. I was however a bit confused with how bash handles strings and ints. Your example works perfectly, but I modified: if [ "$count" -gt 0 ]; then Again, thank you!
I just woke up so I haven't quite had the time to process what you wrote (in head nor cpu) but from the sounds of it you've generalized the "am I already running?" part so that it can be included in any script without modifying it? It will also handle scripts with variable filenames by the looks of it. If so that is brilliant, thank you! I will give it a test after my morning coffee.
&gt; Wow, fuck off. fuck? If the guy cannot fucking read a fucking manual and fucking tries `many combinations` of comparisons and - as per posted script, *assignments* when it is *not* what they are wanting - without knowing what they are fucking doing, then I will suggest something a bit fucking simpler...
Dubug mode is even better!
May I ask what kinds of automation you need to have? Are we talking simple tasks or complex? There's difference between an alias: alias ll='ls -adF *' # List all files, hide current and parent directory, show / for directories And a function: # Create a Bash file from template function msh() { if [ "$1" ]; then if [ ! -f "$1.sh" ] &amp;&amp; [ ! -f "$1" ]; then printf "${Green}Creating ${NC}$1\n" printf '%s\n' \ '#!/usr/bin/env bash' \ '# Description here' \ &gt; $1 chmod +x $1 else printf "${Red}File already exist.\n" fi else printf "${Red}No name specified.\n" fi } &amp;#x200B; Depends on what you need you can use different tools. For me it came while I was working everyday and needed to save time doing simple tasks or maintenance for example. Also, learn how to manage your dotfiles, for instance I have mine linked from my personal Github folder, [here](https://github.com/0ero1ne/config) if you want to get an idea. Also [here](https://dotfiles.github.io/) a list of user's configurations.
Honestly, I followed a few tutorials but it didn't really stick. What really helped is that I started using Linux more and any time I did a task, I tried to do it in a script so I could repeat it later. I'm not sure what things you do regularly in your career/workflow but try to automate them. Google when you get stuck. You really don't need to know all that much to start. My first bigger scripts were: 1. Bootstrapping a new VM. Set up hostname, local time, auto updates, join to domain, etc. 2. For fun: wrote a script that would set up a ricey ArchLinux install on my laptop from live USB to ready to use. Inspired by r/unixporn You could probably do all of the above without much more than echo, cp, and sed.
Use [flock(1)](https://linux.die.net/man/1/flock) for this -- it has a mode where it exits with an error code if the lock is already acquired by another process. This way you're better protected against race conditions because it's an atomic operation. Use it like this: if ! flock -n /path/to/lockfile; then exit 0 fi
 I think that is a pretty vague answer. Every time 'program' evaluates to true 'myotherprogram' is executed, until 'program' evaluates to false, then the loop finishes
It is more difficult than that to see if another process is still running.. this is more of run program, if it exits zero (true) then run myotherprogram, and when myotherprogram exits, repeat that sequence until program exits non zero and breaks the loop.
Very easy! &amp;#x200B; \- go to /tmp \- create a file name "program" and edit like this #!/bin/bash echo "myprogram" \- create a file name "myotherprogram" and edit like this #!/bin/bash echo "myotherprogram" \- chmod +x program myotherprogram \- while ./program; do ./myotherprogram; done &amp;#x200B; See what happens.
When `program` returns true, it executes `myotherprogram`.
Infinite loop is my guess
Yeah, I was getting the impression that it's a lot more like VBScript. Didn't go too deep with that but it pretty much seemed like everything was essentially strings in terms of parsing.
So many assumptions. Try living in a less angry world, my friends. I think you'll be happier there :)
Dick. Lol
There might be a bit of sarcasm in it, but, isn't 'practice' what makes us perfect?
Every program in bash returns an exit status by default after successful or unsuccessful completion. The exit status on successful completion is zero. These can be changed by using `exit` command with a specific integer status (0-255). All the constructs that tests something like `if-else`, `while` etc in bash do it a little differently than in other languages. They test the *exit status of a command*, NOT the value of a boolean expression. The common construct like this `while [ "$var" = "abc" ]` is basically a shorthand for the `test` command which returns an exit status of 0 or 1 depending on whether or not the boolean expression is true or false. So in your example as long as `./program` returns an exit status of 0 the while loop will execute. If nothing is changing inside `./program` in each iteration it will be an infinite loop. If the program returns some other exit status apart from zero the while loop will terminate.
Try some of these... https://www.tldp.org/LDP/abs/html/writingscripts.html or http://wiki.c2.com/?FizzBuzzTest and see if you can combine it with `imagemagick` to create a 30 page `pdf` file with each page containing the appropriate text or number....
Thank you Buddy.
I think program is executed each iteration, and if the result is true the otherprogram is run.
What do you mean by it not working? Does it not set the variable?
Well when I use `program command | read -r variable` and then use `echo $variable` it doesn't display anything.
My bad; I forgot that it doesn't work with pipes. It's done with `read -r variable &lt; &lt;(program command)`, but that probably has the same problem as command substitution. Or you could redirect it to a temporary file and read from it.
yeah to reply whole scenario need to modify "myprogram" so it will do exit(42) after few calls
I would have tried test programs like that before asking for an answer online.
Exactly! Maybe doing some echoing inside the scripts, trying exit different exit status and going debug mode to analyze what's going on.
Depends on what's inside "myprogram" and "myotherprogram". It's the kind of situation where could be everything and by the way not many information where given by OP.
My guess is probably because during redirection the input is streamed as plain text, so special characters like # are not recognize.
Just started shell scripting with sh and it's been great helping me learn
TIL! THanks for the solution.
The main reason why you're getting an error is because the here doc is being fed to ftp and not bash. `#` is not a comment for ftp. If you replace `#` with `!#` it should work (at least in \*nix) as ftp will ignore those lines that begin with `!#`. Of course the syntax highlighting is correct as `gedit` identifies the whole thing as a string.
Glad my learning was able to contribute to someone else learning! Hope it's useful to you!
I will give that a shot, thanks for the help!
This isn't the same question, but I do have another similar question that I'd like to run by you. Since it feeds everything in as a string, is there anything I can do to feed in a variable? So, for example, let's say I'm iterating through a list of files in a folder. I want to: `put $file $destination` How would I do this given that it reads those variables as string literals?
You are feeding these lines to the FTP software. IS your FTP program able to interpret comments? The shell will happily pass that garbage to the FTP software because that is what you instructed the computer to do with your script.
The here-doc body interpolates as if it is in double quotes. It can be used as a kind of template. Just put the variables in the block of text: ``` ftp -i $1 &lt;&lt;EOF !#bla bla bla put $file $destination !# bla bla bla EOF ```
Couple of ideas: you can get each IP from /etc/resolv.conf with `awk '/nameserver/ {print $2}' /etc/resolv.conf` - you could use that in a for loop like: ``` for i in \`awk '/nameserver/ {print $2}' /etc/resolv.con\`; do dig @${i} $fqdn done ```
If you only want the values of the nameservers configured in /etc/resolv.conf then you need to be smarted with out you pull information out of that file. Remember resolv.conf can have comments, domains, and a bunch of other stuff in them. If all you want is the nameservers in that file you need to do something like: dns1=$(egrep '^nameserver ' /etc/resolv.conf | sed '1q;d' | cut -d ' ' -f 2) To break this down into parts, the `grep` selects only the lines that start with "nameserver" from /etc/resolv.conf. These are the only lines we are interested in from your problem description. The `sed` prints only the first line and removes everything else. This is because you said you only wanted one DNS server address per variable. Finally the `cut` removes the word "nameserver" from the beginning of the line so all you are left with is the IP address. This is easily tested: ~ # egrep '^nameserver ' /etc/resolv.conf | sed '1q;d' | cut -d ' ' -f 2 10.10.10.10 From there, you can change which line you grab from resolv.conf by changing the `sed` command. Checking if a port is open on a remote host is done with tools like `nmap` or `netcat`. Checking if a port is open on your local machine is done with `ss`
What I want it to do is resolve the variable, and then feed the value of the variable to the FTP in that line. That is not what it does?
Awesome, thanks!
Seriously, don't use backticks. They are remnants of a time long gone and have been superseded by `$()` which is more readable, allows needing, etc.
You need to have the closing `heredoc` "Left-justified" - meaning, not indented
Yes, moviuro is right. I'm old and set in my ways, and shellcheck tells me this dang near every time.
I love it when the solution is easy! I didn't even realize that white-space mattered in BASH. Thanks so much!!!!
Variable expansion is the default behavior. If you want to disable that use double or single quotes on the delimiter \`EOF\`. From man bash: The format of here-documents is: &lt;&lt;[-]word here-document delimiter No parameter and variable expansion, command substitution, arithmetic expansion, or pathname expansion is performed on word. If any characters in word are quoted, the delimiter is the result of quote removal on word, and the lines in the here-document are not expanded. If word is unquoted, all lines of the here-document are subjected to parameter expansion, command substitution, and arithmetic expansion, the character sequence \&lt;newline&gt; is ignored, and \ must be used to quote the characters \, $, and `.
Awesome, okay. Gedit wasn't color coding it to represent that, so I had assumed it wouldn't do that. That's exactly what I want, thanks again!
I tried to resolve this with an array but ran into what looks like odd scoping issue. Two values get added to `dns` in the loop but they are gone outside. What am i missing? ``` 1 #!/usr/bin/env bash 2 3 declare -a dns 4 cat /etc/resolv.conf | 5 while read f 6 do 7 if [[ $f =~ 'nameserver' ]] 8 then 9 n=${f#nameserver } 10 echo $n 11 dns+=($n) 12 echo ${#dns[@]} 13 echo ${dns[@]} 14 fi 15 done 16 17 echo ${#dns[@]} 18 echo ${dns[@]} ```
Honestly, I think this is the \*only\* place in bash where it matters
And the behavior is similar in many other languages, too. It's why heredocs tend to break indentation flow.
&gt;5 comments This is a great explanation, thank you kindly! I will have to check to see if our servers have either nmap or netcat installed natively.
lol. Thank you!
Similarly, I created this in PowerShell (ewww I know) for our Windows Environment. Here is what it looks like for what it is worth: #Grab and store systems fully qualified domain name $FQDN=(Get-WmiObject win32_computersystem).DNSHostName+"."+(Get-WmiObject win32_computersystem).Domain #$FQDN="dw2dpcwi001.dev.ti.census.gov" # #Grab and store network adapater configuraiton information $NetAdapter = Get-WmiObject -Class "Win32_NetworkAdapterConfiguration" -Filter "IPEnabled=TRUE" # #Grab and store primary DNS ip address $DNS1 = $NetAdapter.DNSServerSearchOrder[0] #Grab and store secondary DNS ip address $DNS2 = $NetAdapter.DNSServerSearchOrder[1] # #Try and catch the FDQN failing to resolve against DNS1. # try { if (((Resolve-DnsName -ErrorAction SilentlyContinue -Server $DNS1 -Type A -Name $FQDN -DnsOnly).IPAddress).Contains(10.25)) {Write-Host -ForegroundColor Green $DNS1 "True"} } catch [System.Exception] { Write-Host -ForegroundColor Red $DNS1 "FQDN cannot be resolved" } # #Check is port 53 is open on DNS1 from localhost. # if (((Test-NetConnection -ComputerName $DNS1 -Port 53 -WarningAction SilentlyContinue -ErrorAction SilentlyContinue).TcpTestSucceeded)) { Write-Host -ForegroundColor Cyan $DNS1 "Port 53 is Open" } else { Write-Host -ForegroundColor Red $DNS1 "Port 53 is Closed"} # #Try and catch the FDQN failing to resolve against DNS2. # try { if (((Resolve-DnsName -ErrorAction SilentlyContinue -Server $DNS2 -Type A -Name $FQDN -DnsOnly).IPAddress).Contains(10.25)) {Write-Host -ForegroundColor Green $DNS2 "True"} } catch [System.Exception] { Write-Host -ForegroundColor Red $DNS2 "FQDN cannot be resolved" } # #Check is port 53 is open on DNS1 from localhost. # if (((Test-NetConnection -ComputerName $DNS2 -Port 53 -WarningAction SilentlyContinue -ErrorAction SilentlyContinue).TcpTestSucceeded)) { Write-Host -ForegroundColor Cyan $DNS2 "Port 53 is Open" } else { Write-Host -ForegroundColor Red $DNS2 "Port 53 is Closed"} BREAK
Yes, this is one of the more unpleasant aspects of shell syntax. Alternatively, you can use `&lt;&lt;-heredoc` instead of `&lt;&lt;heredoc` and then all initial tab characters will be stripped from each line of the heredoc, including the final terminator. That allows you to indent the entire heredoc and the terminator, but only with tabs, not with spaces. (Note that this goes back to the Bourne shell so is shared by all shells that derive their language from it, not just bash but also ksh, zsh, etc.)
Shells are so wicked strange. Quite a learning curve for stuff like this! Thanks so much for the information, I've updated my script to use the tab stripper!
You are feeding comment lined to your ftp client. That is what is happening. Has nothing to do with bash. Bash interprets comment lined, but can we say the same for your ftp client? The likely answer in 'nope'
you have white space in front of your `heredoc` string, that is a bad thing.
Except in BASH, where white space doesn't matter. Except except in heredoc in BASH, where the rules are made up and the points don't matter. Lol
Check out the \`cut\` command, it takes a delimiter as an argument and you can choose a field to return &amp;#x200B; \`\`\` echo name.txt | cut -d. -f2 txt \`\`\`
My finished output: \#! /bin/bash fqdn=$(hostname --fqdn) for i in \`cat /etc/resolv.conf|grep nameserver|awk -F ' ' '{print $2}'\`; do if nc -w 3 -vz $i 53 2&gt;&amp;1|grep -q Connected; then if nslookup $fqdn $i|grep -q Name; then echo "$i True" else echo "$i False" fi else echo "$i False" fi done
Thank you all for the great suggestions.
Awesome, thanks for a direction! I will look into this command, haven't heard of it before.
you can collapse the \`cat | grep | awk\` into 1 call \`awk '/nameserver/ {print $2}' /etc/resolv.conf\`
Bash scripting is great... it you know bash. If I hit too much friction I will write a one off python script (to do the sting manipulations, for example) and then call that from bash 😁
Hi. You can do it this way too: -------------- fullpath="/home/ubuntu/test.txt" filepath=`echo $fullpath | awk -F'.' '{print $1}'` fileextension=`echo $fullpath | awk -F'.' '{print $2}'` echo 'path: $filepath -- extension: $fileextenstion' Output: path: /home/ubuntu/test -- extension: txt --------------
I hadn't even considered if I would be able to use Python on the system in question here. Will look into, if I can, I'd rather do it that way!
\`\`\` \#!/bin/bash \# all files in current working directory for file in $(pwd)/\*; do \# strip the full path to the file fileName=$(basename $file) \# obtain all string after the '.' delimiter fileExtention=$(echo $file | cut -d '.' -f2) echo '---------------------' echo "${file}" echo "${fileName}" echo "${fileExtention}" echo '---------------------' done \`\`\` bash -x &lt;script&gt;
Wait, are you just trying to figure out the file extension? Not knowing what the application is, it's hard to write a good solution, but anyway.. here is a harebrained one: for f in *; do echo "Filename: $f"; echo -n "Extension: "; x=$(echo $f | awk -F. '{print $NF'}); if [ $f = $x ]; then echo "No extension"; else echo $x; fi; echo; done
THIS DID IT!!!! I had to make some very minor tweaks for my specific use-case, but I am now getting EXACTLY what I wanted! THANK YOU SO MUCH! Also, what are the ticks (``) about?
I need to get the files and their extensions, and I need them in separate variables. I was able to get a solution to work from another comment (this sub is very active and full of helpful people!). Thanks so much for your help, I appreciate you taking the time to do so.
Oh yeah, I learned all about that bash -x &lt;script&gt; deal today. I LOVE it. Thanks so much for your help, I appreciate you taking the time to do so.
Using cut, eh? Try a filename with multiple dots in it and see what happens :p
Now the suggestion to us ``cut`` is probably the simplest, but oh well. A few options I can think of: * ``dirname``: Returns the parent directory of a supplied path * ``basename``: Returns the filename of a supplied path * ``awk -F '.'``: You can specify awk's input *and output* delimiters (IFS, OFS) * ``${filepath##*.}`` and ``${filepath%.*}``: use parameter expansion to extract the filename and extension from a given variable. ([source](https://stackoverflow.com/a/965069)) So, for some examples (granted, on mobile so def look at the manuals for each): ``dirname "${HOME}/.bashrc"`` returns ``/home/&lt;username&gt;`` ``dirname "${HOME}" `` returns ``/home`` ``basename "file.txt" `` returns ``file.txt`` ``basename "${HOME}/.bashrc"`` returns ``.bashrc`` ``basename " ${HOME}/.vim"`` returns ``.vim`` ``echo "file.txt" | awk -F "." '{OFS=' '; print}`` returns ``file txt`` For the remaining examples, assume '``file="${HOME}/file.txt``': ``echo "${file##*.}"`` returns ``file`` ``echo "${file%.*}" `` returns ``txt`` --- Lemme know if you have any questions!
Ended up getting an AWK suggestion. I really need to learn how to use AWK, it's amazing.
Hey hombre, thanks for the in depth explanation of possibilities! Someone else ended up writing up a little sample of how to use awk for this, and it ended up working amazingly. I didn't realize how many options there were!
Take a look at this book. Unix Power Tools published by O'Reilly.. published 2002 but still as relevant and useful as ever: https://github.com/wuzhouhui/misc/blob/master/UNIX%20Power%20Tools%20(3rd%20Edition).pdf I bought a hardcopy when I was a padawan, still flick through it occasionally when I need inspiration...
My bookshelf at work, being a new job, is kinda empty. It definitely needs more stuff! This seems like a perfect addition.
Also look up bash linters for vim. \-x is my pro tip when your first getting to grips with bash.
I don't know that I'll ever be hardcore enough for VIM. #PeasantLife
One cheap way to get the file extension is ext=${filename##*.} Removes everything up to and including last period.
Those ticks are old way to execute command in subshell (means a subprocess is created executing command you place in there). Currently used way is to use $() instead of ``.
 sed '/[a-zA-Z0-9]/s/^/#/' c.c If letter or digit (anywhere), do the substitute.
Prepend! That's a better word
Cheap ways are best ways!
Oh awesome, I never knew about that. That's great information to know! Thanks so much!
awk '/FOUND/ {print $2}' /path/to/logfile
I think `/^$/!` is a better choice.
I thought /./ first, but "a character or number" made me hesitate
Thanks, that worked! I had tweak the number to 8 since I neglected the added time stamp. I was working with awk previously but I must have done the syntax wrong because the file wasn't reading properly. A few questions if you don't mind. In previous examples it looked like multiple commands can be issued at a time with awk. Is it possible to chop off the colon in the same command? The output is producing multiple paths since the log has multiple reports of the file. Is it possible to limit that to the last found result, or should I output it to a variable and parse it from there?
Awk provides a complete programming language and a pretty convenient one at that. I'd guess that `sub()` could be used to do what you are looking for. This will replace the first occurrence of ":" in $8 with the empty string then print $8. ``` awk '/FOUND/ {sub(":", "", $8); print $8 }' ``` Here is a link to a PDF of the book I used to learn AWK back in the good old days. https://ia802309.us.archive.org/25/items/pdfy-MgN0H1joIoDVoIC7/The_AWK_Programming_Language.pdf
cat filename.txt | tr '\\n' 'Ð' | sed 's/Ð/Ð™/g' | tr 'Ð' '\\n' | tr '™' '#'. This should work
Okay, so the first step is to get all the lines containing your keyword, "FOUND". grep FOUND /path/to/file is probably the first way you should learn to do that. Second step is to extract the filename. Now, this in principle would be easy and there are many ways to do it. cut -d\ -f2 This is us asking `cut` to pick the second field of data out, using a space as the delimiter. (The space in questions is the extra one after the backslash, the backslash is there so bash knows not to ignore it but send it to `cut` as a parameter.) This, again, is a shell tool that should be learned very early on. Plump those two things together with a pipe: grep FOUND /path/to/file | cut -d\ -f2 ..and you have a rudimentary solution to get a list of all the files. Let's try: `$ ls -l myfiles/ total 0 -rw-r--r-- 1 user user 0 Jun 17 22:31 example1 -rw-r--r-- 1 user user 0 Jun 17 22:31 examplefile -rw-r--r-- 1 user user 0 Jun 17 22:31 Example File $ cat example.log Unrelated log ScanOnAccess: myfiles/example1: pneumonia FOUND Cows smell funny ScanOnAccess: myfiles/examplefile: herpes FOUND Never trust an accordionist ScanOnAccess: myfiles/Example File: aids FOUND Also an unrelated log line $ grep FOUND example.log ScanOnAccess: myfiles/example1: pneumonia FOUND ScanOnAccess: myfiles/examplefile: herpes FOUND ScanOnAccess: myfiles/Example File: aids FOUND $ grep FOUND example.log | cut -d\ -f2 myfiles/example1: myfiles/examplefile: myfiles/Example` A fine attempt, but it has two flaws - you keep the : in place at the end of the filename because that's the way the log is formatted, and the file name with a space in it got mangled completely. If you automated doing something to each of the files at this point, you would not manipulate "Example File", but rather "Example". At this point you'd better hope there wasn't an other file actually named "Example" that you just deleted accidentally. Aha, you say, let's use the colons as delimiters instead! Ok: `$ grep FOUND example.log | cut -d: -f2 myfiles/example1 myfiles/examplefile myfiles/Example File` Excellent, but there's a leading space we don't want, and we need to figure out a way to manipulate each of those files. (Narrator: it was at this point that /u/topicalscream got tired of explaining verbosely and instead just wrote a quick and dirty oneliner to get the job done, sneaking off to have a beer instead of documenting what he did. Pwuh. Typical sysadmin.) `while read filename; do cp "$filename" /tmp; done &lt; &lt;(grep FOUND example.log | cut -d: -f2 | sed 's/^ //')`
Thanks. I'll check it out. I appreciate the help.
There are so many tools for so many tasks. Bash is great, but it is not a magic hammer. &amp;#x200B; If I need to write orchestration/automation, I do it in Ansible. If I need to interact with REST APIs, I do it in Python. If I need to interact with docker or k8s, I do it in Go. &amp;#x200B; I \_could\_ hammer a lag bolt into a piece of wood, but it be so much easier and cleaner to use the right tool.
Can you compute the necessary number first, using the `time` command and some math, and set a variable to the computed value? Alternately, POSIX tells us we have a C compiler and the usleep() function in unistd.h. :D
No. No it is not.
I think `sed s/^.+$/^#/g` would do the trick
So by Posix, you are meaning the one from 1988 when ksh88 was made the Posix shell, right?
good idea! will do
Not at all. You want a skill which will get you places? Learn Ansible, Terraform and Dev Ops.
I think that might be one of the circles of hell.
I write bash pretty much full time. I build tools for other developers mostly around gluing together commandline tools to launch local preview servers and work with vcs. It’s pretty great but I’ve run into more than a few problems that I solved with bash that probably should have used a more featureful language. Those projects are now tech debt. I’m looking at rust right now as the alternative.
Other commenters have noted the better ways to do this. However, your first example should mostly work; I changed `$local_dir` to `"$PWD"/*` for testing and put the `IFS='.'` before the `read` command so it won't affect the `for` loop in the subsequent runs and it worked fine. I'm not sure what's going wrong when you run it; can you try running `IFS=. read -ra arr &lt;&lt;&lt; a.b; printf '%s\n' "${arr[@]}"`?
Really going to the opposite end of the spectrum. Why not Python or Perl?
When the majority of the code is executing other programs, eg: a series of 20+ calls to `svn`, the amount of extra code writtten to wrap that is a pain. It all started with me inheriting 30 or so scripts that were slapped together, where I cleaned them up, wrote a bunch of functions for shared code and it just grew from there. I would say that 90% of the tooling, it makes sense to keep it bash but there’s a couple that probably shouldn’t be. There’s also a ton of stuff that has to change directories and leave the user sitting in those directories so we have a few hundred functions and aliases defined as well. Perl is kinda dead tho. I wrote a fair amount of perl 15 years ago and eventually dropped it in favour of ruby. When I first started I toyed with porting the scripts from bash to node since the team is mostly js devs, but things just got too gnarly with all the shelling out and trying to handle errors. I wound up building a way to wrap bash scripts and then I was writing a ton of bash again and having an additional, unnecessary layer of indirection.
Mean :D
Don’t put all your eggs in one basket. It could be difficult to find a job like that and your resume would look pretty thin with only one tool listed. At my job I automate tasks for both Linux and Windows servers. For Windows I write Powershell scripts. You can apply what you know from bash scripting to learn other languages. You can learn by trying to make a Powershell script do something similar to your Bash scripts. Then at least you could support both platforms. Even if you hate Windows it feels good to write an awesome script.
I don't see anything non-posix there, besides I'm not sure how the OP expected to replace `sleep` without overloading `sleep`. A loop would need a way to wait a period of time no matter what happens, even if it loops over sleeping 1 second many many times.
That seems to work. I don't understand in what way that's different, though (I mean, it's BASH, so maybe it isn't different and it just chooses to work because it has a preference for that string "a.b" over mine :P)
&gt; (I mean, it's BASH, so maybe it isn't different and it just chooses to work because it has a preference for that string "a.b" over mine :P) Bash is weird, but it doesn't have random behavior like that. As a rule, in computing (or at least in the Linux world), whenever something seems like that, you're probably the one who's wrong. Are you sure you copied and pasted it correctly? You have three `echo`s and only two lines of example output...
Yeah, I really don't get wtf OP is trying to do. `sleep` should be POSIX?!
Linux system admin is the job you are looking for. But for a small company. Since a man is not an island your colleagues might not agree that bash is the single tool to rule them all it is best if you have nobody that you have to collaborate with in your daily job. Or start a YouTube channel where you develop stuff in bash. I'd tune in. Get some sponsors etc.
I thought `sleep` was in Posix, but I haven't verified that, yet I'm confident it would be, and would be shocked otherwise. If otherwise, the Posix shell (ksh88) does have a `$SECONDS` variable that counts higher the seconds since shell invocation. So in theory that could be used to compare with user input time elapsed similar to `sleep`.
Thanks so much! I appreciate the time you spent answering my question.
While anything is possible to do in bash it is often better to rely on better tools. I often just inline other languages like perl or python or awk strings=$(echo "this.is.something" | python -c ' import sys strings = sys.stdin.readline().split(".") for s in strings: print(s) ') for s in $strings; do echo "got: $s" done
Editors usually have shortcut keys to insert real tab characters even if you have set to expand tabs into spaces.
Spaces and brackets in the filename doesn't immediately strike me as the best idea in the history of the universe, but it should be relatively easy as long as you double quote your variables and escape the brackets when necessary. Why though?
Easy, yes. A good idea, probably not; it will clutter your filenames. I think it'd make more sense to store the checksum in extended filesystem attributes (`man setfattr`).
Depends on what you think is a good idea. renaming files is super easy if you have the right permissions for the files. A quick way to do this would implement something like this: for file in *; do checksum=$(cksum $file | awk '{print $1}') if [[ ! $file =~ $checksum ]]; then mv "$file" "$file[$checksum]" fi done;
* In the style of Animaniacs* Good idea - Managing filenames with bash Bad idea - Adding symbols and / or special characters to those filenames.
Perl is sort of dead, it still ships by default in most common distros. I think it’s still great glue, no matter how ugly it is.
I work in QA for a large name in network equipment. I knew BASH going in, but most of my current tasks are in busybox, so my advice is to play with embedded systems and see what you can learn from more restricted environments. (I still rely on `expr` for example.) Embedded is a big place to be these days, lots of projects and venues for learning new stuff, and shell scripting/Linux/BSD knowledge is appreciated. I recently completed full automation of a larger test suite, and just the data production part was nearly 3K LOC including documentation. I wrote it wrapper friendly because I expect my employer will need a CLI less interface if I'm hit by a bus.
No worries, hope it helps :)
In pure shell, not possible. Your function doesn't sleep; it maxes out the CPU until it's counted that many times, and the time this takes is not predictable, as you've observed. POSIX includes a `sleep` utility but it only supports one-second granularity – no fractions. The GNU and BSD versions of `sleep` do support fractions of seconds, but Solaris `sleep` doesn't and possibly other Unix versions of `sleep` don't either.
I could see doing this. A few lines of script in a loop. Snag the checksum, use `grep -wq` to see if it's already in the file name, if not rename (`mv`) the file. I'd consider using symlinks. It's hacky, but the get it done quickly type of hacky that often serves well for years.
When it comes to access to external links and stuff and the fact that we don’t have an internal cpan, I Figure that’s a non starter.
JSON and jq would help, but once you start needing multi dimensional arrays perhaps you should move your script to python or similar.
For config to be used by bash, I'd go with bash as config format; the `case` you already have seems like a good approach, though I'd lowercase those variable names.
Once you start getting this complex you're probably better off with another language. But perhaps if you're open to json, you could integrate [jq](https://stedolan.github.io/jq/) into your Bash script.
I have a workaround for you: use a json parser. You can convert your yaml config to json on the fly before doing it. I don't know a parser that will set up the variables for you, I only know jq to query the json. jq is a program installable by apt.
Could your configuration files be themselves written in bash ? That way you only need to source them. Unless you need them to be read by another program/language.
I already was at that step but wanted to take it one further. Especially since a common config file format would make it easier to share with/migrate to another language further down the road.
Thanks, I‘ll look into that.
Thanks, I‘ll give it a look!
I'd do it like this: file=/home/john/pictures/school-trip/french-class/001.png base_folder=/home/john/pictures/ # Remove trailng base_folder new_name="${file#$base_folder}" # Substiture all slashes with dashes new_name="${new_name//\//-}"
`getopts` and co are for parsing *options*. Your script doesn't have any options but only file arguments, so it can't be used here. It's still worth learning it tho. Why disallow a directory and a file together? Shouldn't be too hard to combine a list of files from a directory with specific file arguments. That would also make parsing arguments simpler. If you really want to disallow a combination of directory and file arguments, maybe something like this? case "$#" in (0) set_random_landscape ;; (1) set_wallpaper ;; (*) has_file=false has_dir=false for arg; do [ -d "$arg" ] &amp;&amp; has_dir=true || has_file=true $has_dir &amp;&amp; $has_file \ &amp;&amp; { echo "foo bar" 2&gt;&amp;1; exit 1; } done esac
I don't think there is such a template for processing non-option arguments as you describe - but there are templates for processing optional arguments. **getopt**(1) really only helps you with processing option arguments such as `--help`. But since you really oughta include at least that one option in every script you write (especially if someone else is to use your script - or even as a kindness to your future self) you should master **getopt**(1). It's not that hard although it's not necessarily the best way to do it. Processing options is a deceptively complicated problem when you consider that options can be long (`--help`) or short (`-h`), short options can be merged or separate (`-xyz` or `-x -y -z`), may require their own arguments (eg `--outfile abc`), may occur in any order and be intermingled with non-option arguments. While **getopt**(1) itself takes care of most of that, it does not help you with clean coding (you have to code in 3 places for each option!) nor does it assist with `--help` documentation. I'd recommend (shameful plug) **argp.sh**(1) [http://bhepple.com/doku/doku.php?id=argp.sh](http://bhepple.com/doku/doku.php?id=argp.sh) as a set of extensions to **getopt**(1) to assist in making coding clean and to automate documentation. Of course, this is assuming that **bash**(1) is the right language for the problem. Most other languages such as python have their own equivalent to **argp.sh**(1) to assist with processing options and documentation.
I just retired from 6 years in such a position (old age) in a Fortune 50 company. It was a great run but I have to concede that the young folks didn't get it at all. That was kinda good for me, 'cos they didn't like to get their hands dirty with all the old bash stuff. On the other hand, management wanted to be hip and cool and do what the young dudes were saying and get rid of bash - it didn't pan out that way as nothing (including python) is as slick as bash for those sorts of problems - that was good for me too, in the long run! The reality is that bash will be around for a loooong time but you will need other skills too such as python, puppet/ansible, maybe SQL. Look for a company with a big investment in linux - probably Redhat - my last post had thousands of RHEL instances running on VMWare. They all need help with DevOps and Continuous Development.
If you're looking for short and sweet and don't have any weird corner cases, and if you have `rename` installed, you can do it all with one `find` command. @nook:~/test 7s $ tree . ├── school-trip │ └── 001.png ├── tokyo-trip │ └── 001.png └── vegas-trip └── 001.png 3 directories, 3 files @nook:~/test $ find * -name *.png -exec rename 's:/:-:g' {} \; @nook:~/test $ tree . ├── school-trip ├── school-trip-001.png ├── tokyo-trip ├── tokyo-trip-001.png ├── vegas-trip └── vegas-trip-001.png 3 directories, 3 files @nook:~/test $
I can't see why you'd need backup includes and excludes out of script, such cases are usually variables you'd need changed and stored on the fly (from with in the script itself, like in this [case](https://github.com/michaeltd/dots/blob/master/dot.files/bin/wallpaper-rotate.sh)) for an array based example backup script take a look [here](https://github.com/michaeltd/dots/blob/master/dot.files/sbin/update-bkps.sh)
jq is what allowed me to stay with Bash. I use it extensivly with 'aws cli'.
Bash arrays are limited, but I still find them very useful. You can append values to an array in bulk. But removing values from an array can only be done one value at a time. You will have to make your exclude line into a for-loop.
That sounds interesting, can you elaborate more.
LOL- “it is best if you have nobody that you have to collaborate with”. That describes my job perfectly. I have done many flawless projects on my own. But, if I have to collaborate w someone else then it sucks!
* First one searches for zero or more capital letters, yes. The Upper case 'X' means just that: upper case X's. * The second expression searches for a line starting by "The" and ending by "end\" the way you wrote it. You don't need to escape the '$' after 'end". I guess you wanted to write grep -E '^The.*end$' $1 This will match The most beautiful end and won't match The better ending One more end The only one
I have about a dozen targets for my cloud backup (e.g. „these 6 paths to bucket A“) and this will only grow. Also my current setup doesn‘t let me specify excludes per path, only per target. So either I massively increase the number of targets or the flexibility of my configuration. That‘s when I started considering YAML. On the contrary, there‘s hardly ever a case where I need to backup on the fly, but my script can do that as well. Also I may want to switch to another language one day without having to touch my config files, that‘s why I want to use a more common format than just „include bash code“.
\\\* will match zero or more times, + matches once or more. :) in the [grep manpage](http://man7.org/linux/man-pages/man1/grep.1.html) under "Repetition"
Check that no files from different directories have the same name.
'X' is a literal.. Theend$ is matched because .\* matches 0width
Also one thing that people are neglecting to mention is that the argument containing the variable in these cases are file paths. So if `$1` contains `foo.txt` it will apply that regex to every line in that file.
What's the script for, a course? &amp;#x200B; I'm not going to write it for you, but to write a script you really need to be comfortable with the command prompt. &amp;#x200B; 2 commands to look up (start by adding ' -h' after the command, then look at the man page 'man &lt;command&gt;'): &amp;#x200B; groupadd - adds a group, unique by default useradd - adds a user, unique by default, will also create a group of the same name, and home directory with permissions &amp;#x200B; also look at exit codes ($?) and conditional (if) statements
Exactly. If you want to match contests of a string using `grep` then you need to get the string on stdin: ``` echo $1 | grep -E 'X[A-Z]*X' ```
 Find a nice pdf about Linux administration. Split this job in multiple simple tasks and google-fu it, or search in the pdf. You will learn a lot about useradd, usermod, groupadd, groupmod to check for duplicates, you will have to filter some files ( cat , grep , cut or awk , sort, uniq ) and finally wrap this in a bash interactive script ( how to get user input ? etc ) &amp;#x200B; Keep calm and enjoy .
If you run in shell it will expect input from stdin $1 will be empty
This guy is asking for help in every sub. Apparently he doesn't pay attention to his classes and want people to do his homework while he watches Netflix haha
`jq` is a processing language like `sed` or `awk` explicitly for JSON. It's designed by and for shell wizards so many of its core constructs (pipes, filters, interpolation, quoting hell) will be easy to pick up if you're comfortable in the shell.
No that is not the case I have tried it on my own but I really cant figure it out I also don't expect a full script just some help
So paste here what you have and people will help you.
This is a question about regular expressions, not grep.
Why not maintain two delimited associative arrays? I use this approach all the time. declare -A \ From=( [foo]='/path1,/path2 contains/ spaces' [bar]='/path3,/path4' ) Exclude=( [foo]='a,b,c' [bar]='d,e,f' ) IFS=, read -a Array &lt;&lt;&lt; "${From[${Target,,}]}" for object in "${Array[@]}"; do echo "$object"; done
Also, don't forget case sensitivity. ^(\[OP comment said 'the' matched, not 'The'\])
Thanks, that’s one step better than what I have now so I‘ll implement this next (but it’s still no „real“ config file).
https://github.com/Ackis/checkmediaservers/blob/master/checkmediaservers.sh Line 104ish is where I use an array from an external file. Not sure if best practice. It's not anything fancy.
 grep -E 'X[A-Z]*X' $1 * `-E` isn't needed here, just fyi, not trying to pick it apart, see [BRE/ERE](https://unix.stackexchange.com/questions/119905/why-does-my-regular-expression-work-in-x-but-not-in-y) * `$1` would suggest to use `"$1"` unless you have a good reason, see [quoting variables](https://unix.stackexchange.com/questions/131766/why-does-my-shell-script-choke-on-whitespace-or-other-special-characters) * `X` match it literally * `[A-Z]*` zero or more of uppercase alphabets grep -E '^The.*end\$' $1 * `^` start of line anchor * `The` match these characters literally * `.*` zero or more of any character * `end` match these characters literally * `\$` here `\` is used to escape the special meaning of `$` character, so it will be matched literally instead of enforcing end of line anchor also, as mentioned in other comments, `$1` here is considered as name of input file if you'd like a book to learn `GNU grep` (there are different implementations of grep depending on which platform you are using), my free book offer is ending today, see my repo https://github.com/learnbyexample/learn_gnugrep_ripgrep for download links, sample chapters, exercises, etc
Or you could also use here strings grep -E 'X[A-Z]*X' &lt;&lt;&lt; "$1"
&gt; printf '%s\n' '${sources[@]}' There is a difference between single and double quotes... Are you sure you want to use single quotes there?
The reason why I put single instead of double quotes there is because I thought I needed to encapsulate the code that's taking place within the shell I opened in the script. gnome-terminal -- bash -c " " If I put double quotes there, I thought it might cut everything from the top until printf " into one chunk.
so you need to escape them.....
`bash -c '` `pgrep bash | tail -1 &gt; /tmp/tmp` `read -p "Please enter data: " -a sources` `printf "%s\n" ${sources[@]} &gt;&gt; /tmp/data` `exit` `'`
Escaping the double quotes like this didn't print anything. printf \"%s\n\" \"${sources[@]}\" Is there another way?
 printf '%s\n' \"${sources[@]}\" should do for that part of your problem.... although you won't be out of the woods yet....
I think I noticed earlier that it appeared to be printing %s + a newline for every element in the array, instead of the elements themselves.
Two hours of my life gone forever because I didn't think of switching the single quotes with the double quotes.
there there it is a precious moment of learning
Bash sucks at hashes, and is only marginally better at arrays. Beyond that, if you want to work with structured data, then you need to use a higher-level language, or maintain a database and use bash to make calls to it. That is until the advent of jq. AWS cli outputs in json by default. If you use non-json output, you essentially get a space-separated array. I've tried using that text output with bash, but found that you cannot rely on the instance IPv4 to be in the 14th offset every time, for example. But with JSON, you know exactly where everything is. JQ allows me to parse json without moving to python/ruby/go. Dumping my `aws ec2 describe-instances` for my largest region generates *430,232* lines of JSON. It's far too unwieldy without a parser.
You should just be able to run something like rsync -av /Users/your\_username/ /Volumes/your\_usb\_drive/
How do you know you need to completely reinstall your OS?
Because it corrupted during install.
The first thing I would do, before plugging anything into your machine is run `ls /Volumes/` You should see something like this-- &amp;#x200B; $ ls /Volumes/ MacOS $ Install your USB drive, then re-run it. Depending on what the USB drive is called, it should look something like this: $ ls /Volumes/ LEXAR 2 MacOS You should see your USB drive. Mine is called LEXAR 2. When know your USB drives name, then you can run the rsync command /u/xwarbucks suggested So, I would do: rsync -av ~/ /Volumes/LEXAR\ 2/ `~/` denotes the home directory of the current logged in user. If you have more than 1 users, you should back up the whole `/Users/` directory instead. the backslash after the R in LEXAR 2 is the escape sequence to tell BASH that there's going to be a space between the R and 2. &amp;#x200B; I hope this helps!
Yeah cd ~/.. sudo rm -rf *
&gt; I think I noticed earlier that it appeared to be printing %s + a newline for every element in the array Close, but not quite.... ${sources[@]} probably isn't evaluated when you think it *should* be (hence suggestion to populate an identically named array outside the script) - you needed to escape the `$` too... so a total of adding 3 `\` to your original script would have made it functional... versus changing 6 and removing 3 in the suggested answer.... However, you should *always* quote variables for the sake of safety (even though `printf` is quite good at looking after you in this respect), so `${sources[@]}` should be `"${sources[@]}"` - which would make it changing 8 and removing one. In this case, swapping weak for strong quotes worked out, but sometimes you won't be able to do that, so knowing how and when to escape characters to work round situations like this is a good ability to have in your back pocket.
Exactly. If it's too long use pastebin and share the link here so people can tell you if there's something wrong or an easy method to do so.
I'm actually making a wallpaper script where it allows the option to specify files or directories (in which case it's referring to all their files) to create a symlink for pictures following the file organization mentioned in OP to a `~/pictures/.wallpapers` location. The point of using such a renaming scheme is to guarantee that symlinks aren't overwritten when created in the event that files may have the same name. This also allows me to manage the wallpapers using regex (e.g. delete all symlinks for pictures in `school-trip`, removing them as wallpapers. How can I adapt your `find` command to create symlinks for the script accepting arguments for a files or directories of files whose files will be symlinked to `~/pictures/.wallpapers` with the symlink renamed as described? Actually, I would like to change the naming scheme to the following: /home/john/pictures/tokyo-trip/001.png -&gt; %tokyo-trip%001.png /home/john/pictures/vegas-trip/001.png -&gt; %vegas-trip%001.png /home/john/pictures/school-trip/french-class/001.png -&gt; %school-trip%french-class%001.png I thought about the script some more and decided on these changes. If you're curious, this renaming scheme follows the syntax used by swap files names for `nvim`. Seems like using the percent symbol may result in less naming conflicts than dashes which are more commonly found. Much appreciated, wished this was the original post instead.
rsync is the right suggestion, if available. Otherwise you should tar it over.
I’m a develop... I know better. Thanks for your support though.
The old school way: find . -print0 | cpio -0pdumv /path/to/destination/dir
Nothing special can happen within single quotes. That is the easiest syntax rule in Shell.
Thanks for the explanation. I work with AWS too. So I was curious what kind of scripts you have written and what are you automating?
Sorry for the confusion, I am familiar with `jq`. I was just curious what kind of scripts OP was using with `AWS CLI`.
I don't know how to do what you ask for, but I'm wondering if you noticed the other alternatives for Caps Lock and Escape that are available as options for the X keyboard layouts: Do you really need a Caps Lock feature? Instead of swapping the position of Escape and Caps Lock keys, you could just turn both keys into Escape with this XKB option here: caps:escape If you do need Caps Lock, there's an option where pressing the key normally is Escape, but is still Caps Lock if you hold Shift while pressing it: caps:escape_shifted_capslock
Thanks for that tip!
&gt; probably isn't evaluated when you think it *should* be (hence your Escaping the double quotes like this didn't print anything. and my suggestion to populate an identically named array outside the script) I kind of thought of it like a subshell where it's evaluating the entire array separately and appending \\n to each element. But instead of actually printing the element, it was only adding a \\n for the element it evaluated. &gt; you needed to escape the $ too... I'm not even sure why that didn't occur to me. &gt;However, you should *always* quote variables for the sake of safety (even though printf is quite good at looking after you in this respect), so ${sources\[@\]} should be "${sources\[@\]}" \- which would make it changing 8 and removing one. I understood that it needed to be quoted. What I think I still need to research is the difference between the single and double quotes. I looked at double quotes as 'the quotes that take care of all the problems', so I'd use them in situations where I want to make sure that everything is encapsulated, such as here. I understand now that that's not a good way to look at them (or a good way to evaluate anything, really). But I still need to clarify for myself their appropriate usage. &gt; In this case, swapping weak for strong quotes worked out, but sometimes you won't be able to do that, so knowing how and when to escape characters to work round situations like this is a good ability to have in your back pocket. Absolutely, and I really appreciate your having taken the time and effort to explain it to me!
This is a good point that I didn't think of! I don't really need caps lock, but I wanted to have the option there.
 fred=dave echo "$fred" echo '$fred' bash -c "echo '$fred'" bash -c "echo '\$fred'" bash -c "fred=john ; echo '$fred'" bash -c "fred=john ; echo \"$fred\"" bash -c "fred=john ; echo \"\$fred\""
&gt; while read foo &gt; do &gt; awk -F',' '{print $1","$2","$5","$6","$7}' $test | grep -w "foo" &gt; done I assume you are reading the matching text into variable 'foo'. Mind the '$': grep -w "${foo}"
I don't recommend using Caps Lock for this. There are many ways to jump back to Normal mode from Vim without hitting escape. You can use the sequence Ctrl + \[ which sends an escape sequence, Ctrl + C (see `:help i_Ctrl_C`), or use the Alt key with a normal mode key like j,k etc. You can also setup a insert mode mapping for this like `:inoremap jj &lt;esc&gt;`. See [this wiki](https://vim.fandom.com/wiki/Avoid_the_escape_key) for a good compilation of options.
I mapped Shift-space to i in normal mode and to Esc in insert mode. Primitive, but very convenient.
Good design precludes the need for extraneous process calls. My favorite thing about Bash is concise inter-process communication, but I'm open to new ideas. Would you be so kind as to demonstrate the following generation, capture, and modification of JSON in Go? while sleep 1; do jo epoch=$(\date +%s); done |jq '.epoch |= sqrt'
I think this works for what you want: ps -Ao pmem,pcpu,pid,comm | sort -rn -k 1 | head -n 6
I might be on different ps version, but pcpi and arg did not worked for me, this did though: `ps --no-headers -Ao pmem,pcpu,pid,args --sort=-pcpu | head -6`? I don't really know what you mean by "How can I achieve this exact same output?"
I'm not sure I understand why your `ps` command above is not doing what you are asking for.
It looks like your submission contains a shell script. To properly format it as code, place four space characters before every line of the script, and a blank line between the script and the rest of the text, like this: This is normal text. #!/bin/bash echo "This is code!" &gt; This is normal text. &gt; &gt; #!/bin/bash &gt; echo "This is code!" *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/bash) if you have any questions or concerns.*
You could create an alias for that command in your .bashrc file, or you could put that script in a directory that is in your PATH variable.
Alias won't work
Use this: PATH="${PATH}:/home/${USER}/scripts"
You can always test your script by running the `pandoc` command from the home directory or adding an `echo` in front of the command to see what is the final command line that bash processes. Also sourcing a script simply executes it line by line. In this case it will not produce any effect. If `~/scripts/` is in your path then you should be able to call `mypdf` from anywhere (after you have made it executable of course). Another option would be to define a function (inside a script with similar functions or .bashrc) mypdf() { pandoc --pdf-engine=xelatex --from markdown+autolink_bare_uris+ascii_identifiers+tex_math_single_backslash+footnotes+table_captions+raw_tex+header_attributes+blank_before_blockquote+backtick_code_blocks+line_blocks+definition_lists+startnum+yaml_metadata_block+all_symbols_escapable+strikeout+subscript+superscript+latex_macros+implicit_figures+link_attributes "$1".md -o "$1".pdf } Now if you source the script containing the function, `mypdf` should be available for the conversion.
I would probably create a variable for each column you want. To split the output per variable I would use awk. Something like this: OUTPUT=$(your ps command) MEMUSAGE=$( $OUTPUT | awk -F’ ‘ ‘{print $4}’ ) echo “order your variables here”
Thank you for the helpful suggestions!
It's easier to handle options which accept a parameter. Also much easier to parse combined options like `-ro file.txt -fv`. Try doing that without getopt(s).
Yes, this is the kind of answer I was looking for. I knew that but didn't think about it while asking the question. Great point. I think this alone is one great reason to use getopt or getopts. Thanks a lot for your answer!
I think that OP means the same information as in the example, not the same exact data (which was my first thought).
If it's linux, you can grab the default .bashrc from /etc/skel
I'm on mac, and i want to recover my data from the .bashrc
I can contribute on Monday if someone has an idea.
Processing options is a deceptively complicated problem when you consider that options can be long (--help) or short (-h), short options can be merged or separate (-xyz or -x -y -z), may require their own arguments (eg --outfile abc), may occur in any order and can be intermingled with non-option arguments. While **getopt**(1) itself takes care of most of that, it does not help you with clean coding - you have to code in 3 places for each option! - nor does it assist with --help documentation. I'd recommend (shameful plug) **argp.sh**(1) [http://bhepple.com/doku/doku.php?id=argp.sh](http://bhepple.com/doku/doku.php?id=argp.sh) as a wrapper around **getopt**(1) to assist in making coding clean (DRY - Don't Repeat Yourself) and to automate documentation.
Time Machine backups?
Thanks a lot for this option. I'll dig a little about argp.sh.
Time Machine backup?
Put ‘DEBIAN_FRONTEND=noninteractive’ in front of your command: Example: sudo DEBIAN_FRONTEND=noninteractive apt-get install -y python-pip
Perfect! Thank you very much Paradoxops!
You’re welcome!
MacOS has /etc/bashrc you can copy and start from there. Maybe start using a local git repo to track changes and start making backups more often.
restore from backups.
Really appreciate!
If a process still has the file open, you may be able to recover it from /proc, but in this situation it seems unlikely. I'm pretty sure bash doesn't keep .bashrc open and I can't think of another process that would have it open. Use lsof to check. Maybe if your editor was still open...
If you don’t routinely make backups this would be a great time to start.
I have an idea. We can discuss in the project ToDo list.
This is one of the retarded features of Debian packages, they have the notion of interactive package install. It's terrible design, especially for scripting or otherwise wrapper based package management. I believe FreeBSD has a similar issue, solved a similar way. Rpm based distros pretty much forbid this nonsense. If I were you, I'd just put that workaround in the/etc/profile and be done.
This is far fetched and perhaps not useful at all BUT... **if you still have a session opened** you could gather some of the code: * If you are looking for some custom function you wrote in bashrc you can just enter `type function_name` in the command line and bash will show the code. * Enter `set -x` in the command line and hit enter. Any code you had in your PS1 will be shown &amp;#x200B; Also perhaps your editor saved some sort of temporary file like vim's `filename~` or `.swp`
[The Simpson Dippy Bird](https://www.google.com/url?sa=i&amp;source=images&amp;cd=&amp;ved=2ahUKEwiY0Ly_3vriAhWFKlAKHbQXBI8QjRx6BAgBEAU&amp;url=https%3A%2F%2Fgiphy.com%2Fgifs%2Fsimpsons-dippy-bird-drinking-l41lUJ1YoZB1lHVPG&amp;psig=AOvVaw0fisUwCtts6A87QBiC8ibs&amp;ust=1561212117724172)
You don't need the GUI for this. Here's an alias I use all the time for my upgrades. &amp;#x200B; upgrade-system='apt update &amp;&amp; apt upgrade -y &amp;&amp; apt clean &amp;&amp; apt autoremove -y' &amp;#x200B; This will do a normal update/upgrade while cleaning apt. Don't have to click "yes" or anything.
Yes I forgot to mention that! I did put the path pointing to the executable in the PATH. However, when I execute the command, mdpdf /path/file from /home/, it gets executed but the pdf contents _do not_ update therefore I deduce the pandoc command did not run properly. When I run the same executable from within the folder the markdown file _and_ the executable reside in, via ./mdpdf file the command works correctly and the pdf output is updated. The command also works properly if I run the script from within the folder the executable resides in but in which the markdown file is not, _e.g._ ./mdpdf ./path/file So I exclude that the pandoc command confuses the directory specification /path/file as a file name.
Thanks for the explanation about the behaviour of `source` of which I wasn't aware. As you can see from my other comment I am able to run the executable which I put in my PATH. However, bash or pandoc seem to have issues with reading the argument (file) I give to the command when I run the executable from a directory the script is not in. It seems to me that the solution you suggested wouldn't allow me to specify the argument to the pandoc command inside `mypdf()`, as by calling `mypdf` bash would just run the pandoc command without `$1`, am I correct?
Make a new user and copy the file from there (assuming you haven't made changes)
Functions can be called exactly like scripts with arguments. You can call `mypdf()` in the same way `mypdf /path/to/file` and then `$1` inside the function will be interpreted as arguments to the function. Whichever directory you're running the script from, that is the `$PWD` of the script. This means that you have to provide the absolute or relative path to the location where your target markdown file is in. For example if you're in `/home/user/dir1` and running script.sh from that location but your file is in `/home/user/dir2` then you have to run it as `script.sh ../dir2/target.md` or `script.sh /home/user/target.md`. You can put a check inside the script/function to make sure that it can locate the file using something like if [ -f "$1" ]; then pandoc ... else echo "$1 does not exists" fi An easy way to ensure that file is located is using bash completion. In this case you can call script.sh and then use tab completion to locate `/path/to/file`. if the completion was able to locate that script then the script can do that too.
You should be seeing "command not found" because `$image` is being presented as a solitary command to execute. Just put echo in front of the text between `do .. done` to see what is being fed to the shell.
Thanks for your response! I'm not getting command not found, but it looks like you're right and it is not copying the image pathway. Do you know a way that this can be done?
My guess is the `readlink` is failing.
You should be using the `--target` parameter to `cp` cp --target "/whatever/directory/" file1 file2 file3 ...
Why are you setting $image outside the loop? You want to set it inside the loop.
Thank you! I don't know why I had it that way. Still, when I do ' echo $image ' it is not saving it as a variable.
Ya I believe this is the problem. Not sure why. Thank you
 for old in ./* ; do new_artist="${old%-*}" ; new_album="${old#*-}" ; mkdir "$new_artist" ; mv "$old" "$new_artist"/"$new_album" ; done
I can give you the suggestions. You can choose the easiest implementation (may learn few things on the way) 1. Get the full file name including parent directory 2. Split the directory name using - 3. Make a directory with first part and subdir using 2nd part from step2 4. Move the track file. For first part, you can use any of the following commands. Awk, sed, cut or Perl one liners (a few to name)
&gt; f nc -w 3 -vz $i 53 2&gt;&amp;1|grep -q Connected; &gt; &gt; then &gt; &gt; if nslookup $fqdn $i|grep -q Name; I don't understand why you're so interested in whether the port is open, either the DNS server resolves the name or it doesn't. If you're so keen on finding out, just do the nslookup first and only check the port status if that fails. nslookup is probably going to work 99% of the time and answers both questions in one shot. Only if nslookup fails will it be worth testing whether the port is open. &gt; if nslookup $fqdn $i|grep -q Name; `|grep -q Name` is gratuitous and will cause more problems than it solves. Shortening it to `if nslookup $fqdn $i; then` will work for the same purpose, since nslookup gives a non-zero exit code when it doesn't receive a valid reply.
I can see three mistakes there, and each one of them alone would stop it from working. `sed 's/^\(.\+\)$/# \1/'` works.
the first example of missing a `fi`?
Isn‘t the content of $image an array if you‘re globbing with *? Can‘t feed an array to „cp“ if I‘m not mistaken. Am on mobile or I could check on my server...
You could provide a little more info than „does not work“. What is the error message / unintended behavior?
yep! Sorry edited for clarification in the post I'll get a parse error 'near -H' but the dual ifs I'll get the results of df -H
Silly bands... looks like the ripping has already begun! There aren't too many bands with hyphens? Insert an easily identifiable and definitely not in a band name character or set of characters(--,__) to separate the band and album, replace the hyphen in ang-p's code with that,Bam, solution above.
As the other poster noted, there‘s a „fi“ missing.
something tells me that you didn't read the q... &gt; Insert an easily identifiable ..... character ...... to separate the band and album it's already been done - it was a hyphen.
correct me if i\`m wrong, but there is no declaration for the $RESPONSE variable. &amp;#x200B; i would write it like read -p "RESPONSE? Hello world? y/n " RESPONSE
with zsh it's valid zsh's `read`: If the first argument contains a ‘?’, the remainder of this word is used as a prompt on standard error when the shell is interactive.
 for file in * do mkdir -p "$(echo "$file" | sed -e "s/-.*$//g")" mv "$file" "$(echo "$file" |sed -e "s/^.*-//g" )" done
 somepath="path where you want to copy images" filename=0 for subs in ${images} do cp "$subs" "$somepath/$filename.jpg" filename=$(expr "$filename" + 1) done
I would suggest backing up your data and then rebooting to the Recovery mode, and reinstalling the OS, it should simply install over the existing OS and if successful (I've done this many times) it'll then boot and nearly everything will be as it was before you had problems.
So the answer to OP's question is "no, but `read` is different"
Yep - came here to respond to that - it’s just different enough from bash that it’s a bunch of minor tweaks that are a pain in the ass but
[Beets](http://beets.io/) is pretty awesome.
`%` characters need to be escaped inside crontab files. When you have: * * * * some command%foo%bar that tells `cron` that: foo bar should be passed into the standard input of `some command`. You need to use: * * * * some command\%foo\%bar instead if you really want the command to contain those `%` characters.
% in a crontab entry can have special meaning. Use \\%, see the manpage.
Might be best to write that into a bash script then execute that under the root crontab.
I'd put that command in root's crontab, not your user's. For snapshots, I'm using https://www.zfsnap.org/zfsnap_manpage.html : `@daily /usr/local/sbin/zfsnap snapshot -r -a 15d zroot/var/data/documents`; `0 2 * * * /usr/local/sbin/zfsnap destroy -r zroot`; you might want to give it a shot. Or look into sanoid, whatever sails your boat.
Thanks! Will definitely check it out
Your first example is missing the 'fi'. It should not work in bash either. Why do you wan to convert your scripts from bash to zsh ? Zsh has some nice command-line features, but for scripting there is not a big difference.
Zsh is the new default in macOS Catalina
in a terribly insecure and trusting way without any validation.... variable=$(&lt;file) but don't use this in a nuclear power plant...
This is indeed very simple; ``` $&gt; cat thisisafile.txt 1234 $&gt; cat readthatfile.bash #!/usr/bin/env bash filecontents=$(&lt;thisisafile.txt) echo ${filecontents} $&gt; bash readthatfile.bash 1234 ```
 while read -r varname ; do myvar=${varna me} ;done &lt; infile Where varname will be the whole line, which should be your integer, myvar will hold that integer and infile is the input file. If there's more contents in the file and such you'll need to give more detail. Excuse any mobile formatting issues
For seeing row 2 only your head and tail are backwards, that would get you the second to last row. And when going after a particular row I tend to use sed but there's more than one way to do anything.
Hey fellas, I'm trying to run a script that evidently needs root permissions but it refuses to run, permission is repeatedly denied, any ideas how to remedy this?
Your user is in the sudoers' file?
the `x` in `chmod +x` is lowercase.
the error isn't about the user having the required privilege to run `sudo`.
Mount point is mounted noexec. mount -o remount,exec /mnt/
It already was, sorry should've been clearer
Yeah, if it helps I'm running this script on an rpi
Yes but the script is executable, you can see it in the ls output
Maybe the script tries to write in the mounted partition and it is read-only
https://imgur.com/08mw9AT Contents of the script if it helps
I'll try it now thanks
What type of filesystem is this mountpoint?
This might be the case
Did u try to change to root and run it? Maybe if checks the user runing it. Maybe your sudoers dont give you root preveligies to run the script as root
Thanks! But mine has to be accessed with sudo permission. How would i do that?
Thanks! But mine has to be accessed with sudo permission. How would i do that?
Thanks! But mine has to be accessed with sudo permission. How would i do that?
It executes, thanks a million man you saved me a lot of hair pulling &lt;3
https://www.youtube.com/watch?v=lz9HDvg_mp0
Have you tried charging your phone? Seriously, you're stressing me out.
Windows line endings can cause this: dos2unix yt1.sh
That would not prevent a script from executing via it's interpreter. bash /mnt/PIHDD/whatever-script.bash
script doesn't need root permissions to run, the execute bit is set for everyone (other). It's most likely the share is mounted noexec OR there's an ace set on the share/file
You can just run the whole thing with `sudo bash readthatfile.bash`. It’ll prompt for the root/sudo password, what are you trying to do exactly?
Chattr ?
Just for fun, here's a list of all of your examples done entirely in awk. I put the original commands after each example. 1. `awk -F, 'NR==1{print}' $INPUTFILE` / `cat input.csv | head -n 1` 2. `awk -F, 'NR==3{print}' $INPUTFILE` / `tail -n 2 input.csv | head -n 1` 3. `awk -F, '{print $2}' $INPUTFILE` / `cut -d ',' -f2 input.csv` 4. `awk -F, 'NR==3{print $2}' $INPUTFILE` / `'cut -d ',' -f2 input.csv | tail -n 2\ | head -n 1` 5. `awk -F, -v OFS='\t' '{$1=$1}1' $INPUTFILE` / `cat input.csv | tr ',' '\t'` 6. `awk -F, 'NR==1{print}; NR&gt;1{print toupper($0)}'` / `cat $INPUTFILE | head -n 1\ &amp;&amp; tail -n +2 $INPUTFILE | tr "[:lower:]" "[:upper:]"` 7. `awk '{gsub("row","http://row")}1' $INPUTFILE` / `cat $INPUTFILE | sed 's.row.h\ ttp://row.g'` I skipped the last example, because it was already in awk.
You’re doing it wrong if it requires sudo. You shouldn’t need root access for basic things like that
Since this is the Bash subreddit, here's a direct link to the script: https://gitlab.com/krathalan/wtwitch/blob/master/wtwitch
As far as I can tell, nothing you use is a GNU extension. Also, in most cases, you don't need the `{print}` or `1`. Specifically, in 1, 2, 5, 6
&gt;As far as I can tell, nothing you use is a GNU extension. Isn't `toupper` gawk-only? I might be wrong about that. &gt;Also, in most cases, you don't need the {print} or 1. Specifically, in 1, 2, 5, 6 This is good to know. I guess it's easy to underestimate just how terse awk really is.
Incidentally, this is one reason why Haiku pre-alpha was such a pain to use. Missing a lot of important UNIX utilities and boot services, with no permission to shim and correct.
&gt; Isn't `toupper` gawk-only? I might be wrong about that. My first thought was the same. The `gawk(1)` manpage has a nice section about all it's extensions. Apparently `toupper` just isn't mentioned in the major awk books. &gt; EDIT: 5 doesn't seem to work without `1` (or `print`) when I tried it Weird, it works for me like this: `awk -vOFS=x '$1=$1' file` Good job on those awk versions btw. Always love seing awk to replace those multi program pipelines.
Battery is too low. Causes excessive anxiety. I can’t even look at the text until you connect to power.
Does the `-t` option show that `xargs` is working as expected?
I know I've already posted in this thread, but if you're working with standard Excel CSVs, you might run into some annoying issues where you have quoted cells that have commas within them. I think it's possible for awk to deal with those, but it's simpler if you can remove them (or perhaps replace them with a non-special character like an underscore to be switched back later). One way to do this is with an awk one-liner: ``` awk -F '"' -v OFS='' '{for (i=2;i&lt;=NF;i+=2) {gsub(",", "_", $i)}}1' file.csv ``` You could also use a very similar one-liner to just replace the commas with a more appropriate delimiter, lets say a colon, for example (just make sure it's a character that isn't in the data anywhere): ``` awk -F '"' -v OFS='' '{for (i=1;i&lt;=NF;i+=2){gsub(",",":", $i)}}1' file.csv ``` Here's a fun sed one-liner; add in commas in the appropriate places into all numbers in a stream: ``` sed -r ':a;s/\b([0-9]+)([0-9]{3})\b/\1,\2/;ta' ``` The `-r` allows you to use extended regular expressions. There's a lot more backslashes if you want to do it without that switch. I could probably go on, but I think I'll leave it at that, for now.
Thanks! I was actually trying to use the `$1=$1` inside curly braces, so that's probably why that happened. That's a good thing to know, even if it's generally advisable to not do it. hahaha. &gt;Always love seing awk to replace those multi program pipelines. It truly is a versatile language, especially when dealing with tabular data. It can, of course, be used for [a lot more than that](https://github.com/mikkun/AWKTC), technically, but that's definitely it's forte :)
\`-t\` shows that all the words are passed.
If you're using python why don't you read the file in python ? Something like : with open(sys.argv[1]) as fd: words = re.match("\w+", fd.read()) Not tested and not overly familiar with the `re` module.
If there are not too many words, how about python3 python_script.py $(grep -Eo '\w+' ./file.txt) or even python3 python_script.py $(&lt;file.txt) if there aren't some formatting characters that require removal with the `grep`
&gt; If you're using python why don't you read the file in python ? good point.
You have a terminal on your phone? How often do need to use it?
Get the words into a list or array, then use a for loop calling the python script.
Fair point indeed. However the python script, in this case, should not read from disk.
&gt;python3 python\_script.py $(grep -Eo '\\w+' ./file.txt) &amp;#x200B; still no luck with that. &gt;python3 python\_script.py $(&lt;file.txt) &amp;#x200B; nor with this.
This reminds me of that book, The Cuckoo's Egg. Will moving the Emacs executable work?
I'd suggest that your python script is at fault...
Have you tried, in your python script, looking at `sys.argv` and not `sys.argv[1]`. Just sanity check.
Make a root account of the same name in your own computer, set the password of your choice. Now replace the hash string in the /etc/shadow of the target with your own (This might be tricky).
use realpath input_file="$(realpath $1)" output_file="$(echo "$input_file" | sed -e "s/\.$//g").pdf"
I don't have an explanation for why it's this way, but this: grep -Eo '\w+' someFile.txt | xargs echo returns one line with all words. But when specifying the replacement string: grep -Eo '\w+' someFile.txt | xargs -i echo {} it works.
I love awk, all this plus you can build an http server with it.
Hahaha, that's amazing!
&gt;You have a terminal on your phone? How often do need to use it? Not OP but I use the terminal on my phone all the time, since my Pi is headless and I am too lazy to actually get a hardware shutdown button done.
xargs -n1 Should do it, no?
You can use either: exec 99&lt;&amp;- or: exec 99&gt;&amp;- They will work identically. The code paths are almost identically the same (they are handled in two paths in Bash's parser code, but it ends up calling the same function with the same arguments). Having: exec 99&lt;&gt;&amp;- work as well seems like a worthwhile addition to Bash. It does not introduce any ambiguities. Perhaps you could raise it raise in on [the `bug-bash` mailing list](http://savannah.gnu.org/mail/?group=bash).
Excellent, thank you. I will do that!
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/u_colinhines] [Slice N Dice—a short post showing basic data manipulations using Bash](https://www.reddit.com/r/u_colinhines/comments/c3ygj3/slice_n_dicea_short_post_showing_basic_data/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
This is interesting to me, we use serial UART adapters at work to connect to ssd devices in development for testing. I had no idea you could do this with bash.
It's really handy. I guess that since "everything in Linux is a file", bash doesn't have to know the difference between, say, a text file and a tty.
How did you find that out from the picture?
Not from the picture, just from knowledge. Permissions are correct and there's no + at the end of the permission set indicating ACLs are in use. noexec is a common mount flag for untrusted media, so it's likely the best answer.
It's a brightness controlling file in /sys/class/backlight which requires sudo access.
i want to assign the brightness incr key to a script that increases my backlight. My laptop has a gpu which doesn't support normal commands like xbacklight. so the only way is this.
y tho just edit the python script to parse the args propertly instead of adding more glue to the stack
It actually receives all arguments at once, not one by one.
Yes!
Awesome catch
!remindMe 1 day
I will be messaging you on [**2019-06-24 10:59:55 UTC**](http://www.wolframalpha.com/input/?i=2019-06-24 10:59:55 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/bash/comments/c3rg4d/slice_n_dicea_short_post_showing_basic_data/erulyu6/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/bash/comments/c3rg4d/slice_n_dicea_short_post_showing_basic_data/erulyu6/]%0A%0ARemindMe! 1 day) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! erum1ny) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
`brightnessctl`?
for x in $(find \~/Musiek -type f -name '.mp3' | sed 's/.mp3//g'); do sox "$x".mp3 "$x".ogg; done
The proper way to do this would be to use the `FPAT` variable which allows you to define the field by content (available in GNU awk &gt; 4.0). In this case you define something like `FPAT = "([^,]+)|(\"[^\"]+\")"` which defines each field as something that does not contain a comma or something that has opening and closing double quotes. This can be modified further for more complex use cases. For even weirder Csvs it is better to use a full fledged csv parser (available in python, perl or other languages).
I love bash for stuff like this.
I'll have to look into the FPAT variable. Thanks! That's not something that I've read up on yet. &gt;For even weirder Csvs it is better to use a full fledged csv parser (available in python, perl or other languages). This is, of course, true :)
* Muziek, not Musiek * `find` glob is missing an asterisk – `*.mp3` * completely breaks for paths including spaces, such as the example one provided by OP: $ for x in $(find Muziek -type f -name '*.mp3' | sed 's/.mp3//g'); do echo sox "$x".mp3 "$x".ogg; done sox Muziek/Europe/Secret.mp3 Muziek/Europe/Secret.ogg sox Society.mp3 Society.ogg sox [Bonus.mp3 [Bonus.ogg sox Track].mp3 Track].ogg sox (2006)/02..mp3 (2006)/02..ogg sox Always.mp3 Always.ogg sox the.mp3 the.ogg sox Pretenders.mp3 Pretenders.ogg This will work better: find ~/Muziek -type f -name '*.mp3' -print0 | while IFS= read -d '' -r file; do sox "$file" "${file%.mp3}.ogg"; done
You can give passwordless sudo to one file for your non root user. 1st hit on google (haven’t tested it myself, but have some scripts like it in my enterprise environments): https://serverfault.com/questions/294661/how-to-grant-sudo-rights-only-to-specific-script-files
find ./ -maxdepth 1 -iname "\*.mp4" -type f -exec bash -c 'var="{}"; echo sox "$var" "${var%%.mp4}.ogg"' \\;
Thanks! This worked. Thank you very much!
Did you check setgid?
^^^ Setting guid on the parent directory will make all files inside that directory get the same permissions. chmod g+s
Shebang = #!
You probably need to post the exact form of the data. Because something like below works for me $ printf "ab,\"cd,de\",ef,,xy,yz\nAB,\"CD,DE\",EF,,,4\n" ab,"cd,de",ef,,xy,yz AB,"CD,DE",EF,,,4 $ printf "ab,\"cd,de\",ef,,xy,yz\nAB,\"CD,DE\",EF,,,4\n" | awk -F, '{print $1,$2,$NF}' FPAT='([^,]*)|("[^"]+")' ab "cd,de" yz AB "CD,DE" 4
Interesting. The example that didn't work could actually be dealt with without needing to use FPAT at all (no quotes), but I don't think that matters too much. It was: ``` 1,20773838140,431308,2 2,33245442870,355033, 3,180478224200,2522497,2 4,94283303770,992506,2 5,100351081650,1646459,2 6,2557369410,81400,2 ,,6029203 ``` doing `awk -v FPAT='([^,]*)|("[^"]+")' -v OFS=',' '{$1=$1}1' $file` got me ```1,20773838140,431308,2 2,33245442870,355033, 3,180478224200,2522497,2 4,94283303770,992506,2 5,100351081650,1646459,2 6,2557369410,81400,2 ``` So it's basically skipping the last line entirely.
&gt;$ for x in $(find Muziek -type f -name '\*.mp3' | sed 's/.mp3//g'); do echo sox "$x".mp3 "$x".ogg; done just a little explanation of the commands, it may help OP to understand the logic and play around a little: (ingles quebrado a frente, sorry :)) &amp;#x200B; $ for x in -&gt; *here "x" is a variable. You can call it whatever you want... x, a, Susan... But whatever you choose, you need to reference the same name ahead.* &amp;#x200B; $(find Muziek -type f -name '\*.mp3' -&gt; *the command to find the files, it will be stored inside the variable created above, "x" in the case* &amp;#x200B; | sed 's/.mp3//g'); -&gt; *A little trick to help to create the new name of the finded files. The sed command strips the ".mp3" from the name, so it will be easier to add the ".ogg" later and compose the new file name.* &amp;#x200B; do echo sox "$x".mp3 "$x".ogg; done -&gt; *The act: for every name finded, shout on screen: sox "$variable" and put .mp3 (because sed erased early) along and "$variable" and put .ogg along too.* *done.* Very simple after you get used to. &amp;#x200B; Hope this help, try to creat a folder, inside create many txt files and play arroud with "for in - do - done" to understand, it´s fun.
I just did something like this for WAV to FLAC and I've simplified it down here for mp3 to ogg. I tested it against a path with spaces all over the place. ``` find . -type f -name "*.mp3" -print0 | while read -r -d $'\0' x; do TARGETOGG="/output/path/${x%.mp3}.ogg" DIRNAME=`dirname ${TARGETOGG}` mkdir -p "${DIRNAME}" sox -S "${x}" "${TARGETOGG}" done ``` If you don't want the output to go somewhere else, you could easily do away with all the variables and the `mkdir`: ``` find . -type f -name "*.mp3" -print0 | while read -r -d $'\0' x; do sox -S "${x}" "${x%.mp3}.ogg"; done ```
What is the end use of this? What is the big picture, the larger goal? Why do you need a function to do this? Side note, directly calling a GUI app from a shell function is a generally bad idea, since you have no way to know if a GUI is running.
Even if you access via sambashare?
oops sorry that i didnt make myself clear enough this is just for private purposes and a part of my .bashrc\_custom\_functions file which gets loaded when opening a terminal the use case: if there exists folder such as: folder1, Testi, exams when i type "uni tes" into the terminal it would open up a file manager being directly inside the folder Testi it is probably just convience and couriosity how to write this function nonetheless i have some troubles with the mentioned situation and i realize this is a very specific question, however i think this might also be a nice function for anyoneelse regularly accessing folders within another folder PS: so the very reason why i came up with this is, that i organize my folder quite systematically, but i need to access my university folders very often. And i do have this cool dropdown terminal feature. So i just wrote basic functions to access my university folder instead of clicking through the file manager or using a symlink on my desktop and for now it is indeed faster and more convinient :D.
You already got the correct answer if you use standard tools. However, if you want to do it a bit a fancier, you can make use of recursive globbing and GNU parallel to even do the conversion in a parallel fashion. You have to enable recursive globbing in bash with (this is only available on bash 4, so not possible with the default mac bash): shopt -s globstar You can install GNU parallel with your package manager. And then you can just do this: parallel sox {} {.}.ogg ::: **/*.mp3 Nice thing about parallel is also that you can use the replacement string {.}, which is the argument but without the extension. On top of that, GNU parallel also handles the spaces for you. But always nice to know how to do it without the fancy tools, if you end up on a machine that doesn't have these.
but you didn't want anything that looked like that....
Not sure, worth testing.
Using a case statement input_string=$1 count=0 for folder in $(ls -d */) do if [ "$(echo "$folder" | grep -i "$input_string")" ] then ((count++)) dir_to_cd="$folder" # if more than one then it gets overwritten else : fi done case "$count" in 0) echo "no directory by that name found" ;; 1) cd "$dir_to_cd" echo "you are in $PWD" ;; *) # display a menu of directories to go into esac
lynx -dump -listonly $url make a list of the output after some sed and awk magic, then use wget in a for loop
Too late, have the problem solved.
Although the first answer (for) needs some adjustments, that is the best answer. You can use it for most of you tasks in the future. Don't try to reinvent the wheel. Go simple.
Love how parallel often replaces loops. And it makes all easily readable too. Nevertheless I agree about being able to do stuff like this without fancy tools. I want to point out that gnu parallel can be embedded on a script through the embed option: parallel --embed &gt; parallel_script.sh And then you can source this script to use parallel maybe on another machine. I've use it to have parallel on a remote machine used for scientific computation on which I couldn't install parallel.
GNU parallel is serious feature rich software. It is unbelievable how much features you can find in that little package. Ole Tange sure has been (and still is) busy on that. If you get over its little strange syntax (:::) you start to use it more and more, even if you don't need parallelization. Its features just make it so much more useful than xargs.
Glad to hear it!
What should \`-t\` yield?
Here's a function which searches only the current working directory for directories matching the first argument. I used `cd` because I don't know anything about Dolphin. glhf uni(){ mapfile -t Dirs &lt; &lt;(find . -maxdepth 1 -type d -name "*$1*") case ${#Dirs[@]} in 0) cd / ;; 1) cd "$Dirs" ;; *) echo "${Dirs[@]}" ;; esac }
Instead of the for loop, `xargs` can be used. Makes the whole thing into a one liner lynx -dump ... | sed #or awk here gets the links | xargs wget
-t shows what is executed by `xargs` ... you sounded happy that your command looked like you expected it to be.... i.e. given a `file.txt` of $ cat file.txt word1 word2 word3 word4 you appeared happy that the passed command $grep -Eo '\w+' ./file.txt | xargs -t python3 python_script.py would run python3 python_script.py word1 word2 word3 word4 i.e. your script with, in this example, 4 arguments. when in fact the solution that you were wanting was $grep -Eo '\w+' ./file.txt | xargs -t -n1 python3 python_script.py which would show and run python3 python_script.py word1 immediately followed by python3 python_script.py word2 and so on
Thanks u/ang-p, I assumed \`-t\` printed all the arguments iteratively, not from a single call. That is why I was happy : ).
Ahh... `man xargs` -t, --verbose Print the command line on the standard error output before executing it.
You could use an infinite loop to keep the script running. If you're interested in other solutions, take a look at caffeine. Apparently there is also an option in VLC itself to disable the screensaver.
I think u must execute the script when you launch VLC instead of having it on the background checking all the time
 program="$@" mylist=$(ps -e | grep -i "$program" | awk '{print $1}') sleep 5s prog(){ while true do sleep 5s for item in ${mylist} do # your script here done done }
Thank you very much, i used your template and tweaked it a little bit (case insenstitive, when no parameter is passed it shall open the root directory, only showing the foldernames without absolute path) It does work as intended function uno(){ root_dir='~/Documents/uni' input=$1 folders=() if [[ ! -z $input ]]; then mapfile -t folders &lt; &lt;( find ~/Documents/uni -maxdepth 1 -type d -iname "*${input}*" -printf '%f\n' ) # | only get last string seperated count="${#folders[@]}" else count=1 fi case $count in 0) echo "no folder found like $input" ;; 1) dolphin ~/Documents/uni/${folders[0]} &amp; disown &amp; exit ;; # dolphin ${root_dir}/${folders[0]} &amp; disown &amp; exit ;; *) echo "Be more specific please. Possible Selections:" printf '%s\n' "${folders[@]}" ;; esac } I just have one question, why can't i seem to replace the filepath in find or in dolphin with the parameter $root\_dir? i tried double quote, single quote, echoing nothing seems to work Find throws me a "cant find file or folder" dolphin also does behave wierd, i tried echoing it and nothing seemed off cd doesn't work either if i pass the $root\_dir variable instead of hardcode it
Thank you very much At first i wanted to use your template but ten realized i had to wrap the for folder loop with an if clause in case there is no parameter passed and thought it looked to messy. Thank you still reminding me to be able to loop through ls results
alias vlc='(sleep 300)&amp; while pgrep -g $!; do echo hi; sleep 4; xdotool whatever ; done'
`~` is not a real variable; it's for hacking away at the command line, not scripting. Do `root_dir="$HOME/Documents/uni"`
you probably think this is common knowledge but i am very grateful for your answer i didn't learn this by book but by trial and error and asking people and this is something i wouldnz have known if noone would tell me thanks that i could learn from you
use a wrapper vlc_plus(){ input_file="$@" vlc "$input_file" &amp; # your script here } or something like this vlc_status(){ is_vlc_running="$(pidof vlc)" if [ "$is_vlc_running" ] then # your script here else exit 0 fi } main(){ while true do vlc_status sleep 1m done } main
`man bash` is a life-changing resource. I know it's super intimidating, but just read it at random and ask questions about things that don't make sense. [Bash Pitfalls](https://mywiki.wooledge.org/BashPitfalls) is a similar resource in that it's dripping with powerful information, but it's overwhelming at first. Just keep coming back to it. Ask questions here if you don't exactly know what you're looking for, but definitely check out [[bash]](https://stackoverflow.com/questions/tagged/bash) on SO.
can you please explain what this will do?
yes
r/inclusiveor
Thanks for contributing to the spam every time somebody asks a this or that question, and stopping people from getting legitimate answers. Learn some new jokes.
Okay, any other use cases? I'm struggling to think of times where I'd need to ssh into one of my servers and don't already have my laptop with me (except in an emergency).
I don't think the `exit` is or the `main`. ``` vlc_status(){ is_vlc_running="$(pidof vlc)" if [ "$is_vlc_running" ] then # your script here fi } while true do vlc_status sleep 1m done ``` This should be enough and will not force the script to exit.
Don't use `which pgrep`. Do this instead. tail --pid ${VLCPID} -f /dev/null (check out --pid in the man page for tail)
Many distros have some sort dns resolved hostname. I’m guessing your IP is in dns as briandeesiphone.
Watch out for Brian DEEZ NUTS!
This has happened to me and I remember researching and finding out that it's totally benign. There is someone on your wifi network with that username. I don't remember why it happens though, sorry.
Here is a good instruction page to change your prompt: https://www.ostechnix.com/hide-modify-usernamelocalhost-part-terminal/
Could you use rsync for this, or is it not installed in your environment?
No need to keep polling, if you can make your own \~/bin/vlc with xset s off /usr/local/bin/vlc "$@" xset s default vlc has a --disable-screensaver option, ought to be in vlc's Preferences too.
I suppose Rync -av /path/to/transmission/ /path/to/media. However once the operation is complete I plan to delete the contents of the transmission folder, if the contents of the transmission is emptied how would that effect the target directory?
Hostname is set via dhcp, check /etc/hostname or /etc/sysconfig/network
Run a test, but I believe rsync does not delete files in the target if they were removed from the source, unless you supply the --delete argument.
Thanks a million, tested it there and it works perfectly!
No worries, glad it worked out for you :)
You should read about "associative arrays" in bash. Those are they way to implement structures, hashes and multidimensional arrays
top is designed for interactive use. Once you start it, it will keep running until you hit "q" or kill the process. You'll probably want to use e.g. "ps auxw" instead.
 prefix=pre a=aaa b=bbb c=ccc array=(a b c) for letter in "${array[@]}"; do filename="${prefix}-${letter}" touch "$filename" echo "$filename created" done Output: bash reddit.sh pre-a created pre-b created pre-c created
Your $filename for $a will result in “pre-aaa”, I want it with the variable name (single "a"), like I wrote on the output
Alternatively check out atop? It can run as a service and record values based on timing you specify. Then you could use your script to either start or stop the service instead.
You’ve heard of Google, right? https://unix.stackexchange.com/questions/129084/in-bash-how-can-i-echo-the-variable-name-not-the-variable-value
Thanks TGR, I’ll look into that.
&gt; You’ve heard of Google, right? You mean 10^100? That link is one of the first I've tried, I also have tried the method tried by the OP, but using the answer ``` var_name=(${!foo@}) echo $var_name” = “$foo ``` returns me an error on the echo line saying “bad substitution” using zsh, and something else using bash
 prefix=pre a=aaa b=bbb c=ccc array=(a b c) for letter in ${array[@]}; do A='eval echo \$$letter' B=$(echo $(eval $A)) filename="${prefix}-${letter}" touch "$filename" echo "$filename created" echo "var \$$letter content $B" done Output: bash reddit.sh pre-a created var $a content aaa pre-b created var $b content bbb pre-c created var $c content ccc
You would need to use an associative array like this declare -A MYMAP=( [a]=aaa [b]=bbb [c]=ccc ) Now you can use For i in ${!MYMAP[@]} Now $i is the variable name And bring the variable value with "${MYMAP[$i]}" That should work. Sorry I can't made the code I'm on my phone.
I'm following the tutorial, on Part 4 now. &amp;#x200B; I think you have a typo in main.tex: `\completecontents` should read: `\completecontent` &amp;#x200B; Looking forward to the next part.
Use hashmaps: prefix=pre declare -A myvars=( ["a"]="aaa" ["b"]="bbb" ["c"]="ccc" ) for letter in ${!myvars[@]}; do filename="${prefix}-${letter}" echo "$filename created" echo "content ${myvars[$letter]}" done Output: bash reddit.sh pre-c created content ccc pre-b created content bbb pre-a created content aaa
I believe this is the correct answer.
What if instead of using a multidimensional array, you used just a plain line, as in a file. Different fields represent different data-type (so to speak). field one is $publication, field two is edition and so on. grep, awk, sed and cut will do the job.
Fixed, thank you.
You do know that google works by indexing content, right? It doesn't create it. At some point, someone has to post a question and have it answered in order for google to index it. And more often than not, threads on reddit where someone asks a question and is just told to google their question end up on the top results in that index when people google for an answer. Don't be that guy.
"top -n 1" will run top once then exit. Soooo... &amp;#x200B; for something in whatever; do top -n 1 sleep 1 \# the part of your code where you test to see if a process exists and such goes here \# I recommend using pgrep, as in &lt;&lt;pgrep -fa "Process Name" &gt;&gt; done &amp;#x200B; So then it's running top once a second, but it looks like top is just updating normally (depending probably a little on your terminal settings, but it should work).
Use a hash table to check for identified files, of just hardlinks identical files together so they are logically one file with multiple names.
I would give you gold but I'm broke Here you are a golden medal 🏅
You're welcome, had me stumped for a while and trying to google 'context' is a nightmare!
&gt; Use hashmaps: Thank you, I didn't know about them. It works fine in bash, should I ask in r/zsh how to translate this feature? Also, how can I get my script executed with Bash without sayng `bash ~/script.sh`? I mean, I already have the Bash hashbang in it, but I need to explicitly launch the above command in zsh to avoid errors
Thank you, I have now discovered associative arrays. Do you know how can I explicitely run the script in `bash`? I already have tried the hasbangs ``` #!/bin/bash #! /usr/bin/env bash ``` but none of them works if I launch the command with `. ~/script.sh` in `zsh` (my default shell)
Zsh version :) #!/usr/bin/env zsh prefix=pre typeset -A myvars myvars[a]="aaa" myvars[b]="bbb" myvars[c]="ccc" for k v in ${(kv)myvars}; do filename="${prefix}-$k" echo "$filename created" echo "content ${v}" done &amp;#x200B; Also, how can I get my script executed with Bash without sayng bash ~/script.sh Hm, if you have a shebang in the first line in your script, it's must be executed in the correct interpreter.
No doubt, sorry about that. Yes, the typesetting engine has a terrible name, search-wise. In the future, try variations on: * `contextgarden completecontents` * `context tex.stackexchange completecontents`
I will do.
Associative arrays were an addition in bash version 4. Check your version using `bash —version`
The cat command is unnecessary. &amp;#x200B; `sort -n -k 5,7 input.json &gt; output.json`
\&gt; sort -n -k 5,7 input.json &gt; output.json &amp;#x200B; True. I am in the early stages of learning json. &amp;#x200B; Any reason why my output looks like this? &amp;#x200B; `[` `]` `{"name":"A Label", "value":"a value"}` `{"name":"X Label", "value":"x value"},` `{"name":"Y Label", "value":"y value"},`
For working with json from the command line, I highly recommend [jq](https://stedolan.github.io/jq/). Here's an article I found with a quick search that may apply to what you're doing: [http://bigdatums.net/2016/11/29/sorting-json-by-value-with-jq/](http://bigdatums.net/2016/11/29/sorting-json-by-value-with-jq/)
I have been here an tried it already. If I try running `$ cat sample.json | jq -s -c 'sort_by(.name) | .[]'` I end up with the following error `jq: error (at &lt;stdin&gt;:5): Cannot index array with string "name"` I moved on. I have no idea why its ignoring it yet, I followed instructions solidly. Can you spot the error?
&gt;Any reason why my output looks like this? The sort program doesn't know anything about json (or any other format for that matter). It just takes what it's given and sorts all lines of input. So why that order? You gave it the `-n` flag. According to the man page that will `compare according to string numerical value`. If you look at an [ascii table](https://www.ascii-code.com/) you'll see the ascii codes for the characters in question. Of the characters at the beginning of the lines in your input, `[` has the smallest value, then `]`, then `{`.
I'm not sure your exact input file, but based on your previous comment about the square brackets coming first when you sort, I'll assume it's like this: ``` [ {"name":"X Label", "value":"x value"}, {"name":"A Label", "value":"a value"}, {"name":"Y Label", "value":"y value"} ] ``` In the article, the author's examples are _not_ in an array already, which is why they use the `-s` flag. Because this input is already in an array, using `-s` means jq is actually operating on input like this: ``` [ [ {"name":"X Label", "value":"x value"}, {"name":"A Label", "value":"a value"}, {"name":"Y Label", "value":"y value"} ] ] ``` Given the original input (one set of []) this works: ``` jq 'sort_by(.name)' &lt; input.json ```
&gt;jq 'sort\_by(.name)' &lt; input.json Dude, You rule. Thank you.
OK, should I be concerned ? I mean it isn't recognizable at all. Ihave never seen something like this change. I havn't changed it. and i don't know a brian. It's still really mysterious..
thank you. I am more concerned why.
this is my macbook btw.
This works for me, however your example in the post and your comment below disagree about whether you have a valid JSON array or a sequence of JSON objects, so you might need to tweak it to suit your needs. https://jqplay.org/s/ae0RTNbTiY
Check this in your terminal `host \`hostname -f\``
A small correction: sorting by numerical value means that numbers will be ordered as expected, e.g. 1, 2, 3, 10, 15, 20, 30. Sorting by ASCII value would order them as 1, 10, 15, 2, 20, 3, 30.
Can you suggest a method for doing this? It's kinda over my head
astrologer in usa, astrologer in texas, astrologer in new york, indian astrologer in usa, indian strologer in texas, indian astrologer in dallas, indian astrology in usa, best astrologer in usa, best astrologer in texas,
Sorry, I don’t have more suggestions on that than the previous posters already have given.
Also what editor is this?
thanks! this works! problem solved.
That's a really weird construct. Double paranthesis is artihmetic expansion, but there's no arithmetic going on. So basically that for loop will just run forever. Which is a legitimate thing, but the normal way to do it would be e.g. `while true; do`
Exactly my thought, is there any resource benefit from running this code as opposed to \`while true; do \` ? I suspect it's just 'another way to skin a cat'
That's using c-style(?) for loop syntax, as in: for (( i=0; i&lt;20; i++ )); do ...; done Now, if all 3 fields are empty, you create an infinite loop. It's a dumb way of doing `while :; do ...; done`.
what the fuck?
Why would you skin `cat(1)` though?
Mebbe the programmer uses that as an everything case that can cater for everything and they write all loops like that - if they ever want to change a loop they drop in any required values / formula to make it a once, conditional, fixed iteration or eternal loop...
I tried to test this, and it seems `for ((;;))` is actually behaving slightly different and is a bit faster than `while true`. **EDIT:** *After some more experiments, it turns out `while (( 1 ))` is the fastest way to do an infinite loop.* My idea was to use code like the following to repeat the loop one million times, and time it with the `time` command: foo=0 while true; do (( foo++ )) if (( foo &gt;= 1000000 )); then break fi done My actual experiments at the command line looked like this: $ foo=0; time while true; do if (( ++foo &gt;= 1000000 )); then break; fi; done real 0m2.208s user 0m2.198s sys 0m0.004s $ foo=0; time for ((;;)); do if (( ++foo &gt;= 1000000 )); then break; fi; done real 0m2.090s user 0m2.085s sys 0m0.000s I also tried using `:` instead of `true` in the 'while' loop, and it seems a `while :` is slightly faster than `while true` but still slower than `for ((;;))`. Here's the tests repeated ten times each: $ TIMEFORMAT='%U'; for i in {1..10}; do foo=0; time while true; do if (( ++foo &gt;= 1000000 )); then break; fi; done; done 2.183 2.204 2.173 2.179 2.173 2.205 2.207 2.173 2.210 2.184 $ TIMEFORMAT='%U'; for i in {1..10}; do foo=0; time for ((;;)); do if (( ++foo &gt;= 1000000 )); then break; fi; done; done 2.052 2.026 2.043 2.068 2.041 2.071 2.043 2.050 2.057 2.114 Here's that `:` instead of `true`: $ TIMEFORMAT='%U'; for i in {1..10}; do foo=0; time while :; do if (( ++foo &gt;= 1000000 )); then break; fi; done; done 2.108 2.144 2.115 2.105 2.123 2.110 2.112 2.125 2.118 2.123 And right now as I'm typing this post here, I got the idea to test `(( 1 ))` instead of `:` or `true`, and that's again a different result. It's faster than `for ((;;))`, see here: $ TIMEFORMAT='%U'; for i in {1..10}; do foo=0; time while (( 1 )); do if (( ++foo &gt;= 1000000 )); then break; fi; done; done 1.917 1.919 1.865 1.855 1.887 1.878 1.889 1.880 1.883 1.873
Use a checksum tool like `md5sum` and store the results indexed on the resulting hashes. When two files have the same hash, they have the same data identical. The easiest was is to use a bash associative array.
Aaaah cheers man I'll look into that
`while (( 1 ))` - arithmetic - fast `for (( ; ; ))` - arithmetic, but a few tests.. not quite as fast... `while : ` - evaluates arguments after `:` ( i.e. nothing) and returns `0` not quite so fast... `while true` - runs `true`, gets result evaluates it.....
(( is a keyword while : and true are (builtin) commands. The parser does less parsing for the keywords since things like word expansion don't apply.
Running it with `.` sources it in your current shell. You could put something like `[[ $SHELL == bash ]] || exec bash "$0"` at the start of the script to force it to use Bash, but that defeats the entire purpose of sourcing it. To run it normally, simply run `~/script.sh`.
Thanks! Do you know if I can use associative arrays for more than one content per variable? E.G.: a for loop that sends email to person A1 to his A2 email at hour A3, and the same goes with person B1, C1… in this case A1 can be the variable, but I need A2 and A3 to be the content
Is there anything hidden? echo "$output" | xxd -
Turns out there is a hidden byte in the case of $inst_code (And admittedly I should have remembered it, I was specifically told there was a leading byte that wasn't part of the value :/) Oddly enough, I'm having the same issue in another variable/case and there is no hidden data in the front of that one (at least not that xxd is identifying. Fortunately, I think I can safely use the leading wildcard and still be confident that my pattern match is not open to inaccuracy. Is there a way to remove the hidden component?
&gt; Oddly enough, I'm having the same issue in another variable/case and there is no hidden data in the front of that one (at least not that xxd is identifying. If `xxd` isn't displaying it then it isn't there..... so the problem there is your side of the keyboard
It would seem like what you're looking for is gnu getopt. A quick google should give you some howto's. There is also a built in getopts in bash that does basically the same thing but with the main exception that it only supports short one letter options.
*tr -cd 0-9* would pass only digits, if that's any help.
For me, `while :` is consistently the fastest of those.
An easy way is for $i in „$@„ do case $i in -h | --help ) echo „help“; shift;; --target=* ) target=„${i#*=}“; shift ;; -- ) shift; break;; * ) break;; esac done
interesting.... I wondered if it was down to just what you were running, ran it 3 times for each of the following cases, while I couldn't get a skew to push `while :` to the top, I did,hardly surprisingly discovered that a few million spaces that were or were not parsed made a difference, but what did surprise me was that the space between the cases `while :;` and `while : ;` increased performance. the first line of percentages is relative to the un-padded equivalent, the second row relative to the fastest on my box - `((1));' While :; While : ; For ((;;)); For (( ; ; )) ; While ((1)); While (( 1 )) ; 99.71% 100.61% 102.21% 104.93% 104.62% 106.78% 107.43% 100.00% 102.21%
`cat 1.txt | grep -F '**'`
So it should be smth like `#!/bin/bash` `cat /var/log/exim4/mainlog | xargs cat 1.txt | grep -F '**'` ? Sorry I haven't any ideas at this moment how to link this 2 files
while read line do x = `echo $line | awk '{print $1}'` y = `echo $line | awk '{print $2}'` grep $x /path/to/exim/log | grep $y done &lt; 1.txt Sloppy and not tested....so fingers crossed
I removed the cat out of my command, cause grep can do it all. Is the log file you want to look at `/var/log/exim4/mainlog/1.txt`?
Let me clear a thing. In /var/log/exim4/mainlog we have strings like a 20190623 00:05:53 fmail1 exim\[19605\]: 2019-06-23 00:05:53 xxxxx-000xxD-IZ &lt;= x H=(sender.com) \[ip\_address\] P=esmtpa A=auth\_plain:xS=26959 from &lt;x&gt; for someone@gmail.com 20190623 00:05:54 fmail1 exim\[19612\]: 2019-06-23 00:05:54 1henCr-00056D-IZ =&gt; someone@gmail.com R=dnslookup\_corp T=remote\_smtp\_corp [H=gmail-smtp-in.l.google.com](https://H=gmail-smtp-in.l.google.com) \[[173.194.221.26](https://173.194.221.26)\] X=TLS1.2:RSA\_AES\_128\_CBC\_SHA1:128 C="250 2.0.0 OK 1561237554 b12si5478436lji.90 - gsmtp" there are tons of them (du -sch /var/log/exim4/mainlog around 13Gb) &amp;#x200B; And I have 1.txt with 500 strings like a x1 y1 x2 y2 x3 y3 where x is a date(20190623 for ex) and y an email(someone@gmail.com). So I need to check /var/log/exim4/mainlog with pairs of x&amp;y from 1.txt for rejected letters. &amp;#x200B; It should be something like cat /var/log/exim4/mainlog | grep $x1 AND $y1 FROM 1.txt | grep " \\\*\\\* " &gt;file.txt &amp;#x200B; My English is quite bad sorry for that. btw thank you for paying attention
Thank you!
Any thoughts &amp; heplful links would be pleased! Any actual lines of data as examples that you want to match would be pleased too
already tried something like that but thank you for your response anyway!
Do I need to provide much more information than [https://www.reddit.com/r/bash/comments/c5v9sj/surely\_i\_need\_help/es4d0vi?utm\_source=share&amp;utm\_medium=web2x](https://www.reddit.com/r/bash/comments/c5v9sj/surely_i_need_help/es4d0vi?utm_source=share&amp;utm_medium=web2x) ?
That is surprising indeed. I can't reproduce that myself.
nope - but you had not posted that when I was reading through the comments about `cat`s and concluded that so far you had provided only a date with an `x` in it as an example...
i have put some edits to my post. Sorry for that.
Do you have a line with the mentioned ** in that you can post? Are the two files in order datewise? or does the entire 1.txt file need to be compared against every line of the 13GB logfile?
I wasn't going to reproduce the tests - even the fastest variant of `[...]` or `test ...` test $((foo++)) -gt 1000000 &amp;&amp; break; was still twice as slow - would have been over half an hour running everything three times - my `((1));` averaging in just over 2.4 seconds per million
Only 500 lines in 1.txt? in this cases i usually convert with regex101, reggexbuddy or alike to 1.sh 20190626 [add@ex.com](mailto:add@ex.com) \-&gt; cat mainlog | grep "20190626" | grep ["add@ex.com](mailto:"add@ex.com)" \[...\] Then simply launch [1.sh](https://1.sh) I use very often txt to .sh conversion, even sql CONCAT generating sh lines.
The first field is the date, right. input_file="$@" maillog_file="/var/log/exim4/mainlog" check_the_maillog(){ date="$1" email="$2" while read line do if [ "$(echo "$line"| grep "$date")" ] then echo "$line" | grep "$email" else : fi }&lt;"maillog_file" prog(){ while read line do date=$(echo "$line" | awk '{print $1}') email=$(echo "$line" | awk '{print $2}') check_the_maillog "$date" "$email" done }&lt;"$input_file" prog
Best I could come up with is something like this while read row; do grep "`echo $row | awk '{ print $2 }'`" /var/log/exim4/mainlog done &lt; 1.txt Might need to fiddle with grep arguments but I think that is what you're looking for?
Here is my attempt. Probably a cleaner way to do this in one line, but I am a little out of practice. # $1 is 1.txt # $2 is logfile while IFS= read -r line do x=`echo $line | awk '{print $1}'` y=`echo $line | awk '{print $2}'` sed -n "/$x/p" $2 done &lt; "$1"
Bash’s `read` command splits input based on $IFS (basically white space by default) so provided you have white space between “x1” and “y1” you don’t need to fuss around with `awk` to split the line. Something like this should work: while read date email do grep “**” /path/to/logfile | grep “${date}” | grep “${email}” done &lt; 1.txt However, that triple pipe will be a performance bottle neck so if the logs sequence the “**” date and email consistently in each log line, you can use a single `grep` statement to parse each line of the log file like this: while read date email do grep -E “^${date}.*${email}.*\*\*” /path/to/logfile done &lt; 1.txt This will match any line with “date...*anything*...email....*anything*...**” - you can swap around the email and `**` if the ordering is off. That will still mean your script have to parse the log file each time for each line in `1.txt`, which will be about 500 times. Again, not the most efficient but for a one-off, not terrible and probably “fast enough”.
It’s actually the original and standard style for c
And you want the lines ***with*** `**` that match *both* the date e.g. `20190623` *and* email address **exactly** *as contained in the txt file* - e.g. `[someone@gmail.com](mailto:someone@gmail.com)` ? If I get what you mean... while read mailline ; do if [ "**" == "$(grep -o "**" &lt;&lt;&lt;"$mailline")" ] ;then while read -a maillist ; do grep "${maillist[0]}" &lt;&lt;&lt;"$mailline" | grep -F "${maillist[1]}" ; done &lt;1.txt ; fi; done &lt;/var/log/exim4/mainlog
My solution reads the *big* file line by line and compares it with all lines in the small file... Although total data throughput will be identical, I think disk IO will be less than it would be if you were to take a line of the small file and run it against the large one....
 #!/usr/bin/perl -w use strict; open my $f, shift or die "$!"; my $ws = join("|", map { chomp; $_ } &lt;$f&gt;); my $pat = qr{$ws}; for (&lt;&gt;) { print if /$pat/; }
Hello, can you please explain a bit more? What is the reason behind this? Is it just usability or something else? What is the difference with just setting IP address to static manually? (I read the code, but I am not sure I understood everything there.)
A couple of thoughts: - You should never "steal" a static IP from the dhcp pool. The dhcp server might assign it to another device, and you will have trouble. Instead, configure the dhcpd to permanently assign an ip outside the pool to your mac. - It doesn't seem like you've considered what happens if you run the script twice - There's no need to reboot to change network settings, you just have to bring the interface down and back up - Echo'ing the new settings into the interface file and then removing the old with sed is a bad idea, since it's not guaranteed to always be the same. Move the original file out of the way and create a new one from scratch instead. - `cat foo | sed '/expr/' &gt; file` is bad form. Use `sed -i '/expr/' foo` instead. Change -i to -i.orig to keep the original file "foo" as "foo.orig"
 diff --suppress-common-lines file1 file2 | sed -e "s/^[\&lt;\&gt;]\ //g" -e "s/---//g" -e "s/[0-9].*//g" -e "/^$/d"
You said you tried zgrep but what about something like: grep -vxF -f f2 f1 * `-v` Select non-matching lines * `-x` Match whole lines only * `-F` PATTERN is a literal * `-f FILE` Read pattern from FILE
Try smth like this: declare -a users=( "name=John email=foo@example.com" "name=Doe email=bar@example.com" ) for i in "${users[@]}"; do export ${i} echo "Sent email to $name $email" done Output: bash reddit.sh Sent email to John foo@example.com Sent email to Doe bar@example.com I do not know how to add an associative array to the plain bash array.
\^\^\^ THIS \^\^\^ and the answer to your post is 'ansible' or 'chef' or 'puppet' .... you're making your life harder by trying to do it in bash.
I totally appreciate the feedback, this is why I posted the code and the workaround I made, out of good stackoverflow posts, as a begginer. &amp;#x200B; 1. I combine the DHCP IP fetching with a rule added at my router related to the MAC to avoid the IP assingment overlapping. The reason is ease of use, at a certain moment, perhaps is my ignorance but I had troubles to setup Port Forwarding to other than 1 subnet. And the DHCP config covers this same by default. What I could do is limit the DHCP range and automatically assing IPs outside of this range, but in the same subnet ? 2. By running the script twice you mean to check the configuration state before the execution ? I have run it twice and it simple overrides the existing but causes no additional problem. However would be neat if could check before that IP is set to dhcp 3. Aye, I was following a guide that used `service networking restart` but didn't do nothing so I went and said to myself reboot sure will do the trick. I will totally update this 4. 5. I kept using `cat` command because it seemed more friendly to read than the sed only integration. As I wasn't quite familiar with the syntax. At this step I didn't know exactly why the commands I tested didn't worked, resulting in empty files. I will rename and keep the original configuration file before writing the new one.
The reason behind this is given a working network configuration, set it to static in 2 commands, instead of writing everything. So that I can deploy faster a working environment, in a freshly new created VM in Proxmox.
&gt;'ansible' or 'chef' or 'puppet' are those Free (and Open Source if possible) ? I recently moved to Proxmox and everything I'm using is Debian based. Didn't knew of their existence, which one do you think is best for me?
I would highly recommend looking into having the DHCP server grab the MAC and assign a ‘DHCP reservation’ to the existing IP or one that you’ve selected. Managing and troubleshooting your method is going to lead to a disaster when a statically assigned set of VM’s can not communicate with the DHCP and their IP lease expire. What you’ll end up with is the same IP being assigned to multiple VM’s. Look into DHCP Reservations my friend!
No worries, happy to help someone learn. 1: I suggest making a plan for the subnet and sticking to it. Divide it up into logical parts, e.g servers from .10 to .99, clients from .100 to .199, dhcp range from .200 to .254 etc. depending on your needs. That way, when you're adding a host to your various config files, it's tidy and neat. Also makes it easy to know instantly what type of system a certain IP address is. 2: Yes, handling exceptions or unexpected situations is quite essential for scripts like this. The script you posted would create duplicate lines for instance. It might not break at first, but it's certainly not what you want to happen. 3: Then `service networking restart` is probably not the correct command for your distro/version :) Figure out what is, and use that. 4: Don't worry about it, this is just about learning the tools. cat abuse is typical for new admins, everyone's done it, and it's a logical way to start out learning to use pipes and building command chains. It's mostly harmless, but with experience comes learning to use the tools more efficiently, f.ex do `grep foo file` instead of `cat file | grep foo`, or `awk '/foo/ {print $1}' file` instead of `cat file | grep foo | awk '{print $1}' Anyway, as others have said - there are tools designed to do specifically this type of setup. I think it's great you're trying to script it yourself though, it's a great way to learn. If you decide to try an automation tool anyway, I suggest ansible, since it seems to have the most traction at the moment. Good luck and have fun :)
Yep. Another free option is saltstack. All are designed to help manage fleets of machines. Which one you choose comes down mostly to personal preference
You are great! Thank you!
As it is, this information is just stored as a string in that variable. If you want it as an array, you will need to wrap the `$(...)` part in another set of parenthesis, so `vmid=($(...))`. From there you can use bash array operations (`${varname[&lt;0-based-index&gt;]}`) to access different parts of it.
&gt; vmid=$(vim-cmd vmsvc/getallvms | grep "$vmname" | awk '{print $1}') &gt;how is this information stored? as array? Nope. &gt; vmid=($(vim-cmd vmsvc/getallvms | grep "$vmname" | awk '{print $1}')) &gt;how is this information stored? as array? It is now. &gt; echo ${vmid[3]} &gt; 17
Or iterate over it using for var in ${arrayname[@]} do stuff done
&gt; Or iterate over it using -- &gt; &gt; for var in ${arrayname[@]}; do echo $x; done; You won't get much out of that.... Where do you define `x` but that aside, it is no different from for var in $vmid; do echo "$var" ; done
The `return` here is just to exit the function early with a successful exit code (and that first condition is generally not included in most recursive definition _I've_ seen of Fibonacci). The "true return" are actually the `echo`. In bash everything is a string or a file.
All those lines that are printed are getting captured by the `$( )` and saved into the two variables `$a` and `$b`. That's where the stuff you feel is missing is disappearing to.
Another option is to use `mapfile` which can convert the string output into an array: mapfile -t -d ' ' vmid &lt; &lt;( vim-cmd vmsvc/getallvms | grep "$vmname" | awk '{print $1}') Now you have a `$vmid` variable and can access elements like `${vmid[3]}` for example. See `help mapfile` for usage info.
Most of the echos output go inside the variable a and b,so really your echo output to stdout(the screen) only once (at the end of the outside layer of the recursion, which is the first function fibonacci that gets called)
I would recommend creating an file with this code (i.e fib.sh ) and running it with `bash -x ./fib.sh` It will show you the output of the each command. Note that this function does not take into account 0 and starts the Fibonacci sequence at 1. I am using `fib 5` for the example below. bash -x fib.sh + fib 5 + '[' 5 -le 0 ']' + '[' 5 -le 2 ']' ++ fib 4 ++ '[' 4 -le 0 ']' ++ '[' 4 -le 2 ']' +++ fib 3 +++ '[' 3 -le 0 ']' +++ '[' 3 -le 2 ']' ++++ fib 2 ++++ '[' 2 -le 0 ']' ++++ '[' 2 -le 2 ']' ++++ echo 1 +++ a=1 ++++ fib 1 ++++ '[' 1 -le 0 ']' ++++ '[' 1 -le 2 ']' ++++ echo 1 +++ b=1 +++ echo 2 ++ a=2 +++ fib 2 +++ '[' 2 -le 0 ']' +++ '[' 2 -le 2 ']' +++ echo 1 ++ b=1 ++ echo 3 + a=3 ++ fib 3 ++ '[' 3 -le 0 ']' ++ '[' 3 -le 2 ']' +++ fib 2 +++ '[' 2 -le 0 ']' +++ '[' 2 -le 2 ']' +++ echo 1 ++ a=1 +++ fib 1 +++ '[' 1 -le 0 ']' +++ '[' 1 -le 2 ']' +++ echo 1 ++ b=1 ++ echo 2 + b=2 + echo 5 5
&gt;vmid=($(vim-cmd vmsvc/getallvms | grep "$vmname" | awk '{print $1}')) this gives ./scriptname.sh: line 2: syntax error: unexpected "("
i get scriptname.sh: line 3: syntax error: unexpected redirection
is it an algorithm to predict tool's lyrics??
Are you sure you're using Bash? That seems like ash to me.
https://reddit.com/r/bash/comments/c671rj/_/es8vym1/?context=1
yes that was the problem, ty
i didnt use bash, that was the problem, thank you
do you maybe know how i could run all of these commands in python script? it just wont accept $ anywhere
Yes, Python has completely different syntax... try this: import os vmid = os.popen("vim-cmd vmsvc/getallvms | grep " + vmname + "| awk '{print $1}'").read().strip().split(' 'j
the one with getoutput is not working but other one does :D now i need to work with all that and i have no idea how. can you maybe give me some links or something where i could learn this
&gt; the one with getoutput is not working but other one does :D Ah, you're probably using Python 2 then (the second only works in Python 3). &gt; now i need to work with all that and i have no idea how. can you maybe give me some links or something where i could learn this Do you mean learning general Python? There's an official tutorial [here](https://docs.python.org/3/tutorial/index.html), but I think that it may assume that you already have some programming experience. If you don't, you may be able to find some good resources for beginners at r/learnpython.
What version of bash are you running? echo "$BASH_VERSION"
 for f in *.pdf ; do echo $(pdfinfo "$f" | grep Pages) "$f" ; done &gt; output.txt
By golly, it works! Thank you.
I know Java and rust, but thx to your help I managed to power through writing entire python script today. I meant some resources for working with cli commands in python but I found my ways :D Thanks a lot
Didn't spot you were after recursive... find ~/ -name "*.pdf" -type f -exec bash -c 'echo "$(pdfinfo "$1" | grep -a Pages ) $1"' _ {} \; p.s. avoid using `ls` in your scripts..... Pattern matching (or globbing) (my first) and `find` for recursive are much better tools.... manpage links for the curious... [man 7 glob](http://man7.org/linux/man-pages/man7/glob.7.html) [man find](http://man7.org/linux/man-pages/man1/find.1.html)
I could not find out, all commands for seeing which bash am having did not return anything. At top of script I had to have #!/bin/sh But it does not matter anymore I did it in python Thank you :)
Why use bash then echo then pdfinfo vs just exec pdfinfo? Just curious. I'm always down for learning more about bash
Ah no worries! `sh` isn’t bash so that might also be why.
If you want an output like.. Pages: 1 Pages: 3 Pages: 12 Pages: 4 Pages: 2 Pages: 7 Pages: 1 you could just run -execdir pdfinfo {} \; | grep Pages ( modified it - '-execdir' is safer than `-exec` ) but for an output where you could tie the number of pages to the document itself, you need to be a bit trickier.... Many PDF documents don't contain a `Title` field, so you can't `grep` for it with `grep -E "Pages|Title"` even if you were happy about spreading each entry over two lines - e.g. Title: PowerPoint Presentation Pages: 2 Title: untitled Pages: 2 Pages: 1 Title: 14 Pages: 2 Pages: 1 Pages: 17 Title: PowerPoint Presentation Pages: 6 Pages: 1 This is where `-execdir` gets clever and awkward - it executes things itself - it doesn't use the shell, so things like odd filenames with funny characters and spaces are passed without trouble.... but using the filename twice - once as a parameter for `pdfinfo` and once as a filename - e.g. Pages: 2 - ./print-to-pdf.pdf Pages: 2 - ./Confidentiality agreement.pdf Pages: 1 - ./BA031-out.pdf Pages: 14 - ./MAX17043-MAX17044.pdf Pages: 2 - ./15-04-11-30-1.pdf Pages: 1 - ./out2-0.pdf Pages: 17 - ./Inductor.pdf Pages: 6 - ./2.Machine Commissioning.pdf is a bit trickier
You can probably come up with a complicated `find` and `exec` combination but it is best imo to keep things simple and modular. The first part of the problem is to identify if the file is pdf or not. Extensions can be used but not always very reliable. It is better to use the `file` utility like below file -bi test.pdf application/pdf; charset=binary The `-bi` option gives the MIME type for a file. Using this we can make a simple function that determines whether one or more files provided to it as an argument is a pdf or not. and if so outputs the page number Pdfpages () { for Files in "$@" do Filetype=$(file -bi "$Files" | cut -d';' -f1) if [ "$Filetype" = "application/pdf" ]; then pdfinfo "$Files" | grep Pages | tr -s ' ' fi done } Now we can use this function with `find` to return the page numbers. The function can also be directly used with wildcard expansion. export -f Pdfpages find . -type f -exec bash -c 'Pdfpages "$@"' {} + In the above case using `+` at the end allows find to feed as many files as possible to `Pdfpages` and since it can handle multiple arguments it can get the pages.
Ah ok. Thank you for the very clear explanation :-)
My perl is more than a little rusty, but does this not suck-in one of the huge files into memory, potentially exhausting RAM? Say it's a 20-Gb file and you have 4-Gb RAM and 4-Gb swap. Apologies if I'm bass ackward.
I cab help with a script. Demo sites [https://chatbox.vip/](https://chatbox.vip/). they don't need to be used on TOR or .onion sites.
 #! /bin/bash x=0 cat&lt;&lt;EOF | file name | number of pages | cumulative total | EOF for file in *.pdf do pages_in_this_file="$(pdfinfo "$file" | grep -i pages | awk '{print $2}')" x=$(expr $x + $pages_in_this_file) cat&lt;&lt;EOF |$file|$pages_in_this_file|$x| EOF done echo "total number of pages: $x"
Nope, you're right. I was banking on one being smaller than the other.
As you spesifically #! bash, you could use let x+=pages_in_this_file
&gt; x+=pages_in_this_file ((x+=pages_in_this_file)) ok, that works. side note: x+=$pages_in_this_file # &lt;- behaves like i am adding to a list, all to list[0] element
I don't know the answer to your actual question, but couldn't you just put all of the commands without a sudo in the script and then run the script with sudo?
Sure, but it ultimately doesn't matter.
Oh so you don't want to enter your password at all? I was thinking you meant you didn't want to enter it for every command.
You can configure the sudoers file so certain user dont need a password for certain programs. That's why you can succesfully mount a cdrom without typing password. Good luck, it's a nightmarish config file.
Right. Not at all. I want to type update.sh and have it all run without input from me until it's done.
There are several things wrong with this. First, please do not encode your password into a script, ever. It really defeats the whole purpose of sudo and you would honestly be more secure just configuring sudo to not require a password when your user uses sudo to run apt-get. This can easily be done by editing /etc/sudoers (using the visudo command of course). Second, the problem with your script is that you are attempting to imbed multiple interpreters (i.e. multiple shebang lines) in one script. It just doesn't work like that. Third, why are you calling /usr/bin/passwd?? are you trying to change your password? Even if the expect portion of your script somehow ran, I don't think it would do what you are trying to do.
This is on a personal computer, so security isn't an immediate concern. I already know it doesn't work. That's why I'm asking the question (and I explained that). The question is: how do I take one script to start the password prompt, have it call another script to satisfy the password prompt, and then call back to the first script to finish the remaining commands?
I'm no expert so I only know this in laymen's terms. Maybe someone can correct me. I'm sure you've seen this warning, and I'm not trying to be condescending: this shouldn't be done (in this way). Your operating system is trying to be helpful by making it difficult for you and others to do dangerous things. Don't write your passwords/passphrases/any secret in a plaintext file like a script. Someone evil could search for it on your system. Or maybe, 5 years from now you forget about it and post your dotfiles to github. It's just too big of a risk. An okay way to only type your password once is `sudo bash`. this starts a new shell that is authorized as root. All subsequent requests for authorization will automatically succeed (you won't be prompted). Exit the root shell when you're done with `exit` or ctrl-d. This is risky bc you can forget to close it and enter a dangerous command. But the preferred way to limit it for others is to call the script you wrote with `sudo myscript.sh` which will run only that script as root.
https://unix.stackexchange.com/questions/18830/how-to-run-a-specific-program-as-root-without-a-password-prompt
Your best option is to add the NOPASSWD flag to your sudoers file. **&lt;YOURUSERNAME&gt; ALL=(ALL) NOPASSWD: ALL** Otherwise, become root by typing use sudo bash or sudo su before running the script and you won't ave to worry about it.
Thanks.
I think that `&lt;YOURUSERNAME&gt; ALL = (root) NOPASSWD: /path/to/my/program` might be better so that only the program of interest gets no password access to sudo rights.
Your root access is probably timing out in between these long commands. If your script is *exclusively* running commands which require root privileges, take the `sudo` out and run the whole thing as superuser. sudo bash &lt;&lt;'EOF' for a in {,dist-}upgrade auto{clean,remove}; do apt $a -y done EOF
This is the script I use (aliased as '`dist-upgrade`' in my `.bashrc` file): #!/bin/bash if [ $EUID != 0 ]; then sudo "$0" "$@"; else { cd "$HOME" { echo echo '###############################################' echo '#### Updating `snap` Packages ####' echo '###############################################' snap refresh } &amp;&amp; { echo echo '###############################################' echo '#### Updating Packages ####' echo '###############################################' apt-get -o Acquire::ForceIPv4=true "$@" update } &amp;&amp; { echo echo '###############################################' echo '#### Upgrading Packages ####' echo '###############################################' apt-get -y "$@" dist-upgrade } &amp;&amp; { echo echo '###############################################' echo '#### Removing Old Packages ####' echo '###############################################' apt-get -y "$@" autoremove } &amp;&amp; { echo echo '###############################################' echo '#### Cleaning Things Up... ####' echo '###############################################' apt-get -y "$@" autoclean } || { echo echo "...Exiting"; echo } } exit $? fi &amp;#x200B; Don't remember why I have `cd "$HOME"` in there, but I'm pretty sure it resolved some issue..... Also, forcing it to use IPv4 can help when Google Chrome hangs during an update.
That is very much not a good option. That like resolving anxiety with a lobotomy. If you really want to go that route (which is very dangerous and I do not recommend), at least do it on a per-program basis: %admin: ALL = (ALL:ALL) ALL %admin: ALL = (root) NOPASSWD: apt-get
Place this into /bin/update-whole-os and set permissions to 4755(suid, rwx r-x r-x) \#! /bin/bash apt-get update apt-get upgrade apt-get dist-upgrade apt-get autoclean apt-get autoremove
I wrote bash scripts to do that. In my system a general purpose daemon runs some commands, for some users, as root: RunAsRootRequest --help 'RunAsRootRequest' checks if the supplied 'Command [Parameters]' are registered (in $SYSTEMLINKS_STORE_DIR/CommonSettings' variable 'RunAsRootAllowedRequests') as allowed to run as root for the invoking user. If they are, the supplied command line will be run without the need to supply root's password. If they are not, 'su' or 'XSu', will be used to request root's password and run, as root, the command line. Usage: 'RunAsRootRequest Command [Parameters]'. Notes: 'Command' must be available with root's login environment '$PATH' value. 'Parameters' will undergo shell expansion with invoking user's login environment. I.E. '$HOME' will be the invoking user's '$HOME'. Examples: 'RunAsRootRequest GuiLocalMail' # Root's system mail. 'RunAsRootRequest Crypt $COMMON_DATA_CRITICAL_DIR/FS.crypt $DOCUMENTS_DIR/Secret' # Mount encrypted FS on invoking user's '$DOCUMENTS_DIR/Secret' directory. Explaining how it works would take some time, let me know if you are interested.
Linux ignores SUID on scripts (any executable with an interpreter) - this won't work. Editing sudoers is the way to go here.
Sudo should sort of "unlock" for like 15 minutes or so by default... You should only need to type your password for the first one, and the following \~3 or however many sudo'ed commands should just run fine. Almost every distro has been like that as default for me, unless you've changed something. Strange if it's not like that.
I forgot it... Again
Not the answer to your question, but a solution for auto updating. What I have saved within /etc/cron.weekly `:/etc/cron.weekly# cat autoupdate sudo apt-get update sudo apt-get upgrade -y sudo apt-get autoclean pihole -g -up pihole -up`
Please don't fall into this trap - processing options and arguments is deceptively complex. Use getopt (as mentioned above).
`set passwd "Mypassword"` NOOOOOoooooooooooo.......
That's not my real password lol. Chill 🤪.
at this point why are you not just using *unattended-upgrades*?
I think asking questions is great and you shouldn't be punished for it, but security should always be a concern. You shouldn't do this because if you downloaded linux malware or someone tried to exploit your box and escalate privs then they have an admin computer on your network. gg I'd do what ralfwolf suggested and edit the sudoers file
As others said, not good idea to have your password in plain text inside your script. But if you dont care about that, easiest solution would be sudo with -S option. echo “password” | sudo -S
It only is if you want to support arbitrarily complex options. If you’re fine with options being “--foo” and “--bar=baz”, no problems. Or what example are you thinking of that would require getopt?
Its this whole line sir! myuser ALL=(ALL) NOPASSWD:/path/to/awesomeness/*,/road/to/success/*
The reality is that scripts grow, especially in industry. Things get added to even the simplest script. Best to start right and avoid the traps: [https://www.gnu.org/software/libc/manual/html\_node/Argument-Syntax.html](https://www.gnu.org/software/libc/manual/html_node/Argument-Syntax.html)
Just add NOPASSWD: ALL to /etc/sudoers for your user
Try using xargs -I
for one .csv file awk -F "," '{print $1 "=======================\\n" "LPAR\_NAME : " $2 "\\n" " RAM : " $3 "\\n" " CPU 1 : " $4 "\\n" " CPU 2 : " $5}' my\_csv\_file.csv For all files in dir I like find if they have the same naming scheme for file in $(find /your/dir -name '\*.csv'); do awk -F "," '{print $1 "=======================\\n" "LPAR\_NAME : " $2 "\\n" " RAM : " $3 "\\n" " CPU 1 : " $4 "\\n" " CPU 2 : " $5}' $file; done
About your experiment at the end of your post, that experiment would work if you remove the `` ` `` around the cat command. About what to do with the `$1` argument, you could add a check for it being a filename or directory name. You could do this inside the `&lt;( ... )`, perhaps like this: while ... ... done &lt; &lt;( if [[ -d $1 ]]; then cat "$1"/*.csv else sort "$1" fi ) This would run the 'cat' command line you experimented with if it's a directory, and it will run your original 'sort' command otherwise.
I would use find in a for loop. &amp;#x200B; ```for file in $(find /var/www/cgi-bin/LPAR\_MAP/ -name '\*.csv');```
For displaying cat file | sort --key 1 &gt; temporary_file now read from the temporary file in a for loop for the formatting check the first field of the line for reading all csv files use a for loop to run the script on each file
I replied to your other thread. Please check it out!
Where CONTENT_IMAGE specifies an image file, I would like to have it run recursively on every file in a folder of images. image1.png,image2.png,image3.png etc
I think you are looking for the `find` command with the`-exec` flag. I can never remember the syntax of hand. `man find` and search for exec.
So you want to enable your script to operate on multiple files? In that case you should simply loop over "$@" and run your original script in the loop body.
Please re-word your question as it doesn't make any sense. If you talk about a range of IP addresses you need to specify a start address and *later* end address, and they should have some sub-net in common. And then your attempted answer has addresses which don't match the problem statement in any way.
Hi there. Correct. I would like to have sed delete all lines that have an IP address within a given range. Can you help me to do that please? Many thanks!
As long as they are aligned on dot boundaries, you can just use a regex. For instance 207.46.204.0/24 is the same as 207.46.204.\* If you need to math on non-aligned blocks, that becomes a much more complex job. You'd probably need to use a for loop to iterate over each entry in the list, and then use a tool like ipcalc to determine if each one is within a range you want to remove or not. If it isn't then output that entry to a tmp file.. If it is then skip over it. And at the end the tmp file will have all the entries you don't want to remove.
I didn't think of regex! Good point, thank you! So do you mean, something like this? sed -i ' 207.46.204.\*/d' access.log Can I combine a few of these ranges in one sed command to keep the script clean or must I separate them out? (like using | )
For writing to files you could use something like make_html(){ cat&lt;&lt;EOF &lt;html&gt; &lt;head&gt; &lt;title&gt;This is a website&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt;This is a paragraph.&lt;/p&gt; &lt;/body&gt; &lt;/html&gt; EOF }&gt;"$your_html_file"
Thanks. I'm not sure I understand
It's probably something about the quotes and bash interpreting some parts of the line as code instead of seeing it as pure text. Instead of battling with those `"` and `'`, perhaps use this method here: cat &lt;&lt; 'END' &gt;&gt; /root/.bashrc put your line of text here END Using this `&lt;&lt; 'word' ... word` method, bash will then not try to interpret anything about your line of text.
You should be using single quotes on your first echo like this echo 'alias tc-ipi="echo $(ifconfig | grep broadcast | awk {'print $2'})"' &gt;&gt; ~/.bashrc When you use the double quotes, bash will not perform the command [substitution](https://www.gnu.org/software/bash/manual/html_node/Command-Substitution.html]; and will just print out your local IP from the first time you ran the command.
you're not escaping the inner quotes
This may work ```'alias tc-ipi='\''echo $(ifconfig | grep broadcast | awk "{print $2}")'\' ``` which resolves to ```alias tc-ipi='echo $(ifconfig | grep broadcast | awk "{print $2}")'```
You'd have to replace the image path and name with $1 (the 1st argument after the script) and then run a for loop or find.
find example is in the other comment and is a better solution a for loop would work something like this for i in *.png; do nameofyourscript.sh; done
How is this possible? Since I understand the single quotes remove all expansions including the command substitution. Would not double quotes be better? Because these would not suppress the expansions that start with "$", "` "and" \ ".
Sed isn’t the best tool to manipulate CIDR ranges. I’d go with Python and the ipaddress module which has built in support for it.
Please provide error
Thanks. I'll try to make this work
Many web servers have a “dontlog” functionality to prevent certain IPs from being logged in the first place. Nginx: https://bjornjohansen.no/exclude-requests-from-nginx-access-log Apache: https://www.google.com/amp/s/www.howtoforge.com/setenvif_apache2/amp/
Question - what's the point of the inner echo and subshell? Why not just this: `cat &lt;&lt; 'END' &gt;&gt; somefile` `alias tc-ipi="ifconfig | grep broadcast | awk '{print \$2}'"` `END`
Please share the code
&gt; Hi there. It does make sense :) ***Now*** it does - but only because you edited the heck out of it... Prior to that, if people did not know what `/24` meant and tried to go by what you had written, they would have gotten nowhere....
one time i wanted to set up zsh on this device, but i think i messed up the .bashrc or something every time i give a command this error pups up :I if it cant be fixed its ok, its just annoying
Try to start bash with this commsnd bash --noprofile --norc Or env -i bash --norc --noprofile If it works fine, it's your bashrc.
I'm on githbash, how do i start bash with a command ? and btw, where is the bashrc located on windows ? it ist in the \~/
Sorry, but I disagree. I put (CIDR Prefix) in the title of the post, and the slash 24 is obviously associated with that. But thank you for stopping by. :) I hope you have a great day!
I have no idea what is going on here but a simple for loop would do the job. for i in $your_variable_here do wget "http://whereever.com/$i/whatever.extension" done
If it didn't make sense, why did you edit it?
Perhaps using square brackets in the regex. Something like `[45].*` would get you anything from 40 to 59. Might not be possible to get the range that you want though. Maybe I'll try to tackle it later
Hi again. I edited my post because a) it was asked nicely of me to do so, and b) I wanted to help out someone who took the time to post a response to me. I can have an opinion different than others and still edit a post to help out the community you know. Since I am a kind person who doesn't hold silly internet grudges or go down rabbit holes of bickering, it was an easy choice to edit the post. I hope this answers your question satisfactorily. I'm onto you ;)
Many thanks!
Hi, The &lt;variable number&gt; is a random number that varies per release, so I have to find it out first, for which I used the 'invoke-webrequest/where-object'
If you are using aligned blocks (which you fail to mention), you can use [Parameter expansion](https://www.gnu.org/software/bash/manual/html_node/Shell-Parameter-Expansion.html) to get the IP... An example to get you started... bitmask=${ip#*/} will give you your bitmask.....then you can use `sed` to trim off the correct number of octets by using the bitmask echo $(( $bitmask / 8 )) If you are not, then conversion to binary, and then removing the unwanted number of bits is probably the best way... Have a nice day!....
Thanks for this handy tip! I think I'll try this out. (non-aligned blocks) And thanks for letting me know what I failed to mention. :) I trust I can always count on you!
There is nothing like a well defined question that clearly defines exactly what is desired......
Agreed! See, I knew I liked you :)
Actually, much better would be `[45][0-9]+` because you have to have a number and you need at least one. I realized this after posting before. Note that to use "+" you need to use the extended regular expression switch `-r` (in gnu send) or you need to escape the plus with a backslash. I think I should be able to get an even more specific regular expression using the "or" operator (pipe) once I get a chance to think about it.
Maybe one day you won't edit a post, totally changing the context after I have replied to it...
lol /24 was literally in the original post, what's your deal today? No edit needed. And I didn't edit any post because of your reply. Le sigh. I think I'm just gonna let you have the last word. I can tell you really want it. :) Use it wisely! Peace.
I follow what you are saying, thanks so much for taking some time with this.
Funny you should say that, as I've only taken a few seconds. Hahaha. No problem, though. Always looking for excuses to come up with regex.
Adding to this idea of yours of using curl and then grep, you could just continue adding more stuff to that command line until you get your result. Experimenting around, I came up with this here: $ curl -s 'https://www.curseforge.com/wow/addons/deadly-boss-mods/download' | grep -oE 'href="[^"]+"' | sed 's/^href="//; s/"$//' | grep '/file$' /wow/addons/deadly-boss-mods/download/2730877/file Now maybe add another `head -n1` to the end to make sure it's always just one line of output and then save it in your $href variable: href=$(curl -s 'https://www.curseforge.com/wow/addons/deadly-boss-mods/download' | grep -oE 'href="[^"]+"' | sed 's/^href="//; s/"$//' | grep '/file$' | head -n1) if [[ -z $href ]]; then echo "error! couldn't get download url!" exit 1 fi # wget, unzip etc. here You can add line-breaks to make it easier to read: href=$( curl -s 'https://www.curseforge.com/wow/addons/deadly-boss-mods/download' | grep -oE 'href="[^"]+"' | sed 's/^href="//; s/"$//' | grep '/file$' | head -n1 ) This kind of curl+grep solution is hacky compared to what you did in Powershell, but I'm thinking for this particular problem here it will work pretty well. About how to solve this in a more "correct" way on Linux, people probably use Python (or similar) where you have access to libraries that provide HTML parsing and whatnot. Check out for example the first answer to this stackoverflow question here: https://stackoverflow.com/questions/3075550/how-can-i-get-href-links-from-html-using-python That Python solution there looks really nice because it is easy to read and is short. The downside with this is that you have to make sure the libraries you use in the script are installed. Here's btw. a solution using a Perl one-liner that is similarly hacky as using curl+grep, meaning it works on the text and doesn't really understand html: perl -E '$_ = qx{curl -s 'https://www.curseforge.com/wow/addons/deadly-boss-mods/download'}; say for grep { m{/download/} and m{/file$} } m{href="([^"]+)"}sg'
:) I have an unhealthy obsession with regex too! We gotta stick together! Haha.
Okay, this is what I've got for you. Looks like I was kind of misreading the question earlier. You're actually just worried about the last part of the ip right? Can't test it, but I think everything I'm using is available in extended regex. `sed -r '(207\.46\.204\.|157\.55\.39\.)(2[0-4][^0-4]|1?[0-9][^0-9]/d'` Explanations: the first group is just your two ip address groups (there's probably a technical term for that). This is acting as an anchor so that you'll only find up addresses that start with one of those two combinations of characters the dots must be escaped, because in regex dot stands in for one of any character. The second finds something that's either 2 followed by 0-4 or 0-9 or 10-19. In all cases I'm anchoring the other side with any character that isn't a number because I think those numbers can usually be 0-255. Otherwise it would capture stuff like 243 or 31 or something. If you were using awk you'd be able to split the line into fields and use the more traditional anchor characters of ^ and $, but it might make other things more difficult depending. Try it and let me know if it worked
Shouldn't you be able to call wget from pwsh? No idea how to assign a variable in pwsh, but presumably you could assign a variable with the URL from the pwsh command some how, then call wget on that variable.
I have a [script](https://github.com/42Kmi/LagDrop/blob/master/random_scripts/cidr_list.sh) that could help. It's probably not the most elegant solution, but basically you enter your CIDR formatted range and it gives you each individual IP address in the range. You could then store the output to a variable then use sed.
Can you share the script?
Don't use \`backticks\`, use $(command substitution)
just want to say you are beautiful
bad bot
Thank you, topicalscream, for voting on nkid299. This bot wants to find the best and worst bots on Reddit. [You can view results here](https://botrank.pastimes.eu/). *** ^(Even if I don't reply to your comment, I'm still listening for votes. Check the webpage to see if your vote registered!)
Good bot
Doesn't always have to be elegant - sweet script!! Thanks!
Thanks! You could do something like: &gt; REMOVE_IP=$(echo $(./cidr_list.sh)|sed -E "s/(\s)/|/g") Then for removing from your log &gt; sed -E "/\b($REMOVE_IP)\b/d"
Do you want the expansions done once when you create the alias, and never again? Or do you want the expansions does every time you call the alias?
Yeah it's completely fine, but I did not really want to make it ugly by combining pwsh and bash. Also file paths with spaces is a bitch in general, but even more on powershell core on linux... Just cba (\~/Games/drive\_c/Program\\ files\\ (x86\\)/World\\ of\\ Warcraft/\_retail/Interface/addons)
Wow, thank you! Ended up with grepping the curl result. It feels kind of dirty to handle the html as a string, but got to pick up the Python book to fix that later on... &amp;#x200B; The perl solution seems interesting, but doubt it would have any edge over the curl/grep?
good bot
The Perl thing doesn't really have an edge, I just like writing Perl one-liners.
I wouldn't say that wget is bash. It's a separate program that's just also part of GNU coreutils. As for spaces in file names, I'll take your word for that. Powershell is pretty painful to use IMO, so I don't know too much about it. Python is probably a better choice :)
Just a small tip - you can do `awk '/broadcast/ {print $2}'` and skip the grep.
Use `grep -Fx` to check if that line is already there (look up what the `-F` and `-x` options mean in the manual page) and use the shell's `||` operator to only add it if it's not. line="tmpfs /run/shm tmpfs defaults,noexec,nosuid 0 0" grep -Fx "$line" /etc/fstab || echo "$line" &gt;&gt; /etc/fstab
Thanks!
Make life easier by tagging it with a comment. E.g. write `tmpfs /run/shm tmpfs defaults,noexec,nosuid 0 0 # MYSHM` Now you can trivially verify, remove or replace the line by looking for the "MYSHM" keyword, even if it changes a bit between versions of your script, or if the user modifies it slightly.
OK, perfectly understood.
 ~ $ cat script.sh #!/bin/bash if [[ $* == *\.awk ]]; then echo 'the file ends in awk' else echo 'it doesnt' fi $ ./script.sh file.awk the file ends in awk $ ./script.sh file.not it doesnt
I typed exactly what you wrote. Still doesn't work.
Perfectly understood. Thanks for this explanation.
Sounds like you are doing some homework... and I amd ***not*** knocking that in any way - but instead of providing an answer, - or a fish, shall instead provide you with a link to enable you to learn all about fishing.... You will be looking to use `${FILE.....` in one of [these](https://www.gnu.org/software/bash/manual/html_node/Shell-Parameter-Expansion.html) arguments..... If you test against the filename stripped of the desired extension, you can determine if the extension was there in the first place.....
Check out basename and it's variants at [https://www.cyberciti.biz/faq/bash-get-basename-of-filename-or-directory-name/](https://www.cyberciti.biz/faq/bash-get-basename-of-filename-or-directory-name/)
Then you didn't do exactly what I did. Post the code that doesn't work.
If you are using a modern system, do an aggressive find/replace on backticks (`): `some_random_code` $(some_random_code) Sometimes backticks visually appear to be apostrophes or quotes, and lead to all kinds of problems as you've described. Shell expansion issues then result.
How in the world did you know that that was a bot?
I just tested it. It works fine. root@ubuntu:~# cat script.sh #!/bin/bash if [[ $* == *\.awk ]]; then echo 'the file ends in awk' else echo 'it doesnt' fi root@ubuntu:~# ./script.sh file.awk the file ends in awk root@ubuntu:~# ./script.sh file.txt it doesnt Make sure you do root@ubuntu:~# chmod +x script.sh
My other two IF else statement works. It's just this one doesn't
&gt; POST THE CODE THAT DOESN'T WORK
How can I upload a screen shot?
Copy and paste it. Nobody wants to retype your stuff from a screenshot. Highlight it after you paste in the comment box and press the "code" button.
read -p "Enter a file that you want to test:" FILE &amp;#x200B; &amp;#x200B; if \[\[ -z $FILE \]\];then echo "You need to enter a file" exit fi &amp;#x200B; if \[\[ -f $FILE \]\];then echo "File exists" else echo "File doesn't exists. Please enter another file" exit fi &amp;#x200B; if \[\[ -x $FILE \]\];then echo "File is executable" else echo "File is not executable" exit fi &amp;#x200B; if \[\[ $FILE == \*\\.awk \]\]; then echo "File is awk extended" else echo "File is not awk extended" exit fi
I got it work now. I need to chmod a=rwx the test file. Thanks a lot
 root@ubuntu:~# cat script.sh #!/bin/bash read -p "Enter a file that you want to test:" FILE if [[ -z $FILE ]];then echo "You need to enter a file" exit fi if [[ -f $FILE ]];then echo "File exists" else echo "File doesn't exists. Please enter another file" exit fi if [[ -x $FILE ]];then echo "File is executable" else echo "File is not executable" exit fi if [[ $FILE == *\.awk ]]; then echo "File is awk extended" else echo "File is not awk extended" exit fi root@ubuntu:~# ./script.sh Enter a file that you want to test:file.awk File doesn't exists. Please enter another file root@ubuntu:~# touch file.awk root@ubuntu:~# ./script.sh Enter a file that you want to test:file.awk File exists File is not executable root@ubuntu:~# chmod +x file.awk root@ubuntu:~# ./script.sh Enter a file that you want to test:file.awk File exists File is executable File is awk extended root@ubuntu:~# touch file.txt &amp;&amp; chmod +x file.txt root@ubuntu:~# ./script.sh Enter a file that you want to test:file.txt File exists File is executable File is not awk extended
Yes you were right. It works now. Thank you
&gt; I need to chmod a=rwx the test file #***NEVER*** `chmod a=rwx` you have just opened up a free pass to execute anything on your system....
 $ cat script.sh #!/bin/bash read -p "Enter a file that you want to test:" FILE if [[ $FILE == *\.awk ]]; then echo 'the file ends in awk' else echo 'it doesnt' fi $ ./script.sh Enter a file that you want to test:file.awk the file ends in awk $ ./script.sh Enter a file that you want to test:file.not it doesnt Post ALL of the code that doesn't work. You are doing something else that is wrong.
It works now. I just need to chmod permissions on test file.
Next time, post the actual error message you are getting and you could save yourself a lot of time. You need to be way more descriptive than "it doesn't work". _How_ doesn't it work? _What_ is it doing that is different from what you expect?
Ansible to the rescue! `ansible -m mount --args='opts="defaults,noexec,nosuid" state=mounted path=/run/shm src=tmpfs fstype=tmpfs' localhost` Only makes changes when changes are to be had. [root@testing apnscp]# ansible -m mount --args='opts="defaults,noexec,nosuid" state=mounted path=/run/shm src=tmpfs fstype=tmpfs' localhost localhost | CHANGED =&gt; { "changed": true, "dump": "0", "fstab": "/etc/fstab", "fstype": "tmpfs", "name": "/run/shm", "opts": "defaults,noexec,nosuid", "passno": "0", "src": "tmpfs" } [root@testing apnscp]# ansible -m mount --args='opts="defaults,noexec,nosuid" state=mounted path=/run/shm src=tmpfs fstype=tmpfs' localhost localhost | SUCCESS =&gt; { "changed": false, "dump": "0", "fstab": "/etc/fstab", "fstype": "tmpfs", "name": "/run/shm", "opts": "defaults,noexec,nosuid", "passno": "0", "src": "tmpfs" }
Very neat! I will definitely try this out. Thanks!
I have not yet worked with Ansible, and am just now starting to learn Puppet.
Roughly all the same. I'd explore Ansible, Puppet, and Chef to see which meshes best with you. They all obviate the need for messy shell scripts.
Have a look here for how to do simple string manipulation in bash: http://tldp.org/LDP/abs/html/string-manipulation.html Using that as a reference, have a look at a couple examples of splitting s string: ``` # split on the slash value=start/end echo start ${value%/*} echo end ${value#*/} # split on the colon value=start:end echo start ${value%:*} echo end ${value#*:} ``` Now, imagine splitting `$FILE` on the final period and you will easily see how to parse off a file extension.
I just started taking small projects from my companies DevOps Engineer as I am shadowing him, and we use only use Puppet in our environment so I thought it would be the best to learn first, though I've heard Ansible is the most user friendly. This script question is actually a peice from my first project.
Food for thought, Ansible would be: --- - hosts: localhost become: yes connection: local tasks: - name: Fix my shit mount: opts: "defaults,noexec,nosuid" state: mounted path: /run/shm src: tmpfs fstype: tmpfs - name: Something else debug: msg="Hello!" Save in ansi.yml, then `ansible-playbook ansi.yml`
Jeeze, guys. Do you not remember what it was like being that kid typing in BASIC code from a magazine? Don't downvote the dude just because he's inexperienced.
Conflicted here.... It helps people greatly to provide concise, accurate answers if you post *exactly* what you see and do - as you did here.... if you mistype a `'` for a `\` ` it is spotted, whereas if you just wrote what you *thought* you typed, your typo would never have been spotted....... However.... ***don't*** *run simple schizz as* ** root** ..... as a noob it is all to easy to miss a `.` before a `/` in a command and do something nasty to your root directory... the creation and default usage of your user account as opposed to `root` is ***there to protect you from yourself*** - so you ***cannot*** goof easily...... take advantage of this digital condom and use it to save yourself from all sorts of mistakes that you might prefer not having to explain to HR, while a defensive member of corporate IT is waiting silently during the meeting, waiting for the best moment to stick their oar in re: the 2 years worth of failed backups which were never reported by your predecessor or you, and which *obviously* would have saved the day, had they been running correctly.....
Pretty much this. When that doublequote started after `=` and right before `echo` bash has ended the initial doublequote and started interpreting `echo` as a separate command. It becomes really annoying when you have to mix quotes like this. And thanks, I'll be using this method next time I need to mix quotes.
&gt; I need to chmod a=rwx the test file. You definitely do not need to do that!
Inexperience is one thing, but using the sentence "it doesn't work" when people are trying to help you solve a problem is obnoxious whether you're scripting, trying to start a car, learning long division, giving an animal medicine... This isn't about experience with coding, this is about fundamentally having no idea how humans use words to figure out a problem together.
Toxic environment post. Sorry op usually better.
I'd like to create a shell script (or use an existing one) to see if my DNS changes have propagated to the major providers (Level3, Comcast, Verizon, et al)
This isn't a bash question.
Agreed inexperience is why they are asking for help,but u/Murkycola has a point following instructions to get the information to help is very much a valuable thing.
as a follow up for anyone reading that doesn't really knowing indepth permission in linux the best way to add rx is the following: &amp;#x200B; $: chmod 755 Name\_of\_File &amp;#x200B; I understand that this is very noob thing but rather add the reminder here anyway (someone will ask)
Ansible dude...
Don't learn puppet unless you have to for your current position. It's dying, fast. Check out debians popcon charts. I don't have it handy but basically salt/chef/puppet are on a MASSIVE decline. Who the hell installs management agents in 2019?!
It is for my current position, as I am shadowing our current admin who came in while it was already implemented, though I'm sure after I get more experience and have more weight behind an idea, he might not be too opposed to migrating.
I understand completly. Maybe just ask him if he's tried Ansible? Just word it in a friendly way, it never hurts to ask and start the conversation. Idk where you work but I can understand if they've implemented puppet extensively it's not easy or quick to migrate. However, there are a lot of old heads in this industry stuck in old ways. They won't try anything new.
What about doing it with puppet since you are learning it right now anyway https://forge.puppet.com/puppetlabs/stdlib#defined-types (file_line)
Can it happen that /run/shm is used by something else? Maybe grep -w just that word.
This is my Fibonacci attempt: 1 history -p $[{1..31},i+=_,_=i-_] (Defaults to first 31 iterations) :)
Don’t ever let anyone dull your sparkle :)
Yeah but the way to fix that isn't with downvotes, that won't do anything. And I'm not saying nobody's trying to help, just that for example your comment here is orders of magnitude more useful to making OP a good programmer and better at asking questions, know what I mean?
Sure you can add a timestamp to the destination name using \`date\` command output. Maybe you should delegate this backup task to a specific tool like \[borg\]([https://borgbackup.readthedocs.io/en/stable/](https://borgbackup.readthedocs.io/en/stable/)) ? ps: I have written a tool you might be interested in for your backups rotation : [https://github.com/Kraymer/cronicle](https://github.com/Kraymer/cronicle)
change your destination from `home/taxroot/backups` to `/home/taxroot/backups/$(date --iso-8601)` Not asked, but a freebie: If these backups are important, get them off that machine. Change the find command to operate only in the backups dir.
 mydate="$(date +%Y%m%d%H%M%S)" echo $mydate 20190702122858 So it would look like this: mydate="$(date +%Y%m%d%H%M%S)" sudo scp -r /opt/poolparty/data /home/taxroot/backups-${mydate} sudo scp -r /opt/poolparty/config /home/taxroot/backups-${mydate} You can change the format of the date. All of the sequences are listed in `man date`.
You can do this any way you want but you'll need to be precise, so pick a plan and define it. This is how I delete two weeks old backups ... [cleanup-bkps.sh](https://github.com/michaeltd/dots/blob/master/dot.files/sbin/cleanup-bkps.sh)
You can continue or you can use borgbackup and the borgmatic script to take care of all that hassle for you.
This kinda works: `$ locate biglongstring &gt; output.txt` `$ for i in "$(cat output.txt)"; do ls -l "$i"; done` Surely there is a better way??
Using -0 with xargs and locate, if they both support it, can be used for the simple cases: locate -0 biglongstring | xargs -0 ls -ld Otherwise, to iterate nul delimited data with a loop in bash: locate -0 biglongstring | while IFS= read -rd '' file; do printf 'Doing something with %s\n' "$file" done or if you don't want the loop run in a subshell: while IFS= read -rd '' file; do printf 'Doing something with %s\n' "$file" done &lt; &lt;(locate -0 biglongstring)
Run locate command and write output to a temporary file now read from temporary file in a while loop #! /bin/bash input_string="$1" temp_file="/tmp/my_temp_file" echo -n &gt;"$temp_file" whatever(){ while read line do echo "$line" done }&lt;"$temp_file" locate_operation(){ locate "$input_string" }&gt;"$temp_file" locate_operation whatever
This works: MYSEARCH=$(locate "text.txt") while read File do echo "&gt;$File&lt;" # Process file here. done &lt;&lt;&lt;"$MYSEARCH" but if the list of found files is too long you should save 'locate's output to a file.
 jq [ ... args ...] ' .[$COMMIT_NAME] |= ( .commit = $COMMIT | .date = $DATE | .crap = $CRAP_SCORE | .coverage = $COVERAGE | .complexity = $COMPLEXITY)' \ &lt;myfile.json &gt;myotherfile.json
You need to run it in a `bash` shell ... find . -type d -exec bash -c 'declared_bash_function {}' \; which I think will pull in your function from `~.bashrc`... If not, you will need to have `exported` the function... `export -f declared_bash_function` before running the `find` command It is safer to use the `-execdir` option, but that changes to the directory containing the item, and passes a relative link (`./foldername`) as opposed to the entire path from the starting location of the search, so you might need to modify your function
Use the date command to get the day of the month and use that in/as your filename. Bingo, instant built-in autorotation with no need to use find -delete (eg, backup1.gz gets created on the first of August, and then overwritten by a new backup1.gz on the first of September)
It's an inherent limitation of any utility that is external to the shell, such as `find`. It's a separate program, so it cannot access the calling shell environment, such as your functions. Bash exported functions (`export -f`) are a workaround, but they have problems: * Space in the environment is limited, so you can only export small functions. This depends on your OS, though. * A function may depend on other aspects of the shell environment (e.g. other functions or variables) which you'd have to export as well. * Variables it sets or changes will not survive the run as it will be executed in a new shell, not your current shell. So, for instance, if your function wanted to keep count of the number of files processed, you'd be out of luck. * Exporting code into the environment is fraught with security problems. There's a reason why no other shell does this. `export -f` was the source of the infamous Shellshock bug. * Finally, the syntax of combining `bash -c` with `find` is fiendishly difficult, as evidenced by the fact the other comment got it wrong. So there's not really a good solution in standard shell or even bash; this is one of the common shell annoyances/limitations. My new [modernish](https://github.com/modernish/modernish) shell library offers a different approach: it can properly integrate the `find` utility into the shell as part of a new extensible [loop construct](https://github.com/modernish/modernish#user-content-use-varloop) akin to `for`, so you can just do everything in your current shell environment, with all your functions and variables. Note it uses uppercase `LOOP`...`DO`...`DONE`. For example: . modernish use var/loop LOOP find file in mydirectory -type f; DO declared_function "$file" DONE It's still under development, but already quite usable and this loop construct has been quite extensively used and tested. Plug: I've got an /r/modernish subreddit which may become more active if/when I get more users. :)
&gt; find . -type d -exec bash -c 'declared_bash_function {}' \; Incorrect syntax – you're quoting the `{}`, rendering it ineffective; also, the first argument *after* the `-c` script is the program name `$0`, which is usually useless but does require you to insert a dummy argument there. So you want: find . -type d -exec bash -c 'your_command' dummy {} \; …or, if your_command can process multiple arguments at once: find . -type d -exec bash -c 'your_command' dummy {} + &gt; which I think will pull in your function from `~.bashrc`... Nope. The `-c` argument causes the shell to execute a script, and when executing a script all the *rc files are skipped. &gt; If not, you will need to have `exported` the function... That might work, depending on the function. See my other comment for the pitfalls.
`find . -type d -exec $(declared_bash_function) {}\;` The function can be called within interpolation (from memory, not tested).
Awesome. Thanks!
&gt; Incorrect syntax printarg () { echo $1; } export -f printarg find . -type d -exec bash -c 'printarg basename {}' \; mkdir testdir cd testdir mkdir incorrect-syntax mkdir incorrect-syntax/whoops find . -type d -exec bash -c 'printarg {}' \; . ./incorrect-syntax ./incorrect-syntax/whoops
\`declared\_bash\_function $(find . -type d)\` Something like this may work.
Apparently it won't work - I used the wrong syntax.... YMMV
&gt; exported It worked after I added an export statement in my ~/.bashrc. Thanks for the hints!
Well, I stand corrected on the syntax: "If the string ``{}'' appears anywhere in the utility name or the arguments it is replaced by the pathname of the current file." However, that makes your form unsafe because it can't deal with spaces or other odd characters in file names, and causes a code injection vulnerability as you can insert code in file names. $ printarg () { echo $1; } $ export -f printarg $ mkdir -p 'testdir/spaces in this filename' $ mkdir -p 'testdir/codevuln; for ((i=1; i&lt;=5; i++)); do echo HA HA $i; done' $ find testdir -type d -exec bash -c 'printarg {}' \; testdir testdir/codevuln HA HA 1 HA HA 2 HA HA 3 HA HA 4 HA HA 5 testdir/spaces $ find testdir -type d -exec bash -c 'printarg "$1"' dummy {} \; testdir testdir/codevuln; for ((i=1; i&lt;=5; i++)); do echo HA HA $i; done testdir/spaces in this filename As you can see, your form executes the code after ';' contained in any file name found, which is a classic code injection vulnerability. So that form is totally insecure and should never be used.
And there I go not quoting not-variables... find . -type d -exec bash -c "printarg '{}'" \; ./testdir ./codevuln; for ((i=1; i&lt;=5; i++)); do echo HA HA $i; done
Sorry, but my point stands – {} is not a variable and this is still vulnerable. Exploitation is only slightly less simple – you just need to close the `'` quote in the file name. $ printarg () { echo "$1"; } $ export -f printarg $ mkdir -p 'testdir/codevuln '\'' ; for ((i=1; i&lt;=5; i++)); do echo HA HA $i; done #' $ find testdir -type d -exec bash -c "printarg '{}'" \; testdir testdir/codevuln HA HA 1 HA HA 2 HA HA 3 HA HA 4 HA HA 5
fair point... I only go the -execdir bash -c `.... ` _ {} \; route with the $0 placeholder if I can't easily dump what I want into the `....` I might have a few scripts to update...
`Alt+#`, or whatever you've bound to Readline's `insert-comment` action.
Specifically, which part are you stuck on?
All of it honestly. But to start, &gt; Check if there is a directory called backup (your destination directory) under the current working directory. I know you would use: File= $1 if \[ -d $File \] to check if the file is a directory, but how to i check for specific words? Like, how to i check for a directory called backup?
You can also do something like: locate test.txt | while read file; do stuff: done
I just always hit CTRL-A to go the the beginning of the line, type # and hit enter. (CTRL-E is the end of the line, BTW. Now you know a little Emacs-fu too).
Things to look up: * The test function * Case statements * if/then statements Those will cover most of what you need. I'd be happy to help you with specifics if you were stuck on one thing, but you're basically asking for the entire thing to be written for you. &amp;#x200B; To answer your specific question (to test for a directory called 'backup') &amp;#x200B; BACKUP="/home/backup" if \[ -d "$BACKUP" \]; then (do stuff) else (do other stuff) fi &amp;#x200B; You're on the right path.
I only use bash in vi mode. There pressing Esc - # at any given time enters the current commandline as a comment.
I wanted to show how to process a variable containing lines. It can be done without a variable: while read File do echo "&gt;$File&lt;" # Process file here. done &lt; &lt;(locate "text.txt")
Great answer. Work with this one my dude, and PM me if you get stuck. I'll give pointers but not answers
Check out Emacs yasnippets. There are snippets for every language, you can even write and extend them yourself.
Ah, good point. I had said `Alt`+`#`, but that's the same as `Esc`, `#` as two separate keystrokes. Both of these work in either Emacs or Vi mode.
You could just use: { ... ; } instead of: ( ... ) Packing a compound command into the test of a `while` is pretty convoluted though. How about this? while :; do read -p "How many x do u want to create?" xnum [[ $xnum == *([0-9]) ]] &amp;&amp; break echo "not a valid number" done This approach seems clearer to me. (You probably want `+([0-9])` there, by the way, otherwise the user could enter nothing. But I used `*([0-9])` to match the logic you had.)
works ty, what are those commands " :; &amp;&amp; break " called? i need to learn how to use them lol
&gt; : This is pretty much exactly the same as `true`. In really, really ancient shells the `:` was actually a comment character, so people wrote: : some comment here but in more modern shells it acts more like the `true` builtin. I should probably have used `true` here, not `:`, since the "exits successfully" bit is actually what's important for the `while` loop to work. &gt; `&amp;&amp;` This separates commands, much as semicolons and newlines do, however it only executes the command on the right-hand side if the command on the left-hand side exited successfully. So: [[ $xnum == *([0-9]) ]] &amp;&amp; break could be written more verbosely as: if [[ $xnum == *([0-9]) ]]; then break fi
thanks for the response, yeah &amp;&amp; will be of use for sure, i'm already replacing some of my code with it haha
Press the home key and then hash?
Since it says: &gt;"under the current working directory" it should be "BACKUP = ./backup" I think
 while read -rp "How many x do you want to create? " xnum &amp;&amp; [[ $xnum != +([0-9]) ]]; do echo "Not a valid number." done Also see [http://mywiki.wooledge.org/BashFAQ/054](http://mywiki.wooledge.org/BashFAQ/054).
It's not convoluted, and you **don't** need to group commands inside `{ ...; }` or `( ... )`. The basic syntax for while loops (also applies to if blocks) is `while &lt;list&gt;; do &lt;list&gt;; done`, so you can put any list of commands in there.
&gt; The basic syntax for while loops (also applies to if blocks) is while &lt;list&gt;; do &lt;list&gt;; done, so you can put any list of commands in there. Oh yeah, I completely forgot about that. I still probably wouldn't do it that way though.
And on the 8th day, God said let there be ansible, chef, and puppet, and it was good.
In that case, it should probably be something like, BACKUP="`pwd`/backup/"
Very nice! Compact and elegant. Thank you!
It looks like your submission contains a shell script. To properly format it as code, place four space characters before every line of the script, and a blank line between the script and the rest of the text, like this: This is normal text. #!/bin/bash echo "This is code!" &gt; This is normal text. &gt; &gt; #!/bin/bash &gt; echo "This is code!" *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/bash) if you have any questions or concerns.*
Unless you are using screen or similar in which case you can either: Ctrl-U, # , Ctrl-Y and enter or Ctrl-X-X, # and enter
[You can do the same without a variable](https://www.reddit.com/r/bash/comments/c8eenl/processing_locate_output/esnguoq?utm_source=share&amp;utm_medium=web2x)
&gt;However, that makes your form unsafe because it can't deal with spaces or other odd characters in file names Find automatically handles this. Quoting is not needed. :~/tmp123$ touch 'test file' :~/tmp123$ find . -name test\* ./test file :~/tmp123$ find . -name test\* -exec mv {} ../ \; :~/tmp123$ ls ../test\ file ../test file
`echo "$SHLVL"` It will show you a depth indicator.
you can check easily if a shell is a nested shell by checking its parent with `ps`, for example: get_ppid_f(){ local ps="$(ps -eo 'pid,ppid,uname,args')" head -1 &lt;&lt;&lt; "$ps" awk '$1=='$$' {print}' &lt;&lt;&lt; "$ps" } `$$` is the pid of the current process/shell. So you can add an `if/else` structure before defining PS1, changing it to whatever you want if is nested or if is not, like: ppid="$(ps -eo 'pid,ppid'|awk '$1=='$$' {print $2}')" if [[ "$(ps -eo 'pid,args'| awk '$1=='$ppid' {print $2}')" =~ bash ]]; then PS1="NESTED" else PS1="NORMAL" fi
Interesting description of that var: ``` SHLVL Incremented by one each time an instance of bash is started. ``` But yes. it's an accurate description: ```shell #!/usr/bin/env bash echo $SHLVL if [[ $SHLVL -lt 4 ]] then $0 else echo going no deeper fi ```
&gt;&gt; However, that makes your form unsafe because it can't deal with spaces or other odd characters in file names &gt; &gt; Find automatically handles this. Quoting is not needed. Yes, I'm well aware. But you weren't paying attention. Note the difference between find . -name test\* -exec mv {} ../ \; and something like: find . -name test\* -exec sh -c 'mv {} ../' \; The latter is what's unsafe (code injection vulnerability). Filenames are inserted into the `-c` script as code, rather than passed as arguments.
FYI || is the opposite of &amp;&amp;
Yup, it works. Thanks!
I didn’t get around to doing if statements In bash yet, but I’ll take a look thank you!
shopt is built in bash command. Builtins don't have man pages, but you can get help with "help shopt". "man bash" also has some shopt info.
Shopt is a built in bash command. https://www.gnu.org/software/bash/manual/html_node/The-Shopt-Builtin.html You would have to look at the manual page for bash. ``` man bash
Yes; because your use of exec sh is incorrect. You should be using: find . -name test\* -exec sh -c 'mv "${1}" ../' -- {} \; You should not be unquoting {} to use in the middle of the sh statement.
Thank you. That's exactly what I was pointing out to the other guy.
And here I am using the Home key like some noob
Thanks, I’ll have to look around for why my “shopt -s autocd” isn’t working
I’ll try that out, thank you
That what "." means... And ".." means the directory your current directory is in.
`info &lt;command&gt;` will also show you stuff about both built-in commands like shopt and standard programs like ls.
A related idea: when doing text-based screencasts with `asciinema`, I often like to type some explanation at the shell prompt for the benefit of the viewer \[often just my future self\]. I end those lines by pressing ^(C) (control-C) because `bash` doesn't want to hear my English prose. Use `stty -echoctl` so that you get: $ This is how to use the 'ls' command. $ ls instead of $ This is how to use the 'ls' command.^C $ ls
A related idea: When I was first learning `bash`, I was frustrated by not understanding how pipelines create subshells (which evaporate at the end of the pipeline). For example: $ mkdir /tmp/example $ cd /tmp/example $ touch file{1..10} $ ls file1 file10 file2 file3 file4 file5 file6 file7 file8 file9 $ declare -a fileList=() $ find . -type f | while read -r name; do fileList+=( "$name" ); done $ printf "%d\n" "${#fileList[@]}" 0 # I expected to see 10 $ while read -r name; do fileList+=( "$name" ); done &lt; &lt;(find . -type f) $ printf "%d\n" "${#fileList[@]}" 10 # This is what I wanted! Why? The pipe `|` after the first `find` starts a subshell process with a copy of the shell's environment, including an array variable named `fileList`. It duly adds each `name` to that array…until the loop ends and that subshell goes away and control returns to the parent instance of `bash` with its empty array variable named `fileList`. The second `while` loop is not part of a pipeline so creates no subshell. It reads the filenames and appends each to the array variable in the *same* instance of `bash`. It accomplishes the same thihg by supplying the lines of input via redirection after the keyword `done`. The notation `&lt;( … )` is *process substitution*. It runs the command enclosed in the parentheses, but provides them to the `while` loop without using a pipeline.