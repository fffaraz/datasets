I think what they mean by “executable” is being an ELF executable file. That is, if the file isn’t an ELF executable file (or possibly some other binary executable format – I’m not sure if Linux understands any more), it’s assumed to be a shell script. But I’m pretty sure that’s bogus. Running an executable of any kind is done by the kernel, not the shell (how would the shell correctly process a setuid bit, for example?¹). Bash just says “run this” (`execve`) and it’s done. $ strace bash -c 'cat /dev/null' 2&gt;&amp;1 | grep exec execve("/usr/bin/bash", ["bash", "-c", "cat /dev/null"], [/* 67 vars */]) = 0 execve("/usr/bin/cat", ["cat", "/dev/null"], [/* 67 vars */]) = 0 It is true, however, that the kernel will run any non-binary executable file as a shell script, ~~even if it’s missing the hashbang.~~¹ $ echo 'echo a' &gt; /tmp/script $ chmod +x /tmp/script $ /tmp/script a EDIT: ¹ Actually, it seems the setuid bit is ignored on shell scripts. And just as /u/geirha says, if there’s no shebang, the running is still done by the shell: execve("./script", ["./script"], [/* 67 vars */]) = -1 ENOEXEC (Exec format error) open("./script", O_RDONLY) = 3 read(3, "echo $USER\n", 80) = 11 close(3) = 0 … TIL! And looking for ways to turn this off in the Bash manpage, I actually found the source for your website – it’s mostly copied from the COMMAND EXECUTION section.
In the earlier days of unix, the kernel could only run binary executables. The kernel would read the first two bytes of the file, and if they were the right value (called magic number), it would run it, otherwise return an ENOEXEC error, indicating that it's not a binary executable. The shell at the time, decided that if the kernel returned ENOEXEC, it was probably a shell script, so it ran the file with `sh file`. Obviously, this failed if the executable wasn't actually a shell script, so after a while the shebang was invented. When the kernel returned ENOEXEC, the shell would check if the first two bytes was `#!`, and then use the rest of the line as the interpreter to run the script with. Eventually, the kernel took over the interpretation of the shebang line. However, if the executable is not a binary executable, and there is no valid shebang, the modern shells of today still retain this ancient and dangerous feature of assuming that the file is a shell script, and runs it anyway. On a side note, I recommend you read the BashGuide listed in the sidebar here instead. The Bash "guides" at tldp.org are notoriously bad.
Does simplifying your PS1 make the problem go away? 
I found this in wget's man-page: --retr-symlinks By default, when retrieving FTP directories recursively and a symbolic link is encountered, the symbolic link is traversed and the pointed-to files are retrieved. Currently, Wget does not traverse symbolic links to directories to download them recursively, though this feature may be added in the future. The way I understand that is that wget just can't do it.
Here is a little part of what happen when I press enter with this PS1: 3861 5088 6315 7542 8769 9996 11223 12450 EDIT : The difference is now: 1227.
Do you have a `$PROMPT_COMMAND` set?
I looked at it : history -a; history -c; history -r; history -a; history -c; history -r; history -a; history -c; history -r; It is probably the reason. I'll try modifying it. EDIT: Fixing it help a little (the increasing rate is now 'just' 416), but there is still something else apparently EDIT-2: A temporary fix wasn't enough but a real fix (in `bashrc`) solved the problem, thanks a lot /u/galaktos ! EDIT-3: Or not ... It was apparently fixed, now I have the same problem again. I really don't know what is happening here x).
You are appending the lines from history to the $HISTFILE, then you clear the history list, then you read back the history from $HISTFILE, then you append those back ... you just doubled the amount of history lines.
You’re welcome! I’ll mark this as “solved” then :) In case someone else has a similar problem – would you mind explaining what the real problem was?
I can reproduce it with 4.3.42(1)-release, and also with `history -a; history -n` (though at a much smaller rate). Trying with bash-4.4.0(1)-rc1, I can still reproduce this behavior with `history -a; history -c; history -r`, but `history -a; history -n` works as expected. The behavior makes somewhat sense when using `-a`,`-c`,`-r`, so not sure if it's a bug or not. --- Here's my test case with `-a`,`-n`. If `HISTFILE` is set to `~/.bash_history`, take a backup of your .bash_history before running this, else it will be truncated to 500 lines $ HISTCONTROL=ignoreboth:erasedups PS1='\s-\v \! \$ ' PROMPT_COMMAND='history -a; history -n' /opt/local/bin/bash --norc bash-4.3 501 $ : foo bash-4.3 502 $ : bar bash-4.3 504 $ bash-4.3 505 $ bash-4.3 507 $ bash-4.3 509 $ And then with 4.4: $ HISTCONTROL=ignoreboth:erasedups PS1='\s-\v \! \$ ' PROMPT_COMMAND='history -a; history -n' ~/git/bash/bash --norc bash-4.4 501 $ : baz bash-4.4 502 $ : qux bash-4.4 503 $ bash-4.4 503 $ bash-4.4 503 $ bash-4.4 503 $
In bash 4.3 you can use nameref variables #!/bin/bash blah=my_cool my_cool_exclude=( t1 t2 t3 ) declare -n v="${blah}_exclude" ignores=() for t in "${v[@]}"; do ignores+=( --ignore-table "$t" ) done printf '&lt;%s&gt;' "${ignores[@]}"; printf '\n' See [BashFAQ 6](http://mywiki.wooledge.org/BashFAQ/006) for how to do this in older versions. Don't use uppercase variable names. You risk overriding special shell variables and environment variables.
Yep, I fixed that, but I still have this problem.
Awesome, thanks. I knew it was something simple.
What happened from the time it worked until the time it stopped working? Something changed. Find out what that something is. You may also want to ensure that this file isn't "arguing" over another file that keeps trying to set PROMPT, be that another dot file in your home directory or a global like /etc/bashrc (substitute what shell you use obviously). Locals override globals, but it's worth a look anyway.
That looks similar to some of the stuff I've found Googling. Would it be possible to explain which parts of what I want to do match with what you've posted? For example, what would the expression be? Would my mess of wildcards up there be a regex, or could it be formatted so that it would be and I could use it in what you've posted? Very sorry if these seem like obvious questions, I'm quite new at this, and thanks for the reply! EDIT: It also looks like regex doesn't support inverse matching. Is that right? I think that's what I need to do here. 
&gt; Would my mess of wildcards up there be a regex Yes, the crazy expressions in your `grep` command are a regular expressions, because `grep` works on regexps.\* However, I'm still not quite sure exactly which files you want to match. Could you explain better what kinds of files you're iterating over, and which of those you want to match? \*Fun fact: the name `grep` comes from the ed command `g/re/p`, which can be read as "**g**lobally search a **r**egular **e**xpression and **p**rint".
I'm not knowledgeable enough to be sure, but I think the version played a big role. I learn by using what I see online, and I must have copied something or deleted something that was(n't) mean to be used with my version. I changed the version and everything works fine now, even with my attempts to reproduce my problem.
Thank you. I'm not concerned with actual dimensions at this point, just with reducing image quality and file size. I'm going to try using the file command to get dimensions, though. That sound cool!
I'll have to google this a little bit but it looks promising, at least for simplifying the script. Thank you!
oh man this looks really close to what I want to do. I do have some files that end in numbers, so I'll have to tweak the regex a little bit, but that looks so promising. I'm headed to the airport so I won't be able to play with it for a while, but I'll get back to you once I try it out. A million times thanks!
First of, I'm very new to regular expression myself and only recently got into it to help a friend make some datamined info for a game a bit more readable. But I think you can replace your grep string with ls | grep -v -e -[0-9]{2,}(?:x|) and it should have the same result. [0-9] matches digits. {2,} matches two or more of the preceeding pattern in a row. (?:x|) looks for an x or nothing directly after matched digits.
Here's a pretty straightforward implementation. #!/bin/bash images=$(find . -name '*.jpg' | grep -vP '\dx\d') # Using grep with perl regex syntax to exclude # all image files containing &lt;digit&gt;x&lt;digit&gt; for image in $images; do # figure out which quality to use for each file filesize=$(wc -c &lt; "$image") if [[ $filesize -gt 800000 ]]; then quality=25 elif [[ $filesize -gt 200000 ]]; then quality=50 else quality=100 # or you can use "continue" here, to skip mogrify of the small files. fi # Convert using quality and whatever other options you want. mogrify "$image" -quality $quality done 
&gt; for image in $images This will break if any of the images have whitespace in their name. Using your mogrify command and a few hints from elsewhere in this thread, I would try something like this: find . -type f \! -regex '.*[0-9]x[0-9]*\.jpg' -name \*.jpg -size +800000k -exec mogrify {} -quality 25 find . -type f \! -regex '.*[0-9]x[0-9]*\.jpg' -name \*.jpg -size +200000k -size -800000k -exec mogrify {} -quality 50 EDIT: Breaking it down, `find .` -- iterate over files under the current directory `-type f` -- for files only `\! -regex '.*[0-9]x[0-9]*\.jpg' -name \*.jpg` -- whose names end in .jpg and doesn't match the regex `.*[0-9]x[0-9]*\.jpg` `-size +200000k -size -800000k` -- whose size is between 200000 kB and 800000 kB `-exec mogrify {} -quality 50` -- when `find` reaches a $file matching the above conditions, run `mogrify $file -quality 50`.
Just a little question to throw in: Why don't we use echo anymore? I use it since I started shell-scripting and there was rarely any occasion where I had to switch to printf.
Well it's especially true for sh scripts, since some implementations replace ansi c escapes (like `\t`, `\n`, `\040`, etc) by default, some only replaces them if you add an option (`-e`). Some implement a `-n` option, some don't. It's a mess. `printf` behaves much more consistently. Since bash's `echo` takes options, and POSIX specifically does not allow it to handle `--` to mean end-of-options. You cannot output a string containing only `-e` or `-en` or `-n` etc. $ var='-en' $ echo "$var" $ -- With `printf`, we can output any string we throw at it $ var='-en' $ printf '%s\n' "$var" -en $ Because of the above, both [POSIX](http://pubs.opengroup.org/onlinepubs/9699919799/utilities/echo.html#tag_20_37_16) and [Chet Ramey](http://lists.gnu.org/archive/html/bug-bash/2013-04/msg00008.html) (the maintainer of bash) recommend using `printf` rather than `echo` for **new** scripts. `echo` will continue to be supported for all eternity, most likely, to allow existing scripts to function as before, but **new** scripts should use `printf`.
You could also add history -a to your PROMPT_COMMAND. That way, you'll never lose a single line and it is saved instantaneously.
&gt; Using an alias does not work. You can only use alias for single commands, not something that's several commands put together with | or ; or &amp; etc. Not correct. All of those things can be used in an alias: alias eh='sleep 2 &amp;&amp; echo much later &amp; ls -w1|xargs -I {} echo "some file: {}"; echo that is all ' As to OP's alias issue, getting that into an alias is trickier because his command uses both single and double quotes. One way to make that an alias would be this: awkcmd='NR==1{t=$1} NR&gt;1{r=int($1/t*c+.5); b="\033[1;31m"; for (i=0; i&lt;r; i++) b=b"#"; printf " %5.2f%% %s\033[0m %s\n", $1/t*100, b, $2}' alias ducolor='du -x --max-depth=1|sort -rn|awk -F / -v c=$COLUMNS '"'"$awkcmd"'"' |tac' Also OP you may be interested in the `ncdu` program. Edit: however, /u/ropid is correct that a function would be much cleaner in this (and most) cases.
OP posted this an hour earlier in /r/commandline https://www.reddit.com/r/commandline/comments/45pspj/parse_any_script_as_a_oneliner/ More detail from OP about what they actually want here: https://www.reddit.com/r/commandline/comments/45pspj/parse_any_script_as_a_oneliner/czzh871
So I tested without the eval and got &gt;line46name={string with space}" which meant that eval was causing the issue. I then realized that eval was processing the quotes to early so I escaped the quotes. Now the line looks like: eval line${filecount}name=\"${myArray[1]}\"
Think of each variable as a stack; 'local' pushes a value onto the stack, and exiting a function pops a value. Edit: This is called dynamic scoping.
Actually deleted the other comment. This worked, thank you!
[removed]
[removed]
With the paths I was having issues getting it to work if it was part of an array, but didn't have that issue with URL's. I read up after getting the initial help from the other poster, and I have fixed it all now haha :P 
Yes, I've been using eval in my one-line getopt, before noticing that: while [ "${1:0:2}" == "--" ]; do declare _${1:2}="${1:2}"; [[ ${1} =~ = ]] &amp;&amp; declare _${1:2}; shift; done 
It doesn't matter. You just need to make sure it doesn't do anything with the space or `$`. `awk {print' $'1}` would be fine.
Here is a really good explanation: http://unix.stackexchange.com/questions/65803/why-is-printf-better-than-echo
Yes, it takes the second positional parameter, pipes to awk, uppercases it and assigns the result to `ticker`.
You should consider using exit codes instead of writing 1 and 0 in your boolean functions so you can use it as: setop equel a b &amp;&amp; echo "they are equel" if setop equel a b; then echo "they are equal" fi if ! setop equel a b; then echo "they are NOT equal" fi
I'm just doing all I could find through googling! The only way I had found to do this is with cURL. I'll try and figure rsync out I suppose then!
Yeah, rsync is fucking weird. I'll keep trying but I'd appreciate if you could show me an example of a working rsync command on one of these URL's.
Dude, this is awesome! Thanks! I will give it a shot!
Yeah, this is great! Thanks a bunch! I was unable to get it to work on this site though, which makes me sad :( The github one was just one of two sites giving me trouble!! http://pgl.yoyo.org/adservers/serverlist.php?hostformat=hosts&amp;showintro=0&amp;mimetype=plaintext
Thanks!
Yup, it's `ls`. There's a parameter to get the old behavior back, if you want to. It seems to be `ls -N`. Add an alias for `ls` in your ~/.bashrc to have it as default. If it's not rustling your jimmies too much, a reason to keep it is because it enables you to see what's really up with broken file names. For example, here I create a file name with a new-line character in it: $ touch "abc &gt; def" $ ls 'abc'$'\n''def' That weird output is how you can build text in bash that has a new-line in it. This means with this new `ls` output, you can use copy'n'paste to get what you need to deal with this broken file name in bash. old behavior shows this: $ ls -N abc?def 
Shellcheck is brilliant; I wish I'd been told about it before. Thank you!
don't for-loop the ls output, you have native globs for that shit for file in "$1"/*.dat don't for-loop plaintext blobs from command outputs. Main use cases of for-loops are enumerables: params, arrays, globs, explicitly listed 'words'. If you want to work on a per line basis use while read loop while read line do (( count++ )) (( totalrating += line )) done &lt; &lt;( grep ... | tr ... ) 
It would help if you specify what exactly are you looking in these strings or provide two lines to show what changes and what doesn't in them. Otherwise, if I assume that only abc and xyz change from line to line, then the following statement should work for you: grep -E "^Mr ([a-z]+) came home to Mrs \1 and visit Mr ([a-z]+) and Mrs \2 to discuss backreferences" 
 lst=("${l2[@]}" "${l1[@]}")
`id` is not a builtin: $ type id id is /usr/bin/id In bash you can test the special `UID` and `EUID` variables instead. if (( EUID != 0 )); then printf &gt;&amp;2 'This script should be run as root\n' exit 1 fi On a side note, don't use `[`, `` `...` `` and `echo` in bash. Use `[[ ... ]]` to test strings and files, `((...))` to test numbers, `$(...)` to capture command output, and `printf` to write output.
maybe because -eq -lt -gt -le -ge are an eyesore, not to mention the necessity to $ everything? (( )) version is as pretty and readable as it gets.
Here's an unfair example because arrays require the `{}`: if (( sources[count] &lt; targets[count] )); then ... against if [[ ${sources[count]} -lt ${targets[count]} ]]; then ... I agree it's not that much prettier when it's about `[[ $x -gt 0 ]]`, but I still like `(( x &gt; 0 ))` better with that as well.
I still don't see the issue or problem with your second example. Looks perfectly fine / clear to me. Also, when I start needing array maths in BASH I switch to Perl or something else.
See `man grep` under "Back References": `Back References and Subexpressions` ` The back-reference \n, where n is a single digit, matches the substring previously matched by the nth parenthesized subexpression of the regular expression.` `echo 'Mr abc came home to Mrs abc and visit Mr xyz and Mrs xyz to dis- cuss backreferences' | grep '\(abc\).*\1.*\(xyz\).*\2'`
* On how to use arrays, see [BashFAQ 5](http://mywiki.wooledge.org/BashFAQ/005) * On how to do math, see [ArithmeticExpression](http://mywiki.wooledge.org/ArithmeticExpression) * On how to get the syntax of the `for` command correct, run `help for`. And let's not forget the [BashGuide](http://mywiki.wooledge.org/BashGuide) for learning the basics of bash.
I didn't mix the brackets. `$(())` is how you do arithmetic in bash. edit: You could also do: if [[ $((a+b+c &lt;= d*e)) -eq 1 ]]; then ...but that seems a bit ridiculous.
Parse for what, or do you just want to see the output?
This is a good answer, but let's nitpick, shall we? The main thing is you don't have to annotate variables with `$` in math expressions inside `((…))` constructs. You also don't need to preface the construct with a `$` because you don't actually want to execute the value. Finally, you don't need to assign `sum` to be the value of itself plus 1. Just increment it like so: `((sum += 1))`. It's 2015, so you can use `printf` instead of `echo`. Finally, although it likely doesn't matter for the case where `list` is `(1 2 3 4 5)`, it's still best practice to double quote it in the `for` loop: `"${list[@]}"`. Here's my updated take on your solution: #!/bin/bash list=(1 2 3 4 5) sum=0 for i in "${list[@]}"; do ((sum += i)) done printf "sum %d\n" $sum You can run this code through [ShellCheck](http://www.shellcheck.net/) to see that there are no issues. 
 ((EUID != 0)) &amp;&amp; printf &gt;&amp;2 'This script should be run as root\n' &amp;&amp; exit 1 Short and sweet!
Umm, I don't get why you're introducing newlines with `tr` and then replacing them with `+` using `paste`. Why not just do `tr ' ' '+' &lt;&lt;&lt; ${list[@]} |bc`?
To further nitpick, printf isn't new, it is preferred over echo when writing sh/POSIX-compatible shell code :) (echo has varying behavior across unixes wrt escape sequences and -n)
To further nitpick, you missed where parent poster said: &gt;It's 2015,
Oh no, I got your point. I believe that *you* missed *my* point that *you* missed the opportunity to pin him on stating that it's 2015. I'm pretty sure it's *not* 2015.
Oh snap, I can't believe I'm in the wrong year!
That's elegant, but also permanently changes `IFS`. Could be run in a subshell maybe? Like this: $ cat -A &lt;&lt;&lt; "$IFS" # Show IFS ^I$ $ $ list=(1 2 3 4 5) $ ( IFS=+; bc &lt;&lt;&lt; "${list[*]}" ) 15 $ cat -A &lt;&lt;&lt; "$IFS" # Still space tab newline ^I$ $ $ IFS=+; bc &lt;&lt;&lt; "${list[*]}" 15 $ cat -A &lt;&lt;&lt; "$IFS" # Changed +$ 
Because I *so* wanted to use `paste -s -d`.
It wasn't my homework question lol, but thanks for being thorough.
Nope, doesn’t work. In that case, the new `IFS` will only apply after the here-string has already been evaluated.
https://www.youtube.com/watch?v=TKYQ5ibxslI :)
And that's why I ultimately say script your own script. Do what makes you happy. For me, `(())` is tantamount to just doing stuff like `if grep foo; then` which I try to avoid, in favor of testing `$?` for success after running the command. `[[]]` is how I do tests, for consistency, not convenience.
`man bash` mentions a BASH_SOURCE array, but I don't quite understand it. When sourcing a script it does get set to the path of the script. The directory that the sourced file is in then becomes `"${BASH_SOURCE[0]%/*}/" # '../script.sh' -&gt; '../'`
20 minutes ? good luck. 
Any idea why the separation between /bin and /usr/bin doesn't exist anymore? 
The `&gt;` and `&lt;` in `[[` compare text, not numbers. It's using how text would be sorted to decide what to answer for this comparison. The "abc" text sorts after the "123" text. The "23" text sorts after the "223" text just like an "AB" text would sort after an "AAB" text. Numbers are compared with `-eq`, `-lt`, ... (equal, less-than, ...). The full list is mentioned somewhere in the output of `help test`. In the special variables $1, $2, $3, etc., bash has the parameters of a function. When you have a function "func()" and do "func a b c" to call it, then you'll have 'a', 'b' and 'c' in $1 to $3 when in your "func()" code. You can use `"$@"` to get a list of those $1, $2, etc., and `$#` has the count. You can test with `[[ -n $1 ]]` to see if a parameter exists. The 'local' makes it so a new variable gets created that will hide what was previously going on under that same name. This new variable exists until the function returns and then the previous variable with that name becomes visible again. If you don't use 'local', then you overwrite variables that existed outside of the function. No idea what you are supposed to use for that "extract number" question. There's ways to do it, but what I could come up with feels too complicated. You should look through what you were told about until this point for a hint about what you are supposed to use there. The backreferences in grep are, when you surround something with `\( \)` in a regex, what's in the `\( \)` is put into codes `\1`, `\2` that you can use later in the regex. You can use that to match "Mr Zed and Mrs Zed", but don't match "Mr Zed and Mrs See".
Thanks, that was all news to me :)
Remove the leading and trailing parts with parameter expansions, then split on comma with read. s=${s#/acct/} s=${s%/name/} IFS=, read -ra numbers &lt;&lt;&lt; "$s" printf 'Extracted numbers:\n' printf ' %d\n' "${numbers[@]}"
&gt; #!/bin/python Wouldn’t it be better to explicitly specify either #!/bin/python2 or #!/bin/python3 ? (And can you really assume that they’re in `/bin`?)
I have read all your comments. you guys helped me a lot. Thank you for your time. 
thank you for showing a different way t approach the problem.
simple :) thank you 
You're welcome! Sometimes I find it fun to golf (code-golf); I learn a lot of new things doing that. This was no exception :)
I love shellcheck. This is awesome. 
I learned from reddit user: ropid; that &gt; and &lt; in [[...]] is used for comparing text and -lt, -eq and such is used for numbers.
lol
Wow, thank you! Uppercase variable names is just a carry over from the way I code in python, bad habit I guess. I'll correct that. awk is left over from when I was scraping the whole page before I found out about thingspeak and have that scrape for me. So ya, not needed at this point. I'll remove that. Good tips on the brackets and echo/printf! 
I wrote [this script](https://www.reddit.com/r/bash/comments/3zrdq6/converting_script_into_daemon/cyp6zon). It can be used to do what you want (I use it, for instance, in a script to 'ping' a bunch of servers). Let me know if you want me to post it.
I second parallel. So many loops not needing to be written, and executed so much quicker 
This! &amp; is your friend! 
sounds very handy. do you have it posted? or could you please send me a message with it? thanks. 
Check out pdsh.
Not trying to be an ass or anything, but why not just use fping?
[Here it is](http://pastebin.com/yt6F0Qif).
I didn't know 'fping' existed, but with my script I can check the results of every ping. Background process' info: Text that when sourced (with 'eval') gives values to following variables: 'CommandLine': Command and parameters of process when launched. 'ElapsedTime_mS': Time (in MilliSeconds) the process was running. 'ExitCode': Exit code of process. 'StandardOut': Output generated by process while running. 'StandardError': Error output generated by process while running. 
Not for the task I referred to: I ping SIMULTANEOUSLY to a bunch of servers, after a given time I kill those processes still trying to ping and read the results (Did they succeed? Output?) of those that had finished.
That's literally what fping does. 
Given s=’/acct/1,696,807/name/’, write a Bash command to extract the numbers without commas. Your command must work for any number of numbers and commas. This should work with standard grep: printf '%s\n' ${s//// } | grep '[0-9]' | tr ',' '\n'
Please note that 'BackgroundProcess' should be in a $PATH directory.
I was trying that as well but couldn't quite get it working. I'll try it again. Is this way not possible? Yeah so trying to use an array doesn't store all the values for some reason. Check it out: Code: for i in {0..5}; do if [[ -f ./user$i ]]; then group=($(grep -w "group" ./user$i|awk '{print $2}'|perl -lape 's/\s+//sg')) shell=($(grep -w "shell" ./user$i|awk '{print $2}'|perl -lape 's/\s+//sg')) state=($(grep -w "state" ./user$i|awk '{print $2}'|perl -lape 's/\s+//sg')) uid=($(grep -w "uid" ./user$i|awk '{print $2}'|perl -lape 's/\s+//sg')) users=($(grep -w "users" ./user$i|awk '{print $2}'|perl -lape 's/\s+//sg')) echo -e "---\n\nuser:\n" &gt; ./test.yml echo -e " - { name: $users, groups: $groups0, group: $group0, shell: $shell0, state: $state0, uid: $uid0 }" &gt;&gt; ./test.yml fi done echo ${group[@]} Gives me this output: &gt; root@ubuntu /var/www/stobietech.com/new # bash test.sh &gt; g Even though there are two values that it should print, see below: &gt; root@ubuntu /var/www/stobietech.com/new # grep -w "group" user* &gt; user0:group j &gt; user1:group g
Here is a pure bash version I ran across somewhere else (so not my original work). Replace the '2' in '-ge 2' with the number of copies to have running concurrently. function max2 { while [ `jobs | wc -l` -ge 2 ] do sleep 5 done } find . -type f | while read name ; do max2; some_heavy_processing_command ${name} &amp; done wait edit: Possible source. http://stackoverflow.com/questions/6593531/running-a-limited-number-of-child-processes-in-parallel-in-bash edit 2: Found I have two very similar scripts in my notes. I think this version is more clear. edit 3: Made things more pretty.
There's a command `wait`. Take a look at `help wait`. It has this sentence: &gt; If ID is not given, waits for all currently active child processes [...] Try to see if this here works: tesseract $GRAB_PATH/1a1.jpg $GRAB_PATH/1a1 &amp; tesseract $GRAB_PATH/1a2.jpg $GRAB_PATH/1a2 &amp; tesseract $GRAB_PATH/1a3.jpg $GRAB_PATH/1a3 &amp; tesseract $GRAB_PATH/1a4.jpg $GRAB_PATH/1a4 &amp; wait 
You can use awk to do this nicely. https://www.gnu.org/software/gawk/manual/html_node/Splitting-By-Content.html
What about: `echo 1a{1..4} | xargs -n1 -P4 -Ixxx tesseract $GRAB_PATH/xxx.jpg $GRAB_PATH/xxx` I think it's a bit cleaner. 
If you don't really need portability between systems I would highly recommend installing csvkit for this. It's immensely helpful for dealing with some fairly ugly datasets. Check it out here: https://csvkit.readthedocs.org/en/540/
&gt; printf "1a1\n1a2\n1a3\n1a4\n" | xargs -n1 -P4 -Ixxx tesseract $GRAB_PATH/xxx.jpg $GRAB_PATH/xxx Perfect, thanks. I did try the 'wait' command which did the trick, but this solution works even better and no need for the wait command either. 
Indeed this is cleaner, and in fact I started with this. However on GNU xargs, using the -I switch appears to turn on 'line at once' mode, and the args are no longer split on space. On BSD xargs (e.g. MacOSX), it seems to work as required :-) Example: BSD xargs (OS X) - this seems to work as expected, multiple echo invocations, not necessarily in order: $ echo 1a1 1a2 1a3 | xargs -n1 -P2 -Ixxx echo xxx 1a2 1a1 1a3 GNU xargs (Linux) - consuming line-at-a-time, only one invocation of echo: $ echo 1a1 1a2 1a3 | xargs -n1 -P2 -Ixxx echo xxx 1a1 1a2 1a3 But you're right, if OP is running a BSD-based system, this is the right thing to do.
Glad it worked!
Thanks for the explanation.
not sure why, but this isnt working. No error messages, just not working 
On freebsd's ls it apparently is `ls -B` and it will show the characters as octals like \NNN.
Instead of \? (a literal ?) you can use a regex named group of characters. `[^[:print:]]` is a non-printable character that ls would write as ?. for file in *; do if [[ "$file" =~ ^(.*)[^[:print:]]\(([0-9]{4})\)\.(...)$ ]]; then mv -vi "$file" "${BASH_REMATCH[1]}(${BASH_REMATCH[2]}).${BASH_REMATCH[3]}" fi done 
I tried to use sed. I used this test file: $ cat testfile Jim Parsons,31,California "Lemmiwinks, Hamster",31,Colorado Waco Kid,57,"Rock Ridge, Old West" I don't know if regex is a good idea for this problem, but this here seems to work: $ sed -r 's/^("[^"]*"|[^",]*),("[^"]*"|[^",]*),("[^"]*"|[^",]*)$/\1\t\2\t\3/; s/"//g' &lt; testfile Jim Parsons 31 California Lemmiwinks, Hamster 31 Colorado Waco Kid 57 Rock Ridge, Old West You said it's AIX. If your sed there doesn't want to do it, you can use the exact same rule for perl: $ perl -pe 's/^("[^"]*"|[^",]*),("[^"]*"|[^",]*),("[^"]*"|[^",]*)$/\1\t\2\t\3/; s/"//g' &lt; testfile Jim Parsons 31 California Lemmiwinks, Hamster 31 Colorado Waco Kid 57 Rock Ridge, Old West About the regex that's used, it's three of these here that match the columns: "[^"]*"|[^",]* 
Thanks, I'll give this a shot. 
&gt; which I have put directly in the distribution to make life simpler for downloaders. I'm not sure you should have done that, I believe the proper way is to say "depends on B" somewhere, so people know to download them seperately (if a user already owns B, they are re-downloading with their project). If you plan to make said script a package for a distro, make B its dependency.
If you have Python available to you it would be pretty easy in Python as well. Pure bash would be hard.
that is amazing. thank you. 
&gt; Also, it's not 1981 - that's where backticks belong :) \**swoon**
This script is made for use on an installation disk without a package manager. It would be very hard to install script B, as it requires curling, decompressing, and building. I did this on the actual OS, and copy-pasted the script into my distribution to make life for users simpler. If I were to instead make a script that automated the installation of B, what proper credits should I give to B? Should I add a notice to my readme, or should I just mention that the script uses B?
Okay, thanks.
As a thought for a near-pure-bash option, you could read each line into an array, using the comma as a delimiter for element selection. Then print each element out as you please. E.g. If the element starts with " then print it, a comma, and the next element, followed by a tab. Else, print the element and a tab. I had that thought without coffee on board, so I may be way off target. 
[needs citation] 
 date +"'%Y-%m-%d'"
&gt; PROMPT_COMMAND='l="$(cat /tmp/lasterr)";…' If you instead use $(&lt; /tmp/lasterr) you don’t need an extra process. (I’m not sure if this saves you one or two `fork`s, since I don’t know if `$(&lt; /tmp/lasterr)` still creates a subshell or not.)
Don’t you need to replace the `GET` with something like `cat`? Also, what’s the point of this post? If you want to write a backdoor, there’s easier ways to do it. Ditto for a web server. I don’t understand what you’re getting at here.
You don't really need to resort to GNU date there. postgres can calculate "tomorrow" too... psql -h 1.2.3.4 -U dbuser -d database1 &lt;&lt; EOF &gt;&gt; /home/sql/output.csv COPY ( SELECT sent_date AT TIME ZONE 'Australia/Sydney', from_jid, to_jid FROM jm WHERE sent_date AT TIME ZONE 'Australia/Sydney' BETWEEN 'now' AND 'tomorrow' ORDER BY sent_date ASC ) TO STDOUT WITH CSV HEADER EOF
Slightly off-topic to the date but what is the benefit of using the Here Tag syntax verses what was used in my script? Also, are you missing the -c in your Here Tag?
Someone asked me to run it; I want to know what would happen if I run it, Am I in risk (in theoriy)?
[Don't read lines with for](http://mywiki.wooledge.org/DontReadLinesWithFor). Use a while read-loop instead. Or in this case, awk is fairly on point. #!/usr/bin/env bash read -ep 'File for extraction: ' infile awk -F: -v date="$(date +%Y%m%d)" '{file = "stuff." date "." $5; print $4 &gt; file}' "$infile" If field five has a lot of unique values, you may hit the limit on number of open files. This can be avoided by using a recent version of GNU awk, or by adding some additional logic to close files underway.
You play with ideas on the command line until you feel confident that an idea will work, then try to write your script. You should check out all the small Unix text tools so that you get a general idea of what they do. I mean `cat`, `tail`, `head`, `sort`, `uniq`, `diff`, `comm`, `sed`, `awk`, things like that. You need to know about redirection and pipes to be able to combine the tools into one, so `|`, `&lt;`, `&gt;`, `&lt;( )`. Here's a test file A: $ cat &gt; A green blue black white gray purple # press Ctrl-D here to end file Let's delete two lines in there: $ sed '3d;5d' A green blue white purple Put that into B: $ sed '3d;5d' A &gt; B The `comm` tool can be used to find different lines in two files. The files need to be sorted, so they first have to go through `sort`. $ comm &lt;(sort A) &lt;(sort B) black blue gray green purple white The tool creates weird columns by inserting TAB characters. There's one column with lines in the first file, then a column for the second file, and a third one that has lines that are in both files. The TAB characters can be turned off with `--output-delimiter=`. You can remove the third column that displays lines that are in both files with `-3`. $ comm -3 --output-delimiter= &lt;(sort A) &lt;(sort B) black gray So that would be an idea that might work and you could start writing your script. You can also try to start programming your script at the command line before you do it in the script, like so: $ i=0; while read -r x; do \ &gt; echo "Difference $((++i)): $x"; \ &gt; done &lt; &lt;(comm -3 --output-delimiter= &lt;(sort A) &lt;(sort B)); \ &gt; echo "Count is $i." Difference 1: black Difference 2: gray Count is 2. 
sort A B | uniq -u 
yeah, because it's super helpful [here](http://i.imgur.com/Lj3WfCM.jpg). Also, it's not bash, it's coreutils `ls`.
I think constructing a 'cat file | tool' line matches the initial thinking process better. But it's clunky, not concise, not elegant, you should know better. It's a first draft, not something you would show to the world. Compare it with a letter: you'd go through it one or two times to make sure every 'their', 'they're', 'a lot', commas, capitals etc are right, before sending it. [Useless use of cat award](http://porkmail.org/era/unix/award.html)
What about `&lt;file tool`?
Assuming that you can safely say there will be only one "." in the file name, this will output the newly transformed filename, for each of your files: for i in *.exe; do num="$(echo "$i" | cut -d" " -f 1)"; rest="$(echo "$i" | cut -d" " -f 3- | cut -d"." -f 1)"; ext="$(echo "$i" | cut -d"." -f 2)"; echo "$rest ($num).${ext}"; echo; done Regards, - shellmachine
(heh, didn't know, TIL) that doesn't work for me, in my mind I read '&lt;' and '&gt;' as funnels, arrows
sorry for being late on this one. :-)
Here's the answer: https://en.wikipedia.org/wiki/Cat_(Unix)#Useless_use_of_cat
From man comm Compare sorted files FILE1 and FILE2 line by line. With no options, produce three-column output. Column one contains lines unique to FILE1, column two contains lines unique to FILE2, and column three contains lines common to both files. -1 suppress column 1 (lines unique to FILE1) -2 suppress column 2 (lines unique to FILE2) -3 suppress column 3 (lines that appear in both files) --check-order check that the input is correctly sorted, even if all input lines are pairable --nocheck-order do not check that the input is correctly sorted --output-delimiter=STR separate columns with STR --help display this help and exit --version output version information and exit Note, comparisons honor the rules specified by 'LC_COLLATE'. Examples comm -12 file1 file2 Print only lines present in both file1 and file2. comm -3 file1 file2 Print lines in file1 not in file2, and vice versa. http://linux.die.net/man/1/comm 
Start it with `bash -x ...`. I bet the error is in the line with the `if`, and it's about there not being a file named "6". What you are doing there is, you start this program: date +%u And you redirect a file "6" into its input: &lt; 6 What you really wanted is this: (( $(date +%u) &lt; 6 )) or this: [[ $(date +%u) -lt 6 ]]
Specify the complete (absolute) path to log.txt in both cases. That may fix your problem. 
And I feel like an idiot but have a much better understanding now. Thank you!
There are several problems with that short snippet: 1. `"date +%d"` is a string. It is never executed. 2. `[ foo=bar ]` is the same as `[ -n foo=bar ]`; it checks if `foo=bar` is a non-empty string. The `[` command counts the number of arguments to decide what to do. 3. Your script is missing the shebang line. The very first line of the script should read: `#!/usr/bin/env bash`. Further, don't use the `[` command in bash. Use `[[ ... ]]` to test strings or files, `((...))` to test numbers. Also note that %d results in a zero-padded number, and it will be treated as octal if it starts with `0` and you use it in an arithmetic context. To avoid that, either remove the leading zero, or specify the base to use with `base#` #!/usr/bin/env bash day=$(date +%d) day=$(( 10#$day )) if (( day == 1 || day == 15 )); then printf 'Will update.\n' else printf 'Will not update.\n' fi Since bash version 4.2, you don't even need `date printf -v day '%(%d)T' -1 day=$(( 10#$day )) 
Thanks for the reply. I am running it by the minute in cron. /home/lr/beth is what I called the file before I changed it to cell. lol i just didn't change it when I posted it here. My overall goal is to trigger some home automation stuff instead of playing an mp3 file, but that is down the road aways. This script is primarily to discover when either my wife or myself is home and then execute an action.
Seems good, except for that capital `I`. :)
Well, seems I'm too late, and your question is already answered. I guess I'll just say that this: &gt; yes, my computer is named after a stripper gave me a hearty chuckle. :)
Ahaha, that's hilarious! Linux isn't scary, it's awesome! Sounds like fear of the unknown to me. :)
 #!/bin/bash src=colors.txt declare -A colors while read -r red green blue color do read -ra words &lt;&lt;&lt; "$color" printf -v key '%s' "${words[@]^}" printf -v rgb '%3d %3d %3d' "$red" "$green" "$blue" colors[$key]=$rgb done &lt; "$src" for key in "${!colors[@]}" do printf '%-20s %s\n' "$key" "${colors[$key]}" done | sort &gt; sorted_by_name.txt expected output (with final redirection commented out) $ ./colors.bash AliceBlue 240 248 255 AntiqueWhite 250 235 215 Azure 240 255 255 Bisque 255 228 196 Black 0 0 0 BlanchedAlmond 255 235 205 Cornsilk 255 248 220 DarkSlateGray 47 79 79 Honeydew 240 255 240 Ivory 255 255 240 Lavender 230 230 250 LavenderBlush 255 240 245 LemonChiffon 255 250 205 Linen 250 240 230 MintCream 245 255 250 MistyRose 255 228 225 Moccasin 255 228 181 NavajoWhite 255 222 173 OldLace 253 245 230 PapayaWhip 255 239 213 PeachPuff 255 218 185 Seashell 255 245 238 White 255 255 255 used assoc array (bash 4.x) to easily deduplicate while reducing usage of external tools to minimum having that you can write a thin wrapper around `grep -i "$regex" sorted_by_name.txt` or whatever
Take it slow. The best way to learn is by using it. When you find something you don't know how to do, look it up. Regardless of your distro, the Arch wiki is a great resource (Lots of the entries are distro-agnostic). If you're in a hurry to learn, immersion is very effective. I was a casual Linux user for years until I uninstalled Windows completely; it stopped being a crutch when I didn't know how to do something in Linux. `man`, man. With all documentation, remember that you have a search function for a reason -- `Ctrl-F`, `/`, etc. Reddit is also great for answering your questions. Lots of *nixers around. Feel free to drop me a PM or ping me on IRC if you have any questions as well!
You're right, it would. It can also be changed easily to 'head' for quick testing: &lt;file head | tool1 ... | tool2 ... | tool3 ...
When Ubuntu's file manager display the size as 1.9GB, that means the file is approximately 1.9 * 10^9 B ≈ 1,900,000,000 B. Same on OSX. In other operating systems, it may mean 1.9 * 2^30 B ≈ 2,040,109,465.6 B instead (I think Windows still does that..?). It's a mess.
That's assuming the file is ASCII encoding but it could be UTF-8.
Yeaaaah...as I said, I'm a noob. I learned about cron AFTER posting this. Cron would be the actual way to do what I wanted, but this post was good to fix the code I had. Also, as I said, I got frustrated with the Sunday stuff which is why I tried to make it work with numbers. I was using "=" instead of "==" to set it equal instead of compare. But yeah, I need to use cron and that's what I'll be working to set up tonight. 
&gt; Complicated? As well. Well... no, they're not really complicated at all. Which part of the replies offered are you struggling with understanding?
I really appreciate your expansive advice. would you mind me bouncing another thing off of you? again im not sure how to get started. I ended up using diff to find the differences between the files. currently, im using an input box to to define the two files in which to compare. and my script does exactly what i need it to do as far as output etc. however, its gets more difficult. Image you have 2 directories /tmp and /tmp2 /tmp has the files a1, a2, a3, a4 etc and /tmp2 has the files a1, a2, a3,a4 etc currently in my scrip i could tell it to compare /tmp/a1 and /tmp2/a1 and out put the difference between what is in the first file and the second file. now i want to be able to run the script with out the input. I want to be able to just hit 'Go' and it will automatically compare /tmp/a1 to /tmp2/a1 and /tmp/a2 to /tmp2/a2 etc. then out put to a log showing the difference between each set. i started trying to work it out with an array, but i cant seem to figure out how to marry the two concepts together.
curl -4 http://wttr.in/cityname will give you a bunch of good info, then you can parse out what you need.
Why pipe the file into wc? Why not just pass the filename as an argument to wc? Wouldn't that be much more likely to get a stat call?
Thanks man.
These are the two directories: dirA="/tmp" dirB="/tmp2" You can do this: for fileA in "$dirA"/*; do ... done Each file in $dirA will be put into a variable $fileA, and that "..." code will be repeated. The contents of $fileA will look like this: /tmp/a1 You can get to just the filename without the dirname like this: $ echo "${fileA##*/}" a1 You use that to build a $fileB that is the same filename in $dirB: fileB="$dirB/${fileA##*/}" You should probably check if those two really exist as files as $fileA could actually be a sub-directory and $fileB could be missing. Everything together, you get this: dirA="/tmp" dirB="/tmp2" for fileA in "$dirA"/*; do fileB="$dirB/${fileA##*/}" if [[ -f $fileA &amp;&amp; -f $fileB ]]; then compare_files fi done That "compare_files" would be a function where you have collected your current script. You can access the $fileA and $fileB variables in that function.
Why not just use the builtin postfix implementation (most servers have it enabled for local mail delivery already) and the likely already installed mailx package? $ echo "File larger than 1.5GB" | mail -s "File too big" -r file_notifier@myserver.com me@myserver.com
Here's an alternative implementation using the `find` command. Assuming the file you are checking is located in `/path/to/file/your_file_name`. #!/bin/bash check="$(find /path/to/file/ -name 'your_file_name' -size +1536M)" if [ "$check" != "" ]; then printf "File is 1.5GB or larger\n" #send email notification fi
Ah I see. I’ll look into it, thanks!
In general, you can run your script through [ShellCheck](http://shellcheck.net/) to check for some common mistakes. Apart from that… here’s some comments: - Don’t call your bash script `something.sh` – it’s misleading, since your script won’t actually work with `sh` (you’re using Bash-specific features like `let nbits+=8`). Libraries (meant to be sourced by other programs) should have the extension `.bash`, and programs should have no extension at all: simply `PIA-local-access`. (This also means you won’t have to update your crontab if you rewrite your script in another language: you can keep the file name, since it doesn’t indicate which scripting language is used.) - Don’t use all-caps variable names like `RED` – Bash defines a *lot* of special variables, and by naming your own variables in all caps you risk unintentionally overriding those. Just `red`. - Don’t hard-code escape sequences like `\033[0;31m`. Instead, use `tput`: `red="$(tput setaf 1)"` (**set** **a**scii **f**oreground), `NC="$(tput sgr0)"`. A full list of terminal capabilities is in termcap(5). - When using `printf` with variables, it’s better to not put the variables in the format string, just in case they contain something that would be interpreted as format specifiers. `printf '\tGateway:\t%s\n' "$gateway"` - I haven’t looked at it in detail, but I strongly doubt that it’s wise to have a separate script for cron mode – eventually, you **will** forget to sync some change between the two versions. Just put `PIA-local-access -q` into crontab. If there are more differences between the versions, add options to control them, but maintaining two versions won’t scale. - [Add a license.](http://choosealicense.com/)
You are cheating by using `od`. :) If that's allowed, what else do you allow? Is sed fine? Also, when you mention POSIX, does this mean it has to run with a more basic /bin/sh or is using bash features fine? EDIT: I don't get what output you want. That `${line// /}` is removing all spaces for me so kind of murders text files. Is that right? It also doesn't work in dash, btw., only bash.
What input and output do you want exactly? This is interesting to know because, let's say you want to read raw bytes/characters and want to turn them into their XOR'd result, then output again characters, not numbers as text like in "034 114 156 078". You could construct strings to use with sed's `y/abc/xyz/` command or the `tr` tool. Bash would then only have to work on all 256 possible values for a byte once, just to construct that `y/abc/xyz/` thingy, and then sed or tr would do the real work on the file. It would probably be very fast.
Another possible disadvantage of using `cat` is that if `file` does not exist, `cat file|cmd` runs `cmd` so that its input looks empty, but `&lt;file cmd` causes the shell to return an error and not run `cmd`. Also if `file1` does not exist, `cat file1|cmd&gt;file2` clobbers `file2` but `&lt;file1 cmd&gt;file2` does not. One advantage of using `cat` is that if you have a pipeline like cat file| cmd1| cmd2| cmd3 it is easier to comment out `cmd1` or move `cmd2` before `cmd1` than in this pipeline: &lt;file cmd1| cmd2| cmd3 
Ah, good points I haven't thought about before.
I’m not sure what the working directory for cronjobs is – try writing to `~/updatedon.txt` or `/tmp/updatedon.txt`?
That's exactly what happens. The `$size` won't be seen in the rest of the script when it's set on the right side of a `|`. That's why there's always that weird `&lt; &lt;( ... )` getting suggested.
This isn’t related to the project at all, but the commits aren’t linked to your account. The commit email address is `ptkory@gmail.com`, so you should either link that to your GitHub account, or change your committer email with `git config --global user.email you@example.com`.
Do you just want to keep a terminal open and run the command every hour? If so, then just run $ while; do finger city@graph.no &amp;&amp; sleep 1h; done Or `while true; ...` if you like. See [*while loop*](https://en.wikipedia.org/wiki/While_loop).
The reason for the "&gt; /dev/null" is to redirect the output to nowhere. This is done when you don't care about the output, /dev/null is a junk device that does not save anything. I don't see why your updatedon.txt isn't being updated but do path it out as suggested. Never install a cron job with assumed paths. If you're sure it's not updating check your system logs to see if the cron ran, it should be in /var/log, the file name and location will vary by OS. On Ubuntu for example look in syslog. 
As a linux noob, why not the "at" command?
Cron is for permanent tasks, at is for one-off tasks. Generally speaking
Wouldn't it be better to do ` while; do finger city@graph.no &amp;; sleep 1h; done` so the timing is more accurate?
Thanks for that information, I would probably not have noticed for a while. Corrected.
Pretty much. I get this though - and keep in mind I know VERY little about unix and bash... erik@eowyn:~$ while; do finger lulea@graph.no &amp;&amp; sleep 1h; done -bash: syntax error near unexpected token `;' erik@eowyn:~$ 
It's executable. And it's in the home. Not sure what you mean by the last question?
You can check if `$2` is empty with if [[ -z "$2" ]]; then # empty else # not empty fi or if [[ -n "$2" ]]; then # not empty else # empty fi However, if you plan to support more options, you should look into `getopts`. [Tutorial](http://wiki.bash-hackers.org/howto/getopts_tutorial)
&gt; Even your third example uses a bash/ksh/zsh-ism ("${line// /}") so is not POSIX. Yeah, that's right. In other testing I was using `tr -d " "` Out of interest's sake, I've taken your code and modified it slightly, and on a VM I've ran a quick test against the second and third examples I provided. So, in order: second example, third example, the tweaked version of your code: time Fn_xor &lt; /bin/rand &gt;/dev/null real 0m6.645s user 0m0.788s sys 0m1.116s time Fn_xor4 &lt; /bin/rand &gt;/dev/null real 0m3.519s user 0m0.312s sys 0m0.608s time Fn_xor5 &lt; /bin/rand &gt;/dev/null real 0m0.200s user 0m0.204s sys 0m0.000s Very nice!
Sometimes cron is also used to schedule at jobs to get a random start time when you have a lot of boxes running the same job. If you set your default state on cron to start at the top of every 4th hour and the job the cron runs is at $RANDOM_TIME run normal job Obviously there is a little work around getting $RANDOM_TIME_LESS _THAN4HOURS but this allows you to use a stock config on every box instead of trying to figure out how many hosts to put in each minute of the cron. works well with setups that auto scale adding and removing from the stack based on need.
&gt; sudo apt-get update &amp;&amp; apt-get upgrade That will only run the update in sudo. The precedence is `(sudo apt-get update) &amp;&amp; apt-get upgrade` and not `sudo (apt-get update &amp;&amp; apt-get upgrade)`. There’s two ways to fix this: sudo apt-get update &amp;&amp; sudo apt-get upgrade sudo sh -c 'apt-get update &amp;&amp; apt-get upgrade' --- Apart from that… don’t use `sudo -S`. Instead, put this in your sudoers file (`sudo visudo`): yourusername ALL = NOPASSWD: apt-get update yourusername ALL = NOPASSWD: apt-get upgrade This should allow you to run these two commands without having to enter your password. (I’ve elided the `-y -d` options for brevity; don’t forget to add them everywhere if you want them.)
There’s already lots of advice in the thread, so allow me to zoom all the way out: It looks like you’re trying to reinvent the wheel, specifically the `unattended-upgrades` program. [Debian Wiki](https://wiki.debian.org/UnattendedUpgrades), [Ubuntu Wiki](https://help.ubuntu.com/community/AutomaticSecurityUpdates); these will probably do what you want, without the need for a custom shell script.
In zsh you can do just `while; do ...`. I forgot this doesn't work in bash.
OP said elsewhere he knows very little about unix and bash, so I doubt this is the case, but maybe (or maybe eventually).
If you want to be even fancier than cron, you could use a launchd job so that the command will run even if the computer is sleeping. But cron will probably do the trick too!
Now I ran `while true; do finger lulea@graph.no &amp;&amp; sleep 1h; done`but I get the feeling that the finger-command runs every second (I see the terminal update every second and the response says [Data is cached for 20 minutes. No use in asking every second...]) Any idea? Close to done now though...
I think I got it! The `sleep 1h`where interpreted as 1s, seems it only reads time in seconds. Changed it to 1200 and will find out in about 20 minutes if it works. Thanks everyone!
I'm looking for feedback on this recent project of mine. I'm interested in learning about native Bash options that have become indispensable in your workflow and in common pain points in using Bash. In other words, I'm looking for sensible defaults (hopefully) everyone can agree on. Beginners are welcome! Feel free to open issues, submit pull requests, comment here, or let me know on [Twitter](https://twitter.com/mrzool_). Thanks!
As a beginner, this looks awesome. I will give it a try.
Looks neat. I notice that `set -o noclobber` is used. Might be worth pointing out to users that the little-known `&gt;|` redirection operator can be used to force-overwrite a file even when `noclobber` is active. (This is not even bash-specific, by the way – it's POSIX.)
For me, it's associative arrays.
Yup! Raised on Amiga. Succumbed to PC @school. When Amiga died I went for Linux/BSD @univ but didn't like(hadn't the skill/interest to constantly compile, keep lib.so's in order...) so when I "grew up" I found OS X to meet my demands - easy enough for the rest of the family to use; yet powerful enough for me *if/when* I wanted. Aaaaand it happened to coincide with the iPod-boom. Story of my computer-life... :)
`declare display$i[key]=value` that said you are still swimming up the shit creek, because how are you going to extract these values down the road? The idea sounds like an eval hell Generating variable names is a bad idea, period. That's blurring the distinction between code and data. For something like this, which is effectively a 2-d list, I'd rather use python or some other easy mode language. The next best option would be using a single array display[] with combined key emulating dimensions, eg [$i:$key] 
Thank you very much for the input. That seemed to work, although i switched it around and started with a generic tmpArray to fill in the data and then at the end of the loop copy it to display$i like this: declare "display$i"=${tmpArray[*]} I'm a noob at bash but my plan was this: display$i refers to a display list taken from xrandr, meaning that each $i corresponds to a display actively connected to the computer, and I save the $i in noOfDisplays after I'm done. although bash might not be the best language, don't you think it can work? 
Easy, local -n d=display$i; d[key]="value" # note: use declare if not inside a function.
You can still send messages to logged in users by redirecting the finger process' `stdout`. finger newyork@graph.no | write user_login_name or (to everyone) finger newyork@graph.no | wall or (to all members of a group) finger newyork@graph.no | wall -g target_group 
Cant seem to upload the code clean.. sorry, got kind of messy there!..
right, though just out of habit I always use `local` when inside a function, and it's shorter :)
&gt; export PROMPT_COMMAND="${PROMPT_COMMAND:+$PROMPT_COMMAND$'\n'}history -a; history -c; history -r" &gt; Yep, mine are: HISTCONTROL=ignoreboth HISTIGNORE="&amp;:exit:[ ]*:[bf]g" HISTSIZE=5000 PROMPT_COMMAND="history -a" shopt -q histappend || shopt -s histappend shopt -s cmdhist I don't really see the point of cdable_vars ... i just have aliases set up to go to whatever dir, so instead of doing "cd blah" i just do "blah" and it takes me where I need to go.
Well, you definitely put some effort into this!!! Unfortunately, what you wrote won't come anywhere near what you're trying to do. I can see that you're trying to do the right things (setting variables, using if / else / then logic, etc.), but the hard truth is that this is not even remotely close to working. And it isn't even something that I could comment on a few things here and there to get you to a script that works. You would be better off literally copy / pasting the commands from that blog post (still not all would work, but you would be closer). My most sincere recommendation is to start over, and start WAY smaller. Build a script that does one thing - maybe have it automatically dump the config text to a file. See how it works, make sure the changes that happen are the ones you expected, see what breaks (and what happens/breaks when you run the same script twice on the same system), see what is different when you run the commands from your script as your own user from the command line versus what happens when it runs as a script, and figure out what caused it to execute differently. And once you have *that one piece* working, then move on to add another piece. That way if something in piece 2 breaks at least you know where to go back to. Until you become fluent in a language, I think you should be running the script as you go, to make sure it is performing reliably, and as you expect. This is a time consuming process - the first protects you do are not about getting some amazing tool out of it, they are just a vehicle to learn. Good luck!
Here I'm experimenting at the shell prompt: This declares three arrays: $ for x in {1..3}; do declare -A display_$x; done There's not yet anything to see when searching for them: $ set | grep display_ _=display_3 Next I declare a "nameref" variable. This is a variable where you start with text in it when you declare it, and then when you access this variable like normal, that text that was put in it is used to search for another variable. $ declare -n display I set the contents of "$display" through a "for" loop, then try to write to those earlier declared "$display_1" to "$display_3": $ for display in display_{1..3}; do display[hi]=test; display[hello]=what; done Here's testing if that did what was expected: $ echo ${display_1[@]} test what $ echo ${display_2[@]} test what Here's checking bash's variables: $ set | grep display_ display=display_3 display_1=([hi]="test" [hello]="what" ) display_2=([hi]="test" [hello]="what" ) display_3=([hi]="test" [hello]="what" ) Everything went like expected. You can only set that initial text that's in a "nameref" variable when you do `declare -n`. Afterwards you're always accessing the thing it points to: $ display=something $ set | grep display display=display_3 display_1=([hi]="test" [hello]="what" ) display_2=([hi]="test" [hello]="what" ) display_3=([hi]="test" [hello]="what" [0]="something" ) Here's trying `unset` like normal: $ unset display $ set | grep display _=display display=display_3 display_1=([hi]="test" [hello]="what" ) display_2=([hi]="test" [hello]="what" ) You need `unset -n` to get $display to go away: $ unset -n display $ set | grep display _=display display_1=([hi]="test" [hello]="what" ) display_2=([hi]="test" [hello]="what" ) The rest of this post, I wrote without any testing, so there might be terrible mistakes. You could use this "nameref" thingy and write a bunch of functions to manage your different display arrays. You can use that `-n` parameter also for `local` and not just `declare`. You could do something like this: create_d() { declare -A "display_$1" } set_dval() { local -n display="display_$1" display[$2]="$3" } get_dval() { local -n display="display_$1" echo "$display[$2]" } get_dkeys() { local -n display="display_$1" echo "${!display[@]}" } You'd use them like this: create_d 5 set_dval 5 somekey somevalue set_dval 5 anotherkey anothervalue echo "anotherkey of display 5: $(get_dval 5 anotherkey)" for x in $(get_dkeys 5); do echo "key $x, value $(get_dval 5 $x)" done 
If you have the time I would like you to help with understanding the code you wrote: local creates a local variable but what does the -n parameter mean? EDIT: Judging from /u/ropid's [comment](https://www.reddit.com/r/bash/comments/48zgi8/add_to_dynamically_created_associative_array/d0od57f) that means it's a nameref? since you use d=display$i wouldn't I have to use indirect parameter expansion afterwards to get the values? Thank you
Hi again /u/Vaphell, I think I might now understand what shitcreek you were talking about (or maybe it was my syntax not working for retrieving values but...). Your point about mixing data and data led me to switch it around, so I now have arrays for each type of data I need for the displays. Instead of display$i[xDim]=1920 I now have xDims[display$i]=1920 meaning i now longer have to create arrays on the fly. Maybe it should have been a no-brainer, but I learned something :-) Thank you for the input 
thank you for the thourough explanation of namerefs /u/ropid. I solved it last night by a different approach, but I will have to experiment with the -n parameter. You can see the OP for my solution.
Thanks for the reply! :) Is there a command that waits untill downloads is complete to edit the files? Because they do not exist untill the instalation is complete..
Try this: awk '/q-pt/,/^$/ { print $0 }' file This will print every line between a line matching `q-pt` and a blank line (including both these lines).
what are you after exactly? if you just store dimensions then having arrays for each dimension might be an overkill. Splitting on a char is perfectly doable, so getting x and y from 1920x1080 is trivial. $ declare -A dims=([DFP6]=1280x1024 [DFP7]=1920x1200 [CRT1]=1024x768) $ for d in "${!dims[@]}"; do IFS='x' read x y &lt;&lt;&lt; "${dims[$d]}"; echo "$d: x=$x y=$y"; done CRT1: x=1024 y=768 DFP6: x=1280 y=1024 DFP7: x=1920 y=1200 
Bash reference is very straightforward about this topic: &gt;A variable can be assigned the nameref attribute using the -n option to the declare or local builtin commands (see Bash Builtins) to create a nameref, or a reference to another variable. This allows variables to be manipulated indirectly. Whenever the nameref variable is referenced or assigned to, the operation is actually performed on the variable specified by the nameref variable’s value. A nameref is commonly used within shell functions to refer to a variable whose name is passed as an argument to the function. For instance, if a variable name is passed to a shell function as its first argument, running &gt;declare -n ref=$1 &gt;inside the function creates a nameref variable ref whose value is the variable name passed as the first argument. References and assignments to ref are treated as references and assignments to the variable whose name was passed as $1. Be aware that this option was introduced in Bash **4.3.0**. Also, please read TODO/Note section here: http://mywiki.wooledge.org/BashFAQ/006
so... What does it do?
It just searches for the location of any file you specifiy as an argument.
Another approach is to group `find` arguments, using it as the main loop. find -type f \ \( -exec bash -c 'identify "{}" | grep -q 160x120' \; -printf 'Thumbnail-%f\n' \) \ -o \( -size -20k -printf '0-20k-%s-%f\n' \) \ -o \( -size -50k -printf '20-50k-%s-%f\n' \) \ -o \( -size -150k -printf '50-150k-%s-%f\n' \) 
Good point. I’m surprised that `wc -c &lt; "$file"` still seems to be efficient… I would’ve thought that `wc` wouldn’t be able to shortcut to `stat` in this case.
post the xrandr dump that you are parsing and the current code, i'll poke it with a stick to see if there are improvements to be made. and yes `IFS='x' read x y &lt;&lt;&lt; "..."` is what cuts the dimensions If you needed to cut the dim with offsets, still no problem $ dim=1920x1200+0+666 $ IFS='x+' read x y off_x off_y &lt;&lt;&lt; "$dim" $ printf 'x: %d+%d (%d) y: %d+%d (%d)\n' $x $off_x $((x+off_x)) $y $off_y $((y+off_y)) x: 1920+0 (1920) y: 1200+666 (1866) you could also use regex matching and the builtin BASH_REMATCH[@] array $ [[ 1000x2000+0+1 =~ ^([0-9]+)x([0-9]+)([+-][0-9])([+-][0-9]+)$ ]]; printf '%s\n' "${BASH_REMATCH[@]}" 1000x2000+0+1 # BASH_REMATCH[0] spans the whole match 1000 # BASH_REMATCH[1] -&gt; capturing group #1 2000 # BASH_REMATCH[2] -&gt; capturing group #2 +0 # etc +1 # etc 
Thank you - here you go: xrandr OUTPUT: DVI-I-1 connected primary 1920x1080+0+0 (normal left inverted right x axis y axis) 521mm x 293mm HDMI-0 connected (normal left inverted right x axis y axis) DVI-D-0 connected 1680x1050+1920+30 (normal left inverted right x axis y axis) 494mm x 320mm CURRENT CODE: function getDisplayInfo () { i=0 xrandrOutput=$(DISPLAY=:0 xrandr -q | grep ' connected') while read -r line; do ((i=i+1)) ((activeDisplays=activeDisplays+1)) separateDispInfo () { dispString=$1 # This is a very ugly solution but I cant get expr to escape + # TODO - this should look for '-' as well - or else there isn't much point in saving the arithmetic operators" plusSymbols=() count=0 n=0 while [[ $count -le ${#dispString} ]] do char=${dispString:$count:1} if [[ "$char" = "+" ]] then plusSymbols[$n]="${count}" ((n=n+1)) fi ((count=count+1)) done xDims[display$i]="${dispString:0:(( `expr index "$dispString" x`-1 ))}" yDims[display$i]="${dispString:`expr index "$dispString" x`:(( ${plusSymbols[0]} -`expr index "$dispString" x` ))}" xLocs[display$i]="${dispString: ${plusSymbols[0]}: (( ${plusSymbols[1]} - ${plusSymbols[0]} ))}" yLocs[display$i]="${dispString: ${plusSymbols[1]}}" } displArray=($line) conns[display$i]=${displArray[0]} if [ ${displArray[2]} = "primary" ]; then isActive+=("display$i") isPrimary+=("display$i") #Should be a String var instead separateDispInfo ${displArray[3]} elif [[ ${displArray[2]} = "("* ]]; then ((activeDisplays=activeDisplays-1)) else isActive+=("display$i") separateDispInfo ${displArray[2]} fi done &lt;&lt;&lt; "$xrandrOutput" displays=$i }
You do: cd /the/path/to/your/directory echo "&lt;html&gt; &lt;body&gt; &lt;h2&gt;here&lt;/h2&gt; &lt;/body&gt; &lt;/html&gt;" &gt; index.html Note, the redirection (`&gt; index.html`) needs to be on the same line as the 'echo'. Also, contrary to what NeilHanion wrote, `echo` is perfectly fine as long as you're working on bash and don't need to worry about compatibility with other shells.
That will just print 35, no decimal places at all…
I would just substring it... awk -F '.' '{print $1 "." substr ($2, 0, 2)}' 
 { print int(n*100)/100; }
check this out #!/bin/bash # coloring for shits and giggles declare -A colors=( [RED]=$'\e[31m' [GREEN]=$'\e[32m' [YELLOW]=$'\e[33m' [BLUE]=$'\e[34m' [MAGENTA]=$'\e[35m' [CYAN]=$'\e[36m' [DEFAULT]=$'\e[00m' ) # color_data(color, data[@]) color_data() { declare -A act_prim=( [NN]=DEFAULT [YY]=GREEN [NY]=BLUE [YN]=YELLOW ) local param colname=${act_prim[$1]} local colcode=${colors[$colname]} local reset=${colors[DEFAULT]} for param in "${@:2}" do printf "$colcode$param$reset " done } # get_disp_info(disp_name) get_disp_info() { local data=${displays[$1]} local w h x y active primary IFS='x+ ' read -r w h x y active primary &lt;&lt;&lt; "$data" printf '%s ' "$w" "$h" "$x" "$y" "$active" "$primary" # for capturing in the outer scope } # show_all() show_all() { local d dname width height x y primary row_fmt data_str row_fmt=' %12s | %-19s | %18s | %18s | %18s | %18s | %14s | %14s\n' # width needs to account for the color bytes printf -- '----+-----------+----------+----------+----------+----------+--------+----------\n' printf -- ' | Display | Width | Height | X offset | Y offset | Active | Primary \n' printf -- '----+-----------+----------+----------+----------+----------+--------+----------\n' for d in "${!displays[@]}" do (( i++ )) read -r w h x y active primary &lt; &lt;(get_disp_info "$d") [[ $active = 'Y' ]] &amp;&amp; (( a_cnt++ )) data_color_out=$(color_data "$active$primary" "$i" "$d" "$w" "$h" "$x" "$y" "$active" "$primary") read -r n name ww hh xx yy aa pp &lt;&lt;&lt; "$data_color_out" printf -- "$row_fmt" "$n" "$name" "$ww" "$hh" "$xx" "$yy" "$aa" "$pp" done printf -- '----+-----------+----------+----------+----------+----------+--------+----------\n' printf 'total: %d, active: %d\n' "$i" "$a_cnt" } save_displays() { active_regex='^(.+) connected [^0-9]*([0-9]+x[0-9]+[+-][0-9]+[+-][0-9]+)' inactive_regex='^(.+) connected' while read -r line do if [[ $line =~ $active_regex ]] then disp_name=${BASH_REMATCH[1]} disp_str=${BASH_REMATCH[2]} disp_str+=' Y' active+=("$disp_name") elif [[ $line =~ $inactive_regex ]] then disp_name=${BASH_REMATCH[1]} disp_str='n/axn/a+n/a+n/a N' fi if [[ $line = *primary* ]] then disp_str+=' Y' primary+=("$disp_name") else disp_str+=' N' fi # printf 'saving [%s]="%s"\n' "$disp_name" "$disp_str" displays[$disp_name]=$disp_str done &lt; &lt;( DISPLAY=:0 xrandr -q | grep ' connected' ) echo } ## ========================================================= ## ## program starts here ## ## ========================================================= ## declare -A displays=() primary=() active=() save_displays show_all no idea what you are up to so i just drew a pretty table 
You just don't understand anything about it?? Seems fairly well explained in the information provided...
To someone who knows what they are doing yes. I am in a Linux course right now and its my first script. I look online for help and the code isn't in the order of the assignment. I guess that is throwing me off the most.
if order is throwing you off the most you might want to reconsider your education path. Break everything down in to smaller chunks, accomplish small things together to accomplish great things.
To process a .csv (comma separated values) file, you want to use a `while` loop with `IFS=, read -r `*var1* *var2* *var3* … Use as many variables as there are fields on each line and choose sensible variable names based on what each field contains. Read [this](https://nixshell.wordpress.com/2007/09/26/ifs-internal-field-separator/) and [this](https://bash.cyberciti.biz/guide/While_loop#Reading_A_Text_File_With_Separate_Fields) for more information. Note that putting the `IFS` assignment right before the `read` command makes it last for `read` only. For the 8 requirements listed you're going to need to use the following commands within that loop with the variables populated by your `read` command: `useradd` (for everything except the following two), `passwd` (to set expiry) and `chpasswd` (to set initial password in batch mode). Type `man useradd` etc. and study the information in each command's manual page carefully, down to the letter. Everything you need is in there, you just need to read meticulously. General notes: Be sure to double-quote *all* your variable expansions unless you have some specific reason not to (and you understand what that reason is). If you don't understand something about bash, type `info bash` to look it up in the Bash manual. Also be sure to peruse the links in this subreddit's sidebar. 
You can split it up into two parts. First write a script that creates a single user. Then write a script that reads each line of the CSV and calls the first script with the required arguments. Once you get it working, combine them into a single script.
 #!/bin/bash FloatNum="35.6061" Decimals=${FloatNum##*\.}00 # 00 added in case there are not enough decimal digits Decimals=${Decimals:0:2} FloatNum="${FloatNum%\.*}.${Decimals}" echo "FloatNum&gt;$FloatNum&lt;" # Decimal places trimmed to 2 Prints: FloatNum&gt;35.60&lt;
&gt; When you create a new tmux session, you automatically join it. That means none of your other commands are going to run until after you exit tmux. The only way I see around that is to make an async function call that pulls you out of tmux 1 second after you've entered it `tmux new -d`?
Thanks for going the extra mile with explaining parameters. Just curious if there are any caveats in using `-P$(nproc)`... could there be a chance in locking up other processes if I'm running this script simultaneously with other stuff? EDIT: I think `-i` is deprecated: http://superuser.com/a/132284
I never had issues with using as many CPUs as there are. I just don't know if this "nproc" command might be missing on some machines. Thank you for reporting back about that `-I` (I'll edit the other post).
So the original PNG files could be anywhere? Are the file names guaranteed to be unique? What if there are several foo_bar_0005.png in different directories? You could do something like this. cd $PSD_FOLDER for psd_file in *.psd; do png_file=$(find -name=${psd_file/%.psd/.png} $PNG_ROOT_FOLDER) if [[ $png_file ]]; then mv $psd_file $(dirname $png_file) else echo "png for $psd_file not found" &gt;&amp;2 exit 1 fi done I don't have bash on this computer to test, so there's probably some syntax errors in this snippet, but the principle should work. If your PSD filenames could contain spaces, the script probably must be modified to use a `find` command instead of `psd_file in *.psd`. This special bash syntax `${psd_file/%.psd/.png}` is called "parameter substitution". If `$psd_file` is `foo_bar_0005.psd` then output is `foo_bar_0005.png`
How about find . -name "*.PNG" -type d -exec mv ${$(basename "{}")%.*}.PSD ${{}%/*}/. I don't have access to my Mac now so try it first with an echo before the mv to see if the command is correct.
&gt; If your PSD filenames could contain spaces, the script probably must be modified to use a find command instead of psd_file in *.psd. No, all you need to do is quote your variable expansions and command substitutions properly. mv "$psd_file" "$(dirname "$png_file")"/ 
I used /u/iRobinHood's idea to search for the PNG files and cut the results up into path and file names, then use that to get the PSD file names: #!/bin/bash png_folder="$HOME/t" psd_folder="$HOME/t/PSDs" find "$png_folder" -type f -name '*.png' | while IFS= read -r x; do path=$(dirname "$x") file=$(basename "$x" ".png").psd mv -v "$psd_folder/$file" "$path/$file" done I tried to not use special features. EDIT: changed `read` to `IFS= read`.
okay thanks so for replacing just one line sed -i 's/#fastcgi_pass unix:/var/run/php5-fpm.sock;/fastcgi_pass unix:/var/run/php5-fpm.sock;$ default is what i am now trying although i don't know why it inst working
Now it's the the forward slashes, need to backslash them too sed -i 's/#fastcgi_pass unix:\/var\/run\/php5-fpm.sock;/ fastcgi_pass unix:\/var\/run\/php5-fpm.sock;/' default 
Do this: sed -i '\%^#fastcgi_pass unix:/var/run/php5-fpm.sock;% s/^#//' default Explanation: Your first mistake is trying to use `/` in your patterns. You can't do that because a `/` is also used to mark the "search" and "replace" sections of the `s/search/replace/` command. What you can do is write `\/` for every `/` inside patterns. A neat alternative is that you can use a different character than the `/` in the `s///` command. You can do for example: `s|search|replace|`, or you can do `s%search%replace%`, or any other character. When you do that, you are allowed to use normal `/` inside your search and replace patterns. You don't have to write those annoying `\/`. Another thing you might want to do is not use `s///` to search. You can write sed "programs" that look like this: /address_pattern/ { s/^#// } This first cuts down the work to just the lines where "address_pattern" applies. You can then write a very simple `s/^#//` to cut away the `#` on those lines. You don't have to repeat everything you searched for when doing it like this. You can use a different character than `/` for your "address pattern" by starting with a `\`, for example `\%address_pattern%`
Thank you very much for your explanation and help. That is great to know. It still doesn't work for some reason but i won't hassle you any-more and will look online for other ways. 
It's perhaps a problem with your regex pattern. Those are super annoying to write without mistake. You can experiment with your patterns like this: sed -n '/some search pattern/ p' filename The `-n` parameter makes it so sed will not print anything by default. The `/some search pattern/` is addressing lines, and that `p` is the print command. That's how you can try to build a pattern that will work before later doing your real command that changes the file. Another thing is... check out the program "percol". Your distro might have a package for it. It's a file viewer with a prompt where you can type regex. With each key you hit, it will immediately filter the file. You can then experiment very fast with different rules.
It works for me with this line, not sure what's wrong... #fastcgi_pass unix:/var/run/php5-fpm.sock;
&gt; | while read -r x; do You want `while IFS='' read -r x` there in order to preserve any initial whitespace, such as a filename beginning with a space (not at all an uncommon occurrence on Macs).
I got it. cat {1..10}* &gt; database.txt
Even better: cat {1..10}.txt &gt;database.txt
You could use this [script](https://www.reddit.com/r/bash/comments/3zrdq6/converting_script_into_daemon/cyp6zon).
The problem is just that "hexdump" prints in 16-bit numbers, right? I couldn't find out how to make hexdump print 8-bit numbers, but found out how to have "od" do it. This is what happens when I type "hello" and Ctrl-D into the tool: $ od -t x2 hello 0000000 6568 6c6c 0a6f 0000006 It produces exactly the same output as hexdump when used with the `-t x2` parameter. Here it is with bytes instead of 16-bit output, and you'll see the order is swapped, just like you wanted: $ od -t x1 hello 0000000 68 65 6c 6c 6f 0a 0000006 
I didn't even get all fancy with error handling and all :D but thanks! especially for the parameter substitution explanation, that's really helpful. I posted my final script above!
There's quite a bit of bad practice in there. Run it through [shellcheck.net](http://shellcheck.net) first. Then we can go through the stuff shellcheck doesn't detect/care about afterwards.
fixed it :D, only 2 errors, that don't matter :D
Wow /u/Vaphell, thank you very much. I'll dig through all that and redo my code. For now I'll focus on the getopts part and the functionality between. When I get that working I'll go through it. Thank you again :-) I'll let you know how it goes
thanks :D
I will do the changes . thanks :D
&gt; all the files end in .txt so I tried cat *.txt &gt; database.txt Right? Or am I missing something? 
 oldstring=$(grep -i "$name" "$file" || { echo "grep failed" &amp;&amp; exit 1 ;}) echo $? // 1 //if $name is not found in $file // 0 // if $name is found in $file 
Putting something in parentheses forks a [subshell](http://kaneda.bohater.net/faq/abs-guide/subshells.html). That's a complete clone of the shell in a separate process. This applies to $(command substitution) as well. What you're seeing is that `exit` exits from the subshell and not your main shell. You want to use a block delimited by curly braces instead. Code in such blocks is executed in the main shell. Note they have a slightly different syntax than parentheses as they are "shell reserved words" and not shell grammar. It means the curly braces *must* be be separated with spaces and (if on the same line as a command) a semicolon. oldstring=$(grep -i "$name" "$file") || { echo "grep failure"; exit; } 
Gonna need to see the script.
Make sure there is a stdin even if it's &lt;/dev/null and capture stdout and stderr into a file
Check that the script can run with /bin/dash; Debian and Ubuntu [changed the /bin/sh link to dash](https://wiki.debian.org/Shell) to save on boot/login time. It's quite likely you are using a bashism. I've been bitten with that before; I had some /etc/profile.d scripts that prevented me from logging in with lightdm. Took me forever to make the connection. I believe you can re-link it to bash if you absolutely must (via update-alternatives IIRC). *edit* nevermind, I see you are running the script with `sh`.... try echoing out "HERE" at strategic points in the script and see which line causes it to bomb. try `strace ... 2&gt;&gt;logfile` at the bombing command. Try `set -x; exec 2&gt;&gt;logfile` at the beginning. (just throwin stuff out there)
I had a similar issue which was due to not using absolute paths even when I had changed directory to the script's location.
Thanks for the feedback. I did some further trouble shooting and determined something is wrong with my ~/.config/autostart/loginscript.desktop file. I moved my script into .profile and it worked without any issue. I'd still like to know how to fix the loginscript.desktop file if anyone is interested in helping me. [Desktop Entry] Name=loginScript Exec=/home/andrew/scripts/loginscript.sh Terminal=true Type=Application X-GNOME-Autostart-enabled=true 
Thanks for this idea. I don't understand some of the output yet, but its a nice stating point.
I do have absolute paths, but thanks for the reminder. Always a good tip.
&amp;&gt;&gt; logfile logs StdOut+StdErr
You're a saint. I don't think it was supposed to be solved in any specific way, he just wanted it solved. I tried doing that earlier but I didn't know how to echo the proper words. Thank you so much man.
yup, sorry.. you needed command line arguments both topics are covered in the first link itself.. http://ryanstutorials.net/bash-scripting-tutorial/bash-variables.php
shellcheck in the apt repos is old-ish (0.3.7 vs 0.4.3ish I think is the current version). If you don't mind using cabal, I have code already for that, and at a glance a similar style to you, so you could just copy and paste it. pm me if you're interested :)
ah yep, I was skimming and saw an apt-get install in your commit history for travis.yml
Thanks for the while loop as well. I was just trying to understand the mechanics of what you wrote. What made the for loop work?
The reasons for *not* using a `for` loop in `bash` are good reasons. Word splitting, globbing and losing blank lines. Mostly. But in my view those are simply things to be aware of, not reasons to entirely discount `for` loops. IMHO instead of running away from `for` loops, provided you use them in a way that respects those caveats, they're fine. * Are you in need of spaces in a line in a file that lists hostnames? Not likely. * Are you needing to glob in a file that lists hostnames? Not likely. * Will it matter that the `for` loop skips a blank line in a file that lists hostnames? Not remotely. Now I have known Windows sysadmin chumps who have tried to break these rules, but I don't think you'd find a *nix sysadmin trying to name a server "\n *". Ultimately, provided your input is sane, a `for` loop is perfectly safe. IMHO of course. To be clear: I do advocate for `while` over `for`, I just don't think it's that big a deal provided you're mindful of the gotcha's with each. (`&lt; /dev/null` in my example `while` loop above is a gotcha.) `while` vs `for` isn't worth losing sleep over, and frankly I personally get more annoyed by UUOC. I'm hopeful that one of the subreddit's gurus can provide a *reasonable* justification for me to change my mind.
You do cp ... &amp;&gt; filename If you want to have both output on the screen and in the file, you do this: cp ... |&amp; tee filename I don't know how the output of `cp -v` looks like so no idea how to filter that without an example. Those `&amp;&gt;` and `|&amp;` are short for this here, are about redirecting both normal and error output: cp ... &gt; filename 2&gt;&amp;1 cp ... 2&gt;&amp;1 | tee filename
The global variables are good. The way you use them, they reduce the amount of processing that's done in `$PROMPT_COMMAND`, right? That's a great reason to have them. I like the sourcing and the way you organized features into separate files. About passing arguments to functions in variables, did you know the following about local variables? $ x=red $ echo $x red $ foo() { local x; bar; echo $x; } $ bar() { x=blue; } $ foo blue $ echo $x red $ bar $ echo $x blue What's happening there is, when "bar" is called from within "foo", it changes the local x inside "foo", not the global x. The shell's local variables are not like what's local in C/C++/Java/etc. When you define them in a function, they are more about protecting and overriding an existing name, not about keeping the variable private for your particular function. When you call another function in there, your "local" variables will be visible in that other function's code as well. Browsing your code a little, I don't think local variables would be useful to get rid of some of your global variables, but you know your code best and might see something.
[removed]
Another way to do it: cut -d' ' -f1,2,3 /proc/loadavg
this is where rsync shines.
Use `read`. It's much faster than external commands, very powerful, and not nearly well-known enough. read avg1min avg5min avg10min junk &lt; /proc/loadavg echo $avg1min echo $avg5min echo $avg10min Or to read them all: IFS=' /' read avg1min avg5min avg10min curproc totalproc lastpid &lt; /proc/loadavg For your uptime problem, try: uptime | grep -Eo '[0-9]+ days' 
Good point, but remember to always, always [use `read -r`](https://github.com/koalaman/shellcheck/wiki/SC2162) :)
That is a good point, but a bit overstated. No backslashes ever occur in `/proc/loadavg` so the `-r` is superfluous, though harmless. With something like "please enter your name", a backslash is also hardly going to be an issue. And sometimes, backslash interpretation can be rather handy: it allows for breaking up data units over multiple lines.
Yeah. The `echo` vs `printf` argument is usually overstated, too. It's only really relevant if you care about compatibility between different shells. As long as your hashbang path explicitly references bash (and not `/bin/sh`) there is no real issue.
Yes. In general, you want a script to make no assumptions and provide lots of output. Sometimes a script will read from STDIN, and it will wait until it reads something. If you specify STDIN as a file (even if it's /dev/null), it will not hang because of that. Also - make sure your ENV and PATH is correct. Use absolute (not relative) pathnames. For instance, you can have a script that starts with #!/bin/bash PATH=/usr/bin:/bin:/usr/local/bin: # whatever etc. etc. exit 0; # end of script and then call it with /bin/bash -xv /path/to/script &lt;/dev/null &gt;/tmp/script.$$.out 2&gt;&amp;1 It will write to /tmp/script.&lt;PID&gt;.out with lots of output and capture all error messages. If any error occurs, you can see what happened. 
Look into `rsync`, it's designed just for copying files that are new or changed, and it can also copy across a network.
source=/something/DCIM/ destination=/folder/ rsync -var $source $destination this command does exactly what you want to achieve and better than how you do it (e. g. if a picture, for whatever reason, was not correctly copied, rsync detects it and copies it again). the only thing that is different from cp is the syntax of the source folder. To be precise, the final '/' makes all the difference. using: /something/DCIM/ will copy the things inside DCIM/ into folder/ while: /something/DCIM will CREATE a DCIM subfolder (with all the files) into folder. If you want to copy over the internet, check the 'z' option for compression / decompression of data to save bandwidth. Worth noting that this command WILL NOT delete anything. If you want perfect mirroring, and you want to delete in destination what you have deleted in source, check out the (dangerous) --delete option. 
I think the command is missing the -name or -iname parameter, so find . -name ".Appledouble" -delete If you leave that out you effectively just run find . -delete
The find command line looks like this: find location(s)... rules You did: find . ".AppleDouble" -delete The rule was `-delete`. The ".AppleDouble" was sadly just a second location, was not a rule. Find was finding everything in "." and did not cull that list down to what you wanted. What you can do is first build a `find` command line that just prints all the files you are interested in. When that list looks like what you want, only then you add the `-delete` to the end of the command line. This here might have deleted all files you wanted to murder: find . -path '*/.AppleData/*' -delete Then a second step would have removed the left-over empty folders: find . -name '.AppleData' -delete There's a way to use just one `find` command instead of two, I'm guessing this here: find . \( -path '*/.AppleData/*' -or -name '.AppleData' \) -delete
I understand this, thank you. What if I have a source and destination, but I also have a third temp directory and I want the new files to also get copied there?
In fact, I did. I just mis-read the output... &gt;.&gt;
That sucks, but everyone does it once. :(
Do the setup again from start, as in re-image the SD, and you'll be fine. Nothing else will work at this stage.
&gt; Set up my Raspberry Pi with Raspbian, ran "sudo rm -rf /*". How would I fix it? Fix what? If the command terminated, you’re done. It did exactly as you told it to, so there shouldn’t be anything to fix. 
It would be better to restrict the type only to directories unless you are confident that there are no files or links named .AppleDouble that should not be deleted. Also note that the -delete action only acts upon files, not directories (at least in GNU find, not sure about other variants). One way around this is to use the -exec action like so: find . -type d -name '.AppleDouble' -exec rm -rf {} \; However, if the list of search results is very long, the shell's maximum number of arguments might be exceeded when the rm command is constructed, so the combination of the -print0 action and xargs is better: find . -type d -name '.AppleDouble' -print0 | xargs -0 rm -rf
&gt; find . -type d -name '.AppleDouble' -exec rm -rf {} \; &gt; &gt; However, if the list of search results is very long, the shell's maximum number of arguments might be exceeded when the rm command is constructed No. `-exec … \;` calls the command once for every result. There’s also a variant that’s more efficient: `-exec … {} +`. In this case, `find` will run the command with several results, but it will still watch out that the command line length is below the operating system limit, and call the command multiple times if necessary.
Essentially, I used my Raspberry Pi as a virtual machine in this case. Shouldn't something still be running in RAM?
I don't understand most of this, but I think it answers my question?
It should give you an idea of what is possible if you know as much as a kernel dev guru like Al Viro. 
Sure, if you haven't turned it off yet, the kernel and whatever processes were running are probably still there. Sshd is likely denying logins bacause it can't read /etc/shadow or authorized_keys, and even if you were able to login, it couldn't start /bin/bash or sh because that's gone too.
The idea that it may not "always be there" on a given system is rare these days and doesn't matter for 99% of what you do. 
I've been admining for 15 years at 4 different places. i've never once used bourne. The one old Solaris box I can across that didn't have bash on it? I installed bash and moved along. 
Shouldn’t `shList` be an array? shList=(/bin/bash /usr/bin/bash /usr/xpg4/bin/sh /usr/mbin/ksh /usr/bin/ksh93 /bin/ksh /usr/bin/ksh /bin/posix/sh /usr/bin/sh /sbin/sh) for sh in "${shList[@]}"; do if check_shell "$sh"; then "$sh" "$@" fi done ^/s
I got the joke, but for those who didn't: $ shList=(/bin/bash /usr/bin/bash /usr/xpg4/bin/sh /usr/mbin/ksh /usr/bin/ksh93 /bin/ksh /usr/bin/ksh /bin/posix/sh /usr/bin/sh /sbin/sh) syntax error: `shList=' unexpected $ syntax error: `)' unexpected $ CURSE YOU, BOURNE! We could use `eval` though to emulate an array of sorts... */shudder*
Thanks. I was not really aware of the POSIX improvements. Having real arithmetic in the shell is a big step forward.
Regarding shell arithmetic, just a tip, this little function can really help -- it gives you `let` as in bash, albeit with just a single expression. let() { return "$((!($1)))" } Also note that `++` and `--` aren't POSIX, but everything else (including something like `var+=1`) is. Strange but true.
I'm positive. All the POSIX shells support it, even dash, FreeBSD /bin/sh, et al. It is a relatively recent addition to the standard so the example may not have been updated. In any case a `$` would not even make sense there since that is an arithmetic assignment.
That actually is a brilliant idea! Keep us updated
Your "587724" example turned into what you want is this: $ sed 's/./&amp;00,/g; s/,$//' &lt;&lt;&lt; "587724" 500,800,700,700,200,400 I've saved your config file example as "testfile" to experiment. Here's how you would work with the file with sed and a bash variable `$sequence` with that previous result in it: $ sequence=$(sed 's/./&amp;00,/g; s/,$//' &lt;&lt;&lt; "587724") $ echo $sequence 500,800,700,700,200,400 $ sed -r 's/^(\s*sequence\s*=).*$/\1 '"$sequence"'/' testfile [options] logfile = /var/log/knockd.log [openSSH] sequence = 500,800,700,700,200,400 seq_timeout = 5 tcpflags = syn start_command = /usr/sbin/iptables -I INPUT 1 -s %IP% -p tcp --dport 22 -j ACCEPT cmd_timeout = 10 stop_command = /usr/sbin/iptables -D INPUT 1 -s %IP% -p tcp --dport 22 -j ACCEPT Here I'm just letting it print the file while experimenting. To change the file instead of just printing, you add a parameter `-i` and do `sed -i -r '...' testfile`. I can explain the sed rules I used if you want to know details. EDIT: Changed `[\t ]` into `\s`. EDIT2: Changed `sed -ir` to `sed -i -r`.
Absolute paths are path given from the root of the filesystem (/ if you're *nix machine DRIVE-LETTER: in windows) relative are paths given starting in a certain directory I think. An example would be if you have a file AFILE in a directory ADIR which is in turn in the root folder the relative path from ADIR is /AFILE and the absolute path /ADIR/AFILE.
&gt; relative path from ADIR is /AFILE no, the relative path would just be AFILE. If it starts with a `/`, it’s an absolute path.
https://github.com/64b2b6d12b/otpknock
The first sed "program" that produced the "500,700,..." was this: s/./&amp;00,/g s/,$// You can put that on a single line with a `;`. The sed command used is the "s/search/replace/" command. In the first rule, that "." search pattern means "any character". The "&amp;" part of the replace pattern is special and makes sed insert the search match in that spot. The "00," is just normal text. At the end of the s/// command, there's a "g" flag. That "g" flag makes sed continue working until the end of the line. It normally would stop after the first match and would start looking for the next line. The rule will produce this: 500,800,700,700,200,400, There's a "," at the end of the line and the `s/,$//` rule removes it. That "$" is special and means "end of the line". The command for editing the config file is this: sed -i -r 's/^(\s*sequence\s*=).*$/\1 '"$sequence"'/' testfile If you look closely at the parameter there, it is actually built out of three parts: 's/...' "$sequence" '/' This is something for bash, not for sed. When you have two words that are touching in bash, like this: `'aaa''bbb'`, they will be fused into one word. That parameter for sed is split into three parts so that `'...'` can be used where bash shouldn't look at the text, while still having that `"..."` part where the $sequence bash variable will work. sed will see this parameter: s/^(\s*sequence\s*=).*$/\1 500,800,700,700,200,400/ The search pattern is this: ^(\s*sequence\s*=).*$ * `^` = "beginning of line" * `( )` = marks a part of the search result for later use * `\s` = space or tab character * `*` = repeat the previous character any number of times (can be zero times) * `sequence` = this is normal text * `\s*` = any number of spaces * `=` = this is normal text * `.*` = any character, any number of times * `$` = "end of line" The part that's surrounded by `()` can be recalled through `\1`. This is used in the replacement pattern: \1 500,800,700,700,200,400 sed will put the "sequence =" part of the original line in that `\1` spot. Of note is that the search rule matches the whole line because of the `^` and the `.*$`. Everything from the original line that's not saved in that `\1` will be replaced. The `-r` parameter for sed enables "extended regex". This makes it so you can write `( )` instead of `\( \)`.
Wow.. so much to learn. It seems that the knock client is inconsistent when running the command: `knock 1.2.3.4 500 800 700 700 200 400` but is always consistent if run like: #!/bin/bash knock 1.2.3.4 500 knock 1.2.3.4 800 knock 1.2.3.4 700 knock 1.2.3.4 700 knock 1.2.3.4 200 knock 1.2.3.4 400 How could I setup sed or otherwise to define 500,800 etc as the lines above? Would it be an array?
Absolute path is like a full address--it gives all information needed to find the location from a common "root": `1234 Maple Road, Sunnyville, Georgia, 55475-6678, United States of America` Relative path is relative to a location--you already have an idea of where you are: `1234 Maple Road` We make the assumption you are in Sunnyville, Georgia. 
You can use normal text here, no need for an array. You need text with spaces in it, like this: $ sed 's/./&amp;00 /g; s/ $//' &lt;&lt;&lt; "587724" 500 800 700 700 200 400 You can then script this here: ip="1.2.3.4" otp="587724" sequence=$(sed 's/./&amp;00 /g; s/ $//' &lt;&lt;&lt; "$otp") for port in $sequence; do knock "$ip" "$port" done What happens there is that if you write `$sequence` with intentionally no `"` surrounding it, then bash splits the text apart where the spaces are. The "for" loop then works like you want it to without needing an array.
Yes, that's correct. The `&amp;` is the whole search match. The `\1` is just what was previously marked with `()`. In this example, it is the same as using `&amp;`. The result is actually not 100% the same. The first one has a space character at the end. You'd need to add `;s/ $//` to the first one for things to be exactly the same. See here: $ x=$(sed 's/\(.\)/\100 /g' &lt;&lt;&lt; "587724"); echo "&lt;$x&gt;" &lt;500 800 700 700 200 400 &gt; $ x=$(sed 's/./&amp;00 /g; s/ $//' &lt;&lt;&lt; "587724"); echo "&lt;$x&gt;" &lt;500 800 700 700 200 400&gt; These two rules are what's the same between the first and second one: s/\(.\)/\100 /g s/./&amp;00 /g Another thing you might want to know about `()`, if you use it more than once in the search pattern, what you marked with the different `()` will be put into `\1`, `\2`, `\3`, etc.
Have you read https://support.google.com/mail/answer/81126 ? If you are on a dedicated IP and recently overtook that one, maybe it was flagged as a spammer before you owned it. Otherwise I'd check very carefully, because that seems to indicate that some process is sending out tons of emails from your server. If you are on a shared server, I'm afraid there might not be much you can do. It could be any of the other tenants that got your IP flagged at Gmail.
That works a treat, thanks!
Legit arrays. Wordsplitting is a disaster. Process substitution &lt;() 
You'll often see this with relative paths: ../../somefile.txt That's a relative path. It means go up 2 directories ( `..` means go up one directory) from where you are and the file is there. An absolute path would be: /home/derp/somefile.txt
Most email providers stopped accepting email sent directly from dynamically allocated residential IP addresses many years ago. Configure sendmail to route your outgoing email through your ISP's SMTP server.
&gt; As an aside - anyone able to take a look at my script and offer suggestions? I don't like the use of "sudo" on all of those lines. I'd be afraid that it might ask a second time for a password when it takes long enough to work through the whole backup. You can remove all current uses of sudo and instead put this at the beginning of your script: #!/bin/bash [[ $UID = 0 ]] || exec sudo "$0" This checks to see if the current user is root. If it's not root, the script restarts itself through sudo. &gt; Question: How can I get these all on one line? So you have a lot of lines that are very similar and you find this annoying to manage. There's ways to remove the repetition with the programming language features that bash has, or perhaps through using "xargs", or just changing some of the command lines. Often, you can change how you use commands. You could do this to collect multiple du command lines into a single command line: du -hs \ "/home/" \ "/media/Home Movies/" \ "/media/Pictures/" \ "/media/Youtube Videos/" \ "/opt/" \ "/var/www/" You could also save that du command into a variable, and use that variable instead of du: ducmd="du -hs" $ducmd "/home/" \ "/media/Home Movies/" \ ... You can now change the $ducmd variable and all du commands in your file would change automatically. You can't use a variable like that for your rsync command line. The problem there is the $EXCLUDEFILE variable where you'll want it surrounded by `"` so that it can deal with any filename. That previous $ducmd variable can't do that. For your rsync command line, you would use a function instead of a variable: rsynccmd() { rsync --archive --verbose --human-readable --progress \ --delete --itemize-changes --delete-excluded \ --exclude-from="$EXCLUDEFILE" \ "$@" } You can now replace rsync with rsynccmd in those six lines you have: rsynccmd "/home/" "$BACKUPLOC/home" rsynccmd "/media/Pictures/" "$BACKUPLOC/Pictures/" ... There's another approach: To get that rsync command onto one single line, you could put the parameters that change from line to line into arrays and then use a loop to build the different lines: sources=( "/home/" "/media/Home Movies/" "/media/Pictures/" "/media/Youtube Videos/" "/opt/" "/var/www" ) backups=( "$BACKUPLOC/home/" "$BACKUPLOC/Home Movies/" "$BACKUPLOC/Pictures/" "$BACKUPLOC/Youtube Videos/" "$BACKUPLOC/opt" "$BACKUPLOC/var/www" ) for index in "${!sources[@]}"; do rsync --archive --verbose --human-readable --progress \ --delete --itemize-changes --delete-excluded \ --exclude-from="$EXCLUDEFILE" \ "${sources[index]}" "${backups[index]}" done You could then also use those arrays when you call du: echo "originals:" du -hs "${sources[@]}" echo echo "backups:" du -hs "${backups[@]}" du -chs "$BACKUPLOC" You could also mix both methods. You could collect your du and rsync calls into functions or variables, and you could also use those arrays to collect all parameters into one place. That might be neat.
Wow! What a great answer. Sorry, I'm just impressed by your comment, mixing that much code markup with that much editorial commenting isn't easy, even with Reddit's Markdown interpreter. Thanks for the helpful advice.
A relative path is a path that is RELATIVE to where you are right now. IE it may only be valid if you are in the right directory. ../ refers to the folder on up from your current directory. This is a relative path. An absolute path will resolve no matter what your current directiory. /bin refers to the bin folder in the root of the file system. This is an absolute path.
Is it this one? http://showterm.io/
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/commandline] [Mella – ownCloud upload in bash • x-post \/r\/bash](https://np.reddit.com/r/commandline/comments/4ahmbh/mella_owncloud_upload_in_bash_xpost_rbash/) - [/r/linuxadmin] [Mella – ownCloud upload in bash • x-post \/r\/bash](https://np.reddit.com/r/linuxadmin/comments/4ahn3t/mella_owncloud_upload_in_bash_xpost_rbash/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
This doesn’t seem to be relevant to Bash at all, so I’ve removed it. If I’m wrong, please explain…
There is a WebDAV filesystem that allows you to mount an OwnCloud and use regular file commands on it. We use here at the company I work for. in Debian just do apt-get install davfs2 man mount.davfs 
I am aware of this, I just wanted a way to upload compressed database dumps via cronjob from several servers at defined intervals without having to install any additional packages. But using it your way is definitely a viable alternative.
You're right. Just using `scp` or `rsync` and then rescanning the user's files is another good solution.
Yes - /u/ropid gave some great advice with explanations - must be a teacher. ;)
Depending on how many files you have, running occ to rescan the whole thing could take a while. If the files need to be available all the time from the OwnCloud web interface or WebDAV, it might not be an option.
The second part of the script is checking if the amount of parameters ($#) is not 1, which means there are either 0 or more (2+). In this case, you would want to throw an error and show the user that his syntax was wrong.
Like what it says, it checks for the available parameters. If there are more/less than 1 parameter, say "usage: $0 &lt;/tmp/smartlog&gt;" and exit. Try running the script with 0 parameters and you'll see what it does.
 if [[ the number of arguments passed to the script doesn't equal 1 ]] then print to the screen "usage: name_of_script_you're_running &lt;example of argument to pass to script&gt;" exit with error fi logfile=&lt;argument passed to script&gt;
/u/qalk &amp; /u/timmy_tofu 's answers both worked perfectly. teeing into /dev/tty does the trick!
You didn't say whether you were asking for a review, applause, etc. Here's what I would do in a manner close to your format: declare web ip scan read -rp "Enter Website: " web ip=$( dig +short "$web" | head -n 1 ) if [[ ! -z "$ip" ]]; then curl "ipinfo.io/$ip" 2&gt;/dev/null \ | column -ts : 2&gt;/dev/null \ | sed 's/[{"]//g;s/,$//g' echo read -n1 -rp "nmap $ip/24? [y/N] " scan [[ 'y' == "$scan" ]] &amp;&amp; \ nmap -vv -FoG - "$ip/24" | awk '/Up/ {print $0}' fi unset web ip scan 
Give the info pages a look, you'll find all kinds of useful commands you never knew about. Type the command `info coreutils.info` to see the info pages on the GNU Coreutils software suite. Check out chapters 3 through 8: * Output of entire files:: `cat`, `tac`, `nl`, `od`, `base64` * Formatting file contents:: `fmt`, `pr`, `fold` * Summarizing files:: `wc`, `sum`, `cksum`, `md5sum`, `sha1sum`, `sha2` * Operating on sorted files:: `sort`, `shuf`, `uniq`, `comm`, `ptx`, `tsort` * Operating on fields:: `cut`, `paste`, `join` * Operating on characters:: `tr`, `expand`, `unexpand` 
Any files that running programs have open can be accessed via `/proc/${process_id}/fd/`. From there you can re-link anything that's open. If nothing is writing to the SD card, you may be able to use `extundelete` to restore a majority of files. As long as nothing has done a write that caused a block to get re-used. There's a similar utility whose name is escaping me for recovering the files in `/boot`, which (on the rPi) lives on a FAT partition.
There’s also `rev`, which has the unfortunate effect that I can never remember which one is which. One reverses by line (abc → cba), one prints lines in reverse (a, b, c → c, b, a).
What shell are you using? Or perhaps what kernel are you using? Linux pipes don't duplicate information for multiple readers--once one reader reads it, no others can (I believe all *NIX pipes work this way, but I'm not 100% on that). That means that if you want tee-like behavior, you need a process in there duplicating the data. Bash doesn't do this. Edit: you're running zsh, aren't you? Zsh does (helpfully) automatically do `tee` in your pipelines. However, zsh redirection is only Bourne-shell like for the very simple cases.
Thanks, I fixed it.
Syntax looks fine. How are you running the script?
I have saved it as script.bash and I run it in command line as run script.bash however now I get this error message run FATAL: Could not start C:\cygwin\home\mary\script.bash 
I’ve never heard of a `run` command, and it doesn’t exist on my Linux system, so I strongly suspect that it’s a Windows thing, which almost certainly doesn’t understand Unix-style scripts. The Unix/Cygwin way to run your script would be: ./script.bash It needs to be executable, too, so run this first: chmod +x script.bash
 lsblk -o UUID /dev/sdc1 | tail -n1
just to add another piece in, if you write the script in notepad++ before running, you may also need to run: dos2unix filename on your script as well to clear empty lines. Though in the real world that doesn't exist every, so I would learn the sed command replacement as well sed -i 's/\r//'
You sir are a gentleman and a scholar. That was exactly the problem. Last time I use Textedit to try and write a bash script. Thank you so much!
awk and sed are the most helpful tools. I would use something like: sudo blkid | awk '/&lt;drive&gt;/ {print $2}' ex. sudo blkid | awk '/sde/ {print $2}'
&gt; with a grep piped to another grep some_cmmand | awk '/something/ &amp;&amp; /something_else/ &amp;&amp; !/but_not_this/ {print}'
If you want to be extra terse, you can also do: some_cmmand | awk '/something/ &amp;&amp; /something_else/ &amp;&amp; !/but_not_this/' since a missing action is equivalent to `{ print }`.
I deal with boxes everyday that don't have dos2unix, I wish I could add it, but nope....
This is an instance where you could reinvent it in a limited sense as a bash function: if ! command -v dos2unix &amp;&gt;/dev/null; then dos2unix() { # get started here, hint: tr -d '\015' } fi
You need to escape spaces in a comparison.
Or just quote all the things. 
But not the globs: $ [[ "foo AMD FX bar" == "*AMD FX*" ]] || echo no no $ [[ "foo AMD FX bar" == *"AMD FX"* ]] &amp;&amp; echo yes yes And in a regex comparison, you can't quote the regex specific things: $ [[ "foo AMD FX bar" =~ ".*AMD" ]] || echo no no $ [[ "foo AMD FX bar" =~ .*"AMD" ]] &amp;&amp; echo yes yes 
For that you probably want to use `egrep` e.g. if egrep 'AMD FX|AMD Athlon' /proc/cpuinfo &amp;&gt;/dev/null; then With `egrep` used this way, you can keep adding potential matches just separated by the pipe symbol.
What Gredenis said. If you run `command -v grep`, for example, it will tell you where `grep` is or how it's aliased: $ command -v grep alias grep='grep --color=auto' But if you're testing the existence of `grep`, you don't want that output, you just want to know whether it's true that `grep` exists in some form. So you redirect the output of your test to `/dev/null`, where `/dev/null` is the bitbucket in the sky. $ command -v grep &amp;&gt;/dev/null $ echo $? 0 So you can wrap that up as `if command -v grep &amp;&gt;/dev/null; then`, which is ultimately a way of saying `if true; then` `&amp;&gt;` is a bashism. To write this a bit more portably, you would type it like: `&gt; /dev/null 2&gt;&amp;1` 
Okay thanks I highly appreciate the help and hereby offer you reddit gold for your kindness in helping a person in need.Seriously this thing bugged me for at least 1 day and to see you fix it within 2 hours is amazing to say the least.
Wait I have one final question to you dude.Say I want to run this other script below: &gt;if [[ $(sudo lshw -c video) = ****AMD Radeon R9 290|AMD Radeon R9 290X**** ]]; then &gt;echo "# This enables Experimental Sea Islands support for AMDGPU driver. &gt;options amdgpu.exp_hw_support=1 &gt;options amdgpu.powerplay=1" &gt;&gt; /etc/modprobe.d/amdgpuCI.conf &gt;fi How do you suggest to make it work properly? I know from the rest of the comments here that spaces aren't allowed in a comparison but I'm wondering if there was a way to make it work.I'm also wondering if the pipe symbol is allowed in a comparison? 
This. Also, OP left out the real third type of heredocs: &lt;&lt; "EOF" Literal content heredoc Does not perform substitution so $500 wouldn't get expanded to the value of the variable "500" etc. EOF 
Okay good but now I'm run into another stumbling block like say I want to add another character to the if command like "AMD Radeon R9 290" how do I go about going so? Edit:Here is the script I'm working on now for more info: &gt;if [[ $(sudo lshw -c video) = ****Radeon\ R9\ 290*****,******Radeon\ R9\ 290X**** ]]; then &gt;echo &gt;"# This enables Experimental Sea Islands support for AMDGPU driver. &gt;options amdgpu.exp_hw_support=1 &gt;options amdgpu.powerplay=1" &gt;&gt; /etc/modprobe.d/amdgpuCI.conf &gt;fi
You should reuse the format whetu gave: if lshw -c video | egrep -q '(Radeon R9 290|Radeon R9 290X)'; then By the way, the string `Radeon R9 290` is a substring of the other string you are looking for `Radeon R9 290X`, so it doesn't make sense to look for both of them. And, using your example, inside a `[[` comparison with `=~`, extended regex are allowed as well: if [[ "$(lshw -c video)" =~ (Radeon\ R9\ 290|Radeon\ R9\ 290X) ]]; then 
As a wild guess it looks like your version of echo is printing arguments on separate lines. Try adding quotes: echo "$file"
That seems like an odd thing to do, but the filename of the current script is `$0`, so `rm "$0"`.
TIL about `mv -t`. In this form, you could also terminate the `find -exec` with `+` instead of `\;`, so `find` will aggregate files and not spawn quite as many processes.
You should really use `-q` instead of discarding the output.
Many different ways to skin a cat. I use `/dev/null` for style consistency. When using `if` like this, it isn't always with a command that has `-q` or similar.
About the error, you single-quoted `echo $line` so it will literally try to multiply 'echo $line' by -1. Your script will only read 1 line. To read everything on stdin use `while read line; do`. Instead of checking if the value is under 0 and multiplying it by -1 (which is quite expensive in bash, better use awk for math), you could delete the minus character. `seq -10 10 | tr -d -`
Thank you, i added in the while on my read line and that seemed to do the trick. As far as the formatting, would there be a way to get all the numbers to output on one line?
I would do this by collecting the words into a variable instead of printing them immediately, then printing that variable at the end. It would look like this: while read -r line; do output="" for x in $line; do if [[ $x -lt 0 ]]; then output="$output $((-x))" else output="$output $x" fi done echo "${output# }" done That strange `${output# }` cuts away a space character at the front.
Really, which OS? I live primarily in Red Hat world but the occasional Debain/Ubuntu. 
I'm using Arch right now and I don't have the package installed. I would have to explicitly install it as it's not a dependency of anything else. Looking around, it seems the packages in the repos that depend on it might be a bit obscure. If that's right, the chance that it doesn't exist on a typical Arch installation should be high.
Hacked something simple http://imgur.com/YRaO3I5 Change 'test' to your filename 
You don’t really need `xargs` here, you can do this in a loop: for file in /project/**/*.txt; do { printf '[\n' while read -r line; do printf " '%s',\n" "$line" done printf ']\n' } &lt; "$file" &gt; "${file/.txt/.json}" done
Pasted code as a screen shot on imgur? That's a first. Also not accounting for escaping quote chars
Are you talking about text editor in general? VIM has looked interesting so far, but I've only been using Linux as my main OS for a few months, and only recently have gotten into coding/scripting. I really like nano for its simplicity, and gedit for visual representation. Overall though, I feel Kate (I run Kubuntu) is the most well-rounded. It is very advanced and simple to use. I love it.
thanks! such a simple answer! doh
FYI you can yank all content from vim to the `clipboard` clipboard: ggVG"+y
Note that `mapfile` usually needs `-t` or each array element will have a newline at the end.
Putting 4 spaces in front would also be nice. I'm not sure how to do that with yanking, but you could use a filter and xsel: :%!tee &gt;(sed 's/^/ /' | xsel -i)
Haha I was really tired and didnt want to mess with reddit's formatting! 
Does your .sh file start with the bash header?
While this works in Bash, you should be aware that it won’t select all items equally likely. For example, suppose you have an array with three elements, and `$RANDOM` is one of 0, 1, 2, or 3, each equally likely. Then the first element has two chances of being selected (0 and 3) while the second and third element have only one chance. That is, the probabilities are distributed .5 .25 .25 instead of .33… .33… .33….
find . -type f -exec chmod 644 {} + Then find . -type d -exec chmod 755 {} +
thanks this worked
 find . -type d -exec chmod $permdirs \{} \; find . -type f -exec chmod $permfiles \{} \; Also, if you need correct owner on links: find -type l -exec chown -h user.group \{} \; 
can you explain what the {} + at the end is for?
It doesn't matter now, and might not have helped you while you were battling with restoring the data, but if you don't know: You can copy while preserving owner and modes and date etc. by using `cp -a` instead of `cp -r` for whole folders, or using `cp --preserve=all` for files.
You can also combine them into a single find command. find dir -type f -exec chmod 664 {} + -o -type d -exec echo chmod 755 {} +
the `{}` is like a placeholder - find replaces it with the name of each match found by find. $ touch a b c $ find -type f -exec echo I found: {} \; I found: ./a I found: ./b I found: ./c The `-exec` of find can be terminated with either `;` or `+` (although with `;` it needs to be escaped to stop the shell from interpreting it) $ find -type f -exec echo I found: {} + I found: ./a ./b ./c With `;` whatever you `-exec` is executed once per result found. With `+` it passes as many arguments as possible per execution. (the limit is called `ARG_MAX`). So if you do not need one execution per result using `+` will be more efficient due to the less number of executions needed.
Yes. If you are a vim user you might actually find it useful.
 find /home/user -type d chmod u+x '{}' \; chmod -R go+rX /home/user That's one way to skin the cat. The chmod command is useful in other contexts as well, which is why I use it here instead of just the more complicated find.
It works fine for me.
 if id $userName &gt;/dev/null then echo "User exists" Get that `then` out of there, and quote the userName variable. It's probably not necessary here, but you should get into the habit of using `-r` for `read` You'll want to add exit codes to your `exit`'s e.g. exit 0 That's good exit 1 That's bad. Google exit codes for more. Finally, run the script with `-x` e.g. `bash -x yourscriptname` and see if that gives you anything useful.
Having the two functions call each other is not a good idea. As it is now, if you run it long enough, it will either hit the FUNCNEST limit (if set), or eventually cause a segfault. One way to fix it is to have anotherUser just return success (0) or failure (&gt;0) depending on whether the user hit y or not. anotherUser() { local answer read -rp "Add another user [y/n]? " answer &amp;&amp; [[ $answer = [yY] ]] } Now in your infinite while loop, you can run `anotherUser || break` to break out of the loop if user answers something other than y.
I keep getting a line 17 error with the else command, what have I done wrong?
Exact error message would help. I don't see any obvious syntax errors in the code, so make sure the problem is not due to "invisible" characters, such as CRs. Run: sed -n l yourscript If that sed ends the lines with `\r$` instead of just `$`, then that's the problem. See [BashFAQ 52](http://mywiki.wooledge.org/BashFAQ/052) on how to fix it.
What's the current code you're using?
Go to a bookstore and get The Linux Command line. It's a starch press book. Check it out on Amazon. There's a reason it's highly rated. I read it cover to cover and it vastly improved my command line skills. It will take you from complete noob to being very very comfortable with just a shell.
Use codeacademy
Yes, bash is a language. A cryptic, powerful, unforgiving and dangerous language perhaps, but a language nonetheless. Bash is the standard interface for interacting with a computer directly through a terminal instead of a GUI. If this is what you want to do then learn bash. Bash can be used to write sophisticated computer programs, but this is now what the language is optimized for. If you want to learn to write complex computer programs then Python may be a better choice.
Yes.
I started an account a few days ago to learn Python but from what i've read bash is a language in itself. Unfortunately i didn't see a lesson on bash scripting. Or am i missing something?
Oh haha maybe I wasn't clear - I'm ok with getting and handling the OS - I'm just not sure how to clip to keyboard in every operating system. Most examples I see all use `xclip`, which is not native to Linux or OSX
I'm using linux fedora VM could this be a factor in why it doesn't work? Writing the script http://i1081.photobucket.com/albums/j360/p1ranhaCOD/Screen%20Shot%202016-03-23%20at%2018.04.56_zpsgsvipi6z.png Error messages http://i1081.photobucket.com/albums/j360/p1ranhaCOD/Screen%20Shot%202016-03-23%20at%2018.03.39_zpszbphgzus.png
You need to learn the cli first, which means all the little command line programs out there. Pretty much any command which was installed by a package with the string "utils" in the title (coreutils, findutils, etc.). You need to know how to use all of those. Shell scripting is separate.
It has many quirks and you do have to go through a lot of contortions occasionally but some things are best in shell and others in something more modern, like python. Almost always with shell scripting you would be using some external command where in python you would use some library ("egg"). One can accomplish pretty much anything in either, but large projects, or projects which require a sophisticated user interface are very, very cumbersome in bash. And you don't want to run sh CGI's in a web browser as you would with python, ruby, et.al. Bash is still an excellent thing to know as most sysadminly things really should be done in it. The upside is that shell programs are very low maintenance and will last forever. Shell scripts written in 1995 will still work fine today, same cannot be said of python, perl, ruby, etc. Libraries get obsoleted very quickly with those languages. There's also the point that shell and unix are tightly intertwined, knowing one means knowing the other. You can't know linux or unix without knowing a shell very well. *sh* is the user interface for UNIX and naturally, that is a programming language.
On line 5 you didn't write `then`.
And neither on line 14 (missing `then`).
http://i1081.photobucket.com/albums/j360/p1ranhaCOD/Screen%20Shot%202016-03-23%20at%2018.41.10_zpsyssfj8b3.png I have changed adduser to echo adduser. Could it have something to do with anotherUser? 
They're completely different worlds. Learn both at the same time :-)
In OP's use case you're much better of doing a little feature testing instead. if command -v pbcopy &amp;&amp; command -v pbpaste; then # Mac OS X clip_in() { pbcopy } clip_out() { pbpaste } elif command -v xclip; then # X11/xclipboard clip_in() { xclip -in } clip_out() { xclip -out } # insert more elifs for other operating systems here else echo "no clipboard command found" 1&gt;&amp;2 fi &gt;/dev/null 
The error is because of `if id "$userName" &gt;/dev/null then` you need either a semicolon before then or you need to put then on its own line. e.g. `if id "$userName" &gt;/dev/null; then` When you fix that you will then run into another error regarding `[y/n]` but /u/ropid has shown you how to fix that. Posting code as an image makes it more difficult to help you - especially in an editor with line numbers disabled (you can use `:set nu` to enable them in vim). Consider posting your code in your post or using a pastebin next time.
Ok, thanks for the feedback. I made the corrections which you have suggests but when I run the script. When I run the script it only asks me to Enter user and it identifies there is no user called 'liam' and it generates it but, the there is no mention about assign the user to a group. 
echo $(cat /proc/cmdline | cut -d " " -f 2 | cut -d = -f 3) will give you the UUID of your root drive/partition. I already had that snippet i made inside one of my scripts. Should work but will only get you your roots UUID, as /proc/cmdline only lists UUID of the root. however i formatted it nicely (Just the UUID nothing else)
Well you have code that asks for a username - do the same thing but ask for a group. Then either add the user to the group when creating the user - or do it afterwards using `gpasswd -a` or `usermod` or something.
i3 is a tiling window manager. It gives you a taskbar and decides how Windows are positioned on the screen. Other popular desktops are gnome, xfwm, openbox, or bspwm. I guess I should have said i3-wm instead of just i3. Bash scripting is a tool, but you need something to make with it. Check out /r/unixporn to see what all you can do. 
I have quoted the variable "$username". Where could I include man useradd and -g and -G I changed the code but i'm not sure where to put these commands above and the current shell script doesn't successly create the user but does run. #!/usr/bin/env bash anotherUser() { read -p "Add another user? [y/n] yn" if [[ $yn = *[yY]* ]]; then checkUser fi exit } checkUser() { while : do read -p "Enter user: " userName read -s -p "Enter password : " userPass if id "$userName" &gt;/dev/null; then echo "User exists" anotherUser else echo adduser "$userName" printf "User %s has been added\n" "$userName" exit fi done } checkUser
Start with if then else, then case statements, the while and until loops If you are a sysadmin this will be 50% of your toolbox
This is a great book! This is how I got started writing bash scripts that weren't terrible.
 sleep 1 echo 1 sleep 2 echo 2 sleep 3 echo 3 sleep 4 echo 4 sleep 5 echo 5 sleep 6 echo 6 sleep 7 echo 7 sleep 8 echo 8 sleep 9 echo 9 sleep 10 echo 10 a kind of dumb way :)
 for i in {0..10} do echo $i sleep 1 done
Like from 10 to 0? You could do a for loop: for i in {10,9,8,7,6,5,4,3,2,1} ; do echo $i ; sleep 1 ; done You could stuff it in a while loop: While [ ! ping -c Google.com] ; do for i in {10,9,8,7,6,5,4,3,2,1} ; do echo $i sleep 1 done Done
Maybe make an IF statement with i=1; i&lt;10;i++ and echo out the sleep count then sleep for 1 second
Here's a quick while loop to sleep 10 seconds and echo out a period each second: # Testing - echo the start time echo "Start: $(date)" # Initiate a counter var count=0 duration=10 # Start the output (-n means "no linebreak") echo -n "Sleeping for ${duration} seconds" # Loop until $count isn't less than $duration while [ $count -lt $duration ]; do echo -n '.' # Increment the counter ((count++)) sleep 1 done # Complete the output with a newline echo "" # Testing - echo the end time echo "End: $(date)" Here's the output: $ bash testtime.sh Start: Wed Mar 23 21:17:40 PDT 2016 Sleeping for 10 seconds.......... End: Wed Mar 23 21:17:50 PDT 2016 It's fairly easy to turn this around and have it count down from 10 instead, echoing the counter for remaining seconds. I'll leave that to you to figure out! As a seperate note, your check for $? is seeing the result of the previously run command, which in this case is echo, which will always be true. 
Hey, thanks for the help I really appreciate this. When I run the script it works but when I go to to see if the user has been created on my system it doesn't work. 
I completed the course yesterday. It was pretty easy to pick up with the way they have the program set up but unfortunately there isn't an advanced learning program from them on learning all the commands. Is there an alternative to Code Academy that can teach me more advanced stuff because i really like the way they layed it out.
Some comments on this. 1. Don't run bash scripts with sh. 1. Don't use uppercase variable names for internal purposes. 1. Use a C-style for-loop rather than relying on a non-standard command like `seq`. 1. Use `$(...)` rather than `` `...` `` for command substitution 1. Instead of running `date +%s` and doing math with it to to see how many seconds have passed, just use bash's special `SECONDS` variable. There's no point in using awk either, since bash can do integer arithmetics just fine.
Don't let your blog software change quotes to book-style UTF8, e.g. `date=”$(date +’%r’)”` 
Or you could use `ab`…
After Bash and Python, you might also want to learn C. Much of free software, Bash, and Python is written in C. C is also good to know because it forces you to work close to the hardware of a computer so you learn more about how your machine works.
Well you got the saving to a variable part correct with `$()` - however this saves the whole line and not just the number. There are a few ways to achieve that - one option could be to use `read` e.g. $ /sbin/sysctl vm.hugetlb_shm_group vm.hugetlb_shm_group = 0 $ read _ _ value &lt; &lt;(/sbin/sysctl vm.hugetlb_shm_group) $ echo "$value" 0 (The `_` here is just a placeholder name for the first 2 values as we don't need them) If you want to compare it you can use the following: if [[ $value = 0 ]] then echo "correct configuration" else echo "incorrect configuration" fi There is also **Parameter Expansion**. If you want to strip everything up to the final space in a line: $ output=$(/sbin/sysctl vm.hugetlb_shm_group) $ echo "$output" vm.hugetlb_shm_group = 0 $ echo "${output##* }" 0
Which distro and version are you on? 
Nevermind, i am seeking alternative solutions :)
Use a csv parser.
Would the csv module in Python work?
I think so. 
I'm planning to buy a Razer blade stealth. As far as I've researched, everything works on Linux except the flashy lights for which I need to install synapse. Is synapse working and is it stable?
 sed -r ':open;s/\"/-uniq_flag-/;t close;s/\n//g;s/-uniq_flag-/\"/g;n;bopen;:close;s/\"/-uniq_flag-/;t open;N;bclose' &lt; file.csv Assuming paired quotes I think this funky one liner should work. 
I would use sed for this: sysctl vm.hugetlb_shm_group 2&gt;&amp;1 | sed -n '/0$/q;q1' This will enable it to run in an `if`-statement: if sysctl vm.hugetlb_shm_group 2&gt;&amp;1 | sed -n '/0$/q;q1'; then echo "Correct configuration" else echo "Incorrect configuration" fi How it works: ------------- `-n` disables the auto print, for each line of input /0$/ # Match 0 at the end of the string q; # Quit with successful status code q1 # Quit with error status code Why redirect `stderr` to `stdout` on `sysctl`: ---------------------------------------------- sed works on lines of data, and will invoke its commands for each line of data it gets. But if no lines are send, then no command will be ran. Usually this is what you want, but because we are relaying on sed to exit falsy we need the commands to run once. Redirection `stderr` to `stdout` will archive this
This here works: sed -r ':loop; /^((("[^"]*")*|[^",]*)(,|$))*$/ ! { N; s/\n/ /; b loop }' It replaces the newline with a space. The script checks for lines built out of elements like these here: , "", abc def, "abc, def", "abc ""def"" ghi", (or the end-of-line instead of a comma) If a line doesn't fit the rule, it adds the next line to the current line and tries again.
You should take a look at how [oh-my-zsh does it](https://github.com/robbyrussell/oh-my-zsh/blob/57c2ac1e605c8cc3922c46109b8b65361e05acef/lib/clipboard.zsh).
&gt; theVar="$(sysctl vm.hugetlb_shm_group | awk -F "= " '{print $2})" You're missing the closing `'` in `'{ print $2 }'`
Thanks for the tips; ill try working on how you told me. Useful to know some of the extra syntax to find i didn't know it could be used with the -exec switch to run stat. Now i have alot of fun different things to try
Well what would I do then? I did type in a different terminal prior to determine if it was a bash builtin or not because I thought if it's not a bash builtin you have to use the full path. Or command substitution or a work around. in some cases I got a response that the file was hashed which. I know means it'd work for me without using the full path but I wasn't sure if it'd work for others as its only hashed for me I believe the bash builtin it's talking about the bash builtin "hash" . Anyways your saying I can run external commands without specifying full paths? I.e. grep?
Yes, you can use just "grep". It searches for the program in the directories mentioned in $PATH. That $PATH variable looks different and stripped of most entries when something runs as a service, but I think "/usr/bin" is always in there and "grep" will always work.
Alright thank you that makes things a lot less complicated for me. For some reason with all the random assortment of books I had been reading I had thought only bash builtin could be used and $PATH wasn't mentioned in the scripting books however I obviously know about path in regards to linux
Found a solution, this is much faster: __stoppedjobs(){ hasjobs=$(jobs -p) printf "${hasjobs:+\j}" }
couldn't you just leave the first case out, should have the same effect as printing an empty string, right?
I'd do something like this: PROMPT_COMMAND='_jobs=$(jobs -sp)' PS1='${_jobs:+(\j) }\w\$ '
"head -2 filename | tail -1" Prints only second line from file. Maybe you can use it?
why not just do a while loop and read in each line? cat tests.txt | while read test; do do stuff with $test done
You can add an `os.remove()` just before the `del` line at the end e.g. os.remove(file_to_delete) del listing[file_to_delete] Please have a backup before testing it on real data :-) 
Your information is mostly correct, but there are probably a few things worth noting. It's probably easiest to simply recognize the basic syntax for the command, i.e. `cd [destination]`. This covers `/`, `/etc`, and `/literally/any/other/path`. It's also worth noting that the placeholders `~` and `..` are not specific to cd, and can be used anywhere in bash. And while you're discussing those, `-` is also a good one to know, as it references your most recently visited directory (good for when you're flipping back and forth between locations). *Edit:* Seconding /u/tthatfreak's comment: there's a significant difference between a parent directory and a user's home directory.
 cd /etc This command changes directory to the directory specified after the slash “/ “ but in the tree structure it brings the user back to /. I don't quite get what you mean by "in the tree structure". It made sense until the "but" cd ~ This takes you to the HOME directory. Parent directory means one folder up from where you are. The rest look good if you understand what they mean :).
Paths that start with a `/` are "absolute paths", referencing a specific location within the directory structure. `~` is a special character that expands the contents of the variable `$HOME`(try `echo ~` and `echo $HOME`, and then `export HOME=/some/other/path`, then `echo ~` again.) `..` is a file that is a hard link\* to the parent directory. `.` is a file that is a hard link\* to the current directory; therefore paths that start `./some/path`are not absolute paths, but relative paths from your current location. An absolute path is the same regardless of where you are in the directory structure. A relative path will change, because it is relative to where you are. \* A hard link is a filename that references the inode of another file within the same filesystem.
What I mean by the tree structure is this. http://i1081.photobucket.com/albums/j360/p1ranhaCOD/Screen%20Shot%202016-03-28%20at%2016.00.07_zpscbot38ih.png Do you understand what I mean now, i'm referring to cd /etc Thanks for the help. 
Thank you for your reply. How can I end this loops then? cat nosetestlist.txt | while read test; do S3TEST_CONF=s3.conf ./virtualenv/bin/nosetests $nosetestlist -v 2&gt;&amp;1 | tee output.csv done
The loop runs once for each line in that 'nosetestlist.txt' file. It puts each line into the variable named 'test', so you'd use it as '$test' in your command line, not '$nosetestlist' like you try to do there.
Close on many things. Here is further clarification: --- The slash is part of the folder path. For example: /etc/bin/temp - refers to a folder in the root called "etc" and etc/bin/temp - refers to a folder in the current directory called "etc" --- cd / will take you to the root no matter where you are: &gt;cd /home/john/pictures &gt;pwd / home/john/pictures &gt;cd / &gt;pwd / ^^^ anything with "&gt;" is user input. --- Got it?
this is a better explanation but I think the mention of links is going to through him for a loop.
Yes I understand everything apart from the cd /etc. This command changes directory to the directory specified after the slash '/' refers to a folder in the root called 'etc'. If the linux user was inside /etc folder, typing cd / would bring the user to the root. I still really don't understand the function of cd /etc If the above is incorrect could you correct it in your words then maybe i'll understand that way, have you got any good links which describe the definition?
The first comment put it best: --- It's probably easiest to simply recognize the basic syntax for the command, i.e. `cd [destination]` --- cd [destination] [destination] can be: / or /etc or /home/mike or /path/to/folder or ./pictures/2016-03-24 or ../videos/
I suspect you posted to the wrong sub :)
Huh? 
Someone who can make music and uses BASH. I can barely figure out BASH and know nothing about making music ... so I am not one!
That's actually C code being piped into GCC. There's a good resource on it [here](http://countercomplex.blogspot.com/2011/10/algorithmic-symphonies-from-one-line-of.html) and if you don't know how to compile things yourself, there's a link on that page [where you don't have to worry about that](http://wurstcaptures.untergrund.net/music/).
What does bash have to do with music though? I m missing something...
Even if it was C, you're talking about how to generate a raw .wav file. I think what you're looking for is https://www.reddit.com/r/modmusic/ or https://www.reddit.com/r/midi
The whole point is that this is something you could print so that people could (theoretically) type it in on their own machines. I'll have a look at those subreddits, though.
Bash is a console scripting language. I'm afraid it has no multimedia capabilities.
The title says 'advanced' but this course is designed for someone with no she'll scripting experience. It was one of the main resources i used when learning. http://tldp.org/LDP/abs/html/
Ty man
Also to see each line executed you can run with the `-x` modifier: bash -x my_script.sh Or use: `set -x` in the top of your script just below the shebang, or even add it to the shebang: `#!/bin/bash -x`
Since `$SHARE` is blank, I think it is safe to assume that you're just not getting matches in the evaluation of `$ID`. Unless the desired behavior is to allow later matches on `$IDs` to overwrite the `$SHARE` variable (i.e. - if it is possible for an ID to match more than one, and you want matches farther down the list to take precedence over previous matches), I think `case` would be a better to evaluate the ID and set the variable base on the match. This would allow you to exit the evaluation once a match has been made, and gives you the added benefit of setting `$SHARE` to a default value (or return an error) if no matches were made. For me, `case` is easier to debug. If you're not getting `$SHARE` set, and want to evaluate `$ID` in this way still, then I'd add some debugging, like to print the `$ID` value before it is evaluated to see what you're capturing for that value. Once you consistently know what values you're getting for IDs, you'll be able to debug why they're not getting a match. You'll also likely have someone tell you about the issues, like using all caps for variable names which could conflict with global variables, and using back-ticks for executing commands rather than `$(whoami)`, and not properly quoting your variables to sanitize your input - these are things that you'll want to address to clean it up at some point, and you may consider fixing them now anyhow, just to make sure these best practices aren't the source of your bug.
They're actually not inherited, passed, or anything like that. Sourcing a script doesn't execute it normally, instead it inserts it into the current script. It's literally like using a text editor's "insert block of text from file" command, or like using `#include` in C. It's only logical that the positional parameters are not affected by this.
Yep, upon further inspection it appears that egrep was never finding what it expected, thus the variable was empty. A quick run of the ID command revealed that all groups were shown in lowercase and thus when checking for an expression it was not finding what it was looking for because the case was not the same as the expected result. As a result, the variable was then empty.
Indeed. The fix is for the sourced script to not ~~sure~~ use them.
Two `else` for the same `if` (line 18 and 21). You also have two `done` for the same `while` and two `fi` for the same `if`.
 sed -i 's/#define DEF_FREQUENCY_UP_THRESHOLD (80)/#define DEF_FREQUENCY_UP_THRESHOLD (40)/' file.c
Ray_gun thanks for the help but unfortunately the text file seems to have the same value even after entering the command that you gave me.Can you possibly suggest some other way to get sed to replace the value that I given above?
Did characters get gobbled up or added in your top post (like spaces before parentheses)? Something that checks for less characters might do: sed -i 's/DEF_FREQUENCY_UP_THRESHOLD (80)/DEF_FREQUENCY_UP_THRESHOLD (40)/' file.c 
In that case I would recommend the below, but even that might be too broad. sed '/DEF_FREQUENCY_UP_THRESHOLD/s/80/40/' file &gt; newfile
In your first edit you wrote you tried `shift --` and it didn't work, but that was not what I suggested. I meant a different command, not "shift". I meant this here, the command named "set": set --
&gt; not sure them sure? 
&gt; Use [get opts](http://wiki.bash-hackers.org/howto/getopts_tutorial) For myriad reasons such as order not mattering, some kind of relevant naming associated I've tried `getopts` many times in the past, but it wasn't until I read this tutorial a few weeks ago that I really got it. *Awesome* tutorial. &gt; Avoid passing in any kind of log in credentials in via command line. They're visible in processlist and might end up on various logs monitoring that or perhaps cron emails that go out. Pass in a path to a non world readable config file when possible Or `source` the config file :) 
&gt; No reason you can't pass the path of the file to be sourced as an argument, either. That's my preferred method
I have a cron script that needs to process stuff remotely, and the solution I use is: `PASSWD=$(pwlookup user1234) /path/to/script user1234` So at least it's not showing up via `ps`. Oracle utilities actually overwrite passwords passed on the command line. Most of the time I have scripts consult a single password lookup utility, so they are there, but in one place and controlled with file permissions.
&gt; Global namespacing is a pitfall of any language that allows you to use it And it should never be abused, like its done with OP's script (`source script.sh`) where it's headless reads `$1`, `$2`, . Instead `script.sh` should define a function which could be called with the arguments needed: sourced_func "$1" "$2" # or even: sourced_func "$@"
During testing you can write `echo` before the `useradd` and `adduser` commands.
Ok thanks, I have done that now and it runs without the error but the when I check if the user exists it doesn't. 
So you aren't testing, in that case you *don't* write `echo` before those commands, but instead run the script as root.
I thought OP was talking about a 10xer ninja rockstar disrupter 
I'm not sure I understand your question. Are you listing those commands and asking what practical applications they have? Also it looks like you piped ls into grep in an example, which is not recommended and not best practice. 
[Yesterday](https://www.reddit.com/r/bash/comments/4cblc9/what_are_the_functions_of_these_commands/d1gu2ol?context=3) you couldn't understand what "cd /etc" does. I think you need to learn to walk before you run. The changes you've made to that script are a total mess, and I don't know where to start, because you don't seem to have even a very basic understanding of the shell. Maybe try [this](http://linuxcommand.org/lc3_lts0010.php). 
There are multiple problems with the script. Not just in terms of bad style (backticks belong in 1981, uppercase variables are poor practice etc). Your main issue here is that your variables are not quoted correctly. And arguably you've got a useless use of echo echo $ID | egrep '\bFacStaff ABC\b' &amp;&amp; SHARE=$FAC1"/UsersABC" Could be written as egrep '\bFacStaff ABC\b' &lt;&lt;&lt; "$ID" &amp;&amp; SHARE=$FAC1"/UsersABC" 
I don't have the skills to actually compose anything, but [here's another resource that doesn't involve invoking the C compiler](http://blog.robertelder.org/bash-one-liner-compose-music/). It's basically the same concept, except you're piping random numbers into an awk script instead of compiling and running a C program.
 perl -p -e 's/[^\"]\n/$1/' filename
Perhaps you could show a visual of what you mean exactly? Anyways it sounds like you're after `perl -pe 's/\r([^"])/$1/g`, example: user@host $ sed -n l file-with-carriage-returns foo,"bar,bar\r",omg\r$ lol\r$ user@host $ perl -pe 's/\r([^"])/$1/g' file-with-carriage-returns | sed -n l foo,"bar,bar\r",omg$ lol$ (We're just using `sed -n l` here so we can see the `\r` characters.)
http://mywiki.wooledge.org/BashGuide/InputAndOutput#Redirection
`tree &gt; tree file` means you write the output of the command in a file called tree file if the file exists you should use `tree &gt;&gt; tree file`, which don't overwrite the existing file 
Oh, sorry, didn't paid much attention to sidebar
sed is always good for small stuff like this: sed -i 's/\([^"]\)\r/\1/g' input_file # ^ In place edit Explained: s/ / /g # Global substitution \([^"]\) # Match anything but " and store the match in a caputuring group (\1) \r # Followed by \r \1 # Replace with the capturing group You could also use more sophisticated version of regex, eg PCRE regexes have lookbehind and you could archive the same with the following regex: (?&lt;!")\r # Match \r which doesn't have " infront And in full Perl script perl -pie 's/(?&lt;!")\r//g' input_file # ^ Read line for line of `input_file` # ^ In place edit, just like 'sed -i' # ^ Treat next argument as code and not a Perl file name # And who doesn't like pie ;)
I've seen many times the use of "source" for scripts that return a single value. If it's your case, change source foo.sh to var=$(foo.sh)
Well, either if ! ([[ "$1" = "install" ]] || [[ "$1" = "update" ]]); then or if ! [[ "$1" = "install" ]] &amp;&amp; ! [[ "$1" = "update" ]]; then or if [[ "$1" != "install" ]] &amp;&amp; [[ "$1" != "update" ]]; then will work as you intend. This is because **not (A or B)** is logically equivalent to **(not A) and (not B)**. See [De Morgan's laws](https://en.wikipedia.org/wiki/De_Morgan's_laws)
Use a case statement, it's neater. case "$1" in "install") &lt;some command(s)&gt; ;; "update") &lt;some other command(s)&gt; ;; "*") echo $"Usage: $0 {install|update}" esac
Will it have the usual POSIX utils or is just the shell? Bash is fine and dandy, but without the utils I can't see much use for it in windows outside of basic scripting.
wich code exactly do you run? for me everything works perfectly (with the echo).
Dear Microsoft, Thank you for getting me my Christmas present early. Now whenever a friend asks me to fix their computer I'll have a modern interface to interact with it. I though this day would never come, but you always pull through in the end. If it's not too much to ask, here's my list for next Christmas. - Built-in support for Xmonad - Replace C# with Common Lisp as the default programming language for native apps - Give the Windows Store a command-line package manager - Ship Windows 11 with Firefox pre-installed - Provide all Windows users with free access to a VPN so that they can use Google in China - Set Windows 13 to automatically erase and reinstall itself once a month so I no longer have to help family members fix their computers - Route all Internet Explorer traffic through Tor - Open source the Windows Phone - Write an app that will wash my dishes - Bring back Clippy, but with a Cortana animation instead Your loyal customer, Qelzy
I'll be curious to see how different this is from Cygwin. Has there been any reference in the media?
According to [a Ubuntu developer](http://blog.dustinkirkland.com/2016/03/ubuntu-on-windows.html), this system is kind of like an inverse Wine, and it sounds like it should, theoretically, allow pretty much any Linux binary to run on Windows. He even explicitly mentions using apt and having access to all of the Ubuntu packages.
Most of these actually sound awful. I hope they don't.
Even more reason to continue developing my BASH skills. The market for it has more than doubled by this announcement.
I thought Windows PowerShell was pretty modern. I just prefer BASH.
Few issues. 1. Immediately after the for loop (looping over prime.data), you're setting OUTCOME without a test. Overriding the logic in the for loop. 2. You're not resetting the value of OUTCOME 3. (optimisation) If factor found, you can break out of the for loop to speed things up . #!/bin/bash FILE="/home/tony/prime/prime.data" LOOP=1 TEST=$(tail -n 1 &lt; "$FILE") # OUTCOME # 0 = Not tested yet # 1 = Factor found. Not prime # 2 = Factor not found. Prime prime_test() { echo Testing $TEST OUTCOME=0 sleep 1 while [ $OUTCOME -eq 0 ]; do while read -r I; do sleep 1 echo 2--- echo dividing by$I echo $TEST if [ `expr $TEST % $I` -eq 0 ]; then OUTCOME=1 break fi done &lt; "$FILE" echo 3--- if [ "$OUTCOME" -eq 0 ]; then OUTCOME=2 fi done if [ $OUTCOME -eq 2 ]; then echo $TEST &gt;&gt; "$FILE" echo $TEST is prime fi } while [ $LOOP -eq 1 ]; do TEST=$(($TEST + 2)) prime_test done
This is goddamn amazing.. If I could get some sort of tiling WM, I would be pretty concerned that I might have died and gone to heaven.
http://www.tldp.org/LDP/abs/html/commandsub.html for more info
 Why is $(...) preferred over `...` (backticks)? http://mywiki.wooledge.org/BashFAQ/082
Is it non-regex, then how is `grep -F -f ids.txt file.txt`
What's the python code look like?
So... Does this mean I'll be able to run vim, ssh (and have a .ssh/config file ?), npm, grunt and everything from windows ? If yes, then best news ever.
That's what it means. You can install additional Ubuntu packages like normal. The binaries in the packages are not recompiled or anything, it's the exact same packages as for a normal Ubuntu x86_64 installation. Microsoft built some sort of Linux kernel emulator for this. The only problem mentioned is that the terminal program of Windows might not be able to do everything that a program like vim needs. What was mentioned is that screen and tmux don't work right in there.
well, i have quotes around my echo so i dont think it will look for files when the command is to output stuff. i also do not get any error messages.
Yes, you need the quotes. It's normal that there's no error messages. It just silently does this. Example here: $ echo asdf* asdf* When I do the same with a pattern where I have files that will match, it suddenly does this: $ echo log* log log2 logs Quotes disable that: $ echo "log*" log*
Can you post the source code?
Hell, I may just give Windows a shot again. (It's been since XP.)
okay, so what was the point know? just an information that i need quotes (i have them everytime ) or is there some sort of error than can cause my script to crash?
you are right. i forgot the quotes in the original post. didnt noticed that. now it makes sense ;D. thanks for letting me know all this :)
can you explain that a little bit? what exactly does {} and ! do?
 function weather() { curl http://wttr.in/$1 } Stick that in your .bashrc/.zshrc and you can use it like: weather boston
 weather() { curl "http://wttr.in/$1" } FTFY
Isn't this a carriage return at the end of the line because the file comes from Windows? You would remove those carriage returns like this: sed 's/\r$//' The '\r' is the carriage return and the '$' asks sed to look for the end of the line. The '\r' gets replaced by nothing, so will be removed. There is also a program 'dos2unix' that might be installed on your system that you could use instead.
I'm just getting: ERROR When I go to the URL in a browser, I get the same thing.
Even better: curl "http://wttr.in/${1:-your home city}" Make it default to your home city (which you hardcode into `.bashrc`). And, if you want to protect yourself against passive attackers learning which city’s weather you are requesting: curl -k "https://wttr.in/${1:-your home city}"
UPDATE: realized "read" wasn't good for what I was trying to do. went simple for i in `which time` ; do chmod a-x $i echo "$i has been modified"
It looks like your submission contains a shell script. To properly format it as code, place four space characters before every line of the script, like this: This is normal text. #!/bin/bash echo "This is code!" &gt; This is normal text. &gt; &gt; #!/bin/bash &gt; echo "This is code!" *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/bash) if you have any questions or concerns.*
Use the tool "shellcheck". It will help. Your distro might have a package for it. It is also on a website where you can copy/paste code into: www.shellcheck.net
* the test built-in requires spaces between the brackets e.g. [ -d "$1" ] * prefer the double bracket notation for tests, i.e. [[ -d "$1" ]] * `rm file` should be `rm "$file"` * to check for the file ending use a regular expression [[ $file =~ \\.(swp|tmp)$ ]]
That's a particularly bad place to use `declare -i` - on user input, with no validation. You're also not using it in any context that it would make a useful difference. It really only affects regular assignments to simple commands and not arithmetic expressions.
Something like this I guess PS1='\[\e[$((COLUMNS-8))C$(date +%T)\r\]'"$PS1" #edit: actually PS1 has a shortcut for date, which is faster: PS1='\[\e[$((COLUMNS-8))C\D{%T}\r\]'"$PS1" It will overwrite if the line is too long.
It's not complete by any means and can definitely be improved, but here it is: #!/bin/bash orig_num=$1 updat_num=$orig_num count=0 startTime=`date | cut -d' ' -f4 | cut -d: -f3` echo $1 while [ $updat_num -ne 1 ] do parity=$((updat_num % 2)) if [ $parity -eq 0 ] then # number is even updat_num=$((updat_num/2)) else # number is odd updat_num=$((updat_num*3+1)) fi echo $updat_num count=$((count + 1)) done endTime=`date | cut -d' ' -f4 | cut -d: -f3` totalTime=$((endTime - startTime)) echo echo "Original Number: $orig_num" echo "Number of Steps: $count" echo "Total time spent calculating: $totalTime seconds" echo exit Any feedback would be greatly appreciated :) 
While this might be a fun exercise in bash, I think you really need to find a specific tool (more specific than `netstat`) and use that instead, maybe with some bash wrapping. vnstat, ntop, iftop to name a few that you might like to look at... You may also like to see if FreeBSD's `systat -ifstat` made its way into OSX...
&gt; Or date +%s%N which will give nano seconds since same date. That's a GNUism FYI. ~~`%s` is in the POSIX standard though.~~ (see below) &gt;And just to open the discustion: I have always liked the shebang #!/usr/bin/env bash instead of #!/bin/bash. This gives each user the opportunity to choose their own version of bash instead of relaying on /bin/bash. But don't take it from me: https://unix.stackexchange.com/questions/29608/why-is-it-better-to-use-usr-bin-env-name-instead-of-path-to-name-as-my OTOH, the use of `env` like this theoretically can be a security flaw. Let's say `$HOME/bin` is at the start of your `$PATH`, well you could put a super evil hacked version of `bash` into `$HOME/bin` and get the keys to the universe. Now, the *realistic* likelihood of that happening is slim, but it's still something that's likely to upset the more security-paranoid. As the accepted answer in your link says (emphasis mine): &gt;The advantage of #!/usr/bin/env python is that it will use whatever python executable appears first in the user's $PATH. &gt;**The disadvantage of #!/usr/bin/env python is that it will use whatever python executable appears first in the user's $PATH.** I instead have a `.bashrc` function that, from memory, tests for `/bin/bash` and if it doesn't find it, it suggests creating a symlink to something like `$(which bash | head -1)`. That doesn't help with script portability though. What would be great would be a secure way to have a dynamic shebang self-contained within a script. Or you could just use `env` :)
Your `done` appears to be in the wrong position relative to your `do`, but I'm making assumptions because you didn't format your code as code. Listen to what u/automoderator said.
For the timing, I'd use the `time` keyword or the special `SECONDS` variable. Using `SECONDS`: SECONDS=0 while (( updat_num != 1 )); do ... done printf 'Total time spent: %d seconds\n' "$SECONDS" Using `time`: TIMEFORMAT='Total time spent: %R seconds' time while (( updat_num != 1 )); do ... done
Yeah, sorry... I got confused with `%S`, ultimately though the same effect is true if you're looking for a polling reference point: POSIX `date` will give you per second resolution, GNU will give you nanosecond resolution
thats what I was after thanks, but could you add that to my current PS1 export PS1="\n\w \u &gt; \[$(tput sgr0)\]" I'm pretty new to bash and have no real clue how it works :P 
&gt; vnstat Came to suggest this.
if you like that, check out ansiweather as well - https://github.com/fcambus/ansiweather
Shebang is wrong, but that's not the main problem, assuming you're running it with bash anyway. The main problem is that your ascii art is enclosed in double quotes, and contain unescaped `` ` `` characters, which is part of the old-style command substitution syntax. Since your ascii art also contains `'`, you can't just switch to single quotes either. So either go through and escape all the characters that need escaping (http://shellcheck.net can help you identify them), or switch to quoted here documents. So instead of: echo "You bash your rocks together to no avail. _____ _____ ---' __\_ _/__ `--- _) (_ __) (__ __) (__ ---.______) (______.--- " You either escape backslash and backquote: echo "You bash your rocks together to no avail. _____ _____ ---' __\\_ _/__ \`--- _) (_ __) (__ __) (__ ---.______) (______.--- " or: cat &lt;&lt; 'EOF' You bash your rocks together to no avail. _____ _____ ---' __\_ _/__ `--- _) (_ __) (__ __) (__ ---.______) (______.--- EOF Second problem I see is that your rpsls function is calling itself. That only works for a while; eventually it will hit the FUNCNEST limit, or segfault.
Great response thanks! What's the best way to break out of the for loop? Is that what the break is doing? 
ohhh thats why it only works a few times in my other scripts
cat's default behaviour is to output on stdout. So here, they are using it as a replacement the echo commands you had.
It would help if you ask what you need help with.
This sounds like a homework assignment, so I don’t want to just give you what I’m almost certain is the intended answer… but look through [this part of the Bash manual](https://www.gnu.org/software/bash/manual/html_node/Conditional-Constructs.html) and you should find what you need.
I'm bored this weekend, so I want to offer some further improvements. First, what version of bash are you running? You can find out via echo $BASH_VERSION 
&gt; Unfortunately it is a homework problem Unfortunately most of us don't like being used to do school assignments. 
4.3.42(1)-release
It depends what you input as firstname and lastname; you are injecting that data into the sed script, so if they happen to contain any characters special to sed, you may be executing arbitrary code (at least if it's GNU sed). Consider using grep instead: read -rp "Enter first and last name: " firstname lastname grep -Fv -e "$firstname" -e "$lastname" original.txt &gt; edited.txt
You can play with stuff on the command line before you put it into your script. For example, do that "cat passwd". You'll see it won't work. You probably wanted "cat /etc/passwd". Now add your grep to that: cat /etc/passwd | grep -f dnsmasq You'll see it won't work. Check out the man-page of grep: man grep That '-f' seems to not be what you want. You probably wanted '-F'. Let's try that: $ cat /etc/passwd | grep -F dnsmasq dnsmasq:x:995:995:dnsmasq daemon:/:/sbin/nologin When this gets run in your script, that output will then get compared to "dnsmasq". This can never work because there's all that other stuff on the line, that ":x:995:995:..." and whatnot. The 'grep' tool reports if it found something not only in its text output. It also invisibly reports the result through its "exit status". You can use that like this through the 'if' command: $ if cat /etc/passwd | grep -F dnsmasq; then echo true; fi dnsmasq:x:995:995:dnsmasq daemon:/:/sbin/nologin true You see that "true" printed there on that line, so the 'then' block of the 'if' was executed. Basically, you don't need the features that `[[ ... ]]` provides for that 'if' in your script, can just put the 'grep' command there. Now, you probably want to hide grep's output. It has a '-q' parameter for that. It also can read a file directly, so there's no need for the 'cat'. Then, you probably shouldn't use the '-F' parameter, instead build a regex rule that makes it only look at the start of the line until those ":" that are in "/etc/passwd". Here's how you would experiment with that on the command line: $ x=test; if grep -q "^$x:" /etc/passwd; then echo true; else echo false; fi false $ x=dnsmasq; if grep -q "^$x:" /etc/passwd; then echo true; else echo false; fi true When '$x' is set to "dnsmasq", that regex rule used for grep will be `^dnsmasq:`. That `^` there is special and means the start of a line. Putting this idea into your script would look something like this: for i in "$@"; do if grep -q "^$i:" /etc/passwd; then echo "this user exists: $i" else echo "can't find this user: $i" fi done 
I modified it using /u/webtm's suggestion plus a few more edits so the responses from the server are displayed properly. The old API responded with XML and the new one uses json. [Here](http://pastebin.com/vYbxn4GE) is my modified version. You'll also have to go to Imgur's [API](http://api.imgur.com/) page and sign up to get your own client_id to add to the script for it to work.
Haha. I'm so very glad to know that I'm not the only one who does this.
Oh wow. I took me a second to realize what this does. This saves lives. Thanks. 
I'm not sure I follow, commands will run sequentially so can't you just do this? smartctl -t short /dev/sda write_to_logfile Or does `smartctl` run off in the background or something?
Yes, the test runs in the background and won't notify you when it's done. After starting the test you can see by smartctl -a /dev/sda if the test was completed. But I would like a way to get a return value like 0, 1 or whatever.. 
Ooh, nice idea. Is command_not_found_handle() an internally recognized handler for bash? grep $1 I think $@ could be more versatile here. echo $"$1: command not found" What's with the stray $ in front?
Except when you run some 3rd party script that has a pipe sequence into a command you just don't have installed yet on your system and now you waste time trying to debug why it's not working
Yeah, it might be good to check that stdin is a tty. That'd eliminate behavioral differences in scripts.
I must've missed the first one. Here's some comments I have: * Fix the indentation, it's barely readable as it is now * Don't use `declare -r`/`readonly`, it only adds headaches. It's not a substitute for `const`/`final`. * Use `printf` instead of `echo`; `printf` is superior to `echo`. You're currently using both in your script. Be consistent. * Don't embed variables into printf's format string. `printf "${FUNCNAME[0]} is running..."` should be: `printf '%s is running...' "${FUNCNAME[0]}"` * Don't use `[` in bash. Use `[[ .. ]]` to test strings and files, and `((..))` to test numbers. And especially don't use any of the `-a` operators with the `[` command; it's ambiguous. * Don't add pointless parenthesis because it "looks better" or whatever the reason you added them was. E.g. `if ( declare -F "__${1}" &gt; /dev/null )` causes the shell to fork just to run declare -F. Pointless. * The `function` keyword is redundant. Might as well just use the standard syntax; `foo() { ...; }` instead of `function foo() { ...; }`. Shorter and no less clear. * `hash -r` is pointless unless you intend for the script to be sourced EDIT: * `type NPM` should be `type npm`. It's case-sensitive, and the command is named `npm`, not `NPM` (though it happens to work on OSX since the default filesystem is case-insensitive).
To edit a file, you can use an editor, like `ed` or `ex`. ed -s file &lt;&lt; EOF /\[agent]/a certname = box . w EOF
With 'sed', it's this: sed -i '/^\[agent\]/a certname = box' filename The `-i` parameter makes it change and overwrite the file. You'd first experiment from the command line without that `-i` to see if the end result will look good. If you want to use variables of your script inside that rule for 'sed', you need to change the `'` to `"` on that sed command line.
You can search for text with 'grep'. I tried that self-test thingy, and the following would work with what I saw here: drive=/dev/sdc smartctl -t short "$drive" sleep 10 while smartctl -a "$drive" | grep -qF 'Self-test routine in progress...'; do sleep 10 done
https://www.reddit.com/r/bash/comments/4clhvj/bash_is_coming_to_windows_10_natively/ 5 Days Ago...
Are you sure? Before I posted, I tried this with the sed that's in busybox.
Ah, busybox sed is probably based on GNU sed's source (I know busybox awk is based on GNU awk 3.x at least). So "assumes GNU sed or busybox sed", then.
When I look up FreeBSD and OpenBSD and Apple man-pages online, I see '-i' and I see the 'a' command for their 'sed', so I'd hope it would work over there as well. **EDIT:** When I look very closely at its command line, perhaps it has to be used like this: sed -e '/^\[agent\]/a certname = box' -i "" filename **EDIT2:** That will then not work on GNU sed because it thinks the "" is the filename. I found people posting you can have the backup extension touch the '-i' parameter on OSX if you use something with a dot. This here is supposed to work with GNU and BSD sed and the weird one in OSX: sed -i.bak -e '...' filename
I’ve flaired this as “submission”, but feel free to change it to “critique” if that’s more what you’re looking for :)
I use a script I wrote, but you'll have to modify it because it only uses the 'title' tag (artist and album info are included in the filesystem: artistFolder/albumFolder/titleFile): RenameAudioFiles --help 'RenameAudioFiles' will rename audio files. Usage: 'RenameAudioFiles [-d] [-s String] [-t] [Directory..] [File..]'. Notes: '-d': Dry run: Don't rename. Just print new names. '-t': Rename to theme title (Only available for '.ogg' files). '-s String': Remove first part of name up to 'String'. Example: 'Sissel-01-Stay.ogg' will be renamed to 'Stay.ogg' if String="-". Let me know if you want me to post it. 
Library? All you gotta do is follow the examples from this site which uses tail and head to read the id3 bytes: [https://purplefloyd.wordpress.com/2011/01/29/parsing-id3-tags-in-bash-and-renaming-mp3s/](https://purplefloyd.wordpress.com/2011/01/29/parsing-id3-tags-in-bash-and-renaming-mp3s/) Just tested it with an mp3 from Amazon and using just tail and head was able to read the Artist Name and Song Name using their offsets. Wrap together in a script and you're in business.
Holy cow, this is awesome. I've been using https://github.com/jfrazelle/weather but this is definitely a thing of beauty.
thanks a lot, open to any input. being lazy implies I knew better but didn't, well no, bash n00b here :) Feel free to edit the gist directly!
Interesting. POSIX seems to be vague enough to allow both behaviours. Will have to add that extra newline from now on then. You have a file named `testfile-e` now btw, because of `-i -e`
Yes, while I experimented, both a 'testfile-e' and a 'testfile-E' showed up. :)
Red Hat Linux init scripts before systemd.
The bash 'read' can put words from a line into the elements of an array like this: $ read -a x 25 632 73 343 44 &lt;-- I typed this; the read waited for input $ echo "${x[@]}" 25 632 73 343 44 $ echo "${x[0]}" 25 $ echo "${x[1]}" 632 You can tweak how bash splits a line into words through changing '$IFS': $ IFS=',' read -a x 33,5,1,66 $ echo "${x[0]}" 33 Here's a testfile: $ cat testfile 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 The following reads things into an array. It then goes through the index numbers of its elements. It then uses those to access the elements and add them to the same index in another array. $ total=(); while read -a line; do for i in ${!line[@]}; do (( total[i] += line[i] )); done; done &lt; testfile $ echo "${total[@]}" 75 80 85 90 95 100 105 Here's the code shown over several lines: total=() while read -a line; do for i in ${!line[@]}; do (( total[i] += line[i] )) done done **EDIT:** I forgot to think of the average. You'd extend it to count the lines, to be able to get the average: total=(); average=(); count=0 while read -a line; do (( count++ )) for i in ${!line[@]}; do (( total[i] += line[i] )) done done for i in ${!total[@]}; do (( average[i] = total[i] / count )) done Here's how that looks typing all of that onto a single the command line to try it: $ { total=(); average=(); count=0; while read -a line; do (( count++ )); for i in ${!line[@]}; do (( total[i] += line[i] )); done; done; echo ${total[@]}; for i in ${!total[@]}; do (( average[i] = total[i] / count )); done; echo ${average[@]}; } &lt; testfile 75 80 85 90 95 100 105 15 16 17 18 19 20 21 
I wonder if they named that after the Spaceballs character Lonestar.
Please stop calling it Bash on Windows. Bash is just one of the elf binaries that will be able to run on Windows.
I’m not sure if I want to allow this post. I don’t blame OP – Microsoft calls the bugtracker Bash on Windows too – but the fact remains that this list has almost nothing to do with Bash. - Bash is used to start the programs, and - script authors might want to be aware of problems with certain commands on Windows. For the latter reason, I’d probably allow a post like “`wc -l` is off by one on Bash on Windows”. But most of the programs in this list aren’t really for scripting… Thoughts? (CC /u/geirha, /u/KnowsBash)
I agree. It's no different than compiling a list of programs that will run on Ubuntu (or any other OS). Hadn't noticed MS calls it "Bash on Windows". I assumed it was just ignorant news writers/bloggers that invented that term.
Can you share the output of `compgen -c` from within the Windows version of `bash`?
You need to explain more about what you are expected to produce for this homework assignment. The thing is that you'd normally never do this yourself in bash. You would use an external tool that will do all of the work, the 'bc' command line calculator tool for example. You would send your numbers and some commands to it and receive its output, like so: $ echo "obase=2; 142" | bc 10001110 This makes 'bc' print the decimal number '142' in binary. That 'bc' tool can also be made to read binary input and add it, print results as decimal, etc. This is how you'd work with binary in a shell script for a real problem, but you don't really do anything in bash there so I'd guess it's not what the homework assignment was about.
No matlab experience here. I assume it has the ability to do this easier than bash? Bash is pretty damn awful at just "do all this math" type stuff. This sounds like a logic thing, your teacher wants you to figure out how do do the math to convert from decimal to bin without using the "dec2bin" feature of matlab. Do your own homework bro. 
Third question should be: "What is the air-speed velocity of an unladen swallow?"
African or European?
Huh? I don't know that...
Here is a script that will give the current working directory of the shell (presuming it's its first child) running in the terminal that's currently selected, so you can open a new terminal at that location: #! /bin/awk -f BEGIN { while ( $1 != "_NET_ACTIVE_WINDOW(WINDOW):" ) { "xprop -root" | getline } windowid=$5 while ( $1 != "_NET_WM_PID(CARDINAL)" ) { "xprop -id " windowid | getline } termpid=$3 "ps --ppid " termpid | getline "ps --ppid " termpid | getline bashpid=$1 "readlink -m /proc/" bashpid "/cwd" | getline print $0 } You can use this in a keybind like `urxvt -cd "$(windowcwd.awk)"`
hours and tears, but thank you :) now to read up on `awk`... yay
\*nods* thanks anyway though (sincerely)
Sometimes web hosts have controls that don't let you remotely grab images, regardless of your user agent. Maybe there's a way to masquerade as Google Images? 
 useragent='Mozilla/5.0 (X11; Ubuntu; Linux i686; rv:31.0) Gecko/20100101 Firefox/31.0' mpccurrent="test" link="www.google.com/search?q={${mpccurrent})\&amp;tbm=isch" wget -e robots=off --user-agent "$useragent" "$link" I used this code to download the page the script pulls apart with sed. It looks like they restructured their code so the crazy sed pipline doesn't work. It has all the images base64'd into the code... cat search\?q\=%7Btest\)%5C\&amp;tbm\=isch |egrep "^,.*data:image/(jpeg|png).*\"" |head -n 1 seems to pull the base64 images out of the source. should be able to pipe from there to the base64 command and decode it. cat search\?q\=%7Btest\)%5C\&amp;tbm\=isch |egrep "^,.*data:image/(jpeg|png).*\"" |head -n 1 ,["6fkfmPicSrBFTM:","data:image/png;base64,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"] Need more weed an caffeine may post patched script later
How is this fast? You’re still running `git status`, that will still traverse all files to check if they’ve been modified. Personally, I use `git-prompt`, which ships with Git. In large repositories (e. g. Linux kernel), I add `git config bash.showDirtyState false` so that it doesn’t check for all files.
put a space after the first bracket, and another space before the closing bracket, and space the equal sign on both side [ "$proc" = "push" ] same thing here [ "$proc" = "pull" ]
To clarify why this is needed you should know that `[` is a command and needs `]` to be the last argument, while each other part should be an its own argument: [ arg1 arg2 arg3 ] ^ ^ ^ | | "pull" | = "$proc" These days however `[` is for the most part a build in. 
Your choice to learn bash is definitely a good one. However, I would recommend posting your scripts on another format other than "pastebin". Though that is what it is was meant for, many people will not go near any link going to a "pastbin" domain since often they are malicious. You may get more responses by just posting the code raw. =]
Ok, thanks for the advice!
Other option is to use a function: my_cmd () { sudo firewall-cmd --zone=publicweb --permanent --add-service="$1" } my_cmd ssh my_cmd http my_cmd https # Or to use both, a function and the bucle: # for my service in http https ssh; do my_mcd "$service"; done No error validation neither emptiness checking in this example. Take care depending on the usage patterns. 
It looks like your submission contains a shell script. To properly format it as code, place four space characters before every line of the script, and a blank line between the script and the rest of the text, like this: This is normal text. #!/bin/bash echo "This is code!" &gt; This is normal text. &gt; &gt; #!/bin/bash &gt; echo "This is code!" *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/bash) if you have any questions or concerns.*
i have dont that 
Great - Thanks for the information.
backup a file then clear out the file every three months 
What is in this file? Logs? Checkout logrotate.d
Yeah, logrotate should already be doing this
A2: 15: read: arg count gives me this output
&gt;read: arg count This is no bash error message, you are using dash or ash instead.
&gt; Add a variable to set at the end This is the basic read syntax In fact, bash allows you to omit the variable. If you do, it defaults to `REPLY`. If you get an error, you're using some shell other than bash, as /u/X700 already said.
I have yet to see any good video tutorials. They usually end up falling into common anti-patterns like `ls | grep .jpg`, and `for file in $(find...)` and using outdated syntax.
I've always found the Bash courses on [tldp.org](http://www.tldp.org/) to be useful. Some of it seems to be a bit out-dated so be sure to supplement it with [Bash Hackers Wiki](http://wiki.bash-hackers.org/) or something similar.
http://www.tldp.org/LDP/abs/html/ http://mywiki.wooledge.org/BashFAQ
Did you bother looking at the sidebar for this subreddit? I'm not trying to be a dick, but if you want to succeed at finding information, you first have to know how to look and find the readily available stuff. It's good to ask questions, but this one comes up pretty often in here, which is why those things are posted in the sidebar.
Basically, it's pretty annoying. For `$args` itself, there's "arrays" that you could use. Those can do what you want for passing arguments into `foo()`: $ args=(a "b c" d) $ foo() { for i in "$@"; do echo "&lt;$i&gt;"; done; } $ foo "${args[@]}" &lt;a&gt; &lt;b c&gt; &lt;d&gt; The output of `bar()`, you get into an array like this: $ bar() { echo "a b"; echo "d e"; } $ bar a b d e $ mapfile -t args &lt; &lt;( bar ) $ foo "${args[@]}" &lt;a b&gt; &lt;d e&gt; That `mapfile` does not exist in older bash versions like on OS X. You could instead have `bar()` write into an outside variable. There's also "nameref" variables that you could use to point `bar()` to a specific name to write into, like so: $ bar() { local -n x=$1; x=(a "b c"); x+=("d e" f); } $ bar args $ foo "${args[@]}" &lt;a&gt; &lt;b c&gt; &lt;d e&gt; &lt;f&gt; I think that "nameref" stuff is again something not working in older bash.
Perhaps browsing reddit and trying to search or inquire about technical information is not very well suited to a smart phone. Nevermind the fact that one could type 'best online tutorials for bash scripting' into any reasonably decent search engine and get _somewhere_.
I think this will work perfectly. Yeah I just realised there is no need for the size parameter
There are none. Learn by doing. Use shellcheck.net and a shell style guideline such as [google's](http://google-styleguide.googlecode.com/svn/trunk/shell.xml) to guide you away from the most common shitty behaviours. Set yourself some projects and then figure out how to do them. And this is probably where /r/bash could be creative with building a sticky thread for noobs: a series of projects for self-teaching. For example, I needed a password generator that would work on Linux and Solaris (down to Solaris 8, bash v2.04), because I wouldn't necessarily be allowed to install `pwgen` or `apg`. And so I built one that lives in my `.bashrc` file. Then I wanted to add features, so I added those. Then I built a password testing tool. Then I built a password hashing tool, then I shoehorned that code into my password generator as an option. Then I built a passphrase generator. There was a thread in /r/bash where someone was asking how to slow the output of a command so that it was readable, so I built something to do that. One weekend I decided it would be interesting to implement a basic version of `rev` for hosts where it doesn't exist. So I did that. And I had a chuckle on Monday where I found that I actually needed it. True story. Those are just some examples of projects you can try out for yourself.
http://unixmages.com/
Which situation would you prefer? A) You hold someone's hand and do the work for them? B) They do the work themselves and learn. My point is that lazy people will take advantage of others who are eager to help. This sub has a lot of lazy people trying to crowd-source their homework. Lazy people won't learn because someone did the work for them. I've seen it countless times. So go ahead. Help every person asking for help on "how come my variables don't work when I put single-quotes around them!?!? I need this for a test tomorrow!!!!!1!!!". The only person's time you will be wasting is your own, because lazy people will take advantage of you. By the way, I have a test due tomorrow. My instructor wants me to write a script that sources another file, uses functions from that sourced file, then use cURL to download a config file, edit that file with sed, then take the output and insert it into an array. Then that array needs to be iterated through and have the date appended to each indice. Can you help!?!?!?
I've been doing shell scripting for many years but felt there were a lot of gaps in my knowledge. To fix this, I just read the Advanced BASH Scripting Guide front to back. http://www.tldp.org/LDP/abs/abs-guide.pdf 
I had the same experience. In hindsight, a good bit of the time I put into reading tutorials/guides was wasted. I found it a lot easier to learn all the weird ways bash works and breaks by writing my own scripts. There's also experimenting with ideas on the command line, with pipes and redirection and loops and variables and whatnot. That's neat to find out fast if an idea will work or won't work before putting something into a script.
 #!/bin/bash foo() { for Param in "$@" do echo "&gt;$Param&lt;" done return 0 } Params='one 2 "three four" five' eval set -- "$Params" foo "$@" __________________________________ ./t &gt;one&lt; &gt;2&lt; &gt;three four&lt; &gt;five&lt; __________________________________ EDIT: Note: try also changing 'foo "$@"' to 'foo "$@" six' 
Yes, do tell folks about the sidebar and definitely give them tools to help themselves, but the manner in which you do this can detract from the underlying goal, if that goal is that you care enough to actually lend a helping hand more than criticizing the manner in which they ask it. Also, the byproduct of hassling folks in what some might consider to be a less than desirable approach creates an air of negativism. In short, I guess I'm saying there's definitely a right way and a wrong way to tell people they're doing it wrong. I believe you could've been less of a dick about it, regardless of how frustrating the help requests are. 
Oh, you mistake my help for me wanting to help. I'd rather keep people who are unable or unwilling to help themselves away from my career. If people have a tough skin or are able to learn quickly, then I'd love to have them as my peers.
You might be interested to learn more about `pushd` and `popd`. Either way, modifying `~/.bashrc` with every `cd` operation is pretty unlikely to be what you actually want to do, and is not a practice I would consider 'good'. edit: Also, I'd recommend using `$()` instead of ``, or at the very least being consistent with your usage. (`PS1="$(uname -n)::$(pwd)&gt; ";`) ... also you may be interested to learn about `$PROMPT_COMMAND` (search the internet for more information, or read through `man bash` and search (use `/&lt;pattern&gt;` to search man pages) for PROMPT_COMMAND.
Basically you have two errors in your sed command, first you need to use `/.../` for matching: /^cwd=/ Secondly you need another delimiter then `/` for your substitution, consider: sed 's/cwd=.*/cwd=/my/path/is/here/' As you can see that will not work, you could instead use `:` instead, but note that `:` is a valid part of a filename: sed -i "/^cwd=/ s:cwd=.*:cwd=$curdir:g" ~/.bashrc Also remember to quote your variables or they will undergo [word splitting](http://mywiki.wooledge.org/WordSplitting). You can also use `$PWD` instead of `$(pwd)` # Only needs to be defined once, note single quotes around `$PWD` PS1=$(uname -n)'::$PWD&gt; ' __cd() { cd "$1" sed -i "/^cwd=/ s:cwd=.*:cwd=$PWD:g" ~/.bashrc } alias cd=__cd cwd= When all of this is said, I don't recommend doing the above, unless you have a good explanation for it. 
The error message is caused by not surrounding the `^cwd=` address with `/.../`. The error message would be fixed by using `/^cwd=/`. Here's two sed rule alternatives that would do what you want: /^cwd=/ s/.*/cwd=$curdir/ s/^cwd=.*/cwd=$curdir/ *EDIT: I completely didn't notice that `/` problem that /u/galaktos mentioned, so these sed rule suggestions are definitely wrong. The rest of my post is still good, I think. :P* I would probably do this differently and save the directory into its own file. You could do this to write the file: pwd &gt; ~/.config/cwd In your '~/.bashrc', you would then read it to set the $cwd variable. Here's two alternatives that will do it: read -r cwd &lt; ~/.config/cwd cwd=$(&lt; ~/.config/cwd) You also made some mistakes in your `__cd()` function. You need to surround the `$1` with `"` so that you can enter directories with a space in their name, like so: cd "$1" Then, `cd` actually has some parameters other than the directory name. Because of this, you might want to change your `cd` call to this here: cd "$@" This will pass all parameters of `__cd()` over to the `cd` call, meaning if there's $1 and $2 and $3 or something, those all get passed, not just $1. You don't need to change $PS1 like you do. What you want to happen to $PS1, bash can do automagically for you, without you having to change the text yourself. This is explained in `man bash` somewhere. You can jump to the section about this feature by typing `/^PROMPTING` in the normal man-page viewer. What you want is to set $PS1 to this here: PS1='\h::\w&gt; ' The `\h` gets changed into the same text as what's `uname -n`, and the `\w` is the same as `pwd`'s output. You'd set your $PS1 somewhere else in your ~/.bashrc, not inside your `__cd()`, as you don't have to update it at all because bash will update it. Your original code snippet could then be this: function __cd { cd "$@" pwd &gt; ~/.config/cwd } alias cd=__cd cwd=$(&lt; ~/.config/cwd)
Especially when there are NO tests
Another fun fact: you can’t compile this with a modern compiler (tested: GCC 5.3.0, clang 3.7.1). 1. In these olde times, declarations were written without `=`: int sigivalue 0; int sigqvalue 0; int dbgflag 0; Today, ’tis of course a syntax error. 2. `main.c` uses names from `lex.c` (`yylineno` etc.) without any mechanism to know where they come from (no headers, no `extern`s). I guess back then the compiler accepted this and let the linker complain if it couldn’t find the name… (Note that for functions something like this is still supported. This “Hello, World!” program compiles with both of the above compilers: int main(int argc, char *argv[]) { printf("Hello, World!\n"); } You get a warning about an “implicit declaration of `printf`”, but it’s just a warning. And this isn’t a special case for `printf` – if you `make main.o`, this works for any function name; only if you `make main`, and involve the linker, do you get complaints that `foo` is nowhere to be found.)
If you are writing a program to control other programs use a shell such as bash; that's what it is for. What you want to do is best done in Python, Perl, PHP, Ruby or, with node, perhaps Javascript.
I'm sorry if I'm about to ask alot of dumb questions, but: 1. With the &amp; for the text in the actual drop down menu shouldn't it be $&amp; to reference the value 2. is that Li or the number 1 then i 3. Whats the @ for?
`$&amp;` is used in perl. In sed, it's just `&amp;`. The `@` is that thing where you can replace what character you use for `/` in `s///`. Here, the `s///` is changed into `s@@@`. The `1i`, that's a "one" there, and this "one" is an address. It is addressing the first line in the file. The `i` is a command to insert text before a line. Here's that sed program translated to a perl one-liner if you know that better: perl -pE 'BEGIN{ say "&lt;select&gt;" }; s|.*|&lt;option value="$&amp;"&gt;$&amp;&lt;/option&gt;|; END{ say "&lt;select&gt;" }' file.txt 
I think the easiest way would be to read from an array: readarray arr &lt; countries.txt for i in ${arr[@]}; do echo "&lt;option&gt;${i}&lt;/option&gt;" &gt;&gt; results.html done
you can match each position with the ? char, 1 and 6 by their-self, and the rest by a wildcard: $ touch file1withaverylongnameetc $ touch file2withaverylongnameetc $ touch 0000000160000.txt $ echo ???????16* 0000000160000.txt $ 
Note that `readarray` probably always needs `-t` to remove the newline at the end of each line.
With regex, really, and it gets more convenient: `^.\{7\}16` find -maxdepth 1 -regextype grep -regex '\./.\{7\}16.*' -exec mv -vit /target/directory '{}' +
Use find -execdir.
Whoops, I skipped over the actual problem. That doesn't sound like a bash thing, but something with your test program. 
I love me some Chris Occhipinti, but his recent bash series' brevity is frustrating.
Alias is deprecated. From the bash man page: "For almost every purpose, aliases are superseded by shell functions."
how to use shell function like alias?
Did you check to see that the `script.txt` lines are written with the proper line endings? Are they encoded with UTF-8? Can you post some sample code from the other scripts?
If that's the case then I would suggest he write the directory he wants to return to to `~/.config/new_home` or something like that, and then adding `cd $(&lt; $HOME/.config/new_home)` to the end of his `~/.bashrc`.
* Do you have the ability to debug the LAMMPS program? It seems like the program is preparing the output file but not generating the output. If you can add some kind of debug flag argument to the program itself, you might get more information about why it is exiting. You could check this by creating a script that only processes one input file. Check the run time (you can use the "time" command for this) of your program when run from the command line, versus when run in the script, and see if there is a meaningful difference. * Something is different between how the program is running in your script versus in your script. So the question is, what is the difference? environment variables? You could try running "printenv &gt;~/term-env.txt" on terminal, and put "printenv &gt;~/script-env.txt" in your script. And then "diff" the two files, and look for anything related to LAMMPS. Or try just dumping all your terminal environment variables into you script and see if that fixes it. 
Thanks for the input, will check out this line of thought when I get home!
For your case it would be UNASSIGNED. You don't need the grep since you can do it all in awk.
You can use just javascript to load data from external files, so you could abstract the issue from bash if you want. Anyway, something like this can do it too: while read -r country; do cat &lt;&lt;EOF &lt;!-- Your HTML here --&gt; &lt;option id="option-$country" value="$country"&gt;${country^}&lt;/option&gt; EOF done &lt; countries.txt Note that ${country^} is to make it uppercase in the first letter. Generate HTML is no problem with bash. Issues arise at _parsing_ it with bash. Good luck ! 
 curl -XGET http://localhost:9200/_cat/shards | while read -r index shard _ do echo "do something with $index" echo "do something with $shard" done
None of my Pi devices do, all headless servers ;)
you can certainly configure it that way. But they have one. 
You could escape the forward slash in ${curdir} with a backslash before using it on line 17. Excessive use of this in code is called "Picket Fence", which makes the code hard to read, but it's not like the example snippit posted by OP has any comments in the code anyway. something like: curdir=$(pwd) curdir2=$(echo $curdir |sed "s_\/_\\\/_g") echo $curdir echo $curdir2 (untested, but you get the idea)
Bash has built-in replacement syntax, though it gets horribly ugly: ${curdir//\//\\\/}
Don't use uppercase variable names. Trying to find the script's location in order to use that to create temporary directories seems like a pointless complication to me, but at least do it right; test if cd fails. Always test if cd fails. `root_dir=$(cd ... &amp;&amp; pwd) || exit` And switch quotes on the traps, like shellcheck will also suggest.
Thanks for the feedback. Shellcheck looks like a great tool.
I get /tmp/babel-2039wM5/sh-script-2039lrk: line 4: syntax error near unexpected token `file3=/media/n/Seagate\ Fast\ HDD\KI/batch1/2.jpg' /tmp/babel-2039wM5/sh-script-2039lrk: line 4: `file3=/media/n/Seagate\ Fast\ HDD\KI/batch1/2.jpg'
Isn't it the apostrophe? ' after jpg?
No, that’s just how Bash styles error messages. $ bash -c 'for' bash: -c: line 0: syntax error near unexpected token `newline' bash: -c: line 0: `for' Bash uses the backtick for left quote (‘) and apostrophe for right quote (’).
Oh right. Gotcha.
Read the files in the directory into an array, use the array index + 1 as the option # in your menu. Read a number from the user, subtract 1 from it, delete the file at that index of the array. 
If you have to use `dialog` then this should be enough, because you can use the input box to type in `../` and it will display other directories. If you use the menu to select a file/directory, then press space to copy it to the input box. For directories you have to type `/` to make the windows update with new contents. if file=$(dialog --title 'Deleting file in INPUT BOX' --stdout --fselect '' 20 70) &amp;&amp; dialog --yesno "Really delete $file?" 0 0; then echo rm "$file"; fi 
Thanks for that answer! I will investigate further. My only concern would be seeing how I have like a gazillion aliases write all those as functions would pollute my bashrc, I think. But maybe not. :-) I'll try and see. Thanks again! 
In the same lane as screen, there's tmux. 
Thank you. Nohup is perfect for me simple needs. 
Thanks that is good advice. I will have a go at some projects and figure out how to do them.
Yeah I looked on youtube and none of the tutorials were of much use to me.
I thought I knew something, but please clarify?
&gt; Are you familiar with text encoding and line endings? 
https://www.google.com/search?q=bash+for+beginners litterally gives you a page full of tutorials for learning BASH. Clearly you didn't do much searching on Google. 
I am familiar with there being different standards, yes, but I don't see how this pertains to my problem. If LAMMPS couldn't read the script, I believe that it would be rejected or come out all wrong. 
Right - the data is still formatted correctly in regards to number of columns etcetera. But I see your point, I will absolutely check for this!
Some of the scripts I use have outputs for debugging that I don't need all the time so I usually out of habit do nohup script 2&lt;&amp;1 Might want to check my syntax but I think that's the command to send outputs to null.. I'm just learning to! Great question! 
Some ways to use braces I'm aware of: * To dereference a variable: If you have a variable "foo" and "foo_bar", compare: "$foo_bar", "${foo}_bar", and "${foo_bar}": foo=hello foo_bar=world echo "${foo}_bar" "$foo_bar" "${foo_bar}" The braces make the beginning/end of the variable name explicit. * To group commands without creating a subshell Braces act like parenthesis to group commands, but don't fork a subshell. This can be useful when redirecting the output of multiple commands into a single pipe: { command1 ; command 2 ; } | command_reading_from_stdin * To declare a function body function my_function { ... } my_function() { ... } Note that braces in this context are a bizarre shell builtin, so the newlines and whitespace ends up being important -- you will need a ";" before the closing brace for a one-liner. * As a placeholder for the the results of the "find" command: $ find . -type f -exec md5 {} \; 
Along with just dereferencing variable names, the ${variable} form has some tricks called [Parameter Expansion](http://wiki.bash-hackers.org/syntax/pe): Common uses: * setting a variable's default foo=${bar:-default_value} * find and replace foo=${bar//search/replace} * trimming from the front foo=${bar#prefix} * trimming from the back foo=${bar%suffix} So, in your case ${var%d*} removes everything from "var" after (and including) the last "d" character. $ var=abcde $ echo ${var%d*} abc 
Learning by doing. Many of the [Easy] /r/DailyProgrammer tasks can be solved in Bash, for example.
OS X ships with an outdated version of Bash for [license reasons](https://apple.stackexchange.com/questions/208312/why-does-apple-ship-bash-3-2). It’s possible to install modern Bash (with Homebrew, I believe), but you should keep that in mind if you’re writing scripts that you want to run on both OSs.
No problem. Happy to help.
https://github.com/learnbyexample/scripting_course/blob/master/Linux_curated_resources.md
pskipw has answered already.. this is a good link for more examples of using find command: http://www.folkstalk.com/2011/12/101-examples-of-using-find-command-in.html
This is exactly what I needed! I had all the individual parts but was unable to put it together using the correct syntax. I assumed that the ! had to be part of the operator like this: !=~ Thanks for clearing that up! 
Aaaah. I know what you mean now. When I said it worked for me I meant that regex was being evaluated properly along with the else if I had thrown in. 
bash will be bash in both platforms (this is, what you can see available in "man bash"). The version may differ (and so the features available). What is more hard for scripts, is that the userland, is different in both platforms. This is, common daily tools like grep, sed, cp, rm, even cat, etc, etc, will have different arguments (GNU Vs BSD like). And for example the -i argument will not make the same in both environments. But that is not a "bash" issue, and can be handled with detection of the environment and conditionals. 
This gets the number and filenames in columns: $ paste &lt;(seq -w 0 1000) &lt;(ls -1 ./) | grep ./ So something like $ paste &lt;(seq -w 0 1000) &lt;(ls -1 ./) | grep ./ | while read i f; do mv "${f}" "${f//gen/${i}}"; done
It doesn't work for me. There's no "./" in the output of 'ls', so grep finds nothing.
find's output is unsorted. Better do `ls *jpg | grep jpg`
Yeah, that's it. 
* Use `for` to iterate the files * Use `printf` to generate the zero-padded number * Use parameter expansion to replace `_gen.jpg` with `_$num.jpg`. -- i=1 for file in ./*_gen.jpg; do printf -v num %04d "$((i++))" mv "$file" "${file%_gen.jpg}_$num.jpg" done 
&gt; or something that already exists Yeah, it's `ALT+.` to insert the last argument of the previous command. Also `ALT+0 ALT+.` will insert the command, `ALT+1 ALT+.` will insert the first argument, etc.
I have always used: if test "$Number" -ne 0 -o "$Number" -eq 0 2&gt;/dev/null then echo "Integer." else echo "Not an integer." fi 
not strictly `{}`, but a personal little favourite: for i in name{01..10}; do echo $i; done
Shouldn't you quote `!$` if it contains spaces?
How does this work on a mac? I'm using iterm and alt (option) + 0 is giving me: º
Could you see if the Escape key can replace Alt-whatever? I mean, instead of `Alt-0` and `Alt-.`, you would type this sequence of four keys: `Esc` `0` `Esc` `.` EDIT: I googled a picture of Apple's keyboard to remind myself of what it looks like. Could it be 'Command' for you? 'Command' is in the same spot as the Alt key on a PC keyboard.
Thanks for clarifying!
Don't forget Brace Expansion. String expression: echo test-{one,two,three,four} test-one test-two test-three test-four Sequence expression: echo {1..10} 1 2 3 4 5 6 7 8 9 10 Sequence expression with step increment: echo {1..10..2} 1 3 5 7 9
Thanks, g1zmo! I knew I was forgetting something. $ mv /long/path/to/file{,.bak}
The format of the file is username: firstName:lastName and not asking useradd. Just making my own input to read username. An example would be Dmann: Danny: Mann and if there's another usernamw thats similar it would add 1 to the username Dmann1:Devin:Mann
Assignment uses no spaces between the equal sign: `user=$user$counter`
copy and paste your code into http://shellcheck.net and see what it recommends.
Or the more "standard" AWK way: NR==FNR { banned[$0]++; next } $1 in banned { $0 = $0" Banned" } 1 One line: awk 'NR==FNR{banned[$0]++; next}$1 in banned{$0 = $0" Banned"}1' banned.log access.log 
Try comm. comm -12 a b You'll want to sort the lists first, and if they're variables and not files, you'll need to do a fancy printf to ensure the line endings show up. 
This. Why would you use awk when you have comm and/or diff.
Here are two ways to do it. I tried both using access.log and banned.log as used [here](https://www.reddit.com/r/bash/comments/4fw68x/help_comparing_lists_a_and_b_and_marking_the/d2dbl5h). If it doesn't work for you, please paste some examples from your files. **Using comm** `comm -12 &lt;(sort banned.log) &lt;(cut -d" " -f1 access.log | sort) | xargs -n1 -I{} sed -i "s/^{} .*$/&amp; BANNED/" access.log` Explanation: 1. comm works by comparing two files and printing lines that are unique to each file and common to both. However, it needs these files to be sorted. 2. Since access.log has the IPs followed by some extra info, we remove this extra information to be left with only access IPs using `cut -d" " -f1 access.log` 3. Now we sort both the inputs and present it to comm as files using `comm -12 &lt;(sort banned.log) &lt;(... | sort)` * The -12 hides the lines that are unique to each input * &lt;( ... ) takes the output of the command within the parentheses and presents it as a file. 4. Thus, so far we have a list of banned IPs that are present in access.log. Next, for each IP, we'll add the word BANNED in front of the line in access.log using sed 5. The looping part is done by `xargs -n1` which means operate over each banned IP individually 6. `-I{}` means that to replace "{}" with the stdin wherever it shows up in the following command. Thus, in sed, in the string to be searched for, "{}" gets replaced with the banned IP Another way to do the same thing using `for` instead of `xargs` would be for i in $(comm -12 &lt;(sort banned.log) &lt;(cut -d" " -f1 access.log | sort)); do sed -i "s/^$i .*$/&amp; BANNED/" access.log done **Using grep** Requires adding patterns to the IP-list in banned.log `grep -f &lt;(sed 's/^.*$/\\b&amp;\\b/' banned.log) access.log | xargs -n1 -I{} sed -i "s/{}/&amp; BANNED/" access.log` 1. We create a search pattern by demarcating the beginning and end of the banned IPs as a whole word using `sed 's/^.*$/\\b&amp;\\b/' banned.log`. Note the use of single-quotes and double backslash 2. We present these patterns of banned IPs as a file using `&lt;(sed 's/^.*$/\\b&amp;\\b/' banned.log)` 3. `grep -f` uses these patterns and searches access.log After this it's the same as steps 5 and 6 from above. If someone has any suggestions for improvement, please let me know
**tl;dr:** Try this on the command line and see if you like it: sudo arp-scan --interface=eth0 --localnet | awk -v t="$(date)" '/([0-9a-f]{2}:){5}[0-9a-f]{2}/ { print t "," $2 "," $1 ",\"" $3 "\"" }' --- You get a timestamp with 'date'. You can make it print any format you'd like to have, whatever might be good for use in your graphing software. You can also change the time zone it uses by setting a variable "TZ" while calling it. Example: $ TZ=UTC date '+%Y-%m-%d %H:%M:%S' 2016-04-22 19:16:44 With tools like 'awk', 'sed', 'perl', you can filter out the lines with the MAC addresses in them, and rearrange them into the format you'd like to have as input for your graphing tool. You'd also add the timestamp. Here's with 'awk': timestamp=$(TZ=UTC date '+%Y-%m-%d %H:%M:%S') arp-scan --interface=eth0 --localnet | awk -v t="$timestamp" ' /([0-9a-f]{2}:){5}[0-9a-f]{2}/ { print t "," $2 "," $1 ",\"" $3 "\"" } ' The `-v` parameter sets a variable for use inside the awk program. The awk program here is this: /([0-9a-f]{2}:){5}[0-9a-f]{2}/ { print t "," $2 "," $1 ",\"" $3 "\"" } The `/.../` is a pattern to target certain lines in the text. It's regex. On the lines that fit with this pattern, that "print" command gets run. For that one, you have to know that awk will split lines into fields where there are spaces. It puts those fields into variables $1, $2 etc., that you can use. That "t" is a variable set through that '-v' command line parameter earlier. You can redirect this to a log file. You would use `&gt;&gt;` to add to the end of the log file instead of overwriting it.
This is a fork bomb. Don't run it. It will crash your system unless you have set a process limit.
If the song title is part of the file name: while read -r title; do find /your/music/directory -iname "*$title*" -exec add to playlist {} \; done &lt; playlist.txt If the music files are MP3 files with ID3 tags, using `mp3info`: shopt globstar while read -r title; do for file in /your/music/directory/**/*.mp3; do if [[ "$(mp3info -p %t "$file")" == "$title" ]]; then add to playlist "$file" fi done done &lt; playlist.txt Note that the second one is pretty inefficient. Try the first one first.
Depending on your setup, you could probably utilize SNMP from your switch to get this data as well.
Thank you so much!
Just updated my post with my sort-of solution
Seriously no, don't do that. It has horrible practices and many times doesn't even quote variables. If you pass it through shellcheck it will scream bloody murder.
Awesome -- thanks. Went with: `if (( "$debug" )); then ...` Works like a charm.
Yes, it works, but the quotes and the `$` are unnecessary inside of `(( ))`.
Never knew about `set -x` -- that's awesome, if not a bit hard to actually follow what is going on. :P
searching for "color" in the article revealed: &gt; ;; Add color to terminal &gt; ;; (this is all commented out as I use Mac Terminal Profiles) &gt; ;; from http://osxdaily.com/2012/02/21/add-color-to-the-terminal-in-mac-os-x/ &gt; ;; ------------------------------------------------------------ &gt; ;; export CLICOLOR=1 &gt; ;; export LSCOLORS=ExFxBxDxCxegedabagacad (edit: replaced the # for ;; as comments or they were formatted as headers) The osxdaily article goes into details about the color setup. BUT since it's mainly for the LS command, there might be something else. Also the author seems to use `nano`, but I would not go as far as saying it's a text editor color scheme. On top of that, the color scheme we see in the article is text, those are not screen shots, so there might be some specific formatting. Why not sending a mail to the author directly?
Interesting solution for sure. I would prefer to use the tone generator and probe, or a managed switch with the equivalent of a 'show mac address-table" command
In Windows, the convention is that lines ends with \r\n but in Unix it's just \n. In Emacs, you can try M-x set-buffer-file-coding-system and set it to "unix", then save the file.
Thanks! The script now works exactly as it should. Can I set the default coding system to unix for that type of file? Or if I just set it that way for all files, would that affect any of my other projects?
A quick hack would be to add (add-hook 'sh-mode-hook (lambda () (set-buffer-file-coding-system 'unix))) to your emacs init file. edit: Instead of adding a hook to sh-mode, you might want to save all new files with unix line endings. (prefer-coding-system 'utf-8-unix)
It will only affect new files. It won't change existing files. And I know that Python, C++ and Lisp will work with unix line endings.
netdisco is your friend in the future. I use it to map out all my switchports. Now if someone needs to know what switch/port a device is attached to I just use this awesome tool. https://metacpan.org/pod/App::Netdisco 
Simplest for this use case: echo '10,20,30,40,50,60' | sed 's/\([^,]*\),\([^,]*\)\(,*\)/\2,\1\3/g' 20,10,40,30,60,50 
It's a great introductory. After that, the user can head to bash hackers to refine their skills.
The *website* (more specifically, [this](http://linuxcommand.org/lc3_learning_the_shell.php) series) is perhaps great at explaining basic shell interaction principles, but the book teaches bad practices (as does 99% of all online resources regarding Bash scripting) which later on are very hard to dispose of.
What does you read command look like? if you use `-e`, you can tab-complete the filename. read -e -p "filename: " file printf 'You chose: &lt;%s&gt;\n' "$file"
Thanks! I need to brush up on my sed/regex, some of that looks foreign still.. but I know where to find more detail. Looks like it'll get the job done, so I appreciate the help!
I'm not sure right now what your problem is, if I copy that script I get prompted and can see that the values I'm setting are indeed being stored correctly (i.e., I can print them and see that they have what I expect)
Your code looks fine. The problem is not clear. Perhaps you should have included all the code? What exactly is the problem? Also, rather than pasting into the reddit comment it would be easier to read on pastebin or a github gist. 
Does your data have any quoted fields with embedded commas or newlines? That could throw off the simple answers. https://en.wikipedia.org/wiki/Comma-separated_values
Very nice. Now could that same principal be applied with multiple rows? Because it seems it would count values in a new row as separate variables when they should be a part of their respective column. Would another loop be required for that? 
No, this will work with multiple rows. The block with the for loop and the print statement will be executed once for every line. The BEGIN block will only be executed once (before reading input), but that is an exception. If you have time I can recommend the paper by the original authors. It's written like a tutorial and should be easy to follow if you have programmed in C before. http://doc.cat-v.org/unix/v8/awktut.pdf
That sed command contains a lot of escapes. Is there also a method to display it without the `\` symbols?
In extended regex the parentheses don't need to be escaped, but you can't get around escaping the back references: echo '10,20,30,40,50,60' | sed -r 's/([^,]*),([^,]*)(,*)/\2,\1\3/g'
I'll make the time for a good resource. Thank you!
Thank you! :) 
You can rewrite /u/jaxner's AWK code as well for an arbitrary amount of columns in pure bash: IFS=, while read -a csv; do for ((i=1; i&lt;${#csv[@]}; i+=2)); do t=${csv[$i]} csv[$i]=${csv[$((i-1))]} csv[$((i-1))]=$t done echo "${csv[*]}" done &lt; &lt;(echo '10,20,30,40,50,60') `20,10,40,30,60,50`
Here's four different ways to do it: generatedMD5FromFile=$(sudo md5sum "$pathToFile" | awk '{print $1}') generatedMD5FromFile=$(sudo md5sum "$pathToFile" | sed -r 's/(\S+).*/\1/') read generatedMD5FromFile _ &lt; &lt;(sudo md5sum "$pathToFile") generatedMD5FromFile=$(sudo md5sum "$pathToFile") generatedMD5FromFile=${generatedMD5FromFile%% *} This uses "md5sum", which has output like this: $ md5sum textfiles.zip 80ecacb4d391761ab6e701eaafe1856e textfiles.zip I only have this 'md5sum' and can't find a package for that 'md5' you are using on my distro.
I anticipated that question but I wanted to keep the answer simple. In this case it might be sufficient to write generatedMD5FromFile=$(md5 &lt;$pathToFile) because it seems that some versions of md5 output only the hash when reading from stdin. It's also good to know about these methods: **sed** generatedMD5FromFile=$(md5 $pathToFile | sed 's/.* //') **bash Parameter Expansion** generatedMD5FromFile=$(md5 $pathToFile) generatedMD5FromFile=${generatedMD5FromFile##* } Both will remove everything up to and including the last space. You can also use **awk** like /u/lolmeansilaughed suggested. 
sed -r doesn't work on BSD sed but sed -E works on both BSD and GNU sed. This is not mentioned in the GNU sed manual.
Bigdata needs to be an absolute path. Is your interactive shell bash or sh? What happens when you change the shebang to #!/bin/bash ?
`man [` `man test`
Also, from www.shellcheck.net: $ shellcheck myscript Line 1: [ $[ $RANDOM % 6] = 0 ] ^-- SC2007: Use $((..)) instead of deprecated $[..] `$[ ... ]` is a bit of syntax I've never encountered. Good link: http://unix.stackexchange.com/questions/209833/what-does-a-dollar-sign-followed-by-a-square-bracket-mean-in-bash `$[ ... ]` is now deprecated in favor of `$(( ... ))` `$(( ... ))` is used for arithmetic operators in bash: http://tldp.org/LDP/abs/html/ops.html I'd recommend using `[[ ... ]]` and `$(( ... ))`; also recommend quoting your variables e.g.`"${variables}"` Another good read: http://stackoverflow.com/questions/31255699/double-parenthesis-with-and-without-dollar Thanks /u/jaxner for pointing out that `$RANDOM` is a bash function: http://www.tldp.org/LDP/abs/html/randomvar.html
Sorry, I should have said, that I use OS X. Nevertheless thanks for your answer!
You're right about the zpool, that can't be it. /u/BuffaloFingers has a point. Can you compare $PATH from bash and sh and verify against the location of nc ("which nc")?
I believe it should be 'which'?
Thank you so much!! Is there a way to show the actual number?
No. `type` is a standard, builtin command in posix shells. `which` is a non-standard and rather useless command, unless you're stuck with csh.
&gt;I'd recommend using [[ ... ]] and $(( ... )) So like this? [[ $(($RANDOM % 6)) = 0 ]] If so, why [[ ]] instead of just [] ? Thanks 
Results of that test were: usage: nc [-46DdEFhklnortUuvzZ] [-i interval] [-I bufsiz] [-O bufsiz] So I think it understood nc fine. 
`[[` is bash specific I believe. `[` is a `sh` built in. So it's implementation depends on the OS (I'm not positive though).
Neat. Some `find`-kung-fu right there. The `+` does as a kind of `xargs`, I guess?
Agreed - until we see what the actual error when running from cron is, we're just guessing. You could change your cron entry to something like this: 30 0 * * * /scripts/zfssendBigData.sh &gt; /tmp/cron.log 2&gt;/tmp/cron.log then when it runs, the stdout and stderr get sent to /tmp/cron.log, and you can at least see what the actual error is.
It redirects stderr to /tmp/cron.log as well as stdout.
nope, it just adds up the value of $f to /home/pictures/. It ends up like this /home/pictures//home/pictures/. I did the x=`base64 $f` and cat it to a txtfile. It decodes base64 but with an added line: cat: 33Puoz60lxykDuqM1R6Epj4qxdcnTdQepPi2EXa4o/imtAu65PRY9mIXflBIO/oE8cSbplcLkbrc: No such file or directory cat: rt5jWfFNHVLNUzo4FZGPELtLTuhHiAa2476q6nmVrhVMvulNna4kArLDEDY+cW6JIxEj5nW9e6np: No such file or directory cat: PDWeO3uLdEvxW73WT+P0BDxfsjGLDOBe4T0eGqMrUoPHXRZUYmLm7ze6dOKHOG3Bvt6J7PEaQPaS: No such file or directory cat: hmud1nxiYBtcHWyP7UAadRdPkTy0GcXsjJWd+1AXeXUpRxe+gOo3V9nhoLo7qhbihDQ4m5PQJQxQ: No such file or directory 
You want the output (stdout) of base64 to be written to a file, why not just redirect the stdout of base64 to a file? e.g., `base64 "$f" &gt; "${f}.base64"`; in addition, you need to be careful about the quoting (doublequote/singlequote) to prevent word splitting and filepath globbing behaviours in shell.
I agree. If you are actually writing the files, you don't even need to set variables in the loop: for i in /home/pictures/*; do base64 "$i" &gt; "${i}.b64" done
You can inline the `IFS` definition so it will only be changed for the ~~loop~~ read command e.g. `while IFS=, read -r -a csv`
I'm tying to pass base64 encoded image to an API(google vision api). It only accepts base64 encoded image. I'm encoding the whole image folder. The last thing I tried was image_base64=`base64 $f`. FOLDER=/home/ for f in "$FOLDER"/*; do image_base64=`base64 $f` json_output=`curl -k -s -H "Content-Type: application/json" https://vision.googleapis.com/v1/images:annotate?key= -d '{ "requests":[{ "image":{ "content":"'"$image_base64"'"}, "features":[{ "type":"TEXT_DETECTION", "maxResults":10 }]}]}' echo json_output done 
I got that from the Debian man page so that's very likely.
Which is what I did in my first reply to the OP ;) Glad I'm not the only one who knows about this little IFS-in-a-read-loop magic. 
I didn't know it stayed set for the commands inside the loop, where it was needed for `echo "${csv[*]}"`, but that does indeed work.
I tried this on a few of my systems and didn't realize that if you have a command set up as an alias it will display that output instead of the path... I know this isn't going to be the case in this instance, but this is why I used which instead. I guess this is BASH though and we should be trying to use built-ins when possible
Nothing in cron.log oddly enough. On the receiving end, there was something in the cron log though. Receiving end script is simply "/usr/bin/nc -w 700 -l -p 8023 | /usr/sbin/zfs receive -F backup/netcat/BigData" cannot receive: failed to read from stream Once again, ran the scripts manually today and it worked. 
If I understand you correctly, you mean to say that the day could change, mid script. The cronjob runs at 00:30 so I don't think this is the issue. But I will definitely keep that in mind for future scripts. 
You can use the wc command to count things. If you have a list of files, pipe it to wc -l. The -l counts lines and outputs that count.
Did you make your script executable? I know I had a couple of problems when trying to run a script that wasn't marled executable.
You can get a hold of user input using something like https://github.com/rcaloras/bash-preexec and then filter it as you like.
Well in your .bashrc you could e.g define a function *env* which checks its arguments and then calls the real env command with the arguments. env() { echo "env called with $@" command env "$@" } 
ssh might be waiting for output from cronolog, even though it doesn't produce any. What happens if you redirect stdout to /dev/null? edit: like this ssh -q $server "java -jar $application |cronolog /app/$application/logs/SystemOut_%Y%m%d.log &gt;/dev/null &amp;"
Try puttin the quote inside the &amp;. This will create an ssh session per host and put the ssh session in the background. You may want to wait for all the backgrounded jobs to complete before exiting so putting a wait after the for loop will probably make sense: http://www.tldp.org/LDP/abs/html/x9644.html
D'oh my bad, missed that part.
Use the "read" built-in for the question. 
Thanks! Also have some long shutterspeeds that are not fractions, like 1.3, so thats why I thought of calculating
For the middle loop: found=0 for index in "${!liste_valeur[@]}"; do [[ "${liste_valeur[$index]}" == "$rep" ]] &amp;&amp; found=1 &amp;&amp; break done if [[ $found == 1 ]]; then echo "name is at $index" else echo "name is not found" fi read -p 'Enter new name (or "n" to quit): ' rep
Here's something using 'sed' and 'bc': exposure=$(exiftool -s -ExposureTime "$file" | sed -nr 's/^ExposureTime\s*:\s*(\S+)$/\1/p') if (( $(bc -l &lt;&lt;&lt; "$exposure &lt; 0.0025") )); then echo "exposure is &lt; 0.0025" else echo "exposure is &gt;= 0.0025" fi 'sed' is used to get the "1/15" or "1.3" you mention in another comment out of exiftool's output. This is then used in a short 'bc' program that compares it to 0.0025. When you do comparisons in 'bc', it reports about "true" and "false" just like C, with a zero meaning "false" and any other number meaning "true". The `(( ... ))` in bash also uses those C rules, so you can just stuff the output of 'bc' into that.
Under `until`. `${!liste_valeur[@]}` are all the indexes of the array, to which `$index` gets set. `${liste_valeur[$index]}` become the array elements on those indexes. `break` leaves the loop (and `$index` remains the index at which the name was found). If there are no matches, then `$found` remains 0. Instead of `echo "name is at $index"` you may want to use `echo "name is at $((index+1))"` because the array starts at 0.
It looks like it begins with a 32-character string of lowercase hexadecimal digits. Maybe it's some kind of hash. You can match it with this regular expression: [a-f0-9]{32} To remove that and everything that follows from the last line of a file, assuming that last lines normally doesn't contain this pattern, you can use sed: sed '$s/\/[a-f0-9]\{32\}.*//' jquery.js Normally sed just prints the edited file to stdout. You can edit files in-place with the '-i' option. To edit all javascript files recursively (assuming their filenames end with "js") from some directory you can run find path/to/directory -type f -name '*js' -exec \ sed -i .bak '$s/\/[a-f0-9]\{32\}.*//' {} \; which combines two of the most unreadable unix commands. Backups will be saved with a ".bak" extension.
This sounds like homework. What have you tried so far?
It's a bash exercise so yes, only bash. It's much simple (arguably) in other languages.
Can you get it to work on a single file? Do you get an error when you run sed '$s/\/[a-f0-9]\{32\}.*//' jquery.js What Unix flavor are you using? Linux/BSD/Solaris? sed -i is not defined by POSIX. You can also try the bash globstar feature: shopt -s globstar for file in /var/www/**/*.js; do mv "$file" "$file".bak sed '$s/\/[a-f0-9]\{32\}.*//' "$file".bak &gt; "$file" done 
Thanks a lot mate, unfortunately there was no backup :/
Personally I wouldn't feel comfortable until I blew away the entire VM/server and reinstalled the OS.
Good to know, but shouldn't it work regardless since $file doesn't exist after the mv command?
Make sure your header is exactly what the Google API is looking for. Most of the time these things are case-insensitive, but you may want to try 'Content-Type: Application/JSON' or whatever. Make sure it's not looking for 'text/json' instead. Try adding -X POST to explicitly specify the request type, even though it's implied with the -d. Best practices for curl is to always enclose the URL in single quotes to avoid shell expansion unless you are passing a variable, in which case you should use double-quotes. I typically always put my URL at the very end of the line with all parameters before it. Keep in mind you can combine parameters that don't require arguments, like curl -skX POST, etc. Also you can get verbose output from curl itself with the -v and -i flags. To enable Bash debugging, use set -x and then set +x to disable. Make sure your * is not being expanded to the files in the $PWD. When using variables in a path, I always like to use curly braces to avoid possible issues. In your situation, I would actually probably just cd to the directory and say for i in *. Otherwise, I would use "${FOLDER}"/*.png or something. Use ls to make sure it's actually referencing the correct files. Also, you should try to avoid variables in all caps. The purpose is to avoid overriding default environment variables, but it's more of a coding standard. I used to do it myself all the time because it makes the variables more visible in the code, but old farts on StackExchange will rip you apart for it. It's your code, so it really boils down to personal preference. Just mess with it till it works. EDIT: My asterisks got removed, but you can obviously see where they would be. 
Several days ago, you got examples how 'awk' can split the line into fields where there are commas. Use that, then make it print stuff over several lines with `print $1, $2` then `print $3, $4`, etc. I think the awk program might then look like this (did not try it): BEGIN { FS="," OFS=FS } { print $1, $2 print $3, $4 print $5, $6 print $7, $8 } *EDIT: changed "IFS" to "FS".*
 echo '10,20,30,40,50,60' | sed 's/\([^,]*\),\([^,]*\),/\1,\2\n/g' 10,20 30,40 50,60 columns=(a c) # e.g. I want the first pair and third pair columns_numeric=() count=0 for i in {a..z}; do ((count++)) for col in "${columns[@]}"; do [[ "$col" == "$i" ]] &amp;&amp; columns_numeric+=( $count ) done [[ "${#columns_numeric[@]}" == "${#columns[@]}" ]] &amp;&amp; break done IFS=, echo '10,20,30,40,50,60' | sed 's/\([^,]*\),\([^,]*\),/\1,\2;/g' | cut -d\; --output-delimiter=$'\n' -f "${columns_numeric[*]}" 10,20 50,60 
sed -E ‘s/\}\)\(jQuery\)\;*/})(jQuery);/g’
I said help. not write it.
i just copied and pasted the assignment i left that part in on accident
This seems to work: awk 'BEGIN{FS=",";OFS=FS}{for (i=2;i&lt;=NF;i+=2) {print $(i-1),$i}}' You can try this on the command line to experiment. It waits for you to type. You type things like "1,2,3,4,5,6" or "1,2,3,4,5" and Enter. You finish it by doing Ctrl-D on an empty line. The program looks like this, shown over several lines: BEGIN { FS="," OFS=FS } { for (i = 2; i &lt;= NF; i += 2) { print $(i-1), $i } } What happens there, it seems that '$' selects a field, and you are allowed to use a formula instead of a simple number. With what's shown here, the variable "i" will go through values 2, 4, 6, 8, ... The print then will use $1, $2, then next $3 and $4, then next $5 and $6, ... My experiments on the command line looked like this: $ awk 'BEGIN{FS=",";OFS=FS}{for (i=2;i&lt;=NF;i+=2) {print $(i-1),$i}}' 12,15,462,,4436,346 # &lt;-- this is what I typed 12,15 462, 4436,346 2121,214,2414,4214,4214,141 # &lt;-- this is what I typed 2121,214 2414,4214 4214,141 12,214 # &lt;-- I typed this 12,214 1,2,3,4,5 # &lt;-- ... 1,2 3,4 
ok, so is there an example file or are we assuming `/etc/shadow`?
That never came up because we were discussing something else and I didn't have a need to question why Haskell was used... 
It looks like your submission contains a shell script. To properly format it as code, place four space characters before every line of the script, and a blank line between the script and the rest of the text, like this: This is normal text. #!/bin/bash echo "This is code!" &gt; This is normal text. &gt; &gt; #!/bin/bash &gt; echo "This is code!" *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/bash) if you have any questions or concerns.*
 user@host $ cat input foo #07 02 * * thu root BKUPDB="name" /path/one &gt;/path/two 2&gt;/path/three bar baz I would probably use `perl` for such a task, e.g. user@host $ perl -ple '$_ .= "$/$1 $2 /sbin/reboot$/\@reboot $2 sleep 300; $3$4" if /^#?(.+?) (\S+) (BKUPDB=\S+)(.*)/' input foo #07 02 * * thu root BKUPDB="name" /path/one &gt;/path/two 2&gt;/path/three 07 02 * * thu root /sbin/reboot @reboot root sleep 300; BKUPDB="name" /path/one &gt;/path/two 2&gt;/path/three bar baz If you specifically wanted to use `awk` you could probably process the lines by *"columns"*, something like: user@host $ awk '{ print } /^#?[0-9]+ [0-9]+.*BKUPDB=/ { sub(/^#/, "", $1) print $1, $2, $3, $4, $5, $6, "/sbin/reboot" line = "@reboot " $6 " sleep 300;" for (i = 7; i&lt;=NF; i++) line = line " " $i print line }' input foo #07 02 * * thu root BKUPDB="name" /path/one &gt;/path/two 2&gt;/path/three 07 02 * * thu root /sbin/reboot @reboot root sleep 300; BKUPDB="name" /path/one &gt;/path/two 2&gt;/path/three bar baz Will the lines you want to process always be commented? Will they always have minutes and hours as the first 2 *"columns"*? Is is possible either of them could be `*`?
Hi thanks for the interest. I guess perl will be fine (will need to check though I believe all the servers have perl) Yes the lines will always be commented Yes they will always have minutes &amp; hours after the hash (though the minutes, hours will be different) No * (asterisk) at all. Basically they are all servers with the same format in the crontab. Once I manage the I will be using puppet to send the command to all servers. Cheers
i did
&gt; Mailgun erm which language to use to send from terminal? 
&gt;what do I do to make this work? You need to write a brand new script.
The home page has an example using cURL. Did you even open the page? Here are the docs: https://documentation.mailgun.com/quickstart.html#quickstart-guide
That is 100% ***not*** what I said. 
yes it says ./sendmail: line 8: curl: command not found
Did you try googling "curl: command not found"? It means you haven't installed curl, like /u/Bbannakaffalatta says. Figure out how to install it for your system and then the curl example will work.
&gt; bash parse-cron &lt; input foo #07 02 * * thu root BKUPDB="name" /path/one &gt;/path/two 2&gt;/path/three 07 02 * * thu root /sbin/reboot @reboot root sleep 300; BKUPDB="name" /path/one &gt;/path/two 2&gt;/path/three EDITED: Ah I think I get what you mean. So I have done the below: bash parse-cron &lt; input &gt;&gt; test &amp; it's looking promising. Would it be possible within the script to change the "name" to whatever depending on which server it is? So at the moment I believe I need a file "input" in this case with the command in it to pass to the "test" file. In which case I might have a problem as the file is "crontab" bash parse-cron &lt; crontab &gt;&gt; ??? Just looking at your other one liner perl -i -lpe '$_ .= "$/$1 $2 /sbin/reboot$/\@reboot $2 sleep 300; $3$4" if /^#?(.+?) (\S+) (TIMSDB=\S+)(.*)/' test which actually does the job nicely so maybe this could work if I can figure out how to also change the "name" part accordingly. Thanks EDIT2 Actually the perl one liner may work on it's own as I will be deploying it via puppet! Once I get to work I will give it a go &amp; let you know - Just realised I need to have a hash # in front of the line: @reboot root sleep 300; BKUPDB="name" /path/one &gt;/path/two 2&gt;/path/three When I try a hash in front of @reboot perl -lpe '$_ .= "$/$1 $2 /sbin/reboot$/\#@reboot $2 sleep 300; $3$4" if /^?(.+?) (\S+) (TIMSDB=\S+)(.*)/' test3 I get # root sleep 300; BKUPDB="name" /path/one &gt;/path/two 2&gt;/path/three Any ideas would be appreciated.. Ok manage to get the command perl -lpe '$_ .= "$/$1 $2 /sbin/reboot$/\#\@reboot\ $2 sleep 300; $3$4" if /^?(.+?) (\S+) (TIMSDB=\S+)(.*)/' test Cheers again for your help
It's in case the variable contains spaces.
Ohhhh, okay. I was thinking in terms of file names, and it's been a long time since I've named something with spaces.
Also note that a dot is not a valid variable character. When you reference a variable, those characters won't be part of the variable substitution, so you can do: `$file.$extension`
This one worked like a charm! Thanks for the assist.
 for image in *.jpg.*; do mv ${image} ${image%.*}; done This uses bash parameter substitution. `${string%substring}` Deletes shortest match of $substring from back of $string. It also works with glob wildcards such as `*` Depending on your actual filenames, you might have to change the first glob expression to `*.*.*` or `*.*.[0-9]*` or something like that to process all the mangled filenames. NB: If you have multiple files that would get the same name, you'll get an error. For instance foo.jpg.001 and foo.jpg.002 will both end up as foo.jpg, so the mv command will fail. Make a backup of all the files before renaming them, in case something like this happens.
You can do a lot of stuff with `history`. I don't know if there's a setting that will do exactly you want out of the box. But since your history file is just a text file, you can manipulate it in any way you want. You can write a short script to eliminate duplicate entries, and run that as part of your `$PROMPT_COMMAND`, for instance.
&gt; and the -delete flag. You should probably tell the n00b to do a dry-run first without the `-delete` flag.
&gt;*.pdb fooling with some old palmpilot files?
I do this with `vim` by hand. I always meant to write a script. You would want to save the last 100 entries or so, in order. Often I'll find myself editing my history and turning it into a script, after I've done an odd operation once by hand. You may also want to remove all the commands that start with `ls` or `cd` To edit my history file I use the following function: eh () { # `eh` stands for `edit history` history -a; #save your current history to file vi + ~/.bash_history; #edit with vim, start at last line in file history -r #reload history from file } inside `vim` you can sort and eliminate dups with the following: :sort u to remove all the lines that start with `cd` and then have a space (and probably a directory): :g/^cd /d likewise, to remove all your `git status` commands: :g/^git status/d To quit `vim` without saving your changes: :q!
putting a : before a command will not execute that command, the exit status is always 0
so these commands should not run correct? 
if you do something like :' #no space ' any code within the quotes will result to error : ' #space ' any code withing the quotes will not execute
 HISTCONTROL=ignorespace:erasedups add this to your `~/.bashrc` `erasedups` is what you want `ignorespace` will let you avoid command going into history if you put a space before command and you can use set +o history to switch off writing to history until you use `set -o history` or close that session
&gt; Make a backup of all the files before renaming them, in case something like this happens. Just a tip, whenever you're working on something like this, replace `mv`with `echo` until you're certain you're going to get the results you want. Still probably worth doing a backup, but in general when you're working on one-liners, measure twice, cut once. ___ ^^Responding ^^to ^^OP ^^to ^^make ^^sure ^^they ^^see ^^this, ^^but ^^cc ^^/u/Vitrivius 
To add on to this, there is also `ignoredups` which is not as aggressive as `erasedups`. `ignoredups` - Removes only consecutive repeated commands i.e the same command entered multiple times successively. `erasedups` - Removes **all** previous occurrences of a command, even non-consecutive ones. If you enter these commands: clear ls clear clear If `ignoredups` is enabled, `history` will give you: clear ls clear If `erasedups` is enabled, `history` will give you: ls clear Note that even the first clear has been deleted. 
Or just move/copy them to a new directory and delete the old one. Doesn't matter which if you're deleting stuff anyways. $ mv ./dir/*/*.pdb ./pdb/ ; rm -r ./dir/ If you want to preserve directory structure you can copy recursively I think with cp -r. Somebody correct me if I'm wrong though. $ cp -r ./dir/*/*.pdb/.. ./pdb/ ; rm -r ./dir/ It's all in the man pages though. I'm on mobile so I'm not gonna link anything but it's there. 
Experience is what you get 2 seconds after you needed it
The `:` syntax goes all the way back to Unix v6. It predates bash, and even the original Bourne shell. It's original purpose was to place labels for the `goto` command. http://man.cat-v.org/unix-6th/1/goto It's equivalent in functionality with the `true` command, first introduced in Unix v7. It used to be that `:` was a shell builtin but `true` was not so `:` was preferred for efficiency. In your example it seems to be used to comment out sections of code similar to the C syntax `/* */`.
To protect against empty variables, one thing you can do is: rm -rf ${basedir:?}/${otherdir:?} The `${varname:?message}` expansion prints an error message (or a default value if you don’t provide a message) and then exits if the variable is null or empty. Also don’t forget quoting: rm -rf "${basedir:?}/${otherdir:?}" And the variable might begin with a dash, so ensure that it won’t be misinterpreted as an option: rm -rf -- "${basedir:?}/${otherdir:?}"
You should also be able to use `set -u` at the top of the script (after the she-bang) to make any script exit if you use an undefined variable. Edit: Removed link with good strict mode tips, but shitty advice otherwise.
Thanks for removing it, and for your otherwise good advice.
Let's see if I remember next time the question comes up. :-)
 for image in "$FOLDER"/*; do BASE64_IMAGE=$(cat $image | base64 -) done; change my code to this. thank you all for the reply! :) 
Actually when I run the file manually on a local machine I get error. I can see the same error.
Yeah ! The script has to run in the target folder.
If that's all the information you're prepared to give, I won't be able to help track down the problem.
I like libnmap for this! Im currently using it for my oscp course, i have it parse the iutput and store all the data in a psql database
You're localing/declaring both positional and named arguments twice if I read it right and you can use a counter for the positional arguments: function my_func() { local arg arg_count=1 for arg in "$@"; do [[ "$arg" == *=* ]] &amp;&amp; local "$arg" || local pos_arg$((arg_count++))="$arg" shift done }
i don't know that, i can use the module on my script? ty
In your version variable won't be local'ed if it is not specified among arguments, causing the value of the global variable with the same name as one of the optional arguments to leak inside the function. Original version prevents that by localing all declared vars first. You also lose the default values for optional args and descriptive names for positional args.
Not OP, but have used the python nmap module before. You can just run the scan from your python script directly using the nmap module so won't have to bother piping text into your script. Install it with `pip install python-nmap`, then in your script `import nmap`. There's some examples its PyPI page https://pypi.python.org/pypi/python-nmap/0.5.0-1 
No magic here. Let's use bash 4's associative arrays instead :)
&gt; In the original positional arguments are not restricted to the names like pos_argN. I see what you mean now. I guess that's not really possible to do dynamically.
It's good to explore all the possible ways to accomplish something, and I'll admit that this matches his use case better. That being said, the reason I'm pinching off the latest 100 lines and then adding them back in unaltered is that I may at any time go back and edit a series of commands into a quick and dirty script or a function or something. I want everything intact, including any comments I left for future self. # add permission to use serial port by adding a group sudo usermod -aG dialout $USER # OK, now figure out how to apply this permission w/o # logging out, and then logging back in again # this _will_ become a script after all... newgrp dialout # applies new group permissions w/o logout
oh thanks so much man!! i've upvoted you but if u post on stackexchange i can set you as "correct answer" :)
This is the correct way to show. The rest is noise.
What are you trying to do? Why are you doing it in bash?
Probably because curl doesn't execute any javascript, which fb uses quite a lot. Or, your curl connection is not logged in like your Firefox connection is.
Curl is making a separate request apart from your browser. It's not authenticated. here's a page about it from facebook. https://developers.facebook.com/docs/pages/access-tokens You need to set the page_access_token
I downloaded the cookies first with the --cookie-jar command while logging in with the --user and then used cur again with the --user command and the --cookie command which downloaded the page but just didnt have the date of birth in it which i was able to see through the firefox browser. Im still pretty new to bash ive only been studying it for about 6 months. If its because its not executing javascript how would i go about doing that? Im pretty sure i got the cookies part down because they download into a file where i reuse them. And thank you LoveandRockets ill check it out and get back to you.
Go with phantom.js or any other headless browser if you need to execute javascript. I'm pretty sure facebook uses js for everything data related now since react and other libraries are out. Another thing that might happen is that facebook does log you out even when you send the cookies because curl uses a different user agent (in other words: facebook detects that you are using a different browser and logs you out because of security concerns.). For what you are trying to achieve, a headless browser is your best bet in this scenario. I used phantom.js a few years ago to crawl data from Facebook and it was fairly simple apart from the login mechanic. You might have to use node.js but you can call that bash. 
Works for me. When you say: &gt; as you can see by loading the new shell and writing &gt; &gt; bash --version what did you do? If you did this: ./bash # start the edited bash # in that bash bash --version then you were running the *original* `bash` with that `bash --version` command. What you need to do instead is: ./bash --version # use the edited bash from any shell. When you write `bash --version`, you’re not asking the *current* shell for its version, you’re launching a new shell and asking *that* for its version (it will then subsequently terminate itself). --- Also, when editing strings in a binary file, you need to take care to preserve the length of the string, but you already did that (with the extra `_` in `Copy_left` so that it’s as long as `Copyright`).
I think this might be the culprit: exec &lt; /dev/null 2&lt;&amp;1 There’s only one standard input, and it has file descriptor 0. I don’t know what this exec line will do, but it seems plausible that it would mangle the file. Try replacing it with this: exec &lt; /dev/null --- Also, `typeset` is obsolete – use `declare` instead.
I made both changes. While the script still works, the log file is empty.
Thank you so much for your help ill get back to you once i get it to work and figure out how to do it
Make a script that reads through a webpage and pulls out any valid IPv4 addresses.
There's a few bad habits in this script. Paste it into http://shellcheck.net and fix up what that brings up. Nonetheless, it looks like you need to look at `cron`.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/unix] [\[Question\] Mysterious 23 minute increase (Posted in \/r\/bash)](https://np.reddit.com/r/unix/comments/4in782/question_mysterious_23_minute_increase_posted_in/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
file.sh has : python abc.py #This python writes some content to text file named sample.txt //Some processing on sample.txt 
`/target` contains the right versions of both `file.sh` and `abc.py`? And where does the error occur?
look up functions and aliases: http://mywiki.wooledge.org/BashGuide/CompoundCommands#Functions and file tests like `-e`, `-f` etc: http://mywiki.wooledge.org/BashGuide/TestsAndConditionals
Check out `atd` - it lets you run things at a specified time. You could write a simpler script to execute the screen shots and then just let `atd` take care of all of the scheduling stuff. 
Maybe this will do? unalias subl # function definition will fail if the alias still exists subl() { open -a 'Sublime Text 2' "${@--n}"; }
Thanks I created it below. Putting her for reference if anyone wants it. # opens a text file with sublime function subl { #if no argument passed, open sublime if [ ! "$1" ]; then open -a Sublime\ Text\ 2 # if argument is an existing file, open existing file with sublime elif [ -f $1 ]; then open -a Sublime\ Text\ 2 $1 # create a new file and open with sublime else touch $1 &amp;&amp; open -a Sublime\ Text\ 2 $1 fi } 
ps -ef | grep PROCESS | grep -v grep | awk '{print $2}' | xargs kill -9
 #! /bin/bash variable=$(cat &lt;&lt; '_EOF_' eval "$(ls)" _EOF_) echo $variable Wrap the bit with $() and don't forget single quotes around the first _EOF_.
If you quote the delimiter of your here document (`EOF` in this case), then Bash won't do any expansion or substitution on the lines of the here document. cat &gt;&gt;~/.zshrc &lt;&lt;'EOF' eval "$(x --alias y)" EOF See the "Here Documents" section of the [man page](http://linux.die.net/man/1/bash) for details.
For your specific example, you can avoid "grep -v" by using "grep [P]ROCESS". It's good to work with awk and xargs, but here I think pkill mentioned above will get you there quicker. Or a for loop with pgrep if something has spawned a bunch of runaway processes. Something like for p in `pgrep PROCESSS`; do kill -9 $p; done You could put echo before "kill -9" to make sure you're getting what you want. But it almost sounds like what OP is asking for is an init script, so I don't really know. 
 for ((i=$rounds;i&gt;0;i--)); do string=$(sha256sum &lt;&lt;&lt; "$string") string=${string%% *} done echo "$string"
Well `command1 &amp;&amp; command2` will run `command2` if `command1` exits successfully. (so it will wait until it finishes) If you don't want to wait for it to exit use `&amp;` which will run it in the background e.g. export -f function command1 &amp; xterm -hold -e function
Thanks mate! :D
Great minds think alike ;-)
Friendly tip - run your script through shellcheck.net to check your script for syntax errors or problematic omittions. This is what I got: Line 12: CMD="PATH=\"$NEW_PATH\" ./run-tests.sh &gt;$OUT_FILE 2&gt;&amp;1;" ^-- SC2089: Quotes/backslashes will be treated literally. Use an array. Line 13: echo $CMD ^-- SC2090: Quotes/backslashes in this variable will not be respected. ^-- SC2086: Double quote to prevent globbing and word splitting. Line 17: grep -lir FAIL $OUT_DIR ^-- SC2086: Double quote to prevent globbing and word splitting.
When would that ever be useful? Emergency shutdown?
Try using echo with "-n" parameter (doesn't output a newline character after string). $ echo "bla" | sha256sum 00e3261a6e0d79c329445acd540fb2b07187a0dcf6017065c8814010283ac67f - $ echo -n "bla" | sha256sum 4df3c3f68fcc83b27e9d42c90431a72499f17875c81a599b566c9889b9696703 - Something to keep in mind when using echo against hashing (or in general), especially if you are going to try to validate the hashes somewhere else. Edit: I know this isn't entirely relevant to your comment, but I just figured I would point out in case/for others.
A blank line is the correct answer. I'm assuming your lecturer is expecting people to answer with `The first line from /etc/passwd` or `hello world` Because the `read` command is happening in a pipeline the variable `x` is being set in a subshell and not the current shell. (each item in a pipeline runs in its own subshell) Compare: user@host $ echo hello world | read x &lt; /etc/passwd user@host $ echo $x user@host $ To: user@host $ echo hello world | { read x &lt; /etc/passwd; echo $x; } root:x:0:0:root:/root:/bin/bash As you can see `x` is being set to the first line of `/etc/passwd` but it only exists in the subshell.
from [piping input into read](http://stackoverflow.com/questions/13763942/bash-why-piping-input-to-read-only-works-when-fed-into-while-read-const) &gt; Under bash (and other shell also), when you pipe something by using | to another command, you will implicitely create a fork, a subshell who's a child of current session and who can't affect current session's environ. &gt; 
This is how tabs are supposed to work. They move you forward to the start of the next 8-character column. If you don't want that behavior, then you'll need to output a series of spaces instead.
Perhaps you'd like this here better: printf '%-7s %s\n' "foo" "bar" printf '%-7s %s\n' "foooooo" "bar" printf '%-7s %s\n' "fooooooo" "bar" printf '%-7s %s\n' "foooooooo" "bar" It will use spaces and there won't be a jump if the text gets too wide for the column.
 jq -c '.array[]' $JSON | while IFS= read obj do echo $obj done Ftfy. You can do code highlighting by putting four spaces at the start of each line of code.
I'm gonna try it, hope it works thanks :D
 #!/bin/sh FIRST=0 while [ $FIRST -le 99 ] do SECOND=0 while [ $SECOND -le 99 ] do ID=$FIRST.$SECOND echo $ID SECOND=`expr $SECOND + 1` done FIRST=`expr $FIRST + 1` done
The variable will show up if you do: export seven
This is not true. As he said it incremented to 99 properly but never reset to 0 in the next outer loop. 
Thanks! New to reddit - so I had no idea.
Funny alternative: `seq -w 0 9999 | sed 's/../&amp;./'`
No problem! BTW, the same formatting works on StackExchange sites.
 echo {0..99}.{0..99}
Oh thanks :D, and if i have more than 1 variable?
OP echoes $FIRST.$SECOND and gets results from 0.0 to 0.99, so SECOND gets incremented to 99 first. Then it never gets back into the inner loop, so $FIRST gets incremented to 99 but never echoed again. 
This is the best bash solution I think. To print the numbers one line at a time you can use `printf`: printf '%s\n' {0..99}.{0..99} This will produce the exact same output as op's example but much faster since it doesn't use `expr`. Other series which might be of interest are: printf '%s\n' {0..99}.{00..99} printf '%s\n' {00..99}.{00..99} To see how they differ you can use diff: diff &lt;(printf '%s\n' {0..99}.{0..99}) &lt;(printf '%s\n' {0..99}.{00..99}) 
Thanks! I choose the method with the arrays, and It works so far. I only have a problem with getting the values of the arrays outside of the scope (?) of my function. Screens=() Resolutions=() getScreens(){ screens=$(xrandr | grep \* | cut -d' ' -f4) numberOfScreens=$(xrandr | grep \* | cut -d' ' -f4 | wc -l) for i in $(seq 1 $numberOfScreens) do Screens[$i]+=Screen"$i" Resolutions[$i]+=$(xrandr | grep \* | cut -d' ' -f4 | sed -n "$i"p) echo ${Screens[$i]} echo ${Resolutions[$i]} done } When I call echo $(getScreens) I get this result boxer ➤ ./boxer.sh Screen1 1366x768 Screen2 1920x1080 when I call echo ${Screens[1]} echo ${Resolutions[1]} outside of the function I get nothing, of course because it's not in the scope. I tried return Screens[$i]+=Screen"$i" return Resolutions[$i]+=$(xrandr | grep \* | cut -d' ' -f4 | sed -n "$i"p) with the resulting error that it's not a numeric value. How could I go on from here?
Thanks man, I was not quite sure where to put the second part, so I created another for loop looping through the echo and as long as it stayed in my function it was okay I called this from outside of the function echo $(getScreens) and got the values, but when I called the variables outside of the function I didn't get anything. I also tried return without any results. I only know how to get a value out of a function with return $var but it's not working with non-numeric values in bash..
&gt; Yeah don't do that. Check! Thanks for this! Would you mind explaining me what the bottom part does, or actually what getScreens in the beginning does? I understand that on top I created the function. I understand that $(getScreens()) executes the function and does whatever the function does, but what does getScreens do here? You have been a great help with fixing my problem, now I'm curious how the solution works!
I think you could use wmutils to do this. It already has programs to list window IDs and get currently or next window. It is on github.
A few points of feedback on style: Don't use uppercase variables unless you mean to. It's safer to use lowercase, snake_case, camelCase etc Use `printf` instead of `echo`, it's more portable, more powerful, and in a lot of cases faster. In `bash`, use `[[]]` rather than `[]`, it's more robust and featureful. Put your `then`'s and `do`'s on the same line as your `for`'s, `if`'s and `while`'s. Choose an indentation standard and stick with it. I use two spaces, mostly because I code portably and need the horizontal space should I have to look at a script in classic `vi` when I'm sysadmining on an ancient Solaris or HPUX box. Take the last three and by way of example: if [ "$1" = "stop" ] then mocp -x fi Becomes if [[ "$1" = "stop" ]]; then mocp -x fi In terms of portability, it may be useful to keep your own index file and select file names randomly from it. `shuf` isn't installed everywhere (nor is a version of `sort` with `-R`, if you were thinking of that), so if you want your script to be portable you have to cater for that. How you manage such a file is up to you.
Is this something that absolutely must be done in `bash`? I mean, this would be a great scripting exercise, but there are great tools out there already like `bacula`.
Aside from your `printf` advice and then flipping to your bracket advice, I'd have to agree with everything. Single brackets are more portable. 
I'm using xdotool (something like that; it's weekend night and I had $i beer and stuff, so I can't check) but in the end the base for my tool is 'on what screen is my cursor ' and i could not do this with wmutils :/ That's why I used xstuff, it brings everything :D including widow titled and IDs! So useful, I'll comment tomorrow with the actual name :) 
ah, amazing! I kept getting confused as to how to incorporate the `”$REPLY”`/`”$(REPLY)”` within the `[…]` statement...`[[…]]` did the trick. Thank you!
boom….I just ran `brew install shellcheck` as well and it’s cookin’…thanks x2!
&gt; head -n-15 `man head` tells me that it outputs lines from the file, but I do not need to look into the files?
I don't understand how xargs delimiter works with \\n (newline?) and stat (status of file). Any chance you could give me a rundown?
Thank you very much for your walkthrough :) I will go through testing and adjusting this for my setup!
Thanks for the advice! I'm still new to bash scripting and can make use of that. The "put your then's and do's on the same line as your for's and if's and while's" for example makes a lot of sense, coming to think about it. Also, in #bash they told me the same thing about variables: Only systemwide variables like EDITOR or PATH should be uppercase, else lowercase. Guess [Jason Cannon's "Shell Scripting"](https://www.amazon.com/Shell-Scripting-Automate-Command-Programming-ebook/dp/B015FZAXU6) was wrong about that. ;) Keeping my own index file is what I plan to do next. Again, the #bash elders advised something similiar: To keep all mp3s filenames in an array. That might hog some memory but it supposedly faster than searching the whole filesystem.
&gt; but turns out I cant really make it without some additional scripts and I want to make on on my own. however I cant think of anything that is actually possible to write in pure .sh format. Shell command language is a full Turing-complete language that can technically do anything that any other interpreted language can do. (Whether you would *want* to do some things in shell command language is another matter. It's a very awkward and sometimes slow language for some things.) I've written a few somewhat large [programs](http://git.proteanos.com/prokit/prokit.git/tree/src) in shell command language, including a [self-hosting compiler](http://git.pehjota.net/eggshell/eggshell.git/tree/eshtrans), and some curses-like TUI programs (like a PONG game demo and an interactive application, both without using other programs like dialog or whiptail). I've written shell scripts to automatically install OSes, manage configuration files, build software packages, etc. I've even done OOP and implemented goto in SCL. Older versions of a lightweight [package manager](https://dev.openwrt.org/browser/trunk/openwrt/scripts/ipkg?rev=4287) (like dpkg+APT) were written in SCL. I know of at least one [blog engine](http://shebang.ws/fugitive-readme.html) that's [written in SCL](http://clandest.in/fugitive/tree/). A few ACME clients for Let's Encrypt are written in SCL. Other examples include [debootstrap](https://anonscm.debian.org/cgit/d-i/debootstrap.git/tree/), much of debian-installer, many programs in Debian's [devscripts](https://anonscm.debian.org/cgit/collab-maint/devscripts.git/tree/scripts) package, and [FAI](https://github.com/faiproject/fai). I've even seen games that people have written in sed, which is a far more awkward, limited, and incomprehensible language than SCL is. So, there isn't really a limit to what you can do in SCL or any other language. You can do almost anything with it, although it's really only popular in software build and distribution tools, installers, utility scripts, etc. Some projects are written primarily in shell command language, but many projects use SCL *somewhere* (e.g. in their build system and/or in a scripts directory) even if their primary languages are C or something else.
&gt;I don't think this is really necessary, since another "song 4" for example reshuffles 4 different random songs anyway. In #2, I point out that every time you run this line of code: SONGNAME=$(find "$MUSICDIR" -type f -name '*.mp3' | shuf -n1) it searches your *entire* music directory for *every single song*, then feeds the *entire* list to `shuf`, which randomly arranges *every single song* into a *wholly random list* just so you can pop off *only* the top one song, the one on top of the list. If you ask for 3 random songs you get three shuffles. How much time does this line take to run? Try running this from the command line: time find /home/agopo/Music -type f -iname "*.mp3" |shuf -n1 ( `-iname` is better than `-name` because it will find valid songs named `Song.MP3`) Since you're repeating the exact same `find` search, I think `find` is smart enough to cache the results, but I also think it's slower than optimal. Especially when you have possible *thousands* of songs on possibly a really slow USB 2.0 flash drive to churn through every time. A faster algorithm would be to generate the list once, in no particular order, count how long the list is, ( `wc -l` ), and save that number as $x, and then each time you want a random song, you just need to generate a random number between 1 and $x. The only time you need to do a new `find`is when you add or remove songs. Even that task can be offloaded to `cron` or something and run in the background, so with 10 or 10,000 songs you never notice any delay. ---- One more thought. Will your code still run OK if you somehow get an MP3 with a space in the filename? 
Quotes, yes. Brackets are mostly redundant. More a question of style than anything else.
Bats features is very limited. Using tests.sh it's possible to run even background tasks required for testing (like daemons).
These are my two tests: 1) Will my code pass shellcheck? 2) Will my code work on Solaris-9/FreeBSD-7/RedHat-7? If my bash code works on bash 2.0.5, then I consider it effectively bash-portable and very easily POSIXified or further regressed to, say, SVR4. Yes, Solaris 9, FreeBSD-7 and RedHat-7 (no, not RHEL-7) are, very sadly, real world production cases.
I go through all the things I know could be problematic. Probably the same as you'd test for with your unit tests.
amen to that! When I was teaching intro to Linux courses we spent an hour or so on how to RTFM. I should re-do that bit as a blog post...
It will not work now, because I do not use outdated OSes in the production. However, the fact that it will not run on the systems you've listed it does not mean, that it it's useless. It's obvious, that it's very hard to implement compatibility with vast amount of OSes being single developer. It's even irrational to do it by myself, when I do have task at hand and modern environment, where written tools will be launched to the production. Also, the fact it will not pass shellcheck does not mean it's useless. It's already working with modern versions of bash, so it's not useless by definition.
It looks like your submission contains a shell script. To properly format it as code, place four space characters before every line of the script, and a blank line between the script and the rest of the text, like this: This is normal text. #!/bin/bash echo "This is code!" &gt; This is normal text. &gt; &gt; #!/bin/bash &gt; echo "This is code!" *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/bash) if you have any questions or concerns.*
Thank you bot !
How are you running it? what did you input? What did you expect to happen? What happened instead?
I ran it like: ./CompileASM nameFile I expected to get the final executable file "nameFile" that I could run with "./nameFile" Instead I get some errors that I can't report right now cause I'm on mobile, i'll reply again when I get home. Meanwhile if you could give me some ideas on how it should be done something like this I would be really greatful.
Use Make.
[Here](http://pastebin.com/YJeShiTB) is the output of that. It seems to have issues with the destination directory now. 
Thanks a lot, everything works fine now.
I could. But i would like to start learning Bash, so i took this problem i had to learn a bit of Bash.
The reason I suggest make, is because it's specifically for this. Right tool for the job.
&gt; for name in "$@"; do Little-known fact: the above can be shortened to for name do 
Oh, I see. I'm talking about testing tools written in any language, not bash.
This here seems to work for me: array=("e f" "a b" "c d") mapfile -t array &lt; &lt;( printf "%s\n" "${array[@]}" | sort ) I experimented like this on the command line: $ array=("e f" "a b" "c d") $ printf "%s\n" "${array[@]}" e f a b c d $ mapfile -t array &lt; &lt;( printf "%s\n" "${array[@]}" | sort ) $ printf "%s\n" "${array[@]}" a b c d e f $ echo "${!array[@]}" 0 1 2 $ echo "${array[0]}" a b $ echo "${array[1]}" c d This "mapfile" isn't available in older bash versions. For those, perhaps this here would be good: { array=() while read -r line; do array+=("$line") done } &lt; &lt;( printf "%s\n" "${array[@]}" | sort ) Here's trying that on the command line: $ array=("e f" "a b" "c d") $ { array=(); while read -r x; do array+=("$x"); done; } &lt; &lt;( printf "%s\n" "${array[@]}" | sort ) $ printf "%s\n" "${array[@]}" a b c d e f $ echo "${#array[@]}" 3 
I seem to have gotten the sorting to work by doing: IFS=$'\n' sorted=($(sort &lt;&lt;&lt;"${array[*]}")) unset IFS Now I just need to figure out how to split it into 3 separate arrays, and then add special cases for a couple of them. 
Google.
This has quite a bit of information about Bash on Windows. I'm not sure it directly spells out what you're looking for but it should give clues. I was able to find this by searching Google for your post title. http://www.howtogeek.com/249966/how-to-install-and-use-the-linux-bash-shell-on-windows-10/
See if ftab shows you. 
Are you looking for something that will automate pressing enter and the input? If so, maybe you're looking for [expect scripts](https://en.wikipedia.org/wiki/Expect). The expect script will generate the "enters' that you want.
Something like this? echo -e "set querytype=soa\nwww.google.com" | nslookup
Ok, don't know how to do the enterthingy in bash, I'd use `expect` if it was necessary. But, if you only wan't to do `nslookup` you can call it in a non-interactive way. `nslookup -type=SOA www.google.com` will produce the same result as your example.
Also, before cracking your teeth on the somewhat archaic syntax of `expect`, have a look at `autoexpect`, it can create most of the script for you by recording a session.
Thank you a lot! That was exactly what I was searching for :)!
I will try this out later. Maybe I can adapt "echo -e" for some other stuff as well. Thank you!
bash only supports integer arithmetic because (in the opinion of the author) there's no need for it to do more. It would duplicate the functionality of the `bc` program (which is the preferred language for floating point math, unlike `awk` which is primarily designed for text manipulation). Two current POSIX-derived shells support floating point shell mathemetics: [zsh](http://zsh.sf.net) and [yash](http://yash.osdn.jp). Their floating point math implementations can be a bit buggy with rounding errors and locale-related snags. If you care about accuracy and reliability, use `bc` instead. 
GNU expect program is for exactly that. But the real question is why are you using nslookup over dig?
`bc` is part of the standard POSIX command set, so it should be there on any compliant system. Strange that arch didn't install it.
If I recall correctly centos 6 minimal doesn't include *bc* either.
I am simply contemplating zsh at this point :)
Check `$?` variable. If its != 0 something go wrong. true echo $? # will be 0 false echo $? # will be 1
None of those suggestions make any sense. For `nslookup`, you can simply do: `nslookup -query=soa www.google.com` You don't have to do complicate &lt;&lt;EOF stuff.
I do realize that it's normal to give floating point instead of an error. I guess I was just expressing to him/her that their exact example (4/3) still won't give a floating point like some other languages. Take perl, for example: #!/usr/bin/perl use strict; use warnings; my $i = 4/3; print $i or perhaps javascript var i = 4/3; console.log(i); Both of these will result in 1.333333333, which is expected. In zsh or bash or other shells, 4/3 will return 1. 
Well the question was "why doesn't this give float output?". The answer is because it's just not implemented in BASH. ZSH can handle it, but it's not the best at it. You should just use the best fitting tools ,and bc is absolutely what you should be using if you are doing any semi-complex floating point mathematics. 
check out the edit, try it out yourself! :D It works! FEELS THE BEST.
Check out the end product! :D
check if this helps http://stackoverflow.com/questions/27392410/how-to-check-if-grep-has-no-output
What do you mean with "it fails"? Can you explain with more details? Perhaps when you wrote your example here, you overlooked an important difference to your real script? For me, there's no error with your example.
You know what, you're right. The errors were not due to what I said - they were because the filenames have spaces in them, so grep sees the filename as many files, but the filesystem returns no such file or directory. Try it create a file like touch 'thou shalt not use spaces in filename!' And do the command. Thank you for helping me clear that up! 
If I understand you right, something like this would work: for file in *; do grep 'foo' "$file" &amp;&gt; /dev/null &amp;&amp; echo "$file" done If grep fails, it moves on. If it succeeds it prints "$file" Another way to look at it is: for file in *; do if grep 'foo' "$file" &amp;&gt; /dev/null; then echo "$file" fi done Of course, you can replace "echo $file" with whatever you want. If I've misunderstood your intentions, explain a little more about what you're trying to do.
Thanks. On a side note while I'm in the kingdom of bash, the combination of &amp;amp; and &gt; in bash is something I never understood. I understand what "&gt;" means and also "&amp;amp;" alone. Does the operation of "&amp;amp;&gt;" together follow from the meanings of the characters by themselves?
It's not related to what the single `&amp;` does. It's only related to the `&gt;`. It redirects both normal output and error output into a file. The usual `&gt;` only redirects normal output into a file, and error messages still go to the screen. It is a short version of this here: something &gt; filename 2&gt;&amp;1 That `2&gt;&amp;1` makes error messages go to the same spot as where normal output goes.
Thanks. Love this sub, always great conversations.
Of course if I want to only get rid of THESE errors and still be able to catch others, this isnt great.
oh wow, great. thanks!
The classic Unix solution to this is `ed`: # set up the demonstration $ cd /tmp $ cat &gt; wp.config &lt;&lt; 'EOF' define('DB_NAME', 'database_name_here'); define('DB_USER', 'username_here'); define('DB_PASSWORD', 'password_here'); define('DB_HOST', 'localhost'); EOF # edit the file $ ed wp.config &lt;&lt; 'EOF' /DB_NAME/ s/database_name_here/my_database/ /DB_USER/ s/username_here/wpuser/ /DB_PASSWORD/ s/password_here/hunter2/ w q EOF 
Insufficient information. Your question makes no sense.
So basically you're starting an interactive mysql session from your script? Then just use mysql's quit command when you're done, or type Ctrl-D (the end of file character).
Yeah that's a good idea.
`xdg-open http://127.0.0.1` does the job for me, at least with Firefox.
Most browsers fork if an existing instance is found: $ chromium google.com Created new window in existing browser session. #it actually made a new tab. $ For Firefox I used to have this code, but I'm not sure it's needed: firefox -remote "openurl($url,new-tab)"
Why do you need a script for it - surely you aren't doing this often? That's the sort of thing I'd just write an over-zealous regex-replace or two in vim and use the `c` flag to weed out the ones that shouldn't be changed. If you really want to do this correctly and automatically, you're going to want to hook into a parser.
And then after you log in (however way you do it), you can pass in your commands or queries using the -e switch: mysql -e "create database $dbname;" Make sure you pass in all your commands within the double quotations, and you'll be golden.
I don't have any evidence to back this up, but I believe that Windows just creates a virtual file system that acts as a wrapper from the Linux API to the Windows one. So there is actually nothing to look for! All files and things are directly written to the Windows FS, and the Virtual Filesystem only exists in RAM.
Well OP, we need to know more. Can this file be sourced (is valid bash) or not? If not, you probably need to use tools like awk or grep to get the values and then use sed to replace the values. 
Here's an example: #!/bin/bash splitarray() { local -n initialArray=$1 local -n result1Array=$2 local -n result2Array=$3 local x for x in "${initialArray[@]}"; do if (( x &gt; 10 )); then result1Array+=( "$x" ) else result2Array+=( "$x" ) fi done } foo=(1 2 4 8 16 32 64) splitarray foo large small echo "small:" printf ' * %s\n' "${small[@]}" echo "large:" printf ' * %s\n' "${large[@]}" The output of this example looks like this: $ bash test.sh small: * 1 * 2 * 4 * 8 large: * 16 * 32 * 64 
Those nodes and their names and IPs, those could be done differently. I can't quite decide what to suggest best. Here's one thing you could do: nodes=( "10.0.1.1" "10.0.1.2" "10.0.1.3" "10.0.1.15" "10.0.1.5" ) names=( 'Airport Extreme' 'AppleTV' 'HTPC' 'Raspberry Pi' 'MacBook Pro' ) for index in ${!nodes[@]}; do echo "IP: ${nodes[index]}" echo "Name: ${names[index]}" echo done Or what about collecting your data like this: while read -r ip name; do echo "IP: $ip" echo "Name: $name" echo done &lt;&lt; EOF 10.0.1.1 Airport Extreme 10.0.1.2 AppleTV 10.0.1.3 HTPC 10.0.1.15 Raspberry Pi 10.0.1.5 MacBook Pro EOF The output of both versions looks like this: IP: 10.0.1.1 Name: Airport Extreme IP: 10.0.1.2 Name: AppleTV IP: 10.0.1.3 Name: HTPC IP: 10.0.1.15 Name: Raspberry Pi IP: 10.0.1.5 Name: MacBook Pro 