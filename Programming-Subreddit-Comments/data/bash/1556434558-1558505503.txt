You use a lot of unnecessary processes, plenty of places where awk /re/ print would be ok. Also if [ -d /sys/class/net/wlp2s0/wireless ] &amp;&amp; [ "$(cat /sys/class/net/wlp2s0/operstate)" != 'down' ] if grep -sq up /sys/class/net/wlp2s0/operstate date=$(date "+%F"); timenow=$(date "+%H:%M"); echo " ${date} [ ${color_blue}$timenow${color_reset} ]" date "+ %F [ ${color_blue}%H:%M{color_reset} ]" bat_cap="$(cat /sys/class/power_supply/BAT0/capacity)" read bat_cap &lt; /sys/class/power_supply/BAT0/capacity
There are probably many other better ways of doing this than polling every 5 seconds. Use a message queue or an API or whatever. If you're fetching the file and you don't get any sort of etag or last modified time, rsync will tell you whether the file has changed. If you really must look at a file, check out incron. You can trigger your comparison script only when the file is touched by something else. Without more details it's hard to be more specific though.
For different update intervals, I would add a per module interval variable. Then you can check if `$SECONDS` modulo `$foo_interval` is equal to 0. To shorten longer if statements, I would just use backslash line continuation. So something like this: if ! longcommand --with --many --options &amp;&amp; [ -e "/very/long/path/$filename-variable" ]; then ... fi Could be written as: if ! longcommand --with --many --options \ &amp;&amp; [ -e "/very/long/path/$filename-variable" ] then ... fi You could also use variables for the command and the entire path.
No mate the script OP posted gets the file name from the file inside the zip.
The initial use case was to rename a large subset of incorrectly named files in OS X, where the user had neither access to the `rename` utility or the ability to escalate privileges. It grew from there.
I get no Errors on CentOS 6-7.x Perhaps you're shell isn't bash and it's interpreting -la as an argument to strace ?
I think it might have to do with escape codes getting in the way of expansion. I got it to work by using single quotes instead: for i in white black red green yellow blue; do eval bfg_$i='%{$fg_bold[$i]%}' done
Ohh thank u so much
Not really important, but: if [ "$(ps -C lemonbar --no-headers | wc -l)" -gt 1 ] could be: if pgrep -x lemonbar &amp;&gt; /dev/null This 'pgrep' (and a 'pkill') command is installed by default on the distro I'm using here, it's probably the the same for you. For the lines where you use `variable=$(echo ...)`, like this: ac_plug=$(echo '¬•') You could just write: ac_plug='¬•' When you write this in line 60: cur=$(( cur += 1 )) That's a bit strange because the `+=` you are using is already changing the $cur variable so the `=` doesn't do anything. I would like it better if the line would look like one of these versions here: cur=$(( cur + 1 )) (( cur += 1 )) In line 171 you have a mistake that will be hard to find: if [[ ${bat_stat} -eq 'fully-charged' ]]; then The mistake here is that `-eq` is for numbers, you need to use `=` for text. Bash will behave really strange here. Because `-eq` enables bash's "math" mode same as inside `(( ))`, it will start treating the `fully-charged` text as a variable names and a `-` operation. Check this out as an example of what happens: $ x=12 $ if [[ $x -eq fully-charged ]]; then echo true; else echo false; fi false $ fully=14 charged=2 $ if [[ $x -eq fully-charged ]]; then echo true; else echo false; fi true Now, when you $bat_stat variable is a text, then bash will always see it as a zero number. It should then always read this here, because $fully and $charged don't exist: if [[ 0 -eq 0 ]]; then I found that mistake in line 171 with a neat tool named "shellcheck". That 'shellcheck' thingy is really helpful. Your distro likely has a package for it, and you can also try it online at www.shellcheck.net without having to install it.
Please don't use pastebin. It blocks tor and has all kinds of javascript spyware (in addition to the cloudflare spyware).
https://mywiki.wooledge.org/XyProblem http://xyproblem.info/ It sounds like you want to get new lines from this textfile. If so, why not just `tail -f`? If you really need to compare two files then consider `cmp`.
To compare the modification times: [ FILE1 -nt FILE2 ] &amp;&amp; echo 'FILE1 is never than FILE'
Why individual code tags for each line instead of using a codeblock like so: #!/bin/bash INPUT=$1 while true; do file=$(zipinfo $INPUT | grep "\--" | awk '{print $9}') echo "file :" $file pass=$(echo $file | awk -F"." '{print $1}') echo "pass: " $pass unzip -P $pass $INPUT INPUT=$file done
Quote that `${1%.*}` please.
I'm assuming here that 'obtain text file' is done via a HTTP call.
Apologies, late night and mobile formatting I‚Äôll be sure to use codeblock next time!
Hate it when people can't just ask proper questions.
I generally don't have long running scripts. Why is grep \| awk a no-no? I generally do something like grep &lt;filter&gt; &lt;file&gt; \| cut or awk
Unless you need special grep option which would make it unwieldy to do the same thing in awk, you can simply do `awk '/regex/ { print $4 }'` instead of doing `grep "regex" | awk '{ print $4 }'. That's what is done in the script.
I just revised that and I realized that we can do the trick of putting a \\. after the regexp and that way it's enough to use just .\\+ to catch the domain, since it's already specified its position in the string - and it faster. Now the "base command" is: tcpdump -tln 'port 53' 2&gt; /dev/null | sed -n 's/^.\+ \(.\+\)\..\+$/\1/p' I tried to do also a different thing: putting \[!\] next to queries wich contain a "badword" and it works pretty well by itself: tcpdump -tln 'port 53' 2&gt; /dev/null | sed -n 's/^.\+ \(.*\(google\|amazon\|microsoft\|apple\|youtube\|telemetry\|adsystem\).*\)\. .\+$/\1 [!]/p The problem is that I have to include also the cases in which there are no badwords, so I did this but it doesn't work as expected: tcpdump -tln 'port 53' 2&gt; /dev/null | sed -n 's/^.\+ \(.*\(google\|amazon\|microsoft\|apple\|youtube\|telemetry\|adsystem\).*\)\. .\+$/\1 [!]/p ; s/^.\+ \(.\+\)\..\+$/\1/p' Basically I have grouped the first and second command I posted here, which work well on their own. Can you recognize the error? (soz for the many questions I asked).
This regex seems to be different from your original question as they do not catch the domain name after A (or A?) for IPv4 and AAAA for IPv6 and so it will not distinguish between them. Also be aware that this works because GNU `sed` by default does greedy search so it will try to match the maximum but it may not work for all versions of `sed`. But if this is what you want you can remove those badwords by simply modify the sed command as below sed -n '/google\|amazon\|microsoft\|apple\|youtube\|telemetry\|adsystem/!s/^.\+ \(.\+\)\..\+$/\1/p' The above command only performs the substitution on linesn that do not contain the bad words and prints them. Looks like this is probably what you want, but let me know if it is something different.
Thank you, Saint Stallman. I've updated to use ghostbin instead. You'll be happy to know I'm backing up to gitlab and not github since it's Absolutely Proprietary takeover.
Thanks for the tips. I couldn't get if grep -sq up /sys/class/net/wlp2s0/operstate; then... to work. So I'm still piping (pgrep now) to wc: if [[ $(pgrep -x lemonbar | wc -l) -gt 1 ]]; then....
I just learned you can select column and row with awk. So for most of my use-cases, regex isn't even needed: free -m | awk 'FNR == 2 {print $3} Prints the used memory (in Mebibytes) from the 2nd row, 3d column.
Thanks so much! I've updated a lot of my script according to your recommendations. I was actually wondering why my battery module wasn't working as expected, it does now btw. What would you say is better: read -r var &lt; or var="$(cmd)"
You're the only one to actually address my question, lul. I'm gonna try interval variables, still learning so I'm sure I'll hit some stumbling blocks...
If the zero/nonzero exit code of a program is all what we need to test, *if program* suffices. Don't take those suggestions as gospel, though. Just for ideas. Here's some more variations on the theme. statusline() { printf "%10s %10s %c %c %c $round\r" \ "$disk" "$load" "$network" "$spinner" "$volume" } every() { [ $((round % ${1:-1})) -eq 0 ] } round=0 while sleep 1 do every 5 &amp;&amp; disk=`df -h | awk '/ada0p2/ { print $5 }'` every 4 &amp;&amp; { set -- `sysctl -n vm.loadavg` load=$2 } if every 10 then network=D if ping -qoc2 $PINGEE &gt; /dev/null 2&gt;&amp;1 then network=U fi fi statusline let round++ done
I don't know if it holds on Linux, but FreeBSD pgrep ignores itself and ancestor processes. I guess just for this kind of situation. But check your manpage to be sure. Also, it can be a problem how a shell script shows up the process list, is *-x scriptname* enough ?
Well, it's actually checking for lemonbar which is launched by a shellscript that pipes to it. And yes, I checked pgrep -x with multiple instances and it accounts for pid's with multiple lines.
The `every()` is brilliant. Did you not use `$SECONDS` for portability or just so you can make sure the first round is guaranteed to be 0, so that all modules will update on the first round?
What about just always using 'pkill' or 'killall', without first counting the processes with 'pgrep'? I mean, you could replace that whole 'if' block with just one kill line: pkill -x lemonbar Or, maybe you could check pkill's or killall's exit code with an 'if' to print that message that says you killed stuff, like so: if pkill -x lemonbar &amp;&gt; /dev/null; then echo 'Sorry. Only one instance allowed.' fi
Ok thank you. The strace return works but for ls-la I get 17 errors for 1 syscall in the -C segment
Just replying to ram the message home: # rsync In retrospect, I could kick myself everytime I didn't use it when I had the same task as you.
I have a script with rsync now, will see tomorrow if it is faster :)
I believe you're looking for \`command\_not\_found\_handle\`, you just have to define it as a function and bash will call it automatically &amp;#x200B; function command\_not\_found\_handle { echo "dumb human!" }
https://www.cyberciti.biz/howto/insult-linux-unix-bash-user-when-typing-wrong-command/ This is a little article about setting one up.
You can do this without \`eval\`: &amp;#x200B; typeset bfg\_$i="%{$fg\_bold\[$i\]%}" &amp;#x200B; (This is zsh-specific, like your code to begin with.) &amp;#x200B; Also, depending on what you are trying to achieve, the following will most likely work too: &amp;#x200B; typeset bfg\_$i="%F{$i}" &amp;#x200B; At which point you might as well use \`"%F{red}"\` directly where you are currently using \`${bfg\_red}\`.
A few things to know about that: * It is called within the subshell that was pre-forked to exec the command, so you can't influence or exit the main shell from it * You should return from it with exit status 127, otherwise you'll get exit status 0 (command succeeded) on command not found! * The original command and its arguments are the arguments to the function call, so the command name is `$1`, etc. So that gives: function command_not_found_handle { echo "What did you think \"$1\" was, you dumb human!" exit 127 }
Just a lucky accident. I had not thought of SECONDS. Hmm.. Does it have another benefit: no problem of skipping if some programs take a long time.
Sorry, opened my mouth without understanding the complete situation.
Ohh thank u so much
You should just add the following to your bashrc: export PROMPT_DIRTRIM=3
What errors exactly Note most strafe output will produce errors as they search for c libs and can be ignored as long as they eventually find them in in your library path
You'd be wrong though. The file is not appended, rather it is replaced. This renders tail -f useless in this case.
Nothing other than standard unix tools are allowed. This system doesn't allow for the installation of packages, but provides a pretty decent toolkit of bash tools to work with
You really should have included better information in the OP.
Never heard about etags/ctags, but looked it up and seemed like a good approach. Unfortunately just logged onto the system and they are not installed. I can't install them (not allowed), so that renders the usage of that piece of software moot.
I have no need to replace ls. I have even less interest installing a whole another toolchain for a niche language just to replace ls. I have even less interest piping completely random commands straight to my shell to install said toolchain. Get this crap out of here.
I've been using linux for about ten years now, and the only issue with solutions like this is muscle memory and availability on other systems. I know when I log into a server somewhere, that the tools I have locally are not going to exist, so for the most part continue to use the common command line tools. I currently use tmux/i3wm/fish shell locally, but know I need the muscle memory to use ls and other basics both locally and on servers, and ls is one of the most common of common tools on any linux system.
I see your point. I just like rust and saw how well this exa command was written to used besides ls. Extra features and such. I also like golang. These niche language are fun to learn. I'm sharing and old school folks can just ignore this.
I use old tools to. The well know ones. Been using Linux for 15+ years. Yes, it all becomes muscle memory. So yes you have to use ls. exa not going to replace ls on all systems, so ls will have to be used. I just like rust and golang and finding many useful things written in these computer languages. exa is on my system, but yes when I move to another machine ls will have to be used. I guess I should of post at /r/rust instead of here. But thanks for your feedback.
Here's a sneak peek of /r/rust using the [top posts](https://np.reddit.com/r/rust/top/?sort=top&amp;t=year) of the year! \#1: [Auditing popular crates: how a one-line unsafe has nearly ruined everything](https://np.reddit.com/r/rust/comments/8zpp5f/auditing_popular_crates_how_a_oneline_unsafe_has/) \#2: [Announcing Rust 1.31 and Rust 2018](https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html) | [130 comments](https://np.reddit.com/r/rust/comments/a3pyrw/announcing_rust_131_and_rust_2018/) \#3: [Announcing Rust 1.26](https://blog.rust-lang.org/2018/05/10/Rust-1.26.html) | [226 comments](https://np.reddit.com/r/rust/comments/8igirv/announcing_rust_126/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/afd0dd/blacklist/)
I'm just curious. Why didn't the author simply build and distribute the executable binary?
It is hard to replace ls because it has become an integral part of Unix and in its limited setting of interactive shell use it does its job adequately (for scripts and especially for looping over files you shouldn't be using `ls` anyway). But I see little advantage of this program over ls. It retains all the hard to remember options of ls so for a beginner the learning curve is the same. For verteran users there's just no point learning another tool that does almost the same thing with few extra features (that they can easily script with other tools in Unix).
You got to ask him. I investigated a little bit on this subject. https://www.reddit.com/r/rust/comments/2geibf/how_to_distribute_programs_written_in_rust_as/ http://vitiral.github.io/2017/09/01/distribution-of-rust-binaries.html https://www.reddit.com/r/rust/comments/4cj41s/distribution_of_rustbuilt_binaries/ https://os.phil-opp.com/freestanding-rust-binary/
I get it. This is just written in rust and rust fascinates me. So I guess exa isn't impressive. It's rust I'm impress with. I'm learning rust and Go(golang). And stuff like this helps me learn how it all works. Yes ls is never going to get replace. You got your point across. Thanks for this feedback.
While I agree this is way to much work when ll is a thing. Take another look at rust. It's quickly left the niche market. While I won't run production on it yet, it is certainly one of the more popular languages right now.
Some people do like exploring different tools. After all that is the point of this sub reddit. Your opinion doesn‚Äôt invalidate the usefulness of this tool.
This may have its place on some rust-written OS like Redox. They are trying to build a complete operating system and ecosystem in rust.
ll is an alias.
I haven't downloaded it, but [I think he did?](https://the.exa.website/#installation)
I don't know about other distros, but I use Arch, so I'm somewhat familiar with Arch PKGBUILD. Looking at the PKGBUILD file, it calls `make`, and a quick look at the `Makefile`, it calls `cargo build`. So, at least for ArchLinux, the author does not provide a built binary. In fact, he requires the user to build the binary on the user's computer via `make`. &amp;#x200B; Even though calling `cargo build` without the `--target` option does make sure that the binary is built for the architecture of the target platform, it does require the user to install `cargo` just to build the program, which is really off-putting if you have never had a plan to use Rust. &amp;#x200B; Having said that, on ArchLinux, you can throw away extra packages that were installed and used just for building a binary by using `makepkg -sri`.
Pretty much useless one at that.
My mistake for leaving out the bit that I actually have another script that serves as a launcher which pipes the script I posted to the lemonbar application. So any killing I do within this script without checking for &gt;1 is suicide. What I might do though is add a killall to the launcher, though I think the way it is now is plenty... it only runs once... it isn't looped like everything else.
Does it have a viable replacement for sl ?
can you help me to understand what the every function is doing?
So `round` is just a counter incrementer by 1 at the end of the while loop. `${1:-1}` is the first argument to the every function with a default value of 1 if it's not supplied. That way you can call the function without arguments. It uses the test command `[` to check if `$round` modulo `$1` is equal to 0. The `[` command returns zero exit status if the expression is true, 1 otherwise. A function returns the exit status of the last command run in it's body. So in this case it's just a shorter way of saying: if [ $((round % ${1:-1})) -eq 0 ]; then return 0 else return 1 fi Or: [ $((round % ${1:-1})) -eq 0 ] return $?
That's a good one. If I want to write a rust program, maybe this should be the first one. Like a beat up rusty locomotive. We'll call is axe 13. axe
Emacs has that, `M-x zone-sl`. You truly haven't experienced `sl` before you try it. As for `ls` replacement, perhaps just `M-x dired`
I apologise if I wasn't clear enough. I did say that I was obtaining a text file every 5s, but I do get how that could be misinterpreted
This is interesting.
You should include why. Often people ask for stupid things because they think that will get them closer to the solution for what they want to actually do. https://mywiki.wooledge.org/XyProblem http://xyproblem.info/
&gt;Your opinion doesn‚Äôt invalidate the usefulness of this tool. That's true. But `ls(1)` does.
&gt; So, at least for ArchLinux, the author does not provide a built binary. In fact, he requires the user to build the binary on the user's computer via `make`. Actually, there seems to be a static binary download for 64-bit Linux; that's just a distro-specific option if you want to use your package manager. Also, it's in the official repositories, so pre-built packages are provided by Arch, which it can be installed by `pacman -S exa` just like any other other package in there.
You should first check if your distro perhaps has a package for it. You might not need to deal with this cargo business. For example there's a package for exa in Ubuntu 19.04 and in Debian 'testing' + 'unstable' and in Arch.
This is good to know. Thanks.
I use it on my workstation. The default color palette is nice and supports more coloring and extensions. All in all not mandatory but definitely nice to have when you want to make terminal experience easier on a glance with coloring.
That's how I feel about it. I'm sure ls can do the same though with a little scripting. But this exa is a nicely tight package that does some cool stuff.
To start, don't use backticks and use variables if you're going to use the value multiple times. temperature="$(command to get temp) To test, toss an echo and exit right after setting the value. This is the equivalent of setting up break points in an advanced IDE. temperature="$(command to get temp) echo "$temperature" exit
CURRENTDATE=\`date +"%Y-%m-%d %T"\` file=\~/test temp=$(cat "$file") &amp;#x200B; &amp;#x200B; read -r num &lt; test if \[\[ "$num" -gt 23 \]\]; then echo "$temp" | ssmtp [asd@asd.com](mailto:asd@asd.com) This way i get the temperature, and its good, but i want soemthing like this : echo "$temp" "$date" &gt;&gt;&gt; output : 2019-04 .... 28,5. but if i use the script like this, i got a empty email. How can i connect the date and the temp ?
Format code as code please.
Look into cron. All implementations of cron that I've seen have email capabilities.
 cat /sys/bus/w1/devices/28-031897794ae1/w1_slave | grep t= | awk -F= '{ printf "%.0f ", $2/1000}' &gt;test Done properly: temp="$(awk -F= '/t=/ { printf "%.0f, $2/1000 }' /sys/bus/w1/devices/28-031897794ae1/w1_slave)"
That onewire pseudofile seems to have really ... awkward format: hh hh hh hh hh hh hh hh hh : crc=hh YES hh hh hh hh hh hh hh hh hh t=millicelsius Information is there, yes, but why so cumbersome to parse :/
regular mv command file...directory works normally. Is this different for OSX?
Usually when I see "No file or directory" it's a permissions issue, sometimes not on the files but on the directory.
Try with mv filea-?.{jpg,txt}
&gt;mv filea-?.{jpg,txt} a same issue.
This exact same thing works fine for me on macOS. The ? wildcard substitutes exactly one character vs \* which does.. globbing? I forget the exact terminology, but filea\*.{jpg,txt} would match filealkajlkaslgkjaglk.jpg, but filea?.{jpg,txt} would not because it will only match a single character where the ? is located.
? represent any single character in bash. Single being the key word. What you want is likely \*. I also tried it by changing it to mv filea-?.{jpg,txt} and that worked fine.
You should try absolutely zero colors for a while and you will understand how unreadable this (exa) is. `-F` is good enough.
echo "$F\*100" | bc
try `ls -l ?`. should show you the 'a' directory. if it doesn't, `?` glob doesn't work. or if 'a' is not a directory you can't move files into it.
It works for me, see here an experiment at the command line: $ F=5 $ echo $(($F*100)) 500
What are your expected results?
Look up macros in the bash man-page. Should be possible to create one with 1. recalls the last command from history 2. goes to the beginning of the line 3. uppercases the first 3 words I know how to do this in vi-mode at least. Why not create function, though? Add something like this to your .bachrc file: set_proxy() { export http{s,}_proxy="$1" export HTTP{S,}_PROXY="$1" }
Ahh. Interesting. Will have to try this. Thanks!
Edited my post about with more information.
for file in $(find . \\( -name '\*.txt' -o -name '\*.jpg' \\) ); do mv $file a/; done
&gt;1. recalls the last command from history &gt;2. goes to the beginning of the line &gt;3. uppercases the first 3 words This could also be done in a function. Maybe something like this: lastupper() { set -- $(fc -l | tail -n 2 | head -n 1) shift 2 export "${*^^}" } This is SO specific to OP's required task that honestly, your `set_proxy` or something much like it is the way to go IMO.
Sounds like something I would use `expect` for but that might have bit of a learning curve. You might not need expect if you know exactly what the input sequences will be. Can you post the exact commands you tried? If you did something like `echo 127.0.0.1\n | foo ...` then there are a few issue. First echo requires -e to interpret the escape sequences. Second you need to quote the \n so bash doesn't interpret it. So `echo -e "127.0.0.1\n" | foo ...` might work for you.
You can use a here doc for input: http://tldp.org/LDP/abs/html/here-docs.html
that would be more like: &amp;#x200B; echo -e "7\\n [1](https://74.123.56.30).2.3.4\\n\\n Q\\n" | foo &amp;#x200B; Text interface pops up, enter 7 enter, enter IP enter, enter to confirm, then q to quit. If I use that echo command it seems like it should work but it doesn't seem to be accepting the IP when I pipe it to the command.
This was all I needed. The -e was the trick to get it to interpret the escape sequence. You rule, thanks buddy!
Woah, that's pretty elegant actually.
Maybe upgrade your bash first? My version is 5.0.3.
? and \* are both glob patterns. ? matches 0 or 1 character. \* matches 0 or more characters.
Variations nmea | awk -F, ' $1 == "$GPGGA" &amp;&amp; $7 &gt; 0 { printf "%.2f%c%c%.2f%c%c\n", $3, $4, "\\", $5, $6, "&gt;"; exit 0 } NR &gt; 100 { exit 1 # naah, no fix ? }'
 size=$(du -hs -- "$backupdir" | cut -f 1)
Need a sample of this "smileys.db" to make any kind of comment.
Use a code block instead of formatting every line as code separately.
Can you explain more what you're trying to do? I don't quite understand. Something like this maybe? # ... # code that is supposed to create a backup # ... if [[ -d /home/xxx/backup ]]; then echo "Backup complete." echo "Size is: $(du -sh /home/xxx/backup 2&gt;/dev/null)" else echo "Backup failed" exit 1
As long as you're just dealing with integers you don't need external programs.
where "$backupdir" is just the location of the directory? How would that be usable for echo / print
Of course that's basically what i'm trying to do now, the script is working nicely as intended probably very badly done and can be improved vastly which i'm looking to do and make it more robust and add some proper checks. #!/bin/bash RED='\033[0;31m' GREEN='\033[0;32m' NC='\033[0m' Y='\033[1;33m' # do something in five() five() { if [[ -d /mnt/c/SCADA\ Backup/"$sitename"/nexus_backup ]];then nexuscomplete="Backup Complete" &amp;&amp; nexusfailed="" else nexusfailed="Backup Failed" &amp;&amp; nexuscomplete="" fi } ############################################# # do more stuff in six() six() { if [[ -d /mnt/c/SCADA\ Backup/"$sitename"/mimics ]];then mimics="Backup Complete" &amp;&amp; mimicsfailed="" else mimicsfailed="Backup Failed" &amp;&amp; mimics="" fi } ############################################# # do stuff in seven seven() { if [[ -d /mnt/c/SCADA\ Backup/"$sitename"/user_table_data ]];then usercomplete="Backup Complete" &amp;&amp; userfailed="" else userfailed="Backup Failed" &amp;&amp; usercomplete="" fi } ############################################# # do something in one() one() { echo To backup, please enter the site name followed by YYMMDD read -r sitename echo now, please enter the IP read -r ipaddr if [ ! -d /mnt/c/SCADA\ Backup/"$sitename" ]; then mkdir -p /mnt/c/SCADA\ Backup/"$sitename"; fi } ############################################# # do something in two() two() { sshpass -p password scp -r nexus@"$ipaddr":/var/nexus_backup /mnt/c/SCADA\ Backup/"$sitename" &amp;&amp; echo "Creating Nexus Backup" &amp;&amp; sleep 3 } ############################################## # do something in three() three() { sshpass -p password scp -r mimicsrv@"$ipaddr":/opt/mimicsrv/global/mimics /mnt/c/SCADA\ Backup/"$sitename" &amp;&amp; echo "Creating Mimic Backup" &amp;&amp; sleep 3 } ############################################# # do something in four() four() { sshpass -p password scp -r nexus@"$ipaddr":/opt/xreport3/user_table_data /mnt/c/SCADA\ Backup/"$sitename" &amp;&amp; echo "Creating Reporter Backup" &amp;&amp; sleep 3 } ############################################ # function to display menus show_menus() { clear echo -e ${Y}"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~" echo -e ${Y}"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~" echo -e ${Y}" S C A D A - B A C K U P - T O O L " echo -e ${Y}"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~" echo echo -e ${Y}Backup Location = /mnt/c/SCADA\ Backup/"$sitename" echo echo -e ${Y}Site:${GREEN}"$sitename"${Y} IP:${GREEN}"$ipaddr" echo -e ${Y}1. Configure echo -e ${Y}2. Backup Nexus:${GREEN}"$nexuscomplete"${RED}"$nexusfailed"${NC} echo -e ${Y}3. Backup Mimic:${GREEN}"$mimics"${RED}"$mimicsfailed"${NC} echo -e ${Y}4. Backup Reporter:${GREEN}"$usercomplete"${RED}"$userfailed"${NC} echo -e ${Y}5. Check echo -e ${Y}6. Quit } ############################################ read_options() { read -r -p "Enter choice [ 1 - 6] " choice case $choice in 1) one ;; 2) two ;; 3) three ;; 4) four ;; 5) five &amp;&amp; six &amp;&amp; seven ;; 6) exit 0;; esac } ############################################ # ----------------------------------- # Menu logic - infinite loop # ------------------------------------ while [[ $choice -lt 6 ]] do show_menus read_options done Thanks for taking the time to check over my terrible scripting!
You would use it like any other variable. printf 'site: %s\n' "$size" echo "size is $size"
Thank you, gonna have a play with it now.
Indeed, it seems a bit overly complicated. For example, when you first run the program, `$sitename` and `$ipaddr` won't have any values, so why not jump right into configuration first thing? Also, I would avoid `one()`, `two()`, etc. as function names -- it's hard to read, and very rigid. If you ever want to add or remove an action, then the numbering will all have to change. All in all, I would actually suggest just making it a normal command line program with options and arguments, rather than an interactive program. For example, let's call it `bkup`. Then: $ bkup --help bkup [-c, --check] [location] bkup [location] [sitename] [ipaddress] bkup [-h, --help] $ bkup --check nexus Backup of nexus is complete. $ bkup --check mimic Backup of mimics failed. $ bkup mimics foosite 012.345.6789 Done. $ bkup --check mimics Backup of mimics is complete. (I may not have totally understood all the details of what you're doing, but you get the point.) Then you'd really only need a few functions: check() { # check [directory] if [[ -d "$1" ]]; then echo "Backup of $1 is complete." else echo "Backup of $1 failed." exit 1 fi } bkup_nexus() { # bkup_nexus [sitename] [ipaddress] local sitename=$1 local ipaddr=$2 sshpass -p password scp -r nexus@"$ipaddr":/var/nexus_backup /mnt/c/SCADA\ Backup/"$sitename" } bkup_mimics() { # bkup_mimics [sitename] [ipaddress] local sitename=$1 local ipaddr=$2 sshpass -p password scp -r mimicsrv@"$ipaddr":/opt/mimicsrv/global/mimics /mnt/c/SCADA\ Backup/"$sitename" } help() { ... } Then run the appropriate function, depending on what sort of options/arguments the user gives.
I'm curious...where's the heap? If it's the directory, I don't see any rebalancing. Usually, heaps order the underlying data so that operations have a known time complexity. For example, getting the next item in a heap should require a fixed number of operations (eg. 1). Here, since the data in the heap isn't kept in the right (random) order, peek requires a shuffle (whatever the time complexity of that is). Also, by keeping the data on the filesystem, it's unknown what the actual time complexity of any of these operations actually is. Is the directory list stored in a fixed size array? Stepping back, I'm also curious why u settled on Bash. It's pretty cryptic and requires a tonne of effort to only sorta encapsulate the data behind a data structure. And since VLC and utilities like `shufl` are on this machine, it's very likely that some other more complete runtime would be present. Why'd you settle on Bash? Is this a see if u can üí™ sorta thing? If so, then mission accomplished üôå. Other than that, it's a script that accomplishes its goal, and so deserves credit üéâ. Not sure why you got downvoted for sharing. Have an upvote.
Format your code as code please.
Yeah i appreciate my function naming is poor, this is a rush job really and will need some serious tidying up. The reason why I've made more like an interactive program is because it's going to be used by people that aren't super familiar with using the command line. I like what you've suggested though and i'll have a play with different methods. thanks for the input.
The naming thing is easy to clean up: one() -&gt; configure() two() -&gt; backup_nexus() three() -&gt; backup_mimics() four() -&gt; backup_reporter() five() -&gt; check_nexus() six() -&gt; check_mimics() seven() -&gt; check_reporter() This way also makes clear that you might be able to simplify and clarify your code by creating `backup()` and `check()` helper functions.
I wish I understood what you were saying. I dont really know much about bash scripting.
I need to examine the operation of nmea to see if it will work. I dont have GPS physically on the Pi...so it doesn't seem like it will function for my configuration.
This can be solved by \`expect\`: &amp;#x200B; [https://hostadvice.com/how-to/how-to-automate-tasks-in-ssh/](https://hostadvice.com/how-to/how-to-automate-tasks-in-ssh/)
You should probably use `-r` with those reads. Here is a solution in expect that should work. You might have to change the `expect "password"` line to something else but if the password prompt contains "password" it should just work as is. expect -f - -- "$username" "$password" "$projectid" &lt;&lt;'EOF' | tee -a -- "$filename" set username [lindex $argv 0]; set password [lindex $argv 1]; set projectid [lindex $argv 2]; spawn /usr/local/bin/npm start -- -e -prod -s $projectid -u $username expect "password" send -- "$password\r" expect eof EOF
I believe he means the post itself. Reddit allows you to use a ‚Äúcode block‚Äù to show, well, code in a pretty form.
&gt;I believe he means the post itself. Reddit allows you to use a ‚Äúcode block‚Äù to show, well, code in a readable form. FTFY
Some unimportant stuff: You can set several variables like this, there's no need for `&amp;&amp;` or `;`: a=hello b=hey c=hi There's a tool "shfmt" to fix indenting: shfmt -i 4 -w filename.sh # the '-w' makes it change the file
Thanks. Mostly, I just wanted to do a project in BASH to refresh my knowledge of the syntax. There was also a practical need for this program, and it has been useful around the house. I considered writing it in Python, but I use some older computers that Py would be slow on. I referred to this as being "Heap-Like" because the method of data extraction used is similar to "Popping" from a Heap in that it removes the data. Beyond that, it's just a directory that is managed by regular OS instructions, which run pretty fast. It does not have the re-balancing present in a Heap. Which runtime do you think would be better for this?
Thank you! This is probably the right direction. For some reason it looks like npm exits before expect sends the password. This is what I get now: ./npmtest.sh Enter Project ID string (for example a48c7af7-244d-436f-8761-4687f6475836): 8f3b5518-99d1-45d9-962f-ff9541e8e76d Enter Username: username Enter textfile name: akarmi.txt spawn npm start -- -e -prod -s 8f3b5518-99d1-45d9-962f-ff9541e8e76d -u username &amp;#x200B; \&gt; dss-ids-from-project@1.0.0 start /opt/dss-ids-from-project \&gt; ts-node src/index.ts "-e" "-prod" "-s" "8f3b5518-99d1-45d9-962f-ff9541e8e76d" "-u" "username" &amp;#x200B; Options: \--version Show version number \[boolean\] \--environment, -e Environment \[required\] \[choices: "dev", "qa", "prod"\] \--projectId, -s ID of the project \[required\] \--username, -u Alfresco username \[string\] \[required\] \--help Show help \[boolean\] &amp;#x200B; Invalid values: Argument: environment, Given: true, Choices: "dev", "qa", "prod" npm ERR! code ELIFECYCLE npm ERR! errno 1 npm ERR! dss-ids-from-project@1.0.0 start: \`ts-node src/index.ts "-e" "-prod" "-s" "8f3b5518-99d1-45d9-962f-ff9541e8e76d" "-u" "username"\` npm ERR! Exit status 1 npm ERR! npm ERR! Failed at the dss-ids-from-project@1.0.0 start script. npm ERR! This is probably not a problem with npm. There is likely additional logging output above. &amp;#x200B; npm ERR! A complete log of this run can be found in: npm ERR! /root/.npm/\_logs/2019-05-01T15\_22\_54\_364Z-debug.log send: spawn id exp6 not open while executing "send -- "password\\r""
It exists because there is some error present. Check the log at `/root/.npm/_logs/2019-05-01T15_22_54_364Z-debug.log`
I put it there just as a placeholder, as the appropriate command that emits NMEA.
Ok. I have to look at what gpspipe does when theres no fix. The receiver still outputs NEMA regardless if it has a fix or not.
I get this kind of GGA, quality (field 7) is 0, no fix. $GPGGA,161521.4,,,,,0,,,,,,,,*7C
Ahhhh. That actually does something I was going to add....having the script just silently exit should there be no GPS fix. Thanks!
LOL. True, very true.
The odd thing is if I just run the `npm start -- -e -prod -s &lt;projectid&gt; -u &lt;username&gt;` command just from the command line, there's no error. Here's the content of that log file. Maybe some kind of variable is not loaded in the script. The problem is I don't really know what this npm command is doing, besides it's supposed to give me a textfile with some IDs which I need to use in a later command. I just wanted to use a script to automate a long list of commands. [https://pastebin.com/Pxnuqp8C](https://pastebin.com/Pxnuqp8C)
It works on my PC. Anyway, this is an alternative approach: `F=5` `let F*=100` `echo $F`
When you start talking about records and fields, it's time to go from Sed to Awk. $ awk -vFS=\| -vOFS=\| ' NR&gt;2 { $(NF-1) = "[link](http://www.discogs.com/release/" $(NF-1) ")" } 1 ' file your header goes here |101 Strings|Tubular Bells|Pye International|7N 25658|1974|[link](http://www.discogs.com/release/8629870)| |10cc|I'm Not In Love|Mercury|6008 014|1975|[link](http://www.discogs.com/release/464657)| |10cc|Good Morning Judge|Mercury|6008 025|1977|[link](http://www.discogs.com/release/799173)| |13th Floor Elevators|You Really Got Me|Austin Records (3)|RE-1|1978|[link](http://www.discogs.com/release/1551989)| |999|Indian Reservation|Albion Records|ION 1023|1981|[link](http://www.discogs.com/release/740365)|
Thanks a bunch! You wouldn't care to talk me through it would you? So I can adapt it if I want - the final form is not decided on yet.
http://letmegooglethat.com/?q=centos+bash+script+as+a+service
I made some changes for readability. Here's the nickel tour. * `-v FS=\|` and `-v OFS=\|`: set Field Separator and Output Field Separator to pipe `|` character; we use a backslash to 'quote' the character so it's not interpreted by the shell. * `NR&gt;2 {...}`: On line numbers greater than 2, perform the action in braces * `$(NF-1)` The second to last "field". Awk sees 8 fields here where you see six because of the redundant separators at the beginning and end. This is the same as using `$7`, but I didn't want to presume that all your records had the same number of fields. * `variable = "string0" variable "string1"`: Wrap specified variable in specified text; Awk concatenates adjacent values. * `1`: This means "True". If we specified an `{action}`, it would be performed on every line. We didn't, so Awk will do the default action, which is `{print $0}` (print the whole line)
Perfect. Thanks a million! &amp;#x200B; I should have mentioned that all records have the same number of fields. My bad.
No, this was a good post because you specified the input and desired output. Thanks for the exercise.
Look for sysvinit/ systemd scripts, you‚Äôll get your answer.
`incron` might be a better fit for this.
Funny how the answer just pointing out the tool is higher than the answer with a solution using the tool.
since you asked for it in sed ... (note you've got space after the final | at the end of each line, when i copy it (i used $ in search pattern for "end of line" so i need to account for that space). also, i don't change the first two lines, as you said they were headers... &amp;#x200B; sed '3,$s@\([0-9]*\)| *$@[link](https://www.discogs.com/release/\1)|@' [file] &amp;#x200B; and testing... neil@tvpc:~$ cat test header1 header2 |101 Strings|Tubular Bells|Pye International|7N 25658|1974|8629870| |10cc|I'm Not In Love|Mercury|6008 014|1975|464657| |10cc|Good Morning Judge|Mercury|6008 025|1977|799173| |13th Floor Elevators|You Really Got Me|Austin Records (3)|RE-1|1978|1551989| |999|Indian Reservation|Albion Records|ION 1023|1981|740365| neil@tvpc:~$ sed '3,$s@\([0-9]*\)| *$@[link](https://www.discogs.com/release/\1)|@' test header1 header2 |101 Strings|Tubular Bells|Pye International|7N 25658|1974|[link](https://www.discogs.com/release/8629870)| |10cc|I'm Not In Love|Mercury|6008 014|1975|[link](https://www.discogs.com/release/464657)| |10cc|Good Morning Judge|Mercury|6008 025|1977|[link](https://www.discogs.com/release/799173)| |13th Floor Elevators|You Really Got Me|Austin Records (3)|RE-1|1978|[link](https://www.discogs.com/release/1551989)| |999|Indian Reservation|Albion Records|ION 1023|1981|[link](https://www.discogs.com/release/740365)| neil@tvpc:~$
And that woks just as well - thank you. Note: the spaces at the end of each record are a necessary part of the markdown - so well spotted!
yeah, quite specialized. I was wondering why you are getting a list of all commands and then extract the 2nd last. `fc -l -n -1` works for me to get the last command or am I missing something?
What I ended up doing... folder\_watch.sh while : ; do inotifywait -q -m /folder/to/watch | while read -r path action file; do -- do stuff here -- done done my init.d script prog="/path/to/folder_watch.sh" pidfile="/var/run/folder-watch.pid" start() { echo "Starting folder-watch" if pgrep -f "bash ${prog}"; then echo "folder-watch already running." else kill_inotifywait ${prog} &amp; echo $!&gt;"${pidfile}" fi } stop() { echo "Stopping folder-watch" if [ -e "${pidfile}" ]; then kill "$(cat ${pidfile})" kill_inotifywait rm -f ${pidfile} else echo "folder-watch is not running." fi } status() { if [ -e "${pidfile}" ]; then echo "folder-watch is running. pid=$(cat ${pidfile})" else echo "folder-watch is not running." exit 1 fi } kill_inotifywait() { inotifywait_pid=$(pgrep inotifywait) if [ "${inotifywait_pid}" ]; then kill "${inotifywait_pid}" fi } case "$1" in start) start ;; stop) stop ;; status) status ;; restart) stop start ;; *) echo "Usage: $0 {start|stop|status|restart}" exit 1 ;; esac So far this works for starting and stopping the script on demand and startup.
If you're fetching the file from a web server--and assuming you have access to curl--you could do a quick initial check to see if the file size is different before attempting something more expensive. ```sh remote_size=`curl --head https://url/to/file | grep -i content-length | awk '{print $2}'` local_size=`ls -l /local/path/to/file | awk '{print $5}' if [ "${remote_size}" != "${local_size}" ]; then # replace the file else # do more expensive MD5/diff comparison fi ```
I think I get it now...awk is basically doing something like CSV and then pulling out just what I need. That actually is a lot simpler and now I need to figure out how to do that with the rest of the data I pull. I'm guessing exit 1 if there's no fix just makes the script exit returning an error to the prompt; I'm waiting to lose 3d fix on my GPS server to find out. I don't actually need an error status since the thing will be running headless; so I may change that to a plain 'ol exit. Now I need to play with awk and figure out how to make it work for the rest of the data scraping. Come to think of it, I should have learned more about bash scripting before I jumped in to this.
Learning by doing stuff across hobbies. What's better than that. Exit codes of the awk are seen by the script. Unnecessary in this case, as there is output (the position report) only with success. You can capture that directly to a variable, *gps=$(gpspipe ... | awk ...)* and verify it to be nonzero length with *if \[ -n "$gps" \]*
heres the first two lines of 1719 emojis from [this list](https://unicode.org/emoji/charts/emoji-list.html) grinning face; U+1F600 grinning face with big eyes; U+1F603
This is shorter, not necessarily any better. Output should be the same. echo -e "$(sed 's/.*; U+\(.*\)$/\\u\1/' smileys)"
One more! read -r h1 read -r h2 printf "%s\n%s\n" "$h1" "$h2" IFS='|' while read -r foo a t p i y index rest do echo "$foo|$a|$t|$p|$i|$y|[link](https://www.discogs.com/release/$index)|$rest" done
Nice!
When I got home yesterday I realized the target device has an OS that makes the card ro, so writing files wasnt going to work. So I converted everything to use shell variables. But I got a lot if advice and confusion from some ham ops who are hardcore linux geek and aftet tossing me a lot of awk commands and whatnot...I got super confused and decided I'd "finish" the functionality of my script before I dig in to awk to improve stuff. So for the time being I went back to adding to it doing "what I know" which one old linux geek told me to do...she said I was the one that had to debug and use it and Id be better off doing what I understand. So the script now uses variables...writes a NEMA sentence, checks if the lock byte is zero and exits if it is...then parses the rest of the GPS. I think my GPS module likes to loop the last position when lock is lost. Since I'm using it as a stratum-1 NTP for my network I havent wanted to make it lose GPS. But I spent all of my last two evenings working on this and took a break last night. I went from having no idea how to do this and not the code part...there was a whole lot of just how becauae I didnt see a lot of APRS clients that were headless. Anyway....even if I wind up keeping it a hackjob my only concern is it works and doesn't spam a bunch if garbage to the APRS network. It so far does work...I could drop what I have in to cron and it'll work. I'll probably add a network check on some hacky way like pulling a file off my own httpd off the internet and the if/then/else it.
&gt;makes the card ro, so writing files wasnt going to /tmp and maybe some other directories are usually writable ramdisks, when rest is read-only. &amp;#x200B; There's a good digital repeater nearby, but I have yet to get a capable radio.
Ive pretty much done all of my dstar and dmr operation over pistar based hotspots. I wasn't sure if your username was a ham callsign or not. Yeah...pi-star locks the card after boot..thought about a ramdisk option but variables perform the same function.
I'm a big fan of /awk/ but this is a wonderful example which illustrates the awesome power of /sed/, and it answers the question on the nail!
This will be extremely unhelpful but... works on my machine. May be you need to use curly braces around w3 i.e. ${w3}? Could be that the \" is getting interpreted as part of the variable name somehow i guess
I tried your code on in my Bash interpreter, and it works just fine. I created "Book1.csv" like so: TEST,1.1.1.1/32,description Test2,2.2.2.2/32,description Then I ran this command: while IFS=',' read -r w1 w2 w3; do echo -e "set address $w1 ip-netmask $w2 description \"$w3\""; done &lt; Book1.csv Then I got this output: set address TEST ip-netmask 1.1.1.1/32 description "description" set address Test2 ip-netmask 2.2.2.2/32 description "description" You may have set some Bash option with the `set` command by accident which modifies the default behavior of Bash, or you may have set some built-in environment variable incorrectly. That or there are some weird formatting characters in your "Book1.csv" file. Try closing your terminal and opening a new one to start with a fresh Bash environment.
retting terminal didn't work, set command does seem to do something, not sure what to do
Most likely `${w3}` has a carriage return in it. Check the line endings of your file.
Most likely `${w3}` has a carriage return in it. Check the line endings of Book1.csv.
So it has something to do with the legnth, if i do this &amp;#x200B; while IFS=',' read -r w1 w2 w3; do echo -e ""set" address $w1 ip-netmask $w2 description ${w3}test"; done &lt; Book1.csv &amp;#x200B; the output is this &amp;#x200B; testaddress TEST ip-netmask [1.1.1.1/32](https://1.1.1.1/32) description description &amp;#x200B; it's putting anything after w3 into the front of the line? WHY?!!!!
The file has \\r\\n line endings and the \\r sticks into $w3 ?
Can you switch to markdown for your code? Things are getting lost or mushed together. Hard to read on mobile.
This appears to be correct, when transfering the CSV from windows rto linux this happens, if I vi BOOK.csv and paste the contents the command works. When I VI the microsfot csv however I don't see anything at the end of the line, wtf gives?
Can you paste the content of `Book1.csv` here? Also, try using `printf` instead of `echo`, see if that works differently: So: while IFS=',' read -r w1 w2 w3; \ do printf 'set address %s ip-netmask %s description "%s"\n' "$w1" "$w2" "$w3"; \ done &lt; Book1.csv
My vi does show \^M in a file. Quirk of your vi? ${w3%\^M} would be a quick and dirty fix. Control-V-M to get that \^M.
This is the correct answer. Seen below echo gets to the last escaped " after the carriage return it puts it to the beginning of the line $ cat -v test.csv TEST,1.1.1.1/32,description^M Test2,2.2.2.2/32,description^M $ while IFS=',' read -r w1 w2 w3; do echo -e "set address $w1 ip-netmask $w2 description \"$w3\""; done &lt; test.csv "et address TEST ip-netmask 1.1.1.1/32 description "description "et address Test2 ip-netmask 2.2.2.2/32 description "description OP should use something like `dos2unix` or `tr` or `sed` to remove carriage return. For example `tr -d Book1.csv &gt; Book2.csv`
This also worked for me on OSX (Mojave). I did your commands w/ this one subbed in and it came back fine.
i got some better examples for awesome power of sed, if you want to see them
couldn't agree more!
Heh... I can barely remember as it was two days ago now... I think what was happening was that `lastupper` was appearing as the last command
`:set list` should show the `^M`'s provided that's setup correctly `:set ff=unix` will do the conversion for you.
If you just want the contents, it's in the Google cache: https://webcache.googleusercontent.com/search?q=cache:tf0Wm2lunrIJ:https://learncodethehardway.org/unix/bash_cheat_sheet.pdf+&amp;cd=10&amp;hl=de&amp;ct=clnk&amp;gl=de
Life saver !! Thank you !!!
You are using /var/www/html/$test.png before test is set.
Thank you for your answer ! I put my /var/www/html/$test.png after the test and before my &lt;p id="p1"&gt;. Indeed, when I look my source code, I can see the name of my cluster in my img tag and my pictures is generated in my folder, but the picture still doesn't appear on my web page.
You should really look into using here-documents for work like this. They are really awesome for this. You seem to have nested double-quotes here. That may not be what you intended. A here-document will remove the need for any quotes except for the ones in your markup.
Ok, I found the problem : I have replaced &lt;img src="/var/www/html/picture_name.png"&gt; by &lt;img src="/picture_name.png"&gt; and it works. thanks.
awk is a wonderful tool, extremely versatile, and blindingly fast on large amounts of data. It's a bit esoteric to learn, but well worthwhile.
Why is this treating `awk` as some sort of command? You can't learn awk by remembering a bunch of options and commands like people do for other bash commands like `grep`, `tar`, `ls` etc. `awk` (especially `gawk`) is a fully featured programming language in its own right with its own syntax. The oneliner used in most commands is just an added convenience. If you really want to understand awk you should at least start with the basic structure of an awk statement `&lt;pattern&gt;{action}` and mention that by default it processes every line of the file (or stdin) and prints them. Without understanding the default program structure it would be very hard for a newcomer to understand anything.
Also the manpages for it suck, but there are enough good examples out there to realize that you can literally do anything with it.
please go on this is awesome..
&gt;Is there a way to combine &amp; and &gt;&gt; here? I might be misinterpreting what you want, but have you tried `[tee](http://www.gnu.org/software/coreutils/manual/html_node/tee-invocation.html)`?
There are various things you could improve in these scripts. Instead of billion echos you can just use a heredoc. There are a lot of useless uses of cat as well. Sed can perform multiple operations, you don't need to pipe it to itself. You generally don't need to pipe grep to awk, or cat to awk for that matter. There is no need for cut to get the second field from a variable, bash has string operations that can do this. And so on. #!/bin/bash Cluster_Name=($(awk '{print $3}' ClusterFullList.csv | sort -u)) cat &lt;&lt;EOF Content-type: text/html &lt;html&gt; &lt;head&gt; &lt;meta http-equiv="Content-Type" content="test/html"; charset=UTF-8"&gt; &lt;title&gt; CLUSTER GRAPH &lt;/title&gt; &lt;h1&gt; Cluster Graph &lt;font size=3&gt; &lt;a href="Index.sh"&gt;[ Index ]&lt;/a&gt; &lt;/font&gt; &lt;/h1&gt; &lt;hr size="4" color="blue"&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt; Choose a Cluster and press the button to generate the graph ! &lt;/p&gt; &lt;form action="script_extract.sh" method="post"&gt; &lt;select name="CLUSTER"&gt;" $(printf '&lt;option value="%s"&gt;%s&lt;/option&gt;' "${Cluster_Name[@]}") &lt;/select&gt; &lt;br&gt;&lt;br&gt; &lt;input type="submit" value="Generate"&gt; &lt;/form&gt; &lt;/body&gt; &lt;/html&gt; EOF #!/bin/bash read -r selection selection=${selection#*=} fun() { awk -v r="\&lt;$selection\&gt;" 'r {print $1" "$2","$12","$13}' ClusterFullList.csv sed "s/TITLE/$selection/;s/CLUSTER_NAME.png/$selection.png/;s/CLUSTER_1.txt/selection1.txt/" test1.txt | gnuplot sed -n 's/CLUSTER_1.txt/test1.txt/' Script_Conso.sh } cat &lt;&lt;EOF Content-type: text/html &lt;html&gt; &lt;head&gt; &lt;title&gt; CLUSTER GRAPH &lt;/title&gt; &lt;h1&gt; Cluster Graph &lt;font size=3&gt; &lt;a href="Index.sh"&gt;[ Index ]&lt;/a&gt;&lt;/font&gt;&lt;/h1&gt; &lt;hr size="4" color="blue"&gt; &lt;style&gt; hr{ margin-top: 1%; } #p1{ font-size: 18px; text-decoration: underline; margin-top: -41.8%; margin-left: 58.5%; margin-bottom: 2%; } #p2{ font-size: 14px; margin-top: -2.9%; margin-left: 58.5%; margin-bottom: 4%; } #p3{ font-size: 14px; margin-top: 5%; margin-left: 58.5%; margin-bottom: 4%; } &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;img src="/var/www/html/$selection.png"&gt; &lt;PRE&gt; $(fun) &lt;/PRE&gt; &lt;PRE&gt; &lt;p id="p1"&gt;Consumption difference :&lt;/p&gt; &lt;p id="p2"&gt;$(./Script_Conso.sh)&lt;/p&gt; &lt;/PRE &lt;/body&gt; &lt;/html&gt; EOF
 #!/bin/bash { echo -e "k\n" for ((k=3; k&lt;=15; k+=2)); do echo -n "$k" intval.txt python2 script.py "$k" done } &gt; intval.txt
no, i've been using linux for only 5 days
I would just like to add this link... https://www.gnu.org/software/gawk/manual/gawk.html
The man pages are just a reference. They are really good if you actually know the language. If you need to learn the language just read the actual manual for gawk: https://www.gnu.org/software/gawk/manual/gawk.html
Here are some stuff to get you started. I'd go and read the [GNU gawk manual](https://www.gnu.org/software/gawk/manual/gawk.html) (totally worth it) * Awk views data in terms of records and fields indicated by record separator `RS` (default newline) and field separator `FS` (default whitespace). So by default data is split into lines and each line by whitespace. * Every awk program is applied to each record of each file specified on the command line sequentially by default. Special `BEGIN` and `END` keywords can be used to run programs before and after any data processing. * You need at least a pattern or an action in an awk statement. If no pattern is provided the action is applied to all records. If no action is provided all matched records are printed using `OFS` and `ORS` as the output field and record separators. A pattern can be a regex (indicated by `/regex/`) , boolean expression or a range. * Information about all the fields is stored in variables $1, $2,.... The variable $0 indicates the whole record. Total number of fields in a record is stored in variable NF and records in variable NR.
thank you very much!
The bit I love the best is that array references are strings, so you can do things like: phone [Bob] = 451 phone [Alice] = 432 And then: For person in phone { print person, phone [person] } Of course that last but is usually in an END statement once you've finished parsing all the file (s).
I am that Author of that Blog post, I agree with everything that you have said. That is the reason that I make reference to the original AWK programming language in the very first paragraph and try to differentiate that from the way that it is used in sysadmins daily duties. From the blog post: "When I was first starting out as a sysadmin and I wanted to know what it took to get promoted, one of the things I was told was that I needed to know the BASH utilities, such as AWK. I‚Äôm not sure AWK is actually a utility ‚Äî it was originally intended to be a data-driven programming language when Alfred Aho, Peter Weinberger, and Brian Kernighan wrote it at Bell Labs. The name comes from the initials of their last names, but the program we use in BASH on Linux is (G)AWK or Gnu AWK, and there are many derivatives." I know that I have not done it justice, I really could do a whole month of posts on it and not cover it in enough detail.
Thanks
How about echo "$k" $(python2 script.py "$k") | paste - - &gt;&gt; intval.txt
That's also available in other languages (including Bash), called associative arrays, hash maps, or dictionaries.
Some great awk code here: https://github.com/TheMozg/awk-raycaster
I believe there are already made nagios plugins scripts for UPS monitoring... /s
nice
Its old, it doesnt work, and it doesnt have all the functions I need.
[https://gnu.cat/text/ypb.txt](https://gnu.cat/text/ypb.txt) [https://gnu.cat/wlg.jpg](https://gnu.cat/wlg.jpg)
Bash functions don‚Äôt have named arguments, the first arg is `$1`, the second `$2` etc. So the brackets after your function name should be empty (e.g. `check_load () { ...`). Then the first arg you pass (`$2` in your call within your `case`) is `$1` inside the function, and the second arg (`$3` in your `case`) is `$2` in your function. You should always quote variables, even if doing integer comparison. And `&gt;`/`&lt;` is not valid to compare integers inside single square brackets. You want `-gt`/`-lt` (see http://tldp.org/LDP/abs/html/comparison-ops.html). Your second function returns `$CRITICAL` in one case, but you‚Äôve not defined that. You probably meant `$CRIT`, which you have defined. Also, variables you define inside a function have global scope by default, though that won‚Äôt be a problem in this case.
He also forgot to use command substitution for $value
 \&gt; /dev/stdout is unnecessary.
IMO this is done much better from python itself. Write a python script that imports the function (or run script.py) which calculates the distribution for a particular k and print it from python. You can store the values in convenient data structures and have much better control over the output format. Also you don't have to rely on bash misinterpreting the characters. For example if the bash script fails for some value of k it can totally mess up the output. Within python you can setup proper exception handling to deal with those. Also relying on python to generate these will make sure you can do this in an OS independent way.
Yes I sensed that from the beginning but unfortunately I'm not a programmer so I can't do that in python, nor modify the python script to accept a range instead of a single input. I just need to plot a graph out of this distribution function and as I'm starting to learn linux and bash I though I could "frankenstein" together python and bash in order to obtain an output for values of x and f(x). &amp;#x200B; Thanks for confirmation and information!
I don‚Äôt suppose you have a 1920 desktop background without the 30 years?
I'll make one
As an alternative you can use [https://devhints.io/bash](https://devhints.io/bash).
Looks superb! Thank you very much :)
If you're up to it here some handy links ... https://bashlogo.com/ https://github.com/odb/official-bash-logo
Nice! But it dosent output the same result ü§î
How about posting the first 20 lines of `smileys.db` as opposed to something vaguely similar that you foundz on the interwebz that `but it doesnt output the same result` ***because it isn't the same***
OK, I think I fixed it using some of your points and other sources.... Updated: https://codeshare.io/amvN6k
OK, thanks.... From here and other sources I cleaned it up: https://codeshare.io/amvN6k
Why do useful search results like that ever come up. I used to do gfx and never heard of git's with an image repo. Thank you!
The load part is not working https://codeshare.io/amvN6k For some reason, I cant enter the "Warning porition". Ive checked with echo and variable and Im getting the correct numbers but it enters the OK and thats it.
In the old days before rsync, we would use a combination of find and either cpio or tar. Note that you dont have to create actual tar archives, but you can pipe tar into tar: find | tar -cf - -L /dev/stdin | tar -C destdirectory -xvf -
I think I figured it out
OK, now Im having issues with the string portion....
Hehe my first snipp produces ‚ÄôüòÄ‚Äô and yours seems to produce like chinese letters
Hehe my first snipp produces ‚ÄôüòÄ‚Äô and yours seems to produce like chinese letters
&gt; and yours It's not mine... but replace `u` with `U` and it works.. as would echo -e "$(sed 's/.*U+/\\U/; 20q' smileys.db)"
Is this for a monitoring system? Because it looks like you're trying to hack together a nagios/NRPE script... If this is for outputting information for human usage, then your approach will be different...
1. Yes with `set -a`, but just set the functions in .bashrc instead 2. The closing `}` must be preceded by a command terminator, such as `;` or a newline.
Hi geirha, &amp;#x200B; Thank you for your time, I have tried that ";" at the end already and it didn't work.
&gt; I have tried that ";" at the end already and it didn't work. Hmmm.... Would that be the same sort of "&gt;" sign that you get if you alter your first function to my_func () { echo "foo" } i.e. removing the `;` that /u/geirha suggests that you *add* to your second?
1. You can store all the function in a file (say [functions.sh](https://functions.sh)) and then use source /path/to/functions.sh in .bash\_profile to load it. 2. You `awk` command is missing an argument. That is not how you use getline. **Post the output from the netstat command and the final desired output format as examples.** 3. **It also really helps if you don't put everything on one line**. You're allowed to continue to next line in both `bash` and `awk`.
&gt; You awk command is missing an argument. What argument? &gt; That is not how you use getline "ps -o comm= -p " $9 | getline procname; looks like the name of the process with a `pid` passed in argument 9 from the `netstat` command gets put into the variable `procname`
Working except the string part.....How do I clean the variable from whitespaces and other dirt?
Yeah I got that. My `netstat` output is different which is why I asked about the output of `netstat`. Regarding getline you should close the command by saving the string like `cmd = "ps -o comm= -p " $9 ; cmd | getline ; close(cmd)`. I think the problem with OP's function is that he is missing a semicolon at the end of the last closing brace for the function. Which is why putting everything in one line is really bad practice.
 $netstat -Watnlv | grep LISTEN | awk '{"ps -o comm= -p " $9 | getline procname;colred="\033[01;31m";colclr="\033[0m"; print colred "proto: " colclr $1 colred " | addr.port: " colclr $4 colred " | pid: " colclr $9 colred " | name: " colclr procname; }' | column -t -s "|" Output: proto: tcp46 addr.port: *.51760 pid: 75019 name: /Applications/BetterTouchTool.app/Contents/MacOS/BetterTouchTool proto: tcp4 addr.port: *.51760 pid: 75019 name: /Applications/BetterTouchTool.app/Contents/MacOS/BetterTouchTool proto: tcp46 addr.port: *.80 pid: 68830 name: com.docker.vpnkit proto: tcp4 addr.port: 127.0.0.1.51655 pid: 68828 name: /Applications/Docker.app/Contents/MacOS/com.docker.supervisor proto: tcp4 addr.port: 127.0.0.1.46690 pid: 99590 name: /Applications/Visual Studio Code.app/Contents/Frameworks/Code Helper.app/Contents/MacOS/Code Helper proto: tcp4 addr.port: *.35729 pid: 66837 name: /Applications/Sublime Text.app/Contents/MacOS/plugin_host proto: tcp4 addr.port: 127.0.0.1.45112 pid: 1036 name: /private/var/folders/y1/c1jrs3515jzg8tg8cc1366d40000gn/T/AppTranslocation/8D1330D5-AB54-41BB-974E-4F1B960E87CB/d/Viber.app/Contents/MacOS/Viber proto: tcp4 addr.port: 127.0.0.1.30666 pid: 1036 name: /private/var/folders/y1/c1jrs3515jzg8tg8cc1366d40000gn/T/AppTranslocation/8D1330D5-AB54-41BB-974E-4F1B960E87CB/d/Viber.app/Contents/MacOS/Viber proto: tcp6 addr.port: fe80::aede:48ff:fe00:1122%en5.49156 pid: 43 name: /usr/libexec/UserEventAgent proto: tcp6 addr.port: fe80::aede:48ff:fe00:1122%en5.49155 pid: 43 name: /usr/libexec/UserEventAgent proto: tcp6 addr.port: fe80::aede:48ff:fe00:1122%en5.49154 pid: 43 name: /usr/libexec/UserEventAgent proto: tcp6 addr.port: fe80::aede:48ff:fe00:1122%en5.49153 pid: 43 name: /usr/libexec/UserEventAgent
&gt; Regarding getline you should close the command If you need to reuse `getline` in your program, aye, but since the pipe is closed when `awk` exits, it is - in this case - as you say, a good-housekeeping "should", as opposed a "you *really* want to" or even "must" since `awk` only calls `ps` once, it won't run out of file descriptors. &gt; I think the problem with OP's function is that he is missing a semicolon at the end Aye - as already pointed out earlier.
See the much simpler and readable version of the function below. I have put all the awk into a separate script and made provisions so that you can specify whether the output will be colorized or not. There should always be a backup option if color is not supported or if you're piping the output to something else Awk script (saved in `nstat.awk`) #!/usr/bin/awk -f function Colred(s,flag) { colred="\033[01;31m" colclr="\033[0m" colstr = flag ? s : colred s colclr return colstr } BEGIN { OFS = "|" } { cmd = "ps -o comm= -p " $9 cmd | getline procname close(cmd) print Colred("proto:",rc),$1,Colred("addr.port:",rc),$4,\ Colred("pid:",rc),$9,Colred("name:",rc),procname } Now you can define your function as macnst() { netstat -Watnlv | grep LISTEN |\ awk -v rc="$1" -f nstat.awk | column -t -s "|" } Now you can call the function as `macnst 1` or `macnst 0` to not show or show color. Feel free to change this.
Also, is it possible, while being in a while read loop, to reference the line that comes after the current one?
This isn't an answer to your questions, just some nitpicks. &gt; var=$(grep "number" ./text.txt | sed) The "./" isn't needed for the file, and why are you piping grep into sed when there's no need to?
The grep is to filter out for example all of the lines of the config file i mentioned that contain the first name and sed is to clean the output so that i can record it onto the separate file. Currently my biggest problem is that when appending to that separate file, the file gets all messed up as if it has a limit of 50 characters per line, but when it reaches it it just starts erasing the line from the beginning and rewriting it.
Don't forget that you can experiment with everything directly at the command line. You don't have to edit and run a script all the time when you want to test something. About your first question, I'm guessing your file has DOS/Windows line endings. A file with DOS line-endings looks like this: first line\r\n second line\r\n That `\r` character is "carriage return". This moves the cursor to the beginning of the line. In a Unix file there's just a `\n` "new line" character. To fix the problem, one thing to do would be adding a `tr -d '\r'` command somewhere to your sequence of piped commands. Perhaps at the front of the would be best, like this: var=$(tr -d '\r' ./text.txt | grep "number") That `sed` command you had there was doing nothing so I removed it. About your second question, I'm not sure what to do best. Something that you could do is the following: while \ read -r age read -r name read -r lname do # do something here with $age $name $lname done &lt; your_config_file_name Here's an experiment about this at the command line: $ cat testfile a b c d e f g h i $ while read a; read b; read c; do echo "$a $b $c"; done &lt; testfile a b c d e f g h i
&gt; Also, is it possible, while being in a while read loop, to reference the line that comes after the current one? If you type `help while`, if you look at what it says closely, it says "commands" instead of "command" at the start: while COMMANDS; do COMMANDS; done This means you can use several `read` commands if you want, it doesn't have to be just a single one. That's what you could use to go through the config file. See my other post about how it has to look like exactly.
Have you tried decomposing your expressions into parts, and trying those first? For instance, try var=$(grep ‚Äú5‚Äù text.txt) echo ‚Äú$var‚Äù ...does your variable contain what you expect? If not, have you tried wrapping the output like this? var=‚Äú$(grep ‚Äú5‚Äù text.txt)‚Äù echo ‚Äú$var‚Äù In general though, if you try to use Bash to do text processing, you‚Äôre going to have a bad time.
Thank you, what addon are you refering to ?
You can see the [https://devhints.io/bash](https://devhints.io/bash) cheatsheet as an alternative or addon to your mentioned cheatsheet.
Sudo is normally configured so it requires a TTY. That is, it is not necessarily possible to "pipe" a password into it. However, you can use something like `expect` to fake up a TTY and simulate human-entered input. You could run this on either end of the SSH connection.
Excellent. Thanks. I will research this aspect.
Try this: REMOTE\_USER\_NAME=your\_user; REMOTE\_SERVER\_NAME=you-server.tld; REMOTE\_PATH=/path/to/files; REMOTE\_FILE\_PATTERN=sel\*ction.file; LOCAL\_PATH=.; rsync -ave 'ssh' "${REMOTE\_USER\_NAME}@${REMOTE\_SERVER\_NAME}:${REMOTE\_PATH}/${REMOTE\_FILE\_PATTERN}"" ${LOCAL\_PATH} If you want to use ssh keys, try this: SSH\_KEY="/path/to/ssh/key/" # e.g. \~/.ssh/id\_rsa REMOTE\_USER\_NAME=your\_user; REMOTE\_SERVER\_NAME=you-server.tld; REMOTE\_PATH=/path/to/files; REMOTE\_FILE\_PATTERN=sel\*ction.file; LOCAL\_PATH=.; &amp;#x200B; rsync -ave "ssh -i ${SSH\_KEY}" "${REMOTE\_USER\_NAME}@${REMOTE\_SERVER\_NAME}:${REMOTE\_PATH}/${REMOTE\_FILE\_PATTERN}"" ${LOCAL\_PATH}
Just make a variable and add it to your bash profile. rs() { rsync -aP -- server:/path/to/directory/"$@" . } One thing to keep in mind is that shell will try to expand the glob before rsync ever sees it. So if the glob might match locally so you'll probably want to do `rs 'sel*ction.file'` instead.
You should format code AS code.
I'd change the "$@" into "$1" to avoid getting the idea you could pass multiple arguments to that function to copy multiple files/patterns from the remote.
How about just accepting multiple patterns. rsync -aP -- $(printf 'server:/path/to/directory/%s ' "$@") .
If OP reads this: * You can use \`CODE\` (`CODE`) for an inline code block. * You can use 4 spaces before each line of code for a code block. - CODE GOES HERE
This information is also available under every single text area on the website. Tbh anyone who hasn't learned to format their posts properly should be banned until they prove that they know how to do it.
That seems just a tad bit harsh. I didn't even know how to make code blocks until I had been part of a programming subreddit for months.
Try out `sshpass` Works nice with all remote commands like scp for example
Banning retards is not harsh at all.
How are they retarded if they don't even know how to make a code block in the first place? I could see banning them for neglecting to use code blocks, and probably if it was a repeated offense. But banning them without knowing if they even knew how to make them in the first place is just ridiculous.
&gt;How are they retarded if they don't even know how to make a code block in the first place? They are retarded since the help has been there right next to their textboxes every time they write a comment or a post. &gt;But banning them without knowing if they even knew how to make them in the first place is just ridiculous. I said they could be unbanned after they've demonstrated that they've learned to format their shit.
Upvote for sshpass. One of my favourite tools.
I know my posts looks awful, sorry again and thanks for the tip.
Yep, i had decomposed everything and i couldn't understand where the problem was. However the tr -d command suggested by another user here solved the issue.
No problem. :) I'd make sure to format your posts properly in the future though, so you don't get people like the guy who replied to me trying to get you banned.
In that case I'd feed them to rsync's stdin instead: printf '%s\0' "$@" | rsync -aP -0 --files-from=- server:/path/to/directory .
Yeah, that looks better.
I would, except i cannot install anything on the system that isn't already there. Thanks tho. :)
Being allowed to install it would save you lots of time and hassle. Maybe the simplest solution is to just ask.
you can pass STDIN to sudo over SSH, in scripts, that will type the password. It basically does the same shit `sshpass` does, but without you having to install something else. `echo yourpassword | ssh -T user@hostname "sudo -S /your/command/" `
It doesn't need to be "installed". It can run from anywhere on the file system. So, just copy that to your script directory or wherever it needs to be invoked from and use absolute path when referring to it.
Hmmmm interesting. Thanks
I googled it and all the results i found refer to installing. Based off what you said i assume i can download it compressed...uncompress it...burn the resulting files to a cd...bring the cd to the computer i want it on and copy it to a directory there. Correct? If so do you have a reliable link to the tar file for a red hat distribution?
The dev site listed for this project is https://sshpass.sourceforge.net It's on gentoo repos. I trust that. Downloading a tar from there should be safe. Rest of it is getting the files to the computer you want to run `sshpass` from. Doesn't matter how you get it there.
Format your code as code block for fucks sakes.
Welcome to scripting land! A couple of suggestions: 1. Use #!/bin/bash on the top line to tell the shell it's a bash script. 2. No need to change into those directories, you can do it like this too: touch dirname/filename.
You could have googled [this](https://askubuntu.com/questions/66533/how-can-i-restore-configuration-files)
How about this? [https://pastebin.com/R0vAhkbf](https://pastebin.com/R0vAhkbf) I'd still make some modifications though, perhaps touching all the files from expanded list with just single touch command. Many unix utils (touch and mkdir including) can take a form of "touch file1 file2 file3" instead of "touch file1; touch file2; touch file3" &gt;I'm thinking of trying to make a function that takes arguments for the directory from the DirectoryArray and then having other arrays storing relevant file names in separate lists for each respective directory. From there the function would check what directory was just created, access the relevant list and generate empty files from that. KISS. Keep It Simple Stupid. You are basically creating a bunch of empty files here. The simpler way you go about that the better. Cleaner code. Less places where error can happen. Less typing. Less reading. Remember, in coding - "less is more". Check your retvals! In your code you have NO ERROR VALIDATION whatsoever. If you keep doing this, it will keep biting you in the ass. Hence, quick and dirty and neat \`set -eu\`. Also what others said. Good work. Keep learning.
Thank you for pointing that out. I slightly edited it, could you tell me if this is what you mean? Thank you
1. I forgot to include that in the post but I do have that in the script. Thank you for taking notice though! 2. WOW! Thank you so much I didn't even know I could do that! :)
Add 4 spaces in front of each line of code so it's formatted as one block.
I'm so happy you pointed out how unix tools can take that form, it will save me a lot of time. I'll look into error validation next. KISS is something I'll definitely have to do a better job at keeping in mind. Thank you for all the feedback!
There is a "formatting help" under every fucking text area on this fucking site. Ever considered clicking it?
I haven't noticed it yet on the new redesign. Thanks for pointing it out though, I'll take a look! :)
Just a quick tip how it can be done with the error checking, there may be many many other ways to do it though; for example that helper function would make more sense here: ``` # helper function to print message and die fatalError() { # it's polite to push errors to stderr (2) echo "ERROR: $*" &gt;&amp;2 exit 1 } # one way to check for retval if ! mkdir $top_dir then fatalError "Can't create $top_dir" fi # oneliner cd $top_dir || fatalError "Can't chdir to $top_dir" # when we may need to evaluate exact retval touch file1 file2 file3 retval=$? if [[ $retval -gt 0 ]] then fatalError "Can't touch some of the files, touch returned $retval." fi echo Creating 7-1 SASS architecture structure $top_dir ```
Who hurt you?
I think that [brace expansion](https://www.gnu.org/software/bash/manual/html_node/Brace-Expansion.html) works for consolidating the touch statements while keeping things legible. #!/bin/bash echo 'Creating 7-1 SASS architecture structure' [[ -d sass ]] || mkdir sass cd sass touch 'main.scss' declare -a DirectoryArray=('abstracts' 'base' 'components' 'layout' 'pages' 'themes' 'vendors' ) for DIR in "${DirectoryArray[@]}"; do if [[ ! -d "${DIR}" ]]; then echo "Creating Directory: '${DIR}'" mkdir "$val" fi done touch ./abstracts/{'_variables.scss','_functions.scss','_mixins.scss'} touch ./base/{'_typography.scss','_base.scss','_utilities.scss','_animations.scss'} touch ./layout/{'_navigation.scss','_grid.scss','_header.scss','_footer.scss','_sidebar.scss','_forms.scss'} touch ./pages/{'_home.scss','_about.scss','_contact.scss'} touch ./themes/{'_theme.scss','_admin.scss'} echo 'Done!' &amp;#x200B; I also added some checks for the existence of the directory prior to creating it (I, personally, find the "directory \_\_\_ exists" warnings it can give to be annoying). Also quoted things out of my personal unofficial rules of 'best practices' (and largely simply because I think it looks nicer in my text editor, TBH). &amp;#x200B; You could also use brace expansion to replace the array and for-loop by doing: mkdir -p ./{'abstracts','base','components','layout','pages','themes','vendors'} But you won't get the "Creating directory \_\_\_\_" message for each one. (The `-p` argument isn't necessary in this instance, but it will prevent BASH from triggering a warning if the directory already exists.) &amp;#x200B; As for creating a function to determine which files to create based upon the directory name: that seems like it'd be a lot more work than it's worth. &amp;#x200B; Also, FYI: While there's nothing wrong with including it, "`declare -a`" isn't really necessary; BASH knows it's an array due to the parentheses.
You can use this site to get recommendations as well: https://www.shellcheck.net/
Just make an `rm` function in your .bashrc that checks the args and passes them on to `command rm` if you like what you see in $@. Or, do the same thing and download safe-rm and alias your rm to that.
`$(printf 'server:/path/to/directory/%s ' "$@")` expands unquoted and is probably better written as `"${@/#/server:/path/to/directory/}"`.
Thanks! I'm now using safe-rm! Didn't know about it, but I do now! Much appreciated!
Hey, just wanted to say thank you very much for the info, really helped a lot!
yea but that requires effort on my part
Another suggestion - use [shellcheck](https://shellcheck.net) to perform a static analysis on your code. It can be done both via the website as well as offline. It can suggest some runtime improvements/gotchas that are commonly missed.
You might also want to guard against `rm -fr /*` as well.
I'm using safe-rm now. It will protect me from myself. Not that I've ever made this mistake in my 15+ yrs of off-and-on using Linux until I went full on last year, but one night I might get too far into my cups and try to delete /\* while trying to remove ~/Documents/\* for some odd reason. So now I simply *can't.*
We have built-in protections for that now alias rm='rm --preserve-root=all --verbose --interactive=always' That will sufficiently deter somebody attempting to delete root. Of course there is `--force` in combination with `--no-preserve-root' or somebody can simply execute `/usr/bin/rm` directly to bypass the alias.
Try switching to single quotes?
&gt; somebody can simply execute `/usr/bin/rm` directly to bypass the alias. A shorter way is to type it as `\rm`.
Solved. This string did the trick: .[] | select(.mediaType | contains("HDD")) | .id
You could keep all paths in one array, for easy updating. Something like this FilesArray=( abstracts/_{variables,functions,mixins}.scss base/_{typography,base,utilities,animations}.scss components/ layout/_{navigation,grid,header,footer,sidebar,forms}.scss pages/_{home,about,contact}.scss themes/_{theme,admin}.scss vendors/ main.scss ) for file in ${FilesArray[@]} do mkdir -p $(dirname $file) touch $file done
You cannot have periods in shell variables, unless this has changed lately.
You can safely ignore it; Shellcheck doesn't know that you want `sh` to expand it.
Summat like temps=($(sed -n 's|.*Temperature: \([^ ]*\).*|\1|p' temps.txt))
Why not use disown instead of nohup?
&gt;temps=($(sed -n 's|.\*Temperature: \\(\[\^ \]\*\\).\*|\\1|p' temps.txt)) &amp;#x200B; Works a charm! Thank you!
Seems like you are trying to parse https://github.com/merbanan/rtl_433 Do you know that you can change the output format to f.e. json with the '-F json' param? Then you are able to easily parse it with jq.
Entirely true. However I'm even less familiar with parins json files so I prefer doing it the good ol' bash way. Might be a little more work, but at the moment it's easier for me to understand. Thank you however for the hint!
Clearly, we do not have it "built-in" in LinuxMint. [https://www.reddit.com/r/linuxmint/comments/bl2nsk/today\_i\_accidentally\_ran\_sudo\_rm\_rf/](https://www.reddit.com/r/linuxmint/comments/bl2nsk/today_i_accidentally_ran_sudo_rm_rf/)
You've already got a working answer with sed, but here's an awk approach: temps=($(awk '/Temperature:/ {print $2}' temps.txt)) * On my phone and untested.
Backticks are deprecated, you should use $(vlc &amp; this_pid=$!; sleep 2h; kill $this_pid) instead.
Does Linux Mint not install coreutils or util-linux, or install a very very old version? This is a standard part of any modern Linux distro.
preserve-root only guards against trying to remove `/`. Trying to remove `/*` is another matter.
If he replaced nohup with disown it wouldn't mess with shellcheck.
He isn't using backticks. Those are single quotes.
util-linux version 2.31.1-0.4ubuntu3.3 coreutils version 8.28-1ubuntu1 According to my Package Manager, Synaptic, these are the latest versions.
Use code blocks to format your code.
Very basic answer but should be a starting point: Iterate over the tree checking if the current file / folder path exists in the other tree.
Cool thanks
Cheers I‚Äôll do that
So I'll leave it to you investigated the details, but coreutils has had the '--preserve-root' for over 10 years. I'm pretty sure the Ubuntu package contains the code. I'm highly skeptical of your claim.
Why not use nohup instead of disown?
Keep in mind that disown is a bash feature and other shells such as dash, ash, mksh etc. don't have it.
Duly noted!
it‚Äôs already done , now i want to display the difference in a file text look what i did here (if you are free ofc ) [bash ](https://imgur.com/gallery/GYtYyPX)
and please just skip the comments , they are written in french
Most higher level IDE's will do this for you. For example PHPStorm or any of the products in their suite allow you to copy to clipboard and then right click in your code and choose "compare to clipboard" which will show you a diff file. &amp;#x200B; Alternatively you could commit one file to a git repo and then run diff on the files.
Which claim would that be? That I have those versions installed? Or that somebody else was able to rm -rf /\* ? Yes, that was somebody else, not me. I'm just being proactive about that never happening to me, should I sit down at my computer one drunken night and try to delete something the way that other Redditor did, or accidentally leave out the ~ for some reason, and rm /bin or something. (I'm on mobile and not able to compare / with ~/ to see what similar directories they might have, and I don't know off the top of my head.)
Because it seems to require this awkward `sh -c` trickery, rather than just passing the pid you're grabbing anyway to disown. But I see now that you're also backgrounding nohup, so maybe it's not easier overall.
Too many variables to say for certain but the speed would be marginal unless it's a lengthy enough script where multi-threading would pose beneficial.
\&gt;python \&gt;speed You can only pick one.
¬´ Commit on file to a git repo ¬ª what do you mean , sorry i didn‚Äôt quite understand it
I'd probably do something like... diff &lt;(cd -- "$dir1"; find) &lt;(cd -- "$dir2"; find) &gt; changes
Why would you use an IDE or git when just diff would suffice?
Thank youuu, do you have any idea where i can find it on the internet to have more details about how this works
In this part of the bash guide that's linked on the sidebar: http://mywiki.wooledge.org/BashGuide/InputAndOutput Specifically the section "6. Miscellaneous Operators"
Thanks a lot!! you saved my school‚Äôs project
In case you also care about differences in files you could do just diff -r -- "$dir1" "$dir2"
look what i did , just ignore the comments btw [bash](https://imgur.com/gallery/GYtYyPX)
It helps a lot to know about common utilities in your system.
what‚Äôs your point ? i mean the comparing script i did it , now i want to put the difference in a filetext
One more! sum="" n=0 while read line do set -- $line while [ $# -ge 3 ] do case "$1$3" in Temperature:C) echo "$2" sum="$sum+$2" let n++ break ;; esac shift done done &lt; temps.txt echo Average: $(bc &lt;&lt;&lt; "scale=1; (0$sum)/$n")
Depends. If you could use python for things for which you would otherwise do with bash, you might see a speedup. But if your bash script doesn't do anything complicated, then you likely won't see a difference. PS: you should also have a look at the subprocess module in python, as it is generally more flexible than os.system. I'm also pretty sure that when you start a command using the subprocess and don't give it the shell=True argument, it doesn't execute the command through a subshell and thus should have a little bit better performance than os.system().
Made quick a quick awk version just for fun. Though this depends on gawk feature ENDFILE. awk ' !n {a[$0]++} n &amp;&amp; !a[$0] {b[$0]++} n &amp;&amp; a[$0] {delete a[$0]} ENDFILE {n++} END { print "In A, not in B" for (i in a) print i print "\nIn B, not in A" for (i in b) print i }' &lt;(cd "$1"; find) &lt;(cd "$2"; find)
If you want to redirect the output to a textfile just do `&gt;file`. You should read the page I linked.
Thanks, I don't know if it's right and it's a personal observation but when I make a script that does a lot of file manipulation like writing files, it seems like it goes a lot slower than it could, maybe my bash scripting isn't as refined but I was curious if I was to have python write to files and then use my bash commands like normal, now in python could I possibly see a performance increase.
This is too complicated for what i [did](https://imgur.com/gallery/9QGni0g)
thank you for the effort btw
ProTip: Don't use Python for 'enhanced shell scripting'. Use Ruby! The biggest reason why: you can run any shell command by simply wrapping it in backticks like this: `pwd` Ruby also has a `$?` and regular expressions built-in. It's sooo much cleaner and practically seamless compared to Python. Here is a contrived example: `cat file.txt | grep -i something`.each {}
[https://diffoscope.org/](https://diffoscope.org/) # diffoscope In-depth comparison of files, archives, and directories. *diffoscope* will try to get to the bottom of what makes files or directories different. It will recursively unpack archives of many kinds and transform various binary formats into more human readable form to compare them. It can compare two tarballs, ISO images, or PDF just as easily.
Thank you!! But i should write the script myself in bash
I did a quick benchmark to muddle the issue: Doing 10'000 times write(stdout, "x\\n", 2) took 40 milliseconds, with system("echo x") it took 70+ seconds.
You're making me wonder why I haven't learned Ruby yet.
Really depends on your problem. If the problem is too complicated, as you said bash has its limits so you have to choose a proper programming language. If you're familiar with python then it is an automatic choice (others being perl, ruby etc). With python modules such as `os`, `subprocess` gives easy access to most of bash functionality. The slight decrease in performance is more than offset by: 1. Increased ease in creating a program, reading, maintaining and extending it. I cannot stress enough how much more important this is compared to performance for most programs. 2. Increased **portability**, if you use the functions provided by `os` modules (not just `os.system('bash command)` or `subprocess`)but using the modules/functions like `os.path`, `os.chmod`, `os.listdir()`, etc) you can use it in most other platforms including Windows without worrying about system specific details. If speed is critical for your scripts I'd say use C/C++ with `system()` and `popen/pclose` and for even finer control use os specific system calls. This however is much more difficult and requires a lot more expertise.
How about using a [language designed specifically for ops tasks](https://ngs-lang.org/) then? For example, it will [handle exit codes of external process in an intelligent way](https://ilya-sher.org/2017/01/28/ngs-unique-features-exit-code-handling/), [parse external processes' outputs](https://ilya-sher.org/2017/01/27/ngs-unique-features-execute-and-parse/), will assist you to [construct command line arguments](https://ilya-sher.org/2017/08/04/ngs-unique-features-argv-command-line-arguments-builder/) when running external programs, etc.
The pid I‚Äôm grabbing isn‚Äôt the only one I want to nohup/disown though. It‚Äôs important that sleep and kill are able to run even if the shell exits.
&gt;ProTip: Don't use Python for 'enhanced shell scripting'. Use ~~Ruby~~ Perl!
Cool, hadn't heard about NGS before!
It's been a while since I used Perl. Is the module ecosystem stale or relatively up-to-date? Ruby is _heavily_ influenced by Perl and I see it as a better Perl.
Just use diff. See below $ tree Testdir*/ Testdir1/ ‚îî‚îÄ‚îÄ subdir ‚îú‚îÄ‚îÄ dir1 ‚îú‚îÄ‚îÄ test1.txt ‚îî‚îÄ‚îÄ test.txt Testdir2/ ‚îî‚îÄ‚îÄ subdir ‚îú‚îÄ‚îÄ dir2 ‚îú‚îÄ‚îÄ test2.txt ‚îî‚îÄ‚îÄ test.txt $ diff -rq Testdir1 Testdir2 | tee Diffs.txt Only in Testdir1/subdir: dir1 Only in Testdir2/subdir: dir2 Only in Testdir1/subdir: test1.txt Only in Testdir2/subdir: test2.txt To simply get the output to the text file Diffs.txt use `&gt;` instead of pipe and tee.
Use Bash when the primary purpose of the script is to control other processes. Otherwise it makes more sense to move the logic into a more specialized language.
Was a joke mate ;) I don't know (about) Ruby, but I went to Perl because bash -&gt; sed -&gt; awk -&gt; perl, logic! It's difficult to explain because I'm french, but with Perl regex are so simpler. For me Perl is the language to parse and manipulate text files, and in deeper it's offer a great approach to data structures, imho.
Totally understandable. Apparently, I'm not good at PR :)
If you're mostly going to be calling external programs, it's probably best to stick with bash, unless you're trying to do something that would be easier or less ugly to do in python or ruby or perl or what have you.
https://metacpan.org/recent
You can use -a and -o for ands and ors as well as () to group them. Like ```-not (name "anyfile.sh" -a -perm 744)```
Why not both? I use both at my job. I have several Bash scripts that handle system level stuff, dump the info into, say, a CSV file, and then call a python script to post-process the results.
Since neither of my suggestions were understood, I was trying for simple and clearly failed.
Sure, people commit to it, but how out of date are the really important libraries?
Really important... Like which? To whom?
If you actively used Perl, you'd probably be able to give me a handful of the ones you use and tell me that they're good and stable still and which ones are known to be out of date. I'm gonna guess you probably don't use it regularly? Obviously not everyone knows every module so it's a general question to anyone who has any experience to share good or bad.
Thanks, I'm trying this now...I had to escape the () and I changed the -a to -o but I think this is what I need to do.
Thank you , i‚Äôm gonna try this at home !
Because when you put it on your resume people think you were born in black and white
It looks like your submission contains a shell script. To properly format it as code, place four space characters before every line of the script, and a blank line between the script and the rest of the text, like this: This is normal text. #!/bin/bash echo "This is code!" &gt; This is normal text. &gt; &gt; #!/bin/bash &gt; echo "This is code!" *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/bash) if you have any questions or concerns.*
I have never considered learning Ruby but I'm totally going to check it out now.
Either learn to format or kill yourself.
A bit harsh
Not harsh enough. Half of the posts lack proper formatting. Imo the people should get banned until they learn to format properly.
Banned and committing suicide and very different
The sub can't force someone to kill themselves (unfortunately). Just suggesting it as an option is not that harsh.
If you will not take the time to learn proper formatting on Reddit, could you put on pastebin.com, ideone.com, codepad.org or the like? You will get a lot more feedback on the content of the post if it is easier to read.
Really depends on what you‚Äôre doing, but if you care at all about performance, I don‚Äôt know if either Bash or Python are what you want. One isn‚Äôt obviously faster than the other for every task. Some pros and cons here: https://stackoverflow.com/questions/2424921/python-vs-bash-in-which-kind-of-tasks-each-one-outruns-the-other-performance-w What‚Äôs the basic job/task that you‚Äôre programming? Can it be parallelized or concurrent?
Ah, yes, the write-only language.
My tasks would basically be executing bash scripts that will do system wide changes, it's just that I always felt that when writing to files using sed or appending to a file with echo or other ways took longer than say me doing it through python and I had the idea that was well what if I try and combine the two would I see a performance increase if I had bash commands get me the output i need and python do all the file editing.
That would definitely work for sure. I was only thinking the other way around, using python scripts to call bash scripts.
If you are going to do that, I would very much recommend you pay extra-special attention to exit statuses of your Bash scripts. In other words, make sure that your Bash scripts handle whatever odd behaviour the system can throw at them and exit gracefully on errors. Then, make sure that your Python scripts can interpret when the Bash scripts exit on errors. I would also take a very hard look at what your Bash scripts are trying to accomplish, and rolling out as much of the functionality in the Bash scripts back into Python.
Use `dircolors -p/--print-database`. It gives you a simple list of the colors which you can process easily with something like awk like below (your terminal should show colors if it supports it) $ dircolors -p | awk '($1 !~ /^#.*/) &amp;&amp; ($1 != "TERM"){ &gt; gsub(/^\./,"",$1) &gt; print "\033[" $2 "m" "color" $1 "=" "\\e[" $2 "m" "\033[0m" &gt; }' colorRESET=\e[0m colorDIR=\e[01;34m colorLINK=\e[01;36m colorMULTIHARDLINK=\e[00m colorFIFO=\e[40;33m colorSOCK=\e[01;35m Very simply the above just prints the color escape sequence found from the list (and resets after each line). It filters out the lines which do not contain the color code.
Would I put that as a function in my .bash_aliases file? I just get syntax error: unexpected end of file at the moment.
In .bashrc or some file you source from .bashrc, yes. rs() { printf '%s\0' "$@" | rsync -aP -0 --files-from=- server:/path/to/directory . } The important part there is to put a newline or `;` before the closing `}`, if you don't do that, you'll get an error like "unexpected end of file".
Wow, seems like a really good idea.
Take a look at xonsh. It's basically a python-based shell. Launching apps and piping output works just like bash, and you can mix it with python code in a way I found convenient. I made the move from bash to xonsh simply to get to use/learn python in my work.
I read the StackOverflow Survey report knowing that a lot programmers love to share on Reddit, that's why I wish to share my bash oneliner commands here with you!
Thank you. It's pretty useful.
For now I just manually enter commands: ffmpeg -i petitprince\_1\_saintexupery\_Ezwa\_CC-BY-SA.mp3 -ss 00:07:16 -to 00:07:52 -c copy mini\_01/14\_Et\_je\_lan√ßai.mp3 And I already cut manually 14 audios: 01\_D√©dicace.mp3 02\_Premier\_chapitre.mp3 "03\_J'ai\_montr√©\_mon\_chef.mp3" "04\_Les\_grandes\_personnes\_m'ont\_conseill√©.mp3" "05\_J'ai\_donc\_d√ª\_choisir\_un\_autre.mp3" "06\_Quand\_j'en\_recontrais\_une\_qui\_me\_paraissait\_un\_peu.mp3" "07\_Chapitre\_II\_J'ai\_ainsi\_v√©cu\_seul.mp3" 08\_Le\_premier\_soir\_je\_me\_suis\_donc\_endormi.mp3 "09\_J'ai\_saut√©\_sur\_mes\_pieds\_comme\_si.mp3" 10\_Je\_regardai\_donc\_cette\_apparition\_avec\_des\_yeux.mp3 11\_Quand\_le\_myst√®re\_est\_trop\_impressionnant.mp3 "12\_Comme\_je\_n'avais\_jamais\_dessin√©\_un\_mouton.mp3" "13\_Alors\_j'ai\_dessin√©.mp3" 14\_Et\_je\_lan√ßai.mp3
 if (($j==$u+2)) You don't need the $ here.
What's an "If loop"? I'm not seeing loops.
you are right! I should use 'If statement', thank you!(edited)
thank you! I'm glad that you like it.
Cool, thanks a lot for correcting my mistakes, i will update the commands. I love to add ${!foo\[@\]} too!!
Delete all the ones you did already from the time table file. Here's a pure POSIX version. i=15 while IFS=' ' read -r start x end name; do outfile="(printf '%2d.%s.mp3' "$i" "$name" | tr ' ' '_')" i="$((i+1))" ffmpeg -i "petitprince_1_saintexupery_Ezwa_CC-BY-SA.mp3" \ -ss "$start" -to "$end" -c copy \ "$outfile" done &lt; timetable.txt Don't think there is any benefit in running multiple ffmpeg processes in parallel.
 parallel --slf servers.txt --nonall -j 32 -- whoami Personally I recommend using GNU parallel.
This is a really good list. I looked through it to see if I could add anything, I really couldn't. I use all of these one-liner patterns on a daily basis. I would add just two more default keyboard shortcuts: * `Ctrl + L` clears the screen, or in a scrolling terminal window, scrolls the bottom line with the cursor to the top of the window * `Ctrl + W` deletes from the cursor to the start of the line, it does the same thing as `Ctrl + X + Backspace`, and also `Ctrl + U` does the same.
[https://pasteboard.co/IdLP678.png](https://pasteboard.co/IdLP678.png) For some reason the last 6 files are long. The rest are short as they should be. And there the very last file 22:56 - 24:00 Il rougit, puis reprit is not there.
A sleep 1 or sleep 0.1 (if decimals supported by sleep) in the loop might help, if 300 connects cannot get thru in 20 seconds. btw, how about while read ip port store do echo Store is $store Port is $port IP is $ip &gt;&gt; output.log ssh ... done &lt; backup_ip_list.txt
Missing newline at the very end of timetable.txt ?
This is how it looks with the newline. [https://pasteboard.co/IdMqisa.png](https://pasteboard.co/IdMqisa.png)
To be honest I have no idea why I didn't try a sleep. I put a sleep in the loop for about half a second and that seemed to resolve my problem. Im only getting a few time outs that are likely from something else. Thanks for the duh moment! &amp;#x200B; And functionally is there any difference between what mine and your code is doing? Is there something im missing? I'm still kinda new to this :P
The loop is fine tho. I only did one minor mistake which is using `%2d` instead of `%02d`. I will fix it my post. For testing I ran this: #!/bin/sh i=1 while IFS=' ' read -r start x end name; do outfile="$(printf '%02d.%s.mp3' "$i" "$name" | tr ' ' '_')" i="$((i+1))" printf 'from %s to %s -&gt; %s\n' "$start" "$end" "$outfile" done &lt;/tmp/timetable.txt Which outputs: from 00:05 to 00:54 -&gt; 01.D√©dicace,_√Ä_l√©on_werth.mp3 from 00:54 to 01:37 -&gt; 02.Premier_chapitre._Lorsque_j'avais_six_ans.mp3 from 01:36 to 02:06 -&gt; 03.J'ai_montr√©_mon_chef-d'≈ìuvre.mp3 from 02:06 to 02:35 -&gt; 04.Les_grandes_personnes_m'ont_conseill√©_de_laisser.mp3 from 02:35 to 03:08 -&gt; 05.J'ai_donc_d√ª_choisir_un_autre.mp3 from 03:08 to 03:38 -&gt; 06.Quand_j'en_rencontrais_une_qui_me_paraissait_un_peu_lucide.mp3 from 03:38 to 04:05 -&gt; 07.Chapitre_II,_J'ai_ainsi_v√©cu_seul.mp3 from 04:05 to 04:29 -&gt; 08.Le_premier_soir_je_me_suis_donc_endormi.mp3 from 04:29 to 05:03 -&gt; 09.J'ai_saut√©_sur_mes_pieds_comme_si_j'avais_√©t√©_frapp√©.mp3 from 05:03 to 05:43 -&gt; 10.Je_regardai_donc_cette_apparition_avec_des_yeux.mp3 from 05:43 to 06:14 -&gt; 11.Quand_le_myst√®re_est_trop_impressionnant.mp3 from 06:14 to 06:38 -&gt; 12.Comme_je_n'avais_jamais_dessin√©_un_mouton.mp3 from 06:38 to 07:16 -&gt; 13.Alors_j'ai_dessin√©..mp3 from 07:16 to 07:52 -&gt; 14.Et_je_lan√ßai.mp3 from 07:52 to 08:36 -&gt; 15.Chapitre_III,_Il_me_fallut_longtemps.mp3 from 08:36 to 09:10 -&gt; 16.Et_le_petit_prince_eut_un_tr√®s_joli_√©clat_de_rire_qui.mp3 from 09:10 to 09:51 -&gt; 17.Et_il_s'enfon√ßa_dans_une_r√™verir_qui_dura_longtemprs..mp3 from 09:51 to 10:23 -&gt; 18.La_proposition_parut_choquer_le_petit_prince:.mp3 from 10:23 to 10:59 -&gt; 19.Chapitre_IV,_J'avais_ainsi_appris_une_seconde_chose_tr√®s.mp3 from 10:59 to 11:40 -&gt; 20.J'ai_de_s√©rieuses_raisons_de_croire_que_la_plan√®te.mp3 from 11:40 to 12:27 -&gt; 21.Si_je_vous_ai_racont√©_ces_d√©tails_sur_l'ast√©ro.mp3 from 12:27 to 13:19 -&gt; 22.Ainsi,_si_vous_leur_dites.mp3 from 13:19 to 14:35 -&gt; 23.Car_je_n'aime_pas_qu'on_lise_mon_livre_√†_la_l√©g√®re.mp3 from 14:35 to 15:04 -&gt; 24.Chapitre_V,_Chaque_jour_j'apprenais_quelque_chose.mp3 from 15:04 to 15:35 -&gt; 25.Je_ne_compris_pas_pourquoi_il_√©tait_si_important.mp3 from 15:35 to 15:57 -&gt; 26.Mais_il_remarqua_avec_sagesse.mp3 from 15:57 to 17:06 -&gt; 27.Et_en_effet,_sur_la_plan√®te_du_petit_prince.mp3 from 16:06 to 17:53 -&gt; 28.C'est_une_question_de_disipline.mp3 from 17:53 to 18:43 -&gt; 29.Et,_sur_les_indications_du_petit_prince.mp3 from 18:43 to 19:18 -&gt; 30.Chapitre_VI,_Ah_!_petit_prince,_j'ai_compris,_peu_√†_peu.mp3 from 19:18 to 19:59 -&gt; 31.En_effet._Quand_il_est_midi_aux_√âtats-Unis.mp3 from 20:00 to 20:44 -&gt; 32.Chapitre_VII,_Le_cinqui√®me_jour,_toujous_gr√¢ce_au_mouton.mp3 from 20:44 to 21:14 -&gt; 33.Les_√©pines,_√†_quoi_servent-elles.mp3 from 24:14 to 21:56 -&gt; 34.Je_ne_r√©pondis_rien.mp3 from 21:56 to 22:22 -&gt; 35.Il_√©tait_vraiment_tr√®s_irrit√©.mp3 from 22:22 to 22:56 -&gt; 36.Le_petit_prince_√©tait_maintenant_tout_p√¢le_de_col√®re.mp3 from 22:56 to 24:00 -&gt; 37.Il_rougit,_puis_reprit.mp3 Either something is wrong with the ffmpeg command, or your timetable file is broken. The github paste has a blank line every other line, windows line endings?
it's nice for beginners, but this: https://github.com/onceupon/Bash-Oneliner#get-the-first-character-of-the-variable Could have been done better: var=string echo "${var:0:1}" #s However. the example is pretty cool because I never knew about `${var#?}` syntax, whatever that is doing is neat. Add more question marks and the results change deterministicly, but I still get the sense this is some kind of hack that just happens to work.
Same effect, basically. Mine might survive a typo in the list. Missing word or extra word would only affect that line.
That more complex version might be for POSIX compliance
Nice one ! Will use them !
Just to be clear.... Posix compliance means ksh88, a fairly modern sophisticated shell, and not Bourne shell.
Ahh that makes sense. Ill likely switch over to that then! Thanks for the help!
 case "$ip" in \#*) continue ;; esac That on the top of the loop might make life easier, if you must temporarily comment out a record
For the first one, I would much rather include the $. It doesn‚Äôt matter if it‚Äôs optional, and that‚Äôs actually not a feature. It‚Äôs better to do things in a consistent way than to deal with special cases, especially when the special case doesn‚Äôt matter. You shouldn‚Äôt be concerned with ‚Äúthis type of statement needs the $ but this other type doesn‚Äôt‚Äù. Just alway use it and be consistent.
&gt;cmd |&amp; tee logfile &amp;#x200B; I believe this is Bash 4.x, so not applicable on default bash shell on Mac (stupid Apple and their stupid GPL lawyering!)
`if (( j == u + 2 ))` vs `if (($j==$u+2))` I think the former is much more readable.
Yeah, the gist at github is exactly what I have. Just to make sure that we get the same results I have uploaded both timetable and the mp3 to dropbox (I can upload to any other): The mp3: [https://www.dropbox.com/s/5n04lsln8uaneft/petitprince\_1\_saintexupery\_Ezwa\_CC-BY-SA.mp3?dl=0](https://www.dropbox.com/s/5n04lsln8uaneft/petitprince_1_saintexupery_Ezwa_CC-BY-SA.mp3?dl=0) The timetable: [https://www.dropbox.com/s/2cup902jodss3vc/timetable.txt?dl=0](https://www.dropbox.com/s/2cup902jodss3vc/timetable.txt?dl=0)
just fwiw, there's [argbash](https://argbash.io/) for bash and [this template](https://stackoverflow.com/a/28466267) for posix-compliant scripts if you didn't know about them already.
I alse have this in bash: Invalid duration specification for ss: :22 ffmpeg version n4.1.3 Copyright (c) 2000-2019 the FFmpeg developers Should I put the whole output on gist?
Do they use the same document format?
/u/anton_rich ffmpeg has this silly feature where it eats stdin, so that loop will only iterate once. See [BashFAQ 89](https://mywiki.wooledge.org/BashFAQ/089) for more on that. So either use a different fd for the while loop while IFS=' ' read -r ... &lt;&amp;3; do ...; done 3&lt; timetable.txt and/or add `&lt;/dev/null` on that ffmpeg
[mp3splt](http://mp3splt.sourceforge.net/mp3splt_page/home.php) is a good way to do things like this, so it's something you might want to look into in the future. It can do cool things like automatically cut a longer file into separate files based on where it detects silence. I wrote an `ffmpeg`-based bash script that worked similar to /u/Schreq's answer, but I don't really use it anymore.
Ok, did some test with the actual file and it's super weird. Printing only always prints the correct timestamps. As soon as I run the actual ffmpeg command in the loop, some start times have their leading minutes chopped off. Always happens at the 23rd file for the first time. But only with a timetable file I cleaned up (removed the blank lines). With your original file it works.
As far as I know wikia allows uploading WP articles compressed in xml format up to 60kb which results extremely tedious. If I could do it in batch mode it would be other words.
Doh, I should have refreshed the post earlier. Was banging my head against the wall for the past hour but eventually figured it out. So yeah, you can either use ffmpegs `-nostdin` or redirect /dev/null to ffmpegs stdin like you suggested. What's weird though, is that ffmpeg only started eating **parts** of stdin after the 23rd line. With OP's original file which had blank lines, ffmpeg would eat the blank lines and the whole loop would properly cut out all the parts. What the actual fuck?!
I think `pgrep` is a separate program (provided by procps-ng on my machine) instead of `grep -P`?
They are functionally different. Using the `$` prefix expands it before the arithmetic expansion, allowing you to use it as an operator or expand it twice. You should probably omit it if you aren't supposed to do either of these.
You need to investigate if Fandom has an API.
 - I'd mention `Ctrl + u`, which cuts to the start of the line, and `Ctrl - y`, which pastes it. - Another nifty history expansions are `!:n`, which gets the nth argument of the last command. `!$` gets the last argument, and `!*` gets them all. - You're missing a dash before `name` in `find . name '*.php' -exec sed -i 's/www/w/g' {} \;`. - I'd also mention `+` instead of `\;`. - Why aren't Bash's builtin arithmetic expressions mentioned in the Math section? - You're missing spaces in `if [! -s $data];then` and `if [[$age &gt;21]]`. - You have a lot of unnecessary `$` prefixes in arithmetic expressions, and you inconsistently switch between `[` and `[[`. - - Also, the `&gt;` operator `test` expressions is not numerical; use `-gt` or arithmetic expressions instead. - What is `$popd` in `pushd . $popd ;dirs -l ` for? - Bash has builtin `$UID` and `$EUID` variables that you can use instead of `$(id -u)`. - `declare -A array=()` actually produces an associative array. If you want a normal array, use `-a` instead or simply `array=()`.
Rad! Thanks for posting
sure! i love ctrl + L too, i have added your suggestions, thank you! Seems theres little different bw Ctrl W and Ctrl U, see if its true on your system too Ctrl + w : delete the word before the cursor. Ctrl + u : delete the line before the cursor.
I'm glad that you like it, thank you!
&gt;masta Agree, like your version more.. sometimes I was surprised to see how complicated command works and immediately added it to my note.
It is written in the grep manual that 'egrep' means 'grep -E'. 'fgrep' means 'grep -F', so i think its the same for pgrep?
&gt;pushd . $popd ;dirs -l sorry for this strange command, I use '$' to seperate lines in my old notes, and not fully delete the old symbols. It should be pushd . \#then pop popd \# while *dirs -l* displays the list of currently remembered directories. Thank you for correcting my mistakes! Ive edited the page, as for builtin arithmetic expressions, I love to add some of them to Math section too!
Hey, bonnieng, just a quick heads-up: **seperate** is actually spelled **separate**. You can remember it by **-par- in the middle**. Have a nice day! ^^^^The ^^^^parent ^^^^commenter ^^^^can ^^^^reply ^^^^with ^^^^'delete' ^^^^to ^^^^delete ^^^^this ^^^^comment.
I am happy that you like it! thanks!
excellent, thanks.. starred and watched..
Thank you! i'm glad that you like it.
oops, I have spelled them all wrong. Thank you for letting me know, i have corrected it.
I think the best solution would be to ditch grep alltogether and use finds more advanced options. That way you can dynamically assemble a find commandline like so: find_opts="$HOME /media -type f -regextype egrep -iregex .*\.(mp4|mkv|wmv|avi|mpg|mov)$" for arg in "$@"; do shift set -- "$@" -a -iregex "$arg" done set -- $find_opts "$@" exec mpv --playlist=&lt;(find "$@" | sort "$sort_opts")
while read -p "prompt&gt; " key; do case "$key" in g) goon;; e) exit;; \*) :; esac; done
That is a much nicer solution. Thank you very much. I was using iregex for the filetype before but I had missed that I could use egrep type here too. Nice. Noob question about `set -- "$@" -a -iregex "$arg"`. Isn't this overwriting `"$@"` with one of it's `arg`? Also, why use exec with mpv? And why do I need `set -f` (disable file name generation/globbing)
Consider using the bash built-in test framework aliased as `[[` and `]]` so these tests are faster and more predictable. However, for switching on a string it's arguably better to use a `case` ... `esac` logic instead of the if+test logic. This is in many ways a matter of style and preference, but there are nominal speedups, especially because case statements always use the faster built-in testing &amp; evaluation framework, instead of sub-shelling to stand-alone `test` program.
Why shift in the loop ? It will drop previous -a.
He's way too tricky for me. Lots to learn.
That exec, btw, saves one process. Save those resources! :) Well have to wait for the reason of -f.
&gt; Isn't this overwriting `"$@"` with one of it's `arg`? No. It basically just appends. If the arguments are "silversun" and "pickups", it would do this: # Initially "$@" expands to: silversun pickups for opt in silversun pickups; do The first loop iteration: shift # "$@" now expands to: pickups set -- "$@" -a -iname "*${arg}*" # Expanded: set -- pickups -a -iname *silversun* The second loop iteration: shift # "$@" now expands to: -a -iname *silversun* set -- "$@" -a -iname "*${arg}*" # Expanded: set -- -a -iname *silversun* -a -iname *pickups* I guess you don't really need the shenanigans with the positional parameters. You could also just have a variable and append to it. Or use an array and keep adding elements. &gt; Also, why use exec with mpv? It's cleaner. Without it, the bash process running your script would still be alive until mpv exits. Read up what `exec` does. To understand it a bit better, you could run a little test script: #!/usr/bin/env bash file="somefile" mpv "$file" echo "this should show up when mpv exits" exec mpv "$file" echo "this should never show up" Now run that script and check your process tree (`pstree(1)` or `htop(1)` using the tree view) and compare when the first mpv is running to the second. &gt; And why do I need set -f (disable file name generation/globbing) I don't think we really need it with what I posted but you also don't need globbing, so it doesn't hurt turning it off. Why you do that is because of something like this: my_args="foo * bar" set -- "$@" $my_args The `*` would get expanded to all files in the current directory, we don't want that. A lot of scripts usually start with `set -efu` as a sane default. If you know you will need filename globbing in your script, *then* don't disable it.
Ah, so mpv "takes over" from the script. https://askubuntu.com/questions/525767/what-does-an-exec-command-do &gt;exec serves to also replace current shell process with a command, so that parent goes a way and child owns pid.
Thanks again Gotcha. I think. I also think I agree that appending to a variable might be clearer. I tend to favour clarity over clever tricks. I understand the use of exec now. But I don't see that it makes much difference. On `set -f` your edit has confused me even more as it tells me i should do the opposite (I think) but not why. Anyway, I need to experiment. You've given me lots to look into. Cheers.
Also, a spesific benefit, if you have a program that launches a hypothetical qpmv script, not a function, it does not get unexpected grandchild. It can just signal qmpv (which now is actually mpv) to terminate.
I was just too lazy to wrap my head around whether or not any of the `*` could potentially get expanded. So I simply disabled globbing for good measure. But since OP wants this for a function sourced in his interactive shells, disabling globbing is not a good idea I guess :D
&gt; On set -f your edit has confused me even more as it tells me i should do the opposite (I think) but not why. The difference between running a function, which was sourced in your interactive shell, and executing a dedicated script, is that the function can/will affect your current shell. So disabling globbing in your qmpv function would mean you can't do something like `ls *.mp3` anymore after you ran the function once. So what I mean is that you should also turn globbing back on in the function by adding `set +f` to it somewhere.
I can't remember the syntax but what you are looking for is select + case Select will work as a while + read + case someone commented before but it will be much cleaner. When I get home I can give look and give an example of you still need it
Good lesson. Thanks! What would you think of using bash arrays like this find=(find $HOME /media -type ... ) for arg do find[${#find[@]}]="-a" find[${#find[@]}]="-iname" find[${#find[@]}]="*${arg}*" done I'm a bash newbie, manpage open, suspecting there is a neater way to append to an array.
The code you posted works fine for me (see below). Post the complete code (with the g option) or clarify the expected behavior. Also, put `$key` within double quotes so that bash doesn't throw an error if nothing is entered. $ cat script.sh read key if [ $key = "e" ]; then { echo exit exit } elif [ $key = "r" ]; then echo rm else : fi $ ./test_script2.sh r rm $ ./test_script2.sh p $ ./test_script2.sh e exit $
Ah, like when you want to ctrl-c a script but it takes several to get your prompt back? This way qpmv is basically a wrapper that behaves just like mpv, right?
I'm actually a newbie too when it comes to bash specifics and I also find the array syntax quite ugly so I never bothered to learn it. A quick search reveals you can do `array+=('new element')`. I also think there is no real reason to have every argument in a separate element (same goes for my positional parameter solution).
That's a different case, happens for example when a program catches and exits on ^C but does convey to the shell running the script that it terminated because of a signal. Or something like that :/ What I ment was that if qmpv was a script, without that exec, and something (say a window manager) launched it and then killed it, mpv would not see that signal.
I had to check, if omitting *in "$@"* would make it loop into the added arguments. Whew... It didn't.
Try to fully expand the var and cast it as a string using if [[ "${key}" =="r"]] Then Fi
Meh, it would be much easier to use the audit daemon to capture/snoop the tty rather than directly modify bash binaries. Same thing, but way way easier, and even supported by the vendor (Red hat).
You very well can, but its a larger footprint. An additional process must be ran, a file must be written to locally on the box, and you would need to make changes /etc/audit/audit.rules which could arise suspicion. With this method, since everything is happening transparently within the bash process, the only footprint that exists is the network traffic coming out, which could be much better masked/obfuscated and hidden in a full scale development of this demo. 
OK. I think that's what I was trying to get at with my limited understanding.
Larger foot print? Non-sense! The audit daemon is practically transparent, highly optimized, and can silently stream the same information over the network encrypted with TLS to a log host. The part about arisings suspicion by audit rules is utterly ridiculous, given that your version does exactly the same thing, but much worse!! In one case a root level user replacing the bash shell, and in the other case a config file is configured. Your method is going to get caught by tripwire, aide, or even the package manager itself (I.E. `rpm -V ...`), and let's not even go into selinux.. ugh. You fail to be persuasive, but whatever dude, it's still a neat demo, and despite the glaring issues it's just a proof of concept. I get it, but still I will assert that it's not necessary because Linux already has sophisticated monitoring, instrumentation/introspection tools.
Your point about selinux/tripwire, etc is very much true. I'm not sure if package managers would see bash since I don't believe its installed via any sort of package, but that may be true. But when I say larger footprint, I mean that if a system administrator were to hop onto this box, and do a thorough investigation of the system, manipulated auditd rules would be discovered long before figuring out that the underlying /bin/bash binary was changed. The only way a system administrator could figure out that /bin/bash was bugged was if they saw the udp traffic, which would ALSO be a discovery vector if you're using auditd to log to a host (encryption is obviously a plus, but that could be implemented in this demo as well), if they checked the hash for /bin/bash and saw it was changed, or if they track file modification times and saw the file was changed recently. If you properly clear command history, reset file timestamps and so on, it would be VERY unlikely this vector was detected outside of utilities like tripwire. auditd is an awesome utility and I'm not disregarding its use and utility, but I believe making changes to auditd would be more easily detectable than manipulating /bin/bash (again, apart from things like selinux and tripwire).
If that‚Äôs the end of your script, what are you expecting to happen when you press any other key? Your script will process the else case of your if (do nothing), then reach the end of the script file and just exit normally... If you want to loop back to the start and process another file then you need some kind of while statement or similar, which someone else has already mentioned.
Hehe. Yeah, I think that was your initial misconception as well?! `for` more or less is a command just like any other. So, the arguments to it get expanded only once just before executing it, meaning that changing the positional parameters, while currently looping over them, has no effect on it.
I totally agree (tl;dw, so not sure of the hack itself). Exploring code is fine and fun, but this is not the correct way to audit activity.
&gt; Edit: Thanks for reminding me that "$@" is used by default in for loops. neat!
You do a simple md5 on files, especially the system binaries, and run a daemon that checks if it changed. You change the bash binary, it's checksum changes, I get notified. Also you check network traffic regularly and the firewalls don't allow random traffic in or out. It's not that simple to change a system binary and go unnoticed. Haven't watched the video yet but sure sounds like a nice POC though!
Yep, and checking those md5's is what things like tripwire is designed to do. I would go as far to say, however, that if a utility like tripwire isn't implemented, sysadmins are rarely, if ever, taking a look at those hashes. Additionally, in terms of firewalls, outbound traffic is rarely strongly filtered, at least not nearly to the extent of inbound traffic. I'm sure in a lot of environments some random outbound ephemeral udp traffic would easily slide through. Nonetheless, you are absolutely correct in saying that in secure environments where things like tripwire and proper filtering in place, an attack vector like this could be hard to pull off.
Totally yeah. I guess on a shared server with cpanel or similar you probably would go by unnoticed. Not sure what you'd keylog on a server like that, though :) Jokes aside, it's true that many servers don't have tight enough security, and this definitely sounds like a fun way to go about this.
I'm guessing the mistake is somewhere in `watson_status` or `parse_git_branch`. Or maybe there is something about PS1 wrong that isn't showing here on reddit. You didn't post your `$PS1` as "code" so reddit might have changed some characters. You can post code by putting four space characters in front of every line of a paragraph.
This may or may not be the kind of feedback you won't care about/for...but FWIW, it costs literally nothing to say: &gt; Based on what you said I think you may not be aware of ${thing} or how ${other thing} may impact... instead of responding to what people say by calling it non-sense or ridiculous or "ugh'ing" in exasperation at people's ideas. I've no doubt you're a competent engineer and maybe even fun to work with in person, but I already don't like you and that seems like a shame. You would have had to do so little different for me to go "wow, I didn't know any of that, I want to pick their brain" instead of "boy, I sure hope if I need help on this forum _they_ don't respond" which you know...kind of devalues the forum as a whole. Or maybe you're normally _really_ nice and this is just an off day, in which case hope things get better! Either way there's my nickel's worth of free advice for the day.
yes you're absolutely right! The solution was to change $(watson\_status) to \\\[$(watson\_status)\\\] thanks for the help :)
[Xonsh](https://xon.sh/) shell might change your mind about pythons suitability as an enhanced shell scripting environment. It's a sort of hybrid between shell and python syntax (but really just python). Working with commands is very concise.
Adding those `\[...\]` like that is a mistake. The `\[...\]` should only go around color codes. It shouldn't go around any character or space that's visible in the terminal, and this `watson_status` probably prints some text sometimes. When it prints something, bash will again not be able to position the cursor correctly.
My `$PS1` is `\e[0;32m\][\e[0m\]\u@\[\033[01;31m\]\h \[\033[01;34m\]\w\e[0;32m\]]\e[0m\]$` Can you tell why mine wraps in the same way?
You are missing several `\[`. The places where they are missing seems to be in front of every `\e` of your $PS1.
Oh, you are right! Well, I usually use Ctrl-BackSpace instead of Ctrl-W because that also gets stored into the paste buffer where you can Ctrl-Y paste it back. But those are useful so I thought it may be worth adding them to your list. Thanks for your hard work!
Thank you a lot for that. I've spent several years working around that annoying shit at both jobs and on my personal PC's because I assumed that it was a problem with terminal emulators so never even thought to google it. I've had this problem across several different OS's (pretty much every Distro I've tried but Ubuntu.) Would you mind explaining to me better why this occurs instead of some other behavior? I'm not sure I understand why it writes over the current line due to a failure to escape certain characters.
It was, a real wtf moment. It all makes sense now. Thanks
`\e[0;32m` is 7 bytes, but it does not make the prompt wider; it is consumed by the terminal, which will colour the next characters with green foreground colour. Readline is the library responsible for displaying the prompt, and accepting terminal input. In many cases it has to wipe out the characters you've input and replace them with other characters, for example when hitting up arrow to get the previous history entry. It has counted the prompt to be X characters long, so it knows that it only has to reprint the characters starting from column X+1, but because of the `\e[0;32m` it thinks the prompt is 7 characters wider than it actually is. You use `\[` and `\]` to tell readline that the bytes between will not make the prompt wider.
If it's possible to grep the date out of each file, I don't see why not. Are the headers preserved in your archived mails ? ``` email_date="$(grep somehow "$file")" mv "$file" "$file $email_date" ``` Something like that, in a loop.
oh i don't know Ctrl-BackSpace! btw you can also Ctrl +w and Ctrl+ u will also gets stored into the paste buffer, and you can Ctrl+y
I've been testing and now have this: SORTOPT="-V" if [ "$1" == "-r" ]; then SORTOPT="-R"; shift fi FINDOPT="$HOME -type f -regextype egrep -iregex .*\.(mp4|mkv|wmv|avi|mpg|mov)$" for arg; do FINDOPT="$FINDOPT -a -iname *${arg}*" done mpv --playlist=&lt;(find $FINDOPT | sort $SORTOPT) Which works nicely and is simpler for me to understand. However, there are two things I cannot quite resolve. If I use the iregex on the commandline I have to quote the regex but here it isn't quoted and works. Would it be better to put escaped quotes in here? Also, I am able to do `qmpv silv*pickups` (when I want to specify the order of terms and so just have one -iname) and it also seems to work without set -f. Thoughts?
Looking good. Two minor things: 1. Try to avoid uppercase variable names to avoid the risk of clashing with environment variables. 2. Since this is going into a bash function, I would probably make all variables local I don't think putting escaped quotes around the file-extension regex works, don't ask me why. The bigger thing is still globbing, though. It just hasn't hit you because you haven't used a search string which also matches files in your current directory. Let's take the take the silversun pickups example again. Say you want to play all files having `sun` in their name but your current directory also has two files in it called sunrise.txt and sunflowers.jpg. With your script, `find` will actually give an error because it's expanded commandline will be this: `find /home/name -type f -regextype egrep -iregex '.*\.(mp4|mkv|wmv|avi|mpg|mov)$' -a -iname sunrise.txt sunflowers.jpg` Now if only one file matched the `*sun*` glob, it wouldn't be a find syntax error but it simplly wouldn't find anything because the resulting expression can never be true: It's searching for a file ending in .(mp4|mkv|...) AND having the literal iname "sunflowers.jpg". Just change the last line to: set -f mpv --playlist... set +f
Yep, I'm in an empty directory. I'll change the variable names, thanks :) Seems quoting is an issue. https://stackoverflow.com/questions/12993706/building-up-a-command-string-for-find &gt;Building up a command string with possibly-quoted arguments is a bad idea. You get into nested quoting levels and eval and a bunch of other dangerous/confusing syntactic stuff. &gt;Use an array to build the find
You can't have forward slashes in file names
Yeah, using arrays like that looks good. I think you avoid the glob problem with it too, without even having to disable it.
Seems we are all learning something which can only be good. And it seemed like such an easy task! Cheers.
(https://www.tldp.org/LDP/abs/html/parameter-substitution.html)[https://www.tldp.org/LDP/abs/html/parameter-substitution.html]
Yes you can get the date from the header line. There are three problems here: * The dates can be in different format depending on region or email client settings * There may be lines in the email resemble the header line like `Date: 04/04/2019` and you don't want to grab those. * You cannot use forward slashes in filename so the date has to be in a different format like 04-04-2019 A robust way to solve this would be to use `sed` (GNU version). Command is shown below for a single file but can be easily extended to a loop. $ filename="RE: Studio Capture" $ datestring=$(sed -n '0,/^Date\:/s/^Date\: \(.*\)/date --date="\1" +"%m-%d-%y"/ep') $ mv $filename "$filename $datestring" Briefly, the above sed command searches between the first line and the first line in the file that contains `Date:` which should be the header line. Then it grabs the date and substitutes it by a version that is formatted with `date` utility in bash. IN GNU sed you can run bash command using `e` option at the end of substitute.
This is much more thorough than my own answer, I'll only add that maybe prefixing instead of suffixing the filename with `YYYY-mm-dd` would allow easy sorting.
I'm on mobile and can't play around with your commands (until I get to work), but w3m is a nifty command-line tool to render webpages inside your shell. Depending on how simplistic the widget is, you might be able to see it by using w3m to render your html content.
Well the html there doesn't contain the data you are after. It is being retrieved by javascript, but neither curl nor wget will run that javascript. Through the chrome inspector I found the api it called, and managed to coax it into returning json: https://api.composer.nprstations.org/v1/widget/53877c98e1c80a130decb6c8/now?format=json With `jq` you can extract the wanted information from that in whatever format you need: $ curl -s 'https://api.composer.nprstations.org/v1/widget/53877c98e1c80a130decb6c8/now?format=json' | jq '.onNow.song | {trackName, artistName, composerName, conductor}' { "trackName": "Divertimento on Bellini's \"Sonnambula:\" Larghetto", "artistName": "Russian National Symphony Orchestra Soloist Ensemble", "composerName": "Mikhail Glinka", "conductor": "" } -- $ curl -s 'https://api.composer.nprstations.org/v1/widget/53877c98e1c80a130decb6c8/now?format=json' | jq -r '.onNow.song | (.trackName, .artistName, .composerName, .conductor)' Divertimento on Bellini's "Sonnambula:" Larghetto Russian National Symphony Orchestra Soloist Ensemble Mikhail Glinka
&gt; curl -s ' &gt; &gt;https://api.composer.nprstations.org/v1/widget/53877c98e1c80a130decb6c8/now?format=json &gt; &gt;' | jq -r '.onNow.song | (.trackName, .artistName, .composerName, .conductor)' &amp;#x200B; Ok. I know this is the internet, and it's impossible to truly know who you're talking to, but please know this. You are a lifesaver, thank you so much for this code. I never knew that about JSON and this is amazing. It works great. I had to change the quotes to this though: curl -s "[https://api.composer.nprstations.org/v1/widget/53877c98e1c80a130decb6c8/now?format=json](https://api.composer.nprstations.org/v1/widget/53877c98e1c80a130decb6c8/now?format=json)" | jq -r ".onNow.song | (.trackName, .artistName, .composerName, .conductor)" &amp;#x200B; Because, your code on her Win10 machine complained: ' was unexpected at this time. &amp;#x200B; Thank you for helping me with this. I was up all night trying to help fix this and surprise her and I failed. I hope you have a wonderful weekend. You are an awesome person.
Thanks for the tip about w3m, that's really handy! Good to know.
Oh, one more thing I thought of - you said that this widget is ~dynamic; does it refresh without loading the page? If so, it's probably making an Ajax call, which you can view in your browsers dev console &gt; network tab. Try copying the `GET` your browser is making to retrieve the widget's content directly rather than getting it indirectly from the page.
&gt;Through the chrome inspector I found the api it called, and managed to coax it into returning json: &amp;#x200B; Can you share a screenshot or a simple breakdown of how you found the api because I bet I'll need to use that in the future again. I am familiar with Firebug but not Chrome's inspector. Can you show me please? Thanks! I can't figure out how you found the link: [https://api.composer.nprstations.org/v1/widget/53877c98e1c80a130decb6c8/now?format=json](https://api.composer.nprstations.org/v1/widget/53877c98e1c80a130decb6c8/now?format=json) from my original widget link: [http://composer.nprstations.org/widgets/iframe/now.html?v=5.11.0&amp;station=53877c98e1c80a130decb6c8](http://composer.nprstations.org/widgets/iframe/now.html?v=5.11.0&amp;station=53877c98e1c80a130decb6c8)
In case this helps anyone who finds this thread, this is how awesome it turned out :) clear echo "" echo "NOW PLAYING:" curl -s "https://api.composer.nprstations.org/v1/widget/53877c98e1c80a130decb6c8/now?format=json" | jq -r ".onNow.song | (.trackNumber, .trackName, .artistName, .composerName, .conductor)" [https://i.ibb.co/NtKnXPd/thankyou.png](https://i.ibb.co/NtKnXPd/thankyou.png)
Ah yes, the webpage https://www.classicalwcrb.org does indeed refresh without me doing anything - all automatic. Thank you for your help.
Esc + c: Capitalizes the word, does not "converts letter under the cursor to uppercase". eg: test becomes Test
Why the fork bomb in the readme? That's like a poor man's troll in the middle of a usefull page. People reading that page might not even know what is a fork bomb. People are curious, read "don't try this at home" and you're sure they'll try it at home.
&gt; Instead of looping over ls you should do for i in *; do ...; done Unless there is no file, then * evaluates to *. $ ls $ mkdir /tmp/reddit $ cd /tmp/reddit/ $ for i in $(ls); do echo file $i;done $ for i in *; do echo file $i;done file * $
You can use `shopt -s nullglob` to disable that behavior. Though afterwards you should re-enable it with `shopt -u nullglob`.
The best! Thanks a lot!
But it does support files with spaces in the name, which looping over `ls` does not
True. You can set IFS to alter behavior with spaces though.
That is also true. But I always feel dirty when I have to mess with IFS
I upvote this with a caveat - unless you're very, very careful, perl code tends to become write-only. IOW no-one else (even yourself after 6 months) can read the code.
thank you! :))
Thank you for reminding me that there are a lot naughty kids out there, I've added more explanation and warning to it. It is a cool one-liner itself. More detail [here](https://askubuntu.com/questions/159491/why-did-the-command-make-my-system-lag-so-badly-i-had-to-reboot)
Where is your cursor when you press Esc + c? When my cursor is in 'e' , it becomes 'tEst'. Maybe it works differently on different system/shell? I tested on Ubuntu and bash.
thanks for sharing!
Welcome. :)
I apologize for the late response. I've been off the grid for two day. Man, thank you very much. It all worked! I'm jumping on my chair right now. Thank you again!
No Problem. Glad I could help.
Couple things. First, you should check the status of your license. If you have a valid license, you may just need to regenerate your API key. Second, from your query, { "field": "alias.url", "operator": "contains", "value": "$ResultFile" }, Not sure where you're setting $ResultFile, but is it a URL? Did you mean to use $Check as that value? Because I don't see anywhere that the URL is being inserted into the query?
ya "value": "$ ResultFile" checks the URL name. This variable name is displayed like value: google.com --that saved $ResultDir/HTTP-google.com-$ToDay.json URL and IP addresses are scanned correctly, but the problem is "else" part does not scan domain URLs ([google.com](https://google.com)) This line reads / url correctly, (http://google.com/) echo "${Check}" | grep -E "/" &gt;/dev/null; then so is there a line to write to read the else statement to read the domain URL ([google.com](https://google.com)) ?
random odd information: the fork bomb also works on the bash running on windows 10, brings the whole system to a screeching halt.
Okay, I ran the script with a few echos thrown in to check the variables. Is file.txt only a list of urls? And when you're running the script are you passing any kind of arguments to cat file.txt | /home/scan.sh Other than the URLs? Because when I run it, this is the result: echo $AddCheckDate echo $1 Both are empty. One thing you can try is changing the command to cat file.txt | bash -x /home/scan.sh Which executes the script in debug mode. You'll see whats going on behind the scenes, what your variables are resolving to, etc. And also try adding these flags to your script. python $ScriptDir/bin/pan-python.py -D -D -D '-D' is debug mode, and '-D -D -D' increases the verbosity to 3 (max). Also, did you [check your license?](https://knowledgebase.paloaltonetworks.com/KCSArticleDetail?id=kA10g000000PLamCAG) That would be the most probable cause of your 409 error. I could see it being something like an invalid query, or some operation not permitted by your license, but I'd check that first.
`find` really would work well here: `find . -type f -exec echo Encoding {} \;`. If you don't want to use it, use `globstar` matching instead: for file in **; do echo "Encoding $file" done Note that this also includes the directories; you can prefix the `echo` command with `[[ -f $file ]] &amp;&amp;` if you want.
Change second line to for files in $mydir/*
That did it. Thanks! I don't know why I didn't think of that....
I'll try this, maybe it's faster.
`man dir`
Add. -type f to limit it to files
Gives those Windows users a false sense of security before being drug into the Void (or Arch, btw)
He means before they take the red pill.
Well then maybe just for them SysAds who are forced to work on Windows Server but only do so in secret through OpenBox
btw I use Antergos.
For what it's worth, the fileutils changelog indicates `dir` and `vdir` was present as far back as February 1990. (GNU fileutils was one of the projects that merged to become GNU coreutils.) I suspect these were added to provide some kind of familiarity for CP/M or DOS users... but it's also entirely possible they were added for some other reason. Code archaeology is hard that far back.
The man page doesn‚Äôt explain *why* it exists, which is what OP was asking about.
That's a `find` option, and I'm already using it. The one I was referring to is `glbostar`.
If I make directories with mkdir, remove them with rmdir, it would seem more odd if there wasn't a simple dir command.
The difference can be seen from the example below. Basically `dir` is equivalent to `ls -Cb` so we do not strictly need dir. But the difference is that `dir` always produces same output independent of whether the it is to stdin or pipe or a file. $ ls test.c test.md test.py test.sh test.txt $ ls | cat subdir test.c test.md test.py test.sh test.txt $ dir subdir test.c test.md test.py test.sh test.txt $ dir | cat subdir test.c test.md test.py test.sh test.txt Also if the files contain control characters then `ls` escapes them by default but `dir` prints the control characters $ touch test^C^[.txt $ ls subdir test.c test.md test.py test.sh test.txt test??.txt $ dir subdir test.c test.md test.py test.sh test.txt test\003\033.txt $ ls -Cb subdir test.c test.md test.py test.sh test.txt test\003\033.txt
*The Matrix* is really fucking old and irrelevant at this point, so you'll have to clarify whatever the fuck you're talking about.
I've also had some interest in code archaeology in the past. I was actually trying to find history of `bc` and why they included the bessel functions in the math library. I contacted the oldest GNU author I could find in the ChangeLog ([source](https://ftp.gnu.org/gnu/bc/)), which was from October 1991. He told me he: &gt; The Bessel functions were part of the original implementation of &gt; bc from AT&amp;T (The original AT&amp;T, not the current company.) I implemented &gt; GNU bc from the POSIX documentation and the Bessel functions were part &gt; of the standard. So while it might be in the oldest GNU implementation there's a good chance that means it came from AT&amp;T's UNIX. Sadly I hit a dead end trying to go farther back. I remember finding the name of one of the original `bc` authors but I wasn't able to get her contact information.
Arrays dont work well as they swallow the quotes. I also did some speed testing and the -iregex in find is over twice as slow as piping through grep. My new approach is to store the result of the first grep in a variable then process that variable in a `for arg` loop with grep. It also means that subsequent runs can reuse the results of the search with new keywords :)
dragged?
I wonder if the other regex types are faster. You can do `find -regextype help` to get a list of supported types. You also have to keep in mind that with find only, you do everything in one process, opposed to 2 + number of search terms. Anyway, I don't think performance really matters all that much, so write it as you prefer.
I thing I know what your talking about. &amp;#x200B; Use sudo once and that message should be gone. If I really know what your talking about. Since you didn't post the writing at all.
You talking about a title bar? Like using Temrinator or Gnome Terminal?
Your question as written is impossible to answer. Try adding a screenshot, or more description, or something.
"Fix" as in rectify a problem or "fix" as in attach?
You want a permanent statement on the top of your terminal? If we all give a shot at trying to guess I'm sure someone will get it :') Edit typozzz
tmux! ;D
As in attach :\* I was thinking to CSS, sorry \^\^
Sorry, I must have expressed myself extremely badly \^\^ I meant: is there a way to attach a writing to the top of the terminal?
; - )
It is apt. You are saying that all the references to these types of things, including how our world is repleat with references to those sayings that Shakespeare coined is invalid because he said them so long ago. That's bullshit. You need to grow up. http://mentalfloss.com/article/60264/21-phrases-you-use-without-realizing-youre-quoting-shakespeare Our whole language is based on the past. So, fucking yes, it is apt, means something, and was a good usage.
It's totally worth it for the speed of the subsequent runs. The find is by far the slowest part.
Not really sure I understand the use case here, but could a message queue like mqtt work for this?
Yeah, I meant using the file-extension regex with find vs only finding all files and piping them to egrep to filter. In my tests I just did, I couldn't really see a difference in speed.
Well, this computer is a bit of a slug ;)
Despite my disingenuous venture to misrepresent my criticism of what might subjectively be a timeless classic, I admit that I continue to enjoy the first part of the series, the specific work which originated the phrase. I was even willing to analyze any resulting language adaptation that it might have inspired, even asking you to clarify. Instead of obliging my pretty reasonable request, you instead shifted the goalpost in diverting Wachowskis' writing to one of history's very greatest. As if to rub salt in the wound, you threw in an agist insult that seems to imply I'm unaware of one of the more widely known sociological tenets regarding the cultural influences of classic literature, one which is frequently reported in high-school reading level periodicals, basically implying I'm uneducated. My point is just that reddit's primary age demographic is shifting to one which, at some point in the future, will probably ultimately be pretty unimpressed with *The Matrix*. Most importantly, everyone and their mother's uncle stopped using "red pill" when it was co-opted as a widely known political dog whistle. Stop pretending you don't know what I'm talking about.
hah, ok :D
`! -path` prevents `find` from printing files with a path matching that pattern, but it doesn't stop `find` from looking through those paths. The error is because `find` is failing to look inside those directories due to permissions. To prevent find from descending into certain directories, you want to use the `-prune` argument. Something more like this: `find . -path '*/.*' -prune -o -print` Note this will also prevent any hidden files from printing, not just prevent descending into hidden directories.
Like this? &amp;#x200B; [http://i.imgur.com/ffqLAa7.png](http://i.imgur.com/ffqLAa7.png)
I use redis lists for this. I utilize the list as a queue, adding new jobs to the back and pulling jobs from the front.
Maybe pipe stderr to /dev/null to suppress the warnings or errors about permissions. Or as written elsewhere use pruning feature.
&gt;That looks promising. how can I integrate into my docker containers?
I've always had a hard time getting find to not output 'Permission denied' warnings natively, so I use a redirect. Not the best solution though if you sometimes need errors. &gt;find . ! -path '\*/.\*' 2&gt; /dev/null
Whats the shebang of this script and does it actually work? Never seen this before.
https://www.gnu.org/software/bash/manual/bash.html#History-Interaction &gt; !string &gt; Refer to the most recent command preceding the current position in the history list starting with s
The same as an exclamation mark in front of any other command: the exit status is the logical negation of the command's exit status. Normally the act of defining a function is successful. (This isn't always the case. Redefinition of a read-only function would be unsuccessful.) This means, normally: f() { :; } is successful, and its exit status is 0. Sticking a `!` in front of it: ! f() { :; } will return an exit status of zero only if defining the function was _unsuccessful_. It appears to be entirely useless in this context, since the success or otherwise is not being examined. (Moreover, if this script was being run under `errexit`, you'd probably want the script to exit if the function _couldn't_ be defined, not if it _could_.)
So to put this in context, I have this in my `gitconfig` as a git alias: &gt; [alias] &gt; fu = "!f() { local msg=\"fixup! $(git log --oneline -n1 | cut -d ' ' -f2-)\"; git commit -am \"${msg}\" &amp;&amp; git rebase -i --autosquash HEAD~2; }; f" &gt; fuc = "!f() { local msg=\"$(git log --oneline -n1 | cut -d ' ' -f2-)\"; if [[ \"${msg}\" != "fixup!"* ]]; then msg=\"fixup! ${msg}\"; fi; git commit -am \"${msg}\"; }; f" It makes less sense now. I've copied the `fu` alias and wrote the `fuc` alias myself, taking `fu` as inspiration.
Its in my `~/.gitconfig` see [here](https://www.reddit.com/r/bash/comments/bo1jme/exclamation_mark_in_front_of_function_definition/enbcoxq/) in this thread.
Context matters. :-) Glad you found your answer.
Thanks &amp; sorry for wasting your time ;)
Just to clarify for others - it is still bash after the !. It just happens to be a git alias in your gitconfig, so that prefixed exclamation is how git aliases know you mean to run an external command. That external command starts after the ‚Äú!‚Äù. According to the git docs: &gt; If the alias expansion is prefixed with an exclamation point, it will be treated as a shell command. https://git-scm.com/docs/git-config
&gt; Assuming you saw this in a script, the same as an exclamation mark in front of any other command: the exit status is the logical negation of the command's exit status. That is only true if there is a space after the exclamation mark, so that it is interpreted as a reserved word. If there is not, then it's just part of the identifier. So ! f() { foo; } defines a function called 'f' and negates the exit status of the function definition command, but !f() { foo; } defines a function called `!f` (which is not a standards compliant function name, but bash accepts it anyway, unless it's in POSIX standard mode).
Umh, let's say yes =) The writing should be always visible, even if the output makes the terminal "scroll down".
I was just referring to the title bar. Which I customize to say; More Power To Ya instead the normal Terminal in the title bar. &amp;#x200B; You're so vague of what you want. We are just guessing here.
You integrate it at the application layer, it doesn‚Äôt matter where it runs, it just needs access to a redis server. I run an application that pushes events into the queue, and I can scale up the processing of those events by as much as I would like. It‚Äôs ideal for an environment where you are producing events faster than you can process them. You should be able to run like ‚Äòredis-cli lpop someQueue‚Äô to pop an event from the beginning.
The "shell script" is a few hundred lines of installer script concatenated with the 48MB binary package to be installed. It's in one file for your convenience. The shell ignores everything after the `exit` since it'll obviously have exited then, but the script can still read its own file to get at the data.
I didn't know that was possible, but it makes a lot of sense to have everything in one file. Thanks
This. Also, the script may detail what method the script uses to get the binary contents out of the text file if you're curious, and/or need more info.
Huh. Interesting.
1. Open the page in chrome or chromium 1. Open the [chrome devtools](https://developers.google.com/web/tools/chrome-devtools/) 1. In the devtools, select the *Network* tab. 1. Reload the page. You'll now see all the requests that was made to load and render that page, including the ajax request to get the currently running song. The url it used from the page contained a lot of query parameters, like `format=jsonp` and `callback=jQuery&lt;long number&gt;`. I just removed all of them and only added `?format=json`, which happened to work.
Try `bsdtar tvf file.sh`. should give you some insight!
Do you have a website also?
Ah, you're right. I was thinking `!` was a control operator, so it would always be parsed as a separate token. But it isn't.
I follow exactly what you mean - thank you many times!
okay, that sounds just what I want. How do I set this Redis server on another docker container and redis client on my original containers? Because I don't really like my current approach of my containers, 2 transcode commands, sometime even 3 or 4 running simultaneously, and that makes each of the transcode job takes 1 hour, 2 even.
&gt; Everything looks ok ...apart from the 47MB that you don't understand.. &gt; What is the purpose of that content That is the software you are trying to install &gt; why is taking so much space in the file? be grateful that it is compressed - it could be a lot bigger ;-)
This ... plus .. I have seen some self-contained bash scripts -- not in a very long time though. I think Oracle used to do this with their oracle installer. The script basically is the app and unpacks itself before running it. I don't like using them though as the obvious security issues and running unknown code.
Here you go. I added a shebang line so it's always executed with bash even if you use different shell. `shopt -s globstar` turns on recursive globbing using `**`. The `[ -f ... ]` checks if file exists, if it does `continue` moves onto the next iteration of the loop. #!/bin/bash SRC="/drives/downloads/Show/" DEST="/drives/Video/Temp" DEST_EXT=mkv HANDBRAKE_CLI=HandBrakeCLI shopt -s globstar for FILE in "$SRC"/** do filename=$(basename "$FILE") extension=${filename##*.} filename=${filename%.*} [ -f "$DEST/$filename.$DEST_EXT" ] &amp;&amp; continue $HANDBRAKE_CLI -i "$FILE" -o "$DEST/$filename.$DEST_EXT" --preset-import-file /drives/shared/scripts/x265TvAAC.json -Z "x265TV" done
strings and binwalk will help
McAfee still does this with their agent installer for Linux.
Thanks, I'll test it out.
Dell firmware packages all do this too. The payload is a part of the bash script and in the script it finds the exit and pipes all but the first lines before it into tar or unzip.
https://www.gnu.org/software/coreutils/manual/coreutils.html#dir-invocation According to the man pages, written by Stallman himself: http://man7.org/linux/man-pages/man1/dir.1.html
I have created a github page for it: https://onceupon.github.io/Bash-Oneliner/
Your question is not very clear... What would be the input of the script, and what would be the output? Can you give an explicit example?
Yeah. I saw that you are gonna update more on it! Thank you in advance for that! üëç
we have 2 files , file1 and file2 both are stocked in a repertory called rep1 we compare them if they are identical , we put one of them in another repertory ? rep2 for an example and we display a message if not we display a message saying that they are not identical btw sorry that's what i want to say in the question
OK donc l'algo ce serait un truc du style : compareFichiers(fichier1, fichier2) { if fichier1 identique fichier2 { d√©placer fichier2 dans repertoire2 } else { afficher "fichier1 et fichier2 ne sont pas identiques" } } C'est bien √ßa ?
&gt;compareFichiers(fichier1, fichier2) { if fichier1 identique fichier2 { d√©placer fichier2 dans repertoire2 } else { afficher "fichier1 et fichier2 ne sont pas identiques" } } oui exactement ! et merci pour le vocabulaire , l'anglais est ma troisi√®me langue haha
OK du coup je ferais quelque chose dans ce style: function compareFiles() { cmp --silent "$1" "$2" &amp;&amp; mv "$2" /path/to/repertoire2 || echo "'$1' and '$2' are not identical " } _______ [man cmp](https://linux.die.net/man/1/cmp)
Try using cmp. Look it up with man.
git diff file1 file2 &amp;&amp; cp file2 /path/to/other/repo
"man diff" and go from there.
`#!/bin/bash` `#` `# call this script: scriptname /path/to/rep1/file1 /path/to/rep1/file2 /path/to/rep2` `#` &amp;#x200B; `#` `# assign params to friendly var names` `#` `FILE1="${1}";` `FILE2="${2}";` `REP2="${3}";` &amp;#x200B; `diff --brief -s ${FILE1} ${FILE2}` &amp;#x200B; `case ${?} in` `0)` `echo "Identical - copying ${FILE1} to ${REP2}";` `cp ${FILE1} ${REP2};` `;;` `1)` `echo "Different - not copying";` `;;` `*)` `echo "Unhandled condition!" &gt;&amp;2;` `;;` `esac`
GOG distributes all their games on Linux with the Mojo installer. It looks [like this](http://ix.io/1J0J) (this one is for FTL) with the tar archive data appended to the end. The heavy lifters are the `MS_dd` and `UnTAR` functions. dd handles the data offset to skip the shell script, and tar decompresses the archive: MS_dd "$0" $offset $s | eval "gzip -cd" | UnTAR t
Use `$i` instead of `$file` in the loop's body.
Thank you so much! It‚Äôs getting too late here :)
Some minor improvements: read -p "Enter file names: " for file in "$REPLY"; do [ -w "$file" ] &amp;&amp; w=Yes || w=No [ -x "$file" ] &amp;&amp; x=Yes || x=No [ -r "$file" ] &amp;&amp; r=Yes || r=No printf '%s\n' "$file permissions" \ "Write = $w" \ "Execute = $x" \ "Read = $r" done
md5 hash each file. If the hash value is the same then the files are identical. Use an if statement to compare them and move if I‚Äôd needed
This doesn't look like bash...
Breaks with filenames that have spaces or tabs, also should prolly use `-r` for the read.
Should probably use -r with that read. And what if your filenames have spaces or tabs? printf 'Enter file names (press ^D to end input):\n' mapfile -t files for file in "${files[@]}"; do [ -w "$file" ] &amp;&amp; w=Yes || w=No [ -x "$file" ] &amp;&amp; x=Yes || x=No [ -r "$file" ] &amp;&amp; r=Yes || r=No printf '%s\n' "$file permissions" \ "Write = $w" \ "Execute = $x" \ "Read = $r" done
I've never actually used read without -r, I forgot this time. The c() function is nice. I don't think reading filenames from stdin is a good solution to begin with, so I didn't put too much thought into how to perfect it. But also to stick closer to OPs original code to not confuse him. If he's willing to learn, he should definitely look at your take though.
Not sure why you would do it with the read. Would you not want to get a list? But below will do what you are looking for I believe. for it to be a list of names as you have it they have to be on a single line. \[root@mysandbox\]# sh \~/foo4 Enter file names: /root/foo1 /root/foo2 /root/foo3 /root/foo1 -rwx------ 700 /root/foo2 -r-------- 400 /root/foo3 -rw------- 600 &amp;#x200B; \[root@mysandbox\]# cat \~/foo4 echo "Enter file names: " read file for i in $file;do echo "$i \`stat -c %A $i &amp;&amp; stat -c %a $i\`" echo "$1" done
you have my word ;)
:)
Couldn't you just like... do this? ssh -i "IDENTITY_FILE" "USER@IP" ./SOME_REMOTE_SCRIPT.sh ./SOME_LOCAL_SCRIPT.sh ssh -i "IDENTITY_FILE" "USER@IP" ./SOME_REMOTE_SCRIPT_2.sh
I'd do this with Ansible.
What about a named pipe? fifo="yourfifo" mkfifo -- "$fifo" tail -f -- "$fifo" | ssh -T -i "IDENTITY_FILE" "USER@IP" remote() { printf '%s\n' "$@" &gt;"$fifo"; } remote "~/SOME_REMOTE_SCRIPT.sh" $SC_DIR/SOME_LOCAL_SCIPT.sh remote "~/SOME_REMOTE_SCRIPT_2.sh" rm -- "$fifo"
There‚Äôs some Kung fu in here, would you mind giving a little context?
That opens 2 ssh sessions, which op seems to not want to do
Nah, it was a terrible idea because since ssh runs in the background, it wouldn't wait for commands to finish and you can end up with the first remote command finishing *after* the first local command.
You could do it with cksum no matter the type of file.
Thanks for your answer. Like jhizzle mentioned, this works but creates 2 ssh sessions. I want fastest possible execution of the scripts.
md5sum, sha1sum, sha256sum, cksum, etc.. any had function pretty much, and it's not limited to pairs.
https://stackoverflow.com/questions/20410252/how-to-reuse-an-ssh-connection?answertab=votes#tab-top What about that? That way you can start the first ssh connection in the background and save it's pid using `$!` so you can kill it at the end of the script.
If you have controlmasters on then that new ssh is just a fork and thus almost instant.
God no.
ssh -R /tmp/backchannel:/tmp/backchannel would create a Unix-domain socket on the remote end, and forward a (say) netcat connection back to the local end. You could arrange a netcat -Ul /tmp/backchannel as a bash copro on the local end, to execute the local script. Too crazy...
Use a fast checksum, e.g. md5sum, and output the result to a file... and then sort it `for f in *; do md5sum "$f" &gt;&gt; ../list.txt; done`
It looks like your submission contains a shell script. To properly format it as code, place four space characters before every line of the script, and a blank line between the script and the rest of the text, like this: This is normal text. #!/bin/bash echo "This is code!" &gt; This is normal text. &gt; &gt; #!/bin/bash &gt; echo "This is code!" *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/bash) if you have any questions or concerns.*
Something like this should do it. find -type f | xargs md5sum | sort | uniq -w32 -D
Here is an example of how I do my scrubs (each disk has its own screen session) `screen -S $disk -dm bash -c "time (scrub -f -p dod /dev/$disk)"`
It's called file deduplication - there are some standalone applications like `fdupes`. And as others have mentioned, you use checksum based deduplication too.
Excellent, I can make use of this. Thanks!
 awk 'BEGIN {getline; printf "%s", $1} {printf "\t%s", $1}' file.csv Or you could just remove the tab from the end. awk '{print $1\t}' file.csv | sed 's/\t$//'
Thanks.
Here's a Perl one-liner: perl -n0777E 'say join "\t", split "\n"' filename
Slightly better version of the first. awk '{printf "%s", $1;while (getline &gt; 0) printf "\t%s", $1; print ""}'
This works: `cat file.csv | tr '\n' '\t' | sed 's/\t$//g'`
Exactly, while not super common its a technique that's been around for a long time and appears in the wild every now and again.
No, I asked him whether I understood the desired algorithm
Good bot
What I do is simply use to terminal windows, or one window with 2 tabs.
Why do you need to do this frequently?
Really I just needed syntactical clarification on how to pass longer functions to screen. Putting `bash -c` and then the stuff I needed after it in quotes helped. It doesn't do anything frequently, just needed a working loop in a screen session so when the server crashes it would auto restart, and I wanted this accomplished in 1 script.
Sorry I meant to reply to the scrub person!
Why do you need to do this frequently?
Oh. This message will self destruct in 5 minutes
On mobile but I think paste -sd\t Is what you want
jdupes is a maintained fork with more features including stay on one filesystem
I wrote this years ago... some syntax can definitely be improved, but im lazy and it should still work #!/bin/bash # chkconfig: 2345 20 80 # description: This is the Minecraft Server - Start up script # Source function library. . /etc/init.d/functions start() { echo "Starting Minecraft Server" /opt/mcserver/mcserver-startup.sh &amp; &gt; /dev/null if [[ 0 = $(echo $?) ]] then echo "Minecraft Server Started" else echo "Minecraft Server Failed to Start:" fi } stop() { echo "Stopping Minecraft Server" kill $(ps aux | grep [j]ava | grep minecraft_server.jar| grep "ui$" | awk '{print $2}') screen -X -S mcserver quit if [[ 0 = $(echo $?) ]] then echo "Minecraft Server Stopped" else echo "Minecraft Server Failed to Stop" fi } destroy() { echo "Destroying process for Minecraft Server" kill -9 $(ps aux | grep [j]ava | grep minecraft_server.jar| grep "ui$" | awk '{print $2}') rm -fr /var/run/mcserver.pid rm -fr /var/lock/subsys/minecraft screen -X -S mcserver quit } case "$1" in start) start ;; stop) stop ;; restart) stop start ;; status) if ps aux | grep [j]ava &gt; /dev/null then echo "Process is running with PID $(ps aux | grep [j]ava | grep "ui$" | awk '{print $2}')" echo "State Code of the process is: $(ps aux | grep [j]ava | grep "ui$"| awk '{print $8}')" else echo "mcserver is not running" fi ;; destroy) destroy ;; *) echo "Usage: $0 {start|stop|status|restart|destroy}" esac exit 0 &amp;#x200B; #! /bin/bash # This is the start up script for the minecraft server called by /etc/init.d/minecraft $mc cd /opt/mcserver/minecraft screen -dmS mcserver sh -c "java -Xmx768M -Xms768M -jar minecraft_server.1.12.1.jar nogui; exec /bin/bash" echo $! &gt; /var/run/mcserver.pid
&gt; awk '{print $1\t}' file.csv | sed 's/\t$//' 3 characters shorter: awk -vORS=\\t 1 file.csv | sed 's/\t$//' As /u/bwduncan suggests, `paste(1)` seems to be the way to go, though.
`-s` only is enough. This is the best solution, imo.
Needed two \\ when I tried it, but that might be a the post formatting rather than you. `paste -sd\\t filename`
For something like this I'd probably use [http://supervisord.org/](http://supervisord.org/) with a config file a bit like this: [program:minecraft] command=java -Xms512M -Xmx1536M -jar server.jar nogui autostart=true autorestart=true stderr_logfile=/var/log/minecraft.err stdout_logfile=/var/log/minecraft.log
 printf '%s\t' &lt; file
Oh jeez, I see the problem. Looks fine on desktop, is fucked on mobile
Why reinvent the wheel. This is just what paste was written for.
I've never seen something quite like `${file@E}` before, and I can't find anything with google on what the `@E` is doing here. I'm familiar with string manipulation using `#` and `%` and such, but have never seen `@`. Can you explain that a bit?
Lots of servers means lots of HDD warranty claims. Those require sending the faulty disk back.
This should be doing that trick: \- 0 12 \* \* 1,2,3,4,6,7 /your-command-every-day-but-Friday \- 0 \*/1 \* \* 5 /your-command-only-on-Friday
You need to have two crontab entries to do this. # every day at noon, except on fridays 0 12 * * 0-4,6 /your/command &gt;/dev/null 2&gt;&amp;1 # friday, every hour 0 * * * 5 /your/command &gt;/dev/null 2&gt;&amp;1
Thanks for your correct instructions, and the problem is the license has expired
It's one of the newer features in bash, I think. The different operators for it are explained at the end of [this manual section](https://www.gnu.org/software/bash/manual/html_node/Shell-Parameter-Expansion.html#Shell-Parameter-Expansion). The two top ones are the only ones I've personally used in my scripts. They are rooughly equivalent to... `${file@Q}` to `printf '%q' "$file"` `${file@E}` to `printf "$file"`
No need for brackets. `if condition; then ...; fi`. However, find(1) very often returns a 0 exit code, so it won't help. find ... | while read -r _file; do ...; done
You already have answers but this might help in the future: https://crontab.guru
I kind of find a solution, but it still doesn't work. if [[ `find /var/log/file_name* -mtime +80 | wc -l` -gt 0 ]]; then hostname &gt;&gt; brokenServers.txt fi but for some reason it doesn't work. It returns a huge list of files and then 0 at the end. find: ‚Äò/var/log/file_name1‚Äô: File or directory not found find: ‚Äò/var/log/file_name2‚Äô: File or directory not found find: ‚Äò/var/log/file_name3‚Äô: File or directory not found 0 The 0 at the end should be 7, cause there are 7 files in one of the servers I am testing it with. I am using a script who has a "for" inside it. I also have a list with the servers. Everytime the "for script" runs through the list, it picks the # server, and says "run the if_find_old_logs_then_do.sh script" In the end it kind of looks like that: cssh server_name if_find_old_logs_then_do.sh That means for each server inside my list, it should run the if_find_old_logs_then_do.sh. Inside the if_find_old_logs_then_do.sh, it says: if [[ `find /var/log/file_name* -mtime +80 | wc -l` -gt 0 ]]; then hostname &gt;&gt; brokenServers.txt fi
What is the ask here?
I think what you are looking for is Multiplexing: [https://en.wikibooks.org/wiki/OpenSSH/Cookbook/Multiplexing](https://en.wikibooks.org/wiki/OpenSSH/Cookbook/Multiplexing) Take a look at the following extract (file is \~/.ssh/config): Host machine1 HostName machine1.example.org ControlPath ~/.ssh/controlmasters/%r@%h:%p ControlMaster auto ControlPersist 10m &gt;With that configuration, the first connection to *machine1* will create a control socket in the directory **\~/.ssh/controlmasters/** Then any subsequent connections, up to 10 by default as set by **MaxSessions** on the SSH server, will re-use that control path automatically as multiplexed sessions. Confirmation of each new connection can be required if **ControlMaster** set to 'autoask' instead of 'auto'. This means that you will open only one SSH connection through the chosen socket to the remote server, and all the following will reuse that same socket. It's a good practise to use the `/tmp` folder for your sockets, this way they will be erased at bootup. &amp;#x200B; I hope this helps!
Cool makes sense! Thanks
I think what you meant is `find /var/log -name "file_name*" ...`.
Run it every hour, and have it check if its Friday every time it runs
You haven't said anything about how you're producing this output. But if you're currently just using `echo`, consider using `printf` instead. For example: printf '[*] %-26s %s\n' 'HeUsesWindows' '[BAD]' printf '[*] %-26s %s\n' 'WindowsIsUsedByHim' '[BAD]'
It's produced by a "sed expression" which filters the output of another program.
Came here to post this. Great tool!
Without details there's no way to provide useful suggestions. What I gave you demonstrates how `printf` can be used to print formatted output. It's up to you to use it effectively.
man 1 column
Don't forget you can put logic in the script too. if (( $(date +%u) != 5 )) then exit fi echo "It's Friday!"
Yup. That was it. I made another post and another Redditor helped me. Thank you as well for helping.
So pipe it through `column` as suggested elsewhere, or post details of the command you are using - nobody here is psychic, and your 5ecr3t 5cr1ptz ~~probably~~ aren't worth nicking if you need to ask this question....
Sorry, I just didn't want to make you think too much about my "script" \^\^. Here is the part: -j|--judge) tcpdump -tlN -n -nn 'port 53' 2&gt;/dev/null | sed -n 's/^.\+? \(.*\(google\|amazon\|facebook\|microsoft\|apple\|youtube\|telemetry\).*\)\. .\+$/[*] \1 [BAD]/p ; s/^.\+? \(.\+\)\..\+$/[*] \1/p' If you want to run it (with sudo), you can see it just prints out your dns query (extracted from tcpdump with sed). I wanted to align \[BAD\]s next to the domains.
Like the ancient saying: give a man a crontab entry and he'll be happy for a day, teach him how to write his own crontab entries, and he'll be happy for the rest of his life. ^(or something like that)
Maybe this? ls -lR --time-style=long-iso | sort -k6,7 | tail -2
 find /home/ -type f -name '*201905*.zip' -print
while read -r line; do a=($line); last=${a[-1]}; unset a[-1]; printf '%s %26s\n' "${a[*]}" "$last"; done
You can with AppleScript in macOS (as opposed to Bash), but it's rather finicky.
Thank you. I tried your suggestion today. This showed some improvements but they were not that good as I thought they would be. ~/.ssh/config: Host * ControlMaster auto ControlPath ~/.ssh/%r@%h-%p ControlPersist 30 #1st ssh-connection time ssh -i IDENTITY_FILE user@IP "exit" real 0m0.302s user 0m0.020s sys 0m0.000s #2nd ssh-connection time ssh -i IDENTITY_FILE user@IP "exit" real 0m0.139s user 0m0.009s sys 0m0.003s
Thank you. I tried your suggestion today. This showed some improvements but they were not that good as I thought they would be. ~/.ssh/config: Host * ControlMaster auto ControlPath ~/.ssh/%r@%h-%p ControlPersist 30 #1st ssh-connection time ssh -i IDENTITY_FILE user@IP "exit" real 0m0.302s user 0m0.020s sys 0m0.000s #2nd ssh-connection time ssh -i IDENTITY_FILE user@IP "exit" real 0m0.139s user 0m0.009s sys 0m0.003s
With some better keywords to research with I actually have found something called "xdotool". I probably shouldve mentioned I have a ubuntu based system. So far xdotool seems the most reasonable
I figured it was a toss-up but wanted to mention it, I wish you luck!
Thank you for ur input :^)
Hard to say without knowing which system you're on, but `xdotool` is popular for this on Linux distributions.
Mouse clicks are just events in the GUI that triggers certain programs. Why would you want to automate a mouse click? Not only it is pointless but highly error prone. Find the underlying function or script that mouse click triggers and convert it into a bash script by calling it directly.
Personally I use xdotool for this. Here is an example script that I whipped up the other day for doing some mundane shit in runescape. #!/bin/bash while :; do xdotool \ mousemove 504 397 \ sleep 0.5 \ click 3 \ mousemove 504 422 \ sleep 0.5 \ click 1 \ mousemove 571 601 \ sleep 1 \ click 1 \ mousemove 224 119 \ sleep 0.5 \ click 3 \ mousemove 224 191 \ sleep 0.5 \ click 1 \ mousemove 269 119 \ sleep 0.5 \ click 3 \ mousemove 269 221 \ sleep 0.5 \ click 1 \ mousemove 859 329 \ sleep 0.5 \ click 1 \ mousemove 230 721 \ sleep 12 \ click 1 \ mousemove 865 134 \ sleep 28 \ click 1 \ sleep 12 done
&gt; Why would you want to automate a mouse click? Sometimes task is boring and this is the fastest way to automate it.
Does the user running the script have privileges to create the directory? And why do you purposefully avoid quoting all your variable expansions? You should probably add -r to your read. 15,18c15,17 &lt; while [ "$domain" == "" ] &lt; do &lt; echo -e $"Provide a domain. e.g. domain.lan or Ctrl+c to quit." &lt; read domain --- &gt; while [ "$domain" == "" ]; do &gt; echo 'Provide a domain. e.g. domain.lan or Ctrl+c to quit.' &gt; read -r domain 22c21 &lt; documentRoot='/home/'$USER'/dev/websites/'$domain --- &gt; documentRoot="/home/$USER/dev/websites/$domain" 25c24 &lt; mkdir -p $documentRoot --- &gt; mkdir -p -- "$documentRoot" 28c27 &lt; chown -R $USER:www-data $documentRoot --- &gt; chown -R "$USER:www-data" "$documentRoot" 31c30 &lt; &gt; '/etc/apache2/sites-available/'$domain'.conf' cat &lt;&lt;EOF --- &gt; &gt; "/etc/apache2/sites-available/$domain.conf" cat &lt;&lt;EOF 59c58 &lt; a2ensite $domain'.conf' --- &gt; a2ensite "$domain.conf" 63c62 &lt; echo -e "127.0.0.1\t"$domain &gt;&gt; /etc/hosts --- &gt; echo "127.0.0.1\t$domain" &gt;&gt; /etc/hosts
I'd do the deletion with just parallel. parallel --slh servers.lst --nonall -j 16 -- find filename* -mtime +31 --print --delete And then afterwards it's easy to do the same without the delete to get a list of remaining files from the servers. parallel --slh servers.lst --nonall -j 16 -- find filename* -mtime +31 --print Some jackass will probably tell you to use ansible. Having managed similar sized environment with it I'll tell you DON'T.
What does the `--` do in `mkdir -p -- "$documentRoot"`?
You really should use heredocs for those usage messages... Here is an example. cat &lt;&lt; EOF $script_name A flexible and simple command to deal with sets of git repositories. Reposet provides a handful of subcommands to run common or specified actions on sets of git repositories. Commands are: $script_name apply - execute a given bash command or series of commands $script_name list - list contents of given reposets $script_name list-sets - list reposets $script_name pull - pull from a remote $script_name push - push to a remote $script_name status - show status of repositories $script_name sync - combined pull and push Usage: $script_name [&lt;subcommand&gt;] [...] Examples: $script_name # print the status of the repositories in the default reposet $script_name pull work # call git pull --rebase on all repos in the reposet "work" $script_name push my work # call git push on all repos in the reposets "my" and "work" $script_name apply -q my -- ls -al # call \`ls -al\` on each repository in the reposet "my" $script_name -h # print the usage message $script_name --help # print the usage message For more information visit http://github.com/langenhagen/reposet. EOF
In tools that support `--` it signifies end of options. Most coreutils support this as do many other important tools. It's quite useful if your variable might start with a dash. It's not really necessary here but since you haven't gotten quoting down yet it might be best to deault to using it whenever it's available. For example `rm -- -rf foo bar` would delete a file named `-rf` instead of enabling options `-r` and `-f`.
That's what I wound up doing as well. I'm not sure if this is the best solution for what I'm going to wind up doing with this though. I've been out of town so I haven't had a chance to play around with it. The question I had to myself was if I store the results of the find in an array do the errors get stored or are those ignored? If it's the former then that's great and this solved everything.
Hi StallmanTheLeft, thank you for the suggestion. I considered using cat or read with heredocs for the usage strings. However, I decided to use printf in order to retain the indentation.
It's the neatest way that I've encountered so far to run a script over ssh. There weren't any answers out there that I could find which fully described this technique, thus I wrote the [gist](https://gist.github.com/sourcesimian/933b26f4e8ff516959f9890387bcd512) in the hope that I might help other people avoid spending years doing it in klunky ways, as I did.
I'm pretty noob would you be able to point me in the direction of some resources that speak about what you're talking about in more depth? Seems useful ! Thanks for leaving your 2 cents.
&gt; Does the user running the script have privileges to create the directory? Yes, they're creating it in their own home folder. &gt; And why do you purposefully avoid quoting all your variable expansions? It's just that I looked it up and copied an example. I'm pretty new to bash.
 documentRoot="$HOME/dev/websites/$domain" documentRoot=~/dev/websites/$domain Have you considered using `$HOME` or `~/`? Home isn't necessarily always in `/home/$USER`. &gt;Yes, they're creating it in their own home folder. But are they running the script with su or sudo? A regular user wouldn't normally have write permissions to /etc. You might want to check /root/dev/websites.
üòÇ brings me back to the AllAdvantage days.
You aren't even using the `$f` in any part of that command. Just get rid of the loop, it's completely unnecessary.
What I was talking about was quite general but the way to achieve that is specific to the application. So you have provide more information about program and the particular functionality you want to automate. As an example of what I was thinking about you can check the KDE window manager scripting [page](https://techbase.kde.org/Development/Tutorials/KWin/Scripting#The_basic_outline) which describes ways you can exploit the API to call specific functions that manages windows.
I spent a couple of hours wondering why this wasn't working. Nothing was being printed to screen. Then I was reading up on the exact way prune works and I finally figured out that I need to remove the ! before -path.
Well, you can use `&lt;&lt;-EOF` instead to strip leading tabs, but it seems that you're indenting with spaces. You could at least use `msg+="something"` instead of `msg="${msg}something"`.
Look into Selenium if you're trying to automate something in the browser. I used to use AutoHotKey for this kind of stuff on Windows but it seems that doesn't have Linux support. [This discussion](https://unix.stackexchange.com/questions/165124/autohotkey-equivalent) might be useful though.
You're totally right! That bit has been in since so many iterations of the code I forgot it wasn't even necessary. Thanks!
Sometimes a fresh set of eyes helps.
too much. you can just `sed` the whole file, without the need to loop through each line.
Who made this site? I've been using for a few years now. It's super helpful. I would love to just thank them
* Sed, awk etc processes each line of the file by default so no need to loop through. Also sed needs to read from a file or stdin which should be provided as an argument after the pattern. * Also note that removing all forms of allowed C comments in a non-trivial task using sed and regexes. If all your comments comments follow the `//` single line or `/*..*/` multi-line pattern then it is easier. But you have to use sed multi-line commands for the latter. IMO a much easier option is to use `gcc` which already does this preprocessing before sending it to the compiler. For example you can use &amp;#8203; gcc -fpreprocessed -dD -E -P -o $outputfile $filename In the above `-fpreprocessed` will suppress macro expansion, `-dD` dumps macro definitions, `-E` stops at preprocessing and `-P` cleans up the output. Finally `-o` with filename argument writes to the file.
Thank you :)
I'm in this camp as well. Let filters do what they do best. Of course I can't blame OP for trying when it seems like some developers won't write a shell script without a loop and a \`read\`. Is this a divisive issue among developers? Or is the Internet priming me to look for controversy?
look in. the course material for which field is the 'day of week' field. Then look up how to specify a range for a field.
Would something like: "cat input.file | grep -vP 'PERL-REGEX PATTERN' &gt; output.file" much easier?
I would love to be able to understand what you are talking about, but unfortunately I am an absolute beginner. Also I have never seen commands being used with their full names. I don't even know if it's possible. In my company some of the commands have deactivated(?) parameters. For example "column" might have a "-0" parameter according to man page in internet, but in our server it doesn't exist. Thanks for trying to help though.
&gt; find /home/ -type f -name '*201905*.zip' -print Thanks. Or, when located at /home find . -iname '*201905*.zip' The secret is to put filename wildcard in quotes. That's what I wasn't doing!
There is a link on the page. It was made by [https://cronitor.io/](https://cronitor.io/)
&gt; But are they running the script with su or sudo? Yes, I'm using Ubuntu Mate and sudo.
So the actual user running the script is most likely to root user. Did you check that dir I told you about? You could perhaps do something like this: [[ $SUDO_UID ]] &amp;&amp; home=$(awk -v FS=: -v u="$SUDO_UID" \'$3 == u {print $6}) documentRoot="${home:-$HOME}/dev/websites/$domain}"
`parallel` is just a nice tool called GNU parallel. It's very nice for parallelizing both local and remote tasks. The `--slh` (`--sshloginfile`) takes a list of logins for ssh that will be used to distribute the tasks. Say you had 10000 images to resize, you could easily use parallel to distribute that task to multiple computers using parallel. `--onall` is an option that tells parallel to run all tasks on all the hosts, `--nonall` is the same except it doesn't read any arguments but instead runs the bare command, in this case `find ...`. I forgot to add `--tag` which just appends the sshlogin to the output.
a bit late, but, [this is what I write](https://gitlab.com/skidnik/scripts/blob/master/a2set) to quickly manage local webservers.
Here is my take on your repo. ---- 1. Even though there is nothing malicious in your install script (it's literally just cloning the repo to a specific directory), you shouldn't tell people to pipe directly into bash. While most people here probably already know to check the script that they're piping, there are new linux/bash users who don't understand the probable danger of piping random scripts they find on the internet into bash. At least give people the warning of the dangers of piping into bash if you're going to have them do that. 2. There is no need for an install script when it is literally a single command.
Hi Crestwave, indeed, I was unaware of the operator += for arbitrary variables. However, I decided to change definitions of help messages in a way that comes close to what StallmanTheLeft suggested.
Just an idea, but maybe something like this, the two 1 second sleeps may or may not be necessary. Depends on how fast xdotool can do its stuff. This will restart it every hour restart(){ sleep 1 CUR_DATE=$(date +%s) /usr/bin/chromium-browser --noerrdialogs --disable-infobars --kiosk https://www.new-innov.com/pub/ https://www.new-innov.com/pub/about.html &amp; } restart while true; do xdotool keydown ctrl+Tab xdotool keyup ctrl+Tab sleep 5 NEW_DATE=$(date +%s) if [[ $(echo ${NEW_DATE}-${CUR_DATE} | bc -l) &gt; 3600 ]]; then WINDOW_ID=$(xdotool --search "New Innovation" --delay 100 | tail -1) sleep 1 xdotool windowactivate --sync ${WIN_ID} key --clearmodifiers --delay 100 Alt+F4 restart fi done If you want something more robust, you could look into selenium with python or something. Also, personal choice, but I would use firefox instead if I were you
Thanks! It‚Äôs for work and they‚Äôre specifically requesting Chromium.
ah I see, lame How does the above work? You could change it to restart after 10 seconds or something for a test &amp;#x200B; edit: mind if I ask why they want to do this? depending on what they want, there may be a better way with curl or something, or another tool
I don't see a syntax error there, but it does use bash-specific syntax (the `&lt;(`...`)` process substitution construct). So make sure you run it with bash, and not sh. If that's not it, then the real error is in some other line of the script. Syntax errors don't always show up in the lines that actually cause them. For example, quoting errors can cause a big chunk of the script to be interpreted as a literal string before it reaches the end and the quote was never terminated, throwing a syntax error at the end though the real problem is way back.
Is there a reason your not using something like cron or systemd to handle the timer side of things? It'd be easier to create the timer in cron / systemd and attach the kill script to that.
Using a raspberry pi to display helpdesk tickets and other status‚Äôs. The websites I have listed are simply for example purposes. I changed the 3600 to 10 but nothing happened.
Im very new to bash and dont really know how :((
ah I see It's probably the search name, change New Innovation to whatever the title bar of the browser is
In this case I would recommend getting your feet dirty with either cron or systemd, whichever is installed by default on your linux distro, because it will make creating this timer and script all that easier. Here are a few guides to get you started. &amp;#x200B; [https://www.linux.com/blog/learn/intro-to-linux/2018/7/setting-timer-systemd-linux](https://www.linux.com/blog/learn/intro-to-linux/2018/7/setting-timer-systemd-linux) &amp;#x200B; [https://www.marksei.com/howto-cron/](https://www.marksei.com/howto-cron/) &amp;#x200B; The benefit to using cron / systemd is that cron or systemd handle the actual calling of the script at the set time, so you can configure your script just to restart chromium.
 [Unit] Description=Chromium Kiosk Wants=graphical.target After=graphical.target [Service] Environment=DISPLAY=:0 Environment=XAUTHORITY=/home/pi/.Xauthority Type=simple ExecStart=/bin/bash /home/pi/kiosk.sh Restart=on-failure RestartSec=3 User=pi Group=pi [Install] WantedBy=graphical.target would something like this work?
It may be an encoding issue... ensure that the file is saved as ascii or UTF-8 It also could be an issue with how Windows and Linux do newlines different. Windows uses CRLF and Linux uses LF So it may be trying to use the CR character as part of the filename. Save the file as LF or Unix line endings, or just open it in `vi` and remove those extra characters.
Can you just cat file_2 &gt;&gt; file_1 This will append to file_1
 gdb -batch -n -ex 'dprintf LINE, "%u\n", VARIABLE' -ex 'run' PROGRAM maybe? Obviously, vague questions only get vague answers..
&gt;HEADER=$(cat file\_1.csv) &amp;&amp; sed -i "1s/\^/${HEADER}/" file\_2.csv
No matter what, a 2nd copy of the huge file will get created. The bytes are on disk as they are. There is no way to make a file bigger from the front.
Also if posix mode is set using `set -o posix`. Need to disable using `set +o posix`. BTW the "pipeline" script linked by OP reminded me of [this xkcd](https://xkcd.com/2054/).
You can use `sed` to insert the header of the first file to the top of the second file. This will be the most optimal solution. Plenty of online example how to insert a line at a specific location using `sed`. You could them delete the first file to effectively maintain steady state.
ed, man! printf '0r %s\nwq\n' file_1.csv | ed -s file_2.csc
I came across also "sponge" [http://joeyh.name/code/moreutils/](http://joeyh.name/code/moreutils/) &gt;cat file\_1.csv file\_2.csv | sponge file3.txt
So based on your suggestion, my latest is #!/bin/bash # This is for devlopment in the user's home directory # Set the path you your local dev folder in the documentRoot variable. domain=$1 # Check if the user is running as root or sudo if (( $UID != 0 )); then printf &gt;&amp;2 'You should run this as root/sudo\n' exit 1 fi # Get user input: while [ "$domain" == "" ]; do echo 'Provide a domain. e.g. domain.lan or Ctrl+c to quit.' read -r domain done # Set the path to the document root - the place you will be adding your site's devlopment folder [[ $SUDO_UID ]] &amp;&amp; home=$(awk -v FS=: -v u="$SUDO_UID" \'$3 == u {print $6}) documentRoot="${home:-$HOME}/dev/websites/$domain}" # Create the directory to store the files mkdir -p -- "$documentRoot" # Set permissions and assign permissions to the current user. chown -R "$USER:www-data" "$documentRoot" # Write this to Apache's sites-available.conf &gt; "/etc/apache2/sites-available/$domain.conf" cat &lt;&lt;EOF &lt;VirtualHost *:80&gt; ServerName $domain ServerAlias www.$domain ServerAdmin webmaster@localhost DocumentRoot $documentRoot #LogLevel info ssl:warn ErrorLog \${APACHE_LOG_DIR}/error.log #CustomLog \${APACHE_LOG_DIR}/access.log combined #Include conf-available/serve-cgi-bin.conf &lt;Directory $documentRoot &gt; Options Indexes FollowSymLinks MultiViews # AllowOverride All allows using .htaccess AllowOverride All Order allow,deny allow from all &lt;/Directory&gt; &lt;/VirtualHost&gt; EOF # a2ensite, a2dissite - enable or disable an apache2 site / virtual host a2ensite "$domain.conf" # Append your domain to /etc/hosts echo "127.0.0.1\t$domain" &gt;&gt; /etc/hosts # Restart apache service apache2 restart but when I run that, I get leon@V5:~/dev$ sudo ./my_local_virtualhost.sh [sudo] password for leon: Provide a domain. e.g. domain.lan or Ctrl+c to quit. one.local awk: cmd. line:1: ' awk: cmd. line:1: ^ invalid char ''' in expression Enabling site one.local. To activate the new configuration, you need to run: systemctl reload apache2 The created directory is owned by root, which I guess makes sense now.
Thanks. Can't say I understand all of it, but there looks like some useful stuff there :)
That looks good. I'm not a pro at systemd, but it may take a few tries to get the right timer setup. One thing I can tell you is that the Environment section isn't needed for the most part, and I've been able to setup Timers w/o User and Group. &amp;#x200B; You will likely also need a Timer file and a Service file. The Timer will call your Service file that will start your script.
I converted the line endings to LF and it works now! Thank you!
This 'sponge' tool is only useful if you want to overwrite one of your existing files (meaning one of the two files on the left side of the `|`). If you want to create a new file then using `&gt;` is better.
No it is not the most optimal solution. In place substitution in sed creates a temporary file first and then at the end of processing will moves it to the old file. So it actually needs more space than the original file.
I updated this post to solved. i added &amp;#x200B; watchdogSec=30 Restart=always seems to work great right now. Obviously going to change "30" to probably however I see fit. Thanks for the input though
Sorry, I don't think so because `sed -i` will edit the file "in place" unless an extension is supplied. By default a zero length extension is used, meaning the file is altered in place.
To write to a file you have to load the file in memory, there's is no way around that. However you can combine the header and the file directly to whatever command you're using to process the file using something like `cat file1.csv file2.csv | command`. The `command` of course should be able to read from stdin.
Fantastic! Glad to be of help.
Thank you!
[Read the manual](https://www.gnu.org/software/sed/manual/sed.html#Command_002dLine-Options)
Yeah? But even if a behind the scenes temp file is used, how is this not optimal? From a simplicity point of view, it's easy. A different directory or file system could be used if your so obsessive on file space aspects.
 \'$3 == u {print $6} This should be '$3 == u {print $6}'
Ok, did you even read OP's question? It is clearly mentioned that file2 is huge so a solution like `cat file1.csv file2.csv &gt; file3.csv` is not desirable. `sed -i` will do exactly that with the additional step of overwriting file2 with file3. This means there needs to be free space at least as large as file2 size to run the command.
This is the most elegant solution
You're right. The temp file is really sub optimal and if file2 is really huge, then using sed will take forever.
There are bunch of places in your script that have pretty lacking quoting. Also instead of `[ ! -z $foo ]` you can just do `[[ $foo ]]`. Also when you are using `[ ]` you should always quote your variables. I recommend you install shellcheck. [Here](http://ix.io/1JfW) is my edit of your script. Some of the stuff is purely for cosmetical reasons.
`ed` truly is the greatest.
Maybe not so much. $ du file_* 4.0K file_1.csv 1014M file_2.csv 1014M total Not sure if this is a good benchmark but these are the results: oed 0m13.30s real 0m12.28s user 0m01.01s system gnu sed 0m09.45s real 0m03.16s user 0m06.28s system busybox ed 0m08.78s real 0m02.07s user 0m06.71s system busybox sed 0m04.69s real 0m04.20s user 0m00.49s system
I said greatest, not the fastest.
I'll hate myself for this when future me reads this, but, I think this is the perfect job for ansible
Since I don't see anyone saying this: there is no way to prepend a file the way you would append to a file, at least that I'm aware of. I don't think it is supported by the linux filesystem abstractions. If you only need to read the file once you could look into a named pipe (check the mkfifo command). If you want the file to exist on the filesystem, you have to re-write the file. If the file_2.csv file is bigger than your free disk space, there might be an ugly way to do it but my suggestion would be to either split up file_2.csv so you can do it incrementally, compress file_2, or ideally get more disk space.
If you have the source file, why not just modify it to directly output the data?
cat &lt;(head -2 /etc/motd) &lt;(cat /etc/passwd)|less (named pipes - it generates a stream so you'r not 'loading' the entire file - the only way to load a file is to allocate a gigantic buffer and copy the file into it which no tool does because they use the stream abstraction anyhow) [https://www.gnu.org/software/libc/manual/html\_node/Streams.html#Streams](https://www.gnu.org/software/libc/manual/html_node/Streams.html#Streams)
Im not sure if this is actually better than the other solutions proposed, but it just might let you avoid making a copy (temporary or otherwise) of the huge second file. Im not on a linux machine atm, but i think the commands are # use fallocate to make a hole in the start of file 2 the same size as file 1 fallocate -i -o 0 -l $(stat --printf="%s" file_1.csv) file_2.csv # write file 1 contents to the new hole at the start of file 2 dd if=file_1.csv of=file_2.csv oflag=direct
If the order of records does not matter, you could overwrite the first bytes with the header, padded with blanks to align into existing rows. Then the sacrificed line or or two would need to be appended to the end.
I‚Äôd want to see the code for that... the issue here is usually that the filestream data has to go *somewhere*, even if being created, so is it just in-memory until the replacement stream is ready or doing something more elegant to reproduce a filestream head-insert?
Thanks, It's just me.
This script starts as regular user which is supposed to use the webserver, parses user input, restarts itself as root, `a2setup` function sets apache to run as the user that started the script. Running php (here it's ran by apache via php mod) as a user that edits the code lets you get rid of the file permissions/ownership clusterfuck. Not safe in server environment, perfectly fine on a workstation where the app is not publicly available.
What are you *trying to do*?
I need eval to see the output of echo \\$int\_${str\_testarea}=\`expr \\\\$int\_${str\_testarea}+1\` but when I try to do when I do it results in the errors above am I closing off the experssion wrong?...
nope - what are you trying to ***do***? Wh(at,y) is `str_testarea` ?
I'm guessing at what your overall goal is based on the existence of `$int_T0=$int_T0+1`, and from that what I think you're really after is an associative array. So instead of having lots of variables called $int_T0 $int_T1 and $int_ whatever-else-str_testarea-contains, you have one associative array, and the contents of str_testarea are used to look up values in it. For example: ``` #!/bin/bash declare -A myarray=() str_testarea=T0 # This is the replacement for $int_T0=0 myarray[${str_testarea}]=0 echo ${myarray[$str_testarea]} # This is where you increment the value stored under the entry # for T0 ((myarray[\$str_testarea]++)) echo ${myarray[$str_testarea]} ```
Always try to avoid eval. You can use declare to assign values to variables which names are... variables: `declare int_$str_testarea=...`. You can also use references to variables with -n: `declare -n v=int_${str_testarea}`. Play with it a bit. But I think using an array or associative array would be better, as said in another comment.
if you really need to do this, you need to store the variable name in anorher variable, so this worked for me: int_T0=0 tmp_str="int_${str_testarea}" echo "int_${str_testarea}=$(expr ${!tmp_str} + 1)"
Literally what cat is short for! Concatenate.
[https://wiki.archlinux.org/index.php/dmenu](https://wiki.archlinux.org/index.php/dmenu)
nice, i like that you can add directories to always be searched
I'm guessing it creates a temporary file and then renames it at the end when the stream closes. There's a sentence about temporary files in its man-page.
I'll already fix it :)
Ok, so then it is the bash-specific syntax. I've been running this using sh, so I will try bash. Do I literally type "bash [nameofscript.sh](https://nameofscript.sh)" and then maybe some of those syntax errors will be resolved by that? Thanks for that information, it is very helpful. I'll run using bash command and see what happens.
&gt;this xkcd I will check out what mode I'm in. Thanks for that. Also, the link is hilarious and exactly what I feel like I've been going through lol I've been teaching myself command line and bioinformatics
How about this? https://developer.valvesoftware.com/wiki/SteamCMD
 Use four spaces instead of triple backticks please
Very nice! :-)
No, drugged.
In the .desktop files that the Steam client creates for desktop icons or start menu entries, the command that's run looks like this (this example uses the Kerbal Space Program App-ID): steam steam://rungameid/220200
Is this a sample of the actual file or are these words some kind of stand ins for actual data? If you can't give us an actual sample I don't think it will be possible to help you.
Instead of sourcing you could just read a file and parse it in some way Let's say we have a file like setting1 foo setting2 bar And we wanted to only accept while read -r var val; do case "$var" in (setting1|setting2)) $var="${val[*]}" ;; (*) printf 'Unknown var: %q\n\tValue: %q\n' "$var" "${val[*]}" ;; esac done This wou099
Those are the actual first fields of one of the files. I was not going to include the rest of the files which give IPs and ports.
 n=0 while read -r first rest; do [ "$first" = "SECURITYGROUPS" ] &amp;&amp; ((n++));; printf '%s %s\n' "$firt" "$rest" &gt;&gt;"file$n" done
a bit shonky but awk 'BEGIN {filenumber=0} $0 ~ /^SECURITYGROUPS/ {do {print &gt;"securitygroup-"filenumber ; if (getline == 0) {continue} } while ($0 !~ /^TAGS/) } {if ($0!="") {print &gt; "securitygroup-"filenumber ; filenumber++ } {} END { print filenumber " security groups processed."}' INPUTFILE
The 'sed' tool can get that range of lines out of a file like this: sed -n '/^SECURITYGROUPS$/,/^TAGS$/ p' filename
When you have a problem that allows you to use the line range/flip-flop operators you gotta take advantage of it.
[Link for the lazy](https://github.com/langenhagen/explore-with-dmenu) Looks really handy, I can't wait to try it out when I get back to my laptop. (I hate clicking and I especially hate touchpads, anything to keep my hands on the homerow)
[Link for the lazy](https://github.com/langenhagen/explore-with-dmenu) Looks really handy, I can't wait to try it out when I get back to my laptop. (I hate clicking and I especially hate touchpads, anything to keep my hands on the homerow)
[Link for the lazy](https://github.com/langenhagen/explore-with-dmenu) Looks really handy, I can't wait to try it out when I get back to my laptop. (I hate clicking and I especially hate touchpads, anything to keep my hands on the homerow)
[Link for the lazy](https://github.com/langenhagen/explore-with-dmenu) Looks really handy, I can't wait to try it out when I get back to my laptop. (I hate clicking and I especially hate touchpads, anything to keep my hands on the homerow)
[Link for the lazy](https://github.com/langenhagen/explore-with-dmenu) Looks really handy, I can't wait to try it out when I get back to my laptop. (I hate clicking and I especially hate touchpads, anything to keep my hands on the homerow)
Not found Second link
Not found Second link
I think you scared OP away :D Great post though, totally agree that most people make it much harder to help them than it should be. People struggle with formatting their post properly. Quite often the easiest way to help is if they simply supply input and desired output, no hard to understand explanation of what they try to so.
Thanks a lot! Works like a charm!
https://warwick.ac.uk/fac/sci/statistics/staff/academic-research/firth/software/pdfjam/ seems like the right tool for the job
the `psutils` package has a slew of programs that might be able to help you
I generally use pdftk or stapler.
Since I couldn't be bothered to build pdftk from source (my distro doesn't have it), I used gs to compress the pdfs and sejda.com to rotate and merge them.
Just use a flag to keep track of ending pattern. It is much cleaner $ awk '/^SECURITYGROUPS$/{flag = 1; filen++ ; next} /^TAGS$/{flag=0} flag{print &gt; "securitygroup-"filen }' INPUTFILE
That was not what OP asked, he needed to put each of those patterns into individual files. So sed is not really the right tool for the job as it cannot keep track of number of matches. Also to get the lines between pattern one can directly do this sed -n '/^SECURITYGROUPS$/,/^TAGS$/{//!p}' filename The above suppresses all lines that doesn't match the pattern (-n flag) and among those that match only prints those that do not contain the range specifiers (GNU sed) OR sed '/^SECURITYGROUPS$/,/^TAGS$/!d; //d' filename Here it deletes any line that matches the pattern and then deletes line containing the range specifiers.
A while loop does this perfectly: while read line; do #stuff done &lt; $file
Most bash commands will process a file line by line. What do you want to do with each line?
Just keep the whole line temporarily in a variable.
1. Is necessary the name 'line'? 2. Thank you, I was missing the "&lt; $file" part :P
1. No, line is a variable and therefore the name is arbitrary. 2. Yes, $file represents the file name of whatever you want to read.
One that cares for nothing but the starting line of the pattern... awk 'BEGIN {filenumber=0} /^SECURITYGROUPS/ {filenumber++ } {print &gt; "securitygroup-"filenumber} END { print filenumber " security groups processed."}' INPUTFILE
Don't need to use `awk` enough to remember flags, but aye... .. then again, if the format is reliable, don't even need to track the last..
pdftk --help
Thx again
I normally use the same while loop but recently while using it to call another large bash script I found that that $line would be corrupted every few lines. The bash script it called is large and it calls other programs. Unable to figure out what is causing the problem, I've taken to run each line in $file as a separate bash script.
 eval int_${str_testarea}=`eval expr \\$int_${str_testarea} + 1` Is there a problem with the question logic, we would need two rounds, first round to get int\_T0 and then another to get it's value ?
Note: This may not work as desired when a) There are whitespaces (for example from indentation) before or after a line. read will strip those. b) If there are backslash escape characters in the line c) If the last line doesn't end with a newline (read exits as soon as it encounters EOF) A more robust version is as below while IFS='' read -r line || [ -n "$line" ] ; do #stuff done &lt; $file Here `IFS=''` prevents stripping of whitespace, the `-r` flag prevents backslash characters from being interpreted and `[ -n "$line" ]` makes sure that the last line is still used when end of file is reached and there is no newline after the end of last line. To read a file directly into an array use `readarray` or `mapfile` like `readarray -t arrayname &lt; filename`
Very nice :)
Thanks!
Thanks ALOT to the stranger that gave gold!!
I just do it like this: cat file.txt | while read i; do echo i; done Replacing echo i with whatever you want to do with each line.
Nice work. I think you missed a local declaration in debug to match all other functions.
I like it! Needs a trap though
thanks for the suggestion. unfortunately it didn't work when i tried to use it, so i made some changes to it and used the following instead: # apply configuration from "${conf_file}" if test -f "$(readlink --canonicalize "${conf_file}")" ; then while IFS=' ' read -r configuration ; do case "${configuration}" in "setting1 "* | "setting2 "* ) # remove the first space and everything after it, then use the remainder as the variable name. remove the first space and everything before it, then use the remainder as the value eval "${configuration%% *}"="${configuration#* }" ;; * ) printf 'Unknown variable: "%s"\nValue: "%s"\n' "${configuration%% *}" "${configuration#* }" &amp;&amp; exit 2 ;; esac done &lt; "${conf_file}" fi which seems to work alright and solves my second problem, but i'm not sure if the use of `eval` could be problematic though. i'm also still unsure about how i can solve my first problem. still, thanks.
IMHO needs two separate functions: `err()` and `die()`. Sometimes you don't want to `exit 1` after redtext.
succ!
What are you trying to achieve? There are many tools to do different things. Parsers like grep, awk, or sed process files line by line already.
Locales be damned. Deduplicate all the dates to a simple function so folks with different date requirements can easily adjust.
well python would be a lot easier to maintain for larger scripts The question is, what does the script do; if it makes sense to use python then use it. rsync is usually something you would want to use from a shell. especially if you are wanting the security of `ssh` and the checksum checks.
This is okey but you should set IFS and I would also use `set efu`. Also, other CLI tools usually parse all options. You abort on the first occurance of `-h`, ignoring all potential usage errors after it. Not a fan of the `-d`. Much better to have quiet and verbose options and dynamically redefine the output functions depending on it with `debug() :;`.
Hey, Schreq, just a quick heads-up: **occurance** is actually spelled **occurrence**. You can remember it by **two cs, two rs, -ence not -ance**. Have a nice day! ^^^^The ^^^^parent ^^^^commenter ^^^^can ^^^^reply ^^^^with ^^^^'delete' ^^^^to ^^^^delete ^^^^this ^^^^comment.
delete
I added the steps to the main post, and I don't use ssh or checksum, I use rsync for the --progress flag.
well if you are only using `rsync` to copy a file, and you want a visualisation of % done; then you can always use https://pypi.org/project/progress/ to help make one around the copy functionality within python
I mean, what you have done makes sense to keep it in `bash`, but it's really up to you if you feel it's going to get bigger or more complex, then perhaps rewrite it in python
&gt; I am using a justfile(similar to makefile) Why not just use make tbh.
Just has better error messages and just - l list all the commands you created with their description
Apologies, I didn't realise old-reddit didn't support markdown.
It supports markdown. It doesn't support any extensions that aren't actually markdown.
Python is not the only way, perl is more focused fir this sort of job, and it's been around forever. People are just nuts about python these days.
You have to take those arguments and pass them to the program. You are declaring them but you aren't using them.
How do you pass it to the program? Thats what I'm trying to figure out, but everything I've tried so far just gives me an error. Would it be like this in the sh file? /path/to/program $arg1 $arg2 $arg 3
I would do a find script that compares the contents to a source list file and sends a message if it finds one out of place.
What would the benefit be of rewriting in e.g. Python?
I would use python over perl any day. **So** much easier to read, write, and maintain in comparison.
But what do you want to do with each line? The variables are doing what?
Could you provide the full script that doesn't work? You could try putting `echo` at the start of the command that's not working (i.e. `echo sudo arp-scan ...`) ‚Äì that would show you the command that's being run.
It will be something like ‚Äòfind &lt;DIR_TO_LOOK&gt; ‚Äîname=‚Äú*.html‚Äù ‚Äîexec &lt;IDE_NAME&gt; {} \;‚Äô
Exactly. Script: #!/bin/bash /bin/echo "butter and $1" /bin/echo "parsley and $2" Command line: $ bash script.sh scones sage Output: &gt; butter and scones &gt; parsley and sage Is the same as: #!/bin/bash arg1=scones arg2=sage /bin/echo "butter and $arg1" /bin/echo "parsley and $arg2"
If I want to look in the current location as well as all other sub-directories I assume I use `/` ? And for IDE_NAME, is there a specific name one must use for the IDE ?
To look in your current directory you could use `./` or `.` The IDE NAME but the name of the ode that you are trying to open your files in.
That's part of the question I'm asking, I like bash but this talk about best practices gets me wondering when it's okay to disregard these guidelines and for instance make a script that 100+ lines despite the rule of thumb being that a script of this size should possibly be written in python or another more advanced scripting language instead.
Not working with; `find ./ ‚Äîname=‚Äú*.html‚Äù ‚Äîexec vscode {} \;`
Perl has frustrated me before because of the difficulty of finding and installing new modules. There needs to be a simple way like pip to install perl related dependencies, otherwise too much time is wasted on fixing something that shouldn't be broken. And I haven't used perl for several years now, but I liked it when I first learned it. So how is perl better than bash and python at doing these file transfers etc?
If you still find it easy enough to modify with confidence, then keep it in bash. I think that ppl recommend python because it is easier to read and provides easy to understand stacktraces when things blow up.
Each line contains a mac address, one address at a time will be loaded over the current one and then the OS sends a TCP handshake to [debian.org](https://debian.org) to check if the address in use makes you surf the web. This is because in some networks only some devices are allowed to navigate.
It is not just about lines of code but more on the complexity. Ultimately efficient programming is mostly about selecting the simplest algorithm and data structures that can solve your problem. Bash being a shell scripting language has limited set of data structures and some of the notations can get pretty awkward (for example strings and arrays). In this case I'd look into the underlying data structures used in the script and see if it would be easier if you convert these to python data structures such as list, dictionary etc. That often makes it far easier for example to use a variety of different input data formats such as json. Also python being object-oriented means you can package your functions into classes which could improve reuse, extensibility and maintenance significantly. All of the tasks you mentioned in the purpose of the script can of course be done in python. Python comes with powerful modules in standard library such as os, subprocess, shutil, io, pathlib, filecmp, logging etc that can perform those tasks. The additional benefit is that with a little effort you can make the code portable enough so that it can be run in most other shells or linux distros or even Windows/Mac. Having said all of that using python does come with an overhead that all of the os specific commands are run through a subshell with additional system calls which could cause a loss of performance (in most cases it is acceptable). A shell language like Bash has its own advantage of providing a much simpler way of managing processes by piping together different commands, putting jobs on background, redirecting I/O, process substitutions etc. Of course this can be done in Python but requires lot more syntax so there's a trade-off. So ultimately it comes down to how you plan to use the script. Is it something that is to be used for a short period or something that many people will use for a long time? I'd say make an equivalent python script that does the same thing and compare them in terms of readability, ease of maintenance and performance. Then take the decision to switch or not switch.
FWIW, you can do some cool things with `read` that aren‚Äôt immediately obvious. For instance, say you have a file and each line is a bunch of stuff and you only want the second and fourth item to do stuff with? Easy! while read junk var1 junk var2 junk do #var1 is the 2nd element #var2 is the 4th element #junk now contains the rest of the line after the 4th element done &lt; /path/to/file I use this construct frequently when stripping stuff out of CSV files (just tweak the IFS to use a comma as separator - see /u/random_cynic post above for the general idea).
One good reason to stay in Bash: the job you're trying to do is basically invoke a bunch of CLI utils in a particular order, and watch their exit codes to determine when something goes wrong. Bash is excellent at that because that's pretty much what it's made to do. _If_, however, your script is becoming difficult to maintain, then maybe you have a good argument for Python.
good point! fixed it
`find .` means ‚Äúeverything from this current directory on down. Don‚Äôt need the slash. Also don‚Äôt need the = sign. So do `find . -name ‚Äú*.html‚Äù -exec vscode {} \;` Also, this command will serially tell vscode to open a file, you can also try passing the results to xargs like `find . -name ‚Äú*.html‚Äù -print {} | xargs vscode`
The first command returns; `find: `vscode': No such file or directory` The second command returns; `find: `.-name': No such file or directory find: `*.html': No such file or directory xargs: vscode: No such file or directory `
In my eyes, the key thing to look at is how much of the script is simply invoking commands (`rsync`, `mkdir`, etc.) and how much of the script is implementing logic (`if/else`, `while`, etc.) As long as the script is primarily invoking commands, I think it's still appropriate to keep it a shell script. But once there's a significant amount of logic, I find shell scripts become a burden to maintain.
perl has only been around about 2 years longer then python. I've used both, but in terms of readability and increasing use of python, I would recommend python for a user who may want to move to a higher level language from shell scripting.
as a person who only knows bash well enough to make something decent, I can tell you perl is way easier and more intuitive to read.
Have you tried adding `ORDER BY field` to your SQL query?
&gt; The problem is..i dont know how to work with arrays in linux https://www.tldp.org/LDP/Bash-Beginners-Guide/html/sect_10_02.html OK.. that is sorted... Here is an example.. Obj1...19 May 2019 7:00 .. 19 May 2019 8:00 .. Visible. Obj1.. 19 May 2019 10:00 .. 19 May 2019 11:00 .. 90% Visible. Obj1.. 19 May 2019 9:00 .. 19 May 2019 10:00 .. Visible. Usually people's "examples" have [little in common](https://www.reddit.com/r/linuxquestions/comments/bqglgl/i_need_help_from_my_linux_friends/eo4fsbw/) with reality.... so actually writing a solution that works is impossible without being a mindreader Of course your database might output multiple items with identical tiimestamps....
Bash is basically a "glue language" in that you're sticking several commands together, and running them in sequence. I have seen bash scripts in excess of 700lines just because it made more sense to use that. If your script will benefit from more complex control structures, then pick a more complex language.
I would just set up an IRC server.
Well I‚Äôm trying to re-learn what I forgot. Basic Bash skills‚Ä¶ So thanks for the comment, but I‚Äôm trying to recreate this script.
Sounds like you guys just used `cat` to append something to the end of the file. Rough idea off the top of my head; takes input from user and catenate it to the end of a file on the server using scp I‚Äôd imagine while all users refresh that file periodically. /shrug
Sry, the .. Stuff was to signify the next set of data is a different field. That stuff is not a part of the output the actual output has nothing but spaces.
can you give more details please
Rather than creating an itch to scratch, scratch an actual itch you have. It will bring more actionable knowledge than whatever weird projects you had in the past.
I always found `cpan`/`cpanm` a very convenient way to install Perl modules from CPAN.
Just put it in your .bashrc or .bash_profile
I know that. The point is to do it in a shell script because I am going to make a script that has practical use and then tell students to use it. I want put the PS1 variable change in the script so kids will then have to figure out how to fix it.
The only way that will work is if the script puts something in .bash_rc or bash_profile. The script being executed can‚Äôt change the environment it was called from because it is given it‚Äôs own separate environment when executed.
Damn. okay thanks
What kind of script is it? Does it spawns an interactive bash session? If so, use `export PS1=&lt;your setting&gt;` to make sure it is available in that session. Another way to use that script would be to ask the kids to `source` your script at startup which should contain the `export PS1=&lt;your setting&gt;` line. Then they should see the altered `PS1`.
This seems to just make bash worse... (so just like C++ with C I guess)
The IDE you want isn‚Äôt in your PATH
How should it be in my path so it's readable, what is the variable I must use ?
That‚Äôs tricky from over here, as I don‚Äôt know where your IDE is installed. However, in bash, you set the PATH variable as a colon separated directories like this `export PATH=/bin:/usr/bin:/usr/local/bin` If you simply want to add something to the end of that, you‚Äôd do like `export PATH=$PATH:/new/directory` Obviously you‚Äôd put an actual directory path there
# ***?***
That‚Äôs gruesome. Just use Python.
I can't set a path in SSH for a computer which does not have a version of nix installed. The only way is to set a path in Windows; and then will the command read the path to search all the directories on the server and load them into the IDE ?
Yes, but you can't execute it normally as that starts a new process. Instead you need to run the script in the current process which is done with `source` or `.`: source set_ps1.sh . set_ps1_.sh
psql -Atqc "select to\_char(begin\_time,'yyyy-mm-dd hh24:mi') as begin\_time, to\_char\_end\_time'yyyy-mm-dd hh24:mi') as end\_time, visable from your\_table where visable in ('Visible','90% Visible');" &gt; result.out
Not sure what you‚Äôre asking. If you SSH into another box, you have an environment with variables you can set. It sounds like you‚Äôre doing something different than a normal user would do.
In order to do the command which you mentioned I have to put the IDE in this case vscode into my path. Although I'm not running any flavor of nix nor WSL; therefore how can I run the command which you mentioned if the local machine has no flavor of nix ? The only other solution is for the command you mentioned to read the environment variable, in this case for Windows to know where to load the files searched on the server into the IDE.
This sounds right!
Nope.
Maybe put the change in `/etc/bashrc`?
cat [changePs1.sh](https://changePs1.sh) \#!/bin/bash export PS1="Whatever " &amp;#x200B; source [changePs1.sh](https://changePs1.sh) &amp;#x200B; and you have the new prompt..
Can you give us more detail as to what you‚Äôre trying to achieve?
A function that take 2 directories as an argument and display(output) the files that were in directory 1 but moved to directory 2. And the files stocked in the two directories but were modified
And thank you for your response
Thanks. Since Vim 8 I have been using the in-built terminal in Vim (`:terminal`) a lot though as I found the readline vi-mode to be limited. It allows me to use all the Vim commands for command line editing and my .vimrc settings.
Maybe with gdb, attach to the shell process and call putenv("PS1=funny ")
I've been working on this for a while and have finally gotten it to work as desired. Feedback is much appreciated. Thank you
That is one of the coolest things I've seen. Sadly my ddwrt compatible router is dead so until I find another one I won't be able to test this myself
Personally I feel it's just easier to loop over and use modulo as the index. foo=(a b c d e f g) for((i=0; i&lt;20; i++)); do echo "${foo[$((i%${#foo[@]}))]}" done
 set editing-mode vi set show-mode-in-prompt on set vi-ins-mode-string \1\033[1;32m\2INS\1\033[m\2 set vi-cmd-mode-string \1\033[1;31m\2CMD\1\033[m\2 I've had these in my inputrc for some time now. They affect all programs using readline, not just bash.
[Relevant xkcd](https://xkcd.com/1168).
Tar is confusing for me. I have to keep looking it up to compress and extract. Tar is inobvious. Tar filename.tar.gz should know if it is a gz and should auto offer folder name. Tar foldername should just you if you want it compressed and a filename. If you provide this info as parameters it should take thatinstead of asking. Tar is just so inobvious and it doesn't need to be. The inobvious nature of current software is killing desktop computing.
Tar works as and other POSIX utility. It‚Äôs only unobvious to people coming from windows (in my professional experience). As for your parameters, that‚Äôs what the flags/switches are for: $ tar -xvf tarball.tar -C /directory/of/output As for gz, as far as I‚Äôm aware it is GNU that offer gzip compression/extraction with the -z flag: $ tar -xzvf tarball.tar.gz -C /directory/of/output Pretty sure the -C is redundant in later versions (I keep it for clarity and habit)
My point exactly. It is so overly complex and it doesn't need to be. The programmers can do far more by simply trying. I suggested simplicity by having the program do the logic and inferences. Anything else is burden due to being inobvious.
This is where you can script something for yourself to make it easier for you to use. I wrote myself a couple scripts to handle certain specific tar jobs I do at work to save myself the trouble from looking it up every time. And for my coworkers who aren't very good with Linux, I wrote a script to handle unzipping for them with minimal input (we unzip large files that would take hours on a windows machine). I even have an alias to just echo some lengthy commands so I can copy/paste/edit as needed. This is my way of "simply trying".
Could do: #!/bin/sh for subdirectory in "$(find "${directory}" -type d -print0)" ; do for files in "$(find "${subdirectory}" -type f -print0)" ; do printf '%s is a file in %s\n' "${file}" "${subdirectory}" done done
#!/bin/bash # # foo=(a b c d e f g) # read -erp "number to shift by: " n # for ((i=0; i&lt; (n%${#foo[@]}); i++)); do # foo=("${foo[-1]}" "${foo[@]}") # unset foo[-1] # done # echo "${foo[*]}" There are many ways you can skin this cat. If you don't mind bash-specific things then the most obvious one is globstar. shopt -s globstar for file in "$dir"/**; do [ -w "$file" ] &amp;&amp; W="Write = yes" || W="Write = No" [ -x "$file" ] &amp;&amp; X="Execute = yes" || X="Execute = No" [ -r "$file" ] &amp;&amp; R="Read = yes" || R="Read = No" echo "$file permissions" echo "$W" echo "$R" echo "$X" done If you do mind it you could make a recursive function pretty easily. scan_dir() { for file in "$dir"/*; do [ -w "$file" ] &amp;&amp; W="Write = yes" || W="Write = No" [ -x "$file" ] &amp;&amp; X="Execute = yes" || X="Execute = No" [ -r "$file" ] &amp;&amp; R="Read = yes" || R="Read = No" echo "$file permissions" echo "$W" echo "$R" echo "$X" [ -d "$file" ] &amp;&amp; scan_dir "$file" done } And if you don't want to do recursion you could either write the part of your script in find's exec. cmd='[ -w "$1" ] &amp;&amp; W="Write = yes" || W="Write = No" [ -x "$1" ] &amp;&amp; X="Execute = yes" || X="Execute = No" [ -r "$1" ] &amp;&amp; R="Read = yes" || R="Read = No" echo "$1 permissions" echo "$W" echo "$R" echo "$X" ' find "$dir" -exec bash -c "$cmd" -- {} \; And if you would rather export your function you could of course use find and parallel. perms() { [ -w "$file" ] &amp;&amp; W="Write = yes" || W="Write = No" [ -x "$file" ] &amp;&amp; X="Execute = yes" || X="Execute = No" [ -r "$file" ] &amp;&amp; R="Read = yes" || R="Read = No" echo "$file permissions" echo "$W" echo "$R" echo "$X" } export -f perms find "$dir" -print0 | parallel -0 -r -k -- perms
tar is a gnu core util and indepedant of bash
I had never thought of using ed to concatenate two files, this is brilliant. By the way, by default buysbox compiles with -Os (unless the distribution overrides it), and you can improve the benchmark further by compiling it with -O2. This can be set through `make menu config` in the shell build options.
No offence, but if the above examples are your idea of overly complex, you‚Äôre at a very shallow level in computing. Else, why not write your own, simplified tar ?
Thank you for a comprehensive explanation with examples!
How‚Äôre you planning to monitor which files are moved from 1 to 2? Remember, everything‚Äôs a file on *NIX machines, directory trees are just pointers to allow a more human-friendly relationship to the tree. You could change the `mv` command to be a function, in which it logs your above requirements, and then your required function could source said information. You‚Äôre opening up to some fairly complex process. Can you offer as to what you are wanting to achieve with this?
Oh that is interesting. I wonder what gentoo does by default and I will definitely look into it now. Still surprising that busybox beat GNU coreutils in this case even without optimizations for speed.
I fail to see how fallocate can be fast for anything different from a multiple of the block size. Are there any file systems implementing files as ropes?
v flag makes it easy to miss a warning message when there are lots of files. cf, tvf, xf.
Indeed, most of the bloat in GNU packages is feature-creepism, so one would assume it only acts as dead weight. Something else must be slowing things down, maybe some filters or extra safety checks.
`cat FILE | tr CHAR '\n' | wc -l` &amp;#x200B; Please replace CHAR with something like a comma, or a letter.
https://www.youtube.com/watch?v=TOu1T7fZGNg
Plist? Do you have a sample of the file?
I am getting number of items which is great but also says `tr: Illegal byte sequence`. Also when I put it into my actual script is says permission denied even if I sudo the script
Can you please share the code?
*tr -dc CHAR &lt; FILE | wc -c* would do the same, shoveling less bytes thru the pipe. Not that it matters here, but ...
&gt; based on a keyword at the end of the line? Maybe grep -o Keyword com.quarantine.plist | wc -l Keyword is case sensitive
You can just count how many keywords are there (and add 1 if it doesn't end with that keyword). $ grep -o keyword com.quarantine.plist | wc -l OR $ awk 'BEGIN{ RS = keyword } {print NR}' com.quarantine.plist
You don‚Äôt do multiple do‚Äôs. You separate the actions with semicolon like this: For i in host1 host2;do echo $i; ssh $i uptime; ssh $i df; done
Ah ok. So in my example how would you extract the first and 6th columns from each line of a df?
You probably want something closer to this: $ awk '/sda/ {print $1}' /proc/mounts | while read; do file ${REPLY} ; done /dev/sda5: block special (8/5) /dev/sda1: block special (8/1)
stat can print in whatever format you want. $ stat -c %a /tmp/foo 644 $ stat -c %A /tmp/foo -rw-r--r-- $ stat -c %a,%A /tmp/foo 644,-rw-r--r--
I assume with the formatting, you are only after responses from users of new Reddit
New reddit?
[how old Reddit sees it](https://imgur.com/3rfg0Jx)
Dang it. I'm in my phone. I tried to format it but it seems it doesn't play that well in my phone.
Try "Moving $# Items"
welp, It just so happens to have the perfect article for you :) ... [advanced argument handling in bash](https://dev.to/rpalo/advanced-argument-handling-in-bash-377b)
If you're familiar with any other scripting language, you can think of `do` and `done` as equivalent to curly braces around the loop's execution block. So you only need one set of them.
You might be wanting a while loop round your `case` running until you run out of arguments - e.g `[[ $# -gt 0 ]]`
for a TL;DR version I can mention your basic options that are three to be exact, a custom parameter parsing solution like the one you're experimenting with, getopt, and getopts that you can choose from depending on the blend of compatibility and usability you're aiming for.
Updated my post with some clarification now that im not on mobile.
&gt;function mvt() { for i in "$@"; do echo "Moving $# Items"; mv "$i" "$temp"; done ;} Is this supposed to bring it outside the loop? It didn't work.
You could do this: mvt() { i=1; for file in "$@"; do echo "Moving file $((i++)) of $#"; command mv -i -- "$file" "$temp"; done; }
&gt; Is this supposed to bring it outside the loop? It didn't work. If you keep it where it is, no it won't... ...but if you put it before the `for` and run mvt rod jane freddy it will print Moving 3 Items instead of Moving rod jane freddy Items Moving rod jane freddy Items Moving rod jane freddy Items but since you say &gt; and pymv clobbers the line above it so it disappears immediately and don't feel like fixing whatever is the reason *why* `pymv` erases the line above it, then you might want to either `echo` another line, or change the `echo` to something like printf "Moving $# Items.\n\n" obviously, that is based on `pymv` just clobbering the line above it... If it clears the screen, that is a different matter altogether...
This isn't the answer you're looking for, but the nested for loop looks like this: for host in google reddit; do for extension in de com es; do for prefix in www ftp; do echo $prefix.$host.$extension done done done I use something similar when trying to ssh to loads of hosts.
You dont want to do this with case, use getopts for multiple argument parsing.
Oh, now that explains a lot. I thought it's kiddies using tripple backquotes because of discord/slack or something. What a dumb move by Reddit. Not only is having design specific markdown elements dumb af, it also goes against why basic markdown is cool: It's perfectly readable uninterpreted. i.e. you can view a post in raw form and a code block still stands out due to its indentation.
 $ awk ‚Äò/host/ {print $6}‚Äô /proc/ mounts | while read ; do umount ${REPLY} ; metaclear ${REPLY} ; done The /host/ can use regex.
Apparently you can paste code in "new" mode and then change to "old" formatting before you post, reddit will automagically handle indenting, and when you post it will be in "proper" markdown visible to all... But I'm not about to post anything in `new` format lest I be added to the count of "active users that have posted in the new version" - besides, my phone can't even render it at a usable speed...
According to `strace`, on that gigabyte file, GNU sed seems to use someting like 500% more read syscalls compared to busybox. Btw. I read the other day that you use busybox ash fulltime. Bummer that it's vi-mode doesn't have f and t :'( I need those. How loksh does left-right scrolling on long commands is a big PITA compared to simply wrapping the line and it made me want to switch shell.
Even on desktop it used to feel notcieably slower. I don't care that much for the design, but the speed made me instantly say NOPE.
Thanks for the material, I was working on this when I saw the next comment after a refresh.
This is the code I basically use in my scripts to check for passed arguments. # CHECK FOR ARGUMENTS - START while [[ "$1" != "" ]]; do case $1 in -first_possible_argument|alternate_first_possible_argument) # Code for first possible argument ;; -second_possible_argument) # Code for second possible argument ;; -third_possible_argument) # Code for third possible argument ;; # Add as many arguments as needed. --help) echo "Include help message text here." ;; *) # Invalid argument echo -e "\e[91m\e[1mERROR!\e[0m Invalid argument was detected!" exit 1; ;; esac shift # the shift command is important here, as it moves to the next argument passed. done # CHECK FOR ARGUMENTS - END
Working beautifully thanks. `function mvt() { i=1; for file in "$@"; do echo -e "\tMoving File $((i++)) of $#\n"; mv "$file" "$temp"; done ;}` Moving File 1 of 3 \[1/1\] 100% - \[########################################################################################################################\] - Time : 00:00:00 100% file1.pdf \[###########
&gt; Tar is just so inobvious -***c***ompress(***z***e)?***v***'king***f***iles What could be simpler?
`echo "$x" | sed -E 's/[^0]//g' | tr -d '\n' | wc -m` With Bash, `sed -E 's/[^0]//g' &lt;&lt;&lt; $x | tr -d '\n' | wc -m`
Fantastic! Do you have any ideas how I could store it into a variable instead of printing it?
Don‚Äôt be lazy check out the GNU Bash manual.
I've been reading shell documentation all day... I can only figure out how to save an echo inside a file, but not on a variable.
Hint: use assignment and command substitution together
&gt;echo "$x" | sed -E 's/\[\^0\]//g' | tr -d '\\n' | wc -m As in: zero\_count=$(echo "$x" | sed -E 's/\[\^0\]//g' | tr -d '\\n' | wc -m ) right?
Perfect. &amp;#x200B; Also, I'm pretty sure there's an awk one-liner to do what you want. I just don't remember the special variable and the appropriate option to do that.
I'm really inexperience with Shell, just started using it today so I wouldn't know. So far I can only say that this would be so much easier if I could use Bash on this uni project...
I‚Äôm intrigued. What is this uni project about if you don‚Äôt mind me asking?
Calculating the final grade of students from a given input file along with their absent count (its in binary and I need to count zeros thus the question)
Choosing between generic Shell syntax and Bash, won't make a difference in terms of difficulty in your case.
Really? Thats a surprise, because I'm dealing with float values and I have to do calculations like 5 / 2 which I have yet to figure out and I thought it would be simpler in Bash.
How big is the biggest possible float value for your project? Even if you need arbitrary precision calculation, it only adds a tiny bit of difficulty, unless you need to write your own program to do arbitrary precision, which I believe you don‚Äôt.
Just two digits, I've been playing around with | bc and it seems to be doing the job. I think the hardest part of the project will be rounding up the final grade which I've only ever done in Python very easily. e.g. if the final grade is 4.89 it needs to round up to 5 etc
&gt; Is there any way I could echo the number of lines in the plist based on a keyword at the end of the line? Can you elaborate on "keyword at the end of the line"? XML is not line-based markup language so counting lines is not reliable ‚Äìas you can see- unless you format it first. You can use `xmllint` for this. I think it ships with OS X/macOS or will come with XCode. xmllint --format com.quarantine.plist | wc -l But if you're using xmllint, you may as well use [XPath](https://en.wikipedia.org/wiki/XPath) to count/extract what you need: ~/code/js/create-react-app-test &gt;xmllint --xpath 'count(//key)' ~/Library/LaunchAgents/homebrew.mxcl.postgresql.plist | xargs 7 Note that `xargs` was used just to add a newline to `7`.
Thanks for all your replies! This was super helpful. After everyones comments and especiall /u/ssshaw_ I decided to take another route. Overall I'm making my problem more difficult than it needs to be. My original idea was to populate an array in a bash script that would print out the values from a plist. I have found some other workarounds that will get me what I need. Thanks for the responses!
and people frown at me when I `while [ ! -z $1 ]`.
Simpler to use `tr` to remove all but zeros. `tr -cd 0`
Ah yup. That‚Äôs good.
Should be `while (( $# ))`
 while (( $# ))