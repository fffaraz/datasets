Of course, it's technically possible. But I doubt that a reddit clone will ever gain the momentum. (Otherwise, I would be all for it as I read the best articles on reddit when it was mainly crowded by lisp programmers) 
I have not seen the OSX version.. casual googling did not reveal any links. Can you help a brotha out? :)
Open Genera is commercial and not freeware. There is a Linux version of the emulator (without much of the rest floating around). That version is a cool hack, but buggy. You can't use it for anything half serious. There are newer versions and a Mac OS X version - but they are still not really usable. The DEC Alpha version is still a lot better (more stable, does not need to run as root, etc). If you want to try experimental versions, then you might need to contact Symbolics. I'm not sure what the policy is to give access to the experimental versions. Though I got my version via them. It's cool, but it is not really for the casual user.
Wouldn't the use of &amp;c. for etc. be a violation?
&gt; Open Genera is commercial and not freeware. I am aware of that ;) I was, and am, hunting around for an old (and fairly priced) 500au with DU for some time. Until then I have been running VLM on 64 bit Ubuntu in a VM. I am not a huge fan of Linux. I am, however, an old NeXT user going back to 1991; so an OS X VLM would be far more welcome. Mr. Schmidt seems to be "cool" with people torrenting OpenGenera, at least that's what his comments on The Pirate Bay would indicate. I think that he realizes that it would cost more to enforce IP than not and OG being "out there" might actually produce a few extra purchases here and there... There is no facility for discounted OG. Unlike most redditors, I am actually old enough to remember, and miss, Symbolics. ;) BTW, your reddit page is in my bookmarks, and has been for a while now.
Mr. Schmidt is not the owner of Symbolics. I would hope that there would be an improved version for Linux and OSX, but to accelerate that somebody would need to invest substantial time/effort/money... 
If I were better with programming and had more free time I would undoubtedly chip in. Right now my day job, which is really a day/night/middle of the night job, prevents me from doing anything other than work, sleep, and occasionally shoot.
I thought it might be useful to pull out logo related questions, projects, &amp;c &amp;c, rather than constantly pollute r/lisp with them. There might be *some* need to cross-post (i.e. Brian Harvey's paper that I posted a few days ago), but I'm curious about the projects &amp; work people are using the various (200+) dialects for, and thus, r/logounderground. As to the name, it's in reference to the [scheme underground](http://www.ai.mit.edu/projects/su/su.html)
Do you mean clozure or clojure (that java one)? The author appears to be using clojure judging from the awkward renaming of common macros. :)
Correct, Clojure. changed. Thanks!
Out of curiosity, how many people use SBCL vs other lisps?
I use SBCL.
I primarily use CCL but SBCL does a nice batteries-included type of thing.
Not sure how to reply. Is every SBCL redditor supposed to write a message saying "I do"? Or upvote your comment? A very non-scientific googling seems to indicate that [SBCL is the most popular implementation](http://www.lispforum.com/viewtopic.php?f=2&amp;t=140&amp;start=10) .
No thanks. TeX may have its disadvantages, TeX documents are readable. Look at a DefDoc document. If you want better scripting in TeX, try LuaTeX.
Document creation system where the main text content must be quoted? 
I use SBCL
Hm. SBCL+=0.0.02 ... not that interesting. The more interesting part: They got to version 1.0.37 for Windows...
Agreed. But it could be useful for creating content programmatically (dynamic websites, etc.).
Hm. Ever heard of cl-typesetting?
1.0.39 is for Windows as well.
This is an obnoxious nit on my part, but LISP is not an acronym, it's just Lisp nowadays. I'd love to know the answer to this question as much as you. I would imagine a fair amount of it isn't really reading quality. I'd probably dive in anywhere and just see. Probably stuff that isn't bindings to C would be better.
Definitely [Rucksack](http://common-lisp.net/project/rucksack/). The [presentation](http://weitz.de/eclm2006/rucksack-eclm2006.txt) is just an awesome read in every way.
Also interesting: I overheard on #lisp there's more work being done on threads support for windows, but the page about it is in russian. (I don't have a link to it.)
Any Edi Weitz code is good to read: [http://www.weitz.de/](http://www.weitz.de/). For example, take a look at [cl-ppcre](http://www.weitz.de/cl-ppcre/) which is a good piece of software.
Edi Weitz is a Lisp Machine.
SBCL here. Mostly because its open-source and fast (I do a lot of GA/GP stuff).
I would read the code snippets of ANSI Common Lisp and On Lisp by Paul Graham. Assuming you have read at least the first book (which I find one of the best language "references" together with K&amp;R The C Programming Language)
Be warned that PG's style is somewhat personal. [Here](http://www.cs.northwestern.edu/academics/courses/325/readings/graham/graham-notes.html) is a commentary of his published code.
Indeed. Thanks for the pointer... In fact I was unconsciously aware of these... I prefer cond, although I've read mostly only Graham's code (when I was learning, later just my code, mostly), but have also a distaste for loop (I don't find it lispy enough, I think I read some other "lisp tutorial" where the author also dislikes loop). The recursion vs iteration part... well, I'm a mathematician, when programming to solve something I decide which way to use depending a) the problem: if it is eminently recursive, I write it recursively b) the problem space: if I need a lot of memory just by being stubborn on it and do it recursively, rewrite But in fact, the only two programs I have done and are somewhat interesting are a raytracer (based on Graham's, recursive and under a major rewrite... since two years ago :/) and a generator of Lavaurs chords (a kind of topological identification of the circle related to the Mandelbrot set... if you look for Lavaurs chords in google chances are you end up in my mathematical homepage :)
The thing about recursion is that the Common Lisp specification makes no promises about tail call elimination.
Cool. What's GA/GP?
If I had only one I would use this: [Lisp in Lisp](http://lib.store.yahoo.net/lib/paulgraham/onlisp.lisp) EDIT: And I almost forgot [Lisp In Small Pieces](http://www.amazon.com/Lisp-Small-Pieces-Christian-Queinnec/dp/0521545668).
&gt; but [I] have also a distaste for loop (I don't find it lispy enough...) This is a pretty common Lisp user complaint (and it's why we have libraries like [iterate](http://www.cliki.net/iterate) but it seems to me that if what one loves about Lisp is macros, `loop` is a pretty good example of what's possible and what syntax can be created or eliminated. It also tends to generate pretty tight code.
Yes, I usually use loop as an example of what macros can do. But when I need to do some kind of iteration *à la* C's for, I use do, or dotimes (depending on what I am working on). Didn't know about 'iterate', seems nice!
It's kind of fun to spell a programming language acronym in all caps just to see the protests that XYZ programming language is no longer an acronym. Of course not - in the course of history, obviously the cap letters have all eroded down to lower case. FORTRAN is now Fortran. COBOL is now Cobol. PERL is now Perl. BASIC is now Basic or VB. And LISP is now Lisp. Each programming language's name will eventually erode to punctuation and they will all eventually be called . And there can be only one!
Obnoxious nit: Perl was never "PERL." Qv http://groups.google.com/group/comp.sources.unix/browse_thread/thread/363c7a6fa4e2668b/bb3ee125385ae25f
&gt; BASIC is now Basic or VB. Eventually that will be just Vb. :)
Genetic Algorithms and Genetic Programming. CL is very good to prototype and test ideas and get a feeling of what you should explore next. Unfortunately my colleagues don't like Lisp and in some projects I am "forced" to use their stuff (mostly C or Java). But my own work is always in CL :-)
Peter Norvig's [PAIP](http://norvig.com/paip.html) (Paradigms of Artificial Intelligence Programming: Case Studies in Common Lisp) is worth reading for this reason alone. Don't let the AI aspect scare you.
Nice citation. Time for the obnoxious and equally useless counter: Sure, now you're going to tell me it's not 'TMTOWTDI' and that it's actually 'tmtowtdi'.
* [alexandria](http://http://common-lisp.net/project/alexandria/) - great utils library * [drakma](http://www.weitz.de/drakma/) - webstuff * [cl-json](http://common-lisp.net/project/cl-json/) - good for talking down to javascript. I've found it easier to write my javascript in javascript instead of parenscript, and then use ajaxy crap to get data from lisp. * [spatial-trees](http://www.cliki.net/spatial-trees) - useful for hobby games where spaceships need to know what's near enough to shoot * [lispbuilder-sdl](http://code.google.com/p/lispbuilder/wiki/LispbuilderSDL) - fun with graphics * [clsql](http://clsql.b9.com/) - talking to databases * [tal](http://trac.common-lisp.net/ucw/wiki/IntroHtmlTemplating) - html templating 
Maybe you're right about erosion. APL has dwindled to merely 'J'. Or maybe it's more some sort of tectonic process, as previously unavailable lowercase letters appear. 'Subduction' of FORTRAN to Fortran. 
Definitely PAIP. Some of the solutions are mind-blowing in their simplicity. I haven't programmed in Lisp in over a year, but I still leaf through the book at least once a week
where to find Genera source? only some document in web....
The source comes with the Genera distribution, so you (should! should! should!) either purchase it with the VLM or find a copy on TPB.
&gt; A lot of Edi's common lisp code is substandard, very inefficient and quite hacky in nature, sometimes even /horrible/ (e.g. hunchentoot...) Is Hunchentoot 1.0 still horrible? "Hunchentoot 1.0.0, released in February 2009, is again a major rewrite... A significant part of the 1.0.0 redesign was done by Hans Hübner." ([source](http://www.weitz.de/hunchentoot/#history))
I dont know about quantum computing. But unrelatedly: What sort of Window Management are they using in their screenshot? It looks minimalistic and nice.
btw, John Koza's examples of GP are written in Lisp. And then there is Ken Anderson's work that shows how that same code can be rewritten to become really fast.
Most of us can probably work with cl-opengl by looking at how the C code works, but still a very good idea for assuring people GL works in CL, or people who start programming in CL.(And thus have use for CL tutorial in GL) And it can just saves a little time figuring out how to translate to cl-opengl.
Looks like [System 7](http://en.wikipedia.org/wiki/System_7)
check this for general guide lines www.cs.umd.edu/~nau/cmsc421/norvig-lisp-style.pdf also keep in mind that Paul Graham, tend to lean towards scheme style and way of thinking
Hi, I addressed some of that in the post: compiler errors do not get notes if you compile on a per-expression basis (though you probably don't need them as much then), but also, if you moved stuff around in your source file, the lisp system will NOT find the right location (with slime-edit-definition etc) unless you compile the whole file. At least not in Clojure/SLIME. Plus, when you're writing servers, errors may get logged to a file instead of popping up in the debugger, and then it's pretty handy to have a file name and line number associated with the stack trace. :) Cheers, Joost. 
Thanks for pointing me to this excellent review!
There was talk of someone doing a lisp-based framework for OpenGL on /r/gamedev. Maybe you could x-post there?
We are in a process of phasing out sbcl and replacing it with clojure. Most of the code is already migrated. Only a few services remain (couple of days of work.) But it is not urgent, so i do it when i have free time. 
Ha. This comes at the best time. SDL is too slow and I am currently at trying to use opengl with my project, and searching for some sort of tut.
Just out of curiosity, what are your reasons for moving to Clojure? I ask because I'm currently working on some stuff with Common Lisp, and I've been trying to decide if I should bother with Clojure or not. (:
Libraries, documentation, support. Clojure gets all of it for free, because it rides on JVM. Specifically in our case we needed pdf library, jcifs (connecting to windows shares directly without mapping), emailing (cl email library is buggy) 
David Schmidt is the contact. The current owner(s) did not sell the domain - that was before the remaining assets were sold. Brad Parker wrote both the Linux and the Mac OS X version of the VLM. Open Genera 'is not' out there. All there is is a pirated copy of the DEC Alpha distribution version and some emulator variants. These are not that bad, but Brad would need to invest quite a bit more time plus the Open Genera Lisp world would need to be improved. For example in the snap4 version some arithmetic is broken and GC plus I/O often leads to crashes. Brad has fixed the complex arithmetic, but the error on the Genera side with GC has not been fixed yet. Currently OG is a complex piece and nobody seems to have the time AND money to make a better VLM. Brad's work is really cool and he knows what to do to improve it. But he also has got a job, which keeps him busy with other things. I fear currently the best thing one can do is express interest in buying a version of OG via David Schmidt. 
I know but having an SBCL on Windows would be a good thing as well.
I know Koza's code and a long time ago I remember seeing Ken Anderson's page with the slides and his improved code. I'm glad you remember me about that particular work. I am coding now a library/framework for GA/GP and some of the lessons there can be useful. 
You mean SDL-drawing? That is software based,(except maybe in some cases with blitting) so it is fair that it is slower. The rest is pretty good though, it gives a good handle on things. I have been thinking of trying to improve on the macro lispbuilder-sdl::with-events, though. But i am not sure how to do that well enough to submit to that project..
You rang?
Here's some fun stuff: Old Explorer LISP code. ftp://ftp.cs.cmu.edu/user/ai/lang/lisp/code/impdep/explorer/0.html Don't expect a lot of this to run - though it might make a fun project to patch it for a modern machine.
What kind of problems do you solve?
Web site, internal processing, pdf creation/manipulation/encryption, OCR, xrays, emaling, business rules, order processing, accounting. All inhouse needs. 
That's why I primarily use ECL, it is truly cross platform.
slime + paredit is the way to go imho
It took me a long time to try paredit. I'm glad I did, and sorry I waited. I can make much more complex edits with much more confidence with paredit than without.
Swap Caps Lock to Ctrl.
Why not start with Emacs right now? The learning curve isn't that steep, it's just very long.
I find the default key sequences of SLIME also a bit long.
[Lisp [in a ] Box](http://www.gigamonkeys.com/lispbox/)
Can't get the damned thing to work or the source version compiled...(on debian) For some reason it expects a ~/csound directory, and it has some .lua script i don't know how to run to generate a makefile.(apparently) Yay, dependencies to figure out the dependencies.. I prefer something on CL anyway.. Everything i find has one or more of of horrible gui and language around it, unclear website, or dead links.. I'd have sworn i saw something on a personal website i wanted to try.. [Maybe this](http://old.nklein.com/products/rmusic/), but i remember it being lisp and being on the newer website.. I guess i could use something scheme..
Lispbox is badly outdated nowadays. It's good to take a first look at common lisp, but for real work it's too old. Some time ago Peter Seibel asked if anyone wanted to take care of the problem, I don't know how it ended but...
I found that since the windows key is usually unused, one can map the most common slime commands to it (wk+something).
I would map evaluation/compilation to the enter key, abort and break to some keys, etc. etc. Reusing the windows key on MS Windows to get rid of one layer of SLIME prefix keys would be useful too.
Paredit might be awkward at first, but soon it's blissful.
I use Emacs + SLIME. I've tried LispWorks personal edition and I really didn't like it. Also tried Corman and Allegro. I don't know any other setup that would be as featureful and well supported by the community as Emacs+SLIME. You could try Eclipse+Cusp if you really want something that looks like Eclipse/NetBeans; or you could also try Vim with some of the plugins that are being developed for it... But I can't see any of those being better than Emacs/SLIME in the long run -- and if I were you I'd start with what would work better in the long run.
&gt; [suggestion that OP use a Lisp IDE. suggestion was downvoted mercilessly for insolence.] How dare you proffer an alternate opinion! Everyone knows that No True Lisper uses anything but Emacs, ever.
This has been posted before, but it's been updated since. I bet you'd get more people checking it out if you had mentioned that it has been updated.
You just made me try it out and I can see the "bliss" over the patch of awkwardness (but that's hugging cheatsheets for you). Hot damn.
Slow day in Lisp world, eh...
I don't know why people are downvoting you, but thank you for your advice. Even though it doesn't apply to me (I already use emacs for all my text editing, and wanted to know how to set it up so that I can also do CL effectively), I'm sure people who don't know or want to know emacs will appreciate knowing that there are other options.
There's nothing ever imminent to look forward to, to be honest, because of the wonderful "we've got the tools, do it live" thingy. Unless Symbolics rolls out the VLM wagon out once more, of course. HINT HINT
I really like this survey but I wish it was in version control... or had a changelog
&gt; "... Racket, Scheme, etc." Interesting.
My only complaint is referring to non-free licenses as "commercial", which incorrectly implies the free licenses have commercial restrictions. 
I doubt it; they even sold the domain. I understand that the company is in a bad position, but selling that domain kind of pushed it from the "not very healthy" to "dead" category for me. 
&gt; [...], ECMAScript, [...] Also interesting.
I thought this was silly when I first heard about it, but really PLT Scheme is like its own language. I think it's deserving of its own name. I just hope they go with "Racket" instead of "PLT Racket". 
We don't use the phrase "PLT Racket" anywhere.
It looked like that's what it was almost called. The original domain was [plt-racket.org](http://plt-racket.org/) (which now redirects), and that's what people were calling it when word got out, * [Goodbye PLT Scheme, hello **PLT Racket**](http://www.reddit.com/r/programming/comments/biowt/) * [PLT Scheme being renamed to **PLT Racket**](http://news.ycombinator.com/item?id=1221374) Glad to see it didn't stick, though! Edit: looks like [this one](http://planet.plt-scheme.org/package-source/dvanhorn/backgammon.plt/1/2/planet-docs/backgammon/index.html) slipped by too.
I would understand 'commercial' to mean that you have to buy them.
Planet packages are user contributed, so their naming choices aren't dictated from on high. 
I like that Scheme isn't mentioned anywhere on the page. Being associated with the myriad other incompatible schemes is a ball &amp; chain. A single canonical Racket implementation with batteries included? It's going to be an interesting next five years.
I just looked at his website, actually, it sorta confirms it. &gt; People interested in sponsoring the development should contact 'Symbolics' (link below). (http://lispm.dyndns.org/news?ID=NEWS-2010-01-30-1). Does it deserve another thread?
I wonder what you would get for sponsorship; how much would it cost to open source it? That would certainly be interesting, much like how MIT open sourced MULTICS. &gt; Does it deserve another thread? I wonder if we can get David Schmidt to do an AMA wrt Symbolics. 
How is this change going to be implemented in Linux repositories? Will those of us with the current PLT/DrScheme from our distro's repo get that updated to Racket automatically, or will we need to keep an eye out for a new package and install it separately?
Yeah I'm using 64bit Arch and the closest prebuilt binaries are Fedora7 - the gui drracket uses libjpeg.so.62 instead of 7 or 71. Currently trying to compile and install the unix source tarball to see if that helps.
Sounds like it's going to be a new package then, and the current plt-scheme package will just become deprecated, unmaintained, and fade away. Samth, can you confirm or deny?
If you start DrRacket and go to help-&gt;helpdesk, it shows R6RS right up there. So far only s/PLTScheme/Racket/g
That alone has value.
Swap [ with ( and ] with ), it's easyer to code lisp that way.
We don't have anything to do with the packaging by linux distributions, so you'd have to ask them. But all packaging systems contain a way for a package with one name to replace a package with a different name, so it shouldn't be too hard.
It's not even close to CL, but the source code to the Clojure language and the contrib libraries is pretty great.
I wonder if you could point out one of the mind-blowing ones? The source code is available and listed (with links) at the above site, in the source code section: http://norvig.com/paip/README.html
I didn't have a chance to try it out, but looking at the examples it seems quite pleasant to work with. Supports .ui files loading, and the "syntax/api" looks quite nice. Seems like **the** Lisp GUI framework to me, at least if one is using ECL. I wonder if it can be ported to other Lisp implementations.
As one of the developers who works at [Streamtech](http://www.streamtech.nl) (the company behind BittAds) and worked on it, I'm happy to answer any (technical or other) questions people might have about it. It is indeed written in Common Lisp (running on SBCL) and that includes both the web-based administration interface and all the real-time planning, selection, serving &amp; view/click tracking of ads.
http://www.unlambda.com/lisp/mit.page
Also, its first chapter or two are a very good introduction to Common Lisp, especially if you already know a little bit about other Lisps such as Scheme. I actually only got about a quarter of the way through the book before losing interest. The fact that it occasionally talked way over my head didn't help.
So he evaluates Lisp code?
Ah, ok, thanks. Hopefully they just replace the old PLT-Scheme, but will keep an eye out either way.
Any idea of video lectures available for courses conducted using this book. Also will help if the lectures are available for free
I'd imagine he does, yes.
I just emailed David Schmidt wrt doing an AMA for the Lisp-related subreddits.
I resisted loop for a long time and used ITERATE instead. But IIRC iterate didn't play as nice with the debugger (it was hard to tell exactly where errors happened from the debugger). Although that probably varies by CL implementation. Eventually I just started using LOOP; although not as nice as ITERATE it is just too handy to ignore.
That's kind of how I feel about it. It feels a little disingenuous (to me) to write code that uses iterate instead when loop would work. But extending loop sucks.
Hey, I just found [an old presentation I made about Loop](http://www.hpc.unm.edu/~download/abqlispscheme/archives/2007-11-18-Daniel.Lyons-Introduction_to_LOOP/11-18-2007-Daniel.Lyons-Introduction_to_LOOP.pdf) if you can stand PDF.
What does AMA mean?
"Ask Me Anything", or AMAA for "Ask Me Almost Anything". I'm interested in giving Symbolics a platform to speak to people who are interested; Questions could be upvoted/downvoted &amp; then submitted to whomever Symbolics chooses to field them. It's worth a shot, anyway.
You might want to talk to Russell Noftsker, the former CEO of Symbolics. He should be involved currently, too. After the last owner, Andrew Toppings, died a few years ago a buyer was looked for. But nobody bought the remainings of Symbolics, because the caretaker wanted some substantial amount of money. After some time the caretaker sold the domain to make some money and eventually also sold the remaining of Symbolics. Currently the owners are not that active, AFAIK - but at least the stuff is not lost.
Here are a few good authors, reading their software is very educational - a) Edi Weitz - http://weitz.de/. Writes very clean and well documented code. b) Paul Graham - The On Lisp book examples, http://arclanguage.org/install (for the source code of news.ycombinator ) c) The Code in - "The Little Schemer" - the best introduction to the lisp way of thinking.
Would you happen to know if there are any plans to Open Source at least part of the software? They seem to be making some money off of the remains of Symbolics, since, even after selling that iconic domain name, they still have a site offering contacts.
Try the [General Problem Solver](http://norvig.com/paip/gps.lisp). I liked it because it takes a potentially grandiose problem and solves it with a simple data representation and a simple algorithm. Find a copy of the book! The source loses a lot without Norvig's meta-discussion, plus the source is meaningless without the problem's description [Here's a Google Book version](http://books.google.com/books?id=QzGuHnDhvZIC&amp;lpg=PP1&amp;dq=paradigms%20of%20artificial%20intelligence%20programming&amp;pg=PA109#v=onepage&amp;q&amp;f=false), but it looks like it has a lot of missing pages
AFAIK there are no plans to open source any part of the software. I don't know if 'they' make some money - David Schmidt was making some money with maintenance and selling some OG licenses. It is great that he helped some people to keep their stuff running and that he refurbished some old machines and sold them to people. A good MacIvory is still worth around 3000 dollars. David sells bundles with Macs and MacIvory cards that come preconfigured (with a lot of software installed). That is extremely helpful. He also sells some other machines.
Kind of a sad state for such a company. I'm glad though that someone is still supporting Symbolics' "stuff", even if in a limited role. I saw that the Berlin Lisp group was offering that "if you have a 64 bit laptop you can play with OG" (paraphrase) on planet lisp. It seems like, even if there is no "open source", that there's not much worry about it floating around either.
It is as useful as a pirated copy of MS Word 3.0 is.
HEEEEY, now wait a minute; What am I supposed to do on my old DOS box? It's not like M$ is selling it anymore! :D
Hell, that sounds awesome.
Let's see if he responds though :D
In the case of Debian-based distributions, just like how much of the software is installed, the main `plt-scheme` package is just a virtual one that has the real packages as dependencies. So when they update for Racket they'll create a `racket` package and change the `plt-scheme` package to be a transitional virtual package that depends on it. This is the same process that packages normally go through for major version upgrades. For example, `emacs` is a virtual package that used to depend on the real `emacs22`. When they added Emacs 23 with an `emacs23` package, all they did was change the dependency to `emacs23` and anyone who had installed `emacs` transparently went along for the ride. 
I prefer ITERATE to LOOP for roughly the reasons listed by the author, but why on Earth would you convert 600 LOOPs that presumably work fine as it is?
I might note that the following: (loop for x = 0 then (1+ x)) Is better written as: (loop for x upfrom 0) Which is nearly identical to: (iter (for x upfrom 0))
Persi is an unusual guy. He occasionally likes to experiment with a new library or idea via large-scale refactoring. He's got a variety of tools (lots of custom emacs magic, etc) that allow him to do that quickly and easily. The 600+ loops were part of a 30,000 line lisp codebase powering a startup which will hopefully go public "Real Soon Now". I learned a lot from an internship with him this Spring.
Ah, of course, totally forgot about that. Relatively new Linux user though. Thanks!
There's also [Series](http://www.cs.cmu.edu/Groups/AI/html/cltl/clm/node347.html#SECTION003400000000000000000) ([implementation](http://series.sourceforge.net/)) if LOOP and ITERATE don't do it for you.
I'm fond of series but there aren't as many examples of how to use it.
Thoughts: * upfrom exists in LOOP, as bazfoo points out. * `(collect b into ones)` is not very Lispy. `(collect b ones)` or `(collect b :into ones)` is better. * On second glance, a lot of these clauses aren't very Lispy, and basically look like LOOP clauses wrapped in a list. For example, `(for x in y)` might be expressed more structurally as `(for x (in y))`, where `FOR` introduces a variable binding, and `IN` designates the sequence of values from a list. All in all, interesting.
This looks fantastic. It's basically a generic iteration protocol with sequences (in the abstract sense, not the Lisp sense) wrapped in convenient objects. A lot more elegant than LOOP and what I've seen of ITERATE.
The real TI Explorer Lisp Machine sources: http://www.unlambda.com/lispm/explorer-source/explorer-lispm-sources/ Lots of interesting stuff there - for example a X11 server written in Lisp.
The problem I was raising was that the iter form was shown as an improvement to an overly complicated loop form. It was an apples and oranges comparison.
&gt; He's got a variety of tools (lots of custom emacs magic, etc) that allow him to do that quickly and easily. I started to collect a few of mine in [Redshank](http://www.foldr.org/~michaelw/emacs/redshank/) (back when I still had time to program… :-/). I'd be interested to see what he's got. Care to relay this message? 
Btw, it's a shame that the [Common Lisp Cookbook](http://cl-cookbook.sourceforge.net/) is catatonic.
Hi, what kind of CLOS-features does BittAds use? Multimethods? MOP? thanks!
That's funny (author here), because it has been you to inspire the project. After seeing your nice ECL embedded examples, I started playing around a little... (OK, I already had some Qt and ECL experience). (...a few months later...) Voila!
Yeah. I have been trying to put together a polished source of CL examples in the [external libraries section of the CL wikibook](http://en.wikibooks.org/wiki/Common_Lisp/External_libraries). Of course this is aimed at external libraries with little to no preference to pure Lisp solutions and I feel PLEAC and CL Cookbook kind of do. It's not exactly catatonic as I twitch at it every once in a while, but I really have only put effort into the LTK section. Haven't found much time lately and will probably have less in the future, maybe others can help?
I didn't even know that the CL wikibook existed. I've just submitted it to lispit. 
I see that. The whole book needs a revamp. I didn't start it, I just hijacked a section or two.
I used to do this before i did paredit. Now, paredit takes care of so much that I don't miss doing this particular swap anymore.
I'll pass it along to him. :)
We use quite some CLOS features in the administration interface, including a light sprinkling of the MOP by having a meta-class for all classes that model pages/resources which enables us to do automatic URL &lt;-&gt; CLOS object conversion and dispatching of requests to functions. In other words, an incoming HTTP request is dispatched to a generic function on a newly instantiated CLOS object whose class and slot-values are determined from the incoming URL: (defclass ad-status-page (authenticated-resource db-connected-resource) ((title :initform "Ad status overview") (ad-id :type integer :initarg :ad-id)) (:path ("ad" id-id "status")) ; this defines the path 'pattern' to match for these pages (:metaclass resource-class)) (url-to (make-instance 'ad-status-page :id 123)) ;; =&gt; "/ad/123/status" (defmethod resource-get ((page ad-status-page)) (with-slots (title ad-id) page (&lt;:h2 (&lt;:ah title)) (&lt;:p "Imagine the status of ad with id " (&lt;:ah ad-id) " here."))) ;; this will call RESOURCE-GET on an instance of AD-STATUS-PAGE with ID bound to integer 123 (dispatch-request :GET "/ad/123/status") Now, because we define all kinds of :around and :before methods on those RESOURCE-* functions that specialize on classes such as AUTHENTICATED-RESOURCE and DB-CONNECTED-RESOURCE, we can offer reusable authentication and authorisation or DB connection setup and tear-down to other pages simply by letting them inherit from these classes. We can also organise HTML output and make sure pages and menus are consistent (e.g. there's something like a BASIC-HTML-RESOURCE superclass that defined an :around RESOURCE-GET method that sets the content-type header of the response to "text/html", sets up the HTML generation library and outputs generic HTML such as a doctype and the outer &lt;html&gt;&lt;head&gt;..&lt;/head&gt;&lt;body&gt; tags before invoking CALL-NEXT-METHOD that will render the actual body and finishing up afterwards). On a higher level, we can also model the actual structure of the administration interface, having more abstract classes that indicate that a page belongs to a certain sub-section and letting other code elsewhere deal with this by adding a sub-menu on certain pages or requiring specific permissions to access them. In other words, we (ab?)use the MOP to give ourselves a way to define a model of pages/resources and their behaviour allowing us to build an application-specific web-framework using just 'plain' CLOS features and using very little of that 'magic' that web-frameworks typically reek of.
Hi, thanks for the insight! Does streamtech use hunchentoot or something custom? 
Link doesn't work? Too bad..
[Cache](http://webcache.googleusercontent.com/search?q=cache:Pgs2vnnEVFkJ:lambda.bugyo.tk/cdr/mwl/+%E3%83%9E%E3%83%B3%E3%82%AC%E3%81%A7%E5%88%86%E3%81%8B%E3%82%8BLisp&amp;cd=1&amp;hl=en&amp;ct=clnk). As a Lisp-curious, Japanese-speaking manga fan this sounds very interesting
We're primarily using Hunchentoot, yes (in the case of BittAds, multiple hunchentoots on multiple machines running behind a single Apache load-balancer).
Are they any good?
They work. As for why I am getting downvoted for offering them I don't know. I don't want to do the maintenance, deal with sourceforge or gethub, etc. I'm using the PangoCairo parts in a 3D application to build a REPL. Although I'm curious who would downvote free code? I think someone doesn't like me, it's the third item today. The others were help requests. 
May as well post them somewhere and make a cliki page; even if they are not particularly useful in their present form someone might have a use for them eventually.
The headline reads like a passive-aggressive insult.
It does? How exactly is it insulting?
It helps if you read it out loud in a really whiny voice, followed by a deep sigh.
Anything will sound like an insult if you do that. So?
I didn't mean to sound, well, mean. I've had bad luck getting even basic internet assistance with Pango. And to be fair, I do have a high-pitched whiny voice.
great! can't await that appears in the stable branch!
I wrote image\_science for ruby which is a small wrapper around FreeImage. It focuses on thumbnails and memory efficiency. At the time it was going up against ImageMagick + RMagick which was notorious for using up tons of memory and being a severe PITA to get installed and working. image\_science got a fair number of users just for being clean and easy. I'd recommend releasing your software and seeing where it goes from there.
 (say "Anything will sound like an insult if you do that. So?" :intonation 'whiny) (sigh)
Maybe it's because your link just goes to pango.org?
I haven't voted on your post but I found it a bit of a strange question, because you just cannot know whether anyone else will use them. The only way to find out is to release them. A question: why would you not release them?
I thought people might not know Pango.
Because I'm working on another project and I don't want to put effort into another library no one will use. 
I found several bugs in my pango bindings last night. I'm going to add a few convenience functions and release them.
I've decided to release them, after I've used them for a little while. I need to add some convenience functions and make it into an ASDF library. Look for it in a few weeks. (I work and am making a game so please be patient, especially since no-one seemed to need it immediately.)
This is great! I use sbcl at work to work around the other tools I'm supposed to use. Is there any word on creating executables that are not as big as sbcl itself?
&gt; I've decided to release them Hey, thank you! :-) 
Change for the sake of change? No thanks.
If you could run this in Symbian (ARM), it would be big news. Has it been done?
ISA matters to implementors. With enough skull sweat by implementors, they don't matter to end-users. The primary bad effect of cheap-but-ugly ISAs is that they require large-scale development efforts to succeed economically - they are a barrier to entry, in that the big guys can afford the engineering time to make their stuff go twice as fast as the simple, obvious implementation.
rme had more to the quip at ILC: "PowerPC is like a king sized bed, x86-64 is like a double bed, and x86 is like a bunk on a submarine."
got it... I couldn't see a clear reason why it should not be a Lisp-1?
Who's the guy? Somebody one should know?
Definitely. [Richard P. Gabriel](http://en.wikipedia.org/wiki/Richard_P._Gabriel): &gt; Richard P. Gabriel (born 1949) is a noted expert on the Lisp programming language (and especially Common Lisp) in computing. He is primarily known for his 1990 essay “Lisp: Good News, Bad News, How to Win Big”, which popularized the phrase Worse is Better, and his set of Lisp benchmarks (the "Gabriel Benchmarks"), published in 1985 as Performance and evaluation of Lisp systems, which became the standard way of benchmarking Lisp implementations. &gt; Gabriel was at various times the President and Chairman of Lucid Inc. The product the company shipped was an integrated Lisp IDE for Sun Microsystems’ RISC hardware architecture. This sidestepped the principal failure of Lisp machines by, in essence, rewriting the Lisp machine IDE for use on a more cost-effective and less moribund architecture. During this time period, Gabriel married his second wife, and had a daughter; the two divorced in 1993.
Ah, it's him. Didn't recognize the name instantly. Thanks.
That's not really accurate. Lucid was famous for their Common Lisp compiler which was targetted at (mostly) Unix workstations - not just SUNs. The roots of that Lisp system were in a cancelled project at Symbolics for a portable Common Lisp. The Lucid Common Lisp compiler had two modes. In one mode it would do a quick and dirty compilation, usable for incremental development on the Unix workstations of the 80s. In a second mode it would do extensive and more time consuming compilation with the goal of producing fast code for delivery. A lot of commercial Lisp applications used Lucid CL because of its production delivery capabilities. Lucid sold the Common Lisp directly to end customers, but also to workstation vendors (IBM, Apollo, SUN, ...), which then sold Lucid CL under their name. One example was SPE (Symbolic Programming Environment) from SUN, which was based on Lucid CL. The IDE was AFAIK not developed by Lucid, but by SUN. Lucid CL did not itself provide a Lisp Machine like IDE (which would be graphical, extensive and all written in Lisp). Eventually, when Lucid was sinking, Lucid CL was sold to Harlequin (which was also sinking later). Lucid CL was then available as Liquid Common Lisp from Harlequin/LispWorks. As a last act, Liquid CL got the IDE from LispWorks. Richard P. Gabriel wrote a bit about his experience as a Lisp vendor in his book Patterns of Software (amongst other topics) The AI Lab and a local software company here in Hamburg developed a route finding application for the local public transport (which is quite extensive). That application was initially deployed using Lucid Common Lisp in some local train stations (using a very large touch screen) and the call center for getting route information via telephone. A later version then has been rewritten in Java.
(Well, if someone would sponsor it, I would do it *instantly*, with support and everything...) If you look at the (compressed) size of EQL in Windows (note: now with EQL as shared library), it's really impressive (at least to me) how small it is. The overhead of both ECL and EQL is quite small compared to the Qt libraries themselves.
Are you guys still not making use of epoll? You can mod hunchentoots task manager to handle this if you update to the latest version. Should at least make it so that you can handle more requests. Also I noticed the yaclml syntax, does the site still make use of UCW or are you just making use of the yaclml library? One last question, have you guys looked at Closer &amp; Filtered Functions by Pascal Costanza? Would be cool to see some of these libraries being used in a higher level web layer. 
Concerning 5 &gt; By convention, the names of predicates usually end in the letter p (which stands for "predicate"). Common Lisp uses a uniform convention in hyphenating names of predicates. If the name of the predicate is formed by adding a p to an existing name, such as the name of a data type, a hyphen is placed before the final p if and only if there is a hyphen in the existing name. For example, number begets numberp but standard-char begets standard-char-p. On the other hand, if the name of a predicate is formed by adding a prefixing qualifier to the front of an existing predicate name, the two names are joined with a hyphen and the presence or absence of a hyphen before the final p is not changed. For example, the predicate string-lessp has no hyphen before the p because it is the string version of lessp (a MacLisp function that has been renamed &lt; in Common Lisp). The name string-less-p would incorrectly imply that it is a predicate that tests for a kind of object called a string-less, and the name stringlessp would connote a predicate that tests whether something has no strings (is "stringless")! http://www.cliki.net/Naming%20conventions
1. http://www.lemonodor.com/archives/000100.html 2. http://common-lisp.net/project/alexandria/ 3. No idea. 4. No idea. 5. See hu5tirwfh3frw 6. [comp.lang.lisp FAQ](http://jcsu.jesus.cam.ac.uk/~csr21/lispfaq.html#AEN313) 7. No idea. 8. No idea. 9. Probably because it's deeper than #'eq but not as deep as #'equal? :) 10. Probably because `(loop)` can handle hash tables and vectors. I think you might want to investigate Clojure. It's less low-level than CL.
3. Because a vector can have a fill pointer without being extensible. 4. Lists aren't extensible. 5. Multi-word predicates end in -p, single word predicates in p. NULL and ATOM have special dispensation for historical reasons. 7. Because vectors are arrays, so you make them with make-array. If this bothers you, just define make-vector. 8. No. 9. Because EQL is nearly as efficient as EQ but does the Right Thing for numbers. 10. Because CL sucks. But if this bothers you these are trivial to define yourself. 
Your numbering is wrong.
There is now: (defun copy-array (array) (let ((new (make-array (array-dimensions array) :displaced-to array))) (adjust-array new (array-dimensions array) :displaced-to nil))) Same for every "Why there is no freaking'" question. 
While Common Lisp indeed lacks some of the aforementioned features, you would spend less time adding them than wondering why they are absent. You need to accept that Common Lisp will not change because of your dissatisfaction.
&gt; Why is there a dolist but no doseq or dohashtable? What would you propose as an implementation? Most times that you iterate over an array you care what the current index is. Not to mention that an array might possible have multiple dimensions. As for a hash table, we have the same issue of how to implement the interface. maphash is a much better way of managing iteration over hashtable entries.
When I write in Lisp, it changes to my satisfaction.
That's what I was trying to say, and meaning Common Lisp as a standard.
The only issue I have with hash tables is that for sort you do: (sort data #'test) and with hashes you do (make-hash-table :test 'equal) ; or one of like 5 others. I would like to make it a function. EDIT: I would also like sort to have a default.
I'm not fully understanding what you say. But one can do (make-hash-table :test #'equal) .
I think Markdown decides that anything that looks like it might possibly be a numbered list should be "corrected" to a 1..n labeling. 1. I numbered this line "1." 4. And this one was "4." 6. This one was "6." 11. This one was "11." Cute how it thinks I'm retarded, huh?
Adding them means you have to add another library, another dependency. And other people do it too and might do it a bit differently. It is a valid concern..
1. Usually COPY-SEQ suffices, but having one that would copy arrays with more fidelity in terms of fill-pointers and the like would be nice. Writing your own is a bit tedious, but not hard. 2. No idea. It's a 3-liner with MAPHASH, though. 3. Circular buffers. (Hey, this one actually has a good answer!) 4. Because you can extend lists without mutating any state. (Wow, two good answers in a row.) 5. Decades of history and a sometimes respected convention that you only add "-P" if the name you're adding it to has a hyphen in it already. Hey, if you want a good, consistent naming convention, there's always Scheme. Well, pre-R6RS Scheme; the names of their fixnum- and flonum-specific operations are an affront to nature and humanity alike. 6. Because building trees out of conses is such a fundamental Lisp idiom. Besides, the copy isn't **that** deep, because things like vectors and strings are still atoms. 7. They overlap enough with MAKE-ARRAY. 8. I dunno. I gather there was a lot of resistence to the fancy extra vector/array features from the non-Lisp Machine vendors, though, because stock hardware didn't support it as well. 9. EQL is a good default. It only fails on strings, but the community has a bias towards using symbols instead of hashed strings regardless. 10. What would the final value for the loop variable be in DOSEQ or DOHASH? It's not nearly as easy to chose as it is with DOTIMES and DOLIST. But if you don't care about that (and I hardly blame you if you don't), it's silly how easy it is to whip up your own DOSEQ and DOHASH macros.
Thanks for looking that up.. I disagree though, this is too complicated. Predicate =&gt; '-p' on end, done. *Or* maybe like (setf function)s one could name functions to be in some class, like a 'setting' function one could think of (p function) to be a function in the predicate class, and called ((p function) ...), (derivative function) could refer to the derivative of a function and such. One might want a neat way to decrease parenthesis though..
That's why I have four "No idea"s in my list. :)
About 6 Why not a compiler macro? I guess i know the answer; compiler macros are supposed to make it do an equivalent thing. Making OR/AND an macro when used as function doesn't perform all of the 'clauses' so then it wouldn't work equivalently when some part is destructive. Edit: And 10 is a bad reason. Many don't particularly like LOOP either..
Something along the lines of (defmacro do-seq ((var val &amp;optional return) &amp;body body) `(block nil (map 'nil (lambda (,var) (tagbody ,@body)) ,seq) (return ,return))) Implicit TAGBODYs and BLOCKs are de riguer for DO and friends, after all. A MAPHASH-based DOHASH wouldn't be any harder.
Good questions if you ask me. About 7, EQL is more efficient, and it forces you to use symbols. The advantage of symbols over strings is that symbols can be pointers to a location of (some kind of) dictionary(like an hash table) so (eql symbol symbol) just has to check the equality of two pointers, and getting the value of a symbol is just looking through its pointer. One might implement this by having *only one real* hash table, and each 'hash table' is just a integer, and then when you GETHASH, with a symbol you follow the symbol-pointer to an array of values, AREF(if you will) with that integer gets you the value you want. But there are costs of course, you have to do more to get the value, and maphash would probably be slower.. So i am not sure if/how they leverage it. Anyway, digressing a bit. I have some issues with CL also. For one, everything is in the language standard, nothing is standard-library. (Alexandria is a good idea, btw.) (coerce (list #\5 #\5) 'string) -&gt; "55" (string (list #\5 #\5)) ;; Errors: 'it cannot be coerced' bad wording? What else does it mean? Lacking functions, nothing like whitespace-p and such. No 'bit-or' for no apparent reason. parse-integer but no parse-number. Functions often less general than they should be, sometimes it seems like this is intended as a way to show which type it is. For instance APPEND doesn't work on vectors/strings, instead you have CONCATENATE. SBCL can get a rather long-winded in warning. Actually all a bit superficial concerns, but concerns nonetheless. One thing i find more important is that the types are too opaque, you can just ask it 'what types would you infer'? There is [disassemble](http://www.lispworks.com/documentation/HyperSpec/Body/f_disass.htm#disassemble), though. Btw, i keep a list of these minor concerns as i program, haven't used it for very long, so not that much on it.(yet)
I think in Lisp they're just called macros. No idea what you mean beyond that. Generally you don't make macros where functions will do. If you don't like loop, use [iterate](http://common-lisp.net/project/iterate/) and quit whining.
And what would be the course of actions? Flee to some another language, just because the current one has some (fixable) imperfections?
I understand that you can *construct* things which address many of the issues above. That's no excuse for crappy language design-by-consensus decisions in the first place. (And I'm looking straight at you, Steele). Lisp is supposed to be beautiful.
A simple question mark would be elegant, wouldn't it?
&gt; Circular buffers. (Hey, this one actually has a good answer!) I see no good use of vector-push in circular buffers. Quite to the contrary, it'd be a big source of bugs. It doesn't wrap around. It just fails silently. &gt; Because you can extend lists without mutating any state. (Wow, two good answers in a row.) Definitely *not* a good answer. If the point is that literals shouldn't be mutable, that's already false for everything. If the point is that literals shouldn't be extendable in a mutable fashion, that's already false for lists. If the point is that it should be *possible* to extend a literal without mutating it, that's insipid. Who'd care about that? Lisp should be consistent. Either literals shouldn't be mutable; or they shouldn't be extendable; or they should be extendable without consequence. You shouldn't get to pick and choose your justification based on data type. &gt; Because building trees out of conses is such a fundamental Lisp idiom. Besides, the copy isn't that deep, because things like vectors and strings are still atoms. I think this is another way of saying "because they didn't get around to it." &gt; They overlap enough with MAKE-ARRAY. So does make-string. Why does it exist then? And make-array is a big fat ugly function for making simple vectors. And why isn't LIST called MAKE-LIST? &gt; What would the final value for the loop variable be in DOSEQ or DOHASH? Um, what? Just make DOSEQ work exactly like DOLIST. 
I didn't say anyone should leave the language, nor did TheSummarizer. What is wrong in pointing out things suggesting they can be improved upon?
I meant [as macro defines](http://www.lispworks.com/documentation/HyperSpe/Body/m_define.htm#define-compiler-macro), my point is that OR is a macro, and not a function with a compiler-macro, because it not doing all the clauses is an change of behavior that is not always equivalent.(It is not always just an optimization.) 10 remains a bad reason, why does DOLIST even exist, why not demand of users they use LOOP or MAPCAR there too? Also i don't use iterate anymore either, btw i don't use Iterate anymore either, just function composition and mapcar and such. Sometimes a DO if i really cannot figure it out otherwise. There was one iteration construct i still wanted to learn(eventually) but i forgot its name..
You're saying that because Lisp you can construct (through some hacks I might add) a COPY-ARRAY function, that somehow this makes Lisp beautiful because they forgot to include it in the spec? You can make a COPY-ARRAY function in practically any language no matter how ugly. Yet these languages had the foresight to include copying of basic data types as part of their language design.
There is the issue of cultural history: *Common* Lisp is a Common dialect of Lisp, and so it had to adopt the conventions of the dialects that it was intended to unify.
If you need to copy an array you are probably using the wrong data structure.
This is picking the pepper out of the fly shit. Getting indignant about ten things in a 1200 page spec is absurd. You have options, and you know that CL was not designed _tabula rasa_ but rather by a committee to satisfy MacLisp, Interlisp and Lisp Machine Lisp users. Compatibility with older software was an important concern. Either way, it's not stopping you from hacking around it and getting work done, so get over it. If you want a well-designed Lisp, use Clojure.
Things are better than they once were; nowadays [Alexandria](http://common-lisp.net/project/alexandria/) seems to have a lot of the functionality that the submitter wishes were part of the standard. And then for things like `doseq` ... well then, `loop` isn't there for nothing. AFAICT things like `dolist` are only there for Lisp-Machine-Lisp compatibility ('tho Mr. Joswig would be able to give a more definitive answer).
Life is so much nicer with persistent data structures.
And is there any improvement process which benefits from such suggestions?
Not really Markdown's fault; it just changes it to an `&lt;ol&gt;` which does the numbering (wrong). Of course, it could ignore lists that aren't already 1..n, but meh.
Any improvement process benefits from you getting overly defensive :p I guess the answer is no, i guess, one would have to make a list and go over the names and functionality more thurroughly, i guess.
Youare talking about it like we're condemning CL, we're not. You nor CL is being attacked, just pointing out stuff, no reason to get defensive.
&gt; It doesn't wrap around. It just fails silently. It *doesn't* fail silently; if it can't push because the fill-pointer is at the end, it returns NIL, instead of the new value of the fill-pointer. &gt; If the point is that literals shouldn't be mutable, that's already false for everything. Well, what's actually the case is that modifying literals is undefined according to the ANS. But you can always extend a list without modifying its structure by consing on its front. If what you're asking is actually why you can extend it using NCONC or RPLACD, well, in a way you can't, because that invokes undefined behavior. Your implementation may let you get away with it, but it's a bad idea because you can introduce weird behavior that may well differ between compiled and interpreted code, or compiled code with different optimization settings. You shouldn't use (SETF AREF) to modify the elements of vector or string literals either, for the same reason. If what you're really saying is that it's a damned shame that Common Lisp doesn't have immutable types alongside the mutable ones, I really couldn't agree more. &gt; I think this is another way of saying "because they didn't get around to it." Not really. Conses are used to represent both lists and trees all the time. I don't think I've ever seen someone build a tree out of vectors in real Lisp code. &gt; And why isn't LIST called MAKE-LIST? Because MAKE-LIST is called MAKE-LIST? LIST and VECTOR work by making making their arguments into elements of the relevant sequence, while MAKE-ARRAY, MAKE-LIST and MAKE-STRING construct a sequence of a specified length. As for why MAKE-STRING is distinct from MAKE-ARRAY, it's because it saves you from having to use MAKE-ARRAY with the :ELEMENT-TYPE keyword. If all you want to do is make a vector, you can just omit the keywords that don't apply. &gt; Um, what? Just make DOSEQ work exactly like DOLIST. DOLIST binds the variable to the last value of CAR, which is NIL. There's no analogous final value for the variable when traversing a vector. It's a really minor quibble.
Fair enough.
LOOP bites goat scrotum when it comes to iterating over a generic sequence. You can use ELT and LENGTH and get the thrill of O(N^2) speed, or you can hack together some sort of half-baked iterator abstraction. Or you can punch yourself in the face, which will be more fun and no less productive. File this as reason #17 why ITERATE kicks LOOP's ass and takes its soda money.
I think DOLIST is mostly historical.
&gt; No 'bit-or' for no apparent reason. Er, it's called LOGIOR. It's short for LOGical Inclusive OR. As names go, I guess it's better than SLOT-MAKUNBOUND. &gt; parse-integer but no parse-number. This on the other hand is a bloody tragedy. And unlike COPY-HASH-TABLE, writing your own PARSE-NUMBER (or even just PARSE-FLOAT) is not an entirely trivial undertaking. And you know that the functionality is there in the reader, and you just can't get at it.
Common Lisp was not meant to be beautiful: it was meant to be a common ground between all of the extant Lisp implementations. As such — like any *standard* — it's a collection of compromises. I'm frankly impressed that it came out as well as it did.
Come join [the dark side](http://clojure.org). We have great concurrency support, and [cake](http://clojure.org/file/view/clojure_cake.png/42336345/clojure_cake.png). 1. No need. They're persistent... 2. No need. They're persistent... 3. `conj` works on most all sequential types 4. We have literals for (persistent) lists, vectors, sets, hash-maps, regexes, etc. 5. Ours all end in "?" 6. No need. They're persistent... 7. No accounting for taste, I guess. 8. No need. They're persistent... 9. Java's hash and equality routines do the lifting there. 10. We have `doseq`, and it works on hash-maps, too. 
&gt; As for why MAKE-STRING is distinct from MAKE-ARRAY, it's because it saves you from having to use MAKE-ARRAY with the :ELEMENT-TYPE keyword. If all you want to do is make a vector, you can just omit the keywords that don't apply. I guess what I'm after is that MAKE-VECTOR should create an extensible vector with a fill pointer (which would be easier to type than MAKE-ARRAY) and MAKE-SIMPLE-VECTOR should create a simple vector. And don't get me started about the fact that MAKE-STRING takes an element type (or that Lisp distinguishes between simple strings and general strings, or that Unicode isn't standard...) &gt; DOLIST binds the variable to the last value of CAR, which is NIL. ??? The spec only says that DOLIST returns NIL unless you specify otherwise. It doesn't say anything about CARs. So why not make DOSEQ do the same thing?
Particularly when it must work with existing Java code (and so must ref everything) Clojure can be *incredibly* slow. :-(
I'm reminded of one of Erik Naggum's quotes from my fortunes file: &gt; It is surprising what people will complain about if they think it is &gt; only acceptable to complain and how constructive they are if they &gt; think it is only acceptable to be constructive.
You can escape the period: 1\. Like 3\. This 2\. See?
Not in my experience. Where did you see it being "*incredibly*" slow? Also: compared to what? Clojure is "*incredibly*" fast compared to Ruby or Python.
Bah. All you really need is a cons cell.
I am pained to report that optimized Kawa code will run over 1000 times faster than optimized Clojure when communicating with our Java library. I did not mistype that. All because it doesn't have to make refs. The difference was unbelievable.
That's odd. I'd be interested in seeing code or hearing more about it. Clojure should be roughly on par with Scala or any other JVM language (and even better with the new primitives work that's going on). I don't know what you mean about the refs. Edit: I'm not sure why I'm downvoted. Really, the performance should be fine. It doesn't make any sense why Kawa would be 1000X faster than Clojure. I'd love to help.
&gt; I guess what I'm after is that MAKE-VECTOR should create an extensible vector with a fill pointer (which would be easier to type than MAKE-ARRAY) and MAKE-SIMPLE-VECTOR should create a simple vector. MAKE-SIMPLE-VECTOR would be worthwhile because the precise characteristics of a SIMPLE-VECTOR are implementation-defined. As for the a MAKE-VECTOR that returns a vector that makes a vector you can use as a stack, my guess is that there just wasn't a whole lot of demand for it. I'm glad the functionality is there, but in the Lisp code I've read (and written) I've seen at least ten cons-based stacks for every vector-based stack. It comes back to the fact that Lispers tend to build stuff out of conses rather than arrays. There's nothing wrong with prefering arrays, but by doing so you're going a bit off the beaten path, so you have to do a little more work yourself. &gt; ??? The spec only says that DOLIST returns NIL unless you specify otherwise. It doesn't say anything about CARs. So why not make DOSEQ do the same thing? What is the variable bound to when you specify the return value of DOLIST? What's it bound to when you specify the return value in DOTIMES? Like I said, it's a quibble.
&gt; What is the variable bound to when you specify the return value of DOLIST? Actually I believe the spec says it's bound to nil.
Yes. And in the case of DOTIMES its bound to the upper limit. The analogy makes me always want to have bind the variable to an equivalent value for arrays, and it's just not there. When I wrote DO-SEQUENCE for my own little library, I spent about 10 minutes writing it and an hour trying to figure out a good answer to this **vital** question. 
&gt; And unlike COPY-HASH-TABLE, writing your own PARSE-NUMBER (or even just PARSE-FLOAT) is not an entirely trivial undertaking. At least someone already wrote [parse-number](http://www.cliki.net/PARSE-NUMBER). There are lots of gems like this that were once part of the proprietary libraries that came with Genera, but have been lost in time (e.g. the incredibly flexible date parsing utilities).
The significant implication is ClozureCL on iOS, right?
It was not so much about unifying, but more about preventing the further development of various incompatible of mostly Maclisp derivatives. So that there were a single modernized Maclisp, and not several. It had not to adapt all the conventions of NIL or Spice Lisp, because they were not widely used, yet. It had to have some backwards compatibility with Maclisp, so that some software could be more easily ported (like Macsyma).
&gt; At least someone already wrote parse-number. Oh, nice. Still, I wonder if it would be possible to make something like that part of Alexandria, since it's small and doesn't appear to be actively maintained....
I think that first sentence could just be shortened to the first four words.
&gt; 1. Why is there no freakin' copy operation for arrays? &gt; 2. Why is there no freakin' copy operation for hashtables? [Kent Pitman talks about the question "Why is there no generic COPY function?"](http://www.nhplace.com/kent/PS/EQUAL.html) 
But I don't want a generic copy operation. I just want a standard function to copy an ARRAY, and another one to copy a HASH TABLE. Something which can be done trivially in countless other languages.
How exactly does persistence remove the need for copies?
&gt; If the point is that literals shouldn't be extendable in a mutable fashion, that's already false for lists. What does that even mean?
[Persistent data structures](http://en.wikipedia.org/wiki/Persistent_data_structure) are a particular subset of immutable data structures. It doesn't have anything to do with persistence as it relates to, say, databases. You don't need to "copy" the number 5 since anyone that performs operations with it will get a new, different value; 5 isn't mutable. Likewise with persistent data structures. If you `conj` onto a list or vector, you get a new list; `assoc` onto a map, you get a new map back. For more info: [Clojure's approach to Identity and State](http://clojure.org/state) [Persistent Data Structures and Managed Reference](http://www.infoq.com/presentations/Value-Identity-State-Rich-Hickey) [Are We There Yet?](http://www.infoq.com/presentations/Are-We-There-Yet-Rich-Hickey) 
Yes, it's a collection of compromises and Steele knew it: http://imgur.com/pbNVF.png
Why the downvotes?
I can do that in 60 lines :p Edit: oh, no fractions, hmm maybe it *should* do that. Would still be shorter than linked there, though. Edit: FTR I hereby declare it public domain. (defpackage :j-parse-number (:use :common-lisp :alexandria) (:export parse-number)) (in-package :j-parse-number) (defun parse-positive-number-raw (string &amp;key is-dot junk-allowed) "Raw version, parse-positive-number." (declare (type string string) (type (function (character) boolean) is-dot) (type boolean junk-allowed)) (if-let (i (position-if (lambda (ch) (or (funcall is-dot ch) (case ch ((#\0 #\1 #\2 #\3 #\4 #\5 #\6 #\7 #\8 #\9) nil) (t (assert junk-allowed nil "Junk in ~s" string) t)))) string)) (if (funcall is-dot (aref string i)) ;Is an real (+ (parse-integer string :end i) ;Shouldn't see junk. (multiple-value-bind (result length);Junk should be users fault. (parse-integer string :start (+ i 1) :junk-allowed junk-allowed) (* result (expt 10d0 (- i -1 length))))) (parse-integer string :junk-allowed junk-allowed :end i)) (parse-integer string :junk-allowed junk-allowed))) (defun parse-positive-number (string &amp;key (start 0) end (dot #\.) (is-dot (curry #'char= dot)) junk-allowed) "Documentation string refuses to be tautological." (parse-positive-number-raw (if end (subseq string start end) (subseq string (or (when junk-allowed (position-if-not (rcurry #'find '(#\Newline #\Space #\Tab)) string :start start)) start))) :junk-allowed junk-allowed :is-dot is-dot)) (defun parse-number (string &amp;key (start 0) end (dot #\.) (is-dot (curry #'char= dot)) junk-allowed) "No tautology for this one either!" (assert (&gt; (length string) start) nil "~s is shorter than ~s." string start) (flet ((parse-on (step) (parse-positive-number string :start (+ start step) :end end :is-dot is-dot :junk-allowed junk-allowed))) (case (aref string start) (#\+ (parse-on 1)) (#\- (- (parse-on 1))) (t (parse-on 0))))) And a test. (defpackage :test-j-parse-number (:use :common-lisp :j-parse-number) (:export test)) (in-package :test-j-parse-number) (defun test (&amp;key (fr -10.0) (to 10.0) (to-test #'parse-number) (round-to 1d-6)) "Tests parse-number" (let ((x (round (+ fr (random (- to fr))) round-to))) (assert (= (coerce x 'double-float) (funcall to-test (princ-to-string x))) nil "Test failed ~a ~a" (coerce x 'double-float) (funcall to-test (format nil "~a" x))))) (dotimes (k 100) (test :fr -732525325 :to 71213532532)) Also follows parse-integer closer. Edit: damn you, Tab, this is from before i stopped emacs from making them. Indentation not quite right...
... and, in his case, will bitch and moan endlessly if they have a platform.
Hey, I'm genuinely curious about the performance problems you saw. I'd like to see if couldn't offer some insight, or help improve Clojure.
Looks like a nice read, and well written. Do seem like i miss something now and them, what's primcall-op, primcall? and such? Scheme functions i guess, probably just need to find a reference.(or maybe we're just supposed to infer what it does.) How is immediate-rep available in emit-expr, i though it is outside scope? 
Perhaps my advice was a bit too opaque for the folks around these parts... (or maybe I'm just an asshole). Amortized complexity analysis is a pain and "oh hey I'll use a mutable array even though I need to copy it!" is not something that triggers the danger danger you are shooting yourself in the foot detector in a lot of people.
What exactly is wrong with COPY-SEQ that COPY-ARRAY will fix for you?
The claim was that lists could be extended in an immutable fashion: (setf a '(a b c d e)) (print a) -&gt; (A B C D E) (setf b (cons 'YO a)) (print b) -&gt; (YO A B C D E) (print a) -&gt; (A B C D E) But they can also be extended mutably: (setf a '(a b c d e)) (print a) -&gt; (A B C D E) (setf (rest (rest a)) (cons 'yo (rest (rest a))) (print a) -&gt; (A B YO C D E) So if the point was that literals should only be attached to immutably extendable data structures, it's already nonsense because lists can be extended mutably.
Besides the first class function and closures, what else does JavaScript have in common with Scheme?
I wouldn't say that lists can be "extended". In the immutable case, you simply make a new list sharing structure with the original, but it's still a new lists. In the mutable case, you mutate individual conses, but I wouldn't call it "extending", as lists are largely an illusion in lisp. They're not distinctly defined objects the way arrays or hash tables are, they're simply a conventional usage of conses. That said, making sure the lists (and other objects) resulting from literals are immutable would be a Very Good Thing™ to have in CL; I would probably count not addressing this in any way than "results are undefined" as one of the bigger warts on the standard (by which I mean something that could easily be done differently and better, but wasn't, and not for compatibility reasons).
Oh, that thing. I still think it's one of the absolutely worst names to choose for this concept, *anything* but "persistent" would have been better.
Other than the shooting, Mrs. Lincoln, how was the play?
Cool story, bro.
Those are the only similarities needed that are relevant to the text of "The Litle Schemer" which, so long as I can remember, doesn't even mention macros or other Scheme features. The book is more about recursive functions than about "Scheme" itself (even though the latest editions use Scheme).
&gt;(through some hacks I might add) There is no hacks in that implementation, it's just short. And you can construct more verbose and easier to understand for noobs version if you want to. 
Brilliant! That's just one reason why I like Steele's writing so much. These gems just lie there to be discovered. 
Javascript was first modeled after Scheme and Self. It picked up it's curly brace syntax after Netscape signed a deal with Sun.
.... nor is there a clear (technical) reason why it should. 
60 english pound for a printed version of the controversial R6RS??? Cough. I'm not that enough Lisp fan to buy one.
Dances a bit around not mentioning alternatives to lispworks, of course! I guess i can't blame them..
In that case, I don't understand what your purpose of submitting it was. Is there something more to this I'm not seeing, or were you just highlighting the silly price? 
Also Dan Weinreb's [post on the subject](http://danweinreb.org/blog/rumors-of-ita-acquisition-are-just-rumors).
wait, wouldn't this be clearer and do the same thing? (defmacro emit (s fmt &amp;rest args) (unless (null s) `(when *debug-output* (format ,s (concatenate 'string "DEBUG: " ,fmt) ,@args) (finish-output))))
I thought maybe there was something magical about the macro not returning anything, so I tried this out in sbcl, compiled my wrapper function, and disassembled... no difference as far as the compiler is concerned, so I agree that the "unless" is a better approach than recommending progn as a noop. Another thing I noticed was that if I (setf x nil) and pass it to the macro, the macro does not see it as null. I am confused. (defmacro foo (s) (unless (null s) `(print "hi"))) =&gt; foo (setf x nil) =&gt; nil (foo x) =&gt; "hi" (foo t) =&gt; "hi" (foo nil) =&gt; nil 
Hmm, what's about (when s ...
Macros operate on the symbols, not the value of the symbols, iirc. Man it's been a long time since I poked at lispy lisps instead of schemey not-lisps. i.e. you'd need to do something like: (defmacro emit (s fmt &amp;rest args) (unless (null s) `(when *debug-output* (unless (null ,s) (format ...) (finish-output))))) Realizing that would double-execute the argument s, you'd want to create a let expression wrapped around there to temporarily store that value. Again, forgive me if I'm retardedly out of practice.
You could make the `*debug-output*` a compile-time flag, too, depending on your use case. It should probably compile down to just the format and finish or nothing.
It's also likely beneficial to perform the concatenate at compile time, since most people don't do automated manipulation of format strings. Furthermore, if he is turning these things on and off as needed, prepending #+no or ; to the form is much simpler and more efficient than passing in nil for the stream.
a small amount more info [here](http://formlis.wordpress.com/2010/06/28/what-is-formlis/)
A larger amount of information is in their [Fourth in Lisp](http://formlis.wordpress.com/2010/06/30/forth-in-lisp/) blog post, which lispm submitted to Reddit as [Technology behind Formlis, Forth in Lisp](http://www.reddit.com/r/lisp/comments/ckuky/technology_behind_formlis_forth_in_lisp/).
Anyone tested it ? I would like to see some feedbacks from users. Thanks.
"Macros operate on the symbols, not the value of the symbols" -- this is right. I was silly. I was confused by the use of this macro in debugging. I do not know how it is intended to be used, and my current guess is ugly (and hopefully wrong). (emit stream "Stuff") ... a bunch of code (emit stream "More Stuff") This looks like an annoying debugging approach in that I would envision someone replacing every instance of "stream" with "nil" and vice versa, being careful not to replace other legitimate uses of the symbols.
There is an excellent interview on Software Engineering Radio (se-radio.net I think it is, episode 80-something) with Mr. Gabriel about Lisp. Really enjoyed listening to it on my way to work.
er, ahem, yep. i sure ain't not blushing right now :)
Is it about the blog or is it about 'Stumbling Through History' post? Also i don't entirely get it? Isn't that supposed to be (finish-output ,s) ? And why would (format nil ...) there go into the garbage collector? NIL surely doesn't represent any stream, and then all the function does is return a string, and it is also immediately apparent the string isn't going to affect anything, so it should just immediately be discarded.. Strange though that it doesn't have the guts to warn us about it, it does warn us when a variable isn't used, after all. That said [the spec](http://www.lispworks.com/documentation/HyperSpec/Body/f_format.htm#format) isn't really clear either. &gt; If destination is a string, a stream, or t, then the result is nil. Otherwise, the result is a string containing the `output.' Following that, shouldnt (format :oopsie "text") print the string? It is not a string or a stream.. It doesn't say that it should output into the *standard-output* stream if the input is T.. Eh i am confused, how can the spec be that unclear? Edit: Denest does solve 'the things getting too nested, too many columns' part, but you do have to write with-slots a bunch. Btw, nested macros aren't really a problem, but if you don't want them, just use LABELS, i guess. &gt; (defmacro denest (&amp;rest args) (if (null (cdr args)) (car args) `(,@(car args) (denest ,@(cdr args))))) 
Given that this ITA, I took a while to untangle in my mind the *Faré*-Query part of the title...
&gt; Following that, shouldnt (format :oopsie "text") print the string? No, according to the page you linked to: "destination---nil, t, a stream, or a string with a fill pointer." &gt; It doesn't say that it should output into the standard-output stream if the input is T.. It does in the page about [Formatted Output](http://www.lispworks.com/documentation/HyperSpec/Body/22_c.htm). &gt; Eh i am confused, how can the spec be that unclear? Hint: it's not the spec that is at fault.
Since the debug-output checking is done at runtime, there's no reason for defining a macro here: (defun emit (stream control-string &amp;rest args) (when (and stream *debug-output*) (format stream "~&amp;DEBUG: ") (apply #'format stream control-string args) (finish-output stream))) If we wish to avoid interpretation of the control string when it's a literal, it's possible to define a compiler macro: (define-compiler-macro emit (&amp;whole form stream control-string &amp;rest args) (cond ((null stream) `(progn)) ((stringp control-string) `(emit ,stream (load-time-value (formatter ,control-string)) ,@args)) (t form)))
It is paid for by someone who wants to use it, AFAIK.
No, the spec is could certainly be more clear, if you look at the function Format it doesn't state how T is treated, and this is how it links to your page: &gt; For details on *how the control-string is interpreted*, see Section 22.3 (Formatted Output). So one would expect that to *just be about the control string*. Taken together it isn't ambiguous, but they could've certainly be more clear about it. In [\*standard-output\*](http://www.lispworks.com/documentation/HyperSpec/Body/v_debug_.htm#STstandard-outputST) it only mentions it as an example. Edit: i guess all i am saying that it isn't a perfect crystal.. The obvious..
I've wondered this too. I hate to say it, but I don't have any experience with, say, unit testing or any other formal testing process. When I tried writing unit tests for Calispel, a CSP-style channel library, I was stumped. What I'd love to do is simulate certain predefined combinations--or maybe even all possible combinations--of preemptive thread scheduling before/after lock acquisition/release and CV signaling/wakeup. How else would you *test* code for race conditions? (Which of course wouldn't be *proof*, but it'd be a very big something.) I seem to recall, while researching options, finding a strong bias towards "use this Windows software tool for multithreaded testing"--but in any case I should read up on the techniques more to get an idea of what I want.
Welp, people seem to be bashing the ITA site bad.
The thing I want out of this is a tool that will compare flights and give a *total cost estimate*. You'd have to give it more information (like how many bags you intended to check). This is the kind of thing ITA should be really good at - it's essentially an arms race between the airlines adding more fees, and the search sites adding more features to price them. ITA should be able to out-innovate them, even though they can't really price a new feature until after the airlines add it.
You are *not* ITA's customer. The airlines are ITA's customer. I believe Airlines pay ITA to power their websites and provide ITA access to some very low-level information ("how many tickets are left on this flight?"). I'm not sure spurring an arms race between airlines is good for ITA.
*sigh*... you're probably right. But: * The airlines are already in an arms race with each other * ITA's "job" has always been to use knowledge to get consumers the best deal So, this is not that much of an extension of the current situation, and having Google to support them might help.
The problem is ITA (and other ticket search engines) rely on knowing what tickets are available and what price the airlines is expecting. Preferred search engines will get shown more tickets at cheaper prices. We'll see though. It's not super hard to calculate fees, so I can imagine an airlines not going nuclear over it (but also, fees can change from the day you buy the ticket to the day you fly, so the price you see will be misleading anyways).
Wonder if this means that GOOG will accept the promotion of an active Lisp community? Unfortunately, since the press release/blog entry mentions that "access to the data" was the prime reason that GOOG bought rather than licensed QPX I suspect we'll have a code freeze with slow bit rot of the Lisp code. I wonder if this means that the big project (Polaris?) under way to do airline reservations just overran development budgets (especially after Air Canada bailed) to the point that ITA had to look for a buyer to appease its investors? While happy for ITA, the Lisp community loses its poster-child for Lisp commercial relevance. 
 (defun ansi-boolean (x) (list (concatenate 'string "\\&lt;\\(" (symbol-name x) "\\)\\&gt;") 0 ''ansi-lisp-boolean)) (defun ansi-constant (x) (list (concatenate 'string "\\&lt;\\(" (symbol-name x) "\\)\\&gt;") 0 ''ansi-lisp-constant)) (defun ansi-declaration (x) (list (concatenate 'string "\\&lt;\\(" (symbol-name x) "\\)\\&gt;") 0 ''ansi-lisp-declaration)) (defun ansi-condition-type (x) (list (concatenate 'string "\\&lt;\\(" (symbol-name x) "\\)\\&gt;") 0 ''ansi-lisp-condition-type)) (defun ansi-function (x) (list (concatenate 'string "\\&lt;\\(" (symbol-name x) "\\)\\&gt;") 0 ''ansi-lisp-function)) ... and so on ... WTF????
Hey Marissa, Cambridge != Boston. ITA is no more a Boston-based business than MIT is a Boston-based university.
&gt; The idea that Logo is good for little children but not for older people is, unfortunately, a common one. And not only for Logo!
Or, "hooray for CFFI".
ITA uses an super old linux kernel. We're talking barely 21st century! Stability is so important they stuck with what worked and didn't change. How that style will mix with google?! The other thing is that their lisp programs are so amazing I don't think there's anyway they can move away from them. They code close to the metal and if there isn't a way they create it. Amazing group of people! 
This is fucking 1984soft.
Heh, nice. :-)
&gt; Since we still choose our samples randomly, every rendering will look different - depending on which orbits your random search finds. ... This also means that [the image is not symmetric](http://erleuchtet.org/buddhabrot_symmetry.jpg) So this isn't a visualization of the actual mathematical object as much as it is a visualization of the artifacts of this approximation process, which contains fractal shadows and echoes of itself. Ie, this is the GEEKIEST LENS FLARE EVER!
I was trying to make this thing work on Windows couple of days ago. Couldn't make it work. However I was trying to plug it into an existing and probably little outdated environment. Will try again. 
hmm. isn't it more like a long exposure? (capturing the escape behaviour of a handful of points outside the mandelbrot set) also, it's *pretty* &lt;3
Not a great guide. The first example erroneously suggests that MAKE-PACKAGE with no :USE argument will result in a package that uses the COMMON-LISP package, but that's not specified and doesn't work like that on SBCL. 
&gt; - Once a name has been declared constant, it cannot be used a the name of a local variable (lexical or special) or function parameter. Really. See page 87 of CLtL II. wtf, keep this +convention+ constant, i guess! &gt; You often have to declare the result type to get the most efficient arithmetic. Eg, &gt; (the fixnum (+ (the fixnum e1) (the fixnum e2))) &gt; rather than &gt; (+ (the fixnum e1) (the fixnum e2)) And some similar points, also painful... It would be nicer to declare things to be integers within a range, and then the compiler keeps track of the range by itself. Then one would only have to declare it at points where the range is wider than reality,(edit: i mean wider than the convenient data representation) or you just clamp/coerce(the latter just doesn't enforce) them. My little blogpost about type calculation could be good for this, if it had better simplification. I am working on it, now looking at using [this](http://ojasper.nl/readmes/Regular%20tree.html#Regular%20tree) for equivalences, writing all the simplification yourself([this](http://ojasper.nl/readmes/Simplify.html#Simplify)) is tiresome.. (I should make those readmes indicate where they are in the .tar.gz..) Anyway, similarly with floats, but there maybe one would also want a precision or something. The alternative is ditching the idea that you're giving a formula, and instead interpret the code as if you're giving a description on what to do with data, as C looks at it.
This guide is also included in the [CL cookbook](http://cl-cookbook.sourceforge.net/packages.html). If it contains errors, it is a problem. Is Tim Bradshaw really working on a new section on packages, as the cookbook page says? 
No idea. The general tone of the linked guide drives me crazy, as it takes every opportunity to knock the CL package system as stupid, awkward, inconsistent, etc. I'd like to write a guide to using the CL package system to use multiple independently-developed bodies of software without any name conflict problems, which is something the CL package system can do for you. (Well, I'd really like someone else to write it, because I'm busy, but the fact that this garbage guide gets linked all the time makes me want to bump its priority up.)
SBCL broke with the tradition, which was not specified in the standard. The logic behind the former behaviour: one could do (in-package 'FOO) in a REPL and would be a fully useful package including all the implementation specific extensions. Later IN-PACKAGE was changed in semantics, slightly. MAKE-PACKAGE would work similar. 
&gt; The other thing is that their lisp programs are so amazing I don't think there's anyway they can move away from them. How do you know / why do you think this?
&gt; Are you guys still not making use of epoll? You can mod hunchentoots task manager to handle this if you update to the latest version. Perhaps, but the last time I did any significant work on BittAds is quite a while ago again and last I heard the bottleneck is in flexistreams/chunga, something that can not be 'fixed' with event-based IO without basically rewriting all of Hunchentoot to be event-based. This is actually something I still would like to do one day (make a decent no-nonsense event-based IO library &amp; webserver built on top for CL) but apparently not for BittAds any time soon; the current set up is working fine and work is mostly put in UI and layers between components/parts in the whole system. &gt; Also I noticed the yaclml syntax, does the site still make use of UCW or are you just making use of the yaclml library? We're only making use of the yaclml library; we ditched UCW a long long time ago. &gt; One last question, have you guys looked at Closer &amp; Filtered Functions by Pascal Costanza? Would be cool to see some of these libraries being used in a higher level web layer. The MOP use described above (the use of metaclasses and custom slot definitions) actually uses Closer as it's compatibility layer. Filtered functions look interesting but I doubt it will be of much use in our web layer because I think that once you've mapped HTTP semantics to a few generic functions and have resource types/classes to dispatch on, there's not much left that needs more advanced or precise dispatching on incoming HTTP requests. If there is, it's typically so domain-specific that you end up separating these things from the HTTP interfaces anyway. &gt; Are you guys still not making use of epoll? &gt; does the site still make use of UCW Your apparent knowledge of some things that were not disclosed here, your interest in epoll/kqueue (event-based IO) and especially your replies on some Dylan post here on Reddit makes me wonder: are you Edward by any chance? How have you been?
In fact, the behavior with no :use is implementation dependent. Many impls include :cl and a few others by default. Unfortunately, I don't know of any great guides...
Dr. Weitz's starter pack is awesome - I'm using it right now. There are a few corrections to note, though. 1. "In the listener, on a new line, type (m-v-b and then press the Tab key. What you've typed should have been expanded to multiple-value-bind now. Note that at the bottom of the listener (in the so-called "echo area") you see the argument list of the MULTIPLE-VALUE-BIND macro." Pressing Tab causes the completion, but the minibuffer shows "Finished completing". One needs to first press Space to see the arg list. 2. "Type an L (the abbreviation for "Load ASDF System") and the Return key. The echo area now prompts for the name of the system to load. Type hun then press the Tab key. The name of the system will automatically be completed to hunchentoot. Press Return to compile and load the library." hunchentoot requires trivial-backtrace, which isn't installed by the stock starter pack executable. 3. "Now do the same to load the hunchentoot-test library. (Note that you can type hun and hit Return and you will get hunchentoo as a partial completion. Now type - (a hyphen) and Tab and you'll get hunchentoot-test.)" Should read "(Note that you can type hun and hit *Tab* and you will get hunchentoo*t* as a partial completion." 4. "Evaluate the form (hunchentoot:start-server :port 9999)" ...reflects an older version of Hunchentoot. Doing (hunchentoot:start (make-instance 'hunchentoot:acceptor :port 9999)) works. END FEEDBACK To fix the trivial-backtrace issue, download the tarball from [http://common-lisp.net/project/trivial-backtrace/trivial-backtrace.tar.gz](http://common-lisp.net/project/trivial-backtrace/trivial-backtrace.tar.gz) and decompress it to the equivalent of C:\Documents and Settings\&lt;username&gt;\My Documents\Lisp Libraries (Coincidentally, I sent this feedback to the good Doctor yesterday.)
He should shout less.
I hate this guys delivery. There are too many hand wavy things, he is forcefully animated and sometimes it seems he is just talking to himself.
[direct to the source](http://github.com/akapav/js)
Ftr, mine: (i like to type) &gt; Jasper den Ouden -- HumWorld - game about 'agents'(being primitive humans) sharing paths to food, i'll have to see how far i'll get...
Personally, I hate the php model of mixing code and output in a single soup. Still, an interesting project.
Mixed code and output is also known as *templating*. It's a practical concept for producing output, but indeed gets ugly when used for everything, output or not.
PHP is regret-based programming.
I regularly use TT in Catalyst. That is templating. Now when i return to php I feel bad...
You can... you don't have to.
I literally have earaches when I listen to his talks.
As a lisp programmer who loves going meta, I have to wonder if this works with [parenscript](http://common-lisp.net/project/parenscript/).
The tone of this article is confusingly inflammatory yet it provides some interesting background information into lisp's role in this history of programming languages.
&gt; The tone of this article is confusingly inflammatory[...] In what way is the article inflammatory? I didn't get that at all from my reading.
The constant dimunization of lisp's utility as other than a primordial ooze for better ideas. Though this could be a misinterpreted rhetorical butress. Or maybe simply because I read this before I'd had my morning coffee.
Understandable, though to be fair the whole point of the article was to describe Lisp's primordial ooze-nature... and the language has indeed served as a spring-board for some great things.
Where are the docs and a decent description?
what a great find. thanks for posting. it is interesting to get a glimpse of perspective from 1987. Common Lisp was still being defined. Also, I have never heard of Symetric LISP before. 
I haven't heard of that either, though I seem to remember that Gelernter was doing some with the Linda tuple space and Lisp, IIRC. Here is the paper about [Symmetric Lisp](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.46.9662). Other than that I found the article to be a nice overview of some language experimentation of that time.
Integration tests with print statements, include the thread's name in the output. Test a small component, then test using that component and doing more. This way you can find the smallest integration that exibits the bug. The tests themselves have many threads performing a workload. Sometimes the workload is hand specified and sometimes based on an algorithm. As the tests become more complex, the workloads become a set number of operations, each operation determined by current state and random numbers. Run the tests hundreds of times to eliminate obvious bug and hopefully most race conditions and deadlocks. These last 3 days I've tracked an intermitant error causing everything from run-time type errors to memory access errors to deadlocks -- but only after about a half hour of testing. I found it: it was caused by using sb-sys:with-pinned-objects. Which in SBCL is just without-garbage-collection. If you sometimes acquire a mutex without garbage collection enabled, and sometimes with garbage collection enabled bad things can happen. 
Spoiler alert: I've seen the last ep already and it ends in a )
I'm going! You should too!
It is "almost done", but its nevertheless not out yet. Its comming out in September. See &gt; http://www.reddit.com/r/lisp/comments/bic7p/land_of_lisp_is_it_still_going_to_be_released_in/ &gt; http://nostarch.com/lisp.htm &gt; http://news.ycombinator.com/item?id=841117 A little bit of searching for yourself instead of posting a question, even here at reddit, would have helped.
That's a completely silly remark considering that his order was just cancelled.
&gt; we've since found it's not available from any of our sources at this time Amazon found out they cant ship a book which was supposed to get published in March but wasn't. Absolutely newsworthy. Vs. References from Conrad Barski, the author of the book, about the delay, updated publishing dates from the publishing company. Yes, youre absolutely right, my remark was absolutely silly and unappropriate and I'm sorry and everything.
Try again ordering it when it's out.
Hi, this is Conrad, the author of LOL. Sorry your order was cancelled- it was rescheduled earlier this year and I suspect the Amazon.ca website caught up on that a bit late. It is definitely going to be out this October. Sorry I'm so overdue on it- But I can tell you it will be a thick book and I'm very happy with it. It's my first book and I'm definitely not happy that folks like yourself had to see their order cancelled because of my delay- Apologies funmler.
&gt; The Common Lisp specification defines a random function, but makes no guarantee that this is a cryptographically strong PRNG. In the absence of such a guarantee, I fear I must assume that it is not suitable. The predominant Lisp crypto package, Ironclad, lists “random number generation” in its TODO file. So I use a crude hack: I open /dev/urandom and just read bytes straight from it. Ick. Is there a better way?
http://hcsw.org/blog.pl/34 ? -- seeds with urandom but does more than just read bytes
Same here but at Amazon.fr, I'll try again when it's out or soon to be out.
Hi, I just noticed that LOL is already a Lisp book ([Let Over Lambda](http://letoverlambda.com)), that's dumb :-/.
ARGH! The paper seems to be behind a paywall, or am I confused?
Yes, "the" paper is behind a paywall, but the author hosts a nearly identical copy. Hit the CPS-Macros.ps.gz link. Or pull a pdf conversion from citeseer. http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.5.3666
Clojure is, more than any other Lisp, a completely holistic experience. You never find yourself sighing because you've sacrificed something important just to get macros. It's the most functional Lisp, even more than Scheme, thanks to hashes and arrays acting as functions. Rich Hickey obviously has a great deal of diverse experience, because Clojure also has built-in relational operators, a rich set of easy-to-use and powerful parallelism primitives, and it has a large body of built-in functional combinators. And of course, access to billions of Java libraries. Now I'm going to tell you my nits. - Java is an albatross. The `proxy` macro is hugely wonderful, but not providing a useful way of getting at annotations locks you out of all the cool up-and-coming Java libraries. Not being able to just make a damn object when you need one doesn't help either. - Startup time. This is entirely Java's fault and there's not much anyone can do about it, but if I'm going to fall in love with a language, I need the repl to show up immediately. Two or three seconds is long enough for me to give up, hit Ctrl-C and type `bc` or `irb` or `python`. Sucks, but it's the truth. - Rapid evolution, blog and github culture. This is a minus for me because I like having code I wrote three months ago still working and I like documentation that doesn't disappear when you switch blog hosts. I also hate tracking down who is the real new maintainer of project foo on Github because the author cranked out the first five releases in one weekend and then lost interest in it, leaving four other assholes' forks of it I have to go digging through and evaluate. This is almost entirely a personal problem but I can't commit to any language or platform, so the less ad-hoc they are and the less they demand I be a part of the "community," the more likely I will be able to build up material I can use rather than frustration. As things improve this should settle down a bit. It's an amazing language and I really hope it does take off.
The first paragraph reads like an advertisement.
If you like Lisp or Scheme and you haven't tried it, you really should.
And if you want the REPL to show up immediately, just don't turn it off.
Were you reading my argument on HN, Rainer? =)
I was reading that. Thanks for mentioning it. Last year I read about it here: http://googland.blogspot.com/2009/08/g-under-hood-of-app-inventor-for.html 
I had not encountered that, thanks.
This problem also makes it unsuitable for scripting.
Huh, I remember this from an interview with Sussman.
It's just "Lisp" these days. Absolutely! Read [Practical Common Lisp](http://www.gigamonkeys.com/book/). Whatever language interests you is the one you should learn. If you already have some Java background, consider [Clojure](http://clojure.org/) instead.
Thanks for the reply. :) I'm really not interested in Java at all, sadly. I'll check out that book though, thanks!
Yes lisp would be a good first choice. Another alternative would be to learn Scheme from [SICP](http://mitpress.mit.edu/sicp/)
If that gives you trouble, you may want to start with [The Little Schemer](http://mitpress.mit.edu/catalog/item/default.asp?ttype=2&amp;tid=4825).
If you've not programmed much before, a very nice introduction to Lisp and programming in general is Common Lisp by Dave Touretzsky. I'm not a mathematician or computer scientist and I never felt lost going through it. You can download it at http://www.cs.cmu.edu/~dst/LispBook/index.html You should learn about C too, though, I think. At least how it handles memory, both relating to arrays and structs and the stack/heap distinction and explicit (de)allocations. It'll teach you a lot about how your computer works and you'll appreciate garbage collection much, much more if you know what you're not having to do.
If you do decide, start with How to Design Programs (htdp.org)
If you're going to keep going with programming classes after java, might as well start playing around with C too. But yes, common lisp is a good choice.
Why? (Not disagreeing just interested in your opinion.)
Keep in mind, however, that PCL is primarily aimed at people who are already programmers, so it doesn't really introduce basic concepts of programming, etc., and assumes you're fairly proficient. So if you have trouble keeping up, consider switching to one of the other books mentioned. That isn't to say that PCL isn't good, it's awesome. You just might not be the target audience at this point in time.
What important things are you sacrificing when you use Lisp that you gain when you use Clojure?
If you already have Java libraries you like, it makes the transition easier. If you don't, the trouble probably isn't worth the gain.
It's in the details. The main thing is that there are literals for sets and maps, and they are functions of their keys, and also that symbols are functions of maps. That kind of thing. It's more functional. You can map and reduce without dealing with the function/value dichotomy in CL. And again, it has a lot of nice built-ins, such as for concurrency. Lisp has no built-in concurrency anything, not even threads (they are an extension available in some, but not all, common implementations). I know of no other language with the neat relational stuff it has. It's just nice.
Should have been more clear I actually meant Lisp in general, not the Clojure bit.
It's like love, you can't force it. Whatever language you want to learn first, that captures your interest first, that's the first one you should learn. Good reasons to use a language won't make you passionate about it. With the first language, it's less important than ever. With the second language you will spend a substantial amount of time unlearning things no matter what your first one was. When you're first starting out, you have less direction than later on too, so it's less harmful to choose something unusual because the hard part will largely be learning to program at all. Since programming is hard to learn, you should at least be using something you find pleasant or aesthetically rewarding, because it'll keep you going. Now, Lisp in particular is a fine choice. It's a good practical programming language. You can write high-performance code with it, you can interface with foreign libraries, you can write web apps, you can write games, you can do all that stuff. There's no domain you'll really be shut out of. Plus, if you get Emacs set up with Lisp, you have an editor you can use forever. It's terser and more high-level than most other systems programming languages but is perfectly acceptable for those purposes. It has a many high quality libraries and there are many new, useful books. It's just a good choice. Unlike many languages, you could live your life in it and be really productive.
This is all true in my experience with. Each new language is about learning and unlearning. The fun part is the newly learned things that are portable. 
Learning lisp first is like having an incredibly good childhood. It will sabotage the rest of your life, which will always be harder and sadder.
&gt; It's in the details I think he's asking for the details... &gt; there are literals for sets and maps Why is this a positive? Is it not possible or too difficult to replicate in CL? &gt; It's more functional. You can map and reduce without dealing with the function/value dichotomy in CL. I don't think that makes it "more functional." There is no dichotomy because it is a Lisp-1, like Scheme. [This article is relevant](http://www.xach.com/naggum/articles/3210202045801166@naggum.net.html). &gt; not even threads (they are an extension available in some, but not all, common implementations) Which common implementations don't have threads? When is STM a good idea? What about a bad idea? &gt; I know of no other language with the neat relational stuff it has. What relational stuff?
Sure, Lisp is a great way to develop good programming habits.
(clap slow)
I second this book. It's what I used during university during my cs 1000 class. We used Dr. Scheme. Back then I thought lisp was a horrible programming language as it seemed more complicated than C (the only language I knew back then) now I use variants of lisp quite regularly and enjoy them. Sadly the university has since removed scheme and now starts with java :(.
Yes LISP is great, the first language I was taught was Scheme and it was great. LISP makes you a better programmer. Plus latter on in high level programing classes teachers will let you use what ever language you want and LISP is a great way to show off. (and have the rule changed to any language but LISP) C will be easy to learn after Java because it is very similar. Then after you have learned C python will be a breeze and feel refreshing, almost like LISP but not quite.
Why so?
Comp sci major. :)
Thanks!
In what way is lisp "a good way to show off?"
[Yes!](http://groups.csail.mit.edu/mac/classes/6.001/abelson-sussman-lectures/)
There are a lot of people who think LISP is really hard to learn and use. Like juggling flaming chainsaws on a unicycle hard. There for anyone who knows LISP must be super smart. Later in collage you have algorithm classes where not everyone is equally proficient with all languages so the teacher lets you do it in the language of your choice, choosing LISP is just kinda "bad ass" because most people don't know/are afraid of it. This makes the non-existent chicks in the class think you are awesome.
Ah, very interesting. I got attracted to Lisp from an article I read... it seems neat in principle, starting to look into the actual code a bit.
The implication being that the rest of your programming life can only ever be worse than Lisp. You will start out with unrealistically high expectations. I wouldn't worry too much, though. I refer you to Yegge's wonderful essay, [Lisp Is Not An Acceptable Lisp](http://steve-yegge.blogspot.com/2006/04/lisp-is-not-acceptable-lisp.html). I think this really hits the nail on the head. The *idea* of Lisp is never realized in any actual implementation. I suggest you learn Python rather than Lisp. Python is very similar to Lisp (in the sense of being a dynamically typed, introspective language with a powerful REPL), and its "batteries included" philosophy means that you can easily find powerful libraries for accomplishing just about any task you might wish.
Yes prefix takes a little getting used to but once you do you'll love it. It make everything consistent.
Thanks for the info!
Hm, thanks for the info... Right now, according to what I've read, I think a good toolbox of languages would be C, python, lua, Cg, and LISP. It will give me massive versatility, hackability.... and best of all C and Python play nice together, Lisp seems to be just about the most crazy shit ever, and lua and Cg will let me play with scripting for other stuff, as well as work with GPUs. 
That sounds like a reasonable plan. The choice of Lua or Cg depends on the type of programming you plan to do - it sounds like you might be interested in gaming. Personally, I would recommend Haskell ahead of Lisp as a vehicle for learning to be a better programmer. I think Python is close enough to Lisp that learning Lisp-proper won't buy you much. I actually wrote a huge edit to the above post. Unfortunately, Reddit seems to have hiccuped, and it got lost. Since I took the time to write it, I'll post it below... ----------------------------- Wow, after reading the responses in this forum, I really worry that you're being lead astray. Please realize that I like Lisp. It's a wonderfully fun language, and I highly recommend that you learn it eventually. That said, there are several problems with learning it as your first language. In no particular order: * Learning "Lisp" really means understanding the concept of Lisp. IMO, this is something that is hard to appreciate until you've got some experience under your belt. I suggest that you pick it up after your compilers class. * Supporting the above point - look at the Amazon.com reviews of [SICP](http://www.amazon.com/Structure-Interpretation-Computer-Programs-Engineering/dp/0262011530) - probably my favorite programming book of all time. It's highly skewed to 1's and 5's. Typically, beginners who pick it up hate it because it fails to answer the question "How do I use this language to accomplish X" for any real-world value of X. * Also note that in this forum alone I see 3 Lisps just casually mentioned - Common Lisp, Scheme, and Clojure - these are all quite different from each other. Just choosing a particular implementation and getting a development environment setup is not trivial. * Paul Graham once put Lisp at the [top of the "language power" spectrum](http://www.paulgraham.com/avg.html). However, IMO, Lisp is merely the "logical conclusion" of one particular family of languages (dynamically typed, introspective). There are myriad other paradigms out there - and personally I find Haskell to be more interesting and powerful than Lisp. * Also, Python is in the same family of languages as Lisp, is *almost* as powerful, is much cleaner and more consistent than Common Lisp, and is much easier to accomplish just about any real-world task owing to it's incredibly large set of libraries. Anyway, just wanted to give a different perspective. I don't wish to discourage you from learning Lisp, but I really do not think that it is a good first language.
use Python when you want to drive to the supermarket fast and buy a lot of stuff. use Lisp when you want understand how to build cars and supermarkets. 
Nonsense. I'm quite familiar with both language and I have no idea what you're talking about. Please provide a specific example. Anticipating your answer - about the only thing "missing" from Python is the macro system - is that all you mean?
Python doesn't even touch the 'idea of Lisp', so your advice sends people away from Lisp. If you think 'dynamically typed, introspective, REPL' is the essence of Lisp, then you missed the core: 'RECURSIVE FUNCTIONS OF SYMBOLIC EXPRESSIONS AND THEIR COMPUTATION BY MACHINE' - McCarthy, 1958. In 1962 Lisp got the first compiler of Lisp written in Lisp, the first ever self-hosting compiler. That way the computation with symbolic expressions has been applied to Lisp itself, treating Lisp programs as symbolic expressions. But it also has been applied to domains like computer algebra, logic language, planning languages, up to implementing things like the [App Inventor for Google Android](http://googland.blogspot.com/2009/08/g-under-hood-of-app-inventor-for.html). Quote: 'We parse the visual programming language into an S-expression intermediate language, which is a domain-specific language expressed as a set of Scheme macros, along with a Scheme runtime library'. Python is neither specially good as a functional language nor as a symbolic language. It shows. In Lisp a multitude of languages have been implemented, Python struggles already with its own implementation.
If you were familiar with Lisp, then you would know that it is not a language, but a family of languages.
&gt; I think he's asking for the details... I sometimes like to start paragraphs with sentences that outline the rest of the content to follow. &gt; Why is this a positive? Is it not possible or too difficult to replicate in CL? It's not possible to replicate. You can go far with macros (reader and ordinary) but you can't change the way Lisp is parsed, and it is parsed. No solutions to this problem will be both portable and transparent. &gt; I don't think that makes it "more functional." There is no dichotomy because it is a Lisp-1, like Scheme. This article is relevant. Thanks for the "help." I'm making a generalization. Clojure is more functional because attention has been paid to recent developments in functional programming. My examples are trivial but they're not the only examples. Clojure also has a reader macro for lambdas, a built-in function composition function, and other stuff. Common Lisp has four or five map variants. In practice, people use `loop` and `iterate` instead, which isn't the case in Clojure. I'm talking about pavement here, not theory. In theory, they're much more similar than they are in practice, because CL makes a lot of mundane FP techniques wordier and it has lots of Lispy or imperative alternatives that aren't. Clojure emphasizes FP to a much larger degree. &gt; Which common implementations don't have threads? When is STM a good idea? What about a bad idea? SBCL is notable, because thread support is experimental and off by default on several platforms. Most other Lisp implementations are either much less portable (Clozure) or have no threading support (ECL, CLisp). It's worth noting that threading isn't covered by the CL spec, so this is also one of those fun areas in which different Lisps expose slightly different APIs. STM is great if you like the way RDBMSes work and think in that way natively. It's not the best for performance if you have a lot of sharing. But Clojure also provides actors, atoms and parallel map/reduce type functions. CL doesn't have anything at these levels of abstraction, and they're very handy. You can also still use the Java threading APIs if you need something lower-level, and all of these features are implemented in terms of Java's threading, so you get "for reals" concurrency everywhere. The upshot is that you can get a concurrent performance improvement in Clojure extremely cheaply, without making large architectural changes to your program. &gt; What relational stuff? I'm talking about [clojure.set](http://richhickey.github.com/clojure/#clojure.set), which provides (among other things) `select`, `project` and `join` which provide you relational algebraic functions for treating sets of hashes as relations. This stuff is greatly handy, especially because the database drivers return data in the same structure, so you can essentially treat heterogenous data relationally regardless of the source.
I've read McCarthy's paper. To the limit of Dunning-Kruger, I believe I'm comfortable with the idea of a language that is able to parse its own symbolic representation. It's neat. But honestly, it never really struck me as all that profound (at least not more so than the idea that all Turing-complete languages can be embedded into one another). I'd be happy to learn if I've missed something. &gt; Python is neither specially good as a functional language and as a symbolic language I'm happy to grant both of these points. And yet in the real-world use of both Lisp and Python (that is to say, using the languages to actually accomplish something), I maintain my original position that they are very similar. I suppose I would change my position if we're talking about an exercise such as writing an interpreter, or attempting to embed a DSL, or some such. But these aren't the sorts of apps I find myself typically writing.
If you read above you would realize that I was aware of this. I'm very familiar with Common Lisp (I can breeze through On Lisp, and am halfway through Doug Hoyte's book), and know enough Scheme to get through SICP. Look the only reason I'm tolerating your condescension is in the hope that you can teach me something. So, again, please provide an example or else stop pretending that you have some mystical knowledge that eludes me.
SPIKE: Planner for the Hubble Space Telescope and other telescopes. Macsyma: Computer Algebra System. App Inventor for Android: compiler. [Symbolic Composer](http://www.symboliccomposer.com/): musical composition. [RacerPro](http://www.racer-systems.com/products/racerpro/): logic reasoning system. [CREWS](http://www.siscog.eu/subarea.asp?idSubArea=36&amp;idArea=2): Planning and Management of Staff. There are thousands of Lisp 'real world' applications in these areas. It seems that you are using Lisp way under its capabilities, if at all. That does not mean everybody else has to. 
I'm not here to teach you something. Reading books is nice. I find both books somehow interesting, both teach a lot of techniques and tricks, but there are more essential books. FYI, I had added a [list of books to the Wikipedia page on Common Lisp](http://en.wikipedia.org/wiki/Common_Lisp#Books). The more interesting books are: SICP (Structure and Interpretation of Computer Programs), PAIP (Paradigms of Artificial Intelligence Programming), AMOP (Art of the Meta-Object-Protocol), LiSP (Lisp in Small Pieces), PCL (Practical Common Lisp) and more... Hacking is even more important.
It is acceptable. It's very simple in its syntax and, if you use scheme (which I recommend), then there is very little to the core language. It has great tutorials and books (HTDP is great to start seriously starting reading that online now). I would say it teaches you *about* programming rather than practical programming. LISP is like looking at the parse tree (a kind of half way language between what we and the computers understand). Hence you get an idea of how programming language work. Python is easy and has good tutorials like lisp but you are likely to be programming useful things more quickly. C is now a low level language, learning it will teach you about how computer work bare bones. Again some good tutorials but not very simple. It all depends on what you want to know: how computer languages work generally (lisp), how computers work (C), how to make things quickly (python). And it's not to say the others can't teach you all that stuff it's just a different priority. ---- I think everyone should eventually know a bit of lisp, C, and haskell. But I would choose either "racket plt scheme lisp thingie" (and read HTDP then SICP) or python (the official tutorial then google's python class). Since they don't take that long try HTDP with lisp and the official python tutorial in python and see which one you prefer. 
seen this? http://labs.core.gen.tr/repos/core-server/src/rfc/3501.lisp
While lotu is correct on the image Lisp has let me point out that it is actually not hard to learn at all. IMHO it is easier to learn than any of the other languages you've mentioned. Although the parens can be annoying if your editor doesn't highlight the matching pairs (that would be only Notepad?). Common Lisp has my preference since it's a very practical Lisp designed not just for academic use or to satisfy someone's personal idea of purity but for use in the field. It does have numerous warts but they do not bother me. It's popularity has also picked up the last 5 years or so and there are solid libraries available and efforts are underway to make them easy to install. (Which isn't that hard anyway.) I suggest checking out the online version of Practical Common Lisp: http://www.gigamonkeys.com/book/ 
Yes, and [The Little Schemer](http://www.ccs.neu.edu/home/matthias/BTLS/) might be a great choice of literature.
The ruling paradigm, of C and Perl and Java, is that computer programming is a handicraft. A program is produced by a craftsman for whom the computer is a hand tool. Code created one character at a time, key-stroke by nimble-fingered key-stroke. {;;}{;;}{;;}... If you are old-school that opening paragraph will smell wrong. A program is loaded in binary by toggling the switches on the front panel of the CPU. It is a big relief when the machine boots and the monitor program comes to life on the VDU. Now a program is written by typing in hexadecimal (8B03 A70F ...) and a program is reading the keyboard, seeing an F, actually 01000110 and turning that into 1111, so in a limited sense a program is writing the program. Next job is to write an assembler in machine code. Then one can prepare a file that says ADDA #3, STA F,X, and have a program read it and write the program 8B03 A70F. Naturally one wants to move on to writing in a high level language and prepare a file that says a[15] += 3; and have the compiler write the program in the sense of turning that into assembler. Compiler, assembler, linker, all in a sense program writing programs. You can also look at this from a business perspective. The businessman signs some contracts committing him to provide a web service. Derived from that are requirement documents for the web service. From those derive requirements documents for the programs that provide the web services. Programmers write C to meet the requirements. The compiler writes assembler. The assembler writes machine code. If the contract is modified, changes cascade down. Computer programming is the last manual stage, lower level changes are automatic. The business perspective and the old-school perspective has this in common: the boundary between the automatic and the manual, which we call computer programming, is fluid and one expects the level of automation to rise over time. The ruling paradigm fixes and crystallises the boundary between manual and automatic. Programming is forever the task of typing the sacred runes {;;}. It is not a bad paradigm. It is hard to see how to create general purpose higher level languages. Sometimes one sees clearly enough that one should be notating the requirements of a particular domain in machine readable form and processing those files automatically. The ruling paradigm offers two ways forward. First one could write a program to write a file of characters containing a textual representation of a program. There is something slightly mad about this. The program writing program builds an internal data structure representing the program it is attempting to write. Then it walks the structure to serialise it as a flat file of characters. Next the compiler parses the flat file of characters to build an internal data structure representing the machine-made program, which it then compiles. The distinctive feature of Lisp is that defmacro is the sane version of this. Program writing programs in Lisp both consume and create tree-structured in-core data structures, not flat files of bytes. The second option within the ruling paradigm is to write an interpreter for the machine readable specification. Instead of writing a program that reads some instructions in a domain specific language and writes some code to carry out those instructions, one writes a program that reads some instructions in a domain specific language and carries them out. This is a powerful technique and it lets the ruling paradigm rule. Sadly though interpretation is not composable. You cannot write an interpreter in an intrepreted language and expect usable performance. There is a reason that an assembler transformers its source file into machine code rather than interpreting it and a compiler transforms its source files into assembler rather than intpreting them. If the "compiler" interpreted the input, while itself being written in assembler that was interpreted by an "assembler" the stack would be too damn slow. So it this second option that crystalises programming as an activity taking place at a particular level of organisation and automation. Part manual entry of code, part manual entry of next level up notation, part manual entry of code for interpretation of next level up notation. So far and no further. The dream of ever rising levels of automation is chained to a keyboard and dies of a broken heart. 
If you can handle SICP, Scheme would be a good first language. Common Lisp would be a close second. Python would be a third. I would stay away from Java. C is a good second or third language to learn (but not C++, especially if you've known Lisp).
Then, start with SICP. Only go back to lesser introductions if you find you can't cut it.
&gt; I'm not here to teach you something. Heh, I doubt whether you know anything that I don't. &gt; SICP (Structure and Interpretation of Computer Programs), PAIP (Paradigms of Artificial Intelligence Programming), AMOP (Art of the Meta-Object-Protocol), LiSP (Lisp in Small Pieces), PCL (Practical Common Lisp) I own them all and I've read them. Nothing in PCL, or SICP, and little in PAIP necessitates Lisp over Python. Python has it's own meta-object capabilities. Frankly, I think you're a religious nut, and are hardly worth my time. I'm only responding for sake of OP in case he mistake your extreme condescension as being "right", and thereby avoid learning Python.
&gt; It seems that you are using Lisp way under its capabilities You have no fucking clue about me. It's amazing to me that you seem incapable of grasping the fact that somebody could use Lisp just as well you as do, and yet be underwhelmed by the supposed "profundity". FYI, for my master's-level compilers course I wrote my syntactic analyzer in terms of an embedded pattern-matching engine (in fact, it was essentially [this](http://mitpress.mit.edu/sicp/full-text/book/book-Z-H-29.html#%_sec_4.4) code from SICP translated to Common Lisp). For this particular use, it was a pretty good solution (although, IMO, if I had to write it again I'd do it in Haskell). So once again, I'm happy to admit that I might not know everything, but I think that I've *really* used Lisp. The more you rant the more I suspect that you have nothing to offer. I'm only responding to your stupidity so that OP does not become discouraged from Python based on your attitude, or on the downvotes that I'm receiving.
Nice, but stil a shameless plug :)
You've translated some Scheme code to CL? Great!
I'm genuinely trying to understand what "essence of Lisp" I'm failing to grasp. I wrote my application in terms of an embedded pattern matching language. Based on my understanding, this is the very essence of Lisp. Would you argue that this is "using Lisp way under its capabilities"? &gt; You've translated some Scheme code to CL? Great! Sarcasm aside, it was an interesting exercise. The subtle differences in the various equality predicates was a real challenge to debug. This is yet another reason that I don't recommend Lisp to beginners.
Conrads remarks predated the order cancellation, which could easily have been the product of yet another delay or outright cancellation. It might be easy for you to figure out that the updated publishing dates were still valid, but I don't think that justifies dissing someone for asking the question.
awesome! where? 
&gt; The subtle differences in the various equality predicates Since you are unlikely to be talking about the differences between string=?, char=?, etc. Allow me to give you the 10 second Scheme Equality Lesson eqv? -&gt; is equal? -&gt; == eq? -&gt; pointer equality, ordinarily you want eqv?
:) Thanks. It's a few years too late, but would have been helpful.
uVic up in Canada!
Thank you. That was a really well thought out answer!
Wow, that was really explanatory... Thank you so much.
I graduated from this institution 11 years ago. No one taught Lisp when I was there. Just Java, C, C++, SQL and Assembler. Actually we used Emacs in some labs, so there was some undercover Lisp usage.
I have never understood the appeal of these. I have "The Seasoned Schemer," and I find the presentation rather sing-song, and that's distracting to me. Compare (pdfs are a Google away) the derivation of Z (applicative order Y) in F&amp;F's "Why Y Works" to Richard Gabriel's "The Why of Y" for example. I find RPG's writing far less of an obstruction to understanding. I am thankful that the authors of "How to Design Programs" didn't persist in the style of The &lt;foo&gt; Schemer books. I learned Scheme from SICP and on-the-job Bigloo hacking for a small ISP I co-founded.
I think it depends heavily on the reader. You sound as though you had a strong technical inclination/background when you started. SICP, while a _fantastic_ book, can be a lot for the casual, first-time learner.
I use both at work. I think that the GIL and lack of compilation can severely restrict Python uses. I'd also say that for me there are few applications where some form of a DSL doesn't pop up in the form of light-to-heavy-weight scripting/configuration/logic, offering a real competitive advantage. Both of these are heavily weighted by industry/application, obviously.
&gt; I think that the GIL and lack of compilation can severely restrict Python uses. I can see this. &gt; I'd also say that for me there are few applications where some form of a DSL doesn't pop up in the form of light-to-heavy-weight scripting/configuration/logic Sure, Lisp is easier to embed a DSL into. &gt; Both of these are heavily weighted by industry/application, obviously. Yes, completely agreed. I wouldn't typically recommend Lisp to a beginner, but it definitely depends on the type of work they plan to do. You know, despite receiving dozens of downvotes, this is the first response I've received that actually said something substantial. Thank you. I don't mind the downvotes - but if I'm wrong I'd like to at least know why. For all that Lispers like to consider themselves enlightened, I found this forum to be pretty pathetic.
I bet you have never used Lisp.
You're an amusing troll. If you go to the beginning of my comment history you'll see that I've posted a working Lisp application. Say what you will about my merits as a Lisp programmer, but I have used Lisp.
where?
Here, knock yourself out: http://www.reddit.com/r/science/comments/61y2e/paradox_in_game_theory_losing_strategy_that_wins/c02kxck 
These few lines are an 'application'? To me it looks like the code has been translated from Scheme. Doesn't look like ideomatic Common Lisp code.
&gt; These few lines are an 'application'? Look... &gt;&gt; I bet you have never used Lisp. Make up your mind. I owe you nothing, and yet I continue to torture myself in bemused hope that you actually have something of value to say. &gt; To me it looks like the code has been translated from Scheme. Doesn't look like ideomatic Common Lisp code. Yeah, I tend to write Lisp functionally. I would like to see a version of that app that you consider idiomatic CL.
go Marijn!
Will save you the trouble of unlearning all the bad habits of coming from a crappy language. Then again, whenever you are forced to program in a different programming language (most of them atleast) you will wish it was a lisp. But its definitely worth it. Go for it. 
One can get rid of much of the useless part of excessive FP coding. (defun random-value (min max) (+ min (random (1+ (- max min))))) (defun test-level (max prob val) (&lt;= val (floor (* max prob)))) (defun game-a (&amp;optional (max 101)) (test-level max 0.5 (random-value 1 max))) (defun game-b (earnings &amp;optional (a-max 11) (b-max 11)) (if (zerop (mod earnings 3)) (test-level a-max 0.1 (random-value 1 a-max)) (test-level b-max 0.75 (random-value 1 b-max)))) (defparameter *games* (vector :a :b)) (defun game (type earnings) (ecase type (:random (game (aref *games* (random (length *games*))) earnings)) (:alternate (game (aref (rotatef (aref *games* 0) (aref *games* 1)) 0) earnings)) (:a (game-a)) (:b (game-b earnings)))) (defun play-n-rounds (n starting-total bet &amp;optional (type :random)) (loop with earnings = 0 repeat n while (plusp (+ starting-total earnings)) do (incf earnings (if (game type earnings) bet (- bet))) finally (return (+ starting-total earnings)))) 
Which dependency tried to compile with the -m32 flag?
I don't recall by memory but I want to say babel. I think trivial-babel was compiled, then babel was tried and the error came when it called gcc with -m32 and -fPIC flag (among others), I got the error on -m32 and aborted since I didn't want to continue with an almost-functional library. I am not **totally** sure that it was babel, but I will double check when I get home. EDIT: On second thought, it might have been CFFI (cl-mongo is using cffi-grovel I think) EDIT2: I found [this](http://paste.lisp.org/display/49455) by googling "Common Lisp CFFI gcc -m32"
In my experience there aren't that many Common Lisp libraries that depend on C code which seems to cause your problem with one CL library. And in those cases, you'll probably encounter the same problem in Scheme too. I think your choice of Lisp dialect should really depend on what you're actually trying to do: Are there (good) libraries for what you're doing? How well do the languages built-in features and the implementation support your task?
It would help if you mentioned which platform you're running on. I've found various Lisps / Schemes to be fairly easy to install on OS X and on the various Linux distros I've used (Gentoo/Ubuntu/Fedora/Arch). I say it all depends on what kind of program you want to write. If you need GUI stuff, good luck. Otherwise, if you need sockets or SQL or image manipulation, make sure your environment has a good libraries for that. You can't really go wrong with CL or with Scheme. The arguments between the two are numerous and out there. Personally, I'm a little excited about Scheme at the moment because the (relatively new) R6RS is so nice. You are unlikely to make a "big mistake" and yes, you can do useful and productive things in Scheme.
Sorry, I am only running MIPSel platforms. One with Debial MIPSel port and one with gNewSense metad. Loongson-processor to be specific. So there is no possibility for writing GUI-apps? I am not having anything special in mind to program, but I would like to know what I can and cannot do. 
I am not really "doing" anything yet. I want to learn the basics first but I like to know what options I have for further development. The only thing I have been wanting to make is an free software retail POS system, but that is pretty far away. Now I just want to get the basics.
It is possible to write GUI apps, but none of the open source libraries for CL are very mature. And in Scheme land, GUI libraries are a very implementation-specific thing. The GUI library of Racket seems to be one of the finer choices.
I don't think you'll find many CL authors who have tested their software on that platform. If you want to improve the situation, a good bug report goes a long way.
If you're on a Mac you should try Clozure (with a Z) Common Lisp. 
For getting the basics, I wouldn't worry too much about the dialect choice. In my experience, CL and Scheme are similar enough that switching between them is not too hard.
Hmm, I have seen a little bit of Racket, but it somehow reminds me alot about Python (the concept, not the language). I have found [this](http://common-lisp.net/project/cells-gtk/screenshots.html) while googling for CL GUIs and it looks promising, however, there have not been any "news" on their website since 2007 so I am guessing that development has ended or slowed down.
Sorry, I'm all Linux :)
Why does Racket remind you of Python? Is it just that it has lots of useful libraries?
Maybe you should think first *what* you want to produce, rather than trying to optimize for some nebulous platonic situation. Otherwise, yours looks like a slightly obfuscated version of the "what is the best programming language?" question.
It took me a couple of seconds to realize you guys were talking about PLT suite. Why did they have to to and make such a silly name change?
If you're on OS X, you should also check out [Clozure](http://trac.clozure.com/ccl), not that SBCL isn't a fine choice. But Clozure has a functional Objective-C bridge that let's you write native applications on OS X. Both have a vastly superior debugging environment running under [SLIME](http://common-lisp.net/project/slime/) in emacs. Chicken debugging is unfortunately not much fun in comparison. That aside, Chicken's egg repository is a treasure trove and it's trivial to install and use them. The same cannot be said for ASDF[-INSTALL]. Depending on what Lisp libraries you're trying to install, you can easily end up in a mire of abandoned software. And while Cliki makes it appear like there's a lot of choice, I find that choice somewhat misleading: there's often 13 different libraries to wade through but only one or two that are still being maintained, if you're lucky. It takes a lot of time to vet the dependencies. On the other hand, I've found the quality of Chicken eggs to be much higher on average. This is not meant in any way to disparage any of the Lisp libraries, it's just that so many of them are no longer being actively developed and since so much of what we write these days depends on evolving Internet standards, having stale libraries is a real impediment. Chicken is a labor of love and it shows. It's also embeddable in C which is just insanely useful if you ever were to need it. There are significantly worse things in life than working your way through [The Little Schemer](http://www.amazon.com/Little-Schemer-Daniel-P-Friedman/dp/0262560992) or [SICP](http://mitpress.mit.edu/sicp/). Stick with Scheme though if you're going to be doing either. While the exercises can be expressed in Lisp, they're no fun to write in Lisp for reasons that are beyond the scope of a reddit comment. Once you know either you can switch back and forth fairly easily, though porting code between them, not so much. 
Well, could you try whatever it is that you tried again, and paste the whole resulting buffer somewhere? That should include information about which library was being compiled. It could be CFFI, but it's not babel, which doesn't mention CFFI, UFFI, `.c` source files, or `-m32`.
They were tired of people expecting them to toe the Scheme line. They like doing experiments in language design and are very concerned with providing a practical basis rather than a minimal one and they felt a name change would help align people's expectations better.
Look at it in terms of choosing Common Lisp versus _some implementation_ of Scheme. Portability between CLs isn't a given, but it's much simpler than with Scheme. R6RS should help with that, but there are very few implementations that even intend to give R6RS lip service. I know one guy personally who does all his programming in Racket and he's been doing it for years. I know another guy who does everything in Allegro. I think if you're worried about small embedded systems Scheme might be a sounder choice, but I would be surprised if you couldn't (with some heavy lifting) make CL do what you need. It's going to come down to personal preference and either is a good choice. With Scheme, it's much more like creating your own language from scratch. If that or call/cc sounds better to you than having CLOS, the condition system, loop and whatnot, then Scheme is the winner. If you're worried about wanting or needing those features, CL is probably the winner.
I used to use Gauche &amp; Scheme48 quite extensively as well (but STKlos &amp; Gambit too), for my programming needs (besides C). Now I use a custom dialect that I just port everywhere I end up. It really only matters what you need (I have a decent networking, image/graphing &amp; GUI libraries, which is all I need). &gt; If that or call/cc sounds better to you than having CLOS, the &gt; condition system, loop and whatnot, then Scheme is the winner. If &gt; you're worried about wanting or needing those features, CL is &gt; probably the winner. I don't think you're correct on this point. There are continuation libraries for CL that implement call-with-current-continuation, and there are quite a few CLOS-like object systems for Scheme (STKlos &amp; RScheme have them built in). It's really all about choosing the Scheme system that best suites your needs, which can range from bare-bones (such as tinyscheme, nmh's enhanced minischeme or S7) all the way up to full suites (Jazz, Racket, &amp; whatnot). Basically, there's much more to choosing a lisp system than the basics mentioned here, especially if the various scheme systems enter the fray. I normally break it down thusly: * If you're looking for a language with good portability across implementations, enterprise support, mature code bases, standardized best practices for optimization across the language and lots of smart people working on it, choose CL. * If you're looking for a language with decent portability across implementations, standardized best practices across implementations (not the language as a whole), that has lots of smart people working on it, and are *willing to put in the time hunting down the correct implementation for the task at hand*, choose Scheme.
[Clozure CL](http://www.clozure.com/clozurecl.html) actually supports Linux, FreeBSD, Solaris, Windows and OS X these days
&gt; the dependency hell (JAR hell?) and all the mess with classpath and leiningen just contributing to making a mess messier Exactly my experience. Clojure follows the Java way of solving problems: just throw in a couple hundred megabytes of some more jars; chances are your problem will look less relevant!
I am not sure. I am trying to compile Racket for my platform now and will check it out. Seem to be some issues with glibc, though.
Oh interesting, thanks for sharing. I especially like the game function - I see how you are able to cut down several lines by using it to select games. &gt; One can get rid of much of the useless part of excessive FP coding. My implementation was bloated, no doubt. I don't think this is necessarily an indictment of FP in general though. I assume you're referring to the excessive use of closures as well as the "iter" idiom (straight out of SICP) as opposed to a more CL-like the loop-macro. You certainly demonstrated the effectiveness of idiomatic CL. Are there any other points you dislike about the FP approach? I'd like to comment on a few constructs that I find interesting: &gt; (zerop ... ) Do you really find this easier than (= 0 ... )? &gt; (aref (rotatef (aref *games* 0) (aref *games* 1)) 0) I guess I can't knock what works, but I find this very ugly. You never know what state your vector is in when entering the game function. You're relying on a somewhat gnarly invariant - that the order of the elements in the vector doesn't matter for :random, and that you can always rely on subsequent calls with :alternate to be back-to-back - this would make me uncomfortable in a larger application. &gt; (+ starting-total earnings) I realize that I tend to be particular (to the annoyance of my coworkers I assure you), but this would also make me nervous in a larger application. You're repeating the same statement, which contains a value that is mutated within your loop-expression, and I think the only reason that this is safe is because the value doesn't get modified again once the initial condition fails - a fact which cannot be known by any means except by familiarity with loop-macro semantics. Without trying to derail the conversation too much, the difficulty of intuiting macro semantics is one of the reasons I don't use them often. I view them as the "goto of DSLs" - a discontinuity point when attempting to understand an application, and a potential cause of extremely tough to find bugs. I find that there are other constructs, such as Haskell's monads, which provide some of the power of macros in a much more controlled and understandable manner.
&gt; , but there are very few implementations that even intend to give R6RS lip service. What you forgot to mention is that in Schemeland this transforms into [8 implementations](http://gist.github.com/341044), which isn't too bad.
AFAIK all the development on cells-gtk now happens on the fork at http://github.com/Ramarren/cells-gtk3 . It's the only version of it I could successfully compile with current releases of SBCL.
Of which maybe four are likely to be around in a year.
Your code generates new closures for each round of the game. Functions are generated and then called, instead just be called. There is no need to return functions all the time, with the possibility that closures need to be created over and over. DEFUN is a top-level macro. So it is best used at top-level. Using it to create closures inside a LET works, but is not really good style. Also your CTR variable gets shared by all functions created via ALTERNATE-GAME. Additionally CTR is constantly counted up and there is the possibility that it will change into a bignum some time, which then creates a lot of garbage calculating with bignums. ALTERNATE-GAME only needs to oscillate between two states. Stuff like PAPPLY make arglists unusable in larger programs during debugging. Anonymous functions often sit on the stack and have no name, so a stack trace gets harder to read. If there is a FUNCALL, there is a code smell that a code indirection can be removed: calling a function directly instead of getting a function passed from somewhere and call it then. CL code usually prefers normal iteration forms over tail recursion (since the latter is not portable and implementations have various ideas how to inform the compiler that TCO should be performed). On zerop, yes I find it easier to read because it is a word that I can recognize - that's easier than a form I have to visually parse and find the 0 and the other arguments. On (+ starting-total earnings). I wrote that only to have slightly shorter code in the example. Usually I would write something like this (if I'd use LOOP): (defun play-n-rounds (n starting-total bet &amp;optional (type :random)) (loop with earnings = 0 and total = starting-total repeat n while (plusp total) do (incf earnings (if (game type earnings) bet (- bet))) do (setf total (+ starting-total earnings)) finally (return total))) or (defun play-n-rounds (n starting-total bet &amp;optional (type :random)) (loop with earnings = 0 and total = starting-total repeat n while (plusp total) do (let ((result (if (game type earnings) bet (- bet)))) (incf earnings result) (incf total result)) finally (return total))) On (aref (rotatef (aref games 0) (aref games 1)) 0). For larger code, I would implement independent game selection routines that use their own data structures - also leave the underlying data unchanged for :random. I would then have code like this: (defun random-value (min max) (+ min (random (1+ (- max min))))) (defun test-level (max prob val) (&lt;= val (floor (* max prob)))) (defun game-a (&amp;optional (max 101)) (test-level max 0.5 (random-value 1 max))) (defun game-b (earnings &amp;optional (a-max 11) (b-max 11)) (if (zerop (mod earnings 3)) (test-level a-max 0.1 (random-value 1 a-max)) (test-level b-max 0.75 (random-value 1 b-max)))) (defclass random-games () ((items :initarg :items))) (defmethod next ((r random-games)) (with-slots (items) r (aref items (random (length items))))) (defclass alternate-games () ((pos :initarg :pos) (items :initarg :items))) (defmethod next ((a alternate-games)) (with-slots (pos items) a (setf pos (mod (1+ pos) (length items))) (aref items pos))) (defparameter *random-games* (make-instance 'random-games :items (vector :a :b))) (defparameter *alternate-games* (make-instance 'alternate-games :pos 0 :items (vector :a :b))) (defun game (type earnings) (ecase type (:random (game (next *random-games*) earnings)) (:alternate (game (next *alternate-games*) earnings)) (:a (game-a)) (:b (game-b earnings)))) (defun play-n-rounds (n starting-total bet &amp;optional (type :random)) (loop with earnings = 0 and total = starting-total repeat n while (plusp total) do (let ((result (if (game type earnings) bet (- bet)))) (incf earnings result) (incf total result)) finally (return total))) From there I would remove the global state and create classes to hold game state. 
You will have really missed something if you don't give clojure a fair chance. Use leiningen to overcome the class-path hell if that is your only problem. People on #clojure are really great and will definitely help you out if you have problems with leningen. Btw, I am a java (the language and not the jvm) hater too, but clojure is worth the trouble.
Well, they all made it past the 1 year mark :) Although I don't think IronScheme or Ypsilon are being actively maintained
I am starting to agree. I false started with clojure a few times (run off by the jvm/jar/etc cluster fuck) but after the wrestling match with the java under it clojure is quickly winning me over. 
My problem is mainly that there are different pieces lying around, and the only "centralized" form for packaging is clojure-contrib. That's the easiest way to use third party libraries. When I tried to learn Clojure there was lots of possibilities for other libraries available in leiningen that I could use to simplify the creation of my application. However, to make it easier for an end-user to use my app, they wouldn't need anything else than just clojure and clojure-contrib. Maybe it is just my computer that is messed up, but when I started to get different errors (famous java errors in 30 lines+) for running "lein help" it all came to an end. Sure, you can argue that the language in itself isn't the big bad guy and that I am putting the blame around third party applications. However, the community has come to an unwritten understanding that distrobution of libraries should be done unofficially via leiningen, and to keep track of errors in internal code of the libraries, eventual code that leiningen will produce and errors from own code makes it a great challange to debug. I wrote my test-app in Clojure during my summer vacation (I am a hobbyist, obviously), and I problably spent more time debugging the abstract java errors than learn the programming language. EDIT: My point is just that I think I have given Clojure a fair chance :)
I don't know if I can get the whole output of the SBCL REPL, but I can problably copy as much text surrounding the error as possible.
Thanks, I took that into consideration and decided I problably would want some GUI functionality in the future and Racket has that implemented by default. So I am trying to compile Racket for my platform now.
Seems like Racket would be my best option, as far as I can see. Racket website recommends "How to Design Programs" - which is tempting to buy to begin "from scratch", but I think I have a somewhat good understanding of Lisp "genetics" now that SICP or "The Scheme Programming Language" might be better. Not on OS X, btw.
I guess my threshold for java a.k.a *pain* is higher ;)
&gt; Your code generates new closures for each round of the game...There is no need to return functions all the time, &gt; DEFUN is a top-level macro. So it is best used at top-level. Using it to create closures inside a LET works, but is not really good style.... &gt; Additionally CTR is constantly counted up and there is the possibility that it will change into a bignum some time &gt; Stuff like PAPPLY make arglists unusable in larger programs during debugging. Anonymous functions often sit on the stack and have no name, so a stack trace gets harder to read. &gt; If there is a FUNCALL, there is a code smell that a code indirection can be removed &gt; CL code usually prefers normal iteration forms over tail recursion (since the latter is not portable Good stuff. What you say makes sense. I will keep it in mind. &gt; (:random (game (next *random-games*) earnings)) &gt; (:alternate (game (next *alternate-games*) earnings)) Pretty clever, I like that. I agree that this is semantically much cleaner, it also allows you to easily add a new game selection algorithm. This easily addresses my concerns. In all, I appreciate the time you took responding. I've certainly learned a few things. I think we got off to a rocky start, but I'm pleased with the conclusion.
Do you mean 'generics', as in how CLOS dispatch works? Are you Linux or Windows? Anyways, the nice thing about Scheme is you're free to choose from any of several inheritance models. I like prototype inheritance like the 'prometheus' egg gives you in Chicken, though it can be a lose on the performance front. I suspect PLT offers similar choices. It doesn't really matter which Scheme you choose; clearly Chicken and PLT are among the most fully-featured, as is MIT/GNU Scheme, though with MIT, you get what you get and that's about it. I have no experience with Scheme on other platforms. Lots of people like PLT, it's just not my choice on OS X. And SICP is also not for everyone. If you're not mathematically inclined or you're not of the mindset to want to write a compiler, you're probably not going to enjoy it. But don't let that stop you from learning Scheme/Lisp. Anyone who writes software will benefit from learning either, whether you use HtDP or "Teach Yourself Scheme in Fixnum Days" or whatever. For that matter, if you're at all musically inclined, [impromptu](http://impromptu.moso.com.au/index.html) is a fascinating Scheme (it's an audio unit host), though it's unfortunately only for OS X.
Hi! I am using a loongson myself and there are quite some lisps / schemes that work. [Chicken Scheme](http://www.call-cc.org) for example or [pico lisp](http://www.picolisp.org) work out of the box. Both do come with GUI capabilities. Chicken has a variety of UI extensions (called eggs). Picolisp resorts to HTML / Java mostly. Depending on what you are looking for, this may be what you want. HTH, ckeen 
If you need features that can be found in libraries and you do not want to write it yourself, you need those libraries. And as libraries work in a certain context, so there are dependencies. Think about it -- those libraries are supposed to save your time, so even if you need to spend some time dealing with them, that is still an overall win. If you don't see libraries saving your time then don't use them. SBCL comes with bundle of extension features and libraries, so if you want to stay minimalistic, you can stick to what is bundled in SBCL and so you won't need to deal with dependencies at all. How is that worse than minimalistic Scheme? It's like you're saying that _having an option_ makes CL worse. If you need more libraries than are bundled with SBCL, there are other options which can deal with dependencies for you -- [clbuild](http://common-lisp.net/project/clbuild/) script, [libcl](http://libcl.com/) bundle...
Hey, I'm not going to argue with you on that ;)
Ypsilon will be (at least acording to it's web site) whereas Ikarus' author seems to have disappeared from the face of earth.
That's six years old. Nothing happened.
I have played around with ASDF/ASDF-INSTALL and are very impressed! As I have written some other place, the only error I have ever recieved was because it tried to compile a C file with the -m32 flag which gave a gcc error.
No, with "genetics" I meant the common syntax in Lisp, how it is structured, not the language itself. Sorry for the bad expression! I am not really that good in mathematics and prefer to avoid the more complex concepts as far as I can. I purchased a used copy of HtDP (I prefer it in book form) just to start from scratch even though I am not sure I need it. I have successfully built Racket on my platform now, took a hell of a lot of time so I am going to go through it's documentation and HtDP when it arrives :)
What distro are you using? On Debian I am able to get alot of different lisps/schemes via repo, but on gNewSense (for the YeeLoong) there are much less. Chicken was the scheme I was initially thinking of, but after doing some research on Racket, it seemd fairly sweet!
Pity, would be fun to try out.
I have built these myself in gNewSense.
Hmm, chicken is already in repo I believe, not sure about pico.
Ypsilon hasn't been updated in sometime, and Ikarus isn't much better (there was a 0.0.4 candidate somewhere iirc); [Mosh](http://code.google.com/p/mosh-scheme/) seems to be doing well though. I'm not holding my breath for any of R6RS; hopefully R7RS will be better, though I think the two working group approach might lead to an even larger divide. Only time will tell really.
Yeah, there's a reason for that. Linux running CMUCL as its init process is not "a new Lisp Machine", it's a Linux machine running Lisp as its init process. The OS is still written in C. The device drivers are still written in C. The process model is still a C process model. Kernel code cannot be written in Lisp. The Kernel data structures are not garbage collected. In fact, the only difference between Linux running Lisp as its init process and Linux running Lisp as a regular process with root privileges is that you don't have your file systems mounted and network services started. And the point would be...? 
Maybe something like the old [Schemix](http://abstractnonsense.com/schemix/) stuff? That would be an interesting thing to revive, and use for device development. Of course, Movitz or Dream might be worth the effort as well.
Probably not, but don't despair. It is tiny and self contained, so it will not interfere with system packets
Mosh works well except for some glaring problems. It choked on code that I commented out which made me question my own sanity. Apparently the parser is broken.
Now *THAT* is cool.
I am working on a C parser. Seems to be working, on my projects' files at least.(No macros yet, which might be more difficult.) The idea is that i will 'bijection test' it by also making a writer. (Generally writers are much easier than parsers) It is very neat to have bijections, but we've got to think about how to get them to new users. Asdf is where the files often enter the lisp implementation, hence, people should be able to make extensions to it that read files. Which type of file is should defaultly be inferred from the file-extension. Does asdf have a variant of the simple cl:load? It should, many people use files with a bunch of LOADs in it initially. (Unfortunate that asdf currently imagines ".lisp" at the end of filenames.) If we have a bunch of them, we could make a set, or ship them along with the implementation/asdf. Having these bijections could be neat in other ways too: * Code scanning/autodocumentation via it. (What my C parser outputs should already work with my scanner, if given base-macros and such via the special vars.) * Extending the language. Actually, in C it seems that some things would become less clear to the user. * The language issue is getting it but with this we can just sidestep the whole language issue and point out that CL can actually play &lt;enter language&gt;.
Wow, that's pretty bad; I've not used anything other than simple tests with Ypsilon, and I don't even have a R6RS-based scheme system on any computer I currently own. I'm not sure how much more adoption there will be anyway, considering that R7RS is in the works. When did you have that problem though? Was it with this latest release of mosh?
That's what I thought; very cool indeed. I tested it out with some device stuff I was looking at (and I looked into porting it to NetBSD at that time), but I've not touched it for quite a while. It *would* be interesting to bring it back up to date &amp; use as a LispM, in a similar manner to FreeVMS (i.e. Bliss atop Linux for FreeVMS, Scheme/CL atop Linux for a new LispM). It would be easier to keep that up to date than a movitz or a dream, but it wouldn't have the "turtles all the way down" idea. It's a trade off, but it still might be an interesting project.
It was the at the time current release 0.2.4. Apart from that it ran pretty fine and wasn't even the slowest Scheme (the slowest was PLT).
ah, 0.3.0 does have numerous fixes, which hopefully would help. I'm surprised about PLT though; Do you mean among R6RS systems? Because, there are several that are much slower amongst the R5RS set. Also, do you remember the exact issue? Not that it matters much, I'm simply curious. I don't use R6RS at all really (as I mentioned earlier), but I'm curious to see what issues these new-ish systems have.
Going with the martial arts analogy, the author is just a tenth kyu at Haskell who thinks that his first dan rank in Lisp allows him some privileged knowledge of Haskell. 1. Haskell's type system is an amazing tool to those who master it, it allows programmers to eliminate boilerplate code that they'd have to use in other languages. It's a tool similar in power to Lisp's macros. 2. It's easy to create modules with undefined or partially defined functions. Use the "undefined" object, it's in the standard prelude (e.g., define a function x as "f x = undefined"). Using "error" is also a common way to achieve this. 3. Yes, it does hog brain resources at first. But so does playing the piano. As you practice, less of your brain lights up on the MRI — your brain becomes more efficient at that particular task. 4. Haskell appears inflexible if you haven't achieved basic mastery, which admittedly is not quick. If you get the urge to write a blog post about monads, it's a sure bet you're not anywhere near basic mastery yet. 5. Hugs hasn't been updated since 2006. If you "had to write ... code in notepad" then you weren't looking very hard for alternatives. 6. Haskell has reflective abilities, but they have to be requested explicitly. The type system is your friend, while new programmers do complain about how hard it is to get Haskell code to compile, you'll find (as many do) that the code that does compile is usually correct. Think about it alternatively: Haskell takes 90% of the runtime errors you'll encounter in Lisp and turns them into compile time errors. On the "do" versus "ryu"... I don't think Haskell is as pragmatic as the author makes out. From the analogy, divine inspiration gave McCarthy the idea for a language based on functions and s-expressions... and the divine inspiration for Haskell is purity and the type system. If you want "do" like languages then think of F#, Python, C#, or the others that mix and match borrowed techniques. Complaining about Haskell's type system and enforced purity is like complaining about Lisp's parentheses... it's a sign you don't understand the language. They're both revelatory languages: basic mastery in either one will change how you think about programming forever.
I agree, but: 1. This blog post is from 2008 (concerning point #5) 2. If someone prefers Lisp, let them have Lisp. I think his analysis of Haskell manages to be both shallow and wrong, but Lisp is a fine tool and if it works better for his brain, let him have it.
I agree with that point. I love Lisp &amp; Haskell too, but I like to take the time to respond to complaints about Haskell. (And I wouldn't generally use an environment that hasn't been touched in the past two years.)
That's reasonable.
Yep, I used R6RS systems on my code (ranging from Ikarus on i386 as it does not support amd64, including Ypsilon, Mosh and PLT, excluding Larceny which resisted building). In case you are curious [here's the code](http://xivilization.net/flyserver/tex/hellprog/src/n-queen.scm), along with the [dependencies](http://xivilization.net/flyserver/tex/hellprog/src/schelog.scm) and a [README](http://xivilization.net/flyserver/tex/hellprog/src/README). I commented out ``(main 4)`` on Mosh and it failed horribly while parsing just fine on every other system.
Make sure to check out clbuild as well. I prefer that over asdf; you might too.
Learn Scheme and Python. 
My version of this post would have been: In Lisp *I* find *I* get things done quickly and *I* can change *my* ideas about how a program will work as *I* go along; without being punished. Haskell is really pretty but *I'd* rather use lisp.
I'd like to hear what he has to say now, after he has been using haskell (or not) for some longer period of time.
In the next post he said he was stopping his haskell experiment for good.
I went to his new blog and there's no real talk of Haskell. He seems to be using Clojure though.
I am enjoying looking at the asm emitter in movitz. I ported something similar from smalltalk to ruby in order to have a pure-ruby machine-code emitter. Squeak is another project that has done bare metal ports and might be another place to look. Different language, of course, but their implementation was very sound (and small).
Could, say, Movitz ble written in Scheme? Or Racket (PLT Scheme)? Is it possible to go that low level in Scheme as Movitz is currently doing with CL.
Let's not overestimate how far along Movitz is. Yes. Hardware people I know who use either prefer Scheme. [Bigloo](http://www-sop.inria.fr/mimosa/fp/Bigloo/) has low-level use as an explicit goal; [Chicken](http://www.call-with-current-continuation.org/) is also a very C-friendly Scheme, and [Ypsilon](http://code.google.com/p/ypsilon/) is targetted at embedded game development (the author's company uses it for their pinball machines). So yes, it is feasible, but I'm not sure I'd say Racket is a good implementation choice for it though.
Okay, I am just wondering theoretically. I am not overestimating Movitz, but it is the only Lisp software I know of that is on hardware-level.
Do you notice any difference going between the different Scheme implementations?
There isn't a huge amount of Common Lisp on the hardware level, but there's a fair amount of Lisp-family stuff and similar. I would totally try Bigloo though.
Well, Smalltalk *is* influenced by Lisp (and Simula, logo, Sketchpad), so it's not surprising that there is a sound &amp; small implementation near bare metal. Did you post your code anywhere? I've been thinking about doing something similar using a PreScheme-like language; write a minimal runtime for a microkernel, which can load the minimal pieces needed for each language thread. The GC could be shared across all threads or per-thread. I've a microkernel, but I've not finished the compiler yet (it's on my list of things to do; I'll also use this compiler to bootstrap my Scheme dialect as well, ala Scheme48). I'd like something small &amp; useable, like RiscOS or Btron.
Very odd; I'll have to build the latest mosh today &amp; try it out. I do get the feeling that R6RS is quite a bit more work than the previous revisions were to implement (I have a decent subset of R5RS and other features I liked blended in, and still the syntax &amp; semantics could fit on only a few pages). I guess it's not *totally* out of character for Scheme systems to lay dormant (or seemingly dormant) for some time &amp; then to have a new release come; Scheme48 releases about once a year, for instance. I'll try this code today though, just to see what the latest mosh does.
I'd say Common Lisp is more pragmatic and Haskell is more conceptual. Even McCarthy's LISP was just a simple and pragmatic interpreter remotely based on lambda calculus -- it looks like McCarthy did not want to waste time on doing it according to the theory and just made a simpliest way which worked. There is nothing divine in there -- McCarthy wanted to abandon original syntax and later he've switched away from Lisp.
&gt; I do get the feeling that R6RS is quite a bit more work than the previous revisions were to implement That might be well the case, but except for the SRFI issue with Ikarus, they were more compatible than I have hoped. I basically just ported Schelog to R6RS and ran it, without further trouble. &gt; I'll try this code today though, just to see what the latest mosh does. Cool, thanks :)
&gt; That might be well the case, but except for the SRFI issue with Ikarus, &gt; they were more compatible than I have hoped. I basically just ported &gt; Schelog to R6RS and ran it, without further trouble. Yes, as schemers this is our promised land; unfortunately R6RS isn't terribly popular amongst implementers.
Correct pronoun usage would obviate many opinions people express.
Um, ok, I tried the code with 0.2.5-1 (0.3.0 is the MonaOS base version, sorry about that). I get a weird error with: ;(benchmark) Which raises an error (unbound name: nchmark), which is an odd parse error methinks. If I remove that line, it runs fine &amp; returns exactly what you would expect. Interesting; did you ever raise this point with the mosh devs? They might be interested.
Mostly in terms of libraries, community and subtle language design decisions not covered by the scheme standard. Also almost every scheme implementation comes with their own set of extensions to said standard.
&gt; Interesting; did you ever raise this point with the mosh devs? Nope, I was (and still am) quite busy with university stuff, I assumed that this was a known error ;)
[announcement](http://common-lisp.net/pipermail/parenscript-devel/2010-July/000834.html)
Ah, no worries. There's always some *more* work :D
Why had I never heard of parenscript before? I need a project to try this out on.
Oddly enough I'd asked about a lambdabot on #lisp and was told no one'd been able to sandbox Common Lisp effectively either.
What's the language-level holdup? Let's make it easier and have a designed-for-sandboxing common lisp engine just for this argument.
Hey cool, I built this! Please take a look at the source code on GitHub: http://github.com/fitzgen/tryparenscript.com I would love to get some feedback. As I said on the mailing list, there are still 2 big issues, one of which I expect to fix soon. 1. No macros. Don;t want to let just anyone run arbitrary code on my server during macro expoansion. 2. `defun` isn't being evaluated as function declarations, its being transformed in to Named Function Expressions, which I expect I will be able to fix later today when I get off work. **UPDATE**: So Squirrel_of_doom found a pretty serious security bug. Until I can get home, I can't take the time to fix it, so till then the site will be down.
Check your inbox please.
There is no language level holdup. Either you need to do some OS level trickery to run the process with very few permissions, and just assume that it will destroy anything you let it near, or you need to create a modified reader, and a smart code walker that only allows a subset of the language to be executed. 
You might want to look at ruby's $SAFE and taint. That and the work _why did to ruby to help solidify sandboxing for "try ruby". Good stuff there.
and I suspect that was based on experience from Perl's tainting mechanisms. By my memory of Rich Hickey's presentation at the Boston Lisp meeting, this was a motivating example for Clojure's ability to add metadata to any value. Mark incoming data as tainted, define transforms that untaint known safe operations, and disallow evaluation of tainted forms.
Yeah, the tainting was... I think ruby's $SAFE is a bit orthogonal to tainting and a good addendum. It quickly lets you setup some unsecured operations (for setup) and then ratchet down for secured operations.
could you let us/me know what the security bug was once you fixed it? just curious
The language and the run-time (I actually like the JVM; some don't) is nice, but my impression of the general development environment; "Clojure as a whole"; is not so good. Where is my M-.? Where is the stacktrace which jumps to file and code location as I navigate it? Where is the method browser? Is there tab-completion? This stuff is _very_ important to me; I want to do some somewhat "real" development of non-trivial stuff using Lisp. These things lacking is based on my experience testing clojure quite a while back; has things improved?
Ok the site is back up again. The security hole was that I accidentally allowed anyone to use the #. reader macro to execute arbitrary code on the server because ParenScript still uses the CL reader, and I didn't scrub for #. or set *read-eval* to nil. Thanks a lot, Squirrel_of_doom, for letting me know about this issue privately!
Can you or someone list all the things you need to do to sandbox CL?
I'd probably have more fun with it if (print 'x) didn't open the firefox print dialog. format, write-line and princ are undefined, too. Is there any way to generate string output? Also, it echoed strings back at me, but hung when asked to eval a number.
ECL, Embeddable Common Lisp. LispWorks was used in embedded systems.
First thanks to everybody for reading my posts. Currently I'm using regularly common lisp, java, c#,c/c++ and SQL. I bought Programming Clojure &amp; Practical Clojure and went through them. I would have bought both Clojure in action and Joy of Clojure if Manning accepted credit card payment from Macedonia. I'm little tired of everything Java related, that includes Clojure, so I'm using my spare time to learn OpenCL. Regarding Haskell. I haven't programmed in it since I wrote the post farewell haskell. The reason for that is my programming style for which Haskell is ill suited which described in the farewell haskell post in the paragraph starting with: It may interest you to know that most of my development .. http://tourdelisp.blogspot.com/2008/03/farewell-haskell.html I don't hate Haskell but its not in list my favorite language either() though as one favoring functional style I cheer news like this http://bit.ly/djs4J5. Also I prefer to say what I'm thinking and be rude if necessary then hide my message between being politically correct watered down politician talk. On the other hand I have high opinion about SPJ and enjoy his talks http://bit.ly/4BG5Dp and many of his papers. In the end language wars are pointless, use the language that suits yourself and have a marry hacking. () For those interested my favorite languages those are lisp dialects (cl,scheme and clojure), array languages (j &amp; q), Prolog, Erlang and concatenative languages (Factor, Cat &amp; Joy)
 &lt;h1&gt;This type of response MUST NOT have a body.&lt;/h1&gt;&lt;pre&gt;Error: This type of response MUST NOT have a body. at ServerResponse.write (http:432:11) at ServerResponse.end (http:511:16) at /var/nodejs/tryparenscript.com/server.js:66:106 at /var/nodejs/tryparenscript.com/server.js:56:23 at routeDispatcher (/var/nodejs/tryparenscript.com/server.js:59:6) at /var/nodejs/tryparenscript.com/server.js:9:16 at /var/nodejs/tryparenscript.com/server.js:25:24 at /var/nodejs/tryparenscript.com/server.js:33:10 at Server.&lt;anonymous&gt; (/var/nodejs/tryparenscript.com/server.js:39:20) at Server.emit (events:33:26)&lt;/pre&gt;HTTP/1.1 200 OK Content-Type: text/html Connection: keep-alive Transfer-Encoding: chunked 98a &lt;!DOCTYPE html&gt;
Huh, it works now. Odd.
I haven't tried to use these features lately so I can't speak to their level of completeness, but I don't think there's much point to shopping for a new language if you depend on these features. Even Java didn't have them for many years, although now nobody would consider doing serious Java development without them. If you're looking for a language whose environment has these properties, it's probably not a good idea to try it within the first five years of conception or so.
seen before at http://lemonodor.com/archives/2007/10/youre_doing_it_wrong.html
That graphic was generated with http://wigflip.com/automotivator/ - a Lisp program.
I have this sign on my door. So far, only one person has actually known who "the old crazy dude" was.
this is hanging in my office as we speak
I thought Lisp is [a filthy communist language](http://en.wikipedia.org/wiki/Mccarthyism).
hmmm (&lt;3 (I) (Lisp)) Would make more sense; you're applying '&lt;3 to the results of 'I &amp; 'Lisp, similar to how you use 'get-current-output. Am I over thinking this?
 (and (have-a 'coke) (have-a 'smile)) 
Not necessarily. You are passing the heart ("&lt;3") of you ("I") to Lisp.
I don't entirely get it. Lets say '&lt;3 is a function with as argument the one loving it, returning a function that when applied with an argument, loves that argument.. But then it would be (funcall (&lt;3 (i)) (lisp)).. And if it would be (lisp gets), it should also be (i gets), no? Or what is the default argument? Nil? Cynicalmulch makes more sense.. (defun &lt;3 (sender receiver) ...) with obvious usage.
 (def I "person") (defn &lt;3 "function to grasp the emotion/heart of I" (do something to grasp the persons emotionheart)) (defn lisp "function to apply the emotion of I, found by &lt;3 to Lisp" (send-emotion-to-Lisp)) Clojure.
Up there with a speech impediment joke.
&gt; Am I over thinking this? Yeah. :) And since it's Lisp, it's just as valid to consider this acceptable: (&lt;3 I love Lisp!!!!) (macroexpand-1 '(&lt;3 I love Lisp!!!!)) =&gt; (defemotion 'love (I) (Lisp) :passion 4) 
Yeah, I understand that, but it's certainly not idiomatic as far as what most lisps do. That said, it makes sense, and one can certainly see what the shirt meant, but it's not what most Lispers would see.
The sky's the limit once we start to introduce macros, syntax &amp; reader-macros. :D
'lisp' and 'i' are both a noun, but in your example, they're different. Further the function 'lisp' is designed only to send emotions, while 'lisp' at a concept is much more than something to send emotions too. (Maybe the function I and LISP should be variables for their noun status.) I think this has to do with [generative grammar](http://en.wikipedia.org/wiki/Generative_grammar) and such, of which many have a vague idea in their mind, but i have yet to see anyone online talk about it in a more mathematical, theoretical, sense. [In this thread](http://www.lispforum.com/viewtopic.php?f=2&amp;t=676) there is a bit of mucking about with generative grammars, i am wary of knowledge on math when mucking about with code and not the math.
I agree. You want the verbs to be functions not the nouns.
exactly. The original makes sense (esp. in light of languages such as Nu or EuLisp or some other equally OO Lisp), but it's certainly not how many *traditional* lisps would handle the "I &lt;3 Lisp" notion. 
If you want to try out an early demo, let me know.
This is my desktop wallpaper..
The demo slide was anticlimactic. :( Anything else to tease us?
Sorry. That's when I switched to emacs and showed how it works.
Server error...
http://status.github.com/ doesn't report anything wrong - maybe it's just you?
Worked this time, maybe temporary?
I have this printed out and hanging on my wall at the office.
Possible to make a screencast of the demo?
I'll try to do that next week.
I am curious ...
Which CL implementation is packaged with this? Is it your own, sbcl, LispWorks, another?
Did you read the slides? This isn't bundled with any implementation yet. Xach is developing it to be portable across all CL implementations and OSes. It's presently in beta and hopefully available at a repo near you sometime soon.
&gt; Did you read the slides? Of course. Twice. That's why I asked. &gt; This isn't bundled with any implementation yet. I probably should have used the phrase "will be packaged". Part of the problem with the portability issue is that many packages out there are hardcoded to support specific Lisp implementations. I was curious as to which would get the most attention in order to work with Quicklisp. It sounds like a great project. I am still slugging it through asdf-install "Are your keys set up properly?" land.
I still do =)
I want to try and learn python, C, and Lisp concurrently, and maybe blog about it. I'm sure I'd fail pretty quickly, though.
&gt; Of course. Twice. That's why I asked. Ah. My apologies if I was a bit brusque. I'm not sure if any implementation is planning to include it in lieu of ASDF-Install anytime soon. &gt; I am still slugging it through asdf-install... I sympathize with you there. I've been using clbuild for a while and it's fine...but xach is doing everyone a pretty big favor by creating a good, cross-platform, VCS agnostic method of acquiring lisp libs.
Is there an explicit and preferably standard free license for this? It looks like good code, but I would not be comfortable just using it because a reddit submission title said I could. It would be easy to publish it with a simple MIT license, say.
Seems like the ideal setup would be some cffi bindings for [OpenCV](http://opencv.willowgarage.com/wiki/).
Sure...I'll add it first thing tomorrow. Is the MIT license the 'do anything but sue the makers" license?
Actually it's done. Under the MIT license. 
OpenCV does have a lot of stuff; but it shouldn't be too hard to implement [SIFT](http://en.wikipedia.org/wiki/Scale-invariant_feature_transform) or [SURF](http://en.wikipedia.org/wiki/SURF) in CL... and I'd guess a CFFI binding won't win many "lispy implementation" points. Due to the background being flesh-colored, I'd guess a good strategy is to start by converting to 8-bit grayscale. Image subtraction from the reference image probably isn't so useful; but it may work wonders with proper matching of keypoints and intensities...
Not sure what to think about this.. I'll read some more. [This](http://bywicket.com/users/mikel/weblog/126a4/Bard.html) seems like a good intro. Edit: not a fan about this 'leaving out the function symbol and determining it from the type' thing. It saves only a few characters, better spend the energy looking at other aspects of programming..
Link is down.. [Oh here is a short description](http://nklein.com/2010/07/find-the-people/) (and [here](http://planet.lisp.org/))
as devoid of content as this comment
I agree, but I don't see value in debating a four-year old blog post, regardless of the author.
I don't really think reddit is good place for this kind of questions. I would suggest using something like [lispforum](http://www.lispforum.com/) or implementation specific mailing lists. That said, if you want more efficient way to write a binary sequence to an output stream you want the [write-sequence](http://www.lispworks.com/documentation/HyperSpec/Body/f_wr_seq.htm) function. If you want to save the vector to file, then the [alexandria](http://www.cliki.net/Alexandria) library contains relevant utility function (alexandria:write-byte-vector-into-file). If what you want is not to have the whole request content in memory, then I am not familiar with Allegro, but the open source [drakma](http://weitz.de/drakma/#want-stream) library has a socket stream option, which should be usable with alexandria:copy-stream.
&gt; I don't really think reddit is good place for this kind of questions. I appreciate them. I like to learn things from other people's problems and answers. It also shows a wider curious audience various aspects they may care about. In this case, we are talking about something very modern: downloading a file from a website. This is a great opportunity to show readers another example of how CL is not actually behind the times, as per the silly myths.
You mean you want to do things with it while still downloading other parts? I think if it is passed as a stream, it could in principle do that. [Drakma](http://www.cliki.net/Drakma)s [http-request](http://weitz.de/drakma/#http-request), has an option to return a stream.
If by 'better' you mean faster, probably not. That's (almost certainly) going to be limited by the speed of your internet connection. Have you tried profiling your code? If most of the time is spent moving the file over the network, then you probably can't speed it up without getting a better internet connection.
Ultimately, the download is limited by the connection.. I guess: * Try seek a library using technicalities to the connection to try get more through. * Try predict the next download and get it ahead of time. (Potentially asocial waste of bandwidth) * Find mirrors. Make the application automatically make torrents to mirror and make a network. (Seems like a huge project to me..)
'function symbol'? What's that? Functions are things that can be applied to inputs to yield outputs. In Bard, maps and sequences are functions. If you don't like applying maps and sequences to arguments, then don't. 
I meant with 'function symbol' the first symbol in an s-expression. Yeah, i don't like it, but i guess i wouldn't be that bothered if i could just some equivalent one. I am just worrying that if users start making classes(if they can, but people could argue it arbitrary if they couldn't) act like functions in some cases, they'll do so too haphazardly.. [What do you think of this](http://ojasper.nl/essays/Type%20calculation.html#Type%20calculation), it really needs some more about simplifying.. Working on a proof checker (for sufficiently small steps!) based on ['regular' trees](http://ojasper.nl/readmes/Regular%20tree.html#Regular%20tree) that might help there.. (The simplifications would go through pre-given equivalences to try.) It doesn't really have 'amortized algorithmic complexity' at this point though.. And i don't know Haskell(i should.. or rather perhaps category theory), so you probably already have more of an idea how to do it in a perhaps wholly different direction.(which is fine, my approach might well be much more precarious at this point)
If you're just talking about the first element of an s-expression, there's no very good reason to call it a 'function symbol'. For one thing, a symbol there doesn't always indicate a function; sometimes it's a macro or a special form. For another thing, not all Lisps require the object there to be a symbol (for example, both Scheme and Clojure allow lambda expressions, and Clojure allows seqs, maps, and keywords). I don't think there is much to worry about in supporting things that aren't symbols in the operator position. The programming world has not collapsed around our ears because of lambdas in Scheme, for instance, although admittedly, it's pretty easy to construct a fairly baffling expression that way. But that's okay; it can easily be cured with a simple variable binding. I tried reading the linked page, but it's rough going. I have a tough time following your prose. You may want to get someone else to look at it--someone with whom you can discuss the ideas, and who can help clarify the descriptions. I know that years of working with professional editors definitely improved the general quality of my prose.
"A New Lisp Machine" is an unfortunate description, to be sure, but that doesn't make the exercise uninteresting. I had the good fortune once upon a time, many years ago, to work on a novel operating system written almost entirely in Lisp. The microkernel was written in C++, and the seven "bottleneck" entry-points to the low-level graphics subsystem were written in C, but everything else was written in a dialect of Lisp. It was liberating and very fun. Would it have been beter if the remaining parts were written in Lisp as well? Probably. Would it have been even more fun if the hardware had been designed particularly for Lisp? Yeah, probably. Lisp all the way down remains a seductive vision. You don't have to have Lisp all the way down, though, to have something worth doing.
Good article. One note: *throws of construction* -&gt; *throes of construction*
Is there a non-ftp?
Try this: http://lispm.dyndns.org/documentation/dialects/The-Kernel-Programming-Language.pdf
Here's the author's website. http://web.cs.wpi.edu/~jshutt/kernel.html I only see ftp links for the paper. Is there a reason that doesn't work for you?
I'm behind a firewall.
Are there any implementations for Kernel?
Are you arguing we shouldn't have a memory? If a post is still good now, i don't care if it is a hundred years old. However, that one isn't good. It screams under-informed. For one it says 'There is no acceptable Lisp' *and* 'Ruby is an acceptable LISP'... I do feel it is a bit too hard to be sufficiently informed.. There sometimes seems to be a little too much one has to know about CL.. And i do agree that functions like LENGTH, should've been generic, but the un-surmountainable-ness is highly exaggerated.. Make a generic, define it and call it LEN, then.. It is perfectly possible to make a lib that does these for you. I know first hand that making generic variants of +,-,*,/ can be a bit more involved, depending on how you want it. And i do think the type system could be more accessible and reassuring(that types are being derived) to the user, while still allowing specification of types to be completely optional. But i digress..
You download the entire file, bring it into memory, and then write it out. Instead, you could be writing each byte as it comes in. That way you don't use so much memory, and you decrease run time.
r/lisp??
Rather than a *de novo* DSL, they should pick an existing language with: * a published spec, with numeric semantics that make sense * a track record for multiple, independent, interoperable implementations I can think of three languages that qualify right off: * Java - I don't love Java's numerics, but they *are* at least in the spec * Scheme (RnRS for a given value of n) * Common Lisp C and C++ are right out due to lack of numeric semantic guarantees (*How fast do you want the wrong answer?*). I don't know enough about the current state of Fortran or Cobol to comment, but suspect they're broken for similar reasons.
Yeah, wat?
Well, it was signed by Philip Wadler, so they invariably think that Haskell, Java (using [GJ](http://homepages.inf.ed.ac.uk/wadler/gj/)) or Erlang should be the language used for the DSL. He may be right, but the letter as it's posted is very short on detail as to why Python is a poor choice. It's not a very useful analysis that way.
Let's see .. who would make money supplying such a language? I wonder ..
[Joe Marshall goes into detail](http://funcall.blogspot.com/2010/04/open-letter-to-sec.html).
This is more funny. -----------------------&lt; snip&gt;---------------------------- Some programming languages have been designed with security in mind, and some of their implementations include “sandboxes” that can securely execute untrusted code. Java, C#, and F# are such languages; Python and Perl are not. ------------------&lt; snip &gt;-------------------------------- 
Haven't really started reading it, but laughed a bit at &gt; It is designed to be simpler and more general than Scheme &gt; page 1 / 194
Like many others, he clearly does like Lisp! But it's the *ideal* of Lisp, not the reality.
Also on the wall where I work...
Awe, cut Yegge some slack. Hyperbole is just part of his writing style. This article seemed entirely too defensive.
Way to utterly be beside the point. Yegge didn't claim, more than 4 years ago mind you, that you couldn't write large programs in lisp. That wouldn't make sense, since large programs have been written in Lisp (all lisp machines software for starters). What he claims is written plainly in his article: that Lisp, or the lisps which existed at the time anyway, are not so good languages, and not worthy of being worshipped, because they have numerous issues and are far from the be-all end-all of programming.
Lisp has originally been developed for symbolic programming tasks (computer algebra, theorem provers, logic calculus, natural language translation, ...). McCarthy called his paper about Lisp accordingly: Recursive Functions of Symbolic Expressions and their Computation by Machine. That sounds not like Ruby, more like Common Lisp or Scheme. The computer algebra stuff that Tim Daly is working on is exactly in that domain. The core Lisp dialects are excellent for that. Yegge may have his own idea what Lisp is and what Lisp should be used for. But it does simply not match with the origins of Lisp and even not with its current usage. Neither has Ruby anything to do with Lisp. It is simply annoying when outsiders tell Lisp users what Lisp is bad for and why Ruby is better. Lisp has evolved over the years and several other languages have taken ideas from Lisp (some more, some less). Today's users still use the symbolic programming capabilities for linguistic abstraction. Tim Daly is obviously thinking that Common Lisp works fine for his application domain, which is also one of the core Lisp domains (with a number of prominent applications like Macsyma, Derive, Reduce and others). Quite acceptable, it is. Ruby has not used to write applications in the core domain where Lisp is used. I don't think it ever will be widely used in these areas. If Lisp is not used in these areas, then there are already other alternatives: C++, Java, Prolog, ML dialects. Ruby has already difficulties implementing itself. 
What I don't understand is why do we care what Steve Yegge thinks about any Lisp-like language? If he doesn't use it, that's fine, but it smacks of zealotry when we have to defend ourselves against the unfaithful infidels. I would much prefer we just get back to coding really cool things in Lisps (pick your favorite!) and bettering what we have. 
sadly I don't really have time to update the website - neither the code.. but I hope to do that at some point this year! :) [including more example screenshots]
Not portably, not like that. You'd have to shadow LENGTH in your own package.
Oops, I missed this page: http://www.lispworks.com/documentation/lw50/CLHS/Body/11_abab.htm
Drew makes a good point. Nowadays, however, the civilized way to do that (at least on SBCL) is by using [User-extensible sequences in Common Lisp](http://www.doc.gold.ac.uk/~mas01cr/papers/ilc2007/sequences-20070301.pdf): CL-USER&gt; (defclass yegge-post (sequence standard-object) ()) #&lt;STANDARD-CLASS YEGGE-POST&gt; CL-USER&gt; (defmethod sb-sequence:length ((nonsense yegge-post)) (1- array-total-size-limit)) #&lt;STANDARD-METHOD SB-SEQUENCE:LENGTH (YEGGE-POST) {1003CB6F51}&gt; CL-USER&gt; (length (make-instance 'yegge-post)) 1152921504606846972
Well, brevity is not simplicity. The report is written in a style very different from the r5rs, with rationales all over the place justifying every design decision... I find it a lot more consistent than scheme in many respects. If anyone is interested, I would suggest starting with an older paper from the author: ["Decomposing lambda, the Kernel programming language"](ftp://ftp.cs.wpi.edu/pub/techreports/pdf/03-04.pdf) It's less than 50 pages and it includes most of the important concepts. It also includes a toy interpreter source code, written in r5rs scheme. 
&gt; (reddit markup fail?) Reddit doesn't believe you're linking unless it sees an `http://` in there: `[User-extensible sequences in Common Lisp](http://www.doc.gold.ac.uk/~mas01cr/papers/ilc2007/sequences-20070301.pdf)` =&gt; [User-extensible sequences in Common Lisp](http://www.doc.gold.ac.uk/~mas01cr/papers/ilc2007/sequences-20070301.pdf) It seems to me that Gruber made a big contribution to markup when he invented [Markdown](http://daringfireball.net/projects/markdown/), but that his insistence on (as I see it) pretending [his regexes](http://www.google.com/search?&amp;q=site%3Adaringfireball.net+%22regular+expression%22) are fool-proof, rather than simply very useful in practice, I think is quite damaging in a sure-I-can-parse-HTML-with-regexes \* kind of way. \* I'm not saying that *he* thinks this, but rather that he (inadvertently) encourages *readers* to think it.
[OT] Markup/down existed before Gruber; he just refined one variant. The concept tends to work great for small texts, but fall apart when structured manipulations are required. Please have a look at [Scribble](http://docs.racket-lang.org/scribble/index.html).
Certainly markup, as a generalised concept, existed before Gruber; but, at least according to [Wikipedia](http://en.wikipedia.org/wiki/Markdown), he did co-create Markdown. EDIT: Thanks for the pointer to Scribble; I'll have a look, but, as a mathematician, my mark-up language of choice is, and is likely to remain, LaTeX.
Ada maybe?
I see, thank you!
Someone hasn't heard the big news about iTex yet.
On the contrary; I'm the one who broke [the story](http://www.reddit.com/r/tex/comments/clbgh/knuths_earthshaking_announcement) here.
..and NaCL will support ARM. Hmmmm. :) http://en.wikipedia.org/wiki/Google_Native_Client
 (defun download-file (url file-name) (let ((body-stream (http-request url :want-stream t :force-binary t :content-length t))) (unwind-protect (with-open-file (out-file file-name :direction :output :if-exists :supersede :element-type 'unsigned-byte) (loop for c = (read-byte body-stream nil) until (null current) do (write-byte c out-file))) (close body-stream)))) 
The example is of single-dispatch.
to me it looks like the whole example, especially with the PUT function, makes no sense. Well, the generic function makes no sense either, should be replaced with a hash table or an assoc list.
Lisp is really easy to learn, unless one already knows some other programming languages.
I didn't expect much from the article after seeing "common LISP"; if you can't even write the language's name correctly, I don't have high hopes you'll get an example correct. 
maybe it's not meant serious? To annoy Lispers?
IMO, writing a scheme interpreter in another language doesn't mean you've "learned scheme." Understanding the syntax and constructs of a language isn't enough - the only way to get a visceral feel for it is to spend a significant amount of time working on large projects written in that language.
I doubt it. Check out his [github](http://github.com/isterin) page. It just looks like confusion and ignorance, which are curable.
&gt; It is long journey. Not learning scheme -- that is easy and short one. (Seriously, it is). I disagree. There are many features of Scheme that are quite challenging to fully understand (by which I mean know beyond just the definition). For example, first class continuations are magical and mindbending. Just look at the way it's been used by Oleg, Dorai Sitaram (schelog), and Gerry Sussman (among others). Taking one look at the stuff on Oleg's page, ReadScheme, and books like TAPL, EOPL should be enough to convince yourself that master of scheme is not a trivial matter.
Easy to learn but difficult to master? (Like the game of Go?)
Well, somehow. But I'd say a language like C++ is also difficult to master, though for slightly different reasons. ;-) In case of Lisp its also an interesting experience, you can use it for years and still find new things or get deeper understanding from time to time. There is also enough esoteric stuff to explore.
**Anyone could learn Lisp in one day, except that if they already knew Fortran, it would take three days.** — Marvin Minsky
That could be the case; /dev/shinobi could be sarcasm. Of course, so many developers (well, those with blogs, aspirations &amp; hopefully a usable FOSS project) describe themselves as ninjas or rock stars, so it could be 100% serious. There is a whole class of HR people who fall into this trap as well; how many ads have you seen like this: &gt; ARE YOU A ROCK STAR NINJA CODER WITH A BLACK BELT IN KICK &gt; ASS DESIGN? WE ONLY HIRE THE BEST PEOPLE (to work on our &gt; poorly designed, in-house CMS/CRM/ERP system)! EAT CANDY, CHIPS &gt; AND OVERTHROW THE DAIMYO (also know as our previous &gt; CMS/CRM/ERP system, that was written in Cobol on Cogs). In any case, it was a pretty bad example with pretty bad code. We could start a check list for such things [X] AUTHOR REFERS TO SELF AS NINJA/ROCKSTAR [X] AUTHOR MISSPELLS LANGUAGE'S NAME [X] ARTICLE'S TITLE IS INAPPROPRIATE [X] ARTICLE USES INCORRECT AND/OR INAPPROPRIATE EXAMPLE [X] EXAMPLE IS HIGHLY CONTRIVED AND/OR TRIVIAL sheesh. /rant
&gt; Well, somehow. But I'd say a language like C++ is also difficult to master, though for slightly different reasons. ;-) Like chess.
Then write a scheme interpreter in scheme. That was how Dan Friedman taught us scheme and the concept of programming languages. 
I think the author is confused about EQL specializers, and thinks that using them is an example of multiple dispatch. The fact that he mentions pattern matching supports this theory. 
Also the DEFGENERIC feature of defining multiple methods (!) seems to confuse him.
Well, i commented on his blog, and now he's changed the examples (and s/LISP/Lisp), and actually made his examples use multiple dispatch. He also clarified that it was DEFGENERIC he's excited about : "I was trying to demonstrate the conciseness of polymorphic method definitions inline with defgeneric" I'm not sure why he chose the title he did if that's the case, but that's from the horse's mouth, so who am i to disagree. 
Sure. I was just referring to what the author of the article wrote. It seems to be a common project for people to write little scheme interpreters in random languages - I just don't like the idea that this somehow _teaches_ you scheme.
I agonized about getting that copy but just couldn't bring myself to spend $300 on a book regardless of its sentimental value.
Personally, I would prefer to have an unsigned copy of books like this. The benefit is that they can have twice as many pages, since you number the pages starting at zero. Seriously, though, I've brought my copy of ANSI Common Lisp on airplanes, trains, and automobiles^Wsubways and restaurants. I can use the book there, and not worry too much about losing it or knocking it around. My copy is pretty scratched up, but that's ok -- it's not like it has special value to me that another copy from Amazon wouldn't.
The problem with this book is that it is no longer published. Even if I picked up one of the ~200USD copies that are available, it is still a limited resource. So, I just read On Lisp on my iPad. I find this a better solution over all because I can carry many other out-of-print books (not to mention an entire bookshelf). Over the last 7-8 years I did destroy one copy of ANSI Common Lisp, mangled another and have another in more or less pristine condition, so I get your point. I bought this copy out of sentiment, not to carry around with me.
Yeah, it's sad that this is out of print. pg auctioned one off at the launch of one of the Y Combinator companies -- a charity auction site; I forget the name. I'm a lot better at sitting down and reading a book in hard copy than I am on my computer. I just find the .pdf hard to concentrate on.
You could also probably print it up at Lulu for like $10.
I just wanted a Lisp book from Erik Naggum's library with his signature. On Lisp was the most significant one there. ANSI Common Lisp and On Lisp are not good CL books, but On Lisp from Erik's library is special.
I basically cannot read something of significant length on a desktop or laptop. I have found the kindle and ipad to offer an excellent compromise given that I don't want to print out, carry around or store hundreds of pages of various published and unpublished sources.
I printed up a couple copies on lulu for myself and a coworker. It cost roughly nothing that way and it is pretty good quality. It cost me $13.02 / copy.
"Marvin hasn't written Lisp since the 60s" - Prof. Sussman (jokingly) :)
What *is* a good CL book? (Other than PCL, obviously).
He! Somehow Minsky must have taught some of his students to use Lisp. http://web.media.mit.edu/~minsky/people.html Bobrow worked amongst others on CLOS, Charniak wrote a Lisp book, Gary Drescher developed Object Lisp, Scott Fahlman was of the designers of Common Lisp and lead the Spice Lisp / CMUCL project, Kenneth Forbus wrote a book how to write knowledge based reasoning systems in Lisp, Gosper, Hewitt, Hillis developed the Connection Machine (which used *Lisp), Berthold Horn co-wrote a book on Lisp, Kenneth Kahn, Tom Knight was the principal designer of the Lisp Machine, John Mallery write CL-HTTP and some other stuff, Drew McDermott, Karl Sims wrote animations in Lisp, Luc Steels worked on natural language software in Lisp, Sussman, Strassman worked at Apple on MCL, Winston co-wrote a book on Lisp. I bet that Minsky had/has quite a good idea about Lisp...
You don't think ANSI Common Lisp is a good book? I found it a good, if dense, book to learn Lisp from. Of course, Lisp isn't my first language, and I was pretty dedicated to pushing through the book, working the problems and testing my solutions.
How did you have access to his library? Did I overlook another thread that explained?
The bookseller announced it on c.l.l. See [here](http://xach.livejournal.com/257931.html).
It's amazing to see the people he's advised... hardcore lispers in their own right. Prof Sussman also had this quote about Joel Moses' code: "The original macsyma code was written by Joel Moses in Lisp. I saw in Lisp, although the code was worse than fortran with all kinds of gotos and what not. Poor Minsky had to read the program and he was manually indenting them when one of his students wrote a program that would pretty print automatically."
There are some annotations [here](http://www.cs.northwestern.edu/academics/courses/325/readings/graham/graham-notes.html). Dislike/avoidance of CLOS and loop stand out, particularly.
Paradigms of Artificial Intelligence Programming
The code Joel Moses wrote was not unusual. There are lots of programs in a similar programming style. Common Lisp has these constructs, too. See for example some of the code in this old Lisp book: http://www.softwarepreservation.org/projects/LISP/book/III_LispBook_Apr66.pdf Typical was this something like this: (defun foo (x y) (prog (a b c d e f g h) (setq a (car x)) (setq b (cadr y) ... l1 (if (zerop g) (go l2)) ... l2 ... exit (return h))) PROG sets up some variables, these then get set from the procedure parameters. Then some spaghetti code with GO and IF. A bunch of jump labels and some label to exit the thing. That was not unusual. There is not much effort needed to get that kind of code to run in Common Lisp. 
What books do you like? I have picked up a small collection of various Lisp/CL books. I'm keen on picking up Lisp Style &amp; Design next.
I knew what you meant originally and was in total agreement with you. That's why I suggested scheme as an implementation language for the interpreter. 
It seems like the things the author points out are minor issues -- albeit valid ones -- rather than things that would make the book bad. The author even says "Graham has an excellent Lisp coding style".
Oh, I didn't mean to say that link backs up Xach's opinion, so much as it highlights some lacking elements.
I first read PCL but didn't really understand the big picture of Lisp. I then read ACL which I think is better for the beginner. I now find myself referring back to PCL when I have a question and know the general subject area.
Good Ol' Norvig.
I was actually inquiring of Xach's opinion, since I liked both ACL and OL (and PAIP).
I nabbed a copy of Lisp Lore for ~$10. Couldn't resist after seeing it on Amazon at ~$350. Useful? Perhaps not so much. Interesting read though.
Paradigms of AI Programming, Winton &amp; Horn 3rd Ed, Keene's CLOS book, AMOP are a few.
I don't think it's good for learning Common Lisp because of its bizarre (for CL) style and its denigration or outright omission of important CL features.
[See this link](http://www.reddit.com/r/lisp/comments/b2tx3/people_are_surprised_when_i_say_paul_graham/)
Did you print Erik Naggum's signature too?
How does one get some arbitrary PDF into the iBook reader? Or did you just look at it thru safari??
So I'm curious why you don't like ACL or OL? (Honest question - I've enjoyed all the books mentioned except AMOP, which I've not read yet). Is it just PG's programming style or do you think the books are otherwise poor?
Neither is about Common Lisp - PG has written that he was writing about a platonic Lisp and using CL as the implementation because it was either that or Scheme. But it's clear he doesn't like CL, and the shabby treatment of e.g. packages or CLOS make it a bad choice if your goal is to learn CL.
I don't know about that, but I use GoodReader which is 0.99USD. It lets you specify http/ftp urls and I believe you can open/save from email this way.
I just study lisp, I don't worship it (or the community). :P
Wait--I can't put any PDF I want on it? That's ridiculous!
There might be some way I just haven't figured it out yet. 
Does that save the file on the iPad so you don't need a net connection to read it?
Haha
&gt; Personally, I would prefer to have an unsigned copy of books like this. The benefit is that they can have twice as many pages, since you number the pages starting at zero. Sir, I salute you.
On i* devices open a pdf from a link in Safari or in an email attachment, then select "Open in iBooks" On a Mac with iTunes select "File" -&gt; "Add to Library..." and find the pdf. I'm sure it's similar under Windows.
yes
But to actually answer your question... Some difficulties I had after referring to it as my primary CL text (having drunk deeply in the boston/cambridge-area Graham hype, gone to his first Startup School, read the essays, etc): * CLOS * packages * lisp-1 style variable naming * document strings * loop * overly terse function/macro naming (what do you think gen-site does? what does defstruct item pertain to?). without packages, comments or sane names, it is even very difficult to revisit the [code](http://lib.store.yahoo.net/lib/paulgraham/acl2.lisp).
I went for one of the Perl books with his signature, for the laughs. Oh, and Sonya Keen's "Object Oriented Programming in Common Lisp". Unsigned however :-(
I use that daily.
I would return it, if it did.
It works with any CL implementation on any platform and you get started by downloading and loading a single Lisp file.
It's my hope that Quicklisp will help authors eliminate trivial or avoidable portability problems by making their software easily available for testing on many platforms. Until now, I never tested my stuff on e.g. LispWorks for Windows because it's hard to get all the dependencies there. Quicklisp makes that part, dependency fetching, very easy. Deeper compatibility issues will remain, of course.
$13 actually. :-)
Excellent points, thanks!
You most certainly can.
Good.
What video?
http://ecn.channel9.msdn.com/o9/ch9/3931/563931/ELangsClojureFSharpHickeyPamer_ch9.mp4
http://labs.core.gen.tr/#domprogramming
"Metacutter is an online CAD/CAM system for making the patterns for custom clothing." http://www.symbolicspace.com/ http://www.jacobkozinn.com/ 
&gt; Codename Faust: A Common Lisp implemented in Qt. What does this even mean?
I was curious about this too; I applied anyway :D 
It's certainly better if that's all you do; or you do a lot of it. ..and of course implementing a DSL (reader macros and macros) is actually possible in Common Lisp.
At least as far as numerics is concerned, Fortran is in a better situation than C's. Significantly fewer undetermined behaviors and a well-detailed spec. I don't know anything about Cobol either though.
To translate the point of the paper to present day, the author is advocating teaching SICP with Haskell.
I've never liked this paper, and I can use Wadler's own words as to why (from the end of section 1.2): &gt; Some people may wish to dismiss many of the issues raised in this &gt; paper as being "just syntax". It is true that much debate over syntax &gt; is of little value. But it is also true that a good choice of notation &gt; can greatly aid learning and thought, and a poor choice can hinder &gt; it. In particular, pattern-matching seems to aid though about case &gt; analysis, making it easier to construct programs and to prove their &gt; properties by structural induction. Also, mathematical notation is &gt; easier to manipulate algebraically than Lisp. I don't see any of his points being really that much of a case against lisp, so much as a case of Phillip Wadler preferring the languages he worked in (duh). Besides this, "Lisp" as he calls it, really *is* a mathematical notation; we've had "Polish" and "Reverse Polish" notation for quite some time. Jan Łukasiewicz (ironically, given the paper's point) created the notation to *ease* the formal notation of predicate calculus [*edit*: changed this from it's originally tautological "created the notation to ease notation]. I have case-lambda's in my Scheme dialect since I think it makes for elegant notation in certain instances; currently, one would: (defn sum :case '() 0 (x xs) (+ x (sum xs))) Sure, that's many more parens than KRC, Miranda, but I don't think it's terrible [*edit* terribly -&gt; terrible] either. Of course, I'm falling into the same trap: I prefer the syntax of the language I already use (and designed). *edit*: clarifications as noted in text. :D
But can you do that, without being the copyright owner? (I mean, I suppose they wouldn't even let you...)
What about the missing pictures that he mentions on his website? Are there replacement pictures?
ECL would be interesting on such a device... :-) It looks like it can be kept under 8Mb: /usr/local/bin/ecl 26K /usr/local/lib/libecl.so.10.7.1 7.2M /usr/lib/libffi.so.5.0.10 32K If the router has enough memory, porting ECL would be cool. But I suppose you'd also need gcc installed on the device, right? 
That wouldn't really be SICP. Some more "advanced" features SICP introduces later in the course are central concepts to Haskell. (Streams/lazy lists, pattern matching) Also, building a Haskell interpreter in Haskell is much more complex than building a Lisp interpreter in Lisp, since a Lisp program is just a datastructure lika any other.
Agreed. Some of Wadler's arguments are a bit funky: 1. He mistakenly wrote `(foo = bar)` instead of `(= foo bar)` on a blackboard, therefore the prefix notation is not natural. Er, what? That's like saying infix notation is not natural because the other day, I wrote `= foo bar` in haskell... 2. He's not using macros! If he thinks pattern matching is so great, and the Lisp he was using didn't have it, he could have written a simple pattern matching engine. Same thing when he talks about the "sheer bulk" of the Lisp programs of the article: stop writing constructors and accessors all the time, and write a simple `defstruct` macro!
SICP teaches abstraction, Wadler advocates pattern matching instead. Abstraction is useful even in cases which cannot easily be solved with pattern matching. In fact, pattern matching *encourages* to fix the data representation and use it everywhere, whereas SICP teaches to abstract from the data representation as much as possible. Imagine writing your own doubly-linked list implementation. SICP encourages to use `(dl-empty? list)` whereas Wadler advocates matching on `DLNil`. Now imagine we need to denormalize the list representation such that there's a second representation for an empty list. SICP-style, we change the definition of `dl-empty?` and are done. In the pattern matching case we have to grep for all occurences of `DLNil`, possibly having to add another (mostly duplicate) rule to each function having our doubly-linked lists as arguments, which is non-local and not even easily automated. It it perhaps interesting that Wadler must have seen this as well. He proposed [View Patterns](http://homepages.inf.ed.ac.uk/wadler/papers/view/) (in 1987!). Since then, several [related proposals to enhance pattern matching](http://hackage.haskell.org/trac/ghc/wiki/ViewPatterns#Relatedwork) have been put forward (and a good deal of discussion), but only recently (in GHC 6.10.x) one was implemented in a production compiler.
&gt; Some more "advanced" features SICP introduces later in the course are central concepts to Haskell. You could start with a simple dialect of Haskell and then extend it. &gt; Also, building a Haskell interpreter in Haskell is much more complex than building a Lisp interpreter in Lisp, since a Lisp program is just a datastructure lika any other. Which Lisp? Building a full Scheme or Common Lisp interpreter is a bit more work than your average toy lisp interpreter, even more so if you want to make it production-ready. Also, GHC ships with a parser for Haskell which gives you back an AST, just another datastructure.
The natural bit is an odd one; it's all what one is used to that make anything "seem" natural. His argument is, basically, that infix matches what we generally teach children in school, and is thus natural. Of course, we don't naturally have to think about numerical types either, so that's a deficiency of such languages, right? The best language out there then would have Lisp's numerical tower &amp; Miranda's syntax, and would completely miss the point: you're looking to match the abstractions you get from your choice of language with both the way you think &amp; the problem at hand. The macro bit is kind of funny; he insists that there are four things that are deficient in Lisp, then doesn't explain how to remedy them. I understand the paper is to show that Miranda &amp; family are better than Lisp, but the avoidance of macros is quite funny. All in all, I don't buy it either.
good point
I think you could, they might look twice if you ordered a thousand copies, but if you're just printing a copy for yourself i bet they wouldn't notice / care..
I am biased towards common lisp, but I give reasons below. * Clojure It is good if you want good integration with Java, or its STM implementation. Otherwise I don't see what it has that common lisp doesn't. Common lisp implementations usually interoperate with C rather well, something JVM doesn't. Moreover, common lisp has an implementation on the JVM, called ABCL. Though it is not 1.0 yet. * scheme Awesome language, shitty implementations. PLT scheme is oriented towards academia; gambit and chicken don't support native multithreading. Community is still flinging poo at each other for r6rs and err5rs. Ypsilon is an excellent implementation, but has not been updated for more than a year. Chez scheme is amazing, but closed source. * common lisp Built from ground up to let you do production ready programming. Ref ITA's experience, acquired by google now. Has some impure theoretical constructs that schemers scoff at, but they actually help to balance performance and readability. Plenty of stable and fast implementations, with excellent multithreading support. Though mulitthreading support is not standardised, but it works for me. Check out ecl or clisp if you want to program in under 16 MB of RAM on say a mobile phone. For better performance use sbcl and clozure(don't confuse with clojure). Clozure is almost ready for an ARM release, but generally requires more RAM than ecl or clisp.
All the lisps you mentioned are good. None are perfect. Clojure is modern, fits its technological and cultural environment well, and packages recent ideas from functional programming in an especially elegant way. But it relies on the jvm (a demerit if you don't like it), and its type system needs work (though, to be fair, that work is happening). I find that, with the use of the leiningen build tool, almost all of the pain caused by the java infrastructure is alleviated. Common lisp is great in that it packages up thirty years of what working programmers considered to be essential tools for getting things done quickly. Admittedly, they did the packaging almost thirty years ago, so an awful lot of it seems quaint, arcane, or gratuitously complicated. Still, if you grit your teeth and acclimate yourself, the result is a language with which you can accomplish a great deal with a modest effort, and one that imposes very few arbitrary barriers. Its status as a hoary old standard means that there are a bunch of good implementations, and its age means that a handful of them have been maintained since before half the programmers in the world were born, so they're not likely to disappear any time soon. Be mindful of common lisp's age and the fact that its users are provincial. CL seems weird and gratuitously different when you first approach it, and the locals aren't always friendly to outsiders. Live there for a while and it alters your brain so that, after a while, you begin to see the world from the CL point of view, and outsiders start to look strange and unappealing to you. Scheme's pivot is finding a language whose essential abstractions are so powerful that it doesn't need to have a lot of features. You can learn it very quickly, especially if you like all-encompassing abstractions. The power of scheme's abstractions in intoxicating, and they make you wonder why every language doesn't simply build on scheme's tools. But that focus on smallness and elegance means that for decades of its life scheme has not had a decent story around libraries. That, combined with the power of its abstractions, means that there are fifty different mutually incompatible libraries for doing anything whatsoever. There are a few schemes that ease that problem, providing rich sets of libraries, if you are willing to commit to a particular implementation. But my favorite lisp is Ralph, the scheme+clos variant invented at apple computer, that later evolved into Dylan. Sadly, Ralph is extinct.
&gt; Otherwise I don't see what it has that common lisp doesn't. STM, pervasive efficient immutable data structures, well-integrated lazy operations, a quite different take on the implementation of polymorphic functions, and a nice collection of succinct syntactic sugars for things that are more cumbersome to say in Common Lisp. Which is not to say that I like Clojure better than Common Lisp; I don't. But I have to give it credit for being the first new Lisp variant in decades that made its way into my regular toolbox alongside Common Lisp and Scheme. 
Always been fond of Elmer Fudd's lisp.
[LFE](http://github.com/rvirding/lfe) Lisp macros on Erlang VM; complete access to Erlang OTP modules. Documentation is rather poor, though. I'd like to fix that, if I can ever find time...
Common Lisp. It's a standard, and there are multiple high quality implementations available, both free and commercial. Also has excellent documentation, and mountains of sample code available to help you learn. But in my opinion, 8 years for all those languages is not enough time, and unless you're much brighter than me (quite possible...) you run the risk of mere dabbling.
OK, everbody... Let's see if we can set a new world record for downvotes on this one! I really like [NewLisp](http://www.newlisp.org), mainly because it sends the Lispriests into apoplectic peregrinations of disgust as they deride the bits that don't conform to the Talmud of Steele and/or Sussman. As a matter of fact, let's get that part out of the way now: http://lambda-the-ultimate.org/node/257 . Here's some further information from the NewLisp site: http://www.newlisp.org/index.cgi?page=Differences_to_Other_LISPs . OK, that was a joke and a disclaimer. The real reason that I really like NewLisp is that it's a friendly and useful language. I was going to try to type some more into this tiny comment box, but then I went and wrote something suspiciously like an essay, which I will spare us all the agony of reproducing here. See it at http://hotwax.cjmunday.com/newlisp.html if you're interested. If you haven't seen this, it may be helpful: http://common-lisp.net/~dlw/LispSurvey.html (Although it doesn't seem to mention NewLisp. Boo. Hoo.) 
If you're really into low-level implementations, then you'd probably get the best bang for your time working through SICP and implement your own Lisp to start with. Everything else is just a Lisp not made for/by you. :)
You rock, man! This thing's going to be awesome. Will contributors need to test their code on all lisps, and all platforms?
ecl is available in the easydebian image for n900.
That was really cool. I'm trying it right now!
&gt;&gt;It is good if you want good integration with Java, or its STM implementation. Otherwise I don't see what it has that common lisp doesn't. Most importantly, seq abstraction.
I liked NewLisp as well. Was very easy to get windowed app up and running with it. Lots of features....seems very powerful and definitely appropriate for certain development situations.
&gt; NewLisp What a lovely language! Thanks for sharing! 
Like he was on the radio for all these years. Nicely done.
R, because it is lisp without s-expressions http://dan.corlan.net/R_to_common_lisp_translator/
* I like 3-Lisp because it has another Lisp underneath Lisp, and then another and another ... * I like Lisp Machine Lisp because the frame buffer is just another array and the console is the value of the *console* variable * I like Logo because I can drive the turtle around * I like LispWorks because it travelled further into space than any other Lisp. On board of the space craft Deep Space 1. * I like InterLisp because it does what I mean.
&gt; Gets weblocks working in less than a minute *swoon*
Code in the client would need to be tested everywhere. I don't think I'd mind special things that work only on a subset of CLs, as long as it's not carelessly incompatible or essential functionality.
Xach, who will foot the amazon bill?
I will foot the Amazon bill. July's bill, under pretty heavy testing, was $0.25.
Cool, a man with a mission :) I am only half joking. I welcome your effort to create the grand, portable and painlessly working package manager for CL. I really wish it gets the adoption it deserves. It will make the life easier for all of us and will eliminate, or at least alleviate the perceived 'libraries' problem. 
There are good points in the comments against the paper, but IMHO the most important thing is that pattern matching is too difficult for a beginner; it requires by itself the capability to abstract concepts in your mind, introducing one more level of difficulty.
&gt; 3-Lisp Wow, I haven't heard about 3-Lisp in a while. Must... track... down... 
It's certainly going to shift the libraries problem from "Things are hard to get and install!" to "Which thing should I choose?" or "Many of these things are half-baked and underdocumented!" and similar. I'll tackle those bits too, when I can.
Thanks for the great comment; I'll probably end up trying CommonLisp as well as a few schemes and just see what fits better.
&gt; gambit and chicken don't support native multithreading. That's not actually a bad thing. Both systems have good support for multithreading, and Gambit even supports [SRFI 21 ("Real-time multithreading support")](http://srfi.schemers.org/srfi-21/srfi-21.html). 
very cool stuff ! Thanks!
&gt; But that focus on smallness and elegance means that for decades of its life scheme has not had a decent story around libraries. That, combined with the power of its abstractions, means that there are fifty different mutually incompatible libraries for doing anything whatsoever. Yes, but if you stick to one implementation you'll be fine. Anyway -- the incompatible parts of Scheme are mostly superfluous IMHO, except for three things: threading, networking and interface with external programs (FFI) -- and these are also somewhat problematic in Common Lisp. That said, there is SRFI-18 that is a non-official threading specification that lots of Scheme systems implement. The only reeeealy incompatible parts would then be FFI and networking, but if you have enough patience, you can write wrappers for those so they will work on two or three different Schemes.
I really like Emacs Lisp because it's always around, no matter where I am. I often try out new algorithms or ideas in it. And I like making my editor do crazy things (implementing network protocols for example, so I can Emacs up to various services, or helping me write or understand code in various other languages). It has an interesting heritage shared lineage with Common Lisp, and an interesting subset of features. It's a tiny language, but it has macros, which are a lot of fun. Some people scoff at the scoping rule or lack of packages/namespaces, but usually it doesn't matter (and the 'cl' package provides a lot of help). For serious hacking I currently favour Common Lisp, in part because its macros make more sense to me than Scheme's (despite their problems), even though Scheme is clearly more beautiful and slender, and in part because the ecosystem feels more practical and less academic than Scheme's, which suits me. However, I can never seem to shake the lingering Scheme-envy. One day I would like to try out Clojure. My (totally superficial) reaction so far is that I don't see why a new Lisp would deliberately invent new horribly contracted words (the Common Lisp guys had a good reason -- backward compatibility -- and the MacLisp guys too, and so on, back to machines that had a 6 character symbol length restriction, or something like that...).
C and CL foreign-interface much more easily together. It avoids dependency to java interpretation. C# probably also would require a dependency. The C blowfish implementation is probably self-contained moreso than those you list, simply because no interpreter is needed.
&gt; as well as a few schemes I suggest Chicken (a really cool implementation with a helpful community), Gauche (also very nice) and the newer Chibi-Scheme. Chibi is quite recent, but it's a very clean implementation, and features are being added at a fast rate.
Cool, actually never used ROOM, STEP or BREAK before..
I like newlisp as well. It's friendly, useful, makes it easy to distribute and deploy what I write in it.
Does Fortran require IEEE floating-point? I misremembered that Common Lisp did, but now see that it just strongly encourages it. *&amp;^%$#@! Intel pseudo-standard FP anyway...
&gt; the incompatible parts of Scheme are mostly superfluous IMHO, except for three things: threading, networking and interface with external programs (FFI) -- and these are also somewhat problematic in Common Lisp. You forgot a consistent module system. r6rs module system was unpleasant to work with. I couldn't even use it in an REPL in mzscheme, while DrScheme sort of worked.
Oh -- I think I got used to thinking of R5RS as the Scheme standard, because I didn't like the way R6RS came out. And I do think that a module system is *somewhat* superfluous (although for large systems it would be important). I like Chicken's module system -- it's very simple and offers what I think is important.
AFAIK, it's the same with Fortran. I am not completely up-to-date with the Fortran standards because I do not develop Fortran code, I just work in a field where Fortran is a fairly standard language and I regularly have to interface with libraries and programs written in it. But in addition to something in the back of my head telling me this, considering that a) current Fortran compilers are backward compilers up to FORTRAN 77 and that b) FORTRAN 77 had its own standards for arithmetic, different from the IEEE 754-1985 standard (which it predates), I think that most Fortran compilers can offer an alternative to IEEE 754. I have access to a stackfull of Fortran-related manuals so if you're really interested in this, I can check to make sure. FORTRAN 77 certainly had its own ideas about arithmetic, I'm not sure how many of them survived in recent standards.
He likes JavaScript if I recall correctly
CLbuild on linux for Sbcl isn't so bad. I couldn't get my courage up to try that with Clozure on Windows. (Does Weblocks work with any CL stack on Windows?)
Racket ( http://racket-lang.org ), from the team that made DrScheme/PLT-Scheme. 
Sorry, I should have said why: because *I* like the PLT/Racket community. 
I also like Racket. I like it because i feels like modern language, has a rich set of libraries (well, it used to be PLT), lots of language geek goodness and a nice FFI. What I dislike is hygienic macros :/ and that's why I won't stop using common lisp any time soon.
When do you stop 403'ing the link for the rest of us? ;)
It'll be ready when it's ready! Join #quicklisp for the real link, though.
Section 2.1 seems a bit of a gaff as well. "In Lisp, numbers as data are self-quoting, whereas lists are not." I thought that numbers were self evaluating. 3 isn't 3 because somehow numbers magically suspend evaluation. Now for lists to be self quoting would mean there would be no expression of algorithms possible as every list would evaluate to itself because the self quoting would suspend evaluation. Useless! Just what was Wadler thinking (smoking?) here? The text following that doesn't precisely inspire confidence either. I don't think there too much that's confusing about the distinction between value of (list 12) and the invalid s-expr (1 2). I think it's instead confusing why anyone would expect a second evaluation to take place.
Can you explain why? I'm a Common Lisper myself so I'm wondering what the fuzz for hygienic macros is about.
Weekend task: get this running.
It's easy to get it compiled &amp; running on SBCL by adding a (:use #:cl) clause to DEFPACKAGE. I couldn't find any sample things on which to use compile-to, though. test.lisp doesn't work: Unsupported form (defmethod foobie (woo) (list woo)) 
Why did he switch to the JRE?
everyone has at least a few versions of jvm at hand.
Lines 26 and 31 imply that he was always intending on targeting either the JVM or the CLI.
Thanks for the tip. I might be able to track down some sample code.
Well, in a few words hygienic macros guarantee that you won't have any symbol clashes (symbols you define in your macro won't clash with the ones in the context in which it expands). To achieve this Scheme jumps to all sorts of hoops (see define-syntax and syntax-case). This makes writing more complex macros complicated (or at least I find it more complicated). CL macros on the other hands are just CL functions (and you can use the whole language while writing them). 
Awesome, Xach. I think half the battle is getting the community behind it. I think this is why previous attempts like Lispy and CL-Librarian didn't get anywhere.
upvote for "mere dabbling". Definitely in line with my experience :/ (fun dabbling though)
He did not. It is a cross-compiler. JRE was target from the start.
*I* didn't downvote you. C is pretty portable, so i don't see how it complicates anything much. Reimplementing bcrypt surely would take much more effort for rather little gain. If the java/C# implementations are free maybe one could save a lot of time by converting to CL verbatim. But the C version would remain the best tested and most certain one. Hmm, perhaps useage of Closure CL would stand to gain, if people aren't allowed access to the bcrypt C lib.
from the article: &gt; Being a good little modern perl programmer, I've chosen to implement this as a small Moose-based class: He lost me right there. To my mind, the whole point of coding in Perl is to NOT have to do everything in some weird object model. If you want to write object-oriented code in a scripting language... learn Ruby! (Edit: Sorry for the repeat posts... not sure how that happened)
TIMTOWTDI
The fixed-width font is barely readable.
Looks fine to me.
&gt; If you want to write object-oriented code in a scripting language... learn Ruby! Or learn Common Lisp!
What no one tells you about implementing your own lisp dialect is that's terribly easy to become * addicted to working on it and * reticent to use other dialects. It's pretty fun to work on your own system, and you start to think about it all the time. The great thing about writing your own system is that you know where everything is, and it becomes easy to add things that you like. Originally, Digamma was a AST walker written in C, and a compiler, also written in C that compiled to a bytecode. Then, I started experimenting with a PreScheme-like restricted dialect, then I realized that I could write a compiler that used the C runtime, then I started playing with other ways of compiling to C, &amp;c. So now, I've the original C system, two compilers (two different Digamma-&gt;C styles), a PreDigamma compiler, and a VM interpreter. The ultimate goal is to move this onto my microkernel, so that I can boot Digamma straight, and get a LispM-like OS, with W7's security (which is built in to the main interpreter). Sure, I still use Scheme48 &amp; STklos for those clients I have that I originally wrote software using those systems, but I've replaced my own lisping with my own dialect. So, yeah, it's fun to write your own lisp system, but it's a gateway drug of sorts; some people put it down &amp; think "Yeah, that was fun," others think "sure, I can stop when I want to, but not right now."
Heheh, ruby troll? &gt; To my mind, the whole point of coding in Perl is to NOT have to do &gt; everything in some weird object model. It is 2010 now, so you do not need to continue treating perl like a mere scripting language. You described adequately why Moose exists: perl's native OOP is a hacked-in monstrosity. Moose changes that, makes OOP simple. Moose is currently one of the most modern versions of the MetaObject Protocol. Out of the box, you will find Moose pretty comparable to CLOS. The author did not need to use Moose to prove his point (a sub would have been fine -- poor man's objects and all that), but if you see people manipulating complex data in perl without Moose, they are a bit behind the times. Moose is just a package. perl -MMoose -- done. Or "use Moose" -- better.
I made a hash table, for fun. Then i think.. Why not treat them as symbols. Then i think hmm lets make a Cons thing.(With reader) Then i think: hey why not make a function type so the cons can be interpreted as function useage.(Use a hashtable to connect the first elements of s-expressions to functions) The actual state of that little project is that the hashtable and reader/destructor of cons objects is pretty well-tested. the evalling is completely untried/tested.(but i don't expect it to be hard to get to work) Only [the hash table](http://ojasper.nl/readmes/HASHTABLE.html#HASHTABLE) online atm.(that link is just ftr) And i don't have any garbage collection at that point.(Though there are C libs for that) Anyway, from doing it, i can imagine that people would find it fun/comforting. And they'd consider themselves rather clever the way they do some things. However even if those things are actually clever, are they really useful/improving on existing lisps? The way i was going in writing in C, i don't really think so; the C is limiting the thought more than exploring it from an existing lisp implementation. I think i was/am closer to that when i write stuff like [that type calculation thing](http://ojasper.nl/essays/Type%20calculation.html#Type%20calculation) and looking into simplifiers for those types(I have made some progress.. i should be making another post, the linked article needs better writing too), or even when i was exploring 'new'(well, i hadn't come across them) ways to use macros. I made it mostly when my computer was broken and an old laptop my mom gave me can't connect to the internet. I only had C.. I guess it will stand still(except of maybe me putting on my website) until either my computer breaks again..
I addressed this at the bottom in "What about a native approach". To sum up, unless you are a crypto professional, you should not implement your own crypto routines unless you have no other realistic choice. For the purposes of this discussion, porting Java/C# code to Common Lisp counts as "implementing".
Well, I never claimed novelty, although I *am* fond of my type directed syntax expansion (type inference at syntax expand time, with adjusted rules in syntax-rules), semi-predicates (for fun like porter-stemming with tries), &amp; misc. little tweaks here-and-there. My purpose wasn't to change the face of lisp, but to support what I work on, and make it nice (basically, lots of textual analysis &amp; unix programming). I took the Lush/Clojure approach and made collections (sequences &amp; maps) applicable, and have boot strapped most of the system (i.e. PreDigamma, the two compilers &amp; the interpreter are able to run themselves). I wanted to avoid "thinking in C" too much, even with a nice set of internal functions to help reduce "C-isms." So, is it useful? I think so; as I said, I've replaced all my current lisping/scheming with my own interpreter. All new code going to clients, and most of my internal stuff (data processing, recovery, websites, &amp;c) is done using it, so I'm happy. As for "improving" the sate of Lisp holistically, this was never a goal; I started working on this after seeing the Otter presentation at LispNYC, which failed to materialize. I thought "what the hell, there's some interesting nuggets to start with, I'll take a stab at it." So, there's no plan to make pronouncements about "100 year languages" or the like; it's more apt to say "so long as cynicalmulch hasn't been hit by a bus language." :D
Oh i didn't claim novelty when i wrote that article earlier either.. I didn't read from your earlier post that Digamma did something similar to 'type calculation'. Have some page somewhere that describes it?
&gt; Oh i didn't claim novelty when i wrote that article earlier either.. I didn't &gt;read from your earlier post that Digamma did something similar to 'type &gt;calculation'. I must say that this is one of the reasons I dislike textual discussions; I feel like they are terribly inefficient wrt participants tendencies to talk past each other :D **I** didn't meant to imply that you claimed any novelty *either*; I was just responding to how your points corresponded to my thought process :D As to Digamma &amp; types, I've been working on H-M inference for the compilers, but esp. PreDigamma, so that I can unbox types (part of PreDigamma's restrictions is that it doesn't have the same level of support for the numeric tower as a unrestricted Digamma compiler would have. While it still has rationals &amp; complex, they are restricted and their operations are specialized). The syntax-rules expansions are supposed to help wrt writing the best code possible for compilation; they don't really change anything at interpreter time. It complicates things semantically (I have to make sure that the functions behind don't break where people would expect), but it should hopefully make for better code. I've a [terribly outdated blog](http://corescheme.blogspot.com) and I'm working on getting my server back up; it runs Digamma to host the site &amp; all apps, but it suffered a disk failure, and I didn't have the time to fix it until recently. I'm just glad I used distributed version control :D 
&gt; I must say that this is one of the reasons I dislike textual discussions Well, it was cleared up quickly enough. I'll look at that link a bit later.(minding that it is terribly outdated, of course) Btw, reading up on the Hindley Milner algorithm, for the record, that isn't what that type calculation is(not implying you said it was) essentially it is just attaching to some functions which i call 'base functions' other functions which calculate the type output based on the type input. Then if a new function is defined, it just uses those functions analogously to how the computation would have been done, except it works on the type. With intermediate steps being to simplify it all the time. Of course if you define a function, it needs the types of the arguments. In a language one would either just provide those, or you just use the function, and then it sees what types the input are and makes instances of the function based on the different types. Anyway: &gt; The origin of this algorithm is the type inference algorithm for the simply typed lambda calculus Me not knowing this before really means i should perhaps be looking at it better. Perhaps i am being silly and what i am doing is a subset of that algorithm or something.. Still, i do think there are some good ideas not yet implemented in lisps there regarding the open-ness and interaction to the user about the types of the functions/values.
http://quicklisp.org/screencasts/ has a screencast.
Symbolics has a VLM for OS X in development - I believe you can go sponsor them. I think lispm's done just that.
[Symbolics' Virtual Lisp Machine (short VLM)](http://pt.withy.org/publications/VLM.html). It was originaly developed for Tru64 UNIX. But there exists a port for amd64 Linux. http://labs.aezenix.com/lispm/index.php?title=VLM_On_Linux http://en.wikipedia.org/wiki/Open_Genera (The "Lisp Machine" I use is SBCL + Slime + GNU/Emacs)
A little late to the party, but my favorite lisp is Emacs Lisp. Sure, it is old and clunky, but it lives inside my favorite editor, and it does the job when I need it to do the job, and despite being old, it can still do lots of fancy things. 
[Here](ftp://ftp.parc.xerox.com/pub/lfg/) is an emulator for Xerox's D-machines, and a sysout containing Ron Kaplan and John Maxwell's LFG Grammar Writer's Workbench. It has libc problems with current Linux distributions, regrettably - I've made it work in the past.
I'm 32 years old and what is this?
Hey, why this has been downvoted? Maybe "that's dumb" sound pejorative? What I meant was "c'est bête", in the same sens as "c'est dommage" (french), maybe I should have said "that's too bad", or "that's sad" but it didn't feel the right words either. Anyway, I didn't want to offense anyone, so sorry :-).
Well (author here), the main idea is that emacs lisp is dynamically scoped. If you are a lisper, you probably get at least the difference between dynamic scope and lexical scope. The key question of this experiment is whether, using a macro which examines the code in its "body" we can simulate lexical closures in a way more intuitive and easy to use than emacs lisp's "lexical-let". The key idea is that lexical-let requires you to explicitly name and bind the variables over which you wish to close: (setq thunk (let ((y 10)) (lexical-let ((x 11)) (lambda () (+ x y)))) (funcall thunk) -&gt; error, y not defined You see? Because we did not explicitly closer over y in the above expression, we don't capture it in our "closure". This seems like a pretty unintuitive and poor behavior. This macro uses codewalking to gather the free variables in an expression and automatically generate the appropriate closing lexical-let expression, so that (setq thunk (let ((y 10) (x 11)) (delay (+ x y)))) (funcall thunk) -&gt; 21 Which is the correct desired behavior. Using the same technique, one can implement a `lexical-lambda` in elisp which automatically closes over the environment as if it were lexical, which I think is pretty neat. Since most people don't hack elisp seriously, and because CL and Scheme are already lexically scoped, you might wonder why anyone would care, but I thought, after writing the code, that it was a pretty good example of advanced macro writing that might be applicable in a modified form in CL or Scheme (where a similar trick is used to write apparently non-hygienic macros - a trick I didn't understand until I wrote some more mundane macros in CL/EL). I hope that answers your question?
&gt; . The key question of this experiment is whether, using a macro which examines the code in its "body" we can simulate lexical closures in a way more intuitive and easy to use than emacs lisp's "lexical-let". See, right there is where you lost me. I program in CL, scheme, and elisp on a regular basis. In elisp, i don't find it intuitive that a macro capture the values of free dynamic variables and re-instate them... if i want closures i use lexical-let, and if i wanted a first class dynamic environment i'd use DYNAMIC-WIND. &gt;Because we did not explicitly closer over y in the above expression, we don't capture it in our "closure". This seems like a pretty unintuitive and poor behavior Maybe so if you're not used to dynamic scope, but it's exactly the behavior i expect! Honestly, i usually glaze over as soon as someone starts talking about 'intuitive' behavior... i didn't pop out knowing how to lisp. Capturing the value dynamic variables is not a lexical closure, nor is it intuitive for an elisper. Your macro doesn't really close over anything... it just captures the values of free variables. This is not a closure, dynamic or lexical. Closures capture bindings, you are just capturing values. That this particular behavior is actually non-intuitive for those used to lexical closures becomes apparent pretty quickly : ;;; an example of a lexical closure using LEXICAL-LET ;;; Notice that the binding itself is captured, so if i later mutate it, ;;; the closure sees the new value. (funcall (lexical-let ((i 1)) (lexical-let ((c (lambda () (print (+ 1 i))))) (setq i 4) c))) =&gt; 5 ;;; Now using your force and delay macro we see some _very_ unintuitive behaviour (force (let ((i 1)) (let ((c (delay (print (+ 1 i))))) (setq i 4) c))) =&gt; 2 Ok, so the variable i inside delay is neither a dynamic nor a lexical binding... it's in a 3rd new type of environment... 'delayed scope' perhaps? Creating a new type of environment that acts very different from the existing well known environment type is not something i'd label as "intuitive". The following forms give me errors, so i can't comment further : (force (lexical-let ((i 1)) (lexical-let ((c (delay (print (+ 1 i))))) (setq i 4) c))) (force (let ((i 1)) (let ((c (delay (print (setq i (+ 1 i)))))) (setq i 4) c))) &gt; sing the same technique, one can implement a lexical-lambda in elisp which automatically closes over the environment as if it were lexical, which I think is pretty neat. You keep saying things like 'close over' and 'lexical environment', but the code you demonstrate doesn't close over anything, let alone a lexical environment. I think the fact that you call this 'intuitive' is what has me confused.... my intuition perhaps differs greatly from yours, but when i hear the term 'lexical closure', i expect something that captures a lexical environment. EDIT: I hope i didn't come off as overly negative, i have actually done something similar in CL before finding a 'better way'. It's really just the use of the word 'intuitive' i didn't like. If this type of force-delay works better for you than simply using lexical-let and lexical-lambda, i don't see anything wrong with that... just make sure you document the non-intuitive behavior :) 
Your points are very interesting, and I don't take any offense. I think it is particularly interesting that, I think, if we restrict ourselves to programming without mutation, then my macro does, indeed, provide the equivalent to an automatically generated lexical closure. I am in the middle of an experiment, but I will resume this discussion when I am free to respond completely. 
&gt; think, if we restrict ourselves to programming without mutation, then my macro does, indeed, provide the equivalent to an automatically generated lexical closure. If we restrict ourselves to a subset of elisp that doesn't allow mutation or dynamic bindings, or true lexically scoped variables, then sure. I'd argue that it would be a pretty useless elisp implementation, and certainly not 'intuitive' for those used to lisp. Perhaps i'm just missing the point of such a crippled implementation of promises when LEXICAL-LET and LEXICAL-LAMBDA exist. If one wants lexical closures, they are there for the using, and you can still use dynamic scope when you want. If you're just experimenting and learning about various macro writing and implementation techniques, then more power to you, it's a good thing. If you really want a pure-functional subset of elisp that supports promises (or even implicit lazy evaluation), you'd be better off writing your own EVAL.. you're already 3/4 of the way there really... your DELAY is really an embedded compiler of sorts as it is. You've probably seen this one before, but i find it an excellent reference for this sort of thing : http://home.pipeline.com/~hbaker1/MetaCircular.html . Specifically, 'PERFORM "CELL INTRODUCTION" USING "SYMBOL-MACROLET"' gets you mutable lexical bindings, and 'EMULATE "FUNCTION" USING "MACROLET"' gets you closures. Also, if you're interested in promises, The Kernel Programming Language allows for a completely seamless FORCE by re-introducing fexprs into the lispers toolset. http://web.cs.wpi.edu/~jshutt/kernel.html 
I think we may be misunderstanding one another. This implementation uses lexical-let under the hood, the primary feature it provides is automatically detecting the non-locally bound variables inside an expression and generating the lexical-let around them. One of the primary motivations for implementing this (`delay` is merely the simplest example) is that Emacs Lisp _does not_ provide `lexical-lambda`, which is what this library implements. To me the intuitive behavior of a lexical-lambda form, if it existed, would be to capture the _lexical_ binding of any variables which were not internally bound by it, which is what my implementation of lexical-lambda does. Perhaps the example which precipitated this implementation in my mind would be helpful. I have a small set of functions for working with alists. (alist&gt;&gt; :x 10 :y 11) -&gt; ((:x 10) (:y 11)) (alist&gt;&gt; '((:x 10) (:y 11)) :z 13 :x 14) -&gt; ((:x 14) (:y 11) (:z 13)) finally (alist '((:x 10) (:y 11)) :x) -&gt; 10 Suppose you want to write something like `alist-cons`, which takes an alist, a key, and a value, and conses that value onto the value found via the key, and then returns an alist where the key is associated with a new value. You can implement that with a more general function called `alist-commute`: (defun alist-commute (alist key f) (let ((val (alist key))) (alist&gt;&gt; key (funcall f val)))) then (defun alist-cons (alist key val) (alist-commute alist key (lambda (list) (cons val list)) Is an relatively obvious implementation, except that when you run it, val is bound incorrectly because lambda has dynamic binding. To get this to work in elisp, you have to write (defun alist-cons (alist key val) (alist-commute alist key (lexical-let ((val val)) (lambda (list) (cons val list))) Because there is no lexical-lambda. As I wrote lexical-lambda, it expands almost to the above, except that the macro also generates lexical bindings for `cons`. Both sets are generated using `lexical-let` and `labels`, so, unless I am missing something, mutation will, in fact work as expected. On the point of mutation, suppose I do: (setq counter-functions-thunk (let ((counter 0)) (delay (list (lambda () (setq counter (+ 1 counter))) (lambda () (setq counter (+ 2 counter))) (lambda () counter))))) (let* ((counter-functions (force counter-functions-thunk)) (counter+1 (car counter-functions)) (counter+2 (cadr counter-functions)) (counter-val (caddr counter-functions)) (trace-values nil)) (funcall counter+1) (push trace-values (funcall counter-val)) (funcall counter+2) (push trace-values (funcall counter-val)) trace-values) ; -&gt; (3 1) In other words, the the delay creates an effective shared context for its contents. Perhaps I don't understand the scenario in which mutation will fail? You are right that the main purpose of this exercise is to practice writing a fun macro, but I also think that a lexical-lambda form is a nice think to have, given there isn't one, even if it doesn't have exactly the right semantics. I am pretty certain that there are scenarios in which the `lexical-let` macro has improper semantics too. Edit: by the way, "intuitive" was the wrong word. Certainly, in elisp, dynamic scoping is the more intuitive behavior - I should have said that sometimes, it isn't the behavior I want. Also, thanks for the reading recommendations, though I have seen both before. 
&gt; I think we may be misunderstanding one another. That's entirely possible.. you're not making a lot of sense to me, so i completely understand if the inverse is true as well :) &gt; To me the intuitive behavior of a lexical-lambda form, if it existed, would be to capture the lexical binding of any variables .... but that's not at all what you are doing. LET, in elisp, establishes dynamic bindings, and you are simply creating lexical bindings that shadow the dynamic bindings, and copy the value. This is not capturing lexical bindings... but dynamic values. If you want lexical bindings, why are you using LET and not LEXICAL-LET in the first place? I think this is where the majority of my confusion lies. You keep talking about capturing lexical bindings, and then simply copying dynamic values, and creating lexical bindings out of those. I'd argue that changing the behavior of one of the most common elisp operations is not intuitive at all, and this solution is significantly worse then simply using LEXICAL-LET as it was intended. a LEXICAL-LAMBDA would be a lambda where the arguments are lexically scoped, not one that captures dynamic bindings. &gt; Is an relatively obvious implementation, except that when you run it, val is bound incorrectly because lambda has dynamic binding. This is just incorrect. Variables have bindings, bindings live in environments, lexical in the static env, and dynamic in the run time env. LAMBDA does not 'have dynamic binding', it captures whatever binding exists for any given free variable. This is trivially demonstrated : (setq *closure* (let ((a 1)) (lexical-let ((b 2)) (lambda () (print (+ a b)))))) (let ((a 10) (b 20)) (funcall *closure*)) =&gt; 12 The LAMBDA form in this case captures both a dynamic binding (a) and a lexical binding (b). It is the BINDING that is lexical or dynamic... not the LAMBDA form, which is happy to use whatever binding exists. Your function fails because DEFUN creates dynamic variables, not because LAMBDA doesn't copy values. The solution is to create a lexical-defun, not to create entirely different scoping rules and dynamic closures. (defmacro* ldefun (name args &amp;body body) `(defun ,name ,args (lexical-let ,(mapcar (lambda (arg) (list arg arg)) args) ,@body))) Now, all the parameters of the function have lexical bindings, and your function works as expected : (ldefun alist-cons (alist key val) (alist-commute alist key (lambda (list) (cons val list)) Here, ALIST, KEY and VAL have lexical (static) scope, and LIST is dynamically scoped, though since it never escapes it doesn't matter here. If we needed LIST to also be lexically scoped, we'd then need LEXICAL-LAMBDA : (defmacro* llambda (args &amp;body body) `(lambda (,@args) (lexical-let ,(mapcar (lambda (arg) (list arg arg)) args) ,@body))) This will allow us to close over the lambda parameters as well : ;;;; somewhat contrived : (ldefun alist-cons (alist key val) (alist-commute alist key (llambda (list) (cons val (lambda () list))) ... now every variable in that expression has lexical scope. &gt; except that the macro also generates lexical bindings for cons. I'm not sure what you mean here... you use LABELS to create a lexical binding of the CONS function? why? &gt; Perhaps I don't understand the scenario in which mutation will fail? does this example help? (setq counter-functions-thunk (let ((counter 0)) (delay (list (delay (setq counter (+ 1 counter))) (delay (setq counter (+ 2 counter))) (delay counter))))) There are 4 different bindings of COUNTER there, which is most likely not what the author intended, and is certainly not lexical scope... there is only one lexically apparent binding of counter, which is a dynamic binding, yet you create 3 more bindings in 3 new environments. And it still leaves me asking... if you want lexical scope, why not just use lexical scope? (setq counter-functions-thunk (lexical-let ((counter 0)) (lambda () (list (lambda () (setq counter (+ 1 counter))) (lambda () (setq counter (+ 2 counter))) (lambda () counter))))) This has the same behavior as your version with the single DELAY, but has the distinct advantage of not requiring hundreds of lines of support code, doesn't create new bindings out of thin air, and has semantics a lisper would find quite intuitive (YMMV). To create true lexical scope, you need lexical bindings. Here's a sketch of what a macro might do to simulate a lexical binding form. Note that the names of the lexical variables are compiled away completely in the closure, the only thing that exists at run time is the reference to the binding in the lexical environment : ELISP&gt; (let ((closure (let ((env (vector 1 3))) (symbol-macrolet ((a (aref env 0)) (b (aref env 1))) (list 'lambda '(c) `(let ((env ,env)) (funcall ,(lambda (c) (setf a (+ a b c))) c))))))) (list closure (funcall closure 1) (funcall closure 1))) =&gt; ((lambda (c) (let ((env [9 3])) (funcall (lambda (c) (aset env 0 (+ (aref env 0) (aref env 1) c))) c))) 5 9) That is what lexical closures are about... capturing the lexical environment, and really that's almost all there is to implementing something like LEXICAL-LET. Of course, we're exploiting symbol-macrolet's lexical scope here... if we didn't have that, we'd have to walk the code and essentially be writing a compiler. EDIT: This sort of 'manual' closure is very useful when programming in languages that don't have lexical closures. I do something like this in C quite often.
Now that I have had more time to read your posts carefully, I see your point. My macro should really be called "create lexical bindings for all values in the dynamics scope which are free in the body of this macro," and this is different from creating a lexical closure, which creates lexical bindings, which, if mutated, behave as you would intuitively expect. My macro creates a lexical closure behind the scenes, but it doesn't affect the bindings which is shadows - in fact, it could not do so, because those may not even exist anymore when the lambda is evaluated. I guess a better concise name for what I call `lexical-lambda` would be, `lambda-capturing-lexically-free-values`? Thanks for spending the time to explain! This has certainly been clarifying. 
I use Chicken Scheme. My favorite is Common Lisp, and I've done a fair bit of CL programming. However, CL (and Clojure) doesn't play well at all with other languages/programs. Clojure, SBCL, and all the other fast CL implementations are very heavyweight, don't play nice with C, have lame module systems, and don't have good support for Unix idioms (forking, shelling out, writing filters, etc). I've eventually settled on Chicken Scheme because it fits very well in the Unix environment: - Simple, easy FFI - Fast startup time; fairly lightweight - A interpreter and a compiler that produces reasonably-sized executables - Nice module system with some decent library support 
Scheme is a lisp-1 so having local variables with the same names as global functions becomes a problem: (defun foo (x) x) (defmacro m (y) `(let ((x ,y)) (if (foo x) x (error "shit!")))) (let ((foo 3)) (m 9))) This would be an error because the expansion of (m 9) would try to call 3 as a function. To get around this problem, scheme has hygenic macros which are much more complicated and less pleasant overall than CL macros. Hygenic macros are basically a DSL for syntax transformations instead of just using CL functions. On the other hand they *are* slightly more correct than CL macros, and they are just as powerful. Hygenic macros were my main complaint with Scheme for a long time, but I eventually just sucked it up and learned them.
Thanks!
&gt; Well, it was cleared up quickly enough. Definitely. I had a symbolic logic professor who used to joke about shadows on the net &amp; Parmenides. :D &gt;I'll look at that link a bit later.(minding that it is terribly outdated, of course I'll update it shortly; I've been putting out fires wrt everything else that's going on, and I've not been able to keep up with both app development &amp; blogging. &gt;Btw, reading up on the Hindley Milner algorithm, for the record, that &gt;isn't what that type calculation is(not implying you said it was) &gt;essentially it is just attaching to some functions which i call 'base &gt;functions' other functions which calculate the type output based on &gt;the type input. Then if a new function is defined, it just uses those &gt;functions analogously to how the computation would have been done, &gt;except it works on the type. With intermediate steps being to simplify &gt;it all the time. Yes, this is exactly correct; it attempts to deduce an operation's types from what is already know from base types. This is why it's common to use a simple logic language like Kanren or Datalog to check types (and why things like Qi have prolog all around). &gt;Anyway: &gt;&gt; The origin of this algorithm is the type inference algorithm for the &gt;&gt; simply typed lambda calculus &gt;Me not knowing this before really means i should perhaps be looking &gt;at it better. Perhaps i am being silly and what i am doing is a subset &gt;of that algorithm or something.. From just glancing at what you're doing it seems like you're working on something *similar*; the algorithm in question is applied via logical reductions, which is why there are base cases. It would depend on how you're actually deducing the types in your calculations, which is why I say *similar* &amp; not *the same*. &gt;Still, i do think there are some good ideas not yet implemented in lisps &gt;there regarding the open-ness and interaction to the user about the &gt; types of the functions/values. For me, the areas that I wanted to improve upon in Digamma were: * Posix integration * Batteries Included * Data processing wrt it's use in Posix environments (pipelines &amp; what not) * Web out of the box * Types &amp; their application * System interaction: there is the notion of interpreter *ticks* in Digamma, which aren't shared among the Erlang-style processes (these are shared-nothing W7 environments), but are shared among green threads (which are really just delimited continuations). The Default system includes two types of schedulers (cooperative &amp; preemptive), but allows for users to create their own, if they so desire (I'd like to see EDF &amp; other types of schedulers, but this would be bound to the notion of *interpreter*, rather than *wall clock* tick; that could be changed though, if I see that it doesn't break the platform-neutral nature). * All the fun GHC &amp; Haskell are having on multi-core isn't out of reach to lisp; Lispers had Connection Machines &amp; the like for some time, so it's a solved (if non-trivial) problem with lisp. I'd like to see more multi-core &amp; multi-machine open source lisps (I have a basic grid for digamma, and I'd like to expand that). **tl;dr**: yes.
It's essentially a RAM concern. I have the smallest available Linode (20$/mo, 512mb of RAM) and sbcl 1.0.42 runs just fine with hunchentoot, postmodern and some other libs loaded. I haven't tried a weblocks deployment and subjected it to heavy load but you should be able to get by alright and you can always bump up the ram on your instance. Or use EC2 as at least one lisp-powered startup I'm aware of... [tech.coop](http://tech.coop/index) also offers hosting services and considerable Lisp experience.
&gt; Depends on which VPS you use I've heard of huge problems with Virtuozo, but also of big problems with Xen. &gt; ...RAM, etc. I have the smallest available Linode (512mb of RAM) Do you run any other servers on that Linode - for example a DB? What Linux distribution did you choose? &gt; sbcl 1.0.42 runs just fine. It runs just fine out of the box? Or did you have to do special configuration, such as limiting the maximum amount of memory SBCL will allocate?
&gt; Do you run any other servers on that Linode - for example a DB? What Linux distribution did you choose? I run Archlinux and when I was prototyping a web site in CL, ran postgres, mysql (just backing wordpress as I recall), lighttpd and hunchentoot without issue. &gt; ...special configuration No assembly required. sudo pacman -S sbcl and you're off to the races. :)
I use EC2 to build Quicklisp stuff and it works fine. It uses Xen underneath from what I understand.
&gt; I've heard of huge problems with Virtuozo, One virtuozzo hosting provider I've tried was counting virtual memory used rather than physical. I had to ditch them. &gt; but also of big problems with Xen. I neither had any problems with Xen nor heard about any. It is pretty much like a real OS. No difference at all. We use Xen on our physical server for better manageability. So far it works as advertised -- absolutely transparently. Lisp implementation we're using is SBCL 64 bit. I also tried running SBCL on VPS, runs fine. (&lt;http://prgmr.com/xen/&gt;, Debian 5.) &gt; Do you run any other servers on that Linode - for example a DB? My friend uses Linode for relatively busy and complex site which intensively uses database (MySQL). (Not lisp, though.) They had problems with I/O performance -- it is slow from time to time, so large data imports run slower than on a real server. No other problems. &gt; such as limiting the maximum amount of memory SBCL will allocate? There is implicit limit anyway, AFAIK. So it is a good idea to set it to a sane value. What is sane depends on nature of your applicaiton and available RAM.
&gt; We use Xen on our physical server for better manageability. So far it works as advertised -- absolutely transparently That's great to hear. &gt; I neither had any problems with Xen nor heard about any. I've heard of frequent problems with especially SBCL's memory allocation strategy when running in VPSes. I don't know of any particularly authoritative statements about this - and most reports are lacking in critical details - but web searches such as "xen memory allocation sbcl" bring up a decent number of references. For example [this topic on LispForum](http://www.lispforum.com/viewtopic.php?f=2&amp;t=376) from June 2009. A snippet: I'm doing OK on a Xen VPS with 512Mb RAM, after constraining the runtime's heap with --dynamic-space-size 256 &gt; &gt; such as limiting the maximum amount of memory SBCL will allocate? &gt; There is implicit limit anyway, AFAIK. So it is a good idea to set it to a sane value. I don't know about this. Sure, you'll eventually run out of e.g. swap space. But everything I've read (perhaps before today) implies that you have to artificially limit the Lisp process's runtime heap. If I have a huge burst in user traffic, I'd like the OS to use its strategies to manage memory, rather than having the Lisp image simply die.
&gt; Is that still the case? I don't even think it was a case. Perhaps some VPSes were very limited (particularly, Virtuozzo ones), but you get what you pay for. &gt; I've heard of the successful deployment of CL-based websites, but I've never seen specifics provided. From what I can tell, it usually just works. So you don't need to worry about anything, just deploy it and test. 
&gt; I've heard of frequent problems with especially SBCL's memory allocation strategy when running in VPSes. It might be that VPSes are just memory-constrained (more constrained than development machines, that is). 32-bit version of SBCL has default heap size of 512 MB, so using default on VPS with 512 MB of RAM might be a problem. 64-bit version has even higher default. &gt; you have to artificially limit the Lisp process's runtime heap In vanilla SBCL it is always limited, it cannot grow indefinitely. If you do not provide `--dynamic-space-size` option it uses the default. &gt; If I have a huge burst in user traffic, I'd like the OS to use its strategies to manage memory, rather than having the Lisp image simply die. Swapping works slowly, especially on VPSes. If you're heavily swapping, site will look like it is dead. I've found that it is better to disable swapping completely. (YMMV.) As for bursts in traffic, they should not add to memory usage. If you have threaded server, there is optimal number of threads. Say, if you have 2 CPUs, 2-4 threads would be optimal, depending on amount of I/O. If you handle more than 4 requests at once (running more than 4 threads) it won't work any faster -- only slower. So it is a better strategy to queue those requests until you can server them. Sometimes this queue is implemented in web server itself, sometimes you can use some external balancer (haproxy or pound can do that, don't remember exactly) for you. If your queue goes full it is better to throw `503 Service unavailable` error. Then users will notice that site is overloaded and they will hit refresh some time later. I think it is better to report problem honestly to a limited number of users than to make it very slow, unusable for everyone. If your site is not too dynamic, throwing cache in front of it might be a good idea. Varnish cache can gracefully handle situations with overloaded backend servers. Another thing you might need to consider is sessions -- object your site allocates for each visitor. (Depending on web framework, for each hit.) To be safe you might want to limit maximum amount of concurrent sessions (e.g. if there are more than 10000 purge oldest). 
Which CL? Was special configuration required? Which OS? Which distro? How much RAM?
SBCL, x86-64, Ubuntu 10.04, 7GB-20GB of memory, depending on instance type. No special configuration used.
&gt; tech.coop also offers hosting services and considerable Lisp experience. Do you have experience with tech.coop? Can you recommend them, etc.?
way back when i did this on my vps with 256mb of ram, i had to use command line arguments for sbcl to reduce inital memory size. after that it worked. though, sometimes a big asdf-install (like hunchentoot) would error out from lack of memory, but once the compile was done it was fine. my website is super small-time though.
I don't have any experience with their products, but Drew Crampsie has gone out of his way to keep wiki.alu.org and other such resources alive.
SBCL had problems with the address space iirc. You can bound the SBCL Core Image Size. On the other hand, clisp has a nice fastcgi-interface as far as I know. So the question is whether a clisp-fastcgi-script isnt the best choice for simple webservices.
Thanks for the comment. I'll have to check out CLISP+fastcgi. &gt; So the question is whether a clisp-fastcgi-script isnt the best choice for simple webservices. That's absolutely *a* question, but really not my question. I will be deploying decently sized websites, not simple web services.
I don't have personal experience with them, no. But I've heard good things elsewhere and with drewc running it you ought to be in good shape. He knows what he's doing.
SBCL just wants a decent chunk of address space for heap, yes. I would not call it a problem. Just a requirement.
I'm running a hunchentoot website on slicehost using sbcl. The problem is sbcl crashes the server every time I start it, apparently a xen problem. My slice is 64 bit ubuntu, and my workaround has been to make chroot jail with a 32 bit debian installation and running 32 bit sbcl, which does not crash. Obviously if you can start from fresh, just go with 32 bit from the go. I've had problems with lack of ram because I'm using the smallest slice size, but you can pay to avoid that (or use less ram)
The Xen issues I've run into with SBCL were pretty much limited to threads, and have since then been fixed. (Running SBCL under Xen with threads used to generate bogus FP exceptions at some point, etc.) I'm pretty sure the folks at tech.coop run 64-bit SBCL on Xen, so I suspect the problem is not a deep one. If it's just the address space requirements, try eg. sbcl --dynamic-space-size 128 and creep upwards from there if it works, till you find a limit that's enough for you and not too much for the system. The default SBCL dynamic space size is 8 gigs on x86-64. Xen crashing due to someone trying to mmap more than there is sounds pretty extreme to me -- if that's the case, it is probably your hosting provider killing your instance due to exceeding some VM limit. 
This is true amongst many 3rd generation languages.
Well, yes and no. CL and Java (among others) are languages that need a lot of memory and have their own views of how stuff should be done. They are not very good fit for the *nixy world we live in. I wish there were good alternatives to *nix, but sadly, there aren't. EDIT: Markdown, please Die In A Fire.
No and yes. 1. There are many different implementations of CL. CLISP, ECL and GCL are much less picky. 2. I don't see how address space reservation is a problem. How do you know if it is a good fit or not? Is reserves space, then it can use it. 
This sounds like pretty good news. I'll have to switch from clbuild :)
Others have claimed it, others have failed it.
I'm excited and encouraged by the early positive reaction, but you're right - can't count the chickens before they hatch.
Excellent, thanks for all your work xach!
What? No Enterprise-Solutions? How dare you!
Looks very promising (judging by the screencast)
Sounds very good! I just wish this "lack of libraries" complain just goes away. 
To be replaced by "There's no lack of these half-baked libraries!" But at least they'll be easy to install.
I'd love to see more coming-together in the Lisp community rather than splitting-apart. We already have c.l.l, LispForum, and the infinite mailing lists for specific packages and CL implementations. We have both Cliki and the ALU Wiki. etc. I'm all for testing out better solutions, but it'd be great to see some of them "integrated back into main" so to speak. EDIT: "integrated back into main" was a poor choice of words. "elegantly transitioned to" is better. For example, if the community enthusiastically moves to this mailing list, it would be great to "import" the discussions from LispForum so that they appear in the list's archive - making it tremendously easier to search for past discussion.
many experts don't use c.l.l anymore. Spam, noise, ... Not everyone still wants to use Usenet clients. The Google Groups interface is full of spam... No filters. Too primitive. Lispforum would be possible, but I'm not using that either. Not sure why, but I don't like that particular bulletin board style. ALU Wiki is not a good place to get infos from experts.
Google really dropped the ball on their Usenet interface. It's sad. LispForum doesn't have threaded discussion, which sucks. My mention of the Cliki and the ALU Wiki was meant to be an example of existing "splits" in the community, not as suggestions of Lisp forums.
&gt; many experts don't use c.l.l anymore. Are the experts going to be on your mailing list?
That's not my mailing list. But some seem to have subscribed. The mailing list was created because of a discussion started by Dan Weinreb, where Hans Hübner proposed it and others like Edi Weitz supported that idea. having a mailinglist also does not mean it will be 'alive' - one has to see if it is useful. Peter Seibel and Sam Steingold joined.
This is a coming-together. Folks this list is aimed at haven't had a common place to talk since cll went down the drain.
Hans just posted an introductory email to the list: Hi folks, this list has been created in response to an email by Dan Weinreb, addressed to a bunch of Common Lisp programmers that he knows, who wondered where to turn to for some advice on the existence of certain Common Lisp libraries. comp.lang.lisp was deemed not to be the right place, because it is full of spam and requires sophisticated special-purpose software and regular care taking to be readable. Thus, we came up with the idea of a mailing list targeted at people who already know and use Common Lisp and who don't want to discuss the merits of it or how other languages are worse or better. This is an implementation-agnostic list. Discussing any Common Lisp implementation is on-topic, although implementation specific questions are probably better discussed on the respective mailing lists. We generally also know why we chose one implementation over another, so "my implementation/your implementation"-type discussions should not be started unless they are technical (as opposed to license-oriented). Be inclusive and friendly, accept commercial and non-commercial developers. Let's not use the word "free" here, unless it is about beer. :) -Hans 
It works for CPAN.
This is a good idea. I only have one doubt: MLs tend to be closed communities, or, anyway, less open than a newsgroup. If this list is going to drain cll, it will perhaps contribute to sending CL even more underground, which I doubt it's a desirable outcome.
I meant a coming-together of the Lisp community as a whole. That is: comp.lang.lisp + LispForum + ... + this newly created sub-community. blue1_ says it well in [his comment](http://www.reddit.com/r/lisp/comments/d93vc/new_mailing_list_for_regular_users_of_common_lisp/c0yh0ou). EDIT: I just checked c.l.l and didn't see the list announced anywhere. That makes it seem like even less of a coming together.
The mailing list is a few hours old and now has 74 subscribers.
I've found this to vary by community somewhat. Among people who entered internet culture in the late 1990s or more recently, I find lots of people literally have no idea how to use newsgroups: they've never used a newsgroup in their life, aren't sure how you'd set it up to be able to post, etc. Mailing lists are technologically more accessible imo, as evidenced by the thousands of mailing lists on clearly not-very-tech-savvy topics at places like Yahoo Groups. That was definitely my experience in the late 1990s transitioning a music fan-discussion group that I co-ran from Usenet to a mailing list. We got a lot more young/non-tech-savvy people, more non-university-student types, and generally a bigger influx of subscribers. Of course, this is a Common Lisp mailing list, so probably not too many people are non-tech-savvy. But still I think many potential users are probably not newsgroup regulars. I'm not even anymore; ever since my university and ISP both dropped their NNTP servers I haven't figured out how to reconfigure my news client to post (probably via some sort of NNTP-email gateway?), so I just stopped using it.
look up eternal-september.org
I just watched the screencast. Looks great!
Have you ever used Maven in Java? Same problem. 
This list is not meant to attract the whole lisp community: it is named "pro" after all. I hope that this migration of the pros won't leave the novices without help. After all, they are the pros of tomorrow. On Pro there was a bit of talk on a possible parallel list for less proficient common lispers (the "cons"!)
&gt; This list is not meant to attract the whole lisp community: it is named "pro" after all. My comment was ambiguous. By &gt; a coming-together of the Lisp community as a whole. That is: comp.lang.lisp + LispForum + ... + this newly created sub-community. ...I didn't mean the combination of every Lisp newsgroup, forum, and mailing list into a single one. Rather I meant something like - for example - choosing a common messaging platform (ideally with solid interfaces/gateways for web, email, and NNTP) and creating an appropriate list/hierarchy of discussion groups within it.
You miss the point. Usenet is more than dead and only old people know about it. Forcing people interested in Lisp to learn news/usenet/nntp/bla first is damaging the adoption of Lisp. The fact that many Lisp users at the same time also use usenet, does not mean that they should misuse peoples interest in Lisp by forcing them into the usenet in order to artificially keep usenet alive. You cant be advocating Lisp and usenet at the same time, since usenet damages the Lisp ecosystem. From the point of view of a modern internet user, usenet is dead, they may not even ever heard about it, and everything else that forces you onto the usenet will probably not be worth checking out. Its basically the same as if, in order to get in touch with Lispers, you would have to use gopher or a BBS or whatever was in vogue back then, just for the sake of preserving the past. The sooner the Lisp community at large realizes this fact of life, and finally burries c.l.l., and stops recommending it to newbies, the better it will be at attracting new, young, future users, advocates, application and library writers, etc, i.e. enriching the Lisp ecosystem. Desperately clinging to remnants of the past is just so damn unsexy. 
I suppose that newsgroups still have a charme because, in a sense, they are unique, thus authoritative. Usenet is a taxonomy of the universe. Apart from "alt.", there are no duplicates: there is a single common lisp group, and you know where to look for it. But you are right: this comes from a different age, and the BBS example is convincing. If CL wants to remain visible to contemporary users, our beloved usenet must be shelved.
If this list is going to become a preferred "community entry point" it will have to be advertised more broadly or nobody will ever be able to find it other than by word of mouth.
There generally IMHO should be and generaly recommended "community entry point" to all people new to Lisp. They will one day become the pros. As of now, sooner or later a new user is gonna stumble over cll, most probably over the google group, then turn away and never look back. The Lisp forum is a step in the right direction, but I often get the feeling that only newbies hang around there, asking questions nobody ever answers. But in general, I think that a forum is better and above all, more comfortable way to contact newbies than a mailing list.
There is also the CL-Gardeners Mailinglist. http://www.lispniks.com/mailman/listinfo/gardeners
Interesting. Cl-gardeners has zero visibility, I thought it was dead (like, for example, Cltl3)
You miss my position and context. I was simply responding to _delirium's not knowing where to find an NNTP server. Unfortunately, I only give this new mailing list a ~10% chance of success. Back OT, please tell me how bad IRC is...
There's a new Google AI Challenge posted [here](http://ai-contest.com/). The last time I made a starter package for Common Lisp and as you can see it ended up as one of the top 8 most used languages and according to the blog post they're working on adding support for it for this contest which is great. I'm not sure I will have the time to take part in this contest even though it is about one of my favourite iPhone games. I would encourage any Lisper to check out their forums and see if they need any help with the Common Lisp support so it will be available right from the start. (The competition starts September the 10th, 2010.) If it is setup like the last one I would encourage anyone to take part because it is a lot of fun and also a very good learning experience. During the last competition one could upload his program and follow its progress on the leaderboard and also check out each game visually.
My recommended entry point has always been the -help list of the implementation the person in question is using. 
The right title for the link would have been: "Common Lisp as popular as Perl. ;)"
Unfortunately the google docs generated piechart is broken and does not display.
Looks okay to me.
Maybe because I have cookies turned off: &gt; The bad news is that Google Docs has just encountered an error. &gt; The good news is that you've helped us find a bug, which we are now looking into. &gt; &gt; We're sorry, a server error occurred. Please wait a bit and try again. &gt; In the meantime, if you'd like updates on this and other issues, try visiting the Google Docs Help Forum. &gt; &gt; &gt; Sorry, and thanks for your help! &gt; - The Google Docs Team (citing for the downvoters who don't believe me, this is what I get instead of the image)
Yeah, my CL version is done: a basic random bot that works locally. It just needs to be tested on the server. I've been in contact with Jeff and I assume you have as well?
The reference to quicklisp is a bit obscure. What is the relationship among the two?
Quicklisp has seen some hype lately (e.g. [Hans Hübner's glowing review](http://netzhansa.blogspot.com/2010/09/quicklisp-upcoming-solution-to-common.html)). I think this is Daniel's way of saying Quicklisp isn't the only game in town (and really, it hasn't even come to town yet), and that LibCL ain't dead. Quicklisp and LibCL share no code or data or design coordination.
This was previously presented as a talk at [DANSAS 2010](http://dansas.sdu.dk/program.html#edtsbtied), which we hosted at SDU. It has interesting things in it, though one of our main guests managed to throw a whole slew of papers on the topic he (co-)authored at Hannes that weren't included, I'd need to see if they are there yet. The approach is certainly worth consideration, but sadly it's completely incompatible with Python's existing type inferencer and optimiser, which completely lacks any kind of formal underpinnings. I thought I'd seen someone trying to formalise the inferencer in SBCL, but now I can't find it anymore, am I just imagining things, or did it really happen? And either way, does any of the SBCL gurus know how hard it'd be to get the inferencer to use some kind of formal system similar to the one presented here, to enable sharing with Dylan? And finally, Hannes has made a nifty and shiny visualisation tool that shows the inferencer's workings interactively. I really think it should be linked somewhere in the paper, it makes for very pretty screenshots and videos :)
If both serve similar purposes, then perhaps its better to combine efforts.
I've been making some attempts at coordinating; but nobody will tell me where to find quicklisp.?. To be fair, the previously stated aims of LibCL and Quicklisp were quite different; but the LibCL redesign greatly narrows that difference. Also, both frameworks are currently "feeling out the waters"; so coordinating now might be a distraction/premature optimization.
I added that reference because there has been no interaction between the two. Stir the pot, and see what rises.
Perhaps. When I started working on Quicklisp in July, LibCL had been dormant since September of 2009, and had a philosophy that was pretty incompatible with what I wanted in Quicklisp. I had talked to Daniel about some of my ideas for Quicklisp (particularly the one-file bootstrap idea) at ILC when he announced LibCL, and I got the impression that he wasn't all that interested in the concept. So, until his announcement today, I never really thought it would make much sense to combine efforts. I'm going to wait for a while to see if it starts making sense. 
Join #quicklisp on Freenode and ask for the URL (and stick around for someone to tell you).
I stuck around for a couple hours one night, and have left requests for info by email in a couple places... Life just won't let me hang on IRC longer than that.
Ah, I see that in the logs now. I'm too old to stay up past midnight. I'll email you what you need. Part of the reason for using IRC is to help people quickly understand whether missing/broken functionality is intentional (feature *foo* is philosophically incompatible with Quicklisp) or coincidental (Quicklisp just isn't finished yet). If you find yourself wondering those kinds of things, please let me know (and if you use IRC, sometime before midnight. :)
Thanks. With kids, you can't get anything done before they sleep (my son rarely sleeps before 10). I then need to decompress before even attempting to code. Doesn't make for productive coding. Need to figure out a better schedule.
&gt; With kids, you can't get anything done before they sleep [Tell me about it!](http://www.flickr.com/photos/shannabeane/2781882958/)
*The Little Schemer* has a chapter on this too. 
Well, I bought it anyway ;-)
This is one of those where I could never own it as an ebook because I own the paper copy and I'm not paying another $75 to have an e-copy.
If you're going to make the obvious, second-grade remark, you could at least get the 'th' in the right position, like most second-graders would...
There's a large portion of it on Google Books, too.
Let me know when you find it, I have been looking for time for a long time...
I just tried to do this at lulu with the .pdf from PaulGraham.com. Lulu is saying that I need to embed the fonts. Before I go through the hassle of figuring out how to do this...do you still have the pdf you used? Would you be willing to share it? :) Also, did you go with 5.5" x 8.5" ?
There are also "free" e-copies. Technically they are only selling you right to have a book because bytes themselves cost nothing, but you already have that right.
That's certainly the way I see it as well, but the e-copies I've seen are almost unreadable. (Bad OCR).
I agree I bought this a year ago and would love to have it on my kindle, but to spend another 75$, there is no intelligence in that.
Whoa, you are into LISP?! Dude are we dopplegangers? .. clearly we are the only LISPers on reddit that also frequently contribute to /r/guns.... :)
I don't still have the PDF. I don't know if lulu lets you download it again, do you? re: embedding fonts. I think I opened the .ps file in OSX's preview and then saved as PDF. *shrug* It was a while ago. I did go with 5.5 x 8.5. I did that in OSX's preview. It was a lot easier than I thought it'd be. 
I love Lisp. Funny running into you here... 
Huh, I normally hit operatorchan, and never once thought to look for r/guns.
Your point being...?
that there are at least three people interested in both guns &amp; lisp.
Oh, I'm certain probably 50% of proggit is at least moderately interested in guns, but hell, it seems odd enough just finding another person that's interested in Lisp, much less, Lisp and guns, that it's cause for celebration. Particularly people interested enough to be actively posting in both reddits. I'll bet there are at least four... ;-)
of course I referenced the papers in the related work section! it was henglein's and rehof's work from 95.. and I linked in the paper (on one to the last page) to the visualization (which website still needs some work and some videos)... http://visualization.dylan-user.org
... until the next time they decide to close down the platform. It's their platform, and they've every right to decide what goes on it, but I've just as much a right to avoid spending time writing an application only to have the winds change &amp; be left with time I'm unable to reclaim. Does anyone *really* feel comfortable developing in a non-explicitly-supported language?
No, I don't feel comfortable doing that, but rather that than Objective-C or one of their other sanctioned languages.
I'd rather not develop for the platform at all, even though I don't mind C terribly. Seems like there's too much of a risk of "Oh no, that won't do on *our* platform." I don't think Apple is wrong to do this, but I don't see the gambit as being worth it.
How bad was the spam last time you checked? 5 of the most recent 60 *threads* listed on Google Group's c.l.l are spam - 8.3%. Semi-on-topic question: I suspect most long-time Lispers on c.l.l use a proper Usenet client. Does anyone know if they filter out messages posted via Google Groups?
I've used individual.net and eternal-september.org for NNTP. Neither of them have the garbage flooding Google Groups. I suspect most proper NNTP servers will be about the same.
Last time I checked, it was maybe 80% spam. It was just awful. Now it seems at least tolerable, at least since August.
Yeah, here you go: http://rapidshare.com/files/418195990/onlisp-new.pdf I used these instructions to embed them when I needed to print it on Lulu: http://colinm.org/tips/latex
Thanks a bunch man! I just uploaded the files and ordered myself a copy. I knew a lisper would come through! thanks again!
&gt; It's their platform, and they've every right to decide what goes on it No, they don't. Just because you sold me X doesn't automatically give you the right to tell me what I'm allowed to do with it. The fact people even consider practices like that anything but absolutely *outrageous* is one of the greatest harms done by the abomination also known as modern copyright law.
&gt; Just because you sold me X doesn't automatically give you the right to tell me what I'm allowed to do with it. I meant app store distribution rights; they host the content, provide the store, &amp;c. They can decide what to do with that, and it's perfectly fine. The platform locking is silly, but it's the bane of modern devices. 
Your PDF link seems to be down, any others available?
If you send it to me privately, I'll put it on a public server for everyone to grab.
Wow, didn't realize rapidshare has become such a piece that you can only download 10 times before they shut it down... Here's a link from my dropbox, feel free to put it up somewhere else too, e40. http://dl.dropbox.com/u/413030/onlisp-new.pdf (Might be a couple minutes before Dropbox syncs it all the way.)
Getting a 404
comp.lang.logo gets a fair amount of spam, but it's mostly a rarely used list.
If you say so. But this is the lisp subreddit, where c.l.l means, obviously, comp.lang.lisp.
That was just while it was still syncing, should be working now.
well, first, I'd challenge that Logo is a lisp. Second, nowhere did I say that c.l.l means comp.lang.**logo**, which is why I explicitly spelled it out. Third, I was pointing out that *another* usenet group gets a fair amount of spam; I was going to mention comp.lang.scheme as well, but it's not *always* inundated with spam.
Actually what I meant was: I haven't found a Usenet client I like. Until then, I'll probably subject myself to Google Groups' interface. But will the majority of Lispers see messages I post, or do people filter out posts made via Google Groups? (I feel like I saw someone somewhere mention that they filter posts in that way, but I can't recall the details.)
Ah, it was a half hour after, so I just figured it would have been up.
Yes, I've also noticed that comp.lang.scheme (as viewed via google groups) had much less spam than comp.lang.lisp.
Haha, yeah no prob.
Here is a cover I made and an additional link to the font-embedded pdf. Hopefully Mr. Graham doesn't issue me a C&amp;D. :o http://www.markdomowicz.com/index.php?option=com_content&amp;view=article&amp;id=78:on-lisp-on-lulu&amp;catid=40:programming&amp;Itemid=60
The servers I use filter out the spam and allow the rest.
&gt; Thanks a bunch man! I just uploaded the files and ordered myself a copy. The page size in the PDF is 8.5 x 11... Did you get the same size on Lulu? How much did it cost ya?
Yeah, I noticed that too. I'm trying the 5.5" x 8.5", but it remains to be seen how well that will work. I'll know in 5-15 days when my copy arrives. As for price, I think it was $US 8.90, or there abouts, and the slowest shipping was $US 5.24.
I didn't mind that the pdf has an extra wide margin, all the more room to scribble notes with ;)
&gt; all the more room to scribble notes with Absolutely. The reason I asked about sizes is that Lulu doesn't offer hardcover in 8.5 in x 11 in. The closest size is 8.25 x 10.75. Having never used Lulu before, I don't know how it deals with PDF-vs-finished-product size differences.
What about me? I made that McCarthy poster. And let's not forget the photographer, ripped off by both of us...
For real? That's an awesome poster! Please don't sue me. :)
I'm still not sure I agree with the statement "they can refuse to host X purely on the grounds that it was written originally in Y and not the blessed language Z, even though there's no externally noticeable difference in behaviour". I don't believe distributor rights should extend this far, and as far as requirements go, they should only ever concern the end results, not steps performed to reach them, as long as none of the steps violated anyone's rights by itself. I vaguely remember there's a law (though no idea in what system, probably US? I'll be damned if I know whether it's in any way universal) that explicitly prohibits you from refusing to service anyone if they fulfill the requirements you have previously specified; ie. if you say "you have to be 18 to be serviced here" and nothing else, you can't later turn a customer down for being pimply if they're 18 or older, because "not pimply" is not on your list. There should be similar provisions that prohibit you from setting requirements that are about anything but the end distributable itself. If I have an app that follows your UI and security guidelines, it's none of your business how I made it.
I'd rather not develop for their platform at all, in an attempt to do everything I can possibly do to increase the value of platforms that aren't iOS. Every bit of functionality that's not available on iOS is the bit that might possibly convince someone not to use it and tip the balance away from closed systems becoming an acceptable norm. As an aside, I still don't understand how on earth there aren't twenty anti-trust lawsuits in motion yet. If that's not monopolistic, I don't know what is. And yes, there should be an identical suit against Sony, Nintendo, MSFT and the rest of them.
I agree fully with everything you say, which is *exactly* why I refuse to write anything for it; I can be bothered dealing with the variances, the opacity of the process &amp; the control Apple insists upon. iirc, it's not monopolistic because they don't have the full market segment, only Apple phones. I don't have a problem with stores having policies against carrying certain content, but I do have a problem with devices being tied to a specific store. 