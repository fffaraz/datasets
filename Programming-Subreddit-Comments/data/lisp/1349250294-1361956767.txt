And now that upcoming OpenBSD 5.2 will have kernel-level threads, I'd hope to see threading enabled on OpenBSD as well. 
I would expect Hunchentoot to work fine with Anton's SBCL[1] on Windows. If you're looking for the same setup with upstream SBCL, please try/ask again in one or two months/releases, please. [1] http://www.siftsoft.com/inprogress/forknews.html
you could also use **prog1** and get rid of the **or** and **nil**. (let (once) (remove-if (lambda (x) (and (eq x 'g) (prog1 once (setf once t))))) '(a b h g g k l o p g b b b)))
It works with some minor changes, via iolib.usockets going through iolib.winapi etc. see &lt;http://src.knowledgetools.de/tomas/winapi/index.html&gt;. I don't think it works out of the box with the official Hunchentoot and dependencies unless somebody fixed that in the last year and half.
So how do you get these things to run with slime instead of right on the command line? I'm a lisp slime noob
Many implementations have a profiler. You want to use the profiler to optimize your code. The other helpful thing is type inference hints. I know sbcl and lisp works both have this. Something to note is that disassembled functions can be longer and faster. Why? Because function calls take time and properly optimized code may inline many function calls. This isn't always the case obviously. Reading the disassembly can give you a real insight into what parts could be better optimized. Anyway, get good with the profiler and learn about the way lisp objects like fixnums are generally implemented (tag bits and such), you will be writing speed demon lisp code in no time.
First of all: do not make parentheses feel solitary! Programs look much nicer this way: (define (context proof) ;; need to do stuff here (more stuff)) ; &lt;-- parens flock here Next: local DEFINE is a bit overkill to store a local value. Use LET instead: (define (context proof) (let ((len (- (length proof) 1))) (more stuff))) But then, why do you need the length of the list at all? To traverse a list, Scheme-style, you would write something like (define (context proof) (if (null? proof) ; end of list (display "done!") ; whatever you need to do at the end (begin (do-something (car proof)) (context (cdr proof))))) Or, if you have multi-statement bodies, like above, and nothing to do at the end: (define (context proof) (cond ((null? proof)) ; done! (else (do-something (car proof)) (context (cdr stuff))))) The pattern is the same: Until proof is NIL (end of list), do something with its first member (car) and then pass the rest (cdr) to the function recursively. The rest of your programs looks good as far as I can tell, except for those poor lonely parens. BTW, Racket is closer to Scheme than to (Common) Lisp, so the Scheme Reddit may be worth a try, too. Good Luck! EDIT: formatting, typo.
First off, let me say I don't understand he assignment. I think this is a good hint though. You need to use recursion. For example, how do you define the length of a list? One way is to say it is the length of the first item (1), plus the length of the list resulting from removing that item. You can do this recursively until you have an empty list (0). When you add everything up you get length. Ex. (defun length (list) (if (null list) 0 (+ 1 (length (rest list))))) This idea can be generalized to arbitrary list/tree traversal with the proper amounts of clever. You might want to think about coroutines and mutually recursive functions for more complex cases.
The assignment was not to actually prove anything. We must write two functions, one called context and one called premises. We are to take some proof, implement it into a data structure and pass it to one of those functions, then depending on the function, it will preform the operation and return the answer. In class we learned about an algorithm that was written to do just what I am doing. He sent us what he calls "a long and difficult to read document" that explains how to do this. 
I wasn't sure of how I was going to do this, length was left over from my thinking processes. Also, I am unsure of Common Lisp, but in racket there is a built-in function called "length" that when you pass a list to it, it will return the size of that list. Also, see my response to sickofthisshit below you.
Alright, (define set '(NIL)) defines a global variable named SET and assigns it a list containing the symbol NIL. An empty list, though, would not contain any symbol by definition. NIL represents the empty list in Common Lisp, but not in Scheme. The more interesting point, however, is: why would you want to define a global variable and bind it to an empty list? If you begin like this, you will end up using SET! a lot and write FORTRAN code with Scheme syntax. Scheme programs typically consist of procedures (or functions) that map values to values. Values are not kept in global variables, but generated by procedures, passed to procedures, and returned by procedures. If you try to translate any Java, C++, or FORTRAN idioms to Scheme, you will have a hard time, so I suggest that you invest some time in learning the basics of functional programming. I have received positive feedback about my own introduction, "Sketchy Scheme", which you can get [here](http://t3x.org). There is also a free -- but slightly older -- version [here](http://www.bcl.hamilton.ie/~nmh/t3x.org/zzz/). Finally, to have a look at tons of real-life Scheme functions, look [here](http://www.t3x.org/s9fes/lib.html). 
My suggestion is to try and avoid doing the representation of 'type' as a number and converting it to a string. Lisp supports symbols natively so you could instead write proof as (define proof '((suppose "..." (infer "...") (infer "...") ...)) Then you can just compare the symbols and it keeps things readable. If you want to print a symbol you can use (symbol-&gt;string &lt;symbol&gt;) to convert it. I'm not sure I like the reference to previous rules at the end of each step...It seems that they would be prone to fall out of sync by, e.g. introducing a new step. I'm not sure that I have a great solution to this though... Perhaps if the list was associative? (define proof '( (premise . (suppose "...")) (step-1 . (infer "..." premise)) (step-2 . (infer "..." step-1)) ... (step-7 . (deduce "..." premise step-3)))) Although, that way you might need to write a bit more supporting code to unwrap your data structure.. perhaps it's too bloated/wordy... 
One way to do this is to include the file as a vector of bytes in your compiled executable. I've posted a simple example with a shell transcript using ccl [here](https://gist.github.com/3834446). The basic idea is you define the filename in one file, and include it in the compiled output of your product using `(defvar *my-blob* #.(slurp-file *my-file*))` the sharp-dot means 'evaluate at readtime', meaning the value of `*my-blob*` when compiled will be the *contents* of `*my-file*`. The shell transcript makes it pretty clear, I think.
Thanks, this works great. I changed the output of the compilation to a .o and built it into an executable. Very cool.
What CL implementation are you using? I'm guessing maybe ECL?
Yes, ECL.
np
I do like the first suggestion, I don't understand the second suggestion, but this is only a rough draft.
It worked for me with one of our in-office staplers. I had to try the first staple 3 times, the second 2 times, and the third I got in one go. It helped to press slowly and wiggle the two halves of the staple against each other while pressing. The agitation gets the tips to drill through a bit.
*Makes me want to print it and sew the binding.* Actuallly, the domain is BOUNDP, so yes, T. 
Thanks so much! I've been looking for a way to expand the program, and your comment has a lot of cool ways to do that. One thing that really surprises me about this language is how easy it is to change things like this without rewriting huge sections of the program. Thanks!
I've had good luck with [Japanese bookbinding](http://www.sff.net/people/brook.west/bind/bindit.html) techniques. I make holes with an awl or a drill, then stitch it all together. Works great, lasts well, looks neat.
Great work!
Fair enough, thanks for the explanation.
An FTP link? On Reddit? Say it ain't so!
Submitting at 2AM may not have been the best idea. A few compulsive downvoters? Now that this dropped off the main page this looks almost hopeless... I can't explain the discrepancy of the popularity of the previous submission (http://www.reddit.com/r/lisp/comments/zo8lo/hexstreamsoft_tweets_about_common_lisp_organised/) (15) with this one, which as I write this is effectively at "-3" (3 - 6), considering that the quality is far superior to last time... Or maybe 2 submissions in a relatively short timespan was not well-received by some? If the quality has significantly improved, what's the problem? Is there some knee-jerk reactions against tweets (presumed to be low quality), or my submission's wording? Shit like this is making me consider brutally abandoning any form of advertising.
Your point is well taken. At the same time, I still like what Fare is trying to do. It's pretty much the same thing, I think, that I've been trying to do with Bard, and that I've been interested in since I wrote "Objects Without Classes" in the early 90s. And I think you're right that Haskell typeclasses pretty much capture the same idea. The thing of value in my mind, the thing that all of these efforts are trying to do, is to present a way to describe behavior so that it's orthogonal to structure and representation. I think that's a good thing because those three things--structure, representation, and behavior--are naturally orthogonal, but object-oriented programming facilities have tended to conflate them. That conflation simplifies some things, but is not necessarily a good thing. It's not necessarily good, for example, to reuse behavior in a way that also forces you to reuse structure. We might like to separate the two; the fact that a binary tree and a hash table are both finite maps doesn't mean they should have the same representation, for example. And, besides seeing two different representations as participating in the same behavior is complemented by cases where we'd like to see the same identical representation as participating in more than one behavior--for example, seeing a word as both an integer index and as an array of boolean values. So even if LIL is overengineered (and I'm not saying it is; just allowing for the possibility), I still like what he's trying to do. For what it's worth, in my own work of the past few years I've found it worthwhile to separate concerns in this way, and I think there may be some more goodness to be gotten out of it.
or simply, (remove 'g lst :start (1+ (position 'g lst))) where lst denotes your list. Your might want to check for bound errors. 
Oh?? I actually forgot to check the /r/lisp page after posting as I usually do, so when I checked it the day after and didn't see it there, I assumed it had dropped off the page because of the low "-3" (effectively) score. I also saw it's not on the "new" page but thought that was also because of the low score (not familiar with reddit algorithms), and also thought maybe some might have marked it as spam because of the wording and because the same link (but different content) had been submitted not too long ago... So it might just be relatively quick repost + posting at 2AM and getting some downvotes was a really bad combination... Anyway, I won't be posting links to my tweets collection here anymore. Generally I really want to concentrate on programming, not marketing. I want the quality to BE the marketing!
First off, I really enjoyed watching this project unfold -- I feel like I was there in the front row as Fare was brainstorming and furiously hacking away. Sadly, for much of the time I had almost no clue what he was talking about. At this point I'd say I definitely "get" the idea and am suitably jealous of the capabilities he is able to embue in the data structures built on the LIL concept. That being said, I don't feel very confident that at this point I could just pick it up and, in my own development, continue to extend the platform in the same manner and with comparible quality of the result -- in fact I'm pretty sure... But at least my eyes have been opened a little and I'm sure that over time some of these ideas will take root in my head -- just not immediately I guess. Has anyone looked at https://github.com/jaeschliman/com.clearly-useful.generic-collection-interface/ and had aby thoughts in regards to comparison of his approach? It seems to incorporate some of the same concepts but in a more approachable (and surely less ambititious) manner. I've been considering it might be a means by which to become acquainted with the general ideas and familiar with their use in practice.
I would rename notfat to note-time-and-frequency. Very few things today require saving that much space, and if your editor autocompletes, it's not a big deal.
I think LIL is interesting because it separates the idea of interface implementation from being tied to instances. This can be really handy. The idea of passing around an interface object seems cleaner and more "functional" than setting some special variables that change the way some library works.
I wish this project and those like it the best of luck, however I would be surprised if any become adopted by a critical mass of lispers. The issue seems to be that things are not as clean as everyone would like -- otherwise such libraries would not crop up -- but at the same time things are not sufficiently bad to justify evaluating libraries, deciding on a particular library, depending on that library (along with its possible bugs and possibly incompatible future versions), learning that library, and requiring people that read your code to learn it. It would have been better if things were really, really bad, so that everyone would have been motivated to join together with common purpose create a solution. But it's not like that -- it's just sort of bad, and it doesn't hamper coding enough for people to rally around a common cause. For any particular situation where things might get cumbersome, a few functions or macros can be crafted on the spot to address the issue. So there is this perpetual state of limbo: of being OK but not great, of being slightly bad but not sufficiently bad, of being usable but not slick.
GitHub reports that the last changes were made several years ago... BTW, there is another great idea at bringing the statistical computation and Lisp together: [R to CL translator](http://dan.corlan.net/R_to_common_lisp_translator/)
It's very easy to call R from any language that can call into C using the excellent [RInside](http://cran.r-project.org/web/packages/RInside/). I didn't do much with it, but I did test it out with SBCL and CFFI, and it didn't take much effort to get it working. There were no issues passing data back and forth or calling R functions. Compiling R to Common Lisp would be a big project.
I currently use R for my stats needs but I would love to move my statistical analysis to Common Lisp! Another vote for ggplot2. Other stats related tasks I typically do with R is regression and ANOVA.
Yeah, I think a lot of folks are looking at lisps as a more interesting direction for stats than some of the other up-and-comers such as Python. I know python pretty well, but I don't feel that excited about it, say, as compared to R.
There's also the thing where very radical projects provide the genesis of ideas that come to fruition later. edit: I spent an evening studying Fare's IPS when I was putting this together: https://github.com/pnathan/cl-finance-queries Most of the functions wound up looking like this: (defgeneric frob (underlying-interface arg1... argn)) I havn't had the time to flesh out multiple interfaces yet but so far it's stood me fairly well.
I was wondering whether Fare would address the "every file should be its own package" argument which seems to be the argument of the folks behind cl-project. He didn't. I don't agree with that multiplication of packages proposal, but I'm not a professional lisp programmer, so what do I know.
Thank you very much.
Whoa, google does Common Lisp?
If you're comparing to C/C++, then imagine a cons as a struct with two pointers, which can point to values of any type. It doesn't really help you to think of the cons cell itself referring to a 'real' location in memory, but those pointers certainly do. How any particular cons actually *is* represented in memory, though, will be implementation dependent. 
You can implement a cons in C as a struct of two tagged values, then keep a large array of them or malloc them. So a cons is probably referred to as a pointer or an array index within the Lisp runtime, but you cannot access that value from Lisp code. Here's a CLISP cons from http://clisp.cvs.sourceforge.net/viewvc/clisp/clisp/src/lispbibl.d : typedef struct { gcv_object_t cdr _attribute_aligned_object_; /* CDR */ gcv_object_t car _attribute_aligned_object_; /* CAR */ } cons_; You can access memory using FFI, e.g. CFFI. http://common-lisp.net/project/cffi/ But this is designed for interfacing with code in other languages rather than accessing the internals of the Lisp runtime to modify them. 
Hey rob, good answer. You might want to indent your code by 4 spaces or surround it by backticks so reddit doesn't butcher the formatting. Like: /* Cons */ typedef struct { gcv_object_t cdr _attribute_aligned_object_; /* CDR */ gcv_object_t car _attribute_aligned_object_; /* CAR */ } cons_; typedef cons_ * Cons; 
You seem to think there is a difference between the CAR and the CDR. Both CAR and CDR of a cons cell can hold any Lisp object. And a cons cell is a Lisp object. In the now-distant past, memory spaces were often small compared to registers. So a 36-bit machine like a PDP-10 could live with 18 bits of pointer (where a pointer would count in words: 262k 36-bit words for just over 1M eight-bit bytes). Nowadays, even a 64-bit machine would probably not be viable if it had 32 bits addressing 64-bit words (i.e. 4 giga-words covering 32G eight-bit bytes). Anyhow, in today's world, pointers are roughly as big as a memory word; you can sacrifice a bit or two because most machine pointers are byte pointers, not word pointers. A Lisp object representation these days is usually a single machine word, and the implementations force their pointers to be on word boundaries so they can use extra low-order bits to do type-tagging. A cons cell would be two words (128 bits) long in memory, one for the CAR and one for the CDR, and the Lisp object representation of that cons cell would be something like "address of the CAR + 3 bytes." The byte offset tags the Lisp object representation with low-order bits `0011` (if you align all Lisp objects larger than a word on even word boundaries). Typically, your Lisp object representation can fit 61- or 63-bit integers, along with 32-bit characters, 32-bit floats, and any other object is represented by a pointer to memory with a tag offset that identifies it as either a cons cell or some other kind of structure/array/string/Lisp symbol/arbitrary-precision integer/double float/piece of machine code/etc. To refer to an memory location in a C-like way, you could imagine a Lisp object which wraps a 64-bit integer which is the C pointer. The implementation can then provide operators which take that wrapped C-pointer, perhaps an additional integer byte-offset or word-offset argument, and return a 64-bit Lisp integer, or a 32-bit Lisp integer, or an 8-bit Lisp integer, or a Lisp character, a Lisp single-float, a Lisp double-float, a Lisp string, or a Lisp structure meant to represent a "foreign string of 8-bit bytes" or whatever. Once you've gotten this far into the details, there is a huge variety of approaches, and there are a wide range of tradeoffs and complexities. Most importantly, how the Lisp runtime allocates memory and implements garbage collection: in a multi-threaded Lisp app, if your memory allocation in one thread wants to reclaim memory, the memory reclamation has to understand what Lisp objects are in use by other threads which might have their register contents stored on a stack. If that thread is executing C code, some of those registers could look like Lisp integers, but be C pointers, or look like Lisp pointers or other objects, but actually be C integers.
A lot of effort went into designing compact list representations in Lisp during the 1970s and 1980s, e.g., [Compact Encodings of List Structure](http://bitsavers.trailing-edge.com/pdf/xerox/parc/techReports/CSL-79-7_Compact_Encodings_of_List_Structure.pdf) (PDF). So while a list may logically be thought of as a cons pair, internally they may not be. I haven't looked in great detail if any modern Common Lisp implementations utilize these kinds of tricks, given the amount of memory contemporary machines have. 
Thankfully! It's better for everyone's sanity.
Not really. Survival of the fittest and all. It was great for the future but unfit for the present. Humanity is better off without these expensive toys, we all benefited from the overwhelming success of cheap x86 clones with MS-DOS. We needed a comodity architecture that can accomodate the most explosive growth in both literacy and computing-ability in the history of mankind. Cheap, low-end, single-tasking machines with ROM and floppy-sized programming tools is what computing needed to come out of moneyed insititutions and reach the unwashed masses. 8086, DOS, BASIC, Assembler and Pascal: computational tools of yesterday's proletariat.
Sadly, I think you are right. However, there's no reason why these machines couldnt have flourished in the science/R&amp;D world (I'm too young, but from what ive read, these machines did enjoy some success for a while). It's my understanding that they died in the AI Winter (is this correct?) I just wish that development would have continued to shrink and improve these machines. Then, who knows, our iPhones or androids might be running some version of lisp machine (its a joke).
It's good and depressing at the same time to see them behind acrylic glass.
The point is not the hardware. That had been already beaten by x86 in the early 90s. What seems lost is the software part. Sure you can get good lisp software for PCs. But it is not completely integrated into your system.
[We might see that change soon](http://loper-os.org)
You speak about compilers a lot; what about interpreted code?
Well, I don't think anyone really cares much about performance of interpreted code: if they did, they'd compile it. Certainly I don't remember running any significant amount of code interpreted when I used LispMs.
There were two reasons as far as I can tell. - The AI Winter where Lisp got blamed for AI not being developed as fast as people thought it would - Hardware got faster enough that using special hardware for Lisp wasn't worth This is specially sad, because modern IDEs are just trying to recreate the type of development environment that was already possible with Lisp Machines (or Smalltalk systems).
If you search around, you'll find that many implementations have considered and abandoned these techniques. There was not enough space savings to compensate for the increased complexity and hence slower code.
You're generally correct about general-purpose CPUs inevitably out-performing hardware with LispM architecture. But the "integrated environment" was not just about the user-land software scheme. Having a memory subsystem that understood and supported the GC, and everything from the OS up using tagged data really is something that is hard to support with commodity hardware. People targeting the JVM is at least partial evidence that this is valuable.
I'm currently using LW personal. Is Emacs+SLIME much better than this?
Just to be clear, I am mainly thinking about the benefits of manifest typing and system-wide GC supported by dedicated memory bits and the operating system/ABI. I agree that the benefits of slightly better swap behavior is unimportant. The kind of thing I mean is that you can pass true objects to system calls, integers and pointers are safely distinguished throughout the system, the system debugger knows what your objects are, buffer overflows are less common, etc. You don't have a lowest-common-denominator which is anonymous 64-bit words in memory or streams of unformatted 8-bit bytes. In principle, you can pass objects to other processes without serialization or marshalling, etc., although the security aspects of this are unsolved.
Keyboard driver is quite hard if you use a USB keyboard. If you use an old fashioned serial keyboard, it's easy -- except that the repl doesn't expose the low-level hardware. Usually. Admittedly that could be easy to fix, but not in a hardware independent way -- you'd have to know its IO address and have an interrupt handler for it. The filesystem is hard no matter how you look at it. Skip the filesystem datastructures, accessing a hard drive (or USB drive or whatever) itself is complicated and hardware dependent. Systems programming is nontrivial.
It's an allergic reaction to the distortion field of being a user. I'd like to be a builder, for me there's no better way to see, reality check, ironic considering how disconnected I am still.
Hey r/lisp. I've been working on this library for a few weeks now, and wanted to know what you guys thought so far. I'd love any feedback/criticism/corrections/tweaks/praise/etc. Also, if it turns out it's not a bad library, any help writing/porting drivers would be appreciated. Thanks!
cl-cont -- haven't heard of it. Thanks for the tip, I'll check it out!
&gt; EDIT: Also, is there a way to do asynchronous programming without CPS? You can get an experience closer to ANF with a monadic interface. The trick has been used a few times in CL to implement delimited continuations (that can be converted to callbacks), but we can do things more directly. Rather than having each blocking action directly take a callback argument, let them return a future. Application can't block on a future; they can only attach callbacks to futures. This decouples the specification of blocking actions from the registration of callbacks. Instead of passing callbacks from outermost to innermost calls, futures are simply returned, and the outermost function's caller can attach a callback (or none, or arbitrarily many). There's one more thing we can do to make things compose better: attaching a callback to a future returns a new future. The latter future triggers when the callback has finished executing. This can all be wrapped in trivial `let*`/`progn` -like macros, for example: (mlet* ((x (foo)) ; wait for (foo), bind its result to x (y (bar))) ; same for (bar) (baz x y) ; call baz, and wait for it (quux)) ; and then call quux =&gt; (attach (foo) (lambda (x) (attach (bar) (lambda (y) (attach (baz x y) (lambda (_) ; careful with hygiene here (declare (ignore _)) (quux))))))) `attach` is simply the bind (`&gt;&gt;=`) operator in monads, and `mlet*` (and the implicit `mprogn`) straight translations from do-notation. Given that we don't care about nesting and everything is in direct style, we can also be sloppy and not have a `return` operation to transform regular values into futures. `attach` can check if its first argument isn't a future, and act like a (reversed-argument) `funcall` in that case. Note that acting like `multiple-value-call` is just a bit more work (callbacks have to be ready to receive arbitrary number of values), and will let the programming interface be even closer to CL's usual style.
I'm trying to wrap my head around cl-cont, but I'm getting horribly confused...do you know of anywhere that has examples of what it can do? For instance, "here's code before cl-cont" and "here's code with it". Or better yet, is there a good place to learn about the kind of continuations cl-cont is trying to emulate? Thanks for any pointers here. I'll also check out the teepeedee2 source while I'm at it and see if I can make heads or tails of it.
`(quux)` returns either a value or a future (note that it's in tail position). The caller of the `mlet*` form is free to do anything with that value-or-future, including attaching a callback to it. 
Thanks, this *really* helped me understand more. I've never dealt with this kind of syntax, so it was completely foreign to me. One thing I'm noticing...it seems like the callbacks being generated can only take one value. Would it be possible to support multiple values with this type of syntax, or would I have to wrap all my values in a list or something similar? EDIT: For instance, a lot of drivers might take a `socket` and a `response` as arguments to a callback. Thanks again for explaining.
so if I understand your point correctly, you're offloading scheduling onto the kernel, allowing the kernel to wake up your select() or epoll() event and then managing processing based upon that system?
Emacs is often the favored editor by LISP programmers because it is partially it's own dialect of LISP, Emacs LISP. It can be extended to do just about anything, editing or otherwise, using LISP and serves as an excellent tool for editing LISP as well.
AH makes sense. Sorry, I missed the part in your first post about `multiple-value-all` fir first time I read it (it was a lot for me to digest). This is starting to make sense now. I've been playing with some futures (or at least future-type) objects in my code along with some macros that make the syntax a lot less CPS, and it's starting to make more sense.
The pattern is so simple to use and works on pretty much any platform that supports closures as callbacks (e.g. javascript); it's been bothering me for a while that people just suffer CPS, but I never found time to wrap a useful event system around the trivial macros.
Yes, the details are in the readme, but for the most part, I chose libevent2 because it wraps sockets and socket buffering in a nice API (bufferevents) and it's portable to Windows. If I only wanted to support linux, I would have probably wrapped this around libev/IOLib (or event just IOLib), but even then I would have had to write a lot of code to support all the features I wanted to include. Libevent2 pretty much has all of them from the start, such as an asynchronous HTTP server/client and async DNS lookups. I'm planning to convert Drakma to be async at some point in the near future, which would completely replace the HTTP client in cl-async, but for now the included client works fine for simple, one-off requests. So basically, libevent2 has a lot of features included that I probably would have ended up building anyway, and I'd rather use someone's fast/stable C code than my own pretty fast/stable-after-a-while lisp code.
I have another one: http://lispm.dyndns.org/docs/draft%20proposed%20ANSI%20Common%20Lisp.pdf 
Yeah, the almost-final draft is publicly available in a variety of formats. This was the first time I was able to find the actual published spec without paying $30 for a crappy scan :-)
You `attach` a callback to it. This return a different future, to which another callback can be `attach`ed. The difference is that the future can be passed around before attaching callbacks to it, so the internals aren't as exposed as in CPS.
The site requires a password now.
This seems AutoCAD-specific. You should ask in [/r/autocad](http://www.reddit.com/r/autocad).
okie dokie. 
Did anyone get it before the password went up?
Has anyone tried (with any success!) at transforming the HyperSpec into one of the eBook formats (.mobi, ePUB)? Even if it's not super-clean, it would be nice to have it in a more "wrappable" portable form than .PDF to access on phone/ebook reader.
I think I get it. You can do everything as normal, provided you use `mlet`-family bindings in the place of `let`? While I see that's useful enough to get a lot of mileage out of it, it does leave me uneasy ... the "tautology" you so eloquently referred to :-). Thanks for taking the time. I'm a little disappointed that the short answer is "no", but we can't all have first-class continuations :-).
I'll start. The freakin' package system! More specifically, the lack of package or system-local nicknames, and the trend of predefining short nicknames in library packages. Now that we have quicklisp, sharing CL libraries is very easy. But to really benefit from the network effect, people need to be able to define libraries that A) won't conflict with others, and B) are convenient to consume in user code. I've done a little messing around in this area, but nothing substantial. To me this seems like an (if not *the most*) important issue. The ability to freely share and conveniently use other's code benefits all users of the language.
Hierarchical package names for namespacing would be nice. I miss them from other languages. There's some activity on sbcl-devel to make them, but I havn't tracked that closely. 
http://www.franz.com/support/documentation/current/doc/packages.htm#hier-packs-1
I wish there was less of a glut of peripheral nutjob denigrators.
you're talking about people who shit on lisp but don't know a thing about it?
It might be nice if nil wasn't overloaded with 3 meanings: false, empty list, a symbol. Then again, maybe not. The LOOP syntax for iterating through a hash table is awful.
I would prefer that people focus on writing useful and interesting libraries and applications. Because the language is so malleable, there is a tendency to spend time rearranging the deck chairs of the ship rather than working on the ship. There are whole twitter feeds and websites devoted to the former.
1. A copy-array operator. 2. A copy-hash-table operator. 3. vector-push-extend should have been called vector-push, and vector-push should have been called something esoteric befitting its extraordinarily rare use. 4. literals for extensible vectors. 5. Rational predicate name endings. (atom vs. vectorp vs. simple-vector-p). They should have just ended 'em all in question-marks. 6. Deep-copies of arrays, vectors, and hashtables. 7. Consistency in function naming. Oh, the humanity. 8. The default test for hashtables should not be #'eql (the worst of all options). Make it #'equal or #'equalp. 9. doseq and dohash 10. A radical elimination of low-level functions essentially unused by everyone, indeed frowned upon (setq). CLOS is a particularly rich source of this nonsense. Edit. Good god, I thought this was supposed to be a list of what *I* would change in the language, that is, things that bug me every day. The availability of deep-copying lists, but not other common data structures, bugs me nearly every day I use the language. Having to *always* pass :test to make-hash-table bugs me to no end. And having to paw through a massive index of essentially unused functions, or deal with them at backtrace time, has long proven irritating. I'm not saying I can't (or don't) write cover functions and macros to deal with this stuff. I'm saying I shouldn't have had to.
I've never actually been able to get quicklisp working, and I don't really care for it anyways. ANSI Common Lisp needs to have a defined package system. $ lisp add-package mongodb it should be that simple.
It's even simpler, because there's no separate step like that. For instance in Ruby you have to `gem install foo` and then write `require 'foo'` in code. But inside Lisp, `(ql:quickload "foo")` does both in one step.
I'd like to change a few things. The first would be more OS integration. Lisp has this air about it of completely ignoring the system it runs on. If you want to interact with the rest of the system, you're forced to use implementation-specific packages. It'd be nice if lisp was easy enough to be run off the command line as in the REPL. If I could replace my bash scripts with lisp, I would, but bash kicks lisp's ass in the OS scripting department, which is painful to admit. I think this holds back the adoption of the language. Another thing I've missed: some sort of non-OS-thread concurrency option. Coroutines, yield, etc. Some way to convert a function from `(call) -&gt; value` from being synchronous to asynchronous without disrupting the entire call stack. This is something I'd *love* right now, as I'm writing cl-async, but I've also wanted it in the past as well. I'd also like a lisp image that doesn't use 20mb of memory in its initial state. Sounds like a minor complaint, but for writing server components on smaller VPS servers, every MB of memory counts...I have been known to be frugal though ;). I also recognize that not only is the lisp language large, but also the better (read: faster) implementations host their own built-in compilers, which are bound to take up a lot of memory. Overall, the language is my absolute favorite to write in. What other general-purpose language supports writing programs that write programs that compile to machine code and compare to C in speed tests? This is an incredible system that's been built, and as gushy as it sounds, everyone who is writing in it is doing their part to make it a better language, and I appreciate that.
&gt; I've never actually been able to get quicklisp working This could be the very definition of a CL troll, congrats!!
I believe you can do that with a git version of CFFI.
It is the opposite of elegant.
More like WJ, A.L., Xah Lee, and people like that. They have some kind of illness so "nutjob" is unkind. I guess it affects me more than many because I like to read comp.lang.lisp and wish it was less noisy. GNUS scoring helps.
This. A million times, this.
Number 10 seems absolutely silly for a language that prides itself in being extensible.
`copy-array` is doable in standard CL: (defun copy-array (array) (let size (array-dimensions array) (let new (make-array size :element-type (array-element-type array) :displaced-to array) (adjust-array new size :displaced-to nil)))) 
In this case false can also be null, empty list and a nil symbol. 
(6). seems to be fixed in Clisp, it even does the capitalizing right with non-ascii: - (setq höttöä 'päätäni-särkee) PÄÄTÄNI-SÄRKEE - höttöä PÄÄTÄNI-SÄRKEE 
Eh, I think that the lack of OS Integration was because up until ~CLTL2, Common Lisp was seen as "the new Standard Lisp"--a common subset of the language that lisp implementations would be expected to provide, such that it wouldn't get obsoleted by a new wave, like many things have
Good, then WJ will stop bugging us
What's wrong with 8?
NIL actually has a lot more possible semantic meanings than the 3 you've mentioned, and I love it that way, as it's usually far more practical than annoying, and oftentimes even makes sense, semantically. NIL can also mean "none" (not the same as "empty list" when the other possible values in context are not lists), "unknown", "unspecified", "don't care", "unconstrained", "use default", "return NIL instead of throwing an error" and probably some other meanings. The "false" and "empty list" equivalences are almost always more useful and practical than annoying. I recognize that the "empty list" and "symbol" meanings are less well-aligned, for instance (string nil) =&gt; "NIL" while one might reasonably expect (string nil) =&gt; "" or =&gt; "()"
Is it just me or is automatic capitalization of symbol names a really nice feature to avoid camelCase? Also, 5 is doable with a library already.
I would like a way to define list structures in Common Lisp so the compiler can type check for correctness. This would be nice because lists are often used as an intermediate format.
Except that it may return a non-simple array. On SBCL: (type-of (copy-array #(1 2 3))) =&gt; (AND (VECTOR T 3) (NOT SIMPLE-ARRAY))
Lispers use `long-dashed-names`, so CamelCase doesn't come up anyway.
What about the [existing tutorials page on Cliki](http://www.cliki.net/Online%20tutorial) is not up to snuff? And what is stopping you from fixing it?
Not sure if you're serious (you're addressing a couple of really serious points; thank you for that) or just trolling a tiny little bit here (some of your points sound a little like that, sorry). - I love every effort made to let users install CL (and a development environment for it) more easily. But: Things have gotten a lot more easy recently thanks to Quicklisp, and Debian packages, which you're explicitly listing, inspite of the laudable efforts by their maintainer, never made things truly easy for anyone. That's why the CL community (cue comments saying that it doesn't exist) seems to switched away from those alternatives in the last few years. - Nothing like getting a CL vs. Scheme flamewar started like demanding that one side switch over to the other's semantics. - OK, this is actually important. Not the shebang stuff, which is sort of nice but not too essential IMHO, but POSIX support as such. But: 1. The CL standard is meant to be portable, so you'd be talking about optional POSIX extensions at best. 2. iolib covers most of that. So 3. all one should be asking for in my opinion, is that the standard should at least not go out of its way to make POSIX support a nightmare. I'm looking at you, pathnames. - This is where my troll detector lighted up. You don't like the hyperspec? You're advocating newLISP? What's going on here? - Tutorials, yeah, OK. Nice. I agree. Not sure what you're implying re cliki though. 
Why do we need capital letters?
Instead of complaining about and trying to get rid of the annonying nutjobs on c.l.l, I wish the Lisp community would move off usenet completely. Because of its unmoderated nature, which attracts nutjobs and spam at the expense of non-expert users, usenet is dying and is dragging the Lisp community with it because there still is no more prominent place for meet and greet. For any new user, the first impression of the "Lisp community" as c.l.l. represents it, and c.l.l. does represent it because it is usually the first they stumble upon when searching for help with Lisp, is horrible and negatively affects the motivation to keep learning about the language. Somebody's choice of a programming language is strongly affected by the social component, and I guess that many people simply didnt bother a second look at the language after experiencing c.l.l. Just compare the (nice, friendly, enjoyable) experience of #lisp to that of c.l.l. The main reason why c.l.l is the disgrace it is, is because it is unmoderated. Just imagine how #lisp would look like if you abstained from any kicks and bans and required the regulars to deal with every single troll and spammer themselves, and you would get what c.l.l is, an unattractive anarcho-jungle. The tough anarchism on the usenet is not only harming the acceptance of Lisp in particular, it has essentially killed usenet itself by cutting it off from the influx of new users. I personally would not care much what c.l.l. would be replaced with as long as the replacement it is moderated. Xach, I also think that you should use the great impact you have in the Lisp community to make people move from c.l.l, instead of posting there yourself and making the place even more prominent than it deserves to be.
http://lispforum.com looks pretty active, and it's mentioned even before the IRC channel at cliki. Does this not suit your criteria?
Oh, the SICP lectures. If I remember correctly, that's what got me hooked on functional programming.
It is active, but its level of activity and valuable informationis not comparable with c.l.l. My suggestion to Xach was that if more influential people (like him for example) would leave c.l.l and instead frequent some other venue, c.l.l. would maybe become irrelevant enough to not be the posterchild of the Lisp community at large, and the focus would switch to that other venue. I personally would like r/lisp to become that other venue, but lispforum or even something else would also be ok, as long as some minimal moderation is in place.
Yes, I'm serious on all points. &gt; Things have gotten a lot more easy recently thanks to Quicklisp, and Debian packages Debian packages help Debian users install CL, but what do Mac and Windows users get? They still have to manually install CL. &gt; You don't like the hyperspec? No, it's indecipherable crap. I'm not advocating newLISP, a controversial Lisp implementation. I'm advocating documentation like newLISP offers, with actual, readable, examples. &gt; Not sure what you're implying re cliki though. Anyone interested in learning CL has no idea where to start. We should help them along by promoting good tutorials up front on Cliki, where they are easily found.
&gt; In computer science, a programming language is said to have first-class functions if it treats functions as first-class citizens. --[Wikipedia](http://en.wikipedia.org/wiki/First_class_function) Do we prefix integers with `#'`? No. Do we prefix strings with `#'`? No. What is the only thing we prefix this way? Named and anonymous function passing. This is stupid, because Lisp is a functional programming language. Functions are core to its philosophy and implementation. Treating them as second-class obfuscates their centrality. Lisp-2 is not only an arbitrary distinction, it's a 100% useless distinction that requires more unnecessary typing and causes unnecessary bugs.
Nothing quite so Ajaxy as that, but Dr. Conrad Barski is linking to a telnet based lisp interpreter (provided by Franz, Inc.) on the first page of his [Casting SPELs in Lisp](http://www.lisperati.com/casting.html) tutorial. By the way, the language that started this whole "Try *x* from your web browser" thing is Ruby.
They are not being treated as second class. They are merely being kept in a separate namespace. Saying they are second class is like saying women (or men) are second class because there are women and men's changing rooms. The advantage is that having them in a separate namespace means we don't have to worry about variable names conflicting with function names. You know about the disadvantage, but I'm sure you can accept that it is a tradeoff which could (and has) go either way. I'm not even going to touch that remark you made about Lisp being a functional language... By the way, here's the definition of "first-class citizen" that Wikipedia gave me: &gt; In programming language design, a first-class citizen (also object, entity, or value), in the context of a particular programming language, is an entity that can be constructed at run-time, passed as a parameter, returned from a subroutine, or assigned into a variable.
We prefix strings with " and end them with another ". We prefix hexadecimal numbers with #x. Don't be silly.
Hah! I had just posted this link in another discussion about SICP on another subreddit. What a coincidence! These lectures are fantastic.
Reporting back, continue to consider suicide or self harm 
we type our code in lower case but it all gets converted to uppercase, except if its inside a string. So when creating symbol strings and interning them its sort of weird/ugly to make the string upper case. So having case sensitive lisp code would be more wysiwyg.
 Don't LOOP and ITERATE already fill that niche? (iterate (for list-element in my-list) (for sequence-element in-sequence my-sequence) (for (key value) in-hashtable my-hash-table) (for i from 0) (until (eq list-element :premature-end) (print (list I list-element sequence-element key value))) Please excuse my formatting, I'm on a tablet with no code editor. 
I won't comment about LOOP because I want to stay polite. As for your iterate equivalence, it's true that it's superficially similar to my suggestion. *Superficially*. * DO-FOR is inspired by DOLIST and friends, while ITERATE is inspired by LOOP. DO-FOR takes care of iteration only, not accumulation, while ITERATE tries to be everything at once, which I don't really like and occasionates subtle but real problems (see next point). * DO-FOR has much simpler semantics (equals lower cognitive load) and simpler implementation. Did you know that ITERATE relies on a friggin' code-walker? * I really don't like ITERATE's "in-sequence", "in-hashtable", etc. It's much more readable than the LOOP equivalents, but such gratuitous "duplication" of symbols is reprehensible. My approach just uses appropriate symbols: LIST, SEQUENCE, HASH-TABLE... and it will also use ALIST, BLIST, PLIST and other symbols, and I have a plan to avoid conflicts with those. edit: I think it's important to consider DO-FOR as a vastly more powerful DOLIST-like construct rather than a less powerful ITERATE-like construct.
In a Lisp-1, variables are first-class, because you don't prefix them with *anything*, while you are forced to prefix functions with `#'`. When programmers are simply thoughtful of variable names, like in Scheme, no collisions occur.
Aye, sir. Unfortunately, the telnet service has been down for a few years.
&gt; Tail-call optimization a requirement Note that it's not possible (as far as I know) to optimize tail recursion in CL in some cases, such as in the presence of special bindings.
Why not just use structs or CLOS objects?
I'll check it out, thanks.
That's the obvious counter to the whole list structure thing. To be honest, I'm not sure what to say about it. Perhaps my idea is no good really and we should just use CLOS objects instead? Dunno, thinking about it.
&gt; while ITERATE tries to be everything at once, which I don't really like and occasionates subtle but real problems (see next point). Can you give any examples?
I would like to request that the op rename this thread to: HOW TO RUIN A PERFECTLY GOOD PROGRAMMING LANGUAGE. I mean, maybe an idea or two are cromulent, but good god, copy from Clojure? What is this, programming by Monty Python? 
I agree with this. The common response to this problem (at least as of a year or so ago) seemed to be essentially two things: "long package names are a pain to type, we'll just use short ones" and "the package system is rubbish anyway, so we'll wait for some new, better, incompatible system to (fail to) appear, and in the mean time use short package names". I find both of those answers extremely stupid. I have an alternative approach based on being a bit pragmatic about the likelyhood of the package system being replaced in any kind of standard way. (1) Use long package names, exclusively, with a naming standard based on Java-style backwards domain names. If I own tfeb.org, then I can be pretty sure that "org.tfeb.xml" is a safe package name. Domains are cheap enough that acquiring a provate bit of namespace is easy for almost anyone, and it would also be very easy for some central organisation to hand out namespace, say "org.lisp.tfb.xml" or something, where "tfb" is the bit of namespace I have been delegated by whoever owns "org.lisp" (ie the lisp.org domain). The argument against this is that it means more typing. If, rather than defining working packages for your system you insist on referring to symbols from other packages by their package-qualified names, it might involve significantly more typing. Well, don't do that then: define working packages which either use or import symbols from the packages you need. Now the namespace problem is solved you don't have to think hard about names for your working packages. (2) Package system hacks. There are two of these. (2a) Conduits. This is a system I wrote which allows you to define packages which re-export symbols from one or more other packages with fine-grained control over what is re-exported. Using this tool you can, for instance, define a single package which exports all the names in some API consisting of multiple packages, or define a package which is "like" another package but replaces a few symbols by others. Conduits does not do anything non-portable, it just provides some convenient syntax (in the form of an enhanced defpackage, itself provided by a package which is a conduit for CL). (2b) Package-local nicknames. This is an enhancement to the conduits system which allows packages to be looked up by short names which are dependent on the current value of *package*. So, if I am in ORG.TFEB.CLC-USER, CL:DEFPACKAGE might refer to ORG.TFEB.CLC:DEFPACKAGE and not the real defpackage. You get to define what these mappings are, by an option to the definition of the "client" package (ORG.TFEB.CLC-USER above). For this to work requires some small amount of non-portable code, although in practice it has not proved hard to make it work in any implementation I've cared about. This was originally based on some support in Allegro CL. In practice I use conduits but don't use the package-local nickname stuff. Both of these are purely pragmatic hacks (ie not "let's redesign CL" or the more common "let's complain about there not being enough money to redesign CL"), and in practice they solve the problem of package namespace clutter pretty well. Both have existed for well over ten years, and been public for most of that time. Further, simply using domain-structured package names solves the problem with no supporting code needed at all. Needless to say people still use short package names, because they simply do not actually care to solve the problem. TL;DR This is a soluble problem, and solutions exist within the existing package system. You have to want to use those solutions. [Edit: formatting, add tldr]
I think Peter Seibel offers a good starter example/tutorial on optimizing in the final chapter of Practical Common Lisp (http://www.gigamonkeys.com/book/conclusion-whats-next.html) Scroll down to the section titled "Make It Work, Make It Right, Make It Fast".
profile. reduce consing. add declarations. inline some functions. etc [PAIP](http://www.amazon.com/Paradigms-Artificial-Intelligence-Programming-Studies/dp/1558601910) also has a chapter on optimization. You can also find some ideas in [LOL](http://www.amazon.com/Let-Over-Lambda-Doug-Hoyte/dp/1435712757)
For ultimate performance, get to know your implementation, then employ that knowledge by making your code resemble your implementation expectations, for example, right declarations, using right operators, right data structures. Sometimes CL functions are too general and you can write your own faster versions. For really squeezing every last bit, exploit internal representation and internal interfaces. Prone to hard-to-catch bugs and incompatible changes of the implementation, but may be worth it in the critical parts of your program. And in the same category would be writing sections in assembly.
&gt; Clozure CL right from the App Store &gt; Windows users can grab an installer for SBCL, or the Win32 Threaded fork of SBCL That's fantastic! I'd like to see more CL variants easily accessible. &gt; In addition, implementations of CL are available on Homebrew (or Fink or Macports) This is very good. However, builds often fail due to wacky dependency issues, so it would be better if prebuilt binaries were made available.
It's no harder to optimize a Common Lisp program than a program in any other language. Remember the best way to optimize any program is in the appropriate selection of algorithms and data structures.
Given a good CL compiler (e.g. SBCL), an optimized CL program usually performs on par with a program written in a "fast" language (e.g. C). Unfortunately, optimization often results in code that reads poorly in any language. Fortunately, CL lets you start with readable code, add type declarations, and condense it down. Also, since you have macros and run-time access to the compiler, there are a range of tricks that allow readable code to transform into optimal code without looking particularly ugly. Its not perfect; but in many other languages, the way to optimize is to write C plugins...
That explains a lot. Thank you very much, and happy coding.
I think Franz (Allegro) does this.
I posted this as proof-of-concept that futures and user-level cooperative multitasking/threading is possible and actually pretty easy with Common Lisp, using CL-CONT (or similar continuation-passing macros). I know it's not thread-safe (ironically) and it is missing _all_ the features. But I would love some feedback: 1. Is this sort of thing useful? 2. Should it ship with iolib (or some other nonblocking io library) support built in? 3. What sort of API would you like to see for futures, lightweight/green threads? 4. Should it have a bordeaux-threads compatible API for green threads? 5. Is there another library that already exists that provides this functionality in a useful way? 6. What do you want it to do?
What's the debugging experience like, especially with CL-CONT in the picture? How is interop with vanilla (non cl-cont-transformed) code? Scheme-style predicates, really? What happens when multiple callbacks wait for the same future? Why do you pass around symbols that refer to futures, rather than the future itself?
Hey, thanks so much for the feedback, even if it is in question form and you didn't answer a single one of my questions :). I applied some changes, simplified the futures, made it handle multiple actions waiting on the same future.
Problem is, I hate working with codewalked code, and I mostly do CPU-heavy code, so there isn't a lot of feedback I can offer on your library. A long time ago, I wrote half a CPS codewalker and found it a pain to work with; not just for debugging, but also because of interop issues with dynamic operators (special bindings, catch, condition handling, etc). I then wrote a complete one in ANF, which made interop a lot nicer, but was still a pain to work with. The transformation is never fully transparent, and debugging is always fun. So, now, I stick to simple explicit macros, short stuff like http://discontinuity.info/~pkhuong/callbacks.lisp . It's not transparent, but, then again, codewalked extensions never are either. At least, these macros are easily understandable, especially when they fail.
@ number 8: I'd say that the default values of a function should be treated as generalized variables, so that one could use (setf (default-value function key) value) or (let ((default-value function key) value)) (function foo) (function bar) (function baz))
Name clash. https://github.com/deliciousrobots/cl-future https://github.com/jpalmucci/cl-future
That other lib looks stillborn, but I'll rename mine before it gets into a form that folks would actually want to use. Edit: well, no promises, I might keep the name
CL isn't only functional then this argument doesn't have so much weight. But in a constructive way I think it would be good to have CL with the possibility to choose Lisp-1 or Lisp-2 behavior (even only in parts of code mediated by macros).
Composition is just one cool thing you can do when functions are truly first class. Currying is [another](http://learnyouahaskell.com/higher-order-functions). By treating a function as just another variable, you can do really complex things like [automatic memoization](http://www.yellosoft.us/evilgenius/) by currying the function itself. These techniques are still possible in Lisp-2's, but whenever you throw in extra syntax crap, it makes it that much more obfuscated to accomplish these tasks.
Not to sound rude, but lisp machines are dead. Please post things that made the penguin dance or somethin.
That is pretty sweet. I have wanted to get one of these for a long time now. Thanks for posting. Are these your photos or just found the gallery online? Are there any vidoes from this Lispmachine demo? It looks like it was in a really good condition and it was clearly running. I'd love to see someone using it and show off some of the features. Thanks for posting.
youtube video please :) (with a tutorial on how to write a hello world program) Le awesome power of a lisp machine might blow up my computer !
Found that screen shot in a PDF linked from this post on digital audio. Instantly recognized that app icon :-) http://superuser.com/a/492295 
So cool! I was going to try doing this the hard way. Will report back my results after I try it. 
Oh, awesome. I own a MacIvory board set, docs, etc, but have never gotten around to building up an older Mac to put it in, and this might just result in me sending that boardset onto a better home.
Yes, "ELIS" was independent Japanese Lisp machines. there are some infomation about ELIS ELIS(machine architecture) http://museum.ipsj.or.jp/en/computer/other/0004.html TAO(lisp) http://www.nue.org/nue/tao/bitao/newgen2.html http://www.nue.org/nue/tao/bitao/contao.html http://www.nue.org/nue/ 
Why is this downvoted? I find sightings of Lisp applications very interesting. In this case an Allegro CL application.
please, correct url.
**WAT**
I find the infix a lot harder to read than normal CL syntax.
I don't know why he reinvented the infix wheel. CL-USER&gt; (ql:quickload :infix) (:INFIX) CL-USER&gt; '#I(if f(x) &lt; 3 then 4*g(y,z)) (WHEN (&lt; (F X) 3) (* 4 (G Y Z))) 
Hi, you can write FSMs with Shovel - the language is a Javascriptish Scheme (I need to add more examples to the language spec to make this more obvious) and it's up to you what you write in it. Shovel it's not complicated at all - it's basically a simple Scheme you can provide with primitives written in the underlying language (Common Lisp for now); those primitives can ask the interpreter/VM to stop; a stopped VM's state can be serialized to an array of bytes and deserialized (and resumed) somewhere else. That's about it (the rest are implementation details). One of the main use cases for me is sending a VM machine between a server and a client to allow the client to run programs on the server. A better RPC, if you like.
Thank you kindly for the explanation and for sharing the code. That is indeed very cool. I look forward to playing around with it. Oh, one more thing, I wish I could give you more upvotes for your clear explanation and your work to get some documentation out there.
That's pretty cool. How does Shovel differentiate itself from Lua, another language intended for embeddable scripting?
:-) I guess it depends on what you write (or port)...
you can look at http://dwim.hu click repository/darcs on the menu and check hu.dwim.delico for delimited continuations and hu.dwim.serializer for serialzation. or download them directly from http://dwim.hu/darcs/&lt;project name&gt; and try something like this (I typed this without a repl, so...) (kall (deserialize (serialize (with-call/cc (progn (print "Hello") (let/cc k k) (print "World")))))) saving the continuation to a file/db between serialize and deserialize is left as an exercise to the reader...
This looks impressive. Reminds me of Termite. But why another javascript-like langauge? Why not Scheme itself? Javascript-like is neither here nor there
&gt; Now that I do the math, 20-30mb is about 4-6% of mem, not really that much... It wouldn't necessarily all get paged in, either. Most of the stuff that you're not using should stay on disk.
Thanks! So far I found http://www.cliki.net/CPS (which is nice and I imagine a prototype of your later work). I'll play with the dwim libraries.
I wish Fare all the best with this effort, but in the stance of the classical lisp wheenie (smug or other) I am quite sceptical if the fractured 'community' can live up to the task. While there are some well known and respected figures in today's lisp community, I wonder how the multitude of authors might react if their libraries get disregarded or modified. There is no BDFL as with Python (ironically, Fares post has triggered a similar proposal in the Python community: http://www.jordan-dimov.com/2012/11/consolidating-python-libraries.html)
So I'm just a user of Common Lisp, and I'm pretty sure my (1) quicklisp library is (1) unique and (2) rarely used. How can I help this kind of effort?
Well, at least points 5 and 8 apply. Declare it THE library and rename it from FUNNY-CUTE-NAME to UNFUNNY-DESCRIPTIVE-NAME. Also, I suppose you can voice your opinion on which libraries you would like to see become "standard". I'll start with a few that I've used successfully for years in production. Hopefully these shouldn't generate much controversy: * Regular expressions - cl-ppcre * Utilities (conservative) - alexandria * Web server - hunchentoot 
inb4 -- anticipating a question users have been asking after the last few SBCL releases: So, what's the status on Windows support? - This release includes some support for threads on Windows. - Threading support isn't perfect yet. But it's there! - No AMD64 support yet. - Many other fixes forthcoming. - Yes, hunchentoot works for me in simple test cases (the teen-age New York version). Should you use this version of SBCL on Windows? - For production use, I still recommend Anton Kovalenko's branch and binaries. - But please *test* this new SBCL release to help us debug it. Thanks in advance! For any bug reports, it would be particularly helpful to know whether it is a regression, i.e. did it work with older (official!) SBCL releases -- or is it "only" an old bug for which we haven't pulled the fix in yet. (Both kinds of bug fixes are important to us, but having this information makes it easier for us to assess the situation and plan accordingly.)
I'm not convinced of point 5. When Bob, CL User working on his favorite problem domain, chooses a library and declares it as THE one, the only people involved in the process are Bob and the library authors he'll have kindly contacted (following point 3). We must ensure that Bob effectively contacted and worked with every library author. Moreover, in my opinion, Bob shall involve every user of any library belonging to his favorite problem domain. Points 7 and 8 too must not be accomplished by only one person : declaring a library obsolete and renaming a library are important actions that should, in my opinion, be done cooperatively. Letting Bob do whatever he wants about his favorite domain is dangerous.
Does it still unconditionally show the kitten of death message?
Yes. I wasn't the one who added it, but I'm probably going to be the one who will ultimately remove it. My understanding is that the, uh, message behind this message is that that users ought not expect a production-quality software, and rather see it as a beta version. Considering how many people are now trying SBCL master for the first time (and I'm not surprised that most of them are reporting that it doesn't work as perfectly as Anton's binary), it seems to me that the warning as such still has its place. Is it the wittiness of the message that's under discussion, or the fact that it exists at all, or that it comes up unconditionally?
Mostly the last one.
Personally, I don't think the "kittens of death" message was ever justified other than being a temporary April Fool's joke or something like that. If the idea is to let people know it's beta, then just do what ever other software project in the world does and just label it's version number as "beta". The problem is not just that it's annoying, but that it actually *breaks* software functionality. For example, if you try to use a Lisp executable with piping over standard input/output, that message getting spit out will break whatever protocol you come up with. I use several languages in tandem, such as combining Erlang with other languages. Erlang has a binary protocol for spawning and communicating with external processes over pipes. I use Erlang and Python together all the time. I wanted Lisp to compete with Python in this role, but few Lisp implementations even support something like READ-BYTE for reading *binary* data over standard streams. SBCL does, but the "kittens of death" gets emitted and breaks the protocol. I have to use the alternative Windows port with the options --noinform --noprint --disable-debugger. It's a pain. On a side note, is there any reason why Common Lisp implementations make simple piping of binary (not characters) over streams so difficult? It's trivial in other languages like Python. Is there some library out there I'm missing that makes piping binary over standard streams portable among Lisp implementations and OS platforms? If not, why not? Are Lisp programmers just uninterested in such functionality?
If a Lisp implementation purports to support bivalent streams at all (like Allegro, SBCL, and others do), I would expect this sort of thing to be easy. And without bivalent streams, it's tricky for a library to rectify.
&gt; up to the task well it seems like people do a pretty good job with implementing the language itself, which is certainly no small feat :) &gt; 'community' are we not men? :P in all seriousness though, there's many people who've been actively working on and in the language for years and years who I'd love to have a beer with. I think the reason the 'no community' thing exists is just that it used to be pretty difficult to share code etc. 
It doesn't really seem that easy to me. Bivalent stream support must work on stdin/stdout, and not just things like files. Also, the implementation must be able to silence any extraneous output like debugging prompts or preambles on startup so that what is sent over pipes is *only* what is valid for the protocol. Without both of these being true, using binary pipes over stdin/stdout for interprocess communication won't work. For example, ClozureCL mentions that it supports bivalent streams, but I guess it must be just for files and not stdin/stdout because (read-byte *standard-input*) signals an error that the stream is of the wrong type (i.e. it's not characters). So ClozureCL doesn't work for this. ABCL has the same problem as ClozureCL. SBCL works fine on Linux but breaks on Windows due to the "kittens of death" message. The alternative Windows port must be used. ECL doesn't fail when doing (read-byte *standard-input*) but I can't tell from the docs if extraneous messages can be silenced. There's a lot of blank pages in the docs. In the past, I also had problems getting ECL compiled on Windows without hassles. Clisp only allows making GPL'd software with it, so I didn't even consider it because I want the Lisp implementation to be used at work for some things. Allegro is proprietary, and I don't want to force everyone who needs to use a library that uses pipes for communication to have to use a proprietary Lisp implementation. So while it's possible with Lisp with great hassle and being choosy about implementations, meanwhile for Python I can just do "python -u" on all platforms and it just works. Ruby and many other languages also handle this just as easily. I'd like to use Lisp instead, but it just doesn't seem to be a priority to many implementations. I find that strange, since using pipes is a pretty common and basic thing to do. 
Does anyone else feel that using quote, quasiquote and unquote in places other than macros is sort of gauche or weird? Obviously, if one wants to use symbols, one must use quote, but I find myself shying away from using quote and quasiquote to construct run-time values, almost always preferring invocations of `list` instead. I think this has something to do, in my mind, with preserving the distinction between syntax, as a specific kind of data, and other kinds of data, with the former being the province of quote, quasi and unquote, and the latter being in the realm of construction by function application to other values.
People like me can go [here](http://www.smbc-comics.com/) and click the 'Random' button for instant resolution of their cognitive dissonance. It happens to me every time. : (
The GC calls an user-specified routine to deallocate memory as well. Again, just define your own malloc library (dlmalloc is a good starting point), and hack up an mmap-based allocation to be able to restore the state from disk. There already are hacks to serialise the full state of a Lua process to disk; they work at a lower level, by hooking into mmap directly. EDIT: I think I see where your confusion lies. The hook isn't Lua-side. It's at the C level, in the runtime itself. When I say "allocate" I mean "the runtime asks for more bytes to write to." If you control allocation and de-allocation, you can easily know which pages to write directly to disk (one could even just ftruncate and mmap a file from the start) when you wish to serialise that part of the C heap.
Conversation from 6 years ago: http://www.reddit.com/r/programming/comments/7qng/lisp_naming_conventions_that_might_trip_up_newbies/ (OT: I'm so glad to see that Cliki looks nice. EDIT: And it even has edit history! Excellent! EDIT2: I understand the "refresher" part of the submission title. My link to the previous post doesn't imply any ill will.)
Think about these: Common Lisp has special variables. When switching stacks just by tweaking the current stack pointer, would you expect their bindings to change automatically, too? If not, will the Lisp code depending on those variables still work? How about non-local transfer of control, i.e. unwind-protect and catch as well as all higher-level mechanisms built on top of it? Would the new code try to unwind the new stack to a place on the old one? The stack holds spilled register values holding pointers to Lisp objects. If the runtime doesn't know you've switched stacks around, and hence doesn't scan those stacks during GC, what happens?
Thanks, this is exactly the type of response I was looking for. Is there no control flow mechanism in lisp (standard or not, ignoring OS threads for now) that allows building real coroutines? I want to add a blocking layer over a non-blocking API, and things like cl-cont aren't going to cut it.
I 100% support this effort, though I think the "portable" aspect will be difficult, as each CL implementation will probably need special considerations. Have you looked at https://github.com/deliciousrobots/green-threads ?
I think you're wrong about cl-cont: https://gist.github.com/4027654
I am glad the you like the new cliki! We moved cliki.net over to the new one very recently, and so far so good. Any questions/comments? If so, contact me.
Ah, I see. My main problem with this is that it [blocks inside the thread, but not outside it](https://gist.github.com/4028147). The expected/desired output: start app start sleeper ;; 3s pause end sleeper: HAI end app Actual output: start app start sleeper end app ;; 3s pause end sleeper: HAI Is there a way around this? My hope is that there would be a way of doing this that's transparent to the code implementing the blocking call such that control does not return to the caller until the async action is done, regardless of whether the caller is wrapped in `with-call/cc` or not. The idea being that you could transform lower-level drivers from synchronous to asynchronous *without the caller knowing*. I believe true coroutines provide this abstraction.
I think coroutines are fairly straightforward to implement with first-class continuations. Unfortunately, Common Lisp doesn't have continuations and there seems to be a lot of contention in the community about adding them.
A couple things, what your asking (the first part) is pretty easy with green-threads, you can fire up a whole bunch of threads that all do "blocking" async commands and they will all run concurrently, even nonblocking delays. https://gist.github.com/4028233 The last part... where you magically swap out usocket... that of course can't be done with cl-cont/green-threads since you need the CPS transform to get at the continuation, so you have to have access to the application code itself. Edit: I forgot to add that I hope cl-coro works out. I think the questions of unwinding can be answered probably sufficiently to get work done. You can see how I handle the special variables in green-threads, borrowing bordeaux-threads *default-special-bindings* interface and using progv each time I switch to a different thread.
Oh, didn't see your edit, glad I scanned the thread again. Thanks for the suggestions (and all the code samples you've been typing up). I'll check out how you and bordeaux are handling special vars. It seems like cl-coro is going to be an uphill battle since, well, I really have no idea how lisp works under the hood. On top of that, the details are probably fairly different across implementations. I've probably got a lot of research, hacking, and long nights coming up...but I think it might be worth it end.
Sorry for the double reply, I have a few questions (and answers). Special variables: good question, haven't thought it through at all. I'd probably copy however bordeaux-threads handles it. If it's not possible to handle this case, it will have to be a caveat of using the library. For unwind-protect and other stack modifiers, I think if they happened on a new routine, they would not bubble up to the original caller. An unwind-protect surrounding bordeaux-threads:make-thread will not catch exceptions in the spawned thread. This makes sense, and is the behavior I would emulate. Lastly, what are spilled register values? Also, are you saying the GC is holding references to the values in the stack and if the current stack switches, the values will be collected and freed? Any information you can give me about what's going on under the hood and how I would work around various issues is gold to me. Thanks!
for completeness, this is how I would construct your code example to get the output and delay the way you want: (defun sleeper () (let ((f1 (green-threads:make-future))) (as:delay (lambda () (complete-future f1 'hai)) :time 3) f1)) (cl-cont:defun/cc app () (format t "start sleeper~%") (format t "end sleeper: ~a~%" (wait-on (sleeper)))) (as:start-event-loop (lambda () (with-green-thread (format t "start app~%") (app) (format t "end app~%"))))
&gt;The array-operations package has the nickname *ao* I think libraries should never define nicknames. That's just looking for easier name clashes. Nicknames should be defined by the user only.
Nice! I actually wrote a VNC client library in Gambit so that I could have a frame buffer to draw and show animations on, and then used a function of three arguments (x, y, and t) to generate each frame of the animation.
Not yet, I've been pretty busy with [redacted]. Once I get the time to get back into it I'm gonna hack together an associated slime contrib so you can use the package names interactively. It might be a blind alley for that kind of usage, but as it stands it could be used to at least *load* conflicting systems. FWIW, I've also hacked together the customized reader solution for ccl some time ago. If the CDR proposal #lisp was talking about the other day happens I'll contribute an implementation of it for CCL.
There is also [cl-package-aliases](http://www.cliki.net/cl-package-aliases).
Read the #lisp logs. Looks like that CDR has some potential. Seems a shame to wait, but at the same time, it seems silly to dive into your code or any of a number of other solutions only to be headed in the wrong direction. I guess we need the CDR to focus the effort.
Wow, that was fast. It's gone
Or structs ... that seems like an ideal case for structs ... or even DEFTYPE with SATISFIES and PROPER-LIST-P ... Or, to be more specific : "what is it exactly that you want to do?"
As someone who has worked with codewalking CPS, and interpreted CL with CPS (arnesi) for like 8 years now, I have to agree with you 110%. Now, well, I like &lt;monad&gt;s for that sort of thing : (defclass &lt;continuation&gt; (&lt;monad&gt;) ()) (defvar &lt;continuation&gt; (make-instance '&lt;continuation&gt;)) (defmethod result ((m &lt;continuation&gt;) value) (lambda (k) (funcall k value))) ;m &gt;&gt;= f = Cont (\k -&gt; runCont m (\a -&gt; runCont (f a) k)) (defmethod bind ((m &lt;continuation&gt;) mv mf) (lambda (k) (funcall mv (lambda (a) (funcall (funcall mf a) k))))) ; callCC f = Cont $ \k -&gt; runCont (f (\a -&gt; Cont $ \_ -&gt; k a)) k (defmethod call/cc ((m &lt;continuation&gt;) fn) (lambda (k) (funcall (funcall fn (lambda (a) (lambda (_) (declare (ignore _)) (funcall k a)))) k))) That is not transparent at all, and I thank the gnostic monad for that every day! 
not sure what you're trying to say.
I use quickproject. I added the following to my .sbclrc file to take care of the git repo initialization problem. You'll notice it also sets the README format to markdown--this is my preferred format because it works well with Github. (setf quickproject:*after-make-project-hooks* (list (lambda (pathname &amp;rest args) (declare (ignore args)) (nix:chdir (fad:pathname-as-directory pathname)) (rename-file "README.txt" "README.markdown") (external-program:run "git" (list "init" ".")) (external-program:run "git" (list "add" ".")) (external-program:run "git" (list "commit" "-m" "Initial commit"))))) You'll have to quickload some libraries first: `'(:osicat :external-program :quickproject :cl-fad)` I also like to set defaults for the quickproject \*licence\* and \*author\* variables.
It seems like cl-project sets things up a bit more similarly to leiningen in the clojure world. I'm still in the early days of learning Common Lisp, so I appreciate having the testing stuff set up for me in the template. Sometimes it's nice to have someone come along and make an opinionated stand.
I don't have either an Android or an iPhone so I can't say how well it really works, but I believe ECL works on both. A quick google of ECL and Android found https://github.com/ageneau/ecl-android
I tried fruitlessly to get any of the below working on a modern version of iOS (I'm not a very experienced C programmer but I do know the basics). On the other hand I managed to get Lua working on both Android and iOS inside an afternoon. I guess being designed for embedding really pays off but MacRuby/Rubymotion shows it can be done for other high level mainstream languages. I'd actually pay for a decent well maintained Scheme/ECL implmentation for iOS and Android. Nu doesn't count either because it's too specific to the objective-c runtime to work on Android.
Agree, plus it's got a cool name ;)
Also on Android.
Could you release a Lua interpreter REPL on the Google Play Store? And would you consider doing Nu for iPhone anyway?
On Android I used - https://github.com/mkottman/AndroLua , it's remarkably simple to get started. Also on the Lisp -&gt; Lua front I know that the Longster has been considering porting his Outlet language to Lua, should be pretty easy to do yourself for varying values of easy and self: https://github.com/jlongster/outlet
I really like Nu, but I wish he hadn't been so influenced bu the Obj-c syntax, I'd prefer something a bit more platform neutral, but it's hard: Interestingly, Spotify have a fork of Nu, and one of their devs seems to be playing with it, I dearly hope it gets some blogging attention: https://github.com/spotify/nu
Yes, yes, yes! I love Chicken Scheme. It's the easiest, most practical Lisp out there. csi AND csc AND eggs? Yes, please.
android-chicken-example will give you an repl over tcp:1234 and you can e.g. push an file to your phone/tablet/emulator via adb, which will interpreted immediatly. It comes with OpenGL ES support. chicken-android is a more mature version, which is trying to give you a repl and you can load eggs. At this point ou have a running csi in /cache. However you will have to setup a cross-chicken build with the Android NDK, and with that you can pull and compile eggs, which you then can load with chicken-android. I am preparing a little tutorial how this can be done. But remember, both projects need polishing and are just in the beging. cheers
And the seller promptly cancelled my order. Nice. Anyone ever noticed that Amazon's pre-order price guarantee is meaningless because all the vendor has to do is either keep delaying delivery (current position I am in for a Fables comic book I ordered months ago and have seen in bricks and mortar stores, or just cancls the order.)
You should blog about that.
This is actually really cool, but something about the syntax makes me feel ...weird. Also, having to escape {} isn't my cup of tea, although inline javascript isn't either. So, overall, great job. Also, I really would avoid comparing it to PHP. After learning lisp, I felt like PHP was the freak baby locked in the basement. I can say this because I program PHP all the time in my job and for personal projects. I fully understand what you're going for by saying "PHP for lisp," (easy web pages) but perhaps there's another way to say it that won't scare off any programmer who's ever used anything besides PHP.
Why so much secrecy? What is this, a commercial version of ECL?
It does say the license is "TBD" so I'm guessing they're still arguing out whether they can make money on it or if they should just release it to the community. In the mean time I'm guessing they've been using it internally for developing the software they actually make money on.
Sweet, targeting both platforms simultaneously? Looking forward to it.
I don't suppose we'll get any way to interact with a dynamic environment on the device. I saw "compiles to C" in there...
Calling anything the PHP of anything makes me never want to see or touch it.
Not if it is testing out all my _other_ software, and I am planning on doing it just for that. Can you tell me of a blog software that is static-based, written in Common Lisp, but the webserver is only hunchentoot for posting comments, the rest is all static HTML? EDIT: ok, I found a software that i can use... o-blog. and it integrates with disqus .... thank you!! That is my plan, and to use my For The Web style monads and my SMUG-style new monadic parser interface to have all the blog posts be in org-mode .org, parsed by the &lt;parser&gt; and exported to HTML. Basically, it is a reason to test what I wrote like 2 years ago before my contractee decided to go with something completely different :)
MacRuby/Rubymotion pulls it off for IOS because they reimplemented the language on Objc with LLVM. 
Nice writeup. I haven't browsed c.l.l. in a long time. I see WJ and others similar to him are still there. It's like nothing has changed in, what, 10 years? Oh, and Xah still hates C .. yadda yadda ..heh..
What will be accomplished by reimplementing the core in C++?
Wait, this subreddit isn't about actual lisps? I was using the random button and got here, which probably explains my confusion.
It'll have more plusses!
Just to be clear LISP is a programming language with many "dialects" and this is a subreddit devoted to them. It isn't about speech impediments (if that's what you were thinking about). So the link is about an up coming algorithmic music composition app.
You can always map the video memory into your user mode program and then directly draw to the screen using memory disposals. I've done that on the Raspberry Pi for laughs (https://plus.google.com/u/0/101473924494271635476/posts/2LDwW4xzaJf) and the code in my lispi repository (https://github.com/hanshuebner/lispi) is both Pi and CCL specific, but with a little hacking and looking around, it should not be too hard to do the same on another Linux box. Doing high resolution graphics naively as in my demo program is rather slow, though. In text mode, things should be fast enough to implement robots or rogue like games directly in CL without resorting to any particular optimizations.
Tempting but bad timing for such event.
It'd be really nice to have a CL-from-the-command-line standard, though. Many's the time I've wanted to just slap a script in CL in there and run it from the command-line. Last I checked there were something like 3-4 different command-line parsing libraries. As Fare mentioned, it'd be nice to have a standard. That would, in turn, enable a "runlisp" like functionality.
Good work. Haven't even heard of Vagrant until now.
Another alternative is to *make your own script* and drop it in /usr/bin/cl. It would do its best to autodetect sbcl, wx86cl, lx86cl, clisp, etc etc and provide a *standard interface* for calling them via command line. So you could always call it with the same options, no matter what CL implementation it finds on your system. Then you could easily have a ~/.runclrc that tells it which implementation(s) you prefer, and provide any other options it would need (norc by default, heap size, etc). Obviously, this would work on *nix systems better, but could work on windows with cygwin as well. Actually, I like this idea enough to take a stab at it this weekend. Wish me luck.
What we really need is a lisp os. (yes i know of some various projects, but i'm not entierly satisfied with any of them)
Competitive with other language ecosystems you say? I care not for popularity, i care for functionality. I would much prefere to have lisp natively than in an interpreter in a foreign OS in my OS thats why i feel the need for a Lisp OS.
Right, it would work a bit differently than what you were suggesting (mostly with the autodetect feature). I think you're going to have an uphill battle getting different CL implementations to push their executable path to a file somewhere on the system, so it might be a good workaround in the meantime to build a script that does its best to get every implementation considered, and have a user-based config file that points the script to the implementation you want by default. Also, some implementations distribute in binary form and don't have an install process other than just untarring, so no matter what, you're going to have to edit some file somewhere by hand to point the script to your shiny new cl. Also, if you can get implementation maintainers onboard, there's nothing stopping us from updating the script later on to be able to read from a "latest installed cl" file and updating its config to use it.
There are a couple of x86 on the metal lisp projects out there, and there are also a couple of hardware projects related to lisp, but once again nothing extraordinary.
An OS is measured by the public for its application support. If someone made a killer mobile OS in Lisp and showed how easy it is to write Lisp apps, and how memory management is no longer a problem... How about Lisp on top of ARM?
Thank you.
What would you say is the immediate problem?
I agree on the lisp os comment. I don't care if it doesn't solve anything. The genera demos that I have seen are proof enough that we are living in the past and missing out on technology already 30 years old. Oh what things could have been if the imperative programmers had lost.
Yup, this is how Java does it. Different Java implementations can provide `/usr/bin/java` and `/usr/bin/javac`. `update-alternatives` selects which package those symlinks point to. 
For Scheme there's [SRFI 22](http://srfi.schemers.org/srfi-22/srfi-22.html). &gt; *scheme-rnrs* expects code written in RnRS Scheme. *scheme-ieee-n-y* expects code written in IEEE n-y Scheme. Specifically, *scheme-r4rs* expects code written in R4RS Scheme, *scheme-r5rs* expects code written in R5RS Scheme, and *scheme-ieee-1178-1990* expects code written in IEEE 1178-1990 Scheme. *scheme-srfi-0* expects code written in R5RS Scheme using the extensions specified in SRFI 0. *scheme-srfi-7* expects code written in R5RS Scheme using the extensions specified in SRFI 7. This naming scheme is the "[consensus](http://lists.debian.org/debian-policy/2005/05/msg00062.html)" for Debian. I've found a few Ubuntu Scheme packages that implement it.
I would dare to say that it does solve things. The whole native binary "problem" (which really isn't a problem imho) is solved by having a lisp os. Then again i don't see the problem, you have an interpreter you run the program, no problem. I do think however that not having to have an interpreter but runing lisp natively would be prefered, thus i find the "need" for a Lisp OS.
I'm wondering about using lisp in shebang lines: isn't this what cl-launch is for? (available in quicklisp, although seems to require some extra installation step to use; nevertheless if you read its documentation, there are even examples there how to actually use it for the shebang line).
In this sense, there is a "need" for a Perl OS? What about a Python OS? :P
How is that an issue? The issue is that we're stuck in foreign enviornments running something through an intermediate interpreter instead of natively as we should. Either add capability to run common lisp into whatever OS you run, or run the whole OS in Common Lisp. The latter would be preferable imho.
Yes i agree it could be a problem and i imagine that problem would be much more prominent in a LISP OS, but then again there are ways to deal with it.
So, I need to know because It does not say in my 'reading' ... what makes this different from CL-LAUNCH that cannot simply be added to that project, so needs a completely different thing? Or, why did you not choose to go with what already exists?
Didn't know it existed. Oops, there goes a day.
But runcl still fires up the interpreter which in turn fires up any packages. This takes time and is inefficent. In a Lisp OS everything would be compiled until it needs to be recompiled thus saving a lot of time. An alternative to a foreign system would be to implement LISP in that OS. This is far better than having to start a process that loads all packages and compiles the lisp code before running it. IMHO that is.
happy thanksgiving, american lispers :) (happy thursday everyone else) I've heard mention of other consolidation efforts being proposed/underway but these are the only two I know the details for. Please add more if you know of any/would like to start one. Cheers :)
Well. fwiw, some idiot hosts a site where such things are easily found: http://www.cliki.net/site/search?query=unix+shell+scripting Any issues you have with cliki.net should be taken up with the owner of that domain, whois shows the wrong name, but the right email address :) 
For pages where you need to type {} literally a lot, you can use the [SYNTAX directive](http://lisperator.net/sytes/syntax/raw-mode#directives) to change the special chars. Yeah, it's definitely not "PHP". I thought it would fit the analogy because it's relatively easy to deploy; templates can freely include each other, etc. Basically, you could do everything from the templates (assuming you define the primitives you need in CL). It's quick'n'dirty, and if you're not careful, you probably get a similar mess to what you get with PHP (but let's face it, every website is a read-only mess; talking about the code here). It works for me, better than the alternatives (i.e. Perl or PHP). It also was quite fun to work on it. :) Also it begs the question, if Lisp is such a great language (and it is!) then why is every Lisper's website either a static directory of 1994-like htm files, or using WordPress or Blogger? (simple: because as Xach points out, “writing blog software is a waste of time”. Can't argue with that, but heck, let's prove the platform superiority!)
We are not allowed to replace LET -- even temporarily through MACROLET -- due to [restrictions on the CL package](http://www.lispworks.com/documentation/HyperSpec/Body/11_abab.htm). Putting the CL package restriction aside, one technique of simulating non-recursive MACROLET is to create a copy of the global macro and then have the local macro use the copy. (defmacro foo (&amp;body body) `(progn (format t "~&amp;global foo~%") ,@body)) (eval-when (:compile-toplevel :load-toplevel :execute) (setf (macro-function 'global-foo) (macro-function 'foo))) (defmacro with-local-foo (&amp;body body) `(macrolet ((foo (&amp;body body) `(progn (format t "~&amp;local foo~%") (global-foo ,@body)))) ,@body)) 
Ah! I wondered if there was a way to get "first class macros." This is what I was looking for, I think. I'll play around with this a bit. Also, I was using `(let)` as an example, I'm actually going to be wrapping a custom version of it, but wanted to use `(let)` so people understood my problem without having to learn the ins and outs of some custom macro I'm building. I did not know about that package restriction though, so thanks for bringing it up! I'm going to attempt to wrap what you have above into some sort of generic macro `macrolet-non-recursive` or something in case other people have the same problem. Is there a way to access a `macrolet` macro function? For instance, does `macro-function` work under `macrolet` or does it only work for the top-level? Thanks for your help.
Ok, I'll take your word for it. Thanks!
I've never used the infix package before, but I just loaded it now and found `infix:string-&gt;prefix` (one of only two exported symbols, and the other one is for testing). Doesn't this cover what you want? (infix:string-&gt;prefix "2+3*4") ;=&gt; (+ 2 (* 3 4)) (infix:string-&gt;prefix "foo(x)") ;=&gt; (foo x)
Once again, your answer goes straight over my head =]. BUT I will look up what you're talking about and try to get a better understanding. I just found out about `symbol-macrolet` last night while researching this problem, but I don't really see how it would help to solve my problem. There are a few pieces I'm just not connecting in my head, I think. For instance, what are "lexical annotations?" Could you give me a quick example (if there is one) that points me in the right direction? Also, believe it or not, this is all to add `handler-case`-like error handling over some `let` macros inspired by your [futures implementation](http://www.reddit.com/r/lisp/comments/11lo3a/clasync_asynchronous_operations_for_common_lisp/c6nnvwk): (future-handler-case (mlet ((a (get-user-from-server))) ...) (connection-error (e) ...)) `(get-user-from-server)` would then be wrapped in a `handler-case` (as well as the top-level form), and could also be wrapped N times, allowing to wrap errors that happen asynchronously in a native lisp-like form, without having to wrap all the binding forms individually. Is there a better way to do this? As usual, your help is invaluable.
Ok, thanks guys, I think I solved it: (defmacro alet (bindings &amp;body body) `(let ,bindings ,@body)) (defmacro add-to-form (&amp;body body &amp;environment env) (let ((alet-orig (macro-function 'alet env))) `(macrolet ((alet (bindings &amp;body body) (funcall ,alet-orig `(alet ,(loop for (bind form) in bindings collect `(,bind (1+ ,form))) ,@body) nil))) ,@body))) Now I can call: (add-to-form (add-to-form (alet ((x 5)) x))) and I get `7`, and my expanded form is `(let ((x (1+ (1+ 5)))) x)`. Couldn't have done it without your guidance.
Hm yes I forgot that the raw macro function could be called directly. I say "forgot" because I *must* have known since I played with `*macroexpand-hook*` in the past, but I can't remember knowing. A couple things: you should check for `alet-orig` being nil to cover the case of `((flet (alet ...)))`. I'm also wary of passing the nil environment. Though I couldn't immediately find a fail case, I think you want to pass `env` there.
Ok, I'll pass in the environment, not a problem. How would `flet` make `macro-function` return nil, though? Does `flet` use macros?
reader macros don't eval code. They transform input which is read from a stream. If a reader macro implements an infix reader, it can also read from a string. This means your functionality is mostly already included in an infix reader.
I'm not familiar with the library, but as as security guy, I can add: BE CAREFUL. Lisp lets you do all sorts of magical things, but "arbitrary code execution" is not something you want to take lightly. On a related note, I did some work for a client once, where I found that his Java server app included BeanShell-interpreted page templates, where some users could define new ones. System.exit(0) whacked Tomcat immediately, which made for a pretty solid proof of concept.
I know. This is why I avoided the reader macro and eval approach. Functions and variables are stored as strings (their names) together with their values or lambda in separate structures, \*defined-variables\* and \*defined-functions\*. If it's not in there, the user can't call or use it. For arithmetic operations, the string, e.g. "+" or "**" are associated with their lisp functions.
The only reason I commented about it was due to reddit being a popular place for Lisp newbies. They've seen things like (+ (* 3 (+ (* 2 4) (+ 3 5))) (+ (- 10 7) 6)) that I've pulled from SICP. Much better to tell them to type #I(3 * ((2*4) + (3+5)) + ((10-7) + 6)) 
If you want the user to input formulas, then you might want to write a small and secure evaluator/compiler. But that can also work over code parsed by a special reader. 
You have the unevaluated sexp, so you can walk through it and accept/reject whatever you like. I expect you'd make a list of operators and accept only those.
I was referring to (flet ((alet (&amp;rest args) args)) (add-to-form (alet 0 1))) in which case `macro-function` will return nil, whereupon you should return ``(progn ,@body)`. It may seem unlikely, but covering all the bases upfront can be a big help later on, and besides is the Right Thing.
Excellent point. I'll have a look, thanks!
OK, glad you've thought that one out then. Cheers!
What about speed? How would responsiveness compare for a lisp app vs. a java-script app? edit: I should make it clear that although the feature set is important, speed is even more crucial for my needs. 
Your question requires generalizations and assumptions which may not be valid in all cases. Common Lisp should be able to exceed Javascript in performance/responsiveness for several reasons: * The best Lisps are faster than the best Javascript implementations. * Several implementations have native threads. * Lisp provides access to lower-level constructs, static typing and other optimizations Javascript doesn't have. That doesn't necessarily mean that a given Lisp application will be more responsive than a comparable Javascript application. It means it *could* be if designed with that goal in mind.
The advantages of Lisp are well known and have been discussed to death elsewhere. There's nothing special about web development. There's probably also nothing special about your application. There's a good chance that some library or framework solves 80% of your problem, and therefore the host language of whatever library solves most of your problem has a huge advantage. There's a good chance that isn't Lisp and you're therefore better off using something else. If you *are* doing something genuinely new and different, the advantages of Lisp are the advantages of Lisp and will serve you well if you know how to make use of them.
&gt; Hunchentoot, although threaded so maybe not the best for high-traffic scenarios, is a great web framework to get started in... To anyone looking to use Hunchentoot in production, be aware that its session ID generator hands out a guessable sequence of IDs, which makes session hijacking a piece of cake. EDIT: ...as I understand it.
Are you talking about client side Javascript? Asking if server side language is faster than client side script does not make sense. 
Speed in the server side of web applications is more or less moot. It's completely dominated by the time spent transferring and parsing the DOM and javascript on the client side.
I think I might have put one zero too much into that number... But you are right regardless. Clever algorithms beat fast languages any day in the week.
client side of course. 
Those silly vanishing column labels make this chart a lot more difficult to read than it needs to be.
"Unfortunate" is one of several adjectives that come to mind. Here's more info: http://lists.common-lisp.net/pipermail/tbnl-devel/2008-October/004417.html Excerpt: &gt; I know the documentations discourages from considering sessions as really secure, but after some experiments it turned out that in normal case it is a matter of just several hours to hijack hunchentoot sessions. ~~Again unfortunately, the documentation doesn't call out this particular vulnerability.~~ EDIT: Actually, that may be about eavesdroppers being able to easily decrypt information stored in the session cookie. I'll look for the thing about session ID generation today. In the meantime, can anyone with knowledge of Hunchentoot's security weigh in? EDIT2: Ah, here we go. The thread at the very top, "Sessions not secure?" from 2007: http://osdir.com/ml/lisp.lib.tbnl.general/2007-12/threads.html So "makes session hijacking a piece of cake" is probably overselling it, but nobody is really sure.
You'll have bigger issues, like the fact that your networking stack can't handle more than a certain number of connections. Seriously, the biggest speed boost most sites will ever see? Properly CDN'ifying their assets.
I'm about six months into a pretty substantial investment in Lisp (RESTAS, CL-WHO, Hunchentoot, CXML, Parenscript) to provide the glue to prototype a performative, browser based UX for automated testing in telecommunications networks. We just made our first call through the SIP side of things last week, so I expect to start writing up the experience next month, December. At this point, I couldn't imagine prototyping a system of this complexity with realistic pathways for Internet scale out in any other language. But then, I'm just a lot *happier* to be working in Lisp. I take all the bugs very personally.
That was surprisingly effective at making me happier that I have chosen to get into web development with lisp. Everything that you said is beyond the scope of what I'm looking for, but it's always nice to hear people developing in such a nice language. I absolutely love it too. 
Please blog about it! :-)
Incidentally, it has been an interesting experience developing a library simultaneously in two Lisp dialects. Anyone else doing something similar? At the moment I have two entirely different sources and repositories for each version of shadchen, but I wonder if a version with some compile time switches and a preprocessor might make things easier? There are significant differences between the libraries here and there, given the differences between Emacs Lisp and Common Lisp. Ideas?
It is a good idea - how would the dual status of Shadchen, being in Common and Emacs Lisp, affect the question of which library in the CL world becomes the standard? [EDIT]: Optima looks pretty slick - I'd port it to Emacs and add support for some of the stuff that shadchen has, but optima is missing. I wonder what the implementation looks like - mine is pretty amateurish, I'm sure. 
You have more experience than a lot of us, I'm sure. I'd love to hear more about your experiences.
give me a break, those problems affect every language. in particular, designing libraries is *hard*. and i believe it gets harder (but more rewarding) as you toss in first class functions, objects, MOP, etc.
It's a profound problem that affects the Lisp community more than any other save for maybe Forth, but those people don't even publish their shit. Stop pretending this isn't one of the biggest problems. We need to get better.
The myth of the lone hacker is not Lisp's problem. Lisp's problem is that is is afflicted by *people who want to fail*, such as whoever wrote this. If you just look back a bit you will very quickly realise that the position with libraries and utilities, as well as implementations is better than it has ever been, including during the mythical golden age, and is improving all the time. The golden age is, in fact, now. And here's the thing: if you thought that the problem this article talks about existed (which it doesn't) what would you do? Would you (a) start a bunch of collaborative projects and *fix the problem*, or would you (b) write a whiny and ill-informed article (was this person even *born* during the AI winter?)? Well if you wanted to fail, you'd clearly do (b) which has the advantage of not fixing the problem, not actually requiring any real effort but making you look good (or making you think you look good). Lisp is just surrounded by these people who sit around erecting vast fictions to make sure they can never get anything done. Consider all the whining about the package system over the years. Yes, we *know* it's not perfect, but compare it with *any part of JavaScript* and you'll pretty soon realise it's not, in fact, so bad. The only thing about Lisp stopping from getting stuff done is you. The single best thing that would benefit the Lisp community would be feeding these people to the sharks.
what a piece of garbage
As someone new to Lisp I'd agree with general the sentiment of the article. It can be difficult to find what you need to get started. This colours people's initial impression of the language, especially when compared to newer languages like Python which makes its documentation and standard library immediately identifiable and easy to find. I also think that recurring bad myths really do indicate that there is a problem. Whether this problem is with how the Lisp community presents Lisp or Lisp itself is up for debate, but a more unified approach to the language would help uptake in my opinion. Additionally, posts like that of tfb are even less constructive than the article he attempts to critique.
I agree. Quicklisp has undoubtedly made things better, but there is still a great deal of work to be done. [Fare of ITA fame](http://fare.livejournal.com/169346.html) seems to think something should be done about the large number of partially-baked libraries, AND he's doing something about it. There's a fallacy in thinking that people can't write about perceived problems AND do something about it. "You're complaining about the situation, but instead you should have spent those five minutes writing your blog post writing half a line of code."
Lisp is by definition a language community that values diversity, different approaches, research, dialects, experiments, ... That's why McCarthy created it: as a research vehicle to explore new notations, new paradigms, new boundaries. Now, Lisp is not Python ('There should be one-- and preferably only one --obvious way to do it.' - by providing some limited form of imperative object-oriented programming) and all kinds of people are surprised. Why? Exactly 'the way of Lisp' makes mass-adoption of a single Lisp dialect difficult. But it ensures that it will survive the coming decades as a tool for people who need an expressive language. Now a sub-group, like Common Lisp users, can come up with a definition of common programming styles and libraries for common problems. But even Common Lisp itself is still defined in such a way that it is flexible for experimentation with new (sub-) languages. Even such a subgroup can't escape the fact that some programmer can violate everything, be a rebel and turn the language around into something different. Since Common Lisp (and most other Lisps) allow for such diverse programming styles, it is hard to come up with 'THE Common Lisp programming style'. It's not the bad community, it's just that this community is formed by people who value a very expressive tool with little boundaries - Lisp. A tool which was created for those. Lisp is the ultimate fractal language - in so many ways.
One think that I find problematic in reddit is that sometimes, like in this case, a link points to a lousy article, but the discussion of it is interesting anyway. Apparently people tend to downvote it, but this kills the discussion as well.
I agree that the ability to express and extend in C-L is a strength. But that doesn't mean there shouldn't be a great jumping off point (in the form of clear documentation and libraries) for that expressiveness. 
Your post is almost romantic in its love for Lisp :) It is probably true that an advanced user has less need for style guides, recommendations, suggested libraries, etc; the CL community is probably composed of more experienced programmers than other languages. This however is a self-reinforcing loop: such a community becomes less interested in providing aids to novices, the novices becomes rarer, and so on. Ultimately, the technology becomes a niche tool for rare super-experienced old wizards, and then disappears. 
You are right, there does need to be a balance between time spent calling for change and actually changing things. That balance is hard to strike for anything though. There's nothing inherently wrong with any of these resources, they just don't feel as slick as the tools for learning provided by more modern languages like Python. I'm actually working my way through Peter's book at the minute and I like the way he gets straight into actually using Lisp. Something many introductory texts fail at. CLIKI seems a mixed bag. Some pages are well presented and offer a lot of useful information, others are practically empty. As a website it looks dated, something that seems common to a lot of the resources and may be part of the presentation/PR problem that some feel Lisp has.
no comment on the article really, but whatever happened to kt? Things seem a little square without him around ranting on this and that.
Due to my own unfamilarity, I find JavaScript syntax a bit confusing when it gets very nested, so Parenscript has certainly helped overcome this problem. As for debugging, I cannot think of any situation where the level of indirection has hindered solving a problem. But my use of the debugger has been very simple: setting breakpoints, inspecting values. This is a good question, as it was certainly in my mind when I chose to use Parenscript, so I will keep it in mind when I (finally) start to write up the experience. 
This could help http://lispgames.org/
Well, commercially I know that Naughty Dog uses a lot of lisp, this isn't something that you can use for your own development though.
It's a version of Scheme. But they don't use GOAL anymore, AFAIK - since the acquisition by Sony. They mentioned that they now use Scheme a lot in their production pipeline. http://www.naughtydog.com/docs/Naughty-Dog-GDC08-Adventures-In-Data-Compilation.pdf http://www.naughtydog.com/docs/Naughty-Dog-GDC08-UNCHARTED-Tech.pdf http://www.youtube.com/watch?v=Z8Xamkb-J2k
You can also use ABCL which is a full Common Lisp implementation running on JVM.
Might be worth checking out the gambit scheme space invaders game, https://github.com/sthilaid/space-invaders There's a more in-depth tutorial on using sdl/opengl with gambit [here](http://www.animal-machine.com/blog/2010/07/brief-ffi-tutorial-for-gambit-scheme-and-sdl/)
Not an actual game engine, but of course the book [Land of Lisp: Learn to Program in Lisp, One Game at a Time!](http://www.amazon.com/Land-Lisp-Learn-Program-Game/dp/1593272812/ref=sr_1_1?ie=UTF8&amp;qid=1354389793&amp;sr=8-1&amp;keywords=land+of+lisp) might interest you.
Since this is still on the front page, I'll comment on a few new features here. The `or` match pattern now statically ensures that its sub-patterns all bind identical symbols and `must-match` now ensures that the pattern match is calculated exactly once, in case of matches which might have side effects. 
It's not going to help you much without a ton of reading through poorly commented code, but I've got a simple (read: *very* simple) game engine going on my github: https://github.com/orthecreedence/ghostie. It has a lot of dependencies that probably aren't in quicklisp (although they're listed in the README) and requires two C so/dll files: [chipmunk physics](http://chipmunk-physics.net/) and [glfw](http://www.glfw.org/). It uses SVG files as "levels" (along with an accompanying "meta" lisp file that among other things gives different layers in the SVG a depth). Anything in depth 0 is a physics layer, meaning the character will collide with it. This makes it really easy to build a simple level with a ground and fixed obstacles just in an SVG file. On the TODO is a level editor, scripting, animations, etc (IOW everything not making it a toy project). It currently only supports OpenGL &gt;= 3.3 because it makes use of shaders, so make sure your video drivers are somewhat up to date if you wish to give it a shot. My ultimate goal is to create a full-fledged game engine out of it, so building levels, adding characters (minus AI, which will be app-dependent), interactive objects, etc will all be easily done through a level editor. It's not *nearly* there yet though =]. The project is in its infancy, but actually works really well so far. If I didn't have a job or bills to pay, I'd work on it a lot more, but sadly right now my job and cl-async take priority.
It should be easy to do with a concatenated stream, see my comment on that blog.
It's also refreshingly fun to read! 
Sucker Punch productions in Seattle mentions Lisp as part of their job postings. I don't know *anything* about them except for that; I'd guess they have an embedded Lisp for a scripting engine though. http://jobs.gamasutra.com/jobs/358-32121/Sr-Game-Play-Programmer-Sucker-Punch-Productions-Bellevue-WA-USA 
Made another one to sort a list, using suggestions from dig1 and EdwardCoffin. (defun insertintosorted(x ls) (if (null ls) (list x) (if (&lt; x (first ls)) (cons x ls) (cons (first ls) (insertintosorted x (rest ls))) ) ) ) (defun srt(ls) (if (null ls) (list) (insertintosorted (first ls) (srt (rest ls)) ) ) ) (print (srt '( 1 7 3 10 2 5 0 4 8 34 65 23 11 65 23 12 34 11 555 32)))
Here's a more idiomatic solution that operates very much like your solution but uses some of the deeper tools of Common Lisp--namely, CLOS and map-reduce. (defmethod flatten ((x list)) (reduce 'append (mapcar 'flatten x))) (defmethod flatten (x) (list x)) That said, go read Practical Common Lisp. It already answers a lot of the questions you'll have.
OH NOES u write non-conforming CL code on reddit u get in trouble
should be called nsort
When I see the keywords, I'd prefer uninterned symbols.
Looking forward to!
I'm working on a 3D graphics engine in lisp. I'm releasing it soon (as soon as I get my camera object working in a way I like). It's similar to Horde3D but uses Lisp's features to make like much easier. It can also do text and 2D graphics.
I dont see a way to contact him from his blog, but here are two more I have: * Dieter Müller - [LISP. Eine elementare Einführung in die Programmierung nichtnumerischer Aufgaben](http://www.amazon.de/elementare-Einf%C3%BChrung-Programmierung-nichtnumerischer-Aufgaben/dp/3411006285), 1985, German * Otto Mayer - [Programmieren in COMMON LISP](http://www.amazon.de/Programmieren-COMMON-LISP-Otto-Mayer/dp/3860257102), 1995, German There are also German editions of [ANSI Common Lisp](http://www.amazon.de/ANSI-Common-Lisp-Prentice-Titel/dp/3827295432), [Land Of Lisp](http://www.amazon.de/Land-Lisp-Lisp-Programmierung-programmieren-Professional/dp/3826691636) and [Winston-Horn](http://www.amazon.de/LISP-Patrick-Henry-Winston/dp/3925118616).
can we also NEVER AGAIN link to pinterest and just link directly to the websites? pinterest is like herpes, you never feel clean afterwards. pretty please? never again?
Does anyone have an opinion on the Chaitin books? I've heard some good and bad things about his books (more negative than positive).
I own a copy, and I love it! I'm still having trouble making it through some of the trickier forms. 
Absolutely! It will be a .1 release, but I'll definitely need help testing and fixing it. 
Well, my lisp isn't that good, so I'll definitely be able to help break your code lol
Could you give us some information about your setup? Which Arch/OS, Lisp version, etc... Looks like you tried compiling lispbuilder-sdl under MacOS. Also it would be intresting to know, if you have already SDL installed, and if so, which version. If you went ahead and checked out SDL ( I guess trunk is 1.3 oder a pre2.0 release) then chances are that this will fail with lispbuilder-sdl. The new SDL 2.0 API has changes a lot compared to &lt;1.2, which will lead to a rewrite of lispbuilder-sdl in the future. E.g. lispbuilder-sdl with SDL 1.2 under Debian /Ubuntu works flawless for me. Best regards
This *is* the example project =]. Unfortunately it can be a bit annoying to set up because of all the deps, but I've tested it on windows 7 and linux in CCL and SBCL (works on all 4 combinations), so if you installed GLFW/chipmunk (and put all the non-quicklispable deps into your `quicklisp/local-projects/` folder), you should be able to run it without too many problems. If you do `(ghostie::main)`, it will fire up the game in the "tree" level (my favorite) which is kind of a copy of Limbo's design (without the fancy lighting/shaders). So right now its kind of an engine with an integrated game. I plan to rip these into two separate pieces sometime soon. As far as a tutorial goes, I'd love to write up some of my findings, and will try to do so when I have the time. Most of the challenge is keeping physics objects (which live in the "game" thread) and render objects (in the render thread) in sync. The idea is that you create a game object, which contains tie-ins to the physics system (chipmunk) and mirror that game object on the render thread and set them to sync up via a thread-safe queue (done through jpl-queues). You can do this all without having separate game/render threads, but if your game gets CPU heavy, you can start missing out on keypresses and other events that are dealt with by the display/input system (GLFW) which runs in the render thread. Another problem is that you're calling out to C so much (for windowing, opengl, and physics) that you have to be very careful about cleaning up your memory and following the rules of the libraries you're using, otherwise you'll get the random segfault (hopefully with a helpful stacktrace!). I think I've gotten most of this stabilized now. I haven't touched sound effects or anything yet, but my hope/goal is to have an entirely evented system to build a game off of, with events like player jumped, player hit the ground, player landed on platform x, player was hit by flying hatchet, etc etc. These would all be events you could tie into and run scriptable actions off of (such as sound, player dies, platform moves, etc). I built this because I wanted to know if game development in CL was viable, and I think it's in a stable/fast enough place where I know that the answer to that question is "yes." Now it's just a matter of doing something useful with it. I want to MIT license the engine once it's in a separate piece, but until then if you want to run it/fork it/modify it, please be my guest!
Your parens are misbalanced, and thus the indentation is misleading: the `if` expression is not contained within the `let`, so `v` and `c` are not in scope.
*Please, please learn to indent your code properly!* Here are a few hints: There is a blank between a name and a following left paren: (lambda (x y) ...) ^ There are no random blanks in LET, and their definitions align to the left in separate lines: (let ((c (abs x)) (v (abs y))) In your example, there is an extra paren after the environment of LET, which is easy to spot when your code is indented properly: (let ((c (abs x)) (v (abs y)))) Finally, after fixing the code as amalloy suggested, your program should work fine. Edit: formatting Oh, I forgot: (mapcar (lambda(x y) (something ...)) should be (mapcar (lambda (x y) (something ...)) 
`(lambda (x y) (max (abs x) (abs y)))`
http://en.wikipedia.org/wiki/Steve_Russell
This is neat. I got into programming in the first place by trying to figure out Max/MSP and then Supercollider. I think it would be a fun idea to utilize musical things like this more with beginning programmers. Not sure how it'd work out though. I just remember being really interested in generative/stochastic compositions in college and wishing there was an easier way to play around with that kind of stuff. 
&gt; can be typed Only for a pretty weak notion of types, unless you want to go whole hog and build a Shen on top of an existing Lisp or something like Typed Racket. Even then, the requirement that one interact with non-typed code puts constraints, as I understand it, on the nature of the type system. Typed Racket's type system is quite different than that of Haskell for this very reason, and if you want really fancy features that are present in Haskell, I don't know of any Lisp anywhere that provides them except for Shen (which goes overboard, in my understanding). I don't know of any Lisp which embraces or can be made to embrace types as effectively as languages like Haskell. I love Lisp, and like Common Lisp, but Common Lisp has some serious problems with its type system (dynamic or staticness aside). `nil` is an absolutely terrible idea, and Scheme gets it much better. I mean consider that: (symbolp nil) ; -&gt; t (listp nil) ; -&gt; t (consp nil) ; -&gt; nil ; but despite this fact (car nil) ; -&gt; nil ; AND (cdr nil) ; -&gt; nil ; absolutely ridiculous when you consider that (car (cons nil (list 'a 'b 'c))) ; -&gt; is also nil, but sensibly. And `nil` is expected to be the "opposite" of `t`, that is, stand in for `false` values. If you are working in a problem domain where you need to distinguish easily between the idea that something is `absent`, `false`, or `the empty list`, `nil` is going to make your life hard. Common Lisp has one foot in the identity monad and one foot in the list monad and its fly is down. 
I finally pushed my code to github. It's not a real release, but it's something. [CLinch Graphics Engine](https://github.com/BradWBeer/CLinch/edit/master/design.org)
I think this is unfair, honestly. Common Lisp has a lot to learn from the strongly typed, pure or purish functional programming languages. Us Lispers often like to claim that Lisp is the most advanced language, but I think that our ~40 year period in the lead is over. In many respects the approaches Haskell takes to solving problems are cleaner, better designed and frequently more powerful than the mere "dynamic programming language with garbage collection + macros" that you see in Common Lisp, at which my above comments about the List monad hint. Even Lisp has moved on past Common Lisp in many respects, with implementations like Shen, Kernel and Racket really pushing boundaries while Common Lisp either languishes or "stays stable," depending on one's point of view. I think a comparison of Haskell and Common Lisp in particular does not strongly favor the latter - both are large, complex languages which occasional warts and library problems. But your average piece of Haskell code is significantly more elegant and readable (to me and others) than the kind of stuff you are forced to write in Common Lisp without significant retooling^1, at least when you are talking about the kind of exemplary code which advocates hold up as "elegant" in each language. Common Lisp still wins for me because its a Lisp and because I am, as a Lisper, a fundamentally selfish type of programmer, who lusts more after the power to easily implement my own features than to just have a nice set, but on many days in the Common Lisp trenches, Haskell looks pretty damn good to me. ~~ ~~ footnote 1: One can easily write Lisp code that is as concise _if_ one forgoes the multiple type checks that should be there. You cannot even take the `cdr` of a list in Common Lisp and be sure you are getting an actual list back - you've got to check, in principle, every time. Functions like `car`, `cdr`, `first`, `second`, and so on also follow the convention that their application to `nil` returns `nil`, which means you have all sorts of situations where you can't tell the difference between something like `(second (list 'a nil 'b))` and `(second nil)`, which basically makes these functions useless if you want to write robust code. Of course, 90% of the time you can get away with assuming that the `cdr` of a list is, in fact, another list, but its those other 10% of times that really bite you. Because of these limitations, you've got a real Sophie's choice when writing something like a pattern matcher: do you insert lots of type checks and sacrifice efficiency and generated code clarity, or do you not insert them and accept the fact that your nice looking code is going to either produce unexpected errors or just _behave incorrectly_? 
I know nothing about Haskell's type system (or Haskell for that matter, since trying to learn always confuses the hell out of me). Are there quick examples of things you could do in Haskell that you could not easily do in Common Lisp because of Haskell's type system?
I'm not sure if you're giving nil enough credit. Prior to working in lisp, I worked in C# professionally, writing 100% statically typed code. That was years ago, but even now I continue to be blown away by how easily the code I write in CL "just works" due to the dynamic, weak typing and generic style of functions. And probably the most common case where I am getting the benefit of that is with nil being seen interchangeably as null, the empty list, and false. In fact, just yesterday I wrote code that iterated over a list of strings, pairwise, and, happily, I didn't need to test for reaching the end of the list and making it a special case -- because: * the end of a list is nil * car/first/second/etc. of nil, is still nil, not an error * nil/empty being "false", and anything else being "true" makes for concise control code * (concatenate 'string nil) =&gt; ""; nil even works like the empty string sometimes! This code worked perfectly and saved me from a lot of type-ology ceremony. Coming from the static typing world, such notions used to really scare me. I suppose if you're writing code where quality is the only priority, you should do something more formal. Do have different null, boolean, and empty collection types. But for everyday code, prototyping, and times when you just don't need your compiler in your face all the time acting like a pedantic jerk trying to poke holes in your code, nil seems really great!
Yeah, I realize it is "convenient," but it is convenient^1 only because Common Lisp doesn't provide more modern facilities like ML-style pattern matching, which is simultaneously concise, explicit, extremely expressive and very type safe. The absence of such features in Common Lisp probably inspired all the insipid punning, but simply because a programmer is tired of writing type checks doesn't mean the language should conspire to run poorly typed code. This has nothing to do with the distinction between dynamic and static type systems. I want every piece of code I write to do exactly what it says and nothing more or less and I want it to be concise, explicit and elegant. Having a sloppy type system just gets in the way. Look, if you want to test if the car of a list is nil and you do so by saying `(car nil)` and then act as if the car of the list is nil, rather than as if you have an empty list, you have an _error in your code_, regardless of whether Common Lisp trundles on like a truck without a driver. I like to know when I have errors in my code. I think it is silly when a programming language tries to hide them from me. To call `car` on `nil` is an error, because `car` gets the `car` of a cons cell and `nil` is not a cons cell. I want to know if I try to call a function on the wrong type of thing, because this is a mistake. I do not want the system to hide this. It is not _extremely_ important if this error occurs at run or compile time, but the sooner you know about a error the better, preferably, you'd like to know before your client does. ~~ ~~ footnote 1: It is convenient only in the sense that not thinking about how drunk you are before you try to drive home is convenient. Yes, realizing your inebriation gets in the way of your most immediate goal, but larger goals are pertinent.
A desire for type safety is perhaps a manifestation of the [fail fast](http://en.wikipedia.org/wiki/Fail-fast) principle, and I certainly see the value in that. However, I personally feel that the [convention over configuration](http://en.wikipedia.org/wiki/Convention_over_configuration) principle is more valuable in this specific case, in terms of language design. I see car of nil returning nil not as some dangerous pitfall but merely as a sensible convention, one that works most of the time and can be overridden if necessary with a type check, e.g.: (car some-list) ; works fine most of the time (check-type some-list cons) ; when you require type safety (car some-list) If having bugs in your code is actually as consequential, tangibly, as crashing cars or trucks, by all means use a language with better type safety. I feel that bugs in typical applications, though, at worst will cause the user to frown momentarily. And the time spent avoiding each and every little bug must be traded off against delivering additional, or better features. Now if you're saying pattern matching can provide the same level of convenience and provide type safety for free, it sounds good to me, but I'm skeptical. Care to provide an example?
I'm the author of [Shadchen](https://github.com/VincentToups/shadchen), a pattern matching library. There is a good example (somewhat contrived) in [this blog post](http://dorophone.blogspot.com/2012/11/more-updates-to-shadchen.html). Using shadchen, if one wants to recursively traverse a list, one uses the pattern `(list hd (tail tl))` in the non-base case and `(list last-element)` in the base case. If it must be a list of numbers, one replaces the head patterns with `(! (number hd))` or `(! (number last))`. Shadchen's `cons` pattern, in order to conform to Common Lisp's bone-headed behavior, does indeed match against `nil`, but I did this because I thought it would be confusing to Lispers otherwise. There is also the pattern `cons*` that only matches actual cons cells, eg: (match nil ((cons* a b) :success) (anything-else :failure)) produces `:failure`, since nil isn't a cons. The idea with pattern matching is that one describes in a succinct form the expectation about types and other constraints on input data with their data destructuring and variable binding. After all, you should never destructure a piece of data without first checking its value (at run or compile time).
Is it CLinch or is it Qix? If you are changing the name, check README.md Maybe provide some road-map of what people should work on? For instance a TODO.org, or populate Issues on GitHub with some long term goals, or use the wiki...
Perhaps a step forward would be to use [quickdist](https://github.com/orivej/quickdist) to make a quicklisp dist that contains your freeimage and pango libraries along with the CLinch library rather than containing them within the CLinch library itself?
That's a good idea. I think I'll do it that way instead. Did you get the example to run?
Nice. It looks like shadchen is LGPL rather than LLGPL. Would you consider switching it? Also, how do you think it compares to [Optima](https://github.com/m2ym/optima)?
Allow me a bit to scan over the basic operation. I have never heard of you or CLinch/Qix. I don't usually feel comfortable running somebodies code off the Internet when I don't know the person or know somebody that knows you. DTO and Sykopomp follow you, so that vet's you a bit. That, and I'm supposed to be working right now...
I don't know as much about the GPL licenses as I should, can you explain the differences like I'm five? Well, obviously I am a bit partial to shadchen since I wrote it myself and it contains exactly the features I want, and because I maintain it simultaneously in Emacs and Common Lisp. But optima strikes me as a pretty slick library. Shadchen is not optimized in the way it expands pattern matches, and so if the author of optima has spent some time doing that, it might be a big win. For me, continued simultaneous support for Emacs and Common Lisp is a big deal. 
Well, good enough for me. I'll look into it and change it.
I was able to get the example running on Ubuntu 12.04 64bit with SBCL 1.1.0 after tweaking the example source a bit. You are actually missing a closing parenthesis on window-size-callback... It looks like you worked on this a few years ago and then didn't work on it for a couple years and seem to just now have imported to Git. Is that about right? I have been working on something like this but for the purpose of visualization, more or less a Lisp scene graph program. This looks better designed with regards to modern OpenGL instead of old school immediate mode that I learned long ago, so I think I will try to hack on this a bit instead. Let me rewrite test.lisp as it is a bit messy... Just so I know, are you Beer or just a collaborator?
&gt;prefer '() notation than (list) when possible; it is much less typing and &gt;all lispers will know what you are talking about. This is the very essence of nit-picking, but I never the less _strongly_ disagree. Quotation delays evaluation and as such, should only be used when that is really your intent. Most of the time when one is constructing a list, their intent is not to construct a piece of delayed code, the intent is to construct a list. It is much more explicit to say `list` in this case, and its a good idea for other reasons. For instance, suppose we have a list of numbers, which we might denote '(1 2 3 4) And then we decide that we want to put the value of a variable `v` in that list. We might accidentally write '(1 2 3 4 v) Which does not do what we intend, because the quotation is delaying evaluation. (Properly speaking, it doesn't really _delay_ evaluation so much as "merely read" the code, `lambda` delays evaluation in most lisps. Many quoted pieces of code, as in the above example, do not denote any meaningful (e)value.) More properly one should write, in my opinion: (list 1 2 3 4 v) When one means to construct a list. This is nice, easy, normal semantics. `list` is just a regular function whose arguments are evaluated in the ordinary way. It is soothing, peaceful, simple and clear. The misuse of `quote`, in fact, probably confuses novices - they hear that lisp is this mathematical, elegant language with minimal syntax and the first thing anyone does is hit them with this weird idea of quotation, which does not even _exist_ in other languages. Talk about obscuring, when 99% of most initial lisp example code uses a subset of the language which has exactly the same semantics as javascript or python. Use quotation to denote code and use the list function to denote lists. Note that more modern Lisps (Scheme) drive a deeper wedge between the meaning of `quote` and the meaning of `list` - quotation introduces _syntax_, which is _not_ necessarily a `list`.
Lisp can be used to make games, but it seems more popular for making game engines. 
I mostly think this whole fine-grained who-can-see-what thing is a huge (and mostly unrecognised) disaster - it's virtually impossible to make the right decision about visibility in languages like Java because there are so many options, and it is entangled with the class system an unpleasant way. I don't know what C++ does other than the best guidance I can think of for any language is "look closely at what C++ did, and then do *anything else*". That being said, what you probably want are [conduits](http://www.tfeb.org/lisp/hax.html#CONDUITS), which allow you do construct packages which "extend" other packages: (defpackage org.tfeb.bot.reddit ...) (defpackage :org.tfeb.bot.irc ...) (defpackage :org.tfeb.bot (:use) (:extends :org.tfeb.bot.reddit) (:extends/excluding :org.tfeb.bot.irc #:connector ...)) You can do a bunch of other things. Slight caveat: I might be about to change some of the guts of this stuff but not in a way which will affect the interfaces to it.
It seems like CL generally rejects the idea that there can be two different concepts "protected" and "public." Because you, the library creator, have to assume that anyone can jump in and use protected methods, you have to treat them as public (you can't go around changing their definition without breaking people, you have to design them well, etc). So therefore the only real reason to have protected is a kind of documentation on top of the symbols. That's generally what CLOS solves, though, by providing a nice interface to allow other code to extend symbols. I have found (in java) that any use case that seems to lend itself to using protected is eventually obliterated by clients just subclass my classes to get at it regardless of their intention to build an extension library. So as my career has progressed, I've really fallen out of love with the idea of it, since it never seems to go as I thought it might.
No, it's nothing special neither in ECL nor in C++. It's only a tight integration ECL/Qt, using the dynamic Qt features: QMetaObject, QMetaType, Q_INVOKABLE, creating everything on the heap. Return values like QFont are "garbage collected" using the ECL finalizer.
NewLISP seems to derive (perhaps not intentionally so) from very old Lisp dialects. So it has dynamic scoping by default and so on (there is a weird hack to get around this). Even by those standards its list structure is peculiar: it doesn't really have cons cells as best I can tell. Variables spring into existence when you first mention them making errors very hard to catch. All function arguments are optional making arity mismatches hard to catch. There are other weirdnesses.
I find it to be quite good, but since I don't have experience with the big players like CL I found it easier to ignore the hate and just get on with my work. [This article](http://www.taoeffect.com/blog/2010/01/how-newlisp-took-my-breath-and-syntax-away/) was a helpful read. 
Do you know how NewLISP compares to picolisp? picoliso also has dynamic scoping and and fexpr's so they seem to be very similar to me.
&gt; I mostly think this whole fine-grained who-can-see-what thing is a huge (and mostly unrecognised) disaster - it's virtually impossible to make the right decision about visibility in languages like Java because there are so many options, and it is entangled with the class system an unpleasant way. This is something I've been reflecting on while trying to solve this problem. Perhaps it's my design and not the language that's the problem... Conduits seems real interesting. I'll give it a look.
I am no language expert but by reading about newLisp I feel the same vague alarming hints that I feel by reading a piece of crackpot science: you don't know exactly what's wrong, but you have a feeling that likely it is. Now if only some knowledgeable Common Lisper could write a definitive NewLisp FIQ (frequently ignored questions) to which point people when this topic is periodically raised... 
It sounds like you're coming from much more Lisp-based expertise than me, so I can understand that you'd be frustrated with this issues. But as a hobbyist scripting coder coming from Python: 1. Don't need compilation. 2. Already used to dynamic scope. 3. See #1. 4. See #1. 5. I don't mind ORO, and "guessing" that NewLISP people couldn't figure out GC isn't helpful. 6. I may hit performance issues, but I'll cross that bridge when I get to it. If I was doing the full-on Lisp work you were doing, I would no doubt be as angry as you are. But for what I'm doing and how I'm doing it, NewLISP rocks. (Oh, and comparing everything to PHP is cause for eye-rolling.)
I just can't understand your logic of going apeshit because my tools differ from yours. Tell me why, okay. Give me the details, sure. But what am I supposed to do with this: &gt; It's as if the newLisp language attracts this kind of dumb and allows people to feel proud about it. Like PHP. And programming is many things. To you, it's engineering. To me it's happy scripting fun times. To others it's a shitty day job or a life-and-death situation. Me using one tool in a certain way doesn't disrespect all the other people and their tools/methods. Somewhere in the world is a guy using PHP and *loving it*. I don't feel worse off because of his use case. 
One option is to not care what anyone on reddit thinks about newLISP (or anything else). If you like it, use it.
I'd stick with SBCL and use [QuickLisp](http://www.quicklisp.org) for any external libraries you want to install and use (for things like HTML and such).
Your reply to my technical counter-arguments was basically "I don't care." If you don't care, why did you ask? And how should I feel about wasting my time (yet again) addressing a newLisper who doesn't care?
- PHP# - NewPHP - LisPHP - LHP Seriously, is "it's like PHP" your only weapon?
Wow, thanks for all this! Definitely finding resistance with NewLISP, I'll have a play with ClozureCL since I'm on OS X.
Thanks again! I usually do a re-read of my self posts a few hours after, but I'll check it again now. Have another upvote :D.
correct, that would belong into something like http://www.reddit.com/r/newLISP
Clojure if you want to be able to eventually use Lisp at work. Use whatever you like though, NewLISP or otherwise.
You could do us all a favor and lock the maintainers of weblocks in a room together and don't let them out until they release comprehensive documentation. I keep trying to use it because it looks so great, but every time, I get stuck with three different four-year-old examples open in the browser because I can't figure out how to do things.
Honestly, newLisp does not seem to be that bad. I think that major reason for the hate is that people really hate dynamic scoping (for good reasons). Check out: http://lambda-the-ultimate.org/node/257
@sickofthisshit: thanks to trolls like you, the whole lisp family is under bad impression how lisp community is full of crap. Instead to embrace _any_ new dialect, which will users ultimately led to CL, you are doing opposite. @shabavh: cool project and just continue work on it! At least you are getting job done instead of these loud mouths... Let me tell you a practical story: for one project hosted on one shared host, I had to create a site. The first version I did was in python (django with trac) and that was hell to maintain due often python updates by administrators. Because of lack of privileges to install anything and having already crowded host with a bunch of php/mysql processes, I ruled out PHP (didn't like it anyway) and perl (you can't do anything useful without cpan). I also had to rule out CL; you see, in that time quicklisp wasn't created and I didn't want to spend a week figuring out how to compile hunchentoot dependencies. Ahh yes, since you can't efficiently run CL code as cgi script, you have to use hunchentoot and slap apache to proxy requests above it. Did I mention privileges? The rescue I found in, guess, newLISP. A single binary without any dependency, packed with many cool stuff for which you would have to download a bunch of half maintained CL libraries. I even made that cgi script mulithreaded thanks to cilk API emulation, that can do multiple tasks in a single request. Time spent doing it: 4 days. Server usage minimal. Client happy and never had a single issue since then. Now, to summarize: when you need to get job done (and keep yourself satisfied), you don't care if GC is by the book or is some kind of hack to keep things faster; you also don't care if the code is compiled or interpreted, you just want to run it fast; and you also don't care are there fexpr's, hygienic macros or something else since you just want macros to write boilerplate for you. Use right tool for the job. My few cents...
This is /r/lisp not /r/common_lisp. Go create one for own desire and troll there. Stupid kids...
Lots of CLers here. If you're interested in Scheme/Racket, you might want to check out /r/Scheme and /r/Racket Personally I think with R7RS the Scheme world will be moving towards being more of a contender (though that's "work in progress" stuff), and if I was getting into LISP now I'd probably throw in with some Scheme dialect or another. The lexical scope and simplicity makes it much more beginner friendly anyway.
I took a look at newLISP after seeing your earlier post. I'll second xach's advice. It's different from Common Lisp, but it looks like it's got good documentation, comes with a lot of stuff just working out of the box, and is made for scripting. If you want a more heavyweight Lisp, I'd recommend Clojure. There are a number of books, the community is as good as there is for any language, and frankly there's a lot of mainstream interest in Clojure. Once you learn Clojure, it won't be difficult to pick up Common Lisp. That's the way I did it. As a Python programmer, you may also be interested in the [Clojure-py](https://github.com/halgari/clojure-py) project. It's an implementation of Clojure in Python so you can call any of your existing Python code. I'm not sure of the current status of the project, but Timothy Baldridge just started working at Relevance, so good chance it will get some attention. [ClojureScript](http://clojure.org/clojurescript) compiles to Javascript. r/lisp is a misleading name. As others have said, it's mostly for Common Lisp. Check out the [Google Group](http://groups.google.com/group/clojure) for Clojure.
I'm probably not the smartest person to answer this. I'm on something of a similar voyage of discovery myself. Here's what I believe based on my own recent survey. I'll further qualify this by saying that I haven't used any of these enough to have any expertise. Mainly, I post these for others to disabuse me of my crazy thoughts: Common Lisp: longest history of large production use, less focus on purity or strong opinion. Batteries (and installation thereof) situation used to be horrible, but has improved vastly with the advent of Quicklisp. Libraries may well exist for what you want to do, but they can often be old, incomplete, or abandoned. Quicklisp can be used as a bit of a filter function. Scheme: has roughly a million implementations, and may be the best teaching language ever conceived, in part because of its regularity. It has also historically been a "roll your own" affair, with relatively few libraries. Racket: is scheme plus batteries. Racket builds from scheme with the intent of being both useful for teaching / researching new language ideas, but also for use in production. Not fully scheme compatible, but appears to be where most new language research is happening (e.g. typed racket) in lisp land. Modern, but in a different way than Clojure. Clojure: epic batteries, in that they figured out how go back in time to get hundreds of CS curricula teaching students to get enterprise jobs writing libs for Clojure. If you're very familiar with java, Clojure will rock you. Unfortunately, Clojure's emphasis on purely functional programming gives me cognitive dissonance when every library I need to use is a mutable instance of a ThingDoer class upon which I call methods. But the batteries! Oh how nice it is to be able to do everything and know it'll work. Then there are other lisps such as Shen which are the love child of Haskell, scheme, and people way the hell smarter than me. This subreddit is mainly focussed on Common Lisp, so I suspect most answers will be oriented that way. If you figure out which of these is "best" please tell me. I've felt each was best several times over the course of the last year ;-)
CL is certainly the biggest at _something*!_ HAR HAR HAR HAR. But seriously, look into Clojure, its corpus of libraries and community are ever growing, leiningen is a pleasure to use, and for any need not covered by them there's also the many, somewhat unsightly, but serviceable in the end, Java libraries. nrepl within Emacs takes a stab at providing the SLIME experience too, but they still have a long way to go to be in the same league. The biggest drawback of Clojure are its ever atrocious stack traces. They can be quite daunting and it gets tricky at times to actually figure out what went wrong from them. Other than that, it's pretty smooth. In comparison to CL and Racket, it's the most "functional" of the three as in that all of its datastructures and variables are immutable, using [Software Transactional Memory](http://clojure.org/concurrent_programming) for its mutable state, and for convenience when developing concurrent applications. Its flow of control, on the other hand, is more plain, providing no snazzier error handling mechanism than say, Python or Java, and lacking TCO, both partly due to being hosted on the JVM. \* CL is a pretty big language
By Grabthar's hammer, by the suns of Warvan, you shall have a game!
SBCL on OSX is fine. ClozureCL is another fine option, but not mandatory.
Whenever I try to actually make something with the engine, I run into those annoying bits that are missing or still in development. But I'm feeling inspired to make something now :)
I have revisited this myself many times over the years. I think SBCL is the most complete but I don't use it anymore. It is a bit heavy and I find Scheme cleaner. I tried Racket which has a spiffy environment but is too far removed from typical Scheme. I humbly suggest looking at Chicken Scheme. It has wonderful features and a lot of libraries (eggs). I use it in EMACS with SLIME. Good luck :) 
TL;DR: give the NewLISP guys a break. Wherever NewLISP appears, there's invariably an eruption of hatred. I wonder why that is. My best guess would be that it due to its name. *New* LISP implies fancy new ideas, but when you look at it, most things you see is ideas that other Lisps abandoned 20 years ago. So you are disappointed. Then, trying to sell something as an advantage that most modern LISP programmers see as a grave mistake does not make things better. Maybe, if the NewLISP folks wouldn't imply that their ideas are *better*, then the Common Lisp guys would not hate them so much. Second, standards destroy creativity. Once there is a standard, everything that does not comply with the standard is suddenly considered to be "wrong". Before Common Lisp, there were lots of incompatible, little LISP systems, each with its sweet spots. Then Common Lisp came, and now all that is left is Common Lisp and Scheme, and everything else ranges from irrelevant to "wrong". The same happened to FORTH. Before ANS94, there were lots of very interesting, little implementations, now all there is is ANS FORTH. The Schemers worked hard to achieve this, too, with R6RS. But wait, isn't the RxRS a standard, too? Yes, but prior to R6RS it was weak one, that left lots of room for variation and extension. Wait until R7RS large is out. So, it's good to see that people are still working on incompatible, little, home-grown languages *and* get followers! Even if I don't like NewLISP and would never use it, I'm glad to see succeed. 
Don't forget Abuse! I used to play it for quite a few hours every time. http://en.wikipedia.org/wiki/Abuse_%28video_game%29 
Can we please block Clojure as well?
No opinion here but referring to a higher authority: [Common Lisp Implementations: A Survey by Daniel Weinreb (RIP)](http://common-lisp.net/~dlw/LispSurvey.html) An aside: this should be maintained, kept up to date and listed in the sidebar here.
I want to make it clear that I'm not jumping on the anti-Newlisp bandwagon. On the contrary, I think almost all criticisms of Newlisp are jejune, or are at least formulated in a jejune way. That said, I would call [Racket](http://racket-lang.org/) the cleanest, simplest and easiest Lisp derivative ever and on top of that it is extremely well designed, elegant, fun to program in, and the folks who work on it, whom I had the privilege of meeting at Racketcon last year, are also uniformly interesting, intelligent and friendly. (That last one is important, since I gave a ridiculously rushed and pretty awful talk about monads and they were pretty cool about it.) I've spent a lot of time contemplating Newlisp, and while I think many of its design decisions are idiosyncratic but well motivated, I think Racket forms a much more modern and clean example of Lisp nature. However, I always encourage interest in lisp variants, so you might want to check out [picoLisp](http://picolisp.com/5000/!wiki?home), which, like Newlisp, is a dynamically scoped Lisp dialect. I've always thought picolisp was pretty cute. And I can't help but mention my favorite dynamically scoped Lisp, [Emacs Lisp](http://en.wikipedia.org/wiki/Emacs_Lisp). And I'll plug [a series](http://dorophone.blogspot.com/2011/07/survey-of-syntactic-extension.html) [of articles](http://dorophone.blogspot.com/2011/08/survey-of-syntactic-extension.html) [I wrote](http://dorophone.blogspot.com/2011/08/survey-of-syntactic-extension_25.html) comparing syntactic extension in a variety of Lisp dialects. It is three parts, and meditates pretty consistently on the meaning of "code as data" and the relationship between that idea, lexical and dynamic scope, evaluation and functional programming. 
As someone who was perhaps one of those being rude about NewLISP, I'd just like to agree with this in public. If it works for you, then use it: what do you care what anyone else thinks?
I think there may be cross-purposes here. As far as I know Python is compiled, although this happens on the fly (note that for Lisp people "compilation" does not imply the nightmare C-style edit-build-crash cycle). I'm not aware of any dynamic scope in Python: indeed I think Python has (mostly?) modern lexical scope complete with closures.
&gt; Wherever NewLISP appears, there's invariably an eruption of hatred. I wonder why that is. My best guess would be that it due to its name. New LISP implies fancy new ideas, but when you look at it, most things you see is ideas that other Lisps abandoned 20 years ago. So you are disappointed. As probably the primary contributor of what might be termed "hatred" in this thread, it is not directed at newLisp per se. What I intensely dislike is the proud ignorance displayed by newLispers, and how it attaches to the Lisp name. If people wanted to have a "scripting environment for various web/internet type applications" it would have been much better for them to, say, standardize on CLISP or a relatively performant Scheme implementation and try to create some libraries that do the kind of "make things happen on the internet" that they wanted. That would have been just as productive, but would have been a foundation that could be built on. Instead, the newLisp people rolled their own freshman-CS-quality language with very weird choices and then dress it up in a misleading name and loudly proclaim it everywhere people try to discuss Lisp. Furthermore, there are at least a few people, for example Majorinc Kazimir, who are *really clueless* in the newLisp community, who *actively defend* things like FEXPRs and EVAL in CL forums, and are simply immune to technical reason. I mean like [completely laughable](https://groups.google.com/d/msg/comp.lang.lisp/OanlCqVIY38/am_ZQFWkkHoJ) implementations of [things like IF.](https://groups.google.com/d/msg/comp.lang.lisp/OanlCqVIY38/rxJhmKl3fIEJ) They invent weird things to get around the broken aspects of this one-implementation language, and think they are improving things. It would be actually kind of pathetic, if it weren't distracting honest newcomers to Lisp languages. Instead, there is already a lot of mythology (both positive and negative) about Lisp, and newLisp is just a major negative contribution to this. &gt; people are still working on incompatible, little, home-grown languages and get followers! Even if I don't like NewLISP and would never use it, I'm glad to see succeed. I'd *much* rather see people work at new frameworks and approaches and libraries using reasonable languages, instead of throwing away effort into these kind of tarpits. At least something like Clojure might be a bit strange, but not actively dumb.
You forgot to address the most important thing. Does newLISP work? Can you easily do the things you need to do? For the OP, the answer is yes.
Out of curiosity what do you think of [Factor](http://factorcode.org/), [Joy](http://en.wikipedia.org/wiki/Joy_(programming_language) or [Picolisp](http://picolisp.com/5000/!wiki?home)? I favor pure, functional programming as a rule, and as such prefer Scheme flavored dialects of Lisp. However, if one spends time with concatenative languages it becomes clear that in the realm of functional programming there are multiple ways to skin a cat, no pun intended. Newlisp rarely defends itself elegantly, but picolisp's philosophical underpinnings and insight from concatenative languages with first class quotations, to which New and picolisp are quite close, reveal that one can program quite elegantly these kinds of languages. I don't know if I would recommend Newlisp to programmers for new projects or real work, but I would definitely recommend that they really understand how one solves problems in such a language, at the very least to drive home the _meaning_ of things like `lambda`, `eval`, closures and `quote`ations. Even classic Lisp texts, like Lisp in Small Pieces, dwell at least for a short time on dynamically scoped Lisps. No one benefits from orthodoxy. 
I don't know much of anything about Factor (apart from: "it's like Forth, maybe?"), Joy, or Picolisp. I actually know just about nothing about Clojure except "it works with Java" and "they like immutability, right?" To be honest, if I wanted to explore other languages, I'd start with Haskell or OCaml because those seem to be done by serious people, and clearly have a different take on things. I don't particularly like Scheme, and haven't tried it much apart from reading SICP, but have to respect it being around a while, and, again, being done by serious people. I feel Lisp as a whole has little to do with functional programming or even programming language research. From my point of view, it is about metaprogramming-done-pretty-much-right as well as a lot of flexibility, while not giving up entirely on performance. Dynamic scope is not per se a turnoff for me, I just believe that you need to use it sparingly (and remember your \*earmuffs\* people!) when it is genuinely useful, not because you were copying Emacs Lisp or just got it wrong. It means a lot to me that the people who built Common Lisp, who again were serious people, all agreed it was a bad default. As you may have detected, I'm saying a lot about the people involved being "serious," whatever that means. There's also an element about whether people are pragmatic, in the sense that they deliver substantial software and don't get hung up on cleanliness or needing to perfect Lisp (make FIRST a generic function! I need a Lisp-based OS!) before coding something interesting. I'm also concerned with the dilletantism and quasi-mysticism that surrounds Lisp. Like when XKCD mentions parens or God, or Eric Raymond talks about it, or Gavino or someone like him asks yet again about $BUZZWORD in Lisp. Lisp prospers when serious people understand what it really offers, what it can or could do, and they apply themselves to doing something to help out. It doesn't prosper just because some people react to Lisp as a buzzword and want some of the buzz. 
Lip SYNC?
This was good because I learned about LispNYC.
Scheme, Clojure, and Kernel all qualify as lisp dialects. NewLISP is BASIC in parentheses. It really isn't just about the parentheses.
Cookie? No thanks. ~~I'll take a link to a github/bitbucket/patchtag/etc. repo, though. I would love to work on this.~~ Forked!
I love it. I started learning Lisp to basically solve the same problem for my self. I'm in, I'll help where I can.
This is exactly the sort of jejune criticism of Newlisp which I mentioned elsewhere in the thread. Newlisp has [automatic memory management](http://www.newlisp.org/MemoryManagement.html) of a kind, first class functions and, arguably, a more consistent definition of first class code than the lexically scoped lisps. These are powerful features, if a bit cack-handedly implemented with respect to modern idioms, and they definitely qualify the language as a Lisp. Unlike Basic, you can metaprogram and functional program like crazy in Newlisp. Newlisp is very close to an applicative version of a language like [factor](http://factorcode.org/) or [joy](http://en.wikipedia.org/wiki/Joy_\(programming_language\)), the former of which is a "real" programming language with enough power to, for instance, implement efficient lexical scope in its own idiom and the latter of which is an academic language which has some very nice mathematical properties which help illuminate [fundamental ideas in computation](http://www.kevinalbrecht.com/code/joy-mirror/joy.html), another thing which Lisp is supposed to do. What I gather is that you heard Newlisp doesn't have a traditional garbage collector and that it doesn't usually employ lexical scope, and since they are the most commonly discussed concepts in Lisp, besides meta-programming, you believe this disqualifies it as a lisp dialect. Well, dude, that is silly. 
You could try starting a discussion about the actual technical merits of the language - what do you really lose by using dynamic scope by default? What about one reference only garbage collection? Lispers tend to assume that the solutions in Common Lisp are somehow "optimal" but even if that is true, it doesn't mean other approaches offer no benefits. It has never bugged you that `lambda` expressions produce atomic `function` values, that cannot be introspected in a meaningful way? We brag about functions being first class values in modern Lisps, but they are first class values with no interface and no introspection - all you can do with them is `apply` or `call` them. In picoLisp and Newlisp one can arbitrarily transform functions, which are just lists, which, if you do so functionally, opens up a large range of interesting idioms which are entirely consistent with functional programming. You can even simulate lexical scopes in this way. If CL's choice of lexical scope is better, surely we should understand why that is by understanding the power of alternative approaches. Novices who come to Lisp via Newlisp may not be able to articulate these issues (how could they?) but a discussion of them would be as useful for novices as hoary old Lispers alike. 
I have a passing familiarity with Factor and by extension Joy. I don't see what NewLisp has in common with either of them *at all*, certainly in comparison with any other lisp dialect. Kernel is a fairly recent lisp dialect (probably still without a mature implementation) that does f-expressions right. It introduces a meta-programming equivalent to the lambda calculus. It's all very fascinating but it's still not clear if it's even possible to make them efficient. There are innumerable Scheme implementations, many of them with their own unique sets of features, many of them well engineered, and many well documented (Racket, Chicken, Gamibt, Chibi). I can't think of anything that NewLisp does better than *any* of them. If you want to play with f-expressions, I recall a toy implementation of Kernel in Javascript (if nothing else that means it's garbage collected, and on v8 I wouldn't be surprised if it's faster than NewLisp). 
It doesn't have garbage collection, but it does have automatic memory management. You should realize also that garbage collection is not universally accepted as a good language feature in any event. Many developers will not give up C or C++ to move to D or Go because of garbage collection. Garbage collection is optional in Rust. 
I'm familiar with all of those languages and the only time garbage collection is not considered a good language feature is when a program cannot afford the performance hit, or the program needs to do it's own low level memory management (eg. the program is a garbage collector). Unless you're suggesting that NewLisp's lack of garbage collection makes it suitable for writing operating systems or AAA game engines, I don't think this is a valid defense.
I use SBCL with vim through slimv.vim. It has a few minor bugs, but 90% of the awesomeness of SLIME.
Looks interesting; I'll check it out. I mostly use Racket these days, though.
I think you are confusing (or I was not clear enough in distinguishing) two different issues about "dynamic" language features. Dynamic scoping of variables is not about performance but semantics. Historically (e.g. Maclisp) interpreters were implemented with dynamic scope but compilers with lexical scope, so the interpreter would disagree with compiled code in sometimes subtle ways. Also known as crazy bugs. The real problem with dynamic scope of variables by default is that it means every variable binding in your code is a quasi-global binding potentially affecting any code invoked by any function call you make. It makes closures problematic. Sometimes it is handy to have quasi-global variables, but only when there are things you want to temporarily affect in all code that runs: e.g., re-binding I/O streams. Note the Picolisp FAQ dismisses this with "well other Lisps have macro variable capture" (which is well-known, rare, and easily avoidable) and instead introduces another "transient symbol" concept and says you've got to be careful and use complicated rules to avoid bugs. And, frankly, I don't think they've understood the problem. The other kind of dynamic behavior that *does* drastically affect performance is how you are allowed to redefine functions: in your words "first class code." If your functions are literal containers of source code which can be introspected and modified, if your "macros" depend on passing literal code to EVAL, you are forced to use a naive interpreter, i.e., your language *must be* slow. Being able to invoke a compiler means you now have more opaque blobs that run fast, even in closures and other functional programming tasks. Picolisp brags that it is "usually" faster than (presumably pure interpreted) Python. Forgive me for not being impressed, as even Python fanatics say you should rewrite performance-critical stuff in C. And frankly, I don't believe them because they also claim to beat compiled CMUCL in list manipulations. Maybe they are counting the CMUCL compilation time? The FAQ author also seems confused about the memory model of typical Lisps and about floating point computation. To elaborate a bit on what I meant by the "reflection" issue: if the user can "flexibly" redefine functions like CAR then you are even more stuck, because presumably your interpreter and compiler make ample use of CAR and similar functions: every invocation of CAR has to indirect to find the current definition. And what if CAR is itself used to access the environment containing the definitions? Interpreting your interpreter in this way is somewhat doable but super-duper-slow and basically not more useful than real compilers. &gt; Newlisp as 100x the Lisp nature of Python, The "Lisp nature" does not mean "naive and dumb." It does not mean "my toy is wonderful because it uses parenthesized notation." Just because you can write a naive interpreter in very little code doesn't mean Lisp is amateur hour. Really, people talk about the wonderful "flexibility" of these toy dialects, but show no evidence they understand the flexibility of mature Lisp implementations, and usually demonstrate no particular *benefit* other than the flexibility to do really dumb things with ease. Bash scripts are wonderfully flexible. They also are painfully bad software.
People write software, huge software, every day in _Ruby_, so pardon me if I can't understand your weird obsession with performance, a particularly strange thing to worry about if you are programming in Lisp, which is, after all, not exactly C or Standard ML performance, at least not without a lot of work. &gt; It does not mean "my toy is wonderful because it uses parenthesized notation." Absolutely no one is holding up this straw man except for you. Purveyors of New and Picolisp do not say, nor do they imply, that the important thing about their design choices is parentheses. On the contrary, they consistently point out certain kinds of meta-programming that one can do in their language which cannot be done in middle group lisps like CL. It is 100% fine to believe that these features are not sufficient to outweigh the benefits conferred by compilation or lexical scope, but that is, you must admit, a matter of taste, rather than of some universal fact about computation. I'm not trying to defend the particular design choices of these Lisps, as my preferences are for static, pure, lexically scoped lisps with hygienic macros. But I am defending the value of including them in our rhetoric and discussion. In [another thread](http://www.reddit.com/r/lisp/comments/14v0t1/i_want_to_migrate_to_lisp_from_python_can_i_get_a/c7icp3r) a user suggests that Newlisp is just like BASIC, a hilariously naive statement (talk about dilettantism). Understanding these Lisps and even acknowledging where they allow certain kinds of flexibility can only enhance our knowledge of the design of more typical Lisps. I guarantee that a person who spends an afternoon working out how to program idiomatically in these Lisps will come back to Common Lisp with a better understanding of Common Lisp's semantics. What I see, however, is that when these Lisps come up, a bunch of people who only have experience with one way of Lisping and sometimes barely that, jump to criticize something they haven't really put the effort into understanding. I don't think this serves anyway. Look at my comments - you'll notice the first thing I suggest to the OP is that he try Racket, since I think that especially for exploratory programming, it is the best and most modern Lisp. What you won't see is my heaping scorn on Newlisp, because I think it will only serve the poster to learn both and really get the difference. 
Hey everyone, just finished this up. I haven't tested every piece of it yet, but from the first glance this is functioning 100% the same as Drakma, except it's non-blocking. As noted in the readme, please use the latest/git versions of [cl-libevent2](https://github.com/orthecreedence/cl-libevent2) and [cl-async](https://github.com/orthecreedence/cl-async). This works by creating a stream that wraps a non-blocking socket, and sending it into a version of drakma's `http-request` that has been converted to be async. It writes to this socket like it normally would, but instead of waiting on the socket to return and then parsing it, it returns a function to be called once the entire response is downloaded (this is tracked by the [http-stream](https://github.com/orthecreedence/drakma-async/blob/master/http-stream.lisp) implementation). Once the response is finished, the callback is called and the response is parsed, as usual, via drakma's normal facilities. The nice thing is that the conversion of `http-request` to be async is automated via a macro, and it also uses large parts of the original drakma library, so there wasn't a huge rewrite to support this. This also means that using the latest version of drakma is as easy as copying/pasting the `http-request` function into the conversion macro in [hijack.lisp](https://github.com/orthecreedence/drakma-async/blob/master/hijack.lisp). The bad thing is that the entire response must be held in memory for this to function properly. I've made a [note of this in the issues](https://github.com/orthecreedence/drakma-async/issues/5) and have a fix planned eventually. For now, you can make thousands of HTTP requests simultaneously via drakma-async using the same API as drakma =]. The tests are pretty sparse right now and really only look at core functionality...I want to expand these over the next few weeks as I have time. Please let me know if you have any problems/questions/advice/critique.
On garbage collection, I can't say - the question is whether one thinks about memory management in Newlisp. If the ORO collector makes thinking about memory unnecessary and performance is sufficient, I don't see what the problem is with it. From a perusal of the document, it does not seem like one is manually managing memory? This document does point out one major beef I have with Newlisp, which is that you pass a lot of things by reference, which I hate. 
In order to use local variables newLISP does require you to manually pass around so-called context objects, so I'm not sure that the burden is completely removed from the programmer. What disturbs me most about the text is that it starts with a hand wavy discussion of garbage collection that ends with a paper from 1996, and then goes on to claim that this so-called one-reference-only scheme is actually faster and more predictable than garbage collection. (In the only performance benchmarks that I've seen newLISP is in fact slower than emacs lisp.) This one-reference-only scheme certainly is easier to implement than a garbage collector, and I suspect that is the primary reason that it was chosen.
First, I just reset my Qix githup directory so I can start clean. Yes, I need to update my blog. I've been working through family issues for the past couple years so that's why. Most work is being done in [CLinch](https://github.com/bradwbeer/clinch) which will serve as the graphics engine for Qix. That's where most of my Qix code went since it makes much more sense to factor out the graphics code. I really like your idea to make it a standard. Internally I am thinking you can have some data like a string (or list of) for a file. When someone changes the **data** slot or by watching the cons cells for changes, events can be created. I would like all changes to happen through and add-item/remove-item/move-item using a cursor system so multiple people can edit concurrently. This would also allow for changes across process boundaries (sandboxes and computers). It would also require UUID's for identification. This, or course, is just a sketch of one possible format. A finial note, I've looked at my code comparing it to EGL and it might work. I don't have any EGL devices, but if it doesn't require me to redesign I don't mind attempting it. EDIT: I would **really** like to talk to the makers of the CELLS library about this. Also the Elephant Persistence Library.
I've got something a bit friendlier for getting started over here: http://dylanfoundry.org/2012/12/20/getting-started-with-opendylan-20121/ 
I keep wanting to try this but then I'm reminded by that warning that the Win32 version doesn't work on 64 bit Windows and there is no Win64 build.
Are there binaries or an installer or anything?
There are binaries for openssl for windows, but not libevent as far as I know, and I had trouble getting openssl support in libevent without compiling openssl first. I could always send you my dll files (everything is 32bit), but I realize that's a bit jenky/shady.
For me, some of the high points are: multiple dispatch, conditions, efficient compilation to binaries, macros. But a really important point is the overall simplicity and how well the features fit together in a fairly clear and consistent way without a lot of drama. Threading is native threads. Networking exists, but is currently IPv4 only. DUIM is designed to be cross-platform GUI, but is currently only implemented for Win32. Some of it had been implemented for GTK+ in the past. The language is OO (but generic functions rather than classes-have-methods OO). It can be used in a functional manner, but not (yet?) to the same as Haskell as the type system isn't so static. There's been research into extending the type system with some parametric polymorphism, but it hasn't hit the mainline yet (presented at ILC'10). 
What the above posts said. Basically get Quicklisp installed (I have no idea how to run Lisp on Windows, it looks like it is possible). After that its just do some googling, picks some libraries, projects, etc and just tinker. Quicklisp really makes it just that easy. 
Let me recommend that you reproduce something like this dinky [Random Demon Name Generator](http://dorophone.blogspot.com/2012/02/almost-pure-random-demon-name-generator.html) I wrote in the Lisp of your choice, but I recommend Racket. 
Racket is easy to set up on all systems and easier to work with than Common Lisp for a beginner, and has enough batteries included to start working on simple games. Common Lisp is great, but Racket is a lot better for a beginner. 
I haven't tried it but I think the approach is the right one. Trying to shoehorn Lisp into JS doesn't really work. I've found that the languages that work for me are those that take either extreme: A) map everything into the underlying language as close as possible B) don't even implement interop and create everything from scratch, tailored to the new language. My gut reaction is that it's probably better to bootstrap it from JS/itself than to implement it in Common Lisp. I love CL but requiring a CL installation (not to mention libraries, should you need them) for a language that will target JS just seems wrong. &gt; This dialect allows you to use symbols with dots in them to represent element access Good work on that. For some related work, you may want to take a look at the jscheme [dot notation](http://jscheme.sourceforge.net/jscheme/doc/javadot.html), It's not really that related, Java has a ton of additional stuff, but it's interesting to see what they've chose. &gt; It is written in Emacs Lisp Further work idea: since you already have it running... add an Emacs mode for it? :-)
&gt; Further work idea: since you already have it running... add an Emacs mode for it? :-) Well, it shares a reader with Emacs Lisp, so I've just been using Emacs Lisp Mode temporarily. 
Still early days, so please let me know of any problems you encounter. Or even better, submit a patch! 
What does that even mean? I know Lisp is sort of a metalanguage that lets you create the best DSL for a given problem without even realizing ... but "creating a lisp dialect for X"? (where X is another programming language!) Can you create a Lisp dialect for C++? for Python? for whatever? and what would that mean for a programmer in that language? Is there any article or anything on this topic that I can read? I'm intrigued!
Author here, let me explain briefly. When I say Gazelle is a Lisp dialect for Javascript it means that I attempted to create a Lisp dialect which was a good fit for the semantics of Javascript, and which compiles or transcodes to Javascript. That is, I wanted a language which had all the benefits of Javascript (runs in everyone's browser, has a good code ecosystem) and all the benefits of Lisp (s-expressions, macros, extensibility). So I wrote a dialect whose entire purpose was to be converted to Javascript, whose idioms are Javascript's idioms, etc. You could do this for any other language, but it gets tricky for a language like C++, where you don't have a garbage collector and you have to deal with types. [adder](http://www.thibault.org/adder/doc/index.html) is an example for Python 3, and Clojure is the famous example for Java. 
is clojure really close to java's semantics? it seems different in a lot of ways, and mostly supporting java interop by transforming method calls into functions of their receivers.
yeah...project euler is a great starting point. Solving problems with the functional approach is a sure first while studying Lisp. And when you are comfortable enough go on to do something practical like translating one of your existing projects into Lisp.
I'm curious how you feel about Clojurescript.
Well, it wasn't a good match for what I wanted. I _absolutely love_ certain aspects of Clojure, particularly the persistent collections. However, I really just wanted to code in Javascript with s-expressions. The other issue was that I work with a lot of Parenscript code, and I wanted to develop something which might eventually replace that use case. My workflow depends on generating that code in Common Lisp, and since shadchen, the pattern matching library that does most of the work in Gazelle, is in Emacs and Common Lisp, I can port Gazelle over to Common Lisp quickly, if that becomes an option. Finally, I just like Emacs enough that I don't want to complicate my life with an additional set of requirements just to write my Javascript code in s-expressions. Emacs Lisp did what I needed it to do and its integrated into my editor/project management system already. 
According to CLiki there is [trivial-raw-io](http://cliki.net/trivial-raw-io), but it's not [maintained](https://github.com/redline6561/trivial-raw-io/blob/master/TODO) either. May be you could use [curses](http://cliki.net/CL-Ncurses) for your purpose, I've got tested that wrapper.
There's a project called [iolib.termios](https://github.com/marsijanin/iolib.termios), designed as an extension to iolib. It sounds like it might address your use case, but I have absolutely no idea how well it works -- (un?)fortunately, everything I'd like to interface with these days hides the actual serial I/O behind USB or Bluetooth. But if you can give iolib.termios a try, please report back. It would be nice to know whether it works; I'm sure there are other Lisp users in need of the occasional serial I/O support.
Yeah, you need termios wrapper. Although I like UNIX attitude to modularity and I'd use *setserial* and redirection, I take your out-of-the-box want.
Pretentious title? Check!
I can't tell if this is pedagogy or a simple mistake: (defun curry (f a) `(lambda (b) (funcall ,f ,a))) (funcall (curry #'+ 1) 1) You may be trying to show that (funcall '(lambda (x) (+ x 1)) 1) is fine in Emacs lisp but not in, say, Common Lisp. But on the other hand, `(funcall (curry #'+ 1) 1)` doesn't work with the non-macro `curry` in your example. It seems to me that you are conflating dynamic variables with other features. Dynamic variables aren't strictly necessary in a language like Common Lisp that has macros, lexical variables, and closures. I think of Common Lisp as a lexically-scoped language with occasional use of dynamic variables on top for succinctness and convenience. We can take any Common Lisp program and remove the dynamic variables entirely: just add parameters to all functions which depend on dynamic data, passing the data explicitly through arguments rather than implicitly through a dynamic binding. &gt; I suspect if you examine any large Lisp project you will find that for the most part the actual use of the semantics of lexical scope is small. Did you mean the opposite? A large CL project might have a handful of dynamic variables and, relatively speaking, a near infinitude of lexical variables.
Did not mean the opposite - what I mean is that most uses of bindings are not for purposes that require the lexical scoping rules. Eg (defun add-n-to-list (n lst) (mapcar (lambda (i) (+ i n)) lst)) In this example, it doesn't matter than `n` has a lexical binding. I base this claim on the admittedly shaky ground of personal experience. I port a lot of code back and forth between Emacs and Common Lisp, and usually I have to change 1-2 binding sites because of issues related to scope, per say, 500 lines of code. That means most code isn't depending on the lexical nature of the binding. It might be that I am subconsciously coding around the issue when I work in Common and Emacs Lisp and so avoid lexical binding situations. Certainly if I were porting Scheme code, where my style tends to be far more functional, I'd expect to have more problems. So you are right in a way. And you are right about `curry`, it should be this (oops, Lisp 1 vs Lisp 2 strikes again), but the point remains: (defun crappy-curry (f a) `(lambda (b) (funcall #',f ,a b))) (funcall (crappy-curry #'+ 1) 1) Thanks for pointing out the error, though. 
I wouldn't even argue that they are superficially similar. Just that most uses of variable bindings don't require that the binding be lexical to do what people expect. The problem is those subtle cases where they do.
I agree, people more often need just local variables instead of local [static](http://en.wikipedia.org/wiki/Static_variable) ones. I'm using C jargon.
OK but my original point remains about conflating dynamic bindings with the continuum of static/dynamic languages. We could remove all dynamic bindings in Common Lisp and pass everything explicitly. We could add dynamic bindings to Scheme. We could take a Haskell program and put everything inside a top-level monad. None of this affects the essential nature of the static/dynamic continuum, which is more like [no metaprogramming] &lt;-&gt; [compile-time metaprogramming] &lt;-&gt; [run-time metaprogramming].
Of course, the languages are sufficiently flexible that identifying a particular strategy with a particular language is a bit fatuous. However, the languages definitely have an intent in mind in their design, and hence I felt they were at least exemplary. 
I've always thought fexprs are The Best Way and CL macros are The Practical Way for Performance, with Scheme macros occupying a funny niche alongside CL macros. I see the hygiene issue as essentially a non-problem in CL, and the tremendous effort that Scheme goes through to address it (&lt;cough&gt;dye packs&lt;/cough&gt;) seems ludicrous in comparison to the problem it solves. It's almost a parody of academia, as if someone wanted to drive home the point, using satire, that academia tries to solve problems that programmers don't have. The difference between Scheme macros and CL macros is almost nothing compared to the difference between CL macros and fexprs or Scheme and fexprs. For The Practical Way I prefer the simplicity of CL and the nice slime inspection for macro expansions. The lingering question is whether we'll see an fexpr-based language that can achieve the same kind of performance as CL. It might be possible, but if so will probably take a tremendous effort at least on the order of what went into HotSpot.
I don't think you're giving Hygienic macros a fair shake - I find them easy to work with and feel great knowing I don't have to worry about hygiene. They seem "right" to me, whereas "gensym"ing my way to freedom always makes me a bit uncomfortable. 
This is a bit like wanting to see the assembly language. If I don't understand a piece of code, macro or otherwise, I don't usually spend time fiddling with debuggers or inspecting the running state. I just rewrite it until it is so simple its impossible not to understand. I trust my run-time to do what it says and work at the level of abstraction provided, mostly. 
ive got this and not got around to reading it. :/ Let me know if its any good... i had a bad feeling from scanning through it
Happens to the best of us. I have 3 or 4 books like that. In my defence, they *are mostly* PHP or Java books.
It's the opposite of wanting to see assembly language. I want to see the code that I've written. That I happened to write code which writes code is beside the point. A full LOOP expansion could be compared to assembly language, but that's not my code. I only expand the parts for which I am responsible, *my* code. Writing a macro is an iterative process; at least it should be. I write a macro, look at the expansion, and say, "Is this the code I want?" Very often I catch bugs or think of ways to improve the generated code -- thoughts which don't come to mind by staring, no matter how intensely, at the macro definition.
&gt; I don't usually spend time fiddling with debuggers or inspecting the running state This indicates that you misunderstand? I'm not talking about debuggers or inspecting the running state. I'm talking about looking at macro expansions, as you're writing code, before even compile time. Have you ever used C-c-RET in slime?
Looking at the macro expansion is a similar thing. It is fiddling with the result rather than understanding the code that produced it.
According to this argument, there is never a need to test anything! Just write the code and it should work. Otherwise you're just fiddling with the result rather than understanding the code. Clearly I've failed to get the point across. This is about another level of testing. The analogy is write functions : test functions by running them :: write macros : test macros by expanding them I am willing to bet that if you could see your expansions then ideas would pop into your head about how to improve or correct them. This very often happens to me.
If you have a macro that expands to pages and pages of code, and the macro is not composed of smaller, comprehensible macros then you're doing it wrong. I don't need to explain why huge functions are bad. The same applies to macros. If you're saying the expansions are huge because they are given large amounts of data, then obviously one could test them with a small amount of data. Test the pieces individually, then compose them. That's what programming is about.
I just bought this book at powells for like $10. What a steal. I'm excited 
Can you just spawn stty?
You keep going back to this false dichotomy between understanding your code and testing your code. You are pretending that you understand your code and so you don't need to test. I have found this kind of false bravado is inversely proportional to competence. It's simply wrong to not test. Wrong, wrong, wrong. When you have a bug, you don't know that you don't understand it. You test to find what you didn't understand. If you understood it then you wouldn't have a bug. Programmers like to pretend they always understand. It's a universal character flaw. But we all know it's a lie -- sometimes we don't understand, and we get a bug. And some bugs are totally out of our hands: quirky interactions with components we didn't write, OS-specific subtleties, and the like. You won't know until you test. *Always* test.
Testing is excellent, of course. Sorry if I made it seem as though I think poorly of it. I don't. But I do think we can emphasize writing simple, understandable, and correct code too. That is all I meant.
But why are your trying to pit "writing simple, understandable, and correct code" against testing? You were trying to make an argument against testing by casting it in opposition to "simple, understandable, and correct code". Your responses are kind of like, "But we should not rob banks, too!" Just non sequitur. So you are for testing, but not when it comes to macros. You never make a mistake with macros. You don't check your work with macros. You always understand everything about your macro code. Right?
My point was that I don't usually find it useful to stare at macroexpansions, and I don't mind using hygienic macros even if they prevent me from doing so. _Test the functionality_, by all means, but I don't think its a point against a macro system if the expanded code isn't very readable or is otherwise opaque to the user. When a macro fails to work the way I expect, rewrite the macro until I understand why. The failures are often caught be test cases. 
Thank you. I have SICP; I found the first part very interesting, computing primes etc. I didn't find the second part so engaging. I also have Lisp in Small Pieces, didn't realise it was a deconstruction of Lisp (which I wasn't interested in at the time) so didn't read it. Perhaps it's time for me to go back to it. Thanks for the nudge.
&gt; And Common Lisp seems to have the same fragmentation I haven't been using Common lisp that long but a lot of the useful functionality that isn't specified in the ANSI standard seems to be implemented in libraries that play nicely with all the main implementations. I'm writing a game at the moment using SBCL on linux and Clozure on windows and can run the same code without problem. 'Fragmentation' is a bigger problem in scheme as the standard doesn't seem to specify enough to encourage portable libraries to be built. At least that was the impression I got a few years ago. I understand that R6RS and newer aim to change that. 
I really like Dan Friedman's Essentials of Programming Languages
[*Object-oriented Programming in Common Lisp*](http://books.google.com/books/about/?id=waVQAAAAMAAJ) by Sonya E. Keene is the best book on CLOS that I've come across. 
I'm not sure, and not at home to check, but I believe it was second edition.
Oh, you might want to check Krishnamurthi's Programming Languages Application and Interpretation. I've seen part of the new shining version (finished last month) and it looked great. www.cs.brown.edu/courses/cs173/2012/book/
Maybe you'd find [Programming Languages: Application and Interpretation](http://www.cs.brown.edu/~sk/Publications/Books/ProgLangs/2007-04-26/) interesting. It uses [Racket](http://racket-lang.org) which is "a language laboratory" that grew out of Scheme. The new edition of the book is not finished yet, but they use a typed version of racket extensively and it was basically written during the latest delivery of Brown University's course [CS173 - Introduction to Programming Languages](http://cs.brown.edu/courses/cs173/2012/) Edit: Shame on me - I didn't see [alexandream's post](http://www.reddit.com/r/lisp/comments/15l22u/book_recommendation/c7nkpow) before I posted. Vote him up.
My favorite thing to do when learning a new language is to write a program that will solve [Mastermind](http://en.wikipedia.org/wiki/Mastermind_%28board_game%29). After writing something that will work on the command line, write a little wrapper in Tk. You should be able to specify how long the combination is, as well as how many possibilities each space can be. So far I've done it in C, Perl, Common Lisp, and Python. C was by far the most annoying.
You might even be the first person to find out how STM performs in an object system! Ain't that fun.
Weird conversation. You keep bringing up other stuff instead of actually addressing the point. First it was "Well I prefer understanding my code instead," as if understanding code is mutually exclusive with testing it. Now it is "Well I prefer re-writing my code," as if this is an appropriate substitute for a seconds-long expansion check, and in any case your professed penchant for re-writing is totally unrelated. You can have simple macro checks *and* re-write however much you want. They aren't mutually exclusive. If you have a bug then you should understand what you did wrong. That is done by taking a second to check the expansion (not a full expansion). Re-writing because of a bug is almost irresponsible. It's a missed opportunity to learn how and why you made a mistake. By all means re-write, but understand first. Only occasionally, like when you are purposefully writing bad code and don't care about its implications, would re-writing be an appropriate reaction to a bug. But in general if you expected your code to work, and it didn't, then you should learn something from the experience. 
I think I may be intentionally overstating myself for rhetorical purposes. Obviously when I develop software I spend a lot of time doing all the things you describe. All I _meant_ to say is that I don't find it particularly constraining not to see my macro expansions, and that I don't look at them very often, and that this has not prevented me from writing lisp projects, of considerable size, like [shadchen](https://github.com/VincentToups/shadchen), which are, essentially, entirely made of macros or considerable complexity. My original point was that looking at macro expansions may not be as important as you are asserting it to be, at least in my experience, because I don't often do it, and I still develop quite complex macros.
Joy of Clojure Non-Lisp books. I have a strong preference for Common Lisp, but found these to be interesting nonetheless. ML for the Working Programmer Programming in Scala (First edition is available [online](http://www.artima.com/pins1ed/)) Others on my reading list: [Functional Programming for the Object-Oriented Programmer](https://leanpub.com/fp-oo) [Functional Programming in Scala](http://manning.com/bjarnason) [Programming in Standard ML](http://www.cs.cmu.edu/~rwh/introsml/) Edit: You might also be interested in [Rich Hickey's Bookshelf at Amazon](http://www.amazon.com/Clojure-Bookshelf/lm/R3LG3ZBZS4GCTH)
I am aware of the issue but my feeling is that the user should specify when a form is evaluated and that the library should not presume to force a particular time of evaluation. If one enters the above code at the repl, it executes, which is the intent of the example. Thanks for the other pointer though. 
Thinking about it, though, it does probably make more sense for it to just assume you mean to evaluate at compile time. A pattern is a fundamentally static thing. I probably have lots of Schemisms in my CL code. I strongly prefer Scheme.
Oh come on, you gave a rationalization to save a little face, and then you realized the rationalization made no sense.
Oh come on, you're kind of being a jerk. I did, in fact, know about the fact that `defpattern` did not force evaluation at compile time (I ran into the issue as soon as I started to use the Common Lisp version of the library at my job, and have simply wrapped `defpattern` forms in `eval-when`s since then) but what difference would it have made if I did not: I acknowledged your point and tried to keep the conversation civil, as I have been trying to do for several comments now. You have an awfully strange way of accepting the thanks someone has given you for a good piece of advice. 
But it doesn't make any sense. What is the situation where you want `compile-file` to fail where `load` works?
Here's mine (in a similar setup :): http://i.imgur.com/VXy2o.jpg Really fun and great book. I like the jokes and stories inside (which were the main reasons for buying the book, I knew some Lisp from before).
I keep learning new things about Common Lisp--and about programming in general--from studying CLTL2. 
There were a few links to Naughty Dog presentations about using Lisp in game development that came up recently here. Here's the link in case you missed that. Maybe you'll find some ideas there. http://www.reddit.com/r/lisp/comments/143hqj/lisp_game_development/c79kd5y
I just got this for Christmas, and have already whipped through about a third of it. It's well-written, non-threatening, and does a remarkable job explaining both what CLOS does and why it's a good idea.
Interesting. I'm glad to hear that Common Lisp fragmentation isn't much of an issue, but I have to wonder how much work library implementers have to do to keep their libraries portable across implementations.
You don't need a 1994-era Scheme implementation to learn from SICP. The material just hasn't changed. Running the code is hardly the point anyhow. Understanding what the code means is. As for Knuth, the code, such as it is, generally hasn't been updated for MMIX. 
http://planet.lisp.org/github.atom also has a feed of new repos.
Thanks for sharing. Apologies for my ignorance. But I am curious about LispWorks. It seems like it is easy to build GUIs with it, or am I mistaken ?
Seems to be; I downloaded the demo version a year or so ago and mucking around with the CAPI was very pleasant. http://www.lispworks.com/products/capi.html 
I wonder if there were any open source attempts to write a CAPI like library? (I have never used CAPI, just heard about it) 
&gt; It seems like it is easy to build GUIs They are easy, native and well documented. The only downside is that they are neither free nor Free.
I've actually spent some time fiddling with Common Lisp wrappers around the Win32 API and I have to say the CAPI would be a pretty daunting library to replicate. The biggest frustration would be reconciling the design of older GUI libraries like Win32 with more modern designs like Cocoa. The closest existing wrapper I've seen (tho not used) is the GTK wrappers (since GTK is cross platform). On that note the Win32 api is actually fascinating as a study of the evolution of design decisions/tradeoffs that had to be made going from 16 to 32 bit architectures.
If that is true the note on the download section should reflect that. The current message reads like the whole tool chain would not work. Personally, I have no qualms using command line tools if it's just the IDE that doesn't work.
If we consider wrappers of multiplatform c/c++ libraries and not only native libraries (bindings to OS-specific APIs), I would recommend [CommonQt](http://common-lisp.net/project/commonqt/) as a quite evolved library, it could be more incorporated and have more lisp feel though ([cl-smoke](http://tobias.rautenkranz.ch/lisp/cl-smoke/) is aiming this, but I don't know how good it is).
Unfortunately it looks like wrapping a C++ library like Qt takes some serious determination to get working even if you are just using something like CommonQt. The allure of CAPI or an open source equivalent is that it requires very few external dependencies (preferably nothing that wasn't already available through quicklisp). I only mentioned a GTK wrapper because at a guess it would have minimal external dependencies (I know it has Windows installer) and it's a C library so it would play nice with most CL FFI libraries.
&gt; I wish there were Lisp bridges to other runtime systems (Java &amp;rest) so that the libraries and tools for each could be leveraged efficiently in Lisp and vice versa. That would mean being able to call Java code and handle Java objects in Lisp Armed Bear CL?
http://www.cliki.net/Java
Lispworks may well be a thriving business and if I had money to burn I'd try it out for fun, but the CL community is SO tiny that it seems crazy to support a proprietary implementation instead of trying to expand the community. 
I'd say Lispworks is a respectable member of the lisp community too.
You'll be aware that I replied to your email, and that I'd love to help with the things you mentioned. In addition, despite my long estrangement from Dylan and my lack of enthusiasm for its infix syntax, I've never lost my affection for it, and would be glad to help out with it any way I can.
I think there are many uses cases where proprietary implementations are fine. Free software is about freedom of speech. We cannot save the world, only our selves. Sometimes you gotta look around and think, does your client truly care about freedom anyway?
In my experience, *most* companies using Lisp (including the one I work for) seem to use Lispworks. Lispers are generally happy there are still a couple of commercial Lisp implementations around, and gladly play to support them. I use Lispworks professionally and CCL privately, and am very happy with both.
Fortunately there is choice and competition. Even though the CL community is tiny, there are like around 8 active implementations. Btw., development of LispWorks started 25 years ago...
The 1994-era Scheme was a quote from the Lisp in Small Pieces site, not SICP.
My apologies for misunderstanding your quote. If you actually read the book, or, to be more precise, the English translation of the 2nd edition, (there is a 2007 French edition, which I assume has more up-to-date examples) you will see &gt; All the programs have been tested and actually run successfully in Scheme. For readers that have assimilated this book, those programs will pose no problem whatsoever to port! Really, running the code is not the point of these books. They are not teaching you to run programs, they are teaching you to understand programs. The only real issue of portability I would anticipate would be code that depends on the hand-rolled implementation of the Meroon OO Scheme dialect. I think it is fair to say that porting it to whatever Schemers use for OO these days is a useful exercise, and not a bug.
If you really want to "try it out for fun" there is a [Lispworks Personal Edition](http://www.lispworks.com/downloads/index.html). It lacks CLIM and application delivery, and has time/heap limits, is 32-bit only, but still has [useful functionality](http://www.lispworks.com/products/features.html). If you seriously need to try out other features, perhaps you should actually talk to Lispworks.
Btw., LispWorks can provide interested people with evaluation licenses. With that you can test the full LispWorks - not just the limited 'Personal Edition'. It's valid for some period of time - like a month or so. You'd need to contact LispWorks and ask for an evaluation license. Franz Inc. also offers evaluation licenses for their Allegro CL.
Since Common Lisp is an ANSI standardized language the choice of implementation should not matter in the expansion of the community. Using CL is all that matters.
Trying something out for fun doesn't mean I don't want to use it for something real world, like a constantly running website/API or something with real users. The personal licence is unsuitable for this.
I never suggested otherwise
You're going to get soooo many different replies, so I suggest you read the *motivations* of each very carefully :) As for my 2c: * [Racket](http://racket-lang.org/) offers a couple of different Scheme dialects for you to play with in a very nice environment (DrRacket) * Common Lisp is [standardized](http://www.lispworks.com/documentation/HyperSpec/Front/) &amp; has many [libraries](http://cliki.net/Current%20recommended%20libraries). Also two great books have been written about it: [Land of Lisp](http://landoflisp.com/) and [Practical Common Lisp](http://www.gigamonkeys.com/book/) * [Clojure](http://clojure.org/) combines many of the ideas from Common Lisp (eg. the macro system) with the "purity" of Scheme (focus on functional programming) and great concurrency support. Also, it uses the JVM as a base so you have access to a wealth of Java libraries. HTH!
Please blog/publish source ;) 
What do you want to do with it? * If you want to learn a lot of programming theory and only a few language constructs, you probably want Scheme. Which Scheme to use is its own question. * If you want a large, full-featured language that's been used for significant amounts of serious work, you want Common Lisp. SBCL is more or less the default implementation these days, but others have their merits. * If you want a language with a large library ecosystem and feature set optimized for today's world (*nix, unicode, web development, etc...) or want a language that handles concurrency for you (and strongly pushes all its libraries in that direction), look at Clojure. * If you want to script Emacs, use Elisp.
And indeed, binaries for [Windows x86 and AMD 64](http://www.sbcl.org/platform-table.html) are now up on the platform table (thanks to Elliott). Please test!
When I started out, after dabbling around with elisp, I initially went with scheme primarily because of SICP. But these are the reasons I switched most of my Lisp-related activities to Common Lisp now: 1. When you go with scheme, you will get recursion pushed on you like a political ideology whether you want it or not. Many iteration constructs are unavailable solely to make you get more familiar with recursion. Also other concepts (like continuations, hygienic macros, shared namespace) seem to be pushed more to force some user adoption, than because they are really useful. There is a much greater (and annoying) emphasis on code to be ideologically "clean" than useful and practical. A book like "Practical Scheme" (the equivalent of [Practical Common Lisp](http://www.gigamonkeys.com/book/)) will never be written because it is essentially an oxymoron. 2. Too little of the language is standardized. Schemers like to point this out as a feature (We have only 50 pages, while Common Lisp has over 1000, bloat!) but in practice, it is a liability. Everything that is not standardized (usually mundane day-to-day practical stuff you need to play around with the language) is incompatible and unportable between implementations. So whatever you write in "Scheme", will forever only run on that particular implementation. There are no compatibility layers to abstract away the differences. 3. A consequence of 2. is that too few libraries exist, so you only end up dabbling around with the base language (now lets flatten that nested list) and can never do anything somewhat practical for fun. Since the scheme ecosystem has comparably few developers, and thousands of incompatible implementations exist, they keep reinventing the wheel over and over and over and rewriting the same stuff for each of those implementations, instead of writing _new_ libraries for one single implementation. 4. The available literature essentially boils down to SICP and the Little Schemer. And these, though wonderful in their own respect, also only dabble with the few standardized features (now lets flatten that nested list again) and dont even mention that Scheme could ever use for anything remotely useful or practical. Again, because of 2. you have dozens of dry and sparse implementation manuals essentially talking about the same (but incompatible) stuff, but nothing on top of that, Community is IMHO the most important part to begin with a language, so if you're sure you want to go with Scheme, go with Chicken, since it seems to have the largest and most vibrant community of all Schemes. If you just want to dabble with *a* Lisp, go with Common Lisp: Base implementation [SBCL](http://www.sbcl.org/), Libraries with [Quicklisp](http://www.quicklisp.org/beta/), IDE Emacs+[SLIME](http://common-lisp.net/project/slime/) (An alternative is the proprietary IDE [LispWorks](http://www.lispworks.com/downloads/index.html)). All that being said, GNU Guile has and always will have a special place in my heart. I still use it, but mainly to glue together my C.
I'd learn multiple dialects, because its pretty enlightening to see the differences up close. But I'd start with Racket, as many other people in this thread have suggested. 
If you want to learn lisp for the sake of being a better programmer, any flavor of Common Lisp or Scheme is ok - and you might want to start this way anyways, for ease of learning. I wanted to be able to use Lisp in a production environment, preferably without throwing everything else away - and the best choice I found at the time (and I think still the best) is Clojure. You'll also need to learn some Java to use it properly, but the advantages (easy to setup, libraries for absolutely everything, can be "sneaked" in an existing java project more then make up for it.
Everyone else's code still calls cl:length and cl:+. So does any code that, while in the same package, is read before define-generic-layer executes.
I'm going to get downmodded by the scheme fanbois for this, but here we go. Scheme is dead. Scheme is caught between three better, and more popular, options for different tasks. On the actually-getting-work-done side there is the Common Lisp, which dwarfs Scheme in community. On the interesting-functional-language-for-academics side there's Haskell, which has most of the mindshare. And on the embedded language side there's Clojure and Lua, both of which have far bigger mindshares. Scheme remains an interesting teaching language. But that's about it at this stage. Here are some other teaching languages: Pascal, Logo. That's where scheme is headed. MIT has abandoned 6.001 at this point: this is telling. If you're interested in a Lisp that's likely to be around in the next ten years, look at Common Lisp, maybe Clojure.
Not a Scheme fanboi, but I'd like to respond to some of your claims anyway: &gt; On the interesting-functional-language-for-academics side there's Haskell, which has most of the mindshare. Haskell is not a Lisp. &gt; And on the embedded language side there's Clojure and Lua Clojure is not an embedded language. Lua, while it is claimed to be very similar to Scheme, is not usually considered to be a Lisp. &gt; MIT has abandoned 6.001 at this point: this is telling. Hal Abelson explains [here](http://www.codequarterly.com/2011/hal-abelson/) why they changed to Python. &gt; If you're interested in a Lisp that's likely to be around in the next ten years, look at Common Lisp, maybe Clojure. I doubt Scheme will be gone in 10 years. There's a lot of activity on numerous Scheme implementations. Beyond that, Scheme is a great way to learn Lisp. Much of the knowledge you gain can be used with Common Lisp and Clojure.
I think you may have missed my point. The point I'm making is that Scheme is in serious trouble. It doesn't have a market really, nor a compelling reason for new people to learn and use it. As such if one were to learn a *lisp*, I'd pick something other than Scheme.
It takes a man to say this. You have my upvotes.
Shadowing symbols does not just shadow their function definition, but all their meanings. So if you, say, shadow `*`, then `(array * ...)` will no longer work as a type specifier the way you expect.
There is good reason why Lisp people are smug.
 &gt;Scheme is dead. Note I'm mostly a CL person, but Racket seems to be fairly alive, and is also very much batteries-included. Certainly it's alive enough to use as a learning tool.
https://github.com/drewc/smug
http://common-lisp.net/project/closer/contextl.html &lt;--- layers? yes. Works more then once? yes. Or: shadow what exactly? what happens to (function +) when cl:+ has been shadowed? what happens exactly? Or : The function CL-USER::+ is undefined 
&gt; Scheme remains an interesting teaching language. Scheme remains the best teaching language, which is the whole point really. It is still alive in the arena that it performs best in, and in my opinion it is still the best language in that arena.
[How to Design Programs](http://htdp.org)
Honestly if there was like a Personal Edition Plus I would buy it. The limitations of Personal Edition make it not attractive to me and I'm not dropping 1500 bucks on a license cause just hell no. 
Anyone know if LispWorks has a graphical GUI builder?
It has. But not in the Personal Edition and also not on Mac OS X. Feature list: http://www.lispworks.com/products/features.html
Many are thinking that way. It is aimed at the professional and the 'dedicated hobbyist' market. The price is for a professional tool comparable to what you pay for similar tools from other vendors. Not so good: The 64bit version is more expensive. A single license of LispWorks is also valid only for one platform. One the positive side, LispWorks is now mostly available without runtime licenses. Unfortunately other 'hobby' things are expensive too - I bought a piece of sports equipment for $1500, two years ago. 
The cheaper alternatives are not really that good. Though there are a lot of them. Really cheap ones cost 10%.
Sure. Visual Studio is several K for the pro versions, as are a variety of other professional tools for the enterprise. If I was doing Lisp at the enterprise, I would recommend evaluating LW/Franz/etc without a second thought. But I can't afford $1500 for a hobby. *Any* hobby. I'm not paid that well. 
I can understand that. There were a lot of Lisp vendors offering cheaper implementations. Like ten or even twenty. Most are gone or barely alive. Examples: Coral/Apple/Digitool. Expertelligence. Procyon. Goldhill. Corman. Linklisp from Conscious Computing. MuLisp from Software House. nanoLisp from Microcomputer Systems Consultants. Sapiens Software Corporation. Ufasoft. Some had a range of offerings. Some had a single offering. The ones which are still there are Franz Inc with Allegro CL (they just released Allegro CL 9.0) and LispWorks (which just released LispWorks 6.1). Scieneer tried to sell a CL. I have no idea if that is still bringing money. In the Scheme world, there is Chez Scheme. Franz makes money with a lot of research/commercial/government customers and tools on top (semantic web). LispWorks only develops their Lisp implementation and sells also a lot to individuals. For some reason there does not seem to be a profitable market in the range of $150 for Lisp implementations. Generally the Lisp market is small. A cheaper offering could help to expand the market - but how much? Would it be profitable?
 &gt; One the positive side, LispWorks is now mostly available without runtime licenses. And has been for a very long time, certainly well over 10 years.
Yes, and this is common for any serious hobbyist. Photographers have Leicas, cyclists have carbon bikes, car drivers have whatever it is they have, bird watchers have fancy binoculars, and so on and so on. Me, I have an LW license.
&gt; A cheaper offering could help to expand the market - but how much? Would it be profitable? I wish I knew! Obviously it is an opportunity for someone with some money to invest to work up a commercial lisp and give it a spin at the $100-$200 price point. N.b., Scieneer appears to be still running - last release '09 and for $300 USD. It seems to be focused on Unix systems. Franz is selling AllegroCL at a starting point about $600 USD. Not sure what Allegro supports besides OSX.
&gt; I wish I knew! Obviously it is an opportunity for someone with some money to invest to work up a commercial lisp and give it a spin at the $100-$200 price point. I don't think it has happened in the last decade. If you would like to sell 10000 copies each for $200, then you would need to seriously expand the current market. Allegro CL has a long history on UNIX and Windows. Lots of very demanding applications have been implemented with it. Now also on Linux. The $600-something version is for academic users. Its biggest drawback of Allegro CL for Mac OS X is that it does not support its IDE and its GUI toolkit on Mac OS X with Cocoa.
Intellij IDEA is a good example. But its potential market is much larger than that for a Lisp IDE. The number of professional Java programmers is easily 1000 or even 10000 times larger than that of Lisp programmers. Intellij IDEA also supports more than just Java - it also has to. Intellij IDEA has a nice pricing and licensing structure, that's true. Btw., if there is an open source project in Common Lisp, which wants to support LispWorks, then I would atleast ask LispWorks sales for a good price or even a free license. They can hand out time-limited free licenses...
Can i write a closed source program in CL for iOS? (Static linking)
Linux had free runtimes in 2000-2002 timeframe. I know because I wrote applications on Linux using LW then, and this was one of the reasons we chose it. Legacy Unices might have been different, I guess. Also: no, the osx port is much more recent, not sure exactly when, but well after 2002.
This misses the point that C and Java are in fact both Algols.
But he has a point. It is a completely different thing to say that you must learn a "C family language" than to say that you must learn C, as it is completely different to say that you must learn Lisp (which is now defined as a family of languages) or Common Lisp. What about Emacs Lisp? It is a subset of Common Lisp, why wouldn't it be a Lisp? And Guile? Scheme and Clojure are as Lisps as CL, the same is true for Java and C++. They are from the C family. And let's remember that it's not just brackets that make a C family language, as it's not just parentesis that makes a Lisp. There are other characteristics, such as static and strongly typed variables. I wouldn't consider Javascript a C family language, only a distant descendant.
I was, obviously, saying "an ALGOL" by analogy with "a Lisp": it is more conventional to say "an ALGOL-family language" but it makes no difference to the meaning. The point I was making was that saying "C++ is a C" is like saying "Emacs Lisp is a Common Lisp", and equally silly. Emacs Lisp, Common Lisp, Scheme and other Lisps are all Lisps (or lisp-family languages if you prefer). C, C++, Java, &amp;c are all ALGOL-family languages (or ALGOLs if you prefer). The message of the article that "... the only Lisp currently is Common Lisp [...] Every other Lisp-like language isn't a Lisp, it's just similar to some extent" is not only manifestly silly, it's liable to cause yet more accusations of CL-elitism which we could all, frankly, do without.
&gt; I wouldn't consider Javascript a C family language, only a distant descendant. JS is a poorly-designed Lisp in ALGOL's clothing. I don't mind the clothing, the poor design gets me.
I think we should see two different things: **1) A wide family which shares only tiny amount of features and is basically defined by heritage.** That's the 'Lisp family', 'ALGOL family'... These programming languages in those family are widely different and share very little. Thus the idea of an ALGOL family is mostly meaningless. Same for Lisp. In the wide Lisp family we would have Lisp 1.5, Logo, Dylan, Eulisp, ELisp, Clojure, MDL (ever heard of that?), Scheme, ML, ... Those languages share very little and have developed their own cultures. Maybe the designer has read a book about an earlier dialect and reused a tiny bit. **2) A programming language and its successor dialects.** Let's assume that the first was Lisp 1 and then Lisp 1.5. Lisp 1.5 had been replaced by Maclisp, Interlisp, Franz Lisp, and a few others. Interlisp and Franz Lisp died a horrible death. Maclisp morphed into Common Lisp. Elisp is a Maclisp-derived dialect. Common Lisp provides all the features of Lisp 1.5. Slightly updated. With relatively little effort you can run Lisp 1.5 code in Common Lisp. Identifiers, syntax, much of the semantics, even much of the pragmatics is still present in Common Lisp. We have cons cells, dynamic binding, lambda functions, s-expressions, symbols, ... you name it. Now we are talking about real features: syntax, semantics and pragmatics. There is a core group of languages which preserve these features (lists, symbols, dynamic typing, strict evaluation, s-expressions, garbage collection, EVAL, READ, CAR, CDR, ATOM, LAMBDA, LET, ...) of the first Lisp and most of these languages have Lisp in their name. In this group are languages like Elisp, ISLisp, Visual Lisp, Common Lisp, ... But not Scheme, Clojure, Dylan, ML, ... The lead dialect for this core group is Common Lisp. All the others in this group are either derived, directly related or on the way out. Lisp-derived languages like Clojure, Scheme or ML have or are developing into their own culture. They don't try to be compatible with the language they were derived from. Thus it makes little sense to say they are 'Lisp' languages in a practical sense. For some time it still may look so. After some time the distance gets larger. Scheme started as a re-thought Lisp improving on the semantics. R6RS Scheme got rid of the dynamic features like syntax (not based on s-expressions, but a syntax specification of the language Scheme) and semantics (EVAL was an underspecified library function). 
I would have thought the same ten years ago. But currently I think it is time to give it some thought, again. Many new languages in the 'Lisp family' are so far away from the original Lisp, that they don't deserve the label of a Lisp. They are mostly derived languages with very few sharing. The core languages share a lot more. ELisp (the language) and Common Lisp share a lot.
Part 2 will be all about the implementation, which was complicated and enriched by trying to keep the pattern match expansion flat, rather than nested. I liked the result so much I'm considering rewriting Shadchen to generate flat pattern matches. 
Could we please avoid downvoting lispm? You may not agree with him but at least he argues for his sake
Some of his arguments are fine and I may upvote them, but when he says that calling a language "an ALGOL" is a thing for "Lisp freaks", he doesn't deserve an upvote.
But it is. Almost every language based on blocks structure can be considered an ALGOL-dialect.
It certainly would require a sense of humour, yes.
That's mostly meaningless. Common Lisp is more ALGOL than Java. CL-USER 1 &gt; (block foo 1 2 3) 3 Common Lisp has blocks and names them 'BLOCK'. Now Common Lisp is an ALGOL-dialect? Please.
Yes, it is. Scheme is explicitly so (ah but I forgot, Scheme is not a Lisp because it believes in the wrong kind of pew or something, sorry).
I didn't downvote you. ;-)
I wouldn't say that it is an ALGOL dialect, but that it has support for some ALGOL-like syntax. You don't *need* to use blocks to make your code on CL. It's an option that you may use. The same is not true for ALGOL, C, C++ or Java, blocks are intrinsic to them.
what is a 'block'? A block is a sequence of forms with scope for variables and/or control structures. That's LAMBDA, BLOCK, DEFUN, PROGN, TAGBODY, ... Common Lisp is a block-structured, procedural language. &gt; You don't need to use blocks to make your code on CL. It's an option that you may use. They are everywhere. LAMBDA is a block. PROGN is one. BLOCK is one. DEFUN is one. 
But the block in ALGOL uses lexical binding. You can use dynamic binding in CL. I think the original Lisp didn't even have lexical binding, but I'm not sure. I don't know why we're still discussing. This is not useful at all.
I never said that.
Common Lisp uses lexical scope by default. &gt; I don't know why we're still discussing. This is not useful at all. You claimed that every block-structured language is an ALGOL-dialect. Common Lisp is block structured - surprise. Now we have a new ALGOL-dialect. 
Read my post again. I said you can use dynamic binding, not you must, nor that it is the default. You don't have this choice in Java. Nor in ALGOL. But yes, this kind of treatment of blocks is heavily inspired by ALGOL. That's why tfb said CL is also an ALGOL-dialect. I don't agree, but it does make sense.
Common Lisp is a Lisp-2, and that's needlessly bad.
It's not corporate greed, it's freemium!
And I never said that we should upvote him, so what are we talking about exactly?
trash, I guess.
CL is a lisp-50, at least.
Go on...
It's an interesting bug, and I'm curious to know how and why it was introduced. Ron Garret's initial argument about it was a bit of senselessness that was thankfully withdrawn.
i kind of agree. There needs to be something so you can build something effective. When I tried the PE version before, I uninstalled it pretty quickly. Also, just to be clear. I understand the position the publisher is in. They want to employ developers to improve the product, so they need $. This same issue has crept up over and over throughout the years. It happened with Smalltalk and a few other impressive languages. I don't know the solution.
My guess is that someone decided that would be something nice to optimize and completely forgot (or ignored) the hyperspec. It's very easy to think that the way AND behaves makes also sense here so I think that was the root of the problem, or something along those lines. But it would be interesting to know the answer to your questions! 
Here is another example where the arithmetic operations in the CL package are shadowed into generics: https://bitbucket.org/tarballs_are_good/cl-generic-arithmetic/overview 
Yes, but it's not yet easy. There has been effort put into making ECL run on iOS https://github.com/kriyative/ecl-iphone-builder but it's about as much fun as running Linux was in the mid 90s. There is a company called Wukix that supposedly has a solid Common Lisp implementation for iOS and Android development coming out in early 2013. At this point I would recommend that people who are not experienced C and Lisp hackers stay away from mobile, but that will change soon.
ECL is LGPL which effectively cuts out using it for a program if I want to keep the source files to myself.
You may want to look at Franz's preamble, which explains how they interpret the LGPL applied to Lisp: http://opensource.franz.com/preamble.html You would be responsible for making the ECL code available on request, but you would not be responsible for providing the source for your own code "linked" against ECL.
Common Lisp 2.49 ? There is not such a thing. There is the clisp interpreter/compiler with that version. But already I can see an issue :)
I probably should have stated that i automatically ignore compilers i have to pay for. 
? ECL is free.
His main argument is that Common Lisp is the only remaining dialect since others like Zetalisp that also would've had the right to call itself "Lisp" are all gone. But that's empirically untrue. Scheme is not only still around and in some ways thriving more than Common Lisp, but Common Lisp itself borrows from Scheme and even had some of the same language designers (e.g. Guy Steele). Watch the SICP video lectures and notice how they refer to the language as "Lisp" not "Scheme" even though the specific dialect is Scheme. Then he goes on to make the irrelevant argument that languages like Scheme don't have "Lisp" in their name. If we're talking about what *essentially* makes a language what it is, then why does the name matter instead of its attributes? Also, what about "NewLisp", "XLisp" (which is that basis of niche languages like Nyquist), or "Emacs Lisp"? They have "Lisp" in their names. So now what complaint does he have left to make? Well, he seems to think that since languages like Clojure is different from Common Lisp that Clojure can't be a LISP language. Being different from Common Lisp is irrelevant because both Common Lisp and all the other languages I've mentioned are in many ways distant from the original LISP. Bickering about which is closer to the original is pointless. For example, it's not as if Common Lisp uses 100% dynamic scope (since it follows Scheme in supporting lexical scope as well). In claiming to be a LISP dialect, they all share least-common-denominator features with the original, mostly parenthesized polish notation and the unification of code and data. So they all have the right to claim to be a LISP dialect. And speaking of names, if I or anyone else wants to call the *family* of languages "LISP" instead of "Lisp", we are 100% justified in doing so. Not only is it the historical name, but the name is an *acronym*. Acronyms of any sort, whether about programming languages or not, are conventially in all-caps. If a particular dialect spells it as "Lisp" then that's the naming accepted by that dialect, it doesn't change how acronyms are generally handled in spoken or written language. In any case, there's really nothing to see here, move along. The guy's just trolling. Whether you agree or disagree with him will make no difference at all in your understanding of programming or of the languages mentioned. Agreeing with his position will in no way make you more enlightened or make the world a better place for software development. It's the same tired bullcrap argument: "The universe revolves around MY experiences of programming languages. Ignore the actual history and facts that actually went into the creation of those languages."
Sent them suggestions: 1. It's called "CLISP 2.49" 2. Add SBCL. 3. More idiomatic CL solution.
&gt; Watch the SICP video lectures These are old. He talks about now. &gt; NewLisp That was a wrong name from the start. It would be great if it could be renamed &gt; XLisp Was a Lisp based on earlier dialects and the included features form Common Lisp. AutoLisp was derived from it. The early XLisp definitely stands in the tradition of McCarthy's Lisp. &gt; I've mentioned are in many ways distant from the original LISP Not really. You can without much effort run Lisp 1.5 code in XLisp, ELisp or Common Lisp. &gt; if I or anyone else wants to call the family of languages "LISP" instead of "Lisp", we are 100% justified in doing so. It's usually spelled Lisp since a few decades. &gt; Ignore the actual history and facts that actually went into the creation of those languages. He doesn't. It's time to make clear what 'Lisp' is and that random derived dialects are fine, but that there is a core Lisp. This core Lisp should be moved forward and we should not do that by creating the random derived dialects and derived implementations. It's fine that somebody removes CONS cells, re-does evaluation, removes macros, removes GC and brings back FEXPRs and then claims it is a new Lisp. But it isn't. It is some random programming language derived from Lisp. New users are then confused what Lisp is and what not. To make it clear: Lisp is Lisp 1 and then moved forward. It is not Lisp 1 and then moved sideways. 
I love blog posts like this. Well I didn't understand much about the topic ( I am a beginner), but it taught me some things about Emacs+Slime I didn't know. Also I wasn't aware of the fact, that you can write a function and have a descriptive string at the end of the function. I thaught it must be (define nameOfFunction(args) "some descriptive string" code).
HackerRank is duplicating the functionality of RosettaCode 1:1. There's absolutely no point contributing to it and rewriting all possible tasks from scratch when one can contribute new and unsolved tasks to RosettaCode. If you have too much time at hand, go help out expanding the Common Lisp section: * http://rosettacode.org/wiki/Reports:Tasks_not_implemented_in_Common_Lisp
Just another idea. Clozure is basically a commercial vendor. Their Lisp is open source and does not cost. For support you might either get the community activated or you pay Clozure for the development - which several companies (for example ITA) did. Now, if you want to have an improved Clozure CL which provides missing features like a better GUI toolkit and a better IDE, better Windows integration, or what else you would be interested it might a way to contact them, see if they are interested and then start it via something like 'Kickstarter'. That way one could define the delivery, collect the necessary money and one gets an overview how many people are interested...
There were lots of lisps before CL.
Just trolling.
I'm not sure we're speaking the same language. A Lisp-1 has one set of vocabulary, while a [Lisp-2](http://en.wikipedia.org/wiki/Lisp-1_vs._Lisp-2#The_function_namespace) has two parallel vocabularies, for variables vs. functions.
I'm just kidding. Calm down.
You linked me to franz so i thought that referred to AllegroCL which is not free for commercial use. Edit: anyway, i was curious because i just started writing wrappers for my 3d engine to use scheme. Afaik, there were no free lisps that run well on windows, mac, linux, ios and android.... last i looked into ecl i found a good responds about lgpl static linking (cant fine now). It seems the opinion has flipped since last i checked though.
Thanks for the link to rosettacode, but like instatrash says, that's really not what HackerRank is doing.
Seeing how popular clojure is, I wonder how much it eats into the Franz/LispWorks share? I was a cl programmer at one point. Used SBCL, we even bought LispWorks pro. But then I migrated all my code to clojure and never looked back.
You know, I hadn't thought of CCL in that context. That is a good idea. I will keep that in mind.
I bought the ZM and LW with the savings...
Hehe, yes, it's pretty bad. But I guess it stands to reason that the guys adding language modules to the site aren't going to be proficient in every language they add. That section really ought to be opened up as a wiki though.
Ah, too bad I can't read Arabic. The writing direction is confusing me x_x [The text on top](http://i.imgur.com/wiiPW.png) is what it looks like on GitHub for me, while the one on bottom is what it looks like with `dir="rtl"` added. Is the bottom one how it should look?
Very cool.
I'm not opposed to UTF-8 anymore_ :)
_Pretty_
That's what I thought, too. The way it displays here, it looks like the parens don't match. (They do, though; the display direction changes when you copy-paste it into a Unicode-unaware editor.)
In the 1980s, when my dad taught computer engineering at [KAU](http://engineering.kau.edu.sa/Default.aspx?Site_ID=135&amp;lng=EN), I saw a printout of a Pascal program written all in Arabic. It translated pretty cleanly, too. I don't remember what sort of computers they used at the time, but I remember playing around with a Data General mini in the computer center.
Use "shell" to open a shell and cd to your working directory. start "slime". Open a file for saving your code. Use "tab" all the time. In your file use ctrl-c ctrl-c to compile a function. Also, I just type in commands like "slime-inspect" and "slime-restart-inferior-lisp".
Yes, a few keybindings that put s-expressions from the REPL into the file buffer window could be very handy.
A few features I discovered in addition to simply evaluating code in a separate buffer (which one can implement with two windows in screen and the appropriate screen copy-paste command): * autocompletion for symbols available to you, including ones you created * display of the prototype of any methods and functions in any package, including ones you have built * better debugger integration with your source code than what comes in the basic REPL, including the placement of a NOP form to represent current step position in a complicated nest of forms The first two points highlight that the communication with the REPL goes two ways, actually integrating the editor with the REPL as you type. The last point highlights a fancy wrapper around the REPL debugger.
To my knowledge, everything that Marco does in the video is still correct (but I'm not going to watch through to make sure). The reason that Marco's initialization process is more complicated than you might expect is because he is demonstrating how to connect to an already running Lisp image on a remote server. This is really cool and I use this all the time, but in his desire to show this functionality he forgets to demonstrate the simpler ways that you can start SLIME and Lisp locally, i.e. "M-x slime".
I have a feeling that many Lisp+slime users tend to spend a great deal of time programming in the buffers. Remember that "C-M-x" will evaluate any code chunk in your Lisp-mode buffers (chunks delimited by opening parentheses on the first ~~line~~ *column* as is the Emacs convention/heuristic) and "C-c C-c" does the same but passes it to the compiler. There is not necessarily any need to work at the REPL at all. I use the REPL to try out little test invocations and when I can't be bothered to think up a file name and location to put the source, but usually not much more.
A better suggestion is to have Quicklisp installed for whatever implementation. I started to play with this but then quickly hit the task of parsing a little text input. The thought of hacking together a solution quickly turned me off of the challenge.
I have something like that, although I haven't used it much. http://paste.lisp.org/display/134707
Using GNU Emacs &amp; Slime: I write my code in editor buffers and compile it from there. Everything interactive then is done from a 'repl' buffer. Especially the stuff which creates output and where I want to reuse commands or output.
That's not a function documentation, but variable documentation - it's the last argument for defparameter. Function docstring is, as you've said, first element in function body.
In that case, is there any way to automatically load the REPL and a file, or the REPL and a scratch buffer, or not load the REPL and load something else, in SLIME's options?
What do GADTs look like in a dynamically-typed language?
I did mean 'start SLIME, but open a file in a buffer with code in, instead of the REPL', but perhaps closing the REPL isn't a good idea. While what you describe is helpful, I've found that I liked to open several files in different windows, and if I leave the REPL open, I'd also like to edit code in a different window, or even in a different frame if I am opening several files. Using slime-selector may be fast, but I like having the REPL and files I am editing open in different windows/frames at the same time, rather than switching between buffers in the same window. What I would like to know is if there is a way to load SLIME, opening the REPL and a file in another window at the same time?
They look exactly like Olympic weight-lifters in zero gravity.
Oh right, sorry. I shut down my computer every day when I go to sleep, because of the power savings and with an SSD it starts up quite quickly. What I mean is when you type in M-x slime I'd like it to automatically enter C-x 4 C-f (open another window and open a file in that window) for me. This would probably be a separate command as well, so maybe if I type in M-x slime-and-file I tried to make a new function in init.el to do something like this, by entering M-x slime, then C-x 4 C-f for me, but for some reason it didn't work.
Thank you. I think mine was simply: (defun open-slime-and-file () (interactive) (slime) (find-file)) Just a case of me not reading the documentation on emacs lisp enough I guess.
There is nothing about Lisp, when used to denote the family of languages which resemble one another in the use of s-expressions and syntactic extension, which demands that it be dynamically typed. There do exist languages which I would call Lisps which have static types, like Typed Racket and Shen.
I don't realllly want to get into an argument over what a lisp is, but all the most prominent lisps, both now and in the past, have been dynamically typed. Furthermore, I think s-expression based syntax does favor dynamic typing insofar as it entails that whenever E1, ..., En are lisp objects with defined semantics, then the list (E1 ... En) is a lisp object with defined semantics, which is a merge rule for a unityped language. A language with more complicated type system will have a more complicated syntax combinator than CONS.
Point taken, but it in modern parlance s-expressions and syntax extension are almost always what one means by saying something is a lisp. For instance, if I described McCarthy's first lisp as "not very lispy," it would be clear, I think, what I mean. 
Interesting point about the syntax/semantics relationship. Still, as long as there is a type which encompasses all readable forms of Lisp objects, then it isn't particularly complicated to have a List of them. I kind of _don't_ like that we conflate syntax with CONS cells, though, personally, exactly for the reasons we have to cook up complex syntax representations in a language like Scheme or belabor the meaning of a piece of syntax with respect to first class arguments in languages like Kernel. There is plenty of room for static lisps, I think. 
For me the core of Lisp is 'Recursive Functions of Symbolic Expressions'. 
Unless I misremember the m-expression lisp was not actually implemented: the first *implemented* lisp used s-expressions.
I think this is true. However I think there's probably at least a partial bootstrap problem here: because Lisps have traditionally been dynamically typed, they appeal to people who like dynamic typing, and those people tend not to be interested in implementing statically typed Lisps. So I think, based on that argument, you'd expect such things to be scarce, as indeed they seem to be. As you say, there are exceptions – I've played with Typed Racket and it didn't seem too hostile to me (though I am very much a dynamically-typed-language person).
I'm kind of open about types. I very much like the discipline of a good type system, but I'm not sure that it has to be static to work for me. I've only written small amounts of code in Haskell, and while I like the clarity that having to really think about types produces, I also found that it prevents free flowing development. Since I'm mostly programming in CL these days, which I believe has some warts in its basic types, and since I've been dealing for the first time with an environment where one cannot just throw away bad code and rewrite from scratch, which is how I work in personal projects, I think I've felt an increasing interest in type systems to impose a discipline which can't be escaped, despite pressure to develop quickly and dirtily. My experience so far is that quick and dirty code is fun to write, but piles up like manure. It seems nice to be forced to write clean once, and to be forced to redesign when problems arise, rather than hack your way to the next solution, which is sometimes the pattern I get tricked into. Probably I simply need to enforce upon myself better discipline when writing code (which is hard), and deeper knowledge of CL (I come from a more Scheme background) wouldn't hurt either. 
You could have a typed language with these properties, of course. Haskell or ML are very close. 
Nice password!
How much of the api docs does this implement?
I know [this](http://www.bash.org/?244321) probably doesn't need pointing out.
I don't think this merge rule means that there has to be only 1 static type. It should work fine in other languages for any type hierarchy that forms a tree, shouldn't it?
A set of list contents specifiers, perhaps? I mean, instantiations of such types might look like: ('node :left a :right b) ('leaf :value c) or similar. Although technically, to resemble Haskell more, you'd need to drop the field descriptions (:left, :right, and so on), but I would actually prefer to have them for better readability.
Can you give an example? The way I would define a type is something like an equivalence class of terms with identical distributions ie. x and y have the same type if M is a term iff M[x := y] is a term. To a first approximation at least, you can always replace a subexpression in an sexp with any other expression, so there would be only one type.
Here is what this wrapper currently supports: /api/login /api/me /api/subscribe /api/comment /api/editusertext /api/vote /api/save /api/unsave /api/report /api/marknsfw /api/hide /api/unhide /api/del /api/block /api/read_message /api/unread_message /api/approve /api/leavecontributor /api/leavemoderator /api/remove /api/setflairenabled / /r/&lt;subreddit&gt; /r/&lt;subreddit&gt;/new /r/&lt;subreddit&gt;/top /r/&lt;subreddit&gt;/about /search /user /user/about /message /user/&lt;user&gt;/subscribed /comments *edit spelling
I just talked with some of the people behind Hacker Rank and they seemed to like the idea of providing SBCL with Quicklisp. I figured that this would catch the biggest cross-section of the community. I'll be interested to see how that works out.
Not that I know of, but there is [iron scheme](http://ironscheme.codeplex.com/) and of course [ClojureCLR](https://github.com/clojure/clojure-clr)
 cd ~/quicklisp/local-projects/ git clone git://github.com/jperson/cl-reddit.git There goes my morning. 
dotLisp was created by Rich Hickey quite a few years ago prior to his Clojure work. I don't know if it's CL or not.
For those who - like me - didn't realize this is a link submission and not a self-post, the author lists the implementations he found while researching. &gt; Furthermore, the state of Lisp-languages on .NET is not much better since you can find lots of half-baked, abandoned languages/implementations or just without real followers (for example, [L#](https://github.com/RobBlackwell/LSharp), [Yarr](http://yarr.codeplex.com/), [dotlisp](http://dotlisp.sourceforge.net/dotlisp.htm), [Common Larceny](http://www.larcenists.org/), [ayaka](http://code.google.com/p/ayka/) and others). The major exceptions are probably [IronScheme](http://ironscheme.codeplex.com/) and [Clojure](https://github.com/clojure/clojure-clr). And even the CLR Clojure implementation is just playing catch-up with the Java one.
An ADT isn't exactly the same thing as a [GADT](http://en.wikibooks.org/wiki/Haskell/GADT)
Great timing! I'm also just starting on a .NET project and shopping for a suitable interop library. Does anyone in the community have any experience with RDNZL for a .NET FFI? I need to be able to call MS MAPI and WMI APIs. http://weitz.de/rdnzl/ 
your datatypes.lisp file CameCases class names. That Is Bad.
&gt; Does anyone in the community have any experience with RDNZL for a .NET FFI? Not enough to be a resource to anyone. But I have used it a *bit*. I wanted to do WPF ([Windows Presentation Foundation](http://en.wikipedia.org/wiki/Windows_Presentation_Foundation)) stuff via Lisp. I got it to display something using the built-in WPF dialog box, and also to create an empty WPF window. That's as far as I made it. EDIT: Diction; add link.
Meh, habit from writing c++ code everyday, I actually prefer hyphens. Out of curiosity is there a reason it's bad other than not being the lispy way to do things? *edit spelling
The reader automatically converts it to uppercase anyway
The problem with CLR floating-point is that the virtual machine supports only one floating-point type, double (64-bit). (32-bit) float is a storage format only, so in some cases double rounding occurs, leading to results that differ from "proper" float calculations by 1 ulp.
Good luck on your project! How are you planning to implement the first iteration? I hope you will be using Common Lisp :)
A few years ago, I compiled a list of such projects at http://www.clausbrod.de/Blog/DefinePrivatePublic20080312DotNetAndLisp
That's a good post! I didn't see it before but it's good to know a few more projects I didn't manage to find.
Thanks for the clarification. I saw a few references to the problems CLR had but none made this simple explanation. Thanks again!
Thanks. From the looks of it, support is still in the early stages.
New to Common Lisp? And lisp in general? (defmacro define-api-function (name) `(defun , (intern (apply #'concatenate 'string (mapcar #'symbol-name `(api- ,name)))) (u i) (api-generic ,(concatenate 'string *reddit* "/api/" (string-downcase name) ".json") u i))) (macroexpand-1 '(define-api-function unsave)) =&gt; (DEFUN API-UNSAVE (U I) (API-GENERIC "http://reddit.com/api/unsave.json" U I)) 
I usually write code first then look at what can be refactored. Haven't got to that yet for this since it's just a dumb little project. Stilling learning lisp but I am aware of macros and how to use them.
This worked for me a bit ago. Unfortunately I didn't know enough Objective C to really start building a widget toolkit. :-/ https://github.com/TerjeNorderhaug/ecl-iphone-builder/#readme
These guys said they were providing a development platform for Common Lisp on mobile devices: http://wukix.com/mocl 
https://github.com/chicken-mobile/android-chicken &gt;These files will setup a cross compiler toolchain for the use of Chicken Scheme on Android. With the help of the Chicken cross compiler we can build native binaries with csc for Android.
I have "MaximaOnAndroid" installed. I don't know enough about Maxima to easily test how functional it is. It's running ECL.
They have been running very much quiet. I wouldn't count them out.
LME fixed the bug pretty quickly: a little spelunking through the commit logs should show the fix and the etiology of the defect.
I don't get what you mean. I think what I presented is functionally equivalent (module missing restrictions enforced in Haskell by the type system) to data Tree a = Node Tree Tree | Leaf a
 data Tree a = Node Tree Tree | Leaf a That's an Algebraic Data Type. data Lam :: * -&gt; * where Lift :: a -&gt; Lam a Tup :: Lam a -&gt; Lam b -&gt; Lam (a, b) Lam :: (Lam a -&gt; Lam b) -&gt; Lam (a -&gt; b) App :: Lam (a -&gt; b) -&gt; Lam a -&gt; Lam b Fix :: Lam (a -&gt; a) -&gt; Lam a That's a [Generalized Algebraic Data Type](http://en.wikipedia.org/wiki/Generalized_algebraic_data_type#Higher-order_abstract_syntax)
What you describe here is different from your previous post, and I don't think it would be wise to discuss it before rigorously describing when is M a term. I'm not a programming languages theory expert, so I don't think we share enough common background to skip this part. I have read what you described in previous post as: If you can apply list constructor to any collection of objects and get a valid list, you have a unityped language. Now take an object oriented language with all types forming a hierarchy with single root class of Object, and use {} as a list constructor. For any sequence of objects E1, ..., En, {E1, ...., En} would then be a literal denoting a valid object of class List&lt;Eb&gt; where Eb is the least common super class of classes of these objects. And since all hierarchy forms a single tree with Object at its root, Eb defined that way always exists, and is at worst the root class Object. But maybe it's just me. I, for example, don't understand people vehemently arguing that dynamically typed languages are just static languages that are unityped, and can therefore be dismissed, and are not worth discussing. Well, yes, maybe they are, as long as you are only interested in static type analysis. But that's not where applications usually get most of the work done.
I don't think this distinction makes a difference without static type system. Multiple references to this being a "type safe" approach on the page you linked do not seem to contradict such position. What did I miss?
&gt; I'm not a programming languages theory expert, so I don't think we share enough common background to skip this part. I hope you're not implying you think _I_ might be :p &gt; If you can apply list constructor to any collection of objects and get a valid list, you have a unityped language I think you skipped "with defined semantics". With s-exprs, the objects are the terms of the language. In your example, if objects are taken as the terms of a language, and list construction is the only combinator, then the language thus described is unityped (all terms have the same distribution by rule induction). The fact that the objects that represent the terms have types in the "surrounding" language is irrelevant because those types play no role in the combining of terms in the embedded language. &gt; But maybe it's just me... Hm, I suppose I more interested in types than you then. But, at least in idealized conditions, the fact that dynlangs are statically typed with one type is a totally descriptive fact.
Unfortunally, It has bitrotted. I have tried to contact the original author but have not heard back.
That's really frustrating. He was collaborating with another guy (check the fork graph). Have you tried the heads of the branches on both? What kind of errors are coming out? I'd be OK with helping out with testing and running builds to get the project live again, I don't have time to do coding on it at present.
&gt; I think you skipped "with defined semantics". I don't think so. It's all perfectly well defined. Hey, Objective-C has well defined semantics (doesn't it?), and you can't even tell if object of given type will be able to understand certain message, because you can manipulate definitions at runtime. Looking at your current description, what I did miss from your post is assumption that such merge rule would be the **only** one. I didn't mean that to be the only rule. I understood that it is sufficient that it is a valid rule (possibly one of many). Hence the misunderstanding. Otherwise you may be right, although I think this deserves formal proof. &gt; But, at least in idealized conditions, the fact that dynlangs are statically typed with one type is a totally descriptive fact. **Statically**, yes, I agree.
Then again, if this is just about assigning types to constructors, as opposed to what instances of such type look like, it indeed does not seem to make much sense to talk about such construction in an untyped language. I see your point then.
The proof is just rule induction. Take the following s-expr-type language of atoms and lists a Atom ------ (TermIntro) a Term E1 Term ... En Term --------------------- (ListIntro) (E1 ... En) Term Assuming x Term and y Term, if M Term, then its introduced by either TermIntro or ListIntro. 1. **TermIntro** If M = x, then M[x:=y] = y and y Term so M[x:=y] Term. Otherwise, M[x:=y] = M, so M[x:=y] Term anyway. 2. **ListIntro** We have M = (E1 ... EN). By the induction hypothesis, En[x:=y] Term for all the En. Applying ListIntro to E1[x:=y] ... EN[x:=y] we have (E1[x:=y] ... EN[x:=y]) = (E1 ... EN)[x:=y] = M[x:=y] Term. So we have M Term implies M[x:=y] Term. Incidently, you can always add more types if you can add more combinators (until every term has a different type). Just take any two terms with the same distribution, x and y, and add a rule --- (xDistinguisher) F x where F is fresh.
Makes sense. But you can still add types to Lisp, which would then mean that (E1 ... En) is not always a valid term with well defined semantics, right?
How are you thinking of adding types? (static ones, right?) For CL, I doubt anything really clean works out. For example, the standard says the head of a form that is a cons must be a symbol or a lambda expression, so (1 2) isn't given semantics. So 1 and x have different distributions. I was thinking more of Scheme, because all the nodes in a list denote value objects there (modulo special macros). In CL, I think any two forms are interchangeable in a compound form whenever both are used in a position where they are evaluated, so any terms which corresponds to a run-time object with a dynamic type have a single static type. (Of course this probably breaks because of some obscure clause in the standard I don't know about :)
Clisp which is a dialect of commen lisp or clojure depending o. how advanced you think you are
The package mechanism, by design, performs the isolation. There is no reason to duplicate the name in the generic function. Let the user of your package worry about managing their namespace. 
This must be a nasty habit I carried over from years of C programming where it's the provider's responsibility to manually manage the namespace, not the client's.
C does not have anything like Common Lisp's packages or C++'s namespaces, so you as the library developer need to worry about the global namespace. No need in Lisp. 
I thought I'm being clear that this would require changes in the standard (surprise! :D). It's just speculation though. I'm fine without static typing.
Because I pretty much never refer to symbols from another package without using it (or a conduit for it), I tend to make sure that they aren't going to clash with something else I might want to use as well, unless they are in fact the same symbol, of course.
I really dislike names like `my-data-struct-ref` for generic functions: they are very close to the implementation and tend to make little sense when extended. So, at least, find a name that corresponds to what the generic function means rather than how it's implemented. After that, it depends on whether you intend people to use the package or not. I care a lot more that you stick to a single choice than about the choice itself.
If I'm not importing packages into the current namespace (which is the norm 90% of the time), I use shorter names and the fully qualified symbol is what I see in code. It gets really fun when I'd like to reuse certain symbols from the common-lisp package (list +), because the package with the external api needs to not :use the cl package, which means you now get two packages with a sub function.
Some example code: (in-package :dbus) (progn (setf upower_conn (open-connection (make-instance 'iolib.multiplex:event-base) (system-server-addresses))) (authenticate (supported-authentication-mechanisms upower_conn) upower_conn) (hello upower_conn) (invoke-method upower_conn "Introspect" :path "/org/freedesktop/UPower" :destination "org.freedesktop.UPower" :interface "org.freedesktop.DBus.Introspectable")) Edit: Here's perhaps a more useful example (in-package :dbus) (progn (setf upower_conn (open-connection (make-instance 'iolib.multiplex:event-base) (system-server-addresses))) (authenticate (supported-authentication-mechanisms upower_conn) upower_conn) (hello upower_conn) (setf bat0_obj (make-object-from-introspection upower_conn "/org/freedesktop/UPower/devices/battery_BAT0" "org.freedesktop.UPower")) (object-invoke bat0_obj "org.freedesktop.DBus.Properties" "GetAll" "org.freedesktop.UPower.Device")) 
Take a look at [the notify example](https://github.com/death/dbus/blob/master/examples/notify.lisp).
As you ask the question, this doesnt seem to be a Lisp-only problem. So how does everybody else do it? A combination of importing the packages that you use more often and explicitly referencing the packages you use less often. You last suggestion is bullshit, though.
That's just about a list of *all* the complete Lisp books (as opposed to various tutorials). I'd shorten it four books for the novice: 1. Touretzky 2. Seibel 3. Sussman &amp; Abel. (really a comp-sci book that just happens to use Lisp). 4. CLtL.
I've been working on this site for a few months now. I think it's ready for inital public view. Let me know what you think. I'm very glad to take any feedback you have. It's *entirely* open source and githubby, so any patches you have I'm also glad to take! :-)
No. Don't install them via apt-get.
Because of old versions?
&gt;burrito.lisp, cheese.lisp ... Lol, nice
I installed sbcl via pacman, but quicklisp manually. Is there a problem?
Yes, it's certainly a moral problem if you do that... :p But seriously, the version of SBCL is is absurdly antiquated from apt-get as a rule. So you wouldn't want to use it as your regular version. However, I've used it to bootstrap a modern version of SBCL when the sbcl.org binary wouldn't run due to $obscure_static_linking_problem. 
I'm of the firm opinion that it is the package user's place to manage *their* namespace, whether I'm writing in Common Lisp or C++. I rarely import all of the symbols from a particular package: I'd rather have to type a little more for the explicit reminder of where a symbol is coming from, than to wonder six months down the road what the origin of a particular function/macro/variable is. So from your choices: I generally make all references explicit, and only rarely will I import selected symbols. I would never even consider writing wrapper functions: that's silly. When creating a new package if you use a long package name, *please* consider adding some shorter nicknames to make your users's lives (slightly) easier. 
I think I was eating a burrito when I was thinking about example code. 
Does pacman imply something like common-lisp-controller?
The problem with the notify example was that it uses the with-* macros, which, I think, removes the object once it's out of scope. I need(ed) objects that are created "permanently". So I read up on those macros and "unrolled" them to figure out how to generate connections/busses/objects by hand. Most of my confusion has centered around not understanding D-Bus and being too lazy to read all of its documentation, to be honest.
Do people read CLtL straight through? I own the dead-tree version, but mostly just use it as a desk reference (while wondering why I'm not using the HyperSpec instead).
No, the nearest thing is installing libraries through AUR.
The version in wheezy right now, which will be the new stable in another month, is [less than a year old (1.0.57)](http://packages.debian.org/wheezy/lisp/sbcl). I'd hardly call that "absurdly antiquated." I've never had a problem using the version from the repositories. 
Dude,that's awesome! Last time I apt-getted sbcl down, it was 1.0.29. :-) I guess *I'm* the out of date one.
The "best"? Some of these are not really useful to the contemporary Common Lisp programmer. *Lisp Lore - A Guide to Programming the Lisp Machine* is only useful if you're programming a Symbolics Lisp Machine: I used this book in college to get an overview of the school's 3600 in the late 1980s. *Performance and Evaluation of Lisp Systems* is of historical interest, but I'm not sure how useful it would be now-a-days for most programmers. Siebel's *Practical Common Lisp* and Graham's *On Lisp* are the best books, IMHO, to go with. I've never read Touretzky. 
We're watching you, Big Brother...
AFAIK GCL is dead. These days people use ECL for C interop.
Another benefit (to the package user) of using package prefixes rather than :useing a package is that it makes it easy to see exactly how dependent on a package one is. For example, if you want to swap out sxml for cxml, you just need to grep for instances of "s-xml:".
You should probably add an explanation about building from the source and customizing sbcl. Hunchentoot should be run in sbcl with sb-thread option. The binaries at sbcl.org are not always built with this option. Edit: I was burned once by this (the first version I used had sb-threads, the second version no). Since then, I have always built from the source. So I am not sure of the current builds at sbcl.org.
I listed it for use as a reference. I vaguely recall some interesting material in there, but haven't touched my copy for a few years.
[The picture of everything](http://www.mrbill.net/macivory.jpg) that the previous owner (David Betz of XLISP.org) sent. I have another recent picture but it's just the same set of boards and manuals and media. I still have everything in this picture; the orange manual is not Symbolics-specific and is heavy like a phone book - shipping would be cheaper if you just grabbed a PDF version online. If anyone's interested, please message me. The previous person on Reddit that I was talking to about this board set hasn't been on for at least a couple of weeks.
The printed Lisp Machine manual is quite rare, though and a nice collectors item. But I think it is for an earlier Genera release. The printed manual for Genera 8 is much larger and consists of 15+ books. The manuals can be read nicely with Genera on the MacIvory. 
I'll include the printed manual with the lot, if someone is willing to pay for shipping.
The language is not the build system. It needs to know a bit more about abstractions like build operations, systems, subsystems, ... There is not much need to write custom micro-build systems. In Common Lisp usually one uses an existing integrated build-system. An example is ASDF. Sure we all have seen custom micro-build systems - but usually it's better to use an existing one, which plugs then into some other infrastructure.
You might consider [donating](http://www.computerhistory.org) that. E: incorrect link formatting 
Added!
AFAIK the Computer History Museum already has a bunch of Symbolics stuff. In any case, the person who was originally interested in buying it from me has gotten back in touch and it will be going to them.
I absolutely cannot claim to have thought much about build systems, but they have always seemed non-orthogonal to source code organization systems likes namespaces and modules. One feels one is repeating oneself, for instance, when building package definitions and then ASDF definitions, as if a sufficiently clever build system _should_ be able to read one's package defs and infer the appropriate build order and so on. Of course the way CL's packages are split across several files (or rather, are file and build order agnostic, being purely run time groups of symbol ownership information) and do not specify which files define the meaning of which symbols and what the dependencies are between them, it is obvious why this can't be, but I wonder if it still might not be ultimately better to have an integrated package management and build system. Thoughts? In my toy/serious Lisp dialect, Gazelle, modules are the code organization system and they are designed so that all build dependencies are identical to module dependencies. This seems like the easier way to do it, but I can't say I thought it out that clearly. 
Here are some interesting build system links. http://gittup.org/tup/ https://github.com/apenwarr/redo http://industriousone.com/premake http://neilmitchell.blogspot.com/2012/02/four-interesting-build-tools.html Good build systems not only get things compiled predictably, they also let the builder customize things. For example, there can be options for supporting different dependencies, allowing custom install locations, and disabling features that are not desired for whatever reason. Cleaning all traces of an old build, compiling in a pristine environment, running tests, and creating and validating release archives are also quite nice. It is very helpful for developing robust, portable code if the build system supports detecting the build/run environment (especially probing for known workarounds rather than relying on #+magic-symbol) and making conditional changes to the code. Java's package-name ~ file-name convention can be handy for simple cases, but it is far insufficient. I believe Factor has a nice system where it tracks source forms and can automatically recompile when macros change... http://factorcode.org/ Many languages have a build system written in the language itself (Perl's POD, Python's setup.py, etc.). This is a good way to avoid the bootstrap issues by not relying on other tools being installed. 
 (or (gethash word bad) 0) looks like an obsolete idiom. The idea is that (OR X Y Z) returns the first non-nil value. So if the word has been judged bad at least once (gethash word bad) will return a positive integer and (OR (GETHASH ...) ...) will stop there, and return the number. If, on the other hand, the word isn't present in the hash table GETHASH will return NIL. OR will press on to the next item in the list. It is 0. 0 is different from NIL so OR return 0. This is a fairly common situation and Common Lisp's version of GETHASH takes a optional third argument to let the program text specify a value to return if the item is not found in the hash table. Instead of (b (or (gethash word bad) 0)) on expects to see simply (b (gethash word bad 0)) which binds b to the count in the *bad* hashtable (or 0 if the word is brand new) What is going on in (g (* 2 (or (gethash word good) 0)) ? It looks like the number is being multiplied by 2. My guess is that 2 is a fudge factor. You might want to pull it out. In CL it would be (defparameter *fudgefactor* 2 "Tweak up the good, don't know why") and then (g (* *fudgefactor* (gethash word good 0))) Moving on (max low (min high x)) is an idiom for clipping a number x to ensure that it lies between *low* and *high*. More magic numbers that you might wish to pull out as named variables for latter tuning. Notice that the UNLESS is returning a value. Most style guides recommend using UNLESS rarely, for code such as (unless works-already (adjust foo) (tinker-with bar)) That is, to cause side effect, not to return a value. One expects to see (if (&lt; (+ g b) 5) *default-probability* ; too few examples (max low (min high x))) Which ever way the comparison turns out, there will be a number for subsequent code to use. As written, the UNLESS will sometimes return NIL, so you expect calling code to be watching for NIL instead of a number, and to do something about it. Notice the repetition of (min 1 (/ b nbad)) The code is computing the ratio of *b* to *nbad* to get an estimate of the probability of seeing that the word given that the word is bad. (min 1 p) is limiting the probability p to be no more than one. But why is that necessary? I'm guessing that it is fall-out from the fudge factor earlier on. We actually need it in (min 1 (/ g ngood)) because *g* has been doubled in an attempt to tweak the output. I wouldn't have much confidence in the lisp code that you have been given. Does it come with test cases? Can you get it to run at all? Does it pass its own test suite?
It's from here: http://www.paulgraham.com/spam.html
Sorry - the original interested buyer got back in touch with me.
'prod' is the product of the probabilities. Return this divided by prod added to product of the complements of the probilities. (Where the complement of a probability 'p' is '1 - p')
As in a Common Lisp application or an xtlang application? http://extempore.moso.com.au/
The latter, according to the video description
You code in elisp a lot, don't you? Instead of writing your function names as DB-REST-&lt;some_name&gt; simply put them in a package and just name them &lt;some_name&gt; and export them.
Nice :), saw that someone committed some package files and stuff!
I don't think the standard ever discusses "read/print" consistency. 2.3.6 discusses print-read consistency, though.
Good catch. :)
If I wanted to move all "and" elements to the beginning of a list, I would probably iterate over the list and collect two lists, one full of "and" elements and one full of the rest, and then append the two at the end. It isn't very "functional" (except it actually kind of is) and perhaps isn't the fastest method (though I can't think of a much faster method), but it has the benefit of having a zero "tricky to understand" factor. Another method would be to use sort and craft you predicate to rank "and" forms below atoms or whatever. Take note that sort is destructive.
There are a lot of areas where CLtL is more prosaic than the HyperSpec; for instance the material on [branch cuts for transcendental functions](http://www.cs.cmu.edu/Groups/AI/html/cltl/clm/node129.html#SECTION001653000000000000000).
 (let ((x (copy-tree '(or a b c (and d e) f g (and h i))))) (setf (cdr x) (stable-sort (cdr x) (lambda (x y) (and (consp x) (not (consp y)))))) x) edit: changed listp to consp, assuming you will want to consider nil atomic. and here is a recursive version that works to an arbitrary depth: (defun normalize (x) (if (consp x) (cons (car x) (stable-sort (mapcar #'normalize (cdr x)) (lambda (x y) (and (consp x) (not (consp y)))))) x)) 
 (loop for x in (rest form) if (consp x) collect x into conses else collect x into atoms finally (return (cons (first form) (append conses atoms)))) There is a useful function hiding here, PARTITION-LIST. So: ;; can also use multiple-value-call (multiple-value-bind (lhs rhs) (partition-list #'consp (rest form)) (append (list (first form)) lhs rhs)) (defun partition-list (predicate list) (loop for x in list if (funcall predicate x) collect x into lhs else collect x into rhs finally (return (values lhs rhs))))
The drakma-async (on win32) dictates also that you have the OpenSSL runtime for *32* bit (even on a 64-bit machine) installed http://slproweb.com/products/Win32OpenSSL.html 
I like this declarative way you have an upvote, but the solution to the problem is: (let ((input '(or a b c (and d e) f g (and h i)))) (cons (car input) (append (remove-if-not #'listp (rest input)) (remove-if #'listp input)))) 
Ah yes, forgot about the "or". Thanks
Xach, I was looking forward to this since you mentioned your idea to create it some time ago*. Thanks, I've been enjoying it. In your Naggum archive the message-id is a clickable link to the thread hosted on google groups. Are you planning to add that to the Warnock archive? \*My hard drive shows I downloaded usenet-legend and the cll archive and got as far as creating the Warnock database just over a year ago.
This submission has been randomly featured in /r/serendipity, a bot-driven subreddit discovery engine. More here: http://www.reddit.com/r/Serendipity/comments/17w851/repl_gui_for_clojureclr_c_port_of_lisps_clojure/
I might add that to the Warnock one, yeah. It is kind of a slow deal since Google starts blocking requests after a certain number ber day.
The ability to add comments to a particular message would be extremely handy. For example, I'd like to add a working link to [Pragmatic Parsing in Common Lisp](http://home.pipeline.com/~hbaker1/Prag-Parse.html) to the message [Re: LISP parser (lex &amp; yacc) requested](http://xach.com/rpw3/articles/58iv3c$90r%40tokyo.engr.sgi.com.html). Cool nonetheless!
＞scheme is dead lol?
In the meantime, you might be able to do it without sending requests to google. It appears that appending the message-id to "groups.google.com/groups?selm=" gives you a URL to the message in google groups. For instance, Rob's first message has id "3ro9t2$ems@tokyo.engr.sgi.com", and [here is a link to it](http://groups.google.com/groups?selm=3ro9t2$ems@tokyo.engr.sgi.com) in google groups.
I've used that in the past, but I stopped for some reason; I think after a few views it requires a Google login to get past the redirect, or something similar. Maybe it's changed now. Even if it hasn't, it's a decent stopgap solution and I'll look into it.
KMP is in the works.
Yes, this will be in 1.1.5.
As a long time C++ developer, pining for Lisp, I struggle with the same problem Carmack does. I think if there is ever an angle, it might be with Embedded Common Lisp, and to use CL as a scripting language.
The production code I write is all C++. Everything else I write in Common Lisp: utilities, code generators, you name it. Things a saner (?) person would write in Perl or Python I write in Lisp. Because I can. My bosses are awesome that by give me the freedom to do this. You can find the time. 
Either you are in the wrong subreddit, or you need to stop using scheme.
&gt; Embedded Common Lisp This gets brought up frequently (read: every goddamn time) when looking at embedding a language for AI. Most developers, if they are aware of lisp, still think of it as this ancient mystical language and so explaining its strengths is not something easily done. Lisp is much better experienced than explained and every game that embeds python or lua simply builds on the toolchain that provides a counter argument to ever using it. That said, embedding OOP in OOP is still preferable in most cases than Lisp - least of all because of the direct parallels of language constructs but that's just my experience (and opinion perhaps).
Peter Siebel has the right answer: &gt; @ID_AA_Carmack I quit my job in order to spend a year hacking Lisp. Ended up writing a book about it. That worked. http://gigamonkeys.com/book/ https://twitter.com/peterseibel/status/299582995134820353
A big difference for Naughty Dog is that Andy Gavin already had a significant amount of Lisp experience before founding Naughty Dog. They were able to build those tools thanks to that.
Things like CLOS are certainly close to the class/instance/functions dynamic of static languages but the syntax and bindings of a language like python are extremely well supported and a better parallel to the C++ it's being embedded in.
Could you please give an example for code generation with Lisp, or a link where this is shown ? Thanks.
How would being a grad student help him? His time is not limited by getting paid. He already has enough money to last a lifetime. His time is limited by not having enough hours in the day to work on all the projects he wants to.
yes, it was a bit of a joke.
Compilation chapter from SICP, http://mitpress.mit.edu/sicp/full-text/book/book-Z-H-35.html#%_sec_5.5 Although I advise to read the full book, http://mitpress.mit.edu/sicp/ It uses Scheme, but the concepts are similar.
Thanks !
I don't know if it would be useful for John Carmack (apparently I'm the only person in the world that's never heard of him) but by itself the use of C++ is not a problem. It's trivial to embed Chicken Scheme into a C/C++ program: [http://wiki.call-cc.org/man/4/Embedding](http://wiki.call-cc.org/man/4/Embedding) Performance isn't likely to be at the same level as C++, but if you can call a C function, you can call a Scheme function.
Python have its own metaprogramming capabilities. They're just not as powerful as Lisp's macros.
I'm sorry, it wasn't in joke tags. You should follow the HTML6 draft which codifies jokes, sarcasm and several emotions.
You could argue lua is wonderful for that. Data and code are very closely related as well and it has the additional value of being easy to communicate with other languages (in this case, c++) edit: downvoter, refute me.
To this I would add the maturity of the tools in addition to the language: Emacs + SLIME + Common Lisp makes me amazingly productive. While Python and Lua may have similar (but less complete) they do not have the tool maturity, IMHO. 
My bad.
It would be great to add a web based lisp interpreter to those examples
Oh okay thanks.. I an not that reddit-smart
Okay, your site is VERY cool. Did you create that your self? What actually processes the expressions server side? 
I'm still rooting for CLIMACS. Vive McCLIM!
There is not server-side. It is a Common Lisp to Javascript compiler which runs in the browser purely. The code is at https://github.com/davazp/ecmalisp
There is a work to port Emacs itself to GNU Guile. But this misses the point of the article, which misses the point of Emacs. Emacs keybindings are older than CUA keybindings. M-W C-Y is older than Ctrl+C Ctrl+V. I see no reason why Emacs should use other keybinds. Nevertheless, Emacs has CUA support. What we should do ISN'T create another editor with "standard keybindings". We should make people aware of how powerful, useful, and feature-complete Emacs is. Hell, if you're a Lisp programmer, you can EASILY change all the things the author is saying it sucks. You can change even more. Emacs is the best Lisp editor because it is a complete Lisp environment. Until there is an editor in *other* Lisp environment (like CL or Guile), and as feature-complete as Emacs, Emacs is the best out there.
[What?](http://imgur.com/1IrgGRR)
I don't think the Lisp indentation rules used by Emacs are all *that* sophisticated., so I find the conclusion that any Lisp so indented must have been written in Emacs suspect. Also, heresy. 
The Emacs haters do not want a package to be able to change the standard bindings, they want to change the standard bindings. They do not want newbies to have to change the standard bindings, they want the whole current community to change their editing habits to be more welcoming to newbies, so that the newbies do not to have to do anything and can feel right at home like with notepad.exe.
thanks for the clarification! checking it out.
&gt;non-standard keybindings kill me
[Yes](http://www.gnu.org/software/emacs/manual/html_node/emacs/CUA-Bindings.html). It's an unpleasant experience giving up such valuable keys for such infrequently used operations.
What you propose requires taste *and* tact, and these are not traits generally found in programmers. Further, the knee-jerk reaction to call anything unfamiliar and unusual "crap" that many young programmers have, *does* appear to go away after a few years.
And you've missed the point of the article. Emacs is a *huge* blocker to a *new* lisper learning the language. Why should they have to learn the non-standard Emacs UI - yeah okay it predates CUA but CUA is hardly new and Emacs still hasn't switched? That's Emacs' problem. To someone who wants to learn Lisp, Emacs (and SLIME) is a huge hurdle to the point that I agree with the article: Emacs has seriously held back Lisp adoption for decades. 
Light Table looks interesting: shame it doesn't and probably never will support Common Lisp. The problem is that it supports Java and Clozure: the former has plenty of quality IDEs and as a result so has the latter. 
&gt; ridiculously awful help system interface with no obvious way to get back to the buffer you were working on, etc. What? Is this a case of RTFM? 
What he proposes has a solution already: using CUA mode. But he does not want to CUA mode to exist. He wants to change EVERYONE'S workflow to fit his own personal view of what a newbie wants. I'm not a newbie anymore, why should my workflow change? Why should CUA becomes the standard for me? I don't want it.
Look, I think I "got" him: Ok, he thinks Emacs sucks and does not have good arguments for this (if he said something against Emacs Lisp, or absence of threading, or... but no, only "oh, where are my keibindings? Boo-hoo"). But he has a point: why should we be stucked with Emacs if we want to develop Lisp? Why is Emacs the only editor out there that provides good support for Lisp? I really don't know the answer. Probably it's a vicious cycle: nobody that cares about Lisp really cares about a new editor, because they love Emacs (it must be the case of 90% of this subreddit), or they DO care about a new editor, but they don't care about Lisp. And they won't care about Lisp, because the only editor of choice if Emacs. But would it really change if we did a "Sublime Text 2"-clone in Common Lisp or whatever? Would people REALLY migrate to Lisp if we had another text editor? Do they even need a good editor for Ruby or Python? I see lots and lots of people getting into Ruby with Gedit. What does Gedit have for a Ruby beginner? Basically nothing. The beginner will use the terminal and rake. He article misses completely a point: you can simply use any text editor you'd like, and the terminal to fit whatever you want to do. But Emacs is **THAT** good. Yes, Emacs is amazing for Lisp. That's why most of us use it: not because it's the only choice (it's not - there are some that use vim + terminal on IRC and on twitter, as far as I've seen), but because it is the best choice. If there isn't another good environment for Lisp, I don't think it's exactly the community's fault. It's the vicious cycle that I said at the beginning: nobody really cares for another editor having support for Lisp. But if you really do, go ahead, reunite with a bunch of people, and make your own SLIME-like tool for Sublime Text 2 or whatever. If anyone has this project, I don't know how much help they would get, but why not trying?
I don't understand why people act like that's any kind of solution. All that does is change the keybindings for a *minute sliver* of common emacs operations. To suggest that that makes emacs feel like any other CUA app is laughable.
For me, this article really hit home. It's one of the big reasons I have never bothered much with Common Lisp. Not the syntax or anything like that - I love racket - but the CL implementations whose REPLs are near unusable outside of emacs (looking at you SBCL). Make of that what you will. And CUA mode is barely even worth mentioning. That does not make emacs feel like a gtk/kde/mac/windows application. I can't ctrl-n to start a new file, or ctrl-o to open one. I can't delete things with backspace. I can't alt-f to open the file menu... I could go on, but you get the point.
someone wrote a basic OCaml mode for drracket at one point. it shouldn't be impossibly hard to have it use a common lisp back end.
That was the single biggest reason why I gave up on CL and played around with Racket instead.
I agree with you on all points. There are only two points I would like to add. One, Emacs Lisp is not common lisp. This makes it a little harder to understand the structure as it isn't just "lisp all the way down." Second, I think we can do more with lisp than other languages so we should be able to extend emacs into something beyond their expectations. Emacs is a great editor (the thermonuclear option of editors) but it is time to go beyond that into another generation of editors which allow us to solve problems at the speed we can generate them. Emacs is good at editing text, but I think it could be good at allowing us to set up workflows, explore problems, collaborate, graph our code, requirements, etc and far more. What if we had a first order logic display with graphical data and logic flow displays along with our standard text display? The question is not if we can do this, but rather if we can make this accessible to the average developer. For if it is accessible to them then we can use these abilities reflexively. But I agree with your points: no one is going to switch to lisp based on its editor. 
Also of interest if you've ever wondered if any three words in English can contain all letters of the alphabet. 
*Clojure* - Clozure is a real Common Lisp...
You're saying my high performance sports car is holding back the sport of drag racing because newbies need to put on the training wheels for themselves, as the cars don't come with them already attached. 
You base your decision on what programming language you use BASED on ONE TEXT editor experience. Wow. Just fucking wow.
Well, as I said in other post, there is an effort to port Emacs to GNU Guile. Since Guile is MUCH more powerful than Emacs Lisp, I think we'd have better chances to implement your ideas. They seem perfect as part of Org Mode.
I will say that it is a large manual. But that is just because it can do so much more than simpler text editors. I can do much of my days' work in emacs. It's a shell. It's an editor. It's a car wax and a desert topping. The problem is that with great power comes great confusion.
Now all we need is a Scheme called Clo**s**ure and the Lisp trifecta will be complete!
Yes! Typical bearded lisper viking vitriol. This one is going up in the gallery. 
speak for yourself and write in a different tone
Dr. Barsky, good point. I don't speak for anyone but my self. Comment edited to reflect a less generic inclusion. I apologize for the tone of my flames, but damnit, I am getting tired of everyone just standing by and 'professionally' taking this horeshit complaining as if it has any merit. The original post had no merrit. The confirmation bias in here has no merrit. This entire thread is an absurd conversation between users too lazy to choose a bloody text editor that meets their needs and well meaning commenters coddling them the way an enabler coddles an alcoholic. I mean, the choice of common lisp capable editors and entire environments with proper professional ides is substantial enough that the absurdity of complaints in the article and this thread is beyond (Monty) Pythonesque. No, I have not contributed anything at all to the conversation. Damnit, at least I attempted to destroy this thread, as that is all it deserves. Emacs deserves no saving and it deserves no praise. It is what it is for those that like it and nothign to those that don't. Lazy users deserve nothing. 
Your sports cars default settings gives people RSI. When you try and change it to not give you RSI suddenly half the stuff that was amazing about the car is near impossible to use (language modes)
Again. Missing the point. Someone who wants to learn **Common** **Lisp** does **NOT** want to spend the time working out that first, this "god-awful non-standard editor" (Emacs) *could* be changed to work properly and then find out *how* to do that. They'll just walk away.
It's not just 'one', It's pretty much *the* Common Lisp editor. That's the problem. If there were choices of editors (not tied to specific implementations) then Emacs wouldn't be the problem that it is.
If they can't spend 30 minutes on the tutorial, I'm dubious they'd be willing to put any serious effort into learning a dialect of Lisp... 
Personal attacks and profanity. Nice. Emacs is a bad, *terrible*, **awful** text editor. It's like something put together on a Mainframe in the 70s and then never advanced. For text editing Brief was, *is* *still* far superior to Emacs because it's just a text editor. And development on that stopped in the 80s! If it *wasn't* the case (but it is) that every single introductory Common Lisp book claims that Emacs (+SLIME) is not only the best (hahaha!) Common Lisp text editor but the only one then Emacs being as poor as it is wouldn't be a problem. But they do and so Emacs being an awful, non-standard, piece of bloatware is a huge blocker to Common Lisp adoption. Did you notice that in making my arguments I was able to avoid both personal attacks against you nor did I have to resort to profanity? 
So someone who wants to learn Common Lisp has to first learn Emacs and how to enable something that a newbie might reasonably expect to be the default? That's the problem! Now don't get me wrong I am not advocating a CUA default for Emacs. The problem is not with Emacs as such, rather it's the apparent lack of choice when a newbie comes to learn Common Lisp: you come for the language and get lumbered with what feels likely a clunky, bloated, unfamiliar editor that you have to learn. Learn to use an editor for even basic tasks? That's insane! What Common Lisp needs is a decent, implementation independent, editor. Notepad with a REPL would be good enough for a beginner. Add some really basic layout function and that would be good enough for 90% of newbie CL hobbyists. Contrast the learning curve for such an environment against Emacs.
Remap your control key, to capslock... 
When applied to Microsoft's products with such extensive 'feature' lists we describe them as 'Bloatware'. Emacs is the poster child for Bloat. Or if you want to be kinder you might describe it as unfocused.
Mind burp. My CL of choice is Clozure.
The other problem is that despite obtaining 50% more than it's target on Kickstarter (and the Kickstarter benefits offered were pretty miserly) it's already behind schedule.
Sublime Text 2? Hmm. Thank you. Will have to go have a look at that.
I don't *use* lisp/scheme/racket at all. I fooled around with it and watched the SICP lectures. Then I read Teach Yourself Scheme In Bignum Days, and did some simple web programming and generated markov chains of words from the collected works of Mark Twain. Fun! But, yes, Emacs/SLIME were so big hurdles that they made CL very much less accessible than it should be. I get that they can be a productivity boost for an experienced user, but the learning curve just is too high. I felt like an idiot trying to open a file or move a buffer around. And no, you can't really learn or use CL without emacs, since all tutorials and tools are built around it. I never figured out how to run CL without going through emacs. 
I'm not Dr. Barski, btw.
No, it's not.
How about some civil discussion? Emacs is older than most other editors in use. But it was a different time when it was defined. I have a Lisp Machine with one of these old keyboards which had a different layout, which makes it much more usable for Emacs editors. The first SUNs had also similar keyboards. Terminal keyboards looked different - Emacs came from TECO, on ITS - a time sharing system. One of the next Emacs implementations was Multics Emacs - again on a timesharing system. On my Lisp Machine keyboard, control is next to the space bar, then comes meta and then hyper and super. Plus there were several other modifiers / prefix keys. There was a systematic behind what command types sit on what modifiers. On newer keyboard you have less modifiers and Emacs got more modifier-key prefixes (Esc-x, c-c, c-x, ...) which leads to long keychords. If you look at the typical keychords of a Lisp Machine with Zmacs and a Lisp Machine keyboard and then compare that to Emacs on a PC or Mac, then you can see that the keychords are twice or three times as long. I'll give you some examples from FRED / MCL Describe * SLIME: describe symbol C-c C-d C-d * Fred: c-x c-d * Zmacs: m-sh-D Eval * SLIME: Evaluate current expression C-M-x * Fred: ENTER &lt;- this makes huge sense Interrupt * SLIME: Interrupt C-c C-b * FRED: command-, &lt;- standard on the Mac * Zmacs: C-SUSPEND Macroexpand * SLIME: macroexpand-1 C-c RET * FRED: c-m &lt;- M as in Macroexpand * Zmacs: c-sh-M and so on. In many cases the SLIME keychords are alien to the platform, not mnemonic or even overly long. Even amongst EMACS-like editors, SLIME/GNU-Emacs has more difficult keyboard commands. I would make the most important editing operations as short as possible. I do for example a lot of re-indenting, evaluation, interrupting, looking up documentation, describing things, ... I understand why SLIME has longer keychords - it follows the GNU Emacs conventions mostly. The amount of Emacs-like key commands which is supported in newer operating systems is tiny. I have a Mac and it supports some movement commands from Emacs - that's about it. Current user interfaces (MS Windows, Gtik, Mac OS X / Cocoa) don't support the concepts behind the Emacs UI. CUA is a larger standard, which does not only deal with copying and pasting, and it is quite different from Emacs. There totally basic concepts in Emacs which are at odds with current user interfaces. I'll give you a few examples. * Most editors don't have buffers which are not associated with windows. * Most editors now have a different selection/cutting/pasting mechanism. * No Kill ring. * In Emacs the text cursor is always visible. Scrolling in the file moves the cursor. Not so in other editors. * Extended commands are mostly unknown. * Different prefix keys. * Different mapping of commands to keychords. GNU Emacs lives mostly in its own world. What CUA mode for GNU Emacs does is very very limited. But that's not a new topic. Personally I think GNU Emacs has a lot of usability problems, but the GUI version should be good enough to be useful. The GUI version was improved over time with a useful menubar, some direct manipulation, ... What I find more problematic is that somehow we fail to teach these things. Editing text is not trivial. The concepts behind text editing should be a teaching topic. I learned many Emacs things over the years, I have forgotten some others - but I was even reading manuals - I'm not sure if people still read Editor manuals? Lisp user groups, Lisp workshops and Lisp conferences should really put some effort into practical training and giving advice. Something like SLIME is very useful, but it is not trivial and one can't expect that new users learn to use it effectively just so. New users also should expect that learning Lisp and its eco-system takes some time. Lisp offers new ways to work and a different programing perspective. That's also a reason why it survives: it's useful and it's different enough to not be superseded. 
The CUA support does not look very extensive...
It depends on how you define bloat. If bloat means it is slow and feature after feature is added without forethought, then Emacs is not bloated. If bloat means it contains more tools than a swiss-army octo-robot, then yes it is. Still, I think this is another image issue. Emacs has no marketing budget to clear these things up. Anyway Emacs is not an editor. Not really. It's a programming language with built in text editing capability. The difference is subtle, but important. 
It doesn't really make as much sense in lisp, because lisp doesn't really consider the newline character to be very important. For instance, this is syntactically equivalent: (put-str-ln (show (+ 1 2))) (put-str-lin (show (+ 1 2))) When you think about how the syntactic sugar of where $ would terminate, it becomes challenging because the idea of "after" in a lisp is only defined in terms of the ending of an s-expression, which is only defined via the close parentheses. You could certainly create a reader macro that does what you'd like, but it would be stylistically confusing, in my opinion. 
&gt; completely detached from the Common Lisp community They are aware that something like Common Lisp exists, that Emacs comes with some Common Lisp extensions, that it is deprecated to use them, that still many use them, that they want to rewrite some, that there is a CLOS for Emacs, which they don't use, etc. &gt; porting Emacs to Common Lisp I would not expect that. But if they want to add things CL has, it would be great to take it from there and not reinvent things or 'improve' things. &gt; Common Lisp community (at least the open source part of it) seems to be perfectly OK with Emacs being their editor of choice It experimented with editors written in Lisp: see the various experiments with Hemlock. Climacs. Also some others. &gt; Installing SLIME amounts to copy-pasting and evaluating about 5 Lines of Elisp First you need to check it out from some repository where it's not clear if the head is working or not. 
&gt; Given the choice, I would not ever use it. You have a choice. The choices only are not of equal quality. &gt; What I do want is a decent alternative. There are decent alternatives, pay for them. &gt; Even Notepad with a REPL added would do the job perfectly. Whom do you expect to build it for you? The open source community has SLIME, it fits their needs. There are different standard editors for LispWorks, Allegro, CCL, which fit their needs. Why should anybody do the work to meet your special requirements? You sound like a newbie who wants neither to pay nor to learn. Investing effort to make you happy seems to be a waste of time because you'll never give anything back. Pleasing you is nobody's dream job. &gt; say that Emacs SLIME mode is the best and only Common Lisp editor you should be using Because it is so. Other languages like Ruby, Python, Go, etc, do not have specialized editors at all, and still are thriving. If you dont like Emacs+Slime, just use what you would use for Python or Ruby.
The closest thing I can think of are the [-&gt;](http://clojure.github.com/clojure/clojure.core-api.html#clojure.core/-%3e) and [-&gt;&gt;](http://clojure.github.com/clojure/clojure.core-api.html#clojure.core/-%3E%3E) macros from clojure (which can be trivially ported to common lisp). You can use them to thread operations together: CL-USER&gt; (defmacro -&gt; (initial &amp;rest args) (let ((first (first args))) (cond ((null args) initial) ((null (rest args)) `(,(car first) ,initial ,@(rest first))) (:else `(-&gt; (-&gt; ,initial ,first) ,@(rest args)))))) -&gt; CL-USER&gt; (-&gt; 10 (+ 20) (+ 40) (/ 10)) 7 Admittedly all this really does is remove the nesting, but I find it helps reading certain types of expressions. Removing parenthesis doesn't really make too much sense in lisp as /u/fddjr points out.
&gt; And no, you can't really learn or use CL without emacs, since all tutorials and tools are built around it. Frankly, this is total and utter bullshit. A flat out lie. You are perfectly free to use any random text editor under the sun to edit lisp files, like you would use any random text editor to edit bash, C, python or ruby.
I still don't know if that version works. No releases, no checks, ...
You could implement this as a reader macro. 
Have a look at my [cl-2dsyntax](http://lisp.hyperprostor.unas.cz/cl-2dsyntax/) ([the source code](http://lisp.hyperprostor.unas.cz/cl-2dsyntax/cl-2dsyntax.lisp)), with that you can do: !put-str-ln !show !+ 1 2 In the first place I recommend macro out complex nested pieces of code, afterwards the syntactic sugar isn't for the most part even necessary.
 &gt;And, again, Emacs is OLDER than what you call "standard". Its keybinds ARE a standard by themselves. They're the standard on shell, bash, zsh. No one has mentioned that a great chunk of them are also standard on Macs. 
The effort to port Emacs to Guile seems to have stalled, because it wasnt really supported by Emacs, but primarily by Guile, to somehow make Guile more popular by turning Emacs into a "killer app" for Guile. The effort was primarily driven by Google Summer of Code candidates. As I know, nobody is doing anything on Guile-Emacs besides the GSoC efforts. Similarly, last year there was an effort by [Tom Tromey](http://tromey.com/blog/?p=709) not to reimplement Elisp like the Guile guys want, but to rewrite Emacs' C parts completely in Common Lisp. Since there were no updates for a year now, I guess that this effort also was abandoned. For me, both of these efforts do seem to be neither desired nor supported by Emacs developers and the emacs community, but by Common Lisp and Guile developers. Their primary goal doesnt seem to just improve Emacs, but to make the target language more popular by tying Emacs to it and then riding on Emacs popularity. Emacs developers, on the other hand, seem to not be interested in completely rewriting Emacs in another language and completely replacing Elisp, but in slowly improving Elisp itself, since this allows for more incremental and steady development.
&gt; The effort to port Emacs to Guile seems to have stalled, because it wasnt really supported by Emacs, but primarily by Guile, to somehow make Guile more popular by turning Emacs into a "killer app" for Guile. This makes sense, but still, Guile is superior to Elisp in lots of ways. &gt; As I know, nobody is doing anything on Guile-Emacs besides the GSoC efforts. Yes, somebody is. They mention it every once in a while in FreeNode. &gt; For me, both of these efforts do seem to be neither desired nor supported by Emacs developers and the emacs community, but by Common Lisp and Guile developers. Again, go to #emacs on FreeNode. Some people seem honestly excited about this. &gt; but in slowly improving Elisp itself, since this allows for more incremental and steady development. I have less hope on this. Not that Elisp isn't improving, it really is (lexical scoping was "recently" added, for instance). But Elisp has a too old design, and sometimes it'll get too difficult to make it actually improve. See the problem they're STILL facing with multithread support: some members in the community don't even expect it to ever work. I think that porting it to a superior environment, such is Guile, is much better than just trying to improve a language that is based on some absurd design choices. Come on, even having lexical binding, dynamic binding is STILL the default, EVEN with the "let" syntax (you have to use "lexical-let" to actually use lexical binding). And we can't simply change that. Lots of packages use it.
 &gt; Their primary goal doesnt seem to just improve Emacs, but to make the target language more popular by tying Emacs to it and then riding on Emacs popularity. This can't be right, since we know it's Emacs that is holding Lisp back...
I am not involved in anything of this, so I'm not advocating that they stay with Elisp. This is just the feeling I got after reading the different mailing lists over time. I personally would prefer if they (GNU) gave up Guile completely, because Scheme in general is a dead end. They have been investing massive effort into Guile during the last 20 years and have attracted no users. Even many GNU projects refuse to use guile and rather go with perl, python, etc. My guess is that the main reason for this is that with Scheme/Guile, they for example still try to enforce stupid theological scheme dogmas like "dont iterate, recurse", "() is not equal to false", "dont use defmacro, user our hygienic macros", "dont use keyword arguments, RMS doesnt like them", etc. Elisp is in spirit much more closely related to common lisp than to scheme, and the Emacs and Common Lisp ecosystems would profit much more from a merger than Emacs and Guile would. But since the GNU project has given up on Common Lisp, because of the conflicts RMS had with Common Lisp companies back in the 80s, that merger seems to be politically very unlikely.
Is mocl dead or what? Give us a `(hello-world)` for Android + iOS + WP.
Mono/Xamarin blows. Nonfree dev tool? Yeah no.
&gt; K&amp;R doesnt explain how to use notepad.exe The problem was the opposite; there was so much magic standing in the way of understanding what was going on.
I think the issue of Guile vs Perl, Python, etc. is much less about Scheme vs CL than it is about Lisp-syntax vs ALGOL-syntax. The average programmer doesn't like Lisp.
Why would it need to be a macro rather than a function? Functions compose better than macros (you can pass them as arguments to higher-order functions, etc.).
By the way, the idiomatic way to write that in Haskell would be putStrLn . show $ [[1, 2], [3, 4, 5], [6]] The `$` operator is simply function application. It means "take the function to the left and apply it to the argument to the right." CL already has this function -- it is called `funcall`. You would do something like (funcall (compose #'putStrLn #'show) '((1 2) (3 4 5) (6)))
I'll let you in on a well-kept secret. Haskell only assigns syntactic meaning to whitespace if you don't use curly braces and semicolons.
My haskell is super rusty, but I always thought the $ operator was a nice way to remove the need for parens to take care of precedence: div 10 (2 + 4 - 1) can become div 10 $ 2 + 4 - 1 which would be different than div 10 2 + 4 - 1 It seemed like syntactic sugar to me, because it says "hey, the whole right side of this operator is treated like one expression." But in order to say that, we have to say "where does the right side end?" In this example, the right side ends at the new line, though I suppose it could end at some other expression terminating character. The problem with adding this kind of operator to CL in terms of a reader macro would be defining when the expression sitting on the right side of the $ operator should syntactically end. Though I guess I'm missing something because I don't understand the subtle uses of $. I don't see, if $'s purpose is to remove parentheses where precedence if visually ambiguous, where the right parens would go as a syntactic rule, if not related to the new line.
Do you know how absurd that sounds to most people? Use this text editor with archaic keybindings that are alien to you, and to make it easier remap capslock to the control key. I am not saying it is absurd, but try and look at it from an outside perspective.
Those suggesting regular macros are kind of missing the point. A regular macro will not omit the need to close the expression with a right parentheses. That is, it won't change the number of parentheses. The $ is an operator to do [infix function application](http://www.haskell.org/pipermail/beginners/2009-January/000770.html). The syntax would omit some parentheses and make editing easier in some cases. However, with paredit in Emacs, the extra parens are no hinderance for me. In Mathematica, however, I use the same kind of operator (@) a lot to avoid trying to find where I need to add the closing bracket (f@g@x is f[g[x]]).
In this case, I think it's best to generalize the question and then answer that. Hence: Question: Most languages significantly cut down on parentheses by using infix syntax. Is infix used in Lisp? Answer: Generally not. There are a number of reasons why but the best way to understand is probably by osmosis. Just use Lisp for a while. It's not guaranteed that you'll grow to love consistent prefix syntax but it's pretty certain that you'll see why Lispers don't bother with infix. Edit: kqr's response is also very good for the ($) specific part of your question. In Lisp, use funcall.
You were complaing that the default(s) may give one RSI. I provided you a simple solution, that more likely than not, helps prevent "Emacs Pinky". That being said, besides the lack of a "proper" control and the prominence of the capslock (both of which is to no fault of Emacs), I have been extremely satisfied with the default bindings. If you mean what I believe you are implying, that most of Emacs' bindings -- after long-term use, increases ones chance of RSI, do you have any numbers behind this or is this just pure speculation?
Also, you state it as archaic for the simple fact you are not used to Emacs and related terminology. Would it be so foreign if that's what you learned on?
Somehow this remark is always funnier when it's Simon Peyton Jones making it.
It's just a low precedence infix operator. It binds more loosely than the arithmetic operators (and pretty much anything else), so it "grabs stuff" until the end of the expression.
The second is correct.
GOO. I haven't used it for anything useful: the implementation is clunky, with very verbose backtraces and useless error messages. But the language is very beautiful. It would make for a perfect kernel language for Dylan, or another CLOSy Lisp. http://www.eecs.berkeley.edu/~jrb/goo/ 
Neither, but the second is closer: I is still part of the complete list, not of the "sublist" starting with E.
second is almost Correct This is your main list. (some_list, D, some_other_list, I) 
Syntactic sugar usually refers to syntax built into the language. The `$` operator is not syntax, it is a "user-defined" operator just like any other. You could implement it in two lines of Haskell code if it didn't exist already. This is how it is actually defined in the standard library: infixr 0 $ ($) :: (a -&gt; b) -&gt; a -&gt; b f $ x = f x and the type signature on line 2 is not strictly necessary. The compiler can figure that out by itself.
I don't know: enough that I don't have to think when editing, so the basic cursor movement stuff, anyway. C-k and C-y work. Also, of course, because macs don't use the same bindings as Windows and its clones in the first place (the bindings don't use control but whatever the special apple key is called), emacs can happily support both sets concurrently on a mac.
Clojure for doing quick or serious stuff for clients, CL when I need something that runs fast or when I need to quickly setup some project (thanks to awesome quicklisp) and tinyscheme when I need to add scripting ability. Other than that, I also prefer newLISP for making CGI-enabled sites on shared hosts, where you can't be assured what language/version/package will be installed. Single binary with huge number of functions and features saved me a couple of times.
I find the best way to do this is to get the system do do it for you: write a function such as this, for instance (defun naively-print-conses (thing) (typecase thing (cons (format t "(") (naively-print-conses (car thing)) (format t " . ") (naively-print-conses (cdr thing)) (format t ")")) (t (format t "~S" thing))) thing)
I use CL (CCL and SBCL) for most things. I was big into Clojure in a previous job where we were in a strict Java ecosystem (and ABCL wasn't as mature as it is now.) I haven't looked at the others, and haven't used Scheme in anger since I was in college many many moons ago. 
kinda like this? [try 3](http://i.imgur.com/wPfQiw3.jpg)
[GNU Guile](http://www.gnu.org/software/guile/) is great for an embedded Scheme.
Here's [Andy Wingo's (GNU Guile hacker) guide to Scheme implementations](http://wingolog.org/archives/2013/01/07/an-opinionated-guide-to-scheme-implementations). I'm constantly torn whether to use clojure or Racket for small toy projects, but I end up using clojure because of some Java library. I'd say that both are extremely practical and modern Lisps. I have used EmacsLisp, it's ridiculously easy to get started (if you know your way around emacs), but haven't done anything practical with it.
CCL. It supports threads well enough on Windows to run Hunchentoot.
What's wrong with my post? Why is it downvoted, whereas it's an exhibition of what [/u/shizzy0](http://www.reddit.com/r/lisp/comments/18b6hf/anything_like_the_dollar_operator_in_a_lisp/c8d8wt3) mentioned -- a reader macro?
It is not much if you naïvely count bindings: it is actually quite a lot if you count weighted bindings, which is the interesting thing to count. In particular it's enough that if you are just, for instance, editing some text in a textbox, as I am now, you can more-or-less just not think about it and let your emacs muscle-memory do the work for you (if you have that muscle-memory, of course). In fact the mac is an existence proof that it's perfectly possible to design a system where CUA-variant bindings (ie the Apple version of CUA, whatever that is called) can completely comfortably exist with Emacs's native bindings – for instance, using Emacs on my Mac (with no special bindings set up, except pending delete mode I think) the normal copy/cut/paste bindings work as they do for any other mac application, and as best I can tell most of the more fancy mac bindings work the way you would expect as well (cursor keys including the various function+key variants, cmd-Q to quit and so on). I'm not the right person to answer as to whether that makes Emacs on the Mac behave the way a person who expects mac bindings expects. I suspect this (other than, obviously, being "here's another reason I can't use Lisp that I just made up") is a generational/experience thing: learning new keybindings was just something you had to do when I started using computers, and it's never been a big deal. And in the jobs I mostly do now you are just expected to switch between multiple sets of bindings (vi, Windows, some weird mainframe thing; and optionally the mac, and emacs running on any of the platforms) – people just cope with this. If you're 18 and have only ever used Windows or something which has copied its bindings (pretty much any Linux GUI I think), and have never needed to edit stuff in a terminal on a *nix machine, then it probably seems different to you.
http://www.secureoutcomes.net/Employment.html
Just for the record, any of my posts that appear as [deleted] were NOT deleted by me. Someone else (or scritp) had a hand in that . I stand by my posts and opinion of those that are too lazy to chooze a text editor from a huge set of options and too dumb to realize that asking others to change for you and to code shit for you is just rude and plain wrong. I would never hide behind [delete], that is a cowards way out.
Why do you say that? 
Yeah, I was last year editing key bindings on the Lisp Machine to be able to use the Lisp Machine keyboard with my Symbolics emulator.
You're Rainer Joswig, right? Maybe I'm entirely incorrect and embarrassing myself.
Because I think Lisp is a toolsmith's language. Specifically it is a toolkit for building languages.
So much wrong in the responses here, it makes me sad. The correct answer is: --&gt;+---------------&gt;+--&gt;+---------------&gt;+--&gt;NIL | | | | +--&gt;+--&gt;+--&gt;NIL D +--&gt;+--&gt;+--&gt;NIL I | | | | | | A B C E F +---+--&gt;NIL | | G H 
You can't write a function that does exactly what lispm wrote, because `show` and `put-str-ln` would be evaluated normally, which the first element in a combination is not: in `(show (+ 1 2))`, given that the first element `show` is a symbol, the system looks for a function to call in the function cell of the symbol; so it would work in Scheme, but not in Common Lisp. In CL you would need to write ($ (+ 1 2) #'show #'put-str-ln) Anyway, I'm not sure if it would be *that* useful to pass `$` as an argument to a higher-order function, especially as a variadic function; and as a function of two arguments, it's just `funcall` with arguments switched around.
I can't parse this. But macros. More generally, if you think that constructing languages is as easy in these other languages as it is in Lisp, *why write Lisp*? [Edit, elaborated]
Lisp uses parens and has almost no infixes. Therefore, some find it not readable. There are projects like Dylan, and it is possible to define infix notation using reader macros, and still many people prefer S-expressions. Trying to suggest Lispers a way to omit parentheses is like trying to suggest Haskellers a way to omit monads. In the end, these languages influenced the software world, but they are still cutting-edge, and will probably stay. They should keep their philosophy.
This seems relevant: [Rob Warnock: Emacs is NOT required to hack Lisp](http://xach.com/rpw3/articles/BJqdnd9R65ee3qDbnZ2dnUVZ_vGinZ2d%40speakeasy.net.html)
I write Lisp because it is the most flexible and usable language that I have encountered. The syntax and most[1] of the semantics just "work together". I have never really bought the idea that writing a new function/macro can (usually) be called "adding to the Lisp language". LOOP-esque macros come the closest that I've seen. But if you look at a codebase in other languages that is aggressively m4'd/macrod/frameworked up, you will not per se be able to read it, any more than you could read and reason about some other super-exotic macro. Rephrased, I don't build a new language in my code writing processes, I build abstractions suitable to the problem domain; so do other software writers. Lisp just happens to be OK with combined and clever abstractions more than many other languages. [1] I have my list of complaints, tyvm. :-)
I think you've just agreed with me: 'aggressively m4'd'.
I don't know why you are downvoted so much. Emacs is my primary editor and I love SLIME, but I acknowledge that the current situation is not very beginner-friendly: if you want to try CL you must realistically also learn Emacs. ("Realistically" as in "if you want to stay mainstream"). I did it, but not everyone wants necessarily to do that. Or course, all this matters only if one is concerned with increasing popularity of CL.
Can you elaborate on how "scheme in-general is a dead end"?
&gt; and haven't used Scheme in anger since :( I rather like Scheme, I think it's much more consistent than Common Lisp. Chicken Scheme in particular is wonderfully practical, shipping with both an interpreter and compiler.
To be clear, in Haskell, `$` is not infix. Backticks are used for infix: fizzBuzz n = case n `mod` 15 of ... What `$` does is save you from writing parentheses when you want to apply a function to a bunch of code that takes up the rest of the line. putStrLn $ really long expression with several function calls that would be nested parentheses otherwise
I used Scheme a lot in college --- I maintained both the MIT Scheme and T installation at my school. But for my work now the combination of a Unicode enabled Common Lisp with the Quicklisp package manager is unbeatable. 
&gt; It would make for a perfect kernel language for Dylan Given that Jonathan Bachrach worked on Harlequin Dylan, it's not a surprise. :-) 
 (putStrLn (++ "Bob ended with " (show endBob) " in his account.")) Or am I missing something? And yeah no, the composition is better in every way in the example you described. One of many reasons is that it can be lifted verbatim into a separate definition, yielding whatever it's called when you can replace names with their definitions. Equational reasoning, perhaps. And better is idiomatic. Edit: I'm sorry if I sound like an arse. I've had a bad day and my politeness sensor is a little clouded.
In Lisp it would, yeah.
In Haskell you would use `$`, in Lisp you wouldn't need it since the concatenation function is n-ary\*. You have to view the language as a whole, and not just bits of it. That's because languages have completely different approaches to problems. ---- \* Although in Haskell, too, you always have concat ["Bob ended with ", show endBob, " in his account."] which is almost pretend n-ary in some sense, but it's not as idiomatic in that case, I think.
I suggest that you also follow the directions at http://lispjobs.wordpress.com/about/ , because their postings are included in http://planet.lisp.org/ .
This looks awesome, code is very well documented, though I much prefer extensive examples than reading through comments in source code.
Very nice! I would move the "Embed" section below the table of contents, or even move it to a separate page completely. The content is way more important and should be right up there. Navigation really needs to be improved. For one, there's no way to navigate from one page to the next one. When I'm done with `car` I want to move on to `cdr` directly, without having to go back to the index. The fact that all code snippets submit a form to `/talk/` makes navigation even worse. Please do not navigate away from the individual page, but instead include that "talk" functionality on the page directly. I hope this feedback helps!
Cool! ABCL's java interop still looks very low level and requires one to write a lot of interface code. Are there any attempts to make a higher level abstraction over it to make interfacing (relatively) easier and transparent?
&gt;Installing SLIME amounts to copy-pasting and evaluating about 5 Lines of Elisp. With Quicklisp, it is even easier now a days.
&gt;Emacs developers, on the other hand, seem to not be interested in completely rewriting Emacs in another language and completely replacing Elisp Why would they do that? I am amazed some people expect Emacs devs to undertake such a monumental task because they think it would be cool. ELisp works, warts and all. 
Yes. (ql:quickload :infix-dollar-reader) (syntax:use-syntax :infix-dollar) (= (+ 1 2 $ * 3 4 $ + 5 6) (+ 1 2 (* 3 4 (+ 5 6)))) ; =&gt; T Implementation is as below; (defun infix-dollar-reader (stream char) (declare (ignore char)) (let* ((lp-reader (get-macro-character #\()) (entity (funcall lp-reader stream #\()) ) (unread-char #\) stream) entity )) 
I plan examples, too. It's worth noting that folio2 is not released; it's a work in progress. If I'd known it would get as much attention as it has, I wouldn't have made the repo public until it was closer to done.
regarding repl in sbcl see [linedit](http://common-lisp.net/project/linedit/) though you may not like it because the commands are emacs-like.
IIRC sbcl gave me half a page of errors and a full stack trace every time I breathed incorrectly. I can't be bothered with common lisp really, racket just works
I'm a complete newbie in Common Lisp and I don't have this kind of problems you're describing. Maybe you're just a lazy-learner.
Ninja edit: are you still only looking for in-house employees, or are you willing to entertain remote employees? That was the one sticking point when I interviewed there two years ago.
ABCL will run on Android in interpreted mode with a trivial patch which removes the Java Beans support. Getting a compiler which targets Dalvik will take a bit of work. Working better on Android is a goal for abcl-1.2.0 (and beyond).
Please, no. Publishing early and often is the right thing to do. Even if it's not even close to "released". Just make sure the project's documentation doesn't "accidentally misrepresent" its capabilities by talking of planned capabilities as if they were done...
You can also use husk-scheme and it's FFI to haskell.
&gt;Where do you find ABCL's java interop lacking? It could just be documentation and helpful tutorials that is lacking. For example your example of JSS usage is exactly the kind of thing I was looking for. Anytime I went looking for info, I saw the same samples using jclass, jmethod etc. which seemed like you had to write a lot of boilerplate interface code to do anything. Some small examples with idiomatic ABCL-&gt;Java intefacing would be very helpful in getting over the initial hump. (Even a Fahrenheit &lt;--&gt; Celsius converter using Swing would do)
There's a certain stage, early in the development of something, where scrutiny from others is the opposite of helpful to me. It's like I'm writing a story and someone is leaning over my shoulder, poking the screen with their fingers to point out typos. That's not helpful. I know there are going to be typos, and I'll fix them. But I'm writing down ideas. If I'm paying attention to typos, I'm not thinking the ideas through, and that's even more true if I'm paying attention to someone leaning over my shoulder to poke at my screen. I'll make stuff public when doing so will not interfere with my ability to get it done. It would be perverse to do otherwise. There's no point in making something public at a stage where doing so will interfere with my ability to work on it. 
Or, to put it in terms of the Haskell Standard Prelude: infixr 0 $ f $ x = f x The 0 is the precedence level. Precedence levels range from 0 to 9 with 0 being the weakest.
Clicking "Tell me" on any of the code snippets gives me a Django error with the following message: "CSRF verification failed. Request aborted." (I think the issue might be that I have cookies turned off)
I'm unconvinced by these. Writing a cons-tree walker is so easy that it seems very odd to want to abuse subst-if this way: (defun map-tree (fn node) (funcall fn node) (unless (atom node) (map-tree fn (car node)) (map-tree fn (cdr node))) node) for instance. It's even not really hard to write a general graph walker: (defun map-graph (fn tree &amp;key (only-unique-conses t)) (let ((occurs-table (make-hash-table :test #'eq))) (declare (dynamic-extent occurs-table)) (labels ((walk (node) (typecase node (cons (unless (gethash node occurs-table) (setf (gethash node occurs-table) t) (funcall fn node) (walk (car node)) (walk (cdr node)))) (t (if only-unique-conses (funcall fn node) (unless (gethash node occurs-table) (setf (gethash node occurs-table) t) (funcall fn node))))))) (walk tree) tree)))
Rob uses terms like "gross abuse", "lazy", "unusual", and "perverted". I just thought it was cute.
Why?
As far as a text editor, you can use anything you're used to (notepad, nano, vim, emacs, eclipse, etc etc). Lisp files are just text, and you can edit them as such. Many people here will recommend Emacs, but it can be tricky to learn if you're just starting out, so use whatever text editor you have experience with and later on you can use an editor that integrates with the language better (if you want). Once you've got code in a file you'd like to run, from inside CLISP you can do: `(load "/path/to/lisp/file")` Which will load and interpret the file. Any lisp code you have in that file will be run. 
Is it a compiler that you want? Or a program which takes `.lisp` files and turns them into an executable binary?
There are more complicated options out there, but using [SBCL's --script option](http://www.sbcl.org/manual/Shebang-Scripts.html) is a pretty nice way to treat lisp files as one file executables
It's not my preferred approach, but it sounds like you're looking for something like Lispworks. Google it to find out if its what you need.
I wish someone had told me this when I first tried learning lisp. I think OP is confusing a compiler for an IDE.
OMG THIS IS GLORIOUS
Ok, first let's elucidate some things. A compiler is a tool that transforms text into a executable binary. Only that. It can be a command line tool, such as GNU CLISP and SBCL. You edit the text on a text editor, such as notepad, nano, vim, Emacs, gedit, etc. Some editors have tools to communicate directly with the compiler. That's what Emacs' SLIME do. There are complete environments that provide a compiler, a text editor, a debugger, and other tools, all in one. This kind of environment is called "IDE". Eclipse, for instance, is an IDE. Visual Studio, too. Common Lisp has some IDE's, but there is no free IDE for it such as Visual Studio or Eclipse. The nearest you'll have is Emacs with SLIME. Emacs is a powerful text editor, powered itself by a Lisp dialect (and you can customize it however you want using this dialect, called Emacs Lisp). But it is so powerful that you'll need time to learn it. Its keybinds are a bit different from the ones you are used to. But I seriously recommend you to learn Emacs. It's goddamn good. :)
I think that there is a need for a guide explaining not Lisp the language, but this kind of "practical" things. So I am writing one. I will post it here as soon as it is ready.
http://www.gigamonkeys.com/book/
Thanks for the encouragement (/s), but PCL is *not* the answer to everything.
That's a strawman argument. Nobody said that PCL is the answer to everything. But it describes LOAD and other stuff to be used in the REPL. http://www.gigamonkeys.com/book/lather-rinse-repeat-a-tour-of-the-repl.html 
PCL is indeed an excellent book, but there are a lot of things that are not mentioned there; I am not referring to LOAD or COMPILE, of course, but e.g. how to install SLIME, how to use Quicklisp, where to look for information, and so on. All these things *can* be found online, but with a certain amount a work that, in my opinion, is an unneeded impedance to approaching CL.
So what? Would you rather him not write that guide?
Completely agree; so I wrote http://articulate-lisp.com/
There are already lots of guides. Just collaborate and improve the existing ones instead of add another one. Example: http://articulate-lisp.com 
I would recommend Clozure CL. it has a precise GC and concurrent threads. Its authors and maintainers have a lot Mac OS knowhow. 
My wisdom would be to submit the bug to SBCL developers. And as lispm says, CCL is liable to work quite well.
Please contact Jack Harper, JHarper@SecureOutcomes.net and he will talk about it.
Yes, this implies shared hosts with shell support where I simply uploaded newlisp binary, since the binary depends on small number of shared libraries. Scripts are running as plain cgi scripts (started by web server) and there is no need for using additional server (contrary to CL). newLISP starts up really fast, so using cgi makes almost zero overhead. The best of all, scripts has threading support (thanks to 'spawn') so I'm able to do a bunch of stuff in a single run.
I have downloaded this and will give it a try. Thanks for the recommendation. Seems far more sane, the code to do the same thing is about 1/3 the size if that is any indicator.
I've used run-shell-command a ton in ACL and it's never once crashed.
I think you'll need to explain your question better. As I understand you, you're asking if you can use lists and atoms in a lisp program. The answer to that is yes, but seems like such an obvious answer to me that I think it's not what you meant.
Are you sure you are not just leaking file descriptors?
It still shouldn't crash. No matter what.
No, it shouldn't, obviously. But it's possible that, if it does crash because of file descriptor leakage (both leaked fds and buffered-output deadlocks are really common problems when running subprocesses, and not just in Lisp), then preventing the fd leak will prevent the crash. Obviously the SBCL people still need to do some work to prevent the crash in the first place, but this would make the application work.
so you would say that you follow the idea behind the article [here](http://cybertiggyr.com/lc/) and compile/ship newLISP binaries/libraries? btw, you add functionality, compile, and distribute a new binary? or did you mean that newLISP comes with enough functionality built in that its feature complete for your needs, or that your scripts reference libraries that you ship alongside the newLISP binary?
If you have any experience with Win32 programming itself, ClozureCL comes with definitions for using a large part of Win32.
That's not what a compiler is.
SBCL is a very good implementation that is most actively maintained on 64-bit Linux. On other platforms it may have bugs that don't get a lot of attention. I use SBCL on 64-bit Linux and am very happy with it. I run external programs about 10,000 times a day without any crashes or other issues. It just keeps chugging away. http://wigflip.com/ is one of my SBCL-powered sites.
I think its just because its a neglected platform. Exact same code works flawlessly on 64-bit linux. Either way everything is in order on all platforms with CCL so I think I shall stick with that.
CAPI looks great, but isn't it restricted to LispWorks?
Give [CommonQt](http://common-lisp.net/project/commonqt/) a try in Quicklisp it's just named *qt*, but I don't know if it installs every dependecies. I've already set up that on Windows and I don't remember.
Information retrieval, NLP, text analytics, query-log analysis, data munging, thesaurus construction. I do all kinds of things in Common Lisp, such as * a package to parse Valgrind DHAT traces and allow various kinds of filters and queries to be made against the trace. * a package to read data in NISO 739.2 / ISO 2709 (MARC) and conduct on-the-fly queries/conversions on them. * a little program to run `objdump` on a bunch of files and summarize the RO data sizes for them. * a program to generate (C++) test cases from datafiles describing the tests. Are these things that couldn't be done in another language? Some could be. But I'm very productive in Lisp and the ability to work interactively in the REPL is a huge win. 
Yes. 
Very sure. It sometimes crashes on the first call, which suggests it is not really my fault. The errors are also always floating point related and I am doing zero floating point arithmetic anywhere in any of my programs, internal or external. I pass a string as an argument, and a string as an istream.
ltk is a very usable tk wrapper.
I guess it is. Damn.. I just checked the licensing prices for LW and it's not exactly cheap. http://www.lispworks.com/buy/prices-1c.html It's too bad, because I think they'd see a real surge of interest from hobbyists if they loosened it up. Sure, there's always the Personal Edition, but the built-in limitations kinda kill the fun and hobble the experience. Oh well.. 
Hmm.. it does look nice: http://peter-herth.de/ltk/ltk-osx.png http://peter-herth.de/ltk/index.html 
Oh, one more idea. I don't know your constraints, but you could try Seesaw on Clojure. It's a Swing wrapper.
Well, it's not necessarily about Windows or a Windows thing per se, but hobbyist programming on PCs has been a thing ever since Commodore shipped the VIC-20. And these days, the strongest plays for budding hobbyists and neophytes still comes from Microsoft. [[1](http://msdn.microsoft.com/en-us/centrum-xna.aspx)][[2](http://www.microsoft.com/visualstudio/eng/products/visual-studio-express-products)][[3](http://msdn.microsoft.com/en-us/beginner/ff384239.aspx)] Beyond that, there's an army of programmers out there like me who program in their day job, and look for ways to have fun programming again in their off hours because they are bored stiff with their day to day languages. Ideally, the fun stuff should be something powerful, productive, and give them ways to stretch and learn. Ideally, it should be something they would have a chance to use on the job someday. The way I see it, LispWorks (and Franz for that matter) have everything the hobbyist market would need. All they lack is presentation, outreach, and availability. Sure, any dedicated hobbyist could reap nearly all the rewards of programming in Lisp without a nice little on-ramp like that, but if it's too much work, then most aren't going to bother because that's too much like their day job. And if it's too much like real work, then it's beyond the capability of most neophytes as well. Either way, both groups will have their imagination captured by something else. When it comes right down to it, wouldn't it be great if the next generation of programmers were riding a Lisp wave for once instead of something like RoR? (Nothing against Ruby here, but it's mostly a one trick pony where CL is anything but.)
While I'm at it, if you use Emacs and SLIME to edit Common Lisp code, you might find it helpful to use autocomplete, available at http://cx4a.org/software/auto-complete/ It helps me a lot. Unlike the convention for mutable globals surrounded by "earmuffs" (e.g. *foo*), It's conventional that Lisp constants are surrounded by plus signs (e.g. +foo+), but not everybody follows the convention. They really should, so that it's obvious throughout the code whether or not it's a constant or a plain variable. Also, since in the ABCL example all the Java specific type names are defined as Lisp constants, as soon as you start typing + and a couple letters for the constant name, the autocomplete only shows up with the constants, filtering out a lot of the noise so that it's easy to type in Java types quickly. Autocomplete also makes it easier to use packages like JSS without having to dig through the PDF docs too often.
It would be great if you could set up a reproducible bug report for the SBCL maintainers.
I think [joxa](http://joxa.org/) is worth mentioning in this context. It is a lisp based on the ErlangVM except that it is a Lisp-1 like Clojure and Scheme instead of a Lisp-2 like Common-Lisp and LFE. It is also inspired by Clojure, though a distinct language which I found it very clean, and tidy. **EDIT:** Here is a list of differences between Joxa and LFE written by the author of Joxa. http://blog.ericbmerritt.com/2012/02/21/differences-between-joxa-and-lfe.html
Anyone done anything serious in LFE or Joxa? I'm watching LFE for some time and I'm planning to pair it with Scheme/CL at some pint: LFE as backend and Scheme/CL in front. How it compares to plain erlang like memory usage, speed and etc?
I don't use LFE for anything, but the creator rvirding tends to hang out in #erlang/#erlounge on freenode, and he's quite the friendly guy. He may have kept track of some people who use LFE, and be able to answer some of your other questions.
Common Lisp is a standard, yes but it is not *the* standard, there is also a bunch of Scheme ones, and even the implementations within CL are diverging as the standard is afaik frozen. Different problem domains require for different languages features, so there can't be a *lisp to rule them all* and a thrive for simplicity at the same time. I prefer the thrive for simplicity, I also prefer not being afraid of change and pragmatic solutions that get abolished once better solutions arise. When you combine minimalism with the willingness to adapt you certainly won't end up with "random implementations", you'll end up with concise ones that solve the problem domain well. A real example for a random implementation would be CL, it was designed to fit all the existing lisps and make everybody happy, so what feature got in and what didn't was merely a matter of who got his own way, and in my opinion that is not a price worth paying for cross dialect code exchange. Take a look at Clojure, it broke with every lisp so far and achieved the popularity at which CL has stagnated for decades in a few years.
It's ridiculous how hard it is to search for "range()" functions for a given language. Most search results describe the MIN_INT ... MAX_INT range, not helpful at all. Thanks to jlf on #emacs: (number-sequence FROM &amp;optional TO INC)
Common Lisp will die because current CLers are not willing to move away from the (ancient) standard. Every year that passes with no attempt to update the standard is another year that the language looks crustier and less appealing to new programmers. Languages have to evolve. Common Lisp is a dead end. 
I love Guile. Can it work on the iPhone?
There's a great advantage to having a long-term standard (C, Common Lisp). It allows you to keep reusing the same code and polishing it over a period of many years. This is not possible for languages without that mentality. I wish Clojure the best &amp; have no real antagonism to writing in it, but I know that any code I write now will likely be superceded in 1.5, 1.6, etc. Much like Python &amp; Ruby. Not an incentive to write code I want to use in ten years (Yes, I have code from ten years ago, I keep lots of code around). 
&gt; Common Lisp will die because current CLers are not willing to move away from the (ancient) standard. Because that ancient language is Lisp, not the hyped language de jour. &gt; Languages have to evolve. Common Lisp has change built-in. The user can change the language. &gt; Common Lisp is a dead end. That would surprise me. The Lisp community had these discussions every decade. But there are always Lisp languages which preserve the core feature set. In the 60s several new Lisp dialects appeared. Interlisp, Logo, ... Still the main Lisp (Lisp 1.5) was not abandoned. Maclisp preserved most of it. In the 70s ML (which was first implemented in Lisp), Scheme and Standard Lisp appeared. Lisp was not abandoned. LML was developed. In the 80s Prolog and a bunch of FPs were developed or got 'popular'. Lisp was not abandoned. CL was developed. In the 90s Dylan was developed. Javascript was developed (based on Scheme semantics). EuLisp (European standard). ISLisp (international standard). Lisp was not abandoned. CL was standardized. In 2000s Clojure was developed. Lisp was not abandoned. CL implementations were revived or newly developed (SBCL, Clozure CL, ABCL, SCL, ...). Today, most main Lisp dialects are more or less dead (from Interlisp over Eulisp to Islisp). CL is still there. The chance that the main Lisp dialect will die because somebody develops a new Lisp-like language for a different user group is pretty slim. 
&gt; I prefer the thrive for simplicity, I also prefer not being afraid of change and pragmatic solutions that get abolished once better solutions arise. Well said. There now are a very adequate number of very high-quality, stable CL implementations and at least as many Scheme implementations: no-one needs any more of either, and no-one needs to worry that their codebase will become orphaned because all these implementations have somehow evaporated. There is probably scope for work in pushing the limits of CL implementations in terms of large many-core systems or very small systems, though in the latter case I'm not sure: CL implementations already run happily on platforms much wimpier than a modern phone. I've written CL for a long time and I'm old &amp; tired and probably not going to change to some different Lisp now; but progress is made by exploration &amp; competition with the losers dying, not by strangling possible competitors at birth. Write a new Lisp!
Impressive.
Nice. But relies on MAKE as a short version of MAKE-INSTANCE, which is in git rutils but not yet quicklisp. And GENERATE doesn't seem to work - the initial transition is never generated. 
Thanks!
Spoiler: **NLTK** = **N**atural **L**anguage **T**ool**K**it
Hello. Nice start to a program. Unfortunately I don't have SDL so I couldn't test it. However, I did go over some of the code, and it does definitely need work. I've outlined some of the changes I'd make here: https://github.com/tarballs-are-good/cl-puyopuyo/commit/6918c449fe831e298d6ad7f92b17384bffa234c1 In summary, the code looks like it is written by a recovering C or Java programmer. The tell-tale signs are * The use of CamelCase in Lisp. Since Lisp is more liberal with the kinds of names you can give things, Lispers usually use hyphens. So instead of `fooBar`, you have `foo-bar`. * The extensive use of `loop`. While using `loop` isn't necessarily bad and totally valid, sometimes it's more useful to use functional forms, or more specialized loop forms such as `dolist` or `dotimes`. * Lack of loop idioms. For example, you do `(loop for x from 0 to (- y 1) ..)`. See [1] for equivalences. There are significant other improvements I'd suggest to which I didn't include. * You use `slot-value` a lot. If you want to pull lots of slots, you can use `with-accessors`. If you're only using one or two, use the slot accessors. So for example, instead of `(slot-value foo 'x)`, you can do `(puyo-x foo)`. * If you only have one branch of an `if`, consider using `when` or `unless`. See [2]. * You can combine some `setf`s. You currently have something like `(if p (progn (setf a ..) (setf b ..)) ..)` which could be turned into `(if p (setf a .. b ..) ..)`. See [3]. * Instead of a conglomeration of global state variables, you might consider packaging everything up into a `game-state` structure. * Generally it is preferred to use `with-open-file` instead of doing manual opening and closing. See [4]. If you're confused about these things, I can do some more clean up commits to the repository, but I'm hesitant since I can't really test the code on this machine. If you have any more questions, feel free to ask. Happy lisping. [1] (loop for x from 0 to (- y 1) ..) == (loop for x from 0 to (1- y) ..) == (loop for x from 0 below y ..) == (loop for x below y ..) == (dotimes (x y) ..) [2] (if p x nil) ==&gt; (when p x) (if p (progn x y z) nil) ==&gt; (when p x y z) (if p nil x) ==&gt; (unless p x) (if p nil (progn x y z)) ==&gt; (unless p x y z) [3] https://github.com/tarballs-are-good/cl-puyopuyo/blob/master/cl-puyopuyo.lisp#L163 [4] https://github.com/tarballs-are-good/cl-puyopuyo/blob/master/cl-puyopuyo.lisp#L281 --- *edit*: I've committed a few more improvements. *edit*: I tried building on OS X after installing SDL, but it still doesn't build for me. Probably my/my system's fault, though.
Very nice. The game works for me. But had problems loading it. I managed to fix the load by adding #:lispbuilder-sdl-ttf and #:lispbuilder-sdl-gfx to the system definition, instead of loading them from the main lisp file via quickload: (asdf:defsystem #:cl-puyopuyo :serial t :description "Describe cl-puyopuyo here" :author "Your Name &lt;your.name@example.com&gt;" :license "Specify license here" :depends-on (#:lispbuilder-sdl #:bordeaux-threads #:lispbuilder-sdl-ttf #:lispbuilder-sdl-gfx) :components ((:file "package") (:file "cl-puyopuyo"))) 
SDL is a drag to get running IME.
Wow. Thanks you so much for taking your time reviewing some of my code and writing this advice list. It it highly appreciated. You are right, I have a C background. Before the last commit there were even more loop structures, which I changed to dotimes.... Anyway, I will tr yto implement you advices and commit them next week. THANKS MATE!
Absolutely. I am very happy to have annouced this here, so someone could give me good advices and hints like tarballs_are_good. Thanks for commenting and best regards. 
I think i can get rid of sdl-gfx and sdl-ttf, which maybe improve things on OSX. 
Thank you very much for testing. I will also implement your changes. Best regards.
Nice idea, but it would be even more useful if I could generate the docs on my local machine (like doxygen). So I would generate docs for my own projects.
Fantastic work, Fukamachi. My projects (coleslaw,cl-6502) don't work yet but I'll dig in and figure out why. Thanks. :)
Cool! I searched on my phone, and it automatically capitalized "zs3" to "Zs3", and it got no results. It might be nice to do a case-insensitive search.
Just to add a short note: (number-sequence 2 10) in Elisp will generate a sequnce with 10 included while range(2,10) will not in Python.
I don't know if this is the case for the author of this library, but I think there is a discoverability problem. Thanks to your message I have learnt the existence of libraries I had never heard of. Quicklisp is great if you already know what you want, but I wish there was a way to browse a list of libraries by category, CPAN-like. (And CLiki does not seem the best way to do it)
Quickdoc seems to help, I'm not sure though.
It should be possible to find projects by more than their names. In a few test searches, I didnt manage to find any project by looking for keywords. If I already know the name of what I'm looking for, I can as easily just google it.
Quickdocs is useful, but at least for now it addresses a different problem. As far as I have seen, it searches system names only. It would be nice if it searched descriptions too (not sure if QL has them). Also, there is no way to *browse* libraries by category (or tags), e.g. What graphics libraries are there on QL?
Funny thing is this actually started as a one-time hack, I needed to analyze some TSV file for something work related and I figured "hey, I'll do it in Lisp just for the kicks and to improve.". I figured there would be already libraries to do this, but since this wasn't supposed to be "serious" work I did it on my own. At first I just had the functions to load the TSV and as I was playing with the data I simply added more and more functions as I was needing them. After a while I figured I would package it and publish it, even if it seems like everyone had the same need and followed the same path as I did. The reason is called cl-simple-table is because I knew we already have a cl-table. :-) If you look at the commit dates you will realize this didn't took much work , it was a weekend-long fun project to do, that's all.
One thing I have toyed with is a linq/sql interface over row-based data. It's surprisingly simple to write a macro: `(query select row-name from &lt;variable&gt; where (lambda (row) ... )` It'd be nice if someone took the time to take the query idea and implement it for CL structures, as well as a protocol for non-native data structures so that people could implement it for their favorite data source (cl-csv, fset, etc, etc). I kind of plan to, but it's all vaporware in my head. Was hoping that cl-simple-table would provide that.
As the developer of some of the libraries linked, I am glad that someone else already made this comment. Mostly because I would have felt hypocritical criticizing someone for reimplementing csv readers, and tables when obviously I did that myself. In my defense, I really wanted a csv parser with good error messages, a good test suite, and that could handle gigabyte sized files (and couldn't find an extant one that matched that criteria, though I did glean useful ideas from some of them). I did base mine on the arnesi csv file (though its mostly rewritten at this point). I also wanted a simple-as-possible solution for grabbing a csv and inserting its contents into a sql db (thus data-table).
The google results for "common lisp csv" return multiple references to at least three different csv libraries. Its not perfect nor unified, but I can generally find at least a reference to library that I need. I definitely feel the pain of not knowing about or being able to find the libraries I need, but google combined with cliki is usually at least an 80% solution. If you add asking on #lisp you're probably closer to 95% solution.
This is true, but convenience is important. Also, the scenario that you are describing assumes that you already know what you are looking for. Countless time I have discovered interesting libraries just by browsing CPAN; things that I did not *need* at the moment, but that they would prove useful sooner or later.
And where documentation doesn't exist, this tool can use Lisp's own reflective powers (do-external-symbols + fboundp + doc strings) to extract documentation. 
A related project which I like is docbrowser (ql:quickload :docbrowser) (docbrowser:start-docserver) Docs for all loaded libraries is now at http://localhost:8080
local package nicknames are a great feature
How's the threading on Windows stuff going? EDIT: Also, gotta ask, how are the local package nicknames implemented? Like, pointing to the relevant code or something would be cool, or describing how it works.
I'd go so far to call it fundamental and wonder why it took till 2013 for something like this to get implemented. Do you know whether other implementations have a similar feature and whether there are libraries providing a compatibility layer? I have waited for long for this feature and would hate to have to turn my codebase sbcl-only from now.
&gt; but it makes documentation (if it even exists) easier to read What, how?' I think a lot of Lispers simply **aren't** web devs or designers and often do not think that pretty page implies that it's good. For web related stuff that looks good, check out the RESTAS homepage, Caveman and Clack (google it, son). Also, I didn't really get your commentary on Hunchentoot. I don't think the Hunchentoot page needs any improvement, though.
&gt;My logic was that it relates to the web so maybe it should have a more modern site design. Yeah, I can agree with this. Basically, I think that being pretty can attract new people, because it looks more "proper" and professional to beginners.
There was a discussion about package local nicknames in CCL, starting with http://clozure.com/pipermail/openmcl-devel/2013-February/014064.html 
Right on. Thanks guys for keeping the SBCL dev going.
The problem I have is that [it only takes a handful of lines of css to make your page the least bit attractive](http://imgur.com/IR3CdQQ.png)
Adding on this, people who want to do web development in a lisp usually seem to choose Clojure. I'm sure ClojureScript is a large part of the reason for that, and I really wish there were a good Common Lisp -&gt; Javascript compiler.