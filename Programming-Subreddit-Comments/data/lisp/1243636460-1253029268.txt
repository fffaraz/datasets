how frequently do you use CLtL2 as a reference?
looks totally random, as for me. mapcan? mapcon?
i can confirm these are NOT most commonly used functions.
Often enough to mention it. Recently i've used it for an overview of environements and for the chapter on series. There are things in CLtL2 that are not in ANSI but widely available in common lisp implementations.
How is this lisp-related? The API could be implemented in lisp, but same for twitter and all the other stuff.
Lispers like to talk about a "killer app" for Lisp. I think Google Wave could be one.
On the client side it's JS. On the server side it can be anything, but given that it's a communications protocol I'd bet Erlang would be much better suited than any Lisp (other than, perhaps, Lisp Flavored Erlang). I'm not sure what you're aiming at here.
&gt; let*, ... dolist, dotimes, etc. so you're saying you don't really program functionally at all? but use lisp.. because? i agree wholeheartedly on multiple-value-\* and if you're going to side affect something, yeah i'd generally rather see setf car then rplaca. (although i can't really defend that)
while i agree that list is hugely weird... what!? mapcan, mapcon .. you think those are weird? (admittedly mapcon is more rare, but..) all the map\* functions are your bread and butter in lisp (the list processing language). that's what you do, you map and you reduce.
I guess basically I'm trying to say, in my late-Friday-night befuddled state, 1. Write a Lisp API for Google Wave 2. Become popular 3. Profit 
Common Lisp is not an especially functional programming language. I write programs in Common Lisp because it is a supportive environment and I can explore ideas quickly. I use functional style when it's helpful and other styles when they're helpful. http://xach.com/img/cl-animation.gif is the result of yesterday's program, btw.
&gt; so you're saying you don't really program functionally at all? but use lisp.. because? Because lisp in not a functional language. Lisp supports many different paradigms, and all are as valid as any other. One look at PROG is enough to send functional language advocates screaming from the room. 
never seen them in real code. mostly people use `(loop ... appending ...)`. Common Lisp is different from other languages not by list processing -- you can do it in almost any language -- but by powerful macro facilities. and i think it is shame when you do not use these facilities. 
You don't get to see any good lisp then. I use mapcan all the time. and lisp is different from other languages for a lot of reasons.
well dude, i have not seen your code, but i've seen code of dozens of modern Common Lisp libraries, like cl-ppcre and UCW, and i'm even maintaining some of them (particularly, one backend of Elephant Persisten Object Database), and i've also read source code of many CL implementations (SBCL, ABCL, ECL..). i did not do any statistical analysis, but as i did not have problems understanding code without remembering what mapcan does, i guess this means that it is rarely used in modern code. maybe it was popular in 70s and 80s when there was no LOOP, but i'm not much interested in reading code of those times, as i'm usually working with practical things rather than masturbate lists
there's a difference between the guts of a library and an application. i don't get why people are so fascinated with loop. you need twice as many words in your example. if you need something trickier fine, but if you need to mapcan then mapcan. why because it has a funny name? its the language, get used to it. you use cdr just fine. that's like saying I don't like setf, so I defined set-place. also you *do know* you can map more than one list at a time... CL-USER&gt; (mapcan #'sublis '(((a . 1) (c . 3)) ((x . 5) (z . 6))) '((a b c) (x y z))) (1 B 3 5 Y 6) Although, I don't know why I'm bothering putting up with such a *mature* child: &gt; masturbate lists ps i'm sure your mother wouldn't appreciate you talking like that, don't let her catch you.
Hi. I'm the author of that reference. The primary audience were my students when I co-taught summer course of artificial intelligence for some students from Mexico in Prague in 2005.
PROG and TAGBODY etc. are mostly used inside of macros that are setting up some optimization or new primitive for a DSL. you would rarely use that in your functions, LET covers the majority case. &gt; all are as valid as any other for some definitions of valid. I mean if you mean you can write it and it compiles and does something ok. but if you are trying to take advantage of the language then no. For example, if you are writing a unifier, you have the problem of what to do when it fails. if it normally returns a list of bindings, and you return something like :fail when it fails (a common approach), your unifier is now returning true when it means false. So you can't use any of the lisp primitives with it: AND, OR, SOME, EVERY, etc. but if your unifier returns nil for fail, and a list of list of bindings, you are good to go. The :fail unifier works, but it's a pain in the ass to use for anyone that actually understands how to use lisp.
&gt;Common Lisp is different from other languages not by list processing -- you can do it in almost any language -- but by powerful macro facilities The macro are based on treating code as a tree and using these lisp processing methods on it. Mapcan is awesome: it lets you flatten trees, merge a two stage process of map and remove-if and generally restructure data. I think I predominately use it in macros.
Or he can just message me :-) Anyway adding new functions is easy. It is just needed to produce XML (I know I could use s-exp as well, but ...) file corresponding to a function. See http://jtra.cz/stuff/lisp/sclr/assoc.html vs. http://jtra.cz/stuff/lisp/sclr/assoc.xml Add to http://jtra.cz/stuff/lisp/sclr/index.xml And then run some script to regenerate html.
the difference is that LOOP and SETF are generic -- they are applicable to large set of problems, when mapcan and set-place are good only in a very narrow set of problems. so why bother? how often do you have cases when a combination of mapcan and sublis solves your problem? &gt; Although, I don't know why I'm bothering putting up with such a mature child: i suspect you're just trolling me, so show your code or GTFO.
For me, the reference would be CLHS. When I was learning CL, I read CLTL (on which the CLHS is based, I assume) front to back and it was a delight. But CLHS is too dense for non-ambitious newbies.
and *subtract-and-branch-if* is turing complete and only one command -- why are we using anything else? generic does not equal better. the example was a toy, the point is not about using specifically MAPCAN and SUBLIS. mapping multiple lists is a common construct, made only that much more messy if you try to cram it through loop. (mapcar #'* list-of-data list-of-weights) the point is the right tool for the right job.
Looks cool but what's with the weird capitalization ("Self", "CHOPPER" etc.) and XML.
If you're trying to take advantage of Common Lisp, limiting yourself to only one paradigm is not the way to go. The unifier example is not very persuasive. Not everyone who uses Common Lisp is writing unifiers. Some people are writing [web frameworks](http://www.cliki.net/lisp-on-lines) or [Amazon interfaces](http://www.xach.com/lisp/zs3/). Functional purity is no substitute for getting the job done.
Lisp lecture by a gay lecturer. Fitting.
If you are writing a unifier, i don't see how using TAGBODY inside your implementation makes any difference whatsoever. If your unifier is implemented properly, then the user shouldn't be exposed to implementation details... I could use PROG or a custom CPS transformer for all the user should care. Your point makes very little sense in this context. If you are saying that you've written unifiers with poor interfaces such as the one you describe and had trouble integrating it with lisp code, this is understand... don't do that. It's not at all relevant to the topic at hand though. Regardless, your claims about how common lisp is used doesn't stand up to my experience with real world common lisp code. If you want a functional language, Common Lisp is not it, and no amount of ear holding and lalalala-ing will make it so ;). Common lisp is a very practical multi-paradigm language. It supports all of and not limited to OO, procedural, functional, metaprogramming and declarative styles of programming. You might like functional programming, but CL gives us a lot more. You might want to learn some of the non-functional features, you'd be surprised how useful having a full arsenal of computational ability can be. Limiting yourself to one paradigm is just that ... limiting. Some solutions lend themselves well to some paradigms... your personal favorite is not always the best fit. 
See, the thing is, once you include all the useful functions (which is damn near _all_ of them), it's not going to be quite so simple anymore, is it? :)
:-) correct
Also, OSX only? :(
you've missed the point. (and i'm spending too much time here) you're looking at a tree i described and failing to acknowledge the forest it was meant to represent. the point is the language affords certain things. there's lots of things you *can do* that will *work* but if you buck the affordances of the language, a good developer in that language will not be able to efficiently use your code to his potential.
you've missed the point. (and i'm spending too much time here) you're looking at a tree i described and failing to acknowledge the forest it was meant to represent. the point is the language affords certain things. there's lots of things you can do that will work but if you buck the affordances of the language, a good developer in that language will not be able to efficiently use your code to his potential.
I think you've missed the point. I've worked on teams of a few hundred lisp developers, and i've never heard anyone complain that code wasn't 'functional' enough. I have, however, seen recursion re-written to use LOOP, massive use of CLOS, and yes, even TAGBODY in production code. You seem to have a very narrow view of what lisp offers, and don't seem willing to acknowledge that the other parts of the language are in fact widely used. The problems you speak of have never occurred in reality, so i suspect you're speaking from a very limited point of view, and have never actually developed a large common lisp application in a commercial setting. 
in fact i am arguing the opposite. I am arguing the right tool for the right job. This whole thread started because someone said MAPCAN was stupid and they would never use it because there is LOOP. When if what they are doing is just MAPCAN they should use MAPCAN, or whatever the base function is. If you need LOOP then LOOP, but I'd bet most of what it's used for is the equivalent of a MAP\* function, and there, there's no point. I'm arguing that something *working* isn't good enough, it should *work well*. e.g. the bad unifier described (just an example), works, but the other one works better because it meshes correctly with half of the lisp language. (i would be arguing the same thing if what came up initially was some stupid way to use CLOS, or read macros, or...) I write in a very large settings too. And large doesn't mean better or more efficient, by the way. And I routinely use every last corner of the spec. (although I'll admit I don't programatically use restarts that much, mostly only when debugging, but sometimes in code.)
&gt; in fact i am arguing the opposite. Well, we're in agreement then! &gt; I'm arguing that something working isn't good enough, it should work well. That is a point you are not making clearly. (loop for item in list nconc (foo list)) vs (mapcan #'foo list) ... both produce the same results, both are idiomatic lisp code, yet you are somehow arguing that one is 'better' than the other. My counter-argument is that your opinion is subjective, and both are perfectly valid methods of achieving the same results. &gt; And large doesn't mean better or more efficient, by the way I never said it did.. in fact i believe the opposite. However, you claimed that 'functional' code is the only way to write lisp that will integrate will with the language and be easily used by other developers. My experience does not support this statement. I'm not supporting the 'stupid way' that the OOOP mentioned. What i'm doing is replying to your question : "so you're saying you don't really program functionally at all? but use lisp.. because?" i'd argue that your bad unifier _doesn't_ work, wheres (LOOP ... NCONC...) works just as well, if not better, than MAPCAN. In fact, i have trouble seeing how it relates to your example of a poorly designed unifier interface, to be honest. But we seem to agree that lisp is not a functional language, and one can use lisp perfectly well and not drink the functional kool-aid, so i'm not sure why i'm still writing. 
&gt; why are we using anything else? generic does not equal better. in this particular case generic variant is more convenient and more flexible. LOOP is very readable, and often if you need something you do not need to rewrite the whole thing -- you can add variables, do several things at once while iterating etc. but you cannot extend mapcan without weird hacks. &gt; mapping multiple lists is a common construct, made only that much more messy if you try to cram it through loop. huh? (loop for item in list-of-data for weight in list-of-weights collect (* item weight)) you can say it is more verbose, but it is definitely not messy. in this particular case variable names are redundant, but often adding variable names help understanding the code. as for flexibility, you can easily extend it adding some bias constant bias: (loop for item in list-of-data for weight in list-of-weights collect (+ (* item weight) bias)) or you can find weighted average without making a temporary list: (loop for item in list-of-data for weight in list-of-weights for value = (* item weight) sum weight into sum-of-weights sum value into sum-of-values finally (return (/ sum-of-values sum-of-weights))) code rarely appears in its final form from start, especially in Lisp which encourages exploratory programming, so code flexibility is very important. well, ok, i've gathered some statistics about different functions/macros usage in my code collection (libraries, not my code): LOOP: 3842 occurences MAPCAR: 1462 occurences MAPCAN: 80 occurences MAPCON: 5 occurences so we can now in an scientific and unbiased way say that LOOP and MAPCAR are among frequently used functions, while MAPCAN and MAPCON are not. i have nothing against MAPCAN, personally, and in Haskell its analog -- concatMap -- seems to be more widely used. but in Haskell they do not have LOOP.. and maybe sane name helps too -- if i'm going to write (concat . map f), i'd look for function concatMap, but not for MAPCAN :) 
Gee, I guess I'll stop using LET* then. Thanks!
 (defmacro bf-current-instruction (engine) `(car (bf-future-code ,engine))) sigh. 
Hey, at least it's functional!
verb -&gt; function-name i guess. this makes it clear why people prefer infix and only poets prefer prefix ... its in the head!
Compared to ordinary Languages like C++, lisp in fact IS poetry, isnt it ;-)
That is the way I would interpret it. Verbs are actions. The typical C++-style OOP construct: some_class_instance.foo(x,y,z,...) Is basically just: subject.verb(object1,object2,object3,...) The way I see it, there is some confusion as to which things are the subjects and which are the objects in the typical Lisp usage. Really since the function is the thing "doing to", it sort of is both the verb and the subject. For example, in (+ 1 2), + is the verb, but what are 1 and 2? I would probably call them objects, but where then is the subject? The implied return of the entire construct?
From a theoretical syntax standpoint, the underlying rules which govern the syntactic structure of a language are extremely complicated, even when dealing with simple notions like SVO or SOV word order. Explanations for the relative lack of languages with VSO word order generally have to do with several rather complex and unintuitive observations about they way universal grammar seems to work in human language. As a result, comparing this kind of thing to anything regarding computer languages (whose syntaxes generally have more to do with our sense of logic than with the language functions in our brain) seems kind of unfruitful, even if it's kind of interesting. As a side note, I've heard it convincingly argued (though the details now escape me) that VSO languages don't actually exist, and are actually SVO languages in which the verb consistently moves into the Complimentizer position (where you'd normally see words like "if" or "when" in sentences like "when he went to the store") in standard sentences, and that's why you hardly ever see languages like that.
OSV, Yoda uses.
You're probably looking for swank. And if you're using SLIME in Emacs, then you're already using it.
I was about to post an explanation, but leechblock cut me off from reddit..... After RTFM, I'm trying something now using slime-mrepl, so I can define functions at runtime, with an SDL app having been launched from another REPL. Also, [fluxus](http://www.pawfal.org/fluxus/) has been released for [Win32](http://www.pawfal.org/fluxus/packages/)!! Update:Nope, mrepl doesn't do the trick, since CLisp doesn't support multithreading. (Which I discovered after scraping comp.lang.lisp and [various threads where Peter Seibel was demanding satisfaction but got none.](http://www.mail-archive.com/application-builder@lispniks.com/msg00329.html) If the author of "Practical Lisp" can't get it to work, what hope do I have?). The other repl sits there as useless as the first one. I've ditched CLisp, emacs, Slime, Swank et al for now, while I enjoy fluxus and PLT Scheme, both awesome, fluxus especially. 
It's easier to see with subtraction. (- 1 2) suggests "1 subtracts 2".
Except the natural language equivalent seems more like "Subtract 2 from 1", which follows this form very well. It seems like functions are analogous to imperative form sentences, which contain an implicit second-person subject, that I guess would refer to the computer. It seems wrong to me to imply in either case that the number 1 is doing anything, but I wonder if that's logical? Perhaps people tend to see mathmatical operations as 'meaning' different events, even though they have the same result. Anyway, that's how I'd look at it from an imperative programming standpoint. In functional programming, it might make more sense to look at functions as noun phrases, such as "(The result of) subtracting 2 from 1". Noun phrases don't really need subjects, so it's a non issue.
I'd say it's more like "decrement 1 by 2"
&gt; As a result, comparing this kind of thing to anything regarding computer languages (whose syntaxes generally have more to do with our sense of logic than with the language functions in our brain) seems kind of unfruitful, even if it's kind of interesting. not true. many lisp people claim they think in lisp. perl people also seldom do and perl has an added psychological boost i presume. and learning any computer language proficiently implies some amount of internalization. our sense of logic only comes when we are thinking about writing an essay, a lisp module. for regular code/conversation we dont need logic all all ... our mind just seems to give it out automatically. 'getting your job done' is also cited as perl's strength. and also our sense of logic is mainly useful in large scale structuring and rest all is again regular language. but i dont think you get the irony here, looking purely by numbers infix and oop syntax are extremely popular. although function call syntax is VSO(kindof), it seems to have faded. the point is if lisp style of thinking is totally against the very basics of our i-language then surely we ought to take this seriously. otherwise lisp will always be a Shakespearen language only used by a few. i dont think even macros can help here coz implementing a natural language(okay infix, postfix, circumfix ...) inside macros will be tough. EDIT: typos. 
Could you tell me how to use swank to produce multiple repls for the same CLisp process? I haven't been able to figure this out.
Funny thing is, in the old movies he seldom did. In the new movies, he's a caricature of his old self.
I haven't tried messing around with swank yet, but I would guess that this requires multiple threads. Since clisp doesn't support multithreading, my suggestion would be: don't use clisp. You probably want something multithreaded, particularly if you're doing simulations. Check [here](http://common-lisp.net/~dlw/LispSurvey.html) for something with multithread support. I'd recommend SBCL, though if you're using Windows something like Allegro might work better.
&gt; That is a point you are not making clearly. (loop for item in list nconc (foo list)) vs (mapcan #'foo list) ... both produce the same results, both are idiomatic lisp code, yet you are somehow arguing that one is 'better' than the other. if it's actually implemented with NCONC (and i believe that it would be in your example), then it is way way worse. since every time it will need to re-traverse the whole list of accumulated values, whereas MAPCAN will only traverse the new elements. Using NCONC like this is horribly inefficient. &gt; But we seem to agree that lisp is not a functional language, and one can use lisp perfectly well there are plenty of non-functional parts of lisp. the spectrum of *perfectly well* is ill defined, and the more functional you are, the more power a good developer can get out of lisp. Some things just aren't functional, like maintaining a memory (in the AI sense), it's fundamentally a side effect. But the more functional your interaction can be (to a point) the more power you can get from lisp. 
&gt; (loop for item in list-of-data &gt; for weight in list-of-weights &gt; collect (* item weight)) you're kidding right? this is 13 symbols, MAPCAR is 4 and says exactly what it does. &gt; or you can find weighted average without making a temporary list sure, and you should to do anything else would be a waste, but you don't need LOOP to do it. DO works perfectly well. There's probably a way to use REDUCE cleanly too (but I'm only thinking of hacks right now). &gt;well, ok, i've gathered some statistics about different functions/macros usage in my code collection (libraries, not my code) that doesn't make it good code? I bet most of those LOOPs are just MAPCARs or worse MAPCANs (which is they are appending inefficiently this is a big waste)
It's what all the cool kids are using these days.
&gt; if it's actually implemented with NCONC (and i believe that it would be in your example), actually I believe the LOOP macro may be implemented well enough to do this how MAPCAN would. At least I hope so.
&gt; that doesn't make it good code? cl-ppcre, drakma, flexi-streams, contextl, bordeaux-threads, iterate.. basically, most of the libraries which make practical programming in Common Lisp possible. if that is not a good code, i do not know what is. if you feel adventurous, go to comp.lang.lisp and say that you think that Edi Weitz and Pascal Costanza write not so good code, but your code is really good, and be prepared to be ridiculed. &gt; worse MAPCANs (which is they are appending inefficiently this is a big waste) wat? LOOP can do nconcing just fine. i see you're just a LOOP hater..
&gt; if it's actually implemented with NCONC (and i believe that it would be in your example) Just because you believe something doesn't make it true. &gt; But the more functional your interaction can be (to a point) the more power you can get from lisp. Just because you believe something doesn't make it true. Look, i'm sure the functional kool-aid tastes really nice, but your subjective opinions of the 'power' of programming languages are just that, and not some universal truth. CLOS is an extremely powerful programming paradigm based fundementally on side effects. The idea that functional code is better than CLOS code, or macros, or the condition system, the reader or all the other wonderful and extremely powerful parts of common lisp that are not 'functional' is pure hogwash. Could functional' programming be your 'blub'? Next your going to tell me recursion is fundamentally superior to iteration, conses should be lazy or immutable, and all type errors should be caught at compile time... and i'm not interested ;)
heh ... maybe it's also possible that your belief in functional programming in CL is misplaced as well. 
&gt; CLOS is an extremely powerful programming paradigm based fundementally on side effects. nonsense. just because you have objects doesn't mean you have side effects. &gt; Just because you believe something doesn't make it true. and yet, you make similarly valued claims.
After your reply, I gave it one more go. I selected Clozure. Long story short, I was able to load the sdl library with no problems, and modify running code in a secondary repl with no problems at all. Thank you for the push. I think CLISP should come with a disclaimer that says "USE CLOZURE INSTEAD" 
Another update/howto for anyone interested: **1)** Unzip Emacs 22.3, Clozure and slime-2009-05-31 into C:\lispbox. **2)** Plonk the packages directory into C:\lispbox **3)** Modify _emacs so slime uses clozure **4)** Run emacs. **5)** Run M-x slime **6)** ASDF comes with Clozure, so at the REPL: (require 'asdf) **7)** Use the script in the "Alternative Sysdef Search functionality" at the bottom of http://www.cliki.net/asdf to point ASDF at your packages directory. (C:/lispbox/packages/) **8)** Load your packages. (asdf:oos 'asdf:load-op :blah) **9)** Add an idle event handler in one of the SDL examples. Call a drawing and screen update function there. **10)** Run it. **11)** Open another repl: M-x slime-open-listener **12)** Change the function. See the effect of the change in the running app. I can't believe how painless that was. Smile with joy. 
&gt; think that Edi Weitz and Pascal Costanza write not so good code you can write decent code *and* still use LOOP too much. and for every LOOP evangelist on c.l.l there is one person with my opinion. &gt; i see you're just a LOOP hater.. no. use LOOP, when it's appropriate. do not when it is not. your view, always use LOOP is the dogmatic one. &gt; LOOP can do nconcing my fear was that it was actually accumulating by calling NCONC which would be horrifically inefficient, due to repeated traversal. I now suspect it's actually handled by the macro special (at least in a decent implementation it better be). 
&gt; just because you have objects doesn't mean you have side effects. You can't know much about CLOS if you're planning on backing that up with facts.. we're not talking about objects in general, we're talking about CLOS. CLOS is a dynamic OO system. Defining a class side-effects the global environment. Defining methods and generic functions too. This is an unavoidable part of the design of CLOS. I suggest you flip through AMOP, you might learn something. These are fact, not beliefs. You don't seem interested in facts, and i'm not interested in your opinions and beliefs, so lets stop.
I know plenty of CLOS. (is amazing how right CLOS got it, and how terrible every object model built since then has been) I think you think I'm arguing everything last thing should be pure functional,.. hell lets get rid of variables, uh oh there's a print statement... I'm not. My point has always and will always be though that, in general, the more functionally you can set things up in lisp, the better. Sure sometimes you'll need a side effect here or there, but when you don't, don't. and that makes more useful and cleaner code. you can write procedural code that side effects up a storm in lisp. it works. it gets the job done. however, there is tons of CommonLisp that is designed to be functional. if you write functionally you get to take advantage of all of this part of the language and leverage it. if not you don't. both work. one clearly works better when you can take advantage of it. 
I always thought by the info on the UFFI webpage that it was the more speed conscious. I love it when this sort of stuff happens: the FFI library with that works with more implementations has a compatibility layer which acts as a drop in replacement, and that replacement outperforms the original FFI library.
Yoda: "Around the survivors a perimeter create!" Clone Soldiers: "Huh? What the fuck is he saying?"
I am too lazy to check why, but the damn page keeps refreshing a little. Very annoying.(Just fucking load and be done with it.) Still, good article. I remember seeing (but not using) a thread lib with a plet macro, unfortunately i seem to not be able to find it back :/
It is clear that there are such cases. That is why most functional languages are not purely functional. The problem is, that there are many cases where it is vice versa and anyway anybody uses imperative languages.
I love this description: &gt; ...by modern standards (set by Office 2004), BBN SpyGlass is compact.
Neat example...dunno if I'll use it for my sites, but still neat.
All Scheme, sadly.
pcall is its name: http://marijn.haverbeke.nl/pcall/
Fair enough but there's still things to be learned from the scheme family. Does anyone have comments on the quality of these texts?
Wow! That looks great. I have tried to do similar stuff (http://lukego.livejournal.com/1612.html) and there really is a lot of value in higher-level analysis and visualisation of things like network protocols.
While I appreciate such advice from CL experts, I still am looking for good explanations for how to design conditions. This is a significant gap in CL books. Some questions I always run into trying to define conditions: 1. When to default to crude `(error "Bailing out...")` 2. How to make the tradeoff between subclassing conditions and simply including a slot to carry specific information. 3. What my goal should be in defining `:report` functions 4. Where are there examples of good use of conditions in libraries and applications? IIRC the standard "look at Edi Weitz's code" was not particularly informative, and he seemed to have at least two distinct styles. 
The more possible runtime errors (file missing, network down, syntax errors, host non-existent, space full, ...) there are, the more you want to handle these errors robustly and the more you need to invoke the user to repair the error conditions (new file name, try again, do you really want?, get different host, get additional disk space, ...) - the more you need the condition system to program the error handling. Addressing your points above: 1. no users, just you. no way to recover in a useful way. 2. lots of different errors, makes sense to categorize them, error reporting is important, may want to dispatch on different error types (file does not exist vs. file is not readable/writable). 3. expert user needs information about errors in a somewhat readable way. The output should look nicer than just inspecting the error condition. 4. Common Lisp offers several different levels of error 'handling'. Examples: calls to ERROR and warn. ASSERT and CHECK-TYPE. Condition system using conditions, handlers, restarts. The condition system is often used in REPL implementations (SLIME/SWANK). The CLIM command interpreter and Lisp listener might be useful to look at -&gt; McCLIM. CL-HTTP uses it. Lisp Machines use it.
i think one should be pragmatic -- if there is a useful way to deal with additional information in condition, so one might want to catch this specific condition in some place, check addiotional info and deal with it in one way or another, it is worth bothering; otherwise, it is not. that is, if you cannot imagine how one can handle such error at all, use a generic error with a string description. if you think one might want to distinguish one sort of condition from another, then subclass, otherwise, pass additional info in a slot. as anything in programming, it is a tradeoff, so just use what looks most sane to you. 
&gt; I would wish for a reference that is more user-focused and less implementor-focused. Me too. It sounds similar to that mythical ANSI Common Lisp Reference that for a certain period was in the Apress list of forthcoming titles, and then disappeared. 
This looks very cool so far. One thing that disturbs me is they keep talking about conversations being trees. While true in a sense it's not the best presentation of a conversation. Look at your standard threaded discussion on reddit. Often the same topic is covered in two independent threads (the ubiquitous pun thread for example). There is no mechanism for merging the two threads. It would be nicer if discussions were treated more like a graph. Someone could notice the two duplicate threads, link them together, and that linked node could be "hoisted up" in the presentation as the root node for the threads .
Unfortunately the video's audio is completely inaudible.
The only reference in the linked article about poetry: *Some of these languages, such as English, can also use an OSV structure in certain literary styles, such as poetry.* Oranges Andy ate?
["let's call the whole thing off..."](http://www.youtube.com/watch?v=jdH2ODFYV5s)
For me it is okay. Turn up the volume.
Interesting. In picolisp http://www.software-lab.de/down.html it would be: (load "@ext.l" "@lib/http.l" "@lib/xhtml.l") (allowed () "@start") (de start () (html 0 "Hello" NIL NIL (&lt;p&gt; NIL "Hello World!"))) (server 8080 "@start") $ ~/picolisp/p hw.l $ curl http://localhost:8080/ (or http://localhost:8080/@start) &gt; The shortness is about the number of tokens. Now add database etc. and count number of tokens for "all the software you need". It would be interesting to compare to the number of tokens needed for the same thing implemented in picolisp, including number of tokens needed to implement picolisp (or arc/mzscheme;-)
&gt; As if anyone is going to bother with a legacy CLIM application when there are well established modern applications that do even more (wireshark). Yes and no. AFAIK, wireshark doesn't offer anything near that level of sophistication in the cross-visualisation, if at all.
I *have* the volume up all the way—to eleven. Trying playing any other video on youtube and you'll notice how low the volume is by comparison.
it is low. I have the volume on both the video and the computer up to max. then it is quite okay for me. I use external speakers, though.
Works for me.
Discussed here: http://patricklogan.blogspot.com/2009/06/on-clojure-testing-implementation-and.html On Clojure, Testing the Implementation, and Protecting Your Investment
'we should never accept a dogma' - ;-) TDD * Test driven DESIGN I'm not a fan of that. I'm even less sure about how it could be useful in the DESIGN of a 'innovative' programming language. * Test DRIVEN development I think it's like forcing to let the developer think of customer requirements (instead of just hacking for a while). For me the largest benefit of Lisp is that it enables 'domain driven development', where the domain shapes the programming language and would allow the programmer to get nearer to the customer language than things like 'test driven design' will ever get her/him. More useful I find that 'test driven development' automatically leads to a test suite. The main problem that these guys seem to have is that use of any 'real' Lisp dialect will create the **need to RETHINK the development approach** (how to write code, how the code should look like, architectures, patterns, ...) and it seems they haven't detected that yet. Lisp isn't just another Python (Python : one obvious way, Lisp: many ways) or Ruby (simplified Lisp/Smalltalk). Immediately if the programmer can shape his language in radical ways (through macros and other things) the added flexibility makes a huge difference and interactive use with something like SLIME (or the usual Lisp IDE) also makes a difference. Clojure has technical features that makes it attractive (besides being a Lisp dialect running on top of the JVM). So I guess, they might be better off using a language that has similar features (STM, ...) with less Lisp flavor.
Looks promising, it would be nice to have a working and well maintained GTK library for CL.
I'm guessing you also mean "zero cost", since I know at least Allegro CL has working and well-maintained GTK bindings.
&gt; TODO: Create a screencast Really? are we to lazy to simply read documentation and/or a tutorial?
Screencasts are complementary to tutorial/manual and they do not replace each other.
"Google App Engine Don't break when being run on Google App Engine because 'os.arch' isn't set." Very cool. Some searching around pointed me to this: http://code.google.com/p/jvmnotebook/downloads/list which might be the next step towards getting something running on GAE.
I second that, they are for different purposes. For one, while it would be a big waste of time to learn everything from a screencast, you can get a flavor of how well it will work for your purposes with zero investment. Screencasts are much more approachable than docs, especially for new libraries that are might have a barrier to installation. For instance, cl-gtk2 didn't build on both my OS X laptop or my Ubuntu box, both running SBCL 1.0.25, which was a surprise to me. I would like to see how well it works before I spend time (hours?) tracking down errors.
Oww, the writing style of this thing is awful. This is *not* a superhero *comic*, I *don't* need every other word *highlighted* for no particular reason, *thank you* very much.
Right. Admittedly I just skipped through the video but I doubt that you have things like smart symbol completion, automatic help for arglists, intelligent jump to function source location (because of macros [ce]tags wont work here), an integrated debugger, automatic multithreaded evaluation, an object inspector, presentations, or many of the other features that Slime has. Some of this stuff is dead easy to implement, but others happen behind the scenes, so it would be difficult to implement them in a screen sort of setup. For my first year of using Common Lisp I stuck with vim and used a screen hack pretty close to this. In the end, the functionality in Slime, for the most part, made learning Emacs worth my time (and trust me, it was a painful task). However, from what I hear, there are now several options for the vim user who wants to have some Slime like hackability, though they may be CL only. One thing about the screen method is that it works for anything that has a command prompt.
Could you send a message to cl-gtk2-devel mailing list or to Kalyanov.Dmitry@gmail.com about build errors? Most probably they are caused by unmet version requirements (e.g., ubuntu in its main repository has too old versions of cffi, iterate and some other libs)
That doesn't handle the HTTP GET stuff that their example covers—and the readability doesn't compare well, either. Also see the blog example.
Someone needs to take over and bring this up to date.
Interesting. I know he originally tried to implement this in elisp; this is the first I've heard of the CL version.
'Instrumentation Displays Computer Animation by Symbolics, Inc.. Graphics Division' Star Trek III, The Search for Spock http://www.startrek.gr/st/st3.htm
I'm tired of hearing about lisp machines in the past tense.
How anyone could learn enough lisp to do this, yet not learn how to properly format their source, is beyond me. single closing paren on a line by itself? wtf!
There's no accounting for taste. I came across this code recently and it really surprised me how ugly it seems to me, but I'm sure its father loves it... (defmacro bb (&amp;rest body) (cond ((null (rst body)) (fst body)) ((consp (1st body)) `(progn ,(1st body) (bb ,@(rst body)))) ((not (symbolp (1st body))) (error "~S is not a valid variable name" (1st body))) ((eq (1st body) ':mv) (if (symbolp (2nd body)) `(let ((,(2nd body) (multiple-value-list ,(3rd body)))) (bb ,@(rrrst body))) `(multiple-value-bind ,(2nd body) ,(3rd body) (bb ,@(rrrst body))))) ((eq (1st body) :db) `(destructuring-bind ,(2nd body) ,(3rd body) (declare (special ,@(find-specials (2nd body)))) (bb ,@(rrrst body)))) ; BUG: 1-arg assumption fails for with-slots ((eq (1st body) :with) `(,(intern (format nil "WITH-~A" (2nd body)) (symbol-package (2nd body))) ,(3rd body) (bb ,@(rrrst body)))) ((keywordp (1st body)) (error "~S is not a valid binding keyword" (1st body))) (t `(let ((,(1st body) ,(2nd body))) (declare (special ,@(find-specials (1st body)))) (bb ,@(rrst body)))))) Example usage (define-method is also an _improved_ version of defmethod): (define-method (view-drag-event-handler (v draggable loc0) loc) (bb f (frame v) x0 (ns:ns-rect-x f) y0 (ns:ns-rect-y f) dx (- (ns:ns-point-x loc) (ns:ns-point-x loc0) ) dy (- (ns:ns-point-y loc) (ns:ns-point-y loc0) ) (move-to v (+ x0 dx) (+ y0 dy)) )) 
&gt; Because LISP is an interpreted language Lisp is not an interpreted language. ABCL may be a Lisp interpreter, but the vast majority of Common Lisp implementations are compilers. Don't be misled just because they have as many features as (or even more than) a typical modern interpreter.
Sort of complements PLT scheme on android.
you can read it very often and it gets a bit tiresome to correct them all. The whole idea that there are 'interpreted languages' and 'compiled languages' is mostly wrong. What these people usually mean is that 'Lisp' can be used interactively - they just haven't heard that there are incremental compilers which compile even small code snippets to machine code (or here JVM code).
In this case BB simply acts as a LET* , which makes it kind of useless - though there are a few parentheses less to type. The DEFINE-METHOD macro is for programmers who want it a bit simpler with non-multi-methods and easy access to the object slots (say, like in Flavors). I'd say the author has a mix of parentophobia and 'Graham's disease'. OTOH I have some sympathy for mad programmers. ;-)
I also find it interesting that the "lisp community" has so many facets. Some groups of the "community" would find this code pretty gross, and others would find it perfectly normal...
The problem isn't how many scheme implementations you have. The problem is the quality of existing scheme implementations. 
[Rich Hickey's reply](http://groups.google.com/group/comp.lang.lisp/msg/a86c91091ae16970) was pretty informative. &gt; In short, your version doesn't compare whatsoever to what the Clojure &gt; version provides. By making the problem simpler you've destroyed its &gt; purpose, and you've avoided the illustrative challenges. &gt; &gt; The purpose of the ants sim was to demonstrate techniques for handling &gt; multithreaded applications where units of work involve consistent, &gt; arbitrary, overlapping subsets of information, and, reporting &gt; consistently on correlated data subject to concurrent modifications. &gt; The Clojure version demonstrates that and your version does not. 
pwned.
PLT and Gambit -- the only ones I've touched -- seem fine to me. The reason I don't use Scheme for actual projects is because of libraries. PLT or Chicken has something if you're lucky, otherwise... Ruby's MRI has one of the worst implementations out there, and yet a lot of people use it for fun and profit. I don't think implementation is the problem.
i can't imagine that for any additional schemes added to the list there would exist people who actively dislike them. also the word association graph is the most fun i've had all day.
Who is [Paul McAllister](http://stores.lulu.com/pj325is) and how much money does he make off of this?
and i wonder is it legal at all -- it is one thing to distribute the electronic version of the book, and another thing is to distribute it in a printed form. publisher might own exclusive rights on this...
FWIW, I used lulu to upload and print On Lisp myself a few years ago. At the time, I contacted PG about making it public, possibly even under an account owned by PG. He hemmed and hawed about the publisher possibly reprinting the book. About a year later, I finally gave up on it. A shame. Neither PG nor the publisher make a cent off overpriced used copies.
Since used copies currently cost around $120 (I saw copies at more than $250...), I'm totally happy to be able to order this one. Legal or not, it's really a great service for everyone who's trying to learn lisp.
Yes, the frontend is VB, but the glue library written in C++ is what I found most useful. Are there any other ECL examples? 
ECL rocks, its documentation does it a great disservice though. It has some killer features that are barely mentioned in the documentation! For example, with ECL you can: - Set up a lisp interpreter in your app. - Have Lisp call C functions from within this interpreter [Read this for an example](http://sourceforge.net/mailarchive/forum.php?thread_name=alpine.LNX.2.00.0902182141280.2231%40localhost.localdomain&amp;forum_name=ecls-list) That's just awesome. That means I can script as much or as little of my C++ app as I like using Lisp. 
BTW, thanks Rainer (lispm) for all the interesting links that you keep kindly posting on the Lisp reddit.
Link is dead, now.
Let's hope that some people interested in a copy had a chance to order one...
Did he compile his CLISP function? It cannot be much worse than Clojure.
Heh, i just followed a link from c.l.l to this exact code ... i was thinking about it when i started reading the file, and was not at all surprised to find BB when i did. Scary stuff, especially from such a well known and experienced lisper! 
The code has not been optimized correctly for Clozure. Too fairly compare SBCL and Clozure do this instead : (defun mv* (matrix vec) (declare (type (simple-array single-float (3 4)) matrix)) (declare (type (simple-array single-float (3)) vec)) (declare (optimize (speed 3) (safety 0))) (let ((ret (make-array 3 :initial-element 0.0f0 :element-type 'single-float))) (declare (type (simple-array single-float (3)) ret)) (loop for jj from 0 below 3 do (setf (aref ret jj) (+ (aref matrix jj 3) (loop for ii from 0 below 3 summing (* (aref vec ii) (aref matrix jj ii)) single-float)))) ret)) 
Can't judge the content, but I love the layout and colors on his site.
I don't like metabang-bind all that much, but if I had to use one or the other, it would beat BB by a long, long shot.
I dunno, but just in case since I didn't see clojure mentioned, note "Clo**j**ure" and "Clo**z**ure" are different: * [Clojure](http://clojure.org/) is a JVM-based (at least at the moment) Lisp family (but not Common Lisp) language with a particular focus on concurrency approaches the language designer is interested in. * [Clozure CL](http://www.clozure.com/clozurecl.html) is the Common Lisp implementation that used to be called OpenMCL. 
Written on Corman Lisp as a Gamebryo/Box2D wrapper plus lisp game code: http://www.youtube.com/watch?v=KY0Fmb_ScRk http://nightschool.near-time.net
I was sure that it was Clojure but now that I read it again, you're definitely correct. It's like they changed one confusing name to another. At least OpenMCL and MCL are both Common Lisps.
http://github.com/ayrnieu/ecl-examples/tree/master
elisp was too limiting.
shouldnt this be possible using http://common-lisp.net/project/external-program/
I imagine that EXTERNAL-PROGRAM wraps SB-EXT:RUN-PROGRAM on SBCL and similar functions in other implementations.
Interesting. Also, see [Common Lisp Music](http://ccrma.stanford.edu/software/clm/), and [Common Music](http://commonmusic.sourceforge.net/).
$250? That's CHEAP!!! From Amazon: &gt; 1 new from $763.76 4 used from $150.00 I assume "new" == "used but like new" So why on earth hasn't there been a new press run on this title??? Does Mr Graham own the rights? Is it in some sort of legal limbo? Has anyone just scanned it and put up a torrent?
Done. It is every good persons responsibility to report problems to developers that ask for comments.
&gt; Has anyone just scanned it and put up a torrent? The author is providing an electric copy on his website.
http://ambience.info.ucl.ac.be/download.html
Oh sweet. When did this happen? [Link to book](http://www.paulgraham.com/onlisp.html) Now if only there was a OCR'ed version of Sussman's &amp; Steele's *Art of the Interpreter*. 
clbuild, all you need. Except for elephant last time i tried. *shudders*
For all of them, I did (load (compile-file "tm.lisp")). With LispWorks, I also selected "Compile and Load" from the menu. It performed better from the menu, so I used that instead. And, as pointed out below, I used OpenMCL (aka. Clozure), not Clojure.
Why, thank you.
added bonus: it is NOT for the military, it is in Canada and people like Mark Feeley (the author of [Gambit](http://dynamo.iro.umontreal.ca/~gambit)) and Guillaume Cartier (the author of [JazzScheme](http://www.jazzscheme.org/)) are involved.
I never thought of myself as a "resource" before. The writing could certainly use a good tech editing pass. 
odd that they are doing the web part in php?
Ok, the interesting bit in this is the absolute confidence in Gambit + Jazz + Postgresql + PHP as the technology stack. We all know Lisp can "do enterprise" but anyone care to comment on how well this mix would augment the typical workflow-driven CRUD-fed enterprise situation?
I've been pondering doing some web app stuff in chicken scheme. I've reluctantly come to the conclusion that for an html templating system, I'd have to use PHP for the web-facing portion.
People are normally called 'resources' within management in most companies. It is generally less used outside the management circle as it clearly dehumanises the employees
sure - i guess i wasn't clear enough. i didn't mean they should try re-invent everything in scheme (although that does seem to be their thing). i was thinking more that they could use a proven package and still avoid php. django or rails, for example. python is surprisingly like lisp, once you start to roll with it - see norvig's http://norvig.com/python-lisp.html or even my own http://www.acooke.org/lepl/advanced.html#rewriting where i rewrite python as if it's s-expressions.
The use [Gambit-C](http://dynamo.iro.umontreal.ca/~gambit/wiki/index.php/Main_Page) a version of Gambit Scheme that compiles to C.
They're only looking for artists at the moment. :P Naughty Dog use Scheme too, of course, but they're not looking for developers either. [Adventures in Data Compilation](http://www.naughtydog.com/corporate/press/GDC%202008/AdventuresInDataCompilation.pdf) (PDF) 
It's not cdr all the way down? I find such a reanimated corpse of a dream simply revolting.
Ha, you are even more a 'fundamentalist' then I am. ;-) But the times when you could create content for Nintendo (and other game companies) on Lisp Machines is not to come back soon. For example the 3D worlds of Super Mario 64 were done using Symbolics' S-Graphics. Anyway besides the job ad, the message to get is that such games for PCs and Macs are possible to write in Scheme. I found the demo video on their web site quite cool.
Most current Lisp compilers compile to machine code. What difference does it make if that compilation process happens to go through C, for maximum portability? (Note that Gambit-C programs can run on the iPhone as a result, for example/) Or do you require that the underlying CPU be that of a Lisp Machine?
Even on a Lisp Machine you could follow this route: Scheme to C -&gt; C to Lisp -&gt; Lisp to machine code. Just use Symbolics' C compiler.
None of that, I was just flame baiting.
The only thing I learned from this review is that the book is a tutorial and not a language reference. I'm interested in the book, but this review is unhelpful.
That Link is dead.
Right... but Python is nice enough that you no longer have most of the pain that was driving you towards lisp in the first place. (Which is why I'm currently using it).
Not only does the player look nice, but I like his taste in music :)
Methinks the lady doth protest too much. Worried about the reaction to Erik Naggum's death, it is clear through his postings to various public fora that eg/rg decided to wade in and control the perception of his tangles with Naggum. Despite his attempts to prevent it, eg/rg comes out as being petty and vindictive. I laughed out loud when, in this great explanation of his relations with Naggum (a task that had been suggested to him by one of his critics on cll) he couldn't resist the temptation to take a shot at Kenny Tilton. An ironic Q.E.D. Classy to the end, that eg/rg. He would have done better just to stay quiet and accept the verdict rather than run to control the interpretation of history. Instead, in addition to being petty and vindictive with the man Naggum, he has used Naggum's memory to establish his reputation for sickening self-righteousness; if there was any doubt who Naggum was referring to when he talked about moralists and punishers, one can consider it dispelled. 
You may be right about all of that, but who really cares? Erik was extremely well known to be a curmudgeon, and was considered to be pretty entertaining by a lot of people willing to tolerate the rant aspect. I hadn't heard that Erik had died; I think that's a lot more important than eg/rg worrying about how he's perceived vis a vis Erik. Trying to look good compared with a curmudgeon is a thankless task at best. One of the sites that collected Erik quotes: http://en.wikiquote.org/wiki/Erik_Naggum
&gt; Trying to look good compared with a curmudgeon is a thankless task at best. I agree, I just wonder why eg/rg bothers, after all he has better things to do with his time in his current position. It just goes to the character flaws that I pointed out (and which have been annoying me as he has been posting his self-justifications in every single one of the places online where I like to spend my time). Why bother? Just expressing myself, exercising the same right that is claimed by eg/rg. :-)
He doesn't really make his position crystal clear, but I infer that he has a lot of mixed feelings. Socially, you're not really supposed to speak ill of the lately-departed, but c'mon, Erik really was infamous, one can't pretend that he wasn't without seeming really unnaturally saccharine. Then on top of that, eg/rg was one of the ones that really got involved in arguments with Erik rather than just watching from the sidelines (I was never more than a lurker in CLL myself, noisy though I am elsewhere). I think he wanted to do some kind of obit but didn't even clarify to himself precisely what his goal was, so it ended up being a somewhat ad hoc stream of consciousness that simply reflected his conflicted feelings. The parts of it where he's defending himself or trying to make himself look good or whatever may simply be because he's internally not sure he should be saying anything negative, but he's been at odds with Erik forever, and eg/rg is *still* taking heat even in the current comments, apparently in part from people who never heard of Erik until now but are nonetheless taking potshots -- which is to say, parts of what eg/rg is doing may be purely reactive without a lot of conscious planning. Not really sure.
The impression that I get of Erik Naggum (I went through all his cll postings on an idle day a few years ago) is that he was at a minimum over-excitable. When he flew off the handle, he usually had a good reason for doing so, though often out of proportion with with the offense. With that sort of behavior, the best policy is just not to feed the troll. His greatest flaw was pointed out by someone on cll (Tilton?) that he cared a bit too much about what other people thought, a trait that seems to be shared by eg/rg. Naggum vs cll has the character of a soap opera at times, but to the detached observer, it becomes a little theatre of human relationships and flaws that observes itself and comments upon itself as it unfolds. In the years since it ended, and especially upon Erik's death, I've quite appreciated much of the commentary on it, since there has been a good deal of wisdom about human things in the comments that many have made about it which give the tragic scene (and it is pretty close to being a tragedy in the technical sense of the word, rather than the popular sense) a value that rises a little bit above members of an online community taking potshots at each other over a period of a few years. 
Well said.
I got my copy before it was shut down. It seems that there may have been some typesetting issues, as it's missing certain letters in certain words. Still, I prefer book to pdf, so this works for me.
This guy should seriously shut up. Erik is _dead_ and gone. This guy is still whining.
I know its brief, but why isn't there anything about macros? Still, its free, so thanks. 
Agreed, although I liked that there was a decent chunk dedicated to *loop* and *format*. I feel that these kinds of tutorials don't show enough of their magic usually. Those were a couple of parts of Lisp that, early on before figuring out macros, sealed the deal for me.
&gt; For example the 3D worlds of Super Mario 64 were done using Symbolics' S-Graphics. Citation Needed ;)
Actually it was N-World, which is the port of some of s-graphics to Allegro CL: http://www.franz.com/success/customer_apps/animation_graphics/nichimen.lhtml Symbolics sold its graphics business to Nichimen. Nichimen then developed developed N-World and positioned it as a game content creation tool. Later it was ported to Windows NT and a new version (Mirai) was following later. N-World was adapted to support the Nintendo 64 game console and used by some game companies.
Ron Garred does not disappoint. I remember his c.l.l postings from three things: self-righteousness, passive aggressiveness and inability to let others to have last word. Sometimes people reveal more about themselves on-line than they realize, or can accept. Sometimes they try to patch things up afterwards. Ron Garret is stuck in some kind of death spiral where he tries to rewrite the impressions people have about him year after year, dragging himself deeper and deeper. If he stays in technical points, it's interesting to read what he says. But when it comes to his views about other people, I would not trust anything he says. It's just minor but awkward glitch in on-line personality, nothing serious. It seems that his main motivation is to improve his own image and not to intentionally smear others. 
&gt;I went through all his cll postings on an idle day a few years ago In one day? Wow! ps. does anyone know if there is achieves of c.l.l somewhere you could download. Google groups is annoying and one in AI repository is old. 
As [createuniverses noted](http://www.reddit.com/r/lisp/comments/8x4od/common_lisp_a_brief_tutorial_pdf/c0apqhw), no macros,(i checked but not by reading the whole thing) to me somewhat a deal breaker for it being a complete tutorial. (Although functions as arguments are usually a better approach then macros.) Still, it looks like a good document. So is [PCL](http://www.gigamonkeys.com/book/), so if you prefer learning from this, you can read about the macros in PCL. Btw IMO [iterate](http://common-lisp.net/project/iterate/) is better then loop in pretty much every way, except that it isn't packaged with the implementations. (To get it in ubuntu, apt-get install cl-iterate, (require :iterate), or maybe (require :asdf-install) (asdf-install:install :iterate), if you have asdf. (If you know lisp well enough: [here](http://www.lispforum.com/viewtopic.php?f=2&amp;t=295) is a discussion of various forms of iteration.)
Really? A lot of lispers consider them dubious, breaking away from usual lisp syntax. Check out [ITERATE](http://common-lisp.net/project/iterate/index.html) and [OUT](http://cs-www.cs.yale.edu/homes/dvm/format-stinks.html) for possible alternatives. Of course LOOP and FORMAT are in the standard, so there's that... 
&gt; A lot of lispers consider them dubious Wow, I had no idea they weren't liked that much. *format* maybe (e.g. outputting 2D lists is ugly), but coming from Perl it feels familiar, like printf. *loop* seems fine to me, but I'll check out iterate. Thanks.
Somehow funny, to see an implementation of one of the most unclean languages ever in one of the cleanest languages ever (in case you wonder what I'm talking about, look into R5RS and see how they defined `let` and `letrec`).
 (eq 'scheme 'lisp) -&gt; nil Meh.
 (typep 'scheme 'lisp) -&gt; T 
Gary is a great guy. He and the other Clozure guys were very helpful with a cl-opengl/cffi/clozure related issue, and along with Luis Oliveira he took the time to correspond with me and fix the problem. Details [here.](http://trac.clozure.com/ccl/ticket/527)
`(lisp? scheme) ==&gt; #t` durr hurr hurr
Scheme doesn't obey the Lisp standard, ergo it is not Lisp.
which 'Lisp standard' are you thinking of?
The Common Lisp standard which specifies a common standard for all Lisp implementations. I'm being a _bit_ facetious, of course, but I do have an actual point: Common Lisp was the product of the experience of many people working with many different Lisps; due to the plethora of incompatible Lisps they settled on a single common standard, with the idea that further ideas could be developed atop that common base. Scheme, OTOH, is another language with Lisp-like syntax. It's not a bad language, of course, although IMHO a bit of a toy. None of that is to detract from the article, which is interesting.
ANSI Common Lisp defines a standard for Common Lisp and not for Lisp. It also was not developed as "the Lisp". The US military wanted a single compatible successor of MacLisp for their projects, so the sponsored the standards activity. CLtL2, 1.1 Purpose : '**Common Lisp originated in an attempt to focus the work of several implementation groups, each of which was constructing successor implementations of MacLisp for different computers.**' One should also note that the main difference of Common Lisp from MacLisp (and its successors like Lisp Machine Lisp) comes from Scheme: lexical scoping and lexical closures. Most of these other stuff was in slightly different form already in Lisp Machine Lisp (error handling, objects, pathnames, I/O, LOOP, ...). McCarthy wants 'Lisp' to denote a family of languages not a single dialect. Otherwise the designers of Common Lisp could have claimed that Common Lisp is the Lisp and just name it 'Lisp'. But there isn't THE Lisp. If the designers of Scheme had called their language s-lisp would that have prevented misunderstandings? For me Lisp is that family, evolving over time. I'm less interested to tell anybody 'this is a Lisp'. I rather let the language designer tell me if he/she thinks that the language belongs to the Lisp family. R5RS: '**Scheme is a statically scoped and properly tail-recursive dialect of the Lisp programming language invented by Guy Lewis Steele Jr. and Gerald Jay Sussman.**' At the core Lisp stands for (IMHO) interactive programming of and with symbolic expressions. Scheme fits that. So does ISLisp, Clojure, RLisp and dozens of other languages. Scheme R6RS is a mistake and also highly controversial in the Scheme community. It will be interesting to see what comes after R6RS. Common Lisp is also accidentally misdesigned because the core was designed before the object system. I think there are reasons to explore non-oop dialects of Lisp and a Common Lisp variant that is more object-oriented. Common Lisp is personally good enough for me to use it. But I don't think it has rights to claim to be THE Lisp. Also there is and was some controversy around Common Lisp. Some people in the Lisp community don't like its particular design.
Cool idea, I wonder whether that would work at my university...
So NewLisp is not Lisp, Emacs Lisp is not Lisp, and anything that's not strictly ANSI Common Lisp (including several Common Lisps) is not Lisp, which makes for nearly all of them.
Why do you think R6RS is a mistake? &gt; Some people in the Lisp community don't like its particular design. I haven't used Common Lisp to a point I can say with full authority what sucks and what rocks from it, but I disapprove of Lisp-2 (or Lisp-n) like languages, as well as the general messy and unkempt feeling the standard library gives (which seems to be full of compromises made in favour of its heritage).
interesting but according to their [web site](http://code.roadsend.com/rphp) the compiler is going to be rewritten in c++ using LLVM
NewLisp is a joke.
R6RS specifies a batch language. It suddenly looks very complicated, too. For CL the problem was that after DARPA paid for it and then removed its funding, nobody had the money/time/will to move the standard forward. Choosing ANSI was a logic thing at the time, but who is willing to work on a standard that is 1000 pages long and the result belongs to ANSI and not the community. Personally I don't prefer Lisp-1. I don't think in a large Lisp system it is good to have just one namespace mechanism. It is good for 'clean' languages, but there is a place for Lisps that are not 'clean', but pragmatic. Schemer: "Buddha is small, clean, and serious." Lispnik: "Buddha is big, has hairy armpits, and laughs."
Enterprise professional scalable business solutions (and so on)-writing Java people say the same about Common Lisp. (Well, actually, my post is flawed. Enterprisetards haven't ever heard of Lisp.)
I heartily support ITERATE. Much better than LOOP. However, OUT and every other bright idea to make output "symbolic" is silly, for a very simple reason: every other method but FORMAT intersperses the programme's code with its output. That means you automatically fail at internationalisation of whatever it is you're printing, because you can no longer extract format strings and translate them. So you can no longer translate into languages with the word order different than English (or whatever you used originally).
Just to put the data into perspective (I elaborated on this a little during the original presentation, but not as much on the slides), this includes test code, and code written in Lisp-based DSLs. But even without this, we're safely in the 7-digit LOC range. And yes, LOC data are a bad way of assessing software anyway, but they give you a first idea and illustrate my point that you can build large software systems in Lisp. See http://www.clausbrod.de/Blog/DefinePrivatePublic20090620CommonLispInCoCreateModeling for the full blog post. 
Note that lower down I state that I was being a bit facetious. But in a very real sense, NewLisp and elisp haven't learned from the experience of Common Lisp. An emacs written in Common Lisp that could emulate elisp would be pretty much perfection, but it's sadly unlikely.
They may be tagged as easy, but they don't look easy. Of course, I'm no Lisp expert.
There is so much wrongness in this article that I propose that the author uses Python instead of Common Lisp. Alternatively he could start thinking in code. The worst thing: he talks about it **without giving an implementation**. The only thing in the article that I would agree with is that it could be useful to have a more generic accessor function. How he does it is all alien and better done in Python. * it is not Common LISP, but Common Lisp. * don't use special character syntax for operations like [foo x y]. Lisp by default uses the syntax (function arg1 .. argn). So it might be (ref foo x y). * why does he want to 'recreate it with macros', why not use a function? * what is a 'dispatch macro'? * 'prettiest'? what's that? * lst? Common Lisp is not Scheme, you might as well write 'list'. * '(list array) - that's a list of symbols. use (list list array) to create a list of values * 'represent integers as bits'? this question already looks wrong. Integers can be viewed as bits and bytes in Common Lisp: http://www.lispworks.com/documentation/lw50/CLHS/Body/12_aac.htm * he fails to show how SETF should work with his ideas. * the section where he thinks that data is made of Ts and NILs is so wrong. * **worst part**: 'this would only be slower in cases where you haven’t defined the type of the elements. And those cases usually seem to be a prototype-stadium'. I'm not sure the author understands when and how types should be used. But then he writes: &gt; Now, only the last part remains: A macro which will be implemented in any lisp-compiler which actually does this job for us. It will give programs a faster development-process, and it would be about as fast as programs without these macros as well. It’s a win-win situation. He should have provided it. I think it illustrates the difference between a Lisp programmer and a Python user: **The Lisp programmer implements his ideas how to extend the language, the Python user just speculates how it could be done.** 
at least I would make the computation of the slot values of the various classes a separate method and not clutter the INITIALIZE-INSTANCE generic function with the various methods.
Dan Weinreb is one of THE 'old' ;-) Lisp hackers. He worked at MIT and Symbolics. He worked at Object Design on the ObjectStore database. He worked at BEA (famous for their WebLogic Java application server). Now he is 'hacker' (I like that title) at ITA software. Several older Lisp hackers seem to be busy either doing non-Lisp stuff or/and have now 'strange' hobbies. Not so Dan Weinreb. He is where the action is. 'Europeans' should take the chance to meet him and hear his talk. The other speakers are also very good. Arthur and Edi have organized a very promising program (both technical and touristic ;-) ).
troll of a death
Actually I think he is right when saying, there are too much collection-accessors in common-lisp. But actually I dont see why he wants a special Syntax for it. Why not just shadow the elt-function so it works with hashtables and multidimensional arrays?
I joined this subreddit with hopes of hearing tales involving lisp speakers. The world has let me down once again.
They are easy not just in comparison to the rest, but in the sense that they are (1) relatively localized (2) we pretty much know what needs to be done and if someone with time on their hands wants to give it a try we can provide reasonable guidance. 
Scribe was written in [BLISS](http://en.wikipedia.org/wiki/BLISS_(programming_language). I am not sure what this has to do with LISP.
I think I mentioned it in the title implicitly, Symbolics Genera has an implementation of it - in 'Lisp' (system 'nsage'). It has some documentation about it, but the SCRIBE Introductory User's Manual has some more examples, etc.
PLT Scheme comes with a similar library. Except for the Jeopardy part, of course.
I learned about a nifty use of **get-output-stream-string** from this article.
The use of the stream as a buffer and not as a place to stash the ultimately computed value threw me for a bit, but it's also a little early.
There is an authorized autocad developer who works at my company. He has already designed parametric piping design software. Check it out! www.paracadd.com 
Anything good in there if you are already proficient with macros? Btw, in case you didn't realize, backquoting is really useful. Also, i often prefer (higher order) functions. For speed, these should [often be able to inline](http://www.lispforum.com/viewtopic.php?f=2&amp;t=295&amp;start=30#p2084). Intermediate lists can be avoided with either [compiler macros](http://www.lispforum.com/viewtopic.php?f=2&amp;t=295&amp;start=20#p2068), or collecting in callbacks, although that might encounter the [funarg problem](http://en.wikipedia.org/wiki/Funarg_problem). Well, all that stuff is in-principle, though, as replies in the forum pointed out, not everything is perfect..
Btw, i cannot believe there isn't a submit of this already! (And maybe it needs a submit in programming too!) It is ~14 minutes. (And the first episode already does something.)
&gt; Btw, i cannot believe there isn't a submit of this already! Actually there is... The videos used to be hosted on [lispcast.com](http://listpcast.com) so [this Reddit search](http://www.reddit.com/r/all/search?q=lispcast) is a good one to find previous discussions.
The video was informative, but the content would have been better as text (so I could copy the commands into a terminal) rather than video. Except for the part where he sipped his coffee. That was awesome, ground-breaking stuff and a perfect match for the medium of video.
I think having it as a video shows the process better, but a text version would be handy, yes :)
Why didn't they just test it?
Probably, because it is not easy to test all cases. Remember that Intel had a prominent bug in delivered processors: http://en.wikipedia.org/wiki/Pentium_FDIV_bug AMD wanted to make sure that they don't have the same problem. Interestingly they used the theorem prover ACL2, a tool written in Lisp. The ACL2 code is linked in the article. ACL itself is 'Applicative Common Lisp', a variant of Common Lisp that can be used both to prove theorems and can be executed.
AFAIR the FDIV bug was caused by something like missing LUT entries, and the algo itself was all right. That's implementation or probably even layout mistake, so the formal proof of correctness might or might not help.
From reading about the FDIV bug it looks more like a production error, but it raised the awareness for similar bugs because it cost Intel a lot of money. Intel also uses theorem proving methods to verify their designs - though they don't seem to use ACL2, but 'HOL Light'.
Die, die, die, die. Die.
&gt; To get the nice balance back, we decided that names had to be numbers that matched with the number that was the same but backwards. This is both pleasing to the eye, and really puts the screws to people who want to thwart the system using Emacs. I almost wanted to use it once I read that! 
Since white stands for the forces of good, i suggest we call it [WhitePhosphorous](http://en.wikipedia.org/wiki/White_phosphorous#Effects_on_humans)!
The funny part is that this is satire to a Lisper, but honestly contains some good ideas: &gt; The name \Lisp" is far too tarnished for a popular, modern language. Lisp *is* a crappy name, because it clarifies nothing. Lispers always say "it's not about the syntax!" but there's few other things that all Lisps have in common: lexical scoping? Not elisp. Dynamic typing? Not typed scheme. Interpreted? Not some CL implementations. If you tell someone, "I program in Lisp", all they really know about your code is it has lots of parens. &gt; Modern and popular programming languages have settled on case sensitive names with words separated by changing case (\CamelCase"). Phosphorous follows suit. Good! There's no real difference between the conventions, so you may as well go with the flow. If it would make the language easier on the majority of the programming world, why not? Why drive on the left when almost everyone else is driving on the right? Spite? &gt; After careful study, we determined the problem stemmed from the fact that all parenthesis were alike. This is actually true. Which is easier to read: int Foo(int i[]) { return i[i[0] + 1] * (2 + i[2 + (3 * 4)]); } or: int Foo(int i()) ( return i(i(0) + 1) * (2 + i(2 + (3 * 4))); ) We have all these nice glyphs available. Why not use them? &gt; Phosphorous escapes the Gosling Tarpit by means of a VirtualVirtual Machine (V2M). Some legitimately smart person can then gure out how to do continuations on the JVM once and for all and we can package it up into a callWithCurrentContinuation opcode on the V2M. Retargeting the V2M to the CLR is a work in progress. Lots of compilers use intermediate representations. One that supported targeting to the JVM and CLR would be excellent. There's a reason Scala and others do that: you get two world-class virtual machines (with different installed bases) for the price of one.
Is it 2008 already?
huh ?
Is there any evidence that there is anything more to this than a document that should have been released on April 1st?
If this turns out to be nothing more than a joke, then I'm with you.
&gt;Lisp is a crappy name, because it clarifies nothing. Lispers always say "it's not about the syntax!" but there's few other things that all Lisps have in common: lexical scoping? Not elisp. Dynamic typing? Not typed scheme. Interpreted? Not some CL implementations. "Code as data" is the (only) defining philosophy of Lisp. There are lots of things coming out of that - compile time macros and meta-circularity, but they dependant on this fundamental. The proof of it as a fundamental of lisps is that other languages take different approaches - code as objects (smalltalk), or functions (the ml family). Many of the other features that are commonly associated with Lisp languages (if as a function, functional programming in general, continuations) simply happened to originate there - they aren't fundamentally associated.
&gt; We have all these nice glyphs available. Why not use them? In your second example, you've used the same balancing glyphs for a bunch of different things (probably, since your first example looked C-ish and you just replaced all the different kinds of balanced delimiters with one). See, lisp *doesn't actually do that* (much - in practice in common lisp in particular some smartass read macros use them for other stuff, like `#(...)` for vectors etc.). Open paren means "start list", close paren means "end list". That's it, pretty much. Well, that's an oversimplification, but a better place to begin than where you are. Lisp "source" is a bunch of list literals, remember. The lists are read in, forming a tree structure in memory. That tree structure is munged by macros, then evaluated. (warning: that's also oversimplified, little things like "compilation" I'm glossing over...) Until you get that, you probably haven't "got" lisp. It's pretty important for understanding macros (well, traditional lisp macros, scheme-style macros are a bit different). 「defun foo「i」 「*「aref i 「+「aref i 0」 1」」 「+ 2 「aref i 「+ 2 「* 3 4」」」」」」 
&gt; Open paren means "start list", close paren means "end list". That's it, pretty much. Well, that's an oversimplification, but a better place to begin than where you are. I understand how Lisp syntax works. &gt; The lists are read in, forming a tree structure in memory. Every language parses to an AST. Lisp just doesn't use a very rich syntax to represent that AST. It's entirely feasible to support infix operators, different grouping tokens for blocks, lists, arrays, etc. and still get an understandable AST and macros that operate on it. If you're really in love with s-exprs, you could easily have both: a language that has a nice rich syntax, but also supports expressing the same AST using s-exprs for things like macros and code-as-data.
Good point. I didn't think about homoiconicity.
Excellent point and well said. You've also illustrated the typical use of whitespace to enhance readability. In addition to that, we generally expect Lisp editors to have parenthesis-matching, and many of them use color to highlight syntax. So to answer the question of which is easier to read, I'd say either "none of the above" or that it's irrelevant because we have much better solutions.
Reminds me of [M-expressions](http://en.wikipedia.org/wiki/M-expression)
&gt; It's entirely feasible to support infix operators, different grouping tokens for blocks, lists, arrays, etc. and still get an understandable AST and macros that operate on it. What languages support this?
Well dylan did, but unfortunately Apple made the engineers working on it cut the still-beating lisp heart out the project before they killed it. 
Hilarious. :)
Template Haskell. The trade-off is that the syntactic diversity makes it easier to read/write (this is of course subjective) but much harder to process with macros.
No, Lisp code as Lisp data is a side product. The defining philosophy is **computation with symbolic expressions**. At some point they detected that they could use this for Lisp itself. The same thing that Lisp was invented for (writing theorem manipulating software, computer algebra, ...) was then applied to Lisp.
Well, that is not unique to Lisp. Most other languages have that feature now.
Perl, Ruby, Python, C, C++, Java(script), Lua, any of these have names that describe the language? C++ refers to an iteration of C. Similarly Common Lisp is actually a good name, since it has a lot in common with all the lisps before it. Scheme, well it's a simple scheme, simplicity. That said, lisp might be a little 'worn out name'. About camelcase, maybe lisp editors should be able to automatically switch between camelcase and #\- inbetween, i personally prefer the latter. Frankly it is closer to how we write. Frankly the second example isn't really lisp, +, * can be done that way, but macros not being a list and starting with the indicator which macro is not sane for a lisp. With reader macros i could do in actual lisp: (defun foo (i) (declare (type (vector int) i)) (aref i [(aref i 0) + 1]) * [2 + (aref i [2 + 3 * 4])]) I made [unlisp](http://lisp-umac.berlios.de/unlisp.html), but all very possibly buggy (and i need to fix the lang-lisp-project banner -_-, not sure how well those \[\] work, and there could probably be a disabler of the notation again. All due to disinterest though, i made it just to see if i can in-principle. Maybe i should add [this notation](http://www.lispforum.com/viewtopic.php?f=2&amp;t=159) too. Unlisp also has := and = notation from [scope](http://lisp-umac.berlios.de/scope.html), flet,let,macrolet,symbol-macrolet being nested is often a cause for many hooks. I noticed though, that one is usually doing something wrong when you hit this problem. [Monologue in a discussion thread](http://www.lispforum.com/viewtopic.php?f=20&amp;t=300) :p, but the third post shows code that actually works with lisp, if it has the reader macros. (It is the implementation of itself though.)
Pigs can fly, with sufficient thrust.
&gt; We have all these nice glyphs available. Why not use them? I agree. Let's take this to the obvious extreme and bring back APL: ----- ∇*FOO* ⍵ (1+0/⍵)/⍵×2+(2+3×4)/⍵ ∇ ----- 
I suppose you are trying to use this aphorism to say something tiresome like "all languages other than lisp have little or no value". 
sure
Prolog
Nice indeed. Last time I checked, their Java access mechanism was a bit verbose. I hope they come up with something concise (a la Clojure?)
Franz is cool.
I liked Hanz better.
It't a lisp, it's just that the authors don't want to admit it, for whatever reasons.
Well, it does say "A++ is a Lisp-1, ...".
Looks like blog author is completely wrong -- A++ is not a purely functional programming langauge, it is just a castrated form of Scheme some guy wrote for his book. [See here](http://www.aplusplus.net/appintro.html) -- e.g. it says that imperative programming is directly supported, which means it is not a purely functional programming language. Note that it mentions Scheme few times, but does not mention how A++ is better than Scheme. So probably it is not. Actually imperative programming constructs are used in example program, e.g. (loop (gep n num) (lambda() (print c) (define n (sub n num))) is a classic imperative loop working through assignment of a variable. Then autor writes: &gt; Since all lambdas are closures, you can create a state inside of a function, then return a function which will have access to that state. This makes me think that author is [UPD: there was an insult here, but now author have updated his blog].
If you look closely you can see that LOOP is a variable which gets passed a function, for example the function WHILE. That function is then later called with (LOOP ...). Remember it is a Lisp-1.
I've noticed it. If you look closely, you'll notice "(define n ...)" line. I cannot explain it from functional programming perspective, it is a variable assignment!
sure, but it is not that unusual to study a functional language with assignment, but no mutable data. I don't think that it makes him a 'moron'.
It turns out I've missed an elephant while looking at the code -- this code is as far from functional programming as it can be at all. Functions `digit` and `digits` are called **FOR SIDE EFFECTS**. There are two side effects from these functions -- 1. they modify a "global" variable n. 2. they print stuff. At same time, return values are not use. They are not functions, they are procedures. It is 100% pure imperative programming. Real functional programming will require code to be totally restructured. If he wants to use same appoach, he then he'd need to "chain" the state (current number and string) through the course of computation. &gt; Sure, but it is not that unusual to study a functional language with assignment, but no mutable data. Under some definitions Scheme and even Common Lisp are functional programming languages. Moreover, I think most people who heard something about Scheme and CL think they are functional programming languages (while JS having absolutely same semantics is not functional). So what? Note that he calls this language not just functiona, but purely functional. Pure functions are understood as ones which completely lack side effects. (Of course, you can't do anything practical with a total lack of side effects, but they should not be present at least conceptually -- e.g. in Haskell they pretend that instead of doing IO they make a list of instructions for doing IO.) If there is a considerable number of functions which are called for side effects, it is definitely not pure functional. In given example, about 100% of functions were called for side effects... &gt; I don't think that it makes him a 'moron'. He posts very misleading article, which can totally confuse people who do not understand what is functional programming. This is very bad. By the way, I haven't seen "pure functional" mentioned anywhere on the A++ site, so this seems to be a delirium of this guy who made a blog post.
I'll admit it was temporary delirium on my part (which is a better alternative to moronity, I suppose). I've corrected the post, so as not to confuse any future readers into thinking that "purely functional" means something that it does not. I would like to point out that n is not a global variable, however. It is local to the roman function, and thus accessible to all the nested lambdas. Perhaps that's what you meant with "global" in quotes? 
Ok, thanks. Still, I do not really like your blog post. Checking your blog in general, it seems it was not even supposed to be useful. But still, as you've touched this topic (perhaps you've invested some time learning A++), and if you know Scheme, can you please write a summary how A++ is different from Scheme (either here or on your blog)? I think it might be quite interesting to a Lisp community. Particularly, I think that there is only one important difference -- lazy evaluation. If you can dig up some examples how lazy evaluation semantics can be used in Lisp, I guess that would be interesting. Thanks. &gt; Perhaps that's what you meant with "global" in quotes? Yup, technically it is a lexical/local variable, but actually function `roman` is a whole program, and variable `n` is available everywhere in this "program", so it is a global variable. At least, I see clearly how your example can be translated to BASIC which has nothing but global variables :) -- BASIC program will also have a global variable n...
&gt; Under some definitions Scheme and even Common Lisp are functional programming languages. Moreover, I think most people who heard something about Scheme and CL think they are functional programming languages (while JS having absolutely same semantics is not functional). So what? I consider both Scheme and Javascript mixed paradigm programming languages which support functional programming. However, the first is clearly oriented towards functional programming, while the last is clearly oriented towards imperative programming. While Javascript can do FP, it sucks at it because you need to pull such a big stunt in order to perform tail call elimination yourself because the language provides none. To make matters worse, it has statements (gross, though less gross than Python as at least assignment and function are not statements, and ?: is more comfortable to use), and little standard FP tools.
Check [PLT's Lazy Scheme](http://docs.plt-scheme.org/lazy/index.html) out.
Oh this would have been so much more useful as a PDF file...
What's about CL? You see, in old times it was enough to have anonymous functions to be called a functional programming language. Now most of modern languages have them, so this cheap labeling does not make sense anymore.
CL is also a mixed-paradigm programming language, but FP without tail call elimination or a pretty equivalent macro construct is somewhat pointless. At least many CL implementations guarantee tail call elimination and/or there are probably decent equivalent means to achieve this goal with macros (like what Clojure did). &gt; in old times it was enough to have anonymous functions to be called a functional programming language Under my personal criteria, that'd be a language that allows for treating functions like the data they are to some extent, and to define them anonymously, but it says nothing about the possibility of programming in a functional manner. And by the way, anonymous functions per se are not necessary for functional programming. A programming language could allow functions to be treated as data, support tail call elimination, and anything else, yet force you to name all your functions.
Good article. Also can be applied to a lot of other esoteric languages.
See [Symmetric Multiprocessing in Allegro CL](http://www.franz.com/support/documentation/current/doc/smp.htm) for more info about the API.
I didn't quite explain exactly now it's different from Scheme, but I pointed out the main aspects of it, which distinguish it from most programming languages: http://probablyprogramming.com/2009/07/15/simplicity-and-lazy-evaluation-in-a/
I'm a little surprised they're just getting around to this now. Oh, and SOAP. Just getting around to that too. I guess it's not surprising that CL isn't in more enterprise shops.
Allegro CL has SOAP support since several years now. I think you have seen a link to an article with an example from 2009. But that is not the date when they introduced SOAP support. In companies like Franz it is not that often that new complex features are developed without customers requesting it. There is little benefit from features that customers don't use. It takes time to develop features and there needs to be some market to sell to. Often the customer comes and says something like: "my app is getting larger and we are moving to a new infrastructure, we need a 64bit Common Lisp on an IBM POWER machine running under AIX, do you have a port for that?" Or the customer says: "we are moving our CAD application to Windows Vista and need OpenGL support for the following features: ..., could you please provide those?". If they had been requesting SMP and had been offering the necessary amount of money to buy/develop an SMP version, Franz would have done it long ago. Note though that it is not that easy to support and quite an effort to do it right. So, what is interesting is that there probably was not enough request/pressure/interest from customers to support symmetric multiprocessing, even though Allegro CL is available on SMP capable machines since many many years. Same for LispWorks. The upcoming LispWorks 6.0 will also support SMP. LispWorks also was available on SMP capable machines for years without supporting this feature. A few commercial Lisp offerings tried or are trying to sell into this (SMP) market: Scieneer CL and some earlier commercial adventures like Toplevel CL. For Windows Corman CL also offers SMP support. Then there were lots of research implementations done in the 90s, for example in Japan. For some reason customers/users haven't found SMP support that important. Years ago customers found it more important, for example that Lisp can be used in a distributed fashion. Remember CORBA? What has changed? My guess is that there are now more server type applications (web servers, application servers, databases, ...) written in Lisp that could use SMP and SMP hardware now is cheap and standard in Intel x86 based hardware. Problem: a few years back we had single core machines. Today laptops have two cores and desktop computers have 4, 8 or 16 cores. Changing a Common Lisp implementation from support of one core to support of four cores is already some work (if you want a robust implementation). But what about 16 cores? 64 cores? 256 cores? Without a concurrent and parallel GC using that many cores is probably not a good idea: one has 256 cores generating garbage, but only one core collecting it? But there are probably more problems with many-core machines. The next task will be to make applications that use SMP work on that many cores - for those applications that really need that many cores - remember, you can always use more than one Lisp application on an SMP machine and communicate between those.
My mistake on SOAP. I was looking at the release notes page, and that's where it was mentioned as new. Great post, thanks for that. One point. &gt; In companies like Franz it is not that often that new complex features are developed without customers requesting it. There is little benefit from features that customers don't use. It takes time to develop features and there needs to be some market to sell to. Think "Field of Dreams" here, i.e. if you build it they will come. Without current core enterprise features being **proactively** added to Allegro CL (or other major IDEs for that matter), it will remain little more than a curiosity by mainstream shops. I don't think that's really disputable, because the bulk of the money out there flowing around tools goes to Microsoft, IBM, Oracle, etc. Now, one could say this is a good thing because Franz et al focus on specialized highly-skilled niches where the absence of a feature like SOAP is surmountable and they really don't care if it's included. That's a reasonable choice to make. Actually, that does seem to be the choice they've made. I was probably expecting too much. It's debatable too whether, at this point in the market, building the perfect enterprise-capable Lisp would even be noticed anyway, so there I probably expect too much from the market as well. Oh well.
I don't think Lisp will ever make it into the Enterprise and be the COBOL replacement like Java is. I agree that it is useful to stay competitive, though. It seems that Lisp implementations have other roles in Enterprises (if at all) and SMP support has not been one that was in demand. Lisp applications did not tend to fall into the pattern of lots of small computations, but more into the pattern of *many large computations*. American Express for example checks some credit card transactions with a Lisp application. The bulk of transactions is computed with other systems. But some that require more knowledge to process are given to this application. What they use is a bunch of machines running several Lisp images. The request comes in and the Lisp does its magic. There is probably little or no communication needed between the various requests. So running one Lisp with several concurrent threads does not help to reduce communication - because there is little. This model is changing now. Lisp can be the database serving huge amounts of requests from huge amounts of data, it can be a web server, it could be the eco system for many agents, etc. The older model is to have one Lisp that can concurrently run a single Lisp thread, but multiple foreign function threads. A database for example would do the Lisp computation in the single thread, but the external communication to disks or the network in the foreign functions. This could be changed with a concurrent Lisp (minus the non-concurrent, (worst case) serial GC) A problem Lisp has is the culture it should promote: the responsible, educated and empowered software developer. (sometimes it is the genius, the insane, ... ;-) ). Not something that is looked for in large enterprises. They look for cheap, replaceable, out-sourceable developers that code down the requirements. If you would start building groups of Lisp developers in an enterprise than you need an culture change both at the company and the developers would need to use their 'freedom' wisely. One thing that I found missing is that relatively often people give up their tools and don't support them once they are in the customer role as they should. They buy shitty software (for job safety) instead of helping building better infrastructure, one library at a time.
Using Lisp mostly for projects in my free time. Currently playing with [cl-alsa](http://www3.telus.net/public/thomasw2/cl-alsa.html) and making some simple Lispy music with it.
Mostly Elisp. Hacking on org-mode.
Statistical analysis, network programming, random shell script replacements, data charting using vecto, general programming and rapid algorithmic testing. Fun, mostly.
I live in Dallas, and work in the ecommerce dept of a phone app company. Although, I've been interested in Lisp for a few years, I never had time to doing anything beyond playing with it in my sparse free time. When the company decided to "formalize" their code release process, I took over that role. Initially, the scripting that I did for my job was in bash, but I've been writing more of it in Lisp (with the help of Drakma &amp; CXML). Eventually, I'd like to move most, if not all, of it to Lisp, and use Hunchentoot to create a dashboard to control the various tasks that I've got to do. Outside of that, I'd like to get a better handle on using CCL's Cocoa bridge, and just explore.
here's an incomplete list of what i'm working on in CL these days. * MaxClaims : A web based insurance claims tracker (ucw, lol, rofl + postgres) * CL-ORG-MODE : an extensible recursive descent parser for org-mode files. * ORG-LITERATE-PROGRAMMING : A literate programming system that extracts source code from org-mode files (uses the above parser). * UCliki : A UCW based cliki-compatible wiki (used for wiki.alu.org) * Lisp-on-lines: My web framework * Relational-objects-for-lisp : My O/R mapping * Uncommon Web : I am the maintainer of UCW * CL-WEBKIT-GTK : My webkit-gtk based CL web browser * CLtL3 : I'm currently writing the CLtL3 charter, and researching portable lexical environments. Those are the big ones that take up most of my time.. there are a few other projects that i hack on as well, almost all in Common Lisp. 
I'm trying to do some concurrent processing of a Machine Learning type nature for research. Most languages that are good at one of those seem to be bad at the other, and this being the case I figured I might as well use a language where I get to write my own syntax. 
*tldr; scheme, cl, graphing/networks, list/set comparisons* Randomly using CL and Scheme whenever I can. I shifted over to Smalltalk for the last 6 months or so. Some elisp here and there. I actually restarted the Toronto Lisp meetups a few years back, however I haven't been to a meetup in a while (school/work, ugh). Right now I'm trying to use CL for a custom fine-grained version control system (just a prototype for a paper I'm kinda writing). Also was using it to optimize trade routes for EVE Online, but gah, there's a shitload of data to grab before any optimization can happen, so I gave up...
How are you making the music? :o
Are you trying to be the next [Edi Weitz](http://weitz.de/)? Where's the code for cl-org-mode and cl-webkit-gtk? :S
In short, I can map a function to a scale, then send it to a series of filters. For instance, [this](http://eriknomitch.com/misc/function.wav) is cosine mapped to a (I believe) C major scale. The function that creates the melody "samples" the melody function (cos) at 1/32nd notes in this case kind of like [this](http://eriknomitch.com/misc/scale.png).
I am doing the website: http://BullzBearz.com in my spare time with SBCL. My goal is to have it do charting (that is, technical analysis of stocks) online using stuff like Ajax. Currently all I have done on it is a forum/blog. I have open-sourced the basic code for the site as a framework, which is currently really in the early levels of usability. You can get it here if you want to take a look: http://cgore.com/computing/lisp/bzbz/ I hope to have it really usable in a year or so.
Hey OMouse, long time no see! cl-org-mode will be on cl-net shortly, and hopefully part of clbuild soon after that. cl-webkit-gtk is currently nowhere near release-worthy, it's more of a quick hack that's fun to play with then something usable. CFFI makes it all _very_ easy... good times. I'd have to release a lot more libraries and make excellent documentation to get anywhere near Edi ... he's still the champ. :) 
Currently hobby projects: genetic algorithms, cellular automata simulators, games and Project Euler problems. Eventually I'd like to port some Perl modules that I often use (DateTime and some of the Email:: packages) to Lisp.
I used Lisp a lot when I was working as a post-doc a year back, doing Monte Carlo simulations, and it looks like I may have the opportunity to go back to work on the same project a little bit in the near future. I miss it; my day job is all coding in Mathematica now, and while there are worse languages, it misses way too many of the things that make Common Lisp pleasant. 
I mostly use lisp via emacs, and I'm glad to say that a couple of the scripts I've written myself I use every day. Emacs rocks. I've also written a small schemeish interpreter, which was fun. Nothing too complicated, but being metacircular does help a lot.
Yes! org-literate-programming is *exactly* what I have been daydreaming of. What are the chances of it supporting python?
Small time hacking in emacs. Still, little hacks with elisp are worth more than much bigger hacks in other scripting languages for productivity, since I spend so much time in emacs.
I'm coding the cl-gtk2 binding and maintain cl-sqlite. Other than that, I use Lisp for "for fun" projects, solving projecteuler.net problems, icfpc. I've used Lisp for my student research projects and intend.
I don't do a lot of actual Lisp programming, but I do [research on static analyzers](http://matt.might.net/) for Lispish (more Schemish) languages. My work always applies to other languages, but Scheme is a great target for research.
&gt; researching portable lexical environments Do you know about: http://www.flownet.com/ron/lisp/lexicons.pdf and http://www.flownet.com/ron/lisp/lexicons.lisp ?
I'm doing a lot of miscellaneous hacking using Clozure Common Lisp, mostly seeing if it's ready for prime time (it's looking pretty good). Right now I'm working on a web crawler. It seems to be coming together quite nicely. The state of available libraries is not quite up to Python or Perl standards, but it's a heck of a lot better than it was the last time I looked a few years ago.
l-system plant modeling
&gt; * Lisp-on-lines: My web framework &gt; * Uncommon Web : I am the maintainer of UCW Don't those two conflict/overlap? Why'd you write your own web framework while being the maintainer of another?
SBCL for financial stuff
I have really enjoyed using CL for several years now. I started and maintain [Planet Lisp](http://planet.lisp.org/). I've written [some stuff](http://xach.com/lisp/) for doing graphics and web work. I'm interested in practical tools. I love libraries like CXML, Ironclad, Drakma, postmodern, cl-ppcre, CFFI etc. that let me do a lot of modern programming tasks without leaving Common Lisp. I try to write and release libraries like that myself, when I have time. 
because programming is fun!
I created StumpWM and use lispworks to do psychology research. In addition, I tried to write a drop in replacement for Emacs called LiCE (Lisp Computing Environment) by converting Emacs' C code to lisp and using macros and tricks to run elisp natively on CL. It was one of my first projects and the code is terrible. Handbombing C to lisp is also really boring. Probably an indication that I should have automated it. Also, I tried my hand at writing a Go server and client using ltk (I think). It was functional enough to join/part channels and negotiate and play games. I abandoned it when I decided I'd rather just play Go.
&gt; # CLtL3 : I'm currently writing the CLtL3 charter, and researching portable lexical environments. Will there be input/participation from the CL community on this? CL desperately needs revising!
I'm using Scheme to present solutions to the exercises at my blog [Programming Praxis](http://programmingpraxis.com).
nice
I'm new to lisp, but after a few months of playing around, I really like how fast things can be done and modified. I aim to use cl for writing most of my programs for work (e.g. physics simulations, data processing), as well as some hobbying around. Up to a few months ago, I've mostly been using C, python and OCaml, but am in the process of dumping the latter two in favour of cl, due to speed (devel time when compared to OCaml, runtime when compared to python).
I wrote (and maintain) a bounded model checker written in CL. I also wrote some research prototypes in Scheme: a SAT-based parser and completer for tiling systems, and some parsers for some classes of picture grammars.
Working on CoCreate Modeling, a 3D CAD application. CL is one of the two main implementation languages, and our main administration/scripting/customization/extension language for customers and partners. See http://www.clausbrod.de/Blog/DefinePrivatePublic20090620CommonLispInCoCreateModeling for a presentation I gave recently at the European Lisp Symposium in Milan. 
&gt; CL desperately needs revising! Just curious, which things would you like tackled first? Also, it's not like there were many people writing [CDRs](http://cdr.eurolisp.org/), or pressing vendors to adopt them...
Lisp on Lines is built upon Uncommon Web. UCW is extremely flexible and has been split into a -core and -standard; -core provides the extremely flexible metaframework, and -standard is just one of many frameworks that can be built using it. LoL is another.
&gt;Emacs' C code to lisp and using macros and tricks to run elisp natively on CL Have you taken a look at what's going on with Guile and its VM? THere's a dev who wants to get elisp running on top of it :o
Mostly Elisp and Clojure: * [relax.el](http://github.com/technomancy/relax.el) Emacs CouchDB client * [Emacs Starter Kit](http://github.com/technomancy/emacs-starter-kit) For newbies * [clojure-mode](http://github.com/technomancy/clojure-mode) and [swank-clojure](http://github.com/technomancy/swank-clojure) for Clojure hacking * [clojure-http-client](http://github.com/technomancy/clojure-http-client) What it says on the box * [mire](http://github.com/technomancy/mire) A multiplayer text adventure in Clojure. Mostly for learning from as an example. * [corkscrew](http://github.com/technomancy/corkscrew) a depedency manager for Clojure
I am primarily a Flash game developer, but I use Lisp whenever I can, mostly to support my Flash work. I have written a (rather weak) swf obfuscator in Lisp, a server to catch debug output from swfs, a genetic algorithm level generator for a game, and a back end for user generated levels for another game. Our website also runs on Hunchentoot, which has been really great, especially when we need to tack on some quick dynamic content for a game demo, such as a hi-score system. I would like to develop games in Lisp, but I haven't yet found a good delivery model or business plan for it. The most promising, currently, is probably compiling down to something that runs on iPhone. In the meantime, we will probably work on web-based content. 
I'm adding widgets (and making sure it's asdf installable) to Kenny Tilton's celtk. Let me know if a) you want some widget that doesn't currently exist, or b) you can't install it using asdf. I'm using github to host my changes but so far, Kenny's been cool about incorporating added features back into cvs. Here's the code: http://github.com/cddr/celtk/tree/master
SELC was targeting [Scheme48](http://s48.org/), but it seems mostly dead. The [SELC paper](http://www-pu.informatik.uni-tuebingen.de/users/knauel/selc-ifl.pdf) states that ELisp has around 1800 primitive functions (C code), many just added as speed optimizations. That's some tedious back-translation work.
How far did you get with LiCE? I've been thinking that's the right approach to take for a next-gen emacs, but the magnitude of the effort is...daunting.
Oh, I see. It's sort of esoteric without actually having used it, but I can see your point.
I made a bunch of websites in CL and later Clojure. I use Clojure for daily data munging and reporting tasks at work and I wrote a couple tiny Qt4 desktop apps. I am hoping to learn enough so that I can create and contribute something worthwhile eventually.
Very good. Right now it's entirely language independent, and i intend to keep it that way.
Yes, it's meant to be a community effort. Check out the cltl3 project at cl-net and join the mailing list if you want to participate
Doing various sorts of fun things in CL. Also trying to bootstrap my own company doing CL development, initially with one product in [Weblocks](http://weblocks.viridian-project.de/) I'm working on currently, though I'm not married to the idea of doing webapps. What I want is to work on interesting things in Lisp, and both the web programming and the company are simply means to that end; if another awesome project comes along, I'm all for that.
Used PLT Scheme to implement a structured data compiler with scripting system to specify all kinds of stuff for Uncharted 2 for the PS3. [Here's](http://www.naughtydog.com/corporate/press/GDC%202008/AdventuresInDataCompilation.pdf) (pdf) a short presentation on it.
Thanks for the great responses! Keep responding, if you like to tell what you are doing with Lisp. I've counted 29 people responding so far (18. July 2009). My rough interpretation: Popular dialects: 22 CL, 6 Scheme, 3 Elisp, 2 Clojure. Usage: 18 as hobby, 10 at work, 5 for research. Domains: 14 misc applications, 9 tools, 8 web, 6 user interface, 4 game. There is not that much I would classify as AI related.
And [here](http://www.gameenginebook.com/gdc09-statescripting-uncharted2.pdf) (pdf - 40MB) is a long presentation on it. It looks like exactly what one would want in a scripting language for a game, tracks and continuations. I wish I had the skills to adjust/make/integrate scheme into my primitive engine like that. Oh, and I love Uncharted, can't wait for 2!
I don't suppose you have a preview?
1. I think you mean [Clojure][1]. 2. Clojure runs on the JVM and integrates well with it, therefor being immediately useful within existing Java codebases. 3. You should be happy that Lisp is getting attention as-is! [1]: http://en.wikipedia.org/wiki/Clojure
Qi is going to die because Mark Tarver doesn't understand business and because he doesn't understand how software communities are built. He's got it in his head that he can get rich off of Qi book sales, and has sacrificed the long-term viability of Qi in search of some short-term cash. PS: Read Tarver's usenet rants against free software for a laugh.
What makes languages popular is difficult to gauge. They are essentially a product with a really unusual marketing pattern. I'm not massively familiar with Qi (though it looks good), but most of the other very modern functional languages like that tend to "take off" (I mean that in the same way that Haskell has "taken off") because they have a strong academic community behind them. I'm thinking of SML/NJ and Haskell as examples. Agda will probably happen to, it's really big in research departments. AFAIK, Qi does not have a large research community behind it. Clojure and Scala, however, are a slightly different thing. They're more industry-oriented. The biggest factor for Clojure is probably that it already supports most of the existing Java libraries and contains some nice concurrency primitives and structures.
You are just trying to spark off a flame-fest aren't you? 
Clojure is compelling to me because of its clean integration with the Java platform: lots of libraries, excellent performance, and a good concurrency story.
I thought you were trying to say you were working on a flying pig.
Just curious on a related topic. Can you (somewhat easily) get the reader to switch readtables when it reads something like `(macro1...` it can read the rest of the form using a custom readtable? A different macro (`macro2`) could also use a custom readtable. It would make it easier to re-use the same characters in different situations. Given how powerful the readtable is I'm surprised you are forced to manually write your own state machine.
No, I usually work in an office.
&gt; and has sacrificed the long-term viability of Qi in search of some short-term cash. Could you elaborate on that? What aspects were sacrificed and in what way? I agree that Tarver is a curious individual, but I haven't followed him and Qi enough to be able to form a solid opinion.
I have several little projects that you can find on cliki, but maybe my most useful is dso-parse, a PEG parser generator. I'm also using SBCL and many libraries (thanks everyone!) to make financial-analysis applications with web front-ends. Nothing polished for public consumption yet, though.
This thread is flame bait. His personal opinion is that Qi is better than Clojure, and he states it as fact. He also proceeds to spell Clojure wrong, twice. The reason people like Clojure is most people already know Java, and those, and those who don't indeed realize that with a platform like the JVM, they get hundreds of thousands of libraries for free. Clojure's Java interop is clean and natural, and it has a great concurrency story. It's on the JVM, so it's fast. People resonate with it. I honestly believe it's going somewhere.
Long time programmer. Currently building an industrial-strength low-latency financial application that otherwise would have been written in C++.
My mistake on the spelling. I didn't notice until after the submission. So you're admitting Clojure is for the java flows? What about the die hard lisp who have been waiting for another lisp revolution? What do they get? If the lisp community would focus their efforts on 1 or 2 implementations from the dozens of CL and hundreds of Scheme reimplementations I think we would be in way better shape. How should we start this? I don't think going out and creating another lisp is the answer. I feel we should start creating a new CL standard that is more... modern? Or guile if it ever takes off as a replacement in Emacs.
Well, the JVM is a fantastic VM--why not just extend or "fix" Clojure?
I know we're getting off topic, but you don't hear too many serious lispers switch off to Smalltalk. Which distribution are you using, and what are you reactions? I looked at etoys for my kids--they're still little, but my daughter loved drawing things and then making them go.
Well, that depends on what you consider easy and what you want to do. You've got some some level mixing there - a `(macro1 ...)` syntax would be expected by lispers to be an "ordinary" macro applied only after reading is complete in the first place. It is however AFAIK reasonable enough to define a *read macro* (a different thing to an ordinary macro, set-macro-character establishes them in readtables), e.g. `#macro1(...)` say that switched to a custom readtable though and does a recursive READ. However, some careful attention does need to be be paid to termination conditions depending on what that `...` (or actually `(...)`) is. Also remember Common Lisp READ is not a general parser, it's essentially for at least vaguely-lispy-looking stuff, though readmacros give you a trapdoor into a place you can hang a general parser. ;; handy to keep a backup when you're fooling ;; around with readtables (defvar *backup-readtable* (copy-readtable)) (defvar *my-readtable* (copy-readtable)) (defvar *my-preserve-readtable* (copy-readtable *my-readtable*)) (setf (readtable-case *my-preserve-readtable*) :preserve) ; this could be much more complex (defun preserving-reader (stream char) (declare (ignore char)) (let ((*readtable* *my-preserve-readtable*)) (read stream t nil t))) ;; you could use more complex dispatching stuff here if you ;; wanted lots of different readtable-switching reader macros, ;; remember this is only an example (set-macro-character #\$ #'preserving-reader nil *my-readtable*) (defvar *example-string* "(Hello there $(This Is A Test) How did it go?)") (let ((*readtable* *my-readtable*)) (read-from-string *example-string*)) =&gt; (HELLO THERE, (|This| |Is| A |Test|) HOW DID IT GO?) 46 
I was using Squeak and I just really wanted to try out Seaside. The trouble is, as always, a lack of good documentation. Seaside itself wasn't bad but I couldn't make heads or tails of what to do with some of the classes or methods. I also found it difficult to start coding anything with Morphic and I really would have liked to make a GUI in Squeak. Other than that, it was very easy to pick up the language and start using things and the fact that it's a *system* was excellent. Made organizing code very easy. What books/docs did you use to get the kids started with etoys?
guile? bleh. elisp on scheme? bleh :).
http://repo.or.cz/w/lice.git Have at'r. I think it compiles.
Used CL (CMUCL &amp; Allegro) to write the air and hotel search and books systems for my x-employer which got them from 0 to third position in the Indian travel market. Most of our minuscule downtime was because we could not manage (did not have the expertise) our 'enterprise' Oracle setup. The systems took as much traffic (and bursts) as got thrown at it. But now the systems are being rewritten in a more 'enterprise' level platform, namely Java by a more professional and 'enterprisy' team of senior 'experts' with 'experience' in the US. :) But I think if you go now to cleartrip.com you still get a homepage and the air search thrown up using Hunchentoot and the CL system! Kudos and a big Thank YOU to Edi! You'z the dude!
All of these written in CL: Personal stuff: - Little apps for myself to use twitter and the API of my cellphone operator. - Some addons for StumpWM (never released any though). Reading up on the source code of StumpWM so I can hopefully contribute to the development later. Work stuff: - A program that automates tape changing in the backup system. - A reporting site (hunchentoot+cl-sql) for displaying results of automatic tests. - A tool that parses an EDID dump of a display to create configuration files for our in-house display controllers. - Server software to control our in-house display controllers. (encoding to a binary format and sending across the network)
Well, we haven't done much. They're still learning how to read, so it's mostly my daughter who draws the pictures while I make them run around. As for docs, I just used the following online links: 1) http://waveplace.com/resources/tutorials/ 2) http://waveplace.com/resources/tutorials/old.jsp 3) http://www.etoysillinois.org/library.php I couldn't find much else out there. EDIT: how do i put in hard returns
Thanks for the link...I've passed it on to some folks. Who knows--maybe someday it'll be something.
As unknown_lamer mentioned. because UCW and LOL serve different purposes... but even if they didn't it's easy to imagine different approaches to web development that might require their own framework... i've got thoughts about another one if i ever get the time. 
Count me in: - Gambit Scheme as a hobby (I'm reading SICP) - Clojure at work to create unit-tests for a Java app
I'm interested in using Lisp in the following ways: - Embedding it in a larger app so it can be used as a scripting language - Enjoying a live coding experience by having a lisp repl available during a simulation or game - Transferring more and more control to the lisp scripts, learning lisp in the process 
Long-time Emacs user, "came back" to Lisp around 2005 with PCL. Currently active in developing [ABCL](http://common-lisp.net/project/armedbear/), a CL implementation that runs on the Java VM.
cool.
 \|||/ (o o) ,~~~ooO~~(_)~~~~~~~~~, | Please | | don't feed the | | TROLL! | '~~~~~~~~~~~~~~ooO~~~' |__|__| || || ooO Ooo
you're a real clojure-fanatic, arent you? ^^
Finally someone who is neutral about Clojire.
Yes sir.
I find it interesting, unfortunately the sound is recorded under water...
clpython? That's rather epic!
Clozure CL... ...but Perl is a close second! *EDIT*: Actually, I wish I said ECL, but it still has some bugs with threading and unicode. Until then, I'm still doing more CL in Clozure/OpenMCL.
I like Franz's Common Lisp (expensive though). SBCL is free and also very good. For Scheme, I like Gambit-C because it can generate small fast native compiled applications with a few millisecond start up times. Clozure and GNU CLisp are also worth a careful look. I used CLisp for the examples in my free web book "Loving Lisp, or the Savvy Programmer's Secret Weapon" (old, wrote it in 2002 - but free :-) 
SBCL on Linux. It's the second implementation I tried (after CMUCL), and I've grown used to how it works. It's pretty easy to get fast code by paying attention to the compiler notes. It is well-supported by SLIME. You don't have to resort to implementation-specific declarations to get fast modular arithmetic. It has good Linux threads support and acceptable Unicode support. I've contributed patches and ideas and had them accepted. There are a few minor things I don't like (sb-posix and sb-bsd-sockets interfaces spring to mind) but for the most part I really enjoy writing applications with it.
SBCL, although I never really tried many others...SBCL seems like the most up-to-date...or at least the most developed.
Yup, SBCL is quite good. Other cool things about SBCL: the statistical profiler, and the code coverage tool.
Clojure. Tons of libraries, fast, well known VM, etc.
Clozure. It runs on everything, has a great Objective-C bridge, an IDE and Cocoa integration (if you're on a Mac), a lightning-fast compiler, and it's free. If you haven't tried it lately you really should. It is much improved recently.
well, thats ok. the more lisp-fans the better.
Custom dialect with custom VM and native compiler, because I understand the system from the ground up and add the things I like (basically, a mix of things from Qi, Scheme, CL, Otter, Lush, Clojure, Python, Ruby, with a KSM-style FFI). It's defined as minimally as possible (the only addition to Scheme would be [] for vectors, {} for dictionaries, Clojure/Arc/Lush-style data structure application and the FFI), with batteries defined within the language itself (such as a require system, module system, &amp;c.). Great way to learn lisp, and make the language you want...
Perl? Isn't that a Lisp with that crazy linguist dude at the helm? I'm just saying..
Is your custom dialect a private project, or have you released it?
PERL = Perversion Excused by Random Lispiness 
SBCL on linux boxen. Fast. Recent release 1.0.29 provides an implementation-independent call to get-time-of-day that includes microseconds in its return. Neat to see time stamps in the log file with that resolution and see how fast some stuff really is.
In addition to what createuniverses said, if it is currently private, would you mind releasing it?
You are not allowed to use a ”)” both as a closing parenthesis and the mouth of a smiley; it is parenthesis exploitation. You would think that lispers should know about these things.
It's a private project atm, simply because it isn't finshed. There is a spec for it (defined in levels, to avoid the disaster that R6RS became, imho), and I'm just bringing the reference implementation in line with the spec. I don't wish to pull an Otter (great presentation at LispNYC, then nothing) nor an Arc (finish a basic subset of my over-arching idea, only to have to explain that it's not finished, &amp;c.). I will say though that I have replaced *most* of my daily lisping with it, and the few things left are minor really: syntax expansion (it has syntax rules and CL-style unhygenic macros), the back end storage for dictionaries (I currently have hash, trie &amp; radix tree based implementations), the base libraries (misc. algorithms, cryptography, data structures, strings, network protocols, &amp;c. I have libraries that I needed for a specific project, but I want to flush it out) and complete the OS (POSIX) interface (technically, I could do this with the FFI, but I'd like for this to reside in a "pre-loaded" module within the VM itself). I've no problem releasing it, once finished. I'll put the repository up at http://github.com/define-macro when finished.
That's excellent. Do you plan on making it embeddable? By that I mean, release your lisp as a library so other programs can initialize their own lisp environments.
It currently has a Ruby/S-Lang-style CAPI for "embedding"; the main REPL is actually an example of this: it calls register\_procedure for human interface things (like an interactive debugger and a "quit" procedure). Since you can create evaluation environments for eval (i.e. create an environment with (clone-default-env) and (define-in-env cloned-env something-destructive (fn (x) ...)) (eval '(something-destructive) cloned-env)), the register\_procedure is setup to mimic rb\_define\_method, where you pass an environment. Other than that, it's mostly llread and lleval. There is no eval-string yet, but that's easy enough to implement. *So in the most long winded way possible*, yes, it's embeddable now ^_^
That sounds fantastic. I will definitely keep an eye out for it!
The second user... ^_^
[Obligatory.](http://xkcd.com/541/)
+1 for Clojure, I use it at work because it's a Lisp in a world of Java frameworks. I also like [TinyScheme](http://tinyscheme.sourceforge.net/home.html) as the embedded language of an application.
Stop messing around with your tools and get back to hacking!
Our own Lisp implementation ( http://www.clausbrod.de/Blog/DefinePrivatePublic20090620CommonLispInCoCreateModeling ) because I get to hack at it every once in a while 8-) And ECL ( http://ecls.sourceforge.net/ ), because Juanjo, the chief maintainer, does such a brilliant job in fixing and extending the implementation. 
Gambit is cool, but do you know of any tutorials on how to create really small binaries with it? Using onlu the subset of the scheme runtime that is needed etc.
ECL, because it is the only lisp that support native executable generation and threads on all platforms. On the bad side, library support is not that great, but things are improving. CCL would be also nice for the same reasons if I could run it on my non SSE2 laptop. SBCL is good, but is basically linux only.
great that you have made some information available. What does 'HCL' stand for? Since you are now working for PTC, what happened with their design software written in Lisp? Is it rewritten in C++ or does it still have traces of Lisp? I once heard a presentation about it at some Lisp conference several years ago. It was based on the CDRS (conceptual design and rendering system) software they bought from Evans &amp; Sutherland.
I don't think Mark has anywhere said he thinks he can get rich off Qi book sales. He's simply attached a commercial license to the book which he has the right to do. And the license gives *you* the right to do whatever you want with your own code. Very simple really. And the book is cheap so what's the beef? Much better than being stuck with the GPL. Not everybody wants or supports the free open source movement and Mark like Ken Pitman seems not to be keen on it. I don't see why this makes him or Mark wrong. And I don't see that Mark Tarver's choice prevents me from using Qi since I've got the book and it gives me complete rights to push out my closed source Qi programs if I want. Sounds to me that you have a case of religion. Clojure is more popular than Qi because it appeals to a large existing user base of Javaheads and its using idioms that people are familiar with. Its straightforwardly commercial. Qi uses ideas like sequent calculus which people mostly don't grasp yet. 
DrScheme (PLT scheme) and LispMe (actually a scheme implementation for palm os)
Allegro CL, if you can pay for it. Great documentation, good support from Franz. SBCL, which is free and open-source, also works pretty well.
My favorite was [Macintosh Common Lisp](ftp://ftp.clozure.com/pub/MCL/MCL-5.2-Final.dmg) way back when. These days, it's emacs+SLIME+{[Clozure](http://trac.clozure.com/openmcl) | [SBCL](http://sbcl.sourceforge.net/)}. Clozure's my default, but sometimes I switch to SBCL for single-stepping in the debugger. My reasons for preferring Clozure are mostly historic, though I find its source a little easier to digest than SBCL's. YMMV.
The origins of the name "HCL" are kind of lost in history 8-) I guess the official explanation for the "H" has to do with the fact that when we started the project, we were part of **H**ewlett-Packard. Inofficially, I always found it a striking coincidence that the first names of both hackers who introduced Lisp into our code started with "H"... About CDRS: Apparently, PTC bought CDRS in 1995, but I have no idea what became of it, sorry.
If you need tiny binaries you can try Chicken Scheme, the compiler supports the -explicit-use option for this exactly. http://chicken.wiki.br/man/4/Using%20the%20compiler
SBCL, although tbh i haven't tried others much. Not much inclination too.
Elisp - it lets me customize my work environment to function exactly how I want. It comes with built-in documentation and a superb way of interacting with text, files, and the operating system. It has it's limitations, but as far as productivity is concerned, I bet more people use elisp than any other version of lisp. They just don't talk about it.
SBCL on Linux, and scheme48 (I install that everywhere). But I end up writing mostly in Elisp these days.
Bonus points for its excellent immutable data structures; makes concurrency _much_ easier to deal with. Plus it's really simple, which is refreshing after looking at CL.
Wow, just wow!! Answer to one innocent ask.reddit question reveals new Common Lisp implementation nobody knew about.
It doesn't sound like a Common Lisp impl, rather a new lisp dialect all together. It does sound interesting, though. 
I'll attempt to post design notes tonight, instead of comments spread out across multiple comments. As a quick point, it's not a Common Lisp implementation, but a dialect of Scheme with items thrown in from other places...
I'll attempt to post design notes tonight, but as a quick note, it's not a Common Lisp implementation, but a dialect of Scheme with things pulled in from all over...
Looks good :D
Thanks for responding. Keep adding your favorite Lisp! So far, my impression: reddit Lispers use several different Lisp implementations and Lisp dialects: CL, Scheme, Elisp, Clojure. Common Lisp is the favorite. The favorite implementation is SBCL. Clozure CL is also mentioned a couple of times. About OS preference there can't be said much, but Linux is mentioned several times. Numbers of mentioning the use of an implementation: SBCL 11, Clozure CL 4, Clojure, Allegro CL 2, ECL 2. Elisp 2, plus lots others.
Moved to clojure after 2 years of sbcl and Lispworks. Ton's of libraries. I need a work to do, not to spend my time implementing everything from scratch or fighting with FFI. 
Unoptimized, but compiled. Just the code thrown at the REPL or compiled from the editor. Including GC time, etc. **Apple MacBook Pro, 2.33 GHz** CCL 1.3 : 5.856 seconds SBCL 1.0.22 : somewhere between 6 and 1.2 seconds SBCL 1.0.22 : v1, 0.525 seconds SBCL 1.0.22 : optimized version, 0.3 seconds **Symbolics NXP 1000** Genera 8.3 : 390 seconds **SUN U10, SPARC, 333Mhz** SCL : 65 seconds **Linux, Intel T2370, 1.73 Ghz** SBCL 1.0.28 : 1.510 seconds **Linux, Intel Xeon L5420, 2.50 Ghz** SBCL 1.0.28 : 0.822 seconds 
The code from above linked blog post by jgrant: edit 1: changed (floor (/ a b)) to (floor a b) (defun machin-pi (digits) "Calculates PI digits using fixed point arithmetic and Machin's formula with double recursion" (labels ((arccot-minus (xsq n xpower) (let ((term (floor xpower n))) (if (= term 0) 0 (- (arccot-plus xsq (+ n 2) (floor xpower xsq)) term)))) (arccot-plus (xsq n xpower) (let ((term (floor (/ xpower n)))) (if (= term 0) 0 (+ (arccot-minus xsq (+ n 2) (floor xpower xsq)) term)))) (arccot (x unity) (let ((xpower (floor unity x))) (arccot-plus (* x x) 1 xpower)))) (let* ((unity (expt 10 (+ digits 10))) (thispi (* 4 (- (* 4 (arccot 5 unity)) (arccot 239 unity))))) (floor thispi (expt 10 10))))) (compile 'machin-pi) Call: (time (machin-pi 10000)) 
Part 4 and 5 are not missing! They are here: http://www.youtube.com/watch?v=HkwQTueJPiE and http://www.youtube.com/watch?v=DzAINMhPK7c
Also unoptimized, but compiled. Linux 2.6.30-ARCH #1 SMP PREEMPT i686 AMD Turion(tm) 64 Mobile Technology MT-30 1.6GHz **SBCL 1.0.30.4** Real time: 1.9 - 2.0 seconds Run time (incl. GC): 1.68 to 1.73 seconds
mzscheme 4.1.5 on an Athlon XP 2600+: &gt;(time (not (machin-pi 10000))) &gt;cpu time: 1192 real time: 1268 gc time: 140 &gt;(time (not (machin-pi-tco 10000))) &gt;cpu time: 1132 real time: 1183 gc time: 12 Edit: You people have way faster machines than I do. Did I screw something up, or is scheme really this much faster than CL at this stuff? Extra Edit: SBCL gives me 1.353 real, 1.341 runtime. I guess this computer just isn't as awful as I thought.
Are your results in seconds? I'd suggest the major difference is that compilers like SBCL do a *lot* of type inferencing, and can generate some really fast machine code. For numerical code at least SBCL is pretty close to being a sufficiently smart compiler.
No, milliseconds. mzscheme is **faster** here, not slower.
Bah. Misread that. That is peculiar. EDIT: Can you post the code you used?
Assuming markdown will cooperate... (define (machin-pi digits) (define (arccot-minus xsq n xpower) (let ((term (floor (/ xpower n)))) (if (= term 0) 0 (- (arccot-plus xsq (+ n 2) (floor (/ xpower xsq))) term)))) (define (arccot-plus xsq n xpower) (let ((term (floor (/ xpower n)))) (if (= term 0) 0 (+ (arccot-minus xsq (+ n 2) (floor (/ xpower xsq))) term)))) (define (arccot x unity) (let ((xpower (floor (/ unity x)))) (arccot-plus (* x x) 1 xpower))) (let* ((unity (expt 10 (+ digits 10))) (thispi (* 4 (- (* 4 (arccot 5 unity)) (arccot 239 unity))))) (floor (/ thispi (expt 10 10))))) ____ (define (machin-pi-tco digits) (define (arccot-minus xsq n xpower state) (let ((term (floor (/ xpower n)))) (if (= term 0) state (arccot-plus xsq (+ n 2) (floor (/ xpower xsq)) (- state term))))) (define (arccot-plus xsq n xpower state) (let ((term (floor (/ xpower n)))) (if (= term 0) state (arccot-minus xsq (+ n 2) (floor (/ xpower xsq)) (+ state term))))) (define (arccot x unity) (let ((xpower (floor (/ unity x)))) (arccot-plus (* x x) 1 xpower 0))) (let* ((unity (expt 10 (+ digits 10))) (thispi (* 4 (- (* 4 (arccot 5 unity)) (arccot 239 unity))))) (floor (/ thispi (expt 10 10)))))
faster than SBCL with 1.0 seconds (aleksandros) and 0.8 on another machine? Note though that SBCL can compile it to faster code when there it is optimizing for speed and possibly gets a few type hints. Also, why don't you post your Scheme code? 
Sorry about that; it might be better if you can be bothered to sign up to Nico Nico Douga -- http://www.nicovideo.jp/watch/sm7543530 FWIW, the slides and whatnot are here http://john.freml.in/shibuya-talk-tpd2 There's a better quality but older talk at http://vimeo.com/4884749
The fact that it was even comparable was what was bothering me, given that these people are using new C2Ds and I'm using a god-only-knows-how old Athlon XP. SBCL turned out to give me a similar time, though, so I guess my processor wasn't as much of a problem as I thought.
yes, results can be sometimes surprising. ;-) There is no reason why Scheme compilers should not generate competitive code for this little function. Would be interesting to see if Stalin can compile/run it...
Would be happier if, in addition to Clojure, the book discussed scheme.
Platform: FreeBSD/amd64 7.2 on 2.0Ghz Athon64 3200+ * sbcl-1.0.29.2: 1.1s * clisp-2.47: 1.5s * ecl-0.9l: 0.25s (this one surprised me) * abcl-0.0.10: 2.5s All numbers are "real" time, with a rough eyeballed average after maybe a half-dozen runs. (diablo-jre-1.6.0.07.02 installed for abcl)
SBCL: Evaluation took: 0.854 seconds of real time 0.839872 seconds of total run time (0.707892 user, 0.131980 system) [ Run times consist of 0.264 seconds GC time, and 0.576 seconds non-GC time. ] 98.36% CPU 2,135,045,010 processor cycles 217,918,920 bytes consed CLISP: stack overflow
Allegro CL 8.1, Windows, Intel Core2 Duo (E6750) 2.66GHz cl-user(6): (time (machin-pi 10000)) ; cpu time (non-gc) 578 msec user, 0 msec system ; cpu time (gc) 109 msec user, 0 msec system ; cpu time (total) 687 msec user, 0 msec system ; real time 781 msec ; space allocation: ; 2 cons cells, 62,619,808 other bytes, 0 static bytes Ack! Was recoding a DVD, which pretty much soaks up both cores. Now get this: cl-user(8): (time (machin-pi 10000)) ; cpu time (non-gc) 547 msec user, 0 msec system ; cpu time (gc) 31 msec user, 0 msec system ; cpu time (total) 578 msec user, 0 msec system ; real time 687 msec ; space allocation: ; 1 cons cell, 62,619,808 other bytes, 0 static bytes 
Not happy until there is something to read.
Currently LispMe. Can you take your lisp everywhere? Probably SBCL will creep back as my favourite pretty soon, but the joy of physically portable lisp is quite substantial and I just discovered it a couple days ago.
Yes. In particular, discussion of talking to C, optimizations and SLIME have me quite excited. It all looks good though.
Interesting I always force a gc before trying to do any kind of timing: (collect-garbage) (time (not (machin-pi 10000))) (collect-garbage) (time (not (machin-pi-tco 10000))) I also tried running mzscheme against your script (below) and compiling the same script. ** Script version: mzsceme pi-digits.ss : v4.2 [3m] - Ubuntu package from plt-scheme website ** cpu time: 756 real time: 789 gc time: 80 #f cpu time: 716 real time: 727 gc time: 4 #f ** Compiled version: ./pi-digits ** cpu time: 716 real time: 750 gc time: 36 #f cpu time: 708 real time: 732 gc time: 12 #f What strikes me about this is how good the scripted version is compared to the compiled version although I guess it's expected considering the majority of the work is done in tight loops that can be jitted or inlined quite easily - although I have no idea what mzscheme actually does. **sbcl : Ubuntu Jaunty package version - 1.0.18.0-2 ** Evaluation took: 1.584 seconds of real time 1.564098 seconds of total run time (1.340084 user, 0.224014 system) [ Run times consist of 0.356 seconds GC time, and 1.209 seconds non-GC time. ] 98.74% CPU 4,766,779,725 processor cycles 217,914,816 bytes consed **clisp : Ubuntu Jaunty package version - 2.44.1-4 ** Real time: 1.149473 sec. Run time: 1.096068 sec. Space: 62568192 Bytes GC: 20, GC time: 0.364023 sec. EDIT: formatting
(floor (/ x y)) can be written as (floor x y) while avoiding intermediate rational. The following revision reduces the runtime on my puny Pentium M 800MHz from 2.6s to 0.8s. (defun machin-pi-fast (digits) "Calculates PI digits using fixed point arithmetic and Machin's formula with double recursion" (declare (optimize speed (safety 0)) (fixnum digits)) (labels ((arccot-minus (xsq n xpower) (let ((term (floor xpower n))) (if (= term 0) 0 (- (arccot-plus xsq (+ n 2) (floor xpower xsq)) term)))) (arccot-plus (xsq n xpower) (let ((term (floor xpower n))) (if (= term 0) 0 (+ (arccot-minus xsq (+ n 2) (floor xpower xsq)) term)))) (arccot (x unity) (let ((xpower (floor unity x))) (arccot-plus (* x x) 1 xpower)))) (declare (ftype (function (integer integer integer) integer) arccot-minus arccot-plus) (ftype (function (integer integer) integer) arccot)) (let* ((unity (expt 10 (+ digits 10))) (thispi (* 4 (- (* 4 (arccot 5 unity)) (arccot 239 unity))))) (floor thispi (expt 10 10))))) 
I'm a fan of CLisp. It isn't fast, but it's open source, has good support for the platforms I care about, and most of all it's nice to use at the terminal. SBCL definitely has it's good points (like fast native code compilation and static type checks), but it's quite verbose by default, and it's missing things like tab-completion, REPL history, and line editing. And the errors it throws are big and ugly. It seems like it's designed to be used behind SLIME. CLisp, however, dosn't need Emacs to be useful - I have done development in the past with nothing more than CLisp in a xterm and a notepad-style editor. 
Source? Info? Description?
(dotimes (x 7) (print "Shut-up you"))
You might want to check out Allan Rutenberg's [invoke.lisp][1], which uses the [JScheme implementation][2] to dynamically dispatch method calls. This entails having the 'jscheme.jar' in ABCL's invoked classpath. But when I did a large amount of integration with Java work in ABCL, I find the syntax here quite useful. It doesn't have all the nice things from Clojure, but it certainly cuts out most of the tedium of long sequences like (jcall (jmethod (jclass ...))) type stuff. Eventually, this sort of syntax may or may not make it into ABCL. Right now, we are still struggling with more core language issues like ANSI CL compatibility, CLOS optimization, a better Gray streams implementation, ... The property 'additional.jars' in the Ant based build system can be used to include such jars in the ABCL wrapper script. [1]: http://svn.mumble.net:8080/svn/lsw/trunk/jss/invoke.lisp [2]: http://jscheme.sourceforge.net/jscheme/main.html
I'm confused by the inclusion of Clojure, actually. From the TOC it appears that the book is focused on Common Lisp, and indeed says that it will focus on various CL implementations (Allegro, Clozure, SBCL, LispWorks). Then it includes Clojure ... which is not a Common Lisp implementation. Perhaps he means Armed Bear? As TheSummarizer says, if he's going to talk about Clojure he should at least include Scheme and, if the decision is to drive down the path of "other Lisps", Qi and Arc. 
I'm working on it. For now /usr/share/doc/cl-abop/README
Clojure: (use 'clojure.contrib.math) (defn machin-pi [digits] "Calculates PI digits using fixed point arithmetic and Machin's formula with double recursion" (letfn [(arccot-minus [xsq n xpower val] (let [term (floor (/ xpower n))] (if (= term 0) val #(arccot-plus xsq (+ n 2) (floor (/ xpower xsq)) (- val term))))) (arccot-plus [xsq n xpower val] (let [term (floor (/ xpower n))] (if (= term 0) val #(arccot-minus xsq (+ n 2) (floor (/ xpower xsq)) (+ val term))))) (arccot [x unity] (let [xpower (floor (/ unity x))] (trampoline arccot-plus (* x x) 1 xpower 0)))] (let [unity (expt 10 (+ digits 10)) thispi (* 4 (- (* 4 (arccot 5 unity)) (arccot 239 unity)))] (floor (/ thispi (expt 10 10)))))) user=&gt; (time (machin-pi 10000)) "Elapsed time: 1786.632 msecs" 3141592653589793238... &lt;snipped&gt; 
Fair enough. Any chance to get a .tgz, which is far easier to look at without touching your system inappropriately?
If you look at the code, though, there's not much in the way of places where SBCL can apply its fancy type inferencing; you're going to be doing a lot of bignum operations, not operations on machine-sized integers.
In Haskell : http://jng.imagine27.com/articles/2009-07-23-094212_generating_pi_in_haskell.html
Currently vacillating between Gambit and Larceny. I want to like RScheme, but it hasn't been updated in like forever.
&gt; I'm confused by the inclusion of Clojure, actually. From the TOC it appears that the book is focused on Common Lisp And it seems to be true. Clojure is clearly mentioned in a chapter called "talking to other boxes". That makes sense, just as much as including RabbitMQ.
Well, here you go, [tarball](http://www.creativity.lv/share/abop-0.0.tgz), but you will have to get cl-sdl-opengl, which comes naturaly in debian/ubuntu.
&gt; And it seems to be true. Clojure is clearly mentioned in a chapter called "talking to other boxes". That makes sense, just as much as including RabbitMQ. Still doesn't make sense to me: Nick is the author of CL-RABBIT which provides RabbitMQ bindings for Common LISP... how does Clojure fit into this chapter then? Don't get me wrong, I think the book will be very cool and is needed. I'm just not seeing how Clojure fits into the rest of the story here. 
so it looks like **ECL is the fastest Lisp implementation** with 0.25 seconds runtime and beats all other reported runtimes (CL, Clojure, Scheme, Haskell). The reason for this: ECL uses the GMP (GNU Multiple Precision Arithmetic Library) and the function does a lot of bignum computation.
Chicken Scheme (compiled) using psxman's tail recursive code on a Core 2 Duo T5500 @ 1.66GHz: real 0m1.190s user 0m1.188s sys 0m0.004s 
Just hard-code it as a constant.
SBCL on OSX and Linux
I'm writing a small (at least, it *was* small) engine in Lisp for demoscene productions. That means executable realtime underground [multimedia art](http://capped.tv/sceneorg_demoscene_outreach-demoscene_outreach_reel), with a focus on procedural content generation. &lt;/buzzwords&gt; I'm working with a friend, and we hope to have a release for [Syntax 09](http://syntaxparty.org/) which will be held later this year in Melbourne. There have been some [really nice demos](http://www.pouet.net/prod.php?which=50137) (youtube [here](http://www.youtube.com/watch?v=BMuzdTFwV-A)) in Haskell, so why not Lisp? We're using `lispbuilder-sdl` and `cl-opengl` for graphics, and are writing CFFI bindings to PortAudio for the audio output. I'm teaching myself OpenGL as we go, and I'll also be learning how to write (and use!) a software synthesizer. It's looking like the direction &amp; design will be the hard bits, but coder colors are acceptable for a first release. Development is Linux and Clisp, deployment will be Windows and SBCL or maybe CCL. We're trying to keep things portable. Syntax rocked last year (and the [year before](http://www.youtube.com/watch?v=nMyXIsqA7k0&amp;feature=channel_page)), and it'll be great to contribute our art to this event and the scene, although the deadline approaching will make things stressful. It's been great fun so far, and that's only going to increase.
ACL w/o hesitation. Yeah their tools cost $$$ but it's really no more than you'd pay for e.g. a MSDN license or the super G*D mode of Visual Studio 20xx.. Plus they got good support and they're generally good folks to work with. SBCL follows very closely in second place. 
Well, they do cover nested quasi-quotes at the end of the paper. Not very well, but so it goes.
&gt;And ECL ( http://ecls.sourceforge.net/ ), because Juanjo, the chief maintainer, does such a brilliant job in fixing and extending the implementation. I'll second that! He replies to emails, he is thorough with his work, and he does an excellent job looking after ECL.
Girliemen have no sense of humor....
ECL, for the power it provides to control my app from a lisp repl. 
You know 'fluxus' and 'impromptu'? http://www.pawfal.org/fluxus/ http://impromptu.moso.com.au/
I'd seen fluxus before. Those are both in Scheme. Impromptu dosn't support Windows or Linux. And both seem more oriented towards livecoding than demoscene stuff. Also, I really want something I understand, even at the cost of "Not Invented Here" syndrome.
Anyone else have the connection reset several times when downloading? 
No; I got the cll.bz2 just fine last night.
are you looking for something like this http://lispm.dyndns.org/lisp/pics/symbolics-keyboard-layout.png ?
Yes, I get constant resets, roughly one every 1MB. Fortunately wget retries automatically.
You rock, thank you. Now I just need to convince Kinesis to add more keys that correspond to the joystick buttons, for those who don't want to feel like they are playing a church organ when they are programming.
Also, looking at the code, why is he assuming that the loop over the constant list is optimized, including the "for func= "?.. (Juho Snellman also mentioned something like this.) Now his test is practically testing whether this optimization is there, not the differences in of the case-implementations. Ok, compiling defun ncase-1000... Took 10 minutes on his computer (which is faster then mine..)
That's not a "Space Cadet" keyboard. [THIS](http://world.std.com/~jdostale/kbd/SpaceCadet1.jpeg) is a Space Cadet keyboard!! All joking aside, does Genera have support in it for these earlier designs?
Right, but that one is really old. I think it is for the LM-2, the repackaged CADR, the first Symbolics machine. All later keyboards I have seen from Symbolics have a similar layout to what my screenshot shows. From the 3600 on. Physically there are two different designs, but with mostly similar layout. Genera does not have a Keyboard Layout for the one on your picture, AFAICS. It supports some SUN, Mac, SGI, IBM, ... layouts, though.
Holy hell, I tallied the four Roman numeral keys, quote, overstrike, clear input, hold output, stop output, abort, resume, call, status, line, alt mode, and mode lock keys as ones I hadn't counted before. Sixteen extra keys in all. My head assploded. Hm, I wonder if those could be emulated with a number pad? Wouldn't be the same layout of course, but could still map those keypresses to these sixteen extra keys I hadn't counted upon.
Those HID researchers need to hurry up and start manufacturing direct brain interfaces before we end up [like this](http://history.sandiego.edu/gen/st/~jgaffney/aviation/images/commercial/747cockpit.jpg) for a programming environment. :-)
Mh, I am not sure if I understand correctly this test... The following script: (import (rnrs)) (define (machin-pi digits) (letrec ((arccot-minus (lambda (xsq n xpower) (let ((term (floor (/ xpower n)))) (if (= term 0) 0 (- (arccot-plus xsq (+ n 2) (floor (/ xpower xsq))) term))))) (arccot-plus (lambda (xsq n xpower) (let ((term (floor (/ xpower n)))) (if (= term 0) 0 (+ (arccot-minus xsq (+ n 2) (floor (/ xpower xsq))) term))))) (arccot (lambda (x unity) (let ((xpower (floor (/ unity x)))) (arccot-plus (* x x) 1 xpower))))) (let* ((unity (expt 10 (+ digits 10))) (thispi (* 4 (- (* 4 (arccot 5 unity)) (arccot 239 unity))))) (floor (/ thispi (expt 10 10)))))) (write (machin-pi 1000))(newline) saved into a file and run from the command line of a Linux shell using Mosh Scheme: $ time -p mosh proof.sps 314159265358979323846264338327950288419716... real 0.15 user 0.14 sys 0.01 Mosh Scheme uses GMP. This is on my netbook (Acer Aspire One). http://code.google.com/p/mosh-scheme/ 
If I use the internal time function from the (mosh) library: (time (machin-pi 1000)) ;;0.04089093208312988 real 0.038994 user 0.002 sys 
I would kill for a programming environment like that.
Digging through Brad Parker's [CADR software release](http://www.heeltoe.com/retro/mit/mit_cadr_lmss.html), (LMIO;KBD.123) it looks like even the CADR ignored a lot of the excess keys and funkier greek/APL keycaps on these keyboards, although I'm not sure I understand all of the code. 
In other words: [Chart!](http://chart.apis.google.com/chart?cht=bvs&amp;chs=400x200&amp;chd=t:99,36,36,18,18,18&amp;chco=4d89f9&amp;chl=SBCL|Clozure|Clojure|Allegro|ECL|Elisp&amp;chbh=a)
SBCL. No specific reason, haven't tried much other than SBCL, CMU and CLisp.
I don't understand it either. What lies in "compute"? Can I write the entire Taylor series necessary, e.g. generate a macro that creates the function and then just time the needed additions? 4 * (1 - 1/3 + 1/5 - 1/7 + ...)
I'm pretty sure that doesn't counts as "computing".
Thanks, but I'm not touching anything Franz has been messing with. I might, of course, reconsider when Allegro CL is released under a free license.
[cl-memcached](http://common-lisp.net/project/cl-memcached/) -- Memcached client for CL, written by "quasi" (my ex-boss/mentor). Some of my own Lisp projects: * [cl-bzip2](http://common-lisp.net/project/cl-bzip2/) -- CFFI bindings for libbzip2 * [cl-twit](http://chaitanyagupta.com/lisp/cl-twit/) -- Twitter client, designed to be used from the REPL * [chronicity](http://chaitanyagupta.com/lisp/chronicity/) -- Natural language date/time parser
Thanks for chronicity. I've used that to make a nice date-field in [celtk](http://github.com/cddr/celtk/tree/master). The user just enters text and a label appears to the right with the "canonical" date (or an error message saying the date isn't parseable yet). To me, this seems better than the calendar pop-ups. Haven't made it public yet but it's working pretty well on my own machine.
[Scheme48's rendezvous library for concurrent programming](http://s48.org/1.8/manual/manual-Z-H-8.html#node_sec_7.8)
interesting, thanks!
["I used to be a Vim bigot": How a Vim user converts to Emacs](http://bradbeveridge.wordpress.com/2007/06/21/how-a-vim-user-converts-to-emacs/)
[Pcall](http://marijn.haverbeke.nl/pcall/) has been fun for me. It allows creating promises/futures and collecting the results later. I use it to pull flow tables from a bunch of routers in parallel and then combine and display the results when they are all ready.
Welcome! Nice to know someone else found it useful too.
I forgot a zero!!!! That's what it is! The script with the function called for ten 1000 digits: (time (machin-pi 10000)) prints: ;;1.0974020957946777 real 1.013846 user 0.079987 sys while run from the shell with the "time" utility: real 1.26 user 1.14 sys 0.11 all on my Acer Aspire One. EDIT: This is with Ikarus Scheme: running stats for (machin-pi 10000): 24 collections 996 ms elapsed cpu time, including 211 ms collecting 998 ms elapsed real time, including 214 ms collecting 103402072 bytes allocated 
Though I'm a noob, CL is far and away the language I find most comfortable and most fun to code in. * Shuffletron, a lisp music player, was posted here [recently](http://www.reddit.com/r/lisp/comments/8wlwm/shuffletron_a_music_player_for_linux/). * Shuffletron was built on Andy Hefner's [mixalot](http://vintage-digital.com/hefner/software/mixalot/mixalot.html) libraries which include an ffi to libmpg123 and an ffi to ALSA for linux. They are much more complete than cl-alsa and cl-madhl listed on cliki. * Dmitry Kalyanov also has released some nice gtk bindings with [cl-gtk2](http://common-lisp.net/project/cl-gtk2/index.html). I've enjoyed using these libraries to play around with (toy) mp3 players in lisp. Thanks, guys!
ECL just rocks in general.
WTF? What Size does this screen have?
Larger Than Life. I've been using trunk of CCL for a few months now. Greatness.
**Mac OS X users**: How to get it working. **Step 1**: transfer CCL to some directory of your choice: svn co http://svn.clozure.com/publicsvn/openmcl/trunk/darwinx86/ccl or: svn co http://svn.clozure.com/publicsvn/openmcl/trunk/darwinppc/ccl if you're on ppc. **Step 2**: start ccl from the terminal, for example 'dx86cl64' for the 64bit version on Intel. **Step 3**: create the CCL application (require :cocoa-application) **Step 4**: double click the new 'Clozure CL64' (for the 64bit version) application. Welcome to Clozure Common Lisp Version 1.4-dev-r12383M-trunk (DarwinX8664)! For future use, keep the CCL icon in the dock. Clicking on the dock icon then will start CCL. **Done** You can wander around in the CCL sources. Typing (ed 'inspect) will get you to the inspector sources. M-. on symbols finds their sources. **Have fun!**
SBCL, because of the reasons stated below (e.g. fast native code). On windows I also use clozure cl (since sbcl is not that friendly towards windows)
I'm a new lisper so I'm just playing around :) I write all kinds of little programs (mostly related to programming languages or programming language concepts): a stack language interpreter (a tiny one) a x86 code generator I haven't done web dev in lisp but I wouldn't shy away :)
Lispworks. Full-featured, well supported, very hackable. Pro edition comes with editor source.
Sorry to be late for the party... :-) Intel Core Duo, 3 GHz, 3GB RAM % scheme48 -h 20000000 Welcome to Scheme 48 1.3 (made by ecl on Wed Nov 8 16:13:19 2006) Copyright (c) 1993-2005 by Richard Kelsey and Jonathan Rees. Please report bugs to scheme-48-bugs@s48.org. Get more information at http://www.s48.org/. Type ,? (comma question-mark) for help. &gt; (define (machin-pi digits) ;; "Calculates PI digits using fixed point arithmetic and Machin's formula with double recursion" (define (arccot-minus xsq n xpower) (let ((term (floor (/ xpower n)))) (if (= term 0) 0 (- (arccot-plus xsq (+ n 2) (floor (/ xpower xsq))) term)))) (define (arccot-plus xsq n xpower) (let ((term (floor (/ xpower n)))) (if (= term 0) 0 (+ (arccot-minus xsq (+ n 2) (floor (/ xpower xsq))) term)))) (define (arccot x unity) (let ((xpower (floor (/ unity x)))) (arccot-plus (* x x) 1 xpower))) (let* ((unity (expt 10 (+ digits 10))) (thispi (* 4 (- (* 4 (arccot 5 unity)) (arccot 239 unity))))) (floor (/ thispi (expt 10 10))))) ; no values returned &gt; ,time (machin-pi 10000) Run time: 0.81 seconds; Elapsed time: 0.81 seconds 314159265358979323846264338327950288419716939937510582097494459230781640628620899862803482534211706798214808651328230664709384460955058223 172535940812848111745028410270193852110555964462294895493038196442881097566593344612847564823378678316527120190914564856692346034861045432 664821339360726024914127372458700660631558817488152092096282925409171536436789259036001133053054882046652138414695194151160943305727036575 959195309218611738193261179310511854807446237996274956735188575272489122793818301194912983367336244065664308602139494639522473719070217986 094370277053921717629317675238467481846766940513200056812714526356082778577134275778960917363717872146844090122495343014654958537105079227 968925892354201995611212902196086403441815981362977477130996051870721134999999837297804995105973173281609631859502445945534690830264252230 82533446850352619311881710100031378387528865875332083814206171776691473035982534904287554687311595... 
* [An editor for lisp](http://lisp-editor.berlios.de/). * [A lispy language](http://lang-lisp.berlios.de/), way out of date website, btw. Also made some formula simplification code for it. Ended up just using 'replacement rules' and an algorithm to join stuff in and and or expressions. Those can do what i need, and they are faster; the amount of possibilities of trying to simplify is simply to great otherwise. (Still, good to have done so and seen so myself.) * [Some random macros](http://lisp-umac.berlios.de/) i put online.(Not really a project though.) Some that i don't have anything on the web about is: * A 'multilevel quadtree' (Multiple depths of the quadtree are grouped in arrays, and when searching are skipped.) * Basic simulation stuff. Not really much, just particles, Euler, RK4 integrators.(Untested Verlet integrator) Also have timestep variation, but haven't worked on getting it to work properly(and have benefit) when the particles interact. I wish there were good numerical simulation packages.. i have some things i want to try out where i need them :) . (Prolly i should look outside of lisp for it..)
Favourite has to be Clozure CL because it is generally very well implemented and Open Source. Mostly use SBCL because it is the fastest. In terms of commercial lisps (we have both LispWorks and Allegro at work), I have come to rather dislike Franz's Allegro (awful GC, mediocre code generation) and to rather like LispWorks, which seems the most correct implementation I have used.
What happens when a macro tries to expand something in its environment with this code walker?
By chance, i have written a code walker 'attaching (#'code-scan:scanning-macrohook) to' *macroexpand-hook*. Tbh, i have written it rather naively. It is in [this project](http://lisp-editor.berlios.de/). It works by calling the function that does the macroexpanding. Then it calls the scanning function on the result: * When it finds a s-expression for which (macro-function symbol) produces non-nil, for those it stops; the macroexpansion hook will pick it up. * Looks for special-operator-p stuff, for a bunch of these, how the scanning continues is determined manually. If it isn't specified manually, it stops the scan. * when not fboundp, it stops. This is still a problem for flet's, i don't know if it is for macrolet. (macroexpand '(macrolet ...)) doesn't seem to do anything, maybe macrolet can be replaced with something that immediately expands all of it's elements. Flets are still a problem. Some packages are ignored, like SBCL internal stuff: :sb-impl, :sb-int, :sb-c, :sb-pcl, :sb-kernel. Of course the scanning is to gather information. It has defvars to store the current function(or macro) \*in-fun\*, and it stores function usage in \*functions\*, links between functions in \*function-links\*, currently defmacro and defun are treated differently, and there is some undertested(probably doesn't work) code to more generally store information. I am planning to just have a function that is called at every level to treat everything more uniformly.(defun, defmacro no longer being special.) That way, autodoc(also in lisp-ed project), can also document macros made by the user, simply by providing a scanner and a documenter for the macro. This thing, and its code looks pretty cool too, though. I will surely look at it better, add a scanning-part, and documentation strings ftw! Btw, the posting comments thing on that website is unclear.. What happens to links? How do you send the comment. (Presumably press Enter after your name, but then it disappears, for moderation or just poof?) Edit: Ok, this looks very nice, i am fairly sure i am going to use it. #:code-scan looks rather messy in comparison. It also was easy to add a \*expression-hook\* and a \*expression-hook-state\* to it, so one can use it to get info on what the code looks like.
I always suspected that this guy is weird and Qi is a fad. A true Lisper would never give it up...
&gt;A true Lisper would never give it up... Perfect example of the [no true Scotsman](http://en.wikipedia.org/wiki/No_true_Scotsman) fallacy.
http://www.youtube.com/watch?v=oHg5SJYRHA0
I'll bite. What's so unLispish about &gt; At some point you have to acknowledge that Qi doesn't pay its way. Even as a Lisper, I admit that I have to, you know, eat, and having a computer is a nice thing, too.
Well, it looks like this guy does not have a genuine love for computing, programming languages and stuff like that. He is not a hacker. I remember Mark was struggling with very basic stuff, according to his posts on comp.lang.lisp, made weird statements... It seems Qi was a by-product of his career, which he have ditched altogether. Note that he is going to give up not only Qi and Lisp, but computing in general: &gt; But its also a goodbye to Qi and computing. ... Qi has been a journey that began nearly 20 years ago when I was a very different person and worked for a university. ... I need to move on. As for Lispers, many of them are programming enthusiasts (because people do not learn Lisp just to get a paid job or something), and it is sort of very unusual for programming entusiast to give up programming in general. &gt; Even as a Lisper, I admit that I have to, you know, eat, and having a computer is a nice thing, too. Money is a totally different thing. Even if some programming enthusiast has to choose non-programming job for financial reasons, he is likely to do some programming as a hobby, rather than completely give up programming, no? Many (most?) of Lispers have a job which has nothing to do with Lisp, but they are still interested in Lisp. &gt; At some point you have to acknowledge that Qi doesn't pay its way. Believing that you can make some obscure programming language and it will somehow "pay its way" looks like a lack of common sense, as for me. If you're designing a new programming language, do it because you love what you're doing and because you really think it is going to be useful for something, but not because you need to earn some $$$, that's what I think.
The [correct link](http://www.lambdassociates.org/blog/nextlisp\(1\).htm)
Thanks!
Nope, I don't think that's a redefinition at all. Part of the 'Lisper' image is fanatical devotion to the language, if he changes and no longer has this, then he was no true lisper. The definition didn't change, he did.
I'm happy to see him go, his views on FOSS did it for me. Too bad, he seemed pretty smart.
likely well known, but I have to mention it, because it introduced me to common lisp and convinced me to use common lisp for some projects: [hunchentoot](http://weitz.de/hunchentoot/), the excellent webframework by Edi Weitz. Additionally, perhaps not so well known: [CL-EMB](http://common-lisp.net/project/cl-emb/), a simple templating library. Makes it easier to work with html-people. Last but not least: [postmodern](http://common-lisp.net/project/postmodern/), an (postgres-only) alternative to cl-sql. IMHO with these three libraries it is possible to develop nice webapplications.
&gt; Btw, the posting comments thing on that website is unclear.. What happens to links? How do you send the comment. (Presumably press Enter after your name, but then it disappears, for moderation or just poof?) They're supposed to appear automagically in realtime for everyone currently looking at the site.
&gt; It is in this project. Btw, you might want to link to the source page from there. Unless you know to go to the berlios devel page and search manually for lisp-editor, you can't get the source, which is a significant obstacle.
Fixed that, was a pretty bad screwup. Thanks for notifying me. I am, btw fairly sure i am going to use it. (See edit to parent.)
&gt; I don't have a regular expression library for Lisp. I know they are out &gt; their, &amp; I'm sure they are fine, but I haven't found one I like, &amp; I &gt; haven't found a strong enough need for one to motivate me to &gt; find one I like. Umm... [cl-ppcre](http://weitz.de/cl-ppcre/)? I think his original perl example could be translated to lisp really nicely using [iterate](http://common-lisp.net/project/iterate/) and cl-ppcre.
There is an ABCL (Armed Bear Common Lisp) that works on java.
I think 2004 might explain that part.
Interesting! I really ought to play with this. Probably won't, but in theory I really ought to.
Maybe this is just me, but this failed to interest me.
Is Clojure out of the question? Otherwise, ABCL.
Clojure is the only way to go if you want a Lisp that works well with Java and the JVM. If you are OK with both Common and Scheme I don't think it would be much effort to adapt to Clojure. Clojure while being a Lisp is also a better Java, in the sense that it makes using Java libraries more pleasant to use than directly from Java.
When it has to be Common Lisp then it's Armed Bear, if you're looking for something interesting with a real future then Clojure is the way to go (but it's a different dialect from either Common Lisp or Scheme). There are several Scheme on Java implementations, but I've not used any of them, I suspect Kawa is the most used (which doesn't bode well for you), but you'd have to ask around. If I were you I'd make the jump to Clojure.
but it's not CL or Scheme...
ABLC is the best implementation as far as I know, but I seriously recommend moving on to Clojure. Just my 2 cents.
Kawa, SISC, Bigloo, JScheme... I use Kawa a lot, for both Qexo &amp; Kawa...
I dont see the point to this.
I love the HTML and JavaScript on his page, as well.
One thing that stood out for me: &gt;I should have integrated the visualiser into the simulator more closely (perhaps via an unobtrusive function pointer called every few steps) so we could play problems as they were solved, not replaying traces after getting the output of the controller. That would have sped up our development cycle significantly. Stepping saves time. I wish the lisp people would realize the value of a stepping debugger over just trace output and focus on this (at least for SBCL :)
Sad that we've not figured out a better way to do it...
Honestly, I nearly never use asdf-install. Instead I download packages manually. I would prefer [mudballs](http://mudballs.com/) - it looks more like rubygems. Sadly, if I remember correctly, the project is no longer developed further.
I find it way too tedious to chase down all the dependencies on even moderately complicated libraries. It doesn't seem so bad the first time, but the second, third, Nth times get boring, and it's nice to have something that will do it for you, mostly. Some people are trying to keep up mudballs development. http://groups.google.com/group/mudballs/browse_thread/thread/15755f04ff62629c has some info.
I just check that the url is correct. The GPG checks are too much work.
The arguments don't sound too far fetched to me. Could you pinpoint where he is fundamentally wrong?
Isn't he quite right with open office? *edit: to spare the [discussion](http://www.reddit.com/r/technology/comments/97tqu/microsoft_wins_again_arrghh/)
not trying to solve exactly the same problem, but clbuild is nice
&gt; Is is almost impossible for me to read contemporary mathematicians who, instead of saying “Petya washed his hands,” write simply: &gt; “There is a t₁ &lt; 0 such that the image of t₁ under the natural mapping t₁ ↦ Petya(t₁) belongs to the set of dirty hands, and a t₂, t₁ &lt; t₂ ≤ 0, such that the image of t₂ under the above-mentioned mapping belongs to the complement of the set defined in the preceding sentence.” *V.I. Arnol'd* 
 (define (integrate-from from) (define integrated-from (f to) (integrate f from to)) integrated-from) Produces inverses of differentiation. I wonder if he learned the rigorous version like mathematicians get. Forgot what the exact requirements for the integral being the inverse (in the given sense) The looking at a textbook(Well, dictate) requirement doesn't seem very strict; (= (integrate (deriv f) a b) (- (f b) (f a))) when f continuously differentiable. I think there is also the [constructionist way](http://plato.stanford.edu/entries/intuitionistic-logic-development/) of defining things. Which looks rigorous to me. (Despite the godawful name 'intuistic'.) Still trying to learn that, though. Looks, cool, love the idea of being able to make all sorts of stuff up, because there is more between true and false.
Not Arc?
The problem isn't that the guy is a math idiot, or that he somehow lost mathematical ability; he was missing a few important points to begin with. &gt; I used to believe that integration and differentiation were opposites ...and, for nicely-behaved functions, indeed they are; that's the entire point of the fundamental theorem of calculus. His example: (define (deriv f) ...) (define (integrate f low hi) ...) Is comparing apples and oranges. In this case, "deriv" is a function that takes a function that takes a function f(x) and returns another function (its derivative). "Integrate" is a function that takes a function and lower and upper bounds and returns a numerical value (the definite integral of f from low to high). The "opposite" of deriv in this case would be a function (let's call it "one-side-int") that takes a function f(x) and returns a function F(x) that evaluates the integral of f(x) from (WLOG) 0 to x. In that case, (deriv (one-side-int f)) would equal f, as you would expect.
Why would he bother with Arc? :\
I'm with you. Sad these CL zealots want to whine and down vote a perfectly good post, suggesting an alternative.
I hate explaining jokes, even bad ones. The website is owned by Paul Graham.
Yeah, it doesn't take much to bring down the wrath of the old Lisp gods.
 (define (deriv f) (lambda (x) (/ (- (f x) (f (- x dx))) dx) (define (integ f) (lambda (x) (+ (* (f x) dx) (if (&gt; x 0) (integ (f (- x dx)) (if (&lt; x 0) (integ (f (+ x dx))) 0))) ? edit: I know my syntax is messed up, but there also has to be a better/easier/smarter way to do integrals.
Mark Tarver is from Scotland?
Godspeed through Orissa, gora; I hope you got your hep vaccinations...
Open office != all of open source. There are good open source programs (firefox, chrome, konqueror, gcc, python, ruby, eclipse, netbeans, virtualbox, many more). There are also bad open source programs, although I can't think of any since every time I encouter one I delete it straight away. Finally there are decent open source apps, which aren't as good as the commercial counterparts, but still good programs in their own way. For example open office and gimp. That is the main reason why I disagreed with his views - he always focuses on the okay or poor examples of open source software, but ignored the good os stuff that was better than anything else available.
The original source: [Tetris for TI Explorer and Symbolics Genera](http://www.cs.cmu.edu/afs/cs/project/ai-repository/ai/lang/lisp/code/fun/0.html) installation and porting problems: * the source contains special font information (source styles), get Zmacs to accept this the right way * the file system had to be persuaded that the font file is really 16 bit binary data, byte size is a file property (!) * on an X11 display there is no direct screen, so some drawing and bitblt operations had do be on a sheet and not on the lower-level raster arrays 
via: http://www.advogato.org/person/ingvar/diary.html?start=299 I have previously written a short essay, or possibly a rant on "develop and release straight out of version control" or "release in versioned lumps of code, with the development being separate". 
Of course, incrementing a counter is an inherently serial process, so using threads here is completely pointless. If your entire thread code is surrounded in dosync, it will just get serialised by the synchronization handlers anyways. But I get the point--- in a real application the counter increment would just be one operation of many. 
I think packaging should be done per-distribution/OS; that's why common-lisp-controller is such a great advance. I use it for [my Fedora packages](http://yum.octopodial-chrome.com/); others use it for their Debian packages; there's no reason it couldn't be extended to work on Windows and Mac OS X.
Its good that ABCL gets better, but why do they especially want Maxima to run under ABCL? I mean, this is not really a System you want to run under Java.
Presumably it's because Maxima serves as a good, real-world test case. It's (a) sufficiently complex, (b) open-source, and (c) doesn't rely on platform-specifics a lot (the command-line version at least, I guess).
i think it is a good "test", if an implementation is complete - ECL made the same (successful) attempt in the last months.
I think it's a good start, since Maxima contains a lot of code and touches some obscure stuff. Though I would guess that newer parts of Common Lisp, like the condition system and CLOS, are not used extensively (if at all) by Maxima.
Author here -- a modified (generalized into something of a framework) version of the full source is now on github, if you check my latest post.
There are quite a few lisp implementations, see http://www.cliki.net/Common%20Lisp%20implementation for a decent list. Personally I use chicken-scheme when I want a lisp-like language (chicken-scheme compiles to C).
[Chicken Scheme](http://www.call-with-current-continuation.org/) and [Gambit Scheme](http://dynamo.iro.umontreal.ca/~gambit/wiki/index.php/Main_Page) both provide REPL interpreters that compile to C. Chicken has a very nice port/package [extension library system](http://chicken.wiki.br/eggs) built-in that provides additional functionality where needed. You can, for example, trivially install Common Lisp [Loop](http://chicken.wiki.br/eggref/4/loop) and [Format](http://chicken.wiki.br/eggref/4/format). Chicken is still going through a major upgrade (version 4) that added a very nice library and module system along with a conversion to hygienic macros and not all of the eggs have been upgraded yet ([objc](http://chicken.wiki.br/eggref/3/objc), I'm thinking about you). Gambit's main claim to fame is [speed](http://dynamo.iro.umontreal.ca/~gambit/wiki/index.php/Gambit_benchmarks). Calling out to any random C library is trivial in either. In Scheme, you're free to not use set! to your heart's content. 
What about clo**z**ure? I use SBCL myself and I'm happy with everything except cl-typesetting.
I wonder if you couldn't use [CLAZY](http://common-lisp.net/project/clazy/) (lazy-order evaluation for Common Lisp) with [ECL](http://ecls.sourceforge.net/) (Embedded Common Lisp (but which also supports standalone use quite nicely) that generates C) to get what you need here.
You might want to look at [plt-scheme](http://www.plt-scheme.org/) which has the lazy (delayed) evaluation and immutable conses, but it isn't really like Clojure. If it's that STM and messaging whizz-bang you want, you might want to take a look at gcj as a way to solve your problems with the JVM, and use it to ship executables made from clojure-compiled `.class` files.
Thanks, I read briefly about PLT but somehow never really thought about how it supports lazy evaluation. I guess it's the norm with PLT to use one of these sort of "sub-lisps" (typed, lazy, etc.) that are implemented with it? 
Thanks, I've looked at Chicken a little, and found it pretty cool. But somehow Clojure still seems different, the way it defaults to lazy evaluation and immutable data. Maybe I've just got the wrong impression, but my impression is that Scheme dialects, while they allow functional programming, generally don't default to it or enforce it in any way, meaning that the compilers don't really take advantage of it. For example Clojure, from what I understand, has a pretty kick-ass immutable vector implementation that just wouldn't usually exist in a Scheme. Maybe I'm wrong, but isn't that kind of thing the reason Rick Hickey decided to create Clojure in the first place? He wanted things done in a certain way, in an idiomatic, non-hacky way. I don't see why this requires the JVM, however. (Yes, I do see the advantages of using the JVM, but I don't really want to depend on it, personally..) 
PLT has support for several languages, including [lazy scheme](http://docs.plt-scheme.org/lazy/index.html), [professorJ](http://www.professorj.org/) (a java-like language), [an implementation of Algol-60](http://docs.plt-scheme.org/algol60/index.html), and [FrTime](http://docs.plt-scheme.org/frtime/index.html) (a reactive language that might be useful for embedding).
You're right on all that. I just haven't been able to get into Clojure because I'm allergic to all things Java and that's based on real world experience delivering a client-side IPSec configuration application written in Java/Swing. It was an unmitigated disaster due to the unbelievably poor implementation of Sun's Java libraries, particularly on Solaris. I'm also old school enough that I like the flexibility of mixing and matching imperative and functional style. I can write recursively but I don't really think of iteration that way. It's probably a function of being a self-taught programmer at a time when Algol-derived languages ruled the world. Clojure's strength is that it leverages the Java libraries. Running in a VM is either a strength or a weakness depending on what you believe and what you're trying to achieve.
The closest thing I can think of is [Lisp Flavored Erlang](http://github.com/rvirding/lfe/tree/master). No (implicit) laziness, but it's got everything else about Clojure you mentioned, as well as lightweight-processes, message-passing, and STM.
Rich Hickey, the creator of Clojure, is working on porting most of clojure to be self hosting. The goal is to make it simple to port to other platforms. Right now, all of the collections are build in Java, so porting is a non-trivial task. But when these are re-written in clojure, it should be a lot easier to create clojure on other platforms. C maybe? LLVM? In any case, clojure itself has a pretty good chance of becoming what you are looking for.
First, I think writing those libraries is quite a significant effort and second, bolting immutability onto a language with mutable references probably has limited use.
Haskell is pretty close, but it's ML, not lisp.
How about porting clojure to support gcj? This would at least come near to that idea.
Haskell is not related to ML. (Or it was a joke?)
Or using some small JVM. I've heard there are JVM implementations with size like ~100kb, so dependency on JVM is not a problem. You also need some standard library, however.
[Liskell](http://liskell.org) -- Haskell with Lisp syntax. 
clojure code does not have the same problem
Except that Clojure programs are 100% parasitic on Java libraries right now, because Clojure itself is a little language mostly concerned with data structures and concurrency.
It is a significant effort. I want to point out that FUNDS provides some functional data structures for CL. Clojure has stuff that it doesn't, probably a lot more. I used to use FUNDS fairly regularly. I would again if I had something like Clojure's ideas on STM and simpler parallel code (though admittedly I am fairly naive when it comes to all things Clojure related). But, if someone wanted to add new functional data types to CL, it might be nice for the community (and easier for the developer) to contribute to FUNDS rather than start a new project. 
Is it still unbearably slow when using CLOS ? 
But does one actually mix and match these different languages in a given application? (What I mean is, on the one hand is it feasible, on the other hand is it common)
Ha, it's actually pretty interesting.. :) Do people use it? How different to lisp is it, I mean can I take examples in Scheme and easily adapt them to this, or is it just something completely different?
True, but it's nice to have the compiler take care of this stuff. Although, it's making wonder if Clojure couldn't be implemented in Scheme the same way it's being re-implemented in Clojure.. Would be quite a job, I guess.
&gt; Do people use it? As far as I know, no. &gt; How different to lisp is it, I mean can I take examples in Scheme and easily adapt them to this, or is it just something completely different? Um, Haskell is very different from, say, CL because it is pure functional. But if you're explicitly asking for language with immutable data, then I dunno... Probably they are pretty similar if you consider some limited purely functional subset. Anyway, programming Haskell is fun, I recommend trying, if you haven't already.
Silly people and their compiler/runtime dichotomies.
Modern functional programming and mutability are mutually exclusive.
Haskell has a lot of similarities with ML. I would say it's a continuation of the same ideas, along with SML and OCaml.
I don't understand. All of these languages "compile" to PLT scheme; It's like how GCC supports Fortran, ADA, Java, C, C++, and etc: You *can* mix them all into one program, but what possible motivation would you have for trying?
Wikipedia lists ML (as well as SML &amp; Lazy ML) as the influences on Haskell; I would think it comes from Haskell's ancestors Id &amp; Hope, but there are, as calp says, many similarities between the two.
&gt; Haskell has a lot of similarities with ML. All programming languages have some similarities. Wikipedia says that Haskell is influenced by: &gt; Lisp and Scheme, ISWIM, FP, APL, Hope and Hope+, SISAL, Miranda, ML and Standard ML, Lazy ML, Orwell, Alfl, Id, Ponder So why do you say Haskell is ML but not, say, Lisp or Miranda? Haskell is very different from ML -- ML is not lazy and not purely functional. This already makes programming is Haskell very different from programming in ML. What they have in common is type inference, but that is not enough to label Haskell a language in ML family, just as you cannot label any dynamic language a Lisp. 
&gt; bolting immutability onto a language with mutable references probably has limited use. Well, you know, we do not have computers which have immutability in hardware. That means that immutability has to be implemented on top of inherently mutable platform. 
The needed complete overhaul of CLOS has not occurred, but we have added little optimizations where possible (like a [cache of EQL specialization calculations][1]). Can you point us to an "unbearably slow" applications using CLOS that we can test and profile? [1]: http://trac.common-lisp.net/armedbear/changeset/12042
Erik mentions in the blog post our "applicability target" which means we hear from users that application X is slow on ABCL, and we use application X to drive a cycle of optimization. 
The influence of ML on Haskell is smaller compared to Miranda. ML is strict and not purely functional. Haskell is non-strict and purely functional. Like Miranda. There was some research into these kinds of languages and Haskell was the attempt to channel this research into one common language.
Your parentheses are unbalanced ;)
Except the the pain of dealing with the classpath I have found that Clojure takes away most of the pain that made me drop Java in the first place. If you haven't already I suggest giving the Java interop page on the Clojure website a look. As to mixing styles you can do a certain amount of that in Clojure but it of course negates some of the obvious advantages of the language vis-a-vis concurrency etc.
I don't know why you got downvoted, so lets be clear: if your data is mutable it can't be safely thread-shared unless protected, can't be common between processes with unshared memory without distributed transactions, can't be inlined or constant-folded, and it constitutes a non-obvious backdoor into any function that uses it. It wrecks equational reasoning. You can do FP without immutable data, but you have to emulate immutability with discipline.
Are you sure it doesn't? It can already compile class files for post-processing by eg: Android.
Very good idea. Bookmarked.
[Seen this post?](http://www.reddit.com/r/lisp/comments/99lvv/is_there_a_functional_immutabledata_lazy_lisp/c0bx4wz)
I was aware of Liskell, but had forgotten about it. I might try it out eventually.
Most the ideas behind Haskell and ML, like "Programming should be a mathematical activity" are shared. Evaluation is one thing that is different, yes. Doesn't mean they aren't related.
ML was an early, influential language. It's helpful to think of Haskell, Miranda and SML etc as "descendants" of ML. Much in the same way that C and Pascal etc are "descendants" of ALGOL. Or that Scheme and Common Lisp are "descendants" of McCarthy's original Lisp. You can even look at A+, J and so on as "descendants" of APL. Prolog is similar (ish).
just read [David's Blogpost](http://lichteblau.blogspot.com/2009/08/cl-perec-blog-series-by-pinterface.html). Nice to see a followup on reddit! :)
You've said that Haskell _is_ ML. It makes as much sense as claiming that Pascal or C _is_ Algol. "Influenced by" is a different thing, as usually each programming language is influenced by lots of different other programming languages. E.g. it is known that JavaScript is influenced by Lisp (Scheme, particularly) and Java. So is it Lisp or ALGOL?
I have not said that they are not related. Birds and crocodiles are related, too. The ML family and the 'lazy' family are both FP languages (which dates back to Lisp, which makes both Haskell and ML related to Lisp), but the 'lazy' family is a separate branch that dates back twenty years and among Haskell's direct ancestors are languages like Miranda, which appeared after ML.
I never seriously used Lisp packages on Debian anyway. For Debian Etch latest SBCL version available is 0.9.16. Are you kidding?
I read this a while ago and I would say that I agree with everything said. *Format* control strings can easily pass from the write once regime into the no human being will ever be able to parse this control string. Also, I find that *format* actively discourages me from writing comments. My problem with *out* is that it is part of YTools and I have not (over the last 3 or 4 attempts) been able to successfully install and use it. I think of myself as a pretty smart guy, but I have resigned myself to the realization that I won't be able to use this until there is an ASDF build file. That being said, *format* is very terse (which is nice) and I would say that using it for anything that involves less than, say, 5 ~'s is probably okay as the comments can all be grouped before the *format* form.
I'm sorry, I don't think I did say that, I just said that they were strongly related. This is quite a boring and silly argument to have. Bye
68 registrations from 18 countries, now. Wow! Looks like a 'must be there' meeting!
You said it [in the comment above](http://www.reddit.com/r/lisp/comments/99lvv/is_there_a_functional_immutabledata_lazy_lisp/c0bx3o3): &gt; Haskell is pretty close, but it's ML, not lisp. "it's ML" = "Haskell is ML", &gt; This is quite a boring and silly argument to have. Bye You know, if you meant something else, you could just correct your comment to reflect that instead of engaging into boring and silly dicussion.
The `out` function being used here really irks me. There's one good thing about FORMAT, and that's that you can see the general structure of what the output will be like just by looking at the string, without the need to scan through all the code. In the first example, we can immediately see that it's printing out `x`, `y`, and `z` in some form, and you can see the structure just by looking at the string. In the second `out` example, you have to scan through the lines just to see that there's a "&gt;" being printed at the end. Of course, this falls flat when you use overly-complex formatting strings, but the complex code you'd need anyway would reflect that. But you can write unreadable code in any language, so let's not bring out the more egregious examples of FORMAT just to show that. 
Yeah, if someone can't see how being able to separate the arguments from the control string can be useful in certain situations, I don't want them removing features from my language.
Interesting, except that his proposed `OUT` language is even more annoying than `FORMAT` control strings: everything looks like Lisp, but it has a special meaning.
Egads...I thought CLSQL was nasty!
Well, i partially agree, but it's good to have the option. Also, a method like this may extend to other stuff then just formatting a string, [LML2](http://lml2.b9.com/readme.html) works a little like this. I use it for [lisp-editor](http://lisp-editor.berlios.de/) project of mine. Unfortunately it doesn't work entirely to my likings; only variables can be entered, and it's macros have annoyances; i use EVAL to use it :-/. Perhaps it is possible to create a formatter that can easily be extendable to write stuff like XML and kin too.
Looks to me like the s-expressions of OUT start with keywords. Those stand out from the regular functions/macros no?
I'd like to have both; FORMAT for those times I need highly structured output, and OUT for those times when I simply want minimally structured output...
&gt; everything looks like Lisp, but it has a special meaning. Isn't that kind of Lisp macros in a nutshell?
I think format works really well. There's a learning curve, sure, but if you're already using lisp then it's not a big deal. The hairy example could be made readable / maintainable by separating it into several calls to format.
Yep, exactly what I was thinking.
Indeed, things like i18n would be harder without control strings, especially since the order in which you print things could change from language to language (subject-verb-object permutations, left-to-right languages, etc.). 
Not really...Lisp macros almost never use constructs like `(MACRO stuff (SPECIAL-MACRO-KEYWORD other-stuff))`.
Hmm, I thought this like it is in macros quite often.
&gt; This "format control string" is essentially a little program written in a special "format control language." This language doesn't obey any of Lisp's syntax rules. I guess it's a strange premise to say that a DSL is a _bad_ thing. Of course I can see advantages of having pure Lisp-based control over formatting, but that doesn't meant that **format** has no useful role to play as a more concise language for expressing formatting.
That sucks. I like common-lisp-controller, and it seems like clc just has a lot of potential that's not being used. It's nice being able to apt-get install lisp libraries too.
This is a very bad idea, since it lumps code and output together. This means you can no longer extract the strings and treat them as a resource. That is a Very Bad Thing™ for internationalisation. Sadly I can't google up the writeup I have in mind now, so [this summary](http://www.mihai-nita.net/article.php?artID=20060430a) will have to suffice as an explanation of why the iostreams-style APIs are bad for internationalisation.
&gt; Also, I find that format actively discourages me from writing comments. How exactly does it do that? It's no different than any other general overview comment above a function, like so: (defun frobnicate (foo bar) ... ;; Display frobnicate's result and status ;; ;; FOO should be a list of lists, with the first element of each ;; sublist being the number of elements, the rest being the ;; element names. We iterate over FOO with ~:, so it always uses ;; up exactly one sublist on each step. Inside sublist, we ;; re-use (with ~:*) the head argument to special-case 1 vs. any ;; other number and add the plural -s. ;; (FIXME: This is a hack and not how you do proper plurals, use ;; a real i18n API for that, stupid.) ;; ~#[ tests for the number of remaining arguments; if zero it ;; does nothing, otherwise we output a colon (careful not to ;; confuse ~:; "else clause" and the literal colon there) and ;; process the list of remaining arguments (with ~@{), appending ;; a comma after each, until we hit the end, in which case ~^ ;; breaks out. At the end of each sublist, print a . and ;; newline. ;; At the very end, output BAR (which should be just a keyword) on a ;; separate line (format t "~:{~A element~:*~[s~;~:;s~]~#[~:;: ~@{~A~^, ~}~].~&amp;~}~&amp;~ Status: ~A~&amp;" foo bar)) CL-USER&gt; (frobnicate '((1 a) (0) (3 a b c)) :ok) 1 element: A. 0 elements. 3 elements: A, B, C. Status: OK Sure, it's kinda literate programming and you have to describe the algorithm in two places, but that's a problem with any sufficiently obscure DSL. The problem with FORMAT is not that it's dense; J is even denser and its users love it for that very reason. The problem with FORMAT is that it's a dense language that's very rarely used; you will generally write a working control string once, and then move on. I have that problem with all the parts of the language rich in optionalities. Pretty much every time I use an extra clause in DEFCLASS or DEFPACKAGE, I hit CLHS just to make sure. Not to mention the SETF expanders, those I half-deduce, half try out in REPL to be able to remember the proper argument order :) EDIT: Fixed the singular case. Note that **this is not how you should do it in production code**. It's not an example of proper pluralisation, merely of coping with complex FORMAT strings. For actual plurals, you should use a real i18n API with real support for all the many cases that exist in different languages.
Yup, I use clc on Fedora. It's very much the Right Thing for Lisp.
You mean http://common-lisp.net/project/cl-quasi-quote/ perhaps? Disclaimer: I've never used it, I just know it exists.
FORMAT isn't so hot for internationalization either. Apart from several English-centric features of its directives, it does not offer good support in cases where argument-order should be switched around for different languages.
Hey, you forgot to special-case "1 element"!
Yes, I meant to mention that, but I forgot. FORMAT itself needs to be upgraded to allow proper i18n, but the principle still holds: OUT-like APIs are inherently a disaster.
I did! Will fix.
&gt; How exactly does it do that? I am agreeing with the article here. There is no syntax for comments within the *format* DSL (that I know of). I got to thinking and I guess one could do something like this for more complicated format controls... ;; Guessing from what your code seems to do... (format t (strcat ;; Iterate over foo. Print the CAR of each element. The CAR of each element is the number of elements in the CDR "~:{~A elements" ;; Print the CDR of the list as a comma seperated list, followed by a freshline "~#[~:;: ~@{~A~^ , ~}~].~&amp;" "~}~&amp;" ; end foo iteration ;; Report staus "Status: ~A~&amp;" ) foo bar ) Here I know what is doing what (however it is pretty ugly). If I come back in 3 months and want to add that special case for 1 element, I know basically where this will need to be done. This solves every problem I have except that arguments and structure are separated, which means it is harder to see if you have an argument in the wrong place. That is a fairly minor detail. I am not going to claim that something like *out* is better than *format*, though the author did. In fact, I will reiterate that I find the terse nature of *format* to be a boon, much the same way *cl-ppcre*'s standard regex string notation seems quicker to write than its tree form for regular expressions.
`~:P` does the same thing as `~:*~[s~;~:;s~]`
the taxonomy part is also approached in 'description logics'. The system can calculate the taxonomy or check the taxonomy based on the description of the concepts (classes/types). The typical solutions in OOP is that some things will be inherited, but for much of the things the language has no facilities to say anything about the relationship of classes and whether objects should belong to some class. That's what most languages lack, a hierarchies of categories that are computable.
With each new release ECL is becoming better. The most promising CL implementation wrt platform availability and feature set accross all supported platforms.
Ah, yes, what you say makes sense. Now we just need an IFORMAT that'd support message catalogue extraction, together with the STRCAT-syntax so that it knows it's all a single string to be extracted, and positional arguments/pluralisation support for real i18n. The extraction could be performed as a part of macroexpansion, to ensure all strings get caught. I need to look into what cl-l10n provides exactly in this regard.
Don't know whether any of this works on structs, but here are my notes on slots in classes: "vanekl" &lt;v...@acd.net&gt; writes: &gt; Personally, I would be most interested in seeing how to iterate through &gt; each slot without having to know the slot names a priori. [211]&gt; (asdf:oos 'asdf:load-op :closer-mop) ... [212]&gt; (defclass c1 () (a b)) #1=#&lt;STANDARD-CLASS C1&gt; [213]&gt; (defclass c2 (c1) (d e f)) #1=#&lt;STANDARD-CLASS C2&gt; [214]&gt; (closer-mop:compute-slots (find-class 'c2)) (#&lt;CLOS:STANDARD-EFFECTIVE-SLOT-DEFINITION A #x2052E666&gt; #&lt;CLOS:STANDARD-EFFECTIVE-SLOT-DEFINITION B #x2052E6A6&gt; #&lt;CLOS:STANDARD-EFFECTIVE-SLOT-DEFINITION D #x2052E6E6&gt; #&lt;CLOS:STANDARD-EFFECTIVE-SLOT-DEFINITION E #x2052E726&gt; #&lt;CLOS:STANDARD-EFFECTIVE-SLOT-DEFINITION F #x2052E766&gt;) [217]&gt; (dolist (slot (closer-mop:compute-slots (find-class 'c2))) (print (closer-mop:slot-definition-name slot))) A B D E F NIL -- __Pascal Bourguignon__ http://www.informatimago.com/ AND vanekl wrote: &gt; Rupert Swarbrick wrote: &gt;&gt; Hi, &gt;&gt; &gt;&gt; Is there a function, which will return a list (or whatever) of the slots in a class that I've got an instance of? I'm working with a weird auto- &gt;&gt; generated binding library, which I don't really understand... and I'd like to be able to eyeball the fields I can play with! &gt;&gt; &gt;&gt; The only things I can find are slot-exists-p and slot-bound-p, which of course aren't quite what I'm after. If there's not a portable way to do this, I'm using sbcl. &gt;&gt; &gt;&gt; Rupert &gt; &gt; [211]&gt; (asdf:oos 'asdf:load-op :closer-mop) &gt; ... &gt; [212]&gt; (defclass c1 () (a b)) &gt; #1=#&lt;STANDARD-CLASS C1&gt; &gt; [213]&gt; (defclass c2 (c1) (d e f)) &gt; #1=#&lt;STANDARD-CLASS C2&gt; &gt; [214]&gt; (closer-mop:compute-slots (find-class 'c2)) &gt; (#&lt;CLOS:STANDARD-EFFECTIVE-SLOT-DEFINITION A #x2052E666&gt; &gt; #&lt;CLOS:STANDARD-EFFECTIVE-SLOT-DEFINITION B #x2052E6A6&gt; &gt; #&lt;CLOS:STANDARD-EFFECTIVE-SLOT-DEFINITION D #x2052E6E6&gt; &gt; #&lt;CLOS:STANDARD-EFFECTIVE-SLOT-DEFINITION E #x2052E726&gt; &gt; #&lt;CLOS:STANDARD-EFFECTIVE-SLOT-DEFINITION F #x2052E766&gt;) &gt; &gt; [217]&gt; (dolist (slot (closer-mop:compute-slots (find-class 'c2))) &gt; (print (closer-mop:slot-definition-name slot))) &gt; &gt; A &gt; B &gt; D &gt; E &gt; F &gt; NIL Don't use compute-slots every time. Just use class-slots. Compute-slots actually performs a computation (hence the name), to traverse the class hierarchy and determine all the effective slots for a class. This can be a relatively costly computation. Class-slots just looks up the recently computed set of slots. That's a general rule of thumb: If you only want to look at what properties a class (or any metaobject) has, avoid the compute-xyz functions, but first check whether there are any readers for the information you're looking for. Pascal Costanza AND class-slots, or the union of class-direct-slots and class-indirect-slots if you are using MCL. This is what we call MOP, not standardized I fear, so it depends on your Lisp. btw, there might be a lot of output sometimes, but some meta-help: (apropos "SLOTS") AND This works on SBCL as long as you call: (SB-MOP:FINALIZE-INHERITANCE (find-class 'c2)) before messing with the slots. 
I do what any sensible person who wants to interact with multiple external libraries and modules does: I use a language with a standard object/class system.
I guess that could work, thanks ! I had tried mop-utils, but that would only work on an instance of a structure. And the sbcl utils seemed to be limited to class definitions, I could not get them to work on structure definitions. I'll give closer-mop a try. Thanks again. EDIT: closer-mop works great, and does what I need. On SBCL it works on both structs and classes.
So you are Common Lisp user?
Not in the standard. Also note that the standard explicitly does not require structs to be classes, and so their introspection abilities might be very limited. That said, the implementations that do support MOP tend to do so for structs as well, at least on SBCL and CCL this is true.
No, but that's still a hell of a lot better than rolling my own nonstandard system, if I want to interact with the rest of word. I get modded down, but I'm not so sure these guys who roll their own are more productive with their shit systems than someone else would be with classes. (Oh the humanity! Classes! That's so limiting! Noooooooooo.)
Don't let the article get in the way of a good discussion.
If you want such introspective capability, use classes, not structs!
is that taken from http://p-cos.net/ ? Pascal works at my university, lovely chap :)
These are some of the notes I've taken from c.l.lisp. When I have a hard lisp question I search that group and then save the results in a big-ass text file so I can quickly find it again, which I inevitably need to do.
Check serialization libraries, cl-store or something. They implement this for different implementations.
Do you plan to publish that file?
it can be if you can't depend on other's libraries to be thread safe. 
I was wondering whether that would do any good, and I believe it's too personal to be of much use to anybody but the person who assembled it. I remember key words to use to search the file, as one example. Two, I collect a bunch of things I find interesting that most people don't. Three, it's not organized. Four, it's probably out of date, or has an eclectic mix of data that would confuse the average person. So, no, I don't plan on making the notes public, but I highly recommend everybody keep a big-ass text file themselves. I have four of them that I regularly reference. Looking through my notes has saved me days of time, showing me how I solved previous problems. It's also kind of fun to see how your thoughts and work have changed over the years.
I was asking because I also have my notes files and I'm not sure if it will be valuable to other people. 
Yeah, that's the one I was thinking of, but mostly I was being a wise-ass.
This is one indicator of a professional, imo. They tend to keep project logs or notes files. You would be the best judge as to the value of your notes files. I would probably find parts of it interesting, I'm sure, but I'm strange like that. I mean, come on, I choose to program in Lisp.
&gt; I use a language with a standard object/class system. Common Lisp has a standard object/class system. It's called CLOS. Common Lisp is also powerful enough to support many other OO/class paradigms without leaving the language, and most Common Lisp implementations are also powerful enough that you can leverage parts of their internal CLOS machinery while doing so (i.e. they expose some level of meta-object protocol.) You don't have to pull a Stroustrup to take the language in new directions. EDIT: your apparent ignorance of this, and that you don't allow that ignorance to keep your mouth shut, is probably why you are being modded down.
&gt; Common Lisp has a standard object/class system. It's called CLOS. Yes, but the article isn't about Common Lisp, is it? It's about some guy rolling yet another object system which is going to fix all the world's children's problems.
1) bolting on immutability through a library has issues that a language like clojure avoids. 2) you implied that clojure has this problem as well because it's bolted onto java. Clojure code does not have this problem assuming you stick to clojure code, which is far different than saying "if you stick to this library". 
Also clbuild is a nice tool for pulling these all in, plus more.
surely it is. Generally I know that if I'm using a clojure library that the data structures are immutable and it's thread safe. If I'm using some CL library for immutability then I use another CL library in my code there is a good chance for an impedance mismatch. I'll need to write wrappers or proxies and jump through other hoops to get them to play nice.
I find it odd that you resort to insults so quickly rather than considering another persons point of view or at the least explaining what your absolute certainty is based on. In any turing complete language you can do anything you can do in any other. We can greenspun anything into any of them. However, the ease with which something is made is important. One can certainly go out of their way to break clojure's default way of doing things, but clojure makes it easy to do the right thing in this regard to concurrency. CL does not do immutability by default. You can do it in CL, but as I've said you end up jumping through a lot of hoops and dealing with pain that wouldn't exist on the clojure side. 
the person that resorts to insults is the one that lacks insight. 
Start with Common Lisp. Add FSet. Done. http://common-lisp.net/project/fset/
I've noticed that mathematicians pay no attention to scope. "f(x) = 3. f(x) is a function." No - f is a function. But I was just recently blown away by Euler's e^(i*x)=(cos(x)+i*sin(x)) thingy so I am not a real student of math either, or yet, so what the hell do I know.
Yeah, look at those noobs at Trolltech. They saw that C++ was lacking, rolled out their own nonstandard extensions to C++. Now you have to roll code over extra pass to get their class system converted into C++. How can people say that their QT is extremely good and portable API. 
Some people are successful in creating a new language. Maybe one in 10,000 catches on. You tell by how well the ideas hold up over time. The chance that some blog post describe a way of doing things that will pass the test of time is 0, to about 4 orders of magnitude of approximation.
Some people are successful at creating libraries, functions and structure of their own. In Lisp you can add language constructs or modify object systems as well. Why in house object systems should be something extraordinary?
Lisp blurs the line between library and language, which is both its main strength (when 1 brilliant person is working on the code) and its main weakness (when more than one person is working on it.) &gt; Why in house object systems should be something extraordinary? Because there are hundreds if not thousands who have attempted the same thing, and chances are 100% (to several orders of approximation) that someone else has done it better. In other words, an extraordinary in house object system needs to be extraordinary.
I actually had that idea, but they work on an instance of an object, I needed to get the info without access to a specific instance.
I haven't finished watching it yet, but this made me laugh: &gt; Scott McCay likes to say, 'It's not complex, it's complicated.' QPX is complex. It has deep algorithms. RES is just one damn thing after another.
Peter Norvig is there, too.
Hard to miss the loud shirt and white hair!
yep
I wrote some [notes on the talk](http://xach.livejournal.com/225634.html), for those who want to know if it's worth the 60 minutes. I enjoyed it, but it wasn't quite about what I thought it was.
Interesting stuff. I am not sure the airline industry will be happy to hear some of the things he has to say..
http://www.loper-os.org/?p=42 http://www.reddit.com/r/programming/comments/8w0l9/i_find_clojure_revolting/ http://www.reddit.com/r/programming/comments/9c0gf/clojure_the_zombiereanimated_corpse_of_lisp/
TÖTEN SIE ES MIT FEUER!!!
Cheap flamebait. Nothing to see. Move on. 
Wow you really shot down all his arguments, great going!
I didn't see any actual arguments. It was more like 'it is not Common Lisp, this is bad'. It didn't say why it is bad, whats wrong with the macro wrappers etc. I agree with the disclaimer although Zed usually criticizes in a more productive way.
The complaints are too vague. Where specifically does Clojure get things wrong?
They were discussed the other post of his screed. Now he's just being a troll, so `reddit_clone`'s response is appropriate.
I can't really say i know Clojure, but there are at least these arguments against it in the article. * "Clojure has inherited many of Java's idioms and problems." * "... many Clojure types are Java types underneath. Look at the sequences that wrap some of Java's collection types. There is a fundamental and idiomatic clash in Clojure's type system" * Getting java libraries to work nicely might reduce them to overuse macros. * It will be generally overhyped. From what i do know of clojure, i have an additional worry. The [] and {} denoting are touted as representing other data structures. Not particularly unlispy, yes. But also not particularly smart. The way Common Lisp could do it is obviously much better; reader macros can automatically treat them as lists, and prepend, say, '[] or '{} infront, which the macros can then read. This way the code doesn't contain structures other then list, and it remains closer to regular lisps for no cost at all. (Hell, you can even make destructuring-bind and macro functions take these {} and [] to use them.)
I can't find [other mentions of clojure](http://www.google.com/search?hl=en&amp;q=site%3Ajng.imagine27.com/%20clojure). It might be that he just isn't convinced by the arguments, that doesn't make him a flamebaiter.
I meant the [other post on reddit](http://www.reddit.com/r/programming/comments/9c0gf/clojure_the_zombiereanimated_corpse_of_lisp/) of the same screed.
No, [Haskell is not not ML](http://research.microsoft.com/en-us/um/people/simonpj/papers/not-not-ml/). 
[Lisp Bulletin #1 (PDF)](http://www.softwarepreservation.org/projects/LISP/periodical/p17-bobrow.pdf)
You can download a 300+ PDF with the Lisp-related content of the AI newsletter of the AI interest group of the German Gesellschaft für Informatik. Content is in German and English. Of historical interest with lots of diverse material.
&gt; verlet-autoaddsstruts verlet-auto-add-struts &gt; circuit-AddNode circuit-add-node We have well-established and very sensible naming conventions. Gratitiously breaking them is not a good form, especially if you can't even pick a consistent way to break them. 
The arguments pose more questions to me than answers * Which idioms, which problems? It is like saying Algol descendants have inherited many idioms and problems from Algol, but what are these? * What is the problem with Clojure types being Java types underneath? ABCL also uses some kind of Java types to represent the Lisp data structures. * I want an example of macro overuse and where it is bad. As it stands it is just like saying "yeah, this is bad", no substance. * Hype can be a good thing. Take a look at the number of libraries on Hackage. OTOH your additional argument is much better and I can somehow understand that the way CL does it is better. But the original article would just say "[] and {} represent other data structures. This is bad, take my word for it".
I agree, he should be more specific about the problems he says he sees. Higher order functions have better ability for the compiler to choose what to do. (dolist (el list) body) (mapcar #'some-function list) The first one, it has to expand the code, the second one, it can choose whether to expand the code, or to save space, and use the function map with the function as argument. Of course with the example, the macro can still easily convert to mapcar, but in more complicated cases it cannot. Intermediate data can be prevented with compiler macros, at least to some extend. I also tend to prefer callbacks, which gather data at the end of the functions, rather then passing them between the functions. Macros can also be abused much easier in general, i suspect that in contrast higher order functions 'guide' you to more elegant code. However, i can't really say this is a well founded position. If i only knew more math relating to this, it seems that that part of the discussion is often left out. Because it is easier to only work with experience, not theory about code.
I'm terribly sorry. If you don't like that, what I had before was even worse. I started off with verlet_AddNode. I changed it shortly before packing it up to be posted. Interesting how having to release something puts a sudden focus on polish and usability. Also, until I change it in the next version, feel free to: (defun circuit-add-node (x y) (circuit-addnode x y)) The extra "s" in verlet-autoadd**s**struts is intentional, if ugly - it means "structural". I want to slowly transfer more of the implementation to lisp, in order to practice using it. So in case you thought otherwise, I am only now beginning to learn lisp. Edit: Instead of putting circuit- or verlet- or origami- in front of a function name to indicate which system it belongs to, do they belong in separate packages?
&gt; I want to slowly transfer more of the implementation to lisp, in order to practice using it. So in case you thought otherwise, I am only now beginning to learn lisp. Ah, fair enough. Consider the above a friendly advice then. &gt; The extra "s" in verlet-autoaddsstruts is intentional, if ugly - it means "structural". That kind of proves my point :) -- I simply missed that double s there because it was so hard to read. CamelCase does make it marginally better, but at the cost of being damn ugly (and it won't work very well in Lisp anyway, due to case mangling, so you lose every time the name is displayed). "Sstrut" on its own is not that bad a name; it's very concise while being reasonably readable, so that part is alright as long as the rest of the names is done properly. Good luck with your refactoring. &gt; Edit: Instead of putting circuit- or verlet- or origami- in front of a function name to indicate which system it belongs to, do they belong in separate packages? Yes. They are separate chunks of functionality and there's a good deal of overlaps in the names, so separating them into packages is very sensible. EDIT: Oh, one more point, regarding the submission itself: if you post an update, it's a good idea to mention that in the title, instead of reusing a previously posted one. It took me a while to figure out it was an update and not just another pointless duplicate submission.
This is an update of the program mentioned [here](http://www.reddit.com/r/lisp/comments/8vrnr/for_anyone_interested_in_ecl_here_is_an_example/), not a duplicate post.
somehow I would also think about how to grow and drive a language: by research papers or by application needs? Currently the Scheme language seems to be driven by research papers and the outcome can be seen in R6RS: the record system and the library mechanism is a good example. More successful languages have been driven by hackers, thus are technically inferior to Scheme in some ways but socially superior. What I also find disturbing is the misguided language (same for R6RS): *purpose of a programming language is to program*. Who programs what? The purpose of a programming language is to enable **humans** to write programs that **solve their problems**. The purpose is not to just 'write programs' without context. The purpose is embedded into a social context. To communication solutions. It is not 'write programs', it is about how to write programs, with what people and what for and who the endusers are. A programming language that stays in the abstract and does not make a commitment to some methods, some things it wants to achieve may have the problem that noboby really nows why this language should be chosen for some programming task. R6RS created controversy because it shifted the context (away from the educators, from the hackers, away from the small-language-enthusiasts, away from the dynamic software development, ...) to something that has a design that has outgrown some of its community and something that lacks passion/art/hacking. I should add that I always admired [SRFI](http://srfi.schemers.org/final-srfis.html). I still wonder why given lots of work into useful extensions why R6RS is so ugly. Funny that the position statement not even mentions SRFI. Something controversial to the end: **let the language designers go and the programmers come**.
Any proper Lisp should allow any sufficiently advanced programmer to use language design to solve problems practically.
&gt; Funny that the position statement not even mentions SRFI. The new (draft) [charter](http://scheme-reports.org/2009/draft-charter.html) does. Basically SRFI is seen as the way to communicate with the community. &gt; Something controversial to the end: let the language designers go and the programmers come. Schemers have been doing just that for a long time; the amount of implementations we have is the direct result. This is the main problem of standardization in Scheme-land: if the intersection of top Schemes is even less then R5RS (e.g. quote: "Current Bigloo does not ensure hygiene for let-syntax and letrec-syntax"), what do you standardize?
How about a conformance test suite and regular posting the results to some website? Rank the implementations by two factors: support for RnRS (for some value of n) and support for SRFIs. If there are so many implementations, it might be useful to rank them to help users choosing a conforming one and being able to guide implementors what they are missing. Why not put more effort into 'forcing' the implementations to conform more, than to standardize controversial stuff? 
I'm still waiting for the "cockamamie" and "Ponzi" versions of the language.
I kind of like the idea. On the other hand, you often choose implementation not by it's standard conformance, but by it's speed, available libraries, etc. Some Schemes have completely unique selling points (green threads in Gambit-C, optional static typing in Bigloo, etc). So a conformance survey may be interesting by itself, but it will won't serve as a natural selection force. Besides, it's like you said, the designers went; you can't catch them now.
&gt; How about a conformance test suite and regular posting the results to some website? [Alexey Radul at MIT is working on exactly that.](http://web.mit.edu/~axch/www/scheme/choices.html). 
you could call one lisp and one scheme
&gt; Note that this list of features does not include exceptions, modules, concurrency, unicode text, or mechanisms for defining union types, record types, or abstract data types – yet these too are often important. Could anyone knowledgeable in Scheme (and implementing Scheme) talk about why the above are not standard features of all scheme implementations? (Modules, Record types, and Unicode are the ones that interest me the most)
thanks!
SRFI is a description of extensions, libraries, etc. Conformance to SRFIs gives the user an idea what extensions the Scheme supports. There might be additional extensions and unique selling points, it might be worth to describe those also as SRFIs then.
I guess we disagree on the "practically" aspect. If i need unicode, what am i supposed to do? write that myself?
the lisp one might be very popular too... it might be common for people to use it. Maybe we should call it Common Lisp.
If the unicode implementation is broken, it should be replaceable. In a practical manner.
The problem here is that there is no implementation, and that is one of the issues that these people are trying to address.
It's somewhat complicated. The history of Scheme is summed up rather nicely by the following quote from r5rs: &gt; Programming languages should be designed not by piling feature on &gt; top of feature, but by removing the weaknesses and restrictions that &gt; make additional features appear necessary. Unfortunately, the last [report on Scheme](http://www.r6rs.org/ "r6rs") attempted to "pile" quite a few features into the language, and wasn't very well-received by the community. Some of these features include: * [Unicode](http://lists.r6rs.org/pipermail/r6rs-discuss/2007-August/003251.html) * The [Module System](http://lists.r6rs.org/pipermail/r6rs-discuss/2007-August/003166.html) Even the way the report was ratified carried a lot of controversy. An interesting post on it: http://dekudekuplex.wordpress.com/2009/02/26/too-much-is-not-enough-the-revised6-report-on-the-algorithmic-language-scheme/ The problem is not that these aren't standard features (as most implementations have them in some form), but that they're not *standard*.
Wow thank you so much for these links. The blog post in particular is worthy of its own submission. EDIT: post has comments/rebuttals from Matthias Felleisen and Robby Findler. This is GOLD jerry GOLD!
For more Scheme history, you *have* to read [the Lambda papers](http://library.readscheme.org/page1.html) -&gt; in the beginning, there was λ...
I tried using this table (combined with some other checks I came up with) to write [a small library](http://willdonnelly.wordpress.com/2009/03/14/runtime-scheme-detection/) for determining the host scheme implementation at program runtime. I sent a list of the additional tests I had written to the table's maintainer, but it doesn't look like they have been added yet.
more like a summary than a real review
I thought everyone just rolled their own.
Thanks for this. To my knowledge, this is the only book on clojure currently published.
Seriously, that's not very interesting or Lisp-related.
Easy loading and execution of code is a security problem. There are not many answers to this in the Lisp world (like sandboxes, verified code, signed code, etc). It might be useful to think a little about this. The article shows that Lisp programs may have security problems too and also special security problems (due to code as data, late binding, ...).
That's a good point, and incidentally something I was thinking about recently. I think, however, it'd be much better served by examples from how LispMs did that, not by a tiny, crappy Lisp bolted onto AutoCAD. IMHO, this particular case (and the article, as it happens) is about as insightful for Lisp-related questions as a mention of VBA vulnerability. Do you have anything in your library that'd explain how Lisp Machines dealt with problems like process isolation, the possibility of botching your image (not that hard to do during development, and very problematic when restarting your image == restarting the machine) or security, if at all? I know they were single-user (and no idea about multitasking), so a lot of security or process isolation questions might've been skipped, but at least botching the image is a very serious problem for a naïve LispOS implementation that I don't know how to deal with.
The Lisp Machine prevents heap corruption by hardware checking of operations. That's it mostly. There are not even passwords when you log in. Want to rewrite IF? Sure, the system warns, but let's you go on if you want. Processes, yes. Isolation? No. Making your Lisp image unusable? Try a warm start, if it is temporarily locked somehow and the usual commands to unlock processes, windows don't work. If that won't work, reboot. After a while you learn to avoid trouble and then it may run for some time. Kind of a video game where you learn to avoid losing your life, because you would have to start a the beginning of some long stage. Symbolics then wrote some software to keep end users (for example 3d graphics designers) from easily shooting themselves into their knee by doing such stuff (for example by typing to a lisp listener). The point is not about a 'crappy' Lisp bolted onto AutoCAD - the problem is the same independent of the Lisp, here a commercial vendor of a popular Lisp-using application has a problem, because it is popular enough that some people invest the time to write viruses for it.
&gt; After a while you learn to avoid trouble and then it may run for some time. Kind of a video game where you learn to avoid losing your life, because you would have to start a the beginning of some long stage. That's what I was afraid of. Unfortunately this is not an option in today's world of universal connectivity to the malicious world, and even more importantly, computers being the hub of many/most everyday activities. I sure wouldn't like it if accidentally hosing the image during coding would also mean that my IRC sessions, IM windows, music and everything else goes away. Sure, being able to poke at any level of the system at any time is super-handy, but also super-dangerous. It would need some very careful thinking to expose it in a way that can't be invoked accidentally or maliciously. It's a tough problem. &gt; The point is not about a 'crappy' Lisp bolted onto AutoCAD - the problem is the same independent of the Lisp, here a commercial vendor of a popular Lisp-using application has a problem, because it is popular enough that some people invest the time to write viruses for it. The point is however that it offers absolutely no insights applicable to a modern CL implementation above what a VBA worm would do. Even the fix is indistinguishable from one for a MS Office virus. Any sufficiently popular "scripting" platform will be exploited, that's not news.
What version of Clojure are you using? I'm using the latest Clojure 1.1 snapshot on Debian 64bit Linux and the Clojure version is within 20% slower than the Java version. Sometimes the Clojure version is faster.
Cool, congratulations!
see also the [discussion on ltu](http://lambda-the-ultimate.org/node/3582).
BioBike is quite a nice framework. I use it to run ACT-R on top of it. The idea behind this is to enable collaboration between cognitive scientists using ACT-R.
What advantages does XCL have over other implementations?
It's still ver youg, but the site says it's supposed to be (in the future) very lightweight/embeddable but also fast. Right now it's slow (I just tested it). 
How is that different from ECL?
I suppose he wants it to be "as fast as SBCL" but also as lightweight as ECL, which is pretty difficult but not impossible...
With babby bolts?
XCL: &gt; native-code implementation of Common Lisp ... optimizing compiler written in Lisp ECL either uses C compiler or works via interpreter. 
A friend of mine just pointed out this submission. I wrote and operate this trip planner, and I've released [a couple of GIS-related libraries](http://enroutesystems.com/software/) that I wrote during its development (with more to come).
It builds and runs: alan@inder$ ./x XCL 0.0.0.274 (built Mon Aug 24 22:45:53 BST 2009) Copyright (C) 2006-2009 Peter Graves Only slight hiccup on my very old install of FreeBSD 5.4 is that it needs GNU make, not the native make, but I've encountered this before and could just type "gmake" when "make" didn't work.
I disagree with this blog. And trying to map exceptions from a language that doesn't have resumable exceptions (c++) to one that does isn't very useful imo. I can agree to the convention that you derive your exception from error if you mean the stack can be unwound without a problem and derive from serious-condition if it must be handled. I don't understand the talk about the "type". You decide what kind of exception it is based on what exception it is derived from...
the mentioned error glossary entry is about 'is an error' phrases in the language spec. It has less to do with the condition system.
Which website? Not reddit.
Hacker News
I was looking forward to seeing excercises, puzzles and interesting ideas for things to try with Lisp. Instead, the article features the following pieces of "advice": - A fresh, steaming pile of linux advocacy. Here is a summary: "Lisp is better on linux than on windows. Anyway, you shouldn't use windows, lol" No thanks. I've found many many ways to use and take advantage of Lisp without having to turn my computer hardware into a doorstop. - The earth shattering idea of reading a book about Lisp: "Have you heard of "ANSI Common Lisp" and "On Lisp" by Paul Graham? They're about Lisp. You should read them, lol" I'm sure glad I considered your innovative approach to learning Lisp by reading 2 of the most well known books about it - I've been trying to learn Lisp by drinking yak's blood while dancing around my desk with a teapot balanced on my head. 
The first few sections can be summarised as: &gt; Use Linux because Windows sucks [for Common Lisp] which I know even though I've never used or even extensively researched [Common Lisp in] Windows and am inexplicably proud of that fact. Also, Windows sucks, blows, fails, kills babies, and insulted your mother. You would be better off jumping through enough hoops to build a space elevator than trying to program on Windows. This is not helpful. At best, it alienates the vast majority of possible users for no reason (for those curious, it's quite practical to use Common Lisp on Windows).
Oh neat, this evolved from ucw+, a fork of the ucw_ajax branch of UnCommon Web. Neat to see that it is still being hacked on. It's nteresting how it has diverged from UCW over the last couple of years.
I am, according to the article, in the "safe zone", since I'm already using linux. However, while learning lisp under linux (sbcl), I find it very important to be able, in the very near future, to develop/run on windows as well (still sbcl?). Clearly, this article is of no help to people in similar situations as me. D'oh! Thankfully, even as a n00b, I know enough to just look further.
I've always thought [W7](http://mumble.net/~jar/pubs/secureos/secureos.html) was an interesting solution... If it worked in conjunction with eval to provide something like Perl's Safe, it would be perfect... edit: formating
Why? EDIT: I think it is a valid question to ask why anyone would like to do that, so I don't see why I got all the downvotes.
Python libraries are available to Lisp programs.
If they do it right, it ought to be fast
&gt; I've been trying to learn Lisp by drinking yak's blood while dancing around my desk with a teapot balanced on my head. Now that sounds interesting!
Any benchmark against CPython ?
Aren't most Python libraries just wrappers around C libs. To use them CL Python would need to simulate Python's FFI (For CTypes this wouldn't be too hard, I think). It would seem to be most useful as an alternative scripting language for people suffering from parenthofobia. I like it.
Is it based on ABCL? Why C++? Does C++ have many optimization strategies specific for it's features it has over C? (And is it best to do those via C++ rather then optimization tactics in the Lisp implementation?) Love to see the link when it has more rationale, etcetera.
It seems from [this link](http://common-lisp.net/pipermail/clpython-devel/2008-October/000147.html) that the C API is *not* part of CL-Python. I.e. it is for "pure Python" libraries + CL, not for "Python libs that depend on C". This is a pretty straightforward consequence of running on stock CL implementations. I have thought about trying to create a Lisp implementation that supports a CPython-compatible run time, but this would probably not be compliant with CL: e.g. support Python object model, not CLOS, not support multiple return values, but support tuples instead. But it might be possible to extend a Lispy Python in the Lisp direction in ways that conventional Python could not be, by exploiting Lisp macros.
Windows is an embarrassment to computer science, technology, industry and mankind itself; the willing use of Windows is an indicator of mental disease.
I'm not entirely sure what you mean, but given the presence of macros, you can't compile something that relies on a macro definition without having defined that macro. What is it you are really trying to do and why? 
Implementation is hidden within packages. Interface is exported. See the defpackage statement in the hyperspec, or study any non-trivial lisp program and see how packages are used. [Mr. Gat's Package Guide](http://www.flownet.com/gat/packages.pdf)
Good point about macros. But what if we assume that macros are never exported from modules? I have a large collection of lisp code split over many systems and I would basically like to manage the compilation of modules better. Exported macros make this very difficult, which is why I'm slowly starting to think that exporting them is a bad idea in general. As to the original question: Suppose I have a system consisting of two modules, A and B where A depends on B. How would two coders best go about implementing the modules simultaneously? Bonus points for no style warnings.
Circular dependency bad!
Ok ... what do you mean by 'modules'? I still have trouble making sense of what you want... in the case of two coders implementing 'modules' from a spec (right?) .. you just do it... why do you care about style warnings that will obviously not exist when you compile the entire system? Assuming macros are never exported from 'modules' is silly... this is CL, we use macros. I also don't quite get what you mean by 'compilation of modules', given that lisp has no such thing as modules... but what you are asking for seems somewhat impossible... you can't compile references to packages that don't exist.. and since packages are usually the way one would manage what's exported from a 'module', well... Why not just create a stub 'module' A* that exports the interface defined by the spec for A from which B will be working... programmer A fills out the stubs, programmer B uses them. lets try this again: What problem are you trying to solve, and how does compiling 'modules' separately actually solve the problem rather than create new ones? I'm still not sure how you've gotten yourself in a situation where this is an issue.. can you show some code perhaps? All in all, i think if you're having this problem, you're doing something wrong :). 
Actually, supporting Python's ctypes should be possible (using e.g. the portable CFFI library).
&gt; Suppose I have a system consisting of two modules, A and B where A depends on B. How would two coders best go about implementing the modules simultaneously? How would you implement simultaneously if A depends on B ever? B needs to be defined before those parts of A which depend on B are started.
By "module", I mean a collection of related code forming a logical unit with a clearly defined interface. The problem I'm trying to "solve" is one of scalability and programming in the large. If you modify a macro you're basically forced to "find -name '*.fasl' -delete" for every (asdf) system that makes use of the macro. This isn't particularly nice if compiling everything takes roughly 15 minutes. In teams of programmers it's even worse; every time somebody updates from the repository they need to know whether a macro that affects their work has been modified. This becomes harder as the code base grows, as ASDF seems to offer no facilities for handling this problem. Often, the easiest thing to do is to just to delete all fasls and recompile the whole thing. This is both annoying and costly, and why I believe that exporting macros isn't the best idea. With large code bases it seems natural to split them into pieces so that people can work on each piece independently of the entire application. Knowledge of the various interfaces in the system is still required though, which is why I would like to know if there are any best practices for specifying these interfaces.
You could implement simultaneously if A knows about the *interface* to B (using defgeneric, for instance).
A good introduction / guide to weblocks would be great!
I am not particularly familiar with Python, but many of the libraries I have seen don't use ctypes, but rather the Python/C API to provide Python modules where the actual executable guts are written in C for performance, not just using ctypes to wrap C libraries. The Python/C API involves the C parts making calls to the Python runtime, creating dependencies on things like the Python garbage collector, etc., which are unlikely to be compatible with the Lisp implementation. But perhaps I am misjudging the relative population of Python libraries.
btw - does anyone know about other medical areas where clinical data produced by patients could be useful?
How does ASDF not allow you to specify this dependency? All removing a FASL does is force re-compilation of that file? Unless you have some magical modification of a macro without changing the source file of the macro.
Unfortunately ASDF doesn't seem to force recompilation across module or system boundaries. So if module A uses a macro from module B, and the macro in module B gets changed, 'load-op will only recompile B, not A. This means that the fasls in A do not reflect the current macro definition in B.
right ok... have a look a xcvb, it solves a lot of those issues. Besides that, no, there's really no best practices for such a thing... it's not a major issue in the real world unless your compiler is _really_ slow or your system is _really_ big. If you're making a lot of changes to macro-using code, you might want to consider developing in an interpreter... this avoids the compilation problem entirely. 
Yes, I've looked at xcvb and it's quite exciting. I also have my own experimental (but fully functional) build tool that handles the macro problem correctly, but it's currently incompatible with ASDF. So unless the whole world decides to ditch ASDF in concert, that's what I'm basically forced to use, because my experience is that the overhead of using multiple build tools in the same project is too big (it's also confusing for the more inexperienced coders). 
asdf has a force option: :force t
I wouldn't call ASDF a 'build tool'... ASDF is A(nother) System Definition Facility... It's an extensible tool used to define system (sets of related files and how they depend on each other) rather than a build (sets of related systems etc). This is unfortunate. A tool along the lines of ASDF-DEPENDENCY-GROVEL with a bunch of intelligent machinery might work. Build a list of files that expand a macro when initially compiling the system using *macroexpand-hook* and *compile-file-truename*... the rest is all in the interface after that... you could probably hook it into ASDF with ease. Beyond that, you use generic functions to define 'interfaces', which are known as 'protocols'. You export the symbols that define the protocol from a package, and your coders write to the protocol. 
Guessing here: Peter Graves is using what he learned in implementing a CL in ABCL and applying it to XCL.
You're fully right, and I didn't mean to imply I disagreed... I just hope that now that there are several Python implementations, developers will try to make their libs portable across themby using more ctypes and less direct C/Python interfacing. Btw for IronPython they made something that fakes the CPython interface, and made some big libs work with that. It required hacks for faking garbage collection, but it apparently worked well enough. Never say never.
asdf compiles across package boundaries if you specify dependencies in the .asd file.
Not that you couldn't have CFFI'd to a standard python interpreter in the first place.
I'm afraid it doesn't work. Try it if you don't believe me. And the force option is basically equivalent to "find -name '*.fasl' -delete', so that doesn't help either. The sad truth is that ASDF just doesn't cut it for big projects.
I did test it out before posting. I "touched" a file in one of my dependencies and ASDF automatically rebuilt the fasl for me when I reloaded my project. Your system may act differently, but I don't have any problems as long as all the dependencies are properly specified in the asd file. [I tend to keep an up-to-date set of asdf files so that may have something to do with it.] I have to agree with you that ASDF has its problems, but if you are diligent in specifying all dependencies, asdf _will_ recompile them. The hard part is in figuring out all the dependencies, and keeping them straight when the code is refactored. One tip: the way you keep the compiler from complaining when you have circular dependencies is to forward declare the function as an empty stub. The empty stub will satisfy any dependent code and will get overwritten later with the real function. You can also put an 'error' statement in the stub code just to make sure the stub code never gets called without alerting the developer that there is a stub that was never defined later. Sorry to hear that your asdf isn't properly recompiling external packages for you. Works for me, but asdf is a little tempermental at times.
It is written in and generates some really "interesting" CL.
Here, try this. foo.asd: (asdf:defsystem foo :depends-on () :components ((:file "foo"))) bar.asd: (asdf:defsystem bar :depends-on (foo) :components ((:file "bar"))) foo.lisp: (defmacro foo () '(format t "Hello~%")) bar.lisp: (foo) Then run: sbcl --noinform --load foo.asd --load bar.asd --eval '(require :bar)' --eval '(quit)' ==&gt; Hello Then change foo.lisp into (defmacro foo () '(format t "Goodbye~%")) and save the file. Then run the previous command again. It still prints "Hello". 
considering how much associate professors make, I don't think we're ever going to have to worry about malware targeting lisp environments...
Yes, in this case it doesn't work. The irony is that it _did_ compile across file boundaries, but not the target file itself. Of course using the force option fixes that if macros are redefined, but, as you say, that can be inefficient.
I could actually live with the inefficiency, but what's really disturbing is that it very difficult to know *when* you need to use the force option in a team of programmers committing to the same repository. Improving test cases and communication within the team could help here, of course, but that's not always easy either. It could easily degenerate into a situation where everyone is so paranoid about voodoo bugs caused by out-of-sync fasls that they always use the force option (or "make clean") just to be on the safe side.
There's some cool stuff in core server. Shame about the license though.
Most of the time you can split a macro into a function and very thin syntax layer on top of that. This means that you don't need to recompile system B when you modify system A, because it is very unlikely you will modify the syntactical abstraction in your macro. See http://common-lisp.net/project/cl-def project and the definition of with-macro for example. This provides a solution for that problem and the quite often used with-* macro definitions.
I guess he hasn't heard about the CLR version of Clojure, has he? Or maybe he hasn't heard about Clojure at all. I bet if he seen the progress on the CLR version of Clojure, this post would have never happened. Personally, I'm a Wiccan. I have no concept of sin. Therefore, I'll continue using Lisp. :D EDIT: I just noticed that this article was written a year before Clojure. Forgive me ignorance.
&gt;Clojure [Appeared in 2007](http://en.wikipedia.org/wiki/Clojure) &gt;This text is [Published Sunday, January 15, 2006 6:18 PM by sriram](http://blogs.msdn.com/sriram/archive/2006/01/15/lisp-is-sin.aspx#513096) *edit: forgiven
"Thine holier programmere shoulde withe faithe resiste suche luciferian powers whiche springeth forthe frome thou forbidden language, all withe unquestioning obedience unto thine Moste Holie Churche of Thy Dogmatick Industrie ande Acadamiea whiche defineth thee modderne populous of programmeres. Bye contrarie, thee exceedinglie greatere thou programming langeuage's siin factore, muche more withe cherishing shoulde thine Heretick programmere pursueth thee analiesis ande practickal usse therre-of !" -- Thee Utmoste Heretickal and Siinful Programmere 
The more delicious it is, the more Hershey it has. Why is Hershey so delicious?
http://groups.google.com/group/core-server/browse_thread/thread/ac8d223519b2b540 examples are fixed.
downvoted for argumentative title not explained in the entire article. 
From the article: &gt; I was on vacation a couple of weeks ago at my parents' house in Chennai. My dad and I share a love for James Bond movies so my dad had bought a set of DVDs containing all the Bond movies in existence. I can't help but strike a politically incorrect analogy - Lisp is like the villainesses present in the Bond movies. It seduces you with its sheer beauty and its allure is irresistible. A fleeting encounter plays on your mind for a long,long time. However, it may not be the best choice if you're looking for a long term commitment. But in the short term, it sure is fun! In that way, Lisp is...sin.
Google to the rescue. http://weblocks.viridian-project.de/ 
nice board, go feeley!
Executive summary: There are some cool concepts in Lisp but they are too hard to understand, unless they are implemented in a Microsoft controlled language in a way that runs completely against the grain of the rest of the language and look like the aesthetic equivalent of running nails over a chalkboard. 
this is great, if it works :-)
I guess that a problem with this is that once one learns enough CL, he does not want to work on p6 anymore.
I wonder whether they got any backing by CL implementors (SBCL, CMUCL, CLISP, Allegro, Franz, CCL?).
Cool idea, but website is super slow.
Would have benefited greatly from packing those 17 options into one screen.
where's smalltalk?
probably runs on Ruby on Rails ;)
No list of packages? No list of maintainers? Retards, whoever they are. Why would I want to download a random package collection not knowing what is in and who made it?
Zoom out.
the project sounds interesting, but sadly you are absolutly right! :(
so far most authors not knowing Lisp but writing about it don't have a good track record when it comes to substance, correctness, etc.
Excellent idea. Could still use a list of which packages, autodocs(some libs lack doc strings :/), maybe additional human-written docs.
1. domain is registered to Daniel Herring 2. dherring username in bug tracker. 3. from http://libcl.com/help.html &gt;I can't do this alone... &gt; &gt;Below is a quick list of things which would be helpful, sorted by general population. Feel free to think of (and implement) others. &gt; &gt;Thanks, Daniel pagages according to packages.txt :ALEXANDRIA :ANAPHORA :TRIVIAL-FEATURES :BABEL :CFFI :CL-UTILITIES :ITERATE :METABANG-BIND :ARRAY-OPERATIONS :ASDF-SYSTEM-CONNECTIONS :BORDEAUX-THREADS :CH-UTIL :CLEM :SALZA2 :ZPNG :CH-IMAGE :CHIPZ :TRIVIAL-GRAY-STREAMS :CHUNGA :CL-BASE64 :CLOSER-MOP :CL-CONT :METATILITIES-BASE :CL-CONTAINERS :CL-FAD :CL-GRAPH :CL-JPEG :CL-PPCRE :CXML :FLEXI-STREAMS :LOCAL-TIME :CL-L10N :DYNAMIC-CLASSES :CL-MARKDOWN :FFA :CL-NUMLIB :CL-PDF :CL-VECTORS :CLOSURE-COMMON :DEFSYSTEM-COMPATIBILITY :FLEXICHAIN :MISC-EXTENSIONS :FSET :HTML-TEMPLATE :IEEE-FLOATS :ZLIB :IMAGO :IRONCLAD :KMRCL :LML2 :MEL-BASE :MOPTILITIES :METATILITIES :PARSE-DECLARATIONS-1.0 :PNG-READ :PURI :SKIPPY :SPATIAL-TREES :STEFIL :TRIVIAL-SHELL :TINAA :TREES :ZPB-TTF :VECTO 
I did.
&gt; I can't do this alone... Daniel really does it a weird way... Clearly he recongizes this should be a community effort, but, then, why not ask community first? E.g. he could post a message to comp.lang.lisp, asking who would like to participate in a community effort like this, then IF there are enough members, they can form a working group, decide who they will make decisions (because if there is more than one member there will be conflicts), then pick a list of libraries and make a release. Instead Daniel, not asking anyone, picks some libs according to his own preferences (I like how it does not include `split-sequence` which is quite popular lib, but includes `cl-markdown` which is quite niche) and makes a release himself. Probably he does not believe in community, I think it is reciprocal -- community does not believe in him either. It started as a one-man project and will probably and as one-man project, being just another "prior art" for a library collection of this kind.
&gt; Clearly he recongizes this should be a community effort, but, then, why not ask community first? has that ever worked for anyone? I find your attitude really puzzling, if not downright offensive. &gt; community does not believe in him either. firstly, there is no lisp community; secondly, you don't get to speak for it.
&gt; has that ever worked for anyone? Probably. You know, there are projects with more than one member. E.g. CLtL3 project -- as I understand, they have started with announcement on Internation Lisp Conference, their Manifest is signed by two guys -- Stelian Ionescu and Drew Crampsie. Then in CLtL3's mailing list you can find guys like Marco Antoniotti, Nikodemus Siivola, Daniel Weinreb, Luís Oliveira (I'm listing only ones I've heard about before). This looks more like community effort. &gt; firstly, there is no lisp community; Oh, fuck you, little troll. Then what is International Lisp Conference? Do you homework and count how many people visited it, how many speakers was there etc. &gt; secondly, you don't get to speak for it. I said _I think_ -- this means I'm speaking for myself. Btw, I do not think that "huge tarball" approach makes sense at all. I already have a collection of libs aprox. like that, but that does not help me when I'm installing a new lib to do some stuff. What would make sense is a dependency tracker -- e.g. version xxx of a lib foo wants version yyy of lib bar and version zzz of lib baz. And iff it knows where to get this revisions, it can be really helpful. 
&gt; You know, there are projects with more than one member. I wasn't addressing the entirely unimportant "just one guy" point, but rather the "ask community" point. has _that_ ever worked for anyone? is that really how one starts making something useful? &gt; E.g. CLtL3 project -- as I understand, they have started with announcement on Internation Lisp Conference yes, exactly: an announcement. they didn't ask the ILC participants to kindly tell them what to do and how to go about it. so what's your problem with after-the-fact announcements, again? &gt; Oh, fuck you, little troll. I realize that English is not your first language, but you might want to pipe down a little, lest you start sounding like you are having a fit. &gt; I said I think -- this means I'm speaking for myself. I am in no position to judge whether you spoke your mind or not, but you were most certainly making factual-sounding statements about some sort of "community". &gt; Btw, I do not think that "huge tarball" approach makes sense at all. does the concept of a "standard library" or "base distribution" make sense to you? &gt; What would make sense is a dependency tracker -- e.g. version xxx of a lib foo wants version yyy of lib bar and version zzz of lib baz. And iff it knows where to get this revisions, it can be really helpful. that would certainly be nice. but if the history of open-source lisp development teaches us anything, it teaches us to stop waiting for that particular pie in the sky, and instead to start being pragmatic and accept imperfect-but-working solutions like clbuild or libcl. I personally regard libcl as a minimally-tested subset of clbuild, without the VCS mess as a bonus.
&gt; what is International Lisp Conference? The International Lisp Conference reinforced my impression that the many different groups in the Lisp universe don't have a huge amount of overlap. For example, from some of the presentations you'd think the entire Lisp universe had converged on AllegroCL, but that's obviously not the case. So you have the AllegroCL group, the ClozureCL group, the LispWorks group, the CLISP group, the SBCL group, the IRC group, the Usenet group, etc. It's hard to see them having a lot of consensus on really broad Community Issues.
Oh noes! Someone on the Internet made something that is not yet ready for your purposes! What a bastard that guy must be.
killerstorm has a point, but he doesn't he quite get it himself. Yes, in order to succeed it needs community support, but it's not clear that discussing it in comp.lang.lisp (of all places!) would be a better way to get this thing started.
&gt; it's not clear that discussing it in comp.lang.lisp (of all places!) would be a better way to get this thing started. it would be a perfect way to get the thing aborted, I think. seriously, I'd like to see people like killerstorm here be properly taken to task. the attitude towards others' volunteer work that he displays is simply poisonous and shouldn't be tolerated, full stop.
Sure, I guess any general purpose programming has some sub-groups which have relatively little overlap, but still, they somehow cope with it. &gt; It's hard to see them having a lot of consensus on really broad Community Issues. Sometimes it is hard to achieve consensus even among two persons. However, there are some ways to make decisions -- for example, with voting. E.g. you might remember that there was a lot of noise about R6RS, but still, new spec was ratified, with 65.7% votes for it.
&gt; has that ever worked for anyone? is that really how one starts making something useful? Admit that you just hate comp.lang.lisp. I was getting pretty useful feedback there, and I've seen people were getting good feedback too. &gt; so what's your problem with after-the-fact announcements, again? A difference is that they did not start work on CLtL3 before making an announcement, this way everybody who wants to participate can participate on an equal basis. It is pretty different from how Daniel does it. &gt; that would certainly be nice. but if the history of open-source lisp development teaches us anything, it teaches us to stop waiting for that particular pie in the sky, and instead to start being pragmatic and accept imperfect-but-working solutions like clbuild or libcl. For me downloading stuff manualy is a working solution. Some people are working on version-tracking things, btw, so there are chance we'll see a nice solutions some time.
actually if the Bruce Tate is this Bruce Tate, then I have not much hope for useful content: [The Beauty of Lisp](http://www.ibm.com/developerworks/java/library/j-cb02067.html) 
...and with the vast majority of implementors specifically stating that they would not be supporting R6RS, ever. So you're completely wrong on that point too.
What's wrong, can't I express my opinion? Are people only sing praises in comments or they can criticize stuff too? Note that people often say "Excellent idea!" before even trying, knowing nothing about project, so why not say "This is not useful to me, it sucks" in a symmetric way? I find this attitude weird and puzzling. And I'm not alone. E.g. there was an [article](http://imagine27.com/articles/2009-08-19-011225_clojure_the_false_lisp.html) recently: &gt; !!! DISCLAIMER !!! &gt; Nowadays it's frowned upon to criticize anything in society. It's quite pervasive. That is unless you happen to also be criticizing the same thing that a group of other people are also criticizing. We hardly speak our minds, instead it's more common to take a passive-aggressive and sometimes socio-pathic approach when any type of issue arises. Huh, so now you need a freaking disclaimer before saying anything harsh, because, huh, it can upset someone. 
split-sequence is superseded by the one in CL-PPCRE. I wonder whose brilliant idea was to create a library for a single function anyway.
That's really the only way it can work. I don't know that the commercial vendors would have any real reason to oppose it, so long as they can still sell their commercial extensions.
They are not same -- `split-sequence` works on sequences and is pretty similar to CL functions which work with sequences (e.g. it supports :test), `cl-ppcre:split` is a regex function. cl-ppcre has considerable overhead. I do not really care about split-sequence, but it is required by 4 libs I have here...
I really hope CL isn't included, and i love CL. There's not enough room in a book about many languages to cover what makes CL great, and CL books should really be written by people who are well versed in CL, IMO.
&gt; Instead Daniel, not asking anyone, picks some libs according to his own preferences And that's a bad thing? choosing to support the libraries you already use is a smart way to go about it. I'm sure if someone is willing to support a library that is not currently distributed but meshes with the goals of libCL, it can become a part of libCL. Your attitude stinks... Daniel put a lot of work into making something useful, and you're complaining that it's not how you would have done it? Then do it your own self, make your own community guided collection of libraries, see how far you get. Whatever lisp community you consider yourself a part of is one i'd like to have nothing to do with. We need people who lead, create and innovate, not curse, bitch and moan. 
Quoting the MLeus MLeficarum again?
&gt; CLtL3 project -- as I understand, they have started with announcement on Internation Lisp Conference, their Manifest is signed by two guys -- Stelian Ionescu and Drew Crampsie. We started talking about and defining the CLtL3 effort months before we went public with it (and note it was never announced, by us, on c.l.l). We decided on the project goals and scope, and _then_ invited others to participate. Just like Daniel has... only he's actually produced something of use whereas we're still working on a charter. We need _more_ people doing things like libCL, not a bunch of people arguing about it on c.l.l. . More importantly, what we don't need is negative creeps and baseless criticisms. You my disagree with his library choices and/or distribution methods, but that's no need to attack the person behind it, or his motives.
&gt; What's wrong, can't I express my opinion Opinions are like assholes. Everybody's got one and everyone thinks everyone else's stinks. Constructive criticism should always be welcomed. Your opinions and criticisms are abrasive and offensive, and not in the least bit constructive. This project may not be useful to you, but that's no reason to insult the creators of the project, rant about how you wish the mythical community was involved, and generally make an ass of yourself. What are you _really_ upset about?
&gt; A difference is that they did not start work on CLtL3 before making an announcement, Actually, we did. Please don't use our project to contrast Daniel's, they are different (and complementary) projects with different goals. The CLtL3 Project was created specifically to enable projects like libCL, and i applaud dherring's efforts. &gt; as this way everybody who wants to participate can participate on an equal basis. Umm.. FSVO equal. Everybody is free to join the mailing list, but in the end it's only the core group members who will make the final decisions with regards to what becomes part of CLtL3. It's not a democracy, and i've specifically avoided all use of the word 'committee' as well. 
No, none at all (yet). Essentially, we're looking to describe the non-portable bits of modern common lisp that all implementations share, and see if we can gain some consensus wrt API's and protocols. To get the implementors on board, we need to create some demand. The best way we can do that is to produce a useful lisp to which library authors can code, and make CLtL3 compatibility something that users demand. 
&gt;**Why isn't library X included?** &gt; &gt;Here are the most probable reasons &gt; &gt;[...] &gt; &gt;* Overly platform-specific (e.g. implementation-specific, FFI binding, etc.) (Note: libcl-ffi is a work in progress) Good God, *why*?
I suppose you could actually browse the whole site and try things out before criticizing? :) - git.libcl.com contains full history of what came from where - download tarballs contain an index.html which lists the packages - its hard to build community around vaporware - clouds build around a kernel
FWIW, I did an initial alpha with a select group of people. Several gave helpful feedback, but nobody wanted to join the project due to time constraints. Look at the Nov 16 alpha release to see what they saw. The backing git repos have been hidden from public view; they were a mess and needed a complete redo (to properly separate upstream/local, etc.). BTW, cl-markdown was included so I could use it for the website, etc.
??? Why would one omit platform-specific libs, or why would one bundle ffi libs? To answer both questions, - Platform-specific doesn't fit in with cross-platform. - Some apps simply cry for FFI (e.g. OpenGL code).
After the first full release, I will upload the index.html (and deps) included in the download file. Thus people will be able browse the packages/docs online. Until then, its an alpha/beta release. Buyer beware and all that.
&gt; E.g. CLtL3 project -- as I understand, they have started with announcement on Internation Lisp Conference, their Manifest is signed by two guys -- Stelian Ionescu and Drew Crampsie. LibCL was announced at ILC09 as well. Perhaps you missed the lightning talk?
YOU'RE WELCOME!
OK, so I'm not Zach Beane, but I couldn't resist.
&gt; Then do it your own self, make your own community guided collection of libraries, see how far you get. Once again, I see no point in "collection of libraries". I think dependency tracker might be much more useful. I know some people who do just that, and I can join that effort. &gt; We need people who lead, create and innovate, not curse, bitch and moan. How do you know I do not "lead, create and innovate"? Creating something and bitching are not mutually exclusive. :) It seems there are already abundance of positive comments -- not only here, but anything posted anywhere always gets "cool, very interesting, excellent idea" comments. This leads to inflation of positivity. I'm just taking opposite side and "curse, bitch and moan", to bring rationality back. Don't you think that it is a good idea to have list of maintainers and list of packages visible on the site? I've just pointed to that. So it is a constructive critic. Cursing was a little bonus :)
Why would one make another FFI portability wrapper? We have CFFI already. It's stable, well-designed and tested, includes drop-in compatibility with UFFI and is widely used and tooled for (SWIG, Verazzano). Effectively we have *the* portable FFI library to use. Making another one under the label of a "one stop solution" will have the opposite effect or, at best, no effect at all. Not to mention that CFFI is already extremely light on dependencies: (defun deps (component) (labels ((deps* (component) (let ((deps (cdr (second (asdf:component-depends-on 'asdf:load-op (asdf:find-system component)))))) (apply #'append deps (mapcar #'deps* deps))))) (remove-duplicates (deps* component) :test #L(string= (string !1) (string !2))))) CL-USER&gt; (deps :cffi) (#:BABEL #:ALEXANDRIA #:TRIVIAL-FEATURES) Of those, Babel is "the" Unicode library, Alexandria is "the" snippets collection library and trivial-features is, well, trivial. All three are already in libCL's dependencies. "One stop solution" is a good goal, but not when it involves subverting pre-existing, high-quality default choices. The proper way to go here is to delegate such a chunk of functionality to said default, and offer two downloads: libCL and libCL bundled together with all the recommended externals.
&gt; What are you really upset about? I'm not upset even a bit about libcl, I've just pointed to some factors: * site is not properly organized: most important things IMO -- list of maintainers and list of packages -- are missing, * it does not look open enough for that kind of project, * "the huge tarball" approach is inferior to some other approaches which might contribute to project's lack of success. That's all. What I'm really upset about are reactions like yours, where any criticism and negative opinions are met with utter hostility. It does not make a healthy environment. &gt; Opinions are like assholes. Everybody's got one and everyone thinks everyone else's stinks. I that was my project, I'd welcome any opinions, however negative they are. I do not think they stink. If somebody thinks I'm a retard, probably I'm doing something like I am one. And, btw, it looks like you've just called me an asshole. Ok, point taken. &gt; Your opinions and criticisms are abrasive and offensive, and not in the least bit constructive. Asking to publish list of maintainers and projects is not constructive? What is constructive then? I admit that calling them "retards" was too offensive, but think like I'm just having a weird sense of humor.
&gt; I suppose you could actually browse the whole site and try things out before criticizing? I apologize for being too offensive, but my point is that important stuff like list of projects and list of maintainers should be available directly, without a need to "browse the whole site". &gt; download tarballs contain an index.html which lists the packages For example, I do not want to download a tarball because I already have all libs I need, but if I saw your list of libs more-or-less matching my list of libs, I could switch to it to get a consistently updated bundle, for example.
Get off my lawn!
Not another UFFI, CFFI, or other FFI layer. A distribution of FFI bindings, just like LibCL is a distribution of CL libs... I'm not that crazy.
OK, that makes much more sense then.
ROFL
BTW, split-sequence has been in LibCL for a long time. It is part of cl-utilities, and a custom .asd exposes it to the outside world.
Please give LibCL a try. It may not have all the libs you use, but it probably has most of them. Satisfaction guaranteed or your money back. Yes, things need a lot of polish, but the project just entered its first public *alpha*.
&gt; I've been trying to learn Lisp by drinking yak's blood Jeff Minter would disagree.
&gt; What I'm really upset about are reactions like yours, where any criticism and negative opinions are met with utter hostility. It does not make a healthy environment. .... and calling people who do actual work to help the lisp 'community' "retards" is a healthy environment? If you simply had of stated what you state above rather than name-calling and childish ranting, i might think your opinions are worth something. &gt; Asking to publish list of maintainers and projects is not constructive? What is constructive then? Joining the project and offering to help publish a list of maintainers and projects would be a lot more constructive than name-calling and bitching on reddit. If the project owner then said 'no, it's not part of the project goals', then I might agree with your points. 
&gt; How do you know I do not "lead, create and innovate"? I don't, of course.. for all i know, in your mythical community, you are a leader. But, i've been a lisper for a while now. I've come across Daniel Herring in a lot of community-related ways, and have known him to be a friend of lisp. &gt; Don't you think that it is a good idea to have list of maintainers and list of packages visible on the site? Sure i do. Do you think it's a good idea to call people who are trying to make a difference 'retards'? Your 'bonus' cursing is the main reason why i think you're an asshole... if it was an attempt at humour it was weak, and if your first argument was ad-hominem, what value should i place on anything else you say? 
These FAQ points should now be covered on the website.
My first project where I used CFFI to use C code inside Common Lisp. Atm you can get the time a certain process has been running, the boottime of your machine, your uptime, convert signame to ints and vice versa. Although I'll probably stop here, as it does everything I want it to do. Still, it was a learning experience. People on channel Lisp where very helpful. Project has only been tested under Ubuntu with SBCL, but I haven't used any sbcl specific stuff so I *guess* it should work on a number of implementations. And don't trust the comments in the header files, they lie !
The blurb fascinates me, but I really wish there were more details on the web site. Can anyone shed some light on how it works? I have an application for which something like this could be really helpful, depending on how the library works. The application has a big dataset--around 400MB--and most of it (about 200 to 300MB) could be stored on disk with little performance impact. GC really hurts the app in low-memory situations, because most GCs are copying, and that doubles the peak memory consumption of the app from the size of its working set. If there isn't 800-900MB of available RAM to run the app, GC dips into swap, which kills performance (and that really matters, being a web app). SBCL's old PURIFY functionality would have been perfect, because the dataset is immutable. PURIFY would take all the data reachable from some object and make it read-only and always considered live, so the GC won't touch it. Then it's okay if the non-critical parts of my dataset do dip into swap, since GC won't traverse and thrash in it, and most of it is rarely needed. More importantly, the data won't need to be copied, reducing the peak memory requirement for a copying GC. From what I gather, SBCL's PURIFY is no longer available on any platform which uses the generational GC. I've been looking for a magic bullet that lets me keep CLOS data structures on disk (or even in non-GCed memory) with minimal impact on my app. Custom on-disk data stuctures or SQL tightly couple my classes to some external data format. The object DBs don't integrate with existing code very well--I'd have to "Elephantize" all the data structures referenced in my persistent set. I'll definitely have to take a look at this library when I get a chance.
Surprised this got published.
How often something like this is proposed? I'd say every week or so.
The link behind [this one](http://www.reddit.com/r/lisp/comments/9g4f8/qtimagine_a_skeleton_project_for_live_coding/?already_submitted=true) has more info. Edit, also i didn't know what [constructive solid geometry](http://en.wikipedia.org/wiki/Constructive_solid_geometry) was. Did make a few (none popular) Unreal maps though..
I really like this set of answers.
I would wish there would be more embedded systems programming in Lisp, but, I agree, the answers are pretty good. :-)
Excellent article! CL can be good for functional programming, you just have to stick to no side-effects yourself. As for lazy evaluation, people have tried making libraries, probably is perfectly capable of it.(When there is a proper library to do it.) &gt; You will need to choose an implementation to learn Well, if use some specific stuff, and various ways for compiling, maybe. For the language itself, it doesn't really matter much which you choose. &gt; No, you can't remove the parentheses Well, often you can, by improving the code! However, sometimes declarative variable declaration has the advantage of not nesting further, whereas LET, FLET and such do get overly nested.(Without real information behind it.) Recently i have 'discovered' a macro to help(dunno if anyone had a similar one before), though [DENEST](http://www.lispforum.com/viewtopic.php?f=2&amp;t=295&amp;p=3078#p3071), which 'denests', it nests the next element at the end of the former. It seems to have similar usefulness as ITERATE and such.(Although i got overexited.) [It's in this git archive](https://git.berlios.de/cgi-bin/gitweb.cgi?p=lisp-umac;a=summary), but i might have to push the latest version. Before using it see if you can refactor code! (Also, the forum has an older version; having a body after is silly.)
&gt; We're talking about Common Lisp instead, often shortened to "Lisp", being a much more modern language. I really with CL'ers wouldn't use the term this way. Most non-CLers use Lisp to mean a family of languages. CL is far from the only Lisp in use, possibly not even in the majority any more. Otherwise a good "here's what you're getting yourself into" explanation.
&gt; I really with CL'ers wouldn't use the term this way. Most non-CLers use Lisp to mean a family of languages. CL is far from the only Lisp in use, possibly not even in the majority any more. Maybe it's not ideal, but I've taken to using "lisp" as a common noun for the family of languages, and "Lisp" for Common Lisp only. I use other lisps too, so I am somewhat sympathetic, but I've never found the nomenclature a problem in practice.
Oh, *Common* Lisp. Nevermind.
Just one thing: functional programming per se has nothing to do with lazy evaluation.
This article would have been great to read way back when I began learning lisp.
&gt; CL can be good for functional programming, you just have to stick to no side-effects yourself. Just as good as, say, Python or JavaScript. They have first-class functions and closures and lambdas too. I would not advertise functional programming as a distinctive feature of CL if most dynamic languages work exactly same way. &gt; Well, if use some specific stuff, and various ways for compiling, maybe. For the language itself, it doesn't really matter much which you choose. Any language learning involves debugging, and debugging is very different in different implementations. &gt; though DENEST, which 'denests', it nests the next element at the end of the former I remember Richard Gabriel mentioned in his book that macros which alter control flow are considered evil. DENEST probably is as evil as possible in this respect -- it makes code absolutely unreadable until you get used to this macro, while providing no features of its own. 
in Python 'functional programming' is constantly in danger. In CL much of the library supports the use of first-class functions, closures, lambdas. CLOS uses 'generic functions' as main building block. 'Generic Functions' are both normal functions and CLOS objects. In Common Lisp imperative, functional and object-oriented support is on equal terms. Both Python and Javascript allow the use of some functional features, but their preferred style is more imperative oop. 
Might be worth mentioning CUSP in the IDE section, http://bitfauna.com/projects/cusp/ Altough I don't know if it is still actively developed..?
I dunno about Python, but it is hard to say what is prefered style in JS. There are libs which heavily use closures/anonymous functions (like jQuery); and JS objects are merely hash tables with some syntatic sugar, so it is hard to call this OOP. E.g. can you call this: (let ((x ...) (y ... ) (z ...)) (list :foo (lambda (a) (+ x a)) :bar (lambda (j) (+ y j)) ...)) a OOP? This is a style pretty common in JS.
I don't know if it's still being dveloped, but I found it (surprisingly) NONtrivial to install.
Why not? What is an object anyway? You can pretty much get away with using lexical closures most of the time. And why wouldn't that be OOP? How do you define OOP? 
Good points. Note that macros can be useful for functional too,(like with-slots) though. DENEST does have have to be learned, but it is very simple at it's base. (The real version is slightly more complicated because it also has a BLOCK to return to, and also leverages keyword arguments.) (defmacro denest (&amp;rest args) (cond ((null (cdr args)) (car args)) (t `(,@(car args) (denest ,@(cdr args))))) That should be easy to do by head too. I don't know what you mean with changing 'control flow'. Of course you can write some awful stuff with this, splitting at silly places. (denest (setf a) (+ x y)) But it also seems to be able to behave like macros like ITERATE and LOOP, if you have the macros. (With disadvantage that you have to declare that you want to collect those.) (Example is from expression-hook package i made, e-list expands and 'hooks' a list of expressions.) (defun expand-funs (funs) "Expands flet/macrolet input and returns the names in the second value." (denest (collecting (nil cr col-result)) (collecting (nil cn col-names)) (:return (values cn cr)) (dolist (fun funs)) (destructuring-bind (name (&amp;rest args) &amp;body body) fun (col-result `(,name (,@args) ,@(e-list args) ,@body)) (col-names name)))) To understand the macros here you need to only learn the macros DENEST, COLLECTING and the denest-macro :return. The last one is what it eventually returns, but it is required to be after the collecting terms, which is a bummer, however it functions like a regular macro, however; (use-denest-macro :return value ..body.. does exactly the same. The rest is completely CL itself. Without denest: (defun expand-funs (funs) "Expands flet/macrolet input and returns the names in the second value." (collecting (nil cr col-result) (collecting (nil cn col-names) (use-denest-macro :return (values cn cr) (dolist (fun funs) (destructuring-bind (name (&amp;rest args) &amp;body body) fun (col-result `(,name (,@args) ,@(e-list args) ,@body)) (col-names name))))))) Btw, a macro that uses 'accumulation macros' and returns it in values is also possible. (return-accumulate ((collecting (nil cr col-result)) (collecting (nil cn col-names))) ...) Returns it the same in values. Only thing is that it depends on the location of the accumulation variable to return. (It being the second argument seems a little arbitrary to me :/ )
I think the author is missing one point: There is no progression in learning Lisp. Normally, every new language comes with an additional benefit: -register management sells c against assembler, -function management sells c++, -garbage collection sells java, -first class functions and dynamic programming sell python, -lazy evaluation sells haskell. Today, the unique selling point for Lisp are forms, but only few people like the parentheses. That is, besides macros. But macros are a different beast because they destroy lisp: There is no language if one can redefine the language. That's why one can't learn lisp and learning lisp is not progression but a jump and because of that, Lisp has to be found when one is ready.
You speak nonsense.
It's the majority Lisp in current use that actually has "Lisp" in the name.
Can you be more explicit? Don't you agree that macros are of an entirely different quality? I think it's the same difference as between learning an instrument and composing an opera. A guittar player can create a tune and it is composing. But creating an opera requires an entirely different amount of knowledge.
Sure it does. Lazy evaluation is a strategy that's only practical in a functional setting where side-effects are eschewed.
&gt; Maybe it's not ideal, but I've taken to using "lisp" as a common noun for the family of languages, and "Lisp" for Common Lisp only. How do you pronounce "Lisp" and "lisp" differently? In print, I tend to use "Common Lisp" or "CL" for Common Lisp, occasionally lapsing into "Lisp" when it's in unambiguous context, and use "LISP" or "the LISP family" or something like that when referring to the whole family of languages. Luckily, "Common Lisp" and "CL" are pronounced differently than "the LISP family of languages", so it works in more than just print.
Indeed, a pure functional language is well suited for lazy evaluation, but the concept of functional programming imo does not include lazy evaluation.
It's a good post. Here's the conclusion for those who don't want to read the whole thing: If you have a big project spanning hundreds of files and dozens of packages, though, it will save you a lot of headaches. If you are starting to modularize your system, I highly recommend that you prepare in this way: 1. Always, always, always put an IN-PACKAGE form as the *very first thing* at the start of every file. Don't *ever* switch packages in the middle of the file. 2. Separate the implementation from the configuration. Put the DEFPACKAGE forms all in one place and make sure they get loaded before anything else. Don't start files with DEFPACKAGE. 3. Don't use explicit package qualifiers you don't need. 4. Keep the module count fairly low. 
&gt; How do you pronounce "Lisp" and "lisp" differently? I don't have to, in general. The common noun is denoted by the indefinite article or its plural form. e.g. "this program is written in Lisp", versus, "this program is written in a lisp"; and, "I prefer lisps over other languages".
That has gotta be one of the slowest scripts ever.
It probably is and I might've bothered to optimize it but it whips through my last 8 months of call logs in ~1.8 seconds on my box. My needs were met. *shrug* Plus I wrote it in under an hour. The only thing that took time was figuring out the (declaim (sb-ext:muffle-conditions ...)) stuff the next day.
Hard to optimize loading FASLs. SBCL is pretty slow at that. How fast does it go if you just run it from slime?
&gt; Evaluation took: 0.059 seconds of real time 0.053329 seconds of total run time (0.053329 user, 0.000000 system) [ Run times consist of 0.007 seconds GC time, and 0.047 seconds non-GC time. ] 89.83% CPU 22 lambdas converted 140,190,111 processor cycles 4,697,168 bytes consed Those are the results of running... (time (progn (init) (find-faves)) While I have access to your knowledge, if you were writing this what's the first thing you'd change? (Performance wise, I suppose. This really was a one-time off script. I don't switch phone providers often. :))
Looks like this is for the former 'Memetrics', which was acquired by Accenture: http://www.accenture.com/Global/Consulting/Marketing_and_Sales_Effectiveness/memetrics.htm 
more programs terminate with non-strict evaluation than strict evaluation. if you want to program with total functions, it makes sense to program with the largest subset of total functions possible, especially as many functional idioms require either default or explicit laziness to operate properly, and even for certain algorithms to provide the correct amortized bounds.
Cool. I knew there was a lisp job somewhere.
Ditch cl-containers (ugh), use a hash table mapping names -&gt; minutes, so that your INSERT-CALL-SORTED becomes: (incf (gethash *call-log* number 0) minutes) Then collect the hash table into a (NUMBER . MINUTES) list at the end and use that for sorting. Don't know if it's faster, but it's a lot more Lispy, and avoids cl-containers.
Will do. I didn't realize you could do that with the &amp;optional default to gethash. That's awesome. Thanks.
I save all my Lisp libraries in one big core file and use that for scripts. That saves the startup time a bit.
And as a matter of fact, it looks like it cut the execution time by 75% as well as simplified the code. According to slime-profile-report. [Patch here](http://redlinernotes.com/code/rev/b3ea69beaaea) for the curious.
Common Lisp _is_ the unification of the Lisp family of languages: it took the best bits of the previous ones and gathered them all together. Well, the best bits as of the 1980s anyway.
Fair enough. That actually makes sense.
Xach also posted a version [here](http://redlinernotes.com/code/rev/b3f74cf92898).
Here's mine: (loop (print (eval (read))))
Sacla is an important project, unfortunately not very active anymore. But seems like there is not so much to do anymore. It would be important to have an implementation which is based on a small core, so it is easier to port common lisp to other platforms.
My impression of the code is that it was originally started as an exercise to understand CL, and only secondarily intended to converge toward a implementation based on a small number of primitives. That is, written in the top-down direction, instead of bottom-up. Unfortunately, I suspect the trickiest issues are in finding a set of clean primitives (e.g., all composite objects addressed using primitive accessors, clean primitives for stack winding &amp; unwinding) that still supports CLOS and can be compiled to execute even as efficiently as CLISP byte-code. I'm guessing there is a very good reason why reasonable CL implementations usually turn out to be tricky to port except for gurus.
Well... I thought it was funny.
Since it seems that development on the Windows front of SBCL has been stalled (which is understandable, I guess the intersection of people familiar with the details of SBCL and Windows isn't too big) I have also been wondering if it would be possible to get some community effort up to support completing what is left. Some of the problems I see with this are: - There possibly aren't that many people interested in paying for Windows/CL development. - Even if SBCL/Win were to be "finished", how much work would it be to keep it up with the *nix versions? Would it at some point eventually die because of the bitrot. Any professional opinions on the subject? How much work is there left to do? How many people are willing to pay for it?
What do you mean 'module count' ? Is a module different from a package?
 (ignore-errors (load "foo")) would be one way. There are more selective ways to treat errors and warnings. See [handler-bind](http://www.lispworks.com/documentation/lw50/CLHS/Body/m_handle.htm). &gt; How can I change this just to display all errors and warnings , like non-lisp compilers (aka gcc) does This makes me wonder whether you are developing in the same way as you would with gcc. If so, you are missing out on a couple of niceties. Lisp is really made for interactive development. A list of Lisp IDEs, among other things, can be found in Abhishek Reddy's article "[Before you start learning Lisp](http://abhishek.geek.nz/docs/lisp-answers/)".
Henry Baker's [Critique of DIN Kernel Lisp](http://home.pipeline.com/~hbaker1/CritLisp.html) and [Metacircular Semantics for Common Lisp Special Forms](http://home.pipeline.com/~hbaker1/MetaCircular.html) could be a starting point. Otherwise, [ISLISP](http://islisp.info/) does away with some of the historical baggage of Common Lisp. But generally, if you want small and clean, perhaps Scheme is the way to go, for example [R4RS](http://people.csail.mit.edu/jaffer/r4rs_toc.html).
My vague understanding of it is that the areas that require work for Windows are not those that undergo a lot of flux; they are the parts that were built for UNIX, and where Windows is most different. E.g., how threads can be signaled by the GC machinery to stop what they are doing, how they respond to signals sent by the OS, and how these things influence file and socket I/O. There are some slight differences to how registers can be allocated, as well. These parts don't change pretty much because no one is porting SBCL to non-UNIX operating systems! But they are also relatively pervasive: CMUCL/SBCL has always been targeted at UNIX-like systems. My main understanding comes from lurking on #lisp IRC while nyef talks.
Thanks, I am using emacs, just not getting used to it yet ...
(Disclaimer: I'm not SBCL developer so what I write here might be total BS.) As I understand, there are some things which are fundamentally incompatible between Win32 and UNIX architectures, and it is unlikely that SBCL will ever reliably work under Win32 without changes to its architecture. (SBCL needs to allocate memory at certain fixed address, but available addresses differ on different Win32 systems (depends on software installed etc.), so your SBCL software can run on one WinXP, but refuse to run on another.) So, why bother? If you want SBCL for development or some "heavy" server applications, you can run it on VM under Windows. Virtualization is built-in in new Windows versions (like Windows 7), and Microsoft itself uses it to run so-called "Windows XP compatibility mode" -- they just run a machine with Windows XP. So why not run it in Linux VM? It won't be suitable only for so-called desktop applications when installing virtual machines on user OS would be too much hassle. But for such applications SBCL might be not the best choice anyway, because it is pretty bloated comparing to other implementations.
A complete SBCL-Port to Win32 IMHO only makes sense, if there also exists a clean GUI-Framework. Something like CAPI. If I need SBCL on Windows for a non-gui application I would run it in a virtual machine. BUT :), best solution, add threading and a platform indepentend and integrated GUI (no TK-stuff) to clisp - we wouldn't need SBCL on Windows! So - at the moment, to develop real Windows-Application, you'll need Lispworks or Allegro... 
http://www.sbcl.org/manual/Toplevel-Options.html#Toplevel-Options http://www.sbcl.org/manual/Runtime-Options.html#Runtime-Options „--disable-ldb” and „--disable-debugger” seem to do what you want.
„Otherwise, ISLISP does away with some of the historical baggage of Common Lisp.” The baggage mostly only poses a problem during the initial learning phase, since there are so many symbols in the CL package. Other than that, there's some cruft like Lisp-2, but it's bearable. If a new Lisp is to be written, it can be written in Common Lisp for interop instead of starting from scratch. Mark Tarver's Qi is a good example.
This looks promising, but there are several distracting stylistic issues in the code (which have nothing to do with keeping it small). * Use 'ns' instead of directly importing into the current namespace. * [px, cpx, ph, pw, bh, bw, width, height] don't need to be refs as far as I can tell. * 'timer' probably doesn't need to be a ref. Instantiating Timers in a transaction doesn't seem wise. * Consider 'alter' instead of 'ref-set' where possible. e.g. (alter score inc) * Use 'when' instead of 'if' when there is no else form. * Mixing (.method x) and (. x method) style arbitrarily doesn't look nice. * Use backtracking indent in clojure-mode to align proxy method bodies correctly.
Oh, one other thing, have you looked into the state of Clozure CL on Windows? Clozure also has the advantage that there is a consulting firm behind it, set up to take money to do development on their implementation, among other things.
Loading files and evaluating forms in Lisp is roughly the equivalent of compiling *and running* your Lisp code. You can also do separate compilation; SLIME does a good job of collecting SBCL's compile-time errors and warnings for you to review.
The problem is most of the errors I encounter, being a newbie, is typos (like paren mismatches, forgetting to quote lists ), and so I don't really need to use those debugging features ... Let's say, I have a lisp file with 100 lines of code, which include 10 errors, all of them are typo errors, so for every error sbcl asks me to continue or abort, where I have to switch and fix between the source file and slime in emacs, for each error ... If it reports like gcc, printing (all) the line no/form where the errors occur and error messages, without being interactive, for example WARNING: redefining fib1 in "foo.lisp" ERROR: (fib2 3) -&gt; UNDEFINED-FUNCTION ERROR: (* 3 "2") -&gt; TYPE-ERROR Then, it would be a lot easier for me to fix, and will save a lot of time. 
I'm not sure why (as it seems) you have forms like (fib2 3) at the top-level in your file. Usually, I find myself doing a full file compilation on a file full of definitions. If one of those definitions is referring to an undefined function or similar, then it complains but finishes compiling (because the function might be defined later). If there is an error reading the file (garbled syntax), then SLIME throws me to a debugger, I hit "q" and go find the problem. As I am developing, I usually do one definition at a time, and evaulate just that definition, so it is usually not hard to find. If there are top-level forms in the file with errors like your examples, then you will get a debugger, but this is not typical: these forms don't really have useful effects at load-time, so why are you saving them to load later? If these are simply interactive checks, then I usually type them at the REPL, perhaps get one error, q and retry. If they are useful enough to save for later, I might paste them in the file, commented out using `#| |#`, and then be able to invoke them one-at-a-time the next session. Or, if I am feeling more disciplined, I put them in a test suite which, again, has been built up one test at a time and usually doesn't give me torrents of errors.
Or ECL or, to some extent CCL, which both supports threads.
Actually, they are not the real errors, I just make it up ... Thanks, anyway, I got it, I should stop using C-way of save and compile (load) , and instead evaluate one definition at a time, like you did ...
I've started reading the gigamonkey book and the ``On Lisp'' one and was interested on getting some quiz/exercises done so that I can get a better grip on the concepts involved (i.e. create a balance between theory and practice). Are these problems okay? Do you recommend any others? Something like ruby-quiz would be great too.
Seriously. Don't close your parens like that. It's weird.
Cool
 (&lt; (count 'a-bitch problems) 1) =&gt; T
I got ninety-nine problems; having a lisp ain't one. 
I think they're a pretty good set of problems. They build off each other steadily.
The problems are decent and more focused on the things a beginner needs to understand than something like [project euler](http://projecteuler.net/) or some typical task of modern programming that you might instinctively solve in a spawn-of-c way. Their main flaw is showing their prolog roots. If they get a little dull, you might want to have a look at [this](http://mitpress.mit.edu/sicp/full-text/book/book-Z-H-37.html#%_chap_Temp_850).
I'm glad I wasn't the only one who was thinking it.
Are the talks themselves online (video?) yet, or at least the slides?
You got it. I'm really specifically asking for the threading support to be finished not to get SBCL/Win finished (insofar as that is possible or even a sensible remark). For me SBCL works well enough on Windows except for threading. If you check the rest of the blog you'll see I have released a little graphics demo as a Windows executable to seems to work on most machines (I had about 10 reports back of it working and 0 if it not working (well 1 but that didn't have anything to do with SBCL)).
Site seems to be dead.
no, it isn't
Stunning-looking meeting facilities! 
video has not been recorded (at least I did not see video cameras). Slides eventually will be available from here: http://weitz.de/eclm2009/ Edit: some slides are now available. 
The page seems to have been written for a Programming Paradigms course. There are lecture notes here: http://www.ic.unicamp.br/~meidanis/courses/mc336/2009s2/lisp/apostila-lisp.pdf After page 28, the weird parentheses show up... It's really strange. Hurts. Argh.
I didn't like their style either. But I know the general style rules and I let emacs ident it so I don't think I'll fall into that trap anytime soon.
Yes, my first thought was "observation deck of a massive zeppelin".
It was a very well arranged meeting and the facilities were indeed very good.
looks that way to me EDIT: bad phrasing, I meant its working (maybe someone's blocking your 8002 port).
note that it is on port 8002, you might have a routing/firewall problem. The site itself is still up.
It was at the Hotel Hafen Hamburg, which is a nice location and one has a beautiful view from there. http://www.hotel-hafen-hamburg.de/bildergalerie_hotel_hafen_hamburg.aspx
So jealous! 
No, please no... WHY GOD WHY HAVE YOU FORSAKEN ME????!!! 