Yea I got that too.
Racket built up some excitement for me, but ended up being a disappointment. The bytecode compiler is ok, but I'd prefer more speed. I'd rather the syntax had stayed closer to Scheme. There are libraries, but nothing I was interested in. I've also tried newlisp and picolisp, but they don't offer me enough of an advantage over python. Clojure I tried once, but felt the ecosystem to be difficult to grok for a non Java guy. I might have to give it another try.
Very cool!
It does for me on my MacBookPro, my iPad, my iPhone, with Firefox, Safari, Chrome, and I tested the wiki with success on other platforms and systems, Windows, Android, ... The only one I don't care about is IE. Do you allow Javascript in your browser? 
For what it's worth to you - and it may be nothing - there is tons of Racket code at the rosettacode website. So if you give Racket another go, at least that's a helpful kickstart or cookbook reference.
Point taken. I think of vectors and hash-tables as compound structures, because it seems like you'd still want something like `unify` to recur into them, but they are both technically `atom`s. I'll fix that.
Currently not working on IE11 and maybe later Versions. Please tell me if you find bugs. Have fun!
Very cool and ambitious project! I wish you the best, OP. Also, everything is working fine on Firefox 43.0.2 on Linux. Incidentally, what Lisp interpreter are you using?
Thank you. It's really fun even if I really had no Idea how difficult web programming can be and how big the Common Lisp standard is! I don't use an existing interpeter. I write my own.
You might think about Scheme instead, as being smaller.
Building a Lisp (be it your own or from an existing standard) is quite enlightening and rewarding. I wish you all the best in continuing this project. I'm curious, why is there not yet support for establishing bindings or creating functions? I don't mean this to be snarky, it is just interesting to me how different people approach the process of building up their software, seeing what design decisions were made. Associating symbolic names with values through `define` and introducing functional abstractions with `lambda` were some of the first things I addressed in my own Lisp dialect.
Why is anyone bothering to write a book about a dead language?
Thank you. I try my best. There are three reasons why I haven't implemented defun and others yet. I underestimated the time it took to implement the client. There was not much time left to work on the server. 2. It's not that easy. I don't have the infrastructure to support lexical variables and parameters The data as well as functions must be transfered to the client and back. This is not trivial. 3. I'm not an experienced lisp programmer. I'm mostly a C++ programmer. This two languages are quite different. My knowledge is currently not deep enough to implement some of the features. 
&gt; The problem with ALL of the CL books is they are ancient. _Practical Common Lisp_ was published in 2005. 
10 years is pretty new. If you find that you are ok using asdf as if it were 2005, then this book is probably not for you. :P
X-Post referenced from /r/crypto by /u/tankfeeder [ed25519 and sha512 on picolisp](https://www.reddit.com/r/crypto/comments/40cxh3/ed25519_and_sha512_on_picolisp/) ***** ^^I ^^am ^^a ^^bot ^^made ^^for ^^your ^^convenience ^^\(Especially ^^for ^^mobile ^^users). ^^[Contact](https://www.reddit.com/message/compose/?to=OriginalPostSearcher) ^^| ^^[Code](https://github.com/papernotes/Reddit-OriginalPostSearcher) ^^| ^^[FAQ](https://github.com/papernotes/Reddit-OriginalPostSearcher#faq)
I should have been a little more clear about cl-jupyter installation, that is fixed in the site. Also updated the code in the notebook so it can be ran outside of cl-jupyter.
Try LispWorks personal edition, or your can purchase a professional one if you prefer. Generally, you can write and debug the code using the IDE; when there're some implementation-specific features you wanna use, you can then turn to Emacs + Slime. 
FWIW Amazon is shipping now - just got my copy today (1/12/16). Holy crap, it's big! - I was worried about the binding falling apart with something so large, but I put on a Kapco cover and it should be okay. Content looks excellent: incredible detail with a huge number of examples (on many pages, the code and REPL output exceeds the text), lots of diagrams. The font is nice and large, very small margins (around 1/4" at the page edge). Glad I got it, though at 700+ pages I expect to be reading it for quite a while.
If you find MOCL lacking, there is LW android runtime. 
I probably missed a few, but at least 8. Some in passing, and some amazingly thoroughly since their creation and full code is in the book. *Edit*: To whomever downwoted. * cl-ppcre * com.gigamonkeys.pathnames (which gave birth to cl-fad below) * cl-fad * com.gigamonkeys.binary-data * com.gigamonkeys.macro-utilities * com.gigamonkeys.markup (which is what the book's library "foo" became, and more) * com.gigamonkeys.test-framework * aserve 8 systems, all in Quicklisp.
Does slime not count? That's the best in my opinion, but whatever 
I once ported Ruby's Enumerable module to CL. Because I chose to keep Ruby's semantics (`next` and `break` as in Ruby, comparisons using generic `&lt;=&gt;`, etc.) it ended up being as slow as Ruby. It was a good exercise, but only that. Never actually used it (`ITERATE` is usually good enough). Now, all those convenience functions that exist in scripting languages and CL lacks, especially string related... I think everyone of us has a package full of them ;). There are plenty of third party packages that provide them, also.
I gave a presentation on lisp to my office, Monday, and used iterate to demonstrate extending the language with macros. Going to be sharing this in chat, today.
An entire os written in a year by one person? While the idea sounds fun and ambitious, even in the best case of something usable coming out of it, how will it support any drivers and external applications ? Gnu Hurd is fun to tinker with, but has little driver support and that is with around 10 developers over 20 years.
A URL for (some of) your presentation would be nifty
So far so good, you made a hash table and lisp returned it to you. If you ever see that &lt;angle-bracket stuff&gt; it means it's really an internal value you're not supposed to look at. Instead, you save it to a variable and then you can start sticking entries in there. Here's a tutorial. http://cl-cookbook.sourceforge.net/hashes.html
(creator of 3L) Finishing it in one year would be a wonderful miracle. :) In reality, it will take many years to reach any level of general practicality. The goal for the next year, as mordocai058 mentions, is something very basic, not a full fledged OS. At that point the goal will be to have something far enough along to raise more money to increase the number of people working on the project which would increase the speed of development. Even if the kickstarter fails work will continue, just slower since it will have to be in my spare time.
Anyone remember Movitz?
&gt; I hope to learn something from it. Maybe you should search other sources for learning... Those are one-off programs, never revisited, and I'm not sure they work for anything else than the given input. There were bugs I noticed but ignored, and there should be more I didn't notice. &gt;you can use digit-char-p to obtain the integer value of the digit Oh, right. What a poorly chosen function name, though. &gt;you use in a loop the do (return), you just can use return Thanks. I blame Bert Burgemeister, who forgot to add `return` to the LOOP diagram in the 2010 edition of the [Common Lisp Quick Reference](http://clqr.boundp.org/). ;) **[EDIT** I blame myself. It's there, I just didn't see it (!).**]** (I don't usually use `loop`.) As an example of what I wrote above, in that same program, in the string parsing part, there is a `#\Backspace` that should be `#\Backslash`. And you can see how poor the escape handling is. Btw, I recommend you print a copy of the CLQR and have it at your desktop. It's very useful.
all minor details
Lisp machines most certainly didn't suck. They were top of the line machines with the best documentation system on the planet. They were incredibly expensive however, and didn't play nicely in the cheap PC clone market that got us to where we are today. 
Can I help :D 
And more relevant, is it going to be open source? I'd love to follow the Development on github or another site like that. My major concern is that the goal won't be met, as this is a very... Difficult promise, and a very niche audience, so crowdfunding will likely not raise this much.
The kickstarter states that it will be open sourced within six months. It will be open sourced (BSD and GPL license) regardless of whether or not the kickstarter is successful. In terms of whether the goals will be met: almost all of them are already at least partially implemented so it isn't as far fetched as it might initially sound.
This is one of the, but not the, first compile-to-Go lisps. By this I am referring to jcla1's Gisp (and my own gsp which I will use to refer to the most recent advances to gisp). All the rest (and there are 5-10) are interpreters. What could this project (hypothetically) do better than gsp? Static typing/generics without interface{} and macros. gsp is pretty cool and simple but static typing without interface{} is just not going to happen. Also, I am pretty sure macros are also just not possible with the current parser. (If I am wrong, please let me know. I've only looked into this a few times!) If you can do a better job on these two and take the rest of what gsp has to offer, you will have a sweet and compelling language. Good luck!
Is it because "static typing" is cool nowadays?
/u/bitwiggler What is LW android runtime?
I take it you saw this post: https://news.ycombinator.com/item?id=10397252 ?
Since I got it now, I can say: It's perfect for the case you describe. You'll learn all the (important!) details from ground up, which will avoid many head aches in future (simply because you didn't understand well the first time you learned about something). It really shows that the author has much experience, and is a wonderful "teacher". One always learns best from practice, and it's full of small examples (to try personally, so you will remember).
Oh yeah, th√© old emacs init. Some people wrote drivers in Lisp, iirc from some state machine model to binary. At one point it would cool to have everything as lisp-able component.
My main browser here on my development box is Iceweasel 38.4.0. So your browser is the most tested platform. :-) My CL implementation is not written in JS. It's written in C++. The input is sent the server with an ajax request. It would be fine if there where a JS implementation on the client site but currently there isn't. The user then could switch between server and client as he likes. It's planed to implement one but it has a low priority. Presumably I will use a C++ to JS compiler to port it. Emscripten for example.
Thanks I had not
But useful != critical.
Is just a preference.
Apress is having 40% off promotion. Grab it while you can.
There's a LispWorks implementation available for Android.
Interesting work, but my general impression is "weird, why do lisp need visualization?" Lisp programs are visually programmed by nature. They naturally expand spatially --- it goes both horizontally and vertically, compared to the other languages which tend to go only vertically or only horizontally. BTW, I have an idea to implement a lisp interpreter which understands multiple forms with vertical overwraps. normal: (defun fn1 (x) (1+ x)) (defun fn2 (x) (1+ x)) suggested: (defun fn1 (x) (defun fn2 (x) (1+ x)) (1+ x)) 
This'll be great for Hackers 2, the movie!
Something like this? http://github.com/DalekBaldwin/highlight-backquotes-mode
Of course, this would make the interpreter whitespace dependent and greatly complicate the basic s-expression syntax. FWIW something like this, (defun fn1 (x) (defun fn2 (x) (+ 1 x)) (+ 2 x)) Is perfectly legal common lisp. With normal formatting, it is just this (defun fn1 (x) (defun fn2 (x) (+ 1 x)) (+ 2 x)) 
And an answer now, looks like both Lisp and Prolog are correct for that piece of code :-P Any better screenshots of the Lisp posted?
tl;dr: A++ is a tiny Scheme-like language with lazy evaluation. 
Cool! What kind of stuff do you use it for?
\*hacker typing something insanely fast into the terminal and magical windows show up\*
Last line should be: (apply + '(1 2 3)) -&gt; (eval '(+ 1 2 3))
Well, the argument list is dotted so no I think I'm correct. Though my definition of apply is wrong I yhink
StumpWM and Emacs :)
Scheme is not lazy, everything is evaluated before a function call, apply is a function as well. Now, if it's an interpreted function its body may be evaluated, but not the arguments.
I always found this as meta level bridging to leverage sexps.
That's wrong on so many levels.
Yeah, PCL is still good. Actually more up to date (code style wise) than Land of Lisp.
I wouldn't necessarily call a project dead once they're haven't been commits for only six months. Especially not CL projects. Perhaps the maintainer got a new job or kids and currently can't spend time on the project. Six months fly by like nothing.
I absolutely hated PCL. Gentle Intro to Symbolic Computation is good, and Graham's ANSI Common Lisp is great too. Depending on how deep you want to dive, I recently spent some time perusing the X3J13 spec, which was quite fun. I haven't read Land of Lisp but I hear it's ok. Of course, I hear that people actually enjoy Peter Norvig, so I take it with a grain of salt.
I would buy the everliving fuck out of a PCL 2nd Edition.
I think so! Whoops!!
PCL isn't even written by Peter Norvig, it's by Peter Seibel (who has nothing to do with Python, nor advocates for it in the book).
It boils down to the concept of expressions, what they are and how they are used in Lisps. It's best to be more precise and careful about defining what an expression is and how eval is related to them as well apply. It will help to clear up your confusion. An expression in Lisp is simply an atom, or a list of expressions. They are actually called s-expressions, where s is short for symbol. An expression always has a value. Atoms are numbers, characters, strings, and symbols. The process of producing values from an expression is called evaluation. Examples of expressions: * + * 3 * / * "hi" * (3 4 5) * (+ 2 3 4) * ("hello" "world") All of the above can be thought of simply as data, just sequences of text representing symbols, parentheses, numbers, and letters which we type in our editor. The insight of SICP is that code is really data. We create data which represents what we want the Lisp interpreter to do. Evaluation gives meaning to data and allows us to treat data as code which an interpreter executes. So in this sense, this is what you mean by evaluation as executing code. This is strictly not incorrect, but not really helpful way of thinking. In Lisp, I'm thinking of a generic universal Lisp rather than some specific dialect, we have rules how some piece of data which is supposed to be a valid well-formed expression should be evaluated. Traditionally, we agree that symbol atoms such as +, *, sqrt are treated as variables, meaning we expect they are bounded to some run-time values. So when symbols are evaluated, they are looked up in some environment in a Lisp interpreter, if a value is found, it's returned, if not, we raise an error, usually an "variable undefined" or "identifier undefined" error. It varies depending on which Lisp dialect. We also agree that a list of expressions is to be treated as function calls, where the first item in the list is the operator, and rest of the items are the operands, or arguments So (+ 3 4 5) is supposed to represent a call to the addition function. (* 2 3 5) is an example of a call to the multiplication function. (* (+ 3 4 5) 5) is also another valid expression for a multiplication function call. Notice the nested list within the expression which itself represents an addition function call. Quote is a special rule that when applied to some expression, returns the expression without evaluating it. This allows us to bypass evaluation rules which say symbols are to be treated as variable look-ups and lists of expressions are be treated as function calls. Sometimes we don't want to do that, sometimes we want symbols or expressions to be treated as just symbols or expressions so we say (quote +) which allows us to treat + as just the symbol +, not representing anything, the addition function in this case. We have atoms such as strings and numbers, they are treated as representing themselves, we call them self-quoting expressions in Lisp. "hi" always evaluates to value of "hi". 5 always evaluates to value of 5. In Lisp, functions are also values which can be produced by expressions or be bounded to symbols. Traditionally + is bounded to the addition function, * is bounded to multiplication function. Evaluating an expression may give you function values. How do you handle those function values? That's where apply comes in. Apply is what gives meaning to function call. It will take a function and a list of expressions and applies the function to the values of the expressions in the list. Evaluation is done by the eval function which knows all of the rules we just specified above. Eval takes an expression which is just data and looks at it, is it a symbol atom, then variable lookup and return the lookup result as the value of the atom, if it exists. Is it a string atom? Return the string as is. Is it a number atom? Return number as is. Is it a list? We expect the list to be a valid function call, pull out the first item of the list, is it an symbol atom? Does it happen to be quote? If yes, then return rest of the list unchanged as the value of the quote expression. If it's not quote, then the symbol atom should be bounded to a function value, otherwise it's an error. ("hello" "world") is not a valid function call after all. Assuming the symbol atom returns a function value, eval then calls apply, giving it the function value and rest of the list. For example, we evaluate the expression (+ 2 3 4) using the eval function. The first item in the expression is + which will evaluate to a function value which is of course the addition function. Eval will call apply, giving it the function value along with (2 3 4) which is rest of the original list expression. In this example, apply has a list of symbols, which is also an expression! to give to the addition function. First apply needs to know the value of the expression it has been given. It doesn't need to know the function value because it's already been given to apply. Apply calls eval on each item in the (2 3 4) expression. Since each item is simply the self-quoting number atom, eval will return number value for each one. The addition function then sums up all of the number values giving us 9 as the value of the original (+ 2 3 4) expression which is what eval returns to us at the conclusion. In the slightly more complicated example of (* (+ 2 3 4) 5). When eval calls apply on the multiplication function, apply will be given ((+ 2 3 4) 5) which represents the values the multiplication function is supposed to work with. Since apply will be calling eval on each item in ((+ 2 3 4) 5), the first item in that expression is (+ 2 3 4) which we evaluate with eval. This is the same example above and eval proceeds in exactly the same way, finally giving us 9 as the value of the (+ 2 3 4) expression. Once apply has finished evaluating the ((+ 2 3 4) 5) expression, it will then have a list of number values, 9 and 5 which are multiplied to give us 45 as the value of (* (+ 2 3 4) 5) expression. So you see in a Lisp, executing code is a dance of eval and apply working together in mutual recursion to give meaning to data as code. Eval gives meaning to expressions by assigning them values. Apply gives meaning to functions by taking function values and giving them argument values to operate on. They both recurse as deep into an expression as needed to process all of the nested atoms. The interesting part is that eval and apply are also functions themselves, so that is mind-bending meta-recursive for you. Since they are functions, then we can write them as expressions prepared in the proper form for function calls then they'll be evaluated just as any other ordinary functions. SICP is focusing on understanding how Eval and Apply which you define are function expressions that are evaluated by the Lisp interpreter. The key insight at the heart of the metacircular evaluator is that Eval and Apply aren't the same as the Lisp interpreter's own eval and apply functions. They do behave the same but exist at a different meta-level than eval and apply. 
Also, about the misconception in your "lies to children" paragraph. The time when the ANSI standard of Common Lisp was ratified was not important because the standard wasn't meant to "set in stone" the language, but to, in Kent Pitman (one of the designer of Common Lisp) words, "create better stability of programming language semantics. In particular, standardization was **not** intended to stop **research and development of languages**, but rather to give commercial developers shelter from the pace of rapid change that **was expected to continue**." [[2](http://www.nhplace.com/kent/Papers/cl-untold-story.html)] There are many reasons why there hasn't been any update to the standard since 1994, one of which is the AI winter, another is the cost and time required to update it (it took freaking *10* years to finish the current one). Fortunately, the community has picked up the torch, and continue the development of the language, adding many critical features that are missing from the standard (GUI, threads, etc.). And despite its age, Common Lisp has a very impressive features, many of which are still missing in many "modern" or "contemporary" languages. For example, Python finally gets type hinting in version 3.5, while Common Lisp has this feature since 1994 (if not even earlier in some older dialects). So it is more than possible to use Common Lisp to solve real world problems today. &gt;Hell, I tell most folks to learn Scheme first. Simpler, cleaner, and they can get away with more, knowing less. That is fine, as long as you remember the differences between the two languages (no guarantee of tail-call optimization in Common Lisp, etc.).
&gt;[B]ecause there's no telling what crazy features the newest version of SBCL or whatever the kids use these days has, but knowing what is practically guaranteed to be there, they can be productive from day one onwards. Again, did you confused PCL with some other books? The majority of the book are not implementation specific and only deal with the core language as defined by the standard. You can use what you learn in the book in any implementations that's conform to the standard. The only chapter in the book that uses external, third party library is the one that make uses of an old open source HTTP server, AllegroServe (the book also lists alternative servers to use for portability reason), and this is because HTTP server is not part of the language (and it shouldn't be). PCL, like the other two you mentioned, also has explanations of the various old and obscured corners of the language that helps you understand why it is the way it is.
You can use a dotted pair as two 'pointers', I've seen that in code
I'm not real familiar with picolisp; what's the: `(== 64 64) at the top of the file for?
 (loop for (a b c . rest) in list-of-lists ...)
A lisp that doesn't support conses properly, clever. e: Oh, and they're pretty damned useful for representing trees.
While I am not the person to whom your reply was directed, I'd like to chime as I too have worked on a custom Lisp. Nonetheless, I feel this is more a matter of taste than hard technical restrictions. Using the traditional dotted-pair syntax, I feel that the parser is simpler than one recognizing the proposed `'(. 1 2)` syntax for purposes of error recovery (what if the user enters `'(. 1 2 3)`?) `'[1, 2]` and `{1|2}` add syntax, thus further complicating the parser. `'(p: 1 2)` can be seen as another `'(. 1 2)` with a different delimiter (still one token following an opening parentheses). As writing a parser to recognize the dotted-pair syntax is trivial, I would only consider using a different syntax if there is a good reason to subvert expectation. The question I would like to pose to you is why have you written your parser to use a novel syntax for pairs? Choices in language design are interesting.
No real reason than simplicity, really. It's a work in progress. I will say that the connection between lists and pairs often confounded me as a newcomer; namely improper lists and the weird result when trying to use an alist as a sort of cheap hash-table, then storing a list as a value... '((x . 1) (y . 2) (z . (1 2 3)) (w . 4)) -&gt; ((x . 1) (y . 2) **(z 1 2 3)** (w . 4)) &amp;#3232;\_&amp;#3232; 
Are you asking why symbolic expressions look like symbolic expressions? Lists are made up of pairs and NIL, the empty list. '(1 2 3) is really '(1 . (2 . (3 . nil))) " In the usual parenthesized syntax of Lisp, an s-expression is classically defined[1] inductively as 1. an atom, or 2. an expression of the form (x . y) where x and y are s-expressions." -- https://en.wikipedia.org/wiki/S-expression The pairs _come first_. Historically, it is not an accident, but rather how symbolic expressions, which is the syntax for lisp, **is** defined. Is was not really meant to be a syntax, but rather formed because code as data was a good thing, and [M-expressions](https://en.wikipedia.org/wiki/M-expression), which have a strange syntax like the ones you point out, were not quite practical when dealing with code-as-data, eval, fexprs and eventually macros.
Regarding alists specifically, it's not unheard of to structure them as lists of lists, rather than lists of pairs, e.g. the key is found with `car` and the associated value with `cadr` (rather than `cdr`). If you don't intend to run code that contains literal alists in it of the latter form, then you can use the convention of lists of lists throughout.
&gt; I guess I'm trying to better understand the reasoning behind the syntax. The reasoning behind having some syntax *at all* is to be able to print and read back any list, including improper lists. Classic lisp syntax *really* is just a "serialization format" for data.
Any reason you chose ANSI C instead of C99 or C11?
Actually it was originally written in c99. We rewrote it all for our own c89 compiler that cross compiles to custom risc cpu. Picrin even works on freestanding environment without an OS.
That sounds really fun. 
Nice work! Awesome documentation and very clean code :)
What exactly do you mean by "freestanding environment without an OS"? Do you have an example of that? Really curious.
SICP is pretty mind-expanding (note: I've only skimmed it). It's pretty good about exploring functional style and really shows you some mind blowing concepts later on (object orientation can be built out of closures). Even if you don't use the concepts in a lisp, it can change how you think about programming in other languages. SICP is written in a Scheme dialect; I don't tinker much with Scheme, so I don't know how much the language has changed since that book. But there's a Racket language that's compatible if you can't find anything else - [0]. I'd also recommend "Realm of Racket" for a much quicker/less enlightening/still cool read. [0] - http://www.neilvandyke.org/racket-sicp/
Thanks.
The way I do it using emacs configured with slime is opening a new lisp file, M-x slime to open the repl. Then you can write the code in the lisp file buffer and execute/compile s-expressions using C-c C-c. You can save the file buffer normally using the C-x C-s command 
I'm not sure if you're feeling 'oddness' about the names of those functions or their intention... Grabbing elements from a list is gonna be a routine thing. You'll be using them less or more depending on domain. The names aren't super intuitive in modern times though... Assuming you're reacting to the naming: It's been a minute since I LISP'ed, but shouldn't it be trivial to wrap those functions in something more palatable, thus preserving the ability to copy code from the book while also giving them more meaning? Effectively: let first = car
To me this sounds like two different issues. sicp is worth it for the learning experience alone. It's not about 'learning lisp' specifically, it's about learning programming. It just uses a language that is flexible enough to allow you to explore many idea without fighting the system you are in. Lisps dont force you into using `car`, `cdr` etc if you don't want to. Common Lisp &amp; Clojure for example have `first` and `rest`. So the end result is good news. Work through SICP, it's great. Then, if you like the idea of languages with this kind of power, check out some other lisps and see what they have to offer.
It's never not worth working through SICP anymore, nope.
I use CAR, CDR and friends when I'm thinking in terms of a tree of cons cells, or improper lists. I use FIRST, REST and friends to emphasize a proper list as a linear sequence. Modern Lisps tend to have vectors and hash tables at least, so I think you'll see a bit less of the ancient functions. That said, its common to prototype code using lists and replace with more space/time efficient data structures during subsequent refactoring, if necessary.
You really need to think about your goals. Is your aim to use a Lisp to produce real-world applications, or is it to learn something about the fundamentals of computer programming. SICP is a way to do the 2nd of those tasks. It's an incredibly good educative tool that will arm you with a deeper understanding of how computer programs (and in particular, programming languages) work. It won't get you up an running writing a web app in Common Lisp or Clojure. If you're looking for that seek out some other tutorial.
SICP covers just about every programming issue that's relevant today. The use of scheme only points out how pointlessly convoluted we make those conversations, when the issues are so simple. The book will clarify your thinking immensely.
It's still interesting, a bit fun and a bit worrying. It's hard not to confuse the medium and the idea. Getting stuck with the idea that "A language" is special and not realizing deeper aspects about abstractions, implementation details, interfaces, patterns, maths.
Well, maybe a revised edition of it in the future.
SICP is much, much bigger than the Lisp code within it. It goes beyond that. Do I use the functions in the book? Sometimes, depending (I use car/cdr on cons cells and first/rest on proper lists). Do I use the perspective on programming and CS gained from the book? In every single new thing I learn.
What do you mean by that? Can you point me to some resources?
They like the syntax, they like the power the standard library gives them. They might like the CLOS, which is a fantastic object system with all sorts of features that I've never seen anywhere else(some of them might be from smalltalk). They appreciate the ease of which it allows them to write functional code, and the ease with which they can mutate values in place. They like high level languages that compile to reasonably fast code. They like macros because they are like magic in the right situation. Ultimately it mostly comes down to preferences in language. Sure the library environment, the vibrancy or lack thereof is a major concern when you're looking to write a program with minimal issues, but lisp seems to have a very decentralized community, it's taken me a long time to find the right library because they're spread out so much across the internet. 
I agree with what's been said here... even after computers program themselves with quantum, neural-net processors, it will still be worth going through SICP. And, as for `car` and `cdr`, like others mentioned, you can use `first` and `rest`. You can use `second` and `third` and such, too. In my opinion though, if you're ever finding yourself using `caddr` or any of the multiple `a` or multiple `d` versions, you should wrap it in a function with a more useful name and it should be the only form in that function.
It does, but in an increasingly abstract way. Hypothetically speaking, knowing how a compiler is constructed might make you better at writing programs in a compiled language, but in reality a deep knowledge of the standard library of that language will probably be more useful. Personally I think everyone could gain something by reading SICP, but the question the OP asked seems to lean towards "Am I going to get a quick win out of this?"/
&gt; how does it "evolve"? From what I've seen, the implementations take this into their own hands. There's no OS threading in CL, but most implementations have extensions for it, and someone comes along and writes something like `bordeaux-threads` to unify the interface. &gt; What is preventing a new standards committee from being formed for CL? The incredible time and effort that it would take, coupled with the fact that there are now a lot of other languages to choose from with a lot of momentum. From my (limited) understanding, Lisp was created during a time when the alternative was basically C and maybe a handful of other languages. &gt; If a new standard is created, what features would the community be eager to see included or removed? Coroutines or some kind of cooperative "multithreading." Or just implement continuations (please don't tell me about cl-cont, it completely ignores error handling). &gt; Was defining the language through a government organization a good idea, or should the standardization process have been kept within the community (possibly through a non-profit organization like the Linux Foundation), thereby giving the community greater control over the language's evolution? Seems to have done well. Implementations have a standard to aim for, but that standard doesn't stop them from evolving beyond it. I think it *is* a problem that the standard is basically a stone tablet at this point, but we all seem to be getting along fine without it.
Thanks for linking to Peter's talk on the CL standardization process. It answered a lot of questions I had and shined a light on the history of CL standardization. It seems that Peter's opinion is that putting together another standards committee will be: * Prohibitively expensive * Time-consuming * Unlikely to produce a satisfactory "new" CL, given the wildly divergent priorities of factions within the community. I think he's right, in many ways, that the lack of a Benevolent Dictator for Life (BDFL) means that it's hard for the community as a whole to make decisions and move forward. Some people seem to like that the Lisp family of languages evolve slowly, without anyone "in charge" and able to compel others into implementing certain features. However, *for a particular dialect of Lisp, such as CL*, it's necessary to be able to agree on and implement new standards (*de facto* if not *de jure*). If the wrong decisions are made and the language accumulates too much cruft, at least we've experimented and learned and can move forward with a new dialect if need be. The biggest "risk" to the CL community, I think, is that stagnation will lead not just to new languages (e.g. Clojure), but *new communities* that will not understand and respect Lisp traditions; this is an accusation that I've seen leveled at the Clojure community by other (mostly CL) Lisp communities. Rich Hickey himself has emphasized, on more than one occasion, that Clojure's community, with its vigorous growth and positive attitude towards newcomers, is a key advantage for Clojure over existing Lisps.
Like I said, limited =]
&gt; It seems that Peter's opinion is that I would like to stress, that's it not just Peter's opinion, many around the community would agree. I recommend reading Kent Pitman's history of CL to see more of how we got here. &gt; However, for a particular dialect of Lisp, such as CL, it's necessary to be able to agree on and implement new standards (de facto if not de jure). If the wrong decisions are made and the language accumulates too much cruft, at least we've experimented and learned and can move forward with a new dialect if need be. If the decisions are not baked into a standard then we don't have the cruft problem, we can just refactor the good into a new library, add what was missing and continue. &gt; I think he's right, in many ways, that the lack of a Benevolent Dictator for Life (BDFL) means that it's hard for the community as a whole to make decisions and move forward. Some people seem to like that the Lisp family of languages evolve slowly.. The lisp family of languages includes Clojure, which has a BDFL and is progressing well (which you allude to later). &gt; The biggest "risk" to the CL community, I think, is that stagnation will lead not just to new languages (e.g. Clojure) Clojure isn't a 'risk' to CL in the same way PicoLisp isnt. They are both awesome lisps that chose to focus on different goals, those goals are not necessarily right for everyone and different lisps serve that. I *love* what is happening in Clojure yet I'm not switching any time soon. &gt; but new communities that will not understand and respect Lisp traditions Culture is not baked into a standard, in a language this flexible people will choose how to work. Culture is made by the people, and to that end how we treat our newcomers matters more than any amount of railing about the past. Others here have covered how the community grows the language so I wont state that again, but I would suggest that over the last few decades this question has been raised a few times (see also questions about parens and m-expressions). The fact that there hasn't been a new standard is based on reasoning, not a lack of care. I'd strongly recommend digging into the history if you truly want to see why this hasn't happened. 
Have you try asking on Clozure's mailing list and IRC channel? http://ccl.clozure.com/index.html#support%3Eccl.clozure.com 
&gt; It seems that Peter's opinion is that putting together another standards committee will be: &gt; &gt; Prohibitively expensive &gt; Time-consuming &gt; Unlikely to produce a satisfactory "new" CL, given the wildly divergent priorities of factions within the community. It's worth noting however that the ANSI spec got most things (aside from underspecified cases like logical pathnames) right, despite the much derided design by committee. There's no pressure really to change any of the basic language features and dictionary. Arguably some things matured since 1994 and are ripe for standartization, e.g the MOP or multithreading, and am sure a committee from todays' practitioners and implementors could do a stellar job there. The real issue here is money: no DARPA funds are flowing in the community since the early 1990s, and this kind of process is expensive.
&gt; CFFI, bordeaux-threads These would be standards if a CL implementation (old or new) could decide to expose FFI or threads natively according to these standards. Would that work? My hunch is that it wouldn't work well, that these are just popular libraries that must support an implementation, not real standards complied with by implementations.
The great thing about Lisp is that that is mostly a distinction without a difference. 
If I pick up a random implementation, odds are very good that I can use both CFFI and BT on them. In some cases the odds are better of that working than various corners of the 1994 standard. The fact that they are implemented as a library has no meaningful impact on whether or not it's standard.
&gt; However, for a particular dialect of Lisp, such as CL, it's necessary to be able to agree on and implement new standards (de facto if not de jure). If the wrong decisions are made and the language accumulates too much cruft, at least we've experimented and learned and can move forward with a new dialect if need be. I mentioned several such new de facto standards in my original post. &gt; The biggest "risk" to the CL community, I think, is that stagnation will lead not just to new languages It is disingenuous to suggest that Lisp has stagnated because there is no new ISO standard. It did not stagnate from 1960 to 1994, nor did it stagnate from 1994 to 2016. 
What does that mean?
Yes, I was talking about when "Lisp was created", not when it was standardized.
I would like to give two reasons to love the "Lisp way": 1) The pleasure to understand something in the foundations of a computer language, 2) Among other things, Lisp gave me the conceptual tools to implement in a browser a tiny evaluator in 20 lines (http://epsilonwiki.free.fr/alphawiki_2/?view=foo), a tiny dialect of Lisp with a first subset of 3 special forms [def, lambda if] (http://epsilonwiki.free.fr/alphawiki_2/?view=foo_2) in 200 lines, a more powerful one (http://epsilonwiki.free.fr/alphawiki_2/?view=microtalk ) in 750 lines, and a true useful tool to do markup, styling and scripting in a unified language as you can see in http://epsilonwiki.free.fr/alphawiki_2/ . As a non professional coder it would have been impossible for me to do such a thing in any other language.
What does Sy Ke ln mean?
Someone else might know what lisp this is, but here I assume it is common-lisp (defun c-tone (hz g) ;define the function c-tone with arguments hz and g (let ((c-array (make-array 2048))) ;make an array of 2048 elements called c-array (dotimes (i 2048) ;loop 2048 times with i from 0 to 2047 (setq x (- 1 (/ i 1024.0))) ;set the global variable x to 1 - (i / 1024.0) (setf (aref c-array i) (sqrt (- 1 (* x x))))) ;set the ith element of c-array (setf positive (snd-from-array 0 1024 c-array)) ;set the global variable positive ;; snd-from-array is not a standard function (setf negative (mult -1 positive)) ;set the global variable negative ;; mult is not a standard function (setf c-table ;set the global variable c-table (list (seq positive negative) (hz-to-step 1.0) t)) ;; seq and hz-to-step are not standard functions (mult g (osc (hz-to-step (* 4.0 hz)) 1 c-table)))) ;osc is not a standard function (c-tone 440 0.8) ;call the function c-tone The functions mult and seq may indicate that this is some other lisp variant. In any case without knowing what all these functions are doing I can't tell you what this function is doing. Also, all of the `setf`'s of variables outside the scope of the `defun` which are immediately then used indicates this was written by someone not fully understanding how to write good lisp code.
This is written in [Nyquist](https://www.cs.cmu.edu/~music/nyquist/) from their page &gt; Nyquist is a sound synthesis and composition language offering a Lisp syntax as well as an imperative language syntax and a powerful integrated development environment. As for what is it doing I don't really know Nyquist, but it seems like it is producing some sound samples and playing them. Edit: Correcting the quote.
It is definitely Common Lisp. I don't know Nyquist, but I think it's safe to say that the code makes an array called `c-array` that is 2048 elements long. Then, it loops through each sample. At each sample, it sets x = (1024-i)/1024 and then sets the i-th sample to the square root of 1 - x^2 That formula looks to me like it's trying to be a quadratic approximation of a sine wave. The whole array now is x * (2 - x) where x starts at 0 and gets up to 2 by the end. So, this is one lobe. They make one copy of the first half of this parabola as `positive` and make a copy of `positive` as negative. I'm not sure why they only did 1/2 of the parabola and not the whole lobe. This is weird because now positive arcs up from 0 to 1 and negative arcs down from 0 to -1. Then, it looks like they are setting up something called `c-table` which is just a list of a `seq` (which I'd guess is a Nyquist thing that effectively concatenates) of `positive` followed by `negative` and I'm not sure what `hz-to-step` would mean... If I had to guess, I'd say that for every 20-Hz, it steps through the `seq` 20 times. I'd have expected the seq to be more like `(seq positive (snd-reverse positive) negative (snd-reverse negative))`. I'm guessing the `osc` sets up an oscillator based on the c-table which would probably repeat the sequence. The multiplication by 4.0 looks like an attempt to go 4 times through the sound for every cycle. That doesn't make sense to me either though. But, it looks like the goal is to generate a tone with frequency `hz` and gain `g`.
A hard dependency is some sort of library or other code that the program *needs* to be able to run. As opposed to a soft dependency, where the library or other code is merely an 'addon' of sorts and all you lose is some extra fucntionality.
Cells holding a Symbol Keyword or Integer (my guess at least)
Roswell is a unification of solutions provided by CIM, cl-launch, buildapp, plus additional features such as Bash completion (added recently, very comfortable), unix man pages and tools for scripting in lisp. It **reduces lots of steps** needed to start writing and using common lisp. It is good for lisp newcomers as well as old lispers. I value its effect on lowering the initial threshold. re: your comment -- Quicklisp is a package manager, but it should be manipulated *from within* lisp, not directly from the shell. Roswell connects quicklisp and shell. But this is merely just one of the problems Roswell solves. 
You can also come over and I'll let you read my copy. Seriously though, [Structure and interpretation of computer programs](https://mitpress.mit.edu/sicp/full-text/book/book.html) is also a free read. It's more about how computer programs work but it uses scheme as a teaching language.
[There you go.](http://lmgtfy.com/?q=online+lisp+interpreter)
Were you going [for](https://www.youtube.com/watch?v=VOmD-xqK2Es)?
There's also a newer edition available [here](http://sarabander.github.io/sicp/): &gt; The typography has been modernized for better on-screen legibility and comfort. All the mathematics is set in proper TEX, and figures redrawn in vector graphics. &gt; &gt; It is an improvement of the Unofficial Texinfo Format (UTF) which was converted from the original MIT Press full text release by Lytha Ayth and maintained by Neil Van Dyke. [https://sicpebook.wordpress.com] But if I understand it correctly, the OP is looking for something including an online REPL.
Maybe this: http://learnlispthehardway.org/try-lisp/ ?
&gt;There's also a newer edition available [here](http://sarabander.github.io/sicp/) That sure is much nicer in a screen. &gt;But if I understand it correctly, the OP is looking for something including an online REPL. Yeah, you seem to be right. I missed OP's text post.
&gt; I missed OP's text post. I did too, at first. 
On this tutorial Next button doesn't work, only 2 times and no more
Which compiler or interpreter can be used for a 3 lines formula and a big bracket which covers all 3 inequalities in paragraph 1.1.6 from this publication?
3 lines on both sides of the formula
you will not find. nothing special. my repo https://bitbucket.org/mihailp/tankfeeder/src try 4clojure, Touretzky, crypto, rosetta dirs.
I think it's always down to the rendering side, if you are looking for WYSIWYG, I don't know of any good ones. I think my main query here is, why is this in r/Lisp?
Apparently [ProjecturEd](http://projectured.org/)
One of these wild, whole web crawlers spit this response: [WeScheme](http://www.wescheme.org) BTW, wrong subreddit: [/r/racket/](https://www.reddit.com/r/racket)
Great explanation! Thanks, I still have a lot to learn about Common Lisp :-)
Build your own, for instance: http://epsilonwiki.free.fr/alphawiki_2/?view=foo
That is an intriguing idea. 
[Lisp 1.5 Manual](http://ir.nmu.org.ua/bitstream/handle/123456789/129874/37a4142032912cebb0e8fe8f61c6fe2f.pdf), but I'm not sure what you mean "only with digits?"
Perhaps ask the [Wolfram Alpha](http://www.wolframalpha.com/) people. (Note, though, that Wolfram Alpha is written in Wolfram Language, which afaik is not a Lisp.)
My guess is that you're asking for an online calculating service that uses Lispy syntax - i.e. S-expressions - rather than a service with a Lisp backend; but if you *are* interested in the latter, there's [Maxima Online](http://maxima-online.org/).
X^2 +8 =10
Wonderfully written, sir! 
Interesting writeup on opinion of sexprs and alternate take on semantics. Not keen on the Python-style indentation in LISO, and I'm not sure the blocks are easier to read than a good paren auto-match. Maybe someone needs to create a better way to directly create and edit binary structures, so syntax can be relegated to a printable format for print and text editors. Then we could move past all the pointless debates on prefix/infix, parentheses/indentation, semicolons, line length, etc. Imagine if people could choose whatever parser/formatter they prefer. This could even support internationalization...
Thanks, that sounds a plausible interpretation - if that's indeed what is meant, perhaps the author could add a clarification to that effect.
Just write a proposal already!
LispScript https://bitbucket.org/ktg/lispscript
Surely you mean a revised revised edition? We already have a revised edition.
So...this is about algebra, right?
You appear to have operators / infix functions there too. + Which operators would you like to support, is infix necessary or would lisp style `(+ 1 2 3)` instead of `1 + 2 + 3` be adequate? S-expressions are generally a very nice way of writing math expressions.
Infix notation
Okay, fair point. Still, i'm not sure that the frequency of such things relative to bulk of Lisp source can be described as "tend[ing] to erase the distinction ..."
I've tried porting 3 different C based common lisps to emscripten with little-to-no luck. clisp flat out will not run on emscripten, as it assumes things about the underlying microarchitecture that just aren't true (namely that the call stack is in addressable memory). Ecl I got to go much further before crashing (I actually got the bootstrap lisp running under javascript), and now that I've discovered more tricks for making emscripten not break my code, I may go back. eclipse common lisp gets pretty far into initialization before crashing when a generic function call fails. In any event you'll need to limit yourself to interpretation at runtime, as emscripten is not self-hosting. emscripten uses a truly brain-dead ABI that is much more fragile then most ABIs targeted by C compilers, so large code bases that make heavy use of varargs are likely to break, and the devs have little interest in making it more forgiving.
&gt; Doesn't the second contribute to the first? In the same sense that learning musical theory and scales can teach you how to construct an Open G for guitar. I can teach you how to play Open G in about 15 minutes. Musical Theory is a life long learning process where you can see how the G chord is structured and why it contains the notes it does. You'll still need the learn how to play the Open G, which I can teach you in 20 minutes. The extra 5 is to merge the form with the knowledge you have of theory, so you can try not to understand it and just play it. Is that a contribution? It is, for sure. But if you wanted to learn how to play, it takes less time then learning why it is played the way it is, and much less time over learning the theory, the 12 step octave in western music, why A is now 440 etc.
closer related to the medical meaning of isomorphic, meaning similar in form, shape or structure; common lisp script is isomorphic to common lisp, similar form, but one runs on browser client another on systems.
X-Post referenced from /r/rust by /u/Murarth [Ketos, a Lisp-like scripting and extension language, written in Rust for Rust programs](https://www.reddit.com/r/rust/comments/44t2jh/ketos_a_lisplike_scripting_and_extension_language/) ***** ^^I ^^am ^^a ^^bot ^^made ^^for ^^your ^^convenience ^^\(Especially ^^for ^^mobile ^^users). ^^[Contact](https://www.reddit.com/message/compose/?to=OriginalPostSearcher) ^^| ^^[Code](https://github.com/papernotes/Reddit-OriginalPostSearcher) ^^| ^^[FAQ](https://github.com/papernotes/Reddit-OriginalPostSearcher#faq)
(define (sum-of-squares x y) (+ (square x) (square y))) (sum-of-squares 3 4) 25 Now we can use sum-of-squares as a building block in constructing further procedures: (define (f a) (sum-of-squares (+ a 1) (* a 2))) Okay so... (f 5) 136 so (f 5) let's map it out (sum-of-squares (+ 5 1)(* 5 2)) so (sum-of-squares (6)(10)) so it's the sum of 6^2 and 10^2 - so 36 + 100...136. 
You might be interested in Mezzano: https://github.com/froggey/Mezzano
Interesting. Thanks for the feedback.
Try Skynet here: http://busfactor1.ca/bin/skynet
When you write an OS in C, you need a small amount of assembly to setup the C runtime environment from scratch. When you write a OS in Lisp, you need somewhat more assembly (since lisp runtimes tend to be larger) to setup the lisp runtime environment from scratch. If you are intimately familiar with your lisp implementation, then you can setup a small fraction of the lisp environment in assembly, and then use a subset of lisp (which only needs what you have so far setup to work) to setup the remainder of the environment. You do not need to write a lisp in assembly; most lisp implementations are written mostly in lisp. See sbcl for an example of a lisp which except for startup and GC is written entirely in lisp.
Agree with a good half of what sickofthis wrote. Graduate studies are a special opportunity to set yourself up for a good career. Writing an OS in Lisp may not be the best use of that time. What innovation does it bring to the field? What resume do you want to show people in a few years? What does success / failure look like? A Lisp OS has been done before, and rolling one from scratch could easily consume a graduate program. There had better be a compelling payoff. I appreciate why you like Lisp, but not feeling comfortable with C, C++, Java, etc. is not exactly a badge of honor. You should focus your studies on learning a wide swath of current research. Dabble on prototypes to help cement this knowledge. Large-scale implementation activities are generally best left to a paying job. Find a good advisor (respected / good reference, interesting research, has time to teach and mentor). Figure out how to work with them and the other students in their research group. Form professional connections. Learn new things. Conquer the world after you graduate. I would highly recommend reading Peter Drucker's Innovation and Entrepreneurship before you decide to focus on any particular technical path. A rewarding career involves satisfying work that is valued by others.
Have a look at "[PilOS - A Stand-Alone Operating System](http://picolisp.com/wiki/?PilOS)" from the [PicoLisp](http://picolisp.com/wiki/?Home) crowd.
It was fine for me switching to 720 and going fullscreen. Totally readable.
I would have to agree about the music. Everything else is very good. Looking forward to the next episode.
I know about Zeta C. You could also translate Fortran to Lisp: F2CL still works today. But I don't think *anybody* took a Lisp machine and said "this is such a superior *OS* base that I will run my large C/Fortran program on it." They said "this is such an awesome development environment to write Lisp applications in, I will pay $200,000 per workstation." You can read the [Genera marketing material] (http://www.symbolics-dks.com/Genera-why-1.htm): it's all about the application development. What do they say about the network stack? "Yes, we have one." &gt; I'm not sure why you feel they hadn't got the "global Lisp environment" thing worked out. And it's hilarious that you feel they "punted" on areas like multi-user isolation and security. They were designed to be single-user graphical workstations! I think that is exactly what I was saying. They didn't address those issues at all. But the world of 2016 doesn't need another single-user graphical workstation OS. Trusting every application on your machine not to compromise the security of your network communications sounds pretty stupid. &gt; virtual memory system with protection mechanism in hardware, along with tag bits for hardware-assisted type checking and hardware-assisted garbage collection. Why you assume this is 'hacky' and lacking in security is beyond me. I agree it is awesome at the goal of getting a GC to work with hardware assistance, support virtual memory, and not have the two things completely screw each other up. But the "protection bits" were for virtual memory traps, not for process isolation. You could cons up a low-level pointer that could be used to stomp on any place in virtual memory you would like. The chain of network packets is in a global variable you can address by name. The flexibility of Genera meant loading any application could redefine anything in the system. You could stomp on anything another application did. It seems to me that a modern Lisp OS connected to the internet has to be able to sandbox applications, and if you are going to fully sandbox them, why does the OS matter? I'm sure there is space for innovation here, but I haven't seen anything actually demonstrated. I know the history of Lisp Machines, and in fact I own a MacIvory. And I tout the Unix Hater's Handbook myself. I don't think I'm biased against Lisp or fail to recognize what Genera did achieve. I agree it is unfortunate that UNIX (because the source code was free and hackable) has sucked a lot of the oxygen out of the OS space. (And I *also* think it is bizarre that we run UNIX kernels on our cell phones, because the security model of UNIX of "root can do everything, users can't see each other" seems like a poor starting point for what a *single-user* device needs.) But this "Lisp OS is what we need" is just unfocused wanking. We need much *less* of that, and more actual work.
The catch is that SBCL depends on an underlying OS to provide facilities for a file system and I/O and the memory traps to support the GC.
Interesting. I didn't have any options to switch above 360p when I viewed it...
from looking at other videos, it seems that youtube has to do some processing of videos at higher resolutions, which means they show up sometime after uploaded.
http://picolisp.com/wiki/?PilOS
This looks nifty...Good Job!
&gt;Cache locality has been lisps major downfall. Lisp is so modular, doing everything as pairs (even if often optimized as other datastructs internally), that it thrashes any well designed cache heating the chips by electrifying too many wires randomly spread. Real-world Lisps don't implement everything on top of lists and atoms, since that kind of purity has no real point. Fixed-precision integers, arbitrary precision integers, hash tables, multi-dimensional arrays, strings, etc. are all implemented in their own ways. Internally, the trick most dynamically-typed languages use is pointer tagging: you take the last two or three bits on a pointer, which on modern architectures are guaranteed to be zero, and use those bits to store codes: one for fixed integers, one for conses, one for arrays, for instance. Of course you can't fit all type information on a pointer: for larger objects you need to deference that memory, and inspect whatever data holds the extra information you need. Type inference and other optimizations help here.
I don't know what the hell this is, but it got me reading to the end, so I guess that's something. All I can really parse is the comment about cache locality and the supposed non-locality of lists‚Äîthe statement about "just using languages that blob together a bunch of data" is meaningless, since a "blob" isn't a real data structure to begin with.
Hy is a wonderful little lisp, and very feature complete. It's basically what Clojure on the Python VM would be like.
For the first hour or so after an upload you will only be able to view the low resolution versions.
They should implement full list comprehensions like Python has. Currently Hylang only seems to support the analogue of `[expr for x1 in a1 for x2 in a2 ... for xn in an if condition]` (where the `if condition` part is optional). That's useful, but I often want to put some `if`s between the `for`s. For example, in Python `[(x,y) for x in range(5) if x%2==1 for y in "ab"]` produces `[(1, 'a'), (1, 'b'), (3, 'a'), (3, 'b')]`; but the corresponding Hylang, `(list-comp (, x y) (x (range 5)) (= (% x 2) 1) (y "ab"))` gives: File "&lt;input&gt;", line 1, column 1 (list-comp (, x y) (x (range 5)) (= (% x 2) 1) (y "ab")) ^-------------------------------------------------------^ HyTypeError: `list_comp' needs at most 3 arguments, got 4
Can't you just stick all the conditions at the end and "and" them together?
Sometimes yes, sometimes no. Even when you can, this might make the comprehension run much slower. Example where you can't put all the if's at the end: `[x for i in p if 0&lt;=i&lt;len(a) for x in a[i]]`; you need to check if the index is in bounds before you calculate `a[i]`. Example where you can and you get the same answer, but the version with if at the end is much slower: `[(x,y) for x in range(1000000) if x&lt;3 for y in range(x)]`.
How do I get free online lisp compiler without downloading
rousse101 [asked the same question before](https://www.reddit.com/r/lisp/comments/44a21g/is_there_lisp_programming_online_tutorial_without/) and does not seem interested in providing feedback on what exactly they are looking for.
Self plug. You might find my Skynet Development video series interesting: https://www.youtube.com/playlist?list=PLzTz7AF-PnvJITLYNcC4CcRXbbEpRcQip It's a combination of learning (a) Lisp from first principals and Javascript webdev. You're meant to follow along in the online version of Skynet: http://busfactor1.ca/bin/skynet
God just get a copy of ABCL, armed bear common lisp, run it, do whatever you want. There aren't very many good lisp implementations that have an online interpreter. [here's one, from the first three links from the search for "online lisp interpreter"](http://www.tutorialspoint.com/execute_lisp_online.php) This looks nice. [Another one](http://ideone.com/) 
ideone is using java but no lisp
So this shows you how to do basic things in Guile when it ignores a big part which is that there is large libraries with batteries included for R. 
Reminds me of [this post](http://jackstouffer.com/blog/nd_slice.html) about using the D standard library to replace Numpy. The author seemingly believing Numpy is a matrix multiplication library.
I agree. Pamphlet implies some number of pages less than 85. Which either means somebody looking for a short read will probably not read it, and somebody looking for more detail might pass it over and not even realize how much detail is there. 
You can try deleting the directory `~/.cache/common-lisp/` which is where asdf stores the fasl files. This will force sbcl to recompile all of the packages.
So I found this: https://github.com/edicl/cl-ppcre/blob/master/specials.lisp And I found this: https://github.com/edicl/cl-unicode/blob/master/packages.lisp So that is probably the relationship that is out of whack. It was loading cl-unicode when it blew up. At this point I checked the cl-unicode asd to make sure it depended on cl-ppcre. It did. I found the cl-unicode change log here: https://github.com/edicl/cl-unicode/blob/master/CHANGELOG Read the top change in the changelog. So this is a load order dependency issue. Upgrade cl-unicode to the latest, or always load cl-ppcre first. 
&gt; that kind of purity has no real point. Fixed-precision integers, arbitrary precision integers, hash tables, multi-dimensional arrays, strings, etc. are all implemented in their own ways. Its a far steeper learning curve for someone who doesnt already know what integers, strings, and arrays are, such as a child or an AI trying to create code to understand itself but instead it sees structures designed for Human ways of thinking. I'm looking for a system that builds itself, which functional programming and lambdas started as, but things got added, and if its so efficient and practical why am I, a person who loves functional programming, using procedural programming instead? &gt; pointer tagging: you take the last two or three bits on a pointer... one for fixed integers, one for conses, one for arrays, for instance. I use similar structures of lisp-like pairs (binary forest nodes) to tag my basic types. I'm also planning to use the negative values of signed ints to view expansions of compressed data stored in the pointer array, but I know they're not pointers since they're negative.
What if x.left != y.left, compare(x.left, y.left) == 0, and compare(x.right, y.right) != 0? Won't this algorithm incorrectly return 0 in that case? Also, x.height is not constant time for a cons cell as I under cons cells. But perhaps you mean a richer tree node. 
mods, can we please ban this guy? This is starting to remind me of comp.lang.lisp. Also, what happened to /u/lispm?
Looks really good, great work! Just going to give it a trial and see how I get on with it. Will report back :-)
I'm already using it to replace zsh :-) It's really not close to it yet though, dogfooding made me realize that I'm mostly missing pipes and redirections. The great thing is that I can implement that through external modules though! With regards to the Java VM... ugh. I guess I should rename now rather than later. But I don't want to :(
Thanks! Waiting for the gitlab issues :-) (hoping they'll never come, hehe)
&gt; What if x.left != y.left, compare(x.left, y.left) == 0 compare(a,b) is 0, and a==b, exactly when a and b are the same tree shape. Can you give an example where its not? That means a.left==b.left and a.right==b.right, and recursively. Its built that way using the hashtable. To create/lookup a pair, I concat their 2 int addresses into a long and use that long as a key in hashtable, which either finds the existing pair or creates a new one at end and puts that int as its value. That int can then be used in new pairs at higher index. &gt; Also, x.height is not constant time for a cons cell as I under cons cells. But perhaps you mean a richer tree node. Its a variation of lisp I'm building. My nodes store height as an int16, and I use datastructs that usually keep height under 100 even with long lists.
Your points are right. This isn't a pamphlet, and it has very little to do with R. The main reason why I decided to refer to R is that it is seemingly popular among a large group of users, and its name brings to mind a certain set of applications (and that genetically it is a more or less direct descendant of Scheme), while the base of Guile users is considerably smaller, and most people probably would think that it is some esoteric specialist tool. Moreover, I have to admit that "Scheme" is probably one of the worst names for a programming language imaginable. As to the "pamphlet" part, I initially intended to fit in 48 pages, but in the end I didn't know how to change the font size in LaTeX ;] Anyway, I thank you all for your feedback and for nice words, as they mean a lot to me. Thanks!
lishp!
Crash is the name of a system utility on some older Unixes. Also, there's some MIT folklore about a crash command they implemented to take away the hacking mystique on one of the first time sharing systems.
Hmm, any reason to try this over eshell? I really rely on tramp integration.
Right now? No. Later? Maybe. It's very young yet, but the core will let you easily hack. I plan on adding some features to make ssh easy, so come back to look at it in a couple of months?
A Lisp nube will bitch and complain about 'all those parentheses'. Sadly, been there. But when you spend a couple of days with Lisp you realize that the parens are much better than some arbitrary syntax. You always know where parens go in Lisp, but things like commas and semicolons in blub languages, not so much. Before you know it, parens become really useful, to the point of making things like C seem like a bad dream. I cannot believe that someone would go way out of their way to eliminate a truly wonderful notation, or call it ugly for that matter.
some people will aim for lispiness, most people will only ever want punctuated + traditional arithmetics. They don't care about generic, monad, denotation, a new abstractions in general.
Nope. There is no cl-ppcre::*standard-optimize-settings* to evaluate. cl-ppcre does not export this symbol.
If cl-ppcre has been loaded, you *should* be able to evaluate cl-ppcre::\*standard-optimize-settings\*, and evaluating cl-ppcre:\*standard-optimize-settings\* *should* give you an error saying the symbol is not external - which, because I'm using slime, was printed in a different buffer when I did the following: CL-USER&gt; (ql:quickload :cl-ppcre) To load "cl-ppcre": Load 1 ASDF system: cl-ppcre ; Loading "cl-ppcre" (:CL-PPCRE) CL-USER&gt; cl-ppcre::*standard-optimize-settings* (OPTIMIZE SPEED (SAFETY 0) (SPACE 0) (DEBUG 1) (COMPILATION-SPEED 0)) CL-USER&gt; cl-ppcre:*standard-optimize-settings* ; Evaluation aborted on #&lt;SB-INT:SIMPLE-READER-PACKAGE-ERROR "The symbol ~S is not external in the ~A package." {BD95AC1}&gt;. CL-USER&gt; So if you loaded cl-ppcre and you get an error evaluating cl-ppcre::\*standard-optimize-settings\* that says there is no such symbol, that means that somehow the symbol is not defined in the package at all (and not just defined but not exported). If that is the case it implies that the definition is getting left out after compilation somehow. I would think it's more likely that something like what /u/wwwyzzrd or /u/handle0174 are suggesting is what is going on, and you just need to update cl-unicode and/or make sure the right cl-unicode gets loaded, but it's on the outside possible that the definition of \*standard-optimize-settings\* is getting left out by some kind of 'this internal symbol isn't referenced by anything internally, therefore we don't need it defined in the fasl' optimization by your specific build of sbcl (as the symbol is only used in read-time evaluations). I think it's kind of unlikely, but it could be the case and is something you can check. Edit: You can edit the cl-ppcre package definition to export \*standard-optimize-settings\* and reload it, to see if that fixes things, if it's not one of the imho more likely situations pointed out by /u/wwwyzzrd and /u/handle0174. If other packages reference the symbol it's probably wrong that it's not exported. 
Can Racket even be compiled for iOS to be begin with? Or Android for that matter? Also, technically the license isn't a problem if your app is also LGPL.
A minor annoyance is not being able to switch the metaclass of a class in CLOS
Irrespective of the language, in general there's no guarantee that an object pointing to another object is anywhere near it, memory-wise. It depends on how allocation and garbage collection is done. In any case, "binary searches on lisp pairs" isn't how CLOS instances work. If we're comparing, say, C++ instances and CLOS instances, then we ought to make that explicit. A fair point would be that you can't have an array of structs, directly, in Lisp, as you could in C‚Äîyou can only have an array of pointers to such objects.
This is more of an app store annoyance, no?
I agree with you, but I think the FSF would argue that it works exactly as intended. 
Chicken scheme does not support POSIX threads. Other than that it is an enjoyable lisp implementation to boot.
try lambdanative? its scheme, so might be close enough to racket for you to feel comfortable?
Yes, Apple requires 64 bit in preparation for 64 bit only in the coming year(s): https://developer.apple.com/news/?id=04082015a
With Common Lisp, my biggest issue is that there is no way to hook into the interning of symbols (short of installing a reader macro for every single possible character). There's been a lot of talk about various different ways of doing package nicknames, and it could be accomplished in a library *if* there were a customizable function called to intern each token that is determined to be a symbol.
I'm currently implementing piping, and I have been thinking about that. I'll keep the infix pipe, but the code is easy enough to change it in a prefix pipe too, so maybe I'll provide both ways. For the prefix pipe, I was more thinking about e.g. `| (cat foo) (grep blah)`.
I'd prefer the outer parentheses to be there so to better support arbitrary nesting, but either way is better than the current state of shell syntax IMHO.
I'm talking about the pair, cons, first, second, boolean logic, and integer math funcs of https://en.wikipedia.org/wiki/Church_encoding I mostly use Armed Bear Common Lisp as it can be included in java executables.
From iOS 8 dynamic frameworks are allowed.
There isn't a real pattern. When moving part of the logic from the main function into an auxiliary function, the auxiliary function is sometimes given the same name with a % added to denote the connection. If the process is repeated you might have %% added etc. But all of this is only an aid to the programmer, the underlying lisp doesn't care what you name stuff.
Okay. That makes sense. While I knew that there was no syntactic meaning, I wondered if the percent symbol was a convention, similar to how earmuffs are used for global variables.
You wrote [spm-reader](https://github.com/jasom/spm-reader) as stab solve that issue right? If so, kudos. [Apropos](https://github.com/m-n/lazy-susan)
The code signing thing is still debatable. Besides that you can provide a downloadable zip with unsigned object files and a build script like the Sparrow app did.
I have used it for functions that aren't to be used outside of the current package and probably not outside of the current file. In that way, when reading the code, you can skip down to the first function that doesn't start with a '%' and start reading there, delving into the '%' functions only when needed.
No, not that it isn't also a good point. The argument I remember had more to do with earmuffs hindering quick prototyping. If I change a function from using a dynamic variable to a lexical one or vise versa I would either need to change the variable name throughout or have inconsistent use of earmuffs. Both are irritating for different reasons. Add to this the fact that in all the time I've been writing common lisp I've never once had difficulty determining if a variable was dynamically or lexically scoped without needing earmuffs and the usefulness to me seems moot.
I hadn't heard of Kawa Scheme yet, interesting! While concentrating primarily on non-gaming apps, these gaming alternatives are interesting as well 
I don't worry about you having that trouble, I worry about me having that trouble if I'm using your code. Probably not a good idea to export those symbols for everyone else's sake (that is if you write code that others use). Or perhaps the arguments that are for quick prototyping shouldn't apply to code that is released or shared?
My original use case was this: cd in a directory mounted by sshfs, and any command you execute in it will be executed over ssh. It's the next thing I'm going to implement in crash, after the rename. The hooks provided by zsh/bash let you do things before a command, but they don't let you actually prevent the command from running.
I've done the same thing (might even have the same books, heh) and I don't remember it being too terrible to just pick one to write in and implement whatever I needed to port code from the books from one dialect to the other (scheme-&gt;cl being possibly easier in that respect, although that's sort of assuming not pulling in SRFIs, etc). Unless the code from your books is using heavy CLOS or something like that, it shouldn't be too bad. 
The thing is, it *has* limits. The point of the shell being in Lisp means that you can spin up a swank server in your `~/.crashrc`, REPL into it, and work with any function in it. Then add the functions in your `~/.crashrc`, or make an external module, or whatever. And since you can replace `crash`'s functions, there's literally no limit on what you can do on it. The system that `crash` uses to implement hooks is built with extensibility in mind; every hook is almighty and can do whatever it wants. In theory, you should never need to touch the core, since it's fairly minimal. In fact, most of what I've been doing has been in external modules: `cd`, piping, history, glob expansions are all modules outside of the core.
I did it many years ago. It worked out fine for me. There were a few moments of confusion when I'd forget which things were available in which dialect, but it wasn't bad, and I've been equally comfortable in both for many years now.
Don't. Learning one dialect is hard. Perhaps not very hard, but hard enough that many people fail - that is, give up. There is no reason to make it harder (even if it is not much harder) and increase probability of failure. Pick one - Scheme because it is simpler and smaller and it is less probable you'll give up. You can learn CL later.
Yes, that's mine. If you limit the valid characters for starting a symbol, then it can be done efficiently. Note that informatimago's reader did nearly all the heavy-lifting there. [edit] Just read past the first-paragraph of the lazy-susan README and see some nice things in the examples!
You should be able to learn enough to read both without a problem. Learn the syntax, core data structures, and macro expansion. There are some differences, but the two languages are clearly dialects with common roots. Think Java versus C# or shell versus Perl. Macro expansion -- editing code as if it were data -- is the main thing that should be new to you. Both dialects have a strong read-eval-print loop (interactive console) tradition. Use it to quickly experiment with small code segments. A quick test is worth hours of reading. Getting at the fundamental differences -- coding styles, idioms, low-level tools, etc. -- would require a deeper investment in one dialect or the other, and that would come faster from studying one language at a time. This isn't a problem for your stated goal, but it might be a consideration for others browsing this thread.
Thanks for all the kind answers, I think I will power through both dialects at once as I believe that stimulating the underlying concepts makes programming more fun. Kind regards, multiquine
Functional Reactive has picked up a little steam in the JavaScript realm (of which is currently my main focus in life, so this explanation is coming from that side of the pond). Reactive is simply responding to events, but those events can be key presses to changing values and with Functional Reactive, you can treat those event streams just like lazy lists or arrays of items and deal with them appropriately. If you think of a stream of events as a vector: *--------&gt; On that Vector is a series of events such as keypresses: *---h--e--l-----l--o----&gt; You can manipulate those vectors to produce transformed vectors: v1: *---h--e--l-----l--o----&gt; | | | | | &lt;- v2 = map(v1, ucase) v2: *---H--E--L-----L--O----&gt; which generates another stream of events that could be listened to by another process. Of course, you can `merge`, `delay`, or many other things to those event streams in order to produce a stream of events that portray the intent of your app. For instance, you could have two event streams. One is stream reading a file one line at a time, and another is streaming reading key presses a user is entering to approve or deny each line. Using an appropriate merge (zipper) you can easily link the two event streams into a pair of "line / isApproved" event objects. You can then `filter` that stream by approved and write another file line by line from the filtered set of only approved lines. The first stream will read in the file in entirety but the user input will be slower and much more erratic.
I've switched to this and can't recommend it enough. My experience is that you should make sure you clean out any other installs or configuration files then install and run sbcl, and run emacs/slime, through roswell rather than returning to starting them directly.
I like tools like slime for lisp, as it provides call tips and function signatures. It should help with those language confusion issues should they arise. Luckily, the gross semantics and syntax for both of them are fairly similar. The largest differences other than the lack of CLOS for lisp will lie in the libraries and the macro systems. Oh yeah, functions require special treatment as variables in common lisp. 
&gt; If you dont control garbage collection and organize the datastructs at the bit level, you are not really using a closure. Wat. A closure is just a function that has access to bound variables that were present when it was created. It's got nothing to do with garbage collection, and the structure of variables is similarly unimportant. The specified language semantics require it to behave a certain way, and that's that.
Also garbage collection isn't something that is "hidden" and claiming that garbage collection can crash a program is like claiming function application can crash a program. If someone programs the GC badly it can but the GC is well tested and bugs in it would quickly be found. I'm far more confident in the people who build scheme compilers to write a good GC then I am then am of a random programmer correctly managing object live status manually.
I suspect you don't know what those things actually mean. Scheme absolutely supports closures and continuations. 
Not a problem beyond embedded, buy more ram or a bigger disk.
ECL is particularly suited to this task. Since it transpiles to C, the C compiler will remove dead code automatically for you. You can get incredibly small executables this way.
&gt;would at least a programmer be able to select and delete the unneeded items from the program prior to dumping? Not portably. Though it would be nice if SBCL had some kind of feature that let you mark certain things for deletion prior to dumping.
I think you are somewhat confused. You say you want to get smaller image sizes, but then you say "I am not able, using SBCL,..." SBCL is not Common Lisp. It is just one implementation of Common Lisp. Image size is one of the major axes along which CL implementations vary. You are going to have a lot better luck asking "which CL implementations allow me to deliver small images", and be more or less willing to accept the answers you get. As in, someone may point you to Lispworks (I don't know if it produces small images, but hypothetically). You don't get to cry "but it is commercial!" You said small images were important, not price. Or someone might point you to CLISP, you don't get to cry "but it is slow!" Because you said small images were important, not execution speed. Different implementations have different goals. AFAIK, SBCL has *never* had a goal of small image size. It has prioritized execution speed. AIUI, one complexity is that SBCL likes having the compiler around to support CLOS. My point is that you can't be truly sure what is "unneeded" if you aren't deeply aware of the implementation internals. FWIW, your goal of &gt; hundreds of programs composing the base of UNIX systems. is not a typical Lisp approach anyhow. The more typical Lisp approach would be to have *one* system with hundreds of useful functions, you load the system once, then do all the things you want without throwing the system away and reloading. Processes aren't free. And the additional price you pay for the simplicity of UNIX is that you only get single dumb byte streams to communicate between these small executables. And the typical UNIX approach of "throw away the source, debug, and symbol information" means you lose a lot of debuggability, introspection, and information about how your system is put together.
With SBCL on GNU/Linux you can make your FASL files executable. This will basically mean that your on-disk utilities will not include a copy of the SBCL core but use the central copy on the system, which makes them relatively small. Memory footprint will be the same though.
For your need for hundreds of Unix style mini-apps, I can offer two suggestions: 1. Put all of your apps in one image and create a 40 MB standalone app. In the main function look at the program arguments, specifically the first one which is the program name, and dispatch to that to the correct code. Then create symbolic links with appropriate names to your one large executable file. If one of your symbolic names is mycalculator, then the dispatch code in the main function looks for the program name being mycalculater and calls the correct function. This is simple, but I may not be explaining it very well. 2. Use Gambit/C Scheme. I used to do this routinely. 
Someone pasted a simple SBCL tree-shaker a while back, and with a few modifications it worked for me. Unfortunately I don't have it handy. How small do you want? ccl is about 27MB for a hello world, clisp is 10MB and ecl is 1MB (plus the DLL which is a few MB). Note that with the exception of ccl, all the other lisps have a slower startup time then lz4 compressed sbcl. Here's a quick raw data dump of lisp's image sizes and startup time (generated with https://github.com/jasom/image-bench): (size in kb, executable name, CPU utilization, wall-clock time for startup *lispname* is just '(uiop:quit)' *lispname*.big has drakma loaded into the image) 28 /bin/true 15% .0004 1005 ecl 115% .5093 48151 sbcl 91% .0064 27054 ccl 93% .0060 10162 clisp 96% .0170 4901 ecl.big 113% .8223 70413 sbcl.big 93% .0073 41713 ccl.big 95% .0094 19948 clisp.big 97% .0259 
Nitpicking: ecl.dll compiled with MSVC is 1.5 MB, and upx compressed it's down to 500 KB. Hard to beat.
Spoiler: yes
[CLiki](http://www.cliki.net/Naming+conventions) suggests that `%` should be used for: &gt; low-level, fast, dangerous function, or Lisp system specific implementation of foo 
I wouldn't trust any language in such an envrioment.
[I'm just going to leave this here](http://stackoverflow.com/questions/21769348/use-of-lambda-for-cons-car-cdr-definition-in-sicp/21769444#21769444)
Interesting! Thanks for posting this, I'm incredibly interested in all the optimizations that make lisp so fast without destroying its dynamic nature.
How it's different from manually (or automatically, through compiler macro) converting a list to array and back to list locally?
I had no idea, nor would I have considered this was possible. Thank you.
It looks like OSX doesn't have a posix_fallocate(): https://github.com/osicat/osicat/issues/10
https://github.com/osicat/osicat/issues/10 Here is a possible workaround to use until a fix arrives in a future quicklisp update 1. cd ~/quicklisp/local-projects 2. git clone https://github.com/osicat/osicat.git 3. apply this diff http://pastebin.com/raw/R9nuF3Ls 4. (ql:quickload "linedit") 
&gt; Put all of your apps in one image and create a 40 MB standalone app..... BuildApp can be used to easily accomplish this. Xach gives an example here http://xach.com/lisp/buildapp/. Search for the example on "--dispatched-entry". 
Sounds like a post from someone who doesn't know what they're talking about but had to say it anyway. Is it an oxymoron to say 'brainless troll'?
I'm not sure what slime-load-system does (it may just do asdf:load-system instead of ql:quickload) and am also not sure where you are doing the central-registry modification. Putting a symlink to "/home/user/workspace/foo" in ~/quicklisp/local-projects/ will make it where you don't have to worry about modifying asdf:*central-registry* and will possibly help fix your problem. If you want to modify the central registry still instead then use pushnew not push and see what happens, shouldn't change anything but is better practice. My guess is cl-ppcre isn't installed by quicklisp and slime-load-system uses asdf:load-system not ql:quickload. Edit: Also, i'm not sure because I haven't done it before but I imagine you might need to put :depends-on ("cl-ppcre") in the top level in addition to (or instead of) the file level so that asdf knows it needs to load it. I haven't used file level depends before.
You defsystem is file a.lisp depends on a file or module cl-ppcre. What you intend to expression is that the file a.lisp depends on a system cl-ppcre. However that is not possible with ASDF, the system (in this case foo) has to depend on systems. Files only on files and modules. (asdf:defsystem foo :name "foo" :serial t :depends-on ("cl-ppcre") :components ((:file "a") (:file "b" :depends-on ("a")))) This is all explained in the [ASDF manual](https://common-lisp.net/project/asdf/asdf.html) (Nitpick, if you are already saying to load files in order (serial :t) there is no need to specify dependencies in the files. b.lisp already depends on a.lisp. Also you can use (in-package #:asdf-user) to define your system in.
Oh! Thanks, that helps a lot :)
Well, the thing is, when I edit `b.lisp` I want to be able to easily load the whole system so I can play around in the REPL. By running that command, Emacs uses the .asd configuration file to load everything I need. Not sure if it does (asdf:load-system) or (ql:quickload) though. Adding `:depends-on` fixed my issues :) Also, thanks! I'll use symlinks instead.
Again thanks for doing these videos. The music is still extremely distracting.
I appreciate the idea, and the wish to promote your stuff, which I might actually like on it's own, but for this purpose find massively distracting. I know it is more work, but you could consider dubbing it, which would also give you better volume control.
Nice tunes. Is [this](http://kruhft.bandcamp.com/) you?
Take a look at [phaser.js](http://phaser.io/) with ClojureScript. We developed a mobile app for indoor navigation using it, and it works pretty well. Phaser uses GL canvas when possible, so it actually runs very smoothly on mobile.
Yes, it is.
True enough. I'm just playing through speakers and I can't say I've really had a chance to watch the shows to check the volume yet. I'll look into seeing if I can get the levels better in the future.
No. A macro is just an abbreviation. If your language is not Turing complete to begin with, any abbreviations thereof won't be either. To answer your question about COND, yes, you can make that with LAMBDA, at least in the lambda-calculus sense. 
How would one go about making cond with a lambda? Using some sort of combinator? Do you have any examples of that?
Cond can be expressed using ifs, if can be expressed using lambdas, ergo cond can be made with lambdas.
I liked the music this time - it seemed to me to fit with the project. If I may make one small suggestion though - don't eat on stream. Well, eating is fine, it's the noises that get massive pickup from your microphone. But that's just me and my probably weird hangups. That said, the content, specifically building a lisp image from basically nothing, is one hell of an idea. Don't let me or anyone else discourage you.
Thanks for the feedback :)
INFO y SRC, https://github.com/dvnmk/startx-buffer
Holy crap, this is amazing. Do you work for a company that makes flip displays? :)
I'd have a careful think about the file system... might be an opportunity to come up with something more powerful than a regular hierarchical file system. 
I'd recommend you start out from this repo instead, https://github.com/csziacobus/movitz &gt; What else might deserve a high place on the list of things to do? - A graphics API - Getting Lice to work again Also checkout [Mezzano](https://github.com/froggey/Mezzano)
Prettier HTML Exported version: http://busfactor1.ca/bin/eturia/lib/sigil/the-order-of-symbols.txt.html
Do I understand correctly that you plan to maintain Movitz? :3
Thank you for some food for thought. I'll certainly take this into consideration. I can't agree, that ECL is a relic, but I respect your opinion. Spitting out C is a method for native compilation. Note also, that ECL shares the runtime with C/C++, so there is no need for DFFI for this languages ‚Äì you can directly call the functions and make these functions call Lisp code. DFFI is deprecated and ECL opts to using libffi (which is built-in) ‚Äì https://sourceware.org/libffi/. Possibility to recompile and test C functions in the REPL only adds as a big plus. The other benefit of ECL is it's portability. It bootstraps from gcc (or other C99 compatible compiler) and works on various platforms (*BSD, Linux, Windows, Android, OSX, there are known builds for iOS, NaCL, pNaCL), as a dynamic library ‚Äì you share runtime. Small executables with a very rich programming environment. I agree, that ECL would benefit from optimizations though. I'd love to put more effort into improving the compiler. One possibility would be using GNU Lightning, there are probably other projects which could leverege this effort. Once again thank you for your opinion (even if it is expressed very aggresively with words "relic", "pathetic" or "anachronizm"). I'll certainly keep these points in mind.
I didn't know about libffi (may I suggest you update your documentation? It still refers to the old DFFI there and ppl will get the wrong impression as to current capabilities.) Yes I worded things a bit strongly but sometimes this is what's needed when you want others to pay attention. It's a fault of mine. Kudos for taking my points in good faith. I agree that the C bootstrapping part of ECL can be extremely beneficial in some scenarios but I also want to point out that these scenarios are slim and getting slimmer by the day. Luajit really has killed a lot of the traditional compile-to-C solutions here and it's not anywhere near as portable as C99. I speculate that improving the bytecode interpreter with JIT compilation would do wonders for ECL adoption. There are a lot of people who do not enjoy programming in Lua that would pretty much instantly jump ship to any Lisp that managed to address some of the same usecases. 
Oh that's much nicer :) Thanks! Do people normally use :serial t, or :depends-on? Is there any preference on that?
Thanks for sharing it! I hope you liked it.
I always use :serial. I guess if you're using :depends-on ASDF can be smarter when reloading a system and only recompile the files that depend on changed files, but I haven't ever needed that and determining what depends on what is kinda annoying.
Oh sorry about that! I did a search for lambdanative before I posted, but nothing came up! I'll remove the post
There's also [Common Lisp](https://wukix.com/mocl) for Android and iOS.
Thank you so much. Very interesting!
I am going to give it a shot! I am just a busy undergrad these days but I am committing a few hours every week to read through the source and trying to grok what Frode Fjeld was doing.
I was thinking of doing something with a graph such that a prolog could be used to search files and their content. 
In doing something like this, would the disk just become a backup medium for memory? Or could you go so far as to address the harddrive as if it were your memory and treat RAM as a cache for the disk?
Sounds really cool :-) Good luck!
Do you know of anyone who has published anything about work done with movitz? I have booted in in bochs but haven't made any real progress because of a lack of time. 
I like both. I've been using Lua for a while now, and to me Lua is fun and easy work with on the C side and on the Lua side. Its got great instrospection features, and its Lispy features like closures and coroutines are natural to work with. My bias is based on the fact that I always like to embed languages, and Lua was written specifically so it could be included as a few source files in a C program. The only satisfactory Lisp that has that attitude is s7 Scheme, which I also thoroughly enjoy using. Every other Lisp - Chicken, Gambit, Gauche, Racket and so on, they come with a tonne of baggage and strongly resist being embedded into a larger C program. They have an "arrogance" about them. ECL is embeddable, but really only as a dynamic library. Also, when error conditions occur, it likes to "take over" with its debug mode. There may have been an incantation of its C API that would allow the C program to control the debugging, but it was never clear. I used it initially years ago, but when I found s7, I switched completely to that. S7 has the good parts of Scheme with the good parts of Common Lisp, and its made to be embedded. Long story short, I agree with everything you have said, except for your distaste for Lua, and that is only because I've grown to like it through regular use. 
Part of the disk, the size of RAM, could be backup, and would be read into memory on start-up, and written onto hard disk periodically, and on shutdown. The rest of the disk could be accessible as if it were RAM, with higher addresses than RAM. So, instead of a file read, you'd just read the object the data's stored in as if it were sitting in RAM, though in the background the hard disk driver would execute. If you want an object (e.g. a JPEG image, or a PDF-document, or some hypertext - why are these all just files?) which is on a server in Japan, its address would be higher up, and you'd still access it as if it were in memory, but behind the scenes your system would create a socket and then start reading from it and writing to it using the HTTP. 
I disagree completely. Having multiple backends is extremely useful. However, Common Lisp being a huge language, it's very useful to be able to factour out the commonalities of each compiler. Merging ECL into a kind of backend for SICL, or using Cleavir's AST and environment representation in ECL, would be great.
Codex is a great project I consider to use to document my other projects (ie full CL). It's not a good fit for ECL though ‚Äì I'm rewriting the documentation in texi, so it will be possible to produce the info file *as well* as html and/or pdf. Also ECL's huge part of the documentation is C/C++.
I think the readme does a good job at that, it has an image browser with McCLIM. &gt; For example, where are the binary-types and ia-x86 libraries? You get them from quicklisp, the 'vanilla' version of movitz has the problem that binary-types package uses a package-nickname, bt, that is now used by bourdeaux-threads. &gt; Similarly, how can Mezzano help me out? I admit to not knowing much about it but last I read it did not run on bare metal It is another OS, which is being currently developed by the Original Author (you can drop to #mezzano@freenode for example). It doesnot run on bare metal due to driver issues. 
Honestly these days the 'desktop gui' problem is not really a problem anymore. CommonQT plus QTools plus qt-libs has basically solved the problem. It's really nice having a well maintained foss option over being forced to buy LispWorks or something for CAPI.
Trivia: The only 'recent' program I've seen use symbol-plist is djula.
&gt; the author is obsessed with using reader macros I find it a wise decision to make the bottom layer simple and fast; on top of that, you can abstract things away, see efforts like "qtools". Wrapping the whole thing in CLOS would be a waste of resources and slow, not worth it.
That's nonsense. Since when does GUI code need to be fast? It's always, always the user that's the bottleneck. "The real problem is that programmers have spent far too much time worrying about efficiency in the wrong places and at the wrong times; premature optimization is the root of all evil (or at least most of it) in programming." Donald Knuth The author of this library looks like he just learned about reader macros and now thinks they are the solution to everything.
There has been an effort going the full CLOS way: it didn't take off. Even CommonQt with its relative low-level approach has some problems with responsiveness on some slower CL implementations: but responsiveness is crucial for a GUI! The original author of CommonQt is an experienced hacker, he made a wise decision IMO. So, you're right, but only in theory.
I'm not the author but the project is super new and the makefile only uses sbcl so I'd imagine it has only been tested on linux + sbcl.
thanks
So it's not a lisp environment targeting the shell?
If a CLOS GUI application isn't responsive, there is usually some other reason.
sbcl, cmucl, and ecl are the only 3 major open-source implementations on which it is possible to implement a traditional posix shell. CCL spawns a thread at startup, so forking is out of the question, and clisp does weird things with SIGCHLD
I would use external-program (https://github.com/sellout/external-program) or UIOP as a shell interface to not duplicate the effort. Additional plus is that it would potentially work on Windows I think that posix shell shouldn't be a hard requirement for the project. You forgot about the CMUCL. ABCL also can run external program afaik.
Found a reference to "CLISP" (conversational Lisp) in the back of a giant, blue Interlisp book (which is full of all kinds of other crazy). I think is the original paper
Warmup of various CLOS caches could be a concern.
Thanks for the feedback! About auto-completion et al, I have to look at it. I think I'll rewrite how it's currently handled. Right now, it's just using readline. So it gives several features out of the box (e.g. vi keys if you configure readline as such), but also limits how far you can go. I need to sit on it though. An `export` command is definitely planned! The current way to handle environment variables is clunky at best. For the bugs you've reported: - The `mkdir` not creating in the right directory bug is fixed https://gitlab.com/ralt/avesh/commit/c70fac1278ad51657b962e698bf8f232bf3bd4b3 - The other bugs, I wasn't aware of them. Opening an issue would be nice! (Although I already have ideas how to fix them.) Unfortunately, I don't have a lot of time to work on it these days because life stuff, so it's kind of stagnant for now...
I am particularly biased against the whole DWIM (*Do What I Mean*) thing, perhaps because my first exposure to the idea was via [the anecdote in the Jargon File](http://www.catb.org/jargon/html/D/DWIM.html): &gt; In one notorious incident, Warren added a DWIM feature to the command interpreter used at Xerox PARC. One day another hacker there typed delete *$ to free up some disk space. (The editor there named backup files by appending $ to the original file name, so he was trying to delete any backup files left over from old editing sessions.) It happened that there weren't any editor backup files, so DWIM helpfully reported *$ not found, assuming you meant 'delete *'. It then started to delete all the files on the disk! The hacker managed to stop it with a Vulcan nerve pinch after only a half dozen or so files were lost. &gt; &gt; The disgruntled victim later said he had been sorely tempted to go to Warren's office, tie Warren down in his chair in front of his workstation, and then type delete *$ twice. 
I know of two Interlisp books, though since I don't have access to one of them, it might in fact be the same as the other, only under a different name. Could you specify what the book you are looking at is? I see from pictures of Stephen H. Kaisler's book *Interlisp: the language and its usage* that it appears to be blue, but I don't know what it contains. I have Warren Teitelman's *Interlisp Reference Manual* in softcopy, and it contains the CLISP paper in the back, but I have no idea what colour it was in hardcopy.
With regards to `mkdir`, I cloned and installed today. Is there something else I need to do? Also, I had to add a ".git" to the url when cloning. Thanks, I've made issues for them. I look forward to playing with it more.
I really like code and command completion to be as forgiving as possible. When I actually enter a command that should be precise and unambiguous.
Warren Teitelman was going to the store. His wife said, "Buy a gallon of milk, and if there are eggs, buy a dozen." He got to the store, and there were eggs, so he came home with milk and a box of donuts.
&gt; but maybe it would work great with a OpenGL backend -- especially for targets like Android/iOS etc. Perhaps somewhat inspired by Kivy or something similar?
Shouldn't he have bought 12 gallons of milk?
Milk doesn't usually come in dozens, but donuts do. It's probably what she meant.
Let's state it: the *real* problem behind is not CLOS, but the inadequacy of trying to push the whole CL craft on all of the modern hardware/software combinations. If you already have a perfect hardware/software combination for Common Lisp (as on the ancient Lisp Machine Dream Devices), these problems don't even arise in your most remote dreams...
I hadn't considered inferior-shell. It might be interesting to use it!
I haven't heard any positive stories about DWIM before, but would love to. Would you mind sharing some more of your experiences?
Thanks, that certainly must have been a great first experience. 
Unfortunate name. First of all, it would sound spoken almost like Erlang, quite a different language, and second of all "Ur-" is generally used to mean ancient (Urwelt, etc.), and this isn't.
What is the advantage of this over ClojureScript?
From the looks of it seems a close representation of JavaScript using S-expressions since there is no standard lib. Clojurescript on the other hand is a full blown port of the language and runtime. 
Spot on. One small difference between JavaScript and Urlang is that Urlang signals an error when an unbound identifier is found. If DrRacket is used, you can jump right to the offending identifier. Also Urlang macros are written with standard Racket macro tools such as syntax-parse (or syntax-case).
I've not used it, but I have used ClojureScript and Parenscript. This project claims to aim for "straightforward translation to JavaScript", which has been something I've occasionally missed in cljs. Parenscript is great in that, when writing it, you can usually tell exactly what the JS output will be. It's not so great in that you *have* to keep this in mind as the semantics of what you're doing will not always be identical to the Common Lisp it's drawing from. ClojureScript is kind of the opposite. It aims to be as semantically close to Clojure as it can (with the odd caveat), but you're kind of lost if you ever need to dive in to the JS after it's been through Closure. I do find myself having to do this a lot less with ClojureScript than with Parenscript, but it happens. Either way, I can see why people would want a nice lisp with a semantically understandable mapping to JavaScript. 
Ooh, it works with dr racket....interesting
What do you mean? Macros live in a package....
Yes, they are in a package. But if they expand to be only code not in the package, then the package is no longer necessary after macro-expansion. Using iterate as an example, so long as you don't have something like (defun foo (x) (eval `(iterate (repeat 100) ,x))) then the only time the iterate package would be needed is when compiling. This is because something like (defun bar (x) (iterate (for i from 1 to x) (collect i))) will expand to something like (defun bar (x) (LET* ((I 0) (#:LIMIT313 NIL) (#:RESULT312 NIL) (#:END-POINTER314 NIL) (#:TEMP315 NIL)) (DECLARE (TYPE LIST #:END-POINTER314) (TYPE LIST #:RESULT312) (TYPE NUMBER I)) (BLOCK NIL (TAGBODY (PROGN (SETQ #:LIMIT313 X) (SETQ I 0)) LOOP-TOP-NIL (PROGN (SETQ I (+ I 1)) (IF (&gt; I #:LIMIT313) (GO LOOP-END-NIL)) (PROGN (SETQ #:TEMP315 (LIST I)) (SETQ #:END-POINTER314 (IF #:RESULT312 (SETF (CDR #:END-POINTER314) #:TEMP315) (SETQ #:RESULT312 #:TEMP315))) #:RESULT312)) (PROGN) (GO LOOP-TOP-NIL) LOOP-END-NIL (PROGN)) #:RESULT312))) which contains only functions from the common lisp standard.
I think it is always nice to have alternatives and perspectives. Also, please do not mind if some people are rough and uncouth, here on r/lisp or anywhere. They usually mean well. Just do what you feel is good for you to learn, and I am sure many will find it inspiring.
Fixed, thank you!
Thanks for your feedback drewc! Fixed the readme typos. I'm afraid I didn't quite understand your exercise though: Do you mean that there are other libraries and combinations of built-in functions that can be used to do these? In that case, you're right obviously. That has to be true of any library developed for CL nowadays, and also why i'm asking for ideas to make this more useful. But you mention "improvements" and me "following up" on your ideas, so maybe you mean something else? Like me using cl:loop and ppcre:regex-replace to implement replace-all? 
priyadarshan_ you warmed my heart :) Thanks!
Unfortunately, lots of the built in functions are inelegant, particularly with strings. It's not unreasonable for someone with a sense for elegance to want to build a more lucid system around them. 
I like it, usual names and if it saves me a few characters to type, why not? Would like to see more string operations there as well. As for build-in stuff - if it is not a one-to-one match but even a convenient wrappers are ok. In one of responses below like *what's wrong with something and something* - no it is nothing wrong except it is a code to write (even a few lines of code) and the code in this library has convenient naming. And if someone had already written the code to do exactly the stuff I need - why not to use it? From suggestions I would like to see how good is the test coverage and a list of supported/tested compilers (SBCL? LW?) to understand if I can use it in my projects. 
Awesome, thanks for your feedback furych. I tested only on sbcl and ecl, will test in other implementations soon. Test coverage is 100%, I think it makes sense in a library of utils like this. However, keep in mind this is absolute version 0, less than a day old, i'll certainly find dumb stuff in the next few weeks. Please let me know of anything you find if you use it!
Not got anything technical to add but congrats on your first library and thanks for making it open!
&gt; I'm afraid I didn't quite understand your exercise though: That was not an exercise, it was questions. &gt; Do you mean that there are other libraries and combinations of built-in functions that can be used to do these? Yes, and they are all built-in to Common Lisp itself in the CL package with the exception of PARSE-NUMBER. I have used both PARSE-NUMBER and READ to parse numbers. You have basically re-implemented a lot of what is already in CL. &gt; That has to be true of any library developed for CL nowadays, and also why i'm asking for ideas to make this more useful. That is 100% false. Most lispers I know and work with do not re-implement stuff that is built in to make it less useful and slower. &gt; But you mention "improvements" No, you did. &gt; and me "following up" on your ideas, so maybe you mean something else? I mean that everything implemented in your library is implemented in Common Lisp, so why are you wasting time implementing it when you do not know that it is there under a different name? &gt; Like me using cl:loop and ppcre:regex-replace to implement replace-all? You do? Why? Notice that I asked 13 questions, and each one is asking "What is wrong with the existing way to do this that is built in, documented, standardized and in ANSI Common Lisp?". Why do you refuse to answer? 
I like it. Will comment on code later.
That's a bit toxic....
&gt; I didn't answer because i wasn't sure why you listed all the ways you would perform these operations without using this lib. Because they are built in or common and do exactly what you want. &gt; I still don't quite get it. Ok, let me try to explain. &gt; with loop you have to implement "insert" yourself, which is what I did and the point of any util library I think. If you happen to do the exact thing that your "insert" function does all the time, then for sure, make it part of your utility library. But having an entire library just because of INSERT is not really what I think should be done. &gt; I do get that you're saying this isn't useful, which is valid, but those questions are still a bit weird. That is not at all what I am saying. I am saying that 90% of them are so useful that that are either in CL itself or, say, ALEXANDRIA (which has a lot of what your string library has, only usually for sequences, not just strings). I don't mean to come off as negative, so I apologize if that is that case. I think that what I am trying to get at is: What is wrong with existing versions that are almost identical? 
Can you see my hand, raised up? Just because you hate something does not mean that others do. I do a lot of text processing. I also do function and macro definition. But I do not mind the long-form when defining, because I read more code than I write. I really appreciate well-written forms, even if they are longer than Perl or Javascript.
&gt; Other examples include cl-strings' join and chars, both of which can be trivially replaced with the concatenate function: `concatenate` can't add a separator between the elements like this version of `join` can (notice how you manually appended the `, ` to all but the last string). This is a useful thing that people want, hence the existence of things like this library and [join-sequence](https://github.com/shinnya/join-sequence).
These look handy. Have you considered also submitting them to [quickutil](http://quickutil.org/)? They seem like a good fit.
I'm sorry if I have offended you (or the OP), but I was only trying to give (what I think is) a constructive feedbacks. I'm fine with this library being a thinned wrapper over the built-in functionalities, but the point I'm trying to get across was that the library would be much more useful had it focused more on adding features that are missing from Common Lisp (or other string libraries). Not to mention that there are many aspects that can still be improved and simplified with regard to how the library implements many of its functions as well. Like how **toggle-case** reads one character from a string, converts its case, and writes it out to a stream one character at a time instead of using the built-in **string-upcase** and **string-downcase** to convert the entire string at once.
I think endswith and startwith are the direct port from python. and i like them, especially for an easy alternative to regexp. they are more readable wrapper over string-equal. If the development of alexandria is active, they should be included.
surprised to know that quickutil is still alive.
Sure, but it's still no reason not to follow best practice, right?
Thanks for the tip stevelosh, I will look into it. I've come across quickutil, but never used it yet.
&gt; concatenate can't add a separator between the elements like this version of join can (notice how you manually appended the , to all but the last string). What is wrong with FORMAT? ie: CL-USER&gt; (let ((list '(this is a list!))) (format nil "~{~a~^, ~}" list)) =&gt; "THIS, IS, A, LIST!" Personally, when I do such jazz, I prefer to keep it as a list for as long as possible, because I am usually not simply formatting a string. ie: CL-USER&gt; (apply #'concatenate 'string (loop :with list = '(this is a list!) :with sep = ", " :for (a . d) on list :nconc (list (string a) (when d sep)))) =&gt; "THIS, IS, A, LIST!" What does make them interesting is they both have syntax that is not really sexps. If I wanted that, there is MAP. ie: CL-USER&gt; (with-output-to-string (s) (map nil (lambda (l) (princ (first l) s) (when (rest l) (princ ", " s))) '(this is a list))) =&gt; "THIS, IS, A, LIST" But, all in all, there are many many different ways to that particular thing. When I want the trivial version there is FORMAT. Why are the existing versions (there are many more than what I typed) so fsck'd up that you prefer those library versions?
utility libs never die!
Thank you.
As someone who primarily lives in Common Lisp, I was a bit disappointed by the scheme skew of the book (it covers both, but the author is clearly from the scheme world). However, it really is a good bottom-up view of the lisp world, where most other books are very much a top-down view. A different angle for looking at anything you are familiar with only helps in understanding it.
As far as I can tell, parse-number has no active maintainer: sharplispers maintain the official repository but I doubt they're looking for patches. It's not a simple fix. The way parse-numbers does it now can't be made to work. Either it has to use bignums (easy to implement, slow) or implement a much more complicated algorithm.
It is http://shenlanguage.org/
Almost as elegant and powerful as Prolog!
Sadly the current actively developing version (Shen Professional) is closed source and needs monthly subscription of ¬£50. http://www.lambdassociates.org/licensing.htm
I've been following the Shen mailing list a bit and from what I've heard, Shen professional (SP) comes with a better compiler that does dead code elimination and optimization, a concurrency library, and some other smaller features like a pretty printer etc. That all sounds great but it still doesn't fix the lack of good tooling and a robust standard library for getting things done, which is what most programmers need to do. I've thought about hacking on open source Shen to make some improvements like actually useful compiler error messages and better integration with emacs (shen-mode by eschulte leaves much to be desired) but I also have plenty of other things to spend my time on so I'm not sure how worth it would be to do so. 
I think it sounds pretty cool bit I'm spoiled by decent language tooling and didn't play with it much. Didn't know about the shen professional thing, sounds like the project may need a fork by someone less money centric.
Actually, it has a prolog engine as standard iirc.
If you use symlinks it is more difficult to move your project between computers. With this code one can achieve what OP wanted in a cleaner way. No messing with ASDF directly. (pushnew (truename "/my/projects") ql:*local-project-directories* ) (ql:register-local-projects) 
I hope the SP authors consider fixing / rewriting the emacs mode rather than write a new IDE (like has been mentioned on the mailing list). 
The current shen-mode code is pretty bad. A hack job on top of a copy-paste. It works to just experiment with, but it's nowhere near the usability of other lisps with emacs. A complete rewrite would be necessary 
**I have not looked at this book**, but I had the author as a prof in school. He taught development of psychological simulations and models using neural networks in lisp. The book is called Computational Developmental Psychology by Thomas R. Shultz.
There is MetaML. In general, there is a trade-off between expressiveness and the inability to produce expressions which are not valid ML programs.
Rust and OCaml both provide ways to plug-in your own syntactic sugar. I don't use either language but here are some starting points: [Rust macros](https://doc.rust-lang.org/book/macros.html) [OCaml camlp5](http://camlp5.gforge.inria.fr/doc/htmlc/) If you can't find existing tools for SML, you might nonetheless find MLton or Moscow ML sufficiently hackable that you can patch their elaboration phases as needed to get your syntactic extensions in. That would potentially be difficult to maintain but may still be worth considering. Another option I don't use but which might interest you is [Typed Racket](http://docs.racket-lang.org/ts-guide/index.html).
Basically I see a few possible solutions here. Native wasm is possible and Douglas Crosher works on it (but he encounters some problems with merging of his work): http://article.gmane.org/gmane.lisp.steel-bank.devel/19495 Additionally you may use JSCL (not full yet CL in JS): http://davazp.net/jscl/jscl.html Furthermore ECL has experimental NaCL and pNaCL support (chromium only afaik).
I could see ClojureScript getting a wasm compile target fairly quickly.
If anyone wishes to participate in the hackathon remotely you can http://missoulacivichackathon.org/#!/participate
you might like code quotations in F#: https://msdn.microsoft.com/en-us/library/dd233212.aspx
Hi, i made this in my spare time because i'm learning a new language (croatian) and i was struggling with new vocabulary. To use it, beside cloning it and using quicklisp, you have to give a kind of csv file with a list of words and their translations to the program and he makes a quizz out of it. (or you use mine which is filled with french;croatian words) You can use !quit to exit any moment, !help to see all the available command, !hint to get one two or three hints, and !pass when you give up on a word. Feedback is much appreciated on the code itself and on the program. Thanks 
That's something i should have been careful with. Thank you very much!
To that end, if you are only putting one thing onto the list, then you may prefer writing this: (setf *lang1-list* (append (list (nth 0 words-line)) *lang1-list*)) as (push (nth 0 words-line) *lang1-list*) ...Patrick
He asked for feedback. One better learns idiomatic Lisp code. I've seen a lot really bad code from people who never asked for feedback or had never had the chance to get useful feedback. Data structures like lists are not to be seen in isolation. They are coming with algorithms and implementations of those. Learning to program means to choose the correct combination of data structures and algorithms. Lisp has simple and clear functions/macros to create lists from items: (loop for i = (read ...) while i collect i) Instead of: (defun foo (list) (let ((x (read ...))) (if x (foo (append list (list x))) list))) Lisp also has higher-order functions like MAP which make the corresponding primitive recursion unnecessary. Similar higher-order functions for reading from files are useful building blocks. Common Lisp is not Scheme. The corresponding programming styles are different.
Absolutely, it's good advice and good to take on board. I'm glad to hear it's going so well
&gt;Why is (instruction) a function? For no good reason i fear. &gt;I suppose it's ok for beginners to use lists for everything, but there are a few places that are inefficient due to inherent slowness of linked list. In (nth (random (length key-list)) key-list)) both nth and length are slow (and length is always the same, so there's no reason not to cache it). So array instead of list? Thanks for the feedback, much appreciated :)
Thank you.
reddit auto-completed the title of the URL. I, for one, am currently using `paredit` and I find some of `parinfer`'s *improvements* rather inviting, including easier wrapping of a long expression into another expression. I just can't memorize all of `paredit`'s features, so the shiny automatisms are tempting to me. Thanks for your demos though. I'll read them. Quite off-topic: I haven't heard of Lispy before - it looks like some "Paredit without the features and with non-Emacsy keybindings"?
Yes, parinfer definitely has some cool ideas; I just don't like the method it uses to achieve them. Lispy is a superset of paredit (according to the author, and I haven't found any missing features myself). It does use non-emacsy keybindings by treating the places before and delimiters as "special". Since you wouldn't want to type letters (there are some exceptions like `'`, `'#`, etc.) before or after a paren, the letters are used for commands in those situations. For example, `d` will jump to the matching ("different") paren, and `&gt;` will slurp (it can take a count, e.g. `3&gt;`). I've started using it exclusively instead of smartparens or paredit, but it may not be for everyone due to its different way of handling keybindings. It has a ton of features like paredit, but I think the lispy video demo does a good job explaining most of them, and they usually have mnemonics making them pretty easy to memorize. Lispy will also probably have a `parinfer` "key theme" in the future (I hope to add one), so it could basically be used for parinfer's features with the keybindings basically the same. 
I've found that I don't have any problems getting keybindings confused (I use evil exclusively). One of the nice things about lispy is its key themes, which would allow addition of a `vim` key theme where `d` is delete and `y` is copy and so forth. Hypothetically, all of lispy's features except for the parinfer ones could be ignored, and someone could still use it with paredit. Right now I'm working on a package to make lispy and evil work better together. Lispy aside, hopefully smartparens and paredit will take a few pointers from parinfer. If you want the equivalent of the "change indentation to change scope" feature by itself, you can use the `adjust-parens` emacs package. As an example of what it does: (defun foo ()) | ;; press TAB; becomes (defun foo () |) 
&gt; Does adjust-parens work with paredit? There shouldn't be any conflict. `adjust-parens` has two commands; normally you bind the indent one to `TAB` and the dedent one to `&lt;backtab&gt;` (S-TAB). If you're not using aggressive-indent and want to keep `TAB` the same, you'll probably want to use a different key for the indent command.
Sounds great. I'll play with it these days. :-) Thank you for your advices. 
I'm impressed! I really like the way Parinfer works and I'm seriously considering bolting it into my toolbox. Obviously it isn't perfect, and I've already managed to trip it up a couple of times after a little testing, but I can't help thinking of two reasons why it might not be possible for Parinfer (or any other smart editor) to always do the "right thing". 1: (unless anyone knows better) I have gut feeling that a perfect set of rules for "LISP pretty printing" and/or "proper LISP formatting" is not something that can be unambiguously or rigorously defined. 2: Moreover, LISP code, like any other program code, serves types of master: the machine (which demands perfect syntax but doesn't give hardly a damn about line breaks and indentation) and the human beings who read and write it, for whom the typographical shape of the code is hugely important - intelligently laid out code can reveal it's purpose, or the nature of its algorithm, to a quick glance. Thus there are certain conventions regarding the formatting of LISP; but here's the thing: there are many coding situations in LISP where something very powerful or obscure is happening that might not be obvious or easy to understand. And so (I don't know about you) I might choose to format such code in a distinctive manner and style, typically involving shorter lines, carefully placed comments, generous use of white space, and so on. Since there is no perfect rule set for pretty-printing, and since we should in any case be able to format code how we like to maximise its readability: a tool like Parinfer cannot "do it all for us". What a tool like this can do is to behave in a predictable fashion as it applies simple and well-defined rules to help us keep our parentheses balanced and assist with indentation and formatting. And one would also wish that it might achieve this magic without arguing with us when we choose to format code in our own special way. I have to say that Parinfer seems to achieve all this pretty damn well, and I'm very impressed with it. 
Still looks maintained https://github.com/marijnh/Postmodern/commits/master
Hey, awesome. How long has this implementation been around? EDIT: I guess I can answer that for myself: 2011-02-15 is the first commit, and 2014-12-06 is the most recent.
Yes -&gt; https://github.com/mmaul/clml
I like these settings for occasional use of evil: (use-package evil :ensure t :config (evil-mode t) (defalias 'evil-insert-state 'evil-emacs-state) ; http://stackoverflow.com/a/27794225/2932728 (setq evil-default-state 'emacs) :bind ;; https://bitbucket.org/bastibe/.emacs.d/src/12d08ec90a6445787b028fa8640844a67182e96d/init.el?at=master&amp;fileviewer=file-view-default (:map evil-emacs-state-map ([escape] . evil-normal-state))) That way, the insert mode behaves like regular emacs, but you can get into normal mode with the escape key.
Just wait until you understand macros. It's like changing the compiler. And you can do it at runtime. Lisp also reduces run, test, debug, compile loop to almost nothing. Unfortunately It's so powerful it's easier to implement than explain to others. This makes for a lot of 'lone gunman' projects. And I'm guilty of it too. It's called the 'lisp curse'.
What you told here applies to Python also. Lisp is (of course) more powerful than Python, but you can master e.g. Python in a few months, whereas you'll need a decade to really master all of Lisp...
You can still enjoy functional programming in Bash or C ! My shell scripts almost look like lisp :)
You can also 'enjoy' object-oriented programming in machine code but why would you want to do so in a language that provides no support for the paradigm?
Why this one in particular ?
It's basically comparing a high level language with a low level one - most the perks described are in most high level languages. Just happens he chose lisp for his first
If you follow the book chronologically the stuff up to that point seems trivial: Tree data structures, functions as data, mutually recursive functions, maybe even the symbolic differentiation could be handled with OOP and some simple parsing with `yacc`, but this example and it's corresponding `amb` function really captures me and starts to show how powerfully simple functional programming can be. Most other languages use built in functions or massive programs like yacc to solve this particular problem, and you never really get to see all the details but in the following section 4.3.3 you get the rest of the implementation of the `amb` function. that being said scheme is still using things like define and if and cond etc. but even those can be defined by lambda the ultimate. And even more importantly the solution is incredibly readible, even by people who have never even seen lisp before. However [there is a more readable implementation of `amb` available](http://matt.might.net/articles/programming-with-continuations--exceptions-backtracking-search-threads-generators-coroutines/).
Yes, I should use Bash and C for my work. But I'm sure the style will be different after I realize FP.
because sometimes (uiop:run-program XXX) is longer than XXX :)
Thanks a lot for that detailed explanation. I was recently reinvestigating pure simple untyped LC (lambda, Y, CPS) with the goal of reaching non deterministic and backtracking. So your answer rings a bell.
Well, combinatorics remind me of point free haskell, some people hate it, I have a thing for this (much like forth) but I've never used that style really, so I think lambdas can be clearers. my 0.2cents
Don't worry, I climbed the ladder and walked it all already. I also read the ioccc submission (and posted it on proggit because too cute)
Oh no, I only meant I went through the other files in the repository.
A tutorial like this is great and I'll probably work through this as I've been interested in Erlang but really like Lisp-like languages. But what is the realistic way to learn LFE to a productive level? Is it really required to learn normal Erlang first and then translate things to sexps, or can one actually learn LFE as an independent language?
&gt; Simplicity Define Simplicity. Do you want a simple Lisp, a simple implementation, a simple platform, or a lisp made for simple people? &gt; Environment (debugger, profiler) Depending on what version of simplicity you want, there are many responses to this. &gt; Performance Depending on what version of simplicity you want, there are many responses to this. &gt; Ease of interfacing with C (not C++) Depending on what version of simplicity you want, there are many responses to this. Why do you not want an easy C++ interface as well? I would suggest Common Lisp, as that has been my workforce for some 12 years. But, the implementations are usually not simple and interfacing with C++ can be easy, so it may not be what you are after. 
All lisps have small intrinsic syntax. However Common Lisp has no joke like 1000 functions and macros defined in the standard, not to mention the whole domain specific language of `loop`. It has everything from the lowest level bit-twiddling to high level meta programming. I'm not sure why you "have" to write your own implementation since there are already half a dozen under active development with varying trade-offs. Honestly I can't think of any existing lisp which you have much hope of fully implementing on your own other than purposefully feature poor ones whose purpose is to be re-implemented. But if you are new to lisps in general I think it is a bit early to be thinking of implementing one. Pick one which has a decent sized community behind it; like common lisp, scheme, racket, or clojure; and focus on learning the language. Especially coming from C++ you need to explore just how different lisps are from pretty much every other language in popular use. Once you are familiar with lisps in general you can always create your own lisp to suite your individual needs. There are scores of such lisps out there.
I'm hoping to write a system that can analyse short functions, and offload parts of it to the gpu automatically using SPIR-V. It obviously won't be able to offload everything, but I'm hoping to use external libs, but I want to implement as little as possible. But yeah, it will take a long time :) I'm hoping to just learn for a while, do some exploration using metaprogramming, and then move to LLVM. It's a lot, but it's going to be my hobbyproject for a while yet.
If you are interested there is a project I have wanted to start. There is a common lisp library called [lparallel](http://lparallel.org/) which defines parallel versions of ansi standard functions. It piggy backs off of [bordeaux-threads](https://trac.common-lisp.net/bordeaux-threads/wiki/ApiDocumentation) so that it is portable among all common lisp implementations which support multi-threading. I have wanted a similar project which provides the same but for gpu parallelization. It would also be possible using a method similar to [ACL2](https://www.cs.utexas.edu/users/moore/acl2/) to create a "common lisp" in common lisp which can automatically transform regular cl into parallelized cl when appropriate via compiler-macros. The net result would be an implementation agnostic version of common lisp capable of automatic parallelization in a manner similar to haskell.
Exactly along the lines I'm thinking. Have you had a look at [SYCL](https://www.khronos.org/sycl)? It's that for C++, with a simple heuristic on what to offload (default everything, optimization moves some stuff, usually thread constant calculations, to CPU).
I have not. Unfortunately I have very little experience with C++ or opencl for that matter. I'm confident I can implement the cl side of things, but I lack the experience necessary to do the gpu aspect, which is why I have yet to start.
Unfortunately it seems clasp is *nix only atm, and I have only a windows box, so that's probably me out :/ Shame. In any case, you could get away with using clasp to compile specific blocks with --emit-llvm, and then transforming that into spirv. I doubt you would need to write an llvm pass if you can massage your input to clasp. Let me know if you ever start, I might contribute if i can!
Scheme is more minimal than Common Lisp, but its macro system is more complicated. Most serious implementations have a C FFI; Chicken Scheme's is supposed to be particularly simple (never personally used the FFI). Racket probably has the best IDE for anyone who's not a command-line junkie like myself.
I've liked Shen (and Qi) since I first read about them, but haven't actually used them for anything. Optional static typing is great. Types based on the sequent calculus? Not so sure... I'm sure there were tens of other programmers waiting for that feature, though. :) I think the substrate KŒª is one of the more inspiring parts; I wish I could find more open information about it. It would be cool to have an optimized low-level Lisp as a sort of VM that higher-level lisps could compile to.
Fun fact: he's also the author of ["The Bipolar Lisp Programmer."](http://www.lambdassociates.org/blog/bipolar.htm). 
In the Common Lisp dialect, there is ecl. Not quite the performance of sbcl, but decent. It does more than interfacing with C: They are happily married. You can embed it in C, call functions back and forth, compile lisp to C, and many more nice things.
Another way to do this which is a little more canonical than your use of `append` (though not as canonical as using `push`) is: (setf *lang1-list* (cons (nth 0 words-line) *lang1-list*)) or: (setf *lang1-list* (list* (nth 0 words-line) *lang1-list*)) I prefer the second of these options because it stresses that what you are building is a list. But, many folks prefer `cons` when you're only prepending a single item and would use `list*` if they needed to prepend multiple items.
Several people have given generous donations. Thank you! I updated the page to provide some info about the April fundraiser. If you only want to donate once, please wait for April, because there will be matching funds from a few large sponsors.
Please check out this: http://missoulacivichackathon.org and this: https://github.com/Blue-Sky-Skunkworks/hackathon I am now communicating with this group, as the brothers and sisters that you are to me, reaching out to share my current situation and to ask you to consider, deeply, helping me now. This hackathon, which I am running remotely via this email address, like a supercomputer AI, is about to pop *this* Easter weekend, March 26‚Äì27. And it is running on a 27 day clock cycle and I caught everyone off-guard and, to date, I have spent $8 on the domain name and it is all falling into place and, if I may say so myself, it is shaking things up here a bit already. And the talent on the ticketed list is staggering, many coming from afar. And they are coming here to work on projects of this caliber: https://github.com/Blue-Sky-Skunkworks/missoula-civic-hackathon-notes/wiki/Projects So, what I need now, from every lisp hacker out there that wants to play with us now, in real time, is to link into this channel at will@blueskystewardship.org and let us, collectively, set up the online systems, in preparation, for the arrival of all these people, coming from afar, and near, that have never met, and are coming here to work on problems experienced by this community but also experience by yours and a massive number of communities around the world. And this is an open-source event and the solutions that we can potentially discover in this bridging or many worlds, will be made available, to you personally, for your own pleasure and enjoyment and learning, but also, and this is critical here, for you to instantiate within your own community, as needed. And you can follow the life of Hackathon long after we have successfully released it into the wild so that it can grow unhindered, potentially long after our own individual short time frames of existence on this planet have ended. Now after this genesis is completed, you will see me √¢‚Ç¨≈ìrebase√¢‚Ç¨¬ù this Hackathon continually, and write the story of Hackathon in the commit messages of that beautifully constructed and programmed tree structure called a ‚Äúgit repository‚Äù. Such a beautiful new art form this ‚Äútrade‚Äù has become. To be able to write a story, in time, showing a path to followers and at the same time giving everyone else a shortcut to the front of the race and if you have ever ran a Hash House Harriers race in the jungles of Borneo like my dad did every week for years, and he won them all, except for a few of them, as those HHHs are tricky and they make 'em that way on purpose over there, with swamps and such, so I give this run up to him now and get back to work. And don't I, and most, just deeply love planting trees, and computer programming is just that. Trees within trees within trees, and this repo called Hackathon is is going to be fun here, because for William the first Missoula Civic Hackathon has already started and he is well ahead of the competition so come on boys and girls, lets link into this energy and heart and mind that is called The Missoula Civic Hackathon and bust out some code. Happy Hacking! Will https://en.wikipedia.org/wiki/Hash_House_Harriers
I'm not sure I understand what the aim is. Is there some documentation on the concurrency model or is it more a case of parallelize all the things?
Pretty cool. It's odd that the example lisp code is written in a newbie lisp style though (hanging parentheses). I've heard Forth system implementers are often not Forth users. Is it the case for simple Lisp interpreter implementers too?
Maybe written outside of a paren aware editor ? 
Okay, so if I wanted something where parallelism was a real issue, I'd wanna look to LFE or - probably more aptly - Clojure, if either of those will compile on the Parallella?
Quicklisp is "only" a quite sophisticated wrapper around ASDF, so there is no "either ... or". However, with Quicklisp being a *relatively new* thing in our ancient Lisp world, ASDF is still considered to be the widely accepted *standard‚Ñ¢*. I guess the main difference is that a "pure" ASDF loads local packages a bit faster than Quicklisp; but I haven't benchmarked that yet.
ASDF is used to specify the requirements and dependencies needed to build a Lisp system, much like `make` is used to specify how to build a module for C applications. This is not a trivial task. ASDF's achievement is even more remarkable because it provides a consistent interface and performs this task exactly the same regardless of the peculiarities of all the the Lisp implementations and operating systems it runs on. Try to write a library which deals consistently with pathnames across all operating systems and Lisp implementations to get a feeling for the problem. It seems like Quicklisp is all you need, but it stands on the shoulders of giants. ASDF is a basic requirement for Quicklisp. ASDF loads a single system. Quicklisp locates, downloads and installs any system so that ASDF can load them. It uses ASDF systems to determine what needs to be installed. If you create an `.asd` system for your program you can use `ql:quickload :project` to load it instead of `asdf:operate`. Quicklisp will manage the dependencies for you which you are currently doing in `loader.lisp`. While both the `loader.lisp` and `.asd` approaches achieves what you want, the `.asd` approach is 'better' in the sense that it is cleaner, portable and standard.
When 'local-projects/' becomes inconvenient you can load your project from any location with this: (pushnew (truename "/projects/app/") ql:*local-project-directories* ) (ql:register-local-projects) (ql:quickload :app) I mention some reasons why I don't like 'local-projects/' in this blog post: http://darkchestnut.com/2016/quicklisp-load-personal-projects-from-arbitrary-locations/
Curious, what do you base this upon? A statement by the developer or some other fact? Perusing https://www.quicklisp.org/beta/ doesn't bring me to that conclusion, the only mention to ASDF is that `quicklisp:uninstall` also clears its cache. Anyway, if it is like you say, it's a pity then, always good to assume less. EDIT: The FAQ (https://www.quicklisp.org/beta/faq.html) does mention ASDF a bit more. Come to think of it, you're right. It is a "core assumption" of the _implementation_, but is it a _core assumption of the interface_?
When you do `(ql:quickload :system-name)`, you're loading an ASDF system.
Why would one modify ql:*local-project-directories* instead of asdf:*central-registry* or the discovery DSL of ASDF? 
For me ASDF is most important for mapping system names to paths. First so that I can do either `(asdf:load-system :system)` or `(ql:quickload :system)` instead of `(load "/I/forget/or/typo/this/EVERY/time/load.lisp")`. Second, when you have a dependency that isn't in quicklisp it is important to be able to depend on it without putting any absolute paths in your source files and preferably without any manual per dependency configuration at all -- this means ASDF instead of loading thier `load.lisp` from yours. I also like some of the other stuff ASDF provides, but to me that's the elephant.
The asdf registry system is very complex and the central registry system is deprecated. Local projects is neither. 
It is true that central registry is system is deprecated in *theory*. In [practice](http://permalink.gmane.org/gmane.lisp.asdf.devel/5067) this is not the case, in the words of the current maintainer: &gt; I'm even the maintainer and I still use ASDF:*CENTRAL-REGISTRY*. &gt; ... &gt; As long as I am maintainer, *CENTRAL-REGISTRY* will stay. Although how the registry system *works* is very complex, most of the use cases of the DSL seem easy to me. For example, to mimic local-projects one would add the following lines in any file in `~/.config/common-lisp/source-registry.conf.d`: (:tree "/home/puercopop/quicklisp/local-projects/") or if I want to add a specific directory instead (:directory "/home/puercopop/.emacs.d/site-lisp/sly/slynk/") However I must confess that I had mistakenly assumed that `ql:*local-project-directories*` was a shim over asdf:*central-registry*. After reading the code in *local-projects.lisp* I see I was mistaken. `ql:*local-project-directories*` seems a solid choice upon further inspection.
What concept of modularity is that? I ask not to antagonize but the understand what you intended to communicate. Modularity in the sense of packages? In the sense of responsibilities of quicklisp vs ASDF? To me, it is because of this that it makes more sense to configure ASDF to discover the systems than quicklisp. Quicklisp is the 'package'[0] manager, its job is fetch systems and make them available to my machine. ASDF is the build system. If the system is already in my machine, it is the job of the build system to find it when required. [0]: system would be the proper term
Modularity in the sense of responsibilities. Quicklisp manages the systems completely. It knows when to use ASDF, how to configure ASDF and how to do things which ASDF doesn't but is necessary for complete system management. In most cases I don't think there is much to be gained by manually configuring ASDF.
Also here's a [link](https://leanpub.com/u/fogus) to the past volumes of this newsletter/magazine. Anyhow, it's always nice to see a new Lisp resource.
I really enjoy ELS. It's great to meet online friends in person, and new friends who don't use the typical online channels very much. There's historically been a nice mix of industry and academic people, and interesting topics from each. I wish I could go this time around, but it's just not in the cards.
https://www.youtube.com/watch?v=4OJZF8hLsVk - a new upload without the audio problem.
It's a good way to meet people working with Lisp in various ways.
RemindMe! 27d
I will be messaging you on [**2016-04-28 00:16:12 UTC**](http://www.wolframalpha.com/input/?i=2016-04-28 00:16:12 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/lisp/comments/4cqha3/spring_2016_lisp_game_jam/d1l5uvf) [**3 OTHERS CLICKED THIS LINK**](http://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/lisp/comments/4cqha3/spring_2016_lisp_game_jam/d1l5uvf]%0A%0ARemindMe! 27d) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! d1l5vn5) _____ |[^([FAQs])](http://www.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^([Custom])](http://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^([Your Reminders])](http://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^([Feedback])](http://www.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^([Code])](https://github.com/SIlver--/remindmebot-reddit) |-|-|-|-|-|
Nicely done. The Design Philosophy document is a special touch.
I assume this package is intended to be a satire of the recent Node.js's left-pad fiasco[[1](http://www.theregister.co.uk/2016/03/23/npm_left_pad_chaos/), [2](http://www.haneycodes.net/npm-left-pad-have-we-forgotten-how-to-program/)], right? Edit: Silly me, I just remember what day it is.
We'll see. I have also a nice proposition to switch to COBOL, I'm now investigating if it's modern enough for our purposes.
The problem with lisp is that it's got a write-only quality to it unless written by a professional lisp programmer who can write great code. Just look at Norvig's code in PAIP for GPS. My gut feeling is writing this in a nice modern language with pattern matching would look much better, shorter and easier to understand. I don't mean esoteric like Haskell or old like ML - not even Python but something well designed and with powerful features. Any suggestion for which language that might be?
It needs to be downloadable from the Internet through a centralized package manager though. It isn't left-pad otherwise.
I believe left-pad show the strength of JS, both in its package system and the community mindset. The point is left-pad function does not comes with standard Javascript. What would you do? Surely, you could write your own function. But not everyone will write the exact same code, order of argument may be different, there could even be bug/inconsistency between implementation. Left-pad only shows that using third party library is cheaper than developing your own, even for small functions. The fact that it breaks so much library shows that JS community really buy that mindset. Saying your favorite language comes with left-pad in the standard library miss the point so much. Your standard library cannot possibly contains everything. Damn, I don't even like JS that much to want to defend it, but seeing such a low-blow attack from language notorious for having small useless library does trigger some response.
A macro form is not passed to the corresponding macro directly. It is destructured to the macro arglist. A macro also does not return a list. A macro returns a form. A form is any valid Lisp object which can be evaluated. Thus a macro expansion can result into the form 42. EVAL is not the interface to the interpreter. The CLHS does not mention 'interpret' or related in the definition of EVAL. The glossary explains 'evaluation': 'Such execution might be implemented directly in one step by an interpreter or in two steps by first compiling the form and then executing the compiled code; this choice is dependent both on context and the nature of the implementation, but in any case is not in general detectable by any program. The evaluation model is designed in such a way that a conforming implementation might legitimately have only a compiler and no interpreter, or vice versa.' This means the macro expansion mechanism must work both in an interpreter and in a compiler and there is no reason to assume that evaluation is done by an interpreter and target that specifically. I don't think parsing the code inside ITER is a dirty workaround. It's necessary. An alternative macro system might need to be able to specify more syntax and be able to parse that. Currently the only syntax provided by macros in a more direct way is what the macro arglist provides (incl. &amp;key and &amp;optional). Last: It think it is a mistake to assume that WHILE and COLLECT forms inside a macro like ITER or LOOP can or should be implemented as simple local macros. It's also wrong to assume that the interpreter is the issue. Generaly 'evaluation' is the issue. Thus it is a mistake to think the macro expander should be able to do that. Not the implementation of ITER is a hack, but implementing WHILE and COLLECT as macros may be the hack. I also would not assume that I should be able to implement macros which expand into such forms (while and collect forms) . The paper makes a lot of assumptions about what a macro system should do. I don't buy into those. The simple, but restricted model is that macros are computed outside-inside. Adding complex mechanism to have inside-&gt;outside communication does not look convincing. The ITER macro provides a complex machinery, which is difficult to implement with any macro system. It's certainly useful to think what kind of macro mechanism (or code walker) would make that implementation easier, but I fear this paper is not covering the problem from the right angle.
[already posted](https://www.reddit.com/r/lisp/comments/4cfth8/els_2016_registration_now_open/)
I've only been to one so far and am not an academic at all, but I really enjoyed it. It has lot less polish than many conferences, but just seeing what kinds of odd things people are using lisp for (primarily CL) is really cool. For example I loved a talk by Miroslav Urbanek on quantum physics research using lisp. I have no idea about the equations themselves but seeing how they used CL across massive clusters was super cool. Also as it's small it only has one track so you get to see everything :) Hope to see you there!
Thanks! Maybe we will be able to run CEPL on OSX there. [cepl#28](https://github.com/cbaggers/cepl/issues/28) :D
Sure! would be great to test it on your machine
Nice work. Just a note - transactions don't contain databases, they're more like peers within the environment. Databases must be created within a transaction, but they live on in the environment after the transaction commits. This is documented quite explicitly. It should also be obvious from the fact that mdb_dbi_open takes a transaction handle, but mdb_dbi_close takes an environment handle.
Sure. You'd actually use it as part of an FPGA design, "wiring" the microcontroller core to other peripherals and I/O lines in more Verilog or VHDL, and then interfacing the programmed FPGA with external devices, memories, etc.
Ah, okay. Thanks for the reply. 
&gt;transactions don't contain databases, they're more like peers within the environment I meant the diagram to illustrate object lifecycles -- then again, even that's wrong since the database handle cannot be closed before the transaction is completed, an error that tripped me up during development.
The article uses interpreted mode to illustrate some concepts more clearly, but the semantics are the same in compiled code. The proposal actually relies on code being compiled, or at least on making interpreters act slightly more like compilers by using more distinct phases. A piece of code can exhibit different different semantics between interpreted and compiled mode. A recursive macro with no base case will never finish expanding in compiled mode, but it can terminate in interpreted mode when the expansion and evaluation are interleaved and the runtime base case is reached. If compile-time continuations worked similarly, parts of a form could be evaluated before it is determined that the the entire form must be re-expanded. If the code has side effects, this would produce observable differences. In fact, the idea may not make sense at all in traditional interpreted mode. When you reach a form whose expansion invokes a compile-time continuation, you can't just re-evaluate the parent form in the same position where the compile-time continuation was invoked, because you're expecting to receive the return values of the subform there, not the return values of the parent form. You might run into an error before you ever got to that point because you evaluated a subform that did not yet have the correct expansion. The behavior of non-local exit mechanisms would be even more unpredictable. The only way to avoid all those problems is to fully expand all forms before interpreting them. I don't remember whether the official spec dictates whether an interpreter must interleave expansion and evaluation, but this article is a vision for what might be possible in a new spec, so I wouldn't be surprised if it required other changes too. In regards to iterate in particular, to me the real question is not whether things like `while` and `collect` should be implemented as macros, but whether they should be implemented as forms at all; it may make more sense to think of `while` as a declaration, and to only treat the s-expression following it as a real form. But if they are understood to be forms in themselves, it's natural to expect that other macros could expand into them, like the `sum-of-sqrts` example from the iterate docs. The point of iterate is to incorporate `loop`-like concepts into finer-grained forms in order to make them more extensible. There is a great virtue in being able to expand into forms that have special meanings in the context of a surrounding macro, which allows for greater interoperability of language extensions and/or DSLs like iterate. What if you interleaved macros from two DSLs that both used a code walker? You'd have to understand their implementation details in order to use them. Otherwise you may discover uncomfortably late in the game that one of them is transforming its inner code in such a way that the other one can no longer properly handle its own subforms, at which point you've coded yourself into a corner and you have to decide to stop using one or the other. I think this is an anti-pattern that dooms a lot of macros with a lot of ingenuity behind them, which could otherwise be broadly useful, to never be trusted outside of applications built by their same authors. They don't scale into the whole Lisp ecosystem. (Anyway, I'm not a fan of DSLs that infer context from the inside and lift it to the outside, regardless of how they work. Most really good Lisp code, even with heavy use of macros, even if not built out of pure composing functions, can still be mentally parsed and understood according to compositional principles; you accumulate pieces of semantic context as you descend into expressions and pop pieces of context going back up. But constructs like `collect ... :into`, even if they are relatively declarative in style, still force you to think procedurally to understand what they do; instead of simulating the runtime procedure in your head, you now have to simulate the expansion procedure to figure out things like what bindings are produced and where they are in effect. I've written a little language extension to try to make it easier to achieve these two virtues in systems of cooperating macros: https://github.com/DalekBaldwin/macrodynamics)
This book has the kind of enthusiasm and hard work that I personally find so useful, if not inspiring to learn more about Common Lisp. In the past few years the Lisp community has been growing in such a great way. Thank you.
Very nice, I just spent a few minutes reading through the online version. BTW, the first book I ever wrote, this was back in the 1980s, was also a Common Lisp book.
did anyone step up?
I'm looking forward to reading more. 
Ha, considering how much I've procrastinated on it, that's weird to hear that, but thank you :)
&gt; I have to write an analysis about the evaluation of Scheme but I'm not that familiar with the language yet. Have you learned any Lisp yet and made up your own mind about the readability? Spent at least a day playing around with Scheme, getting some help from the IRC channels like #scheme on Freenode? I wouldn't even start without that - it's hard to talk or analyze what you have no idea about. Again, how readable it is depends on how used you are to programming languages. And the case that might come up, with "Lisp has parens", is lost from the start; all programming languages look funny at first, regardless of whether you go (setf (car (rassoc :my-key *alist-1*)) (car (rassoc :my-key *alist-2*))) in Lisp, public static final StringFactory myStringFactoryFactory in Java, s/\((.*?)\)/\"$1\"/ in regex. Then you get used to the quirks and the features of the language and then you get people claiming their language is the one that looks *normal* because they're used to it.
What's not 'standard Lisp syntax'? All the examples I skimmed through looked Lisp-y.
Lispy? You mean ( and )? That's s-expressions. But not Lisp. No Lisp has + for strings. DEF ? Lisp (Common Lisp, Emacs Lisp, ISLisp, ...) uses DEFUN/DEFVAR/DEFPARAMETER and Scheme uses DEFINE. DO ? Lisp uses PROG&lt;N&gt; and Scheme uses BEGIN. Lisp uses DO for iteration. Under 'LAMBDA': FN. Why not call a LAMBDA, LAMBDA? Like in Lisp? (nth '(1 2 3 4) 2) is (nth 2 '(1 2 3 4)) in Lisp. One takes trivial Lisp code and tries to run it in 'Tiny Lisp' and it won't run. Why? 
&gt; No Lisp has + for strings. What? He's implemented a Lisp, not an existing Lisp. def not define? Come on. &gt; (nth '(1 2 3 4) 2) is (nth 2 '(1 2 3 4)) in *current* Lisps. FTFY. &gt; DO ? Lisp uses PROG&lt;N&gt; and Scheme uses BEGIN. You're kidding right? Tell me you're kidding. What does Clojure use again? It's neither of those, do you also try and claim Clojure isn't Lisp? &gt; One takes trivial Lisp code and tries to run it in 'Tiny Lisp' and it won't run. Why? Because they're different dialects. Take Common Lisp code and try to run it under Scheme or Clojure under Common Lisp. There are lots of reasons you might criticise tinylisp (JS, Jison really?, does the world need another lisp?) but I'm afraid your reasons are just downright silly or you're trolling.
Clojure is no Lisp. It's a Lisp-derived language with arbitrary syntax changes/renamings/functionality changes/... plus a lot of stuff from other languages. The main data structure - the persistent lazy sequence - was influenced by developments in other FPLs. See for example Okasaki's work on Purely Functional Data Structures, which used SML. &gt; Take Common Lisp code and try to run it under Scheme or Clojure under Common Lisp. Try to take Lisp code from Mccarthy and run it in Common Lisp, Emacs Lisp, ISLisp, Standard Lisp, .... Changes are minimal. Example: I took a piece of graph search code from McCarthy. It had MLISP syntax. Changing that to s-expression syntax and using DEFUN (instead of DEFINE) - it ran in Common Lisp without further changes. Semantics, core data structures, core language constructs - all there. Scheme used to be much closer to Lisp. At that time there were compatibility libs and some applications were written in a language looking like Scheme, but which had macros so that it ran in Common Lisp, too. Then there were Scheme variants running on top of Common Lisp and even a Common Lisp written in Scheme. After decades of development in different directions (Scheme was defined mid 70s and Common Lisp in the early 80s), they are now fully languages on their own. They have their own definitions, their own libraries, their own eco-systems, their own books and communities. &gt; There are lots of reasons you might criticise tinylisp (JS, Jison really?, does the world need another lisp?) but I'm afraid your reasons are just downright silly or you're trolling. Accusing me of being silly or trolling is silly or trolling. Lisp is not parentheses. Lisp goes back to Mccarthy. It's a set of core operators (CAR, CONS, ATOM, NULL, APPEND, ASSOC, EQ, APPLY, EVAL, SET, ...), core datastructures (cons cells, numbers, symbols, strings, ...), core syntax (LAMBDA, DO, DEFUN, COND, QUOTE, SETQ, ...), core semantics which is shared by Lisp dialects. Lisp is defined by literature, libraries, code and a community sharing those. Any language/community combination which does not share core code/syntax/semantics/etc. is not Lisp. It's Lisp-derived. Like Logo, Scheme, Racket, Dylan, Javascript, Clojure, ... Example: Clojure does not even have cons cells. It replaced standard Lisp cons cells / lists with one or more different data structures: lazy persistent sequences and some others. There are countless examples. Clojure has been defined in a way that it is fully incompatible with all prior Lisp dialects and software can't be transferred easily - basically it needs a full rewrite. For me that is the best indicator that it is a different language. There isn't even an attempt to provide a compatibility layer - because it is pointless. Emacs Lisp contains a bunch of CL. The core of Emacs Lisp was anyway already quite compatible with CL. For CL there were/are compatibility layers / translators from other Lisps. There was the will to share and move code. For Clojure it makes no sense. The language is very different. TL;DR: Lisp is defined by more than ( and ).
&gt; Any help would be appreciated. :) Sorry, no help for homework cheaters. :)
I find you work very cool. I guess you know the Peter Norvig's [lispy](http://norvig.com/lispy.html) essay. I am facing same comments in my own project [lambdaway](http://epsilonwiki.free.fr/lambdaway/). I get a lot about "why using braces {} and not parens (), it's not Lisp!", and never about the interest (or not) of a Lisp "related" language embedded in a web site (a wiki) where text is 95% of the content, and not in a console where it's not a big problem to embed text as strings between quotes. Until now, I am not aware of another Lisp's dialect implementation allowing writing such a thing: {b Hello {u (brave new)} World} without boring with (b "Hello " (u '(brave new)) " World") and carefully inserting spaces in the right place and quoting parens around "brave new", or something alike. I thought Lisp could be seen as a meta-language allowing a lot of dialects depending on context, even if not compatible. Now my question is ¬´ Is there a better place than in r/lisp to share experiments following the Lisp meta-language spirit? ¬ª
There is a long tradition that any language not containing the core Lisp language should avoid Lisp in its name. Those languages are members of the wider family of Lisp-like or Lisp-derived languages. Also languages containing the core usually have 'Lisp' in their name: Lisp 1, Lisp 1.5, Ucilisp, Standard Lisp, Lisp Machine Lisp, Interlisp, Maclisp, Emacs Lisp, ISLisp, ... There have been all kinds of experiments to derive new languages from the core Lisp: * Logo as a small core Lisp without the s-expression syntax * Dylan as an object-oriented Lisp without the s-expression syntax * MDL as an extended Lisp with a syntax around &lt; &gt;. * CURL as a web language with another surface syntax. Have a look at curl and compare it to your language. * RLISP as a core Lisp with algebraic syntax on top of Standard Lisp etc etc. For me it's okay to discuss something like 'lambdaway' in /r/lisp - but be aware of the expectations of SOME people, that 'Lisp' means also real compatibility and that it is not just a spiritual fluffy thing around whatever vaguely defined concept of Lisp one has. 
Because the author enjoys that syntax and maybe the users do too?
Afaik, asking people for information is a valid way of doing research. And I'm not asking you do my homework, I just want a bit of a jumpstart or a point towards the right direction.
TL;DR: your personal definition of 'Lisp' is 'must be identical to Common Lisp or Scheme' which is just silly trolling. 
It's not just my personal definition of Lisp. See for example Professor Krishnamurthi, one of the core developers of Racket, who doesn't want to see Racket grouped with Lisp for the same reasons. https://plus.google.com/+MichelAlexandreSalim/posts/2vhp2GE9k8Z Racket was even renamed from PLT Scheme, to make it clear that it is its own language: http://racket-lang.org/new-name.html 
Thanks for your answer, lispm. And OK, I can understand that Lisp is a copyrighted name not to be used outside a very precise "pr√© carr√©". Maybe my concept of Lisp is "vaguely defined", maybe yours is a litlle narrow, I don't know. And thank you for opening /r/lip/ to discussion about something like 'lambdaway'. About [CURL](https://en.wikipedia.org/wiki/Curl_%28programming_language%29), I know that this language was intended to 'provide a smoother transition between formatting and programming' but, tell me if I miss something, CURL doesn't answer to my very basic needs in a wiki context: ¬´ writing simple text out of any quoting like "Hello World", or any s-expression container like (text Hello World). ¬ª And I know it's the same with Skribe, Scribble, LAML, SXML coming with a ton of specific names away from HTML and CSS ones (i.e "paragraph" instead of "p"). These tools come with the full power of a true Lisp, OK, but they come with some boring workarounds to write simple strings, ie. "some words" or (text some words). In a console, I can understand that, in a wiki I can't. With lambdatalk, I can share with non coders a lot of documents because I give them the possibility to minimize the code part. Having built standard functions on standard HTML tags/syntax and CSS rules/syntax, I give them the possibility to improve their knowledge without leaving the real world. For instance: * A beginner can begin with simple things, some raw text and small enrichments like {b Hello World}, * then, helped by a web designer, he will add some more style like this {span {@ style="font: bold 3em Georgia; color:red"}Hello World}, * then, helped by a coder, he will define a constant {def HI span {@ style="font: bold 3em Georgia; color:red"}} * and use it like this {{HI}Hello World} * or even he will create a function like this {def HI {lambda {:size :col} span {@ style="font: bold :size Georgia; color: :col"}}} * and use it like this {{HI 2em red}Hello World} or {{HI 5em blue}Hello World}. It's a collective work where an author, a web designer and a coder can work together, sharing knowledge. It's how a 10 years old kid built her own wiki: [Romane](http://rue74.fr/F6/romane/). I don't think she could have done that with CURL or Skribe, Scribble, LAML, SXML. Sorry if it was not the right place to speak of that! 
So PicoLisp is no Lisp for you? It uses "de" instead of "defun" and has nothing like "lambda", using "quote" instead, though even "quote" works differently than it does in Common Lisp.
What you will often hear people say: it's hard to read lisp at first, but once you got used to it, it's very readable. It worked like that for me; where I can only speak for CL and Scheme. Both CL and Scheme do have a very simple and regular syntax, both prefer identifiers over sigils and especially CL often has these readable long names. Also most people seem to use Emacs for editing, so that indentation is very regular over various sources. You won't experience that in a few days, but you might find some more reliable sources than me ;) All the best for your analysis... 
It looks a good idea. Such a subreddit could help to avoid endless discussions like in this one, [a_small_and_simple_but_very_powerful_lisp](https://www.reddit.com/r/lisp/comments/4e7jst/a_small_and_simple_but_very_powerful_lisp_written/). It would be possible to study how some Lisp functionalities (S-expressions, homoiconicity, lambdas, ...) can be used in other contexts than programming consoles.
emacs &gt; vim
What does " languages directly compatible with LISP " mean? Common Lisp is a Lisp but it's not "directly compatible" with Scheme, which is also a Lisp which makes it impossible for both to be directly compatible with some theoretical uber LISP. Similar arguments apply to Racket, also a Lisp, and Clojure, also a Lisp, and many other Lisps.
[removed]
&gt; Arguing whether a language is a "Lisp" (or worthy of being called a Lisp) is one of the oldest cause of flamewars in Lisp community since time immemorial. Perhaps the answer is to introduce a sub rule forbidding any statement along the lines of 'that's not a Lisp because it isn't CL or Scheme'?
I know you created this thread because you want to make the community of /r/lisp a better, more welcoming place. However I had a diametrically different impression of the same exchange. That thread left we wondering, where are the mods. Heinemenusch exhibits a toxic behaviour not only in that thread but in pretty much every thread I can recall where they participated. To explain why I think your statement in the OP is misguided. lispm, didn't say don't discuss your unlispy/false lisp here. He didn't remove the article, which as a mod I assume he can. He asked a question after taking his time to read the link. What's up with the weird syntax?. Which considering that do was used as a progn/begin instead of an iteration construct, seems a pretty reasonable question. Then when someone counter argued mentioning code sharing is hard between CL, scheme and Clojure he argued his well known position that Scheme and Clojure are *not* a Lisp. This is a reasonable opinion shared by other, Kent Pitman for example. An although it is not an opinion I share, I ask, what is the problem with someone thinking and *arguing* that position? Especially since, unlike me for example, he actually has a definition about what is lispy Keep in mind, He is not seeking to ban links about languages that don't adhere to his definition of lisps. I hope you'll understand why I think the perspective from which you posted the question is misguided. What I think that is an issue that should be dealt with is what happens next. Instead of responding with *arguments* or even attempting to inform themselves, Heinemenusch resorts to name calling, 'lol u must be trolling', which as lispm adequately describes imho, is trolling in itself. Shouldn't there be etiquette guidelines, that when breached result in a warning or maybe a ban in order to erradicate this kind of toxic behaviour? Anyhow my 2c.
This **is** such subreddit. Creating a new subreddit (or even new web forum) wouldn't solve the problem because it's a social one. There are no quick and easy solution to this issue. The best course of action to take is for us to continue having civil discussions on Lisp and all of its dialects, both old and new, and try to be respectful of the opinions of other people. You've already contributed a great deal to this subreddit by posting your lambdaway project, and I would love to see you continue to do so.
To paraphrase Taylor Swift: Moron's gotta downvote, downvote, downvote.
&gt; Heinemenusch exhibits a toxic behaviour not only in that thread but in pretty much every thread I can recall where they participated. In /u/PuercoPop's lexicon 'toxic behaviour' is "behaviour exhibited by someone I disagree with and therefore will lie about". [And he's just pissed that he tried to correct some Lisp I'd posted (he introduced the problem in his typing) and then tried to present an example that was full of bugs and didn't meet the requirement, which he didn't have the balls to admit when I pointed it out](https://www.reddit.com/r/Common_Lisp/comments/4585ci/eliding_text/czvwrm1). Which is a bit sad.
&gt; I have started work on a (weird) Lisp without a Garbage Collector (using explicit regions instead). Sounds interesting. Do you mind sharing a link? And please do keep us up to date with your progress. 
I use explicit regions. You can use a construct like (with-new-region expr) that will evaluate `expr` while allocating all objects in a new region. Finally, it will copy back the return value to the region used previously and free the region used while evaluating expr, the latter being a simple O(1) operation. (There's some more things you can do, but that's the main idea). When you use regions like I do, you basically have the choice to give up imperative programming or to give up memory safety (i.e. there may be dangling pointers). For now, I decided to give up on imperative programming. Regions are very simple to implement, both allocation and deallocation are very cheap, you get control over which objects are allocated together in memory (making good locality of reference possible), cause no problems with fragmentation, cause no GC pauses, cause no problems with extremely large heaps etc. On the other hand, they do impose some limitations. For some situations, it might be the right trade-off, I think.
Personally I have zero problem when people post about languages which are Lisp-related. As a mod I would not remove them. I even post stuff like that myself from time to time. But I feel free to point out needless incompatibilities, etc.. Giving feedback on language design, even if the feedback is negative, is as welcome as posting new attempts at Lisp related languages and implementations.
I just read this quote from Peter Wayner. "The technology world is a bit different than the pretty, coiffed world of suits and salesdroids where everyone is polite, even when they hate your guts and think you're an idiot. Suit-clad managers may smile and hide their real message by the way they say you're doing "great, real great pal," but programmers often speak their minds, and when that mind has something unpleasant to say, look-out, feelings." Perhaps you should give up programming and stick to being a "coiffed manager" or "salesdroid". But other than that, "you're doing great, real great pal".
&gt; Bone Lisp Lovely name, and nice logo too! :) &gt; but it already does full tail-call elimination. Very impressive!
IIRC warweasle in the #lispgames irc was chatting about gifs the other day, but that will no doubt be in the 'cl-opengl' camp as he is normally working on his game engine, may get you some leads though.
Thanks. I pm'd him
mplayer plays gifs and you can control it via a named pipe.
There is a big difference between saying that something is not a Lisp and saying that it is needlessly incompatible.
Well yes but that was rather the point: to personally insult /u/PuercoPop. And of course to highlight the contrast between my behaviour and the weasel hiding his personal attack against me in the middle of his typically boring wall of text post.
I think this would be pretty straightforward with the sdl2 bindings. Example https://gist.github.com/lispnik/157b734cb2c51a9659948b16c2eb6d16 In the animated GIF I used, there were 23 frames and I hard-coded it. I first had to convert the animated GIF to a montage (each frame next to the other).
What exactly? How successful Lisp marketing could look like? :-D
haha as much as I like that your logo as works in unicode (‚ò† Bone) I was hoping you'd focus on the 'no GC' a little :p
I need to get practical experience with this before it makes sense to talk more about it, I think.
&gt; because otherwise it will seem weirder and weirder to new users. Sounds like Unix/Linux/Mac OS X. Totally weird and ancient base, but widely used. &gt; If the Lisp community does not share a common vocabulary with the larger programming community, it will be doomed eventually. I have no problem with giving up old things like Common Lisp and moving forward. Racket. But don't call it Lisp. It's no longer the Lisp community. reddit.com/r/racket It's a new community. Clojure. But don't call it Lisp. It's no longer the Lisp community. It's a new community. reddit.com/r/clojure
SDL2 is probably the easiest option assuming it does something sensible with animated GIFs. SKIPPY + CLX or OpenGL would be interesting too. Not directly relevant to your problem, but I'm fondly reminded of using SKIPPY to add GIF export to my toy "McPixel" animation editor built on McCLIM, several years back (http://ahefner.livejournal.com/17723.html).
Does the region have a fixed size? If so, what happens if you create too many objects in the region? 
But left-pad is not web scale enough
By the way, tcc seemed to be the best option for on-the-fly compilation of code. Am willing to look at other options as well. 
Thanks, I'm looking forwards to messing around with it.
Yep. As stated previously in the thread, this is the argument that most of us dislike having.
Wow, looking at the system browser screenshot takes me back to when I learned Smalltalk in university. It's uncanny.
I think WITH-OUTPUT-TO-SEQUENCE in Edi Weitz's excellent flexi-streams library may be just what you're looking for: http://weitz.de/flexi-streams/#with-output-to-sequence
&gt; And then there's another argument ... and I'm the only one who has commented on it at this time. Don't pretend to know that "most of us" share your sense of entitlement to have your cat questions answered at the weekly dog breeder's club meetup, because all four-legged pets look the same to *you.* Anyway, nice that you found a home for yourself over at Hickey's place. 
Thanks for your kind words :-)
maybe [Babel](https://common-lisp.net/project/babel/) which contains the system babel-streams?
Thanks!
Thanks for your great work!
&gt; built-in vs std classes yes, this should be investigated. In fact, Im not sure SBCL can detect disjointness of standard classes (even when their inheritances are finalized.) LIL would be a good direction, but the most severe problem is the lack of documentation/test/benchmark... BTW, Would someone be interested in writing a good benchmark platform? Unit Testing framework does not suffice here, since we should test several implementations of a single interface (like I did with Optima vs Trivia) I didnt do much survey yet. This project is like a proof of concept which eventually turned out to be general enough to support other method combinations. Well, it's now very funny to see a phrase like `The consensus seems to be building in the Computer Science community that object-oriented programming languages are a "good thing"`. I haven't even touched Dylan yet. 
First off, people usually recommend practical common lisp (check out the sidebar). You might have more luck with it. If not, also think about getting Land of Lisp which is the book by the author of the tutorial you are following. Either way, the error means you've put a comma somewhere that it doesn't belong. Take a hard look at them. Something like: (,blah `(+ 1 2)) Is going to give an error where as something like `(,blah (+ 1 2)) Might not. You should put your code on a pastebin (http://paste.lisp.org is one) and someone will probably tell you what is wrong. P.S. I wrote this on my phone at 1 am. Accuracy is not guaranteed.
commas are a special character in Lisp. My guess is you are modifying the following piece of code (setf *map* '((living-room (you are in the living-room of a wizards house. ...) The tutorial uses periods, which aren't really a special character in Lisp, so there is no problem with it. Since commas actually do something (like parentheses), Lisp won't understand them unless they are part of a backquoted form (don't worry about what this is). My guess is you did something like (setf *map* '((living-room (you, the player, are in a ...) For the purposes of the tutorial: if you can, just avoid commas. If you need commas, you can wrap the sentence in ""s like (setf *map* '((living-room "You, the player, are in the living-room of a wizards house.")) There are other special characters too, like ; will comment a line, and ()s and ` (the back-tick). Since I haven't read the tutorial I really recommend you just avoid ""s and commas for now. It might mess things up for later parts of the tutorial.
Period '.' isn't a special character in Lisp ? Periods denote cons cells, one of the basic data structures. (this-is-the-car . this-is-the-cdr) 
Quote (') is a shortcut for (list). Backquotes (`) is a special version of quote. Commas must be used in combination with backquotes. Paul Graham devotes a few pages to explain them in [On Lisp](http://www.paulgraham.com/onlisp.html). See chapter 7.2.
except quote is a quote.
But one or more . alone are not read as a symbol.
[removed]
That looks like the :around method from the test code, which is apparently there to show that it works too.
You're right, that is a stupid mistake.
Yeah no problem. In case you didn't understand the other comments in this thread, you can't use periods by themselves either. You'd get an error like "more than one object follows . in list" or "too many dots". So .s are also special syntax, but when they are part of other symbols its ok. Commas, semicolons, parentheses are just always special syntax. The rules are a bit confusing at first, but you'll pick up on what everyone is talking about in no time. and like most general rules there are always exceptions. also be sure to check out /r/learnlisp as another good place to post questions like this.
Thanks, that fits the bill. I appreciate your help.
Oh this is going to be great! See you there! :-)
Its a small, casual conference. Cozy! :-) Its nice I can recommend it.
Signed for it. See you there ;)
The subreddit does appear to be primarily focused on CL, and I think that's a bit unfortunate. There is already /r/Common_Lisp for CL specific topics, just like there are subreddits for other Lisp family languages. In my opinion it would be great if the subreddit focused on general Lisp related topics that are of interest to everybody.
Is there something wrong with using company-quickhelp? I don't know of any automatic alternatives.
It works with CL for me. I'm not using anything besides in addition to sly-company-mode to company-quickhelp. You have both enabled right?
Love it! It's better if it detects some kind of dependency between them. I generally append numbers to filenames which identifies the stages of compile-load scheme (like in sysvinit), for example, 0-package.lisp is loaded first, 1-X.lisp and 1-Y.lisp depends on 0-package.lisp, 2-Z may depend on all source files with 0 and 1. but I am too lazy to add that dependency and instead abuse `:serial t`.
There's no automated dependency checking. You state parts of the load order yourself, as seen in the *data* over there, in the example.
Personally package-inferred-system is too complicated and requires a radical change in the development style. 
Nothing groundbreaking here but may be of interest to some. The full issue of Amiga World can be found here: https://ia600808.us.archive.org/16/items/amiga-world-1986-01/Amiga_World_Vol_02_01_1986_Jan_Feb.pdf
I've used Cambridge Lisp on the Atari and it was pure pain. The amount of runtime checking was limited and it was crashing a lot. Especially on the FFI side it was not robust. That it was more or less Portable Standard Lisp was not so much a problem, but I remember than binding worked differently between interpreter and compiler - the classical problem at that time, which got fixed in Common Lisp then - by requiring lexical binding for both by default. A manual: http://chrisacorns.computinghistory.org.uk/docs/Acorn/Sci/AcornScientific_CambridgeLISPRM.pdf
I am not a "Python guy" but if I were to write something about it, I'd make sure to understand it thoroughly. I expect the same from someone who writes about Lisp, even in the context of multiple dispatch. I could elaborate on why methods are not functions, but instead of wasting my time I can just delegate to the various books that explain CLOS properly, like [Practical Common Lisp](http://www.gigamonkeys.com/book/) (which is referenced by the author), the [Keene book](http://www.amazon.com/Object-Oriented-Programming-COMMON-LISP-Programmers/dp/0201175894/ref=sr_1_1), and most importantly, [AMOP](http://www.amazon.com/Art-Metaobject-Protocol-Gregor-Kiczales/dp/0262610744/ref=sr_1_1). This "mixed feeling" you're talking about is expressed throughout the article. You may regard humor as the important emotive content in the (half) paragraph quoted, but I see frustration. The author sees something in Lisp, but yet does not understand it in depth. In certain persons this ambivalence prompts further research. When it comes to the author, it seems he has given up. Instead of putting more effort and time in learning it proper, he satisfies himself with the rationalization that Common Lisp is antiquated, unpopular, obscure. That his next article will discuss Clojure is no surprise to me, as it is The Lisp For Those Who Don't Quite Understand Lisp.
the true sacred lisp as handed down from McCarthy and blessed by Steele, amen bro (call-with-current-continuation sarcasm) 
[http://eli.thegreenplace.net/tag/lisp](http://eli.thegreenplace.net/tag/lisp)
&gt; Chez Scheme, a powerful implementation of Scheme designed to maximize programmer productivity as well as application reliability and performance. Question for Chez Schemers, the above is a very cool goal, what would you say are the features of the language that most help your productivity?
Wow. Colour me very, very interested.
So does this mean it's going to die? Or is this a good thing. Chez always seemed like a great implementation but like other lisps that have been abandoned to open source, this may be sad news too. 
I think I was too harsh there, but sometimes that is how I feel about it. Clojure is a "shiny new Lisp" that draws in many people without a Lisp background. As a result, a lot of Clojure code is written in a way that is not what I would expect when reading Lisp code. For basic advice on Lispy style, see the [Tutorial on Good Lisp Programming Style](http://norvig.com/luv-slides.ps). Don't get me wrong, there are some very good programmers writing Clojure, but the language and its community departed from the Lisp tradition. Some may see it as a good thing. The core of Clojure was designed by one Lisper, Rich Hickey, and while it is certainly a great intellectual achievement, it also reflects his idiosyncratic style (incl. use of those annoying brackets which also afflicts Scheme code at times, a pet peeve of mine), his bias towards functional programming, the particular constraints he chose (e.g., JVM). Reading a language's manual may provide you with a certain level of understanding, but to immerse yourself with the historical choices made, and the choices not made, with the design considerations, the rationale for how things are, and the alternatives not taken - this makes for a much deeper level of understanding. When these choices are made in the mind of a single person, the process by which they are made is usually not sufficiently documented, and you either have to ask him, or accept the way things are without fully understanding the rationale for it. In contrast, Common Lisp has a historical baggage full of treasures. It is a product of the Lisp community at large (well, at least the American part), and had copious amount of discussion going into its design, with inputs from people with diverse interests within the community at the time. They arrived at a compromise, a common denominator, the mainstream of the Lisp tradition and thinking. Read [cl-su-ai](http://cl-su-ai.lisp.se/) for some understanding of why things are the way they are, for understanding the mindset of Lispers. Clojure took something from the Lisp tradition, but turned out to be something quite different. 
The articles in the list confirm my analysis. One third of these are trivialities, another third is rants (some bordering on trolling), and the rest are "I read a book", "I wrote a toy scheme", "I try to explain &lt;lisp-associated-buzzword&gt;".
If you are using gnus: I took the contents of this mailing list and munged it into a [single file](https://adeht.org/dump/cl-su-ai.7z) that can serve as a gnus source. Extract it, type `G f` in the gnus summary buffer and select the extracted file. Now you can read it comfortably. I have done [the same](https://adeht.org/dump/ll1.7z) for the [ll1 mailing list](http://people.csail.mit.edu/gregs/ll1-discuss-archive-html/threads.html).
Now you gave me a reason to finally start recording my podcasts. Gimme a few weeks.
Thank you so much, that is priceless. PS: How I wish there could be something similar for the whole comp.lang.lisp usenet group. Alas, since Google took it over, that is not possible anymore.
 @@ -1 +1 @@ -...how to write your our programming language... +...how to write your own programming language...
How did Cisco use Scheme?
Looking forward to it.
Seems like 4 episodes were produced. Will check them out, thanks!
You might want to look at chapter 8 of [On Lisp](http://www.paulgraham.com/onlisptext.html) which is about when to use macros.
I've taken a look but it's still not quite clear. I feel that Graham's transformation (#1) and conditional evaluation (#3) rules are the same, they're both predicated on delayed/cancelled evaluation. However, given the pitch that macros are Lisp's superweapon, I'm struggling with finding cases where they would be more appropriate than the built-in primitives. Current conditional forms seem to cover pretty much every possible use-case, so do most of the binding forms.
To me, LoL is best read as one person's take on programming power. He has a consistent view on what makes a language powerful but many would argue against some of his methods. To that token it is generally recommended that you have some experience writing macros before diving into the book as it helps not just getting swept away in the authors excitement. Saying that, it's a great book and great fun to see what can be done with macros and to be honest, given how you are asking your question I'd say just read it. 'PAIP level' is just handy simplification as it would be hard to have grasped it without forming some nuanced views on lisp of your own. I'll add that with macros it's as much about 'when' your code run's as 'what' it does. CL-PPCRE (a regex library) is the canonical example in that it reads your regex string at compile time and creates lisp code that implements the regex. This avoids parsing at runtime and the code generated goes through the compiler so your regex string may now be optimized machine code. This gives a massive performance gain over a runtime interpreted approach. Of course this is supported by C# too, but there it's a language feature, here it's just another macro, something that its perfectly reasonable to write yourself.
The author basically says you should be good if you understand everything in the second and third chapters. I thought the author did a good job easing you into things. I haven't read PAIP yet.
SETF. If you read the hyperspec for it, it's trivial to see the implementation as a macro. It's very much not doable as a function, and you probably already use it every day.
Thanks for the comment. My goal was definitely "known, reliable precision and rounding behavior in a known range and domain". I essentially used [this](https://en.wikibooks.org/wiki/Ada_Programming/Types/delta) as a pseudo-spec. That said, the type definition mechanism provides all the information required to meet the compact representation needs. Each type that is defined with a particular range specifies the underlying value as a ranged integer. Do you have any particular recommendations on how to go about achieving a more appropriate underlying representation? I suppose a different version could be specified to operate on arrays of the underlying type. Is that what you mean by massive numeric structures?
Note that the LOOP specification in the ANSI CL standard defines no extensibility. Several LOOP implementations are of course extensible. That's the typical difference between a specification and a implementation/documentation combination. For example Symbolics Genera provides the macros DEFINE-LOOP-PATH and DEFINE-LOOP-SEQUENCE-PATH. There are several cases where some LOOP implementation has been extended (iteration over database query results is typical).
This caught my eye &gt; enhancement: the interleaved structure slot optimization from release 1.2.6 has been ported to all architectures. From the release notes for 1.2.6 &gt; enhancement: efficiency of access to untagged structure slots is improved on x86-64, and the order of slots in memory is exactly as specified by defstruct, simplifying use of structures as arguments to foreign calls. Is there a way to know when this applies to a given struct? Or is this one of those 'Those who need to know, know already' kind of things? If it's the latter could anyone recommend where in the sbcl source to start reading to get insight on this?
I would also like to give an example. Taking C to allow some object-orientation, either via Objective-C or C++, took massive compiler modifications. In Common Lisp you could do the same thing without touching the compiler. In fact multiple different "macro packages" for OO programming were developed. You could implement your own vision of what OO should look like without having to burden yourself with becoming or hiring a compiler hacker. I'll leave it to those who know Objective-C and C++ to judge whether a pure implementation of a coherent vision of OO has been implemented after it went through the compiler people. I can't say I am entirely happy with the Common Lisp's OO winner (CLOS) but then I am not a OO type of programmer anyway, so what do I know. (disclaimer: you can hack up the compiler later to special-case some OO operations in Common Lisp that your choice of "macro package" left hard to optimize. CLOS is very featureful, so that happened quite a bit afterwards. A simple OO system with inheritance and objects-with-classes would be no different from a functions-n-structs optimization, which of course were in the compilers already)
thanks, that's very interesting
Yes, you can write a lambda that does the same as eval. A lambda form evaluates to a function object. But APPLY and FUNCALL, which you use to make use of a function object returned by evaluating a lambda form, are both functions, not special forms, so they would evaluate their arguments. 
LOOP (along with other "local languages") is created via a macro, which is also distinct from a function. A macro, at it's core, is a function that takes an unevaluated expression and turns it into another expression which is evaluated in its place: (defmacro foo (x) (list 'string (list 'quote x))) (foo hello) ;=&gt; "HELLO" 
&gt; How are these many "local languages" created, like Can you write a function to translate a list like: '(times 3 print "Hello") into: (progn (print "Hello") (print "Hello") (print "Hello")) Sure you can. Here's one: (defun zebra (x &amp;rest rest) (if (= 0 x) nil `(progn ,rest ,(apply #'zebra `(,(1- x) ,@rest))))) I'm sure you can come up with your own way. Now I want to write a program that uses one of those "local languages": (defun cow () (times 3 print "Moo")) What I want to have happen, is instead of evaluating that `3 print "Moo"` which doesn't make any sense, I want to pass it to my function. This thing is called a macro. I can create one like this: (defmacro times (x &amp;rest rest) (apply #'zebra `(,x ,@rest))) And sure enough, (defun cow () (times 3 print "Moo")) (cow) does what I expect. But how do I *know* it's evaluating my function at compile time? (defun zebra (x &amp;rest rest) (print "zebra") (if (= 0 x) nil `(progn ,rest ,(apply #'zebra `(,(1- x) ,@rest))))) (defmacro times (x &amp;rest rest) (print "times") (apply #'zebra `(,x ,@rest))) (defun cow () (times 3 print "Moo")) "times" "zebra" "zebra" "zebra" "zebra" (cow) "Moo" "Moo" "Moo" 
No. Quote is not a function. It is a special form. Check the hyperspec.
This is best done in Scheme: (define troll 'as-a-lambda-function)
Interesting. I have to say.... I really don't get the joke. /u/benrayfield - can you explain it? For what it's with to anyone who spent time on this: your efforts are not wasted. I enjoy learning about lisp, and am benefiting from being a lurker and hearing smart answers, even when the questions were being asked insincerely.
I think it is also possible that the threshold for being able to type coherent looking prose into a public forum is a lot lower than the threshold for being able to make sense of programming. The thing about computers is that they are infinitely patient. I can picture gavino doing some Ruby-on-Rails demo over and over and the same magic response shows up every time. And for him it never gets old, and he never can grasp what is going on. As for the expert responses, I think part of it is showing off to the other participants: look at how cleverly I can use this idiot's nonsense to make an academic point. It's a performance as well. The curious thing about BenRayfield is his ability to appear uniformly clueless in every subreddit he submits to, and his lack of repetition. Maybe some people are really that stupid: their language center is fully developed but their power of abstract learning is just not there. I think I have taught such people. They get by because others want to see intelligence, and manage to see it in the word salad.
Not sure why macros are used in Clojure, in Lisp they would not be needed for the described application. Doesn't look like the author understands Lisp macros. If we have a function and pass a lambda expression, then this lambda is a function object (possibly compiled to machine code) and not a list. CL-USER 14 &gt; (defun foo (f) (describe f)) FOO CL-USER 15 &gt; (foo (lambda (x) x)) #&lt;anonymous interpreted function 4060001044&gt; is a TYPE::INTERPRETED-FUNCTION CODE (LAMBDA (X) X) If we actually wanted to pass source code, then we would quote the expression and we can compute new code without the need to use a macro. We would the compute the derivate of the code and call the compiler on the derivate to have an efficient version. Again. No need for macros. For those interested in the basics of computer algebra implemented in Lisp, I'd recommend Peter Norvig's outstanding book 'Paradigms of AI Programming, Cases Studies in Common Lisp'. Edit: Here are two actual Lisp versions. With and without macro. (defun derivative (function variable) (if (atom function) (if (eq function variable) 1 0) (destructuring-bind (main &amp;rest args) function (flet ((der (x) (derivative x variable))) (ecase main (+ `(+ ,(mapcar #'der args))) (- `(- ,(mapcar #'der args))) (* (let* ((u (nth 0 args)) (du (der u)) (v (nth 1 args)) (dv (der v))) `(+ (* ,u ,dv) (* ,v ,du)))) (/ (let* ((u (nth 0 args)) (du (der u)) (v (nth 1 args)) (dv (der v))) `(/ (- (* ,du ,v) (* ,u ,dv)) (expt ,v 2)))) (expt (let* ((u (nth 0 args)) (du (der u)) (v (nth 1 args)) (dv (der v))) `(* (+ ,dv (/ ,du ,u) (expt ,u ,v))))) (exp (let* ((u (nth 0 args)) (du (der u))) `(* ,du (exp ,u)))) (log (let* ((u (nth 0 args)) (du (der u))) `(/ ,du ,u))) (cos (let* ((u (nth 0 args)) (du (der u))) `(* (* -1 ,du) (sin ,u)))) (sin (let* ((u (nth 0 args)) (du (der u))) `(* ,du (sin ,u))))))))) (defun approx-nr (function target start &amp;optional (tolerance 0.00000001d0) (n-iterations 100)) (let* ((variable (second function)) (code (third function)) (func (compile nil function)) (der (compile nil `(lambda ,variable ,(derivative code variable))))) (approx-nr-aux func der target start tolerance n-iterations))) (defun approx-nr-aux (func der target start &amp;optional (tolerance 0.00000001d0) (n-iterations 100)) (loop for k from 0 for res = start then (+ res (/ (- target (funcall func res)) (funcall der res))) until (or (&gt;= k n-iterations) (&lt; (abs (- (funcall func res) target)) tolerance)) finally (return res))) (defmacro m-approx-nr (function target start) (let* ((variable (second function)) (code (third function))) `(approx-nr-aux ,function (lambda ,variable ,(derivative code variable)) ,target ,start))) (defun example () (values (approx-nr '(lambda (x) (expt x 2)) 2 1.2d0) ; without macro (m-approx-nr (lambda (x) (expt x 2)) 2 1.2d0))) ; with macro simple example: CL-USER 8 &gt; (example) 1.4142135642780896D0 1.4142135642780896D0 
 lispm, you are moderator, right? Clojure has /r/clojure Scheme has /r/scheme Why bother responding to each "lisp in 100 lines in js or whatever", or "I've got parenthesis, so this is lisp". Why /r/lisp is not /r/common_lisp. 
You're both saying the same thing, but maybe not in the clearest way. My attempt: defparameter is used when you want to reset the value every time you reload your code. Especially if you want to be able to change settings by changing the defparameter form. Defvar is used when you don't want to clobber the current value by loading your code.
The first guy is saying that if you use `defparameter`, then you shouldn't use `setf` to alter the resulting variable at runtime ("you don't change the value while the program runs"). The second guy is disagreeing with that part, arguing that it's perfectly acceptable to use `setf` on a variable created with `defparameter`. 
They are actually quibbling over the meaning of the phrase "change the value while the program runs". /u/ncsuwolf is using it to refer to programmatically changing the variable, but /u/KDallas_Multipass is using it to mean a change to the variable by editing the defparameter form. So defparameter is for changing the variable's value by editing the definition, without restarting the image (i.e. while the program runs), while defvar is for when you only want to change the variable's value programmatically (i.e. your program does it while running). Both are correct.
`defparameter` makes it more convenient to revert the program's state variables after a test run. You can reset the program to it's initial state by re-loading the source file. This wouldn't be the case if those variables were defined with `defvar`. Then you'd have to explicitly `setf` them back to their initial values. 
And define helper functions early and often. The genperson function could use: (defun pick (list) (nth (random (length list)) list))
It can even work well for longer C tasks. Right now there isn't much in terms of error checking, but when that capability comes along, it will be even more useful than I've found it recently.
Project like these are really cool, I'd love to take a stab at something like this once I'm a more experienced programmer. Any pointers you can give? Great work by the way, really cool.
Just hit the ground running, and don't be afraid to start over more than once is the advice that I'd give.
It has C++ support now. And here's a video: https://www.facebook.com/jbakid/posts/10154049973656597 
Very nice advice, thanks.
I made twelve interviews at this year's ELS. I'll post them as soon as I'm awake enough and got a while.
And Pixie, https://github.com/pixie-lang/pixie
The image is available on docker hub [here](https://hub.docker.com/r/fisxoj/common-lisp-sbcl/) as `fisxoj/common-lisp-sbcl`. Let me know how badly I did and if you find it useful!
&gt; We're currently working on parsing the TeX sources of the specification to generate a more modern version of the CLHS. &gt; This might take a while. I wonder how the [spec](http://lisp-lang.org/spec/) will look like.
It actually looks quite good on a phone (which is what I read it on.) 
Good web page, but the ITA entry is slightly inaccurate. The name of ITA's flight search engine is "QPX". "Matrix" is the designation for one of many web front ends for that engine (apart from many carrier web pages, cheaptickets, Google Flights etc). Allegro CL was never used for QPX production. QPX during production timeframe was first CMUCL and then changed to SBCL, which it still uses today. ITA also had the now-canceled reservation system written in large parts in Common Lisp.
I'm trying to join forces with them. http://phoe.tymoon.eu/clus/doku.php
&gt;Big problem with CL today IMO is that it's hard to sell something where almost every resource is straight out of 1996. This is it. &gt;I will say he will kill his bandwidth cost though at the size of those images It's hosted by GitHub Pages.
Awesome! CL was my first real LOVE, and I've re-read either OL or PAIP at least once every couple of years. I'm not going to dive back into trying to use it for everything (Elixir scratches the macro itch for me nowadays), but I think we can all agree that Lisp deserves to have a nice brochure site. That tease about the HyperSpec, though ... mmmm. That's awesome. If you make a lightning-fast-to-navigate, readable-and-responsive version of the HyperSpec, I might just cry!
Cool. for /learn/first-steps I'd change `(format t "Hello, world!")` to `(print "Hello, world!")` as it's cleaner / simpler for n00bs
Certainly. I mean, the images _can_ be shrunk, and potentially served in different sizes for different screen sizes. I just haven't done that yet because I'm a lazy bum and I've been working on this project on and off for quite some time, so I wanted to get an MVP done ASAP.
For an example, see this c.l.l thread, where Kent Pitmann and Erik Naggum are both on the side of Scheme being distinct from Lisp: https://groups.google.com/forum/#!topic/comp.lang.lisp/Bj8Hx6mZEYI[1-25]
Saying that someone says anything isn't much of an argument, don't you think? Even if these are Common Lispers of a big fame as Kent Pitmann and Erik Naggum (they are clearly biased for instance in favour of CL). Besides except Scheme which has all the characteristics of Lisp (homoiconity, macros, writing in AST's, dozen of other, and given the random part of the sourcecode it looks definetely like lisp), we have others: clojure, picolisp, islisp, elisp, racket (arguably Scheme), LFE ‚Äì should i go on? I'm sure I could remember a few more. The argument that if it were a lisp it would call itself a lisp is so weak, that I won't comment on it. And while I agree that if you talk with Common Lispers and somebody says: lisp does something, he means the CL and it's obvious. On the other hand lisp-lang hints, that it's *the* lisp whatever it means, without any clear context. And the fact that there were some animosies between the two communities (CL and Scheme) doesn't make theirs common roots non-existant, like the fact I don't like my brother much doesn't put him outside of my family. It doesn't work that way.
Awesome! How can we contribute?
Ask /u/eudoxeea about it. I'm working on http://phoe.tymoon.eu/clus/doku.php myself, but I want to join forces with him.
While your link might be helpful for people new to the debate, you are somewhat missing the point: Whether Scheme is a Lisp or not isn't very relevant here, as there are also plenty of other Lisps besides Common Lisp and Scheme. If there is an authority on Lisp, it should probably be John McCarthy, and several sources claim that his wish was that we should use the name "Lisp" for the family of languages, not for a single language (still searching for the exact quote, though).
Well, there's also `princ`...
yeah, good point.
- What does "Requests per second using Woo, an HTTP server written in pure Common Lisp." mean? Is this a typo? - I'm not sure it's a great idea to brag about the tools, while showing a faked screenshot with a version of OS X that's now at least 5 years old. - The SLIME link is `href=""`, anyway, so even if somebody's interest was piqued by seeing Emacs on Mac OS X 10.6, it's not terribly helpful. 
Also for example some Racket developers say that Racket is a new language, different from Lisp and even Scheme.
&gt;What does "Requests per second using Woo, an HTTP server written in pure Common Lisp." mean? Is this a typo? I don't see how it could be. &gt;I'm not sure it's a great idea to brag about the tools, while showing a faked screenshot with a version of OS X that's now at least 5 years old. meh, I'll upload a realer screenshot some day. &gt;The SLIME link is `href=""` Oh yes, I did notice that just after publishing but forgot to change it. Thanks!
These communities long ago split up. My claim is that there is a set of languages which share code. As long as they do, they belong to one family. Once they only share an unspecific number of 'ideas' they are no longer one language family. &gt; I'm not claiming that Scheme is Common Lisp, or that the Common Lisp is Scheme. But neither Common Lisp is Emacs Lisp and none is LISP. My claim is that Emacs LISP and Common LISP are members of the LISP family. Where languages like Clojure or Dylan are derived/inspired/... It's possible to write non-trivial programs which run in Emacs LISP and Common LISP. This is not possible with Dylan and Clojure.
Very nice
Nice find! Lisps need more love!
Left-hand console panel?
I will be working with eudoxia from lisp-lang.org on this one!
The image is a screen shot is from a recently released game called Doom. The image is of a display terminal. The display has three panels. The one on the left has the title 'console'. It contains s-expressions. The s-expressions start with (setq...). 
It is nice to be able to define new documentation types for your new defining forms, and have system tools retrieve that doc. In addition, you'll want your new namespaces to work with IDE functions, such as TRACE, definition finding, undefine, etc. IOW, something like [the LispWorks Dspec system](http://www.lispworks.com/documentation/lw70/LW/html/lw-39.htm#pgfId-887589) (in many ways inspired by Lisp machine definition specs).
Yes many implementations have similar systems. for example sbcl has info system which basically stores all kinds of information like optimization, documentation, anything. but there are no portable way to do it currently.
as far as mop see [https://github.com/robert-strandh/CLOS-MOP-HTML](https://github.com/robert-strandh/CLOS-MOP-HTML)
Yes, thank you. I will be utilizing this to add MOP.
I don't see anything in the right hand panel. 
You can also !clhs in duckduckgo and there's http://www.xach.com/lisp/clhs-search/
True! Useful still though.
Fare said on a blog, low-level programming is just generating a binary sequence. I found it quite liberating. You can always craft bits the right way for a particular arch, if that's needed.
Why 'Quicklisp is not sustainable?'
Seems to be missing slides for talks 5-9.
I really like Alan Perlis' quote "A programming language is low level when its programs require attention to the irrelevant", which I think is both thought-provoking and also a much more useful definition than one that leaves pretty much only assembler as "low level". If the OP means to ask if Common Lisp can be used to poke directly at hardware, then the answer is that there is nothing in the Common Lisp language that prevents this, but whether it is actually supported depends on the particular implementation and system. (As is the case for the C language.)
Important part of Lisp tradition is that it is easy to implement original or slightly modified Lisp. Idea that these are not real Lisps is insulting. 
As other have said, it depends on what you mean by low-level programming. With that said, you may find the following video of interest: [Escape from the heap: low-level programming in Common Lisp](https://www.youtube.com/watch?v=njfyWgqZmkI)
To me this definition suggests that stratified design is the way for writing high level code. Your program is built upon a hierarchy of linguistic layers, each self-coherent. Stratified design is easier to practice in Lisp than it is in other languages, because Lisp offers a good set of syntactic abstraction facilities, where as they usually offer none.
If you mean low level, like system application programming, SBCL specifically has an interface to the POSIX (Unix) apis that you can use to write the same type of command line programs you would find on a typeical system. In fact, I would say it‚Äôs excellent for that, and the sb-posix package has been given some ‚Äòlispsms‚Äô to help with it.
Ah, nice to know! Thanks.
I write lisp (scheme really) in vim and I haven't had a problem with it. Although I'm not on windows.
It's not really a microcontroller, but I've heard that TeMPOraL from #lisp IRC channel managed to compile and run a Common Lisp implementation on Raspberry Pi. I think it was CCL because of native threads on ARM!
I was actually investigating this a while ago, because I had a discussion about it in another post. I used to program in assembler and was wondering how to inline assembler in lisp. Turns out some people were working on this, the way they were approaching it was what you just said, they made an assembler for the x86 and when you called the assembler with a parenthized version of the code it will translate the data to a binary vector which was then loaded to memory using FFI and called from there. I don't know how they passed values in though, but it was an interesting project. I can't seem to find the link now. Edit: Fixing some of my writing.
Can't speak for Lispworks, but emacs/slime is way better than the Allegro IDE. I do like Allegro lisp though.
I wouldn't say windows is painful to use and I'm not really willing to shell out for an ide for a language that I may or may not find useful in the long run. It hasn't been an issue for most of the other languages I've looked at.
&gt;I don't know what you mean by "a pain to set up on Windows". It generally comes in an executable or a zip file with an exe. For example, Clozure Common Lisp doesn't even need an installer, and it doesn't require any dependencies. I don't think it gets much simpler than that on Windows. Every time I've tried, there's been lists of dependencies that I'd need to get set up first that never quite worked. &gt;I will agree that Emacs is the only really viable IDE lisp offers, and I'd like to see more, but I will disagree that the community will take your head off if you want something else. A lot of Lispers use Vim (or whatever text editor) + simple REPL, and that works fine for them. I've tried asking for an alternative IDE (because I don't want to be using a text editor or vim either) on this sub and I've gotten my head taken off. &gt;Generally, I think, people asking about "text editors for Lisp" want a free IDE: which means Emacs. If they are willing to pay money, that means LispWorks or AllegroCL. If they just want a text editor... anything will work. So the most common response will just be EMACS+SLIME, because that is the best free IDE that we know of. What I want is a free IDE, like I could get for most other languages, that is not EMACS. Something like Eclipse would be nice. 
&gt; Every time I've tried, there's been lists of dependencies that I'd need to get set up first that never quite worked. If you are just setting up Lisp I think that it isn't much work, but it's admittedly a lot of work to set up Emacs/Slime/Lisp all just to try it out. Even setting up for regular development it's a lot of steps and deps. &gt; I've tried asking for an alternative IDE (because I don't want to be using a text editor or vim either) on this sub and I've gotten my head taken off. That's too bad. I guess my perception of the community was off. &gt; What I want is a free IDE, like I could get for most other languages Yes that would be nice. It would be good for the community too, I think, since it would bring in more people are put off by Emacs, but still like Lisp.
Are there any other public dists?
Nice! I want to get things like (mapcar (&lt;tattoo of lambda) &lt;something kewl&gt;) but many of them, to create a chunk of code :D 
Seriously? It was a while ago and search doesn't seem to be turning up my name. I don't know what to tell you. Either you can believe me or not. No skin off my nose either way.
I ask because all I can find is people being nice to you and making quite a few helpful suggestions for alternatives to Emacs. EDIT: This being the Internet and all, I don't see why we should have to take anybody's word on this kind of thing, when we could all just see for ourselves. I don't think it would be polite for me to link your past discussions, especially if the only ones I can find don't match your description. So I thought maybe you'd like to do it.
Lispworks offers a free limited version of their IDE that you can use to try it out. [Here:](http://www.lispworks.com/downloads/index.html)
Last time: https://www.reddit.com/r/lisp/comments/3d8x0x/share_and_discover_tutorials_lisp_is_missing/ct313bc
It'll be anything that involves the use of lambda :D So maybe mapcon as well.
Great read!
I've been writing CL for more than 10 years now and I can't find even one utility in RUTILS that I would like to use. All of them make the code less clear and somehow do not mesh with the 'feel' of the language. They do not seem 'lispy' for whatever definition of lispy, but instead conjure visions of PERL (*horror*). I dare say that the vast majority of ppl who write CL for fun will look at RUTILS (as they've done with similar projects in the past) in the exact same way as me, which is why the library will end up going nowhere. Alexandria, which is a similar library to RUTILS at least in scope, takes a far more conservative approach and ends up meshing with core CL. Which is why it's actually widely used.
Hi all, I found this really cool tweet and would love to be doing this on my MacBook (albeit it's a Pro). Does anyone know anything more about this? Does anyone have a VM image that can run this in something like VirtualBox, Veertu, VMWare Fusion? I've read about many attempts at getting a VLM working but almost everyone seems to intentionally leave out various details of the steps making it very hard to replicate. I'm not sure why the intentional obfuscation/omission. Thanks!
OpenGenera is not freeware, so I wouldn't count on VM image.
I find it a bit discerning that there are so many languages where the standard changes every few months or even more often. Why call it a standard at all if it's meant to be obsolete in a few months? How should I write a program if the language I'm writing against is going to change a few times as my program develops?
There is no working group, but you can contribute to improve it here. ;-) http://www.cliki.net/proposed%20ansi%20revisions%20and%20clarifications http://www.cliki.net/Proposed%20Extensions%20To%20ANSI http://www.cliki.net/Lisp%20-%20Next%20Generation There is also the Common Lisp Document Repository, where you can find a few proposals: https://common-lisp.net/project/cdr/
This might help: https://github.com/ynniv/opengenera 
It would be nice if some representatives from various vendors (open and closed source) did chat on a regular basis, if only to cross-pollinate and unify some aspects of implementations, especially quasi-standard extensions. 
Thanks, I've added it to my list above.
I think that the best place to address this stuff is CDR (https://common-lisp.net/project/cdr/). It's just a question of convincing the vendors to write a specification if they implement some feature and publish it there.
If CDRs were taken truly seriously by implementors, we wouldn't need the likes of CLOSER-MOP for example. Everyone would provide the MOP under a package like MOP or CLOS. If CDRs are used properly, great. 
Ha, this is the only tattoo I've been thinking of getting. Nice to see it actually done. 
I suspect it was ECL (Embeddable Common Lisp)
nice one :) yeah, I agree that Python is skyrocketing regarding the popularity etc., what I mean is that Common Lispers are proud of theirs standard, because the portable programs will work even in 1000 years when the archeologists will reconstruct the language, which truth doesn't hold if we count not documented extensions. Not that it's a big problem for me, but it's a fact that many praise the actual standard because of that.
Nope! Definitely not ECL, AFAIR.
All this talk of the Lisp Symposium makes me want to go next year :D
https://www.youtube.com/watch?v=ZXsQAXx_ao0
Scary, like a deadly slug crawling on your skin.
Fractaly spanning the whole skin surface.
Yeah, he was doing what I thought: https://twitter.com/RainerJoswig/status/722562656956215296
Here's mine. I was trying to go a bit more lispy. http://i.imgur.com/VMiowAV.jpg 
Was CL able to exist alongside Lisp Machine Lisp Because of packages? (Inter and Zeta Lisp) Are you looking for a ([My](http://www.myhdl.org/)) [HDL](https://www.google.com/?q=common+lisp+HDL) (port)?
I don't understand what you did and what you are asking. 
Did you follow the links? Could you, for instance, have a look at this [quick introduction](http://epsilonwiki.free.fr/lambdaway/?view=overview) ? Don't you find some elements of answer to questions about lambda calculus or Ycombinator via this iconoclastic approach ? Am I allowed to follow the Lisp way out of academic ways?
You're not talking about the book *Land of Lisp*, are you?
Thanks for your correction. I'm not native english speaker, sorry I'm french. Replace "out of main roads" by "out of academic ways" or something better, tell me. Did you find a few minutes to follow the links?
Thank you very much. I feel better :)
I looked at the quote from Richard Stallman: "Lambdatalk is neat, but since it does not have lists, it is more of a mocklisp than a real Lisp. Can you add lists to and give it the real power of Lisp?". I think to serious lispers things like ()s vs {}s don't matter much. Even having words being words and prefixing variables with : is fine. What you have is a really cool Domain Specific Language (DSL). It looks and acts a lot like Lisp, but like Stallman said: without the power of lists, it isn't as powerful as Lisp. One of the keys of Lisp is that "code is data", meaning the code is made of the same data structures used by the language. I don't think you are being iconoclastic or heretical, just missing a key ingredient to make it a full Lisp.
I think the ? form might also want to take accessors. e.g. for an object of class foo: (foo-bar obj) can become (? obj #'foo-bar) Clearly this is a loss for a single item access, but would be useful for chaining.
You should find in the [home page](http://epsilonwiki.free.fr/lambdaway/) a quick [overview](http://epsilonwiki.free.fr/lambdaway/?view=overview) and a progressive introduction to lambdatalk (one, two, three). By itself the wiki is a workshop, a place I'm working in, where I explore lambdatalk. You should understand then what is "the point of lambdatalk". You can also download and easily install your own wiki if you want to go further. 
Maybe related to "code is data", this is what Ward Cunningham wrote about lambdatalk: ¬´ I was surprised that the technique worked so well in so many cases. I knew that regex are highly optimized and the cpus themselves optimize sequential access to memory which the regex must have at its core. [..] Yes, this has at its heart the repeated application of a text transformation. The fact that it is repeated application of the same transformation makes it exceptional. [..] Repeated application of Regular Expressions can perform Touring Complete computations. This works because the needed "state" is in the partially evaluated text itself. ¬ª So I don't know if "code is or is not data" in lambdatalk but code and data are closely mixed. And regular expressions play on them everywhere, in the evaluation of S-expressions, in the evaluation of special forms, particularly of lambdas, in the construction of macros, see for instance [macros](http://epsilonwiki.free.fr/lambdaway/?view=macros). The Javascript code is simple and can be seen in [JS.js](http://epsilonwiki.free.fr/lambdaway/meca/JS.js).
It's really only confusing because there is a book by that title. Also, "off the beaten path" is a more idiomatic version of the phrase you used. But with regard to your page, I don't think it's heretical to use {}, and running the whole thing with a regex is a fun idea. Although I wouldn't say these are the most *practical* choices.
It's hard for me to understand what's going on here. It actually starts out well enough: "Lambdatalk is a kind of Lisp's dialect working on top of any modern web browser, freely downloadable and easy to install". But then it gets somewhat confusing: &gt; Please note that, contrary to other implementations of Lisp's dialect, lambdatalk catches S-expressions in a single loop working on a single Regular Expression, /\(([^\s( )]*)(?:[\s]*)([^( )]*)\)/g, and replace them by a value according to a small dictionary of standard primitives, [cons, car, cdr, +, *, ...]. As a user, why do I care? Is this just an implementation detail, or is there something about using regexes that makes this different from Common Lisp? Are you trying to write a small, browser-based lisp for interactive webpages? (You seem to say so, but your examples are pure mathematics and computer science.) Is it a general-purpose Lisp with a clean design? Or is it focused on math processing? Saying who Lambdatalk is designed for would be helpful. Good luck!
Bonjour! (Je suis qu√©b√©cois) I spent a few minutes on your website, your language is interesting, and I think most people would agree it has a lispy feeling. Now, I have to read further on this, but if I understand correctly, you are literally using regex on the text of your code. That's quite interesting to me, as I'm currently implementing a minimal language based on regular expressions. But I'm using a Kleene algebra on ASTs, not directly on text (my "alphabet" is composed of tokens). As interesting your language might be though, I must admit that the structure of your website is a bit confusing. It took me a while to understand it had to do with wikis -- you can use them as notebooks, right? It's a nice niche for a language and the concept kind of reminds me of [Boxer](http://web.media.mit.edu/~mres/papers/boxer.pdf). I'll come back later with some more comments, but a few remarks before I do: * *comment* takes 2 *m*s * What do you mean by *workshop*? A workshop is an *atelier* in french. Perhaps you meant a *work-in-progress*? (that's the meaning I get from one sentence) or an *environment* (that's another meaning I seem to get). Oh well... I'll come back in a few hours to comment further. 
&gt;Today, all those features, except for macros, are common in the popular languages. So the ideas won, but the Common Lisp implementations didn't -- perhaps because CL had a lot of legacy cruft from a language that goes back to 1958; perhaps because some people just don't like parentheses. Seeing how Clojure continues to gain traction in the industry, I suspect that the CL baggage is definitely more of a problem than the parens. I've been a fan of Lisp conceptually since I found out about it, but I simply couldn't get into CL even though I tried a number of times. When Clojure came out, it clicked with me almost immediately and the parens never really bothered me there. 
You need to put it in ~/quicklisp/local-projects/ , I plan to add it to ql soon. I know you managed to do that (your other comment in thread) ‚Äì but putting it here if someone else encounters the problem.
...that looks like it is from 1985
Thank you very very much :) for your constructive comments. You found one of the weaknesses of lambdatalk: because the arguments are used as regular expressions for the substitution, their intersection must be null. Or the intersection of :a and :ab is :a. And with Bash, Make and Rust, you gave me the solution, writing :a: and :ab: will work fine :) :) I don't understand {{lambda {a ab} {a} {ab}} x y}. When I try in my [sandbox](http://epsilonwiki.free.fr/lambdaway/?view=sandbox) I get (x ) (xb ) ? Could you give me more explanations? Thanks in advance. 
Nice, behaves fine on my phone.
The evaluation of {lambda {:a} :a} returns a reference to a function, a new constant in the dictionary. This reference is unknown, in fact it may change randomly depending on other lambda definitions. As you can see in [sandbox](http://epsilonwiki.free.fr/lambdaway/?view=sandbox), there is no interference with the lambda expression. HTML tags can be applyed on sequence of words. User functions are not variadic and {ub Hello World} will only return "Hello" in bold underlined style. You can see in [sandbox](http://epsilonwiki.free.fr/lambdaway/?view=sandbox) two workarounds. 
Yes, that's one of the things I want to do ‚Äì evaluate on which implementations does it work now and after the cleanup to provide a reliable info (and I will put it on the website as soon as I'll know). From sources you may infere, that the supported systems right now are: cmu, scl, allegro, sbcl, ccl, lispworks, clisp, ecl, but I'm not sure if it works fine on all of these.
ah. Well, there is gtkcairo backend which looks somewhat better (and a few others), but it's outdated and not sure how well it works now. Either way it's definetely possible to improve the look&amp;feel of it, but for now I want to focus on the codebase cleanup. After the cleanup we'll think about documenting how to create the backend and/or provide the theming support. The default backend is clx, which uses the core X window system protocol ‚Äì no wonder it's not pretty :)
I have the following in my .emacs: (slime-setup '(slime-fancy slime-asdf)) I thought this was the preferred method for a while. Setting the variable probably stopped working ages ago.
I understand now. But it doesn't look bad to differentiate globals and locals, for instance in: {def a Hello} -&gt; World {{lambda {:a:} :a: {a}} Hello} -&gt; Hello World {{lambda {:a:} :a: {a}} Goodbye} -&gt; Goodbye World {a} is identified as a global and :a: as a local. 
Why was the post above this one deleted? It was good and reasonably detailed.
&gt; Is there a link to the R. Kent Dybvig's paper? Of course. [Just Google it!](https://www.google.com/search?q=R.+Kent+Dybvig%27s+paper+Three+Implementation+Models+for+Scheme)
I'm back. You really should make [this](http://epsilonwiki.free.fr/lambdaway/?view=lambdatalk%20three) your landing page - only by reading this did I really grasp what lambdaway was. Now I see I got it backward. The wiki isn't a front-end to your language, your language is meant to be embedded in the wiki. Your (clever!) use of regexes has not much to do with the semantics, other than the order of evaluation; it compiles directly to javascript, from which it takes its semantics. Therefore, you don't need ASTs. Lambda encodings are all right. Therefore: * Your language is a lambda encoding embedded in javascript embedded in a wiki. * Lambdaway and lisps are based in their core on lambda-calculus; hence the lispy feel to it. Now, the big question: is it a lisp? I don't know. But it definitely is adequate for its domain: * its data is wiki text &amp; markup, its code is also text &amp; markup (using the {M N} format, quotes, ...), thus it is homoiconic. * The use of regex substitution for macros/eval is a good design choice. Its macros have leftmost-outermost ("normal") order and its evaluation has leftmost-innermost ("applicative") order. If its not a lisp, it's pretty close... 
When everyone is moving away from GTK (and X for that matter), McClim folks present it as a viable solution. McClim needs to be OS-independent and ideally run on top of something like OpenGL or SDL to attract new blood. Otherwise, it will remain a relic forever. It's not the 90s anymore, anyone thinking GTK or X11 are even remotely viable, needs to have his head examined.
Super happy to hear people are working on McClim! My albeit limited experiences with McClim was that it was a really well designed GUI toolkit (miles ahead of GTK, QT, etc). IIRC, it's the only instance I can remember where the GUI code structure actually matches the UI structure. A GUI is something user-facing, looks really matter! It does not have to have a bazillion bells, whisles and fireworks; just something slick (e.g. lighttable). Anti-aliased fonts at the very least :)
That quite the claim. My work is focused around a UI &amp; UX tooling and we have a pretty sweet GL UI engine. I can say without any shadow of doubt that it doesn't matter how good it is, if you can't give people native UI widgets/elements on a given platform they just don't accept it. GL driven UI is great (*if* you can do it well) but you have to be able to mix and match or people stay where they are. Also the idea you would do this on top of SDL is, let's say a poor start. SDL is very focused on games and you want to compete in UI these days you should have a long-term view to web and mobile. SDL is on mobile but again, is focused on games and hides some details you will need when you get far enough into this. That said I'd QT favor over gtk for linux desktop at this point I'm happy to expound on this but lets avoid head exams at this stage
Load the pixie theme and clim-freetype (or clim-truetype), that will teleport it forward through time to at least 1995.
http://www.cliki.net/machine%20learning
Cool. How comparable is MGL to TensorFlow? Do they differ more in philosophy/approach or feature set? As someone who would love to tip their toe in the machine learning waters in the next year or so, tensor flow is ace as the tutorials are very approachable, but I'd obviously love to be able to stick with the great tools and environment I already have in common lisp. 
the scale is smaller the better, so MGL is outperforming TF. but note that TF is for scalability on distributed / multi-GPU machines while MGL does not support multi-GPUs yet.
working on that :-)
There is also https://github.com/Incanus3/ExiL &amp;I think a few more. Though to start with lisa you could try the CLIPS manuals, tutorials, &amp;(the many)code-examples to get started; then maybe some related books/class-material/listserves/etc. You can also ask this again on the CLIPS email list, &amp;,you should add something about the application you want to build, as that should be useful info.
As I understand, the low level components of TF are written in C++. Python can be used as a compositing language for a network.
Thanks, I‚Äôll check it out!
Thanks for your insights :) Today I want to evaluate, on which CL's McCLIM works fine, and which need some work. I'll do it again after the codebase cleanup. One of the near goals is to plug some big baroque systems with the portability layers (it's been done with Bordeaux Threads for instance, but we have a few other parts which would benefit from taking 3rd party dependencies instead of providing it's own implementation ‚Äì closer-mop, trivial-gray-streams, opticl etc.). I'm also the ECL maintainer, so I want to make McCLIM as portable as possible :P Regarding CLX ugliness, truetype will be default soon, so it will be little less ugly. CLX would benefit from some love too, but I'm not planning to work on it right now. Default backend is CLX, but I don't see a reason, why we should get rid of other backends if they're functional (ie GTK) for users who want to go beyond the defaults. Thanks for the threading link and the feedback regarding the GTK :) Also it's a very good idea with adding the contributing page. Thanks, this is very helpful, I'm copying your post to my McCLIM notes :)
One thing that I've been unable to figure out is, what is the API that backends need to provide? (ej, what is needed to add a Backend)
Robert said, that he needs to think about the actual API, so it may change. I don't know how needs to be provided yet as well.
This is a really good idea. I'm a huge fan of Lisp for rapid development and testing out ideas, which is what the Arduino platform is all about. No doubt this Lisp engine is not exactly optimal with regard to memory usage (I did see a number in the docs suggesting that there would be room for about 1.4k cells on an suitable Arduino, and this is not a lot). And of course anything you could write in Lisp for the Arduino could be written more concisely and efficiently in other languages - but this is not the point. The point is that development in Lisp is *fast* and *elegant* and the language is ideal for prototyping cool ideas and generally "trying things out". Once you've got the logic worked out and tested (which is the tricky part) you can always transcode your source to a less friendly, but more efficient language. So top marks for this, and you can be sure that next time I head down to my basement to knock up an Arduino project I'll be testing this language out. 
This is great!
ok, requested the account
Port it to C64 and get a vast ocean of memory :-)
It runs for me on full Allegro. What flags did you set to make it pass on express?
I think there is still an error in misc.lisp. (defun setup-walk-list/mess () (setf *big-mess-list* (make-big-list 2000000)) (sort! *big-mess-list* #'&lt;)) The sort! generates a copy, so *big-mess-list* is not changed. I believe the last instruction should be (setq *big-mess-list* (sort! *big-mess-list* #'&lt;)) 
IMHO using CLOS for perf critical parts of code, like in gaming, is *very bad* idea. It's not C++ with its static typing. This is not to say CLOS is bad compared to *other OO* for perf critical applications. It just should not be used in the same way. For example, you can use it to nicely structure your runtime compiler via closures to efficient code.
I think that https://github.com/guicho271828/inlined-generic-function/ gives us best from both worlds. Unfortunately it doesn't work with ECL yet. I have investigating this issue on my todo list though. But yeah, raw CLOS isn't a deamon of speed (especially on ECL without the native compiler, which does dozen of additional optimizations before emiting code for GCC).
This is the perfect usecase for https://github.com/guicho271828/inlined-generic-function
Meh, it's a 2D-game engine focused on prototyping, I think that it's a decision based in reality. Not that your criticism is wrong in any way.
You need to make trivia build on ECL essentially
Does it matter for a game on 3x0ng's level of sophistication? We're not talking about the latest iteration of Call of Duty, here. The power to run it is well below the specs required by a modern AAA title.
Looking awesome! Nice work.
I made it build on ECL, CLISP and ABCL last week. Perfect timing maybe. https://travis-ci.org/guicho271828/trivia Plz wait for the next quicklisp update or use local-projects. (it also depends on the latest lisp-namespace) It was due to ECL specific bug [here](https://github.com/guicho271828/trivia/commit/ec63599d89fc0cfef3ee47130780599da130c303) and [I reported it to kochimanski](https://gitlab.com/embeddable-common-lisp/ecl/issues/247) but trivia has its own workaround ... oh but I didnt tested inlined-generic-function on ECL
Hey, it's me! :) And it's Kochma≈Ñski :P I'm tackling recent bugs on ECL today. Thanks
Hard to tell which one are the new.
As someone else pointed out, https://github.com/mmaul/clml looks good. I am just starting to kick the tires.
X windows backend is the reference backend. There is also backend for cocoa of uknown quality. Target goal is to create a portable toolkit for various operating systems.
These look atrocious to say the least. People are more likely to run away after viewing these, than wasting their time with McCLIM.
What sets McCLIM apart from the other GUI toolkits, like LTK?
For once it has a proper specification (like the Common Lisp itself) which was a result of many feedback iterations in previous Lisp systems. Moreover it's an interface manager, not just a way to present information to the user. You may read http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.54.6663&amp;rep=rep1&amp;type=pdf for some more information ‚Äì basically CLIM is niecely integrated with the language (Common Lisp) and you can trully separate the application logic form the presentation. All "gestures" from the user are translated to the commands, which are Lisp operators.
Ceramic is awesome, it's basically Electron (Atom's UI runtime) with a CL wrapper. The developer is very helpful when you find an issue.
As the maintainer of [Qtools](http://shinmera.github.io/qtools/), I'm naturally inclined to suggest it. I've written a lot of documentation for it to get you started and acquainted with the system, and I've taken great care to make the setup and management of things like foreign libraries a no-brainer. Usually you should be able to just quickload Qtools and be good to go on all three major platforms. Deployment is also handled, so that a single ASDF command is enough to prep a complete directory for you that you can simply zip up and ship to other people. There's a few example applications bundled with it, as well as other, more fancy toys like [Halftone](https://github.com/shinmera/halftone), [Parasol](https://github.com/shinmera/parasol), and [cl-gamepad-visualizer](https://github.com/shirakumo/cl-gamepad) that you can look at to see what is being done with it. As a side note, if anyone else has projects of their own that use Qtools that I'm unaware of, I'd love to hear about those! Also worth mentioning is [Qtools-UI](https://github.com/shinmera/qtools-ui) which provides you with some nifty standard components and other mechanisms that you can incorporate into your application to take away some of the boilerplate work you otherwise might have to do.
LispWorks [CAPI](http://www.lispworks.com/products/capi.html)? (Since you didn't mention "free".) 
And the license is extremely liberal - use the sources as you want, but acknowledge the original contributors.
I think the problem is that you used `(require 'slime)` instead of `(require 'slime-autoloads)`, but I'm guessing since you haven't posted your config. Anyway, I'll try to make `(require 'slime)` work even though `(require 'slime-autoloads)` should be better in general, since it leads to a faster Emacs startup time. (See discussion in https://github.com/slime/slime/commit/330877a6041bc68eb47f1525dea93d3629346bfc)
I just tried setting up qtools last night on both OSX and Linux for the nth time and failed yet again. I tried both on OS X El Capitan and on Linux Mint Rosa. I tried with SBCL and CCL. I tried with Qt 4.x and Qt 5.x. I tried it with Homebrew and I tried it with the latest Qt installer downloaded from the Qt site. I had the same result I always have: it starts out looking promising and somewhere along the way falls into a breakloop with a bunch of restarts I know nothing about. Then I frob around with them trying one after another to see if anything good happens, and reading error messages and groveling around in directories trying to figure out what to fix, and eventually give up and go back to hacking with Lispworks and CAPI. I would like it to work. There are some things I wrote around twelve years ago that I'd like to update, make cross-platform, and give away. No luck so far, though. I assume there are people for whom it pretty much just works. I assume there is something about the way I set my systems up, or maybe the incessant tweaking that I'm always doing, that causes problems. Regardless, no joy again. I'll probably try again in a couple of months. 
If 'standard' hardware is fine for you, this project of a Lisp-based operating system would be a start: https://github.com/froggey/Mezzano
I'm a bit flustered by this response because I don't understand why you haven't contacted me about this before or made an issue ticket about it. From the very scarce information you mentioned here it seems you're running into problems compiling the dependant external libraries. Have a look at the [qt-libs README](https://github.com/Shinmera/qt-libs), maybe you're missing a dependency that's listed there, or you could try its precompiled download option.
HTML + CSS. It's very easy to generate dynamic HTML with Lisp.
Might be more productive to * say what specific things need fixing * explain why McCLIM is a waste of time
I think it would be something near a month to have something usable (ie not pre-alpha quality). But I wouldn't advise starting yet, since there is some problem with backends which needs to be addressed and the backend API will most likely change during the upcoming weeks. After that we want to document the backend idiosyncrasies. 
How's Zwei in McCLIM? Is anyone working on CLIMACS at the same time, to build out a more ZMACS-like editor? Or on making the Listener demo more than a demo? It seems like having an editor and listener as part of the standard load-out would be helpful for adoption.
Are you updating this because you are writing an application that uses McCLIM? Or is this a Google Summer-of-Code project? Or are you just scratching an itch? Is there a list of "issues"? As in, I see screenshots, why isn't / hasn't McCLIM been used more? Are there any "plans", like a Windows port, or is that still too far in the future? It seem like an interesting project. Good luck. 
Worth pointing out that Emacs also has a common lisp mode
I'm going to take this opportunity to rant a bit. "Lisp Machine" is a bit of a red herring. The reason they got built long ago was that Lisp implementations on conventional (shared mainframe-type) machines were running into limits and Lisp implementations on microcomputers were unavailable or toys. What made them great is that the *development environments* were designed by Lisp programmers. For example, the debugger knew where your source code was at all times, and understood how the Lisp compiler worked and all the Lisp datatypes and memory layout. Your debugger also knew what editor you were using and how it worked. The integration with the OS was secondary: they wrote the OS in (idiosyncratic, really ugly) Lisp because Lisp was there and they liked it. The *really* low-level stuff was written in microcode. Now, there is some advantage from the *virtual memory* system working well with your garbage collection because they were designed together. But apart from that slight detail, what you really got was a GUI framework, an Emacs written in your native Lisp, and some add on packages like OO databases, etc. The network stuff was creative in some ways, particularly in being somewhat agnostic about the underlying protocols. Nowadays, people develop all sorts of things in languages that their OS knows nothing about: Ruby, Python, PHP, Java, whatever, *almost nobody cares* that their OS is written in C. What you really should care about is 1. Getting awesome libraries for your Lisp implementation 2. Advanced research on things like sandboxing, network and web and mobile application frameworks, etc. 3. Getting awesome Lisp development environments: good debuggers, good source file tracking, integration with version control, etc. 4. Tuning GC, making it support multiprocessor machines, and *maybe* doing clever hacks on the Linux kernel to help. *If* it is a barrier to any of the more important goals. 5. Improving compilers. 6. *Maybe* developing an Emacs and GUI environment that works well with a modern Lisp. None of those need Lisp Machines. They need good programmers who can do hard work.
Generally the Lisp landscape looks much better now than in 2000. The things you list are definitely a good direction.
Not to mention that Le-Lisp, due to the LLM3 virtual machine, ran on commodity hardware (on around a dozen different architectures) and was competitive with the Lisp Machines of the time. On a DEC VAX 780, it actually benchmarked *faster* than the Symbolics 3600. My point is that even by the time the Lisp Machines were commercialized, Lisp implementations for commodity hardware had already caught up in terms of performance. Are there architectural things we could do to make Lisp run even faster? Yes, but unless you're able to *also* keep up with all of the tricks and optimizations that a modern amd64 chip does for performance, you'll probably still wind up slower simply because all of those optimizations can make up for the performance lost to architectural mismatches.
The best place to start is the McCLIM's website. It links to the mailing list and the irc channel #clim on freenode: https://common-lisp.net/project/mcclim/ 
One reason LispMs were cool is that the entire system was unusually transparent. Everything right down to the microcode was written in Lisp, and all of the sources were at your fingertips all the time. Having a single language from top to bottom along with sources to everything plus a system that's able to present the source code to absolutely anything you want in a second or two--and enable you to change it right now, and to revert easily back to what it was before--is completely different from anything available now. Most people don't miss it, I think, because they don't know what they're missing. I had the opportunity to work on writing another system that was Lisp almost as far down--not-quite--and that was extremely cool in similar ways. We didn't get as far as the LispM companies did, but it was deliriously fun and mind-expanding trying, and it remains one of the best and most educational experiences I've ever had. 
CAPI is not cheap but it as hassle-free as you can get in Lisp world.
It's not used more because: + It was tied to X, so not really cross-platform. Those who will say "just run an X server" please shoot yourselves, now. + It looked atrociously bad by 2000 standards (nevermind now, it's just a bad joke at this point in time). Look at the fonts, FFS. + It was dog slow and "felt" like shit. No double buffering, tearing, slow redraws and so on. This could all be related to X being a pile of shit but it's the perception that counts, not the technical justifications. THE UI IS THE PRODUCT. This is a lesson that McClim folks never quite understood. 
I feel like this post is a troll more than anything.
1. You have to be sure that it's not a beginner. 2. BenRayField is a troll (example), and people know it.
I don't think it is, I understand his frustration. If you look back 4 years at his Lisp submitted stuff it's all very reasonable.
Just downvote, all you can do.
I believe that a good FAQ could be a decent troll-mitigating tool. Trolls' questions are usually not very sophisticated, and being redirected to a FAQ item frustrates the trolling effort. OTOH, if a troll asks an apparently non-trivial question, even a trolling seed may spark an interesting thread.
I Like the idea of FAQ, I suppose the only caveat is that people has to maintain it, I tried the Nickodemus' CL FAQ in the sidebar and it did not work for me. The [FAQ in Cliki](http://www.cliki.net/FAQ) is not very extense and has no link in the main page, you have to search it. A possible solution would be to have a /r/lispfaq subredit and redirect people there, or as a contingency redirect them to /r/learnlisp and at least keep trolls outside of /r/lisp. 
**Wat?** I don't see any trolling going on on /r/lisp right now. Point me to the posts you suspect of being trollish.
I wish I agreed. Modern IDEs and environments have good features, to be sure, but on the whole I think they are mainly larger, slower, less capable, more cumbersome, more complicated shadows of the better systems they have replaced. I have a younger friend who is an accomplished programmer and whose native environment is .NET. (I remember when .NET was a gleam in Greg Whitten's eye.) He reacted to his first proper glimpse of a Smalltalk system with astonishment at how small, fast, and featureful it was. If you haven't used an old-fashioned Lisp or Smalltalk or Oberon system enough to understand its advantages thoroughly then it's hard to convey what's good about them. They weren't consumer products, designed so that their advantages are immediately obvious to a casual observer. It took time and ambition to come to understand them properly, and it takes time and ambition to explain them. The process of explanation is further complicated by the good features that modern systems have. Those features, and the inevitable observation that old systems look, well, *old*, distract from understanding the sometimes subtle power of the old environments. For a classic example of the problem I mean, read through the messages in this old USENET thread: https://groups.google.com/forum/?hl=en#!topic/comp.lang.lisp/XpvUwF2xKbk%5B101-125%5D In it, a fan of GNU Emacs questions whether there was any value in the old Lisp machines that is not captured by Emacs. Kent Pitman tries with mixed success to explain what the other fellow is missing. In that thread you can get a taste of what has been lost, but perhaps more importantly you can catch a glimpse of how hard it is to explain to someone who hasn't understood it from their own experience.
Who is gavino? The user /u/gavino has no comment history, and I don't recall seeing him before.
A very persistent and long time troll of c.l.l. who always asked either very basic questions about Lisp, or questions about how well CL compares to other languages for anything from databases to web stuff. He seemed perpetually stuck on the basics of CL, unable to learn anything. Also, he'd periodically break out into anti-semitic, anti-government rants against Obama, liberals, the Democratic party, Larry Ellison... I don't think he was all that mentally sound.
I fully agree. Besides my own experience with Smalltalk and Oberon, as I mentioned I also hunt for history of computing. I have spent endless hours hunting for Xerox PARC, ETHZ, DEC/Olivetti, Genera manuals, papers and movies. And keep on doing that. From what I learned from those findings, coupled with my experience, UNIX being embraced by workstation startups in the 80's alongside many management misfortunes killed what could be a wonderful computing experience. We had interactive computing systems that the current ones only kind of come close to, implemented in safe systems programming languages. Hence why I cannot get why some find so great about using their computers as a PDP-11. If only they could understand how a Xerox PARC REPL felt. Thanks for the link.
Interesting. I haven't been on USENET since Time Warner stopped providing access to it.
&gt; It includes a database, web application framework, and a Prolog engine all as part of the language. Impressive, I didn't knew that PicoLisp has these features built in. I have a Raspberry Pi 2 laying around, maybe it's high time I try playing with PicoLisp on it. Also, excellent website &amp; documentations. Keep up the great work! ~~EDIT: Does Quicklisp works with PicoLisp?~~ NVM, my bad.
Quicklisp is a Common Lisp application, so no, it does not.
Why not statically build with musl or ulibc, that would bring the container size down to the absolute bare minimum?
Just trimmed from 170MB down to 14MB!
Wow, that's impressive. 
It seems that the new container broke the link in the OP. Here is the new link, I think: https://hub.docker.com/r/progit/docker-tinycore-picolisp/ 
Oops, corrected thank you. Named changed due to the way automated builds just take the name of the repo directly from Github.
Thank you. After compiling PicoLisp in the container I simply copied the build into a fresh container and linked the binaries following the typical instructions found in INSTALL.
Related links: - [Source code for the MIT CADR Lisp Machine.](http://www.unlambda.com/mit/) - [CADR emulator.](http://www.unlambda.com/cadr/)
https://github.com/melisgl/mgl
s/doubt/questions/ That use of the word "doubt" is only idiomatic in Indian English.
Yeah spend whole day on it, awesome stuff. Im working on running it on an IBM 704 emulator. P.S - and the amount of original papers, dame. Happy lisper.:D
One buys things for some reasons; there are reasons people buy commercial products instead of using free/opensource: * stability and quality of the compiler * IDE * "goodies" included * support All these reasons may be appealing for some and not interesting for others. So, it all depends on one's usage of common lisp. 
Very cool!
You can actually try to edit color theme [using this extension](https://github.com/acelent/lw-editor-color-theme) and take a look at [my theme extensions](https://github.com/fourier/lw-config)
Very cool project.
In this here [NokoLisp](http://timonoko.github.io/Nokolisp.htm) there was a special command "reclaim" which explicitly moved an object to garbagebin (in addition to regular collector)... However the Lisp-to-C translator had only "reclaim", so you had to design the program so that the garbage-collection was not needed (much) if you wanted to compile it. - "*TN-tools in Nokia were automatically compiled into C-code to be run in VAX-computers. Compiled C-code did not have garbage collector, there was separate reclaim-command for discarding used data. If you managed to run your program without ever hearing the BEEP caused by garbage collector, your program was ready for VAXing.*"
Is it possible to construct recursive data structures using this approach?
Yes and no: You could implement a primitive in C that helps to construct recursive structures. Maybe like this: (let ((start (gensym)) (middle (gensym))) (rec `((,start (1 2 ,(+ 1 2) . ,middle)) (,middle (a b c . ,middle))))) ; =&gt; (1 2 3 a b c . #4) 
The day LW goes open-source is the day that Lisp wins. Emacs is the biggest barrier for mass adoption imo. I was really excited when Light-Table was being talked about because I thought Chris Granger would think "Oh, yeah let's include CL and Scheme and change the world" and then announced Python support. The idea that a development environment needs to be thousands of dollars needs to die, sooner rather than later. 
Mr. Paul McJones has already done that: http://www.softwarepreservation.org/projects/LISP. But I am sure he will be happy to receive your contribution.
If you have a commercial need, then yes. sbcl can be quite fragile, and a bit on the slow side on compiling large projects. Additionally it's memory consumption is typically double the other two options. sbcl is quite fast however at most things in comparison. Feature growth is much faster. Very rarely will you need something only available in Franz/LW. http://zeniv.linux.org.uk/~ober/clb/ for reference
You can still get www.isi.edu/isd/LOOM written in Lisp, and even PowerLOOM can be used from Common-Lisp. There is also reasoner.sf.net &amp;quicklisp has: gbbopen (&amp;I like it's KM). There are a few from textbooks that incl code: http://norvig.com/paip.html https://github.com/aimacode/aima-lisp &amp; http://www.qrg.northwestern.edu/BPS/readme.html &amp;yes you can get: https://github.com/briangu/OPS5 &amp;a few others I think still.
Sweet, what are your view on approaches like rust's borrow semantics?
&gt; how so many, educated and intelligent people are unable to spot a troll? most autists don't perceive sarcasm and other subtle forms of humor
ah, the good old days of unmoderated usenet... today you're silenced for expressing your opinions... BTW, first got here following the whole lisp-&gt;scheme debacle... I used to roam on /. too...
1. Make the REPL usable (it currently aborts the program on the first error) 2. World domination Actually, I just want to have a usable programming system that won't frustrate me due to its complexity. The idea for this project was caused by me having to debug garbage collector problems...
I don't really have a competent opinion on that since I never used Rust. I think one shouldn't judge Rust by the first impression that its memory management causes work, because maybe it becomes simple after getting used to it. But Bone Lisps explicit regions are probably easier to get started with, at least if one has no problems with the immutability of objects that goes hand in hand with them.
The streaming SPARQL https://github.com/aaltodsg/instans has RETE under it as well.
Nice, and very timely. My sons (8 and 10) and I are building games in Lisp right now, so finding some of these libraries might be helpful. 
Come hang out on #lispgames on freenode irc as well. All three of those people and many more are there a lot
Thanks to anyone who takes a look at this!
How many hashtables are you making? One per file? You could just increase the size of the heap http://stackoverflow.com/questions/7181183/how-to-configure-sbcl-to-use-more-ram-when-started-through-emacs
 &gt; (setf (gethash hashname *global-names*) (make-hash-table)) this seems a bottleneck (hash table is large). Also, &gt; (concatenate 'string name "," gender) This conses a lot.
The whole data set in ascii is ~20MiB. I don't think that's too large for my laptop which has 20GiB..
This fixed it! Thank you! How did you know to look for this? Was there anything in the output above that you used to determine that the test function for the hash table was incorrect?
It's a common mistake new lispers make when using hash tables and strings.
I am glad there is more innovation in the space of compiler-managed memory.
It's, apparently, a very active area of research. There's a (surprisingly long) list of Lisps without GCs mentioned in [this](https://www.reddit.com/r/lisp/comments/4mtktn/bone_01_lisp_without_garbage_collection/) post.
That's a really interesting idea! Though, I'm not aware of any projects that have attempted to do this. I don't see why it wouldn't be possible using reader conditionals (a la [cljc](http://dev.clojure.org/display/design/Reader+Conditionals)) and a new, common library repository. I suppose the reader could also figure out which existing repository (Quicklisp, Maven, etc.) it should reference. 
[Looks that way, yes.](https://github.com/eriksvedang/Carp/blob/master/examples/game.carp#L10)
Thanks! Much appreciated.
In my experience, since common lisps tends to not be "batteries included", real apps require you start reaching for libraries. And even if a lisp has good C FFI, I probably dont want to roll my own bindings if I can leverage someone elses work. Even ignoring quicklisp (package management) for a second, how portable would standalone CL libs (with no dependencies) be for use in carp, picolisp, etc? 
You could use or borrow the format from: http://vindinium.org/
Very cool, what type system will you be using for this?
Yup, I develop on OSX but both Windows and Linux are being worked on. Since the goal is to use Carp for games it's a high priority for me to get it running equally well on those platforms (and iOS/Android).
Barebones [Hindley-Milner](https://en.wikipedia.org/wiki/Hindley‚ÄìMilner_type_system), nothing fancy. Might extend it with a few niceties eventually.
Is this from the Author of Else Heart.Break()?
If you're into this sort of thing, note that each summer there is an ICFP contest which almost always has AI elements and is often about creating a program to play a game. It can be fun and I'm a member of a team that does it in Lisp (usually Common Lisp, though this year we are thinking about Clojure, not sure at this point). Drop me a line if it turns out you didn't hate this and are interested in spending your weekend of August 5th-8th in similar fashion.
Ya, I was really confused by this as well. Oh look something neat ported to Lisp Machines.. Nope.. Arduino and Linux.
https://wiki.haskell.org/Haskell_Lisp check Liskell ;)
I always feel that if Lisp compiles to C it's a cop out :( Might as well just write in C.
 ; du -sh . 52M . ; time sbcl --script yob.lisp &gt; yob.txt 15.69user 1.42system 0:17.34elapsed 98%CPU (0avgtext+0avgdata 395948maxresident)k 108728inputs+57936outputs (287major+509934minor)pagefaults 0swaps ; For comparison, the python version: ; time python2 yob.py &gt; yob.txt 6.03user 0.13system 0:06.17elapsed 99%CPU (0avgtext+0avgdata 285776maxresident)k 0inputs+106416outputs (0major+81845minor)pagefaults 0swaps ; time python yob.py &gt; yob.txt 7.52user 0.09system 0:07.63elapsed 99%CPU (0avgtext+0avgdata 245308maxresident)k 0inputs+106416outputs (0major+79441minor)pagefaults 0swaps ; So not great yet, but not horrible. 2x worse.
What problems do you run into without "quicklisp per project"?
No.
Awesome, will check your solution out. And yes, it should print 0 for empty years. Thanks for your work and code! Will help me learn üòÉ
You should be able to do that with i.e. `ros use sbcl/system`. Roswell will install its own version of sbcl before using any Lisp installed by the system package manager, though. [[source](https://github.com/roswell/roswell/issues/121#issuecomment-179793605)]
There are those who argue that a lisp which compiles away the list structure of a function is a cop out (what? no fexprs!?). But lisp is an increasingly broad family of languages.
no, roswell does not require you or your computer to have any implementation beforehand. You can use roswell on e.g. a fresh ubuntu/arch box / Mac. (well, ubuntu requires curl4 and autotools)
I've just now started focussing on 64 bit, turns out there is quite a bit of code changes and testing to be done - pLisp segfaults all over the place right now in 64 bit. Apologies, hope to fix these issues shortly.
Thank you! This manual has clarified many points of the Genera configuragtion for me. It contains a lot of interesting tiny bits. I have configured virtual machine with old Ubuntu to run Genera recently. It works OK so I can load all of the loadable systems into a running image. I should make an addition. If some keys on your keyboard did not work as expected you could try to set X keyboard mapping in the Genera to the NDS (whatever it is). You can do it with the following command: Set X Keyboard Mapping &lt;space&gt;&lt;space&gt;nds&lt;enter&gt; This command needs to be entered every time after Genera had started. This paramater won't save into the world image. It is possible to set keyboard to the NDS using following lisp command too: (X-SCREEN::COM-SET-X-KEYBOARD-MAPPING (X-SCREEN::DEFAULT-X-SCREEN) :NDS) The right place for it is lispm-init.lisp init file, but unfortunately I can't figure out where to put this file to get it loaded after logging in into Genera. I would appreciate any help with this. BTW you could find some interesting Genera configuration tricks by googling "lispm-init" or "lispm-init.lisp". Also it is possible to use genera from the Windows too. https://www.youtube.com/watch?v=12USa3gU_oU Open Genera is definetely not an easy thing to configure and get running. ---- Edit: minor change to the keyboard type selection command.
You should email the original author with your findings. I only post the link here.
Wow, that project of yours sounds interesting! I agree that ICFP would be fun and right now I'm working hard on this program. It's a really good opportunity to learn code, and I also believe we're up against great competition. Where would we begin if a new member like me would join the team?
In your #'tok (as an aside, reading this comes out as "hash tick tock" to me, which is humorous) function, I'm curious why you're using the let / setq / append / cons pattern instead of a collect? E.g.: (loop for c across s for x from 0 collect (cond ((char= c #\+) '|+|) ...)) Also, #'append is inefficient, since it has to walk all the way to the end of the first list. As your list gets longer, this function will be less and less efficient. A standard idiom for building a list like this (say you don't want to use the `loop` macro's `collect` action) is to build the list backwards, and then reverse it at the end. This means you only do one "expensive" traversal of the list: (let ((res '())) (loop for c across s for x from 0 do (cond ((char= c #\x) (push '|x| res)) ...)) (reverse res)) Some people don't like the loop macro, and would instead do this with a recursive function or with `#'dotimes` and indexing on the string. Personally, I love the loop macro, and find it very concise and expressive. 
Yes, i know about append, but i couldn't find a better way. Had totally forgotten about push. Between push and collect is there a big difference in performance or just in style?
As I wrote up my comment above, I thought to myself, "I wonder how the loop macro implements `collect`?" In SBCL, at least, it's not a question that `#'macroexpand` and a quick glance can answer, so I gave up. Looking at it more closely, I see a gensym for the `head` and one for the `tail`, and some uses of a loop-dedicated `rplacd`, so I suppose it keeps track of both ends of the loop and directly extends the tail. That would be better than `#'push` followed by `#'reverse`.
Indeed -- I would think that to do it right, building in a REPL using swank would be essential for making a good Lisp extension. I do see some [prior art](https://visualstudiogallery.msdn.microsoft.com/6a94b530-e71c-4dda-979f-bf3b0d3a1c81) that appears not to have implemented any REPL feature. 
Msbuild is the standard embedded in the visual studio, that works alright on Windows, it's also supported by mono. 
It was really a rhetorical question, representing the sort of thought process one *might* go through. With msbuild, you still need a project file, which will be loads of fun for a newb to learn how to build anyway. The point is that moving into a new full-size dev ecosystem is going to be non-trivial no matter what.
Great read. thank you very much. keep them coming.
Some investment is expected but there are differences. Comparing Common Lisp to C# we can see some things that are not good for helping the adoption of common lisp. IDE to work. C# download Visual Studio Community, 1 step. Common Lisp you can go for LispWorks or Allegro to do it in 1 step too, or go can go to the recommended route of emacs/SLIME/common lisp implementation. The only way I've been able to get it is some years ago when I installed Lisp-in-a-box. The difference in ease of installation is quite big. Ease to tinker. In Visual Studio theres the New Project... in where you can choose a skeleton of a solution that you can flesh out later, easy. In a REPL you can play and try things, but there's no easy way to get an skeleton to flesh out (at least not that I found in LispWorks, and not that I know in slime). So you have to search for information how to start projects, and their typical structure. So, going by the recommended route you can either have a C# project in no time, or be still either configuring slime or searching how should your kind of project be structured and what libraries to use if you go for the common lisp route. To invest in the language is expected, having to fight the interface is not ok.
On your second point, I think it's entirely cultural. We Lisp folk are essentially the quintessence of the non-IDE faction in the programming world. For me, it doesn't really matter what language I'm working in, I'm wrangling source files in Emacs. The only exception for me is when I am using C# -- in that case, I use Visual Studio, if for no other reason than auto-complete (for the life of me, I can't remember that API). On the other hand, I'm a niche language hobbyist, so I'm very used to picking up new languages with no tool support beyond an Emacs major mode. It's my comfort zone. For people trapped in the IDE, I can see how uncomfortable it is. The only time I've been completely and utterly incensed at the IDE world is when I was trying to do embedded development for STM's cortex microcontrollers. Burn those IDEs with fire (ha ha, only serious). 
1) It's two-fold. The poor OS support AND lacking clear process is what makes it difficult. Then you have the personal limitations, my time is limited and spending two hours trying to make something work is not what I want to do. 2) The project thing is just a basic skeleton that puts you in a good direction. An example would be a program that asks for your name and prints it, another would be one that makes the same but with a GUI. These kind of tools help you because you can then start working on the real problem, not on the structure.
I only meant to say what I said about windows in order to say "some work will be required of the user". Things to look out for in windows is that emacs and some lisps disagree with what is considered the "home folder" so you have to explicitly fix this so that your lisp init file (which will load quicklisp for you, as well as find your .emacs file) can be found by your lisp, as in if you were to try to "find file ~/.ccl-init" in emacs, this may be written to a different place than expected by ccl. Also recently discovered, if you use the sbcl installer, the environment variables that it sets don't become available when you invoke sbcl from windows explorer until you restart. This whole path issue may be resolved in recent years, but it was the first gotcha I've run into in the past. once you decide you need to put your code into a project, the quicklisp author wrote quickproject, the salient function is (make-project where you can define the path to where it will be initialized (i recommend the quicklisp/local-projects folder) and also what dependencies you initially wish to require. As you change dependencies, update your .asd file to reflect this (and if you have running code from this package for which you wish to pull in dependencies, re-running the ql:quickload function on your project will pull the new deps down) and the package.lisp file if you wish to "use" symbols from your dependencies without having to explicitly call out the source package name. Native repl experience will vary from system to system, while SLIME in emacs is powerful and more consistent (think autocomplete, history navigation, jump to symbol/function definition, function prototype suggestions, etc) not to mention having paredit, if you haven't heard, which is a mode in emacs for helping keep your brackets and quotes closed, while also allowing operations to manipulate s-exp's like switching them around or promoting them etc. For posterity, if you have to do this all again, the path I recommend is as follows. 1) obtain emacs and your lisp of choice, if sbcl use the installer and reboot post installation. if ccl just checkout trunk. 2) download the quicklisp.lisp file. 3) add sbcl or ccl init scripts to your path. in ccl you'll have to make these by hand but they are two line bash scripts that simply set env variables for you and pass arguments to the real binaries (i should submit mine for inclusion in ccl trunk perhaps....) 4) use sbcl or ccl --load /path/to/quicklisp.lisp. read the prompts and add quicklisp to your init file using the suggested commands. to test success you can (quit) and restart sbcl/ccl and verify that (ql:system-apropos "drakma") or the like, function. 5) (ql:quickload "quicklisp-slime-helper") follow the instructions, which will involve pasting some provided code into your .emacs yourself, be sure to change the variable describing the expected inferior-lisp command to be your choice of lisp. 6) restart emacs and invoke M-x slime. After this, if you'd like paredit, go to this [this](http://y.tsutsumi.io/emacs-from-scratch-part-2-package-management.html) link, ignore the part about making two separate files, and add the (require 'package) block of code to the top of your .emacs file, save, restart emacs 7) In emacs, M-x package-list-packages, C-s paredit. might have to keep hitting C-s to get the package itself rather than text in comments (I don't know of a better way to do this.) By including marmalede AND melpa, you get a repo with cutting edge package versions as well as a "sort of" more stable, slower release. You're welcome to add either version of paredit, packages with date prefixes are usually the cutting edge versions. put the cursor on the paredit line and hit i then x, you'll be prompted to install the package. restart emacs and try it out. You might also want org mode. You can make paredit-mode automatically enabled upon editing lisp buffers, but I invoke it by hand. once you use m-x slime to start a lisp, going to the *scratch* buffer and invoking m-x slime-mode will allow you to send forms to your lisp for evaluation, don't forget to also enable m-x paredit-mode. in the future, M-x package-list-packages and M-x package-refresh, followed by u "for update" then x will update your currently installed packages with their latest versions. in quicklisp (ql:update-client) and (ql:update-all-dists) will do the same for ql systems. Optional, (ql:quickload :clhs) and follow the instructions for installation. this lets you put your cursor on a symbol (or be prompted for a symbol, with tab complete) and invoke C-c C-d h and have hyperspec lookup occur on a local copy of the spec. with the cursor on no symbol you are prompted in the minibuffer for a symbol, which you can tab complete. M-. finds definition of symbol under cursor or prompt, and M-* browses backwards from such browsing. If you wish to start your lisp separately from emacs, include --load /path/to/quicklisp/dists/quicklisp/software/slime/start-swank.lisp, and later in emacs invoke M-x slime-connect (defaults should work) and be connected. you can alternatively invoke m-x slime a separate time to fire up a new lisp, buffers in slime-mode will indicate on the status line which lisp buffer they are associated with when you invoke slime-compile and the like. Some output may be redirected to your *inferior-lisp* buffer, so if you do something expecting some output, don't forget to invoke (force-output *standard-output*) and then check in this buffer for your output. I'll admit that some of these instructions might be unnecessary now and I am of course open to corrections, but this path gets me up and running. On second thought, I do these same steps on OSX. I guess on linux some of this would change and I'd get emacs from the repo. If this helps great and any questions let me know. edit: italics text is supposed to be surrounded by asterisks, i.e. *inferior-lisp* is really *inferior-lisp* 
Sorry about this reply, I just have to get it off my chest, I've installed Gnu Emacs and SBCL, ECL, CLISP and ABCL in several windows machines, using the same process for all of the distributions, and since I was a newbie I was able to get it to work quite easily by installing Quicklisp and then SLIME-HELPER, so I fail to see what is so complicated about it, afterwards I modified my .emacs, which if you use emacs to edit it is really easy to find, C-x C-f and then in the minibuffer delete everything and type ~/.emacs, the ~ will be replaced by the right directory in windows too, and it is called .emacs as in a Linux, Unix or FreeBSD. With the proper configuration I was able to have auto-completion, and contextual pop-up help, add paredit to the mix because is the right thing to do, and all of this makes for a great workflow. But enough ranting, I will just say, whatever effort manadonada and other people (hopefully you won't leave him alone with the task) are going to put on a Visual Studio extension is good, and I think is worth it, since there is a market for it, and once it is done I bet is going to be just as complicated to setup as in EMACS, but you will be in your preferred environment, which is what really matters, giving people what they want/need. Again sorry about the reply, but I hear this argument of Emacs being difficult to setup all the time and I just don't see it, maybe is me. Edits: Correcting some badly constructed phrasing.
Look at [quickproject](http://www.xach.com/lisp/quickproject/), and projectile on emacs also helps.
Ah, cool -- I'm a quicklisp user, but hadn't run across quickproject. It looks OK. The [documentation](http://www.xach.com/lisp/quickproject/) is good for someone who already lives in the Lisp community, but a guide that's a little friendlier might be helpful for a newb. But then, there's nowhere to put such a guide, is there? 
So it sounds like there are issues with the installers that are actually *bugs*, then? Lots of things install and successfully update environment variables, so it seems like that would be a misbehaving installer. On the .emacs file, is there a good reason that quicklisp-slime-helper is loathe to edit the .emacs file for you? It's S-expressions, for goodness sake, and all you're doing is appending to it. I'd think it could at least ask, "Would you like me to try to add it for you (I'll put a backup in \&lt;path\&gt;)?"
As for the former, sort of. Its been common in the windows world to have to restart windows after running some installers, so this isn't too unexpected, however what I noticed was that while opening new command windows would be loaded with the correct environment vars (indicating the installer did make some change) I went in to the system ui for editing the env, saw that the change was reflected there, committed and reverted a spurious change to the var, and everything was working. In my case I had an old installation path that was being referenced by the new one. Path work with CCL seems to be less of an issue as in I only recently started setting ccl_home for use with ccl in later installs. SBCL seems to need it. Regarding restarting emacs after changes to .emacs, you can actually eval the buffer in which you've opened the .emacs file and have the changes take effect immediately. A slightly longer discussion is necessary if you have a complicated .emacs, but suffice it to say if you're starting from scratch you can eval the changes you make to the file immediately and not have to restart emacs. Regarding quicklisp writing the lisp init but not the emacs init code, I don't know.
Cool. Thanks for the link.
&gt;except that on windows isn't called like that C-x C-f '~/.emacs' works fine for me... I've set up geiser and cider on windows, I don't know about slime. 
[FAQ](https://www.gnu.org/software/emacs/manual/html_mono/efaq-w32.html#Init-file)
On the last line... well, my patience was short when I was at that point of the instalation, I did not read it. Now I have two different files, a .emacs that I don't know where it resides and an init.el that I do know where it is...
Part of that frustration comes from the fact that Emacs is still configured like a Unix application, even when it's running on Windows. It clashes so hard with the Windows philosophy that it makes a pretty unpleasant user experience in these situations. 
Thinking about this question with [my previous project, a lisp implementation](http://akkartik.name/post/wart) was how I ended up working on [my current project](https://github.com/akkartik/mu). One way to think about it is as a minimal, easy-to-implement substrate for building high-level languages on top of.
Interesting project. I've fooled around with languages, VMs, and OS ideas for years, ever since I worked on the Dylan version of Newton OS. I've made bits of progress here and there, but real progress would require either more people or someone with a more obsessive focus on a single project than I can manage. 
Maxima source is a big help.
[Symbolic differentiation of compiled functions in Lisp](https://web.archive.org/web/20080216182353/http://sleepingsquirrel.org/lisp/sym_diff.lisp).
https://bitbucket.org/tarballs_are_good/symbolic-function/src
Say more about your project when there's more to say. I'd be interested in tinkering with it when it's at a tinkerable stage.
1 isn't quite correct. What's happening is *tun0* is actually a tap. As you observed, VLM speaks CHAOS as well as IP, so it's barfing out ether frames rather than IP. IP framing is handled in the lisp runtime itself. *tun0* is a complete misnomer. 2 is interesting. I wound up beating on that via *(setf (cadar (send net:*\**emb-host*\* *:address)) "10.0.0.1")*. I didn't know there was a utility to do that. It looks as if the supplied binary is statically linked. For some reason, genera needs a fairly old version of X11 (Xorg 6.8), or the shutdown/reboot on *Save World* hangs. Further, it is possibly to use *LD_PRELOAD* and a small wrapper to avoid the need for root privileges and VMs. See: http://cliki.net/Linux%20VLM%20workarounds Having source would provide an even slicker answer. http://imgur.com/pVoMl4Z
Because the scope of res is limited, you could #'nreverse which is destrutive but faster. If anyone is curious for more: a blog post about #'nreverse vs #'rplacd, which also cites a 1993 paper on the subject: http://blog.splittist.com/2007/10/10/nreverse-vs-pointer-manipulation-revisted/ 
 $ du -sh /usr/local/share/emacs/24.5 89M /usr/local/share/emacs/24.5 And that's with dynamic linking of libraries such as `libtiff`, `libgtk-3`, `libX11`, etc.
I regularly develop on a machine with 16Gbs of storage. I have no problem running vim-slime as well as a couple other plugins.
&gt; Packages aren't as nice as clojure namespaces, but again, once you get used to how things are done in CL they don't bother you as much. "Aren't as nice" is a bit of an understatement. Preface: Common lisp is my favorite language, and I use basically nothing but that for everything I have a choice in. Common lisp is a bit warty at times, but the biggest wart, the one the doctor looks at, goes pale, and just shakes his head when you ask him about it, is the package system. ASDF does its best to manage it for you, but even that is a bag of hacks built to fix a bag of hacks. And, that's not the fault of ASDF; they are working with a limited system due to one of the only restrictions on language redefinition that exist: You cannot redefine the `:' operator. My biggest complaint specifically is the versioning system. Let's say you have a package bar which has major versions 1.0.0 and 2.0.0, and you have package baz which depends on bar 1.0.0. Let's say you then have a package foo which depends on bar 2.0.0 and baz. When you import foo, both foo and baz will get bar version 2.0.0, which is awful, as major version changes are literally defined as api-breaking changes, so baz will probably crash everything when trying to use bar. There's no good way to fix it as there is no way to have two packages of the same name which have different versions in the definition of `:'. Source: I was trying to fix this exact problem at one point. The only possible solution would be to either make the major version part of your package name as a package maintainer (recommended) or to rebuild the common lisp reader to do this automatically, which would be much more herculean.
On my machine, $ du -sh /usr/local/share/emacs/24.3 8.0K /usr/local/share/emacs/24.3 But seriously, I stand corrected.
Wow. This looks very impressive! Man, I wish I was as productive as you during my holiday. :D Looking forward to giving this library a try on my next project.
I see everyone kvetching about the use of the term 'Lisp Machine' here, but I'm really excited about this from the aspect of what it *does* do, it seems to give me a workable memory efficeint non-interpreted lisp on the arduino. That is pretty nice. Looking forward to trying this out.
It's absolutely worth learning. There's no way to know if you'll like one better than the other until you try them both, but it's a worthwhile thing to do, if only for the sake of the expanded options and understanding you'll get from it. Common Lisp and Clojure are pretty different. Clojure is an opinionated language with an opinionated community. It's embedded in a pretty elaborate ecosystem of tools. Common Lisp is more like a very flexible building material. It doesn't have a lot of opinions about how you should do things. Another difference is that Common Lisp is an old-fashioned interactive programming language like FORTH and Smaltalk. Clojure is more like newer languages, designed with the assumption that you're using it to construct software from a plan. Programming with the old interactive languages is less like building something from a plan, and more like teaching things to an eager assistant. It's a different feel, and the languages have features that assume that's the way your working, and that make very little sense in the build-from-a-plan world. I moved from Common Lisp to Clojure for a while, then went back. Moving from CL to Clojure was very easy. It felt like picking up a new set of libraries, basically, except that while I was using them I didn't get to use the rest of Lisp. Then again, I've used libraries like that before with Common Lisp. Moving from Clojure to Common Lisp might be harder. A lot of things you take for granted are not part of the language (though you can have most or all of them from quicklisp libraries). Common Lisp isn't opinionated in the way that Clojure is, and neither is its community. Don't get me wrong; you can find a lot of strongly-held opinions among Lispers! I'm just saying there isn't one true way in the same way that there s (kind of) in the Clojure community. Common Lisp is very much a multiparadigm language, perhaps unique in the extent to which it's a language for inventing and experimenting with new paradigms (as examples, ML was originally implemented in Lisp, and one of the first Haskell compilers was written in Lisp; the Common Lisp Object System isn't so much an object-oriented programming language as it is a toolkit for building and experimenting with object-oriented programming languages--I worked on a frame representation language at Apple that used CLOS to implement object systems quite unlike anything in widespread use today). If you decide to try it and get frustrated or confused, ping me. I'll be happy to help. I've been on both sides and I still like Common Lisp best of any currently-available language. I suggest Peter Seibel's _Practical Common Lisp_ as a good getting-started book for the working programmer. It takes you from zero to working code pretty smoothly and sensibly. Getting started can be as confusing as getting started with Clojure. If you like Emacs, get SLIME and either SBCL or CCL. If not, I suggest the free edition of Lispworks, which has a good IDE-like set of tools for Linux, Mac, and Windows. If you need Java interop, try ABCL. Be prepared for fifty years of history as embodied in the language and its standard library. Sometimes the naming and parameter-passing conventions will have you scratching your head. Sometimes the way things are designed will make you wonder what kind of world they were designed in. In the end, though, it's worth learning. Good luck. 
The repl in Common Lisp and in Smalltalk is quite different from repls in any other language I've used, including Clojure. The simplest way to put it is that Common Lisp and Smalltalk are designed with the assumption that you'll do all or most of your work in the repl, and that it should just obviously be easy to do everything you can do in the language from the repl. About the only other languages I can think of that take the same attitude are the concatenative languages like FORTH and Factor.
Congrats. looks like a very useful utility :-)
That Windows tutorial is mostly about getting a virtualized Linux system running on Windows, and then he goes on to explain how to get Genera running on Linux. He gets it fully configured to where you can edit the system source code and use the Document Examiner, which I wasn't previously able to do. 
There's a Smalltalk-inspired object system in there, in addition to CLOS. It appears to be based on message-passing. I attempted this: (let ((object (tcp::ip-network-for-host (net::parse-host "DIS-EMB-HOST")))) (send object :route-to-host (net::parse-host "DIS-EMB-HOST"))) It produced the following error: Error: The object #&lt;TCP:INTERNET-NETWORK INTERNET 238289349832&gt; received a :ROUTE-TO-HOST message, which went unclaimed. The rest of the message was (#&lt;FS:UNIX-HOST FOOBAR 12939424&gt;). The message is handled by the flavor TCP::IP-PROTOCOL. 
You're quite right. Building from a plan is not new. I implied that it was, though I didn't mean to. I only meant to say that the great canonical systems of programming-as-teaching are old. It seems to be slowly fading, more's the pity.
&gt; the Common Lisp Object System isn't so much an object-oriented programming language as it is a toolkit for building and experimenting with object-oriented programming languages--I the Common Lisp Object System isn't so much an object-oriented &gt; programming language as it is a toolkit for building and experimenting with object-oriented programming languages--I worked on a frame representation language at Apple that used CLOS to implement object systems quite unlike anything in widespread use today Super curious, could you expand on those object systems? In the open source CL there are few libraries that take advantage of extending CLOS. I can think only of CLSQL, perec and elephant (maybe rucksack as well). Manardb db uses the mop to mmap instances. There are some that are starting to like Crane, mito, integral. All of them for database/persistance integration. I haven't seen any extension of generic functions for instance. Method combinations are also not commonly used, but it seems to be more out of lack of awareness than of applicabilaty. For instance [spacebat gave the example of the append method combination being used to collect triggered errors](https://news.ycombinator.com/item?id=11576032). In retrospect the append method combination [models a source/filter system](https://github.com/PuercoPop/completion-candidates/blob/master/src/core.lisp#L19) very well, with primary methods 'registering' data sources and the :around method as a way to filter/reduce. There are also some 90's papers about extending the object model to fit your domain, but that doesn't seem to be taken advantage of much these days. Or patterns for extension (ej the meta-helix).
Check here regularly: https://functionaljobs.com 
He also explains how to connect to the running system using X server for Windows (old version of XMing), so one could forward Open Genera window to the Windows desktop.
It is Flavors, a very early predcessor to CLOS. You could read about it here: http://www.softwarepreservation.org/projects/LISP/MIT/nnnfla1-20040122.pdf and, obviously, on Wikipedia too: https://en.m.wikipedia.org/wiki/Flavors_(programming_language)
My copy of this just arrived today: https://www.amazon.com/LISP-Lore-Guide-Programming-Machine/dp/0898382289
Cool! I have found it in djvu format. Happy hacking, just do not procastenate on it too much :-P I know it is very tempting though :-)
Thank you!
I did not! Thank you!
That's a great idea!
Thanks for the info! I will definitely follow up in this community. After all, these are the people I'd like to work with who are passionate about Lisps and will help that market grow.
Would you be comfortable talking about your road to Lisp, and what types of systems you work on?
Careful what you wish for :-) I'm an old fart and it's a subject I like to talk about. My first shot at this started to turn into an autobiography. I've been a programmer for 30 years, and I became a Common Lisp programmer right at the beginning. The short version of the story is that I taught myself to program the Commodore 128 first in BASIC and then in assembly language. Then I found a copy of figFORTH and started fooling with interactive programming, and then reading everything I could about every programming language I could find. Soon after that I got a job at Apple, working in technical publications on programming manuals. Apple in the late 1980s was like heaven for someone who wanted to learn about programming. They had a great library of technical books, a great library of software you could borrow, and a great "competitive intelligence" laboratory where you could go to spend time on practically any kind of computer hardware you had ever heard of. Heck, one of my first experiences with Lisp was using Portable Standard Lisp on UNICOS on Apple's Cray Y-MP. That's also where I first learned to use Emacs. At Apple I worked sometimes as a tech writer and sometimes as a programmer. Some of the time I was working in C and C++, but some of the time I was working in Common Lisp and Dylan. I worked on a knowledge-based automated testing system that was written in Common Lisp. I worked on bauhaus, one of the Lisp-based OS projects for the Newton. I worked on SK8, which was meant to be a much more powerful successor to HyperCard. After SK8, and some not very satisfying work on things that weren't all that interesting to me, I left Apple to join a startup founded by people I had known at Apple. I spent seven years at that startup, Reactivity. Reactivity was eventually bought by Cisco. A Wikipedia article about Reactivity's first CEO, John Lilly, refers to alumni of the company as "the Reactivity Mafia" because several of its employees have become very influential in technology. Lilly himself is a partner at Greylock. My direct boss at Reactivity, Brian Roddy, is now a VP at OpenDNS. A guy I worked with on one of Reactivity's projects is now Facebook's CTO (Mike Schroepfer). Other Reactivity alumni have become pretty influential across the industry. They were all really bright, really good people. The Reactivity Mafia are old friends, but I'm not really one of them, because in 2004 I developed a serious illness that pretty much took me out of the workforce for several years. It took about two years just to figure out what it was (it's this: https://en.wikipedia.org/wiki/Chronic_fatigue_syndrome). I did some contracting in 2005 and 2006. In 2006 I found a doctor who listened to my account of the onset of the illness, recognized what it was, and figured out how to treat and manage it. After that I started to be able to do a lot more work. Lisp became even more attractive to me because CFS sometimes restricts my activity, so it becomes more important than ever to get the most done with the least labor. Nothing accomplishes that for me better than Common Lisp. Since then I've mostly worked as a contractor. It turns out it's pretty hard to find companies willing to hire me as an employee. That wasn't so before 2004, but it is now. Nevertheless, I've been gainfully employed as a contractor most years since then. Once again, somewhere around half of those gigs have been in Lisp programming. I became friendly with Andrew Shalit and the other Coral people way back when Coral Software was still selling Coral Common Lisp. Nowadays they're called Clozure Associates. Since 2004 I've worked for them several times on several different projects. Some of that has been working on the code or documentation for Clozure Common Lisp. Some of it has been working on other projects in other languages, including the initial versions of their LearningTouch products (written in Objective-C) and on a very cool research project that was part of the DARPA-funded CRASH-SAFE program (that was all in Haskell--another language I really like). I worked on an embedded control system for a forensic fingerprint livescan device, all written in Common Lisp using Lispworks. I wrote the foundation of an experimental MMORPG using Kawa Scheme and JMonkeyEngine. I wrote a high-level code differencer for Java and C++ in Common Lisp and sold it for a few thousand dollars. I wrote a personal list manager for the Mac, called Delectus, in Gambit Scheme. It's still on the Mac App Store. There may eventually be a cross-platform version of it written in Common Lisp. I've done some work in that direction. I worked on a framework for educational games on iOS for another DARPA program. I used my own Lisp, Bard, for part of that work. Right now I'm working on an experimental social network, again written in Common Lisp (except for small amounts of Javascript in the browser-side UI). That's a contract project for a researcher. 
&gt; However, on Github, there are many more scheme repos. Are there? Looking for `struct language:scheme` finds 15,620 results in 25 repositories, looking for `struct language:racket` finds 51,064 results in 24 repositories. `let` finds 13 scheme repos, 12 racket repos. `define` finds 11 scheme repos, 15 racket repos. On what data are you basing your claim?
Racket is two things, similar to Java. It is a language and it is a platform to develop languages. Racket the language is not a superset of Scheme (any version), Racket the platform comes with R5RS, R6RS, ...
racket is a language for writing languages, including scheme. it's also a pretty damn good dev environment, full batteries included and a pretty fast JIT compiler. 
I really wouldn't recommend Slimv. I found it to be frustratingly slow and prone to crashing. Nowadays I use Vim + rlwrap'd repl in a terminal multiplexer, which achieves the same thing without the crashes and hangs.
Does this play well with the `atom-slime` plugin? Also does this allow compiling single top-level forms or just the whole file?
Oh, man... not anywhere near New England, but I'm still hoping to make this event...
I need to talk to dto and see what we can do about recording/streaming talks for those who cannot attend.
warez?
Libgen's great for lisp books and more: http://libgen.io/ It's changed the way I read more than anything. In fact, I can't think of anything else that has changed the way I read. 
i dont get it
And? copyright in this day and age is an abomination. Thank the heavens for http://gen.lib.rus.ec and http://sci-hub.cc
cool, thanks for the info
I have configuration for Common Lisp development for Emacs and use it succesfully on both Windows and Linux. It could automatically detect most major implemetations of the Common Lisp, but they should be in the PATH. You could check it. Here is the link: https://bitbucket.org/arbv/emacs-config You just need to put it into: %USERPROFILE%\AppData\Roaming\.emacs.d and start Emacs (I use it with Emacs 24.5). It will download latest versions of all needed extensions automatically on the first start. It contains some things you probably do not need, hovewer it is easy to throw them away. I hope it will help you.
Copyright issue aside, the authors of these books have to eat too, you know. I'd rather buy the books to support the authors so that we'll get more Lisp books in the future.
on the same server : http://buhoz.net/public/libros/sexuality/How.To.Make.Love.All.Night.And.Drive.A.Woman.Wild.pdf You're welcome! :P
So, buy the books. Buying (or not) the book and also downloading it for free, completely disregarding copyright, are not conflated. Only idiots and various corporate lobbies are claiming that warez leads to lost sales, and they've been thoroughly debunked many many times. 
They're pirate. They don't care about rules.
I can't attend because I'm far from New England and more or less prevented from traveling by health issues. I'm pretty interested in the conference, though. I'm especially interested in game engines for use with Common Lisp. I spent around a year working on a networked multiplayer game, and I got it far enough along that Per Bothner used it as the basis for a talk at JavaOne 2015. I wrote it using his compiler Kawa, which is a Scheme that targets the JVM. I've stopped work on it for the moment for several reasons, but one reason I stopped is that Kawa is not presently well-suited to highly-interactive incremental development cycles. I also miss CLOS. I know there are projects like cepl and clinch that could maybe be turned into what I want. I haven't have great luck trying to use them, but maybe all that's needed is some conversation and shared effort. 
Cool idea, but doesn't seem to support any kind of MVCC. I think it'd be a lot smarter to serialize sexpr's and store them in an established relational database (like SQLite or Postgres) that could be selected based off of use-case. That way, you're not reinventing the wheel and you have proper support for the DB constructs you're eventually going to want. Clojure's Redis library (Carmine) is a pretty good model, albeit fails to satisfy hard persistence requirements. 
I didn't pirate this, I found this in an open directory...
Ask an admin to remove it. :P Also when I saw your videos a few years ago you got me into CL :D I own a copy of pretty much all the books in that directory.
It is undecided but ILC will likely be mid to late 2017
It's an honest mistake, but it's still piracy. Torrents, napster, pirate bay, those are all "open directories" too. If you really like these books, delete your post and create a text post with a list of the books and (if you feel so inclined) links to *legitimate* publishers of said books. Edit-add: [reddit's content policy](https://www.reddit.com/help/contentpolicy/), specifically [illegal](https://reddit.zendesk.com/hc/en-us/articles/205701075) content prohibiting "copyright or trademark infringement".
new CEPL video with this please
adorable
One interesting message from that thread comes from Mike McDonald: https://groups.google.com/d/msg/comp.lang.lisp/XpvUwF2xKbk/bQ5eqGzRsY4J &gt;&gt;&gt; So if you added some sort of "multi-user" and/or "protection" to a LispM, &gt;&gt; it wouldn't *necessarily* hurt your I/O performance (unless you botched &gt;&gt; the job). &gt; But why would I want a LispM that "protected" me? Why should I trust your &gt;buggy kernel anymore than I trust my own abilities? That's the core question &gt;when deciding whether you want multi-user and/or protection: do you trust the &gt;user of the machine? The LispMs said yes, Unix says no. It's part of a thread about the lack of multi-user protection on the LispM. McDonald was arguing that this sort of protection was totally unnecessary for a single-user system. This was in 1999, when malware wasn't on many people's minds. This was before the ILOVEYOU virus and the explosion of virus-writing that followed. I think that today that attitude towards multiuser protection would be unthinkable. The first thing that *any* malware for a LispM would do is redefine functions that might be used to detect or remove the malware, and doing this would be really, really easy, unlike trying to replace libc on a Unix system or KERNEL32.DLL on Windows. Malware on a LispM would be *completely* undetectable. 
Looks a lot like this ‚Ä¶ animal: https://www.amazon.de/Land-Lisp-Learn-Program-Game/dp/1593272812?ie=UTF8&amp;SubscriptionId=AKIAILSHYYTFIVPWUY6Q&amp;camp=2025&amp;creative=165953&amp;creativeASIN=1593272812&amp;linkCode=xm2&amp;tag=duckduckgo-ffab-de-21
haha that would be ace! I havent written an animation system yet but I would love this asset!
Because it *is* this "animal". The Lisp Alien to be exact.
Sounds like someone set your `adorable-p` to another fdefinition.
i wonder if that's a chatbot that wrote it. 
Sorry for not noticing that you submitted a link, not a question. I guess I'm too old for reddit.:-)
My previous job was in Racket, a corporate email sniffer. The current job is about railway traffic scheduling, the primary code is in Java and Scala, but when something goes wrong, one has to browse complex cross-referenced logs which I usually do by opening the log files in Emacs and running ELisp snippets on them.
Regardless, it was a good and succinct explanation. 
&gt; in late 1080s and early 1990s Can you explain this gap in your employment, sir?
I don't have a "Lisp job" but I did our web site generator in CL.
I'm programming full time in Common Lisp for my job. There are 2 of us CL programmers here now.
I've been using Common Lisp at work for the past two years, my job is more about data analysis than about programming, so I just use it as one of the tools in my arsenal, I manage to spend about 10% of my time writing code to extract data from log files and configuration files, the only requirement is that the data is accurate so it does not matter what I use. Recently I created a program which takes data which is in files in different servers and creates a single SQLITE DB from them. I created an executable and distributed to my peers and it has been received well. I guess if you are not a programmer (as a job description) you can take anything, call it a tool, and as long as you deliver value you can get away with it. At the end I am not lying, Common Lisp is a powerful tool which with good use can save you a lot of time and effort, and from using the REPL to having something you can distribute so others can also use it is just a bit of extra effort that pays off.
I have been working Clojure full time for these last 3.5 years at Yummly.com. Primarily backend web services, and deployment and monitoring automation. Some groups also use ClojureScript. Finding and hiring developers who want to work in Clojure has been relativity easy. PS: Riemann.io is a good way to sneak lisp into your job of you do anything "ops"ish 
&gt; PS: Riemann.io is a good way to sneak lisp into your job of you do anything "ops"ish I will keep this in mind. Thanks for the tip!
&gt; Any chance you'd be willing to explain a little more about your background and how you got into working on embedded systems? Getting a degree in Computer Engineering is a good first step :o) We use microcontrollers mainly for the real time capabilities in the sub-microsecond range (device synchronization and error detection/reaction) and because they draw much less power than even passively cooled "regular" PCs. We actually considered just slapping in a Raspberry Pi into some of our devices that didn't need the "real-time" part as much, but we ended up not doing that because we'd still have to design our own electronics around it and - unfortunately - the RPi's [I¬≤C bus](https://en.wikipedia.org/wiki/I%C2%B2C) driver is [not implemented correctly](http://www.hobbytronics.co.uk/raspberry-pi-i2c-clock-stretching) and thus unusable for us. So not only would we end up with a bad communication bus but also a lot of extra hardware work (connecting the Pi to the rest of the electronics and the device case instead of just slapping another small IC and a JTAG header on the PCB). The device running Guile isn't one of those though. It's just a regular Linux OS on an industry mainboard which only requires soft real-time in the two-digit millisecond range. &gt; Also, have you considered using any of the Lisp-&gt;Rust compilers, like Ketos or Moon? No, and I don't really see any point in using those either. Not only because I prefer the Scheme family. What do they do better than Guile, Chicken and Racket? What do they do better than SBCL? 
&gt; Getting a degree in Computer Engineering is a good first step Well, sure. I was more interested in how you came to focus on that niche. No doubt their reasons are all different and their motivations their own, but I know a fair number of people whom hold CS/CE degrees from prestigious schools, who do (rather mundane) web/mobile programming. &gt; No, and I don't really see any point in using those either. I guess you'd know better than I would. Though, I was thinking it could be advantageous to take advantage of Rust's memory/safety guarantees and its ever expanding library ecosystem.
Clozure has a built-in IDE based on Cocoa on OS X, and uses Hemlock for its editor. It feels pretty close to the classic Macintosh Common Lisp environment to me, though it only does command line debugging. 
Can't you just connect to the running Lisp environment on the small system from SLIME on a decent system?
Saturday will be 15 years on QPX :-) Common Lisp, using SBCL. I spend some time in C, though, hacking up the SBCL GC.
I have been primarily using Common Lisp at work for over 12 years now. It is used roughly 80-90% of the time, with SQL, JavaScript, HTML/XML, Scheme and C rounding out the pack. I do try to use CL to generate code in other languages that are needed for any particular project, and where possible I use Lisp for all projects. It is a small sphere, the CL "community", the enthusiasm is widely shared, and I suppose the major reason I get to work in lisp all the time is that I am a sole proprietor and thus get to choose my own poison. When I am part of another team, I was chosen because Lisp experience is what is needed, and I have a tonne of that. 
I occasionally use racket (best scheme for windows), but just for throwaway handy "scripts". It's sad, but "enterprise" projects is run by standardized bureaucratic morons focusing on bureaucratic multi-layered, multi-douchebag java-tech. 
It looks like it uses [JavaScript for the clients](https://github.com/turtl) and [Common Lisp for the server](https://github.com/turtl/api).
How so? üòÄ
I introduced Clojure at work about 5 years ago. Today, my whole team of 5 people is using Clojure/Script for full stack development. One of our other teams started introducing ClojureScript on the front-end this year, and they're considering Clojure on the backend if that goes well. We used to be predominantly a Java shop, and we're very happy with the switch. I recently gave a [talk](http://chariotsolutions.com/screencast/philly-ete-2016-2-dmitri-sotnikov-transforming-enterprise-development-clojure/) about how and why we're using Clojure.
I started a kind of "side project" when I entered my current startup, where i had the freedom to choose a language. Since it had to do with generating code automatically, I opted for common lisp. It grew inside the company, and I've been at it for a year. The rest of the stack at the company is node.js, so I have cl (ecl is the implementation) acessing mongo, redis and talking via zeromq and http with the rest of the system. We even have the mobile apps using rest endpoints that route directly to ecl. I'm a lucky, lucky developer.
In slide "LISP Dialects Timeline" missing Emacs Lisp - one of the most used(if not the most used) lisps nowadays.
Yes, during the speech I've informed attendants that it's incomplete (listing emacs lisp, racket and a few others) ‚Äì it's a diagram borrowed from wikipedia entry.
Nice overview.
I have one issue with it: IMO "Quicklisp is in the same spirit as NPM and RubyGems" is very very wrong. NPM and RubyGems are online package repositories where every package can have multiple versions independent of each other, whereas Quicklisp is a curated distribution system that snapshots the source packages at a certain point in time, taking the latest version and (lightly) checking that they are mutually compatible. It's an integration effort.
Yes, you are right, I didn't take that into account (sorry). Thanks for this remark. What I meant is that it download source to the user directory and that it's totally language specific.
IMO curated distributions are better and have mostly advantages versus pure package repositories because distributions represent an important QA filter. They can of course be implemented atop package databases, but since the CL world doesn't have such a thing Xach has to implement the source code fetching on his own. One disadvantage is that upgrading source distribution upgrades all libraries therein, and so if a library that your project directly uses breaks API, then you'll have to fix your project, which might not be easy.
&gt; Shipping binaries isn‚Äôt very viable option for CL developers what does this mean? &gt; Revenge of the Ners "Nerds" &gt; "Peter Siebel" "Seibel"
There is the compensating advantage that if upgrading breaks your project, you can easily downgrade to an older distribution.
Good point.
It's funny than right now there's a discussion on HN about how ugly Guile is as a language.
Hacker News: news.ycombinator.com
Sinatra spelt backwards? Interesting name
isn't guile scheme and isn't HN run by smug old common lisp bastards? BTW, rather old smug scheme bastard here.
Might be talking about [the Tcl War](https://news.ycombinator.com/item?id=12025218).
&gt; bureaucratic multi-layered, multi-douchebag java-tech Stable well supported, familiar to many java-tech
At my last job I wrote a fair amount of Emacs Lisp "off the books" to make my environment more useful - things like looking up LDAP entries of user ids found in logs and config files. My current job is around 95% Common Lisp, doing multivariate website optimization. Other products here use different languages, this product has been almost all CL since the beginning so when I came on board, no excuses were needed. Myself and another team member joined in no small part for the opportunity to use lisp professionally.
I agree. I am someone who's thought about getting into Common Lisp for a long time now, and finally decided to take the plunge a while back. I am still a newbie, but I found it weird that stuff like sockets, threading, FFI et al are not part of the standard, especially when there are so many vendors around. I hope things start changing soon. I much prefer Common Lisp to Clojure and I'd love to become productive in CL well enough to start justifying its use in projects at work as well as my own.
Probably because the bug was so old, and it is reverted several times(?).
It's been a combination of self-study, practice, and my career. But mostly lots and lots and lots of reading being being stupid long enough to maybe become slightly less stupid. 
I've been writing Lisp professionally since 1985 (with the odd gap). Currently using CCL at my startup. https://sc4.us/
You could frame this as a blog series, much like Clojure for the Brave and True, which eventually got published http://www.braveclojure.com/foreword/
I'm stupid, but I've read the README, and I still don't really know the purpose of roswell. It kinda seems targeted towards running scripts from the command line. But it is also for installing common lisp compilers? Is there some "synergy" between scripting and installation of compilers that I'm missing? Is this to patch up some deficiency in the way Quicklisp handles FASL files from different compilers?
You left out `/`, `//`, and `///` which are useful for functions which return multiple values. Also `-` which contains the form currently being evaluated. Should also include the slime inspector, by default bound to `C-c C-v C-i` in addition to the built-in inspector. Also worth mentioning the package `macrostep` which now comes included with SLIME by default. It is truly awesome and has completely supplanted my use of `macroexpand-1`. As a side note I wish someone would make a rosetta stone for different REPLs like the python one. I found it incredibly difficult to google what the equivalent to `*` was in the python REPL. (side side note: I don't understand why python doesn't implement more of the features of the CL REPL. It is almost painful to use when I know how much better it could be.)
I read `BWFP ch1.md` so far. No real feedback for you yet, other than to say, "keep going!" I'll read the rest soon.
Hopefully this comment won't seem negative, but I do not think this book is on a good track. It uses very non-idiomatic constructs (ergolib utils; REQUIRE; etc.), is mostly tutorial in nature (there's tons of this elsewhere), and moves along very slowly (showing essentially LET in chapter 2). I want to see more Lisp books that show where Lisp is amazing to work with. I want to see it put to the test. Show me how to build something great that's incidentally easy in Lisp. Don't show me how to add numbers. I also want to see books where Lisp isn't the main subject. Maybe a book on good web application design, but uses Lisp. Or parallel programming techniques, but uses Lisp. I say enough with the "learn Lisp from scratch" books. We have a very good one already. 
Well, this isn't really intended to be a book about Lisp. It's intended (as the intro says) to be a book about programming in general that happens to use Lisp as a vehicle, more like SICP than Practical Common Lisp, but not quite as abstract and theoretical as SICP. But thanks for the feedback. 
The title makes me think this is about hacking/exploitation I think you should retitle it so it's clearer what it's about.
&gt; Lisp &gt; immutable &gt; lexical This is a lie. Lisp is capable both of mutability and dynamic extend of its variables.
Describing a mutable system as an immutable system is a lie. Same about describing a lexical/dynamic system as a lexical one where the context doesn't say anything about it being dynamic as well.
Oh, I'd forget. &gt; Lisp &gt; functional This is one more big lie as Lisp is multiparadigm and does not enforce any single paradigm on the user.
So any description of any Lisp trait is a lie, that's wonderful! 
CL and Emacs are, but lisps are increasingly moving away from dynamic extent and mutability. Most CL programmers I know agree to encourage functional programs. Anyway, K doesn't have lexical closures, so I'd read this as "lexical scope" not "lexical extent".
&gt; Describing a mutable system as an immutable system is a lie. A lie suggests an [intent to deceive](http://www.dictionary.com/browse/lie). I really don't think that's the case here. You might say it's incorrect, but in trying to have a conversation with someone, it's better to try and find out the way that they are correct, *and assume they meant that*. Otherwise you're just being an asshole. In this case, K supports global variables and mutating (amending) values, same as Lisp. Most programmers don't recommend this type of programming in K or Lisp, so it is useful to think of K and Lisp as similar in this way. If you know Lisp, you will find it easy to learn K because *in this way* they are similar. This is in contrast to languages which encourage object-oriented programming in the Simula/Java/C++ sense of the term, where objects represent crude non-concurrent actors. (Which, of course, can also be simulated in Lisp and K, if you're thinking about capabilities, but as these aren't the first tool used by experienced Lisp programmers, you won't find "private variables" or "classes" very accessible in K either).
Dude, what? Why are you being so snarky? Is it because he calls them lies?
historically, Lisp was the first attempt at programmable lambda calculus, way before Scheme and ML... common lisp became quite an imperative dialect, though...
why not try asking questions about stuff you are having problems with?
Did you get hired to do the things you're doing, or was it more like your boss keeps coming up with these things and you learn your way through them?
You don't need a thorough understanding of denotational semantics to continue with the rest of the book. In fact, I don't think formal semantics are brought up anywhere else in the book. It'd be good to read the code in chapter 5 and make sure you know what it's doing _(which you should - it's just a more abstract/pedantic version of what you've already read about in the first four chapters)_ because he spends the next several chapters making it more and more performant.
These have been at a variety of companies. I was hired to do them. 
(defun foo () (bar)) is already mutating a global symbol FOO. I have never seen a Lisp programmer recommending to not use it.
This is not a definition of "mutating" that I've ever heard, and I don't think it's the definition of mutation that Arthur is talking about when he refers to Lisp and K as both "immutable". That you can use `(setf (symbol-function x) ...)` would probably be closer, but I think he was referring to using `(rplaca)` on lists you don't `(cons)` which is *very sensible*. I think that if you try hard to find an interpretation where a statement is incorrect, when there's a perfectly easy and obvious interpretation where a statement is correct, you're going to miss out.
Symbol package(s) are basically global mutable hash-tables. Every READ is potentially mutating those. The symbols then are changed with every DEF / UNDEF operation in some way. CL-USER 12 &gt; (defclass foo () () ) #&lt;STANDARD-CLASS FOO 42200BCB83&gt; CL-USER 13 &gt; (defclass foo () (a b) ) #&lt;STANDARD-CLASS FOO 42200BCB83&gt; That's mutation of the global symbol package CL-USER and mutating the registry for classes. Symbols are mutable objects with slots: value, function, property list, package, documentation, ... &gt; but I think he was referring to using (rplaca) on lists you don't (cons) which is very sensible. If I know that the list is consed, there is no reason to not change lists. Lisp traditionally provides a lot of destructive list operations. Additionally Lisp has a multitude of mutable data structures like: symbol tables (packages in CL), symbols, conses, vectors, arrays, structures, object system instances, pathnames,... Lisp also provides zillions of mutating operations for those. It's definitely useful to control mutation in Lisp, but there is no recommendation to actually avoid it for general programming. Lisp is not Haskell, which tries to minimize mutation on a language level and also in libraries/programs. 
&gt; there is no recommendation to actually avoid it for general programming Of course there is. * McCarthy's original Lisp didn't have mutation. * Cartwright and McCarthy spent a lot of time exploring mutation-free lisps * Gigamonkeys observes most CL functions are functional * Let over Lambda notes the value of a functional approach * Racket made immutable cons the default a long time ago now * Clojure has a lot of tools to encourage immutable data The list goes on. In fact, I can't find anyone who seriously recommends not avoiding side effects and mutation at a high level, and everyone I can find who does recommend some use of mutation in practice, admits it's [a performance hack](http://clojure.org/reference/transients), and it's only necessary because computers are made out of matter and powered by energy, and because the linked list. &gt; If I know that the list is consed, there is no reason to not change lists. Lisp traditionally provides a lot of destructive list operations. Unfortunately, programmers do not always know what they think they know, instead they only *believe* things. If you *believe* that the list is consed, you may use `nreverse`, but then you might cause a bug someplace else to show up. That's one of the things that makes writing high performance programming difficult in Lisp, but as the array languages show us, a better solution might simply have been to use arrays. 
Technically, yes. It's effectively a metalanguage. Describing the traits of the language is therefore dependent on what one actually does with it.
***TL;DR: Happily using common lisp at work most of the time for automation, R&amp;D, whatever else possible.*** I'm fortunate enough to have convinced smart people who own the company for which I work that common lisp will be our secret weapon citing the numerous reasons which make common lisp superior to popular language choices. For nearly three years I've used common lisp to be the conductor to the orchestrata of multiple software suites into one cohesive automated solution. This involves custom robotics, a very expensive custom computer, and a very very expensive camera and projector setup to take 2D pictures of objects and reproduce them in 3D to the accuracy of microns, which is then compared to a CAD model, finally producing highly customized reports. I've used common lisp to produce software and a machine which we were told we could not build, wouldn't work with anyone's software, etc. Yet, over many thousands of parts these machines have successfully helped companies reduce scrap material, make better jet parts, improve energy efficiency, make better hip and knee implants, make better gun parts, and much more. Without lisp and it's community I wouldn't be able to make new custom features in days or hours sometimes. Lisp helps me back around other software suites shortcomings and affords me more capability than entire teams of competition. I stand tall on the shoulders of giants. Much respect to all lispers, especially those who contribute back to the community. -DB
&gt;I think he implies that if you don't need Lisp macros, then you don't need Lisp. He also implies that people who don't understand Lisp don't know whether or not they need Lisp macros. See [Beating the Averages](http://www.paulgraham.com/avg.html), especially the section about The Blub Paradox. I think that anyone who's ever written a script that generates code can begin to appreciate the benefits of macros.
&gt; I think he implies that if you don't need Lisp macros, then you don't need Lisp. I dont know what Graham implies, or not. However Lisp is more powerfull than most of the regular-mainstream languages even without using macros. Macros for sure are powerfull but not required to beat the average. Erlang for instance does not have macros (in sense of Lisp) and yet is one of most powerfull language/system available today. One of the basic advantage of Lisp over the 3 languages you cite is that it is a functionnal langage. This feature alone give a key advantage by itself. I suggest you read [SICP](https://mitpress.mit.edu/sicp/) which is considered as one (if not THE) of the most important course in general computing science. They do not use very much of macros, and yet presents key concepts.
&gt; One of the basic advantage of Lisp over the 3 languages you cite is that it is a functionnal langage. "Functional language" can mean a number of things, such that, for example, the author of "Let Over Lambda" explicitly claims that Common [Lisp is not functional](http://letoverlambda.com/index.cl/guest/chap5.html#sec_1). So in what sense is CL a "functional language" where Perl is not?
Really the wrong way of thinking about it. How hard the problem is has little to do with anything. The advantage of Lisp, to me, is compile-time computing (via the macros) and that keeps every assumption you make during implementation in one place (because you use that place to expand into the actual code) and you never spread those assumption across the code. If you do the latter then a change in assumption (often) usually leads to incomplete trackdown of the other places where that same assumption has also been used. Autonomous cars are actually piles of reasonably simple individual software pieces. Not saying the whole thing is simple, I'm saying that there is little software in there that is very complex in one individual piece.