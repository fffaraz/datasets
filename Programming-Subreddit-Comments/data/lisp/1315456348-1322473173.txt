Also, my incomplete [coleslaw](http://github.com/redline6561/coleslaw) (powering [this](http://blog.clockwork-webdev.com/)) and archimag's more complete [arblog](https://github.com/archimag/arblog) (powering [this](http://archimag.lisper.ru/)).
CLOS
elephant is very nice, and it's still in development! 
Slime
Wider standard, greater portability between implementations.
[Scheme's alternatives \(includes CLOS\)](http://wiki.call-cc.org/chicken-projects/egg-index-4.html#oop)
[Slime for Scheme](http://wiki.call-cc.org/chicken-projects/egg-index-4.html#tools)
good dirty macros without all that hygienic stuff
Whats your point in going from answer to answer and repeating that "Scheme also has this"?
I've used it in the past, and would do again. SBCL + BDB.
Edi Weitz and Xach. EDIT: Ok, if you want to get down into the details, I also find myself missing `plist`s, the `:keyword` package, `assert` and the swiss-army-style `format` directives in Scheme.
I am not very experienced with both, so dont understand my answer as flaming or something. The reasons why I consider CL a more overall pleasent experience (from a non-CS learners point of view) than Scheme are basically the same reasons people consider other languages "better" than Lisp. * Bigger community, so its easier to get help. * More available free code, so easier to learn from. * More available books and documentation in general. * Bigger "standard" library, more standardized stuff, less conflicting implementations. * A de facto "standard" implementation. * More "standardized" libraries for common, everyday stuff. * Standardized CLOS. * Standardized package manager, Quicklisp. People coming from Perl/Python/Ruby with their single reference implementation often point out that having too many conflicting implementations is slowing down the Lisp ecosystem. The same Windows/OSX users point out generally for Linux with its 1001 distributions. Having first come into contact with Elisp and then CL, I have the same feeling with Scheme, that the overall ecosystem is broken up so badly as if it were nuked, so that the only practical use I will possibly ever have for Scheme is to go through SICP/TLS, and that after that, whatever implementation I choose, there will be no more than 10-20 people on the whole planet using it. Knowing that most scheme implementations only have a few people keeping it alive, and that a implementation might easily disappear if they abandon it, makes investing time and effort into CL instead more reasonable. Having said that, I still think that of the implementations I tried as of now, Guile is mighty fine (from a newbish point of view, I just use it to glue together research-related C utilities), and after it replaces Elisp in Emacs "real soon" and being an "official" GNU project, it has chances to get significantly more traction and not die away in the case its primary author gives up on it somewhen in the future.
Filtering out actual things which Common Lisp has but Scheme lacks?
Considerably better infrastructure, especially for doing interactive development (SLIME; Quicklisp; interactivity-friendly libraries like Hunchentoot and LTk; discoverable library APIs; the condition system; painless method, variable and class redefinition; et cetera) without having to compromise on performance and compiler diagnostics.
Scheme has [Geiser](http://www.nongnu.org/geiser/) for Racket and Guile.
Most Scheme implementation provides a [defmacro](http://docs.racket-lang.org/mzlib/mzlib_defmacro.html) ;-).
Which one is comparable to CLOS?
- More sophisticated compiler infrastructure and optimisation - CLOS (scheme doesn't has FULL CLOS yet) - Richer set of libraries - Commercial variants (Allegro, Lispworks)
That is not comparable to SLIME for CL.
So it does, and I think that Geiser is pretty cool; but SLIME is a philosophy of programming as much as it is a piece of software, and as such, it doesn't quite fit Racket. Take Racket's built-in web server, for example. It is based on the assumption that after changing your code, you restart the Racket runtime. This might apply to other libraries and language facilities as well. Sure, it's a cultural thing rather than a technical one, but it does quite practically make Geiser less useful for Racket than SLIME is for CL. Guile may be different; I've never used it.
There is no "Full" CLOS for Scheme only SDHCY (Scheme doesn't have CLOS yet) ;)
Forgot: Multiple namespaces
* defmacro (Scheme may have alternatives to this but they just never seem as practical as the Common Lisp macros) * large standard library (at first this seems really daunting and there are many dark corners and undefined behaviors but eventually you realize how practical much of it is) * SLIME, REPL, and the interactive live environment * multi-paradigm development approach instead of a more functional approach While writing these I realize most of this can be summarized into the fact that Common Lisp just seems more pragmatic than Scheme.
Noob here... Nobody mentioned "type system". I like how it is optional in CL but greatly helps compiled performance and can be used to easily restrict or branch. With the type system incorporated from the ground up, most things can be extended or involved in new entities. When I explored Scheme, all I found for types was the basic primitive checks (which CL also has) and a few experimental packages people wrote for Scheme. I always wonder if I missed something. But I agree with a bunch of the other sentiments. CLOS and the MOP behind it are big winners for me. defmacro is standard. I tried to find big scheme repositories recently and did not find much help for various questions I asked at the time. cliki.net has been my big and almost-always-perfect go-to for CL. The CL community seems more vocal, more active, more vibrant. There is a sense that CL is a practical language with a large built-in toolset. With the recently-created QuickLisp, suddenly I have access to a bunch of other tools, almost as if they were also built-in. I can bring up a website from scratch in a few minutes. Things I like about scheme... It has the "continuations" feature. The API for various data types feels consistent and clean. But the loss of a good CLOS and type systems were deal breakers for me. In the end, though, it really just boils down to this: If I can do in CL everything I can do in scheme but in shorter time than trying to do things offered by CL and its community in scheme, then CL is my winner. 
Quicklisp and "Land of Lisp"
What about [GOOPS](http://www.gnu.org/software/goops/)? I don't actually know much about either CLOS or GOOPS, so I'm genuinely asking, rather than specifically trying to offer a counter-point.
And Nikodemus Siivola.
**The Good** I would say that most practical Schemes implement most of the features of Common Lisp but they all do it slightly differently. This means that CL code is more portable, has more documentation and is used in most community projects. Another important aspect is the compilers. Scheme compilers are pretty good but not one comes close to SBCL (the lisp compiler I'm familiar with). Yet another important aspect are libraries such as quicklisp which is so useful that it completely change the Lisp experience. SLIME is also more feature complete for Lisp than it is for Scheme. Dirty macros are more flexible. **The Bad and Ugly** Threads and networking aren't part of the standard The built in file browsing sucks donkey balls I doubt there will be a new CL standard whereas there is going to be new Scheme standards. You die when you stop evolving. CL is more complicated and that makes it harder to learn properly.
Goops like most of the Scheme CLOS variants (Swindle) is based on TinyCLOS. I haven't looked into it for a while but the TinyClos core along with the MOP core is much simpler and not optimized. Furthermore the different variants don't seem to provide a generic system for at least the most used schemes as they differ significantly in extensions. So I would argue that a program you write in GOOPS will run on racket or Scheme48.
and Peter Seibel and CL has by far the nicest trolls ...
Ok, take a look at cliki, many libraries are so old. I think elephant is stable enough for small application, and we alll know , the rapid growth of sbcl would more or less make changes of the api, in the other hand , other libraries will be left behind! 
But defmacro in lisp-1 language (variables and functions occupy same namespace) is quite dangerous, while in lisp-2 language (variables and functions occupy different namespaces with option of explicit conversions) it is usually ok.
I'm pretty sure the CL standard was intended to stop CL evolution. Peter Seibel gave a [talk on the Lisp standardization process](http://itunes.apple.com/us/podcast/episode-1-peter-seibel-on/id408612064?i=89554226).
&gt; CL is more complicated I didnt experience CL to be any more "complicated" than Scheme. &gt; I doubt there will be a new CL standard ... You die when you stop evolving. You dont need a official standardization process to evolve. The community can de facto standardize on libraries without having to costly push them through an standards body. Nowadays, Python/Perl/PHP/Ruby/Lua are doing rather fine with having merely a dictator-driven reference implementation as a "standard". CL needed an initial standardization back then, because the primarily commercial implementations all tried to erect walled gardens around their proprietary systems and minimize code portability to the detriment of the overall ecosystem. Today, as we have several high quality free implementations, which are all interested and working together on maximizing code reuse, standardization can occur spontaneously and naturally, so a new official process is not really beneficial any more. &gt; whereas there is going to be new Scheme standards. If those standards will cover only a small subset of whats actually part of an average scheme implementation, and thus can not lead to greater portability, they are imho not of much use. As long as I know about scheme, one if its selling points was "R5RS is only 50 pages".
I don't know a thing about Elephant... I was just curious what your dependencies were so I posted them. No statement was intended. :)
The Scheme community formed two steering committees to define two complementary languages, one small like R5RS and a larger one extending the former. However, the process is uncertain, and I have seen some heavy revising as of late on the small Scheme mailing list after the spec had seemingly stabilized.
I feel the need to emphasize your point with a link to [a blog post by Matthias Felleisen about interactive development](http://blog.racket-lang.org/2009/03/drscheme-repl-isnt-lisp.html). The short version: he thinks it's unnecessary, and does more harm than good.
I never actually understood what the point of having a "small standard" is. The use of a standard, in general, is to increase portability, of code, of machine parts, of documents, of whatever, and to prevent people reinventing the wheel over and over in incompatible ways. Trying to make a standard as small as possible is the opposite of what the point of standardization is in the first place.
If you mean "separate function and variable" namespaces, I actually prefer the way Scheme handles that. No need for `flet`, `funcall`, a `defun`/`defvar` distinction, `#'` notation, or passing around quoted function names (as opposed to functions). The only place it really costs is that you have to be careful when defining unhygenic macros, since variable capture is that much more likely (though I doubt it would be tough to port `with-gensyms` to Scheme if one had a mind to).
&gt; When I explored Scheme, all I found for types was the basic primitive checks (which CL also has) and a few experimental packages people wrote for Scheme. I always wonder if I missed something. There's [a typed variant of Racket](http://docs.racket-lang.org/ts-guide/), though there is then the philosophical question of whether it's still a Scheme (something the Racket people acknowledged when they renamed PLT Scheme to Racket).
Well, actually I _do_ think that standards should be as small as possible, but no smaller. The bigger the standard, the longer the time required to agree upon it will be, and the harder it will be to displace its cruft in the future. The thing here is that Scheme's standard was too small to allow it to grow organically. But on the subject of Scheme, it was obviously part of the Scheme ethos. To cite the credo with which the various RnRS documents open: _Programming languages should be designed not by piling feature on top of feature, but by removing the weaknesses and restrictions that make additional features appear necessary. Scheme demonstrates that a very small number of rules for forming expressions, with no restrictions on how they are composed, suffice to form a practical and efficient programming language that is flexible enough to support most of the major programming paradigms in use today._ And sure, in a way it delivered its promise, you could take a certain Scheme implementation and build upon it whatever you wanted. The way it did just wasn't very useful because you _had_ to build whatever you wanted that was in some other implementation and you couldn't use in the one you picked.
Yep, I guess it's a thing of personal taste. I sometimes tend to name fcts and vars the same. And yes there are also some good arguments (mostly optimization and idiomatic) for having a single namespace. I think also Clojure being closer to CL than Scheme uses a Lisp-1 approach.
I've never used Racket's built-in web-server but why would it need to be restarted when code change? If there's a repl listening and you reevaluate some part of the code you just changed like Geiser allow you to do, why would Racket's built-in web-server needs to be restarted?
Of course, I was just pointing out that defmacro is there if you really want it (but of course it must be used with good care) :-).
Along those lines, does anyone use [Rucksack](http://common-lisp.net/project/rucksack/)?
According to Jay McCarthy (the writer of the Racket server) &gt; This may be what others say. In my opinion, it is good to not allow this because it stands in the way of simple inlining optimizations and analysis. I wrote [an article a while ago](http://langnostic.blogspot.com/2010/09/yegge-strikes-back-from-grave.html) comparing Racket (then PLT Scheme) to CL, and [Jay responded in the comments](http://langnostic.blogspot.com/2010/09/yegge-strikes-back-from-grave.html?showComment=1285691885973#c4252115480538682294) (including the above quote in response to my wondering aloud what the reasoning behind a mandatory restart was). EDIT: Added direct link to Jay's comments.
I read that post and I quite literally do not understand what he is talking about. Perhaps someone here can explain it better. "In the presence of macros and higher-order functions and other beasts, it is difficult for masters of the universe with 30 years of experience to keep track of things." What does that even mean? Also, without ctrl-c-enter and ctrl-c-m to show you the macro expansions, how do you even write macros? Blind trial and error? Keep re-running calls to macroexpand-1, re-pasting the results by hand? I submit that SLIME (or something like it) is by far the best way to write macros. What could possibly be better than hitting a key and seeing the actual expansion of the macro you just wrote? You can also selectively expand the forms you want by simply placing the cursor.
Say you have a file containing this (not valid code, just a theoretical): (defmacro a-template (&amp;body content) `(foo (bar) ,@content)) (defun a-page (request) (a-template (:p "A test page")) Lets say we have those evaluated. And now, we decide to change `a-template`. (defmacro a-template (&amp;body content) `(baz (bar) ,@content)) If you just re-evaluate `a-template`, `a-page` will still be using the definition that calls `foo`. Now, with one macro and one function, it's easy to see what to do; you just re-evaluate `a-page` as well. Matthias' point is that 1. It's easy for people to forget that macros work this way (if `a-template` was an equivalent function, you would *not* need to re-evaluate all its callers) 2. In more complex situations, it's easy to lose track of what you need to re-eval along with the macro. I actually agree with the premise (having been tripped up by both situations at some point); what I don't agree with is the conclusion that it's therefore a net-win to remove incremental development from the system. That would solve the problem (if you just reloaded the file containing those definitions, they'd work as expected), but the cost is immense if you're developing an app of any length and/or using old-ish hardware to do it.
Although I know neither, I have heard that macros are simpler and easier to write in Lisp than in Scheme. Is that the case? If so, why?
I am still totally unable to make sense of the blog post. If I change macros which are local to a file, I recompile the file (ctrl-c-k). If they are used elsewhere, I reload the ADSF project (my own key binding). If I'm working on a live server, I plan the changes appropriately. I can use ctrl-c-w-c (slime-who-calls) to find exactly which functions are calling the macro. The list I get is a response from the live sever. There's no guesswork, there's nothing to keep in your head. This is not a problem, *at all*. The only argument I can possibly see is that since newbies may make mistakes, we should therefore remove this tremendous (and sometimes crucial) advantage of piecewise compilation for all programmers everywhere. Is that the argument being made?
As I understand it, more or less, yeah. The only additional point is that his anecdote was meant to illustrate that it's not just newbs; experienced lispers sometimes trip over it too.
I'd use [coops](http://wiki.call-cc.org/eggref/4/coops), though in most of my scheme code I've used [prometheus](http://wiki.call-cc.org/eggref/4/prometheus), in part because coops is a relatively new egg but also because I like prototype-based object systems.
Yes, Elephant is fantastic. The most set-and-forget persistence layer I've used in any language. I highly encourage its maintenance, even if I doubt I could help in a meaningful way.
Well I just don't believe it's a problem outside of raw newbies who don't understand how compilation works, in any language. I learned Lisp after years of C++ so I immediately grasped the issue of dependencies from the start. I don't mean to brag, but I have *never* been bitten by a stale macro problem. Maybe it's just because of my handy ASDF-reload key binding. But point taken. I will modify my statement thusly: The only argument I can possibly see is that since newbies *and the perpetually inept depicted in apocryphal stories* may make mistakes...
CLisp support would be good. 
I don't agree with his conclusions either, and feel free to be as back-handedly vitriolic as you like, but keep in mind that "Dan" from Matthias' story (who "stumble[d] across the state of the repl") is [Dan Friedman](http://en.wikipedia.org/wiki/Daniel_P._Friedman). He might be getting forgetful after 30 years of studying Scheme, but my intuition is that he's not "perpetually inept".
Typing in CL is as much about performance as it is about contract enforcement. I.e., CL with type declarations is about as fast as Java (and probably quite a bit faster than carelessly written Java). I don't think that Racket's VM can achieve that speed (or indeed if you'll find large useful libraries in Racket's typed language)
You've misunderstood. I'm saying that Dan Friedman probably isn't inept, and that the author of the blog probably jumped to conclusions based on what he saw. That's why I called the story apocryphal.
I know I'll get full flak for saying this from the CL people, but non-hygienic macros are fundamentally broken, both in Lisp-1 and Lisp-2; it's just that you will run into the brokeness much easier in a Lisp-1, but it's not too difficult in a Lisp-2 either. Consider, for example (in CL): (defpackage foo (:use common-lisp) (:export when-friend)) (in-package foo) ;; Note that this procedure is an implementation detail of the ;; `when-friend' macro; the user of `when-friend' might not even ;; know it exists. (defun friend-p (person) (member person '(sue john harry))) (defmacro when-friend (person . body) `(if (friend-p ,person) (begin . ,body) nil)) ;; Then, in some code in another package (defpackage bar (:use common-lisp foo)) (in-package bar) (defun friend-p (person) (member person '(sue eve lisa))) (defun third-party-func (person) (when (friend-p person) (when-friend (format t "~s is a mutual friend!" person)))) ;; Now, see how the implementation detail leaks to the user: BAR[67]&gt; (third-party-func 'sue) ;; this one is OK SUE is a mutual friend! NIL BAR[68]&gt; (third-party-func 'eve) ;; brokenness here EVE is a mutual friend! NIL BAR[69]&gt; (third-party-func 'harry) NIL BAR[70]&gt; (third-party-func 'lisa) LISA is a mutual friend! NIL 
That looks closer than the others. I'd miss some of the standard generic functions, though.
Ah. Fair enough then.
I'd rather say it must not be used at all. I've too many times run into obscure failures because there was a defmacro sitting in a module I used, just waiting to bite me in my proverbial ass.
Advantages of CL over scheme are: * the defined condition handling and restart system * the defined type system that's integrated with CLOS * SLIME development and debugging in general (Chicken debugging sucks) * Clozure has a nice bridge into Cocoa so you can make "native" apps on OS X * much better support for native multiprocessing (in both SBCL and Clozure) on OS X That said, I prefer scheme because it's more, um, elegant. Chicken is neat because it's embeddable in C and thus can be used for many real-world applications. If your goal is to avoid writing C, this is a real advantage. Things I don't particularly like about CL: * there's a boatload of cruft in CL * it shows its age (e.g., TOPS/VMS file/directory abstractions, lack of networking...) * it's sometimes a challenge to root out the correct set of libraries to use * package management is tedious though Quicklisp made life much much better * deploying Lisp systems is non-trivial though a live debugging REPL mitigates the pain But it's hard to overstate how pleasant the emacs+SLIME debugging environment is. That's probably the biggest overall reason to prefer CL at the end of the day.
Okay, thank you for your answer and the links.
Thank you for this reference. I also completely forgot about restarts/conditions; honestly, I do not use them as much as I should yet.
There is indeed brokenness here, but it's a PEBKAC brokenness, not a CL brokenness :) First, you made a mistake in the call to when-friend, which takes a person as the first argument. You gave it (format...) instead. Second, it seems you are not aware that symbols inside a defmacro definition refer to the symbols in the package where that definition appears. Therefore it does not matter that a function of the same name is defined inside another package. To CL it's a totally different symbol because it was defined in a different package. I am pretty sure you misunderstand defmacro in the same way I originally did. Contrary to your perception (or my early perception), functions inside a macro definition are safe. (Unless you export them and accidentally redefine them elsewhere, which is a totally different problem also afflicting Schemers and having nothing to do with hygiene. Most (all?) CL implementations give a warning when that happens.)
Noob bere... Anecdotal, of course, but I was playing around in emacs recently in a slime session, working with multiple packages that included macros, functions using macros, and so forth. I did not know about the neat feature of viewing macros within emacs without typing them at the REPL... but I did know enough to remember that they only apply to compile time code. Every time I changed a macro, I would either recompile the dependent files or the specific functions using the macro (the REPL had to be in the right package for that; it is easier just to recompile the file). I may have forgotten exactly once, realized what happened, and immediately corrected with a blunt file recompile. So bottom line: this noob remembered to do it and did not have any problems.
I expect it is still quite relephant.
Ok, but I feel like you've misunderstood Matthias' arguments. He's not claiming that all Lispers everywhere (or even all newbs) will trip here. He's trying to give you less to remember by making sure that there's exactly one way to evaluate code. This is consistent with the Scheme modus operandi from what I've seen. Without the choice they made, you would have to remember to treat macros differently from functions when working at the REPL. In this case, it's such a small inconvenience and their "fix" is so outlandishly annoying that I believe they made the wrong decision. That said, I think it was an error of scale, not an error of direction; they're right to minimize any and all inconsistencies, they just misjudged how useful incremental compilation is. The ideal solution (as far as I'm concerned) would be to automatically re-evaluate all callers along with the macro when you do so (I don't do it myself, but based on what dont_mention_the_war says, it sounds like that would be a relatively simple Elisp function for SLIME users). The bigger ideological argument here is one of complexity. The fact that certain individuals (myself included) *don't mind* keeping the extra information in their heads doesn't mean that it's convenient, it just means we've learned to deal with it. If the goal is to simplify the language for all newbies rather than just the ones that choose LISP based on the current situation (I've concluded that this *is* a goal for Racket, correct me if I'm wrong), then it's obvious that such complexities need to be boiled out no matter how trivial they seem after they're learned. There are places where I wish Common Lisp did a better job of that including - the dual namespaces that force you to decide between `defun`/`defvar`, `let`/`flet`, and keep you from passing a function around just like a variable - the fact that `t` is a reserved symbol (as opposed to the designated truth value `#t`) - that predicates are inconsistently named (`foo`, `foop` or `foo-p`, depending on how you feel, as opposed to `foo?`) - that side-effect-inducing functions aren't labeled as such in their names (most notably `sort`, which I sort of assumed would be functional the first time, but turns out to be destructive and actually has no functional equivalent out of the box) I realize some of this is subjective, and having learned the current CL way already, I'm not about to spend time actually working on the solution, but it seems like the Racket guys are trying. I can't fault them for that. TL;DR; There are three ways to deal with a wet floor; you can make a mental note for your own future reference, you can put up a sign saying "BEWARE WET FLOOR", or you can mop it up. In this case, it seems like Racket went for option d; condemn the building containing the puddle. That's, shall we say, less than ideal, but the first two solutions (which you implicitly advocate) don't quite satisfy either.
I tried Elephant a while ago in order to store more objects than available RAM allowed. Without having played with it *much*, I was frustrated by two things: 1. Speed. I think it was hitting the disk on every object access, but maybe I was misinterpreting something or I'm misremembering. 2. It seemed like it wasn't very useful with non-trivial third-party data structures unless those data structures were "ported" to Elephant. I wanted a totally transparent solution, probably something that would only be possible at the CL implementation level. 
I would summarize it as, "Do we allow sharp knives?" You can accomplish a lot with a wooden mallet, but sometimes only a knife will do. The problem behind the banning of knives is that it revisits the old utopian newspeak fantasy of wanting to prevent the existence of bad things. It overlooks the fact that you can hurt yourself with a wooden mallet as well, and in the end a knife is likely to be tremendously more helpful than hurtful when used with care. . Regarding `sort` and `t`, I dunno. `#t` seems ugly to me. Thinking about this stuff too much is a kind of disease of procrastination where one wanders around seeking abstract perfection instead of doing things. In terms of doing things, `sort` vs `sort!` has no relevance whatsoever. I don't know what you mean by the `p` suffix being inconsistent. The rule is no dash for one word and a dash multiple words. Maybe you were talking about `atom` and `null` which, yes, are warts, but nobody really minds. Lisp-1 vs Lisp-2 has been discussed to death. In short, the simplicity of `defmacro` means that I can write macros very quickly in SLIME. I just expand to see if it's what I want; if not, change it; expand again. I'll never want to give that up. Lisp-1 is simply wrong for `defmacro`. A codewalker could possibly fix it, but considering that Scheme went in an entirely different direction with `syntax-*` may mean that codewalking has problems.
Does any language have that type of to disk serialization of objects without requiring some form of ORM to be setup? 
Honestly, it's just personal preference to me. CL is my first choice, but I'd still jump at the opportunity to work in Scheme before some non-lisp. (Or Clojure, which I just haven't been able to love).
[Terracotta](http://www.terracotta.org/) for Java, maybe. I've only played with it a bit, so I don't know for sure, but it looks like it provides fine-grained serialization. For example, I was able to load Armed Bear Common Lisp with it and variables were preserved accross different runs. (ABCL does not have save-image functionality.) Moreover, when I loaded two instances I could define variable in one of them and other will see it too. That's awesome. (It required some heavy tweaking, so it is not 100% transparent.) It works through heavy JVM instrumentation, though, so I wouldn't call it a Java library.
You're right, it is not transparent, more like a database for persistent objects :) It can work with third-party data structures as long as "check-out/check-in" model is OK for your application. If you work with something like a large graph then it needs to be converted to 'persistent object' use. You're right about overhead too, it's probably not for applications which are bottle-necked in data access. &gt; I tried Elephant a while ago in order to store more objects than available RAM allowed. ... I wanted a totally transparent solution, probably something that would only be possible at the CL implementation level. Going 64-bit and enabling more swap space would do that, no? Garbage collection could be a problem, though.
It's more like CLISP should add support for Elephant, not the other way around :) (AFAIK CLISP has really crappy MOP.)
What do people think of Guile?
You might start a new topic and ask that question in /r/scheme. 
Very interesting, wasn't familiar with Terracotta. Neat that it works with ABCL. I think Apple has something similar for Objective-C/Cocoa, but based on SQLlite maybe?
&gt; "Do we allow sharp knives?" The reason I wouldn't choose this characterization is that it implies that there are situations in which you want to change a macro definition without re-evaluating the functions that call it. I can't think of a place where I'd want that (at the very least, it's such an edge case that it probably shouldn't be the default behavior). On the other hand, there are plenty of places where a sharp knife can be useful despite the fact that it's dangerous. This is more like "Should knives have handles?". You could probably use [a knife without one](http://www.wasatchmountainknives.com/_/rsrc/1250712259033/work-in-progress/Picture%20030.jpg?height=229&amp;width=420), and you could argue that [cord-wrapping](http://images.outdoorpros.com/images/prod/5/Smith-Wesson-CKGMGM-rw-37189-42103.jpg) is more useful if less comfortable than an actual handle, but why would you work with a naked tang if you had the choice? &gt; Regarding sort and t, I dunno. #t seems ugly to me. I agree; as far as I'm concerned, Ruby handles this best (`TRUE` and `FALSE` are the reserved boolean symbols). The reason it annoys me is that sometimes I want to assign an intermediary value to a local variable named `t`, but can't in Common Lisp. &gt; In terms of doing things, sort vs sort! has no relevance whatsoever. I agree again, though I suspect we're on the opposite sides of "no relevance" here. If they both do the same thing and have the same cost, but one makes it much more obvious (and consistent) what's happening underneath, it's pretty clear which a language should decide to use. The secondary gripe in my original point was also that there isn't a functional sort defined already. If you want *that*, AFAIK you need to explicitly copy a structure, and then return the new one after `sort`ing. &gt; The rule is no dash for one word and a dash multiple words. Maybe you were talking about atom and null which, yes, are warts, but nobody really minds. I had no idea this rule existed. Why treat them differently? `atom` and `null` are precisely what I was talking about (I vaguely recall there being inconsistencies in other libraries, but these are the main culprits). I get that "nobody really minds", but that's sort of the point of my little rant above. They're still warts. Ok, we're used to them, but if someone's goal is to create a LISP without warts in order to minimize cognitive overhead, should we keep them just because the existing base is now used to these defects? Keep in mind that one of the goals of Racket is to attract newbies. Not just newbies to LISP, but to programming in general. &gt; Lisp-1 vs Lisp-2 has been discussed to death I'm aware, but as discussed as it is, in this context I feel the need to point out that it's easier to deal with one set of definition macros. It's also easier to pass functions around without having to worry about whether I need to pass `foo`, `'foo` or `#'foo`, and without worrying about `funcall`. I'm not saying these are new issues, or that we should begin chopping up Common Lisp to fix them, but if you're not starting from Common Lisp, it's clear that there are different ways to do things. &gt; Lisp-1 is simply wrong for `defmacro`. I'm going to need some clarification here, because the only thing I could see tripping you up is the slightly increased chance of variable capture which seems like it could be fixed with a Scheme version of `with-gensyms`. Am I missing something?
In my analogy, the knife is the ability to incrementally recompile. Getting bitten by a stale macro corresponds to cutting yourself with the knife. CL implementations are not required to have `slime-who-calls` functionality. While a `recompile-affected` function might be interesting, it's not a pressing matter and there would be essentially zero payoff in writing it. Think about the rarity of the use case. For example you have a live server which is running credit card transactions. And you just got slashdotted so you don't want any stutter whatsoever. And you want to change a low-level macro used in multiple places. And you have an unrelated bug which sabotages a reload. This is basically the only scenario where you just want to recompile affected changes instead of reloading the ASDF project. Nobody wants to write a tool which nobody will use. On the other hand, defining or redefining a function on a running lisp image is a common operation. In SLIME, ctrl-c-c compiles the function containing the cursor, underlining warnings or errors directly in the code itself. Lispers who haven't tried this workflow are really missing out. Regarding `t`, `sort`, etc., again I see this as a kind of procrastination where one wanders around seeking abstract perfection instead of doing things. All of your gripes can be addressed trivially by a handful of one-liner macros and functions. Even `t` can be changed to the way you like by shadowing the symbol. Perhaps one day someone will publish a thin layer CL package which streamlines these things. Probably every lisper has thought about it. But since CL is so fun and productive, everyone seems to just move on to other things. While `atom` and `null` are historical warts arising from backward compatibility, the Lisp-2 namespace is a correct design decision in light of `defmacro`. Again I point to the fact that SLIME + `defmacro` is the most kickass way to write macros, as I've tried to explain. But Lisp-1 + `defmacro` is a problem. #lang racket (require mzlib/defmacro (for-syntax racket)) (defmacro foo (lst0 lst1) `(list (car ,lst0) (car ,lst1))) (let ((bicycle 1) (motorcycle 20) (car 100) (bus 900)) ;; ... traffic calculations ... (display (foo '(a b) '(c d)))) (newline) Error: `procedure application: expected procedure, given: 100; arguments were: '(a b)` You could try fixing this by gensymming every function call, but that would be too cumbersome in general. You could write a codewalker to do that for you, but I expect there would be problems with that approach. I vaguely recall other issues with `defmacro` as well. Scheme's `syntax-*` is definitely a more reasonable macro-writing facility for a Lisp-1.
These questions are a little puzzling. Maybe the place to start is to tell us what you mean by "not get bound correctly". Is this a confusion between `defparameter` and `defvar`, perhaps?
If you have a problem with things not loading properly, but they work interactively, it is almost always a dependence on something being defined in the environment earlier than it "actually" is. The usual example is a macro that uses a function to perform the expansion: if you've evaluated the function definition in your interactive environment, then the macro works. But it is possible to screw up your .lisp file so that the function is not available at the time the macro is first used. EVAL-WHEN is the trick needed to solve these. But, really, the first step is truly understanding the difference between read-time, load-time, macro-expansion-time, compile-time, and run-time. See for example [this blog post](http://fare.livejournal.com/146698.html). 
`begin` is not CL.
you hit it spot on. thanks for the link, these issues are the question i could not ask more clearly.
&gt; These questions are a little puzzling. i'm sure they are ... that's one of the issues with being noob at something: it's hard to come up with meaningful questions. if i could, i would probably be able to look it up myself. in this instance, i used defvar, which i placed before the defun. the function then would use that global variable. when evaluated those expressions, everything went ok. when i simply loaded the file, the variable in the function would appear to be unbound. if that doesn't make any sense, i'll have to post the code in question tomorrow (i don't have it with me right now). 
Actually, I was a bit glib in my response regarding EVAL-WHEN. There are also cases where all you need to do is to segregate some definitions into another file or files, say, "package.lisp," "macros.lisp", and use your build tool (e.g. ASDF) to manage loading your multiple files in the right order. EVAL-WHEN is for when that is just not enough.
i have the feeling that is a topic which is skipped in many introductory lisp texts, though it's so important.
The blog link appears to make it more complicated than it actually is. I didn't have any trouble with EVAL-WHEN after reading PCL (http://www.gigamonkeys.com/book/the-special-operators.html). The writer seems to be complaining about CL, but he's really complaining about issues which are natural outcomes of separate compilation. Once you get the implications of compiling, EVAL-WHEN is not surprising or strange.
defvar won't replace a pre-existing binding. When you say you have to evaluate everything to make it work reliably, I'm guessing you might be using C-M-x from SLIME which has a special hack which silently converts defvar into code equivalent to defparameter.
I first read that as "Nuke blog".
I was actually using "Evaluate Last Expression" (C-x C-e), since I didn't know the difference between the two. So thanks for clearing that up.
Object persistence. For web applications in my case.
A few comments: - adding comments with contracts and purpose statements to your functions would make it a lot easier to understand. - you don't need 0 as the first argument to `in-range`, it's implied. You can even just use `(length heaps)` by itself as a sequence. - I'm not sure why you're producing a list with keywords in it in `take-from` -- maybe a struct would be better here. - I would use `cond` instead of nested `if`. - I would also use internal `define` instead of `let`, to reduce rightward drift.
Oh, I recommend that you cross-paste here: http://paste.lisp.org
For persisting objects.
Added the link to my top post. Running the mouse over the pasted code makes it look like a kaleidoscope of colorful parentheses! I like it.
Made your indicated changes. Much cleaner! http://paste.lisp.org/display/124619
Why are some of the (s [s ?
I might as well mention that an ASDF project lessens the need for EVAL-WHEN since you normally place utilities needed by macros in a file which is compiled first. Other utilities used by a macro should be specific for that macro, so an FLET or LABELS inside the macro definition is more appropriate than an outside EVAL-WHEN. For references to special variables, `(declare (special *foo*))` removes the need for EVAL-WHEN.
In Racket, all of "(", "[", and "{" are treated as parentheses.
oh, so no semantic difference, just for readability?
Yeah, exactly. It's to distinguish different levels of ( ) especially in bindings.
Besides Racket, R6RS also specifies that "[]" and "()" be equivalent: [section 4.3](http://www.r6rs.org/final/html/r6rs/r6rs-Z-H-7.html#node_sec_4.3). A handful of Scheme implementations have also supported it for some time now, but I think Racket programmers are the ones that have most widely adopted the style.
Apart from the simple solution of reloading the ASDF project, there's another reason that you don't hear lispers complaining about stale macros. If a macro is nontrivial or expected to change, it should usually be written as a function with a trivial macro counterpart. For example, (defun call-with-blah (fn) (with-some-context ;; ... blah stuff ... (funcall fn)))) (defmacro with-blah (&amp;body body) `(call-with-blah (lambda () ,@body))) Now we are free to redefine `call-with-blah` without worrying about recompiling.
Rucksack had its lunch eaten by Postmodern &amp; CL-Store on both ends. For small blobs, serialization with cl-store is better. For anything more than a few tens of megs &amp; long term durability, I would use Postmodern. 
You can use `positive?' instead of (lambda (h) (&gt; h 0))
The general problem is that CL macros are in some sense "quick and dirty." It works in CL because as a Lisp-2+ the dirt doesn't get in the gears. (Although you still have to learn about unintentional variable capture, and how to use `gensym` to avoid it.) In Scheme, the use of the same names for variables and functions means you have to be a *lot* more careful, because someone's choice of variable names can affect your macro expansions' choice of *functions* to call. Schemers have invented the concept of "macro hygiene" and various other forms of macros to avoid these pitfalls.
Just wanted to say that I feel like (the content on) reddit has been sucking a bit lately, and I enjoyed seeing this bit of code and other people's comments. Thanks.
Thanks for the heads up! Is there a list of all the standard predicates?
Glad you dig it! :)
The codebase...
I know that racket isn't supposed to be called "scheme", but [most of this](http://www.schemers.org/Documents/Standards/R5RS/HTML/r5rs-Z-H-15.html) will be applicable. Although I guess racket is closer to r6rs, but [its index](http://www.r6rs.org/final/html/r6rs/r6rs-Z-H-21.html#node_index_start) is unreadable. And [the index](http://docs.racket-lang.org/reference/doc-index.html) of racket is too large.
And instead of (for/fold ([counter 0]) ([h heaps] #:when (= h 1)) (add1 counter)) you can use (count (lambda (x) (= x 1)) heaps) EDIT: And if you're into that sort of thing (I'm not), you can even write: (count ((curry =) 1) heaps)
0.2 beta is out, anyone want to test ?
Here's the reference documentation for [numbers](http://docs.racket-lang.org/reference/numbers.html). The core `racket` language comes with more than 1200 standard procedures, so as stassats points out, reading a list of all of them is hard.
More suggestions: - use `positive?`, as suggested - use `λ` instead of `lambda`, it's much shorter - Racket style is typically to write the three parts of an `if` all on separate lines, or all on the same line
You don't need quite so many partial applications there: `(count (curry = 1) heaps)` works fine too. I wrote this little hack: https://github.com/samth/fancy-app so that you can write `(count (= 1 _) heaps)`.
I can't say that's an improvement, it uses ordinary lisp syntax while doesn't behave ordinarily, which is confusing. In CL we just do (count 1 heaps) (although it uses eql, not =, it's sufficient in this case)
I don't think using shorter names for the sake of being shorter is a good thing, especially when you're sarificing ease of editing and displaying. Now, if you like to see greek letters instead of latin words, you can configure your editor so that it displays said letters instead of words, [e.g.](http://www.emacswiki.org/emacs/PrettyLambda)
But I'm not sacrificing anything. In DrRacket, `λ` is Ctrl-\, which is much shorter than l-a-m-b-d-a, and it displays just fine. 
Others may not be so lucky. Can you make DrRacket insert "lambda" on Ctrl-\? And can you make it display "lambda" as λ?
Shiro Kawai (author of Gauche, a scheme implementation) had written about his use of λ rather than lambda somewhere (I found [this](http://lists.r6rs.org/pipermail/r6rs-discuss/2010-December/006223.html) discussion quickly, but I know there was a longer one that gave a rationale), and the reasoning was something along the lines of that the shorter version aided in quickly understanding a program 6 months after writing it. Personally, I tend to use λ or `fn` when writing in the REPL, and `lambda` when delivering code to clients (indentation normalization &amp; shortform-&gt;longform are two things I always do before handing off code).
What I'd love to know more about is how they manage such a large numbers of Lisp systems. init.d start/stop scripts, using Unix signals to request shutdown? Booting from the network from a common image? Installing executable Lisp images via a package manager? How would they monitor them, debug them, deal with logs? Anyone got any juicy inside details, or wild speculation to share, or stories from other users of distributed Lisp systems?
http://xach.livejournal.com/225634.html has some notes from Dan Weinreb's talk about ITA from 2009. The video has been taken down since then, unfortunately.
I actually do my Racket editing in Emacs, which I have setup to automatically replace "lambda" with λ via Quack, but copy and pasting the code or even viewing it displaying it with less at the cmdline seems to restore it back to "lambda". I like DrRacket a lot, but it runs really slowly on my machine. 
Very cool. I wasn't aware there was a built in count or currying function. I actually wrote my own currying and function composition functions recently. 
I like this quite a bit. I'm gonna play around with it once I get home for the day.
Alright, made some more changes according to your guys' suggestions. Link up in the top post. Thanks for all the feedback! Keep it comin' if you see more things to improve :)
Dunno if it's from a video or the ECLM2008: Airlines do some strange stuff, like you can get for several (50?) offers for every day of the week for a flight to (afaik) the Easter Islands. There's just one problem, the number of actual flights per week to that island is just one :)
Added a Common Lisp version too.
looks like it was ECLM2006 here are some more bits from Martin Cracauers talk: http://web.archive.org/web/20061018001318/http://lispmeister.com/blog/lisp-news/eclm-2006-report.html http://jsnell.iki.fi/blog/archive/2006-05-03-eclm-2006-report.html
New version up. :)
Put a new version up :)
* (boole boole-xor) =&gt; logxor * (apply #'max heaps) =&gt; (reduce #'max heaps) (because the number of arguments which can be passed to a function is limited) * Use LET instead of SETF. * Split the code into sub-functions. For example, the bit calculating `heaps-two-or-more' can be easily put into a separate function. * IF should be formatted (if condition then else) not (if condition then else).
Looks very nice.
&gt; Can you make DrRacket insert "lambda" on Ctrl-\? Yes. &gt; And can you make it display "lambda" as λ? Only with much more effort (but DrRacket is extremely extensible, so it's possible). There's infrastructure for defining keybindings, but not for changing character display. However, I think if your editor can't display UTF8 text properly, it's time for a new editor.
&gt; I like DrRacket a lot, but it runs really slowly on my machine. Is this just because you have an older machine, or is their something wrong happening? If the latter, we'd like to know so we can try to fix it.
Dude...you couldn't use the one powered by Common Lisp at http://wigflip.com/roflbot/ ? I am pained.
Someone sent it to me and I reposted, I will yell at them for you
It also looks like that other site supplies the standard meme images which might have been why it was chosen.
Oh Xach, bringing us meme generators and quicklisps. 
It's ok. Some of the other sites have gotten much easier to use. I need to give roflbot a facelift.
I was expecting God to kill a kitten in retaliation for the broken build. My memes are less than fresh, it seems.
What are FASLs? Wikipedia doesn't have a relevant entry.
You should have done [this](http://i.imgur.com/VyfQA.jpg)
A `.fasl` is the result of compiling a `.lisp`.
What does it stand for? Is it bytecode? Why doesn't the build system delete bad FASLs, or overwrite them?
AFAIK: - FASt Loading - Yes - When you compile a `.lisp` in SLIME it overwrites the old `.fasl`, but how would you automatically decide which are "bad" enough to delete?
i feel so 1337 for laughing hard at this :\
Thanks. &gt; When you compile a .lisp in SLIME it overwrites the old .fasl, but how would you automatically decide which are "bad" enough to delete? I'm not sure how Lisp would do this, because a Lisp build is inherently complicated, but I love how make uses timestamps to decide which files need to be rebuilt. Maybe FASLs can be updated similarly.
Thank you!
Thanks for tips. I'm fairly new to the Lisp family. I'm kinda torn as to whether I prefer Racket or Common Lisp, so I've been rewriting all my code in one into the other to see which one fits better.
It's an older machine--a 2007 Lenovo ThinkPad T60. 2 Gig Intel Centrino Duo &amp; 2 gig RAM. There's significant latency when typing in the definitions window. It's considerably slower than Emacs with multiple REPLs open on my machine.
The lisp equivalent of a makefile is an ASDF file, which does what you describe. A lisp project is defined by its ASDF file.
"...how would you automatically decide..." Reload the ASDF project. [You and I recently discussed this to death](http://www.reddit.com/r/lisp/comments/k9r4q/lispers_what_are_the_primary_benefits_you_see_of/c2inchm), in which I repeatedly mentioned reloading the ASDF project. That's one of the purposes of ASDF. There's a certain kind of "advocate" that keeps going back to the same arguments even after they are answered. It's like creationism or something. I wonder if you'll keep touting that Lisp should not have a separate function namespace, even though I thoroughly explained that it exists because of `defmacro`, which has advantages over other macro schemes but does not fare well in a single-namespace language.
&gt; There's a certain kind of "advocate" that keeps going back to the same arguments even after they are answered. It's like creationism or something. &gt; I wonder if you'll keep touting that Lisp should not have a separate function namespace, even though I thoroughly explained that it exists because of defmacro, which has advantages over other macro schemes but does not fare well in a single-namespace language. Ok, wow. I get it; you like the separate namespaces and they help out with macro writing, but they *also* complicate passing functions (as I have pointed out in our to-the-death-discussion). Are you seriously going to follow me around and yell about how I should listen to what you seem to assume is your objectively superior reasoning? I wonder if you noticed that I haven't advocated a thing in our correspondence (or maybe you were too entrenched in your viewpoint to notice "I'm not saying these are new issues, or that we should begin chopping up Common Lisp to fix them"), and was rather trying to clarify why I could see someone justifiably making a choice to go with Lisp-1 and automatic module loading? EDIT: Language.
Anyone can see that you haven't addressed the issue. Our last discussion revolved around your point that one doesn't know, in general, what pieces of code need to be recompiled. The answer kept coming back: reload the ASDF project, reload the ASDF project. I do somewhat resent having spent time explaining something as clear as I could, only to see the same confusion raised by the exact same person I explained it to. You've given us a lot of strange bluster, but you haven't provided a justification for how you could possibly act so inconsistently.
You had listed the second namespace as one of the "complexities [that] need to be boiled out" alongside the `t` symbol, the `p` suffix, and destructive markers on function names. My response was to show that you had a misconception about the function namespace. It's not an historical wart that should be boiled out like `null` or `atom`. The Lisp-2 on purpose. It's totally irrelevant to me whether you or anyone prefers Lisp-1 or Lisp-2. But I do speak up when I see misconceptions being propounded, such as the suggestion that the function namespace is an historical artifact like `atom`. It's not, as I tried to explain. Your response here indicates that I have been wholly unable to communicate this point to you. The same for ASDF reloading as well.
Hoo boy. Have you actually read my pieces of the conversation? I was wondering why you kept pointing out this true, but seemingly unrelated fact. No, I wasn't saying &gt; that one doesn't know, in general, what pieces of code need to be recompiled I was saying (quote from my end) &gt; Without the choice they made, you would have to remember to treat macros differently from functions when working at the REPL. It has nothing to do with not knowing the set of code you need to re-compile and everything to do with the fact that the set looks different for `foo` the function than it does for `foo` the macro. I haven't been acting inconsistently and don't need to justify myself to you in any case. Is there any particular reason you seem to have been treating our entire conversation as a contest?
In actual fact, what I said was &gt; **If** the goal is to simplify the language for all newbies rather than just the ones that choose LISP based on the current situation (I've concluded that this is a goal for Racket, correct me if I'm wrong), **then** it's obvious that such complexities need to be boiled out no matter how trivial they seem after they're learned. Emphasis added. Notice that I was not saying "We need to change this in Common Lisp", but rather "If you are in the situation of creating a new language, and that language is geared mainly towards newbies, it's valid to avoid the same choice". &gt; My response was to show that you had a misconception about the function namespace. It's not an historical wart that should be boiled out like null or atom. The Lisp-2 on purpose. That the function namespace was a deliberate choice is true, and at no point did I dispute it. You did show me that unhygenic macros are more dangerous than I thought in a Lisp-1, but my point wasn't that this feature was a mistake or a historical accident. Rather that it *added complexity*. Specifically, it adds complexity when using high-order functions (by necessitating `let` vs `flet`, `funcall`/`symbol-function` and the `#'` notation for function names. It's a trade-off. The Racket team went the other way, and you said (relating to a post by Matthias Felleisen wherein he explained his choice) &gt; I read that post and I quite literally do not understand what he is talking about. Perhaps someone here can explain it better. All I was trying to point out is that, yes they took a different path, no it was not a mistake either. &gt; But I do speak up when I see misconceptions being propounded, such as the suggestion that the function namespace is an historical artifact like atom. One more time, because you don't seem to like reading things you didn't write. I'll bold it, hopefully that helps. **I did not claim that the extra namespace was a historical fact. I claimed that there are conditions under which a different choice is valid and that it complicates higher-order functions. Stop misrepresenting what I said, please.** EDIT: Clarity.
Our first conversation began when you wrote, &gt; 1. It's easy for people to forget that macros work this way (if a-template was an equivalent function, you would not need to re-evaluate all its callers) &gt; &gt; 2. In more complex situations, it's easy to lose track of what you need to re-eval along with the macro. It's hard for me to read that and take seriously your latest assertion that what you are saying "has nothing to do with not knowing the set of code you need to re-compile" or your assertion that you weren't talking about "what pieces of code need to be recompiled". You state "the set looks different for foo the function than it does for foo the macro", but this is just another way of saying that one needs recompilation and the other doesn't. You present this as a different concept, but it's the same thing. I think we agree that Lisp-1 vs Lisp-2 is a trade-off. Lisp-1: higher order functions are nicer, but macros are more complex and opaque. Lisp-2: higher order functions are less nice, but macros are dead simple and their literal expansions are immediately viewable at any time. People banter forever about Lisp-1 vs Lisp-2, but the recompilation issue is a total red herring. I'm still not sure you understand that the solution is to reload the ASDF project. If you did, I don't think you would have written points 1 and 2 above, and I don't think you would have asked a similar question on this thread. By the way the Scheme blog post still makes zero sense to me. Suppose in my .emacs file I replaced every compile command and every eval command with an ASDF reload function. Or I replace them all with a command that restarts the REPL entirely. Now I have the setup being advocated in the blog post. I don't understand why this is being framed as "taking a different path", when one path is a strict superset of the other. This isn't an issue of trade-offs like Lisp-1 vs Lisp-2. It's an issue of "I have a wooden mallet" vs "I have wooden mallet and a knife". 
You introduced the list in question with the text "There are places where I wish Common Lisp did a better job of that including". Yes, Lisp should have done a better job with `atom` and `null`. Backward compatibility with Symbolics code was the wrong choice. Lisp could have done a better job in naming `sort`. I agree. But you included the Lisp-2 issue in that as well, for which Lisp did the right job. It did the only sensible right job for `defmacro`. It's pretty clear that you didn't understand the reason behind Lisp-2 because you listed it alongside things for which CL could have done a better job, and you said "I wish Common Lisp did a better job". If you still think I'm misrepresenting you, then you should first consider the possibility that you are misrepresenting yourself, if only by mistake. I'm only going off the most natural interpretation of your words that I can imagine.
&gt; ...the recompilation issue is a total red herring. I'm still not sure you understand that the solution is to reload the ASDF project. ... &gt; By the way the Scheme blog post still makes zero sense to me. Suppose in my .emacs file I replaced every compile command and every eval command with an ASDF reload function. Or I replace them all with a command that restarts the REPL entirely. Now I have the setup being advocated in the blog post. I don't understand why this is being framed as "taking a different path", when one path is a strict superset of the other. You still seem to misunderstand the basic issue here. I'll start again. - When you change a macro, you need to reload the project (or just the part that calls that macro). - When you're dealing with functions, you can get away with merely `C-c C-c`, which re-evaluates just that function. - If you use the default SLIME `C-c C-c` on a macro, you get stale definitions in that macros' callers. Follow so far? The decision the Racket guys made is to discourage the second and third options. As in, the Racket REPL nags you to reload the entire listing whenever you make any change, even if you could get away with just reloading one function. Yes. Lisp gets both options and as I've said **multiple fucking times** in our conversation, this is not a trade-off. I see this as a mistake on the Racket guys part and prefer having the choice (which is one of the reasons that I'm not using Racket myself). Their reasoning has nothing to do with which one is more useful from my perspective; it's a user interface decision. There is only one option for their users which they believe keeps newbies (and some more experienced folks) from tripping themselves up (I don't know if or why they really do that; I read the same blog post as you, albeit it seems with a different perspective. Perhaps you should ask Matthias about it). Now, the decision is founded on an attempt to simplify things for newbies. Therefore, **even though I don't agree with it**, I can see why they would do it and agree with the **premise** (as opposed to the conclusion and implementation). The next time you feel like calling me out on my opinions, kindly attempt to know what my opinions are. I have plenty of stupid ones, but those you've taken issue with so far were either misconstrued or not mine.
That should definitely be enough horsepower to run DrRacket effectively. Can you report a bug describing the issue (preferably via the "Report a bug" entry in the "Help" menu of DrRacket)? Thanks!
Except that you seem to selectively ignore words in order to paint me as a Lisp-2 hater. You're right, *on its own*, the phrase &gt; There are places where I wish Common Lisp did a better job of [boiling out complexity including... followed by "Lisp-2" would be an indictment. Except that what I actually said was &gt; the dual namespaces that force you to decide between defun/defvar, let/flet, and keep you from passing a function around just like a variable which I think makes it pretty clear that I'm talking about annoyances with higher order and inline functions. I do think you're grossly misrepresenting me, and it's not something I can explain with a mistake on my end. Even if I was slightly unclear, I can't see a basis for your accusations of "creationist" (by which I assume you meant "holds irrational beliefs"), "advocate" (because I haven't been advocating) or that I "[tout] that Lisp should not have a separate function namespace". That last one is particularly egregious and tells me you haven't been paying much attention because I've explicitly stated several times that I don't think Common Lisp should lose the namespace. A separate language with different goals, more focus on higher order functions and less on unhygenic macros is a different story.
The stale fasl problem rears its ugly head when the Lisp implementation *itself* is upgraded, not when one of the source files changes. So you'd need some sort of version flagging, which isn't covered in the Standard, so you'd have to get all the implementations to agree on how to communicate to `asdf` (Lisp's `make`) and similar tools when it had undergone a `fasl`-incompatible upgrade.
&gt;You're right, *on its own*, the phrase &gt; &gt;&gt;There are places where I wish Common Lisp did a better job of [boiling out complexity including... &gt; &gt;followed by "Lisp-2" would be an indictment. Except that what I actually said was &gt; &gt;&gt;the dual namespaces that force you to decide between defun/defvar, let/flet, and keep you from passing a function around just like a variable Lisp-2 means exactly the latter -- replace it with "Lisp-2" and it's the same. That's why it's an indictment, as you say. By your own standards you have been indicted. I didn't misrepresent you at all. Are you just keeping this up to avoid admitting that you misunderstood the purpose of the separate namespace? Nobody cares that you don't know everything, but carrying on like this is a different story.
&gt;You're right, *on its own*, the phrase &gt; &gt;&gt;There are places where I wish Common Lisp did a better job of [boiling out complexity including... &gt; &gt;followed by "Lisp-2" would be an indictment. Except that what I actually said was &gt; &gt;&gt;the dual namespaces that force you to decide between defun/defvar, let/flet, and keep you from passing a function around just like a variable Lisp-2 means exactly the latter -- replace it with "Lisp-2" and it's the same. That's why it's an indictment, as you say. By your own standards you have been indicted. I didn't misrepresent you at all. Are you just keeping this up to avoid admitting that you misunderstood the purpose of the separate namespace? Nobody cares that you don't know everything, but carrying on like this is a different story.
"Lisp-2" doesn't mean exactly the latter, otherwise I would have said "Lisp-2". I'm concerned specifically with the complexity it introduces in dealing with higher-order functions. Why is this so difficult to accept when you've already agreed that Lisp-1 vs Lisp-2 is a trade-off? I neither claim to, nor do I know everything. I'm responding to you because you started this particular thread off with accusations that were disproportionate to comments I've made. I will continue until either - you acknowledge that calling me a creationist was unwarranted and that accusing me of asking for Common Lisp to drop the function namespace was inaccurate - you stop talking to me either is perfectly fine.
Well there it is. A claim that Lisp-2 does not mean separate namespaces. A contradiction has been obtained, making this reductio ad absurdum proof is complete. The thing to learn from this is to just admit mistakes when you make them. Nobody's going to blame you for being mistaken. You become extremely foolish, however, contorting things to appear otherwise. Eventually the contortion leads to an outright contradiction, and there's no way out after that.
 (defmacro defun* (&amp;whole whole name (&amp;rest params) &amp;body body) (setf (get name :definition) whole) `(defun ,name ,params ,@body)) (defun* hello (person) (format t "hello, ~a~%" person)) (get 'hello :definition) The last expression returns: (DEFUN* HELLO (PERSON) (FORMAT T "hello, ~a~%" PERSON)) You can replace `defun*` with `defun` if you like by shadowing the symbol. I don't know what other lisps do, but the above is probably the usual CL solution. If you want the definition of code that's already compilied, then you're out of luck in any language, of course.
Thank you. &gt; If you want the definition of code that's already compilied, then you're out of luck in any language, of course. I fear this is going to be my problem in many cases...
Actually there's [function-lambda-expression](http://www.lispworks.com/documentation/HyperSpec/Body/f_fn_lam.htm), but implementations are not required to return anything interesting. CLISP respects it, at least. I assume compiled lisps are less likely to do so, but a high debug setting might work. I'm just guessing, though -- I've never used the function.
Common Lisp has DISASSEMBLE, which gives the assembly for a given function. There's also FUNCTION-LAMBDA-EXPRESSION.
If you understood ASDF reloading, as you assert here, then why did you ask the question on this thread? ("...how would you automatically decide...")
Odd to use PureData as the example, since it is a message-passing object system. In comparison, [OpenMusic](http://repmus.ircam.fr/openmusic/home) is a visual music system based on Lisp, which might make a better basis for this. In OM, blocks are functions rather than object instances.
Ok, so what I'm taking from this is that you don't actually give a shit that I was talking about a specific aspect of multiple namespaces as opposed to its entirety and are more concerned with proving yourself correct. I'd appreciate you stop putting words in my mouth at every opportunity, but you're not likely to stop. Enjoy having proven your puppet argument wrong and don't bother talking to me again.
Because I didn't have ASDF-generated `.fasl`s in mind. I meant in general. As in, when you hit `C-c M-k` and then copy it out to your deployment environment. In hindsight I probably could have thought that through better before saying anything.
I'm afraid that I'm far too impressed to be critical. Maybe I've been under a rock for a while, but showing the assembler underneath a visual block? In case anyone else runs into this: I've already email the author about broken Blogger and YouTube links.
This isn't entirely related, but if anyone uses Max/MSP and is interested in incorporating Lisp code into their Max patches (incredibly useful if you are doing data intensive live sound/MIDI manipulation), I wrote a Max object and corresponding Lisp function that communicate over OSC that makes life SO much easier. I really enjoy working with Max and Lisp together, as I do a lot of musical AI stuff, and this lets Max do what it's good at (I/O, data routing, timing) and Lisp do what it's good at (list handling and processing). Let me know if anyone would be interested, and I can upload the stuff.
What words have I put in your mouth? You can immediately remedy the situation by explaining how Lisp-2 is not "the dual namespaces that force you to decide between defun/defvar, let/flet, and keep you from passing a function around just like a variable". That's what it comes down to. The other explanation is that you were mistaken about something all along, and you have been lashing out at me for your mistake. But despite your best efforts to demonize me, nobody is going to fault me for thinking that "the dual namespaces that force you to decide between defun/defvar, let/flet, and keep you from passing a function around just like a variable" refers to Lisp-2. This indicts you, as you explicitly said yourself. Why don't you drop the charade and act reasonable? It's OK to not know something. Lashing out at others to cover for it is deplorable, however. You should be ashamed.
Well "in general" nobody in their right mind would write a project without a deterministic way to build it, which means ASDF or something equivalent. Can't you see this from my perspective? On the other subthread you agreed yourself that you were indicted on the Lisp-2 issue. Now, here, you are suggesting that there's some unsolved problem with fasls or something. These two data points are pretty damning. They suggest that you are starting from a conclusion and trying to make stuff fit into that conclusion. In that sense it's exactly like creationism. You aren't necessarily conscious of this.
The [genuine article](http://nojay.livejournal.com/69340.html) doesn't have keys for doing multiple parentheses with a single key stroke, but, look closely, it does duplicate the paren keys. (see my comment)
Ah. Do each CL implementation have their own FASL format?
Yes. Not only that, but FASL formats change from version to version of the same implementation.
You two sound perfect for each other.
The Blocky website looks like [this](http://i.imgur.com/EX0cw.png) in Chrome. Otherwise, cool beans!
It took me a while to get the joke, but it was worth it! Here's another: There was a joke back in the 80s when Reagan's SDI program was in full swing that someone stole the Lisp source code to the missile interceptor program and to prove it he showed the last page of code... )))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))
Sounds interesting, please post it! I'd love a good alternative to javascript. 
You got it- I need to clean up a few things, but I'll post it in the next day or so.
That is some heavy duty stuff.
It doesn't bode well for my social life that my first thought on seeing this was "Wow, that would be really useful! I wonder how much it costs?"
Posted a new CL version incorporating your suggestions.
very nice! I'd like to have a try.
too cool for C-c C-) ? :')
In Soviet Russia, Natalie Portman pours hot close-parens down your trousers. Enough already.
How does one run the GUI application seen in many videos such as: http://www.dailymotion.com/video/xksmk2 ?
did i get sucked through a wormhole and end up on slashdot?
Parens belong in unshifted positions.
Exactement.
My question on the submitted keyboard was why the parentheses weren't in easier-to-reach places.
Actually, that's a Russian smiley face.
You can pry my parentheses out of my cold, dead hands. Also, you almost never need more than `((` open parentheses.
If you're using SLIME, you can go to a procedure definition with M-. on the procedure name (works with libs and with your Lisp implementation if you have the sources installed).
Silly. You already have C-u in Emacs.
The most typed letter in English is "e". In QWERTY this character is in a terrible position, on the other hand, in Dvorak it is replaced with the dot character ".". I switched to dvorak and since the "." is only used for cons cells (a . b) I switched the dot character to paredit-open-parenthesis. This works like a charm, and now I can type common lisp programs at lightning speed, far faster then I can think. The main advantage is when writing throw-away scripts, copying pre-existing code, and when writing something I have otherwise already thought out.
I'm glad someone said it.
Why websockets and not just regular AJAX calls? 
OK, if I was to use AJAX instead of websockets, what would be your recommendation?
There are 2 CL websockets servers that I know of, [clws](https://github.com/3b/clws) and [hunchensocket](https://github.com/e-user/hunchensocket). I use (and wrote) clws, but haven't really exposed it to any serious stress yet. It uses iolib and runs on sbcl and ccl so far, and supports current drafts of the websockets spec (ccl and recent protocol support are only on the 'refactor' branch for now, but should be merged to master in the near future). Don't know much about hunchensocket beyond it working with hunchentoot (something clws doesn't currently do, due to iolib vs usocket usage). 
http://www.reddit.com/r/lisp/comments/kjqnk/lisper_the_maxmsp_to_lisp_interface/ Posted it! Let me know what you think.
Thanks, looking at clws now. I have a lot to learn.
For the webserver compontent is [hunchentoot](http://weitz.de/hunchentoot/) by Edi Weitz. Its probably the most widely deployed lisp web server. I personally love it. Seems like a good fit for your needs as well, allows a lot of customization when it comes to handling requests, etc.
awesome
Nice, good job!
What exactly it is is implementation defined; for example, I wouldn't call SBCL fasls byte code, because it compiles down to native code, but I wouldn't call a SBCL fasl native code either, since I'm sure there's tons of metadata there. Think of them like object files.
&gt; I thoroughly explained that it exists because of defmacro, which has advantages over other macro schemes but does not fare well in a single-namespace language. I hadn't heard this argument before. Care to elaborate? Any thoughts on how that might or might not apply to Kernel-likes?
If I switch implementations, do I have to delete relevant FASLs, or are each of the implementations able to identify and ignore FASLs built by themselves/others?
Looks fine on my Chrome 12.
[Overtone](http://github.com/overtone/overtone) is something similar that is written in clojure and runs on top of SuperCollider. check out a [demo](http://vimeo.com/22798433) of it!
The implementations I've used have different filename extensions for them. If there is a conflict, from a version upgrade or a name clash, then you'll get a self-explanatory error and you'll know to delete them. SBCL at least can be configured to store fasls elsewhere, too.
Well, cl-svg is one option for the image generation. On the web side, if this were on a normal server I'd suggest investigating sb-fastcgi/cl-fastcgi. These allow CL to sit behind Apache -- IMO a good thing for integrating with other software. However, that would add unnecessary complexity for a desktop app.
Didn't expect this to be anywhere near so good. Usually they don't have actual singers doing this sort of thing!
This is [Eternal Flame](http://www.gnu.org/fun/jokes/eternal-flame.html) by Julia Ecklar.
It is a pity gnu abandoned Lisp as their primary and promoted high-level language.
[Land of Lisp](http://landoflisp.com/) does this, only he *creates* a simple web server (NOT SERVICE, A SERVER) and sends out SVG files. In about three or four pages. Simple ones. Still you should use Huntentoot, as it is ready to go and is fun to say. SVG *can* support javascript and should, for client side requirements. Only *certain* web browsers don't support it. Surprise surprise. I swear they do everything they can to make people use their products. Oh, and you should know about cl-json. Lisp&lt;-&gt;Json library. 
Thanks for the pointer. My copy of Land of Lisp arrived recently, but I have not read it yet. I was assuming some javascript would be involved, which is not a problem. I was going to see whether parenscript would be helpful for this. I don't have any problem requiring a particular browser.
Any particular reason to resort to CGI though? Seems to me it would be just as easy and probably more pleasant to use Hunchentoot behind nginx or lighttpd.
Can you explain more clearly? Do you mean that recursive functions throw exceptions containing the continuation? Is this an implementation of trampolining? If not, how are exceptions used?
Did you click on [the link](http://www.reddit.com/r/lisp/comments/k9r4q/lispers_what_are_the_primary_benefits_you_see_of/c2inchm)? I am happy to answer questions, but you haven't told me what part is unclear.
https://sites.google.com/site/sapidlisp/recursion-optimization
I was hoping to not have to dig through what I not-entirely-wrongly assumed to be a vitriol-filled argument. It looks to me like you're arguing that lisp-2 prevents the lexical shadowing problem, but that's not true at all: global variable references can be shadowed with let, and function references with flet. Sure, it decreases the chance of a collision, but it still happens. This is exactly what Kernel solves elegantly, too.
Excuse me? There is no vitriol in the link. About Lisp-2, do you have the same misconception as [this person](http://www.reddit.com/r/lisp/comments/k9r4q/lispers_what_are_the_primary_benefits_you_see_of/c2ioaui)? (defpackage :foo (:use :cl) (:export :do-stuff)) (in-package :foo) (defun stuff () (format t "foo stuff~%")) (defmacro do-stuff (&amp;body body) `(progn (stuff) ,@body)) (defpackage :bar (:use :cl) (:use :foo)) (in-package :bar) (defun stuff () (format t "bar stuff~%")) (do-stuff) (flet ((stuff () (format t "flet bar stuff~%"))) (do-stuff)) The output in both cases is `foo stuff`. The `foo` package can export `stuff`, but CL does not allow conflicting symbols and shadowing must be done explicitly. In short, what you said just isn't true.
Thanks! Seems to be using exceptions basically as a way of detecting an alternate return value. I'm not sure I totally see the advantage of exceptions here, as opposed to just returning a pair value describing the loop/no-loop status along with the return value. Wouldn't there be some important efficiency differences?
That's due to the package structure you've used, which has nothing at all to do with CL being a lisp-2. Your flet doesn't shadow foo:stuff because its name is interned in package bar. Just like having a separate function namespace, this is but a bandage on the problem; it stops you from bleeding to death, but the wound is still there.
But I already addressed that in the second link, which is why I gave it. &gt;Contrary to your perception (or my early perception), functions inside a macro definition are safe. (Unless you export them and accidentally redefine them elsewhere, which is a totally different problem also afflicting Schemers and having nothing to do with hygiene. Most (all?) CL implementations give a warning when that happens.) You can redefine functions in a Lisp-1, too, e.g. Scheme. So I don't know what your point is about Lisp-2. Your gripe seems to be with mutable state, which has nothing to do with Lisp-1 or Lisp-2 namespacing.
Shadowing is not at all the same as redefining.
Of course, but that only makes me wonder ever more what your purpose is. You began by quoting my words, &gt;I thoroughly explained that it [Lisp-2] exists because of defmacro, which has advantages over other macro schemes but does not fare well in a single-namespace language. You responded, &gt;I hadn't heard this argument before. Care to elaborate? Any thoughts on how that might or might not apply to Kernel-likes? Having not clicked on the link, you asked me to elaborate. Since the elaboration is in the link, I provided it again. Here it is again: is the bottom of [this](http://www.reddit.com/r/lisp/comments/k9r4q/lispers_what_are_the_primary_benefits_you_see_of/c2iw401) not a precise explanation for why `defmacro` is bad in Lisp-1? Again, what problem do you have with what I said there?
The fact that lisp-2 doesn't actually solve the problem at all, just make it rarer.
Of course, but that doesn't answer my question: what problem do you have with what I said there? Give me a quote that you think is wrong. Are you just disagreeing with CL's approach? Flet can be a convenient tool. I can lexically replace a function with an equivalent that does some logging or whatnot. As I said, CL does not tolerate symbol conflicts and symbols are imported explicitly. If `flet` is being used to override an existing function, it is done so intentionally. Well, it could be unintentional, but, you know, the sharp knives argument.
"Clojure is obviously the most popular Lisp today." I'm not saying that the statement is patently false, but it's not obvious that it's true either. Saying that "Clojure is the best publicized lisp outside established lisp circles today." has the ring of truth, but if you want to call it the most popular lisp, we're gonna need some numbers. Going by installed base, elisp is almost certainly the most popular. Going by "curious about X" Clojure is probably at the top. Going by people who self-identify as "serious users of X", I have no idea. Going by applications deployed per month, I have even less idea. Going by people visiting websites whose backend involves X, I'm willing to bet a beer or two that Common Lisp and Clojure both beat Scheme -- but I would not put actual money on it. 
Ok, so I have a problem with the following: &gt; Scheme is only useful for teaching in universities Even if you discount Rackets' `lang-scheme` as a scheme, I have to believe that someone out there is using [Chicken](http://www.call-cc.org/) or one of the other C-targeting schemes in production. &gt; ... there’s Common Lisp, which is just a horrible, horrible mess (think C++ but with more parentheses than you can shake a stick at)" ... Which I *might* agree with, depending on what he meant *if* sufficient arguments were presented, but it doesn't fly as an assertion and he never follows up. &gt; Clojure is obviously the most popular Lisp today. A better lisper than me has already tackled this one. I just wanted to remind everyone that [tiobe](http://www.tiobe.com/index.php/content/paperinfo/tpci/index.html) actually lists "Lisp" at the top (which I assume means "Common Lisp", since they list "Scheme" separately. "Clojure" isn't even in the top 100). &gt; Clojure is obviously the most popular Lisp today. Some people would even consider it the only Lisp that’s actually practical anymore. Weasel words aside, I take issue with that as someone who currently does production work in Common Lisp. The real problem here is why he thinks this &gt; It added syntactic sugar for more datatypes, seamless integration with the JVM, and it ditches all the old legacy junk of traditinoal lisps. "Syntactic sugar" is something you can add copious amounts of already in (AFAIK) any Lisp and "seamless integration with the JVM" is one of the big reasons I *don't* use Clojure (ymmv, of course). Further, if it was such a huge deal, I'm reasonably sure [Kawa](http://www.gnu.org/s/kawa/) and [ABCL](http://common-lisp.net/project/armedbear/) exist. Again, "legacy junk" might be legitimate, depending on what he means, but he's short on details. &gt; ... there’s no sane interoperability from an algorithmic language like Lisp to a processor-driven language like C ... I. Uh. [What](http://www.cliki.net/UFFI)? &gt; ...But that dream dies quickly with the realization that those languages each provided an emacs-free REPL which anyone could quickly leverage to become an expert in the language in weeks flat. The s-expressions inherent in Lisp simply won’t allow for that. ... oh. I'd better stop using [SBCL + linedit](http://xach.com/lisp/linedit-screencast.gif) since Lisp simply won't allow that. Also, I haven't done it in a while so this in an honest question, is instaling [Lispbox](http://common-lisp.net/project/lispbox/) really difficult enough to justify *writing a new language* to fix it? Incidentally, the worst (funniest?) part of the entire article is &gt; I’ve been considering the possibility of writing another Lisp dialect, and where it might fit. My prediction, in case you care (and there's no particular reason you should): poorly implemented port of Dylan to the JVM with curly braces and a Java-style object system. That's if he's serious. Honestly, this article has the feel of someone trolling for pageviews. EDIT: Teh grammers.
I'd think so, since exceptions are usually pretty costly to handle. But it'd need more careful measurement, and benchmarking for each particular implementation.
i agree, but i guess i don't really understand what exceptions bring to the table here so i wouldn't be motivated to do such a comparison. I'm wondering if the author could expand on why he took this approach.
&gt; [...] Common Lisp, which is just a horrible, horrible mess (think C++ but with more parentheses than you can shake a stick at). I make my living coding in both Common Lisp and C++. Neither of which would I consider to be "horrible, horrible" messes. This statement is a prime example of the someone who doesn't (seem to) know what they're talking about parroting what someone else has spewed in their presence without fulling understanding it. If you are going to make a statement like that, you sure as hell better back them up. I spent well over a year, maybe two, writing in Clojure as well when my job required me to work in a Java ecosystem. Clojure has a lot going for it: I really like its functional nature and the inherent support for concurrency. Is it the "most popular Lisp"? No idea. Is it the Lisp with the most mindshare, undoubtedly: the sheer size of the Java community will see to that. &gt; But that dream dies quickly with the realization that those languages each provided an emacs-free REPL which anyone could quickly leverage to become an expert in the language in weeks flat. The s-expressions inherent in Lisp simply won’t allow for that. That statement is so laughably wrong I don't even know where to start. &gt; I’ve been considering the possibility of writing another Lisp dialect, and where it might fit. But thankfully concludes that Clojure fits his needs just fine. Which is great. If you can, or need, to reside in the Java ecosystem and you want to program in Lisp, Clojure is a swell choice. But so is ABCL. 
I guess it depends on how big of a difference stack unwinding costs when returning vs when throwing an exception. Either way it can't be as efficient as a real tail call.
Well [lang-index](http://lang-index.sourceforge.net/) ranks Lisp at #20 in popularity, between Go and Lua. That sounds about right. Clojure is #68, between Maple and the AS/400 Control Language. It isn't even mentioned on [tiobe](http://www.tiobe.com/index.php/content/paperinfo/tpci/index.html). Clojure will always be a small slice in the JVM world, I think. Not many people like paren languages in the first place, and a whole lot of people either actively avoid the JVM or just have no need for it.
Well. You know, you have this fun and simple recursive interpretor handling dynamic non local exits. Unfortunately, it crashes after some recursive calls. You knew it had to. Now you face the choice to either rewrite it with trampolining or whatever, or use the magic wand changing a single function (evalexpr in that case) and making the whole thing tail optimized. (To be honest, they are some precautions to be taken to make it work). I have chosen the magic wand :-) I understand recursion optimization can be done by controlling explicitly a loop status. However, I cannot imagine doing that without testing the status all along the call path. Aren't exceptions here to avoid that? Regarding bench and timing, this is described in the page linked above. 
Why not use lexical scope, out of curiosity? It isn't much harder to implement and it is _substantially_ nicer. 
I guess I just don't see a big difference between: while True: try: x = eprogn(fval.cdr) break except TailRecException: pass and loop = True while loop: loop, x = eprogn(fval.cdr) Not sure what is has to do with the program crashing.. you mean because of stack overflow? Are you actually catching stack overflow exceptions and _then_ performing tail optimisation? That would make some sense, but I can't quite see it in the code -- you seem to be detecting tail calls and popping the stack quite explicitly. Maybe a diagram would help :)
Yes, of course written this way, it is equivalent. I am also interested in the rest of the program. Have you any working example of a complete interpretor? I mean an example of transform from a complete interpretor without tail recursion optimization to an optimized one. 
Good question. The answer is in the web page: no more reason than I learned lisp years ago with a dialect implementing dynamic binding. It was tempting to implement lexical binding in sapid but I preferred to limit the development to release a consistent package. Now, to continue this project, I have the choice to implement sapid lisp in a compiled language (with exceptions!) or implement lexical binding. What would you advice?
I'm not sure if I'm reading your tone correctly, but you seem to be taking offence here. Please don't; if you are then rest assured that it's not intended. You asked for feedback on your technique. I'm simply asking why you did it this way instead of just returning a value, because I don't see the advantage. If your answer is "because it was easier to implement," then that is fine. I'm only questioning whether it's an efficient thing to do.
[Here](http://pastebin.com/raw.php?i=yKvX9imQ) is a little racket program that will create a file containing the names of all the default namespace defined symbols. (tip: you can use it as a Vim dictionary to get auto-completion)
Just as a data point, it didn't seem offended to me, rather it was a request for more information.
&gt; Regarding bench and timing, this is described in the page linked above. The efficiency radarsat1 was referring to is "efficiency of TCO handling done via throwing exceptions compared to an implementation of TCO using explicit flow control". Ie. exceptions are a relatively expensive way of returning, and thus can impact the performance negatively if overused.
I thought this too but seeing unbalanced parens would make my brain explode every time I looked at my keyboard! Seriously, one point of typing one closing paren at a time in an advanced editor is that you get to see visually what open paren it matches up with. I do this in Java (day job) as well except instead of just being able to type a close paren, I have to guess if it should be ) versus ] vesus } which has me thinking I'm missing some magic Emacs command that just inserts the right type of balanced close delimiter (and flashes the open delimiter it is closing). (And no, I don't wish to use something like par edit or worry about keeping parens always balanced in the middle of an edit.) The most annoying thing about XML is that guessing the end delimiter is even more impractical (again, I guess I need a special emacs command). I was a lab assistant for a Scheme programming class and the lack of knowledge of how to just add enough closing parens (and watching what they closed) and the lack of knowledge of how to quickly re-indent a top-level definition was an important simple skill to teach for writing Scheme code. I'm not sure how many students even knew about the tab key in scheme-mode). I actually don't think parens are much of a challenge for reading Lisp-like code as long as it is properly indented - you just need to learn to ignore the parens and see the structure (so maybe my brain wouldn't really explode like I claimed). Of course I love parens because of the sexp movement command in Emacs and how predictable they are (I use them in other major modes of course). I'm not surprised that JSON is slowly winning the text format for structured data war since it is so much easier for a human to read versus XML (but the reality may just be that people are using JSON because of ease of use with Javascript). 
Well, you're a python user, so you know no one really cares about speed anymore in high level languages. And lexical binding is basically the only way to go these days, apart from some partisans in the New and Pico Lisp camps, so I'd go with lexbind. If you implemented an integrated Lisp in Python that could call out to scipy functionality, I'd be ecstatic. I'd love to abandon Matlab for a nice, modern Lisp.
Not sure how seriously I take that... it's really hard to believe that javascript would be behind ruby. Perhaps they are going by lines of code? That would not be a good measuring stick.
I'm still something of a beginner with CL. I've never done much with macros, or most esoteric CL features. But I just completed a project porting some 20k LOC from Pascal to about 1500 lines of CL. This was the first project I have done using quicklisp. This project finally got me over a hump in the learning curve. Prior to this, I would anticipate a new CL project with a mixture of excitement and dread. Excitement, because of the pleasure I experience developing in CL. Dread because of memories of all the times I've been stuck trying to find the right versions of the right libraries and get them to play together. Dread also because I never really understood the packaging system, and asdf seemed mostly like magic to me. If it worked, fine. But if it failed, I was immediately lost. Now, I still have the excitement, but the dread is gone. Quicklisp obviously solves the library problem. It also provides ql:quickproject, which somehow finally allowed me to 'grok' the packaging system. Also, prior to this project, I had been using the older version of asdf which I found hard to understand. Now, everything is asdf version 2, which is much more coherent to me. I also found it difficult to keep my CL install, slime, and asdf all up to date. It's now easy to update them without breaking things. There is still much to learn, and I'm doing that gradually. I'm trying to become competent at debugging using slime, but I'm finding the stack traces (from sbcl) cryptic. Give me gdb and a stacktrace from code compiled with gcc, and I have no trouble getting to the correct line of code very quickly. With slime, I get lost very quickly and have to resort to sprinkling print statements around to see where the problem happened. I also need to find the correct way to invalidate all the fasls in my project. Currently, I have a makefile with a 'clean' rule that just knows where they are and explicitly deletes them. But I suspect there's some official way to do this. I still run into problems caused by stale fasls and code that doesn't get recompiled when it should. But anyway, as far as I'm concerned, quicklisp is a lifesaver, and it finally put me over the edge with CL development, to the point where I can tackle anything and know I'll be able to make it work. Thanks, Zach. 
Thanks to quicklisp I can keep multiple development machines (laptop, testing server, workstation) in sync very easily -- I still have to manage stuff I am working on (`clc-register-system` makes this less painful than it otherwise would be at least), but for everything else... `(ql:quickload ...)` and life goes on. Anything that makes installing UCW take a single command is a life saver (oh, how painful it used to be ...).
[Where does the special form LABELS come from?](http://www.reddit.com/r/lisp/comments/k1tnl/where_does_the_special_form_labels_come_from/)
Yes, I understand that. I'm asking why they didn't call it flet* instead of labels.
**labels** isn't *quite* **flet***—consider the following: CL-USER&gt; (let ((x 4)) (let* ((y (+ 1 x)) (x 100)) y)) 5 CL-USER&gt; (flet ((x () 4)) (labels ((y () (+ 1 (x))) (x () 100)) (y))) 101 **labels** is more akin to **letrec** (which does not exist in Common Lisp) than **let***. In fact, except for the scope of [declarations](http://www.lispworks.com/documentation/HyperSpec/Body/s_declar.htm), you can think of **let*** as a nested **let**: ;; this: (let* ((x 1) (y 2) (z 3)) ...) ;; is like: (let ((x 1)) (let ((y 2)) (let ((z 3)) ...))) If you defined **labels** this way, it would not permit recursion.
I always wondered, why upper case, why couldn't it lowercase everything? 
Quicklisp was a huge motivator to release code. In the dark days before, the libraries were so hard to track down a working version of, that often it was easier to just manage everything yourself. Now all (ok most) of that library pain is just gone. Now that there is a chance someone else will actually use or see something you release, it makes it very much worth writing some documentation and releasing the code in an accessible form. * Getting a new system setup for lisp takes minutes, which is fantastic. * My code quality has gone up, both because other people might see my code and because I actually think about how to get this loaded now, rather than taking the "it loads for me now on this system" approach. * Quicklisp has allowed others to use new versions much more quickly which causes bugs to be fixed more rapidly. More bug reports = more bug fixes. Quicklisp has very much been an inflection point. Its hard to even imagine lisp without that capability. 
Why is really the only question I have? Other than interfacing with other language's case conventions, I can't remember intentionally wanted two different variables that only differ in case in the same context. It has just always seems like setting a trap for myself.
After working with Common Lisp a while, I've come to the conclusion that I'd rather have a case-insensitive language. It removes the class of bugs possible with variables &amp; functions that vary only by case. 
Thanks for Quicklisp. The best tools are the ones which you have forgotten are there. Quicklisp is integrated into all my loading and setup scripts now. In my everyday use I give nary a thought about what's happening behind the scenes -- I just hit a key and everything just works. Considering the early history of Python and Ruby distribution, it is most remarkable that quicklisp has emerged without a single bug or problem, at least in my own experience. Alien technology indeed! Do you have any download stats available? Number of quicklisp clients, most downloaded packages, etc?
I think it's due to history. Back in the day ('70s) all code was uppercase.
Well I'm not touting it as an absolute answer, but it's a measure of something. There's nothing mysterious or opaque about the stats -- you can see how they are collected from the search links there.
Why not just use `let*` everywhere, or better yet, redefine `let` as `let*` in ANSI Common Lisp?
I am not that proficient in CL but I think Quicklisp makes CL development a breeze. (I hope I can use more CL in my work and contribute something in return) With Quicklisp, I no longer need to do so much plumbing about installiing libraries and dependencies. I thought it was an impossible feat for CL since some have tried the waters but they are not even close! A great achievement indeed! Thanks Zach!
We need a place to report problems and bugs. It is hard to trackdown the original authors and file bugs on hundreds of libraries. Could quicklisp host a bug tracking system where one can go and file a report on any of the libraries supported by quicklisp? That way it reaches everyone. Anyone with time and expertise can fix the problems and send a patch. Not just the original authors, who might have lost interest and moved on.
For building SVG xml files you might find both [buildnode](https://github.com/bobbysmith007/buildnode) and [talcl](https://github.com/bobbysmith007/talcl) useful. I haven't used these to build SVG before, but i have used these libraries to write multiple other XML dialects.
I, too, am much more likely to go ahead and use a library rather than roll my own now that Quicklisp is available. I'm also more likely to just upgrade my Linux box saving only my src/ and data/ directories instead of trying hard to keep from deleting anything on the box. Quicklisp's slime setup is god.
When you're in the slime debugger, you can hit "v" on a frame to jump to the defun that signaled the condition. If you compile the defun with high debug (easy to do with `C-u C-c C-c`), you "v" jumps to the exact form that signaled the condition. I use that pretty often. With ASDF2, FASLs are all stuffed in ~/.cache/common-lisp/. I haven't had problems with stale fasls for a long time now, but if you do, deleting that entire directory tree should clear things out.
I'd like to gather information about how to find more information about a project, including its documentation, authors, mailing lists, bug trackers, etc. It will take time, though.
Only after someone invents a really nice system to set up Common Lisp do we admit that setting up Common Lisp _before_ Quicklisp was a huge hassle. Two years ago if someone had posted "It is hard to set up Common Lisp," the community would have jumped down his or her throat (ok, maybe not r/reddit but definitely comp.lang.lisp). None of this is directed at you, Xach, since obviously you stepped up and solved the problem. Which is something neither the complainers, nor the people who got angry at the complainers, did. Quicklisp is awesome. I'm just making an observation. I've used Quicklisp to set up a project before, to answer your question, and its great. But I still prefer Racket. [EDIT: Upon reflection, I've decided this comment was obnoxious, but I'm leaving it up so that I can face my shame like a man.] 
Thanks for the insult veiled as a compliment.
Quicklisp is a killer app. If we can convince a few people to look at it, we could save various industries millions. Also, are there any plans to extend Quicklisp into a collaboration tool? Perhaps we could add something to the REPL where whenever we add or redefine a symbol, it could update a table which can then update the repo? Or even a real time update feature for dev teams?
Thanks for the tips about 'v', and high debug. Re deleting FASLs, that's what my 'make clean' does. I just assumed there must be a way to do it from the REPL. Maybe the problem is that I need to express the dependencies explicitly (as you do in a Makefile). I thought that the compiler would magically just know that when I change file x, it needs to recompile file y that depends on it.
It seems odd to me that you're hitting problems with stale fasls. If you ever run into a situation where you can reproduce it, I'd love to hear more.
Definitely wasn't meant that way _at all_. Sorry.
OK, be careful what you wish for ;-) I'm just starting a new project, so I'll ping you if I see it again.
"Steven has worked with a variety of programming languages including ruby, python, c, php, clojure, javascript, objective–c, html, css and bash–scripting." How can he talk about Common Lisp being a horrible mess if he never worked with it??? Clojure is a novelty so there are a lot of curious persons etc..but far from being the most popular Lisp today or anytime soon. Anyone knows about any Clojure project that can be compared, for example, to ITA Software products that are using Common Lisp?
Don't worry; it's a common slip. :D
I've used Perl's CPAN before. It is pretty nice - really nice, actually. I've used Python's PIP thing. I think it's terrible. I stared at ASDF and companions long ago and went on my way. I started in (for the second or third time) on Common Lisp a year or so ago and found Quicklisp. It beats CPAN. It does all the work of configuring and managing dependencies of libraries. It acts as a reference manual for what Lisp libraries are commonly used. Quicklisp is an enabler, the good kind. I do more with a Quicklisp setup in my Common Lisp. It is the Way Forward for right development. 
From the point of view of someone who has spent zero time looking at how QL does what it does, I'd like to say I love it. Although I don't get all of it yet, like rolling back to previous releases, and every once in a while something will fail and I'm not sure if it should be reported as a bug or not, I can say undoubtedly that QL has made my life measurably easier. Previously I had a built up, over the course of years, hundreds of libraries. Each library in whatever state I happened to have cloned their repo/downloaded their tarball. If I ever had something fail to build or display wonky behavior, I would have to start by upgrading it, check to see if that fixed the problem, then recursively move along the dependency tree, manually, until it worked or I ran out of dependencies. This was hit or miss and I was often operating with only a few working libraries, but luckily enough to get my research done. Then, I have to sync this tree of 420MB (and that doesn't include compiled files) to every computer I ever want to run my Lisp programs on. All of this, is now handled in QL. I actually have a library in the QL dist (Modf). Not sure who saw it fit to get it in there, but I'm honored that it is there. I tend to write something to the point where it works for my purposes, but now I feel like I want to improve my stuff beyond my own purposes because I have proof that other people are (perhaps) using it. I can't help but think that having a de facto gate-keeper for "good libraries" (or multiple gate-keepers if things like monkeydist become popular) only helps developers to keep users in mind when they publish their code. I know it has for me. I'd imagine that with something like QL running in perpetuity, we should expect better quality libraries in the future particularly in the areas of portability, less bugs, and active development.
After working with Common Lisp for a while, I don't see the need to case sensitivity either **unless** I have to talk to something that does, like every other language on the face of the planet (that might be an overstatement). Same issue with OS X and a case sensitive file system. It almost never causes a problem, but inevitably some idiot makes a two files, one called "Makefile" and another called "makefile".
(note I'm a {bad,long time beginner} programmer) Is your add-sprite function generic ? I mean, do you see it as a general function, which could unify some implementations behind the same behavior, or the same meaning ? When I'm writing a function, I always start with a defun. But sometimes I want to write another function with the same name ; in this case, I think about it as a generic function, that's all.
Sometimes :around and :before and :after method-combinations are nice. But, beyond that... not that I can think of. If you decide later that you want it to be a generic instead, it's easy enough to switch.
I wouldn't. If others use it, they might make a `defmethod :after`, and then maybe they extend in an undesirable way, or you break their stuff if you make changes on your end, because you weren't particularly interested in it as a generic, and describing what it should do.(Perhaps a bit unlikely case..)
Eh. I still don't use Quicklisp. I install most systems by tracking down a tarball and pointing ASDF-Install at it. Otherwise, its mostly just a matter of dropping a couple symlinks in your systems/ directory. I don't think that's really a huge hassle.
There's also nothing stopping you from just doing (defmethod add-spirite (index-x index-y position-x position-y spritesheet) ...) That will automatically define the generic function, etc. It will work more or less as a function, unless you choose to define a method.
Yeah, but then SBCL complains at me. :P
It's useful to define a generic function in case you change your mind about making it extensible later. It's a little like writing `cond` even if you only have two branches with single forms each. You also don't have to have separate `defmethod` and `defgeneric` forms, and the `defmethod` need not specialize: (defgeneric add-sprite (ix iy px py spritesheet) (:method (ix iy px py spritesheet) ...)) I do that fairly often.
Besides providing some arcane options, is there any real reason to use defgeneric at all? Why not just use defmethod?
All true, but they still should have called it flet*, and merely noted that it also enables recursion.
The generic is the primary thing, and methods provide the implementation. It's the ideal place to put the documentation and the only place to provide options e.g. regarding method combination. You can also define methods within the defgeneric form.
Well, I suppose it's time to remember the KISS rule. If you don't have any real visible need for defmethod go with more simple defun. Later, if you find that you want any functionality of defmethod you always can rewrite your code with it, can't you? 
Yes, but then the CL impl has to guess what the generic signature is, and that guess isn't always what people want. Kinda like how (setq *var* val) may make *var* special in some impls.
When you call defmethod, defgeneric is automatically called for you. So the question, I guess, is why impose on yourself a requirement to call defgeneric. I know it's accepted good style: but I don't see why, besides "well, everyone else did it that way". It seems to me to be one of those classic boilerplate things which provide little functionality in return for the excess typing you have to do. It doesn't buy you any compiling safety: if you call defmethod here and then defmethod in a different way there, it'll be just as bad as calling defgeneric here and then defgeneric in a different way there. And I'm not a big fan of globbing lots of methods together inside defgeneric -- stylistically I'd much prefer to have separate methods, just as Lisp for 50 years has had separate functions with defun. So the only remaining stuff I see is that defgeneric lets you define a documentation string for all the methods in the abstract (okay), and a few arcane options which are so rare that I don't recall ever seeing them in practice. These two things seem to me to be a pretty weak hook on which to hang the hat of requiring a defgeneric for every unique defmethod symbol you use.
I view it as "CL is case sensitive, except the sensitive part is somewhat broken". One readtable-case flag affects all symbols in a file, it requires coordination with *print-case*, etc. In fact, CLHS 22.1.3.3.2.1 feels the need to itemize the ways in which a read/write cycle can go wrong. Franz has done some interesting experiments with sensitivity. Personally, I think the case conversion should probably be moved to the vicinity of INTERN. In such a scheme, the reader might do no case conversion, but FIND-SYMBOL could do fuzzy matching depending on a couple factors specific to package-specific settings. Thus symbols in CL: could continue matching all cases, symbols in C++: could be case specific, ...
There is a couple of things to consider: 1. Is it a library or an application code? If it is a library then users might want to subclass `spritesheet` and make their own method, without changing library code. If it is an app then you can change to defmethod at any time. 2. If implementation is trivial, for example, a convenience function it doesn't need to be a generic. 3. I guess even a trivial GF will have some overhead, even if a tiny one. (Like following one indirection.) But if function called frequently, you do not want it. It is probably non-inlineable too. 4. If you mention type in the method it will do a check, which is a good thing for ensuring code correctness, but adds some overhead. 5. When I write CLOS code quick &amp; dirty I find it easier to add accessors to each slot and to make each function a GF -- in this case I don't have to waste time thinking, I can just type it. It can be refactored later, but usually it is good enough. I don't bother with defgeneric, though. Yes, SBCL complains, but it is perfectly legal. 6. There is one problem, though: if you need to change parameters of generic, you have to `fmakunbound` it, which is rather annoying.
Generic functions are the primary thing you're calling. A method is a fragment of the implementation of that generic function. You also need not define any methods at all; it might be part of a library provided for other components or consumers to implement. There *is* a convenience factor, too. If you change the lambda list of a defmethod and recompile, you'll get an error about congruence. If you change the lambda list of a defgeneric+defmethod and recompile, it removes the old generic first.
I think the FAQ should include this: "I wrote a library; how can I have it included in Quicklisp?"
That's the ~~first~~ second question in the FAQ.
Providing a docstring is the most usual good reason I think.
I am a professional developer working in common lisp. At work I use CL to work on a windows application. I also like to program at home to scratch various itches that I get for applications that I think would be cool. As someone who wanted to use open source libraries and implementations of lisp at home, I always found dependency wrangling to be a nightmare. If you could find the correct library, it wasn't guaranteed that it would then be compatible with the other libraries that you had found (using different versions of the same dependency, for example). It was nothing short of a nightmare. After a while, this drove me to switch to Clojure, which is a really nice language. But there are things I don't like about it, the whole java thing, having to read the stack-traces, lack of CLOS and lack of the robust restart system and debugging that CL has. But I soldiered on because it was better than spending a week or two searching for libraries and then hacking on them until they actually worked. Then Quicklisp came out, and I gave it a shot. It wasn't that the libraries for common lisp hadn't been there, it was that they weren't organized, they weren't compatible. With Quicklisp, CL libraries are organized and kept in a usable form. If I want a library, I simply ask for it from the repl. This has seriously brought me back to Common Lisp in terms of 'scratch an itch' programming. In terms of ease of use, this makes CL infinitely easier to use than Clojure, as I don't have to manage classpaths or anything... I rarely have to leave my emacs buffer to install a library. Sometimes I just download and try out libraries to see what they do. It takes the duration of the download to get hacking. This is a stark contrast to when I would spend an afternoon (or two) trying to get a single library to even compile. Anyway, serious kudos for quicklisp.
apologies, for some reason I didn't see it
&gt; but you can't put a docstring in a defmethod (defmethod foo () "This is the docstring" (+ 1 2))
There's another side to making something a generic function in library code: if you do that, you have to **expect** that users will add methods to it when they use the library and things should keep working fine. You'll probably have to document carefully the requirements opt hat new methods will satisfy. That's a big commitment to make, and you shouldn't do it without careful consideration beforehand. 
The order of evaluation of LET is unspecified to allow for compiler-specific optimizations. Imagine you might do something like this (defun fn (x) (let ((y 1) (z 2)) (if (zerop x) y z))) A compiler now has the choice of only evaluating Y or Z when it's needed and not waste time evaluating all the forms in LET. It may seem trivial here, but imagine Y and Z were calling some expensive functions, this allows for much better performance. You really shouldn't use LET* unless you absolutely need sequential evaluation, because it denies your compiler the opportunity to optimize your code.
Why? Because CL standardization process was concerned with backwards compatibility with older dialects of Lisp. But it's an easy enough fix, though should you, you'll have some 'splanin' to do if you share your code with other lispers: (defmacro flet* ((&amp;rest fns) &amp;body body) "Allows for recursive definitions of local functions. Synonym for LABELS." `(labels ,fns ,@body)) 
There's a lot of "I get what standard function/macro X *does*, but what does it's name *mean*?" from new Lispers. &gt; SETF -&gt; set declared field &gt; SETQ -&gt; set quoted symbol &gt; RPLACA/RPLACD -&gt; replace car/cdr (geddit, CA/CD wraps around the fn symbol to R?) Is there a glossary for such things?
The keyboards didn't have lowercase letters back when lisp was invented ;)
No, it isn't. You may be thinking of Scheme. &gt; The form [...example...] first evaluates the expressions *init-form-1*, *init-form-2*, and so on, in that order, saving the resulting values. — [CLHS: Special Operator LET, LET*](http://www.lispworks.com/documentation/HyperSpec/Body/s_let_l.htm)
Ah, that makes sense. I assumed the LET semantics were identical in Scheme and CL. I guess the standard specifies that they must be eagerly performed in parallel. I wonder if any compilers break from the standard behavior and use Scheme-like semantics on LET. **Edit** Apparently Racket uses CL-style LET binding too: &gt;The characterization of let bindings as “parallel” is not meant to imply concurrent evaluation. The exprs are evaluated in order, even though the bindings are delayed until all exprs are evaluated. 
Why does it need to guess what the generic signature is? The defmethod has a specialized lambda list, which is a superset of the lambda list for the generic function. It does force the impl to assume standard method combination and standard metaclasses but I'm assuming that's not what you mean.
That's mostly what I meant. CLHS on defmethod has a paragraph beginning with "If (fboundp function-name) is nil" that itemizes the defaults. I forget the exact problem, but there are cases where two defmethods without a defgeneric can work in one order but not the other (IIRC, one happens when only one method specifies &amp;key). Stylistically, I do prefer plain defun when there are no plans for dispatch. When dispatch is required, the defgeneric provides a good place to hang documentation, default methods, etc. This refactoring frequently changes the defun's lambda list in other ways anyway.
Before Quicklisp i use Common Lisp only for Intellectual exercise. After Quicklisp i use Common Lisp for All Purposes including Scripting,Fun,Algo,AI,Day Dreaming ,Mental Masturbation, etc.... With Quicklisp my Linux Laptop with SBCL is transformed to One Giant Powerful Futuristic super LispMachine which survived AI Winter. With Quicklisp i'm Learning from Others Code which is Priceless. With Quicklisp i suddenly got 550 Libraries to work with. And Thanks to Mr.Xach you saved CommonLisp and you bought CommonLisp Community together. I think you found Cure for Bipolar Lisp Programmer Disease. May the force be with you......... 
&gt; And no, I don't wish to use something like par edit That's what I thought until I used Paredit.
Why does every "improved" lisp try to incorporate brackets and/or other delimiters? Does anyone really believe that if they could just get away from parenthesis the entire programming world would flock to lisp? I'm instantly annoyed when I see that. (I'm fine if they're optional, as in some Schemes).
I just compiled it with clisp. I like partial application aspect. (map (/. z (z 10)) (map (/. x y (* x y)) [1 2 3])) [10 20 30] Is there any particular reason why Qi never caught on? I guess the Qi license was restrictive, but Shen seems to have fixed that.
I hate the brackets in some schemes. It's even worse that they are optional because it gives rise to varying styles. Use of brackets to denote lists (like in Haskell) seems OK, but I haven't used Qi/Shen enough to form an opinion.
I looked into it but found the alternate syntax of the typing system to be to far away from the original 'extension of lisp' to be what I was looking for. The syntax basically threw any type-system meta-programming out the window, so I didn't look at it for very long.
I didn't think he raised the money to go ahead with Shen. Maybe it just pushed it down to hobby status?
I don't think that is the case here. Taking a wild guess I would say that it was done in Qi/Shen in order to provide additional type hinting for the optimization system.
I would say Qi never caught on because it was based heavily on Common Lisp which doesn't exactly have the install base of CLR or the JVM. The Shen rewrite addressed this by the creation of K1 as a minimalist lisp needed to support Shen.
The [December 2010](http://www.lambdassociates.org/News/dec10/index.htm) newsletter says that he achieved the funding goals for Shen 
&gt;It's even worse that they are optional because it gives rise to varying styles. You make a valid point. I shall now dislike them in all aspects. (Even to denote lists).
It should be `fletrec`, not `flet*`.
&gt; Is there any particular reason why Qi never caught on? Here's my guess (note that all I know about Qi/Shen comes from a looking through its wikipedia page, but it only makes it more relevant): 1. It is not Lisp, syntax is far too complex. E.g. `N [M | _] -&gt; M where (&gt; M N)`. So lispers are not interested. Parts which look lisp-like make it only worse in uncanny-valley kind of way: it looks ugly because you're comparing it with pure lisp syntax. 2. Non-lispers will find it ugly because it looks like lisp. 3. There is a number of mature functional programming languages, like Caml and Haskell. They are widely available, they actually work... Even if Qi implements some interesting features other languages don't have, does it justify switching? 4. Lispers might prefer language with lisp syntax, but Qi isn't one. It actually looks more complex than Haskell (for me) because at least Haskell is logically consistent. 5. [Liskell](http://clemens.endorphin.org/ILC07-Liskell-draft.pdf) demonstrated that it is possible to implement pattern matching with real lisp syntax in a way which isn't too bad. 6. As I understand, Qi/Shen is Dr. Mark Traver who is a weird guy: http://groups.google.com/group/Qilang/browse_thread/thread/592773c562017d87 7. Qi/ Qi II/Shen. How is language named? Wait, they do not separate language from implementation? Is it PHP or what?
Yeah I don't know why Qi/Shen doesn't have an sexp option or least provide macros to convert `N [M | _] -&gt; M where (&gt; M N)` into an sexp and back again. The question of why not Caml and Haskell is the same question of why Lisp. The answer is absolute power and the end to greenspunning. Look at all the scaffolding and greenspunning Yesod does. Then there's the configuration problem -- lacking dependent types, Haskell has to greenspun away. Qi/Shen has the right idea; how it happens to have materialized is another matter. I would like to write Lisp code first and add static types later, if I choose. Dependent typing can do that. But static typing during development is a total waste because designs are never fully formed from the outset.
Dwelling on brackets here is truly bizarre. Shen has so much else going on. A type system, pattern matching, a prolog subsystem. There is a difference, at any rate, between the brackets in some schemes, where they simply function as parentheses, and brackets in Clojure or Shen, where they represent a read syntax. A priori, it is unclear to me why the Lisp reader should be restricted to reading Lists alone, without provision for other data structures which might reasonably be considered "code". Clojure acknowledges that tables, vectors and lists are all appropriate data structures and supports them in the reader, which seems fine. This choice _enhances_ homoiconicity. I don't see a disadvantage. Even Common Lisp supports _reader macros_ and they seem to be relatively frequently used to denote objects which are not lists which the reader should know about. I can't see any objection to alternative brackets in the Clojure/Shen usage that doesn't also apply to reader macros. Do you object to reader macros?
["You do not touch the parentheses!"](http://i.filmot.com/ZJqNF.png)
&gt; Yeah I don't know why Qi/Shen doesn't have an sexp option or least provide macros to convert N [M | _] -&gt; M where (&gt; M N) into an sexp and back again. Having two syntaxes only makes it worse -- you have to know both. I guess that's why M-expressions never got popular. &gt; The answer is absolute power and the end to greenspunning. Can you please elaborate on what power Qi provides? Aside from verification potential. &gt; But static typing during development is a total waste because designs are never fully formed from the outset. I can't say it is a big problem during development in Haskell, it is just a different model. If something compiles it is likely that it works, so you can skimp on testing in REPL
&gt; Can you please elaborate on what power Qi provides? Aside from verification potential. It's in the sentence immediately prior to the one you quoted. "The question of why not Caml and Haskell is the same question of why Lisp." However nice Caml and Haskell are, they eventually have to greenspun. I am a convert from these languages, and looking back I cringe at all the scoffolding and recompiling. Take a look at Yesod for the ultimate proof that Haskell runs into its own self-constructed barriers and then greenspuns around them. &gt;If something compiles it is likely that it works, so you can skimp on testing in REPL That's the wrong order, in my experience. The best way I have found to write code is by composing examples of what I wish would happen. In the process I usually realize a better way and I change the examples. In my experience that development model encourages the cleanest design and the cleanest end-user APIs. And in that model static typing is a hindrance every step of the way. It would be nice to add it at the end, however. 
It has s-expr syntax - [X | Y] is short for (cons X Y). This compiles (define cdr (cons X Y) -&gt; Y) 
This is backwards. It's probably got the most powerful type system programming around.
Using ttyrec and replaying it with ttyplay is kinda creepy the first time.
What is the sexp of this (define factorial {number --&gt; number} 0 -&gt; 1 X -&gt; (* X (factorial (- X 1)))) and this (define swap-order {(A * B) --&gt; (B * A)} (@p X Y) -&gt; (@p Y X)) ? And how does one create sequent notation with sexps?
Playterm is a bad idea. * Videos are hard to search * Have to wait while someone types verrrry sloooowly * Hard to distinguish between comments and commands Text tutorials have none of these problems.
B.S. Actually compare Qi syntax in http://www.lambdassociates.org/Book/page395.htm with http://www.haskell.org/onlinereport/syntax-iso.html and the protracted apology here for the mess that is Haskell http://forums.xkcd.com/viewtopic.php?f=11&amp;t=42408 Qi has about the simplest syntax of any pattern-directed FPL Shen is so-named because it is a separate language from Qi. This you would know if you knew anything at all about what you are pontificating about.
It is an s-expr. 
&gt;Did you learn all your Linux console skills from books or from forums? Or, did you peek over someone's shoulder to see the real action? Neither... I typed &gt; $ man command
OK; quick fast explanation. We like s-expr syntax because we like programs as data? Check. This means that we can pass a piece of program around as a list structire say and compile it down. Right. Qi lets you do that. Don't get hung on the idea that metaprogramming requires uniform use of ( ..) and nothing else. Here I pass your program as a list structure. (1-) (eval [define factorial {number --&gt; number} 0 -&gt; 1 X -&gt; [* X [factorial [- X 1]]]]) factorial Got the jive? (2-) (factorial 9) 362880
This is just one step above running scripts that someone else already wrote. I'm more of a fan of the "read the manual pages, break it, fix it, repeat as necessary" school of learning.
There's nothing that encourages you to not fuck up a system like having to re-install it from QIC magtape overnight. Sun 3/50 FTW.
Thanks. This works: (let expr [* X [factorial [- X 1]]] (eval [define factorial {number --&gt; number} 0 -&gt; 1 X -&gt; expr])) But this doesn't: (let expr [* X [factorial [- X 1]]] (let type {number --&gt; number} (eval [define factorial type 0 -&gt; 1 X -&gt; expr]))) `arity error in factorial` I suppose there is a way to do this, but in any case the OP's point was that it's not readily clear how to metaprogram in Shen. And from just my own experiment above, I don't know either. I tried many variations of it, including quasiquoting and splicing as well as Shen's `defmacro` construct with and without quasiquoting and splicing, but to no avail.
Separate language as in having different syntax/semantics? Which one should I learn? Don't you see a problem when dude releases a book and then changes the language?
This isn't an example of partial application, though. You're just providing an example of the short lambda syntax. Partial application, which I believe comes at the expense of variable arity functions, means that if you don't pass enough arguments into a function, you get a new function back as the result. Eg: ((+ 1) 1) Evaluates to 2, because `(+ 1)` evaluates to a function which adds one to its single remaining argument. This function is then applied to 1, resulting in two. This is a handy feature, but clashes somewhat with variable arity. Not sure precisely how Shen resolves this conflict. [EDIT: it seems to resolve the problem by simply evaluating to a value as soon as a function has enough arguments. Subsequent applications produce a value, rather than a function, even if you might want to partially apply further. Interesting ....]
&gt;This isn't an example of partial application, though. Look again. (map (/. x y (* x y)) [1 2 3]) This returns three partially-applied functions.
So it does! Oops!
Ok, seems interesting, I want to try it, but .... where's the tutorial/getting started? I see there is a tutorial for Qi, but do I really have to learn Shen by learning it's predecessors?
The simplest way is [ltk](http://www.peter-herth.de/ltk/).
Have you considered using the web browser as the UI? The application could still be running on the local machine but would launch a browser pointed to the application and present the UI through that. Then the UI would truly be cross platform and there are plenty of Common Lisp libraries to support this kind of development. Also if you ever did need to move to a full web application part of your work would already be done.
LispWorks is commercial, not that cheap if you want to cover all platforms - but it has CAPI, a Lisp-based graphics toolkit, which is running on top of GTk+, Windows and Apple's Cocoa. http://www.lispworks.com/products/capi.html
I bought this book as soon as I saw the video (and read the comic). We need more books like this! I remember when I first started with BASIC programming for the C64, all books were filled with fun drawings and humorously written texts. Nowadays programming books are most often boring. Where did the imagination and creativity go?
I've used [mcclim](http://common-lisp.net/project/mcclim/) for a non-trivial GUI application (among other things, it had its own custom music notation editor) at work which we ran on Linux and OSX. Windows would have worked had there not been a problem with threading in SBCL on Windows (but getting this to work wasn't a priority). McClim worked well across platforms (again, make sure your lisp supports threads well on those three platforms). It uses CLOS heavily and has some interesting ideas. You may also want to look into the [GTK bindings libraries](http://www.cliki.net/Gtk). I don't have any experience with these, but plan to use one for my next project. 
If you want to make a roguelike then I would suggest the Land of Lisp book as it makes something similar in there. It's not completely roguelike, but they go through similar skills that you need to make a roguelike. Though the book might not be enough to start from scratch.
I haven't ruled it out entirely. It was my first thought, but I may have a heavier amount of image interaction than what I'm comfortable cramming through a browser, fills, selections, etc. and I'm not a complete JavaScript guru.
Yeah I emailed the author and he personally told me he never intended the book to be for beginners, though he said it might be possible. He did say he thinks common lisp is the perfect language for making a roguelike. Not sure whether I should get it or not.
That was not your original point. But re syntax - the languages are the same. Shen is a RISC version of Qi with an extended functionality and a $free license. The spec says clearly that unless stated otherwise in the Shen spec, features stay the same. The differences are listed here. http://www.lambdassociates.org/specification/shen_1.8.htm#Shen and Qi: differences
Look at http://www.lambdassociates.org/studies/study02.htm for a place where Qi blows Haskell away.
CAPI is included in the personal edition of LispWorks 6.0 which may be useful for evaluation at any rate. (I'm not sure if it was included in prior personal versions.) On OS X it looks very nice - proper Cocoa Widgets, rollout dialogs, sliding windows. I can't speak about its appearance or behaviour on Windows or GTK but the OS X result feels native. (This is based on running a few toy programs to test individual widgets. Of course, the real test is a significant project incorporating many widgets and complex interactions.)
I've been recommending [Racket](http://racket-lang.org/) for outright beginners since before they were called "Racket". Here's their [download page](http://racket-lang.org/download/) (the download includes a simple IDE with a macro stepper), [here's](http://docs.racket-lang.org/quick/index.html) the absolute basic get-started tutorial, and [here's](http://docs.racket-lang.org/continue/index.html) a web application tutorial to follow up with. Their [documentation](http://docs.racket-lang.org/) in general is also fantastic. You already listed the books I'd recommend to a beginner, so I won't bother pointing you to more until you've had your fill (though I will note that [Practical Common Lisp](http://www.gigamonkeys.com/book/) is online in its entirety, just in case you didn't know already).
It's easy. All you have to remember is that when you eval E in Qi, you get the same as you would if you typed in the expression E' where E' results from E by replacing all the square brackets by round ones. (eval [+ 1 2]) = (+ 1 2) = 3 Your {number --&gt; number} is not a single s-expr.
CAPI has been available in LispWorks 4 and LispWorks 5 before. Right, the personal edition of LispWorks should be fine to evaluate the usefulness of CAPI. That's a good point. CAPI looks fine on Windows, too. I haven't tried it on Gtk, yet. Earlier it used Motif/X11. 
**BASIC LISP** 1. Write my-member, which determines if a given element is in a list. (my-member 'a '(b c j a)) =&gt; (A);;;; Problem 1 (my-member '(c d) '(a b c (a b) (c d) j k)) =&gt; ((C D) J K) (my-member 'a '(b c (a d) e)) =&gt; nil 2. Write my-insert, which inserts a given element into a list at a given location (zero based). If the location is too small (i.e. negative) or too large (i.e. greater than or equal to the length of the list), the function should place the new element at the beginning or end of the list as appropriate. (my-insert 'a '(b c d e) 0) =&gt; (A B C D E) (my-insert 'a '(b c d e) 3) =&gt; (B C D A E) (my-insert 'a '(b c d e) 14) =&gt; (B C D E A) 3. Write my-remove-dups, which removes duplicate entries in a list. (my-remove-dups '(a b a c a d)) =&gt; (B C A D) (my-remove-dups '(a b (a c) a d)) =&gt; (B (A C) A D) (my-remove-dups '(a b (b c) a (b c) d)) =&gt; (B A (B C) D) 4. Write my-intersection, which returns the intersection of two lists. (my-intersection '(a b c) '(c a e)) =&gt; (A C) (my-intersection '(a b (a c) c) '(a c b)) =&gt; (A B C) (my-intersection '(a b (a c) c) '((a c) b)) =&gt; (B (A C)) 5. Write dyadic-apply, which takes a function and two lists and returns a list of the result of the function applied to pair-wise elements from the two lists. If the lists are of unequal length, processing stops when the end of the shorter list is reached. (dyadic-apply #'+ '(1 2 3) '(6 5 4)) =&gt; (7 7 7) (dyadic-apply #'list '(a b c) '(1 2 3 4)) =&gt; ((A 1) (B 2) (C 3)) 5. Write tree-sum, which returns the sum of all numbers in a list, including those numbers in lists within the list, ad infenitum. Note that there may be elements in the input that are not numbers. (tree-sum '(1 2 3 4 5)) =&gt; 15 (tree-sum '(a 1 b 2)) =&gt; 3 (tree-sum '(a (1 (2 (3 b) c) d e) f 4)) =&gt; 10 6. Write my-flatten, which "flattens" a list. This means that the function returns a list with no nested lists such that the elements are the same and in the same order as they were in the printed version of the original list. (my-flatten '(a b (c d))) =&gt; (A B C D) (my-flatten '(a (b (c (d (e f))) g (h i (j k)) l (m)) (((n))))) =&gt; (A B C D E F G H I J K L M N) 7. Write full-reverse, which reverses every symbol and every nested list in its input. (full-reverse '(a b c d)) =&gt; (D C B A) (full-reverse '(a (b c) d)) =&gt; (D (C B) A) (full-reverse '((a b) (c (d e) f g (h i) j k) l m)) =&gt; (M L (K J (I H) G F (E D) C) (B A)) 8. Write my-subst, which replaces all occurences of a given element with another. Your function should replace lists as well as atoms and correctly replace arbitrarily nested occurences. ;; replace all occurrences of B with A (my-subst 'a 'b '(h b d b c b t)) =&gt; (H A D A C A T) (my-subst 'a 'b '(a b (a b (a b)) (a b))) =&gt; (A A (A A (A A)) (A A)) ;; replace (P Q) with A (my-subst 'a '(p q) '(p q (p q) (((p q) a b (p q a))))) =&gt; (P Q A ((A A B (P Q A)))) *I pretty much copy/pasted this from an old college homework. You should be able to do most if not all of these with nothing more than cars/cdrs and recursion, if I recall. None of this is totally practical for your goal, but it will definitely drill into your head that in LISP, EVERYTHING IS A LIST.* 
I thought it was cool and went through about half of Functional Programming in Qi, but I never knew what to do with it. Pattern matching and backtracking and everything is cool, but I don't solve a lot of search problems.
Something that's crucially important when learning to program is having fun. I don't know if LoL is for you, but most beginner books are terribly dry. That's a sure way to kill off a budding interest in programming.
I agree with the author of LoL, common lisp is an excellent language for writing a roguelike. You can test, define and redefine everything at the lisp command prompt (called the "REPL") which is a huge help in developing a complex application. It is a multiparadigm language - you can write in a mix of procedural. functional, and object-oriented style, depending on what approach is best for the problem at hand. The object system, called CLOS, is extremely powerful and flexible. The language compiles to machine code and can often approach C/C++ in terms of execution speed. SBCL is probably the best free lisp, but you need to set up your own editor. The commercial lisps come with their own editing environment/IDE but are very expensive (except Corman Lisp which is reasonably priced but I think windows-only?). Once you are ready to start on your roguelike, you will need a "graphics" library to allow you to put symbols on the screen. I have written a library that allows you to use the [libtcod library](http://doryen.eptalys.net/libtcod/) from common lisp. Libtcod is a console emulation library (like curses) that is used by many recent roguelikes. The library is at: http://bitbucket.org/eeeickythump/cl-tcod/ At the libtcod forum site there is a subforum for roguelike development in common lisp. It's not very active but there are a few interesting posts there, including a list of roguelikes written in various lisps. The best editor and IDE, by miles, is Emacs. But Emacs has a steep learning curve -- it's probably too much to try and learn Emacs + CL at the same time. Start with something simpler, maybe [lispide](http://www.daansystems.com/lispide/), or your favourite text editor + a console window. The best first book is probably practical common lisp, which you can download for free. 
Thanks for this reply, I have got practical common lisp, luckily I recently learned to use emacs, and the practical common lisp book pointed me to a emacs package called lisp in a box, which allows me to jump right in. It works very well. Thanks for the link to libtcod, the people at the roguelike group pointed me there but I was sad to see its make for C and python only. so with your library, could I use all what libtcod has to offer? I look forward to learning more, thanks.
Can my second example be fixed somehow, or not? (`arity error in factorial`)
Yes, the cl-tcod library provides pretty much all the features in libtcod. Another piece of advice: use [quicklisp](http://www.quicklisp.org/beta/) to automatically download and install any libraries you need, it is a huge improvement on trying to download and install them by hand. Good luck.
For beginning programming from "square one" I like [Common Lisp: A Gentle Introduction to Symbolic Computation](http://www.cs.cmu.edu/~dst/LispBook/) by David S. Touretzky. Between it, Practical Common Lisp, and Land of Lisp, you have plenty variety in the pace of material presented and engaging projects to experiment with. If one book is going too fast or if you feel like you need a bit more explanation, one of the other two surely will help clarify.
(let Expr [* X [factorial [- X 1]]] Type [{number --&gt; number}] (eval (append [define factorial] Type [0 -&gt; 1 X -&gt; Expr]))) 
[Read this book, it's free!](http://gigamonkeys.com/book)
Thanks for the help.
Yeah I now have both the free on on my hard drive :)
[Greenspun's tenth rule](http://en.wikipedia.org/wiki/Greenspun's_tenth_rule)
Thanks. This just underlines the point that Qi metaprogramming differs sharply from Lisp metaprogramming. Even if Qi does it better in some measurable sense, that doesn't mean lispers will be convinced to adopt it. Experimenting with the factorial example eventually led me to this: (define delicious-factorial {vanilla --&gt; chocolate} 0 -&gt; 1 X -&gt; (* X (delicious-factorial (- X 1)))) Which is a working factorial function. This contravenes my initial guess about typing in Qi. It seems to not be Haskell typing + dynamism, but something entirely different. So, we have a language whose metaprogramming is unlike Lisp and whose typing is unlike Haskell. And human nature is to stick with what one already knows when it is perceived as sufficient. This appears to be a good explanation for the unpopularity of Qi. Lisp doesn't get adopted because programmers don't realize their blub languages are insufficient. Maybe Qi doesn't get adopted by lispers because they don't perceive Lisp as insufficient. Many idiosyncrasies of the programming world, and of things in general, can be described by such local eddies of "sufficing".
I'm glad someone mentioned the REPL; so used to it that I keep forgetting it doesn't come standard with all languages.
Except for all the things that are not lists... strings, arrays, files, structures, classes, ... CAR and CDR are good for teaching CS students how a clean API can build powerful data structures, but I'm not sure they're good for teaching the messy craft of software development in today's world.
Sounds like you're miles ahead! I'd really suggest common lisp as well. I'm not overly familiar with rouge-likes... but an option that I always like is just doing the UI/display code in HTML. May or may not be very applicable to you. I also believe that abcl lisp provides access to the java ecosystem. Or there's clojure, a fairly new and popular lisp dialect. 
Didn't DTO make a roguelike and roguelike-library? I think it was called Sanctuary.
I am glad lisp-in-a-box was adequate. Slime is pretty much unmatched. Don't get stuck in toyville with Racket! Also don't forget [ParEdit](http://www.emacswiki.org/emacs/ParEdit). I could probably write Lisp with invisible parens, just by the indentation and navigation cues alone. (Which I'll try as soon as I figure out how to make parens invisible!)
And this is as far as I ever got with LISP.
Just to clarify, all the major dialects of lisp (CL, Scheme, ...) have had all these other data types for decades. Poorly taught CS courses often give students the impression that lisp is just a bleak landscape of pointless abstract functional recursion.
"in lisp, everything is a list" has been false for several decades, but it's one of those untruths that keeps being repeated nonetheless, because it's the only thing a lot of people "know" about the language. Lisp has all the same data structures as your favourite language.
Land of Lisp is about showcasing the cool things Lisps have. I started with Practical Common Lisp, but it didn't seem to be for beginners either. I went with A Gentle Introduction to Symbolic Computing, and liked it fine. I intend to go back to PCL now that I think I'm ready for it.
agreed! I learned to program from the [ZX81 manual](http://www.zx81kit.com/online_zx81_manual.htm) but learned to love it from [The Usborne Book of Computer Space-Games](http://www.amazon.co.uk/Computer-Space-games-Usborne-computer-programs/dp/0860206831/ref=sr_1_2?s=books&amp;ie=UTF8&amp;qid=1317192590&amp;sr=1-2). Land of Lisp tickles exactly the same spot for me :-)
And good.
As the author of the review in question I must say that I in fact prefer those boring programming books as long as whatever they're teaching is not boring at all. Land of Lisp is full of great examples that, unlike all the "Alice and Bob" examples, give you the feel of achievement whenever you finish a working game you can actually play and have fun with. The comics spread across the pages of Land of Lisp don't go in your way at all, I'm not entirely sure how did Conrad Barski achieved this, but it seems to be rather hard. On a side note, I was sure to get Land of Lisp the second "There's nothing cooler than a macro" lyric came along in the video. Tis' just... *Manly tear*
And some it probably doesn't. 
People are advocating Common Lisp a lot here, and I don't really disagree. Common Lisp is a great language. However, I do suggest you try out Racket. The main benefits of Racket are that it is dead simple to set up and get running, it is based on Scheme, so it is simpler (and I would argue better designed, but this is a matter of opinion) than Common Lisp, it feels much more modern, includes a GUI library in the standard distribution, and is much better documented. Racket/Scheme are a little more functional in style than Common Lisp, but that probably doesn't matter that much. All that said, I don't think you'd go wrong with Land of Lisp either.
I wonder why they didn't use guile.
Interesting question. I just learnt that my syntax for [] and {} has a bug. Checking against it I see the same behaviour. Wrapping the (read stream NIL NIL T) with an eval doesn't allow the variables to come from the outside bindings (since we are in macro territory, they don't exist yet). I believe the problem is that our read-macros are returning a data structure, which **does** get evaluated. Compare this syntax for a quotation: (set-macro-character #\$ (lambda (stream char) (list 'quote (read stream T nil T))) The results of which are clearly eval'd. The problem is evaluating the data structure (array or hash) will not evaluate the contents of them (the symbols that you want to be variables). The solution is to generate code that will generate the structure. (let ((hash (make-hash-table :test #'equal))) (setf (gethash X hash) ... 
Which Lisp dialect are you using? In Common Lisp, `#(a b c d)` will always give you `#(a b c d)`, a vector of four symbols.
MELT has a different set of features, and some things are semantically simpler than a full Scheme dialect (slightly different call semantics, '() as the only false value, &amp;c.). It also has things like boxed &amp; unboxed values that might have been difficult to wedge into Guile proper. From the [LtU Discussion](http://lambda-the-ultimate.org/node/2825) it seems it is not so much evaluated as expanded directly into C.
If you're just starting out in the world of programming, I strongly recommend [How to Design Computer Programs](http://www.htdp.org/). It's a book from MIT Press, but it's also available online for free from the above link. The focus isn't on learning LISP, but learning LISP becomes a bi-product of learning how to write better programs through this book. Just note that the environment it recommends is DrScheme, but DrScheme has since been renamed to DrRacket.
omg you're right. this is what i get for posting before coffee. geez am I embarassed.
 (let ((a 1) (b 2) (c 3) (d 4)) (vector a b c d)) =&gt; #(1 2 3 4)
Thanks I will follow the start of a book/tutorial for the three, CL, scheme and racket, see which I like.
Racket can be used almost as if it were Scheme, but it has features which make it much nicer (pattern matching, in particular, and syntax-parse.)
thanks for your reply! 
Well, to at least partially defend me/my alma mater, the course wasn't even remotely focused on LISP, it was an Intro. to AI course. We were told, "Use LISP for this course, here are some primers, go and figure it out." Turns out LISP is handy for implementing recursion which is really good for doing game theory/searches/etc. So we really only wanted the landscape of abstract functional recursion.
I wonder if you could speed this up by using a faster/simpler regular expression matching engine? You don't need a lot of the bells and whistles that CL-PPCRE has if you are able to include recursion in your regular expressions. I like the way that the grammar is basically described in an extended bnf. For example, I wonder if augmenting an engine that does DFA reduction would be possible? It is neat how easy and fast CL makes this; you can compile the DFA directly to machine code jumps and character value comparisons via macro expansion into a tagbody/go form. An example of this is here: https://github.com/JonathanSmith/Fast-Regex You may or may not find that interesting... it is a toy implementation, but actually is faster than CL-PPCRE for matching by quite a bit. (Caveat: isn't Perl compatible).
hi @sepok, running (blocky:play "turtle") will bring that up, but as the GUI code is still in alpha state, the example isn't very self-explanatory.
Did you enable type checking? Type (tc +) and then put this function in.
I hope to write one a day for as long as I can...
That keyboard pretty much eliminates search-and-replace (M-%). 
My guess is that you'll need something that has svd (singular value decomposition). I was hoping to use Clojure + Incanter but I'm not sure Incanter is up to the task and I don't know what it could be replaced by. 
You could probably get a month's worth just out of the format control character minilanguage...
Very cool. I'll check up on it.
Hi there. Welcome to Lisp! I like Common Lisp a lot. It has the advantage of being standardized, with multiple conformant Common Lisp systems being available. Scheme doesn't have that advantage. Land of Lisp is probably your point of contact for the game programming. For actual programming concepts, you should look up the SICP book. It's really hardcore, but if you consider it a challenge, you should come out on top. Practical Common Lisp is awesome. A Gentle Introduction to Symbolic (etc) is okay. In general, programming is all about persistence and being ok with learning. Cheers!
This is one reason I don't like FORMAT. Here's how I like to do things: (out (:d 42 :pad-char #\0 :base 2 :width 8)) (out (:d 42 :pad-char #\0 :base 2 :width (read))) The second form is quite similar to the first one, and still the first one takes advantage of the fact that the width is known before evaluation. Of course it's possible to have a FORMAT compiler-macro that's "smart" about ~VB like that, but I doubt any implementation has one, and that anyone generally uses ~VB with literals for consistency's sake... As for the idea of Lisp Tips: cool, subscribed!
good. but it seems it does not appear in Planet Lisp
I think it may not be the best idea to open yet another blog for it. You could directly post the tips to /r/lisp an let us comment or ask questions on them directly here. Something like [/r/carlhprogramming](http://www.reddit.com/r/carlhprogramming). This would make them more visible and searchable, it would decrease the number of different places newbies have to look for lisp information, and it would strenghten /r/lisp as a community where interesting discussions about lisp can be had, as competition with c.l.l for example.
The existence of [formatter](http://l1sp.org/cl/formatter) suggests to me that at least the intent is that *all* implementations will be able to produce a smart compiler macro for a constant format string.
 (format t "~VB" 8 42) Here the format control-string is indeed a literal, but by itself does not mention the width. If the compiler-macro is as simple as expanding to something like (format t (formatter "~VB") 8 42) It's not wholly satisfactory. A "smart" compiler-macro would also consider that the width argument is a literal and perhaps take advantage of that fact. I am not aware of any implementation that actually does that (and frankly, that doesn't bother me...).
This library might be interesting: http://matlisp.sourceforge.net/
hey thanks for the reply, I started reading land of lisp, which was going very well, but I am confused about all the car and cdr combinations, and the little train robbery comic only confused me more :\
A guy goes on a balloon ride when he drifts into a fog bank and gets lost. Suddenly the fog parts and he sees a man standing on a hilltop. "Excuse me, can you tell me where I am?" The man on the hilltop shouts back "You're in a balloon!" "You must be Raganwald!" "How can you tell?" "Because the way you adapted the joke doesn't make any fucking sense!"
By Stas "stassats" Boukarev, a SLIME expert.
There are probably lots of things to do to make this faster and less memory consumptive. I like PPCRE because it is robust and fast enough for most of my use cases. Were there another regex engine that supports named regex groups (something specific to PCRE, I think) and filter functions as CL-PPCRE does, then it should be feasible to port recursive-regex to that engine. A DFA based architecture would not be a problem (I dont think). Even baring that there are probably huge performance gains to be made just by improving the recursive-regex code. Thus far a working implementation has been the goal rather than efficiency. 
Don't worry. Everyone was confused by car and cdr and all the combinations. Eventually it'll settle into your brain with time and use. Read and write enough code and it'll be second nature. And I'm glad to hear you're reading LoL. I agree with others that you should read something else to help you, but definitely you should *also* be reading LoL since it matches what you want to do. I'll tell you something about learning to program... if you don't have a personal project your chances of learning to code are slim, but with a project that you're motivated to do you can get over the hurdles and keep going. So learn a bit and start writing your rogue! Start simple and add more later, but keep going. I will add one more bit of advice I haven't seen here yet: use source control, and do it now. Really. Why? Because here's what will happen... you'll start writing your game and get something going. You'll add stuff, break it, fix it, etc. Then you will break it and it'll be so broken that you're not sure what to do, and you'll wish you could go back to where it worked and go from there. When this happens (not *if* but *when*) and you are using source control, that option will be there for you. If you are not using source control at that point, the most likely outcome is that you will cry like a baby and when you stop crying you will still have a pile of broken code. I would recommend git or hg, but it matters far more that you use *something*, *anything*. You don't have to master using source control, just learn to commit your changes and then get back older versions. That's enough. Then commit early and often; no saving up 40 hours of work and then committing it.
I would absolutely love to see more on Slime usage. I have a feeling that the way I use it is suboptimal. When the completion window pops up it always seems to move where the point is on screen (not in the document) meaning there is a lot of &lt;Tab&gt;, search for point to see how much was completed and where it was hung up, go back to find the completion window. Less efficient than bash completion I think. (This is a general problem in Emacs, I think, but somebody must have come up with something that works better. Looked at popwin.el and even started coding some emacs lisp (not my forte) to solve the problem but haven't sorted it all yet.) Also, how do I get faces in the REPL window? Why can't I set my own local key bindings in the REPL buffer (they never seem to take effect)? Why does slime try to reuse previous (disconnected) REPL buffers? This is nice sometimes, but actually the wrong behavior at others. Maybe swank can save a little fingerprint token so that an old buffer can be matched with the disconnected Lisp. I imagine all of these things are configurable or hackable, but I haven't been able to figure them out. Does anybody else have any of these issues?
The slime repl uses slime-repl-mode-map for key bindings.
[Raganwald: Mistaking superficialities for deep understanding since 1962](http://raganwald.posterous.com/raganwald-mistaking-superficialities-with-dee)
Because we use paredit ;) Also, do you hold your breath while you type? Also, why do you type so slow? Curious me.
I don't really understand your complaint about completion. But here's how I use completion: Type (def, press TAB, a buffer pops out with a list of completions, now I either navigate through it with M-p/M-n, or refine my query by typing "u" and typing TAB again. When the intended completion is selected I just type further what I wanted to type (space in this case). And that's with fuzzy-completion. What do you mean by "get faces"? You want ot know which faces are used in the repl? Then use M-x describe-face while your point is at the desired face. If you want to define key-bindings only for slime-repl, use slime-repl-mode-map, if you want to define key-bindings for more slime modes, see slime-parent-map, slime-prefix-map, and slime-editing-map. See their docstring for what they are used. 
Ok thanks, I will try to setup git.
&gt;I don't really understand your complaint about completion. But here's how I use completion: Type (def, press TAB, a buffer pops out with a list of completions, now I either navigate through it with M-p/M-n, or refine my query by typing "u" and typing TAB again. When the intended completion is selected I just type further what I wanted to type (space in this case). And that's with fuzzy-completion. Hmmm, my bindings for M-n/M-p are to recall previous inputs. I use c-p-c completion, so I imagine this is where that difference comes from. I made a [video of my Slime usage](http://www.youtube.com/watch?v=iXRLw0A5G9w) to try and be clearer. Be forewarned, it uses Youtube "annotations", so it won't make much sense on a mobile device. &gt;What do you mean by "get faces"? You want ot know which faces are used in the repl? Then use M-x describe-face while your point is at the desired face. Sorry, I was unclear and perhaps used the wrong terminology. [Here is how things differ](https://imgur.com/a/B8eXX) when typing code into a normal Lisp buffer versus the REPL. In the REPL, all text is displayed as white text (well, maybe grey80). I long ago added something to my .emacs file so that "(lambda" is displayed as a Greek character, for some reason this doesn't work in the REPL either. Both of these are super minor issues, I am just wondering what makes the REPL special. FYI, for anybody who cares: ;; Make the sequence "(lambda" render with a greek font lambda (font-lock-add-keywords 'lisp-mode `(("(\\(lambda\\&gt;\\)" (0 (progn (compose-region (match-beginning 1) (match-end 1) ,(make-char 'greek-iso8859-7 107) ) nil ))) ;; Qi style lambdas ("(\\(/\\.\\&gt;\\)" (0 (progn (compose-region (match-beginning 1) (match-end 1) ,(make-char 'greek-iso8859-7 107) ) nil ))))) &gt;If you want to define key-bindings only for slime-repl, use slime-repl-mode-map, ... Cool, thanks (and thanks to Xach who also pointed this out). Okay, I spent too much time on this. I have to get back to work.
Absolutely fascinating to see such a different editing model!
&gt; Because the camera is obscuring the view... There are [a variety of options to record screen video captures on Linux](http://www.dedoimedo.com/computers/glc.html) that should let you ditch your camera when making more videos like this. Thanks for the video, it pointed out some neat features I'll have to try to find equivalents in SLIME and paredit.
RE faces You aren't really supposed to write definitions in the repl, you do that in files (or in *slime-scratch*), and invoke them from the REPL. lambda doesn't work in the repl because repl doesn't have lisp-mode, and you define it for lisp-mode, if you want it to work there, use slime-repl-mode instead.
RE lambda, did you try it? I have a similar line for slime-repl-mode and it still doesn't work. It is identical to above except it with 'slime-repl-mode replacing 'lisp-mode. This doesn't change anything. Interestingly enough, it does affect the context sensitive help in the message window. I am not an expert at Emacs stuff, so it is entirely possible that I did something really stupid here. It was just weird that I have two identical forms in .emacs except for the change of 'lisp-mode to 'slime-repl-mode and I didn't see the same affect. RE faces, sure. That's why it isn't a big deal even though I'm a fan of colored text. In the past I actually did most of my coding at the REPL and then copied it to a buffer when it was working. I did this primarily because I really hated doing a M-Tab (which, since I use that to switch windows in the WM and prefer not to reach for the escape key, translated to a C-[ &lt;Tab&gt; for my fingers). I eventually worked out this so I have REPL like indent then complete even in Lisp buffers. (I also did this for 'slime-mode-hook and 'slime-repl-mode, tough I'm not sure of the reasons. I tend to just hack on something until it works and never get around to understanding why I had to do it that way) (add-hook 'lisp-mode-hook (lambda () (local-set-key (kbd "TAB") 'slime-indent-and-complete-symbol) )) Regarding the completion, do you understand my complaint now? Is this just a non-issue for you? I am actually interested just to see how other people use Slime+Emacs. I don't work with any Lisp programmers and basically taught myself things from Internet articles and experimentation. I might have learned how to do things vastly different than other people. I took a bit of time to finalize the little hack I mentioned before that keeps the screen location of the point fixed during completion and [put it here](https://github.com/smithzvk/fixed-point-completion) (*edit* Here is another [video of the interaction](http://www.youtube.com/watch?v=lQrkTTOopP4) except I'm using the hack). It probably isn't very robust, but there it is and it seems to work.
lisp.el has a number of sexp-motion routines. 
Regarding completion, I usually have two windows so completion doesn't split new windows and nothing is moving.
And lambda, it's not possible to do without modifying slime.
[GSLL](http://common-lisp.net/project/gsll) might be useful too.
Here is a question I had recently... If I use sbcl as my inferior lisp and am in the middle of single-stepping through some code, how do I set a conditional breakpoint on-the-fly, say, to break at this expression in a loop 10 iterations later? I hit "b", and slime told me that the function was not yet implemented. Is that because there is a different, better approach?
I'll give it a shot. Okay, so we're defining a function that takes a list as a parameter. If you start out 'at the end', you'll see that this function is defined recursively--it calls itself. The next thing you'll notice is the 'if' conditional. It's asking if the list is 'true' or 'false'. Really it's asking if the list is empty or not. If it's not empty (list is 'true'), then the result of calling my-length is the result of adding 1 to 'my-length' of everything but the first element of the list (cdr list). In other words, it takes the first thing off the list, calls itself and adds 1 to the answer. On the other hand, if the list is empty (list is 'false), the result of calling my-length is 0. So take the example of a list with just one thing in it, e.g.: '(a). Calling my-length will test list to see if it's empty. It's not. So it calls my-length with the cdr of list. The cdr of a list is the list that results if you remove the first item. So if we remove the first item, we get the empty list. Calling my-length with the empty list returns 0 since the empty list is 'false'. Now we add one to that result and that's our answer: 1. Or you can write it out using what's called the 'substitution model' (I'm sort of writing this short-hand, I don't think this is the best way to write this): (my-length '(a)) (1+ (my-length '())) (1+ 0) 1 Or with two things in a list: (my-length '(a b)) (1+ (my-length '(b))) (1+ (1+ (my-length '()))) (1+ (1+ 0)) (1+ 1) 2 Does that help at all?
Not much time to reply, but try &gt; (trace 'my-length) &gt; (my-length ...)
Thank you, that is a perfect answer. I spent ages trying to work that out, and you finally made it click in my head.
&gt; Or you can write it out using what's called the 'substitution model' Also known as equational reasoning
I still wonder how much "space" is needed if a very, very long list is being examined with this function. e.g. if there is a megabyte of data in it and every byte is an element - wouldn't that use up too much "references" during the function call? 
A clearer way of stating the same thing would be: (defun my-length (list) (if (null list) 0 (1+ (my-length (cdr list))))) I prefer to have the base case of recursive functions called out first and explicitly, myself.
I think you'd want to replace this with an iterative version of it. The space used for the recursive version is at least linear to the size of the list (the function isn't tail-call optimizable). But I'm not a Common Lisp expert, so I should defer to an expert.
Yep. This isn't strictly necessarily in recursive functions, however. Note that the last sexp of a function body doesn't need to save anything--rather than having to save the location of the next sexp to continue after it returns, it continues with the next sexp from wherever it was called, and that information was already saved when the initial call to the recursive function was made. So if the recursive call *is* the last sexp, you've gotten rid of the call stack problem. This is tail-call optimization. I'm not familiar with Lisp implementations, but this is very common in Scheme implementations. A version of this function which would take advantage of TCO: (defun my-length (list len) (if list (my-length (cdr list) (+1 len)) 0) SICP treats this in more detail: [chapter 1.2](http://mitpress.mit.edu/sicp/full-text/book/book-Z-H-11.html), [lecture 1B](http://www.youtube.com/watch?v=dlbMuv-jix8).
You're missing a parenthesis! 
I was also utterly confused with the list-variable and the list-symbol. More essential Clisp for you: (defun list-list (list) (list list 'list)) 
Haskell syntax: length (item:rest) = 1+ length rest length [] = 0
If'n you'd like to know more, it essentially treats the list as peano arithmetic: https://secure.wikimedia.org/wikipedia/en/wiki/Peano_axioms#Arithmetic
A couple of things: * If you're using an accumulator, then you need to return the accumulated value, not zero. :) * +1 (is this a scheme function?) is 1+ in Common-lisp. So: (defun my-length (list len) (if list (my-length (cdr list) (1+ len)) len)) Of course, now you need to call the function with an initial accumulator value, e.g. (my-length '(apples bananas oranges pears) 0) which changes the interface of the function, not just the internal mechanism. Since you probably want to always accumulate from 0, you could hide the internal details of accumulation: (defun my-length (list) (labels ((length-iter (list len) (if list (length-iter (cdr list) (1+ len)) len))) (length-iter list 0)))
Dont confuse Common Lisp and Clisp. Clisp is not an abbreviation for Common Lisp, Clisp is the just the name of one particular implementations of Common Lisp: [http://www.clisp.org/](http://www.clisp.org/). This is the implementation that the author chose for Land of Lisp. There are several implementaitons: SBCL, CMUCL, Clisp, CCL, ACL, LispWorks, ECL, GCL. As you see from those names, the commonly used abbreviation for Common Lisp is CL.
If you really want to deeply understand this kind of thing, you'll want to read "The Little Lisper". (Normally I'd say "The Little Schemer", but you're already using Common Lisp, so why not stick with that.)
 #: is the literal for a unique symbol. This behavior is happening because each instance of #:G1300 is unique, even though they have the same name. Instead, you could do something like: * (let ((GS (gensym))) (setf x `((a (1 2)) (c (3 4)) (,GS (5 6)))) (find GS x :key #'first)) Which will return something like: (#:G796 (5 6)) 
In addition, I found this nice discussion on it in [Practical Common Lisp](http://www.gigamonkeys.com/book/programming-in-the-large-packages-and-symbols.html): &gt;Uninterned symbols are written with a leading #:. These names (minus the #:) &gt;are converted to uppercase as normal and then translated into symbols, but the &gt;symbols aren't interned in any package; each time the reader reads a #: name, &gt;it creates a new symbol. Thus: &gt; (eql '#:foo '#:foo) ==&gt; NIL 
So you can use #: instead of GENSYM? nice.
Can someone perhaps explain the significance of this video?
To write macros? Well, no. Then you want symbols that are unique with respect to everything outside the macro, but in the macro every occurrence of the symbol needs to be the same. `#:` would not allow you to do that.
Thanks for the reply; that makes sense. I'd been hoping to refer back to the "variable name list" between calls though. Maybe gensym isn't what I need. Is there a way to programmatically create a basic symbol (like just x100) without it having the unique symbol literal on it? Perhaps, take a quoted symbol like x and then merge it with a counter variable's value? Edit: I'd still like to know the above, but I think I can see how this would be used more effectively... CG-USER(19): (setf l '((#:G1304 (C)) (#:G1300 (B A)) (#:G1296 (A B C)) (#:G1292 (A B)))) ((#:G1304 (C)) (#:G1300 (B A)) (#:G1296 (A B C)) (#:G1292 (A B))) CG-USER(20): (setf m (first (second l))) #:G1300 CG-USER(21): (find m l :key #'first) (#:G1300 (B A)) As long as I keep referring to the same symbol it should work; this will make testing slightly more of a pain, but I think gensym will be able to do what I want. Another edit: It looks as if gentemp will create an *interned* symbol which appears to be more what I was expecting originally from gensym. I'll probably stick with gensym though. Does anyone have thoughts on the pros/cons on gentemp?
It depends on what you want to do. The pro of gentemp is that you can just type the symbol in, and you should be able to retrieve it. The con is that it will clutter whatever package you are putting the gentemps in. The other con is that it is possible to create a collision by typing the symbol in. You could put all of your gentemps in their own package, however. I cannot recall a case in which I had to use gentemp, personally. Gensym has always been sufficient. Perhaps if I were trying to print something out, and then read it back in.. but I haven't had occasion to do that. If you do it so that you create all of the gensyms, and keep them somewhere in your code when you want to refer to them later, gensym should be fine. You should also look at 'make-symbol' and 'intern' in case you haven't already. Another kind of ugly hack that might get around this would be to make a 'symbol-name-equal' that compares the symbol-names of the gensyms, rather than their identity.
Cool, I was on the right track then. gensym seems like it'll be fine, since I'll be storing all my symbols in a master expression list; I just managed to confuse myself in the process of trying out the idea of using generated symbols. Thanks for the help!
One word of caution: after upgrading I had slime / swank errors about mismatched versions. It went away after I restarted Emacs. There is some state that persists across `M-x slime-quit-lisp` and `M-x slime`. Not quicklisp's fault, of course. But since I was confused for a good ten minutes, perhaps a warning upon upgrading swank would help? Quicklisp is great. Thanks!
I'm not sure who is responsible for teaching/learning about the issue. slime has two sides, the emacs side and CL side, and you can't upgrade one without upgrading the other, although in practice, sync issues aren't usually a big deal.
You could get a month out of the formatting string for a Xapping: "~:[{~;[~]~:{~S~:[-&gt;~S~;~*~]~:^ ~}~:[~; ~]~ ~{~S-&gt;~^ ~}~:[~; ~]~[~*~;-&gt;~S~;-&gt;~*~]~:[}~;]~]" http://cs-www.cs.yale.edu/homes/dvm/format-stinks.html 
Do you still maintain Nokolisp? Is there somewhere we could get it to try it out?
[Edit: reddit ate my sharp signs :-| ] #&lt;closure&gt; conveys two important pieces of information: 1) That this object is a _closure_ and not some other kind of object, like integer, or array, or cons cell or generic function. and 2) The sharp-sign tells us this has something to do with the Lisp reader. The Sharp (#) sign is a dispatching macro character, when Lisp sees it, it reads the following character or two to find out how best to _READ_ this sharp'ed object. In case you're wondering READ/WRITE here is not your typical getchar/putchar you might be familiar with from simpler languages: it implies serialization/deserialization of composite objects, and perhaps some further processing .. http://www.franz.com/support/documentation/8.2/ansicl/subsecti/sharpsig.htm A great many Lisp objects have pre-specified macro characters, as you can see in the link above. E.g. #'fn is equivalent to (function fn) which evaluates to the function body, and not its name, or something else. #\ is for characters #\A #\B #\C and so on #( are for vectors, #(1 2 3) is same as (vector 1 2 3) You must have seen #P"/etc/passwd" as well, for pathnames. Now going to the hyperspec link above, you can see that #&lt; is there, and it signifies an invalid syntax, used most often for printing unreadable objects. Not every datum or value in a computer program makes sense outside of its execution context: some stuff just can't be written and read back reliably, so render them as #&lt;something&gt; unreadable objects. A closure might be considered one such object, at least CLISP thinks so. But if you have a way to reliably write closures to disk, including all their necessary context to be _correct_, then nothing is stopping your from creating your own readers along with appropriate reader macro :-) A handy operator for printing unreadable objects is PRINT-UNREADABLE-OBJECT. It takes the object to print, an output stream and two keyword argument signaling whether to print the TYPE of the object as well, and another for printing its IDENTITY. Identity here is an implementation specific notion of "sameness", most often the address of the memory location where the object is stored, so you can have objects that are structurally equal, but stored in different locations. PRINT-UNREADABLE-OBJECT is most often used with PRINT-OBJECT to render CLOS objects in some preferable fashion. A common idiom is: (defmethod print-object ((bike vehicle) stream) ; print bike to any stream (with-slots (make model year engine fuel) (print-unredable-object (bike stream :type t :identity t) (format stream "~a ~a ~a ~a ~a" year fuel engine make model)))) P.S. Do _not_ prematurely specialize print-object. Postpone all cosmetic I/O until your application takes shape, most importantly, do not contort how objects are rendered to fit a GUI or web framework: premature reflection is the root of all pain. 
A closure is a function whose definition encompasses the entire environment at the point of its definition. (setf *foo* (let ((a 0)) (lambda () (setf a ( 1+ a))))) The above creates a closure which counts up from 0 when funcalled. (funcall *foo*) With some care, you can create objects from closures.
If there's no mention of LAMBDA in the body of your EVAL function, means that the LAMBDA subroutine should do its tricks itself. Which means that your evaluation strategy is just split among several entities, but essentially is the same as with other lisps. Why other lisps can't do (eval '('(lambda (x) (+ 3 x)) 5))? Well, what's the point in being able to evaluate doubly-quoted forms? Why people are downvoting this? Because this doesn't look like an honest message, which tries to convey some useful information and instead looks more like bragging along the lines of "hey, look, my lisp is different and I wrote it 35 years ago".
Can you please show SUBROUTINE, RUN and how lambda is handled?
I've not looked at it extensively, but at least philosophically, what you're describing looks a bit like [PicoLisp](http://home.picolisp.com/), which aliases `lambda` as `quote`. It's an interesting concept; the main problems that I see with it are: 1. No lexical closure. 2. No good way of doing compilation. You can get (1) with some code-walking macrology and `gensym`. It's even easier to get dynamic closure, which you can get pretty far with as well. (But note that such macrology might be hard to integrate well with IDEs and debuggers.) (2) is much harder, though. It may be possible to do some HotSpot-like magic with a JIT compiler, but this would presumably be quite a lot of effort. (Perhaps native-code compilation is overrated—but it sure is a nice thing to be able to do when you need it.) So the answer to your question is that it's a trade-off. Now, would it be worth revising it? In order to answer that, you have to be aware that there are lots and lots of Lisp dialects out there, and there's simply no way for all of them to be popular simultaneously. For better or worse, Common Lisp and Scheme are the general-purpose ones that survived, and since these languages are already very powerful, there's usually very little reason for Lispers to look at anything else. Clojure provided such a reason—a “hook” if you will: a really nice approach to concurrency that makes writing functional, concurrent programs relatively elegant and easy. If you want your Lisp to succeed, you need to provide a similarly compelling hook. Easy concurrency is such a thing. Theoretical purity isn't (because if you want that, there's always [Kernel](http://www.cs.wpi.edu/~jshutt/kernel.html), not to mention PicoLisp, Scheme, et cetera). So try to think of something that your Lisp makes elegant and easy, and *do it*. If there's a compelling reason to use your Lisp rather than one of the existing ones for actual programming, people might flock to it.
Ah, I see now. I guess the most unusual part is `(eval (eval (car x)))`, i.e. first position in form is evaluated. This gives you both standard and no-standard features for free, but has some performance overhead, I guess. Also use of stack makes it a bit like Forth, I think, i,e. EVAL transforms "prefix" code into "postfix" code. I don't see why you say that lambda is a regular subroutine. It is implemented in machine code, not in lisp, so it is a "special operator" in lisp terms, I guess. Moreover, they receive non-evaluated arguments via stack, as far as I can tell from this snippet, so they are like FEXRPs/NLAMBDAs rather than like regular Lisp functions, and so they need to be able to call EVAL in some form. 
You're being a snot.
Picolisp lets you write lambda as a subroutine. Probably true of newLisp. Neither has lexical scope. Is nokolisp lexically scoped?
hm, I should once read this SICP, but not now. Maybe when the day comes I finally decide to study applied computer sciences :P
How about [Urban Warfare - The Escape](http://roguebasin.roguelikedevelopment.org/index.php/Urban_Warfare:_The_Escape)
https://github.com/death/towers is a tower defense game and https://github.com/death/consix is a Qix-like.
On behalf of dto: http://dto.github.com/notebook/xong.html
Racket broke me into the lisp world; I wasn't able to comprehend anything lispy until I ran through its tutorials. Having said that I have the attention span of a fish and was trying to learn Factor, Haskell and smalltalk all at the same time. It might be that Factor is more responsible for making the abstract concepts behind lisp click than Racket was. Not that I am suggesting you go off and learn Factor instead. I am currently, very slowly, running through Practical Common Lisp which I am quite enjoying with my new fond love of emacs. I decided to go back to learning common lisp because of slime and lispbox. Racket has emacs integration, but I didn't like it. Incidentally learning emacs is a difficult task in and of itself. In contrast the editor that comes with Racket is simple and easy to use, yet perfect for writing small programs in Racket. Emacs is definitely worth learning, but if you just want to learn lisp then all it does is get in the way. There are other IDE's for common lisp, but most tutorials seem to assume you are using Emacs+Slime which I always found off putting (until I learned to use Emacs). In short I think Racket is the best option for people new to programming and lisp (especially if they are on Windows). You can go learn Common Lisp later, there is no harm in that and in fact the differences between scheme and Common Lisp are quite enlightening. I also tried Clojure, but it was a configuration nightmare. 
Isn't there a version of Tower of Hanoi for emacs?
`M-x hanoi` iirc.
Obligatory: [cliki.net/game](http://www.cliki.net/game) One of the projects listed there, [RLX](http://dto.github.com/notebook/rlx.html) is "...a cross-platform graphical roguelike engine" written in Common Lisp.
For us casual observers, could you briefly describe what M-p is supposed to do and what you'd like it to do instead?
Yes. The slime documentation says: &gt; M-n, M-x slime-repl-next-input &gt; M-p, M-x slime-repl-previous-input &gt; Search the next/previous item in the command history using the current input as search pattern. If M-n/M-p is typed two times in a row, the second invocation uses the same search pattern (even if the current input has changed). I want it to match a previously entered input like CL-USER&gt; (defun times-two(x) (* 2 x)) if i write CL-USER&gt; (def) with paredit and press M-p. So the last ")" is in the way.
I believe that Abuse (by crack.com) was originally written in Lisp, and was then open sourced, IIRC. However, the [modern incantation](http://abuse.zoy.org/) appears to be a mixture of C++ and Lisp, so I am just mentioning it in passing.
Feel free to add Nokolisp to the http://progopedia.com/ if you want (registration required for editing) 
I use paredit, but I don't use the repl a whole lot and I've only tried paredit a few times while inside the repl. I tend to litter my source with little expressions instead. The repl seems too constraining compared to evaling stuff in the editor. It's like the difference between a browseable history and a shell-like history with M-p. I dunno, maybe it's just me. If my habits ever change I may revisit this paredit/repl history hack :)
Hello Xach, do you have any long-term ideas or even plans for Quicklisp? Where do you see it in 5 or 10 years from now?
There are a lot of features I'd like to add. Here are a few off the top of my head, in no particular order: * Accumulate documentation for easy offline use * Gather &amp; share bug-report, mailing list, author info for projects * Make it easy to "export" or "deliver" a set of libraries so they can be loaded into a project independently of Quicklisp * More integrity checking of archives * Tools to help anyone make &amp; share a dist * A manual * Make it easy for people to share informed opinions about projects * Gather &amp; share dist-wide information like symbol apropos, package apropos, docstrings * Make it easy for people to get a hackable version of a project a la clbuild * Build testing on a variety of platforms to make it clear what projects are meant to work on what platforms, e.g. "don't bother trying cl-xyz on clisp for windows, it's known broken"
It was always a mix of C++ and a homegrown toy Lisp.
You've probably already heard that a thousand times, but: Thank you for Quicklisp!
Xach: A while back, you asked for stories about how Quicklisp has affected its users. Are those going to be part of a year-end retrospective?
I'm giving a talk at [ECLM 2011](http://weitz.de/eclm2011/) in a few weeks and I might incorporate the feedback into it.
the fabulous quicklisp has hundreds of libs, some with misterious names, so... * a web frontend to browse the libraries by category, search the descriptions, etc. (thinking of the CPAN web site) :-) 
Ah, my mistake. Sorry for the noise.
At this point this amounts to little more than a "Me too!", but thank you for Quicklisp. You rock.
The subtitle * "Lisp-Programmierung einfach lernen und originelle Spiele programmieren" translates to * Easily learn Lisp programming and program inventive games" 
That's great, and the ratio is up near what I've seen with lzma on an SBCL core, and he did it with zlib. Does that mean that they will be convertible outside of SBCL? For instance, if I have an old core sitting around and I decide it's taking up too much space and I wouldn't mind if it started up a bit slower, can I just pass it through gzip (or the other way around if I need speed at the cost of space)?
You can't use new runtimes with old cores, so the old runtime wouldn't understand the compressed core.
Right... Oh, I see sorry, I need to actually read the post. You have to recompile SBCL.
Yay! Finally!
What is a core? What is a compressed core?
A "core" is a copy of the memory image of a program. If you save it to disk, you can load it again and get a program in mostly the same state. It doesn't keep track of things like file descriptors, which are outside of the memory image of the program -- they exist inside the kernel's memory space -- so you need some extra code to handle that. Since Lisp is exceedingly dynamic, it is very hard to make a traditional binary from program code. This causes program load times to be very long, unless you find some trick to speed it up. The trick is to save a core of the program, and load it back. Conceptually speaking, a core image is not very different from a modern executable format like ELF. In fact, if you save the core of a C program on an ELF system (like modern Linux), the core will be in ELF format, just like the program executable. However, cores tend to be large, so we want to compress them.
which seems to me that the easy-going colloquial style of the book may have been lost in translation.
It would if you used it the same way as one uses gensym, which I think is what SCombinator was suggesting. It could get confusing to read, though, as you might end up with identical but unique symbols.
Keep up the good work! :D
What two libraries gave you the nickname clash? I think the easiest short-term solution is to use better names.
clx and cl-opengl
As I see it, in Lisp as in life, nicknames are useful as shorthands. But, no matter how com.domain.complicated.package.names you employ, all the benefits of this complicated non-clashing uniqueness is lost if you then attach a simple nickname also. I believe that it's the *user* of the library the one that can set nicknames. Libraries should not come with nicknames already defined.
As a newbie Lisp user, I thought this nickname stuff was weird. When I was using ASDF to download and use packages, there were a few that had this kind of collision, which I solved by manually editing the .lisp files to remove the nicknames or by loading in just the right order. Authors assigning nicknames: thanks, but no thanks. Edit: Xach is right; my memory was wrong. It was .lisp files, usually package.lisp, although a notable exception was a version of "split-sequence", which wants to also be known as "partition", presumably for some kind of backward compatibility, but I don't really care about the history.
Packages aren't usually defined in .asd files and if there is a package conflict, load order does not matter.
I am pretty sure I needed and managed to work around things by changing compilation order. I think I had to answer some debugger question about overriding, so it was not a magic always-works solution. But that is history now. It has been a while since I have had to worry about that mess. The mentioned CLX looks familiar.
Well, I think I agree 100% with you. However, please correct me if I'm wrong, but nicknames are completely out of the users control, right? I find this nickname business to be very irksome and I envy languages where you can use something similar to "import package as pkg" where you get to specify the nickname on a per module/file basis. If I were designing things today, I would have setup nicknames as an extension of the reader. All they do is expand into the proper package name. There are some corner cases with this, but I think it would be a workable solution. The funny thing is, if nobody specified any nicknames, we could actually implement some reader tricks that expanded your file local nicknames into the proper values. But, since nicknames are part of Common Lisp currently and prone to collisions, there is nothing we can do. If two developers choose the same nicknames for their projects, the conflict will happen at their system's load time, so we either have to patch the system (never a satisfying solution) or modify the way ASDF reads files (even that wouldn't catch systems that side load files). All of this wouldn't be so bad, except having short nicknames for packages is extremely useful! I kick myself every time I have to insert "alexandria" into my source file, why not alex, or al. Horizontal space is at a premium here, guys. In short, nicknames in Common Lisp seem like they were designed completely backwards.
YMMV, http://code.google.com/p/autoproject/source/browse/trunk/ap-pkg/alias.lisp
The package system of common lisp is so broken. To be fair, the guy who invented it was a grad student at the time, it was for his private use. He was part of the CL standardization committee. Apparently he went away for a weekend, and in his absence, the committee used his package specification, much to his horror.
Please tell me this is a false legend. 
Sorry, no. I heard it from the horse's mouth - David Dill (now prof @ Stanford) - in his office ~ 4 years ago.
The CL package system has worked very well to allow people who aren't coordinating strongly share their code without much conflict. That there is still the possibility of conflict between parties that are not communicating at all is a bummer, but it's not broken.
Look at the :shadowing-import-from option for defpackage. I use that to pull in symbols from alexandria all the time.
Python has an elegant design. CL, not so much. It's evident when you watch beginners try to learn it. Watch the confusion that results when they start running into symbol conflicts. The biggest problem is that there is no file-level namespace. And INTERNing into a package causes the symbol to be interned in all files that that are in that package. Depending on the order of load, this can change the meaning of a program, or cause symbol conflicts. Terrible. Actually, it's hard to think of a worse package system than CL's, but of course this was a design from the earliest days of coding, so it's understandable.
Thinking about packages in terms of files is certainly a good way to get confused in CL. A beginner should learn they are not related, and stop being a beginner.
Even the designer of this system thinks it's seriously flawed. I don't think the problem is with beginners. The job of a language is to be natural, easy to use, modular and powerful. CL's package system fails on a number of fronts when compared to modern approaches.
It works fine. That other systems have done different stuff since it came out is not a big deal.
Okay, I will resist the temptation for diatribe. Yes, that solves some issues, but not everything. It in no way alleviates nickname collisions which is the entire problem. The whole alexandria bit was an attempt to describe hypothetical benefits of such a user definable nicknaming system.
This is very cool and I was not aware of rename-package's existence. I am in the process of figuring out what this means in terms of my original gripes. Thanks for pointing this out.
I actually _like_ that packages are first class objects and not arbitrarily restricted to a single file. But I do think the nicknaming system could be more ergonomic.
The brilliance of Lisp is that everything is a first class object. That's one of the good things. The killer problem of *not* having a per-file namespace (independent of whether packages could provide that functionality) is that load order can change the meaning of a program. This is a really horrible gnarly thing to debug. The file-level namespace is a tried and true pattern that improves modularity, readability, sharability and debugging. The advantages of programmability of the current system are far outweighed by all of these other considerations, IMO. And file-level namespace doesn't mean giving up programmability either - or contributing a symbol to a different module than the one owned by the current file. Both of these things are possible in Python, for instance. All you need is that module/namespace/package is a first-class object with methods for interning symbols. So all of the things we currently do would still be possible. Just without the *mess* that the current system produces.
I think we may be losing sight of the original topic here -- in my somewhat limited contact with CL I've come to love it. I love that it's flexible and powerful, I love that there are many quality open source platforms available &amp; able to run in a large range of environments &amp; unconstrained by the whims of e.g. Oracle, and I love love love that the ability to share code has recently been greatly eased. What I'd like to have is the ability to package up utilities etc. that I create &amp; share them without the worry of polluting the shorthand namespace -- the one that's actually used in writing code. It's a testament to cl's flexibility that tfeb could implement a solution to this as a _library_ and I'd love to see this power brought to the cl community at large, and the possibilities for ease of collaboration it entails.
Could not agree more. I view the package system as one of the big impediments to making libraries as easy to use and install as they are on Ruby and Python.
If it's just a small amount of work, a basic programming text editor such as Notepad++ or SciTE should suffice. If they're familiar with Eclipse, Cusp is a plugin that turns it into a lisp oriented IDE that I think is pretty good.
+1 for Emacs/SLIME. There are plenty of tutorials on getting this combo up and running along with installing the [Lisp HyperSpec](http://www.lispworks.com/documentation/common-lisp.html). I hope that the OP sees the hilarity in wanting to code in Lisp while referring to Emacs as esoteric.
Maybe he should try the graphic version of emacs. Less shortcuts to learn. 
vim is esoteric?
I agree, emacs is the way to go. And really, its only really bad if you use it in a cli environment. In a windowed environment, its hardly different from any other editor. Menus and mouse-clicks.
I guess I thought there was a way to to just dip one's toes in lisp. Maybe that's just the wrong attitude :).
Is the Lisp dialect fixed? If not, I would suggest using racket and it's editor/IDE DrRacket.
Yeah its ultimately going to run on Clozure CL.
http://www.yellosoft.us/installing-common-lisp
Oh okay, too bad ;-)
There is nothing esoteric about Emacs. You just need to spend some time configuring it up to your taste and learning few keybindings. After that learning curve is pretty smooth. You probably want to enable CUA -- copy/paste through ctrl-c/ctrl-v, so it behaves just like a normal editor. (There are less intrusive options if you're used to shift-ins/ctrl-ins.) Then there are maybe 5 key combos which you actually need, the rest can be done through menu and commands. So it takes maybe 10 minutes to set it up, how is that esoteric? Editing text in Emacs is not different from other editors.
Emacs is esoteric in the same sense that Common Lisp is: you need to invest a bit in it before you reap the (large) rewards. Doing "a very tiny amount of work in lisp" is probably itself not worth the effort. 
I'm with you. It's a bit much to learn Emacs AND Lisp. I tried the free [Cusp](http://bitfauna.com/projects/cusp/) plugin for [Eclipse](http://www.eclipse.org/), and I thought it was quite good for my beginner needs. Another popular Eclipse Lisp plugin is [Dandelion](http://sourceforge.net/projects/dandelion-ecl/).
[Lisp in a box is a good start](http://common-lisp.net/project/lispbox/)
Emacs is all you need if you're only looking to dip a toe into Lisp—it contains a full-blown Lisp interpreter.
Are you developing on Mac OS? I'm just curious because the bundled version of Emacs is the very vanilla command line version. There are much better options: * Emacs for OS X: http://emacsformacosx.com/ * Aquamacs: http://aquamacs.org/ Aquamacs is great for people unfamiliar with Emacs as it adds a lot more functionality to provide a version of Emacs that behaves like a standard Mac Application. (If you aren't using OS X, then ignore this, it was the use of Clozure CL that made me curious.)
btw, you can use Emacs/SLIME + Common Lisp without worrying about elisp (emacs lisp) at all. Unless you want to customize your emacs, it's not necessary to know the inner machinery of emacs.
Additionally, Clozure CL has its own native editor on OS X. http://ccl.clozure.com/ccl-documentation.html#ccl-ide
seriously! if vim is esoteric, what would lisp be? he's in for a world of hurt.
There is [ABLE](http://common-lisp.net/project/able/), which is meant to be an ultra-basic LISP editor that still supports the usual (symbol completion, hyperspec lookup, &amp;c.). I used to use it all the time, and it wasn't bad, although iirc it is a bit dead.
I would almost literally rather die than live without emacs. You should consider learning to use it.
[If you need help getting going with Emacs + SLIME](http://www.reddit.com/r/lisp/comments/fcpr1/common_lisp_quicklisp_slime_howtos_for_windows/)
Emacs + Slime. Anything else is a waste of time and effort. (Yes, I've used Vim).
Yeah my coworker is doing it all on OSX. I completely forgot about aquamacs. That might be perfect! Thanks!
Tried for a while Emacs/Slime (with various lisps), but now I'm firmly settled on Clojure + Eclipse + Counterclockwise. Should be even better for somebody not committed enough to invest in learning Emacs.
LISPBox: http://common-lisp.net/project/lispbox/ I know you said no Emacs, but literally you crank up lispbox which has emacs + slime and whatever, and you type in some code, hit CTRL-C CTRL-K and bam.
Easily more portable than the reference section of Paul Graham's 'ANSI Common Lisp'.
It looks fun, but I'm not sure I'd describe it as "ready to get started." Many details of the game — such as how combat is calculated, for instance — seem to be completely unspecified.
Is this from the viewpoint of an onlooker or are you involved in the development? I haven't been following the development really close lately but my impression is that the code is pretty much done except that they still need to update the wiki with the specifications.
I'm speaking as an onlooker.
I found it not immediately obvious where to find more specific rules.. [This](http://aichallenge.org/problem_description.php) and [this](http://aichallenge.org/specification.php) page are more specific.
So CLQR moved to this new address because of the closing of berlios.de
I hope that the next ILC in 2012 will take place in Kyoto/Japan (as rumors say). That would be a good reason to visit Japan...
 (let ((list '(a b c d e f g))) (cond ((member 'e list) :yes) (t :no)))
No, `case` does not evaluate case keys. You can use read-time evaluation if you want to test for constants, like this: (defconstant +foo+ (list (gensym) (gensym))) (defun bar (x) (case x (#.+foo+ 100) (t 0))) That will only work for compile-time constants, though.
Yes. Much better than my suggestion. :)
yes cond is certainly the right way to go in that particular case, but I was wondering the syntax to force case (or similar macro) to eval the case keys.
Not wanting to use an esoteric editor to use an unpopular language is fine, the two are not the same.
Long story short, I believe CASE works the way it does because of historical performance considerations (which are probably still pertinent today). Look at why and how switch statements work in C to gain some insight. However, you can make a new macro that takes something that looks like a case statement and converts it into a COND statement. For instance, see CLISP's macro [EXT:FCASE](http://www.clisp.org/impnotes.html#fcase) for an example of how you might do this, although I don't think FCASE does exactly what you want. Edit: In case you don't have the source at hand, here is what I have in my personal util library (adapted/stolen from CLISP source): #-clisp (defun case-expand (whole-form form-name test keyform clauses) (let ((var (gensym (concatenate 'string (symbol-name form-name) "-KEY-")))) `(let ((,var ,keyform)) (cond ,@(maplist #'(lambda (remaining-clauses) (let ((clause (first remaining-clauses)) (remaining-clauses (rest remaining-clauses))) (unless (consp clause) (format t "~a: missing key list" whole-form) (break) ) (let ((keys (first clause))) `(,(cond ((or (eq keys 'T) (eq keys 'OTHERWISE)) (if remaining-clauses (format t "~a: the ~a clause must be the last one" whole-form clause ) 't)) ((listp keys) `(or ,@(mapcar #'(lambda (key) `(,test ,var ',key)) keys))) (t `(,test ,var ',keys))) ,@(rest clause))))) clauses))))) #-clisp (defmacro fcase (&amp;whole whole-form test keyform &amp;body clauses) (case-expand whole-form 'fcase test keyform clauses)) 
I think everybody ends up writing that macro. You should, too, it's a good exercise :). But if you don't want to, you can use `alexandria:switch`.
I can't wait to try it. Thanks!
lisp - the language everyone learns by reinventing it in part (or in whole!) thanks for the tips, question answered! 
Easily installable libraries are sort of a new thing to lisp ;-)
&gt; So how can I get the case macro to actually expand the first argument &gt; of a clause inside a case statement? You can't. But here are three techniques to achieve what you want: 1. Use read-time expansion: (case x (#.(range 1 5) 'in-range)) assuming (range 1 5) returns (1 2 3 4 5). This is a quick-and-dirty solution. 2. Define your own macro: such that e.g. (my-case x ((1 5) 'in-range)) expands to (case x ((1 2 3 4 5) 'in-range)). This is a good solution especially if MY-CASE can capture a frequent pattern in your code. 3. Take advantage of type-specifiers: Because type-specifiers are so flexible, TYPECASE can often do the job of CASE much better, e.g: (typecase x ((or (integer 1 5) (member :one :two :three :four :five)) 'in-range)) I think especially for numeric ranges this works quite well. 
Here's a hack to get something like a REPL from the code at http://piumarta.com/software/maru/ (cat boot.l; awk '{ print("(println " $0 ")"); fflush(stdout) }') | ./eval /dev/stdin Only works for one-liners.
Huh? Packages came to CL via ZetaLisp, no? 
I use initform when the initial slot value is independent of the other slots. I think it serves well to communicate when that is the case. Any kind of slot interaction should use default-initargs instead (or handle them elsewhere). I am not sure about using default-initargs as a shortcut for initializing independent slots. I'll have to think about that.
Sonya Keene's "Object-Oriented Programming in Common Lisp" has a nice, succinct, and clear write up on when to use those keywords. From pages 158-189, *Two Kinds of Defaults*, here's what she wrote: --------------- It is important to keep in mind the difference between **:default-initargs** and **:initform**. The **:default-initargs** option gives a default value to an initarg, and the **:initform** option gives a default value to a slot. If you intend to allow users to initialize a slot, then you should * Use **:initarg** to declare a symbol for initializing the slot * Use **:default-initargs**, if you want to give that initarg a default value If you do not intend to allow users to initialize a slot, then you should * Not use the **:initarg** option * Use **:initform**, if you want to give the slot a default initial value These two options come into conflict if they are used together. Consider what happens when a slot has a default value via **:initform** and an initializer via **:initarg**, which itself has a default value via **:default-initargs**. The default given in the **:default-initargs** effectively overrides the default given by **:initform**. For both of these options, the default value form is evaluated every time it is used. The value of an **:initform** is evaluated each time it is used to initialize a slot. The value of an initarg in **:default-initargs** is evaluated each time **make-instance** is called and that initarg is not given as an argument to **make-instance**. --------------- For what it's worth, I've also used after-methods for **initialize-instance** as an alternate method of initialization. In general, I found that appropriate for *complex* initializations, but that the in-class declarations using the keywords above really wins out for simple stuff.
Lisp in a box!
&gt; For both of these options, the default value form is &gt; evaluated every time it is used. The value of an &gt; :initform is evaluated each time it is used to initialize &gt; a slot. The value of an initarg in :default-initargs is &gt; evaluated each time make-instance is called and that &gt; initarg is not given as an argument to make-instance. In other words, using **:default-initargs** where possible means fewer initializations on a slot value when using **make-instance** in a complex class hierarchy?
Newbie Lisper here. I thought Lisp's macros were what made it so powerful. Am I wrong? How would you write COND, for example, as a function and not a macro, with the requirement that a proc-expr for a condition only be evaluated if the respective test-expr is non-nil (or true, whatever)? Genuinely interested - not being a smartass.
By wrapping bodies in lambdas. Yes, it will be more verbose for caller.
Macros are primarily used to extend the primitive hard-coded set of non-function forms. You can write DO as a macro, but you can't write it as a function. Obviously one would not write a new COND, but one often wants to write a new form that does something appropriate to your problem domain. Lisp macros are rarely if ever used to improve performance. I've never seen it. 
* Don't replace a call without knowing what it does (ie, reading the docs). Bad programmer. Bad. * Don't do semantically different things with the same call with similar invocation. Bad designer. Bad. (pedantic aside: this is like dynamically switching behavior from concatenation to division depending on the type of the incoming object; not a behavior restricted to macros)
I suggest you look into the implementation of control structures in, say, SBCL. 
If you are interested you can look at uses of macros in popular libraries. 
CL-PPCRE - a regular expression library that is faster than perl performance, partly because the expressions get precompiled into the state machines since they are wrapped by macros 
No. Initform is used only when it is actually needed and only once.
The rumor is true! Int'l Lisp Conference (ILC) 2012 will be held in Kyoto, Japan in October or early November in 2012. See http://www.lisp.org for more info. 
A really interesting talk by Nick Levine about his count of the infamous violet ostrich book he wrote and didn't finish because of health problems. I, for one, would love to see the book finished (maybe sold online in pdf/epub), since I am a beginner. I hope Lisp won't get another winter :p
The finished parts can be downloaded for free here http://lisp-book.org/ This also includes the "Basics" Chapter so maybe it is enough to get you started
I would prefer Practical Common Lisp by Peter Seibel to this unfinished book but I will go over Chapter 1, 16, 20, and 21 since Nick feels he is content with them.
An essential document to have around to code Common Lisp. 
I really need to attend ECLM next time.
There are things which cannot be accomplished even by passing lambdas to a function. For instance, one can write a type-checked version of Lisp using macros, but one cannot simulate this behavior with lambdas (at least not without static guarantees, which would be the whole point). You also can't specify a monadic binding form with regular functions which receive thunks.
This is a really bizarre article. The original macro is a bad idea in the first place. I'd solve the problem differently. We want a wait function which is polymorphic in the type of its first argument. If you were writing in common lisp, the most idiomatic solution would be to use CLOS to define multimethods for different input types. It is entirely idiomatic to dispatch on the number type in the case of a literal number and to dispatch on a function type in the case of delayed computation. If you wanted to have some better type checking (you don't just want any delayed computation/lambda, but only those with no arguments), I'd advocate something like: (defstruct thunk the-lambda) (defmacro thunk (&amp;rest rest) `(make-thunk :the-lambda (lambda () ,@rest))) (defun thunk-value (thunk) (funcall (thunk-the-lambda thunk))) Then you could say: (wait-for n) or (wait-for (thunk (have-the-cows-come-home?))) `wait-for` would be a multimethod with two behaviors. I can't recall at the moment whether CLOS methods can dispatch on structure types or not, but you could just as easily replace the struct with a CLOS object definition. The idea is clear nevertheless, I hope. This is better because it explicitly delineates the kinds of things which the method `wait-for` expects. If you want a delayed computation, then its best to say so directly instead of letting a macro do the work for you, because the macro expansion is implicit with respect to evaluation, which might be why the original macro was confusing in the first place. Lisp is a language where delayed computations have a first class life as lambdas, so you might as well use them as such. Then CLOS dispatch will error out if you pass in some kind of unexpected value. I _do_ use a macro here, but only to make it easier on the programmer to represent the types of interest. 
&gt; I hope Lisp won't get another winter :p Without another bubble there can't be another winter.
Can this make use of the OpenCL implementations out there?
***wendyg***: &gt;&amp;#91;2011/10/24&amp;#93;&amp;#91;19:33:31&amp;#93; &gt;[&amp;#91;Translate&amp;#93;](http://translate.google.com/#auto|auto|R.I.P. John McCarthy, father of AI, inventor of Lisp, suddenly at home last night. Pls RT. 'google translate this tweet'): R.I.P. John McCarthy, father of AI, inventor of Lisp, suddenly at home last night. Pls RT. [&amp;#91;This comment was posted by a bot&amp;#93;&amp;#91;FAQ&amp;#93;](http://www.reddit.com/help/faqs/tweet_poster 'tweet_poster FAQ')[&amp;#91;Did I get it wrong?&amp;#93;](http://www.reddit.com/message/compose/?to=tweet_poster&amp;subject=Error%20Report&amp;message=[Oops!](http://reddit.com/r/lisp/comments/lnk0f\)%0d%0dPlease leave the subject and this link unaltered, but feel free to add a description here. 'report an error')
Not in its current form, but I'm sure one could thunk through efficient OpenCL operations where appropriate with a bit of elbow grease. Nice that it works with ABCL…
what a bummer.... he did live a long life
Fuck you October! :(
Can somebody give a summary of where this would be useful? The documentation on the website directly goes into details. Is this a way to organize and write concurrent applications? (Abstracting thread pool management and job queue management) Or is it for farming out parameterizable computation to simply make it faster?
no data on who is behind this... 
The Rule of Three strikes again.
&gt; McCarthy often commented on world affairs on the Usenet forums. He most certainly did, he was one of the few high profile figures who posted under their own name on USENET in the 90s. I remember getting into some pretty heated arguments with him there over politics. Vale, John. You've made a mark in the world. 
It seems that October is a reminder that life is fragile and short so use it wisely.
A giant has passed. May we seek to stand upon his shoulders with care and diligence.
:0
(cons 'the 'world)
His archive of papers is worth looking through: http://www-formal.stanford.edu/jmc/ Particularly Lisp-relevant, his 1980 "Lisp--notes on its past and future", which he says as of 1999 still more or less represented his opinions on the subject: http://www-formal.stanford.edu/jmc/lisp20th.html
Here's his web page: http://www-formal.stanford.edu/jmc/ There is a lot of interesting stuff there. For example, &gt; THE ROBOT AND THE BABY is a science fiction story. One of the most thought-provoking short stories I've read, definitely worth reading. &gt; The Sustainability of Human Progress He says what others are afraid to say. &gt; Elephant 2000 As I see it, it is a new approach to persistence, still not implemented anywhere. 
Damn :(
Parallelism and concurrency are different things: parallelism is about making things faster through using multiple cores, while concurrency is about handling events which might be overlapping in time. This library, as name suggests, is about parallelism, not concurrency. Well, maybe there is some limited use for concurrency, but concurrency usually involves primitives for IO operations.
API is friggin awesome, it gives almost everything one might want from this kind of thing. But as scheduling cost is high it only makes sense in case you have very expensive individual pure functions OR you're working with large lists. I wonder if it is possible to make overhead lower. Benchmark suggests that it takes about 70 microseconds to send work to worker thread and get result back. I guess OS synchronization functions are used. Low-level synchronization using busy-wait and atomic, non-blocking operations might have dramatically lower overhead. I did a test just few days ago got something like 260 CPU cycles (~130 nano seconds) in best case. So there is a room for improvement, I guess. But I dunno whether it is possible to use low-level synchronization in Lisp. It is implementation-dependent, obviously, but would it work at all?
Dammit...I think it was Larry Ellison's turn next.
Links: * [Amazon.de page](http://www.amazon.de/Land-Lisp-Lisp-Programmierung-programmieren-Professional/dp/3826691636) * [Publisher H:J:R](http://www.hjr-verlag.de/hjr/detail/isbn/978-3-8266-9163/) 
Is any more information available about this? &gt; Sunday started off with Nick Levine talking about learnt lessons from his failed attempt at writing a [Lisp book](http://lisp-book.org/). 
Yes the slides, see here: http://enlivend.livejournal.com/32907.html
Thanks.
I'd like to see what you could do with an SBCL only version. I personally think this library without any dependencies would be great.
Oh hell yes people!, my next keyboard is GONNA have a "Greek" key on it. 
Has there been any effort to make a modern replica of a space-cadet (or Knight) keyboard? References to them seem to crop up fairly often, and everyone present always expresses a lot of interest and envy. Why not make a (limited run?) of USB-compatible ones?
Why does he mean by "listener"? All I can think of is the Observer pattern, which Java certainly uses as often as it can.
He's talking about the REPL. 
First example: (defun set-cross-product (sets) (and sets (cond ((not (rest sets)) (mapcar #'list (first sets))) (t (loop for el in (first sets) append (loop for el2 in (set-cross-product (rest sets)) collect (cons el el2))))))) I'm looking for ideas to make this more concise or elegant or tail recursive. Sample use CL-USER&gt; (set-cross-product '((1 2) (a b))) ((1 A) (1 B) (2 A) (2 B))
Here is an example of before/after ;;Before (defun csv (l) "make a csv file (written to *standard-output*) from a list of lists." (dolist (el l) (format t "~&amp;") (if (consp el) (dolist (ell el) (format t "~S," ell)) (format t "~S," el))) (format t "~%")) ;;After (defun csv (l) "make a csv file (written to *standard-output*) from a list of lists." (labels ((helper (item) (typecase item (float (format nil "~F" item)) (t (format nil "~S" item))))) (loop for el in l do (fresh-line) (if (listp el) (loop for item in el do (format t "~A," (helper item))) (format t "~A," (helper el))) (terpri)))) 
Using ITERATE might be clearer when nesting loops like this. Use ENDP instead of NOT for testing list recursion base cases. I'd personally prefer an ETYPECASE over a plain COND in general, but it's not clear whether that's better in this case, since it leads to some unnecessary nesting. Here's a version with ETYPECASE and ITERATE: (defun set-cross-product-2 (sets) (etypecase sets (null nil) (cons (etypecase (rest sets) (null (mapcar #'list (first sets))) (cons (iter outer (for x in (first sets)) (iter (for xs in (set-cross-product-2 (rest sets))) (in outer (collect (cons x xs)))))))))) Here is a version with ITERATE only: (defun set-cross-product-3 (sets) (cond ((endp sets) nil) ((and (consp sets) (endp (rest sets))) (mapcar #'list (first sets))) (t (iter outer (for x in (first sets)) (iter (for xs in (set-cross-product-3 (rest sets))) (in outer (collect (cons x xs)))))))) Regarding performance, you repeatedly compute `(set-cross-product (rest sets))`. It's better to lift it into a variable: (defun set-cross-product-4 (sets) (cond ((endp sets) nil) ((and (consp sets) (endp (rest sets))) (mapcar #'list (first sets))) (t (let ((tail-sets (set-cross-product-4 (rest sets)))) (iter outer (for x in (first sets)) (iter (for xs in tail-sets) (in outer (collect (cons x xs))))))))) Finally, you can do away with the second case if you realize that the base case should actually yield `(list nil)` (the set containing the 0-tuple) rather than `nil`: (defun set-cross-product-5 (sets) (cond ((endp sets) (list '())) (t (let ((tail-sets (set-cross-product-5 (rest sets)))) (iter outer (for x in (first sets)) (iter (for xs in tail-sets) (in outer (collect (cons x xs))))))))) Alternatively: (defun set-cross-product-6 (sets) (etypecase sets (null (list '())) (cons (let ((tail-sets (set-cross-product-6 (rest sets)))) (iter outer (for x in (first sets)) (iter (for xs in tail-sets) (in outer (collect (cons x xs))))))))) 
That is usually called cartesian product, not [cross product](http://en.wikipedia.org/wiki/Cross_product). (defun cartesian (sets) (reduce (lambda (x y) (mapcan (lambda (i) (mapcar (lambda (j) (cons i j)) y)) x)) sets :from-end t :initial-value '(()))) 
 (format t "~{~{~A~^,~}~^~%~}" '((1 2 3) (a b c)))
Thanks
Is the normal usage for iterate to use-package it? I tried iterate on a small project recently and mostly liked it, but I was put off by symbol conflicts.
Yeah, the symbol conflicts are pretty irritating. As far as I can tell, ITERATE doesn't really conflict with anything in the COMMON-LISP package. In my experience, adding ITERATE to the :USE clause of a DEFPACKAGE form *before* creating the package usually works. It's when you try to USE-PACKAGE it after already having compiled some LOOP forms within the current package that trouble ensues almost invariably.
Nice work! While I haven't looked at the implementation, the API looks feature-rich, and very useful. Question for you: have you thought about what refinements to the API you might need to make (if any) to support not just a local thread pool but perhaps a distributed environment, where work is distributed to other machines/processes? Most likely that means sufficiently abstracting the "tasks" so that it is easy to propagate them to other machines. If tasks are just sexprs, then propagation is easy. Similarly, errors need to be abstracted as well, so they can be shipped over the network. Nice!
"l" is one of the worst names for a variable. If it's a list and there's no better name, call it "list". Add docstrings. It's not clear what your function is meant to do.
Sorry, I don't have a Kindle, but I have a question for you if you don't mind. Is there often a problem with formatting on the Kindle? Is the issue that people are selling you PDF files and it is irritating to read them on an e-ink display (e.g. slow update so zooming and panning is a pain)?
I don't use a kindle device, but do have a kindle program on the mac, and many - most even - books are malformed to one degree or another.
It's normally failure of the built-in SW to render graphics and code formatting correctly. Nook and Kindle both suck that way. I haven't tried another yet.
Well, the Reasoned Schemer was not a pdf - it was a native Kindle book. But the book, as you may know, consists of question and answer dialogs which have a columnar layout. This layout was not adjusted for the kindle screen, just scaled down to fit. This rendered the text too tiny to see, and the text size was not configurable by changing the display size. The book was almost unreadable. Obviously it had been converted automatically and given at most a cursory examination. I want to make sure that LoL doesn't have that problem.
Yeah, perhaps. I actually bought a Nook Color in order to read PDFs without printing (I don't like the extra papers lying around). I didn't take into account that PDF is a pretty complex format. Most files are readable, though sluggish, but about 10-20% of the time the files will be very screwed up. I am using a third party program, though, VuDroid.
Hi, I'm Conrad Barski, the author. I have been wondering the same thing myself, so I went ahead and bought the book in the Kindle store :-) I have the new "special offers" kindle and can report that the conversion is pretty decent: All the code samples are implemented as text (not bitmaps) and wrap appropriately. The pictures look good (given the limitations of the small device.) I don't think you'll be disappointed if you buy it in the Kindle store. That said, some of the code samples have pretty long lines that wrap, but the Kindle handles this as well as can be expected. Also, the wrapping of code is pretty minimal if you use the kindle in landscape with the smallest font (which is still a pretty large font) BTW, I also own "The Reasoned Schemer" on the kindle and know about the problems you describe. I can report that LOL on the Kindle is a significantly better experience.
Awesome. I actually have a hard copy of your book, which is awesome, but I left it at my sisters and she is being somewhat recalcitrant about mailing it to me (might have lost it in a move). I'm thinking about writing my own book about purely functional game development in Scheme, so you are a real inspiration. Thanks for the response! 
Glad you enjoy my book. I will keep an eye out for you book in the future, it sounds fun!
I have it on my kindle dx and reading was a pleasure :-)
Honest question, is that understandable to the average CL programmer? I'm only a Lisp noob but that looks like J or something, heh. 
How much time have you invested in learning different format directives yet? This is not wizardry, the format strings are just not self-explaining on the first sight, you have to learn them. In "Land of Lisp" there are several nice and easy examples to learn both format and loop macros.
format is powerful/complex enough to have [it's own section](http://www.lispworks.com/documentation/HyperSpec/Body/22_c.htm) in the hyperspec... it even has it's own (small) wikipedia page.
agreed, your book is great :)
I have a 2nd generation kindle and the book looks fine. 
A "listener" is a tool which provides a Lisp REPL, amongst other things.
I thought LOL was Let Over Lambda, or was it LoL? Anyways, I've got them both, and thanks lots, mate.
The nested `~{` and `~}` things (for iterating through a list) are easy and useful. You learn these rather quickly. The `~^,` part (for inserting a comma after every list element except the last) is a pretty common idiom that one also learns to recognize over time. The only thing I had to think about for a moment when reading the format string was `~^~%`, but of course, that's just the same thing as `~^,`, except with a line break instead of a comma. All in all, this isn't too hairy a format string. I've seen (much, much) worse. :)
Quicklisp?
I don't know. My feeling is that people who know about and use Quicklisp tend to be SBCL diehards. Maybe Xach has statistics on this sort of thing? *edit: I can't write sentences :(*
I checked the last 90 days. 65% SBCL, 18% Clozure, 10% CLISP, 7% other.
I wonder if that correlates with implementation popularity in general. 
Here's the solution: http://qa.debian.org/popcon-graph.php?packages=clisp%2C+common-lisp-controller&amp;show_installed=on&amp;want_legend=on&amp;want_ticks=on&amp;from_date=&amp;to_date=&amp;hlght_date=&amp;date_fmt=%25Y-%25m&amp;beenhere=1 common-lisp-controller is a dependency of all cl-something packages (including Swank and ASDF)
so...?
I'm not the best person to answer this, having quite limited experience myself, but I'm sticking with Lisp, particularly Common Lisp for a few reasons (in no particular order): * Metaprogramming via s-exps and macros means there is more I can do to make my programs succinct, efficient and correct than in other languages * Compilers with support from optional declarations make my programs run much faster than in (P(erl|ython)|Ruby) and push back any need to think about switching the program to C/C++ whether partly or wholly * The library scarcity problem is gradually being solved, in part due to: * Quicklisp solving the installation/dependency problem * There seems to be less distance between an idea for an algorithm and an implementation of it: less syntax and less boilerplate/ceremony * Few of my Lisp books are new, but they are all still relevant. I've owned several Java books but only one is still relevant after a few years. I like things to be timeless rather than fashionable. * Some of the code I write can be shared between CL and my Emacs config, thanks to the partial CL implementation in Emacs * CLOS tends to make the object systems of other languages look puny, with the possible exception of Perl's Moose Scheme/Racket/Clojure/Arc/Shen are on my bucket list but CL has my attention for now.
As someone who knows very little what would you say the best target of lisp code is. Of course we can code almost any type of software in any language but php is useful mostly for web sites. C does systems and websites when they need to be really fast. C++ is good for desktop applications. C is also really good for making custom UNIX utilities and stream processing. I really do dislike the association of language with context, like I do webdev in c and I think Java is a great language that shouldn't be stuck to VM and an stdlib. C# is almost exactly Java but different context. Why? Language is for humans. But let's face it, forced context aside, if you get in the habit of coding in a particular language there is a certain class of software you find yourself coding more often. What is that for lisp? 
Lisp is good at becoming a domain-specific language, because practically everything about the language is available for extension and modification. 
Lisp *is* the tool belt.
There are a few being related in the [tribute thread to John McCarthy at lambda-the-ultimate](http://lambda-the-ultimate.org/node/4387).
There is also problem with cl-json and yason, they both have "json" as a nickname.
There's plenty written about this on the web: [advantages of common lisp](http://www.google.ca/search?gcx=w&amp;sourceid=chrome&amp;ie=UTF-8&amp;q=advantages+of+common+lisp) For me, there's a lot of subjectivity when it comes to languages. If Lisp doesn't grab you pretty quickly, it's probably not for you. Some [love](http://c2.com/cgi/wiki?WhyWeLoveLisp) it and some [hate](http://c2.com/cgi/wiki?WhyWeHateLisp) it. 
A.I. :) I think Common Lisp is really a versatile language which you might want to use for everything _unless_ there are special requirements. At least I do. I'm fluent in a couple of other programming languages, particularly, C++, but I use CL wherever possible. It particularly good with 'explorative' programming, where you try different ideas in REPL. C++ not so much, obviously. Python has REPL too, but it is nowhere as good as SLIME. Besides that, Common Lisp is pretty fast, so it is suitable for number crunching, simulations, etc. Python -- not so much, at least not without weird libraries which defeat the point. Matlab and R are good for some math, but with CL you have a general purpose language which is crucial for some things. As for web programming, if you know right libs it is actually easier to do HTML templating and RPC server in CL than in PHP. But there are cases when you absolutely want top performance, no GC and easy deployment, so you choose C++; or you need to deploy web app on a server which only has PHP and so on. In cases like that it becomes obvious that you need something else. But if it is not obvious I'd rather choose CL.
C is hyped for maintenance ease? Really?
Perl, Python, and Ruby have functional elements. Take Python's list comprehensions for example, or Ruby's `collection.each` iterator. Lisp takes these ideas further, by emphasizing functions. http://en.wikipedia.org/wiki/Functional_programming Lisp gives you power that other languages only dream of. Lambdas, domain specific languages, A.I., the list goes on. You really have to see some of this stuff to understand why Lisp is so powerful. See for yourself by following the [Casting SPELs in Lisp](http://www.lisperati.com/casting.html) tutorial. I recommend [CLISP](http://www.clisp.org/) or [Chicken Scheme](http://call-cc.org/), but the choice of Lisp doesn't really matter--just learn one.
it's 21th century and we don't capitalize Lisp anymore, mate.
my experience is that after Commom Lisp the other languages look a bit like toys. But this doesn't mean they can be abolished. There are times when throwing a quick text-processing script in Perl is still more convenient than writing it in CL.
CLISP, not Common Lisp. [CLISP](http://www.clisp.org/) is the name of GNU's implementation of Common Lisp, not an abbreviation for Common Lisp. CLISP is specifically targeted and recommended in Land of Lisp which was published October 2010 and was reportedly rather successful. Quicklisp, on the other hand, is implementation agnostic and available for several impementations, and thus wouldn't selectively boost CLISP usage. (Edit: @anonymous_downvoter Why the downvote?)
Lisp seems especially good for programs that tackle a class of problems; you then want to modify these programs, even at runtime, more extensively than just parameters and configuration. Such programs are best thought of as role specific platforms, with AutoCAD and Emacs being the best known examples. Its hubris to think that we know where our programs will take us. Like any tool unexpected applications of it tend to arise. Lisp lets us preserve the laboratory at the heart of the factory.
Because you stay able to read your programs as the tree structure it is, because the syntax is just the tree structure itself. Underrepresented: we have [special variables](http://www.gigamonkeys.com/book/variables.html#dynamic-aka-special-variables) they're pretty useful and i am not aware of any other languages using them. Of course the state of lisp is not perfect. I haven't been able to make a couple-of-kb simple executable with any of the implementations. There should be a compilation mode for this. Ability inspect lisp objects is not quite good enough. How do you get a list of the slots of a class/structure? How do you get the argument list? [`function-lambda-expression`](http://www.lispworks.com/documentation/HyperSpec/Body/f_fn_lam.htm#function-lambda-expression), usually gives `nil`. `not` only takes one argument, defining it as `not (and ...)` would have made sense. `append`, only appends lists, `+` is not extendable.(can't add vectors) Basically, many little things.. Edit: of course, some stuff may be library-work, but then we will want them in standard library so people don't have to worry about the next user having to get all the dependency. (Although quicklisp already covers this a bit.)
Yeah but [looking at this](http://www.b9.com/blog/archives/000003.html) they may have installed the controller for clisp, not the other way around.. muuh-gnu has a potential reason it was clisp and not sbcl.
Thought it was strange, since usually sbcl is often recomended. Probably with the idea is 'compiled is better'.(edit: which probably is often valid)
If you are working on big projects in a corporate environment where you want to keep the codebase to standard idioms, so that you can hire and fire mid-level programmers at will, then Lisp isn't for you. Or, I should say, you probably want some other language, like Java or C#, which have been designed exactly for that universe. Languages with easy to use meta-programming facilities, like Lisp or Factor, allow programmers to create and use their own syntax. Lisp programmers are, therefore, often writing code which reflects their own personal idiom. I come at Lisp from an almost purely functional approach, for instance, staging computations monadically, using destructuring, etc. I've built syntax just for this purpose in my Lisp of choice. But other people don't think of Lisp this way, so much so that they wouldn't even say Lisp is functional. Their code looks very different than mine, I'd imagine. Lisp is a great language for small, one or two person projects worked on by geniuses. It is a great language for a person to learn to understand _programming_ in, because you can really play with the _model_ of programming used in Lisp. I've noticed a lot of programmers have an _ad hoc_ understanding of their discipline; they know the text they type gets turned into actions at some point, but their mental model of that process is often hazy. Lisp will teach you to think _very_ carefully about that mental model. It will let you build new models of computation quickly, try them out, modify them. It will let you understand what programming really is. That alone is worth it, to me, but then again, I'm not working on big projects in the "real world."
&gt; What does LISP do better than Python, Perl or Ruby? I'll stay away from "language power" type stuff, and just say how I think the Lisp implementations are better technology. FFI. Interfacing with C code, and hence with everything under the sun, is very easy with Common Lisp. To my knowledge, Python and Ruby (don't know about Perl) require you to write something in their own C API if you want to use an existing C Library. In Lisp, you can just call the C functions directly. Performance - you can get numerical code down to about Java speeds (sometimes C speeds, but, pragmatically, Java speeds).
Ha ha. I came looking for that exact comment.
That's a first for me too.
You should take a close look at some of the [experience shared by Andy Gavin](http://news.ycombinator.com/item?id=3152131) and [someone who worked with him](http://news.ycombinator.com/item?id=2092507) who put it best: &gt; In terms of productivity, no language design can compete with not have [sic] to write code at all. If you search around the Net, you will find various [realizations that the Lisp productivity story is slowly crumbling](http://groups.google.com/group/comp.lang.lisp/msg/6f75cfb5a289d3f6?pli=1). The Lisp ecosystem in its current form today simply cannot compete in productivity terms in a broad context. I believe the Lisp advocates' claims of expressiveness, power, *etc.*, but I think that only kicks in when you have an existing sophisticated and complex code base already built up in Lisp. I have yet to see another large'ish language ecosystem where one can access the AST as powerfully and easily as Lisp, so that makes some problem domains a lot easier, for example. However, starting *de novo*, if you had to integrate with a wide range of interfaces, I find it really hard to see how Lisp is superior to alternatives. Starting *de novo*, if you had a very narrow problem space to address in some contexts, I could see Lisp's benefits shining relatively soon in whatever project you are tackling. Part of what I think is happening is an engineering economics situation. We have entered an era where there are orders of magnitude more programmers than there used to in the past. Lisp was a more broadly appropriate choice in the past when there were not as many published interface specifications and fewer programmers to implement the ones that did exist. It was not uncommon for management to need integration against an interface to have no difficulty approving the programmer time to build it from scratch. In such an environment, Lisp is a very powerful force multiplier. Today however, vastly more programmers (*almost* regardless of their proficiency), open source, and many more published interface specs, and large CPAN-like online libraries have led to an environment where essentially the network effects of massive code re-use has stripped away most of the benefits Lisp conferred upon the individual programmer. While it is true that there are some truly craptastic libraries out there, the sheer quantity of alternative libraries has a quality all its own, to pharaphrase Stalin. My personal evaluation: I have chosen Lisp for my personal projects where time is not critical and where I also expect the project in its advanced states must manage extremely abstract processes and concepts. I choose almost anything else for my professional work, where time is of essence.
&gt; Lisp... Is it fast? Is it fast? Is it right for your task? Probably not. It depends on whether you know what libraries you need and if you already know what you're doing. If you don't, then the previous claim ("You can express what ever you need to quickly, with minimal pain") is wrong. 
The Common Lisp ecosystem provides a framework for writing code with a high-speed integrated code/test cycle. It provides a generally greater programmatic flexibility than other languages. The higher level of sophistication offered by macros allows higher levels of abstraction. Python/Perl/Ruby are all three specialized around string handling and dictionary based programming. Effectively, they were all attempts to make Bash 2.0 that got hijacked by web programming. They fall down the further you get away from that center, which usually is exposed by a reliance on C FFI libs. All three are weakly designed and organically grown. Common Lisp, in contrast, explicitly took advantage of 20ish years of dynamic language work and designed in a lot of aspects that make sense. Python/Perl/Ruby usually make the most sense when you are writing small scripts or simpler web pages. Lisp should fit in your toolbelt when you need to build larger programs doing more sophisticated things. I don't believe it has gotten much in the way of bindings for the enterprish acronym soup (SOAP, WS-\*, ESB, blah blah blah). Java has filled that niche quite well, with *lots* of lines of code. tl; dr: if you want to do something more than 100LoC and not tied into Enterprise Jibba Jabba, Common Lisp is fine.
Your book is on my list, and I really liked casting SPELs and the Haskell tutorial. Just wanted to say thanks!
What implementation are using that doesn't give you the list of slots on an object when you inspect it? SBCL certainly does. Slime will also automatically look up the argument list for a function, maybe not by default? Concatenate works for other built in sequences, and is part of the standard library. 
`inspect` and `describe` write does not return in list form, reading back via the stream is an ugly hack to get at the information. `concatenate 'string ..` is painfully verbose.
Check out the metaobject protocol. There's a function class-slots which gives you a list of the slots in a class. There are slight differences in the way different implementors provide this API but the closer-mop library tries to standardize it. Also, extract-lambda-list gives you the other thing you're looking for.
&gt; If it's your first time attempting the task at hand, you may not want to do it in Lisp (especially if it's for work). Yes, and in this case it's quite likely you won't be able to express it quickly.
Once you've learned lisp and use it to learn more about the idea of programming in general, you've probably learned enough. There really is no call for professional lisp programmers, and to be honest very few commonly used community-based lisp projects. 
With no standard tool sizing, about a dozen competing identical tools that each hit a different 80% of the solution, and no real unification whatsoever.
Since my first answer wasn't terribly popular, let me go through this point for point with you: Here are the advantages of Lisp: * You can program in any style (Procedural, OOP, Functional, etc) * Macros * Extreme flexibility. Here are the disadvantages of Lisp: * Poor libraries. Most are written to solve 1 person's problem, and very rarely work well outside that domain. There are a ton of "Trivial-X" libraries, for any given X, and few work well. * Difficulty in deployment. If you want to deploy sans source code, you must jump through hoops to deploy to an end user. This is okay if it's a server-grade application, where delivering a core dump and SBCL will work. You're insane if you think end users will accept this though. * Lisp isn't an in-demand skill. I can't really think of any other companies in my city that have open positions for Lisp programmers. * Lisp has phenomenally low community impact. Lisp massively changed the face of computing, but many decades ago. Today very few community projects exist, and the few that do are mostly the pet projects of one programmer. * Poor compiler guarantees. Even with type-safety declarations turned up to the maximum SBCL will happily ignore various issues as undefined-variables and undefined functions. * Macros. What is a brilliant and sublime solution today is hell to debug tomorrow. Once a macro is largely deployed in your application it is damn near impossible to modify it. * Implementation details. There exist libraries whose entire job is to unify the naming conventions across multiple implementations (see Bordeaux-Threads). Once again, this is fine if you're deploying to a server, but can lead to run-time hell on desktops, and good luck writing portable libraries. * Too much flexibility. CLOS method combinators may sound like a good idea until you realize that you have no clue which combinator is leaving your system in a bad state, or even where in the project folder it exists. One must be extra-vigilent to ensure that you enforce best practices in your code. Not a big deal in individual projects, but this becomes a major issue in commercial and open source work. Personally, I've learned a lot about programming from Lisp. Macros are very handy sometimes, and CLOS makes some things a joy. But if I had to implement anything new from scratch, I'd reach for C# or Haskell. 
Comparing a compiled language (at least in some implementations) to scripting languages in speed is silly. Of course SBCL is faster than Python, was there any doubt? But speed of execution isn't the main problem in my experience, I care more about the following: * How fast can I implement? * How often will I have to go back and fix issues. * How easy is it to re-factor? * How does the language, and its libraries, handle concurrency and IO? Personally, I've found that Lisp is definitely a lot more mixed on these questions than its proponents like to admit.
Took me a bit to catch this. Are you saying that FLOSS implementations make up more than 93% of Quicklisp users? You can use Quicklisp on the commercial imps, right? Did you just omit them because we are talking Debian?
Be aware that almost all bullet-point lists of Lisp advantages &amp; disadvantages you find on the Internet are written by individuals who have only a peripheral understanding of Lisp. Learn Lisp on your own; make your own assessments. For example one of the commenters here complained of having "no clue" "even where in the project folder it [a definition] exists". In Lisp, source code is decoupled from source files. If you're not using an interactive environment like Slime when programming in Lisp then you're doing it rong. Slime is downright amazing, and jumping to the source of a definition is among the most trivial features it offers. Lisp has the problem of making people think they understand Lisp when they don't, so a lot of misinformation gets disseminated.
You can use Quicklisp on commercial CL implementations, but most people who use Quicklisp don't. I didn't filter the numbers for this discussion.
First, you can do: brew edit clisp to edit the Ruby script that configures and installs clisp. Second, on my Mac, the build script for clisp has this snippet of code: if MacOS.lion? opoo "`make check` fails on Lion, so we are skipping it." puts "But it probably means there will be other issues too." puts "Please take them upstream to the clisp project itself." else So brew should automatically skip the tests if you're on Lion. Are you still on Snow Leopard? If not, you might want to try running "brew update" to update your build scripts.
I don't think the distinction between Lisp and scripting languages is a useful one. Lisp is useful in the same problem domains as Perl/Python/Ruby, it's as least as dynamic as them, and many of the features that make them worthwhile are derived from Lisp. If CL code runs a lot faster, that's worth mentioning. Common Lisp can and should be improved, lets not pretend its the only "local maximum" worth considering. 
I just tried too and failed, I think you should try other lisp implementations. Try: "brew install sbcl" or "brew install clozure-cl" edit: if you don't have any requirements, sbcl and clozure-cl should be good enough.
I just installed it on my Mac Pro running 10.7.2 using this command: brew install clisp --use-gcc and it installed just fine. I haven't done anything with it other than enter the REPL, but that worked.
I'm not familiar with "show", but unless it starts a new thread, I wouldn't expect the above code to work on any lisp.
Half of Homebrew packages don't build, and half of MacPorts packages don't build, so I use both. http://www.yellosoft.us/installing-common-lisp
Thanks for that info.. I should probably have already looked at that. Found [this link to be down though](http://www.lisp.org/mop/index.html). To be honest, I shouldn't really be spending time on this right now.. Besides, i wrote a expression-hook library that reimplements macroexpansion and provides a hook on every expression encountered during expansion. One of many things that should already have been online long ago.. I will put a bunch out there next weekend..
"**There exist libraries whose entire job is to unify the naming conventions across multiple implementations (see Bordeaux-Threads).** Once again, this is fine if you're deploying to a server, but can lead to run-time hell on desktops, and good luck writing portable libraries." Uh, if those cross platform libraries exist, what is the problem exactly?
Since we've had Bordeaux threads break badly on us because it was doing tricky and stupid things (another danger with lisp), it is an issue. The fact that Lisp doesn't provide a unified way to access common resources, such as threading, is bizarre. Furthermore, having a community whose generic response to issues in Lisp is "That's not really a problem," truly explains why Lisp has consistently failed to draw the attention of new programmers.
This is more than twice as fast as my original code as well as much more concise.
Done.
Agree, once I looked them up it made a lot of sense. The format string version is somewhat more fragile than mine for some inputs though. Eg my code copes with (csv '(1 2 3)), putting each numeral on its own line, whereas the format would require (csv '((1) (2) (3))). However I could not really complain about this because I did not say what the function is actually supposed to do.
Here I use the feature that allows the format to call a user-supplied function. (defun csv-helper (output-stream format-argument colon-modifier-p at-modifier-p) (declare (ignore colon-modifier-p at-modifier-p)) (typecase format-argument (float (format output-stream "~F" format-argument)) (t (format output-stream "~S" format-argument)))) (defun csv-line (output-stream format-argument colon-modifier-p at-modifier-p) (declare (ignore colon-modifier-p at-modifier-p)) (if (consp format-argument) (format output-stream "~{~/csv-helper/,~}" format-argument) (format output-stream "~/csv-helper/," format-argument))) (defun csv (list-of-items) "Output a list of items in csv format. Each item can be one thing or a list and is printed on one line. Print floating point double precision without the trailing d0" (format t "~{~/csv-line/~%~}" list-of-items)) 
Each bit is quite understandable but the language is huge and you have to prioritize. Quite a few times I have written a utility only to find it already exists with a non-intuitive (to me) name. Eg my name: filter; lisp's name:remove-if-not.
I wasn't original downvoter you are referring to, but I regularly downvote all reddit comments that talk/complain about upvotes and downvotes. To be consistent with this, I'll downvote myself.
People actually using common lisp are more likely to build it for themselves, since debian packages are often outrageously outdated. And given quicklisps ease of use, there's no any reason to use debian packages for any common lisp library. Quicklisp stats that xach mentions are much more accurate with regard to usage of common lisp implementations. Debian statistics is only valuable as an indication of what lisp newbies use.
Do you have an example where this is the case? I have not yet come across a problem for which CL wasn't properly equipped, and I always felt that the standard functions and macros go fit hand in hand.
In the past, I've used noweb. But, it can be somewhat annoying if you've already got a document layout you like to try to merge in noweb stuff that doesn't wreck your general format.
Can noweb just pretty-print an existing `.lisp` file? Or do I need to write my file in noweb's format before typesetting?
I don't really have any experience with this, but as a random suggestion, you may try using org-mode in emacs ([documentation](http://orgmode.org/manual/)). You can [embed source code](http://orgmode.org/manual/Working-With-Source-Code.html#Working-With-Source-Code) in the document, then [export to PDF or Latex](http://orgmode.org/manual/LaTeX-and-PDF-export.html#LaTeX-and-PDF-export).
I can say it does a good job colorizing your code (if that is what you are interested in) when exported to HTML, so it might do well for PDF as well. I think it did it automatically, but I might have had to tweak it following some other (temporarily forgotten) Lisper's blogging setup.
I suppose a verbatim environment isn't good enough? And I suppose you have tried the Listings package which says it supports "Lisp(empty,Auto)" whatever that means?
Streams, threading, and FFI come to mind. There's really no unified interfaces with which to do these, and most of the libraries we've had to deal with only cover 60-80% of the solution, and are generally incredibly poorly documented. I've had incredible issues getting the following libraries to work: * Bordeaux-threads. * Hunchentoot * CFFI (The exception, being actually documented properly) * IronClad (my coworker. Documentation is stale and incorrect) * CXML Plus a few others I can't think of right now.
I have always used lstlistings which also has support for Lisp. It allows you to include files, line numbers of a certain file (quite error-prone though if you are still modifying the files) or you can just add the code in the tex-document itself.
If you are interested in Lisp, you should learn it. Either it will colonize your brain and you will become a Lisp hacker, or it will be incompatible with your brain and you will not. If you become a Lisp hacker, you will be happier and more productive, and will henceforth understand all computation in terms of Lisp. If not, then Lisp hackers will seem even weirder ad more deluded than they did before, and you will probably find uncomplimentary things to say about Lisp. Lisp's niche is defined not by what it's good for, but by who it's good for. It's good for a certain class of programmers who become phenomenally happy and productive when they have it, and who suffer when they don't. These programmers are in the minority, but they aren't going away, and neither is Lisp, despite what its detractors tell you. People have been saying that Lisp is ugly and wrong and doomed for fifty years. They'll be saying the same things fifty years from now. That kind of talk doesn't matter. Yes, Lisp is a ghetto. That's always been true and it probably will always be true. If you're a Lisp hacker by nature, you get over it. Turns out it's not that important. If you're a Lisp hacker by nature, it turns out the ghetto is a good place. The only way to find out whether you are is to learn Lisp.
Emacs does a good job all by itself, even soft-tabbing your code properly when you indent.
There are some long lines in my code, which aren't really a problem in emacs, but which are a very big problem in verbatim mode, since LaTeX doesn't break them.
I've used enscript forever and it seems to have formatting for a large variety of languages. 
Okay, yikes. Auto-linebreaking is a difficult problem because where it should break is a matter of taste. The most experience I have with this is using Maxima and iMaxima, which uses the breqn package. It works okay, I guess. It occurs to me that this might be a much more solvable problem since we are dealing with S-expressions. My preference is to try to format my source such that it will print well (kind of on a literate programming kick, so always thinking of how things will look in a PDF or HTML). Sorry that doesn't help your dilemma.
&gt; My preference is to try to format my source such that it will print well (kind of on a literate programming kick, so always thinking of how things will look in a PDF or HTML). I try to do this to an extent, but it's a constant battle with my monitor's aspect ratio.
...enscipt! That was the thing I used to use! Thank you.
&gt; If it's your first time attempting the task at hand, you may not want to do it in Lisp (especially if it's for work). You mean if you don't know Lisp well? Lisp is my first choice for that.
&gt; People actually using common lisp are more likely to build it for themselves I doubt this also applies to newbies learning the language with a book like Land of Lisp. Those are also unlikely to know about Quicklisp or to need any external library because Land of Lisp doesnt require any.
I use [Pygments](http://pygments.org/). 
IMO it's worth to try to keep lines short, and, if your emacs is too wide, to get used to follow-mode. Try it: `M-x follow-delete-other-windows-and-split`
That's your problem right there. Limit your code lines to 80 chars max. It avoids problems with formatting, printing, readability, overview and version control.
I don't know if I can do that. My screen is 220 characters wide! It feels like such a waste of screen real estate.
That's why you use 2 (or more) buffers side by side in Emacs. No waste, and a good motivation to wrap your lines reasonably. 
noweb can't pretty-print an existing .lisp file. You need to add a &lt;&lt;*&gt;&gt;= at the top and an @ at the bottom. And, it doesn't do any sort of syntax highlighting. It seems to me that the 'listings' recommendation above is the best choice.
You probably don't want to do this, but usually I manually install clisp, emacs, etc. That way I'm 100% up to date.
Lack of UTF-8 support makes it a non-starter.
That appears to be a highlighter rather than a formatter. Can you use Pygments to format?
I do this, but I still can't get past a strange claustrophobic feeling with less than 132 line width. I suspect that goes back to the screen settings I used in college. Just the same, I do love having code and SLIME up with plenty of room to see both :)
Since the OP went with enscript, that appears to be what they wanted: a tool to highlight code for a document. But I don't know what exactly you mean by formatter. Do you mean a tool that automatically indents code, like [`indent`](http://en.wikipedia.org/wiki/Indent_(Unix\)) or [AStyle](http://astyle.sourceforge.net/)? The only Lisp indenter I'm aware of is Emacs. I've only used Pygments for producing HTML, but the website says it can output "HTML, RTF, LaTeX and ANSI sequences," meaning it's well-suited for a LaTeX document, like the OP needed. 
What's the current status of stuff CMUCL has that SBCL doesn't yet have? Apart from miscellaneous bundled libraries (e.g. CMUCL's Motif widget toolkit), the main one I know of is [block compilation](http://common-lisp.net/project/cmucl/doc/cmu-user/compiler-hint.html#toc178).
The bundled stuff is the main thing.
Also quad-floats.
Did SBCL get green threads or did they remove them from CMUCL too?
FYI, Hans plans to release 1.2.1 within a day or two.
I don't know, sorry.
As pandering as it is to say it on this subreddit, the importance of the work of late Prof. McCarthy is quite understated in the article. _It is the second-oldest high-level programming language still in use today—one whose grammar and vocabulary were more perspicuous and versatile than the machine code early programmers had to use._ Yes, because garbage collection, macros and first class functions (however botched by dynamic scope...) make for a language comparable with machine code. Let's not talk about the influence of the early LISP and its descendants on all the rest of computing.
Anyone know what this means? &gt; Add www/ directory with default file tree that is being served
The beautiful thing. Best used with RESTAS web framework. 
CMUCL is more elaborate than SBCL. Hemlock is its builtin Emacs clone, written in CLM, its Motif bindings along with CLX, the Xlib &amp; Xt bindings (portable spec.) I thoroughly enjoyed it before slime, and perhaps even after. It's a strange feeling to have the IDE so thoroughly integrated with the compiler. It's a good place to be if you have 3-6 months without distraction and want to immerse yourself in Lisp. CMUCL was good to me. It made me _happy_ as a C++ &amp; Perl refugee. It's an immersive environment, perhaps the only serious alternative to Smalltalk, in terms of fully integrated languages. 
For /r/lispers who aren't subscribed, here's Hans Hübner's post to `hunchentoot-devel`: &gt; Hunchentoot release 1.2.1 &gt; &gt; Hi, &gt; &gt; I have made a new release of Hunchentoot, version 1.2.1. This release updates the documentation to describe the API changes since v1.1.1, in particular with respect to the easy handler framework. Also included are some bug fixes for SBCL/win32 by Anton Kovalenko and another fix from I. Perminov. &gt; &gt; Cheers, &gt; &gt; Hans 
Ye cats. It's still alive!
While I agree with you, I think the majority of the audience of _The Economist_ would not understand, or really care, about the wider influence of McCarthy's work. I would posit that the Ritchie's legacy is "physical" than McCarthy's influence on theory.
I think it's probably because it's required to build the kernel for some reason. This surprised me a couple of days ago. $ apt-get build-dep linux-2.6 
It'd be a great read I'm sure, but slideshare doesn't seem to load it..
&gt; Land of LISP &gt; &gt; \- ConardBaraksi Is that supposed to be a joke I'm not getting? The guy's name is Conrad Barski, not whatever this is. 
I assume it means hunchentoot now starts with a folder dispatcher pointed at `(merge-pathnames "www/")` by default? Someone who knows should chime in.
it's hard to post 'text' on a 'website'
[Conrad Barski talking about "Common Lisp" and "Land of Lisp" at Philly Lambda](http://vimeo.com/9605639).
It might actually be a typo.
With "Conrad -&gt; Conard" I can see how that might be the case. But how do you do "Barski -&gt; Baraksi"? :O
Maybe they read it really fast.
[restas](http://restas.lisper.ru/en/) with [quicklisp](http://www.quicklisp.org/) for [@armedbear](http://trac.common-lisp.net/armedbear/timeline) is a bit wonky currently. We're working on it… #abcl 
I havent been able to quickload the new package "able" with CMUCL 20b because of the following error: [package able].................................... [package tstree]; ; Error: (during macroexpansion) ; Error while parsing arguments to DEFMACRO DEFPARAMETER: ; Invalid number of elements in: ; (*WEB-BROWSER*) ; to satisfy lambda-list: .. Execution of a form compiled with errors: (DEFPARAMETER *WEB-BROWSER*) [Condition of type KERNEL:SIMPLE-PROGRAM-ERROR]
Looks like it only checks for quite a limited number of Lisps when setting up `cl:*features*`.
As Xach said, ABLE doesn't have the proper detection for CMUCL. Try pushing one of :able-windows, :able-linux, or :able-macosx to *features* before loading it. Xach, what git branch of ABLE are you tracking?
master from git://github.com/dherring/able.git 
What libraries were used? Where is it hosted?
On comp.lang lisp: &gt;Juanre &gt;&gt;On Nov 7, 11:29 am, Zach Beane &lt;x...@xach.com&gt; wrote: &gt; Not that many tools. I used the great cl-ppcre to parse the HYG stars database. I built the database as lisp objects that get compiled in the main utility. And used python for the AJAX interface with the server. &gt;&gt; Do you have anything written about your experience using Common Lisp? &gt; I haven't written about it yet, but it has been great. Common Lisp has been my first-choice language for many years now, and I am certain that I writing it in any other language would have been more time consuming and less reliable. &gt;&gt; Do you intend to share any CL software or libraries as a result of the work you did for the product? &gt; Yes. I still need to figure out what to do with it, but at the very least I'll publish the postscript generation library I wrote. It needs some clean-up, though :-). He earlier mentioned AWS.
Lots of non-technical context here: http://juanreyero.com/article/technology/23visits.html
Lisp is too tired from winning last year.
ABCL is awesome too . Thanks for your hard work guys! 
Not even in top 100.
even worse, java is at #1
In Python you can use Cython... It essentially creates a C Python Module that you can then compile and import into python. You can either use a normal python file, or provide data type hints to improve performance. If you really wanna get down to the metal you can write everything in C and just a couple of prototypes defs to call you C functions. It works really well with Numpy. It works out pretty nice, even though its not FFI.
Best to use Hunchentoot without SSL for now. Add the following to your "~/.abclrc", as the problems seem to stem more from the use of CFFI by Hunchentoot for SSL: (push :hunchentoot-no-ssl *features*) 
I started playing with this last night. I think that the starter pack needs work. You have to run 'make' like you are putting together a C program and then you can't debug it, because all of the debug output goes off into the great nether of i'm not quite sure where. Writing lisp as if it is C/Java is basically impossible for a mere mortal like me... I think the alternative starter pack might be better, but there aren't any instructions (!) for how to use it... Anyway, I will be investigating the avenue of improving the starter pack and figuring out how the alternative works tonight. I'll write back if I do/create/find anything interesting.
I am using the alternative -- Aerique's proxybot. The way it works is that you compile his "proxybot". Meanwhile, you have your actual bot loaded into a running lisp image, and in that image you run (MAIN-FOR-PROXYBOT), you will see it say something like "waiting to connect", and when you run playgame.py with a proxybot as one of the bots it will connect to the image, relay the orders from there, and you will see debug output in your image (you may need to set \*verbose\* to t). 1. When I pulled Aerique's package it didn't keep track of "hills", but that is a couple lines to add. 2. His package used CLOS objects instead of number codes to keep track of what object was at what square. 3. His package includes a (start at?) a full lisp game engine, I think. I started by refactoring so I'm not sure what all was in there. You could probably pull main-for-proxybot and all of its supporting functions into the official starter pack, and just use Aerique's package to compile the proxy bot. It doesn't matter what directory your code is in, except that playgame.py gets the full path to the proxybot executable.
Either using enscript: enscript -E --font=Courier@8/10 --line-numbers --mark-wrapped-lines --output=- ${1+"$@"} | open -a preview -f or using the cl-typesetting library: (asdf :cl-typesetting) (use-package :typeset) (defvar *name* "ai code") (defvar *source-file* #P"Desktop/code.lisp") (defvar *destination-file* #P"Desktop/code.pdf") (typeset::pprint-lisp-file *source-file* *destination-file* *name*) 
[Access on github](https://github.com/AccelerationNet/access)
I didn't get the example. I've never used something like the awhen construct described so I didn't see how the access operation made it easier. Do you have an example in plain old CL?
I am quite happy to see Nikodemus living up to his promises. Keep up the good work!
 (let ((luke (slot-value vader 'child))) (let ((leia (slot-value luke 'sibling))) (setf (slot-value leia 'home) 'alderaan))) becomes (setf (accesses vader 'child 'sibling 'home) 'alderaan) 
Never used CFFI or CXML, but I had really good experiences with bordeaux-threads, hunchentoot and ironclad. Which are as far as I remeber very well documented. I eman what kind of documentation do you seek except for their interfaces?
I'd change it a bit now. You can put projects in ~/quicklisp/local-projects/ and they will be automatically loadable. No need for any ASDF configuration.
 (let ((it (foo a))) (when it (gethash 'a it))) He's saying that access takes care of the let and the when for you: if any result in the accessing chain is nil, access will return nil instead of e.g. trying to run gethash on nil.
I really like the looks of auto-complete-mode and have wanted to use it for quite a while but it (together with anything.el) is one of the few things that makes Emacs unstable for me. I've tried several versions including the latest from the repo but always the same thing: segfault after a while. This is with "emacs -q" and just doing completions in the scratch buffer. After 20 to 100 completions it segfaults (same for anything). The only thing I haven't tried is a different Emacs, mainly because I can't be bothered. I'll just wait for Emacs 24 to show up in my dist and try again. The above has happened with several versions of Emacs 23 in Debian Test for x86.
Arrh, always wanted to have this. I've installed it but it still doesn't want to work, what a shame. EDIT: Oh, now it suddenly works. The wonders of computers, eh?
:( emacs 24 os x 10.72 works great here.
I bought the eBook directly from No Starch Press, so I have a PDF and a mobi (Kindle) file. The book is fine on the Kindle. Sometimes the code's text formatting gets munged a bit (not as badly as you'd think, and I have the type size cranked up pretty big), but you can read everything and the comics come through fine. The PDF looks great. I have a 24" monitor, and the book looks wonderful in two page mode -- better than a real book, I think. The Kindle is great because it's always with me, and I can dip into the text and review whatever point has got me stuck whenever I have a free moment. The PDF is great because on a big monitor it's a no-compromises reading experience, and you can cut and paste into the REPL. And No Starch is great, because if you decide you want to take another crack at the book way after you bought it, they'll let you download your copies of the files again. :) I'm a big fan of the multi-format eBook model that people like No Starch and the Pragmatic Programmers are using. 
try [clsql](http://clsql.b9.com/)
Thanks!
You should also become comfortable with reading and writing files.
Try elephant, or any other persistence library. I'd run shrieking from SQL, at least for the moment. Or you can just write s-expressions to disk, as long as the objects are readable.
You can read data from files and write data to files using standard functions READ and PRINT. It isn't only for tiny data sets. For example, I'm currently working with a graph stored in 2 GB plain text file on disk. (It is reddit vote dump, I'm trying to build a recommender for reddit.) Of course, for some things you might want a database, and there are libraries for that. But for many thing text files in lisp format are OK. There are different database libraries for different purposes. CLSQL provides drivers for a couple of popular SQL DBMSs. Postmodern implements only PostgreSQL interface, but has no dependencies on foreign libraries. There are low-level persistence libraries, such as interface to BerkeleyDB. There are high-level libraries which provide object persistence. Particularly, ORM solutions (I think CLSQL includes some primitive ORM) and object database (Elephant). So it depends on what you need, just like in any other language. BUT in some ways it is better in Lisp: * native printed representation, no need for XML, CSV, JSON etc. * small data sets can be typed directly in REPL * if you have something ugly there is usually a way to wrap it in some macros * high-level solutions are well-integrated with the language and are quite natural 
Oh thats good to know. Many thanks.
There is also a great object database for cases when all your data fits into RAM: https://github.com/hanshuebner/bknr-datastore Quicklisp installable.
Because people at the introductory level want to do more things than manipulate S-expressions.
My first major project in Lisp was a neutron transport solver, and I really needed to know how to use arrays to do that right.
If "handling large real world data sets in a business environment" is something that entails a large purchasing budget, [AllegroGraph](http://www.franz.com/agraph/allegrograph/) and the Lisp client Allegro provides may be of interest to you.
Yes, this is the sort of question I always ask myself, but too afraid to ask and too lazy to read lisp source code to understand how they store data. In Practical Common Lisp by Peter Seibel in [chapter 3](http://gigamonkeys.com/book/practical-a-simple-database.html), you should see that how easy it is to build SQL-like syntax in lisp. I guess lisp is so flexible that anyone can build their own databases anyway they like. I know that lisp has commercial-grade data stores that are good but for open-source data stores, there are only several listed under [recommended lisp libraries, mostly SQL data stores](http://www.cliki.net/Current%20recommended%20libraries) I know that Elephant is great, but it is not actively developed, and I think the documentation is lacking. I think lisp lovers/enthusiasts should be more active in lisp community (myself included), helping out docs, more tutorials, share more code since I think lisp has the potential to be great. edit: I think I should write code instead of making rants.
&gt;but for open-source data stores, there are only several listed under recommended lisp libraries, mostly SQL data stores Cliki doesn't attempt to survey any large amount of what is available, they just list a very few in each category -- that's why it's "recommended libraries". If you wanted a big list of what is available, you need to look elsewhere.
For saving and loading data, read [Practical Common Lisp](http://www.gigamonkeys.com/book/practical-a-simple-database.html).
Re: maxima * a good 2/3d plotting interface * better 'notebook' interface * numerics * special function support * summation/integration improvement * I'll add more as I think of them. And wxmaxima is only a start to solving interface issues. Re: the rest The rest have essentially matured beyond Macsyma. Well, if by python, you mean Sage. And by Matlab, you don't mean matlab at all. Sincerely, a lispm/maxima/macsyma user. 
Could you specify elsewhere? I thought cliki.net is the comprehensive Common Lisp resource.
So Macsyma doesn't really have much over them?
I meant: Cliki has a more complete list at: http://www.cliki.net/database
What Maxima needs, is the same Octave needs: PR. More, much more PR. They need to get into schools, they need to get into universities, they need kids growing up with them. Entire departments, across the planet, completely run on Matlab/Mathematica/Maple, not only for stuff that Maxima/Octave might lack, but for teaching and basic LA and calculus. Many teachers do not even know free software tools like this even *exist*. 
That's correct. It used to be the cream of the crop, especially with symbolic computation, but it hasn't been developed in more than a decade. Others have caught up and surpassed. Sage has a good amount over others, though. 
I was imagining some son-of or bride-of Macsyma. Wrong CAS.
Sage has the problem of not being a single application, of being a 1,5 GB (!) download, an of being Linux only, all of which is a high barrier to entry for Windows using newbies. Even if Sage was installed at schools, students couldnt easily use it for doing homework. wxmaxima is the nicest of them for newbie Windows/OSX users. It is a relatively quick download, a single setup.exe, has a nice gui, a notebook file format, math fonts, plots (using gnuplot), etc. It most closely resembles the interface of Maple of about version 6. [http://andrejv.github.com/wxmaxima/screenshots.html](http://andrejv.github.com/wxmaxima/screenshots.html)
I agree entirely. For a working mathematician, however, I'd still have to recommend Sage, despite some of the hoops. Sage does have an advantage over (wx)Maxima though, and that is its ability to be used via the web. So all you need is one computer running it, and then it's accessible from anywhere, even low-grade hardware.
Tobblo has the right of it modulo slot boundedness and nil checks. If there were accessors named for the slots it would call those rather than slot-value. Also the dict-like-objects could be a mix of alists, plists, hash tables and objects. It would probably be poor taste to combine all of those data structures at once, but I definitely have had objects that contain one of the other dictionary types. This eases getting and setting values from those nested dict. Essentially when using access I never want to get gethash of nil or slot unbound errors. 
Amazon will MAIL me a hard copy the book for less than they will send the digital copy to my Kindle.
Another option beyond a database, which would be Lispy, is to write your own mini DSL. Basically, if you have a graph, you have certain operations that you will always want to use to traverse it. The back-end for this doesn't have to matter to the person who is actually using the data. In land of lisp, he is using a a list.You could easily use a hash-table and lists of symbols, your own data structure, CLOS objects, structs, an SQL database, whatever fits your needs for size and efficiency... You could write your initial implementation using lists, and then swap out the back-end functions when you decide that you need to handle bigger or different data. 
Amazon doesn't set eBook prices; publishers do.
Matthew Flatt just wrote an article in ACM Queue about this: http://queue.acm.org/detail.cfm?id=2068896 in Racket
There's the [Swine before Perl](http://www.cs.brown.edu/~sk/Publications/Talks/SwineBeforePerl/) talk by [Shriram Krishnamurthi](http://www.cs.brown.edu/~sk/). He finishes it up by developing a DSL for writing finite state machines in Scheme using hygienic macros.
Last week, I put together a toy macro that recognizes and evaluates this: (query SELECT * FROM (get-data) WHERE (expr)) I'm sure you recognize the DSL. I get tired of hand-coding what amounts to sql queries against non-sql datasets, so this will help me out.
I wrote a small amateurish Scheme macro to allow "docstrings" (which are saved into a hash-table) by using `define*` instead of `define`; you can find that on my [blog](http://demonastery.org/75/docstrings-in-my-chicken/) if interested. Obviously not quite a DSL but (I feel) a good example of how macros in general can be helpful.
Now you have to share it! :)
Thanks - I was actually inspired to inquire based on this. It was quite verbose (not the article but also the code) so then I bailed before I could appreciate the merit of the end product...
Brilliant! I can see that this is very useful. Just curious, was this in scheme, clojure, or common lisp? I interact with SQL through Python and R and wonder why you would use one of the lisps (for web stuff, or analysis?).
Ah, i was not aware that this was not standard in Scheme as it is in Emacs Lisp. But yes, this would be useful and clever.!
A lot of the control structures in Scheme itself are formally defined in the language spec as macros (in practice they might not be implemented that way, but they can be): [R5RS derived expression types](http://schemers.org/Documents/Standards/R5RS/HTML/r5rs-Z-H-10.html#%_sec_7.3). These are impressively brief and powerful, and could give you ideas for defining new control structures.
Yeah self documenting code is always a plus to me and certainly a great feature of CL and Emacs Lisp (and Python too for that matter) :)
The Common Lisp [LOOP](http://www.gigamonkeys.com/book/loop-for-black-belts.html) macro provides a DSL for writing loops. It's pretty damn powerful, especially for iterating through several collections at once.
Which implementation of `LOOP` would you recommend as being concise?
Don't these basically constitute a list comprehension? 
Well, it's work code, so it's not sharable. It's really not that hard though, just sit down and do some thinking.
Common Lisp. I'm using it to analyze information coming in from a http source.
As written, yes, but I expect I will extend the semantics and available keywords to be broader than simply a list comprehension. 
Yes~I particularly like how the Python docstrings can be linked with Sphinx for html/pdf output, which I have yet to integrate in my daily work.
Beautiful. And very relevant context for macros for me, thanks.
I see, like a select-case construct?
Very useful looking project. I'd love to see it added to quicklisp.
My preference would be to use a monadic approach, as in [this](http://planet.plt-scheme.org/package-source/toups/functional.plt/1/0/better-monads-guide.html) library I've written. Using the monadic binding form with the list monad gives you all the freedom of a list comprehension but allows you to use arbitrary functions to shape the comprehension. These functions take the place of special keywords in a regular comprehension, but don't require special syntax and are first class objects, which is nice. Your approach is definitely more familiar to more programmers, which is probably better.
Access should probably be available in the December update unless something goes awry. 
https://gist.github.com/1367565 I was toying around with making a [Legend Of the Red Dragon](http://en.wikipedia.org/wiki/Legend_of_the_Red_Dragon) style game and wanted a quick easy way to define the various locations. A class to hold location info, a hash table of all locations in the game and a macro to let me define them cleanly.
Until then: cd ~/quicklisp/local-projects git clone git://github.com/AccelerationNet/access.git Then you can quickload to your heart's content!
Ah sorry to hear that, but that's fair enough :)
I think you may have accidentally left out the macro.
Whoops, thanks. Fixed.
I see Lisp at [28](http://aichallenge.org/profile.php?user=839) so I'm guessing that the rankings are changing pretty fast.
I'm not as comfortable with the monadic world as I'd like to be. I will enjoy reading your library.
I've written a lot about this at [my blog](http://dorophone.blogspot.com/). All the monad posts are tagged with `monad`, so you should be able to find them. If you can read lisp, you can understand what a monad is and how they work. 
Is there anything quicklisp *can't* make easier?
I can, of course, define a macro for 'defslice' that adds in the default key parameters, but that seems overkill a bit, too. Eh, maybe not. Hmmm.
Some time ago, I wrote this little article: http://nklein.com/2009/05/finding-better-polynomials/ There, I wrote some macros to find the minimal-degree polynomial given some constraints: (polynomial-to-string (calculate-polynomial-subject-to (value :at 0 :equals 0) (value :at 1 :equals 0) (derivative :at 1 :equals 0) (nth-derivative 2 :at 1 :equals -1) (integral :from 0 :to 1 :equals 1) (mean :from 0 :to 1 :equals 1/4))) =&gt; " + 37.25*x**1 - 163.0*x**2 + 265.0*x**3 - 190.0*x**4 + 50.75*x**5" Code is linked in the article.
How about (defun slice (instance &amp;key (key #'identity)) (slice-guts instance key)) (defgeneric slice-guts (ins key)) (defmethod slice-guts ((ins a) key) ...) (defmethod slice-guts ((ins b) key) ...) (defmethod slice-guts ((ins c) key) ...) It is normal to have a configuration layer and an implementation layer such as this. Get the algorithm right in "slice-guts" without worrying about the interface. We can make changes to the "slice" front end without affecting the core algorithm (if we are lucky).
On a tangent, you don't have to construct a new list to pass to apply. You can use just: (apply #'call-next-method :key #'identity all-args) The leftmost keyword argument takes precedence.
Xach and duali have it right. Couple of tangential notes: * Passing NIL as :KEY traditionally (ie. in all ANSI defined functions) means the same as #'IDENTITY, so you might want to employ the same idiom. * Duali's solution is going to perform better: you can inline the wrapper function, which means there isn't going to be any keyword argument processing at runtime. This also allows you to dispatch on keyword arguments, so it's a very good idiom to know. (The typical naming convention for generics used in this manner is FOO-USING-BAR -- as in SLOT-VALUE-USING-CLASS -- so in this case SLICE-USING-KEY, if one is inclined to nitpick.) 
If I do that, then I have to if: (if key-p (apply #'call-next-method :key #'identity all-args) (call-next-method)) Unless, I don't want any of the more-specific methods to be able to care about key-p (or have a different default).
I like that. Then, I don't need to export the generic unless I want to. Thanks.
Both excellent points. I thought about the first point, but don't really like that idiom. It is, however, the standard idiom so I should suck it up. Thanks.
If you want really short examples, you're only going to get simple ones.
What indicated to you that David Lichteblau is MIA?
I've sent several emails over the last couple weeks. Even looked him up on facebook, no response :/ Edit: nor is he active on the mailing list.
 (defmethod slice :around ((ins A) &amp;rest all-args) (apply #'call-next-method ins :key (getf all-args :key #'identity) all-args)) **EDIT**: I didn't read your last sentence carefully enough, and it doesn't resolve anything and is actually an equivalent of (defmethod slice :around ((ins A) &amp;rest args &amp;key (key #'identity)) (apply #'call-next-method ins :key key args)) so, you may disregard what I said.
Perhaps he's on holiday. He's usually pretty responsive and active. I'd keep trying if I were you.
ah ok, thanks :)
maybe the sound could be improved with a noise filter?
How about directly linking to the source instead of blogspam?
I emailed David about your remarks. Here's what he had to say: &gt; I think stories mutate in the re-telling. Anyway, I also think the package system does a decent job of serving its function. I also don't know how different the package system I proposed is from what others were thinking about. I think the predecessor was lisp machine lisp, which had a more rudimentary package system. What I proposed was modeled roughly on the package system in MDL, a lisp dialect that I used when I was at MIT. I got a lot of feedback and guidance on what I did from Fahlman, Steele, and others on the project -- it was sort of a "stone soup" think, anyway. and &gt; When I was in grad school, before I had settled on my main research area and before I had published any research papers, one of my early projects was to come up with a proposal for a package system for Common Lisp. I thought it through as carefully as I was able, wrote it up and gave it to Guy Steele and Scott Fahlman, and didn't hear anything for awhile. Then a draft section appeared that may or may not have been influenced by what I did -- I was not "in the loop" on that part of the process. At the time, and when I used it later, I was a bit irritated whenever I was inconvenienced by some feature of the package system that I proposed to do differently, but the differences were no really that great. ...among other interesting things. Thanks for citing a source for your information, it's always fun to talk to the people involved with the genesis of CL.
Thanks for the info! I agree, it is interesting to hear from these people.
They forgot CCL (clozure common lisp, former OpenMCL). Especially great, as it has an excellent windows32/64-Port. 
I am kind of amazed they managed not to link to any of the projects: * [GNU CLISP](http://www.clisp.org/) * [GNU Common Lisp](http://www.gnu.org/software/gcl/) * [Kyoto Common Lisp](https://en.wikipedia.org/wiki/Kyoto_Common_Lisp), from which GNU Common Lisp and Embeddable Common Lisp derive * [CMUCL](http://www.cons.org/cmucl/), Carnegie-Mellon University Common Lisp * [SBCL](http://www.sbcl.org/), Steel Bank Common Lisp, originally based on CMUCL * [Embeddable Common Lisp](http://ecls.sourceforge.net/) I hadn't heard of Embeddable Common Lisp or GNU Common Lisp before, so I learned something. :)
The links are linked at the bottom of the text. Here are they: http://www.heise.de/ix/artikel/2011/12/links/135.shtml 
CLISP and GCL are different things. GCL is an offspring of KCL while CLISP is a separate project. If you want to use GNU prefix call them GNU CLISP and GNU CL respectively, although GCL is much more common, as is CLISP without GNU. 
Thanks, now I can see the link to the links. I think inline ads must have trained me to skip out-of-line bold text paired with links. :)
Thanks, now I can see the link to the links. I think inline ads must have trained me to skip out-of-line bold text paired with links. :)
Fixed. Thanks for pointing out that I misattributed a GCL attribute to CLISP. I wasn't aware there were two GNU Common Lisp implementations. I find it odd that neither project acknowledges the existence of the other on its homepage or offers any reason to pick one over the other.
Save time, just go directly to [the source](http://blip.tv/eclm).
Does it use the CL reader? Is `*read-eval*` nil?
`*read-eval*` is t. Why do you ask?
If you use the Lisp reader, `*read-eval*` is T and the standard read macros are available, then arbitrary code can be executed.
Ah, ok. I think that maybe ACL2 prevents that, but I will definitely look into it. Thanks. Edit: I looked into it. It looks like an unrelated bug was preventing `#.` things from being evaluated. ACL2 prevents arbitrary expressions from following `#.` (they have to be a constant defined with `defconst`). And even then, it executes them in the ACL2 context. Still, there are bad things that can be done with it (if the other bug didn't exist), so I am working on preventing it from working at all. Thanks.
So is the proof that the incorrect factorial definition does not terminate _entirely machine generated_? Or was that written as part of the tutorial. If it is really derived entirely automatically, that is quite impressive.
The Computer History Museum (Mountain View CA, near San Jose CA) is *amazing*. John McCarthy was on a panel for their 2005 [The History of Computer Chess: An AI Perspective](http://www.computerhistory.org/press/history-of-computer-chess-an-ai-perspective.html) event. While I didn't attend, I was fortunate enough to get an autographed copy of the poster.
It's entirely machine generated. It's an impressive system. :-) You can read more about it here: http://www.cs.utexas.edu/~moore/acl2/
for some reason, the site doesnt exist!
I'm holding out for the text adventure.
Books. Maybe we need more books just like SICP, and have teachers actually use them to teach.
It was down for a bit; sorry about that. It's working now.
Seems to be working better now.
@xach, will you release the source code on github?
Yes, sometime soon. It's 98 lines or so - nothing very inspiring or general.
Still, I am a newbie so simple programs are quite inspiring :). Thanks xach.
I enjoy cl-yacc, which implements a DSL for specifying a formal LALR(1) grammar which it then generates a parser for.
Just put it up at https://github.com/xach/ghprojects - enjoy.
Thanks for sharing, xach.
Very cool. ACL2 has a couple of official "tours", and I really enjoyed the walking tour, in which you define an append function and prove that it is associative -- it could be fun to go through with this interpreter at hand. http://www.cs.utexas.edu/users/moore/acl2/v4-3/The_Tours.html Also, shortly after typing a key that makes input in the interpreter, the interpreter scrolls to the top for me. I'm on Firefox, copied from about: Build identifier: Mozilla/5.0 (X11; Linux i686; rv:7.0.1) Gecko/20100101 Firefox/7.0.1
ghprojects depends on webscraper. Where it could be found?
On github, right next to ghprojects on the left.
Hooray for unscientific ballot stuffing!
Thanks for this.
That is a fantastic idea. A text adventure that teaches lisp programming basics.
I'd be more interested in more specific categories, like: * I've been paid to write Lisp * I've implemented a Lisp * ... that complies with a specification * I've contributed to an open-source Lisp project
I /use/ Lisp is the obvious missing category. 
Zadar is pretty good choice for this. The city is very beautiful. 
IOLib is for writing highly scalable servers, clusters; no one uses Windows or Mac for this to begin with.
Yeah, and Linux should focus on supercomputers and not desktops or other tiny hardware.
Sure, why not; IOLib on servers, usocket on desktops. Whatever works best; not harmful.
Does anybody even still bother to read posts with "considered harmful" in the title? Statistics so far: Title misleading in 100% of all cases.
Where do they make these entitled, whiny idiots? Boohoo. It doesn't work in my favourite combination of OS and Compiler. No one should be using it until it does? _Grow up_ ! I initially thought that he had run into some serious bug or security flaw that made the library unusable.
Just a little story from a quite while ago: UCW supported both iolib and usocket (or some other native socket wrapper) as a backend. We used iolib because it is 'scalable'. (According to UCW documentation, other backend was just for testing.) SBCL periodically crashed. I've switched to simpler backend. It never crashed since. And I don't think there is any performance difference, if anything, simpler backend was probably faster on workload we had. UNLESS you have a lot of idle connections, a simple thread-per-connection (or even process-per-CPU) model can saturate CPUs with application workload, and it won't get any faster.
Yeah, and 100% portability isn't always feasible or optimal anyway.
I have become aggressively pragmatic in this sort of thing. If it works in SBCL on Linux/Mac, I'm happy. I don't require a library that is oriented around implementation-specifics to work everywhere on all implementations. I am not looking for the perfect solution. Just the 'better' solution, just 'better' enough to not be 'worse'. :-)
Have you even bothered to read the whole post? He didn't complain so much about the limited portability of IOLib itself as about the fact that other libraries build upon IOLib and thereby inherit the same portability issues. I think it's right to be bothered by libraries switching to IOLib and so becoming less portable than they used to be. That is a serious drawback for people that used to use these libraries on platforms that aren't supported anymore.
So that's a pretty accurate analysis of iolib from someone who has quite some experience writing lisp libraries himself. It sounded a tad negative to me initially. But it may be good for iolib, in the sense of there being no such thing as bad publicity. Some comments regarding minor points the article makes: &gt; Over the years many different wrapper and portability libraries (CLOCC, ACL-COMPAT, TRIVIAL-SOCKETS, USOCKET) appeared. Often, this libraries were made by the principle of the least common denominator. For simple applications this is good enough, but complex applications have special needs. One thing I'd like to add is that iolib now has a compatibility layer that emulates usocket (just like usocket has a layer to emulate trivial-sockets, which was important back in the day when people hadn't switched to usocket yet). So if you're thinking of running your existing usocket-based project with iolib, you don't actually have to rewrite it; just plug in the compatibility layer. (That's how we're running Hunchentoot.) &gt; If you got some time: Help hacking IOLib to work flawlessly on OS X I couldn't agree more with that. &gt; Windows, My colleague Tomas Hlavaty has ported iolib sockets to Windows. (Further APIs like fancy I/O multiplexing are in the works.) &gt; LispWorks and AllegroCL a.s.o For iolib's Windows socket implementation, we're testing on both Allegro and SBCL, and the code is very portable in principle. So that's at least one Allegro platform that works. LispWorks should be easy, too. The harsh reality is that Allegro on UNIX/Linux will not be able to meaningfully run FFI code (like iolib) at all until Allegro starts offering native threads on that platform. In addition, Allegro/x86 does not offer long long support, which is essential for modern syscalls. Unfortunately there is nothing iolib can do about these issues. &gt; Even the ClozureCL didn't work I've used iolib a lot on Clozure without any issues. So either that's recent breakage or a MacOS problem. So -- keep the patches coming. I'm not an iolib developer, but I can report that its maintainer has been very helpful when we have sent patches. 
It is fair to say that I've been missing in action when it comes to ZIP fixes or cxml releases, etc. Sorry about that! One issue in this case is that we've still got an in-house fork of ZIP with various fixes which I first need to feed back into the upstream version. The other issue is a temporary lack of time. I hope that I'll be able to sort out this stuff RSN. 
no problem, good to hear :)
I understand the concern. But whenever there is a such a leap in functionality all platforms seldom get it in unison. Portability will come in time. Interested parties need to pitch in. Isn't it how open source is supposed to work? &gt;other libraries build upon IOLib and thereby inherit the same portability issues I would say, more libraries use IOLib there be more interest to get it fixed and portable. Progress Vs Compatibility is always a tricky issue. Can't make everyone happy. True, IOLib needs to be more portable and robust (what isn't?). Calling it 'harmful' is hardly helping.
No, I haven't. But looking at the source code for both CL libraries [listed here](http://mongrel2.org/features/languages.html), neither seem to offer much functionality compared to - say - Hunchentoot.
Hrm, I had high hopes for finding a repo for weblocks that had recent commits, but the best I found was mid-2010. I liked the idea of weblocks, but I always ended up using hunchentoot, cl-who, css-lite, and elephant. Then again, I'm just kinda starting out at this.
Sorry, all my in-house stuff is hunchentoot, cl-who, postmodern and utilties that have just built over time. Can't say why I never got enamoured by weblocks.
We are using Ext JS to great effect on the project I'm on now, though we are using it from .NET using Ext.NET. That said, Ext JS is fairly language agnostic, so it would appear to be a good starting point. Here's an article where the author attempts to marry Clojure and Ext JS: http://www.fatvat.co.uk/2009/05/using-clojure-and-extjs.html I can't speak from experience on this one, but this is where I would start apart from a better idea that might come up here.
&gt; I've been wanting to rewrite in Lisp Why? What's wrong with it currently? What do expect to gain from rewriting it?
I think it's the other way around -- complex framework will allow you to make a site with ease, **but** only as long as it is what this framework was designed for. (Usually, CRUD.) And for some complex site you need to make your own thing on top of low-level components. Hunchentoot is OK, but I use html-template instead of cl-who. (It lets you to make templates in real HTML which is sometimes easier to debug/outsource/etc). 5M pages monthly is just about 2 requests per second, that shouldn't be a problem unless you use really antique hardware and really complex pages. With modern hardware and moderately complex pages you can expect at least something on scale of hundreds per second, which corresponds to 260M per month. I usually throw nginx in front of lisp web servers to handle static pages and whatnot. (Historically, there was a need for complex, continuation based frameworks to implement complex functionality without JS. Now using JS isn't a problem, so there is no need for continuations and you just need JSON-RPC on server side. I don't see what else high-level framework can do, things like CRUD and CMS are kinda app-specific. You might need some stuff for authn/authz, CSRF and XSS prevention etc., but you can do that with a little macrology specific to your project.)
is UCW alive/usable?
It was usable ~1 year ago (when I last did a project in it). ~~It probably broke with the latest Hunchentoot upgrade, although I didn't test it.~~ EDIT: It isn't based on Hunchentoot, sorry for the confusion.
&gt; What's wrong with it currently? It's written in PHP. PHP has a lot of brain-dead aspects that I've experienced but haven't thought to record in order to enumerate them. &gt; What do expect to gain from rewriting it? "Rewrites considered harmful", right? What I expect to gain is having a website written in a language that I like. ;)
&gt; It's written in PHP. Ok, this is a sufficient reason :)