It was a big jump for Lisp, indeed. Scheme was jumping ten years earlier, but had to give up dynamic binding (adding that as a hack). If you look around, Maclisp to Common Lisp was the first traditional Lisp to make that jump. Few followed. Some jumped never. Before (or at the time CL was defined/implemented) Common Lisp, lexical scope in some Lisp variants was implemented in the compiler and dynamic binding in the interpreter. Common Lisp demanded that the interpreter too had to use lexical scope.
I'm sorry, you're right, I wasn't clear. I don't want to set a breakpoint at a function. I want to set a breakpoint IN a function. You know, the kind of thing debuggers have been able to do since the 1980s. I repeat: TRACE is practically useless.
&gt; Common Lisp is basically a simplified Lisp Machine Lisp, with the 'compromise' that it could be efficiently executed on 'stock' hardware. I take it you don't agree with the [argument by Brooks and Gabriel](http://dreamsongs.com/Files/clcrit.pdf) that CL was *not* designed to be efficiently executed on 'stock' hardware (and their related argument that it in fact wasn't efficient on such hardware)?
I suspect when running on a CL with threads this will happen automatically. I wonder which implementation OP is using and if it has thread support enabled.
&gt; the kind of thing debuggers have been able to do since the 1980s. If you try to debug a C program, you see nothing. You need to compile it with debug information first. &gt; I want to set a breakpoint IN a function. You know, the kind of thing debuggers have been able to do since the 1980s. You still haven't read the manual. 
We saw where you said "Lisp".
Yeah, Gabriel and Brooks. Did you see the date of the paper? 1984. Gabriel and Brooks started a company which sold an extremely efficient CL implementation for stock hardware. ;-) They disproved their own paper. Check out this paper about that Common Lisp compiler written by, non other than, Rodney Brooks: http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.170.6249&amp;rep=rep1&amp;type=pdf The summary says: &gt; The dynamically retargetable compiler has been shown to be a means by which ease of compilation for a variety of Lisp implementations can be performed; a means of porting Lisp systems to a variety of computers; **and a tool for producing high-quality, high-performance code for a variety of computers** from a common source. Rodney Brooks himself just advertised what the paper you mentioned said is difficult. Lucid CL then got popular among application writers because it was able to deliver well performing applications on stock hardware. The company killed itself later because of a failed C++ project. For the Lisp you still can get maintenance: http://www.lispworks.com/products/lcl.html Now you can ask what the purpose of that paper from 1984 was. Was it to keep the competition from developing a similar thing?
It looks like I didn't have thread support enabled.
So in the section where I was complaining about SLIME's GUI, your response is to talk about GUIs other than SLIME. Gotcha.
Very odd to see this old post here. Given the number of people that fall in and out of love with languages and the nature of the points raised I'm not sure what useful can be derived from this. I hope the author is having more fun programming now than they were when they wrote it, especially as a couple of his posts inspired me when I was getting into lisp.
You don't need a GUI to set break points.
Okay big boy, in Slime + CCL (say). I am running my program. It may or may not presently be in a function X. I want to pause the program, set a breakpoint in a certain spot inside function X, then unpause and continue running the program. Go.
&gt; You still haven't read the manual. You mean that place in [CLTLII](http://www.lispworks.com/documentation/HyperSpec/Body/m_tracec.htm) where TRACE does nothing like you claimed it did? &gt; If you try to debug a C program, you see nothing. You need to compile it with debug information first. If I want to debug a C program, I compile it once with -g and I can then set breakpoints in any function I have written, and step into/out of any of them. If I want to debug a Lisp program, I have to manually insert BREAK statements exactly where, and each time, I want to break in a given location. Then delete them later. Are you just being pedantic?
You want to create an asdf project, M-. Into a project that you've quickloaded and look after the file that has the filetype .asd to read what that looks like :) EDIT: oops! I wrote this on my phone and didn't check the repo.
They can either '(load "/full/path/to/beebster.asd")' before doing '(ql:quickload :beebster)', or they can go into their ~/quicklisp/local-projects/ and make a symlink to the beebster directory (or just clone the beebster directory right into their ~/quicklisp/local-projects/ directory).
Funny timing, in a second reading of your elisp monad articles I found that interview talking about gazelle among other things (~30min long total) : http://www.hrabaninterviews.com/2013/03/dr-jv-toups-js-as-lisp-pattern-matching.html 
&gt; A language whose semantics doesn't change under your feet is a good thing. This is a very big deal for me. I don't like it when I have to keep updating my language interpreter/compiler and refreshing my code just to keep it doing the same thing.
As Eyor says, "Thanks for noticing." Gazelle is in a funny place. I use it for almost all of my side projects and have written several tens of thousands of lines of code in it. It is mature enough and useful enough to me for that. On the other hand, its written in Emacs Lisp and provides terrible error messages in certain situations, so it is pretty profoundly unready for use by others. Kind of a frustrating place to be! I'm hoping that making it self hosting, which will result in a better reader and transcoder with more useful error messages, will improve things significantly. 
The author has been using lisp for about 7 months for a single project, he has been ruby programmer for 7 years. Somewhere around 5 months, he embarks on a quest to *fix* common lisp: &gt; I really poured myself into CLUEL. I estimate that over the past 2 months, I’ve spent over 100 hours studying the CL language and considering how to make it more usable, another 100 hours researching Lisp history and other dialects to see what has been tried before, 60 hours planning project organization and policies, and 20 hours developing infrastructure for packages, aliases, etc. Ok for two months that's a lot of work (4.5 hrs/day if everyday). But that does not make one an expert at CL. Each designer of CL had probably at a minimum 100x that in experience programming and *implementing* lisp. He also expected his project to be embraced by others: &gt; In the long run, the initial design of CLUEL is irrelevant, because it was intended to be changed soon, with the involvement of more people. He burns out, gets disillusioned. Notice there is not a single self-criticism in the whole article. Nothing like: *I took the wrong approach here*; *maybe I should have blogged more about my ideas* ; *maybe I should have tried to become an experienced lisp programmer first*. All his self-referential statements are about how much an expert he has become; how much he has studied: &gt; I have personally looked up the documentation for every one of the 987 symbols in CL. All the criticism is directed to CL and it's *negative* community. His failure is not his but ours. Finally, he goes bipolar and won't even release what he has done: &gt; Worse, I suspect that even handing off CLUEL for someone else to run it would be a mistake, because it might prolong CL’s decline, and delay a better Lisp dialect with a healthier community from rising to prominence. He wanted to become CL's savior and, now that he has given up, he wishes its death. Aside: I think his idea CLUEL is not half bad. But I doubt someone with 7 months experience and experience in only one other language is the right person to pull it off. 
&gt;Scheme is approaching where CL was 30 years ago. R7RS-big is an admittance that although a small understandable core is appealing, the problem arises that this core, because it can be understood, is then used to implement greater and greater abstractions, such that the languages features are pushed to the extreme, and left wanting. This, I think, was what was stated in the Worse Is Better paper. I don't particular like that term as it seems derogatory to me, especially because I like Scheme, but it's meaning is I hope understood. This recalls Forth, a language beautiful in its pure simplicity, yet easily incomprehensible when composing "large" software.
Unfortunately there is also a CL software from ISI also called LOOM. http://www.isi.edu/isd/LOOM/
They constitute libraries for general programming in Gazelle and several other small projects like `flat`, some game development prototypes, and a series of experiments with `processing.js`. I'm very interested in Game Development, procedural content, and live coding and Gazelle is an attempt to let me use Lisp in an environment which is ubiquitous and which has good support for showing things to the user. We have vague plans to move the Javascript development at some future point at my job into Gazelle, but Gazelle is a few months away from that, at least. I can get by with the cruddy error messages and idiosyncratic development environment because I wrote it, and a really enthusiastic person could probably make good use of Gazelle now as it is, but it isn't really ready for production level code.
&gt; CL and it's negative community Typical ruby programmer. 90% of rubyists do just rails. I would become insane if all I ever did was riding one and the same framework. No wonder that those guys feel like they need a 'strong' community. Because if they couldn't indulge themselves in endless blog drama their life would be _really_ boring. Maybe he assumed the lisp wizards would crawl out of their caves and hail him as their new messiah because he descended from the ruby community to stop CL's "decline" - and is now just pissed because no one gave a fuck.
First of all, consistency. A variety of things are peculiar in how they are named. TERPRI? Really? Second, Common Lisp is a (the?) programmable programming language. CLUEL-esque platforms could be used to drive CDR adoption and cleanups of the original language. My primary gripes with CL are the lack of CDR-2, lack of CDR-8, the lack of hierarchical namespaces, the funky naming conventions &amp; expectations[1], and the lack of deeper CLOS integration[2]. [1] ELT vs AREF vs NTH, for instance. Or, LOOP for lists vs arrays vs (your data structure here). [2] See CDR-8.
They might be widespread, but 90% of ruby jobs are rails jobs. &gt; In a sense Ruby is the new Perl (as in, language of choice of sysadmins). Sysadmins do other interesting stuff in their job while full time rubyists are rails cowboys.
They have a forum with a lisp subsection http://forums.parallella.org/viewforum.php?f=25 It's not active but you could also ask there. Just in case.
It is not really necessary to denigrate another community to criticize this article. I think his own words do it. 
A typical Common Lisp like ECL should be fine. Maybe CCL runs on it. Then maybe Starlisp ported to it? http://www.softwarepreservation.org/projects/LISP/starlisp/sim/ http://en.wikipedia.org/wiki/*Lisp http://omohundro.files.wordpress.com/2009/03/omohundro86_the_essential_starlisp_manual.pdf http://people.csail.mit.edu/bradley/cm5docs/nov06/GettingStartedinStarLisp.pdf http://starsim.sourceforge.net 
Since your audience is probably larger than the Common Lisp community (i.e. anyone who can use the command line and wants to record that program), you probably *do* want to make it into a stand-alone application. Check out [Buildapp](http://www.xach.com/lisp/buildapp/) for an SBCL-specific, but more convenient than save-lisp-and-die, method of creating stand-alone binaries. You might also want to look into SBCL's core-compression feature (which it needs to be built with -- look at `*FEATURES*` to see if `:sb-core-compression` is present and if it isn't, read SBCL's INSTALL file). If you go this route you will definitively need to compile your program on each platform you plan on supporting. As an aside, if you're looking to process command line arguments, I've had luck with [CLON](http://www.lrde.epita.fr/~didier/software/lisp/clon.php). It's not the only package that does this, and I can't speak for the others, but CLON has done what I've wanted with little friction. Additionally, if you want make the program look like a "proper" GUI application, I can point you in the right direction -- just let me know.
This was very commonly believed, particularly with regard to CLOS (which came fairly late to CL, and also was dropped in very much in one big chunk). I think the belief was clearly wrong, fortunately.
I think the underlying point here is that this whole change-behaviour-of-x-without-changing-x's-source is something that is *really important* in a language where going from changed source to something you can run is both expensive and requires restarting whatever you had running before, and hence losing all the state that was interesting. Lisp systems aren't generally like that: if you want to change x you do that, compile it (or not!) and then next time the running program calls x you get the new one. That makes debugging-by-inserting-code a completely viable way to work. In fact, even though I use LW, which has a very hairy GUI debugger, I often work like this.
Thanks, haven't seen Ranger before. Is there a specific way in which Gingko could be "Ranger-like"?
Ranger always has an idea of where you *are*. You navigate largely with the keyboard and the emphasis is more on *moving around the tree* than on the tree itself. I haven't used Gingko but the screenshots suggest to me that it's too focused on organising your code in a pretty tree, rather than on interpreting your code *as* a tree. An important point is that it's *not important* what level the code is on, only how it relates to the previous levels. Thus, a moving field (rather than moving around the field) like in Ranger is probably a better solution. --- Additionally, fit more writing in! Less space, more code! Ranger's interface is lovely; I can't see a mouse-oriented editor to be.
Yea that's legit, good point. I (mis)interpreted what you meant as "90% of ruby code is rails since anyone who codes ruby is a rubyist". 
Since your goal is to learn LISP by writing the interpreter, let's divide into two cases: 1. Your goal is to learn just LISP, not call-by-sharing (= what you are referring to as pass-by-reference). 2. Your goal is to learn call-by-sharing and then LISP. In the first case, it may be better to write the interpreter in Python or any other call-by-sharing language you are familiar with. In the second case, http://pythontutor.com/visualize.html will get you familiar with call-by-sharing.
it runs linux/arm so some should work out of the box without porting: - ecl - ccl - picolisp
Thanks for the helpful reply. I updated the Readme to include a link for get-iplayer and also deleted the load-file line. 
&gt; &amp;key can be combined with &amp;optional and &amp;rest. However, the &amp;rest argument will be filled with all of key-value pairs, so it’s generally not useful to use them together. now that I know not to mix &amp;key and &amp;rest. my newbie question now is.. is using &amp;key and &amp;optional together good still?
Learn Common Lisp and Scheme
I prefer common lisp since it is not tied to a paradigm like Scheme or Clojure.
Agreed, though I'd say Scheme has good pedagogical value
Well, I prefer Common Lisp. Read Land of Lisp or Practical Common Lisp.
I'd personally go with Common Lisp, because a) plenty of freely available very good learning resources. b) the combination of Common Lisp, Emacs, Slime and Paredit has to be the most enjoyable programming environment there is.
Hehe, I get what you're saying, but I really think that OP is the one that should've told us some more info in the first place :). Maybe that's mean of me, I dunno.
Those two are generally not mixed either, but it's less messy than &amp;rest. You'll only be able to supply key arguments *if* you fill in the optional arguments. The convention is to use nil for optional arguments you don't actually want to supply, but, honestly, that's kind of messy. It also breaks the third part of optional arguments: the supplied indicator. (defun foo (&amp;optional (x 0 x-supplied-p) &amp;key a) (list x x-supplied-p a)) (foo) ;; =&gt; (0 NIL NIL) (foo nil :a 1) ;; =&gt; (NIL T 1) 
Try doing some independent research first to see which is most aligned with your needs/values. I'm a Common Lisp user primarily but there is great work going on in the Clojure and Scheme communities.
I would say common lisp as well, because I have written some libraries for it and I need testers.
I went the Common Lisp route for similar* reasons and have been happy with the language. To me, one downside is that the community is relatively small. For example, if you want to go to an active meetup or look for jobs you might check what is available locally before making a choice. *I would say that I enjoy SLIME, without making a comparison to environments I haven't used. 
Any Lisp? Racket or Clojure. Why? Because you won't have to learn Emacs. I love it, but it's quite a time investment, and it's a goddamn editor in the end. You can program Racket from its own native Editor+REPL, or Clojure from a more familiar IntelliJ, Eclipse or Netbeans environment (there are plugins for those IDEs), so pick one of those if you are only delving into it casually. Racket has nicer, if rather laconic, error messages, though, but the upside of Clojure is the Java integration and libraries. Just pick one and get on with it.
Sidecomment: Buildapp now works with CCL also https://github.com/xach/buildapp/pull/10
Maybe I worded that too strongly. For me it is the most enjoyable programming environment I have encountered so far. But, of course, I might be different in that regard. I like Vim and Emacs but sit me in front of one of those IDE's like Eclipse and I'm lost like a little child in a big warehouse.
It was probably worded fine for your experience; I personally had to word it extra weakly because I am largely unfamiliar with other IDE's.
You're in a predominantly Common Lisp subreddit, so be aware you'll likely get answers that mostly break that direction. I very much like the functional disposition of Clojure, as well as the syntactic sugar. I work with data a lot, and those square bracket vectors are pretty handy. That said, I'm less enamored of the JVM. The JVM is great and all, but it does have its downsides. If I were to pick another lisp that I wished I'd put at the top of my to-learn list, I'd say Racket. Racket's community and docs are very discoverable. Racket isn't quite as functionally inclined as Clojure, but it does definitely lean more in that direction than CL. Racket also had some cool experiments going on that include strong typing. Some of the stuff I like from Clojure has been added via an add-on language called "Rackjure." 
You're getting some down vote hate for this, but you make a valid point. Though I love me some emacs, DrRacket is a really comfy environment in which to learn (as well as to continue working).
Nice! Glad to hear that. 
GUI app users generally expect some sort of icony thing to click on. In Linux this is generally an item in a menu which is accomplished through by having an appropriate `.desktop` file. On OS X a `.app` bundle is necessary. On Windows one wants a link to the `.exe` in the Start menu (although I have no idea what Windows 8 is like). These things are not too hard to script if you know what you're doing, but a general purpose solution would be non-trivial (and nice if it existed!).
Implement Lisp yourself. See [Parenjs](https://bitbucket.org/ktg/parenjs) Parenjs is lightweight and efficient Lisp in JS, now with script tag support.
After going back and forth between Common Lisp and Clojure, I went with CL mainly due to the fact that most of the material for learning Clojure I came across was more focused on the Java interoperability than how to program in a Lisp. I still plan on moving on to Clojure, but felt that learning "the Lisp way" was more important. 
[Simple but refined, guaranteed to blow your mind. The Land of Lisp!](https://www.youtube.com/watch?v=HM1Zb3xmvMc&amp;feature=player_detailpage#t=67)
This question was asked there months ago. I had hoped that, given the number of folks that subscribe here, that there would be more discussion here. Alas, this does not appear to be the case.
I was actually going to suggest Emacs Lisp because he would get to apply it to his day to day :)
I like Racket because it's "batteries included", i.e. there are a lot of libraries so you can get shit done faster and easier. Also, Racket has a lot of core functions that make the source much more readable than what I've seen from other lisps. In the end, though, you can start with one and learn the other later. They're all lisps; you're not going to be confused as to what's happening in any of them after a while.
Do you want to learn Java too, or its libraries? If not, then you're better off with Common Lisp. Or maybe some Scheme dialect. I personally prefer CL as it's more versatile (no focus on functional programming).
Being a veteran of Eclipse for many years, Slime was easily the best/most enjoyable environment until LightTable Showed up. I think anyone really just getting to grips with Lisp of any sort, really should get Slime set up and familiarised. LightTable is very very nice, but I feel the maturity of Emacs and Slime really is very tough to beat. And really to address the OP directly, going for a two pronged approach, learning Common Lisp with CLOS, and Clojure will basically fast track you to great experience.
I concur. I prefered this over Graham's "ANSI Common Lisp" or Seibel's "Practical Common Lisp" when learning. "Gentle Introduction to Symbolic Computation" is often overlooked and yet remains a jewel among CL literature.
 void Player::update() { TouchJoystick* joystick = context-&gt;get(HUD_JOYSTICK); position += speed * joystick-&gt;stickPosition; } HUD_JOYSTICK could be a uint32 or guid, as long as if the game reloads the hud.layer file while running, the new joystick is returned, and not the instance from the old hud.layer file. In fact, the context::get could even trigger an initial file load in order to even use a resource. Raw pointers to objects make the application more brittle when data is unloaded, since all pointers to some unloaded object must be NULLed.
Gentle Introduction to Symbolic Computation is the CL book I went with, after looking at Land of Lisp. The former is a really great intro text I think, and it would be suitable even for an intro to programming course. The exercises were really great too as well as its diagrams for the programs and an abstraction for CL's list/cons etc. constructs. I like the idea behind Land of Lisp, I was just really dissatisfied with how it contained no exercises for the reader to work through and absorb the concepts themselves; the way it spoon fed everything to the reader made it difficult to really absorb any of the CL features, where as the Symbolic Computation book had those in spades, as well as solutions to them to check against. It had quite a few concept only questions, especially early on, which is something I find great texts in any field use. I am hopeful that a future edition of Land of Lisp will have greater pedagogical value though and more suitable for teaching CL in a fun, interactive way while still challenging the reader, but right now it is my least favorite Scheme/CL literature that I have read. That is not too damning of a claim though as there are many excellent and provocative Lisp based books available that continue to transcend their time, and I would recommend everyone read them as they have been very enlightening and fun.
I just wanted to post a quick thank you to the community here for helping deal with the various questions that come up. I am fairly new here and I enjoy learning from everyone, especially those with valid criticisms. Unfortunately, it is painfully obvious, that there exists an enormous amount of criticism that is simply wrong or poorly researched. The way you guys answer these questions and the fact that you do actually address specific concerns helps provide light on various issues and helps us all learn. I really appreciate the work you guys put into this.
I'm not so sure that the analogy with forth here is anything but superficially pertinent. While both forth and Scheme share simplicity and meta-programming features, Scheme is significantly more disciplined in its approach to the latter, even more so than other Lisp languages like Common Lisp or Clojure. As a consequence meta-programming in Scheme is significantly less destructive than it is in a language like forth, where there are essentially no guards in place against metaprogrammatic excess. It is true that the simplicity of both languages does encourage the undisciplined reinvention of wheels, so there is that. 
From 2001, but still interesting to see how he basically predicted "SaaS" (or maybe cloud blah blah) also some of the comments are interesting.
LispWorks is sweet for this IMO.
Very interesting; thanks for this. The article talks about another half. Is that somewhere or was it vapor?
Anyone wanting more comments from Pitman after reading this: he has some informative material in this comp.lang.lisp thread, in which he explains why Emacs and ~~Slime~~ [Garnet](http://garnetlisp.sourceforge.net) and such don't really replicate the functionality available in the Lisp Machine's environment: [More LispOS talk (was Re: Lisp subverts the world (was Re: ints vs fixnums (was Re: Java ... (was Re: ... (was Re: ...)))))](https://groups.google.com/d/msg/comp.lang.lisp/XpvUwF2xKbk/o6CKxgzNLFUJ) Edit: I misremembered, thought the poster Pitman was responding to was talking about Slime, but was talking about Garnet. I've corrected it above.
You could always unify your type system with your code a la dependent types.
I don't know what app you are trying to do, but you should think about using the Browser as UI platform. Thanks to hunchentoot and cl-who it's very easy to get into, and you spare yourself the nightmare that is gui layout.
[Gruff](http://www.franz.com/agraph/gruff/) was made with [Common Graphics](http://www.franz.com/support/documentation/current/doc/cgide.htm) which works on Mac, Windows and Linux.
to be fair. he is not talking about slime. these comments are from 1999 and predate slime by about 4 years.
Thanks for pointing that out. I should have re-read the posts I linked to before talking about them.
I am shocked how relevant Kents comments are even after all these years and the many new languages created each year.
Stuck on the JVM and want to stick with Common Lisp? Look at ABCL. Happy with a lisp dialect? Go with Clojure. Want native code? Running Linux? SBCL. Gotta use Windows? Clozure CCL. Any other questions? 
I use [EQL](http://www.cliki.net/eql) (ECL only): it can directly convert Qt Designer files (*.ui) to the corresponding Lisp code (see -quic). This is really convenient.
If I remember right, there was supposed to be better support for Windows and its toolchain, plus good multithread support (IIRC), etc.
I didn't find these things in the announcement about the fork, but maybe I overlooked something. I still don't understand why the above should lead to a fork. Were the ECL maintainers reluctant to accept patches that implemented features you mention?
At least today. Macintosh Common Lisp had a visual GUI builder. But that was tied to the classic Mac OS. Sigh.
To change the architecture of a project is a bit more than 'accepting patches'. If I have my own fork, I don't need to discuss this. It's just a different goal to advance a C-based Lisp on Intel Windows/Linux, vs. a C-based Lisp which should be portable to various architectures and operating systems.
I've always found Tk easy to write and understand. It's ease of use may have something to do with its Tcl and plain ANSI C background, as opposed to the OO type taxonomies underlying the other major toolkits. You can quickload Ltk and run through this up to date Tk tutorial, if interested: http://www.tkdocs.com/tutorial/ . There are many examples of Tk in use from the Python, Ruby, Pearl, and Tcl communities. Ltk was designed to retain the legibility of Tk's documentation, so one should be able to use the Tk examples from other languages when learning and maintaining Ltk code.
I'm afraid you're comparing apples to oranges here. In your Clojure example you're simply destructuring a map. Destructuring is a powerful mechanism that can be used in any binding on any data structure even if its nested. If you want to have static typing there's [core.typed](https://github.com/clojure/core.typed/wiki/Types) for that: &gt; Keyword parameters are specified using `&amp;` after the fixed domain. &gt; eg. (Fn [Any &amp; {:a Number} -&gt; Any]) &gt; is a function that takes a fixed parameter and an optional keyword argument `:a`, of &gt; type `Number`. &gt; We can also specify mandatory keyword parameters: (Fn [Any &amp; {} :mandatory {:a Number} -&gt; Any]) &gt; is the same function, except the keyword argumetn `:a` now must be present when calling. &gt; We can express finer grained invariants by combining keyword types and ordered &gt; function intersection types: (Fn [Any &amp; {} :mandatory {:a Number :b Number} -&gt; Number] [Any &amp; {:a Number :b Number} -&gt; Any]) &gt; This function type returns a `Number` if provided both `:a` and `:b` parameters, &gt; otherwise returns `Any` if some other combination of `:a` and `:b` is provided. 
Thank you all for your suggestions. I am sure I'll find one I like.
&gt; In your Clojure example It wasn't my example. You may want to contact the author of the linked article to rewrite HIS examples to use core.typed. 
The author doesn't talk about type safety in the link, so his example is perfectly fine. You're the one claiming CL does something better and I'm pointing out that you can have the same thing in Clojure if you like.
I also don't talk about type safety. I've shown that SBCL complains about unknown keyword arguments. You MAY be able go get something similar with some library in Clojure, but so far you have showed some documentation and no REPL interaction how it works in practice. HE was claiming that Clojure parameter lists are more powerful: &gt; Clojure parameter lists are simpler than Common Lisp’s lambda lists and, thanks to destructuring anywhere, they end up being more powerful at the same time. It’s a full super set of lambda lists, so there’s no practical trade-off. I showed in one example, that he does not understand what parameter lists offer in CL and that there is a trade-off. Please read the article.
No, you're just comparing apples to oranges when say "I know which 'more powerful' arguments I prefer.". One is syntax sugar for passing named arguments the other is a uniform destructuring in bindings. Both have their own advantages. 
I would for ANY keyword argument mechanism expect that a Lisp compiler does certain checks: missing arguments, wrong arguments, duplicate arguments. This is available in various Lisps since the early 80s. Clojure only provides a less powerful mechanism based on destructuring data structures. The article claimed that Clojures' apples were oranges, not me. I cite again the article (this is what the author wrote, not me): &gt; Clojure parameter lists are simpler than Common Lisp’s lambda lists and, thanks to destructuring anywhere, they end up being more powerful at the same time. It’s a full super set of lambda lists, so there’s no practical trade-off. I showed that there is a practical trade-off. No core.typed example? 
In Clozure CL, you can use the Objective-C bridge to interact with Cocoa Interfaces designed in XCode's Interface Builder. See: [Bridge Documentation](http://ccl.clozure.com/manual/chapter14.html), [Currency Converter Tutorial](http://trac.clozure.com/ccl/wiki/AppleCurrencyConverter)
&gt;I would for ANY keyword argument mechanism expect that a Lisp compiler does certain checks: missing arguments, wrong arguments, duplicate arguments. And if it was a keyword argument mechanism that would be a different question. Destructuring is not that. It can be used like a keyword argument mechanism. Conceptually it's looking up keys in a map and binding them to variables of the same name. If you fail to look up a key returning `nil` is the sane thing to do. &gt;Clojure only provides a less powerful mechanism based on destructuring data structures. Clojure provides a completely different mechanism that's a lot more flexible. Here's a few advantages: * extract things from nested structures * use it in any binding such as `let`, `for`, `loop, etc. * apply functions that destructure arguments to collections. * not have extra crufty syntax for specific use cases Here's some things Lisps since early 80s don't do: (let [{even true odd false } (group-by even? (range 10))] (println even)) (defn get-foo [[{[{hello :bar}] :foo}]] hello) (get-foo [{:foo [{:bar "Hello"}]}]) &gt;I showed that there is a practical trade-off. That's fair you won't have the same level of compiler checking by default. The part I disagree with is that destructuring is strictly less powerful as it allows doing things you can't do with keyword arguments. Here's the example using core.typed (ann height-option [String &amp; {:height Number} -&gt; String]) (defn height-option [name &amp; {height :height}] (if-not height (str "I have no opinion on " name ".") (if (&lt; height 6) (str name " is short.") (str name " is tall.")))) if I call it properly the compiler will say `:ok` (ann bar [-&gt; String]) (defn bar [] (height-option "foo" :height 1)) if I pass it a wrong type it will complain (ann bar [-&gt; String]) (defn bar [] (height-option "foo" :height "test")) Type Error (typed-test.core:14:3) Type mismatch: Expected: Number Actual: (Value "test") I think that makes it pretty clear where the error is if I pass wrong arguments, again I'll get a clear error: (ann bar [-&gt; String]) (defn bar [] (height-option "foo" :heght 1)) Type Error (typed-test.core:17:3) Undeclared keyword parameter (Value :heght) in: (typed-test.core/height-option foo :heght 1) So, with Clojure I can have the best of both worlds. Flexible destructuring and a powerful type checker to catch errors at compile time. 
I don't know how you do it but I'm glad that you still do. I haven't been here in a while but after all these years you still somehow have the patience to deal with all the FUD spread about CL.
Somehow the notion that it was to be celebrated that "big budget" AI was coming back seemed a bit depressing to me. I also really hate meaningless, unitless graphs such as the "plateau of productivity" graph. And finally, I'm pretty sure it's improper to have your entire management team constitute a controlling majority of the board of directors, as the H+ charity (publisher of the magazine) does.
No docs ;)?
Dude this is pretty neat! I would like some cross platform compatibiliy: extensions for other browsers, clients for mobile devices (iOS, Android, WinPhone). That would certainly make this a true viable option. I really appreciate your efforts so far as more options to protect our privacy are key.
Coming soon! I promise. I've been working really hard to get this alpha out the door, and really wanted to just get it out there instead of giving myself more time to stew about how imperfect it is. I figured docs can wait a few days =]
Thanks! You're right, Turtl most certainly needs more clients. I wanted to include more in this release, but decided it's better to release early on and build as it gets feedback than try to do a million things before launch (and have to support them all). That said, a firefox addon is coming in the next few days. Mobile apps should hopefully be coming in the next few months, and possibly desktop soon when I get around to learning GTK and building a nice CL app with it.
Awesome! Can't wait :)
Because you don't need to smuggle in mutability and pretend otherwise at considerable educational and conceptual cost.
Monads aren't about mutability, any more than macros are about lazy evaluation.
I'm using Clozure CL (32bit) on a small VPS on Linode. Right now, load is minimal as my release hasn't gotten a ton of traction. I did some load testing the last few nights for the just-in-case scenario where 10K people hit the site, and the API (driven by CL/Wookie) is able to process at least 200-300req/s with a concurrency of 300 users. I say at least because the load tester maxed out before Wookie did, and I didn't have the time to spin up a bigger server and do more testing. If I get more than 200 req/s right now, I'll probably have bigger issues than how the app server handles it. As far as how CCL handles the load: pretty high CPU. Right now Wookie (and the library it runs off of, http-parse) is completely unoptimized and could probably stand to be a lot faster. I have noticed some very rare (as in once every 3-4 months) crashes where CCL will segfault (double-freeing a pointer in C land), but this is almost definitely something to do with cl-async, not the implementation itself. It's too intermittent to really test, unfortunately. 
Ah, I think I get it now. Sounds tricky to deal with manually.
Related fun fact: there is a track titled "(defun botsbuildbots () (botsbuildbots))" on the Portal 2 Soundtrack. http://media.steampowered.com/apps/portal2/soundtrack/Portal2-OST-Complete.zip
&gt; If you have mutable state, you don't need to simulate it using the state monad. This isn't exactly surprising. Similarly, there's no real need for a delimited continuation monad in Scheme. However, how does mutable state help you with a Promise monad, monadic parsing, the list monad, etc. etc.? Very much, in fact. [The continuation monad is the mother of all monads.](http://blog.sigfpe.com/2008/12/mother-of-all-monads.html) If you have continuations and mutation (or even just some form of delimited continuations, I believe), you can implement all other monads directly in the base language. I think I first read about this result in Filinski's [Representing monads](http://www.diku.dk/hjemmesider/ansatte/andrzej/papers/RM-abstract.html).
dr racket is a good choice for learning lisp http://racket-lang.org/
[**@RainerJoswig**](https://twitter.com/RainerJoswig): &gt;[2013-09-17 23:05:52 UTC](https://twitter.com/RainerJoswig/status/380105350315520000) &gt;[#lisp](https://twitter.com/search?q=%23lisp) Full FriCAS/Axiom running on top of Clozure Common Lisp on the ODROID-XU quad-core ARM board. Speed is great. [*pic.twitter.com*](http://pbs.twimg.com/media/BUZnzVdIYAAHXNw.png) [^[Imgur]](http://i.imgur.com/lskmRtg.png) ---- [^[Mistake?]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=http://reddit.com/1mmlyi%0A%0APlease leave above link unaltered.) [^[Suggestion]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Suggestion) [^[FAQ]](http://www.reddit.com/r/TweetPoster/comments/13relk/) [^[Code]](https://github.com/buttscicles/TweetPoster) [^[Issues]](https://github.com/buttscicles/TweetPoster/issues) 
I think that in the about section you could add a sentence or two explaining how it works. Initially I thought that all data is stored on the user's computer, but now I realize that it is stored on the central data storage server but is encrypted/decrypted on the user's system. I just thought that you could clarify it a bit to avoid unnecessary confusion. Thanks!
Good idea, thanks! Based on what you and others have said, I think I need to do some overall doc improvements to give a better idea of what's going on and how it works.
Thanks :)
Some additional information could be interesting: did you have to do anything special to get it running, are there specific issues that are still unsolved, what is performance like, etc.
So...they aren't *about* that but are *used ubiquitously* for that?
I can name many common monads that have nothing do with mutability that I use ubiquitously: * Error handling monads (i.e. `Maybe`/`Either`) * Non-determinism monads (i.e. `[]`) * Free monads (i.e. `pipes`)
Clearly you know that "ubiquitously" doesn't mean "only", so what's your point? My point is that /u/pipocaQuemada's metaphor really doesn't say what they want it to. 
I hereby suggest that unsafePerformIO be renamed to smuggle! Comapre: p :: MVar Int p = unsafePerformIO $ newMVar (1::Int) With: p :: MVar String p = smuggle $ newMVar ("Arrrr" :: String) Much nicer! Tomorrow is talk like a pirate day after all! :-)
No. *Some* macros can be replaced with lazily evaluated functions. Other macros are about polymorphism (e.g. setf would probably use typeclasses in a non-purely-functional Haskell-like language). Others are about boilerplate generation.
Monads are values with some context. It is more general concept. Mutability and State is few of many possible applications for monads.
Ubiquitous. Noun. 1. existing or being everywhere at the same time 2. constantly Synonyms: omnipresent, ever-present, everywhere, all over the place, pervasive, universal Saying that foo is ubiquitously used for bar means that foo is almost always used for bar. I think you meant "are commonly used for that".
They help maintaining abstraction barriers, see [David Espinosa's work](http://groups.csail.mit.edu/mac/users/dae/).
Basically I followed the installation instructions. Took quite some time, but worked. Speedwise it is very usable. The ODROID-XU ARM chip runs Clozure CL at roughly 1/3 of the speed of a Intel i7 mobile processor - single threaded.
If that's the route you want to go down (and I predict that you will regret this choice), the Shorter Oxford English Dictionary 6^th edition, which I happen to have right here on my phone, says: &gt;ubiquitous *adjective* Present, appearing or found everywhere; omnipresent. Derivatives: ubiquitously *adverb*. Let's try using that definition in a sentence: &gt;So...they aren't about that but are [found to be] used [everywhere] for that Not "used only", nor "used always", but "used everywhere", as in "all over the place". 
I agree. Take it up with the monad tutorial authors.
... but they aren't used everywhere for that. Relevantly, they aren't used for that in languages where mutability and IO are unconstrained.
No no. That's ADD 1 TO COBOL GIVING JAVA.
But... he (the first guy) uses the list monad instance to represent the list monad instance. The continutation is just a fancy identity, like the ($) of monads. There's also another name for the i function there. It's called lift. He literally lifted monads unto what is a weird identity monad, and used that to claim that that monad could be used to generate other ones, as if the Monad instance he already had appeared from mid-air.
If, for you, the List monad is `[]` and `++`, then ok… but you're accusing the post of using lists and concatenation to manipulate lists. The point is that the programs are written in a small language that supports (delimited) continuations, and that that suffices to splice logic in, like monads and `do`-notation enable. The small language happens to be implemented with `do`-notation and the continuations monad, but Scheme would work just as well. In fact, Scheme would probably be a better example, because the phase distinction is more obvious. Instead of writing programs with `bind` and `return`, it suffices to capture the current continuation whenever we'd pipe values in with anything but `return`. For the List monad, rather than returning a list of values and then counting on `bind` to iterate through lists as necessary, a Scheme program can capture a delimited continuation. That *delimited* continuation is called with each value that would be in the list, and the corresponding return values are concatenated. Some thinking shows that's equivalent to what the List monad does, and that concatenation is only necessary because we're asking for all the results -- the interesting bit, forking computations out, only needs continuations. The difference from having to work with monads (and wrapping that in `do`-notation) is that only the choice operator is aware that it's emulating the List monad; the rest of the program is regular Scheme code, and delimited continuations are enough to insert specialised behaviour where necessary. In other words, there is no need for lifting or for functions like `FoldM`, because every function is lifted and `foldl` is `FoldM`.
I wish I had more upvotes. I am getting started with CL and wanted to try teepeedee2, but it has not been worked in 2+ years. A week or so before this post I went looking for anyone make web stuff using libevent in CL, and found wookie. Needless to say, I am very intrigued. This is an AWESOME project, just like wookie. I really like your work so far. Keep it up! Important question: no plans on a Firefox extension? I have no idea how to make one but I am willing to learn just to help you with this. UPDATE: And WHY are there no screenshots with pictures of your dog Wookie? And no Wookie MIT license. That makes me kind of sad. I appreciated the silly side to your very serious code. :-)
Thanks for the awesome encouragement! I'll tell Wookie you support his license ;) There's a [Firefox extension](https://github.com/turtl/firefox) built already, but it needs some final tuning before release. Hopefully in the next few days (maybe this weekend) it'll be released. Unfortunately there's no mailing list or anything, so you'll just have to be vigilant!
I was going to reply here, but the reply grew. It's [on my blog](http://pvk.ca/Blog/2013/09/19/all-you-need-is-call-slash-cc/).
Very cool. And will self-hosting the Turtl server be a possibility? I will take a look at the code on Github and try to run it on my own VPS if possible.
Absolutely. By virtue of the fact that Turtl is open-source (GPL), you are more than welcome to run your own server if you don't like the idea of someone else holding your data. Right now, there's not going to be much support for self-hosted versions (since I'm working fairly hard as it is to get the hosted service off the ground), however I'm always happy to answer questions or give guidance. Also, while the hosted Turtl service in the future may charge for certain featured (large amounts of storage for instance), I'm planning on making the restrictions/subscriptions plugin-based so you can have an environment where your only restriction is the actual resources you have, not the arbitrary "Oh! You hit the 5GB mark, kindly pay us $10/mo to keep using Turtl" BS. The requirements right now are fairly minimal: A lisp implementation that can run Wookie/cl-async and a RethinkDB instance. Right now, Turtl has hardcoded ties to Mixpanel (analytics) and Sendgrid (email), but I want to make these plugin-based as well so you can do your own analytics/email if you don't want to bother with more third-party services.
Interesting, what inspired you to consider and use RethinkDB? I did not know many people using it for production yet, so cool. Also, you are on [HackerNews](https://news.ycombinator.com/item?id=6400170) and I gave you an upvote of course.
If you have mutable state you still might want to simulate it with the state monad, because you want a nice way to encapsulate the state and to ensure that that state is capture-able and examinable at each step of the calculation, be able to capture the current state easily and backtrack to it or to be able to combine the simulated state monad with other monads, like a nondeterminism monad or Maybe. It is true, as posters below have pointed out, that one can do these things using continuations in Scheme, but in Common Lisp it is sometimes handy to simulate particular monads explicitly. I find it helps me write clear, maintainable, sensible code. 
I agree completely. The key is to lower the barrier to entry. The language itself is very easy to learn, but it's initially intimidating because it looks very different from mainstream languages. Couple that with having to learn a very alien development environment and you've lost most people out of the gate. Unfortunately, this means that most people in the community don't see a problem since anybody who couldn't get past using Emacs got filtered out. In my opinion CL could've been what Python is today if there was the same beginner friendly atmosphere in the community. Instead of telling people to suck it up and learn arcane ways it's much better to provide a path for them to start using the language with minimal friction. 
Looks like a very neat DSL. Though the demonstration was interesting, I wonder how well this works when composing larger pieces with richer structure.
Or composing less "electronic" music. You'd think that a computer can imitate a guitar or piano as easily as it can a synthesizer these days. This is one of the better examples of live coding music I've seen.
I didn't get through maybe before realizing how Cont actually could possibly do this. I also realized what exactly you were saying it does. It doesn't seem like anything more than inflated do notation though, as these things could be done manually using the functions anyway.
Sure. One could say that programming in Scheme amounts to having *everything* in `do`-notation.
i recently followed the "alexandria" link to the "official project home [page]" for Alexandria, which says that "[i]nitial release of the Alexandria library is yet to happen", and the last page update being on 2010-03-09 (about the switch from darcs to git). Further, one can't quickly check the alexandria-devel mailing list archives for recent activity, because "[t]he new mailing list software does not yet have a web interface". i can't imagine this encourages confidence in devs new to CL ....
"I contend that _automatic_ backtracking is the wrong structure for the domain for which PLANNER was intended, that is, Artificial Intelligence."
I think cl-yaclml should be on the list for web-development.
What does the . syntax mean in the define "return . arguments" ? I've seen it before in scheme code, but never understood it.
The argument after the dot is passed as a list of values (which can be null). Think of it as optional arguments. (define (run thunk return . arguments) (reset (return (apply thunk arguments)))) `run` is a procedure with 2 (or more) arguments When you call run you must provide 2 arguments, but you can also provide as many extras as you want. They will be passed as a list. So: (run square log) =&gt; thunk = square, return = log, argument = null (run square log "level 1") =&gt; thunk = square, return = log, argument = '("level 1") (run square log "level 1" "critical") =&gt; thunk = square, return = log, argument = '("level 1" "critical" ) 
Add it :)
Wookie is still rather unstable if I remember correctly
It's a syntax for dotted list. In lisps, lists are constructed from pairs (conses) which have their own syntax which involves a dot between it's "car" (aka "first") and "cdr" (aka "rest"). (a . b) is (cons a b), b is (cdr (a . b)) Dotted list is an extension of this syntax. They are not true lists, but are useful sometimes. (a b c . d) is (cons a (cons b (cons c d))), d is (cdr (cdr (cdr initial-list))) In Scheme function call (f arg1 arg2 ... argN) is matched to the list appearing after define. If you understand how lists are constructed from conses, it's easy to see what happens when argument list is a dotted list. 
I always found [this argument](http://okmij.org/ftp/continuations/against-callcc.html) against call/cc pretty convincing. Continuations are like GOTO, except *worse* (i.e. more powerful). Unlimited continuations make it impossible to implement unwind-protect, which is why Scheme has awful dynamic-wind instead.
In Common Lisp using Interface monads (http://drewc.org/interface/monads.html#sec-7) : (interface:define-interface &lt;continuation&gt; (&lt;monad&gt; &lt;run&gt;) () (:singleton) (:generic call/cc (&lt;continuation&gt; function)) (:method&gt; result (value) (lambda (k) (funcall k value))) (:method&gt; bind (mv mf) ;; m &gt;&gt;= f = Cont (\k -&gt; runCont m (\a -&gt; runCont (f a) k)) (lambda (k) (funcall mv (lambda (a) (funcall (funcall mf a) k))))) (:method&gt; call/cc (fn) ;; callCC f = Cont $ \k -&gt; runCont (f (\a -&gt; Cont $ \_ -&gt; k a)) k (lambda (k) (funcall (funcall fn (lambda (a) (lambda (_) (declare (ignore _)) (funcall k a)))) k))) (:method&gt; run (mv &amp;rest args) (declare (ignore args)) (funcall mv #'identity))) -- https://github.com/drewc/lisp-interface-library/blob/interface/monad/interface/monad/continuation.lisp 
Towards the end, it also considers the universality of call/cc. GP's comment seems like a fine addition to OP's second-to-last paragraph.
Well, /u/Grue's article does [rise a counterpoint to that claim](http://okmij.org/ftp/continuations/against-callcc.html#traps).
How does one "comment on them"? Do you mean here on reddit? I don't see any equivalent to "Talk" pages on Wikipedia. More generally, is there a canonical place where people discuss these things? Without synchronization, I imagine people just add to this page what worked for them or what they developed themselves; I can't imagine that's what a "recommended library" is supposed to be. For instance, the page already mentions 6 options for building websites, and people in the comments here are suggesting adding another 2… I don't see how this page is going to avoid turning into every other page on CLiki that presents 15 options for parsing XML, 10 of which are in pre-pre-alpha version, and where 3 of the others have no documentation whatsoever.
Acoustic instruments are fairly non-trivial to simulate well. Pianos are at least somewhat amenable to brute force - you can just make a huge number of samples of each string (or small range of strings) with the hammer hitting it at various velocities, and as far as I can see this is what good acoustic piano simulators do. Other instruments tend to have a stupidly large number of parameters: there are just a lot of ways you can bow a note on a violin.
Or you could use [cl-reddit](https://github.com/jperson/cl-reddit) ``` (cl-reddit:account-comment_karma (cl-reddit:get-about-user "lispm")) ```
wookie is not yet a quicklisp library which should be a requirement. see https://github.com/quicklisp/quicklisp-projects/issues/558
Looks pretty neat! Is there any reason why it's not merged into fare's repository?
Protip: don't try to find equivalents between lisp and java
Yeah. This is like trying to find some common point between a [cheap ball pen](http://mereditharnold.files.wordpress.com/2010/01/bic.jpg) and a [nice fountain pen](http://reddit.com/r/fountainpens).
IMO it would be much easier to list the *similarities* in semantics when you compare CL and Java. Even obvious things like arithmetic can have different semantics (eg CL has bignums built in, in Java you have to use them explicitly, etc). You are much better of learning CL as a new language, instead of using Java as a starting point. Peter Seibel's PCL book is an excellent intro.
Looks like you are making a few statements. 1. *All variables are always boxed.* Not sure about this. Certainly a Lisp compiler can make use of unboxed values if it can prove that nothing is lost if it does. 2. *This boxing leads to eq, eql, equal while Java only has == and obj.equal.* Again, not sure about this. From what you tell me, == is like eq (which I doubt, because 5 and 5 are not necessarily *eq*) and obj.equal is like equal. I would guess that == is like *eql*. The docs I have found reference something called *equals* and state that it tests whether two objects are "equal". This is ambiguous, but sounds more like *equalp* if you ignore the (IMO stupid) case insensitivity. Equality in Common Lisp is a well examined subject and the reason for these many different functions (and many more possibilities) is due to the inherent situation that data can be represented by reference or by value. I believe this is distinct from boxing of values. 3. *Packages are like hashtables.* This is probably right, but you should note that they probably aren't meant (optimized) to be used as such. As to what the other semantic differences are between Java and Common Lisp, that seems like an impossible question to answer. I would point you to learning the language via something like [PCL](http://www.gigamonkeys.com/book/). I would not recommend that you try to map onto something like Java (maybe try doing this with the CLOS chapters?). It seems that the dominating sentiment in the Lisp community is that Java was a bad idea from the start and has only gotten worse since. On the other hand, I found that mapping Common Lisp onto C (where I came from) was very useful for understanding. *edit for grammar*
They are completely different languages in most ways. You shouldn't try to analyze them as equivalents because they are nothing alike. Reddit wouldn't have enough space to list all the differences between them. Try to learn Common Lisp as a new language, don't base its knowledge on Java, because this will only frustrate you.
&gt; I think that in CL there are no real primitive all the variables are always boxed All types that are immutable (various types of numbers, characters) and small enough to fit CPU registers are usually unboxed by most optimizing compilers as long as they can prove number will fit register. This is pretty old version of SBCL on 32 bit x86: * (defun plus2 (x) (+ x 2)) PLUS2 * (disassemble #'plus2) ; disassembly for PLUS2 ; 0AAFE112: 8B55FC MOV EDX, [EBP-4] ; no-arg-parsing entry point ; 15: BF08000000 MOV EDI, 8 ; 1A: E8392050F6 CALL #x1000158 ; GENERIC-+ ; 1F: 7302 JNB L0 ; 21: 8BE3 MOV ESP, EBX ; 23: L0: 8BE5 MOV ESP, EBP ; 25: F8 CLC ; 26: 5D POP EBP ; 27: C3 RET ; 28: CC0A BREAK 10 ; error trap ; 2A: 02 BYTE #X02 ; 2B: 18 BYTE #X18 ; INVALID-ARG-COUNT-ERROR ; 2C: 4F BYTE #X4F ; ECX NIL Do you see the GENERIC-+ call? That one works with boxed representation and it allows to work with many kind of numbers. See this: * (plus2 4) 6 * (plus2 1000000000000000000000000000000000000000000000) 1000000000000000000000000000000000000000000002 If you put a bignum in there it result will be bignum. If you put large fixnum that it may be upgraded to bignum if necessary. On the other hand, in Java you would get silent overflow if you use say int (or long) and get outside of its range. You can get that in Lisp too, if you restrict the type and compile with safety turned off. * (defun plus2 (x) (declare (type (unsigned-byte 32) x) (optimize (speed 3) (safety 0) (debug 0))) (the (unsigned-byte 32) (+ x 2))) PLUS2 * (compile 'plus2) PLUS2 NIL NIL * (plus2 4294967295) 1 * (disassemble #'plus2) ; disassembly for PLUS2 ; 0AC752E8: 83C002 ADD EAX, 2 ; no-arg-parsing entry point ; 2EB: A9000000E0 TEST EAX, 3758096384 ; 2F0: 8D148500000000 LEA EDX, [EAX*4] ; 2F7: 7407 JEQ L0 ; 2F9: 8BD0 MOV EDX, EAX ; 2FB: E847B538F6 CALL #x1000847 ; ALLOC-UNSIGNED-BIGNUM-IN-EDX ; 300: L0: 8BE5 MOV ESP, EBP ; 302: F8 CLC ; 303: 5D POP EBP ; 304: C3 RET NIL ADD EAX,2 - that is the unboxed addition. In Common Lisp you can set each block of code to different optimization level, some function may be optimized for safety while others for speed. Types may be inferred by compiler, but you can also write them, like I did. &gt; , this is the reason CL has three equalities eq,eql,equal while java has only == (like eq) and obj.equal (like equal), eql function unbox and then compare. Java could have more equality methods. You can often found that class is used in two different ways that mandate different equality and you have the problem when equals is called from third party code or collections. (For example sometimes you want to have comparison of list of strings exactly, sometimes you may want case insensitive comparison). There is elaborate article on various equalities in Common Lisp here: http://www.nhplace.com/kent/PS/EQUAL.html 
In the example you show, you're missing the most important thing about **defparameter**: it defines a *dynamic* variable. Using a dynamic variable in a **let** form establishes what is called a *binding context*, a dynamic storage slot. Java and most other languages don't supply an equivalent semantics. For example: (defparameter *v* 1) ; global binding context (defun printv () (print *v*)) (printv) ; =&gt; 1 (prints 1) (let ((*v* 2)) ; binding context level 1 (printv) ; =&gt; 2 (setf *v* 3) (printv) ; =&gt; 3 (let ((*v* 4)) ; binding context level 2 (printv))) ; =&gt; 4 (printv) # =&gt; 1 A binding context is essentially a storage slot that gets created at runtime. Think of a dynamic variable as a FIFO stack of these storage slots. When evaluating or setting the variable, the top binding context is used. A storage slot is created (pushed onto the stack) by **let** and popped when the **let** finishes evaluating. Dynamic variables turn out to be incredibly useful when writing parsers, printing methods, and tree traversal functions. This is just one of very very many examples where Lisp differs from Java (and a relatively trivial one). @tkpapp and @samiamamma have the right advice. It is a waste of time enumerating all the differences, as this would require describing practically the whole language. 
Wookie is now considered (by me, anyway) to be fairly stable. I'd still call it late beta...ie don't base your entire business on it functioning 100% of the time, but I've been using it in production for some time now and it seems to hold up nicely.
Sweet, cl-async got props. Thanks =]!
&gt; I think that in CL there are no real primitive all the variables are always boxed This is an implementation detail. Depending on the optimization level, most compilers will avoid boxing overhead when they can. &gt; I think that package are like hashtables for the global variables Although they may seem to be similar, packages are more complex than a simple hashtable. Packages support shadowing, nicknames, inheritance, etc... &gt; What are the other semantic diffrence between Common Lisp and Java? CL and Java are so far from each other that comparing them doesn't make much sense. Other than the basic notions like "both have conditionals or loops", everything is different.
Sure. Look into automatic differentiation.
I think symbolic differentiation may have been done first in in Lisp (probably very early 60s: algebra systems written in Lisp were certainly being used in anger by the late 60s) but I am sure it has been done since in other languages.
Actually differentiation was first done by two authors independently in 1953. This is what kicked off computer algebra which was a primary driving force of computer science for the following decade or so. Lisp was actually one of the products to come out of the computer algebra area.
Not intimidating at all when people like edi weitz judge your efforts in Common Lisp.
Oh boy... I feel so small now.
*Amazing* list!
Yes, I even knew that it predated Lisp but had forgotten: thanks for correcting me.
Man, Chicken Scheme is really awesome.
He mentions at around 3:59 that it can be used as a shell replacement, that there's a kernel module that evaluates scheme code inside the kernel. Can anyone elaborate on that? I love me some scheme and would jump at the chance to crash my system directly with it.
http://www.abstractnonsense.com/schemix/ I guess.
All you need and what you need are two very different things. 
Slides are available at http://www.call-with-current-continuation.org/scheme-implementation-techniques.pdf
I think I'll pass.
Submission is on Monday, so you'd be a bit late anyway.
What what what? Wow cool. They post that Movitz is also a bare metal lisp implementation on x86. Holy cow, that is cool. Both projects deader than a door nail, however, perhaps at some point in time we can help and contribute some resources to resurrect either approach. A complete non-sequitur to the op, anyone have any comments on what it might take to get sbcl to be interpreted inside the kernel so we could have an sbcl based shell?
Short answer: way too much work. And a shell is completely independent from the kernel.
Thank you.
But CL isn't free, no? 
Lighttable is working with Lisp now? Sweet.
FYI, just released a Firefox addon: https://turtl.it/ Let me know if you have any issues!
Clojure, not Common Lisp (afaik)
Good points/questions. I'll add a page (hopefully today) that gives details about the internals of the app with some diagrams about how data is encrypted/transported/stored. I'd like to do full/deep documentation of both the client and the API sometime in the next few weeks. This should give a fairly decent overview of how everything works both inside and out. As far as Linode goes, yeah they've had some hiccups. I'm going to evaluate all hosting options (I've heard great things about Hetzner). Keep in mind that unless you own your own data center (or even if you do), there will always be the possibility of somebody snooping on your servers. That's one of the places Turtl really shines: even if the NSA strong-arms a certificate authority into giving them man-in-the-middle abilities, or even if the FBI/DEA/hackers/etc grab everything in our database, everything is still AES 256-bit encrypted. When I'm documenting the API, I'll also document the process for operating a self-hosted version of Turtl. This way if people really want to be in control of the environment and have no need to share data with anyone other than immediate friends/family, they can run Turtl themselves.
I can't seem to find the papers at the moment, but I seem to recall comming across some automatic differentiation tools out there for statically compiled languages such as C++ and Fortran. The techniques vary from using special numeric types (similar to complex numbers) to code transformation techniques (basically symbolic manipulation via a special pre-processor). So, technically, yes it can be done without lisp. However, all other things being equal, I think the Lisp approach is much more elegant. EDIT: I see that I posted this rather hastely, and I failed to see all of pkhuong's comments. Yes, pkhuong is correct: "automatic differentiation", which is not to be confused with "numerical differentiation", does yield exact derivatives.
It's very, very clever. 
Interesting. What is needed and how difficult is it to set up one's own server?
Good question! Just added this to the FAQ: https://turtl.it/faq#can-i-run-my-own-turtl-server Unfortunately there isn't much documentation at all about running your own server, but feel free to ask me any questions. What you're looking at is a lisp implementation (preferably CCL or SBCL), the libevent2 library, and a RethinkDB server. Libraries you will need that aren't in quicklisp: - [Wookie](https://github.com/orthecreedence/wookie) - [drakma-async](https://github.com/orthecreedence/drakma-async) - [cl-rethinkdb](https://github.com/orthecreedence/cl-rethinkdb) Once all set up, you'd copy `api/config/config.lisp.default` to `api/config/config.lisp` and edit to suit your needs. Then you do: (ql:quickload :turtl) (turtl:start :port 8081) You'd also have to edit the `config.js` file in your extension of choice ([chrome](https://github.com/turtl/chrome) or [firefox](https://github.com/turtl/firefox)), run the `./scripts/package` bash script to repackage the addon and then install it. I'm (very soon) going to be making it easy to point the official addons at a different server than the turtl.it ones so you won't have to do any mods to the addon to run your own server.
François-René Rideau writes on comp.lang.lisp: &gt; Open-Sourcing QUUX, QUAKE, QUEPASA, etc. &gt; Dear Common Lispers, &gt; I am pleased to announce an initial release as open source (under the MIT license) of QUUX, QUAKE, and the rest of the general-purpose infrastructure used by ITA's QRes (NB: ITA is now part of Google). &gt; Currently, all that is available is a tarball with files excerpted from our source tree and lightly scrubbed: &gt; http://common-lisp.net/project/qitab/archives/quux-2013-09-24.tar.bz2 &gt; The source is published as part of QITAB, and the correct mailing-list to discuss things is qitab-devel (hosted by common-lisp.net). &gt; http://common-lisp.net/project/qitab/ &gt; This snapshot is not directly usable, and won't even compile, but we realized that by failing to release, and not spending resources on a clean release either, we were only losing mindshare and the opportunity to outsource part of the cleanup and bugfixing, so there it is. &gt; We expect some interested lispers to loot the code for useful bits, integrate them in their own libraries, that we may perhaps someday reimport into our code base. &gt; This qitab-devel mailing-list is a proper venue for discussion on how to take apart the codebase and get pieces to work cleanly outside of it. There is no official support for that code from Google engineers, but we will still try to be helpful, even without firm commitment. On the other hand, there are of course plenty of Lisp consultants around the world who will gladly offer you commercial support if you pay them enough. &gt; Some known issues: &gt; * We haven't yet worked on extracting history, but will try to unearth some useful history. Even then, commit messages will be essentially non-informational, because it's too much work to scrub potential trade secrets from an entire history. Stay tuned. &gt; * (bug 10342133 &amp; 7868425) Quake fails to do its updates, inserts, deletes and mod_count checks in a consistent order (e.g. via sorting object ids) which causes database deadlocks. &gt;* We are experiencing stability issues at times using CCL 1.9 and the current multithreaded server. An uncommitted patch improves on the multithreading using thread-pooling, but exposed a memory leak issue that may or may not have been fixed. &gt; * Support for MySQL as a backend is also available as an uncommitted patch. &gt;* We may or may not include our patched (but now antique) SLIME in a further release. &gt; * There are probably many more issues that will surface if anyone actually tries to use that code. &gt; * QUUX is a ball of mud that begs to be taken apart in smaller units, such as the previously published QUUX-TIME (though we recommend you use LOCAL-TIME, and push any useful feature you miss from the former to the latter). &gt; Regards, &gt; —♯ƒ 
I've created this: http://cl.hajovonta.com/ It's super easy to download, install and run.
As a former graphic designer, I cannot express how much I appreciate a simple no bullshit website. No css, no images, no colour, no bullshit. 
Great idea, but instead of doing this I wish people would just write really good guides on how to get a good dev environment running on Windows. There is a surfeit of good documentation on how to get Emacs/SLIME/Lisp + good customization running on Windows. Stuff like this (and LispCabinet, and LispBox) is generally very opinionated and doesn't explain how to customize things or how and why things are set up the way they are. BTW, any reason for going with SBCL instead of CCL? SBCL is great, but I think CCL's windows binaries are better.
I won't sleep tonight because I lost the url but one of the most beautiful website I've seen recently was a 'vanilla html' website, similar in style to this : http://okmij.org/ftp/ [1] but simpler. ---- ps: my point was, you can't be more on point. ps2: Lucky for me, I shared the link on g+ not long ago, I could dig it back : http://pauillac.inria.fr/ - black on white - blue links - 3 columns perfect. ps3: forgot web.archive.org existed http://web.archive.org/web/20081219175224/http://okmij.org/ftp/ ps4: also this http://mitani.cs.tsukuba.ac.jp/ori_revo/ , with a bit more sophistication. ---- /me on to a not so bad sleep after all.
Was [this](http://justinjackson.ca/words.html) what you were thinking of?
nope, just a little more structure and links. thanks for asking though edit: found it: http://pauillac.inria.fr 
Man, that is just on point. Thanks for the link.
Sure it's possible. How depends on the implementation. Most implementations have a way to save an image and determine how the image gets started. Implementations also might be directed with start-up parameters, if necessary. With the commercial implementations, Allegro CL and LispWorks, developers can 'easily' implement end-user applications which look and feel like normal Windows/Gtk/Mac applications. They have also tools so that unused code isn't included in the application. Thus there are quite a lot gui-based applications written with them. Especially if the target platform is Windows, developers usually have to use the commercial Lisps, since they bring the necessary capabilities built-in. Clozure CL is more limited in this respect, but it still can create gui-only apps with no trace of how it is implemented. One of the main sponsors of these features in the Clozure CL world is Alex Repenning. He develops an application called Agentsheets. http://www.agentsheets.com . I think he even has a Clozure CL application called Agentcubes in the Apple Macintosh App Store (for the Mac, not for iOS). 
Thank you for the detailed response. I'll try pinging Alex and see if he can give me a few pointers on native GUI executables. I suppose if it comes to it, I can check out LW/Allegro too. I really only use the developer versions for testing libraries, and always prefer to keep as many pieces as possible open-source (especially since I'm building some crypto stuff at the moment) but I will keep them in mind.
You just need to tell the Windows loader that the executable is a GUI executable. After reading your post, I slapped up a [small program](https://gist.github.com/death/6740474) to do just that. Didn't test it (wrote it on linux :), so caveat programmer and all. * Build your executable (hello.exe) * Load my program (it needs NIBBLES which is available via quicklisp) * (subsystem.hack:patch-subsystem "hello.exe" :win-gui)
I hate websites with white background because it burns my eyes like looking into a thousand suns through a magnifying glass.
Perfect! Thanks for the code, this is exactly what I'm looking for.
Just think about who may be the target of this. When I started coding in CL, I really didn't want to dive into Emacs and Slime installation docs, and I've read papers about how painful is to simultaneously learn Emacs and Lisp for a beginner - and I agree. It's especially true for users coming from the Windows world. There is no specific reason behind choosing SBCL, I'm using it on both Windows and Linux, and it's a popular platform. Maybe it would be a good idea to package more platforms and let the user choose among them. But for a beginner, I think SBCL is not a bad choice.
I somewhat agree, but a well structured site can be reformatted by Readability.
Recently I had to install Lisp/SLIME/Quicklisp on 3 different Windows PCs and it was rather simple, although not without problems. Since then I wanted to write a tutorial, but alas, I don't have a programming blog.
Are there any lisp machines still in production anywhere? Is there a spec one could use as reference for implementing one? Everyone raves about lisp machines, it would be terrible to lose them to history entirely.
I'd be interested in a virtual lisp machine, just to see what the fuss is about.
I would be as well, or at least very in depth documentation that was essentially a blueprint for building one. I have never even seen a Lisp machine in person, only pictures/videos of them on the net. 
There's an Open Genera project that runs under Linux in a VM. It's a bit of fiddling to get it working, but it'll give you a taste for what the Genera OS on a Lisp Machine was like. https://github.com/ynniv/opengenera I picked up a MacIvory a few years ago. It's a Mac IIfx with a card added that essentially turned it into a Symbolics Lisp Machine. You still see full-sized Symbolics machines for sale on occasion. http://wheagy.com/Site/AI-Robotics/Entries/2009/11/19_MacIvory_model_2_-_Lisp_Machine_-_Genera.html 
Last time I tried, Hunchentoot on SBCL didn't work at all. It works great on CCL. Since the web is so popular, it might be good to pick an implementation that can run multi-threaded web servers (such as Hunchentoot) on Windows.
&gt; You still see full-sized Symbolics machines for sale on occasion. Do you know if they're typically in working order? 
If one of you buys it, please, for the love of all that's bracy and tail-recursive, scan it and publish it.
If you want a Symbolics machine in working order, you are going to become pretty familiar with David K. Schmidt, who does the maintenance on these old things. Even getting "ordinary" SCSI hard drives for the Mac IIfx is a bit of an ordeal. Probably similar for the XL1200, if he has any of those left, or a DEC Alphastation that can run the officially supported OpenGenera. Note the MacIvory support software was never ported even to the PPC, so your Mac OS environment will be 15 years out-of-date. The classic big-iron Symbolics used even more ancient hard drives: ESDI, SMD, or ST506 disks. I'm guessing the only way you will get these with the right format is for DKS to pull one from his (hopefully adequate) pile of spares. Then, you'll find that unless you have a large body of code written for Genera, the powerful editing, introspection, and debugging environment will be pretty meaningless.
A cursory search on the net did not show up much *complete* documentation of any Lisp machine system. It's surprising the things that aren't archived on the net somewhere openly.
Much is on bitsavers. http://bitsavers.trailing-edge.com/pdf/symbolics/ same for TI and Xerox
Ah, awesome. 
You probably stand a better chance with the Ivory machines than the earlier L and G machines, as they had less to go wrong, as well as SCSI, while the earlier systems were SMD (larger ones) and something even more horrid for the little ones. They were all well-made physically though. Screens will perhaps be the biggest problem. The L machines were the most interesting, as machines.
I think the problem for which Lisp Machines were intended to solve no longer exists. (That Lisp programs were too big/slow to run on the conventional hardware of the time.) There were a few 'interesting' projects that perhaps might lead you towards a modern Lisp Machine, or convince you otherwise ;). I think many of them are inactive or at least infrequently updated: * [Movitz](http://common-lisp.net/project/movitz/) is a CL implementation that runs on bare metal. (All it needs is an OS kernel, Hardware abstraction, file system, user interface, etc etc ;)). You can create a bootable image for Virtualbox fairly easily and play around with it. * [Unlambda.org](http://www.unlambda.com/) hosts CADR, Meroko and Nevermore which are simulators for the Cadr and Ti Explorer Lisp machines. You may have to supply roms for the Ti simulators. * [LoperOS](http://www.loper-os.org/?cat=11) was a project to build a Lisp based OS. It's hard to find any information about its current state from the website. * Open Genera - see Wheagy's information. There are also some nice responses and discussion on [this Stack Overflow question](http://stackoverflow.com/questions/1848029/why-not-port-linux-kernel-to-common-lisp) but I should not dare attempt to elaborate on them.
&gt; There are some labs/organizations that still use them. Really? That's awesome. Do you know who, why, what they use them for, etc.?
In military probably. I heard a story where people in the military were not willing to replace them with 'modern' hard/software, because they never have crashed.
I also feel this way about teletype machines, which were quite common in the 60s and 70s, but now are virtually non-existent. Unix and C were written on them (no screens, only paper!), and yet I've never seen one anywhere. Also, all the original computers seem to have disappeared, except for those found in the occasional computing museum.
I think this might be the fellow who gave me mine! Wonder where he got another...
You'd be surprised at what lurks in corners of datacenters. I used to run a web site dedicated to the history of and collecting old DEC equipment, and after 9/11/01 I got a couple of feelers from people in government looking for spare parts for some of their old DEC VAX systems. Technically, the last VAX was officially sold by the end of 2000, but the Alpha systems had been out and replacing them since '93 or so. I heard rumors at the time that large computer systems sold to the government and military were required to be fully supported for up to ten years after the initial purchase; this is one reason it took DEC/Compaq/HP so long to finally retire the last VAX offerings. 
Isn't all of the documentation available online in an OpenGenera environment anyway?
I used a teletype in university in my introductory computer science classes. Learned some programming with them. Mid 80s
&gt; It's all rapidly evaporating off the net. I've found Lisp-related URLs to be especially prone to disappearing. For example, all of http://wiki.alu.org/ disappeared a few years ago and we had to recover it from Google's cache and similar. It seems like a lot of links on http://common-lisp.net/ now 404. etc. It really is unfortunate. I hope to build a sort of archive.org-specifically-for-Lisp-related-content soon.
Given his location (Washington DC area) it wouldn't surprise me if he works in an arm of the Government that is cleaning out a closet that hasn't been opened in 25 years and found the doc sets for a bunch of Lisp Machines. It says in the listing that he has two sets and is selling one.
Erik Naggum's set is still for sale.
Damn. His set was once mine, now I might feel I should buy it back.
My friend actually designed this with myself providing the artistic direction. My coworkers are generally unfamiliar with functional programming and joke about me being a idealogical leader for the cause of converting everyone over to Lisp. This inspired me to go with a Soviet propaganda theme. Glad people like it =)
I love Lisp, and functional programming has its benefits (and limitations), but Lisp comprises a family of programmable multi-paradigm programming languages. Apart from maybe the fact that Common Lisp has a standard that people feel has ossified it, I don't see how there's anything particularly Soviet about it.
So CDR-2 is, I think, really cool. It answers a need I have time and time again. Therefore - I dug up genhash's source (it appeared to be disappearing quickly from the Internet), and placed it on my Github: https://github.com/pnathan/genhash . The license is public domain. A half-done project I have is an implementation of each type: https://github.com/pnathan/implemented-genhashes . At some point I'll finish it up. 
I don't see what the design has to do with functional programming. If one replaced "functional" and the lambda with something else, it could be a poster for a claim about something else being the right way.
Is it for sale anywhere? :) (Or failing that, a higher res version suitable for printing?)
It's not that soviet propaganda actually won over the people's hearts and minds. Here in Germany this was how much of propaganda art looked like in East Germany before the fall of wall. Within days after the 9th November of 1989 this art fell out of fashion, together with what it promoted...
Common Lisp has often been described as an anarchist utopia, to contrast it with benevolent dictatorships(a term used for absolute monarchs), so maybe "very early revolutionary Russian" is more accurate than "soviet", since this poster is inspired by early soviet constructivism, I guess it's more or less accurate :) PS People who know about art or soviet history, feel free to correct me if I'm wrong.
Common Lisp is a product of the military-industrial complex in the cold war as a weapon **against** the soviet union. Funding and the initiative for developing the Common Lisp standard came from DARPA (the Defense Advanced Research Projects Agency). The biggest dreams were fueled by Ronald Reagan's 'Star Wars' project, where Lisp-based AI systems were supposed to be an enabler for laser weapons in space. Other projects were planning systems for the army, training simulators for the army and intelligent assistance for jet fighter pilots. Example: the DARPA funded Lisp Chip, thought to be embedded in smart weapons. http://articles.chicagotribune.com/1987-03-16/business/8701200892_1_texas-instruments-artificial-intelligence-list-processing Consequently with the end of the cold war, the funding for Lisp-based systems collapsed. Thus Common Lisp was actually a model of what collaborative research in a capitalistic (and 'free') society can achieve against a authoritarian system. Anarchism was not part of it. Background here: http://monoskop.org/images/d/d4/Roland_Alex_Shiman_Philip_Strategic_Computing_DARPA_and_the_Quest_for_Machine_Intelligence_1983-1993.pdf 
It's quite annoying that everyone thinks Lisp is "functional", though. Most people don't even know what functional means and it seems to be used as if it were a synonym for "esoteric".
This seriously lacks some [mise en abyme](http://upload.wikimedia.org/wikipedia/en/thumb/4/4d/Knights_of_the_Lambda_Calculus.svg/390px-Knights_of_the_Lambda_Calculus.svg.png)
I think that posters of this style were quite passé by 1989, if not much earlier. At least posters in Czechoslovakia and Hungary that I have seen were much more graphically innovative: pop art started trickling in by the late 1960s, the secessionist style was enjoying a revival, and the typography was innovative.
Great! [Similar](http://www.eecs.northwestern.edu/~robby/logos/steal-your-face-plt.jpg), maybe racket-ish....
SED Parteitag 1986 http://www.fr-online.de/image/view/4472396,2482592,dmFlashTeaserRes,Parteitag+%2528media_965879%2529.jpg Viele Motive feierten den technischen Fortschritt, insbesondere in der Raumfahrt. Werktätige wurden heroisch dargestellt. Etc. Die Bevölkerung war da allerdings schon nicht mehr so begeistert. The German communist graphical propaganda was not really that advanced... 
finally documented extensible sequences. maybe i'll use them now. edit: http://www.sbcl.org/manual/index.html#Extensible-Sequences
I have a PDF of a scanned copy from 1980...
Christophe Rhodes's ILC paper [User-extensible sequences in Common Lisp](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.65.1604) documents the feature and has been freely available since 2007.
&gt; I don't see what the design has to do with functional programming. If one replaced "functional" and the lambda with something else, it could be a poster for a claim about something else being the right way. Of course, reusing a visually identifiable visual style was certainly a conscious choice of the people that made this poster. It is a very light modification of [this artwork](http://julietburtonillustration.blogspot.com/2010/06/designing-for-science-fiction.html) (I would even suspect plagiarism, given the lack of attribution), which is itself closely inspired from a [classic soviet propaganda image](https://www.google.com/search?q=НАРОД+И+АРМИЯ+ЕДИНЫ), and is immediately recognizable as belonging to the visual style of socialist propaganda art. It is a form of humor, if you will.
yes, I am well aware of the pdf which I found. But the source nor sbcl.org had any reference to the pdf. SBCL manual had no references to user extensible sequences and the source code was almost totally undocumented.
It's also notable that most implementations provide support for custom hash table tests. When I've used them I've used the implementation specific interfaces, but it also seems that cl-custom-hash-tables exists as a compatibility layer over them, whereas from looking at the genhash reference implementation, it seems to implement its own hash tables. 
Bluntly, while I applaud the effort of the cl-custom-hash-tables author, I believe it's more appropriate to code towards the CDRs when possible. I have a real thing for using standards when possible. I will quite possibly link in the cl-custom-hash-tables code for implemented-genhashes sometime when I find myself in need of some more hash-tabling than I need right now.
Cool. Sorry can't resist the temptation to micro-optimize: (defun ip-range (start-integer-string end-integer-string) "Transform a couple of integers to an IP4R ip range notation." (declare (optimize speed) (type string start-integer-string end-integer-string)) (flet ((integer-to-ip (int) "see http://dev.maxmind.com/geoip/legacy/csv/" (declare (type (unsigned-byte 32) int)) (loop for p from 24 downto 0 by 8 collect (ldb (byte 8 p) int)))) (let ((*print-pretty* nil) (ip-start (integer-to-ip (parse-integer start-integer-string))) (ip-end (integer-to-ip (parse-integer end-integer-string)))) (format nil "~{~A~^.~}-~{~A~^.~}" ip-start ip-end)))) This version shaves &gt;40% off the runtime (SBCL x64). Edit: changed fixnum to (unsigned-byte 32), thanks to pkhuong for noticing. In case anyone is interested, stassats has versions that are ~100x faster, using table lookup and other cool tricks [here](http://paste.lisp.org/display/139246).
That code better be running on a 64 bit machine. There is no guarantee that fixnums are wide enough to hold 32 bit unsigned values. Fusing the format loop and `integer-to-ip` will likely help a lot, if that's not already good enough.
Ah, to feel like a smug lisp weenie once again.
https://github.com/fare/lisp-interface-library/commit/3b55871b4a0cfa94f903447db5fb64b49c7ccb3f
(defun multiply (lis x) (mapcar #'(lambda (n) (* n x)) lis))
&gt;(setf *list* (* x number)) Okay, do you see what you're doing here? You're setting the list to be a number (the reason that the dolist finishes without an error is because it copies the *list*). So what you want to do is append the number to the list instead, like this: (setf *list* (append (* x number) *list*))
1) it is hard to beat the mapcar, since that does what you are supposed to do 2) Fixing your dolist ;; you don't want to change *list*, instead change a new temp variable ;; you need to collect the result 1 by one, check push or append ;; you need to return a result from your function, e.g as the third agrument to do-list 3) Pass *list* as a variable - with a different name - to the function, don't use the global definition 
I am curious as to what is this bug bug fix: (setf . a) is pprinted correctly (reported by Douglas Katzman). Searching on doesn't https://bugs.launchpad.net/sbcl/+bugs I couldn't find a bug report on that subject
I don't know why you were downvoted, this actually worked. Of course I changed the variables to be consistent with my program and made a temp list so I wouldn't edit the original. Thanks for the help! 
At a guess I'd say because it's an answer without explanation. It's a good answer but you won't learn anything if you don't figure out why it works.
I shit thee not, Symbolics machines [remain in use](http://www.usaspending.gov/search?form_fields=%7B%22recipient_name%22%3A%22symbolics+%22%2C%22recip_state%22%3Anull%2C%22recip_congdist%22%3Anull%2C%22recip_country%22%3Anull%2C%22recipient_duns%22%3A%5B%22966978090%22%2C%22873185821%22%5D%2C%22spending_cat%22%3Anull%2C%22dept%22%3Anull%2C%22extent_competed%22%3Anull%2C%22psc_code%22%3Anull%2C%22naics_code%22%3Anull%2C%22fyear%22%3Anull%7D&amp;sort_by=date&amp;per_page=25) at various government labs.
That is probably why! I don't fully know why it works, but the gigamonkeys book also uses mapcar for basically this exact purpose. I did have to change a couple of things from OPs suggestion. Could you break down why it is that this work, and more specifically, what the "n" parameter is? I think it would have to be the value in the current cell of the list. With x being what it is multiplied by. 
It was reported to sbcl-devel on August 29th.
DOLIST does not copy the list. (setf \*list\* ...) doesn't cause an error because that doesn't change the list; it sets the binding of \*list\* to the new value (a number, in the OP's code) without mutating the old value (the list that DOLIST is iterating over). You are mutating the binding, not the object that the binding pointed at.
True. Ty.
Mapcar takes 1 + N parameters: The first one is an n-argument function that will be applied to each element of the lists passed as the N following parameters. Some examples: (mapcar (lambda (n) (+ 1 n)) '(1 2 3)) ; (2 3 4) applies `(+ 1 n)` to each element of the list. (mapcar #'+ (list 1 2 3) (list 2 3 4)) ; (3 5 7) applies `+` to each pair of elements (that is, `(+ 2 3)`, `(+ 3 5)` and so on).
Since your program runs on a physical machine, it can be mapped to machine instructions. So in any other language that can be mapped to those instructions too you should be able to implement that algorithm. 
Ah. I needed an excuse to stay up late hunched over a computer. Thanks.
Just a few corrections/notes: `(append ...)` works only with list values: (append '(1 2 3) '(4 5 6)) =&gt; '(1 2 3 4 5 6) (append 4 '(1 2 3)) ; ERROR!! `(dolist ...)` always returns `nil` (empty list/false). It looks like you already got advice on using `mapcar`, which iterates every element in a list, runs the given function on that element, and collects the return result from each function call into a new list. You can also do something similar with the `loop` macro (but loop is a whole nother rabbit hole): (loop for x in '(1 2 3) for y = (* x 3) collect y) =&gt; '(3 6 9) 
Great! Thanks to both of you!
Awesome! I didn't know LW and ACL are that good... Btw. is it possible to get some average values for all tests (with some graphs maybe)? Also, CLISP is good with bignums; maybe because of gmp?
CLISP does not use GMP.
On a sort of related note, http://musicforprogramming.net/
I noticed that all the x86 benchmarks are on OS X. Would there be any reason to expect different results on Linux and/or Windows, or do these generalize to other OSs running on the same CPU?
Bruno Haible, one of the authors of CLISP, uses a library he wrote that is similar to GMP called CLN: the Class Library for Numbers. It is written in C++ I believe, and is written to be fast for number theoretic computations.
Is the link broken?
does this work well on Linux too?
puredata is a graphical data-flow programming language used mainly for audio/music applications. You have boxes (called objects) connected with cables and objects have input on top and output on the bottom. On the wires you can pass numbers, symbols, lists or audio-stream. This should be an object that lets you process input data and output data with a common lisp script.
There might be differences depending on how the GC is implemented (handling sigsegv is really slow on OS X, compared to Linux).
Oh wow. I had been thinking about this kind of thing for a long time. Thanks! Can't wait to try it out.
Or the site is down.
Thanks, now it's clear (and quite interesting). It would greatly benefit this project's findability to include this kind of description in README.md
It seems that you define the test package in the cl-cidr-notation system, which does not depend on lisp-unit, so gives an error when loaded. There's still a lot of opportunity to make this code go faster. Some general advice that seems relevant after skimming the code: avoid key parameters, avoid consing, avoid branches, avoid memory lookup, and avoid LDB. Allow a user of your library to avoid them without the knowledge of internal functions. After avoiding all those things, consider avoiding safety 0 as well.
Insanely old version of ACL, though (6.2, 9.0 is current version). Actually, looks like all the versions in the table with ACL are old. Hmmm.
Avoiding LDB? And why is that? And lookup tables is the fastest way, though not portably: http://paste.lisp.org/display/139246#8
Looks good mostly, but heads up random returns 0&lt;=ran&lt;n not 0&lt;=ran&lt;=n. Another useful way to see a list of related functions is that (almost every) chapter of the CLHS ends with a dictionary section. So by browsing starting in the chapter index then entering to the respective dictionary sections you can sometimes use the full reference as its own quick reference. 
I'd advise against including such SBCL specific functions, since SBCL may decide to change its memory layout or some other thing.
link?
Booyah bitches! With this document in my trembling hands, nothing can stop me now. You hear me, world? NOTHING!! #unlimitedpower #amiganuts
 (cons form1 form2) ;; Can use '(form1 . form2) too NOOOOOOOOO!
Yeah, I know that it's possible to do it in any language, but while my code in clojure is quite trivial, I suspect it would be much more complicated in a language that doesn't have the lisp syntax.
Really cool visualization. Makes you appreciate how much goes into a project like SBCL. What visualization tool is this?
I like stuff like this since I learn new functions just by glancing over it. Never knew about `substitute`.
Returning a string is the purpose of this function, and you can't do that without consing. The fastest iterative version is twice as slow.
http://xach.livejournal.com/257931.html
So you mean that you cons at compilation or what? I mean, you can obviously just call the function with a string of a specific length once then, right? Cuz otherwise you'll get corrupt data.
[Clojure vs SBCL vs Common Lisp Google Trend](http://www.google.com.au/trends/explore?q=clojure%2Csbcl#q=clojure%2C%20sbcl%2C%20common%20lisp&amp;cmpt=q). 
Sounds good to me. I thought it was not portable in the sense that it uses SBCL specific code, as opposed to not portable between SBCLs. 
The load time issues have been resolved, thanks again
sold for $298
I did the benchmarking for those in 2003 for a talk at the International Lisp Conference.
So it appears that Clojure didn't harmed CL that much, but it severely injured SBCL. Very interesting. 
No classes?
Do you read hacker News? This was posted yesterday or so. "Archiving URLs" https://news.ycombinator.com/item?id=6504331 I haven't taken a look yet but there may be some good content in the article or comments. (At the very least, while skimming the comments, it looked like several tools were mentioned...)
I actually did read it when it was posted and found it immensely useful. I was unaware that people could submit their own archives to the Internet Archive before reading that. I did not see any that were a silver bullet; gwern seems to implement a multitude of redundant solutions to try and avoid link rot. The situation is much more precarious than I had even realized though. I thought the point made that no one **owns** a domain, merely rents it contributes to link rot was good. There are a lot of confounding factors involved. Gwern's article and responses were good, I highly recommend someone giving it a read if knowledge preservation is something that matters to that person.
This is really unfortunate. I kind of suspected something was going on because I'd report a bug, it was confirmed, and would then just sit there for months untouched. I really like the idea behind ECL, as it gives CL a lot of targets that it wouldn't normally have (basically, anywhere with a C compiler and a few megs of ram). It's shown to be portable to a lot of places. I wish I had the knowledge of C to step in and help. I do know a bit of C, but most likely not enough to actually build/maintain something like ECL. Also, what's the deal with the licensing? Is it different than other implementations because it compiles down to C? And if someone "owns" a project, shouldn't changing the license be as simple as just picking a viable one and slapping it in? Forgive me if these questions sound ignorant. Anyway, I hope ECL finds its way to a successful future. 
Even more regarding the license, the LGPLv3 (the license used by MPIR which Juanjo wants to use) is incompatible with the LGPLv2 (the license that Juanjo wants to use for ECL). This means that he would have to stop using MPIR or change the license (or stop distributing ECL (or risk a lawsuit)). I am not familiar with the intricacies of the LGPLv3, so I am not sure what the problem is. Edit: Actually, this licensing stuff is confusing. The point of the LGPL is that it is not "viral", so why does it matter what license MPIR/GMP uses since all you are doing is linking against it? That said, the GNU license page clearly states that LGPLv2 is not compatible with LGPLv3...? I can only assume that this only apply to mixing contributions within one project, i.e. you cannot have a single code base that mixes LGPLv2 code with LGPLv3 code, which shouldn't bother this project.
Do you mind if I ask why you were using ECL? Or what led you to report a bug?
Is [ManKai Common Lisp](http://common-lisp.net/project/mkcl) (forked from ECL some time back) a useful and maintained replacement?
MKCL is definitely maintained. Its latest bug fix release (1.1.6) dates from 3 weeks ago. I would even say that it is in rapid and heavy development with a whole set of major elements to be released for 1.2.0 in a few months (I still plan to get 1.2.0 out before the end of 2013 but it may slip a bit). Is it useful? I certainly think so but I may be considered somewhat partial in that department. :-) 
I was using ECL to test the performance of a 2D game engine I'm in the process of building. I was testing on Windows, and calling out to OpenGL via CFFI, however ECL was ignoring the `defcfun` declarations for `:cdecl`/`:stdcall`, causing all kinds of segfaults. So the bug wasn't with ECL's spec implementation, but more its FFI (which I feel is essential). Overall, I generally don't use ECL unless I'm testing a library or app and want to hit as many targets as possible. From what I remember, I had a few other issues here and there where ECL just wouldn't run what CCL/SBCL would (something to do with sockets/slime/windows if I remember correctly) so I little by little just started ignoring it more.
Ok, this makes more sense. I hadn't even thought about code ownership and contributions. Thanks for explaining. 
This is a pity, since ECL is my favourite CL implementation, but let's hope for the best. I remember when Peter Graves stepped out of ABCL stewardship, and a new group of contributors gathered around ABCL and made it thrieve. Hope the same will happen with ECL. Or not. Junajo is a great guy and was steering ECL quite good, but the lack of community support was evident for a long time. Maybe cutting the fat from ECL is a good idea, after all. If there is "C mode" for numeric operations, just use it and ditch both GMP, MPIR, FSF and its nonsense, ditch non threaded builds, ditch all bundled libraries. Go back to the root and provide only a small cleaned up core ready to be built upon. Sounds like a plan. Who's up for it?
Awesome, thank you for the links.
I'd be up for it, but have no idea where to start. And I don't think I actually have the necessary skills and/or time. I like the idea though.
Someone asked about [Andrew Topping](http://fultonhistory.com/Newspaper%2011/Geneva%20NY%20Finger%20Lake%20Times/Geneva%20NY%20Finger%20Lake%20Times%201982%20Apr%201982/Geneva%20NY%20Finger%20Lake%20Times%201982%20Apr%201982%20-%200219.pdf) few months ago. 
Agree with you; I'm also interested in small core, configurable in compile time. That is the main reason why I still use/maintain a couple of TinyScheme installations: with a couple of #ifdefs, I can disable/enable math or module or else features. I'm also interested (not sure how hard would be to do it) in providing multiple different backends; AFAIK ECL now can execute bytecode and generate C code. How about adding LLVM or javascript? Something like clojurescript guys are doing... Anyone tried this?
Does the C mode have bigints, or are we talking about something that is pretty radically different from the standard CL numerical stack (i.e. something like the C numerical facilities)?
Wow.
Is this the same as the [refcard in the SLIME repository](https://github.com/antifuchs/slime/blob/master/doc/slime-refcard.pdf?raw=true)?
Looks like it.
* automagical [playlist for videos in this post](http://radd.it/r/lisp/comments/1o20q2?only=video) *^Downvote ^if ^unwanted. ^Comment ^will ^be ^removed ^if ^score ^is ^0.* [^Message ^/u/radd_it](/message/compose/?to=radd_it&amp;subject=Please Blacklist&amp;message=Good sir, I appreciate your efforts but do not require automagical playlists. Please add me to your bots blacklist.) ^to ^never ^receive ^comments ^from ^this ^bot.
I notice that there is nothing about using the debugger, and that info is hard to find. Basically, my working knowledge (which is lacking and possibly wrong) on this is: 1. Always compile what you want to debug with debug at 3 and (possibly) speed at 0 2. Insert a (break) in your function where you want to examine things and recompile (this is the equivalent of a break-point in a "normal" debugger) 3. Step into via 's', step over with 'x', step out (like gdb finish) with 'o', continue with 'c' (though this doesn't seem to work with SBCL while stepping right now), or you can invoke the restarts by hand in the debugger 4. You can examine any variables that your Lisp hasn't elided (optimized away) by moving to the stack backtrace and pressing enter (or 't'). The real question is what are the capabilities for examining data in the frame? There is 'e' to eval-in-frame, but it seems that SBCL (at least) elides certain variables and leaves you nothing to eval/examine. Also, super annoying, is there a way to get it to print the result of each form during stepping? Sometimes SBCL will tell me "evaluating with so and so args" more or just as often it will say that the args are unknown. I would love to see some tutorials about how to use this, in fact, if I can get enough information, I would be happy to make such a tutorial myself, but I don't know enough yet and what I do know, I'm not sure that it is the proper way to do it.
I've looked this project up from time to time, but am still not able to figure out how it differs from ECL. It most certainly seems more relevant now with ECL's troubles, but can you give a very basic rundown? - Are you going for more platforms that ECL doesn't reach, or are there specific platforms you intend to focus on (Windows, for example)? Does this mean support for other platforms will fall to the wayside? - What problems did you find with ECL that prompted you to fork? Was this a technical limitation (ie, you wanted to change the core of how things worked) or a community one (patches ignored, etc)? - Do you have any kind of plan/milestones shared anywhere? "a whole set of major elements" is somewhat vague. I'd love to know more! I'd really love a simple website explaining what you're accomplishing, or even just update the common-lisp.net page. It's been a few years since your announcement, a bit of literature/documentation would be nice.
That's amazing, I wish you'd have more success into running it. If you have online references, or anything related, I set up /r/nichimen a while ago, feel free to post.
Many of us old timers, saw with sadness UNIX, CLI and C take over the enterprise world, when there were already quite powerful GUI systems in the early 80's. For many reasons that would be enough to write an essay, those technologies didn't had as much success, as such, many developers are nowadays rediscovering lost concepts. A remarkcalbel way to see it, is to watch the Bret Vitor's talk, [The future of programming"](http://vimeo.com/71278954), where we pretends to be in the 70's doing a talk how computing will look like in the 21st century.
Well you see, there is in this neighborhood a clique that is ready to resort to [grotesque insults](https://groups.google.com/d/msg/comp.lang.lisp/cuQbgKmBwm0/UlyEX6F8674J) and other forms of intimidation in order to keep control of their surroundings. This makes such that I am not very much motivated to share ahead of time any more information than really required and that I am (excessively?) prudent in front of anything that looks like a flame bait. There are real reasons for having forked MKCL away from ECL but this is as far as I care to disclose them at this moment. Some things are best kept for the history books (to be published well after the events) and some other things are best simply forgotten entirely. I have kept careful records of it all, and it is my privilege to decide if and when to make them public. In the meantime there is some information to be found in the successive MKCL release announcements: - at the bottom of the [original MKCL 1.0.0 announcement](https://groups.google.com/d/msg/comp.lang.lisp/cuQbgKmBwm0/S7wgsqJP32AJ) - in the [MKCL 1.1.0 RC1 announcement](https://groups.google.com/d/msg/comp.lang.lisp/oKZiceNDKOQ/krtDPLPace4J) It is terse, I agree, but substantial. For the rest you have to read the source code. BTW, to say that "Read The Source Code" is not an acceptable statement (as some have done) does not sit well with me. In fact it is probably one of the fastest way to antagonize me very seriously. I don't publish my code as Open Source to have it NOT read. A world where Open Source projects would be published for their source code to be read by next to no one looks to me as a kind of Kafkaesque nightmare pastiche. 
That talk is great! answers many of the questions that I had about mediocre technology taking over the world.
Thank you for your responses. Personally, I tend to shy away from projects that don't provide good documentation. I can see your point of view though...you obviously had your reasons for forking ECL, and received a backlash for doing so for reasons I do not understand either out of ignorance or out of not understanding the technical details behind your approaches (to which I make no judgements). However, reading the source code is not an option for me. I wish it was. If I could read/understand the ECL/MKCL source code, I probably would have jumped in and started helping out long ago. Truth is, I'm a lot better at lisp than C, for better or for worse. I could probably muddle through the source and gain a fair understanding given a few weeks of close study, but I just don't have the time nor inclination. This is where docs come in =]. I'd say that for each 100 users of my libraries, 10 of them read the code, 5 of those who read it put in the effort to understand it, and 1-2 of those 5 actually contribute. If I didn't document what I do, my code would probably see 5-10% of the use it does, and see no contributions. I'm not telling you how to run your project at all, but I'm speculating that if you put a bit more effort into showing the world what you're doing, your efforts would be much more appreciated. After all, if you're building an open-source project, the idea is to not only build something people can understand if they put in the time, but also attract contributors to make your life easier. In a sense, you're selling your project, your time, and your work to people who will either use it and provide feedback or be impressed enough to help you build it. Otherwise, why open source it at all? In the end, who cares what a handful of dicks on CLL think? The place is a wasteland.
"We wanted to develop a superior software substrate" [[1:30](http://www.youtube.com/watch?v=-K01FQ73xgY&amp;feature=youtu.be?01m20s)] I've always wondered why Lisp machines never really caught on. Now I know. Edit: That came off snarkier than intended; I apologize. This isn't negate the historical appreciation I have for the device, or even (especially not!) the fantastically strange marketing style that was in vogue at the time. Thanks OP for sharing.
Yeah, Genera 7 was supposed to be superior to Release 6 and 5.
This answer still doesn't answer the **why** part of the question. It's fine that you don't want to disclose the reasons to fork ECL, but it's also hard for me to believe in your project when the motivation part is missing. I don't remember you from the ECL mailing list, apart from the MKCL announcement. What led you to not even try to improve ECL? Is it that hard for you to work together with someone else? Is it a problems that you are not ECL project lead? Did you have a conflict with Juanjo, which is hard for me to believe given my experience in interacting with him? Given I don't know your motives, and by the sound of your answers here and on other mailing lists, I guess if Juan couldn't gather a big support for ECL, it would be even harder with you and MKCL. I'll just keep keeping an eye on ECL, maybe submit a patch here and there, and avoid software written by someone whose motives are not clear to me.
The spiritual successor of Mirai is [wings3d](http://www.wings3d.com/), which is open source and written in Erlang.
Though it only does a fraction of what Mirai does. wings3d is 'only' a modeller. 
What would it take to recreate this experience on modern computers? (excluding emulation)
* a really stable 64bit Lisp development which is able to stay up during development for days, weeks, months. * an excellent and stable FFI * an excellent GUI toolkit * many man years of Lisp and domain experts * money, lots At its height Symbolics had a thousand employees (IIRC) and revenue of $100 Million. 
Holy canoly. What don't you know about? I have never met a programmer before that actually knows what 3d software does. Actualy I met one Alias programmer once, but that is an aside.
However, can you imagine having that environment available in the 80s? Wow. We still have not caught up to most of the ideas in those videos. We just keep on re-inventing the lowest hanging fruit over and over again. Poorly.
How much woul one of these machines've cost at launch?
The original S-Geometry modeler from Symbolics was just one of several modules. Each was in the range of $25000. It had 2d paint, animation, rendering, ... plus 'geometry'. Mirai had extended versions of those.
Aha! I appreciate any clarification, thank you. Question for you: I have a rough understanding of the current availability of old lisp machines and the expense in buying one and maintaining one. What would REALLY be interesting is having a full suite of all of the Symbolics software available installed on a machine. Chances of that every happening would be ... zero to none? Or slightly better? Would anyone actually have the whole library of software or even a substantial part? It would be of interest, at minimum, from a historical and archival perspective. 
Sometimes there were machines available with the full suite of graphics software and the necessary hardware. But the machines were usually very large. I mean LARGE. Rare. There was little point to use them without the color graphics or even the accelerated color graphics. A basic machine was around $100k with upto $250k with a really extensive machine (XL1200 with accelerated color graphics, output to video recorders, lots of memory and disks, ...). A smaller, but also rare, was a MacIvory with the graphics suite. Since Symbolics sold a substantial amount of their high-end machines to the graphics industry, some still exist. But generally they are very rare.
If you look at that video, it was more of video letter to existing customers who know the product.
It seem like every declarative build language devolves into an imperative build language.
An example in 1990: &gt; The XL400 High-Definition ColorStation, which includes the FT100, a high-resolution monochrome monitor and the color graphics software library is available for $58,800 (U.S.). That was a good price. From there it goes up. With the color graphics software alone you couldn't do much. It was basically the Lisp library to talk to the color hardware. The 2d/3d graphics software itself was extra. The high-res color monitor was also extra. As all the other stuff you would need: larger disks, more memory, ... 
make itself is still declarative. The actions have always been imperative.
True. It's been so long.
Make is terrible.
Do you think the Genera 7 could have gone the way of the IIe with different marketing practices though? I did a quick Google search for "Symbolics commercials" to see if they had an answer to Apple's [1984 commercial](http://www.youtube.com/watch?v=R706isyDrqI), and nothing came up.
Symbolics did not serve a mass market, home user market, or similar. Completely different audience. A Symbolics was a highest-end workstation for AI, CAD, Graphics, costing tens of thousands dollars - often $100k and more. An Apple II or a Mac was a tiny machine compared to that. Apple came 1984 with a Mac using a 68000 processor. Symbolics already used the 68000 just as a boot processor and to talk to some hardware. The 3600 Lisp Machine models used a 68000 as the front end processor. The real Lisp processsor then was a couple of huge boards. Symbolics had a lot of press during the AI boom, but only few people had the money to buy such a machine. Most users were universities, government labs (SRI, MIT, NASA, ...), military and industrial users. There was no reason to make a 1984 commercial, because nobody in the audience would be able to afford such a machine in the forseeable future. In 1984 there was no affordable hardware which was needed. Do you now what a disk with just 100MB cost in 1984? 8 MB of special purpose RAM? A ethernet network card? High-res graphics monitor? B&amp;W or Color? Over time they developed smaller and cheaper machines - but still $20k for anything 'entry level'. Still the market was limited, prices were high and there was no idea/chance to develop a cheap mass market workstation or even a mass market personal computer. There were discussions to bring the software to standard hardware - but for Genera it was first tried with Open Genera on a DEC Alpha. Which itself was an expensive and rare computer, but the first viable 64bit processor workstation. Something which was needed - there was thought that 32bit machines could not run Genera in a useful way. The Symbolics machines were already 40bit machines.
Make is actually pretty good. The problems come from thinking that build systems should be easy and also wanting to solve the general case at the same time. 
I'm no lispm, but: * [mentions cpu arch a few times](http://pt.withington.org/publications/LispM.html) * [Lambda: The Ultimate Opcode](http://dspace.mit.edu/handle/1721.1/5731) (warning: I hear the Scheme processor has little to do with the Lisp processors) * http://www.cs.utah.edu/~mflatt/past-courses/cs6510/public_html/lispm.pdf * http://fare.tunes.org/tmp/emergent/kmachine.htm * http://www.unlambda.com/cadr/ (contains Verilog for a CADR processor, and I think somewhere in there links to more accessible documentation) Once upon a time, I found a few references to papers on actual internals of the Symbolics and LMI architectures, but they were all behind either ACM or [IEEE paywalls](http://citeseer.uark.edu:8080/citeseerx/showciting;jsessionid=669F0183DBF59670B6939B48BF51EFAC?cid=2544782) &gt;:O 
http://git.hcoop.net/?p=bpt/emacs.git;a=summary a few weeks out of date, but Guile Emacs can boot itself now, without the Emacs Lisp interpreter (instead using exclusively the Emacs-Lisp compiler for Guile's VM). Of course, you still need that pesky POSIX system under it all, but maybe one day...
Generally this is a good overview about the state (software + hardware) of the Symbolics 3600 in 1983: http://www.textfiles.com/bitsavers/pdf/symbolics/3600technicalSummary_Feb83.pdf
It solves a problem in an OK manner but it's slow without hacks.
I'm looking forward to reading these. Thanks!
Depends what you mean by "hacks". For example, non-recursive Makefiles are pretty much the opposite of a hack and make speed issues much less likely.
Also: http://www.textfiles.com/bitsavers/pdf/symbolics/ (the motherlode!)
I don't know. Make is pretty good. And really not too hard! What I think a lot of people do is conflate Make with Autotools (and I'm not implying you're doing this, I frankly have no idea what you think!) Autotools brings magical things like Makefile.am, configure.ac, autoheader, libtool, etc into the fold. Make doesn't know or frankly give a shit about any of that stuff. It just executes makefiles. It's not Make's fault that autotools generated makefiles are hairy lumpen monsters feeding on the shores of the river of the damned. I think Autotools gets a bad rap too (mostly because practically noone knows what the fuck M4 really is) but that's not really germane to Make. So grats Make devs! I think it's about time the Official GNU Project Extension Language Guile&lt;tm&gt; had basic support in your own build tools!
Make is like lisp: it's a fine thing, but it tends to be used in a terrible way which gives it an unduly bad reputation - in make's case that means both having to run builds for bad programs written in really awful languages with terrible compilation semantics, and having the build infrastructure itself be badly written. (I used to say the same about Java, but I think it probably now really is a terrible system: I don't think it was originally but the layers of cruft have destroyed it.)
Well, I still didn't get answer to questions `why fork?` and `what are your motives?`. Seems like my "tongue in cheek" approach didn't help. Yes, you have some successful contributions. As you can see, they are accepted into source tree. What is the problem then? Why fork if you can contribute? Is the problem that you are not in control/leading role? Sorry that you feel intimidated by my questions. I just tried the classic `linux sucks because you can't do ...` instead of `how to do ... in linux` approach, but you were clever and consistent enough not to provide a fork justification either way ;) Have a good day and best of luck with your fork, but I won't be using it given you couldn't answer a simple `why fork instead to collaborate?` question.
http://www.lassila.org/blog/archive/2012/04/time_to_revisit.html http://www.lassila.org/blog/archive/2012/04/time_to_revisit_1.html 
Yea, if you're trying to write portable makefiles by hand it's just a bad scene. It wants to be a good idea, but at the moment it's up there with writing portable Scheme libraries.
Because it's not fun to balance them manually and there are a lot of advantages to having a structural editor. There's a reason paredit is so popular. With paredit you already have a similar workflow, this is just a different visual representation of the same thing.
OPs link is not opening on my network. [This](http://www.scirp.org/journal/PaperDownload.aspx?paperID=35599) Seems to be the same article from somewhere else. OP, can you confirm, please?
Yes. http://www.scirp.org/journal/PaperDownload.aspx?paperID=35599
Wait, and I just finished a phd on the topic of quantum computing where I extensively used Lisp. *looks over his shoulder* *checks for cameras*
 &gt;*generalized boolean* n. an object used as a truth value, where all objects represent superposition of two-state system. See [two-state system](https://en.wikipedia.org/wiki/Two-state_quantum_system). source: http://www.dwavesys.com/documentation/HyperSpec/Body/26_glo_g.htm#generalized_boolean 
hey, do you have a freely available PDF of your dissertation? inquiring mind(s) want to know.
Take is with a grain of salt, but it seems to me that jobs for X coders where X is a popular language are more "language jockey" jobs (like doing java CRUD apps), while the more exotic languages are more mathematically oriented, or domain specific oriented, like this job offer.
newt0311: So I don't want to rain on your parade too much, but how is Kernel not a lisp? OP: Kernel supplies fexprs, along with a theoretical analysis of fexpress called by Shutt as the vau-calculus. fexprs are essentially *run-time* macros, as opposed to Common Lisp and Scheme's *compile-time* macros. Note that originally, fexprs were the usual approach to macros, but they were generally dismissed in popularity due to some complexities with lexical and dynamic scope. There are several publically available papers describing why this choice was made around 1980 during the development of Scheme and Common Lisp. 
I consider myself to be doing quantum computing any time my boss isn't looking at me. In these moments I may or may not actually be doing any computing.
For macros you should go with Racket. Pretty much for anything you should probably go with Racket, actually... But definitely for macros.
I'd recommend Common Lisp and the following two books: * 'Common Lisp: A Gentle Introduction to Symbolic Computation' It is a basic introduction. http://www.cs.cmu.edu/~dst/LispBook/ * 'On Lisp' Explains macros. http://www.paulgraham.com/onlisp.html Both books can be downloaded as PDF. Since there is a lot Common Lisp code using all kinds of macros, there are a lot of real examples to study then. 
I just tried to view the Cliki page for SWCLOS, unsuccessfully. How long has cliki.net been down? [Here's Google's cached copy](http://webcache.googleusercontent.com/search?q=cache:7wwrjI_ygX8J:www.cliki.net/swclos+&amp;cd=1&amp;hl=en&amp;ct=clnk&amp;gl=us), but there isn't much information there. This may be a good intro: http://iswc2004.semanticweb.org/demos/32/
Add another vote for Common Lisp
Well, he said only that &gt; it is not _quite_ a lisp. (The emphasis is mine.) He just wanted to emphasize the next sentence after the colon: &gt; it is (a) better (lisp). Also, your note &gt; fexprs were the usual approach to macros seems not quite accurate. According to the survey paper [Special Forms in Lisp](http://www.nhplace.com/kent/Papers/Special-Forms.html) by Kent Pitman, MACROS and FEXPRS were parallel.
Not to forget: http://letoverlambda.com/
While the opportunity may sound enticing, you might want to think twice before dropping into a software engineering environment. Presumably you're interested in, well, quantum computing and research, not stuff like maintaining servers/code, and being ordered to add some new feature to some software system. Of course I might be wrong, but with a PhD, it seems you'd be better off doing R&amp;D than measly software dev. Just my two cents.
Actually, exotic stuff is often done in a "normal" language like C, C++, and Java because they're performant, well-documented, portable, and ubiquitous.
Indeed, not to mention the controversy around D-wave. I still don't know what to think about the company. But at least it will be in lisp! :p
I think fexprs make efficient compilation to machine code especially difficult. Because the arguments are not evaluated prior to being passed in, their types are unknown to the compiler, which often makes the type of return values unknown. Thus a simple type inferring compiler is stumped and otherwise normal functions might not be optimized for types because they use the result of a fexpr. A modern JIT compiler could perhaps do a better job with them.
D-Wave seems kinda snake oily. But I applied anyways.
I learned from Winston and Horn. Hard to do better!
Try [Paren](http://jsutil.sourceforge.net/parenjs.html) 
Tinyscheme, which is a scripting language in GIMP (Script-Fu), has Common Lisp style macros. Tinyscheme is even smaller than R5RS Scheme. http://pasture.kerosenecow.net/archive/2011/11/Script_fu_Tinyscheme_Macros.html
Nice :) "Problem-Solving Methods In AI", is it good? Looks like there are some used copies on Amazon for 6$...
Doesn't look down to me: http://www.cliki.net/swclos
 I think this is right: the Lisps I first used (Standard Lisp family) had both fexprs and macros.
Prefix sexprs have the advantage that the first element of every non-quoted list is a function call. Adding infix operators throws that away. Is it worth the tradeoff versus readability for newcomers?
How would (destructuring-bind ((a b) c &amp;optional (d 1)) expression ...) look like in the proposed syntax? The [Examples](http://sourceforge.net/p/readable/wiki/Examples/) page only contains a single macro, and claims that the version with S-expressions is awkward, but I don't think that the proposed alternative version sprinkled with `!` and `\\` is going to win any beauty contests either.
The distribution comes with a lot of examples incl. use of several CL macros.
Using it with CLOS code looks a bit like the ill-fated later version of Dylan.
unreadable lisp you mean. &gt; I think I have a solution to the problem. Yes, the solution is: Use Lisp for longer than 2 weeks and you won't find sexpressions awkward anymore. Now crawl back to the ruby/python hellhole you came from.
Nevertheless it must be appreciated that they guy has put some considerable efforts to make this thing run and if it finds its niche users why not?
I don't want to sound rude. But I can't see point in that. Sexps are great. That syntax only complicates language.
You can mix both syntaxes together, so it *should* be worth it... in theory. What I don't like about readable (and I advocated it to other beginners, back when I was one, although I never used it myself) is that it makes macros harder to get. Homoiconicity becomes awkward. You represent the structure of the code in two different ways: sweet expressions for most of your code, but when you need to generate code, you resort to s-expressions, because creating macros with s-expressions is **easier**. So readable is aimed to beginners, but instead it makes more difficult to beginners to grasp the single most important aspect of Lisp, since it introduces two different representations for the same syntax. I'm sorry, but that's not worth it. S-expressions are clear enough, and the best way to attract beginners to Lisp is to explain *why* Lisp code is represented with s-expressions. I've been successful with some people on that, showing what some simple macros are capable of doing, and also how s-expressions help the editor to understand the structure of your code, which helps you with navigating and editing. I think everybody in this subreddit will agree that ParEdit is awesome - and nothing like it exists for Python-like syntax, and I'd say it is for a good reason: Python-like syntax is a bad representation of tree structures.
Readable Lisp is called Dylan.
Interestingly, The only thing I like in this is the simple version of "fully parenthesised" infix notation. I do think, though, that in a reader that recognizes more than lists (Like curly braces denote tuples, Square bracket denotes vectors...) It would fit well . What's you opinion on this? The place where this seems to fit for me is relational and arithmetic expressions. Although I like the power of Sexprs t always feels weird to write (&lt; x 10)... Ps:written in tablet struggling with autocorrect. Will revise later.
&gt; Although I like the power of Sexprs t always feels weird to write (&lt; x 10) Indeed it is, but it has the advantage of working as (&lt; x y z) instead of C-style x&lt;y &amp;&amp; y&lt;z. Although Python-style x&lt;y&lt;z is also nice.
Try reading &lt;,&lt;= and &gt;,&gt;= as 'is an ascending sequence' or 'is a descending sequence'. They are more succinct when you need to check more than 2 arguments. e.g. (&lt; 2 x 8) ; x within range exclusive. (&gt; x y z w) ; x,y,z,w form a descending sequence. ;; Maybe you need to check values not known in advance (apply #'&lt; (loop repeat 5 collecting (random 10))) compared to ((x &gt; 2) and (x &lt; 8)), etc...
M-expressions, anyone?
3rd post of this. The other two discussions: http://www.reddit.com/r/lisp/comments/1ebbd9/readable_library_for_common_lisp_now_avaiable/ http://www.reddit.com/r/lisp/comments/yoznm/readable_lisp_sexpressions_project/
You can't add infix without also adding a way to specify operator precedence for any function you call an operator. What is the order of operation here? (defun $$$ (x y) ...) (defun &amp;&amp;&amp; (x y) ...) ... ( a &amp;&amp;&amp; b $$$ c ) The answer is, you don't know.
If I do not like sexprs then I am the problem. 
Homoiconawhat?!
I think dismissing this completely is kind of harsh. I think most people who can recall being introduced to Lisp can remember how strange and unreadable code looked initially. Most other languages have broadly similar syntax, while Lisp has something completely unorthodox going on, which throws most people off initially. Eventually you get used to the syntax, realize it's actually a lot simpler than most, and you don't mind the parentheses any more than someone writing Java minds the semicolons. But that doesn't really help the beginner, who I could easily see dismissing the syntax as horribly awkward and giving up. Yes, there are numerous reasons why actual Lisp syntax is better once you get used to it. Think of this as an attempt at training wheels for people more used to traditional syntax. Maybe it's not perfect or even not that good, but surely we can agree there is a point to having these sorts of things?
I've created a similar [library](/r/lisp/comments/10lng8/cl2dsyntax_the_cure_for_parenthephobia/) some time ago. I agree, working in s-exprs is the right way, but sometimes I feel (when I turn off my filter of seeing parentheses) there are many parentheses in a *visual way* (not semantic). And gibbering about there is no way without s-exprs doesn't have a cogency because the indentation can be isomorphic to parentheses -- that's what I originally wanted to say by that library.
Wow, 27 comments and downvoted to oblivion. Some people on this sub-reddit need to grow up. If it's worthy of discussion, it's worthy not to be buried. See Reddiquette item: ["Downvote an otherwise acceptable post because you don't personally like it."](http://www.reddit.com/wiki/reddiquette)
To be fair, readable does not allow {a - b + c}, only {{a - b} + c}. {a + b + c} isn't a problem because it's the same operator, so there's no precedence.
What about having {X &lt; Y &lt;= Z} translating, somehow, to (and (&lt; x y) (&lt;= y z))?
[/r/python](http://www.reddit.com/r/python) and [/r/ruby](http://www.reddit.com/r/python) are infiltrating.
[/r/python](http://www.reddit.com/r/python) and [/r/ruby](http://www.reddit.com/r/python) are infiltrating.
Too much logic for my taste. It creates specific semantic to the usage of the the relational operators in "infix mode". What I was talking about was blindly performing the following transformation: {a op1 b op2 c op3 d} (op3 (op2 (op1 a b) c) d) Considering the idea that "anything that is not false is a truth value" one could then specialize the relational operators with simple mechanics. (op X false) = false; (op false X) = false; Edit: of course, one can argue that the specialization of relational operations on the input is, itself, a bad thing. It definitely makes for some weak typing I'm not entirely comfortable with. Though, one could think of it in terms of the Maybe Monad. Relational operators take N-Arity Maybe Number parameters. My real problem is the return value, though.
worst. idea. ever.
This seems to be a contrary opinion but I would argue that if you can handle Haskell and typed level programming then the exigencies of Scheme's macro system will be very little trouble for you. Contrary to some misinformation often propagated Scheme's `syntax-case` (or Racket's `syntax-parse`) are capable of anything you can do in Common Lisp and are better principled and cleaner than how things work in Common Lisp. They are also "better integrated" at least in the sense that Scheme macro programming addresses directly the reality that macros are _syntax_ transformers, whereas in common lisp one manipulates an impoverished representation of the code which does not include any information about syntax. If you wanted to do real programming I would definitely recommend Common Lisp as the most serious contender for real world development, followed by Clojure - I don't know of any large commercial concerns implemented in Racket or other Scheme dialects. But if you want to program in a language which is well designed as it pertains to metaprogramming, it is hard to beat Scheme, in particular, Racket. 
*Very* cool, looks like it has some overlap with CLinch.
This is pretty cool. I usually do OpenGL with C++ and there it's: change, recompile, rerun. Live coding with Lisp seems so much better for testing out effects.
Exactly my point. This *making it more accessible* for newcomers is just making it less accessible for anyone else. The only valid reason for infix notation is lisp that I can aknowledge is heavy math code, but that can be achieved easily by a simple macro DSL. If you want *infix lisp* you can just use Dylan.
I understood your point, but it reads as though you are suggesting the purpose of &gt; prefix notation in Lisp [is] in order to make it "more accessible to newcomers" Did you mean to say infix notation here?
Maybe I'm missing something about CLinch, but don't you have to specify shaders in CLinch as big long strings of GLSL? Compare that to this: http://www.youtube.com/watch?v=2Z4GfOUWEuA&amp;list=PL2VAYZE_4wRKKr5pJzfYD1w4tKCXARs5y&amp;index=8
You do! I said some overlap, not that they're completely the same :)
&gt; Why should {8 / 4 / 2} be the same thing as (/ 8 4 2) and not (/ 8 (/ 4 2))? Because "/" has the same precedence as "/", so they should be evaluated from left to right. Test it for yourself in any program language. &gt; Or better yet, if ^ is a power operator, why should {8 ^ 4 ^ 2} be the same as (expt (expt 8 4) 2)? The usual convention is the other way around! You're right on this one, I'm not sure about the mathematical reason. But can you use the power operator this way in readable? I guess it is only possible to use {} with operators that accept any number of arguments.
I understand. Every time I read about CLinch, I wanted it to encompass writing useful shaders a great deal more than I wanted it to do scene graphs and such. *shrug*
The sexp-&gt;glsl compiler is cool.. I went down this route some years ago with a project called photons. I made two major mistakes. Firstly, concentrating on an over-engineered math library which turned out to be bit of a beast to maintain (marco writing macro writing macros..), and secondly wrapping and using too many native libraries. The last point is lethal to getting a good Open Source project off the ground. To have to build your own binaries that match the lisp compiler and the version wrapped is often tricky. Distributing library binaries with the project *might* work, but then you'd have to take into account different platforms, architectures and even compilers..I did at least establish a decent format for assets, geometry and the like. ..am thinking of coming back for a second go...this time staying away from native libraries as much as possible, and also embedding hunchentoot in the system for a GUI / asset browser type thing, relying much less on Emacs+Slime for data inspection.
The audio volume is way too low. Maybe you should ask the slime folks to add the link to their list of screencasts: http://common-lisp.net/project/slime/
You could just check for updates to the shader files and reload them during run time.
Thanks.
There's also some neat discussion in [the thread](http://article.gmane.org/gmane.comp.lang.smalltalk.fonc/4558) where I found it.
Well holy crap, I didnt expect to be on here so soon! Hey folks, thanks for all the kind words: @johnfredcee: Thanks for the comment and the insight! I'd love to nater about some of the gui ideas when I get closer too that. The smalltalk environments, WorryDream and lisp projects like blocky have been very inspiring. @oaty1: Nope I'm Baggers there too. @amigaharry: Cheers! yeah the instant iteration and common lisp's conditional system make it a dream. The experience needs some work, but it is always about trying to make gl as effortless as lisp can be. @WarWeasle: Cheers, who knows what the future holds :) Right now though I am still trying to work out what this thing will look like, though I feel like i'm getting close to a baseline of functionality, I'm mainly trying to nail abstractions around time and space right now. @samlamamma: thanks! @patrickwonders: Aye, having to switch mental context between languages is horrible for productivity (at least for me!) The glsl compiler came out of that fustration (though it is pretty ugly right now). I havent looked at scene graphs or the like as they are solutions to particular problems, and I'm defintely not at that point yet. I want to know if there are composable axioms for realtime graphics Sorry that this project is still VERY alpha but I hope some people have some fun with it. I have plenty more ideas I am still ironing out especially around handling time. I'm happy to answer any questions and would love more ideas/comments.
&gt; marco writing macro writing macros.. why would you do that?
I just want to chime in that there are alot of places to learn how to use macros, but "On Lisp" is the one that I can think of that provides the most in-depth discussion of them. That book will beat you over the head with how powerful they are.
The issue to run the cl-cffi-gtk library on Mac OS X has been solved at least for SBCL. You can see a screen shot on https://github.com/crategus/cl-cffi-gtk/issues/10 The cl-cffi-gtk can be compiled succesfully on Windows with SBCL. The demos will start and work. But if you move the window the application will freeze. This issue is a open problem.
Seems that their machine works well for a certain class of problems. Ars has a good summary [here](http://arstechnica.com/science/2013/05/d-waves-quantum-optimizer-pitted-against-traditional-computers/). It's not a general purpose quantum computer, but it appears that it might have a niche where it's actually useful.
..because it was the only way I could do what I wanted. Or so I thought. Turns out compiler macros will probably do the job, too.
Learn how to use reddit, Chris! ;-)
Haha reply buttons are for the weak!
I can imagine a cl-who designed for shaders.
My first tests would indicate that it's not ready for production. mocl is far from a complete CL implementation. I've tried it with: mocl repl --ios /tmp/ which invokes the repl that's announced as experimental. I don't criticize the lack of debugger or the fact that it often exits on error, it's an experimental repl. But on the language level, processing files in batch (with load). It even not a beta, and cannot justify the cost. (and even as a kickstarter campain for a free software project, it would be a hard sell at this price). I'm yet to evaluate a form that hasn't conformance or mere non implemented CL operators in it. Of course it can't load quicklisp/setup, and can't load my personal libraries. If that's not possible to load my personal libraries in the repl on the development workstation, I don't see how I could use it to (and them) to produce anything on iOS or Android. My $200 would have been better invested on ecl or ccl to improve their EXISTING iOS and Android ports.
Interesting. How do you imagine this looking/behaving? I havent use cl-who yet so what parts feel the best to you? What makes the experience good? I'd love to know just so I can copy good coder experience patterns that occur in other projects :)
I guess I imagine being able to make something structured like a shader, except that changing between per pixel lighting or per vertex lighting, or GLSL vs HLSL, or CPU vertex transformation vs GPU vertex transformation would be easy.
Cool, the cpu/gpu switching is something that I've been thinking about. I'll keep the easy switching lighting models in mind, it would be an excellent test to ensure I'm keeping things modular. Cheers
He should start with something smaller like an MMO.
I look forward to seeing the responses from people that actually know SBCL internals. In case you actually know less than me about this, I'll confirm: 1. If you start 4 or more threads with bordeaux threads then, yes, it will use all 4 of your cores. 2. You have to make sure that SBCL has threading compiled in. This is probably the default on OS X these days, but it wasn't always, so make sure there is a :sb-thread in your \*features\*. 3. The threads in SBCL are OS level, which means that the OS decides how to assign threads to cores. This is usually one of those things that you leave up to the OS, but I imagine that some very advanced users might want to tweak with thread affinity or the scheduling algorithm, but that is way beyond me. 4. There are libraries that run on top of bordeaux threads that provide some scheduling from inside Lisp (for example LParallel and Eager-Future2 (or whatever the most recent name is)). IIRC, these maintain a thread pool and provide some scheduling based on dependence between computations.
Have you tried adapting it to use http://lparallel.org/? It is not SBCL specific but also surprisingly well documented
No, I hadn't heard of lparallel. Looking at it briefly, it reminds me a lot of Termite, as used with Gambit Scheme. Thanks for the pointer.
Thanks for the info. I checked, and I do have sb-thread in *features*. Definitely sounds like it's worth trying. 
Generally, anything that schedules OS-level threads uses one core for each thread (or if more threads than cores, the threads are split amongst the cores in (hopefully) the most efficient way possible). So yes, since SBCL support OS-level threads, your four threads will *possibly* (most likely) be used on the four cores, at the discretion of the OS. As smithzv mentioned, there may be ways to force a thread onto a specific core, but I'm not sure how this is done. Not sure if you have [htop](http://htop.sourceforge.net/) on OSX (if not you might be able to compile it), but it's an easy way to show how much work is happening on each core. Sometimes the best way to test is to load up 4 threads, tell them to churn away, and watch the madness in htop =].
&gt; As smithzv mentioned, there may be ways to force a thread onto a specific core, but I'm not sure how this is done. You can't on Linux as far as I know. But you may reach near state with the help of sched_setaffinity() system call and, even further, by setting the relative priority of the process and changin its class with the sched_setscheduler() system call. But then how call that from Common-Lisp? I don't know. Does someone how to do that ?
I guess that another important thing to consider is global locks - Garbage Collection, etc. Does SBCL suffer from this kind of issues?
https://github.com/xach/cmucl-direct-syscalls
This is overkill, and fragile. The normal SB-ALIEN stuff should suffice.
Try here: http://audio-video.gnu.org/video/ghm2013/Luca_Saiu-GNU_epsilon_tutorial_.webm
Cheers Rainer. Please keep making videos, they are always interesting. Your dsl-in-lisp video helped me when I was starting out.
If there is a long line like this: (displayln (bytes-append (bytes-&gt;hex-string (sha1 in)) #".")) I would just write it like this if I find above too difficult to read: (displayln (bytes-append (bytes-&gt;hex-string (sha1 in)) #".")) I see also that the main operation is `displayln`. It is on top. The arguments are the detail. In the 'threaded' version it is at the bottom. Basically my code is now reversed and I get the details on top. (~&gt; (sha1 in) bytes-&gt;hex-string (bytes-append #".") displayln) Additionally the editor now has to be told about the macro to understand that the parameter lists of the functions are not wrong (if it parses them), that a symbol alone is not a variable but a function call, finding the start of an expression is now more difficult, ... Basically it is like Perl programmers using funny characters and lots of syntactical 'short-cuts' are taking over Lisp. 
I use stumpwm. What is dswm really addressing? The readme on github was rather vague and just talked about usability and emacs integration.
Seems a bit underdocumented at this point. I'm running it right now; the visible differences, at the moment are: a) Uses c-j rather than c-t, by default b) There's a bar up top with a clock and list of frames and windows That's not compellingly better just yet.
That is the exact opposite of 'better' as far as I am concerned. If this is what the dev considers better, I am glad they forked it so as not to pollute stumpwm proper.
A few years back I gave DSWM a go before StumpWM had floating window support (so far as I'm aware anyway). I didn't mind it but ultimately there were some stability issues at the time that led to me dropping it. I bet it is much improved now.
Oh, jeebus! You are correct. I totally forgot about that! I have had mine turned off for so long, I have forgotten it has it turned on by default! My bad indeed.
Can someone tell me about Stumpwm besides what is on their site? I see a picture of the user's workspace, but cannot make anything out. Can someone give me an example of what you would build with it and how you would use it?
I hope this helps: http://www.youtube.com/watch?v=do0DVxy4HBc http://www.youtube.com/watch?v=tKt_rVO960Q To build it on Debian: 1) Install Stumpwm from repo. It should be recent enough. 2) If it isn't recent enough for you, download from wherever stumpwm is located now, follow compile rules and you will end up with a file called STUMPWM. You can then just use this STUMPWM binary to replace the one in /usr/bin. This way you don't have to do too much manual work. Lastly, I no longer use panels, application menus or anything of the sort. To my way of working now, I use the shell instead of a panel/applications menu. Panels make no sense to me any more now that my window manager is simply a dynamic INTERFACE MANAGER -- if i need an interface i can just split up the screen and load up the tools i need as I want, I no longer need to bend my brain to someone elses concept of what a computer interface is. What is weird to me is that as desktop managers get more complicated (kde/osx) and bizarre (win8), Stumpwms simplicity, I believe, paves the way for a sensible future.
IIRC the stumpwm pitch is basically "a tiling windows manager written in common lisp with an emacs inspired interface." So, to backup a step, the windows manager is what arranges the windows on your screen. It also controls whether your windows have borders around them or a title bar at the top along with close/minimize/maximize buttons, chooses whether to display a desktop background, controls which window is being "focused" on, etc. You can replace the windows manager software on your computer. Tiling windows managers are a category of windows managers that are typically largely keyboard driven, typically allow you to hang functionality off rebindable key bindings, and typically automatically full screen most windows, and have key combos for perfectly splitting the screen between two or more windows, and have key bindings for changing focus between windows. (The screen shot probably shows the result of this splitting; programs fit next to each other in rectangular frames.) You use stumpwm like other tiling wm. Since it is easy to customize and script, one thing I have added is a timer, which asks me for a time in minutes and a message and displays the message to me after the minutes have passed. Another use is that a key press can bring up an input to the underlying lisp image, so you can use it as a handy programmable calculator. 
This may be helpful. It's been five years, though, so prepare for bitrot. https://github.com/nikodemus/sb-cpu-affinity 
I hadn't seen that first video before. I like how he talks in the complete opposite way to male in the second.
I really like the fact that Abhishek Reddy starts with mentioning rich, exact arithmetic. Looks like a small detail, but the designers of CL made the right choice here: having the full numerical tower in CL is invaluable.
A subset of that can be done with rationals and then [printed in decimals](https://wukix.com/lisp-decimals) when applicable, but full-fledged decimal arithmetic I would place in a library. CL is extensible enough to support it pretty seamlessly (except for the arithmetic operators, which would need to be shadowed and made generic). BTW, I also miss standard (portable) notation for infinities and NaN.
The author is Abhishek Reddy, not Nikodemus.
thanks, I edited my comment.
Mnyeh, how can returning NaN be better than signalling an error?
I was thinking about infinities, mostly. But you are right about `NaN`s, it is usually better to deal with the error the right way.
I agree! Thank you, Rainer.
Thanks to everyone who gave explanations. I understand now. One question, besides displaying windows in an emacs like way, could you build a GUI with it? Guess not, it can only control an existing one right?
Thank you for the link. This has to be one of the most important videos that I have seen online (for me anyway). This doesn't apply just to programming, this applies to a lot of other areas. I can see applying this approach to system administration for example. Thanks again.
Stupidomoust macro ever. For fools. Make programs hard to read. * On that note. Why dont you macro which compile all Pascal-language statements, if you hate brackets so much?
Oh my. Over a million lines of code. Of LISP. I want to set up a betting pool and see who can guess the closest to how many lines of Java a hypothetical JAxiom would need.
Scheme's [right over there](http://racket-lang.org) if you want it: #lang racket ;; Finds Racket sources in all subdirs (for ([path (in-directory)]) (when (regexp-match? #rx"[.]rkt$" path) (printf "source file: ~a\n" path))) Oh, nevermind...
Probably closer to 1 billion. But in all seriousness, this is a great talk outlining the importance of communication in code, something I have always lamented the absence of. When I look at software, I often don't know where to start unraveling it because there's little/no/bad documentation and the code is littered with little hacks and rough edges. 
The Lisp code with the fancy symbols is the result of a transformation. It is not hand-written and not the source code.
If you can't read a loop, you're the one at fault, not the macro. 
I was expecting something on the line of ABCL. Why having a new dialect? 
Is CLISP/DWIM an ancestor of LOOP (in terms of ideas), or was LOOP an independent invention? I suspect this might be hard to know now.
Why? I find LOOP awesome macro (and a bit sad why Scheme doesn't have it), a readable language for expressing loops. It is good especially for beginners, where the first thing one does in new language is declaring some variables, basic math and looping. Now try to convince someone to use recursion or **DO**; for the second one I always have to check documentation to see where is going condition and where modifying part...
If you read the paper, the LOOP macro was called FOR. (loop for x from m to n do (print x) while (primep x)) was (example from that paper) (FOR OLD X&lt;-M TO N DO (PRINT X) WHILE (PRIMEP X)) As you can see, the syntax is basically the same for this iteration and conditional. That loop language was then implemented as LOOP macro for Maclisp. This was then ported to Lisp Machine Lisp and Common Lisp. The CLHS says: http://www.lispworks.com/documentation/HyperSpec/Body/01_ab.htm &gt; Interlisp introduced many ideas into Lisp programming environments and methodology. One of the Interlisp ideas that influenced Common Lisp was an iteration construct implemented by Warren Teitelman that inspired the loop macro used both on the Lisp Machines and in MacLisp, and now in Common Lisp. For further information about Interlisp, see Interlisp Reference Manual. The Maclisp doc says: http://www.maclisp.info/pitmanual/contro.html &gt; LOOP is a programmable iteration facility used in Maclisp, NIL and Lisp Machine Lisp which was inspired by, but is not compatible with,the “FOR” facility in Interlisp's CLISP. 
Mostly I hate it because it esthetically unappealing and not Lispic enough. For example if you build nice S-expression editor you cannot use on LOOP -- it is just nonstructured string of symbols: (LOOP FOR X FROM 1 FOR Y = (* X 10) WHILE (&lt; Y 100) DO (PRINT (* X 5)) COLLECT Y).
Interlisp had a nice s-expression editor and this syntax is from there.
I think that SEdit, which is what you're referring to (the earlier DEdit doesn't qualify as "nice" in my book!), did indeed support CLISP/DWIM pretty well via, presumably, the usual IL magic. Sadly it didn't know what to do with LOOP though (if only because LOOP was at that point not part of CL). I'd be interested if anyone has a clearer memory than me of its support for CLISP though: it might be that it really didn't support it properly.
Then you can use ITERATE. 
I lost interest when I saw that the mapping from Lisp symbols to JS strings is not one-to-one, e.g. (= 'multi-word 'multiWord) compiles to ("multiWord" === "multiWord")
I still can't believe that all these tools and platforms are essentially lost now, just perished... how unfortunate...
The slides are [here](http://daly.axiom-developer.org/TimothyDaly_files/publications/DocConf/LiterateSoftwareTalk.pdf). More good stuff at [his site](http://daly.axiom-developer.org).
They are not really lost. Symbolics sold them to Nichimen. They ported it to Allegro CL and SGI/Irix. It was sold as N-World to customers. They invested a lot also to make it a product for game content creation. It was sold again and ported to Windows XP/NT / Allegro CL. http://www.izware.com/mirai/requirements.htm Thus Izware owns the rights. From them there was little to no news in the last years. Izware's Mirai is basically the third generation of the Symbolics S-Graphics products.
Note that Wings3d is only a simple modeller. The actual inspiration was Nendo. http://www.izware.com/nendo/modeling.htm Nendo was cheap and people could easily use and download it. Its modeling part was then copied by Wings3d. I would guess the developers of it haven't seen Mirai in actual use - just some pics, videos or other documentation. Mirai is much much more. As was Symbolics S-Graphics or Nichimen's N-World.
Too many lines, with or without literate (if any) programming. 
Yes. I don't mind the syntax of `loop` so much as the inability to nest a `collect` deep down in the code; that's why it has to reinvent `if` and `progn`. With `iterate`, you can do stuff like (iterate (for x from -5 to 5) (cond ((&lt; x 0) (collecting x)) ((= x 0) (write-line "Yay!")) ((&gt; x 0) (appending `(+ ,x)))))
Since it was checked into version control, I assumed it was source code. Is there an easy way to figure out where the actual source code is?
SBCL does not have global lock in the sense of GIL. Threads allocate memory from their own pools (so most allocations are lock-free). But there are finer locks in SBCL runtime. GC is not concurrent/parallel and stops all threads during collections.
[All this will be lost...](http://www.redhat.com/archives/redhat-list/2003-September/msg00389.html)
sagenhaft!
Great slides.
Pay money for CAPI and you'll get a mature toolkit from a company with stellar support plus a helpful community of users who have shipped real applications. 
Looks nice, but probably more $$$ than I want to pay, especially since it would preclude a lot of folks from collaborating if I wanted to release it. Also, can you embed a LispWorks interpreter? It doesn't look like it. Anyway, I nonetheless agree that is cool and I am glad it exists.
How about ABCL? It will allow you to use Swing for gui development. 
[guile](http://www.gnu.org/software/guile/), is pretty lispy. Even has [gtk](http://www.gnu.org/software/guile-gtk/). 
Forgive me for asking as it may be a stupid question, but if you're looking for performant OpenGL drawing/graphics research, why do you need *any* GUI toolkit? Using something like GLFW/SDL will give you an OpenGL context, and cl-opengl gives you a very minimal (yet effective) wrapper over OpenGL's C APIs. I'm fairly certain this recipe works in ECL. One nice thing about using Common Lisp is that you don't *need* sliders/input boxes/etc in your GUI, since you can just redefine your parameters on the fly while the app is running.
LispWorks is a compiler and interpreter. Yes, you can embed LispWorks. It is possible to create a shared library, which can be uses by an application.
Well, enough extra to write a Lisp, obviously, so in the limit about the same number. There's a famous quote about this.
Let me fix that for you If you meant for it to be scheme: (define (filter predicate inList) (cond ((null? inList) '()) ((predicate (car inList)) (cons (car inList) (filter predicate (cdr inList)))) (else filter predicate (cdr list)))) (codeIn (head (filter (lambda (lang) (not (eq? lang 'PHP))) languagePreferences))) If you meant to use haskell: codeIn :: [String] -&gt; String codeIn languagePreferences = head $ filter (/="PHP") languagePreferences And that, friends, is why I use haskell
https://kindista.org/ for the lazy (they should really put a link front and center on the github). It's nice to see more CL development in the web app space. It really has a chance to shine here, and it's a good wave for CL to ride because it's still a really hot ticket, even with mobile being so ubiquitous now. It looks like a cool app, almost like a craigslist-esque bulletin board system.
I added a link to the README, thanks for the suggestion. We've been super happy having the app written in Lisp; it performs well and has made it easy to add new functionality. Next week I'll be launching a completely unrelated web app also using secret alien technology, will post a link when it's up.
Wow, I was wondering if some of their code would ever be published. Awesome!
It's a very nice way of saying rg. "missing data". Computations involving missing data get NaNs as their results, and you can still use SSE, etc, for data-parallelism. Yes, often signaling an error is better -- because hunting down a NaN source is never fun either -- but sometimes you really want to return a NaN. 
If you are on Mac OS X and want to target just Mac OS X you can just use CCL's Objective-C bridge and make GUI's that way.
Indeed. CL-USER(12:28:18): (defun fib (n) (declare (optimize (speed 3) (safety 0) (debug 0))) (declare (type (unsigned-byte 64) n)) (if (&lt; n 2) n (+ (fib (- n 1)) (fib (- n 2))))) FIB CL-USER(12:28:42): (compile *) FIB NIL NIL CL-USER(12:28:44): (time (fib 40)) ; cpu time (non-gc) 0.835340 sec user, 0.000000 sec system ; cpu time (gc) 0.000000 sec user, 0.000000 sec system ; cpu time (total) 0.835340 sec user, 0.000000 sec system ; cpu time (thread) 0.834655 sec user, 0.000000 sec system ; real time 0.836666 sec (99.84%) ; space allocation: ; 0 cons cells, 0 other bytes, 0 static bytes ; Page Faults: major: 0 (gc: 0), minor: 0 (gc: 0) 102334155
Looks neat, but warning alarms go off in my head when I see benchmarks against "Common Lisp". CL is a specification. It's like seeing a benchmark between "Unicode" and ASCII. We are given no information about the actual implementation of the CL standard that this was measured with (as the post provided with the C benchmark), nor about the implementation of the *fib* function (interesting bits of information I'd like to know here, was the same function requested of the CL system and did you provide the same type information to the CL compiler?).
Technically you do need to try out the other implementations too.
That is exceptionally good performance for CLISP. Something doesn't make sense to me. My compilation of a simple C *fib* program runs around twice as fast as you report on your machine, but using (compiled) CLISP runs ~6-7 times slower than the number you report, and that is with type hints (though they don't help much). Just a mystery for the morning I guess, it doesn't matter.
In retrospect, I should have just published a benchmark script.
Looks cool dude, i'll have to try it out this weekend. Try not to let the benchmarks fiasco mess with you, the lisp community is full of well-meaning curmudgeons.
Now that it's gone, you can upvote again. ;)
I did.
Love it. 
*You still have time*.
* Do you have plans for Windows Phone? * You have a benchmark graphic, but I don't see a link to the source and scripts for replication. * You don't describe in detail what Wukix adds/subtracts from CL. My recollection is that you have commercialized some 90s work from Germany that is an ahead-of-time compiled subset of CL. So I expect you don't have EVAL and a few other run-time operators. --- I wish you the best and if/when I do my own commercial app development, you are near the top of my list.
die in a fire
Thank you. Very ego-boosting. :-) Windows Phone is not a platform I anticipate caring about at this point in time. My current Lisp project is actually a FirefoxOS webapp with SBCL (or possibly CCL, not sure yet) as the backend. However, for people who are *really* into cross-platform compatability (say, government or university services who have to serve everyone), I would expect targeting the more niche platforms to really be important. 
I would go with Chicken Scheme or Guile (although I don't know if the latter works under Windows). 
I don't want "practical", just something that I can use with SICP. Thanks for the tip about CHICKEN though, I take it that it's better than Racket. Where do I download a distribution for Windows (if there are any)?
I would *strongly* recommend upgrading your operating system. You'll have a far more pleasant development experience on a modern *nix. Check out Racket or Guile. See the following link for more information: http://wingolog.org/archives/2013/01/07/an-opinionated-guide-to-scheme-implementations
I am currently studying SICP by myself and I use DrRacket. There is a language menu in DrRacket that you can reach from the button on the bottom left. If you open up that menu and choose "R5RS" from the list, you will get the correct dialect of Scheme for SICP. (It was under "Older Languages" or something similar as far as I remember, I am on mobile now so I can't check it.)
[Racket the language is a Scheme, but it's philosophy is different enough from that of standard Scheme to consider it a language of its own](http://racket-lang.org/new-name.html). Nonetheless, Racket the implementation supports running in various compatibility modes, so you won't have any problems restricting it to standard Scheme if that's what you really want. As far as I know though, the Racket language is completely backwards compatible so you won't even need those compatibility modes. Its GUI, DrRacket, is probably the best learning environment for Scheme in existence, so I would definitely recommend it as your first Scheme implementation. **EDIT:** Some good information gathered from other comments here: * [From this comment](/r/lisp/comments/1pltiq/i_want_to_learn_scheme_what_implementation_should/cd3v36w): There's a package for Racket to make it fully SICP-compatible [here](http://www.neilvandyke.org/racket-sicp/). (These are a description and instructions. Racket can actually install it automatically because it's in the [official package repository PLaneT](http://planet.racket-lang.org/).) * [From this comment](/r/lisp/comments/1pltiq/i_want_to_learn_scheme_what_implementation_should/cd3pkgm): There are some minor incompatibilities between Racket and standard Scheme, the biggest seem to be immutable pairs - actually AFAIK R6RS had immutable pairs, too, but R7RS reversed that decission. 
I have a weird deja-vu feeling reading this thread. I like racket but use guile 2 (for learning first principles) because racket distribution is a bit too large for my tastes.
Racket used to be called PLT Scheme. Racket vs Scheme is rather similar to C++ vs C - both Racket and C++ are mostly supersets of their parent language, but they broke compatibility on a small number of issues (note: I'm not trying to suggest that Racket is the C++ of scheme, just that they share a similar relationship to their parent language.). Nevertheless, most Scheme code should compile using Racket, much like how most C code will compile using a C++ compiler. In particular, from http://stackoverflow.com/questions/3345397/how-is-racket-different-from-scheme, &gt; * Racket has no set-cdr! and set-car!, rather set-mcar! which only works on pairs specifically created as mutable. &gt; * What Racket calls letrec is called letrec* in R6RS and doesn't exist in R5RS, what R5RS and R6RS call letrec doesn't exist in Racket. &gt; * In Racket, a lot of things are self-evaluating which would raise an error in R5RS, most importantly the empty list. &gt; * Racket is case sensitive, though R6RS is also case sensitive &gt; * Racket treats ( ... ) and [ ... ] as equivalent, R5RS does not, but R6RS does. 
I recommend [Scheme48](http://s48.org/). It's a small and standards compliant (R5RS) implementation. If you need a editor, most people will suggest Emacs. Learning to use Emacs and a programming language at the same time can be daunting. Perhaps [LispIDE](http://www.daansystems.com/lispide/), although nowhere as powerful, is a decent choice at first. Racket is a great language (or many great languages, as it implements multiple dialects). Both choices are fine.
I'm partial to Chibi, Gambit, and DrRacket. Bigloo seems fine but docs are hit and miss. Guile is useful. Eventually you can try making yours. If you're going through SICP probably you should try http://www.gnu.org/software/mit-scheme/ although others will do the job too. For instance DrRacket with this http://www.neilvandyke.org/racket-sicp/
Its too late now! The internet is closed!
Having used both, I wouldn't call chicken better. 
I used MIT Scheme with EDWIN, but downloaded Racket to get the "picture language" to work. That was easy to do in Racket, just look up the command when you get there. Racket and its IDE were easy to setup and there seems to be a community around those tools. 
Btw does anyone here know where the source of the website is hosted?
[http://sourceforge.net/p/sbcl/sbcl-page/ci/master/tree/](http://sourceforge.net/p/sbcl/sbcl-page/ci/master/tree/)
&gt; I will probably work through "The Little Schemer" and SICP. I've heard good things about DrRacket I wouldn't bother with "Scheme for Mouth-Breathers Who Like Food," but it's written by the same guy who does Racket, a.k.a. DrScheme, so if you want some Matthias Fellation..., er, Felleisen, go for it.
Just curious, why SBCL binaries for different platforms are out of sync, especially x86 and x64 versions? Recently I went to deploy a small product on older x86 thin client, just to find out version hasn't been updated for ages....
Someone just didn't care to update it. You can still update it yourself by downloading the already compiled version and the new version and then compile that.
Is there any reason why the fork by Anton Kovalenko has not been back ported to the main source tree ? 
It has been.
I've had this book on my bookshelf for a few years now. Unfortunately something always got in the way and distracted me yet again from completely immersing myself in Lisp. Well not this time: I'm close to finishing ANSI Common Lisp (Graham) and Lisp 3rd Edition (Winston &amp; Horn), then going to go through Practical Common Lisp (Seibel) and finally will have a go at PAIP. There's no turning back! :)
It also supports using hex triplets for colors out-of-the-box (but you can't change the colors of the message/input windows as far as I can remember) I think what DSWM is supposed to address is the feeling of anxiety at the lack of activity in StumpWM.
A lambda is an anonymous function, while defun creates a named one. You mainly use lambda when you need to create a function that can be thrown away later, eg: (map (lambda (x) (+ x 5)) '(1 2 3 4 5)) It would be silly to define a function (defn plus-5 (x) (+ x 5)) that is never used in the rest of the system.
What's the difference between (defun plus-5 (x) (+ x 5)) and (def plus-5 (lambda (x) (+ x 5)) 
My Lisp is a bit rusty so I may be not 100% technically correct: First of all, 'def' does not exist in CL. You can use defvar, defparameter and defun. While you can technically use defvar and defparameter in combination with lambda to create a function, it is not the way to do it. The reason (besides clarity and style) is that CL is a Lisp-2 (or whatever the name is). This means there are 2 separate namespaces for functions and variables. When you would do: (defvar plus-5 (lambda (x) (+ x 5))) (plus-5 1) You will get an error that the function plus-5 is not defined, as it tries to look it up in the function namespace. Doing something as (apply plus-5 '(1)) will work, as the variable is looked up in the correct namespace. This is also why you need to do (apply #'incf list) The #' is a shorthand for 'look this thing up in the function namespace'. Reading [this](http://www.gigamonkeys.com/book/variables.html) might help you. In other Lisp-dialects (such as Scheme) there is no difference between: (define (plus-5 x) (+x 5)) (define plus-5 (lambda (x) (+ x 5))
It depends on whether your Lisp implementation is a Lisp-1 or a Lisp-2. In a Lisp-1, these are effectively the same (though defun may perform additional operations on the lambda form like adding documentation). In a Lisp-2 however, (def name (lambda ...)) will set the value slot of name to the lambda whereas (defun name ...) will set the function slot. This means that you can't call 'name directly like (name ...). Instead, you usually need something akin to 'funcall or 'apply to do so. Emacs Lisp is a Lisp-2, as is Common Lisp; Scheme and Clojure are Lisp-1s.
Agreed that the point seems to be to reassure that development is taking place. After some more days of usage, it seems no worse to me than stumpwm, and it hasn't had any crashes. I haven't gone onwards to customize either; with the limited docs, that doesn't help much for dswm :-(
&gt;If that's not the case, then I'd argue Lisp isn't much of a functional language :) Pardon my ignorance, but what's to argue? From what I've read, Lisp is a family of multi-paradigmatic languages. If you want to use some version of Lisp in a functional manner, does it keep you from doing so? On the other hand, it seems clear that Common Lisp, Scheme and other dialects of Lisp can be used in a non-functional manner. So maybe I'm missing your point. If there's something I can learn here, kindly elucidate.
`elt` is generic for sequence types and `aref` is array specific. In other words: `(elt '(1 2 3) 1)` works; but `(aref '(1 2 3) 1)` doesn't. If your function is specific to strings, use aref; if your function can be applied to list-of-characters, use `elt`.
I don't think so? If your compiler is smart enough/your type hints are good enough, the type check before the call could be removed and you'd get the same result. I'm not certain, though.
Using AREF in general will be faster. But if you're accessing strings only, use CHAR.
One thing you get is an error message in save code when you call AREF with something other than an array.
If the string has a fill-pointer, ELT will honor it while AREF will ignore it.
Or you can use SCHAR if the string is known to be a SIMPLE-STRING (neither displaced nor having a fill-pointer nor being expressly adjustable).
Quite pricey.
And getting an electronic version seems almost impossible. O'Reilly does this kind of things so much better. TOC is really appealing though. 
Not really. It is available from Amazon, Apple iBooks, ... The links are here: http://eu.wiley.com/WileyCDA/WileyTitle/productCd-1118129857.html 
Thanks for the pointers. I was looking for DRM free pdf version, so far found just a Kindle edition for 54$. Still looking for a better option, 'cause I'm yet to see a programming book for Kindle which is not screwed. 
Oh, thanks. So I have been too quick when browsing the ChangeLogs. 
It's been (still is) backported piecemeal.
Have a look at the \*read-default-float-format\* variable that defines how the CL reader interpret a floating-point marker without an exponent marker. By default it is single-float. If to set it to double-float you'll get the same behavior as in Python and Clojure. * (setf *read-default-float-format* 'double-float) DOUBLE-FLOAT * (+ 0.1 0.2) 0.30000000000000004 * (= (+ 0.1 0.2) 0.3) NIL 
in addition to ilowry's explanation above, I would like to add that if you want rationals in CL, then just use rationals. (= (+ 1/10 2/10) 3/10) ; =&gt; T Also, CL-USER&gt; (ql:quickload "wu-decimal") CL-USER&gt; (wu-decimal:enable-decimal-printing-for-ratios) CL-USER&gt; (+ 1/10 2/10) #$0.3 
The main difference is during printing. CLs print with the fewest number of digits necessary to reconstruct the value exactly (under some assumption about the rounding mode, e.g. that READ rounds to nearest). SBCL implements the naïve algorithm in [Burger and Dybvig's "Printing floating point numbers quickly and accurately"](http://www.cs.indiana.edu/~dyb/pubs/FP-Printing-PLDI96.pdf). Doing that quickly is still an active research topic, see http://www.serpentine.com/blog/2011/06/29/here-be-dragons-advances-in-problems-you-didnt-even-know-you-had/ for example.
I'm guessing that professional automated trading is not typically in the realm of cheapskates and amateurs.
Not *really*. Most serious technical books start at about $60. It's your flavor of the month books that are cheap, IMO. E.g., Foundations of Multidimensional and Metric Data Structures by Samet is about $66 on Amazon.
For the lazy: /r/scheme --- I provide direct links to lesser known subs mentioned in the title if one isn't already provided. Let me know if I need to try harder: /r/LazyLinkerBot
Interesting, though only available on back-order, due late november. I have API access to price data from a broker, it uses java of course but I got it working with ABCL.
This isn't the answer: the answer, as someone else pointed out, is single vs double floats.
Apart from the other answers, note that in CL defun wraps a block with the function name around the body of the function: ignoring docstrings, it's a bit like (setf (symbol-function ...) (lambda (...) (block x ...)))
&gt; If your function is specific to strings, use aref; or char! There are an absurd number of accessors for arrays and sequences: I find it almost impossible to know which to use. What I do in practice is: if I know it's a string I use char (never schar), if I know it's an array I use aref (even if it might be a string), if I know it's a sequence I use elt (even if it might be a vector), if I know it's a list I use nth. Not sure if I would use bit, but probably I would (I don't deal with bit arrays much). Obviously this is just a matter of taste, and my taste is probably bad. One thing I never do is use the simple versions of things (ie schar, svref, sbit) *unless*, after profiling, it turns out to matter, when I might. I don't think it ever has mattered.
You're right. I think Python even changed their printing logic a couple years ago.
Thanks. I wasn't trying to be rude BTW, just typing on a phone...
So after a month, what are you using to make your GUI, and how are you building your applicaiton?
TBH haven't started yet. Right after I posted this, I got distracted with other things. So I'm pretty much torn between XULrunner (because the GUI will contain a "web view" to show a javascript app that's already written) or Tcl/Tk. I really like the simplicity of Tk and cl-tk seems nice. I've toyed around in it a bit and like it, plus this would let me do higher-level logic in lisp. XULrunner will make actually porting what I've built already over to desktop much easier, but there's pretty much no lisp involved at all, which makes me a sad panda. Unless there's an easy way to embed HTML/javascript into a non-XUL app without spending the rest of my days shoddily wiring a bunch of libraries together, I might be doomed to go this route. However, the desktop version of my app might be different enough that I'll have to redo a bunch of stuff anyway. I really need to plan things out a bit more before taking the plunge with one of the GUI libs out there. TL;DR: don't know, and don't know. Haven't started yet.
so you're saying that you need to incorporate a javascript application that already exists into a frame of your desired gui program? 
Yeah, pretty much. The app is a chrome/firefox extension that I'd like to have available on desktop. While there are some parts of doing this that are ideal (ie, not having to rebuild the app on another platform), it kind of completely ignores the benefits of having it on desktop, like much faster performance (which *is* an issue since I'm doing a lot of crypto) and filesystem access. There may be a way to split parts of it out into a second desktop client (ie, one like a desktop evernote, one like dropbox) and package them separately. The dropbox one would get the filesystem access it needs and the evernote one (which is the pre-existing JS app) would get its pretty web-in-GUI views.
Honestly, I got the most out of The Little/Seasoned/etc/etc Schemer books when I did it like this: https://twitter.com/stevelosh/status/310487495198523393 No screwing around with computer bullshit, just your brain and the code.
While I'm sure a lot of people will dismiss your question as trolling, I'm going to attempt to answer in case you are serious. The parenthesis in lisp are not "syntactic sugar" but actually contribute to the power of the language (via homoiconicity). By removing parenthesis in certain cases, you are removing the ability for a language to be easily homoiconic. If you code in lisp for a while and actually 'grok' it, the parenthesis basically become invisible.
And a good editor will diminish their contrast, making it easy on your eyes.
Because [s-expressions](http://en.wikipedia.org/wiki/S-expression) are the [most powerful](http://www.ymeme.com/s-expressions-most-powerful-data-structure-available-68.html) data structure. And, we like [macros](http://www.apl.jhu.edu/~hall/Lisp-Notes/Macros.html) and being able to easily have our programs generate code at runtime. As you spend more time reading and writing Lisp code, a funny thing happens. The parens fade [into the background](http://www.loper-os.org/?p=295). Relevant [xkcd](http://xkcd.com/297/).
I don't like parentheses without limits either. But fortunately in Lisp, the contents of each `(` is limited by its closing pair `)`. Ain't that nice? :P Most Lispers have configured their IDE to make handling `()`s as effortless and unobtrusive as possible. In my Emacs setup, they fade into the background a bit, so my eyesight remains unharmed (I got poked in the eye by a stray `)` as a Lisp newbie, and learned my lesson. Though `}` is more dangerous IMO. And don't get me started about fancy LaTeX brackets, I usually wear protective goggles when writing math). When it comes to editing, I have yet to find something that rivals [Paredit](https://github.com/emacsmirror/paredit). I have never checked alignment manually—why should I waste my time doing things that can be fully automated?
Well, I am not an expert language. But contrary to the other answers I do think someone could implement a lisp interpreter which would use indentation as a delimiter, *without* removing the power of homoiconicity or power of s-expressions. I feel there is a one-to-one relationship between an s-exp and the equivalent with indentation only: an increment in the level of indentation from on line to the other denotes an opening parenthesis, and reciprocaly. The same for closing parenthesis and a decrement in the level of indentation. Maybe such implementation could a little bit harder for the lisp interpreter developer, but I don't think it would be harder for a lambda final user. People are developing in Python every day and never complains as far as I know. :-)
Python has no s-expressions and also no macros. If you want to use Python use it. It is possible to use Lisp with an indentation based textual syntax. There have been various more or less successful attempts since the 1960s. But for some reasons it didn't find much support among Lisp programmers. You might want to find out why that's the case.
Lisp data structures, which are the input to EVAL, can represent cycles/etc. since decades. The printer/reader has been extended many years ago to be able to represent some of that. 
You don't even need a full interpreter, you just need reader macros. See [readable](http://readable.sourceforge.net/). The problem about using indentation is that parenthesis make the tree-structure CLEARER, so it is easier to create macros with them.
I'm having trouble understanding what you want to make, but I guess I'll ask, what are you wanting to accomplish that you need to do much crypto computations in the context of a browser addon?
s-expressions also allow it to move code around a bit more easily. Also code does not need to be indented everywhere. Source code is data internally and after inventing a printed representation for it as s-expressions, it was found to be easier to work with. Many Lisp programmers don't think about code as text, but as data. This data is better (more usefully) externally represented with s-expressions.
I've always been of the opinion that relying on indentation as a hard syntax requirement (ala python, not just for pretty printing) makes it hard to move code around, because indentation levels are affected by every prior indentation scope level. If you suddenly move one section of code from one place to another, your editor (or you) has to keep track of the indentation levels below the section to be cut in relative terms and then transform them when the code gets placed.
The whole 'must be s-expressions only' has nothing to do with homoiconicity, [Julia](http://julialang.org/) for instance is homoiconic. You can have all sorts of shit and have it basically not affect the homoiconicity. With the following rules, you are not limited at all in using homoiconicy: * a list starts one line before an indentation * ends when the indentation level reaches the original * stuff within parentheses works as usual and whitespace in it is ignored. * idem for strings etcetera. * `|` puts the rest of the line in a list * `,` splits any lists into sublists between those (screw it another one) Added the latter so you can do `let | a 3, b 3` something like \``(....)` still works as usual. I find the whole discussion stupid. People put off by the s-expressions are being silly. But they're gonna stay silly. Besides with two simple concepts of 'beginners and enders' and a sequence of infix symbols that have some particular order, you can produce something *much* closer to what people are used to. [I tried to suggest it to Julia](https://github.com/o-jasper/Treekenize.jl), but it didnt catch. I mean a homoiconic language *should* be clear about how the syntax works, and it should be simple. Other than that they dont have the syntax clear enough,(presumably they havent changed it much.) I reckon Julia is on the money. (kindah need it more portable/less of a dependency i think, even that makes it slower version interpreted by something)
You could do this if you want, just write your own READ.
Just use emacs with paredit. 
As Triclops200 pointed out, the parens are not syntactic sugar. Lisp is a language that describes data structures (like XML), and then (unlike XML) interprets those data structures as instructions. This is what is meant when people say "In Lisp, Data is Code and Code is Data". This has profound practical implications. In Lisp, you can write code which writes code. Since code is described as lists, you just write a function that creates a list. These are called "macros". That is an incredibly powerful technique that allows you to extend the language with new language constructs. For example, in most other languages "AND" and "OR" are special keywords. In Lisp, they're just macros created from "IF". The entire object-system of Common Lisp (CLOS) is essentially nothing more than a set of macros. You can build up domain specific languages really easily this way. In Lisp, you're writing lists. When a list contains a list, you're representing a tree. In fact, all compilers and interpreters internally translate code into trees - what is referred to as the ["Abstract Syntax Tree"](http://en.wikipedia.org/wiki/Abstract_syntax_tree ). The compiler can then manipulate and optimize the code or translate to run on different processors, etc. In Lisp, you've got direct access to the AST. Feel the power.
There have been a [great many attempts](https://www.google.com/search?q=alternative+syntax+lisp) at alternative syntaxes for Lisp. The [first one](https://en.wikipedia.org/wiki/M-expression) was from John McCarthy himself, and he couldn't be bothered to finish implementing it. People who like Lisp usually don't like them. People who don't like Lisp still don't like Lisp if the syntax is changed. There's no point in trying to develop alternate syntaxes for Lisp. That said, there are a lot of ways to streamline the syntax of common operations. Clojure, for example uses fewer parens in its versions of let and cond. Idiomatic Clojure often makes considerable use of the [thrush operator](http://www.emacswiki.org/emacs/ThreadMacroFromClojure), which is easily defined in other Lisps.
&gt; The entire object-system of Common Lisp (CLOS) is essentially nothing more than a set of macros. There entire object-system of Common Lisp is a complex bunch of functions, macros, types, classes, objects, generic functions, methods, ... The lowest level is implemented as classes and generic functions. The next layer is a set of functions. On top of that there are some macros...
Agree. I oversimplified. (Did you downvote me for that? )
'oversimplified'? I would say 'wrong'. ;-) Here is the source of the original implementation: https://github.com/ubikation/portable-common-loops
Is this significantly different from keeping track of parentheses? In both cases, editors have great tools to help with this, and once you've become accustomed to them, it becomes second-nature.
Good question: https://turtl.it. Right now it's more or less a client-side encrypted Evernote clone (but with a much better interface, if you asked me). I want to move it onto desktop as well though, and add dropbox-like file syncing (ie, point it at a folder and your files are encrypted then synced so you can access them from anywhere). The idea is all crypto happens client-side, and as a result only you and those you specifically share with have access to the data in any capacity. The people running the servers have no access and neither do hackers or the NSA. Right now the API is written in common lisp, and if possible I'd like to stay on one of the two current platforms: common lisp or javascript.
The interested reader could also dig up the discussions of that library on this forum.
&gt; Because s-expressions are the most powerful data structure. The site reminded me of [this](http://realultimatepower.net), but without the sense of humor.
You ask why we do not use indentation instead of parenthesis to make it easier to edit and read lisp code. You have an idea of your destination, but how well do you know your starting point? To save the eyes, as you say, I use line breaks and indentation. Typically I would use the same line breaks in the s-exp version as you used in your white space version, with the exception of the newline after cond. I'm also a fan of syntax highlighting. To reduce effort to deal with parenthesis, I use editor functions and modes for them. Describing Emacs' s-exp facilities and paredit would get lengthy, but the bottom line is that with some effort you can make editing s-exps very comfortable -- for me it became competitively comfortable with editing other code formats and often I even prefer it. I also swap [] with () on my keyboard. So I feel that I have competitive readability and writability between lisp and other languages. Then why not make a big change to try to improve that? For most of the same reasons that I wouldn't in any other language. 
That's what I actually mean. Thanks for pointing out.
that means I have to force someone to use "good" editor before they start learning lisp. It's hard to convince anyone without prior exprience to deal with a lot of parenthesis plus emacs.
I'm looking for a uniform and regular solution, not tricky skills.
Thanks for the tips, I definitely use these a lot! Very useful, especially in C or Javascript do `ci{` and change an entire block instantly. 
Is that supposed to be easier to read than this? (defun abs2 (x) (cond ((&gt; x 0) x) (t (- 0 x)))) or this (defun abs2 (x) (cond ((&gt; x 0) x) (t (- 0 x)))) or this #lang racket (define (abs2 x) (cond [(&gt; x 0) x] [else (- x)])) All of these are as readable to me and they allow me to switch between them without even considering something like newlines, tabs or special characters ever breaking my expressions. Using parens (or brackets + parens like Racket, which is easily the best solution) is robust and never breaks.
Furthermore, each line as a list, inner identations as outter's parameters defun abs2 (x) cond (&gt; x 0) x t (- 0 x)
Then I can't switch the formatting around if I want to(, right?). I need to be able to add or remove newlines as is appropriate for the function I am using. I use newlines to make things clearer in each case, which sometimes means keeping condition and expr on the same line and sometimes it means keeping them on different lines. Also, sometimes I need to newline in the middle of an expression (several times) to keep a hard limit of 80 columns in my files (yes, that is a priority). (define (start-download url parent [chunk-size (human 100 KiB)]) (thread (lambda () (download/report parent url (get-pure-port (string-&gt;url url)) (open-output-file (last (string-split url "/")) #:exists 'replace #:mode 'binary))))) Then becomes: (define (start-download url parent [chunk-size (human 100 KiB)]) (thread (lambda () (download/report parent url (get-pure-port (string-&gt;url url)) (open-output-file (last (string-split url "/")) #:exists 'replace #:mode 'binary))))) And this would theoretically become (?)
While this must be possible, I will reiterate what KDallas said, when: - I edit Python code and I copy a block of code to a new location, I often have to spend a few minutes getting the whitespace right as the copy put lines an the wrong indentation level. - I edit Lisp, I am often joining lines or breaking lines based on the horizontal space in the file. This means that joining lines and breaking lines needs to also strip or add parentheses. I have not found the tools in Emacs (or elsewhere) to provide these facilities. Then again, I haven't been looking as s-exprs work fine for me; I just program less Python and am annoyed when I do. There is one non-editor support reason I can think of. Every time I write a macro a start by writing what I want the form to look like, then what it must look like in order to run, then a function that maps between the two. It seems silly to add a special step in that where I must mentally translate to s-exprs when figuring out that map. This is particularly the case if I fundamentally think in terms of your syntax and think of s-expr as a kind of IR that the macro system uses, which would be the case if I learned Lisp at a time where this was the predominant syntax. That seems like a real hurdle for macro writers.
&gt; I edit Python code and I copy a block of code to a new location, I often have to spend a few minutes getting the whitespace right as the copy put lines an the wrong indentation level. What editor do you use? The copy pasted code should still be at the same relative import levels as each other, so the worst case scenario is: * Put the first line on a new line and fix its indentation * Press your editor indent/unindent hotkey a few times until it's at the right level for you code. * Search and Replace tabs/consecutive spaces to your own codebase's standards (though for Python you should use PEP-8, which wants four spaces, for consistency with nearly every Python codebase)
I use Emacs. The process I go through: 1. Take a block of code and copy it. 2. Move to the line where I want to insert the code, at this point assume that point is at the correct indentation. 3. Insert the code. The first line has the correct indentation level, the rest have their original indentation level. 4. Find a way to increase or decrease the indentation of the rest of block by a fixed amount. There are smart ways to do this and there are dumb ways to do this, but I think it is pretty dumb that copying the text severely damaged the semantic meaning of the code in the first place. This is not the worst case scenario, this is the every case scenario except for the special case where I want to copy a block to a place where the indentation happens to be exactly the same. This is distinct from "normal", non whitespace dependent languages where you can paste then run indent region, which works great.
&gt; This is distinct from "normal", non whitespace dependent languages where you can paste then run indent region, which works great. I don't understand, how is it different? I also use Emacs for Python and Lisp, and the exact same thing happens in both cases. The thing you describe - the first line is indented properly, the others not so much. In both cases you have to manually fix this. Of course, the Lisp code would run despite how it looks like, but I'm still not going to run it before it looks properly. The amount of work to indent them is exactly the same for both languages - you select the stuff you want to indent, and press Tab. 
So I was hoping this conversation would be a learning experience, and it was, so thanks. I have been moving through line by line and modifying the indentation. The only issue I see is that the indentation program inserts a bunch of whitespace only lines, but those are easily removed. I will say that I don't quite understand the heuristic that it is using to determine the indentation level, and I'm not entirely sure what to expect it to do in every circumstance...
I can't for the life of me imagine what problem this is trying to solve.
&gt;In both cases you have to manually fix this. Of course, the Lisp code &gt;would run despite how it looks like, but I'm still not going to run it &gt;before it looks properly. It's your choise, it's up to you. But I, personally, rather choose to C-c C-c as soon as possible and gain the implementation speed. And lisp gives such freedom to the users. I do indent-region sometimes when I paste something. sometimes not. It's up to me and the compiler wont complain about it. Of course, for short functions it doesn matter, I agree, because I hit tab often without thinking and also selecting the whole code is easy. However, consider the situaton you are writing a big implicit progn... it's far from a good way to implement things, but in some stage of development it might be needed, how it looks definitely does not matter there. I don't say the appearance is unimportant. I do indent-region. but not that time. I rather do it at the end of the day, when I close emacs, or when I commit, or when I move to another source file. I select the whole file and indent-region.
In my opinion, using a parens to indicate the function head and macro head is unavoidable. However, implementing "something that appears in other language" which is local in that macro is possible. loop macro would be a good example, though I love iterate: (loop for i from 0 to 100 do (something) while ...) the tab and the space means nothing there but the editor detects "loop" and a loop kewword "do", then indent correctly. Therefore, if you want a "cond" with haskell-like case notation you can implement it yourself, though "|" is already defined as a reader macro in cl. I mean, something like this: (cond | (&gt; x 0) x | t (- 0 x)) the macro head is "cond". How to implement this would be straightforward: (1) disable the cl-defined reader macro "|" (2) during the macroexpansion, if the compiler finds '| then the rest of elements before the next '| are treated as ... etc.
It's interesting. Mostly though the missing parenthesis completely obscure what's going on for me: echo foo bar baz | shly loop :for x = '(read *standard-input* nil)' while x :collect x tells me: Usage: loop [&amp;rest keywords-and-forms] So, I end up having to instead do: echo foo bar baz | shly progn '(loop :for x = (read *standard-input* nil) :while x :collect x)' It still saves me a few keystrokes: echo foo bar baz | ccl --eval '(print (loop :for x = (read *standard-input* nil) :while x :collect x))' --eval '(ccl:quit)' but not many....
More info from the author: This bike configurator just soft launched yesterday evening. Hopefully you will not see any Hunchentoot stack traces :-) The project is a web interface for configuring fully custom folding travel bicycles that are made to order in Oregon. Prior to this launch the only way to buy one of these was to visit the factory or call a highly-trained sales consultant. You may need to go light on the checkboxes on the search page to get matching starting designs at this point. One of my favorite parts of the project is the custom cartoon generator. Bike Friday builds so many bicycles that to photograph everything would not be possible. Even with the limited component selection displayed in the cartoons there are over 15,000 cartoons generated just for the ~130 starting designs so far in the system. The cartoon generator works by using CXML to load a master SVG file, remove all but the appropriate layers for a given model, and then colorizing different parts of the bike using a mix of SVG patterns and RGB hex codes depending on the bike and color selection. It then uses ImageMagick to convert the generated SVG file to JPG. Everything else is fairly basic Hunchentoot and Postmodern stuff. Quite a bit of the data and searching on the site is done using read-only in-memory indexes that are generated from snapshots of the SQL database. The basic frame of the web design is taken from the CMS used for the rest of the site and makes the page loads slower than they would be otherwise. Libraries used: CL-FAD CL-MARKDOWN CL-PPCRE CL-SMTP CL-WHO CXML HTML-TEMPLATE HUNCHENTOOT IRONCLAD DRAKMA ITERATE LOCAL-TIME POSTMODERN SIMPLE-DATE Let me know if you have any questions! If you're curious about the bikes here are some videos: * The most recent carbon belt model reviewed by Adventure Cycling (video): http://www.adventurecycling.org/resources/blog/video-review-bike-friday-silk-road-alfine/ * The fastest-folding model: http://www.youtube.com/watch?v=fQscBxx7wLE * Sometimes we get a bit too custom: http://www.youtube.com/watch?v=Nc4GnkHWE0I 
On behalf of what must be thousands of redditors who are both Lisp programmers and Bike Friday owners, I declare this to be (* cool cool).
Thanks!
Quite opposite, I find this idea very useful. One of the things I was missing in normal shell is eshell feature, where elisp function can behave as normal command. With this, we can get similar thing... The only thing I'm worry about is startup time; if author gets this solved, this will be my ultimate tool.
In the context of my comment, the difference is that I as a human being don't have to bother with keeping track of the indentation level. I now have a difficult time without a smart editor to make certain that the code reflects my intent. I will admit that the flipside to this is that in lisp, a common theme of advice for initiates is to get a smart editor to handle the parenthesis for you, but it seems like there is less required of the programmer in order to make the code reflect the programmer's intent when using lisp. If I suddenly wrap a long set of lines inside a new level of scope, every inner line must be updated before the program reflects the intent. In lisp, I place 2 parens. In the spirit of your question, I would say, imagine writing such a smart editor to allow the user to keep track of indentation levels for the user for each language. In lisp, I walk through the document to count parens. In python, I find the whitespace (tabs or spaces or mixed? the language allows for both at once I guess, so I'm guessing here) on the front of the current line. save this as base scope level, go to next line, repeat until you find an empty line, for which the prior line matched the level of initial indentation 
this is very specific to osx and ccl, but the ccl repository has an example of interfacing with webkit, and the example code spawns a browser instance inside lisp. Also, how do you guarantee that Alice can no longer decrypt Bob's data if she obtains it out of band, and stores the key Bob gave her out of band?
(expt cool 2)
Now add a "Made with Lisp"-icon at the bottom ;)!
Is there any reason that you decided to use Hunchentoot directly instead of using something like RESTAS?
Thanks, that's a really helpful tip. I may be able to use that in a more general sense. As to your question, the answer really is: it's impossible. You cannot reasonably expect that when sending data to someone they won't be able to store it. No crypto system does this. You can program the client to delete the local data and key(s) if the share is terminated (which Turtl does) but if Alice has copied the decrypted data into a file not controlled by Turtl, then that's that. At some point, you no longer control the stream of data and must be transparent about your lack of control. For instance, we could try to build in-app viewers for every type of data that wouldn't let you save files or copy/paste (ala Snapchat with files/text), but it would be a huge undertaking and wouldn't account for things like screenshots, opening the app in a debugger, changing the client's source, etc. Not to mention it would cripple the app's usefulness. The official response is if you don't trust Alice with your data, don't share it with Alice =]. EDIT: As a followup, I thought I'd mention that it's on our (long) TODO list to be able to regenerate the keys for a shared object, so if someone has keys stored from a previous share, it would be possible to lock them out from decrypting *new* versions of the data even if they someone managed to get passed the app's security measures.
Which one?
http://www.lisperati.com/logo.html or http://tapoueh.org/images/made-with-lisp.png I can't find the original source for the second one unfortunately (and therefore no license).
&gt; Why would I need Perl for this? For allowing users to choose which Lisp implementation to use, the startup script has to be independent from Lisp.
I admit Shelly is not suitable for executing complicated code. Instead, you can define your own commands in ./shlyfile.lisp and ~/.shelly/shlyfile.lisp. https://github.com/fukamachi/shelly#declaring-project-specific-commands It is intended to be like a Makefile for Lisp projects.
So thats the subtle difference I was wondering about, granted alice can decrypt whatever you've given her a key for and save it out of band, but what about future updates to that dataset? How do I prevent alice from decrypting future content once I want to revoke her access?
You should try [ScriptL](https://github.com/rpav/ScriptL) by Ryan Pavlik. It starts a server in a running Lisp, and then executes commands given by its command line client, with input and output connected to the shell.
Can't the shell do this?
The prototype implementation of the TiCL idea [is published on GitHub](https://github.com/didierverna/ticl-for-TUG2013).
I used Guile myself when I was working through those books. It integrates nicely with Geiser-mode along with Quack. Geiser also supports Racket too, so those are options if you are into emacs.
Going through "The Land of Lisp" now, gonna do this when I'm done with that to learn both more Lisp and Haskell - excellent idea, good sir! I also have "the art of computer programming" at home, and intend to use it to teach myself assembly language.
as for the second one: [this](https://groups.google.com/d/msg/comp.lang.lisp/dOS2dMSSTHg/xLtJ3gOmlXsJ) is the original announcement on comp.lang.lisp. The logo is by Manfred Spiller unfortunately the lisp logo link is no longer working.
It's a nice idea, but I can't see it being adopted because the end result is TeX-ish but not TeX, no LaTeX either. It's a programmatic face lift, which would be nice, but for adoption you need a killer app. 
You must pass the socket file descriptor to make-ssl-client-stream, not the stream itself: use (iolib:sockets:socket-os-fd socket-stream)
Yeah, thank you, I tried this, and it didn't work, but after reading your comment I tried it again, and it works! But there is a new problem, *cl+ssl:make-ssl-client-stream* returns flexi-streams socket, and iolib uses another type of streams. How can I convert flexi-streams socket to iolib compatible? Sorry for my dumb questions ;-)
You can get the underlying stream that flexi-stream is built upon! http://weitz.de/flexi-streams/#flexi-stream-stream
Put a (break) at the start of the function, recompile it in debug mode for more info with C-u C-c C-c, and when you hit the debugger at the break, use SLIME stepping keys described in its manual.
This looks very interesting (and well done), but any example of what I'd use this for?
Well, I would check if something is a symbol and the count 1 up. I would also check if something is a cons and then add the count of that list.
An alternative to adding a break is to (after recompiling with high debug) call (step (your-function-call)) at the repl. Step is not guaranteed to stop at every form and may look like it isn't doing anything if you test it on a trivial example, but it can be helpful. The trace facility can also be useful. Instead of format, if I decide to print the info anyway, I sometimes use print and take advantage of the fact that it returns the object it prints, so you can wrap a form in print and the program will still run. (It will only return the first value though, so don't do that in a case of multiple values.)
Or as an alternative to tracing, printing, or stepping, have a look at my implementation of PRINTV: a batteries included debug-logging macro. http://github.com/danlentz/printv
In addition to this, you should also see if the question wants you to differentiate between symbols and other data types, like numbers or strings. What do they want this to return: `(count-symbols '(a 2 "three"))` But you should only think about this once you get it working for any type of data.
What do you mean by "iolib-compatible" ? What are you trying to do ?
would the encrypted data ever live on remote machines, like dropbox? or would it be served on demand?
I'm sure a 1:1 translation into another assembly language will be fairly easy though, no?
I'm just trying to make SSL client stream from my iolib's socket. For example with usocket my code works good. You told me to get an underlying stream by flexi-stream-stream function, it returns ssl-stream from cl+ssl library. So, how can I substitute my IOLIB socket stream with this ssl-stream without reconnection? I'm just writing xmpp library, and one of the negotiation stages requires convert plain tcp socket into SSL tcp socket.
It does a bit more than that: http://common-lisp.net/project/slime/doc/html/Debugger.html What more do you need?
Usually homework requests are dismissed but for learning recursion you need to see examples. Here is my implementation in elisp. The "rest" function is the same as "cdr". You should read The Little Schemer. It drills the patterns of recursion into you. You'll be able to solve problems recursively in your sleep. (defun count (lst) (cond ;base case: if list is null it is empty ((null lst) 0) ;if head is an atom, combine 1 with recursion on the rest. ((atom (car lst)) (+ 1 (count (rest lst)))) ;else the head is a list. We must recurse through this sub-list. ;combine recursion on the head with recursion on the rest (t (+ (count (car lst)) (count (rest lst)))))) 
If it is possible I offer a combination of "flatten" in alexandria and "length". Otherwise I will implement "flatten" by myself.
Neat. I have always wanted to do this but separate the textual content from the markup entirely and split the presentation stuff into separate files that reference either line numbers or character numbers to denote beginning/end of styling rules. A text editor would be able to 'render' the compound style and resource files and provide an 'edit view' while a render engine would provide the final render output for finalized editing. If I could only win that powerball lottery to finance some of these things ... 
There it might be like this: a technical writer, who also is a common-lisper. ;-)
The linked introduction to LispWorks shows neither more functionality nor more usability (for an Emacs user) than SLIME provides. However, LispWorks indeed allows something more: to insert breakpoints without textually inserting a BREAK statement, and, if I am not mistaken, to do so without recompiling the function.
Once you wrap the IOlib socket in a cl+ssl stream, you can simply read/write to the SSL stream
Sadly it doesn't work. I use non-blocking read/write mode, in that mode I must to use *iolib.multiplex:set-io-handler* (second argument is *(iolib.sockets:socket-os-fd socket)*), so after calling *make-ssl-client-stream*, I get an error: There is no applicable method for the generic function #&lt;STANDARD-GENERIC-FUNCTION IOLIB.SOCKETS:SOCKET-OS-FD (1)&gt; when called with arguments (#&lt;FLEXI-STREAMS:FLEXI-IO-STREAM {ADB3919}&gt;). And I think it's logical.
but you progressed another step, what if you define method IOLIB.SOCKETS:SOCKET-OS-FD to return the fd of the underlying flexi-io-stream? &gt; I use non-blocking read/write i don't think it is a good idea, common lisp doesn't have the concept of "no data available yet". iolib introduces this concept at the expense of writing all io code from scratch and this code is incompatible with the standard io code I don't know how cl+ssl works except that it is a ffi wrapper, but I would be surprised if it was possible to layer cl+ssl streams on top of iolib streams. I'm curious to hear your results:-)
+1. I like how your solution has 1 combination operation, whereas mine had 2.
So, you talk about that in lisp we must to use threads for multiplexing IO?
you don't have to, iolib is a good example. problem is that the io semantics you choose have fundamental impact on compatibility of different libraries. usual common lisp libraries expect blocking io. If you do otherwise, you need to write your own version of the libraries to understand the chosen io semantics have you tried to define the method IOLIB.SOCKETS:SOCKET-OS-FD for flexi-io-stream? what happened?
No, I didn't. But I definitely will try. Thanks
&gt; You should read The Little Schemer. It drills the patterns of recursion into you. He should also read *How to Design Programs*. They drill that even more, I think.
that's purty
Right now it's architected such that the encrypted data is always synced to a remote server. Pushing it this way allows dropbox-esque syncing and sharing, without the need for two people to be logged in at the same time to share data. At some point I'd like to explore a more distributed architecture, but it's definitely an area I'd need to study a whole lot more to accomplish. There is a newer feature in Turtl (unpublished, but working) where your data profile is stored locally (via IndexedDB) and only synced incrementally. This could eventually drive things like offline mode or selective, peer-to-peer syncing between users. We're not there yet though =].
Yay for Lisp in school projects. I never had that, and its not like Lisp wasn't in use when I was young. Somehow the brain damage of BASIC was all the rage.
I don't use typecase much and on reflection think the numbers should be in one branch of the primary form. Using cond like you did is nicer: (defun count-syms (tree) (cond ((consp tree) (+ (count-syms (car tree)) (count-syms (cdr tree)))) (t (if (and tree (symbolp tree)) 1 0)))) 
SBCL warns about many suspect constructs by default, people often ask about turning them off.
You have been asking this question before. http://stackoverflow.com/questions/6893241/is-there-a-lint-for-common-lisp-or-chicken-scheme
For s7 scheme, there's lint.scm in the s7 tarball or the snd area at sourceforge. There used to be something similar in Guile (was it named guile-lint.scm?) 
Depends on how similar the instruction set architecture is to MMIX, I guess! It's a RISC design, similar to MIPS and ARM (though the ARM instruction set's getting more complex), and rather different to, say, x86. On the other hand, it may well be easier to learn MMIX assembly to get your head round programming at such a low level before you deal with the complexities of real-world assembly languages.
The novelty of the UI wears off quickly.
Yes, I think that's reasonable. Also, of course, no one should listen to what *I* say: if you want to write a *TeX replacement you should!
In particular it gives two of my favorite language universal warnings: undeclared/unused variables, and undeclared functions. These features are mentioned prominently on some of the tools the OP posted. Skimming through the docs on some of the other mentioned tools it seems that much of the warnings they give are either for language specific gotchyas, or for style guide enforcement. It's interesting to consider what additional analysis might provide the most benefit for lisp. 
I read a lot of code (flexi-streams, gray-streams, trivial-gray-streams, sbcl's streams), but I didn't find how to get the file descriptor. My google-fu also didn't help.
Wow, this is really cool. I looked at it when you first posted it to github, but didn't realize you had done so much additional work. (Including the nice readme, I don't know how much is new and how much I didn't discover the first time.) I keep a variant of the simple debug logging macro around (e.g. print all of the included forms and their return values). The biggest immediate problem I have with that naive approach is not exposing the workings of bindings and conditionals. The way you are printing let and cond forms here looks like a very large improvement over that. 
SBCL already does warn about some gotchas. For instance, it warns if you use a variable named \*something\* but are using in a lexical binding. It also notices if you are trying to call a destructive function on constant data. Another good gotcha would be detecting if you use a destructive function but don't bind the result, but this is not detected.
You can check them statically: http://logaan.github.io/clojure/core.typed/2013/08/29/first-look-at-core.typed.html But you're probably looking for one that will work without any additional (type) annotations.
Not function call depth, sorry, lexical depth. Eg, show what is happening more sensibly when LET forms are nested
Why are you calling socket-os-fd on the SSL stream ?
I don't. It's just an example. My current question - how can I get os-fd from flexi-streams' socket?
It is, somewhat. Not all destructive functions are annotated to trigger that style warning; for example it makes sense not to use the result of SORT on a vector, so we'd need extra logic. CL-USER&gt; (compile nil `(lambda (x) (nreverse x) nil)) ; in: LAMBDA (X) ; (NREVERSE X) ; ; caught STYLE-WARNING: ; The return value of NREVERSE should not be discarded. ; ; compilation unit finished ; caught 1 STYLE-WARNING condition 
Curious as to why SourceForge. There have been some troubling reports that have come out recently about some of their practices that include a campaign to encourage developers to provide an "Installer" based distribution incorporating various forms of adware. Of course, I remain a fan of the closer projects regardless. 
In my reading of the CLHS, NREVERSE is not guaranteed to modify the existing array. So even though most if not all implementations do it, you shouldn't rely on that behaviour. 
Rely on what behaviour?
Hey! I know it's been a while, but just spent a few days [documenting Turtl inside and out](https://turtl.it/docs). Let me know if you have any questions or if you think it's missing anything. Sorry for the delay, had to juggle a bunch of priorities with the project. Just recently decided to do a feature freeze until I get some non-programming tasks finished (including docs).
flexi-stream wraps flexi-stream-stream. whatever flexi-stream-stream is, the fd will be somewhere inside. Easiest to find out is to reproduce the error you got in slime, let the stack trace pop up and inspect the objects in slime inspector and also use M-. to navigate and peek around interesting code. There will be layers of streams (two?) with the last layer containing the fd. Then you need to find accessors/readers/functions to get hold of the fd and put it in the IOLIB.SOCKETS:SOCKET-OS-FD method.
Excellent! :-) We need more documentation to help ameliorate the social problems of Lisp. Nice to see someone working on this.
You cannot get it directly.
Very nice start. Some questions: 1. Would it be desirable to change the page title as I navigate through the dictionary? Then when I hit the back button for history, I can jump directly to a previously-named point in the history. 2. I don't know if this following author will accept updates, but if you could get this project included in this very [highly-ranked (by Google)](https://www.google.com/search?q=common+lisp+info+documentation+generator) and [useful brief survey of CL documentation generators](https://sites.google.com/site/sabraonthehill/lisp-document-generation-apps), as well as on the [CLiki page](http://www.cliki.net/documentation%20tool) for documentation tools, it may help gain traction for your project.
Yes, I did all of these manipulations except stack trace inspection, and I didn't find any accessor or reader for fd. That's the problem.
(defun count-all (list) (cond ((null list) 0) ((listp (car list)) (+ (count-all (car list) ) (count-all (cdr list)))) (t (+ 1 (count-all (cdr list)))) )) Basically, don't go straight to adding one and going to the next. Check if it is a list, and if so, call count-all for the car and the cdr, adding them. 
Thank you for the kind words on the survey page. Yes, I am willing to keep the page updated, I just have to find the time to run the tests. If people find my occasional library comparisons useful, I should ask for other comparisons that people would like to see. 
It's not really related to functional programming, except that I've run into a bunch of people that hear the high-level explanation of flow-based programming and immediately have the reaction "Oh, this is just functional programming" or "Oh, this is just actors". Our use case for FBP is as a structuring tool for heterogenous systems. The end goal is to be able to take visual representations (something like the images I posted in the article) and turn them into networks of intercommunicating parts. The idea is that this will make it easy to change large systems, without losing sight of their architectural structure. Because the "parts" are all completely separate, you also get all the usual benefits attributed to the actors model (reusable pieces, easy visualizations, simple porting from one machine to multiple machines). Just as an addendum: as I said in the article, I'm not an FBP true believer quite yet. I'm going to throw the next few years at trying to figure out whether its effects are worth the extra code and odd structures, but I don't know yet. I'll poke my co-workers about it (they both have much more experience with this approach), so they can hopefully answer questions.
While you're here, a word from the author. If you're a Lisper in the Greater Toronto Area who found this article interesting, drop me a line. We're currently hiring developers for our team.
Thanks for the post, looks interesting.
How does this relate to Hoare's CSP? On a cursory scan through the post it seems like FBS and Clojure's core.async would work well together.
It has nothing to do with DOTIMES. SORT is a destructive function. It changes the list. You give it a literal list. Each run may change the list destructively. 
So, the difference in implementation is that CLISP's DOTIMES (apparently, breaking expected behavior) copies the list for each run, whereas everything else has it operate on the same object? Thanks for the clarification. This doesn't seem so weird to me now.
Sorry, I meant DOTIMES. DOTIMES just iterates. CLISP just uses a different implementation of SORT. For example: * one SORT might reorder the cons cells. Then you see such an effect as you describe, that the list gets shorter. * another SORT might keep the cons cells and reorder the contents. Then the list stays the same in length, just the contents get sorted. LispWorks: GRAPH 25 &gt; setf l1 '(a b c d e f g) (A B C D E F G) GRAPH 26 &gt; sort l1 (lambda (x y) (oddp (random 10))) (D A E C F B G) GRAPH 27 &gt; l1 (D A E C F B G) GRAPH 28 &gt; sort l1 (lambda (x y) (oddp (random 10))) (E A D G C B F) GRAPH 29 &gt; sort l1 (lambda (x y) (oddp (random 10))) (E B A D F G C) GRAPH 30 &gt; sort l1 (lambda (x y) (oddp (random 10))) (A D B G E F C) GRAPH 31 &gt; sort l1 (lambda (x y) (oddp (random 10))) (G D C F E B A) GRAPH 32 &gt; sort l1 (lambda (x y) (oddp (random 10))) (B D A G C F E) Btw., don't be puzzled by the parentheses. In LispWorks' REPL I can omit the outer parentheses. 
I'm talking about GNU CLISP specifically when I say CLISP; I'm just speculating as to why it behaves differently than everything else while running this code. Thanks for taking the time to explain more though.
Yeah, sorry about that. But, when I read the CLHS entry for SORT, it doesn't seem so clear-cut to me that it guarantees that the function sorts arrays in place. Reading the sentence that precedes the one you quoted, we see the following: "The sorting operation can be destructive in all cases. In the case of a vector argument, this is accomplished by permuting the elements in place." The key word here is "can". The way I interpret it is that it's allowed to be destructive, and when it is, it permutes the elements in place. The entry has the following sentence: "If sequence is a vector, the result is a vector that has the same actual array element type as sequence.". This sentence doesn't make much sense to me if there was a guarantee that the array is modified in place. You'll also notice that the example assigns the result of SORT to a variable, even when the array is already referenced by that variable: (setq committee-data (stable-sort committee-data #'string-lessp :key #'cadr)) Finally, there is a note at the bottom of the entry that reads: "If sequence is a vector, the result might or might not be simple, and might or might not be identical to sequence." Are there any other references in the spec that states that the array is modified?
in cl, your example corresponds to something like (defun foo () ... (list :out "something" :log "something else")) (defun bar (&amp;key in) ... (do-stuff)) (defun baz (&amp;key in) (do-other-stuff)) (defun box (&amp;key (foo 'foo) (bar 'bar) (baz 'baz)) (destructuring-bind (&amp;key out log) (funcall foo) (funcall bar :in out) (funcall baz :in log))) you created new syntax where * your functions (parts) can have implicit input args (&amp;key in) * your functions (parts) have named return values * you introduced strange infix syntax for calling functions with some arguments as far your argument about separation goes, your example is pure matter of code factoring and has nothing to do with deeper semantical concepts. you just refactored the knowledge of bar and baz from foo to another function above is "more" lispy translation of how one could write your code. now it is almost simplified to essentials, that it is more convenient to think about semantics. if you abandon sequential evaluation when thinking about the code above, you'll get closer to scheme. if you want spreasheet like behaviour with automatic async updates, you might have a look at cells (dataflow extension to clos). however, if you find out that your concept of time is discrete and any calculation is fast enough from one step to the next step, you can avoid all this complexity of managing cache updates (which is what any dataflow machinery is about) and simply synchronously compute things with plain cl. For example, in your web app, discrete steps are when users click on something. It makes sense to cache only things that would make the response too long and in those cases, it's better to have special purpose cache which is easier to manage. also, pictures are nice to have sometimes, but source code scales much better note: if you go with the "asynchronous operation is the norm" route, you should be aware that this is exponentially more complex than using synchronous semantics Edit: code formatting + bugs + note.
The spec also says "sort and stable-sort destructively sort sequences according to the order determined by the predicate function." in the first line. Compare that wording with "nreverse might either create a new sequence, modify the argument sequence, or both. (reverse does not modify sequence.)" I'm not sure that was the intention, but given that notes are not normative…
I've had more or less that same conversation with some FBP stalwarts, and I can just point out the assumptions we both seem to have made: - That `box` will always only be feeding its arguments to one part, whose output will then be propagated to other parts which must run in serial. - That every part will fire on all pins simultaneously. - That there will always be one `:log` message for every `:out` message provided in a given part. - That a given part will always produce one output given one input. The first three happen to be true for the off-the-cuff pseudocode I posted in the article, but certainly aren't true in general. It's possible for a container or sub-map to feed multiple initial parts, and those chains are each expected to work in parallel with each other. It's possible for a part to send messages on multiple pins simultaneously, or send messages on just one pin, or send multiple messages on one pin and single messages on another. For example, this is possible: (define-part foo () (when something (out! :log "Something happened...")) (when something-else (out! :log "Something else happened...")) (out! :out "A message")) Finally, a part doesn't necessarily produce output given an input. For instance, in the server images on my post, there's a box labelled "Request Buffer", which might consume multiple inputs before emitting *any* output, but will probably emit output regularly. It's also possible (though I haven't used them myself yet) to have "splitter" parts that produce multiple outputs for each input. I agree that there's probably a simpler way of getting the same effect in CL, but I don't know what it is, *and* I've become convinced that `funcall` won't do it trivially. Which means that I don't accept the code you post above as analogous to an FBP system. I tend to agree with you about pictures vs. code in terms of construction, but I've observed some pretty good results in documentation and presentation contexts so I'm reserving judgement until we actually deploy a few systems. The trade may end up being worth it, and I don't want to make a call before seeing it in the wild. As for the reading recommendations, [cells](http://www.common-lisp.net/project/cells/) looks interesting, and I'll be taking a close look at it. I do also plan to put together a minimal FBP system built on top of [Racket threads](http://docs.racket-lang.org/reference/threads.html?q=thread) to see how it would work. Can't comment on that yet though, because I haven't actually done the work; it'll probably get a write-up and I'll be around to answer questions if there's interest.
No idea, except that Hoare's CSP paper is cited in the [FBP book I'm currently reading](http://www.amazon.com/Flow-Based-Programming-2nd-Application-Development/dp/1451542321/). I'm ... kinda new at this.
This reply is an interesting example of the Blub Paradox ( http://www.paulgraham.com/avg.html ). IN:, OUT: and :LOG are not function arguments, they are "pins" (aka ports, sockets, mailboxes, unix pipes, etc.) on software IC's (ref. Brad Cox 1991). They decouple the components of a software architecture. The unix shell is a simplistic example of this concept - plumbing pieces of (decoupled, asynchronous) functionality together. Asynchronous semantics are exponentially more complex than using synchronous semantics *only when* you try to implement asynchronocity using synchronous semantics. RTOS'es, processes, preemptive multi-tasking are epicycles ( http://en.wikipedia.org/wiki/Deferent_and_epicycle ) necessitated by the use of call-return languages. In my experience, diagrams (concrete, compilable (e.g. not UML)) are vastly more scalable than syncronous textual code. I would argue that synchronous text has reached an asymptote (embodied mostly in CL, btw). Digital hardware is designed using asynchronous components, yet, the bug rate is drastically less than that for software. David Beazley can easily describe the construction of a traditional O/S using the concept of coroutines http://www.dabeaz.com/coroutines/Coroutines.pdf . I regard that to be a step in the direction of FBP... 
Nit: Digital design is usually done in text: VHDL/Verilog, and efforts have been underway for a long time to perform compile-to-VHDL.
The connections between FBP components are controlled by the parent component - siblings cannot "see" each other, they can only see their output pins and cannot know who the pins are connected to (if connected at all). This provides for hierarchical composition of FBP architectures. I believe that CSP and Actors, at least the earlier versions, required explicit naming / identification of the receivers w/o a "coordination layer" above a group of siblings.
Yeah, thank you, I know.
it depends on what you imagine under the term function. you can simply think of the arguments as pins, ports, sockets, mailboxes, pipes, whatever. they are simply inputs. Asynchronous semantic is always exponentially more complex than using synchronous semantics; asynchronous semantics leads to state explosion when components are combined. Introducing synchronicity exponentially reduces the state explosion when components are combined. No, digital hardware is pretty much all synchronous. I am aware of only one guy who does async chips which is Chuck Moore, the inventor of Forth. There might be other niche stuff but nothing mainstream. I still remember an OS made of coroutines, it was called Windows 3.1. 
To go into a bit more detail on that point, the [Common Lisp specification](http://clhs.lisp.se/Front/index.htm) notes in the entry for [QUOTE](http://clhs.lisp.se/Body/s_quote.htm): &gt; The consequences are undefined if literal objects (including quoted objects) are destructively modified. "The consequences are undefined" generally means badness. Some Lisp implementations will give you warnings to avoid that sort of thing. SBCL responds to your code with: ; caught WARNING: ; Destructive function SORT called on constant data. ; See also: ; The ANSI Standard, Special Operator QUOTE ; The ANSI Standard, Section 3.2.2.3 The reason for not defining destructive operations on literal objects is to allow literal objects to be created exactly once (possibly at compile time, if applicable), instead of each time the literal object is encountered. That's why quoted lists do not necessarily behave the same as lists created with `list` (which are not literal objects). The following would have the behavior you expected, with the list freshly created each iteration through the loop body: (dotimes (n 10) (print (sort (list 'a 'b 'c 'd 'e 'f 'g) (lambda (x y) (oddp (random 10)))))) (I'm not recommending you use `list` instead. Surrounding the literal list with `copy-list` is fine, though /u/sickofthisshit is right to [note](http://www.reddit.com/r/lisp/comments/1qg13x/weird_dotimes_effects/cdcgzc4) that the above is an unreliable way to implement a shuffle. Just saying it's important to know the difference between a list created with `list` and one created with `quote`.)
&gt; In LispWorks' REPL I can omit the outer parentheses. As an Emacs user, that made me want to steal that feature. For fellow Emacsers out there, here is how I would sort of replicate that feature in Emacs. I say "sort of" because instead of letting users omit top-level parens, I would simply let users not have to type the top-level parens (in REPL) and have Emacs highlight the top-level parens in different color (maybe grey, or to go in the other direction, a bold face). Ingredients: - rainbow-delimiters (latest version) Customization code: (add-hook 'ielm-mode-hook 'rainbow-delimiters-mode) ;; black top-level parens and grey non-top-level parens (setq rainbow-delimiters-outermost-only-face-count 1) (set-face-attribute 'rainbow-delimiters-depth-1-face nil :foreground nil :weight 'bold) ;; ;; grey top-level parens and black non-top-level parens ;; (setq rainbow-delimiters-max-face-count 2) ;; (setq rainbow-delimiters-outermost-only-face-count 1) ;; (set-face-attribute 'rainbow-delimiters-depth-2-face nil ;; :foreground nil) ;; Make () be inserted automatically at every new prompt in ielm mode. ? Not sure how to make that face customizations local to just ielm mode. Edit: Just realizing that using rainbow-delimiters for this is probably an overkill and brings complications. 
The main lesson to take is "never modify (in place) a literal list" ;; modifying a literal list. bad. (dotimes (n 3) (print (incf (car '(1 1))))) ;; prints 2 3 4 in some implementations ;; this surprising-to-beginners behavior is allowed by the spec. ;; I don't know why the spec allows it. Maybe for optimization? ;; good (dotimes (n 3) (print (incf (car (list 1 1))))) ;; prints 2 2 2 in every implementation Side note. Most sorting algorithms rely on the assumption that x &lt; y &lt; z implies x &lt; z, and your predicate breaks this assumption. 
I wonder how lispworks deals with a toplevel form that is a single symbol. It could inspect the symbol for a value or a function and treat it appropriately, but if it has both I guess it has to prefer one over the other, or ask. 
In my own OPFR (outer paren free repl) I look for whitespace, e.g. "\*foo\*" vs "foo ", but I think requiring the parens as in "(foo)" for single symbol calls would also be a good choice. (I don't know what lispworks does.)
This is why I semi-seriously advocate that people not use `quote` when what they want to do is construct a list. An invocation of the function `list` is semantically simple to the point of boredom: the arguments are evaluated and then the list function is applied to them and a list is returned, like any other function call in the Lisp universe. The semantics of `quote`, as the discussion in this post demonstrates, are somewhat more subtle and might even vary from implementation to implementation. Cognitively, to understand code with `quote` used just to construct a list requires that the programmer rope in a significantly larger portion of the hyperspec, maybe up to and including ideas like evaluation. Of course, in practice, the meaning of an expression containing quoted sub-expressions is straightforward, but from time to time you get cases like this. Use of `quote` falls into the category of silly and mostly harmless things programmers do to avoid typing a few more characters, but I think it might have real consequences. Think about the number of Lisp tutorials and introductions which use `quote` in the first ten lines, usually to just introduce literals. This introduces a lot of conceptual overhead to people looking at Lisp code for the first time and it does so almost without any benefit. I try to use `quote` only to denote things which will eventually be evaluated in the course of program execution. I use `list` to construct lists. Symbols are a weird case, here, that gets right to the heart of questions of hygiene, but I don't have time to get into it here. 
Endearing in the way of a small, cute dog that will, nevertheless, savagely bite your hand? True story: once I called sort on a list I got back from the mop and destroyed the class hierarchy in the running Lisp image (as I recall, an error was thrown by the `:key` I was using to sort by and so a large part of the list disappeared). It took us a few minutes to figure out what had happened, but we were working under deadlines. The mistake was obvious in retrospect, but when a programmer is tired, preoccupied, or working on a tough deadline, obvious mistakes happen. Part of how I evaluate a language is by how easy it is to make such obvious mistakes, and the mislabeling of `sort` doesn't really score in CL's favor here.
Was the author you quote also a developer of GNU Hurd, that would explain his assertions? The discussion about microkernels and monolitic kernels gives a hint where things go wrong with even-based architectures. When you introduce events, you need to deal with event ordering which when components are combined rises complexity combinatorically. Edit: typos
&gt; except stack trace inspection you left out the key part, that is the problem you might actually learn a lot if you try this exercise
why not?
A CL+SSL stream wraps a generic I/O stream which may or may not be backed by an OS descriptor. So the only thing you can do is get the underlying stream then use some implementation-specific call to obtain the file descriptor.
&gt; then use some implementation-specific call to obtain the file descriptor in other words, it is possible
Okay, thanks to all. I think there is nothing more to discuss. I will try to solve this problem based on your answers.
Yes, but not portably.
You don't seem to be familiar with the concepts of FBP, which differs from dataflow programming. This seems like an applicative approach, which it is, but it's based around components with no shared state, that send information packets through their out ports to the connected in ports of other components. There's no direct relation between sending a packet and activating the receiving component as if you were doing f(g()) , so that's why there's no simplification, connections are bounded buffers.
Nice write up. Glad to have a reference for how this is done.
The primary reason I was using a literal list in the example is that this code is in a function that's fed a list directly from another function. (it's for a toy flashcard system I'm making, and the order of tests needs to be random) Thank you for your thoughtful response, I'll keep these things in mind as I move forward. Another lesson I took from this: DOTIMES isn't the DO-LOOP or WHILE-TRUE loop of more imparative languages that simply loops over a literal set of instructions and executes them like a tape.
No problem, although, I should say, if it wasn't obvious from before, that this whole "use `list` instead of `quote`" thing is a little eccentricity on my part, and you aren't likely to run into a lot of lispers who care about these things. It is more of a way to just highlight the fact that there is a pretty big distinction between `list` and `quote`. I mean consider these things: (list x 1 2) ; error, presuming x isn't bound (let ((x 10)) (list x 1 2)) ; (10 1 2) (let ((x 10)) `(x 1 2)); (x 1 2) (let ((x 10)) (eval `(x 1 2))); (10 1 2) (let ((x 10)) (eval (list x 1 2))); (10 1 2) but for different reasons (funcall (let ((x 10)) (lambda () (list x 1 2)))) ; (10 1 2) if x is not special (eval (let ((x 10)) `(x 1 2))) ; error, if x is unbound I'm a fan of separating macro programming semantics from the rest of the language, to an extent, and so I think quote is a bit out of place in general Lisp code. If you want to represent a delayed computation, `lambda` is the proper abstraction. `quote` is for things which are supposed to be code, which should generally be handled by the macro-expansion system. Obviously there are lots of special things to consider and unusual circumstances, some of which are the very thing that gives Lisp its spice and power, so you know, bear that in mind.
Bummer, I was hoping it was more recent.
See [alexandria:shuffle](http://common-lisp.net/project/alexandria/draft/alexandria.html#Sequences)
What is missing beside recursive types? I have been messing with the internals of that for a while now (type-expand and such...) and pretty much everything seem to be there (beside recursive types I mean); not taken seriously by most implementations but that is not the spec that is to blame on that. (BTW, I don't think there is much needed in order to support recursive types either, just a small adjustment in the CL type expansion semantics, I guess it could easily be done as an experimental extension of the spec). Is there something I am misunderstanding here? 
I guess this is one area where lisp-1 implementations win out, as there is no ambiguity in a given scope what a symbol refers to. One day I'll get scsh running in guile and see how it goes interactively with an OPFR. As for lisp-2, being a Perl user I am partial to sigils giving a bit of extra information, #$foo could mean the value and #&amp;foo could mean the function, while foo on its own could inspect and prompt when its ambiguous.
simplified translation to elisp: (defun shuffle-list (l) (let* ((n (length l))) (do ((tail l (cdr tail))) ((zerop n)) (rotatef (car tail) (car (nthcdr (random n) tail))) (decf n))) l) note: destructive, does it in place.
I love this phrase: &gt; calling a function with too few arguments **is reported** with a segfault Look mate, is not a bug, is documented!
Many years ago, I worked in embedded software development. Our target platform was an ISA plug in card that had its own 386sx, and a serial port for a debugger. (It was fairly typical to have a null-modem connection that connected a serial port on the back of the computer to a debugging serial port on a board in within the same computer). Anyway, to get a debugging session started, there needed to be a way to transfer the debugger kernel over to the development card, so that it could start listening to the serial port for debugger commands. One of our better (but more eccentric) developers wrote this tool as a command line program we could run. The *entire* UI was that it took half a second if it worked correctly and about a quarter second if it didn't.... we had to watch it fairly closely.
You also don't have return type polymorphism (required to create monads) or type variables (IIRC).
I was using a Lisp interpreter/compiler on the Atari many years ago: Cambridge Lisp. http://www.atarimagazines.com/startv1n4/cambridgelisp.html This thing had very very little run time safety. It was mostly crashing... It was really frustrating. A Lisp with no compile-time safety and no runtime safety: the worst of both worlds.
&gt; The hypertrophied CL hyper-spec is their Holy Bible. The guy who wrote this, obviously never tried other languages with some sort of specification. C and C++ land are full of *Preachers Of Standard* that will quote you some section with undefined behavior. You can't use python seriously without reading at least one PEP. And so on... I don't think CL killed Lisp (Clojure is rocking pretty much nicely); maybe some history badges (lack of adaptability from big systems like Symbolics comparing to Unix) and lack of corporate interest, due large investment in current state: Java is popular thanks to Sun/IBM/Oracle pushes, Python thanks to Google, C/C++ thanks to AT&amp;T...
Of COURSE there was an IOCCC entry :-) http://www0.us.ioccc.org/2005/mikeash/mikeash.c http://www0.us.ioccc.org/2005/mikeash/hint.text http://www0.us.ioccc.org/2005/mikeash/Makefile
The novelty is its small size.
No it's not. Just google: small lisp interpreter under 4k 
http://symbo1ics.com/blog/?p=1495 has some info!
Wait. Is Kenny Tilton actually dead?
Agreed on all points. My pet theory is that programmers have a superior capacity for memorizing infinite syntax rules and abstract symbolic meaning so things like c++ and Perl really are not a problem for them. I just cannot get my self to work that hard.
Curious...does anyone here use GCL? If so, how do you like and what do you find its sweet spot is? I know SBCL has an awesome compiler and is de facto on *nix, CCL is multi-platform (and also pretty dang fast), clisp runs everywhere (plus bignums yada yada), ECL is embeddable. What is GCL known for?
I used it at a university in New York for an couple under grad AI courses. Not sure why the professor picked it, though I think it's the parity with older lisp systems. It's very quick for some tasks though the docs leave much to be desired.
GCL's build process involves, or used to involve dumping a lisp image which complicated porting it to a different platform. See [point 1.4 in the ECLS FAQ]( http://ecls.wikispaces.com/FAQ)
How do you use return type polymorphism with dynamic language? 
very nice &gt; It then uses ImageMagick to convert the generated SVG file to JPG. why dont you serve the svg image directly to the browser? they are quite capable these days. or are you using some svg feature which is still not reliable across browsers? I am in a process of rewriting part of an app from flash to svg+vml backend and it seems good enough these days. there are some issues so i have to do some things with vml (on ie) but it is fast and easy to work with on the whole
&gt; It would be cool to have a more expressive type system for example Doesn't it already have it, sort of? I was thinking of combining the [SATISFIES](http://clhs.lisp.se/Body/t_satisf.htm) declaration with a theorem prover. It wouldn't be fully general, of course, but it might still work for a large class of predicates, both regarding type checking and optimization. If you want something Haskell-like, though, that would probably be un-lispy. (Would that really play well with incremental development and compilation?)
Perhaps it would have been much more interesting to do a Lisp interpreter/JITter for GA144. ;-)
Are you sure you weren't programming in Forth?
In the past, the raison d'etre of GCL was to run Maxima. Other implementations strove for ANSI compatibility or whatever, GCL tried to remain Maxima-compatible. Or at least that's what I've heard.
I am talking about Common Lisp optional type system. If it were more expressive, it would have a way to emulate that.
Fascinating. Look like [] were used in this variant of Lisp to simplify the parenthesis writing- beginning a form with [ would force termination of paren up to the ] when a ] was written. Was this an INTERLISP feature? I notice the presence of NLAMBDA.
What, you've never used Scheme, not even just for fun? I love Common Lisp, but it is a big language.
Building on archlinux was a little problematic. Make sure you have texlive-core installed. Couldn't get it to build with the version of tcl/tk installed and the option for disabling it doesn't show up when you do ./configure --help. Here's the configuration that worked: ./configure --enable-readline --enable-ansi --enable-tcltk=no 
I saw it in Franz Lisp in the late 80's IIRC.
Further details. It is quite snappy, as reported elsewhere. It still doesn't export cl-user, and so you can't use quicklisp with it, afaik. That's probably the biggest issue for me.
Typically a single ] was closing all open (. That was used from the days of punch cards...
interlisp used `&gt;` as the closing "super-paren" iirc. was it interchangeable between them or sid it change between bbn and interlisp? 
What is the relation between GCL and CLISP? Why does GNU have two Common Lisp implementations? Which one is official?
GCL is officially GNU's but (last I looked) not quite CL. CLISP is only GNU because of readline.
I'm not the author of the above post and it is meant to compare the bignum performance only... one of the major imrovements in gcl 2.9.10. I hope someone will run a complete benchmark.
Interesting; the Interlisp system I've used (Lispf4) used `&gt;` as superparen (and `&lt;` to match), and I *thought* I had seen it else where (still have to dig out the Blue interlisp book). 
Nice, didn't know he had a twitter presence. 
What platform?
Emacs? 
This isn't a particularly easy question to answer. Where are you now? Are you looking for opinions about an interface? Have you ever coded before? What are your goals?
Start with reading [The Craft of Text Editing](http://www.finseth.com/craft/) by Craig A. Finseth. Even if you decide to organise your software differently, you won't regret reading this book.
Uh, there already are great HTML modes for Emacs. 
&gt; Much of HTML is just S-expressions with a different syntax https://github.com/Fuco1/smartparens
See http://www.quicklisp.org/beta/faq.html for how to get them added.
Note that the style promoted by LoL (especially the `g!`/`o!` macros) is not what most CLers would call uncontroversial. It is great to have the code for the book, it is full of neat ideas, but it is not something I would think of as a library I would use in production code.
Why is that? Is the code bad or just odd?
The semantics of some macros is not that great. There have been quite a few discussions on CLL, eg [a recent one](https://groups.google.com/forum/message/raw?msg=comp.lang.lisp/--CKgYFolK8/sIB7UtcpuOAJ). That said, I still like the book.
Don't be scared, fear will get you nowhere. Be curious - *that* is the way to go. Think of your task as a mystery, a puzzle to solve.
Ok, what code do you have so far?
Ok, do you know lisp at all? "build an html editor" seems like a really big project for a class -- are you sure you understand the scope properly? Building an editor is one thing, but then specifically for HTML? That's more complexity on top of it.
Windows. :-( OP, thanks much for posting, but you might want to mention system requirements near the download button. I had to DL it to find out what it was. On the plus side, it does work under wine.
All of the screenshots on the main page suggested Windows-only to me, but I agree that having it in text would help accessibility.
Is this software open source?
I don't think so, at least I could not find the source code. It looks free as in beer. I recently had to design something using a CAD system, and found [LibreCAD](http://librecad.org/cms/home.html) very nice, but AFAIK you can't use Lisp for scripting in it.
I am not trying to deprecate what you did, I just wanted make the point above because I think it is important. It is great that you made a repo on Github, now readers of the book can just clone it; IMO this makes things more convenient.
There are other bosnian Lispers besides me ?!?! Holy crap, exciting!
Oh, I know, the point you made *is* important, so no offence taken. I was referring more generally to the criticisms already out there about Hoyte's book. And thanks. I think the repos need a lot of work still---basic documentation, reorganization to strip out the extraneous eval-when forms, compatibility checks for all platforms, tests, and at least a minimum of code clean-up to reflect lisp best practices---but I figured, to minimize confusion, it would be best to keep his code as much as-is as possible, to start off with. Then, as a community, we can decide on how to best build on the library for general, production use if need be.
good idea, but for me file size is the deciding factor. the vectors are traced bitmaps with a massive number of data points, so the SVG is over 1MB even after stripping out all of the unnecessary layers and patterns. i don't have the time at the moment to hand-tune the paths to use fewer nodes.
Nah, this still seems too complex. Do you need a windowed program, or just to work in a terminal? How does "HTML editor" differ from "text editor"?
So, to summarize: * you don't understand the assignment, * you don't have any practical experience with Lisp, * you don't even know how to get started. The best thing you can do at this point is to * talk to the TA or the instructor, * find out what prerequisites you have missed, * with their help, either work out a plan to catch up (will involve a lot of effort on your part), possibly asking for an extension on the deadline for the assignment, * or drop the course. You can still learn the prerequisites you would have needed, and come back to this course at a later point in your studies.
I got hunchensocket to work a while back - maybe a year ago, and used it for a project. The problem is that I'm moving at the moment and I don't have access to it. Unless someone pipes up with an example, I'll post a gist or something when I can.
Thank you for the thought, but I've seen this code; I examined Hunchen.io to see how it's supposed to "handle the tedious parts for you" when used with Hunchensocket, but I couldn't really make sense of it, I'm not that good yet. What I'm looking for here is basically an extension of Hunchensocket's very short documentaiton; under Usage there's vague (to me) instructions, but no example code... I just need an echo server, I'm sure I'll be able to take it from there. The catch is to make it work without Hunchen.io, since it won't load on Win7 using CCL (same reason I'm not using CLWS). I couldn't find any other way of making websockets work... Edit: typos.
It took me a grand while to understand that Shivers wasn't referring to the conventional diss when he said so - the ethos of the technical one-up was *incredibly* strong in the narration.
https://en.wikipedia.org/wiki/Mereology ?
Is LISP mentioned there?
i assume what p_nathan means is, Is the referenced Wikipedia page the 'mereology' to which you're referring?
Yip.
I hate to be a downer, but the fact you're not able to find sample code is probably because those who may have been up to the task didn't have a machine loaded with just the right combination of outdated software to actually get the library up and running to begin with. The Hunchensocket library hasn't been touched in a year, was never quite finished, and is now sorely in need of an update&amp;mdash;the [web sockets W3C draft (now candidate recommendation)](http://dev.w3.org/html5/websockets/) has progressed a ways since then. I haven't given the W3C draft a careful read, and am not really up on web sockets at all, but problems with Hunchensocket seem rooted in changes to the standard for web socket handshake routines. Hunchensocket's main development stream only supports a very old way of doing handshakes. I found [a fork of the repository](https://github.com/Publitechs/hunchensocket), however; it is at least a little bit more up to date on that front, and seems to come with bug fixes as well. So far as I could tell, it was *nearly* working in tandem with the code you linked when using my current build of Chrome. After plunking that repository in my local-projects directory and doing a `(ql:quickload :hunchensocket)`, I cobbled together the following snippet before handshake issues barred going further: (defpackage :websocket-demo (:use :cl)) (in-package :websocket-demo) (defparameter *acceptor* (make-instance 'hunchensocket:websocket-acceptor :port 8080)) (hunchentoot:start *acceptor*) (push (lambda (request) (format t "Received request. Feel like handling it with websockets.~%") (lambda (stream mutex) (format t "Handshake begun.~%") (break) ; I'm not able to get to the function below (I mean even without the call to BREAK). ; The connection is severed and I get an error message in Chrome that ; indicates we're doing the handshake wrong. (lambda (message) ;; message handling would go here.... ))) hunchensocket:*websocket-handlers*) Chrome's exact complaint was `WebSocket connection to 'ws://localhost:8080/' failed: Error during WebSocket handshake: 'Connection' header value is not 'Upgrade'` Just thought I'd share what I found. Hopefully an expert can take it from here. 
No. Do you have any pointers or references? Someone here may be able to point you further on your quest if you provide some ideas. I actually was unsure if you were interested in mereology or meteorology. 
Could you explain why you think there would be an overlap between the two and what the overlap would be?
"it has been wholly developed by logicians, ontologists, linguists, engineers, and computer scientists, especially those working in artificial intelligence." - wikipedia on mereology. 
So what you really want to know is whether people using mereology have been using Lisp for there work, and if there are libraries available for mereology.
It's mereology, not meteorology. 
Thank you VERY much for this post, this kind of insight was exactly what I needed. I spent the bigger part of the day going through Hunchensocket's code, trying to figure out how it works (I'm still new to Lisp) in order to get an idea on how to fix it, and give your post the reply it deserves. I'm not there yet, any expert help will of course be of great help. If it can't be fixed, I will have to wistfully continue development in Clojure (which, I think, is the next best thing for my purposes). 
Thanks anyways.
That's that damned interestings. Thanks man.
/u/pavelludiq, would you mind blogging about your experiences publishing a book this way after the release has occurred for a while in the future? I think this way of publishing is the proof of concept for other authors, especially with programming subjects, so I am interested in how it works out from your POV.
[The Craft of Text Editing](http://www.finseth.com/craft/) is definitely a must read. I started working on Emacs clone and use that and Emacs/Deuce code to answer most of my questions. Deuce is also written in Dylan, which can be much easier to read for beginners. I guess with those as a reference you could implement some fundamental stuff that any editor would use quite easily.
&gt; I’ll be defending on Friday, December 13th What does that mean?
I love these blog posts.
Always write opening parens with closing ones. paredit will even do that automatically. For example, if I type the partial fragment above, I actually get `(defun factorial (n) (if (zerop n) 1 ()))`.
Ok, I have to clarify my intention. I want to detect the last () in your case and see the partial state, during the development. However using () will not raise any read-error, because it will be parsed as just a nil, so the dubugger cannot catch it. Inserting something manually (using symbol-macrolet) would be another possible way but I want to avoid it. example: (define-symbol-macro ! (error 'some-error ...)) (defun factorial (n) (if (zerop n) 1 !)) I'm working on a code with large destructuring-binds (using optima) and see whats happening there, before writing the entire code. something like this: (defun abstract-component-task&lt;= (t1 t2) (match t1 ((abstract-component-task (init i1) (goal g1) (ac (abstract-component (attribute-facts af1)))) (match t2 ((abstract-component-task (init i2) (goal g2) (ac (abstract-component (attribute-facts af2)))) (and (and (&lt;= (length af1) (length af2)) (subsetp af1 af2 :key #'name)) (and (&lt;= (length i1) (length i2)) (subsetp i1 i2 :key #'name)) (and (&lt;= (length g1) (length g2)) (subsetp g1 g2 :key #'name))))))))
It'll be a lot easier to have an easily typed (symbol) macro that breaks into the debugger than to try and hook into the reader. Just editing right gets you almost all the way there.
In addition to pkhuong's suggestion (symbol macro calls debugger), you might want to consider learning features of your editor that help you understand code better just by eyeballing it. For example, I find [symbol highlighting](http://www.emacswiki.org/emacs/HighlightSymbol) very handy in Emacs when I want to understand complex code.
I think I kind of understand what OP wants help with. You see, you can create an implementation like lis.py with lambda, cons, car, cdr, define, quote and all that. I think the OP wants to know if its possible to kind of not implement stuff like lambda in a host language. I'm in a **very** similar situation myself. If I am implementing a Lisp in C, what are the basic functions/special forms that I need to provide to make the language able to bootstrap the rest?
Wow, your reddit comments and blog are a treasure trove!
have you looked at newlisp? (http://www.newlisp.org/) It is only 300kb in size while having 400 builtin functions. However, it is neither a Common Lisp or a scheme. 
Check out Shen. Shen will be IMHO next lisp. Little marketing: shenlanguage.org, /r/shenlanguage
OMG! There is a shen subreddit?!!?! UPBOAT FOR U!
Now I may be a bit biased as a Haskeller: 3 Scheme impls, I probably missed some. [Husk Scheme](http://hackage.haskell.org/package/husk-scheme) [Haschoo](http://hackage.haskell.org/package/Haschoo) [Haskeem](http://hackage.haskell.org/package/haskeem) If you are interested in other languages implemented in haskell, there are 285 packages in the [language section](http://hackage.haskell.org/packages/#cat:Language). There are all sorts, prolog-like, dynamic oop langs, ml-like langs, and as well as the lisp-like langs. Lots and lots of stuff to get you started! EDIT: Also, check out [the kernel language](http://web.cs.wpi.edu/%7Ejshutt/kernel.html), with an [impl here](http://klisp.org/). If you really want to get to learning what I think is one of the best lisps around.
Newlisp is super cool, I like it's focus on fexprs.
Woah, Scheme 9 looks amazing! I'm suprised I haven't heard of it yet! Thanks so much!
Commenting to find this later, thanks!
It is just a design phase, nothing is obvious. Catch the read-error, complement the insufficient close parenthesis, attatch an error signalling code to each such branch of code and run is all I have considered. I also tried "cl:step" but it failed to make it work on sbcl. (I guess it needs a proper compiler optimization option?) "library" might not be appropriate for this feature. A debugging paradigm?
Check out Paren and its friends. Host languages are: C++, Java, JavaScript, C# https://bitbucket.org/ktg/paren (1100- LOC) https://bitbucket.org/ktg/parenj (1400- LOC) https://bitbucket.org/ktg/parenjs (600- LOC) https://bitbucket.org/ktg/parensharp (1700- LOC) 
Husk Scheme is indeed a good choice, it has a FFI from haskell to scheme and it's currently aiming for full R7RS.
AFAIK there is no single definite answer. From Henry Baker's Metacircular "Semantics for Common Lisp Special Forms": 'In short, the choice of which "macros" are "special forms" is just as arbitrary as the choice of a axes in a coordinate system for the Cartesian X-Y plane--e.g., some sets of macros are "linearly independent", and some sets of macros "span" the space of special forms.'[1] For example, Common Lisp has 27 Special forms[2]. AFAIK a special form just means it doesn't obey the regular semantics of the language. [3] [1]: http://home.pipeline.com/~hbaker1/MetaCircular.html [2]: http://www.lispworks.com/documentation/HyperSpec/Body/03_ababa.htm [3]: http://www.lispworks.com/documentation/HyperSpec/Body/26_glo_s.htm#special_form Btw, as you can see lambda is not a special form in CL, but a symbol and a macro. Also PicoLisp has no lambda IIRC. 
ruby hosted http://blog.fogus.me/2012/01/25/lisp-in-40-lines-of-ruby/
[Lisp In Small Pieces](http://www.amazon.com/Lisp-Small-Pieces-Christian-Queinnec/dp/0521545668) should probably be an interesting read to you.
I've had it sitting on my shelf for like 6 years. Some day I should read it, too (I've also wanted to write a minimal, McCarthy style Lisp, someday I'll find the time) :/
No one here has mentioned [Picolisp](http://picolisp.com/5000/!wiki?home) which is a tiny Lisp interpreter implemented in C (with lots of code in Picolisp itself) which I find totally charming and thought provoking. I implemented a complete RESTful server system thing in it. Good exercise.
Yeah, it's great!
People should read Maru's source. Piece of art.
YES! I've been waiting to see if you'd release this. Thank you.
The author still says It's twice the size it should be.
/u/dcxi post mentionned maru last, almost implying it to be an interesting outsider here. So yeah.
Wicked. Can't wait to try this out for myself.
so ... is it a fake conference? EDIT: the top line - a link - of the linked page above: "JBBE: Fake Academic Journal, the Next Generation" talks at length about fake academic conferences and fake Journals... the post immediately preceding a post on this lisp conf is a post about fake conferences. 
Montreal and Paris! I am glad for being Acadian ... First language spoken, and glad for being me ... first language that I focused on :) 
This is super awesome :)
So, looking up [this year's ELS](http://www-sop.inria.fr/members/Manuel.Serrano/conferences/els13.html) was too much trouble before posting any weird inferences here? And what do we find there: the conference was organized by INRIA, program committee consists of people from Intel, Google, and oh there's even an Olin Shivers in there...
gcc?
i.e. mingw :-)
Same, but PG translated the math notation into sexps: http://www.reddit.com/r/lisp/comments/1fj0qf/lisp_vs_haskell/caarko8
Awesome, thank you for the post.
Does he use 1.5, MACLISP, ISLISP or some other old variant that still uses the capital acronynm? ;)
Well, so did I. Go to the solution page of the exercise.
Ah, I didn't know SBCL requires gcc; me was thinking older SBCL version would be enough to produce binary, without needs of C compiler presence...
Not SBCL proper, some of the contribs.
Just off the top of my head (I promise: I did no web searches for this!) I can think of... Other Examples of Combining Printing and Computing --- Babbage === I have a vague recollection that Charles Babbage was inspired to design and (start to) build his "Analytic Engine" (or was it the other one?) because the log tables used in his day were riddled with errors. Because of this, he viewed printing the results of his calculations to be a critical part of the design. There was no point to performing obsessively accurate calculations if transcription and typesetting errors would destroyed the integrity (punintended) of log tables he hoped to provide. PostScript === I also have the vague recollection that in the early days of TeX processing, it was in a kind of weird direct competition/symbiosis with Adobe's PostScript. PostScript is also Turing Complete, and I'm sure a web search would turn up many bizarre applications written for that stack based language. Maybe even a lisp interpreter. I have to believe that if Adobe had chosen a lispy language instead of a stack-oriented one, our printers would have followed a very different path to get to today. Literate Programming === Knuth himself is interested in having programs written and printed in easy to read form. I can easily imagine that the benefits to the lisp community for this kind of interpreter is that one document can be written that generates both annotated code documentation and compilable source code. Search for WEB, with the command 'tangle' and 'weave'. My point --- The blending of a strong computation engine and a comprehensive formatting tool has a long history. So long as print is not dead (even, imho, print to screen) there will be reason to have both together.
The garbage collector and the core runtime are implemented in C (and a bit of Assembler); see [here](https://github.com/sbcl/sbcl/tree/master/src/runtime).
I don't see why this answer was given either. Perhaps access to COM ports is strange on windows. Even if FFI is needed, wrapping a few standard library calls isn't hard.
Do what you are motivated to do. I wrote a [6502 emulator/assembler/disassembler](http://github.com/redline6561/cl-6502) in lisp. Just because lisp is a high-level language doesn't mean it lacks the tools to operate on low-level details. It's not clear what you're actually trying to do though so I can't comment on the availability of lisp libraries that suit your exact need.
Lisp (which is also very old) would be very nice for working with Modbus. I'm using JavaScript for the same thing now. CL has the CFFI, which is a really easy way to call C libraries. Where Lisp really shines is when you sit down in front of the REPL and try ideas. When something works, you paste it into your program. You can modify your entire Lisp Environment to make working with your problem easier. If you use macros, you can make a scripting language which "just in time compiles" for free. Need a communications protocol? Try s-expressions (provided your data is trustworthy). Don't know how to structure your application? Just play with some simple functions and a design will magically appear. (I'm really not making that up.) The most important thing, however, is that you will start to think in lisp, which is a nice way of using the mathematical power of the lambda calculus. Once you get to this point you can write lisp in any language.
&gt; Don't know how to structure your application? Just play with some simple functions and a design will magically appear. This is really only kind of true. In my experience, Lisp doesn't obviate the need for software design as a separate step from coding. It can help that design process along, but it can't replace it. I think there is a fair amount of over-enthusiasm for Lisp's power floating around in the rhetorical space. As I've said elsewhere, my main perception of the utility of the language is that it is a sufficiently multi-paradigm language to implement what you need, it can be made performant, and it uses s-expressions to denote programs, and working with s-expressions is particularly easy and nice. I maintain a personal lisp dialect that compiles to Javascript. The design relies on modules with a dependency graph and therefore doesn't easily support interactive evaluation. I don't find this to be a serious impediment to design or development. 
Thanks for the source. Rich has certainly quoted it as a design philosophy for Clojure in his presentations so it's worth asking the question.
It's the design philosophy for much of Lisp of the last fifty years. For example Common Lisp provides hundreds of functions working with lists. It inherited that from a main Lisp line: Lisp 1.5 and Maclisp. Common Lisp, like several Lisp dialects, is one Lisp which makes no commitment to just one design philosophy. You'll find lists, sequences, simple record like data structures and full-blown object-systems. The latter had been added in the 80s.
Think you're off the mark there. In CL a list has unique operations with well defined performance characteristics. An array has it's own, and so on. The operationd on a hashtable are unique to that data structure in CL. But in Clojure Rich has decided to cloak all these various data structures under the one abstraction called seq. This hides away details and allows you to use the same set of seq functions for all these structures. But there are pitfalls.
Think you're off the mark there. Lists don't really exist in Lisp and Common Lisp. They are just one abstraction out of several you can make with conses: lists, trees, graphs, circular lists, assoc lists, property lists, ... Those form the base for a lot of Lisp. That's what Alan Perlis observed. All that is still in Common Lisp. You can run a lot of the software from the decades before CL using those cons-based data-structures without much changes in Common Lisp. Common Lisp also does not say anything about performance characteristics of list-based data structures, arrays or hashtables. Even if you think you know how it would be, the complexity of modern computer architecture makes it very difficult to understand the effect of pipelines, cache hierarchies and memory management strategies on performance with cons-based data-structures. Common Lisp also has a sequence abstraction which provides common operations for lists and vectors (incl. strings). Common Lisp also has a class system, which allows to implement data structures and which share operations. Various other high-level data-structures are available as libraries. Personally I don't care too much what Alan Perlis thought of Lisp, because he was not an actual Lisp user, AFAIK. My impression is that he had only superficial (or academic) knowledge of software development in Lisp and how Lisp applications actually work. He was more famous for his work on ALGOL and for his quotes.
It's attributed as such on the Clojure [rationale](http://clojure.org/rationale) page. Notice, however, it is listed under the "OO is overrated" rather than the "Lisp is a good thing" section. The implication being they (Hickey) don't think it's a difference from (Common) Lisp. 
Cool! I've been looking at doing an XULrunner project, this could help. I'm trying to hit multiple platforms though, so might have to make a cross-platform websocket lib. Been toying with the idea of doing websocket support in [Wookie](http://wookie.beeets.com) but haven't had time (or really a use for it). 
Ha, I remember asking that question. Still wish the libraries were there and cross-platform. But I don't do much (anything) with serial ports these days. If I did, I'd probably write a cl-serial, stub in some reader conditionals for SBCL and Windows (or whatever), use it, release it as open source, and be on my way.
Looks a bit like a Scheme program written in Common Lisp. Personally I would replace all the recursive iterations with higher-order functions or LOOP or ITERATE. That would make the iteration much more natural and cleaner. With LOOP or ITERATE I would also use the destructuring features to get rid of the CAR and CDRs... For more complex problems I would also get rid of recursive string concatenation.
There are fundamentally two ideas embedded in Rich Hickey's quote. Let me address them in order. First, it is a very clear an direct reference to Alan Perlis' quote: &gt; It is better to have 100 functions operate on one data structure than to have 10 functions operate on 10 data structures. as has been said in other answers. Is this true? Well, before we can answer that, it might be helpful to elaborate on what it means. If you have many functions on a single data structure, you can combine these functions easily. If you have 30 functions to manipulate lists, most of them will consume and produce lists, so you can easily chain them. If you have 10 functions on lists, 10 functions on hash tables, and 10 functions on, say, strings, the combinations you can make with these functions are much more limited. Practically, this means that you will need more functions to convert between types, functions that consume two or three of the types, etc., increasing cognitive load. What the quote is asserting (imho, I have not have the opportunity to discuss with Mr. Perlis himself) is that, if you have to know 100 functions, you will have more power if they all operate on the same data structure, because of simple combinatorial laws. Basically, 100^2 is greater than 10 * (10^2). Of course, in the real world, where performance matters, you do need more than one data structure, so the quote should be understood more in the sense that fewer data structures is better than many, rather than in the literal sense of "you should have only one". The second idea of the quote is embedded in the change that Rich Hickey has made: he replaced data structure by data abstraction. In modern programming, we most often do not rely directly on data structures; rather, we rely on abstract data types that can be implemented in many ways. This does not invalidate Perlis' original quote; it actually kind of multiplies it. Say you know ten functions that operate on an associative array (hash map, dictionary, whatever). You can use these same ten functions and combine them in the same way with any implementation of an associative array. And there might be situations where one goes dramatically faster than another. A simple alist may be faster than a full-blown hash-based mapping, if you only ever have three mappings in your maps. The Clojure language has 4 main data abstractions: seq, vector, set and map (dictionary). These are the data abstractions he is speaking about in this quote. Additionally, the three others can be easily transformed into the first one, and there are facilities in the language to transform seqs into any of the other, and to, for example, treat vectors and seqs as maps with integer keys in situations where you would need a map. But these are details. What's really important is that these four abstractions are all you need to represent almost any kind of data, and the Clojure programming language and ecosystem is built around them. This means that the vast majority of Clojure libraries are just collections of functions that operate on these four abstractions and return instances of these abstractions, and therefore are easily composed with the functions of the standard library *and with those of other libraries*. It also means that the few functions to manipulate these abstractions are basically everything you need to know, and every new operation you want to add is easier to add to your mental model (you only have to understand a new operation on known types, not a new type *and* a new operation), and to your code (since it is compatible with basically all of your existing code base). This is the code reuse he is thinking of. As for the comparison to Common Lisp, it depends on what you actually do with Common Lisp. As CL does not have, as far as I know, explicit interfaces, that part of the Clojure philosophy would probably translate in something like: "when you build an application, define a set of generic functions that you reuse everywhere, and have your classes implement them", rather than create specialized functions that only handle one classe. As a practical example of Perlis' quote, think of how CL uses lists to represent sets.
I believe UNIX also embrace this philosophy. I am talking about "file as an abstraction".
I don't think this approach scales well. Works for hackish, write-once, throwaway software, though.
In my experience it scales pretty well. Especially when you start hitting real business complexity (e.g. different versions / variants of message formats that must be supported concurrently by the same API). That can get very nasty very quickly if you try to model everything in statically typed OOP style..... I'd certainly rather be working with flexible abstractions at that point. Obviously, you still need to be careful. But most of the problems can generally be mitigated by: * Good testing (everyone is doing that, right? :-) ) * Use of data-driven schemas / validation approaches * Type systems (e.g. Typed Clojure lets you encode the presence/absence of specific keys in a map along with the type of the value, which gets you roughly the same type safety that you would have with a statically typed language)
You don't need to use 'static' OOP. Common Lisp, Smalltalk, ... have 'dynamic' OOP.
&gt; Because of the IOlib limitation, it works only on Linux at the moment, until a platform independent implementation of websockets is found. see http://src.knowledgetools.de/tomas/winapi/index.html for winapi port of iolib, will be hopefully merged into the official iolib at some point is there some deeper reason why websockets depends on iolib? couldnt it be relatively easily ported to usocket for example? or even abstract away the socket lib dependency and pass it at runtime as a closure which would do the socket stuff using any user defined way and wasnt hardcoded in cl-xul? some time ago i wrote something which understood glade files and created html, xul or xaml interface in the web browser &lt;http://logand.com/sw/webglade/index.html&gt;. soon after that mozilla disabled xul breaking every app that bet on xul, so i would be very careful using xul for anything since then edit: link
No, there's no deeper reason. I just wanted to make it work quickly, and clws did that for me. Thanks for your suggestions. I will try an usocket port as an alternative to websockets. It would be great to make it work in every platform.
I've never used add-method. I don't think I've seen any code in the wild that uses it. Is it common and I've just missed it?
" In Lisp, add-method is *typically used by the system*, as part of the defmethod macro, but it can be invoked by the programmer if needed. " Quote taken from article, added emphsis on the typical usage.
Sure. How often is it needed by the programmer?
I haven't seen it in my own browsing, but one technique for casting a wider net is M-x find-grep in emacs. (I learned this from PJB in #lisp.) Then use a query like: find ~/quicklisp -type f -exec grep -nH -e '(add-method ' {} + On my computer this comes up with a with-method macro in McClim, as well as a bunch of closer-mop references. You can make browsing that list slightly nicer by adding a (recenter) call before the pop-to-buffer call in emacs' next-error-no-select.
Just as you do in Clojure with protocols and multimethods.
protocols are based on type/class-based single-dispatch OO, not the associative maps mentioned above.
classes don't implement generic functions in CLOS.
ADD-METHOD exists to allow for the programmatic manipulation of meta-objects. DEFMETHOD is one way to interact with a generic function meta object, ADD-METHOD is another. As for an example, I used ADD-METHOD in [chains](https://github.com/markcox80/chains) to provide an alternative interface to interacting with a specific meta-object.
Sure, but they provide an additional way to do dispatching and can be extended at runtime.
Thanks for your input -- is it a matter of style, or will your approach yield better performance as well? And what is your point on recursive string concatenation? (just trying to learn to become a better Lisp programmer, hence sharing)
Common Lisp, not Lisp. Lisp didn't have an object model.
&gt; And what is your point on recursive string concatenation? Let's say you have a list of hundred strings. Now you do something like: string1 = string2 string2 + s0 = string3 string3 + s1 = string4 string4 + s2 = string5 and so on. All but the last one of the string-n are immediately garbage. With each iteration the string gets longer. With each iteration a new, slightly longer string has to be allocated and the old two strings have to be copied. With a little maths you can compute the complexity of that operation. The simple solution is to collect all the strings in a list, allocate a new string once of the result size and then copy all the strings into the new one: traverse the list once to get the size and then traverse the strings once to copy them. The simpler version is to create a string output stream and write the strings to that stream. See: WITH-OUTPUT-TO-STRING. On exit you get the result string. 
&gt; Thanks for your input -- is it a matter of style, or will your approach yield better performance as well? Maybe you get less stack overflows? Would that be useful?
Let's look a the alist-count function. I would actually base it on lists not strings. I would also rename it DISTRIBUTION and give it a :test argument. This increases reuse. (defun alist-count (string) (distribution (words-sorted string) :test #'string=)) Now there are several ways to write it. In the real world I would not require a sorted list and I would use a hash-table. But I'll do the sorted version which returns the alist for now. The old-school Lisp version to do this is to use DO* : (defun distribution (sorted-list &amp;key (test #'eql)) "Given a list, return an alist counting the items" (do* ; variables init step ((list sorted-list (rest list)) (item (first list) (first list)) (next-item (second list) (second list)) (same-item-p (funcall test item next-item) (funcall test item next-item)) (count 1) (alist nil)) ; test result ((null list) alist) ; body (if same-item-p (incf count) (progn (push `(,item (count . ,count)) alist) (setf count 1))))) The best version to write this stuff is to use the ITERATE macro: (defun distribution (sorted-list &amp;key (test #'eql) &amp;aux (count 1)) "Given a list, return an alist counting the items" (iterate:iter (iterate:for (item . rest-list) on sorted-list) (if (funcall test item (first rest-list)) (incf count) (progn (iterate:collect (list item (list 'count count))) (setf count 1))))) Much clearer code. Granted: a certain amount of macro magic is involved. 
This is a great series. I hope you will be covering some aspects of the MOP; it being something that would blow the mind of just about every other C++ coder on earth.
This neat little implementation of cons is also available for reading in sicp
Though I applaud anyone exploring functional programming, I get annoyed with the inaccuracy of this type of post. A cons is no more a function in any actual lisp implementation than Java's 'for' construct is a Y-combinator. 
*cons* is always a function in many lisps, unless they optimize it in list form or perform some other tricks. Now what kind of function, written in language itself or something beneath it, usually for speed, that is different case... But yes, there are lisp implementations which leverage minimalism of host language and implement as many primitives as possible, including *cons*.
I said *a* cons. This term is usually accepted to mean a cons cell, which is what was the initial blog post was interested in constructing.
It also exists since [lambda calculus](http://en.wikipedia.org/wiki/Church_encoding#Church_pairs).
The 'add' function assumed in the article would be a little unusual: (defun add (cell) (+ (car cell) (cdr cell)))
It was never my intention to convince anyone that a cons *is* a function in any lisp implementation, just that it can be. Perhaps I needed to dive into the fact that this is lambda calculus more to get that point across.
Lisp == Common Lisp in my book. Scheme is Scheme, Clojure is Clojure...they are all in the "Lisp family" but "Lisp" the language is Common Lisp. I don't think there's a need for distinction anymore.
Right, so rather than an explicit data structure relating the elements of the pair, the closure returned from cons does so. I must finish SICP one day.
cool! looks great. would love to try building a gui for this. 
And the CL Library review advent calendar from last year: http://qiita.com/advent-calendar/2012/clladvent Even though google's machine translation from Japanese to English is a bit sketchy it made my day when I saw my library featured last year. I'm happy to see another Lisp related advent calendar this year.
L, MARS : http://www.cs.cmu.edu/~chuck/pubpg/luv95.pdf
Isnt using Tail-call recursion save?
is Common Lisp giving you tail-call recursion? Many compilers will support it under some optimization level. But interpreters often won't. Even for compilers this is not necessarily the case: Try to run your code in ABCL on the JVM. If you target a special set of compilers, then it is fine. If you want to write portable Common Lisp code based on the standard, then avoid tail call recursion (or TCO in general). This is different from Scheme. But also note that TCO is more problematic in Common Lisp than in standard Scheme, since Common Lisp has features which prevent TCO from working - like dynamic scope constructs.
None I could think of. But if you want to start one, you could check [Vision Lisp](http://dl.acm.org/citation.cfm?id=237681). [Download it here](http://www.cvc.uab.es/~javier/vili.htm) It is old and it's not being used any longer for teaching, but... I learnt lisp with it. Oh! And I just found [this paper](http://kogs-www.informatik.uni-hamburg.de/publikationen/pub-seppke/ELS2010_seppke_dreschler-fischer_vigracl.pdf). The second chapter may help you. 
[cl-opencv](https://github.com/ryepup/cl-opencv) has been around for a while. I even have a [fork that used Verrazano](https://github.com/redline6561/cl-opencv/tree/generated) to generate the FFI bindings. Not sure if that ever got merged in though...
Yeah when in doubt, just wrap a well-known C library. Now you have a library with a wonderful CL interface that someone else maintains for you for free =] (assuming you don't use a dead C library).
I want to make some robots with my beaglebone black.
it probably didn't. I started cl-opencv then realized I was way out of my depth. Most of the code in there was merged from https://github.com/jbromley/cl-opencv
What computer vision task does this robot need to perform?
Good points on debugging. Also, you're right, CFFI is more or less limited to C, and also then only C that returns values by ref (returning structs by value breaks everything unless you also have libffi). I've never even tried to wrap C++, I hear it's a nightmare. That said, there's a balancing point. If the library is small enough, yes definitely write a CL version yourself (please release/document it as well for the sake of others). But for something as complex as computer vision where you have a library that has a plethora of working features and performance enhancements already, trying to reproduce that code and momentum in CL is begging to be abandonware in a few months. I've had my fair share of segfaults and tearing-out-hair when using C libs in CL, but usually it ends up being worth it.
SBCL definitely welcomes (code) contributions.
We have not discovered anything that scales well. I think this Perlis epigram has lots of merit when correctly applied and used. For example, the cons cell in Lisp is nice abstraction, but my personal feel is that its outdated and too low level. Traditional *nix OS philosophy uses strings same way as Lisp uses cons and it has been extremely successful. Nowadays XML or Json seems to take the palace of raw strings. Scalable things are made of separate programs that communicate by exchanging these data structures.
Looking forward to seeing the next video(s). Audio would would be nice as well.
Hey glad you liked the video. I'll try to get some audio going in the next couple of videos, that said I'm an absolutely terrible narrator...
Just want to second the request for more videos, this looks very cool! Also dont worry about the quality of the naration, I'd just love to hear what is going on and where you may take this.
That sounds really cool! You could make it into an education tool (learn some new CL or Scheme at each level to complete it). And yeah, don't worry about the quality narration, it would just be nice to have some sort of introduction to follow (and also so people don't scramble to check if there is something wrong with their audio :P)
Not a programmer myself, but: "...please don't assume Lisp is only useful for Animation and Graphics, AI, Bioinformatics, B2B and E-Commerce, Data Mining, EDA/Semiconductor applications, Expert Systems, Finance, Intelligent Agents, Knowledge Management, Mechanical CAD, Modeling and Simulation, Natural Language, Optimization, Research, Risk Analysis, Scheduling, Telecom, and Web Authoring just because these are the only things they happened to list." - Kent M. Pitman
It's probably worth mentioning that the Lisp Interface Library project by Fare Rideau extends CL with what he calls Interface passing style. This basically translates to mean that you might define an Associative interface (protocol of generic functions) that you may reuse with alists, hash tables, trees, etc. The interface is always explicitly specified as the first argument of a call and provides a means of treating the same data in alternative ways. Fare does a *much* better job of explaining all of this within a very nice project documentation he has written. http://github.com/fare/lisp-interface-library
My coworkers have stacks of old Dylan manuals from many years ago. Are they still useful for using Dylan in 2013?
Depends on which ones. Are they the dull grey ones from Apple that document the s-expression syntax? Those are less useful. If they are the Dylan Reference Manual (DRM) from Shalit (also published by Apple, but white n color), that is still usable. The Dylan Programming Guide which had 4 authors is still pretty usable. (It is also online at http://opendylan.org/books/dpg/ and the DRM is available at http://opendylan.org/books/drm/. The rest of the Harlequin documentation has been updated and converted along with other documentation and is at http://opendylan.org/documentation/.) I jokingly say that we're the best documented language for the number of users that we have. :)
What's the benefit over Lispbox? (real question, no irony) http://common-lisp.net/project/lispbox/
LispBox seems to be abandoned for serveral years and therefor comes with quite old versions of its subsystems. LispStick has actual version of emacs, slime, sbcl and quicklisp
How do you run it?
LispStick also has an exceedingly clever name.
Thanks. Shalit sits next to me!
Very nice. I've been using it over the past couple of days and it has worked flawlessly.
Good work! In run.bat, the last line **should be changed** to work properly in a path having space: "%CD%\%EMACS%\bin\runemacs.exe" -Q --load "%CD%\.emacs" --directory "%CD%/%SLIME%/" 
Lipstick?
 (every #’identity list)
This is a nice little site. The problem with CL isn't the syntax or the function corpus, it's all the idioms you need to know to be useful.
Note that the [Part 1](http://www.merl.com/publications/TR91-04) is also online.
One of the sections of part 1 describes his regression testing library, RT, which I find notable for being both simple and still used. When I came across these papers for the first time I particularly enjoyed "To NReverse When Consing a List or By Pointer Manipulation, To Avoid It; That Is the Question" and "Implementing Queues in Lisp" sections. I was not familiar with the technique of holding a reference to the tail of the list and mutating that to add an element to the end, and found the explanations to be very clear. 
how to find you? will you add a location on the ccc-wiki? looking forward to meet some lispers! :)
Not quite the same: (and 4 5 6) =&gt; 6 (every #'identity (list 4 5 6)) =&gt; T Or you could cheat and use a Lisp with fexprs.
Example: http://stackoverflow.com/questions/20778926/mysterious-racket-error-define-unbound-identifier-also-no-app-syntax-trans/20790617#20790617
Wow! What a smart musician!
See also destructuring-bind http://www.lispworks.com/documentation/HyperSpec/Body/m_destru.htm
The page mentions an initial meeting on the 27th at 12:30. I'm at the congress center right now at Hall 1 for the opening talk. If we find out, where, I'll be at the assembly at around 12:30.
As a newbie reading that, a couple of questions came to mind. When I run the first example which is (loop for numlist in '((1 2 4.0) (5 6 8.3) (8 9 10.4)) for a integer = (first numlist) and for b integer = (second numlist) and for c float = (third numlist) collect (list c b a)) I get this error B is an unknown keyword in FOR or AS clause in LOOP. current LOOP context: FOR A INTEGER = (FIRST NUMLIST) AND FOR B INTEGER =. [Condition of type SB-INT:SIMPLE-PROGRAM-ERROR] Am I the only one getting this error? Something wrong with my Common Lisp installation? And is there a difference between this (loop ... do (return (list a b))) and this? (loop ... return (list a b)) 
Something is _not_ wrong with your implementation, it is telling you that the form you used is not a valid LOOP syntax form. It is correct, but _something_ is wrong... "B is an unknown keyword in FOR or AS clause in LOOP" ... or (loop for [...] and for [...]) is not a valid loop form. The "AND FOR" is an error. Learn syntax and do not blame the implementation for not DTRT when you enter the incorrect syntax! :) **edit**: " In that case, you can join multiple for clauses by replacing all but the first for with and. You saw this formulation already in the LOOP version of the Fibonacci computation in Chapter 7. Here's another variant, based on the two previous examples: (loop repeat 5 for x = 0 then y and y = 1 then (+ x y) collect y) ==&gt; (1 1 2 3 5)" -- http://www.gigamonkeys.com/book/loop-for-black-belts.html 
When I press C-M-\\ after selecting the loop form, it just becomes: (loop for i from 1 to 10 when (&gt; i 5) collect i into number-list and count i into number-count finally (return (values number-count number-list))) even in SLIME mode. 
Red object tracking is interesting!
As a beginner in CL who is always told that no one uses Lisp these days, this is highly motivating. Thanks! Great job! :-)
Yes son, you were
This sounds great! I'll come tomorrow to maximize my 35 euros. Is the assembly area in the same place everyday? Should I just look for a sign on a table?
http://github.com/byulparan ...is my github repository :-)
See also [NREVERSE vs. pointer manipulation revisted](http://blog.splittist.com/2007/10/10/nreverse-vs-pointer-manipulation-revisted/). (I can't believe that was from 2007. Where does the time go?)
sorry for the late reply! We are on the ground floor behind the help desk towards hall 3
This was so rad. I'm definitely going to spend some time with chicken now. Although I do depend on the batteries included with Common Lisp normally, I think chicken will be perfect for my Modo project. It was great to meet you folks.
What's the difference between this OpenCV-wrapper and cl-opencv :-)?
It doesn't surprise me at all. It certainly fits with my belief that Common Lisp is one of the most productive languages around. This both means that you don't waste a great deal of time asking questions and you spend a great deal of time getting stuff done.
What does this measure? Where does the Stackoverflow data come from? To me this looks totally bogus. Coq for example has 229 questions tagged, Common Lisp has 1877 questions tagged. But Coq is placed far above. The io language on stack overflow? WTF?
Most people I know use libraries beyond the Hyperspec. Far beyond. Most Common Lisp users use mailing lists for the various distributions, libraries and topics. Stackoverflow is often used by beginners and students learning Lisp - not so much by Lisp PROGRAMMERS.