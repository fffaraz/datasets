&gt; CCL for windows is not available as a easy installable binary, but only through a SVN repo, and it requires a complete Cygwin environment to build and run. Yes, no, no. An installer isn't available, but you can download [the ZIP for Windows](ftp://ftp.clozure.com/pub/release/1.6/ccl-1.6-windowsx86.zip), extract it anywhere, and run wx86cl.exe (for 32-bit) or wx86cl64.exe (for 64-bit). I use CCL. Getting a webserver running in Lisp is a piece of cake now. First install Quicklisp... wx86cl.exe (load "http://beta.quicklisp.org/quicklisp.lisp") (quicklisp-quickstart:install) then run the server: (push :hunchentoot-no-ssl *features*) (ql:quickload "hunchentoot") (hunchentoot:start (make-instance 'hunchentoot:acceptor :port 8080)) (That may work in Clisp as well. I chose CCL due to its threading support, which is important for webservers. (Hunchentoot *can* work in a single-threaded mode, though.))
Ahhh, that would explain a lot. I can't complain too much about the LW examples - given that there are no CL standards for those things. 
I also want to add, although not an answer to your question (which is already answered by other fine people), that Common Lisp is a Lisp-2, where you have a seperate namespace for variables and functions. This means that the + in your let-statement is just a variable, and you can continue to use + as a function. In Scheme for example this would give you an error: afaik you could rebind primitives in older versions, but with R6RS/Racket you no longer can. So (let ((+ 3)) ...) is legal, but using + as a function no longer is in the scope of that let.
I stand corrected. After a more detailed look, there obviously _is_ a precompiled windows binary, somwhere, but needlessly hidden several levels deep below the landing page to (obviously) make sure that a potential new user, who needs it most, will not be able to find it before he gives up, or has to go to a totally unrelated site (Reddit) and ask _there_ about how to download. Where is the eye-catching, shiny "Hello new user, we see that you are using windows, click here to download our easy windows installer and start consing in 30 seconds" button? (Take a look [here](http://www.franz.com/) for a positive example of how to do it.)
I still find Lisp and most other languages and programming environments much nicer under Linux; that's why I'd take that route even though it might be a slight detour initially.
It was down one level for me - either you scan the top and see Download beside Wiki and everything else you discard, or jump straight to Getting Clozure CL and a link underneath that says "the download page".
C'mon, not even the paper (from 1990!) wrote it as "LISP".
I don't get the karma hit. Do I have to say in so many words that Kay is one of my few personal heroes, which he is; was my admittedly lame TeX humor lost on the crowd? Was I wrong to praise VPRI, a place I believe to be one of the few doing imaginative work with computers? Is it so wrong to say that when I went to the site in the OP, my vaporware BS alarm was going full blast? Was this a drive by shooting by the site's author? I don't get it.
Being stuck in 1958 is better than being stuck in Java.
What happened to this project? The only links I'm seeing on google point to this pdf.
The only error I got was that of gccxml not available on my system. Once I had it installed, it generated the CFFI bindings just fine. (64-bit SBCL, Linux)
Ganz cool! Two languages I like at once...
The other day I was reading the code for the GNU Scientific Library (long story) and I was struck by a really great use case for Lisp. The GSL implements a lot of special functions (Airy, Bessel, Gamma, erf, you know, all that shit). The way it actually does this is by using polynomial approximations with a guaranteed upper bound on the error within a given range. Anyways, not really important. The important part is that the GSL is littered with stuff like this (paraphrase): &gt; double coefficients[24] = {.00567132, .008243556, and so on. In other words there are a bunch of numbers, no doubt computed somehow, by someone, somewhere (likely Messrs. Abramowitz and Stegun), just sitting in the source code with no context. In Lisp, if you know how to compute expansion coefficients like that, you can write code that _does it_ at compile time. In my book, this is a huge win for clarity, especially if you have a function where you can easily write down a way to generate taylor coefficients or something, because you can actually write a macro that expands to your approximation of choice. Like this: (defmacro define-taylor-approximation (name order nth-coeff) `(defun ,name (x) (+ ,@(Loop for i from 0 to order collecting `(* (expt x ,i) ,(funcall nth-coeff i)))))) So, assuming lisp has a built-in factorial function (it doesn't, but writing one is beside the point), I can write: (define-taylor-approximation my-sine 6 #'(lambda (i) (if (= (mod i 2) 0) 0 (if (= (mod i 4) 1) (/ 1 (factorial i)) (/ -1 (factorial i)))))) And this will compute 6 coefficients in the Taylor series of sine _at compile time_, so that at run time, you just have a static array of 6 coefficients, like in GSL, only you can actually see _where it fucking came from_, which I think is a really big win. This kind of situation (compute a bunch of numbers _once_ in the _history_ of a program, that will be used over many, many runs of the same program) is _everywhere_ in scientific computing, and a lot of times one runs a script that barfs out the appropriate set of numbers into an appropriately formatted C or Fortran declaration as part of some horrendous jerry-rigged makefile-driven hell of a build process. In Lisp, the language and compiler natively support this kind of behavior.
Try using a the complete path to the file. Also see http://www.ai.mit.edu/projects/iiip/doc/CommonLISP/HyperSpec/Body/fun_load.html
just a guess ... but you know, maybe env vars. just sayin.
In CLISP, you can use the non-standard "CD" function to change directory. If you are on Windows, the forward-slash / works as a separator, or you can escape backslashes \\. C:\Documents and Settings\mahmud&gt;clisp [banner] Type :h and hit Enter for context help. [1]&gt; (cd) #P"C:\\Documents and Settings\\mahmud\\" [2]&gt; (cd "C:/hack") #P"C:\\hack\\" [3]&gt; (load "hello.lisp") ;; Loading file hello.lisp ... Hello MAHMUD ;; Loaded file hello.lisp T [4]&gt; 
Sorry Xach, I cut and pasted from an antique reference online. 
A standard way to do this is `*default-pathname-defaults*`. E.g. (setq *default-pathname-defaults* #p"c:/lisp/") Then it will add that directory to any relative path. You can get full pathname via `merge-pathnames`: (merge-pathnames "foo/bar.lisp") =&gt; #p"c:/lisp/foo/bar.lisp"
Being stuck in JAVA, right?
Homepage is here: http://lisp.geek.nz/weekly-repl/
Cool. You should ping whoever ran [Common Lisp Weekly News](http://lispnews.wordpress.com/) and see if they'll give you a plug, since its last post (and hence top-most content on the site) is from March of 2009.
Nice! I assume you're planning on releasing it at some stage? I had a similar idea just a day ago, and it seems you've read my mind. Or more likely I've read yours.. :) I think Lisp is definitely the most suited language for this type of visual programming
You can check out 0.2 (the version shown) right now at http://github.com/dto/iosketch But it's not very user friendly and not packaged for easy setup. I will release a beta Real Soon Now.
Thanks for the uber quick response, I think I will check it out :D
You have a nice voice :3 This is very cool; mad props! Could you elaborate on the actual mechanics? Could I use it as a general purpose listener for example? Why does it know + is a function of two functions?
The block types are defined with a macro called DEFBLOCK and you have to specify arguments and such. Now that I have a usable GUI, next I'll be fleshing out the library of available blocks to cover more of Lisp and more of my game engine's functionality. See the source for the blocks stuff here, it's about 1000 lines: https://github.com/dto/iosketch/blob/master/blocks.lisp
 (defblock if (type :initform :control) (result :initform nil) (schema :initform '(:block :block :block)) (arguments :initform '(nil nil nil))) (define-method execute if (recipient) &lt;results&gt;) (define-method execute-arguments if (recipient) (with-fields (arguments results) self (destructuring-bind (predicate then else) arguments (if (/run predicate recipient) (/run then recipient) (/run else recipient)))))
What I really want to know is, who exactly is the target audience here? Are they: 1. Beginners / "non-programmers" / people who don't want to learn a full programming language? If so, I have general reservations about this sort of thing, but even that aside, isn't it a bit at odds with its primarily keyboard-oriented interface? If you know to know the names of everything already to type it into the REPL window, wouldn't it be easier simply to stick to REPL and keyboard? 2. "Pros" / people who actually do think of programming as their trade and know CL. If so, what's the point? You have another UI on top of the usual CL UI, one with a weird hybrid mode where you type for a second and then have to wiggle your mouse for a bit and then go back to typing again. What's the gain, and how do you see it used? I could sort of see the appeal of it as a visualisation method of the high-level structure of your logic, _overlaid as a presentation mode on top of the usual text presentation_. But as the primary means of programming? That just looks like a lot of work to get inferior and more limiting UI. Another thing I find odd and distracting and schizophrenic is this dychotomy between the outer-level commands ("set direction"), which are all AppleScript and English-like, and the arguments, which suddenly revert to ordinary CL. It's just asking for trouble when you have to switch between two different syntaxes, and additionally the outer-shell commands have this weird implicitness going about them, which I find hard to grasp and reason about. That's something that _will_ come back and bite you if you create things the users can't reason about. DWIM is only a good thing as long as you both agree on the "WIM" part. And by the way, I don't really mean to complain or try to put your work down. I just don't quite understand your goals, and so the above questions are honest questions with a bit of wariness prompted by earlier, failed similar attempts I've seen by people who didn't quite manage to get it right.
I would prefer a native CL library but perhaps bindings to Mahout are also a good alternative. However, what would be the best option to create those (Mahout is in Java right?)... jfli? Foil? The easiest thing would be to use ABCL but then, it wouldn't be portable across other CL implementations. So the basic question is, what is the best way to create bindings to Java libraries, i.e., what is the CFFI equivalent for Java.
Hello @mathrick, these are the risks i suppose of showing something in an early stage of development. First, the prompt I showed is not intended as the primary UI strategy, it's just what I implemented first. I'm making a browse-by-category blocks browser like in MIT Scratch so that you don't have to type them in, that should put to bed the requirement of comparing this to a straight text REPL (if the video didn't). Want to grab the Nth last REPL result and drop it into the previous one, then make multiple copies, and keep building ONE complex expression out of pieces before you're ready? Try building a large sexp interactively at SLIME prompt. When I have more block types to show this might be clearer----think of an editable curve or line graph with draggable points, inside a block----not going to happen at a traditional REPL, nor will that be object-oriented and integrated with a game engine. If you look at Scratch http://scratch.mit.edu/ you will see where I am going with this. I don't know how to evaluate your choice between 1 and 2 or why you assume visual programming would be of no help to "pros"---check on citeseer if you want to see how much research and interest there's been in visual programming, I would not dismiss its usefulness out of hand. The prompt currently does not require the outermost parens, so that "(+ 3 5)" and "+ 3 5" evaluate the same if it's the top-level expression. I admit this could be confusing (your impression that it means 2 different syntaxes being a case in point) but so could the requirement of typing parentheses at the beginning and end of every command, especially for non lispers. The visual blocks ui is also not meant to be the primary means of programming---the idea of IOSKETCH is to be able to do one or the other when needed. I think this will be clearer in the coming weeks as I progressively wrap the features of the underlying game engine (pathfinding, line of sight, collision detection, serialization) to these blocks, which is turning out to be a very straightforward process.
perfect, thank you.
Thanks for the clarification. I did actually wonder whether the prompt was intentional or just a WIP consequence, but finally I decided to go by the lack of obvious disclaimers and ask assuming it was at least semi-intentional :) Also I sadly haven't had the time to try it out yet, and probably won't before the Christmas, so apologies for missing anything I'd have known had I tried the thing in practice. &gt; Try building a large sexp interactively at SLIME prompt. When I have more block types to show this might be clearer----think of an editable curve or line graph with draggable points, inside a block----not going to happen at a traditional REPL, nor will that be object-oriented and integrated with a game engine. That is a good point, but then there are also (hacks, so far) to make SLIME's output live or at least not limited to pure text, which I think are a good idea. I'm always a fan of building on existing working (*) tools (REPL and text editors in this case) and making them do new tricks rather than building entirely new tools, because new paradigms rarely are wholesale improvement in every aspect possible of old paradigms the existing tools support. But then you also say you build it for use together with SLIME and Emacs, so you're way ahead of pretty much everyone else building their Brave New IDE. (\*) Or rebuilding them to be less of a horrible hack and have a sane core (*cough*GNU Emacs*cough*) that can support the added weight, but still keeping their fundamental "oldtoolness". &gt; I don't know how to evaluate your choice between 1 and 2 or why you assume visual programming would be of no help to "pros"---check on citeseer if you want to see how much research and interest there's been in visual programming, I would not dismiss its usefulness out of hand. I'm very much aware of the research interest, but that in itself is no proof of goodness of the idea, or else it wouldn't be research. I didn't assume it was of no use for "pros" either, I'm just very convinced it wouldn't be a good exclusive or even primary way of programming, which is what I'm arguing against. That's why I mentioned it as a mode of presentation on top of the existing, text-based UI, and I'm very happy to hear you want IOSKETCH to be able to mix the two. Do you intend it as toggle on/off kind of visualisation, or would I rather need to commit to one or the other way of programming for any given piece of code? It's obviously trivial to convert blocks to source, as that's what you do already to compile it, but do you see it being able to take an existing chunk of code and show it as blocks? &gt; I admit this could be confusing (your impression that it means 2 different syntaxes being a case in point) but so could the requirement of typing parentheses at the beginning and end of every command, especially for non lispers. OK, so let me ask another clarifying question: is the block that says `set direction (foo)` supposed to be exactly equivalent to the ordinary CL form `(set direction (foo))`? If so, you have a huge problem and a special layer of Hell for people who use SET in new code. If not, you have a huge problem with the surface syntax looking different than the actual CL it gets converted to. Either way you run into issues when the -- historical or otherwise -- CL quirks surface and I must admit I don't see a good way out of this. All my doubts aside however, I definitely do appreciate somebody working on moving CL to a spot where it's suitable for games. I also appreciate the time you spend explaining your ideas and hope that it will, indeed, get easier for us to grasp as you progress.
No no. I'm not suggesting using mohout directly, more as guidance. 
great book
Yes, very nice. I saw some videos of this. Livecoding stuff is definitely an inspiration, and it looks like they also draw from Scratch.
Sorry, I understood the other way around! 
What does this do? Can you do FFI to Cocoa libraries?
Racket will not help you follow along with Practical Common Lisp.
::choke:: ::cough:: A leg::cough:: legacy Rails system? Those are not words I expected to see any time soon.
Neat!
Sometimes I think that companies that are desperate for programmers try to entice people to apply with a cool language like Lisp only to deceive them later. How to stop this? 
I don't think I've seen that practice in the past, and I am willing to bet that this is not an example of the practice. 
Could be a Rails app that's &lt; Rails 3 (I've worked on a few such apps), or any thing else these wish to describe (i.e. they have moved from Rails2 to Merb or Sinatra or to something else, and this is the legacy version that they are attempting to move away from). 
Ken Tilton is many things, but a liar isn't one of them, esp. when it comes to work (at least as far as I've seen). Also, for those wondering, they are looking for **local candidates only** at this time; I emailed KT earlier &amp; asked. 
My first thought: Two examples had the same code pattern. Instead of: (with-tree-node a (with-tree-node b ...code... how about: (with-tree-nodes (a b) ...code... or handle lists as the first parameter in with-tree-node from the start. It's a common API problem in CS: it is rare we really do want singular entities. The second thought I had was, wow what a crazy nested etypecase. We can make that more readable. The comparison looks at the keys, which can be strings or symbols. Strings &lt; symbols. For string vs string, we do standard comparison. For symbols vs symbol, we compare their names. I was thinking... (etypecases (a.key b.key) (string string (string&lt; a.key b.key)) (string symbol t) (symbol string nil) (symbol symbol (string&lt; (symbol-name a.key) (symbol-name b.key))))) thanks to a new macro off the top of my head: (defmacro etypecases (things &amp;rest cases) (append '(cond) (loop for case in cases collect (cons (cons 'and (loop for thing in things and type in case collect (list 'typep thing (list 'quote type)))) (list (nth (length things) case)))))) With `() fun: (defmacro etypecases (things &amp;rest cases) `(cond ,@(loop for case in cases collect `((and ,@(loop for thing in things and type in case collect `(typep ,thing ',type))) ,(nth (length things) case))))) 
Not the case here. I'm already there.
I love CL but man I miss dot notation for slot/member access. It's my only real turn off from the language.
They're moving away from Ruby/Rails to Lisp (unclear what framework). So the Rails system is legacy.
Yes, I understand that, I was talking in the general case (of what could be considered a "legacy" rails app).
I want to be a full-time hacker where I can use whatever language makes sense at the time. (Semi-aside: I mostly write in CL at work)
Haha, in that case, a 'legacy rails app' is one on the 1.2.x series, running ruby 1.8.5 - I've worked on a couple of those. Code dating entirely from the last half of 2006.
Sure, that could be a legacy app, depending on direction &amp; what your company is working on currently &amp; a whole host of other factors. I'd hate to think what some of the code I've worked with is considered...
Way back in time some prominent Lisp software used the dot notation without the WITH-... notation. Which made the dot notation much easier to use...
Cute, but why bother? The longer I work with Lisp (and other programming languages) the less I like syntax. Most syntax is just a cheap trick which distracts from, rather than makes clear, the underlying functionality of the code. Lists of atoms and lists were good enough for my grandparents, damnit, and they are good enough for me!
Really? No structures, classes, vectors or hashmaps? Lisp has plenty of great data structures that perform a lot better than lists. I don't think anyone is building large scale software out of lists of atoms anymore...
Thanks for the review ! I like the pluralized style, though it would be tricky to get right for structure names, the typecases one is very nice. The example was just the next thing i was writing at the moment, not the most relevant but it was simple enough. 
 (defun dot (object slot &amp;rest more-slots) (if more-slots (apply #'dot (slot-value object slot) more-slots) (slot-value object slot)))
You're welcome; I am still learning, so it was nice to get some exercise in. Some things that bugged me about my suggestion (a chance to get them off my chest): my etypecases is missing the condition signaling (the "e" part) and would need a little support there with some defined conditions. There is no checking or DWIMing for correct number of types per case. It would be nice if there was a convenient shortcut to express "for all other cases" aside from a bunch of t's. Alternatively, one could do four defmethods (even loop their creation or use that neat module on cliki that lets you do ML-style method definitions). The main point of the suggestion was to propose a clearer code arrangement, but my implementation leaves out some details. Thank you for the contribution.
Every system written before you is, by definition, legacy ;)
I really don't know why I'm getting downvoted. I like this.
Don't confuse syntax with semantics. Lisp _syntax_ is a list of atoms and lists, by default. It is true there are reader macros to create specialized data structures, but you can also create them with regular function calls, which are syntactically represented as lists of atoms and lists. Lisp has every data structure imaginable, and I use them all (although I tend to use lists unless a specific requirement demands otherwise).
[Don't work for Paul Graham](http://xach.livejournal.com/146281.html).
And how do these macros distract you from accessing slots ? From just the name of the macro you get the instance accessed, its type and the slot you want to access. With little tweaking you can take advantage of (:type :list) in your structure definition. I don't see how cadddr and nested lists would be less of a "cheap trick".
must have been nice, but how did you avoid the namespace and type collisions then ?
Same for me, but sometimes you have to deal with a few structures in the same code and repeated calls to slot-value, accessors, with-accessors, or with-slots can be really obtrusive, then the dot notation can be useful. Of course it's just a tool, I'm not advocating using it.
I'd use function composition to create named and unnamed functions which operated directly on the data structure in question using the same semantics as the naked functions. This way the code is clean, and it only depends on the functions you compose with the bare functions as to how the data structure is implemented. Merely changing those functions changes the code. With slot access as described here, your structure is leaking all over your code.
I like a good technical debate to weigh the pros and cons of approaches. Can you post an example of your system that I can place next to billitch's to compare?
So suppose we want to sort a list of objects on a particular key (stored in key-name) (neglecting that there is support for this already). I'd write that as (sort lst (decorate #'&lt; (partial #'get-slot key-name) (partial #'get-slot key-name))) There are two higher order functions which are related to composition. `Decorate` takes a function and a list of functions, and returns a new function which applies the listed functions to each argument before calling the function to be decorated, in this case `&lt;`. The second function is `partial` which "partially applies" a function to some arguments. Partial returns a new function which takes fewer arguments and is "waiting" for the remaining ones, in our case, the objects to pull `key-name` out of. Neither decorate or partial are standard Common Lisp functions, but they are easy to write. Even if this seems less transparent than using slot accessors directly, when you start to realize that about 80% of functions are combinations of different kinds of compositions and other functions, programs become terse, abstract, and have a low error rate. Note that this locates the business of slot access in just one place. The sort algorithm is used without any kind of change. The only way to really get good code reuse is to keep your abstractions in tightly limited places.
Your original comment was the source of confusion as you stated that only only used lists and atoms. That was misleading.
I meant for syntax.
First rule, no whining. Second rule, no pithy responses. Third rule, you do not talk about fight club. Follow those rules and you wont get downvoted. (I like it to.)
Folks, I don't think the Rails code-base is "legacy". I think it's just good ole Kenny trolling the infidels in his usual way, bless his heart. 
This was posted here just a week ago. 
Thank you so much for this post. Just what I was looking for, without realizing it.
I was looking for something like this and didn't know it existed!
Ok, I'm working through the book. So far so good. I've reached Chapter 6. I like working through creating a game. So far, I like what Lisp has to offer. I'll let you know how it works out for me once I've finished. 
What would you say some of the downsides are?
1. Standard is a bit dated and doesn't include things which modern programmers find necessary (multithreading, sockets, unicode...) but includes some cruft which is a legacy of older systems. (But if you're programming for a certain implementation you can find those missing features implemented as an extension and you can find some compat libraries which provide uniform access to these extensions.) 2. Object system is not integrated into the standard library, that is, most standard functions are not generic, you cannot extend them to handle your own types etc. (But for people who do not like objects it is a good thing.) 3. As there are many different implementations it might be hard to find library which works with yours, libraries are not organized into repositories, and, finally, there are less libraries than for more popular languages. (For larger projects it is less of a problem; there are some library-writing and organizing efforts out there like quicklisp.) 4. Dynamic typing might be not good in some cases; type specifications, while possible, look kinda cumbersome and I think it could use more type inference. (Although maybe it is a problem of making a proper implementation.) 5. It lacks features which are found in functional languages like ML and Haskell. Pattern matching, for example. (But you can find a library which does this in some form.) 6. Garbage collection might be not suitable for some applications, especially since it is not of top-notch quality in some implementations, e.g. I don't know any with realtime, low-pause GC like Java has. 7. CL tends to produce pretty large binaries which is bad for some uses. (But usually you can find some tradeoff.)
Thanks. I like that the writer draws in Clojure and Dylan and gives some guidance for Scheme. I've found the first article, The Nature of Lisp got me thinking about how languages and syntax can work.
In `x-coord`, `(round (/ pos 10))` returns the same first value as `(round pos 10)`, see the note at http://www.lispworks.com/documentation/HyperSpec/Body/f_floorc.htm In `check-guess`, `(and (&lt;= guess 99) (&gt;= guess 0))` is the same as `(&lt;= 0 guess 99)`. Please use keywords (like `:east-west` or something) instead of magic numbers for directions, and maybe for the values of `*board*` too. Storing `*ans-board*` as an array is probably suboptimal. You can probably just store a list of ship objects which maintain the data of where they are located and which of the coordinates they cover. To check whether they are hit, you just loop through and ask each of them if they cover the indicated coordinate. This also solves the problem of how to report when a ship is sunk. Note that you could get two hits at a time since you don't check whether ships overlap. Also, code for manipulating the data seems to be mixed into the code for user interaction, eg: `fire-shot` calls `show-board`, which I would find unintuitive personally. 
It seems like his rant is mostly against having to learn emacs to code in lisp.. He seems to have had some success using viper-mode though :-)
&gt;Vi and Emacs are long time rivals, [snip] &gt;And, most importantly, both of them have incredibly steep learning curves. Really? incredibly steep? It does take some investment of time, but I'd say learning either one is relatively *easy* for a programmer. Learn the very basics, print out a cheat sheet and then consult it whenever you're stuck.
But does he complain that he has to learn lisp in order to program in lisp?
cannot help but repost the [emacs learning curve](http://blogs.msdn.com/b/steverowe/archive/2004/11/17/code-editor-learning-curves.aspx) :-)
Lol! I suppose that is the definition of *incredibly* steep ;P
&gt; It seems 100% crystal clear that if you want to be a Lisp developer, you have to use Emacs. [...] I suspect that this is the major reason that Lisp isnâ€™t more popular. Clueless.
Learning a new editor _can_ be pretty painful, especially if you're trying to do something at same time. But newer versions of Emacs follow common conventions (w.r.t. default keybindings) and so you don't need to learn anything to edit text files. Sure, there are some Emacs-specific things and some things one might want to change, but from a practical perspective Emacs is just like any other editor there, no need to learn basics. Vi is entirely different story, though...
You can pry my emacs out of my cold, dead hands.
I like what you describe, sounds very much like SICP, but isn't this indeed completely orthogonal to my syntactic macro ? My point was only to reduce the verbosity of possibly nested slot-value calls in boring, structure or class ridden, glue code. How the heck could that be opposed to "use lists, they're good" and "higher order closure-based calculus" ? 
What do you use? I'm always running into the heap size limits on the 2 other Lisp IDEs that are available for free - LispWorks and Allegro. (The restrictions on what kind of software you can develop on them is also pretty unfortunate.)
Incredible. Quicklisp really leverages Lisp development.
&gt; But newer versions of Emacs follow common conventions (w.r.t. default keybindings) and so you don't need to learn anything to edit text files... Emacs is just like any other editor there, no need to learn basics. What have recent versions of Emacs done to enable standard keybindings aside from accepting CUA cut/copy/paste bindings? I don't think there's anything. C-g (not Escape) is still abort, C-x C-s (not C-s) is still save, C-x C-f (not C-o) is still open, etc.
Any particular reason why &gt; (setf *random-state* (make-random-state t)) instead of &gt; (defvar *random-state* (make-random-state t)) ?
When you're _editing_ a text file you just need navigation within the file, moving cursor, copy/paste and typing letters. You can use common keybindings to do this stuff in Emacs. The only thing which is frequently used but has different key is search -- C-s instead of C-f. But it is not that hard to remember, is it? I guess people are confused because Emacs tutorial still teaches traditional Emacs key combinations for moving around -- C-p, C-n, C-b, C-f -- and so on. Open/save and stuff like that is done before/after editing a file, not during. It is done relatively infrequently and so you can just use menu to do it. There is a large save icon, I really do not see how saving could make learning curve steep. If you need to save file each second I'd say you're doing it wrong.
&gt; If you need to save file each second I'd say you're doing it wrong. Or you've experienced data loss in the past, and hence are as paranoid as I am. ;) But I understand your greater point: once you've got a document loaded, editing that document in Emacs isn't tremendously different than editing it in the vast majority of other editors. But I think the *largest* point is that: if you believe that to do professional-level Lisp work you need something beyond * a Lisp implementation * a text editor that matches parenthesis * copy and paste capability ...then your options are * Emacs - which doesn't hobble your development environment and lets you develop whatever kind of software you want * Commercial implementations (LispWorks and Allegro) which are both hobbled and have various restrictions on what you're allowed to develop using them
&gt; But I think the largest point is that: if you believe that to do professional-level Lisp work you need something beyond ... Yep, sure. But I thought we were discussing experience of beginners who only try Lisp (and they don't know whether they would be using it professionally). My point is that these newbies shouldn't be whining as much as they do because Emacs isn't really that bad. I guess most complaints are merely due to unfamiliarity (it doesn't look like a Java IDE!) or it comes from those but-I-want-to-use-vi guys. &gt; Commercial implementations (LispWorks and Allegro) which are both hobbled and have various restrictions on what you're allowed to develop using them Hmm, I heard that they are not that bad. Lispworks doesn't restrict what you can develop AFAIK. But sure, at least when you're learning Lisp sticking to just one implementation isn't a great idea.
Learning Lisp at the moment, and really, really dislike emacs. Seems pretty spot on comment to me.
[\*random-state\*](http://www.lispworks.com/documentation/HyperSpec/Body/v_rnd_st.htm) is a standard variable. Setting it like that guarantees that the random state is fresh, rather than one saved in an image, which would result in repeating random numbers on Lisp restart on some implementations.
&gt; But I thought we were discussing experience of beginners who only try Lisp Sorry, you're right. I got my conversation threads confused. &gt; My point is that these newbies shouldn't be whining as much as they do because Emacs isn't really that bad. I guess most complaints are merely due to unfamiliarity (it doesn't look like a Java IDE!) To be fair, there's a pretty big jump from basic-editing-of-a-single-document-in-Emacs to the functionality offered by a Java IDE. &gt; Lispworks doesn't restrict what you can develop AFAIK. Barring semantics, I think you're fairly correct. I might have been thinking about Allegro and a no-commercial-software clause. I can't keep the restrictions straight... Though I must note that [LispWorks Personal](http://www.lispworks.com/products/lispworks.html) "does limit program size and duration and it does not support application delivery."
Thanks for the clarification.
&gt; You can pry my emacs out of my cold, dead, crooked by RSI hands. FTFY
I'm on my phone so a short reply: check [http://www.cliki.net/development](http://www.cliki.net/development). The tools mentioned there are in various states of usability. Basically you need your favourite editor and a Lisp with a REPL with command history (and ideally also tab-completion), so that means one of: * CLISP * the Linedit package * using rlwrap The latter won't give tab-completion. If you're becoming a serious developer you could also consider *paying* for the commercial implementations which removes some of the restrictions you mentioned.
*If you're becoming a serious developer you could also consider paying for the commercial implementations which removes some of the restrictions you mentioned.* Totally. So jaybee's criticism of the view that Emacs is required ("Clueless.") is not so close to the mark. There are *several* other options: 2 restricted commercial implementations. Boy howdy! I sense a renaissance in our near future!
Sigh...
Do you care to contribute anything more than a downvote to my comment and a "Sigh..." response?
Honestly, I had more problems when I was using Vim. If you use the extension capabilities of emacs correctly, then you shouldn't be making many keystrokes. Although it obviously depends on what you are doing.
You'll probably learn to love it, SLIME is so good that the emacs RSI is worth it. Protip: remap caps lock to ctrl
I believe I can answer this. I had to think about commonlisp's response, and his original message makes sense. The message is: Why do this in the first place? It makes things harder to maintain. Let me see if I can illustrate it more clearly, for the both of us! I will use his example. My goal is to put his side-by-side with yours. Let's say I want to implement a "sort" function. My input is a list of objects, my output is the objects sorted, and the thing I want to sort by is the "foo" accessor/method on my objects. Let's further assume that the only tools I have are the basic ones you provided: with and define-structure. Then here is the sort (pretend sort does not have a key; sort could be some arbitrary function for working with things, so we cannot assume it was built with a key param): (define-structure obj-struct foo ; a number bar) (defun obj&lt; (a b) (with-tree-node a (with-tree-node b (&lt; a.foo b.foo)))) (sort obj-list #'obj&lt;) And here is a functional alternative: (defun make-obj&lt; (key) (decorate #'&lt; (partial #'get-slot key) (partial #'get-slot key))) (sort obj-list (make-obj&lt; #'foo)) Now let's talk about maintenance. Let's say I need to sort by bar instead. (sort obj-list (make-obj&lt; #'bar)) What about sorting by the negative of bar? (sort obj-list (decorate (make-obj&lt; #'bar) #'1-)) In order to have these three situations simultaneously under your system, I would need to define a different obj&lt; per scenario that uses the appropriate dot notation. If we generalize our functions, we can instead combine functions as needed. Thus, a standard of having that tightly-coupled syntax actually inhibits maintenance, inhibits flexibility. If this isn't clear, I propose that it can take a bit of mucking around with this code in complex situations to feel the difference. 
DEFVAR will declare the variable special even if it exists, and while \*random-state\* is already special, it still violates package locks on SBCL, since modifying properties of symbols in COMMON-LISP package results in behaviour undefined by the standard. But anyway it is more important to indicate the ownership of the variable to the reader of the code properly, and DEFVAR would suggest that the author of the current file "owns" it, which is not true and possibly confusing.
Better tip: swap Alt with Ctrl.
&gt; What about sorting by the negative of bar? &gt; (sort obj-list (decorate (make-obj&lt; #'bar) #'1-)) i think you meant (sort obj-list (decorate (make-obj&lt; #'bar) #'-)) Perhaps my example was misleading. I do not wish to sort structures, there's already #'sort for that... My point was to shorten code and reduce eye pain when muckin around with many structures. Again, the functionnal style is awesome and dynamic, but not every code is a regular, nice, rational piece of factorisable closures. I'm not intending to define a new language of structures here, I intend to speak a lot and to make it fluent. Think ACPI tables for example. You cannot hide much behind semantics when facing arbitrary data. But with Lisp you can make it sweeter. 
Well here is one way to have dot notation for slot access. It is easy to come up with a much more dynamic syntax. For this project I wanted a fast and static access to various predefined structures and i liked the result.
&gt; i think you meant (sort obj-list (decorate (make-obj&lt; #'bar) #'-)) Or (sort obj-list (decorate (make-obj&lt; #'bar) #'1- #'1-)); sorry. I mean to subtract 1 from each of the two parameters. The point was not to implement sort but to implement some function that would benefit from the comparison (&lt;). We are familiar with sort's semantics, so it made for an easy example. :)
So your games are free. How are you paying the bills?
http://www.stanford.edu/class/ee380/Abstracts/070214.html is the actual link to the talk. There, the slides are downloadable as pdf which was good because they are kind of hard to read in this video.
I forgot it was a proposal and looked for the link to watch it. Good idea :)
&gt; However, if you've wanted to build anything actually useful with Lisp, you've historically been in the position of having no vibrant, powerful open source community to draw on. WTF? Is there any problem with using, say, SBCL and Hunchentoot? It works, it is easy, it is used by many, it is actively developed, there is a community. I'm pretty sure community behind SBCL+Hunchentoot combo is much larger than behind "Sibilant" (I guess it is probably one guy and his dog). I wonder why bullshit like this perpetuates. Why didn't they at least try to do something before bashing what they do not know?
For the more textually-oriented among us, the PDF is [here](http://labs.oracle.com/features/tenyears/volcd/papers/14Steele.pdf).
In my experiences with both the common lisp and node.js communities, the node community is enjoying a lot of enthusiasm right now as compared to the CL community. CL has libraries, has their share of competent developers, etc., but (in my opinion) many of the libraries aren't very well documented (part of this is due to the sheer backlog of ancient code from past decades), and it's a little hard for new people to dive in. Node.js, on the other hand, while not having very many mature libraries, has a lot of developers that have been writing client-side javascript for a long time, has a lot of people pretty excited about about the whole async thing, and has a pretty solid group of people using node.js "in the trenches" (sencha, LearnBoost, Nodejitsu, StackVM) and contributing lots of new, exciting code. I don't really say this to dump on the lisp community. Hunchentoot looks pretty awesome, I really like quickLisp, everyone I've talked to has been awesome, and I'm really wanting to get my hands more messy with CL once I'm not having the holidays and my thesis smacking me around. I do, however, see why people would complain about the CL libraries situation and why one would want to develop a lisp on top of node.js. I will say, however, that I'm skeptical about the *value* of a lisp implemented on top of javascript. I guess my feeling is that moving too far away from an "it's just javascript" attitude with a language implemented in javascript (\*cough\*coffee-script\*cough\*) will end in a bit of a clusterfuck. As an aside: Node.js's major claim to fame is that it does pretty much everything asynchronously, meaning it can handle lots of concurrent requests very well. How well does Hunchentoot handle concurrent connections? Also, node.js and websockets are pretty much a dream with things like Socket.io---can Hunchentoot handle these? Not a lot of webservers and frameworks can handle these things particularly well as compared to node.js, which is one reason to, say, use node.js over RoR or Hunchentoot.
i &lt;3 xach
I met him and heard him speak at the first Start-Up School talks. I don't think I'd get myself in that position.
Absolute garbage. The point of Lisp macro usage is completely missed by the author : https://github.com/jbr/sibilant/blob/master/lib/macros.lisp 
Is this man a wizard?
very cool. thanks, Xach
&gt; I do, however, see why people would complain about the CL libraries situation and why one would want to develop a lisp on top of node.js. A bit of problem here is that "lisp on top of node.js" won't be a Common Lisp but some new bastard dialect. While if access to mature libraries is indeed a problem you could use ABCL which is a real Common Lisp running on top of JVM with access to all Java libraries. &gt; How well does Hunchentoot handle concurrent connections? It uses thread-per-connection model which, I think, is enough for 99% of applications. (Considering that many applications never even get to having lots of users.) If you need to handle thousands simultaneous connections then, I guess, you'd have to use some other web server. As I understand teepeedee2 does it: "However, it also includes general support libraries ... for doing fast networking in a continuation passing style, i.e. fast event driven userspace threading". Haven't tested it, though.
Thanks for the link. I would recommend that anybody who hasn't seen it before watch the first nine minutes of the video (= the first three pages of the paper). There's something very clever going on that isn't nearly as good on paper. In fact, the way I usually read papers--skimming first for novel content, then going back to read in detail--I probably would have entirely missed it. 
Well, why not? You can overwrite it by reader macros, so its good to specify it in detail.
It makes perfect sense, but I never thought about it. 
This is a great talk! 
the whole string concatenation already looks ugly...
&gt; A bit of problem here is that "lisp on top of node.js" won't be a Common Lisp but some new bastard dialect. I completely agree. This is why I'm skeptical of the value of a lisp-on-js. I actually started poking at parenscript earlier (I figured running 'compiled' parenscript on node.js may be worth investigating), and I came to realize that PS, too, is pretty awkward in a lot of ways because it's trying to control js underneath. &gt; It uses thread-per-connection model which, I think, is enough for 99% of applications. Indeed, most webapp frameworks roll with this model. You may find it interesting to compare 2010 entries to the [Rails Rumble](http://railsrumble.com/) vs. [Node Knockout](http://nodeknockout.com/), as node.js's model opens doors to some pretty interesting possibilities that are next to impossible to handle in Rails (last I checked). There are definitely libraries that can handle asynchronous CPS connection action for CL, as I looked into it when considering making a port of [dnode](http://github.com/substack/dnode) to CL. I don't remember which off-hand and am too lazy to look it up, but it's easy enough to find in the cliki.
Yup. Don't just skip through it either. My wife came into the computer room about half way through the talk and was thoroughly put off by his use of terms like "Five and Twenty" until I explained what he was trying to do.
Yes. He's contributed to the specification of more languages than most people will ever know.
I don't quite see how you could otherwise standardise a language without specifying how it's read.
Wow, parentheses aren't referred to directly in this. They may be referred to indirectly (e.g., if close-paren is a "terminating macro character), but I can't find out how.
Most languages don't specify how a lexer works. They specify a syntax mostly.
Clause 4, I'd say. A parentheses is a 'macro character'.
Right, because they don't expose the lexer to user code. But CL does as an extensible facility, so it has to specify it. I guess what I'm saying is that it's the wrong place to wow: it should be not "wow, CL specifies how the reader facility it defines should work", but rather "wow, CL defines and exposes the reader facility".
Right, for many other languages, the lexer (or the comparable facility) is gone once the program is running and/or it is not extensible in a standard way.
&gt; I'm pretty sure community behind SBCL+Hunchentoot combo is much larger than behind "Sibilant" (I guess it is probably one guy and his dog). Hunchentoot is just a guy (Edi Weitz), so as long as the community behind SBCL is larger than a dog, I suppose your math for Lisp still comes out on top. But there are no silent masses developing these Lisp projects, as far as I can tell. EDIT: Out of curiosity, I counted the number of [SBCL comitters](http://git.boinkor.net/gitweb/sbcl.git/shortlog) over the last 6 months: eight.
I guess "The Standard for the Lisp Reader Algorithm doesnt talk about parentheses" would have been the more suitable title.
There're these things called "grammars".
Not a great example: * Uses a "normal" OO style of treating objects as buckets of slots, rather than a more CLOS-like GF-centric approach * Prefixes generic functions with class names It would be interesting to see an iteration of this project that was closer to how I like to use CLOS.
I'm not sure I can follow. Can you point out specific parts of his code that you would write differently? Especially for point 1. How is are generic function an alternative to 'a bucket of slots'? (I'm not saying anything against your remark, I just don't understand it fully in the context of his code.) Point 2, well yes and no. The typical reason is to avoid that functions with the same name (like 'x') end up in the same generic function, which is sometimes not desired. For 'larger' software packages will prevent that. 
&gt; Uses a "normal" OO style of treating objects as buckets of slots, rather than a more CLOS-like GF-centric approach I think one "problem" is that there has not been a good primer on idiomatic CLOS style. PCL's treatment is good insofar as it starts with generic functions and then moves to classes, but for people moving to Common Lisp from another OO language I suspect the Option 9 approach is common. 
I would start by writing generic function definitions, sometimes with a plain defgeneric, sometimes with a default method that implements the generic semantics in terms of other generic functions. Then I would write defclasses that implement some of the methods of the generic functions via :accessor or :reader. Then I would add class-specific defmethods like print-object and the other generic functions initially specified.
That's just one reason. I hate to say it this way, but this page is "Full of Win."
I wouldn't do this. I would write a a bunch of classes, a few methods, get something, refine it and repeat. If he has an idea what kind of objects are needed in his game and he writes down the classes for them and brings them into a hierarchy, I think that is still a valid approach. I would also think about a linguistic construct that makes writing down these things less of a pain (or copy/paste). What is the start to get one thinking? Is it operations like 'collide', 'move', 'shoot', ... or is it ship, enemy, debry, planet, ... - I'd say it depends and that there is no single rule to follow. He has generic functions in his code for the operations.
I would criticize your code in the same way, then. More specifically, I think about the objects, too, but I think about what I want the objects to *do* first, both by themselves and by interacting with other objects, and I use that to flesh out a protocol of generic functions. After that, I think about how defclass can save me some work when implementing the protocol. 
Agreed with this. My initial reaction was they were more lispy, in the sense that (var.method1.method2 arg1 arg2) looked wrong. The real power of multiple dispatch is not always obvious, or I'm not that bright ;-)
I find if I start with classes, I tend to look at generic functions more like methods in more 'traditional' OO languages so I end up with a lot of things like (defgeneric gf (object arg arg)) (defmethod gf ((object type) arg arg) ...) Instead of 'true' generic functions. EDIT: By this I mean I tend to pin a method to a class, which works in some cases, but tends to miss the root of the problem. I'm sure Xach or someone will do a better job articulating my point.
I find that when I start with the generic functions, I feel more free to implement them in ways other than just referencing slots. The components need not even be stored in the instance.
I think people who just use software and participate in discussion in some way are also important part of community -- at very least they help with testing and steering project into the right direction. But they also can help with documentation (mailing list archive is a form of documentation too), examples, and some even contribute patches. So even if there is only one maintainer it does not mean that only he is developing the project. 
Why? (defclass thing () ()) (defclass ship (thing) ()) (defclass planet (thing) ()) Why should I now define (defmethod collide-with-ship ((p planet) ship) ...) or similar, instead of (defmethod collide ((p planet) (s ship)) ...) In message-passing OO it would be correct to find verbs that have a single subject. Even in CLOS there are lots of activities (verbs) that have only a single subject (plus zero or more additional parameters). I tend to identify nouns and verbs. Verbs can mean activities which involve more than one object. But it does not mean I start thinking about all the verbs first. What is important is that there are activities like 'print', 'collide', 'explode', 'touch', 'land', ... and to think of them as what objects do they involve, what are their preconditions, what are their effects, who invokes them and is it useful that the activities are objects themselves (do I want to pass them around, store them, etc.). I would not know why in a game with entities on the screen I would not start with naming some of these entities and then describe the kind of interaction between them. I would also not know why that should lead to a non-idiomatic CLOS design. It would be interesting to see Xach's remarks expanded a bit (how about a blog-post ? ;-) ) so that there is some input for a style discussion. 
I've not yet read this page carefully, but I would like to say a few words. I think it *is* a great example, and I wish there were more pages like this. The program's design and implementation is not perfect, but it's certainly not bad. The author also says that these are "live sources", i.e. it is not fixed code. With regards to prefixing generic function names with class names: I do not mind it if the name is of a protocol class. In fact, that is my usual convention. It seems the author did attempt to think about protocols. Certainly, there's room for improvement, but it's not a bad start. In this case, where I have a small program already written, I would try to factor the code a bit before coming up with protocols. For example, take the function MAKE-EXPLOSION. It may not be terrible, but I think it's too ambitious: it groups several functions into a function. The use of WITH-ACCESSORS is a symptom of such ambitions. [Here's a quick attempt at factoring it](http://paste.lisp.org/display/118178). You can see that the functions are very simple. Several of these functions are quite general utility functions. Only EXPLODE is side-effecting (ignoring effecting of random state), the rest can be tested very easily in the REPL without much context. They also make it easy to think up Functional Protocols, a concept described in [The Art of the Metaobject Protocol](http://www.amazon.com/Art-Metaobject-Protocol-Gregor-Kiczales/dp/0262610744/ref=sr_1_1?ie=UTF8&amp;qid=1293821259&amp;sr=8-1), with some consideration for the parameters and points of extension.
I might write some stuff sometime. In the meantime, http://www.xach.com/naggum/articles/3243735416407529@naggum.no.html aligns with my thinking and has a bit more detail.
So far [BuGLe](http://www.opengl.org/sdk/tools/BuGLe/index.php) has been the best I've found. It uses a pass-through method to record the calls going to the opengl .so lib. I've not worked with it in quite a while, so I'm not sure if it will give you what you want with your shaders...And if the gldb-gui you mention in your question is the same as the one in the BuGLe tools, I guess you've already found it... When I've used BuGLe, I usually set the config file to what I want it to log and then call LD_PRELOAD=libbugle.so sbcl --core "my-opengl-app-saved-core" or similar with correct pathnames etc. I'm not exactly sure why the gRemedy etc tools won't work but I'm pretty sure it has something to do with them assuming C-world binaries and/or memory models and Common Lisp (SBCL in my case) breaks those assumptions. You also might want to try the cl-opengl mailing list. They might have some better ideas. Regardless, CL inspection tools for GL are lacking... :( I
I'd love to see more people write programs and get people to discuss them publicly, and I think this is a great example of that sort of thing. But I don't think it's a good example to base your own project on.
&gt; I might write some stuff sometime. Please do.
&gt; I think one "problem" is that there has not been a good primer on idiomatic CLOS style. I would say that Sonya Keene's book "Object-Oriented Programming in Common Lisp" serves that purpose. 
While Keene's book is good, it was written in the late 1980s contemporaneously with the development of CLOS. It is certainly a primer on CLOS, but it shows its age. There has been 20+ years of CLOS experience now which is not (ahem) encapsulated in her book. This is what I meant by "idiomatic CLOS style". 
Thanks. I've managed to get some useful output using BuGLe without its gui, which should be enough to stop me banging my head against a wall when the time comes. &gt; CL inspection tools for GL are lacking Yes but being able to redefine and inspect parts of my app while its running more than makes up for that. The compile &amp; reset the world way of working in C++ was boring me to the point of giving up with OpenGL all together. :)
hello, just keep in mind this article is very old and i sort of forgot it was still up :) enjoy
That code is pretty ugly, and uses ugly, hackish ways to achieve things that are available in portable, standard ways .
Hello Xach, about 1/2 of my work in 2010 involved Clojure. In the last 5 years about 1/2 of my work involved Common Lisp (or recently Clojure). Clojure: machine learning of social media Common Lisp: lots of stuff, mostly medical data crunching
Wow, you certainly had a productive year of lisping. Mine was mostly just learning Lisp, and working with the cl-graph package, which was quite a pleasant experience. ... Before I was cruelly torn away and thrown back into a world of Perl, Python, and C.
2010 was a good year for my lisp usage. Used it quite successfully in my (now finished) degree. Just basic stuff in a databases course and an OS theory course. Got a few surprised looks from professors I think, and one "I didn't know LISP could do that" comment in an evaluation. With Quicklisp making it so easy to grab and install libraries, even those outside of Xach's ecosystem, CL has really become the first tool I reach for. Big regret was not checking the Boston Lisp Meeting schedule before traveling there this summer. Could have easily made the July meeting if I had thought about it. I've been playing around with RDF on and off for the last few months, and am now looking into text searching. There's a large dataset I've been using that I think I could really pull some interesting and non-obvious data out of so I'm hoping to get some time to really develop that idea. 
My 2010 in lisp: * Released the first three episodes of [The Weekly REPL](http://lisp.geek.nz/weekly-repl/), a new lisp podcast, after many months of fooling around with the idea. It took so long to discover that it was feasible, as I experimented with different publication frequencies and formats, got into a rhythm, and basically privately produced pilot episodes for a while. * Re-seeded the notion of a [lisp user group in New Zealand](http://lisp.geek.nz/) â€” we're still organising, but I finally got things moving again after letting it simmer on the backburner for four years. * Helped establish the budding [lisp games community](http://lispgames.org), following the lead of [David O'Toole](http://lispgamesdev.blogspot.com/) and others. We set up a wiki under a sensible domain name, and a [@lispgames Twitter account](http://twitter.com/lispgames) (a la [@quicklisp](http://twitter.com/quicklisp)), and began holding [week-long lisp game development competitions](http://lispgames.org/index.php/2010_October_Lisp_Game_Dev_Competition). * Started to use and contribute more to the [CLiki](http://cliki.net/), also releasing [slicker-cliki](http://abhishek.geek.nz/code/slicker-cliki/), a userscript to enhance the usability of the site. * Published [some](http://abhishek.geek.nz/code/cl-charms/) [other](http://abhishek.geek.nz/code/py-configvalidator/) [bits](http://abhishek.geek.nz/code/dated/) of lisp code. * Started using [Quicklisp](http://www.quicklisp.org/), answered the [SBCL User Survey](http://random-state.net/sbcl-survey-2010.html), learned more Scheme, etc etc. There's a lot going on. Some projects have as yet borne no fruit. One in particular involves Clojure web development â€” it has been my main Clojure focus lately, and will get more love in 2011. Another is lisp on mobile platforms (especially Android) which I'm still just playing with. But mainly, this year, I'll be trying to improve the podcast and its web presence... or at the very least keep up the frequency. And also help establish the NZ lisp group.
Reading SICP, hacking Emacs.
I had 9 months of contracting for a database vendor, doing low-level Lisp stuff using Allegro CL. This was pleasant in that I did not have to consider portability, and unpleasant because I had to target a platform that sucks: Linux with ext3fs. Getting accurate memory usage information, making the kernel use a few gigabytes of memory in a sensible way, controlling what gets written to disk when, all no fun. In fall, I returned back to the Huge Common Lisp Project - A three tier application with Oracle underneath and Java providing the web layer. Again, being able to use Common Lisp in an environment that consists of arcane protocols and baroque data models coming from the 60ies was a great plus and made it easy to have some fun, too. End of year, got a small translation job, used Common Lisp and the BKNR datastore in a workbench-style setting. Symbolic computing was really helping, and Common Lisp was the kool-aid with its built-in symbol manipulation capabilities. Parsing the original text into lists of symbols and then using CL functions to find common substrings and the like was so easy and straightforward, it made me appreciate the language again. So: 2010 was a very good Lisp year for me, most of my income coming from being a Lisp hacker.
Oh man, this was the year I began learning Lisp! I started with Scheme in the spring for a programming languages class. Now I'm learning and playing with Common Lisp. Right now I'm working my way through Land of Lisp and Practical Common Lisp and enjoying every minute of it. I have a game or two that I'm interested in writing in Lisp and there is a web project that I want to do Lisp as well. I've been briefly looking into Clojure and might try to tackle one of those projects in Clojure instead of CL. 
In 2010, I didnt have as much time to spend on Lisp, so I didn't progress as much as I hoped for. For 2011, I've again the same intentions, to plow through the Lisp books I've managed to gather during the last year, finish my small (useless) pet projects, try to put everything I've learned so far into a (hopefully useful) small number crunching (optimisation) app (which seems not to yet exist in Lisp) and also hopefully get enough confidence to publish it. I've also thought about writing/translating an article or two about my learning process so far and publishing them also. Lisp is cetainly mighty fun.
2010 started with good intentions, but I veered off the road to hell (paved with Python) and returned to basics. ABCL was a revelation. Quicklisp was a revolution. ILC was a pity - too far away, too sparsely populated, I don't even really regret missing it. Struck down with second system syndrome in Q3, I hope to recover in 2011. Teclo, The Weekly REPL, ZSLUG and the post-Quicklisp explosion are my must-watch for 2011. And the intriguing Lisp-games community.
In my 75-employee Mac-based natural food store, I deployed the time clock program I've been working on for years. I also wrote a primitive scheduling program and continued to improve my refrigeration-monitoring program. Using LispWorks, I've reached the point where I can produce real, reasonably well-behaved Mac OS X applications. I look forward to making the refrigeration monitor into a web server, making the time clock/scheduling into a multi-user system, and using the skills I've gained to develop a point-of-sale/inventory management system. I've enjoyed Conrad Barski's Land of Lisp, and I continue to learn, relying mostly on Practical Common Lisp, ANSI Common Lisp and various documentation. I'd really like to get fluent with using Cocoa and Interface Builder through Lisp, perhaps using Clozure Common Lisp.
Used CL all year long in my day job, went to the European Lisp Symposium 2010. :-) Didn't have much energy for Free CL stuff other than minor CFFI maintenance. :-/
Still a student so my year was mostly learning: * Spring semester took a class with Prof Gerry Sussman on symbolic programming. I'm still chewing on the things he taught. * Paradigms of AI Programming: worked up to the Prolog compiler chapter. Got overwhelmed, will resume it later. * Land of Lisp: worked through most of the book, extending systems and rewriting them as I saw fit. Most fun was in the wumpus game... I totally rewrote it, added support for colors and shapes, incremental production of the game graph. Right now I'm actually learning Erlang, but I hope to be proficient in it to start hacking on Lisp Flavored Erlang (https://github.com/rvirding/lfe). 
In August I became a full-time professional Lisp hacker at Akamai, where I develop mobile content adaptation technology in Clojure. I also spent a great deal of my free time this year using Clojure in the context of a part-time Computational Linguistics MA program I am in, some of which can be found on my github page (a rudimentary clojure-python interop library to make use of nltk, and a web-based game demonstrating use of nginx server push). A couple other things I started got pushed on the back burner because I was busy with my new job and aforementioned work for my course. They are a personal organization system called Listful and an applet-based game called Word Honey (in collaboration with my wife Judy). Also related to Word Honey is a project I am calling Claplet or Caplet (I think I'm back to liking the name Claplet better), to abstract most of the Java level away when creating applets in Clojure.
'rewrote' some of my software in s-expressions as a way to understand it better, and wrote a simple lisp-on-javascript, so toe in the water, i guess :)
2010 was an excellent year! I've recently became a more independent researcher and I decide to use CL as my main language (best decision ever). Before I was always subjected to projects languages and what my supervisors/colleagues wanted to use (mostly C or Java). As a result, I did an Ant Systems library, two GP libraries (one for small/quick experiments and later a complete rewrite using CLOS), several parsers, CFFI bindings to a L-BFGS library and GMP (this one was more of a toy to see things working), a CL library of sorting algorithms (an hobby), started a prng library, submitted a patch for SBCL, and lots of other small stuff. I also started to use Quicklisp which made me more aware of lots of nice projects that I intende to play more seriously in the future. The libraries I am working own are still "vaporware" since I still didn't release them but that's my main goal for the first quarter of 2011: release them! Specifically, a new, modern and comprehensive GP library in CL, as well as one for Ant Systems (since these are directly related to what I do). Moreover, I want to release the prng library since it is portable across CL implementations and can be useful to more people. Finally, one of my goals for 2011 is to engage in more community related activities. I already made plans to attend a Lisp meeting in ZÃ¼rich and let's see what I can do more :-) 
That's awesome, what are you using for writing GUIs in your programs?
I took an introductory course to Lisp in my last term on my bachelor degree, in the first part of the year. Here I finally understood Emacs and managed to start using it regularly. During the course I grasped the concept and blessing of writing functional code, thus removing side effects. This have in turn made me a better Java programmer. A side effect of the Lisp course was that I started to use Linux regularly. Hacks where had here and there, Emacs was the aggregator for most of my work with Lisp. I got Land of Lisp and have been working some on that, mighty fun. This year I will definitely be using Lisp or Clojure for web applications and web related projects.
Thanks. I'm using the [LispWorks CAPI](http://www.lispworks.com/products/capi.html).
I just discovered lisp so I've only had about a month, but working through Land of Lisp and just starting Practical Common Lisp has been excellent, I look forward to doing something with lisp next year
This year was ok but not exceptional. A second child born into January 2010 took a lot of my spare time that would otherwise have gone into personal projects. I used CL for both [Google AI Challenges](http://www.ai-contest.com/) this year. My rankings were nothing to write home about but the contests themselves were very educational and highlighted deficiencies in my approach to such projects (and in my personality :-) ). The last challenge also reignited my interest in genetic programming which is something I'm playing with currently. Not much progress on most of [my GitHub projects](https://github.com/aerique/). A highlight was dto's [ILGE 2010](http://dto.github.com/notebook/2010expo.html) and my entry [Engine Troubles over Tentacle Planet](http://www.youtube.com/watch?v=RMwJXP8EOU4). Nothing much useful was produced for other people but I gained some more insight into using CL for game development and [ECL](http://ecls.sourceforge.net/)'s place in it. Besides that I use CL for almost all my personal projects and small things I need to do at work. Most of my day job unfortunately consists of maintaining legacy company software. I'm hoping for an [ECLM 2011](http://weitz.de/eclm2009/) this year to meet other Common Lispers again.
2010 was a very important year for me with regards to Lisp. It began in January with the release of [Paktahn 0.8.2](http://blog.viridian-project.de/2010/01/10/paktahn-0-8-2-released/), the first open source project I ever made contributions to and definitely the first time I had other people using my code. I continued to grow in comfort with the language throughout the Spring thanks to further work on Paktahn with a release in May, Databases and OS courses where I used CL for the course projects and an internship with a Lisp-powered startup. There was a lull in Summer due to a variety of factors but this was followed by a resurgence in the Fall. I began writing the [CL Web Development Primer series](http://redlinernotes.com/blog/?p=1277) and [Clockwork](http://github.com/redline6561/clockwork/) as a pedagogical aid and useful example. In November and December, I contributed some small patches to Weblocks too and have almost finished a Postmodern backend for it as well. I wrote a silly, possibly pretentious article called [The Spirit of Lisp](http://redlinernotes.com/blog/?p=1252) the response to which was flattering and really made me feel a part of a community. Over the Christmas holidays, I hacked up a quick [Tic-Tac-Toe game](http://github.com/redline6561/Tic-Tac-Toe/blob/master/lisp/tic-tac-toe.lisp) which has only further convinced me that I need to sit down and read PAIP. I'm finally at a point going in to 2011 where I'm less worried about whether I know Lisp or can use it to build things as I am about what to build and getting started. I'm really looking forward to what's next.
I've spent the entire year working solo on a self-funded Lisp project. I've used Lisp off and on for about five years, but it's been excellent to have things start sinking in the way they do when you can be fully invested in the language for a good chunk of time. Hopefully, 2011 will be the year when I launch my Lisp project and start making income again. 
Over the summer, I got my first job ever, which was to program in not-Lisp (Java). However, I still found time to read the first chapter of SICP. When school started, one of my classes was, "Independent Study: Programming in Common Lisp", which has been great. I'm about halfway through PCL, and am currently working on tic-tac-toe with a genetic AI (yes, writing an AI normally would both result in a better AI and less-crazy code. But I'm just doing it for educational purposes.) I also got *Land of Lisp* for Christmas, and am inhaling it. In 2011, I hope to reach a level of competence where I can spend the majority of my time working on a program coding, and not refreshing myself on the specifics of the stdlib. I want to finish PCL--including the practical projects at the end--and *Land of Lisp*. In general, I want to feel as comfortable with Lisp as I currently do with Python and Java, and also feel my knowledge of Lisp deeply influence how I write Python. My wildest dreams involve convincing my employer to let me write Clojure, not Java, but in reality I doubt it'll happen.
* Spent a while on Project Euler, doing 51 problems in CL and building up a decent chunk of utility functions in the process. * I started and am closing to releasing [my wrapper](https://github.com/masonium/cl-fann) for [fann](http://leenissen.dk/fann/)
Thank you.
2010 in Lisp: * Wrote a book about Clojure named [The Joy of Clojure](http://joyofclojure.com) * Released a heavily annotated version of an "early Lisp" REPL named [Lithp](http://fogus.me/fun/lithp) written in Python * Helped with the [DC area Clojure UG](http://meetup.com/Cap-Clug/) * Discovered [Quicklisp](http://www.quicklisp.org/) and started re-educating myself in Common Lisp * Discovered a great Lisp-related book *Architecture of Symbolic Computers* by Kogge. * Took over the [@learnclojure](http://twitter.com/#!/learnclojure) Twitter account. * Pushed a fair share of [Clojure projects](https://github.com/fogus/) into the wild via Github. 
An article on the Scheme reddit covers generic functions pretty well: http://www.reddit.com/r/scheme/comments/eupwe/coops_an_introduction_to_chicken_schemes_object/ Just remember, this is in Scheme and not CLOS, but the concepts are similar enough to xach's point.
That's interesting, in 2008 I did a CFFI wrapper for fann for some small experiments and to learn a little bit of CFFI. But never used for anything serious. Need to take a look at your library!
It's in a usable state right now (though it's not 'officially' released, and the documentation is pretty sparse outside of the included examples), but feel free to try it out and tell me why it sucks :-P
2010 was a productive year for me as a Lisp programmer. * I ported [ECL](http://ecls.sf.net) to the iOS (iPhone/iPad) platform, and made it robust enough to build and ship an iOS app with it. See [ECL/iOS](http://funcall.posterous.com/ecl-for-ios-updated-to-work-with-sdk-42) for more details. * I got to work on a fairly sophisticated web app backend in Clojure using Compojure, and Ring. This contributed significantly to [Cynojure](http://github.com/kriyative/cynojure) an open source Clojure library I'd been working on. * Aside from these, I continue to support a third Common Lisp code base (Lispworks), for a major client which continues to be interesting and challenging. All in all, a full plate for a solo developer shop. 2011 looks even better with new web/app projects using Common Lisp and Clojure. Wishing all Lispers (really everyone), a very Happy and productive New Year.
I started two months ago toying with MIT/GNU Scheme and reading SICP, then I started using Racket and learning to use Emacs. Now my laptot is just sbcl/emacs/stumpwm/conkeror/racket, so I guess my last Lisp-year was pretty productive. In 2011 I'll learn CL better and try to implement a toy lisp interpreter in some language, maybe C.
I don't understand why Dylan is considered as a Lisp. Can somebody explain me this ?
Good review. Made me realize that I was on the right path to learning CL. I have the PDF of LoL. And a copy of Seibel's PCL. And I'm taken the path that the reviewer mentions. I've learned Perl and a bit of C/C++ but Lisp really captures something about learning to program in language that I haven't felt since my first computer, the Apple ][e, and it's language, AppleSoft Basic.
This was the Dylan syntax before it went infix: http://groups.csail.mit.edu/mac/ftpdir/Thomas/Thomas-1.1/examples-from-book.text 
&gt; Mac-based natural food store Get a job, hippy! &gt; I deployed the time clock program I've been working on for years. oh, never mind...
Well, I would point you at the [D-Expr](http://people.csail.mit.edu/jrb/Projects/dexprs.htm) paper for some insight, or the Dylan Reference Manual. Dylan really *is* a Lisp-dialect, as much as Logo &amp; other "Lisp-alikes" that use alternative syntax. 
Hey, thanks for the plug! 
Changed jobs, from a startup that was partly Lisp to SRI, one of the last bastions of GOFAI and pure Common Lisp development. In both jobs, working on biological knowledge representation and visualization. As a spinoff from the earlier gig, released the [WuWei ](http://wuwei.name) package (web UI toolkit) and plan to do the same for a semnatic web based frame system that also came out of there. Despite some dalliances with Rails, Clojure, and Pythn over the last few years, I seem to always come back to Common Lisp for development, and now that I have a good infrastructure for building Lisp-based web sites (WuWei/OpenMCL/EC2) may do some more side projects with it. PS: as a Lisp old-timer, I'm pleased to see that Lisp is now hip again and there's a lot of new Lispers and Lisp activity.
Thanks for ECL/iOS. I'm planning to work with it in the near future. Now for the eternal question: did you ship an actual app using it and is it available in the Appstore? Is Apple aware of the technology used and do they not mind?
Actually, the store is what supports my programming, which is more often a leisure-time or vacation activity. It would have been so much cheaper to just buy a commercial product, but if my projects turn into a money-making activity, that would be nice.
I believe Apple has relaxed the restrictions about source language (see [here](http://mobile.dzone.com/news/apple-relaxing-sdk-license)). The only remaining restriction, if I understand correctly, is that apps cannot download and execute code on the fly. I'm sure there's a reddit discussion thread on this somewhere.
Originally Dylan was designed by taking a Scheme-like core language with a CLOS object system built-in from the start. So it was an object-oriented Lisp dialect - more than standard Common Lisp which added CLOS after designing the core language (CLtL1 was written without any trace of an object-system). One of the target audiences for Dylan were Pascal, C and C++ programmers. Programmer who were developing applications on the Mac. That was a time when Apple hadn't settled on Objective C. Apple did some stuff with the Lisp-like Dylan (especially writing an OS for the Newton) which were not brought to the market. It was thought that a different syntax (but eventually with support for macros) would help getting wider adoption. 
Just downloaded, run the examples and made a quick browse of the code. Looks good. I will take a more seriously look the next days. I'll send some feedback!
* Delivered well received 30 min presentation to the company on Clojure. Lost 1st place to someone using MS technology to animate video on jigsaw puzzle piecesâ€¦ granted, the piece surface continued to animate as it was thrown around the screen via multitouch, but still basically just a demo of stock technology * Convinced a total of 10 developers from the company I work at to attend [Clojure training](http://pragmaticstudio.com/clojure) * An active attendee at the DC area Clojure meetup * Helped extend scope of said meetup to include monthly hacking session * Attended the first Clojure conference. Some attendees happily and willingly shouted out knowledgable answers to Haskell questions, among others. Do watch the (Hammock driven development)[http://clojure.blip.tv/file/4457042/] keynote, it poses an interesting approach to problem solving: sleep * Bought a copy of Lisp in Small Pieces, probably Land of Lisp in the near future. Had a beer with Conrad -- cool guy :-) 
D'oh yeah! I started writing my first [Lisp interpreter](https://github.com/seth-schroeder/nihilisp)! N.B. the most useful version is a few commits back. I stopped in the middle of a medium sized refactoring :-|
Disclaimer; I hack Java, especially JEE in near real time enviroments for a living. Lisp is my hobby, mind candy, melon tweak, so I play with it in my spare time. My 2010 in lisp: * played around with various packages, mostly understanding how to add them to my SBCL install, clbuild is interesting and a bit hairy (to me) * compiled SBCL from source to include multithread support on OS X * added mod_lisp to Apache in my development environment. * hacked around with UCW, it's an unusual way to develop web apps * tried getting CLSQL to work in my development environment still no luck with that chestnut, time to punt and post some questions on a mailing list * played around with generating SVG with lisp in a manner similar to yacml and lml
Well, my lisp-related achievements are: * made CLISP [work](http://talk.maemo.org/showthread.php?t=42339) on Nokia N900; * helped to fix several bugs in CCL ARM port (Quicklisp didn't work there due to some of these bugs); * did some work on [CommonQt](http://common-lisp.net/project/commonqt/); * as a result of two previous points made CommonQt [work](http://i.imgur.com/6pWsk.png) on Nokia N900 (well, at least the tutorial does run, didn't try anything else yet); * wrote [swank-js](https://github.com/ivan4th/swank-js) that makes it possible to use SLIME for browser js (the project itself is implemented using node.js but still is SLIME =&gt; Lisp related); * published my [xml matcher](https://github.com/ivan4th/xml-match) (no one seems to care much but maybe it will see some use someday); * finished porting my mini-SCADA project to CommonQt, the day when I'll be able to make it open source is nearing. EDIT: formatting. EDIT2: just in case: (eq ivan4th fionbio) =&gt; T
The latest update was almost 2 years ago, and it doesn't look like it really even has any functionality (most of the code looks like utility functions)
I made [something](http://norstrulde.org/ilge10/index.html) for [ILGE 2010](http://dto.github.com/notebook/2010expo.html) and continued to /join #lispgames off and on for the rest of the year. There is a good chance that 2011 will involve more fun lisp game projects.
Over the course of 4 months read HTDP and most of SICP, read some emacs lisp tutorials and started using it a bit.
2010 was obviously huge for Common Lisp in just about every area of endeavor. This year I released a few new Common Lisp games, and finally got started wrapping a Scratch-style visual programming interface on top of my existing game engine, which I believe could significantly broaden its usefulness and appeal. See http://ioforms.org There is too much else to mention: Quicklisp, The Weekly REPL, the lispgames.org wiki, ECL on iPhone, and so on.... Special Thanks to everyone around the world who made 2010 a banner year for our language.
I really would love to see Scheme articles in /r/lisp as well.
2 of us spent the whole of 2010 working on a self funded startup. Our main development is in Common Lisp. Hopefully will launch in Q1 2011.
I got a prototype of a Goo-class [Lisp-&gt;C compiler](http://github.com/manuel/ell) working, that can bootstrap itself, and has advanced hygienic macros, in a small number of KLOC.
How much did you pay for the Clojure training? Did you do it as a private one? I want to convince my company to invest in it as well.
The per person charge was somewhere between $1000 and $1300. The intermediary company (Pragmatic Studio) offers discounts for groups and attendees for their second &amp; subsequent courses. This was a regularly scheduled, publicly available training course. The company I work for has a.) a *very* generous training budget b.) a requirement to take at least one "hands on" training course per year. With the end of the fiscal year approaching and "use it or lose it" as the policyâ€¦ I have been a steady source of propaganda about Clojure on the corporate internet and at company meetings. Specifically I started and continue to maintain an internal wiki page for it as well as giving a presentation with a no-emacs, don't-miss-the-immutability-for-the-parens path to Clojure. Advocating Clojure has been a long slow process. At the moment all the company is doing with Clojure is hosting a monthly community meetup... basically paying for some electricity, wifi, and pizza. Actually we've hired one great developer already and have a resume from one other developer so that has been positive. Best of luck in your efforts -- may they lead to many more parens :-)
It seems that you care less nowadays. Do you think the situation wrt (require 'cl) has improved, possibly since RMS stepped down as an Emacs maintainer, or are you are just working more with Common Lisp and less with Emacs Lisp?
Thanks for the explanations :D
it would be helpful to mention the resources one can expect to need to maintain/host the site
New Lisper here. I searched for a good LISP IDE last week and now I'm using Emacs + SLIME. It's really nice, but I could not make it work with CLISP, so I now use SBCL. It's really a shame that the choices are so limited. 
[Rob Warnock's IDE advice](https://groups.google.com/group/comp.lang.lisp/msg/6e91e20f2f371b52?&amp;noredirect) is pretty great.
&gt; The Weekly REPL I love it. Great job so far. :-) 
slime works fine with clisp, what was the problem when you tried to run it? regardless sbcl is awesome
Is this story supposed to make Paul Graham look bad? As smart as that Trevor is, in Paul Graham's position, I'm not sure I would hire a guy who thought rewriting our whole code base in a different language was a good use of his time.
Or why Bill is getting off the project.
Emacs+SLIME is the de-facto standard. The LispWorks' IDE seems pretty good too. There isn't too much choice, as what we've got is already "good enough".
OT but irresistible: "where for art thou" is meaningless. In Romeo &amp; Juliet, it's "wherefore art thou". Wherefore means "why", as in "why are you Romeo, and not someone else who isn't related to my enemies?". Anyway, Emacs+SLIME.
Limited??? Let's count: 1. Allegro CL has its own IDE 2. so does Lispworks 3. CMUCL has Hemlock 4. CUSP 5. Dandelion (first time heard about it, but ok) 6. slimv (again, it's first time I hear about it) 7. [ABLE](http://common-lisp.net/project/able/) 8. SLIME So you have like 8 choices. Yes, some of them suck, and some of them are limited to certain implementation. It seems that only SLIME works with most implementations. But the problem is clearly not in number of choices, but a _quality_ of choices. And further fragmentation won't help at all, problems with quality are caused by a lack of community actively using IDEs. So the only solution is to stop bitching and start using Emacs+SLIME. Article says: &gt; learn Emacs (boo!) as if learning Emacs is very hard. It is not. And you DO NOT need to "learn Emacs". All you need to learn is about a dozen of useful key combinations. Otherwise Emacs is pretty much like any other text editor, all common key combinations work, especially if you want to spend a dozen of minutes configuring it to your taste. And then you need to learn something no matter what IDE/language you use -- you need at least to be aware about menu structure. And, believe me or not, you can do most things through menu in Emacs too, it is just not very efficient. Now about SLIME not working with CLISP, it is all about finding right versions of SLIME and CLISP. Because arbitrary version won't work with other arbitrary version. I recommend getting latest official vanilla releases of both (as opposed to using ones from OS packages). If it doesn't work then complain in CLISP and SLIME mailing lists -- it is a bug and they should fix it.
The problem is that CLISP does not come with asdf. I downloaded it and compiled it, but for some reason I could not get CLISP to load it automatically on startup. (tried to put some stuff in .clisprc) 
ah well that's a pain for sure
That's so [wizard](http://www.urbandictionary.com/define.php?term=wizard).
9. Clozure Common Lisp has a rudimentary IDE.
Easiest way: 1. Download Quicklisp from http://beta.quicklisp.org/quicklisp.lisp 2. (load "C:\\\\path\\\\to\\\\quicklisp.lisp") 3. (quicklisp-quickstart:install) 4. (ql:add-to-init-file) 5. (ql:quickload "quicklisp-slime-helper") 6. This will give you a line to add to your .emacs file. 7. So in Emacs C-x C-f (Hold control, hit x, release x, hit f, release f, release control) "~/.emacs" 8. copy and paste the line quicklisp gave you. 9. C-x C-s to save your file. Close emacs, reopen emacs. 10. M-x (Hold alt, hit x) type slime, hit enter. 11. Ta-Da! 
There's good work being done by [the Racket folks](http://racket-lang.org/) too. Their [awesome IDE](http://docs.racket-lang.org/drracket/index.html) is supported by [lots of well-organized docs](http://docs.racket-lang.org/) and [libraries](http://planet.racket-lang.org/). I know it's a Scheme, not a Common Lisp, but I've been [pointing out](http://programmers.stackexchange.com/questions/20586/how-should-i-start-with-lisp) for [a while now](http://langnostic.blogspot.com/2010/09/yegge-strikes-back-from-grave.html) that it's probably a better place to start, unless you already use Emacs (and, as a note, I've met exactly one person who uses Emacs, but doesn't yet know Lisp. I have no idea how he keeps sane).
Uh, no. http://www.clozure.com/clozurecl.html
yup, FIDO pretty much sums up the blog post in question...
1. [Franz' licensing](http://www.franz.com/products/licensing/) is pretty scary last I checked, and it doesn't seem to have changed much as of this writing 2. Lispworks gives you a [free IDE that turns itself off after 5 hours, has a heap-size limit and is crippled in other small ways](http://www.lispworks.com/downloads/index.html) or [a commercial version that you'll need a second mortgage for if you're not an academic](http://www.lispworks.com/buy/prices-1c.html) 3. [Hemlock](http://www.cons.org/cmucl/hemlock/index.html) is basically Emacs in CL (instead of Elisp), so I don't think it's fair to present it as a separate choice from Emacs. 4. 5, 6. Can't comment as I haven't used them. CUSP is the only one I've heard of before this thread. 7. I haven't used ABLE either, but according to the page you link, it's completely keyboard-driven. Typically when people ask for "an IDE", they mean "a tool where the first step is poking around menus to get my bearings, rather than memorizing commands and keystrokes". I'm not sure it's fair to present this as a separate choice from Emacs either, as it seems like it would have the same newb-hostile UI problems (but again, I haven't used it, so take that with a grain of salt). 8. Yup, SLIME + Emacs. Which I use and love, but the learning curve was near-vertical because I didn't know how to use Emacs when I started with it. Learning Emacs is hard in the sense that it either involves a lot of memorization, or requires that you know Lisp first. It's also hard in the sense that anyone used to today's standard IDEs will have a hell of a time re-training their muscle memory, and their basic models about what it means to interact with their files. Things both big and small are different in it, and that makes people hesitant to learn it if they've already committed a different editor's model to memory. You can make all the arguments you like about the difficulty being all in their heads, but the end result of that argument is typically that one more person fails to give a shit about Lisp. 
Thank you so much. I feel better knowing I'm not the only pedant in this particular way.
sorry, forgot about that!
&gt; it's completely keyboard-driven. I don't see how working in REPL and programming can be NOT keyboard driven. You cannot program by clicking icons. You need to type commands or function code. You can do a lot of things with mouse in Emacs. You can switch between buffers with mouse. You can select code with mouse. You can scroll with mouse. You can compile functions with mouse. (Through the SLIME menu.) It's just that working with mouse is inefficient when you work with REPL, that's why you need to learn some keyboard combos. You cannot fix this. &gt; Learning Emacs is hard in the sense that it either involves a lot of memorization No it does not. Maybe they forgot to tell you, but now Emacs supports most common keyboard combos (especially when you enable CUA mode) out of box. Cursor movement, pageup/pagedown, copy/paste, home, end, delete. Shift+cursor to select, ctrl+cursor to jump words, ctrl+shit+cursor to select while jumping. And so on. All basic functionality is there, and the rest is not common either. And then you just type code, just as you do in any other editor. After you're done you can either use SLIME menu to compile function, or press C-c C-c. Then you go to REPL -- again, you have a choice to either use mouse or learn combo Ð¡-x o. And you type some code in REPL, hit enter. If you want another call, either copy-paste with mouse (or keyboard) or learn M-p and M-n. If it pops into debugger you have a choice -- either press buttons, or use mouse, or use menu. That's as much key combos as you need to start. Four total. Or you can chose not to use them and use mouse. (Well, ok, if you've managed to close one of windows you need C-x 2 too.) Open/save files? Do it via menu. There are huge buttons on top, hard to miss them. Did I miss anything? Do you know other key combos which are absolutely crucial for learning Emacs? &gt; or requires that you know Lisp first. You mean to customize keybindings? No, it doesn't. It requires a bit of brain to customize examples you can easily find on the net. &gt; but the learning curve was near-vertical Oh, it is, if some idiot will tell you that you need Emacs tutorial to learn Emacs. Or if you don't know what to do with REPL at all. It just isn't something you can learn by looking at buttons in IDE. Read some book, watch video where they use SLIME, hang on IRC, ask questions on reddit. It isn't hard to find info on how to use REPL properly. &gt; It's also hard in the sense that anyone used to today's standard IDEs will have a hell of a time re-training their muscle memory Basic editing is mostly the same. And complex things are different in different IDEs anyway. &gt; and their basic models about what it means to interact with their files People who come from languages like C need to learn that they do not recompile everything to update state. But I don't see what it has to do with IDE. SLIME has "Compile defun" command and that's pretty much it, it will be the same in any Lisp IDE (which does not try to mimic Java IDE, at least). Otherwise model is same -- you open file, you edit, you apply changes, you test. &gt; Things both big and small are different in it, and that makes people hesitant to learn it if they've already committed a different editor's model to memory. Same thing applies to learning new language in general. Why learn at all if you want it to be exactly the same? &gt; You can make all the arguments you like about the difficulty being all in their heads, but the end result of that argument is typically that one more person fails to give a shit about Lisp. Do you want me to cry for them or something? It is their choice. Either they were not willing to learn something new, or they were unlucky to find bad intro material (and were not willing to learn enough to look for another intro material). I'm all for more people using Lisp, but I really don't think we need a whole new another IDE for this. If anything we need better intro materials which is no-bullshit and is optimized for typical average people trying to learn Lisp. &gt; Franz' licensing is pretty scary last I checked, and it doesn't seem to have changed much as of this writing It is not like seasoned Lisp professionals are having problems learning Emacs, is it? It is people who are in the very beginning of learning Lisp. And I do not think those people are going to produce commercial applications right away in their first hours of learning language. So using ACL with IDE is perfectly fine for newbies. I was using it a bit when I was learning Lisp. Actually I was trying pretty much all implementations. Then I've eventually settled on ABCL and SBCL. I don't quite understand why some people are trying to settle on a particular implementation in their first try. It won't be an informed choice. Try them all, pick the best one out. &gt; Lispworks gives you a free IDE that turns itself off after 5 hours, has a heap-size limit and is crippled in other small ways or a commercial version that you'll need a second mortgage for if you're not an academic Likewise, this wasn't a problem when I was learning Lisp. Lispworks was my implementation of choice for some time because it has better editor (IMHO) than ACL, is easy to install, comes with docs, works pretty well, etc.
LispWorks is expensive, but not out of reach. Emacs does not require to learn Lisp first. Emacs can be used with little or no Lisp knowledge. I have nothing against Emacs-editors in general, but GNU Emacs and SLIME lacks usability (for example the keyboard commands are long and complicated). For Lisp one needs an open mind anyway (meta-linguistic programming, functional programming, REPL, ...). If prospective users fail at the editor, they better not use Lisp. 
 (load #p"/path/to/asdf") (pushnew #p"/path/to/systems/" asdf:*central-registry*)
You don't need to convince me that Emacs is powerful. I use it, and I know. But your argument that it's easy can be distilled to "aside from all the difficulties of learning Emacs, it's easy to learn". That's not a reasonable position to take, even if it happens to be technically true. &gt;Maybe they forgot to tell you... They did, sadly. As of Emacs23, the tutorial that you're greeted with still says things like "We recommend learning C-b, C-f, C-n and C-p [as opposed to the arrow keys] for three reasons. [a paragraph or two of explanation follows]" &gt;(especially when you enable CUA mode) This is part of the usability problem I was pointing out. There is a menu item in Emacs that essentially reads "Act almost the way I expect". In order to be easy to learn, a program needs to do what you expect by default. I'm not saying the decision has no merit, again, I learned and currently use the thing (without the CUA training wheels, in case you care), but realize that there's a tradeoff between ease of use for newbs and power for the veterans. Fair enough, but when you've chosen to do that, why exactly are you surprised and dismissive when people point out that it's difficult to learn? &gt;Did I miss anything? Evidently. Your arguments are true if Emacs is being taught as the first editor you ever use. If you already have an IDE and a language you're comfortable with, the thought process is not "Well, I don't know the keyboard shortcuts, I'll just use the menu", it's "Screw this, I already know what Ctrl+o is supposed to do. What's all this C-x C-f shit? I'm going back to Eclipse." In other words, "Emacs is hard to learn compared to what I already know", and this is not an unreasonable position when +90% (I don't know the actual number) of desktop software acts consistently from the UI perspective. &gt;No, it doesn't. It requires a bit of brain to customize examples you can easily find on the net. So I want to be clear. Your argument is "Emacs is easy because you just have to download example files from various sources on the internet, without knowing exactly what they do, tweak them and then run them on your machine." My experience has been that Elisp knowledge is required for a good Emacs experience. That's not a bad thing; it gives you a lot of power, but you're not convincing me that it's easy. &gt;People who come from languages like C need to learn that they do not recompile everything to update state. But I don't see what it has to do with IDE. I'm talking about the IDE's model, not that of the language. As an example, how would you explain Emacs' redo/undo functionality to someone used to Ctrl+z and Ctrl+Shift+z (or Ctrl+y) as they appear in the vast majority of today's software? This is the same pattern as elsewhere in Emacs; it trades an easy learning curve for power. Again, that's fair (and well worth it IMO), but at least recognize the trade. &gt;Do you want me to cry for them or something? It is their choice. No, I don't expect you to cry. I expect you to make haughty, dismissive arguments about how your way is better (and easy in any case), then point out that people who have brains agree with you, then point out that it was your arguments' targets' choice to walk away from that which you advocate. Which is absolutely true, but comical from my perspective; carry on. &gt;...or they were unlucky to find bad intro material... In this case, "unlucky to find bad intro material" can be accurately translated to "clicked on the tutorial button included with the tool". &gt;If anything we need better intro materials which is no-bullshit and is optimized for typical average people trying to learn Lisp. I couldn't agree more. The [Racket](http://racket-lang.org/) guys are doing a lot of good on that front. &gt;It is not like seasoned Lisp professionals are having problems learning Emacs, is it? It is people who are in the very beginning of learning Lisp. And I do not think those people are going to produce commercial applications right away in their first hours of learning language. The problem with this statement is that you are excluding many non-Lisp professional programmers from the world of people who can learn Lisp. A seasoned pro from another language likely isn't using Emacs, and (if interested at all) probably wants to do some professional work with Lisp. The choice for such people is 1. Learn Emacs (which often (IMO erroneously) doesn't seem worth it from an outsiders perspective) 2. Learn Lisp, but don't use it for commercial projects (which is pointless if that's the goal) 3. Try the probably half-assed Lisp support on my current IDE (which will probably give them the wrong impression) 4. Keep using what I'm using. One of these is not like the others. In any case, you pointed to the Allegro and Lispworks IDEs as options; all I'm pointing out is that these options come with such obvious, and numerous strings attached that I could see people reasonably steering away.
Alas, I did no Lisp in 2010. The closest I got to Lisp was sending some guy $30 to support Quicklisp (oh, wait, that's you! ;), and getting *Let Over Lambda* for Christmas. Hopefully 2011 will be better, Lisp-wise. Humorous aside: What is it with the Lisp-y "LOL" acronyms? There's Lisp On Lines, Let Over Lambda, and Land Of Lisp. W. T. F? Makes it hard to abbreviate any of them unambiguously. Maybe subscripts? LOL(1), LOL(2), and LOL(3)? Shortening instead of abbreviating? LOLines, LOLambda, LOLisp? (But really, it's not a big deal. :)
&gt;Emacs does not require to learn Lisp first. Emacs can be used with little or no Lisp knowledge. ~~This hasn't been my experience.~~ Edit: On reflection, I could see how you could use it without knowing much Elisp, but I find that getting the most out of it in a lot of ways requires significantly more. &gt;For Lisp one needs an open mind anyway. If prospective users fail at the editor, they better not use Lisp. I can see where you're coming from, but I was in the "Emacs sucks" mindset not too many years ago, so I hope you see why I can't agree with you on that point. Opening minds is a worthy endeavour.
Limited?? I have my Mac setup to run Lisp+Emacs+Slime with my favorite Lisp, Clozure CL. But my dot emacs file is written so that commenting out Clozure, and uncommenting any one of the below Lisps works great. That way, if I want to run code that requires Clisp like the new Land of Lisp book, it is super easy. * [CMUCL](http://www.cons.org/cmucl/) * [Clozure CL](http://ccl.clozure.com/) * [SBCL](http://sbcl.sourceforge.net/) * [Clisp](http://www.gnu.org/software/clisp/) * [Allegro CL](http://www.franz.com/products/allegrocl/) In addition the OP talks about the crippled Lispworks, but 5 hours of coding in Lisp a day is quite a bit. And I'm sure there are ways to get around that limitation. I haven't tried. [Lispworks](http://www.lispworks.com/) Also, not Common Lisp, but a interesting Lisp tool [PicoLisp](http://software-lab.de/down.html) As far as Clisp, I don't know why I see so many people trying to run Clisp when there are much faster, better maintained Lisps like Clozure CL and SBCL. If Paul Graham used Clisp a hundred years ago so maybe people think they need to also. They don't. Conrad Barski uses Clisp for his book. It's what he is comfortable with. Big deal. I want a well maintained Lisp that works great with Quicklisp and the other tools I use. Lastly, I also run Debian via VMWare where I can also run most of the above Lisps. I know nothing about running Lisp on Windows. 
&gt; Fair enough, but when you've chosen to do that, why exactly are you surprised and dismissive when people point out that it's difficult to learn? Why exactly are you surprised and dismissive when people point out that it is easy to learn? You said that learning curve is very steep, but apparently there is easy mode in Emacs too. So you're plainly wrong. You should recognize this instead of insisting on your point of view. I'm using Emacs for 6 years and last 3 years I was working as professional Common Lisp programmer. I still use CUA, sort of. I started with XEmacs rather than Emacs, and it was configured with very sane keybindings out of box. I didn't need to change any keybings or learn anything (w.r.t. basic text editing) when I started using XEmacs on Windows and I changed just few keys when I moved to Linux. Now I'm in process of moving to Emacs because XEmacs support is new software is lacking. New Emacs is pretty good with keybindings too, I had to change just a handful of things, including enabling CUA. But actually you can still have C-c, C-v and C-x while enjoying other features of CUA -- there is an option for this! So if you think that CUA sucks, maybe you don't know what is CUA? Anyway, my point is that Emacs with common keybindings is good enough for professional use. So it should be good enough for newbies too, no? Using common keybindings is a rational choice because from time to time you use other editors and you don't want to have problems with muscle memory. There are hardcore Emacs fans, of course, but it is their choice, again, and there is no reason to inflict it on other people. &gt; Your arguments are true if Emacs is being taught as the first editor you ever use. No, it is not. I was using "traditional" DOS and Windows editors (particularly, MS Visual Studio) before trying XEmacs and starting using XEmacs wasn't problem at all. It just worked as I expect. &gt; "Screw this, I already know what Ctrl+o is supposed to do. What's all this C-x C-f shit? I'm going back to Eclipse." I'd say it is profoundly moronic. How frequently do you open files, once per hour? Why does it matter at all? &gt; My experience has been that Elisp knowledge is required for a good Emacs experience. That's not a bad thing; it gives you a lot of power, but you're not convincing me that it's easy. Ok, I understand now. You're one of those guys who spends months learning all possible keybings of editor to be fully productive. I do not care about this bullshit. Emacs is good. If it is not available, I can use nano to edit code. If nano is not available, I can use vi -- and barely know how to type stuff in it. Editor is not such a big deal, it is just for editing code. &gt; A seasoned pro from another language likely isn't using Emacs, and (if interested at all) probably wants to do some professional work with Lisp. Seasoned pro should expect that he needs some time to learn a completely new language.
You say its Scheme and not CL as if that was a bad thing? :)
&gt;&gt; learn Emacs (boo!) &gt; as if learning Emacs is very hard. It is not. And you DO NOT need to "learn Emacs". All you need to learn is about a dozen of useful key combinations. Otherwise Emacs is pretty much like any other text editor, all common key combinations work, especially if you want to spend a dozen of minutes configuring it to your taste. Which gives you Notepad++-esque editing capabilities. For other IDE mainstays like auto completion in your buffers you're in for a ride installing and configuring a zillion big or small packages that don't work the same across languages and that are bound to a zillion different keys. Granted, I've only tried them for a few days, but I have already come across with auto-complete.el, hippie-expand, slime's own auto complete (admittedly quite good), and heck, CEDET's. All with their nuances and none that seem like a good fit in general. Addendum: I'm starting to use Emacs quite heavily and the idea of an editor that you can grow as well as you grow towards it is beautiful. I use it whenever I must write LaTeX, C or Clojure (and the odd dabble with Scheme, R). With respect to autocomplete, auto-complete.el is what seems to work best for me now, though it seems like one of the default configurations screwed it up for Clojure initially.
&gt;Why exactly are you surprised and dismissive when people point out that it is easy to learn? Two reasons. First, because it's not "people", it's just you. Of everyone I've talked to (which includes professional CL hackers who use Emacs, newbs to lisp, newbs to Emacs but not lisp, newbs to programming, and programmers from other languages whom I've tried to point in the direction of Emacs or Lisp or Both), you're the first I've encountered to claim it's easy to learn. Second, because I don't remember it being easy for me. I remember struggling against Emacs to start with. It was worth it, but "worth it" and "easy" are not the same thing. In any case a sample size of one (or ten, or twenty) does not a conclusive study make, so neither of us can really say in the absolute "it's easy" or "it's difficult". When I said "it's not easy" above, I meant "based on my own experience, hearing anecdotal evidence from others, and hearing reasons they don't want to learn Emacs from still others, it seems that Emacs is more difficult to learn than it could be", but typing that each time would have added to the giant wall of text you and I are already constructing. &gt;...there is easy mode in Emacs too... You've yet to point out "easy mode" aside from the CUA bindings, which doesn't cover everything. For example, the undo command (not the keybinding, the command), works differently in Emacs than in other programs I've used. Redo doesn't exist in the sense most people mean at all (instead you either need to wrap your head around Emacs' undo, or use redo.el, which does the non-Emacs thing). The idea of opening a file works differently (not a huge difference, but it's still enough to trip up a first-timer). The idea of cutting/copying/pasting text works differently (and again, this isn't just a keybinding difference; I've yet to encounter another program with a concept of the kill ring as it exists in Emacs). These are all differences, some small and inconsequential, some large and far-reaching, but they all add up to a huge list of things you need to know about Emacs that you don't learn by using other editors. That list can reasonably be considered a challenge, and little of it goes away when you turn on CUA. &gt;good enough for professional use. So it should be good enough for newbies too No. This is the opposite of true. An experienced professional will want to maximize the amount of power they get from their tools. A newbie wants to be able to get up and running easily. These aren't necessarily opposed, but Emacs intentionally sacrifices ease of learning for power in many cases, which means it's geared more towards the experienced. A complication to this state of affairs is that one must be a newbie before one can be experienced. Can you see the problem (from the perspective of someone who would like wider adoption for Lisp than it's had) with that? &gt;I'd say it is profoundly moronic. How frequently do you open files, once per hour? Why does it matter at all? The particular keybindings in that illustrative example are irrelevant. (defun screw-this (key-bind emacs-key-bind) "It doesn't have an exclamation mark because it doesn't affect state" (format nil "Screw this, I already know what ~a is supposed to do. What's all this ~a shit?!" key-bind emacs-key-bind)) This has the same implications for "Ctrl+s" "C-x C-s", "Ctrl+q" "C-x C-c", "Ctrl+z" "C-_", "Ctrl+c" "M-w", "Ctrl+v" "C-y" etc. And yes, I save, copy, paste and undo much more often than once per hour. Additionally, while I don't exit Emacs more than once a day, note that the keybinding for doing so is the combination of two different, but (outside of Emacs) much more common keystrokes. CUA addresses some, but not all of this. &gt;Ok, I understand now. You're one of those guys who spends months learning all possible keybings of editor to be fully productive. &gt;I do not care about this bullshit. Emacs is good. If it is not available, I can use nano to edit code. If nano is not available, I can use vi -- and barely know how to type stuff in it. &gt;Editor is not such a big deal, it is just for editing code. Yes, I like to be fully productive. If you really feel that it's "no big deal", why bother learning Emacs at all? Why not just use notepad/gedit/nano/stickies as available (plus REPL of choice in a terminal) and chuck the whole argument? 
If you're missing jump-to-definition from other IDEs, check out etags. I wouldn't mention it, but lots of people seem to overlook that feature.
It's not bad, but the article talks about Lisp IDEs in the context of [Land of Lisp](http://www.amazon.ca/Land-Lisp-Learn-Program-Game/dp/1593272812/ref=sr_1_1?ie=UTF8&amp;s=books&amp;qid=1294055521&amp;sr=8-1), which is a book that tries to teach Common Lisp (I haven't read it yet, so I can't say how specific to CL the examples are, but I imagine they wouldn't run unmodified on Racket).
FYI, you can have several lisps configured at once. "M-x slime" runs the first. "M-- M-x slime" gives you a prompt to select which to use. Here's an example [slime config](http://www.lispforum.com/viewtopic.php?f=2&amp;t=856&amp;p=5222#p5222)
"You can do a lot of things with mouse in Emacs. You can switch between buffers with mouse. You can select code with mouse. You can scroll with mouse. You can compile functions with mouse. (Through the SLIME menu.)" And it's all ridiculously fidgety. I'm a die-hard Emacs/SLIME user and I still get tripped up by some of the conventions. Eg: when you have a split pane with a directory view in one window, clicking on a directory will open it in the other window. WTF?!
For those of us without a copy of that particular book could you please supply some code examples?
&gt; I'm asking this as the nodes, objects, and object-locations variables &gt; are implemented using lists but there is no interface for them: This &gt; variables are manipulated throughout the code with standard list &gt; manipulation functions like caddr, cadr, assoc, etc. Any abstraction (or "interface") you make has some benefits and some costs. Some typical benefits are: * Separation from implementation, in case you need to change the implementation. * Intentional clarity, as you have an specially-tailored "language" to speak through. I.e. "get-next-banana" conveys more than "pop". Some typical costs are: * Development and maintenance, any code you add takes time and new possibilities for bugs. * Obfuscation, any abstraction (or specially-tailored language) must be learned to be used. I.e. while the overall meaning of "get-next-banana" may be clear, the small details of it are not. Whereas any Lisp programmer will immediately know precisely what "pop" does. As always, it's a matter of balancing the benefits and the costs. &gt; it's not weird to skip the interface and code directly to an &gt; implementation (that is, lists) but isn't it more desirable in the &gt; event the implementation changes? You have to consider the likelihood that the implementation will actually need to change. If the likelihood is small, the associated benefit is small. A typical example of "changing the implementation" is to change a sequence between list and vector implementation. In practice, it's very very rare that this is feasible, because of the different access patterns they support (well). Another aspect on this entirely: I think that in programming languages such as Java there's a huge focus on "separation from implementation" because the core language is such that actually changing existing code is very often a huge pain. This is simply not (as) painful in Lisp, leading to a programming style where things are constructed as simple as possible initially, and only changed/refined/improved as required. As a Lisp programmer, when I read Lisp code written by people heavily influenced by Java, I tend to be annoyed by the amount of gratiutous abstractions. It's like reading obfuscated code, i.e. having to unwind 3-4 function calls to discover that the net effect is (car x). 
As far as I understood, you could: 1. define your own accessors. 2. use structs.
&gt; Which gives you Notepad++-esque editing capabilities. Which is perfectly fine. &gt; For other IDE mainstays like auto completion in your buffers Completion for Lisp code comes with SLIME, you just need to bind it to a good key because M-TAB neither works nor is convenient. Other features one expects from the IDE is slime-edit-definition and slime-hyperspec-lookup. And they work out of box too. And completion for other things and other niceties are really out of scope of Lisp IDE. Yep, there are many options, but having many options is not a bad thing and it does not make learning curve steep.
Thanks for the tip. I had a feeling there must be a better way than the old commenting/uncommenting technique that I use. I appreciate the help. 
&gt; A typical example of "changing the implementation" is to change a sequence between list and vector implementation. In practice, it's very very rare that this is feasible, because of the different access patterns they support (well). Actually, if you're developing a new, non-trivial piece of software such as a game, it is very, very likely that your sequence representation will change for example from list to a vector, precisely _because_ of the different access patterns they support. What's a good first-cut, lowest-effort representation for an object during exploratory programming probably won't hold up when that object turns out to be the core data structure on which all updates depend. &gt; As a Lisp programmer, when I read Lisp code written by people heavily influenced by Java, I tend to be annoyed by the amount of gratiutous abstractions. It's like reading obfuscated code, i.e. having to unwind 3-4 function calls to discover that the net effect is (car x). Still, that gives your code an _intentional_, as opposed to merely _incidental_ meaning. It's a very different to read two `CAR`s next to each other in the code, than it is to read `BANANA-LENGTH` and `PLANE-SPEED` instead. Sure, you can go overboard with this, but as long as the chain of indirection is not too long (4 probably is), you can just follow it once and then ignore it for the rest of the code and read things for the meaning, and not for the implementation.
The code of chapter 5 is here: http://landoflisp.com/wizards_game.lisp
&gt; As a Lisp programmer, when I read Lisp code written by people heavily influenced by Java, I tend to be annoyed by the amount of gratiutous abstractions. It's like reading obfuscated code, i.e. having to unwind 3-4 function calls to discover that the net effect is (car x). I get annoyed by the opposite. I don't want to see (car x) when I have no idea what that means in the context of what you want to achieve. Seeing a well-named function is often all I need, and I wouldn't have to dive deep in, at least if I can trust the function name doesn't lie. I'd also argue that despite abstraction sometimes adding more code, which has ofcourse bug-potential, that direct manipulation of data without abstraction is much more likely to lead to bugs, simply because it is much harder to get things right without good abstractions.
&gt; Second, because I don't remember it being easy for me. So you did it the wrong way and now you want to inflict pain onto others. :) There really is nothing wrong with it, one chooses learning curve he is comfortable with. You're just into denial of existence of easier (and lamer) path. &gt; For example, the undo command (not the keybinding, the command), works differently in Emacs than in other programs I've used I'd say each editor implements undo its own way. Many editors do not have redo at all. So it is better not to depend on it. If you've screwed up, use undo wisely. If it is FUBAR reload files from disk. If you need to use it frequently, stop being a monkey with keyboard and think before you do things. &gt; The idea of cutting/copying/pasting text works differently (and again, this isn't just a keybinding difference; I've yet to encounter another program with a concept of the kill ring as it exists in Emacs). I don't use kill ring. It turns out that Emacs has both clipboard and killring and you can use functionality you're more comfortable with. &gt; a huge list of things you need to know about Emacs My point is that you don't really need to know them. 99% of time it is a simple editing and newbie can start with that. With time he'll bump onto differences and will have to learn some things, but it is not like you need to learn things _before_ doing any programming. &gt; An experienced professional will want to maximize the amount of power they get from their tools. The real tool programmer uses is his head. IDEs are overrated. Yes, sometimes it can save you a second or two here and there, but you get much more time savings from thinking more. &gt; Yes, I like to be fully productive. Being more productive with one editor you become less productive using other editors. If you're a Java guy who uses only Eclipse or a Lisp guy who uses only Emacs it's fine. But if you're trying to be versatile it isn't. Let's say you've logged into a remote server and you want to look through some huge log file, will you open it in Emacs so you can use familiar keybindings? I think much better solution would be to use `less`. And when you're using shell it is different from Emacs too. And when you're using browser. And when you're fixing something onsite and you don't have your .emacs with you. So it doesn't makes sense to invest too much into a particular editor if you're not doing just one thing. &gt; If you really feel that it's "no big deal", why bother learning Emacs at all? It is called diminishing returns. If you go from vi which you don't know to nano you get 10x speedup. If you go from nano to Emacs you get maybe 2x speedup. If you go from Emacs with just few basic keybindings to fully optimized and customized Emacs you get what, maybe 5% speedup? At some point it is not worth it. I've learned Emacs to the point I'm comfortable with doing most things (like 99%) and it is just good enough at that point. What really helps is learning how to type fast. That will work with any editor. And if you can type a thing in a second learning a key combo which will do that in 0.2 seconds becomes much less important. 
I like Racket very much but the DrRacket IDE isn't really that great. It might the best option for an absolute beginner looking for a lisp-with-batteries-included but it's incredibly clumsy when compared to Emacs and lacks even the basic features I would except from an IDE. And it's quite slow also; I applaud the work they have done converting big parts of the original C++ code to Scheme but unfortunately it shows in the editors performance. Although I wouldn't be surprised if it got better in future as Racket/PLT Scheme in general has had huge improvements in performance during the last few years.
&gt; This variables are manipulated throughout the code with standard list manipulation functions like caddr, cadr, assoc, etc. It depends heavily on how much code you have and how much use and maintenance you expect it to see, but in general, no, it's not a recommended programming style. See also my reply to fvf below. That said, it does happen a lot in real life, particularly with the exploratory style of programming Lisp is so well-suited for. How it goes is that you start with a simple idea of what you want to do right now, so you knock up the least-effort implementation, which usually is a list plus a bunch of `CAR`s an and `CDR`s to access it. That's fine as long as you have one or two functions that do it, but with time it starts to pile up and get really messy. That's why it's important always to couple your REPL hacking with constant refactoring and cleaning up of the code, separating out abstractions *as they happen* (not later, but also not much earlier). Fortunately, Lisp gives you a very good toolbox for this kind of refactoring. Even aside from the macros, the (daunting at first) richness of vocabulary you can choose from to talk about things really does come in handy. IMHO, it might be an excellent exercise for you to try to apply the following on the book's code: 1. First of all, convert `CADR`, `CADDR`, etc. into `SECOND`, `THIRD`, etc. This is really an inexcusable lack of abstraction or just common sense. Ordinals are defined by the standard up to `TENTH`, and there's never any reason to prefer `CAD*R` instead. 2. Next there comes an very useful trick provided by the standard. You can use [DEFSTRUCT](http://www.lispworks.com/documentation/HyperSpec/Body/m_defstr.htm) with `(:type list)`. That makes the defined struct be exactly equivalent to a plain old list in terms of implementation, but still gives a meaningful structure to things it represents. Thus if your `NODE` is, say, a list of two elements: key and value, you'd say this: (defstruct (node (:type list)) (key value)) Then replace every relevant `CAR` with `NODE-KEY`, and every `CADR` with `NODE-VALUE`. The usefulness of this technique comes from the fact you don't have to do it all at once -- all the existing list-accessing functions will continue to work exactly as they did before. 3. Lastly, whenever you see a repeating pattern emerge, define functions to abstract that patter away. Then, if you can define no more useful functions, but still see obviously repetitive code, move on to defining macros. Repeat as many times as necessary. Don't be afraid of refactoring and improving code as you read it. It's a very good way of ensuring that you really understand it.
&gt; I don't want to see (car x) when I have no idea what that means in the context of what you want to achieve. Like I said, it's a tradeoff. (car (get-the-bananas x)) is not very cryptic even if a contextless car can be. &gt; that direct manipulation of data without abstraction is much more likely to lead to bugs, simply because it is much harder to get things right without good abstractions. In my experience you rarely do a lot of intricate stuff above the abstraction layer, because if you do then your abstraction probably isn't very good in the first place.
Do bear in mind you're reading a book primarily about learning Lisp and writing games in it, not a book on structuring good code. This isn't to say LoL has *bad* code, it's just not the books main intention. Personally, I don't think you should abstract for the sake of abstraction, but *do* abstract for clarity and reducing duplication. This for me is a mantra that carries over all languages, I don't tend to make decisions like this on a per-language basis (however, if a language doesn't have enough means of abstractions for me to achieve this, then that says something about the language, my blood pressure rises, and then I go find a better choice :])
&gt; it is very, very likely that your sequence representation will change for example from list to a vector I'm not saying you should uneccesarily expose implementation details. The thing is, should (get-the-bananas x) return a list of bananas, or an object for which you need to use get-banana-collection-item or -iterator to access? Your code (above the abstraction) is going to be very tedious to write if you're going to ensure its working equally well for lists and vectors. &gt; you can just follow it once and then ignore it for the rest of the code and read things for the meaning, and not for the implementation. But each such abstractional language takes effort to learn and not the least remember. Not the least the little details that suddenly start to matter when you need to find that bug. That's a cost that shouldn't be ignored. (And, funnily enough, it's a cost that's suddenly totally unbearable when many non-lispers talk about lisp macros!)
&gt;So you did it the wrong way and now you want to inflict pain onto others. Define the "right" way, just so we're clear. &gt;Being more productive with one editor you become less productive using other editors. This is not true. You become less productive using other editors *relative to* your preferred editor, not in an absolute sense. Putting points into "Emacs use" doesn't reduce "Move Silently". &gt;Let's say you've logged into a remote server and you want to look through some huge log file, will you open it in Emacs so you can use familiar keybindings? I think much better solution would be to use less. No, I wouldn't open it with Emacs; I'd use `grep` or `less` or `tail` depending on what I need to do. You need to know how to use terminal commands as well as an editor. This doesn't mean you shouldn't know the editor well. &gt;The real tool programmer uses is his head. IDEs are overrated. I agree in principle, but your conclusion is that you therefore shouldn't bother learning any tools to the point of mastery. I reject that conclusion. &gt;So it doesn't makes sense to invest too much into a particular editor if you're not doing just one thing. &gt;It is called diminishing returns. If you go from vi which you don't know to nano you get 10x speedup. If you go from nano to Emacs you get maybe 2x speedup. If you go from Emacs with just few basic keybindings to fully optimized and customized Emacs you get what, maybe 5% speedup? At some point it is not worth it. I've learned Emacs to the point I'm comfortable with doing most things (like 99%) and it is just good enough at that point. I think I'm beginning to see the problem here. You're arguing against specialization. In other words, when you said "it's easy to learn Emacs" above, you meant "It's easy, in Emacs, to get to the point of using it as notepad with a REPL, as long as you don't need to undo, or move blocks of text around a lot". You've missed the point. If this is what constitutes "learning Emacs" to you, then we have radically different ideas about what that means. Further, I have to point out that if this is your definition of "learning" an editor, it doesn't make sense to learn any of them. Typing works the same way in most, so you should just stick with notepad or nano because those will be available anywhere. Out of curiosity * are the 10x/2x/5% numbers just out of thin air, or can you cite something? * what do you mean by "fully optimized and customized Emacs"? The point of customizing Emacs is as much that it gets you thinking about tool design as that it improves your workflow. * what do you mean by "99% of things"? I feel the need to be specific, because if you mean "I know how to type and use keyboard macros", then this is a meaningless statement. * what must one know, by your definition, to qualify as "knowing Emacs"? As a note, I agree that it's not good to become dependant on a single tool, and I agree that it's a poor strategy to learn one thing to the exclusion of all others, but it doesn't follow from this that you shouldn't seek mastery in anything. I've been arguing that there's a wide gulf between "I know how to poke keys and make letters appear on screen with Emacs" and "I know how to use Emacs".
&gt;&gt; Which gives you Notepad++-esque editing capabilities. &gt;Which is perfectly fine. Not even so, the thing doesn't show which paren matches which out of the box. You must put (show-paren-mode 1) in your init file for that to happen consistently. &gt; you just need to bind it to a good key because M-TAB B neither works nor is convenient Yet it is bound to M-TAB anyway (what window managers do they think most people use?), and you must learn how to rebind it, and thus learn of M-x commands, and of the init file. &gt; And completion for other things and other niceties are really out of scope of Lisp IDE. Yep, there are many options, but having many options is not a bad thing and it does not make learning curve steep. Yes, I realize that I ventured outside the scope of a Lisp IDE, but to say that the more the merrier is disingenuous, because you will have to actually _learn them_ (after you've configured them) and bear the inconsistencies between them. That's a whole freaking lot of memorization, a huge space-inefficiency which isn't forced on you by Eclipse, which I believe did it 'right' in that instance, by providing a standard auto completion tool kit. My point is, beyond basic editing functionality (to which you must adapt yourself or configure anyway because the defaults will be alien to almost everyone), things start to get hairy as you must start installing and configuring packages, using the rather daunting interface for configuring variables, and editing your init file! Besides, as is said below, Emacs itself tells you to go follow its tutorial to become a Stallman clone from the start... I know I did* :(. * Though I must clarify that Emacs hasn't affected my personal appearance or hygiene, nor made me any more or less zealous about FOSS.
thx bro!
&gt; Yet it is bound to M-TAB anyway (what window managers do they think most people use?), and you must learn how to rebind it, and thus learn of M-x commands, and of the init file. You need to learn about init file just to setup SLIME. Some setup is required, of course, but my point is that it isn't that big and complex. I saw how people set up Eclipse to work as a PHP IDE, it took maybe half an hour or so to install all plugins and to configure them, then it took some time to figure out how to check out code etc. But somehow people do not complain that much that Eclipse or PHP suck and are hard to setup. When I was working as a C++ programmer one guy had his Visual Studio "got broken" (I don't even know what this means) and he spent a whole goddamn day to reinstall it. Very few things work very well out of box. But somehow when it is Lisp and Emacs but not Java and Eclipse there is all this whining about how hard it is. &gt; Besides, as is said below, Emacs itself tells you to go follow its tutorial IIRC I went through this tutorial twice but I barely remember anything. :)
He told me he doesn't have time to do anything with it.
He told me it currently runs on a small linode instance shared with other applications.
According to several sources (including SICP) and whenever I have presented Lisp code to others, the advice to me has always been to provide an interface. If you are using a list to glue data together, then you should provide an interface. I am surprised to hear suggestions otherwise. Optimize later. It is unlikely that (defun red (color) (first color)) (defun green (color) (second color)) (defun blue (color) (third color)) is going to cause confusion or slow things down.
What stops you from sticking related data into structs? I myself am new to Lisp. In my explorations I've found structs very useful. Combined with defmethod, they give you code that is straightforward to read and modify. IMO, of course. I don't know what experienced programmers think of this. Is this the C programmer in me speaking?
FWIW, I believe later on in the book he introduces structures, which (arguably) come with their own interface. For a structure 'person' with a slot 'age', the slot is accessed via the call 'person-age'. I think Barski avoids providing an interface in Chapter 5 in order to keep things simpler. Given the reaction you've had, it's worth considering whether that was a good approach. By contrast, SICP tends to emphasize coding to an interface right from the start. 
I think that you first should learn to make structs "by hand" with lists and c[ad]+r, learning to think in lists, which is *fundamental* when programming in Lisp. After that, you can make your structs with, uh, structs.
Sure. Use whatever storage makes the most sense. I personally prefer classes over structs, but that is because for larger projects, I tend to have more relationships between my data. Whatever approach, (red x) could be the same interface to the underlying structure that holds color data as per my example.
I empathize with GeneralMaximus's position, however, in that structs are usually more correct to use for certain kinds of data, such as in my color example. In the C world, the compiler translates the friendly name of a field in a struct to a simple offset in a block of contiguous bytes, so it is quite a bit bulkier to be accessing a "field" in a linked list. In other words, my example -- and other similar examples -- are a poor for showing people what ought to be done in general. They lack a good sense of immersion into the language. And yes, intimately understanding how to work your way through lists is important, too. I think we just need to make a point of *when* to use each of these tools.
good job! i'm writing this from a n900, have tried your clisp port and also tried to install commonqt under ccl. concerning the latter, did you compile commonqt.cpp on the emulator or did you install the dev tools on the n900?
And once you do figure out how you want your .emacs setup, it's just a text file, so it's much easier to manage the configuration than it is for typical IDE's.
Yeah, when I said "awesome IDE", I meant "awesome for someone who heard of Lisp yesterday and doesn't know Emacs". It hits the basics, provides a simple macro-stepper and doesn't demand much attention. It goes without saying (IMO, of course) that if you want to stick with Lisp, you should learn Emacs, but I wouldn't recommend that to people just looking to get their feet wet.
DrRacket is very different from emacs in some ways, but what basic features is it lacking? Of course, it also has much better integration with Racket than Emacs. Also, I use DrRacket every day, and at this point the change in the GUI backend is not noticeable in performance. Further, if you're using a released version, you aren't using the new backend yet anyway. If you have particular use cases that are slower, please report them so they can be fixed.
*The thing is, should (get-the-bananas x) return a list of bananas, or an object for which you need to use get-banana-collection-item or -iterator to access?* I like the idea of doing defmethods for car and cdr for entities you want to treat as lists. Then you can use all the other functional features CL provides with your special list. You do not need to define specialized iterators. I experimented with this a while back successfully; I had to deal with sbcl package locks in the process, but I was happy with the result. I will see if I can dig up an example somewhere. This topic comes up from time to time.
I wish it built on SBCL!
&gt; I like the idea of doing defmethods for car and cdr for entities you want to treat as lists. Not entirely sure I understand, but if I do then this sounds to me a bad idea. Not only do you create a new "abstractional language", you mess up the existing, standard language too, no?
My goal was to extend Lisp such that I could apply any Lisp sequence function to an object that pretended to be a list for iteration purposes. My experiment object was a simple lazy range, such that the rest of the list was calculated as needed. I was able to change car and cdr, but I was unable to subclass 'list and 'sequence properly, so I could not flesh this out for functions like mapcar. Just some notes if you want to try going down this rabbit hole... Here are the minimum requirements for altering the standard language to support your new type: (defmethod car ((list list)) (cl:car list)) (defmethod cdr ((list list)) (cl:cdr list)) Is it a good idea? I suppose there is an important distinction between primitives and custom functions. Maybe car and cdr should be untouchable, but first and rest should not be? And what is the best way to add "any iterator" feature to something like mapcar?
&gt;DrRacket is very different from emacs in some ways AFAIK it was/is never meant to be Emacs. Which is actually a wise choice since that's a race that no editor can win. If it can't read my ~/.emacs it ain't Emacs. &gt;what basic features is it lacking? Basically all the stuff I have with SLIME and to lesser extent with Geiser under Emacs. Something like: * Show arglists functionality. Racket is heavily documented, why not show function signatures somewhere in the IDE. I believe it would also encourage more people to document their code. * Symbol completion. I don't know exactly what Rackets completion feature does but it's not very helpful since it seems to offer completions only from the current #lang in use. * I don't use the OO part of Racket much but class browser could be handy, especially when working with the GUI toolkit. * Jump to definition &amp; back. DrR has it but it's clumsy and slow to use (you need to check syntax, wait, mouse around). * Less opaque way to (re)define keyboard shortcuts. I sometimes get weird results when I try to add my own keybindings and even more often I'm completely at lost with it. * Paredit. There is no way I'm going back to manually manipulating sexps after using Paredit for years. I'd do it myself if I just had some clue where to start. * The editor's Search function is very clumsy. It seems that I need to mouse around to use it. * Inspector. Edit: * Eval region. I know that iterative development is limited on DrRacket for purpose but it already has a REPL so a way to evaluate expressions directly from the editor buffer wouldn't be big change. Bottom line is, even if Emacs lacked all the functionality I mentioned, most of it wouldn't be that hard to add. &gt; GUI backend is not noticeable in performance. Further, if you're using a released version, you aren't using the new backend yet anyway. With the few weeks old prerelease version scrolling documents is very slow and flickery. Moving around is also slower than it used to be, with cursor noticeably lagging behind keypressed. I don't know if it's worth reporting since it is still under development and DrScheme has always felt slow to me. It was just something I noticed when I tried the IDE after last update.
I don't think there's much chance of this working. Certainly not on any natively compiled implementation, as CAR and CDR will be heavily optimized (inlined/open-coded). This is one reason why that package-lock is there.
I've used SDK image from [here](http://talk.maemo.org/showthread.php?p=695728) on the device. As of kdebindings, I've compiled them in scratchbox (as of now, this is rather painful process) and then copied *.so files to the device, because building them on the device would take TOO long.
&gt; But each such abstractional language takes effort to learn and not the least remember. Not the least the little details that suddenly start to matter when you need to find that bug. Sure, but that cost is *much* lower when you have self-descriptive names such as `BANANA-LENGTH` and `PLANE-SPEED`, as opposed to having to remember that the `CAR` on *this* line means banana's length, as opposed to the `CAR` on *that* line, which is the plane's speed. And if we're talking about bugs, don't forget the savings you get when you're able to get the abstraction's implementation right once, and can then just continue to use it in as many places as you desire, without having to check over and over again if you typed each one of them correctly and without mistakes. Sure, it's possible to have wrong/too many abstractions. But chosen right, abstractions pay back much more than they cost to create and maintain.
If only CL would have specified standard code walker. Current CL reader, macros, compiler macros combination is very powerful, but it's only 1% of what could have been if you would have access to standard code walker: full blown architecture independent compiler front end with ability to do semantic analysis etc. 
CL reader is programmable. You can change macro characters. Kent Pitman once reprogrammed Lisp reader to read in Fortran code. 
I actually used it a few years ago. Good times...
&gt;Eval region. Agreed that this is very useful, but the Racket team has explicitly come out against it (it's not just something they left out accidentally; it was a conscious decision to exclude it). [Cited](http://blog.racket-lang.org/2009/03/drscheme-repl-isnt-lisp.html). This is one of the reasons I left Racket+DrRacket for CL+SLIME/Emacs after I got my bearings on Lisp.
map/filter. (define-syntax (lc2 stx) (define (filters stx) (syntax-case stx (&lt;- ?) ((v &lt;- vs ? p r ...) #`#,(cons #'(filter p vs) (filters #'(r ...)))) ((v &lt;- vs r ...) #`#,(cons #'vs (filters #'(r ...)))) (() '()))) (define (vars stx) (syntax-case stx (&lt;- ?) ((v &lt;- vs ? p r ...) #`#,(cons #'v (vars #'(r ...)))) ((v &lt;- vs r ...) #`#,(cons #'v (vars #'(r ...)))) (() '()))) (syntax-case stx () ((lc b v ...) #`(map (lambda #,(vars #'(v ...)) b) #,@(filters #'(v ...)))))) (define l '(1 2 3 4 5 6 7 8 9 10)) (define xs l) (define ys l) (map (lambda (x y) (+ x y)) (filter even? xs) (filter odd? ys)) ; =&gt; '(3 7 11 15 19) (lc2 (+ x y) x &lt;- xs ? even? y &lt;- ys ? odd?) ; same *edit*: fixed the indentation.
Dependencies: Uses the Prototype and Scriptaculous JavaScript libraries What about other javascript libraries?
Another lc implementation: [git](https://github.com/jmbr/incf-cl) [info](http://www.cl-user.net/asp/zgdO/sdataQvTG81n$zw5lDQ38Ry8X8yBX8yBXnMq=/sdataQu3F$sSHnB==) [blog](http://superadditive.com/software/incf-cl/) 
Appears to be here: [http://www.iolanguage.com/library/papers/parallelism/connectionmachinelisp.pdf](http://www.iolanguage.com/library/papers/parallelism/connectionmachinelisp.pdf) 
Thanks! I wonder why you were downvoted.
That's much nicer looking than [SRFI-42](http://srfi.schemers.org/srfi-42/srfi-42.html), in my opinion.
I bought the book out of curiosity, and it turned out to be a really boring book. Large meaningless cartoons taking up a lot of space.
Don't believe everything you see on reddit. Keep refreshing this page and see the number of that comment's downvotes change but the number of upvotes remain the same.
Um, range + map + filter. EDIT: Or, for efficiency (defun filt-map (f guard seq &amp;optional (output nil)) (if (not seq) (reverse output) (let ((item (car seq)) (rest (cdr seq))) (if (funcall guard item) (filt-map f guard rest (cons (funcall f item) output)) (filt-map f guard rest output)))))
**IT'S THE HASKELL MAFIA!**
Cute name there!
Lots of hacking; and lots of hacking. :-)
I think you're looking for [this thread](http://www.reddit.com/r/lisp/comments/ey04z/implementation_of_a_lisp_comprehension_macro/).
I've been seeing more and more positive response to the book lately. I can recall it being ridiculed when it was initially published.
Derp, so I am!
&gt; I can recall it being ridiculed when it was initially published. That's what I remember; idiosyncratic style that was critiqued harshly, iirc. Doesn't mean it is useless, but it *is* interesting to see the change.
I've read this; This was a really mind-expanding book and I think anyone who is remotely serious about learning Lisp should read it.
Absolutely. I was going to give this one a miss because of what I had heard/absorbed about it. But - as you can tell - I'm really glad I did get it. I'm now wondering why I got the impression that I did that it wasn't worth much. And I'm really looking forward to re-reading PAIP (:
Do you think it's worthwhile for someone who already knows lisp, or is it really just useful for beginners? 
I think it is really useful for people who know lisp. I don't think I'd recommend it for a beginner. But what is a 'beginner'? If you enjoyed 'On Lisp' but understand (not necessarily agree with) the criticisms of PG's approach and style, you'll really like this.
Interesting. I program in Lisp professionally (in Scheme mostly, but some CL and once &amp; a great while ISLISP), so this might be interesting. I'll check it out, thanks!
I thought it was worth reading. I wouldn't give it a fawning review, but it was thought-provoking. 
Land of Lisp? Got it, too.
[lol](http://knowyourmeme.com/i/000/051/726/original/17-i-lol.jpg?1275228554)
R Over Functional Languages?
Ramifications of Fast Lisp? Return of Functional Lisp?
Reduce Or Fold Left?
I vote for LOL (Let Over Lambda) and LoL (Land of Lisp), so we have disambiguation by capitalization of the O/o.
Got both. Land of Lisp is the better of the two, Let over Lambda is a nice addition if you have an otherwise complete collection.
I don't know that Python is a good replacement for Scheme in a teaching context. Also, do note that Racket isn't really a Scheme anymore. They respect a lot of the spec, but they support a pile of other stuff too. This includes a good module system, file system operations, port operations, a web server, regular expressions, hash tables, etc. In that sense, you can do about as much serious work in Racket as you can in CL (the big holes are image/PDF generation and printing libraries). Agreed on the interactive development point though; I think they severely undervalue it, and that was one of the reasons I left Racket for Common Lisp.
Let over Lambda is on my next-to-buy list. Unfortunately, there's less and less spare minutes to the day, so they'll keep gathering dust, just as the rest of the lispy literature I've accrued over the last 25 years.
hi @sugarshark, Since the inclusion of the elisp package manager in mainline Emacs and its compatibility with third-party repositories, the FSF policy has become less of an issue.
I don't see how inactive subreddits are annoying. It's good to have them here just in case something gets posted one day. The rest of the time the links aren't doing any evil :-).
What happened to arc anyway?
Lisp munges awkward ontologies
Actually, the best acronym for Land of Lisp would be just LL since "of" and related are never part of acronyms. The best examples are all the books you mentioned with the 4 letters. But I still don't see why many people worry about this since it's really not a big issue.
If you mean the programming language: Its first preview release was very underwhelming. Slow progress from PG might or might not be going on to improve it. Some people forked it I think. For accurate info google, wikipedia, the arc forums etc are your friends.
Basically the lisp community isn't large enough to warrant splitting it up into 6 subreddits (in addition to r/lisp).
Well, it turns out PG's great idea for a new lisp was scheme with shorter names and NIL punning. It also turns out that it wasn't an improvement, and looked a lot like the 'My First Toy Lisp' that most lispers write at some point. So, lispers who already know and like lisp didn't care, and those who were waiting for arc to be something different were disappointed. The only folk left were PG's ballwashers, and really, i think the mans 'nads were shiny enough to begin with. 
LL always makes me think of LL parsers.
you probably want sb-sequence or another extensible sequence protocol?
There was Anarki, which was the community fork that fixed many of the short comings of PG Arc, and there was quite a bit of experimentation, but I haven't seen anything as of late. I mean, even [arcfn](http://www.arcfn.com/), which was a blog about Arc &amp; Anarki, doesn't have too many posts about Arc. There are quite a few Arc systems out there besides PG Arc &amp; Anarki (several JS implementations, an implementation atop SBCL, several stand alone ones, self-hosting ones, &amp;c.), but I'm not sure how many are actively maintained.
&gt; FYI: Such as "to", as in HtDP. So? You do really like acronyms. &gt; But it would be nice to Google for "lol lisp" and "lofl lisp" and get sensible results. Google "Land of Lisp" or "Let Over Lambda". 
I don't really know what just went on there, was he praising lisp or making fun of people that use it?
tldr; Language designers dictate features that are present or absent from their language, and are thus making moral decisions about what the users of that language fill their minds with when solving problems. Lisp removes the moral/ethical decisions from the language designer and puts the power in to the user's hands by letting them redesign the language using macros.
Yes.
lol, one of the funniest things I've read today. &gt; If you're good enough to use lisp, you'll soon be frustrated with lisp. Lisp is not an adequate lisp. By the time my bus had made it two blocks I'd written some simple lisp macros that were so powerful they made lisp completely obsolete and replaced it with a new language. Fortunately, that new language was also called lisp. And i was able to prove, mathematically, that the new lisp i'd created was both far superior to lisp in every conceivable way, but also exactly equivalent to lisp in every possible way. I was very excited by this. But also found it very boring.
Its not so much a size thing, as it is activity. Links to dead or dying subreddits just gives the impression of a barren landscape IMO.
It's even funnier when you know that's true.
PG recently posted that arc is still in development, but mostly in his head. He needs some time to think it through before writing more code.
Possibly the best use of tl;dr I've seen
&gt; PG recently posted that arc is still in development, but mostly in his head. He needs some time to think it through before writing more code. Well, that's very nice, but that doesn't really help anyone who *isn't* PG. I actually found all the experimentation (like CatDancer's stuff) quite a bit more interesting than what the original "Vanilla" or PG Arc was anyway. Still, I'd be interested to see what improvements are actually made to Arc by PG; say what you want about him, he still has some interesting ideas. 
Since you got me thinking about this, I decided to look over CatDancer's stuff again to see what s/he was up to. Man, arc was implemented in a funny way: [Patch to use MzScheme's nil as Arc's nil](http://hacks.catdancer.ws/nil-impl-by-null.html).
It's a nasty patch but I think CatDancer is right to simplify both the language and the compiler this way. Makes it more like cl. If he keeps on going he'll eventually get all the way back to cl.
I think it's a great patch, but I just can't imagine implementing lists with anything *other* than the host system's '(). I mean, I've written several tiny lisp systems like this from time to time (and quite a few not-so-tiny ones) and I've never *once* thought of doing anything like this (and my first lisp implementation was **terrible**). I think CatDancer is 100% correct in this patch; I was aiming the critique more at PG/RTM than CD.
PG's primary motivation for arc -- concise code -- is a useful concept but from what I can tell brings nothing new to the table. Arc is dead unless somebody else takes it over and adds genuinely new capabilities. Maybe CD is that guy. I don't know. But it's not looking like PG is. I think he's having too much fun "incubating," if that's the new term for programmer sweatshop.
That guy has a dogmatic obsession with anti-dogmatism.
&gt; PG's primary motivation for arc -- concise code -- is a useful concept but from what I can tell brings nothing new to the table. Definitely; I actually even hated the style when it first came out, and I've never used it for anything other than to check for new ideas. &gt; Arc is dead unless somebody else takes it over and adds genuinely new capabilities. I'm not sure if that is the case *per se*; there is room for a pragmatic &amp; small Lisp dialect that fulfills some use case, I just don't see Arc as being there, and I don't see it going there either. I've been working on a Scheme dialect, and "eating my own dog food" with it for about three years now; I was inspired to create a "real lisp" system because of [Otter](http://otterlang.org), which was inspired by the author of Otter disagreeing with Arc's result, but agreeing with the need for something different in certain spaces. I'm not sure about Arc being useful in and of itself, but I think anything new like this can be a lightening rod of innovation. &gt; Maybe CD is that guy. I don't know. But it's not looking like PG is. I think he's having too much fun "incubating," if that's the new term for programmer sweatshop. I think he could come up with something useful, but you are correct, he doesn't seem to be moving fast enough. It looks more like a Perl 6 type scenario: when the new Arc *does* come out, it will have the features we've all been using for years, and have no idea why we should switch to Arc.
Except I spelled tl;dr incorrectly :P
Someone recently wrote a compile from prefix-Dylan to JavaScript (https://github.com/turbolent/ralph). That doesn't support everything (macro expansion is not complete, multiple inheritance and multiple dispatch are still missing, I think). With Gwydion Dylan, we're talking about adding a reader / parser for the prefix-Dylan syntax. While our website hasn't been updated for the new activity in the last couple of months, we're around a lot on #dylan on Freenode, working on things. 
Oddly enough though, none of the current Dylan implementations use this. We'd like to, though! 
It's worth mentioning that [Lamkins seems to have come out victorious against the publisher that was witholding his royalties](http://psg.com/~dlamkins/sl/). If you weren't buying it to support Lamkins, you can go ahead and do so.
Those are good news! I was lucky to buy his book before all that mess started. However, a second edition would be welcomed!
why is this so?
Ahem. I would say, let's give the author a few more months to deliver his much better version, or talk himself out of it. 
In fact, a second version of most Lisp books would be welcomed, along with a house-broken pony. The only two exceptions are Land of Lisp, because the author needs a break to regrow hair and adjust his eye-sight to daylight, and Winston &amp; Horn, which is on it's 3rd Edition. 
I figured listing these smaller Lisp related subreddits might actually give them some traffic. But if the lispit consensus is that they are not needed, I'll remove them (leaving scheme and clojure?) We could also add a few links to usefull lisp resources (planet lisp, ALU, Common-Lisp.net, CLiki, etc)
Well... CLtL is also on the second edition so it's three exceptions. And this is just counting CL books :-) 
CLtL is not really an exception, since apparently it needs a [third edition](http://ilc2009.scheming.org/node/48) (sort of).
mahmud was refering to the need of second editions ("a second version of most Lisp books would be welcomed"). 
No one did the work. I'm not aware of any technical difficulties in doing so (and it would benefit things too because it would allow optimizations to generic dispatch). I've been reviving development work on Gwydion Dylan. We'd like to implement C3 there but are currently working on getting some of the basics in place (GC improvements, 64 bit support, fixing some compiler bugs). 
I'll bookmark this. Thanks.
One thing that struck me in that linked article was this concept of grassroots users and CL changing over time... and I realized that QuickLisp might be an interesting start towards CL Extensions. That is, it would be useful to work with a list of what Lispers consider to be "recommended" or 5-star packages, useful extensions to the language that might not be as portable as a rigid standard would require but are loved by the community all the same. Would it be possible and relatively easy to set up a voting/rating system (with comments for those who want to see what 4/5 stars means) for packages that are exported through QuickLisp? Just a thought.
I want to add that to Quicklisp sooner rather than later.
I searched through the sbcl docs (perhaps not deeply enough?) and did not find any references to sb-sequence. Where can I find information on how to work with it or recommended strategies for using it? Right now, I just get the message that this is a forward class. Is this as simple as defclassing sb-sequence and defining a generic sequence interface that I can then subclass from? Thank you for the pointer.
Is there a reason why this competition is always limited to.... seven days? Isnt there a possibility that a significant part of possible participants could be put off by such a short time limit?
If you're personally put off by a limit of 7 days, you could announce your own game jam that was exactly as long as you wanted. It's just for fun.
because 7 is a traditional number for such things, as is 2 &amp; 5. I think once you go beyond 7 it gets to be too much of an investment for people, and it tends to end up as a 48 hour game jam, since many people wait until the last two days to do anything (not that I've ever done that... *cough*). 
* Anatomy of Lisp - John Allen - McGraw-Hill. This has a fascinatingly detailed analysis symbolic expressions. 
Try a library.
google "User-extensible sequences in Common Lisp" or just look at the sb-sequence package and the symbols it exports.
I asked McCarthy for the author's email (Allen was at Santa Clara U. at the time, FWIW) and asked the author directly about this, maybe 7 years ago, and he said that he did want to do a new edition but there were issues with getting the project off the ground. IIRC the biggest issue was that there was no online copy of the words, followed by the author's belief that it should be largely rewritten to be more modern, in multiple ways but especially by removing the M-Lisp (high level) notation. (Yes, I told him it would be great for it to be re-printed as-is, but that didn't fly with him.) Prospects don't look that great, I would think, unless someone has a brainstorm of some sort. I re-read the book once in a (long) while. It has a different perspective on Lisp.
He's been at it for a while and is convinced of the utility of the idea.
If the OP is from California, there are [10 copies available](http://csul.iii.com/search~S0?/tAnatomy+of+Lisp/tanatomy+of+lisp/1,1,1,B/detlframeset&amp;FF=tanatomy+of+lisp&amp;1,1,) in the Link+ system.
I have never programmed any "game" that was playable (self-playing mostly) and I'm psyched about participating in this and subsequence lispgames events. 
He might have a point although I find his zealous writing a turn off, perhaps I'm getting old. About his point: I sometimes joke I actually write in LOOP instead of CL since it it is my go-to macro for so many things where other constructs (which I'm not even aware of anymore) might be better suited.
I have a copy (autographed by the author). I hope to make a million bucks by auctioning that book one day. Not!
So does &gt;Technical: No bitmap (image files) really mean that, well, no bitmap files/data of any kind. Seems kinda too restricting. What about bitmap fonts?
At the very least, loop COLLECTs for free while DO et al. don't, making cleaner code trivial. I flirted with ITERATE, mostly because of its extensibility, but found that writing a driver is not as well documented as I hoped. 
Sorry for the zealous language, when I released Loopless 1.0 (the current version) I thought there was much more LOOP hatred going on because of its "philosophical" problems. It turns out, however, close to nobody gives a shit about such problems, so my documentation makes all the wrong points. Loopless 1.0 didn't have much to offer in terms of functionality, so it had to appeal to LOOP hatred, hence the zealous language. Now I know that just won't make the bar. Fortunately, Loopless 2.0 will be completely different. I "stacked" many epiphanies on top of eachother in a few days (great ideas that build on top of eachother), and now I'm convinced Loopless will become one of the top 5 Common Lisp libraries of the decade if I can implement all the ideas I have on mind and if they're as easy to use as I think they will be (though getting the point of and taking advantage of novel features might take some getting used to). I have a pretty precise idea of what the final Loopless 2.0 will be like. Sorry for not telling you much details, one of the reasons I'm being a bit secretive about this is that I feel many of these ideas, if discussed in hypotethical terms (what if you could do X) without an actual implementation to play with, would be easy to dismiss as pointless. Think of the Blub paradox. There's already a fair amount of early dismissal of Loopless 2.0 right now (mostly because I'm a nobody and how far-fetched my claims might sound I suspect), and I don't want to give it more legitimity than it has by presenting sloppy broken half-implementations of not-yet-refined ideas. I want to make sure I release 2.0 in one shot as a "final" product everyone can start using and enjoying profitably right away. I want to make a strong case that nobody can ignore. I'll make sure to explain the benefits of Loopless thoroughly in the documentation.
Wow! I'm really surprised someone bothered to post this to Reddit! Thank you, it really means a lot to me that there's any amount of interest for this, especially given how lackluster the current version is. Loopless 2.0 is in development, which will be another beast entirely. It will introduce quite a few "novel" concepts (nevermind that most concepts were discovered in the 60s or something), at least as far as standard Common Lisp practice is concerned. Among many other things, I found a way to pack a ton of features in a way that results in zero runtime overhead, and most importantly **near-zero cognitive overhead** when you don't use them for the situation at hand.
Extensibility will be a core feature of Loopless 2.0 and will be comprehensively documented! Not only will it be possible to extend it with new clauses (which was planned from the start of the development of the new version), but it will also be trivial to extend *already-existing* clauses with new subclauses. It will be possible to do so in ad-hoc one-off ways or in more formal ways (analogously to LAMBDA vs DEFUN). Importantly, the interfaces you'll be using to create new clauses or extend them are exactly the same ones used internally by Loopless to create all the built-in ones, so you know that the extensibility isn't an half-baked afterthought. The built-in clauses won't use any special code-walking tricks, no special rules about a "top-level". The body of the loop is just straight Common Lisp. Moreover, macros will be supported so that multiple similar specific clauses can all expand to a more general clause. Many clauses which are in the core in LOOP will be implemented as trivial macros in Loopless.
Can you still contact the author via email?
Thanks for giving me the benefit of the doubt! There won't be any "talking myself out of it" because I can already see a very broad and deep area of practical applications of the things I want to implement. The worst that could happen is that some of my ideas can't be implemented exactly as I envisioned them or are a bit less convenient to use than I would have thought, in which case Loopless 2.0 will be merely "very nice" instead of "insanely great". But note that I have zero doubt that Loopless 2.0 will be very significantly better than LOOP, prompting a mass transition. The sorts of things I'm not sure about are more advanced features that I didn't yet have enough time to think about. During the last years of intensive development there are many advanced features I dreamed of implementing in various projects of mine but there were recurring big stumbling blocks in my way. Loopless 2.0 should make some of these disappear. So, I already know that this will be very, very useful to me. There won't be any giving up here.
I like ITERATE a lot but during a "no dependencies" binge a couple of years ago I finally got comfortable with LOOP (also thanks to ITERATE and Practical Common Lisp). ITERATE looks better and has couple of extras over LOOP (like NEXT-ITERATION) but I rarely need them and they can usually be worked around. IMHO ITERATE also had a better manual before the PCL LOOP chapters were published. If you're new to Common Lisp and LOOP looks daunting I can recommend learning ITERATE first. LOOP will be easier to pick up afterwards.
I'd definitely support putting in more 'external' links. Perhaps to quicklisp as well?
Anyone know of a version of this interview on YouTube or something similar?
Well, it hasn't happened yet, but hopefully Franz will post it for those that are unable to attend the webinar.
Sorry to say that that email address (and some years of work -- sigh) was lost in a disk crash a few years ago -- have you backed up lately? :-S Do what I did, ask John McCarthy (professor emeritus at Stanford, for those who haven't been paying close attention to his status). As I recall, at the time I simply looked up John's email on the Stanford site. It's probably actually on his (interesting) web pages. Or maybe I asked some Lisp or AI person for McCarthy's email; I can't recall. I tried googling Allen for you, but almost immediately got side tracked by a PDF of slides of a talk he gave in 2005 that I'm reading on and off today. He teaches (taught?) "periodically" at Santa Clara U., it said. BTW anyone interested in Anatomy of Lisp is likely to find interesting historical archived material on McCarthy's web pages about Lisp and AI etc., whether or not they're interested in his 4 decades of research in non-monotonic logic. P.S. I have a vague memory that the publisher was being curmudgeonly about copyright issues, too, although I can't swear that my memory is accurate. If so, that's not *usually* insuperable; they don't benefit from keeping something out of print, after all, although they can be greedy about not wanting someone else to publish and make money that they see as rightfully their own. Greed can be dealt with, though.
The used price is high and getting higher gradually over time, even skipping the common profiteers on e.g. Amazon, but yeah, it's better to just keep it as a collectible -- selling wouldn't yield *that* much, and I prefer to have the classics right at hand, anyway.
Why are we promoting a pay-for site that appears to have "borrowed" stuff from lispjobs? Over half the stuff there isn't even related to lisp (unless you adopt Java, Erlang, Haskell, and Python).
thanks... i'm trying to contact Dr. Allen via email. I'm not too far from Santa Clara, so I might even be able to meet him.
I'll put it on github within the week...it's my first lisp, so it's pretty hideous. It's really just a better syntax (lisp syntax) for javascript. Features an interpreter and a half working -&gt;js translator. There are some unresolved issues around macro expansion and namespacing right now and I haven't had a chance to work on it in a while, but I'll clean it up and put it out there ... and maybe someone smarter than me will decide to fix it up ;) at any rate, yeah sure.
actually I have a hard time to see any real use for definitions of select-values that return values not in the exact order of the keys provided. You get a bunch of values, but you don't know what those values are, since you don't know what keys they came from (the nil-filtering version has the same problem as when there are nil in the middle, all values shuffle up one position per nil and so don't correspond to keys anymore). As allways, those little snippets of code never really make much sense to me, as they feel completely made-up and artificial. Not really much you can learn from them, either, except that, yes, you can combine functions in clojure. so what? nobody questioned that ... 
[Iterate](http://common-lisp.net/project/iterate/) is much better thought out.
I could join you if you think there would be benefit. United front. Bodyguard. Muscle. You know. :)
Norvig suggested Queinnec's *Lisp in Small Pieces* as a pretty decent successor. While I have a copy from when it first came out, I wish it were a lot less expensive so I could recommend it in better conscience.
Except that during no part of it does it mention, you know, Lisp.
There is also a [revised edition of L.i.S.P.](http://paracamplus.com/?CGIRunMode=book&amp;urn=Cours/LiSP/4), less expensive but unfortunately in french only.
The [other](http://www.informit.com/articles/printerfriendly.aspx?p=1671636) [three](http://www.informit.com/articles/printerfriendly.aspx?p=1671637) [parts](http://www.informit.com/articles/printerfriendly.aspx?p=1671638) are pretty interesting too. (the site doesn't exactly load quickly, so I'm continuing the tradition of linking to the printer-friendly pages)
That was the brief part; the full tour includes all sorts of lispy-ness. 
Hi - I got a hold of him. There are questions about the copyright with the publisher. Really nice guy, and he was kinda bummed about this.
Congrats on taking it that far. Now, I believe that this isn't the end of the road, it's just that the author is defeatist and not doing anything about it. Thus my original comment about it probably needing a brainstorm: someone to figure out how to work around the recalcitrant publisher and defeatist author, and continue to follow up with making it happen.
that.
hello, this was done as a side video to an audio interview with The Weekly Repl about lisp, but the interview's publication was delayed a few days so the video doesn't really stand by itself. My point is that these are all things I am using with lisp (dance pads, screens, nice keyboard, and all). sorry for the confusion---I'll post a link to the interview as soon as it comes online. 
Okay, fair enough. I didn't downvote you before, but I didn't upvote either. +1 now. :)
nice book sofar, thanks for posting. Uses R6RS and DrScheme (Screenshots show version 4.2.2).
&gt; The most notorious of all bumps is lisps idiosyncratic syntax. We are blaming the parentheses again? When I first encountered Lisp, ()s were not my concern. CAR and CDR were. ;) The function call arrangement looked the same to me. I actually thought Lisp was a little cleaner-looking from the start, and I had been programming in Pascal, C, a C++ for a long time before I touched Lisp. func p1 p2 p3 # bash (func p1 p2 p3) ; Lisp func(p1, p2, p3) // C In all these languages, we have to be careful with complicated parameter sets: func long-p1-that-takes-a-lot-of-space \ $(subfunc x1 x2) \ long-p3-that-takes-a-lot-of-space (func long-p1-that-takes-a-lot-of-space (subfunc x1 x2) long-p3-that-takes-a-lot-of-space) func(long-p1-that-takes-a-lot-of-space, subfunc(x1, x2), long-p3-that-takes-a-lot-of-space) That Lisp syntax is starting to make more sense on the cleanliness scale... But the initial point stands: seriously, what's the difference? We just move ()s around. In fact, it looks to me like we are moving them out of the way. (And I can maybe argue that bash is an ugly kind of Lisp.) The other thing I had to get used to was that I had to use (+ x y) instead of (x + y). On the other hand, different infix-style languages have different operator precedence rules, and that lack of consistency can run you into trouble or cause you to use ()s all over your code to guarantee you are doing what you think you are doing. With this prefix-style, it is not an issue at all. You end up using the same number of parentheses. (9 / ((3 * (1 + 2)) - 6)) (/ 9 (- (* 3 (+ 1 2)) 6)) I am wondering if the real problem people have with ()s is that they keep hearing that ()s are a problem. Studies show that if a falsehood is repeated by a large number of different sources, people believe it is true or important (it has something to do with the mind not remembering the "NOT" and only remembering the info instead of the sources, an effective political campaign strategy). It is long past time to stop talking about ()s and to focus on other language features that are actually significant.
I've really never understood the parentheses "problem". When I encountered the Lisp syntax, I instantly fell in love for its beauty (I was mostly a perl programmer at the time).
I'll admit that, on a personal level, I'm still stumbling over Lisp and Scheme syntax. Granted, I'm a drooling amateur at best, with just enough programming experience to disassemble C function calls and write some bad (yet functional) Python code. Scheme, in particular, has really opened my eyes and I find it quite inspiring, even if I have absolutely NO idea what I'm doing. And yes...those parens trip me up quite a bit at a glance, but at least I can break down the bits and figure out what's going on. To me, it's beautiful in that 'alien landscape' kind of way.
What trips you up on the ()s? Is it because you expect them to surround function parameters, and your eyes are looking for the function on the left side? In other words, is it a matter of familiarity? If so, I think I was able to adapt easier because I had played with other ways to put programs together (DOS shell scripting, BASIC "10 PRINT 12", and so forth).
I've been learning lisp for a few months and the parenthesis were intriguing for 48 hours and really quite attractive after that. If you indent the code properly I find it more readable than other languages compared to a file full of template and pointer noise with c++ or nested anonymous classes in Java. My biggest annoyance with Common Lisp is the slightly messy standard library with a mixture of generic and non generic functions. That's a bit like complaining the Â£50 note someone has just given you has a tea stain on it though.
Well as i use lisp more, i do see some places to kill some parenthesis or nestedness. Often times code is *mostly* functions and variables, so might aswel make = special at body-level, saving a parenthesis pair at each variable/ function definition, and saving three(pretty high, that..) pairs on LET, combined with scope(which we could put onto {}, or onto whitespace, like python) it also saves nestedness. Well, about nestedness, i have whined about ['denest'](https://encrypted.google.com/search?hl=en&amp;biw=1280&amp;bih=897&amp;&amp;sa=X&amp;ei=epwwTYj4LMaYOqfOhJwB&amp;ved=0CBIQvgUoAA&amp;q=defmacro+denest&amp;nfpr=1)(no not dentist, dammit) before. Its: &gt; (defmacro denest (&amp;rest args) (if (null (cdr args)) (car args) `(,@(car args) (denest ,@(cdr args))))) Anyway i think this can be applied to the scope-idea, by declaring some macros to be automatically denest 'into a scope'. Here this done to with-slots: { (with-slots (mekker mek) lame-object ..Note that putting stuff here still works..) ... stuff .. var=value ...more stuff... } For (with-slots (mekker mek) lame-object ... stuff .. (let ((var value)) ...more stuff...)) Or with denest (denest (with-slots (mekker mek) lame-object ..stuff..) (let ((var value)) ...more stuff...)) Probably should write it. Hmm how to get it to work with it `, stuff.. And if people learn this way of writing and not the regular way.. Not good. And maybe i just don't care enough about those extra parentheses. Edit: perhaps this is a bit pointless..
Lisp is notorious for its steep learning curve? Also, I did not grow to appreciate the parens. They're one of the things that I initially liked about Lisp.
That's a very good question and I can't really put my finger on it. Familiarity is likely the biggest culprit. Considering my very limited skills revolved around languages that used parentheses to denote parameters, perhaps. I'm starting to think it's less to do with the parenthetical markup itself and more to do with prefix notation *with* the parentheses. I understand why it's used, I enjoy the consistency, and it does make me tingly in a good way but...I'm FAR from comfortable with it yet and my eyes rebel. Like I didn't have enough vision problems!
Same here CAR and CDR were far worse than the brackets.
Today, they make sense to me. I would say I prefer them because of their connotation, at least as opposed to "(one-part cell)" and "(other-part cell)".
Two things that help me with the mental shift: * color to differentiate ()s from other symbols * NOT using rainbow colors for that 
just curious, what format is this in?
When I code in C-style languages, I end up putting the opening parentheses at the beginning of the function call, especially when the name is short: `(foo` *delete* `foo()`
Scheme (Chicken, Racket) is the way*!* It hasn't many good things CL has, though.
I loved `car` and `cdr` from the beginning. But I didn't understand them, especially why `cdr` returned a list.
I wish we had, for each language 1) a library to convert code from it to s-expressions 2) a library to turn the s-expressions back to the original language 3) libraries to turn the s-expressions to CL. For extra awesomeness make asdf be able to use these automatically, with the right plugins, and for yet some more awesomeness, also have tools be able to provide some autodocumentation on the various languages. Unfortunately parsing nonlispy languages is much more difficult than writing it.
I wish we had Lisp Machines.
&gt; a library to convert code from it to s-expressions I dunno that it's such a good idea. This is basically how you would go from a C-style `for`-loop to that `while` monstrosity I quote in the post (as opposed to realizing that you're operating on a sequence, and that you therefore actually want a single-line `mapcar`). There's a difference between *transliterating* between languages and *translating* between them. I could at least picture a library that did the first (and wasn't tied down to a specific compiler). A library that could do the second seems like it would obsolete programmers.
I really don't understand that wish. Any machine could be made into a 'lisp machine', there would just be a little compilation layer inbetween. 'I wish we had a lisp OS' makes more sense to me. Really though, that too has many ways to interpret it.. I'd interpret it as something that boots and is easy configurable all the way through. For instance GUIs you can click on anything and get to changable code.(And the default code is *good* of course.) However, i do not think we're quite up to it for making it. Really, though initially, i'll settle for a 'lisp browser', knowing how to do that tells a lot about how to do the OS.
It doesn't have to convert to that monstrosity. You could convert it to a DO, or you could apply some 'equivalence transformations' in between. Not sure if seeing the equivalence to the MAPCAR or something is very doable, but you can't really expect to get much more information out of it than the language allows. You are right, often it wouldn't convert to very good common lisp code. I want both 1 and 2 because it allows us to show quality of the thing because they must be inverses.(Edit: relation like between [cl-html-parse](http://www.cliki.net/CL-HTML-Parse) and LML2) Modulo irrelevant stuff, of course, perhaps not entirely modulo comments, because comments might be useful for autodoc. Another reason is because we're better if we critize the languages *and* are able to read it automatically. And some languages do have the constructs to nearly be good lisp code if converted, for instance, when everything is functional,(No setting, no classes) that'd translate very well; it'd be just defun's, flet's, labels, let's and let*'s, and perhaps defvar's.
isn't it what the Smalltalk does? 
Well, you can't have microcode/instructions for garbage collection, car, cdr, cons, etc, in x86. That would make writing a fully Lisp-written OS almost trivial. For a Lisp OS, it's fundamental having incremental compilation (like any non-toy Lisp system) and, inheritly, everything should become part of the OS, making possible having anything communicating with everything.
I took it to mean "I wish Symbolics had crushed IBM".
I don't know any smalltalk, what do you mean?
But those sound like things that give you performance gains, not something preventing anyone from making an lisp OS. Perhaps it makes things easier for the programmer, but does it really make sense to shift the problem off to processer makers? Does it make sense to do garbage collection to the chip?
The model of providing a fully-introspective UI layer on top of the base OS is basically how smalltalk works. Download [pharo](http://pharo-project.org/home) and go through the first bit of their [getting started tutorial [pdf]](http://gforge.inria.fr/frs/download.php/25599/PBE1-2009-10-28.pdf) to see what I mean. It's more or less what you propose above (except not in Lisp, obviously).
That's why they are called *Lisp* Machines, they are Lisp-based all the way down to the hardware. You can do a Lisp OS on x86, but it's an awful architecture and I'd lose/reimplement all the nice things that LispM have. Yes, it makes things easier for the programmer and gives you *significant* performance gains. Lisp Machines had all this 30 years ago, so they are possible. Having all that bloat in the x86 is not so happy and simple, too. Leaving the garbage collection to the machine ensures that there will be no leaks and will be much more faster than a software one.
He does mention iterate ftr. Iterate is better than LOOP in many ways. But at least a big subset of it can be done with more regular like (defmacro collecting (&amp;key (onto (gensym)) (return t) (call 'collecting)) &amp;body body) ... macros(thats a different collecting than in loopless), though. And stuff like DOLIST can be used in combination with denest too. It can pretty much be combined with everything, it really is a 'notation-changing macro' and nothing else. (defmacro denest (&amp;rest args) (if (null (rest args)) (first args) `(,@(first args) (denest ,@(rest args))))) This kindah suggest that we just need regular old macros and this to deal with some nestedness. That said, i haven't gotten my head wrapped round this iteration thing entirely. And maybe that is the problem. We don't really know how to deal with the problem generally.
We had Lisp OS with Symbolics and Xerox. I remember the File browser on the Xerox machine. How hard would that be to make a Web browser from that? I wish we had Scheme or Lisp instead of Javascript! 
At least we have [some libs](http://www.cliki.net/JavaScript) on it, but i am not sure how effective those are. I have been trying to get something that can render html in LML2 form with cl-cairo. A simple browser for just plain html would then follow just by applying it with cl-drakma and cl-html-parser. And it might be useful for making GUI interfaces and html pages at the same time.(Those things should be largely the same, shouldn't they?) (And cairo is neat in that it can output .pdf, .ps, .svg, and .png too)
Ok, you sound like you're right. Still though, i prefer to have my code usable by the regular public with regular computers. We have to deal with the actual computers out there, not just with our 'dream computer' anyway, so then i dont really see all that much point in LispMs at this point.
&gt; a library to convert code from it to s-expressions Doesn't the compiler itself do something like this? After lexing and parsing, you end up with a parse tree, which is very similar to Lisp. You'd just need some code to make the compiler spit out the parse tree in s-expression format.
Correct, but more easily said than done. Otherwise one would expect such libraries already to exist. There are 'parser generators' like [bison](http://www.gnu.org/software/bison/) but tbh i don't know how to use them. Using them is significantly harder than using s-expression output. I also recently found [this](http://www.cliki.net/parser-combinators) on cliki.
I think I would write a FOR in Lisp. (for (init) (cond) (incr) (code block)) There is a difference between converting to sexprs that are idiomatic Lisp as opposed to converting to sexprs that represent ASTs of the source language. As in, I think we mostly agree. I think it can be a good idea in that now you can really play with the C code.
Sort of. Getting the AST and outputting it as s-exps is relatively simple (compilers almost do this, as you note). I was just pointing out that this isn't the same as translating from [language x] to Lisp; it would get you something closer to the "before" snippets in the article than to an idiomatic, but equivalent Lisp program.
Yup; you hit the nail on the head. Getting the AST and representing it in s-exps is possible. I just wanted to clarify that this wouldn't give you idiomatic code (that is, what's happening is transliteration, not translation).
Many programmers say such things. Respectable computer architects showed that, at least on early RISC architectures, baking stuff into the hardware only gave a ~20% speedup. Remember: gates dedicated to tagging, etc. cannot be used for other operations. Lisp machines died like most other special-purpose machinery. Its generally better to pool resources into developing general-purpose, configurable hardware.
For many languages, see LLVM. Non-lispers are starting to do great things.
&gt; I concluded that i didnâ€™t have enough experience to say for sure if certain things were good or bad. This is the right attitude to have, and one i held for many years when i first started lisping. The designers of lisp had a good reason for every decision. You may not agree with their rationale, but you can appreciate what needed to be done.
&gt; cdr returned a list CDR returns whatever is in the second slot of a CONS. If that happens to be a CONS, it will return it as is : (cdr (cons 1 2)) =&gt; 2 (cdr (list 1 2)) =&gt; (2) (cdr (cons 1 (cons 2 nil))) =&gt; (2) (cdr (2)) =&gt; () (cdr (cons 2 nil)) =&gt; () 
&gt; Edit: perhaps this is a bit pointless Only thing in your entire rant i agree with 100% :)
Yeah, now I know, but at the time I didn't knew how a proper list was formed.
I wish I had this.
Just give the parse tree as s-expressions. Assume for, while, etc are special forms. The real problem here is the semantics of lots of languages are a huge mess.
Consider the evolution of multi-core architecture and consider how natural that evolution would be if a functional language had won out over the hacks we are left with. Yes, the Lisp Machines of the 80s have lost their value today, but given the chance to develop, I suspect the 'Lisp Machines of today' would be simply beautiful. Call it wishful thinking... it is. Lisp was indeed too far ahead of its time.
The weather is here, wish you were beautiful, blah blah.
That's basically what LispWorks and other Lisps provide. With the difference that usually the Lisp implementations prefer more native backend implementations for GUIs. Thus LispWorks doesn't look half as alien on Mac OS X as pharo does.
You can't deny my counting of the numbers of parentheses. (Though you can argue the usefulness of avoiding them.)
[Compose](http://common-lisp.net/project/alexandria/draft/alexandria.html#Function-compose) already exists in alexandria.(looking at it.. no delete-if-f? bit strange) Alexandria is a good lib.. Well, i only use a little subset though. I had a while doing silly stuff with macros too, silly can mean you're exploring things. Well, some silly some normal. Don't let the silly come out as it did with Loop.(And looks to me, to lesser degree also in loop.) Yours has much 'normal' in that they're indeed just stuff that CL sortah misses. Read your code a little, you made a little mistake(not a bug, i didn't check for that) in defining WITH-COLLECTORS. Usually, if you can do them one-by one you should, then collecting multiple times can be done by nesting the collecting-once one. When i was mucking about with [denest](http://ojasper.nl/src/lisp/basic/denest.lisp). Which, btw, i dont use all too often anymore, usually if you need to, usually rethinking a little works better. And it is also not sufficiently tested..(I really need to update that website some day..) Pretty sure collecting is good though. (defmacro collecting ((&amp;key (init '(list)) (onto (gensym)) (collect 'collecting) (append 'appending) (last (gensym)) (append-1 (gensym)) (ret t)) &amp;body body) "Collect everything asked to, return result. (Also, appending) If you want to use two different collectings, you need to provide the\ collect argument.(To avoid namespace collision, and to separate the two.)" `(let ((,onto ,init) ,last) (declare (ignorable ,onto)) (labels ((,append-1 (collected) (if (null ,onto) (setf ,onto collected ,last (last ,onto)) (setf (cdr ,last) collected ,last (last ,last)))) (,append (&amp;rest appended) (dolist (a appended) (,append-1 a))) (,collect (&amp;rest collected) (,append-1 collected))) ,@body) ,(when ret onto)))
Well, I wrote my own compose because I like my set of semantics better (and also I'm hopelessly NIH), they're explained at the bottom of this page: [Loopless Reference for COMPOSE](http://www.loopless.org/doc/COMPOSE.html#COMPOSE). Regardless, I realized this function doesn't belong in Loopless so I will deprecate it in the next release. ----------------------- As for your DENEST, it's otherwise known as WITH-NESTING, part of fare-utils: ;; Nesting binding forms (from a suggestion by marco baringer) (defmacro with-nesting ((#-ccl &amp;optional) &amp;rest things) (reduce #'(lambda (outer inner) (append outer (list inner))) things :from-end t)) For years I dreamed of a macro somewhat like this, and then when I discovered this implementation I was all excited but for some reason I actually never got around to using it for real. Some things are more fun in theory than in practice I guess... Maybe I should try to give it a shot again. However now I have a bit of a more aggressive indenting style when running out of space so I have less indentation nesting problems. For example, spreading mapcar on 3 lines (not counting additional lambda lines). ----------------------- As for WITH-COLLECTORS, it's straight from cl-utilities (but I added nconc-style accumulation). It will probably be deprecated in the next release too. First of all, because though I used it pretty extensively ever since I stopped using LOOP and liked it, there's some things about it that annoy me a bit. One of the things is that indeed, I always have a feeling this should declare only one collector at a time. But there are situations where I *actually* want to declare, say, 4 collectors at a time (seriously!) and the level of verbosity and indentation that would result if this was one-collector-declaration-at-a-time is just plain unacceptable. Even a solution with WITH-NESTING strikes me as pretty verbose (you'd have to repeat "with-collector" multiple times. Even this "plural" feature doesn't save you when you need to declare different sorts of accumulators at once, however, which is pretty aggravating. Another thing that I find convenient yet annoying is the "auto-returning" feature of this macro. If you only need one set of list iterators and want to return the results, this is perfect and exactly what you want, but in other situations this really gets in the way. I think I have an idea for an accumulation construct that would strike a better balance between ideals and practicality, but as for many other things I'm keeping this under wraps for now ;)
It's really disingenuous to compare Pharo/Squeak to LispWorks. Smalltalk is smalltalk all the way down. They're drawing all their GUI elements with simple primitives. It has it own concept of desktop and storage. It even abstracts away the concept of mouse. You will have to learn a new desktop system with its own metaphors and conventions. A full application with all the bells and whistles is binary compatible across all Pharo VMs. Same image runs on all supported platforms. Common Lisp could never muster this level of full integration just by virtue of it being *Common*: it's a standard born out of compromises, meant to be implemented by groups, independent of each other, and at times even adversarial. While Pharo/Squeak has no written standard and is just whatever the core group feels like having in the codebase this year. 
I'm not sure you understand the history and role of Common Lisp and the technology of something like LispWorks. First Common Lisp. It was not 'common' Lisp. Common Lisp was a work for DARPA to write a common successor to MacLisp. Several were in the works or existed (NIL, Lisp Machine Lisp, Spice Lisp, ...). The goal was to create a Lisp that would make all the software developed for and on Lisp Machines deployable on the next generation of machines, so that the military could have the next generation of AI software brought out of the Labs into the field: image processing, planners, software development tools, expert systems, CAD systems, ... All the fancy stuff that had been developed and was under development on Lisp Machines and mini computers (from DEC and others). Common Lisp was not created to have a common compromise Lisp. If you think that, you should reread who paid the show for what. It also worked. There were several successful applications for the DoD. One was a planning system written for the logistics of the first Gulf War (1990). It ran on Lisp Machines and machines from SUN distributed. It is said to have alone paid back for all AI (and Lisp) research financed by DARPA. Common Lisp was not designed as a compromise Lisp. It was designed as a language for implementation of large-scale AI software on a bunch of different hardware. Thus it mainly took much from Lisp Machine Lisp, updated it and defined it such that it was implementable on 'stock' hardware. From CLtL2: &gt; Common Lisp originated in an attempt to focus the work of several implementation groups, each of which was constructing successor implementations of MacLisp for different computers. These implementations had begun to diverge because of the differences in the implementation environments: microcoded personal computers (Zetalisp, Spice Lisp), commercial timeshared computers (NIL-the ``New Implementation of Lisp''), and supercomputers (S-1 Lisp). and &gt; Common Lisp is a new dialect of Lisp, a successor to MacLisp influenced strongly by Zetalisp... Zetalisp was the Lisp developed by MIT for a several Lisp Machines from MIT, Symbolics, LMI, TI and others. These guys knew Lisp ALL the way down. Not only with drawing primitives, but also providing the hardware that implements the drawing primitives from framebuffers to processor instructions. Next LispWorks. LispWorks provides a full introspective UI layer on top of the base OS. Called CAPI. But LispWorks is more clever, it does not implement its own drawing primitives, it provides an abstract layer (with drawing primitives) and below it delegates the execution of many CAPI constructs (where possible) to the host system. I can for example run LispWorks on a machine and load the environment with different backends (for example Cocoa, Motif or GTK+). Yet the Lisp interface is the same for all these platforms and the tools provide the same functionality. You can see Pharo here: http://pharo-project.org/about/screenshots The effect is that it reimplements Mac OS user interface elements poorly, instead of reusing native elements where possible and providing an abstract layer over those. There is no need in 2011 to draw your own buttons pixel by pixel. 'pharo' is basically only a prettier looking Squeak, which was a confused looking Smalltalk 80. There is really no need to have for example the Smalltalk browser as a subwindow inside some other window. Smalltalk had this already 25 years ago. In the meantime other Smalltalks improved over that and adapted to the host user interface. One can do what pharo does, but it is not an achievement. It is old and it shows. Though the UI is cleaned up over Squeak, it still looks ugly. Lisp had that with InterLisp-D from Xerox and many others. Other window systems won. Lisp usually nowadays adapts now not by reimplementing a window system based on primitives, but by providing an abstract layer and mapping that to the currently used native window system. The effect is that the programmer still sees Lisp's concepts, but the thing does not look and feel completely alien. Since Common Lisp defines only a base language, the type and scope of the integration into the host system is fully left to the implementor.
A bit OT: When I saw the title, I originally thought this would be about some kind of lisp--&gt;C compiler. As someone looking to program microcontrollers and not being too jazzed about needing to program in embedded-style C, I got all excitable for a moment. &gt;_&lt;
Lispers sadly do not (any more) enjoy a comparably mighty amount of funding, which Apple and Adobe provide for LLVM. In its heyday, Lispworld had that and could innovate at a higher rate. Proper long-term funding is the linchpin of substantial progress.
Good points. Well what i meant is that you can have an internal macro with-1-collector and make the external macro via that. That way instead of having to do '(multiple-value-bind (names collectors ncollectors tails) ..' and put lists in each you can just do one at a time. Like:(using previous collecting) (defmacro with-collectors ((&amp;rest collectors) &amp;body body) (if (null collectors) `(progn ,@body) `(collecting (,(car collectors)) (with-collectors (,@(cdr collectors)) ,@body)))) I usually treat compile-time speed a bit badly, and kindah assume the compiler/interpreter can figure out some stuff. I kindah assume that the interpreted/compiled result isn't much affected by many independed nested LET's/LABELS/FLET's.
&gt; Common Lisp could never muster this level of full integration just by virtue of it being Common A library can do pretty much anything, we have libraries for input like SDL, and libraries to draw. Of course it could be done.
:( Sorry. It deals with writing Lisp code with C idioms (and why you shouldn't). If you're really jazzed about lisp-&gt;C compilation, you can check out [Gambit Scheme](http://www.iro.umontreal.ca/~gambit/doc/gambit-c.html) and [The 90 Minute Scheme to C compiler](http://lambda-the-ultimate.org/node/349). Both Scheme-related, but you could probably translate them to Common Lisp without getting a serious headache.
Oh, neat! Thanks. I did find the article a rewarding read. It gave me a better idea of just what C idioms *are*.
Personally, I like generating nice readable expansions as long as it doesn't significantly and unduly complicate the implementation of the macro. I feel "gratuitiously" expanding to a recursive call to the macro goes against this goal. It's also a bit of an usability issue for things like macroexpand-1 through Slime. When I macroexpand a macro call, I like to see the "final product" of the macro immediately to see what it is exactly the macro is doing. I don't want to have to manually expand recursive calls to the macro in the expansion. It's true that simplifying the expansion can sometimes hide more advanced features of the macro that weren't used in this particular call, but I think it's a tradeoff worth making. However, I don't feel strongly about these issues (at least not currently) and would express no concern if anyone adopted a diametrically opposed strategy.
Just noticed: http://norvig.com/lispy2.html (An ((Even Better) Lisp) Interpreter (in Python))
I'm a fan, I think that provides more useful resources than previously.
All links are good, but there's only one thing missing... http://symbo1ics.com/blog/?p=275 (edit: Let me clarify, it is not a useful post for everyone, but it is to newcomers people say. It is my website, and I did write that post, but I posted a comment of it here because I think it is genuinely useful for others.)
You have to correct the link to the Common Lisp Directory, it links to Planet Lisp. I would also remove the "The" from the name to make it a little bit shorter.
s/usefull/useful s/compl.lang.lisp/comp.lang.lisp I would perhaps also add a link to common-lisp.net.
Didn't Genera have a C-&gt;Lisp compiler by the way? I think I remember that.
Thanks, done.
Thank you, fixed it.
Yes, but AFAIK it wasn't fully standard-compliant.
While I ultimately agree, on practical grounds, that "comp.lang.lisp" shoud link to google groups, I find somewhat sad that it is not a link to news:comp.lang.lisp.
Looks good to me but I would order the links from the resources section into similar types. For example, c.l.l., lisp forum and planet could be one group, Cliki, cl.net and cl.dir another one, the hyperspec, etc. As it is, it's a bit mixed...
Honestly, I've seen more Lisp users complain about newcomers complaining about parenthesis than I've actually *seen* newcomers complaining about parenthesis. I wish it were easy to verify something like that empirically.
I don't think I've ever heard anyone complain about parentheses, ever, even in CS230 AI Programming in Lisp &amp; Prolog (and I was the only person in the CS department who used lisp regularly, let alone liked lisp). I was just at a client who had just converted some old BASIC program to AutoLISP, and really liked the result, and he mostly programs CNC machines, so I don't think the parens are the barrier for entry for most people.
I guess that's interesting. It has been the complete opposite for me. Anyway, sorry y'all. Didn't expect such a negative reaction. Edit: Also, I hope you realize the article isn't just about parentheses, but captures a part of the essence of what lisp is.
I have the opposite experience actually... I've teach in the past an AI intro class using Lisp and parens were the number one complain. Even outside, from friends and colleagues who dislike Lisp, the number one complain was always the parentheses. I never understood why this behavior because in some cases was really irrational. I used to joke that parentheses were the most aerodynamic and sexy of all kinds of brackets but for some people, it was really a lost cause (including very smart people I must say).
It depends I guess; where are parens on your country's keyboard? The only time I've ever heard someone complain about parens (in general, not about in Lisp) was from a Swedish dev who used an odd layout (something like Dvorak but for Swedish?); his parens were far away, and thus he didn't like them. Bulgarian State Standard has them in an odd position too, but Bulgarian Phonetic is relatively normal. It all depends. Plus, as you say, it could be wholly irrational; they just don't like it because they don't like it, not for any other reason. I like the aerodynamic part though, I'll have to steal that :D
Maybe you could add [lispdoc](http://lispdoc.com/) and [Simplified CL Reference](http://jtra.cz/stuff/lisp/sclr/).
How about adding books like: Practical Common Lisp Land of Lisp Successful Lisp and some others to the sidebar?
The AI contest winner wrote in...Lisp.
is that how it is on the net?
The original examples in John Koza's book were (are) in lisp. And then Ken Anderson rewrote an optimized version of them.
You might like [ECL](http://ecls.sourceforge.net/) (Embeddable Common Lisp).
One thing I saw in the article and want to get repeated around the net so that it is more searchable: if you want similar readline-like experience to clisp in sbcl, you can use linedit. This makes sbcl much more palatable from its built-in REPL. Add this to your .sbclrc: ;;; Check for --no-linedit command-line option. (if (member "--no-linedit" sb-ext:*posix-argv* :test 'equal) (setf sb-ext:*posix-argv*. (remove "--no-linedit" sb-ext:*posix-argv* :test 'equal)) (when (interactive-stream-p *terminal-io*) (require :sb-aclrepl) (require :linedit) (funcall (intern "INSTALL-REPL" :linedit) :wrap-current t))) Modify as appropriate if you want to use quicklisp for loading linedit.
Linedit has been in my .sbclrc for years and works very well. I didn't mention it in my article since I didn't want to deal with packages and rc-files.
No problem. I had to get pretty lucky to run into mention of linedit when I started, and I just want to make it easier for future Lisp beginners. Later in the article you justify the use of clisp with the idea that clisp compiles the eval code faster. I do not have enough experience with sbcl and clisp to say one way or another, but is that still true? And can anyone suggest an alternate approach that would speed up the algorithms that generate and then run the code? An idea off the top of my head... Maybe the generated forms could be collectively evaled in a single large form, returning the results as a collected set that can then be evaluated for fitness? I assume that would remove the start-up/tear-down times of the compiler for N forms.
How does (funcall (intern "INSTALL-REPL" :linedit) :wrap-current t))) differ from just (linedit::instal-repl :wrap-current t) ?
I specifically added the paragraph on the speed differences between CLISP and SBCL because the former was so much faster to my surprise. The code in the article is from my initial exploration. In my current codebase things have developed further and I keep the generated code in a class together with its compiled version and fitness. I only recompile and recalculate when necessary (ie. when the generated code changes): (defclass mote () ((fitness :accessor fitness :initarg :fitness) (n-nodes :accessor n-nodes :initarg :n-nodes) (tree :accessor tree :initarg :tree))) Oh, I see I don't keep the compiled code around yet (since it's used only once when calculating the fitness). I've called the class "mote" since I needed a word to denote the individuals in a population and I thought the word "individual" itself was a little too ambitious. "Organism" didn't sound applicable and "digitism" just sounded stupid. "Mote" was nice, short and applicable. 
With the latter, you'll get an error because the linedit package is not defined at the time the form is read.
Oh, this sounds pretty great actually! I may have to try this out. &gt;:)
Nice. I've been using extensively CL for the past year for my research which uses GP. I have a GP library in CL (in CLOS) with standard GP and Strong-type too. It also allows normal EA stuff. However it's still in a very rough state and needs some parts to be rewritten. I've tested recently some new ways to represent trees which speeds up the engine a lot, but these still need to go into the main code. It's one of my goals to make it available soon but it can still take like a month or two unfortunately. 
I want to have a look at line edit's code. But I don't seem to find the right wording for google. Can you tell me where I do find it?
I almost freaked out when I realized that I have the same keyboard and mouse as you.
http://www.cliki.net/Linedit
can't upvote enough, as this is another step to turn ccl into a full dev environment for OSX on par with what MCL provided for Classic OS.
CCL is by far my favorite Lisp implementation and all of the Mac specific tools is one of the reasons I use it over SBCL. 
I would love to see a thorough implementation of the Google Data API. And although I'd like to write it myself, I wouldn't mind if someone else wrote a comprehensive Amazon Web Services API system.
A datetime package that ties together [date-calc](http://www.cliki.net/Date-Calc) and [cybertiggyr-time](http://cybertiggyr.com/pdl/) in some struct/object. 
And maybe someone can recommend me something for hobby/free time GUI programming :).
http://www.franz.com/services/conferences_seminars/webinar_1-20-11.lhtml
Porting [feedparser](http://www.feedparser.org/) to CL would be useful.
This recorded Webinar is only available for Windows 2000 or higher. 
Computer science isn't about language advocacy. 
You'd be better off with PCL than ANSI CL.
I see 3 *very* different languages depicted in that image.
Follow that up with some [On Lisp](http://www.paulgraham.com/onlisp.html), and possibly some [Let Over Lambda](http://letoverlambda.com/).
But you're supposed to interpret it as a story, left-to-right.
That seems like a bit of a harsh reaction to a post like this. To me it seems like he is learning a few new programming languages and enjoying it, not saying that he has found "the one true language" (as if there could be such a thing).
The webinar was actually fairly interesting. The recording is available [here](http://www.franz.com/services/conferences_seminars/webinar_1-20-11.lhtml) if you have "Windows 2000 or higher". Which is just about the dumbest requirement I've ever seen on a website, but hey.
The Objective-C bridge in CCL is really awesome. I've been using it and lispbuilder-sdl for a project of mine, and the interaction between the two has been completely painless (except, you know, forgetting to retain things - for some reason being in Lisp makes it harder for me to remember). It's good to hear that I'll have an easy way to make a full-fledged application of it.
Oh yes, it very much would.
According to Franz the whole thing is suppose to be in .wmv format in there, but I can't find it ...
You're quite right, I think it was past my bedtime.
They seem to know their target demographics intimately, don't they? Making such an absurd requirement in the middle of a media-visible press release is nothing short of embarassing, for both the company and the (unvoluntarily) speaker. Especially requiring the 11 year old "Windows 2000" is somehow reminiscent of the dotcom bubble time and immediately suggests that the company (or at least it's mindset) maybe hasn't progressed since then. FAIL. (Had they had the balls to require "Windows 95 and IE 4.0" it would at least have been funny.)
If someone can provide the whole recording, I am most interested
It's well worth the listen, if just for listening to MÃ©lis talk about how one goes about solving a software problem through several revisions and how using CL helped in that context.
Yes, I have listened to the excerpt and I like it. Makes me want to hear the whole thing.
Source? I don't remember them promising anything other than a recording of the webinar (which they seem to have done in GoToMeetings' Windows-centric format).
If you register you can download an asx playlist which when played will stream a wmv. Unfortunately on both Windows and Linux the stream dies around the 15 minute mark for me, just as it gets interesting. I have no idea why a company that prides itself on being at the forefront of the Semantic Web would choose such a rancid format to distribute their webinar. It's like time traveling back 5 years, why didn't they use real player while they were at it :)
[Workaround](http://news.ycombinator.com/item?id=2129438).
Email from Franz after i asked if it was available in a open format
tl;dr: change your user agent to something windows-y
My experience is that ANSI CL as a first text is easier than PCL. However, PCL is a must and has better style.
For the supremely lazy; google-chrome --user-agent="Mozilla/5.0 (Windows; U; MSIE 9.0; WIndows NT 9.0; en-US))"
floating point?
if you need more precision try (exp 1d0)
It probably has something to do with this: smithzv@ciabatta:~/src/c$ cat exp-test.c #include &lt;stdlib.h&gt; #include &lt;stdio.h&gt; #include &lt;math.h&gt; int main (void) { printf ("%'.16g %'.8g\n", exp(1e0), expf(1e0)); return 0; } smithzv@ciabatta:~/src/c$ gcc -o exp-test exp-test.c -lm smithzv@ciabatta:~/src/c$ ./exp-test 2.718281828459045 2.7182817 Not that I think the math library that for the C language is the gold standard. EXP returns a float, and a float can only be trusted to a certain accuracy. A rule of thumb I use is that a 32 bit float tends to hold 8 significant, decimal digits and a 64 bit number 16. Maybe your complaint should be that SBCL prints one too many digits, but the accuracy doesn't actually correspond to a whole number of decimal digits. [See this as well.](http://www.reddit.com/r/programming/comments/ezl58/what_every_computer_scientist_should_know_about/)
Thanks, that helps a lot. I'm new to Lisp and just found a bug in alexandria:subfactorial, caused by (exp 1).
Because he gets 500 Bucks if someone would post a job there.
Those days are still yet to come ... ;-)
Hmm, does this "LISP punditry" fluffticle seem too early to anyone, or is it a leap-week? I was expecting them on strict Mon-Wed-Sat schedule, two each day. 
I have never tried those things, but LOCAL-TIME and PERIODS are a good mix. http://cliki.net/time has more of the time stuff. PERIODS is here https://github.com/jwiegley/periods Generally, local-time is recommended for time stuff; it's up there with alexandria and babel as "stuff that everyone uses to augment the standard". 
Bad, bad, bad choice. X/MIT/BSD are obsolete licenses which were created before the onset of software patents. They do not have patent release clauses, and using software under these license puts one at risk of patent claims by the licensor. Change the license to something modern and decently designed, like Apache. 
For me they certainly are. I program very part-time, and 20 years after taking an AI course in which I learned Scheme, I've been producing serious finished applications for my business using LispWorks.
Kazimir Majorinc is asking? The the answer is obviously when lisp was dynamically scoped, interpreted, and had fexprs, regardless of what the experts and evidence say.
This is the language I presented two years ago at the 2009 International Lisp Conference. It's finally ready for people to try out. From the documentation: Adder is a Lisp-1 which compiles to Python. It aims to integrate seamlessly into Python: every Adder function is a Python function, every Adder list is a Python list, etc. Python-on-Lisp has been tried before; I think Adder has two advantages that previous attempts did not. The first is technical: Python's metaprogramming has gotten better in the past few years, which allows Adder to integrate more smoothly. The second is social: Clojure has prepared the ground for the notion of a Lisp that integrates into an existing language. It has one bit of non-Lispy syntax: foo.bar.baz means exactly what it does in Python, and .bar.baz is a function, defined so that (.bar.baz foo) is identical to foo.bar.baz.
all this is true, however it still reads ad hominem.
"The ad hominem is a classic logical fallacy, but it is not always fallacious; in some instances, questions of personal conduct, character, motives, etc., are legitimate and relevant to the issue." -- [wikipedia](http://en.wikipedia.org/wiki/Ad_hominem) I'm am not making a logical argument, but rather questioning the motives behind the post.
The post seemed pretty neutral to me. Not extremely interesting perhaps, but there was no newlisp in the chart. The lisp community, perhaps because of its longevity, seems sometimes a bit too quick to apply certain personal heuristics, i.e. labelling trolls. Sometimes (albeit, I agree, not often) even Xah Lee has interesting things to say. Likewise, as you know, there was some days ago a certain thread on the Pro ML that was silenced by the moderator because it was rapidly labelled as the same old pointless question ("is Lisp dying?"). While I agree that Lisp and BSD have been happily "dying" for decades, I think it is nonetheless useful that the community reflects on the future in a way a bit more far-sighted than "quicklisp is great" (it is, btw).
&gt; The post seemed pretty neutral to me. Kazimir has a history of posting seemingly neutral topics and then using the responses as a launching point to push an extremely pro-newlisp agenda, usually to the detriment of the conversation. &gt; The lisp community, perhaps because of its longevity, seems sometimes a bit too quick to apply certain personal heuristics, i.e. labelling trolls. I can't speak for the 'lisp community", only for myself. I think Kazimir is a troll. Can i not freely voice my personal opinion without me becoming a spokesperson for the entire community? &gt; Likewise, as you know, there was some days ago a certain thread on the Pro ML that was silenced by the moderator because it was rapidly labelled as the same old pointless question I'm the person who labelled that question as the same old pointless question, in a private email that the author felt the need to publish publicly on the list and set off that whole shitstorm. &gt; I think it is nonetheless useful that the community reflects on the future in a way a bit more far-sighted than "quicklisp is great" (it is, btw). Are you trying to say the "lisp community" doesn't reflect on the future enough to your liking? Are you saying that the lisp community has failed to look forward, and that they focus too much on quicklisp and not on what is truly important? Really, i have no idea what point you're trying to make here.
&gt; Kazimir has a history of posting seemingly neutral topics and then using the responses as a launching point to push an extremely pro-newlisp agenda, usually to the detriment of the conversation. Ok. I did not know that. &gt; Can i not freely voice my personal opinion without me becoming a spokesperson for the entire community? Of course you can, but I am also free to note that what you say belongs to what seems to me a recognizable current of thought. &gt; I'm the person who labelled that question as the same old pointless question, in a private email that the author felt the need to publish publicly on the list and set off that whole shitstorm. Yes, I agree that publishing your private mail was unproper. However I found the public follow-up interesting anyway, because even if the question is the same, the forum in this case was composed by a qualified group of people, not by a collection of trolls. So I was sorry that the discussion was cancelled, maybe something interesting could emerge. &gt; Are you trying to say the "lisp community" doesn't reflect on the future enough to your liking? I think so. Is that a crime?
&gt; So I was sorry that the discussion was cancelled, maybe something interesting could emerge. The same conversation has been re-hashed over and over again, with newbies blaming the existing community for not catering to them, and the existing community countering that they are getting along just fine without whingy newbies. It's counter productive, and leads people to generalize about 'the lisp community" and how it reacts to 'good advice' from 'concerned citizens' instead of focusing on the real issues. &gt; I think so. Is that a crime? Not in any jurisdiction i'm aware of. I think you've got two options that makes sense if that's the case: 1) Do something to help. 2) Find a community that caters to your needs. Unfortunately, too many choose option 3 ,"bitch about it on mailing lists and forums", which i personally find deplorable. (edit: I don't mean to refer to you here, this is not a personal attack) I also don't feel like re-hashing the same tired bullshit, so unless you have solutions or something positive/interesting to discuss, i'd just as soon leave this conversation here.
Talking about a topic is not "bitching", nor it is "tired bullshit" just because you are not interested. You are unnecessarily rude. [edit: did not read your edit!]
And here i thought i was being unnecessarily nice. Perhaps you read my post before my edit? Or doth perhaps you protest too much?
&gt; Perhaps you read my post before my edit? That was the case. But I still side with the poor clueless newbies sometimes. "Do something to help or shut up" may be ultimately true, but I still think that kindness is an important virtue. We are human beings, not software constructs which PASS or FAIL. Also, one must have a clear idea before doing anything, and I know no better way to form one than talking. I don't feel knowledgeable enough on lisp, yet. And I've been using it for some years.
they should have called it thnake
Some style suggestions: * Use .rkt instead of .scm for Racket source, as Racket doesn't adhere to any standard. * Instead of `(if predicate true #f)` use `(when predicate body ...)` `when`'s body has an implicit `begin`. You also have `unless` which is the same of `(when (not p) b ...)`. * Use `racket/base` and `require` just what you need: it will make the code load faster. * When you need `racket/gui` or `racket/gui/base`, use just `#lang racket/gui(/base)`. * Always specify the `#lang` in every file (and prefer `racket/base`, it *is* important) You can use different `#lang`s in various files. * Use `(require "file1" "file2" lib/1 lib/2)` instead of `(require "file1") (require "file2")` etc. The same applies to `init` and `field` in the class definitions. * You don't need the `SRFI 43` in `maze.scm`, vectors are in `racket/base` * Don't rely too much on classes and destructive updates. Prefer pure functions and returning a new, modified data structure. * I don't really want to appear rude, but take a loot to the [Racket's docs](http://docs.racket-lang.org/). Also, prefer the reference manual to the tutorials and such, because the PLT folks can't really make good tutorials. * You could change the `(vector #t #t #t #t)` to `(make-vector 4)` or `(make-vector 4 #t)` in node.scm *edit: finished spouting sentences, you can ask for your questions.*
Why does it seem like the fundamental parts of Lisp are considered to be bad practice? Its map implementation is a list of tuples with O(N) insert, search, and delete. Merging maps is O(M*N). Its list implementation is a linked list that is also O(N). It's almost like the entire language was designed before the fundamental papers in hash maps, binary trees, or algorithmic complexity were written. Oh yeah; that's right ... it was.
Relative vs. Absolute
Probably not, but that's all I can guess.
&gt; But I still side with the poor clueless newbies sometimes. You seem to be assuming that i don't. &gt;"Do something to help or shut up" may be ultimately true, but I still think that kindness is an important virtue. I agree. I also think it's important to respect the efforts of the people who work hard just to keep the "lisp community" going. All this talk about what isn't being done seems to miss what is... a lot of people are working very hard to keep things at the level they are. Expecting other people to provide for you whilst simultaneously disrespecting their efforts to date is, unfortunately, all too common amongst "clueless newbies". &gt; We are human beings, not software constructs which PASS or FAIL. The "lisp community" is also made up of human beings. Human beings who are not only aware of the issues faced by "clueless newbies", but many who are actively trying to make things easier. Unfortunately, there will always be a newer newbie who takes for granted everything that existed before they found lisp... regardless of how many years of discussion and effort are behind them. &gt; Also, one must have a clear idea before doing anything, and I know no better way to form one than talking try research! It may turn out that your idea is not original, and has been talked about for many years. It's ok to want to discuss, say, free will... but unless you've read Descartes, for example, you're probably rehashing the same old "tired bullshit". To someone actually interested in free will, explaining Descartes for the nth time is not only not going to be interesting, but likely quite boring. It would be much more useful if the newbie read Descartes themselves, rather then expect the experienced person to make the effort for them. Do you see what i'm getting at or am i casting pearls? (edit: when did you stop beating your wife?)
&gt; its map implementation is a list of tuples with O(N) insert, search, and delete. nonsense. &gt; Its list implementation is a linked list that is also O(N). A linked list is a linked list? true, but meaningless . &gt; It's almost like the entire language was designed before the fundamental papers in hash maps, binary trees, or algorithmic complexity were written. Wait, so the hash tables, binary trees and algorithms i've been using in lisp all these years don't exist? Either you're a troll or completely ignorant of Lisp. I'll assume the former, as you are reading a lisp forum ;) edit : for those following along at home, common lisp comes with hash tables, arrays, classes, methods and instances, structs, streams, strings, characters, pairs (cons cells), integers, floats, complex numbers, symbols, packages, and a few data structures i'm sure i'm forgetting. It doesn't really have lists (only chains of conses), maps (though it has #'MAP), and the ANSI Common Lisp standard is in fact newer than Java. 
Mu. edit: I know it does, in some cases, and it certainly doesn't in others. I'm not sure what answer you expect to get beyond 'maybe' given how general the question.
&gt; Unfortunately, I look at my code and it cries for being such a mix-and-match of styles. That's not actually such a bad thing. Lisp allows you to get away with this, as it's a multi-paradigm language with no particular prejudices. The hard part is figuring out what style suits which problems, especially if you don't know many styles. Try writing the whole thing as a functional program (no mutation, no set!). Try using different algorithms, data structures, etc. Some problems are well suited to a 'typical' object oriented style. Some programs call for recursion, some for iteration.. some for mutation, some for provable correctness. Lisp is style-agnostic, in my opinion a "lispy" program is one that is written in a style most suited to the problem being solved... the language gets out of the way. I know that's not really the advice you were looking for, and i hope it's not so vague as to be useless. 
Lisp programs are themselves lists, which leads to macros etc. I would certainly be interested in a mind-warping language structured in hash tables. 
+1 for Mu.
Curious, is that Mu, as in Japanese negative?
Yes: drewc's answer references the Zen koan where the novice asks the master if "a dog has a buddha nature" and the master's response is "mu"... essentially the thought (and how it's used in hacker culture) is that the question is really quite meaningless since it depends on incorrect assumptions or is otherwise meaningless. 
it has I think its (I am not too keen on IBM 701 register acronyms from the mid 50s) a "cons" of "cars" I think it's called ... which are effectively maps. The "chains" of "conses" are linked lists. If they weren't in "lisp", they would all be considered algorithmically prohibitive. And it's a fact, a *fact* that lisp predates these fundamental data-structure papers which have helped craft modern (read, within the past half a century) languages. Not everyone that gets lisp necessarily does the juvenile childish "mind = blown" or what-have-you. After that epiphany or whatnot, then there is 15 years of hard work, then you realize "hey, maybe this wasn't so awesome after all". And yeah, it's not. Lisp holds CS back intensely. There's a huge MIT ego amongst many lispers I know; the "not invented here" syndrome; it's appalling.
Don't think so. As far as I know it's older than the Zen koan treerex refers to, also exisiting in sanskrit sources.
Step 1: write code Step 2: run on both implementations (using LW PE if needed) Step 3: tune code to implementation of preference ...
that's like asking if macs "run faster" than pcs. it depends on so many variables.
My trollert is sounding so loud that I will probably end giving credit to Drew, and for this reason alone I hate you already :-) *However,* let's suppose that you have a point, somewhere, and I really am too uninformed and closed-minded to understand it. How would you modify/rethink Lisp to make it more modern according to this paradigm shift that you are mentioning?
[Mu](http://www.eps.mcgill.ca/jargon/jargon.html#mu)
Thanks, drewc, It actually makes a lot of sense. I think one way to achieve this will be to actually try to implement the same thing with different styles (with strict adherence to each one) to see which parts of my problem are best solved by which style. I'll give that a try later.
Thanks for the tips, anvsdt. I was, indeed, annoyed by the weird usage of if. It's good to know there are better alternatives. I'll also try to use more of the #lang and less of require, when it's appropriate. About using SRFI 43, I needed it because of vector-for-each, that I (can't remember now) either couldn't find in the other set of vector libs, or it behaved differently (not giving the index of the element as a parameter to the applied function) About relying less on classes and destructive updates, that's exactly what I want to do, I simply don't know how to do it and still maintain the code fairly easy to modify (such as, adding new algorithms for creation and stuff like that) I'll work on that, but if you have any tips I'd love to hear them. The stuff about the docs, I figured that indeed. I've been reading them while programming, but I think my problem is more in knowing which tools I can use than to how to learn more about them. Thanks for everything :)
I was wondering that, too. In a VM running on my laptop, Takeuchi times (1000 iterations): 15.05 secs, cll-trunk 14.97 secs, c, unoptimized 6.36 secs, c, optimized 
&gt; it has I think its (I am not too keen on IBM 701 register acronyms from the mid 50s) a "cons" of "cars" I think it's called ... which are effectively maps What the hell are you talking about? &gt; The "chains" of "conses" are linked lists. If they weren't in "lisp", they would all be considered algorithmically prohibitive. Lets say i give you the benefit of the doubt, and assume you actually have a coherent point. Can you explain, to a poor stupid lisper, what the hell you are going on about? What does any of this have to do with your central premise? What does "they would all be considered algorithmically prohibitive" mean in the context of cons cells? &gt; And it's a fact, a fact that lisp predates these fundamental data-structure papers which have helped craft modern (read, within the past half a century) languages. And? Lisp is a general purpose programming language, and all those data-structure can, and have, been implemented in lisp. Do you think we are all still using LISP 1.5? The lisp i use had its most recent release on December 06, 2010. Exactly which fundamental data-structures have been introduced since then? &gt;Lisp holds CS back intensely. This is complete nonsense, you make all these assertions and statements yet you very obviously don't have a clue about lisp, and all your data seems to be pulled out of your ass. No wonder it smells like shite. 
&gt; I think one way to achieve this will be to actually try to implement the same thing with different styles (with strict adherence to each one) I think that's a great idea, exactly the sort of thing i had in mind.
&gt; About using SRFI 43, I needed it because of vector-for-each, that I (can't remember now) either couldn't find in the other set of vector libs Indeed, but you could use `vector-map` or a loop (I suppose you already know about named `let`s). But that's just me, I don't like to mix Scheme and Racket. You are free to do what you want. &gt; About relying less on classes and destructive updates, that's exactly what I want to do If you can use [structs](http://docs.racket-lang.org/reference/define-struct.html) to aggregate data, and then define some functions that work on it. The `node%` class can be replaced with structs and functions, and the wall-index thing could be replaced with a `(struct wall (left right top bottom))`, accessed with `(wall-left my-wall)` and setted with `(set-wall-left! my-wall)`. Or you could just use an `hasheq` with 4 elements. (but remember that the main data structure of Lisps is the list, not the vector!) &gt; (such as, adding new algorithms for creation and stuff like that) The secret is: your functions and data structures should be indipendent from each other, do little by themselves, but work together. My overall suggestion is: forget about all the extensions Racket gives to Scheme and use just the base Scheme, with `let`, `Î»`, lists and such, learning functional programming and the joys of immutable data structures. Then step up to more complex things like vectors, hashes, defining your structs and classes (even though, after that, I doubt you will touch classes anymore), etc. Basically, limit yourself and do simple things first, and unlearn whatever you already knew. (Also, try to avoid creating new lexical scopes and nesting `let`s, use `let*` if needed (it expands to nested `let`s anyway)) I'd really like to help you more, but the reddit's comment box is pretty small. 
Are you trying to say that linked lists are never an appropriate data structure? That's nonsense. Even alists, which I think you're referring to with "its map implementation" are fine data structures. If you're going to throw big O notation around, you should know that O(1) can easily be bigger than O(n). Hash functions and tree operations aren't free any more than list operations.
Looks idiomatic - for Franz Lisp - 25 years ago.
Just for those who are reluctant to open the PDF: it is dated for August 17, 1989, and the first line in the abstract says, "Prolog and Lisp bookmark timings are compared on the VAX 8600."
the terms are from the vacuum tube based 704, not 701: http://en.wikipedia.org/wiki/CAR_and_CDR#Etymology My apologies. Ok, now I don't have the time to really get into point by point rebuttal, my apologies. But let me just be very general here. Lisp was a phenomenal language in the 1950s. It was 30 years ahead of its time; which means it belongs in the 1980s. We're in 2011. I know many respectable people that come out of Harvey Mudd, MIT and Caltech who speak very highly of lisp, but appear to call out blasphemy when I speak of say, Arrows or type polymorphism or cofunctions or other types of fairly impressive language stuff that has been done in the past 50 years. I know that you can do things in assembly, C, Fortran, Lisp, whatever you feel like. But the problem I speak of is the routes of least resistance. What is the route of least resistance when programming in Python for instance? You end up going down a fairly nice path when you do things the easiest way. But in reading lots of lisp code, I've seen people do things that would be really bad practice, if it wasn't for it being in lisp; where lots of things appear to be sanctioned; if not honored. That's what I mean; In the world of lisp, the rules of engagement appear to change. It's not a level playing field any more. I can give numerous examples, but if you don't see it instinctively, I don't know what good they will do unfortunately.
I don't think you can necessarily. I think it was created with the tools and knowledge of the time. People have built on it, for sure. But there comes a time when the old ways just won't do anymore. That's why we have Go and Ruby, Python and Scala, Haskell and Smalltalk, Oberon and C#, Javascript and Erlang. Some of the development of these languages were written to sell software and acquire PhDs, sure. But moreover, they were trying to account for some unfilled void in previous technologies. Surely. Not because the older languages couldn't accomodate the needs; I mean, they are the same point of the Chomsky heirarchy; can solve the same class of problems; sure; but the fundamentals of lisp; the foundational constructs; by which the language is limited by; were solidified; as far as I can see; prior to the invention of the resistor, the file system and the coining of the term "operating system". I cannot expect the fundamental design of lisp to be accomodating to anything after it; even though things have been built upon it. And alas, in about 6 months into a lisp programming exploration I did a few years back; thus was my finding. I just can't honestly view it as a proper solution to modern computing problems.
For instance, these were clunky: * producer/consumer models * udp socket comunication * file locks * semaphores and mutexes * doing a select(2) style call I found each style of invocation fairly awkward and unnatural compared to other languages that were created after say, Edgar Djikstra's 1965 Dining Philosophers paper or Bob Taylor's Arpanet project.
&gt; the terms are from the vacuum tube based 704, not 701: http://en.wikipedia.org/wiki/CAR_and_CDR#Etymology and the term LAMBDA comes from ancient greek... what's your point? Your arrows and typed-lambda calc are from 1940... &gt; now I don't have the time to really get into point by point rebuttal To me that reads the same as "i got nuttin'" ;) &gt; But in reading lots of lisp code, I've seen people do things that would be really bad practice, if it wasn't for it being in lisp; where lots of things appear to be sanctioned; if not honored. That's what I mean; This is all vague handwaving, and also has nothing to do with the Lisp language itself, but rather how people are using it. So this is a social argument, not a technical one.. and people have not changed that much in the last 50 years, so it's not a relevant argument at all. Without getting into a turing tarpit, do you have any decent examples to back any of this BS up? Keep in mind that i also regularly program in Haskell, ML, scheme, ksh and C. I keep up on PL theory, love monads, and can see the utility of static type systems.... yet i choose to work in common lisp... so unlike you, i actually have knowledge of both Lisp (historical and modern) and so called "modern" type systems and languages. Computer science is fun and relevant, but in the end one uses whatever tool is best suited for the job. In my case, that's lisp, and i couldn't give a fuck about your so-called "bad practice", and nor do my clients. 
Indeed these things are not in the ANSI standard (1994, not 1950), but this just means that they are not standardized. Implementations have extensions covering some of these things, and there are good libraries anyway. Not really a problem. 
Especially since Macs are PCs now.
Given how (I assume) he doesn't own any related patents, it would be the height of silliness to pretend he was giving any sort of patent release. The BSD series of licenses is hardly obsolete. A license written short is extremely important, and I'd say far better than a license written long like Apache.
&gt; would be the height of silliness to pretend he was giving any sort of patent release Unadulterated bullcrap. The licensee does not know whether the licensor holds patents on things he is licensing which he can use to attack the licensor later on. He must magically trust him, something which is quite dangerous in this day and age. And furthermore, the licensee may himself further distribute the work to others. These sublicensees down the chain are even more distanced from the original licensor. A good modern license *must* protect the licensee from such things. Licenses without patent releases are unacceptably bad practice.
Great diagram to follow. This should really help improve my lisp language skills.
Someone looks very happy.
- Chicken and SBCL would make better first implementations. - Try ML/Ocaml instead of dylan if you don't like the syntax, although you'd have to be pretty dense to not like the syntax after using it for a bit. - Most Scheme implementations have some sort of non-hygienic macro system. My flowchart: 1. Read the first few chapters of SICP, using Chicken. 2. Read the first half of PCL, using SBCL. 3. Port your PCL code to Chicken, and your SICP code to SBCL. 4. You are now educated enough to make your own decisions, have fun. If at any point you're not having fun, go learn something else. 
LOL -&gt; PCL -&gt; PAIP -&gt; ON Lisp CLISP -&gt; SBCL -&gt; CCL -&gt; LispWorks/ACL -&gt; ... Scheme/Racket might be more useful for Computer Science introduction. For **programming** I would not waste time and start with Common Lisp.
Why SBCL -&gt; CCL?
If you want to learn "Lisp", pick one and stick through with it, all the way to the implementation techniques. Lisps differ, but they all converge in their implementation details and literature (we're all one big happy family in CiteSeer :-) *Except* NewLisp! it's a BASIC dialect with parenthesis that uses the "Lisp" label in false advertising; it's not a Lisp, and it's just as attractive as "Mr T" in drag, after a weekend of heavy boozing. 
Upvoted for "Mr T" in drag.
What you said plus writing *actual code* in that language, whatever it is.
Not sure why liking eval dooms you to newlisp and closes off other languages like Scheme, Clojure and CommonLisp. 
maybe because eval and newlisp share a concept: "if you're using it, you're probably doing it wrong" :)
I'm curious about what makes newLISP not a Lisp. I'm not familiar enough with newLISP to know much about its oddities. 
I don't think there is a clear progression through implementations as each of them has its own scope of applicability. It depends on what kind of programming one is doing.
In CL EVAL is normally used only in specific situations which actually require it -- e.g. writing REPL. People don't use EVAL just because they like it very much. OTOH Kazimir means using EVAL in a normal course of programming _instead_ of macros. Is somebody is such a weirdo that he doesn't understand merits of lexical scoping and compile-time macroexpansion maybe he is better with NewLisp. IIRC NewLisp even has some kind of F-exprs to assist in eval-instead-of-macros scenarios. What I think is really wrong with Kazimir's diagram is that one makes a decision about EVAL before even trying various macro systems. That's like luring people into NewLisp.
See ITA. ;-) My motivation was: * CLISP is used in LOL * SBCL is then a great step forward with optimizations, native code and type inference * CCL is then slightly different since it comes with a GUI and IDE (on Macs and possibly Windows) it is slightly better to use in some areas (for example there is an ARM/Linux/Android port) * LispWorks and ACL come with special stuff and a better IDE * after that point one moves on the the Lisp implementation one likes best - that was the last arc
CLISP is terminal + readline SBCL + SLIME is a big step up CCL + GUI/IDE is a step forward to simple GUIs (on Macs) LispWorks/ACL is another step forward in the direction of application delivery I agree, that it depends on the kind of programming one is doing. I learned Lisp with a simple Scheme on the Mac with editor windows and listener windows and no further stuff...
Ok, so you see it heading towards GUI programming. I'm just not a fan of it, to be honest...
Most of the typical applications I use have a GUI.
I use Racket for **programming**, and Chicken has lots of libraries.
&gt; Most Scheme implementations have some sort of non-hygienic macro system. Or you can roll you own. My flowchart: 1. SICP+MIT/GNU Scheme, learn using just the "base" Scheme tools (lists, car, cdr and making new data structures with them) 2. Meanwhile, learn to use Emacs. 2. Choose a new Scheme implementation (Chicken, Racket, ...), redo something from SICP with it. 3. Learn CL. 4. You are now educated enough to make your own decisions, have fun. If at any point you're not having fun, you need to press the button harder.
While the licensee trusting the licensor argument certainly holds merit (though I am personally fine with the academic honesty inherent in the BSD series), I do not think the chain of sub-licensees does. The copyright notice from the original licensor is required to be reproduced in any derivative work, allowing any user to find and get into contact with the original licensor. Maybe they shouldn't have to. That's certainly a fair position to take. I take the position that that's not a big deal.
[Chicken](http://www.call-cc.org/)? That's the first time I've even heard of it. Why, in your opinion, would it be better for a beginner? 
anvsdt said it, but it deserves top level mention: Step 0 - learn emacs. :/
I recommend the following for Scheme (each step makes the next one easier): 1. The Little Schemer 2. How To Design Programs [working through atleast 80% of the problems] 3. The Seasoned Schemer 4. SICP [working through as many of the problems as humanely possible]. For common lisp, based on personal experience it'd be: 1. Land of Lisp 2. Successful Lisp or ANSI Common Lisp (for more practice on the "basic stuff") 3. Practical Common Lisp (doing the projects and extending them) 4. On Lisp and PAIP. going slow, stopping when it becomes overwhelming and revisiting as necessary. 5. [I haven't reached this step] Art of metaobject protocol ? Lisp in small pieces? building problem solvers?
Very Nice! I'm sure having a better look at this later tonight. Thanks for sharing.
"Lisp in Small Pieces" is that advanced?
awesome stuff! thanks for sharing!
Upvoted for interest. I know it's fully interpreted, and makes some odd decisions about cons cells, but that's about it.
Really nice! Native monads will be really handy. Now how about pattern matching? ;)
(I hope someone who has read the book would chime in) I lumped it there because it looked specialized (building lisp interpreters and compilers) compared to the other books. It may not be any more difficult than PAIP, but I would still recommend PAIP first just to see Norvig's idiomatic code and awesome projects.
I'm not a seasoned lisper, but I have to say: I'm reading Lisp in Small Pieces and it is pure awesome. I've read a third of the book and every chapter makes me learn something completely new about how to think about programming languages. It's mostly aimed towards lisp implementors, though.
Prof Sussman had a pretty fantastic unification library in the class. Maybe that could just be incorporated in? If all else fails, a port of the unification library from PAIP would be easily doable.
Some kind of sequence abstraction over the datatype collections (list, vectors, rb-trees, hashmaps and your suffix trees) would be very nice. Maybe the STL, clojure's collections and scala's collections libraries could be a source of inspiration?
How does it handle mzero, mplus, etc?
I agree, and it shouldn't be hard to do either. Didn't we implement something similar in 6.945 (Problem Set 2 I think)?
I think something similar to Python's tuple unpacking should be easy to implement as a special pattern-matching "let". For example: (plet (((x . y) coordinates)) ; x is bound to (car coordinates) ; y is bound to (cdr coordinates) ....) Pattern matching on function arguments - that's the harder part. I might implement it if there's enough interest :-)
At the moment the library only supports "vanilla" monads defined through &gt;&gt;= and return. mzero and mplus are a part of MonadPlus in Haskell, aren't they?
Only with eval does the word probably belong in that sentence.
Yeah i don't think it'll be too difficult either. The main difficulties are in picking proper names and defining good abstractions (that are still performance sensitive... e.g. ops on vectors should take into account the O(1) random access etc). I think in both cases taking a look at the other libraries might be a good idea (especially STL). How difficult would it be to add reader macro support to mit scheme? One thing I'm totally spoiled for after using python and clojure are literals for data types e.g. [1 2 3] for a vector with those 3 items {a 1 b 2 c 3} for a mapping from a -&gt; 1, b -&gt; 2, and c -&gt; 3 #{a b c} for a hash-set with a, b, and c
What do you think is the "level" of the book? What books on lisp/scheme did you read before it? 
&gt; MonadPlus What. Wait. No, you're telling me that I have thought **every** possible way to bind arbitrary functions to arbitrary functions defined elsewhere in a struct when I could just define an obvious ``MonadPlus''â€½ *sigh* I feel stupid. I have nothing more to say other than good job, now.
Better to sit down and write some programs.
Why does this seem so dreadful to you? Why is it worse than learning (say) Eclipse for Java? (sincere question from clueless emacs user)
CCL with Objective-C bridge if you're on a mac. If you don't need widgets, just a window and a place to draw, Lispbuilder-SDL.
I've never used Eclipse, so I don't know how difficult it is to learn. But I have tried to learn emacs multiple times (because I'm learning lisp...slowly), and every time I have to stop. Two things get me. 1) Supposedly once you know emacs, you'll be able to edit code faster. But then right off the bat, doing something like "save a file" is 4 key presses. I'm sure people just get used to it, but to new users, stuff like this is decidedly a backwards step. 2) Worse is the general attitude that "emacs is super powerful - but you have to work at it." imo, it shouldn't be difficult to learn how to use a text editor. There is no reason why emacs couldn't be made friendlier for newcomers. The last time I tried to learn emacs I had to code my own settings to turn off auto-tabbing. There wasn't just a setting for it, like every other editor would have. But you know what *was* right off the menu? A functional version of Tetris - just to show off how powerful the editor is. Talk about messed up priorities. 2a) sadly, because of this "you have to earn it" attitude, there is not much effort put into usability. This badge of pride that many emacs users have about their leet editor is also what gives their editor a limited audience, despite (ironically) how strongly the need to evangelize emacs. Personally, I love the concept of emacs - an editor that's programmable and introspective. I just wish someone would write a lisp based editor with modern usability concerns in mind, and without the historical/community baggage. Sorry for the rant. :) Hope that answered your question. 
The [eggs](http://wiki.call-cc.org/eggs) system (pre-packaged libraries) is pretty awesome as is the [Gazette](http://gazette.call-cc.org). The Chicken community is pretty active, and there is quite a bit of activity going on. I think `csc` (the chicken scheme compiler) might still be a bit complex for a complete beginner, but most people get the hang of it.
I've always thought of it as a Logo-ish Lisp: make "s (sum 1 2 3 4) (set 's (+ 1 2 3 4)) i.e. it's a Lisp, but doesn't have as many special forms, has odd ideas about memory management &amp; what not, but it's still a lisp.
btw, I should also say that I honestly believe that one of the biggest problems for Lisp the language is that its best editor is emacs. I really think that holds the language back. Emacs fanbois will scoff, but really, if lisp had a Visual Studio, more people would get into it and get into it faster.
And could you compare and contrast what is available for Chicken with what is available for Racket/PLT (including "PLaneT")? It seems to me that "Anon_C" made that statement with a view toward learning Scheme with the SICP book.
Well, maybe we should bug the folks at [JetBrains](http://jetbrains.com) to design a Lisp suite!
So where is the full tour?
[Here you go](http://www.mediafire.com/?truph5zaudjdvp5).
Thank you!
You do not need a real parser for format which is that simple. You "parser" would be just as complex as your `parse-blockmap-list` function. E.g. (defun read-map (s) (let (dim-x dim-y layers...) (loop for block-name = (read s) do (ecase (find-symbol (string-upcase block-name) :keyword) (:dimensions (setf dim-x (read s) dim-y (read s))) (:layer (loop for x from 1 to dim-x nconcing (loop for y from 1 to dim-y collecting (read s)))) And so on. You could profit from S-expressions if you were using plist directly. Is `(map-name map)` really that better than `(getf map 'name)`? Great thing about lists (and S-expressions) is that you can use them as as-hoc data structures directly.
Thanks!
For learning the language with SICP both schemes are fine and in my biased view towards chicken both have everything you need for that. On the library aspect Racket may be ahead, I haven't checked lately. You will have to decide yourself if the existing libs fit your needs. The FFI to C is easier in chicken which makes writing new bindings a bliss and fast.
&gt; doing something like "save a file" is 4 key presses. I do C-x C-s (three keystrokes) even when saving something in DrRacket, now. C-x C-s and C-x C-f are few of the keybinds that emacs got right. &gt; I just wish someone would write a lisp based editor with modern usability concerns in mind, and without the historical/community baggage. I wish the same too.
I learned emacs in ignorance of its reputation. I picked it up randomly when Eclipse wasn't available. It never struck me as "something I had to work at" or "something I had to earn". It was just "the text editor with wonky shortcuts on the Linux box at work." I guess me and emacs were just made for each other.
You start off with a bunch of defconstant forms. This smells to me like C/Java style, where you don't have symbols and must make do with integers etc. Without having studied your program in detail, I'd say keep state in symbolic form, and if need be (for display) convert it only at the last minute. (There are the usual exceptions, such as optimizations etc.)
Thanks. I'm not terribly experienced with CL yet, and this was targeted at an audience that doesn't use it at all, which is why I opted for a straight list instead of plists. :)
Use `error` instead of printing error messages. There is no function called `exit` in the standard. I'm guessing you're using Clisp? If so, _please_ don't kill my lisp image. Instead, signal that I have made an error and let me correct it.
Well, actually your file format is already an alist (the cdr is, anyway). I don't know what the equivalent in Common Lisp is, but in Scheme to get the name it would be: (cadr (assoc 'name (cdr map)))
It is exactly same in CL.
Actually what you have is a variation of alist. You can use ASSOC to access it, but it is not very convenient, as usually you need (CDR (ASSOC 'name alist)). If you use library _alexandria_ it has convenience function `assoc-value` to do this. So: (defparameter *map-alist* '((name "foo") (direction -1 0 1))) (import 'alexandria:assoc-value) (assoc-value *map-alist* 'name) =&gt; ("foo") (assoc-value *map-alist* 'direction) =&gt; (-1 0 1) So it "just works" (with your existing list structure) for list values and you need additional FIRST to get singular ones. Or you could write them as `(name . "The Blocky River")` in file, but that looks a bit weird. As for plists, file format for them would be simplier, actually: dimensions (12 12) num-layers 2 background "cloudy-sky.png" light-color "#D1AE4D" light-direction "-0.1212 -0.4848 0.4848" To read this either wrap it into parentheses and do READ just once or read it in a loop: (loop with eof = #:eof for o = (read s nil eof) until (eq o eof) collect o) So, as you see, it is very simple you make your data structure either alist or plist, and once you've done it you can use variety of standard tools to work with them. And, btw, on your LOOP code: (loop for item in fields do (let ((key (first item)) (value (second item))) There is a better way to do this. To work with alist use destructuring: (loop for (key . value) in fields do ... With plists you also need destructuring, but it is more quirky (loop for (key value) on fields by #'cddr
I [pasted a version of Tic-Tac-Toe](http://commonlisp.pastebin.com/7NHYG3Wn) I wrote the 2 days after Christmas. I'd argue it's a bit more idiomatic and might prove instructive. Your indentation is off in places and the use of defconstants isn't very lispy. I'm still on the fence about whether my use of them was reasonable/defensible. You also never should need to quote nil. It's just "nil". For a first lisp program it's not bad though, I've seen much worse. I would try to use fewer progns and **all-equal**/**get-winner** definitely need a rewrite though that may be less of a language issue and more of a general approach thing. See my **game-over-p** and **three-in-a-row-p** functions. **prompt-read** and **read-int** look pretty good to me on the other hand. Note the difference between indentation in your PROGNs in **game-loop** and **get-move**. Pick one style and stick to it under all but the most exceptional circumstances. I'd also replace the cond in pretty-print with (when (condition) ...). Also, I'm not sure why you bother to establish cell in a LET in **get-move**. You could just return the result of **prompt-for-cell** or **ai-move** there. These are just some first random thoughts. Feel free to disregard me or ask for more. :)
It's easier to answer how if you explain why you want to do it.
For example, if the primary goal is to find out if some element of the list is nil, I'd use (some #'null list)
If by any chance you use a Mac, do yourself a favor and go grab [Aquamacs](http://aquamacs.org/). You can use it on a Mac with all of your normal shortcut keys (Command-S to save, etc) right out the gate, and just learn the other stuff as necessary. Plus it comes with a bunch of extra bells and whistles already installed/enabled. Which actually annoys me at times because I prefer some alternatives (such as html-mode vs. html-helper-mode), but oh well. :)
I probably wouldn't have made cycle mutate the board, and written something like this. (defun main () (format-win-message (do ((board (make-board) (cycle board))) ((game-over-p board) (winner board)) (print-board))) The advantage would be that you could keep a set of board states around for testing with cycle without messing them up, and you could easily collect a series of board states if you need some history.
Just out of curiosity, if you are pulling from a database with foreign keys that are integers, and your program is facing case statement situations based on the foreign key, is there a better way using symbols rather than defconstants? 
You also might be interested in [the code review](http://codereview.stackexchange.com) stack exchange site, which is still in the beta phase and was started with just this sort of question in mind.
I don't think there's one way that is always "better", it all depends so much on the program and data. For some cases it makes sense to convert to (and from) symbols, others not so much. I'd also advise to use defparameter rather than defconstant, in general.
I'd use an alist and assq.
Put a **defpackage** and **in-package** ontop, with some exports. (But you probably know that) The marks and the players seem mixed up. Either make both convenient at the same time, by using keywords **:x** and **:.** (Last one looks like it could be nasty though.) Or give users names some other way, and then have a final function map that to the shown 'field'. Also, did you kill all the warnings?(Not for me running it on SBCL) I personally prefer to do so. I got crazy and wrote [a tictactoe how i'd do it](http://commonlisp.pastebin.com/BfjDBSJn)(94 lines, i win in brevity :p), the (defun name (..stuff..) (lambda (..args..) ...)) thing is often nice to do, or alternatively make a class and ten use it a lot like it is a lambda made like that, (edit: i mean, use it only with a funcall like method and no accessing slots otherwise) with only exception the **initiate-instance** methods, which may use earlier defined slots when deriving. Made heavy use of entering functions to make things flexible. And humans are actually functions entered into the game function :).Not 100% happy, it should have an arbitrary amount of dimensions and cleverer bots :) and it is largely written imperatively, though i don't find that latter all too bad if it is contained. Oh that should export **human-player**, not **human-input** ... ah well.
 (position nil sequence) 
I guess **member** should be efficient. I don't think it is costly or anything to return the **cdr** of the position that has a match for the **cadr**. It is essentially just returning a pointer, though i am not sure what the garbage collector has to do.(If the compiler can see you're discarding it that shouldn't matter) If you just want to know if it is in there, might be best to look at the **null** of it. (defun in-list (val list &amp;key (test #'eql)) (not (null (member val list)))
Tbh i don't see the point. Might it not be better to do: (defvar *map*) (defmacro map (&amp;body body) `(let ((*map* (init-map))) ;Perhaps some additional (special) variables here to keep track of stuff.(Like number of layers) ,@body *map*)) And then define functions to alter the map. It can be 'just' lisp code. (More like cl-cairo2's approach)
Two reasons: * I'm not terribly experienced with CL yet * My target audience probably doesn't use it at all.
I'm not sure. I didn't get many books on lisp to learn it (and I'm still learning). I just trusted a somewhat solid knowledge of computer science topics, a few articles I read about lambda calculus and my experience with a gazillion of programming languages. But I'm in no way a "proficient" lisp programmer, just a beginner. I've read a bit of SICP and watched about half the lectures on the MIT Courseware and that's about it. I love language design and implementation, though, and I've read a big chunk of Anatomy of Lisp, a couple chapters of Art of Meta Object Protocol (just enough to find out I need to learn more about lisp implementations) and then now I'm reading L.i.S.P. Considering the books on "learning" a language that I've seen for various programming languages, I'd definitely put L.i.S.P in the "advanced learning" shelf, but I might be completely off track when it comes to the literacture on lisp, since I just don't know it very well. **TL;DR:** I'm not that much of an authoritative source of opinion on this, but I'd guess it's fairly advanced stuff.
Cool, thanks.
Hmm. In fact...
Inaimathi! 
Hah, I just saw your post (on my front page) and came here to post a link.
By the way, when I try to register on the new site, I get this error message: &gt; Unable to log in with your OpenID provider: &gt; The following required parameters were missing from the DotNetOpenAuth.OpenId.Messages.CheckAuthenticationResponse message: &gt; is_valid A search on Meta.SO shows no question with that particular error. I need to go to bed, so I will check again in the morning and post a question if it still doesn't work.
Funny story: After posting this link, I went over to codereview.SE to see whether there were any new lisp-related questions. It turns out there *is* no lisp tag yet (the closest is elisp, which is only there because I submitted my etags functions on day one of the private beta). It's feeling even lonelier now. And this story isn't funny at all, it's just depressing.
There is also http://paste.lisp.org/ and for discussion there is #lisp and comp.lang.lisp. 
I wanted to be upset with the quality and utility of this answer, but given the question, I'll give it to you.
Why is it depressing? There are established venues for this already. c.l.l, #lisp, paste. I think one of the most appealing things about Lisp is that its community doesn't feel the need to jump all over every new mode of communication. I think the users tend to be more cautious. That said, when places are of obvious value, you see them crawl out from their dark caves in the deepest oceanic caverns. See Reddit, StackOverflow.
From [here](http://www.reddit.com/r/programming/comments/fah8p/).
Fair, but I'm new at this and still not very good at cave-spotting. With a reserved community, it's very easy to get the impression that I'm one of ~10 people that actually cares about using Lisp. Which is depressing, if unjustified.
Don't worry about it. When the stars were last in the correct alignment and we all gathered, there were at least 20 of us. But seriously, check out c.l.l. And ignore Xah Lee.
Geez, did you even look?
I don't really like NewLisp approach (like, at all). But there is probably something left to say about fexprs and eval. Another way to look at it is that with macros you construct a new list (or form if you will) that will be IMPLICITLY evaluated. In the traditional way, this lisp is eval'ed in the dynamic environment of the macro call; in the scheme/hygienic way, each identifier is tracked with info about it's origin and evaluated in that environment. When you use fexprs you are responsible for EXPLICITLY eval'ing each part in the environment you want. I think John Shutt nailed this down with his Kernel Language, which unlike NewLisp, is statically scoped but has first class environments. There's even a doctoral dissertation (if anybody is so inclined) but alas no implementation but a simple,incomplete one in scheme. I was toying with the idea of writing something in the spirit of Peter Michaux scheme interpreter, but I am not sure there is sufficient interest in fexprs anymore...
A funny thing. Disapproval for greeting someone I haven't seen ~~in a while~~on here before (from Pr.SE).
Seems like a shallow mashup to me. Where is the relationship between lisp and kabbalah?
Kernel rules, i'm a big fan of the design and i play around with implementing it for fun.
Whoa, it's Zach! I wanted to say thanks for RoflBot; I've been using it for quite some time---then two days ago I (re?)discovered the site was done in Lisp!
Hat-trick! "Captain, the happies are closing in!" "Downvote them!"
in a few places you use 'nil, and nil works just fine there. In get-move I think you can get rid of the cell variable. If you think about your function as a tree, the leaf nodes on that tree are the options for the return value. The lisp indentation is designed to accentuate the tree nature of lisp code. In get-move, the leaf nodes all (setf cell something), so you can just do the "something" part, no need to save it in a variable. I frequently write a bunch of code and in the development process I usually have a bunch of useless assignments like that to strip out when things work. In all-equal, another way to write "(not (equal nil a))" is "a". A frequent idiom is something like: "(and a (some-calculation a))" to guard against "a" being nil. I didn't look too closely, but you seem to use all-equal in with (nth X board) a lot, it might make sense to put that inside all-equal; so you'd call: (all-equal board 4 5 6) instead of: (all-equal (nth 4 board) (nth 5 board) (nth 6 board) I saw one instance of: (if X Y nil) That is usually written as: (when X Y) Overall, very nice start! Way better than my first attempt, in which I was trying to write C# in lisp.
The UI is a hunchentoot web app. Me like :-) 
Thanking Xach for roflbot is like thanking George Clooney for Batman and Robin. 
Maybe that is your opinion, but I found it useful and fun.
Why does it have to be in lisp? looks like he wants help on a research project, I don't see any reason why he would care what language it's in.
Because Jeff Shrager is a long-time Lisper and has lots of Lisp projects done. I would expect that the infrastructure around is also Lisp-based. I guess he likes Lisp a lot. ;-) Possibly he also wants the research development project to have some interesting results, too. See his vita: http://nostoc.stanford.edu/jeff/personal/vita/vita.html 
Is this presentation worth watching?
position works fine imo. The reason is that nil can be in any position of the list right? That means that, in the worst case scenario, you'll have an O(n) algorithm (because, to be sure, you have to check *at most* every item in the list). It can't get better than that (worst case). Therefore, a worst-case algorithm like position or member is your best bet.
Dylan, so people can argue "Lisp or not", but, Network Night Vision does some pretty interesting stuff in this area, is designed to be safe / secure with the decoding and is under a BSD-like license: http://nnv.dylan-user.org/ 
But maybe he's not occidental, and thus you should read it right-to-left.
I know this smacks of typical lisp snobbery, but why would I want to make "really deep changes to the language?" It would just lead to problems unless handled correctly. Besides, `caml4p` is a preprocessor; what's to stop someone from doing something of the same for a Lisp dialect? Make some changes to sbcl &amp; add a `-pp` ala O'Caml and you too can make "really deep changes" to the language without relying on reader macros, or the like. *edit*: to add to what I said &amp; not sound like a total douche, what I mean is that I don't see what making "really deep changes" to the language gets you other than confusion. I think there's a reason why Camlp4 is a separate program that outputs pure O'Caml on the other side, which is to avoid two individuals making mutually exclusive "really deep changes." It's the same issue with relying on reader macros: if two people add reader syntax for `{}` that conflict, and you attempt to use those two files, there would be problems, unless handled gently. **tl;dr**: not too much different. 
&gt; They change the scanner and parser of the language, Reader macros. &gt; so you can really make deep changes to the language Plain macros.
When I did a search and found out it was a separate package (and saw the word "preprocessor", although I don't know much), it seemed like the kind of thing you could do to a given language given a powerful-enough library. And yes, "really deep changes" sounded like a nice theoretical idea (write a new language---but then why use this one in the first place?), but it seemed like it would create problems.
And then there's Perl 6. Just saying.
I don't know much about it except for this (see the first link): http://programmers.stackexchange.com/questions/7806/what-would-be-a-few-ideas-concepts-from-programming-that-i-can-have-on-paper-and/7807#7807 I have some more that I need to add once I start running FireFox again and work through my tabs.
Camlp4 macros don't compose well. If you have two Camlp4 extensions, there is no guarantee that you can use both at once. Lisp macros on the other hand compose like libraries. You pick and choose which libraries of macros you want and how many, with no restriction. This feature is the key reason why there is no "no-parens" version of Lisp. If you get rid of the parentheses, you lose composable macros. When you have composable macros, you can build [the language's entire object system](http://docs.racket-lang.org/reference/mzlib_class.html?q=new) out of macros, and the result is completely transparent. Nobody notices that they are not native. The equivalent of Camlp4 in the Lisp world is called "reader macro". When reader macros are combined with normal macros, you get a very [expedient way of defining wholly new languages](http://download.plt-scheme.org/doc/html/scribble/getting-started.html). 
&gt; When I did a search and found out it was a separate package (and saw the word "preprocessor", although I don't know much), it seemed like the kind of thing you could do to a given language given a powerful-enough library. Exactly; I don't see that it's something wholly beyond what lisp has, or any language really, save for that lisp is quite close to it's AST. &gt; And yes, "really deep changes" sounded like a nice theoretical idea (write a new language---but then why use this one in the first place?), but it seemed like it would create problems. Well, reader macros can create problems, but they have a place, just like Camlp4, but it's not some "wholly unrealized truth" that lisp doesn't have (or Haskell or anything for that matter). 
Thanks. :) I've got DrRacket in another window, I'm working through the newbie guides.
So, our conclusion: **Onward to Lisp!**
Perl 6 lets you define new infix, prefix, postfix, circumfix (e.g. [something] would be circumfix:&lt;[ ]&gt;()), postfix-circumfix (something[x] is postcircumfix:&lt;[ ]&gt;($x)) and maybe other that I don't remember. Other than that, it also as *meta* operators, *=, +=, -= are all metaoperators, the Z= metaoperator. Then, it also has macros, that work on the AST, unparsed source, etc. I don't really know how they work, as rakudo still doesn't implement them. So, yeah, it's perl, but messier. I'll love it.
Whoa, you read my mind! Ignore my other comment. That table of operators seems like total *overkill*, though.
I think that the thing more close to a reader macro in Racket would be a [readtable](http://docs.racket-lang.org/reference/readtables.html), but it doesn't have all the CL's sugar (e.g. read-delimited-list, even though it's trivial to implement)
&gt; I've got DrRacket in another window, I'm working through the newbie guides. Scheme (and, erm Racket) do not have reader macros, neither does Clojure. Out of the "popular" Lisps, only CL has them. Edit: Ok, Racket seems to have something comparable.
http://docs.racket-lang.org/reference/readtables.html
Two impressive examples from teh PLaneT: * http://planet.racket-lang.org/package-source/chongkai/sml.plt/1/6/planet-docs/ml/index.html * http://planet.racket-lang.org/package-source/jaymccarthy/c.plt/1/1/planet-docs/c/index.html
&lt;tongue_in_cheek&gt; Sometimes a call is made to use the best tool for the job. &lt;/tongue_in_cheek&gt;
Well, that's *my* conclusion; there's nothing wrong with other languages having the same facilities, just don't knock something until you've tried it :D
Alternative to extending the language is building complex frameworks and libraries that use conventions and special data formats to do the same thing that macros do (all those Java frameworks, beans, setters and getters are good example of this). These frameworks and conventions add layer of complexity over the language just like extending the language lisp style. Macros work well with bottom up programming. You build up your language towards your problem and not only try to redefine your problem towards your language. Extending the language using macros and meta-object protocols etc. are more tool for system architect than for code monkey that tries to solve one specific thing today. Imagine being software architect and being able to write code that defines the architecture. Another good example is language extensions that don't require involvement from language implementors. See for example [AspectL and ContextL](http://common-lisp.net/project/closer/aspectl.html), Common Lisp libraries that add aspect oriented and context oriented programming paradigms in language as libraries. 
I have no issue with macros or syntax, but I think *reader macros* can cause issues, which was my (most likely poorly worded) point previously.
Anything that completely alters the structure of a language can cause issues, but can also be extremely useful. With great powers comes great responsibility.
Thanks! Re OSX and emacs, I have found [this](http://emacsformacosx.com/) to be ever so much more like the real thing.
I think that *is* the real thing. :) I prefer Aquamacs solely because it acts like a normal OS X application with regards to frames: I can close every one without closing the entirely application.
They look great, thanks for putting them up!
I notice you chose SBCL for OSX and Linux, but CLISP for Windows. CLISP doesn't support threads on Windows, so things like Hunchentoot^* don't work properly. I'd give CCL a look. EDIT: To be clear, Hunchentoot doesn't work at all, last I checked.
You're right. I went with CLISP because I thought it was the easier one to install and it doesn't have the 32/64 bit confusion that CCL does on Windows. CCL is probably the better choice though. 
Wow, down to -6 for asking a reasonable question.
The latest trunk release of CCL allows 32-bit versions to run on 64-bit Windows.
Does emacs --daemon work on OSX? If so that would also act similar to the behaviour you describe. It just makes emacs hang out in the background as a daemon (as you might expect) and lets you open up and close clients to interact with your persistent emacs session.
Do you not use GetThreadContext on Windows? If so, how'd you get around the bug in that on WoW64 (described on http://en.wikipedia.org/wiki/WoW64)?
I'm not a windows programmer: I have no idea how they do it. Just reporting what I read on the mailing list this evening.
Ah, another proof of the Kazimir Effect! ("downvoting forces arising from a newlisped field"). Any Patient and Knowledgeable Lisper care to comment about this? (the linked post, I mean, not the effect)
His arguments have merit only if you ignore matters of pragmatism and engineering trade-offs. Take his first point, which states that Lisp evaluates functions at once, while the lambda-calculus beta-reduction only replaces variables with their values within the body, then stops: "*; Because of that, in general case, one applies reductions many times to achieve similar effect. How many times? Typically, until further reduction is impossible*". Riiight. Because Lisp is a programming *language*, not a programming *formalism*. They both produce the same value for the same expression, except one does it in increments (corresponding with the small-step operational semantics) while the other does it one go (big-step operational semantics) But the two are equivalent, and proven to be so. (see compare this to MACROXPAND-1 vs MACROEXPAND; you can rewrite the later with the former) His next argument (4.1) is really not an argument but a statement: "*Lambda-calculus is not an algorithm. It is "formal system". One who performs reductions - human or computer - can pick order by any criteria.*" Next (4.2): "*Lisp evaluation strategy is not best for lambda-calculus*". This boils down to 'non-strict evaluation is better'. Debates on eager vs lazy evaluation are very popular and the matter has been well studied. Nothing wrong with having an opinion. In 4.3 Look at this confusion: *"In Lisp, function, like [snip] if valuated is either evaluated to some "compiled value", i.e. it is not S-expression any more"* It IS an s-expression, in fact, it's an atom. He doesn't seem to accept functions as atoms, and/or atoms as s-expressions. Then .. "*or evaluates to itself, as in Newlisp*" In NewLisp, a function is a list consisting of its its body, unevaluated. So he considers this an "s-expression", because it's a list. This is where he loses the plot, the fun part. Remember how above he argued for the lambda-calculus model of small-step evaluation? Here he is, arguing against it because that's how it's done in Lisp (wat?!) "*2. In Lisp, result of the evaluation of the S-expression is frequently ; in form that allows further evaluation. ; ; ((lambda(x)(list '+ 1 2 x)) 3) =&gt; '(+ 1 2 3) ; ; Obviously, this form can be evaluated further. But, it is ; not evaluated, except if explicitly ; ;*" 
According to [his blog post](http://mihai.bazon.net/blog/uglifyjs-a-js-parser-compressor-beautifier), Mihai ported [parse-js](http://marijnhaverbeke.nl/parse-js/) to Javascript to facilitate his work in UglifyJS. Now coming full-circle, he's ported UglifyJS to Common Lisp. [jQuery now uses UglifyJS in their build process](https://github.com/jquery/jquery/pull/173)
Usually you don't make deep changes, for many people lisp macros are just for convenience, just keeping to the structure of higher order functions, using some LETs, LABELS, for you, putting some slots on symbolmacros. With some subset of these macros, with some parser, you can make the rest of the stuff look a bit C-like (Or better, ML/Haskell-like with SETF added) Inconvenient to get what the arguments are of a function. [function-lambda-expression](http://www.lispworks.com/documentation/HyperSpec/Body/f_fn_lam.htm#function-lambda-expression) doesn't always get you the information you need.(like for polish notation) (Can hardly believe i haven't noticed this function earlier.) Other implementations than SBCL might give more information. Strangely SBCL *does* give the information from DESCRIBE.. Another reason for macros is that we simply dont want the language to impose on us.
I don't think macros (or my preferred, syntax) have any real issues, other than abuse (use of macros/syntax where a function would suffice, or in a way that could be better served by existing macros/syntax, &amp;c.). The only issue I have with *reader* macros is that common things like `{}` could be over-ridden by two different packages that you're attempting to use; as other's have said, it's power vs. responsibility. **tl;dr**: yes, I agree with you, I just don't like *reader* macros as much as I like normal macros &amp; the rest of the language.
Sorry, i must admit i misread you completely due to my fault.
No worries, happens to everyone at one point or another.
Just a reminder to those who might not know, Summer of Code is location-independent and all communication is done online. As far as I could tell last year there weren't any lisp projects so it'd be pretty cool if it worked this year.
Per popular request :-) You can grab the latest version on GitHub: [Scheme Power Tools](https://github.com/mpacula/Scheme-Power-Tools)
Have you heard about Racket?
Some might get a kick out of this: &gt; ...we were instructed to port a very concise, elegant (if rather inefficient) version of Quicksort from a bizarre obscure programming language called Haskell.... From the author's comment below: &gt; The second way this implementation should be improved for a production system is to determine which sublist is shorter and which is longer, and make sure that the shorter one is done first and the longer one last, to take advantage of Lisp's ability to unwind tail recursion. It has been shown that this significantly reduces the depth of the recursion that is necessary â€” without bothering to write iterative code. &gt; Oh how I love Lisp!
1. It isn't quicksort. Quicksort should work in-place. This is bastard version useful only for illustrative purposes. If you want sort algorithm which is designed to work on lists use mergesort. 2. Beautiful part of implementation is that it uses remove-if and remove-if-not together with a closure. So it is, basically, a combination of power of higher-order functions and simplicity of singly-linked lists. But code is not beautiful at all. lis? car? cdr? Are you programming Lisp like in 60s? I'd write it [like this](http://paste.lisp.org/display/119331).
But Racket libraries are not portable between Schemes. But there are Chicken eggs.
Usually there is a pretty tight deadline between such an announcement, and needing to get the proposal for the mentoring structure to GOOG. Any idea what this deadline will be this year? 
I found your version much more readable and not necessarily for the lack of CAR and CDR. It is amazing what happens when your eyes are trained to read real words. lis? r? x? a? fn? This is what happens when you mix Lisp (or other languages) with Fortran, right?
Cool :) Does it support pattern matching within structures? I've found this to be incredibly useful in erlang. For example, suppose you have a struct "coords" which has x and y fields. Then in erlang, you can say: #coords({X = 10}) to match those structs where X = 10. Another request would be to allow something like this to happen: (?list = (?head . ?tail)) (with better syntax). The goal is to match head and tail and then call the whole thing "list".
This whole thing looks like a troll.
My [Standard Prelude](http://programmingpraxis.com/standard-prelude/pattern-matching) includes a simple version of pattern matching on lists.
My [Standard Prelude](http://programmingpraxis.com/standard-prelude/#pattern-matching) includes a simple version of pattern matching on lists.
I'm glad you like it! :-) As for structures, aren't they just an abstraction over lists? If so, you can use list patterns.
I must admit I haven't heard of Standard Prelude, but it seems to have a lot of great things. Good effort! I like the simplicity of your pattern matcher, but I think the one in SPT is a bit more featured. It supports things like pattern-directed dispatch, which (at least for me) makes pattern matching particularly useful. 
I'm not sure how it's defined in MIT scheme, but ~~in racket they're abstractions over vector.~~ Edit: I was wrong: see SamTH's reply
Here's the timeline: http://www.google-melange.com/document/show/gsoc_program/google/gsoc2011/timeline The FAQ describes how to apply: http://www.google-melange.com/document/show/gsoc_program/google/gsoc2011/faqs#applying
thanks, maciej! This is great!
It bugs me that the site uses "Common Lisp" to describe this language.
So, is this Common Lisp or yet another JVM language? *edit* Ok, I read some of the examples from the site, how is supposed to be (Common) Lisp? Because of `stringp`?
&gt; This feature is the key reason why there is no "no-parens" version of Lisp. Not true. See Dylan &amp; David Moon's PLOT.
If you look into the sources you can see that it tries hard to be one. The examples on the site mostly show implementation specific extensions, so they are a bit misleading. It is almost completely implemented in Java, with macros and some functions defined in 15 Lisp files. Apparently it compiles to a self defined byte code and interprets that. I haven't tried it, because there is no REPL! At least I could not find one. ABCL grew from a scripting language for the J editor into being a Common Lisp as well, so let's see. 
It's annoying how there's extremely little of what'd pass as an actual *description* of the thing, as opposed to recipes for specific situations. Such as an overview of the language, what it is based on (implementation-wise), maturity level and the (in?)compatibilty with Common Lisp.
I've looked through the sources, and I'd love to try to explore the extent to which it is CL-like at a REPL, but yeah, no REPL. Also, using literal tabs to indent Lisp code makes it hard to read. At least the close-parens aren't on their own lines...
&gt; car? cdr? Are you programming Lisp like in 60s? What's wrong with car/cdr, I use them everyday. I'd write it [like this](http://paste.lisp.org/display/119359), instead. (no, I'm not an Haskeller)
Usual CL procedures and macros seems to work (including loop) as do packages and conditions. Unfortunately, it runs very slow, 20~ times slower than interpreted ABCL.
Why not write such an interface for ABCL instead? ABCL is a common lisp. ABCL runs on the JVM.
Perhaps lispers ought to stop writing lisp and start writing some re-usable code for other things.
This was a shock -- this is the developer's example of the recommended way to run code: FileReader reader = null; try { reader = new FileReader("test.lisp"); engine.eval(reader); } catch (Exception e) { // handle error } finally { if (reader != null) { try { // the Reader object is never closed by the engine. reader.close(); } catch (Exception e) { } } } Really? You have to write your own java method to read in the file, and then eval it, 'cause there's no built-in way to do so? And there are empty catch blocks? And the caught exception is of type *Exception*? I was all set to comment how this was definitely Common Lisp-influenced, what with long names like *java-class-declared-method*, but this is insane. And on the [Getting Started](http://www.longino.com.br/article.html?file=getting_started) page, the only lisp is two lines of *defun*s within strings in Java code: engine.eval("(defun some-function (x y) (+ x y))"); engine.eval("(defun another-function (x y) (+ x y))"); I'm not sure what the goal of this project is, but it doesn't appear to make it very easy to write Lisp on the JVM.
What is the deal with JVM based languages? What is the appeal?
Having interoperability with scalable turnkey synergetic robust enterprise-grade solutions. Or masochism.
&gt; Apparently it compiles to a self defined byte code and interprets that. Wait, it is VM running on top of JVM on top of physical machine? We need to go deeper!
I used ABCL for one project because it gave me access to Jena Java library which implements triple store and a query language. I've found no such thing for vanilla Lisp. (Aside from Allegro Graph which costs a lot...)
I don't know what any of that means, except turnkey, which means "Not my problem any more."
 ) ) ) ) ) ) Oh my, the beauty.
I tried it with Clojure. It's definitely masochism.
Upvoted for Clojure hate.
[Wilbur](http://wilbur-rdf.sourceforge.net/), though it has unfortunately been all but abandoned. 
Yep I know about it, but I work with large quantities of data, so I need data to sit in database, and that's not what Wilbur does (AFAIK).
True enough: Wilbur does not use an external triple store.
&gt; (new)Lisp Uhm...
Where can I read more about the problems/social controversy with newLisp?
**A B S T R A C T I O N**
Beginners can't really deal with the dynamic scoping, CL is cross platform and Scheme is easy, small and clean. But oh well, de gustibus non disputandum est.
&gt; Many (Common) Lispers get aggressive when its mentioned, probably because newLisp has a "Lisp" in the name but by lacking many common Lisp features Less its lack of features than its design decisions. Dynamic scope? "Oh, but you can hack around it with this other feature" doesn't make it less a terrible idea. That's the one that really gets me. The marketing is icky too. For example: &gt; I will focus on the most modern and accessible version of Lisp NewLISP is all the smugness with none of good design or maturity that justifies it.
&gt; But: it is easy to install, cross platform, has a easy, built-in GUI toolkit, is actively maintained, nicely documented and generally "polished" enough for beginners, and has a helpful community. Sounds a lot like [Racket](http://racket-lang.org/). Sorry, my contract stipulates that I have to mention them every two days. In all seriousness, I get the feeling that a lot of anti-newLISP sentiment comes from 1. The perception (justified or not) that its creators didn't take the existing wisdom of Lisp to heart in a lot of ways. 2. The perception (more likely justified in this case) that there are enough LISPs already for any purpose, and that we need to start solidifying support for some of them rather than crafting new ones.
&gt; I will focus on the most modern and accessible version of Lisp newLisp is definitely *not* the most modern version of Lisp. This line sent me racing for my browsers back button. 
'The most modern and accessible Lisp'? Somehow 'modern' has lost a lot of appeal lately ... 'All of the details seem very confusing at first...' - confusing the confused? 'Rule #1 Everything is a list.' ... Rule #1: Rule #1 is bullshit. 'Everything is evaluated, like math, from the inside to the outside.' ... 'math' is evaluated from the inside to the outside? 'In the second list, we are using a keyword (or function) called "list" to let the list know it is an actual list and should be interpreted that way.' .... Oh no.... I don't think 'Lisp' is confusing, it is introductions like these. :-( 
It seems a little scrambled. E.g. &gt; Everything is a list. (+ 1 2 3 4 5) Looks like a symbol and five numbers to me. Or this "explanation" of the LIST function: &gt; In the second list, we are using a keyword (or function) called "list" to let the list know it is an actual list and should be interpreted that way. "Let the list know it's a list?" No, like, function calls or return values? Evaluation rules?
The main purpose of newLisp is that of a 'honeypot' for people who have all kinds of wild ideas about Lisp, but should not be allowed to use Lisp. 
The first statement is corrent, everything *is* a list.
&gt; 'Rule #1 Everything is a list.' ... Rule #1: Rule #1 is bullshit. Why? It's the only thing he got correct. &gt; In the second list, we are using a keyword (or function) called "list" to let the list know it is an actual list and should be interpreted that way. &gt; I don't think 'Lisp' is confusing, it is introductions like these. :-( Too bad it seems too difficult to explain that `list` is a function that returns a, well, list.
Sounds like [Racket](http://racket-lang.org/), tastes like [Chicken](http://call-cc.org/). &gt; In all seriousness, I get the feeling that a lot of anti-newLISP sentiment comes from The fact that it's a nerfed Common Lisp. Welcome back, 1970.
&gt; still stuck in the 70's. More like the 50s. Maclisp had lexical scope in the compiler in the 1960s.
 foo Is that a list?
&gt; should not be allowed to use Lisp. More like "should not be allowed to program computers."
Why? A symbol is a list?
That's an ato-oh, wait, you're right. I downvoted myself as penalty.
I forgot about atoms for a moment, sorry, you're right.
It's not (IMO, at least) that it features a wrong dialect, it's that the author pushes newLISP as hands down the best dialect (and that's obviously at least controversial if not outright false). The author also seems to have a broken understanding of how some basic things in lisp work (or he's deliberately misleading the audience in order to simplify, but it's not obvious which from this one article). Add to that the fact that many [excellent](http://www.lisperati.com/casting.html) [beginners](http://docs.racket-lang.org/quick/index.html) [teaching](http://mitpress.mit.edu/sicp/) [materials](http://www.gigamonkeys.com/book/) already exist for free in quite a few places aside from the [physical](http://landoflisp.com/) [books](http://www.amazon.com/Little-Schemer-Daniel-P-Friedman/dp/0262560992), and I can easily see how there would be a strong negative reaction to this piece.
I'd say position if it has to work on lists and vectors, member if the sequence is guaranteed to be a list.
http://web.cs.wpi.edu/~jshutt/kernel.html &lt;--- if one really cares about lambda calc in a lisp setting, Kernel is an excellent starting point The OP seems far wide of the mark as usual. Beta reduction is more akin to compilation or partial evaluation then it is to the concept of a programming language evaluating expressions. Kernel makes that very explicit. His point seems to be that 'Lisp and Lambda Calculus are different', which is not much of a point. I'm sure a future post will prove that newLisp is a much better lambda calculus than Church's, because dynamic scoping and interpreted EVAL's are better then static scoping and compilation, or something.
and numbers. and strings.
I've always wanted to do Summer of Code, but I can never think of any ideas that would be both interesting and feasible.
Atomic values are atoms.
Yes, he does. If he was evangelising PHP, it'd be a similarly bad thing. newLisp is a terrible Lisp with way too many bad, bad design decisions. Contrary to the popular opinion, any publicity is not necessarily good publicity here.
&gt; I do not actually know enough about newLisp other than it's a simple, beginners oriented Lisp dialect ...which actually means terribly broken in many places, in ways which will not be immediately obvious to beginners, but which are seriously harmful. The "simple" there very often also means "I have no idea how to implement it in a proper way, so I'll just specify it in a way I can implement", which is exactly the wrong kind of simple to aim for.
&gt; &gt; ("my" "cat" "is" 2 "years" old) &gt; ERR: value expected : "cat" That is a HORRIBLE error message to give here. &gt; The reason we have an error is that Lisp cannot evaluate "cat" as part of an expression. And this is a HORRIBLE way to "explain" it. This tutorial is as bad as the language it attempts to describe.
&gt; way too many bad, bad design decisions Has this been formalized and explained in a single document that we could point the newbies/uninformed to? It seems like that would cut down on a lot of the pointless arguing.
Is this different from PAIP ?
oh, right. forgot about that. so lists and atoms it is.
I think the main objective of PAIP was to introduce pattern matching in general, while I was trying to make it easy to use in everyday programs. Hence the pdefine, plet and pcase macros, which allow your code to use patterns in a manner similar to Haskell. 
One option: run multiple ECL instances and control them with IPC.
Threads are what you want if you require pre-emptive scheduling, where your scheduler interrupts the executing 'routine' and runs another in its place. Of course if you use built-in threads then you're not really scheduling anything. Alternatively you could use cooperative scheduling, where each function is required to relinquish it's hold on the "CPU" so that another routine can run. I suspect this is what you're going to have to do. Google around for "green threads" for one approach to this. 
For a pure-lisp solution, you could use [Arnesi's CPS](http://common-lisp.net/project/bese/docs/arnesi/html/Automatically_Converting_a_Subset_of_Common_Lisp_to_CPS.html). It's very easy to implement task-switch with `call/cc`. However, you should understand that ECL is slower than other CLs at this kind of stuff. It may be best to get [bordeaux threads](http://trac.common-lisp.net/bordeaux-threads/wiki/ApiDocumentation) working, especially if your application already maps well to threads.
You are right, I'm aiming at something like cooperative scheduling. Here are more details about what I'd like to do: I have a VM coded in C and a LISP environment communicating. - LISP -&gt; VM calls allows me to manipulate some data that are living inside the VM - VM -&gt; LISP calls allows me to run some routines that are dynamically defined inside the LISP environment. My VM operates a scheduler, and time is constrained by audio output (the VM is generating sound). - At a given time, the scheduler calls a LISP routine with unbound execution time. The routine does its work and then make a special call saying "now I'd like to sleep for X (samples), scheduler wake me up when it's time". - The scheduler registers when it will have to do this wake up call and wake up any routine that should be woken up now - when done, the scheduler advance time by one sample and check if it has to wake anyone up. reading various things about LISP, I realize that the BREAK function does something similar - suspend execution, pass the hand to the debugger, which can resume execution. So I wonder if the is something similar to BREAK that would allow me to get back to the caller.
I would embed an HTTP server and process any input sent to ecl via the HTTP port. If you have only a few states, they could be saved in a global between HTTP calls.
I think this would be discussed on the ECL mailing list, where you can get the implementor(s). Typically other Lisps have something like PROCESS-WAIT, where you can let a thread wait until some condition is true or another threads wakes it.
&gt; However, you should understand that ECL is slower than other CLs at this kind of stuff. Interesting, why's that? Is it only because it implements its control structures in C, and thus doesn't get to be as smart about the emitted machine code, or is there some other cause? Even then, it's possible to implement very low-overhead green threads in C, though I guess expecting ECL to see through two layers of code transformation and choose the optimal representation in C is a bit of a tall order.
Do the VM and the Lisp (btw, we stopped spelling it LISP some 20 years ago) live in the same process, or are they IPC'ing with each other? As for BREAK, as long as you want to keep it strictly to this kind of up/down exchange, you can do directly what BREAK does and signal a condition, then invoke a restart. If you're not familiar with conditions and restarts that don't unwind the stack, see [this PCL chapter](http://www.gigamonkeys.com/book/beyond-exception-handling-conditions-and-restarts.html). Be aware, however, that this kind of structure would be rather odd, and you'd effectively be sitting permanently in a condition handler when your VM is running. Whether or not it's acceptable you'll need to decide.
First, ECL isn't magic. It's compiling the output of the codewalker macros which look like the kind of barf that the loop macro only wishes it produced. It doesn't "see through" anything. Second, ECL still relies on GCC to do a lot of optimizations. This works well because *normally* lexical variables get turned into C locals. The problem is that the CPS transformation makes a lot of nested lambdas, which makes ECL identify *every* function as a closure-with-environment, and ECL puts lexical variables used by compiled closures in an alist. And that's if you compile everything. If you don't, you get the much slower bytecode interpreter which makes clisp look fast.
Have you thought about using a fifo and simply running them in separate processes?
Do you *have* to use ECL for this? Unless you happen to be on PPC it appears that there is no threading support. An implementation with semaphores or condition variables would make this much easier. With condvars you could e.g. `(condition-wait vm-audio-cvar vm-audio-lock)` Lisp side, and `(condition-notify vm-audio-cvar)` on the other side. Another way would be to manually transform your code: is there any reason the Lisp-side procedure cannot simply return and be re-called later? Basically, something like: (defun make-callback (...) (let ((...)) (lambda (...) ... reference let vars to maintain state between calls ...))) (setf *something* (make-callback ...)) ; then somehow (funcall *something* ...) from the VM If you have no ties to Common Lisp itself you may want to investigate Guile Scheme. It has full threading on most platforms, the impending 2.0 release is quite fast, and it is really geared toward being embedded in C programs. Alternatively, you could use SBCL or Clozure CL and invert the relationship: embed the VM (which I assume is controlled by C in some way) into Lisp using CFFI and just use the better Lisp scheduler directly (using condvars, semaphores, or arnesi's call/cc machinery depending on what you really need to do).
Why not use a Lisp that supports first class continuations? For example, I think the Dybvig Scheme book shows how to implement a mini green thread system.
http://linuxfinances.info/info/lisposes.html
[Movitz](http://common-lisp.net/project/movitz/), [DreamOS](http://www.stripedgazelle.org/joey/dreamos.html), &amp;c. &amp;c. &amp;c. It's a very common, and, in my opinion, good idea, but it requires a metric tonne of work.
There is a torrent floating around with the source to Open Genera. Very interesting reading.
[A LISP Machine?](http://en.wikipedia.org/wiki/Lisp_machine)
In other words, you offer an existence proof. An OS can be done in just about any systems language... and by systems language, Imean any programming language with a scalable module system and is conducive to multiple developers working on independent parts. Given that C qualifies, it really doesn't take much to qualify as a systems language. CL can easily meet these criteria. edit: bumped submit early (dang 2" wide keyboard) 
As someone else has already mentioned, that was the entire idea around LISP Machines.
I mean, on a modern day RISC.
Somebody hacked scheme into the linux kernel once. There are also opportunities in the unix userland (especially startup scripts). I think that would be a much more profitable way to go than writing an OS from the ground up. The C guys have thousands of man-years head start on you...
RISC is newspeak for C-machine. So, yeah, but the lower levels will be just as evil looking as they are now and implementing fancy user space stuff will be just as difficult because the underlying architecture is designed to be minimal rather than helpful.
I was confused because I thought we already had emacs... and then doubly confused that no one had made that joke 10 comments in.
So if I put in a long ton of work, I've squandered my time and done to much ??
It would be good if all those improvements were actually submitted to the shootout. C versions are heavily optimized, whil SBCL one not so much, which gives false impression that C is much faster than SBCL, while truth is that just people spent more time on C benchmarks.
you are right, I said ECL because I looked around and it seemed to be the right tool for embedding a Lisp environment into a C program - but as you may have guessed, I'm not really familiar with the Lisp ecosystem, and there might be better tools for the job / other approaches to the problem.
I'm the author of the "improvements" and I submitted them to shootout: for spectralnorm, fasta and pidigits test. Check [my response](http://lbolla.wordpress.com/2010/12/05/sbcl-quicker-than-c/#comment-7805). Other tests don't show so much improvement though, expecially if the tests are I/O bounded (fannkuch-redux, for example).
It's too bad Genera has never been opensourced. Sure it's dated, but it would be a good point of departure for a modern Lisp machine.
It's an excellent idea, actually. Let Linux deal with messy hardware recognition, and just use it as a hardware abstraction layer for your Lisp.
What would be nice is a small-footprint Lisp that could live on a meshed sea of ARM cores, just within embedded memory.
Actually, Genera has real limitations. 1. Dependent on microcode support for things like maintaining the GC invariants and decent paging performance for the tagged memory. 2. Pervasively single-processor 3. Trusts the network implicitly 4. Single address space for everything That's just off the top of my head. The coolness of "hey, I can see the source of almost the entire OS" quickly morphs into "actually, this code is pretty gross." Genera is a good thing to know about and even study, if only to counter "In the beginning was UNIX" ignorance. It is almost certainly not a foundation for a useful 21st century OS. Also, FYI, the CADR OS has been open-sourced, and it gives you a vague idea of what Genera is like near the hardware. (Genera itself was immensely improved from that base by many man-years of effort, of course.)
The Genera source code has always been available to the user. It is one of its distinctive features. The system is completely open to modify. The code is just not free. And the OG VM is closed. 
Money quote &gt; It initially lacked support for filesystems and TCP, which means that it lacked the ability to save data or programs anywhere. Even with these lacks, probably still remains more functional than most of the other projects.
Modern-day RISC processors also come with MMUs that don't help much with preserving GC invariants.
My pet idea is a Lisp environment running atop a Linux kernel which has been modified to help out with implementation issues. E.g., maybe there is some way to make the memory faults for the GC avoid inefficient(?) context switches? Add support into the virtual memory system to avoid paging in things that the GC wants to crawl, but could defer? Help hide GC behind blocking system calls? Or provide better mechanisms for synchronizing GC among multiple threads? I have no quantitative idea how much any of these are real issues, or how much this kind of thing could help. But it is much more likely to help than Lisp from the ground up.
I'm sure speed doesn't need to be the primary concern, which I'm sure you're aware of. 
&gt; The code is just not free. Precisely. So it's useless as a base to build an open source Lisp machine.
So probably just getting a stripped-down Linux distribution to run SBCL or CMUCL sans X (writing the window manager in Lisp) sounds like the easiest way to make something workable.
There's a difference between "open source" and "free/libre open source". I am just making it clear that Genera IS open source, just not with a FSF-compatible license. 
To qualify as open source the license must a) ship product with source b) allow you to modify the source c) allow you to distribute modified source
On the other hand, if you are just going to write applications in SBCL, why strip down the rest of Linux?
If Unix and Lisp form their own ecosystems, and you're building a Lisp machine on an Unix foundation, then you only need the barest minimum to deal with the hardware. Sure you could run SBCL on an Ubuntu box, but it would be a Unix machine, not a Lisp machine. There would be little incentive to tackle the network stack, window manager, or dealing with graphics hardware as GPGPU, and the like. How would you tie Unix resources into a Lisp GC, which would be a key aspect of a Lisp machine?
Okay, I researched a little and there does seem to be a collision of terminology (and hence I wouldn't say either of us were necessarily wrong). I suppose this is why I like to strictly say FOSS, since usually if one thinks X is not open source, then it must be closed source.
Upvoted for actually doing some analysis. Your conclusion looks correct, but this is not "misleading". The benchmark tells you something useful here - that it's easier to use certain types of concurrency with some language implementations.
Agreed, that's why there is the question mark! ;-) "SBCL quicker than C?"
Agreed. It makes library installation as painless as apt-getting in Linux. Amazing effort. I'm looking forward to the meta tools that will make it easier to sift through the hundreds of packages. Things like categories ,user voting, commenting, download numbers, frequency of updates etc. CLiki is a complete mess in this regard (and most other regards too).
If it could only fetch platform specific C binaries for CFFI based packages I would call it perfect.
You're not getting my Bud Light.
I'd like to do something like that. It's frustrating to want to try e.g. lispbuilder-sdl on !Linux and have to jump through a lot of hoops to get the C library. Some people are really upset at this idea and think that Quicklisp shouldn't get anywhere near non-Lisp library installation.
Perhaps it can just be some sort of optional extension? Edit: I'm not sure if I'd be thrilled either, but that's only because I can definitely imagine all of the issues that come with it. Then again...
I was waiting for this question and waiting for this answer.
It still calls Racket as MzScheme, so it's kinda old. To run Racket on bare metal, you first need to compile OSKit, which need gcc 2.75.something, which need to be compiled with gcc 3.3.something, which compiles only with gcc 4.4.1. So, no, it's impratical.
If you are annoyed by number of hoops for linux, just imagine some windows user where apt-get, emerge or similar don't exist. It shouldn't install library, but putting a dll in some specific directory which is added to cffi library path would be enough. It could be made optional if people are against it. It could be even be optional on the package basis. Quicklisp is godsend for lisp only libraries, and if it could be made to help with bindings it would be really awesome.
ok, I've been looking at guile/scheme and continuations are definitely what I'm looking for. thanks a lot !
!Linux, not Linux. `apt-file search libfoo.so` is super-handy.
But then you'd have to deal with the Unixy everything-is-a-file, e.g. /dev and /proc.
I used to think it would be really cool and maybe even possible to network together a bunch of Commodore 64s and a Nintendo Gameboy (through it's little game-link port), and use it as a pie-in-the-sky cluster. Then I stopped being 8 years old.
I'm an alkie. You can have mine!
Agreed. I recently did a linux reinstall and was up and coding with emacs, sbcl, and all my libraries in a few hours. Compared to the download, install, compile, break, google loop I had before.
Well, I used to be in the Beowulf FAQ, so I guess I never stopped to be an 8-year old! Seriously, any Lisp which doesn't embrace massive parallelism by way of shared-nothing message passing (and not just by multithreaded shared memory illusion) isn't long for this world.
M-x psychoanalyze-pinhead
Actually, all that is created later during the init sessions. Someone could just run lisp as /sbin/init and add some startup code to get the system into a workable state. Then just wrap everything in lisp.
me too! :)
&gt; Some people are really upset at this idea and think that Quicklisp shouldn't get anywhere near non-Lisp library installation. Who cares...
Too bad Movitz is as dead as Climacs and DreamOS is more a toy project than a serious attempt to make an usable Lisp OS.
No, the question mark allows you to say something not necessarily true but inflammatory enough to get people to click. See: "Is Obama a secret muslim from Kenya?"
even if this is not the intent of the author, what you say is absolutely true. popularity should not mean authority: that's why there are little "down" arrows next to each comment, and I clicked the little "up" one next to yours.
I'm not nearly hardcore enough about Lisp to really be able to help with this, but I thought it might be worthwhile pointing out that [cygwin does something similar](http://www.cygwin.com/cygwin-ug-net/setup-net.html#internet-setup) already for compatible binaries. I don't know what packaging / dependency analysis libraries this might be built on, but it seems to me like this could be built-on or even just expanded to get the desired effect. 
Any of the (unfortunately, and annoyingly) common "faster than C" posts are inherently misleading...
Is there anything a c-machine can do that a Lisp Machine could not? Like bitwise shift and crap?
&gt; Well, when C is using GMP for some benchmarks, while SBCL is using built in arithmetic Huh? [Looks to me like SBCL uses GMP for its benchmarks too](http://shootout.alioth.debian.org/u32/program.php?test=pidigits&amp;lang=sbcl&amp;id=1).
Yes, SBCL built-in infinite precision arithmetics is way slower than GMP. And the benchmark specs explicitly allows using GMP (http://shootout.alioth.debian.org/u32/performance.php?test=pidigits#about)
Agree again. I had a an OpenGL repl project I gave up on because of the pain of managing a scadzillion dependencies. Now I will pick it up again..its something lisp developers have needed since forever, but only now it's here is it appreciated. 
Still, it proves the point that it is possible, not necessarily that it is practical, or that people are doing it for "Real Work" (TM). There's nothing really barring anyone from doing it, other than time &amp; dedication.
You will have just approximately made enough work to have a Lisp OS, but only just enough.
That's why Symbolics used to be. 
That's a pretty broad definition of "systems language," but yes, there's nothing stopping an OS written in most any "systems language" save for time &amp; dedication. Witness: * Haskell: quite a few, HouseOS, &amp;c &amp;c. * JavaScript: [es](http://code.google.com/p/es-operating-system/) (large portions are C++ obviously, but large portions are WebIDL &amp; JS too). * Java: JNode, Java/OS, &amp;c. * Pascal: quite a few, PERIX, &amp;c &amp;c. The list goes on (Modula-2/3, Oberon-2, anything really). 
[Schemix](http://abstractnonsense.com/schemix/). Great system, did quite a bit of work with it some time ago, and made something similar for netBSD, though the system with all the source long ago bit the dust. Was great testing out kernel work too.
Wouldn't that be a short ton of work ?
(pedantry "It is a benchmark for language-*implementation* - language-*implementation*") ; (/pedantry just didn't seem right.)
but the short ton is less than the weight of a metric ton...
Hmm, why can't they use pthreads in C? SBCL's "concurrency primitives" are exactly like pthreads. Only two concurrency-related functions are used: sb-thread:make-thread and sb-thread:join-thread. So just call pthread_create and pthread_join, huh.
&gt; use certain types of concurrency with some language implementations. No it is not.
Exactly.
but it's dedication &amp; time as the metric, so if a long ton is *more* than a metric ton, you would have surpassed &amp; finalized a Lisp OS, whereas a short ton would be a waste of your time, as you got close, but dropped it. That's at least how I read this.
Okay. I read "..You will have just approximately made enough work to have a Lisp OS, but only just enough..." as having barely accomplished the task, not surpassed &amp; finalized it. Ahh, curmudgeonville here I come :-)
Ah, I see. We'll have to opposing long &amp; short ton houses in curmudgeonville.
As noted elsewhere, OpenMP is just using pthreads, and sb-thread is just using pthreads. Beyond that, most of the shootout benchmarks exercise the runtime and libraries to some extent. I don't see why OpenMP isn't fair game if I/O, regex, etc libraries are too.
[Lorenzo Bolla's program](http://shootout.alioth.debian.org/u64/program.php?test=spectralnorm&amp;lang=sbcl&amp;id=2) has been shown on the benchmarks game website **since December 8th** 2010. Does it 'beat' the C program?
The MMU's support the functionality, but the APIs don't give full access to it. You can use readable/writable/not-present traps to implement hardware read/write barriers (see Azul's pauseless GC). However, this is glacially slow on a UNIX system because mmap() won't let you twiddle page protection in batches and each mmap() call requires an expensive TLB invalidation (potentially on all processors on an MP system). The GC algorithm is amenable to batching the work, amortizing the costs of TLB invalidation over a number of pages, but there is no API for doing so. Such an API would be wholly feasible: mmap() would accept a list of virtual-address ranges and the new protections to apply to entry of the list. The kernel would modify the page tables (locally) for each table in the list, but the modifications would only take effect at the end when the kernel did a global TLB invalidation. Azul has a kernel module that does pretty much exactly this. 
You forgot to acknowledge that the programs you contributed to the benchmarks game have been run the way you requested and shown on the website **for the last 2 months**. Your response was just - *So, different numbers on different boxes, which is not at all unexpected.* **Please provide full information** on how you made your measurements, which language versions *etc* 
How about something like Debian does, i.e., stable/testing/unstable? Only in this case would be something like "only CL", "CL+non-lisp-stuff"?
&gt; I think this really comes down to ... You haven't shown the compiler flags used with gcc. CPU {Elapsed} C GNU gcc #4 --11.14s {2.80s} Lisp SBCL #2 -- 15.25s {3.97s} Go #3 -- 15.70s {4.05s} [N=5,500 x64 Ubuntu quad core](http://shootout.alioth.debian.org/u64q/performance.php?test=spectralnorm#about) 
&gt; Well, when C is using GMP for some benchmarks, while SBCL is using built in arithmetic Did you read the SBCL program? (define-alien-routine ("__**gmp**z_init" mpz-init) void (a mpz-ptr)) *etc* 
`sipefree` hasn't shown the compiler flags used with gcc. CPU {Elapsed} C GNU gcc #4 --11.14s {2.80s} Lisp SBCL #2 -- 15.25s {3.97s} Go #3 -- 15.70s {4.05s} [N=5,500 x64 Ubuntu quad core](http://shootout.alioth.debian.org/u64q/performance.php?test=spectralnorm)
Why does sbcl not handle io very well?
Since both must be Turing-complete to implement Turing-complete languages, one can do anything the other can. Due to the limited instruction set of the RISC architectures, the generated code for compiled Lisp would be as ugly as it is in x86 (which is a CISC with a particularly bloated instruction set, with instructions specifically for languages like C, Pascal, etc, but they are really slow and never used). C code maps fine to single RISC opcodes, instead, think about `inc`, `dec`, `xor`, etc. It also doesn't have lexical scoping (and anonymous functions), this simplifies even more the code. LISPMs had special hardware support for running Lisp, like native garbage collection and other stuff. Car and cdr were opcodes if I recall correctly. *edit: typos*
Structs are not vectors in racket -- they're disjoint data types.
That would be good to know. There is precedent for Lisp hackers being able to wring the last cycle out of C compilers. Check out Siskind's [Stalin](https://engineering.purdue.edu/~qobi/software.html), which compiles Scheme into "faster-than-handwritten-C" code by: * doing whole-file global optimization * knowing a lot about gcc optimization flags
Link? That seems like something that would be worth collaborating on.
I don't have access, right now, to the boxes I ran the test onto. I've rerun them on another box with these specs: * Linux 2.6.29-2-686 #1 SMP Sun May 17 17:56:29 UTC 2009 i686 GNU/Linux * 2 Intel(R) Core(TM)2 Duo CPU E4500 @ 2.20GHz * gcc-4.3 * sbcl 1.0.31 Results for gcc are: * N=1000 0.5secs * N=2000 1.8secs * N=3000 4 secs * N=5500 14secs * N=10000 44secs Results for sbcl: * N=1000 &lt;0.1secs * N=2000 1.7secs * N=3000 5 secs * N=5500 16.4secs * N=10000 55secs Times are averages over 3 runs. It looks like the sbcl version runs faster for smaller N, which might imply, that some "setup" (OpenMP maybe) in the C program is taking much of the runtime. On a side note, posting a blog link on HN is for stimulating a discussion about a subject I'm interested. Of course I acknowledge that the program was accepted and run by "benchmarks game website" *since December 8th* 2010! I'm just interested to hear what other people have to say about it!
Even better, start with [a window manager that's already been written in Lisp](http://www.nongnu.org/stumpwm/).
True, but it still needs X. For a modern Lisp machine you'd probably redo NeWS in Lisp instead of PostScript. Of course, you'd need to handle OpenGL and OpenCL-like computing model as well, so that's tough. The whole thing is academic, unfortunately, because it's a lot of work and hence it will never happen.
Fuck, I'm getting my windowing systems and window managers confused, sorry. That one does need X. And the real problem you'd get with bypassing X is drivers. If you don't build on either X or windows, you can forget about having hardware accelerated graphics.
No, you would "just" have to do it in Lisp, with the hardware abstraction provided by the Linux kernel. In fact, Wayland, if successful, would succeed X11.
That comment is *very* tongue in cheek. Reddit was rewritten from Lisp to Python in [2005](http://blog.reddit.com/2005/12/on-lisp.html). At the time, Spez wasn't able to sleep through the night without the site [going down](http://lemonodor.com/archives/001301.html#c12730).
Duty cycle feels like 80% at times.
Does it only work with fann 2?
[reddit @ pycon keynote 2009](http://pycon.blip.tv/file/1951296/) lists plenty of reasons why they moved off of LISP.
speaking of which, can anyone else reach [r/scheme](http://reddit.com/r/scheme)? Every time I attempt it, I get a "you broke reddit" message (or the like), but all other subreddits work fine.
Yeah, It is broken for me too.
I doubt it. The SBCL GC and memory management in general sucks arse IMHO. The compiler and stuff is pretty great, but this part of the run-time is not.
The first time I hit it, I received the "this never would have happened under Lisp" message, which was quite funny, but now I'd like to check it. :D 
I didn't know about r/scheme, but it looks like I can't subscribe today.
Not really. They mention one thing they like with python (many libraries available) but don't necessarily say that it is not the case with LISP. The only criticism is that it is more difficult to roughly evaluate the overall quality of the code without doing a thorough code review with LISP than with python.
It should be forward compatible, but it only provides that API that's available in 2.0.0. When I started writing it, 2.0.0 was the main version available in my distro's software repo, so I figured I'd target that. There are a couple of features in 2.1.0 (not the least of which is creating training files from a callback function, rather than having to load them from file), so I'll definitely be adding those features in the near future
It should be forward compatible, but it only provides that API that's available in 2.0.0. When I started writing it, 2.0.0 was the main version available in my distro's software repo, so I figured I'd target that. There are a couple of features in 2.1.0 (not the least of which is creating training files from a callback function, rather than having to load them from file), so I'll definitely be adding those features in the near future.
It should be forward compatible, but it only provides that API that's available in 2.0.0. When I started writing it, 2.0.0 was the main version available in my distro's software repo, so I figured I'd target that. There are a couple of features in 2.1.0 (not the least of which is creating training files from a callback function, rather than having to load them from file), so I'll definitely be adding those features in the near future.
&gt; Of course I acknowledge that the program was accepted and run by "benchmarks game website" since December 8th 2010! I'm just interested to hear what other people have to say about it! 1) Note that `deverdev` (before he decided his mistake was embarrassing and deleted his comment) thought that your program was not being shown. 2) Note `rst` on HN - *Bolla says that alioth blew it, by not asking SBCL for full optimization --- and he does in fact get different timing with the optimization in place* - without understanding that both timings were for your program. 3) They made those mistakes because your blog entry has been out-of-date for 2 months! Your program was shown on the benchmarks game website 5 hours after you contributed the program.
&gt; another box with these specs Maybe I said back in December - full information should be in your blog entry. &gt; Times are averages over 3 runs. The times in your blog entry were not averages - please use the same approach you used for your blog entry when you post measurements here.
Actually, this is very recent. Before it was not using GMP and the Lisp code was considerable slower.
Looks good! By the way, why the system name is :fann and not :cl-fann? I would guess :cl-fann would make more sense since it's a CL wrapper.
&gt; this is very recent Published on the website since December 15th - so `deverdev` was *merely* 8 weeks out of date ;-)
Thanks, what are your measurements for N=5,500 ?
This just in: Reddit uses things written in languages other than Python.
fann 2+ isn't available in my debian/ubuntu yet. I see only version 1 libraries.
&gt; A safe language means a reliable environment without the need to separate tasks out into their own separate memory spaces. Umm, how about no? &gt; CORBA is reasonably characteristic of how IPC protocols need to be constructed, it involves copying and marshalling arguments into input and output structures, along with all the joys of managing the memory consumed by those extra copies. That's also very inaccurate. CORBA is not representative of anything besides being an abortive committee monster. You still need process boundaries and trust management. If that weren't the case, I'd never restart my SBCL, and the truth is I restart the moment I start suspecting I might not be on top of everything going on, because you simply can't tell when you cross the safe boundaries when there are none to be seen. You also still need IPC, if only for the fact not everything ever will sit on the same machine. You just don't need your IPC to be CORBA, there are much better offerings around. In fact, pretty much everything you can name is going to be better, because it takes a lot of work to do something as horrible and complex as CORBA.
I guess in this case 8 weeks is a short time :-) I must confess my first reaction was the same, that it was unfair to compare since the SBCL submission was not using GMP. Simply because last time I checked the shootout around October/November there was no GMP usage in the Lisp submission. It's not that the shootout is something to be checked every day or even every week ;-)
Would you please care to elaborate?
CVS shows [673 revisions](http://alioth.debian.org/scm/viewvc.php/shootout/website/websites/u32/data/data.csv?root=shootout&amp;view=log) of the Ubuntu x86 data file during the last 2 years and 5 months. Simply *check the facts* right after you decide to opine about the benchmarks game, right before you do opine. 
Broken for me too.
Yeah, it's weird; various other subreddits, from the tiny LogoUnderground to the large r/Gaming, r/Programming, &amp;c. work, but r/Scheme is *consistently* borked. 
Seems like reddit's still a bit broken, I can't reach /new/'s second page. We can use r/lisp until they fix r/scheme, though.
The `new` issue seems hit or miss too; I've not seen it, but I'm not terribly surprised by it either. r/scheme is a bit slower than r/lisp, but they're both interesting; Most definitely will stick to r/lisp until the transition succeeds though.
I would certainly hope they didn't use LISP; I mean, they could have at least used LISP 1.5.
I've always sort of thought movitz would be an ideal canidate for virtualization... all it really needed was a network stack that worked with the two of three virtualized eithernet cards these systems tend to offer.
How about you learn how to read/interpret a comment *before you comment*? I was not talking about CVS revisions or anything like that. The SBCL code for the pidigits program with GMP appears on CVS (revision 1.4) on Sun Dec 12 23:41:06 2010 UTC (8 weeks, 3 days ago). The last change from the previous Lisp code (revision 1.2), without GMP, is from Wed Sep 21 13:59:07 2005 UTC (5 years, 4 months ago). Revision 1.3 is a file removal. Like I said, the last time *I checked/consult* the Lisp code for the pidigits problem it didn't have GMP code! Only with this post I became aware of that. Because, like I said, *I don't check/see* every day or even every month the shootout website looking for new things. PS: I doubt there are many people consulting the website, especially for Lisp submissions, very often. *edit: PS and small corrections.*
I can't say I'm fond of it, but haven't seen problems with it for quite a while. It looks like on x86-64 conservativeness of GC is much less of a problem.
Definitely; something like that Xen mini-os that was used to boot-strap an O'Caml OS.
Because if you're using it from Lisp, you already know the cl- part. It's therefore redundant and pointless to include it.