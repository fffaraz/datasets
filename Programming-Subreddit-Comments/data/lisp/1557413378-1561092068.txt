I installed everything that I found related to Gstreamer, maybe I am missing something, but I don't know what.
If you mean that you want to speed up runtimes on the CPU that use GC by using the GPU, not likely. This is much more a latency problem than anything else, and GPUs are thoroughly throughput machines.
Simple garbage collectors are easy to write -- you can dust off a mark-and-sweep GC in a couple hours. So for toy language purposes, it's not that big a deal. You won't compete with top-of-the-line, but that's not the point in a toy language.
Try deleting ~/.cache/gstreamer-1.0 and restarting the browser.
Nice would love to see simpler install on linux like flatpak which has become quite standard, guix is not even available in my package manager and downloading it fails to even extract the tar at which point i gave up :/
Can you elaborate please?
Lisp, one of the oldest languages family, pioneered the CS field with thighs like high level abstractions, garbage collection, syntactic macros, etc. At one point there were specialized Lisp Machines running various lisp dialects (ex. MacLisp, precursor to Common Lisp). Those machines had direct hardware support for lisp specific operations to improve its performance. They eventually went away due to the ai winter and rise of the fast generalized processors. Many "new" ideas have already been invented by someone. Oftentimes they can be traded to lisp, hence the whole reinventing stuff. Lisp machines is one example.
You need lzip to extract the archive. Flatpak creates in effect an unverifiable blackboxes. It's not something very commendable for a free software web browser ;) It does not allow for reproducibility and transparency among others. Guix gives you all that :)
Got it. Thank you. I was mainly curious as to how you were implying that the language performed hardware GC. I see what you mean now though with the Lisp Machines.
&gt; The large box is the minibuffer that does not get resized properly. This is due to a bug with WebKitGTK. I'm working on it, but it's surprisingly non-obvious :/ I see. Is there some public info about this anywhere? A github issue perhaps? I'd be interested in investigating and working on it too if I can find the time.
&gt; Since the higher end boards are multi core, dedicate one to polling loops. BeagleBone should have two dedicated microcontrollers with accurate timing, so you don't need extra cores and polling loops. Just program your low-level control loops for the microcontrollers.
Here you are: https://discourse.gnome.org/t/programmatically-resize-a-box-split-next-browser/718/4 Thanks for your interest in this, this problem has been annoying me for too long already :D
I dont know about all that but if its mcuh better why are distro's not placing it in there repository, flatpak and click seem to be on just about every distro availability is the first hurdle to adoption else people get annoyed and just give up :/ I thought flatpaks just build from code via a config file and package it up is that much different than supplying binaries which I never try reading ? or does guix not work like that ? Anyway its just about availability to the masses anyone can click install via a gui with a flatpak with out even touching the command line, I know its not perrfect but at least I can use the software with out hassle.
Every time any programming language becomes mature.
The Guix pack could not be more universal, it can really be used on any (recent enough) Linux kernel: it's a tarball, just extract it and you are ready to go! The fundamental difference between a Guix pack and the alternatives is that it gives you transparency and bit-level reproducibility: this means that anyone can reproduce the pack from source and obtain the exam same result. This is the only way you can trust the code you execute. Popularity is not always a sign of quality (or else we would all be using Windows :p)
You would also need a GC with Lisp, but you can also start by not having a GC cause you probably won't run anything too exciting in your language.
If you have to reach to the λ-calculus, you have a Lisp interpreter in λ-calculus in Rust, not a Lisp interpreter in Rust.
It’s been researched in the past https://people.eecs.berkeley.edu/~krste/papers/ismm31-maas.pdf
You should patent your hair-splitting technique
Guess what: Lisps have conses and symbols out of the box. You don't have to implement them out of lambdas in user code. Furthermore, using your technique, you can call literally any Turing complete language a Lisp, which is utter bullshit.
There really is no magic, it's just late binding.
I assume that's the same Maas which OP's link is discussing.
Yeah, unless you declare a function INLINE (in CL) it just looks up the function in the environment. You can do this yourself using SYMBOL-FUNCTION, eg `(symbol-function '+)`
Wow so it's the same author
Well, *half* every time.
Round and round it goes.
λ-calculus...isn't a Lisp. A Lisp is generally a very sugared λ-calculus but the sugar is important (it avoids requiring the Y combinator for recursion, implementing unique symbols and conses), and so on. You aren't getting this, are you?
When it comes to functions, it is exactly as stassats described - late binding. When it comes to classes, there is a little bit more magic involved; when a class is redefined, old instances are made obsolete and therefore, just before the next time that instance becomes accessed, the generic function `UPDATE-INSTANCE-FOR-REDEFINED-CLASS` will be called on it to update the instance to the newest version. It is possible to define methods on that function to implement custom behaviour.
Any papers / books about this topic in general ? theory about binding time, caching etc ?
On another thread in this subreddit, I stumbled across an interesting series on YouTube titled "Little Bits of Lisp" by Bagger. (He also put out the "Pushing Pixels with Lisp" YouTube series.) Perhaps this short episode might explain. https://youtu.be/oufGYAAVLfQ
&amp;optional are parameters that isnt required to pass. &amp;key are named optional parameters, &amp;rest is a list of all other arguments, &amp;body is used in macros and is more or less the same as &amp;rest, which you'd use to handle logic passed to it (Like with a let). Addition (+) is an example of rest. (+ 1 2 3 4). So for ex (defun test (x y &amp;optional (z 0)) (* (+ x z) y)) Z is 0 unless you pass a third parameter (test 2 3), (test 2 3 1). Key: (defun test (x y &amp;key (z 0)) (* (+ x z) y)) - (test 2 3 :z 5).
Or from the authors. https://people.eecs.berkeley.edu/~krste/papers/maas-isca18-hwgc.pdf
After programming in Scheme for a while now, I find I encounter this issue whenever I have to go back and program in Python. It's so much easier if everything is immutable by default and that the standard library assumes that. It's unnecessary mental load to have to think "wait, does this mutate the original or return a new one?" **especially** when that list/value could also be modified by other parts of the program. I've often heard people talk about how hard it is to imagine writing a program in which everything is immutable. Thankfully, I didn't have years of programming experience under my belt before coming across the concept, so to be honest it actually seems like a more sensible default, and far from strange. From my perspective, it's actually **more** difficult programming with values that are assumed mutable.
What I found most interesting about this was how small it was: the coprocessor takes up the same space as 64KB of static ram. That's tiny.
My rule of thumb is it's ok to use &amp;optional for one, maybe two, parameters. Anything beyond that, or anywhere performance isn't critical, use &amp;key. &amp;body is used only in defmacro and macrolet, where it should match the "body" of a macro form. I'm not sure it has any meaningful difference from &amp;rest; I use it to indicate "this is a list of forms (perhaps with declarations); treat it as such". I suppose it could be useful in writing automatic code walkers.
The importance of static guarantees has become more and more apparent to me when I write more complicated programs. Common Lisp and Clojure aren't super great for that. The main reason for me to stick with CL is freedom with macros and the interactive development. A language like Idris has some kick-ass interactive type-checking, but I haven't gotten into it too much so far. I have a moderately (1k lines or so) sized CL program I might choose to re-write in Idris as an exercise.
I spent years programming in C++ (and I still do quite often) so when I heard the concept of immutable by default I had that reaction exactly - "how can you do anything!?" But as I explored Clojure and Scheme the simplicity of it dawned on me: every function takes a value and returns a value. Let go of all these other ways of getting data into functions like pointers, references and global state. At least in C++ the differences between these are explicit - in languages like Java I never know when I'm passing by reference or by value. Switching to value semantics everywhere is a radical simplification that bubbles through your whole programming experience. Although of course it puts more burden on language/library designers to find ways of making this efficient. And in the end we almost always need mutability somewhere - even if it's just a global 'atom' or a database. But by restricting mutation to one or two places in the program all kinds of benefits just 'drop out'. One of them is that unit testing becomes 10x easier. Anyway, I'm rambling on for no reason except this was one of the most important 'enlightenment' moments Lisp gave me (even though it doesn't have much to do with the language itself).
I think the term immutable is a teeny tiny bit improper. It's a bit jokingly pedantic to say that but mutation-free would be a bit better. Immutability means you accumulate new information along the evaluation process until you get a final result, like computing on paper. It's a flow. Also, I do believe that exposure to mainstream imperative languages (c / pascal etc) restrict your understanding of computing and programming way too much. First time I saw Ocaml I tried to interpret everything in a Java mindset (not helped by shared terminology but different meanings such as 'constructors'). And it was a disaster.
Help out with [Coalton](https://github.com/stylewarning/coalton)! Have your cake and eat it too! With that said, we have around 30k lines of CL code (excluding dependencies) for our quantum compiler and simulator. While I wouldn’t deny the value of static type checking, none of us developers also feel suffocated in development. It does take discipline to not be sloppy with functions, to document them, and to write clear code. If you can do that, and if you use Emacs and SLIME, managing the code is pretty easy. However, we would welcome Coalton into the project as soon as it matures a bit more and the rough edges are sanded out.
Heh, Liszts made of Kons cells made me chuckle. Coalton looks intriguing.
I thought it was just Racket that was immutable by default. I thought scheme often had mutation
&gt;The importance of static guarantees has become more and more apparent to me as I write more complicated programs. You should take a look at Coalton, and also at ACL2, a strictly applicative subset of CL that features a theorem prover.
Er, is it normal to use camelCase in Clojure? I'm fairly sure people write the name Lisp in title-case too.
&gt; *In Clojure, Data Collections are values, exactly like numbers. They never change!* That's nice, but in Lisp, they are objects that can change; they are values if you treat them as such. Unlike Clojure, most Lisps do not support this very well in data structures other than lists. For instance, in Common Lisp can't add a new element to a hash table or vector such that the original hash table or vector remains the same. Not without allocating an fully blown copy of the original and adding to that one instead. Clojure does this by exclusively relying on boutique data structures. Lisp programming is perfectly nice (and better than Java) without these data structures.
&gt; *I spent years programming in C++* ... without ever using `std::string` or anything of its ilk that lets me add two sequences together without destroying them, just returning a new one ... &gt; *so when I heard ...*
Racket is an implementation of scheme. Both racket and scheme have mutation, by precedence any procedure ending in ! mutates one of it's arguments, otherwise it's safe to assume it doesn't.
You're "allowed" mutation in both, though in both cases the procedure is almost always (if not always) suffixed with a **!**. I suppose it depends how you look at it, but I'd say that counts as "by default", in both if you know what I mean. One thing I do know is that Racket doesn't have set-car! and friends in the stdlib, you have to require it. There's probably other things like that I can't think of off the top of my head, but yes I'd say Racket by and large is "more" functional than vanilla (SICP) Scheme, even if just for that reason alone.
 (let ((a '(1 2 3 4))) (values (mapl (lambda (b) (1+ (incf (car b)))) a) a)) ....although that's a contrived example.
There is one wart when it comes to redefining functions: (defun foo () :original) (defvar *closure* (let ((my-foo #'foo)) (lambda () (funcall my-foo)))) (defun foo () :redefined) (funcall *closure*) =&gt; :ORIGINAL But conveniently, symbols are funcallable, so if you need stored versions of a function to update when the original is redefined, you can just write `'foo` instead of `#'foo`.
Garbage collection is decadent. If you can't afford the overhead, you should be more frugal with your resources rather than complexifying the microprocessor. Reference counting is much tighter.
Your code works for me in SBCL but if I keep going with a LET I get something that I do not expect: (defun foo () :original) (defvar *my-foo* #'foo) (defun foo () :redefined) (funcall *my-foo*) =&gt; :ORIGINAL (let ((x #'foo)) (defun foo () :third) (funcall x)) =&gt; :THIRD What is different about the LET form that it runs the new definition?
This is one of the reasons why I love writing Rust. There is no mental load like that because mutability is expressed directly in the type!
std string’s API is far from immutable. Actually I hardly ever used it because I was using JUCE &amp; Qt, but that’s another story. But yeah mutability is always assumed as the default, even with strings quite often. I think working at that level of awareness of bits &amp; bytes also frequently encourages a mutable approach because you’re terrified of doing something ‘slow’ - even though that doesn’t matter in 9/10 cases. My approach now is to write immutably first and optimise (possibly via mutability) where it counts.
&gt;I think working at that level of awareness of bits &amp; bytes also frequently encourages a mutable approach because you’re terrified of doing something ‘slow’ - even though that doesn’t matter in 9/10 cases. Amen! When I first started programming (not so long ago!) I would often find articles and blog posts to the effect of "learn C first, and you will have a better understanding, a firm foundation, and carry best practices through into other languages" but, in all honesty, I couldn't disagree with this more. Of course, if you're sure that you want to go into embedded programming or AAA games programming, it's almost certainly good advice. However, as you said, 9/10 cases nowadays efficiency is much lower on the priority scale. Most importantly of all, it's well below readability and reasonability. I think bits and bytes should obviously be mentioned first, as it's good to know how things "actually" work (especially for the specific cases noted above) but anything other than that I think puts too much of a focus on writing efficient (as in, bits and bytes efficient) code, when really that's of little concern when writing the kind of software most people will end up writing. It's strange how I see a lot of people jumping on FP as soon as you mention returning an entirely new object like "oh god! the inefficiency! this is what is wrong with FP, it's just unrealistic and slow!" and yet when it comes to creating hundreds of GCd objects, that's okay because "the VM takes care of it". Yet, if you try to say "the compiler takes care of it" regarding optimising away the allocation of entirely new objects, that's "cheating" or something. sorry, rant. I agree with what you said very strongly :)
FYI: it's going to name-collide with https://github.com/Shirakumo/radiance if added to Quicklisp.
&gt; conditions are caught and returned as (VALUES NIL CONDITION) One suggestion: a condition on its own might not be enough for debugging. You might also want to capture the stack information and return it alongside the condition.
And even if it isn't added to Quicklisp.
Reference counting is a poor approach for Lisp, for multiple reasons (which is why it isn't used): It requires a synchronization between threads for updating the counts, and updating the counts is itself costly. It has large space overhead for small objects, like cons cells. It needs GC anyway to deal with cycles. Copying GC compacts objects, reducing cache overhead. In a language without cycles, and with larger objects, reference counting could work better. Lisp is not that language.
This is not the correct community to pose this question to. We are focused on the lisp family of programming languages. I have removed your submission.
Thank you!How come a (ql:system-apropos "radiance") or a (find-if (lambda(dist) (string-equal "radiance" (ql-dist:name dist))) (ql:system-list)) don't find it, even after updating all dists?
Sensible suggestion, I'm working on it. Thank you.
I see - https://shirakumo.github.io/radiance-homepage/ lists a different Quicklisp dist for it. (ql-dist:install-dist "http://dist.tymoon.eu/shirakumo.txt") (ql:quickload :radiance)
...the fact that it fetches the symbol-function after its redefinition, so it fetches the new value?
&gt; *std string’s API is far from immutable* So are many data structures in mainstream Lisps, like Scheme, which are used immutably anyway.
CCL returns :REDEFINED. Maybe it's undefined behavior? Or, maybe more accurately, yours is a non-conforming program?
Anyway there'd be a conflict, so I'll rename the package. Thanks again, I totally missed it.
Do you know which language invented garbage collection?
If you need more than the answers that have already been given, you can read the [Functions](http://gigamonkeys.com/book/functions.html) chapter from Practical Common Lisp.
Feel free to read [Chapter 5.: Functions](http://www.gigamonkeys.com/book/functions.html) in Practical Common Lisp. It's a nice explanation.
Follow-up: I renamed the package to :RADIANCE-POOL, or :RADPOOL (same URL for the repository though). Error-catching methods now return (VALUES NIL CONDITION STACK-TRACE) Thanks to /u/flaming_bird for the valuable suggestions.
You can just do a Java and prefix with "org.whatever". With package nicknames available in defpackage, it's easy enough for someone to give it a nicer name to use.
Really cool work! Runs fine on my ubuntu machine, however the version installed via brew on MacOS crashes at startup for me (MPB 15, Mojave). Should I submit issue on GitHub?
Others have reported similar issues with macOS, it's being worked on, but just to be sure, feel free to report the issue in case it's something different.
&gt; in languages like Java I never know when I'm passing by reference or by value. I held up a little bit at reading that - not because your general point is off, but because Java is simple enough in this respect that it seemed an odd language to use as an example. Java is pass by value. The language doesn’t let you pass by reference. Now, the values *being passed* are either a primitive or a reference, but that bit of it is just “the primitives are boolean , byte , char , short , int , long , float and double - everything else is a reference” So in the aspects where it matters, it’s a pretty simple test -&gt; is it one of those eight primitives? If not, then it’s something where mutability/side effects/etc could come into play.
Nice to know the work. It's a great effort. Hope to use it in the future.
The only question is why. The reason numpy is in C is because of speed concerns.
Let me clarify: Tl;dr: reread the *goals* section. The point of this library (at this moment) is to set up a reference implementation of something that works, is useful and is intuitive. (I'm dogfooding it myself) Rule 2 (for experts only). Don't do it yet - that is, not until you have a perfectly clear and unoptimized solution.
Thanks! I'll try to check it out more sometime, but don't hold your breath.
Wow, this is exciting! &amp;#x200B; My highlights: \- It contains a sophisticated type inference library for Common Lisp. \- It shows some of the cool things one can do with [https://github.com/guicho271828/trivia](https://github.com/guicho271828/trivia) \- The project contains a demo video that explains all the features. Can we have demo videos for other CL projects, too? Maybe I should start by making demos for my own projects :) \- I always learn some new tricks when reading guicho271828's code.
Now this is the news I have been waiting for!
Yeah, that's all true. But I never wrote Java regularly, and coming to it from C++ I just found it strange that the semantics of function parameters were different for different types, with no annotation to tell me when that's happening. It caught me out a few times when I was dabbling in Java to write an Android app. I'm not saying that it's a hard rule to memorise and internalise, but it's a good example of the kind of complexity that immutability avoids altogether.
Lisp might be just a little slower then C. It is still better to have a native library rather then bindings. If it was 10% of C speed, that would be a major downside, but it is not.
Is there a list of the lightning talks online somewhere?
While not exactly a list, you can find the pdf file that contains all presentations of the lighting talks [here](https://www.european-lisp-symposium.org/static/2018/lt1.pdf).
Great news indeed! Thank you Andrew Lawson for going to all the trouble to making the talks available online, I really appreciated your efforts.
It is likely that the comments have been done this way for backwards compatibility. Take note that Lisp source isn't purely based on S-expressions - comments are just one thing, but another are reader macros that can do arbitrary computations, and indentation that is not preserved when a sexp is read.
Define reader macro #; which eats the next atom and write #;"foobar". Note, that custom readers (like eclector) may not throw away comments. As things are now you still can do #+(or) "foobar". If comments were "ordinary" expressions, then they would get in a way of function arity: (qux 3 4 #;"foobar" 8) ; function is called with four arguments instead of three. That's why reader can't make comments "normal" expressions.
&gt; If comments were "ordinary" expressions, then they would get in a way of function arity: I think it is possible to implement `#;` in a way similar to `#+` and `#-` - the reader simply returns no value if the conditional isn't met. This way, `(qux 3 4 #;"foobar" 8)` would still be called with three arguments just like `(qux 3 4 #+(or) "foobar" 8)` would be valid.
AFAIK the auto-indentation (e.g. in SLIME) is different for &amp;body and &amp;rest arguments.
it's probably due to historical reasons. As in, just happened to be. Technically, it should be s-expression. It is so in Mathematica and Clojure also support it, as secondary form of the usual semicolon comment.
that's why I've suggested it. my point was, that if it is treated as an expression returned by reader, then there is no way around that.
Because it is inconvenient to restrict your comments to be syntactically valid expressions. (And also the hassles of things like what package your comment symbols would end up in.) If you want to manipulate source, your code has to be aware of source format. Things like `(COMMENT ...)` have been used. They just don't offer much benefit. Who cares if the source parser might be a few lines less code if every programmer has to jump through hoops?
I think his idea was not simplifying the parser but using comments to annotate code, possibly in the way Java does. And also to modify the code without losing the comment information (which may be relevant for the human to refer to later - e.g. while debugging). There are probably better ways of achieving both, though.
It reminds me of pandric macro's from Let over Lambda.
Thanks for your comments. I understand that it is difficult to include comments-as-sexpr in general. But one could restrict those comments to specific instructions (like documentation strings for defun, defmethod etc..): &gt; (defmacro :progn (doc &amp;body forms) (declare (ignore doc)) `(progn ,@forms)) &gt; (:progn "let's add 2 and 3" (+ 2 3))` 5 At top-level this would be weird but inside a definition is could be ok. The benefit ? It would be relatively easy to make tools that take advantage of semi-standardized comments: (defun myfunc () (some-code) (:progn (fixme "Should work with ...") (foo x y z))) And we could have tools that analyze code and automatically include comments: (defun foo (x y z) (something) (if (bar x) (:progn (code-analyzer "These instructions are highly inefficient because...") (my-code))))
Hi /u/guicho271828 , wonderful project! May I suggest to please clarify what the license for numcl is? It appears as "LGPL" on the graph, but you are including both the GPL and the LGPL licenses on your project.
nothing prevents you from defining macros which ignore one or another parameter. It is important to be able to distinguish them though, because if comment is optional, then you need to know if the form is a part of the function. Consider the following: (defun xxx () "xyz") This function returns string or provides a documentation? it returns a string. It is documented in the spec and it must be handled with something in a spirt of (if (length= 1 body) (not-doc) (doc)). For removing top-level comments you could do something in this spirit (as an naive example): (defmacro my-progn (&amp;rest body) `(progn ,@(remove :comment body :key #'car)))
Interlisp-D had S-expression comments - they had to since their code editing environment was based on in-image S-expressions. When Interlisp-D was extended to include Common Lisp, they kept all that, and did pretty much what you mentioned above. The visual structure editor, SEdit, displayed S-expression comments in-line looking like normal Common Lisp comments and let you edit them without awareness of the underlying S-expression. [Details here](https://www.reddit.com/r/lisp/comments/6iq2u8/how_was_lisp_edited_in_the_80s_and_90s/djm60yi?utm_source=share&amp;utm_medium=web2x).
That's where I started (https://github.com/codr7/g-fu/blob/master/v1/doc/functional_objects.md), but then having to squeeze everything through the lambda started rubbing me the wrong way...
I still don't really follow. If you are making macros, you can already include any kind of structure you want. If they are comments, they are just for the human. If they are structured for your macro-related code then they aren't comments but code. Comments including semantic annotations are a hack around inflexible or non-extensible syntax in other languages *Maybe* I could see a rationale for something like extensible `DECLARE` clauses, where code-walking code could make use of entries not known to the implementation. But that is probably part of a code-walking facility that you would have to figure out how to make generally useful.
Trying to support QtWebEngine is a very good decision! WebKit sounded good initially, but it's horribly buggy in very subtle ways, which can't be fixed in this Universe... (because it's written in C++, and doesn't have tons of test runs (like WebEngine), because of limited resources... (And being Apple fanboys doesn't help here, because "reality is reality", without pardon...)
&gt;FYI: it's going to name-collide with https://github.com/Shirakumo/radiance if added to Quicklisp. Lol, i originally thought the OP had created a connection pool for Shinmera's Radiance!
Also, package-local nicknames are now ubiquitous, so long package names are no longer an issue.
Interlisp-D was a very interesting system indeed. Thanks for the link.
Holy cow! Are you xah lee? THE xah lee? Your articles convinced me to get an ergonomic keyboard an I also like your opinion on paredit.
LGPL is an extension of GPL and therefore it is recommended to add both texts when you use LGPL. https://www.gnu.org/licenses/gpl-howto.html.en
Thanks for the explanation!
that's not what comments are for. comments aren't *supposed* to interfere with anything past read-time; they're only for readers of the source code. if you want a construct which includes documentation, consider docstrings - those are s-expressions, and they get saved by the reader/compiler/interpreter, and you can retrieve them later from a running image. or, find a function/declaraion/special form which conveys the information you want to include in your comment, like: (declaim (ftype (number) number) 3+) (defun 3+ (n) (+ n 3)) or: (the integer (i-think-this-function-returns-an-integer)) or: (assert (things-are-good-p)) then, the compiler can read your note, and it might be able to offer better optimizations or debugging. tl;dr:comments aren't preserved by the reader because comments are the programmer's way of saying "hey, reader, ignore this next part"
[hyperspec](http://www.lispworks.com/documentation/HyperSpec/Body/v_rd_eva.htm#STread-evalST) Bind \*read-eval\* to false for reads from untrusted sources
The problem happens if you use the reader to get the data in, as pointed by cark, you can disable evaluation, but the same thing used to happen with JSON in the beginning, as people used the eval to get the object in memory and the same security concerns where applicable. You can write you own reader too, making sure that the evaluator is not called. There are packages like [CL-Marshall](https://github.com/wlbr/cl-marshal), that use s-expressions to send and receive data.
I haven't used them myself, but there appear to be a quite few people using Lisp on top of ROS to control robot arms.
Will that really curb malicious code? I'm not much familiar with reader macros, but regardless, couldn't you still write your own reader macro that ends up evaluating stuff?
If you write a reader macro that allows malicious clients to execute arbitrary code, they will be able to execute arbitrary code. If you don't, they won't. I can't imagine a reason you would write a reader macro that enables arbitrary code execution besides that controlled by \*read-eval\*.
 This is the TXR Lisp interactive listener of TXR 215. Quit with :quit or Ctrl-D on empty line. Ctrl-X ? for cheatsheet. 1&gt; (list 1 2 #;(foo bar) 3) (1 2 3)
Sorry I was confused, now it dawns on me that the server would have made \*read-eval\* nil and so the data given by the client can in no way define other reader macros that could eval code too.
I lurk but I keep reading with interest.
Dear someone, thank you for posting this on HN. It got a lot of attention.
Well, if you’re ever in a spot where you need to write Java again, maybe knowing that it has nothing to do with parameter passing semantics and everything to do with every variable being either a primitive type or a reference type will help.
Why do you think that sexps need to be parsed by Common Lisp's READ? Why must they be evaluated? JSON is not Javascript, Symbolic Expressions are not Common Lisp. The web is not a CPU. Make sense?
In defense of the OP, this seems to be about a generic, extensible mechanism for passing information between different environments. The term "comment" might be a bad choice. I suspect the idea is instead "structured information which is reliably transmitted but not fully constrained by standard." This is probably an area that Lisp has not fully explored. E.g. internationalization of strings. You would want a way to instrument literals so that your localization tooling can be informed about the requirements around the literal and for the contents to be controlled by the delivery environment. Other possible applications are things like database or RPC schema or hints to JIT or other complicated runtime environments.
Well, eval() used to be how you 'parsed' JSON on the web.
yay, thanks
It is not just `*read-eval*` see this library: https://github.com/phoe/safe-read
TIL about dugnad. Sounds like a good tradition!
the link: https://news.ycombinator.com/item?id=19904905
FYI it is easy to install guix with their installation script: https://www.gnu.org/software/guix/manual/en/html_node/Binary-Installation.html and we don't need guix to extract the Next tarball.
You spent those years programming C++ doing it wrong. Instead of int foo(std::string in) you should be writing const int foo(const std::string in) const This has been standard practice for correct C++ for some time now. Mutability only where absolutely necessary; everywhere else, use const liberally. At least Rust had the forethought to make mutability require the explicit keyword.
That’s of course what I did, though lately I’ve preferred move semantics where possible. My point was that all this adds mental overhead - what if some other thread modifies that string while I’m looking at it? Etc, etc
Yeah, it's a simple thing but gives a nice excuse to see the rest of the folks in building.
I will use this in my Lipstick project it will be combination of lisp in JS and Lisp in PHP I will use this to create S-Expr RPC same as JSON-RPC but it will send S-Expressions. I think it's better idea then JSON in lisp.
i would like to know this as well. let us know if you find anything good.
there's no reason why lisp/scheme can't be statically checked. racket has typed racket which can be integrated into each other.
Thursday ... Thursdayyy, man :)
Hey folks, I hope you don't mind the advertisement. I'm happy to answer questions if people have them. &amp;#x200B; I should answer the biggest question I usually get, which is "**Is this a remote role?**" We do have some remote employees, but we are currently looking to grow our team in Berkeley, CA. This is especially important for a Lisp programmer hire, currently, because more on-premise expertise is desired.
So I'm looking at the site and I don't see what problem the QPU solves. Does calling the QPU function like an oracle that solves a specific instantiation of some Ising model problem, or some other hard problem? Sorry if it's a kind of low-level question. I'm still pretty new to this whole Quantum Computing stuff.
The QPU is currently not solving problems a laptop cannot solve already. It can, however, solve problems. The usual applications are molecular simulation and combinatorial optimization. You might like this little [video](https://youtu.be/PN7mPYcWFKg). The current limiting factors are things like noise, fidelity of operations, and qubit lifetimes. Each of these are seeing continual and rapid progress, not just at Rigetti, but within groups around the world. One of the goals of this open role is to actually make the QPU easier to program and debug, especially opening it to audiences that can’t or don’t want to learn all this quantum mechanical junk. The more people who learn how to write software for a QPU, the more problems we will discover can be solved—possibly more efficiently—on a quantum computer.
That is very interesting, too bad I don't have a green card or similar, I think Quantum Computing is one of those fields where there is a lot of room to contribute new ideas and take big strides.
I 100% agree with this, especially from folks who are from non-quantum disciplines.
You should start by adding a README explaining what a project is doing, and why it exists, especially if you ask people to provide feedback on them. It might be a personal, I know, but there is something about a repo without a README that makes me think it's either too early to have a look at the code, or the code was simply dumped on GitHub as a backup without much interest in it being shared.
For ECL it is enough to have a working C compiler, libgc and libgmp on the system. Libgmp may be built with portable C interface, the only part which would be required to port is libgc.
Sounds interesting, I'll take a look at that.
CL implementations written with some layer of C are a good bet. Like CLISP or ECL. CLISP is widely ported. See: [https://gitlab.com/gnu-clisp](https://gitlab.com/gnu-clisp)
Just looking at the hyperspec ([http://www.lispworks.com/documentation/HyperSpec/Body/s\_setq.htm](http://www.lispworks.com/documentation/HyperSpec/Body/s_setq.htm)): &gt;*result*\---the [*primary value*](http://www.lispworks.com/documentation/HyperSpec/Body/26_glo_p.htm#primary_value) of the last *form*, or [**nil**](http://www.lispworks.com/documentation/HyperSpec/Body/a_nil.htm#nil) if no *pairs* were supplied. So it returns the last value assigned. (print (setq a 5)) will print "5".
I can't say I've used it before, but Racket (a Scheme mainly used for educational purposes, but is very powerful and general-purpose) has turtle and logo implementations: [https://docs.racket-lang.org/racket\_turtle/index.html](https://docs.racket-lang.org/racket_turtle/index.html) [https://docs.racket-lang.org/logo/index.html](https://docs.racket-lang.org/logo/index.html?q=logo)
JVM if it has a Java virtual machine, ECL and CLISP if it has a C compiler.
Racket's `set!-values` is rather equivalent to CL's `multiple-value-setq` (which returns the primary value of the supplier form). According to R7RS (and earlier revisions), the result of `set!` is unspecified. That is, a conforming implementation can return the value of the supplier form, but it can also return some entirely different value (such as the nonstandard `#&lt;void&gt;`). Conforming programs just shouldn't expect anything in particular.
Cheers for the clarification, good to know.
There is one exception for setq in CL. If the symbol being assigned to is a symbol macro, then setf is used instead, and that can return multiple values. (symbol-macrolet ((x '(values a b))) (setq x (values 1 2))) ==&gt; 1, 2
ECL may compile to a shared object (also to a static library etc). Please see: https://gitlab.com/embeddable-common-lisp/ecl/tree/develop/examples/asdf_with_dependence .
Great, thanks!
I wrote a turtle graphics program in Scheme at [my blog](https://programmingpraxis.com/2012/01/03/turtle-graphics/). Input is turtle commands, output is a PostScript file.
Like one ARPA net was to provide access to supercomputers.
Posix: functions plus grovel over libc?
Posix and libc sounds reassuring, but what's grovel? :)
Grovel is a tool to automatically parse headers and create FFI bindings to C libraries. This approach will work in a scenario, where "main" application is written in Common Lisp and you want to use system libraries in it.
Got it, thank you, I'll study that, but my original question was about exposing functionality from Lisp code to the rest of the system.
calling u/kazkylheku
I'm aware of that hence there was my answer above. I've just clarified here what @n2kra meant.
Hi Sheepduke, vindarel here :) What exactly is wrong with the quickstart ? I'm eager to help. You can also get in touch on gitter: https://gitter.im/40ants/weblocks Here's my little app with Weblocks: https://github.com/vindarel/cl-torrents-web (working, needs a last touch before "releasing")
Here's a little app: https://github.com/vindarel/cl-torrents-web (to be put in production somewhere)
Besides the good point of /u/landimatte , a README can help people setup your code which will further lower the barrier for trying your code. Also a few examples of how to use you code can be really nice for people looking at your repo. (especially as it seems you don't include tests in your repos)
If you don't go specifically through a Common Lisp route, where people already suggested ECL, you could also use Gambit (quite similar to ECL, possibly better performance, possibly problems with threads), or maybe Chez (link against the static Chez kernel and deliver the shared library with bootfiles - have to check if boot file data can be embedded in the binary, I think I may have sen someone doing that).
Thank you, especially for the idea with Chez, as I'm more familiar with Scheme than with CL.
There are some examples on how to use the Chez API in the source package, as well as [some educational code for embedding in other languages,](https://github.com/go-interpreter/chezgo) I think that the Chez API is [really nice](https://github.com/cisco/ChezScheme/blob/master/boot/a6le/scheme.h), there's not a lot of going on, compared to other C APIs for Schemes like Gambit or Gauche. I was able to embed it and pass commands to it in less than an hour. Also the recently added Sregister_boot_file_fd() call [seems to be relevant](https://bzdww.com/article/116294/) for embedding the boot files in the library itself - follow the general pattern, only with writing a library API C file instead of the main.c file in the example. Put all initialization in one of your API functions.
Thanks a lot!
&gt; JVM if it has a Java virtual machine (he means "ABCL if it has a JVM")
Chicken Scheme may also be an interesting choice! It can be embedded in C/C++ programs, [http://wiki.call-cc.org/man/5/Embedding](http://wiki.call-cc.org/man/5/Embedding)
Looks not complicated, thank you!
I know you asked for the opposite direction (calling Scheme from C), but the method they have to include C code directly in Scheme is really great!
I found in the manual how to call into Scheme, like define-external and I can possibly use that from C library wrapper using functions provided by Chicken Scheme.
One extra point for Chicken: the community is really friendly and helpful.
thank you!... i found this, and i'll study some of the example code. &gt; python -m turtledemo i'll keep looking for turtle graphics in Lisp (GCL).
In Common Lisp, `setq` must yield the new value that was stored into the place. If multiple place/value pairs occur, then the rightmost value is yielded. In Scheme "standard procedures" that perform a side effect have an "undefined" value. Demons may fly out of your nose if you rely on the value of a `(set! ...)`.
IIRC, in Scheme "standard procedures" that perform a side effect have an "undefined" value. This is not a specific object; I think what it means is that if you rely on the value of a (set! ...), an error can be raised, or demons can fly out of your nose, etc. The `#&lt;void&gt;` rendition is just some implementor's interpretation of what it can possibly mean to have an undefined value.
&gt; For ECL it is enough to have a working C compiler And yet it hasn't built on windows for like 3-4 years now...
I'm definitely not able to get this job unfortunately, but what sort of qualifications are you after?
First and foremost, being a good software engineer. That means being able to think rigorously about complex problems, work well with others, provide good feedback on designs and implementations, and so on are perhaps the most valuable. &amp;#x200B; Knowledge of some abstract math is preferred. For example, being able to discuss what a vector space is, show some intuition around properties of linear operators, etc. is beneficial, because that sort of discussion comes up often. &amp;#x200B; Not being a super crazy Lisp programmer, in the sense of solving every problem with a new DSL or abusing the reader, or ... is also good. We love Lisp, and we love to use it to solve problems, but we actively shy away from using language features gratuitously. &amp;#x200B; Also important is to be a good teacher. Your colleagues in this role will not all be Lisp programmers. The last thing that's needed is a deep sense of condescension for e.g. Python programmers. We employ folks from all different backgrounds, including physicists at the top of their field who have only learned a bit of Python programming and don't have the time/energy/etc. to learn 50+ years of historical PLT R&amp;D that is in Lisp, just as you will probably not have the time/energy/etc. to learn 150+ years of physics and quantum mechanics and quantum computation. With all that said, being able to share piecemeal aspects of how Lisp lets you do your work better, and showing them in a digestible way, is very welcome.
http://clhs.lisp.se/Body/d_declar.htm#declaration
PostScript is easy, but maybe even better today would be SVG, since Emacs can currently display it directly, and so can browsers. (I'm definitely looking for paths to make Emacs display special types of objects in REPL, like some interactive shells do (Imaxima, anyone?).)
Have a look at Racket: https://docs.racket-lang.org/inside/Writing_Racket_Extensions.html
What? ECL supports both MSVC and MinGW and we even have a continuous integration system running, which checks that any changes don't break the build. If you really have trouble getting ECL to run on Windows you should open an issue on our bugtracker.
That is bullshit, please check your information before you post uneducated comments.
The wording is about an *unspecified* value, which literally just means the RnRS documents don't *specify* what the value is. Back when I first learned Scheme, I was quite bemused by the fact that most implementations religiously returned a *specific* `#&lt;unspecified&gt;` value for all of these cases.
You can get there with any embeddable Lisp: Gambit, Guile (mind the LGPL), Chicken Scheme, ECL, Chibi Scheme, etc.
Bro is this ProgLang from SMCM? LOL whattup
my point is that s-expressions already encode "structured information which is reliably transmitted but not fully constrained by standard"
Sure, but in your examples, `declaim` and `assert` don't have an API defined for, say, a code-walking library to pick up information not belonging to the implementation. They aren't extensible by libraries or frameworks. An "extensible declare" would allow libraries to decorate variables or function names with things like "is a point for dependency injection" or "is a constant fetched from localization information" in a way that Java decorators do.
could you maybe provide an example of the kind of code you'd like to be able to write, but can't? in my mind, if i wanted to define an annotation which i could add to an expression which added some information to my code, i would probably just do it using a function or macro. i listed `declaim` and `assert` because they are examples of common lisp doing this, not because they are ways of defining new annotations, but i still think that the language includes facilities for such annotations --- `defun` and `defmacro` are two common ones, since they define new annotations which conveniently fit into common lisp's syntax. by the way, [cl-annot](https://www.cliki.net/cl-annot) adds python's decorators to common lisp, which might scratch this itch.
I can't really speak for the OP, and only vaguely understand the kind of things that Java annotations are used for. I'm only trying to suggest that there are probably gaps in the Common Lisp approach that could be fruitfully improved. I did see cl-annot in a brief search, but it seems really limited, and feels to me that it is really just an alternative read syntax for S-expressions of fixed arity. So I don't see it as doing very much at all. The main thing I am getting at is that Java annotations, for instance, stick information in the JVM class files so that *after the compiler is done* the binary itself has information that can be reflected over or can be processed by post-compiler processing (e.g. in the run-time environment or in some packaging process). This is completely decoupled: as I understand it, you can compile with one Java compiler, then bring in another tool that didn't even exist when you wrote the code and then use that tool to act on the annotations. I'm not aware of any facility that takes Common Lisp FASLs, for instance, and lets you usefully process them later. (Part of that is that Java code has a high degree of structure compared to Lisp). You can write macros that send implementation-specific information to the compiler, but you can't write them to send implementation-*in*dependent information into the compiled artifact, to get picked up in the delivery environment, except maybe by manually doing things like writing to other files during the macro expansion. Imagine, for example, being able to deliver Lisp servers and then have things like monitoring or service debugging or logging or localization or database integration done with independently-developed tooling, based on library-like extensions to Common Lisp. Here's a toy example: you would be able to pick up a FASL where the code was developed with a "localized constants" extension, point your localization tool at it, and then update all the strings with localized equivalents, producing a new FASL, without caring which compiler version or even implementation the code was compiled in. You could even get crazier: I'm imagining things like generic "GUI toolkit" annotations, where a Lisp application could be later decorated with Android, iOS, or Javascript elements to provide the user experience. The code was originally written to render things in some generic way (say, emitting some kind of HTML-y dialect), but because the rendering code has rich enough annotations on it, you can later design a mobile device UI and plug the Lisp application into it, because the compiled application has labelled all the connection points. All sorts of accessibility applications and so on.
Very interesting. Would you consider a Clojure programmer, generalist, very willing to take up CL?
Very interesting. Would you consider a Clojure programmer, generalist, very willing to take up CL?
Very interesting. Would you consider a Clojure programmer, generalist, very willing to take up CL?
Very interesting. Would you consider a Clojure programmer, generalist, very willing to take up CL?
Very interesting. Would you consider a Clojure programmer, generalist, very willing to take up CL?
Very interesting. Would you consider a Clojure programmer, generalist, very willing to take up CL?
Very interesting. Would you consider a Clojure programmer, generalist, very willing to take up CL?
Very interesting. Would you consider a Clojure programmer, generalist, very willing to take up CL?
Of course, all programmer backgrounds are welcome. What’s important is that you can program, and that Lisp isn’t super foreign or spooky.
I see /u/lispm preceded me two years ago. Hats off to lispm!
Congratulations on the baby!
This is more like a list of impl-specific libraries that comes with LW, not a list of impl-specific extensions to the language (e.g. sb-ext:truly-the ). Do you have such a list?
Do you want to include https://common-lisp.net/project/cdr/ ? Did you disable the issues on the project? Why?
Can you can't add entries to the Project? This is the first time for me.
Project? Which one do you mea--- oooh, there is a kanban board there at https://github.com/guicho271828/common-lisp-extensions/projects/1 ! It was not obvious for me in the slightest. You should perhaps mention that in the README with bolded text. I was too blind to notice it immediately.
I see, will fix soon. But note that this is (atm) not the place to put NEW ideas for extensions. This is merely a leaderboard for tracking the progress across implementations.
I see.
The core CL package may have extensions for its stuff, but a lot of base extension is outside of that package. The language users see in an implementation is for example what is in CL-USER. Many of the language extensions are available in CL-USER via using the core extension packages. An example is the CLOS MOP functionality. &amp;#x200B; |*Implementation*|*Used packages in CL-USER in addition to COMMON-LISP*| |:-|:-| |ABCL|JAVA, EXTENSIONS| |CCL|CCL| |LispWorks|HARLEQUIN-COMMON-LISP, LISPWORKS| |SBCL|SB-ALIEN, SB-DEBUG, SB-EXT, SB-GRAY, SB-PROFILE| |||
BTW, regarding CDR, I will publish a post in the meantime...
No, I don't, but I have been looking for that for quite some time. If you happen to have it, I would be grateful to study it.
It works the other way too, Java has immutable data structures and "the world's best Java instructors" should be telling their students to use them. Bit of an odd article imo.
What I really hate about lisp, more than anything, and the ONLY reason I don't only ever write lisps, is because it's so hard to find jobs that want lispers.
OP's blog post was not really any more useful than to ego-stroke or to get free clicks.
I find Common Lisp too nested, clever and dusty. And it insists on pretending to rule the world, which just isn't going to happen much. I like Lisp as a high level scripting language, but prefer something more conforming and mainstream as a foundation. Which is why I started designing a new Lisp-dialect more to my taste (https://github.com/codr7/g-fu/tree/master/v1).
The conflicts arising from the balkanisation. I am dead tired of being told how things are even though many things are very much just opinions.
What I hate is that we don't have the same amount of people, money, and energy to throw at making Lisp better as the newfangled languages like Rust.
Well, me neither, and that's why I made one just today. https://www.reddit.com/r/lisp/comments/bqe51b/commonlispextensions_list_of_extensions_beyond/
you can now make a new issue, and new issues are automatically reflected in the leaderboard.
I wish CL had tail recursion standardised sometimes. There's a lot of complex parts of a CL implementation like CLOS and restarts, and I guess you can imitate it using do, but sometimes recursion just works better.
That is excellent, thank you very much.
Such is the universe. Linear types are not new.. except for the mainstream, and Rust did the right thing at the right time. Kinda like Tesla ..
Maybe the saying is true: lisp is for when you need to explore new territories.
I hate it because I learned it too soon before I learned another programming languages. I became totally unimpressed by another programming languages. I remember when Google announced Kotlin for Android, everyone shit their pants about how awesome it is. I took a look and just said, "That's it?". When people look at me like that, they would just think, "He doesn't seem to be enthusiastic about technology much". The fact that I'm still young doesn't help too. Almost all Lisp shop only want veteran developers. That's a really good way to kill Lisp.
My only "real" lisp daily usage is elisp, so I do not know how much it count for you. My most hated thing is the lack of complete/powerful precooked libs for pretty anything like C++/Python and other have. Second thing I have is the lack of comprehensive book that not only teach the paradigms, basic language usage or idiomatic things but also a good set of libs for the most ample usage spectrum... I think most of the problem lay in language popularity and userbase, or the fact that lisp programmers are few compared to more well known languages and lisp programmers tend to be seasoned expert or newbie without nearly anything in the middle...
I think it's more of being backed by a large entity, like Mozilla. Or Google with Go.
This seems like one of CL’s non-problems. I use tail recursion all the time. What’s my net negative?
I have never heard this one, but it I like it.
I don't think it's true. Rust has no marketing army like Java or similar. It's popularity is probably due to other factors.
I think you need to actively seek them out. Every year at ELS there’s an ad. As my recent post indicates, the company I work for hires them. I myself have been non-stop continuously employed writing Lisp for almost 10 years. It’s true, it’s not Python. If you trip over a rock you’ll probably land yourself in a Python job. One thing the Lisp community can do is to act more like Python: have a shiny website with idiomatic American English, have an unrelentingly positive community experience, and have a shiny editor that’s not Emacs. Those things take sustained effort and passion, and Lispers haven’t put that work in.
I'll hijack your comment for my general observation, if you don't mind. It seems that the Lisp's problem is (meta-)circular. The community is weak, so there are not enough Lispers. This leads to businesses not embracing Lisp because they can't hire people. So the existing devs can't work on libs and standardization, so everybody is forced to reinvent the wheel, which is easy because of the Lisp's flexibility thanks to meta-circularity. This is quite sad. However you mentioned Rust. r/rustlang has 60K members, while r/lisp and r/clojure has 18K and 16K members, respectively. I would say these numbers aren't low. But, there isn't Lisp, but Lisps – Lisp dialects, and that is probably the main problem. There isn't a singular vision for the language, rather million different paths going in all directions. Which is okay, because research is always a good idea. As an outsider, I perceive Clojure as the leader. Businesses hire Clojure people which is cool. They have mission-critical products based on Clojure which is also nice. There is the benevolent dictator for life which helps a lot. They only "problem" seems to be that it is targeting JVM. I think JVM has/had great reach and it was a smart move to target it. So what is the next step? My first encounter with Lisp was [ClojureScript Koans](http://clojurescriptkoans.com/). It ran in the browser – platform with the best reach – better than JVM. Targeting browsers with WASM seems to be the hot new thing. Rust is way ahead of everybody. I haven't seen any progress within Clojure(Script) community regarding it. The question that keeps bugging me is: **Do non-Clojure Lispers hate (or tried) Clojure?**
&gt; Do non-Clojure Lispers hate (or tried) Clojure? Yes, I don't like anything about Clojure. No, I haven't tried, but I have no reason to.
Getting started with it. Okay, may be, because I was a beginner in programming itself: I had just started programming (being introduced to C++ in school), just started using Linux, just started with emacs. I got my hands on Paul Graham's ANSI Common Lisp, after a bad experience with Tutorialspoint's LISP Tutorial. The trouble was: how do I run the code? I didn't know about *implementations* like SBCL. I didn't know about portacle. I wasn't familiar with emacs. I sure, did, learn about *clisp* from Tutorialspoint - but the REPL it provides is fairly basic, and therefore, irritating. I didn't even know about *--help* or *man* on Linux! Even after portacle, another learning curve was the paredit mode. So, how do I think could the experience be improved? List the prerequisites to enjoy lisp - * Portacle - or working with emacs and its packages * Working with quicklisp, and manually installing packages from github * Paredit mode * Implementations, and getting comfortable with linux *--help* and *man* * Making packages - introduction to asdf and all PS: For me, for some reason, emacs24 didn't connect with MELPA packages - and it took me forever to discover this. Switched to emacs25 and things are working fairly easily.
&gt; Rust has no marketing army like Java or similar Being backed by Mozilla (a very visible organization) and also being used to (re)write Firefox (arguably Rust initial "killer app") *is* a marketing in and of itself, and a significant one at that. Compare to Common Lisp or (the multitude of) Scheme (dialects), where we have neither an organization nor a "killer app" to help back or market the language.
I’m not a fan of Clojure. I used it to build an advertising product on contract. It has the skin of Lisp, but tears away much of what makes me feel like Lisp is useful for. I couch Clojure more as a sanitary functional language with S-expression syntax and an opinionated ruler.
I know but it has nothing to do with the cosmic amounts of money spent at Java by Sun and Oracle. Mozilla is a pebble in that world. And maybe Rust was accepted as a potential firefox building block because it was already a great piece of work. Not the other way around. Lisps don't lack killer app, they were just 20 years ahead of the market.
&gt; Almost all Lisp shop only want veteran developers. To be fair a lot of companies in general want a freshly graduated programmer with 15 years of experience in at least 3 languages. If you think you know enough Lisp to work full time with it, just apply for the position and see what happens. In most cases the interview will make clear that you know what you’re doing. The fact that you’re young might even appeal to the companies as they can potentially benefit from you longer.
&gt; Do non-Clojure Lispers hate (or tried) Clojure? Yes I did. No, I didn't hate it, but I still prefer Common Lisp or Scheme over Clojure for, ironically enough, the same reason as why many people like Clojure: the fact that it is a hosted language. I've found that, despite what people claimed, when writing Clojure, you constantly *need* to drop down to the hosted language (be it Java with Clojure or JavaScript with ClojureScript) to perform many mundane operations. This means that you *need* to know the hosted language to use Clojure effectively (especially if you plan to use the hosted language's libraries or reason about performance of your code), which means things get complicated real fast if you didn't already know the hosted language. So, my 2 cents is that Clojure/ClojureScript is okay if you're stuck with a project that has to use either Java or JavaScript (because writing Clojure/ClojureScript, despite all its warts, is still a million times better than having to deal with Java or JavaScript). OTOH, if you don't need to use Java/JavaScript (and their libraries) in the first place, then I see no reason to choose Clojure over Common Lisp/Scheme.
Is there any definitive spec for Clojure aside from the implementation? Because if there is, it might be possible to port the whole thing to Chez.
&gt; a sanitary functional language with S-expression syntax Strictly speaking, Clojure's syntax is not an s-expression. It is an [edn](https://github.com/edn-format/edn).
Lisp is fine, in my opinion. Many of the people who write Lisp for whatever reason though prefer to use it as a tool for their own itch-scratching and learning (e.g., how can I re-invent the list comprehension as a macro?) as opposed to a tool to solve their problems. Very few of even the “famous” internet Lispers I know have written bonafide applications or services with it. I contend that an ecosystem of deployed applications and services actually irons out implementation difficulties, deployment difficulties, and enriches the library ecosystem. Including the boring stuff. I think it’s insightful to see that boring is suddenly OK when you have a bigger goal. In contrast, boring is not OK when you’re just in it for your own personal fun. I’d like more boring things to be OK for existing and new users of Lisp. At Rigetti, we’ve faced issues with packaging, deployment, and interaction between Lisp and other languages. Our own internal team, plus the likes of the SBCL devs, Turtleware &amp; Daniel Kochmański, and others have pushed to improve these things. Anything from GC tuning, to shared library bundling, to supporting Thrift, to improving ECL for shared library deployments. None of that is “sexy” work (as implied in this context), but it actually helps me and others get work done.
Meh, it seems like a made-up thing to feel different.
&gt; Is there any definitive spec for Clojure aside from the implementation? I've no idea. You better ask people on /r/Clojure/ about this. &gt; Because if there is, it might be possible to port the whole thing to Chez Ha! Now that might be enough to make me use Clojure again. Incidentally, I remember that years ago (back when Clojure hype was at its peak) there were several projects that tried to port Clojure to Common Lisp or Scheme (not Chez though, this was way before Chez was open sourced). I wonder what happen to those projects...
 &gt; maybe Rust was accepted as a potential firefox building block because it was already a great piece of work You got to backward. Rust was created internally by Mozilla, specifically Mozilla Research. As such, Rust has the full backing of Mozilla from the beginning. Also, even though they are tiny, I'd argue that Mozilla's reputation and influence is much more far reaching than the size of its bank account. Hell, almost all of my friends first heard about Rust through the announcement that Firefox will be rewritten in it.
&gt; What’s my net negative? IMHO, nothing, as long as you understand that not all Common Lisp implementations support tail-call optimization (TCO), which could make your code less portable (especially if you're writing a library that you intend to share with other people). But for your personal projects? Knock yourself out.
Elitist odor around it (created by "Beating the averages" and alike). It makes more harm than good to the language and community, attracting some toxic persons. Using it daily for fun and from time to time at work for auxiliary utilities.
I think rust started as a pet project from Hoare then Mozilla accepted to let him work full time on it. My theory is that it was already a well carried project by a wise guy. That's what makes Rust interesting, not Mozilla's brand.
&gt; What I hate is that we don't have the same amount of people, money, and energy to throw at making Lisp better Lisp had better marketing than any other language: AI, Lisp Machines, expert systems, all that academic legacy. It just doesn't have much to suggest to programmers. It has a barely readable syntax, slow dynamic nature, lack of static typing. Macros and homoiconicity are nearly the only selling points of Lisp, yet IMHO people don't need metaprogramming that much in their daily activities. How would you market Lisp? Unlike Rust it doesn't have low footprint and powerful type system. Unlike Go it's not simple enough. Lisp is not good in solving actual problems, you could just use any other language and be more productive due to static checks, plethora of libraries, small footprint, standard facilities etc.
The [community and the individuals comprising it](http://www.winestockwebdesign.com/Essays/Lisp_Curse.html) has often been raised as its greatest weakness. This led to fragmentation into dialects, redundant libraries, etc.
There is no definitive spec for clojure. I think it would be difficult to do with the way clojure exposes some of the implementation details of the platforms it is hosted on. For example, numbers behave differently in clojure and clojurescript because they just use the numeric types of java and javascript respectively.
&gt; For example, numbers behave differently in clojure and clojurescript because they just use the numeric types of java and javascript respectively. Ewwww, yucky! :-p
Yeah it's not always the best thing, but if clojure implemented it's own numerics it would essentially end up with only boxed numbers that would kill performance. It's an interesting trade off.
&gt;This is quite sad. However you mentioned Rust. r/rustlang has 60K members, while r/lisp and r/clojure has 18K and 16K members, respectively. It is kind of bad circle: Not many people write Lisp (common lisp/scheme, clojure has better market) =&gt; companies do not want to draw into some tech they may hard to hire new people =&gt; no new guys want to learn it (even some guys never heard it). &amp;#x200B; I keep telling my co-workers how good lisp is. But I have to admit it there are not many companies use it now (maybe a lot but I just heard Grammarly). And I am afraid I am the only one write Common Lisp for fun in a whole company. &amp;#x200B; I think Lispers should develop some productive tools, libs, or applications to show outside world that Lisp can use in product. And it works well.
I can’t tell if this is trolling or simply deep misinformation.
I think you've missed some things: - CMUCL supports truly-the. - ABCL supports extensible sequences. - CMUCL supports freeze-type. - ECL (at least) supports package locks. - CCL has thread-safe (lock-free!) hash tables. - CCL, Allegro, Lispworks, SBCL, and CMUCL all support custom hash tables.
&gt; Barely readable syntax: I disagree but won’t argue the point. I have a hard time reading Rust’s generic line noise. Take a look at a structure and a function declarations in lisp, they are barely distinctable. It looks like a naked AST or some intermediate representation, really hard to read for a human, yet easy for a machine. Languages are for humans though. &gt;Slow dynamic nature: You get what you pay for. Don’t use dynamic features You can't not use dynamic features because the language is dynamic. Even when you use `(declare ...)` for declaring types, you still have a lot of static checks you won't have in static languages. But the main problem with its dynamic nature is lack of correctness rather than the lack of speed. I really don't want to be thrown in debugger or get exception in a working program, I want it to work if it compiles. &gt;What about being standardized Like SML, Ada, C, C++ and dozens more. How do I benefit from this? Standard is a burden rather than a benefit. It's great for a compiler writer, but a burden for an application writer, since standards are rarely enough and you need additional features, hence you are either using non-standard language anyway, or restricted by a standard. CL standard hasn't changed since 90s and it's outdated. In case of lisp even the crucial things like threading and ffi are non-standard anyway. God, even TCO is non-standard. &gt;world-class interactive development How is it better than any other repl in any other language: OCaml, Haskell, Scala. Lisp REPL is terrible due to its mutability, hence you could get the state you would never achieve in a working program. &gt;its selection of compilers, its commercial support, its library ecosystem Or rather lack of these, if you compare it to mainstream languages.
Throwing money at Lisp to turn it into a piece of shit would be counterproductive.
&gt; newfangled languages like Rust Why not simply write a Lisp program to translate Lisp to Rust? Then Lisp programmers could stay relevant without letting their Lisp skills get Rusty.
I am usually happy to prepare a response to claims like these, but just about every sentence you wrote just isn’t right in some way. Some of the statement are borderline intellectually negligent. I really mean this in the most polite way possible, but I highly suggest you take a deeper look at Common Lisp, and take an honest approach to its comparison with other languages. Peter Seibel has a free book called Practical Common Lisp and he frequently makes comparisons in the context of what he is teaching. If you spend a little time with it, you might be pleasantly surprised with what you find!
&gt; (I will say this: No compiler on Earth will give you the guarantee that if the code compiles, it works. F* is doing fine to a very high extent. OCaml, Haskell and Scala do fine in 99% of cases if you know how to use the type system and encode invariants in types. Sure, they are not as great as Coq, but they are doing a much better job then dynamic languages, and falling back to exceptions and dynamic checks in exceptional cases, when the type system is lacking expressive power. To catch 80%, 60%, even 20% of bugs in compile time is still better than nothing. In lisp it's just a mess, where you can't ensure even the most simple invariants statically. &gt;I really mean this in the most polite way possible, but I highly suggest you take a deeper look at Common Lisp, and take an honest approach to its comparison with other languages. &gt; Some of the statement are borderline intellectually negligent. Yeah, I think that's the greatest problem with lisp community. Lisp community believes Lisp is The Language, yet no one knows what makes it a better language. Please, make an intellectually acceptable description of common lisp features which make it a better language to do the job, that's the point of the conversation. I've tried common lisp for many times for years (I emphasize CL, because I use scheme all the time and find it a great language), and see only a slow barely readable average imperative language with no advantages except macros (which, unfortunately, are not hygienic). I don't see any reasons to use it, and neither does the industry in general it seems. CL community needs a better way of marketing rather than saying "try it and you will become enlightened".
&gt; It implements most of the unique features of Haskell and OCaml. In some respects, Qi surpasses them. For instance, Qi's type inferencing engine is Turing complete. Since when an undecidable type system is better?
Because Lisp has a lot of stuff you cannot do in Rust: garbage collection, recompilation at runtime, late binding, etc.
&gt;(No compiler on Earth will give you the guarantee that if the code compiles, it works.) F* is doing fine to a very high extent. F* solves the halting problem and can understand variable names to the extent that it can say `hey, you wrote "add1 x = x - 1" and add1 is supposed to add not subtract`? I would *love* to see that.
What are short arrays?
Wouldn't that defeat the whole purpose of Clojure? I mean, why build a pseudo-Lisp on top of another language if the other language is already a proper Lisp?
&gt;It is kind of bad circle: Not many people write Lisp (common lisp/scheme, clojure has better market) =&gt; companies do not want to draw into some tech they may hard to hire new people =&gt; no new guys want to learn it (even some guys never heard it). There are a lot of guys out there who encountered Scheme in college, and it left a bad taste in their mouth, and for them Scheme is perfectly representative of what Lisp is all about.
Good points in the comments. I also don't like the fact that Lisp has such a small community, and it shows. There aren't many good libraries/frameworks for many tasks - often you can either find a bunch of them (testing libraries - so many of those), or almost none at all (machine learning, web development). Even if you finally find them, most of them are not suitable for use - they either lack a documentation, features, are not maintained anymore, not in quicklisp or have some stupid license. Usually a library that's "good" for CL is still a lackluster compared to other languages. People don't develop documentation, so even if there is a library out there, it's useless. To prove some of my points: - If you want to use css-selectors with cl-html5-parser, you need to quickload css-selectors-simple-tree too. I remember spending too much time trying to figure it out. - There are some JSON parsers, but they either lack some features, documentation, or maintenance, so even such a simple task requires you to use e.g. alists instead of hash-tables and read the code, because library's design &amp; docs are lacking. - Even though it looks like there is a community of game programmers for Common Lisp, there is no good framework for writing games in Common Lisp. - Machine learning is practically dead on CL. This came as a bit of rant, so to end things on a positive note - many people are doing good work with Common Lisp and the situation is getting better(or so I think). Portacle is a good step towards providing a better developer experience for new users. SLIME is great too. Compilers are getting better, new projects, such as "next" browser are showing up.
Hopefully this part is solved with https://lispcookbook.github.io/cl-cookbook/getting-started.html, Portacle, Lem (self-contained, ready to use), Atom pretty good, or more editors, also this emacs+lisp tutorial https://lispcookbook.github.io/cl-cookbook/emacs-ide.html (to improve) + making packages in the cookbook. But I feel you.
Keep up, and I'd advise to show your lisp: write a blog, do open source work, write documentation… at least that's my recipe: I was recently contacted by the guys at Atlas and I now work in CL in an awesome team \o/
&gt; I just heard Grammarly) there are more: https://github.com/azzamsa/awesome-lisp-companies Obitz and Kayak are still powered by Google's ITASoftware, it still runs the underground of capitals, Rigetti chose it for quantum computing,… https://lisp-lang.org/success/ PostGre's pgloader was rewritten from Python to CL,…
heey please help the project! You can find the issue thread for each topic
&gt; neither an organization nor a "killer app" We at least *had* killer apps: https://lisp-lang.org/success/ The the Next browser is coming :) and we have the CL Foundation, which I'd like to see do more corporate organisation.
Ok it's hard. Want to share that my experience tells that there are few job announces, but companies that reach to you (to me :) ) given your public activity.
Just in case: https://github.com/CodyReichert/awesome-cl (some people are still pleasantly surprised to discover all this)
The article you linked argues that Lisp's *expressive power* is its greatest weakness.
What’s wrong with it?
It bottomed out fast for me when I tried to optimize code. The error handling and recovery experience was sorely lacking.
Thanks, knew it though.
I've made my plead against crippling our freedom as programmers several times, with various levels of agreement in this community. I think Clojure is just not my style, but it is good for a lot of people, I find Common Lisp very liberating, it does not try to make the programmer follow its rules, instead it is a very maleable material that molds to your style. Clojure is more opinionated than Scheme or Common Lisp, and you can feel it, it tries to be pure functional, and if you like that, that is ok, but I like Lisp's fluidity to be able to be turned into any paradigm you want /need, putting the responsability in your hands to know what you're doing.
I kind of like my editor to look like it's from 1976.
&gt; F* is a domain specific language for proving correctness Nope, it's a general purpose ML dialect with dependent types. &gt;but people are stupid and it seems to me that having to provide a description of what it produces is also another source for errors. People are stupid, so writing no description and types is less error prone than thoroughly typing your code preventing your colleagues from shooting their feet? &gt;Nonetheless, having a compiler that emitted style-warnings like the add1 example would be really funny. add : x:int -&gt; y:int -&gt; int{add x y = x + y} What's funny about it? Contracts and refined types are quite ubiquitous those days: Java can do it, Ada/SPARK can, C with Frama-C. Any serious production language.
&gt; Dunnet Hey, it was 1992. Give me a break. ;-)
&gt;Nope, it's a general purpose ML dialect with dependent types. Maybe that's F#? [F* looks quite like it's put a bit of effort into proving to me](https://www.fstar-lang.org/). &gt;`add : x:int -&gt; y:int -&gt; int{add x y = x + y}` So, your definition is in the type description now? How is this different to just writing the function? &gt;What's funny about it? The funny thing was if the compiler read `add1` and inferred the function was supposed to add something. As in, it read `add` in the function definition, saw a `-` in the body and wondered if that's a mistake.
Unfortunately, the Serverless thing is owned by my employer, and they don't want to release the source.
Mee too, for what it’s worth. I actually edit on a VT520 terminal.
&gt;F* looks quite like it's put a bit of effort into proving to me. And? It's a language with dependent types, so you have proves for free. It also does proving automatically using Z3. How does it make it domain specific? It's not alike Coq and allow impure code, only functions in type domain should be total. It also can be compiled in Js and assembly, and is used in some parts of the tls layer in Firefox. &gt;So, your definition is in the type description now? How is this different to just writing the function? Because it's checked in the compile time. I want the compiler to check the invariants I've designated. &gt; The funny thing was if the compiler read add1 and inferred the function was supposed to add something. As in, it read add in the function definition, saw a - in the body and wondered if that's a mistake. I would let such a compiler to just write the code for me.
The thing I hate the most is how painfully slow text I/O is. I wrote an optimized test program to see how fast different Lisp implementations could read and write files: [https://gist.github.com/j3pic/2000fd02c01a2db2fdb3fbcf4dad9ae7](https://gist.github.com/j3pic/2000fd02c01a2db2fdb3fbcf4dad9ae7) While Lisp is quite fast at reading binary data (`:element-type (unsigned-byte 8)`), every Lisp implementation I looked at was really, really slow when it came to text (`:element-type character`), or else I was unable to run the test because of unexpectedly low array size limits. I tried reading a 20MB text file as binary and text into a buffer big enough to hold the entire file. Here is the amount of time each Lisp implementation took to read as text: &amp;#x200B; |SBCL|0.492000 seconds of total run time (0.412000 user, 0.080000 system)| |:-|:-| |ECL|run time : 4.596 secs| |CLISP|ARRAY-DIMENSION-LIMIT is too small.| |CCL|ARRAY-DIMENSION-LIMIT is too small.| |CMUCL|1.612 seconds of user run time| SBCL only took "0.072000 seconds of total run time (0.020000 user, 0.052000 system)" to read and write a binary file, and the other implementations were similarly fast.
Does Coalton (plan to) support any form of dependent types?
There are two assumptions in your code: * the encoding is unknown and the encoding the Lisp will use is unspecified * the number of characters read is also the same as the file length -&gt; this depends on things like the platform and the encoding used -&gt; see the return value of READ-SEQUENCE, which says how many characters actually have been read
Though I like it better when it also is implemented in Lisp.
The lack of static typing.
&gt; Being backed by Mozilla (a very visible organization) and also being used to (re)write Firefox (arguably Rust initial "killer app") is a marketing in and of itself, and a significant one at that. Lisp was backed by DoD, DARPA, Lucent, LMI, Symbolics, Xerox + investment from Dec, HP, Sun. Didn't help. Lisp had more money and marketing than any contemporary popular language: perl, python, ruby, hell even java.
I guess 1977 is OK too.
I'm surprised CMUCL has so many features that SBCL doesn't have. Not that I'd ever use them. [Generalized function names](https://pmsf.eu/pub/cmucl/doc/cmu-user-2010-09-27/extensions.html#toc65) sounds fun though.
You can remap Emacs to behave like famous IDEs or editors bindings. Doom and Spacemacs are definitively "shiny editors"
I hate that there are anymore that many of active and importants LSP projects. Projects that are interesting for non-lispers and average users. That might be one thing that can boost LISP yet again to mainstream devs top list "learn x language"!
\&gt; Lisp was backed by DoD, Nasa, DARPA, Lucent, LMI, Symbolics, Xerox + investment from Dec, HP, Sun. The source of funding was a lot DARPA/Government. LMI, Symbolics, Xerox, DEC, HP, SUN, were after that money and delivering into that market. For large companies like Xerox, DEC, HP, SUN, IBM, TI, ... Lisp was never more than a side show - helping them to sell some higher-end hardware and with some AI business. Without government funding and government demand, the market quickly went away and these companies quit that market almost overnight. \&gt; Lisp had more money and marketing than any contemporary popular language: perl, python, ruby, hell even java. Don't think so. Lisp money/marketing is tiny compared to the Java business.
A blog article without open-sourcing the thing would be equally interesting !
&gt; Without government funding and government demand, the market quickly went away and these companies quit that market almost overnight. Sure, but Lucid alone (a pure lisp busyness till they switched to C++) was quite big &gt;bout this same time Lucid’s revenues were approximately $6 million per year and growing at a modest rate, but not nearly so fast as we had hoped and planned for. The company was up to 75 people, almost all technical—we did almost all our sales through OEM royalties and development contracts, so we didn’t really need much marketing or sales. In fact, we considered ourselves the OEMs’ development arm. And symbolics had an even better net income on its peak. And unlike mozilla or oracle/sun, these were pure lisp companies selling lisps. The resources behind lisp vastly surpassed those behind the vast majority of programming languages.
&gt; Lucid alone (a pure lisp busyness till they switched to C++) was quite big $6 million revenue per year with 75 people? That's not big. Not even 'quite big'. &gt; And symbolics had an even better net income on its peak Sure, it was larger and sold hardware, too. &gt; The resources behind lisp vastly surpassed those behind the vast majority of programming languages. Not really... Lisp was tiny then in comparison. The big companies were DEC, HP, IBM, SUN, SGI, Apollo - for none of them Lisp was a really critical part of there business. I would guess the whole Lisp market for that decade was just 1-2 billion USD.
The defining feature of the Clojure family of languages (JVM-Clojure, Clojurescript, Hy, G-Fu, ...) it to host something almost, but not quite, entirely unlike Lisp on top of another language and ecosystem The host could be Lisp. Why not?
So the Next Browser is basically a graphical web browser if it was inside emacs?
Nope. Its a Common Lisp project built upon webkit-gtk web engine.
LispWorks on Windows, with a 100MB test file: User time = 0.140 System time = 0.171 Elapsed time = 0.303 Allocation = 104886040 bytes 0 Page faults (Thinkpad Extreme x1)
As one commenter in this thread said: "Lisp is for when you need to explore new territories". Did any exciting new feature came out of the experimentation? I saw hierarchical history which is what I wanted for a long time, but somehow I can live without it. Do they plan to have UI?
I tested the code on LispWorks (I pasted results from compiled buffer above), and it is faster than Python3 on my machine. But I need to compile it, otherwise it will congest the repl with the test data.
&gt; Lisp was tiny then in comparison In comparison to what? Companies used Oberon, Pascal, C, Tcl, Simula back in the days. Now they use Ruby, Python, Erlang, Scala, well and Java &amp; C++ ofc. Languages like Ruby, Python managed to achieve mass popularity with the significantly smaller resources available than Lisp had. That's the point. Behind lisp there were two lisp machines companies, one company doing the compiler solely, DARPA and DoD, standard. Behind python there was an relatively ignorant guy working in MS, and MS wasn't even interested in python. Yet python was adopted by Google later, and lisp wasn't. The same with Ruby, Erlang (Ericsson wasn't interested in Erlang and shut it down, hence OTP was born).
Do you use http://github.com/cxxxr/lem/ ?
You are totally over-estimating resources and hype that were put into Lisp+AI and into a very specialized higher-end market. Supporting the development, research and deployment of AI software was never a mass market. For example the most prominent Lisp-based AI tools (Knowledgecraft, KEE, ART, ...) were in the range of $50000 for just the software - and we not even talking about the machine that was necessary to run it. Lisp was develop originally for AI development (-&gt; McCarthy), which shaped its design, selected its user base and it remained dependent on symbolic AI hype cycles (-&gt; cold war funding). It rarely addressed a mass market (exceptions exist like AutoCAD/AutoLISP), so the question why it never got mass market adoption is like asking why Porsche sold fewer cars than Ford. The answer is easy: Porsche does not address a mass market. There is a lot of hype around Porsche, though.
hmm that's awesome
Hey, it's a working program so no foul.
Not planned, no. Maybe GADTs or type classes, or maybe ML signatures/functors, but not dependent types.
I love Emacs, it's the only editor I use. But nobody I know considers it a shiny, packaged product. (But that's just anecdotal and opinionated!)
No, I'm using Hemlock derivatives.
Nobody asked their opnions! lol
UI? Emacs-like Hydra are on their TODO. But Next aims to be like Emacs, minimal UI, extensibilible in every aspect, no mouse, chromium packages, easy interface with system packages and more...!
note: the experimentation is ongoing.
What's SBCL's time on your machine?
Why bother working to get *almost* Lisp when your starting point is already Lisp?
Dynamic typing is a feature, not a bug.
With same 100 MB test file: Evaluation took: 0.641 seconds of real time 0.625000 seconds of total run time (0.046875 user, 0.578125 system) 97.50% CPU 1,408,605,588 processor cycles 104,857,616 bytes consed
and if I did need to use Java, I'd rather use ABCL
&gt;garbage collection non-GC'd lisp when :')
Probably never, if you like your circular objects and sanity.
It's a matter of opinion. Dynamic typing is a feature, but one I no longer find beneficial - I'm sick of tracking down bugs that static-typing would have caught. In my own experience, dynamic typing makes it easier to write the code quickly; static typing makes it easier to write it correctly and to maintain it. A team-mate and I are introducing static typing in python to the rest of our team, because we're sick of spending far too much time tracking down type-related bugs, and doing forensic archaeology to figure out what types a given function expects to operate on. For a concrete example, I've spend a couple of *weeks* refactoring one codebase, just to understand exactly what's going on so we can extend it safely; with static typing, that would have been a couple of *days*. And before you tell me that more tests would have been helpful, that's one of the purposes I see type annotations serving: a very compact way of defining integration tests, in complement to the unit tests.
Sorry for the late reply, I got some problem with my Gentoo system. As for the quickstart page, at the very beginning of it there is a command `(ql:quickload '(:weblocks :weblocks-ui :find-port))`. However, when I evaluated it quicklisp told me that `System "weblocks-ui" not found`. Could you please elaborate?
By the way, glad to see you here Vindarel ;-)
This is amazing to hear. I will look more into the requirements when I get home. I am in love with Lisp dialects, currently working with Clojure the most since it lets me target our Java stack at work :D. I have never used Common Lisp outside an academic setting but would be willing to give it a go. The only thing that worries me is my knowledge of quantum computing. I know about it on a very superficial level due to my C.S background. I love all programming languages really. But Lisp has a special place in my heart.
You are right. This Weblocks and weblocks-ui are not on the current Quicklisp. There's the orange warning at the top, but no download links. This could be improved. Either clone those in ~/quicklisp/local-projects: https://github.com/40ants/weblocks https://github.com/40ants/weblocks-ui/ Or use Ultralisp: http://ultralisp.org/
Nice. Does it have a meta key?
Installation instructions being updated: https://github.com/40ants/weblocks/pull/34/files How to use Ultralisp
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/common_lisp] [What is the best way to write docstring in Common Lisp?](https://www.reddit.com/r/Common_Lisp/comments/brn439/what_is_the_best_way_to_write_docstring_in_common/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Thank you so much! I will check it again later.
&gt; ELS There are some clojure jobs. I work as clojure dev but I also love CL.
It does, but it sends ESC. That’s all I got to work.
I all-caps function and variable names, and don’t break lines. Look at examples [here](https://github.com/rigetti/quilc/blob/master/src/analysis/fusion.lisp).
&gt; how to represent rich text in doc strings Don't take my opinion as gospel. That said, my opinion is that you *don't.* If you generate marked-up HTML documentation from doc strings with markup, they cease to be interactively useable docstrings and become source code for your HTML documentation. Possibly better to generate *both* your HTML documentation and your docstrings from elsewhere. (defun myfun (....) ;; look ma, no docstring ...) (my-fancy-doc myfun (...) "Tons of markup here, rendered to docstrings my IDE can display, rendered to HTML the search engine can index, rendered to PDF my boss can print out and file away, ....")
&gt; P.S. Just found cl-str was made by Vindarel. I love this package. Nice work! Thank you very much ! (and it isn't over, I recently added case predicates, and I'll integrate cl-change-case). &gt; the Scriba format. The package cl-str uses it. Not anymore, because Codex requires you to write a line for every function and macro you want to get documented. It does produce excellent documentation for other happy users: https://commondoc.github.io/codex/#users I just write a readme. I made a little overview of documentation generators: https://lisp-journey.gitlab.io/blog/overview-of-documentation-generators/ If you're into RestructuredText there's cl-domain, based on Sphinx.
I always find the "Any Language You Want" line silly - Trevor Blackwell wanted to write in Smalltalk, but got shot down even after he did all the necessary work.
Regarding pbewig's comment in the linked discussion: "Many people have tried to fix Lisp. All have failed." Is anyone familiar with such attempts?
I don't see anything wrong with Lisp.
In terms of syntax, [Sweet expressions](http://wiki.c2.com/?SweetExpressions) maybe? Generally speaking S-expressions are accepted as a good Lisp syntax, since it's exactly the same as the lists they process.
https://en.wikipedia.org/wiki/M-expression
I think PG was talking about technical constraints here. I imagine trying to deploy a lisp application to windows 95 and 98 back then would have been a big hurdle. &amp;#x200B; That line hasn't aged well though for different reasons: If you pick lisp for web applications today you end up with much less tooling all around. In some cases it may still be worth the tradeoff, but when viaweb started it's not like there was significant dynamic web tooling for any language.
I'm personally not a fan of white-space as nesting (Python-style). For now, I'm considering C-esque atomic structures where parentheses are for smaller-scale grouping and curly braces are for larger-scale grouping. I'm not against somebody proposing or refining white-space styles, it's just that I'm limiting my focus to the C-esque experiments right now.
As described in the linked discussion, everyone is different and no language/syntax will make everyone 100% happy. But a big enough percentage of programmers have found Lisp syntax difficult that there is a reason to explore alternatives.
Sexprs are perfect. What you seem to be looking for are data types and pattern maching.
I think most people's aversion to lisp syntax comes from the fact that it's seems so different than anything they've used before. I have yet to meet anyone who, after writing some non trivial amount of lisp, still had an issue with the syntax.
What I think you'll find, ultimately, is that what non lisp people want is complicated grammars that encode program structure in syntactic variation. But a core tenet of lisp is consistent structure at all levels. It's where homoiconicity comes from, macros, and other powerful advantages of lisp. I don't think you can make lisp people happy by chopping out that core simplicity and consistency. And I don't think you can make normies like it without basically making something that's just not lisp. Playing both ends against the middle is a losing strategy in programming language design.
Figuring out a way to write Lisp in C syntax is a lot like writing a bunch of C macros that allow you to write C in Basic syntax. I.e. moving the wrong way along the hierarchy. Especially if it makes structured editing more difficult. A more productive activity would be programming your editor to display normally-formatted Lisp in an enhanced way.
It's possible the second group is self-filtering: those who don't like it tend to leave it such that they are not among the group of those who wrote some non-trivial amount of Lisp. People tend to gravitate toward languages they prefer and avoid those they don't. After pondering this a good while, I've decided that the tree-vs-forest issue is the biggest "visual" problem with it. It needs more variety, and the variety has to communicate something visually about the intent or purpose. In moth code, seing "(" versus ":" versus "{" instantly tells the eye generally where in the statement you are looking at. With lisp you have to read or interpret the operator to give you the same info. That's more mental processing steps, at least for my head. **My head can turn symbols into info faster than it can labels.** That's just how my head works, for good or bad. It didn't seem to improve noticeably when I tried to get used to it. maybe after 10,000 hours it may finally "kick in", but I don't have that kind of patience. Even if we accept that it's just a matter of familiarity (exposure time), that's still something that has to be dealt within practice. if people don't want to deal with a longer learning curve they won't. That may make them "bad" or "lazy", but **people are what people are and we have to live with that fact**. I believe there is a similar situation with GUI's versus command-based UI's (CUI's). The most efficient software I've seen in terms of productivity was with CUI's (when well-designed). However, it's a longer learning curve until the additional productivity is actually encountered for most users. You can chew them out for being lazy, but most users prefer GUI's. That's life.
&gt; I don't think you can make lisp people happy by chopping out that core simplicity and consistency. I don't expect to please or win over Lisp fans with moth syntax. Those who like Lisp will probably stay that way. I'm looking for a better compromise between the two kinds of approaches, and am wondering what else has been tried. It still will probably not make everybody happy (nothing will), but hopefully would provide a new avenue for those who like something in-between. If the idea fails it fails, but worth giving a shot. Look at it this way though: if moth succeeded in becoming mainstream, then Lisp fans could use an "at work" language that is *more* like Lisp than the current crop of "at work" languages. It would allow more Lisp fans to be able to use a semi-Lisp-like language at work. Semi homoiconicity may be better than no homoiconicity. Deal?
Moth does not require usage or implementation of data types nor pattern matching (regex) syntax. I do admire sexprs for their simplicity and power, but doggonit, they are just hard to read for many of us muggles.
There are no statements in lisp so I don't see the point of making up gratuitous syntax to delineate something that didn't exist.
Ah! Very classic. But how do you handle all capitalized terms, such as "HTTP", "URL" or so?
You mean...separating the doc string and its rich-text representation? To be honest I am not sure if this is a good idea, since functionally it is very same to a stand-alone README file...
&gt; Not anymore, because Codex requires you to write a line for every function and macro you want to get documented. I thought it would require one single line to generate documentation for a package, which seems to be wrong. By the way I think the markup used by Scriba is a little bit verbose. I will have a look at Coo. Thanks!
&gt; If you pick lisp for web applications today you end up with much less tooling all around I beg to differ. If you use ClojureScript you get a decent Lisp with access to most of the current web ecosystem.
&gt; moving the wrong way along the hierarchy. Compromise to get the best mix of concepts sometimes requires giving up ground in some factors. &gt;A more productive activity would be programming your editor to display normally-formatted Lisp in an enhanced way. If the syntax more or less does that, then we don't have to make or rely on a fancy IDE/Editors.
Okay, I described it poorly. I'll try again. Suppose you throw a dart at long listing of code, and look at where the dart landed. Your friend then asks, "What structure(s) did the dart land on?" With Lisp you'd either have to count parenthesis, and/or read the function names and maybe the elements (parameters). That's rather slow (at least for my eyes/brain). With moth syntax, the absence or presence of parentheses, curly braces, colons, commas, periods, and semicolons gives a relatively quick visual cue of where the dart is in various statements/constructs, and also gives hints about what kind of statements they are, since each will tend to have a different visual signature (pattern). In short, it's just more visual.
My abstract "worry" is that rich markup tends to be unreadable when mixed with a rich programming language syntax like Lisp's, and that your proposal to put rich markup right into docstrings makes the development environment's *interactive* documentation unreadable. That said, I don't want to discourage you from discovering or inventing a way to markup writings about Lisp that is highly readable as-is.
It’s usually not ambiguous and it’s ok. The variables are just above in the parameter list.
I'm not a fan of forced whitespace (though Lisp people definitely have pretty consistent whitespace usage), nor am I a fan of your suggestions either.
Prior art: CGOL. This is an Algol-like syntax developed by Vaughan Pratt. It's the input language for Macsyma.
don't fix it if it ain't broken ,-)
The best way.
This is a terrible idea as it splits the documentation from the object it documents. Every single library of that sort that I've seen turned out to be a disaster in practice, introducing lots of unneeded mental strain.
&gt; Your friend then asks, "What structure(s) did the dart land on?" A person accustomed to reading Lisp code will answer rather quickly if you are throwing darts at a Lisp code listing. Same with a Java programmer and Java code, or Haskell and Haskell code, or ML and ML code, honestly. Let me give you a different argument, paraphrasing yours. &gt; With non-Lisp you'd have to count parentheses, curly braces, colons, commas, periods, semicolons, or absence of any of those. That's rather slow (at least for my eyes/brain). With S-expressions, reading the first symbol of a form and proper indentation give a relatively quick visual cue of where the dart is in various expressions, and also gives hints about what kind of statements they are, also since each non-standard form will tend to have a different indentation. In short, it's just more visual. Maybe some people's eyes process text faster such that it breaks even. I can only go by what my head does when explaining this.
I mean, I wish you luck in your experiments. There's nothing wrong with more languages being out there. &gt; It would allow more Lisp fans to be able to use a semi-Lisp-like language at work. Maybe, except that we already have that in many ways. We have tons of languages that give us first class languages, garbage collection, high level abstractions, DSLs, etc. I'm sure I don't need to go into how Lisp has infected many mainstream languages with its cool and powerful ideas. The one thing no language is really willing to steal, though, is the list-shaped syntax. And it doesn't take much "compromise" before you fall off that maximum and no longer have its benefits. Like I said, though, good luck -- and don't get bummed out if us lisp weenies aren't so responsive because we actually *like* the parentheses :-).
I suppose with enough time, one gets used to anything. How much people "get used to" and how fast it happens is hard to really say and probably varies per individual. I don't know of any definitive studies on such learning curves so all we can do is speculate. All things being equal, a shorter learning curve (such as speed-reading a language) is better than a long learning curve. As far as the re-paraphrasing, the things you say s-expressions do to help identify one's surroundings are *also* in moth-code or could be: it also has function/identifier names and (potential) indentation. If you *personally* can read Lisp easily, that's fine. I'm not disputing that.
&gt; we already have that in many ways. But they have complex syntax. Rudy is an example of a very "meta" language. But, it's also syntactically and structurally complex. It has no "root" or atomic structure (like a moth statement is), at least not a simple one. I don't know anything with that which can do C-esque or Algol-esque style syntax/constructs decently. Plus, moth is a syntax platform and not a language implementation, which is what Ruby is. It's sort of like comparing XML to HTML5.
If you grasp symbols faster than labels, maybe its time to look at APL? For exampe GNU APL and Dyalog APL are actively maintained and evolving all the time
Somewhere on Reddit there's a whimsical discussion of emoji-based programming languages. While it may be easier for some to read, it's so far difficult to type. APL's philosophy is to have a different symbol for each operator/function. That *doesn't scale* well to a language or libraries with hundreds of functions. Since the Querty keyboard has a limited set of symbols, we have to use them judiciously. In moth, I chose to use them to indicate which "part" of a statement one is in.
&gt; so all we can do is speculate You're speculating too. Here many of us have used not only Lisp but a lot of languages over the years. I haven't found anyone that complains about Lisp syntax, quite the opposite.
&gt; to see what other attempts there have been to rework Lisp ideas into more "typical" languages The s-expression syntax makes macro writing and "code is data" trivially **easy**. Damn easy. And the fact that transforming code into code is trivially easy is about 50% the power of Lisp, and about 33% of the power of Common Lisp. Lose the s-expression syntax, lose that power. Yes, many languages today can transform some code into an AST and then transform that AST again into the (modified) code, but this is a cumbersome job compared to doing that in Lisp or Scheme or Clojure.
&gt; Is anyone familiar with such attempts Yes, Lisp was fixed by adding OOP in the 70s, the result was Lisp. Lisp was fixed in the early 80s by adding type declarations, the result was Lisp Lisp was fixed in the 90s by adding networking features, the result was Lisp Lisp was fixed in the 00s by adding async features, easy-to-download libraries, a better build system, the result was Lisp Lisp is extensible within Lisp, so you fix Lisp by writing Lisp code.
&gt; If the syntax more or less does that, then we don't have to make or rely on a fancy IDE/Editors. Sure, mark that down as a pro. But I think there are more pros to merely adjusting the display. For one thing, you won't end up with files on disk containing Lisp code in a format most Lispers don't want to look at. And the converse, all Lisp code you might edit will appear the way you want it. For another, that would allow more advanced visualization than are possible with ASCII markup. You mention believing that you can read symbols more easily than textual labels. Then perhaps it would be helpful to visually annotate different forms by placing icons beside them. I actually agree with you that there's a lot of potential to present Lisp code more clearly, but by methods more radical than just making it written more like C. Plus possible issues with structured editing, as I mentioned.
If you post a use-case, I'll will attempt to propose a way a moth-based language could possibly do the same thing.
The big difference between web development today and back then is that instead of serving dumb HTML forms and having to track the state of a session on the server side, you can write a complete GUI app in JavaScript and have the backend just be a dumb data store that exposes an API to the client. That obviates the need for all that closure hackery described in the article. I'm at a loss trying to figure out how Node has better tooling for serving JSON over HTTP than Lisp does, though.
&gt; After pondering this a good while, I've decided that the tree-vs-forest issue is the biggest "visual" problem with it. It needs more variety, Have you checked out Clojure? It arguably has more variety.
/u/stylewarning , bloke's into quantum stuff
Calling /u/jmercouris
Contributing to open source projects is another way to gain experience and (eventually) references.
It's too late in the season for summer internships, but I sent your links over to HR. We're not far from you, in Ithaca.
The Google Summer of Code might also be a good alternative to classic internships!
I commend you for choosing to pursue Lisp!
Maybe ping known companies ? https://github.com/azzamsa/awesome-lisp-companies There's also a `pro` mailing list at common-lisp.net.
Thats like the one thing I remember in Let Over Lambda that isnt some weird esoteric way to code lol
&gt; but it seems nearly impossible to find an internship that would use this language. Another way is: learn CL (the learning materials are free and good) up to a very good level, and go after the [$$BOUNTIES$$](https://www.bountysource.com/teams/mcclim/bounties) for CL projects. If you got the free time, you could do it. I have faith in the young scientist generation. &gt; For reference, I'm not a total fool: https://solb.io Nice picture there, you [look a bit like](https://www.flickr.com/photos/sneachda/11984788465) a young Pat Metheny, who's a hell of a guitar player.
Hello, I had a student intern remotely with this company: [https://blink.social/#!/](https://blink.social/#!/) Jeanette
I say it's off-topic. This article is about databases and RDF. The only thing that is lispy about it is the fact that it comes from a commercial Lisp vendor.
Is there anyone using AllegroGraph in production today given how bad it is compared to modern alternatives that also happen to be free and opensource?
It happens to be written and customized in Lisp, too.
https://allegrograph.com/customers/
Paul Graham didn't use Windows or SSL.
FreeBSD, CLISP, Apache, ...
Decided to try portacle win 7 and old X11 ubuntu, clisp -repl Or ccl -l /path/to/portacle/quicklisp/setup.lisp A newer Cygwin X needed -listen tcp or inet4, but no CCL. maybe I should try its clx &amp; hemlock while no 64 bit cocotron. McClim climacs started from hemlock.
I only use SBCL on Windows, so can't really speak to other implementations but a friend of mine swears LispWorks is worth the license if I start trying to do windows desktop applications. I have my doubts... I have put together a simple web app in CL before, just a toy project, but used a reverse proxy for SSL. That is equal parts noticing the same SSL issues you have noted, familiarity with running a collection of application processes behind a reverse proxy from doing things in other languages, and pure laziness. Caddy is easy to set up and with do the Let's Encrypt handling automatically so I just don't have to think about it. Given that production web app to me means a set up similar to this, I would not have any reservations about using CL for a modern web app other than my unbound laziness and familiarity with JavaScript. If I ever find myself writing another web app, it will probably be in CL. Maybe, let's say fifty-fifty... I really like JavaScript but again, that laziness kicks in when I find that people have reinvented everything again and all the tools I used a year ago have changed.
Thanks for the reference! OP if you are interested check out [https://atlas.engineer](https://atlas.engineer) and send us an email, thanks. &amp;#x200B; \-John
What? It has been production-ready for about five decades. &amp;#x200B; On some of your points \- Use SLY instead of SLIME. \- Don't use Windows. \- You don't come to CL for the community. It is a bit of a thing to hack things yourself (for good or bad). \- If you want a list of things to start with, check this out: [https://github.com/CodyReichert/awesome-cl](https://github.com/CodyReichert/awesome-cl) &amp;#x200B; How did people get things done in Lisp? They wrote everything they needed. I have seen this first hand.
Webstuff (I assume that is what you need SSL for) has no business being on Windows. A windows server will be less safe, slower and more expensive than a normal server (meaning Linux, BSD or maybe even Unix). Consider also that you are not forced to use a SSL library written IN common lisp. Calling the relevant functions in a library written in another language from within lisp is perfectly fine.
You have that experience mostly because Windows is not popular among lisp developers.
I am also new to cl. I use ecl in windows (compiled with mingw) and Emacs/slime. It works ok i guess. Actually more stable then under Linux. Under linux slime regulary crashes during autocompletion. But yeah not the most stable toolchain.
&gt; Is there anyone using AllegroGraph in production today given how bad it is compared to modern alternatives that also happen to be free and opensource? Citations?
lol
What is Windows?
&gt; The big difference between web development today and back then is that instead of serving dumb HTML forms and having to track the state of a session on the server side, you can write a complete GUI app in JavaScript and have the backend just be a dumb data store that exposes an API to the client. The way you put it almost makes it sound like a feature instead of the festering bug-ridden featuritis it really is. I used to be able to keep about 50-100 tabs oben on my Firefox back in 2005 (before tabs were offloaded). This was on a Centrino single-core Laptop. Today that machine would probably be overloaded with just one single tab if your average site is loaded. And yet none of the "features" today are actually any improvements at all compared to what we had back then.
The OpenSSL situation definitely sucks on Windows. I usually have to download and install all 3 of 1.0.x, 1.1.x and 1.1.1 before I find out which one works. AFAIK, cl+ssl is the only FFI binding in the land of Lisp that tries to support 3 ABI incompatible C libraries. There's some other project though that is a binding to the Windows native SSL APIs, so maybe things work out better soon via that.
 &gt; Don't use Windows. This is why it will never take off.
/u/Noogie13 - there's your reference
Take off for what? I would argue that few sane developers use Windows as their environment. Those who do probably do it out of habit or out of necessity. I am sure there are exceptions, but I bet they are rare. If you are writing SaaS, you are definitely not tied to Windows. You can use whatever you want to write and host you system. If you are writing Windows apps, there may be more suitable tools than CL.
Exactly my thoughts. I have a dual boot with Win 7 and (now) Ubuntu 18. I have not been to the Windows side in a year or two. I used to use it for FL Studio, but ever since they released a Mac version, I waved good bye to the Windows. Ubuntu and Linux world really came along in the last few years. Also, I learned about the collusion (no, not that one!) that Microsoft had with processor manufacturers to get people to switch to Windows 10. Apparently, no one wanted anything to do with it. Hence, Microsoft asked Intel and AMD to include instructions that would make Windows 7 not work on the new processors. This was supposed to get people to switch. I think it is making people switch to Linux instead :D
Just the notion of not being portable on the most popular platforms besides Linux can very limiting and off-putting to anyone who wants to use it. Not everything revolves around Saas nor web development.
Did you checkout cl-tls: [https://github.com/shrdlu68/cl-tls](https://github.com/shrdlu68/cl-tls)? Also ABCL is possible where you can use all the Java based libraries.
Clozure CL on Windows. You'll never look back.
Can't basically anything support Windows at this point? With WSL, Cygwin, Mingw, and the fact that the majority of libraries have some amount of Windows support (Gtk, Qt..) How much does true Windows support (as in without Cygwin or any other compatibility layer) really matter? Genuine question. I'm not a programmer, so I really don't know.
&gt;The way you put it almost makes it sound like a feature instead of the festering bug-ridden featuritis it really is. It can't be featuritis if it's not a feature.
&gt; given how bad it is compared to modern alternatives Any example of comparison?
It's been production ready for two decades.
Those are less reliable than using MS VS certified tool chain.
Windows user here &gt;SLIME only seems to work with SBCL for me. ECL and Corman both blow up with cryptic errors under Windows It works fine with ABCL, CCL, SBCL and CLISP for me. Haven't tried ECL nor Corman. &gt;The only SSL library out there requires an antique version of SSLeay on Windows that you have to install from a third party .exe Wasn't the ssl library relying on libssl which is widely available? &gt;Roswell Roswell isn't needed at all for CL development. In any case, you ought to submit an Issue to the authors. &gt;So am I missing something? SBCL, CCL and ABCL work fine in Windows. I bet CLISP and ECL too. &gt;but the ecosystem seems broken as hell. That hasn't been my experience. &gt;Should I just suck it up and hack my way through? No, just research a bit more inside the ecosystem.
&gt; Don't use Windows Sometimes this isn't an option when creating production software, due to external constraints.
jeez... for real... 12 proud years of Debian.
OnGoing, though I see it more as simplifying and evolving: https://github.com/codr7/g-fu/tree/master/v1
&gt; What is Windows? The thing Linux people speak about in derision, while using a [system essentially contrary to Lisp values](https://web.mit.edu/~simsong/www/ugh.pdf)
Too bad, it seems now a great system, not that flexible for devs, though!
WSL isn’t installed by default, and in its current state isn’t really a good platform to ship software on, as performance is severely lacking, and there’s no interface to allow graphical applications directly. And those other things help, but portability is still a pain, particularly in C/C++ land, which is what all of those tools are for. But none of those things really do much to help in lisp. That needs to be in-built in the language’s ecosystem like it is in others. The fundamentally different way some things work still makes portable software a pain. Source: recently had to port Linux software to Windows that accessed a serial-over-usb device, and it kinda sucked
Source for that?
- The CL community is small (compared to others at least) so there's plenty of do-later and/or works-for-general/my-case cracks (not saying all other communities have similar problems ofc *looks at JS, npm*) - When it comes to tooling others have mentioned portacle, which is very nice. - Regarding creaky old foundation: You do not want to dig deeper into basically any lib you depend on... And it is open source and free, supported by alot of people's spare time. Create an issue or fix it and contribute. 😃 - CL is an awesome language. All ecosystems are more less broken in one way or another. As with any new thing, it takes time to learn where the cracks and holes are and either avoid them or help fix them. Sadly, there are not that many big players out there that can pump millions of dollars into CL (like Google with go, Apple with Swift etc). - Keep trying because it is truly an amazing experience the more you get into it. Looking back I never feel I have wasted any time at least.
&gt;Node has better tooling for serving JSON over HTTP than Lisp does, though. It does not. Where node wins is that it has all the tooling for the Single Page Application frameworks. For example to be able to transform a ".vue" single page component (so it can be served to the client) requires a js engine on the server. Same for React components if i recall correcty.
mingw and qt are realiable on Windows.
Was using boost asio with serial ports support on Windows, don't remember any significant problem. [https://www.boost.org/doc/libs/1\_65\_0/doc/html/boost\_asio/overview/serial\_ports.html](https://www.boost.org/doc/libs/1_65_0/doc/html/boost_asio/overview/serial_ports.html)
&gt; Your company has 1000+ people Fire one of them and you can afford a LispWorks license.
Yeah I need to get back and do some more work on the windows schannel library. I got it working but ran into some issues writing a usocket streams interface and never got round to finishing that part.
Somebody commented, &gt; Don't use Windows. We have been using LispWorks on Windows, for the past few years. I just wished we bought the license years ago. To me, that environment is sheer joy to use, absolutely worth it.
Thanks! Just sent an email!
I have read Common LISP: A Gentle Introduction to Symbolic Computation and read much of PCL and skimmed through On Lisp (which I intend to give a proper read to soon). CL is a ton of fun! I'll look into those bounties, although I suspect they will be somewhat above my scope, but maybe that just means I'll have to broaden my knowledge! Thank you!
&gt; So am I missing something? You're missing that there are commercially supported implementations that are very good and production ready. What's next, complaints that the FOSS fairy doesn't deliver production quality z/OS support?
Not more than VS and CL in Windows have always been a low class citizen.
Does having gpio count? ccl, clisp on arm RPI. Does 32 bit only CCL run on the high end 64 bit boards, cocotron 32 for their IDE? Or clx/hemlock.
It doesn't matter. Both successfully used to produce commercial software.
LispWorks works just fine.
Very cool. What do you use CL for ? Is there a mention of CL on your website, and would you like to reference your company into https://github.com/azzamsa/awesome-lisp-companies ? Regards.
Doesn't change the fact that CL is not friendly in any other platforms than Linux.
&gt;Fire one of them and you can afford a LispWorks license. LW licenses are affordable for companies, although I suspect this is going to change now that things like Azure services are setting a drastically lower price point for what were expensive software.
I just written in toplevel comment, LispWorks and Allegro work on Windows just fine and quite friendly. LispWorks for Windows even has more features than for Linux (interface builder is available on Windows only, COM support etc).
I saw your work on github, looks like a promising start. I might chip in after I get comfortable with the language.
 &gt;I have read Common LISP: A Gentle Introduction to Symbolic Computation and read much of PCL and skimmed through On Lisp (which I intend to give a proper read to soon). CL is a ton of fun! Allright, now you can start experimenting by implementing something you need. Don't forget to know understand the ecosystem: What is "quicklisp" "asdf", and also check out the "awesome-cl" listing of CL libraries. &gt;Thank you! you're welcome and thanks for joining this fellowship of dignified defenders of programming freedom.
&gt;I would argue that few sane developers use Windows as their environment. You're looking at a subset of software development. C# development is wildly popular (particularly in the money-making world) and this is "sanely" done using Microsoft Visual Studio, which -leaving smalltalk and CL IDEs aside- is a really good IDE. All this stuff is intended to work best in Windows.
&gt;Caddy is easy to set up and with do the Let's Encrypt handling automatically so I just don't have to think about it. Would you please give more details on how you solved the ssl issue? I don't know what Caddy means in this content.
&gt;All ecosystems are more or less broken in one way or another. As with any new thing, it takes time to learn where the cracks and holes are and either avoid them or help fix them. True!!
&gt;Yeah I need to get back and do some more work on the windows schannel library. Please do!! Fjames86 FTW!!
It was a C program, not C++. I ended up using Cygwin as the program also depended on pthreads, unix sockets, and POSIX message queues
&gt; Allright, now you can start experimenting by implementing something you need. I have! I implemented a few libraries: [3d-vector-lib](https://github.com/noogie13/3d-vector-lib), [lispotify](https://github.com/noogie13/lispotify), and my tons of [StumpWM config](https://github.com/noogie13/stumpwm-configs). I absolutely love CL, and was just hoping I could find some fun things to work on and get some work on my resume too. &gt; you're welcome and thanks for joining this fellowship of dignified defenders of programming freedom. Thanks for the official welcome into the community :-)
&gt;I absolutely love CL, and was just hoping I could find some fun things to work on and get some work on my resume too. May I suggest you some tasks that can improve the ecosystem? - Fix `burgled-batteries3` so it works with the latest Python implementation (CPython latest version) - Ensure `cl+ssl` works ok in Windows. - Hack `Cl-Javascript` so it works with Ecmascript 6 or 7 etc
&gt; some posters here mistook this project for a wholly unrelated project on github that was me but i'm pretty sure that was because the the name you picked for your dialect was already taken. ;) good call on the rename. i'm checking out your updates now. thanks for the update!
Hey, thanks ! I hope you find it interesting.
There are essentially two types of responses here. One type that scoffs at windows users, and one that scoffs at people unwilling to pay for a commercial lisp... and people wonder why the lisp community is small.
&gt; Roswell. I started it up on my machine but had to Ctrl-C because it was reinstalling SBCL which I already had installed of course because it is a tool to install and manage multiple lisp implementations... You interrupted it, so the internal coherency is already broken. What sane behavior do you expect from that situation?
I would expect it to detect the fact that it's not fully installed and do a fresh install. At the very least, throw up an error code or message saying it can't continue, rather than just silently doing nothing with no indication on how to fix the problem.
I built the site without SSL support in common lisp, then it behind caddy https://caddyserver.com/docs/automatic-https#on-demand which is kind of like nginx and aquires SSL certificates when it launches. I guess I solved it by not needing it in my CL application.
That's where we are now. But Allegro CL and LispWorks survived. Why is that? * the Microsoft Windows platform is simply not attractive for free software developers (-&gt; see Richard Stallman [https://stallman.org/microsoft.html](https://stallman.org/microsoft.html) ) * Microsoft has zero support for Lisp technologies * there is in the last twenty years only a small market for niche languages and their IDEs. Such that a reasonably priced Corman CL didn't generate enough revenue to expand... What you find on Windows are Application USERS who don't care what an application is written (there are some Lisp applications where people don't see Lisp much) in or who might accept Lisp when they use it for scripting (AutoCAD and related CAD systems). In the past one had for Windows a bunch of development environments: * CLOE from Symbolics, expensive, used for example for PC Macsyma * Procyon CL, extensive IDE, $1000-$2000, bought by Franz and used for their Allegro CL on the PC product. * Golden Common Lisp from Gold Hill, extensive IDE, $2000 [http://www.goldhill-inc.com](http://www.goldhill-inc.com) * Corman CL, some IDE, cheap, now open source [https://github.com/sharplispers/cormanlisp](https://github.com/sharplispers/cormanlisp) * Software Engineer, cheap * Star Sapphire CL, IDE, cheap * Reflisp, free * XLISP, free * Linklisp, cheap * Nanolisp, cheap * Eclipse, expensive * mu-lisp, small/cheap * CLISP, free * LispWorks with IDE and extensive Windows support, expensive * Allegro CL with IDE and extensive Windows support, expensive Later one got ports of the naked SBCL, Clozure CL, ... to be used with GNU Emacs / SLIME as its IDE. A Clozure CL IDE using Cocotron didn't materialize. Of probably fifteen or more Windows-specific options the survivors are either * extensive expensive commercial implementations * implementations without special Windows IDE (SBCL, CCL, CLISP, ...) * abandoned implementations like Corman CL has been open sourced. &amp;#x200B; \&gt; Let's take lispworks... ... Insane. But they are still there after 30 years. The others from the list above are mostly gone. They don't have 'you' as a target market, since 'you' wouldn't bring enough revenue anyway. Thus they have to structure their pricing to what the market currently looks like. After so many years the Lisp market on Windows is not because there were no offerings and no attempts to broaden the user base. There is just not much money to be made to support the development of Lisp developer tools and a cheaper price point.
The question was about production, and this should not remove commercial options if they speed up time-to-market of your product. The cost of license then not so huge comparing to other costs (I.e. business trip to the customer site which you might often do, specific hardwarw etc). I know companies which use quite expensive subscription-based Dyalog APL (was in their office on a meetup) just because it makes them more productive. Every engineering workplace (in industry) I've been to had commercial licenses of Matlab (yes there is opensouce Octave btw). Some guys couldn't live without their LabWindows which is not cheap either. Artifactory, Jira etc all costs money. As for hobbyist usage here you are on your own, and LW price is too steep I agree. But that's what hobby for you.
Is there a syntax chart or BNF-like chart around for it? I couldn't find any via Google.
Or in other words, those frameworks are written specifically with Node in mind.
\&gt;Plus, moth syntax resembles languages we know and love. You mean languages we know and hate?
I realize the Lisp forums will have a lot of Lisp fans and I don't expect them to change their mind. I'm just asking about past attempts to provide something having features of Lisp but that looks more like "mainstream" languages.
&gt;"forest/tree problem" described in the intro. Could you elaborate on exactly what the "forest/tree problem" is supposed to be, and how other programming languages supposedly "solve" it?
Where do you get your slime and swank from? Are their versions matched?
Your post is duplicated - I can see the first post on /r/lisp.
I apologize for not putting more info. For whatever reason, my original post wasn't showing up. Original text below. ~ So, Clozure CL works perfectly with SLIME on my Windows 7 box. On my Ubuntu 18.04 box, however, SWANK craps it's pants. I get "SWANK-BACKEND:WAIT-FOR-INPUT not implemented" and hundreds of "Return to SLDB level". Inferior Lisp did start, and it did say "Swank started at port: 33409", but the SLDB kept spewing. So, thinking there's some version mismatch or something, I strip down my EMACS init to just ELPA/MELPA stuff and SLIME, and start experimenting. Now, here's the thing. 64-bit Clozure will work from the terminal (though other people have noted the 32-bit won't work with Ubuntu since 17.10), and even Quicklisp will work, but SLIME doesn't. On the Lisp side, I've done the official v1.11.5 release (https://github.com/clozure/ccl/releases/tag/v1.11.5) with their instructions, no dice. Then I installed a Ubuntu package (https://mr.gy/blog/clozure-cl-deb.html); first using the recommended DPKG method, and then a redo using the Ubuntu Software GUI. Still no dice. On the EMACS side, I've tried using three different SLIME's: the one from the EMACS repository, the Apt one, and the Git one. Did nothing, even after I deleted Clozure's ~/.slime FASL's so it could make new ones. Then I tried loading a SWANK instance from the terminal. That did work; only when I tried connecting to it from EMACS with "slime-connect", SLDB still did the infinite loop. (Strangely enough, when I exited EMACS, the Clozure session in the terminal changed it's prompt to "CL-USER". So something's going on, but not working right.) Then I tried Quickloading SWANK using the ".ccl-init" file. It would load every time, yet continue to be obstinate. Now I'm back to version mismatch. My Windows has EMACS 26; my Ubuntu has EMACS 25. Would that solve anything? So I then add Kevin Kelley's PPA and install EMACS 26, and lo and behold, absolutely nothing changed. I'm not sure where to go from here. For reference, SBCL and CLISP always worked with SLIME; CMUCL finally started working when 1.) I installed a 32-bit library, and 2.) I moved to the 21d release, after seeing ASDF saying I needed the newest release. But since Quicklisp works perfectly on terminal-run Clozure - it loads Hunchentoot and CEPL perfectly, and (supposedly) loaded SWANK during my "slime-connect" test - I have no clue why ASDF would suddenly have a panic attack about SWANK with EMACS.
Yes, I did try slime-helper.
Yes, I do.
Are you sure that emacs and CCL load slime and swank, respectively, from the same directory? That is the best way to ensure that the versions are matched.
I just tried this; set up a separate SWANK instance using the SLIME in /usr/share/common-lisp/source/slime/, and set up EMACS the same way. No dice. I also did this with the Git and ELPA versions. No dice. Strangely enough, I did the same with SBCL, and it came right up. So it definitely has to do with Clozure.
Hm. Swank defines an internal interface named `WAIT-FOR-INPUT` at https://github.com/slime/slime/blob/e6d215d77148079799d2fc3253ef402b5d9ed4d7/swank/backend.lisp#L1377 and it seems that it's not implemented for CCL - see https://github.com/slime/slime/blob/e6d215d77148079799d2fc3253ef402b5d9ed4d7/swank/ccl.lisp Try giving us the stack trace for that error even if it's really long. The question is, why and where `WAIT-FOR-INPUT` was called inside Swank, and why Swank doesn't have this function implemented for CCL.
Sure. Strange that it would only affect Linux and not Windows, though. SWANK-BACKEND:WAIT-FOR-INPUT not implemented [Condition of type SIMPLE-ERROR] Restarts: 0: [ABORT] Return to sldb level 811. 1: [ABORT] Return to sldb level 810. 2: [ABORT] Return to sldb level 809. 3: [ABORT] Return to sldb level 808. 4: [ABORT] Return to sldb level 807. 5: [ABORT] Return to sldb level 806. --more-- Backtrace: 0: (SWANK-BACKEND:WAIT-FOR-INPUT (#&lt;BASIC-TCP-STREAM ISO-8859-1 (SOCKET/5) #x302000F0389D&gt;) NIL) 1: (SWANK::WAIT-FOR-EVENT/EVENT-LOOP #&lt;SINGLETHREADED-CONNECTION #x302000F02AAD&gt; (OR (:EMACS-REX . SWANK::_) (:SLDB-RETURN 812)) NIL) 2: (SWANK::WAIT-FOR-EVENT (OR (:EMACS-REX . SWANK::_) (:SLDB-RETURN 812)) NIL) 3: (SWANK::SLDB-LOOP 811) 4: (SWANK-BACKEND:CALL-WITH-DEBUGGING-ENVIRONMENT #&lt;Compiled-function (:INTERNAL SWANK::DEBUG-IN-EMACS) (Non-Global) #x302000EAADEF&gt;) 5: (SWANK::DEBUG-IN-EMACS #&lt;SIMPLE-ERROR #x3020021401CD&gt;) 6: (SWANK:INVOKE-SLIME-DEBUGGER #&lt;SIMPLE-ERROR #x3020021401CD&gt;) 7: (SWANK-BACKEND:CALL-WITH-DEBUGGER-HOOK #&lt;Compiled-function SWANK:SWANK-DEBUGGER-HOOK #x302000EACBDF&gt; #&lt;COMPILED-LEXICAL-CLOSURE (:INTERNAL SWANK:SWANK-DEBUGGER-HOOK) #x30200214018F&gt;) 8: (SWANK:SWANK-DEBUGGER-HOOK #&lt;SIMPLE-ERROR #x3020021401CD&gt; #&lt;Compiled-function SWANK:SWANK-DEBUGGER-HOOK #x302000EACBDF&gt;) 9: (CCL::BREAK-LOOP-HANDLE-ERROR #&lt;SIMPLE-ERROR #x3020021401CD&gt; 17474327250441) 10: (CCL::%ERROR #&lt;SIMPLE-ERROR #x3020021401CD&gt; (SWANK-BACKEND:WAIT-FOR-INPUT) 17474327250441) 11: (SWANK-BACKEND:WAIT-FOR-INPUT (#&lt;BASIC-TCP-STREAM ISO-8859-1 (SOCKET/5) #x302000F0389D&gt;) NIL) 12: (SWANK::WAIT-FOR-EVENT/EVENT-LOOP #&lt;SINGLETHREADED-CONNECTION #x302000F02AAD&gt; (OR (:EMACS-REX . SWANK::_) (:SLDB-RETURN 811)) NIL) 13: (SWANK::WAIT-FOR-EVENT (OR (:EMACS-REX . SWANK::_) (:SLDB-RETURN 811)) NIL) 14: (SWANK::SLDB-LOOP 810) 15: (SWANK-BACKEND:CALL-WITH-DEBUGGING-ENVIRONMENT #&lt;Compiled-function (:INTERNAL SWANK::DEBUG-IN-EMACS) (Non-Global) #x302000EAADEF&gt;) 16: (SWANK::DEBUG-IN-EMACS #&lt;SIMPLE-ERROR #x3020020EB61D&gt;) 17: (SWANK:INVOKE-SLIME-DEBUGGER #&lt;SIMPLE-ERROR #x3020020EB61D&gt;) 18: (SWANK-BACKEND:CALL-WITH-DEBUGGER-HOOK #&lt;Compiled-function SWANK:SWANK-DEBUGGER-HOOK #x302000EACBDF&gt; #&lt;COMPILED-LEXICAL-CLOSURE (:INTERNAL SWANK:SWANK-DEBUGGER-HOOK) #x3020020EB5DF&gt;) 19: (SWANK:SWANK-DEBUGGER-HOOK #&lt;SIMPLE-ERROR #x3020020EB61D&gt; #&lt;Compiled-function SWANK:SWANK-DEBUGGER-HOOK #x302000EACBDF&gt;) --more--
Remove (setf *communication-style* nil) from ~/.swank.lisp
I made a change so that it's a bit more helpful the next time https://github.com/slime/slime/commit/bdef5868c41b306e54c21c68ed7775d3dbf56b0d
Holy crap, that worked. For both Clozure AND ECL! Thank you so much!
I just tried the answer from /u/stassats, and it worked.
That's good stuff.
Try these: https://en.wikipedia.org/wiki/CGOL https://dspace.mit.edu/bitstream/handle/1721.1/41951/AI_WP_121.pdf
Why do people keep posting this degenerated dialect?
Why do you need ECL and Corman when SBCL works for you. SBCL is production-level open source implementation that's suitable for almost anything. WTF is SSLeay? CL+SSL works with the newest version of openSSL binaries for Windows just fine. I don't use Roswell, why do you need it exactly? I developed a website using Windows/SBCL/Hunchentoot and it's happily chugging along in production for 4.5 years running.
[tinyScheme](http://tinyscheme.sourceforge.net/home.html)
&gt; CL+SSL works with the newest version of openSSL binaries for Windows just fine. Thanks for this info. Which implementation did you use? SBCL?
HN Discussion of it https://news.ycombinator.com/item?id=20012953
1. SBCL has a big splash banner that says the Windows support is "fragile" and not explicitly supported. So that's why I was searching for an alternative implementation. 2. CL+SSL only works with the 1.0.x or something versions, not the 1.1.x which is the latest. 3. I don't really need it but it's not exactly promising when the tool just fails silently when it diverges off the happy path.
It's possible that their eyes see something yours are yet incapable of recognizing.
I have.
I attempted to explain that to u/Zotlann with limited success. The simplest example is in C-style languages where if you see curly braces "{...}" you know you are looking at bigger-scaled units (typically "blocks") than if you see parentheses "(...)". The colons of moth statements provide yet further clues. I find such helpful, and expect others will also. I don't expect unanimous agreement because every brain works different.
Thanks ! I'll probably go over there and post something. By the way, the price will come down soon, as soon as I can build them about 50 at a time. Maybe I'll offer a rebate or credit on future purchases for those who buy now, something like that. I'm open to suggestions, and ideas for what an attractive/competitive target price would be.
i wonder how many people make use of it
&gt;I have. Was he/she a Common Lisp or Scheme user, or just somebody that was reading a bit about Lisp?
I had to do a number of repetitive operations on a bunch of images a few years ago, and I was overjoyed when I discovered that script-fu was actually just scheme with some gimp specific functions added. So at least 1 :)
Awesome. Is it discussed too ? I mean it should really be more known.
Whenever I have seen gimp discussed in a programming context (which is admittedly a limited number of times) someone usually mentions it.
pretty cool :)
I just wanted to log in and let you know that I really appreciate this project. I will be buying a full kit in a bit, I have to complete a move first. Really great work, thanks for building it. I have been waiting for something like this since the early 2000's.
&gt; i wonder how many people make use of it What I understood was that Guile Scheme was the "official" GNU embedded scripting language.
If a butterfly had flapped a little harder the web could have been quite different - https://paulhammant.com/2013/03/28/interface-builders-alternative-lisp-timeline/
That is so kind, thank you ! I hope to hear from you soon ! info@makerlisp.com
Yep. Guile == GNUs Ubiquitous Interpreted Language for Extensions, or something like that. GnuCash (accounting software) uses it, as well, for reporting and other features.
I have, but it's a lot of work, since they decided to use this crippled Scheme implementation called TinyScheme instead of either a real Scheme implementation or Common Lisp, and they only did the minimum amount of work to bind the Gimp to their Scheme. As a result, the functions have a C-like interface. Things tend to come in vectors instead of lists. There are other annoyances. There are no macros, so you can't improve the spartan syntax of the crippled Scheme they chose to use. What's more, there is also an alternative to Script-fu, called Python-fu, which is way better integrated, and doesn't use a crippled implementation of Python. It's as if they actually cared about the Python integration. But OTOH, it's fucking Python. To add insult to injury, the REPL just sucks. Also, TinyScheme is slow.
This makes me sad.
I'm glad this finally got posted :p The audio/me talking is off the editor by about 20 seconds, but this is still a really good effort by the editor to keep everything looking coherent. If anyone has questions, let me know! (Also, if you want to contribute to/use [`cl-notebook`](https://github.com/inaimathi/cl-notebook), click [here](https://github.com/inaimathi/cl-notebook))
This is beautiful in every conceivable way. Classic nostalgia-trigger in its A/V production, conjuring real "gold age" feelings. &amp;#x200B; Makes us feel that we f\*cked up the future so bad.
[GuixSD](https://www.gnu.org/software/guix/)
I love emacs as a concept but find the editor itself (as in, GNU Emacs) to be too legacy and not keeping up with advancement in modernity to be a bit annoying at time. I'd like to do everything in a sort of Emacs/lisp machiney way, kind of like EXWM, and although EXWM is impressive, Emacs itself (and Elisp IMO, but maybe that's because I'm more of a Schemer/LISP-1 person) is not a good software stack to run an actual window manager in. (StumpWM is a good alternative). I've been toying with writing my own editor for myself, but have yet to write any code so whoops lol.
It used [SIOD](http://people.delphiforums.com/gjc//siod.html) in the early releases, TinyScheme replaced it in GIMP 2.4
[There are Common Lisp-style macros](https://github.com/tshatrov/scriptfu/blob/master/animstack.scm#L1009). It's a perfectly reasonable Lisp as long as you write helper functions to iterate on vectors. There's even namespace support (similar to CL packages).
I'm using it, I wrote some [pretty complex scripts](https://github.com/tshatrov/scriptfu) for GIMP 2.8 and unlike many Python scripts they still work just fine in 2.10. There are a lot of undocumented features that make it a practical programming language, such as regex support, macros, namespaces, persistently attaching arbitrary data to GIMP images (so-called "parasites"), etc. Most people don't know about these features, which is a shame.
I don't like GIMP UI, but I think I would love the programmatic aspects of it
SBCL releases roll out so fast, I think somebody will have to create an auto-update daemon... &gt;enhancement: (declaim (optimize (debug 2))) ensures compilation of top-level forms, providing better debugging for simple forms that are otherwise "byte-code interpreted" when compiled into FASLs. This is interesting. Which kind of forms don't get compiled? I thought that when a file was `compile`d, all the toplevel forms went into the compiler by default.
see also https://vimeo.com/62618532
If I had to use Windows, I'd quit being a developer entirely, that's how much I hate it. Also, Lisp is really fragmented and attracts the "lone hacker" types. I'm not sure it really needs to take off. IMO Lisp will always be a niche language.
Is the most powerful meta language in the world. Is not supposed to belongs in any niche, but mold it self into many.
Do you know about JavaScript yet? :) [https://jorgetavares.com/2010/05/19/original-implementation-of-javascript-in-cl/](https://jorgetavares.com/2010/05/19/original-implementation-of-javascript-in-cl/)
It's a powerful general purpose language, in that sense it does not belong in a niche. It appeals to a certain kinds of users.
Is not useful as a general purpose language, but for embedded domain specific languages that are at the interest of anyone's domain.
add the following lines to `portacle/config/user.el`: ``` (remove-hook 'lisp-mode-hook 'enable-paredit-mode) (remove-hook 'lisp-interaction-mode-hook 'enable-paredit-mode) (remove-hook 'slime-repl-mode-hook 'enable-paredit-mode) (remove-hook 'eval-expression-minibuffer-setup-hook 'enable-paredit-mode) (remove-hook 'emacs-lisp-mode-hook 'enable-paredit-mode) (remove-hook 'ielm-mode-hook 'enable-paredit-mode) ```
The Interface Builder origin wasn't first developed in ExperLisp. The actual first version was called SOS Interface and was developed around 86 in Le_Lisp for the Macintosh at Inria / France by Hullot. It was basically the first 'modern' gui-based interface builder. http://www.softwarepreservation.org/projects/LISP/le_lisp This was then moved to ExperLisp and then to some Common Lisp implementations, incl. one for the Texas Instruments MicroExplorer Lisp Machine board for the Mac. It was sold as an add-on for some CL implementations
&gt; Which kind of forms don't get compiled? Simple forms that don't need to be compiled.
This is one of the most annoying things about portacle. Not just `paredit`, but lots of emacs choices have been made that are very opinionated. And even as a long-time, die hard emacs fanboy, I found it unbearable. Some of the changes were using things I didn't even know how to search for to find out how to turn then off. It would be nice if they had a clear document describing all the deviations from emacs normal.
You're describing one purpose...there are many. Why argue about this?
Because Lisp is not supposed to be niched like you stated.
See https://www.reddit.com/r/Common_Lisp/comments/bo0m0u/global_declaim_with_defvar_type_checking_not/ for context.
Thanks!!
&gt;And even as a long-time, die hard emacs fanboy, I found it unbearable. I think Portacle is intended for beginners, not Emacs power users. The latter would be better installing SLIME and setting up an implementation.
I was surprised at this, since I had heard a version of the Javascript development story from Eich and others that didn't involve Lisp, but on closer [inspection](https://www-archive.mozilla.org/js/language/semantics/index.html) it [seems](https://www-archive.mozilla.org/js/language/js20-2000-07/formal/index.html) like, for version 2.0, once it was starting to become ECMAScript, they had brought in someone with real talent, who of course used Lisp, to try to get a handle on the semantic mess. It's quite debatable what effect it had, but seems to be a commendable endeavor. I read some of it, but I can't easily figure out where it is, or muster the enthusiasm to try to download the code and run it. But maybe it's good that CL doesn't have the rather dubious honor of being the first JS implementation language.
Thank you. This is very fascinating.
One part I don't understand is that according to the manual (2.3.3) sbcl is `SBCL is essentially a compiler-only implementation of Common Lisp` and the interpreter is only used internally. What is done with, for example, a defvar if it is not compiled?
Nice. (where's the xpost?)
https://github.com/sbcl/sbcl/commit/e7549c3ac1008eead29292a26b5a184200e0769d Is this the commit?
&gt; What is done with, for example, a defvar if it is not compiled? It's byte-code interpreted. Setting a variable (which is a single function call) doesn't really need to be compiled.
That's dealing with consequences, as the compiler is able to see dead code, unlike the byte-code compiler. The commit is https://github.com/sbcl/sbcl/commit/4a0dbc3f65cc48e3dcfddb5ff06dad80cdc0d2fb
Let me be that guy. Production system and MS Windows... well, let's look at it this way: Windows was never even a contender for a large spectrum of "production systems", eg. supercomputers, storage, banking. It is also a really poor choice when it comes to cloud (too expensive, too difficult to automate, very little support). It is also a bad choice (although, viable if you are a fan) for web development. Expensive, difficult to automate and to configure, and, not playing well with almost any other web technology (except those developed by MS). Windows has almost nothing to offer on mobile front either. Surprisingly, Windows has some market share in embedded (things like cash registers, or ATMs tend to use Windows). So, Windows is a plausible choice for office-like programs targeting desktop users in big American corporations or governments (probably, internationally), for non-expert users: accounting, education, management. Another area where Windows is the user's choice today is games. From your mention of SSL library, I infer that you might be into web development. If that's the case, you probably want to try another platform. I mean, if you chose Lisp, you are not choosing ASP.NET, and, basically, every other web-backend technology will work badly on Windows. So, you are already swimming against the current. And, I mean, sometimes swimming against the current is rewarding, but in the case of trying to do web development on Windows, there's no epiphany waiting around the corner, nothing even moderately good will come out of it. Some people do it, often because they've inherited the system which was built like that, often because the original builders didn't know what they were doing. Other times it's because the non-programmers in the management made a bad choice. So, really, it's just not worth going there.
Thanks! The xpost never quite made it off the ground in /r/programming :) https://www.reddit.com/r/programming/comments/bu1pdd/clrdkafka_a_common_lisp_library_for_kafka/
&gt; It's byte-code interpreted. Setting a variable (which is a single function call) doesn't really need to be compiled. Thanks, I think this is the answer I was looking for. I thought just like /u/Baggers_ : That everything was going to go through the compiler.
How about using mpv as an example? Could be useful for CEPL.
Off to read the phrase values that are assumed to be mutable. Values aren't mutable lol.
&gt;This is one of the most annoying things about portacle. Not just paredit, but lots of emacs choices have been made that are very opinionated. Portacle is maybe the greatest contribution to the CL ecosystem since Quicklisp. And mostly the work of one developer. The least we can do is to allow this developer to make some opinionated choices. I am extremely grateful that Portacle exists. Thanks to it, I can teach CL to students at my university, instead of teaching them Emacs Lisp first. &gt;It would be nice if they had a clear document describing all the deviations from emacs normal. You could contribute such a document :)
*variables Just encase you weren't being a pedant :) I think you knew what I meant really.
&gt; You could contribute such a document :) No way, dude. I basically gave up on it because I could spend my life trying to figure out how to untangle it, and i have other stuff to do. I was at first excited that there might be a single package option for windows, but because of over engineering, it's easier to install the parts by hand.
As in this mpv https://mpv.io/ ?
&gt; I have now clarified that I mention Common Lisp only an illustrative counter-example. I do not want to get into an extended argument here about Common Lisp.
Even if there were no mentions of Common Lisp, ranting about complexity is not exactly insightful.
Not really about Common Lisp, although it’s an interesting article. I don’t think CL is really all that large in the senses he indicates, to be honest: the syntax is small and the special forms are few. The state is a bit large, I’ll grant.
I like to use [Zeal](https://zealdocs.org/) (on Windows, but also available on other platforms), beside the internal help system. I believe with small modifications it could be used with all the wonderful LipWorks manuals. Thanks to /u/f0urier for another very fine LispWorks tool.
&gt;We present CuLi, an interactive Lisp interpreter, that performs all computations on a CUDA-capable GPU. The host system is needed only for the input and the output. At the moment, Lisp programs running on CPUs outperform Lisp programs on GPUs, but we present trends indicating that this might change in the future. Our study gives an outlook on the possibility of running Lisp programs or other dynamic programming languages on next-generation accelerators.
Typical [medium.com](https://medium.com) clickbait headline.
But in this case, it's a verbatim copy of the subject line that was used in the 2015 `es-discuss` mailing list: https://mail.mozilla.org/pipermail/es-discuss/2015-June/043307.html These JS-pushing cretins should confine their discussion to the garbage language they are working on.
I've heard similar forest/tree complaints from experienced Emacs and AutoLISP (AutoCAD) programmers or programmer/user hybrids. It was a while ago such that I cannot provide hyperlinks.
"Broken" either varies per individual, and/or is subjective. Programming languages are at least as much meant for human readers and writers as much as for machines. Machines don't "care" about code format: they just follow processing rules like a dutiful narrow savant. You may find Lisp easy to read, but many others don't.
I don't see that it has a simple base- or root-structure.
Hello, This isn't my company, but a company one of my students interned with. You can contact Blink through their website. Jeanette
&gt;I've heard similar forest/tree complaints from experienced Emacs and AutoLISP (AutoCAD) programmers AutoLISP is to Common Lisp (or Racket) as "steam-powered locomotive" is to "maglev train". I would be complaining too, if I had to use AutoLISP. Emacs Lisp isn't too friendly as well, considering that it didn't have lexical binding for decades and considering the abuse of globals.
That's because the author of the article doesn't actually know anything about Common Lisp, their example of "poorly thought "out features was: &amp;#x200B; &gt;\* *eval-when* &gt; &gt;\* package namespace system &gt; &gt;\* separate name spaces for functions vs values including functions &gt; &gt;\* like C, too many “undefined” behavior cases &gt; &gt;\* Don’t even get me started on the CLOS object system ;) &amp;#x200B; CLOS as a poorly thought out feature? Is this some kind of joke?
&gt;I have been on the JavaScript standards committee (TC39) since 2007. Stopped reading here, OP probably does not have a functional brain with those qualifications.
Common Lisp isn't a large language; it just predates the distinction between "language" and "standard library."
Scope issues were not the crux of the complaints, as I remember them.
&gt;Scope issues were not the crux of the complaints, as I remember them. Codebases that don't use lexical scoping tend to be horrible, and this will be the cause of pain, since everything can modify everything.
Awesome stuff. I haven't tracked down why, but in experimenting with define-declaration and friends, I've noticed that (at least on SBCL) macroexpand does not seem to propagate custom declarations down the expansion. Have you experienced this while working with gtype?
&gt; The first one you might have heard (and never tried yourself) is `cl-algebraic-data-type` (or `cl-adt` in short). It does not support parametric types. From the documentation, it is also not clear if you can define a list that contains only some type (i.e. the arguments to the type specifier is evaluated lazily). It comes with its own pattern matcher, but it is not complete and its performance does not seem like the focus. As a result, the library is not widely adapted. A few comments. In the documentation, it shows an ADT: ``` (adt:defdata liszt (kons t liszt) knil) ``` This is a polymorphic data type using Lisp's `t`. You could specify a more particular concrete type, but it's true, there's no way to define a parametric `(liszt s)` type which represents a usual list whose elements are of type `s`. As any experienced Common Lisp programmer knows, it's actually not possible to express such a thing at all in Lisp, even with `satisfies`. I claim that `gtype` doesn't solve this either. It too doesn't support the creation of new parametric types; `gtype` lets you notate a function as being parametrically polymorphic, though from my cursory inspection, it doesn't actually net you many advantages, while simultaneously netting you the disadvantage of having to use implementation-specific CLTL extensions that may or may not actually lead to an improvement of the correctness of your code. The purpose of CL-ADT isn't to give you this whole new world of strictly and strongly typed functional programming, it exists to solve an 80% use-case. When I want a discriminated union, CL-ADT gives me that. CL-ADT doesn't contain a "pattern matcher" so much as it does a macro to discriminate that union. I don't appreciate the author's speculation of it being "not complete" and "not focused on performance". It is complete: it discriminates unions like it's supposed to and nothing else. It is performant: it even takes the extra effort of sealing the structures and specifying field types as statically as possible. The author's conclusion that these (false!) claims are why CL-ADT isn't widely adopted is nonsense. (On that note, what even counts as "widely adopted" in Lisp? Maybe the only library I count as truly "widely adopted" is `alexandria`, `bordeaux-threads`, and a handful of `trivial` libraries. I don't suspect that Lisp programmers are going to be heading to `gtype` in droves any time soon.) I'd like to think of CL-ADT as part of a new breed of Lisp libraries that does a bit the opposite of what many Lisp libraries do, including `gtype`. In particular, it provides a very simple set of *orthogonal* functionality that won't interfere with other Lisp code. It doesn't make up a bunch of crazy new syntax. It doesn't force you into an entirely new paradigm of programming. It doesn't add quasi-CL-but-slightly-different primitives. ADTs (of CL-ADT) are just (sealed) structures and nothing else. Any library, function, system, and so on can work with them just fine. There are downsides to the simplicity of CL-ADT. Because of this simplicity, it doesn't have the fluff of statically typed parametric data structures, because they're simply not possible to make in a way that fits with CL's type system. If you want parametric types, parametric data structures, and parametric functions, you really *do* need a new language. You can't do that stuff in standard, idiomatic Common Lisp. The good news is, Lisp lets you build languages. So if you're willing to agree to write in a new language, you can get the job done in Lisp. That's what Coalton](https://github.com/stylewarning/coalton#coalton) is for. If you agree to write *all* of your strictly and strongly typed functional code in an embedded DSL of Lisp, and you're willing to communicate between Lisp and the DSL with a few primitives, then boy do I have an offer for you. Coalton is an embedded dialect of ML in Lisp, which does full Hindley-Milner static type checking on both parametric functions and parametric data types. In Coalton, you *can* define `liszt` with [truly parametric types](https://github.com/stylewarning/coalton/blob/master/src/library.lisp#L27). It has so far been a one-man weekend project, so it needs work. It's not a pleasure to use, and the library of type-checkeable functions and data structures needs to grow. But it *does* work, it *is* being developed, and it *does* solve real needs of people who want, need, or rely on static compile-time proofs of correctness of their code. It's not a cheap veneer over some simple functionality, it's not 1/2 working for a quarter of your codebase. It is a real asset, providing something complete and novel to the Lisp ecosystem.
here is a short comment: In the future there **could** be an implementation that naturally recognizes `gtype` and propagates its type assertion in the compile time. This is an implementation specific feature that any existing implementation can choose to support, too. The advantage of `gtype` over other libraries is that *it is not a macro*, and is truly expecting some implementation to natively support this feature, with minimal compiler modification (e.g. you don't need another special ops for this --- just edit the type propagation pass.) `gtype` ONLY provides a way to express parametric type constraints in Common Lisp code without conflicting the existing standard declarations. While it does some minimal runtime checking through the use of `resolve` macro, it is an insignificant minor detail. A new implementation that supports `gtype` natively would run the normal CL code as well as the `gtype`-annotated CL code.
Perhaps it changed.
Here's another way to put it. The purpose of cl-adt and gtype is different. The former is to provide a DSL to write a program with type correctness, WITHIN/ON TOP OF common lisp. The latter is to improve/augment the base type declaration system of common lisp, in a backward-compatible manner (as most impls would just ignore them). Declare-declaration is indeed already completely outside of ANSI standard. The only criticism I have about Coalton is that the syntax is too different from the typical common lisp idioms.
480 pages -- it has been a journey!
Yay! Can’t wait to get it in my hands!
And separate namespaces for functions vs. variables is a great and practical thing, Lisp-1 dogmatism notwithstanding.
I imagine you have some sort of prepared statement for people curious about using all caps "LISP" in a new book and its website.
For the sake of argument, why would someone use this over Build Your Own Lisp?
because everything nils writes is pure gold and BYOL is actually pure crap
&gt; *And separate namespaces for functions vs. variables is a great and practical thing* Milliions of users of Linux and other POSIX-like systems benefit from this each time they do anything with the shell, which is a "Lisp 2". PATH() { echo "I have nothing to do with the PATH variable' }
This looks great and I think I'll buy it! I have a question / request to the author: ideally, I'd like to get both a physical and a digital version. The ebook version on Lulu does not seem to have clear licensing terms, especially whether we are allowed to print it for personal use. Whatever the case may be, could the description or PDF itself be amended to include a more explicit license? Thanks again for the great work!
My first thought when reading the title.
Really cool — I just bought a copy. One thought for a future edition: you might consider typesetting it with LaTeX and a serif font for the body text. I’ve done that with a few books and I’ve been very happy with them. Really though, for a technical work like this as long as the information is good then the look doesn’t matter nearly so much. Can’t wait to read my copy!
Constellations! I've ordered my copy.
I refuse to get the memo. [Mission statement](http://t3x.org/lsi/preface.pdf)
Feel free to print the PDF copy!
When JS evolves proper file compilation, this little imbecile will have no choice but to re-evaluate his position on `eval-when`. JS has undefined behavior, they just call it "implementation-dependent" and "implementation-defined" to avoid the **word** "undefined". Note that the ECMA-262 standard does not define these terms in its scanty Terms and Definitions section even though they are used all over the place. Nowhere in the document is there a requirement that "implementation-defined" means to execute successfully, in a manner that must be documented by the implementation. If, upon encountering "implementation-defined" behavior the JS program behaves unpredictably, or abruptly terminates (with or without an error message of some sort), that behavior does not violate anything in the document. This is a jaw-dropping omission for something supposed to be a language standard. Well, it's from Microsoft, what do you expect; it's MSDN-grade documentation. Let's talk about limits. Can a JS program have any degree of lexical nesting without ill-effects? Any depth of non-tail recursion? Can it allocate any number of objects? What are the consequences when such limits are hit? (I don't know of any language that defines all behavior, except for some machine instruction sets. Machine instructions spell out everything: there is no "lexical nesting", the memory is specified through the addressing structure and all dynamic allocation is supplied by user routines. Recursion is a concept built by the user: the stack pointer is a concrete address and its valid range is established by the user's environment, with predictable consquences like accessing a guard page that triggers a very specific CPU exception with precise semantics. ...)
Tried TeX and was not happy with it! It is basically the reason why there is currently no print edition of Practical Compiler Construction. I have a half-finished TROFF version, but that's low priority. I think that sans-serif is acceptable as long as the lead is sufficient, and it looks much cleaner. YMMV, though!
LISP (sic!) System Implementation does not teach C, but goes really into the depths of LISP implementation. Also: Lots of beautiful figures. Cover art featuring an octopus! 8) Support a starving author! ;)
Style... ;-) Personally I would expect that `DEFUN` looks like in traditional Lisp, not like `DEFINE` in Scheme. I would also provide an additional `v` in the name. And call the vars l1 / l2 or list1 / list2. (defun revconc (l1 l2) (if (null l1) l2 (revconc (cdr l1) (cons (car l1) l2)))) Also: if you write LISP, then you might as well write the code in uppercase. ;-)
Thanks!
Just bought it. Can't wait to read it. Also, awesome cover.
IMO, A and B are the perfect names for the variables. It's LISP, so what will they be? :) If they were fixnums, N, M, K would be best. Or even X, Y, Z (although those might be realnums). L1 and L2 look ugly to me, but that's just a personal preference. LIST/LIST2 is right out! ;) Yeah, the DEFUN is unusual. I thought about using a different name, but then "DEFUN" is simply too cool! Regarding upper case: hmm! Now that's an interesting idea! :)
Take my money!!!
By the way &gt; *"reconc (‘‘reverse and concatenate’’) is a well-known LISP idiom, just like strcmp (‘‘string-compare’’) is a well-known C idiom.* Hardly the case. C codebases tend to be replete with `strcmp`, whereas `reconc` is hardly seen in the wild. Or, rather, `nreconc` is hardly seen in the wild; `reconc` doesn't exist in Common Lisp, which is an rather odd thing for a "well-known Lisp idiom" not to be doing. Pardon me, "LISP idiom".
Point taken! That being said, I have seen RECONC quite a few times, although never in a Common Lisp (yep!) context.
In Common Lisp the function is called REVAPPEND.
Holy crap. Some of your lisp style advice given no noobs is undoubtedly useful, but stylistic bikeshedding at this level is... not.
It is absolutely not a book for "noobs".
If you sold it for &lt; 10e, I'd buy it and put it up on gen.lib.rus.ec. For 30euro, I'm not even going to try to read it.
Would've been really nice to have serif-font version. Still, a great book!
Or NRECONC.
By the looks of things, LISP System Implementation goes into compilation of some sort, and was written by someone who has experience with Lisp and implementing Lisp systems. Build Your Own Lisp only has an interpreter, uses some silly parser the author wrote that you don't need at all, names its data structures weird (calling them s-expressions instead of lists, the hell), some weird macro system involving "q-expressions" (which actually comes before the environment model in the book? the fuck?) and, well, this: &gt;Conceptually, syntactically, and in implementation, this Lisp has a number of differences to other major brands of Lisp. So much so that I'm sure I will be getting e-mails from Lisp programmers telling me it isn't a Lisp because it doesn't do/have/look-like this or that. &gt;I've not made this Lisp different to confuse beginners. I've made it different because different is good. Really the author just made something weird and confusing. Then again, I don't think the emphasis was to actually make a Lisp, rather it was to: &gt;Learn C and build your own programming language in 1000 lines of code!
take my money
Just ordered pdf!! Can’t wait to dig into it!!
&gt; &gt; *I've not made this Lisp different to confuse beginners. I've made it different because different is good.* Different is good. Highly non-conforming, incompatible different that continues to use the same name: not so good.
Yup, exactly that.
book is great just got my copy :)
&gt; (calling them s-expressions instead of lists, the hell) S-expressions are linked structures of cons cells. They are subtly different from ordinary lists. In particular, and for example, the structure (A . (B . C)) is an S expression, more typically printed (A B . C), that isn't a proper list.
Even better, you could call them conses, and I shall.
I feel like he can write LiSp any way he wants after displaying the brilliance and depth of understanding in his writing. I haven't read this book yet, but I'm a fan of things like this: http://www.t3x.org/lisp64k/index.html
&gt; g-fu is a pragmatic Lisp Narrator: g-fu is not a pragmatic Lisp.
[Repost](https://www.reddit.com/r/lisp/comments/busvaj/the_tragedy_of_the_common_lisp_why_large/), and also this sucks.
How daft do you have to be to post a dupe of something that is still item #7 on page 1?
what does 'first class' mean in this context?
Aren't gensyms always first-class, being a special case of symbols?
I don't understand this notation: (LAMBDA; (X); X) What is the semicolon doing there? In McCarthy's paper the semicolon was used in argument lists between the arguments: cons[(a . b) ; (c . d)] The paper says &gt; McCarthy used a third notation for convenience. A list is many S-expressions separated by semi-colons. (FOO; BAR; BAZ) What?
Thanks for reading. I'm not usually on Reddit but I noticed some traffic from the site this morning, and got curious. You're right! I messed a couple of things up. I just published some corrections. Regarding EQ, McCarthy writes "eq \[x;y\] is defined if and only if both x and y are atomic." The paper also describes a function "equal" that is "a predicate that has the value T if x and y are the same S-expression, and has the value F otherwise." Maybe you're thinking of equal?
A special case without literal support, yes.
I'm not sure how to phrase this, but how do you delimit the environment `$foo` is bound in? Something like `(with-gensyms (a b c) ...)` is trivial to understand, but your example makes me wonder. I'd guess the deepest one created though.
I'm trying to think of a good reason to spew this kind of bullshit when you clearly don't have a clue. Is it just the ego-boost? I mean you have to hate something, right? Compensate in some way for feeling pushed around and insecure in real life. Please get a clue, for everyone's sake. This leads nowhere worth going and you'll have to deal with every single harmful thought before your miserable joke of a life is over.
You are right. In this paper it is defined as you say. It was then different in the actual Lisp 1 Manual&gt; &gt; eq[x;y] is defined if and only if either x or y is atomic. eq[x;y] = T if x and y are the same symbol, and eq[x;y] = F otherwise. &gt; eq[X;X] = T &gt; eq[X;A] = F &gt; eq[X;(X . A)] = F
I usually take that to mean they're represented using their own names in the code, as opposed to hidden behind an api like gensyms usually are. Wouldn't it be more interesting to focus on the idea than the title? I think so.
An interesting idea! However, like other commenters have pointed out, the title is confusing.
Responding to criticism is tough. I know it firsthand since I also do a very poor job of it. I think now would be a good opportunity to reflect on what you just said, and whether it was merited or justified. Maybe it can be rephrased, perhaps you can cool down a bit before answering. In your response, you've actually undermined yourself by making yourself look like the bad guy.
I don't agree, and I don't need someone else to tell me how to react.
I was trying to understand the idea communicated in the title. https://en.m.wikipedia.org/wiki/First-class_citizen
**First-class citizen** In programming language design, a first-class citizen (also type, object, entity, or value) in a given programming language is an entity which supports all the operations generally available to other entities. These operations typically include being passed as an argument, returned from a function, modified, and assigned to a variable. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/lisp/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
"AVAILABILITY CuLi and test applications will be published on the web server of the Johannes Gutenberg University Mainz under https://version.zdv.uni-mainz.de." anyone been able to access it yet?
There is literal syntax for gensyms: `#:`. You can use `#=` and `##` for repeated reference. Example: `(eq '#1=#:foo '#1#) =&gt; T`
OP actually misused the term [literal](https://en.wikipedia.org/wiki/Talk:Literal_%28computer_programming%29), but that has become so common that resistance seems futile.
**Talk:Literal (computer programming)** Felt this needed to be made a bit more precise and ended up rewriting it - Sorry! don't apologise, you did a great job. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/lisp/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
Is it possible to ban all these stupid bots from a subreddit?
&gt;when you clearly don't have a clue This only shows you have no clue of who /u/stylewarning is and his contributons to the Lisp ecosystem.
&gt;Lots of beautiful figures. Cover art featuring an octopus! I want a "premium" version illustrated by Conrad Barski, please. Btw i love your website, and had great fun clicking on the "about nils" page. Yes, we're not objects.
You are overreacting way too much.
Sorry, it’s true, I didn’t say something constructive. A lot of people who make new programming languages call it “pragmatic” as a result of an ego-centric point of view. If the programming language author wrote it, then it must have avoided any fluffy academic nonsense in its design. I reviewed this Lisp, and I found that almost every aspect of it is incompatible with every other Lisp. So it doesn’t scream “pragmatic” off the bat. But then I dig further and wondered, “would the essential elements of Lisp apply to this language, so someone who has taken a course in Scheme could get it easily?” The answer again seems to be “no”. Gratuitous changes to various syntaxes, like quasiquote. Gratuitous departure from cons cells as lists. Etc. Does making it embedded in Go make it pragmatic? Criticism of Go aside, there are perfectly reasonable embedded Lisps. From the ultra-lightweight Scheme dialects to the heavyweight Embeddable Common Lisp. Now, to be clear, there’s nothing wrong about making a programming language. It’s especially fun making a Lisp! I have no vitriol to fun engineering efforts. But if I wrote Go for a living, I don’t think my boss would say “embedding some guy’s incompatible, home-grown Lisp in our codebase is a reasonable, practical idea.”
A “gensym” isn’t an object. It’s a function to produce an object. Those objects are uninterned symbols, which are entirely first-class citizens in Common Lisp with native syntax. You can use GENSYM the function to produce a new uninterned symbol guaranteed to be distinct from all others present, or you can use the syntax #:x to make an uninterned symbol whose name is "X", which will also be distinct from all others. What more is there to offer do you think?
[English usage note] Is it still overreacting if you don't do it too much? :)
&gt; I don't need someone else to tell me how to react. Narrator: He did.
/u/MrShiva I'm a bit late to the conversation, but I've created [cl-rdkafka](https://github.com/SahilKang/cl-rdkafka) recently. It wraps librdkafka and provides a lispier interface, as well (both a high-level producer and consumer are provided)
I've just got versions of drakma and hunchentoot working with schannel instead of cl+ssl on windows. Seems to be working ok.
After some thought, I don't think something that isn't static should have a literal form like that. `(f x)` will always funcall f with x, `'x` is always x quoted, etc. `$x` breaks this consistency as `$x` will return a different value when read each time.
And I suppose you are the one who gets to decide who has reason to react which way? Please get over yourself.
That's nice, didn't know. To be useful, it really needs a better syntax though; macros are tricky enough to get right without parsing something like this. I do wish that Common Lisp would allow some form of read macros without the #-prefix, it feels too much like a separate syntax bolted on to the side.
In Lisp jargon there is definitely "a gensym" which refers to the thing returned by `gensym`. E.g. "this macro requires three gensyms to guard against accidental capture".
&gt; *Responding to criticism is tough.* No it isn't. Just practice saying thing like: "If you don't like it, don't use it." "Patches welcome." "Fork the code." "By {pragmatic/useful/performant/small/clean/...} here is what I mean: ..." Pin them on your fridge, if necessary.
Let's avoid the word "need", and re-frame it in terms of "benefit from".
done
I don't know what is meant by "environment" here, but this notation would make the most sense if it is namespaced to a single top-level form. So for instance: (foo '$bar '$bar) ;; these two $bar's are actually the same symbol. (foo '$bar '$bar) ;; so are these, but not the same one as in the previous form I.e. the $ sigil denotes a symbol namespace restricted to a single top-level form. (A single top-level form in the reader sense, not in the compilation sense, that is. A compiler might treat `(progn a b c)` as three top-level forms, but to the reader it is one, so that a defining effect in `a` is visible to `b`, but to the reader it is one form.) The problem with gensyms which are scoped this way is that they are not always correct. Sometimes each invocation of a macro really has to manufacture fresh gensyms. The safer thing is to just always do that and not try to rely on reader tricks. If multiple invocations of the same macro are nested, then if that macro keeps re-using some read-time gensyms, there is the concern that they will somehow interact due to sharing the same private symbols. Before you can use that technique, you have to be sure that isn't the case, and that costs extra brain cycles which offset some of the gains from having a slick syntax for read-time gensyms.
actually it does. `(` is a reader macro. You could change the reader to use `[]` instead of `()` IIRC, Erik Naggum posted how to do this in one of his rants against people who complain about parentheses but I can't find it right now.
Environment as in lexical scope, except g-fu supports first class environments which means it can come from anywhere. The macro call scope in this case, so fresh symbols are generated for each expansion. I feel like the more barriers we can remove to writing correct code, the better. Switching mentally between expansion and evaluation mode often throws me off when writing macros, being forced to do that every time I need a variable is a major drain.
&gt; I do wish that Common Lisp would allow some form of read macros without the #-prefix It does allow. I think you're thinking about Clojure, not CL. See, in Common Lisp, the CLSQL library and it's [ ] reader macro, for an example.
 Atoms are also S-expressions, even if they're not in a cons cell.
write a pair of terminal reader macros where `#\[` calls `READ-DELIMITED-LIST` ending with `#\]`, and `#\]` is an error. That's all. https://nl.movim.eu/?blog/phoe%40movim.eu/0521a0cd-290a-4829-af6b-895ec10639d4
 export PATH="/bin/echo I have everything to do with the PATH variable." $PATH
It's not a *type*, but it's certainly an established concept. &amp;#x200B; Historical note: It's also a system call in ITS. Yes, the operating system can return gensyms. But it was part of PDP-6 LISP before that.
That's all fine and dandy if you're completely emotionally detached from your work and/or have achieved Buddhist enlightenment. In my experience, anyone who takes any measure of pride in their work also ties that work to their identity. This leads to: my work = me, criticism of my work = criticism of me. That's why criticism is tough. Not because the techniques are difficult- they aren't.
See also https://github.com/mishoo/SLip. Apologies that this is old and probably a repost.
The wobbly spinny clock at the end is exactly the kind of culmination that I expected from such a video. Wonderful!
See also https://github.com/mishoo/SLip. Apologies that this is old and probably a re-post.
Sorry I deleted and re-posted to add "screencast" to the title, but yes! I thought it like somewhere between a practical demo and fun artistic livecoding.
If you interact with society, do not be surprised that there are some norms that society as a whole follows, and it is the duty of others to inform you when you violate these same norms. Not everything has to be agreeable to you (or indeed in agreement with you) when you deal with other people. That defeats the basic purpose of that interaction, doesn't it? It's not about me or anyone else in here, it's just about that.
The wobbly spinny clock at the end is exactly the kind of culmination that I expected from such a video. Wonderful!
Awesome!
I tested the current head --- it seems fixed now. thanks!
Thanks for this! I didn't know about SLip. I wonder if it uses part of JSCL?
oh mighty FJames For The Win (ftw), is all in your github? a specific branch?
I was searching for a way to have Scheme macros in Lisp for my own interpreter in JavaScript. And it seems it's possible and my lisp allow to use \`...\` as symbol so it should work even better then in Common Lips.
&gt; Okay, Tom, this system runs in Lisp. [Why is Lisp the right language for an AI application?](https://youtu.be/_S3m0V_ZF_Q?t=1002)
Yeah I’ve got forks on my github. You’ll need a few of my other libraries (fsocket, dragons, schannel). I had a technical problem with usocket so I had to use my own socket library to get something working. Drakma seems to work fine, hunchentoot mostly is ok but only with self signed certificates, I need to do some more work to polish that side of things.
A followup episode: [1986](https://www.youtube.com/watch?v=7Uz3HYfCIGc) -- vision recognition, NLP, Terry Winograd, Symantec Q&amp;A.
&gt;I had a technical problem with usocket I feel you're pain. You're not the only one... Thanks for this info, fj.
TL;DW: Q: What limits of AI? JMC: Human intelligence. Q: Is AI harder then we thought? JMC: Yes, because everyone is just doing "IF .. THEN .."
&gt; JMC: Yes, because everyone is just doing "IF .. THEN .." https://www.reddit.com/r/programming/comments/6hm9n/programming_youre_doing_it_wrong/
paging resident lisper /u/theangeryemacsshibe to do a YTP version
&gt; In my experience, anyone who takes any measure of pride in their work also ties that work to their identity &gt;This leads to: my work = me, criticism of my work = criticism of me. That was the difference, in my university, between the students of literature/social sciences versus engineering. The former valued students' subjective opinions and stances, which is invariably tied to their egos of course. On engineering tests, the correct answers were independent of the individual that was giving them.
look, a full Sysbollocks is coming soon, maybe I'll use this too
will it be a Sysbollocks 3600 or will it be a later model?
obviously a [Sysbollocks 6900X](https://coinsh.red/ipfs/QmPi5kU2mvZPqgbuuSDHZmDSsmWZZCXWvdBC8sduoko8jm)
Those 36MB of cache should be enough to keep all the latest-generation conses close.
Nope, I didn't know about JSCL back then. It's written from scratch. It's not really useful for serious work (probably too slow), but bootstrapping it was a great experience. More here: http://lisperator.net/slip/
Hello, congratulations for all this.
i need to take a look. This is great info!
Including conditions, format, an ffi, and tiny CLOS, emacs editor, turtle graphics, is impressive and makes it better than many Lisps that have been written.
Common Lisp also allows `...` as a symbol.
Common Lisp does that. Actually the whole s-expression syntax is implemented via reader macros.
http://www.gigamonkeys.com/book/ has several chapters named Practical that show you how small example projects are built inside Common Lisp.
"Paradigms of Artifical Intelligence Programming: Case Studies in Common Lisp" aka PAIP by Peter Norvig is the best How to Design Programs for Racket. Realm of Racket, writings games in Racket.
Didn't know that, the code have \*\*\* instead of ... because they said that they couldn't use it.
&gt;that a member of the Lisp community has written Besides Practical Common Lisp, which is excellent, another content to check out is the "Common Lisp Cookbook", [here](https://lispcookbook.github.io/cl-cookbook/), maintained by the boss /u/dzecniv and featuring lots of content by the community. It also has a list of more learning resources, so ch-ch-check-check-it-out!
While u/xach is "technically correct", an unescaped sequence of dots is a syntax error. You'd have to escape it, like `\...` or `|...|`.
Have you looked at land of the lisp book? http://landoflisp.com/ It introduces common lisp via small games. I've been going through it and find it helpful.
Hello (a bit late), The community did update the most important website :) http://common-lisp.net/ see also https://lispcookbook.github.io/cl-cookbook/
&gt; via small games And truly awesome comic strips too!
Nice!
Very true!
This is quite impressive!
Great going!
I learned Scheme and C++ simultaneously when I first started programming. &amp;#x200B; My first reaction was "is that it?" I had been conditioned to believe getting a computer to do something useful involved a lot of ceremony, complex syntax, bits of trivia, and opaque binaries that transformed my program into some weird binary on disk. In Lisp, you type something and see what happens. Other than the feeling I was being tricked due to the simplicity, the main hurdle was learning to think in terms of expressions returning values, versus statements performing side effects. &amp;#x200B; As for syntax in other languages, it just feels like learning trivia, i.e. a waste of time. Something I hate about this industry in general is the endless amount of trivia, and the dearth of actual enduring knowledge. Knowing what the fourth argument to the connect call in redux is a very different thing to knowing the fundamental paradigms of computation.
I didn't learn lisp as a first language, so I get that you're not asking for my opinion but maybe it'll help. The best answer I've come up with is this: /* This is a statement */ function(argument, argument); and ;; This is a data structure. (function argument argument) Since it's a data structure, I can manipulate it in all sorts of ways. Speaking about Common Lisp specifically, I can choose to manipulate it when the code is loaded, when the code is evaluated, when the code is executed, all three, or none, and that's really just the very tip of iceberg. The rabbit hole is bottomless. Of course, the amount of footguns you can create with that if you don't exercise discipline is enormous, but once you gain some intuition nothing compares with that level of power.
Once upon a time, I learned Perl; it was Perl 4 back then. It was full of clever syntactical tricks and I loved it. Then Perl 5 came, with MORE clever syntactical tricks! More magical abstrusities! Then one day I learned Lisp. I was never able to enjoy Perl again.
Well, there's syntax, which in lisp is only due to crazy macros, mostly loop. There's the learning factor for the various precedence rules, but after some time nobody cares. I still care about hating loop though.
&gt; Well, there's syntax, which in lisp is only due to crazy macros you should check the ANSI CL standard some time. See for example: special operators, various defining macros like DEFSTRUCT, DECLARE and the syntax for declarations, various variants of lambda lists, format strings, etc etc.
I remember distinctively seeing something about Stallman and a snippet of Lisp a little less than a decade ago. This was back when I was safety tucked in the corner with C &amp;#x200B; I thought at the time, "Well I love Stallman but I guess when you get to the top you go crazy and use insane languages". I paid it little heed after that but remembered something about it being the "path to enlightenment". &amp;#x200B; Then I met Python and realized syntax could be different, but for the worse. Then I met Haskell and realized programming languages can be cool but also have bad syntax again. (Whitespace with indentation as syntax really? Just my personal preference not to like that I guess) &amp;#x200B; Then from Haskell I decided, "well I've already gone a little off the deep end might as well see what Stallman was smoking". &amp;#x200B; And then I was passed a blunt wrapped in a million parenthesis and in a moment all of the C-Family syntax was completely ruined for me. I don't know how I lived my life without all the parenthesis. Such a simple and beautiful syntactical rule. Takes 5 minutes to understand; over a book on Javascript constantly having to apologize for why you have to add a seemingly innocuous pair of braces to a function because the language designers did it "just cause". &amp;#x200B; To me the only languages with "Correct" syntax are Lisp and Forth (and maybe Prolog). Coincidentally, these languages happen to have extremely good meta capabilities. So there is something to getting syntax right by keeping it very simple. I see some people laugh at homoiconicity while descending into an abyss of insanity with their C++ templates to claim that they have macros too. There's a whole paper that could be written on just this paragraph though so I'm aware there's some gaps that need filling in to this logic. &amp;#x200B; Not trying to bag on anyone but it seems to me that a wide margin of programmers are really just gluttons for punishment. Part of lisp's enlightenment to me was the simplicity it gives you by telling you to pull a beanbag chair up next to Stallman and chill for a bit. &amp;#x200B; Parenthesis Ad Infinitum
Yes, of course: special forms (aka builtin macros in C) and macros. But all those still honor normal lisp syntax, defstruct, defclass, defmethod, declare, the, ... Just loop went overboard, series not so much.
 my next language was forth and i can't remember that i cared about syntax in any way. the lisp was interlisp, a fairly verbose type with "multiply" for "*". i learned lisp from a fairly botched thesis without explaining macros after reading douglas hofstaedter's lisp-column every month, so practical experience with it i had not. i remember liking C's syntax much more than pascal's. I started liking lisp's syntax a lot after designing a couple of syntaxes myself without the nice feeling of getting it right. From then on I used s-expressions as a precursor before json, because easy to parse and build on it, even in C. That was at some time in the 20th century. Since then I've seen many botched homebrew syntaxes. Lisp is a good universal data format, too, trivial to parse in any programming. Notation IS important, but if you think you are smart if you leave the s-expression mold for clever complications, you are probably wrong and in for many unpleasant surprises. Clever syntax interacts with other syntax in very clever ways, and at some point you are under zugzwang and must make decisions that make your head spin. From the domain-language perspective, s-expressions make development of syntax for the project a non-issue. I don't know how that could get any better.
&gt; But all those still honor normal lisp syntax, What is 'normal' Lisp syntax? Are you talking about s-expressions? They are not the syntax of Lisp. Can you remember how the syntax of DEFSTRUCT is to define a structure based on a list with a BOA constructor? Here is the syntax for DEFSTRUCT: defstruct name-and-options [documentation] {slot-description}* =&gt; structure-name name-and-options::= structure-name | (structure-name [[options]]) options::= conc-name-option | {constructor-option}* | copier-option | include-option | initial-offset-option | named-option | predicate-option | printer-option | type-option conc-name-option::= :conc-name | (:conc-name) | (:conc-name conc-name) constructor-option::= :constructor | (:constructor) | (:constructor constructor-name) | (:constructor constructor-name constructor-arglist) copier-option::= :copier | (:copier) | (:copier copier-name) predicate-option::= :predicate | (:predicate) | (:predicate predicate-name) include-option::= (:include included-structure-name {slot-description}*) printer-option::= print-object-option | print-function-option print-object-option::= (:print-object printer-name) | (:print-object) print-function-option::= (:print-function printer-name) | (:print-function) type-option::= (:type type) named-option::= :named initial-offset-option::= (:initial-offset initial-offset) slot-description::= slot-name | (slot-name [slot-initform [[slot-option]]]) slot-option::= :type slot-type | :read-only slot-read-only-p
Same. Common Lisp totally killed the pleasure of programming in C and C-like languages.
QUESTION 1: if you don't like nonlisp syntax, then how do you work with it? (is it getting better as you learn that language or perhaps worse?) &amp;#x200B; QUESTION 2: how can you tell if you should learn computer science? at what point can you say: "ok this isnt working lets move on to something else" and what would be the reason for that. &amp;#x200B; QUESTION 3: if you dont like whitespace based languages like python, do you like parinfer? &amp;#x200B; some people here mention that after lisp they cant enjoy other syntax, i have the same problem. (only i m not a real programmer) &amp;#x200B; i learned lisp first (scheme\\racket), it was actually more like i learned computer science using lisp. and i like lisps, i really like s expressions, and that everything is like a function. &amp;#x200B; one problem - it is not popular. and that is a huge problem. its easy to find tons of content for popular languages, get help, get work etc. &amp;#x200B; getting paid is what i wanted, but its extremely unlikely to find work that involves lisp, and when there is one, its certainly not for noobs like me. &amp;#x200B; so uh computer science is computer science right? i can learn other language and use it. except i cant. because i dont like it (language), maybe even hate it. &amp;#x200B; i certainly didnt try hard to learn other languages, but when i look at them, i just dont like how they look, all the unnecessary complications that just can be solved with s expressions. i see some decisions were made, but i dont see why those decisions were made. &amp;#x200B; popular languages are oop. that is something that i dont know and that looks complicated again idk for what reason. &amp;#x200B; because i m not a real programmer, i dont know, is lisp syntax really that much better and easier, or other syntaxes make sense and are actually good (right now i think that they are a historical accident, but again i m not an expert at all) ? &amp;#x200B; i know that syntax is not everything in a language, but for a lisp its a big part, and i see that this big part is lost in other languages for no benefit. &amp;#x200B; idk if i like programming, i spent some time learning it, but i cant say that i would do it over watching something or playing game. and while its possible to find job it is very unlikely. but i was able to solve many problems, that i had while i was learning lisp, some of which were not easy, that is something that i cant say about other syntax languages, as soon as i got first problem, i didnt want to solve it and it is still unsolved, while it wasnt that complicated at all. &amp;#x200B; i dont know if i should continue to study it (lisp) or not, given that i hate non lisp languages.(so to get paid i need to be some kind of lisp wizard, which would require tons of knowledge, which is not very interesting for me)
Well you should learn computer science no matter what, because that's what you are using. You are using concepts, no matter what language is selected each time. The language is just the tool to implement the concepts. Lisp has extensive oop support too, for example. Some languages may be more suitable for a task than others, but in the end you can do everything in every language. What each language is equipped with defines what of this "everything" is easier to implement with it. &amp;#x200B; The language barrier at the professional world is indeed annoying, and it is hard to find jobs with Lisp alone. So, unfortunately, you "have" to learn other languages too to make a start in the industry. But because it is actually concepts you are using, when you become acquainted enough with the concepts needed for programming, learning a language means getting used to another syntax wrapper to get the job done. So, find the right balance between syntax hate and job prospects, and go for it. Check for the number of job offers available, if you wish to have a clue about what opportunities a language will give you. In the meantime, do your own projects to get used to real-world programming and the need for clean and elegant code, and solve puzzles and problems to get used to data structures and algorithms. &amp;#x200B; I don't know who you are, if you are in school or college or if you work somewhere already. Nor is it necessary you will like programming in the end. But if you wish to become good in programming, then, like anything else, read about it a lot and do a lot of it, hands on. It is, still, more art than anything else. No passion and willingness mean you won't go far in it. If one day that switch turns on that makes you want more of it, that makes you curious about programming and wishing to become as good as you can get, then you've arrived at the point needed.
Lisp was my third language after Focal on a PDP-8 and Pascal. I learned Lisp with APL and Snobol in a comparative languages course. I've programmed in lots of languages including assembly and for the most part I have enjoyed them all. Each of them causes you to think differently. You also structure things differently. Even between scheme and common lisp. With scheme, I think more functionally. With C, C++, Pascal, Java, etc things are top down, you know what you are doing before you write any code. Lisp is bottom up, more exploratory, get a prototype running quickly. Differences in syntax really does not bother me. It is what is. The only language I really hated was Basic and that was probably because of the syntax.
Stupid clutter caused by all the different types of delimiters and punctuation.
In Common Lisp at least, I don't see any value this would add beyond what we already have with *assert* and *check-type*, and you don't need to clutter the docstring to get them.
There's too much of it and too few ways of extending what's built in.
My first language and initial year of CS education was pure Scheme, with C++ and Smalltalk slipping in the second year. &amp;#x200B; \- "oh no, yet another layer of arbitrary highly opinionated static syntax" \- \*googles language's precedence table constantly\* \- "Boy, I really wish I had proper macros right now" (yes, this is related to syntax; full macros are difficult enough in sexpr) \- Why isn't everything an expression? Why do statements even exist? \*mangles trinary conditionals\* &amp;#x200B; It all mostly feels like an arbitrary unneccesary layer on top of the AST that both the computer and our brain uses anyway. My brain constantly has to play parser in the background, even though I know it's right there inside the compiler. Most infuriating is when you cannot express something because it doesn't have that particular case in the syntax (looking at you C++). &amp;#x200B; A basic tennent of programming style is that something that is different should look different, and vice versa. As such, the benefit of a PL syntax layer is that you can make languages/semantics that are different also look differently. Smalltalk, Prolog and APL are good examples in my book; Java is a syntax crime (same keywords, seriously?).. It infuriates me that every new language needs to yet again mangle C's syntax to make it feel familiar to new users.
&gt; how can you tell if you should learn computer science? &gt; at what point can you say: &gt; "ok this isnt working lets move on to something else" Well, as an example, at a certain point when I wanted to get good at drawing and painting, I realized that with enough practice I could literally be Michelangelo. But "enough practice" requires a certain degree of dedication - you have to really enjoy what you're doing. I didn't actually enjoy drawing and painting at all; it was boring and frustrating and I was awful at it. I just liked the **idea** of becoming a great artist - but liking the idea of something isn't enough. In your case, you have to decide whether you have to motivation to persist in studying other languages and making a serious career in software development. Professional programmers (yes, even even lisp wizards who get hired at lisp companies) have to understand, at least at a basic level, a variety of languages - even languages we may not like very much. It's how you gain a complete understanding of how computers and systems work.
This is probably trivial to most and is also Scheme specific, but I just **love** predicates suffixed with **?** and impure procedures with **!**. Really do miss that in other languages. Just, why, why am I prevented from using certain characters? Whoops, I mean is\_prevented\_from\_using\_chars.
I learned common lisp as a first language. &amp;#x200B; I find other languages very awkward. Particularly javascript and C. I find myself rolling my eyes a lot when the compiler fails to compile because i missed a semicolon somewhere. The syntax feels like overhead to me, there's very little gained from it. I find the structure of these languages very blocky and ugly. &amp;#x200B; I think the lisp syntax has really effected the way that I think about code. All the code I write I think of as big recursive graph/trees. I think it is hard to reason about computer code unless you have this sort of traversable structure in your head. I'm not sure how you would write code accurately without being able encapsulate the entire program and step through it. Part of this is also being able to break it down into constituent parts.
Markup in docstrings is evil. Just write a short description and put proper documentation, tests, examples, and other assets outside of it, where they belong.
&gt; What could we do in lisp that maybe python can't? I like the `#+nil` trick that helps testing functions right away. For automatic testing I use proper unit tests, I don't use doctests (too limited). #+nil (defun test-foo () (some tests)) You can put this snippet in the middle of a source code, it won't be loaded or compiled, only if you `C-c C-c` inside it. We can use functions like this to test things out, to set some state, etc. (if you want such a thing, something like `#+doctest` ?)
The link don't work, JS errors in Chromium only header and footer rest is blank.
Doctests are great for examples embedded in docstrings, making sure they remain correct -- not so great for actual tests. You don't need to change anything, just parse the example out of the docstring. There's even an established style for showing return values: ``` (foo) ; =&gt;42 ```
&gt;As for syntax in other languages, it just feels like learning trivia, i.e. a waste of time. Something I hate about this industry in general is the endless amount of trivia, and the dearth of actual enduring knowledge. (incf \*)
The site is still broken, for those wondering.
They're having problems with the site, no idea what's happening with it, but it's being very wonky today.
How's your documentation generator doing by the way ? (I'd love [a TOC on each page](https://github.com/fisxoj/coo/issues/5))
&gt;which means you can write things in docstrings with a certain syntax and a test runner can treat them as assertions Horrific.
&gt; I learned common lisp as a first language. Lucky you! Can you please elaborate and tell us how did this happen?!
Well, i started at 7 years old learning LOGO, which is, curiously, a Lisp-family language. I thought it was fun. &amp;#x200B; Then I learned GW-BASIC which I thought was much better than LOGO (how little I knew then!) Then I moved up to QuickBASIC which seemed like extremely powerful... &amp;#x200B; Then in the 90s i got my very own computer, an Atari 130XE (8-bit) which was programmed in Atari BASIC. This is a more limited form of BASIC so, for the first time, I learnt that languages that lack certain features can be an annoyance and a huge pain in the arse. &amp;#x200B; My next language was C and i was impressed by the more minimal syntax. I liked C a lot, in fact i was almost in love with that language. Later I learnt Prolog in my spare time and my head \*\*exploded\*\*. Prolog was the first language that really shocked me, because it was so much different to everything else. It seemed like magic. &amp;#x200B; Afterwards, in college I learnt Pascal, which was a piece of cake because i had already tried ALGOL-60 on an old 8-bit Kaypro I had. Then we changed to C++ which looked like an "empowered" version of C, but this was the first time I thought that perhaps a language has too much syntax, or an uncomfortable syntax. &amp;#x200B; Later we were asked to write in Java and the first thing I noticed was that I was not allowed to use multiple inheritance and THAT limitation was considered a "good thing" by our teacher. WTF moment. I did like, though, the concept of compiling to portable bytecode, something that was mentioned on my Pascal books (when talking about UCSD p-code). Pascal had far cleaner syntax than those, but on the other hand it felt really verbose. &amp;#x200B; Afterwards, on my professional life I faced Java for very large systems (disgusting), C# (slightly less disgusting) , then Javascript (a terrible joke, I thought), then I tried Python. &amp;#x200B; I did think Python's syntax was very nice, extremely nice and i didn't miss the \`{\` \`}\` or \`begin\` \`end\` delimiting blocks. However i soon bumped into the many limitations of Python. And its lack of speed was revealed to me when writing a financial simulator in said language. &amp;#x200B; It was afterwards that I chose to learn Common Lisp, and man, I found the syntax refreshing. Not to mention all the other nice things... I got \*addicted\* to CL, and wanted to climb to the \`toplevel\` of a building and then \`declaim\` and \`proclaim\` that John McCarthy was the savior of mankind, the one that came to purify our sins... Yeah, i went nuts. Then I learnt Ruby for applying to a job position. After using CL for a year, I did not like Ruby at all. I also had to fix a Node.js application, so i had my exposition to modern Javascript and it wasn't \*that\* bad. The ecosystem, on the other hand, was horrific. &amp;#x200B; Afterwards i read about OCaml, tried a little bit of F# and read about Standard ML. I thought that those languages had reasonable syntax, Standard ML looking more elegant and uniform in particular, but the price to pay is lack of homoiconicity. I also didn't like abandoning interactive development. But the ML languages look fine overall. &amp;#x200B; Finally, here on reddit the Rust Marketing Team finally got his publicity on my nose and I had to take a superficial look to Rust; suffice to say, the creators haven't realize that they have created a language with a syntax as horrific as a theoretical C++ of year 2050. &amp;#x200B; In short, syntax-wise: Lisp awesome, ML very good, Python good, JS &amp; Ruby acceptable, C++ ugly, Orange Crab Bad.
but cffi, no?
oh yes clojure, i actually know some, in fact i know more clojure than scheme or racket. the irony is that its a lisp that should be used with nonlisps(which i dont like), so often you need to know java or javascript. those two are infamous. &amp;#x200B; relatively early is when specifically, like what i need to know to try it?
in other words you wanted result but without process. &amp;#x200B; &gt;you have to really enjoy what you're doing to persist when things don't come naturally to you. but to what point? i tryed to make a small game, thats when i felt most interested in the process, i wanted to do this, i was thinking about it etc. but then i had a problem and another one, and another. i have no idea how to solve them, i dont have knowledge, i dont know where to ask for help, and when i do know where to ask i still get answers like: "well idk it may work or it may not work, but its probably gonna work". so while it was interesting, all the uncertainty just killed it.
&gt; Not trying to bag on anyone but it seems to me that a wide margin of programmers are really just gluttons for punishment. i don't think that is the case but i understand why you'd give that thought a go. a couple alternatives... that wide margin... - finds comfort in the ceremony. - finds value and job security in the trivia. - is inheriting the language choice of those that came before it and isn't interested in swimming up a language switch and subsequent evangelism stream. - isn't aware of how good the alternative feels. - just spent all that time learning to program and now just wants to do that with whatever tool/technique/language is in wide use.
&gt; *write things in docstrings ... treat them as assertions.* Idiotic cluster-fuck in a language for imbeciles.
To gain knowledge from the ground up, your best resource is a book on the subject. Which language were you trying to learn?
idk what exactly i should learn computer science or language. i started with sicp, its very hard for me, i m bad at math, even without math that book is hard. (i did first chapter and started second, i skipped some exercises) i did htdp second edition up to exercise 70 i think, its good but i stopped because solutions are unavailable for second edition so i cant test if i was right or wrong. i did simply scheme a little bit but it had some artificial language on top of scheme, which i didnt like. then one day i started doing codewars katas in clojure (because it was the only lisp available on that website) without knowing any clojure. i was just writing in racket and then changing define to defn, i defined iter as it is shown in sicp instead of using loops and recur. whats interesting is that it worked, you cant do all the katas this way but you can do many, from then on i started learning clojure as language, instead of learning computer science. problem is that most clojure books assume that you are a programmer of not lisps, and you just want to learn lisp skipping all the computer science, making brief stops to explain functional paradigm. thats not my case sadly. another problem is that clojure is hosted, so its assumed that i can use those languages, and i dont. i dont even know to what degree i must know them. and then when you build something its unlike anything else, here you have to imagine what you want to do, and be specific which isnt easy, then you need to imagine how to do that, i had small problems like how do i name this element? how do you choose a name for something? the licensing problem, it looks super complicated and i dont understand what i can do and what i cant and it seems like i need to become a lawyer to understand it, and that is certainly something that i dont want to do. problems with libraries, how do i figure out which one to use, some are pre realese that mention "well it works but i can break everything if i want", or that have last update 2 years ago. or that have license and idk if i can use it, and if i can then what should be done. and then maybe my whole idea is bad and i should use clojurescript instead of clojure. this whole design part, it was mentioned a bit in htdp. &amp;#x200B; just so you know for me this exercise that is marked easy: [https://www.reddit.com/r/dailyprogrammer/comments/6i60lr/20170619\_challenge\_320\_easy\_spiral\_ascension/](https://www.reddit.com/r/dailyprogrammer/comments/6i60lr/20170619_challenge_320_easy_spiral_ascension/) felt very difficult for me, i spent an hour trying to do it but i failed, and i felt like i am trying to invent a wheel, like there must be a way to do this type of things but i dont know it. so i thought it would be better to learn how to solve this type of tasks instead of trying to solve this one. but i didnt learn it.
What is an alien structure?
[removed]
FFI
Funny. I've been searching for a way to have CL macros in Scheme.
Cool. Is there anything like this for Linux?
Maybe it is sunk-cost fallacy, but I think some programmers are indeed masochists. Here are some reasons (and maybe some ways to combat them) why I think they excuse themselves: - Their languages are "inspired" by the good ones like Lisp, ML, Smalltalk: JS is "inspired" by Scheme, Rust is inspired by Haskell, etc, etc, so they must be as good as those languages. (You should be well aware neither of these examples are true.) I can make analogies to music, street food, etc, the pop culture is usually a very poor imitation of the real thing. Maybe even skim the Blub paradox; it's hard to imagine things you've never seen or used. - Unix has ruined them. Lisp is not a Unixy language; one thing you see you don't "compile" programs into binaries, for example, they run in an image. The amount of introspection and dynamic work you can do is also not common for Unix. - They believe marketing hype. Go has Google, Rust has Mozilla, C has Unix addicts, JS has webdevs, etc. Someone has someone else to convert to those languages, maybe because they are opinionated and directed and it therefore isn't hard to make an elevator pitch for them. Try explaining to a newcomer that you can use any paradigm, invent your own, and structure code however you find most productive in Lisp in a dozen or so words. However, if you fork SBCL and say it uses blockchain AI smart contract decentralised compiler magic, you will likely double the usage of Lisp overnight. - They are obsessed over efficiency. If you use a statically typed language, you're guaranteed *something*. Basically any compiling CL implementation is faster than Python and JS typically, but they don't expect anything fast (so they resort to Numpy and friends which are faster). Everyone else has a fairly high lower limit, many of which can be sure that adding two fixnums gives them another fixnum (though, that fixnum is prone to overflow, and it will, but what can you do). That is to say C and C-likes map very simply to assembler, but Lisp's more dynamic (yet correct) nature is not as easy to compile. Maybe, instead, we can show off what Lisp can do very efficiently. I can allocate a cons on my laptop in 6 CPU cycles, which is many magnitudes faster than any malloc thanks to compacting GC. - Following on from the point about static typing, maybe if a feature isn't obvious, newcomers may not notice them. For example, without type annotations, a ML program might not look like it has static types. (Can someone comment on this? I'm just speculating now.) You can tell what a macro is in Rust, its name has to end in a `!` (RIP Scheme users). But, if you showed someone `with-open-file`, they might just assume it is a special form instead. However, I do agree there is better job security in other languages, and that people are very reluctant to change; but I also believe that people can just be stupid sometimes.
&gt; Lisp is not a Unixy language To be precise, *some lisps* are not a unixy language. I love lisp for writing programs, and I love unix for coordinating programs.
Thanks for asking! It hasn't gotten much love lately. Honestly, I've been having trouble how to do things like that using cl-docutils, which it's based on. Trying to decide if it's better to work it or write my own. Was hoping I wouldn't have this problem by using an established library. Also looking at shinmeras staple which does lots of neat things but doesn't seem to support so much rich linking/markup right now. Please feel free to open issues on GitHub if you have any ideas. I'm just strapped for time.
Not sure if you're familiar with the Python version, but they aren't runtime assertions, they're an embedded testing dsl. You can provide examples in your docstring and ha e them be tested as part of a test suite.
Looks like shit.
What do you think is evil about it? I find the further code is from the documentation, the faster it goes stale. I'm not saying doctests are great necessarily, but rust for example seems to do well with some stuff like this.
Markup in strings or comments is a nuisance. It is taxing to read, taxing to write. Source code is read and written by humans, but this markup is food for a program, only there because of language and tool limitations. Structure does not belong in strings or comments (FORMAT stinks). There's no need to blame the language designers or the tool writers. They tend not to be the monkeys that have to vomit and regurgitate these huge chunks of "structured non-code" throughout their daily lives. Some tool takes the chunks and generates a low-quality reference document. Who looks at it? Not the people dealing with the code: they already see it every time they find-definition. Maybe those who don't have or want access to the source code? It's instant gratification when some tool tells you your "(factorial 5) =&gt; 120" example is consistent with the code, almost like an actual test. Feels good. The wise language designers begat docstrings, the enterprising tool writers begat Javadoctest (a "technology" you proudly mention in your resume), and now you spend your time writing tool-approved examples in docstrings. It's not hard. It looks like work. The tool gives you thumbs up. Your Product Manager pats you on the back. He spends hours dicking around the generated documentation. Occassionally he'll find a typo: an opportunity for a vanity commit or an assertive delegation. Anyway, when I look at code, I like to see code, not reams of text. The first thing I do when I need to read some Java program is to filter out all the comments. When I read a docstring, I don't want an example. I want a description, short and sweet. An example would be a program that I can actually run in the REPL.
hey you! :D
Knowing nothing about the developer I'd say it was enough effort that they feel proud to post it publicly. Not sure why you're being an ass.
As long as you are depending on the absence of specific symbols in `*features*` for your code to be commented out (using `#+nil` instead of `#+(or)`) you can use more descriptive symbol names, ej. `#+example` or `#+test`.
Good job /u/guicho271828 , you always come up with cool and useful libraries!
If there are better ways to achieve the same behavior without touching the impl-specific internal, I am glad to hear.
Hah! Sound like something I could steal from for some delayed code generation ideas that I had. :)
What is the purpose of the "for i fixnum from 0". I didn't see how it was used, except if I am missing something.
ah, I just forgot to remove it, it used be used for aref.
I said relatively early, because it is quite popular and thus you might be able to find, for example, a junior Clojure position, instead of needing to achieve considerable seniority to hit a more demanding Common Lisp position. I suppose knowing a lisp language would be one thing to help you get into clojure, as you will be familiar with the language concepts, and then you should maybe know about java or javascript, depending on the positions you want to go after. These two are not nice languages of course, but it might help to see them as stepping stones towards your goal.
Look carefully at the sidebar, in the *Books* -&gt; *Free, On-line* section. ;)
TBF, it's not immediately obvious that the link in the sidebar is actually two links and it doesn't mention a PDF.
that's cool, thank you.
I'm interested in Rust, but haven't really looked too deeply into it yet, though I've definitely noticed the dislike for Rust over in r/lispmemes. Can you give some examples of its bad syntax?
the link in the sidebar is slightly different (to the html5/epub project which has a link to the pdf project). In old reddit, the sidebar is limited to 10k characters and it is currently right at the limit. So space is at a premium. New reddit is just a copy of the old reddit sidebar because I do not want to maintain two different sidebars.
What are these `#+nil` and `#+(or)`?
Feature expressions: [http://www.lispworks.com/documentation/HyperSpec/Body/24\_aba.htm](http://www.lispworks.com/documentation/HyperSpec/Body/24_aba.htm)
I have found this interesting mainly becasue of the LaTeX and TeXinfo source.
No problem. I just wanted to explain that by clicking on the word "Structure" you would be sent to MIT Press, so the OP cannot be expected to see that the sarabander link is already there. Maybe you could scratch the "as " in "Spec (as searchable pdf)". That would get you 3 characters, which you could use to separate the two SICP links. Just a suggestion. Thanks for running this place!
If you have questions about `cl-flow` feel free to hit me up here in comments or PM, or in `#lispgames` channel at [freenode.net](https://freenode.net). As for the shorthand syntax, yeah, at the time of the design it didn't occur to me someone else is using similar stupid naming scheme for different purposes. There are properly lispy, sound, awesome, intricate and inventive names for the same operations there too.
also: playing youtube videos (youtube-dl and mpv): https://github.com/mihaiolteanu/youtube last.fm-like music player with lyrics: https://github.com/mihaiolteanu/muse and a reminder about a music player for the terminal: https://github.com/ahefner/shuffletron/
\[author here\] Let me know if it works for you. Any ideas for extra features?
I hope you wrote a program to generate this program!
That was indeed a lot of typing if he did it all by himself.
Thoughts? Problems installing? Extra functionality ideas?
`do-external-symbols` Though not all *functions* are functions. for example `least-negative-normalized-long-float` is a constant variable.
How does it look like. Do you have a screenshot?
Instead, I suggest having a testing macro that you put in the body of a function or method. It would normally macroexpand to a no-op, but use a macroexpand hook on DEFUN/DEFMETHOD/etc. to attach the data inside to the function name somehow. No need to use a string for the data.
Make it small by turning in compression.
Please see edited answer.
Of course...not! That would be too stupid, right? I took the source from the Common Lisp CookBook highlight JavaScript file and wrote some small functions to accomplish some text transformation work.
Yes. And picking them out would be somehow time consuming, so I just left it as is.
&gt;Is it possible to make really small SBCL executable by dynamically linking to the SBCL lib? If your goal is to make a really small Common Lisp executable, then SBCL isn't the implementation you're looking for. You should try using ECL instead, I think.
fyi https://github.com/wadehennessey/wcl &gt; Common Lisp implementations for Unix have traditionally provided a rich development environment at the expense of an inefficient delivery environment. The goal of WCL is to allow hundreds of Lisp applications to be realistically available at once, while allowing several of them to run concurrently. WCL accomplishes this by providing Common Lisp as a Unix shared library that can be linked with Lisp and C code to produce efficient applications. For example, the executable for a Lisp version of the canonical ``Hello World!'' program requires only 20k bytes on 32 bit x86 Linux. WCL also supports a full development environment, including dynamic file loading and debugging. no idea if it works.
I've tested it to some extent. WCL is not stable yet (frequent crashes) nor complete (as in – not standard-compliant Common Lisp)).
&gt; WCL is not stable yet Given those commit dates, I suspect it never will be, looks abandoned.
ECL is in fact libecl.so (may be compiled as a statlic library). If you strip the binary you get around 3.3MB for the Common Lisp, 1MB for the compiler module and 800KB for ASDF. CL libraries may be compiled as shared libraries too.
from the library [repl-utilities](https://github.com/m-n/repl-utilities) EXFNS: Print the external fboundp symbols of a package. EXVS: Print the external globally special symbols of a package. EXCS: Print the external symbols for which find-class is truthy. EXTS: Print the external symbols which are type specifiers. EXS: Print the external symbols of package.
Compiled FASLs are pretty small.
Maybe someone could write a program that generates executables that run sbcl and give it fasls. Each executable could be very small because it would only have to know about sbcl and the fasl.
FASLs are already executable.
Then maybe that's the perfect solution to the OP's problem.
The SBCL runtime itself is quite compact. Most of the size is in the standard library. Creating a single .fasl from an ASDF bundle (search for "bundle-op" on [https://common-lisp.net/project/asdf/asdf/Predefined-operations-of-ASDF.html](https://common-lisp.net/project/asdf/asdf/Predefined-operations-of-ASDF.html)) may be close to what you want.
Looks cool. I submitted a pull request, some links are broken
&gt; I took the source from the Common Lisp CookBook highlight JavaScript file and wrote some small functions to accomplish some text transformation work. You can also get all the symbols on the COMMON-LISP package using the REPL, and paste that into your `.el` script.
Thanks!!
Makes sense. Then you can using the values of i with the alternative approach
We'd better ask the author. Seeing interest, he could get re-motivated, who knows.
Nice work! You have a few Common Lisp libraries around music/services. Are they part of some other awesome app?
No offense meant, but what is this good for? Doesn't last.fm just give you info/videos from thirdparties while keeping data on you?
Option of storing the lyrics in actual song files. ...so I don't have to do it :) Really this is great. I was just about to get started on music as my file library is almost finished and I was hoping I wouldn't have to write a lyric finder.
oh, and maybe some use of $XDG to place the database even though it's trivial to change the source, but seems lots of people don't read it.
Yes! Thank you for asking! :) It's for a music player for the StumpWM window manager that I've been working on lately \[1\]. I've split the functionality into libraries since that might be useful for others. Currently there are lyrics, youtube and lastfm libraries, plus the music player itself, zbucium, which is also written as a library. These are submitted to quicklisp, but they're not yet in, so you'll have to manually install them as of now. And, finally, on top of this all is the stumpwm module (zbucium-stump), basically, just the interface. I've put some gifs to showcase what I've had in mind. I'm actually using it and it's quite usable. But again, it might lack some features which I couldn't yet think of. \[1\] [https://github.com/mihaiolteanu/zbucium-stump](https://github.com/mihaiolteanu/zbucium-stump)
None taken. But I'm not sure I understand your question. Lastfm keeps a huge database with user music preferences. Browsing it you can answer questions like "what are the best songs from this artist?", "what artists are similar to this one", "what are the best songs for this particular genre?" plus all the info for the artists themselves, complete with albums and song. &amp;#x200B; And on top of this there is the so-called [last](https://last.fm)fm radio. You can play everything that's in there. A couple of years back they've streamed it from god-knows where but I guess from their own databases. But nowadays they use youtube for that. So everything that you can play on lastfm you can also find on youtube. That's why the Common Lisp library. It's a way to decouple from the browser and the lastfm website. Same functionality as available on their website, only as a programmable library. I've used to write a StumpWM music player (check the above comment) and it works nicely for me.
What’s the point of n+1 array size as opposed to n?
I seem to be getting this warning again and again, but still not sure how to proceed \[1\] You mean, it would be better if the user would be able to chose where to save the database? I, for one, have no problem with tons of files in my homedir. Maybe I've gotten used to it since all the apps seems to save stuff in there. On the plus side I can add them all to source control. But if there's a better way around these issues, I have no problem changing the implementation. [https://github.com/quicklisp/quicklisp-projects/issues/1696#issuecomment-500998388](https://github.com/quicklisp/quicklisp-projects/issues/1696#issuecomment-500998388)
Storing the lyrics in the files themselves? What has gotten into you? :) I did youse id3v2 in the past to put tags (again from lastfm) into mp3 files and then filter the files by genre in [cmus](https://cmus.github.io/) \[1\], but not lyrics. But lately, I'm using youtube + lastfm more and more since all the songs are in there. That's why the library, and the related lastfm and youtube Common Lisp libraries and the player itself \[2\] If you're using the library, let me know how it works for you. I was actually thinking about requesting lyrics in bulk, like, "here's a list of 100 songs, go grab the lyrics for them". That would also imply a method to evade banning from the lyrics websites as you cannot safely make that many http requests and not raising suspicious activity flags on their side. So maybe a random timeout between the requests, every request sent to a random lyrics website and changing the user-agent on each request might spring to mind. \[1\] [https://github.com/mihaiolteanu/lastag](https://github.com/mihaiolteanu/lastag) \[2\] [https://github.com/mihaiolteanu/zbucium-stump](https://github.com/mihaiolteanu/zbucium-stump)
My copy just arrived. Thank you for writing it.
which is this: https://github.com/orthecreedence/highlight-lisp
&gt;One-based permutations were chosen because that is the dominating convention in mathematics To make array index access 1-based. n+1 because then you don't need to subtract 1 at every array access.
Its interesting, when recursion is more inuitive than for loops for others
Awesome I didn't know UIOP implemented all the XDG specification, with the appropriate defaults when the environment variables aren't specified, and windows crap too! That's one less thing to write a crappy implementation of :) I'd use uiop:xdg-data-home, solves most peoples problems except for multiuser environments that want to share the db.
I do dislike data duplication and have been thinking of storing lyrics separately so I can use them for both audio and video files, but options are always nice :) Though I forgot I'd still have to change to lrc or srt so, um, yeah, ignore that suggestion. :)
to be honest, I am not sure why he even mentions this. This is totally internal. Direct access to the array is not given. It is wrapped in a struct. He has a pretty complete api. Even has two different referencing functions: (defun perm-ref (perm n) "Compute the zero-based index of PERM at N." ...... ) (defun perm-eval (perm n) "Evaluate the permutation PERM at index N." ..... )
I might have been under the wrong impression that the data they served up was available elsewhere, since by using last.fm you become part of the data. That coupled with the fact they're no longer streaming audio themselves but linking to youtube videos, it seems a less big brother solution might be available. Though I see there doesn't seem to be a free music similarity db available.
I would say to heck with the dominating convention in mathematics for permutations. It's wrong, and at odds with mathematic's convention for **congruences**. A modulo N congruence is canonically represented by the symbols 0 through N-1, not 1 through N. And this has very good reasons for it, which transfer to permutations, which have a certain relationship with congruences. E.g. congruences modulo a prime can arithmetically obtain some of the permutations by modular multiplication.
The problem is that the elements of the permutation could be externally used as array indices.
You could have used something along the lines of (do-external-symbols (s (find-package "COMMON-LISP")) (print s)) (Plus filtering it according to your wishes.)
Thought I'd post this since the section on threads is fantastic. Kudos to whoever wrote that.
Wow, that was comprehensive!
z0ltan did (credit given at the 3rd section): https://z0ltan.wordpress.com/2016/09/02/basic-concurrency-and-parallelism-in-common-lisp-part-3-concurrency-using-bordeaux-and-sbcl-threads/ and I put it in (with kind approval).
btw, do you like the new cover ? https://lispcookbook.github.io/cl-cookbook/
nice lisp lizard!
The `do-external-symbols` is a function exported by the `common-lisp` package, so where is the bug?
Thank you, you all make CL very easy and interesting.
The atomic section makes it obvious that bordeaux-threads is a lowest-common-denominator library - similar to most other CL "portability" libraries - that lacks important features that the underlying implementation may offer. In this case that's SBCL. This would have been even more obvious if the author delved into and presented **sb-concurrency**. He should have at least mentioned it rather than proclaim that concurrency in CL is primitive. It certainly feels primitive if you handicap yourself with a pile of bloated "portability" libraries.
I think it would be really funny if the animal on the cover was the Lisp alien, but drawn in the O'Reilley style.
&gt; The portability nightmare is dragging down Common Lisp into a sea of mediocrity. Or raising the quality of various implementations to new standards?
This disclaimer should be more prominent: "Producing real random numbers on a computer is difficult, and often requires specialized hardware, or some other source of randomness from the real world. This is very important for cryptography, and is very difficult and slow. I am not talking about that level of randomness here." (BTW, producing cryptographically secure random numbers is neither difficult nor slow. But you do have to know what you're doing.)
For anyone interested, the bounty is up to 200$ already.
The page offers a kllink to a .ps and .pdf file. Reference to this very interesting memo was in a recent comment on the mailing list Openmcl-devel (openmcl-devel@clozure.com).
And that is roswell. Just ros install sbcl and it starts looking for a new version.
I think this paper is definitely outdated. One thing that's become more and more apparent in programming is a shift towards Modular Programming and the influence of Functional Programming. Both practices make a very big deal of the idea that a function or module should take an explicit number of inputs, and from those inputs return a predictable output. This "explicit number of inputs" idea is important, and something that dynamic typing undermines. Lexical closures are also a very natural and useful idea, and one that is no longer "inefficient" like the paper claims. I think the programming languages that force lexical scope are ultimately more readable and modular.
&gt;This "explicit number of inputs" idea is important, and something that dynamic typing undermines. &amp;#x200B; Dynamic typing?
On the contrary. For example, if it wasn't for bordeaux-threads, there would be a small chance that certain implementation might accept SBCL's features as a de facto standard and implement all of them. Library and program authors willing to jump through hoops to make everything run on the lazier implementations anyway makes them even lazier. OK, I realize that's not fair because some of these implementations are maintained by a single person in a small part of their spare time. Then again, that's hardly a reason to go out of your way to make your program run on these implementations.
Rp
good feature, i didn't know that.
Something like (with-alien ((x (array c-string 10))) (setf (deref x 0) "abc"))
When I do that, and then (print (type-of (deref x 0))) I get (SIMPLE-ARRAY CHARACTER (3)) Shouldn't type-of mention that it's an alien type?
You are asking it for a lisp value, it's giving you a lisp value.
But I'm not sure as to pinning the strings. Probably has to be something like (with-alien ((x (array c-string 10)) (y c-string "abc")) (setf (deref x 0) y))
I'm confused by that. Shouldn't (deref x 0) be a c-string, since x is an array of c-strings?
To narrow the problem down, let's forget about the array. (with-alien ((y c-string "abc")) (print (type-of y))) ==&gt; (SIMPLE-ARRAY CHARACTER (3))
You want to pass this to C, not just print it.
But I want to know what I'm passing to C.
I meant dynamic scoping, sorry.
It gets converted in the above code, but since you are asking for a lisp value it gets converted back. But I can't figure out an easy way to pin a list of strings to be passed into C, as with-alien does a stupid dance of converting strings back an d forth.
Note that there is at least one day delay because the CI service check the RSS on a daily basis and update the internal database
&gt; since you are asking for a lisp value I don't want to ask for a lisp value. What can I do to get it to show me the actual alien value, and make it clear that it's an alien value?
&gt; converting strings back and forth. When does it convert them back and forth? And why would it want to?
Why do you need that? But forget about c-strings, as, apparently, they can't be used with with-alien.
Here's the straightforward syntax I could come up with: (defun strings (list) (with-alien ((x (* (* char)) (make-alien (* char) (length list)))) (labels ((populate (list index function) (if list (let ((array (sb-ext:string-to-octets (car list) :null-terminate t))) (sb-sys:with-pinned-objects (array) (setf (deref x index) (sap-alien (sb-sys:vector-sap array) (* char))) (populate (cdr list) (1+ index) function))) (funcall function)))) (populate list 0 (lambda () (loop for i below (length list) do (print (cast (deref x i) c-string))))))))
What if I use defparameter or something like that? Is there a way to give that an alien value such as a c-string?
And with-alien doesn't free the alien, so, (defun strings (list) (with-alien ((x (* (* char)) (make-alien (* char) (length list)))) (unwind-protect (labels ((populate (list index function) (if list (let ((array (sb-ext:string-to-octets (car list) :null-terminate t))) (sb-sys:with-pinned-objects (array) (setf (deref x index) (sap-alien (sb-sys:vector-sap array) (* char))) (populate (cdr list) (1+ index) function))) (funcall function)))) (populate list 0 (lambda () (loop for i below (length list) do (print (cast (deref x i) c-string)))))) (free-alien x))))
make-alien-string + free-alien could be used instead of string-to-octets + with-pinned-objects, allocating in foreign memory instead. Can't say which is better.
&gt; *I get that CL is not at all minimalistic and a fairly large language.* The *CLISP* implemenation of CL runs in a couple megabytes of RAM: an amount of memory that Firefox will steal in a heartbeat if move your mouse wrong. &gt; *What is most interesting for me in Clojure is the philosophy on concurrency and parallelism, I also like the focus on functional purity and the elegance of the language a lot. * Common Lisp is a multi-paradigm language. A lot of items are mutable in CL: variables, arrays, cons cells, strings, CLOS objects. If you're a multi-paradigm programmer, you can put multiple skills to use. Common Lisp has multiple implementations and runs on multiple platforms. There is ABCL which runs in the Java machine, and there are native-compiling CL's that spin a standalone executable.
The Common Lisp Conditions system is an absolute pleasure to work with. Clojure does not, on the other hand, have a *de facto* mode of error handling (it provides support for Java-style try-catch which is extremely jarring when used with Clojure) leading to usage of ad-hoc maps with error payloads (which I find quite distasteful). SBCL's performance is also miles ahead of Clojure's, and SLIME is far superior to CIDER in almost every imaginable way. Finally, FFI in Common Lisp is painfully easy. And fast.
&gt; The Common Lisp Conditions system is an absolute pleasure to work with. Is this similar to Racket's continuations? &gt; Finally, FFI in Common Lisp is painfully easy. And fast. Is is also true for calling very small functions, like calling sin(x) in libm.a ? Another question - is programming in a functional style (that is, rather generating new container objects, instead of mutating them) efficient in SBCL? What I find ideal for the task of number-crunching and numerical optimization is iterative code and mutable data structures on the lowest levels, and a functional style on any higher level. By the way, does CL have a way to mark a function argument as const?
&gt;What is most interesting for me in Clojure is the philosophy on concurrency &gt;Rackets (Schemes) minimalistic philosophy. &gt;with an expressive power and means for abstraction which are far far larger than Python. All lisps and lisp-like languages will be better than Python in those respects. &gt;whether it would make sense to explore Common Lisp a bit further, and with this I mean probably SBCL. SBCL is just a Common Lisp implementation. If you learn, you learn CL and what you'll learn will work in any CL implementation: sbcl, ccl, ecl, abcl, lw, acl, etc. &gt;I get that CL is not at all minimalistic and a fairly large language, That's subjetive. Clojure is very large to me: it introduces a lot of concepts and it requires you to be familar with Java J2SE as well. &gt;My expectation is that the performance would be better, and that a purely functional style would be less well supported. I expect a better support for low-level concurrency primitives than for Racket, but nothing that matches Clojure - here That's just preconceptuons; we have good concurrency libs. &gt;However, I am also expecting that SBCL is less well documented, That's just preconceptuons; CL exists since the early 80s and is extensively documented. SBCL -an *implementation*- is also well documented. &gt;My guess is that when I need, for example, a XML or JSON parser library, that it would be very easy to get a high-quality implementation and stunning abstractions accessible from Clojure, and at least possible to access a good implementation in CL That's just preconceptuons; we have many XML libs and they are very good (first-hand experience here.) &gt;A hot secret wish I have is something like Clojure's concurrency primitives and immutable data types for Common Lisp. Are there any chances that this wish becomes true? We also have libraries for inmutable data type usage. Plus, most of CL's functions don't mutate. If there's something in abundance in the CL ecosystem, is language extensions. Think of any feature the language should have: yes, CL has a library that can do that. Also, we the Lispers are friendlier, funnier, fancier, and better looking, so come to the CL Party!
Please share knowledge and add a new section. Thanks!
Thanks for the feedback! &gt; we have good concurrency libs. Can you give me some pointers what could be interesting? At the moment, I am mainly interested in adding some degree of parallelism to number-crunching code. I am also interested in things like channels and actors.
&gt;&gt; The Common Lisp Conditions system is an absolute pleasure to work with. &gt; Is this similar to Racket's continuations? No. It's something completely different and as far as I know, unique to Common Lisp. [Here's an introduction to the concept from the book "Practical Common Lisp".](http://www.gigamonkeys.com/book/beyond-exception-handling-conditions-and-restarts.html)
I feel like the simplicity of JavaScript kinda doesn't matter. Sure vanilla JS can be simple but no one is writing vanilla JS nowadays. And so many JS libraries are really massive, many of them even using babel to change the syntax of the language. Not to mention things like typescript. This to me is indicative of a language that is too simple, we see this with scheme where the spec is too simple to the point where it's hard to write code that works across scheme implementations.
/u/defmacro-jam has already explained about the Conditions system, so I'll skip that. I haven't actually benchmarked it, but my experience has been that yes, even on small calls, the overhead has been minimal compared to say, Ruby's FFI or even Java (using JNA). Be warned that it's purely anecdotal. I would say that functional style in Common Lisp *can* work, but it probably will be less efficient than doing it the normal way, which is imperative. I personally like to call it "symbolic" in the Touretzky tradition, but yes, Common Lisp is best written imperatively. FP style would also probably raise eyebrows from the revered members of the community (I have personally been lambasted for using recursion in some programs instead of say, `loop`). As far as marking a function as `const`, I personally am not aware of any such functionality in Common Lisp (I might be wrong, but unlikely). Mutation is deeply entrenched within Common Lisp's way of doing things.
`bt-threads` and `lparallel` are some commonly used libraries. Note that each flavour of Common Lisp also usually provides their own version of doing concurrency and/or parallelism. The aforementioned libraries are ways of making code more-or-less portable across flavours. I would say that Common Lisp is quite suited to number crunching (compared Racket and Clojure that is). Also, with Common Lisp, you can provide some rudimentary mode of type declarations to generate more efficient code. YMMV though.
I can point you to a selection of libraries: https://github.com/CodyReichert/awesome-cl#parallelism-and-concurrency channels and actors included. There are more out there. An actors library posted some days ago: https://github.com/j3pic/simple-actors/ Also this tutorial and discussion on Threads: https://www.reddit.com/r/lisp/comments/c0bavx/threads_the_common_lisp_cookbook/
&gt;Can you give me some pointers I can't give you pointers because direct memory access is not the preferred way on CL. As for libs, i can recommend you `lparallel` for easy parallelism and `cl-stm` for software transactional memory. &gt;I am also interested in things like channels and actors. I don't watch TV. My favorite actor is Marc McKinney from "The Kids In The Hall". He really has thespian skills. IIRC, `lparallel` also lets you create channels. &gt;number-crunching code There is a numpy clone in CL in the making. There are also bindings to Cuda and GMP.
y is not what it seems. From the manual, [http://www.sbcl.org/manual/index.html#index-with\_002dalien](http://www.sbcl.org/manual/index.html#index-with_002dalien) "The names of the variables are established as symbol-macros" `CL-USER&gt; (defmacro expand (form &amp;environment env)` `;;` [`http://clhs.lisp.se/Body/f_mexp_.htm`](http://clhs.lisp.se/Body/f_mexp_.htm) `(multiple-value-bind (expansion expanded-p)` `(macroexpand form env)` `\`(values ',expansion ',expanded-p)))` `EXPAND` `CL-USER&gt; (with-alien ((y c-string "abc"))` `(expand y))` `(SB-ALIEN-INTERNALS:LOCAL-ALIEN` `'#&lt;SB-ALIEN-INTERNALS:LOCAL-ALIEN-INFO C-STRING&gt; #:VAR656)` `T`
The first difference is that Racket and Clojure are languages AND implementations - with Clojure having some more or less similar languages like ClojureScript. Whatever the implementation does or what of it is documented is the language. Common Lisp OTOH is a defined language with a bunch of quasi-standard extensions and implementations with more extensions and some interpretation of the standard language. As a language &amp; implementation Racket moves in some important way into the direction of SBCL: SBCL is an implementation largely written in itself, including a native-code AOT (ahead-of-time) compiler. The implementation can be bootstrapped with an earlier version or with some other supported CL implementations. Racket is currently being partly reimplemented on top of a modified runtime of Chez Scheme. SBCL has its own compiler written in Common Lisp creating native code and a runtime for it. In some ways a JVM-based runtime has some advantages (like a lot of industry support - but Oracle is in the process of developing new JVMs, which are large software), but it also has a lot of disadvantages for Lisp: no support for TCO, no easy executable generation, no dynamic objects (like direct support for CLOS), no easy AOT compilation, no saving/starting of images, etc. In SBCL you only see Lisp backtraces. A difference to Racket's philosophy of developing code in a deterministic way (in the IDE doing RUN starts a new Racket with the program), one may (!) work with something like SBCL much more interactively and develop the running program for a longer time (days? weeks?). SBCL has also the support of Common Lisp's sophisticated runtime error handling, which lets a program recover from a lot of runtime errors and also offers the developer interactive choices to work inside the error - when an error happens, a Common Lisp system can stay within that error - the debugger is not terminating the problematic code - then one can explore the error and even possibly fix it and continue. Common Lisp is also a low-level language in itself (with low-level bit handling, low-level data-structures, go-to-like control flows, etc). It offers a bunch of facilities, which are mid-level language features like its error handling, I/O, macros, etc.. There are also a few high-level features like the Common Lisp Object System with its own implementation layer, the Meta-Object Protocol for CLOS. SBCL gets even more low-level, for example one can implement low-level compiler extensions. Thus SBCL is a full-stack Lisp: Lisp-oriented runtime, parts of the runtime in Lisp, library in Lisp, compiler in Lisp, ... Racket will have a similar philosophy when one uses the implementation on top of the Chez Scheme runtime with an AOT. Generally for every CL programmer it's useful to have a copy of SBCL and use it for development (maybe in addition to another implementation). One of the good things of SBCL is the sophisticated compiler which gives a lot of information and warnings: missing declarations, different declarations, type errors, optimization hints, etc etc. Be prepared that while people are writing new code, a bunch of very very old code will be able to run in SBCL. Code which not only is old, but also might LOOK old. There is a lot of language stability and some stuff might not be updated for a decade or more and is still expected to run. But be prepared that the developers and users of SBCL are not working in the same domains as Racker/Clojure developers do. Thus you may see libraries and applications in different domains. SBCL users develop very often with GNU/Emacs and SLIME as the IDE. Racket has its own IDE. \&gt; There seems to be a general opinion that Scheme implementations are good for teaching while CL implementations are good for doing "real work". I don't have a very clear picture what that means, and this is my main question. Scheme was used in education for a long time, mostly with small variants of the language. For example SICP used a tiny fraction of Scheme - for example without any macros. CL can be used in education too, but there is no obvious small language documentation (like R7RS small). Books use subsets - like Land of Lisp uses a simple subset of Common Lisp to give an introduction into Lisp programming via developing games. Scheme has larger implementations, too. For example Racket. But Scheme is quite diverse in that respect - so diverse that Racket now is its own dialect of Scheme - where Common Lisp implementations share a larger integrated core language with one way to do macros, one way to do object-oriented programming, one way to do error handling, etc. Summary: what you get with SBCL is a 'full-stack' Lisp with a sophisticated AOT native-code compiler, supporting a very interactive development style.
I am not convinced that clojures vectors are meaningfully slower than linked lists. Guile-fector (https://bitbucket.org/bjoli/guile-fector) is a pure-guile version of persistent vectors, and that is within 3x of guiles c-based lists (and, I suspect, much closer on the beta for guile3). Arximboldi's "Immer" collections ( https://github.com/arximboldi/immer ) are very very close to their std::-included counterparts, and I suspect that clojure's pvectors are similarly efficient, at least if it exposes proper iteration facilities. Pvectors are usually built from 32-cell array trees, and thus have good cache locality, which is very much not guarranteed with linked lists. I suspect your hashmap implementation will not stand a chance against a HAMT, especially not when you have workloads that do lots of independent writes. I dislike clojure as much as the next guy, but the data structures are just about the only thing I really envy.
I dabbled in CL before switching to Racket to implement my PhD work, but coming back now I think I finally understand one of the key differences. There are little cosmetic differences such as the fact that Racket prefixes many syntactic forms with #, some larger differences like the fact that Racket doesn't natively have bare keywords :keyword style (though it does have a library that implements them, as well as smalltalk style keywords), but the real difference is in how the underlying runtime for Racket differs from CL. Racket's phases and module system are incredibly powerful, but they are quite rigid when it comes to changes at runtime. So while you get excellent guarantees about the behavior of compiled code, and hygenic macros, if you want to change something at runtime you are pretty much out of luck. This manifests in other ways such as the top level being hopeless because the semantics of interpreted code in Racket (and probably scheme more generally) can diverge more than one might expect. This is especially true for Racket due to the fact that it is hard to figure out what phase you are in at the REPL or whether maybe the REPL is its own strange phase. Common lisp on the other hand embraced the hopelessness, and accepted mutable state as a sort of unavoidable part of computation, and more importantly of the runtime. The community also to great pains to come up with a way to reconcile differences in behavior between compiled and interpreted code (because it used to be a big issue) and as a result you can sort of think of the default CL runtime as always being at the REPL, though that is not strictly true. The end result is the seemingly magical ability to do live reloading of classes, functions, and really any symbol in the whole runtime, change the reader macros on the fly, and all sorts of other literally unimaginable things. Of course this has its drawbacks in that you have to manage that persistent mutable state, but unlike other languages CL actually has the tools to let you do it. CL doesn't pretend like that state doesn't exist or that it is somehow bad or to be avoiding (which many languages have tried to do), instead it embraced it and figured out the tools that _humans_ needed in order to work with such systems. A good paper related to this from RPG https://www.dreamsongs.com/Files/Incommensurability.pdf.
Using Lisp has conssequences, with cons in one color and sequences in another
We aren't lisp programmers; we are cons artists
&gt; unique to Common Lisp. Well, not quite, but mostly other more obscure non-common-lisp lisps and [schemes](https://groups.csail.mit.edu/mac/ftpdir/scheme-7.4/doc-html/scheme_17.html#SEC157) as well as e.g. [Dylan](https://opendylan.org/documentation/intro-dylan/conditions.html), admittedly originally very much inspired by lisp, have similar systems.
Haha! Love it
They are also in Factor and SWI-Prolog has a library implementing them.
&amp;#x200B; λ (lisp (programmers) (are cons (artists)))
&gt; Clojure's exotic immutable structures, such as vectors or hash tables to which you can add ("conj") elements to obtain new structures that don't touch the old ones, are inefficient and impractical compared to their straightforward mutable counterparts. do you have any reference for this?
&gt; Finally, FFI in Common Lisp is painfully easy. racket has a nice ffi.
I think the "not at all minimalistic and fairly large language" part refers to the number of concepts and parts of the standard library, not its memory usage. Of course no one needs to know it all to be proficient but compared to something like lua which you can learn in a few hours CL is a *very* big language.
I speak with a Lisp
or just (cons artist)
 &gt; Error: Too few arguments in call to #&lt;Compiled-function CONS #x3000000F765F&gt;: &gt; 1 argument provided, at least 2 required. &gt; While executing: CONS, in process listener(1). &gt; Type :POP to abort, :R for a list of available restarts. &gt; Type :? for other options. 1 &gt; █
( Unmatched open parenthesis will leave you with unexplained tension for the whole day
&gt; and `cl-stm` for software transactional memory. Cliki says that `cl-stm` has been superseded by `stmx`...?
sorry, i mean STMX
In that case, make no attempts at small talk.
I have no need for vectors that have to be unfavorably compared to linked lists. &gt; *I suspect your hashmap implementation will not stand a chance against a HAMT, especially not when you have workloads that do lots of independent writes.* In run-of-the-mill single-threaded use, this HAMT nonsense will have its ass kicked by GNU Awk associative arrays. A language should provide the fundamentals first, then the boutique stuff on top for specialized use.
The "you absolutely never get anything for nothing" reference. A hash table that gives you a new hash table when you add an item, allowing you to retain a reference to the old hash table without the element, cannot perform as well as a plain old mutable hash table. It is impossible.
"Fixed" is probably relative and/or subjective.
That was so funny =) thanks.
Thanks for this interesting and useful example!
&gt;This is especially true for Racket due to the fact that it is hard to figure out what phase you are in at the REPL or whether maybe the REPL is its own strange phase. I can answer that for you: At the REPL, code is evaluated at the "execution" phase level, not the macroexpansion one (I don't remember the numbers that Racket assigns to each). Before each entered form is executed, it gets macroexpanded, and this takes place at the macroexpansion phase level. &amp;#x200B; The following illustrates how phase levels and the REPL interact: &gt; (begin-for-syntax (define (hello-world) (displayln "Hello, world!"))) &gt; (hello-world) ; hello-world: undefined; ; cannot reference undefined identifier ; [,bt for context] &gt; (begin-for-syntax (hello-world)) Hello, world! (begin-for-syntax hello-world) ;; returns void. You can't extract values from the syntax phase level, nor ;; have them print directly to the REPL.
that sounds like warm fuzzies. immutability has its place. it isn’t a lesser feature. it is a design choice.
If you know a way of producing cryptographically secure random numbers that is as easy and fast as the methods for producing random numbers of less quality suitable for simulation, I'd love to hear that. What level of "not difficult" and what level of "not slow" are we talking about?
I am not sure I agree. Clojure is opinionated and went with "immutability first, faster mutable options when you need them" and that's a fine choice. That is just seeing the benefits of linked lists and taking it a bit further. That's is a fine choice and apparently good enough or even preferable for a lot of use cases.
&gt; Racket's phases and module system are incredibly powerful, but they are quite rigid when it comes to changes at runtime. My understanding that the strict border between compile time and evalation time is necessary for sanity. There is a blog post which describes how this blog post can be defeated: https://lexi-lambda.github.io/blog/2019/04/21/defeating-racket-s-separate-compilation-guarantee/ I think the issue here is the rule that there should be no difference between a pre-compiled program, and a program running from source. I'd be interested to know more how CL addresses this, and how this makes a practical difference ;-)
With the few experiments I made, it seems really easy to use! My guess is that most of the possible complexities come from interfacing garbage-collected code with code and objects from, for example, C++, that are manually managed.
&gt; What I find ideal for the task of number-crunching and numerical optimization is iterative code and mutable data structures on the lowest levels, and a functional style on any higher level. As an aside, the tech.ml folks are doing excellent things regarding bridging strategies and efficient numerics in clojure. https://github.com/techascent/tech.datatype http://techascent.com/blog/datatype-library.html http://techascent.com/blog/jna-simplifies-your-life.html http://techascent.com/blog/native-pointers.html https://github.com/techascent/tvm-clj There's an illustrative notebook that works out the Ames housing data from Kaggle [here](https://nbviewer.jupyter.org/github/cnuernber/ames-house-prices/blob/82e3ce1679b3e6e31c0128290f60ef7ae16947b0/ames-housing-prices-clojure.ipynb). Chris (the author) comes from c++ from graphics, ML, and other systems stuff. His goal is to provide a fungible, 0-cost bridge across multiple ecosystems (java, scala, clojure, python, c, c++, etc.) which is what tech.datatype provides. The other strategy he's pursuing is using TVM (tensor VM) as the computational backend for numerics, which can then delegate implementation details to TVM's backends (e.g. cpu, gpu, cluster, whatever). They've actually got working python bindings too, which allows tapping into keras and other stuff (e.g. leveraging python's API as a wrapper). The other (pseudo) contenders are core.matrix and neanderthal. [Neanderthal](https://github.com/uncomplicate/neanderthal) is primarily BLAS/LAPACK focused, and is aimed squarely at performance. So, you define all the high-level operations in clojure while Dragan's libs execute (including GPU-based backends via cuda and opencl). In short, there's a pretty broad landscape accessible directly from clojure, and that landscape continues to expand. Still, if your domain requires low-level pointer swizzling or other stuff, then these may not be solutions; but if you're targeting numerics, there is significant focus on that at the moment.
&gt;A hot secret wish I have is something like Clojure's concurrency primitives and immutable data types for Common Lisp. Are there any chances that this wish becomes true? There was (at one point a couple of years back), a port of clojure's persistent structures to CL using CLOS. I tried to find the original link, but could not (I mean, I really tried digging through emails, github, gitlab, everything). Maybe the author pops up here and broadcasts. Absent that, the structures aren't that hard to implement (in fact they're bootstrapped in portable clojure in cljs pretty elegantly). I have a persistent vector [here](https://github.com/joinr/clclojure/blob/master/pvector.lisp) that could be built on (basically a direct port of the java implementation). There are hamt-based maps [in cl-hamt](https://github.com/danshapero/cl-hamt) although I haven't used them. It's too bad I lost that link, because the HAMT-based stuff is really nice. FSet (often touted as an equivalent) loses out in performance due to reliance on balanced binary trees, where the HAMT-based stuff lets you use persistent stuff in broader range of use-cases before hitting performance gripes IME (particularly constant-time lookup scenarios).
I read somewhere that Felleisen had somewhat changed his mind about the immutable top-level, which would do wonders for some kinds of repl driven development.
Probably, I do not understand it fully yet. They key difference to exceptions seems to be that one can retry or resume execution of a failed function, is this correct? Digging a bit, I see that CL does not have continuations but does have control transfer operations like "go" which can achieve very similar results. The essential difference seems to be that while a continuation captures the local variables and stack state of a function, and allows to re-enter that state from a position which is higher up the stack, this is not directly possible with exceptions, THROW, GO and so on. What would be needed is to create an object which holds all the relevant temporary values. For 'pure' computations, this seems relevant, but differences (and potential semantic difficulties) arise when a called function holds additional resources, like open files.
&gt; I haven't actually benchmarked it, but my experience has been that yes, even on small calls, the overhead has been minimal compared to say, Ruby's FFI or even Java (using JNA). Given my interest in complex numerical computation, that's very interesting. It is also plausible to me for implementations like SBCL that compile to native code, since calls to native functions would be no different from other function calls. My guess is the overhead in Racket comes from some memory management behind the scenes.
&gt; The first difference is that Racket and Clojure are languages AND implementations - with Clojure having some more or less similar languages like ClojureScript. Whatever the implementation does or what of it is documented is the language. &gt; SBCL is such an implementation of the language standard. Yes, I am aware of that. I am specifically interested in SBCL because of my interest in computing-intensive numerical code and algorithms. &gt; Common Lisp also makes no commitment for a certain programming style and provides runtime flexibility with ways to reduce that to generate more efficient code. Well, I think it is probably hard to support every style of programming with equal efficiency. For example if a compiler supports a functional style, it can do many optimizations based on the assumption that functions are side-effect free. I think a key advantage of the JVM is support of concurrency on a very low level. In principle, this makes it interesting for high-granular parallel numerical computation. However, JVM code still has a speed disadvantage compared to native code, which seems to outweigh that advantage. If I were primarily interested, say, in I/O-heavy concurrency in the context of web server applications, the balance of advantages and disadvantages would probably be quite different. I think there is a tendency with "large" languages that people tend learn and use a sub-set of features which is most useful for them. A notable example would be C++. What makes "small" languages like C and the earlier versions of Python attractive is that it is very easy to pick up the language and understand any program of modest size in it. I think, in that respect, Scheme is more to the small side, Racket is larger, and CL is even larger, but the core concepts are of course still much more compact than for C++.
&gt; The CLISP implemenation of CL runs in a couple megabytes of RAM: an amount of memory that Firefox will steal in a heartbeat if you move your mouse wrong. Oh, I was not thinking in the memory footprint or resource usage, or the depth of library support. What I had in mind is the number of concepts one has to understand to (a) work productively in a language, and (b) somebody else who you give a program needs to be able to understand an algorithm. In this metric, I'd argue that C is "smaller" than Python (even if it is a much sharper tool), and I guess Scheme would be "smaller" than CL. Personally, I am not afraid to work with big, complex tools, or to learn highly abstract concepts, and long as I can work more productive with it in the long run. However, there is always a barrier when you use a language for paid work in a company or organization which has a reputation to be difficult to learn. Also - and this is why I like Scheme - the less concepts are needed, the smaller is the risk that concepts do not fit well with each other. Again, C++ is a good negative example. On the other hand, Clojure, for example, is quite opinionated, and uses some number of concepts, but they fit very very well together.
&gt; Lisp has one very important data type that can be (and very often is) treated immutably: the cons cell. We can extend a list without touching the existing part by "consing" elements at the front. This is very efficient; it basically comes for free from the semantics of the list. I think that for small lists, this is surely OK. But if there are many items, a linked list is not so efficient on modern processors, because it does not conserve memory locality, and accessing different regions in memory can be quite costly.
&gt; I dislike clojure as much as the next guy, but the data structures are just about the only thing I really envy. What are the main common critic points on Clojure? My own experience is that it is, for somebody completely new to Lisps, stunningly elegant. What did cost me some time was to realize that it is very well suited for applications like web back-ends, and less well-suited for things like computing-intensive numerical code. The causes for this are not very obvious. For example, Clojure has a powerful sequence abstraction. But all these sequences are lazy by default, and because sequences are immutable (like almost everything else), each step in a sequence iteration requires creation of new objects, which increase pressure on the GC. There are also restrictions on the capability to pass unboxed numerical values to functions. This is probably completely irrelevant for server code, but very relevant for numerical operations in hot, performance-critical loops of computing-intensive algorithms.
I think in some aspects, both of you are right. For the most performance-critical code in hot loops, immutable data structures can have a performance cost that is too large. Implementing the kernel of a numerical linear algebra and matrix library, or image processing, in immutable data structures is not A GOOD IDEA. However, Clojure's data structures are IMO geared toward the need of web back-ends, where real parallelism is rarely needed, but good support for concurrency is a must. Also, in such server applications, the amount of code that passes data around is far larger than the amount of code that destructively processes some data structures. Therefore, immutable collections make a lot of sense, and they are surprisingly effective. Now, you need to compare the cost of immutable data structures to the cost of alternatives in heavily concurrent programs - because this is the problem space which Clojure addresses. The traditional alternative is heavy locking. That has both a performance cost, and in addition a cost of bugs that are difficult to find and make development much more cumbersome. I think Clojure's solution is a million times better than what Go offers, which is also optimized for this problem space. And yes, choosing immutable data structures by default is a design choice, which has advantages and disadvantages. The performance argument matters for the lowest layer, but one or two layers up, a functional style is pretty much standard, for example if you look at Python's numpy library, or at R or MATLAB where return results by default use copy-on-write. (I am not talking about Lisp syntax here but whether function arguments with data are modified by default). Personally, I think the advantages can be so substantial that it is good when languages can offer both ways, like Rust or Scala do. And finally, copy-on-write and concepts of immutable data structures, b-trees, etc are not something private to Clojure. Journaling file systems like btrfs, and databases like LMDB use essentially the same techniques, and can yield extremely high performance. (Sorry that this answer is partly more from a general computing background rather than from that of a Lisp expert, but outside of the Lisp universe, the world has been a bit changing, too.)
BTW, small hash tables in Cloure are implemented as short arrays of key/value pairs, which on modern CPUs can be passed as values and copied very efficiently.
Yes, that is what I mean. But I am quite comfortable with that, as long as there is a decent trade-off in expressive power.
&gt; I have a persistent vector in CL [here](https://github.com/joinr/clclojure/blob/master/pvector.lisp) that could be built on (basically a direct port of the original java implementation). Cool, many thanks for the links! &gt; I think something like stmx would suffice if you wanted STM on top. STM is a really interesting and powerful concept, especially the aspect that it composes (while Mutexes don't compose). In CL, it could be much more useful than in Clojure, where it appears not to be used often.
&gt; Scheme is more to the small side, Racket is larger, and CL is even larger, but the core concepts are of course still much more compact than for C++. Unfortunately that small Scheme is for application programming often too small. Real Scheme implementation add everything CL has and more, but each slightly different. See MIT Scheme, Guile, Chcken Scheme, Chez Scheme. They all easily have the size (in features, constructs) of a comparable CL implementation. CL was born a mid-sized Lisp in CLtL1 (1984) and then got expanded with CLtL2 and ANSI CL. That growth was not optimal in execution, but that's what we got. But still the effect is that basics like full-blown error handling and an object-system is a part of the language and there is some integration, in some implementations even a relatively extensive integration. Common Lisp has a mid-sized core plus stuff one could consider as a library. It's also described in some detail which makes it look even larger. This approach was criticized, but there was no experience with alternatives. Later other Lisps tried to go different ways to define a large language: EuLisp was supposed to be defined in layers. Scheme's R6RS had a core plus a standard library plus a library mechanism. R7RS is supposed to have two standard parts: a small R7RS and a large R7RS. Common Lisp also never really tried to standardize immutable functional programming, advanced functional data structures, concurrent execution, parallel execution, networking, unicode, CLOS-based streams, etc. All this is left to quasi-standards, libraries and implementation specific extensions, ... That's all far from optimal. The only thing that helps to get over this, is that Common Lisp was designed in parts as an extensible language and extending it there is possible in many ways. If you come from Functional Programming, then CL looks much less sophisticated and may be improved by using some optional libraries. It looks also much lower level in many places - but as I've mentioned, that was on purpose, since Lisp often was used to implement large parts of itself in itself - sometimes even close to the complete implementation.
When one signals a condition in Common Lisp, a handler is looked up in the dynamic environment and called. At that point the error context can still exist. The handler can then look around and do something. It can for example call restarts which it finds in the dynamic environment. Calling a restart is done via some form of-non-local control transfer. &amp;#x200B; A handler can also present available restarts to the user and asking him/her which one to use: &amp;#x200B; &gt;CL-USER 49 &gt; (with-simple-restart (abort "abort it") &gt; &gt;(handler-bind ((error #'invoke-debugger)) &gt; &gt;(signal 'simple-error :format-control "does not work"))) &gt; &gt; &gt; &gt;Error: does not work &gt; &gt; 1 (abort) abort it &gt; &gt; 2 Return to top loop level 0. &gt; &gt; &gt; &gt;Type :b for backtrace or :c &lt;option number&gt; to proceed. &gt; &gt;Type :bug-form "&lt;subject&gt;" for a bug report template or :? for other options. &gt; &gt; &gt; &gt;CL-USER 50 : 1 &gt; :b &gt; &gt;Call to SIGNAL &gt; &gt;Interpreted call to (SUBFUNCTION (FLET #:HANDLER-BIND-BODY-FUNC1265) :UNKNOWN) &gt; &gt;Interpreted call to (SUBFUNCTION (FLET #:RESTART-BIND-BODY-FUNC1263) :UNKNOWN) &gt; &gt;Call to LET &gt; &gt;Call to CATCH &gt; &gt;Call to THE &gt; &gt;Call to MULTIPLE-VALUE-BIND &gt; &gt;Call to LET &gt; &gt;Call to LET &gt; &gt;Call to BLOCK &gt; &gt;Call to EVAL &gt; &gt;Call to CAPI::CAPI-TOP-LEVEL-FUNCTION &gt; &gt;Call to CAPI::INTERACTIVE-PANE-TOP-LOOP &gt; &gt;Call to MP::PROCESS-SG-FUNCTION &amp;#x200B; one can see that the handler called the debugger and in the debugger we still have the full context and the call to signal is still on the stack...
Thanks. I also tried putting it in a defparameter, which should presumably work fine: (defparameter strings (make-alien (* char) 5)) (setf (deref strings 0) (make-alien-string "abc")) (setf (deref strings 1) (make-alien-string "def")) (print (loop as whichstring below 2 collect (loop as whichbyte below 4 collect (deref (deref strings whichstring) whichbyte)))) (free-alien (deref strings 0)) (free-alien (deref strings 1)) (free-alien strings) ==&gt; ((97 98 99 0) (100 101 102 0)) And I added (print strings) to show it: #&lt;SB-ALIEN-INTERNALS:ALIEN-VALUE :SAP #X025333C0 :TYPE (* (* (SB-ALIEN:SIGNED 8))
I previously had a LLC under the name A Cons Apart.
&gt; This approach was criticized, but there was no experience with alternatives. What were the main points of criticism? &gt; That's all far from optimal. &gt; The only thing that helps to get over this, is that Common Lisp was designed in parts as an extensible language and extending it there is possible in many ways. Well, I have almost no background knowledge on CL. But in general, this does not look like a bad approach. Python and C++ (any quite a few others) work very much the same and one can say that they are highly successful. The standard solution for other languages seem to be that that parallel execution are supported by the OS, concurrency like async is supported by libraries. Functional data structures can be as well, on an opt-in basis, as done in Racket and Scala. Immutability is in many ways more of strategy to cope with complexity, which is used in sane traditional languages as well, only that some newer languages (Scala, Clojure, Rust) use it by default and support it in data types. As an ignorant guess, it could perhaps be supported by type annotations in a CL compiler, which produce errors or compiler warnings if violated. For unicode support, I'd agree that for a modern language implementation it belongs into the core. Also, there seems to be some tension between concurrency / parallelism and immutability - for example, OCcaml does not support the two first ones and is strict, while Haskell supports all three while being lazy. But layiness comes at a cognitive cost, too. Clojure is partially lazy and seems to have a intermediate position here, but this aspect is IMO more likely to get in one's way than many others.
&gt; Racket is currently being partly reimplemented on top of a modified runtime of Chez Scheme. My understanding is that it is hoped this will make possible to improve OS-level threading support.
&gt; Common Lisp is also a low-level language in itself (with low-level bit handling, low-level data-structures, go-to-like control flows, etc). It offers a bunch of facilities, which are mid-level language features like its error handling, I/O, macros, etc.. There are also a few high-level features like the Common Lisp Object System with its own implementation layer, the Meta-Object Protocol for CLOS. SBCL gets even more low-level, for example one can implement low-level compiler extensions. Thus SBCL is a full-stack Lisp: Lisp-oriented runtime, parts of the runtime in Lisp, library in Lisp, native code compiler in Lisp, ... Racket will have a similar philosophy when one uses the implementation on top of the Chez Scheme runtime with an AOT compilation. I think this aspect is extremely interesting for developing numerical algorithms - the ability to work in many levels of the stack, low-level bit fiddling, number crunching, numerical cores, and at the same time, and within the same language, working with high-level abstractions, immutable containers, plus a good number of libraries. Racket has here two points where I am not aware what comparable facility in CL would be : It has a very very nice plotting support, and a good support of array and vector functions, similar to numpy. (I saw there is [a numpy clone for CL](https://github.com/CodyReichert/awesome-cl#numerical-and-scientific) on the Awesome Common Lisp page, ([discussion here](https://news.ycombinator.com/item?id=19904905)) and this is very, very good - I think numpy is by far the most important element in the Python ecosystem which makes it interesting for scientific programming.)
&gt; each step in a sequence iteration requires creation of new objects, which increase pressure on the GC. transducers alleviate that fyi, providing an opt-in alternative to sequences while using 99% of the same libraries (e.g. take, drop, map, etc.). They also work on core.async channels.
&gt;where it appears not to be used often It crops up, although the early days of exploration haven't turned it into a go to tool (beyond atoms typically). I've used it in discrete event simulation and other concurrency contexts to drastically simplify managing state. I've also used agents for gui programming and managing other shared async resources. I haven't leveraged the other end of the value prospect (fine-grained concurrency) as much, although it's been plumbed out. Nice to have though (if you've got persistent structures with cheap hash equality and value semantics).
These techniques are well known and there are many subtleties so don't rely just on the information I give you here for anything mission critical, but the TL;DR is that you need two things: 1) a random source of some sort and 2) a cryptographically secure hash. The random source doesn't have to be fast or of particularly high quality. The only thing that matters is that you have a good estimate of how much entropy it actually produces. When in doubt, err on the side of underestimating. The procedure is simple: collect enough data from the source to guarantee that you have enough entropy for the level of security that you want (a few hundred bits is plenty for any realistic application), run those through your cryptographic hash, and iterate to get more bits. Add entropy from the source whenever you can. That will produce random bits at the rate at which you can run the hash (i.e. really freakin' fast) after an initial seeding time that depends on the source. Quality random sources that can seed the process in a millisecond can be had for well under $100. (I sell a product that includes a random source that produces entropy at the rate of about 10kbits/second for $75. https://sc4.us/hsm.)
perhaps the transient function world be interesting to those who are interested in implementing an algorithm that uses mutable state. Clojure has all the mutable variables any other language has, it just doesn't come up in daily life often.
So, my main gripe is mostly the JVM, and I agree with what you say. However, I don't really like the syntactic choices (very much a matter of taste) and I dislike that whenever I have to write fast code, I have to drop down to java with parentheses. But TBH that is also a problem of my daily driver (scheme, where you end up writing c-in-scheme). CL does not have that in the same way, because there is no "dropping down" to ugly mutable code because that is something that is still "CLesque", or at least it is still very much considered acceptable code.
How does clojure do transducers in parallel? Some of the transducers have internal, hidden and mutating state, which surely must wreak havoc in multithreaded environments. Having written a transducer implementation in scheme, I can't say I would know how to solve it, so I am very curious. I have a WIP on removing the hidden state (which is simple!), but a transducer like map-indexed is inherently serial.
&gt; Clojure's exotic immutable structures Now adopted by a bevy of mainstream languages (c++, python, scala, F#, ocaml, haskell, c#, java, ruby, hell even javascript has HAMT-based persistent structures). Hardly exotic. &gt;This is very efficient; it basically comes for free from the semantics of the list. How are those list semantics for getting the last element, or the nth again? Thankfully structures exist that alleviate these problems without sacrificing immutability while retaining performance. Cake is both plentiful and edible. If prepending is your thing, lists remain viable as ever. &gt;Algorithms involving immutability can be implemented using a combination of immutable lists, and other data structure. Sure, slowly. There's an analogous reason alists are dominated by hashtables in many real-world associative workloads. &gt;Clojure's exotic immutable structures, such as vectors or hash tables to which you can add ("conj") elements to obtain new structures that don't touch the old ones, are inefficient and impractical compared to their straightforward mutable counterparts. You're completely wrong. They reference (e.g. touch) prior structures, in fact the preponderance of said structures. Only in optimized cases, e.g. where the collection is "small", typically 32 entries for vector or 8 for a map, do you have a complete COW without any sharing. The persistent collections based on hash-array mapped tries are designed to support efficient operations so that the vast majority of the previous structure is shared in the new structure. Copying of substructure is also typically a fast array copy, typically of 32 elements, and is relative to the size of the collection. So, in the worst case, if you have a vector of 32^6 or 1073741824 elements, and you want to update one of elements, and the element is not within the last 32 elements of the vector (the tail, for which a reference is kept for O(N) access, bypassing the worst case), then associating the new value will require - finding some child leaf array contained by 5 nested 32-element parent arrays in the HAMT along the index to-be-changed (the "path") - constructing a "new" HAMT by copying the 6th or leaf array that actually contains entries (updating the index with the new value from assoc), creating a copy of each parent array along the path that now contains the copied child, all the way up to the root of the HAMT. So you get 6 copies of 32-element arrays, 192 / 1073741824 of the entries are copied, so 0.999999821 of the entries are shared by reference in the "new" structure. There are some novel bitmasking tricks to make lookup (finding the entry) efficient too. Note: this doesn't extend to all collections, only those implemented on top of HAMTs (e.g. persistent vectors, persistent maps, persistent sets). Other collections (lists, seqs, sorted sets) have different semantics due to underlying balanced binary tree implementations (FSet's default). You're also off on performance claims (presented without context). I continue to be surprised by how much I don't need mutation in contexts where I thought the persistent structures would get trounced (particularly vectors). I've done 60fps animation with 8-10K onscreen entities based in a persistent entity-component-system being updated every timestep for realtime visuals, games, etc. without having to go mutable. It's not AAA but it's far from what I expected from something "inefficient and impractical compared to their straightforward mutable counterparts." Particularly when dealing with coordinating entity behavior and resulting side-effects, managing state, etc. the presence of mutability is far less straightforward. Trade-offs exist. Personal experience shows about a 4x worst case trade off (depending on operations) for individual writes (e.g. not using batched writes and transient structures, which is far more common). Reads for small collections of 32 elements are near identical to array reads, writes are still more expensive but improve due to simpler path discovery [only 1 leaf array] and fewer copies [1 vs. 6 in worst case] at around 3x for single entries amortized over millions of runs, unless you use transients (about a 1.23x writes to primitive mutable arrays). If/when that isn't enough for your needs, primitive arrays and mutable collections abound (or implement your own; I have when it made sense). &gt;Those hashes can just use the good old efficient mutable implementation. How does your solution scale with the size of the table, changes, etc? Every change means an O(n) clone. After about 10^6 writes, how long does it take to scan through and check for association? There's a reason path copying and structural sharing is a thing, and why shadowing or concestors (while useful in some cases) runs into a brick wall under practical workloads. The benefits of not lobotomizing everything for space/performance sake (or adopting a COW view of immutability) are manifold, particularly for testing and reasoning. Concurrency/parallelism add more utility. Reasoning about a system that can't mutate from afar is perhaps the biggest draw. That one can achieve these things without making ludicrous performance tradeoffs is a testament to the advances in persistent data structures (of which HAMTs were a novel development on top of Bagwell's work).
\&gt; What were the main points of criticism? That it was a language definition without layers, modules, libraries, ... Thus all was always required.
[more context instead of FUD](https://hypirion.com/musings/persistent-vector-performance-summarised) I also replied at length to earlier post (for reference).
thanks for that. i'll give that a detailed read. although i did skip to the end, and it seems the conclusion is that it isn't anything major to worry about unless in certain situations. and of course, immutable data gives programmers some nice guarantees. i work in a dataflow langauge. that means that if i modify or branch some dataflow value, the previous one is retained or copied but only if this is needed. i am not for sure of the implementation details but the language is very performant, so i can't imagine it being much at all. and the benefits are huge.
Stateful transducers violate assumptions necessary for fold to work out of the box [as discussed here](https://labs.uswitch.com/transducers-from-the-ground-up-the-practice/#parallelism). Pure xforms are fine (e.g. stateless transducers - map, filter, to name a few of about 1/2 the standard library). Behind the scenes, there's a fork/join invocation based on how the fold is defined (breaking up the input collection - assumably an indexed collection or reified thing that can be indexed). The transducer is supplied during the reducer phase of each chunk, and caller is responsible for combining the (now transduced) chunks via a supplied combinef. Very curious to see what your WIP is. The current "solution" in Clojure is to just not use stateful transducers if you're going the parallel route (either via `fold` from clojure.core.reducers or `pipeline` in the core.async stuff). That leaves an opportunity for footguns though. I'm unsure if there are community-supplied work arounds (e.g. provide shared state [like an atomic counter] among the workers to somehow coordinate the worker-local transducers).
I won't sugar coat it, but I'm not big on dismissive doom and gloom either. Immutable stuff has it's place. What used to be fairly gross performance implications for random-access collections and the like has since been (IMO solved) by the HAMT-based stuff. That changes the equation for what's in scope for the definition of "has its place." For about a decade, I've been able to leverage the immutable-by-default without living with piss poor performance. I've optimized at the lower levels in some cases where mutation made sense, but I can probably count those times on one hand (e.g. where it was necessary, vs. an incremental improvement). These kinds of decisions need to be made at the system level too, not necessarily the micro-benchmark or toy project level. Build some actual working stuff that's non-trivial, benchmark it, and find out. I've been surprised more often than not (for my stuff) by how performant the default ends up being when things are said and done.
&gt; *Now adopted by a bevy of mainstream languages* Nonsense. &gt; *javascript has HAMT-based persistent structures* Not as their go-to associative array, vector or list type. Python dicts are not HAMT. Correct me if I'm wrong now; I was looking at the code around six months ago, and it didn't look very "HAMTy" at that time.
My WIP is not unlike the Ableton "atria" transducers for c++ in that they send state with the current result as a linked list. The downside to this is that a stateful transducer will not be able to tail-call its reducer, but at least the state is visible. I am not sure whether I should still do mutation (to avoid GC pressure) or if I should make them pure.
So everything in a library is exotic then, got it lol.
Good stuff, thanks for sharing.
Cool. Had not heard of [https://github.com/borodust/cl-flow](https://github.com/borodust/cl-flow) before
But the point of the CLISP example is that CLISP has everything in its image; nothing is auto-loaded. CLOS is there, conditions, streams, the compiler, everything.
So, you need additional (in this case proprietary) hardware, you need additional non-trivial software, and it is much slower than dozens of billions of numbers per seconds, just as I wrote.
I never disputed any of that. All I said was that there should be a more prominent disclaimer that one should not rely on Neanderthal for cryptographic applications.
The most recent update I have seen on that is this thread on racket users. https://groups.google.com/d/msg/racket-users/0BLHm18YUkc/BwQdBlnmAgAJ. When I asked him about it at Racket School last year the basic gist of what I recall is that he didn't see a way forward, not that there isn't one, but that there were few proposed solutions that had been investigated rigorously enough to be worth the time to implement.
just curious, does the library help normalize punctuation in words when searching? a song's official lyrics might have a comma or hyphen somewhere you don't expect, etc.
&gt; like generic equality ah, I'd have liked to know this before. There is also https://github.com/alex-gutev/generic-cl/, with many more generic functions.
For comparison: a quick and dirty FFI I hacked up in the early mornings of one month in 2017. http://www.kylheku.com/cgit/txr/tree/tests/017/qsort.tl
No, nothing of the sort just yet. But you can consider opening a ticket, if you please.
Very nice! Looking forward to seeing this on MELPA.
Exactly, there are second order effects where the shittier API ends up becoming the standard. Another example of Gabriel's "Worse is Better". This is more than obvious in opensource Common Lisp-land and most don't even see it (or refuse to acknowledge it). Let's stop with that madness today!
&gt; Orange Crab Bad Is that a variation on Orange Man Bad??
Maybe. The OCR meme seems to have started within 4chan; i found it on /r/programmingcirclejerk and loved it.
Here's a sneak peek of /r/programmingcirclejerk using the [top posts](https://np.reddit.com/r/programmingcirclejerk/top/?sort=top&amp;t=year) of the year! \#1: [I've been programming on LSD for 6 months. I live and breathe programming and have transformed my entire cognitive process to one massive programming terminal.](https://np.reddit.com/r/Drugs/comments/afeugg/ive_been_programming_on_lsd_for_6_months/) | [72 comments](https://np.reddit.com/r/programmingcirclejerk/comments/affaji/ive_been_programming_on_lsd_for_6_months_i_live/) \#2: [What no one really wants to admit here on YC is that the userbase here is something like the top .01% of (intelligence / literacy / analytical skills).](https://news.ycombinator.com/item?id=20107451) | [76 comments](https://np.reddit.com/r/programmingcirclejerk/comments/bx6zqr/what_no_one_really_wants_to_admit_here_on_yc_is/) \#3: [I'm new here and made a npm package to help this subreddit with the daily chores](https://www.npmjs.com/package/letter-spacing) | [102 comments](https://np.reddit.com/r/programmingcirclejerk/comments/a0yrgd/im_new_here_and_made_a_npm_package_to_help_this/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/afd0dd/blacklist/)
&gt; I saw there is a numpy clone for CL on the Awesome Common Lisp page You can also (though I don't know how powerful it is yet) just pull Python code in to Common Lisp with [burgled-batteries3](https://github.com/snmsts/burgled-batteries3).
&gt; Real Scheme implementation add everything CL has and more, but each slightly different. See MIT Scheme, Guile, Chcken Scheme, Chez Scheme. They all easily have the size (in features, constructs) of a comparable CL implementation. Also there's [Gerbil](https://github.com/vyzo/gerbil) which is built on top of the Gambit Schem runtime. It's module system compared to Racket as stated in the README: &gt; The main difference from Racket is that Gerbil modules are single instantiation, supporting high performance ahead of time compilation and compiled macros.
If you'd like to try it, you could always checkout [Gerbil Scheme](https://github.com/vyzo/gerbil). Seems like an interesting alternative to Racket.
 λ (lisp (programmers) (are (cons artists)))
There was nothing related to Lisp on that page. Please, fuck off.
&gt; I'd be interested to know more how CL addresses this, and how this makes a practical difference ;-) As far as I know, a way to separate compile time and evaluation time is using `eval-when`: http://www.gigamonkeys.com/book/the-special-operators.html See the section on EVAL-WHEN.
&gt; I am specifically interested in SBCL because of my interest in computing-intensive numerical code and algorithms. You should take a look at CLASP too; it was intended specifically for that. &gt;Scheme is more to the small side, Racket is larger, and CL is even larger Once you need to understand the Scheme's SRFI documents to do practical stuff not covered on the base Scheme language, CL doesn't look *that* large.
Regarding FFI in Common Lisp, we have the CFFI library, which unifies FFI across all implementations, however i've read that CCL (implementation) and CLISP have some particularly easy to use FFI features. Also, ECL is a Common Lisp implementation that allows embedding a Lisp system within C, and should have easier FFI with C (haven't tried it.)
This looks pretty sweet!
I [applied awhile ago](https://github.com/melpa/melpa/pull/5858), and am just getting around to reapplying.
Yes. (Sorry for late reply, I'm only ever in here to check for Lisp stream plans…)
My other CAR is a CDR.
I don't know if pressure is the best thing to get out of a depressive episode /u/Shinmera but I hope you will find it enjoyable!
This part of the book tells on it. [https://mitpress.mit.edu/sites/default/files/sicp/full-text/book/book-Z-H-11.html#%\_sec\_1.2.1](https://mitpress.mit.edu/sites/default/files/sicp/full-text/book/book-Z-H-11.html#%_sec_1.2.1)
The difference is that calling `iter` doesn't require any work to be done after it's evaluated as it is in a tail position, so we don't create any more work for ourselves when recurring. If you look at the [recursive and iterative factorial procedures](https://sarabander.github.io/sicp/html/1_002e2.xhtml#g_t1_002e2_002e1) and try to evaluate them (traces are provided in the book), you'll notice the recursive procedure requires you to "bottom out" with a base case before you can work up the tree and get an answer, whereas the iterative one simplifies very nicely for each step.
&gt; Isn't this recursion though? Iter is calling itself. Yes, it is recursion. But keep in mind the difference between a procedure and a process. What you posted is a recursive procedure that generates an iterative process, and the other sum procedure you are referring to (that "sum procedure above" in th book) is an recursive procedure that generates a recursive process. &gt; What's the difference between recursion and "iterative" procedures. As /u/chunsj has mention, look at section 1.2 "Procedures and the Processes They Generate".
&gt; What's the difference between recursion and "iterative" procedures. Nothing! Or rather, whether you're pushing any junk on the call stack or not. Great question. See also: [the ultimate goto](https://en.wikisource.org/wiki/Index:AIM-443.djvu).
More grist for the pedagogic mill: It is a tail-recursive "procedure" defining an iterative "process," which is operationally equivalent to a looping construct due to the magic of scheme (although you can do far grander things like mutual tail recursion with scheme's implementation). As the authors describe eloquently, right before problem 1.9, it's an elegant way to use the same familiar recursive "procedure" call without ending up with a recursive "process" requiring pending expressions potentially exceeding the ability for the system to keep track of. They are showing you how to extend a familiar mechanism (recursion) to implement an efficient technique (iteration). If you can define how to compute the next state from only the immediate state of a computation (e.g. the rules defining the next state are not defined by recursing on a y pieces of the current state, unlike the recursive definition of `factorial` after figure 1.3, where `(* n (factorial (- n 1)))` requires another recursive call to find out before we can determine the value of `(* n ...)` ), you can define how to step through a single iteration of an iterative process. If you can codify this iterative transition in the body of a tail-recursive function, you can define an iterative process that computes without needing more space than the state (like `iter`, we only ever need to know the current value of `a` and `result` since they are never recursed upon to provide input to some outer procedure like `+`). Scheme will recognize these tail recursive procedures (defining iterative processes) and implement them efficiently, as opposed to non tail-recursive procedures (defining recursive processes) that must necessarily grow in space during computation (may even fail to compute due to requiring too much space).
Nice pointer, thanks. That works due to lisp having proper tail call so the calling function is cleared off the stack before calling its following iteration, is that correct?
1. You should learn Lisp because it elevate you to a higher level. Instead of writing code to do stuff, you will write code to write code to do stuff. 2. You should learn Lisp because it will hammer home the non-duality of code and data. After a while, you will realize this is just a repetition of point 1. 3. You should learn Common Lisp because it's fast, supported on most any platform, and comes with all features included. You should learn Scheme because it's as close as you can get to pure lambda calculus while still being comfy &amp; expressive. 4. You should learn Lisp for the same reason you should learn C, or any programming language really: it will teach you the mechanics behind the "magic" of computer programs. For a good example, look at [Let over Lambda](https://letoverlambda.com/)'s explanation of how to make classes out of closures. Reasons not to learn Lisp: 1. It's a provable fact that any program that can be written in Lisp could be written in any turing complete language. Full stop. 2. That quantum computing thing is BS--there's no reason Lisp is better suited to quantum computing than any other language. 3. Lisp will not improve your programming skills any more than practice in any other language. Sure, it's one of the most featureful language families--but you'll run up against the bounds of your own understanding way before you get to the point that, for example, Python, C++, or JavaScript's lack of features will be obstacle.
Because it's interesting and fun and has a lot of history and stability.
I don't believe Lisp will improve your programming skills any more than any other language could. That solely depends on you. Learn it if you want. I recommend reading some books and seeing if it has anything to offer you, pick and choose: * http://www.gigamonkeys.com/book/introduction-why-lisp.html * http://landoflisp.com * http://www.paulgraham.com/acl.html * http://www.paulgraham.com/onlisp.html * https://github.com/norvig/paip-lisp * https://letoverlambda.com/index.cl/toc
If you love programming, and have been frustrated in the past about having to find clumsy kludges or workarounds to make the compiler do thing X, instead of just writing "do thing X" and call it a day, If you think you should tell the compiler what your program intent is, [and not the other way around](https://www.reddit.com/r/LispMemes/comments/b8vqeg/lets_try_to_outnumber_rrustjerk_remember_only_you/), If you want [professional](https://www.reddit.com/r/LispMemes/comments/b8phrx/error_handling/) error handling, If you want to be Neo and [see the Matrix for what it is](https://www.reddit.com/r/LispMemes/comments/b8orcl/another_pl_chart_a_very_accurate_one/), If you really want God to give you the cheezburger so you can [eat it](https://www.reddit.com/r/LispMemes/comments/bdope1/your_offering_pleases_kitty/) If you like [jazz, aikido](https://arxiv.org/abs/1804.00485), or Frank Zappa's music, If you are a member of the Church of The Subgenius, If you think code should be readable and express what the program should do in the most natural way, and, most important, if you think having to choose between OOP versus Functional Programming, high-level versus low-level [is silly](https://www.reddit.com/r/LispMemes/comments/b9x1vh/morpheus/)... Then you perhaps should take a look at Common Lisp at the very least, and eventually all Lisps.
If you have to ask, you'll never know.
I can recommend to learn you some clojure. It's a lisp running on the jvm and inthe clojurescript variant it runs compiles to JavaScript (Browser and nodejs). It's core mantra of persistent data structures (avoid in-ilace mutation) and the extreme stability of the core library and most 3rd party libraries make it a very different (I think better) environment to work in. Also the interop with Java (and JavaScript) is excellent: in case you need it, you can access the huge host language ecosystem. It's not a common lisp (which made me avoid it in the first place) but give it a try. (https://clojure.org is a staring point)
I don't think you should learn any Lisp. I wouldn't spend time learning Clojure, for example. &amp;#x200B; You should learn Common Lisp if you're not a programmer by trade, but have to program as part of your work. And you're fed up with the programming language you're currently using because you have to keep up with changes in it. You're sick of updating perfectly working code when a new version of the language is released. &amp;#x200B; You also should learn Common Lisp because you are after a single language that does everything you need reasonably well, and you don't have time to learn many languages (e.g. Python and C). &amp;#x200B; You should learn Common Lisp because you don't know if it fits your style of programming. You should learn it to find out whether interactive and iterative development is for you; whether you enjoy manipulating code as an data rather than text.
Great comment, going learn lisp today ;) &amp;#x200B; i will remember what you said
not if you want to enjoy your work~
&gt; If you are a member of the Church of The Subgenius, and want to achieve eternal Slack, Apparently I'm a very spiritual person: https://en.wikipedia.org/wiki/Church_of_the_SubGenius#Conspiracy_and_%22Slack%22
That free clojure hate :) It definitely has different goals, tools and methods as common lisp but it's not as if it didn't have its own value. It just serves another purpose. I wouldn't dismiss it as something not worth learning until knowing what OP actually expects from a language.
I'm learning it (Common Lisp) ATM and I don't regret it. It's really awesome. It has all the language features of modern languages (and maybe even more) even though it's already quite old. Strong vs. dynamic types is debatable.
&gt; You should learn Common Lisp because it's fast, supported on most any platform, and comes with all features included Also because it will probably usefully last a long time.
For me: I was interested in Lisp because it's different. I wanted something to expand my view beyond the similar routes in C, Java, and Python. I initially was looking at Haskell, but it was pretty clear that I would need to invest more than I really had available for a language I wasn't going to be using primarily at the time. I hope to get to Haskell someday, but ... I found Scheme. And I love it. It's fun, it's elegant. It's the language I write when I want to enjoy writing code. Also, I do feel like the differences in how it presents things like environment, data, code, etc have really helped me see a bigger picture of development.
&gt;It has all the language features of modern languages (and maybe even more) even though it's already quite old. That's because modern languages have been copying selected features from Lisp and Scheme for a very long time. Since modern languages only ever copy a subset of the features, Lisp has a superset of most language's features, and most other-language features that aren't built into Lisp can be implemented as macros.
Lisp is one of the oldes languages and at the same time still one of the most modern. This alone is a good reason to learn a Lisp like Language. I think the major reason why people don't understand Lisp is because Lisp is at a conceptional level very easy. An easy system enables you to express more complex ideas than an already complex system -&gt; you can push it further.
Wow, jazz is a huge part of my life along with computer science/information theory, I will definitely be giving that Lisp, Jazz, Aikido paper a read. The abstract is giving me strong _Gödel, Escher, Bach_ vibes. Thanks for the link!
&gt; Since modern languages only ever copy a subset of the features, Lisp has a superset of most language's features, and most other-language features that aren't built into Lisp can be implemented as macros. Yours is the most succinct, complete answer to the OP's question. Well said.
Maybe you shouldn't? &amp;#x200B; ;) &amp;#x200B; If you're asking too much, you probably won't benefit. Lisp just overwhelmed me initially, out of pure intuition! And if you can't feel anything similar, it's probably not worth it for you personally (because we all are talented, but talented in very different manners, so there can't be a generic answer...).
I used to be in a similar position as OP, Lisp was praised constantly, but no one could really explain what was so great about it. That actually made me dismiss Lisp for quite some time as just an academic toy and intellectual masturbation. I wasn't until I read SICP that I began using Lisp, and even then it wasn't really apparent what was supposed to be so great about Lisp. First off, learning Lisp will not make you a better programmer because it's Lisp, it will make you a better programmer because it is sufficiently different from other languages. The same thing could be said about pretty much any language that's different. If you know Python, then learning JavaScript won't really teach you anything new. But learning a very different language will give you a different perspective on the topic of computation, and that different perspective will allow you to make out fundamental patterns instead of "language recipes". It is not unlike how learning a different human language makes you better at understanding the fundamentals of languages; by seeing the differences the underlying common parts start to shine through like a pattern. Now as for Lisp, here are a few key advantages. I will focus on Lisp in general, the individual Lisps have their own strengths and weaknesses as well. * Lisp supports every paradigm under the sun. If a fancy new language comes out, chances are you are getting just a shiny subset of what Lisp has already had. And on the off-chance that it is something new, you can just retrofit it to Lisp as a library (more on that later) * Lisp is unopinionated. You could for example write sort of OOP in C, but you'll just be fighting the language. You could write sort of functional code in C++, but you'll just be fighting the language. You could write sort of imperative code in Haskell, buy you'll just be fighting the language. You could sort of write something useful in Javascript, but you'll just be fighting the language. While Lisps can sometimes have a bias (like Scheme towards FP), there is nothing stopping you from using any paradigm you prefer instead. * Lisps have a lot of implementations. OK, that's not really true for Clojure, but with Scheme and Common Lisp you can choose an implementation that fits your needs. Compiled or interpreted? Maybe running on top of the JVM? Or how about being embeddable? I mean yes, you can *technically* embed Python or write standalone Lua scripts, but it's not really designed for that. * Lisp has no syntax. I'm sure you have seen the weird prefix notation with the parentheses, but that's not really a syntax, you are writing the abstract syntax tree (AST) directly instead. In fact, if you let a compiler for another language show you the AST that it has generated, it will suspiciously look like Lisp. Why would you want that? Syntax just obscures the view to the computation and enforces opinions on how programs should be written. Seriously, try nesting several lambdas in Python and try not to stab out your eyes. In languages with a lot of syntax and lots of features this leads to a million different ways of writing the same thing. * Lisp is interactive. Most Lisps (not all) allow you to change the program while it is running. When your program crashes you are dropped into the debugger, you fix the source code, re-compile and and resume your application right where it had crashed. In fact, you don't even need to crash it, you can change the source anytime you want. * Lisp is programmable. This one took me the longest to understand, but it is what makes Lisp beyond powerful. In Lisp you have macros, but since Lisp has no syntax, macros can transform any expression into any other expression. Code is data and data is code. You can re-write portions of your program at compile time. Why would you want to do that? You could add new features to the language, pack them up as a library and now everyone can retrofit their Lisp with it. Features can extend a language with generally useful features, or you could build domain-specific mini-languages into Lisp. The power of Lisp is when all these points come together. Lisp lets me write software faster and easier than other language. The only thing that can beat Lisp is if it is a domain-specific language, but even then you could just retrofit Lisp (usually not worth the effort though if there already is something good). For instance, I was using a static site generator named Pelican for my website. It was written in Python by several people over many years. It was slow, rigid and I had stretched it beyond what it was intended for. So I wrote my own generator from scratch, without prior experience of planning, in one go. Within less than one week I was completely done, and it generated my entire site within a second instead of half the minute Pelican took. I wrote it in GNU Guile, a Scheme implementation. I wrote a bit about the topic here: [http://hiphish.github.io/blog/2019/01/15/a-new-ssg/](http://hiphish.github.io/blog/2019/01/15/a-new-ssg/)
Yup. I came to Lisp because of the universal syntax. I stayed because it is a superset of features of most other programming languages.
Yes, that too! It's crazy how Common Lisp has (not) aged! It's older than most of the big languages these days, but it doesn't feel less modern.
Hofstadter wrote some Lisp too!
"Lisp will ruin all other languages for you."
A good reason to start learning Lisp in 2019 is so that you're more or less up-to-speed when 2022 rolls around.
Not more than **any** other language? Really? Does MS-DOS batch count as language? Or BrainF*****? or only True Scotsman's languages like PL/I?
I'm going to simplify a ton. &amp;#x200B; Because in essence there are 5 language families that will greatly alter you mode of thought. &amp;#x200B; Forth (Best low level language) C (What everything is built from by way of circumstance) Lisp (A journey into all sorts of wonderful things) SML (Almost purely functional approach) \[Haskell counts here too\] Prolog (Logic programming. Hold a conversation with your computer!) &amp;#x200B; &amp;#x200B; If you learn any bits from those 5 you have essentially learned most of what computer science has to offer at this point in regards to the basis for how we interact with a computer through language. Notwithstanding some outliers that are also cool, and ignoring assembly. &amp;#x200B; You should learn lisp because it's hella cool and the easiest step outside of the C-Family languages. There's a million other reasons that other posters have elucidated, but that's my two cents.
“python confs”?
APL is conspicuously missing from that list. Array-based programming is definitely a category of its own.
"A language that doesn't affect the way you think about programming, is not worth knowing." *Alan Perlis* There are already plenty of comments explaining lisp and its unique attributes. I'd say learn Lisp if you don't have another similar language already in your toolbox.
If someone says no in the thread you shouldn't listen.
You're getting down-voted because you didn't say, "Learn only Common Lisp, invest no time in others (despite learning one will make transitioning to other dialects almost trivial albeit sensitive to common context switching issues)"
Check out this article on Beautiful Racket (a book teaching Racket, a language derived from Scheme): https://beautifulracket.com/appendix/why-racket-why-lisp.html The author lists 10 points, some of them specific to Racket, others apply to other Lisps as well. See the article itself for more details. - Everything is an expression (if (&gt; x y) (+ 1 2) (+ 1 3)) and (+ 1 (if (&gt; x y) 2 3)) are both legal. - Everything is either an atom or a list. - Functional programming.
I would argue against reasons not to learn Lisp 3. Lisp is a structurally different language than basically everything else. The code you write in Lisp is structurally equivalent to what the compiler/interpreter understand (give or take macros). This is what enables reasons to learn Lisp 1 &amp; 2. Learning Lisp and learning to translate programs you have written in other languages into Lisp teaches you to understand how the compiler/interpreter understands your code. Much like learning an assembly (which one should do as well), this shifts the way you understand programs in any language out of human linguistic mode and into the deep structures the computer understands.