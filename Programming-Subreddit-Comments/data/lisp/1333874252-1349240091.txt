Done already. :)
Funny, your complaint about Scheme ('[...] everybody can invent his own little object system, a new looping construct [...]') shows up in some Naggum threads on cll from the late nineties. He was also complaining that Scheme, while 'small and beautiful', grows ugly once projects get big (because there is no standard object system etc.). He was comparing it with Common Lisp, which, while much larger than Scheme, is more 'batteries included' from a conceptual point of view (CLOS etc.). So if you don't have much experience with Common Lisp, maybe you shouldn't associate Scheme complaints with Common Lisp. There is a lot of flexibility in CL, arguably more than in Scheme, but for trivial problems it's not really needed (CLOS and first order functions go a really long way). However, if the project uses objects etc. and still needs new constructs, building them is possible in CL.
I'm pretty sure you can abuse macros more than anything in Perl.
Common Lisp is a language, CLisp is an implementation of that language, Lisp refers to a family of languages generally unified by by s-expression based syntax and metaprogramming facilities. For instance, SBCL and Franz Lisp are other implementations of _Common Lisp_. Emacs Lisp, Scheme, and Clojure, and Arc are other _Lisps_ but are not Common Lisps. Generally speaking Common Lisp is the most practical Lisp available, in that many implementations of the language are ready for, and used in, real production environments. Scheme is an academic Lisp with an emphasis on simple, static semantics. It is a very simple language, and so a plethora of implementations exist, with varying degrees of elaboration and pragmatic potential. Clojure is a Lisp for the JVM with influences from both Common Lisp and Scheme, but also some large influences from Haskell (laziness, principally). Emacs Lisp resembles Common Lisp superficially but has many semantic divergences which make it something of an ugly sister. PicoLisp and NewLisp are "sports," to some extent, but worth looking into after you have a good grasp of how Common Lisp and Scheme operate. 
It is a bit disingenuous to call Common Lisp, in particular, a "functional language." Common Lisp is, and is used as, by most programmers that I am aware of, a true multi-paradigm language where side effects are allowed and used frequently, without any special semantic proscriptions required. Most Common Lisp programs interact with the outside world and the user in the same way that most other languages interact with the user - by making calls to impure functions which read and set state someplace. Your question, however, is very insightful: can you have a programming language which really _is_ pure, where the programmer only ever describes computations which _produce values_ and nothing else? The answer is, perhaps surprisingly, yes - but, as your question hints, then run-time of such a language must eventually engage in side effecting actions in order for a program to mean anything. Haskell is such a language, when you restrict yourself to its pure subset. In Haskell you use combinators on various values which the run time interprets as side effecting operations. When you run the program, your Haskell code calculates an "operation" that may have side effects and then Haskell runs that operation. The user never participates directly in those side effects. I wrote about this [here](http://dorophone.blogspot.com/2011/11/understanding-haskell-io-monad.html).
I feel the same way about it, I've been doing Java development for over a decade, and the experience became incredibly dull. Then I started looking into FP, and settled on Clojure, and I'm enjoying coding again. Main things I love about Lisp, is that it's really consistent syntax wise, and it gets out of your way. There's practically no boiler plate, and once you get enough practice you pretty much think in terms of functions. So, you can literally just write down your thoughts as code and see it work in front of you. The REPL is an amazing tool, and I find it incredibly shocking that it's not part of every modern development environment. To give an example of what I mean about being able to think in Lisp, here's a common real world scenario. You have an address or a name in a DB, that's stored in a few separate fields, and you need to pull those out, remove empty and null fields, and concatenate it into a string that's displayed to the user. In Clojure I would write (defn concat-fields [separator &amp; fields] (apply str (interpose separator (remove empty? fields)))) The function literally says what it's doing, and says nothing about how it's doing it. Now consider how you would've written something like that in C/C++, you'd probably write a loop and think about the edge cases you have to handle with the nulls, handle empty strings, etc. So, you have that extra step, between the code and what's in your head. Every time you read a function you kind of run it through your head to see what it's doing, that step is often not present in a language like Lisp. 
&gt; I've recently been playing around with projects like Vensim, doing stock-and-flow models. Is this something similar, using a lisp dsl instead of diagrams? Little b was specifically solving a problem of combinatorial complexity in biochemical reactions. In most models, the number of variables is fixed - in Vensim, you'll add new variables by manually adding new nodes to the system in the UI. In biology, you're simulating genes, proteins and reactions. But proteins bind to each other, creating new macromolecules with new properties. These are essentially new variables in the system... and these macromolecules might interact with existing elements of the system resulting in even more molecules. As long as chains don't form, this process terminates, giving you a final set of molecules required to simulate the system. The problem little b solved was to compute this final set of molecules, then compute an ODE system that describes how the system evolves over time as molecules are created, bind to each other, chemically modified, transported between compartments, and destroyed. &gt; Based on the website, the project seems a little dead...no news since 2008. What's the status? Sadly, yes. Though there is a very closely related project called BioNetGen. I'm working on completely different stuff now - mobile internet.
I like cl-pdf. It's low-level; if you want to make something pretty with it, it won't stand in your way and it won't give you a head-start.
I created a pattern matching system for Emacs and Common Lisp here. Completely, totally impossible in Python. Code [here](https://github.com/VincentToups/shadchen-el).
I'm not sure, but looking at the examples, it seems to me that it's like in Prolog or Erlang: lower case identifiers are symbols and upper case ones are variables.
We use CL-PDF to produce customer invoices, but with no infographics. CL-PDF has been very reliable for us. As xach said, it wont get in the way, but it is a pretty low level to be making graphs with. Good luck and please open source anything great you make!
In Python, because you don't have macros, you have to type the same thing twice sometimes, leading to more opportunity for typos: Point = namedtuple('Point', ['x', 'y']) In Lisp, this would look something like: (defstruct point x y) 
Isn't self-quoting symbols something that old Lisp systems had? Learn from history I say, there's probably a reason or two that we don't have that anymore (like, say, the separation between symbols and 'variables').
They are mentioned in a few places in Lisp In Small Pieces as being among the features which add complexity to the evaluator while simultaneously increasing the chance of making bugs by non-local changes, and so that is the received wisdom I have about them. However, there may be other reasons Mark Tarver included them in this Lisp - by all accounts he is a thoughtful guy. Maybe we should try to ask him about it.
Well, at least Qi included parts of itself in your programs thanks to having gobs of Qi-YACC generated code, so it makes sense. I accidentally caused this shit to happen a few years ago -- I noticed that Qi-YACC was spitting out lots of code into client programs, and suggested that he add the Bison/Lex exception to his (then LGPL) license text because he clearly was not intending to force downstream users to license their code under the LGPL ... his response was basically "screw this, I'm going to use my own stupid book license because this GNU stuff is so complicated." I thought I was being helpful :( The disadvantage of not using a well known copyleft (or non-copyleft) license is that no one else can use your code and you can't use anyone else's code... i.e. the Shen implementation shall always be a barren cathedral (I see some suspicious use of GPLed code in the implementation there, but IANAL and I didn't spend much time looking at it).
Well, I am certainly on board with not polluting the world with more licenses. As with anything, what is in your own head seems simpler, but that might not be the case for other people and it will almost certainly be off putting to others that have to fit yet another license into their mental space. I like to see a common, old license on a project because I know just about exactly what to expect.
How did you get into writing Emacs Lisp? I'm struggling with simple functions, is there a good tutorial for writing it?
If you really know Common Lisp, than Elisp should be easy: just remember that by default scope is dynamic. That is a major difference, but superficially the languages strongly resemble one another - the only thing you need to be careful of is if you use lots of closures - you can construct them using `eval` from backquoted lisps or use cl.el's lexical-let, or use Emacs 24 and enable lexical scoping. What specifically is giving you trouble?
What is so complicated about them - buffers are just representations of a linear sequence of characters. You interact with them via functions like buffer-substring and insert and you select which you want to with `with-current-buffer`. 
Nice. I had not realized that undefined was so type-compliant. It's not something I can do in C++, C, or Java which are the statically typed languages that I've done the most in. So, your original question of "Why wouldn't you be able to do that in a statically typed language?" would be answered with "because the language doesn't let me." Certainly, it would be good if it did, and Haskell does, it seems.
My impression is that Tarver seems completely oblivious to the reality of programming in the real world. The recent thread on Shen packaging is a case in point, http://groups.google.com/group/qilang/browse_thread/thread/825fe73aba038d94 Apparently Shen packaging is screwed because Shen programmers have to coordinate with each other so that they don't overwrite each others' external symbols. That rather misses the point of packaging. There's every indication that Tarver only understands programming in academia, with little feel for what real-world programmers need. On the other hand, CL is great because it brings together What Programmers Need based upon many years of experience by many people. For example the CL packaging system, while not perfect, provides the flexibility to actually deal with things like conflicting symbols when they arise. This is a good example of how CL is designed as a practical language; it does not put idealized scenarios or abstract ideals above what is actually useful.
Thanks for this, it is interesting. I've always found that issue bothersome. It seems the redundancy can't be taken out because it occurs within a single statement. If the redundancy were spread between 2+ statements, you could use runtime functional abstraction. I wonder if this example is just a missing language construct (sharing obj name &amp; var name), or whether it is a member of a larger family of such issues that can only be addressed by macros. As a side note, you can abuse the metaclass hooks to achieve this non-redundant syntax: class Point( namedtuple ): names = 'x, y' 
C'mon downvoters, that was funny :)
A cross-platform GUI toolkit has always been a bit of a problem child for the free open-source part of CL (the commercial implementations do come with good ones). However don't despair if they do not seem too up-to-date: anything that's not older than a couple of years should be worth a try. I have had good results with [CL-GTK2](http://common-lisp.net/project/cl-gtk2/) in the past: * http://www.aerique.net/software/okra-gtk-demo/ * http://github.com/aerique/clysma#readme Also see the FAQ for some recent information: http://random-state.net/files/nikodemus-cl-faq.txt
[McCLIM](http://common-lisp.net/project/mcclim/), if you're brave.
It specifies later that &gt; Unlike Lisp, Shen is case-sensitive, so b and B are not treated as the same. Calling it self-quoted or implicitly-quoted is just confusing. It should rather say that symbols and variables are in different name spaces.
Well, yeah. In my first post I was talking about *good* static type systems, and that's all I've been going on about. To compare anything to the bad cases of a class of things wouldn't be very representative of what the class of things *can* do.
Oh thanks, didn't know there was one already. You might want to mention GTK Server as well: http://www.gtk-server.org/
Thanks Man, but i really don't wan't to uses some ffi(Foreign function interface) code. for its hard to debug. where as cl-pdf is native common lisp code without any cffi. I got nothing against ffi code. In daytime i use C++ all time i don't want same nightmare in the Night where i code in Common Lisp. I also appreciate Cairo in Python,Ruby etc. 
This is a pretty surprising thread - its kind of amazing that he fails to see the importance of the issue.
Each one of those languages has very distinct features and use cases. With Lisp dialects it's just a reinvention of the wheel with no good reason. And as said, it's not like there are just two or three Lisp dialects, there are essentially as much Lisp dialects as I know applications using Lisp, everybody is rolling his own stuff.
Alternative suggestion: use the browser as a GUI and use Parenscript.
I'm sorry I didn't explain myself very well. Here's the code: from collections import namedtuple def to_record( name, attr_names ): attr_names = attr_names.split( ', ' ) return namedtuple( name, attr_names ) class record_meta( type ): def __new__( s, name, bases, class_attr ): try: record except NameError: return super( record_meta, s ).__new__( s, name, bases, class_attr ) record_attr_names = class_attr[ 'names' ] return to_record( name, record_attr_names ) class record( object ): __metaclass__ = record_meta class Point( record ): names = 'x, y' point = Point( 1, 2 ) print point assert point.x == 1 
It's called "sockets and sexprs". Old story. Ever heard of SLIME? Go take a look at the backend. 
I've heard good things about commonqt on #lisp. believe me, I've been in some levels of pain here. 
I hear McCLIM is fairly buggy. 
Snarky answer to the entirely wrong question.
The documentation is a bit sparse, can you say a few more words about this library?
[I'll just leave this here.](https://en.wikipedia.org/wiki/One_instruction_set_computer)
Haters gonna hate. While you're at it, have you noticed that the SMP images lack Common Graphics? That means you're out of luck if you have a graphical application or if you want to use the IDE.
Oh my god, and it's not a typo: (0-) (+ 1 1) /* c */ 2 -slash-* c *-slash- (1-) (+ 1 1) \* c *\ 2 \&gt;.&lt;
Ok, this is a great post for other reasons, but the analogy is a bit strained, if only because, as I [joked about before](http://www.reddit.com/r/lisp/comments/s5vqx/lisp_as_the_maxwells_equations_of_software/c4bcq1t), there are many ways to talk about the fundamental nature of computation other than Lisp, which is, when compared to the lambda calculus or turing machines, somewhat over complicated and/or execution oriented. Even in the realm of actual computing I really think Joy, which you can read about [here](http://www.latrobe.edu.au/phimvt/), is just as compelling, if not more so, as a fundamental theory of computation as Lisp, if only because syntax is significantly less important in concatenative languages and they are somewhat more amenable to algebraic manipulation. I really recommend learning a concatenative language for the insight it will provide you about Lisp. I actually think this mystification of Lisp is somewhat counter-productive. I posted in another thread that I was a Lisp programmer and got all sorts of comments from outsiders about how they heard Lisp was mind bending and you had to be on drugs to understand it and so forth, and this ultimately scares people away from a language which, absent the metaprogramming, is quite similar to any modern dynamic language. Metaprogramming, while somewhat harder to wrap one's head around, is not too much more magical and certainly unrelated to these fundamental questions of computer science. The lambda calculus doesn't have macros. 
Under Preferences -&gt; Settings - User change the file to include: "auto_match_enabled": false, And this should stop the auto closing of parens (but will effect quotes as well).
This is actually quite a helpful behavior if you work with it rather than fight it. I use Emacs, and Paredit does something similar with () and "". I find it really really helpful for keeping things balanced.
Can you write Joy in Joy?
Btw, are there news for the crowdfunded sbcl effort? Last update was [six months ago](http://random-state.net/log/3523852985.html)
(1) We have more commits during the first 24 after the release-freeze than in the past 3 months. (2) There's more where they came from.
Well, Clojure is anyway.
And it loses reader macros for the purposes of [] and {}! Yay! Sob sob..
This looks like a really nice idea; I was skeptical of the title thinking only of Emacs, but I can see why this is really cool.
Does it have sane, non-RSI inducing keybindings?
As said, my main problem is that every Lisp app I have ever encountered in the wild was written in its own little dialect of Lisp, with it's own little module system, it's own little standard library and it's own little syntax extensions. With Python or Ruby, sure there is redundancy and similarity, but people aren't reinventing those languages with every app, they use the stock Python or Ruby interpreter and that's it. And if the language needs a syntax extension, then the language itself gets an update every few years instead of reinventing yet another special purpose dialect of it. If Scheme on the other side doesn't do the job, people will just hack their own little language that kind of looks like Scheme, but now allows [] instead of () or whatever. That in turns leads to a situation where there never really develops much of a community and library landscape, as everything is slightly different and incompatible. 
That's nice, but I'm not convinced it will scale to real world programs. Maybe I have a program that does some long lasting computation which I don't want to evaluate all the time. Or maybe I have some side effecting code which I don't want to run all the time. That's why I think a REPL is better. It gives you control over what you execute and when.
There is already a web browser in CL called [closure](http://common-lisp.net/project/closure/)(with very cool "TeX-like paragraph formatting and hyphenation support"). There are many js implementations; e.g., [CL-JavaScript](http://marijnhaverbeke.nl/cl-javascript/). Will be very interesting if they can be integrated. Go for it!! 
cl-ppcre is pretty educational. It does an interesting, useful job (regular expression matching), touches a lot of different features of Common Lisp (classes, conditions, compiler macros, packages, etc), uses an interesting technique ("compiling" to chains of closures), is well-commented and straightforward to read, and is really fast.
JavaScript was originally prototyped in CL iirc, you should be fine ;)
Here's a math library: http://common-lisp.net/project/sapaclisp/ Probably the best code I've seen in terms of documentation quality and clarity of implementation. Written around 1990, still works! That's what you can expect from a mature, standardized programming language.
If you do not mind example code from book, take a look at PAIP: http://norvig.com/paip.html Norvig's code is excellent, and there is a lot of code. Although it's probably better to read it together with book.
Meh, it's Clojure, the false lisp.
Try mcclim.
Really Really Good code, good Commenting Practice, Its Awesome. Only in Common Lisp Wisdom transfers from one generation to other generation. Happy, feeling like Padawan Learner learning from jedi master.
PAIP is wonderfully clear, and the examples are based on real historical systems. It's like a study of the AI canon.
Any lisp game code for review and learning? It can be a simple to complex game.
I just looked at my code and apparently I did just that. My only disappointment was that indentation of the html code didn't work correctly when using separate functions.
Is the Lisp in that book extract written in M-expressions? Or something else?
I'm somewhat surprised at the mention of ISLISP at the bottom. I've dabbled in it, and I have version 23.0 of the spec printed out for a summer project (ISLISP system bootstrapped from Scheme), I don't think many people use it for much of anything. Does anyone know of "professional" uses? I know of thxmoo &amp; some other projects, and I presume [OpenLisp](http://christian.jullien.free.fr/) has clients, but that is it.
Yes, I found cl-who to be terribly difficult to do anything componentizable with. I went with vana-templating which solved the matter *very* nicely.
You have done a very cool thing. Can a person download the source? I didn't see the link, or looked past it somehow. 
I am generally in favor of this kind of activity. Perhaps you can start by listing a few things you wish there was a library for here? The more common case I encounter is not that there isn't a library, but that library might be sub par, or much more annoyingly, perfect but without any documentation or tutorials. I also may be so far gone that I don't even know what functionality I should expect.
This is really cool, but I would have rather seen it named something like "Lithp" over something that promotes negative stereotypes. I know I probably sound insufferably PC and prudish...I get it, and it's a joke....but those sorts of jokes don't belong in what my grandparents would call "mixed company"...but between friends where everyone is comfortable; not smack in the title of your project.
Most certainly. In particular, for the compiler course, this came across reddit a few months ago: http://lambda-the-ultimate.org/node/1589 
I'd recommend hijacking this page (and publicize the hijacking): http://www.cliki.net/Suggested%20Programming%20Projects Or, maybe better, is to make a prominent page linked to from the Libraries section of that page. Maybe incorporate some of this stuff, as a start, too: http://www.cliki.net/Lisp%20-%20Next%20Generation 
My top suggestion: documentation of existing libraries. I think the #1 biggest problem with the libraries out there is that no one has any earthly idea what the hell they are. Zach on Quicklisp has acknowledged this as a big-time failure. The same situation existed for LaTeX for a long time: there were oodles of libraries available on CTAN, and no one had any idea what to was available, what to use, how they interacted, what was good, what was old, or even how everything worked together. So these libraries languished in obscurity. Then [The LaTeX Companion](http://www.amazon.com/LaTeX-Companion-Techniques-Computer-Typesetting/dp/0201362996) came out and revolutionized the LaTeX scene. And all this book was was a compendium description of existing libraries. Lisp badly, *desperately*, needs a *Lisp Companion*.
Just a suggestion: when in the tutorial, have the value of what's typed in shown (as would be expected in an actual REPL).
The few words that I have to say on it are: "I plan to try it out soon. I will definitely post something when I get the chance to try it."
I doubt all of the gaps are filled, but, yeah, I don't know. I bet if you dig deep enough, there is some Lisp out there directed at any subject you are interested in. Lisp has been around for a very long time and nothing in the programming world is terribly new (and the things that are new draw enough attention for someone to develop something in Lisp). The question is really all about whether it is well implemented, well maintained, and well documented. &gt; I actually haven't run into cases where I couldn't find a library mostly because I don't use any. I agree I should probably list something I'm looking for. I just want to help the community by trying to fill some gaps that may exist Is it fair to say that you are fairly new to the language and would like a project to test your Lisp legs on?
I like your enthusiasm and want to help channel it in a productive way. CL has tons of libraries, covering a wide range of areas. In any field of human endeavor, there are endless possibilities but only finite resources. What are you missing? Focus on what you and others are already asking for. If an existing library is insufficient, what is holding you back from improving it? Focus on achievable goals. Build on what you already know. There is a time to daydream and a time to take action. Pick an application and stick with it. Useful libraries will appear almost as an implementation detail. When people talk of Edi Weitz or Rich Hickey or whoever, they are talking of people who do the things they understand.
(list (list)) evaluates to '(()), a list with only one element which is the empty list; this is because (list x) evaluates to the list '(x) containing only the element x, and here x is (list), which evaluates to the empty list, '(). The right answer in Scheme is (list list), or equivalently, (cons list '()). In Scheme, list evaluates to a function, in, say, Common Lisp, you would use something like (list #'list), I believe.
Why exactly is this gay? And I don't really think the #about would do it for me.
Why it isn't?
Since I see a lot of confusion about the language this REPL implements, I think it's the case to point out that it's scheme (r5rs). It's nice to see something that isn't CL here on /r/lisp for a change :P
I'm not sure I understand. Is "gay" a negative term now? Or do you find the "gay lisp (impediment)" to be an offensive stereotype?
Thanks, I'll take a look.
&gt; I named a recent Lisp project using a 's-&gt;th' pun, and one of my friends (fellow Lisper) pointed out that this isn't particularly common. Probably because it died out well before CL became a standard. I think it was Berkeley that had all sorts of "th"-related jokes, and it just got old; there are only so many times you can see "lithp" jokes. 
That got me thinking, this Call for Libraries page on cliki could have a list of projects that need documentation. I think the hardest thing about working on some of these projects is knowing what all needs to be done. If you use the libraries of course you'd know that work needs to be done, but there are tons of developers out there running idle that maybe haven't used a project before but could get in there and work on the documentation. And I know every language has this fault, no "master list" of work to be done. I have lots of random down time at my job that I could spend a couple hours a week working on things but without any sort of helpful signs pointing me to the work I end up wasting a lot of time just browsing around.
&gt;As of early 2012, the status of R6RS as a community standard is in doubt. There is talk of splitting standarization efforts into two tracks, one of which could abrogate features introduced by R6RS. Actually, as of early 2012 the R7RS effort had already split into two working groups, and WG-1 ("Small language" working group, treated as an update of R5RS) has a draft up for public comment.
[https://github.com/Ubehebe/Gay-Lisp](https://github.com/Ubehebe/Gay-Lisp)
I agree. It's a terrible name for an otherwise neat project.
Sorry about the confusion. The tutorial now [makes it clear](https://github.com/Ubehebe/Gay-Lisp/commit/9155b6db2439b14da5966bf2ccf4036cfe127484) that this is Scheme, not Lisp.
Sounds homoiconic.
Alexandria needs a ton of docs. the extant docs barely touch what's available in it. 
I think the article had a point that you've missed. The tokens generated by a scanner for C are language specific--an interpretation has already been assigned even before the grammar rules come into play. The Lisp reader produces data where all symbols are completely uninterpreted. In Lisp, even a core symbol like "lambda" is read in as any other symbol and has no effect on the structure produced by the reader. The front-end of a Lisp system is genuinely different from the front-ends of most languages--and the difference has interesting consequences. You both obviously have a good grasp of the situation and probably agree much more than you disagree. I just have the feeling that you've dismissed the argument a little too quickly. There really is something there. And you're right that it's not so much about the lexical syntax using parentheses specifically. It's about there being a whole stage (or more) present in Lisp which is simply skipped in most languages.
Thanks! Apparently I don't read so well...
You're right, and this is a result of the code-data duality. Though I might point out that there's no reason a C compiler couldn't do the same thing: defer attaching primitive operators until parsing time. I fundamentally disagree with the thesis of the article. Lisp is not all about `READ`. If anything, it's about `EVAL: data-&gt;code` and `QUOTE: code-&gt;data`, the homoiconic duals. `READ` is just a convenient human interface—a translator from characters to something `EVAL` likes. The dual is `PRINT`. Where does the meat of the language lie and where do the principle strengths come from: the interface or the machinery behind it?
Just because "homoiconicity" is a complicated word using it doesn't have to be pretentious. You could translate it and use the term "same-representation-ness" instead, but would that really improve matters?
…it was supposed to be a self-effacing a joke about lisp users.
Hi @nonrecursive, those are custom-rolled features of my game engine Blocky http://blocky.io 
don't ask me why i haven't thrown out the broken mic.
Hope you enjoy the video---I was looking at this new code and just realized why the "future trail" updating step is slow, should be reasonably real-time in the next video.
cool. how does emacs communicate with the graphics window ? - is the window created from within the repl and everything (render commands, objects) ffi'ed ? - communication via ipc ? 
hi. Yes, the game window is opened from the REPL and uses LISPBUILDER-SDL and CL-OPENGL functionality. The auto-updating is helped by a tiny code snippet in Blocky that hooks into SLIME, so it uses the current connection between Emacs and SLIME. 
I had a similar approach on OS X with Lispworks - it was pretty convenient modifying GL states or the render loop with a plain C-M-x and observe the change instantly. Sounds cool but i change my route cause i didn't feel comfortable always working with foreign memory and ffi'ing everything. nowadays i am trying a new concept: i semi-automatically transformed the webgl idl into Lisp code and am trying to build a DSL out of this (which emits JS code). what do you think about this kind of way for developing games in Lisp ? the main disadvantage is the lack of runtime introspection... but on the other side, every browser has an integrated JS debugger built-in. 
Why is this? This seems like a bug in ASDF. Maybe the maintainers will address this as ASDF is active right now.
OK, why did you keep it then?
hi wg1024, runtime introspection is a big feature to lose IMO. however you might have success with parenscript?
The Lisp community needs a lot more than libraries, it needs a change in mentality. The ethos of the lone hacker, doing amazing wizardry by himself pervades the community to the point of poison. There is very little visible collaboration, the libraries are non-existant, poorly documented, poorly executed, or poorly maintained. And the lack of proper debugging and build tools is astounding. I personally work professionally as a lisp programmer. I spend way too much of my time fighting with tools and basic libraries (like our ORM library), rather than actually solving problems. Part of this is due to the age of the application, but part of it is a lack of proper tools and coherence in the Lisp world. Personally, I think I'd rather work in Ruby or Python.
Though I get what you're saying, I also do not consider "gay" nearly as offensive as most of the terms you mentioned. "Gay" could actually even be considered to have its original meaning, i.e. "happy".
And the only downside is that debugging your code becomes increasingly impossible the more metaprogramming you use!
From my fortune file: &gt;DEFSYSTEM is to Lisp as make is to C. Which is to say, &gt; &gt; * thoroughly incomprehensible at first sight &gt; &gt; * not standard, but incompatible versions are provided by most vendors &gt; &gt; -- Daniel Barlow 
You can, but no one does.
Tiny update: I've built a simple monadic parser combinator library on top of parenlisp and it is totally working, and performance is tens or hundreds of times better than the equivalent code in Emacs Lisp, which is what I used to use for parsing things. Parenlisp is kind of an awesome lisp if you can handle absolutely useless error messages and the idiosyncrasies inherent in transforming lisp to a language with statements _and_ expressions.
I dunno, but you can easily get hold of it as a torrent.
I read somewhere that the lone hacker - if he is great - can be two orders of magnitude more productive than a plodder/normal programmer.
&gt; no one had any idea [...] what was good, what was old I think this is the main problem I've encountered. Indexes like CLiki are great, but I'd argue they index too many libraries. When you're looking for some functionality, you probably don't want a list of all the half-baked libraries that were written at any point in time and haven't been maintained for ages, have no documentation to speak of, and exports 40 billion symbols. You just want *one* library that's fairly complete, well documented and maintained. Often times it exists, you just have to dig through a lot of cruft to find it. In contrast, the experience I've had with Python is that you just google for a few keywords and you find out that there's usually one, sometimes two, modules that implements the functionality you're looking for. Now that's great. I really enjoy programming in CL, but sometimes I just succumb to the Python temptation because although I don't find the language itself that great, I know I won't waste my time library-hunting. Btw, this seems to tie in nicely with the "Lone Lisp Hacker" idea: why the hell does CLiki index *five* different XML handling systems? Why could anyone go and write yet another XML parser?? TL;DR: I'm not sure there's a problem with a lack of Lisp libraries; there might actually be too many in some cases; a _Lisp Companion_ would be the greatest thing since sliced bread. 
&gt; Macros in C operate on streams of characters Minor nit: in ANSI C, at least, they actually operate on tokens, not on characters. For example, you can't do this: #define QUOTE " printf(QUOTE hello QUOTE); Your point still stands.
Yes, ebook prices doesn't always make much sense. Especially for a book like this that is available free on the web. It costs $42.09 in the Amazon Kindle store btw. Paradigms of Artificial Intelligence Programming costs $64.76 for the Kindle version. Let over Lambda is not available for Kindle, but Land of Lisp is more reasonably priced at $29.20
I would consider a good general programming book for max 30 Euro ($40) in electronic form. But only in epub format. Not in an format that's tied to a particular company and their software. Then either the book must be worth it (for me at least) or it must be cheaper so that I could buy me a different format if needed. The price of Let Over Lambda seems to be very fair. I bought it on Apple's store yesterday. http://letoverlambda.com/ also has a link to lulu.com, where the ebook costs slightly above 10 Euro. Again, a nice price. 
I script with CL a bit. Some of [cl-command-line-wrappers](https://github.com/o-jasper/cl-command-line-wrappers) are meant for that. [destructuring-regex](https://github.com/o-jasper/j-basic)(it uses [regex](http://www.cliki.net/REGEX), many people use [cl-pcre](http://www.cliki.net/CL-PPCRE), i probably should get a version for that) should be useful for that too. What i kindah want with acpi(actually ffi-ing the C interface would be better), iw-scan and cl-ps-command is to log it and have an 'overview panel'. Would also be neat to be able to figure out connections between cpu activity and temperature and such. Crazily, I havent been able to find a good time-series library though, preferably something with compression(aware of the context) and random-time-in-the-past access. Main thing i use it for currently, though, is to switch windows. Have a wm-man package that uses the cl-wmctrl package that implements different categories of window. The S(super)-somekey cycles through the category. For instance S-z cycles through editors, S-a cycles through browsers, S-s through document readers S-c terminals, S-v email. It uses cl-wmctrl from my , the package that uses it is wm-man, and i havent put it online yet though. It is very far from perfect. Worst, and very fixable, CL functions are called by using `echo '(slime-interactive-eval "(ojasper-wm-man:wm-'$1 ':'$2')")' |emacsclient -e`, auch! Second worst it cannot see the current window. It assumes it dealt with all the window changes.(This is only a problem when you want to cycle inside a category, and it doesnt know one of the category is already.) I used to have a program that selects which program to use on a file. Now i just use `xdg-open` for that. That said, i feel it is too tricky to just add another program, and tell xdg-open to use it when it sees a file meant for it. Also `xdg-open` doesnt have *different ways* to open something. It would be nice to be able to open it to edit it, or just to read it or something else.. Another thing is that i would want is to get my browsing in my control. Basically i want a program that can read the html and return some other html to the browser, for instance. I can probably recognize some html and enter 'buttons' if i could figure out how buttons can communicate back and how to intercept the html in the first place. For instance this might allow a 'bookmarks everywhere' system where html through some browser is a gui, and bookmarks can go anywhere in the gui as long as adresses are consistent? Also i have at some point implemented this 'regular tree' in which symbols are variables and proving two trees it figures out if it matches and what the symbols would need to be filled with. Applications for html should follow if i could get at the html.. Proxies like privoxy do stuff like that but cant seem to figure out how to do it. Really though, all that shit takes time, i have more ideas than i have time. (And i waste some time)
I think this is non-issue for several reasons. First, parenlab allows you to write vectorized code quite easily, and the docs indicate several things about using `let` in them. Secondly, the above expansion is really all about variable binding, not really whether the final expression is properly vectorized. Finally, Matlab's jit, I have found, is incredibly good at producing optimized code, these days even from very poorly vectorized source. This is one of the main reasons I prefer Octave to Matlab. Octave is about 4 years behind Matlab in performance of non-vectorized code. I'm not sure how Matlab's jit does it, but I've stopped consciously vectorizing all but the most intensive code in my day to day work without any noticeable performance issues. Finally, I use Matlab for a lot of scripting-style tasks, where performance just doesn't matter. 
You can `(compile-file yourfile.lisp)` and then `sbcl --noinform --no-userinit --no-sysinit --non-interactive --noprint --load yourfile.fasl`, but i dont even really know how linking goes, hope that is automatic somehow, and works as well as the .so files... Really sucks very much that i dont know! Anyway, you might 'have state' in your program and thus want to basically run a function in the program. Then that doesnt work very well :) I do `echo '(slime-interactive-eval "(ojasper-wm-man:wm-'$1 ':'$2')")'|emacsclient -e` which sucks :/. Some kind of 'server' to which commands talk to is i think how emacsclient works in the background, but trying to get into that stuff always sucks..
Sure, but a key thing is I *don't care about compiling* for this stuff. I don't want to *have* the compile step for lightweight scripts. It's an extra step and just slows me down. 
I think the most reproachable thing about this name is that it reinforces an stereotype about homosexuals being 'campy', poking fun at the wrong thing, really.
Finally I can put my CS skills to use! 
&gt; Imo too much documentation in the source code. Well, it's meant to be educational, I guess. But I actually found that useful: I can go from SLIME completion to code and read very detailed documentation (and use examples!) without switching to some other view. This means I can focus more on code I write.
Yeah i guess it is subjective/dependent on habit. I am pretty used to going back and forth to html/pdf documentation, so for me having to much documentation in the code means i see less code, and other media have nicer formatting than the flat text of code comments. Maybe this is a 'tools problem' emacs could maybe 'close' big comments and docstrings.. (Should look at that)
At least on the iPhone, (the sample of) LOL has all the indentation from the code removed, which makes reading it rather too much effort.
Yes, there is the same problem on the iPad. The author should update it. Might be useful to contact him.
[shameless karma whoring](http://en.wikibooks.org/wiki/Common_Lisp)
As was mentioned in another post, what Common Lisp needs is something like a "Lisp Companion," not another introduction. We have several good introductions (PCL, ANSI CL, On Lisp, perhaps Land of Lisp). If you want to contribute, the most benefit might come from working on the "Advanced topics", "Beyond ANSI CL", and "External Libraries" sections.
I agree with this. We really need more "literature" on topics that are not covered in introduction books. 
You're building a bicycle, and asking how well the aluminum in the frame can withstand airspeeds of 400 knots, because you think the bicycle will become a 747. You're paying attention to the wrong issues. Both languages are fine. If you had to ask what language is the most "well-suited" to the task, I'd go with Prolog. Prolog's inference engine makes it easy to write the kind of rules that govern the gameplay in a MUD. I've seen a Prolog book with a text-based adventure as an example, even. Among languages that aren't logical languages, the closest relative to Prolog is Lisp. The other thing you often find in Prolog besides text adventure examples is implementations of the Prolog core inference engine in Lisp. I'm not sure what advantage you're trying to seek by switching between languages. Learning languages is nice, mkay, but so is making "finished products".
Lisp is fine for this, and there are already Lisp MUDs. Lisp would also make a good scripting language for a MUD. Erlang's actor model would be good for user sessions. So it depends whether you want to deepen your knowledge of Lisp or start learning Erlang really. :-)
That's... I don't think I was quite asking that. I guess a better way of phrasing my question would be: Is Erlang better-suited than Common Lisp for handling the network aspect of MUDs even when there are only only two simultaneous players? Your answer, if I'm reading it right, is that I'm assuming the network aspect to be way more complex than it actually is, and that it's more important to have a good inference language. That's comforting to hear. However, I wish I had some good resource explaining what's involved in the "Multiplayer" part of "MUD". I'm not intending to learn Erlang any time in the next few months, but I've been curious about it for years. It's not that I'm trying to seek a specific advantage, I'm just looking for good opportunities to learn - in this case, a language and a project that's well-suited to it. Re: finished products - I decided that I'd spend this year just learning in free my without regard for "shipping". It's been really enjoyable so far, and I'd recommend it to anyone.
Hint: [Parenscript](http://common-lisp.net/project/parenscript/)
Sweet! Thank you!
On top of my head, I think it would be useful things on: 1) optimization 2) parallel/concurrency programming (special focus on bordeaux-threads, lparallel) 3) web programming 4) using cffi 5) how to use slime, debugger, profiler (and other development related topics) There will be other topics for sure. But like it was said, a "Lisp Companion" would focus on how to use the best libraries for certain tasks. Nick Levine's book "Lisp out of the box" seemed like a fine project of this kind. Unfortunately he was not able to finish it. 
Cool! What have you found to be your biggest challenges on it so far? My project is: https://github.com/flyingmachine/hobbitvgiant
If you want to embed shell scripts in your programs, you can also use [clesh](https://github.com/Neronus/clesh). You can find it in quicklisp now. It allows embedding ala perl's backtick operators.
Trying to find out how the server backend was to work, and channels. I haven't really been able to do much...
If you don't know about #lispgames on freenode... well, now you do. It's a good place to discuss Lisp MUDs. Also, I can recommend Programming Erlang by Joe Armstrong. It would be a great resource for creating a MUD. One of the big examples is all about IRC. I don't know if there's an equally helpful (for MUD-making) resource for Common Lisp. There might be. Of course, if you're just experimenting with a little MUD prototype, I guess you could manage fine with a simple polling loop even writing it in C and just running transactions against a simple central database. Keep it simple and then write a version of it in each language you learn. Edit: And since you mentioned gaming, Lisp, Erlang, and Javascript... I kinda feel obliged to mention a project of mine that touched each of those things to some extent: http://norstrulde.org/ilge10/ -- it's not exactly well-documented or useable for others (not maintained at all) but make sure you visit the about page and feel free to use "wget -np --mirror http://norstrulde.org/ilge10/" to get all the sources (the repo link is broken at the moment, sadly). All the concurrency stuff I learned to make that prototype, I learned from Joe Armstrong's book.
sweet, thanks. this is very useful to me
Thanks for the words of advice! Could you share any of the stuff you've shipped? It's always fun for me to look at the stuff other people make. It also gives me motivation. I'm curious, what prompted you to make the remark about shipping in the first place?
It's good to see someone taking over development and maintenance of good but older/unmaintained projects. I've been doing a little bit of the same thing myself, both for preservation reasons and bit-rot-avoidance.
My one comment is on your inline documentation. Though your functions and key values are obvious to the reader when looking at the code, it might be useful to describe the purpose of the keys. It might be a habit you want to get into. Plus its easier to do it during development as we all have a hard time finishing our projects by writing good, detailed documentation/tutorials on how its used. As for your code, its short and to the point. No overly long functions, no crazy nesting of function calls on a single line, etc. Very easy to read. As for (get-current-pid) I'd just add an error case in the end if the system does not support it. I hate it when a function just returns nil when I could be told "This function is not supported in your system." Either way if I use it, I have to come up with a test for the error case and this is a **system** dependent call. But maybe that is my own preference. If you want to still just return nil you could mimic how files are opened, allowing the user to pass in a *fail* case value (i.e. :if-not-exists-return). If fail value return it, else return an error. Something along those lines. Remember it might be silly looking in such a small function but it could be used all over the place in the end application and will come in handy at that point.
You have to decide if, at some point in the future, someone might want to handle the situation specially and do something different as a result. For example, in a function call that could result in 10 different types of conditions being raised, the caller might want to do something different if the result is "host unreachable" vs. "resource not found on remote host". In this case, it's such a simple situation that it doesn't seem to warrant a distinct condition to me.
I know.
By optimization I meant Lisp code optimization, especially things related to specific CL implementations. As for parallel/concurrency, I think it would be useful to show how to use the different libs that exist in CL that were developed with this in mind. IMHO, just general CS books is not enough. What we need is tutorials, chapters, books, etc, on these topics. But I know it is not easy to produce them...
The [COMPUTABLE-REALS](https://bitbucket.org/tarballs_are_good/computable-reals/overview) library in particular.
Now this is Real Finger Nail Clippings as a Meal ,instead of Finger nail clippings in the Oat Meal.
For impatient readers: &gt; This language was inspired by a conversation with Lucas, who said that scheme looks like this: ())()()()))))(). Well, it does now! 
Excellently named.
Good lord... it is beautiful... I know when I was learning lisp I was always complaining because of the completely unnecessary letters, numbers, and other symbols. This is Lisp as it was meant to be- parentheses in their purest form. 
If this site was written in null then we would not have this problem.
Most reasonably large Common Lisp projects I've seen make extensive use of the CLOS (an object system). Take a look at Practical Common Lisp for an intro, and The Art of the Metaobject Protocol for details. Here's a small project of mine that I think does a pretty good job of organizing things by functionality instead of class (while still using OOP where appropriate): https://github.com/smanek/blackjack
Lisp has classes. Lisp objects have named fields (aka slots.) Lisp has an object system. ...but packages and files are units of organization. My recommendation: read Practical Common Lisp.
I think you should clarify what you mean by "not everything is an object" to avoid any misunderstanding.
Code doesn't need to be organized really. You can put all your code in one big file and be happy. You can structure data with vectors or multidimensionnal arrays, so that you don't need to name fields. Then you can easily process the data with a loop indexing the slots of the array. I don't know if it's common to use an OO system, it's certainly trendy. But it seems to be that promoting OO has had an unfortunate side effect: it dumbed down people, who are not able to do any software engineering anymore. Organizing and structuring a large project is not done with classes. A class is a data structure. For large projects, you need more than a few data structures or a few classes. You may have between 1000 and 100000 classes or data structures in a large project. Organizing them doesn't rely on classes, because the purpose is to organize those classes! Rather, this is done as always, by decomposing the big pieces in smaller pieces and by ensuring that the interfaces between the smaller pieces are small, and that the graph of dependencies between the pieces is not circular, and not too deep and not too wide. In short, by thinking. Also, decomposing is a recursive process: once you've split your big project into between five and nine smaller projects, those smaller projects won't be small enough, so you further decompose them into smaller and smaller subproject, until you reach a size that can be implemented with a few data structures and code written in a few files. 
In addition to CLOS there are also structs (similar to structs in C) available. I don't know if it is accepted practice but I typically use structs on my way to a CLOS based design. I may start with structs, then as I refactor, I may slowly transition toots CLOS centric code base. Check out defstruct for details. defstruct also does cool things like auto-define accessor methods, etc.
do you have a github project for this yet?
So nice to see a good environment back on the Mac. I was starting to miss MCL.
Thank you for the reccomendation :)
I like the sound of structs to begin with... what does CLOS do better? Inheritance and other classy things?
Thanks for the reference :)
For that use case, I think I'd do something like this: (defclass window ...) (defgeneric move (obj offset)) (defmethod move ((obj window) offset) ...) ; code to move windows here (move (make-instance 'window) offset) ; use it like this (defparameter w (make-instance 'window)) (move w offset) ; or like this, they're equivalent In short: define a `move` generic function, then implement methods of that generic function that move a certain kind of object. You'd probably simplify this by defining some class to represent objects-that-can-be-moved, `box` or `widget` or something, then deriving individual things like buttons or labels from it as well as their other parent classes. tldr; CLOS.
Unless there's a good reason to use OO techniques, I normally try to avoid objects. One thing I've done before is this: (let ((a (intitialize-type-a ...))) (defun method-x (args) ...) (defun method-y (other-args) ...) ...) This is a good mix of local vars (you can control what they're visible to quite well) and global vars (you can share state between functions without passing it around). If you want `a` to group related data, consider using a hash table indexed with symbols. 
&gt; How can you structure data without named fields? Store it in local or global variables. If you have several related things that you want to look up by name, consider using symbols to index a hash table. Failing that, consider if your data needs to be stored in anywhere other than function arguments - you may be able to get away with not storing it at all. Or you can store it in a closure, then pass that around. Common Lisp does have a rather powerful OO system, named CLOS, but it's not used in the majority of projects.
Who downvotes? what's wrong with you people? :)
Hello, you must come from Scheme country? While that is perfectly legitimate CL, it is hardly ever done because placing the defun inside let means the defun is no longer a top level form. This has several implications, all of which are disadvantageous. See http://www.gigamonkeys.com/book/the-special-operators.html
You're referring to the Java convention of having one class per source file? Common Lisp doesn't use this convention because it's not always the best way to organize code. However, there's nothing to stop you from doing it this way. A common approach is to have a few files that are loaded early in the project that define your core types, generic functions and macros. Then you can put each new feature of your system in it's own file (or if it's a big feature, a directory).
The topic of character encoding keeps coming up. ASDF is starting to encourage UTF-8 as the default encoding, and for good reason. Moving everyone to a common encoding will greatly improve support for non-ASCII character sets by removing accidental complexity and error. This "UTF-8 Everywhere" site has a fairly good summary of why UTF-8 is the best option available today (and not far from a theoretic optimum).
I haven't tried this for CL, but I'm finding that RosettaCode serves pretty well as a clojure cookbook, at least for the most common patterns.
I did not say that defun did not create a global binding. I said the defun is not a top level form when it's inside let. I am not "looking for" anything. http://www.lispworks.com/documentation/lw51/CLHS/Body/03_bca.htm http://www.lispworks.com/documentation/lw51/CLHS/Body/26_glo_t.htm#top_level_form
Looking forward to 1.2 in 2014!
Ideologues who can't stand Apple.
I don't really understand the premise. What's the result of (mapcar 'or (list 1 2 3 4))? 1 2 3 4? How about (mapcar 'quote ...)? How did this come up in real life?
I suspect he means something more like: (mapcar #'or '(t t nil t t) '(nil t nil t nil)) This seems like a perfectly reasonable thing to try. I'll admit I'm a bit baffled about the purpose of mapping quote. Perhaps an identity on syntactic structures, or something.
Thank you.
I occasionally want to do: (reduce #'and ....) So I wind up implementing some AND function so that I can map over it.
You don't need to turn 'or' into a function. 'Some' has the same effect. (mapcar #'some ...) Also look at the 'every' function as it is comparable to and. The point of or and and being macros is that they only evaluate as much as is necessary to return an answer. Turning them into functions breaks this form of 'lazy' evaluation. I can't think of a good way to use mapcar quote, but I have used the 'identity' function for what I imagine would be a similar purpose.
&gt; I'd really like to know is there an explicit reason why make a function wrapper for a special form or a macro Are you asking why you have to make a function wrapper, or are you asking why you might want to? To answer the former, I highly recommend reading through [SICP chapter 4.1](http://mitpress.mit.edu/sicp/full-text/book/book-Z-H-26.html#%_sec_4.1.1). It addresses special forms and why they could not be written as regular functions. I suppose it follows that since special forms are not functions, they cannot be used in places where the interpreter expects a function. To answer why you might want to, I see nothing wrong with what you were attempting to do - there are plenty of good reasons to map over an *or* function. It just happens not to work here for reasons that, IMO, would not be immediately apparent to someone new to Lisp semantics.
It looks like you're confusing QUOTE with list creation. QUOTE doesn't exist in runtime. It's used to refer to objects directly in source code, i.e. it means "return whatever object reader have read here". If reader have read a list, QUOTE will return list. That's pretty much it. &gt; my transpose function uses the splice un-quote Backquote is just a syntax sugar for list manipulation functions. It cannot "unquote" anything, it receives lists and splices it. You can talk about "un-quoting" is macro context, though: at that point code exists as data, in form of lists, thus manipulations with list correspond to manipulation with code, and so you can refer to semantic changes it makes. But you don't transpose in macro, do you? Shouldn't it work at runtime? So I would recommend forgetting about backquote and using list operations: LIST, LIST*, APPEND, CONS, FIRST, REST and so on. They are sufficient. Then you can think how to add sugar. For example, `(cons 'abc foo)`, which is same as `(list* 'abc foo)` can be also written as ``(abc ,@frob)`. If you aren't sure what certain backquote expression does, you can quote it: CL-USER&gt; (setf *print-pretty* nil) NIL CL-USER&gt; '`(abc ,@foo) (SB-IMPL::BACKQ-CONS (QUOTE ABC) FOO) SB-IMPL::BACKQ-CONS is exactly like CONS, but it prints as a backquote when pretty-printing is on. How does it work? Backquote is a reader macro. Reader reads stuff in a special way, it produces commands which would create list according to template it sees. Adding QUOTE on top of it means that we will see these commands which reader created in backquote macro as they are returned rather than executed.
Yes! It will be part of the "C99-complete" feature announced for 1.2 along with a (re)port to current Mac OS X. And I plan to have it released well before 2013 ;-). It's the "image dump/load" that may be pushed to 1.3 if time runs short. This work should start in early June.
I forgot the words "it is bad" after the why in what you quoted but thank you for answering my question.
Fortunately [everyone knows not to buy it there](http://xach.livejournal.com/279786.html) (right?).
Not that I'd buy it at $350, but is the printed standard as bad quality as the pdf? http://www.techstreet.com/standards/incits/226_1994?product_id=56214
What does your code look like? Did you specify `cl-observer:observer` as your class' metaclass? The following works for me: CL-USER(3): (defclass foo () ((x :accessor foo-x :initarg :x)) (:metaclass cl-observer:observer)) #&lt;CL-OBSERVER:OBSERVER FOO&gt; CL-USER(4): (make-instance 'foo :x 100) #&lt;FOO {10074DF863}&gt; CL-USER(5): (defvar *foo* (make-instance 'foo :x 100)) *FOO* CL-USER(6): (cl-observer:observe (*foo* 'x new old) (format t "~&amp;Old: ~A; new: ~A" old new)) (#&lt;FUNCTION (LAMBDA #) {1007AE578B}&gt;) CL-USER(7): (setf (foo-x *foo*) 100) Old: 100; new: 100 100 CL-USER(8): (setf (foo-x *foo*) 200) Old: 100; new: 200 200
No, a superclass is something completely different from a metaclass. The way it works in CLOS goes like this: Every value is an instance of some class. But a class is itself a value—so it, in turn, must be an instance of some other class. Such a class—a class of classes—is called a metaclass. Since classes direct the behavior of their instances, the class of a class directs the behavior of the class. Usually, classes are instances of the class `standard-class` (note: this is different from the class `standard-object`, which is an *instance* of `standard-class` and the default supertype for `defclass` forms that don't specify one); but if you want to define a class that is an instance of a different class, you need to specify the `metaclass` option in the corresponding `defclass` form. The following REPL interaction might be interesting to think through: CL-USER(3): (defclass mulky-class (standard-class) ()) #&lt;STANDARD-CLASS MULKY-CLASS&gt; ;; Ignore this for now. CL-USER(4): (defmethod sb-mop:validate-superclass ((class mulky-class) (superclass standard-class)) t) #&lt;STANDARD-METHOD SB-MOP:VALIDATE-SUPERCLASS (MULKY-CLASS STANDARD-CLASS) {1005721463}&gt; CL-USER(5): (defclass normal-foo () ()) #&lt;STANDARD-CLASS NORMAL-FOO&gt; CL-USER(7): (defclass mulky-foo () () (:metaclass mulky-class)) #&lt;MULKY-CLASS MULKY-FOO&gt; CL-USER(8): (defvar *foo1* (make-instance 'normal-foo)) *FOO1* CL-USER(9): (defvar *foo2* (make-instance 'mulky-foo)) *FOO2* CL-USER(12): *foo1* #&lt;NORMAL-FOO {1005B94473}&gt; CL-USER(13): *foo2* #&lt;MULKY-FOO {1005C1E593}&gt; CL-USER(14): (class-of *foo1*) #&lt;STANDARD-CLASS NORMAL-FOO&gt; CL-USER(15): (class-of *foo2*) #&lt;MULKY-CLASS MULKY-FOO&gt; ;; NORMAL-FOO and MULKY-FOO have the same superclass. CL-USER(16): (sb-mop:class-direct-superclasses (class-of *foo1*)) (#&lt;STANDARD-CLASS STANDARD-OBJECT&gt;) CL-USER(17): (sb-mop:class-direct-superclasses (class-of *foo2*)) (#&lt;STANDARD-CLASS STANDARD-OBJECT&gt;) ;; But their classes' classes are different! CL-USER(19): (class-of (class-of *foo1*)) #&lt;STANDARD-CLASS STANDARD-CLASS&gt; CL-USER(20): (class-of (class-of *foo2*)) #&lt;STANDARD-CLASS MULKY-CLASS&gt; ;; It's turtles all the way down... CL-USER(21): (class-of (class-of (class-of *foo2*))) #&lt;STANDARD-CLASS STANDARD-CLASS&gt; CL-USER(22): (class-of (class-of (class-of (class-of *foo2*)))) #&lt;STANDARD-CLASS STANDARD-CLASS&gt; Metaclasses are useful only in the context of the meta-object protocol. They let you redefine things like the way slots are looked up and the way methods are composed into effective methods. In other words, they let you customize the way the object system works. I've used metaclasses in order to embed Objective-C classes into Common Lisp. The MOP is very powerful, and once you get the hang of it, it's actually quite simple, but it takes some getting used to.
Yes, this can be done in Lisp. Yes, I would do this in Lisp, because I know it and like it. Pretty much anything can do the stated problem. (n.b. most any language can be used for ai... some just do it better)
&gt; I might be confusing it with an artificial intelligence type language. Lisp has been widely used for AI and [a very good book](http://www.amazon.com/Paradigms-Artificial-Intelligence-Programming-Studies/dp/1558601910) exists on this. But it is actually a general-purpose language.
You can use the paiprolog library. PAI stands for Paradigms of Artificial Intelligence (as it's from the book) and prolog is a language made for doing first order logic. This library gives you the power of Prolog's logic processing while allowing you to use a more natural syntax for the rest. In prolog you would need to write your interface as logic statements. I'm not even certain how to do that. Simply, you make statements like (I'm not sure of the commands): (-&gt; Calculator is electronic) (-&gt; Item_12134 is a hoodie) (-&gt; Item_12134 is a jacket) (-&gt; Item_12134 is for boys) (-&gt; Item_12134 is 50% cotton) ... Then you could ask questions such as: What is Item_12134? (?- (Item_12134 is . ?x)) and get back (?x (a jacket)) (?x (a hoodie)) (?x (for boys)) (?x (50% cotton)) You can ask anything, such as which items are cotton, 25% cotton or more, etc. You can also set up rules such as "if sweater is red then it matches yellow or purple, or black". Very powerful stuff. EDIT: You can get paiprolog with [quicklisp](http://www.quicklisp.org/beta/) so it's very simple to install and use. The book is practically the manual so it's very through. 
Look up ways to program the game 20-questions. I own the [book](http://www.amazon.com/Paradigms-Artificial-Intelligence-Programming-Studies/dp/1558601910) posted by blue1_ and the solution is there.
You could do this with a relational database and SQL. Categories can be related to Properties (M-M), then as the user picks properties, you just keep requerying for categories until the user stops entering new properties and selects a category to use. This is probably the simplest way to do it, though perhaps not the most efficient at run-time. You could do it with a rules engine too if you want to get fancy. Implementing Rete (or even Prolog with straight up backtracking) in Lisp could be a lot of fun, but then you have to understand you're re-inventing that particular wheel just for fun at that point.
Lists are great when you want to add something to the front or traverse it linearly, but for anything else the performance hit becomes severe. Using a list as a hash will give you O(n) lookup time whereas hash tables should have constant time lookup.
Computational complexity. STRUCTURE GET AT LOCATION/KEY FIND OBJECT ITERATE ADD OBJECT --------- ------------------- ----------- ------- ---------- Singly Linked List O(n) average O(n) average O(n) O(1) Hash Table O(1) costly costly O(1) Extensible Vector O(1) O(n) average O(n) O(1) amortized 
For the record... there is a language that takes that approach to the extreme: [Picolisp](http://software-lab.de/doc/ref.html). As everyone said, not a sensible approach. Lookup on big lists is a performance-killer.
Lists are fantastic, more on that in a minute. How would you represent a phonebook with lists? The funny thing is, to do this properly, you effectively create a property list, which is just an unoptimized hashmap. You do need other data structures, but I too find it fascinating that they can be implemented as lists. Hashmap = list of (key value) pairs. Graph = ((node list) (edge list)). Trees can be represented with lists in much the way they are represented in arrays.
Furthermore, all of these can be encoded using lambda expressions. Not that you'd want to, for the same reason that you don't want everything to be a list.
&gt; [sufficiently smart compiler](http://prog21.dadgum.com/40.html)
&gt; Furthermore, all of these can be encoded using lambda expressions. Heh, yeah. If you really want to travel down the path of "all of these can be encoded using..." then try out SKI calculus, Brainfuck, and NAND/NOR gates.
"Everyone" has been fooled. Picolisp has an extremely thoughtful design. It's a great language for keveam to check out. &gt; Lookup on big lists is a performance-killer. If your program is working with big lists, then maybe it should be using C code, GPU code, or a database to deal with them. Also, a number of people are saying "O(n) lookup for lists", which seems a bit silly--even if it's kind of true--because we all know that you can build trees with cons cells as keveam already indicated by mentioning "nested structures". I think the question was more about, "are s-expressions enough?" not "are flat lists enough?". Personally, I'm really attracted to the "scripting" way of thinking. Others prefer something like Common Lisp that can "do it all". It's a different mindset.
the more memory and processing power the dummer the compiler you can get away with and vice-versa. no?
Well you could use prolog but using question responses as hard binary constraints is normally a mistake. For example if you show people either a kilt or a dress, and ask "Is this a skirt?", you'll get mixed responses.
You're right, I should have extended the first line of my comment with, "...in cases where you've found the performance characteristics of lists to be insufficient." I generally consider lists to be the go-to data structure in Lisp for just about anything, so by the time I'm looking at vectors and hash tables, I've already deemed plain lists to be insufficient.
The complexity of a hash table is not quite as simple as that, of course. Given an ideal hash it is. But collisions cause you to have to fall back on to a linear search (O(n)), and if you're recomputing hashes then additions are really O(1) amortized.
That's like saying "ideally you could do any computation with O(1) complexity growth". Which is the same as not making sense at all. There is no single general data structure which has fast iteration, random-access lookup, insertion and deleting. You have to sacrifice one or several of those traits. In practice this has little to do with the efficiency of compilers or computers. It is a fundamental concept of computation. Using a data structure with linear time complexity (for iteration and random access) for everything will never be a good idea, no matter how fast your hardware is.
I read somewhere (can't find the source now) that a general rule of thumb is up to a certain size a plist is about as fast as a hash table. Edit: dannywoodz posted below that what works for him is a list of up to length 12 is faster than a hash table.
Yes, I agree. There is a good book on prolog, apparently, but it's expensive and I haven't gotten to it yet. So my style is not the best.
what's next? bubble sort for all your sorting needs?
Good point. Clearly, I was confused.
The author's website is here, which has the slides and the downloadable videos: http://home.in.tum.de/~lehmanna/lisp-tutorial.html
where have I heard this voice, something to do with machine learning?
Thanks for this interesting post. I will enjoy following this to the end where actual ray tracing happens.
good question. I am in that mailing list too, I had forgot it. Although I fear the answer.
I(and perhaps also Drew) underestimated the amount of work required for such an endeavour, so unless somebody with a lot of free time decides to pick it up, it's not going anywhere. For the moment IMO the best thing is to built new functionality on top of current CL and gather such code in portable libraries.
I've just read the charter, it sounds way too ambitious. Adding things like "Multiprocessing and Concurrency", "Networking", "FFI" would greatly expand the language and, perhaps, make it POSIX-y. Do you really want to make Common Lisp another POSIX-y language? I think effort to improve the language should be separate from effort to add goodies. Say, CLtL3 should disambiguate standard and add important features which cannot be implemented on user level. And, say, _CL POSIX Layer_ should add stuff like networking and OS access. Networking and stuff are actually libraries, they might be part of language runtime, but not a language itself. I think it's strange that these efforts are united, it's way too hard to get consensus. Say, implementation vendors might agree on language extensions but disagree about adding POSIX stuff, now what, they cannot advertise cltl3 support? And then again, perhaps in 50 years we'll use some different OS, does CL need to work through POSIX APIs? 
Seems to follow my road to lisp. Though I had it more like Clojure to Scheme to Common Lisp. Didn't like JVM package on my slow end computer and Scheme didn't have portable way of doing things or libraries available. Common Lisp just allowed me the get things done and offers pretty sweet environment for doing it.
Well, it also aims at language improvement, according to [charter](http://pmeta.net/projects/cltl3/charter/cltl3-charter-draft-2.txt): (a) Repairing mistakes, ambiguities, and minor ommissions in ANSI Common Lisp (b) Extensions outlined in the CDR (including the MOP) (e) Extensible Streams (f) Extensible Sequences (i) Editing and Introspection I think it's unfortunate that 'standard library' issues are bundled with language issues.
&gt; OS-agnostic character of CL will be lost Good. &gt; There are ways to prevent aging of APIs: 1) make them abstract enough I don't want to prevent aging of APIs, quite the opposite: as we learn how to do things better, it's very useful that old stuff gets thrown away and re-implemented. &gt; Maybe you see no benefits today, but people in 50 years will thank you. In 50 years I'll probably be dead, and people's thanks will be of no use to me.
Not the author, so I can only speculate - but Guile does have native threads. Racket is trying to address concurrency through futures/places (2 different mechanisms), but thats at a higher level than native threading. PS: Gauche Scheme (another "batteries included" implementation) also has full support for native threads, across Linux, OS X &amp; Windows.
The purpose of this isn't clear to me. The example shows (:module "ports" :components ((:madeira-port "sbcl" :when :sbcl) (:madeira-port "ccl" :when :ccl) (:madeira-port "ansi" :unless (:or :sbcl :ccl)))) But why not just handle platform-specific stuff in separate files? (:module "ports" :components ((:file #+sbcl "sbcl" #+ccl "ccl" #-(or sbcl ccl) "ansi"))) 
Excellent! Looking forward to this!
That's one of the points. Another is the ability to write (:madeira-port "swank-hooks" :when (:find-package :swank)) or (:madeira-port "legacy-support" :unless (:find-function #:new-stuff :foo)) (:madeira-port "modern-support" :when (:find-function #:new-stuff :foo)) 
Sadly no. Right after that post shit hit the fan at work and I haven't had time to do much at all...even visit reddit. Hopefully I'll find some time this weekend.
Because I was tired of writing variations on an IO reactor with timers, which libev handles damn fine.
Gauche is also one of the most consistent &amp; fast implementations of Scheme out there. 
&gt; Why would anybody want to expose continuation passing style. That's easy. Events are familiar to many people, they are simple, and they work.
Is there a common lisp library out there that does what you're talking about?
sweeeeeeet! thanks!
Well, Shiro is a native Japanese speaker iirc; Scheme &amp; Lisp in general seem to have a large following in Japan, but I too run into the Google translate wall. I think keyword handling in Scheme in general is a bit messy; SRFI-89 isn't terribly useful without extension, and Gauche isn't terribly much different in this regard, unfortunately. I never liked PicoLisp's FFI, because it always seemed overly terse; c-wrapper and [KSM's style FFI](http://square.umin.ac.jp/~hchang/ksm/ref/ksm_10.html) are my preferences, though as of late I've been wrapping C access in PreScheme-like code and compiling it as an extension. I've used my own Scheme's C FFI much more than I've used c-wrapper, but it always seemed quite nice when I did have to use it. &gt; PS: do you have your scheme dialect on a public repo anywhere? Not yet, no. Part of it is that I have so many ideas that I'm testing, that I never get around to releasing, and part of it is that I'd really like it to be "perfect". My friends generally accuse me of never releasing personal projects, but releasing it is one of my long term goals.
https://m.twitter.com/PLT_Borat This alternate link will work without requiring javascript. This comment generated by an [automated bot](/r/link_unscripter).
Hahaha, this is no ordinary troll. He's good.
&gt; most eager await API of 2012 is http://www.w3.org/TR/2012/WD-vibration-20120202/
Let not forget PLT_HULK: https://twitter.com/#!/plt_hulk. HULK CRUSH.
Excuse me, but does hash key generation ever depend on n? Or why on earth are you getting O(lg n) "typical case" due to hash key generation?
 (defun dot (x y) (loop for i in x for j in y sum (* i j))) 
Did this guy seriously not realize that his third example is O(n^2 )?
3 is?
From my understanding, if you spend more time waiting for IO than CPU crunching, it can make sense to do evented programming. Many extremely fast systems use this model (Redis comes to mind) with great success. There are cases where you need both: processing *and* IO eventing...but there's nothing stopping you from doing that (Nginx comes to mind). There's a time and place for each type of system (threaded, evented) and I think it's nice to see the options open up for lisp.
QUOTE is a read macro, which expands 'whatever to (QUOTE whatever). If evaluated, *whatever* is returned. *whatever* can be any Lisp datum - a symbol, a list, an array, ... *:foo* is a special syntax for a keyword symbol. Such a symbol is in the package KEYWORD and evaluates to itself.
They are completely different. QUOTE is a function which returns its one argument. 'thing is syntactic sugar for (quote thing). It's a reader macro. Colon is used to tell the reader which package to intern symbols in. package::symbol tells the reader to INTERN a symbol called SYMBOL in the package PACKAGE. package:symbol means the symbol must be exported from that package. :symbol is actually short for KEYWORD:SYMBOL. The symbols in the KEYWORD package are automatically exported and their value is themself (like T is).
I attempt to address the "Sometimes you actually do want to crunch for a while" problem in Hinge with an API for a threadpool that can do work externally from the event thread in a blocking style, then return the results back to the event machine as an emitted event without interrupting it. This lets me have the production of work and consumption of results live with the guarantees of a single-threaded event loop, while the actual blocking or CPU intensive work is queued, then performed in a pool of N threads that have zero interaction with the event loop machinery during their execution. My demonstrations of the concept are pretty weak, since they mostly demonstrate the proof of theory rather than aim to drive a point home, demo style, but they can be seen [here](https://github.com/sshirokov/hinge/blob/master/examples/async.lisp#L26) and [here](https://github.com/sshirokov/hinge/blob/master/examples/http.lisp#L11). The pool implementation is in [src/pool.lisp](https://github.com/sshirokov/hinge/blob/master/src/pool.lisp) The `(async (:success .. :failure ..) ..)` macro is the bridge between the event machine and the thread-pool. I could expand on it if anyone's interested. 
Thanks for all the answers. Surprisingly, every single one has given me a slightly different insight.
I thought at first this was called Emacstasy. I kind of like that name better!
Looks like embed-able emacs with REPL API to me, nothing CLIM-like.
What CLIM also provides is key accelerators and extended commands (somehow similar to the idea to have a minibuffer in your app). With Climacs, you could also have an emacs-like editor as part of the app. LispWorks' CAPI also has these extended commands for its application windows. LispWorks also provides an Emacs-like editor which can be used inside the app.
This is kind of the opposite of what you're looking for, but since Haskell is a functional language, it should get you started: http://en.wikibooks.org/wiki/Write_Yourself_a_Scheme_in_48_Hours
Jwacs
You mean like these? http://www.cliki.net/programming%20language
There are a lot of languages that are implemented in Common Lisp. Now, unfortunately, it's often only the early implementation of a language that is written in Lisp. cl-python http://common-lisp.net/project/clpython/ There's a r4rs scheme implementation named Pseudo. http://www.cliki.net/PseudoScheme An early implementation of Yale Haskell. http://www.cliki.net/Yale%20Haskell "In ~2003, Mozilla's CVS tree still contains the original implementation of Javascript... written in Common Lisp." Well, the mozilla/js2/semantics/README that I just checked-out from mozilla CVS says: js/semantics contains experimental code used to generate LR(1) and LALR(1) grammars for JavaScript as well as compile and check formal semantics for JavaScript. The semantics can be executed directly or printed into either HTML or Microsoft Word RTF formats. You may also be interested in Zeta-C although it's not written in Common Lisp http://www.cliki.net/Zeta-C. maxima (which implements a mathematical language similar to macsyma, ie. similar to mathematica, octave or mathlab). http://maxima.sourceforge.net/ acl2 (which is a theorem prover) implements a lisp-like language in CL. http://www.cs.utexas.edu/~moore/acl2/ Qi is implemented in Common Lisp. http://en.wikipedia.org/wiki/Qi_%28programming_language%29 Here is a toy implementation of BASIC in CL: http://www.informatimago.com/develop/lisp/com/informatimago/small-cl-pgms/basic/ And the implementation L.S.E (Langage Symbolique d'Enseignement, a French programming language of the 70's): http://nasium-lse.ogamita.com/ http://fossil.nasium-lse.ogamita.com/nasium-lse/dir?ci=tip And a few more, see http://www.cliki.net/programming%20language 
Initial versions of the Yale Haskell Compiler have been written in Common Lisp, see [here](http://www.cs.cmu.edu/afs/cs/project/ai-repository/ai/lang/lisp/code/syntax/haskell/0.html).
Axiom (axiom-developer.org) is a computer algebra system implemented in Common Lisp. It has a langage called Spad for the algebra. The Spad compiler is all in Lisp. 
Hah, I got bitten by the Loop Variable odd capturing behaviour in Javascript just yesterday. Coming from a Scheme background I found it pretty confusing, indeed!
No, I depend on this: * proper indentation * editor commands that understand s-expressions * [paredit](http://emacswiki.org/emacs/ParEdit) * occasionally use show matching parens mode when the parentheses get out of sync
On the contrary, I have no trouble programming with invisible parens. Once you really grok paredit, you can "feel the Force around you". Think Luke Skywalker practising with the visor over his face. That said, my usual setting is dim parentheses, slightly visible. I am not sure why everyone doesn't use paredit or some kind of structured editing. I suppose it is the typical aversion or indifference to understanding new things. "Good against remotes is one thing, good against a living -- that's something else."
Alas, I'm too new to the language to know exactly what "proper" constitutes, but reasonable indentation is obviously still important; I just find that highlighting paints an even clearer picture. Sure, it's easy to track the outermore lists, but rarely if ever does one impose a limit of one per line. I think highlighting is most effective for the tightly nested lists that, perhaps as a novice mistake, I find myself using [pretty frequently](http://i.imgur.com/GRiwi.png). I'm sure the main issue is that I'm too used to Ruby, but still, would you actually write it like this? (match (string-ref input pc) (#\&lt; (set! bp (- bp 1)))) I'm really comfortable with Sublime at the moment, but it's always nice to have your editor work with you. Could you clarify what it means for an editor to "understand" s-expressions? Is that not essentially synonymous with matching parentheses? "Just [type] `paredit-open-parenthesis` instead of... parentheses." No, thanks. : ) From what I gather, "show matching parens" here means displaying the start and end of a list. If doing so improves clarity, why not always have it enabled and to a depth of more than 1? It also provides instant, plainly obvious feedback during desync. This last bit is essentially my reason for posting: what is it that makes it a detrimental feature for you, rather than an occasionally beneficial but otherwise neutral one?
Well I've already got C++ application and I'd like to keep it separated from CL part, now that ECL embedding failed.
Proper indentation is automatic indentation. Indenting by hand is just WRONG. (Sometimes you may have to do wrong things because we live in an imprefect world, but that doesn't make them any less wrong.) 
I'm not too interested in rainbow parens, but then I haven't tried them, maybe I would be surprised. I use dimmed parens. What I would like to try at some point is to undim the parens which don't precede an operator. 
That's right, you're no longer writing parantheses with names and numbers in them, you're directly writing trees with symbols in them. This is I think why S-expressions are still used and why other readers like M-expressions or whatever were never needed.
You may also be interested in [ReadScheme](http://readscheme.org/), which is a great repository of knowledge about language design in Scheme. For metaprogramming, see the sections on [macros](http://library.readscheme.org/page3.html) and [reflection](http://library.readscheme.org/page11.html).
Well, I like the idea too and would like to see this project I am working on done with ECL, but time is crucial right now. Later on I am planning to inverstergate this matter deeper and try to make it work.
I did not know about his, but I think it sounds like a great idea (but I'd probably set the custom colors to be different shades/hues of greys.. the multicolor would get annoying...) I use paredit and it definitely helps a lot, but it would be nice to get more visual clues about the s-exprs at a glance, aside from indentation and cursor blinking (I hate playing the game of, move-the-cursor-and-look-for-matching-blink) I understand your sentiment of not-wanting to be dependent on editing packages (I shared it when I started with lisp), but after using paredit almost exclusively for a while, it doesn't seem to have handicapped my s-expr editing skills the few times I've fired up 'mg' to do a quick edit. From my experience it's more about exposure and familiarity than muscle-memory.
I just added QVariantList to the Qt_EQL example, just for convenience: (qlet ((a "QVariant(QString)" "hello") (b "QVariant(int)" 42) (c "QVariant(double)" pi) (d "QVariant(QByteArray)" (vector -50 0 50))) (qmsg (qfun* *qt-main* :qt "callQt" (list a b c d)))) ; call to Qt/C++ using Q_INVOKABLE in Qt See [example](http://gitorious.org/eql/eql/blobs/master/Qt_EQL/EQL/trafficlight.lisp) at the end of the file.
I use rainbow-paren. It's not as sharp as I might like, but provides a nice background visual distinction. I plan to study paredit at some point.
&gt;There are empirical studies which show that programmers wallow around in suboptimal editing behavior. This is expected: see 'diminishing returns'. At some point investments into speed of typing just stop paying off. &gt; But since you don't know paredit, you have no business making claims about the efficiency gains. A thought process similar to [Amdahl's law](http://en.wikipedia.org/wiki/Amdahl%27s_law) can be used here: if I'm currently bottlenecked at thinking, not at typing, speeding up typing will have negligible effect, while speeding up thinking would speed up whole process roughly proportionally. The thing is, I know how much time I spend typing. Not much, that is. Maybe you think much faster then I do, or you do something which requires a lot of typing -- then indeed, paredit might bring some speedup for you. &gt; It's the same justification that non-touch-typing programmers use to justify not learning to type. They can get by. But they still are fucking idiots. There is no need to learn to touch-type -- with enough practice one picks it automatically. &gt; It's the blub paradox applied to everything. Absolutely not. Faster typing gives you a linear speedup at best, while use of higher-level abstractions gives you an exponential speedup. The thing is, complexity grows exponentially. &gt; Your use of the insert and delete keys looks wasteful to me. They are too far away. They are close together, though. &gt; You would benefit from not using them. Yes, that 0.3 seconds to move hand from cursor keys to letter keys totally makes a difference, especially when I spend it to analyze what was written and thinking about what to do next. However futile efforts to try Emacs-specific keybindings in applications which do not support them are not a problem at all. &gt; But doesn't that apply to every single emacs command? No, it doesn't. &gt; This time you ignored the subsequent phrase: all of functionality in http://mumble.net/~campbell/emacs/paredit.html I've read whole list before replying about paredit. Pretty much all of that stuff either can be trivially replaced by few 'plain Emacs' keystrokes, or it is some obscure shit which is used to rarely to learn keybindings. Do you know that memorizing keybindings takes time? Breaking habits -- even more so. I learned only keybindings which I use frequently. For stuff I use infrequently I either use M-x or menu (via mouse!). It absolutely does not kill me to reach a mouse few times a day. &gt; If you don't know about something, you can't conclude anything about it. Same applies to you -- you have no idea how fast I am with backward-sexp/kill-sexp and so on. How do you know that paredit offers a significant speedup? What is this speedup, by the way? Can you estimate it? Apparently you're bad at estimating speedup because your 'wrap with progn' scenario didn't offer any speed up at all, yet you thought it's worthy. &gt; There are only two rational approaches you can take. The first is to say, "Well people claim that paredit greatly enhances efficiency, but I haven't had time to look at it yet. I don't know." I checked that cheat-sheet and noticed that there is no spectacular stuff there. &gt; You want to not learn. I want to learn something else. Say, I'd rather read a paper on implicit parallelization rather than spend time on improving parentheses-typing speed _when I already can type them fast enough_. 
Does anyone know if there are any plans to support the new x32 ABI on Linux? (leading to reduced memory consumption on 64bit platforms)
[Relevant song](http://www.youtube.com/watch?v=5-OjTPj7K54).
In emacs (with or without paredit) there are commands to manipulate sexps: * c-m-f : forward-sexp * c-m-b : backward-sexp * c-m-d : down-sexp * c-m-u : up-sexp * c-m-space : mark (select) sexp (repeat to select more than one) * c-m-backspace : backward-delete-sexp * c-m-k : kill (delete) sexp * c-m-t : transpose two sexps I've been using emacs off and on for 30 years and have really only programmed lisp in emacs. though I have used other editors for other things and other languages. My conversion to paredit is recent as I was doubtful it would be helpful and it is hard for an old dog to learn new tricks. But now I am glad I went through the pain of learning it and believe me it is painful.
Basically yes. Or said differently: there were 2 paren(t)s, the starting one AKA Adam, and the (en)closing one AKA Eve. 
Just something I thought of when seeing the beautiful image posted by /u/lispm Hope you guys like it :)
Clever :-) I wonder how small the intersection is of people with an interest in lisp and church history - I remember writing a paper on whether Constantine's "conversion" was ultimately good or bad for the Church...
...and since it's in Twitpic and every Twitter user has an @ in front of their names, it's pretty clear that God, after designing the universe in Lisp, quickly hacked humanity together in Perl as an afterthought.
SBCL supports shebang just fine and I'd assume others would have support for it as well. POSIX support isn't in Common Lisp standard so the support varies by implementation but thats by design. 
&gt; I've had moderate success with Common Lisp; CLISP, CCL, and SBCL seem to be the most featureful, though their relative lack of POSIX support (shebangs are a hack) finds them wanting. How is (in SBCL) #!/usr/local/bin/sbcl --script a hack? Further, what does shebang have to do with POSIX support? The `sb-posix` package in SBCL gives you access to pretty much everything. What in particular are you looking for? Common Lisp was designed to be OS agnostic. &gt; Not sure if Clojure is considered Lisp. Why wouldn't it? &gt; I find its classpath funkery way too clunky to use. E.g., the current directory is NOT part of the default classpath, as Clojure expects every piece of code to reside in its own structured directory layout (eff that). Which has 0 to do with its Lisp nature. 
Thank you! Thank you! Thank you! I was obsessing about something like this a while ago, but couldn't find anything like it. I actually started implementing it, which turned out extremely slow and buggy, but was still very helpful. And now, thanks to you, HazierPhonics, I have finally found it. And it's fast and works great. And just in case the above sounds odd or wrong that's because a) I'm odd and b) I was just about to hit the sack when I wanted to give /r/lisp a quick look, found this and then had to hack my .emacs (rainbow-delimiters helped a lot) and now it's an hour later, and I'm very happy and thankful, but probably just writing very long nonsense sentences, but I just had to let you know that you just made me very, very happy. OK, I'll stop now and go to sleep. 
The problem with Racket or any of the niche Schemes is that you end up being confined to that little niche (and they are little). You have to add so much to Scheme in order for it to be useful/interesting. On the other hand, Common Lisp code can run almost anywhere with little modification: JVM (ABCL), embedded (ECL), and so forth. Lisp also has better tools: Slime, Hunchentoot, Quicklisp etc.
Yeah I've missed the point. Why don't you elaborate? What do you think 'niche' means? And what *are* Racket's limitations to a newbie?
Ok, Racket doesn't run on the JVM. What's another limitation? Of course I'm still missing the point. I *said* I'm missing the point.
Relax. My original was "Yeah I haven't." which was ambiguous. I edited it to reflect what I meant. Sorry that wasn't clear.
Waitaminnit, is this your final answer? You call racket a 'niche' just because it doesn't run on JVM, and you insinuate that that's just the tip of the iceberg with phrases like 'for instance'. Common lisp has features, but racket has 'bells and whistles'. And *I* am dishonest for correcting a typo?
Yep, that's why it's not used by SICP, which is of course not highly renowned... :-L
&gt; Not sure if Clojure is considered Lisp. I find its classpath funkery way too clunky to use. Of course it is Lisp. However, Clojure, due Java's approach of using classpath concept, can only obey to this, but every Clojure user will advise you to use [leiningen](https://github.com/technomancy/leiningen); from it you will be able to configure classpath, pack jars, start REPL listener, deploy and more.
A lot of his arguments are poorly worded. However having to specify arguments to run a script is always a pain for writing portable scripts (although that has nothing to do with POSIX support). When writing portable scripts, you generally want to use env instead of specifying your path. For example, when writing a ruby script, instead of using for the shebang this: #!/usr/bin/ruby you would do #!/usr/bin/env ruby This works no matter where ruby is installed. Your solution given above will only work if sbcl is installed in directory `/usr/local/bin`. However, this doesn't work if you need to pass arguments to the program, as many systems join everything after the command into a single argument. So #!/usr/bin/env sbcl --script won't work, as that will attempt to run `/usr/bin/env "sbcl --script"`, and complain that no program "sbcl --script" exists. There are some [workarounds](http://superuser.com/questions/280927/usr-bin-env-interpreter-arguments-portable-scripts-with-arguments-for-the) for this, but they aren't very pretty.
The common response at this point is to point out all of the popular de facto single-implementation languages out there, like Perl, Python, Ruby, Java, Objective-C, and C#. Ports or reimplementations of these languages are generally measured against the original implementation rather than some language standard. Choosing a single Scheme implementation is donning a pair of golden handcuffs, but so is choosing one of those other languages.
As a a) writes Lisp code and b) studies late Roman history, I would say that the intersection is very small. Also, that Constantine was good for the Church hierarchy.
&gt; However, this doesn't work if you need to pass arguments to the program, as many systems join everything after the command into a single argument. Key words being "as many systems": on Mac OS X this works fine. So your portability gain of using `/usr/bin/env` is lost. 
Exactly, which means it is pretty difficult to write a portable script using an interpretor that requires arguments passed to it to operate. You either have to either: * Use env, where the script will work no matter where the sbcl binary is, but won't work on the many systems where text after the shebang command is treated as a single argument. * Don't use env, which will result in the script not working on systems where the sbcl binary is in a different place to your system * Use one of the workarounds in the linked SO answer, which is portable, but ugly, and text editors won't detect the right text mode for it. There is really no good choice here. 
I'd also recommend arc (Hey akkartik! Didn't know you were on reddit too). It's very clean and, while not perfect, produces some of the prettiest lisp code I've seen. As a side benefit, you'll be one of the experts in it, because almost no one uses it!
Clojure is a Lisp. Racket is great for a person new to Lisp. Maybe the best. Zero fiddly configuration, which is, in my experience, a major buzzkill for a person trying something for the first time. Quicklisp makes CL much, much easier to get into, thank god, but it is still more fiddly than Racket. Clojure is ok, I guess, but still pretty fiddly. 
Common Lisp has more options, but as a _language_ it doesn't always come out ahead of Racket. Racket is a lot better in a lot of ways. You are right that CL runs on a lot of systems, but that isn't the only thing that matters. 
Please elaborate. I find your opinions _highly_ suspect. Look, its fine to prefer interactive programming. It has a lot of advantages AND you can do it with Racket via Emacs, if that is your thing. However, to assert that its the end-all of programming methodologies is, to be frank, idiotic. It is how you like to program. Other people like other styles. It is fine. I don't even know what to say about a statement like "Scheme is braindamaged." What does that even mean? For one thing, Racket is a pretty large superset of Scheme, with some features completely disjoint. So it isn't clear how it applies. But even then, Scheme, despite its recent revision issues, is a simple, well designed, and explicitly minimal language. I can't point to a very poorly designed feature. Maybe you can?
I like Common Lisp. It has a wide variety of implementations, an *excellent* package manager, usually is competitive on speed, and has profound abstraction capabilities. Schemes tend to diverge on the implementation and are frequently used primarily as research or teaching languages. It has the advantage of simplicity and theoretical hygiene Clojure is the new Lisp kid on the block, and has some interesting flavors. It's gaining a lot of momentum and popularity. I would not recommend it as a starting Lisp unless the learner is Java-based; it's a bit divergent as a dialect. emacs Lisp is, of course, tied to emacs. That's its own flamewar. ;) newLisp is an oddball Lisp that gets flamed regularly. I am not sure how good it is. --- My rank opinion.... I would, of course, recommend Common Lisp for a generic newbie to Lisps. I don't think there's any defining reason to use another dialect if a programmer wants to learn a Lisp as a generic Lisp (seeking the Lisp mind, basically). Common Lisp was also designed as a pragmatic Lisp, and its use and libraries seem to reflect that. For programming newbies or for researchers, a Scheme is likely the best. Kernel is a Lisp variant written in Scheme that's very, very, very interesting (to me). For people looking to consult or who are otherwise heavily tied to Java, Clojure is probably their best bet. I have a notion it's the most enterprise friendly. As for me - I anticipate learning basics of Guile Scheme and Clojure over the next year, but don't anticipate making them my primary Lisp. 
I'm a racket developer. Interactive programming is a huge deal. There you go.
Not to mention that the portability of a certain system has *nothing* to do with fitness for learning. My first Lisp system was Racket (well, PLT Scheme back then), and I've found that the *vast* majority of the concepts I learned while using Racket are applicable to *all* Lisps. The DrRacket IDE was a very accommodating environment for learning, and after I felt comfortable with Racket, it was rather straightforward to pick up standard Scheme, Common Lisp, and Clojure. It even made ML and Haskell more approachable. OP is asking about environments for *newbies*. I think it's silly to worry about portability as a newbie. If you want to choose something other than Racket for production, then fine. My experience has been that Racket is an excellent starting point that's very conducive to learning.
Well my emphasis was on small. The parentheses languages account for -- what the number is I have no idea -- maybe 1% of all programmers who get paid using them? Probably less. Relatively speaking, they are barely a blip on the radar. Like Haskell, the few that use them make a lot of noise, but the reality is that the overall landscape is pretty barren. Now Racket is a small subset of that small subset. I'm sure it's great for certain things. And I would actually advocate that everyone learn Scheme just to get a perspective. You can understand my point if we take a language which almost nobody uses -- say, Shen. I am sure that Shen is great. The type system is Turing complete, so it literally has the most powerful type system possible. It definitely is a good thing to learn. But for practical programming, you almost certainly want to leverage existing libraries and tools instead of writing everything from scratch in Shen. In terms of long-term goals and getting stuff done, the power tools are CL, SLIME and all that is available in Quicklisp. I expect it will be so for the foreseeable future. It's really hard to imagine going back once you've learned them. I don't know what you're getting at with "try that in CL". CL excels at building "new, non-lisp languages in a cleanly designed, well integrated fashion". You can even embed mini-languages in CL with a reader macro -- how could anything be more integrated than that? Do (ql:quickload "infix"). Now you have #i(1 + 2\*3) translated to (+ 1 (\* 2 3)) right inside your CL code. That's a pretty awsome level of power and convenience.
I see your point, of course, but I'm not sure it should be the most important thing for a new Lisp programmer. A new lisp programmer probably wants 1) a thing that is easy to set up, and 2) a thing with minimal design cruft to get in the way of fundamental Lisp ideas. I love Common Lisp - after programming with it intensely for several months, I've come to see that a lot of its rough edges make a certain sense. However, it is neither 1 nor 2. Reader macros are also great, but they don't come anywhere near the level of sophistication of Racket's "languages as libraries" system, which you should really check out. In fact, regular Lisp metaprogramming (including reader macros) is somewhat orthogonal to the "languages as libraries" feature of Racket. People have payed me to program in both Racket and CL, and it doesn't seem obvious to me that I would choose one over the other if given complete freedom; it would depend on the problem I needed to solve. But in terms of pure language design, my preference leans strongly towards Racket. And at RacketCon last year, I met lots of people who felt the same way. 
Hadn't thought of that. There is the terrible learning curve of learning a text-based editor while at the same time learning a new programming paradigm and syntax style, but... Its practicality can't be denied.
Yeah, Chicken Scheme's fiddliness seems to be limited to locating the Windows installer (well hidden on their website), and setting up readline.
I forgot about newLISP. My favorite thing about it is the docs, very well organized and with LOTS of examples of actual function calls. Pretty much the opposite of MATLAB docs.
I spent a lot of time treating this exact problem in a few languages, including CL and [Emacs Lisp](http://rosettacode.org/wiki/Multiline_shebang#Emacs_Lisp). Feel free to edit the article; I'm afraid so few people use shebangs, let alone Lisp that I haven't described the problem well.
Well, I'm a part of the intersection
The thing is, although Clojure has a few good things that I like, it removes reader macros and has not yet found a way to be completely independent of Java, which is a Bad Thing (ideally, you should be able to implement it both on and off of the JVM and write portable code--Clojure doesn't seem to be doing that or promising it). Because of this, I prefer Common Lisp. It has the promise of portability, and it has reader macros. It doesn't feel dependent on a specific platform. 
This is a very good response, though I would deprecate Clojure.
You already took your choice, so you don't need any help, do you? Lisp is Lisp anyways, there's no "wrong" choice, just follow your heart...
I clearly don't care about standards, and they're inarguably useful to you. For me to miss the point, you'd have had to actually articulate why standards are useful to *users* of a language. Perhaps it's fairer to say we're talking past each other.
That's a full compromise. So sure you would be hosed. But what was happening for a long time was that /usr/local was being installed with very lax permissions. For a long time Unixes like Solaris/HPUX etc. didn't even have a /usr/local unless installed by a user. And as it made sense to have an alternative location to /bin and /usr/bin to install additional supplementary software, the major vendors opted for /opt. They then delivered this installed in the OS with harder permissions because they worried that * changing permissions on /usr/local might break a lot of the (usually open source) software that was being installed in /usr/local * /opt could be a root level mount point to another disk where you could store this without affecting the /bin:/sbin disk.
Anyone else having problems with thread creation causing a crash into LDB on mountain lion with this version? 
I'm looking for Common Lisp implemented mostly in (any) lisp. What I'm really trying to do is get my own lisp interpreter (running on the objective c runtime) to become (closer to) common lisp, and I'd rather not have to write it all from scratch. Any pointers?
Hey guys, it's a language written in Common Lisp with different semantics than CL. What's wrong with that? I thought you guys were all about the DSLs. 
First, I got a comma not inside backquote error when trying to compile your macro. After removing the comma before alist it behaves as you described, and am proceeding under that definition of the macro. It is instructive here to (trace alist-to-let-clause) and then call both your sample call to it, and your macro. (alist-to-let-clause (car (get-state 1 2))) 0: (ALIST-TO-LET-CLAUSE (("Count" . 7) ("Stage" . 6) ("LastUser" . "Mary"))) 0: ALIST-TO-LET-CLAUSE returned ((COUNT 7) (STAGE 6) (LASTUSER "Mary")) ((COUNT 7) (STAGE 6) (LASTUSER "Mary")) Note that the argument alist-to-let-clause sees is the value (car (get-state ...)) returns. Now, the macro: (amonitor (first (get-state 1 2)) 1) 0: (ALIST-TO-LET-CLAUSE (FIRST (GET-STATE 1 2))) ; Evaluation aborted on #&lt;TYPE-ERROR expected-type: LIST datum: FIRST&gt;. The difference is that alist-to-let-clause doesn't see the value of (first (get-state ...)), but rather that list whose car is FIRST itself, and during the macroexpansion the call to loop within alist-to-let-clause errors because the symbol FIRST can't be destructured into (key . value). The underlying issue here is that macroexpansion happens, (at least behaves like it happens), at compile-time. So in (defun foo (bar) (amonitor (first (get-state bar 2)) ...do-stuff)) foo should behave like its body is the macroexpansion of amonitor, which could be macroexpanded at compile time, yet bar is unknown until foo is actually called! arc_tangent gave a nice answer on the assumption that the names of the variables you want bound (count, stage, lastuser) change based on the return of get-state. If you actually only want count, stage, and lastuser bound every time you can go with something like (defmacro amonitor (alist &amp;body body) (with-gensyms (alist-val) `(let ((,alist-val ,alist)) (let ((it "ok!") ;; testing ability to use "it" (count (assoc-value ,alist-val "Count" :test #'equalp)) (stage (assoc-value ,alist-val "Stage" :test #'equalp)) (lastuser (assoc-value ,alist-val "LastUser" :test #'equalp))) (declare (ignorable count stage lastuser it)) ,@body)))) Edit/p.s.: You mention testing a call to amonitor at the repl. Remember to test its macroexpansion. (macroexpand-1 '(amonitor (first (get-state 1 2)) (format t "~&amp;it:~A, count:~A, stage:~A, lastuser:~A, " it count stage lastuser))) (You will likely use an editor command or convenience macro rather than calling macroexpand-1.)
Interestingly, I wonder if this introduces potential threading issues (the use of special variables).
&gt; The global default is set with DEFVAR and DEFPARAMETER. But you don't have to have a global default -- that is, you can make special variables without DEFVAR and DEFPARAMETER. One way to do so is with PROGV. Another way is I see. That is the piece I was missing. I was too focused on the statement "The global environment is shared between all threads[.]" from the LW "Usage of Special Variables" section. I have never used progv or declare special so that was a little piece of magic dispelled for me. Thank you.
I was referring to EVALing a LET form, which can be done but is kind of silly. (defun silly-with-special-vars (alist code) (eval `(let ,(loop for (key . value) in alist collect `(,key ,value)) ,code))) (silly-with-special-vars '((a . 1) (b . 2) (c . 3)) '(list a b c))
I should clarify that if a variable is already declared special with DEFVAR or DEFPARAMETER then LET respects its specialness. One might say that the effect of DEFVAR or DEFPARAMETER is to insert an implict (declare (special ..)) inside LET for that variable. (defvar a 0) (let ((a 1)) ;; a is still a special variable; it's rebound to the stack with value 1 ..) It's a little odd that LET does two very different things. It can create a lexical variable, or it can rebind a special variable to the stack.
Well three things -- or it can *create* a special variable and bind it to the stack. That is, (declare (special a)), where a has not previously been declared special.
I'm curious. What domain is this intended for where Lisp is inadequate? 
I imagine for writing strongly typed programs that compile to C++ or Java. 
I didn't notice that: appreciate you pointing it out.
If this was written around 2000, why are we posting it now?
Ok, I think have the correct version now. I understand the spectrum point. This particular case is literally so I can dump cases in a file as I or others think of them. That's obviously not a long-term solution, but it's pretty attractive at this point. I really appreciate that you took the time to answer my questions with such detail. Thank you.
This is amazing. Can't wait to play with this.
http://www.michael-edwards.org/sc/liner.html &gt; The algorithmic system in "slippery chicken" has been used to create musical structure for pieces since its inception and for several years now has been at the stage where it can generate, in one pass, complete musical scores. **It can also, with the same data used to generate those scores, write sound files using samples, or MIDI file realisations of the instrumental score.** The project's main aim is to facilitate a melding of electronic and instrumental sound worlds, not just at the sonic but also at the structural level. Hence certain processes common in one medium (for instance sound file slicing and looping) are transferred to another (the slicing up of notated musical phrases and the instigation of sub-phrase loops, for example). Techniques for the innovative combination of rhythmic and pitch data—arguably one of the most difficult aspects of making convincing musical algorithms—are also offered.
My brain expected a library that expedited the composition of simpler algorithms into complex ones
FiveAM is the original project and more widely known, so I'd like to see eos as deprecated
What are the exact commands you are entering into the clisp prompt?
(load "file.lisp") Which is what it's telling me in the book.
Stupid suggestion, but did you start clisp in the correct directory? LoL is a wonderful book, but its pace may be a little too fast for somebody completely new to programming in general.
What directory would be the correct one to start it in? I agree with the pacing, however I am determined. edit: to clarify I am certain it's starting in the correct directory..
Isn't #lisp quiet enough as it is?
Lowest layer is byte-file which is pretty much like an array of bytes with extra features: it automatically grows as needed and supports writing sequences. `record-file` is for records of fixed size which are mapped onto these byte files. (Since they are implemented using CLOS it's fairly easy to extend them to support cache/buffering/transactions/replication and so on: it can be done on byte level, implementing only a very simple GF API.) Then it includes two implementations of binary search trees which are persisted in files: one is simple integer-&gt;integer associative array, another is string-&gt;integer. There's just enough code to show the concept. I'm now working on a basic triple store.
If you type you lisp expression in Emacs or Racket editor and keep pressing TAB key, you'll notice that the indentation doesn't keep increasing like when you do it in Sublime-text or other editors. Because Lisp-aware editor knows the proper indentation for your code. When you let go of formatting indentation yourself and let the editor do it consistently, then you will see the structure of your Lisp code by indentation. After that the parentheses will fade out from your brain as you don't even need to see it to see your code structure. All your problem and concerns about with Lisp editor is because you want to fight it. The proper way is to use sexp-aware editor and let editor indent the code for you. You will never have to wonder where in the sexp you are if you indent your code correctly in the first place.
I strongly support this. I like Common Lisp, but really enjoy a multi-language approach. I'd be happy to camp and answer questions as soon as I have just one job again.
What happens if you discuss other dialects?
Somebody will say "don't do that".
It does happen all the time, usually with newbies who are lost. And people in #lisp do give a fuck, myself included.
right but the newcomers come from all dialects.
I think that is really weird, because it doesn't really matter, as you learn, whether you hack in Common Lisp, Racket, some Scheme, Picolisp, Emacs Lisp. Many of the basic skills are the same, and jumping between them really serves to _drive home_ the nature of Lisp. My approach to Lisp, as a person who went from total newb to professional developer was extremely multi-lisp. I think for some folks it makes sense.
I am using windows 7.. It says Clisp in the program files directory When I enter (dir) I get a list of the 32 files that are related to Clisp. When I enter (load "file.lisp") It reads back *** - LOAD: A file with the name file.lisp does not exist the following restarts are available: Abort :R1 Abort main loop
At this point I think you need to (cd "/path/where/you/put/file.lisp") without including file.lisp. For example if you have the file in c:/users/bl4ino then I think you need to: (cd "c:/users/bl4ino") or (cd "/users/bl4ino") and then try (load "file.lisp") Unfortunately I don't have a windows box available to try that on. So at this point all I can say is Good luck!
It's also worth noting that their APIs are not completely identical. For example, when Adlai was working on Eos he removed the QuickCheck-like randomized/specification-based testing stuff. So there's no for-all, defgenerator and friends.
Isn't there already a #LispCafe for casual "hangingout" about generic LISt Processing? 
i think that's an off-topic overspill channel for #lisp (common lisp)
I use package-project in [expression hook](https://github.com/o-jasper/Expression-hook), will only work on sbcl currently unfortunately. Should probably improve it, including scanning most of the lisp packages on my computer so i know stuff works... (I did it at some point, but there have been changes since then) Dependencies for instance are added automatically by looking to which packages it refers. Leaves some stuff to enter manually for when the asdf system name isn't the same as the package name. Also, a package can depend on another without refering to its namespace at all, via methods, those have to be done manually too. (Even if i could infer all the types, this dependency can be retroactive..) Some stuff specific to projects is usually in `doc/info/info`, including possibly `:version`, in the future i hope to add sniffing of version control systems to autogenerate the version if not explictly provided. The asdf file name and name is based on package names, idem docstring. It looks for a header for the file and replaces them. (Currently it defaults `doc/info/header.txt`or a file named after the license, but not all headers intend to indicate a license..) Basically i try have 'the package' to be the unit of distribution and treat asdf as superfluous.(other than the mechanism) Hmm, havent thought about scriptability of the thing yet.. I guess you can get/set values with `package-project:package-info`, but running `auto-update` to get it is overkill.. (think i need to separate out a little function that fetches/writes the stuff in `doc/info/info` for better scriptable writing of that data..)
Um, what's your goal? Code::Blocks is a C++ IDE, as far as I know, I don't see how it would be of any help, unless you want to embed ECL in your C++ project. Basically, you can start 'slinging parens' right away -- launch ecl, you'll get a REPL, you can type Lisp code there and get it executed. That's pretty much it. If you want your code to persist you should write it into files and then `(load "foo.lisp")` in REPL. Any editor would work, but preferably it should be something with Lisp code coloring. Finally, for serious coding you would benefit from real Lisp IDE, such as Emacs+SLIME: it has REPL and editor well-integrated and all kind of goodies. (Don't be afraid of Emacs: you can keep using familiar key combinations if you reconfigure it a bit, for example, enabling CUA mode might help.) If your goal is to embed ECL you should look for some examples. [Like this](https://gist.github.com/662109). But it's a good idea to get familiar with Lisp first.
Going the ECL route is slightly difficult, unless you need the C++ environment. If you want to dig into Common Lisp, why not installing clisp ? It has a very comfortable REPL and is beginner friendly. Otherwise, you can find the ECL user's doc here: http://ecls.sourceforge.net/ecl/user.html 
Thanks, this is looking better already! For future reference, how would I use ECL? Is it just a C library or something? (Pokes around the ECL guide) It doesn't look like it installed the ecl executable - only ecl-config. Hmm. . . Maybe this is a question for a linux-specific board.
That kind of thing is really why I gave up on CLL. Perhaps I should give up on #lisp as well, judging by some of the other replies here.
You can use ecl as it is, which provides a Common Lisp system, with a REPL and all bells and whistles, by calling 'ecl' from your command line. ecl has one distinct feature: the whole system can be embedded into your C/C++ app. See here for the beginning: http://ecls.wikispaces.com/Embedding It still won't be easy to get started, but it shows you the things you will have to deal with. What do you plan to do with Lisp ? Again, I strongly recommend forgetting about embedding and diving into Lisp, first. There are a lot of "new" concepts to learn and it will be a pretty rough ride, but it's worth :) 
While you're at it you should try out Emacs and Slime. If the linux you're using has apt-get it should be as easy as: sudo apt-get update &amp;&amp; sudo apt-get install slime cl-swank sbcl sbcl-doc clisp clisp-doc And you'll have a couple good versions of Common Lisp and a really good IDE. Practical Common Lisp has a good quick tutorial on Emacs at: http://www.gigamonkeys.com/book/lather-rinse-repeat-a-tour-of-the-repl.html Don't worry about Lisp in a Box. That existed back when it was tough to set up Slime in Emacs. These days apt-get handles everything.
ECL definitely has command line. There might be a problem with Debian package, Ubuntu package definitely has `ecl` binary which provides REPL: http://packages.ubuntu.com/precise/amd64/ecl/filelist And I previously used it in Debian... So either they forgot to include a binary, or there is some clever way to launch it. Anyway, if you don't care much about CL implementation, CLISP is probably OK, it has pretty nice REPL. Although for serious work I would recommend CCL or SBCL: they have multhithreading, are fast, have lots of extra features and good library support. But REPL provided out of box is rudimentary, you either need an external program (Emacs) or some extra package to work comfortably. If you want to install CCL or SBCL do not bother with Debian packages. With CCL you can just download binary from site, unpack and run it. With SBCL you probably need to install it, but it should be trivial. (I generally build SBCL from source so I don't remember exactly how binary installation works, but probably it's just `sudo sh install.sh` which would install it into `/usr/local/`, so if you have `/usr/local/bin` in PATH it would just work.) I mostly use SBCL, but I like how how CCL is able to compile and load projects MUCH faster.
By far, the best freely available editor for Lisp is Emacs + Slime. Unfortunately, you'll need to grips with that at the same time as learning Lisp, so the barrier to entry is quite high. It is well worth the journey though, even if ultimately you do not end up using that much Lisp day-to-day.
 Last time I check it, there is a bug in current debian stable ecl package, which cause the installed binary to be deleted in some post install script. It's reported either to the debian bts or debian-user mailing list. Not sure whether this got fixed or not.
+1 for Emacs, mainly because you can learn more Lisp via using Emacs! If you also like Tiling WMs... I think StupmWM was configured in Lisp.
Configured? Mate, it's **written** in Lisp*!*
Someone will point you to #scheme or #clojure.
&gt; If you want to install CCL or SBCL do not bother with Debian packages. Can I ask why not? `sudo apt-get install sbcl` works fine for me. 
"Whatever"? Please delete this post. It is a disservice to needlessly balkanize the Lisp-like channels. And please consult cliki before making suggestions like this.
Here is the article in case web.archive.org is slow for anyone. The psychology of learning I have often observed that students are very inefficient in their work. They frequently use methods of working that are unproductive and slow. Some examples: Students do not know how to touch-type. Instead of taking the relatively limited time to learn to do it, they waste many hours per week on slow typing and typing errors. Students frequently do not know how to use advanced features in the text editor such as the interface to the version-control system, the interface to the Lisp system, etc. Again instead of taking a short time to learn, they waste much more time. Students do not know how to use a debugger. Instead, they waste time debugging programs with trace output. etc. As it turns out, this practice is not restricted to students, but is also common in the software industry. But why do people deliberately waste time when there are much more efficient ways of working? This is a very good question. In fact, it is such a good question that I decided to ask a well-known professor of psychology at one of the top universities on the east coast of the USA. What she told me was no doubt a simplification so that a layman like myself could understand it. Despite such simplifications, her explanation both gave me a much better understanding of the phenomenon and some ideas about how compensate for it. She told me that (with respect to this phenomenon) people can be roughly divided into two categories that she called perfection-oriented and performance-oriented. The people in the category perfection-oriented have a natural intellectual curiosity. They are constantly searching for better ways of doing things, new methods, new tools. They search for perfection, but they take pleasure in the search itself, knowing perfectly well that perfection can not be accomplished. To the people in this category, failure is a normal part of the strive for perfection. In fact, failure gives a deeper understanding of why a particular path was unsuccessful, making it possible to avoid similar paths in the future. The people in the category performance-oriented on the contrary, do not at all strive for perfection. Instead they have a need to achieve performance immediately. Such performance leaves no time for intellectual curiosity. Instead, techniques already known to them must be applied to solve problems. To these people, failure is a disaster whose sole feature is to harm instant performance. Similarly, learning represents the possibility of failure and must thus be avoided if possible. To the people in this category, knowledge in other people also represents a threat. As long as everybody around them use tools, techniques, and methods that they themselves know, they can count on outperforming these other people. But when the people around them start learning different, perhaps better, ways, they must defend themselves. Other people having other knowledge might require learning to keep up with performance, and learning, as we pointed out, increases the risk of failure. One possibility for these people is to discredit other people's knowledge. If done well, it would eliminate the need for the extra effort to learn, which would fit very well with their objectives. This model of learning also explains other surprising behavior that I frequently observe. I have seen novices in software development with knowledge of a single programming language explain to experienced expert developers why their choice of programming language was a particularly bad one. In one case, I talked to a student of computer science who told me why a particular programming language was bad. In fact he told me it was so bad that he had moved to a different university in order to avoid courses that used that particular language. When asked, he admitted he had never written a single program in that language. He simply did not know what he was talking about. And he was willing to fight for it. With respect to programming languages, negative opinions about a language that a person does not know, are usually based on very superficial aspects of it. To people obsessed with performance lack of such in a programming language is a favorite reason to advocate its eradication (even though performance is not a quality of a language, but of a particular implementation). As the reader has probably already guessed, my surprising observations concern mostly performance-oriented people. The above discussion is obviously a simplification. In particular, a person can be in one category with respect to a particular domain, and in the other with respect to another domain. Thus, I have seen professors in mathematics who were obviously perfection-oriented with respect to mathematics, be firmly in the performance-oriented category with respect to the efficient use of (say) word processors. It is almost a surrealistic experience to see a person in one situation full of intellectual curiosity and wanting to know everything about everything, and in another situation argue why you should not use a particular method that he himself does not know anything about, for reasons that are obviously totally artificial. Thus, what I have observed is not only what one might expect, i.e., some reluctance to learning new tools and methods, but a kind of reaction orders of magnitude stronger than I had expected. I have observed that people ignorant in a particular domain, or not knowing a particular tool or technique, would go to great trouble to explain why knowing this domain, tool, or technique, would be a complete waste of time. Usually these explanations were based on erroneous ideas of what it represented. To make things worse, they were perfectly willing to present their erroneous arguments to the very experts in the field in question. Similarly, I have heard people argue against a tool that they ignore based on the fact that it can do too much. Too much functionality in a tools is a problem only if unneeded or unwanted functionality somehow makes it harder to use the needed and wanted parts. I have heard people argue about the amount of memory a particular tool requires, whereas the additional memory required might represent a cost equivalent to a few hours of work at most. A favorite idea is to label a particular tool with a name suggesting what it ought to be doing, and then arguing that it is doing more than that. For instance, a text editor that is capable of automatic indentation would be accused of being a ``kitchen-sink'' tool because after all it does much more than allowing the user to just edit text. Needless to say, these people make complete fools of themselves. But that does not seem to bother them in any way whatsoever. It is hard to overestimate the strength of this phenomenon. I myself recently discovered a marvelous feature in a programming language that I had purposely avoided for the past 10 years, simply because 10 years ago, a colleague (who did not know the feature) explained to me that it was no good. We were both victims of our own minds. My colleague because he obviously needed to defend that he had made a different choice, and myself because I subconsciously found it very appealing to be able to brush off the feature as useless and thus not having to learn it. It is hard to overestimate the wasted time I have put in during the past 10 years due to considerably lower productivity than I could have had, had I realized at the time what I now know about human psychology. It is my hope that this explanation of a common phenomenon makes it possible for students to reflect upon their own motivations, and that it ultimately makes all students perfection-oriented.
In the brevity department: Zach suggests using a TYPE of "sexp" over "lisp-expr". 
And anywhere that you have a [jvm][] you have [ABCL][]. For [reference on the Common Lisp symbol dictionary see the freely redistributed hyperspec known as CLHS][CLHS]. [jvm]: http://hg.openjdk.java.net/jdk7/jdk7 [abcl]: http://common-lisp.net/project/armedbear/ [CLHS]: http://www.lispworks.com/documentation/HyperSpec/Front/X_Symbol.htm
I can very much relate to that. I've heard countless of more or less stupid excuses from people about why they're not willing to learn a more efficient keyboard layout than QWERTY. But obviously a constant strive for perfection can be counter productive too.
Same here, the book is on my desk right now so I couldn't help but misread the blog title. I think introductory texts like this would deserve an online REPL, is there a try-lisp out there ?
Jumping in a bit late here, but I'll reply to this subthread at this point (avoiding the silly "you're being dishonest" whining) random_lisper, we get it. The old "Common Lisp's standard has a lot of stuff included, while Scheme's standard (pick any one) leaves a lot of stuff out". I guess amongst lisp old-timers, this sort of stuff still holds some resonance (or else, why would I keep hearing this same old argument again and again?). However, for newcomers, I would suggest that it is ever so slightly **irrelevant**. How cares whether function X is described in a "Standard document for Scheme", and function Y is in SRFI-999? All that matters is - what does it do? How well does it do it? Otherwise, you're just looking at all "Scheme's", taking their lowest common denominator, and ignoring all the rest. In fact, you're not even doing that - because you're ignoring the mainstream SRFI's which have wide cross-Scheme-implementation acceptance and use. Such a blinkered view does not a valid criticism make. Forget about the Scheme standard. There, I've said it. Now, take some of the better Scheme implementations, and evaluate them as independent languages. Great, now we've taken the whole "hey, but all this functionality is not part of your supposed **standard**, so its completely useless, unusable, irrelevant, pointless, etc etc" out of the equation. Now we're down to looking at "which lisp is better for x, y or z". Which is closer to the **point** behind this thread. 
Just started reading this yesterday. L.I.S.P. seems great.
&gt; In Lisp + is called a procedure. Is that true? I always thought everything is a function in Lisp? 
Usually the name procedure is used as the word function indicates that there are no side effects. As for '+' this may be true but for others certainly not... So if you are more comfortable with function just think function when you read procedure.
Of course, the fact that the procedure-creating form is called `defun` isn't confusing at all...
This missing corollary to this essay is the downfalls of being too perfection oriented. These are certainly harder to find, but their effect on a project can be equally damning - your project never ships because there is always some section of it that is being redone. Given an infinite amount of time, achieving the perfect implementation is simple. The true art is getting the best solution in about the time allotted (I say "about" because, lets be honest, it always ships a little late).
&gt; This code was previously part of fare-utils but has been split into its own package since Quicklisp has now tipped the balance of practicality towards having plenty of small interdependent libraries rather than big independent monoliths. This reminds of how much better things are with Quicklisp. Yay! &gt; However, I looked at the state of Common Lisp libraries, and could find precious little in terms of functional datastructures, except for FSet which comes with its own CL dialect which is more than I'm ready to deal with Ugh, really? I wonder if Fare has ever tried using FSet without "use-package"-ing FSet? I have used FSet in many projects and not once have I used FSet's "own dialect". That aside, very cool to see more of this kind of work.
Thank you. That's pretty much how I knew it from my more familiar grounds. Even though a lot of C literature is very sloppy with the distinction. In Lisp context I just never heard the word "procedure" before. Either it was all functions or there was a distinction between "pure functions" and "functions with side-effect." And given that + is very clearly in the pure function category I was pretty surprised here. &gt; In Scheme, procedure is the "official" name, by the way. If the guy has a Scheme background, that's probably the explanation. 
Well, it's just about comfortability. In fact, the fastest typest(I know of) in the world also uses caps lock for upper-case letters, instead of shift. Now how he manages that? I have no idea, but he can type 200 wpm, so.. whatever floats your boat.
&gt; Usually the name procedure is used as the word function indicates that there are no side effects. Phooey. "Function" is the word to use in Lisp. It appears on every page of the hyperspec that describes a function. There is also a function type http://www.ai.mit.edu/projects/iiip/doc/CommonLISP/HyperSpec/Body/syscla_function.html#function and a glossary index for the term http://www.ai.mit.edu/projects/iiip/doc/CommonLISP/HyperSpec/Body/glo_f.html#function C uses the term function as well, along with many other languages. It's not a term reserved for purity only.
I wanted to clarify the distinction between the two terms, which both are used actively in lisp languages, such as scheme. The CL hyperspec is not the one and only authorative resource.
It's not true that "the word function indicates that there are no side effects." You introduce the ridiculous red herring of CL being "the one and only authorative resource" when in fact I said the opposite: "C uses the term function as well, along with many other languages. It's not a term reserved for purity only."
I merely answered the hidden calls of zillions of people who have asked me over the years, where oh where they can talk about lisp without being instantaneously shouted down by somebody's hair-trigger temper? I'm a nice guy and have utterly lost count of the times I've been pulled aside to explain the dripping condescension and rage of my so-called fellows. I don't need to trawl the web for your correct answer about where as-yet-unidentified people should go first (cliki) to find out where they should go next (#lisp) in order to finally ask their real question. I just answer people's questions to the best of my ability and don't chew people out simply because I have heard a question before. Magically, it means I end up hearing many more questions and thus coming up with some way to help. "Please follow my angry post to the angry IRC channel that I am angrily linking to, or else you're Balkanizing." Here is a hint from Zen mind: avoid channels you don't personally like. Others are already doing the same, if you haven't yet caught on to this aspect of my koan. If you can make your channel more personally likeable by being likeable, do that. If not, don't. In other words: The more you tighten your grip, the more star systems will slip through your fingehhhhhs
The name isn't too descriptive. What is one suppose to infer from the name? That it's a library, written in lisp and there's an interface to it? Huh?
True. This showed up in my rss feed and I clicked on it just to understand what it was.
which I did as well -- seems to work?
I agree with timonoko: in practice programming in Prolog turns into a nightmare of explicitly avoiding backtracking all over the place if you want to write anything non-trivial. However the comments on pattern-matching are interesting. Although there have been various times where really annoying functional-programming people ranted endlessly about pattern-matching being the solution to everything which kind of puts you off it, I think there is something to be said for it as a tool. (Of course, there are several very competent pattern-matching packages for CL: this is not an anti-CL comment).
I believe the "real" rationale would be that, following the rest of the style guidelines regarding indentation (and some others, regarding line breaking), the parenthesis are largely unimportant for reading. It may be the fact of being used to them but, after reading lisp for a while, the second version feels (to me) absurdly easier to mentally parse, because there's less "parenthesis noise". Ignore the parenthesis and focus on the indentation and the tree structure is quite obvious. The noise to signal ration on the first version is too high
How do you know that you find it easier to mentally parse? Does your brain have introspective capabilities? Lot's of people try to rationalize their preferences, without any real insight. In AI so-called Expert Systems we used to capture the 'knowledge' of domain experts. It was found that experts didn't really know how they do things and their explanations of their reasoning process was just what they thought how they think.
Lonely parens are easier to parse when you are trained by C/C++/Java and the like. After spending a bit of time with traditional Lisp formatting, you will find it has Python-like indentation properties, and it doesn't suffer from Python's tab/space mismatch or nesting issues. It is also more compact vertically, with some horizontal loss. More code on the screen means less scrolling and faster cross-reference.
&gt; How do you know that you find it easier to mentally parse? The same way that you know that you personally find it easier to parse any of the above two examples than the following: (define (factorial x) (if (&lt; x 2) 1 (* x (factorial (- x 1 ) ) ) ) ) 
&gt; It may be the fact of being used to them but, after reading lisp for a while, the second version feels (to me) absurdly easier to mentally parse, because there's less "parenthesis noise". Ignore the parenthesis and focus on the indentation and the tree structure is quite obvious. But the whole point is that in the first example I found it easier to see the tree structure at a glance within the expession (* x (factorial (- x 1))) precisely because of the way that the parenthesis were laid out. Having said that, I will happily admit that this could simply be due to my personal programming experiences and need not reflect in any way on the actual objective merits of the first style versus the second style. :-)
that's an impressive amount of dead in one sentence!
My theory is that it is a matter of human pattern matching. If you measure "easier" from Person A's perspective, naturally, they will feel that the patterns they have seen most are the easiest, and the incorporation of new patterns must somehow mesh with the old patterns... or replace as "better", but that takes time. Person B, who has compatible patterns, might agree about the "ease" faster. Person C, who has no preconceived patterns (someone completely new to reading code in any language), will grow into the new pattern faster than Person A and slower than Person B. In other words, I am learning to take with a grain of salt people's initial reactions to new concepts. The important thing is the exposure to the new concepts. If one makes more mental links with it and incorporates that knowledge into their existing patterns, it was definitely worth the exposure, even if for understanding why to reject it.
Too Russian;Didn't Read
It did not exist in 1985.
Isn't Apple listed in the credits of the ANSI CL spec?
Yeah, that's a good point. I'm not sure how to phrase what I meant, though. I guess Wikipedia's phrase is that Russia "assumed [the SU's] rights and obligations". I've never really considered what it means for one country to be replaced by another.
&gt; The explanation is pretty bad because it's intended to be a joke. To be clear, that fact was completely obvious to me, it just seemed to have no place in a style guide if the goal of the style guide was other than to preach to people who already agree with it.
Many Russians think that there's a bit too much of Soviet Union still left in contemporary Russia.
Are you saying that you want (#'+ 1 2) to work? In other words, an implicit `funcall` whenever the list head is a function object? What about (let ((x #'+)) (x 1 2)) Should that return 3, or should it be an error for undefined function `x`?
I felt the same once, too. We end up relying too much on the punctuation when reading most other languages. After a while, in Lisp, it just feels more natural to follow the indentation for structure, so the parens kinda like "fade out". This is what I actually read when I see that: define (factorial x) if (&lt; x 2) 1 (* x (factorial (- x 1))) Not that big of a difference, I admit, but it all adds up. And in the end, a lot of parens just get ignored. Edit: Of course, this is probably not a "good thing" to say about Lisp's syntax. That we learn to ignore a lot of it is not what you'd expect from a good syntax. On the other hand, the oversimplified syntax gives so much in return that I'm willing to take it, clumsy as it is. Edit2: And now that I think of it, I believe the code above is written in a form of what some call "I-Expressions", as defined by [SRFI 49](http://srfi.schemers.org/srfi-49/srfi-49.html). I'm not sure if it's entirely correct, since I don't actually use it, and just found the number by googling "SRFI Indentation".
That's an undefined function error. Is that what you want, or not? Assuming not, what is the rule for the compiler to tell the difference between function `x` and your thing?
Try load by absolute path first, if it stops yelling that error. At least it proves Clisp tells no lies. ;P
Maybe I have a function named X ;) But yes, that is what should happen. Its not about Lisp-n-ness. The question is what is the motivation for the definition of [operator\[4\]](http://clhs.lisp.se/Body/26_glo_o.htm#operator)? Why should lambda expressions be permitted but not actual function objects? Actually, lots of function concepts seem messy. Function names, function designators, extended function designators, `(setf` blah`)` forms, operators, lambda lists, the LAMBDA macro.
Your point has become progressively less clear. What exactly should happen, again? Common Lisp tries to call the function `x`, which is apparently what you want. If not, then what? What is the compiler rule you want to add?
Why do not use '+ instead of #'+ ? (eval (list '+ 1 2)) ==&gt; 3
The OP wants (#.#'+ 1 2) to mean the same thing as (+ 1 2). Or put another way, for (#.(lambda (x) ...) ...) to mean the same as ((lambda (x) ...) ...).
But what is this about? (let ((x '(lambda (&amp;rest as) (apply #'+ as)))) (x 1 2)) I guess you don't want to call function x, even though you responded yes to my question. I'm suggesting that if you imagine for a moment how a compiler would implement it, you'll see the problem.
Yes, I _do_ want it to call the function X (techincally, X could name a macro too, but anyway...). My point was that asking about the let thing had nothing to do with the OP's question. The OP doesn't want the variable binding of the car of the form evaluated and the result used. The OP wants to know why its illegal for the car of a compound form to be a function. Actually, I probably should have corrected your first post. OP wants `(#.#'+ 1 2)` to work, not `(#'+ 1 2)`. Sorry.
&gt; Yes, I do want it to call the function X (techincally, X could name a macro too, but anyway...). That's what CL already does. It tries to call the function `x` or the macro `x`. Macros are functions, by the way.
If you are asking why a LAMBDA literal is treated specially in the head position, think about a macro that places a parameter in the head position. (defmacro literal-funcall (fun &amp;rest args) `(,fun ,@args)) (literal-funcall + 1 2) (literal-funcall (lambda (x y) (+ x y)) 1 2) Both of those work. Isn't that nice?
Sure. But this is all about whether it'd be nice if `(literal-funcall #.(lambda (x y) (+ x y)) 1 2)` would work.
&gt; Why should lambda expressions be permitted but not actual function objects? Because a literal lambda form corresponds to a function that is known at compile time. As does a symbol.
What does "known" mean? What is known about the functional value of a symbol that isn't known about a function object? For the function object, you actually know the function you'll be calling at compile time; for the symbol, you don't.
I think the answer you're looking for is that it would be inconsistent with the expansion rules. For instance, would your #.(lambda...) bypass compiler macros? Would it bypass recursive macro expansion? How does CL even know whether it's a function or a macro?
&gt; bypass compiler macros? Yes, those are for names. This is exactly the same as it already is for lambda forms. &gt; bypass recursive macro expansion? What do you mean?
Then what did &gt; Because a literal lambda form corresponds to a function that is known at compile time. mean? It can't be about names. Compiler macros already don't apply to lambda forms and macros work fine with them. The (_F_ x) syntax where _F_ is a function object would have identical semantics to ((lambda (y) (funcall _F_ y)) x).
I think the answer is no, there's no reason. But rather than some huge litany of special cases for the operator position of a form, wouldn't it just be easier to say that it has precisely the same evaluation rules as all the other positions? Well, that's what a lisp-1 is and there are many well-known examples of such languages. Essentially a conventional Lisp-n like CL has a pretty simple rule: - does the car name a macro? - if not is it (lambda ...) - if not it names a function And a lisp-1 has a slightly simpler rule - is the form a macro of some kind? - if not it is a function application, evaluate the car to get a function I don't see any reason to make there be more rules, in either case, since almost always (and certainly in this case) they seem to amount to half-a-lisp-1.
You didn't tell me what the problem with flet and macrolet is. And I don't know what you mean about lambda expressions not being able to refer to existing functions.
&gt; You didn't tell me what the problem with flet and macrolet is. ? "(foo 1 2) is not in general equivalent to (#.#'foo 1 2)" *because of flet and macrolet*. There is no expectation that ((lambda ...) 1 2) would be equivalent to any function. It doesn't represent the name of any function. flet and macrolet aren't going to affect it.
М-да, даже пошутить здесь не дадут.
Because if it were referentially transparent then it may be of value. Since it's not, I see no redeeming qualities whatsoever. It must always mean funcall, so we might as well write "funcall".
Again, your argument applies just as well to lambda forms. Speaking of referential transparency, since function objects are immutable, these would actually be better off than function forms or lambda forms. If you expect that foo's function value will not change in the execution environment that's not a problem with evaluation.
Ron/Erran/Error/whatever, you responded to me. You weren't responding to the OP. I said &gt; I guess you don't want to call function x, even though you responded yes to my question. I'm suggesting that if you imagine for a moment how a compiler would implement it, you'll see the problem. You responded, &gt; Sorry, I imagined how a compiler would implement it and I still don't see the problem. You didn't read or understand my post. This is why your co-workers hate you. It's always something like this crap with you.
If you actually read or pay attention to the parens, you're doing it wrong. &gt; The actual bracket characters are simply lexical tokens to which little significance should be assigned. Lisp programmers do not examine the brackets individually, or, Azathoth forbid, count brackets; instead they view the higher-level structures expressed in the program, especially as presented by the indentation. ... and your editor should be able to directly operate on your code as a tree, managing parens for you. 
There's more work to be done and I'm sure I'll blog again when I have something more interesting to show. In the meantime, I'll be in #lisp if anyone has particular questions. :)
*That* is a limitation of some common-lisp implementations, but there's no reason a common-lisp implementation cannot dump a function: Clozure CL (the CL whism is using) happily dumps functions, for example. What's *actually* going on is better illustrated with this: (defvar *some-list-a* (list 'funcall #.(lambda (x) (* x x)) 2)) (defvar *some-list-b* (list #.(lambda (x) (* x x)) 2)) Now, while `(eval *some-list-a*)` works fine, `(eval *some-list-b*)` fails, and it fails for the same reason whism's example fails: `(a b)` isn't *exactly* the same as `((function a) b)` or `(funcall (function a) b)`: From [Section 3.1.2.1.2](http://clhs.lisp.se/Body/03_abab.htm), the cons may be a special form, a macro form, a function form, or a lambda form. All of these forms use a symbol for the operator except the lambda form, which allows a lambda expression, which is [a list](http://clhs.lisp.se/Body/26_glo_l.htm#lambda_expression), and not a lambda object. That same section prohibits any other value from being there- and that includes a lambda object. tl;dr: that's a red herring, the real reason it doesn't work is because the form is prohibited by the CL spec. 
You're looking for [Section 3.1.2.1.2](http://clhs.lisp.se/Body/03_abab.htm). The answer is having a lambda object as the operator is prohibited by the spec.
Implicit funcalls make me nervous- I'm suspicious of some kind of interaction at macroexpand time, but I admit I haven't thought about this very much. How long have you been using this, if you don't mind my asking?
and then MB looks back over his shoulder and as politely as his clenched teeth will allow says, "... I fucking hate rockstar programmers ..."
A long time (years) but not very extensively. I think this is mostly of academic interest, mainly for demonstrating the lambda calculus and the Y combinator, e.g.: http://www.flownet.com/ron/lisp/Y-combinator.lisp I don't actually use combination-hook in any production code. But YMMV. 
Something like: http://michaux.ca/articles/scheme-from-scratch-introduction ?
yeah, this seems like it'll work, thanks :)
I recommend the book "Lisp in Small Pieces", maybe not as a guide to implementing a Lisp in C, but as an excellent introduction to language semantics in general.
Have you looked at this? I've not had a chance to play with this, but it might save part or all of a journey. http://voodoo-slide.blogspot.com/2010/01/amplifying-c.html http://www.cliki.net/c-amplify
If you want to read some code for a minimal (but quite useful) Lisp, check out [SIOD](http://people.delphiforums.com/gjc/siod.html).
/u/nschubach reference to Scheme from Scratch is a *great* material. If you're past it and want to try other ideas and techniques I'd recommend Nils M. Holm's *awesome* [Scheme 9 from Empty Space](http://www.lulu.com/shop/nils-m-holm/scheme-9-from-empty-space/paperback/product-13002199.html) book. It is a little costy (at US$ 30,00 for an e-book), at least for me, but it's worth every penny. If you don't feel like paying, a slightly outdated and less polished version used to be available for free in Nils' website, though I don't have the time to look for it. In a shameless plug I wrote a simple Scheme interpreter based on a compiler + virtual-machine architecture as described by [Kent Dybvig's PhD thesis](http://www.cs.unm.edu/~williams/cs491/three-imp.pdf) in the simplest version by chapter 3. It was made in C, instead of the Scheme he uses in the thesis, though and is hosted on [Github](https://github.com/alexandream/scheme-interpreter). My version is somewhat badly commented (though a whole description of it can be read in the .tex files inside the monograph/tex directory, unfortunately in Portuguese) and fails in a few situations but it has full Lexical Scoping, defmacro style macros (unhygienic, procedural macros), a couple of different types (numbers, characters, strings, cons cells) and includes a simple fixed-width allocator and garbage collector. The project is dead (I'm working on another Scheme interpreter for fun, learning from the mistakes on the code in this one), but if you want to discuss it in any way just message me sometime.
If you don't mind showing unfinished code, I'd say post it on github (or any other open hosting system), so a few of us (I would, at least) can follow it and even discuss the strategies if you're interested in more opinions throughout the process. I, at least, find lonely programming depressive sometimes and my projects always go faster when other people are involved, even if only reviewing it.
&gt; Nils M. Holm's awesome Scheme 9 from Empty Space book I recommend this excellent book, too. It walks through the source code of his well-written C implementation. Full disclosure: a year ago Nils gave me a free copy so that, in return, I would fully read it and post an honest review, which I did. 
If you want to really master Lisp, I can't recommend this method enough. [I've done it twice](http://www.reddit.com/r/gamedev/comments/u2c8w/building_a_scripting_language/c4rurg2), the second time with a friend and got to be rather advanced. Doing this will advance a lot more than your Lisp knowledge because you'll get a real understanding for what's happening in the guts of other languages, too. Lisp has such simple syntax that you don't really need to use lex/yacc. I would recommend just writing your parser by hand unless you want to practice your flex/bison. If you do choose this route, a big word of warning: by default, bison has global state and is *not* reentrant, which is essential if you want to write a proper reader. It's an old yacc design flaw and is not bison's fault. It's surprisingly easy to create a working Lisp. The hardest part is probably memory management. If you want to skip that detail you can always use the [Boehm GC](http://www.hpl.hp.com/personal/Hans_Boehm/gc/), which does stack scanning and will make the rest of your C code base cleaner as a result. 
Yeah, I figured I'd use libgc to take care of memory management, since it's really just wasting time to do otherwise. Also practicing flex/bison is probably good in case I want to try something harder to parse than lisp later on.
Somebody should publish robust CAR,CDR and CONS with garbage collector, and READ and PRINT of course too? It would be so cool, when you do not have mess with lowlevel data constructs in C. 
This will not be difficult but I'm not sure flex and bison would be appropriate for a full lisp. Once you learn flex and bison, this would be a very short exercise. 
Might as well dump in [my own attempt](https://github.com/fisxoj/glisp). Nothing special yet, but, thanks a lot for a great project idea! (also, mine is a lisp, not a scheme like the michaux.ca link that I drew inspiration heavily from...)
Heh, I'm having a fun time comparing http://github.com/akkartik/wart#Readme and http://github.com/skeeto/wisp/blob/master/doc/wisp-guide.txt. Like the sections on garbage collection.
On occasion I have thought about something very similar, giving C++ an S-expression based syntax and then some Scheme macros or even functions to manipulate things. However finding errors in the C-code generated from the S-expressions would likely be hard, so I believe this pre-processor would have to contain a complete (!) validation of the input so that the C-compiler never barfs (just like the C-compiler always outputs valid assembly). This still doesn't solve the source-level debugger problem, but I could live with that, printf()-debugging FTW! 
I wrote [Horns](http://code.google.com/p/horns/) a while back to practice lex/yacc. The docs are based on the newLISP docs.
C? Why not Lisp? I found implementing Lisp in Lisp a thoroughly enlightening experience. Implementing READ and PRINT is just tedious and boring.
There are of course several levels here, one is to produce some garbage, another is at which level something like an undefined variable is flagged, the S-expression or the C-code level...
Nah, I'd say using flex/bison is more of a waste of time than not using Boehm GC. Of course, my point is not that this is a fact or something, is that it depends on the goal and the person. I'd definitely give it a try at writing your own memory management. It was one of the things that made me learn the most during my implementation, all the rest being very simple. You could try different approaches to tokenizing and parsing, too, such as ANTLR and PEGs. My silly implementation uses flex, but the parsing is done by hand, because it seemed like too much work to get it all set up for such simple cases. Not trying to convince you of anything, of course, just sharing a different view on the subject.
If you haven't seen it already, [lispy](http://norvig.com/lispy2.html) is a little lisp in just a couple dozen lines of Python. You could translate it into C, or as inspiration. 
Yeah, I started out looking at norvig's lisp.py, but the high-levelness was making translating into C harder.
Not at all. First, everything becomes pointers. Next, you intern all strings: struct symlist { const char* s; struct symlist* next; } struct symlist* symlist_head = NULL; const char* intern_string(const char* s) { struct symlist* p; for (p = symlist_head; p; p = p-&gt;next) if (strcmp(p, s) == 0) return p-&gt;s; p = malloc(sizeof(struct symlist)); p-&gt;next = head; s = p-&gt;s = strdup(s); head = p; return s; } And so forth. Just remember to leak memory like crazy, and check no errors. Then you only have half the code to write!
If all you want is that stuff, you can sit down and write it in a day using Bohem gc. At that cost, it's strictly a worthwhile exercise.
Based on the listed publisher it might just be a reprint which is what they specialize in. http://en.wikipedia.org/wiki/Dover_Publications
Thanks for pointing that out. I didn't realize it was Dover that is publishing the new version. Also, I just looked at the difference in page count between the 1989 edition and the new edition. The 1989 version has 600 pages, the new one has 608. This would seem to indicate that there isn't any new material -- other than a new preface or something.
I talked about `&amp;body` for passing a `progn` body, and the overall consensus in #lisp was "there's no reason to differentiate between `&amp;body` and `&amp;rest` whatsoever. The only utility in the differentiation is the difference in indenting." It came up because I was asking for `defstruct` style indenting without using `&amp;body` because, like you, I think `&amp;body` has a sort of semantic meaning attached to it (even though it doesn't according to the language specification). So, I suppose I agree, but a lot of voices (to my surprise) disagree and view them as interchangeable.
Perhaps my journey to Lisp-master status still has a long ways to go, but most instances where I've felt inclined to make a macro, I've eventually refactored down to a simple-ish defun. 
I wrote about it a bit in 2006: [Aha! moments in Common Lisp](https://groups.google.com/forum/?fromgroups#!topic/comp.lang.lisp/oSslA8mJdho). The thread has lots of interesting responses.
What I meant about writing a `defun` first was more like "write a function which produces code, then turn the `defun` into a macro." I do *not* mean "replace functions with macros". As a simple example: (defun generate-inc (x) `(prog1 ,x (setf ,x (1+ ,x)))) And then executing this function (generate-inc 'x) produces (PROG1 X (SETF X (1+ X))) So I've made a code generating function, and then I would take this and write a macro version, which is effectively calling this function at compile time.
Can't you just write the macro and use MACROEXPAND? (edit: or C-c C-m)
I understand; and most places where I've felt like I needed that, I ended up over-engineering. Given that, I fail to really see why that example is exemplary of the power of macros. Is abstracting that out to be generated at runtime *really* the most effective utilization of your tools and time?
Yes of course you can. The point of writing the function goes back to my original point though, that macros are just programs that make code. And that idea is encapsulated in creating the macro as a function which generates code at runtime instead of compile time.
I no longer do it. I used to when I made the realization. It was also helpful in this [recent blog post](http://symbo1ics.com/blog/?p=1352) about optimizing a certain boolean circuit. The blog post really is a better example than the above. The `generate-inc` function doesn't really do much to actually build up code. In the blog post, there are much less trivial examples.
No, no--WJ is the Clojure troll.
I'm on the French side on this: naturalize concepts, don't appropriate words. It's bad for programmers short term, but it's better for the culture and language long term.
I actually program in CL full time, for a living, but I still think the C.L. has some design shortcomings compared to Racket. There isn't anything wrong with, or even particularly strange, about preferring Racket to CL. I brought it up in this case because the OP seemed to use CL as synonymous with "Lisp," which is a common mistake for people new to the language family, and its important to point out that alternatives exist.
I mention them together because one can start programming in the elegant and simple world of Scheme, using Racket, and then move into doing real, or semi-real, things with the Racket runtime.
On occasion I have thought about something very similar, too. However, Implementing a C-like sub language in some Lisp implementation which generates corresponding C code will make your idea go further. I see several scheme implementations will generate C code as an intermediate language. ECL is this sort in CL implementations. But shamed that I haven't put any time on this. 
I came to CL from C++ and Perl, so I was used to iterative solutions for pretty much every problem. Finally understanding how *bloody powerful* recursion is was my biggest "Eureka!" moment in my journey, at least so far.
The craziest clock I've ever seen (screencast) - what other amazing things could you do with it? Other than it being super nice for educational purposes. This should be taught in elementary school.
This is the same as [this, submitted yesterday](http://www.reddit.com/r/lisp/comments/vmncr/slip_a_lisp_system_in_javascript_for_browsers/). The project has been renamed to "SLip".
I looked for it and couldn't find the darn link. sorry for the mis-re-post 
Why would you write `#'(lambda ...)`? Do you know what the LAMBDA macro does? Lambdas are just object and can be bound in the variable namespace like any other object. Also, are you doing [this](http://i0.kym-cdn.com/photos/images/original/000/112/479/trollexploitable2.png)?
Practical Common Lisp [says](http://www.gigamonkeys.com/book/functions.html): &gt;Most folks either always use #' before LAMBDA expressions in value positions or never do. In this book, I always use #'. I guess it makes the code more uniform?
Sure they are: (defvar foo (lambda (x y) (+ x y)) Guess which name space that's in?
Only porting the C code is not enough. There was an attempt to port it: http://repo.or.cz/w/sbcl/llvm.git/ Last commit 2 years ago. 
Mr Seibel should really write that next book.
Statistics for programmers? With the same author as PCL? I'd buy that. 
Ditto.
Take my advice with a grain of salt. I still know Perl much better than CL and I never really liked object oriented programming. There is probably a much better way than what immediately comes into my head. Here goes: Worst case you could always just use an existing slot to hold either lists of values or associative lists of properties and values to create the illusion of new slots within an existing slot, perhaps named newslots or on-the-fly or something. Seriously, I can't begin to tell you how many times I have used lists and hashes in Perl to solve issues just like this. CL is powerful enough that there is probably a better way, but until someone else tells us what it is you can get something up and running that way. You don't even have to use the built in CL hash unless your associative list starts needing dozens or more keys. There's probably some canonical way to handle adding slots on the fly, or creating derivitive classes at runtime or something. I would say change it to that later. Storing a list or a-list in one of the slots should have you up and running in time to store tonight's data. Edit: Not sure what language you're coming from so let me ask you to just remember that any variable can hold whatever you like, including a-lists of lists of a-lists of hashes of whatever.... and you should already know how to change any of those to add/remove stuff :)
Well, the data I'm using is all rather old, and there's nothing new coming in, so there's no urgency here. Better to get it right the first time. The program I'm writing takes dozens of well-sampled observations of cepheid variable stars, which fluctuate in brightness with extreme regularity (better than the best atomic clock iirc), scales the observations so that all of the stars overlap nicely, and fits a curve to them. After that's done, I can use the well-sampled light curve (called the template light curve), and predict the light curve of a very poorly sampled star (with as few as 1 or 2 data points) by scaling the template to it. For various reasons, I need to store all sorts of data about each star, including creating the template, storing the results of the template fitting, and testing how well it fits the star. My primary language is Python (although I'm liking lisp a lot more), and if I did this in Python, I probably would have made one big dictionary containing dictionaries for each star, containing dictionaries for each filter. Lisp is much better for the actual data analysis though.
Can you post an example snippet, to make it clearer? Also, do you intend to persist the data or recreate the object graph anew each time?
Ah. When I work in IT I'm usually doing "Production Support" i.e. fix it tonight so the customers get their data/reports/checks/whatever and do a well thought out implementation in the morning. I'll go ahead and give my best shot at a well-thought out layout: I think that since you know what you need lists of, making an official slot for each thing you're listing (luminosity, temperature, time of measurement) that storing those lists in the slots probably will be a reasonably canonical solution. You can then have other slots for the mean and average that would be calculated with a method. I'm thinking you really don't need to add slots for new measurements since the new data would fit nicely in the lists of luminosity and temperature measurements. You still might want to use a-lists to associate the time with the measurement, but other than that it sounds like luminosity-measurements and temperature-measurements should hold a-lists while luminosity-mean and luminosity-period could be either a slot calculated by the function you use to add measurements to the object, or could be member functions themselves that calculate the measurement on demand. Since the data is old you already know all the different types of data you have about the stars so you can certainly make a slot to hold each type of data. Anything you don't have for a particular star can be set to NIL. Fixed things like distance would logically be just one value, and measurements would be held in lists. Unless I'm really missing something I think even the pros would do something similar, but you can always hop on #list on chat.freenode.net and ask them. I know that channel seems to always have at least a few awake people on it.
Post the code somewhere(e.g. paste.lisp.org). From your description it's not very clear what you're trying to do.
I added a gist link in the original post.
I've added an overall blueprint of the object to the end of my original post. The goal of this project is to create a template which anybody can use to estimate the mean luminosity of a first-overtone cepheid variable star by simply putting in their few observed luminosities and associated phases. The phase is how far along in its period the star is, so for example, the hour hand on a clock is at phase 0.5 when it is 6 o'clock, and 0.75 at 9 o'clock. First-overtone means at a givent time at a certain distance from the center of the star, the gas below it is moving in one direction, and the gas above it is moving in the opposite direction (so part of it expands while the other contracts). This was already done previously on fundamental-mode cepheids, where the entire star is either expanding or contracting. You can read it [here](http://www.jstor.org/stable/10.1086/431434) if you're interested All the template is, is a table like [this](http://www.jstor.org/literatum/publisher/jstor/journals/content/publastrsocipaci/2005/pasp.2005.117.issue-834/431434/production/images/medium/tb3.gif) (this is the table for fundamental-mode cepheids), and a method for scaling it to new data. So things like the &lt;OBSERVED&gt; values, name, and position will persist (unless I get new data), while the &lt;FITTED&gt; values and mean-luminosity will be different each time it's run.
&gt; better than the best atomic clock iirc This is not related to programming, but I just can't let it pass. There is absolutely no way a Cepheid variable is going to have a period more stable than the best atomic clocks. You are thinking about pulsars.
Yeah you're right. Somehow I thought they both did, probably because I used to think cepheids and pulsars were the same thing. It's still really stable though. I said "iirc" because I figured somebody would end up telling me I was wrong.
err #lisp
see also https://github.com/angavrilov/cl-gpu
I'm interested in seeing what you come up with.
Looks cool. I've been waiting for Emacs to absorb the SubEthaEdit experience.
Rudel, the library that actually does the Emacs collaborative editing bit, has started with a SubEthaEdit backend. Looks like [Obby is the only thing really supported right now](http://rudel.sourceforge.net/backends.html), though.
comp.lang.c, comp.lang.c++, comp.lang.python, comp.lang.ruby, and comp.lang.javascript all show similar dropoffs in the past couple years. Have you considered that it's Usenet that people are dropping, not Lisp?
Lisp is more popular than ever before, if you're able to see above the clouds. I've never experienced more Lisp popularity than now -- having started to be a Lisp beginner in 2005. The Internets Know Nothing. Ask fresh programming freaks: Lisp is probably the most Wannabe Language out there nowadays.
awesome project.
My favorite lisp-flavored window manager (and what a wonderful thing that it's only one of many choices of lisp-flavored window manager).
In your example, I assume you mean assoc instead of acons. You can provide a test function, e.g. (assoc item alist :test #'equalp), see [HyperSpec](http://www.lispworks.com/documentation/HyperSpec/Body/f_assocc.htm)
Dumping functions is at best problematic: consider the case of two functions sharing lexical environment getting dumped into two different fasl files, say. To make that work right is reasonably hard.
If you're not familiar with the issue, google "lisp-1 vs lisp-2". Short version: it's easy to accidentally re-use a name that's used inside some macro in your own code, or to write a macro that could clobber someone else's names. This leads to unpredictable results and is difficult to debug. Since most global names refer to functions, they get their own namespace to cut down the risk of collisions. Whether this is a good idea might be a holy war. Scheme and Clojure provide different solutions to this problem: hygenic macros and namespace-qualified symbols, respectively.
Note that your code has the pattern: (if condition nil t) There's already a function for this: `not`. ;; Returns T if the alist contains the key (defun key-exists (key alist) (not (null (assoc key alist :test #'equalp))) ;; Returns T if the alist does not contain the key (defun key-exists-not (key alist) (not (key-exists key alist))) I, for one, believe the latter function is a bit unnecessary (look at the definition, and consider: is `(key-exists-not foo bar)` that much better than `(not (key-exists foo bar))`? You'd probably not even use the latter construct, since instead of (when (not (key-exist foo bar)) (princ "No Maches")) you should write (unless (key-exists foo bar) (princ "No Maches")) . And your first function is, as you've been told in another comment, transforming a generalized boolean (nil/non-nil) into a "pure" boolean. For most, if not all, cases, you can simply make the first function ;; Returns a generalized boolean indicating whether the alist contains the key (defun key-exists (key alist) (assoc key alist :test #'equalp)) This property allows you to write code in a slightly cleaner (and incidentally more optimized) way: instead of (if (key-exists foo bar) (princ (assoc foo bar)) (princ "No element matches.")) vs. (let (v (assoc foo bar)) (if v (princ v) (princ "No element matches.")))
Eh, another "critique" of common lisp by someone that has very little to no experience actually programming in CL. Yay! 
clueless
&gt;This chapter is where my gripes about the language start. To represent the nodes, author uses a list of lists. Each nested item represents a node, with the items in cells corresponding the attributes of a node. Edges are represented in a bit more complicated manner - with a list of lists, which again contain some more lists. The problem gets worse during processing where some of the functions use maplist on edges' list and therefore have to deal with a nested structure of depth 4. Ok, am I missing something here? Is this a legitimate complaint about a language that is used to process lists? In fact, isn't *Lisp* an abbreviation of *List Processing* ?
Used to be. I believe these days its just Lisp, without a background meaning. It's more about the family, too, so by that meaning Clojure is "a" Lisp, too.
It is a legitimate complaint about the book. I've read it (I didn't learn Lisp from it, but I did learn from it), and it makes reading some code much harder. The problem is not that *lists* are used, but that *accessor functions* are not created, leaving `caddr`, `cadr`, and the like as the ways to get data. It becomes very complicated if you have a function as follows: (defun print-all-users (user-lst) (when user-lst (format t "~A: age: ~A, height: ~A" (caar user-lst) (cadar user-lst) (caddar user-lst)) (print-all-users (cdr user-lst)))) What's the bug here? Well, obviously a `user` is a list where the *second* element is the height, and the *third* is the age. This style is pretty hard to read, and error-prone. Why not just write a `user-name` function that is `cadar`? You don't have to remember the structure of the data, and you can easily scan your code and find your bug.
I'm pretty sure I sing the chorus to this damn [song](http://www.youtube.com/watch?v=HM1Zb3xmvMc&amp;feature=player_detailpage#t=108s) every day. I loved this book personally.
It doesn't even seem like he's read any code, or historical documents.
[cl-ev](https://github.com/sbryant/cl-ev) perhaps?
If you're looking for higher-level wrappers of non-blocking I/O and event loops, you might be interested in [Hinge](https://github.com/sshirokov/hinge) and [Conserv](https://github.com/sykopomp/conserv). I don't have personal experience with either but the authors are competent folks and the libraries are in quicklisp last I checked.
perhaps they return, reassured, to their less sophisticated technical culture of choice
True, that example wasn't from Land of Lisp, and I should have made that more clear. But there were some examples (I don't have the book in front of me, but I'll see if I can come up with some tonight.) where I found the code hard to read because I had to remember what was where in the list, where simply having (defun get-name (person) (car person)) (defun get-age (person) (cadr person)) would have helped immensely. That aside, I do think it's an awesome book. I am especially impressed by the chapter on laziness. It was also cool to talk to you at a DC Y Combinator meetup.
 rudel on Marmalade is v. 0.3, SF is 0.2-4. Just confirming that I should go with the SF version if I want to participate. *edit* &gt; Setting up Rudel is easy so long as you get the correct version (the one from SourceForge). Ok, got it. 
In German or English? :)
It is live as for now. * youtube live stream : https://www.youtube.com/watch?v=yEWPBOoe9l4&amp;feature=plcp&amp;newstate=e79da435b27c589988f02e098d9eead0 * contest subject : http://icfpcontest2012.wordpress.com/task/
It was 1985 &amp; he was talking to a science/engineering university. Of course he's going to be talking about Lisp.
I hit that downvote button so hard I think I broke it
Why? Do you know what Lisp macros are?
Yes. I also know that this isn't /r/adviceanimals
This also isn't the [den of seriousness](http://www.reddit.com/r/lisp/comments/w8bps/the_axisof_eval/) that you imagine.
We all know what macros are. 
Your mass mind-reading ability is being squandered on reddit comments. You could provide vital information to government intelligence, for instance, possibly saving thousands of lives. For the good of humanity, get off reddit and use your ability more constructively!
Um...I think you are in the wrong place...
You are in the wrong place, this reddit is about the Programming Language "Lisp", not the speech impediment.
19.7.2012 ab 19:00 Uhr im Gebäude der innoQ, Krischerstraße 100, 40789 Monheim 
Things went fairly well with regards to the tools. In the end we put actually submitted something, but it won't win any awards. In fact it will likely be kicked out early as that I screwed up and our submission actually never submits an answer unless it runs out of time (i.e. it will not submit a solution that it deems as good enough to submit, but will submit a solution if it hits the time limit and is forced to submit the best solution found so far). I got caught up in figuring out how to silence the output from SBCL and correctly handle the SIGINT signal that informed us of the timeout. This is pretty stupid and basically my fault... :( It isn't like we were going to win with our submission even if I got it right, we never adapted our heuristics to some of the later aspects of the competition anyway. The tools worked the way they were designed for the most part and development with this setup is, by far, the best remote development solution for *rapid development* I have experienced. That said, I haven't completely explored the possibilities here. One thing that sucked was that the Youtube broadcast was of a substantially lower resolution than the hangout, so what we were able to see was basically illegible to any that attempted to view the broadcast.
See also Loper OS
Which is why I refuse to use it. I can't wait until LoperOS 0.0 comes out, with EtaLisp (HLisp?)
I got Clojure working on the Pi but due to limitations of the JVM, it doesn't support things like Graphics2D. Code still executes; you just don't see any graphics displayed. Text mode stuff works fine though.
When can we get more projects into the test grid? Are there any guide lines to making a proper test suite? I have 6 different FOSS Lisps installed in order to test on, but I sure as heck am not going to test against different versions of each, on different operating systems, at various combinations of versions of dependency or dependent libraries, or proprietary implementations. I would very much like test grid to go public.
it is, mostly: [https://github.com/cl-test-grid/cl-test-grid](https://github.com/cl-test-grid/cl-test-grid)
I found [Interpreting Lisp](http://civilized.com/getlisp.html) to be an interesting read. Beware though, I don't think the accompanying code compiles easily if I remember correctly.
This came up at the meeting. One "loophole" was that there was a license with MIT such that anyone with some campus affiliation was a legal user. Apparently the current rights holder intends to make it free to all but this hasn't happened yet.
CCL is actually commercial too.
In what way is it commercial? It's licensed under the LLGLP. Clozure Associates provides commercial support for the implementation, but implementation is 'free'.
Native threading wise, CCL seems pretty solid on OS X and Windows. I assume it is pretty good on Linux too.
It appears that you're confusing "commercial" with "proprietary": http://www.gnu.org/philosophy/categories.html#commercialSoftware
Only if you're going to be pedantic like rms. Whatever.
No, if I'm not going to confuse people.
I have been steeped in lisp the past couple of weeks and wanted to have a little fun. Would love to hear more captions that make sense **and** sound good!
Have you read the link I provided? Commercial doesn't mean non-free.
I've read the GNU philosophy more than once in my life. Have you read what Clozure says about CCL? CCL is free, both as in speech and as in beer, per the LGPL licensing of it. Paid support is not free. Paid support is the commercial offering here, not CCL, the software. You appear to be the confused one here.
It's not GNU philosophy, it's just a little section describing the exact same situation. Clozure Associates develops CCL, they are able to do that because of the money received for support and for adding features to CCL. Their main business is done through CCL. The initial statement was "hey, look, CCL was able to get threads before Allegro or Lispworks, and yet it's free!". But the thing is, that CCL was developed in a commercial fashion, the developers received money for doing it. So, there's no difference between CCL and Lispworks or Allegro in that regard.
The link you provided is actually the GNU philosophy. Check the URL. CCL is free. Their consulting and support is the commercial arm of the business. CCL is a means to an end, not the commercial product itself. The OP meant CCL, an implementation released for free (both beer and speech), got SMP before Lispworks and Allegro, non-free (also both beer and speech) implementations, and the OP is factually accurate. I get paid to develop software, and as part of that, I contribute to open source. That doesn't make the open source software I've contributed to commercial.
Well, no, I mean, we're all aware here that in this context Lisp is just a nifty language, right?
Religion for geeks! Hah imagine that!
Oh my God, someone apart from me has actually seen, let alone read, my blog :O Thanks for sharing, lispm!
s/de/en/ in url
Flying Frog is a long-standing troll. Please do not feed.
Reading through your old tweets. There's some really great stuff in here. Thank you for sharing.
I don't know about "old", I started my twitter account 6 days ago on July 20 (hence "already" ~70 tweets). Thank you for the encouragements!
I've now responded to issues raised both here and in the comments on the previous post. See http://yeel.es/2012/07/27/the-land-of-raspberry-lisp-part-0-5.html Cheers!
Perhaps it may be interesting to take a look at hexstream's follow list. Presumably, there will be people interested in/tweeting about CL related issues.
His point, as I understand it, is that Lisp fostered a mentality of putting objects into boxes such that you had to pay a cost to manually take them out and check that they had the right type every time you use them, instead of using static analysis up front that eliminates the need for such boxing because it guarantees that your code will always get its data in the form that it expects thus making run-time checks unnecessary.
Unfortunately he makes this assumptions without knowing any insides of a Lisp compiler. The purpose of his postings is to get his business going. He is not shy to use questionable marketing tactics like abusing Wikipedia, trolling Usenet, etc.
Yeah, it's just my preference. Though I would just share it so you're aware of it. I check Twitter two or three times per day and only follow people that post less than a couple of times per day. Your feed would drown out all others. 
Ohhh, you're looking for the Twitter Creek, five miles east of the Stream. :)
Well, next up would be [Practical Common Lisp](http://www.gigamonkeys.com/book/). You'll also want to find [Quicklisp](http://www.quicklisp.org/) (perhaps that's covered in *Land of Lisp*, I haven't read it yet) and [SLIME](http://common-lisp.net/project/slime/) if you're using Emacs. And if you're not, you probably should be.
I don't believe quicklisp was covered. Ill definitely check those out. Thank you!
Because I'm on my phone (and therefore far too lazy to google) do you happen to know of an awesome quick-start/cheat-sheet thing for emacs? :) As I'm sure mentioning i know vim is going to be a huge sin right now... EDIT: if i had just read some more in Practical Common Lisp id have learned theres a tutorial built in. Go me! I should work on my laziness
I second Practical Common Lisp, and may I recommend [ANSI Common Lisp](http://paulgraham.com/acl.html) and [The Little Schemer](http://www.amazon.com/The-Little-Schemer-4th-Edition/dp/0262560992) (I know its scheme, but when I did the exercises I did them in LISP).
&gt; do you happen to know of an awesome quick-start/cheat-sheet thing for emacs? :) [Several](http://www.rgrjr.com/emacs/emacs_cheat.html) exist, [actually](http://refcards.com/docs/gildeas/gnu-emacs/emacs-refcard-a4.pdf) [PDF warning]. &gt; As I'm sure mentioning i know vim is going to be a huge sin right now... No, no. We don't judge people willing to take the first steps toward recovery. Have you learned about [Evil](http://www.emacswiki.org/emacs/Evil) to help make the transition smoother?
Reading little schemer now. Very interesting style, really enjoying it +and+ learning.
I'll second the SICP recommendation.
Ill have to check those out Pretty sure i now how over 2,000 pages of lisp to read. Freakin sweet Thank you!
There's more accurate vim emulation out now: evil-mode http://emacswiki.org/emacs/Evil For me it works *almost* exactly like vim (dot repeat doesn't work quite right sometimes, though they may have fixed that already).
I certainly haven't read the entire thing cover to cover (yet), but Norvig really knows Common Lisp well and even working through the beginning will get you well on your way to being a better lisper.
Doesn't look like anyone's mentioned [Common Lisp: A Gentle Introduction...](http://www.cs.cmu.edu/~dst/LispBook/) yet. Highly recommend.
The main things, from my perspective, would be excellent support for editing Lisp code (especially with addons like paredit) and interactive development using SLIME. For the latter, basically it means that Emacs becomes a front end to your Lisp interpreter so you can edit and change stuff "live", use the interpreter command line from an Emacs buffer, etc. And of course Emacs is itself a Lisp environment, a somewhat idiosyncratic one to be sure, but customizing it is good practice for your Lisp skills :)
Yes... SLIME works with a wide variety of interpreters, and it's pretty unlikely that you will find an up to date Lisp or Scheme environment that someone hasn't made a connector for. And on the editing side, stuff like paredit tends not to care what sort of Lispy language you're using as long as it follows the general s-expression syntax. There are also interpreter-specific modes for a few specific Scheme environments like Racket and Chicken.
You can stay on Vim if you want, see my answer elsewhere in this thread: http://www.reddit.com/r/lisp/comments/x9k06/i_want_to_learn_more_lisp/c5kn1lp Although I did switch from Vim to Emacs many years ago and do not regret it.
Apparently I chose the perfect day to ask about this, awesome! Thanks!
Visit #lisp on Freenode IRC. Also, I'd recommend using SBCL.
So don't just blindly read them all, got it haha. I'll definitely see if some have a PDF though, so I can possibly save them for later. Thanks for the suggestion!
Note that in the comments Fogus says the goal of the post is to highlight lesser known books, so you're on the right track:)
This looks pretty similar to how laziness is done in Haskell, sequences of thunks (promises of unevaluated data roughly equivalent to closures). I honestly think a language should default to strict, but have the ability to provide lazy sequences like this, rather than the other way around. Trying to get Haskell to behave predictably is like getting your organs dug out by a hungry cat.
And for the love of your pinky fingers, you might think about making caps lock a control key (kind of like vim users often switch caps lock with escape). I found that after a year or two of heavy Emacs use on a keyboard without a right control key (laptop) my left pinky finger went numb. Having a caps-lock control fixed that and is in many ways more convenient.
He's explicitly mentioning macros alleviate some (but not all) of the issues, so clearly he's not assuming that.
Well I remembered that the there was obvious objection which wasn't answered in the post. Right, it wasn't the bare assumption of no macros. Skimming it again, I think it was his comment that macros can't solve lazy composition, shown in the `any` example. He uses `or . map`, but that's the wrong thing -- of course you can't just take two strict functions and magically compose them into a lazy function. The obvious answer is a macro that expands `or l. map` to `lor . lmap`. There's not general way to transform a lazy function into a strict function or vice versa, otherwise we'd just have `foldl' = strictify foldl`. I guess he's telling us the disadvantage of explicitly writing lazy functions, but `foldl'` is explicitly written, the other side of the coin.
[Xah Lee's Elisp page](http://ergoemacs.org/emacs/elisp.html) is a great resource.
Thanks. I've reviewed this before but not specifically for elisp. Will check it again.
&gt; Getting good performance from GHC largely revolves around disabling laziness -- just look at the shootout programs That's not really true. Laziness is responsible for lots of performance *benefits*. The shootout actually banned lazy programs when they performed *too well*, because it demanded all the unnecessary work be forced despite not being required by the result. Haskell performed too well --&gt; shootout changed the rules to disallow it. &gt; That laziness is not a binary property is exactly the issue. We have a choice of which side to start from. Whenever you make a seemingly innocuous change to a Haskell program and then find that something is suddenly screwy, you are seeing the consequence of starting from the laziness side Strictness is symmetric from this regard. Making a lazy program strict can also add space leaks and performance problems. However, a lazy program will *always* have better termination properties. People used to strict semantics are surprised by lazy programs when they expect them to have their familiar semantics. People used to lazy semantics would be surprised by the strict semantics "going screwy". &gt; A strict language with optional laziness, which includes lazy versions of common functions, seems the best compromise to me That would mean you don't get to have lazy variants of all libraries, which means you won't have the nice compositions augustuss described as his last point. When I program Haskell (which is my main language now) I don't actually have much performance problems. When I do, they're never because of laziness. I don't have a single strictness annotation in my project. It's easier to sprinkle strictness when needed than to add laziness when needed. Only rarely does adding strictness from outside a function is a problem, which is why functions like "foldl'" are very rare.
I assumed it was an alias. In fact I still do so assume. it's a good pisstake of clojure...
last commit 8 months,looks pretty dead.
It is [not an alias](http://web.archive.org/web/20110723050339/http://www.jfm3.org/). The [author](/user/jfm3) passed away [last year](http://www.legacy.com/obituaries/mycentraljersey/obituary.aspx?n=joseph-f-miklojcik&amp;pid=151581037#fbLoggedOut).
After you have read Practical Common Lisp and SICP I suggest [The Art of the Metaobject Protocol](http://www.amazon.com/The-Metaobject-Protocol-Gregor-Kiczales/dp/0262610744) then [Paradigms of Artificial Intelligence Programming](http://norvig.com/paip.html). If you make it through those, you will be very well prepared for solving industrial problems with Lisp. 
Don't feel bad. The only thing that makes me sad is how quickly this was downvoted into invisibility. He was alive again for a little while, here. He definitely died too young.
"Perform the intended workload" -- is basically saying that the laziness made some computations (clearly ones not needed for the result) not occur. This happens in practice all the time -- and in that sense laziness often saves work in real programs. Of course it is possible to do so manually, but in many cases it's not obvious that the work can be saved. &gt; Except when it doesn't. Come on, don't tell me you've never changed a function and blew the stack as a result. Sure, laziness can cause space leaks, on the stack as well. But from an evaluation viewpoint -- lazy evaluation will always terminate if any evaluation will. That is a remark more about theory than practice, but it does translate into practice too -- it is the basis for the extra composability. &gt; This is not about newbie problems. Let's assume experts all around. Significant issues exist even for them. I disagree. Experts who are used to lazy evaluation are not surprised by the performance of their algorithms. There is an issue with stack traces becoming more difficult with laziness, but not with performance predictability. &gt; Making all functions lazy just to solve lazy composition sounds crazy to me In practice, Haskell doesn't do that. It has a strictness analyzer which makes functions which are strict anyway be eager. &gt; as it's seldom needed in the first place Disagreed -- needs become visible when they become practical to solve. Haskell code uses composition which wouldn't work in a strict language *all the time*. &gt; Well we'll have to agree to disagree about that. A place to start is [2] Robert Harper's post; I disagree with his post, and find augustuss's response to his post to cover his points quite well. &gt; To place this discussion on more pragmatic grounds, I point to the history of darcs, which had performance issues that persisted for years They were not because of laziness -- but because they are trying to solve a very difficult problem, much more difficult than the other dvcs's (tracking all cherry-picks). The problem they are trying to solve is algorithmically more difficult and has pathological cases. &gt; It's very hard to pinpoint and understand problems when they happen in Haskell I mainly code in Haskell, and except for the lack of stack traces, I disagree. Laziness rarely causes me any trouble, and when it did, the excellent profiling support quickly solved the issues. &gt; Understanding the global behavior of a Haskell program remains difficult even for experts. That is only true insofar as it is true for non-trivial strict programs with higher-order functions (callbacks).
Any time I get frustrated with my tiny corner of Reddit, I should remember Usenet.
If we actually look at the history of the shootout, it doesn't fit the rosy picture of your narrative. We are simply talking about bugs in artificial benchmarking programs. In the real world, if something didn't get computed when expected, and down the line a deleterious slowdown happens because of it, I could equally argue that laziness caused bugginess where strictness did not. There is always a flip side. That is why I keep stressing that there's no clear winner here, it's just a matter of which end you start from, with pros and cons contained in either choice. Another point I wish to address is that you still appear to be generally framing this as only newbies encounter problems. It just isn't true -- really -- just put some real time into developing something real-world and highly non-trivial in Haskell. I think you are trying to paint me as a Haskell newbie. I am not in the least. The problem I most frequently encounter when talking to other Haskellers is that they draw on their experience with fairly simple programs, or at least programs which are not tied to the complexities encountered when interacting with disparate systems in practice. Haskell is my first choice for writing stuff like theorem provers. For situations which aren't as mathematical, where we must deal with hairiness that lies outside of our control, Haskell doesn't fare as well.
&gt; just put some real time into developing something real-world and highly non-trivial in Haskell I am working on [Bottle](http://github.com/Peaker/bottle), a highly non-trivial project. We have yet to encounter any laziness-related problem. &gt; For situations which aren't as mathematical, where we must deal with hairiness that lies outside of our control, Haskell doesn't fare as well. Bottle does database storage, a GUI framework via OpenGL, lots of complex logic (type inference as you edit, automatic sugaring of the database representation), and revision control. Haskell has made the development of Bottle really really great -- performance is generally great, and our only performance problems are of truly algorithmic/architectural nature. We've not yet encountered a single space leak from lazy evaluation. If we did, of course, we'd find it in a heartbeat with the [excellent profiling](http://book.realworldhaskell.org/read/profiling-and-optimization.html).
I'm not quite sure what you mean by "minimizing" Ax=b, since this is an equation, and hence my answer may not be what you are looking for, but here goes: If what you mean to do, is to find an x that minimizes f(x) := ||Ax - b||, where || . || denotes the euclidian distance (i.e. f(x) measures the length of a straight line going from the point Ax to the point b), what you are looking for may be the so called Moore-Penrose Pseudoinverse [wikipedia-link](http://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_pseudoinverse). note: the pseudoinverse is cool and all (and robust to rounding-errors if implemented well), but if you are not that interested in understanding a lot of theory, and just want minimal approximate solutions of linear problems, there probably are less general and easier to implement algorithms for least-square approximation out there. hope that helps. Edit: I just reread your post. Actually (A^T \* A)^-1 \* A^T *is* the pseudoinverse. Computing it this way is however not always computationally efficient (Since inverting large matricees is computationally problematic), and can be prone to rounding-errors depending on the matrix A. If you have access to a library that can do singular value decompositions, computing the pseudoinverse by means of the SVD is probably advisable. I think [GSSL](http://common-lisp.net/project/gsll/) should be able to do singular value decompositions. Edit2: A further problem with (A^T \* A)^-1 \* A^T is that (A^T \* A)^-1 only exists when A has full rank (I think). 
KvanteKat is right, use [pseudoinverse or SVD](http://news.ycombinator.com/item?id=1062613). If you can [avoid computing the inverse, even better](http://www.johndcook.com/blog/2010/01/19/dont-invert-that-matrix/). 
Me too! Sadly I also have not yet got anything to show...
Does it matter? Either way it's funny.
Stating the obvious here, but paredit. Also, I don't use the REPL too much but slime-scratch instead. I have slime selector bound to C-c g do I can jump between relevant buffers easily.
avoid the 'protocol version mismatch' message by ignoring it: (eval-after-load 'slime '(setq slime-protocol-version 'ignore))
also, if you use BS/IBS, show the repl: (setq bs-must-always-show-regexp "repl")
Use the MIT Lispm source code instead. That's open source.
I configured slime-banner to display the hostname and port the swank server is listening on. Really useful when using several REPL with remote swank servers.
I’d like to see a comparison with [*Lisp](http://en.wikipedia.org/wiki/*Lisp). Given that it’s for a different architecture, and comes after almost 30 years of lessons learned about implementing parallelism, I’m sure there are some interesting differences.
Oh, we do it all the time: car, cdr, cadar, caddr, cddr... 
[Adjusting my chunky, scotch-taped glasses.] Indeed, and Steele and Sussman invented Scheme specifically to investigate the actor model, and found a useful relationship between it and the λ-calculus. And I said *implementing* parallelism precisely because new fundamental ideas have been rare.
Sure and I love that Brad Parker has done that work but it's really not the same thing, is it? The CADR sources circa 1980 vs Symbolics sources circa 2000. I'm glad that you know the current rights holder and that he's a nice guy but it seems to me he's sitting on a crowning achievement of the lisp community for not much profit. I defer to your experience /and/ his legal rights but it's hard (for me) to understand why this stuff didn't wind up getting open sourced back in 2006. Also, a side note, but the opengenera sources have been passed around via torrents for years now and there's an emulator for them also written by Brad Parker. I appreciate that the rights holder hasn't taken action against that. I guess I don't care that it's not open source really, I just wish it had a more permissive license based upon commercial vs non-commercial usage. If I knew the rights holder personally, I'd probably be more comfortable too as I would know his intentions. Which, I grant, are none of my business.
I enabled paredit at the slime repl, and edited slime-repl-history-pattern to ignore trailing close parens and white space, so that M-p, M-n still work appropriately. I changed the slime repl prompt (in slime-repl-insert-prompt) to (downcase (format ";(in-package %s)\n" (slime-lisp-package-prompt-string))) The combination of the prompt with a newline and paredit makes it nicer to cut and paste in and out of the repl.
Symbolics mostly stopped writing code around 1992, IIRC. There is not much code written later and the amount of code written then was already slowing down. No Unicode, no multicore, no multimedia, no security, many applications have ancient UIs, a complex mix of old and slightly newer code. The torrent out there is the Alpha distribution of Open Genera - that's not the complete sources for Open Genera. The Symbolics code is a pile of complex stuff. The chance of being open sourced is currently zero. It was not open sourced, because former owner left behind some debt. The executor wanted to make some money with what was left. So it cost money to get it out of the hands of the executor. Most people anyway would be happier hacking with one of the great open source Lisps. There is really no excuse not to use them. They are more accessible, more modern, support current systems and more. Alternatively there are wonderful commercial Lisps which are maintained by active companies. Like Allegro CL and LispWorks. 
Oh, I'll keep up my SBCL+CCL hacking. Just hope the rest survives for history. I'm now looking at Brad Parker's CADR stuff on your advice. It looks good. And thanks for shedding some light on the rightsholder.
I like to make my own [presentation](http://common-lisp.net/project/slime/doc/html/Presentations.html#Presentations) commands for mundane things. e.g. CL-USER&gt; (defmethod swank::menu-choices-for-presentation ((ob fixnum)) (list (list "English" (lambda (choice object id) (format t "~r~%" object))))) #&lt;STANDARD-METHOD SWANK::MENU-CHOICES-FOR-PRESENTATION (FIXNUM)&gt; CL-USER&gt; 42 42 CL-USER&gt; Right-click on the red 42, then click on English. 
No, I'm serious. But you would be wise to treat it as a joke, like every other vaporware.
I am not sure a one-man band is enough for a project of such magnitude, but good luck anyway
[Somewhat relevant](http://web.cs.wpi.edu/~jshutt/kernel.html).
Not that I know. I'd post it in a Kernel subreddit, but I don't know any. Try /r/programming, maybe they can appreciate it too, first-class macros are not something you see everyday.
Thanks - done!
If you are interested in first class macros or fexprs, you can join us at the [klisp google group](https://groups.google.com/forum/?fromgroups#!forum/klisp) (shameless plug). It serves both as a ml for [klisp](http://klisp.org) (a more or less complete Kernel interpreter in c99) but also to discuss implementation strategies and optimizations in the face of fexprs and first class environments.
Unless we wipe ourselves out first.... Never forget that option.
You are right. And *coerce* is something I'll have to remember. Thanks for that.
As a student of linguistics, this made my day.
He asks "Does the syntax of your spoken language affect which programming languages you like?" and then dosen't answer it.
But you got the parens wrong for the bottom expression, while you got them right for the top one. Clearly it wasn't obvious to you that the bottom one was wrong. *Edit: Oh come on. You fixed the parens without noting the change and downvoted me.*
Eh, this argument seems to come up a lot, but my memory of learning (elementary) algebra at school (about age 6?) is that we were pretty much taught 'the sum of/add $X and $Y', 'subtract $Y from $X', 'multiply $X by $Y' style language first, the infix-reinforcing '$X plus $Y', '$X minus $Y', '$X times $Y' came a couple of years later as we headed towards more advanced subjects than the 4 basic operators. I'd argue that 'add 5 and 3' is very much a language analog of (+ 5 3) and thus prefix is just as natural as infix. Postfix (although in many ways my preferred syntax) is pretty unnatural though.
That still doesn't solve the underlying problem. If you want to understand what + operates on, you still have to scan the whole expression, with infix syntax you only have to scan half the expression. One can of course fix the problem with some newlines, but then you are using more vertical space: (+ 234 (* (+ 5 3) (+ 2 1))) 
Since the OP neglected to provide *any* data, I will, though a single anecdote is not much, I admit. I started with Logo, then VB and HP48. That's last one is the important bit. The HP48 is postfix, and while it took some getting used to, my brain was malleable and motivated (that is, bored in math class). When I got to Lisp, it reminded me of programming that HP48, so it didn't feel funny or difficult. Well, no more difficult than learning to use the `==` in C conditionals. Now *that* is a backwards and difficult language ;-) but I digress. So Lisp is significantly hard only because its new syntax, and many programmers have seen woefully few variations in programming language syntax.
Python also has a standard implementation, and a BDFL. GLS and co. have tried their hardest to not become BDFLs. Plus, CL was standardized around the time of the AI winter, and it was designed as a compromise between NIL, Symbolics, MIT and co--designed with multiple implementations in mind. We used to have really cool IDEs--in fact, it'd be the entire environment, from the hardware up--called Lisp Machines, most famously the Symbolics line.
Look up Practical Common Lisp. Read it, and read it well.Also, look up cl-launch. 
There is Lispworks http://www.lispworks.com/products/lispworks.html oh, I guess Allegro has an IDE, too http://www.franz.com/products/allegro-common-lisp/acl_ide.lhtml . Personally, I use Vim with Slimv, which is basically Slime for Vim.
You can use any text editor to save your script and sbcl or clisp will gladly interpret it for you. If you just want to learn the syntax of CL, don't worry about types like int and double, let Lisp worry about that. You can use integer or real number literals and variables don't need type declarations or annotations. 
Are you aiming to learn Common Lisp specifically, or is this more of a conceptual exercise in learning to think functionally/recursively/in macros/etc.? Because if it's the latter, I'd suggest angling toward Scheme so you can use [Racket](http://racket-lang.org/) -- it comes with its own IDE which should help eliminate a lot of those "how do I run this" and "where the heck is the documentation" sort of issues, and has enough libraries to make it very practical for real work as well.
:-(
Guy L. Steele.
Gerald J. Sussman, Guy L. Steele, any SBCL dev. 
Rich Hickey
First, emacs/SLIME IS the nice free IDE. It's been customized and refined for many years to be good for professional programmers in Common Lisp. Second. You might find http://mclide.com/ of use. Third. There are other SLIME modes for other systems, e.g., vi. Fourth. Lispworks and Allegro have IDEs. I don't like the IDE as much as Emacs/SLIME inasmuch as I've used them. Fifth. Gentle Introduction to Symbolic Computation is probably what you are looking for if PCL isn't cutting it. HTH.
Thanks, I'm working on it now. Upvote for you.
unless you are just trolling, know that pg is a somewhat controversial figure in the lisp world
So: (+ 1 (* 2 3) 234) or whatever. Edit: as you pointed out. Yes, it uses more vertical space, but against that you *can* say (+ a b c)
im new, have heard nothing but adulation from books and literature, can you elaborate?
I doubt Paul Graham would ever agree to do an AMA on Reddit. One of his reasons for creating Hacker News is that he was disappointed with the Reddit community of the time and wanted to create a smaller one that was more resistant to Eternal September. He speaks of this in his essays. Redditors struck back, perhaps due to the slight to the community, or perhaps because folks were less than impressed by his "Hundred Year Language". Either way, pg stopped posting here 4 years ago, and I don't imagine he's keen to return.
his book "On Lisp" is a respected text on lisp macros. He is also an important figure in the startup scene with ycombinator, which, if I am not mistaken, is where reddit itself comes from. However, he is usually criticised by lispers because: 1) he seems not to like *Common* Lisp too much. His book "ANSI Common Lisp", while it's a clear explanation, has a very personal point of view on the language. For example, CLOS and the condition system are almost ignored. [Personally I liked reading the book, but it just teaches pg's idea of lisp. For a more complete and idiomatic tratment of CL, see "Practical Common Lisp" by Seibel instead]. 2) he promised for years a new Lisp ("arc") fueling enormous expectations. It stayed in the top ranks of vaporware for a lot of time, and when it was finally released, many lispers filed it in the "nothing special" category (or worse). Some time has passed now, and it seems that arc was not very successful. 3) generally speaking, pg has a certain attitude, which could be said not very community-oriented, that many don't like too much.
Symbolics Genera. But perhaps it's blasphemy to call it an IDE
Perhaps, I thought there might be people here interested as well, after all he has used other Lisps (and even created one) before creating Clojure.
I guess it might also be my bias against Clojure, which is partially because of people like WJ
Also, I can't believe no one has mentioned Zach Beane, creator of [QuickLisp](http://www.quicklisp.org/).
Yes, him.
Also, if you don't like emacs you won't like Genera.
The thing is how much code is taken up by long mathematical operations? It's a minor concern, really, unless you're doing a large amount of numerical computations. I believe there's code for building a paren-less infix reader in *PAIP*.
There's more to it than that (and it's not only WJ, it's people *like* WJ who rob us of any respect, but that's another thing). Some of Clojure's decisions feel a bit too funcpurist for my tastes (at least, in a Lisp--I don't mind an attitude towards functional purism in a language that doesn't claim to be a Lisp). I guess I tend to see some more common ground in [Scala's claim to be "postfunctional"](http://www.scala-lang.org/node/4960).
It'd be cool if Emacs/Slime had a ASDF system project broswer and cross-system refactoring tools that also updated the live code in REPL. That'd make working on large projects much more manageable. I imagine one could cook something up in Emacs, but who writing CL is hacking on an industrial scale code-base and not using a proprietary CL environment?
Have you heard of Kawa Scheme?
&gt; I'm not the world's biggest Clojure fan, but it beats the pants off ABCL as a useful Lisp on the JVM. Why? I don't deal with the JVM much, but I tried ABCL a few times found that everything just worked. Developing for the JVM with slime is pretty neat. I didn't try Java interop -- is there some bug with it, and if so has it been reported?
I've heard of it, but I didn't give it a super close look. Maybe I should take a second glance. Though mind you, we already have a sizeable chunk of Clojure code that works just fine and I don't think I'd want to hand translate it Scheme.
Hadoop has Java bindings (is, indeed, written in Java I think) so this should be easy in Clojure. Edit: I am a fool and misparsed the question, which is about CL. I don't know the answer in that case, but I would hope Hadoop has bindings to C, and so it should be possible to do things in an implementation with a C FFI?
There are Mongo-DB bindings and Cassandra bindings and Redis bindings and Tokyo Cabinet bindings and a variety of Couch DB bindings: http://www.cliki.net/StructuredStorage
All it didn't have for CLOS when I was looking for it was CLOS implemented via the MOP. Which I'm glad to see it does now. I'll definitely give it consideration when our next project rolls around.
It is easy to use CL w/ http://hadoop.apache.org/mapreduce/docs/current/streaming.html
Has anyone used the Windows port for anything "serious"? Just wondering about speed, stability, etc. on that platform as I'm forced to use it for work. Currently I use Gambit Scheme, but thought SBCL is so well regarded that I wouldn't mind giving it a whirl. Last time I tried it (a while ago) I wasn't so comfortable.
Why do you say that?
Based on my (probably outdated) knowledge about SBCL not really having working threading on Windows.
Hi , I need some CL lib to query Hadoop, or using a CL base Hadoop like mapreduce big data storage. Do you know any ?
These three are not the same. TokyoCabinet, by its own admission, is a "dbm" clone. At best, a commercial-license friendly BerkeleyDB. Redis is hardly "big data". It's a glorified memcached with a few more data-structures. For one, it's in-memory. Of these three MongoDB comes closest. At least it has a query *language* (Redis has commands, TC doesn't .. TokyoTyrant has something rudimentary) but I wouldn't call MongoDB "big data", it's a document store with a json API .. great innovation for the know-nothing hipster-coder, useless to anyone else. 
What is the difference between "data" and "big data" in your opinion? A cursory look tells me it's the "big" part. If so, define "big". Data is defined across several axes and engineering tradeoffs have to be made maximizing one against others. Data is volume, distribution, durability, access times, security, versioning, auditing, concurrent use, atomic updates, query speed, storage cost, etc. I'm afraid you will have to *think* about your problem before you can get any more specific answers.
http://bit.ly/O5kaVS has an example &amp;mentions ZS3 etc..
Agreed. Mix a cacophony of downvotes for expressing an opinion that's in any way against libertarian ideals or not *extremely* politically correct with the fact that every other post is "Why I'm an entrepreneur and you should be too LOL!!" makes HN a bit sickening. There are some really good articles on there from time to time, but expect to wade through fields of garbage before finding them. Not to mention most of the good stuff ends up on the front page of proggit anyway.
The key isn't 'How Big' but find the fast/best way to work with these big data. I have several TBs data to process, I now using Hadoop+Clojure, but I don't like clojure so much, I want to replace it with CL, I am finding some solutions to query hadoop using CL. Or somebody can show examples how to process tons of data without hadoop but using CL ?
I'm not sure how bad it would be. Obviously doing the initial framework stuff would be a pain, but after that it might be fine. It does seem to me that if you want to to mapreduce stuff then probably this is a bullet that has to be bitten, since Hadoop is probably mature enough and well-accepted enough that inventing something else is probably not really a good idea. However I haven't yet got to the point of trying this.
The Windows fork is supposed to have working threading and it was supposed to be merged back into the main line. That said, I agree that if stability is what you're looking for on Windows I'd lean toward CCL. CLISP is definitely stable but I've encountered performance issues.
That fork is abandoned, and I haven't seen any evidence that sbcl maintainers are interested in merging it to main line.
https://github.com/akovalenko/sbcl-win32-threads It doesn't *seem* abandoned....
Since you seem to be involved in some fashion: what kind of help do you actually need?
Thanks for stepping up. It is indeed a good news that his effort will not be wasted.
Very interesting. Where can one find Kay's project?
As far as I know, the source isn't publicly available at this time. The reports are online [here](http://vpri.org/html/writings.php) and I've linked several particularly interesting ones in the slides.
I know that Brit frequents \r\lisp, so this question is aimed at him: how do you plan on handling the graphics system? cl-opengl? I can imagine that you'll just need to provide a primitive that plots a pixel at a given address with a given color. Thoughts?
Clojure maybe? Seems a bit young though...
http://www.tiobe.com/index.php/content/paperinfo/tpci/tpci_definition.htm 
racket, clojure, arc, emacs lisp, autolisp... I think there are some more.
So, I believe I made a point of describing famiclom as a "headless" NES emulator. The (admittedly nuts) plan is to simulate the graphics card and ship bytevectors or diffs of bytevectors via JSON to a client, then probably draw with Canvas or something maybe adapting from JSNES. Though recently it occurred to me that CCL will run on Ouya and it would be fun to try targeting that. In which case, cl-opengl or sdlbuilder would probably be my next move.
AutoLisp, I'd guess.
Nothing. It merely tells you what you already know: these lists are junk.
[CL = AS/400 Control Language](https://secure.wikimedia.org/wikipedia/en/wiki/CL_(OS/400_command_interpreter\)) not Common Lisp, that would in the Lisp listing.
&gt;CCL will run on Ouya Huh? Wait, how exactly will that work?
The Clozure Cocoa IDE is also available (for free) in the [Mac App Store](http://itunes.apple.com/us/app/clozure-cl/id489900618?mt=12). I also second the recommendation to read *Practical Common Lisp* first.
You mean like this? http://www.franz.com/services/classes/download.lhtml I don't have time to step through those to see if that's exactly what you're looking for, but I would guess it's close. Edit: Also this in case your interests extend beyond Allegro: http://c2.com/cgi/wiki?CommonLispCodingVideo 
Please refer to Cooper's "Basic Lisp Techniques" which is a tutorial specifically for Allegro CL: http://www.franz.com/resources/educational_resources/cooper.book.pdf
Please refer to Cooper's "Basic Lisp Techniques" which is a tutorial specifically for Allegro CL: http://www.franz.com/resources/educational_resources/cooper.book.pdf
From some cursory googling, seems like both Bigloo and Chez Scheme have implemented it, where it formed the basis for hygienic macros in both. Both influential Schemes. 
It's more important than it seems. There's a big difference between free speech and free beer. 
Seriously, it doesn't take any energy to figure it out and run down the list of pros and cons for your situation. If you're talking about the polarization and demonizing that occurs around the rhetoric then I agree and I just NOPE my way out of all of those conversations. Light vs. heat and all that...
The "CL" in this does not stand for "Common Lisp". That's under "Lisp"
Fexprs are invoked at run time, whereas macro expansion happens at compile time. For that reason fexprs can choose to do the work of the form themselves like an interpreter, but EPS expanders still follow the macro principle of generating code that will do the work at run time. Also traditional fexprs don't do well with static scope, but that can be fixed if you have first-class environments and pass the appropriate environment to the fexpr. I think that this is what [Kernel](http://web.cs.wpi.edu/~jshutt/kernel.html) does. (Disclaimer: I haven't looked that carefully at Kernel, so it may in fact pursue the same goal a different way.)
Languages based on paranthesis-delimited expressions and prefix notation.
This site deals with all varieties of Lisp: * [lispjobs](http://lispjobs.wordpress.com/) [Clojure.core](http://clojure.com/) does Clojure consulting. They're a facet of [Relevance](http://thinkrelevance.com) which is a Rails/Clojure shop. They do have people who can work with Common Lisp and probably Scheme if necessary. I sent two people I know the url to this post. I'd like to work with either or both of them.
The other question is, what happens if this burden falls on your shoulders? Ruby is not an acceptable Lisp. nil is not an instance of anything in any Lisp I've heard of. Ruby macros &lt; C macros &lt; Lisp macros. Ruby is a great language, but its idioms don't map well into a Lisp. If this project might come your way, start learning Lisp now. Expect shock and awesome :-)
There's a lot of legacy AutoLISP code out there. My friend's dad works for an HVAC firm that ported a sizeable chunk of their AutoLISP code to VB and C# so they wouldn't have to pay consultants so much to maintain it.
Thank you sir
Thanks! It looks more like a site for FT jobs though?
When you have the time, either [HtDP](http://www.htdp.org/) or [TYSINFD](http://www.ccs.neu.edu/home/dorai/t-y-scheme/t-y-scheme.html), or [SICP](http://mitpress.mit.edu/sicp/), depending on the speed and meta-ness you're tolerant of. (Ordered from slow/unmeta to fast/meta)
I've heard from multiple employers who got good candidates for CL hackers via lispjobs.
Are you kidding? ...there is always someone at LispNYC looking for a gig! http://lispnyc.org/recruit-experts
I would very much like to write web apps in common lisp. However, I use Clojure because it is easy to run on free web service platforms such as Amazon Web Services or Google App Engine. Clojure is nice but when something goes wrong, Clojure prints out a java stack trace. I would much rather debug pure Lisp than debug Clojure AND Java. Does anyone know of a common lisp tiered-hosting site that offers a free tier? Any suggestions would be welcomed.. thank you!
If you haven't yet you could use an Amazon EC2 micro instance for free for a year. Even after that year you'll pay peanuts per month.
&gt;is available for Java, C#, and probably C++ in the IDEs. It's been out for a pretty long time, too. Not just in IDEs, this exists for Emacs for most languages too. Hovering my cursor over a function/value in Haskell on my Emacs flashes its type signature in messages.
&gt; Clojure is nice but when something goes wrong, Clojure prints out a java stack trace. I would much rather debug pure Lisp than debug Clojure AND Java. Can someone comment on just how much is this turtles all the way down ideal useful in production? Is it possible for Clojure to start pushing the abstraction level further and further down as Clojure matures, so that the JVM eventually is similar to the compilation layer in SBCL? I have a hard time visualizing just how much benefit there is to be had by insisting upon turtles all the way down, after reading lots of back and forths [like this one on HN](http://news.ycombinator.com/item?id=587289) all I get is the sense that if you are interfacing with lots of Java code, it certainly can get tiresome to have Java stack traces barfing all over. But with lots of debugging macros out there for Clojure, how much are people using pure Clojure applications in production having to deal with Java stack traces that originate from pure Clojure code that doesn't interface with Java libraries?
Thanks tater! 
Two newlines gives you linebreaks, and it picks up formatting for 1., 2., etc. Just in case. =]
Didn't expect this kind of language in an academic paper: &gt;That night I pulled the paper down from the ACM server &gt;and read it while outside enormous puffed clouds dwelled &gt;overhead, lit from beneath by the town of Porto de Galinhas &gt;on the Brazilian coast; the smells of burning sugarcane and &gt;bitter ocean pushed into my room
My workplace does consulting on all types of code, and we'd be happy to give you a quote. More information about us is at https://www.acceleration.net/programming/custom-solutions/, and there's a contact form at https://www.acceleration.net/contact-gainesville-isp/ to start the process off. We do a lot of development on [clsql](https://github.com/UnwashedMeme/clsql/wiki/).
Thanks for the info, I don't normally post on Reddit. I'm not fond of Reddit's comment system. At least on Slashdot I get a "Preview" button rather than forcing me to immediately use the "save" button. The "formatting help" also didn't mention this stuff, so I decided not to bother with formatting because there's no preview that will show me the result before it gets posted. I edited the original post with your suggested changes.
Yeah, it is a little awkward. If you intend on posting more, I highly suggest installing the Reddit Enhancement Suite, as it includes a live post preview among other things. http://redditenhancementsuite.com/
The amount of stupid in that post staggers the imagination.
BS?
This post is *objectively* horrible.
good grief!
dude, Ayn Rand is like the Michael Bay of philosophy.
So a cond condition is ( CONDITION ACTION ) where condition and action are forms. It's attempting to take the value of CALC-DISTANCE as a variable. If you're trying to use it as a default action... (t (calc-distance ... ) will be the appropriate form
This is some weird-ass code and you don't really seem to know what you're doing, care to shed some light on the situation for us?
I'm glad that he clearly shows that not everyone is fascinated with Clojure and explains why. It's not that I'm antagonized to it in itself, I'm just really sick of the hype, and I prefer the agnosticism of CL. I also wish he'd said "agnosticism" instead of "minimalism"; Lisp may have large standard libraries, it's just that one of the principles is that it should work well with any general paradigm, which (I think) is what he means.
It may be noteworthy to point out that unlike `default` in C, `t` isn't (or need not be) part of the syntax of `cond`. It's just an expression that happens to be true all the time. Any truthy literal would work.
i'm not sure that the conclusions in this article are that useful or even accurate. these sorts of articles seem to suffer from the 'paralysis from overanalysis' syndrome. for example, one thing that we know about human beings is that we are shallow, self serving and unethical. show someone a way to potentially make tons of money and they will sell their mother into slavery. to wit, objective c and the iphone lottery. flash enough cash around and you can get monkeys to do anything you want really. the reason c, c++ and other imperative languages got traction is because they solved an economic problem of some sort. either you could make great money at being a core developer on some project that was making tons of money during the early stages of the information age where nothing existed and all you had to do was invent something new using your own personal bad sense of aesthetics, or you gained an economic benefit by creating a scripting language that reduced the cost of doing things in a domain of problems which did not pay in cold hard cash but paid in productivity gains ... get more done in less time (witness perl, python, php, etc). once something gets traction for an economic reason, its easier for a programmer to change them selves to suit the environment than for them to change the environment. simple economics. so what does this mean for the future? those that say that lisp will never again gain traction simply don't understand economics. flash enough cash around and you can get monkeys doing anything you want really. show us the next reddit coded in lisp and the ability for joe programmer to make shit tons of cash coding lisp and you will see lisp gain traction. just remember, no one loves c, c++, php or perl. by the same token, if lisp gains traction no one will love lisp either. which brings us to my favourite question: right now lisp exists in a sort of golden age, used and loved by those that love lisp, ignored by those that don't. //START EDIT// if i actually had a choice to make it tract, would i willing to accept the consequences? //END EDIT// 
You make it sound as if Lisp developers are some species of hipster, and are secretly *glad* that Lisp doesn't have nearly the traction of other languages.
fair point. i have no right to speak on behalf of the lisp community. edit the last statement to reflect the singular.
This paper is hardly a refutation of her work. It's also beyond wrong in so many ways in it's interpretation of her views. This is typical academic long-winded pontificating spineless drivel found in many 'philosophy departments'. It is tedious to read at best and is oh so careful not to draw any actual conclusions. Yawn ... There is also significant distortion of Ayn Rand's philosophy in many places. The authors attempt to label her philosophy in terms of other philosophers as if Objectivism could be made to fit in a pre-packaged philosophical academic cardboard box. A quick example : Ayn Rand never claimed that survival was the ultimate goal for all living entities. She said that survival was a primary goal of rational human beings AND in order to achieve happiness. The authors either erroneously or fraudulently classify her as a 'survivalist'. Not to mention that the paper itself is morally abhorrent in places. An example is it's view of human life : "The biological premise that survival is the ultimate goal of all living things is mistaken. Animals of many species risk their own death for the sake of reproduction, or for protecting their young or even their group. But even if survival were the ultimate goal of other species, it need not be ours." This is true of animals and in some cases human beings. However the authors state that as human beings to sustain life through survival is not necessarily the basic goal of human beings, it's reproduction and/or defending the young. That's fine and ok when it is a human being's choice to do so. However this statement has serious echoes of immoral pro-life garbage. Ayn Rand had no primary intention of 'making a contribution to a broad field of work' as many academics do. For her, philosophy was a matter of life and death. Her goals were practical and she worked to synthesize a system of philosophy that would enable human beings to live a long and productive happy life. Not very different from the truths which were once widely pursued and considered rights in the US by all citizen's as their primary goal : "Life, Liberty and the pursuit of Happiness". From the Declaration of Independence no less. 
&gt; When I returned in 1998 I was startled to learn that my field—advances in Lisp-like languages approached in an engineering manner—had been deleted, literally. The conference I routinely published in deleted “Lisp” from its name in 1996 \[...\] the journal I founded with Guy Steele deleted “Lisp” from its name in 1997. I was half expecting him to say "as was the style at the time". It fascinates me how cultural attitudes toward languages evolve; Lisp isn't the only example.
I think that's mostly correct. Well, I don't think they're hipsters -- *scheme* programmers are hipsters -- but I think an enormous amount of effort is expended to make sure that, somehow, it is never quite possible for people to get anything useful done in Lisp. The number of articles which came down to "Lisp is stopping me doing x" or "things were so much better 20 years ago, Lisp's time has passed" that you used to see on CLL was frightening. Of course, it has always been possible to get useful stuff done in Lisp and it has never been more possible than now, with multiple high-quality implementations and an increasingly good library available via a quasi-standard module system (Quicklisp). So these articles say more about the people who write them than they do about Lisp. There remains the possibility that it's only the people who complain who you ever hear, resulting in a very biassed view of the community. That's probably correct.
Maybe everyone else has been paying attention, but what is "mentioned by RPG"? FWIW, I think these three links would have been much better as a self-post with a little more context :-).
I've posted yesterday: http://www.reddit.com/r/lisp/comments/yb14b/richard_p_gabriel_the_structure_of_a_programming/ [Richard P. Gabriel](http://www.dreamsongs.com/RPG.html) aka RPG is quite famous in the Lisp community and even beyond. See: http://en.wikipedia.org/wiki/Richard_P._Gabriel 
Thanks - I missed yesterday's link; guess I wasn't paying attention :-). RPG is who I thought it probably was, but he's mentioned a lot of things over the years! :-)
I had the honor of seeing a presentation by RPG at last year's Clojure West conference. His speaking style is very much the same. Forever the poet I suppose.
Ahh... jejune sums up so many of the programming articles I see posted in the programming subreddits. Thanks for adding a new word to my vocabulary!
I would very much like to see which debugging macros that you are talking about. If you know of something that will give me a lisp-like stack trace for Clojure, please DO post a link, it would be much appreciated! I personally think that it IS important to have "turtles all the way down" or as I would call it "a consistent programming environment."
I am waiting until Mac OS X becomes such a terribly walled garden that I have to switch back to a *BSD variant. I'll probably use a OpenBSD/StumpWM/Emacs system.
I use an Ubuntu system using stumpwm because I'm getting too old to deal with hardware compatibiltiy issues :) The first thing I do i rip out the display manager and setup an .xinitrc running stumpwm, or use the technique on this page to set it as the default window manager using a dm: http://www.mygooglest.com/fni/stumpwm.html (search for 'Installing StumpWM as the default window manager ').
&gt; TL;DR: &gt; &gt; ? (fun-p 'lisp) &gt; T for us schemers (fun? 'lisp) =&gt; #t
These aren't the same as what you get out of SBCL or one of the commercial Lisps, [but they are a start](http://stackoverflow.com/questions/2352020/debugging-in-clojure). Even if a [bare metal Lisp](http://common-lisp.net/project/movitz/) was somehow completed to give rise to a modern day semblance of a Lisp Machine, just like a Lisp Machine there would still be a layer of assembly so the consistency of the environment does have a set boundary. Though such a boundary would be much, much lower than it is today.
Is this any easier to use than SLIME for someone just starting out that's not familiar with Emacs or Lisp development in general?
This...isn't an introduction to Lisp. It's a discussion of Lisp's history and a few basics about it. Any introduction to a programming language should show code in that language. The parts that talk about code are too vague to be of any use to someone wanting to learn Lisp. This article isn't very well-written. It's full of falsehoods, misconceptions, and thinks about things in the wrong way. Leaving aside the awkward constructions and bad phrasings (it reads like English is the author's second language, so I won't nitpick these errors), a few selected gripes: &gt;Myth: Lisp programs require expensive computers - A few years ago. getting started with Lisp required a million - dollar commitment, today on the low end excellent Lisp systems for personal computers at only a few hundred dollars. This implies you need a special computer to run Lisp. &gt;Lately Common Lisp has been extended to include features for object oriented programming via CLOS. This statement is true for none of the people this article is aimed at. CLOS is from the [80s](http://www.dreamsongs.com/CLOS.html). &gt;Myth: Lisp programs are big - This is not a myth, they are actually big. But that is only because Lisp makes it possible to create programs that are big enough to know a lot. No they're not. Lisp programs just aren't big. Saying "but you can write programs you can't in other languages" doesn't make Lisp programs big; it makes big programs possible. There's a giant difference.
Ah, the actual widget under the hood is CUSP. http://bitfauna.com/projects/cusp/ I need to get it rolling and see how it works. I'm working on putting together a better introduction to Lisp at some point in the near future and CUSP is on the list of things to mention.
Do you know of somewhere I can read about the progress on the Guile Elisp interpreter?
Unfortunately, no. Bpt lives at my house soooo... I've been pestering em all damn summer to weblog or something about it... I'm going to end up writing an article and publishing it on slashdot about it in a week or so, stay tuned.
I am very pleased to hear that! I look forward to writing Guile for emacs! :-)
Use Hadoop Streaming, no doubt about it, as all you need to do is read data from the standard input and output to standard output. Input looks like a sequence of: key&lt;tab&gt;value&lt;newline&gt; and so does output. For map functions you will get input in any order and for reduces you are guaranteed to get all of the data with the same key in a sequence. And that's pretty much all there is to it, really, and Hadoop abstracts away almost everything else. You can even simulate this in the shell by running "cat inputdata | yourmapscript | sort | yourreducescript", and that's a full Hadoop step you have there
Why? I can see the appeal of a specialized IDE for a language, but I see no point whatsoever in simply porting Emacs (that is, unless there's a new OS or something). That just reeks of cult-like behavior
I suppose. I guess it's due to my biases.
I am SO pumped for the guile version. For two reasons: * The guile cffi interface is the bomb diggity * Threads in Emacs Tell bt I've been obsessively trying to follow his work and one day contribute!
Is it bad that I find the sweet-expression harder to read? I have to start thinking about this is a neoteric something, curly-infix other or sweet that while I read. I suppose practice could fix it, but why do it if practice already made me see the structure in simple and homogeneous parens?
https://www.youtube.com/watch?v=xlA9bNk3b5Q That is the first thing that came to my mind after checking that out. I thing the the Lisp syntax is fine just the way it is. I really don't see any benefit with those. After using Lisp a while you don't focus on the parenthesis and you should be using any decent editor to pair parenthesis anyway. I have to admit that Lisp syntax doesn't win any points in longer math expressions but I think some sweeteting on math expressions could be doable.
I love s-expressions for mathematics as I don't have to remember precedence.
&gt; I have to admit that Lisp syntax doesn't win any points in longer math expressions but I think some sweeteting on math expressions could be doable. I always find that the longer the expression, the more I want a prefix notation....
Whitespace delimiting? I always thought that was a bad idea. Perhaps you can make a infix/postfix reader macro? so hello(world) becomes (hello world)? This way the programmer decides where space is necessary. Also, I still don't see the point of this exercise. S-expressions give us many hidden benefits like seeing the abstract syntax tree, macros, and code and data similarity (Homoiconicity). I really can't describe the differences, but once you learn them, s-exps just seem *right*. Anyway, good job! If nothing else you might make lisp accessible to more people, which is always a good thing. After we baptize them we can take them into the back make them 's' users. Like scientologists do with zenu.
I will be interested in any project like this when it addresses macros - real, messy, non-hygenic code that writes code. This one acknowledges the problem, and tries to solve it by introducing visible markers for indentation level (ecch) and using define-syntax - not my cup of tea, personally, but I'm somewhat of a CL fossil.
&gt; Is it bad that I find the sweet-expression harder to read? No, and me too. I really don't understand why people hate parens. With editors from the 80's they are trivial to handle and visual parsing is just fine.
Threads, alas, are still going to be a huge PITA :( Asyncs may be less problematic IIRC, but stuff like "touching buffers" from more than the main thread is going to require a ton of work. It appears that Tom Tromey just dumped a huge threading patchset on emacs-devel, hopefully that work is applicable here and we can be one giant Scheming Threaded Emacs family.
Woah nice! I've been doing lisp coding in Windows using CLISP. I might give it a go but I'm expecting the worst :/
(ql:quickload "infix") will let you write f(x,y) instead of (f x y), a[i,j] instead of (aref a i j), x&gt;y for (&gt; x y), and so on. [Full documentation is here](http://www.cs.cmu.edu/afs/cs/project/ai-repository/ai/lang/lisp/code/syntax/infix/infix.cl)
Can you tell what learn path you used to know lisp?
nonsense - the parens are one of the big advantages of (real) lisps to write code AND data ...
David Wheeler has worked on this before (or perhaps this is a continuation?): [sweet expressions](http://www.dwheeler.com/readable/sweet-expressions.html). I don't seem to recall either this or [SRFI-49](http://srfi.schemers.org/srfi-49/srfi-49.html) having many users.
[Ahem](http://www.paulgraham.com/syntaxquestion.html)
Scheme has lexical scope?
I know it's hard to believe, but it's true
What's lexical scope? Something functional snipers use?
Wow, as a non lisp programmer, this looks awesome! 
OMG! This will take you back to 1991! tho awethum!!
Thanks very much for this review. Three coworkers and I all had half-finished blogware and agreed to a 1 week sprint to finish them, hence the lack of tests and some other sloppiness. I look forward to fixing these issues. My coworkers blogs (for the curious): [Nate's Node.js entry](https://github.com/nathanielksmith/cadigan) [Michael's M4 insanity](https://github.com/datagrok/m4-bakery)
It says that is built on top of the BT library so my guess is that the threads are not light weighted since it will use the ones from the CL implementation that is running on. 
Point by point: 1) Fantastic. I wouldn't have thought of this as I don't use Unicode much. I also am inexperienced with Lisp encoding stuff generally. I won't have time to delve in for a few days but this is very worth doing and the [code Mozilla uses](https://github.com/mozilla/unicode-slugify/blob/master/slugify/__init__.py) looks straightforward. Just need to find Lisp analogues for unicodedata. Any pointers besides what's on cliki? 2) Not quite. DO-FILES wraps LIST-DIRECTORY from CL-FAD. Actual directory walking isn't required here. It also allows me to say "(do-files (file dir with-extension-x) (foo file))" which is very important when I only care about, say, compiling template ".tmpl" files. It's a nice bit of extra abstraction and reads a bit nicer than looping over (list-directory) IMO. 3) I also am a bit conflicted about this. However, a careful inspection of packages.lisp will reveal the two main reasons I'm using it: WITH-CURRENT-DIRECTORY and RUN-PROGRAM. If you have a suggestion that is portable for those two things, let me know. :) 4) I have taken your advice and [the resulting indices code](https://github.com/redline6561/coleslaw/compare/8f4f2b0af9...a7af16e7eb) reads much better. Thank you! 5+6) Still haven't figured out what to do here. Will have a closer look in the coming days. Thanks again!
1) Weitz's CL-UNICODE looks good, but doesn't have normalization stuff to de-accent non-ASCII LATIN letters. Python's unicodedata is actually a C module full of magic. I also looked at Play Framework's slugify function which is in Java, and uhhh, not too smart. 3) RUN-PROGRAM analogue is in a package called trivial-shell, which has no dependencies. I'm not sure if (make-pathname :directory ".") is a portable way to get the current directory or not. There is also USER-HOMEDIR-PATHNAME. Cheers! - m 
Sure, it's probably got a few kinks to work out of the policies, but overall I love the idea of BountyOSS. The unabashedly programmer-created UX, not so much. I keep trying to convince Scott to give me access so I can make it look less like a database dump and more like the awesomeness that makes up the core idea, but it's hard to blame him for being hesitant to give repo access to strangers on the internet. :) (Also, he's pretty busy squashing bugs and fleshing out features.) Right now, I'd consider BountyOSS more of an early-stage open beta than ready for prime-time. It's got serious potential, but also a ways to go, and I look forward to seeing it progress.
I always like the examples people give when comparing an S-expression to an Algol-like. (define (factorial n) (if (&lt;= n 1) 1 (* n (factorial (- n 1))))) define factorial(n) if {n &lt;= 1} 1 {n * factorial{n - 1}} All ya did was get rid of the ones in front of define and if and move the one for the function call. No one ever shows an example where you go from a large, complex, correctly indented S-express to a similar Algol-like. If anything I tend to dislike how many other languages use parens and braces and brackets for very similar cases. In this example parens are used in the definition of the function parameters but when calling the function you use curly. And then you also use curly for grouping an operation and two values. Seems like a much more complicated, not well thought out implementation. 
Thanks! 
Oh, interesting, what Lisp are you using? It looks like the url binding is changing out from under some of the threads before they run. (sbcl.org 3 times). Maybe if I wrapped each call in a let, so they each get their own binding?
Maybe try this: (time-it (let ((chan (make-instance 'chanl:channel))) (dolist (url *urls*) (let ((local-url url)) (chanl:pexec () (do-request-chan local-url chan)))) (dotimes (x 8) (format t (chanl:recv chan))))) 
How do I create a new bounty? I cann't seem to be able to create a new pledge/project. There are hackers I want to entice with an offer. How can I pledge $ and write a summary of what I want done?
This is super naive - Ruby lacks a significant portion of Lisp nature. 
It's not "Hey, developer, I'd like to pay $X for Y." (for that, see [FreedomSponsors](http://www.freedomsponsors.org/)), it's "I'm thinking about doing X, anybody want to pay for it?".
I participated in some of the SOPA black-outs and by far, the best way to get your point across is to show some warning that looks like the information on the site has been suppressed and then fade into the actual content with a message detailing how people can help.
For anyone having trouble running this on OS X, here's what I had to do to get it work with SBCL. The following applies to the steps below: - These steps assume that you've already installed [quicklisp](http://www.quicklisp.org/beta/) - The `%` symbol represents the command line prompt - The `*` symbol represents the SBCL prompt. 1. `cd` into the directory where you downloaded `asteroids.lisp` 2. `% sbcl --load asteroids.lisp` &gt; *This will probably fail while trying to install lispbuilder-sdl. For some reason the build process doesn't quite work on OS X. The solution above is thanks to a Google groups post I found from Zach Beane. Steps 2 and 3 below show how to get the lispbuilder-sdl build to work properly.* 3. `% cd ~/quicklisp/dists/quicklisp/software/lispbuilder-&lt;version&gt;-svn/lispbuilder-sdl/cocoahelper` 4. `% make` 5. `% brew install sdl_gfx` 6. `% sbcl --load asteroids.lisp` 7. `* (asteroids:main)` That did the job for me, hopefully this helps anyone else trying to get it working.
Good for David. I support his thoughts on this issue.
I would guess that most Lispers care quite a lot about what he's trying to protect already and that this won't change any minds.
Not sure if this is aiming in the right direction , but anyway it is intresting IMHO: This guy uses CL to write ASM for a Nintendo Entertainment System. http://ahefner.livejournal.com/20528.html 
While I basically agree with you (as I wrote earlier), in fairness it is worth noting that an extreme action can in rare circumstances galvanize a revolution if the conditions are right, as was the case with [Mohamed Bouazizi](https://en.wikipedia.org/wiki/Mohamed_Bouazizi) whose public self-immolation galvanized the Tunisian Revolution which led to the Arab Spring. I don't think, though, that David's action is even close to being in that category.
3) Iolib dependency has been removed.
Horrible explanations. Simple fact is when last command in a procedure is a call (to another procedure), the call command can be replaced with direct jump to that procedure. And If the procedure calls itself, such a recursive call becomes just a loop, which is faster and can last forever. -- A call pushes returns address to the stack, which eventually fills up and kills the process.
Computer Science. LOL.
What does Lisp 'look like' ? 
I posted the link because I wasn't sure what exactly you were talking about. You make a wonderful product and I was sad to see the site go down. Just didn't fully understand what you were protesting. 
I *so* wish back these simple times...
Neither the canonical Haskell example or the OP's are [true quicksort](http://stackoverflow.com/questions/7717691/why-is-the-minimalist-example-haskell-quicksort-not-a-true-quicksort). 
About reddit's switch to python: http://blog.reddit.com/2005/12/on-lisp.html &gt; Lisp will never get in your way, although sometimes the environment will. &gt;Emacs and SLIME are a killer combination, but I develop on a Mac, and reddit.com is a FreeBSD box. On my Mac, my choices of threaded Lisp implementations was limited to OpenMCL, and in FreeBSD it's CMUCL. Because of the low-level socket and threading code we had to write, reddit would not run on my Mac, and I was always tethered to our FreeBSD development server. Not being able to program offline is a pain. &gt;If Lisp is so great, why did we stop using it? One of the biggest issues was the lack of widely used and tested libraries. Sure, there is a CL library for basically any task, but there is rarely more than one, and often the libraries are not widely used or well documented. Since we're building a site largely by standing on the shoulders of others, this made things a little tougher. There just aren't as many shoulders on which to stand.
The [arc version](http://arclanguage.org/item?id=16705) doesn't require any list-comprehension macros.
Pattern-matching is much nicer than "when" and "destructuring-bind".
Why? Because remove-if-not is deprecated? I'll stop using it when the next version of common lisp comes out.
I, for one, simply did not know that it existed.
The author made a branch called "rotate" https://github.com/dballard/flight-sim/tree/rotate which behaves much better on key strokes than the original branch. Also the rotate branch is much newer (2 months). The original branch would work on key "w" and crash on a,s,d etc... Thanks for the link 
Or conversely, I think Bash is the default shell in MacOS. Verify which is right for you by: `$ echo $SHELL` returns `/bin/bash` You can add ccl to your bash path by typing: `$ echo 'export PATH=/Applications/ccl/scripts:$PATH' &gt;&gt; .bash_profile`
Finally, another super easy answer brought to you by homebrew: &gt; `$ ruby &lt;(curl -fsSkL raw.github.com/mxcl/homebrew/go)` &gt; &gt; `$ brew install clozure-cl`
Really ? Which platform ? Yesterday I played around with the flight-sim lisp mentioned in another thread here on /r/lisp, which depends on lispbuidler-sdl. I setup sbcl+quicklisp+lispbuilder-sdl under Win7 and also Linux in about 5-10 minutes each without any problems. Remember to place a SDL.dll into the directory where you run the application from under Windows. Linux should be fine. For Apple, look down this thread. Hope it helps.
Took me 6 seconds to spot the url trick.
While the article does highlight the limitations of lisp's type system as opposed to languages like Haskell or ML, I do like the trend of programmers getting more interested in doing things with types that before would have been unthinkingly done with Objects. 
Kind of unrelated, but I found this picture to be very helpful: http://sellout.github.com/2012/03/03/common-lisp-type-hierarchy/
This topic is thrilling. Thanks y'all
That's kind of hackish though, but yeah, would work.
Anyone has any details? This is sad year where great people left us...
lookin good. it will be very helpful to see how this is done in a functional style. thanks for sharing!
Thanks! I've thought about the functional maps vs. classes issue and I have a couple ideas. Shallow copying the class instance every time is of course less than ideal from a efficiency perspective. One idea that would be simple is just creating a class that wraps a single FSET:MAP and has methods implemented to pass along all the normal map operations to the internal map (and returns a fresh instance on "mutating" operations). Basically, it would work just like normal FSET:MAP instances, but you could subclass them and do multimethod dispatch and it would only be marginally more expensive. That would be pretty close to what Clojure gives you with records which are pretty much just "typed" persistent maps. If you wanted to access the attributes like normal class slots you might be able to do some MOP magic, but don't ask me how.
 (sadp 'treerex) =&gt; true 
:( something realish, instead of a wikipedia edit: http://www.xconomy.com/boston/2012/09/07/dan-weinreb-boston-computer-geek-community-figure-dies-of-cancer/
Dan was diagnosed with cancer about a year ago. He was on medical leave from Google and had gone through several rounds of chemo, but unfortunately it had spread and he lost the battle. 
Many thanks we had him alive for so many years (as this isn't granted for nobody of us, starting from -9 months to 99 years...).
Donations in Dan’s memory may be made to the Dan Weinreb Memorial Scholarship Fund, c/o William Weinreb at 83 Forest Street, Newton, MA 02461. 
Awesome project! I was just playing around with Lisp again, and was thinking how great it would be (for both reading and writing) if we could replace the parentheses. Ideally, do for Lisp what haml did for html. So my idea would be to do this a bit differently, by keeping the argument ordering but replace paren groups with indentation, I hope projects like this catch on!
I won't try to give an answer but I'll offer two data points from my personal library: * The AWK Programming Language--210 pages * The C Programming Language, 2nd Edition--272 pages Also, I'll mention that the VPRI system being developed by Alan Kay's team should be an interesting point of reference because they are going for extreme concision and broad coverage using language design as a major tool.
I gave clisp+lispbuidler a shoot. Two issues : lispbuilder-sdl will compile under clisp. Then I tried the mandelbrot example, which rendered fine, but then hit a segfault in the end. The other thing I tried was to compile and run asteroids lisp in clisp. This also compiled fine and started. As soon as I hit "p" for play, it would crash with an memory access violation. This is on a Kubuntu 12.04 AMD64 installation with clisp 2.49. Both tests work flawless with sbcl on the same machine. Edit typos.... 
Maybe I should switch to sbcl.
How fun!
Some of the smaller remaining stuff will definitely be picked up during normal development. * fair spinlocks will be done, soonish if it's blocking someone. However, I don't expect they'll ever be good enough to be the default. * RW locks are hard to do one size fits all, but I'm pretty sure any will do for a default choice, especially if alternatives are readily available.
I updated the game a bit in the last few days with scoring, levels (with speed-up), game-over, starting a new game, and I added a Windows .exe build (let me know if it doesn't run) [here](https://thezerobit.com/ccl_win32_build.zip). The windows build was made with 32 bit CCL and ships with 32 bit SDL.dll, but I built it on Windows 7 64 bit, and it runs fine, there, so hopefully it's pretty universally compatible.
I had been wondering what happened. Honestly, I'm kind of bummed. I was really looking forward to the improvements, and I had no idea what was happening. Like tarballs_are_good, I sincerely hope that the money can be directed towards SBCL and improvements on its parallelism software. I won't ask for money back - it was a gift, and I hope to see the improvements put in. I wish niisivola all the best, and hope that he gets to introduce Lisp in his new job. :D
Simply to offer a different viewpoint, I don't feel cheated. A few thoughts: * I remember people wanting to give money. Some to say thanks for 8 years and 1400+ commits worth of SBCL hacking. Others because funding SBCL development generally was an idea they supported, irrespective of Nikodemus or his particular goals. * Compiler hacking is a very difficult thing and reflective systems like Common Lisp don't make it any easier. The point of this was to improve SBCL for concurrent programs. That has certainly been done. I certainly don't think there was someone more qualified to get it done or that he slacked off. * Nikodemus didn't expect the amount of response that he got and, I believe, he was trying to create goals to correspond to the money flying in to some extent. He had to come up with them on the fly and was forced to rely on intuition with regards to their LOE. It is unsurprising to me that some of this backfired in the course of hacking. * Note that some of this stuff is available prototyped or on a branch somewhere but didn't deliver the benefits expected as pkhuong noted and so hasn't been merged.
&gt; 16k is a lot of money to be given, and I hope he realizes that. No, it's really not. If he had worked on SBCL for a year for that money then he made $1333/month **before taxes**! That's not a lot of money for a skilled developer like him and I'm not surprised that the money ran out quicker. But as you said: You don't purchase but you are making an investment. You invested in the development of SBCL despite not getting the exact features you wanted. It's not like he ran away and it seems that improvements for SBCL came out of it.
It's not a lot of money to pay a developer to work full-time for a year in the USA at all, but I think it's quite a bit to give upfront from a grassroots campaign. 
I agree with the 1st point. &gt;Nikodemus' didn't expect the amount of response that he got and, I believe, he was trying to create goals to correspond to the money flying in to some extent. He had to come up with them on the fly... I would recommend that Nikodemus does this again if he has any interest. The next time, just stick with the original goals; If people start giving more money than you expect it just points to the fact that you may have undervalued the development you are proposing. To be honest, I don't feel ripped off at all, but then again, I saw this as a donation in the first place and, therefore, probably gave less than someone that saw it as purchasing new features for SBCL.
These are great. Thanks!
I contributed without even needing the specific features since I just wanted to fund some SBCL development. In that regard, I think the result was good. And thanks for all your work on SBCL in particular and Lisp in general!
It's not quite as dire as that. I've just substantially scaled back my involvement for now -- and SBCL was there kicking ass long before I showed up. While money (and the fact that I suck at sales) was a factor, the stress of working as an independent consultant was also getting to me, and is something I definitely do not miss.
Glad you like it!
I was under the assumption that bignums are only limited by the amount of ram your lisp has access to. I just tried (expt 2 2097085) which worked. Even (expt 2 (* 2 2097085) works, but takes awful long. Tested with Gambit Scheme on an 8GB Ram machine.
You didn't have to calculate it, it's right there in the documentation: http://www.clisp.org/impnotes.html#bignum-lim &gt; BIGNUMs are limited in size. Their maximum size is 32*(2↑16-2)=2097088 bits. The largest representable BIGNUM is therefore 2↑2097088-1. 
Well, this is a clisp specific bug, so I suppose that Gambit Scheme has little to do with this question. It is good to point out that it almost certainly doesn't take very long at all to actually calculate the number, but it takes a very long time to format it for output. For instance: CL-USER&gt; (time (log (expt 2 (* 2 3000000)) 10)) Evaluation took: 0.000 seconds of real time 0.000000 seconds of total run time (0.000000 user, 0.000000 system) 100.00% CPU 1,161 processor cycles 0 bytes consed 1806180.0
That test you're running on SBCL isn't really fair. It calculates the exponent at compile time, before running TIME. (defun raise (x) (expt 2 x)) (time (log (raise (* 2 300000000)) 10)) Evaluation took: 0.014 seconds of real time 0.016001 seconds of total run time (0.016001 user, 0.000000 system) 114.29% CPU 35,946,228 processor cycles 75,000,016 bytes consed
And as to why SBCL is still much faster than CCL, that's because raising 2 is optimized as a series of shifts, not multiplications. Raising 3 gets more comparable results. EDIT: Not even a series of shifts, but just creating a large enough bignum filled with zeros and the left-most bit set to 1.
Thanks for pointing this out, I noticed the 0 bytes consed which I knew had to be wrong, but I also knew that that number seems to just be a ball-park estimate. But the point still stands: printing 2^3million takes something like 6 seconds and computing it takes approximately zero time. Your 300 million is still barely noticeable on human time scales. These operations are very quick, but printing them makes them seem dog slow. In Clisp, for instance, you can compute those numbers right up to the limit of the bignum implementation without breaking a sweat, so long as you don't print them. Edit: saw your post further down the page. Using 3 as a base does shed more light on the subject. There, printing is only five times slower than computing... I guess they are not as cheap as this initially indicated.
My newb-like analysis is - I don't like the name, pretty heavily overloaded term "lift" as tarballs_* mentioned. - The naming of :let and :once are confusing, since :let really means "once" and :once really means, "once, lazily". I would call them :once and :lazy or something like that, leave "let" out of it. + I love that it handles ignores. + I like it, might even use it.
That's surprising to me. Can you point to specific examples that are giving you trouble? Note that you really have to read the page "linearly", without just reading the examples or skipping to the end, as there is an implicit progression, implicit "dependencies". You have to build up your understanding with the simpler examples and take in consideration what has already been said for the latter things to make sense. Note also that since I use mapping quite heavily (which refusing to use LOOP or ITERATE pretty much requires), I can immediately see the usefulness of the features, especially automatically ignored parameters, but that might not be as obvious for "normal" people. Maybe I should illustrate the usefulness in context more. I did say this on the page: &gt; LIFT is particularly useful when used in conjunction with mapping operators such as MAPCAR, though for brevity the mapping parts will not be shown in these examples, only the LIFT expressions and equivalent LAMBDA's. One good example usage would be: &gt; (maphash (lift :2 (print :1)) my-hash-table) Which would print the keys of my-hash-table. The initial :2, as explained on the page, ensures that the function accepts at least 2 arguments, and since the second argument is not referenced anywhere, it will be ignored. I didn't put that example because I wanted all examples to be executable (without dependencies) and creating and populating a hash-table in the example would have been quite verbose. (I have a plan for a novel (and surprisingly sane, almost completely avoiding readtables) literals library that would finally solve this problem). It's a good idea to actually try the library by loading it and trying interactive macroexpansions in Slime with C-c C-m. Maybe I should mention that on the page. Hope this helps!
(integer-length (expt 2 2097085))? Isn't that just 2097086?
Ok, one thing I realized is that I was avoiding putting too many examples on the page for fear of making it just too goddamned extra long. But what I should really do is put tons of examples on a separate page. I'll do that soon. edit: Hum. And the examples page would explicitly explain "here's what's happening here, exactly", in all details, so there would be no "implicit dependencies" of "you have to understand earlier examples to have a chance to understand latter, more complex ones."
I have a suggestion: MU-LAMBDA for library name, and MU for the macro name. I hope the connotations are obvious. Search engine collisions will be unrelated. Some people like to set up their editors to render (lambda ...) as (λ ...), (mu ...) could be (μ ...) for extreme brevity.
Just an idea. However, I don't think you can really argue that LIFT is neutral. CL-MONAD has a macro 'LIFT!' which is the exact operation tarballs_* had mentioned. And, frankly, lambda lifting is a thing, and it's not the thing this library is doing.
I'm quite at ease with the fact that the same symbol/word can mean different things in different contexts.
Thanks for taking the time to respond. &gt; There are a few good reasons for not specifying the behavior formally and thoroughly: [...] I agree for the most part. A lot of my libraries aren't really defined formally; they're more a collection of use cases. But those libraries are usually function APIs. I think macros (with embedded DSLs) duly require description of the syntax in a straightforward way. It doesn't have to be CLHS-caliber. &gt; By the way, do you realize how `(lift (cons :2 '(:3 :4)))` is such an unrealistic smart-ass example? I have programmed tons of tons of CL, and never before `LIFT` did I ever use keywords like `:1`, `:2`, `:3`, `:4`. I've used `:|&lt;just about everything&gt;|` during lexical analysis when generating memory efficient token streams with lots of redundant tokens. Since the keywords are `EQL` comparable, it's quite fast. Digits would get lexed to `:6` for example. In this scheme, it is entirely possible for something like `(remove-if (lift (member :1 '(:0 :1 ... :9))) some-list)`. Just because *you* have never used it, doesn't mean *someone* will -- perhaps in a smart way even. At one point, no one thought it was sensible to allow compilers with loops of depth greater than some fixed constant (5? 50?). But then someone did it in a non-contrived way, and that restriction was since freed. If your library is simply a personal library for your own consumption, then rough edges are fine. If your library is for public consumption (as you say on your website), then I think it's a poor design decision to tell your users "don't do this because it doesn't do what you expect because I wanted to keep the implementation simple." &gt; First of all, the possibility of an ignored &amp;rest is absolutely crucial. And before you suggest it, no, I'm not willing to make &amp;rest implicitly ignored. That just feels icky. This is as I suspected. &gt; Don't dismiss it just yet. The reason most libraries don't gain widespread adoption is because they're crap and/or totally undocumented, or bring in tons of dependencies, or are way too big and complex, or other combinations of factor which add up to "this library is a liability". I didn't mean at all to imply your library should be dismissed. My remark really was a statement about Lisp culture in general, and how it might "react" to your library. 
Ok, well, I'll hold out for a better name that's about as short, and pleasing to everyone, me included. I'm not renaming to something random and ugly that just happens to be "unique and non-misleading". But personally, as you can tell I'm sure, I could live with this "problem". edit: ... What about "positional-lambda"? PLAMBDA?... That's a name I had thought of during development but honestly I think it's a bit ugly and inconvenient... Maybe "positional-lambda" as project name and LIFT as operator name? This would avoid confusions with many things like googling while still being the nice "one single non-abbreviated short actual word" I like. I think this could be a good compromise. And it's even almost completely backwards-compatible! I could export both LIFT and PLAMBDA from the package, and you'd :import-from the one you like most... Sounds like a plan? 'Cuz I'm not interested in continued bitching over this matter.
The output of DISASSEMBLE is implementation-dependant. Generally you will get some kind of byte code, like machine assembler. Assembler isn't different than any other language in that execution speed is not directly related to code size.
You can check if your implementation is properly tail recursive ;) Other than that it's as if you compiled C function into an assembler form, and then tried to infer something from that representation. You want to optimise speed? Profile your code.
[Agreed](http://qph.cf.quoracdn.net/main-qimg-472fdfa1984c972d7ac8b901438d40fb).
lol, thanks, fixed hehe
sorry, where?
In theory, performance is not contingent on the assembly length, rather it's related to how an algorithm that you're using scales with the input size. In practice, another important (not nearly as important, though) factor is how compact the code and data are in memory (it affects how much the CPU will have to wait for memory pages to load into cache), but again assembly length doesn't scale with the input so who gives a damn?
Can you tell us a little bit about what lisp environment you are using and why you chose lisp for the startup? This is really quite cool. Looking forward to watching you guys kick some butt.
Here's a blog exactly on that question: http://kuomarc.wordpress.com/2012/03/05/the-uncommon-lisp-approach-to-operations-research/ And here's why I chose to launch the startup: http://kuomarc.wordpress.com/2012/07/02/top-hackers-we-need-you-for-operations-research/ Please excuse the length ;) Stay tuned!
Soo, how was it? What happened?
* Only the operator will be named "plambda", the project's name will become "positional-lambda", averting almost any possible confusion. * I don't think Doug Hoyte's plambda is or will go in widespread use. It doesn't seem to be in Quicklisp, and its author is well-known for, uh... wackiness. * I didn't investigate what a "pandoric" macro is enough to understand what it does, but it's almost certainly a wacky name that doesn't have much to do with what it does. * plambda is a operator name that makes sense for my macro and is very much related to what it does. I almost always prefer long, unabbreviated names, but in this case "positional-lambda" would be way too long, and "pos-lambda" inevitably sounds like "piece-of-shit lambda" in my mind. ;P For these reasons, I'm not too sheepish to "take over" the plambda name. "plambda" as a project name will still be available if someone decides that Doug Hoyte's plambda absolutely must be in Quicklisp...
Hey -- traditionally hasn't the concept of "positional" argument list been expressed using the already widely known convention "BOA" -- as in "By Order of Arguments" -- as well as the ever-amusing term from the "BOA-constructor " fom defstruct. 
Can you say more about what you mean by System Programming or what you'd like to do? Is your goal to write a fast webserver or daemonized system service? Just to twiddle bits in interesting ways? To write a Lisp OS?
my god ... we live in the frickin dark ages. thank you for the links anotheraeon. the opengenera demo was mind blowing. what the hell has the industry been doing for the last 30 years?
Cobol effectively has automatic memory management built in too, no? I mean, I know we "allocated" records and such, but all the memory management aspects of that were basically handled for us. The same basically goes for Fortran, and of course Lisp. Once we left those languages behind for the most part, the industry standardized on C and therefore on manual memory management, and we took a giant step backwards in the general expressiveness of programming languages. I can only account for this detour by noting the relatively proprietary nature of the languages that pre-dated C basically enabled its explosion into a de-facto standard because those other languages were so expensive in the first place; Lisp being no exception at the time. We may in fact get to use GC in our programming today because of Java, but the only reason Java ever needed to exist in the first place was because of the extreme greed of the compiler authors 2 or more generations previous. So, yeah, now if you want to use a GC'ed language at work and not have to worry about memory management, you're probably stuck with Java or C#. Yay? 
there has been activity in the scheme world for target devices that are microcontollers. just search for that and you will find lots of info. Marc Feeleys's works will come up a lot. now, if you mean real systems work, i think you will find a lot of roadblocks if you use CL currently. IMHO, C is still the best choice for this work currently.
On my case I am able to use any language that is able to target the JVM or .NET runtimes.
The VMs themselves may be the most lasting and important legacy of this entire generation of technology. Lisp itself could see a renaissance in those contexts.
I know it is not really 100% Lisp, but I really enjoyed speeding a few days solving problems with Clojure on the 4Clojure web site, and I am aware of a few startups in Germany using it.
This looks pretty cool, but unfortunately the package names would prevent me from using it in anything I intend to share.
I know the gospel: why CL is historically so, how the Scheme history is a mess, how many things may be done in CL at user level because of extensible syntax, how ANSI CL is a very high quality standard, how a new ANSI standard is a practical impossibility, etc etc. All this is true. I am a regular user of CL and I like it; however, I am scared by the general attitude that a twenty-years old computer language does not need *any* change, ever. It seems to me a dogmatic position more than everything else. For example, there was the [failed] CLTL3 initiative, which apparently showed that some minimal kind of refreshing was desirable.
Not trying to be facetious but what would you want to change?
also defines the package names `map`, `box`, `fun`, `fn`, `as`, `seq`, + a couple others.
Sure but that's not a problem if you're sane with your package import/exports. 
Ah crap I did misunderstand! Yes, agreed on polluting the global package namespace. 
But even for immutability, the first step would be to write a prototype in the form of a CL library. I can't think of *any* feature that could not be built on top of CL. Can you? "Not enough manpower" is not a knee-jerk response. It's a statement of fact. The only practical and feasible solution, sans the necessary manpower, is to layer libraries.
What differentiates it from ECL?
Fantastic stuff!
I agree that manpower and interest was insufficient for the CLtL3 effort to succeed. I didn't mean to imply otherwise. I maintain that *language-level revision* will at some point be necessary. Therefore, it would be nice if we stopped culturally suggesting that *all* improvements to the language come through libraries. Obviously, turing-complete macros make it possible to add *any* feature as a library. Many prototypes exist already for: laziness, immutability, generic collections, etc. Writing a program with these is often tantamount to using a new dialect though. Let's please remember that a language revision would be interesting given appropriate resources.
Beware session ~~fixation~~ hijacking attacks when using Hunchentoot.
can you elucidate?
Besides the fact that I do not really see great differences to ECL, one might be that it supports only x86 platforms. Actually, I would prefer to have a fork of ECL which only relies on standard C (or C++) wherever possible, and otherwise (like for Threads and Networking and Library Loading) on SUS-Standards - so being maximally portable. And maybe even a "non-binary" coredumping mechanism which dumps objects into portable C-Code. It seems like currently, a lot of stuff is written in Assembler just for efficiency.
Yeah, I know, I thought about that as I was writing my comment (didn't mention it though, as I was on my smartphone). I still find this user's activity to be rather, well, weird. A one year long member, hasn't written anything but two comments simply reciting his own username and boom, suddenly 8 link submissions to /r/lisp about trivial stuff that almost everyone knows about now and whose titles are simply copied from the pages that they came from? It just annoys me, heh.
Yes, I'm now focusing on writing the kernel module in C first. If it's possible, I will call Common Lisp code inside the module, if not, then the module will be written entirely in C and assembly. Kernel module written in C and assembly (and possibly in Lisp too) could communicate through /dev . If this idea becomes a useful program, I will post it on github. But I'm aware that a project of this size will take a lot of time (and this is hobby for me, not a paid job, anyway). I'm interested to know more about your design idea with 3-layered system. Do you think the kernel module could/should be written in ECL with inline C or in pure gcc C? And then what would be second and third layers, why 3 layers instead of only #1 kernel module written in C and/or ECL and #2 userland debugger that sends keyboard commands to /dev/mydevice/keyboard and reads eg. /dev/mydevice/registers and /dev/mydevice/opcodes, /dev/mydevice/screen to get info about registers' values and the current opcodes to be disassembled and the hits of eg. memory regex searches. But I'd happy to know what would be the best way to do it. This debugger should also be as invisible as possible (also the userland side) to permit reverse-engineering of eg. closed-source device drivers with anti-debugging code etc. The regex instruction searches would permit trying to find correct code blocks without needing to know the specific instruction encoding used, in the best case with some heuristics engine to try to manage with obfuscated code etc., but first I need to get some basic system working.
best is a sketchy way to think about it. now that I realize you are focusing on writing a kernel module (presumably directly pluggable), I don't think you need 3 layers. I was initially assuming you would own the boot process wholly. I would suggest that the kernel module implement the absolute minimum number of primitives you need. That's probably going to look like the following list: * halt process * halt thread * read memory * read registers * resume process * resume thread * poke memory. I would advise that those become interrupts; your UI would be wrapping over those interrupts. C-side ECL would trip those interrupts and return data to the Lisp-side ECL. What I would anticipate is that as you keep doing this is that the primitives become composed into an actual useful layer of code; you'll write new functions and store them off; eventually you'll have a DSL. I would anticipate that actually halting the kernel for examination will be very difficult.
very good to know. :) thanks!
The excerpt I quoted is from the current docs. Do you have a link about the fix? I can't search at the moment. EDIT: From https://github.com/edicl/hunchentoot/blob/master/CHANGELOG: Version 1.1.1 2010-08-24 Exported WITHIN-REQUEST-P (Far� Rideau) Safeguard measures against XSS attacks (J.P. Larocque) Prevent potential leak when closing stream (Matt Lamari, Martin Simmons) Change some occurrences of HANDLER-CASE* to HANDLER-CASE (Hans H�bner, Allan Dee) So it doesn't look like it was fixed.
You'll be relieved to know he deleted his submissions.
I believe the main difference that most people will notice is that the MKCL distribution for Windows comes with the GCC distribution that it is built against/depends on while with ECL you have to setup a build environment (either Microsofts C/C++ compiler or GCC) before hand and go through the ECL build process.
I didn't write folio with the intention of distributing it to the general public; it was purely for my own convenience. On the other hand, when Zach somehow found it and added it Quicklisp, I didn't mind, either. If I can do things to make it more convenient for folks who want to use it, I will. Reverse-dns naming is a sensible practice--I've used it before in a number of cases--and it's easy enough to achieve the same level of self-documentation and convenience by adding some package nicknames. Consider me persuaded. At some point in the not-too-distant future, I'll change the package names to reflect the approach you suggest. Just in case it's not obvious, I should mention that it leans fairly heavily on Scott Burson's FSet, which is a great library in its own right.
Not really important, but just wondering... Why a distinct BOX object instead of using (CONS :BOX &lt;VALUE&gt;) ? Just wondering about the overhead: a defstruct is typically header + layout + slots % 2, which means that in most implementations the smallest struct you can have is 4 words, whereas a cons is almost universally 2 words. (With the exception of jvm-based implementations, I believe, where everything tends to have full Object overhead.) Similarly accessing a cons cell part is likely to be somewhat cheaper than accessing a struct slot. ...of course, for many things overhead on this scale is just noise -- but I at least tend to run into situations where it can matter.
Managing Complex Structured Data In a Fast Evolving Environment - by our very own tarballs_are_good.
If you've been running 1.0 for the past 6 years, then you're in for a treat. :) Otherwise this is just an acknowledgement that it /has/ been 6 years since 1.0, and a lot of things have gotten better in that time. 
Why the stupid var stuff? If you're going this far, why not make locals effortless, add sugar for shorter function declarations etc.?
C ?! Lisp was used in the past to write operating systems. So why not follow that path? http://en.wikipedia.org/wiki/Genera_%28operating_system%29 
I'm aware of Genera -- however, as I understand it, the legality of the source code is questionable. Can anyone elaborate on this? Also, as Ubertekk points out, there may be some places where the code needs to drop down the assmebly (as is done in linux kernel code) to get certain things done. I'm not particularly interested in doing that kind of work in CL (others may be, and that is perfectly fine), what I want to do is investigate using lisp for building layers slightly above those very low level operations.
There is the MIT CADR Lisp machine code which was the ancestor of Genera, and is available under a much less restrictive license. On the other hand, it is primitive, the code is often ugly, and it is deeply tied to a particular architecture with 40-year old hardware features. It pervasively assumes uniprocessing. Lots of the basics like e-mail and file storage were AFAICT farmed out to machines running ITS or equally dead operating systems running on PDP-10 hardware.
Extending the Lisp to be able to emit low-level code is not a huge obstacle; most Lisp implementations support C interoperability. Extending the compiler and runtime to support low-level operations is not trivial, but also not the hardest part.
One approach would be to take a kernel+services approach such as [GNU HURD](http://www.gnu.org/software/hurd/hurd/status.html) or [Plan9](http://plan9.bell-labs.com/plan9/), get ECL running on it and then start implementing various services providing filesystems etc. Starting with the linux kernel and rewriting the userspace in lisp (possibly by porting the android userspace, which uses objects and a GC) might be more productive in terms of having drivers available for a vast range of devices. 
Yeah, I'm not saying that it couldn't be done, but it'd still be a lot of work before you can even start on your OS(rip out garbage collection and anything needing a runtime library, add the needed functions and types to work that low, probably add some sort of inline assembler...)
Lisp needs its own architecture like the lisp machine first
Listen; just pretend Linux is your CPU microcode or something like that and be done with it already. Now, what did you really want to do?
&gt; It is not obvious that there are applications waiting to be written, except they are blocked by the lack of a Lisp OS. First, I think that on a Lisp OS, many basic Lisp data structures would be primitives on the system. Lists and trees could be created as output from and passed as input to programs, as in Genera. Software wouldn't be written in the same way as on other OSs, much like how the pipe changed the way software was done on UNIX. Data structures are more useful than character streams, however, and don't have to be parsed if the operating system helps out. Second, since there are primitive data structures on the system that all programs know about, there are many interesting things you could do in a shell. The data structures returned by a process would be understood by the shell in a level above characters. Data structures can be represented graphically in many different ways and the output of a process could be inspected. Perhaps outputs from a number of processes could be drag-n-dropped into a tree, to create the input for another program. There'd be little use for ad-hoc graphical user interfaces for many things. And of course, Lisp would be available in the shell as well to process lists programmatically.
I guess that the proper title would be "Lisp Document*ation* generation" as it deals with propgrams generating documentation for sources written in Lisp. An increadible amount of work nevertheless. Thanks for posting it!
&gt; I, for example, wouldn't be particularly interested in recapitulating a UNIX-style OS in Lisp. That just wouldn't be different enough from the status quo to be interesting. It would be much more interesting to ask yourself what would be a Lispy approach to OS design, and build up from there. I agree with this. In some sense, Unix (&amp;co) is a character-oriented (or rather, byte-oriented) operating system. All data flows as untyped blobs. It would be silly to re-implement this in lisp. Also, Unix provides protection (between subsystems/applications/users) by means of processes. A process is pretty much an empty virtual machine. It shares in principle nothing except system calls with other processes, and communicates only via aforementioned blobs. What is an appropriate level of protection for a Lisp OS, such that you can still maintain a integrated system with objects rather than blobs floating around? 
Most Lisps compile to native code as well. As for the low level interface to the hardware you only need to provide a few primitives to do so. Plus if you're writing the operating system, why not the Lisp compiler with those extensions as well? This is basic operating system design, that any CS student should know.
The lisp machines that natively ran Genera had some rather extensive hardware support for running a Lisp kernel. Later variants of Genera (opengenera) ran on top of Tru64 on Alpha hardware (there also exists the half-port to x64/linux), and required a lisp runtime in the backend. with regard to metaobject's query, [the source is here](http://www.unlambda.com/lisp/mit.page) and appears to contain at least a nod to Tom Knight and MIT as giving assent, though no citation is given that I can see.
All languages require a runtime, even Assembly (if you see processor micro-code as runtime)
That source is not full Genera which was many Lisp-programmer-years (and hardware architecture projects) of development using the MIT code as a starting point.
My apologies, you are correct.
(historically,) not all processors are microcoded, so I would not consider it an absolute requirement; and it's a pretty impressive logical jump that has you comparing processor microcode against multiple levels of abstraction layered between genera, lisp, unix, and the bare metal below.
Because the discussion about what a language runtime is, specially when people without CS background participate in the discussion, always goes to the next layer, so I've cutted it short to the lowest possible layer where some kind of runtime is yet to be found (in most processors).
I would like to re-iterate the underemphasized point at the end of the post: **the use of reader macros presented are bad and should not be repeated**. I realize this is a prescriptive thing to say, and while the post probably serves more as an introduction to how reader macros are used and not what good examples of reader macros are (:S), I do think it sort of hypes the idea of "make your own crazy syntax in Lisp!" which shouldn't be hyped. Specific to the post, the vectorizing operations could be done with a high order function: (defun vectorize (binary-fn v1 v2) (map 'vector binary-fn v1 v2)) If you want it shorter, do `v` instead of `vectorize`. Personally, I've [used a different](https://bitbucket.org/tarballs_are_good/lisp-random/raw/2bc9d4eb8a88/fft.lisp) way to express vectorized, "point-wise" operations. (defmacro define-pointwise-operation (name function) (let ((v1 (gensym "V1-")) (v2 (gensym "V2-"))) `(defun ,name (,v1 ,v2) (map 'vector ,function ,v1 ,v2)))) so then you can do (define-pointwise-operation .+ #'+) (define-pointwise-operation .- #'-) (define-pointwise-operation .* #'*) (define-pointwise-operation ./ #'/) (define-pointwise-operation .^ #'expt) I don't see this as a bad abstraction; it makes things explicit and readable. Anyway, many programmers, especially ones who are learning Lisp, have a strong affection for making their own whacky syntax. I suggest it be used as a very last resort or when the convenience of making one severely outweighs the cost of typing some extra characters (this is especially true with that bracketed `lambda` syntax). Like said in the post, it screws up the uniformity of the code, makes editors gag, and makes structural editing difficult, on top of the usual concerns of readability.
I've frequently thought about this and I think it would be very cool to do this. Having an OS which could be hacked on live would be... exciting. A few issues have to be solved, such as shared runtimes for dynamic systems instead of static libraries (pervasive separation of data and code). If you've never done it, I'd really suggest you hack together a preemptive multitasking OS in C for an embedded system (or for a VM). It's simpler and harder that it seems. Adding support for Lisp would be simple for a simple system. But for a more complicated system, you have to consider process separation, libraries, IO, paging, caching, etc. It's not trivial. Anyway, I've come to the conclusion that leaping into the Lisp OS world is going to be difficult without ground work. You'll need to define low-level forms to talk to the machine. If you can't directly write assembly, you're out of luck in all sorts of ways. So... My ponderings during my commutes lead me to this thought for how that might look- Suppose you define DEFPROCEDURE which takes parameters and allows *only* lexical variables (no specials). Suppose there exists a ASM form which takes a string and outputs it as assembly and also a FORMATASM form which takes variables and translates them into addresses/registers appropriately on compile. Let DEFPROCEDURE's compilation magic up the FORMATASM forms into correct register/memory allocation, and let the compile output ASM forms appropriately. This isn't too different than a C _asm {} style block. As a strategic approach, I would suggest defining an incremental approach and building off of Linux. What did/does Lisp OSs do for you that you can't get today? Define that, then figure out what it'll take. I think - without being an expert in OS development - Lisp runtimes, shared libraries, and multiprocess systems that don't interfere with each other's memory in 'bad' ways are going to be the big challenge. And frankly, AFAICT, that problem hangs out there for any programming interpreterish system with a big runtime: .NET, JVM, Python, Ruby, etc. 
I suppose people generally like the idea of lisp "all the way down", and that there's nothing you can't do in Lisp. I agree that you get very far (and to most of the fun stuff) with way less effort by using, for instance, a linux kernel and build the Lisp system in user land. If anybody is really serious about it, this is the best way to start out. This was suggested by gosub as well. Still, as a comment to your original post, a system that's Lisp and talks Lisp throughout (even if there is a linux kernel underneath) is different from running SBCL as just another process in linux. What would be gained if the kernel (not necessarily written in Lisp) knew about lisp data structures is that the virtual memory manager could co-operate with the garbage collector much more (as you said). Further, if all programs were Lisp, there's theoretically no need for memory protection, and the kernel could run several processes in the same address space and split them up later when they grow. For this to work reliably the operating system would have to be able to trust all programs, so the compiler would have to be very reliable, maybe it should even be part of the operating system itself. All of this is still mostly optimizations and wouldn't change much how programs themselves are written and used if the kernel was linux.
Okay, checked out the link. You, kind sir, are truly a badass. Wow.
Yeah, I'm talking about the really low levels where you would actually be using C, instead of lisp(I'm envisioning either something like Inferno or Singularity where the kernel contains the bytecode interpreter/jit or some sort of extremely minimalist microkernel where the core was C and everything on top lisp) EDIT: with regard to at least having some sort of gc, I've always been interested in the concept of using static analysis to generate the required memory freeing, then emitting warnings about ones it can't figure out. that'd at least leave an improvement over C. 
&gt; I just want to be able to write the code, press a button and get the output. I don't understand why everything has to be difficult. Because complexity exists. Other than that, go look at a commercial Lisp system, they have personal editions. 
Emacs / Slime can be configured with SBCL. 
I don't want to use Emacs or Vim.
Emacs with slime is, in my opinion and the opinion of many others, to be one of the best ways to write Lisp; certainly the best *free* way. The interaction, the ability to work straight from a source file and send functions/commands/etc to your repl and have instant response/feedback... its unparalleled in my Lisp experience. Why are you so adamant against Emacs? You don't necessarily have to use it all the time. Just like I wouldn't want to write Objective-C (Mac/iOS apps) without Xcode, I would never want to write Lisp without Emacs. 
Your whining does make me feel better though.
That question was asked in 2008, and I've already said I'm not using emacs or vim.
I don't think new free incredible lisp editing solutions have appeared since then anyway. I'm afraid but I suspect that the editor you are imagining does not exist.
At no point have I indicated anger at the communal incompetence displayed in this thread. I don't really care that much, worst case scenario, I can do what I need to do in another language. I thought I'd try something new and work with SBCL, but now I'm starting to think I may have made a bad choice.
I agree.
I use Vim almost exclusively for editing. In the past year or two, [slimv](http://www.vim.org/scripts/script.php?script_id=2531) has really improved a lot and made my Vim/lisp experience excellent. I never really took the time to sit down and learn Emacs/Slime, so I can't speak to how slimv compares, but it does let you evaluate code remotely, profile your code, debug, etc. It's really badass, and if you use Vim (or want to use Vim) I fully recommend it. I do not feel like my editor holds me back at all. As far as the configuration goes, I think it's fairly stock. I have some useful Vim plugins to help my productivity, but for lisp specifically I mainly just use slimv. Was there more specifically you wanted to know about?
Yeah, it looks like lisp needs a little bit more time before it's ready.
So, this is an interesting question. It's interesting because you have a problems with emacs that you don't really describe. I understand that Lispbox "wouldn't even start up", but that is pretty bizarre and I have never heard of that happening before. I would also like to point out here that emacs can be a really complex and powerful editor. It can also be a really simple one. You type, characters show up. You have a mouse-driven menus to save &amp; load files, to run this and that. So, at the risk of enraging you further, I would suggest trying it out again. If you don't want to use wizbang ctr+meta+fishtank+Zanzibar key combinations, don't, and the experience shouldn't be so wholly different from a Gedit. Granted, it could be arguably uglier, but you can readily change fonts, etc., from the mouse driven menu. So anyway, outside of that, maybe you would be interested in [ABLE](http://common-lisp.net/project/able/) which I have never tried, and know nothing about, and cannot vouch for at all, but at least it's not emacs or vim, so hey give it a shot and see how it goes.
Seems to be terminal based, not really what I'm looking for, although it's a bit more what I'm looking for. Better than Vim or Emacs, but still not something I'd actually use. At this point, I'm probably going to just use one of my trusty editors like Gedit or Geany, and just interact with lisp manually through a terminal. It's a huge hassle, but I guess the lisp community sees no need to provide new users with a way to use lisp without a vertical learning curve.
&gt; The world is different now. It would be nuts to put a machine with no security on the Net. I'm not sure... what's the difference between such a lispm exposed on the net and a single unix process exposed on the net? Problem is, you'd have to buy another machine (or start a new virtual one...) to start another lispm like you would another unix process, which is inconvenient and/or expensive. (I'm not saying I don't want protection of course, just trying to think straight about what the implicit assumptions are.)
emacs here, it's vanilla slime + a hyperspec lookup keybind + .my highlighting settings
Dude, OP, you're coming to a decades-old community (Lisp in general, that is) and demanding that things be arranged for your convenience. You also say shit like "At no point have I indicated anger at the communal incompetence displayed in this thread" - the sourest passive-aggressive sulking sentence I've seen this week. *It should not be surprising to you that you're not getting a warm reception*: you are fundamentally assuming that you are the most important person, that your existing preferences and habits won't need to change at all to learn a new skill, and that your personal issues with the community and the body of work that it's centered around, are more important than the cultivated-over-decades community consensus. This makes you about as welcome as Todd Akin at the Michigan Womyn's Music Festival. * You can say: "Lisp is difficult!" * You can say: "Emacs is difficult!" * You can say: "It's tricky to configure SBCL!" No one will argue with you. Everyone gets that there is a learning curve. People are clear on the fact that Lisp requires some adjustment, and the community has had an internal conversation going on for donkey's years about these issues. No one's gonna harsh on you just for saying those things. But there are things you can't say if you want to still be welcome and have a productive discussion. * You can't say: "Emacs is a deal-breaker, so is Vim, and I'm not going to use a commercial Lisp implementation. I demand you point out to me another way." * You can't say: "You folks don't indulge my demands, therefore you don't know what you're talking about and Lisp is bad." * You can't say: "I don't care about your opinions just give me an answer!" And you've said all of those things in this thread. You are the aggressor here, dude. Your interactions with /r/lisp are indicative of *you,* not of the Lisp community. You are behaving like a greedy, petulant, whining child. The reaction you're getting is a community of adults trying to get you to calm down and try something different: I would lay down good money that you'll get no warmer a reception in /r/python, /r/ruby, /r/clojure, /r/haskell, or any other programming community. 
195's only rule is that you can't leave without posting
I use emacs with SBCL. I use (ql:quickload "quicklisp-slime-helper") to get slime set up. Then I add paredit. I bind RET to newline-and-indent. I have a few personal bits of elisp to insert file header comments and in-packages into source files with [F2].
&gt; virtual memory manager could co-operate with the garbage collector much more Yeah, this is theoretically one of the benefits of the Symbolics microcode being Lisp-aware. GC invariants were enforced by microcode, things like forwarding pointers and broken hearts were supported transparently by the memory subsystem, and (I've heard) the GC would avoid or postpone following pointers that would require a page fault. But my larger point was that GC performance is only a modest fraction of total time. You're going to do very tricky development, and in the end, maybe you save (wild guess) 10% performance in a few Lisp apps. Is it worth it? Maybe you can publish some papers on it. Maybe ITA would find enough benefit that they would change how they do things. (Or maybe they've got other lower-hanging performance fruit.) Maybe the savings could be greater, but you ought to benchmark realistically before you start. &gt; there's theoretically no need for memory protection, and the kernel could run several processes in the same address space I'm not sure about this. Just because you got array bounds-checking "for free" in the LispM doesn't mean a malicious program couldn't use low-level primitives to trash memory, or fake pointers to point outside of your allocated space. I think there are substantial benefits to separate address spaces for processes that don't need full sharing, with carefully designed sharing mechanisms to expose the stuff that the process wants to expose. &gt; operating system would have to be able to trust all programs, so the compiler would have to be very reliable, maybe it should even be part of the operating system itself. This seems unrealistic: I need source for all of my apps? My compiler and kernel are joined at the hip?
Imagine someone trying to do some .Net under Windows and doesn't want to use Visual Studio. Sure you can use plain notepad and compile everything by hand, but that wouldn't be optimal, right? This is the same. The most suitable editors for Common Lisp are those that integrate not just editing but also evaluation, looking up functions specs and documentation. So you can choose vim/emacs/commercial implementation or start writing your own editor.
Perhaps if you weren't trolling the community you wouldn't have to be so afraid. People have already sugested you some alternatives. Short of buying a commercial product or writing your own editor, what do you expect? Go cry somewhere else.
Lisp doesn't need you. It is obvious it is not for you. It is you who is not ready.
A single response would have sufficed. Also Lispworks only allows your files to be a certain size, if they get too large, it won't let you edit them. Eclipse is a problem all its own. And Cusp hasn't been touched in years. My team members are my roommates and if my Lisp exploration fails, we'll keep writing Go/C#/Haskell (I write Go, best friend writes C#, etc) Speaking of not ready, Lisp is one of few languages I can think of whose community hasn't reached out and created a real solution. Ruby has RubyMine (or something), Java has NetBeans, Python has IDLE (amongst others), I mean, just about everything other than that can be done in Geany with syntax highlighting and a terminal embedded. I plan to fiddle with Racket after work tomorrow, but I'm not shitting myself with excitement about it. The thing about Emacs is that if it takes any time at all tolearn it, I'm not interested. I guess I see how that can come off as ignorant, but I don't really care. Even if it works, I'm not going to sit around learning an editor when I can better spend my time in a real editor writing real code making real money. (a little anyways...) I'm not saying that emacs doesn't work. I never said that. I'm just saying that it doesn't fit my needs and I don't want to use anything resembling it. Also &gt;imagine trying to do .Net under Windows kill me 
&gt; Speaking of not ready, Lisp is one of few languages I can think of whose community hasn't reached out and created a real solution. There is a real solution. One which satisfies the majority. You are in the minority, so your either find your way or... you get the picture. No one is going to write an editor when there is already one that works.
yes, there is no foolproof, script-kiddie-grade turnkey solution for common lisp. Most lispers do not think this is a problem. This is probably a tradeoff that privileges quality over quantity of users. If you don't like this state of affairs, either you take a detour to php-land, or you organize an initiative to write the lisp editor of your dreams. Everything else is just trolling.
Programming in common lisp is really hard bro and its not worth it . It requires intelligence, patience hard work and dedication to make it to do something. And those old farts clearly designed Lisp language for solving impossible Problems. Not regular problems.since we are Facebook generation we don't need any of that. why do we need to do impossible. why do we need to create solution for the impossible problems. What we really want is elegant solution which these old farts call junk food . try Visual Basic.NET and they have Visual Studio editor which is awesome. use Java we have IntelliJ editor. We can do awesome things on that like creating fart application etc. . This community is filled with load of craps who wants to change the world and make impossible possible. Do you believe these guys want to make Machine do the Thinking. what a load of crap. just stay away from these guys. p.s : hey dude did you bought the iPhone 5. if yes that's awesome bro. Fantastic dude.
What do you make at the bakery? Isn't that a bit of a waste of your potential?
&gt; I think there are substantial benefits to separate address spaces for processes that don't need full sharing, with carefully designed sharing mechanisms to expose the stuff that the process wants to expose. If processes are totally independent there's very little to gain with sharing the address space. &gt; This seems unrealistic: I need source for all of my apps? My compiler and kernel are joined at the hip? Distribute intermediate/byte code and run that, like Inferno. Optionally translate it into native code.
Actually, there's a good chance that someone will get around to it, and when they do, you'll see the Lisp community grow a great deal.
People stopped writing new DO loops sometime in the mid-90s. You can safely ignore DO. Reading them is a useful skill if you're maintaining old code, I guess, but otherwise you can pretend they don't exist. The other looping constructs (like dotimes, dolist, and loop) are almost always a better choice.
But Lispm's were integrated software distributions, too. They weren't really a kernel plus some user land stuff you installed. It was a big ball of stuff: basically combining an OS, full development environment, e-mail, network chat, file-sharing, etc. And there was no isolation for you to "secure" things. It's one big process that also includes all the code and data in the system.
I learned from On Lisp and spent a long time becoming fluent in DO. Xach is right, don't do the same. It is basically a waste of time. The construct makes for some pretty hard to decipher code. I would like to add Iterate to Xach's list, though. It is not in the standard so you will have to download it and install it on your own or use Quicklisp. It is very similar in capability and feel to "loop" but adds quite a bit in terms of extensibility as well as maintaining at least a guise of code uniformity (basically wrapping complete statements in parentheses).
do is very useful if you're writing a macro with an interface analogous to `dolist` as you get things like the optional tagbody etc for free. other than that, I haven't used it for anything.
emacs 24 + slime + paredit + w3m emacs browser + local hyperspec + elisp hack to open hyperspec in other window + w3m bookmarks to library documentation + egg for git
I will second the recommendation that other constructs are likely to be your first choice for iteration, and that the gigamonkeys link is a nice LOOP tutorial. That said, I would like to answer your question anyway, but I am not sure which part of writing DO loops you are stuck on. PCL also has a subsection on DO, and I remember the illustration of DO forms "with the skeleton in bold" helped clarify them for me. http://www.gigamonkeys.com/book/macros-standard-control-constructs.html
&gt; Not very elegant, but achieves the same semantic. It is elegant in the sense that it vastly improves the readability, if the example is more complicated than yours, and especially if somebody else wrote the code youre trying to understand. Loop is a small DSL, and the point of a DSL in the first place is to express intent more clearly than a general language construct would do.
It seems quite a lot of people go through a denial phase before finally conceding themselves their eternal love of parentheses.
Relax, folks; this appears to be pure satire. Look at the once-only macro definition at the bottom. Nobody would seriously propose that is any kind of syntactic improvement. :)
"If on the next line occurs nestation..." indeed
If I could upvote this article more than once, I would.
And, yet more of your badassery. Frickin awesome.
Major update: http://www.hexstreamsoft.com/projects/positional-lambda/ I did not yet significantly improve the documentation. I want to make a great documentation system first...
I need to check out quickproject, I've been use cl-project which creates a slightly different set of files and puts the main code in a "src" folder.
See also [cloak](http://lichteblau.blogspot.com/2007/08/cloak.html).
I'm disappointed that the author of this project missed this golden opportunity to write a JVM in Clojure.
You were really hoping for a 'Yo Dawg' moment, weren't ya? :)
You know it's finished when the Clojure JVM can run Clojure running the Clojure JVM running a Scala program at a reasonable speed. 
That should be at least as fast as CRuby in that configuration.
http://memegenerator.net/instance/27681491 (last meme I promise :P this was the funniest sub-thread I saw all day)
Perhaps the author wants to write his GUI front-ends in SWT or Swing and write his logic and datastructure back-ends in CL... I feel like Armed Bear is the opposite of this project (JVM CL implementation)
I wrote the original article (but did not submit it this time) and I want to emphasize tarballs_are_good's point. Reader macros are crufty and gross, probably don't use them. 
Basically because BOX is a placeholder for a facility that I haven't gotten around to implementing yet, so its representation does not matter in its current form. Bear in mind that folio is a way to have a subset of bard in Common Lisp; some of the implementations of bard have boxes that are thread-safe updatable containers for passing values between concurrent processes or threads. In one of the implementations, boxes (which I sometimes call cells when it doesn't bother me that I might confuse users of Ken Tilton's cells) were implemented as Erlangish mailboxes. You could pretty easily make an argument that I should just pull boxes out of folio (though in one case I actually used them as a convenient way to sprinkle mutable places through immutable graphs, and that was so handy that it's probably why they're still in there). But an equally true answer is that I usually start building things without paying the slightest bit of attention to efficiency, and then worry about efficiency after I've figured out what I want things to do. Boxes are in an arrested state of development; I haven't used them enough to care what they cost.
Who cares. Why run a web-server under windows when you can get a Linode instance for $20/month.
Why can't you use REMOVE-IF and REMOVE-IF-NOT? Buncha sequence operators take a :test argument that lets you specify a test-function (aka "comparator") E.g [1]&gt; (setf vals '( a b h g g k l o p g b b b)) (A B H G G K L O P G B B B) [2]&gt; (remove-if (lambda (sym) (equalp sym 'g)) vals) (A B H K L O P B B B) [3]&gt; (remove-if (lambda (sym) (member sym '(a b))) vals) (H G G K L O P G) Familiarize yourself with the rich offerings of Common Lisp sequences. If creating unique sequences at the start is superior to filtering, then you can use PUSHNEW, again, with a test function of your choice. 
Too much magic, and I'm sure that second AND will always fail (and (setf once t) nil) 
AND does seem kind of weird compared to PROGN. This is a pretty nice example of the use of non-functional higher order procedures!