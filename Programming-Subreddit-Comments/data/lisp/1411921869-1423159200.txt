Afaik Huang is not a transpiler
Yeah, it's blurry, it's not text to text, but text to python AST.
The traffic is so low here that it actually is useful. Reading the release notes is helpul and occasionally there is a good discussion about one detail or another. I would say yes.
(loop for c across "convert s and S" do (cond ((string= c #\s) (format t "th")) ((string= c #\S)(format t "Th")) (t (format t "~a" c)))) -&gt; convert th and Th
Using the package I built (glyphs) which reduces some lisp verbosity, you can do it with: (ql:quickload :glyphs) (in-readtable glyphs:syntax) (ƒ listh ~"s"~ → |"th"|) ;; This is the function definition, call with (listh "Lisp rocks") You can see the package source at https://github.com/ahungry/glyphs 
Any particular reason why you'd want to translate Lisp into Python? Python is pretty bloody slow. 
Not so brief: (do ((str "So it was") (i 0 (1+ i)) (acc nil) (map '(("s" . "th") ("S" . "Th")))) ((&gt;= i (length str)) (apply 'concatenate 'string (nreverse acc))) (let ((char (subseq str i (1+ i)))) (push (or (cdr (assoc char map :test 'string=)) char) acc))) 
Sort of, but all macros are reader macros and are not the same sort of reader macros one might know from Common Lisp. They are really more like source-&gt;source transformations that are applied to a source tree until they reach a fixed point. { ... } syntax isn't special, it's just part of the define macro; "-&gt;", "--&gt;", "{" and "}" are symbols with no special meaning like using "=&gt;" in scheme.
Are you Icelandic? You know, the name. And why tree?
I'm not the project author, just stumbled upon it and came here to see if redditors knew about it.
Nice. Must check cheap flights.
It's bi-bidirectionally interoperable, which means all of Python's ecosystem is compatible out of the box - Python can even call into Hy just as well as calling into Python - Django modules work great in Hy :) Also, I'm surprised slowness is the main issue, stuff like mutable data structures and it's scoping are usually the main pain points. 
Oh, I see. Well.
[The spec](http://clhs.lisp.se/Body/f_descri.htm) says it must return No value. The nature of this function is implementation- and object-dependent, so there's no specified structure for the information it outputs.
If you try it out, please let me know what you think (and any suggestions)!
Thanks, at the bottom there are some ASCII options as well (for those who dislike having to bind non-ASCII keys)
But it would be nice to have access to the return value programmatically: CL-USER&gt; (describe '+) ((:lambda-list . '(&amp;rest numbers))) 
http://clhs.lisp.se/Body/f_desc_1.htm#describe-object describe depends on this
I should probably remove from the listed binds, it was one I was going to make useful, but ended up using it for an internal bind when the regex replacement goes on (it holds the last used regex pattern).
Ahm, something is not working (quite likely my setup: quickly installed clisp, slime and quicklisp to check it and probably missed something. It's essentially complaining about ƒ and the rest not being defined, after correctly (I think) having loaded glpyhs via quicklisp
Awesome.
Did you make sure to: (use-package :glyphs) Or have in your defpackage? Otherwise you'll need to use; (glyphs:ƒ 
:smashes head against keyboard: Been too long since I used Lisp for anything, so forgot all the details of library management. Damn! 
Very neat! Given that you're introducing a kind of infix syntax to common lisp, I'd like to recommend [my proposal](http://web.archive.org/web/20140404005121/http://akkartik.name/post/wart)[1] for adding infix to lisp in an extensible way without compromising homoiconicity. Every proposal ever made for adding infix to lisp ends up making compromises to either homoiconicity or precedence. I slice the knot by adding only one single precedence rule: operators not surrounded by spaces expand before operators surrounded by spaces. So this works as you would expect, unlike just about any other programming language in the world: (n * n-1) The drawback, so far, has been giving up dashes in variables, which I've never been happy with. But now you could steal yet another idea from APL and use different glyphs for hyphens and subtraction! [1] Sorry, my site is down while I wait for the fog of shellsock to settle down.
In my very humble opinion the students are going to see a lot of material but very few examples of programs in Lisp. The reference slides are very complete but the students are not going to use all that material and probably they are going to get very bored. I think they could enjoy using Lisp if there are some examples. This is the flip side of Land of Lisp. This is like learning to speak reading a dictionary. I apologize if this is a little harsh but I believe that this is not the right way to do things, fortunately this is not my duty. 
&gt;A free, acceptable Lisp, with a working FFI Has existed for years. 
It looks more lispy than my solution but I think it's a little confusing. You can test it with (time ...) and compare with mine. You will see that my solution is very more efficient. Nevertheless I'm a very beginner and I respond to you only for getting your advices. If a lisp veteran come here he will surely laugh seeing what we are doing here... I remember a post where it was saying that printing string in the lisp repl was consuming a lot of time. Maybe redirecting the output of our code directly to a file (or somewhere but not to the repl) would improve our code.
C++ is about not using GC, using restricted numbers and the like. So the interface between C++ and Lisp requires to split the task using C++ this way is like using a FFI. In the end the best thing is to have a very good FFI. I recall there is an automatic FFI summer of code project. To show the limitations of using C++ and Lisp, for example in Julia there is no automatic conversion from floats to bigfloats or from integers to big integers. The same limitation happen with general lists, Julia (LLVM) is not well suited for general list, you have to use a list of unsigned integers or similar to achieve good speed. Clisp and ECL are abandonware and the lesson to take away is that speed of execution is a very important feature. Python and Ruby are trying to survive the new age of Haskell, Lisp and Go. The GIL that limit parallelism and concurrency is such a burden that many developers are thinking in ditching python. Purish or peril here is fight for speed and perfomance or die. 
Please point me in the general direction of that then, because I haven't been able to find one which would allow you to register lisp functions as callbacks in place of c pointer to functions. admittedly it may seem like a small complaint, but it would mean I could experiment with an idea for a new gui system that I have been meaning to play with for some time now.
&gt; The developer already has plans for a faster version of Clasp coming soon that should offer significantly better performance over other Common Lisp compilers. I wonder if that was supposed to be "significantly better performance than it currently has, close to other compilers".
Yeah after seeing your implementation with LOOP, I wrote it with DO as an exercise. I knew it would be more verbose but it was moreso than expected. I'd say the reason its slow is that it conses, traverses and mutates lists rather than just stepping over an array and writing to a stream. Edit: Also it doesn't declare any types, constructs a string to return and has a less verbose way to expand the map of substitutions, so they aren't equivalent. I did run it under TIME on SBCL 1.2.0 and found it to be faster than your LOOP on the same string, but benchmarks are hard to get right and usually premature anyway.
for some fixnum value of 'close'
Those are some broad and ascerbic brushstrokes, and I accept your point of view, but everything exists in a context and privileged perspectives usually don't last. Behavioural economics has brought the differences between social and market ethics into sharper focus. A transaction can be seen as mutual giving in the context of a social bond, or as mutual taking in the context of an efficiency seeking market. The sense of obligation and what is appropriate behaviour differs based on this. I believe a healthy open source community is predominately in the former mind-set. The sense of fairness inherent in higher primates has some basis in empathy, and this is reflected in human culture by phrases like "price gouging". In the ecosystem of many open licensed languages, a language that is less open is perceived as a signal that the commitment to that language may not be repaid by an ongoing commitment to openness by the licensor. Given that the rights pass on to your next of kin, I assume they are free to tighten the screws whenever they like. Also there is considerable conservativeness in the legal community, and software even in licenses as open as the WTFPL may be barred from use in an institution for the simple reason that legal consensus is expensive to achieve and a fringe license may never have it. I appreciate the desire to have a small set of licenses for software, in the same way that I expect high quality software to employ common, well understood interfaces. I believe the existing contribution of Ki/Shen is already significant and I don't want to downplay that, the things that have held me back from learning Shen more are limited time and attention (and budget - the books aren't cheap). But I also understand why the peanut gallery sometimes prey on the license - initial/surface impressions have weight and its easy to take offense from text streams. Thanks for engaging with me on this BTW.
For C yes, for C++: no. Especially in game development where C++ libraries (without C APIs, because, hey, who uses any programming languages other than C++ for gamedev?) run rampant I've been longing for an easy way for Common Lisp and C++ to interact.
Thanks mate. I joined the guys there, and had a nice and chatty evening! Looking forward to the next one.
Native French speaker here. I read some pages of "Traité de programmation en Common Lisp" which I suppose is what is going to be taught, and I can't disagree with what you say. The course seems very theoretical, and doesn't have example of "practical thing", like, say, how to use common lisp to read a file. I am curious of the expected level of the students. Do they have some previous exposure to programming? (In France there isn't any programming course in high school, so if it's a first year university class they won't have in theory previous experience in programming). When I was myself student, I was taught Excel VBA, C, and C++ - I studied maths and statistics, not computer science, so the programming part was a bit weak. Now I think I would have liked to be introduced to Lisp instead.
I'm making a game in Common Lisp and the most important libraries are all C based. I don't see a use for CL and C++ together. I started with C++ and moved away to CL as there's no point in C++ for a game engine for the kind of game I'm cooking (I would go as far as to say most games in the Indie category don't require C++ speeds). Most people considering C++ for game development will probably also use Lua or some other scripting language; there's really no point in integrating CL when the entire game can be made in CL with some C bindings. Even then, for most games Unity is the best option.
It's only half the teaching, they also have the "TD" (Directed works?), where they have exercises to complete under the supervision of a doctorate student.
I found the way [Common Lisp: A Gentle Introduction to Symbolic Computation](https://www.cs.cmu.edu/~dst/LispBook/book.pdf) organizes itself lends to a great balance of reference, guiding, and testing understanding. The appendix was nice as it shows some more realistic lisp use cases with its DTrace and SDraw tool examples. The lack of problems to test the reader against was the main weakness of the Land of Lisp book imo and where it can improve to an exceptional book rather than just a good and fun one.
Another way to do lambda symbols in Emacs: (add-hook 'lisp-mode-hook (lambda () (font-lock-add-keywords nil '(("(\\(lambda\\)\\&gt;" (0 (prog1 () (compose-region (match-beginning 1) (match-end 1) ?λ))))))))
Not at all; happy to discuss. The rights actually don't pass to the next of kin. In the event of my decease they actually pass to the 2011 committee who helped to port the work to different platforms. In effect I cannot change the license and transmit the change without securing their unanimous agreement. http://shenlanguage.org/2011committee.html This was set up very early.
I wouldn't agree. If you are going to use sequent calculus then you'll find that the notation that logicians have evolved is actually very clear. Not surprising because this notation has become accepted during an evolution of 70 years, is used in scientific papers and existed prior to Lisp. Anybody who knows sequent calculus would be able to read Shen datatypes w.o. trouble. That said you *can* treat sequent calculus definitions in Shen as s-exprs for the purpose of compilation and there is an internal form which is an s-expr. It is not especially easy to read and was not designed to be so.
I don't agree with your understanding of Lisp. You are mixing the superficial syntax with the deep ideas; see the discussion of genotype and phenotype here. http://www.marktarver.com/next.html But if we limit ourselves even to syntax, I don't think that visually, Lisp programs help programmers to grasp programs. Reducing everything to what one commentator called 'porridge with finger nail clippings mixed in' is actually not a good move because it deprives you of visual clues as to what is going on. We are creatures of vision. Humans beings process visual information at a faster rate than the linear process of intellectual cognition based on semantics of what is written. 
Good. I'm assuming this is coming from Hans Hübner? Then it will get into Hunchentoot. 
I don't agree with *your* understanding of lisp. The visual syntax is a *key* part of the language. Macros work because everything is a list and everything looks like a list. I have no idea how to decompose `X -&gt; (and (number? X) (&lt;= X 0)))`, but decomposing `((X) (and (number? X) (&gt;= X 0))))` is trivial. Larry Wall is hardly one to be commentating on the visual appeal of programming languages, given the disgusting inelegant inconsistent mess that is Perl. Also, that article is *awful*. &gt;When the CL community is exposed to criticism of CL their attitude is confrontational and conservative. For example, nearly every other newbie who hits CL for the first time complains about the brackets. And when they do they are told to shut up because they don't understand Lisp. Actually that response shows that the shushers don’t understand Lisp, because the Lisp genotype is not hung on the idea of brackets. Guido van Rossum realised that in creating Python. Python is not new; its just a sugaring on the Lisp genotype in favour of a syntax that people feel comfortable with. And look how far that idea went. Python isn't even close to Lisp, by the author's own definition. Recursion isn't the primary means of expressing procedure calling, whatever that is meant to mean. Recursion isn't actually in any language the 'primary means of expressing procedure calling' in any language, of course, because that doesn't actually make any sense. Heterogeneous lists aren't the way of composing and dissecting complex data in Python. Programming by defining functions has nothing to do with Lisp. Every single programming language in use today and for quite some period into the past has had a way of defining functions, and it has been the primary way of organising code. Garbage collection, sure, but while garbage collection is an important part of lisp, it doesn't turn something into Lisp. Programs *certainly* aren't data in Python. That's the most important aspect of Lisp, and it's the one that is most clearly and most starkly missing from Python. &gt;Along with all these ills went another - macro laziness. CL programmers think that macros are absolutely central whereas they are not. Macros are absolutely central. That is indisputable. The author said it himself when he listed "programs as data" as an important part of Lisp. &gt;‘CL is great and Blub is crap’ has not worked as a strategy for selling Common Lisp. Who actually cares? Enough people use Common Lisp for there to be libraries for just about anything you need to do - concurrency, etc. are all there, despite what the author might think. If there aren't libraries to do what you need to do then you can write them very easily and with a small amount of code. That is the strength of Lisp. Blub *is* crap, and CL *is* great. etc. etc. etc. The whole article is just a puff piece for the author's shitty Qi language that he wants to rule the world. It hasn't and it won't. 
Is anyone out there creating builds for Windows? The last binary from the official site is 1.2.1. Couldn't these builds be automated so that when there's a point release they're produced for all the main platforms?
Macros work because everything is a list and everything looks like a list. I have no idea how to decompose X -&gt; (and (number? X) (&lt;= X 0))), but decomposing ((X) (and (number? X) (&gt;= X 0)))) is trivial. It says a lot for what you don't know that all Qi/Shen programs are lists and data. Every Shen programmer knows this. The reason you don't know this most basic fact is because either you have not read or assimilated anything on this work. Anybody with that level of ignorance is really too clueless to be worth bothering with.
Is GCL being resurrected? How ANSI compliant is it?
Thanks Christophe. Appreciate the reading and study! /me bows.
Perhaps the bit-rot of Clisp has prompted this. It says it targets CLtL1, so I'd guess until that changes there will be important differences. http://en.wikipedia.org/wiki/Common_Lisp_the_Language The notes for the much older GCL 2.6.2 mention greater ANSI compliance as a goal. I just built 2.6.11 and though LOOP is present, DEFCLASS is missing and so is HANDLER-CASE.
That's not an ad hominem. That's saying "Larry Wall's *opinions* on programming language visual appeal are irrelevant *to me* because Perl (his creation) is ugly". 
How about compiling with the `--enable-ansi` config option? AFAIK GCL compiles for ANSI compliance with it. E: redundant stuff removed, word order
I'm not sure I understand the thought process behind this.
`set` takes a symbol and a value and sets the symbol's value to the given value. If you know the name of a symbol then you can set it's value like this: `(set 'sym val)`, where val is evaluated as normal. Because this pattern is so common `setq` was invented to save quoting the symbol. So `(setq sym val)` does the same thing and `sym` is not evaluated. `setf` is a later invention that generalises it to more "places" other than just a symbol, notably you can do `(setf (car x) val)` instead of `(setcar x val)`. In the case of `menu-bar-mode` etc. those are also functions, so you are merely calling those functions with a parameter of -1. In my emacs lisp I tend to use `setq` only. In common lisp you should use `setf` almost all of the time.
Well, you should ask your question to [r/emacs](http://www.reddit.com/r/emacs), but what you misinterpret as “mode variables” are just functions: for example, (line-number-mode 1) just calls the function named *line-number-mode* with the argument 1. It's strictly equivalent to M-x line-number-mode Now, the difference between set, setq and setf. Emacs Lisp is what we call a *Lisp-2*, that means a variable name (like “scroll-step” or “foo”) is actually bound with **two variables**: one inside the “functions space” and the other inside the “values space”. It means the name “foo” can denote a function **and** a value. For instance: (defun foo (x) (* x 2)) ; foo denotes the function that multiplies its argument with 2 (set foo 5) ; foo also denotes the value 5 (note semicolons mark comments) How do we make the distinction between using the value and using the function behind foo? Well, in Emacs Lisp (and Common Lisp), you generally call a function with the syntax `(myfun argument)`: then every time your name is preceded by an open paren, you're talking of its function, and otherwise your talking of its value. Example: foo ; =&gt; 5 (foo 2) ; =&gt; 4 (foo foo) ; =&gt; 10 If you want to access the “function value” of foo without calling it, you can explicitely get it with `symbol-function`: (symbol-function 'foo) ; =&gt; the function behind foo (funcall (symbol-function 'foo) 2) ; =&gt; 4 (funcall (symbol-function 'foo) (symbol-value 'foo)) =&gt; 10 Now, the difference between set and setf: set is used to explicitely change the *value* behind a symbol, while setf change *whatever* is behind your symbol. (set foo 5) === (setf (symbol-value 'foo) 5) (defun foo (x) (* x 2)) === (setf (symbol-function 'foo) (lambda (x) (* x 2))) And the difference between setf and setq is: setq is the old deprecated setf, do not use it.
Just a little joke. From the wikipedia: The primary meaning of shen is translatable as English "spirit, spirits, Spirit, spiritual beings; celestial spirits; ancestral spirits". In our material world spirituality can't exist without money. The author was thinking about paying a lawyer to develop his ideas in a license, then he realized that he would better get the money and use a standard license like BSD, I think that is the simplified thought process (just my 2 cents). 
I don't have an answer as I am about to dive into both. I just wanted to post that you might want to add this to your list: http://www.lambdanative.org/ A worthy option as well.
Very clear explanation, thanks man.
Very clear explanation, thanks man. I didn't want to post this onto /r/emacs because this was clearly a Lisp related question (and I didn't know the difference between Lisp and Elisp at that time).
mocl has the advantage of being under active development with a dedicated person supporting the project. It is also designed for mobile development. ecl is currently only semi-maintained and is not especially designed for mobile development or deployment. Personally, I'd try mocl before trying ecl. It's cheap as tools go and seems like it could give a decent head start.
I believe this uses gambit under the hood, which may be a viable option in itself (as well as chicken if scheme is even an option).
I had a project using gambit on iOS three years ago, but I'd like to try out a Common Lisp this time around. I think scheme has optimized for simple and learnable, whereas Common Lisp has gone for powerful and practical. Emacs integration of scheme is not as good as I hoped, and things like live code reloading were not well supported by the libraries I was using. It also didn't help that the gambit toolchain broke when Xcode 4.2 came out and I didn't want to maintain a separate Xcode installation just for this project.
Mocl is a nice development environment, though immature as of yet compared to other CLs (such as SBCL or Clozure). It is a *code generator* for iOS and OSX, just to be transparent. It does have an on device REPL though for simple debugging (but no defun, etc.). Several libraries require significant work arounds to use. (I haven't tried out the Android support yet.) That said,their support is top notch and often can get a fix in a matter of days when reported. 
Aha. That is very good feedback, I appreciate that.
I like the support status, but this doesn't go a long ways towards explaining the problems with ecl or the benefits of mocl. I've read that mocl is based on an old BSD licensed version of CLICC, but how is this better than ecl? 
Fuck that, data is free!
A CL isn't tough to make because of namespace decisions, it's tough to make because it has a lot of features and a typical CL programmer expects most of them to be suitable for real work. They don't want to hear something like "My CL implementation is great but streams are really slow and hash tables are EQ-only and it doesn't support displaced arrays and..." The bar is set pretty high by the quality of existing implementations. They've had _decades_ in which to improve.
The inverse (scheme in common lisp) is more common. See [Jonathan Rees' Pseudoscheme](http://mumble.net/~jar/pseudoscheme/) The book [Lisp in Small Pieces](http://pagesperso-systeme.lip6.fr/Christian.Queinnec/WWW/LiSP.html) does not hold to the CL-spec but does have scheme code to develop a CL-like implementation as well as a scheme-like implementation.
What is a linear list? 
(listp arg) will check if arg is a list
Yeah but it also returns T on the empty list NIL so is probably not a good test for atomicity. (atom x) seems a better choice.
Nil is the empty list and can be safely treated as a list. Which one he needs to use depends on why he's checking.
That's exactly my point - NIL is both an atom and also a list so you can't assume all things for which listp returns true are non-atoms. Of course if he merely wants to test for non-list then listp is fine.
also (listp (cons 1 2)) =&gt; T
Try (defun linear-list-p (list) (and (listp list) (every #'atom list))) Or something similar Edit: of course this isn't a complete solution as it doesn't deal with dotted lists but could be something to work from. There's prob other approaches too.
Ok, I think this is a confusing thing. Let's first start by defining precisely what you want. Do you want to return true if the thing is a list, and the `car` of the list is an atom? And otherwise return false? Ok, how do you check if something's a list? (sidenote: what do you want to do if you're just passed `nil`?) Then how do you get the first thing in it? Then how do you check whether that thing is an atom?
`consp` is the opposite of `atom` ie. returns true for a cons cell, or nonempty list.
mocl developer here. It looks like other comments already have some good points, but one additional one I'd like to mention is licensing. A number of issues have been raised about conflicts between FSF-style copyleft licenses and app stores. ECL is under LGPL which could be problematic. (See for instance http://faif.us/cast/2012/mar/13/0x24/). On the other hand, mocl's licensing is targeted to app stores and commercial applications. mocl is also unique among Lisp implementations in that it is very focused on integrating with official platform toolchains, like Xcode and the Android Developer Tools, rather than trying to replace them. I like to think that this gives you the best of both worlds and is very practical in terms of not making you give things up. Those tools have a lot of engineering effort behind them, and they can be very handy to have, or even indispensable for some things (for instance UI design, testing, working with native libraries, packaging your app for store submission, etc.). Finally, I would also add that various users come to mocl only after toying around with alternatives like ECL and running into problems (see [paines' comment](http://www.reddit.com/r/lisp/comments/2cs6qo/mocl_lisp_for_ios_android_and_os_x/cjili83)). I can't personally speak to what those are, but I can definitely say that mocl works out of the box, and I am continually updating it as iOS and Android evolve, to make sure that it keeps working without much headache. I'm not super familiar with ECL and there are probably some things I'm forgetting, so if you have any questions, feel free to ask.
Which is why effort spent improving the existing ones is probably better spent... unless you have something to prove or it's just an academic exercise.
 (defparameter *result* (testfun arg ...)) Is an easy way to suppress printing of the result in the REPL.
If you are using sheme, you may use (pair? arg)
Depends on the language. 
One of the big pains relating to Shen is the oddball license. 
Shen is a successor language to Qi, which is under a proprietary license, and so Shen is currently locked to using that license. Presumably this pledge is to either in some way buy the right to freely license Shen at their own discretion, or fund development of Shen to remove the dependency on Qi.
Holy shit, who in their right mind would take money from people for such a thing. It's not like Tarver is currently making money off it anyways. Besides a lot of shen was written as part of his Ph.D so this stuff should be in the public domain anyways. The UK gov already paid for that research.
Use EQUAL and CONS and iterate through the list.
My two favorite things in computing... NES and Lisp combined into one article! 
Excellent task. Don't hesitate to show us your solution.
http://www.gigamonkeys.com/book/they-called-it-lisp-for-a-reason-list-processing.html
Let's see... Lisp C Perl PHP SQL Yep, that's 6 alright. Mmmhmm!
Must have been written by a C programmer ... that's such a classic fencepost error!
I'm not sure how this would work, since according to Tarver its [not up to him](http://www.reddit.com/r/lisp/comments/2h8jbu/shen_a_sufficiently_advanced_lisp_by_aditya_siram/ckyrlkb). Perhaps there has been a unanimous decision to switch license if there is sufficient legal oversight.
One hint is that you wouldn't usually modify an existing list. Think instead of creating a new list like your return value. So the general algorithm can be something like "Go through the top level of the first list. Put whatever you find into the new list, unless it is equal to the second expression, in which case put in the third expression." The "go through the top level of the first list" part is what is meant by "iterate through the list". There are a couple of different ways to do that.
Ok so once you are used to the language the solution will obviously come to you very quickly but I tried to do it step by step in the hope the logic would become clear. So I started by copying your post and put it in my editor as a comment and started adding the constructs that mapped to what you were saying ;;I am back again in all my noobiness. (let ((e1 '(e f (g h) i j)) ;;This time I have 3 expressions (e2 '(g h)) (e3 '(m d))) ;; and i want to replace the second expression with the third expression (labels ((replace-if-matches (element-from-main-list) (if (equal element-from-main-list e2) ;;if the second expression appears in the first expression e3 element-from-main-list))) (mapcar #'replace-if-matches e1))) ;; as a first level element. ;;this should return (e f (m d) i j) As an exercise turn this into a function so you can call it with the three arguments like: (swap-it-match e1 e2 e3) Notes: * There are cleaner ways to write this, but this matches your explanation structurally. Making it better is an exercise for you! * (labels...) is how you make local functions we use this to encapsulate the single step. Wherever possible break you solutions down into independent chunks. This will help solve and maintain the solution * mapcar is a function which runs another function (in this case 'replace-if-matches') on each element of a list (in this case e1) and returns a list of the results. IMPORTANT: Look up info on all of these expressions and see the ways they can be used. It will help the next problem you approach. Lisp has less rules to remember than most languages but this means the ones we have are very important and compose in very useful ways. Good luck :) p.s. There is a function already in lisp that will do what you want. After understanding this example go look for it!
From the horse's mouth: https://groups.google.com/forum/#!topic/qilang/HBBjtIxegFY
Haha! HTML must be the missing programming language.
I especially liked the part, where CL-HTTP was this exotic web server in Lisp at the MIT. Then the White House called when they needed a web server and they got a Lisp-Machine-based web server as their publications site...
[proof](http://archive.today/RXVg)
99.9999% of the time you don't need eval. I have never used it.
No. No. Not memes here, the sub is small.
http://vintage-digital.com/hefner/misc/lisp-programmers.jpg This is the fourth top link of all time from this sub.
I don't have a bone to play with in this argument, but reading this late, I can't avoid commenting. Haven't you proved Tarvers "awful article" to be correct? You've played out the predicted stereotype to a tee!
The number of 9s in this expression depends on one's style and projects of interest. REPLs and GAs come to mind. Ironically, avoiding EVAL can at times look like Greenspunning on top of CL. I've only read a few bits and pieces about this boundary, when to cross it and tricks once inside, like setting current lexical values in the evaluated form, or calling functions that expose lexically bound state. Anyone know of a good read on the topic?
A related issue is that environments, like so many other things such as TCO, are left up to the implementation and tend to be opaque. It would be nice if the spec were more explicit about introspecting when and how these things are supported.
His 'predicted stereotype' was that people would say things that are correct and would defend common lisp. Is it surprising that that's true? 
And it's shit. No image macros here. 
Two wrongs don't make one right. ;)
[More about the game](https://en.wikipedia.org/wiki/Dark_Angael) at Wikipedia.
reminds me very much of [Abuse](http://lispgames.org/index.php/Abuse)
The whole thread is interesting. Game archived. edit: I just ran the game under win7 x32 ... ran fullscreen, color palette was off though. Surprised it ran so nicely.
I'm guessing the symbols use underscores because they map to C/C++ identifiers.
(define add X Y -&gt; (+ X Y)) Is a list. Nothing magic about the syntax. First token is define, followed by add, X, Y, -&gt; , (+ X Y) The arrow is nothing other than another symbol - symbols in shen can contain more characters than in other lisps.
Fukamachi, this is awesome! Thanks for doing this. I put in a good amount of work into http-parse (and so have you lately) but I never felt *great* about it like I do with some of my other libraries. The code feels like a bunch of subseqs and regexes slapped together that I never had the time to really optimize. There *needed* to be a generic HTTP parsing library for lisp, but I'm probably not the best person to make it. Also, between cl-async, drakma-async, etc etc I have a hard time keeping up with updates. Once this gets into QL, I'd be more than happy to switch Wookie over (and point http-parse to fast-http).
Currently much the code is compiled with SAFETY=0. Not a good idea in Lisp. 
Obviously it's faster because: 100.23% CPU... ;)
Reading his Twitter, is seems he's been working on getting Wookie+Clack to catch up to the performance of Node.js. It would be hilarious if a bunch of lispers beat the many man-millennia spent into making JavaScript fast :)
There are a few Fukamaki on Twitter. For who may wonder which account, https://twitter.com/nitro_idiot
It seems he is working hard on Wookie. https://twitter.com/nitro_idiot/status/520504037389520897 BTW, Thank you for `wookie`!
Have you seen teepeedee2?
I have, and I was pretty impressed, but the project seems abandoned and I couldn't build it when I tried to.
Why not? That's how C does it. :-)
&gt; That's how C does it. Exactly because of that.
Honestly it wouldn't surprise me. Lisp has some really great native code compilers and although the Node people have put in a ton of work to make JS fast, I'd be surprised if it compared with SBCL. Once I switch the backend for cl-async out to libuv (working on this currently), there's a good chance a Wookie app will beat its Node equivalent performance-wise.
I can't wait!
While I'm not a giant fan of the language (largely due to the bizzare inaccessibility of it on my platform of choice) I think a relicense would be good for it, as more people would be willing to put effort in to making the language with the slogan "write once, run anywhere" live up to such claims with greater ease. I'll probably contribute, but I think some explanation as to where the money is going is needed, especially considering that the (wise) choice of BSD is in lieu of hiring a lawyer to draft a new license, if I read the linked post correctly.
Discussion on HN: https://news.ycombinator.com/item?id=8449488
Yes, but the amount of money being poured onto Javascript optimization dwarfs the amount of money being poured into Common Lisp optimziation.
You're mostly right. But I'm really curious about how much resources have been spent into SBCL. This isn't a toy either born in a vacuum either.
&gt; Common Lisp has no feature that corresponds to Emacs's buffer-local &gt; variables. I thought the point of lisp was it has any feature you want because macros. 
Some interactive functions use `C-u` as a boolean value to mean "do something other than the default". The specific prefix value is not important. I wrote the initial implementation of this feature. Did you have a question about it?
buffer-local-variables seems like a necessity in elisp because it only had dynamic scope + no modules, with lexical scope the same name can refer to two different values/'places' no-problem
Thanks for checking, but I just wanted to post my findings in case anyone was curious about the interaction between the IDE and the implementation. I also wanted to re-link those really good responses about how to debug in SBCL.
From the link, for the lazy: New features in v3.0 * SMP Optimized -- perform simultaneous operations on index btrees * Compressed Indexes -- reduces database size by up to 50% * Regex Cursors -- efficiently match string values against regular expressions
`sb-ext:restrict-compiler-policy` is a neat feature. Another use of it is to recompile with safety to turn a mysterious failure from `safety 0` code into an error.
Except in Shen you pattern match, so it's not hard to deal with at all.
The article is about clasp, not clisp. The other things you said are irrelevant, as far as I can see. Also, there are several spelling errors, like "purish" rather than "perish".
&gt;new languages have been taking Lisp's concepts and _updating_ them for present-day users -- such as Clojure, a Lisp-like language built on the JVM. Haha
Oh yay, that sounds like a good idea. How lispy. Let's just leave all the hard work to the compiler. Lisp is all about small primitives. 
&gt; I thought the point of lisp was it has any feature you want because macros. True enough, but the cost of implementing a feature on an existing compiler/interpreter that wasn't designed with it in mind can be high. 
&gt; Javascript optimization dwarfs I see them
They were not common practices before the book. I haven't seen them much after the book, either, except from people who started learning CL from that book (and no others).
I think that LoL generally falls in the "clever" category. Which means that it's an interesting read, but many of the patterns presented there have a cognitive cost (in reading someone else's code especially) that is not always justified.
Personally, I use `aif` pretty much everywhere.
Is there a reason why nobody has considered Racket? It runs on x86, PowerPC, SPARC, MIPS, ARM, etc. I have it running on both my desktop and Raspberry Pi. It's a Lisp, but it's also a Lisp designed to create completely different programming languages that all integrate with Racket. In fact, Racket itself is internally made of multiple dialects of itself, and also supports R6RS Scheme, Racklog (Prolog like language), a Datalog implementation, Typed Racket (a statically typed version of Racket), etc. It's even supported Algol and a subset of Java at one time or another. It's not like Common Lisp or Scheme that is limited to macros that only transform s-exp. It seems like implementing Emacs Lisp in Racket would be more feasible in Racket than other Lisps, since Racket already supports multiple Lisps with different semantics. You just choose your language for the module by declaring #lang &lt;language&gt;. And the DrRacket IDE is aware of the syntax semantics of any #lang because they're all really just Racket behind-the-scenes. Here's an article showing how to make an adventure game DSL. Scroll to the bottom and you'll see Racket implement syntax that looks nothing like a Lisp: http://queue.acm.org/detail.cfm?id=2068896 http://racket-lang.org/ http://en.wikipedia.org/wiki/Racket_%28programming_language%29 
I'm a big fan of Racket, but it's way too big to embed so lightly in a text editor (even Emacs).
I think it really depends what you are writing. If I'm writing applications where the goal is a robust deliverable then I want to make the parts as understandable as possible and the edge cases introduces by the more exotic macros may be barrier to that. On the flip side while you are using lisp for exploration, you want every tools that helps you get ideas out of your mind and into the machine and if that means some crazy dsl then go for it! I certainly cannot think in the context of all macros he introduces in the book but I no doubt have my own set that would cause similar problems to others. Reading your question again, I doubt most these have their place in industrial apps. Some of concepts introduced in the efficiency chapter may be an exception though.
And likewise `awhen`, as both help to avoid errors.
I've found that one can use the same technique of hiding values in the scope in which a function is created in a lot of languages to guarantee privacy.
Guile is not dead, there's a lot of active development happening right now. This is easily disproven, [several branches are clearly active](http://git.savannah.gnu.org/gitweb/?p=guile.git;a=heads). Not to mention that there has been a large number of commits to Guile in the [relevant branch that BT Templeton is working on for this feature](http://git.hcoop.net/?p=bpt/guile.git). The community could certainly be bigger, but the project is *far* from dead.
Sorry for the very late reply, but I agree. That is why I was interested in this. Unfortunately, it looks like that despite what is available in QuickLisp and commentary here, I am not sure I could get Hemlock to work. This is a shame because, despite my love for my Emacs lifestyle (Arch running StumpWM, Emacs daemonized with tmux, Conkeror/FF with KeySnail), it would be cool to take the Lisp learning experience and what I like to call "Lisp culture" further in my own life. But I can already tell few have enough stable mental health to go up against that wrecking ball. Oh well.
Ok, you're right.
A project I want to do (but have not had time yet to do) is cook up Docker containers usable as Common Lisp base systems. With some work, it could lead to an extremely nice CL deployment system.
This project started out pretty much the way Vagrant did, as a minimum-effort "Just give me a VirtualBox system", but if there is demand it would be very easy to generalize to support multiple providers (VirtualBox, VMWare, Docker) and multiple sources of images (Vagrant Cloud or Docker base images).
And still, there is no amd64 virtual machine written in Common Lisp ...
Can you say a bit more? Is the idea that you have containers and within them a combination of, say SBCL, static content, and specified quicklisp components plus your own ASDF systems, with the Lisp compiled to FASL files or dumps? Perhaps with intermediate "build containers" which generate the FASL/images repeatably and hermetically?
Yes roughly. but there's also single inheritance in docker which is good for modularity
What does this even mean? There are Common Lisp compilers that target x86-64, and quite good hardware implementations of the architecture. With virtualization support, too.
https://www.indiegogo.com/projects/zero-plus-prototype-your-iot-product-in-seconds
&gt; (Another Internet of Things Board (But This One Has Lisp)) FTFY, OC author.
Make stuff like cameras available to you via the cloud. Totally doesnt support panopticon!
I like your suggestion of having subclasses, but even that seems like overkill for what I want to do. Arrays seem like the easiest way to specify type right now. &gt; instead of using classes which you prob don't need for your task. So in this case you think classes are overkill? Is it because classes incur some kind of overhead that arrays don't? I like having the x y readers, and I would end up defining those for the array too. Plus I would lose the (with-slots (x y)...) which I'm using for more than just my 2d vector.
Being able to extract the type-parameter from the type of either X or Y allows you to write (typep x 'integer) for (typep vec (vector-2d integer) TYPECASE facilitates this kind of dispatching on type.
First, accessing slots directly is considered a bad OOP practice¹. You should generally replace these *WITH-SLOTS* with *WITH-ACCESSORS*. Second, CLOS is a complex system involving lots of function calls and dispatching ; if you don't intend to use inheritance and polymorphism, there's no point involving all these heavy calculations. You can replace your class with a structure, and even an “array structure”². ___________________ ¹: http://en.wikipedia.org/wiki/Mutator_method ²: search “:type explicitly” in http://clhs.lisp.se/Body/m_defstr.htm
Oh ok I see. So WITH-ACCESSORS respects the access rights of the object per the :reader/:accessor options, while WITH-SLOTS provides direct access to the slots no matter what? I chose WITH-SLOTS simply because it let me type less, but my intention was to still have read-only access. A struct is probably more appropriate for what I am doing. I think the only reason I chose class over struct is because I can have readers of different classes named the same and there would be no conflict.
I don't think this advice is of much use for CLOS. I don't see much advantage of using accessors vs. slots. Especially since CLOS doesn't do much information hiding anyway. The advice is useful for other languages which have different OO systems and language features. An accessor makes mostly sense when it actually might be extended by functionality. Preferring structures over classes is optimization. Generally I'd prefer classes over structures.
It's not a feature if their OS can't be a target because of library license incompatibilities. 
The [learnxinyminutes](http://learnxinyminutes.com/docs/common-lisp/) page on CL should be useful, I think.
Regarding implementations, CMUCL is probably faster than SBCL if you are looking for performance, given the additional compilation features it supports, and is open source; but it also might be harder to build. CCL is good if you want a reasonably compact compiler and runtime, especially since SBCL &amp; CMUCL are a bit heavy in terms of memory and compilation times. To be honest, they're all more or less the same; CL is much more portable than the Schemes. Just pick the one easiest to install for your purposes.
to work with existing libraries, or just generally read good code you want to learn: 1. the package system for which i recommend reading: [this chapter](http://www.gigamonkeys.com/book/programming-in-the-large-packages-and-symbols.html) of "practical common lisp" 2. the prominant ASDF which is to common lisp what the build tool "make" is to C. Just so you can run any code from github and co. Have fun!
Oh so can I define methods for structs too? Yeah I clearly have a lot to learn about CLOS. It looks like defstruct has a :read-only option too, which is what I want. It seems like it isn't really possible to make a read-only class, if you can always setf the slots? Also I definitely see the value of using accessors over slots, I just didn't understand that I was accessing the slots directly.
And after you read those and have some practice, read every other book on Lisp you can find, and apply your newfound good Lisp judgement to deal with any wacky ideas and absurd statements.
Thanks, I've had onLisp kicking around for a while but haven't picked it up. You've given me reason to, and I shall!
Will have a look, thanks.
That's two for Practical Common Lisp; I'll have to give it a look.
Cool, you got composer and highlight-lisp as known assets...thanks for the nod! Looking great, I'm going to try integrating this into Turtl when I get a chance.
It shares with PURI some unpleasant non-safe declarations. I tried passing a displaced string to PURI once and managed to corrupt my image, since it declares everything a simple-string and has (speed 3) (safety 0). It would be nice to see benchmarks of safe code.
I wonder which applications need extremely fast URI parsing.
trivia: It's a play on きゅうり (kyuuri); cucumber 
Thank you. At first I thought it was the name of the dish in the picture.
Thank you for posting this!
It's nice in a non-blocking web/app server, where every moment spent doing something like parsing a URL is a moment not handling IO. Not that any of my apps really require that amount of throughput, but it's nice to know there are options available if I do some profiling and "oh shit! URL parsing is 60% of the CPU!"
It won't corrupt your image because all exported functions are declared as (safety 2). However, changing the type to non-simple 'string' might be useful if there's someone like you. The limitation doesn't make much difference in the benchmark.
Right. When I was profiling Wookie, I found URL parsing was the third bottleneck (the first is HTTP request parsing, and the second is libevent2).
Note that On Lisp isn't an introductory text; also PGs style differs from what is generally considered idiomatic (https://www.cs.northwestern.edu/academics/courses/325/readings/graham/graham-notes.html)
Unrelated question: will quri support unicode? A few of Wookie's users were asking to get puri-unicode merged into puri, but the puri maintainer never responded to our requests. It would be nice to support non-ascii routes in the various web frameworks.
Is this a Wookie issue or Clack? Ideally Wookie should be able to handle any string you pass back for a view, but maybe there's something bad happening that I can take a look at. Also when you say it bailed, did it throw an error?
WEIRD, confirmed. [Github issue](https://github.com/orthecreedence/wookie/issues/55). Thanks for the heads up!
Thanks for Wookie!
Can you access it by ssh without X11 forwarding?
Not really a lisp question. Why can't you run Clisp locally?
Just seems a bit overkill to get CLISP running.
I did this is because 1. I have had an emacs for my daily Cpp programming, I don't want to mess it. 2. Just a practice to learn how to build docker and make it useful. I know it's a overkill to some purpose, but it's 'lighter' than opening a virtual box and still useful sometimes when you want to just practice something like me :) Back to this question, maybe it's not so fit to ask it here, I would move it to docker sub once I known how. 
I don't set the sshd up, but I can run this image locally and gui started well.
The arguments for docker run are strange, $1 outside a function or script? 
How did you make it faster?
Your target language has built-in garbage collection and objects whose values are polymorphic? Lucky...
"Stream compile with gulp-jisp" 
Any documentation on what "early" means? Is it feature complete, but perhaps buggy?
"Untested" is the sense I mean. I don't know about feature complete.
A lot simpler: ParenJS | https://bitbucket.org/ktg/parenjs 
I've read PCL (which was fantastic), and I'm working on Norvig's book now, what would you recommend as a third Common Lisp book? I should state my biases, my first CL book was Graham's *On Lisp*. I came to lisp by way of Clojure and Scheme and I like those languages. But I want to give Common Lisp a fair go because a few my friends / people I work with really like it.
this problem is solved by referring [stockoverflow](http://stackoverflow.com/questions/16296753/can-you-run-gui-apps-in-a-docker-container)
What are the main differences from clojurescript?
I recommend emailing the authors. 
I dunno. After those two, start writing cool programs? I liked Lisp in Small Pieces, Winston &amp; Horn's Lisp, 3rd ed., parts of ANSI Common Lisp, parts of On Lisp. There are a bunch more books yet to read.
&gt;Stable release: 2.49 / July 7, 2010; 4 years ago Yes.
This is better asked on the clisp mailing list. 
&gt; Debian dropped it Eh? Seems to be available via [Debian package management](https://packages.debian.org/search?keywords=clisp) along with packaged CLISP modules. True not much development going on, but it's a robust Common Lisp implementation with conventient integration with Linux/Unixen, also runs on Windows and OS X, and has plenty of extensions. Not to mention [Clisp as a Shell](http://www.clisp.org/clash.html).
Debian has dropped it from the testing distribution. It looks like CLISP won't be part of the next release, Debian 8/jessie. It seems the reasons are build failures on some architectures, which blocked the removal of Berkeley DB 5.1 from the distribution.
I can strongly recommend SBCL as well
There were talks of it a month or two ago. If you search for "clisp" on this /r/, it pops up near the top.
It doesn't really mean it's dead, it could just be extremely stable and not needing to be fixed where it ain't broke. Or something of the sort.
"extremely stable" is a joke. For example, thread support is always experimental in CLISP. Both CCL and SBCL is better choice.
Please post back if/when you have any more details
I suggest you should use Emacs + SLIME. When I was first learning CL, I wasted time with Eclipse because I was scared of setting up SLIME in Emacs. After struggling with Eclipse for a while (i.e. balance parentheses manually is not fun). I suggest you to take a look at [jrockway's answer on SO](http://stackoverflow.com/a/1101605/496700). That's where I started with Emacs and SLIME, so you don't have to read the whole SLIME manual to set it up and get to play with CL immediately and productively.
Akamai uses Lisp? I didn't know.
&gt;Note that this code is intended to be used against the other HTTP/2 interopability client/server code linked above, and not necessarily any part of the Akamai network; nor is any feature herein indicative of any planned or actual feature of Akamai products or services.
Will do. No word yet.
Does a single implementation guarantee decades of stable, peaceful ecosystem growth? Much of Perl's supposed decline may be overstated, but claims of it might suggest something else - a single implementation may not guarantee that all of a language's users will perceive that it is surviving and growing... http://www.fastcolabs.com/3026446/the-fall-of-perl-the-webs-most-promising-language https://speakerdeck.com/stevan_little/perl-is-not-dead-it-is-a-dead-end
Haha, perl is declining because of many other reasons - primarily that it is not a particularly well-designed language. Sure, strings, quickly-written out scripts, but not much else. You should look at Ruby or Python these days for most of the problem sets that could involve perl.
Your guides are much appreciated, thank you. Also, the animation of the aggressive-indent-mode conveys the practical usefulness of the idea wonderfully. I will certainly be trying it out.
Interesting, also, much like on the also-supports-JVM(ParenJ), and native version. The native version is an interpreter though, afaics not a to-binary compiler. Someone, probably me, should make a 'noparen'. A language with syntax that makes paren. Probably me. It is funny, but true, *because* syntax is so superficial, we should do it, just make it *real simple*, which i know how to do. Basically two rules "beginners and enders" - parentheses, but multiple kinds, with some slight variations in kinds. and infix notation, and something to turn M-expressions into s-expressions.
Is SBCL good on Windows and Mac now? If it is not, I doubt it would be good decision for CL community. 
I think there are so many Lisp dialects *because* it is so easy to implement. If someone likes C, but wants to tweak it in some way, they usually don't do so because writing their own C compiler is hard. However, if someone wants their own Lisp dialect, it's relatively easy to create it.
I think you just answered your own question.
There are many priority-related choices in implementing a Lisp, and even some pure taste-based ones. There are many flavours because people disagree and can afford to disagree productively — by building the tool they want for themselves.
I've noticed something about what programmers do when they take over a project. When a project is large and unwieldy there's a strong desire to rewrite but there's a fear of breaking compatibility because the existing project is difficult to analyze; so people just keep doing bug fixes with the occasional large attempt to refactor large chunks of code. When a project is small and simple, a programmer is actually more likely to restart from scratch when implementing a new feature because it shouldn't take them very long to rewrite it and they think a rewrite is easier to do than to shoehorn a feature the code wasn't designed to do.
Actually, a C compiler is fairly simple compared with another language. There are about 35 keywords in ansii C. And the execution of a C program is very similar how the hardware works. http://tigcc.ticalc.org/doc/keywords.html 
Yeah, C is certainly simpler than a lot of other languages, but even still, just writing a front-end C compiler is still way harder than it is for Lisp.
It's not simple enough that there are dozens of toy C compilers made by undergrads entranced by the mind-expanding novelty of C.
This is a project I'm working on to make building lisp apps easier for my clients. What do people think of it?
The answer is in the question. I’m writing a new Lisp myself right now, Why? Well, I just don’t like the way other Lisp’s hang, as in they have become fairly bloated over the years with historical additions, and are full of archaic nonsense and clutter (OK, hold your fire Lisp devotees - that was rash of me!). I want a decent, clean, fresh object-flavoured language that I can build useful apps with. Hopefully others will too. I’m aiming squarely at iOS, Android and Mac OS X apps with this new tool. I’ll be posting some stuff here in due course and you are all welcome to play with the alpha version when I do. I’ve written a few implementations of Lisp over the years, the last one was, for my sins, written in PHP!! I used it to build a lot of database-driven websites, a fairly crazy concept I agree, but damn it worked a treat and saved me a bunch of time and trouble.
i love [stockoverflow](http://stockoverflow.com/)
OP see this is why there are so many dialects... :D
 main() { printf(&amp;unix["\021%six\012\0"],(unix)["have"]+"fun"-0x60);}
But... there are dozens of toy C compilers made by undergrads. Maybe they're not "entranced by the mind-expanding novelty", but they do write them in order to learn more about their own machines, and, of course, C.
 &gt; gcc test.c &gt; ./a.out unix 
This was the most informative answer to my question (which I could have phrased better). Thank you.
There a few toy C compliers out there, but writing a compiler for any ALGOL-like language is a far, far, harder task than for a LISP-like. You can literally write a basic LISP compiler in an afternoon. Probably the only thing simpler is a stack-based language like FORTH.
This is true. I was just pointing out that many have written toy C compilers.
I agree with you that implementing a complete solution is hard, but lisp only has a few special forms and the structure couldn't be simpler. If I had it in my head to write my own language, I might start with a Lisp 1, like scheme.
Writing a parser for a C-like language is harder than writing an entire interpreting lisp. 
Funny how you get down-voted for building a perfectly good Lisp in /r/lisp. Ah well...
Unlike most language families, the number of Lisp implementations is seen by many as a significant problem, because of the fragmentation of effort and reinvention of wheels well known to the elders. That explains the downvote, but it wasn't me, I hope your implementation is successful.
Well mostly it was meant to work similarly to buildapp but be very simple to use for the lisp illiterate. I use lisp a lot for my clients and having them able to download and install something without me helping has been awesome as I can get more work done and get to clients faster that actually need help. asdf and buildapp don't hide things that my clients don't understand or are worried to fuck with enough to make them feel comfortable to build and install things. I've never used cl-launch so I can't really comment in regards to that (though I need to try it). Hope that answers things some.
About "lisp implementation": I wonder if such a work: http://epsilonwiki.free.fr/alphawiki_2/index.php?view=lambdabook could be considered as a valuable lisp implementation, even if, essentially based on a regexp approach, it moves away completely from the academic approach. 
I predict your "new lisp" will become bloated with its own archaic nonsense in order to maintain compatibility with other implementations' archaic nonsense. If it can't run existing code out of the box, then it's not gonna fly. Ergo the OP's question, which, I believe has been answered. 
If anyone can make a lisp, ofcourse everyone will make a lisp. And honestly, looking at the various XML-based config-DSLs out there, it seems the problem is not strictly limited to the world of lisps. And I think we can all agree lisps are better :)
From this I will infer that clang is the superior compiler. Garbage code like this *should* be thrown out.
I know for a fact it works well on mac (it is in homebrew so super easy as well). It looks like windows is still experimental, but very few developers I know still work in windows, and none who are interested much in Lisp. http://www.sbcl.org/ source for windows.
Cheers, will check it out
Ditto. Au contraire erlang has not msny dialects.
&gt; Given how simple Lisp is to implement Is it? 
Damn it, 60$ for your homework, your laziness is grandiloquent.
common lisp will do
I would pay more but I'm broke. This is the best I can offer.
This is the most eloquent and elegant analogy I have seen on the topic of fragmentation. Is it original? 
I think yes, given the huge amount of lisp implementations existing out there. Of course, simple here should be taken in the proper context, we are in /r/lisp and not /r/learnprogramming or something.
It's not that hard. Maybe only a few hours if you steal the lexer and cut loads of corners. A friend of mine told me that C wasn't really turing complete because it didn't actually support infinite memory so I decided I wanted to see what C was like if we simply made `sizeof(X)` yield 1. Rather: * Every integral type had a sizeof 1, and a range from whatever [GNU MP](https://gmplib.org/) would get me. * Every pointer type had a sizeof 1, and would be a decimal float of {M,N} where M is the allocation number and N is the offset within the allocation * Every struct had a sizeof their cardinality of fields. Now while I don't think the above rules are a violation of the ANSI C spec, the real question I had was how much "porting" would I have to do in order to get C programs to run in such an environment. That is, if it was more or less than porting to some other strange architecture. Parsing was *by far* the most complicated part. I don't think I bothered to "properly" implement typedefs since it's so complicated, and my friend conceded that afternoon when I got factorial and the animal game working.
I first encountered aif and awhen in Paul Graham's On Lisp, 15 years earlier.
I'm criticizing the fact that you want to pay somebody to do your homework, not the amount of money you're willing to engage.
First off, it needs to be said, screw Springer for price gauging. I don't mind buying good books--and yes text books are low volume but higher price--but I'm not subsidizing their dead tree profit machine at that much per online chapter. If they have ~10 chapters at us$30 that's $300? Second, if you like this idea, also look at Connection Machine's C* parallel common lisp on 64k processors. Before its time? 
Danny Hillis's book on the CM is also a lot cheaper.
There was a lot of this in the academic air at the time. My first project as a grad student at Maryland was [ZMOB](http://www.ijcai.org/Past%20Proceedings/IJCAI-81-VOL-2/PDF/071.pdf), a machine that was going to have 256 Z80s. We had grandiose plans for it, including a distributed Lisp, but it never got past the sort-of-working prototype stage - our communication bus never really worked reliably.
Out of curiosity, what did you use to format papers back then? It doesn't look like LaTeX -- was it an earlier system?
Looks like troff. 
The problem is that a lot of new implementations focus on some niche application like "light-duty web scripts", pick up some very strange initial quirks, decide to postpone things like decent compiled performance, and don't even begin to think about things like exception handling or robust metaobject protocols. You end up with toy dialects that defy compilation, have lousy performance, lack basic facilities, but with creators and early adopters who are so proud of their baby that they refuse to listen to people explaining things that were basic discoveries from the early 1970s. See "Newlisp" for the most egregious example I've seen.
"One of the bibles of the LISP/Scheme world." 1. It's Lisp, not LISP. 2. It's a Scheme book that has nothing to do with Lisp. 
The Connection Machine book: http://libgen.org/get.php?md5=d026289f3e50944e47ee334922c7ba29 Great read and be sure to buy a copy if you like it. You can find plenty of used ones on ebay.
I couldn't agree more. I just don't understand why someone would seriously believe the answer to solving a specific problem is to design and implement a whole language and then solve the problem in that language. We've already got the best language and development environment there is (Common Lisp), learn it, use it, embrace it, and make it your own. Common Lisp can solve your problem, whatever it is.
FWIW I have been a professional CL developer for over 10 years, and still do not like On Lisp. I own /signed/ copies of PCL and PAIP.
really cool and I'm an awful mathematician
Troff, with bibtex in the chain for references. The IJCAI archival copy was created by OCR, as you can tell by the typos. My dissertation in 1985 was basically the same, with some figures drawn on our spiffy new Xerox Star workstations and physically pasted in.
And it only has 13 pages, 7 if you discount list of references, some code examples at the end, and pictures. Thank the Universe for shady Russian web sites.
Thank god for youtube's playback 2x speed feature. Really sound ideas here, even if they could have been presented a bit more concisely. Worth the watch. Btw, anyone know what emacs theme that was? I liked it.
I believe it is `tangotango`: http://pawelbx.github.io/emacs-theme-gallery/
Excellent video, I enjoyed the broad information, the demos, and especially the comments that reveal a real Lisper's persepctive and modus operandi. It is rare to find such informative and interesting video on Lisp. Thank you. Please give us more!
Thanks!
Is there a doc or readme anywhere?
Can you give an example usage? I have no idea what this is supposed to be or how it is used.
I use it on OS X, it looks like it's getting better, but before a year or two ago it has been having stability issues, at least on my systems. It's also been very painfully slow to start up (yet to see it on 10.10 due to MacPorts upgrade from 10.9), and at the moment I'm simply too ignorant to comment on anything else about its performance on OS X.
Is [this](http://en.wikipedia.org/wiki/De_Bruijn_index) what you're describing?
I'll have what he's having. 
Nice DIY video. If you do not like tinkering, check out lispstick as announced here: http://www.reddit.com/r/Common_Lisp/comments/2hplco/lispstick_common_lisp_development_environment_for/ Worked like a charm for me.
Hmm I was originally trying to submit this to see if it could be added to the 'Tutorials/FAQs' section on the right. Is there some process for that or just the will of the cabal? :)
since /u/lispm submitted it and he's a mod perhaps he'll see your comment and oblige :)?
No. Right column is already CL biased. CL is OK dialect, but it is only one of many Lisp dialects and it should be fixed. 
&gt; Probably the only thing simpler is a stack-based language like FORTH That's been my experience
One of the moderators here. Yes it favors CL. But this subreddit favors CL and the sidebar reflects that. This subreddit serves its users as a collective whole. Check the current front page or the top posts over any time period, CL-specific posts dominate along with dialect agnostic posts. These users have a greater interest in CL but also have interests in other dialects. The moderators ~~have never removed~~ *generally do not remove* posts based on the lisp dialect even when they had been reported (some users had complained about a certain dialect being posted). edit: **never** say *never* unless you check your facts. Two posts were removed about the dialect in question.
Every other Lisp dialect already has a specialized subreddit except for Common Lisp. The other dialects intentionally used names without references to Lisp to emphasize that they are not and dont want to be Lisps. It is the only remaining Lisp dialect with "Lisp" in its name, and the qualifier "Common" doesnt emphasize that it is just another dialect of Lisp, but that it is "the" Lisp.
[quicklisp controller](http://blog.quicklisp.org/2013/08/wish-list-parallel-fetching-in.html)
"flood" would be a severe overstatement. The user posted about one clojure link per day with the odd fact that he never cross-posted to r/clojure. Nothing became invisible or knocked off the front page. The user did not troll, manipulate votes or even comment. Almost all posts had "clojure" in the title. For users with a common lisp bent, it increased the noise level a little bit.
I haven't tested it on multiple machines, yet. And unfortunately, quicklisp-controller scribbles in too many shared spaces at the moment for it to build everything in parallel on a single system.
no. it was some troll-ish person who gave up and left at a point, iirc.
&gt; The user posted about one clojure link per day That is a lot on here though, though you are pretty much correct.
You could write a simple AI to play chess against a human player, using a database with moves, or alpha-beta pruning etc.
Hi, I'm really new to Lisp and programming in general, and I found this video fantastic. I'm sort of blundering my way around, reading A Gentle Introduction to Symbolic Computation by Touretzky. Is there any tutorials for emacs or quicklisp around? I can't really find any. 
i second /u/samlamamma's questions about which Lisp / what kind of program; but also, note that Lisps aren't necessarily inherently 'functional' in the same sense that e.g. Haskell is: cf. [this](http://letoverlambda.com/index.cl/guest/chap5.html#sec_1). (i don't agree with everything Hoyte says in this section, but i do think he makes some points worth keeping in mind.)
The lisp syntax and everything is data mentality makes it ideal for genetic programming. I'm working on using GP to develop a stock trading strategy using some of the common algorithms that traders use. http://stackoverflow.com/questions/1538235/what-are-good-examples-of-genetic-algorithms-genetic-programming-solutions
* emacs has its own built-in tutorial. also crtl-h f and ctrl-h k are your friends. you may also search [emacswiki.org](http://www.emacswiki.org) or look at the videos on [emacsrocks.com](http://www.emacsrocks.com) * slime has less stuff. but the home page has a couple of older videos. one is also on [youtube](https://www.youtube.com/watch?v=_B_4vhsmRRI). There is also lispm's video [Debugging CL-HTTP, using Clozure Common Lisp, GNU Emacs and SLIME](http://vimeo.com/77004324) * quicklisp is rather simple but Zach has intro [videos](https://www.youtube.com/watch?v=11wYPAy9qNw) 
These are all exactly what I needed, thanks so much! 
you might want to look at what [Gabor Melis](https://github.com/melisgl) has done. He [won the Google AI contest](http://quotenil.com/Planet-Wars-Post-Mortem.html) using lisp a few years ago. And also won the The [Higgs Boson Machine Learning Challenge](http://quotenil.com/Higgs-Boson-Machine-Learning-Challenge-Post-Mortem.html) a few months ago.
Hello @doomchild, Nothing particulary stands out to me as wrong. In `read-delimiters` you could probably use `alexandria:alist-to-hash-table`, but `setf` should be fine as well. 
I haven't heard of Alexandria. I'm assuming it's a utility library or somesuch?
Not a criticism of the code itself, but it could do with an example showing typical usage. I just tried to use it but realised I have no idea what API it's presenting. Maybe add to the readme?
That's actually on the list of things I'm doing either tonight or tomorrow. I've been using the library as something to do after work, so it's been kind of sporadic.
Yes. Alexandria is the most commonly used utilities library. It always tops the list of Quicklisp downloads because all kinds of other Quicklisp packages depend on it: http://blog.quicklisp.org/2012/11/download-stats-for-october-2012.html
The general style looks clean and readable. Three of the defclass forms need to be reindented. I personally rarely define initialize-instance :after methods, and instead go with explicit make-foo -style constructor functions. This is probably just a matter of taste, although having "make-foo" makes the datatype more opaque, and is also a bit more descriptive in the package export list than just "foo", in my opinion. Also, be sure to check out the ASDF extension "package-inferred-system". It's a great way to keep packages small and manageable.
Yeah. It's got quite a few useful things in it.
CLOS is still rather mysterious to me. Before, after, and around methods are a bizarre concept in my head, so playing with them helped. Most of my day job stuff is in C#, so I'm definitely used to having named constructors. I may switch that up. Like I said, this is all a learning experience.
 (defclass delimiters () ((field :initarg :field :initform #\|) (component :initarg :component :initform #\^) (repeat :initarg :repeat :initform #\~) (subcomponent :initarg :subcomponent :initform #\&amp;) (escape :initarg :escape :initform #\\))) (defvar *default-delimiters* (make-instance 'delimiters)) (defmethod get-delimiter (type &amp;optional (delimiters *default-delimiters*)) (slot-value delimiters type)) (defun read-delimiters (s) (make-instance 'delimiters :field (elt s 3) :component (elt s 4) :repeat (elt s 5) :escape (elt s 6) :subcomponent (elt s 7))) and so on... (defclass HL7-Mixin () ((value :reader value :initarg :value) (delimiters :reader delimiters :initarg :delimiters))) (defclass HL7Message (hl7-mixin) ((segments :reader segments))) (defclass HL7Segment (hl7-mixin) ((fields :reader fields))) (defclass HL7Field (hl7-mixin) ((components :reader components))) (defclass HL7Component (hl7-mixin) ((subcomponents :reader subcomponents))) also: (defun split (character sequence) #+lispworks(lispworks:split-sequence `(,character) sequence) #-lispworks(split-sequence:split-sequence character sequence))
The only one of those I'd question is the last. Is there some stylistic thing I'm missing? I don't really see a difference between (split #\Newline stripped) and (split-sequence:split-sequence #\Newline stripped) I don't know why, but that makes some part of my code brain twitch. Also, I don't know what that #+ and #- syntax is.
The difference is that one can switch the implementation in one place. For external libraries this might be useful sometimes. In this case there are two different implementations, which will be selected at read time (during compilation typically), depending whether it runs in LispWorks or not. Just an example...
LispWorks comes with its own lispworks:split-sequence. One less library to load. I was too lazy to reach for split-sequence:split-sequence. I used it as an example that it might be useful not to use external symbols throughout the code, but to package them in one place.
Hmm. I didn't think about swapping the implementation of that particular thing out, because I feel like string splitting is one of those things that isn't really subject to change. I could be wrong, though. It's a more plausible case than I originally thought. 
Purely formal, but I don't like the few overly long lines.
Good find! There use to be a link where all the examples were done in common lisp, but that site seems to be down and I can't seem to find it using google, does anyone have a mirrored link?
You don't have to use objects. Most often than not I won't use them. That's really up to a person's style.
I have not read the code yet but I liked your initiative. We should do this for more libraries!
That's completely fair. In general, I'm not a fan of super long lines, either, but sometimes it's hard to know where to break them to maintain readability.
Thank you orivej! That did it for me, regards, CK
AI + Lisp? You may want to try an AI framework called [ACT-R](http://act-r.psy.cmu.edu/). If you only have a couple months, this saves you from having to build things from scratch by leveraging decades of research into Cognitive Science. Helpfully, it comes packed with tutorials and supporting documentation.
Thanks. It was slightly harrowing, but it turned out to be a good thing, because the idea of people looking at it has made me try to improve it out of sheer shame. I know I'm a good developer. I've done enough of it, and seen enough stuff working to know that I'm at least capable of writing code to perform a given task (I am also painfully aware that everybody, *everybody* writes shit code most of the time). But there's something intensely terrifying about putting it out in front of a bunch of people that you suspect are far more talented than you are within the realm you've chosen to operate (in this case, Lisp).
The idea is nice. If [package local nicknames](https://github.com/3b/package-local-nicknames) could get wider adoption too, it would be just great.
However this thing is already available for all of us to use.
I've just spent some time this morning converting a project over to this "package inferred system" style. At first the relative verbosity of the defpackage forms at the top of every lisp file annoyed me, but I got over that as I realised it was forcing me to think very carefully about what symbols I was actually using from other packages and those which I wanted to export. I liked the extra discipline... But that was just a cursory look. Anyone with experience care to comment on potential downsides to migrating to this style? It does require ASDF 3.12+ and that caused my LispWorks to choke just now... 
There are different ways of doing the same things. Parenteshis placement when defining a function, for a very basic example: (define (hi) 'hi) for scheme (defun hi () 'hi) for emacs lisp. It's a matter of preference. And being capable of writing a compiler, hehe. Would be a pretty boring world otherwise.
&gt; 1. It's Lisp, not LISP. You should at least read the first sentence of [the Wikipedia article on LISP](http://en.wikipedia.org/wiki/Lisp_(programming_language).
What if the package is too big for one file? Also, a unified packages.lisp allows somebody to see which symbols are exported by which module at first glance. If every module contains package definition in its file, this is not possible.
See the 'A last trick' section in the post. You can form bigger packages as a sum of smaller ones.
And you can export symbols explicitly from the main package if you like: (defpackage :project (:use :project/foo :project/bar :project/foobar) (:export #:symbol1 #:symbol2 ...)) 
I agree having the exports laid out in a package.lisp can be nice. `quicklisp-client` is an example of a project that has a clear organization using that setup. Browsing `~/quicklisp/quicklisp/package.lisp` gives you a nice overview of `quicklisp-client`. It's not necessarily a deal breaker for me. I think having a file start out with a defpackage form stating what it is exporting has its charm. Also, a package's exported symbols can be printed programmatically (e.g. using Slime's autocomplete). I use the list and order of files and modules in classic style defsystems to get an idea of how I might want to go about understanding the system. I might miss that, but I'll have to get some experience with package inferred systems to know for sure.
Sorry I don't know what a sidebar is. I only use reddit because I read about the alien blue client during the week that it was free to download and upgrade to pro. So I literally only use alien blue to access reddit and therefore I have never seen one of these sidebars you speak of. 
Similar, but my syntax can be processed by a loop of regular expression, while http://en.wikipedia.org/wiki/De_Bruijn_index adds the complexity of variable scope since the same number can refer to different lambdas depending where its written. My point was to get it as simple as possible.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**De Bruijn index**](https://en.wikipedia.org/wiki/De%20Bruijn%20index): [](#sfw) --- &gt;In [mathematical logic](https://en.wikipedia.org/wiki/Mathematical_logic), the __De Bruijn index__ is a notation invented by the [Dutch](https://en.wikipedia.org/wiki/Netherlands) [mathematician](https://en.wikipedia.org/wiki/Mathematician) [Nicolaas Govert de Bruijn](https://en.wikipedia.org/wiki/Nicolaas_Govert_de_Bruijn) for representing terms in the [λ calculus](https://en.wikipedia.org/wiki/%CE%9B_calculus) with the purpose of eliminating the names of the variable from the notation. Terms written using these indices are invariant with respect to [α conversion](https://en.wikipedia.org/wiki/%CE%91_conversion), so the check for [α-equivalence](https://en.wikipedia.org/wiki/Lambda_calculus#Alpha_equivalence) is the same as that for syntactic equality. Each De Bruijn index is a [natural number](https://en.wikipedia.org/wiki/Natural_number) that represents an occurrence of a [variable](https://en.wikipedia.org/wiki/Variable_(mathematics\)) in a λ-term, and denotes the number of binders that are in [scope](https://en.wikipedia.org/wiki/Scope_(programming\)) between that occurrence and its corresponding binder. The following are some examples: &gt; --- ^Interesting: [^De ^Bruijn ^notation](https://en.wikipedia.org/wiki/De_Bruijn_notation) ^| [^Explicit ^substitution](https://en.wikipedia.org/wiki/Explicit_substitution) ^| [^De ^Bruijn](https://en.wikipedia.org/wiki/De_Bruijn) ^| [^Nominal ^techniques](https://en.wikipedia.org/wiki/Nominal_techniques) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cmgmiu1) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cmgmiu1)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
I'm with you on this one. Although maybe this makes sense for a beginner who doesnt automatically fold that cond statement mentally. My best guess anyhow. FYI, this is (afaict) a mostly common lisp centered reddit, and you might have more luck at r/scheme.
Cross posting now, though I suspect this isn't an issue centered on which variant it is. I'll post back here if I get an answer over there though.
I'm guessing there is something missing from this puzzle and that, perhaps later in the book, the author reveals the reason for this remark. The second version is pretty standard, wherein the cond of a recursive list-processing function typically has three clauses to catch the typical NULL, MATCH and ELSE cases. It's what we usually see. Either the author's remarks are irrelevant or just plain wrong, which is always possible, or there is something else we are missing in the narrative. That's my best guess.
IMHO the word *argument* is not referring to the function's arguments but to the discussion/argument/dialogue the book is having with you. Either way it is a poor choice of words. In this case the first example, the decision tree the book outlines is more obvious in the first example especially visually since the code is formatted and indented to show the decision *tree*. The second example is more of a decision *list* and more compact and preferable when you understand *cond*.
Probably Clojure should be ported to SBCL, like Shen. Or it should be implemented in a way that it emits 'C' or native binaries.
Every time I come back to Clojure after working for a bit in another Lisp, I forget that bindings are always done in vectors, not lists. It's so frustrating because it seems so arbitrary.
&gt; There seems to be substantial dislike of Clojure among Lispers Who falls under the moniker "Lispers"? Common Lisp programmers? Scheme programmers? Racket programmers? Arc programmers? Are you implying that Clojure programmers are not Lisp programmers? WRT your dislikes: &gt; long startup time Absolutely, but one that is largely mitigated (at least for me) by nrepl and Cider. &gt; the need to know and use some Java, Java libs, and the Java ecosystem in general when programming a substantial amount in Clojure Details would be useful here since you make a broad statement about the Java requirement. Two areas that come to mind are regular expressions and string operations. However, `re-seq` (part of clojure core) and `clojure.string` remove details of knowing about the underlying Java APIs. &gt; I think I'm allergic to the JVM Well, that's a problem isn't it. Are you equally allergic to .NET and/or JavaScript? &gt; the pressure to do everything in a functional way OK. So you're unlikely to be interested in ML, Haskell, Erlang, Scheme as well. &gt; difficulty interacting with C libraries Yet easy access to Java libraries. What C libraries do you need access to that don't already have Java bindings via JNI? &gt; error reporting (long stack traces) No argument here, though CIDER makes these easier to deal with. As for your likes, &gt; the great package manager (leiningen) Quicklisp provides this for Common Lisp. I use both Common Lisp and Clojure in my day-to-day work. I am writing a significant project in Clojure at Work because it allows me to write my code in Lisp while (a) utilizing existing open-source and internal Java libraries, and (b) utilize our existing infrastructure for CI, deployment, monitoring (e.g., JMX), etc. Common Lisp does not offer this capability to me. Our ops team knows how to deal with JAR file based releases. It is much less comfortable with a technology not otherwise used in the organization: it is true that we have C++ services, these are few and essentially "grandfathered" in. The syntactical differences between Clojure and Common Lisp are not an impediment to me. Transitioning between the two takes twenty or thirty minutes, usually remembering the extra levels of parens I need in CL vs. Clojure. 
I'm curious, why do you think this? I thought running on the jvm and making use of its libraries seamlessly was the main selling point of clojure? 
&gt;(a) utilizing existing open-source and internal Java libraries, and (b) utilize our existing infrastructure for CI, deployment, monitoring (e.g., JMX), etc. &gt; Common Lisp does not offer this capability to me. [ABCL](http://common-lisp.net/project/armedbear/) runs on the JVM and can do inter-op with Java.
As someone who tried Clojure first, I find the parens-all-the-things of other lisps to be harder to parse.
I think the bigger violation is that Clojure doesn't have "real"(?) cons cells. One could argue that vectors are still S-expressions, just with a different delimiter.
I like clojure as language, but I really don't like JVM. Can confirm all your dislikes, but I think it all just about JVM, except the pressure to do everything in a functional way. A lot of things can't be done without interacting with Java, and such interacting is really painful for me. But it's the main idea of clojure as hosted language. May be offtopic but I really wondering what [clasp](https://github.com/drmeister/clasp) will be. 
Yeah sure, not having real cons cells is a massive issue too. My issue with using vectors as an integral part of the code representation is that whereas before all Lisp forms are either an atom or a list, now they are either an atom, a list OR a vector.
It's the main reason why Clojure has been successful as a commercial language, but it's also the main reason why I, for example, abandoned it after completing a handful of projects, some 4 years ago now. Having said that, you'll note that my Clojure experience is now *very* dated. Please forgive me therefore if what I say is irrelevant. Here's what I thought when I quit Clojure: The java ecosystem is huge, and flawed. The mindset of many Java developers is distinctly "unlispy", and that makes a lot of the libraries unpleasant to use. Or to put it another way, any programming ecosystem, where people seriously suggest "Aspect Oriented Programming" as a solution, is one where people have correctly identified the cancerous growth in their system, but rather than remove it, have invented convoluted way to route around it. Clojure is smarter than that - it sidesteps all of that, right up until the point where you have to use non-Clojure code. 
But actually using java libraries not designed for use in ABCL is absolutely terrible, with lots of boilerplate needed both ways. One of the main selling points of clojure is that it allows you to write lisp while smoothly using existing java libraries, with essentially no interop code needed.
Quote below from Rich hickey explaining the logic behind different syntax for structure literals. The view (to which I don't entirely subscribe) is that one of the things we overload is the concept of access time, we have these primitives with different internal behaviors which we have to keep in our head as our language hides this from us. Too me I don't see the advantage over using the # based reader macros and it kind of becomes moot once the data is bound to a var anyway. I personally would rather keep the reader syntax for occasions where the evaluation model is changing. e.g. quote, backquote etc as at these points we change have to change you we read the upcoming code. Rich's quote here: "Since we were talking about syntax, let’s look at classic Lisp. It seems to be the simplest of syntax, everything is a parenthesized list of symbols, numbers, and a few other things. What could be simpler? But in reality, it is not the simplest, since to achieve that uniformity, there has to be substantial overloading of the meaning of lists. They might be function calls, grouping constructs, or data literals, etc. And determining which requires using context, increasing the cognitive load when scanning code to assess its meaning. Clojure adds a couple more composite data literals to lists, and uses them for syntax. In doing so, it means that lists are almost always call-like things, and vectors are used for grouping, and maps have their own literals. Moving from one data structure to three reduces the cognitive load substantially."
But it's still homoiconic. It's just uses more than one type of data to represent code. I agree it seems a bit arbitrary, but can you explain why having vectors is a problem?
I'm not a clojure guy myself but am mildly surprised by the bashing it gets. The focus shouldn't be that it runs of java, as the belief espoused by rich hickey is that the platform is the vm not the os or machine. He chose the jvm as it is solid and popular but, as clr &amp; clojurescript already show, it is willing to be based on any vm that can leverage it. If java were to die, i don't believe clojure would necessarily follow. Clojureclr/clojurescript would just become defacto clojure. Also while right now it is easy to point that they lean greatly on java libraries, as time goes by the user's will start wanting their code to be more clojurey, and will begin porting more things to clojure. As this happens the dependence on java drops and so does the strength of any argument based on clojure's java nature. Clojure has the belief that, from now on, machines are basically only going to get faster by adding more cores, and that leveraging that well it paramount. Anything that makes that harder should be avoided. Given that premise, it is natural that clojure doesn't aim for optimizing the same things that CL does, either in syntax or in runtime behavior. I think clojure goes after it's goals admirably, and there are/will be things that are good to steal in Common Lisp, but as libraries rather than enforced paradigms.
* Common Lisp is Miles Davis * Scheme is Charlie Parker or Thelonious Monk (can't decide) * but Clojure ain't John Coltrane or Dizzy Gillespie. It more like MMW, Diana Krall, or George Benson, good (maybe excellent) and popular. Just be thankful Clojure ain't Kenny G.
My personal issues with Clojure: * Not a very elegant bootstrap: too much Java, not enough Clojure * I cannot comprehend the reasoning behind ditching dotted pairs. They're just too important in my workflow * `recur` is awful, but it's not a Clojure fault, it's just JVM being a steaming pile of crap
I don't have any opinion on Clojure the language. The community of users seems to be very nice and vigorous and growing, which can't be said of many other Lisp dialects. My impression is that relatively few people who used and liked Lisp before Clojure arrived have switched from their preferred Lisp to Clojure. My impression is that people who would otherwise use Ruby, Python, Perl, Java, or some other non-Lisp language have found Clojure to fit their needs well. That's just speculation, though.
For an even greater point if Java were to die the JVM itself is not going to die.
Even though I liked the literals at first, I think they make clojure a noisier to look at than parens only sexps. I'm fond of the "denotational" type constructor (vector xs...) (dict pairs...) etc etc
I don't dislike clojure. I like the paradigm and I like the mentality that it helps me get into when solving a problem. I do have some familiarity with SBCL and I do not like the fake recursion in clojure. The way SBCL (and most other common lisp dialects afaik) use trampolines to adjust the stack and allow for true recursion. That was the biggest confusion for me since the language is considered a lisp and I've always thought of recursion as part of being a lisp.
Unfortunately, JVM simply does not allow to implement trampolines efficiently, and definitely won't allow to do funny things with a stack. That's one of the reasons why I prefer CLR - it's got a relatively low overhead generic tail call support. For this very reason, Clojure (or any other JVM-based language) cannot be considered truly functional.
Historically LISP. It is currently the present, and in the present we say 'Lisp'. 
The answer is in your first two sentences. &gt; There seems to be substantial dislike of Clojure among Lispers, and I'd like to *understand* why that is. After some playing around with Clojure (and *almost no exposure to CL*) It always turns out that people trying hard to understand something about "lisp", use some dialects and have no CL exposure. 
I have never heard of any of the people you mention.
&gt; Yeah sure, not having real cons cells is a massive issue too. How is this a massive issue?
/u/Tuna-Fish2 nails it on the head: ABCL's interop is awkward compared to Clojure's, and when you are developing in a Java-centric universe the ease of interoperability is paramount.
As the person who submitted the original bug report, I'm very happy that this has been fixed!
&gt; Clos and condition handling are the first examples I think of. For some features it is actually just a step sideways, but inertia and personal preferences exist. CL's condition system is definitely something I miss. For object-oriented development, CLOS is awesome. But Clojure espouses a different programming paradigm that eschews OOP. With that said, one could build a CLOS in Clojure if you desired. Clojure supports multimethods, records, and protocols which provides me with many of the features I used CLOS for. 
It's just that it seemed a bit confrontational, that's all.
I like to think of Clojure more as Herbie Hancock: rooted with the masters (*Maiden Voyage*) but not afraid to get funky (*Chameleon*) or electronic (*Rockit*).
&gt; [...] and I do not like the fake recursion in clojure. Recursion is not fake in Clojure. You can write recursive functions just like you can in any other Lisp. The issue is that it is impossible to implement general tail-call optimization on the JVM and Rich Hickey made a design decision to not provide a partial implementation. The Common Lisp standard does not require TCO in conforming implementations. While SBCL, CCL, LW all implement it, ABCL does not. If you want to write portable CL code you can't rely on TCO being performed. Kawa does provide an implementation, but it has restrictions. 
Well, that does seem a bit dated simply because in my experience modern clojure usually has a clojure library to interface with just about anything java you'd want to use. So someone else has done the nasty part of making the java stuff be usable in a more lispy way. I don't use clojure for my day job, just for hobby projects, but so far i've had to interop directly with java very very rarely.
OK, well maybe I'm just a bit grumpy and don't like things that are different, but here goes. I admit here I have only played with Clojure (and clojure-clr), I've never done anything serious with it, so take my opinion with as little regard as you wish. Lisp code is supposed to be a literal AST i.e. a tree. This is important because it means you write functions which examine code by mapping over the sub-forms. If you can embed sub-forms into objects which are not lists then you now have to examine them in a special ad-hoc way. It might sound trivial, but it's inconsistent and unnecessary. People have been writing Lisp without it for half a century so why do it.
Some of the response from Common Lispers, etc. on this thread remind me a lot of the attitude of a lot of traditional UNIX gurus towards Linux in the mid-1990s. Lots of people raised on Sun workstations and the like felt that Linux was a bastardization of real UNIX even though looking back on it, Linux *saved* UNIX -- we'd probably be living in a Windows-only world today (even on servers) if Linux never existed. I kind of feel the same is true of Clojure. Certainly it restarted the "functional programming is good" movement among mainstream programmers who generally considered it a classroom curiosity at best before.
&gt; This is important because it means you write functions which examine code by mapping over the sub-forms. If you can embed sub-forms into objects which are not lists then you now have to examine them in a special ad-hoc way. This seems to me to be a description of 'writing code that manipulates code', that is, using homoiconicity. The argument seems to be that not having everything as a list impedes using homoiconicity. In particular that one needs code represented by **one** data structure. I would really like to see an example where having exactly one data structure represent the code makes things much more elegant. I have a feeling that such an example would be very strange because it would imply that the programmer doesn't know the semantics of a chunk of code he is generating (e.g.: 'this is function call'), so that the transformations he is coding are not well typed. When I say I would like to see such an example I don't mean this as a challenge; I would genially be interested in it! *Another question*: Is your point about vectors in the source code completely resolved by just considering [a b c] as syntactic sugar for (vector a b c) ?
&gt; Certainly it restarted the "functional programming is good" movement among mainstream programmers who generally considered it a classroom curiosity at best before. Did it really? I'm not sure I'd contribute that solely to Clojure.
&gt; How about assoc lists? Um... ok. &gt; I think I just don't like change tbh, because all the parts of Clojure which make it different from CL are the bits I feel uncomfortable with. Bingo.
yes, and points for kenny g
[Music is the answer, to your problems](https://www.youtube.com/watch?v=ZkPhIIESof8)
What else then? F#, maybe? I'm being serious here. Why did functional programming suddenly become popular a few years ago outside the traditional users of it?
Well, you haven't met any diehard BSD users then -- they will give you an earful on how Linux ignored existing API standards in many cases.
As if assoc lists are implemented by cons cells in any meaningfull lisp, way too slow. Clojure has fast immutable maps for that.
Haskell, Erlang.
I mostly use clojure, and while it is somewhat weird at first, you eventually get used to it.
LINQ, I suppose.
CL is not positioned as a "mostly functional" language, it favours other means of control flow to a plain recursion. While Clojure tries to play on the same field as Scheme, enforcing pure functional approach wherever it is possible. So it's very unfortunate that it cannot handle trivial tail call cases like in `(defn f [g x] (g x))`.
Finally! Congrats and a big thank you!
Yes, that seems like something that would happen naturally over time. Glad to hear it!
"... whole thing becomes well above 40 MB. It appears that this is a well known problem with SBCL. ... Now, I should absolutely try ECL. Here a short of a tutorial. ... -rwxr-xr-x 1 enrico staff 16K Jan 13 00:07 life This looks reasonable."
In Clojure, you use assoc on a Map, not on a List. Clojure can use different data structures for maps to give best performance. Small maps are internally implemented with vectors. Larger maps are high performance hash-maps. Accessing a map element by its key is extremely fast in Clojure. Because lists are immutable, I have not been able to find any way that I cannot just think of Clojure as using cons cells. In fact, I think of it that way all the time. I have yet to find a situation where cons cells are not a great abstraction, albeit not the actual implementation reality of lists. Go ahead and think in terms of cons cells. Since you cannot modify one, ever, it doesn't matter. Because there are no _actual_ cons cells, Clojure does not have dotted lists. That is perhaps a bigger issue to you than the fact that lists are not cons cells. Because many lists in Clojure are actually internally a Trie, calling nth to seek out an indexed list element is very fast. It is a tree lookup in n log 32 time.
Java is the Cobol of the 21st century. When I was a student in the 70's, I was told Cobol would be around long after the year 2000. I couldn't believe it. But it was true, and for the reasons I was told. The software base written in Cobol, even back then, was so gigantic, that the language simply would not go away anytime soon. The same is true of Java. It is used in major banking and high speed trading. It is used in every Blu-ray player, in the SIM card of your cell phone, and in lots of other every day stuff. The JVM will have an even longer life than the Java language. The JVM is a solid industrial strength runtime platform with GC, dynamic profiling and JIT compilation to native code. The JVM compiler has amazing capabilities. The JVM will aggressively inline code. But, classes (eg, binary class files) can be dynamically reloaded! So a class gets reloaded and your method now has inlined stale code! The JVM will de-optimize your method so that it is back to being interpreted again. If your method is (still) truly cpu intensive, dynamic profiling will quickly reveal this and your method will again get re-compiled to native code. A reasonably well tuned JVM can routinely handle heaps in the tens of gigabytes with GC pauses under ten milliseconds. The JVM gives you lots of controls for tuning. If you need a heap in the hundreds of gigabytes, contact Azul who can sell you a JVM that will do this and still have astonishingly short GC pauses. That brings up the fact that there are multiple JVM vendors around. Clojure running on the JVM isn't such a bad idea. Access to Java is much easier than access to C code. But the JVM provides JNI which allows access to C code. So one level of optimization can be to write in Java, or to move down to C. Java has a _truly_ _vast_ collection of third party libraries. I'm just saying, it's not a bad platform to run an industrial strength lisp on -- that has an excellent story about concurrency due to immutability.
Clojure has an excellent story for dealing with concurrency. Writing massively parallel programs is the reality now. Writing single threaded code is no longer good enough. If I want the prime factors of a number, the lisp function that does this should light up all of my processor cores. It should be _easy_ to write parallel code that is provably correct. Just one example: Instead of using 'map' with a function over a list (or vector), just use 'pmap' instead to do the mapping in parallel.
Clojure does have transient data structures. Example, I want to sieve all the prime numbers in some range, say 10,000,000 to 25,000,000. Just create a transient vector of ints. Assume zero means the flag is 'set', and one means the flag is 'cleared' -- that way you don't need to initialize all of the elements of the vector to 1s first. Then do the sieve up to the square root of n, striking out cells that are multiples. Finally, a single function (persistent) turns your transient vector into an immutable value. Once you call persistent to get an immutable value, doing any operations on the transient vector will throw an exception. Now return the immutable value from your pure function. There is nothing wrong with using transient values in this way. The transient value exists only within the local scope of a function in a loop. You discard the transient vector (and let it get GCed) after you create the persistent vector from it. Only the current thread executing the function ever has access to it, so there are no concurrency issues. Multiple threads could execute the function, but they each are a separate function call with separate locals, separate transient vectors, etc. 
It is self-hosted? or does it depend on a ECL's shared library? 
It can be useful in some scenarios. For example, if you want really low startup time. Specially because some libraries out there make a lot of things at load-time when it could be done on compile-time instead.
I'm trying to get buildapp ported to other Lisps. Maybe I can support ECL without too much hassle.
Damn man. Wonderful follow up. 
 $ ldd hello ntdll.dll =&gt; /cygdrive/c/Windows/SYSTEM32/ntdll.dll (0x775f0000) kernel32.dll =&gt; /cygdrive/c/Windows/system32/kernel32.dll (0x75b00000) KERNELBASE.dll =&gt; /cygdrive/c/Windows/system32/KERNELBASE.dll (0x75940000) cygwin1.dll =&gt; /usr/bin/cygwin1.dll (0x61000000) ecl.dll =&gt; /usr/local/bin/ecl.dll (0x64880000) $ ls -lh /usr/local/bin/ecl.dll -rwxr-xr-x 1 Administrator 없음 8.6M Dec 3 10:28 /usr/local/bin/ecl.dll* ECL is not the answer. 9MB dependency. It is still big.
&gt; ECL is not the answer. 9MB dependency. It is still big. Only if you use cygwin; if you do as most Windows users do (using msvc), you get **1.5MB** for ecl.dll (and obviously don't need cygwin1.dll).
"Lisp function closures are used to express queries over in-memory, in-process Lisp data." Neat. @lispm: Thank you so much for the treasure trove of good resources you share here. Greatly appreciated!
I don't think I said it didn't, I merely said it was opinionated about preferring immutable datatypes.
Cool. Would love to see some vimperator/conkeror style link browsing, where all links become numbered and get filtered as you type.
Terrible name :/
Can you say more about what "filtered as you type" means?
What else do you suggest?
Fantastic piece of software, a game changer
I've been playing with this. I need some help really because my actual front end skills (JS/CSS) aren't that great and my attempts to highlight links on the page look shit. There are some internal functions to execute javascript on the page, if you fancy taking a look.
When you enter follow link mode, every link on the page is given a short code, usually 1, 2 or 3 charaters, shown in a little box above the link. When you type a character, the codes for links that do not start with that character disappear (this is the filtering). If 3 characters codes were necessary, typing a second character also filters out the codes that do not have that second character.
I do no mind the name, but how about 'Lisperor'? Thank you for it, in any case. Very cool!
Thanks!
That's really great, much more complete than last time! Still, there are some things missing: 1) Can't break entered expression in multiple lines (in REPL) 2) Characters data type is missing 3) function rem doesn't work with strings [try, for example (rem #a "abacus") or, using ASCII code for a, (rem 97 "abacus")] 4) This produces segmentation fault: (= airports (table)) (= (airports "Boston") 'bos) Segmentation fault Once again, nice job, thank you, I really like your project!
No it isn't. *Kit are usually frameworks, like WebKit, IOKit, etc. The kit name suggests it's a kit for building something with it. LispKit is not a kit for building something in/with Lisp. It might be confusing. Just my opinion.
Even though [Conkeror](http://i.imgur.com/V9DOvDy.png) does highlight things, it doesn't seem very useful, the numbers would be enough, sort of like [Keysnail](http://i.imgur.com/BSiSWzR.png) does with letters. 
That sounds pretty nice, thanks.
Cool, either of these should be relatively simple to implement once I get the labeling looking nice. 
ok
Lispkit will learn this feature soon. Visit the github page and chime in with other features that you would like to see!
http://mason-larobina.github.io/luakit/
Is it in emacs yet? Edit: from the videos it looks like it is. I think?
No segmentation fault: Arcadia 0.7.3 &gt; (= airports (table)) #&lt;table:&gt; &gt; (= (airports "Boston") 'bos) bos &gt; (airports "Boston") bos &gt; 
This is stunningly lovely, thanks for sharing!
My impression is that I see quite some people I know from the CL world to be using Clojure. Of course, I can't tell whether they have "switched" entirely or whether they are using it only on some projects. I've been using CL for quite a long time (not exclusively, unfortunately), but have more or less switched roughly a year ago, in the sense that I'm currently not doing any CL. The main reason is that I would like to deepen my knowledge of Clojure, not any particular dislike against CL. I started looking at Clojure specifically to find a smooth way of getting a foot into the JVM universe. Actually, I must admit that Java and the general "host symbiosis" thing of Clojure (cf. ClojureScript) are on of the things I really don't like. However, for many "Java" things you'll find ready-made Clojure-icing on the cake already, so it's not too bad (when it's bad, it's really bad). I also tend to miss CLOS a little, but that's actually just another way of saying I would like to keep the more multi-paradigm approach of CL over the far more restrictive ("opionated") approach that Clojure takes, especially wrt. immutability. As others have pointed out, there are ways to have mutation, but this is the way to write non-idiomatic code. In comparison, Clojure also suffers from a general lack of good documentation. clojure-doc.org used to be a rather comprehensive site of outdated documentation, now it's a shiny up-to-date stack, lacking many things it previously provided. I also have the impression that Clojure is still lacking some mature libraries in some areas -- mainly it's the maturity that's lacking, with the availability of a ridiculuos stack of Java libraries at your hand, you have always many options. Some things I like: the immutability preference (comment above notwithstanding), the multiple language constructs and tools like core.async for supporting concurrency, multi-platform availability (ClojureScript) and having protocols as an explicit language construct for disentangling dependencies. I also like that there is still a rather big momentum of innovation, there are tons of interesting things popping up here and there (core.async, transducers, lots of stuff on the ClojureScript side like Om, repls etc.). *Update*: I would love to understand why my comment was down-voted. Care to elaborate, please?
On my machine (64-bit Linux, Ubuntu 12.04) it always crashes with string as a key: &gt; (= a (table)) #&lt;table:&gt; &gt; (a 3) nil &gt; (a "xyz") Segmentation fault I didn't try if it's the same case on Windows.
This is one of the things I actually really like about Clojure. It has a simple convention that data is expressed using vectors. It's not arbitrary and I find it makes the code a lot more readable.
It's worth noting that native Clojure dialects are starting to pop up, such as [Pixie](https://github.com/pixie-lang/pixie) and [Rhine](https://github.com/artagnon/rhine).
&gt;Purely functional programming is fine as far as it goes, but for that, we have Haskell, a much better language than Clojure in all respects. Having used both, I simply can't agree with that statement. Haskell and Clojure are very different languages, and Haskell is far more complex than Clojure. The only real similarity is that they both default to the functional style and provide persistent data structures.
The language is growing aggressively, and the number of people using it in production is roughly doubling each year according to the state of Clojure surveys. There are also lots of mainstream companies [using it](http://clojure.org/companies) nowadays. While it's still a niche language, it definitely appears to have a lot of momentum.
But you don't pass data as a vector. You don't use square brackets at all to call a function, which is the time that data actually is passed. And that's not even getting into homoiconicity. I find that overloading square backets makes it confusing -- unlike most lisps^(1), when you see square brackets, there are *two things* that they could mean^(2). So you still have to check to see what context you're in. [1] If square brackets *always* mean a vector literal, then it's obvious what's happening when you see one. [2] Even ignoring that `let`-bindings aren't the same thing as lambda bindings, because `let`-bindings have values associated with the vars.
&gt;But you don't pass data as a vector. You don't use square brackets at all to call a function, which is the time that data actually is passed. Why in the world not? &gt;I find that overloading square backets makes it confusing -- unlike most lisps1, when you see square brackets, there are two things that they could mean2. So you still have to check to see what context you're in. It's not overloading anything, they arguments are a `vector`. It doesn't need to be like other Lisps and the fact that it's not doesn't make it worse or better in and out of itself. The brackets always do mean that it's a vector argument. The `defn` form expects the second argument to be a *vector* of arguments. The `let` binding expects its first argument to be a `vector` of bindings as well. I'm really having a hard time understanding what it is that you're confused about.
Here was my implementation of lazy evaluation which includes optional syntax for lazy calls: [BitBucket](https://bitbucket.org/tarballs_are_good/lisp-random/src/1adef101eea5eed7de9dae70e328308f4c572c7a/delay.lisp?at=default) It's essentially the same approach.
&gt; Why in the world not? Because parentheses are used to call functions. Right? You don't call `[print 3]` or `(print [3])` to pass `3` to the `print` function; you call `(print 3)`. &gt; It's not overloading anything, they arguments are a vector. It doesn't need to be like other Lisps and the fact that it's not doesn't make it worse or better in and out of itself. The overload is "sometimes when you see square brackets, it's a data literal. Other times, it's a list of keywords. Other other times, it's an alternating list of keyword value pairs." This is the confusing part. &gt; The brackets always do mean that it's a vector argument. The defn form expects the second argument to be a vector of arguments. The let binding expects its first argument to be a vector of bindings as well. I'm really having a hard time understanding what it is that you're confused about. I'm talking about it being bad design. It's entirely *clear* that the second argument to `defn` should be a vector of arguments. But every time I come back to Clojure, I forget that and have errors. `defn` could be defined to take a list instead; the vector is not important to the *meaning* of the code.
Thanks from me as well. Not only lovely, but scary as I have been trying to write something similar, but without success And thanks too to Rainier for sharing
&gt;Because parentheses are used to call functions. Right? You don't call [print 3] or (print [3]) to pass 3 to the print function; you call (print 3). In your example `print` is the function name that's what's being called. When you call `(print [3])` that's a perfectly valid way to call `print` with the argument being a vector containing the number 3. Yeah precisely, parentheses are used to call functions. The first argument of the list is the name of the function to call, the rest are the **parameters** to the function: (defn foo [bar] ...) `defn` is that's being called and it accepts parameters representing the name to define, the vector of parameters and the body of 0 or more elements. I'm frankly confused by your confusion here. If bar was in a list then you would be overloading the meaning of the list to sometimes be callable and sometimes being a literal which would make absolutely no sense. &gt;The overload is "sometimes when you see square brackets, it's a data literal. Other times, it's a list of keywords. Other other times, it's an alternating list of keyword value pairs." This is the confusing part. No it's not, the square brackets are **always** representing a literal vector. Period. &gt;I'm talking about it being bad design. Except it's nothing of the sort, you just don't seem to grasp the difference between the function call and the arguments. &gt;defn could be defined to take a list instead; the vector is not important to the meaning of the code. This would be incredibly poor design because a list represents the intention to call a from where the vector represents a literal value. 
I feel like we're mostly talking past each other. &gt; When you call `(print [3])` that's a perfectly valid way to call print with the argument being a vector containing the number 3. This is a point unrelated to what I was talking about. When passing the single argument `3` to the `print` function, you don't use a vector. &gt; defn is that's being called and it accepts parameters representing the name to define, the vector of parameters and the body of 0 or more elements. I'm frankly confused by your confusion here. You keep saying "this is how it is. Why are you confused?" I'm not confused as to the definition; I'm *forgetful*, because I don't find the design intuitive. The confusing part is not *what* it is, but *why* it is what it is. &gt; ...the square brackets are always representing a literal vector. Period. Sometimes the vector is used as literal data by your code; sometimes it's data used by a macro or special form (e.g., `let`, argument lists). One of the benefits of Lisp is how little syntax it has. This is an example of introducing syntax, and I don't think it helps. Apparently you do, and neither of us are convincing each other. &gt;[defn taking a list] would be incredibly poor design because a list represents the intention to call a from where the vector represents a literal value. Is this sentence missing a word? I think you're arguing "pretty much every other lisp that defines functions as `(defun foo (arg) ...)` is "incredibly poor design". Is that accurate? EDIT: to go back to your original point: "[Clojure] has a simple convention that data is expressed using vectors." Either I'm still not understanding this, or it's clearly false. Only one data type is vectors. There are many others that don't use vectors.
I genuinely do not understand what it is that you find confusing about vectors. The syntax for calling forms is: (name-of-the-thing-to-call arg1 arg2 ... argn) The first item in the list is what we're going to call and the rest of the items are the arguments that will be passed in to the thing being called. So, when you write: (println "hi") then you're calling function called `println` and passing it a single argument `"hi"`. When you write: (println [1 2 3]) You're calling `println` and passing it a single argument which is a vector `[1 2 4]`. When you write: (defn foo [bar]) you're calling `defn` with the first argument being a symbol `foo` and the second argument being a vector with a symbol `bar` in it. When you write: (let [a 1]) You're calling `let` with a single argument that is a vector `[a 1]`. What exactly are you having difficulty with here?
I found the bug. Problem solved now.
I said that I'm done talking about this here. I can't seem to make you understand that I find the reason for the design confusing. I understand the design; I just think it's pointlessly complicated. That doesn't mean I don't understand how to call functions, or that I don't understand how to pass a vector to a function. I'm not interested in continuing the conversation any further in this forum.
I'm just trying to understand your position that's all. I simply can't understand how overloading lists to be both collable and not depending on the context is less confusing than using vectors for arguments. In any case, since you've made it clear that you don't wish continue discussing this, cheers I guess.
As somebody who came to Clojure as my first Lisp I find it far more intuitive. For example, in CL you'd write: (defun double (x) (* x 2)) Why are `defun` and `*` being called, but not `x`, exact same syntax is used in both cases, but it means different things. I would've expected to have to do something like: (defun double '(x) (* x 2)) With CL, when you're reading the code you just have to know when something will be called or not and there's no indication from the syntax itself. Let's compare this to Clojure: (defn double [x] (* x 2)) Now we have consistent semantics for lists being callable. When I see a list I know the first element is what's going to be called and the rest are parameters. When I see a vector I know it's just a data literal.
However, the advantage of `recur` is that the compiler can actually check that you are doing a tail call. Mutual recursion is probably the only case where this becomes a disadvantage, but I rarely see it actually used in practice.
I love this, I've been writing a graph database, it is also hosted on github (protograph), and probably can get some insight from looking at your code. I love the concept and the execution, and I love it when I click the language statistics bar in github and I see "Common Lisp 100%"
That someone doesn't know shit lol. You want to deploy on Linux? Ship fasls or source with bash script (or whatever your choice is) as installer OR dump your image. Dumping your image is like bundling the jvm with your jar files. Depending on if you deploy your user space app with source or as fasls will decide if you have to include an implementation or not (of course the user will still have to have a common lisp implementation installed, it's just that you probably won't have to choose for them if you provide sources) EDIT: Disregard this
&gt; Catching errors early. With recur I can't accidentally put something in a non-tail position so that the stack can't be cleaned up. It's a very common pattern to have both tail- and non-tail recursive calls in the same function (e.g., walking over a shallow but long list). &gt; I've been working with Clojure for 4 years professionally now and this simply has never come up as an issue. Of course. Because Clojure runs on a limited VM, Clojure users are denied the power of this approach in implementing their DSLs. &gt; Also worth noting that continuation passing style is akin to working with gotos and can make code extremely difficult to understand and maintain. Why would you want to *write* this kind of code yourself? This technique is for implementing the DSL backends.
&gt;It's a very common pattern to have both tail- and non-tail recursive calls in the same function (e.g., walking over a shallow but long list). Sure, and you can do that in Clojure just fine. &gt;Of course. Because Clojure runs on a limited VM, Clojure users are denied the power of this approach in implementing their DSLs. So, please provide an example of a Clojure library that suffers from this problem. &gt;Why would you want to write this kind of code yourself? This technique is for implementing the DSL backends. So, if you're not going to write this code yourself it really doesn't affect you in the first place does it. 
&gt;Obviously, it does not exist, because this technique is not available to the Clojure developers. But it's pretty common in Scheme. Presumably though it would have a practical negative impact on how libraries are written. Continuation passing style in Scheme often makes code extremely convoluted and hard to follow. So, while it's certainly popular I don't know if I would call it a clear improvement on other approaches. &gt;How exactly it does not affect me, if I cannot implement a macro which will generate this kind of code? Sure you can, you would just use trampolines instead so it'll be slightly more verbose.
I actually have no idea whether there are any problems with "huge" executables. I don't do embedded programming, so it's probably fine. I'd think it would affect at least startup time?
What are my options for repeatable builds? What does a lisper do to go from "tree of .lisp files" to "here, install this"?
&gt; Continuation passing style in Scheme often makes code extremely convoluted and hard to follow. Once again, it's a very useful *target* semantics. Do not write this kind of code on your own, use high level DSLs to produce it! &gt; Sure you can, you would just use trampolines instead so it'll be slightly more verbose. In such case I'd just resort to a stupid ad hoc interpreter instead, it would not be any slower than the trampolines.
So Lisp is probably not viable for small tools just because of that?
Well it really depends on how small and I actually don't have the knowledge to give you an absolute answer, sorry
It is true, in my opinion, that there is conflict between Lisp and Unix here. Lisp philosophy is very different from the Unix philosophy of small and efficient single-purpose programs. It was designed instead to run everything inside the same implementation. See Emacs as an example. However, I would not say Emacs is a joke, would you? Now, the problem is not a big deal nowadays. You can deploy large executables or deliver your source code/fasl and provide the implementation, just as Python or many other environments do. But, what if Lisp were more popular? I don't think the current approach could support many Lisp applications living on the main Linux distributions. There are many problems, like: - Two versions of the same library cannot be loaded in the same process in general. - Because Lisp is very dynamic, memory pages cannot be shared between multiple processes. - Startup times are very slow. More if you need to compile! In SBCL, fasl are not compatible between versions, so if you upgrade your Lisp implementation, you need to recompile all Lisp software in your machine. Those are not unsolvable, but it requires work. And it is not a necessity currently. But I would like to see this improved.
No, I'm arguing that Clojure is not a real functional language, because functional style is not possible in it (due to JVM deficiency). And there are no other *efficient* ways to accomplish the same result.
Well that's weird, last time I checked what I said was true. I guess it's because of the compression? 
It depends on what kind of an application it is and who is your target audience. Generally speaking, most users will prefer 'single executable' format, as it is very easy to work with. And many Lisp implementations allow you to create such an executable with ease. As this executable would include a complete Lisp implementation, it won't be small. But, say, 20 MB hardly matters for your typical user. If, for some reason, you want to make it small, you can try CLISP or ECL/MKCL. IIRC with some effort I managed to get it on a single floppy, when floppies were still relevant. And then there is an option to make a tarball with Lisp executable, Lisp scripts and sh scripts which start them. Finally, if your users are tech-savvy, you can ask them to install the implementation themselves, and ship only source code. You seem to think that Lisp is somehow inferior in this respect, why is that? Do you know how they distribute Java programs? Usually they ship a jar (which can be quite big), and user is supposed to install JRE himself (again, big). And rather often people have compatibility problems with it. Python? Either in source code, or via py2exe, which isn't really that better than Lisp executable. (E.g. PyQt apps are 10-20 MB in size.) 
I wrote a benchmark [1] and I found an image saved by sbcl has a shorter startup time than even modestly sized python programs: [1] https://github.com/jasom/image-bench
&gt; sbcl produces a 50mb hello world How often do you have to "deploy" hello worlds?
I mentioned in a deeper comment that I benchmarked lisp image starup times. Here's the results on my machine. A few notes: * /bin/true is included as a "0 overhead" startup program. * This saves an image that only calls quit * ones named like foo.big are with quicklisp and drakma loaded into the image * SBCL supports core compression which reduces the size by about a factor of 4, but really hurts startup time. It's not included here. * ECL needs a dll to run that is ~3MB TL;DR: ECL generates slow startup, but small images. SBCL has fastest startup, but largest images. CCL is a decent compromize. ECL 13.5.1 SBCL 1.2.2 Version 1.9-r15769M (LinuxX8664) GNU CLISP 2.49+ (2010-07-17) (built on clarabell.ghs.com [192.168.99.153]) SIZE LISP_NAME CPU% STARTUP_TIME 28 /bin/true 4% .0008 1952 ecl 98% .4292 50568 sbcl 41% .0100 29432 ccl 23% .0133 7832 clisp 71% .0112 4996 ecl.big 99% .6559 70184 sbcl.big 39% .0116 42200 ccl.big 36% .0115 17140 clisp.big 81% .0234 
That wasn't the point. The point was "the smallest possible application produces a 50mb binary". I know that this is just an initial size and that it's not like it grows by 50mb per 3 lines of code or anything.
If Lisp is not viable for small tools because it needs a runtime, then basically any other non-native language isnt viable too. That difference between Lisp and java/python/perl is that you can expect the user to already have them installed, so you just ship your part of the equation. With Lisp, this usually isnt the case, so you have to ship the runtime, which inevitably adds to the footprint. Years ago, Java had this problem too. Every tiny Java tool triggered an enormous runtime download. But Java won that uphill battle by having a large company enforcing its ubiquity. Nobody ships the runtime any more, you just can require it now. Python and Perl had the luxury of being preinstalled by Linux distros. Lisp does neither have a powerful backer, nor do distros ship its runtime by default, therefore the uphill battle has to be fought every time you want to ship something. But in principle, the problem isnt different than for any other non-native language out there. 
&gt; You seem to think that Lisp is somehow inferior in this respect, why is that? I do not. Quite the opposite, in fact. I regard Lisp with a lot of respect, as a language. I'm convinced that writing Lisp is awesome, but there's more to a program than writing it. It's hard to write my mind without sounding like I'm a bashing Lisp hater with a flamethrower, though... I'm genuinely curious, and not trying to hate or bash or flame. What I'm trying to understand is everything that comes *after* you write a program. Namely, using it, and allowing others to use it with reasonable ease. Let me describe my current idea of how a Lisp program "lives", and perhaps you can slap me over the head for spouting nonsense. It appears to me like Lisp programs live "towards the inside", where they expect everything to happen *inside* the Lisp environment. Oppose this to C programs, which live "towards the outside", expecting to be invoked with enough information to do their job, and expecting to be combined via pipes. In essence, where C expects to be called with `tool --arg --some-more-args`, Lisp appears to expect to be called with `sbcl --eval '(some-lisp-function with-some args)'`, and for its output to be consumed by other Lisp programs, which ought to live in the same Lisp environment. The Lisp machine *is* the world, and everything outside doesn't matter. I have a hard time seeing this as a good thing. I read that generating well behaved, small Lisp programs is "not necessary", and that big, monolithical Lisp black boxes are "fine". I don't get it. What is good about that? What am I missing? &gt; Do you know how they distribute Java programs? Usually they ship a jar (which can be quite big), and user is supposed to install JRE himself (again, big). And rather often people have compatibility problems with it. Yes, and I have trouble taking Java seriously because of this. &gt; Python? Either in source code, or via py2exe, which isn't really that better than Lisp executable. (E.g. PyQt apps are 10-20 MB in size.) I've usually written Ruby stuff, which is in the same boat, and is one of the main reasons I'm looking at other languages. Shipping Ruby programs is nothing but a pain. I'm trying to get away from this model.
&gt; In essence, where C expects to be called with tool --arg --some-more-args, Lisp appears to expect to be called with sbcl --eval '(some-lisp-function with-some args)', and for its output to be consumed by other Lisp programs, which ought to live in the same Lisp environment. The Lisp machine is the world, and everything outside doesn't matter. It's true that Lisp has a greater focus on having things happen inside a running image, as opposed to concatenating object files as in most system languages, but you can certainly write a command-line application with Common Lisp. The [main function](https://github.com/eudoxia0/cmacro/blob/3858675ada3d3cdd2c14207581ffd22ff4a2b95d/src/cmacro.lisp#L62-L87) is essentially the same, although the [Makefile](https://github.com/eudoxia0/cmacro/blob/3858675ada3d3cdd2c14207581ffd22ff4a2b95d/Makefile) is rather large, since you have to install SBCL, use that to install Quicklisp, use that to install Buildapp... And finally use Buildapp the executable. 
&gt; Lisp philosophy is very different from the Unix philosophy of small and efficient single-purpose programs. Actually it isnt. In unix, the small and efficient programs also run within the Unix "image", just like small and efficient Lisp programs would run within the Lisp image. The philosophies are completely the same. They are just incompatible. The thing is that Lisp predates Unix, and that it considered Unix inferior, and that there was a Lisp-Unix war, and that the supposedly inferior Unix *won* that war, and the Unix image became the "default" system, so Lisp programs designed to run within a Lisp system now have to run in a Unix system, with the obvious difficulty C programs would also have if you tried to run them within a Lisp image. You would have to write a C compiler in Lisp, to produce Lisp executables and run them in the Lisp system and ship a C runtime. Just as C people are used to live in a Unix system, Lisp people are as used to live within the Lisp system. What is causing the rift is their unwillingness to produce a Lisp compiler that would live in the Unix image, give up the Lisp image, behave like a C compiler and just spit out Unix executables. Every other language accepts that Unix is the default and simply adapts. But Lisp people remember the time before unix even existed, and they do not want to give up their worldview and accept that the "worse is better" arch enemy has won.
I used to believe the official lisp gospel that it doesn't matter if you can't produce EXEs etc. That, I now realize, was because I was the only consumer of my own lisp code (with the theoretical possibility of distributing to other faithful lispers via quicklisp etc). Then one day I had this lisp CLI program, and asked myself how to distribute it so that non-lispers could use it without effort (i.e. download &gt; install &gt; launch, like for countless other softwares). So I discovered how big the problem is. And the reason why, as someone told me in another subreddit some time ago, "there is basically no software written in lisp".
Lisp refers to a family of languages. You may use Common Lisp for server applications and they may come as huge images(30MB or so). For small applications , you can probably use Scheme (Chicken/Gambit/Racket) whose applications can be statically compiled as small as 3MB and be deployed without any dependencies. If you still want something smaller, you can go for newLisp which can be linked or distributed within 350KB standalone app, although some lispers will reservations against newLisp in general. 
It is comparable to how Unix people did not want to give up on Unix and adapt when Windows "won".
&gt; The point was "the smallest possible application produces a 50mb binary". This is a pointless point then. You are not going to ship hello world binaries anyway, so the hello world binary size is irrelevant for any practical purpose.
Very interesting
&gt; It appears to me like Lisp programs live "towards the inside", where they expect everything to happen inside the Lisp environment. Oppose this to C programs, which live "towards the outside", expecting to be invoked with enough information to do their job, and expecting to be combined via pipes. C is a low-level programming language which is suitable for writing all kinds of programs: * UNIX-style utilities like `grep`, `find` * long-running, interactive applications, e.g. editor, browser * daemons * device drivers * operating systems Lisp might be somewhat less suitable for some of these types of programs, although it depends on what kind of Lisp we are talking about and what qualifies as suitable. So if we're talking about, say, Steel Bank Common Lisp, it is certainly not optimized for the needs of small utilities. But, say, CLISP can be suitable for that, as it is small, loads quickly, and has certain features which are good for script-writing. Here's an example. Put this lines in lisp-echo file: #!/usr/bin/clisp (when ext:*args* (princ (first ext:*args*))) Then make it executable: `chmod a+x lisp-echo`. Now you can call it: $ ./lisp-echo hello | grep he hello So it's definitely possible to write UNIX-style utilities in Lisp. And it's pretty fast too, lisp-echo executes in 0.01s on my computer. I don't think CLISP is worse than bash or perl in this respect. And, as you probably know, bash and perl are popular for these purposes. &gt; The Lisp machine is the world, and everything outside doesn't matter. Now you're a bit too far into a realm of philosophy... It all depends on what kind of software you're building. &gt; I have a hard time seeing this as a good thing. It is a good thing when you're building stateful, interactive software. &gt; I read that generating well behaved, small Lisp programs is "not necessary", and that big, monolithical Lisp black boxes are "fine". I don't get it. What is good about that? What am I missing? I believe that UNIX-style utilities are a very narrow niche. It is possible to make them in Lisp, but Lisp is mostly geared towards a different kind of software. And it's not different from Java in that respect. &gt; Yes, and I have trouble taking Java seriously because of this. OK, so Java is serious enough to run enterprise software worth millions of dollars, but not serious enough for your scripts? Am I getting it right? 
I know, but the reality is that most lispers does not seem very interested in these topics. Producing executables seems an afterthought, not a fundamental feature. I use SBCL, the most used cl implementation, and standalone executables are awfully big, nor anyone seems interested in reducing their size; some years ago someone wrote a proof-of-concept tree shaker for sbcl that AFAIK went nowhere.
If you wouldn't mind considering Scheme, Bigloo is a scheme-to-c compiler that I used many years ago that worked quite well for my purposes. Apparently the last update was earlier this year, so I guess it still is being supported. http://www-sop.inria.fr/mimosa/fp/Bigloo/
I think everyone here knows that quote :)
&gt; The JVM makes a very specific type of recursion more difficult and that alone does not define the functional style. It does. If you cannot translate, to put it simply, any possible sane lambda calculus expression into a language and expect it to be evaluated, it's not a functional language by definition. I cannot think of a better definition than an equivalence to the lambda calculus. I'd have the same issues with Common Lisp, but Common Lisp is not even positioned as a functional language. Clojure, on the other hand, pretends to be one, and it encourages functional style, while the underlying VM is so unsuitable that it's not really possible to do anything functional efficiently on top of it. 
[Buildapp](http://www.xach.com/lisp/buildapp/) is the de-facto solution.
&gt; ever compiled/installed the Common Lisp program Maxima under Unix? Ever considered that GCL is obsolete, incomplete and abandoned, not recommendable for general use and the sooner it vanishes the better? There of course are Lisps that behave nicely on Unix, many Scheme implementations even come as shared libs, but in the current Common Lisp ecosystem, the major implementations (SBCL, CCL, ACL, LW) are all image based and there are no initiatives to change that. &gt; lost to Unix The Lisp ecosystem *did* lose to Unix in the sense that even although Lisp predated Unix and considered Unix inferior, we today have Lisp images run on Unix and not vice versa. The point I was trying to refute in the previous post was that Lisp and Unix are different. They arent that different, just incompatible, because Lisp isnt merely competing as one of languages on Unix, but *against* Unix itself as the host system.
I would concentrate on *making* something that people would buy/use in whatever language that works for me, then think about anything else. The game: Wolfenstein: The New Order Requires 50GB HD Space. So what.
&gt;And what is really annoying is that such a limitation is absolutely pointless, and it's really cheap and easy to have proper tail calls in a VM (see CLR). Sure, it's not ideal but hardly a show stopper for doing FP. Also, now that CLR is finally open source I'm sure ClojureCLR is going to pick up as well. [Arcadia](https://github.com/arcadia-unity/Arcadia) shows that that it's quite usable already. &gt;How exactly does it default to mutable data, while it discourage the use of any state mutating constructs? It's possible to use a pure functional subset of Scheme (i.e., without set! and such) with no penalty. Correct me if I'm wrong, but Scheme doesn't use persistent data structures. It means that you either mutate or copy wholesale when making changes instead of revisioning. So, you're either doing things unsafely or expensively. On the other hand, Clojure provides lazily evaluated persistent data structures that allow you to efficiently thread data through functions safely. Mutability is simply the wrong default for a functional language.
&gt; GCL is obsolete, incomplete and abandoned. Actually, a new version was released last week. What's wrong with it? &gt; the major implementations are all image based Alright, so "lisp image" is the correct idiom for this? I never thought about Unix as an "image" that's simply not compatible with the lisp world. That's a surprise, but explains all my concerns. That this is considered correct and desirable in the Lisp world pretty much means that Lisp is not something I would wish to use outside of a learning situation. Thanks for clarifying.
&gt; CLISP That looks very interesting, and I'm not sure why I skipped over CLISP. I'm going to play with it for a while. &gt; OK, so Java is serious enough to run enterprise software worth millions of dollars, but not serious enough for your scripts? Am I getting it right? I *did* word that pretty badly. What I meant to say is that I have trouble *liking* Java. I realize that Java is serious business that moves billions each year, but that doesn't mean I have to like it. I should probably change that if I ever want to have a job writing software.
Unix has isolation, Lisp doesn't. It is not something I made up.. the philosophy are considered very different approach to writing software in general, at many levels.
&gt; SBCL now has image compression. Which trades file size for startup time on a rather steep scale. The compressed image needs to be uncompressed into memory either way.
 &gt; ever compiled/installed the Common Lisp program Maxima under Unix? &gt;&gt; Ever considered that GCL is obsolete, incomplete and abandoned, not recommendable for general use and the sooner it vanishes the better? I can't understand your post as a response to the quoted text. Did you quote the wrong post?
Maxima has historically been built on GCL.
I will be optimistic! The good news is that Lisp is quite simple and the basis is not incompatible at all with other models. So, even if we end up forced to use a browser-based OS, with no native applications running on our machine (please no!), and even Unix would lose its moment, if you learned Lisp, it will be always yours. You will be able to build a Lisp wherever and have fun with it.
I have used this already to deploy CL to servers, and it is really useful. But do you mean deployment to ordinary users? I'm writing https://github.com/davazp/cl-docker , consider it if it is ready when you start to experiment.
I absolutely agree. The difference between composable tools that run in the same address space with shared data structures and composable tools that run in separate processes and communicate in text over sockets or pipes is considerable. There are some interesting similarities too, e.g., the shell and the REPL as tools for composition. But the differences matter for more reasons than compatibility.
2) Added character data type 3) Now it works. &gt; (rem #\a "abacus") "bcus" 
Ha! I do mean ordinary users. Ill eyeball your work.
1) Now you can use multi-line input! I really like your suggestions!
&gt; i have only experience with lispbox, would that work fine as an implementation? Lispbox isn't a Common Lisp implementation; it's a dev environment that makes use of a Common Lisp implementation (specifically, Clozure). In any event, Lispbox hasn't been updated for nearly 4 years now, which means that it's well behind current state-of-the-art - i feel you'd be much better off picking a CL implementation (such as Clozure, since you're on Win), installing the latest version of Emacs (24.4; zipped Win binary [here](http://ftp.gnu.org/gnu/emacs/windows/emacs-24.4-bin-i686-pc-mingw32.zip)), and then using the Emacs package system to easily install SLIME (as per instructions [here](https://github.com/slime/slime)).
It's also easy to forget that even native programs need a runtime too, it's called glibc and is ubiquitous on linux, this means everyone knows what to build against. On windows it's slightly more apparent (ever had to install a visual c runtime?). In principle you could use a different libc, but if you did you'd have to ship that too.
&gt; not something I would wish to use outside of a learning situation. Historical incompatibilities aside, today the only practical inconvenience is that if you absolutely have to ship Unix executables, Lisp executables will be "slightly" larger that C executables because the whole Lisp image has to be included into the executable. Which is at worst 50 MB. I dont think that having to ship larger executables confines it to learning situations. Nowadays every second smartphone app ships executables of similar sizes.
&gt; Scheme doesn't use persistent data structures. Scheme is minimalistic. It does not provide any data structures at all out of the box. But you're free to pick up a copy of the Okasaki book and implement your own pure functional data structures any way you fancy. &gt; Mutability is simply the wrong default for a functional language. Language is not functional at all if it allows mutability, or at least if it's not possible to use a pure functional subset fully with no penalty.
You could build a gui that runs in the web browser, using Hunchentoot and HTML+Javascript (or Parenscript).
Thank you. I plan on using CCL too, using http://common-lisp.net/~dlw/LispSurvey.html as a source.
You should pack all your small tools into a single image, and invoke them busybox-style. Image size doesn't affect startup time, and the operating system only loads the necessary pages and shares memory between processes using the same image.
And I like your work! I'm sure that, once completed, this will be great arc implementation. In the meantime, please, take a look at this new bug: Arcadia 0.8.2 &gt; (= s "foo") "foo" &gt; (= (s 0) #\m) 9.46650972848035e-317 &gt; s "" 
Problem fixed! The bug is introduced by changing the data type of character (double -&gt; char). Arcadia 0.8.3 &gt; (= s "foo") "foo" &gt; (= (s 0) #\m) #\m &gt; s "moo" 
Seconding this. GUIs are hard, web development is easy and portable. But I wouldn't use raw Hunchentoot for the server, we have [higher-level options](https://github.com/fukamachi/caveman) now.
And Quicklisp!
Any plans to use the Emacs notion of buffers as an alternative to tags?
I like @fukamachi's work, but I am quite confused. Why do you advice on `caveman` and not `clack`? Also, I am a little unsure about `woo`, why developing it when `Wookie` is such a good server already?
Clack is an HTTP server abstraction, while Caveman is a web framework built on Clack. Clack is a "web framework framework". As for woo, the main difference from Wookie is that Wookie tries to replicate the whole HTTP stack -- like Hunchentoot. Woo, on the other hand, is just a web server. Routing and over web framework stuff is handled by frameworks built on Clack, so the code is more modular and reusable.
I prefer to think of Clack as a HTTP Request/Response API, same as WSGI/RACK/etc.
I usually compare it to those too, but I've also heard of those described as HTTP server abstractions.
You are right, they are definitely an abstraction of the HTTP server from the 'client-side' perspective.
&gt;The industrial robot is programmed in VB.NET 2003 and runs on a windows XP machine Egads, man!
I get by in Haskell just fine, but for those who don't care to, I understand your point. Let me rephrase mine: Common Lisp is a better Lisp than Clojure, Haskell delivers the benefits of Clojure over Common Lisp far more effectively than Clojure does. 
I disagree that CL is a better Lisp than Clojure. I find Clojure to have cleaner syntax, to be simpler, and much more focused than CL. On top of that the Clojure community, unlike the CL one, managed to settle on a consistent way of doing things. This means that there's a common style and practices as opposed to the wild west approach that's prevalent in the CL world. Again, not sure in what way Haskell delivers the benefits of Clojure over CL. Clojure uses s-expression syntax that works well with structural editing and facilitates meta programming, while Haskell does not. Another major benefit of Clojure is that it runs on the JVM that's widely used in the industry. Meanwhile, Haskell has the same problem as CL where you would have hard time introducing it as a platform at most companies. Clojure has a decent package manager and an excellent library management system with [Leiningen](http://leiningen.org/) and [Clojars](https://clojars.org/). Haskell has a rather sad story in that regard with Cabal. Clojure has decent IDE selection for people who don't use Emacs, while Haskell not so much. Clojure is a dynamic language, while Haskell is statically typed. I much prefer the dynamic approach, so once again Haskell would be of no benefit to me here. In fact, I see this completely the opposite way where Clojure brings the useful parts of Haskell to Lisp. Clojure provides the persistent data structures and the STM, which in my experience are the most useful aspects of Haskell.
So there is a really nice discussion, about how it hard or not ship lisp programs. For me it seems really hard sometimes, but may be someone can give me some hints to make it less painful. For example we want to build executables for all supported by SBCL platforms and we don't care about it's size. So what we need automaticly build windows, linux, freebsd and macos X executables for both 32 and 64 bit versions. We have some quicklisp installed systems and something in local-projects. I think anyone who tryed to do so knows that the size of image not a biggest problem. Or may be i just didn't understand how it should be done. It'll be great to know! Ok, may even knowing how to build linux32 executable on linux64 system will be great. And let's mention another problem. I don't know about other implimentations, but SBCL has a BIG problem with so-called multicore images. Just try use for example verbose logging library and save executable: buildapp --manifest-file ql-manifest.txt --load-system verbose --output test.bin You'll get: Cannot save core with multiple threads running. What are you doing with all this? Of course ql-manifest.txt here is just output of "ql:write-asdf-manifest-file"
that's pretty advanced for a robot!
&gt; Why did functional programming suddenly become popular a few years ago ... Concurrent and distributed systems. &gt; ... outside the traditional users of it? Elaborate?
That's actually a good point -- the trend toward distributed computing and processors with multiple cores makes the stateless nature of functional programming very convenient. What I meant by "traditional users" was pretty much the LISP AI community which seemed to be on a decline for the last 15-20 years or so with Symbolics going bankrupt, TI abandoning their Lisp Explorer workstations, and so on.
That analogy is quite useful. But then, if Clack is comparable to Rack, would Cavemen be comparable to Sinatra? What is the equivalent to Erb, then?
This really isn't particularly decipherable without the other part of the presentation. Unless the dude just stood in the front of the hall and clicked the slides forward every few seconds. That would be some Andy Kaufman level audience trolling.
It's not very strange actually. It's very easy to make a unit-testing framework in Lisp and if something doesn't fit your needs, it's easier to make your own than to adapt to whatever the framework thinks you should do. I experienced this recently when deciding on a framework to use. I'm currently using list-unit2 which more or less does what I want, although I'm annoyed with some features of it, so I will probably create my own. If I make that one public, you'll have one more framework to choose from.
Right, and that trap is something I want to avoid. I'm not comfy at all with macros yet, and the idea of writing a test framework (which, one would assume, would need to be tested as well) just gives me the heebie jeebies. Maybe I'm too stuck in my mode of thought, but reinventing the wheel just seems like a bad idea to me.
Aargh.
Not true, scheme has had that for ages. If you wish to use squares you can.
I think your mode of thought is fine. I bet you will get some recommendations to try out. If you are lucky someone will even have a smallish project using one of the frameworks to point you to as an example. You noticed the cliki doesn't typically host the documentation. Hopefully if there isn't a link directly to documentation from the cliki page the project's readme will have one, or clearly state there isn't any. Also, the docstrings might be viewable on http://quickdocs.org .
I like FiveAM. I don't really push the boundaries of testing, so not sure how well it holds up under bending and twisting, but it has always done the job for me.
Hey everyone, the new `uv` branch just got merged into master tonight for cl-async, and the doc site has been updated as well. This is a complete rewrite of the backend to use [libuv](http://docs.libuv.org/en/v1.x/) instead of [libevent](http://libevent.org/). Although excellent, libevent was starting to show its age and slow development cycle. There are breaking changes, so please see: http://orthecreedence.github.io/cl-async/upgrade-v0.6 Libuv provides many things libevent does not such as cleaner threading support, UDP, async FS IO, and in general just has less quarks. The new version of cl-async also has a completely re-written SSL wrapper. This is mainly because libevent has a built-in openssl wrapper, and libuv doesn't so I had to write a non-blocking SSL implementation from scratch =]. If you notice any problems with the SSL stuff, please let me know. I do apologize for any problems the upgrade may cause you, however I believe it's worth the pain in the end because of how much more we'll be able to do with libuv. Please let me know if you hit any bugs or notice discrepancies in the doc site. Enjoy!
Relevant: [Common Lisp: The Untold Story, by Kent Pitman](http://www.nhplace.com/kent/Papers/cl-untold-story.html) Kent was the project editor for the ANSI CL standard and he created the Common Lisp HyperSpec.
Please, for the love of Christ, will you people stop recommending "just roll your own"? This isn't the pre-Quicklisp stoneage we're living in. Just use FiveAM. [Here](https://github.com/eudoxia0/arachne/blob/master/t/http.lisp) is an example of use. If you're feeling all wild, maybe try [prove](https://github.com/fukamachi/prove).
The question is, is it now time to be standardising a new edition of this standard? A lot has changed in 20 years, and standardised first-class concurrency is pretty much a necessity at this point IMO. 
I can highly recommend Peter Seibel's talk, [Common Lisp Standardization: The Good, The Bad, and the Ugly](https://soundcloud.com/zach-beane/peter-seibel-common-lisp#t=3:20). It covers the context and history of Common Lisp standardization, with some ideas about where things might go in the future (as seen from 2010). None of the incentives in effect for the Common Lisp standardization and implementation process of the 80s and 90s are in effect today. Nobody is fighting to beat the Europeans to a standard or trying to satisfy DARPA needs to land federal contracts. What are the new incentives? Are they worth it?
Neat, I will look at it. I saw this in the code: (defun http-request (url &amp;rest args) (apply #'drakma:http-request url (append args (list :user-agent (format nil "qlot/~A" (asdf::component-version (asdf:find-system :qlot))))))) This can be written: `(apply #'drakma:http-request url :user-agent "the user-agent" args)`. Leftmost keyword arguments take precedence.
Not really a bug, but it doesn't look like libuv is available in Debian up to version 7. I'll have to install libuv manually to build cl-async for Quicklisp. *edit* It looks like the tarball for libuv requires autotools to build, too? Or a new build tool (yay!) called "gyp"? Is there a download that includes a built ./configure script?
Awesome, thanks. I had seen FiveAM in the list, but I hadn't taken much of a look at it yet. I'll check it out. 
You don't need much to build libuv on Debian stable: https://github.com/iojs/build-containers/blob/master/debian/libuv-stable/Dockerfile
Wonderful, thank you. BTW, thank you for `eco`!
Not a ton, but more than apt-get, and more than your typical download and ./configure &amp;&amp; make install. I don't much mind doing it (there are projects with even more difficult prerequisites), but it's a little annoying. I love easy stuff.
Right, I think in [our testing](https://github.com/orthecreedence/cl-async/issues/98), you and I found libuv to be slower. It seemed to boil down to `uv_write` taking longer to process than writing to libevent's bufferevent objects. This isn't a complete surprise to me because I found *zero* benchmarks comparing libuv to libevent in my research, and I'm guessing the uv devs/fans know about it but haven't caught up yet (or have reached a level of performance where they just don't care to improve anymore). So really it comes down to more than performance...features and maintenance. Libuv wins on both counts. Also, I think with some optimizations we can get `uv_write` working faster. We tried buffering *all* writes so uv_write is only called once per loop, but that seemed to slow things down. However calling uv_write with lots of smaller data seems to slow it down as well. Perhaps there's a sweet spot somewhere in the middle (ie buffer all data up to 4K or until next loop, then flush). There's more testing to do here, but I really haven't had the time to do the benchmarking yet.
Clojure isn't a very good Lisp. It has some interesting semantics, some awful syntax, and suffers from being a skin over its underlying runtime. Clojure has the advantage of being designed by a single person with long experience, and has a good story around certain problems. The Joy of Clojure had some genuine design wisdom. However, Common Lisp is better as a language, but far worse as an ecosystem. For better or worse, Clojure has hype, which really helps a platform mature. Yes, I've written Clojure and Common Lisp.
You're right. You didn't.
For my part, I like [NST][https://svn.sift.info:3333/trac/nst/wiki]. It is more complicated than the other frameworks, but that complexity allows one to create very specific tests with very useful error message that make the tests read really cleanly.
Thanks! Your input was really helpful for both projects.
Wow, you are dick, buddy. Or rather you don't have one while imagining to have a huge one.
Upvote for NST! It has a framework for test data. You can control/guarantee when you're using fresh versus mutated test input data. And much more:)
Note that *concurrency* and *parallelism* are two different concepts. LispWorks did look very deep into the language and its implementation wrt. concurrency. Most implementations are very primitive and underspecified about it. &gt; It's not painful to write highly threaded parallel or even event-driven asynchronous code in CL today. Just the opposite. It's okay to write some basic concurrent code, but Common Lisp and most implementations are totally underspecified in that area. Support for typical parallel execution is mostly not existing on a language level and implementations don't offer much in that area. &gt; to support practically non-existent file systems CL does not require any implementation to support non-existent file systems. 
There was a presentation about making LispWorks concurrent on multicore processors. From five years ago. http://www.lispworks.com/SMP_LispWorks_ECLM2009.pdf See also the LispWorks documentation on Multiprocessing: http://www.lispworks.com/documentation/lw61/LW/html/lw-244.htm and http://www.lispworks.com/documentation/lw61/LW/html/lw-1002.htm
Thanks for mentioning this, it gives me a starting point. I figured there was some kind of buffering happening here, and it can't be too hard to replicate in lisp. All sockets in cl-async are set up to have an outgoing buffer anyway, but by default they aren't used right now. When I get the chance to do some benchmarking, I'll go over the evbuffer code in libevent and see what can be ported over. Is there any concept of page-alignment for memory in lisp?
The size of individual chunks probably matters more than their alignment.
Summary: a bit like paredit with some slime-like introspection but for elisp.
Was this it? Andy Keep - Writing a Nanopass Compiler https://www.youtube.com/watch?v=Os7FE3J-U5Q
Glad I could help :) 
Summary: (add-hook 'emacs-lisp-mode-hook 'paxedit-mode) (add-hook 'clojure-mode-hook 'paxedit-mode) Not just for elisp.
Probably you're looking for the nanopass paper? http://www.cs.indiana.edu/~dyb/pubs/nano-jfp.pdf There is quite an impressive language built on top of Nanopass and cKanren: https://github.com/eholk/harlan Also, unrelated to nanopass, https://github.com/combinatorylogic/mbase is built more or less the same way, plus a load of "passes" is done in macros. And this thing itself was designed for the sole purpose of implementing manypass compilers.
I think this works for CL and Scheme as well...
We can also mention his github account where you can find his nanopass framework he is talking about in the video. https://github.com/akeep/nanopass-framework Note that it was also discussed in the scheme subreddit not long ago: http://www.reddit.com/r/scheme/comments/2o8nuo/the_new_nanopass_framework_an_embedded_dsl_for/
http://lispblog.xach.com/post/105043399223/the-unknown-dependency-tree has info about why the strategy of loading all Quicklisp-provided dependencies doesn't work.
I watched this to set myself up. It is much better than other implementations I tried before. 
I disagree with saying beginners should stay away from one liners. Indenting a simple + call with each argument on a separate line would just lead to bad habits. 
Agreed, to me this only shows that the platform is immature.
The first function is not better, but it corresponds to the semi-formal process of writing functions that authors are teaching you. When they derive the null? clause: &gt; – What do we know if (null? lat) is not true? &gt; – We know that there must be at least one atom in the lat. &gt; – Is there any other question we should ask about the lat? &gt; – No. Either a lat is empty or it contains at least one atom. this ‘No’ becomes the ‘else’ in the ‘null?/else’ cond. If you do not want ‘else’ there, you must either find a way not to answer ‘no’, or answer ‘no’ and mentally contract this ‘cond’ with the ‘cond’ that follows. The latter is what the authors meant.
The infix problem has been solved!
 emacs -Q -batch --visit FILENAME -f lisp-mode --eval '(indent-region (point-min) (point-max))' --eval '(save-buffer 0)'
WHY is the standard indent for lisp 2 spaces and not 4?
Lisp code tends to have more levels of indentation than, say, Python, where you could perhaps get away with 4-space indents. If every function in a lisp program were indented by four spaces, it would fall out the right side of your monitor pretty soon.
Would it be acceptable behavior to verbosely load packages which are explicitly asked for, but load dependencies silently?
One thing I dislike about Clojure is that the errors will always be Java exceptions, and they can't tell you much if the error was generated by REPL-entered code (or code entered from EMACS with C-x-e). For example: &gt; (defn foobar [a b c] (+ a b c)) #'user/foobar &gt;(foobar 'a 'b 'c) java.lang.ClassCastException: clojure.lang.Symbol cannot be cast to java.lang.Number (NO_SOURCE_FILE:0) Vs. SBCL: * (defun foobar (a b c) (+ a b c)) FOOBAR * (foobar 'a 'b 'c) debugger invoked on a SIMPLE-TYPE-ERROR in thread #&lt;THREAD "initial thread" RUNNING {AA818F1}&gt;: Argument X is not a NUMBER: A Here you can see the actual value that caused the error: The symbol A, where a number should have been. SBCL then drops you into a debugger, which Clojure could never do. Now that I started Clojure to produce the above example, I'm finding other things I don't like about it. It seems to be missing really basic math functions like CL's `expt` (equivalent to Java's `Math.pow()`), presumably because you're supposed to use FFI calls to Java to do almost everything. But that would be like SBCL requiring FFI calls to C to use its `pow()` function instead of having its own function. Googling the problem led to a Stack Overflow answer in which the best answer implemented from scratch. The author didn't even use the same name as in other lisps, going with `exp` (which does a different math function in CL). I also found some third-party library that implements math functions, so doing math in Clojure necessarily involves downloading a third-party library from GitHub. There are no `&amp;optional` arguments in Clojure, which is a feature it has in common with Scheme. There are "multi-arity functions," however, in which you define a separate version of the function for each number of arguments, similar to function overloading in C++, except all the variations are contained in a single ~~lambda~~ `fn` form. Keyword arguments have to be surrounded by curly braces, both in the function's definition and in its invocation. Technically, Clojure doesn't even support keyword arguments. You pass in a "map" (hash table) as a single argument, and there's syntax to bind to keys in the hashtable in the function body. Clojure is missing quasiquote completely. This means that macro code in Clojure has to use `list` and `'` a whole lot. From a Clojure macro tutorial: (defmacro code-critic "phrases are courtesy Hermes Conrad from Futurama" [{:keys [good bad]}] (list 'do (list 'println "Great squid of Madrid, this is bad code:" (list 'quote bad)) (list 'println "Sweet gorilla of Manila, this is good code:" (list 'quote good)))) ...it gets invoked like this: (code-critic {:good (+ 1 1) :bad (1 + 1)}) In CL, you can do away with `list` *and* the curly braces, and the macro looks like the code it generates: (defmacro code-critic (&amp;key good bad) "Something I ported from a Clojure tutorial" `(progn (format t "Great squid of Madrid, this is bad code: ~a~%" ',bad) (format t "Sweet gorilla of Manila, this is good code: ~a~%" ',good))) The comma in front of `,good` and `,bad` means that `good` and `bad` are treated as if they were outside of the quasiquote operator. `format` is an ugly `printf`-like beast. I think I've heard that the format-string language is actually Turing-complete. It's invoked without curly braces: (code-critic :good (+ 1 1) :bad (1 + 1)) Another feature of the quasiquote is that you can splice the contents of a list directly into another list: (let ((a '(a b c)) (b '(1 2 3)) `(,@a * ,@b)) Output: (A B C * 1 2 3) The Clojure equivalent would involve using Clojure's version of `append`, which they decided to call `concat` for some reason. Even if Clojure did have a quasiquote operator, I'd hate to see how it interacts with the fact that Clojure code is a mixture of lists, vectors, and hash tables instead of just lists and atoms. That's probably why there isn't a quasiquote operator. There'd be cases where I'd want to `,@` something, but it would be illegal because that something is a vector instead of a list. I use quasiquotes all the time when writing macros in CL, and would hate to have to write a macros in Clojure, without the benefit of quasiquotes. 
Proprietary and only for MacOSX, that's disappointing. The article sold it to me, fairly well too. Music composition is one of those edge cases that some form of psuedo-programming would prove to be a great benefit and Lisp seems like a great tool to help facilitate such a thing. Things like this seem to spring up pretty often over the last few years, so maybe we already have or will soon have a Foss solution to such a thing.
After 50+ years, you can bet the irony will be completely lost on this crowd. 
Oh very cool, thanks, Ill look into it!
The guy who made the new opencv bindings have made music in common lisp, you should be able to find him on github
Went for the LISP. Was disappointed. I see a machine spec there, but nothing particularly LISPy. OP?
Is there some logical ordering on the values, like you might have for an enum? For example, if you impose F&gt;M&gt;T one could also wonder about (if (&gt; X maybe) (say "it's true")) (if (&lt; X maybe) (say "it's false")) (if (&lt; X true) (say "maybe false")) (if (&gt; X false) (say "maybe true")) 
I'm developing [lispy](https://github.com/abo-abo/lispy) - an Emacs minor mode that has a feature like this. See an illustration taken from OP's article: http://i.imgur.com/VLo97vn.gif 
Well we just had the 20th birthday of Common Lisp so that could be a message from God. Or go with the hipsters and learn Clojure. I think for learning you might do better with Common Lisp. AllegroCL and LispWorks have nice free versions with IDES.
Common Lisp is the best! :)
Any book or tutorial you can recommend?
http://www.gigamonkeys.com/book/
Why clojure is for hipsters?
Generally speaking, the "yes no maybe" interpretation of a ternary architecture isn't great. A better architecture is based on balanced ternary, with trits -1, 0, and 1. Under this model, all numbers are automatically signed and there is no need for weird hacks like three's complement. [Wikipedia has more on the number system and its benefits.](https://en.wikipedia.org/wiki/Balanced_ternary) Getting back to logic, though, the fact that all numbers are signed and one trit has a sign leads to a very natural comparison instruction. When comparing two numbers the comparison flag corresponds to less than, equal to, and greater than for -1, 0, and 1, respectively. How you then want to break this down depends on you, but I've always liked the elegance of having one ternary branch instruction on a ternary architecture. Instead of a conditional jump dividing the execution path in two, it divides it into three. This meshes well with the three-centered nature of the rest of the architecture.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Balanced ternary**](https://en.wikipedia.org/wiki/Balanced%20ternary): [](#sfw) --- &gt; &gt;__Balanced ternary__ is a [non-standard positional numeral system](https://en.wikipedia.org/wiki/Non-standard_positional_numeral_systems) (a [balanced form](https://en.wikipedia.org/wiki/Signed-digit_representation)), useful for comparison logic. While it is a [ternary](https://en.wikipedia.org/wiki/Ternary_numeral_system) (base 3) number system, in the standard (unbalanced) ternary system, digits have values 0, 1 and 2. The digits in the balanced ternary system have values −1, 0, and 1. &gt;Different sources use different glyphs used to represent the three digits in balanced ternary. In this article, T (which resembles a [ligature](https://en.wikipedia.org/wiki/Typographical_ligature) of the minus sign and 1) represents −1, while 0 and 1 represent themselves. Other conventions include using '−' and '+' to represent −1 and 1 respectively, or using [Greek letter](https://en.wikipedia.org/wiki/Greek_alphabet) [theta](https://en.wikipedia.org/wiki/Theta) (Θ), which resembles a minus sign in a circle, to represent −1. &gt;In [Setun](https://en.wikipedia.org/wiki/Setun) printings, −1 is represented as overturned 1: "1". &gt; --- ^Interesting: [^Ternary ^computer](https://en.wikipedia.org/wiki/Ternary_computer) ^| [^Ternary ^numeral ^system](https://en.wikipedia.org/wiki/Ternary_numeral_system) ^| [^Setun](https://en.wikipedia.org/wiki/Setun) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cmxv52b) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cmxv52b)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
The machine as designed does use balanced ternary for arithmetic. That still leaves the question of logic though. Under the machine, + maps to true, - to false, and 0 to maybe (+2.5, -2.5, 0 volts respectively). The assembler uses the +,-,0 syntax for numbers so +-- maps to 5. I think the numeric comparisons are very natural and have clear meanings. The problem is with the equivalent of the boolean type - the trilean. It's often hard to know what you want. There's also a staggering number of functions you can have with two inputs. I agree with you on the ternary branch. I was thinking of overloading if but that may be confusing. The actual instruction would have to be emulated though if I want to build this machine. Operands are really annoying from an electronics point of view.
Land of Lisp is a wonderful guide.
Hi GMathe! I think Common Lisp is a great choice for a number of reasons, most of which you can read at the Common Lisp FAQ here: http://random-state.net/files/nikodemus-cl-faq.html You said you are new to programming, so if you are interested in learning Common Lisp, I strongly recommend reading David Touretzky's "Common Lisp: A Gentle Introduction to Symbolic Computation". You can download it for free here: https://www.cs.cmu.edu/~dst/LispBook/book.pdf To get started with Lisp, you will want a Lisp compiler and a good editor. Lispbox is a bundle of software to help newcomers get started. You can find that here: http://common-lisp.net/project/lispbox/
Practical Common Lisp comes highly recommended.
Honestly, at a machine level, there's no need to even address the logic question. But if you want to provide trit-wise operations, then you do need to do some thinking. You'll need two unary operators instead of one as in the boolean case -- roll and swap (negate) are good choices. Composition of these two should be able to form any function. Binary operators likewise are more complex. You want to be able to, through composition, form every Cayley table possible. A simple min/max lattice approach will leave some out. It is well known that unary not and and (or equivalently or) are sufficient to form every Boolean Cayley table thanks to DeMorgan's Laws. It's easy to prove (by simple exhaustion) that no single binary operator combined with one or two unary operators can do the same on a ternary codomain. So you'll need a second operator. You have choices here. If memory serves if you constrain yourself to only associative and commutative operations, there are only a handful up to isomorphism, so pick the one you want. While all of this is very fun it doesn't have any bearing on control flow as far a I can tell. A single ternary branch instruction like the one I described will give you Turing completeness. Boolean logic is just a high-level way of organizing a jump tree, anyway.
I've been going through the Land of Lisp for the past month. The author is delightfully quirky, the explanations of the code are extremely thorough, the projects are fun, and the chapters on functional programming are nothing short of eye opening. Just check out the Land of Lisp music video to get a taste of what you're in for if you get this book. http://youtu.be/HM1Zb3xmvMc
I love this book, but it isn't a gentle introduction to programming. Peter Seibel said that he meant it to be for people who already understood programming, and just wanted the fastest path to learning lisp. But definitely when the time comes I recommend that you should read this book :)
If you decide to learn Common Lisp, I recommend you the "Common Lisp: A Gentle Introduction to Symbolic Computation". It is not the most popular book, but I liked it. It is slow but very clear and conventional. You can skip parts of it. http://www.cs.cmu.edu/~dst/LispBook/ If you are an Emacs user, you should probably learn Emacs Lisp first. It is more primitive but a kind of simpler subset. And it will make your life easier. It comes with both a tutorial and manual.
[Practical Common Lisp](http://www.gigamonkeys.com/book/), both the website and the book, have been helpful to me. Many others seem to like it as well.
It's kind of eerie how similar the code is. I guess it drives the point home for me how carefully crafted CL was to has some form of backwards compatibility with older lisps. Is this runnable somehow?
Well it's time for me to pimp my videos again (dont worry about the one on the loop macro for now): http://www.youtube.com/playlist?list=PL2VAYZE_4wRIoHsU5cEBIxCYcbHzy4Ypj Emacs and Vim are by far the best editors for common lisp, coding without them is like coding c# or java in notepad. I can also add a recommendation for land of lisp as an intro (that's what got me started) and then 'ansi common lisp' is probably a perfect follow up. Also for free 'Practical Common Lisp' [edit] which kpoeck is linking to below, damn I'm blind :) [more edit] Also we are going to be biased as this subreddit is mainly home to Common Lisp people. See the other subbreddits for scheme and clojure for different kinds of lisps with different goals and specializations 
I haven't seen that book mentioned in the other comments, so I'd suggest you to have a look at "Paradigms of Artificial Intelligence Programming: Case Studies in Common Lisp" by Peter Norvig [0]. The book teaches you to implement some AI techniques, and its support language is Common Lisp. It doesn't require to know Common Lisp beforehand, so you can use it to learn bits of CL, and I find PAIP really pleasant to read. [0] http://norvig.com/paip.html 
I agree with amp108, Practical Common Lisp is a good starting point. You will also need Ansi Common Lisp by Paul Graham. If you want to be aware of the lisp programming news you can read planet.lisp.org and regularly read comp.lang.lisp with your favorite newsgroup reader. The greatest lisp programmers are here and can help you if you have any question!
I think some of the syntax might be a little hard to adapt for the modern Common Lisp reader, but if that could be overcome, it doesn't seem like it would take much to get it running.
You may start with reading 'Little Schemer' and use Racket/Scheme to go along with it.
You guys might want to check out https://github.com/jeffshrager/elizagen
Seconding the Gentle Introduction. It was really useful for me when I didn't know jack shit about programming. It goes from diagrams and boxes to a tic-tac-toe AI in a very, well, gentle manner. 
Linked in the article.
That looks really cool, and I've been hoping for an open-source music generator in lisp, but the documentation is pretty impenetrable to me. I jumped in the middle, could make out the barest bit of generating sine waves and got lost in all the VUG and UGEN talk. I went back to the beginning to see what those meant, and the definitions still weren't helpful. Based on the libraries its using, I imagine it's really great, but I can't make head or tail of the documentation, so I can't use it until I have a weekend to read the whole project or something like that.
http://lisp.nyc/learning-lisp This is a great starting point that covers much of what was already mentioned. It's setup for either learning Lisp the technology as well as Clojure, Common Lisp, Scheme and Racket. Plus the easiest IDEs.
http://landoflisp.com/ had me smiling half of the time I was reading it.
I tried read it but i don't get how you actully read it xD
It's a socratic dialogue. You read it statement or question | explanation
&gt; a close bracket also closes any intervening unclosed parenthesis between it and the last open bracket Yuck, so essentially `(say-hai (get-name (get-user 123]` was valid? Sounds like a nightmare. Is it even possible to modify the reader enough to do this fully? Not that I'd ever do it, but I'm curious how it's done. I've barely touched the reader at all yet.
Are these the same as delimited continuations?
&gt; Not clear if decomposing a procedure into physical hardware instructions is adaptable to problems other than hardware engineering problems. Is it? In reality, the primary application of that chapter is not hardware engineering but programming language implementation. It's about how to create a fast interpreter that's not too complicated. The idea is that you take high-level code in a language like Scheme or Javascript or Lua and you compile it, not into native code, but rather some low-level abstract virtual machine code like what you find described in SICP; then you interpret the virtual machine code. Many, many real world languages are implemented this way. It's a popular approach because it hits a sweet spot in the speed vs simplicity design space. On the simpler and slower side you have direct interpretation with no compile step and on the faster and more complicated side you have compilation to native code. The chapter also provides a really nice introduction to garbage collection. &gt; Seems like Structure and Interpretation builds on itself. Every chapter has been an adventure! I'm worried that I might be missing out on something valuable if I stop at chapter 4. Yep. I worked through SICP as an undergrad and I loved chapter 5. It's very much a worthwhile investment. The topics introduced there are still some of my favourite topics, many years later.
Delimited continuations are discussed (starting page 6); after a quick look, the present article rather seems to discuss the interaction of continuations with concurrency.
&gt;I don't much care that Clojure is regarded as the 'cleaner' language, whatever that means. What that means is that it has simpler semantics that are consistent and easier to follow. My experience has been that simply having more features in a language isn't necessarily valuable in and out of itself. Scala is a perfect example of a language that has every features under the sun stuff into it. The result is a lot of complexity with no clear benefit. &gt;In between you find an extreme range of features that isn't nearly encompassed by any other language of which I'm aware. If you're engineering a large application that has to be fast and do well at many different things, this is a huge win. Can you perhaps provide some concrete examples of this in practice. What kinds of applications written in CL would be difficult to write in Clojure and why. There are plenty of real world applications written in Clojure large and small. I have yet to any company developing Clojure claim that the language is not effective. &gt;It may not seem like it to an outsider, but there is an established idiom for writing Common Lisp code. You pick up on it by reading lots of recent code, as well as the newer introductory texts like PCL. From what I've seen it's quite the opposite in practice. CL appears to be similar to Scala in having many different ways to do things. This results in different projects using wildly different strategies and idioms when solving problems. It may not seem like much to an outsider, but there is a lot of value in having a focused language with a clear consensus in the community regarding the idioms used.
Well, that code was written by the instructors (probably Brian Harvey).
I wish the instructor who wrote it formatted it better.
I'm new here and interested in Lisp. Had some touchy moments with C based languages and read through this thread. So what I extracted from this is, that with each program you compile you need to run some environmental packages which are built into the final binary for the programm to even work? Something like a virtual box?
More like java and its VM actually. 
&gt; Could it be more useful for you? How so? I can formulate a few objections I guess a new user could have, since I had them when I started out with Lisp and the objections are more to aspects of the Lisp culture as a whole than of your site specifically. * Drop the "Here are 1001 different implementations that you can chose from". This is confusing as hell and overwhelms a new user, so instead of making a quick download and starting a first hello world within 3 minutes, he has to make decisions he cant be possibly be expected to make. Wisely choose one single implementation for him, pretend that the other ones didnt exist. * Instead of merely listing 1001 different packages, make interesting examples. "Look, you can do this cool stuff with Lisp. Here's how." Giant lists of packages do not impress, they overwhelm, and the new user gives up. Make everything seem easy. ELI5. * Remove the "TODO" sections. They make the site look unfinished, so the user thinks "oh, I shouldnt bother now, I'll look at it again in 6 months when he finishes it." and then either forgets it completely, or sees the TODOs again and gives up. * Advertize the site more often. I lookd back at it a few months (a yaer?) ago, and forgot it existed. Hope anything of this helps.
The TODO parts are probably to whet the interests of users by trying to say: "Look at all the cool features we'll be adding in the future!" If so, instead of TODO, list the ones you know will come out in 3-6 months, then slap a version number to that release, and put a "Coming in version X.Y in season 20xx!" If you conservatively pick your new features and deliver on schedule, you'll have marketing / PR announcement fodder on a regular basis to ping sites like here with announcements. If you show what feature was added in which version, then it gives a sense of vitality to the project. 
You don't wear a thong. U thing a thong and wear a thong
So... what is a topological relational algebra anyway?
I tried to connect to his server, but got a "connection refused" error :(
&gt; Or go with the hipsters I prefer to think of myself as a "hickster".
People wanting to learn Lisp and/or wanting to do professional development in it.
In that case: You might want to mention `rlwrap` in Choosing Your Lisp. It works quite well with both SBCL and CCL, and `rlwrap sbcl` is easier than downloading and setting up Linedit. You might also want to point out what I consider the principal reason SBCL is the best Lisp for beginners: it has the strictest compiler. That’s good when you’re learning, because the compiler catches your mistakes early. And even if you plan to switch to another implementation eventually, the discipline required to master SBCL, and leverage its compiler, will pay off in better code. (I say this as someone using Clozure in production.) In the new projects tutorial, I strongly suggest reversing the order of exposition and putting Quickproject at the top. All a beginner really needs to know is that projects in `~/quicklisp/local-projects` are automatically visible, and that they can use Quickproject to create new projects. I don’t see any good reason for a beginner to mess with the ASDF registry nowadays. I find the “ABCs of Lisp” very hurried and confusing. I honestly think the most helpful thing to have here would just be a link to the relevant sections of Practical Common Lisp. 
...and not just for OS X any more, either!
Needs more examples, how to pass in query string parameters etc. It's easy to be fastest if there is nothing to parse through - when it has the same features as the others I wonder if it will remain fastest.
&gt;how to pass in query string parameters Out of scope. Look at the [Clack](http://clacklisp.org/) documentation, or that of one of the frameworks built on Clack.
OP here. I would welcome any feedback or suggestions for the post.
http://orthecreedence.github.io/blackbird/
tpd2 suffers from bit rot.
The article clearly shows the power of Lisp macros, but promises aren't the best abstractions for re-inversion of control. You actually want coroutines or continuations. Promises are nice when your code has no side-effects: in this case, you care only about results of the computation, but not _when_ it is executed. But when your code has side-effects, it becomes a bit ugly. That's not to say it doesn't work: in practice, when you know the details of the implementation, you can write imperative code in such a way that it will work, but I'd say it constitutes abuse of promises as the concept. JavaScript people have no better options, so it's something they have to live with. But in Common Lisp you can have real continuations, which are more general and flexible, as they suitable both for imperative and functional code styles. Of course, CL has no native support for continuations, but there are CL libraries which implement them via CPS-transform using code walker. Implementation-wise it's very similar to what you did: code walker is used to transform special operators like `LET*` and `PROGN` into continuation-passing style.
One-argument require is non-portable, so I doubt this works outside of CCL.
Yes, you're probably right. I only ever use CCL so portability is not high on my priority list. If you tell me which CL you want to be able to use ergolib with I'll see what I can do about getting it to work. 
&gt; You actually want coroutines or continuations Although, you could build coroutines/continuations somewhat easily via CPS conversion within a macro.
SBCL is pretty popular: making it work with SBCL is a hard requirement for me. ABCL is the next priority for me in general. (Not sure what ergolib offers me, but those are basically the two systems I care about)
As someone only slightly familiar with both, what's the difference between a Promise as shown here, and the Stream/Delay concept from SICP? Edit: My knowledge of "Stream/Delay" come from SICP, I'm sure the idea came from before that. [Link to the relevant chapter](http://mitpress.mit.edu/sicp/full-text/book/book-Z-H-24.html#%_sec_3.5)
I'll see what I can do. I've never used ABCL (I'm allergic to Java) but getting it to work on SBCL is probably worthwhile. &gt; Not sure what ergolib offers me If you're already a hard-core CL hacker then it might not offer much. But it's designed to make CL more approachable for beginners, parenthophobes, Python fans, and people like me who like to optimize for reducing a programmer's cognitive load. 
It looks like the cl-async project moved their promises implementation into a separate library, which is great. I will provide a link to this library for people wanting to use promises for their real world projects. Thanks!
&gt; Twisted implements the promise pattern with their Deferred class. I'm kind of surprised that it doesn't already exist in CL. Actually promises/deferreds have existed in various CL libs for a while, but what has been missing, IMO, is a runloop based async framework that takes advantage of promises. However, now there is cl-async, which seems to be doing exactly that.
I have read that section on streams in SICP (to be more accurate, I have almost finished reading that section), and I must say, I had my mind blown when I realized what you could do with streams. Promises are a way to transform a callback into an object, while streams are basically delayed lists i.e. a sequence of values where the values are computed only when you need them. I doubt if streams can be used in general to simplify async programs, like you can with promises.
Thanks for the feedback, its on my to-do list to understand continuations/coroutines better. I will see if I can use coroutines (I think they are similar to [generators](http://davidwalsh.name/es6-generators) introduced with ECMAScript 6) to do something similar. 
&gt; This looks awesome Thanks! &gt; I'm interested in using it in SBCL btw. OK, I'm working on it. Turns out it's going to be a little harder than I thought. The SBCL compiler is complaining about a lot of things that CCL doesn't. I also use more CCL-specific features than I thought. (For example, I use terminators to close the underlying stream when a stream iterator is garbage collected.) 
ABCL is made for people allergic to Java!
Delay takes an expression, and returns an object `o`. When calling `(force o)`, you get the value you would have gotten had you never called `delay`. I.e., `(eq (force (delay (f))) (f))`, but `(delay (heavy-computation))` just returns an object. Note: `delay` does NOT take a function. It takes an expression. Delay is built-into the language. Promises aren't. Promises are eager (because of the `then` method, up next), but non-blocking: Their value is calculated concurrently. Promises' `then` method take a promise and a function. As soon as the Promise is evaluated, every function bound to it via `then` is executed with the value of the Promise as a parameter. E.g: (defun slow () (sleep 2000) 1) (let (q (delay (slow))) ;; `delay` is a special form, and takes the thing it will execute. (sleep 1000) (print (force q))) (print "after") Takes 3 seconds to run: The sleep inside the `let` is run, then `force` forces the `sleep` from `q` to run. The output from this is: &gt; *wait for 3 seconds* &gt; 1 &gt; after Vs. (let (q (promise slow)) ;; `promise` is just a function, and it takes a function. (sleep 1000) (then q print)) (print "after") `then` "merely" binds a function to a promise, and immediately ends. ~~It doesn't return a value.~~ It doesn't block. Whenever the promise finished, it runs all bound functions. The output from this is &gt; *wait for 1 second* &gt; after &gt; *wait for _either_ 1 or 2 seconds* &gt; 1 With Promises, you're guaranteed the function is evaluated exactly once; I don't know if that's true of `(force)`, but it might be. The "either 1 or 2" is because it depends on the system: in a naive system with 1 thread and a "pending" stack, the evaluation would be: * Create the promise and push onto the pending stack * Sleep for 1 second * Bind `print` to the promise * Print "after" * Fetch a promise from the `pending` stack and run it. * Sleep for 2 seconds * Call all bound functions * Print 1 While a smarter system might use threads, or it might pull stuff from the `pending` stack as soon as `sleep` is called. Edit: Clarification on the first paragraph. Edit: I made an error re: promises. `(then)` *does* return a value: it returns another promise, whose value would be that of running the function on the value generated by the previous function. i.e.: `(then (promise q) p)` == `(promise (lambda () (p (q))))` Edit: Further note: You can simulate `(delay)` with a lambdas: (defmacro delay (&amp;body) (lambda () &amp;body)) (defun force (f) (apply f))
Wow, you are a dick specialist buddy.
Thank you!
This is more than helpful -- thank you for the explanation. I will definitely look into continuations sooner rather than later. I have several questions to ask but I'll read up a bit first.
For what it's worth: http://imgur.com/ON8mou1
I didn't really focus on mobile since the site would most likely be used as a reference, by people coding from a laptop or desktop.
Ok. I often browse news posts from my phone in the morning. 
I wish someone implemented a direct implementation of shift/reset on SBCL: http://www.deinprogramm.de/sperber/papers/shift-reset-direct.pdf That would give lispers even more power!
It looks weird because the content is narrower than the header and footer.
Very nice, it feels more clear to me now. Thank you.
trivial-garbage is good for portable finalizers.
Just what I needed. Thanks!
One problem in the tutorial that I hit yesterday: The second code snippet on the 'Hello World' page uses the slanted single quote ` where it should use the straight vertical single quote '. Otherwise, everything is going pretty well so far.
The problem of "simplifying" CL is that you are essentially creating another language. Since you will never manage to make everybody switch to this new "better" language at the same time, instead of improving Common Lisp, you will be competing with Common Lisp for users. I dont think that the ecosystem is large enough for user base dilutions like this to be helpful. If you want to do Common Lisp a favor, write a useful library and document it well. People will use any abomination of a language (say, JavaScript) provided they can do easily useful things with it.
&gt;How would that work when deploying the fix? Security bugs should be treated as any other bug imho. The point is that bugs that could lead to sites being compromised should not be reported as public issues. That way, we can announce the bug when the fix is committed and ready to be deployed.
[Overtone](https://github.com/rosejn/overtone) is a similar environment for Clojure and there's a really nice [Emacs Live](https://github.com/overtone/emacs-live) mode for it.
I found Clojure to be the Lisp that clicked with me the best, and ended up writing a [primer on it](http://yogthos.github.io/ClojureDistilled.html) specifically aimed at getting into the mindset. Might come in helpful. :)
That's a good argument but it's still better to use this library than not using cl at all from a cl community perspective.
I just pushed out a new version that includes preliminary support for SBCL as well as ABCL and CLisp.
I just pushed out a new version that support ABCL (as well as SBCL and CLisp).
If the new language is implemented in (and hence backwards compatible with) Common Lisp then it can't take market share away from Common Lisp. Also, IMO the ability to create new languages like this within Common Lisp is the *whole point* of using Common Lisp in the first place. There really is very little else that CL offers over other languages nowadays.
There is no bug in SBCL's pathname parser. Namestring syntax is implementation-defined. If you want predictable structure in a pathname across implementations, use make-pathname and be explicit.
I spend a remarkably vast amount of time on mobile these days.
Ok, so from this feedback clearly a mobile version is now on my to-do.
 + +#+SBCL +(progn + (use-package :sb-mop) + (defun arglist (thing) + (if (symbolp thing) (setf thing (symbol-function thing))) + (if (typep thing 'standard-generic-function) + (SB-PCL::GF-LAMBDA-LIST thing) + (SB-KERNEL:%SIMPLE-FUN-ARGLIST thing))) +) Isn't that SETF very unnecessary? Why not (if (typep (symbol-function thing) 'standard-generic-function)
&gt; If people speak different languages, it makes it harder to people to work together. But that's true of any code library. &gt; One of us will have to yield No, that's not true. You can freely mix code that uses Ergolib with code that doesn't. In fact, my own projects rely on dozens of external libraries that I get from Quicklisp. All of them are written in regular old Common Lisp, and they all get along perfectly well with my own code. (Ergolib is a little antisocial at the moment because it doesn't live in its own package, but that is straightforward to change. And because Ergolib is published under a BSD license, anyone who wants to make that change can do it.) If you want to understand and modify my code, then yes, you will have to learn a small handful of constructs that I make heavy use of, mainly BB, FOR and REF. But if you consider three macros an impediment to cooperation then you probably ought not to be using Lisp. &gt; everybody pushing their "clever" macros on everybody else is poison for any coordinated action No one is pushing anything on anyone. 
It's not strictly necessary because any code that uses SETF can always be transformed into code that doesn't. But SB-PCL::GF-LAMBDA-LIST and SB-KERNEL:%SIMPLE-FUN-ARGLIST only work on function objects, not symbols.
Do it.
Ok, `call/cc` has always been confusing to me... When you do (let/cc cont (my-func 42 cont)) (foo) (bar) You're doing (not exactly the same as, obviously, but kinda) (my-func 42 (lambda () (foo) (bar)) ?
It does that because later on in the expression it uses a comma to evaluate a `getf`.
Oh, awesome, I always thought there was a lot more magic there (I mean, there's a lot of magic already; but I thought it was even more complicated).
Probably about as useful as monads.
As for me, promises aren't that bad. [blackbird](https://github.com/orthecreedence/blackbird) library provides more-or-less convenient syntax for promises and promise-related macros don't require code walker (CL code walkers aren't perfect, e.g. try ASSERT inside ITER (iterate) under CCL) and thus are less intrusive, so to speak. EDIT: also, blackbird provides UNWIND-PROTECT workalike for promises (FINALLY) - AFAIK that's not something you can have with cl-cont.
I think OP's goal was to write async code exactly in the same way as he writes normal code. In that case continuations are a way to go. Whether it has any practical significance is another question. I guess that usually it isn't a problem to give async code a special treatment, and if macros make that code nice. Perhaps continuation-based approach is warranted in some complex cases. Or maybe if you have lots of async functions, it might be bothersome to keep track of which ones of them are async, so it would be easier to use continuations and call all functions in the same way.
It's not really written in Common Lisp, but the lisp part is a thin wrapper on top of lots of C code.
[Ycombinator thread](https://news.ycombinator.com/item?id=8801997) also has discussion about this. The first thing I encountered is that the examples are all static "Hello, world!", no examples to show how to get the request headers, etc. The readme mostly focuses on the benchmarks, and describes how to reproduce the benchmarks of various stacks, etc. important data for people who want to run their own benchmarks, but not very important for people who want to try to make a test site with woo. Looking around a bit, I found [clack documentation](http://clacklisp.org/tutorial/03-hello-world.html) which shows how to print the visitor's IP in the response, and another page describing what is typically in the "ignored" ["env" plist.](http://clacklisp.org/tutorial/04-the-environment.html) I tried this code: (ql:quickload :woo) (ql:quickload :clack) (defun app (env) `(200 (:content-type "text/plain") ("From Woo to " ,(getf env :remote-addr)))) (clack:clackup #'app :server :woo :use-default-middlewares nil) Which gave me debugger invoked on a SB-KERNEL::UNDEFINED-ALIEN-FUNCTION-ERROR in thread #&lt;THREAD "clack-handler-woo" RUNNING {1007080C43}&gt;: The alien function "uv_loop_size" is undefined. Which led me to [this bug.](https://github.com/orthecreedence/cl-async/issues/97) Apparently to get the quicklisp dist of woo to work with libuv, I need to install a fresher version than my distro comes with (libuv-0.10.29-1) Still it's interesting and I'll probably try out other clack backends first so I can relate woo to some of these other projects.
Really interesting, some things I didn't know, thanks for shared.
Ooh for the new lispers could you show what you mean by hiding it? To my inexperienced eyes it looks exactly as it should. (No sarcasm.. I genuinely want to know)
What is the `let` for? To what clause does the `else` code belong? How many bindings are in the inner `let`?
[The whole book is online in HTML](http://www.psg.com/~dlamkins/sl/contents.html)
It's a bit disappointing to me to read something about Lisp in the present tense and discover that it was written 13 or more years ago. (Yes, I get the "history" part. I'm referring to the "State of the Art?" section.)
http://clhttp.plasticki.com
https://github.com/eudoxia0/lisp-site/blob/master/wiki/recommended-libraries.md
Derp - I meant to say 'machine code'. Will fix this imminently.
Thanks for those - added them all!
http://cliki.net/Current%20recommended%20libraries
The license inhibits wider adoption.
cl-opengl for graphics!
I found this when I was just starting, and find it very useful for those times when you don't remember the name of a function, or how it is used. I printed a copy, because it is more useful in it's printed version, at least for me.
Thanks, added!
Wow, some of those links are old as hell. Added all, with more modern links.
I like the idea and the presentation a lot. Handy. I'm not so keen into including additional packages such as alexandria or iterate (unless on their own separate tabs). If I were to make a suggestion: [find] item seq &amp;key from-end test test-not start end key ⇒ element If the sequence seq contains an element satisfying test, then the leftmost such element is returned; otherwise nil is returned. Functional variants are [find-if] and [find-if-not]. I think it would be better if the links: "find-if" and "find-if-not" pointed to the MiniSpec symbols and only have the first symbol (not the "hey, see also: ...") point to the HyperSpec. 
there should be some crowfunding perhaps. (Perhaps with less embarassing results than how this kind of thing ended up last time :-))
I too am interested in what tree shaking is
http://www.lispworks.com/documentation/lw61/DV/html/delivery-54.htm#marker-859860 &gt; The term "treeshaker" is derived from the notion that the routine picks up, by its root, a tree comprising the objects in the image and the links between them, and then shakes it until everything that is not somehow connected to the root falls off, and only the important objects remain. (An image would usually be better characterized as a directed graph than a tree, but the metaphor has persisted in the Lisp community.)
I certainly do not have the skill to do it, but perhaps someone does. That's why I was asking.
Yes.
How can you do that in a dynamic language with eval? It sounds like a Turing complete problem or your risk breaking runtime code?
Do you need EVAL in an application?
&gt; released December 29, 2014 just in case anyone wonders...
Yikes, hope this doesn't become a trend. This is a nice tool for the weary, but for the uninitiated LOADing over HTTP is a hand grenade with the pin pulled. The only reason this should ever be ok is if you are loading a script on an internal network where you control every piece of software/hardware serving the request. Even still, beware. Reminds me of the direct-to-bash one-liners people loved publishing not long ago: curl http://definitely-not-malware.com/dont-bother-verifying-me.sh | bash 
&gt; It would be nice if all implementations provided good SSL/TLS communication features. It'd be nice to have a good library written in a safe language that everyone could use instead of rolling their own.
Can someone tell me why I should be excited? We have really powerful and modern lisps today like clojure or racket. Its an environment I hope to never use. Its quite outdated to even compile on a modern OS. 
There is not much to get excited. As you said it might not even compile. Maybe somebody picks it up and improves it? Hard to say. Still, now there is another Common Lisp implementation available under MIT license. Maybe there is some code to be reused in other contexts? Maybe somebody learns from its implementation? Who knows. There are already people exploring and compiling it... There are a lot of working Common Lisp implementations. I'm not a Windows user, but the general support for Windows from low-cost Lisps does not look too good - that was the initial appeal for Corman Lisp. At the higher-end there are still Allegro CL and LispWorks, which both have good support for Windows. But Roger Corman wanted to write an affordable/compact Lisp which exclusively supports the MS Windows platform and an IDE for it.
It's exciting if you want to look at how a project was constructed, in the historical sense. I think there also may be pieces and components that can be re-used, like the C declaration parser or the customized Closette implementation. And I think it's also nice to see this sort of thing live on in some form rather than just die in obscurity. Nobody will twist your arm and make you download and use it. If it doesn't float your boat, you can comfortably ignore it.
I would recommend [Buildapp](http://www.xach.com/lisp/buildapp/).
I'd rather avoid having a dependency, I want static binaries to distribute in releases. :-/
You can't have portable images in Lisp. That is something I miss from Smalltalk.Smalltalk is great at that.
Thank you so much for your inspiration. I'm the idiot who wrote it to just let it rot together with a bunch of apps – I'm afraid tré stopped working ages ago. When it did – I shit you not – I could replace regular web development _teams_. At the moment I'm moving it on top of SBCL to make it work again and much more usable, too. I'm not Icelandic, btw.
Aren't there solutions for automatically setting up VMs and building things on them? 
Yes, namely vagrant. But there isn't any windows/osx VM as it would likely cause licensing issues.
I used CCL quite a bit. It has a delicious FFI and was easy to get up and running with a C++ executable. I could ping pong between eval'ing stuff in the CCL IDE and stepping through breakpoints in Visual Studio. There's no goofy unixy middle layer to wade through in order to make a functional native windows application and part of the Win32 API is directly exposed in CCL. That said, I'd probably still use SBCL at this point, since there is an active community behind it.
Perhaps, or perhaps they deflated any interest (and there was considerable interest, what was it, 2... 3 years ago) by doing weird things with the license. The people that love the idea including the people that were involved in the funding probably didn't care about the license, the people that were scared away by the license probably have moved on by now.
Stupidity is not a valid argument. If you don't know how to do it, learn. If you just want to start a discussion about interest of arrows in CL before actually implementing them, please elaborate.
There are differences between the different modified BSD licenses, they are similar but not equivalnet from a juridical viewpoint, besides the original BSD license might be unusual today but that is no reason to misuse the name of it in a context where it can be confusing. Furthermore the ISC license has problamtic choice of words which can be misused and there is no such thing as the "MIT license" which is also an ambiguous term. But yes, they all fall into the same category of licenses, but that is not the same thing. Court cases has shown that minor details in choice of words does make a big difference. I mean some people would categorise the licenses which you mentioned in the same category as the Pine license. And sure there is a point in categorising licenses, but one has to understand the dangers of considering them the same just because they fit in the same category. It's not that i like the idea of the choice of words being so important, it's just that it is because of how legal systems works. And i think people need to understand how important choice of words are in legal settings.
Totally bizarre. I think it's equally bizarre that the decision to make the change was left up to whether enough people would chip in a few bucks to make it happen. Though not more bizarre than the CL-HTTP license.
Wans't Mark Tarver rather [critical](http://www.lambdassociates.org/blog/the_problems_of_open_source.htm) of open source?
Do you use quicklisp? It's using HTTP, doesn't verify signatures and doesn't verify checksums. Anyone can trivially man in the middle it and force you to execute malicious code. Nothing different to CCL LOADing over HTTP. Quicklisp is in fact a lot worse, given the number of ppl who use it. 
Good point.
But why? iPython is just an inferior version of SLIME anyway.
I haven't used IPython Notebook. What does it do? What does Fishbowl do?
Doing everything properly is a lot of work so I don't blame Zach for not having done **everything** properly. Doing the simple thing first, which will deal with the prevalent attack vector, is extremely simple however. We do know from this year's CCC congress (31c3) that nation states do targeted surveillance. They build profiles of 'interesting' users and record what applications the target is using. Then they can focus on exploitation based on that application history they've built. So, what should happen first with Quicklisp, IMO, is checksum verification. This assumes that the user already has a good, non-compromised, Quicklisp installed, which is a valid assumption to make, initially. Quicklisp build scripts already do checksums for everything, so the information is **already there**. All Zach (or 3rd parties) need to do is implement the verification which is a lot simpler than doing signatures portably. I tried to do it myself but Quicklisp code is **TERRIBLE**, overengineered, undocumented junk, again IMO. I gave up, removed everything and did a full OS reinstall. With checksum verification, man-in-the-middle during package installation (which is the frequent operation) is completely defeated. One can still man-in-the-middle the Quicklisp install itself, but this happens infrequently and one would have to be in the middle at that exact moment in time. Eventually, you want to do signatures and HTTPS, but simple checksums are enough to start with. And of course, **WARNINGS**. The user should **NEVER** be left in ignorance, these should have been there from Day 1. I would bet money that if you asked a lot of Quicklisp users, the majority would say that they had no idea that anyone who can MITM HTTP (which is everyone on wireless and lots of others besides nation states on wired) can own their machines. 
If you're only doing checksums, how do you know the checksums haven't been modified? Otherwise when QL grabs its list of packages (and checksums) it could be MITMed to overwrite the checksum for any of the packages to support the version I want to nefariously inject. I think checksums would have to be paired with HTTPS to be effective. Luckily, I think setting up a domain/cert and running some SHAs is still going to be way simpler than verifying PGP signatures. I'm not opposed to that solution at all though. It would get us 95% of the way there, and make casual attacks nearly impossible.
The checksums are fetched at first time Quicklisp installation and during quicklisp client/dist updating which are infrequent operations. They are then saved on disk. The major attack vector is package installation, because it happens a lot more frequently. You are right in that we do need signatures and HTTPS for maximum effectiveness, I'm just saying let's start with something simpler that defeats the major attack vector and build on that. Once we have checksums, then even if Zach does none of the rest (HTTPS, package signatures) security-aware users can **manually** verify their locally stored checksums and determine if something is amiss. Zach could make that step easier by distributing and signing the checksums for a dist separately. 
Yep, he was and still is. An updated version of that essay is here http://www.marktarver.com/problems.html
&gt; quicklisp client/dist updating which are infrequent operations Fair enough, hard to attack at that exact time because it's unknown. Just doing checksums shouldn't be more than an hour or two of work (after a bit of research figuring out how QL works to begin with, never actually read the code) and a PR. I'll look into this in the next week or so if time frees up.
This still doesn't solve the problem of potentially running malicious code, because nobody guarantees that the code that Zach packaged up and checksummed wasn't compromised to begin with. This is when you really need package signatures and public keys that correspond to the package authors (not Zach). ASDF-INSTALL for example had that problem solved. But this doesn't mesh well with github and necessitates a 'release' scheme which ok might not be what everyone wants or needs. I'll be happy if MITM is no longer a concern with Quicklisp. 
So compared to a SLIME repl, ipython notebooks - have a decoupled frontend (browser, emacs) - can be replayed, updated - can easily embed pictures, other kinds of nifty stuff - have no debugger Is that a fair summary? I see a value in having a CL (swank?) backend to ipython and also in making the SLIME repl more capable.
[Discussion on Hacker News](http://news.ycombinator.com/item?id=8844329)
You can save an .exe running SBCL under Wine.
Have you looked into ReactOS, it is still on early stages but it is functional enough that you could try to install a Windows version of CL in it and produce a binary, without licensing issues.
Really? That sounds interesting
Haven't looked! Does it support Darwin too?
Thanks for the sample. Some day I may actually use it. Edit: I got down voted for saying thanks?
It is supposed to be compatible on the binary level with Windows NT and descendants, so you should be able to run there anything you can run on windows, is like Open Source, Free and Gratis Windows.
Have you seen [cl-notebook](https://github.com/Inaimathi/cl-notebook), it does not do markdown, it uses cl-who instead, but that could be easily fixed. As I see it it serves about the same purpose, there is a [video demonstration in vimeo](https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=4&amp;cad=rja&amp;uact=8&amp;ved=0CCoQtwIwAw&amp;url=http%3A%2F%2Fvimeo.com%2F97623064&amp;ei=7i6zVLWtN-fLsATJ94CYCg&amp;usg=AFQjCNFVGTmBJw1wfQJi-NZy32lA2VmyJg&amp;sig2=McwzBoXFNf0WxNw6xVDgyw) 
I've found cl-opengl to be great due to how closely it maps to standard gl. They have a lot of helper macros and functions expecially around vertex arrays (though I dont use those as much, as Im wrapping that myself). These can be ignored though if you just want 'raw' gl The naming format is very regular, you just knock the gl off the front of the name and uses hyphens instead of CamelCase. For example: glDrawArraysInstancedBaseInstance -&gt; draw-arrays-instanced-base-instance For enums its the same but also make it a keyword. So: GL_CULL_FACE -&gt; :cull-face When I started with gl on lisp I had around 6 months experience with lisp and none with gl so I feel ok in saying that the cl-opengl source isn't too terrifying, especially if you stick the the basic gl functions as well. Writing gl with this will obviously give you imperative, 'C-looking' lisp code though so you fairly quickly start abstracting (this can get addicting as cepl is a testament to!). There is nothing in gl I have tried yet that isn't supported by cl-opengl though so I would recommend trying it. The other massive benefit from lisp is the possibility of lisp-&gt;glsl compiling and the live updating of your code, that is just great fun. My little compiler is getting better but still doesnt support glsl fully. 3b is working on one which I haven't tried yet but given his experience is no doubt very good https://github.com/3b/3bgl-shader [Glkit](https://github.com/lispgames/glkit) looks handy but I haven't tested it. [SDL2](https://github.com/lispgames/cl-sdl2) is wrapped well and highly recommended. Also come on down to the #lispgames room on irc, we are often a little slow to respond but the folks that made the libraries are often there which helps massively is getting the best answers.
Thanks for the link, I didn't know about cl-notebook and I will definitely give it a try ... Note that even if the two projects share similar goals from a user pespective, technically the motivation is different. Fishbowl aims to be part of the Jupyter ecosystem. (Jupyter is a multi-kernel -- and *not* Python-centric -- version of Ipython currently under development).
Too little, too late. It just went to show the originator was too crazy to invest in - this doesn't change that in any way. It's a pity because I really liked the original language Qi and wanted it to succeed but we can't always expect the creator to have not just the technical insight but also the social chops to make it succeed. 
I don't know your knowledge of OpenGL. If your a beginner in OpenGL then you can learn using this widely recommended guide by Jason L McKesson: [Arcsynthesis](http://www.arcsynthesis.org/gltut/). It teaches modern OpenGL. I've found modern OpenGL CL guides also lacking (couldn't find any) and I went ahead and tried to translate the example code, with minor differences, into Common Lisp code [here](https://github.com/k-stz/arcsynthesis/). This also uses cl-sdl2. Caveat: I'm a beginner in Common Lisp and OpenGL. The translation is an on-going learning project and should only be useful to get running examples from concepts explained in each chapter of the book. The code is rife with notes-to-self comments. But it should suffice to understand how to deal with cl-opengl intuitively. The main problem which I found lacking in documentation was, as nikki93 pointed out, the translation of data to opengl owned data via cffi.
Yo dawg i heard you like locks so I put a lock in your lock... Anyway, pkhuongs blog is probably one of the most interesting blogs that I've ever read
Isn't the issue you are experiencing this: https://github.com/slime/slime/issues/201 if So it was fixed in a subsequent release (2.10 which was released the 8th of october)
Hey this is good to know. I'll update to fix that. (EDIT: Updated, and this works, thanks again! ) I definitely still want the typeout frame, because the echo area is being used by other plugins, and I'd like to be able to look at the messages, even if I move my cursor outside of the sexp. 
Hopefully merging tonight!
I have removed it. The user should reenter it with the direct link. I've sent him a message.
In the Lisp world it is not unusual to implement a small Lisp interpreter and then update the language from there... initially a C compiler is needed. Maybe sometimes assembler, too. ;-) 
How perfectly beautiful!
Whoa, the Y combinator works on humans too?
Kind of an aside: is there a way to install Quicklisp packages system-wide, rather than locally in a user's home directory? I like Quicklisp's dependency management and updates (vs. e.g. pulling Lisp packages from Debian with apt-get) but I don't want every user to have to have their own copies of every library. edit: I found this project from a few years ago, but it seems to have been abandoned, and uses a bit of a hack (it creates a "quicklisp" user whose home directory is in /usr/share and chmod'ed to be pubic). https://github.com/sebyte/swiQlisp
This is great! Is there any way to query quicklisp for the "most installed" or most popular packages? This would be really helpful when selecting similar libraries.
I haven't looked at your code yet, but if you're having trouble calling read-char and having it hang, then #'LISTEN might be of service. http://www.lispworks.com/documentation/HyperSpec/Body/f_listen.htm
Thank you, this was wonderful news to read about. I heartily agree that offering the opportunity to learn from a newly Open Sourced commercial Common Lisp implementation is effort very well spent. Anyone who's left wondering why this should be done could ask the same about any open source project that shares functionality with any other existing project. The answer is simple of course, because at the very least, the more curious of us will learn, and that alone is enough of a reason. But, just as important, the more imaginative of us will lead after they've learned. Hats off to Roger Corman and to Zachary Beane for doing us the favor.
Very nice! Am I correct in seeing only 512 sloc? Pretty amazing.
Tried making this work on windows 7 x64 with ccl x64, sdl didn't seem to like the format the images were in. ran out of time trying to convert them to uncompressed bmps.
LOL. Latest bug fix. [Fixing parens.](http://i.imgur.com/nvcjtX7.png) Of course. EDIT: *(setq sense-of-humour nil)*
&gt; I think are related to trying to use 32bit libraries in hindsight Any reason you're opposed to using 32bit CCL? Windows x64 essentially comes with a multilib that can run 32bit or x64, so if you're building a cross-platform app, 32bit libs in windows is a safer choice (could run on XP or even earlier, for example). When I'm in windows (also on 7 x64) I'm almost exclusively using `wx86cl`. Most libraries distributed in binary form are 32bit, many cross-platform games are distributed on windows as 32bit, etc. If you truly want x64, I suggest you figure out a way to compile the libs you want *from source* to x64 and redistribute those, but keep in mind you'll be leaving quite a few potential users out. TL;DR using 32bit CCL and DLLs on Windows is a perfectly fine choice, especially if redistributing and app and *especially* if using pre-compiled libraries (like GTK).
Thanks.
A couple things: On SBCL I encountered all kinds of floating point errors and I had to wrap the `sdl:with-init` form with `(sb-int:with-float-traps-masked (:invalid :overflow :divide-by-zero) ...)` to get the game to run. Some Googling suggests these are being trapped from within foreign function calls: http://comments.gmane.org/gmane.lisp.steel-bank.general/3882 so this may just be an SDL thing. Also, I've seen this same trick with swank to enable interactive development with OpenGL, but for both OpenGL and SDL I can't interact with the external window when running a multithreaded SBCL (hovering the mouse over it shows the spinning pinwheel cursor). This may be related to an OS X restriction that prevents OpenGL API calls being made outside the main thread of an application, but since the graphics render just fine, I hope it's something else that can be easily fixed.
I hope so too, in opengl/sdl projects I have no issues on linux or windows, only osx. My hunch also is that it isn't what thread the gl calls are made from.
Please, do write your progress and process somewhere. I would love to do cross platform ui from common lisp but previously have got stuck and run out of motivation.
I've played around with an evaluation version and it is quite nice. I haven't gone with it for any of my projects, though, because the price is steep if your project doesn't have a "real" budget, mostly because of the per-platform licensing policy. If you want to ship Windows/OSX/Linux binaries, you need to buy 3 licenses, or 6 if you want to ship both 32-bit and 64-bit binaries. The cost is $4500 for 3x 32-bit, $13500 for 3x 64-bit, or $18000 for all 6 combinations. Of course if you have a real funded project it's not prohibitive; even $18k is way less than one engineer costs. And as an academic I can get the licenses at a 50% discount. But even still, my budget unfortunately doesn't support thousands of dollars in licenses.
Ha. Thx. I also love Lisp. Editors take most of the pain out of parens for us, so when we trip up on them I think it's honest to laugh/curse at them. :) A bit like tabs-vs-spaces in Python, or curly braces in C, or a stack underflow in Forth. It's gonna happen, so we must see the humour in it. Cheers.
It says: previous version of this compiler OR on alternative implementations of the language. So you don't really need alternate implementations forever. As long as your compiler runs on itself, then when you change the source code of your compiler, the current implementation now is the 'previous' version from the POV of the newly modified source code. The 'alternative implementations' thing might be useful for the very first few versions of the compiler.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Memory hierarchy**](https://en.wikipedia.org/wiki/Memory%20hierarchy): [](#sfw) --- &gt; &gt;The term __memory hierarchy__ is used in [computer architecture](https://en.wikipedia.org/wiki/Computer_architecture) when discussing performance issues in computer architectural design, algorithm predictions, and the lower level [programming](https://en.wikipedia.org/wiki/Computer_programming) constructs such as involving [locality of reference](https://en.wikipedia.org/wiki/Locality_of_reference). A "memory hierarchy" in [computer storage](https://en.wikipedia.org/wiki/Computer_storage) distinguishes each level in the "hierarchy" by response time. Since response time, complexity, and capacity are related, the levels may also be distinguished by the controlling technology. &gt;The many trade-offs in designing for high performance will include the structure of the memory hierarchy, i.e. the size and technology of each component. So the various components can be viewed as forming a hierarchy of memories (m1,m2,...,mn) in which each member mi is in a sense subordinate to the next highest member mi+1 of the hierarchy. To limit waiting by higher levels, a lower level will respond by filling a buffer and then signaling to activate the transfer. &gt;There are four major storage levels. &gt; &gt;* *Internal* – [Processor registers](https://en.wikipedia.org/wiki/Processor_register) and [cache](https://en.wikipedia.org/wiki/CPU_cache). &gt;* Main – the system [RAM](https://en.wikipedia.org/wiki/Random-access_memory) and controller cards. &gt;* On-line mass storage – [Secondary](https://en.wikipedia.org/wiki/Computer_storage#Secondary_storage) storage. &gt;* Off-line bulk storage – [Tertiary](https://en.wikipedia.org/wiki/Computer_storage#Tertiary_storage) and [Off-line](https://en.wikipedia.org/wiki/Computer_storage#Off-line_storage) storage. &gt;This is a general memory hierarchy structuring. Many other structures are useful. For example, a paging algorithm may be considered as a level for [virtual memory](https://en.wikipedia.org/wiki/Virtual_memory) when designing a [computer architecture](https://en.wikipedia.org/wiki/Computer_architecture). &gt;==== &gt;[**Image**](https://i.imgur.com/V30sG03.png) [^(i)](https://commons.wikimedia.org/wiki/File:ComputerMemoryHierarchy.svg) - *Diagram of the computer memory hierarchy* --- ^Interesting: [^Random-access ^memory](https://en.wikipedia.org/wiki/Random-access_memory) ^| [^Write ^combining](https://en.wikipedia.org/wiki/Write_combining) ^| [^Locality ^of ^reference](https://en.wikipedia.org/wiki/Locality_of_reference) ^| [^Processor ^register](https://en.wikipedia.org/wiki/Processor_register) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cnwucyo) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cnwucyo)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
I had exactly the same issue in Clojure the other day - except with Clojure the command is `(flush)` It was quite a surprise, because I'm used to shit like this from a low level language! There are always little gotchas in every language you learn, I find.
Thank you! :)
Also you may be interested in using sdl2 https://github.com/lispgames/cl-sdl2
extempore
In C, option B is not generally true if you created the FILE stream with fopen() on a regular file (as opposed to a pipe or tty).
Doesn't seem to actually 'manage' windows. It's just a full screen emacs with the ability to start applications - which is not new. A window manager would be something like StumpWM: https://github.com/stumpwm/stumpwm
Interesting. How well does StumpWM work in practice?
It's pretty good. The default configuration can be a little weird for someone who's used to other tiling managers like Xmonad or AwesomeWM, for two reasons: * It uses Emacs style keybindings (prefix key combo + something), over the more "direct" keybindings of other managers (modifier key + something). * It doesn't directly tile windows, but rather split the screen into frames, each of which holds a stack of windows. But with a little [configuration](https://github.com/eudoxia0/dotfiles/tree/master/.wm) it can be a very comfortable experience. It's also much easier to configure if it's built with the programming language you know best.
I think the sense is "I use emacs and get rid of any windows manager, unless I need it"
That's a terminal multiplexer, like tmux, not a window manager
&gt;Is that really the problem? Even when writing to standard output you would have horrible performance, because the program would do a write system call for each character, and a system call means a context switch, which can be expensive. That's true. But seeking on a mechanical disk would be the worst as far as performance goes. If you're putting pages in swap on disk on every context switch, that would incur the same sort of penalty, but you would have to fill your RAM to start thrashing that bad. You incur that penalty every time if you were writing to disk unbuffered with every call. &gt;I'm not sure the picture is very different when writing to a disk, because even if you did a write syscall for each character, a good kernel would presumably buffer the writes to disk, wouldn't it? You would hope. But reifying buffering so it can be manipulated by the programmer allows the programmer the ability to deal with efficiency issues, which may go beyond that particular scenario. Not only that, but then the programmer would have to be familiar with the OS characteristics around buffering characters when writing to disk. Do Linux, BSD, Mac OS, Windows, etc. all have the same performance characteristics when buffering output to disk? Has the user disabled buffering? So it ultimately comes down to a design decision, how much should we expose to the programmer? I will say that it is somewhat annoying to have to worry about this on occasion, but it's more annoying when you need it and don't have access to it, which means either relying on an FFI pulling in some C code or looking for another language that allows you to fret over performance details.
Thanks FloatingHand. I am a novice at Lisp and SDL as well. Last September I decided to properly learn Lisp by creating a Roguelike. For learning Lisp I started with 'Land of Lisp' by Conrad Barski and 'Lisp' by Patrick Henry Winston. I learnt SDL by first going through a couple of the lessons on Lazy Foo http://lazyfoo.net/SDL_tutorials/ and converting them to Lisp. Then I just worked on making the RL game, tackling one issue at a time, with the aid of the Lispbuilder-SDL API reference and Lispbuilder-sdl examples. Occasionally I would look at other developers source code to get ideas on how to tackle certain issues/tasks. There are hardly any Lispbuilder-sdl tutorials on the web.
I took a look at your videos, baggers, and it looks great! I am hoping to see this continue to grow.
Somebody was complaining for something like this on 8ch /prog/, glad someone else got around to this. They were concerned over large binary sizes, maybe this will help.
&gt; cl-annotations I fail to see that as an example for Macros. AFAIK it's a Reader macro, which provides syntax for the Reader.
My first line of defense is to say that reader macros are also macros. If that fails I'll just blame it all on my fever 
You may have seen this: https://gist.github.com/burtonsamograd/f08f561264ff94391300
LOOP, ITERATE, SERIES and related...
Aye it's tricky, however I'm kind of interested in talking about macros in the broader sense, the when and why, and what a language with macros becomes with relation to itself without macros. I'm hoping to convey the idea that for explorative coding macros allow you to investigate through language rather than just to investigate using a language. So cl-markup is actually a nice example, as I don't to break down exactly how they do it, just what the effects are. Cheers
Sorry I should have been clearer, editted the question
[Screenshot](https://dl.dropboxusercontent.com/u/46753018/Screen%20Shot%202015-01-19%20at%2001.29.31.png). It's in its early days, but it has a working compiler, garbage collection, etc. It was announced on the Freenode `#lisp` channel; start [here](http://log.irc.tymoon.eu/freenode/lisp?around=2015-01-25T15:08:33&amp;types=mnaot#1422198513).
My one simple macro that I really like is one where I give it a bunch of bindings and it prints their names and values. e.g: (inspect foo bar) =&gt; foo: "hello world" =&gt; bar: 42 That's something that I always wanted for debugging and that was never possible in languages without macros. Though thinking about it, it may be possible in languages that support a degree of introspection, e.g. ruby and such PS: Checked for both ruby and Javascript: It's impossible! Yay :D
I am very excited about this project! I wish them the best of success. Hopefully this project can advance rapidly (hint to developers: think about requesting support from Google's summer of code, crowd funding sites, and government grants). I believe this project can become the best Lisp in all dimensions: support of modern libraries, fast code, and small executable size.
I assume it's open source. Would it be a good code base for an experienced programmer to learn lisp?
Who knows? It's only just been released and it's just something that one guy hacked together over a number of years.
Yes, it's open source under a MIT license. It will be on Github soon.
I have such high hopes for clasp. Excited that progress was made!
I may be biased, but some of the macros in [blackbird](https://github.com/orthecreedence/blackbird) are kind of cool. Specifically, the [alet](https://github.com/orthecreedence/blackbird/blob/master/syntax.lisp#L3)/[alet*](https://github.com/orthecreedence/blackbird/blob/master/syntax.lisp#L68) which provide `let`/`let*`-like bindings for promises, and [chain](https://github.com/orthecreedence/blackbird/blob/master/util.lisp#L86) which takes a flat list of operations and builds a hierarchical tree out of it. The idea is that you can use promises + macros to circumvent the CPS callback hell that many non-blocking libraries/apps have without sacrificing much in readability.
It means nothing. It was just a joke.
Good call, yeah I think these may well make an appearance. Thanks!
I'd recommend taking a look at Shriram Krishnamurthi's Automata via Macros - the paper uses Scheme, but porting it to CL should be straightforward. http://cs.brown.edu/~sk/Publications/Papers/Published/sk-automata-macros/
My answer will be off-topic, since it won't be about Lisp itself. But I think applications written in Lisp, such as Emacs or StumpWM, can contribute directly to the popularity of the language. Maybe I can reformulate this point in order to be a little bit more close to the topic - and as a beginner I might very well be wrong: I think Lisp, **as a language**, tend to produce pieces of software that can make Lisp immediately useful and attractive, and maybe a bit fascinating. I will quote Richard Stallman: &gt; The special properties of Lisp, which make extensibility possible, are a key feature, even though many of the users will not be programmers. Lisp has escaped from the ivory tower forever, and is a force to be reckoned with as a system programming language. (https://www.gnu.org/software/emacs/emacs-paper.html#TOC28) I will talk about my personal experience here. I began to learn Emacs in 2009, learned to hack a little bit of Emacs Lisp, got used to the syntax. I was viewing Lisp like a non-programmer tool, I could manipulate a piece of software that was useful in my everyday life with it. Soon I wanted to do more, I needed to manipulate other things, system-wide. I remember my very first need was to rename files based on their EXIF data. I was already familiar with Emacs Lisp, so I decided to learn Common Lisp. I loved the idea of interacting with the Lisp process using the REPL. But the real next step for me was StumpWM: it was like Emacs, but with Common Lisp. The Lisp process became even more fundamental to me since it was the center of my entire desktop experience. Today I want LispKit to be my everyday browser very bad and I learned about Mezzanine (the LispOS) with very much excitement :)
Lisp is a meta-language. It can be easily turned into *any* other language, therefore, it combines strengths of all the existing and not-invented-yet languages. Of course, any other sufficiently powerful meta-language can do the same, but Lisp is by far the simplest and the most basic of them.
* documentation - **self-documentable** part is almost non-existent in CL, which is pretty shame as elisp/clojure are extensively using it * binary size dump - I like *image* concept, but &gt;50MB for anything serious is a bit too much * professional/commercial implementations (ACL, LispWorks) are way too expensive * hyperspec documentation is ugly
IMHO, the biggest weakness of Common Lisp is that the purity of the original Lisp is lost and there are too many black boxes hiding the "Maxwell equations of computing". Such a huge machine doesn't allow a non professional coder to write his own language: http://epsilonwiki.free.fr/alphawiki_2/?view=lambdabook , and a "lambda" user to use it, for instance: http://rue74.fr/farm/italy/?view=Mythology%20quiz Alain Marty 
As both a dipshit and dilletante I concur. You forgot smug weenies though.
Emacs. It's not a problem with CL but when I started trying to learn it this summer I found that I'd also need to learn Emacs. I hate Emacs (I also hate VIM if that's any consolation), I don't want to learn Emacs, I want to learn Lisp. CL integration into other stuff is really lacking - I think because Emacs has everything no one bothers writing alternatives. For instance I don't know of another formatter that works. So while I try using Geany (F5 loads the file in SBCL or CLISP) I use this bash function for indenting and reload the file; function lispindent { emacs -Q -batch --visit "$1" -f lisp-mode --eval '(indent-region (point-min) (point-max))' --eval '(save-buffer 0)' } Which isn't exactly ideal. So mostly I've switched to Racket, DrRacket probably seems like a toy to Emacs users but I've been getting on much better with it. Although I wish there were Racket versions of the books Practical Common Lisp, and Land of Lisp.
No matter what criticism you might have of it there is always someone who knows better than you regarding x y or z (despite any lack of experience with your business or operational needs).
Metaprogramming. Run time metaprogramming through the MOP and CLOS. Compile time metaprogramming through macros. Also that it has well defined behavior for updating itself while it's running. Most people get stuck on weird issues about the language, like using first and rest instead of head and tail, or that you have to use a reader macro to look up a function, or whatever. Those are tiny issues, but I think they can be understood immediately from using the language. Much harder is to understand the framework and system provided, what it does for you, and how you can leverage it. CL has much more depth as a system and platform than other languages and other Lisps. More people should leverage the MOP and CLOS. Too many people come to CL that have been influenced by snobbery about objects and don't get to see just how nice working with CLOS and the MOP is, how generic functions break their notion of OOP, and how you leverage incredibly rich pre-existing semantics to easily create powerful object systems that can live side by side with the given one in the same image. Macros are cool, sure, but you're only getting one side of the metaprogramming coin.
The language itself isn't an issue. For me, my personal problem is that CL has so many detractors, both inside and outside the language. I wish more people would try it out, stick around longer than it takes to write a blogpost about using it, and see what's actually there. But there are so many detractors that you have to swim through a sea of negativity and doubt about the language before you type one paren. So yeah, I don't really want to contribute anymore negativity. There are numerous posts about all the things people think are wrong with CL, I don't feel like contributing more is going to help anyone, aside from the people who want to use the language as a philosophy prop rather than write software.
Disagree. I often sigh when I have to dig through CLHS. The examples are sometimes really esoteric and tangential to just letting me know how something works. It's a great reference for things I already know, but as far as learning new things from the spec it's fairly difficult *sometimes*.
On the subject of dilettantes (which can be very smart people, incidentally) I think I can offer an explanation of why this seems to be the case: Common Lisp _promises_ the elegance of the lambdacalculus, but in reality is a very large, highly technical language which requires significant experience to use correctly and appropriately. So the promise of simplicity ropes in the dilettante because dilettantes like simple things they can understand easily, and then the language itself casts into stark relief their lack of interest in engaging seriously with what is, after all, an industrial strength programming platform more akin to C++ than the lambda calculus. 
Missing continuations (or some form of manual stack manipulation). I would really like language-supported coroutines/green threads. This can be replicated with cl-cont and [green-threads](https://github.com/thezerobit/green-threads) (built on cl-cont), but cl-cont is a hack on top of CPS that doesn't provide real error handling and also requires wrapping all your code in macros. That said this can be somewhat solved with promises, but it would be nice to be able write async code as if it was synchronous.
I like the ability to change the language with macros, CL's real threading (on most implementations), and the ability to have both dynamic and lexical scoping.
It lacks the hipster cachet of Clojure and so is not sexy enough for 'modern' programmers.
I can't believe I've not heard of this before, thanks.
[the source code](https://github.com/froggey/Mezzano)
IMHO, tools for developers and for software distribution. We have very cool tools (quicklisp come to mind), but ot really attract more people to use lisp we need better tools. For comparison, imagine a run-of-the-mill Joe that want to start a new lisp program in his *super cool* windows notebook. Try to imagine the "adventures" that the guy will put himself into until he have a confortable environment. Now, do the thinking again but replace "lisp" with (for example) "haskell". Can you see the difference?
Thanks, I did really enjoy reading that. So to understand the problem correctly, he's saying that `unwind-protect` can only work with single-use continuations? From my understanding, single-use continuations can't be used for coroutines =]. I did not know `unwind-protect` and continuations were in direct conflict.
just in case: https://mitpress.mit.edu/sicp/full-text/book/book.html
There are plenty of practical reasons to choose Clojure over CL. One obvious reason is that the JVM is a very popular platform used at many companies. This makes it much easier to introduce Clojure than CL. The JVM also has plethora of mature libraries pretty much for any task under the sun. Having a much bigger community and wider use results in having better tooling, documentation, and other resources. Not having to use Emacs is a pretty big deal for people who aren't already using Emacs. Clojure has lots of editors options available, which makes it a lot more appealing to the general public. Clojure defaults to the use of persistent data structures and makes working with them easy and natural. It encourages writing referentially transparent code by default. On top of that Clojure provides excellent STM facilities for working with shared mutable data. CL doesn't offer anything comparable in this regard. It's also worth pointing out that there are some pretty big differences between Clojure and CL syntaxes. Clojure has a number of features that greatly aid code readability in my opinion. The literal notation for data structures breaks up the code visually and makes it easier to scan. Compare CL code with its Clojure equivalent below: CL: (defun foo (a b) (let ((c (+ a b))) (print c))) Clojure: (defn foo [a b] (let [c (+ a b)] (println c))) I certainly find the latter a lot easier to read. I also think the fact that CL overloads the meaning of lists to be somewhat confusing. For example, why is `defun` called, while `a` is not when the exact same syntax is used in both places. With CL, when you're reading the code you just have to know whether something will be called or not and there's no indication from the syntax itself. On the other hand, Clojure has consistent semantics for lists being callable. When I see a list I know the first element is what's going to be called and the rest are parameters. When I see a vector I know it's just a data literal. The only people I know who prefer CL syntax are those who are already used to it. Practically everybody coming from another language finds Clojure syntax more intuitive. The only justification for why CL syntax is preferred that I've ever seen is personal familiarity. Clojure also provides destructuring, where we can easily write out the parameters to a function: (let [[smaller bigger] (split-with #(&lt; % 5) (range 10))] (println smaller bigger)) (defn print-user [[name address phone]] (println name "-" address phone)) (print-user ["John" "397 King street, Toronto" "416-936-3218"]) (defn foo [{:keys [bar baz]}] (println bar baz)) (foo {:bar "some value" :baz "another value"}) The threading macro is also extremely helpful in flattening out nested expressions: (reduce + (interpose 5 (map inc (range 10)))) when we use the threading macro it looks a lot more natural: (-&gt;&gt; (range 10) (map inc) (interpose 5) (reduce +)) Little things like that really add up in the grand scheme of things.
Somebody said Emacs already, but what bothers me most is that so few editors are out there that will handle Lisp gracefully. I've used SLIME and Light Table, and Hemlock and Guilemacs, I've tried it all. Most were decent, but anything even similar to emacs at this point makes me gag. SLIME was some of the most poorly designed tooling I have ever used. Currently, I'm writing a curses-based roguelike in ruby with just nano and rvm for coverage. I've never been more comfortable with a development setup. Unfortunately, Lisp requires a bit more than just highlighting, since parens are so deeply ingrained into the language. I want to love Lisp, I really, truly do. Maybe another time, another place, so they say. 
That's a great attitude :-) We should write more software and talk less about what is good and no so good in the language. 
I think Common Lisp: The Language is much more readable to discover new things. Not nearly as dry, also not as precise and of course not the final word, but a fun read.
The things that are still tripping me up:* 1. Emacs. I hate emacs. Better/easier support in *any* *other* *editor* or even having an inoffensive editor built into the REPL would IMHO help a lot. 2. Lots of one-off syntax to remember. The operations that work on an array are different from a hash. Why? Loop is a bunch of syntax that does not show up anywhere else in the language. Same thing for format. I don't know if they add up to more or less than, say, C++ or Java (with which I am fairly adept) but so far they've proven to be hard to learn. 3. The almost-compatible variety of implementations. I think this is because there is stuff (like network functionality) that is just plain missing from the standard, so it ends up as a defacto-required but spec-optional extension. This is something that I'd love to see fixed in a CL2.0 or CL2016 (or whatever). 4. The idea that Lisp is primarily interesting as a functional language. Lots of other languages do functional in a cleaner, easier way. If instead you think of Lisp as a metaprogramming language, then it's a lot harder to find other languages that do it better. The only ones I've seen the same level of flexibility are Perl and Forth. In Perl it's a dangerous, hot mess; while Forth is a serious neck-pain about storage and lifetimes. * I'm something of a n00b in CL, having written only a few hundred lines and having never shipped anything written in it.
I feel like Clojure's syntax has too much noise compared to CL's though I'm not saying it's bad, because you end up writing less. I dream of a Lisp on top of LLVM, like CL but without all its warts.
* Lack of guaranteed tail call optimization. * Environments aren't standardised to be introspectable * There is no lexical EVAL in the language * Generic collection/sequence support in the core language could be better. * The standard has frozen the implementations somewhat, so that while they extend it here and there, they don't seem to be marching together to fix some of these issues - some things can't really be fixed by the community with a library of macros. None of these are that terrible in and of themselves, I feel like I should now go to the "Honest question" thread to list features that I like.
If he supports a commercial OS, he might as well pay for a commercial Lisp, like LispWorks or Allegro CL. &gt; Try to imagine the "adventures" that the guy will put himself into until he have a confortable environment. With LispWorks he/she basically has to start the installer...
Common Lisp promises to be backwarts compatible with community practice. LOOP comes from the late 60s from Interlisp (called FOR in Interlisp) and FORMAT comes via PL/I and Maclisp... It was community practice to use those. There was a lot of discussion about adding LOOP, but eventually it was put in because it was the best iteration construct with wide use. CLtL1 didn't have the extended LOOP - even though implementations were in use for years. Eventually it was added... Common Lisp continued to support them.
&gt; I don't think Common Lisp promises elegance. I don't think it does either, but maybe people think it's going to be elegant. I mean LISP (in all caps, of course) is basically the untyped lambda calculus, right? What could be simpler and more elegant than that? You can see everywhere people wanting to learn Lisp because it's functional. In short, I think it all comes from the gigantic amount of misinformation floating around.
This is great! Is there an alternative to https://www.gitbook.com/donate/book/lfe/sicp that accepts donations without entering a credit card? Like PayPal, Amazon, or Google Wallet?
I think the lambda-calculus connection is often overstated. Mathematicians have noted since the 1960s that Lisp was *not* an implementation of the lambda calculus, rather a language vaguely inspired by the same idea of functional abstraction, which borrowed the term "lambda" but gave it different semantics. In particular, Lisp for decades had variable resolution rule that to mathematicians was weird, nowadays called "dynamic binding". This had the advantage of being easy to write an interpreter for, but caused Lisp's semantics to diverge from the lambda-calculus semantics from the very beginning. As a result, theoretical results generally were not shared (theorems true of lambda calculus did not cross over to Lisp or vice versa), and the two communities did not have that much contact.
&gt; one of the best documentation ever written This is what I was disagreeing with, not with its value as a reference. As a reference it's extremely informative. As a source of documentation, it's very frustrating to read. I personally think documentation is for teaching and reference is for what's already known.
&gt; It is a magnet for dipshits and dilettantes. That is rather an unattractive elitist position to hold.
I wouldn't call it noise because it provides useful visual information when you're scanning through code. Noise is something that's incidental and doesn't carry useful information.
Do you mean "functional" as in "first-class functions" or "functional" as in "side-effect-free pure functions", or both?
Source, etc.: http://www.sebity.com/games/the-invaders.php https://github.com/sebity/the-invaders
What's wrong with SLIME?
&gt;hyperspec documentation is ugly Having dealt with several languages specs (including C++, that was something...I guess it damaged my mind) I'm telling you, hyperspec is paradise. Where other introduce obscure concepts which are often in conflict and behavior is ambiguous, CL spec has few concepts (due to CL orthogonality) and behavior is clear.
https://dl.dropboxusercontent.com/u/46753018/Screen%20Shot%202015-01-19%20at%2001.29.31.png
Thanks, makes more sense now 
&gt; If he supports a commercial OS, he might as well pay for a commercial Lisp, like LispWorks or Allegro CL. Not necessarily. I can assure you most "Joe's" will immediately think "What? PAY for lisp? No way, java is free..."
What's the relationship between [Mezzanine](http://www.reddit.com/r/lisp/comments/2tmu60/mezzanine_a_common_lispbased_os_runs_under/) and Mezzano? Similar names, similar projects, announced nearly at the same time
Is backwarts compatible a pun?
From the horse's mouth: http://ircbrowse.net/browse/lisp?id=8939829&amp;timestamp=1422227749#t1422227749
The idea is that named optional parameters are better than unnamed optional parameters. It makes them also better extensible, in case new arguments are needed. One can use subsets of named parameters in any order. Common Lisp has other conventions and argument list facilities than ruby/python/julia. Best not derive style from there, but let the design of Common Lisp be consistent. I want for example allowed to write (iota 10 :step 2) Named arguments can greatly enhance readability of code and it is hard to say where the threshold is when one should use them. Best not to have a threshold and let the developer decide.
This is why I dabble in Scheme and not Lisp because I enjoy to see how much you can build with pure building blocks instead of just a regular imperative language with macros on steroids. I mean by that its really not that clever or exciting or exotic language, it's exceedingly pragmatic. 
*Mezzano* is an almost-archaic italian word that used to mean *mid* (hence *mezzanino*: a floor between two others, eventually *mezzanine* in french and then in english). But nowadays *mezzano* is used almost exclusively to mean a procurer of love, that is, a pimp. (Wonder if the author knows this...)
You don't want them in your community; they make you look bad. Java is a great language you can do interesting things in but it gets a lot of flak simply by having those programmers in it. 
IMHO Scheme is for functional-programming, CL for meta-programming. Standard required TCO and reader-macros I submit as proof. 
&gt;Having some good guidelines can buy us a wonderful standard library. We do &gt;My point is that I should like to see a library that follows some reasonable guidelin It does Isn't it better to be explicit rather than implicit according to Python?
Zen of Python
Use whatever notation you find useful. Lisp is not using math notation. Thus it does not make sense to use that as an example. If you look at Lisp there are different camps: * Short as possible and domain specific: Arc is an example for that. * Descriptive as possible: Common Lisp is an example for that If you really need concise math-like operators consider using Macsyma/Maxima or Axiom instead. In a large Lisp system there can be many thousands of different operators/functions. Probably tens of thousands. Micro-optimizing them isn't much of an advantage there. If I read (iota 10 5 40) I actually have no idea what 5 and 40 is for. Being able to read what the :step value is, is a help. Remember, not everybody is a mathematician and there are lots of other domains which are not obvious to you, but are obvious for domain experts. It would help me, as a non-domain expert, if they write their code in a more descriptive way. If they want to have a tool for themselves, they can use a specialized tool. If I want to support them from within Lisp, I would add special notations for them. C++ uses iota(first end start) Scheme uses Iota(count start step) Which one do we use? You propose: Iota(start end step)
In maxima they use makelist(fun,i,start,end) there is no step possibility. I don't know why people choose iota (perhaps from APL or J using the initial of interval?). If we are going to develop a library like Alexandria, why don't we use range and follow the usual order start and optional end and step? If you are not a mathematicean perhaps range is a better word than iota. It doesn't have any sense to define range with start = 1 and step = 10 since you can't say what is the end, there is no way to determine the end of that sequence. But if you say that start = 1 and end = 1 and there is no step then step is going to be 1 that is the usual convention. So here there is a semantic meaning that give us the only way in which the range or iota function can be defined in such a way that the one, two and three arguments version are clearly defined. The initial value by default is the same that is used to index an array. 
Can be easily added as a library.
How so?
Another way to look at that issue is that call/cc is more important in Scheme than unwind-protect; and therefore, we should keep call/cc as is and require that programmers be careful with it and be aware of the consequences of its use in their programs. call-with-port could simply be: (define (call-with-port port proc) (let ((x (proc port))) (close-port port) x)) I think the situation is similar to non-termination in the typed lambda calculus. You can guarantee that all programs terminate if you omit general recursive types but recursion is a powerful feature so we usually prefer to weaken our reasoning power in order to increase our expressive power. In the context of Common Lisp, it's the other way around: unwind-protect is more important than call/cc. So you probably don't want to introduce call/cc into CL. However, unwind-protect does not clash with coroutines or threads, whether native or light-weight. Therefore, a good way to proceed would be to consider coroutines and light-weight threads as primitive language features instead of features built on top of continuations. Edit: Fixed the code to return what the proc returns. I haven't attempted to deal with multiple-value returns because I don't know Scheme well enough. Edit 2: Added the bit about Common Lisp.
Because your code is not just lists ? It seems like it might cause problems but I've never done much generation. 
That's not what homoiconicity means though. What it means is that your code can be treated as data and vice versa, having additional literal notation doesn't affect that in any way. It doesn't cause any problems in regards to code generation and macros in Clojure work just the same way as they do in any other Lisp in that regard.
Emacs itself is a roadblock for the vast majority of users. It behaves very differently from practically every other editor out there and it has a fairly steep learning curve. Having to learn Emacs along side CL is simply a deal breaker for most people.
Most people aren't going to spend money just to try an obscure language out. The fact that there isn't a free simple to use development environment is most certainly a barrier for potential users. 
I can't speak to Ruby or Clojure, but you simply can't learn Python without learning `range`. It's builtin function which is idiomatic to use liberally throughout your code, so keyword arguments would just mean more typing for every programmer. But `iota` is a library function. You use it when the builtin constructs that handle most of the normal cases involving consecutive numbers are not a clean fit for the problem at hand. In all my Quicklisp libraries it's only used to generate data for a few tests in cl-num-utils, and even then it's only passed the first argument.
The threading macro is not more *natural*. Granted it *looks* cleaner. But all you are really doing, is moving some end parentheses around and reversing the functions. It is only *natural* to imperative-only programmers who only think of what order things need to be done. Mathematically is it not natural. To a functional programmer it is not natural. You have arguments on the right and left. It is hard to manipulate the expression or inner expressions because the only thing that is complete is the whole thing or the first expression. The AST is gone. In your example, what if you want to change what reduce calls or you need to add an optional/keyword parameter to one of the function calls? If you reversed everything and put the functions last, at least it would be consistent: (&lt;&lt;- (10 range) (inc map) (5 interpose) (+ reduce)) Of course this would be even worse to manipulate. The destructuring on a defn looks cool. great for cranking out code. But what if [name address phone] changes to an object. This encourages one not to abstract data. I might use this during development. But in the end I would factor it out. The rest is just personal preference. The difference is common lispers don't *see* parentheses; you do.
I wonder how she would portray Perl, as you can write functional code in it as well. http://hop.perl.plover.com/ Although it does mention Python: &gt;Many Force-sensitives without formal Jedi training designed languages, for example [this one](https://python.org), that used the Force freely, mixing it with teachings from the Ninja and many other Sages.
There's slimv for VIM which works quite well. You could try that.
Well below a certain size a hash lookup is less performant that a linear search. Also by default common lisp doesnt have print support or a hash literal syntax. These are easy to add however. So creating a hashtable with one element is CL-USER&gt; (defparameter h (make-hash-table)) H CL-USER&gt; (setf (gethash :a h) 1) 1 as opposed to CL-USER&gt; (defparameter h '((:a . 1))) for an assoc [edit] Here is quick gist of how you could add hash-table literal syntax https://gist.github.com/cbaggers/7a0d432e45a71dd024af Behaves like this: CL-USER&gt; (defparameter g #h(:a 1 :b 2)) G CL-USER&gt; g #h(:A 1 :B 2) [meta language gloating] Moments like this make me happy as you spend 10 minutes or so and have syntax that feels like it is a part of the language, macros baby!
yes they are redundant. But they are a list. So they print nicely and can be saved to a file. And CL has lots of functions for manipulating lists. As with everything it is a trade off. 
Thanks, I'll have a look.
One approach you might want to consider is separating the GUI process and communicating through a messaging system to the core of the application (using, say, 0MQ). "Neovim" is approaching their GUI like this (although it's not LISP). It's detailed here: https://github.com/neovim/neovim/wiki/Plugin-UI-architecture Light Table for instance uses node-webkit. I think those approaches are the future as the traditional highly coupled GUI code in applications is a bit of a dead end, and more stuff goes to the web, mobile and multiple native OS's. Note that you can have a 32 bit process for the GUI if that's what works best (say using CommonQt) and 64bit for your core app. The application I'm working on right now doesn't have a proper GUI yet (it's for internal use, too) but if I make a GUI I think I will approach it this way. I also need 64bit in the main process as I work with GBs of memory. I don't need to distribute the application but it's always better if the GUI doesn't dictate anything else on the project and also to be able to run it in different machines easily in the future. 
About plists, I like that you can get them and use them as keyword argument in functions, which is convenient sometimes.
&gt;The threading macro is not more natural. Granted it looks cleaner. But all you are really doing, is moving some end parentheses around and reversing the functions. It reads from left to right like everything else you'd read, that makes it more natural. It also flattens the operations out into a list making it much easier to rearrange them. What if I wanted to interpost before mapping, with the threading syntax I can change that in seconds. When I have a tree structure it makes it more painful to rearrange things. Also, the part you seem to be missing is that the threading macro is another tool. It doesn't replace the nesting. You use it to make code more readable. &gt;It is only natural to imperative-only programmers who only think of what order things need to be done. Mathematically is it not natural. To a functional programmer it is not natural. That's an extremely contrived argument and I flatly disagree with it. &gt; It is hard to manipulate the expression or inner expressions because the only thing that is complete is the whole thing or the first expression. The AST is gone. Qutie the opposite, precisely because the AST is gone it makes it much easier to manipulate the chain of transformations. &gt; In your example, what if you want to change what reduce calls or you need to add an optional/keyword parameter to one of the function calls? I'm afraid I don't follow the problem you're describing here. &gt;The destructuring on a defn looks cool. great for cranking out code. But what if [name address phone] changes to an object. Then you obviously have to change the arguments. You're absolutely no better off if you start pulling these parameters out inside the function. Except here you actually have them all in one place and it documents what the function expects. &gt;This encourages one not to abstract data. It does no such thing, and since it works perfectly well with maps and other nested structures it makes it much easier to tell what the function is meant to be doing. &gt;But in the end I would factor it out. So when you come back to your code 6 month later you don't know what the arguments the function is expecting and you have to read through its body to figure that out. That's some brilliant logic right there. 
To complete the analysis, the term *mezzano* is also used in the production of some Italian cheeses, to indicate second-choice lots.
Me seems that you're too fixating on possible negative interpretation. Especially in italian, it's even hard to find terms with no double (negative) sense whatsoever, so let's just think more positive!
Naming is hard, but disregarding flaws is not a strategy. However, feel free to explain why mezzano is a great name, if you think so :)
Both alists and plists can share structure, which can be advantageous if you are using non-destructive operations. The most common use is for environments in simple interpreters; if you have an alist of all your bindings, you can attach it to a function to get a closure, and you can prepend more bindings as much as you like without disturbing the closure.
 Almost 300 years of mathematics (since Euler) treat functions this way. I fail to see how it is **extremely contrived**. Threads treat things as a list of things to do. If you think the innermost function is most important or think that composing functions is like listing them, fine you can think it is more natural. I'll side with the mathematicians over 60 years of imperative, spaghetti coders. My other point is that -&gt;&gt; threads through the last argument of each function call. Need to change the parameters like adding an optional parameters, you can no longer thread. Rewrite one of the functions used to have more arguments also kills use of a thread. If you write it normally, you only need to manipulate the function call. In emacs with or without paredit, it is easy to change the order of composed functions you don't need a thread. as for destructing bind, 6 months later you do not realize that you have functions that expect all users to be lists with the first three elements [name address phone]. The function is called print-**user** pass the user not his name, address and phone in a list. 
&gt;Natural" is an opinion. We will just have to agree to disagree. I'll side with Euler. It's hardly an opinion, our brains are hardwired to identify objects sequentially. We evolved that ability over millions of years. &gt;I never claimed CL was more functional. CL is imperative when you want it and functional when you want it. I'm simply pointing out that there are plenty of things in CL that are actually unnatural to a functional programmer. Threading macro is hardly a good example of that. All we're doing is discussing specific language features available in Clojure and not in CL. My personal experience is that these features add readability and make a positive impact on the user experience. So far you haven't really said anything to contradict that. &gt;Now print-user is called a hundred times in your code. Now you have to change 100 calls instead of one function. Brilliant. This is still completely tangential to having destructuring. What is the point you're trying to make here? Without destructuring you will have exact same problem, and in addition to the problem it's also harder to tell what parameters your function expects in the first place. If you're going to argue against destructuring then please find an argument actually relating to it.
&gt; simply pointing out um, no, you made a wrong claim about what I wrote. &gt; our brains are hardwired to identify objects sequentially citation please. If I recall correctly from my cog psych course from years ago, our brains are highly parallel. If you are talking about reading order. I suggest you take some linguistics. Some languages go right to left. Some languages are SVP others are SPV. Besides I read CL left to right with no problem even with nested function calls. &gt; completely tangential Um, you should up the meaning of tangential. I don't think you mean that. "Orthogonal" maybe? &gt;This is still completely tangential to having destructuring. What is the point you're trying to make here? Without destructuring you will have exact same problem, and in addition to the problem it's also harder to tell what parameters your function expects in the first place. If you're going to argue against destructuring then please find an argument actually relating to it. As I said my function would be: (defn print-user [user] ...) Now if I change the data representation of user from list to object I only need to change this function, not the 100 calls to print-user. If you recall, my original rebuttal of destructuring in the parameters of defn: &gt; This encourages one not to abstract data. This is my point. The fact that you do not understand this means that this discussion is just a circlejerk. See if this was a normal discussion you would write something like. "Ok I understand that, my example is not so good. Here is a better one". Finally you originally wrote this: &gt; I gave a concrete reason above for preferring Clojure syntax, rebuttals welcome. I gave rebuttals to your concrete reasons. But they certainly were not welcome. But you seem unwilling to acknowledge any argument. You simply respond with a point by point rebuttal using terms like "extremely contrived", "completely tangential", "extremely amusing". EOD, I'll give you the last word.
 (defmacro dlambda (args &amp;body body) `(lambda (&amp;rest args) (destructuring-bind ,args args ,@body))) CL-USER&gt; (funcall (dlambda ((a b) (c d)) (+ a b c d)) '(1 2) '(3 4)) 10 :)
Alists function like lookup tables that retain their entire history when new elements are added with the same key. Hash tables can't do that. 
What I'm saying is that there is no practical benefit to CL syntax over Clojure, and the only argument I've ever heard to support it is based on familiarity. People who work a lot with CL are used to CL syntax and therefore prefer it to anything else. My point is that if you're using it all the time you develop a bias towards it. This is the same kind of bias people who use C style syntax develop and are unable to see any problems with it. I'm suggesting that people step away for a second and consider if having things like literal data notation might actually be beneficial even if they're not used to seeing them.
&gt;What I'm saying is that there is no practical benefit to Clojure syntax over CL, and the only argument I've ever heard to support it is based on familiarity. My argument is that having literal notation is more explicit. As I pointed out CL syntax conflates the meaning of the list making callable in some cases and not in others. The syntax also requires reading text in order to see what the code is doing, Clojure syntax is more scannable because you're looking at icons. Having explicit notation reduces cognitive load and reduces the chance of errors caused by code being misread. 
There are a lot of reason for the failure. 1) I think a lot of problems in LISP are problems that clojure solved. For example namespace behaviour. Verbose typing (mystruct-x st) vs (x st), strange equality (eq,eql,equal,equalp). Hard api for non native english speaker for example: destructuring-bind. 2) LISP was really slow in the 90's and it leave a bad impression. 3) A lot of student learn only small part of the SICP book and it leave a bad impression of a linked list processing language. 4) LISP lack a good documentation, where are the examples? were are the common lisp monks? I just discover what the v key does in emacs when I debug sbcl. 5) A lot of implementation of LISP are close source that cost a lot of money. 
It works for me.
Usocket is arguably "standard" since there are better alternatives (like iolib which I can say, as someone who migrated from usocket some time ago, is much better) and, as far as I know, it isn't maintained anymore.
So... You want a standardized lisp, eh?
I recently just started learning lisp and it is a really interesting language to me. So why has Lisp failed? I personally think it might be because it is just too different from the other languages. If you aren't really exposed to it while learning to program, it seems just too weird and would probably put most people off from even looking into it. Lisp needs something that can get more people interested in using it, I have no idea what that can be though. Either way, I am enjoying Lisp so far and I hope Lispers keep hacking away on it.
Some problems 1.- The NIH syndrome 2.- The saying: Better be the head of a dog than the tail of a lion 3.- How are you going to sell a new book? Some people make a living (or a little money) selling booking about clojure (Fogus), Racket (Mathias), ... 4.- There are many solutions in design and all of them are valid, is difficult to make a canonical choice. 5.- ITA is not enough to prove that Lisp can be a good solution for big corporations. 6.- Haskell could be mostly a lisp library 7.- Erlang, (LFE), Channels (Clojure), Lisp should get strong in concurrency and paralellism. 8.- Julia &lt;-&gt; Lisp, we need to be able to use C numeric when speed is crucial. 9.- Python? =&gt; Hy. 
compiled it from sources downloaded as tar. Claims that its version number is -dirty . 
[Continued from here.](http://www.reddit.com/r/lisp/comments/2uaaxp/why_lisp_failed_opinions_rebuttals_all_sort_of/co6s7x3) &gt; Seriously, after thirty years, Lisp still doesn't have infinity! Not in the standard, but all implementations implement it. &gt; Lisp has weird data structure omissions, for example, hash tables and non-simple vectors alone lack literals, Nobody stops you from making custom reader macros. (Unlike Clojure) &gt; and arrays and hash tables alone lack copiers. Alexandria has them. &gt; Someone thought DO had a usable syntax. DOLIST and DOTIMES. Use them. &gt; And there is no one who can fix or advance the standard. You can. I can. Everyone can. CL implementors and library writers are already advancing it. But the standard itself is not broken, and kept stable in 20 years. I'd prefer to work using a language where I don't have to rewrite everything once in 2 years because the standard or reference implementation changed. (Java, Ruby and Python are all offenders on this front.) 
Cannot reproduce.
It would be helpful to share an opinion on what LXC is.
something is wrong in version generation, too boring to figure out, cleared the script generate-version.sh, rebuilt, version 1.2.8.
&gt; their enemy What.
I didn't write lxc, just a wrapper around it. But yes, solaris zones and linux containers are similar. So are BSD jails.
No, no. You got it backwards. It's *scheme* that should add a second namespace. &lt;g&gt;
Lets say I want to leverage the MOP to extend CLOS to accommodate to a model described by Magritte (or a less ambitious one like [active record](https://github.com/quek/info.read-eval-print.active-record/blob/master/active-record.lisp)). The AMOP explains how the MOP is implemented and a reference of its API. But not how to leverage it. And while one can find people saying one should extend CLOS to better fit their domain logic most of that code appears to not be open source. I've found few open source projects that extend CLOS: Rucksack, CLSQL, Elephant, Crane, Integral. But most only scratch the surface of what is possible. E.g. all those projects use the same direct and effective slot definition. So if it is not too much to ask, could you elaborate on how to leverage the MOP? Maybe share some experience?
If you can post a link to what you tried over in armedbear-devel, we can try to help diagnose your issues, as this is a a large topic. What do you mean by "abcl-jar"? Are you referring to ["asdf-jar"](http://abcl.org/trac/browser/trunk/abcl/contrib/asdf-jar/README.markdown)? When you say "runnable", what OS are you targeting? If you are looking to "double-click" on the jar in a GUI shell, there are a number of different scenarios you may need to consider depending on whether the OS is Windows, OS X, or Linux. The first is whether you expect the user to already have Java installed, so do you have some control over the client OS (i.e. is this in a managed deployment)? When you say "deployable", could you be more specific? "Deploy" in the Java world is usually used wrt. an Application Server, like Apache Tomcat. Do mean to have your application run as a "Desktop" application or a "Server" application? Looking forward to helping you get where you want to go with the Bear… 
&gt; In this day and age of hash tables, someone still thought association lists were a useful piece of crap to add to the language. Association lists are useful and can be faster than hash tables for small sets. Hash table syntax is nice (and easy to implement), but mostly used for small sets used once or twice in languages like python anyway. Performance is rarely an issue for these things, and having a choice of two data structures with different capabilities is not an issue in my experience. &gt; VECTOR-PUSH and fill-pointers exist even though no one in their right mind would use them over VECTOR-PUSH-EXTEND How about a fixed-size stack or queue? &gt; Someone thought DO had a usable syntax You can pretend it doesn't exist and use loop. There's plenty of stuff in python, C, C++, Objective-C, Ruby, and Javascript that people prefer to ignore. &gt; RETURN-FROM is needlessly, hopelessly overwrought given that 99.99999% of its usage is to return from the current function. It's for returning from outer functions (or blocks). I use it quite often actually. The only other way to do this is via manually CPSing your code. Throw/catch are deceptively similar but are dynamic rather than lexically bound. RETURN is for returning from the current function. &gt; There is no standard way to deterministically seed the random number generator (!!!) (make-random-state &amp;optional state) 
Someone submitted a link to this comment in the following subreddit: * /r/lisp: [A comment on the CLOS MOP](https://np.reddit.com/r/lisp/comments/2ugtzn/a_comment_on_the_clos_mop/) ---- This comment was posted by a bot, see /r/Meta_Bot for more info. Please respect rediquette, and do not vote or comment on the linked submissions. Thank you.
This thread has been linked to from elsewhere on reddit. - [/r/lisp] [A comment on the CLOS MOP](http://np.reddit.com/r/lisp/comments/2ugtzn/a_comment_on_the_clos_mop/) *^If ^you ^follow ^any ^of ^the ^above ^links, ^respect ^the ^rules ^of ^reddit ^and ^don't ^vote ^or ^comment. ^Questions? ^Abuse? [^Message ^me ^here.](http://www.reddit.com/message/compose?to=%2Fr%2Fmeta_bot_mailbag)* 
Corrected.
So far I've only used caveman2, ningle and I've played with lucerne. All of those are based on clack and they share the same middlewares. There is a lot of love in the clack webframeworks these days, so you might want to start there: http://clacklisp.org/
Yep I think I'll look deeper into that no matter what. Also, I have experience with Python's WSGI + Flask which seems to have had some influence it its design.
Clack is definitely the way to go. It's server-agnostic, so you won't risk the server you're writing your app on bit-rotting. The author has also been doing a lot of amazing work on fast CL web servers, so the ecosystem around Clack just gets better and better. &gt;I've played with lucerne &lt;3 &lt;3
Yeah when I first found out that book was a thing I was pretty excited.
Haskell is easier to install but libraries are really a pain to install compared to using Quicklisp. What I think is really needed is a single distribution (not necessarily a single compiler) with a good IDE that is not emacs. I like and enjoy emacs, but when most developers are using Visual Studio, Xcode or Eclipse, switching to something more difficult is not going to cut it for most. Whatever reason they had to try Common Lisp, it's lost when you have to build your own .emacs to make it work for whatever compiler you just downloaded. I suppose a sort of LispWorks but "freer" is what's needed the most, with the ability to build a self contained executable application. But without a good GUI toolkit, something like CAPI, you're going to be making mostly console or web applications.
I recently needed a fairly straightforward CRUD site, and I tried weblocks; there are good things and bad things about it. There seems to be significant bitrot in places. It worked for what I needed, and it really is easy to make a CRUD site with it, but I wouldn't recommend it.
"lightweight" for framework tends to mean "We don't make you do it our way"
Also, smaller attack surface. In the web when you don't want a feature it's better that it isn't there, and since what I want to do is rather simple... 
The reference appendix D of Graham's _ANSI Common Lisp_ is organized more like you want, perhaps. The advantage of the Hyperspec organization is that the closely related functions are mentioned together: if you remember you want one of the mapping functions, but you forget which, they are all in the same page.
First of all, the CLHS is very very good and you would do well to learn to appreciate its value... That said, this is a perfect opportunity to plug my [Notes and tips: Standard Common Lisp symbols](http://www.hexstreamsoft.com/articles/notes-tips-standard-common-lisp-symbols/) article which is **not comprehensive** since it's not completed yet, but it's already useful notably to find related symbols. You can go to the top of the page and click on the green links on the left to access the more comprehensive pages. You can click on related categories from [the mapcar entry](http://www.hexstreamsoft.com/articles/notes-tips-standard-common-lisp-symbols/#mapcar) to find related symbols among various categories and subcategories. Also worth noting that my article is specifically designed as a *complement* to the CLHS, not as a replacement. I recommend investing untold hours studying the CLHS, as it's the most authoritative (accessible) reference on Common Lisp! There is still MUCH work to do on this article, I have a number of fairly concrete ideas to make it much better, but for now I must attend to other things. I hope it can already help you and others a bit!
Perl and Emacs together led me to Common Lisp
Please forgive me; I'm a bit new to the tooling in the Java world. I am a little confused by your response; how do people normally deploy JVM-hosted applications? I am definitely open to learning what I should be doing better. Yes, I was referring to "asdf-jar"; sorry. :) What I know so far... I have made use of the Selenium standalone jar for testing web apps ("java -jar selenium-server-standalone-2.14.0.jar"). I have some small amount of experience working with Picard Tools (https://broadinstitute.github.io/picard/), also deployed as a jar. I have obtained sundry other programs that run on the JVM, also packaged as runnable jar files. I figured that is the norm for how folks in the Java world deploy the non-web programs, though I have heard of other kinds of tooling; I always wondered how one could distribute an app that also helped the end-user auto-update their JRE to the minimum required to run the app. I have experimented successfully with creating standalone jars in Clojure ("lein uberjar") as well as jruby ("warbler jar"). I was hoping I could find something similar for ABCL. I was also confused by the notion in your response that I needed to be concerned about targeting OSes. Seems the default Java on OSes I am surveying tends to be the ancient 1.6. I thought that so long as I did not make use of any FFI, I pretty much could deploy the same JVM-based jar to any OS and see the same result. The exception to that is using the flag that styles Swing windows to look native, and I only tried that option on a Windows system with a Clojure jar, so I do not know yet the practical problems of trying to get the app to look right in linux or Mac OS X. I figured ABCL would be similar to SBCL in that the entire runtime would become part of the final image, as in, I'd basically be extending what is in the abcl.jar akin to what Aidenn0 referenced. I am hoping someone will point me to some kind of package (save this ABCL image into a jar, and use this specified method as entry-point) or build system (ant-based? doesn't matter). It's possible I am going the wrong direction with trying to build a standalone jar, but now you know what I've played with and am trying to find. :)
&gt; I don't know of a good way to distribute binaries that are both small and fast. SBCL's save-lisp-and-die gives me at least 20MB files, **which are hard to send around**. Buy a faster modem. I heard 56k US Robotics are available now.
Afraid not but I do understand the feeling. It took ages for me to be able to read the hyperspec and find it useful, to me it feels similar to the opengl wiki, really useful once you already know how to use the program well. The hyperspec is actually wonderful once you are past a certain point of understanding (which is why some of the comments here are a bit brisk). It's also why a more minimal version won't be coming from the community at large any time soon. @sickofthisshit is spot on though, ansi common lisp's appendices are great. 
Also the "simplified Common Lisp reference" http://jtra.cz/stuff/lisp/sclr/index.html EDIT: mapcar -&gt; http://jtra.cz/stuff/lisp/sclr/mapcar.html
I am working on a hyperlinked PDF version of CLTL2. I've been told that Guy Steele has given permission to use the original sources. It is much easier to navigate. 
I think the OP wants something *less* condensed.
I'm aware of the html versions. I need it in PDF form for other reasons. The main change is minor rewrites to make it LaTex2e. This first iteration concentrates on navigation in the PDF. The table of contents has each function listed and linked for easy reference. The index has links. I've removed all of the sections marked obsolete. It should be done by next week. As for the "serious rewrite", it would be possible to put this up on github if people are interested. On the other hand, my second copy of CLTL2 has fallen to pieces so I decided to make a PDF. I plan to include a lot more example code snippets and hacks I've learned (but can't remember). Also "in plan" is to add a section on quicklisp, ffi, and notes about variations between the open source implementations of functions. In the longer term I plan to make a "literate program" version of common lisp which includes the actual source code from an open version of common lisp. (Think of the Lisp in Small Pieces book but for common lisp). This will be part of the Axiom documentation.
&gt; The alternative would be to duplicate information on every page or to refer to a common mapping page. &gt; Doesn't sound much better to me. That's actually what I was hoping to find. I'm sure there'd be duplication, but I think in the end it would still be a much cleaner, clearer document to read. (Also, MAPCAR, *et al*, was just an example. There are many more like it.)
Yes, I'm really excited for Rhine and Pixie for that reason. Clojure is my favourite Lisp dialect, but the JVM is way too heavy. I tend to write my backend code in (Chicken) Scheme now, but I really miss the dead-simple concurrency and hash table reader syntax.
Asking "Why bother with Clojure?" diminishes the author's credibility as a language designer in my mind and makes me less likely to invest the effort to determine whether his language actually has merit. First, it implies that the primary reason to use Clojure is to gain access to the JVM ecosystem or use a Lisp in an existing JVM project. Clojure offers an approach to functional programming that's more convenient and pragmatic for a lot of users than more "hardcore" functional languages like ML and Haskell, as well as making the use of concurrency-safe constructs idiomatic and easy. Second, it implies that Clojure was the only option for Lisp on the JVM with Java interoperation before PicoLisp. ABCL and Kawa aren't exactly new, and if PicoLisp's creator hasn't heard of them, I suspect him of reinventing their features poorly. After writing this, I realized the wiki page may not have been written by one of the authors of PicoLisp itself.
So it's like a bash for the JVM then? With some [datastructures](https://github.com/slburson/fset) and [concurrency](http://stmx.org/) stuff that are already libraries in Common Lisp?
[logv](http://www.cliki.net/logv) because it's very convenient during debugging. If you actually want something to write to disk in production, maybe take a look at [log4cl](https://github.com/7max/log4cl).
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Persistent data structure**](https://en.wikipedia.org/wiki/Persistent%20data%20structure): [](#sfw) --- &gt; &gt;In [computing](https://en.wikipedia.org/wiki/Computing), a __persistent data structure__ is a [data structure](https://en.wikipedia.org/wiki/Data_structure) that always preserves the previous version of itself when it is modified. Such data structures are effectively [immutable](https://en.wikipedia.org/wiki/Immutable_object), as their operations do not (visibly) update the structure in-place, but instead always yield a new updated structure. (A persistent data structure is *not* a data structure committed to [persistent storage](https://en.wikipedia.org/wiki/Persistent_storage), such as a disk; this is a different and unrelated sense of the word "persistent.") &gt;A data structure is partially persistent if all versions can be accessed but only the newest version can be modified. The data structure is fully persistent if every version can be both accessed and modified. If there is also a meld or merge operation that can create a new version from two previous versions, the data structure is called confluently persistent. Structures that are not persistent are called [ephemeral](https://en.wikipedia.org/wiki/Ephemeral_(disambiguation\)). &gt;These types of data structures are particularly common in [logical](https://en.wikipedia.org/wiki/Logic_programming) and [functional programming](https://en.wikipedia.org/wiki/Functional_programming), and in a [purely functional](https://en.wikipedia.org/wiki/Purely_functional) program all data is immutable, so all data structures are automatically fully persistent. Persistent data structures can also be created using in-place updating of data and these may, in general, use less time or storage space than their purely functional counterparts. &gt;==== &gt;[**Image**](https://i.imgur.com/hTaZAG5.png) [^(i)](https://commons.wikimedia.org/wiki/File:Purely_functional_tree_before.svg) --- ^Interesting: [^Hash ^tree ^\(persistent ^data ^structure)](https://en.wikipedia.org/wiki/Hash_tree_\(persistent_data_structure\)) ^| [^I/O ^request ^packet](https://en.wikipedia.org/wiki/I/O_request_packet) ^| [^Persistence ^\(computer ^science)](https://en.wikipedia.org/wiki/Persistence_\(computer_science\)) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+coabjp9) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+coabjp9)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Quicklisp and ASDF have improved deployment a lot, but still there should be a standard way for packages to compile and install binaries to the standard Perl does since forever (credit to them). Other than that practical consideration, really things work pretty damn well in Common Lisp land right now. Popular or not.
&gt;Not sure what the bash analogy is supposed to mean, bash : C binaries :: clojure : JARs &gt;but there is a big difference between a language that defaults to immutability and one that provides it optionally on the side as a library. I take a different view. There's a big difference between a language that lets you define new semantic constructs on the side as a library and one which says "Yeah, that should be good enough for everybody." Aside from that, this big difference you talk about is not some type of a priori truth. An argument for this would be good. Although I think it would ultimately come down to a value distinction between you and I based on what we find good in a language. This is probably something we won't agree on. &gt; Clojure defaults to using persisent data structures. Any changes to data are done by revision and immutability is prevalent throughout. I know. &gt; On top of that Clojure provides powerful STM facilities for working with shared mutable data as well as transients for dealing with local mutable state . I know. &gt;Again, this is built into the language. Idiomatic Clojure code is stateless and referentially transparent. I know. &gt;Immutability also helps with parallel processing. In many cases parallelizing an algorithm in Clojure is as simple as swapping map for pmap. pmap is neat. Although I don't think it'd be too difficult to implement with CL, it's still neat. &gt;Clojure also provides things like transducers and core.async that have no equivalent in CL that I'm aware of. [chanl](https://github.com/zkat/chanl) I need to read about transducers. They seem interesting! &gt;When you try to bolt these features onto a language then many benefits are lost. Is it fair to say "bolt" when you have access to compile time and run time metaprogramming in a language? Is it fair to say bolt when things like CLOS, the MOP, setf, loop, etc. were each just some personal lisp code some lisper(s) had written that got folded into the standardization process? Does setf feel bolted on? Does the MOP feel bolted on? &gt;Now it's up to you to make sure you're using the proper data structures and you have to plan up front for concurrency in your design. You *always* have to make sure you're using the proper data structures. You *always* need to plan for concurrency in your design. Go hang with some Fortran people some time. Tell them you have a persistent vector that copies it's structure when an operation is called on it. They might then show you the supercomputer doing complex differential equations on a single giant array in memory because *they are using all the memory on the box* to compute it. Then you do some persistent modifications on it, copying some of its substructure for every new computation you do. Great, now we're out of memory. And the concurrency thing, you still need to *pick* which concurrency strategy you are going to pursue. Agents? Actors? STM? Futures? Promises? Channels? It's not like you go "oh yes here's THE concurrency abstraction which meets every need I'll ever have" when using Clojure. &gt;You also have to worry about the behavior of libraries written by others as well as people you might be working with. How is this not true for every library ever? How is this not true for Java libraries which Clojure pulls in? I don't mind Clojure. It is a very light (but powerful) abstraction on top of java primitives, it has a nice concurrency toolkit, and it's getting more people interested in Lisp. But this marketing hype and cult of personality stuff has made me very disinterested in learning it. The fact that it seems to have attracted all the startup scene tech fetishists is also really off putting to me. And I feel there is this sort of constant need to assert "Yes, we're Lisp. We are THE Lisp. All other Lisps, get outta here." If it were me, I wouldn't be talking about the benefits of Clojure to Common Lispers or Schemers or Racketers or Picolispers. I would be talking about the benefits of Clojure to Java people, as to me the benefits of the language are most pronounced for them.
Huh, interesting. I'd say the darcs copy is fine, but there is also [this repo on GitHub](https://github.com/nallen05/logv) which has a few changes to that, I'm going to check that one out.
I use log4cl. The biggest benefit is its Emacs integration that not only highlights log messages and allows me to click on a message to go directly to where that message was generated where the log message was written, it also allows me to control the logging levels directly from Emacs (move to a function, and use the menu to select the logging level for that function). 
&gt;Same way CL is bash for C then I guess. It was you who were championing Clojures Java interop. It was not I who was championing Common Lisps FFI. &gt;Except that's not what it says at all. Sorry, let me expand here. I let my thoughts become implicit. What I mean here is, you are beholden to your design. If you look at the purely functional datastructures, they are backed by combining various forms of the functional list datastructure. Consing to the front, treating the tail as the rest of the last, walking down the list, lists of lists. So what you can do is take these mutable structures, which are memory efficient at the expense of being harder to deal with concurrently, wrap them up in some CLOS classes with some generic functions, and have the immutable structures backed by plain old cons cells. CL has the necessary primitives and sufficient means of combination to get your immutable data structures. And you can create read and print syntax for them. In contrast, it's harder to go the other direction. If Clojure wants to be memory efficient as opposed to concurrency effecient, my guess is you'd have to pull in something like an ArrayList&lt;T&gt; or Array[T]. This is fine for Clojure's design goals, and it fits with them, as your leveraging the existing JVM infrastructure to accomplish your task. I just don't care for it. Again, I thought we may disagree. &gt;My experience is that I like to be able to safely reason about the individual parts of the application in isolation, but hey to each his own I suppose. Oh come on now. Clojure does not have a monopoly on referential transparency. I know the value of referential transparency. &gt;The difficulty is not in implementing pmap, it's in knowing whether it's safe to use it on a particular piece of data or not. That's the joy of working with shared mutable data, you never know where else it might be referenced and what state it's in at any point in time without knowing the entire state of the application. Again, I know. I'm just aware of the trade-offs of both mutable and immutable structures. I don't see one or the other as better. &gt;What I mean by bolt on is that the language doesn't encourage you to use immutable data structures and it provides no way to tell whether a particular piece of data is referenced elsewhere or not. &gt;Clojure is designed around immutable data structures and using them is natural. When you're using these data structures in CL, you have to put a lot of effort into making sure that you're only working with immutable data. For example you could have an immutable collection, but it could contain mutable data referenced elsewhere and the whole thing falls apart. Yeah. That's why I advocate hiding this immutable machinery behind CLOS classes, similar to the ISeq abstraction in Clojure. &gt;That's plain ignorant. Clojure is not an abstraction on top of Java primitives. It's a completely separate language that has its own semantics. There are at least two other major platforms that Clojure targets which are .NET and Js that have nothing to do with Java at all. Nah I meant more you're not far away from the primitives of the language you're programming on top of. Clojure strings being Java strings, stuff like that. I don't mean Clojure isn't its own language. Just that it's easier to see what you're programming on top of. That's why the interop is so easy. &gt;It's not hype if it actually works. What claims about Clojure are inaccurate exactly in your experience. You misunderstand. I have no doubt Clojure is a good language. It's the *community* that irks me. &gt;The fact that CL community seems to consist primarily of people telling everybody else how their languages suck and Lisp is the one true way, but doing absolutely nothing to help make it palatable made me very disinterested in using it. Really? My experience in the CL community is totally different. I have sort of partitioned the space in my head between philosophers, trolls, and programmers. The philosophers like to talk about how beautiful lisp is and how great it is. The trolls like to come in and say how Lisp sucks and how language X is better. The programmers write Lisp code. I agree there are a lot of philosophers. But I've also seen a lot of "Oh yes, we had this problem in Lisp in 1974, here's how Common Lisp solved it" and then people flip out and go "Jeez you arrogant Lisp weenies and your smugness! This is why no one likes you." One of the reasons I like this community, as well as the Smalltalk and ML communities, is the awareness of history. They know what came before them and how they got to where they are. You don't see that in a lot of other tech communities. &gt;So, the fact that people are actually using it in the real world for practical purposes is a negative somehow. That's an interesting position to take. Nah I mean tech fetishism. Like going "oooh ahh look at this language it's so great." See discussions of Go, Rust, and Clojure circa now, Ruby circa 2007, Python circa 2004, Perl circa 1998, Java circa 1995, TCL circa 1993. It's the constant "this language is IT!" and then the hype tide recedes, reality steps in and you have to start thinking in trade-offs. I mean, I know there are some things about CL that suck. I like the language, but they're still there. It's just the other stuff offsets the sucky bits for me. &gt;Who precisely asserts that? Ha! But you see, I was careful with my language here. I said "I feel". This absolves me of giving sources. ;) &gt;What precisely is wrong in educating people about the advantages of the language you use compared to other similar languages. What you'd call education I might call propaganda. A bunch of blurbs with no context does not make for education. Education is a framework in which to discover. &gt;People who are already using a Lisp tend to be in the best position to appreciate the benefits that Clojure brings. That's true. But they also tend to be in the best position to see issues with it as well. That's a common trope. The closer two languages are to each other, the more there differences matter to people. This conversation would give credit to this, wouldn't you agree? C vs C++, OCaml vs Haskell, whatever. Proponents on both sides are much closer than they are further away. &gt;If you don't think that Clojure has any advantage over CL then why are you so worried about people discussing it. Ha! I'm not worried at all. I just want to round out the discussion with some context. The text I type doesn't give a feel for how lackadaisical I am about programming languages, and I'm sorry for that. I don't mean to be disrespectful to you or your choices of language, and if you're feeling attacked I apologize. It's not you who I am trying to analyze and be critical of, but the argument and points you've set forth. &gt;Majority of newcomers in Clojure community actually come from languages like CL, Ruby and Python. Very few Java developers actually switch to Clojure or pay any attention to it because it's extremely alien to them. And the Java programmers are missing out on quite a good language. :)
Reader syntax can easily be fixed; this is Scheme, after all.
&gt;It was you who were championing Clojures Java interop. It was not I who was championing Common Lisps FFI. I was not championing anything, I merely pointed out it's useful to have access to a mature platform. I certainly disagree that this somehow makes Clojure a glue for Java libraries though. It's much more practical to get controlled mutability in a purely functional environment than going the other way around. After all you don't want to optimize prematurely. Most of the code in your application isn't going to be run all the often and you should write it for clarity and maintainability first and foremost. Working with immutable data structures is akin to having garbage collection. Instead of me having to track mutable state manually I offload that to the language and I can instead focus on the actual problem that I'm solving. Mutability is an optimization and I generally do not want to be exposed to it as the user. As I already pointed out, shared mutable data makes it impossible to reason about code in isolation. Any time you're considering a piece of data you have to know exactly where and how it's being used throughout the application. When I find that there is a bottleneck that's where I want to create mutable state. I want this to explicit and I want the compiler to be able to track it. Clojure provides things like [transients](http://clojure.org/transients) precisely for that purpose. Another thing to realize is that immutability affords a lot of optimizations that aren't possible with mutable data, such as fast and consistent equality checks, history and so on. &gt;Oh come on now. Clojure does not have a monopoly on referential transparency. I know the value of referential transparency. Where did I say that it had a monopoly on it? You're just using hyperbole again here. &gt;Again, I know. I'm just aware of the trade-offs of both mutable and immutable structures. I don't see one or the other as better. One makes it possible to reason about code in isolation and the other doesn't. That's the short of it. Defaulting to mutability is a premature optimization in my opinion. &gt;Really? My experience in the CL community is totally different. I'm sure that's what the community looks like from the inside. To people on the outside it often feels hostile and negative. Just look at your own pejorative comments about Clojure in this thread. Instead of having the mindset of what can we do better to attract more users and grow the community, your mindset that it's hype that's driving people to other languages. &gt;You misunderstand. I have no doubt Clojure is a good language. It's the community that irks me. I feel the same way about CL community. Instead of working on making CL more accessible the community simply tells other people that their languages suck. Clojure isn't popular because of hype. It's popular because the community puts a big focus on making things usable and accessible to new users. Show me an equivalent of [Luminus](http://www.luminusweb.net/) or [Leiningen](http://leiningen.org/) for CL. When it comes to IDEs, with Clojure I can use Light Table, Emacs, Cursive, Counterclockwise, Sublime, and Vim. People have a lot of options to pick from and can choose one that's most familiar to them. With CL you pretty much have to suck it up and learn Emacs. Learning CL is difficult for anybody coming from a mainstream language, compounding that with having to learn an arcane editor is pretty much a deal breaker for most people. Yet nobody in CL community seems to think it's a problem, instead you complain that people are choosing other languages like Clojure because of "hype". In my opinion the state of CL ecosystem is downright shameful considering how long it's been around. &gt;One of the reasons I like this community, as well as the Smalltalk and ML communities, is the awareness of history. They know what came before them and how they got to where they are. You don't see that in a lot of other tech communities. I'm really not sure where you get that idea from. Clojure community is perfectly aware where its ideas come from and many people come from CL and Haskell communities. I started out using FP with Haskell myself as a matter of fact. &gt;Nah I mean tech fetishism. Like going "oooh ahh look at this language it's so great." See discussions of Go, Rust, and Clojure circa now, Ruby circa 2007, Python circa 2004, Perl circa 1998, Java circa 1995, TCL circa 1993. Clojure has been around since 2007. People have been building things in it for close to a decade now and feedback from people actually using it to make stuff is overwhelmingly positive. Calling it hype is a bit silly at this point. &gt;Ha! But you see, I was careful with my language here. I said "I feel". This absolves me of giving sources. ;) Well as long as you're admitting that it's pure unsubstantiated FUD that's fine then I suppose. :) &gt;What you'd call education I might call propaganda. A bunch of blurbs with no context does not make for education. Education is a framework in which to discover. There is plenty of context available for anybody who cares to look. Most importantly people try the language and decide whether they like it or not. Most of Clojure "hype" comes from people who started using it and found it better than what they were doing before. &gt;That's true. But they also tend to be in the best position to see issues with it as well. That's why everybody can try different languages and decide what they like for themselves. It's not a zero-sum game after all. &gt;And the Java programmers are missing out on quite a good language. :) If they knew better then they wouldn't be programming in Java in the first place. :) 
I built (and use) [vom](https://github.com/orthecreedence/vom) quite a bit. I have never needed anything like what log4cl provides and found it hard to work in many instances, plus I don't use emacs so there goes one of its positives. Vom was designed to be tiny and easy to understand, while customizable enough to do what you want with it. Not sure if anyone else has even used it though, it may only be useful to me.
Now I think I understand your question, to which I can only reply that unfortunately there is currently no way to create a standalone JAR for ABCL that contains a given application plus the Common Lisp runtime. There [probably should be](http://abcl.org/trac/ticket/383) but we don't currently have a schedule for its implementation. ASDF-JAR is for packaging systems defined by ASDF in JAR archives for distribution but does not deal with the actual ABCL runtime. The SBCL mechanism for creating standalone executables relies on being able to save memory directly to disk that may be again be loaded to restore the process to the exact same state. As ABCL runs on the JVM, there is no direct analog that can be used in the this manner. 
&gt; CLtL2 needs to be seriously rewritten to make sense as a 'modern' Common Lisp reference, IMHO. And I think it would be worth comparing the cost (in time) of such a rewrite with the cost of just writing a new book.
Sophism spotted: 1. (Common) Lisp defaults to mutability. 2. Mutability is premature optimization. 3. Premature optimization is the root of all sins. 4. Therefore, (Common) Lisp is the root of all sins.
Indeed. And aren't there also some Scheme-Compilers for the JVM? (Not that I like Clojure)
One example why; the very first day I used weblocks, I found an arbitrary code execution vulnerability (since fixed; it was using READ to parse one of the values, which is super-low-hanging-fruit). I only use weblocks for personal-use stuff behind a password.
So insulting Clojure community by saying that the reason for its popularity and uptake is hype is kind and thoughtful. Meanwhile, challenging that by pointing out that Clojure community invested a lot of effort into making things friendly to beginners is insulting Lispers. I gave plenty of concrete examples where CL community could improve things like tooling, documentation, and developer tools. If you choose to continue getting offended when people give you constructive criticism instead of acting on it then don't act all surprised when people choose other languages to invest their time in.
You can choose to interpret it that way if you like.
Thank you for your response. How is a typical ABCL project deployed? Is it a matter of starting the runtime on whatever platform, loading appropriate Lisp files (quicklisp, load, require, whatever), and then running whatever function is appropriate?
So this is the apply used inside _that_ apply? Hmm. Can't say that I know exactly what is going on there, though! Am I right then in thinking that apply cannot be written in terms of simpler forms?
Nice. I remember playing wih vecto a few years back to generate recursive images / fractals, but the main thing I learned was that I have no sense of aesthetics. 
Also, if you disagree with my reasoning as to the problems associated with mutable shared state then please do state a counter argument.
Of course a native compiler is feasible, it's just a ton of work. Relatively speaking.
&gt; I gave plenty of concrete examples where CL community could improve things like tooling, documentation, and developer tools. Okay, then here's the bunch of “concrete examples” you refer to: 1. Luminus 2. Leiningen 3. IDEs Let's start with **IDEs**. &gt; When it comes to IDEs, with Clojure I can use Light Table, Emacs, Cursive, Counterclockwise, Sublime, and Vim. People have a lot of options to pick from and can choose one that's most familiar to them. […] With CL you pretty much have to suck it up and learn Emacs. You've forgotten at least Vim, LispWorks, AllegroCL, Eclipse, SublimeText, CormanCL, and LispEdit. Now **Leiningen**, here's the trick: Common Lisp doesn't have *one* software for that. | Feature | CL program to do it | |-----------:|:-------------------------| | create new projects | Quickproject | | fetch dependencies for your project | Quicklisp | | run tests | ASDF | | run a fully-configured REPL | Quicklisp (plus: no need to install Java runtime or SDK) | | run the project (if the project isn't a library) | Do you really need an external tool to start your software? | | compile and package projects for deployment | buildapp/lisp-executable/trivial-dump-core | | publish libraries to repositories such as Clojars | Quicklisp | | run custom automation tasks written in Clojure (leiningen plug-ins) | ASDF | (from [official leiningen features list](https://github.com/technomancy/leiningen/blob/stable/doc/TUTORIAL.md)) Finally, **Luminus**: well, Common Lispers aren't found of big frameworks when you can choose your own libraries and combine them, but I believe Weblocks and Caveman2 does the same thing. Please, I'd be happy to read any other “concrete example where CL community could improve things”.
Maybe I'm a bit crazy, but in my opinion argumentation only makes sense when articulated with [logic](http://books.google.fr/books/about/Introduction_to_Logic_and_to_the_Methodo.html?id=XoWTzdbZgeYC&amp;redir_esc=y); and your reasoning simply lacks it.
He made some videos too: https://www.youtube.com/playlist?list=PLzTz7AF-PnvLOH7T_vIr8-TrICdXvCKzn
Mark returns to his cave awaiting the arival of his lost R2 unit
I'd also like to point out that the topic in context here is "Why bother with Clojure?". My original reply was an explanation of what features Clojure offers that people find valuable and why they bother with it. Naturally, /u/voltaire4 started arguing how none of these features really matter apparently and how Clojure community sucks. Then you come along and start claiming that it's the other way around. Making a rational argument is sophism apparently and I'm the one in the wrong for daring to have a different opinion on the the topic and have the gall to defend it.
Slightly off topic, but does anyone know of a similar vector library for Racket?
It is not different from what other people said, but I will give you an example easier to understand. Imagine you implement a compiler, and it knows how to compile `(car arg1)` forms. It produces inline code, no function call at all. However, you still need a `car` function, for example, to use it with `mapcar`. So, you do (defun car (x) (car x)) and then you can do `(mapcar #'car '((1) (2) (3)))`.
I use CL-LOG by Nick Levine. http://www.nicklevine.org/cl-log/ It is the only one that I found which supports binary logging.
Comparing the cost of a "new book" vs "a serious rewrite"... I've tried to write 4 books, only one of which actually was published. A book like CLTL2 has roughly 80chars x 40lines per page (3200 chars). A "word" averages 5 chars, so a page represents about 640 words. A "healthy pace" is about 2000 words per day (including edits), so about 4 pages per day. CLTL2 has about 1000 pages, or 250 days of writing (ignoring format, proofing, research, indexing, etc). So it rounds out to about 1 year. A "best selling" textbook, according to my publisher, sells about 3000 copies. You get about $1 per book sale. So, for one year of every-day effort you gross about $3000. Factor in the cost of the coffee and you don't break even. A "serious rewrite" which updated it to meet the spec would take significantly less time which you can trade for $3000 worth of slacking.
Thanks. That does clear up things. I've been trying to implement a small Lisp and I was thinking about whether I can implement `apply` in terms of the other operators I have written so far, or whether I have to add it as a built-in. Apparently the latter.
I might abstract running things in ABCL into three categories: 1. Starting the "naked" runtime as you describe, possibly in a screen/tmux session to make it long-lived. 2. Starting the runtime via [SLIME](https://common-lisp.net/project/slime/) running under Emacs. One can then detach/re-attach to the runtime as necessary. 3. Running the runtime as a Java servlet in a Java Application Server such as Tomcat. See [abcl-servlet](https://bitbucket.org/easye/abcl-servlet) for the basis of such a deployment. ABCL-SERVLET provides the machinery where one can attach a SLIME session in a REPL to such a servlet. In all three of these methods, [ASDF](https://www.common-lisp.net/project/asdf/) is used to group the files into systems which then declare dependencies between the various libraries needing to be present for a given system to be loaded. [Quicklisp](http://www.quicklisp.org/beta/), which uses ASDF to define dependencies, provides a convenient method to install known dependencies locally. The use of ```CL:LOAD``` and ```CL:REQUIRE``` is not really necessary for the user of ASDF which provides a superior abstraction for locating and loading dependent code. What is not really covered in these scenarios is providing a user friendly manner of delivering a standalone application which was the thrust of your original question. The first two methods assume that the end user is familiar enough with Lisp to start a REPL in the first place. The third method--running ABCL as a Java servlet--can be abstracted enough as a single WAR binary artifact so that non-technical users (i.e. those who don't want to learn about the Lisp REPL) can deploy ABCL as an application. 
I've been thinking about this on and off for a while now. It would be great if you could specify categories from a closed list in your ASDF system definition, e.g: :categories (:science/chemistry ; Computational chemistry :science/parallel ; Scientific HPC :environment/console ; Runs in a console :application) ; Is an application Then we could extend Quickdocs to handle those and search by category.
I think you should post this as an issue on [http://github.com/quicklisp/quicklisp-projects].
A public closed list of categories is a rather unwieldy thing, I'm afraid. It would be something akin to bibliographical classification systems (Dewey Decimal, LoC etc.) It would have to be revised and updated every now and then, and that would give us troubles concerning backward compatibility and logistical issues.
I like the art is very cool. And since people is going slightly off topic so will I, this kind of reminds me about an idea I had to crate something similar to [rainmeter](http://rainmeter.net/) using Vecto and/or [LispBuilderSDL](https://code.google.com/p/lispbuilder/wiki/LispbuilderSDL), I never acted on it, but I think it would be interesting to use LISP to build widgets you can have on your screen as real time, interactive indictors or similar stuff. I never have time for these fun projects though.
Perhaps associating a list of tags with each project? Edit: oops that would hardly be "...without human intervention and manual categorization", would it?
&gt; search system It sounds like a fulltext search of the documentation, but also an automated tagging system with heuristics, given that it should work "without human intervention and manual categorization". It's an AI. Something like this http://www.sematext.com/products/key-phrase-extractor/ , http://www.easychair.org/ , https://code.google.com/p/kea-algorithm/ ?