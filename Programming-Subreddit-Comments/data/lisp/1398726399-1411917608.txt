&gt; For example, you can pass sort a function that doesn't return a boolean If you're talking about common lisp, it might make sense, because of generalized booleans.
Updates to the original article made as promised. Direct credit to SBCL for the strength of its type analysis, and a standards-conforming argument type declaration made. Thanks for the feedback, folks, I do appreciate it.
via John Fremlin's [article on the mmap pattern](http://john.freml.in/mmap-pattern). John is also the author of this library.
Oh, thanks. It was actually about a year ago back when some big fights broke out about the amount of non-CL content on this reddit. I contacted the mods and offered to help since they weren't around as much anymore. Just noticed the "distinguish" button on my comments today. :)
and Clojure with core.typed
&gt; Manardb is not a SQL database That I did know. I guess I just formulated the question poorly. I guess by (1), what i was really looking for was the difference between if you set up SQLite to store data in memory and define a user object that gets stored as a row in a user table, apart from the difference in architecture considerations, how otherwise is it different from (defclass user() (...) (:metaclass manaradb:mm-metaclass)) 
According to the network graph, hankhero's fork seems to suggest that he's added support for sbcl.
Didn't realise it was the mascot of lisp currently. 
I'm still not sure I understand your question. When you have your SQLite in-memory database, there is not much persisting going on really. Obviously an in-memory SQL database is mostly useful for temporary things. E.g. I use SQLites in-memory feature to test database code that is in production running against a "real" database (be this SQLite with a file or some other DB like Postgres). Let's assume you have some data in a collection of CLOS objects. When you want to persist this in an SQL database, you have to either use an ORM (e.g. CL-SQL) or write your own code to convert these objects as rows of tables. (Please note that the following statements are just from taking a glance at the manardb API documentation, I haven't used it yet.) Manardb works completely differently, it "just" dumps areas of memory to some file and knows which areas correspond to (instances of) known classes. It hence doesn't provide query facilities (think SQL "where" clauses) and you also don't have things like "INSERT" statements. In this respect, manardb offers some behaviour you would like to see from your typical ORM which in the best case would free you of having to worry about when you're adding or retrieving data from the database as you're just juggling your (business) objects. Finally, manardb is not an in-memory database, quite to the contrary it's providing you with a way to just dump contents from memory to files and vice-versa.
Why are mods allowing clojure trolls to hijack this subreddit?
Here is a man with his head in the right place. Look at the last thing on the TODO list (bottom of the page). Finally!
It was created by Conrad Barski, the author of Land of Lisp. http://www.lisperati.com/logo.html
Most of the time when I see things referring to common lisp I see that alien thing. (Ex. Land of Lisp, /r/lisp, http://common-lisp.net/)
It is _a_ mascot but not _the_ mascot.
_I don't think trolls of any sort are 'hijacking' this subreddit._ The sidepanel indicates that this is a subreddit for the Lisp *family* of programming languages. While the initial user base and posts on /r/lisp may have been primarily Common Lispers, it has expanded in recent years. All users are welcome here. The homepage to me seems to have a good mix of content from various lisps with plenty of Common Lisp representation. What about Dylan? Do you think they should be allowed to post here? I certainly do. If you would like to see more Common Lisp content on this reddit, I'd encourage you to **write some** and post it.
Hey everyone, just finished up this series of posts I thought you might like. I've been working on a project, [Turtl](https://turtl.it), for a while now and recently converted it to be a desktop app (it used to be a browser addon) using Node-webkit. I love NW so far, since it makes it stupid simple to write a desktop app if you know HTML5. However, I recently realized that while javascript is good for many things, crypto and heavy amounts of data processing is not one of them. I've spent the past few weeks getting ECL embedded in Node-webkit. The goal is to move a lot of code that's currently written in javascript into lisp instead. I want to use lisp for all API calls, data processing, local storage, etc...leaving javascript to handle the stuff it's good for: interface event handling and simple GUI stuff. My eventual goal is to have a common core lisp app I can embed in Node-webkit, Android, iOS, etc. This is done by setting up a *very simple* message-passing layer between lisp and whatever GUI is hosting it. The series goes through the problems I went through and how I got past them. While many of you might find it fairly obvious stuff, I figured I'd document what I ran into in case it could help others. The resulting project is on the [Turtl github](https://github.com/turtl/core) for anyone who's interested in taking a look. It consists of a lisp app (`app/`) a C module that facilitates simple communication between lisp and any generic GUI system (`src/`) and a native node module that wraps the C module (`node_modules/turtl`, which will eventually be moved out of the core and into the desktop repo). Enjoy!
Actually, someone correct me if I'm wrong, but I think Emacs is one? You can open an emacs source file from within emacs, edit it, save it, and load it so that the changes take effect.
Emacs mostly fits the bill as long as it's okay for the source not to actually be a part of the binary program. Essentially all code on the Genera operating system also satisfy your condition.
Before writing this library, I was "scared" in a sense to add to every type declarations to every function, because that's not really the proper thing to do. I was also "scared" to explicitly type check every function because of the speed hit I would take. I've now gotten into the habit of using this notion of "expectations" provided by this library with nearly every new serious function I write. Here's a somewhat full example of what I might write: (deftype array-size () `(integer 0 ,array-total-size-limit)) (deftype array-index () `(integer 0 (,array-total-size-limit))) (defun dot-product (a b &amp;optional (n (min (length a) (length b)))) (policy-cond:with-expectations (&gt; speed safety) ((type (simple-array double-float (*)) a b) (type array-size n) (assertion (&lt;= n (length a))) (assertion (&lt;= n (length b))) (returns double-float)) (let ((sum 0.0d0)) (declare (type double-float sum)) (dotimes (i n sum) (declare (type array-index i)) (incf sum (* (aref a i) (aref b i))))))) I've found that this style has generally been a good habit to get in because it helps me find logical errors, especially in larger codebases. And I additionally get the benefit of optimizations, of course. It's closer (though not close enough) to static typing. SBCL even does something like this for its type declarations by default (i.e., type declarations being treated as assertions for certain policies). I also have found that using this notion of expectations in a distributed library allows the library's consumer to decide what level of optimization/debug/etc. they want for the library, as opposed to enforcing it internally. I immediately realize however that this is not very Lispy; a lot of Lisp code is devoid of any notion of types and this is rather verbose. There are downsides. While this may help some kinds of bugs, it may cause other kinds of bugs. For example, if you do as in the example above, and you let `speed &gt; safety`, you have to be absolutely sure all consumers of your code are correct. This is usually *only* the case if you control all consumers (i.e., it's an internal library). Another downside is that it's just more work. The following is just a lot more tempting to write, especially during fast prototyping. (defun dot-product (av bv) (loop :for a :across av :for b :across bv :sum (* a b))) The last downside I can think of is that it sort of polarizes your code: either you get the full benefit of safety or the full benefit of speed (if you use expectations idiomatically). This hasn't practically caused any issues, but I could see them happening. 
It is also fair to view everything which runs on a computer between its power downs as its program. The kernel and executables are its functions. Every open source part of it, excluding some core parts, is editable and swappable without reboot. This makes any OS with an editor and a development environment satisfy the requirements.
If the discussion on /r/lisp will not satisfy you, you may be amused asking the same question on /r/smalltalk.
Potentially stupid question: Why node-webkit, instead of something like CEF3? Portability reasons?
Thanks, this is the sort of realistic and nuanced analysis I like! (Though I don't always live up to that standard.)
I love the license!
There's a typo in the README, "maintaner". (I hope it's okay to make 3 different replies for 3 completely unrelated comments...)
You don't even need to save and load it, just eval the expression via C-x C-e. In fact, if you never needed to restart emacs, all your custom emacs code could be in buffers that were never saved to disk. Look at laws VI and III [here](http://www.loper-os.org/?p=284) for the relevant desiderata that you're after.
How is this more proper than normal declarations?
Is there anything for the compiler to note?
Smalltalk
The desire to run CL everywhere (with a common core like you mention) was what led me to start mocl. I looked at ECL, but one major blocker (amongst others) was the LGPL license. Since you're doing a commercially significant project and plan to eventually target mobile, here are a few links to help clarify the situation: http://multinc.com/2009/08/24/compatibility-between-the-iphone-app-store-and-the-lgpl/ http://faif.us/cast/2012/mar/13/0x24/ http://arstechnica.com/information-technology/2011/02/windows-phone-marketplace-bans-the-gpl-and-the-app-store-should-too/ mocl is getting better than ever lately (announcement coming on Tuesday: https://wukix.com/D7139999), and if you'd consider using it in your project, I'd be happy to work with you to embed it into Node-webkit.
Declarations are inherently (portably) unsafe as defined by the spec. Specifically, the consequences of either mis-typing a variable, or passing the wrong type to a typed function, are undefined. Being able to control easily when you want to assert a type rather than declare it is useful. SBCL is an example implementation where you get some of the benefits of expectations by default with type declarations. But that's not always true and relying on that isn't portable anyway. 
I get a lot of notes using the same source on an older SBCL. Just putting a `(declare (optimize (speed 3) ...` into a function without specifying any types used to get me notes but now nothing. So either the SBCL compiler has improved a lot or I am missing something obvious on how to enable the optimization notes. Dou you get notes and have perhaps a small function that generates them?
I researched a lot for webkit or chrome embedding projects and never even heard of CEF3 (maybe I wasn't searching right). The main reason for Node-webkit is that I already have a working app built on top of it. I considered something like Xulrunner or GTK+Gtkwebkit, but it would be nice to not have add a whole complexity from a system I'm not familiar with. Not sure if CEF3 provides things like tray icons, borderless/taskbarless windows (for notifications) etc...NW gives these out of the box, and for the most part it all works really well. That said, thanks for the tip on CEF3, I'll keep it in mind if I have issues with NW!
I've always been fairly fascinated with your work on mocl. My app has almost the opposite requirement, oddly enough: all pieces of it *must* be open source, and it itself is GPLv3. &gt; one major blocker (amongst others) What are the others besides licensing? I'm interested to know your perspective on ECL's limitations. Also, thanks for the good reads on licensing. Actually had no idea Microsoft banned GPL. I read that and kind of thought "Well, good thing I don't give a shit about Windows phone!" but still, being limited from a platform for choosing a fairly ubiquitous open-source license seems shady. I haven't read the full article yet and maybe they have a great reason, but GPL is a great choice for an end-user app with the requirement of being open-source (as opposed to GPL-ing a library which forces a lot of people's hands). 
How do you compile? We muffle notes at the REPL. COMPILE and COMPILE-FILE should be as noisy as usual.
This reminds of Quid pro quo. [1]: https://github.com/sellout/quid-pro-quo
I am going to have to look at this as I still use descriptions everywhere, but no longer the Lisp-on-lines version. yay!
Many have said that one of the biggest problems with lisp is the proliferation of non-standard and incompatible mascots.
More like a primitive C++ with s-expressions. 
Even if my Lisp abilities are pretty limited, I can see, you're just making something of a search and replace to translate to C, and the language itself doesn't feel at all like Lisp, more like a very cluttered C. Also, I'm curious how would you handle structs, classes and pointers? Sorry for not being impressed, I'm sure you invested some time to write this.
&gt; translate to C It translates to C++. It utilizes C++11's *auto* keyword for type inference. In C++14 and C++17, L++ will be better. &gt; cluttered C Cluttered C++ it is. &gt; how would you handle structs, classes and pointers? Use (code), an inline C++.
There can never be enough half-arsed attempts at Lisp. The question is - is it half-arsed in an interesting/useful way? :-)
Half-assed attempts are how we learn to go whole hog.
I'll say something positive as there are a lot of criticisms. Even if this is a thin s-expression wrapper over C++ syntax, it can still be useful. For instance, if you are building a program to write C++ programs, having an s-expression syntax means that I don't have to define my own AST form, nor do I have to write a translator between that AST and the C++ code. Also, I imagine this might open the door for Lisp like macros in a language that maps trivially to C++. I'm not a C++ programmer, but by accounts from those that are, C++ is an enormous language and the typical way things go in C++ is to pick a subset of the language and work within it. Is the intention for L++ to work within a subset of C++ or to have a syntax to match to any C++ syntax/coding style? If you work within a subset, will that subset have the capabilities you might want in an reasonable manner? Presumably the C++ community is using disparate coding styles because they are necessary to get the result they want in a reasonable way.
&gt; Is the intention for L++ to work within a subset of C++ or to have a syntax to match to any C++ syntax/coding style? To work within a subset of C++. Lack of time and money is a problem. 
Clojure - page 2
How does this compare to Chris' [Clasp](http://clang-developers.42468.n3.nabble.com/Refactoring-C-with-Common-Lisp-built-on-the-clang-ASTMatcher-library-td4037738.html)? He has not released it yet but hangs out in #lisp and you can ask him any questions about it. I think he plans to release it within few months 
Although perhaps only peripherally related to Lisp, an interisting read none the less.
v0.2: Macros are supported via Racket's macro system define-syntax.
Evil mode has removed the need for vim for me. Now to get used to paredit mode
It's nice to see any lisp language get more mainstream-ish press but this is hardly technically edifying content. I guess I need to start working on a blog post again.
I use Evil in Emacs as well. You don't *have* to use paredit if you do not like it :-)
Fortran is 'a relic from the 1950s' in approximately the same sense that Lisp is: that is, no useful sense.
Anything still widely used and altered but 60 years old being a relic seems to say more about the writer than the subject.
I'm glad to see "Defmacro for C: Lightweight, Ad Hoc Code Generation", which is very similar to [L++](https://bitbucket.org/ktg/l)'s approach. L++ already has define-syntax and defmacro. e.g. https://bitbucket.org/ktg/l/src/337c13802c5e9a64b8cadee2440df4e87816d185/ex/define-syntax.lpp?at=master
Am I the only one for whom the link doesn't work?
Works fine here, enough to proxy it through google docs viewer https://docs.google.com/viewer?url=http://www.european-lisp-symposium.org/ELS2014.pdf
And next week we'll get microsoft's new L#.
License? Last I looked the rights for Lucid CL were owned by LispWorks. They are calling it Liquid CL... http://www.lispworks.com/products/lcl.html
https://groups.google.com/forum/?hl=en#!topic/qilang/VHe3r-EEmfM I should have said. Mark
You can see documentation at minute 3:13 in the video. This is included with mocl (but we choose not to post it publicly).
This looks awesome (in general and also compared to how tedious mobile applications are otherwise). So does/will the remote side support slime/swank?
Let me try to be nice because your demo is impressive. I've spent a lot more than $200 hoping that some piece of software would do what I want. But without something beyond three YouTube videos and [one web page](https://wukix.com/mocl#buynow) it's probably just not going to happen in this case. You're selling some custom subset of Lisp and a Lisp-to-C compiler. IMHO, it's just not reasonable to vend such a thing with no documentation or description of its limitations.
There is also some example code on [GitHub](https://github.com/Wukix?tab=repositories). I apologize for the general lack of info. Will try to work on putting more out there. For what it's worth, there is a 30 day refund period so you can check things out.
There wasn't. Pondered it initially, but instead we have paid source. Maybe totally open one day, but for now, I've got to eat. License proceeds go straight into burritos :)
FWIW, I think you should rethink your decision not to post any documentation. The GitHub sample code is essentially just the content of your YouTube demo.
I will be checking this out soon too. Thx for the post, looks neat. What are the limitations?
Could somebody explain me the calculation of the points appearing at the top-right corner of the page? Thanks
Although perhaps best known as a famous c.l.l. troll, Xah Lee also has published some nice material about emacs on his site.
I re-submitted this because I couldn't find the link in the new submissions on /r/lisp for some reason.
Xah Lee acted many years as troll and did a lot of damage to the Lisp community. No need to give him publicity.
He also did a lot of good for the emacs community and in the end I don't think any of that matters considering his situation
Then post it to an Emacs Reddit, not here. 
I haven't looked at the code but I found this http://code.google.com/p/monte-go/
I haven't seen that many mentions of how good Lisp is for go-specific AI, not in Go related channels, nor in Lisp books (I'm thinking specially on Winston here.)
Lisp machines were like this: you lived in a memory image - variously called a 'world' or a 'sysout' - which you could incrementally modify as you went along: to some extent all programming on these systems was the incremental modification of the memory image. Depending on the system it may or may not have been possible to reconstruct the image ab initio: I think it was generally possible for MIT-derived systems (though not by the end-user for Genera) but probably was not possible for the interlisp systems. Related to these - they ran on similar hardware at various points - is SmallTalk, which culturally seems to have been a more extreme/pure version of the InterLisp approach. I suspect they could not rebuild the world from cold either.
I'm a Lisp programmer who has a background in neuroscience and some machine-learning flavored kinds of data analysis and, frankly, there isn't anything about Lisp that is particularly well suited to artificial intelligence. The association is primarily historical, probably because when Lisp was used as an AI language, there were few other languages with symbols, for instance, and other high level features. In the contemporary landscape there is nothing in particular to mark lisp as an outstanding AI language. In fact, the profile of AI has changed significantly, and involves a lot more number crunching than symbol manipulation, and Lisp is not a particularly good or bad language for that kind of thing. 
While not Common Lisp, he wrote a nice tutorial on emacs lisp. Besides, this is a humanitarian matter, not a technical one, and I am pretty sure that many readers of this subreddit know who he is. By the way, I really couldn't stand Xah on c.l.l., but even "trolls" need help sometimes.
Monte Carlo Search Trees allow you to combine expert knowledge, even if incomplete or wrong, and still find good moves (given enough computation).
This is a talk about doing that in clojure, http://m.youtube.com/watch?v=v5dYE0CMmHQ
He needs help all the time. He had posted that he needs money before. Xah Lee is high on the list of people who caused damage to the Lisp community. He contributed nothing. Not a bit. Before that he posted widely how bad Lisp (and the jargon around it), cross posted his drivel everywhere, and now others post his stuff for him? Please don't. I'm not sure how he could have written a 'nice Emacs Lisp' tutorial. He failed to understand Lisp on a practical level. He might have written some Mathematica functions, but for some strange reason he could not write four lines of Lisp himself. Still he gave advice on Lisp as though he had a bazillion of libraries and applications written - while that was zero. /r/lisp is not a group for helping mentally ill people. There are millions of them and many don't have Internet access, a website, ...
Sure, fine for general programming forums like HN. Or Twitter. With Lisp, Lisp programming or the Lisp community this has nothing to do. 
Isn't Go supposed to very difficult to implement an AI for, as opposed to Othello, which is sort of trivial?
The definition of life becomes very blurred when you look at a virus. They are more analygous to an executing algorithm than other forms of life like bacteria. For the simple forms of life (virus) and their building blocks we have already successfully ported their intelligence and ability to indepentantly react to an environment to electronics.
Not sure of Zach's code is up, but: Playing Go with Clojure - Zach Tellman: http://youtu.be/v5dYE0CMmHQ
Wouldn't the multi- (CL all- ?) paradigm duck type REPL help: * Fork an existing game. * Let you see: board setup, A-B or diff searches, file (SGF) save restore * Dynamically, Incrementally add AI Rules, Then add assertions and compile for speed. * learn/try new paradigms * port to diff web or gui, platforms, os
as brilliant as scary yeah
Except there are 8510 readers here and 188 readers there at the time of writing. I posted a question on what was the easiest order to learn languages, eventually reaching lisp (you know, should I learn something like C++ first or not), and got about 4 replies. For some reason, I am very sure that I would have gotten much more help and many more opinions here. I understand that all you experts would like to keep the new-person questions to a separate subreddit, but it would help if more people would subscribe to that/frequent it. 
Nice! Just subscribed. One never learn enough. It is good to keep questions focused there, imho.
I don't think people should use a separate subreddit. I think it was created for symmetry with the /r/learn&lt;language&gt; of other programming languages.
I am confused about your final opinion. So basically us new lisp learners should post our questions here? Then what purpose does that subreddit serve?
Thanks to everyone for taking videos and posting them. I have them on my phone and am going throught them on my way to work. Really great topics.
just watched the talk, brilliant work. 
Just ask in /r/lisp. We hardly ever get posts here (a handful a day if lucky) and most of them are articles talking about how great lisp machines were. In other words, people in this sub jump at a chance to help out. At least in my experience. Also some of the people here may be experts, but we're all still learning. I think learnlisp unnecessarily diverts questions that could make /r/lisp better.
Huge respect and thanks to organisers for making this available! I hope this sets a precedent for future conferences.
The order in which I learned languages: 1) BASIC 2) C 3) Enough Pascal to pass the AP CS Test 4) Lisp Looking at 1,2, and 3 it's obvious why I loved lisp so much. At the time, python and ruby, while existing were less well known than lisp; perl and tcl were the only other well known higher-level languages at the time. I still like the combination of expressiveness and performance, but I've used it enough to have things I don't like about it. My ideal language is probably still an improved common lisp though.
Sorry if my comment seems noobish, but I am unfamiliar with Shen. So, are you demonstrating how to implement objects *a la* java in Shen with a macro? In that case it seems to me quite powerful. There is one thing I don't get: in the line: (instance bird) [[flies true] [latin_name] [migrant] [blood warm]] : (instance bird) What is (instance bird)? Is it somehow equivalent to the Java new Bird(); In this case, I am confused what this does: (9+) (assign (instance bird) latin_name "passer domesticus") [[flies true] [latin_name "passer domesticus"] [migrant] [blood warm]] : (instance bird) Are you assigning a value to the slot *latin_name* to a particular instance of *bird*? In this case, wouldn't that be garbage collected since no variable gets assigned to this instance? 
&gt; always afraid of hitting that question that just stops me dead in my tracks No question should have that effect. It's ok to not know everything. 
If you really want to brush up, go hop on SICP, free online here: http://mitpress.mit.edu/sicp/full-text/book/book.html and poke around in the first couple chapters. You could grab a free scheme like Racket and work some examples.
Agree with gensyms. If they ask a question you don't know, just calmly tell them you aren't familiar but you have the skills and the drive to learn. Also, I've found it helps to approach these situations with the mindset that I'm interviewing them just as much as them me. Do I want to work here? Why? Will these people make my life better or will they make it a living hell? What's this strange language they've invented and do I actually want to use it? They are asking you to work with an undocumented tool they built themselves...don't be too scared of not knowing how it works. They're lucky to have you.
Awesome book. Reading it now! Edit: thanks for pointing me to it
Thanks! I already know half the people there, and I like to think that I'm studying to work there (and not just for the interview). But the most I know about lisp is A) parentheses, B) functions are data, and C) it's similar to programming the AST directly. One or more of these points are likely wrong, so reaching out to a more knowledgeable crowd seemed like a good decision.
Yeah, I know I shouldn't be afraid to not know something, but not knowing what I don't know makes me uncomfortable.
My thought process: * Oh, systems programming! I can help with that. * Wait, r/lisp? Maybe it's about lisp machines or something. Cool! * Logo? I guess it's based on Lisp, but for systems programming? * Scientific data collection hardware?! W. T. F. I have no idea; surely there's no one else in the world programming drivers for scientific data collection hardware in Logo. I learned Logo as a kid (had it on my Apple II clone), I know several varieties of Lisp, and I've got extensive experience in embedded systems and device drivers. But I never thought I'd see all those things together! As others have said, I think the key to getting this position will be to show your enthusiasm about the project itself and your ability to learn things quickly. Don't try to fake knowledge you don't have, but *demonstrate* how you learn by asking smart questions about what they're doing and what they want you to do. Find connections between the things they describe and things you have experience with and talk about them. Your desire to research this stuff out is most likely a point in your favor as well. You can learn a bit more about [Logo](http://el.media.mit.edu/logo-foundation/logo/index.html), and if you don't know anything about embedded systems, you should probably [read up](http://en.wikipedia.org/wiki/Embedded_system) a bit. Time is short, but if you can you might want to pick up an [Arduino](http://www.arduino.cc/) or something similar; [Radio Shack](http://www.radioshack.com/product/index.jsp?productId=12268262) actually carries them at a lot of locations, so you might be able to pick one up quickly. There's a guy that wrote a [Common Lisp to Arduino-C++](http://sourceforge.net/projects/arduinolisp/) cross-compiler thing; it looks like it hasn't been updated in a while, but it's the closest thing to 'embedded development in Logo' I could find. :)
Yeah, it is an odd thing isn't it? The way the program was described to me was that it was like an arduino with optional dedicated modules to handle thing like accelerometers, thermometers, pH-meters, and the like for students to be able to program little data collection boxes. The choice of a logo derivative was to make it easier for nonprogrammer phys students to learn over something like C.
Sounds like you'll be making those devices/data accessible to them via logo - not sure you'd be doing the low-level stuff in logo itself.
Thanks a lot for spotting these issues! I've just published a new version of the book that corrects 1 and 2. You're correct about 3 too. But what I was referring to in the book was that, with Mongo, we resolved the initial race-condition in the code: things won't become invalid or crash due to concurrent access. 
Man, that sounds like a really fun job 
other link : http://medias.ircam.fr/search/?q=lisp
I'm not a Java person so somebody else might be more qualified to comment on this. As regards 'garbage collection'; yes, quite right. The instance created here is temporary so you would have to assign it to some global variable to keep it. The actual class definitions are stored on property lists so they are permanent.
I'm a bit confused as to what the SETF statement would look like. Could you write an example of a form that should result in setting both BAR and BAZ?
not really, no. setf expansions are computed at compile (macro expansion) time, which is before the place has a value we can check the type of (i guess you could use declare to tell the compiler about the values the place will have at runtime, but that's beyond me at the moment). you're going to have give your "set both slot values to this value" method a name, which your write into your code and which the compiler sees, and once you've done that you can just define the setf method normally.
OMG THANK YOU Google was not helpful. 
Also you might want to add (add-to-list 'load-path "/usr/share/emacs/site-lisp/slime/") (require 'slime) (slime-setup) to your ~/.emacs file. You might want to change the path depending on where your site-lisp directory is.
http://www.quicklisp.org
s/ s / a /
I try to imagine a lisp machine. * How does it compare to modern smalltalk like pharo? * How does it compare to Acme text editor? * How does it compare to modern operation systems like windows? * How hard it was to program? It feel like the programmer can get lost in the number of functions available to him. 
Interesting discussion on HN: https://news.ycombinator.com/item?id=7797218
Comment by HN user crististm: &gt;The level of complexity of these systems is high even for today. But complexity has nothing to do with why we struggle today with vim, emacs, eclipse with gdb or what-have-you for developing and debugging. &gt; &gt;Those who understand the system are few, and the time they have at their hands is scarce to begin even contemplating the amount of work required to develop a free alternative to genera. I have no other explanation of why so many hobby projects started and failed at replicating what is still state of the art in programming environments
with a bit of structure/abstraction and packages, I'm sure it won't be worse than the JDK. Betting on the opposite, since IIUC lisp code reuse is often higher than OOP.
Thia. You don't really need Liap in a box any more.
You are right. I would prefer the *after* method however because I would end up writing the BAR method as well and it would be a little bit more verbose.
[Here is a better formatted change log](http://sbcl.org/all-news.html#1.2.0) ... reddit considered it a duplicate even though there is new content.
Hurrah for ARM port
Honest question: I am not familiar with ARM. Can you give me some examples of the usefulness of this?
Running SBCL on any of the following devices: Raspberry Pi, Beagle Bone Black, and I have also heard someone running it on a rooted Samsung Galaxy S series device. So if you have shell access to your android phone or tablet, you likely can run SBCL on it now 
Awesome!
And the next release will have support for native Android, and you wouldn't even have to root it if you run it from within a Java app.
It's not possible to be not familiar with ARM processors. It's at most possible to be unknowingly familiar with them. No matter what kind of computers and gadgets you use, you're guaranteed to have at least a few ARM processors among them, even in things like an Intel-based PC. (However, most embedded ARM processors aren't running Linux, so there's no direct applicability of this SBCL port to them.)
What? That too? Jesus F. Christ. I got some beers and care packages to send out to the devs. This is just badass. I knew that someone was working on an ARM port but I never expected to see it given the amount of time all of this stuff requires. Well, I'm off to get me some beagle and and raspberry devices. 
The comments below that article are useful as well. MikeS raises some of the other differentiators between CL and Clojure, such as immutability by default and the sequence abstraction. The author gives a nice response to those points, and suggests he will take some of them onboard for a future article.
Send them to Stas Boukarev (stassats) and Alastair Bridgewater. The latter did the initial work while the former brought it home. EDIT: typos in names.
Cool! I might try this for a little project I've been working on. I've been wanting to use Lisp, but I don't like having to use the JVM (Clojure) for a desktop app.
"Stas Boukarev"... edit: and "Alastair Bridgewater".
Just curious: what should the JVM usually be used for?
Gain libraries; lose performance, type inference, compiled binaries.
Well, why not give [Common Lisp on the desktop](http://common-lisp.net/project/commonqt/) a try?
Let me guess: another Lisp dialect which is incompatible with any other Lisp dialect and shares zero code. 
I just think of it as a different/better way to use Python
Then better not say, 'Lisp in Python', but 'New Lisp dialect in Python'. When I read Lisp, I would expect that the basic data structures, functions and special forms (DO, LET, PROG, MAP, LAMBDA, READ, ...) exist and work similar. Good that it is called Hy and not something like HyLisp. We get a mix of different s-expression syntax, arbitrary renamed/'improved' Lisp functions and parenthized Python... What's wrong with implementing most of say, Scheme, on top of Python and then change it slightly. Thus the syntax and semantics of a known Lisp dialect were used. Instead we get another selection of 'improved' Lisp operators...
Why is this the case? Both in the standard and the SBCL case? (To me: it seems like such a natural thing to allow for that denying it could only possibly have a terrible backwards-compatibility explanation.)
 MiniCalc - Postfix Calculator + - * / ^ sqrt Racket expressions can be entered. The inexact result will be copied to the clipboard. &gt; 2 3 + 4 / 1.25 &gt; 5/4 (cos 0) 5 + 6.0 &gt; 6 (define (foo a b) (+ a b)) #&lt;void&gt; &gt; #&lt;void&gt; (foo 2 3) 5.0 &gt; 5 
Now implement the shunting yard algorithm :)
CL was an effort to unify pre-existing code bases and CLOS was a late addition to the spec. This also shows up in, e.g., conditions having their own class and dispatch system (which may or may not be CLOS under the hood). Most of the non-CLOS part of the spec could be implemented with TYPECASE and perhaps some ad hoc single dispatch system. For SBCL, Christophe Rhodes found a nice way to expose extensibility (via CLOS) without hindering optimisations.
Perhaps one day the common CL implementations can come together and agree on an updated spec! Or at least one can dream :-(
The history there is lacking any mention of Franz Lisp. Yes, it had core compatibility with MacLisp, but it had a lot more. And, it enabled Macsyma to run on a VAX. Franz Lisp was also included in BSD releases for the VAX. It was in processor research at UC Berkeley, as well as a lot of other stuff.
There other ways to access [python libraries](https://github.com/pinterface/burgled-batteries) Hy's community also seem to be doing some interesting things like using a port of [minikanren to write rewrite rules for code](https://github.com/algernon/hydiomatic/blob/master/hydiomatic/rulesets/control_structo.hy)
If you look at the book CLtL1, Franz Lisp is not mentioned at all. So it is a historically significant Lisp (its developers later created Allegro CL), but it played almost no role for the first definition of Common Lisp. It's not mentioned in compatibility notes, not in the references, not in the index.
Hey, I saw your submission for greenlighting Cypress. Have you thought about expanding 2x0ng even further and greenlighting that :)? I personally think that 2x0ng is a great little game that really could expand into something bigger. Hm, I guess since the source is open I could always start working on 2x0ng Extended Edition.
Nice, refreshing article that doesn't try to go overboard on selling Lisp.
I'd argue that even more than blocks, Ruby metaprogramming is possible due to definition of class members and methods being just plain function calls in a class context. Even without blocks, you could just use lambdas. Of course that's all possible in Lisps, but the context-sensitivity of ruby is a fascinating bit of language design. Here's an example from an attempted 'Magic the Gathering Rules Engine' I was working on in ruby a few years ago: class Giant_Growth &lt; Card name 'Giant Growth' mana MtgMana['G'] type :instant targets :target_creature text 'Target creature gets +3/+3 until end of turn.' effect do |card, state| target = card.target state.until_end_of_turn_effect do target.power += 3 target.toughness += 3 end end end
Looks compact but I suspect understanding it a year later might be a bit tricky. How do you find Ruby in terms of code maintainability? (I wrote the essay, by the way, but only have an academic familiarity with Ruby).
I feel like you have to subscribe really hard to TDD to make Ruby work, otherwise it's too easy for 'spooky-at-a-distance' changes to break things. Other than that, I think maintainability is fine as long as you are principled in your development. In fact, looking at this code again (it was written in 2006), I was surprised how quickly I understood how all the pieces fit together. This was likely due to huge testsuites that documented how everything was supposed to work. There was even a test suite for the "scripted player" component I used to make testing other components easier: # just one test, there were 10 in this particular test suite def test_pass_until_legal s = ScriptedPlayer.new do |player| player.pass_until_legal :a player.act :a player.pass_until_legal { |obj| obj == :b } player.act :b end assert_equal(:pass, s.get_action(nil, [:pass, :go], nil)) assert_equal(:a, s.get_action(nil, [:c, :b, :a], nil)) assert_equal(:pass, s.get_action(nil, [:pass, :go], nil)) assert_equal(:b, s.get_action(nil, [:c, :b, :a], nil)) assert_raise(ScriptTerminatedError) { s.get_action(nil, nil, nil) } end But I moved to Haskell because I couldn't solve correctness issues to my satisfaction with just TDD--one of the game rules states that illegal actions cause the game state to back up to the last legal state, and it's virtually impossible to predict what actions might be illegal ahead of time. I didn't have confidence that I could implement a safe undo framework around my side-effects-everywhere code.
Man, I wish I had a good excuse to use Haskell someplace. It is one of my major areas of interest, type systems and pure functional programming. 
Try Implementing Functional Languages: A Tutorial. It's a free book that walks you through implementing a basic compiler for a pure lazy functional language in Haskell (the text says Miranda instead of Haskell everywhere but 95% of the syntax is the same and 90% of the places where they differ are already updated in the code snippets in the textbook) Alternatively, the ICFP programming contest is coming up next month, and you could try to solve the problem there in Haskell over a single weekend.
I got too much to do between the job and [the videogame](http://procyonic.org/corpseWizardEdge/corpseWizard/) to do the ICFP, but I will check out the book. Thanks for the suggestion!
Rooted Android - is it hard or soft float -ABI ?
So a APK/DEX header that loads the SBCL arm like it was compiled with the NTK ?
Speaking of Lisp books, are there any current reference out there I can buy on paper today? I've read Practical Common Lisp and Let Over Lambda, but these aren't books you can slap on your desk like [this one for C++](http://www.amazon.com/The-Programming-Language-4th-Edition/dp/0321563840/ref=sr_1_2?ie=UTF8&amp;qid=1401915055&amp;sr=8-2&amp;keywords=c%2B%2B+reference). Or do I have to stick with online stuff like the CLHS?
[keene](http://www.amazon.com/Object-Oriented-Programming-COMMON-LISP-Programmers/dp/0201175894/ref=sr_1_fkmr0_1?ie=UTF8&amp;qid=1401930152&amp;sr=8-1-fkmr0&amp;keywords=kleene+object+oriented+common+lisp) is a good one edit: it's not a large language reference. but it is a good book about CLOS
http://clqr.boundp.org
I like it when I find this simple yet powerful ideas implemented, these are the things that when you see them you think, Why didn't I think of that? I think the results you have gotten from it speak by themselves, very nice looking dynamic pages, and very nice looking PDF export. I also liked your presentation on the 7th ELS, I saw a video of it, I was not there.
Thanks a lot :) It's a great encouragment to go further.
Why doing that when one can create a proper relational DSL? 
"Crane doesn't judge", why should you? That said, I generally love the Rails' ActiveRecord, and this is almost definitely inspired by ActiveRecord, if you consider migrations and everything. So I definitely like this.
There's CLSQL, I don't know how good it is, though.
Looks really cool!
&gt; SSQL for scheme There are two, [SxQL](https://github.com/fukamachi/sxql) which this project builds upon and [s-sql](https://github.com/marijnh/Postmodern/blob/master/s-sql/s-sql.lisp) used by postmodern
Better than a DSL, you can just use CL-INTERPOL with parens as the outer delimiter. You get reasonable indentation, structured editing, and real SQL.
yey. looks like what the doctor ordered for Common Lisp Web Development
I'd never heard of ACL2 before. Very cool!
:-) i've become more interested in automated theorem proving of late, and being able to map something as widely used as LLVM to something like ACL2 seems to be exciting progress. :-)
Cool
nice! btw - is there some similar library for elisp? would be nice to use it together with org-mode...
Last stable official release is from 2006 but I have seen some github repos that were much more recent - not sure with what kind of changes. But it doesn't seem that there is any active maintenance/development being done anyway. There are plenty of scheme implementations and probably as many reviews and claims that each is faster than the others, it depends on your use-case. Stalin is fast because it's a scheme-to-c but difficult to install and use. Other implementations usually offer interpreted and compiled option and the results will vary greatly.
Chez Scheme is available at [scheme.com](http://scheme.com). It's very good; I use and recommend it. Unless you need the C foreign function interface, the free version is probably sufficient.
The language seems to be intuitive. There is a bug in hy (for [x (range 10) 7]) the following works (for [x (range 10)] seven) 
The free version, Petite Chez Scheme, does not do native compilation. It uses a bytecode interpreter. For most things that's fine, but this question was specifically about fast Scheme compilers.
I think Gambit and Chicken are your best bets for fast, compiled, active, open source implementations. Both are able to compile unsafe code in favor of performance. Both also make direct access to C code very easy. If you're not familiar with either and you just want to write Scheme that compiles to a binary you should most likely start with Chicken. I would use Gambit if wanted static compiled executable (chicken defaults to shared objects but can also do static) or if I was planning to cross compile the generated C or if I wanted to incorporate lots of custom C code but only after determining that the necessary scheme libraries were available for Gambit or easily ported. Truthfully I really love to work with Gambit. I think It's compiler/interpreter are second to none and a joy to use but not having built in support for modules and no library system like Chicken's eggs makes it hard to recommend for lots of tasks. I also highly recommend Gauche. It's compiled to byte code and interpreted so I would suggest it's suitable for any task Perl, Ruby or Python would be. What makes Gauche awesome is it's standard features and libraries. I think they're extremely well thought out. It supports native threads, utf8, r7 small, currying, streams, modules, an object system, generics, multiple dispatch, etc... 
I assume that means it doesn't play well with networking or media, is it suited for numeric/statistical work or is it just a badass demonstration of program provability?
Thank you for the link. Amazing.
at least the promised free migration does not work as expected.
&gt; it feels a little weird having an option in the function call that 99% percent of the time would only be used by the function calling itself I think a reasonably common approch is to have the function which provides the external interface "set up" the recursion and call a helper which carries the full state across. e.g. the "typical fibonacci" does it this way (from wikipedia): (defun fib-trec (n) "Tail-recursive Fibonacci number function" (labels ((calc-fib (n a b) (if (= n 0) a (calc-fib (- n 1) b (+ a b))))) (calc-fib n 0 1))) the outer functions calls the helper with the initial conditions: (calc-fib n 0 1) 
That's what I meant in the second option I mentioned. Sorry that wasn't clear, I should have provided an example.
This is what I do. For a question like this, unless there's a technical reason to prefer one approach over another (e.g., one approach permits better optimization) then IMO you should prefer that approach that fits best with the way you think about programming and solving problems. In most cases, reducing cognitive dissonance has a lot more value than almost anything else.
I do appreciate your work :) On a quite lower level I wrote a small Javascript code which creates a tiny Lisp-like syntax easy to use in a wiki : http://epsilonwiki.free.fr/alphawiki_2/. A kind of "Mocklisp" as said Richard Stallman, speaking of the James Gossling EMACS' interpreter. Your opinion would be appreciated. Best regards Alain Marty
This is pretty much the sacred idiom yeah. From book to teachers, it's everywhere.
&gt;ki has lambdas, lexical scoping, namespaces, local bindings, recursion, persistent data structures, lazyness, data literals, keywords, multiple arity functions, backcall-style continuations, multimethods, atoms and macros. And source maps. Oh hey! It's actually a proper Lisp and not a toy!
I have to admit, for a 'thin layer' it is pretty dense.
Okay perfect. Getting this done now.
Danke.
The some in the t case seems a bit strange. I had expected some to return a generalized boolean as the other similar predicates, but I see that the hyperspec supports your use. Recursion just blows up the stack and not the heap, the consing must be result of the (list (append (list ...) or whatever you do in valid-crossword-intersections
I was afraid the `some` would be weird. It was my solution to getting it to branch and still terminate on the first solution found. I'll probably eventually change to the more conventional structure that others have pointed out. In the meantime I it works but the helper functions are returning garbage so I need to fix that first. The whole thing is definitely a pig... I count O(n^5 ), could be low on the power though. At least it's not exponential or factorial. I think.
Yeah for me it was about being able to `trace` the function.
It is wise to post this on /r/forth. EDIT: I think the best way to find out is to learn both Common Lisp and Forth ;-) If you have any more questions you can post them on /r/learnlisp.
Ah. Forth, or at least implementations I'm familiar with, don't really have macros. What you showed above is just the regular way to define a new word. The closest Forth come to macros are builds/does words. They let you define a new "compiler words" that have different behaviors at compile time and runtime. 
If consider a macro as something that substitutes its body instead of inserting a call to it in the definition of some other word, then you can definitely do this: ---- : plus10 10 + ; : plus10-macro postpone 10 postpone + ; immediate : test1 plus10 ; : test2 plus10-macro ; ---- see test1 : test1 plus10 ; ok 20 test1 . 20 test1 . 30 ok see test2 : test2 10 + ; ok 20 test2 . 20 test2 . 30 ok If to use the MACRO: word from [NOVICE](http://www.forth.org/novice.html) package of Hugh Aguilar writing macros will be much easier: ---- macro: plus11-macro 11 + ; : test3 plus11-macro ; ---- 20 test3 . 20 test3 . 31 ok see test3 see test3 : test3 11 + ; ok 
I know both. I am writing a CL to JavaScript compiler http://github.com/davazp/jscl I learnt Forth writing a Forth implementation on the metal http://github.com/davazp/eulex Forth immediate words (macros) linear structure make them more painful for me. If you want to simulate nesting words need to cooperate. Like DO...LOOP. They communicate through the stack to compile correct jumps. The nice thing is you can write a variant like +LOOP as long as it conforms the protocol. But error handling and reporting is hard. On the other hand CL macros are usually more independent because code walking is hardly ever an option. But they are easy to compose. I prefer Common Lisp for sure but Forth was fun puzzle too. Look this awesome keyboard scancodes array :) : https://github.com/davazp/eulex/blob/master/kernel/keyboard.fs#L135
ASDF3
Isn't ASDF3 only for building Common Lisp packages? Both Rake and Shake are general purpose build tools. Can you easily say in ASDF, for example, that the file `bundle.tar.gz` depends on each file mentioned inside the file named `MANIFEST ` and should be re-compressed whenever `MANIFEST ` or any of the files mentioned therein changes? (I've never even run external programs in ASDF3, but I assume that's possible, but I don't know how general its notion of dependency is.)
There are a few scheme based build systems whose names escape me at the moment. http://home.gna.org/conjure/ but I could have sworn there was another...
Well I guess it depends if you are looking doing. If you want to extend current capabilities of asdf, there is asdf-linguist (https://github.com/eudoxia0/asdf-linguist/) which provides interfaces to external build systems like make and has interfaces for running processing tool such as text processing (org-mode, pandoc) or js compressors or copliling certain js languages to java script. Presumably it has a base framework that can be extended to fit your needs. 
DEFUN is usually a toplevel definition. Everything which begins with "DEF" is by convention a toplevel macro. Using it inside LET and FLET is possible, but not really intended.
Of course, it is also somewhat common to do it without labels: (defun %fib-trec (n a b) (if (= n 0) a (%fib-trec (- n 1) b (+ a b)))) (defun fib (n) (%fib-trec n 0 1)) Then you can TRACE easily without cluttering up the API. 
Thanks, I was wondering why he did this.
Sure, I know. But that does have some disadvantages, too. Actually there is very little difference to using a global variable, which is easier to debug.
Read my article to see how powerful Lisp syntax (a pair of parentheses) is so powerful for macro: http://tuhdo.github.io/emacs-tutor2.html
I tried cl-cffi-gtk at crategus' github, which worked great for nix but couldn't get it to run on win xp. Guessing a gtk3 issue, although ultimately got blocked up with no libpng15-15.dll found and a missing z.dll 
guix is a guile scheme reimplimentation of parts of the nix package manager. It works in conjunction with nix build daemons, and is an interesting lisp replacement for nix's own homegrown functional dsl. Not exactly a make replacement, but it may be of some interest. [Guix](http://www.gnu.org/software/guix)
Are you trying to make something interactive or just draw a picture? Vecto is nice for drawing pictures.
Thanks aleksandros - works in gnu/linux and windows?
Thanks phalp, got vecto working for making static images - I'll be drawing a map that updates every second or so and vecto seemed to eat up my cpu to do that (and refresh the png in the gtk window)
Yeah, it's not super fast. I wouldn't try to use it real-time, although generating some artwork with Vecto and caching it could work for some purposes.
Clinch has some examples.
Thanks!
I'm toying with Cairo together with SDL. If I have a time, I'll create the VT330/VT340 terminal emulator. For now, the code is rightly a [hello world example](https://bitbucket.org/Goheeca/cairo-sdl). I hope it helps ;-). One very quick [screenshot](http://imgur.com/dtefiGn).
You have to install zeromq (the C library) first. 
Oh, thanks Xach, this helped a lot! I was humming and hawing over this thinking maybe from something like quicklisp, it's all self contained; still learning this side of it, so wasn't sure if I needed something else. For future reference, steps I took (mostly from [here](http://maddigitiser.wordpress.com/2013/05/02/installing-zeromq-on-ubuntu-13-04/), with a minor correction) were, on Ubuntu 14.04: sudo apt-get install libtool autoconf automake uuid-dev build-essential cd ~ wget http://download.zeromq.org/zeromq.3.2.4.tar.gz tar zxvf zeromq.3.2.4.tar.gz &amp;&amp; cd zeromq.3.2.4 ./configure sudo make &amp;&amp; sudo make install export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib/
Installing non-Lisp libraries is a tough problem, especially cross-platform. Quicklisp only does the Lisp side of things. It's one of the reasons I am so glad that many of the useful Common Lisp libraries are more than just wrappers around C libraries.
Thanks, Tsuru - duly noted!
Is Tcl/TK really that bad? I'm actually asking, not refuting he point. I have only used it minimally and found it easy to work with and from what I hear, Tk has made a lot of progress in the last few versions to not look like like a hunk of ugly crap. Also, yeah you're stuck with ECL (or similar) if you want to call lisp code from somewhere else without setting up some sort of messaging. With implementations quickly approaching usability on ARM, it would be cool to have libsbcl.(so|a|dll) or libccl.(so|a|dll) and be able to load them dynamically and run arbitrary lisp code. Or do these already exist somewhere and I just haven't stumbled on them yet? Finalizers: what exactly is left here that trivial-garbage doesn't handle? My wishlist - Coroutines, green threads, or continuations that don't require code walking. I don't like the idea of a macro rewriting my code for me. I use futures all the time for async stuff, but they are weak when it comes to error handling (error handling can only wrap the current lexical form, once you leave that form you have to re-wrap error handling). This is one thing I've been liking about scheme as I've been messing with it the past few days. If it had real threading, I might use it more. - An MIT (or similar) licensed implementation that's embeddable and has small memory usage. 
Tcl/Tk: There's MUCH left to be desired. I am specifically referring to [LTK](http://www.peter-herth.de/ltk/ltk-osx.png). Is it really that bad? Well of course this is subjective. For something extremely basic, it can get the job done. But it's extremely basic, and I would not want to depend on it for a modern, interactive application. I see it about as good as something available in the 90s. `trivial-garbage`: Of course, `trivial-garbage` can get the job done. But can't things be implemented more efficiently on a per-class basis as opposed to a per-object basis? Maybe so, maybe not. If not, then maybe it's good enough.
You are an engineer looking for a resource, not for another engineer? That's interesting.
http://lmgtfy.com/?q=autolisp 
Maybe the "last outsource guy ... went dark suddenly" because they were over being treated as a "resource" to be exploited mercilessly, rather than as a human being.
How is Qt junk? I was pretty impressed with CommonQt actually. It worked well and I could just go off the C++ docs and everything just worked as expected.
Embed ability as a shared object would really open up some options for the sort of work I do. At the moment there isn't much I can do with a saved lisp image.
I could only get it to work reasonably with one compiler on one platform/OS combination. 
almost all of those are things that should be implementation details.
[Leiningen](http://leiningen.org/) is the standard build tool for Clojure.
There're the ECL qt bindings, have you tried those out?
There's a blog called lisp jobs
I'm pretty sure quite any Common Lisper knows about it -- but it's not very "nice" (or politically correct) to just support one single implementation. On the other side, supporting ECL only allows for some neat C integration which is hardly possible with other implementations (I remember having tried some tighter integration of Qt/C++ with SBCL, and it just resulted in horribly bad segfaults.)
There's a strong suggestion here that the savvy programmer's secret weapon is Mark Watson [archived]. If english is not your first language, what happened is that you started out with well-recognized 'newspaper headline grammar', but then broke the rule by adding '[archived]' at the end, which causes the more logical and grammatical (although confusing) meaning to re-assert itself. 
There is also an updated version in ebook format: https://leanpub.com/lovinglisp
This is also not how colons are used.
That's why they call it "human resources"...
Looks really nice. Congrats!
I liked it! I will try to give it a try this weekend. Congrats! https://github.com/Inaimathi/cl-notebook 
One interesting application he hints in the end is a more interactive way to write documentation and export it to html
Only 64 bit binary available
You can always use quicklisp
I'm working on improving the LTK experience; I know the things I want, but do you have a wishlist?
Re: Better Executable support It doesn't do any of the fancy whole-program opts (which would require restricting the runtime anyway), but cl-launch makes it really easy to generate executables. Also, SBCL has made gigantic strides in startup time improvements; moderate sized dumps startup faster than python, for example.
I want both of those things on the wishlist. There's also a lot of minor annoyances in the spec that could be tweaked. One example that came up last week: displaced arrays are slow, and there is no type between simple arrays and arrays that could be displaced. This makes portably declaring a vector type that isn't totally braindead, but still reasonably fast hard. I would also love to have a reader that allowed you to hook in at the token level. Right now interning a symbol is the only option for non-number tokens. That makes doing things like playing around with the package system a pain.
Funny, I *just* ran into this issue. I had types declared as `'(simple-array (unsigned-byte 8) (*))` and at one point read about displaced arrays (which I hadn't known about) and thought "Cool, this will solve all my problems!!" Nope, I'd have to change all my types to accommodate which I'm guessing would slow everything down. Ended up just implementing the usual `:start/:end` keywords which is lame but works. So yes, I agree displaced arrays could be a *lot* more useful, but as is they are kind of a weird addon that nobody seems to seriously use.
[Gitcl](http://www.cs.cmu.edu/~dst/LispBook/) is a good first book. It moves slow and explains things. The repl is a just a convenient way to eval code as you write it. You can eval code in a regular text buffer too. 
This. Racket also has support for SICP, and the DrScheme IDE is both powerful and easy to get started with. 
So if I wanted to go the purely academic route and get a better understanding of programming, I would want to work with Scheme/Racket and read SICP but if I want to be productive in the future, I would probably want to go with CL? 
Well, "if you want to really know how to program and be efficient", stepping outside the comfort zone of an IDE[1] might be a useful exercise, as you learn how things work "under the hood", which IDEs can tend to hide from you. Having said that, using something like the DrScheme IDE, as others have suggested, certainly makes sense to give you a familiar learning environment whilst learning a Lisp! [1] Though i would argue that Emacs can indeed be configured to function as an IDE, in the literal sense of "Integrated Development Environment" - i do just that. One of the benefits of using Emacs is that you can heavily customise it to your preferred workflow, and then reuse that environment when working with new languages/systems. So i use Emacs to work with Perl, PHP, LaTeX, HTML, CSS, JavaScript, XML and have recently started using it for Android dev. :-) And support (or at least initial support) tends to get written quickly - cf. initial support for Apple's new Swift language.
O forgot car and cdr . Remember a comes before d in the alphabet. 
Or just use first and rest. car and cdr are anachronistic; Clojure doesn't even keep them around as legacies.
Racket! Do not use Lisp-2.
I think you should seriously consider Clojure if you are considering using a lisp for something in the future beyond academics. It's growing quickly (version 1.6), runs on the jvm, has a repl, can use java libraries. Book: Programming Clojure 2nd ed. If you choose Clojure, you might be interested in trying the Light Table text editor which has a Clojure repl built in, along with inline-eval of Clojure. Light Table was also written in ClojureScript (Clojure compiled to JavaScript).
Why would that be?
No, Scheme is [apparently used at Naughty Dog](https://www.youtube.com/watch?v=Z8Xamkb-J2k) (in video description), etc. Clojure has alot of nice features, including its concurrency model, and is already being used [industrially](https://wit.ai/jobs)
A lot of people here are offering up their favorite dialects, which are often strongly held feelings without much relevance to your particular issues. To some extent religious wars. For someone ready to learn, you can probably pursue any of them, so I don't think you are asking the right question. None of them are going to provide an IDE which is going to feel like programming in C or Java. You are not programming in C or Java. The reason to learn Lisp or Haskell or ML or other languages is to change how you do things. But you seem somewhat unready to change. For an IDE with a point-and-click editor, something like LispWorks Personal Edition is probably better than an open source Emacs + open source Lisp, but the editor is still a flavor of Emacs. SICP is a good book to read. But you don't need to ask someone else's advice to do so. You just read it. If you want something less dense than Practical Common Lisp, you might want to try something like [Touretsky's Gentle Introduction to Symbolic Computing](http://www.cs.cmu.edu/~dst/LispBook/).
Not going to buy into the flame inducing op, but could you enlighten me in some of the benefits of Lisp-2 over Lisp-1? I know I prefer Lisp-1, but I also know it's more of an artefact of me being introduced to lisps with them and they just "feel better". So I'd love some objective arguments either way.
It's nice that you don't need to worry about using the same name for a function and a variable. Which may sound like a thing only a crazy person would want to do, but this means I don't have to worry about my variable names accidentally shadowing system functions or my own functions. It's totally possible that I would want to have a variable called ERROR in the same scope that I call the function with that name. It's fairly often that I call a function and save the result in a variable of the same name, because this is clearest, and it's good that I can call that function later in the same scope without a problem.
I think ccl is worth mentioning at least for its obj-c bridge due to how prevalent the macs seem to be with developers
IMO lisp-1 vs lisp-2 is mainly about i) functional programming and ii) about metaprogramming. i) functional programming: lisp-1 is more "conductive to functional programming" as some say, and they are right :) I can't say it's easy to do fp in common lisp, certainly not easier than scheme or racket, but it's not that hard either. Thanks to stuff like #', apply and funcall remain the only offenders. ii) metaprogramming: when it comes to unhygienic macros, lisp-2 makes it easier to keep hygiene than lisp-1 because it's harder to accidentaly redefine a function. This is important because functions are more problematic because they usually have a wider scope than variables. Couple this with judicioua use of gensyms and it's not that hard to write safe macros in common lisp. Of course scheme doesn't have this kind of problems thanks to its hygienic macro system. Now, I personally preffer CL's macro system. I never felt comfortable with scheme's macro system, but that's mostly a habbit thing, because the first lisp I learnt was CL.
can use java libraries is not a differentiating factor there are implementations that allow you to do that in scheme and common lisp as well, i.e. Kawa Scheme and ABCL
I'm registered, see you there! 
&gt;Many Lisps support concurrency. The difference being that Clojure is built with concurrency in mind from ground up. Clojure defaults to using persistent data structures, which aren't even readily available in most Lisps, and it provides a STM implementation out of the box, not to mention things like [core.async](https://github.com/clojure/core.async). &gt;Like many other Lisps. I think the point he was making is that despite being a new language it's already seeing a lot of adaption in the industry. Clojure also appears to be much more popular for starting new development than other Lisps. Last I checked others Lisps aren't being [mentioned at the Google I/O](https://twitter.com/mikeflynn_/status/482251458742472705). 
&gt;Other Lisps also support concurrency. That's a true statement for pretty much every language out there, the question is how well concurrency is supported. For example, Java supports concurrency, yet it's notoriously difficult to write correct code dealing with concurrent in it. &gt;Well, Google bought a company for $700 million which had developed software with Common Lisp at the core. Nobody is saying that CL is not being used in production, what's being said is that Clojure is a more popular choice for starting new projects. That means that there are more job opportunities using that language. *edit: Apparently lispm was not happy with the direction of this conversation and decided to to flip the table on it. It's rather unfortunate since I think it would be interesting to read both perspectives on what constitutes a Lisp.
I didn't know there was an active community like this. That's great. Does anyone have videos of talks of previous conferences?
&gt;I've seen a lot of concurrent software in Java, can't be that difficult. I've seen operating systems written in assembly too, what's your point exactly? &gt;On a very small scale. I did not realize stackoverflow was the definitive metric for Clojure jobs, thanks for clearing that up for me. Oddly enough, [indeed.com has a slightly different result.](http://www.indeed.com/q-Clojure-jobs.html) 
Unfortunately, those 2002 videos are not authorized copies. Most (all?) conferences affiliated with the ACM cannot post videos. The same holds true for public distribution of the proceedings outside of the "ACM digital library". The ACM brand provides value for academics, but many believe their copyright policies are providing a significant hindrance as well. It is unclear at this point whether ILC 2014 will be video recorded at all.
While Clojure has many good ideas, it also made a number of sacrifices, many just to be a more idiomatic fit to Java (not always a win). When you are using "cons cells" to make structures other than simple lists, car and cdr are actually more meaningful than first and rest. Why not define custom 2-slot data types for such structures? Because then you lose the existing library of functions that know cons...
&gt;The point is that there are a lot claims and very little substance around concurrency in programming languages. You just repeated some of these claims, but did not provide any evidence. There's plenty of evidence of Clojure being used for concurrency. [Storm](https://storm.incubator.apache.org/) is one such example. Seems to me like you're the one making unsubstantiated claims here regarding concurrency support in CL. &gt;Indeed.com has no different result. If you look at the search results, there are very few actual Clojure jobs. Plenty of companies advertise for a set of languages. I've been developing with Clojure for the past 4 years on my job, and it was advertised as a Java position. I know plenty of people who use Clojure at companies that also use use Java, Ruby or Python. On the other hand, I have yet to meet anybody who started a job at any mainstream shop and was able to use CL however.
Very nice, succinct advice. Would you mind to say (even a few words), why would you advice `A Gentle Introduction to Symbolic Computation` in respect to `Practical Common Lisp` as "Powerful"? Thank!
It's more that LispWorks is 'powerful'. You could for example as an exercise easily write a GUI version of the cons cell inspector *sdraw*. LispWorks has a nice IDE and a cross-platform GUI interface. http://www.cs.cmu.edu/~dst/Lisp/sdraw/ *A Gentle Introduction to Symbolic Computation* describes the basics of the language.
CLs concurrency libraries are actually really nice and macros makes using them pretty damn easy. Persistent data structures is a plus, I'll give you that. And yeah, there is a certain clojure hype going on but I don't think that it's necessarily because clojure is that much better than other lisps, more about devs liking the "new, shiny, cool things", but maybe I'm just cynical
My personal experience has been that Clojure was the first Lisp I could really get into and apply professionally. There are a number of reasons for this. Clojure has a bit more syntax and I find that to be extremely useful when reading code. Having literal notation for different data structures is very helpful to me. Conversely I think it does a better job at reducing noise. For example, take the `let` statement in Clojure vs CL: (let [foo "foo" bar "bar"] ...) (let ((foo "foo") (bar "bar")) ...) Destructuring is another feature that I find extremely helpful when it comes to readability. Let's say I'm passing a map to a function that uses some keys from it. I can pull out these keys right in the arguments vector and that helps document what's happening. (defn foo [{:keys [name id] :as person}] ...) I find this sort of thing really adds up when you're looking through a lot of code. To me, Clojure code is a lot more scannable. Tooling is another problem for developers coming to Lisp. While Emacs is fantastic, it's also incredibly archaic and requires a large time investment to become proficient in. You also have commercial tools like LispWorks for CL, but somebody who's not already into CL isn't going to pay for them. On the other hand you can develop Clojure using Light Table, Eclipse, or IntelliJ. These tools are far more familiar to vast majority of developers out there. Next, you have the issue of infrastructure. There are a lot of companies that already run the JVM stack. When you introduce Clojure, the only thing that changes is the language. You can keep using the same development tools, profilers, package repositories and deployment environment. You can even keep leveraging the existing code base that you already have. Saying let's try using this new language for the next project is a far easier sell than a whole new platform. Conversely, you have the existing ecosystem of Java libraries and repositories. This means having access to a lot of well tested libraries for doing pretty much anything. For example, when I needed to do PDF reporting I ended up writing [clj-pdf](https://github.com/yogthos/clj-pdf), which is a wrapper for the iText and JFreeChart libraries. While Maven is not very user friendly, its dependency management model is quite nice. Clojure can be built with either Maven or Leiningen, and both use the same repositories and manage dependencies extremely well. On top of that, Leiningen provides a single tool for managing the whole lifecycle of a project. If I want to make a web application in Clojure I can simply run `lein new luminus my-new-app` and I'm good to go. So, while I don't know that Clojure is better than other Lisps, I definitely found it to have a much lower barrier to entry. 
Such as claiming implying that it's comparable to what's available in Clojure. &gt;Yeah, as 'experience'/'knowledge', not as a language these companies actually works with. It's great that you can write Clojure. My experience is that companies advertise experience/knowledge for things that are relevant to them. While not all of the companies listing Clojure actually use it, they are often open to trying it. 
&gt;Thus Clojure appeals a lot to people who haven't learned Lisp yet. Which happens to be the vast majority of developers out there and hence why it's a Lisp that many people get excited about. &gt;If I would need Lisp on the JVM, I would use ABCL. But usually I try to avoid the JVM. It's quite clear that Clojure is not the right choice for you personally. However, the thread isn't about what dialect of Lisp is best for lispm. Clojure is a great choice for anybody who wants to start using Lisp and have the ability to do so professionally. As you yourself point out, Clojure syntax appeals more to people who haven't learned Lisp yet. 
&gt;So what? People have been programming without those concurrent software for decades. People have used punchcards for decades as well, I don't think we should go back to doing that either. More to the point, concurrency has only recently become an important problem. For decades we had single core architectures with little or no networking. Nowadays most chips have 4+ cores and many applications run on clusters or deal with many concurrent clients. The problems we have today are not the same problems that we had in the 70s. &gt;There are a whole bunch of languages and concurrency constructs, which are well understood. This is precisely why immutability is considered a good choice for working with concurrency. The concurrency constructs in languages backed by mutable data structures are well understood to be a poor fit for this domain. &gt;Neither immutability nor persistent datastructures are necessary or sufficient for programming concurrent software. They're not necessary or sufficient, but they do make reasoning about concurrent code much easier. Since it's a hard problem to begin with, any tool that makes it easier to reason about is very welcome.
First, Clojure is just as much a Lisp as CL or Scheme, the fact that it doesn't follow your personal definition of Lips is not relevant to this point. Second, Clojure is far more popular with Ruby and Python programmers than Java programmers. Java is not a factor in learning or using Clojure, the JVM is however. Finally, learning Clojure is demonstrably easier than a language like CL. CL is the C++ of Lisps, a huge language designed by a committee and facilitating many different paradigms. By contrast, Clojure is a small and simple language with a clear focus. Learning Scheme might be easier, I personally didn't find that to be the case. However, it's quite a stretch to argue that it's more useful considering that Clojure is far more prevalent in the industry.
"If the fool would persist in his folly he would become wise"  William Blake
&gt;It's not. Clojure is a Lisp derived language. Like Logo or ML. It's fully incompatible with any Lisp prior to it. No Lisp book, no Lisp source code can be directly used in Clojure. Emacs Lisp, Common Lisp, Standard Lisp, etc. all all derived from McCarthy's Lisp. Scheme was a new Lisp, but it stayed largely compatible with many concepts of the original Lisp branch. That is an incredibly inane argument. Having compatibility with other languages in the family is by no means a requirement for a language to belong in that family. Scheme is not compatible with CL, Java is not compatible with C++, yet it's accepted that they're both members of their respective families. The only difference between Clojure and Scheme is that it is more aggressive about modernizing the syntax. Furthermore, having legacy syntax is in no way a benefit out of itself. Many things have been learned since the original syntax was invented over half a century ago and some of them, like literal data structure notation, are rather useful. Denying that out of principle is the height of idiocy. The defining feature of the Lisp family is the use of s-expressions which facilitate homoiconicity and the powerful macro features. Keeping historical baggage is not a relevant feature for a Lisp language. &gt;The state of Clojure survey tells something different. 33% from Java, 15% from Python, 16% from Ruby. Could you point out where you found these numbers in the [survey](http://cemerick.com/2013/11/18/results-of-the-2013-state-of-clojure-clojurescript-survey/) exactly? &gt;Scheme has been used for decades in education and has extensive literature and tools for that. Assembly has been used for decades in education and has extensive literature and tools for that. That alone doesn't make it easier to learn or use though. &gt;Clojure is a complex language on top of a complex runtime married to another complex language. It's error messages are poor and it's debugging information is complex, coming from another language's runtime. Yet, thousands of people come from other languages and use it just fine. Many of these people tried learning Lisp before with Scheme and CL and gave up. Clearly learning it is not nearly as difficult as you make it out to be. The Clojure error in your example is less friendly, but it doesn't take a rocket scientist to decipher. If that's the best example of Clojure being a complex language then I don't think there's much to worry about. At the end of the day your language bigotry is completely counterproductive. You seem to think that programming languages are a zero-sum game and if more people use Clojure it will somehow harm CL that you love so much. The reality can't be further from the truth. The more people use Clojure the more people appreciate what makes Lisp a great family of languages and the more they're likely to use another Lisp or recommend learning Lisp to others. Whether you personally like it or not, it's clear that Clojure has a lot of momentum and there is a lot of positive feedback from companies that use it. This has attracted far more mainstream attention to Lisp than there's been in decades. This is a good thing and it benefits everybody who likes Lisp including you. 
&gt;McCarthy invented a different syntax for Lisp. Originally it was believed that m-expressions would be useful for readability, yet it turned out that everybody was quite happy using s-expressions. They were **figuring this stuff out at the time**, taking the first idea as gospel and clinging to it would've been pretty stupid and that's why they didn't do that. You could take a page from McCarthy when it comes to your own views. :) &gt;So, MDL, Dylan, Logo and MLISP are not a part of the Lisp family? Inform the International Lisp Conference about your redefinition of the wider Lisp family. Check the invitation of the Lisp conference as a reference. Sure they are, but they're also very clearly outliers and not definitive examples of the family. However, I'm not the one who's intent on splitting hairs regarding what constitutes a Lisp. Your original description of Clojure was "a Lisp-inspired language for Java-Programmers", thank you for taking the time to demolish that silly notion. &gt;Have you ever used a macro assembler? One writes very nice and clean code with those tools. There are also nice assemblers on top of Lisp. You can write very nice and clean code in practically any languages short of brainfuck. &gt;That's what I'm saying. Clojure attracts a lot of people who have no interest in Lisp by not being a real Lisp in the first place. Clearly, you've already adequately demonstrated that Clojure is very much a real Lisp. You can't have it both ways I'm afraid. The problem you appear to have with Clojure is that it runs on the JVM and it has the audacity to use sane and modern name conventions like `first` and `last` instead of archaic terms like `car` and `cdr`. &gt;They pretend to use Lisp, while they actually use a Lisp-like language designed to be compatible with something else. So, given your own definition of Lisp that you spewed above, how is Clojure a Lisp-like languages and not a Lisp? Aside from the fact that you learned CL first, what precisely makes it a "real" Lisp that does not apply to Clojure. 
* S-expression * first class function * general list
I think you will get a very different response from each person. For myself, who started with Lisp after the turn of the century round of dynamic languages, strong metaprogramming (strong in that it is well supported and integrated in the language and, most importantly, commonly used in the community) is the distinguishing characteristic of "a Lisp". To a lesser extent, a distinguishing characteristic is interactive development (in most other languages with a REPL, there comes a time when a programmer will cut the REPL out of the development cycle for whatever reason). Note that both of these have a large social/community component to them. This reflects my opinions about language in general. In many ways, the community behind a language is more important than the language's syntax, runtime support, and whatever technology has been developed to work with it (compilers, IDEs, debuggers, and what-not). I believe you shouldn't talk about one without talking about the other. To drive this home, a Lisp tends to be different because it has a community that is interested in morphing the language in interesting ways and defining new ways to think about problems that exist outside of the current syntax of the language. This is purely social, but one of the characteristics that I associate with a Lisp dialect. Certainly the language itself must foster this kind of culture, but the culture had an integral role in defining the language and the language's common use patterns (especially in Lisp where there is good metaprogramming support). It is the culture itself that I hold dear. There is also a general "feel" of Lisp... s-expressions, the ability to tweak every minutia of the language, the ability to easily explore the inner workings, the ability to express (at least recursive) algorithms elegantly, the brushing of implementation details and quirks under various rugs so the user need not bother herself with them. IMO, these are of less importance, are more nebulous, and are becoming less useful as distinguishing features on a daily basis. Those that people find desirable are being, or have already been, co-opted for new languages.
In my opinion, the most defining features of LISP include roughly in order of importance (a dialect doesn't have to have all): 1. Syntax is based on some form of S-Expression with a little leeway for minor shortcuts (e.g. the code 'foo has the same meaning as (quote foo)), or if there's a richer syntax, such as M-Expressions, there should be a straightforward translation to S-expressions in terms of which the semantics are defined. 2. Everything is an expression. 3. Late binding as a general principle, but 4. Procedures with eager evaluation and call by value. 5. Small set of primitive special forms, such as quote, if, set!/setq, define/defun, and the rest (theoretically) expressible in terms of these through: 6. Syntactic extensions. This doesn't require macros to be definable in (the same) LISP, but generally it will be. For instance, there can be DSL LISPs where you can extend the syntax from the hosting environment (probably a more general purpose LISP) but not from within the DSL itself. 7. Symbols and other primitives, and list structures made of pairs which you operate on directly. 8. Garbage collection. 9. First class procedure values and lexical closures. 10. Dynamic environment for dynamically bound variables. For a practical language you also want more data structures and maybe user defined types, library functions, multiple dispatch, continuations, exceptions etc. but those don't make it more of a LISP in my opinion. The apply procedure was at least initially quite distinct.
Programs consisting of cons cells, symbols, and nil (which may or may not be a symbol). The ability to read, print, and evaluate these.
Preferably in a loop!
How can you have Common Lisp without s-expressions?
Here: http://readable.sourceforge.net/ I'm not trying to say that it is a good idea (personally, I think it's awesome to edit s-expression code). But it's possible.
I'd say the prefix notation fits better than s-exprs or simply facilities enabling homoiconity in an easy way. Since the superficial syntax of s-exprs isn't important, there exists a plenty of isomorphisms as you linked or I've [created](http://www.reddit.com/r/lisp/comments/10lng8/cl2dsyntax_the_cure_for_parenthephobia/).
* [](http://en.wikipedia.org/wiki/Lambda_calculus) * [jmc.lisp](http://lib.store.yahoo.net/lib/paulgraham/jmc.lisp) ; The Lisp defined in McCarthy's 1960 paper, translated into CL. ; Assumes only quote, atom, eq, cons, car, cdr, cond. * [The SKI Combinator Calculus a universal formal system](http://people.cs.uchicago.edu/~odonnell/Teacher/Lectures/Formal_Organization_of_Knowledge/Examples/combinator_calculus/) * [Lazy K](http://homepages.cwi.nl/~tromp/cl/lazy-k.html) 
readable is fine but to me just dropping top-level parens is more than enough to make s-exp unnoticeable.
Yes, they are, because the language comes with them. But you won't be required to use it. Besides, Dylan. 
I tried to figure out if Dylan had s-expressions but I gave up. Besides, I'm not sure Dylan is a Lisp.
Discussion about what is meant by "Lisp" is one of the most pervasive points of derailment in discussions of s-exp based languages, so I try to avoid it by enumerating the languages I am speaking of instead of using that term.
I came here to give this answer, but since you already took it, I'll say: homoiconicism and smugness. :-) 
A language where the syntax describes data structures, and which can either compile or eval those data structures - or both.
Dylan started out with s-expressions in the early 1990s. However, in 1994 or so, the syntax was changed to the current syntax. The original syntax looked like: (define-method canonicalize ((number &lt;ratio&gt;)) (bind (((the-gcd &lt;integer&gt;) (gcd (numerator number) (denominator number)))) (unless (= the-gcd 1) (set! (numerator number) (truncate/ (numerator number) the-gcd)) (set! (denominator number) (truncate/ (denominator number) the-gcd))) (when (negative? (denominator number)) (set! (denominator number) (- (denominator number))) (set! (numerator number) (- (numerator number)))) (if (= (denominator number) 1) (numerator number) number))) In the current syntax, that would be: define method canonicalize (number :: &lt;ratio&gt;) let the-gcd :: &lt;integer&gt; = gcd(numerator(number), denominator(number)); unless (the-gcd = 1) numerator(number) := truncate/(numerator(number), the-gcd); denominator(number) := truncate/(denominator(number), the-gcd); end; when (negative?(denominator(number))) ... end; if (denominator(number) = 1) numerator(number) else number end end; The overall structure remains the same, the fact that everything is an expression remains the same, there is still a macro system, the support for something like "set!" operating on locations remains the same. Functions are first class. I could have written some of it a bit differently which would've removed more parentheses, like any "numerator(number)" could've been written as "number.numerator". Underlying it all are the same set of assumptions: everything is a generic function, even slot accesses. Everything is an object (in the CLOS sense), even primitive types. It is up to the compiler to optimize all of that into efficient code and eliminating boxing and method dispatch where it can. Open Dylan does fine with that sort of optimization. Dylan was designed and implemented by some of the same people that were behind the Common Lisp standardization and major implementations of Common Lisp (some Symbolics people, the CMUCL people, Harlequin, Macintosh Common Lisp people, etc.)
Following this question, I should be happy to get your opinion about the tiny language I am working on in this workshop : http://epsilonwiki.free.fr/alphawiki_2/. - A 10 pages presentation can be found in this link http://epsilonwiki.free.fr/ILC_2014/ILC_20140516.pdf - A shorter one is here: http://epsilonwiki.free.fr/alphawiki_2/index.php?view=syntax_lambdatalk_structure Thank you in advance. Alain Marty
If it's something that you want to go out and use immediately as part of projects, the best are probably Clojure and ECL. Now you might be reading that and thinking to yourself "I can get why you said Clojure, but what gives about ECL? Wouldn't you choose some implementation like SBCL or CCL instead?" The answer is because ECL is the easiest to use within C and C++. It can also compile to standalone executables and libraries. By libraries I don't mean the stuff you download from Quicklisp, I mean honest-to-god .so files (if you're on Linux). It can play in the rest of the world's ecosystem.
Yup. Words.
FYI, SLIME 2.7 (the latest release) is incompatible with this version of SBCL. If you upgrade SBCL, you have to use SLIME from git until the next release.
Clearly there are reasons as we don't see any. Your point could be one cause, it's a fair point.
You have no idea how long I spent scratching my head wondering why I couldn't run slime.
I wasn't a particular fan of this article. I guess my problem is that it's not actually based on anything concrete. It tells a story (possibly a compelling one, depending on where you're coming from), but it doesn't give us any reason to actually believe that story. It also dates itself, as it was written before a lot of work that's been done to bring the lisp ecosystem up to snuff.
I think it is more an about how education system (society?) fails on individuals than about lisp. That is why I downvoted it in spite of liking it.
I don't really understand what the writer is explaining here. Anyone can make an ELI5?
First he shows an example of from the SICP in code and an illustration that represents what the code is doing. Then he proceeds to generate code from an illustration.
did not know this even existed
Just noticed this struct Allocation { struct Pair pair; int mark : 1; struct Allocation *next; }; Using a bit for the mark instead of a byte is probably pointless (because it has to allocate an extra byte anyway), and most likely slower. Other than that, definitely an interesting read. 
The dash.el code for -split-with looks really really ugly.
I noticed this too, but on a 32-bit platform the compiler will add 3 bytes of padding between `mark` and `next`, and 7 bytes on a 64-bit platform.
Following your posts and comments here on reddit, I respect and value this judgment. I am a real beginner, and I would like very much to acquire more discernment in assessing lisp-beauty. Would you give me a few pointers on where and how some lines could be improved? 
The main problem is the use of a macro. I would never write such a functionality as a macro. Debugging the macro is ten times more difficult than a function. The use of anaphoric macros is not necessary at all. It might be that the macro generated code is more efficient, but here it just spoils the code base with a lot complex code. For macros I need to answer: is the generated code correct? is it evaluated in the right order? does it capture variables? Is the generated code readable? does it do error checking of the passed code? Do we have multiple evaluations of passed forms? Is it maintainable? Is the generated code compact? Etc, etc. Implementing basic list functions as macros is bad style. If the anaphoric style makes it necessary, then the anaphoric style is wrong. Additionally given the high level anaphoric macro style, the implementation is low level, non-functional, and on the cons level. But it still needs to reverse a part of the result. Also the naming. Basic Lisp functionality is renamed, already (like !cons). --split-width says it takes a pred (predicate) as the first form, but it doesn't. It needs a form where the predicate is being called. The basic evaluation rules (from left to right) are also not kept for this macro. First the list is evaluated and the first form, the pred form, is evaluated multiple times. The anaphoric macro expands its code into all the user code, where it actually used. If the macro needs to be changed, I need to recompile all calling code, too. The code is this (from [dash.el](https://github.com/magnars/dash.el/blob/master/dash.el)): (defmacro --split-with (pred list) "Anaphoric form of `-split-with'." (declare (debug (form form))) (let ((l (make-symbol "list")) (r (make-symbol "result")) (c (make-symbol "continue"))) `(let ((,l ,list) (,r nil) (,c t)) (while (and ,l ,c) (let ((it (car ,l))) (if (not ,pred) (setq ,c nil) (!cons it ,r) (!cdr ,l)))) (list (nreverse ,r) ,l)))) (defun -split-with (pred list) "Return a list of ((-take-while PRED LIST) (-drop-while PRED LIST)), in no more than one pass through the list." (--split-with (funcall pred it) list)) If you look at it: --split-with (pred list) -split-with (pred list) The calling semantics are very different. The first thing evaluates list first and the pred possibly multiple times. The second evaluates pred and then list and both only once. The first pred is actually anything, but preferably a call to a function. Passing a function does not make sense. The second pred is a function. That's a confusing API. Not a 'modern' API. In user code I can spot the difference by counting the dashes? In Common Lisp I would write the function like this: (defun split-with (pred list) "splits the LIST at the first NIL result of PRED" (list (loop while (and (not (null list)) (funcall pred (first list))) collect (pop list)) list)) Above is a simple function. It uses a macro, too. But that macro is general purpose, high-level and efficient. Since Common Lisp has multiple values, I would return both parts as values: (defun split-with (pred list) "splits the LIST at the first NIL result of PRED" (values (loop while (and (not (null list)) (funcall pred (first list))) collect (pop list)) list)) I could also write some functional building blocks: (defun map-while (predicate function list) (loop with e while (not (null list)) do (setf e (pop list)) while (funcall predicate e) collect (funcall function e))) If I wanted to, I could rewrite MAP-WHILE without using LOOP, but it does not help here. In oldish Lisp it looks like the following code. Note that it does not need to reverse the result or parts of it. (defun map-while (predicate function list &amp;aux e r rt) (do () ((or (null list) (not (funcall predicate (first list)))) r) (setf e (funcall function (pop list))) (if r (setf (rest rt) (list e) rt (rest rt)) (setf r (list e) rt r)))) Now I would TAKE-WHILE write that it returns two values: the elements taken and the rest. (defun take-while (predicate list) (values (map-while predicate (lambda (e) (pop list) e) list) list)) Then the original split-with is simply the list of the results. (defun split-with (predicate list) (multiple-value-list (take-while predicate list))) Generally the dash.el implementation and API looks like a nightmare. Despite being advertised as a 'modern' list API for Emacs. With no 'cl required. :-( Too many possibly buggy macros. Not functional enough.
Wasnt it kind of irresponsible releasing a major Lisp ecosystem component which is incompatible with another major ecosystem component? Thats like Microsoft releasing a version of their compiler incompatible with the current version of Visual Studio.
Since most people often emphasize that Lisp code is basically a flattened version of the [AST](http://en.wikipedia.org/wiki/Abstract_syntax_tree), I wonder if there is a GUI tool that would let me work with actual trees and would flatten the trees to Lisp code. Paredit, for example, is such a high-level editing tool that it does let you tinker with the tree structure of your code, although it is still text that you are editing. Why not just work in the tree if S-expressions and trees are so isomorphic?
For a more advanced version of that: http://repmus.ircam.fr/_media/openmusic/omprisma.png Generally structure editors for Lisp code have been tried, but have not been that successful.
subtext is one instance of tree source http://www.subtext-lang.org/demo1.html
It's a little annoying, and a little inconvenient, but I think "irresponsible" is too strong a word. SBCL publishes releases every month. So does SLIME. There is, at most, a month's window of incompatibility in this sort of situation. Furthermore, SBCL and SLIME updates aren't feature-based, so there is usually little incentive to keep on the bleeding edge of both. If SLIME doesn't work in SBCL 1.2.1, just stick with 1.2.0 for a few weeks. SBCL and SLIME are maintained by separate groups of volunteers. It's not much like Microsoft at all.
what do you mean by "understanding"?
&gt; Why not just work in the tree if S-expressions and trees are so isomorphic? I think it's because for a while now there's been a general feeling that source code should be plain text, plus the fact that anybody who cooks up a tree-based display saddles it with a pretty poor layout. Seriously, I think visual design is the big obstacle. We want the tree structure to be distinct, but we don't want to lose much screen space or make something really ugly, and satisfying all three at once isn't necessarily easy.
new control structures (case, dolist, dotimes, ...), defining forms (defclass, defmethod, defun, ...), code rewriting (with-accessors, ...), evaluation control (AND, OR, ...), sublanguages (LOOP, ...).
macros
Thanks for the concise list.
Most notably: continuation, tail recursion, and garbage collection
Randomly clicked on the Arrays entry and got bad advice: "The function make-array makes an array. The aref function accesses its elements. All elements of an array are initially set to nil." Reality: "If initial-element is not supplied, the consequences of later reading an uninitialized element of new-array are undefined" Not promising. Plus it's really ugly and old.
"LISP represents a string as a variable-length array of characters." hmm...
I've been thinking about wanting some tutorials in this same sort of vein: a sort of "how is LISP different?" guide -- covering things like macros, user-defined data structures, closures, &amp; anonymous functions -- ideas that have been transferred into other languages, but don't actually follow the (full) LISP model. I've only written one for [error recovery](https://docs.google.com/document/d/1Gmc98gf5PVXYEPWglnebBaeqkDbLIElyP1vAPxjbIZc) so far, and I think this sort of broken tutorial might be a good place to look for other things that people struggle to understand. [If you read the linked document: I'm fully aware my example code does not follow normal LISP style. If I were to write this entire series, the final chapter would be a style guide, and my examples there would just be pointing out the places where I deliberately violated them in order to emphasize the differences in LISP, then showing the proper styled code.]
All in all, entirely valid points, but there are still two that I would say are worthy of explaining my choice: &gt; Recursion vs. Iteration I wanted my example function to be something short and familiar so that any readers not familiar with reading Lisp code can easily understand the example. However, I also needed something with sufficient complexity that readers can verify that errors do not unwind the call stack, and restarts have access to the full variable scope where declared (even if called from another scope). Between those factors and the fact that the common recommended Lisp compilers [perform TCO](http://0branch.com/notes/tco-cl.html) to some extent, I felt recursion was the better choice for this use. &gt; Integer type declarations and CHECK-TYPE would be better If I were to work this idea into a full book, type inheritance/inference with Lisp is the sort of topic that could easily be a chapter unto itself (and given the usual confusion of weak typing and dynamic typing languages, probably should be early). However, as this was the first example I was writing, I decided that (in part because the error being caught was a type error) emphasis on the error handling should override using the standard forms for catching this sort of error. Finally: &gt; It's Lisp nowadays, not LISP. You don't think that for this sort of discussion of Lisp for non-Lisp programmers, that we shouldn't acknowledge the mock acronyms of "Loads of Irritating Superfluous Parentheses" in some fashion? ;)
I don't know if that makes sense. Even if saving memory were relevant, you're requesting an int. You'd have to have used a char so it only takes up 8 bits. You can verify with a simple program: #include &lt;stdio.h&gt; struct padded { int foo :1; }; int main () { printf("%d", sizeof(struct padded)); return 0; } This will print whatever `sizeof(int)` is, since that's what the struct is defined as. However, just defininf `mark` as `char` doesn't work, since the compiler will usually pad structs because unaligned access is slow, and in some architectures impossible. You can reorder your fields, though: struct Allocation { struct Pair pair; struct Allocation *next; char mark : 1; }; And now you have the benefit of the smaller struct... And yet, you still gain nothing because, either: 1. You allocate each Allocation independently: malloc will return word-aligned blocks. You'll have 3-byte gaps anyway. 2. You allocate a chunk of sizeof*n. Either your platform allows unaligned (and slow!) access, or your program doesn't run.
&gt; you still gain nothing because ... You gain clarity of intent.
You've made your intent explicit with the bitfield indication. Using a char to request less space makes your struct harder to optimize.
Yes, I meant in general. Using `:1` you gain clarity of intent even if you don't gain any space.
Wow, this is an excellent and thorough response. I really appreciate that you took the time to write it.
Here you are: https://github.com/pnathan/generic-comparability But I agree that the CDR is sadly underused. The aproach is perhaps too minimal. I think the requirement for a reference implementation would help the adoption of the CDRs. Perhaps we only need a standard place with links to existing implementations. There is a page on CLIKI that could be used for this purpose: http://www.cliki.net/CDR. 
Another one: https://github.com/csziacobus/equals
That's the one I wrote yesterday myself after failing to find anything :)
Hah! I wondered if the usernames a similar enough to indicate that.
C discovered `bool`eans in 1999.
I think most people ignore the CDR. It is a process without a product. I'm not sure what it would take to make it more useful. (Hours-long meetings have been held at lisp conferences to try to answer that question.) While not perfect, actual libraries are incredibly helpful. closer-mop, cffi, usocket, bordeaux-threads, and more -- these are what make it easier to write programs. 
I loved/hated the article. 
Heh, my error, I was thinking this was C++ (since it has all those visual studio related files in the repository)... -_-'
[here](https://gist.github.com/jaeschliman/0e2aad17b7d021e40d37#file-struct-equal-lisp)'s a `struct-equal` function for sbcl and ccl. It's basically just the innards of the structure-object clauses of their equalp functions.
I think defining a generic function protocol that is specialized by code you load later is good. You don't have to do in-package tricks, though; you can have something like this: (defmethod output:output ((target (eql :tex)) document) ...) I'm not sure the best way to have plugins loaded later automatically, though. I shy away from code that calls LOAD or ASDF:LOAD-SYSTEM or QL:QUICKLOAD at runtime. I do all that stuff from the REPL.
I did something similar for my static blogware, [coleslaw][coleslaw]. There is a `render-text` generic function with additional methods defined in plugin files (e.g [ReStructuredText support][rst-plugin]). Here's the code that [loads the plugins][load-plugins]. Coleslaw's [Plugin API docs][plugin-api] may prove interesting too. I've seen questions about how to do plugins in Lisp several times and I have to say, the above system has worked well for me. That said, it does have limitations, primarily that there is no facility for unloading plugins. This isn't a big problem for a static site generator, you don't usually want to change plugins *during* a build. Andy Hefner wrote an [interesting article][ahefner] about a way to implement plugins with mixin classes and released a corresponding library, piddling-plugins. That may also be worth looking into if you need to load and unload plugins or just want to see a different approach. [ahefner]: http://ahefner.livejournal.com/19770.html [coleslaw]: https://github.com/redline6561/coleslaw [rst-plugin]: https://github.com/redline6561/coleslaw/blob/master/plugins/rst.lisp [load-plugins]: https://github.com/redline6561/coleslaw/blob/master/src/config.lisp#L37 [plugin-api]: https://github.com/redline6561/coleslaw/blob/master/docs/plugin-api.md
If you're on Windows, you could try out the free editions of LispWorks or Framz's AllegroCL http://www.lispworks.com/downloads/ http://franz.com/downloads/clp/survey The free editions also run on other platforms, but I'm note sure if the IDE is included. There's also CUSP and Dandelion for running CL under Eclipse, but I don't know much about them.
&gt; emacs is just too much for what I need at the moment. By this, do you mean that Emacs has too many features? Or that there is too much additional 'learning effort' for your needs? The reason Emacs gets a lot of praise by lisp developers is partly its ability to connect with a running lisp process to enable interactive development and debugging. Asides from that, if you only want a text editor then any programming editor with syntax highlighting and paren-balancing should do. Are you specifically wishing to use Common Lisp? If not, perhaps you could try Light Table as a Clojure IDE? http://www.lighttable.com/ or perhaps PLT Racket as a Scheme IDE? http://racket-lang.org/
I'm just learning lisp atm. I'd rather not learn lisp while learning emacs. That's really it. I've tinkered with emacs but if I start learning it I know I'll stop reading my lisp book and start reading emacs 'power user' guides.
Which book are you reading?
Thanks for the `output:output` tip, I didn't think about it :). I'm not a fan of calling `load` either--that's what made me ask the question in the first place. Any suggestions on how to avoid `load` and still be able to load code dynamically?
I'll have a look at coleslaw, thanks for sharing :).
I'm using Emacs &amp; SLIME for Common Lisp development usually, so I don't really recommend it, but perhaps you could use Sublime Text with [SublimeREPL](https://github.com/wuub/SublimeREPL). Actually, its original version is hard to use for Lisp development because it doesn't respect which package you are in when C-c C-c. However, I made some changes for that function. https://github.com/fukamachi/SublimeREPL/tree/sender-for-common-lisp (I [sent a pull request 5 months ago](https://github.com/wuub/SublimeREPL/pull/332), but it's not merged yet) Although it still lacks some features that SLIME has, for instance CL debugger integration, the experience would be similar to Emacs/SLIME.
You could use emacs with a mouse and all the menus/toolbars enabled.
I'm quite happy with tmux and https://github.com/jpalardy/vim-slime. Especially in combination with http://www.reddit.com/r/vim/comments/22ixkq/navigate_around_vim_and_tmux_panes_painlessly/cgnnnai?context=2.
DrRacket
I think... without emacs and slime... the bast tool for lisp are...PENCIL and PAPER.
Yeah, and you can hire your little brother to hold a **(scan-error "Unbalanced parentheses")** sign. 
Use :dont-close t in start-swank.lisp, it won't launch another server. Yeah and it never "died" for me. Works just fine. 
Land of lisp
What do you want? You could just use a text editor you already know and run code in a terminal window. I use Vim and slimv and it works really well.
Considering that book is targeted towards Common Lisp I would agree with [lisphacker's suggestion](http://www.reddit.com/r/lisp/comments/2a8lpc/besides_emacs_and_slime_what_would_you_reccomend/cisjf7g) to either get the free version of LispWorks, or AllegroCL if on Windows or Linux. If you're on Mac, I would prefer [Fisch003's suggestion](http://www.reddit.com/r/lisp/comments/2a8lpc/besides_emacs_and_slime_what_would_you_reccomend/ciskg1j) to get ClozureCL's IDE from the Mac App Store. Good Luck, and hope you enjoy learning Lisp!
Also: LoL tells you to use CLISP, but if I recall correctly, the only chapters that actually rely on it being CLISP are the sockets and HTTP ones, and the socket code is easily translated to either usocket or whatever implementation's native functions.
 Since Lisp has first-class functions, why don't you have the plugin just call a "register-plugin" function with the output function itself? That way you can just take the registered function (or a list of them) and call it with your output without having to worry about having the runtime figure out what you want to do. For example, in Clojure: ;; plugin-system.clj (ns plugin-system) (def plugins (atom '()) (defn register-plugin [plugin] (swap! plugins conj plugin)) (defn exec-plugins! [input] (doseq [plugin @plugins] (plugin input))) ;; my-plugin.clj (ns my-plugin) (require [plugin-system :as plug]) (plug/register-plugin my-plugin-fn) 
Clozure's IDE is the venerable Hemlock. I used it on MCL in 1996. It's got a bunch of problems, but by *far* the biggest annoyance for me is that it doesn't scroll to the site of changes being made when undoing or redoing. I know that sounds small but it's a huge problem for development.
Also, if you really don't want to learn emacs keybindings, you could enable CUA mode. Don't recommend it though. I've never tried it with slime, but I seem to recall someone mentioning that it doesn't quite play nice out of the box. 
For Windows users who are pretty new to programming, I've recommended Notepad++ for editing (acceptable syntax highlighting, paren matching, &amp; indentation) and Clisp (for the Readline enhanced REPL) to work through Practical Common Lisp.
Iirc SublimeText has a rainbow parens plugin
I just read the chapters that are already written and they are great! That's the first book on Lisp that felt really nice to read. I think it is something worth to keep an eye on. PS: check the author's github [here](https://github.com/thephoeron)
You're right. FAQ corrected.
Do you mean the Common Lisp Cookbook? That was a good project. I wouldn't mind doing something similar---and certainly the book would be much better for it; might be a problem down the road though, if I ever want to put it in print. I mostly just put the whole thing up on GitHub for transparency's sake.
That's a viable solution, indeed. Thanks for the code sample.
You are right although Racket goes as far making cons cells immutable. You have to use mcons in order to set! (!)
Very nice. Can't wait to read all the chapters. Thanks!
The layout is certainly very attractive and accessible. While I'm fairly new to Lisp, the book Land of Lisp seemed like a fun way to learn. You don't like that one?
&gt; You are right although Racket goes as far making cons cells immutable. Which isn't very far at all.
PCL wasn't nice to read ? :O
any plans for an epub/mobi version? I know some people uses leanpub to sell the formatted ebooks while keeping a free version available for browsers.
The phrase government contracts are the holy grail of software development was laughable. 
It was, but this looks more promising, IMO. But PCL is great anyways.
I've read Land of Lisp, PCL and getting through SICP now. They are all great and entertaining books. But there's something about the way that [/u/thephoeron](http://www.reddit.com/user/thephoeron) writes that makes it feel sort of "magical". Not sure how to explain it.
Sorry ): Didn't mean to cause you any disturbances. But I must say that your book looks very promising. I like the way you write. It's... passionate. That's the word. You write with passion about Lisp and that's what makes it so awesome. It's the same feeling I get when going through SICP. 
If I could make some suggestions: Provide multiple solutions to your exercises and explain the difference in each approach Don't be afraid of teaching aspects of computer science that aren't necessarily specific to lisp. For instance, it would be cool to first define an array, then a hash, and then a list, and this automatically explains pointers in a practical way. Paul Graham had it right in emphasizing recursive algorithms to iterative. Recursion is much more interesting, and once you understand it, understanding iteration is trivial. A lot of people who will read your site are bored with codeacadmy and all the other teach yourself how to code places. I would examine what their approach is and take a different one. I would say that explaining prefix notation can be done in 1 line and doesn't need a whole page to do, though that is up to you. One sentence for what it is and one sentence for why it's more efficient is enough imo. WIsh I new enough lisp to contribute
When I was doing exercises in PG's ansi cl, I would come up with a solution and then look online for what other people came up with, and everyone's answer to each question was different. For instance, writing a function that returns the fibonacci sequence recursively is not as straight forward as it sounds, especially for a beginner, while writing an iterative solution was actually more straight forward and simpler (at least to me). Let's say your goal is to figure out optimal solutions to things, not a bad definiton of "good programmer," right, so the most obvious way to do this is to look at all different approaches to a solution and learn from that. Somebody who is attempting to learn Lisp would be thinking htis way, whereas someone who enjoys learning jquery from codeacademy would be thinking, how do I learn to program something asap, which would be the fastest, though least diligent way to learn.
To save memory and get better performance he needs to steal the mark bit from the struct Allocation *next. Such pointers are always aligned to steal a few bits.
I have no idea what the holy grail of it is, but government is not it. Government IT is not about programming its about the process. You will probably work for a contractor. You will be on a team. Most of the people on the teams will be ,devoted to compliance with government regulations. Your company will have to be CMMI / ISO / lean six sigma compliant have produce reams of paper work proving that they are so overwhelmed that it will take weeks to get a change done Your job will involved dealing with various political enties. They will all hate each other. The infighting will be amazing. You will have no control over your work because changes will have to be approved by a contracting officer. (ko) This person will be impossible to talk to so you have to talk to a cor who whill have no power. The most important thing you will do is fill out time sheets. You will probably use deltek (a shitty piece of software) to fill your hours. Your company will be obsesed over them and on time sheet day you have 3 reminders to turn them in. Government IT is not about making things or doing things. Its about following the rules even if they lead you off a cliff. Its great if you want to make money. Its bad if you want to accomplish something like make a usefull program. 
It's on fire! :-(
Not sure this is possible or easy, but have you considered getting ECL through emscripten?
The site is back up now... looks like another big traffic spike in the middle of the night (my time) led my webhost to kill the process. It was using over a gig of memory! Which is messed up, because with 400 active users it was only using max 270mb RAM...
It's cool :) the response has been overwhelmingly positive, despite it being such an early draft and still having some glaring mistakes. It was really nice to get Zed Shaw's feedback on Hacker News too.
The reddit hug of death :-)
There's government contracts and there's government contracts. Some agencies want cutting edge stuff and understand that researchers need space and time to create, or deal with companies that have this understanding. An example is Richard Gabriel's work over the last few years: http://medias.ircam.fr/x03b42f
There is also the use of external commands to create maps for Grand Theft Wumpus (I think that is the right name). Which runs graphviz. I think that is CLISP specific.
Have you thought about using EMACS with VIP or VIPER, that way you leverage your experience with VIM and still be in EMACS with the full power of SLIME.
I have been a Lisper for a couple of years now, and never payed any attention to the CDR, even if I heard of it in passing. I went into the link for the first time after reading this post, and I find that is a nice idea, it could help with standardization and communication. I mean if I implement a CDR, I could, in the repository say this is an implementation of CDR x, with the following considerations (if any) and provide a link. Another useful thing would be to have a search engine tied to it, which will allow me to find libraries that implement particular features described in CDRs, or find if there is a CDR which describes something I am trying to implement, and even have CDRs tied somehow to quicklisp. However it will take time to make everybody CDR aware, and also it will need a push to have people write CDRs for whatever functionality is been added. I see just a few, but I know things like pattern matching, FFI, and external executables, and other things that are implementation specific and deserve a common interface, would be good candidates for CDRs. 
Oh, right, I'd forgotten about that. I think I just ran those by hand when I went through the book.
I'm registered. Hope to see you there!
Would someone new to lisp be able to glean anything from this conference? I considered going but I'm not sure I know lisp well enough to benefit from attending.
In my experience, the talks can be hit or miss. This year's schedule sounds pretty good. When I first started going to Lisp conferences, the most fun part was meeting, face to face, people I had talked with only online. I learned about new projects and met people who rarely post online but who have lots of interesting stuff to say in person. It also helped cure me of the impression that the only Lisp community is a bunch of people writing open source libraries for SBCL. The conferences attract people who do a lot of different Lisp stuff: for industry, for research, for school, for fun. They aren't always answering questions on StackOverflow or reddit, or posting libraries and applications to github. Lisp people do a lot more than just that, and they don't always get a good chance to talk to each other outside of conferences like ILC.
How old is it? 
I didnt watch the whole video, so I know nothing about the hardware. I found this searching for specs actually.
I used this to implement several real-life applications! Nice complete API for dealing with all the PalmOS stuff so I could easily use standard PalmOS widgets, databases, etc.
Registered!
Most lisps have more than just s-expressions and quoted lists to offer. For instance, in Common Lisp, I would write: (make-query-url 'person :first-name "Bob" :last-name "Smith") Each lisp (Common Lisp, Clojure, Racket, Elisp) has its own style, though. You might look at examples of actual lisp code to see how they solve common problems.
How would I go about writing a function to parse (= name Bob)? Or would it be easier to create a function called something like fieldEquals? 
The "lots of small functions" version is usually easier to expand, because you can start with (build-query-string (query-equal 'name "John")) and in the future expand to (build-query-string (query-greater-than 'age 18) (query-omit-field 'location)) (Using packages you can avoid that ugly repetition and say `(q::omit-field ...)`). Additionally, users of your code don't depend on you making `build-query-string` general enough; they can just define their own `query-so-and-so` methods. Besides, if it feels "repetitive" to write the small functions, you can always use more functions, or even macros. E.g.: (defun query-equal (field value) (query-build-string field "=" value)) or (def-query-method query-equal "=")
You don't replace mappings in the symbol table - you store mappings in a separate hash-table: (defconstant +query-operators+ (make-hash-table)) (defun equal-query-op (var arg) (format nil "~a=~a" var arg)) (defun not-equal-query-op (var arg) (format nil "~a~!=~a" var arg)) (setf (gethash '= +query-operators+) #'equal-query-op) (setf (gethash '!= +query-operators+) #'not-equal-query-op) Then, you just need a function that takes a list with a query operator as the first element and returns the parameter string: (defun query-param (qexp) (let ((op (first qexp)) (op-args (rest qexp))) (apply (gethash op +query-operators+) op-args))) And just map this method over the list: (mapcar #'query-param '((= first.name bob) (!= last.name jones))) Which will yield a list of strings: ("first.name=bob" "last.name!=jones") Which can be concatenated with FORMAT: (format nil "~{~a~^&amp;~}" (mapcar #'query-param '((= first.name bob) (!= last.name jones)))) Which gives: "first.name=bob&amp;last.name!=jones" ----------------------- **EDIT**: fixed bugs (thanks, /u/spacebat)
I wrote [an Emacs tutorial for beginners](http://tuhdo.github.io/emacs-tutor.html) that might help you to be comfortable with Emacs in a week. Learning Emacs is a fun experience. The article also contains GIF screenshots to demonstrate what Emacs is capable of, and Emacs worth your time to take it serious. Emacs also has many powerful package, [like this one](http://tuhdo.github.io/helm-intro.html#sec-17).
A type checker  la core.typed for clojure or typed/racket would be welcome.
Oh dear. Quite right. (It's been about 5 years since I used CL.) It should have been: (setf (gethash '= +query-operators+) #'equal-query-op) *EDIT*: fixed
I thought I didn't but I do! Behold [SKU Thingy](http://quadium.net/code/skus/). Side note: Be warned that page is full of my seething resentment at having been stuck in not just any retail but dead-end retail after the *last* recession dropped the bottom out of my first full-time professional coding gig and also the businesses that would have bought stuff from that store at the time. Nowadays I'd handle it differently: I'd like to think it would be less dead-end due to more flexibility and I certainly wouldn't name names. I'm glad I was able to take the opportunity to keep practicing my craft though. I also made another application to capture and track inventory "in the back" (sorry /r/talesfromretail but I have to admit there's more stuff back there) and generate quick-lookup sheets. That stored information in PalmOS databases which I synced to my laptop; I believe writing some code against pilot-link to extract it. Then I had some Common Lisp code which generated the output. Can't remember whether it emitted PostScript which I converted using ps2pdf or used cl-pdf directly. That was fun because I got to play with pagination and related things.
It looks like the TI Explorer UI, did UNISYS have a TI or LMI license?
30:15 META CONTROL META CONTROL rrrrrrubout!
Generally, you want to break up your problem into a series of steps. You want to start thinking in terms of data transformations. You have some initial data and you want to run through a series of transformations to get a new piece of data. I'll use Clojure for your url encoding example. Our data might consist of a base url string followed by the parameter. So, we could create a function that takes a variable number of arguments. We know that the base url is required and parameters can be optional, so we could write it as follows. (defn to-url [base &amp; params] ...) Then we can encode each parameter, join the encoded parameters using "&amp;" and concatenate them into the base url: (defn param-&gt;str [[type id value]] (str id (get {= "=" not= "!="} type) value)) (defn to-url [base &amp; params] (if (not-empty params) (-&gt;&gt; params (map param-&gt;str) (clojure.string/join "&amp;") (str base "?")) base)) (to-url "http://website.com/person/" [= :name.first "Bob"] [not= :name.last "Smith"]) =&gt;"http://website.com/person/?name.first=Bob&amp;name.last!=Smith" 
Anyone have a direct PDF link for this?
You can download it directly from the site, without registration
The interface is screwed on my phone, I want to just wget it for later.
thank you. I've been spending significant hacking time on mozilla rust lately, but as I wrap my project there up, I plan to return to CL and push my CDR implementations out to Quicklisp when I can.
I personally have implemented 2ish of the CDR proposals, and want to move forward with them in a few months to get them into QuickLisp. I don't think that we're well-served by having the proposals out there hanging. 
https://pdf.yt/d/e0zOI5ZcGrSpSLxH/download this is the link
Thank you
When I copy that code into slime and run it, it works fine. But when I use M-x eval:buffer, it tells me that defconstant's function definition is void.
eval-buffer is an EmacsLisp command.
ecl does that fairly well.
https://groups.google.com/forum/#!topic/comp.lang.lisp/Bj8Hx6mZEYI%5B1-25-false%5D [edit] Just noticed that that thread was started by Ron Garret. Is it me or did he start a lot of the flamewars on c.l.l?
There are a couple pretty cool projects among the non winners like [interactive org-mode] (http://lispinsummerprojects.org/static/summer/240927.pdf) built on top of picolisp. 
PDFy owner here. Sorry for that - there are known issues with mobile display. I'm currently waiting for a testing unit to arrive (I don't actually have a smartphone myself), and once that happens I'll be fixing the mobile display properly.
Nice, didn't know about https://github.com/rpav/cl-autowrap. Will check this out the next time I do bindings. I have a copy-paste project and a few scripts I use to do automatic binding generation (a lot of which I got from [the clipmunk bindings](https://github.com/fred-o/clipmunk)) but it still takes a good amount of finagling for each new project.
Thanks for this article! It really hits home when comparing with lisp.
Did this post get deleted from /r/programming? It had over 70 upvotes I believe.
It's still there, although a bit buried http://www.reddit.com/r/programming/comments/2b7yt2/a_lispers_first_impression_of_julia/
A few months ago I gave [my own Lisper perspective](http://nullprogram.com/blog/2014/03/06/) ([posted here](http://www.reddit.com/r/Julia/comments/2052cc/the_null_program_blog_assesses_julia/)). As you touched in in your article, I think one of the biggest mistakes of CL was making generic functions a special case of functions rather than having all functions generic as they are in Julia, so that was something I was excited to see. My biggest criticism of Julia was that it will never have an interactive environment like SLIME. It requires restarting too much, such as for redefining parts of module or redefining classes. 
Why do you say it will never be interactive? I thought that was a possibility given the use of LLVM and its JIT facilities...
It's not a technical limitation, just a design/language limitation. You can't redefine a function in a module without reloading the entire module, including any classes it defines. It means you're going to have to stop and restart the system a lot during development. In contrast, CL has `in-package` to jump around packages and redefine practically anything at any time while keeping the whole system running.
No streaming and likely no video or audio after, either.
Nope.
Damn.
I always love hand wavy "just because" feel of these kinds of things.
Damn, eight years ago, and he's still not wrong.
Lovely quote: &gt; Why does this exist? I wanted to write an interpreter and was stuck on a Windows XP laptop without Internet.
I think there is a big difference between government-supported research, defense acquisition contracts, and government IT contracts.
I use emacs with evil-mode (which is a reimplementation of vim in emacs). The only big thing you need to know that is emacs specific is to use C-g if you get stuck in an emacs or slime command and want to cancel (instead of escape like in vim). I don't know if sublime text has a non-broken lisp indentation mode. Vim is the only non-emacs one I've run into that isn't 100% broken, and it's still inferior to slime. If it does, then you can just use a text-editor to write code, and then ASDF load it into your repl in emacs/slime. Prior to evil-mode existing, I did something similar to that with vim.
CFFI extends asdf to grovel header-files and generate lisp code from that. Far really took it in the direction of more than just loading code into images (which makes sense, considering his work on xcvb).
This looks rather nice. I considered doing something like this coupled with a custom (S-expression-based, of course) markup language, but eventually decided to go for plain on XML and XSLT. It just werks.
I was looking at writing a generator a few weeks back. Thanks for sharing I'll take a look at this instead. 
While I wrote this from the perspective of the current Dylan streams library, much of the same things apply to the implementation of streams that I've seen in Common Lisp.
Digressing, that [Goo](http://googoogaga.github.io/) (from https://lists.opendylan.org/pipermail/hackers/2014-April/007032.html) language seems pretty fun. 
If you just have a real problem to solve, use whatever tool that is fit for the job &amp; you know well, e.g. Python in your case. If otherwise your desire is to to learn lisp, I'd say a good introduction to CLOS is chapters 16 and 17 of [Practical Common Lisp](http://www.gigamonkeys.com/book/), or better yet read the whole book :) BTW, not sure how the CSV file is relevant to the question
Yes you can store the substation data in a struct (defstruct) or CLOS object; and reference using hash tables, which should be faster than assoc lists (unless you have a tiny amount of data). edit: stick to Common Lisp or scheme, it will be easier to get answers to any questions that come up
Touretsky is very clear but quite basic and a bit slow and boring IMHO. Generally, in Lisp you can do almost anything with just lists, so they are a good tool for simple prototyping and experimenting, but beyond that it's usually better to use more specific constructs. For sequences, you have lists and arrays. For mapping keys to values: association lists (alists) or property lists (plists) are easy but slow; hash tables are the most general and scalable solution. For structures, generally use CLOS classes; structs are more limited and in practice are only used for very simple situations or for some speed optimizations.
Thanks for the heads up! I'd never heard of plists before. I suppose I should use CLOS classes and access via hash tables?
Property lists are basically just another way to use lists to map key-value pairs. The book mentioned above explains them too. However, mostly you can use hash tables and forget about these things.
Cool! Thanks.
I've tried those ways. Copying is the FotM for me right now, but my Lisp methodologies are always changing.
I have ~/src/lisp as a tree in my ASDF registry. [edit] This is from before ASDF had a default search tree. ~/common-lisp and ~/.local/share/common-lisp/source would be better choices now.
Nah, I put my own projects in c:/lisp or ~/lisp. Long directory paths are annoying.
Common Lisp's setf also works like this.
You can also change or extend `ql:*local-project-directories*`, but it's not documented.
The common advice here is to use classes and hash-tables. They are certainly the more robust and scalable data structures. To me this is *premature optimization*. Lists, association lists, property lists and structures have advantages during development. They are easier to debug, visualize, print, manipulate, and enter by hand. Lists have tons of built-in functions. Defstruct automatically creates constructor, copy and slot-accessor functions. My advice would be to prototype using assoc lists and structures using small amounts of data. Concentrate on your algorithm/process first, worry about data structures later. Then when moving to real world data, refactor your code if necessary to use classes and hash tables.
What is the lifespan of your application? Those electrical substations will be operational at least 15 years. Therefore the pulled data should support unicode, be storable into version control system and be parseable by configuration tools that might not exists yet. I am not sure whether CVS as external format has enough staying power.
I also found out that it is sufficient to simply link the project directories in quicklisp/local-projects.
GOO is basically just a tiny version of infix Dylan with some slight syntactic changes, such as argument|&lt;class&gt; instead of the Lisp-style (argument &lt;class&gt;) and a bunch for Unix-style abbreviation that makes code harder to read. (Using dc instead of define-class is not a win.) A full Dylan that goes back to the prefix/Lisp styleand which restores some of the dynamism that was pulled out before the syntax changewould be much nicer. The Pascal-style syntax was just created to placate a bunch of people who were never going to use the it anyway. I never understood why it outlived the 1990s.
Awesome. I'd love to see more Arc in this subreddit. I'm a huge fan.
FYI. The (incompatible) change in backquote implementation in 1.2.2 may affect code that non-portably relies on internals of backquote expr. Let over Lambda's defmacro! as written in the book will break as it's non-portable -- expects to find bang symbols in flatten of a body which is (normally) backquote expr. Still I wonder if the use of *struct* sb-impl::comma is really necessary in implementation, instead of list of some sort. (setf *print-pretty* nil) (print '`(x ,y)) # (SB-INT:QUASIQUOTE (X #S(SB-IMPL::COMMA :EXPR Y :KIND 0))) 
The quick fix of defmacro! for sbcl is to use pseudo-flatten instead of flatten that also descends into sb-impl::comma-expr of sb-impl::comma.
Does anyone know what the thinking behind the change was? What improvement did the author think about?
Simpler implementation (including rewrites to minimise runtime consing) and more robust pretty printing. I give priority to normal standard compliant code over implementation dependent hacks that kind of work most of the time.
But why structs? Couldn't `#S(SB-IMPL::COMMA :EXPR ... :KIND ...)` be represented just as well with `(SB-IMPL::COMMA :EXPR ... :KIND ...)`? What's the purpose of representing code with structs where regular conses suffice? I think I understand the non-portable assumptions in existing code, but it seems to me that *any* non-implementation-supplied code walker is fucked now. What happens when a backquote is encountered? Implementations often provide their own code-walkers, but still some people try to write portable ones, such as in the ITERATE macro. Is ITERATE fucked?
Thank you kindly for the explanation. I appreciate that.
&gt;&gt; How can you tell the difference between a normal argument to a macro (e.g., LET) and a backquote cons when pretty printing? &gt; Because one says `(LET ...)` and the other says `(SB-INT:QUASIQUOTE ...)` And then one gets into cases like `(let ,x foo bar) Is that a LET form with a funky binding list, or an unquote? I feel like I have a decent grasp of the (not fully working) hoops SBCL used to jump through to pretty print backquoted forms decently. &gt; I was asking what happens when a code walker encounters a backquote. And I replied: "It [the backquote] is expanded like any other macro." Iterate works as well as it ever did. What stopped working are macroexpansion-oblivious hacks.
`#S(SB-INT:QUASIQUOTE ...)` and `(SB-INT:QUASIQUOTE ...)` contain the same information. The code that handles each can accomplish the same thing. Are you saying that is not the case?
The transcript I pasted shows that what has changed is the representation of unquote, unquote-splicing, etc. inside quasiquotations. Quasiquote is still a regular macro.
I don't see how this answers my question. It doesn't matter whether quasiquote is a macro or not. If it can't be a macro, then it won't be implemented as a macro. In any case it's a detail of the implementation.
I made the mistake of being too specific, choosing a bad example of SB-INT:QUASIQUOTE. Given code filled with #S(FOO ...) and #S(BAR ...) along with code to pretty print it, I can write another pretty printer that handles code filled with (FOO ...) and (BAR ...) that accomplishes the exact same result, right? Who cares whether QUASIQUOTE happens to be a macro or not? I'm talking about how something can be implemented, not the particulars of SBCL. I don't see any reason for the structs. Is it to preserve the macroness of QUASIQUOTE? If so, why must QUASIQUOTE be a macro?
Unquote, unquote-splicing and other syntactic elements interpreted by the quasiquote macro are structs to make it easier to pretty-print them usefully. Again, how do you tell the difference between `(let ,x ...) and any other let binding? Ideally, you want (let ((foo x)) ...) to pretty print as such, even if there is a hook for `(foo ...)`. However, you want (let (,x ,@y) ...) and not `(let ((sb-impl::backq-comma x) (sb-impl::back-at y)) ...)`. To achieve this, you end up adding heuristics to the LET pretty printer ("a variable named SB-IMPL::BACKQ-COMMA? seems unlikely."), then the same for the pretty printing function of every macro that treats some arguments specially (i.e., almost all of them). The issue here isn't "How to pretty print the leading backquote," but how to pretty print unquote, unquote splicing, etc. that occur at an arbitrary depth inside the backquoted form. The reason I keep telling you that quasiquote is still a macro is that expanding macros is what codewalkers do. What's the effect of the new representation on iterate? None: iterate expands the quasiquote macro like it always has. After macroexpansion, the structs are gone (unless they're inserted/protected by another level of quasiquotation that will itself be [eventually] expanded).
Ok everyone, stop everything right there, I found the crux of the issue: We couldn't possibly be having this discussion if backquote was a macro, which conceptually, it might as well be. If backquote was a macro instead of a reader-macro, there's no way SBCL could hide user-supplied code inside implementation-dependent objects BEFORE macroexpansion. That's the crux of the issue. SBCL has broken the decades-long social contract that backquote conceptually expands to, at worst, a macro call. `(foo ,my-code) == (backquote (impl-dependent-junk (unquote my-code))) How is SBCL going to hide MY-CODE from me, now? It can't, because BACKQUOTE, being a macro, can't possibly manipulate its unevaluated arguments before it (BACKQUOTE) is macroexpanded.
This thread has been linked to from elsewhere on reddit. - [/r/dylanlang] [Function Types for Dylan2016](http://np.reddit.com/r/dylanlang/comments/2cawif/function_types_for_dylan2016/) *^If ^you ^follow ^any ^of ^the ^above ^links, ^respect ^the ^rules ^of ^reddit ^and ^don't ^vote ^or ^comment. ^Questions? ^Abuse? [^Message ^me ^here.](http://www.reddit.com/message/compose?to=%2Fr%2Fmeta_bot_mailbag)* 
I missed this when it was posted, but I got a [Certificate of Awesome](http://lispinsummerprojects.org/awesome-projects) for my [unit test library](https://bitbucket.org/zck/unit-test.arc/).
Thank you, thank you, thank you. I have been trying to find a template system that is good, not just for me but for potential collaborators. I searched everywhere and couldn't find anything satisfactory: * `cl-template` is broken (The examples from the README don't work). * `cl-emb` has aged and makes it difficult to do the things it doesn't support by default, like iterating over a hash table or otherwise writing your own `LOOP` body. * `cl-closure-template` has the most autistic parser. * `cl-markup`/`cl-who`/etc. all have the common flaw that they try to represent HTML as a sexp, making them unusable to anyone who is not a Lisper and for anything other than generating HTML. Djula *looked* promising because it's pretty much the only one that supports the common Django/Jinja syntax and supports template inheritance, and would be easiest for Python web developers to pick up. But when I saw the repo, the last commit had been made in 2008. I have actually been working on my own (Not yet public) using a syntax similar to that of the Play Framework's template engine, but this looks very, very promising.
:) There's still work to be done. I had the same problems you had with existing template systems, so I decided to try to improve Djula which looked promising. It's been only a week's work so far, but I think we can achieve a pretty usable implementation with enough work.
Yep. Now I'm doubting it is a Lisp library. It has too much documentation for a Lisp library :P . I will try to keep working on it, although Lispers are well known for getting bored and moving on to other things :/
Author here, feedback welcome!
A couple example plots would be nice, just to sell it to the user.
Done! I added an example for each graph :) There isn't so many yet...
Smart people think that Regular Expressions are a bad choice to parse nested s-expressions. But sometimes it can work fine, as it does in this wiki: http://epsilonwiki.free.fr/alphawiki_2/. A small introduction to the embedded language, lambdatalk, in this page: http://epsilonwiki.free.fr/alphawiki_2/index.php?view=oncemore. I would be happy to have your opinion on this subject. Alain Marty 
If you have any idea of new charts to draw, give away! There are only 2 charts plotsvn can currently draw, but I'm out of interesting ideas.
Nice, fresh approach. I just wish it would use () instead of {}. I am too attached to good old () to let them go. Thank you. Very interesting.
The RegExp is detailled in this page: http://epsilonwiki.free.fr/alphawiki_2/index.php?view=syntax_others_parser The only one alternative I know to parse s-expressions is the standard "tokenization-&gt;build_tree-&gt;tree walk" used in Lisp interpreters. Following the Peter Norvig's Python code implementing a small Lisp interpreter, I wrote one in Javascript which can be seen here: http://epsilonwiki.free.fr/alphawiki_2/index.php?view=stock_lisp_alphalisp But this approach isn't the answer I'm waiting for in a wiki context where text must be written easily, without bracketting strings between quotes. Do you think that a pushdown automata could be an answer in a wiki context?
Deliver us from eval.
I read 'On the perlis of eval'
It's also an anagram of Lisper. Just how deep does this rabbit-hole go?
Has someone some experience using it ?
Good catch.
I like it. Since the last version you have a repl running once you fire up your app, so it is easy to try out things on the fly, this saved me a lot of time. Also, now it is possible to manipulate e.g. Objective-C objects, which wasn't possible before. Take a look at https://wukix.com/mocl-screencasts to get an idea about that. I evaluated different Lisp solutions for iOS (from compiling ECL, Gambit, etc...) , but with mocl it was the best experience for me. My app, a game using cocos2d for gfx/input and mocl for model&amp;controller(MVC) isn't in the store yet, cause Apples QA is having a problem with my UIs quality. Also I cannot give any input about Android. 
A paid, proprietary programming language? Nope nope nope
Common Lisp is not a proprietary programming language. I don't think it's a bad thing to make an environment for using Common Lisp in situations where it's not easily used today. And I don't think it's a bad thing to try to get paid for that valuable work.
There's a [previous thread](http://www.reddit.com/r/lisp/comments/25jbc7/creating_a_planet_lisp_mobile_app_in_15_minutes/) on this too...
Agreed. I have no problem paying for support / product.
Awesome. I will look into this. I have needed a static site generator for a long time.
Go back to your [chumpatrons,](http://www.loper-os.org/?p=1446) trendoids.
[**@marutakoEX**](https://twitter.com/marutakoEX): &gt;[2014-08-01 16:00:49 UTC](https://twitter.com/marutakoEX/status/495237727604846592) &gt;Lisp(LispAlien) [*pic.twitter.com*](http://pbs.twimg.com/media/Bt9wFkmCMAA7c3d.jpg) [^[Imgur]](http://i.imgur.com/Py2WqnO.jpg) ---- [^[Mistake?]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=http://reddit.com/2d1xvg%0A%0APlease leave above link unaltered.) [^[Suggestion]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Suggestion) [^[FAQ]](http://np.reddit.com/r/TweetPoster/comments/13relk/) [^[Code]](https://github.com/buttscicles/TweetPoster) [^[Issues]](https://github.com/buttscicles/TweetPoster/issues) 
Correct me if I am wrong, but MOCL looks like it is based on ECL which already supports Android and iOS. The value-add consists of a set of proprietary libraries and a pre-configured environment, along with support and updates, so that it all should 'just work out of the box'. You could, potentially recreate something like this for yourself, so the trade off is between how much you value your time and whether MOCL actually delivers value greater than the price of the license.
You are wrong.
World-Wide-Search-Engining "mocl is based" has a bird tweeting: &gt; mocl is based on an older version of CLICC, which is available under a non-GPL BSD-like license (thanks to Rainer Joswig for telling)
Nine. Nine ways.
That of course depends on the precision demanded and whether you're rounding, flooring or, as the OP seems to be signifying, ceiling-ing to the next zillion.
The homepage is very confusing... it's not at all clear what to do. edit: and now that I'm getting into it... I like it. Thanks for doing this OP.... you're the man. 
Ah, a Lisp-tan? 
Yeah.. I figured that out. Just saying it wasn't obvious, for all the cool looking content there. 
Nein. Eight-nine. Eight-nine ways. Probably Wrong :-P
Later versions were released under the GPL. CLICC was itself originally written in Common Lisp, which may explain why the code-base was still a viable starting point when code from that era written in other languages has rotted beyond recovery. Another plus for Lisp. &gt;Lots of software is rotting in some archives nobody is looking at anymore. Pearls of programming effort are getting more and more outdated every day, as their implementation language and their host operating system subtly changes. CLiCC belongs to this group, for it is obviously abandoned since 1996 and silently broke on recent Common Lisp compilers. It was developed using Franz Lisp, though they say any standards based Common Lisp system would compile it. It looks like it has taken a lot of work to go from the original seed to the current system, and they have targeted a viable market opening by generating small executables for deployment to mobile systems rather than their competitor's image based approach. I hope they get rich. They have earned it.
/Sarcasm?
A little. How about some more information? What size team, what is the expected workload, what is the timeline... etc etc (I'm not interested, just helping others out)
Can you share *any* more details publicly?
Oh man, this sounds amazing. Imagine what you could do with other people's time, money, and skills! 
There is a certain craziness to many IT jobs.. contract or otherwise - you probably realize that by now, though perhaps not the full extent. The main difference between mature technology groups and not-so-mature ones is that things are more organized and less panicky.... Yes, there is more process, more paperwork, to the point of being insane - but all the work involved in producing it all is normal work. It's not an emergency; it's not crunch time every day. It's the job.. you go to work, you do your work, you go home and don't have to take the work with you. I'm not in a beurocracy. .but I am in a technical department that has mostly been working together for 15 years. I'm one of the older employees. We have hired over the years, slowly, and a couple people have left - but, by and large, we have been working together for more than a decade. Every year, at least for the last several years, we've become more efficient and less stressed out - we tackle larger, more demanding projects with less worry. Our relationship with our clients (internal business clients) is always improving. Do we do more documentation and paperwork now than we used to? Absolutely.. but we spend less time in panic mode and far more time working a proper 9-5 job where we are productive during those hours. We come in knowing what we're going to deliver, how we're going to deliver it, and how much work we need to get done that day. Our estimates are realistic. I hope I can take enough of that knowledge with me if and when I move on somewhere else to implement the same thing, because having watched the change from what we had 10 years ago, it's amazing. 
"Real Soul"? I challenge you to find a definition for that. We don't know enough about sentience to state that something made of "dead material" can't be conscious. 
Why are you using Arc for this? You're working off a five-year old release that's missing a bunch of features you want, and has an incredibly small community. Why not use something else publicly available with more features and people who use it? And I say that as someone who loves Arc. Also, "I want someone to help with this thing that I won't give details for, and I won't pay you, but it'll sure get publicity" is pretty disrespectful. Will you come over and help me move my couch?
I've moved a couch or 3 for free. If you're wondering why, it was because someone needed my help. But we aren't asking for free work, you will be compensated. I'm not going into complete detail publicly, but if someone has any level of interest, private message me for further discussion. Talking privately is not a binding contract.
We are, of course, aware of the ABCL faq but we were hoping for some real world, feet on the ground experience. I wouldn't have even suggested the possibility that we use ABCL without it passing the standard test suites, but that information doesn't give us much to go on about surprising performance bottlenecks or things that have slipped through the test suite but might show up. These sorts of issues can take a significant amount of time! 
You could always e-mail the devs and ask them, or check out the testimonials and try to contact those people?
I don't know of any usage reports or success/failure stories for ABCL. I do know the development team is active and takes bug reports seriously and handles them pretty quickly. (This is in contrast to a few Common Lisp implementations that are effectively unmaintained at the moment, like CLISP and ECL.) I understand reluctance to invest time and effort into non-core problems. Consider the benefit, though, of taking a bit of time to seriously evaluate ABCL and put it through its paces for your problem domain. Even if it's not ultimately a good fit, it can help inform people in the future who have the same kinds of questions, and help the developers understand where to target their effort.
We are in the middle of a very superficial version of exactly that: building little mock-apps with ABCL, Clojure and Scala, just for the sake of comparison. But it will be quite difficult to accumulate enough experience in to give us a real heads-up about potential issues. One of the benefits of using a JVM language is that we can fish around a bit, as long as we are careful to not tie ourselves down to a particular language runtime.
Try out CLiki? https://github.com/archimag/cliki2
None of these actually work on *vectors!*
This is the primary reason we are seriously considering ABCL. All of us are quite willing to change our programming style to write Clojure, but we have deadlines to meet.
I've started a personal project recently, a calendar web application, and decided to do it on ABCL. I did that because I'm going to need to access iCalendar and some other stuff, and I was not sure CL libraries were 100% ready. Some of the issues I found are: * Some CL libraries don't work. Although they load, sometimes they don't work, like Postmodern, which I intended to use. That can be "solved" accessing Java libraries instead, like JDBC in my case. * Working on a live ABCL image is not as pleasing as working on say an SBCL image. It takes more time to start up, so I cannot slime-restart as efficently. Also, package exports can not be modified live, you have to either evaluate the export explicetly, or slime-restart. * I guess Clojure java integration is probably better, with more working libraries at your disposal, but I don't "buy" or "like" Clojure. I want more lisp, no less. I like CLOS, method combinations, and other CL features Clojure doesn't provide. I don't know about deployment or running in production. The project is not production ready or anything, these are just some of the issues I came across on the way so far.
&gt; Some CL libraries don't work. Although they load, sometimes they don't work, like Postmodern, which I intended to use. That can be "solved" accessing Java libraries instead, like JDBC in my case. For a pure CL, flexible DB interface library, you might want to try [Crane](http://eudoxia0.github.io/crane/). 
Can you elaborate on the package export issue? Do you mean defpackage and related functions?
If you consider Clojure realistic alternative then I think you should also seriously consider Kawa: http://www.gnu.org/software/kawa/ I'm working on a substantial project that runs on the JVM, and we seriously considered all three: ABCL, Clojure, and Kawa. After a few weeks of trial implementation of our project in each, we chose Kawa. I would honestly have preferred to choose ABCL, because I always miss CLOS when I don't have it. To be frank, I am missing it now. But in practical implementation and testing, Kawa stood out as the best choice for several reasons. It's a good implementation of Scheme, with support for R5Rs and R6Rs, and planned support for R7RS. The support is not 100% complete; for example, Kawa supports only upward continuations, not full continuations. That's a conscious choice on the implementor's part, choosing an implementation that provides consistently good performance on the JVM over one that is fully standards-compliant. It's mature and well-supported. Per Bothner has been implementing and supporting Kawa since the 1990s at Sun and later at Oracle. More recently he left his longtime job at Oracle to concentrate on supporting Kawa full-time. There is a low-traffic mailing list for Kawa, and Per responds quickly to messages on the list, sometimes issuing fixes for reported problems in an hour or two. Performance is good, and launch times of Kawa apps are surprising. Our app, an immersive 3D multiplayer networked game, launches in under 2 seconds. Framerates are excellent. Kawa's interoperation with the JVM is smoother and more comprehensive than ABCL's. I do like ABCL, and I especially like that ability to wrap access to Java in CLOS, but ABCL's java interop is not fully comprehensive and it's not as mature as Kawa's. Many Java libraries expect that the way you will use them is by subclassing and annotating their classes. With ABCL the easiest and most reliable way to do that is by dropping into Java. By contrast, there isn't a single line of Java code in our app, because Kawa's Java interop makes it completely unnecessary. We've been able to do everything from Scheme. Clojure's Java interop is one of its selling points, and it's certainly both mature and comprehensive. It's not as straightforward as Kawa's, though. Try Googling for how to extend and annotate a Java class in Clojure. I think you'll find that it's not obvious how to do it. In Kawa you use define-simple-class to create a new Java class, and it understands Java annotations. Packaging an ABCL program for delivery is not exactly straightforward. For pointers on how to accomplish it, you might start with this page: http://www.didierverna.net/blog/index.php?post/2011/01/22/Towards-ABCL-Standalone-Executables It's much simpler with Clojure, as long as you buy into the whole Clojure tools ecosystem. That's the thing about Clojure; it's not just a language or a language implementation; it's a whole stack. It's *possible* to use just the Clojure jars, but you're making things gratutously hard on yourself if you do. The sensible way to use it is to buy into the whole ecosystem--Clojure, ClojureScript, leiningen, nrepl, clojars, the whole magilla. There's nothing wrong with that; it's a decent ecosystem and learning and using it will make things like packaging for delivery pretty simple. But if you just want a Lisp to work with, not a whole tool stack, then Clojure may not be the best way to go. Kawa imposes little or nothing on you in the way of tools. You can easily use it all by itself. It's a single jar that comprises a repl, libraries, and a compiler that can produce executable jars. You can run the repl directly in a terminal, or in a Swing window. Kawa supplies an ant task you can use in a build.xml, or you can tell Java to run kawa in batch-compiler mode. Our build process yields a single executable jar that launches almost instantly, using Kawa's batch mode to compile our sources. It works with Scheme modes in Emacs. It even works with SLIME, using swank-kawa.scm; I generally run Kawa from a SLIME session. Disadvantages? It's not as robust over redefinitions as ABCL. What I mean is that I can redefine classes and methods all day long in an ABCL session and never see a problem. I attribute that to good ANSI compliance. Kawa is much more likely to get confused and need a restart. The pain of the restart is mitigated by how quickly Kawa restarts. I can kill a SLIME session and have a new one ready to go in about a second. It doesn't have the huge community that Clojure has. There is a community, and it's loyal and helpful. Per himself is remarkable responsive. But Kawa does not have the vast resources of the Clojure community, nor the huge collection of libraries and extensions that come with it. We might argue that, on its merits, it *should* have those things, but it doesn't. It isn't Common Lisp. It's Scheme. Now, I like Scheme, so it's not that big a deal to me--except that I miss CLOS and pine for it any time I don't have it. But also, it means you don't get Quicklisp. I don't pine as much for Quicklisp as I do for CLOS, but it's starting to get close. Would ABCL work for a serious project? Probably. You should expect to do some of your work in Java. Would Clojure work? Most likely. You should expect to get to know the Clojure community and tools stack intimately. Would Kawa work? Yep. It would. 
If you're concerned about the time it would take to adapt to Clojure's style, then it may be even more of an issue than you anticipate. Clojure strongly discourages assignment, to the extent that SETF has no direct equivalent in the language. I'm not objecting to Clojure's style--I like it, actually--but if you haven't worked in a side-effect-free style then adapting to Clojure might take more time than you expect. Also, I made the point in another comment that nobody just adopts Clojure-the-language. It comes with a whole tool stack. It's a decent enough tool stack, but it takes time to learn the stack and adapt to its way of doing things. And if you're contemplating bypassing the stack in order to save time, don't. It will cost more time than it saves. 
Yes. Basically, the evaluation of DEFPACKAGE forms for existing packages is ignored. So, if you want your package to export a new symbol, it is not enough to evaluate the package definition with the new exported symbols, as nothing happens. But there's a workaround calling the export function directly. Here is the bugtracking issue: http://abcl.org/trac/ticket/16
It is true that some libraries don't work, but this is usually a fault of the library, not ABCL, and can often be fixed with a modest effort. Case in point, cl+ssl, after some fixes to both ABCL and cffi, now works with ABCL. Yay.
IIRC, the main missing piece for my being able to avoid writing any Java when using ABCL was constructors in the jnew-runtime-class stuff. Shouldn't be too hard to add. Oh, and the maven asdf support could use some attention.
I haven't tried using it with Android, but if I'm not mistaken, others have. You might try asking about it on the Kawa mailing list: kawa-subscribe@sourceware.org You say elsewhere that you want certain Lispy features, including CLOS. I should warn you that there is currently no CLOS-equivalent for Kawa, and that Kawa is generally less dynamic in nature than ABCL (c.f. my other comment that mentions the Kawa can easily become confused if you redefine Java classes in the repl). For what it's worth, Per has mentioned that he's looking for ways to address that objection, and has some promising ideas. Also, as I said before, restarting Kawa is really really fast--unlike restarting ABCL. 
Nice. At least there's syntax to write Java objects, that's better than nothing. Also, I've taken a quick look at the examples, and seems to integrate quite well with Java. I feel I would prefer it to Clojure for JVM programming. Also, it would be great to be able to use Kawa from Slime, including connecting to a live Android "image". I've got used to the interactive programming Slime provides; it is difficult for me to go back to the traditional write/compile/run cycle. 
Consistently, but for some of the queries if I remember correctly.
swank-kawa is in slime contrib and works well for me. define-simple-class is the macro for defining Java classes. (There's also define-class, which defines more flexible but less Java-compatible classes.) There's a macro called 'object' that can create an anonymous class and instantiate it. If you're extending and instantiating a SAM type (that is, a class with exactly one abstract method--a "Single Abstract Method" type), you can use lambda to do it. Here's the reference: http://www.gnu.org/software/kawa/Anonymous-classes.html If you need to work with the JVM and want to write Lisp code to do it, Kawa is a pretty reasonable choice. 
You could probably share your tips with Xach, for his lisptips blog/twitter. P!
Oh, that's a relief. Certainly not ideal, but at least it works on the main implementation.
Sure. It seems that CLiki follows the MVC. Thank you :)
Clojure seems not to be side-effect-free, just immutable (although there's a way to get mutability back, but Clojurists would say - "why would you do that?"). Side effects are normal part of using the language (although the consensus is that it's good to have it in as few functions as possible).
If you happen to be using SLIME, `slime-export-symbol-at-point` runs the necessary `export` of the symbol in the lisp image and also adds the symbol to the defpackage form. By default it is bound to `C-cx`. That said it is frustrating when `defpackage`'s behavior isn't conducive to interactive development. 
Where's the one that takes two constants and does it at compile-time?
Unless there's some deeper bug in ABCL, you can do the same redefinition in ABCL, it "just" takes more steps.
You're right; Clojure is not side-effect-free. It can't be. After all, it has a reasonably comprehensive Java interop. On the other hand, in Clojure you can't say (setq x 5) or anything directly equivalent to it. Simple assignment is not part of the language. The issue is maybe complicated a little by the fact that it has a few operators that sort of look like assignment, but they're not. They're all doing something different from (and more complicated and expensive than) assignment, and they have different and more complicated restrictions and failure modes. So, yeah, if you have experience working in a side-effect-free style, then Clojure is going to come a little more naturally. 
Good tip. Thanks.
For better or worse, this is par for the course for many such improvements. There just aren't a lot of folks working on it and they're all busy with other things, AFAICT. I don't think any of the high-priority things on my list (jnew-runtime improvements, better maven support (or better yet replacing it), and the defpackage issues) are particularly challenging.
Good; I'd still like to use ABCL. :-) 
So it seems like you have the tools to make the decision. You really want to use a Lisp. You really want it to compile to the JVM. You really can't afford to look beyond ABCL and Clojure. Okay, then; that reduces the choice to expected risk versus time. If you're willing to accept elevated risk in order to maybe (probably) get your product done more quickly, choose ABCL. The risk is that the smaller development team and community and the relative immaturity of the implementation as compared to Clojure mean a greater chance that a showstopping issue will blow your schedule out of the water. If you're not willing to accept the elevated risk, but you are willing to accept a longer schedule, new and different language semantics, a very different tools stack, and a less dynamic, less interactive development environment (less so even than ABCL), choose Clojure. 
For what it's worth, I can support these observations. 
&gt; In the case of a Lisp Machine, do you run Lisp on 'bare metal'? In a way, is the Lisp interpreter the hardware itself... Not really, it's just that the instruction set was designed and optimized for compiled Lisp. &gt; Does this mean you could start from a few 'fundamental' functions, and just like in Emacs, build an entire environment from these functions? In a way, most lisp dialects have a relatively small core (special forms, basic datatypes) and build everything from there. Even Common Lisp, which is quite big, has only a handful of special forms. How you build this core... doesn't really matter. In the lisp machines, everything was written in lisp and compiled to that instruction set. Even today, most of SBCL is written in CL too. &gt; To take a practical example, could Firefox, or LibreOffice Writer, or any game... Yes. w3m and org-mode would be the Emacs "equivalents". Let's say you write a game in C. You use SDL or any other library. That's your API, your building blocks. You can do the same by providing the same building blocks, no matter the language. The convenience of Emacs/Lisp machines is that everything is integrated in a single programmable environment. &gt; wouldn't it be a good idea to create modern 'Lisp Machines' today? Yes, but this is... a metric ton of work. Even migrating from Emacs Lisp to a better Lisp (e.g. Common Lisp) for Emacs would be great, yet there are so much useful things already written in Elisp that it's just not practical. At this point, your best bet is to continue using Emacs and contributing to it. There has been interest and work in creating a kernel in CL (see movitz) or lisp machine emulators, or better Emacs clones, all of which have failed to gain enough momentum and see wide usage. If you want to see an environment that takes the "I provide some fundamentals, you do the rest" to the extreme, take a look at Oberon. 
&gt; If you want to see an environment that takes the "I provide some fundamentals, you do the rest" to the extreme, take a look at Oberon. It was a great environment, specially System 3 with those nice gadgets.
Yes, the Lisp Machine booted an OS written entirely in Lisp and the hardware was specifically designed to make hosting Lisp easy (tag bits in the memory addressing scheme, for example). A subsequent attempt at MIT to produce a bare metal Lisp also resulted in Scheme and the [SCHEME-79](http://dspace.mit.edu/handle/1721.1/6334) chip. The Lisp Machine, like the Xerox Star and the original Macintosh, was also a full-on GUI workstation, which was quite advanced for its time. But today's hardware is mindbogglingly capable compared to then. It used to take hardware to make garbage-collected environments like Lisp tolerable whereas Lisp now runs fine in pure software. The Lisp Machine, as cool as it was at the time, was designed by hackers, for hackers. That was both its strength and its fatal flaw. 
Emacs is just one application on a Lisp Machine. Most applications are not build on top of Emacs, but were applications on their own. Lisp Machines have real GUIs and we're not limited to being fancy text editors.
&gt; The Lisp Machine, as cool as it was at the time, was designed by hackers for hackers. That was both its strength and its fatal flaw. The marketing also never broke out of the "Lisp is for AI" perception into being a general workstation. So its revenues were almost entirely dependent on a handful of universities and research contractors "doing AI". And since that volume was fairly small, per-unit manufacturing costs were high. Towards the end of its lifespan they developed a bunch of interesting graphics tools in a bid to broaden to at least a second major market, but they were quite different from what was being used in industry at the time, and couldn't beat the SGI-workstation juggernaut in that market.
Symbolics was operational in 1981/82. The graphics tools were already sold in 1984 for the 3600 and the 3670 machines. http://lispm.de/symbolics-3/symbolics-3.html So the 3d stuff actually got developed early in its lifespan. This business was sold in 1992 to Nichimen. During the mid/end 80s this software plus hardware was sold and used in a lot of TV companies, for some movies and then also in the game industry. SGIs took over the business once their hardware was so much faster for display and rendering. Also the Symbolics hard- and software was quite expensive. Nichimen ported the Symbolics software to the SGI then... 
I think you misunderstand the nature of the Symbolics Lisp Machine architectures. They were micro-coded CPUs. That microcode implemented a relatively large number of operations that had to be *efficient*. They weren't chosen for minimalism, except that there was a limited amount of microcode storage, so the speedup had to be worth it. The microcode was an implementation of a stack-oriented "macrocode" machine which was designed to be easily targeted by a Lisp compiler. The microcode implementation also was designed to maintain the memory invariants and handle some of the basic operations of garbage collection, and operations like copying blocks of memory. You can't really say the lower levels were "Lisp." They were designed for Lisp. It is true that device drivers, etc., were written in Lisp, though it was very tightly coupled to the implementation and had to be written in a particular style for efficiency. Finally, what made the environment unusually powerful and nice for programing was that everything was running in a single memory space, and the whole thing had been designed by programmers for programmers. So the system could tell you where to find the source code for every function in the machine. And the editor and debugger were designed in as part of the system. You can find out more by reading [The Lisp Machine Manual](http://common-lisp.net/project/bknr/static/lmman/frontpage.html) and the source code for [CADR, the MIT grandfather of the commercial Lisp machines](http://www.unlambda.com/index.php?n=Main.Cadr). From the [Lisp Machine Manual](http://common-lisp.net/project/bknr/static/lmman/code.xml#A%20More%20Advanced%20Example-section) &gt; Here is a more complex Lisp function, demonstrating local variables, function calling, conditional branching, and some other new instructions. (defun bar (y) (let ((z (car y))) (cond ((atom z) (setq z (cdr y)) (foo y)) (t nil)))) &gt; The disassembled code looks like this: 20 CAR D-PDL ARG|0 ;Y 21 POP LOCAL|0 ;Z 22 BR-NOT-ATOM 27 23 CDR D-PDL ARG|0 ;Y 24 POP LOCAL|0 ;Z 25 CALL D-RETURN FEF|6 ;#'FOO 26 MOVE D-LAST ARG|0 ;Y 27 MOVE D-RETURN 'NIL 
I'd like to add that Nichimen Mirai (product of Symbolics S-Graphics use) was, I don't want to abuse hyperbole, a miracle in that market. In my biased view, it demonstrate the qualities of good abstractions (and languages supporting this way of thinking), uncoupled from hardware performances. To this day I find Mirai demos impressive in the natural flow and barely limited possibilities (3d painting, skeleton based mesh deformations, fluid FK/IK animations) that took a decade to appear in the most advanced competitors (Alias, Softimage, etc) except with more bolts showing, not as pretty. Mirai, as Lisp Machines, faded away since long. We're hitting a law of nature here .. some things are only good to spread genes and die. Well Lisp ain't dead yet.
&gt; I have been reading a little bit about the 'Lisp way' vs. the 'UNIX way' I don't think that's a meaningful comparison to make.
I gotta try to contact Izware and find out what their goal is with the source code. I don't know if it would do any good to open source it, but it sure would be cool. If they open sourced it, I'd love to try and do crowdfund the porting of the code from the Windows NT world to a modern Linux environment. Modern OpenGL should be able to handle the requirements. You are right, Mirai is in many ways still ahead of the curve.
Well, Izware has a contact page. No idea if the phone number is valid. According to them, they bought the rights to the software and source code as per: http://izware.com/news/index.htm I don't see why it would be a nightmare to open source if they own all the copyright. The biggest issue might be dependency on the Franz environment. I don't know if porting to SBCL would be doable, but it seems plausible.
Considering that no one wants to even use something as amazing as Blender which costs nothing and has some amazing features, good luck to me indeed!
 (= (z 1) #\p) I don't think I like this. It seems like trading ease-of-understanding for terseness. In CL, I would do this with: (setf (char z 1) #\p) Or: (setf (aref z 1) #\p) In either case, I see what sort of thing z is before I reach the end of the expression. In the arc example, if I don't know the type of z, I have to read to the end of the expression to infer it.
But why not?
Yet the STL uses refinement of concepts (eg, the iterators) which is... inheritance applied to an extremely narrow scope.
Isn't kawa gpl'd? 
its license is the MIT/x11 license. 
&gt; Would ABCL work for a serious project? Probably. You should expect to do some of your work in Java. I really don't agree with the point that using ABCL means that one will have to write code in Java "the language" as well. For the EHR project that has been using ABCL for the last nine months, we have yet to need to write anything in Java "the language". I guess this comes down to your contention that most Java libraries are used "by subclassing and annotating their classes" which may be true for persistence frameworks, but I would argue that it is not the typical way one uses JVM libraries. 
I'm glad to hear it. I'd really love it if I could use ABCL for my app. The showstoppers for me, roughly in descending order of importance, are: - this: (define-simple-class ChatMessage (AbstractMessage)(@Serializable) (name type: String init-form: #!null) (contents type: String init-form: #!null) ((toString) (format #f "[~A] ~A" name contents))) ...and other uses of Java libraries that want me to subclass and annotate something. - simple builds for deployment. My project uses a simple ant buildfile that produces an executable jar from Kawa Scheme code. It's certainly possible to do the same thing with ABCL, but it's nowhere near as easy. Heck, the Kawa distribution includes an ant task to do the compilation, or, if you prefer, you can run kawa itself in batch mode to perform the compilation. - Load times. ABCL reports its own startup time under SLIME on my box as about eleven or twelve seconds. By contrast, I can kill the Kawa SLIME process, restart it, and have a working process in less than one second. Now, ABCL is much more robust under redefinitions than Kawa is. As I've said elsewhere, I can redefine classes and methods all day in ABCL with nary a problem. Kawa tends to get confused when I do that. On the other hand, restarting Kawa is so fast that the problem disappears. The length of time it takes to have a fresh Kawa SLIME session is exactly the time it takes for the keystrokes, and since I'm using Emacs, I can make the keystrokes very convenient to type. My delivered app--an immersive 3D multiplayer networked game--starts up and is ready to play in under two seconds. It's easy to rationalize a longer startup time in discussion, but if you ask end users whether they prefer a game that takes twelve seconds to start or one that takes two seconds--all other things being equal--there's no contest. Two seconds wins. If Kawa lost these three advantages, I would most probably switch development to ABCL. As nice as Kawa is, I do miss CLOS and Quicklisp. 
What is the quote? Those who do not understand Lisp are doomed to reinvent it...poorly. Something like that, anyway.
I wish I could know Lisp at this level.
Hello easye &gt; But once we had an automated recipe to produce that single artifact, &gt; the operations staff was able to treat the thing as "just another &gt; application" that they could deploy or revert new versions of the &gt; application without ever seeing a REPL. that seems interesting, since I'm having more or less the same problem, i.e., I'm trying to deploy a lisp system that has dependencies as a WAR file. Do you have any pointers/code that you can share? Thanks. 
Keep at it.
"Any sufficiently complicated C or Fortran program contains an ad hoc, informally-specified, bug-ridden, slow implementation of half of Common Lisp." It's Greenpun's tenth rule: https://en.wikipedia.org/wiki/Greenspun%27s_Tenth_Rule
Some people have gone very far in the implementation of a lisp in python : http://hy.readthedocs.org/en/latest/index.html
Pretty funny, I made a Lisp in Python just yesterday ! https://github.com/antoinealb/lis.py
I've roughly packaged what I am using to pull all the ASDF systems into place for packaging in [a commit to abcl-servlet][1]. I have undoubtedly missed some parts, but at least ABCL-SERVLET/BUILD:PREPARE will get all the ASDF systems in place for inclusion in a web archive. At the top of prepare.lisp, I've also included the relavant snippets of an Ant script that will automate this process. [1]: https://bitbucket.org/easye/abcl-servlet/commits/e3bf36e015f2b5168d3e1d3d547aa6d85373ce6b
Well... LISP is a family of programming languages. UNIX is a family of operating systems. What kind of comparison were you thinking of?
I think https://github.com/bigos/lisp-openshift leaves Quicklisp out of the repository, to be installed by the developer. Isn't that better?
Lisp: everything is (or can be reduced to, if performance doesn't matter) a list. Unix: everything is (or can be reduced to, if performance doesn't matter) a file. Lisp is recursive by definition (as lists can contain other lists ad infinitum). Unix is... not (as directories are already "special" files.) Now, from there on, everything sufficiently differs already...
Now let's contrast LISP and pears...
&gt; Near the end, R. Matthew Emerson said what hopefully everyone was thinking, which was that panels like this, filled with hand-wringing, tend to be pretty depressing; that important solutions like Quicklisp come out of people deciding to solve their own problems in Common Lisp; and that the most important thing any of us can do is to just go hack more Lisp, for which he received applause from all present. To add to this, I'd suggest what every Lisper needs to do is: Pick an area of interest, something that Common Lisp has not been deeply used in, and hack away until you have something that makes people who work on that with other languages jealous.
There's still a proxy error (error reading from remote server).
w.r.t. updating the ANSI spec, I think the main ingredients would be: 1) Time 2) Money 3) Cooperation of two or more Lisp vendors I'd be open to providing #1 and (my part of) #3. mocl does not bring enough income to provide #2, but perhaps we could do a spec refresh on a kickstarter basis. Thoughts?
They seem to have been recorded but I don't know by whom or if/when they can be released. 
LISP has been an ingenious discovery (thanks to the discoverer!). Pears have been an ingenius Creation (Thanks to the Creator!). But there's a but: without pears (ore similar), nobody ever would have been able to discover LISP... Concluding: pears are much more BASIC than LISP/Lisp/whatever.
There was a CLtL3 draft charter: http://permalink.gmane.org/gmane.lisp.cltl3.devel/3 I didn't see any accounts of why that effort died, but looking at the ideas that were tossed around, it looks too aggressive to me. Even if one could successfully spec out a real CLtL3, I think implementations are going to be very reluctant to do anything that requires substantial labor. Resources are limited and we need to be realistic about goals. Rather than doing a major update, which I agree probably is impossible, it might be feasible to make progress incrementally, in ways that are limited and focused. In my mind the lowest hanging fruit would be simply to standardize some syntactical conveniences in ways that won't break old code, and push for implementations to adopt them. For instance, the standard hash table syntax is ugly and off-putting especially to newcomers from other languages. Without breaking things, we could add a new function 'hash-table' analogous to the 'list' and 'vector' functions, which accepts a rest argument for the initial contents. The test could be equal so that string keys are not treated like a special case. Finally, the default hash table printer could actually show the contents (after all, lists and arrays do), possibly in conjunction with a reader macro. Of course you can do these kinds of changes on your own with a library and that's what everybody does (or they just live with it), but it would be nice to make these things consistent across code bases as well as implementations. I'm also hopeful that making any change, however small, would give CL a little boost in that we aren't just resting on the laurels of work that was done a long time ago.
I've heard of Kawa and runs some tests with it, but somehow I didn't notice until just now that it's a GNU project. That means the GNU project has *three* different Scheme implementations: Guile, MIT, and Kawa. 
So, sort of a standard library. There was the "curating libraries" proposal (aka libraries consolidation) from Far some time ago that could be a first step in this direction
I don't know if it's a coincidence, but the related [HN discussion](https://news.ycombinator.com/item?id=8212860) also has a link to a thread discussing the off-putting ugliness of hash table syntax (in scheme, in that case). :-)
Your way 8 does work, but it's not really in the spirit of Backus. FP functions take one argument; FP functional forms such as Insert and Apply-to-all take functions and return them. Your insert and alpha2 take Lisp &amp;rest functions, and return one-arg functions. FP functional forms can be chained to build more complicated functions, e.g., (  lP) in the definition of matrix multiplication in Backus' original paper. You'd want an operator to convert &amp;rest functions to FP-style functions that take a sequence (list). (defun rest2FP (fn) (lambda (l) (apply fn l))) Then (rest2FP #'+) would be the FP +. insert and alpha2 would operate on those: (defun insert (op) (labels ((/op (l) (if (cdr l) (funcall op (list (car l) (/op (cdr l)))) (car l)))) #'/op)) (defun alpha2 (op) (lambda (l) (mapcar op l))) Backus' Insert was required to know about the identity for each function (at least built-in ones), but that's more than I want to write today. 
I've been learning lisp for the last year or so, and I'm still learning. My current mantra is "There is no syntax, only the form of the list". Putting an if statement as an argument for instance. Or an unless, or a when. My previous mantra was "Smallest thing that will work, add functionality". Which is from lean startup etc, however it works quite well for lisp. Don't write the function, write the first thing the function must do in the REPL. Then the next, then next, then finally wrap it in defun, then call it, then copy it into the source file. Since you sometimes end up nesting things quite deep, this actually makes the edit/debug/test cycles go faster, and there are fewer of them. YMMV :)
Sorry there have been no updates for a while. I'm working on support for framebuffer objects and implicit uniforms. I have also cleaned up the GPU structures, added buffer backed textures &amp; added temporal functions, but that is all in another branch. I need to spend some time so I can push all this to master but I am spending a lot of time on a work project right now. Thanks again for checking this out though
You got it on steam? Nice. Congrats brother. Will be downloading it tonight to play. Keep it up.
Hooray for the REPL!
Thanks for the advice, I'll try that as I learn and practice more. 
Paradigms of AI Programming is a good book on learning CL, too. It is dense, but if you work through it slowly you will come out the other side with some pretty good knowledge and tools on hand. Be aware that it's possible that learning Lisp on your own might hamper your ability to meet the instructor's requirements for a course. Many courses in LISP follow an individual instructor's idiosyncratic views picked up in the 80s and the way to get through is to reflect what's expected, rather than a general best idea gleaned from current practices. Here's hoping your course won't be like that.
Figure out slime + emacs sooner rather than later - before your course starts... it's worth it. If you are hesitant.. then grab the free version of lispworks and do some training in that, just to get a feel for what it's like to use a more integrated system. Then when you go back to sublime and feel like you are showering with pants and socks still on, you'll understand why you want to try emacs + slime. 
That's partly why you should take advantage of integrated editors... you can just do all that in the editor instead of copy/paste, executing whatever expression you want in the lisp image whenever you want. It seems trivial at first, but it helps later. 
for most tutorials they usually use SBCL, but my class will be using CLISP. Is there a huge difference? 
You read SICP already, it's not CL per se, but the chapters on abstraction really helps thinking how to solve a domain problem.
Thanks for the recommendation, i'll try to check the book out after Practical Common Lisp. I hope my instructor isn't like that. I've had friends who've taken the class before say he's one of the better instructors for the class, however I really don't know how he teaches.
Great idea! From what I read in the sources, it compiles everything with just `make`. I know that for example, sbcl requires some options to have meaningful options like multithread support, will cim support this?
Very slow.
Ow man, you should have made more of a ruckus to get it greenlit! I would have loved voting for your game. *edit:* Ah, it can still be voted on I see.
Yes and I think because of this, it's no longer *really* accurate to say that modern CL is a standards-defined language. Modern CL is a hybrid of a formal standard, and implementation-based "de facto standards", layered on top of that and necessary to get any real work done. For example, the CL threading standard is a library implementation (Bordeaux-Threads), and so is the CL standard for packages (ASDF).
Kawa is the result of a split in Guile development in 1996 over whether it should target the JVM, at least according to the [history](https://www.gnu.org/software/kawa/internals/history.html) in its manual. I would guess GNU kept both because: Kawa was developing more successfully, but Guile was still intended to eventually become the standard GNU extension/scripting language (replacing the role that TCL often took in non-GNU Unix software). MIT Scheme is a much later addition. For almost all of its history it was an MIT project. But it was donated to the FSF around 2003 or 2004, and became a GNU project then. I would guess GNU accepted a *third* Scheme into the fold because it's historically important and a mature implementation (and widely used in education), and would otherwise be orphaned, since none of the people who used to maintain it at MIT are there anymore.
[this](http://www.clisp.org/) doesn't help either... 'This project has been temporarily blocked for exceeding its bandwidth threshold'. Since g3 powerpc builds on debian for a lot of things seem to be broken i'll try to build a version from source myself. Thankfully apt-get source clisp does fetch it and i'm building the 'original' source now into /opt/clisp. $ cat /proc/cpuinfo processor : 0 cpu : 745/755 temperature : 18-20 C (uncalibrated) clock : 600.000000MHz revision : 51.17 (pvr 0008 3311) bogomips : 49.92 timebase : 24960000 platform : PowerMac model : PowerBook4,1 machine : PowerBook4,1 motherboard : PowerBook4,1 MacRISC2 MacRISC Power Macintosh detected as : 257 (iBook 2) pmac flags : 0000001b L2 cache : 256K unified pmac-generation : NewWorld Memory : 384 MB It's an old g3 and a lot of ports seem to assume altivec for it which it doesn't have but they fail with illegal instruction. It wouldn't suprise me if it was the newer gcc (gcc version 4.9.1 (Debian 4.9.1-4)) however. It takes a while to build though.. *impatiently drums fingers on desk* I had to pass --ignore-absence-of-libsigsegv to configure. To continue building CLISP, the following commands are recommended (cf. unix/INSTALL step 4 ff): cd src vi config.lisp # The default stack size on your platform is insufficient # and must be increased to at least 16384. You must do either # 'ulimit -s 16384' (for Bourne shell derivatives, e.g., bash and zsh) # or 'limit stacksize 16384' (for C shell derivarives, e.g., tcsh) $ cd src $ ulimit -s 16384 $ make I'll edit later if this worked out better. e: well this didn't get very far either so it has to be something in clisp or gcc 4.9 i think; gcc -g -O2 -W -Wswitch -Wcomment -Wpointer-arith -Wimplicit -Wreturn-type -Wmissing-declarations -Wno-sign-compare -Wno-format-nonliteral -O2 -falign-functions=4 -DENABLE_UNICODE -DDYNAMIC_MODULES -I. -Wl,--export-dynamic spvw.o spvwtabf.o spvwtabs.o spvwtabo.o eval.o control.o encoding.o pathname.o stream.o socket.o io.o funarg.o array.o hashtabl.o list.o package.o record.o weak.o sequence.o charstrg.o debug.o error.o misc.o time.o predtype.o symbol.o lisparit.o i18n.o unixaux.o built.o modules.o -lncurses -ldl libgnu_cl.a -o lisp.run ./lisp.run -B . -N locale -E UTF-8 -Epathname 1:1 -Emisc 1:1 -norc -m 2MW -lp -x '(and (load "init.lisp")(sys::%saveinitmem) (ext::exit)) (ext::exit t)' [snip logo] ;; Loading file defseq.lisp ... ;; Loaded file defseq.lisp ;; Loading file backquote.lisp ... ;; Loaded file backquote.lisp ;; Loading file defmacro.lisp ...Makefile:1397: recipe for target 'interpreted.mem' failed make: *** [interpreted.mem] Segmentation fault I'll retry with CFLAGS="-g -O0" ./configure blah (which doesn't seem to work since it still builds with -O2..., so i did edit Makefile and deleted -O2 (the -O0 was present before other cflags)) and this also gives the same segfault so now i don't really know what to try except my homebrew memory tester (which just allocates 384mb of ram and writes/reads bytes from it) but that runs fine. I don't know if there's a memtest for powerpc but i doubt the memory is the problem). using layout asm in gdb for the original segfault: +---------------------------------------------------------------------------+ &gt;|0x1004af38 lwz r9,-4(r3) | |0x1004af3c lis r0,-20480 | |0x1004af40 rlwinm r9,r9,0,0,5 | |0x1004af44 cmpw cr7,r9,r0 | |0x1004af48 beq cr7,0x1004d734 | |0x1004af4c addi r9,r11,2 | |0x1004af50 rlwinm r9,r9,1,0,30 | |0x1004af54 not r9,r9 | |0x1004af58 rlwinm r9,r9,2,0,29 | |0x1004af5c lwzx r0,r3,r9 | |0x1004af60 lis r9,4130 | |0x1004af64 stw r0,31884(r9) | |0x1004af68 li r0,1 | +---------------------------------------------------------------------------+ (gdb) info registers r9 r9 0x1040ab93 272673683 (gdb) info registers r3 r3 0x37f6c0a8 938918056 (gdb) x/16xb $r9 0x1040ab93: 0xa8 0x10 0x34 0xf8 0x9d 0x10 0x21 0x6c 0x1040ab9b: 0xcd 0x10 0x37 0xb6 0x19 0x10 0x40 0xab (gdb) x/16xb $r3-4 0x37f6c0a4: Cannot access memory at address 0x37f6c0a4 (gdb) x/16xb $r3 0x37f6c0a8: Cannot access memory at address 0x37f6c0a8 
I have the same problem on my G3 with CLisp. I've done some dicking around with building from source, but with no resolution in sight. 
IIRC, the clisp in apt-get is old. You might have better luck pulling from cvs. Regarding error handling, I think it only really works if you have libsigsegv.
I find the music of Chopin to be very helpful. I also recommend peeking into the book "On Lisp" by Paul Graham. Even if you don't go through everything, there is a lot of advice within about how to design programs. You might also learn a lot from Sonya Keene's "Object Oriented Programming in Common Lisp".
fmargaine: Yes. If you have any options that you want CIM to enable, comment here https://github.com/KeenS/CIM/issues/30.
Thanks heaps for doing it!
I can't believe nobody has mentioned Conrad Barski's "Land of Lisp". Amazingly good lisp book that uses clisp. It teaches the history of the language as well. The teaching medium is via console games that range in complexity from guess the number to hunt the wumpus. A really stellar book. Another great book is David Touretsky's "A gentle introduction to symbolic computation". It is by far the best book for teaching lisp data structures. Cons cells, CAR, CDR, NIL, and linked lists were a very big mystery to me until I read it. SICP is also pretty great (you can watch the accompanying lectures on YouTube from the 80's as well...all good). This is scheme and not common lisp, but close enough. Honestly though a great way to see code is on Rosetta Code. Click on a problem like "99 bottles of beer" and look up the solution in 1) common lisp 2.) scheme 3.) picolisp 4.) newlisp the latter two are often referred to as "toy lisps", but I find them very lightweight, practical, and specialized. Picolisp can usually run decently close to a compiled Lisp like SBCL and will absolutely smoke the interpreted version of SBCL. They haven't caught on too well though due to not having real macros and using dynamic scope. If your teacher doesn't make you do anything insanely complicated, newlisp might be something fun for you to peek into. It has some of the greatest documentation known to man, and like picolisp, the author has solved a ton of Rosetta code problems. I mean it has ODBC support practically straight from the box. Its trivial to do parallel computations in both as well due to how easy it is to fork it. 
I've added the 'Where to get help with Common Lisp' link to the sidebar. The other text about starting a Lisp project is not really Lisp specific.
[yes](http://www.paulgraham.com/onlisp.html)
No problem! Usually people are pretty good at answering my questions on this subreddit should you need it. You can read chapter 8 of Land of Lisp for free on the publisher's website.
1. COUNT is a local variable defined by LET. Calling the function, the value of FN, increments it. 2. the value of FN is a function, here a closure. A closure is a function + a binding environment. If the value of FN is called via FUNCALL, this function is called.
I think I understand what you're getting at. The first time (funcall *fn*) occurs count is set to 0 and the function object containing the lambda expression is returned, and then evaluated. Each proceeding call to fn would then evaluate just the lambda function. My follow up question is why is the let no longer evaluated? Is it because the init call is defparameter or the body is a lambda function? For a normal function (defun foo () let()), the let would be evaluated each time foo is called right? Basically how does Lisp differentiate?
&gt;The first time (funcall fn) occurs count is set to 0 Actually, this happens early. When you do `(defparameter var val)`, CL evaluates the `val` expression and assigns it to `var`. When evaluating `val`, which in this case is a let, it creates an environment (Where variables and their values are stored), then assigns the value zero to `count`. Then, CL evaluates the `let`'s body within this environment, and in this case the body is just a lambda function. The key here is that a lambda is a way of saying "wrap this code up, carry any environment you need, and return it. I'll use it later." In this case, you're asking CL to package the code `(setf count (1+ count))`, along with the variable `count` on which it depends. So that piece of code and that variable will be "wrapped up", and the resulting *closure* will be the value of `fn`. When you do `(funcall fn)` for the first time, CL "unwraps" the closure, then calls the code, which increases `count` by one to the value one. Next time you `(funcall fn)`, once again, that code will increase `count` by one more. And so on and on. EDIT: [This](http://i.imgur.com/jzaCnUB.png) image might explain it better. Sorry for the wonky Inkscape effects.
&gt;So in the end, setf count isn't setting a global variable, it's just setting a local variable in that environment? Yes, that's exactly it. The lambda is said to "close over" that variable.
&gt; The first time (funcall fn) occurs count is set to 0 and the function object containing the lambda expression is returned, and then evaluated. Each proceeding call to fn would then evaluate just the lambda function. No, that's not it. What does the expression `(defparameter var (+ 3 5))` do? It assigns some value to the variable `var`, in this case the value of the expression`(+ 3 5)`, which is the integer 8. What does the form (defparameter var (let ((x 3)) (+ x 5))) do? It assigns to the variable `var` the value of (let ((x 3)) (+ x 5))) What's the value of that expression? To find it, you use the rule for evaluating a `let` expression: introduce a new variable `x` whose value is `3`, and evaluate the body `(+ x 5)`. What's the value of `(+ x 5)` in these circumstances? The integer 8, of course. Now consider the expression you mentioned in your post. It assigns to the variable `fn` the value of the expression (let ((count 0)) #'(lambda () (setf count (1+ count)))) To find the value of this expression, you again use the rule for `let` expressions: introduce a new variable `count` whose value is `0` and then evaluate the body. The body is #'(lambda () (setf count (1+ count)))) so in order to evaluate *that*, you use the rule for `#'` expressions: the value is the function which, when called with no arguments, evaluates the expression `(setf count (1+ count))`. So the first time you evaluate `(funcall fn)`, the function I mentioned above is called with 0 arguments. That means that the body of the function, that is the expression `(setf count (1+ count))`, is evaluated and the result is the value of `(funcall fn)`. What does it means to evaluate `(setf count (1+ count))`? It means increment the variable `count`, and the result of the evaluation is the new value of `count`, in this case 1. Indeed, if you type `(funcall fn)` at the REPL, the system will answer with `1`. Now if evaluate `(funcall fn)` a second time, the same thing happens, except that the value of the variable `counter` is now 1, not 0 as it was originally, so after `counter` is incremented the new value is 2. And if you call `(funcall fn)` a third time, `counter` will be incremented again, which results in the value 3. Etc.
Just saw your edit, it's very helpful!
I basically do that, but much faster. It's a bit like reading natural language: when you start out you struggle with every other word, but after a while you just read it, and you understand what it says without having to think about the words themselves consciously. The main thing to remember is that the code is run by evaluating an expression. This produces a value (or several), and maybe some side effects). How to evaluate a compound expression is completely determined by the first word in the expression (let, if, defparameter, etc.).
SBCL is very strict in showing warnings and errors within your code. That's actually a good thing! If you carefully read its warnings you can spot your typos or errors that CLISP would just wave away. So it might be worth to see if your code compiles in SBCL without any warnings even if CLISP is your main Lisp.
i tried to get the source from the website but it's unaccesable atm, for now it's really unstable but building it myself from the same sources as debian does (do they use a cross compiler for other arches like netbsd?) fails with a segfault. I'll see if libsigsegv makes a difference. Otoh i installed gcl into opt. I like clisp though for it's interactive usage and completness. I only use lisp for toy programs atm but it would be nice to do something with asdf packages like clx and such. I've looked at quicklisp for that but using it on gcl is quite an adventure, somehow that doesn't work well with package statements. I meant to use it for bootstrapping sbcl but it seems pretty nice so i'll stick with that for a while.
Learning emacs lisp, finding the repl M-x ielm was a breakthrough for me. I was surprised that few people on #emacs ever talked about it, but they learned elisp in the scratch buffer and elisp files on disk. These days I most often evaluate elisp from source code segments of org-mode buffers, but ielm is still my go-to for a quick experiment where even thinking "what file should this go in?" is overkill.
Macros tend to be where I sometimes get lost for a spell. Not many languages operate on themselves at compile-time and run-time like Lisp does. Distinguishing clearly the compile time manipulation of forms, from the run time manipulation of values helps. Also, not so much a way of thinking, but macroexpand-1 is your friend.
Interesting - I wasn't aware of that either - possibly because the scratch buffer is all I ever needed (or any other .el buffer) The benefit of doing lisp in emacs or other integrated editors isn't that you have the repl in a window though... that's just cosmetic. It's that you can execute expressions straight from the editor... 
No we just need an AllegroServe handler for Clack. I'm gonna write that down as "Things I hope Fukamachi is working on".
This is a really interesting way to look at representing numbers. This can only represent a subset of the reals, right? Since there are uncountably many reals and countably many computer programs, there must be some real numbers that cannot be represented by this method. 
when i use (defun read-numbers () (loop for i = (read *standard-input* nil :eof) until (eq i :eof))) (time (read-numbers)) gcl acts strange, it outputs numbers on stdout? clisp doesn't. I think there's something wrong with my gcl but i recompiled it from source to be sure. $ gcl GCL (GNU Common Lisp) 2.6.10 CLtL1 Aug 28 2014 00:05:55 [..snip..] output is like: &gt; 6173129058 &gt; 3375260069 &gt; 537889628 there's no time information at the end but before all the stdout with all 0.000, while clisp is just $ clisp read.lisp &lt; random.dat Real time: 0.050423 sec. Run time: 0.052 sec. Space: 0 Bytes e: it's not that i like gcl so much but i'm looking for a lisp which is available on lots of platforms. Clisp runs fine on my openbsd g3 powerpc ibook but a lot won't. Gcl compiled but it seems to have problems (or i'm being stupid which is very much also probable) while it is the common choice for large projects. I did use sbcl in the past for a while but that won't run on as much architectures as clisp. Clisp also has troubles in debian testing i believe, i think it's even being removed from it. The homepage is also not reachable. What a mess :( https://packages.debian.org/search?suite=jessie&amp;searchon=names&amp;keywords=clisp https://packages.qa.debian.org/c/clisp.html e2: i didn't see numbers on stdout while testing the mean program btw.
thought it would be worth to share. https://packages.qa.debian.org/c/clisp.html
This blog post is not even wrong. Most real numbers have no representation even as a computer program. And why does a representation as a computer program gaurantee error-free arithmetic? 
&gt;Since there are uncountably many reals and countably many computer programs There aren't countably many computer programs. Well, I guess there are - but there are uncountably many *potential* computer programs, which is (I think) what you meant.
&gt;And why does a representation as a computer program gaurantee error-free arithmetic? It doesn't - it's just a shorter representation of a number.
A little explaination of what is happening would help
There's a really old library for Common Lisp called [Computable Reals](http://www.haible.de/bruno/MichaelStoll/reals.html) that can do stuff like this. It seems to be currently maintained on [bitbucket](https://bitbucket.org/tarballs_are_good/computable-reals).
Seems like it doesn't build on some archs so they're rejecting it? It's not quite clear to me.
Is clisp even maintained anymore? It hasn't been updated in years, AFAIK.
Yeah it seems to be dead. too bad. 
That's a pity. I always liked CLISP for being available on almost any platform. No matter which OS you're on, there's almost always one Common Lisp available for it: CLISP. That said, I rarely used it because for the usual platforms either SBCL or CCL is available as well. Perhaps that is the reason CLISP seems to be struggling. 
true indeed, it's more like toy test program. Converting it to floats surely doesn't have the memory/computational overhead when using large numbers for input. When using normal numbers however it is pretty fast.
1 minute late, goddammit!
clisp itself doesn't seem to have had any updates since 2010 
don't fix it if it ain't broke. (well, ahum, now it is broken :) I don't think there's anything wrong with that, it worked pretty well before i tried jessie (on powerpc it also has problems on jessie but works on openbsd). Maybe (but i haven't tried with another yet) gcc does some optimizing which it doesn't like, that's quite new in jessie. 
Oh, for sure... I'm just wondering if it's abandoned. 
Haha. Maybe next time.
What you say is simply not correct. Most real numbers (even most integers) are incompressible. 
&gt; there are uncountably many potential computer programs This is not correct. There are countably infinite computer programs, because there are countably infinite finite length strings.
Your comment is a more sophisticated version of not even wrong. The article is about real numbers, not about the countable subset of real numbers called computable numbers. But even if it were about computable numbers, most computable numbers have grotesque representations. If what we seek is a practical benefit, well, there ain't no free lunch. 
It's great to see more ARM love. Time for another marathon compile session on my cubietruck.
What's needed to improve the process for building binaries for download? Some of the platforms are obscure, but it seems odd that Windows x86 often lags by several releases.
Step 1 would be to repeat this question on sbcl-devel. I don't think many people who can answer it read reddit.
This is the second article I come across today about embedding TinyScheme, cool stuff! 
No love for GNU Guile? I embedded Guile into my demo/demoscene framework, and it works nicely. The only thing lacking is better support for threads and better Windows support.
To be fair, those are two HUGE things. 
&gt; I found the C API of S7 WAY better than TinyScheme. Plus it's a much bigger and battle tested project, Good to see s7 scheme mentioned. The C API of s7 is why I use it.
No you don't. It is the same article spreaded web-wide. No seriously, where is that other article?
The scripting language of GIMP is based on TinyScheme. It has some interesting features like non-hygienic (CL-style) macros and namespaces.
Nice. Could you post some links ?
Guessing that spaceman_ was referring to this: http://philosecurity.org/2009/01/12/interview-with-an-adware-author It was posted to HN a couple of days ago.
Tinyscheme says it can have separate interpreters running at once. Does this mean the program I embed it in can have an instance in each thread, giving the ability to have "real" threads in an app that uses scheme? This is one of my main pain points that keeps me from really using a scheme for embedding is that if I need to spawn some kind of worker thread, none of the embeddable options really let you do this (at least not that I know of).
Qi was coded in CL, but Shen is a distillation of Qi into a set of primitives that have in turn been implemented in a variety of languages. This does have the feel of stacking turtles on tortoises though.
Yes, that's the one. I read it before, but I came across it again on [lobste.rs](http://lobste.rs) recently.
It's not the case that Lisp and Smalltalk were "culturally worlds apart". Smalltak came out of Xerox PARC which was also a hotbed of Lisp use and development, and Alan Kay quite explicitly acknowledges Lisp's central influence on Smalltalk design.
&gt; Smalltalk-80, was new It was just a language release in a series. Smalltalk 71, 72, 74, 76, 80. http://www.smalltalk.org/smalltalk/TheEarlyHistoryOfSmalltalk_III.html http://www.smalltalk.org/smalltalk/TheEarlyHistoryOfSmalltalk_IV.html http://www.smalltalk.org/smalltalk/TheEarlyHistoryOfSmalltalk_V.html &gt; The inventor of Smalltalk-80 pictured his language eventually being used by children for fun Lisp was not designed for children, but it spawned languages for that purpose - especially, Logo, a Lisp for children - in 1967. https://en.wikipedia.org/wiki/Logo_(programming_language) http://files.eric.ed.gov/fulltext/ED038034.pdf &gt; Culturally, Lisp and Smalltalk-80 were worlds apart. Smalltalk took a lot basic Lisp technology. At XEROX PARC there was the development of Interlisp and Interlisp-D - the latter took inspirations from the Smalltalk environment, but a lot of IDE/GUI inventions were done with Interlisp-D. Interlisp-D was then even running on the same hardware. http://www.codersatwork.com/l-peter-deutsch.html http://larry.masinter.net/interlisp-ieee.pdf For an example of an Interlisp-D application: Notecards from XEROX: http://www.ics.uci.edu/~redmiles/ics227-SQ04/papers/Hypertext/Secondary/p836-halasz.pdf &gt; But books for beginners are not much easier going. "The Little LISPer" from Felleisen/friedman... Touretzky's book is relatively easy... Hard to say how many introductory Lisp books existed - easily more than twenty. &gt; Lisp is a language designed by computer language theoreticians for their own purposes. I thought it was originally designed by AI people for their purposes and expanded from there... &gt; Moreover, Lisp, like Smalltalk, is interpreted (or at least seems that way when you use it) We say it is INTERACTIVE, even though compiled and/or interpreted. &gt; Lisp did not take off on the PC until the x386 computers with a 32 bit flat addressing space became plentiful in the late 1980s . But the Macintosh, despite its well-known limitations, used the same Motorola 68000 CPU used in many engineering workstations. Not much different on the Mac. Coral Lisp appeared 1987. &gt; Franz Allegro Common Lisp product, which ran on minicomputers Unix machines/workstations ... http://franz.com/about/company.history.lhtml &gt; Seeing the writing on the wall, The MCL team wisely replaced Object Lisp with the Common Lisp Object System in version 2 of Macintosh Common Lisp. The whole UI (and a lot more) was already written in Object Lisp. The transition to CLOS eventually took place (1991 published as MCL 2.0b1), but the Object Lisp heritage was still there. &gt; Unlike those languages, CLOS does not employ message passing between objects. Lisp developers experimented with that for some, for example Flavors was message passing. Object Lisp was more like Self or, now Javascript. Based on prototypes and delegation. &gt; In 1987, it was a very advanced way to do Macintosh user interface programming. In 1987 CLOS was not used. Coral Lisp used Object Lisp in 1987. MCL 2.0 with CLOS was eventually published in 1992. &gt; The kind of IDE that we normally use now, like Microsoft's Visual Studio or Apple's XCode, was invented by THINK Technologies for their Pascal and C programming systems in the early days of the Macintosh. Interlisp-D. MIT's Lisp Machines were IDEs invented before the Mac existed. &gt; Before that (except for some experimental systems) programmers developed interactive tools that relied on character, not graphics, displays. Well, Interlisp-D and the MIT Lisp Machine were used with graphic displays. For example LMI's first commercial offering in 1991/1992. http://s7.computerhistory.org/is/image/CHM/500004885-03-01?$re-medium$ &gt; The emacs text editor was developed by Richard Stallman and Guy Steele, and became the standard tool for Lisp programmers. The EINE editor written by Dan Weinreb was an Emacs on a Lisp Machine with raster graphics. 1979. Interlisp-D had non-Emacs editors on raster graphics. https://en.wikipedia.org/wiki/EINE &gt; It also seems to me that Lisp programmers would want class browsers for the classes they use and make in CLOS. There were several class browsers available for MCL. The community wrote it. That was much of the appeal of Macintosh Common Lisp: it was easy to hack on and to extend. &gt; An incredibly great set of browsers and analysis tools were built into the Macintosh version of the Lisp-derived language Dylan And they were written in MCL by Apple. &gt; It cant be a coincidence that these things are not part of Lisp IDEs, but I cant figure out why not. They were. Partly. See Interlisp-D. But many also wanted to have more basic text-oriented tools. See 'Programming in an interactive Environment, the Lisp experience', 1978 http://www.ida.liu.se/ext/caisor/archive/1978/001/caisor-1978-001.pdf Interlisp-D then moved to more GUI tools... &gt; an earlier version called SOS Interface, was written using ExperLisp by Jean-Marie Hullot, who worked at the National Institute for Research in Computer Science in Paris. Which was later ported to other Lisps, including MCL. Action! 3.0 from Expertelligence was released for MCL 2.0 in 1992 and did cost $595. &gt; The job of porting the program was turned over to Digitool, which so far as I can find out consisted of pretty much the same people as Coral and Apple Cambridge. Well, Apple cancelled a few projects and Lisp was no longer central to its direction, especially since the Newton did not use Dylan (whose most tools were written in Lisp). So the future of MCL was in danger, since it was on 68k and PowerPC was the future. Apple then decided to help MCL survive by giving it to Digitool, which ported it to the PowerPC. Later MCL was open sourced in form of OpenMCL, later renamed to Clozure CL. Clozure CL is available cross platform and was not focused on being a GUI-based Lisp. &gt; That probably explains why Clozure Common Lisp looks so much like MCL Unfortunately Clozure CL still lacks a lot of stuff one had available in MCL. One of the newer more advanced UI-basic applications written in CCL is http://opusmodus.com , a tool for music composers. Since there was never put much thought into a new GUI for Clozure CL, it looks similar to what existed. Newer and better GUIs and IDEs are possible, but there is not too much effort going into it right now. But a lot of research used MCL to develop new GUIs... Example: http://old.sigchi.org/bulletin/1998.2/spohrer.html 
Lots of interesting comments. Thanks for posting. 
[**@xach**](https://twitter.com/xach): &gt;[2014-09-05 13:36:17 UTC](https://twitter.com/xach/status/507884927447470080) &gt;SBCL is 15 this year. Planet Lisp is 10. What are some other round milestones in Common Lisp this year? ---- [^[Mistake?]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=http://reddit.com/2fjxmc%0A%0APlease leave above link unaltered.) [^[Suggestion]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Suggestion) [^[FAQ]](http://np.reddit.com/r/TweetPoster/comments/13relk/) [^[Code]](https://github.com/buttscicles/TweetPoster) [^[Issues]](https://github.com/buttscicles/TweetPoster/issues) 
&gt; Culturally, Lisp and Smalltalk-80 were worlds apart. I think this is an exaggeration. The languages are different, and the communities have different aesthetics, but "culturally", Smalltalk and its community are about as close to Lisp and its several communities as anything possibly could be while still being considered a separate thing. I've met more Smalltalkers who were interested in and competent with Lisp than who were not, and vice versa. Smalltalk folks gleaned inspiration and ideas from Lisp, and vice versa. If that seems like a lot of empty abstractions, let me be more concrete. The Dylan language was designed in a series of meetings in Cupertino. Interested programmers from around Apple attended those meetings. I was one of them. Among the other attendees, Lisp and Smalltalk users were heavily represented. There was far more agreement than disagreement among participants, and as best as I can remember there were no significant differences across language lines. That was a concrete example of Lisp and Smalltalk communities collaborating on a clean-slate design, and for all intents and purposes they might as well have been a single unified community. 
The screencast explains more than the README what differs from slime. *edit* The NEWS.md file has good info, too.
The original announcement, and its first (quite sombre) reply: http://comments.gmane.org/gmane.lisp.slime.devel/11484 I am actually quite interested in SLY.
&gt; Unfortunately Clozure CL still lacks a lot of stuff one had available in MCL. One of the newer more advanced UI-basic applications written in MCL is http://opusmodus.com[13] , a tool for music composers. Isn't it developed on CCL? see [here](http://www.reddit.com/r/Common_Lisp/comments/2azyi2/opusmodus_out_now_a_ccl_application/) 
I meant CCL, corrected. Thanks.
yes, i know sbcl is a fine lisp but it is also advertised as a portable lisp and offers downloads for powerpc. So maybe it's not so portable after all? People might want to use it for it's portability after all imho. Clozure is a good recommendation, i'll try that on it.
I think it's ok to claim portability while still not working on a ten-year-old laptop that is multiple generations obsolete.
i don't agree with that. Let's see the list of supported platforms which you think are obsolete. PPC SPARC Alpha MIPSbe MIPSle if this is the case it would be better off only supporting amd64. If that's the case don't show off with unsupported architectures please. It will save people a lot of time trying to make it run.
Mmmmaybe, or maybe "rejecting" or "evaluating" rather than "selecting."
The Sly coder seems to started from a very defensive position that seems rather unwarranted... :/ Is there some history that I am unaware of?
God, that comment chain seems really tense.
Not sure if it will work on your computer, but perhaps try [Clojure](http://clojure.org). It has quickly become my favorite and preferred lisp. Plus, it is viable and used in many new production applications these days and appears to continue gaining more traction.
Well, the author is a douchebag. Count me out.
Purely from reading that thread.. the author seems to ask for advice from people, and then when he gets advice form the very people he should be hoping to get advice from, he basically shoots it down and/or refuses to do anything. He accuses those who say they don't get it of not looking hard enough, and asks that they provide better documentation for what the new features are after trying it out. He also appears to refuse to rename any of the internals to differentiate it form slime/swank despite it being an obvious thing to do, even after the package maintainer requests it. He argues with Zach about why he would ever want to load it at the same time as slime/swank. I'm nobody, and I'm not one to look down on the work of others - but if you want to get any community support, that's certainly not the way to go about it. People gave exactly what the author asked them for, and they gave it professionally and politely and he shot them down. It's your project bud... if you want people to understand it, you need to document it. Telling someone who is happy with their current solution that yours is better but you can't explain why and they should figure it out for themselves is a good way to get people to not bother trying. You're asking people to swap out a very long-standing, heavily supported tool for your version without being able to explain clearly why, or show any kind of community support even in it's infancy.. that's not going to get you far (and that might mean that cool things you've done in there never see the light of day, unfortunately) edit: He also appears to justify everything from an open-source-advocate point of view rather than from a needs point of view. His reason for making a fork is "Freedom! I'm allowed to fork!" and he repeatedly mentions how much work went into it. None of this addresses the actual questions. We know you are allowed to fork, you are absolutely allowed to fork - but now you're asking us all to pay attention to your fork, and that's different. 
I'm very glad SBCL works on my 2003 P4 which I use for all my programming and any other computer activities. (Ubuntu 14.04 with gnome-session-flashback is fairly snappy on it!)
&gt; Rhine aims to expose how common Lisp constructs map to hardware. ... &gt; common Lisp I'm having a hard time reading this sentence the way it was meant to be. Anyway, it looks interesting.
I fully agree. Thank you for your comment, coming for a 'senior' Lisp developer it feels like a touch of sanity in quite a bit of silliness.
What makes you say that? I've read some (not all) of the discussion and he seems very reasonable and open to feedback?
I used to run SBCL on such a machine, years ago. So perhaps you just have to try an older version of SBCL. After all, it is not too reasonable to pretend that an ancient machine should run brand-new software.
In the years I've observed that the SLIME maintainers, while doing an excellent job, tend a bit on the conservative side. This fork is an experiment by someone that is trying a new direction. I don't see anything wrong with that. Actually, so many times the lisp gurus have issued the commandment: "don't discuss, code", and this man is doing that. For the rest, I read icy hostility in the forked ones, and frustration in the forking one (both before and after the fact). It seems a common situation, unfortunately. Amicable forks are rare.
Does this make use of being able to hook in to c libraries at all? The readme leaves much to be desired. I also do not like "(= [] coll)" if the hope is to be similar to clojure. This is all interesting none-the-less!
I don't know man, it's as if he was asking why gcc doesn't compile on his machine and you suuggested he should try c++.
&gt; heavily supported Except for people who actually want to add features. 
I am not sure it is reasonable and open to essentially answer &gt; Hey, can you rename all this stuff? &gt; No! Give me a reason!
Sure... and forking it and adding features is absolutely fine.. I'm just suggesting that if you want people to take your project seriously as an alternative to a long-standing pillar of the community, you need better PR than this guy is displaying. 
I'm not in any way suggesting the fork itself, or the experiment, or the product, is wrong, in any way. It's great. I see him asking very clearly for feedback, getting feedback from the exact people he was asking (none of which was anything related to "don't do this" or "you are wrong".) and his responses were fairly hostile. Not a good way to get traction. I get that the community he's trying to get into might not be all that receptive, that seems obvious - but his responses to polite questions were pretty sharp retorts. 
I don't get that metaphor. How do you mean?
C and C++ are not the same language and neither are Common Lisp and Clojure.
xach was polite and entirely reasonable (nor he is a SLIME maintainer afaik). However, while I understand the quicklisp requirement (which itself might make SLY easier to try), perhaps the rename-everything request has a possible drawback in the sense that perhaps (I am just wild guessing) it makes SLY more an independent project, rather than an experimental branch of SLIME that could be possibly merged back eventually, which perhaps is what Joao hopes. But I am just guessing.
yes, the downloadable version is already quite old compared to the newest version. This segfaults however, clozure also. I'll try to build a version myself using ecl which does run.
Yeah, I think I'm pretty much agreeing with you, and if you fork, it's only fair to make the fork actually distinct. SBCL is a fork of CMUCL, but you hardly would know it. They don't go make demands on the CMUCL folks. It's a weird sort of entitlement on the forker's part. But it also would have been nicer if SLIME weren't so hostile to new features and functions. Which is probably part of the sensitivity.
That "merge back in" possibility makes some sense to me as an explanation: the renaming also substantially adds to the hassle of keeping track of SLIME enhancements as well. But you know this kind of thing happens. Sometimes you just have to reimplement features that exist in one code base on another. But one had to know that the conservative SLIME environment doesn't care about making it easy for others to do their own thing with the SLIME code base, no matter what the license is. I was just pointing out that Xach made reasonable points that the Joao seemed not to appreciate. 
It's not even that he didn't make it distinct... .. it's that he deliberately asked the SLIME stakeholders that if there was anything he missed, let him know, because he was trying to do right by them. They DID let him know, entirely politely, and he shot them down. 
Well, if you want to fork, then go make a fork. And if you ask the maintainers of the original code what you should do, maybe you should expect that kind of answer, especially given the history of slime development processes. They gave a generous license to the code. That doesn't mean they have to be your best friend and make your life easy.
You cannot be this fucking dense. Seriously? 
Fair, though I thought all the CL implementations were different as well. Just didn't take into account the relative scale of difference. All I saw was "I need a portable lisp", to which my answer is Clojure.
hmm it segfaults on debian jessie; but i downloaded 1.0.28-powerpc-linux. $ SBCL_HOME=/opt/sbcl/lib/sbcl /opt/sbcl/bin/sbcl &lt; Segmentation fault This is the gdb output: Program received signal SIGUSR1, User defined signal 1. kill () at ../sysdeps/unix/syscall-template.S:82 82 ../sysdeps/unix/syscall-template.S: No such file or directory. Which is kindof weird because it gets SIGUSR1, not a segfault. I ran it with SBCL_HOME=/opt/sbcl/lib/sbcl gdb /opt/sbcl/bin/sbcl if that matters.
LLVM makes it very easy to call C functions; it uses malloc, memcpy and other functions internally, but I haven't designed a proper FFI yet. What else would you like to see in the README? "(= [] coll)" is because a lot of automatic type conversion work is in progress.
It's all in the capitalization ;)
i can't reach the mentioned build page for crosscompiling sbcl but i want to try that, does anyone know how to do that? http://www.sbcl.org/porting.html I have sbcl on amd64 which runs fine.
https://web.archive.org/web/20130323180853/http://sbcl-internals.cliki.net/Build
haha why didn't i think of that, thanks very much!
lispm, the walking lisp history book
FYI, thanks to Bob Nicksic at SourceForge the Clisp project page is whitelisted now and should not go inaccessible again for 'exceeding its bandwidth threshold'.
I suspect this was a private email to someone who asked something like "Why did you use CL for project XYZ? Should I use CL too? How can I get started?" The answers given are pretty reasonable for questions like that. Not a lot of detail (though it _does_ give a few reasons for the various CL implementations), but good pointers in the right directions.
Counterpoint: I've been working in Common Lisp for about three years now, and these features are almost exactly those which I would label as being problematic, because they introduce an enormous cognitive load to the programmer which does not, in my opinion, generally speaking, pay off. I have seen, for instance, one programmer spend hours debugging a piece of code because he didn't realize another programmer had declared that a variable had dynamic extent and he was trying to use the variable as the key to a hash table. I have seen two programmers scratch their head for an hour trying to understand why a variable was declared `ignorable` (that you can even declare a variable as such is, in my opinion, a code smell). In general, the flexible optimization which Common Lisp exposes to the user seems janky and out of place when compared to contemporary practices. To clarify: my compiler should perform escape analysis to determine which values can be stack allocated and which need to be on the heap and it is not my job as the application programmer to concern myself with these things _especially_ if the language will not prevent me from violating the annotations. If I really need performance, let me inline C, which has the benefit of some statically enforced guarantees and a design which is explicitly targeted for performance. I would rather program in two languages, each coherently designed for specific domains, than in one language which attempts to cover all domains at an enormous cost in complexity. Ninety percent of the time when I sit down to program and I am interested in specific goals: telling the compiler how to work by giving it declarations which it does not even enforce statically seems like an unnecessary cognitive burden, especially in a world where large applications are written in much dumber and slower dynamic languages. Ultimately I feel the same way about systems like CLOS/MOP. Yes, they expose an enormous amount of power. But that power imposes a cognitive penalty which is not, for the most part, warranted. I generally speaking do not want to consider the details of how my object system might be extended. I've seen projects accrue enormous complexity because people thought it might be interesting to customize the behavior of their object system. And these are two specific examples. Common Lisp, as a language, loves to attach knobs to every little thing. I don't like that approach, maybe because I am not that smart, and I can't keep it all in my head at once. In general, I want less choice than more. I want static guarantees. I want predictable, simple semantics. I want the ability to extend my language, but I want that ability constrained enough that I (and, more importantly, the programmers I am working with) have to be disciplined about how they use it. I want the language to _help me_ keep the complexity of my program under control. I'd rather program in Common Lisp than Java, but I'd prefer Racket or Clojure to Common Lisp, and Racket to Clojure. And I would really love a nice Lisp with non-gradual, non-optional, Haskell-style static type enforcement. No such luck, unfortunately. 
What do you think about [Shen](http://www.shenlanguage.org/)?
Shen seems ok, although I read about some peculiarities associated with external symbols and packages which left me a bit confused about how it is supposed to work out. As I recall, the language had no mechanism for resolving conflicts between external symbol names. Suppose, for instance, that module `algebra` exports a `+` operation and module `monads` exports a `+` operation as well. I was given to understand that they could not be used at the same time. I was further given to understand that Mark Tarver's rejoinder to this state of affairs was "don't export + from multiple modules: library authors should collaborate to make sure that exported symbols never clash, if you don't like it, build your own module system". This seemed inadequate to me. I am almost certainly misinterpreting the details, but it didn't seem to bode well. I also understand the type system is turing complete (and optional), which seems ill-advised. If you have a non-complete type system you are still writing and debugging one program (and some valid programs are not allowed by the type system). If you have a turing complete type system you are now writing and debugging two programs, one at the value level and one at the type level. This seems to defeat the purpose. Again, I am pretty naive about programming with types, but that is my intuition.
Choraline, I think you make some falsehoods in your post and am willing to discuss them with you. Since you mention, but not quote, the slime-devel thread so frequently, I invite you to reply there, where the actual people involved in the discussion can follow your reasoning. Don't sit in the sidelines! Some points. 0. I didn't not ask for "advice", rather I asked the maintainers of SLIME to audit my fork, which they did. I am not forced to accept all the auditor's recommendations blindly. 1. I have explained that the reason I am reticent to do the swank.* internal renaming is that that would lock SLY out of a free communications protocol. It is not, at all, an "obvious" thing to do. 2. Is arguing with Zach somehow disallowed? There's interest in Zach's argument, and I am working to make his feature request possible. But there's validity in my arguments, and Zach did not refute them. 3. When I stated that I disagreed with Cyrus Harmon, I was not accusing him of anything, I merely said that I disagreed. Cyrus stated that the screencast did not impress him, and that SLY brings nothing to the table. I disagree. I don't think Cyrus had read the NEWS.md file when he made those points, though they perhaps hold for the screencast. 4. I did not "shoot down" anyone, except for Mikel Evins who made a recursive argument restating the obvious. I said "stack overflow" as a joke. Again, please join us at slime-devel and quote from the actual messages if you feel so strongly about this. 5. Finally, while Free Software is necessary, that is not the main reason I gave when I used the word "freedom". One of the reasons for making this fork is that to make the changes I did to SLIME, I had to break much backward compatibility and change many internals that Helmut would **very reasonably** **not** allow. So I took the freedom from Free Software and made my own version where I am in control. Many people do exactly that: keep private forks with theyr own personal hacks. See Ferada's and Attila Lendvai's github forks of SLIME. They have their own changes. The difference here is that I believe these changes can be useful to others and made an extra effort to polish these changes and redistribute them under a new name. It is my belief that a fork is not necessarily a schism (as wikipedia puts it) or represents any kind of aggression to anyone. It is perhaps a naive belief, but I will stick with it. You can suit yourself and don't have to use SLY. But I invite you to. Keeping in mind that it is alpha status, it is my hope that you will find it is a familiar, yet improved, Lisp development experience. If it is not, I invite you to open issues and discuss them with me. In any case, I kindly ask you not to make distorting claims about my contributions. Sincerely, Joo Tvora
Maybe not: [2DVects](http://epsilonwiki.free.fr/alphawiki_2/?view=stock_maths_2DVect) Just kidding. I loved your post and learned a lot. Thanks. Alain Marty
Thanks for your response. I'm not much into Shen myself, but it looked like it could alleviate some of your concerns with CL. Arguably its goals seem to be more about bringing functional &amp; logic programming closer together. I don't have many issues with CL itself, my biggest problem is with the libraries. I know there is something for everything, but it's much harder to get into than let's say Clojure's. For example if I want to deal with some [XML](http://www.cliki.net/xml) over [HTTP](http://www.cliki.net/HTTP%20Client): I don't even know which library to try first. It looks like everyone who ever had to process some XML wrote his own library to do it (and didn't bother to maintain or document it). In comparison the first google result for ["Clojure XML"](http://clojuredocs.org/clojure_core/clojure.xml/parse) and for ["Clojure HTTP"](https://github.com/dakrone/clj-http). Even Emacs Lisp has better libs &amp; library docs than CL.
My colleague has a good strategy for evaluating libraries: go to the github and check out the activity. Both the frequency of activity and how rapidly issues that are reported are addressed. If a library has lots of quickly fixed issues, then its probably a good candidate, even if the activity has slowed down a bit. It is a lot easier to find libraries like this in Clojure than in CL, unfortunately (or fortunately, depending on your perspective). 
&gt; they want to feel better about it through a clearly expressed and justified explanation. "they" should feel *great* that someone found their work brilliant enough to invest his time and energy (and not a small amount of it) into taking it in another direction. &gt; If you wrote the second paragraph above in your original announcement, I think you would have avoided some of the ensuing discussion. So much for my public relations skills. I tried to be terse and but to be fair, so much for benefit of the doubt as well. Some of the comments in this list are really nasty and not based on any fact. Well that's the internet I guess Anyway, I will these paragraphs to the README to address the "reason for this fork" question.
PR tip: "When you're in a hole, stop digging."
If you don't think you're in a PR hole, I'm sorry I wasted time trying to help you out.
You miss the point. Your paternalist tips about PR or popularity (two of them now) are irrelevant to me (but I'm not offended or anything). Let's see if I can explain this to you, because you don't know me in person: I go years without logging into social networks, I don't use IRC, barely read reddit, don't have a blog, and don't fly to Lisp meetings. Perhaps I should do more of those, and learn the tricks of the trade, but my life is busy, and all these things are external to the real interesting matter. Luis Oliveira, whom you know from meetings, has been sitting in front of me at work for 3 years now, and is my most beloved and respected hater, and also critical of SLY project. I work with in in many projects and he warned about the community's reaction, and me, being not stupid :-), also read the way people are sometimes aggressive in these lists. Anyway the point of SLY is not me at all, my friend! The point of SLY is free software made available "in the hopes that it will be useful" and I want it to be useful and to help the Lisp community, because I feel the urgency to help Common Lisp (if not for anything else, to preserve my job possibilities so I can provide for my family). Sure, it would help the project if I were some kind of respected open-source buda, but I'm not and it's not in my genes. That is why I don't need your PR help really. By now the only comment you have made to me about the software itself is that it is "neat". OK, that's nice of you, and I thank you. You've also suggested an improvement that I think is secondary, but still I considered it and am about to deliver it. Lastly, if you think it is valuable to the community or for whatever purposes, redistribute it in quicklisp, blog about it, suggest improvements (as you have already done), and ultimately, fork it :-)
I like the idea of SLY, but I think your reaction to questions about its purpose will delay or possibly completely inhibit its adoption. I may be wrong, and time will tell. Good luck!
&gt; I like the idea of SLY, but I think your reaction to questions about its purpose will delay or possibly completely inhibit its adoption. Fair enough, and point taken for sure, believe me. It you like the "idea of SLY", whatever is it that I cumbersomely still managed to get across, the next thing to do is to try out actual SLY :-) And tell me if you like it. If there's anything you don't like, submit an issue, or better yet a pull request. The code is just a `M-.` or `C-h f` away.
I did appreciate them, and have a fix ready to deliver. The issue at hand is the communication protocol not the "merge back in" possibility. See the thread if you have not done so recently.
I'm replying to a reddit post, not some other thread somewhere else. That's all I read, that's where I'm replying. I'm all for the project - I was only highlighting what I saw as WHY the response to your project seemed to be pretty cold from people. That was an honest view of the impression I got of how this was playing out - maybe I'm totally wrong.. but I'm not here to argue with you about who said what to whom when.. I thought about a description of how this looked to a newcomer might be useful. If you want to write that off as useless, go for it - maybe it is. 
&gt; I'm replying to a reddit post, not some other thread somewhere else. That's all I read, that's where I'm replying. But I'm saying you should reply or contribute your views in the thread that you read, don't you think that's reasonable? It's there and it gives you that freedom. I am not saying you can't comment here, but your since you made some false claims, such as implying that I wasn't complying with Helmut's requests for no reason. I hope you understand that I want to set the record straight, or at least be allowed reply to your claims. &gt; I thought about a description of how this looked to a newcomer might be useful. If you want to write that off as useless, go for it - maybe it is. I also would like to tell you that SLY is free software and work that I do in my spare time and is provided as is. I will try to document it as best as possible (it is currently alpha) now, but for now the screencast was the best I could do. I also did a reasonably extensive NEWS file which I think many people didn't read. Finally, I've said here to Xach, who to my amusement has stated that I'm "digging a PR hole", that the goal here is not me but the project itself. Your reaction is not "useless" any more than it is "useful" to me because it is a reaction about me, about the social thing started by an annoucment, not about the SLY project itself. An even more inflammatory reader here states "I'm out, the author is a douchebag". This is an extreme reaction, and irrelevant to the project. (also irrelevant to me btw, though it's interestingly the first time I've been insulted like on TV). Anyway, a reaction to the project itself would be an useful reaction, I hope you try SLY out when you get a chance and happy Lisp hacking!
I ran what is now called CCL on my G4. You might want to give that a try. I do try to keep my code portable across several implementations so that I can pick a different implementation for a different platform if required.
I don't get the point of this project. Can someone explain, please?
Many people have requested this, I finally went ahead and spent the hours required to make proper documentation. While it is relatively bare-bones, I consider it a good start. I'm working on a tutorial too.
I'm sorry to say, but I find it a bit infuriating that the back button doesn't work. And open a link in a new tab seems broken too. I guess it's because of all the fancy magic. Other people might care less though.
Hi. I've added a non-javascript alternate URL. http://xelf.me/reference-plain.html
Thank you. :-)
cool!
I appreciate your response; I haven't yet seen the cognitive burdens of Common Lisp, but when I'm far enough along, I'll pay attention. A useful comment in /On Lisp/, page 114: &gt; Lisp blurs many distinctions which other languages take for granted. In other languages, there really are conceptual distinctions between compile-time and runtime, program and data, language and program. In Lisp, these distinctions exist only as conversational conventions. There is no line dividing, for example, language and program. You can draw the line wherever suits the problem at hand. So it really is no more than a question of terminology whether to call an underlying layer of code a toolkit or a language. One advantage of considering it as a language is that it suggests you can extend this language, as you do Lisp, with utilities. It sounds like Paul Graham, the author, is agreeing with you: if there isn't strict separation (which in CL would be arbitrary), programmers must make distinctions themselves, or hold in their heads all the abstractions. 
One of my long-term goals is to make a game in common lisp. Thank you so much for your work on Xelf. I'll definitely look into this once I have the free time.
Are there any screenshots of games developed with Xelf?
Ok, but what is the benefit/reason of this? To become sort of a reference implementation? To lighten the burden on other implementors? To have Yet Another Implementation? It is an exercise in portability? I mean, perhaps it's the best idea of the decade, but it is not sold very well. Maybe it's because I am just a user and not an compiler writer, but I have read and *still* do not understand why, so to say, it will make the world a better place.
Thanks. So, I presume also the reverse path should be possible. Start from SICL, then tweak, replace, improve, etc the various modules, so to gradually mutate an implementation of Common Lisp into an implementation of something different. Seen this way, it looks like the perfect experimenting kit for the "Common Lisp should be modernized" types.
See also http://xach.livejournal.com/319717.html which links to a very similar idea from the 80s.
There are some shots and downloads at http://blocky.io/3x0ng.html and http://blocky.io/2x0ng.html and i'm working on a new one http://blocky.io/skyw0r.html
Enjoy! and don't forget to visit #lispgames on freeenode
It could use some clearer license terms. It's not clear how it's licensed, or if it's really even open source at all. 
&gt; Right now it's not safe to re-use. Define safe? 
Lisp troll showed up. Abort thread!
Thank you. I find that reading very interesting. One may want to peruse the associated github ticket here: https://github.com/thephoeron/let-over-lambda/issues/4
[Image](http://imgs.xkcd.com/comics/lisp.jpg) **Title:** Lisp **Title-text:** We lost the documentation on quantum mechanics. You'll have to decode the regexes yourself. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php?title=224#Explanation) **Stats:** This comic has been referenced 34 times, representing 0.1032% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_ckdjmsn)
So, the documentation says that is "is in the public domain, or is distributed according to a license that serves the same purpose in places where it is not possible for works to be explicitly placed in the public domain." Now, what source code has a license when you said "that's all I could find about it"?... because you contradict yourself there given you found a license in the SICL source code that is not under the license that SICL is placed under. ... and that is not safe enough for your lawyers to say your business can use it in your country? Have you contacted Robert Strandh about it? If you have done a lot of work using SICL and just found out now that public domain does not work, and your lawyers say you need a LICENSE file, I will fork it and put it under whatever license you think is 'free'. That way only I can be sued by countries that do not recognize copyright, not your company being sued. Make sense? If that sounds as illogical as typing it felt. there is a big reason. These are reddit comments, not email, c.l.l, IRC, or any other way to get clarification on the license. Have you contacted Robert Strandh about it? 
https://github.com/robert-strandh/SICL/issues/7 &lt;---- These are reddit comments, not email, c.l.l, IRC, or any other way to get clarification on the license. I'n'I contacted Robert Strandh about it.
Thanks for the links! Good luck for your new project (which looks nice).
In Let over Lambda he praised Perl and the chapter on sorting networks had a lot Perl code IIRC. I think he has always been into Perl a lot always. But programming Languages are not exclusive. Being into Perl doesn't mean dropping CL.
I really think this needs more attention. It's a shame that the papers on the repo aren't readily available online, but everything seems really thought out and definitely draws on the experience accumulated over the years. One thing I found especially neat was the much more helpful error messages and internationalization framework described.
UPDATED with a new much smaller example ball-and-paddle game! It's rather simplistic, but the point is for the user to remix it. https://github.com/dto/plong
I've also added a mailing list, for those interested. https://groups.google.com/forum/#!forum/xelf-dev
Is there a good tutorial or explanation somewhere of what qualifies a code walker as 'proper'? I'm blurry on how environments are obtained and used to inform the walker of the semantics of different forms. I saw the links to examples of proper walkers which I'll have to delve into, but to some extent the distinction was skimmed over in this article.
Thank you. His projects are quite inspiring. For example, his `antiweb` server. https://github.com/hoytech/antiweb
It is pretty cool and it has documentation! You should also check John Fremli's projects. He also has a [web server](https://github.com/vii/teepeedee2) and a [database](https://github.com/ilitirit/manardb/) that (IIUC) uses a CLOS instance as a 'view' to a memory-mapped collection of Objects which is 'setf'ed in place for fast traversal. It lacks indices though. His code isn't as readable though, at least not to me. Although for web server's I prefer [Woookie](https://github.com/orthecreedence/wookie). Good Design, documented and the code is dead simple so it easy to extend.
I think it is great that Christopher Rhodes is going the extra mile educating us users about how to do code walking in the face of the recent backquote changes. Maybe this could spark a 'usocket'-style code-walker compatibility layer across implementations?
Nice, I did not know about `wookie`. Do you generally prefer it to `Hunchentoot`? BTW, I have found this nice comment by /u/orthecreedence: http://www.reddit.com/r/lisp/comments/1ge5rx/wookie_an_asynchronous_web_server_for_common_lisp/caoc7ct Also, this interesting comparison of threaded vs asynchronous: http://stackoverflow.com/questions/12924124/why-would-i-choose-a-threaded-process-based-approach-vs-asynchronous-web-server
I have some scripts for building on Mac, but can't yet try them myself because I still need to get a Mac: https://github.com/dto/delivery
You might be interested in looking at LUSH
Having read the edit, and the issue itself, I have to argue that you are wrong. "The goal is definitely wide acceptance. I am not in a rush though, because I am not actively soliciting contributions at this time. " How is that not understanding the issue? There is a reason there is not a LICENSE file... one is to avoid spending time arguing with folks like you who want nothing to do with it yet have time to reddit post about unrelated things. Me, on the other hand, read reddit for at least 8 years, and enjoy such things as a break from lisping. "Let me just repeat what is already mentioned in some file: The code will be in the public domain, or it will be distributed according to some equivalent license for the benefit of places where a piece of work can not explicitly be placed in the public domain." So, you care more about their lack of understanding why someone who has no interest in using SICL wants to argue over the lack of a LICENSE file for something which is stated to be public domain than you care about SICL? Fair enough... you win! 
I said you win ... what else do you want? 
doesn't lush require c wrapper functions for any c++ code it calls? (also, is it still alive?)
I added more documentation to the example, it should suffice as a tutorial for now. https://github.com/dto/plong/blob/master/plong.lisp
I tried building 2x0ng, with little success. The bootstrapping will bail out with several UNBOUND issues regarding different variables. Not sure if those can be ignored. The resulting .app is "broken" or missing stuff. The finder shows it crossed thru. Unfortunately I hadn't much time to look into those issues. Maybe at the weekend.
unfortunately 2x0ng won't build against current Xelf, i need to make some updates. did you try 3x0ng?
nope, 2x0ng, like mentioned in the readme. i will give it a try.
which readme are you referring to?
https://github.com/dto/delivery/ -&gt; README. Oh, now I see: you stated to get 3x0ng, but I just copied/pasted the lines from the README which will pull 2x0ng!!!
Yes, it's very easy to fall-in-love with (Common) Lisp, but the Real Story starts with The Day After...
I'm happy with doing logic on the lisp side and gui on the java side 
&gt;to compile lisp code into JS+html5 You can compile Common Lisp to JavaScript through ParenScript, but I'm not sure how complete it is.
Not even close. It's intended to be a more lispy JS rather than a CL implementation; it does have a somewhat useful intersection though.
From what I can tell, mocl still doesn't do cross platform GUI. You are still expected to write your gui in Java/ObjectiveC and write write your logic in portable CL.
Exactly. So mocl isn't a solution, if it was providing cross platform gui, buying personal license was a good solution.
Have you actually done this? If so, which toolkit did you use?
Oh wow. Lambda native looks amazing. Thanks for the link.
Have you tried Ikarus scheme? It was made by a graduate student of Dr. Dyvbig, who made Chez. Ikarus compiles to native binary and is an almost compete R6RS implementation. 
That makes sense. I think there is room for things like MOCL and Lambdanative approaches. Also $199 is reasonable, I don't know who complains about this stuff. Also, I agree with your native vs html interface comment in the webcast. That makes sense. I really appreciate you putting in the effort to give us the option to code in something nice.
See my [remarks on hackernews](https://news.ycombinator.com/item?id=8317599) about the tricky parts / bugs of the CL examples.
I've made remarks about how to do what he said in Dylan in a pretty pleasant way: http://www.reddit.com/r/programming/comments/2gesag/comparative_macrology/ckihk2b
Culd you provide also android example, something like your planetlisp or such?
There is a mocl [contact lisp app example](https://github.com/Wukix/mocl-example-lisp-contacts-android) for Android. The example draws its own GUI for a couple views, which is not really ideal, but it at least gives an idea of how mocl works. (I really ought to put together an equivalent Planet Lisp app for Android... I'll try to put that out soon)
+ darwin + cygwin. start point: http://rosettacode.org/wiki/Category:PicoLisp 
I agree with zlrth's response. Additionally, I think you need some appropriate coding rule within your group that ensures those kind of conflict would not occur, for example http://google-styleguide.googlecode.com/svn/trunk/lispguide.xml. It can also be controlled in the language level. For example, you can define a hypothetical new package :our-project-cl which is almost identical to :cl but some undesired features like 'special are shadowed. you can also rewrite the readtable in order to disallow the use of external package (in case someone explicitly specifies 'cl:special). Somehow you can put those codes, along with package definition, in one file which no one other than you/project leader have the write access to, using versioning system like git, and let the build system loads that file first. you can even separate those codes from the main repository. And you can share those coding rules within the team. Personally, in practice, I never declare variables which is not defvar-ed to be a special variable, except a few temporary variables made for the debugging perpose. *removed* something we needs is a library that help people constrain the ability of cl. Yes it attach knobs to everything. However unless somehow the knobs are controllable, they are just knobs that no one pulls...
Not that I know of. http://www.xach.com/naggum/articles/3245983402026014%40naggum.no.html has a nice rundown of where the Common Lisp approaches and the Unix approaches differ.
What a nice explanation. Scott Schwartz was wondering the same questions (like, why not exploit more the underlying OS?), and Erik Naggum clarified that and much more. Very nice. "What I actually admire in Perl is its ability to provide a very successful abstraction of the horrible mess that is collectively called Unix." "I think having only one implementation of Common Lisp would be a dramatic setback". Wise words, thank you.
I take it that means that the Lisp way is not to emulate Unix apps, like Perl so well can do, but to offer whatever service from the Lisp level, in a Lisp way, and thus possibly imbued with a perspective that Unix and Perl can't grant. This sounds very natural, elegant and powerful. Thank you.
If what you want is Lisp-scriptable access to Unix services, I suspect the closest you're going to get is [scsh](http://scsh.net/). At least with scsh, you start with a base language that was actually designed.
I would use CLISP for this. It has relatively good Unix integration. See it's documentation for the various facilities. http://www.clisp.org/impnotes/clisp.html and http://www.clisp.org/impnotes.html 
Thank you for point at `scsh`. I believe Emacs' `rx` syntax was inspired by Olin Shivers' `scsh`. Interesting.
OT, but perhaps a little related to that, I have found this amusing section: http://www.schnada.de/quotes/contempt.html#unix
Unfortunately, especially in the segment I am interested in: games, we live in a C++ world which makes things quite a bit harder.
Right... I see non-starters.
I wanted to learn more about shell-scripting, so I wrote a partial implementation of sh in common lisp: https://github.com/jasom/plush
Well, historically the Gnu Emacs development team (or at least RMS) has been very reluctant to change. Hence the whole [Lucid Emacs fiasco](http://www.jwz.org/doc/lemacs.html). But there have been historically Emacs-like editors based on common lisp -- Symbolics workstations used to have ZMacs, which was their version of Emacs 
Impossible for anything that needs to do fancy things with fork(); It does funny things with SIGCHLD, for example.
"May" is far, far too strong and definitive a word. More like "if Emacs were to seriously consider moving to another language, Common Lisp would probably be a decent choice". 
When we get a FFI that works well I hope this won't matter. I'd rather the community build extension that are editor agnostic instead of duplicating efforts to provide completion/refactoring etc across every editor. Let Emacs be the scriptable layer on top but do the heavy lifting in a standalone lib that can be made available to all editors. As a concrete example, I really wish intellij would expose its services as a headless server, so I could consume its deep understanding of languages and frameworks from Emacs.
Right, I thought /u/KingEllis was seeing non-starters in the article, not in general. Thanks for the jwz link, it looks interesting.
The first steps are always quite trivial, but real world isn't (there has been an effort to do things like this for Qt, see **EQL** in this [example](https://gitorious.org/eql/eql/source/Qt_EQL_dynamic/cpp_calling_lisp/lib.cpp), but Qt isn't equal to C++...).
I get this popup when visiting: SyntaxHighlighter Can't find brush for: lisp
Very interesting! I wonder if something similar has been done for Perl.
I wasn't talking about the specific example, I'm just miffed that talking to C++ libraries that do not expose aC API is such a pain in the ass.
I also published a library for signed (and encoded, but not encrypted) cookies: https://github.com/orivej/ht-session. I tried to emphasize security by handling malformed cookie values without raising errors and without using IGNORE-ERRORS or otherwise relying on third-party libraries to handle input errors correctly and safely in all cases.
The current revision of your library signals an error when cookie value is not Base-64 encoded, when it calls (DECODE-AND-DECRYPT NAME VALUE), where VALUE is an untrusted cookie string.
yep, err handling and input/output checking are still in TODO list
I also want to implement a session using hash-table, so can easily store multi values in one cookie, do not need to encrypt/decrypt multi cookies. In this lib I use ironclad HMAC digest to sign cookies.
Very nice. Your other projects there are also very interesting. Thank you!
Ordering mine now. By the way, would you see any obstacle in publishing Naggum's contributions as a real book? I believe usenet posts are in the public domain? This would not be meant as source of profit, but more like an *homage*?
Everything works so far. Find an old USB gamepad and I can play the game, but I must admit, that I suck at it :-p. Looking forward for some time, to hack something with you framework. Thanks for your hard work David!!!
I'm not even sure my own archive is good. "This is actually a very _bad_ idea." -- http://xach.com/naggum/articles/3200585186145741%40naggum.net.html
I think we can do better than just a text editor. Lisp can make an editor for everything. 
That's a clear answer by Naggum. Thank you.
Has anyone gotten the Symbolics Emulator to run on anything recent? I've found a few readmes but they are all about 5 to 10 years old and don't seem to work on any recent Linux distros. 
You can try this repo: https://github.com/marsam/opengenera This is a more up-to-date version of the original repo it forked that is usable. Before running it, you have to download opengenera.tar.bz2 from somewhere (I got it from torrent).
I'm thinking a *media* editor. It can edit any type of data because lisp can extend itself from a few simple editors.
Thanks! This worked.
http://permalink.gmane.org/gmane.emacs.devel/174498 has good info about the situation.
This is what I tried: max: min 20 * R11 + 15 * R12 R21 * 30 + R22 * 10; row1: R11 + R21 &lt;=1; row2: R12 + R22 &lt;=1; row3: R11 &gt;=0; row4: R12 &gt;=0; row5: R21 &gt;=0; row6: R22 &gt;=0;
That is not Lisp code.
LiPS and Lisp are not the same thing 
I guess that explains it. I'm trying to solve some linear problems like the one above. Is LISP the best way to go? I'm some what proficient in Python, but somebody suggested to use LISP, should I use Python instead? 
Well yeah Lisp is a fantastic language - in my opinion it is by far the best way to write programs. It does have a very steep learning curve compared to more pedestrian languages (Python) but you get so much back from that investment of your time I think it's worth it. If you're a student and have the time and inclination then read some Lisp text books and start playing. If you need a solution to a specific problem right now then just work with what you're comfortable with - Python or whatever. EDIT: co-incidentally I wrote a library for manipulating systems of dense multi-variate polynomials a few years back https://github.com/fjames86/fpoly unfortunately the project stalled and I don't think the lib ever got to the stage of being "complete" (bug-free). 
It's for a work project and I don't think I'll have much use for it outside that project. Somebody told me to look into LISP because it was easy to do linear programming with it. Is it true? Or is the same as other programming languages?
&gt; Somebody told me to look into LISP because it was easy to do linear programming with it. Is it true? Or is the same as other programming languages? i don't think there's any 'objective' answer to this: it depends on so many factors, including personal experiences and preferences. Many people loathe various Lisps because of "too many parentheses!!!"; i don't find them an issue, for the most part - particularly due to the editor i use for programming - and certainly not an issue significant enough to outweigh the other benefits of Lisps. Having said that, as a data point, you might be interested to know that the Computer Algebra System '[Maxima](http://maxima.sourceforge.net/)', which [provides functionality around matrices and linear algebra](http://maxima.sourceforge.net/docs/manual/en/maxima_23.html#SEC113), is written in Common Lisp. Also, one thing to keep in mind: 'Lisp' can refer to various programming languages. On this subreddit, in my experience, it's often assumed to be referring to "Common Lisp"; but here and in other contexts, it might be referring to [a more generic notion of Lisp](https://en.wikipedia.org/wiki/Lisp_%28programming_language%29) instead. 
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Lisp (programming language)**](https://en.wikipedia.org/wiki/Lisp%20%28programming%20language%29): [](#sfw) --- &gt;__Lisp__ (historically, __LISP__) is a family of [computer](https://en.wikipedia.org/wiki/Computer) [programming languages](https://en.wikipedia.org/wiki/Programming_language) with a long history and a distinctive, fully parenthesized [Polish prefix](https://en.wikipedia.org/wiki/Polish_notation) notation. Originally specified in 1958, Lisp is the second-oldest [high-level programming language](https://en.wikipedia.org/wiki/High-level_programming_language) in widespread use today; only [Fortran](https://en.wikipedia.org/wiki/Fortran) is older (by one year). Like Fortran, Lisp has changed a great deal since its early days, and a number of [dialects](https://en.wikipedia.org/wiki/Programming_language_dialect) have existed over its history. Today, the most widely known general-purpose Lisp dialects are [Common Lisp](https://en.wikipedia.org/wiki/Common_Lisp) and [Scheme](https://en.wikipedia.org/wiki/Scheme_(programming_language\)). &gt;==== &gt;[**Image**](https://i.imgur.com/ISXIwhE.jpg) [^(i)](https://commons.wikimedia.org/wiki/File:John_McCarthy_Stanford.jpg) --- ^Interesting: [^Clojure](https://en.wikipedia.org/wiki/Clojure) ^| [^Common ^Lisp](https://en.wikipedia.org/wiki/Common_Lisp) ^| [^Emacs ^Lisp](https://en.wikipedia.org/wiki/Emacs_Lisp) ^| [^John ^McCarthy ^\(computer ^scientist)](https://en.wikipedia.org/wiki/John_McCarthy_\(computer_scientist\)) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+ckmcgfb) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+ckmcgfb)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Sounds like [Linear programming](https://en.wikipedia.org/wiki/Linear_programming) (mathematical theory, actually has little to do with programming). Your problem is unbound because you can set R21 and R12 large enough that they'll dwarf the other terms.
Bur R21 and 12 can't be greater than 1 because of the first two constrains and none of the values can be less than 0. Don't those constrains make it bound?
Great. I would buy one for playing with when it's on the market.
Well, I didn't notice that they are all &gt;= 0.
I think there are enough lisp-heads around to make this a likely crowd-funding project, I would contribute enough money to have one at the end of the campaign. How much money would it take to have some prototypes, to show and have them do some interesting stuff?
"What is even better is understanding that macros create a new language syntax on top of Common Lisp. I really like programming in Common Lisp... but what are you calling the language/format that your functions use? And exactly why? What is the purpose of your 'simulating (some kind of object) using functions'? You give an example, but what it does is beyond me.... I know common lisp quite a bit, but again your created syntax is creating a language which I do not know, so mentioning what it does and why it is superior to a Common Lisp style approach would be appreciated. EDIT: It is 8:27AM, so have not had my coffee yet and still somewhat 'sleepy', So I do apologize for not starting out with niceties. But,learning that macros are great and should be avoided at all costs /is/ quite important." -- http:// www.reddit.com/r/Common_Lisp/comments/2gu3th/a_cl_macro_to_build_complex_closure_generators/
Perhaps they'll release the verilog source? I've never played with verilog but this sounds like fun! Depending on the cost, I'd be very interested in picking one up.
Accidentally hid it... stupid new "pirate" links. Posting here for later retrieval. http://www.mail-archive.com/picolisp@software-lab.de/msg04823.html
According to Wolfram Alpha, the answer is 21. I entered the following search term: Maximize MIN(20a + 15c, 30b + 10d), a + b &lt;= 1, c + d &lt;=1 , a &gt;= 0, b &gt;= 0, c &gt;= 0, d &gt;= 0 
You are correct. However, this subreddit is filled with people who equate Lisp with Common Lisp. Unfortunately so.
My concern is that they haven't synthesized the design on even an FPGA yet. It's entirely possible that they've written a bunch of verilog that describes shit that can't be put on-chip, in which case they aren't really as far along as they think they are.
I was wondering about the down votes. That is unfortunate, as [Common Lisp is only one particular type of lisp](https://en.wikipedia.org/wiki/Lisp_\(programming_language\)#Major_dialects). And even then, you have [different CL implementations](https://en.wikipedia.org/wiki/Common_Lisp#Implementations). Edit: URL formatting.
Probably because it's more fun this way. I actually don't care if it's ever actually etched, but I would like to stick it on an FPGA. That would be neat!
Interesting stuff. A few blog posts on your static and dynamic CLOS, and closure based approaches - doing the same thing in each - would be an engaging on-ramp to productive discussion.
So that its turtles all the way down! Well I like the idea for its purity and experimental curiosity value, and because of nostalgia for the lisp machines I've only read about. Yet another computer architecture that is pretty much the same as the others on the market is not nearly so interesting. I wonder though - picolisp has been crafted with close attention to the architectures it has run on thus far. If picolisp can have the hardware it wants, how might that change picolisp?
Thank you very much. It's going to take time, but I'll willingly try to do it (dubitative use of "try" is due to a serious shortage of time :) Experience seems to suggest already that CLOS is a more practical approach than closures, but it's interesting anyway, as an exercise, to see how flexible a tool CL can be. 
Worst LISP I've ever seen. 
PilMCU is being discussed in r/programming. I should mention these papers: "The SCHEME-79 Chip" - 1980 - Holloway, Steele, Sussman, Bell http://dspace.mit.edu/bitstream/handle/1721.1/6334/AIM-559.pdf "Design of LISP-based Processors or, ... LAMBDA: The Ultimate Opcode" - 1979 - Steele, Sussman. http://dspace.mit.edu/bitstream/handle/1721.1/5731/AIM-514.pdf This design had concurrent GC in hardware. We could do more with less instructions, higher-level language support and HW memory management. The costs of producing custom HW now is far cheaper than it was in 1980. The problem, is now, and has always been HW adoption. :( 
I'd give them money if they open-sourced the design right now.
[**@bodil**](https://twitter.com/bodil): &gt;[2014-09-19 22:53:54 UTC](https://twitter.com/bodil/status/513098688114069504) &gt;What's the collective noun for lispers? [#strangeloop](https://twitter.com/search?q=%23strangeloop) [*pic.twitter.com*](http://pbs.twimg.com/media/Bx7kiA8CIAA8GyW.jpg) [^[Imgur]](http://i.imgur.com/DTAhx91.jpg) ---- [^[Mistake?]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=http://reddit.com/2gxmio%0A%0APlease leave above link unaltered.) [^[Suggestion]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Suggestion) [^[FAQ]](http://np.reddit.com/r/TweetPoster/comments/13relk/) [^[Code]](https://github.com/buttscicles/TweetPoster) [^[Issues]](https://github.com/buttscicles/TweetPoster/issues) 
&gt; graphically managing the artifacts that make up an application or other system. That's one aspect of an IDE. IDE's like Think Pascal (1986) provided a lot of things what you had on the Lisp Machines. For example its debugger . The Think UI was more menu/dialog driven/... though - tailored for the UI of the Mac. But Think Pascal could only edit Pascal and it had no GUI editor (one had to use Resedit for that). The Lisp Machine's provided an IDE, with a lot of GUI tools, but they often looked different from what you have in IDE's like on the Mac. Some screen shots from the Symbolics UI for IDE tools: http://www.sts.tu-harburg.de/~r.f.moeller/symbolics-info/development-environment/index.html There were integrated IDEs on top of the Lisp Machine, like Intellicorp's Kee, released in 1983. a little bit of it here: https://www.youtube.com/watch?v=5HKsbY3ZurM It had a menu driven UI, various browsers/editors, an extensive GUI builder, saving artifacts as objects under program control, ... It was a bit expensive though. Stuff looked definitely different from something like Think Pascal.
Don't trust anything that says it will give you common native GUI for iOS/Android. It's just not going to happen. Either you write your UI in HTML5 and use message passing from the mobile browser to talk to your ECL/mocl backend or you use the native UI toolkits and program your UI twice. CL on mobile is already a stretch (although mocl is gaining traction here) for backend stuff. GUI is not in the cards.
Picolisp is freaking awesome. Newlisp is another tiny, yet powerful lisp. I just wish they could compile and had more adoption. What would be the advantage of lisp all the way down?
The LispWorks editor is also a distant (proprietary) derivative of Hemlock. In current LispWorks versions it is also coming as source code. It only runs as a GUI-based editor. In former times (1987) Lucid CL had an editor called Helix, which was also based on Hemlock. What can we do to promote the Portable Hemlock a bit more? I'd like to use it with Clozure CL and also with LispWorks - but over a terminal. I'm not planning to use it immediately (currently I have some other Lisp stuff to look at), but later this year I would be interested to make it work under Clozure CL on Linux / ARM. It would be great to have a tutorial how to use, debug and hack it. I could for example present Portable Hemlock at the Hamburg Lisp Meeting. That would make it necessary first, that I make myself more familiar with it. What's the stuff you think needs work and how could one help?
I had some issues with this when I tried it a few weeks ago. Genera started ok, but I couldn't "save world" after defining the site, and I got some nasty errors whenever I tried to save anything in zmacs. I ended up doing it manually, setting up Ubuntu 7.10 inside virtual box. (see [these notes](https://github.com/marsam/opengenera/blob/master/notes/patrick-collison.txt) ). Apparently, newer versions of Xorg lack some things that the emulator requires, and 7.10 is the latest Ubuntu it will work in. 
No. I use potatoes.
The whole idea of Picolisp is based on the dynamism of interpretation (the argument that once compiled, the code is no longer Lisp), and keeping the size/number of opcodes and types in the interpreter small so that a lot of code fits into a hardware cache line and runs faster. As such, this project is a hardware implementation of the interpreter.
9,002, it's officialy over nine thousand.
As hard as I have been trying to merge Emacs+Slime with my Common Lisp workflow, I still feel a great divide. Even the recent talks about steering more towards Common Lisp do not make one feel more confident. I like Emacs, but I would love to use an alternative to Emacs that could be extended in just straight Common Lisp. How I wish the LispWorks people could regale the Common Lisp community with their Hemlock-based editor code.
It's over 9000!!!!
emacs' eshell has emacs lisp implementations of a number of Unix tools.
It is good occasion to clean Common Lisp bias from the column on the right side. There is nothing wrong with CL. But other members of the Lisp family should be fairly represented. 
Now I have to unsubscribe. I'm a hipster programer that used Lisp before it was cool. See you in /r/Scheme.
/r/lisp has 9K users, /r/scheme 3K, /r/clojure 6K. /r/common_lisp &lt;1K. So it is reasonable to assume that CL users are mostly in /r/lisp, while users of other lisps are mostly elsewhere. I think that the links in the current side column reflects this "lisp, mostly common lisp" reality of this sub (also reflected by the topics posted); links to the other lispy subs are there, anyway.
&gt;/r/lisp has 9K users, /r/scheme 3K, /r/clojure 6K. /r/common_lisp &lt;1K. So it is reasonable to assume that CL users are mostly in /r/lisp, It seems at least as reasonable to assume that just about everyone subscribed to /r/scheme, /r/clojure, or /r/common_lisp is also subscribed to /r/lisp. The /r/lisp subscription number being slightly lower than the total could easily be explained by individuals who subscribe to multiple of the dialect-specific subs (eg: someone subscribed to both /r/scheme and/r/clojure can only count as one subscriber to /r/lisp).
In theory it could be possible, but looking at years of posts, comments and votes on this sub, the reality is that most of the content is about CL. Also, this looks like the discussion on "nature of comp.lang.lisp" 2.0.
So even though its interpreted, it could be blazing fast on an FPGA?
My point is that you can't really draw much of a conclusion from those numbers either way. The subscription numbers alone are consistent with either interpretation.
[Light Table](http://www.lighttable.com/) pursues this idea.
If the chip doesn't clock fast enough or has poor memory caching it may not be so fast. It may be energy efficient though compared to a normal CPU running a software interpreter.
It is better than the old one, but some things that aren't right. 1. No mention of quicklisp. 2. The trac doesn't seem to work. 3. The page is responsive, but can be better. It's using Bootstrap but hardly any of Bootstrap's features 4. styles.css has git merge issues that's plain to see. I'm sorry for being critical, and am more that willing to volunteer to help. Is there anyone who I can PM?
IMO, this is how you give constructive criticism: targeted points delivered with tact, and an offer to help. Well done, sir/madam.
Well at least that is a plus, lol. I guess we'll just have to wait and see on this one. So once the Picolisp program is written, how is it executed differently with this system than on a regular computer? From the title, it would appear that the only difference is that the OS is in the same language that you are writing your code in. That would be pretty cool...am I missing anything else?
You are mistaken, this subreddit is not about 'the Lisp family of Languages' but about Common Lisp. Same as #lisp.
A mobile theme would be great too
I wrote my interpretation of "swiss arrows" (https://github.com/rplevy/swiss-arrows) recently: https://github.com/andy128k/cl-swiss-arrows 
Oh another project on github with a single commit and no readme.
looks cool, can you add readme and examples?
You are entitled to a full refund.
I tried this (format nil "~2,'0d" num) Where num is an integer beetween 0 and 99 It returns: "Wrong type argument: stringp, nil"
Then you are using Emacs Lisp, and this should work: (format "%02d" num)
You need to be very clear which Lisp you are using when asking for help, I defaulted to Common Lisp since that's the most *cough* Commonly used implementation. https://gist.github.com/AeroNotix/bbb2ef5fd2f202aff23a
Yep! Thanks.
I really like shen, but its makers are hiding in their caves for too long. Languages need marketing and publicity, and clojure is doing relatively better. 
Given that Lisp/Scheme's strength is regular syntax, I am not sure how I feel about so many ad-hoc syntax additions. I really like the pattern-matching and optional type checking. Anyone able to compare the type checking with Racket's contracts?
Amazing. Thank you for your work and sharing it. Looking forward to seeing more.
Also: pandas!
Really not used to the idea of something as infrastructural as a language having a proprietary licence. Either public domain or some liberal OSS licence make more sense to me, for the language proper. Maybe someone knowledgeable can explain the need of a completely new and seemingly proprietary licence.
For the most part, I like the design. In interest of full disclosure, I should mention my bend toward minimalism, and that I think of http://sdf.org as an example of a perfectly-designed website. Likely, many users of Common Lisp share a similar appreciation of elegant minimalism, so it may be worth in fact quite seriously considering finding inspiration in sdf.org, and other similarly-designed sites, specifically ones relating directly to Common Lisp, such as the CLHS, CLiki, Practical Common Lisp (on gigamonkeys) to name a few. Applause to /u/shortsightedsid for all his/her points, especially that there is no mention of quicklisp (including a download link, and perhaps a short history of asd ideation / related packages). I have only one additional primary problem with the site: * The site does not work if javascript is disabled. Most of my recent work with Common Lisp has involved the development of CL-generated internet applications, and I'd love to volunteer to help. Since I'm the second to respond to this post with expressed intent to become a part of the project, maybe the relevant information (as requested by shortsightedsid, "Is there anyone I cam PM?") should be featured prominently on the site's face. Thank you for posting &amp; for listening. I'm looking forward to the new common-lisp.net very much!
Is there a documentation/guide to the MGL and other libraries? They look very interesting but daunting in raw form.
Thank you very much!
Really sorry! I forgot to specify I was using Emacs Lisp. Next time I won't forgot it. Thanks for the help :-)
It's not like makers are hiding, they are trying their best, but not willing to compromise. Which is fine for language design, but not for the license. In every single thread anywhere people say that Shen is an interesting and unique in many aspects, and they would like to investigate it more, but don't want to because of the license. And it's not the license that matter, it's the perception that the language will never take off from its current status as long as this license is there. And, for some reason, author seems more interested in the license "rightfullness" and "justness" and simply can't see that this choice is holding the language a hostage. In the meantime, Clojure is gaining traction at a stellar rates.
Isn't a lot of this covered in PAIP?
I can't even count how many of these papers/talks I know. Every Lisp conference had one or two of those. Sill, Henry Baker has interesting points. Looks like he is nowadays active with Maxima. http://search.gmane.org/?author=Henry+Baker&amp;sort=date
I'm not claiming to be knowledgeable but I've read a bit about Qi/Shen. With Qi the predecessor language, the license to use the language was tied to owning a copy of the book. Pretty oddball. I think there is a fear that the notion of Shen will be polluted if it is opened up to approval-free forking. I also think that they're being too precious about it - if they really are onto something special that will shine through. Despite all the meditative analogies, the rights holders don't seem able to detach themselves from the fruit of their work.
If this was written 5 to 10 years ago, XML was still a big buzzword all over the place - it was the new hotness.... so putting aside any argument about the merits of XML - it does make sense that lisp should be one of the easiest languages to work in easy, innovative ways with XML. Today this seems mis-placed, because we've largely moved on from XML as a focal point..... instead we use markups more suited to our medium (usually JSON in this web based world) edit: This was written in 2005.. so seems logical. 
Just to be clear... it's not that I think he doesn't have a good point - it's that I'm sure he does and want to understand it. :) (so yeah, a video would be great) 
Heh. I'm so torn. A video would really help indeed.
Well, 10 years ago was 2005. Was xml new hotness back then? I guess ... I kinda thought it was really a thing in the 90s with a big uptake in 'enterprisey' in the 2000's. Mebbe. 
Storing it as cons cells directly?
Regarding the XML, I think the point he is getting at is that XML is the same concept as S-Exps, that is data as code. When I write an XML file for an android UI or string, that XML is parsed and transformed into an Java object exposed under the R namespace. I have seen a s-exp based syntax for XML that uses @ for attributes although it is not very popular afaik. There are also incipient attempts at XML readers like the one in [XMLisp](http://xmlisp.googlecode.com/svn/trunk/XMLisp/sources/XMLisp/XMLisp.lisp), albeit not industrial strength and mapping XML to CLOS instances only.
He has interesting points although in this format they are presented only as bullet points :( His arguments for immutable cons cells and strings are presented in more depth in this Critique of DIN Kernel. Racket has followed his opinion/advice regarding immutable cons cells.
This is a long debate in the Lisp community going back to the 60s. There were two types of editors: text-based and s-expression based. Text-based is what you see today mostly - Emacs, vi, whatever. But there were also s-expression based. Like S-Edit in Interlisp. They were available for the terminal and later also for bitmap displays. Then you would store the code as s-expressions. Interlisp had a facility to store and edit s-expressions. It could also dump them, or write diffs of those. It managed source code like in Smalltalk 80 under IDE control, but based on s-expressions. Even there the textual storage was used, but it was not visible for the developer - usually. The system loads the code behind the scenes. A full binary storage of Lisp code as data was not done, AFAIK. For textual storage, it was also added that the textual storage can store binary data (say, the bitmap of an icon). The thing one was looking for is called 'persistent heap'. A persistent heap is a storage for Lisp data, which is on disk and not on memory. Typically binary data on disk. One could use a persistent heap also for storing code as Lisp data. Lisp developers dreamt of using database-like storage for code. Lucid implemented it for their C++ system called Energize. They used the Objectstore database to manage C++ code. Apple used it in their Apple Dylan environment - the storage was a persistent heap in Common Lisp. Sometimes we see claims that managed source code / data is better or would have been better. For most people this is a theoretical option, because practically the text/char-based editors and development environments have long 'won'. In recent years this got some revival in other places with formats based on XML or JSON. There are source representations on XML and XML 'databases'. This grand vision * a persistent sharable heap * a persistent heap with database characteristics (ACID) * Lisp IDE based on code as data has never really materialized. It was kind of a dream. The holy grail. 
I suspect they're talking about an image based system like what Smalltalk has. I came to Lisp from Smalltalk and I was surprised that this wasn't already the case given the nature of the language. Lisp is more of an "imagine" language. Every new piece of code really wants to be adding to an already running base (e.g. think about macros that use user functions). In Smalltalk this is no problem because the image is always there, running. By definition, any code I add becomes an addition to the established system. Lisp, on the other hand, fights against its nature by expecting to be compiled from "dead" source files. This leads to complexity like having to control evaluation time to make sure e.g. a function that macros depend on will exist when the macros run, etc. If you've not experienced this kind of development, I would suggest downloading Squeak Smalltalk and trying to do some work. It will take a little while to acclimate but once you do you'll see the power of the approach. For one simple example, with an image based system you obviously must be able to edit code while the system is running. This includes debugging. If doing TDD, instead of writing the test, compile, run test, see problems, fix code, compile, etc. you can edit your failing code right in the debugger.
See Interlisp. Generally it is expected that IDEs like that are built on top of Lisp. With Common Lisp as a base language one does not want to be bound by a particular IDE, operating system, deployment style, ... With a proper IDE you get in-debugger editing/fixing code like in Smalltalk. Smalltalk is actually text based - the Smalltalk editor is a text editor. What Baker talks about is a system where the code is data - all the time. In the editor and a store.
Lisp has a long tradition of not operating from source files, but instead building up images interactively over time like Smalltalk does. There is also a tradition of loading source files in order to produce a fresh image with only the artefacts of interest. Both can make sense depending on the context. 
I'm not much interested in perceptions, more in realities. I've never bothered too much about what people think unless there is really something behind it. http://www.amazon.co.uk/What-Care-Other-People-Think/dp/0141030887 Anyway my post from Y-combinator "The license was introduced before Shen was issued in September 2011 (the license came out in June) and for a year or so the only specification was Shendoc (now Shendoc 16). The understanding was that Shen was specified in that document and what was not covered by Shendoc was covered by 'Functional Programming in Qi'. Later a hurriedly introduced text 'The Book of Shen (first edition)' (TBoS) was produced to fill a gap (2012) and this year (January 2014) a more thorough 2nd edition of TBoS (&gt; 400 pages) was published which fixes the language standard very thoroughly. This is currently the canonical standard. You can find a link to that book on the Shen home page. http://www.fast-print.net/bookshop/1506/the-book-of-shen-sec... Shen is now very stable and has been for nearly two years. At my suggestion, I posited that it might be better to move the standard to a computable series of tests and this was floated to the 2011 committee that is responsible jointly for all the ports. http://shenlanguage.org/2011committee.html Such a change requires the unanimous consent of all the people involved and it seems we have this and a reworded simplified license. The only obstacle is the work needed to put this test suite together. I've suggested that this suite might be assembled in Github, though for legal reasons the final version must be put in a publicly accessible but tamper-proof place. Since the type-integrity given out by the system is not better than the strength of the kernel, we take kernel work very seriously. There is already a suite of 126 tests that I run every Shen port through and 2011 members echo these tests. But this informal test suite needs to be amped up to several hundred tests to approach what I consider to be an adequate test suite. It is very boring but important work. So far I have begun assembling all the programs in TBoS into this suite. These license issues really only affect people who are deeply involved in kernel work and as far as application programmers are concerned, I doubt that it affects them much at all. As far as graphics, concurrency, FFI etc. and add-ons are concerned there are no restrictions. Likewise none on closed source work. I'll also add that I'll be asking for volunteer contributions on the Shen news group to help assemble this test suite. So people who want to expedite us here can do so." 
I don't agree completely with the last bit. Everything you do in a Smalltalk editor is sending messages. When you type some "text" into a method window, as soon as you hit save that's compiled and attached to the class. It shows up as text, just as Lisp does and it's parsed just as Lisp is but it's not stored as text.
Thank you for the explanation. I find that dream haunting. Generally speaking, holy grails tend to be nice, useful things. Of course, they need their Galahads.
Yeah that sounds right. In 2005 it was still a very popular thing though... everyone was providing SOAP/XML interfaces for web APIs, xml was used in all kinds of formats. This has since died down. 
Yeah okay.. so it's really more about having the code stored in such a way that the system can use it naturally, yet still displaying it to the user. The editor would effectively be a live-view of the running image at all times? Sort of like that? 
Thanks... that all makes sense... and the more I get into lisp, the more I get the feeling I should check out smalltalk. 
Ha, this explains that.
No; this is a misreading of non-attachment. Non-attachment is not letting people do what they want. Non-attachment is doing the right thing and then separating yourself from the consequences and accepting what comes. So if you have to go to war to protect your home, you prepare yourself and then sleep soundly without worrying. In this case, the right thing for me is embodied in the license which requires correctness. What transpires beyond that belongs to the realm of the accidental.
Indeed 
For some reason I recently got this mixed up with https://github.com/robert-strandh/SICL. I remember seeing some of your chats in #lisp about architecture and being interested. I'm really stoked this is coming to fruition. It's really cool two see two new implementations pop up in such a short amount of time.
While I agree with your definition of non-attachment, I may have misread the intent behind the license. Though its an improvement over the Qi days I do think it is having a chilling and limiting effect on adoption. To take up a parenting analogy, if ideas are like children you want them to be well formed and presentable, but you don't own them. They have a life of their own and when allowed to flourish have a way of transgressing and also transcending the parent's ideas of correctness or completeness. Parenting does involve providing protective limitations while the child is young. I do think Ki/Shen are important and that they can stand on their own feet. Do you foresee a time when a more conventional open license is applied? **Edit** I just saw your response to deverdev and will have a look at the new version of the license.
Too bad it's LGPL, otherwise exactly what was needed for quite some time.
&gt; Too bad it's LGPL Why is that bad? 
And then we can also compile Common Lisp to Javascript with this: https://github.com/kripken/emscripten ?? :)
Any chance of releasing under a more permissive license? I don't mind being required to release the source code of changes made to the library itself, but the LGPL also requires end users to be able to re-link the target program against their own changes to the library, which makes it really difficult to use on closed hardware systems, of which there are an unfortunately large number of desirable targets these days.
Thanks for the info. Fascinating. I have a question: what is the difference between editing code with text-based editor and s-exp based editor? For example, if I want to edit a single character, is there any difference? I imagine that in a s-exp based editor, it is aware of buffer content: that is, every sexp I add got parse and understand immediately by the running Lisp system, so I can perform arbitrary actions on the sexp, like sexp movement, refactoring, value insertion and inspection... Is this correct?
lmgify: gpl vs bsd E: apparently even this /r/ suffers from https://en.wikipedia.org/wiki/Eternal_September
I went with the LGPL because Clasp depends on a lot of ECL Common Lisp code (~35,000 LOC) which is LGPL, so I'm kind of stuck with it for now. If people wanted to contribute and develop clean-room Common Lisp source code to replace the ECL code and a few other things I cribbed from the ECL C code (~ 10,000 lines) and translated line by line to C++ I'd be totally up for that. I'm a really reasonable guy and an academic and I really want people to use Clasp and see Common Lisp become more popular.
"The free beer at the Lisp meeting was _Sam Adams_. Ugh." -- A thing that I actually saw happen once.
[Free is a feature.](http://www.gnu.org/philosophy/free-sw.html) Users have the freedom to run, copy, distribute, study, change and improve the software.
Nice job. Really nice. Hope it takes off. 
LGPL is not the same as GPL
Thanks! I've seen a lot of such examples over the years though. Like I think I've implied, the big difference between the THINK/Metrowerks/Microsoft/Apple style of IDE and the LispM/Unix style is the graphical management of the assets that go into building a product. (Not just GUI-builder assets, things like sources.) These days, that's a lot of what *defines* an IDE for developers: If there's not a list of the sources that make up a product, then they don't consider the thing in question an IDE. Authoring a makefile or a package/system definition doesn't really seem "integrated" to a lot of modern developers, despite the obvious power.
see LLGPL vs LGPL
I think you could put the new-in-Clasp code under a separate, LGPL-compatible license instead of also making it directly LGPL. I think the MIT license would qualify.
This must be some joke for the initiated few that I will never get...
After a bit of thinking, here's my take on text-based vs sexp-based editors: - In the beginning, text is only itself. 'c' is just 'c', 'aaa' is just 'aaa'. We simply call these "text objects". - But, we can treat text beyond just itself: text can be used as a presentation for underlying objects, such as data and functions in a dynamic system like a Lisp Machine. For example, writing code in C or shell script or whatever, a written variable in a editor/IDE is just text itself, we cannot interact. It has no connection with the actual objects at runtime. In a proper Lisp system, it should understand what underlying object the text is representing right away and allow users to interact with such underlying object right away. For example, after user done writhing this text `#p"/foo/bar/baz.txt"`, the Lisp system understands and turns such text into a filename object immediately. This can only done with a proper REPL for fast dynamic evaluation. Such empowered text we called `symbol`, and each `symbol` represents exactly one object. - Because of such property, a Lisp system can keep track of objects represented as text (we call this Lisp symbol) in real-time. Any text entered that matches an existing symbol in the system automatically becomes interactive, i.e. you can inspect and modify its value. Since the Lisp system keeps track of all symbols that way, we can perform query like which uses a function where, finding definition, create call diagram... as much as the system can reflect itself. - Underlying objects can have multiple representations: symbol - textual representation - is one of them. The objects can be represented by its binary form such as image, sound or its actual binary image when compiled. For example, consider a list: `(banana apple peach)`. The symbols inside the list can be switched to images: once switched, the Lisp system displays image inside a pair of parentheses; or sounds: the Lisp system automatically plays the sounds of symbols inside the list. Or we can see the actual binary representation inside the system. And we can modify all of them at will, in any representation. - Because of multiple representations and realtime tracking, a Lisp system requires a database to effectively track things. - Because of these properties, there's no disconnection between source code and runtime system, thus no distinction between compile time and runtime. Compiling is just a form of caching. - The whole system is a real development environment in the sense that the whole system can reflect itself.
I look at the first slide and my first thought is "I don't like this, it doesn't look like Lisp. Why would you use this syntax: (define welcome X nil -&gt; (output "Welcome to ~A" X) X Y -&gt; (output "Welcome to ~A and ~A" X Y)) when you could do something like this: (define welcome ((X nil) (output "Welcome to ~A" X)) ((X Y) (output "Welcome to ~A and ~A" X Y))) Then I see the second slide. Why would you want this: (define is-positive { number --&gt; boolean } X -&gt; (and (number? X) (&gt;= X 0))) when you could do something like this: (define is-positive (type-check (number boolean)) ((X) (and (number? X) (&gt;= X 0)))) Or whatever. This seems to be something a bit like Lisp made by people that don't get Lisp. 
Maybe they just abuse reader macros to do ad-hoc parsing ...
&gt;Maybe they just abuse reader macros to do ad-hoc parsing ... That would make me *quite* unhappy. 
Have you read On Lisp and Let Over Lambda? Because you should read them. On Lisp intentionally leaves CLOS for last because it's not actually that important, and seems far far far less magical once you understand Lisp properly. 
It's probably easier to use pcre if you are going to do fancy stuff, but this should work: (format nil "~{~A~^th~}" (split-sequence #\s some-string))
I think python has a built in str.replace() method or something along those lines. I know there are a couple of libraries you could google. Common Lisp probably has one as well, but if not you could always write your own function to handle this. The input variable would be a string or list of strings as well as the character you'll want to replace and the character you'll replace it with. You would pass this to a for-loop that would loop over each character in the string. Each character would be compared against whatever you want it to replace. If it is a regular character just add it to a variable. If it matches what you want to replace, do the switch and then add it to that variable. After the loop finishes print the output. If I remember tonight I'll try to write you an example in picolisp or newlisp.
A Soul can't be examined scientifically, it's beyond science, sorry... Why do you think so many Religions still exist, and are ever growing, despite the fact the science reaches new goals every other year already?
So if a "Real Soul" isn't something that can be defined how can you possibly use it's presence as an excuse as to why stuff made of "dead material"(whatever that means) can't be conscious? Your'e making a factual argument then saying it can't be debated because the facts can't be defined? The fact is, we haven't cracked consciousness yet, we don't fully understand it. We have no reason at all to think that the right pattern can't be conscious, whether electronic or biological or.. whatever. 
Science is science, and limited there. Religion is everything transcendent (beyond science). Nothing more to say...
1.2.5 will have basic IPv6 support.
Is it able to compile itself properly at the moment?
"Except for PHP tr can compile itself to all other targets."
&gt; LGPL is most probably just like any other "free" license. http://www.freebsd.org/doc/en_US.ISO8859-1/articles/bsdl-gpl/index.html All-n-all, I'm just glad to see something like Clasp to come into existence, licensing (and reddit's collective butthurt) concerns aside.
This is cool. I have a fantasy for a lisp that can be compiled to any language that uses a template to extend it to any other language along with tests that must pass in order to insure that it works. The template would work like this: ;; javascript.template ;; What is the addition operator? + ;; What is the statement terminator symbol? ; ;; What is used for single line comments? // ;; What is used for multi line comments? /* */ ;; What is the language equivalent statement to if in lisp? if (predicate) { return true;} else {return false;} etc. Some of the tests would ensure that garbage collection is working ok. Anyhow, just my fantasy! Cool project. 
Fails to compile under Arch Linux 32 bit (didn't try 64 yet) despite having lib dependencies on page installed.
Actually, I just hit /r/Random and it brought me to the Lisp subreddit, and I decided that I'd make a joke about the name of the programming language. Because if you change all the 's' and 'c' characters to 'th' characters, then you end up with a thententh that'th a lot like thith. 
I'm very bad with gcc search path and host os libraries. Headers are in /usr/lib/libffi-3.1/include .. by adding symlinks in /usr/include I got ./make.sh boot working enough to fail on php transpiler code. I don't know if libffi should add itself to /usr/include by default or not. **edit** : or simply patch make.sh to add "-I/usr/lib/libffi-3.1/include" to gcc flags somewhere ./tre loads but fails on (defun id (x) x) .. that's where I'm at.
I do dream of transpiling lisp everywhere. Right now there are many javascript transpilers, pharen for php, hylang for python.
Do we really need these posts each time there's a point release?
The votes don't lie.