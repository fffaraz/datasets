A straightforward approach to what (I think) you're doing is to use a clustering algorithm like [K-Means](http://en.wikipedia.org/wiki/K-means_clustering). You want 12 colors? Use 12 clusters. Also, I'd recommend converting to a color space that more closely approximates human vision, like the [LAB color space](http://en.wikipedia.org/wiki/Lab_color_space).
[This](http://www.reddit.com/r/IPython/comments/1fm5hd/lectures_introducing_scientific_computing_with/) might be what you are looking for.
http://orange.biolab.si/
You've spent more time raging about this guy than you did reading his post. He doesn't work for Zappos, btw. He works for a company called Pipewave, which was recently acquired by a company called Zefr. http://www.crunchbase.com/person/jonathan-tushman As far as I can tell there's no connection between him and Zappos other than maybe being an overzealous fan of their socks. Considering the recent acquisition of his company though, I'll bet he doesn't give a shit about zappos sponsorship. He wants some attention, fine. So does half of this site. How has your contribution (name calling, and pitchfork grabbing) made things any better? Have you now solved the problem of attention seekers posting on reddit? Or did you just make an elaborate set of offensive accusations with no evidence but loads of suspicion? Essentially, have you made this place better, or have you simply demonstrated that not following our rules you'll be treated with irrational hostility?
I've never tried using multiple package managers on a mac but I presume it is likely to cause difficulty, I am sure it will if you are installing multiple instances of the same software with different tools. You'r post was not clear about where you were running into the problems, because for instance, pygame does have libraries for python 3+. Like others have said most things have been updated, so I was wondering if something else was getting in the way. From the python side as in do you have your $PATH set up correctly, from the side not of dealing with your OS, but of how to utilize the libraries from python. A lot of the time getting your tech stack working smoothly will be a lot of the work and will always be hard to just learn from a textbook. Dealing with an individual implementation constrained by the real world is always more difficult than writing code that works in an isolated environment. By their nature any kind of interface library is not isolated. Not my cup of tea personally though so I'll bow out. Good Luck
Check out [12 Factor](http://12factor.net) for a detailed explanation of why to use env vars over config files.
Correct. That is exactly what I meant. It enables more. 
" how to use Python with databases" is really generic. I mean, you can start with the [SQLite3 module](http://docs.python.org/2/library/sqlite3.html), which is builtin into Python. It's mostly "write everything from scratch". You'll also notice that there are some connectors to others databases, like [DBM](http://docs.python.org/2/library/dumbdbm.html) and [lots others under "Persistence"](http://docs.python.org/2/library/persistence.html). Now, if you escape the default modules, you have [SQLAlchemy](http://www.sqlalchemy.org/), which is an ORM for relation databases (and Canonical have [Storm](https://storm.canonical.com/)), not to mention [Django own ORM](https://docs.djangoproject.com/en/dev/topics/db/). Apart form relational databases you also have [MongoEngine](http://mongoengine.org/) for MongoDB and [Cassanda-DBApi2](https://code.google.com/a/apache-extras.org/p/cassandra-dbapi2/) for Cassandra. (And all those are the ones I know, there should be more around). So... did they mention anything else?
Even though I am not a windows user, let me disagree. Check out this link: http://womunix.wordpress.com/2012/07/12/cygwin-xterm-256color-mintty/ Update: and this is probably what you want. enter conemu: https://code.google.com/p/conemu-maximus5/wiki/Screenshots
https://pypi.python.org/pypi/scikits-image utilizes SciPy (and thus NumPy) for [digital image processing](http://en.wikipedia.org/wiki/Digital_image_processing). 
https://github.com/python-imaging/Pillow/blob/master/tox.ini
The Foundry have had PySide in their applications for a while and Autodesk just added it into Maya 2014. Autodesk being huge on backwards compatibility most likely won't let it die and there are also a lot of other companies in the vfx biz using it. I am pretty sure it will stick around for quite some time. Maybe forked because of PySide trademark if that cant be resolved.
If ORM, relational database systems, or SQL sound Greek to you, then you will have lots to learn. LyndsySimon is correct, working with databases using Python would be the least of your concern. There are layers of technologies and terminologies you will have to be familiar with first. If you are completely new to databases, I would start off learning how to work with relational databases and so you would need to learn SQL. Then proceed to decide which database software to use. I would start off using Sqlite3 first and maybe find a GUI client for it. I would suggest Sqlite Studio. After you have progressed some and want to check out more complex databases like MySQL, you'll have to familiarize yourself with database drivers or connectors. If you think you'll be working with mainly Windows OS, then you also need to familiarize yourself with ODBC. I would play around with sample tables that comes with MS Access. There is a Python module called pyodbc which you can use to connect to ODBC data sources. Anyways, I'm tired right now and can't think of anything else that I would suggest further. Good luck!
I have been stuck on the part of the net still stuck in 2.7, for some reason. Every time I asked for help, google-fued, the answers were old and I was expecting new ones. 
I got it working. I made a pretty big mistake, but it was mostly me missing information. 
NumPy *is* fast for matrix operations.
We're currently using nginx and uWSGI with emperor/fastrouter as well, along with a few scripts to help deployment. So far it's been great, low resource usage, and very flexible for each site - but I'd like to improve on it to make deployment as easy as some of the PaaS providers. It feels like there's a bunch of people trying to provide their Python PaaS solution, but not that many people providing the solution for others to use. Sometimes we get some of the tools which can build part of it, but there's still a significant amount of effort in bridging the tools together. 
The result of your filter looks awfully similar to a [posterization filter](http://en.wikipedia.org/wiki/Posterization), which can be performed in O(N) time. I know your filter is different (since its basically generating a palette of "good" colors to use, rather than doing a naive bit depth reduction), but I thought I'd point out the similarity. Couple notes: - Why is the image being scaled to 4x the size, then back down to the original? Seems inefficient. If you're looking for a blur or smoothing type effect, surely there's a better way to do that (eg: median, gaussion blur, bilateral, or something similar). - HSV or LAB would probably be much better colorspaces to work in for this. RGB really isn't well suited for finding color palettes. - Performance could certainly be improved. I'm not entirely certain what the Big-O running time of what your current algorithm is, but it *should* be possible to do this much faster. Currently, it looks like you're iterating over the image once for the size of your palette... What if you generated your color palette in one image pass, by throwing colors into a palette bucket and replacing the bad colors with better ones (or possibly applying k-means like others suggested), then did a second pass to apply the palette to the image? This is where HSV can be nice, because you can create a bucket of say 12 hues with 2 saturation/value levels each (12x2x2 = 48 colors). Nice work so far, but you should definitely explore improving the running time of your algorithm before trying to implement it in C. It took over 1 minute for it to process a 500x500 image on my laptop, whereas it should be taking no longer than 15 seconds, even assuming a pure python implementation (posterization on the same image takes about 2-4 seconds for me, in pure python).
[Depends what it's compared to](https://modelingguru.nasa.gov/docs/DOC-1762), but in general yes.
Ok, so the common appearance is probably due to reducing the colors to a noticeably small palette.
Numpy was about 9 times faster for the test image I used (70s vs. 8s). http://pastebin.com/CzJ88rq4 Spent way too much time on this because of a buffer overflow error that [numpy doesn't check for because of performance reasons](http://stackoverflow.com/questions/7559595/python-runtimewarning-overfow-encountered-in-long-scalars), so there is no warning whatsoever, making it pretty difficult to discover if you don't know about this behaviour already: In this case, numpy.asarray() returns an array with dtype numpy.uint8, so it's not a good idea to subtract from that array if the values could become negative.
This is really cool. Time to get kind of off topic and impractical: Someone should make a statically typed fork of Python. I don't mean to sound like a troll. Python is my favorite language currently; I use it at home and at work. But I feel like the biggest source of frustration I have using Python nowadays is the lack of a static type system. Whether it's because it makes undocumented library features that much harder to puzzle through, or because it means typo errors and other nonsense doesn't get detected until sometimes as late as an acceptance test or even just futzing around in a big project if you have subpar coverage... I've been trying to adopt Scala or Haskell for this one single reason. But Scala has some weird syntax, and Haskell is... well... a bit hard to swallow. On the other hand, Python is an extremely easy language to learn, has sleek and minimalistic syntax, and is just an all-around gorgeous and fun language. The only thing it leaves me hurting for is typing. I know it would end up conflicting with some features I love about Python, such as dynamically named functions (e.g. ``render_FOO`` methods in ``django_tables2``), and probably metaclasses as well. I DON'T CARE, MAKE IT HAPPEN INTERNET PEOPLE!!
If I recall correctly, there's already some JIT compiler annotations that you can use to declare parameters of a function to be of a certain type. But it's generally seen as static types belong to Cython and parts of Python you do in C. 
[Cython?](http://www.cython.org/)
SQLite is built in to Python3. Learn SQL the hard way has a SQLite tutorial.
Dude I am on the static train. Scala's syntax is not weird. You just have to realize it is all sugar. Once you connect what's happening under the hood, it is like... gravy. It's just all OOP masquerading as functional. It's super awesome.
I was already using ConEmu... I didn't know it had a different ANSI interpreter. It seems the problem was with [Take Command](http://www.jpsoft.com/)'s ANSI interpreter. Well, actually the console still doesn't display 256 colors, but it's a decent replacement.
yeah. It's very inefficient, and this was made in less than an hour just hacking it together.
This may be of interest. http://www.psychopy.org
You mean like Boo? http://boo.codehaus.org/ They liked the syntax of python, but wanted static typing - and threw in running on the .NET / Mono VM (and soon JVM) while they were at it.
Can you specify any number of optional arguments for the individual dispatch functions? Like the verbose argument
Cool, I wanted `pprint.pprint()` to be customizable for a long time. However, why does `singledispatch()` always require a function for the `object` type? I want to write like spam = singledispatch() @spam.register(int) def _(obj): pass @spam.register(str) def _(obj): pass instead of @singledispatch def spam(obj): raise Exception() @spam.register(int) def _(obj): pass @spam.register(str) def _(obj): pass
Well, Python isn't exactly close to Haskell's type system either...
Because you need a fallback function that applies when all the other options fail.
Whilst I'm not myself convinced about wanting static typing in Python, you might want to check out http://www.mypy-lang.org/, which I think is trying to do exactly what you want.
Thanks for reminding me of this one. Mypy is also a lot more interesting now that they are aiming for 100% compatibility with vanilla Python syntax. It might actually turn out to be a very useful tool and not just an interesting experiment. http://mypy-lang.blogspot.co.uk/2013/04/pycon-update-python-compatible-syntax.html 
Try Yahoo Finance: http://finance.yahoo.com/
Thanks. I made a post about it [here](http://ubuntuincident.wordpress.com/2013/06/05/syntax-highlighted-less-in-command-line/), with specific instructions for Ubuntu.
.. I saw Boo as an option in Unity and was told it's "sort of python?" - but this actually sounds *good*. 
Thanks, Lyndsy!
Congratulations for your awesome effort! PS: How about HttpCore?
Other people would expect an implicit default to be a no-op. So we refuse the temptation to guess in the face of ambiguity. More importantly, singledispatch also uses the default implementation to provide the docstring, name (and qualname), annotations and __module__ for the generic function.
&gt; Other people would expect an implicit default to be a no-op. Who are these other people? An implicit no-op default doesn't exist in the other languages I am familiar with (C++, Java, C#) and it doesn't make sense given the mathematical definition of a function either (in that if the input is invalid, there's no attempt to define an output).
I would love for python to have TypeScripts (optional) type system. Especially structural typing is such an awesome feature.
Thanks to Mark Steve Samson (http://marksteve.com) who created the WerkzeugAdapter, you can now use the Authomatic authorization / authentication package with Flask and any other Werkzeug based Python framework.
Hello, [PythonAnywhere](https://www.pythonanywhere.com) dev here. I think the reason no complete package exists is because the the extra bits and pieces (above virtualenvs and linux containers) that make everything work are only really required at very large scale. You probably don't care about making a large cluster of servers appear like a unified machine to thousands of different users. unless that's actually what you are doing. It is just overkill for a single developer. It's also very tricky to successfully package that up and open source it. Hats off to dotcloud for what they've done with docker.io. They had a really clear idea about a defined part of their stack that they could pull out, that was useful without the rest of it. 
Try Go. It's a different language, yes, but around the time I found myself tempted by Cython, I ended up trying Go and it fit all of my needs. Go is very easy to learn from a Python programmer's perspective. 
RPython: a statically typed subset of Python https://code.google.com/p/rpython/ It's what PyPy uses for JIT-ing.
Others have mentioned the likes of Cython and Pyrex, but limited type inference would be a nice feature to be able to switch on in the language.
Now throw in [numba](http://numba.pydata.org/) for an extra kick in the pants.
Thanks!
Wanted: C-level multithreading experts (see post)
I've recently came across your book in my search for a good Django tutorial and TDD. I'm just a few pages into the first chapter but it reeks of massive potential. Hopefully you could include a section on strategies on how to incorporate tests to an existing Django project. Keep up the good work and hopefully those knowledgeable around this area will hear your plea. I would've if I was good enough :D
Raise an exception in your "fallback function". Since this is Python, you can later overwrite it with a "real" fallback function at will.
Explicit is better than implicit.
I know how I would do it. I'm just saying that I don't see a good reason to have to write a fallback function here when a more reasonable implementation would seem to be to make the fallback explicit, if you want one (and you usually won't).
Why thank you! Talking about existing projects is outside the current scope of the book, but it's such a popular question that I'm thinking of including an appendix on the topic... My problem is that I've only really retrofitted TDD onto an existing project once, so I'm hardly qualified to talk about it... Still, I may be able to get someone more knowledgeable to contribute some thoughts... If you want my brief tips straight away: - try and use tdd whenever you need to make new changes to the code. that's one way to start growing test coverage organically. especially for bug reports, make sure you have a test case each time. - When looking to start retrofitting tests, start with functional tests -- they tend to give you an immediate benefit in terms of protecting you from regressions, giving you that reassurance that you haven't broken your app whenever you add new code. - start with the most important or "core" parts of the site - use unit tests whenever you find yourself refactoring -- write a high level one, then progressively write lower and lower level unit tests, which will help to drive good design in your app... that's as much wisdom as i can muster from my limited experience!
I don't like having a callable that works for some types but not for others with implicit behaviour for the types with which it doesn't work. That's why I think explicit is better in this case.
The book looks great! I think I'll start with the web version, then buy it when it comes out. Just in time, i was looking to start learning Django after having studied python for the last 6 months. Thanks!
I don't see how that makes sense, because it already effectively exists. eg.: def format_my_string(text): for s in text.split() print("Substring '%s'" % s) Call that with a byte string, and it works. Call it with a unicode string, and it works. Call it with a dict, boom, exception raised. If anything the existing behaviour is more implicit because you have to know what types the function accepts. With single-dispatch generics the accepted types are right there in the decorators.
If a type is re-registered, is it replaced, ignored, or an error?
Could you include something more general for those who don't use Django ?
In hogeplyo's example above, the behaviour of `spam` is explicit when called with an int or str but implicit when called with another type. I think the behaviour of `spam` on other types should also be made explicit, and not hide inside `singledispatch`. This is why I prefer the second example in hogeplyo's post. Nobody should be downvoting you for presenting a dissenting opinion in a rational way.
A solution in search of a problem.
It's a valid problem. It's actually so prevasive that some languages address it directly http://en.wikipedia.org/wiki/Multiple_dispatch The only mistery is why to call it "single dispatch". Single dispatch is exactly what this approach is trying to overcome.
I think we just disagree over how to interpret 'implicit'. Sure, there's no explicit code showing what would happen if I call `spam()` with some other type. But there's also no explicit code showing what happens if I call some other function like `eggs()` with any type. The state space of programming is implicitly, by default, to emit an error for everything, and you carve away explicit exceptions to that, bit by bit. It feels like if I define a function for ints, and an overload of that for strings, I shouldn't then have to go one further and 'undefine' it for everything else - it was already undefined.
http://www.reddit.com/r/Python/comments/1drv59/getting_started_with_automated_testing/c9tfxgd http://www.reddit.com/r/Python/comments/1bx3vj/how_are_python_apps_deployed_to_production/c9b5tea
https://en.wikipedia.org/wiki/Software_transactional_memory#Python
Try getting it from the source: https://github.com/numba/numba Or install the anaconda distribution: http://continuum.io/downloads.html This library is being developed by Continuum Analytics under a multi-million dollar grant from DARPA. I have trouble believing it simply "doesn't work at all" unless the issue is on your end.
Try this you-tube intro to python and mongod database https://www.youtube.com/watch?v=FLIEJt6IymY be mind-full of the python version being used 2 or 3 and the projects final output needs. there is a large learning curve so have time available to research what is needed 
Are you talking about function annotations. IIRC, those don't do anything at all.
Yeah I was wrong about a lot. For some reason, every time I asked a question on google it would send me to an old post from StackedOverflow, or send me to the 2.7 tutorial for Python, or when talking about GUI libraries it would mention PyGame, wxPython, and EasyGUI. Things that are outdated. 
for web testing look at selenium too: http://www.infoq.com/articles/Tutorial-TDD-Selenium or web driver: http://www.slideshare.net/alimenkou/tdd-in-functional-testing-with-webdriver the idea is that it's browser-based functional testing
I'm a little disappointed honestly of how wordy this solution looks. Erlang for instance does it with less verbosity: get_css(gray) -&gt; "gray.css"; get_css(blue) -&gt; "gray.css"; get_css(_) -&gt; throw(somethingsomething). Do we really need all those decorators etc? Seems like it would be much better to just bake it into the language properly.
Good suggestion, thanks. Ultimately, I'm trying to teach TDD, not Django, so the theory is that it shouldn't matter that I've chosen Django, the TDD lessons are the same. In practice, that's not quite true. Django, as always, is quite opinionated, and ends up influencing some aspects of how you test... I suppose half the focus of the book is on functional testing and selenium, which should be independent of Django -- although even there I transition half-way through to using the Django LiveServerTestCase to run Fts, which is a bit Django-specific. I may yet back out of that decision, since it creates as many problems as it solves. When I move on to talking about JavaScript, then the choice of web framework will be totally irrelevant. So I think I'll say -- I have to choose *a* web framework, and Django seems the natural choice, but I think I'll try consciously to reduce how Django-specific all the examples are... Another thing I could do is include an appendix, maybe, on "testing outside the Django world", which would talk about what the alternatives are to all the Django-specific things? Eg, how to roll your own unit test runner, functional test runner, etc... Do you think that would be enough to make it feel like less of a Django book? 
I like that link on "what are functional vs integration vs unit tests". I definitely conflate unit tests and integration tests, and I think I need to draw attention to that...
thanks. I mentioned that I use Selenium as my first bullet point in the description, and I use Selenium in the very first test I write in the book.
`qnew` creates a new patch (`hg help qnew`) with [Mercurial Queues (hg mq)](http://hgbook.red-bean.com/read/managing-change-with-mercurial-queues.html) ... which are also supported by the [TortoiseHg GUI](http://tortoisehg.bitbucket.org/manual/2.8/) 
So this is basically polymorphism. Is dynamic typing a bad thing after all?
I've been having ennui with Django lately. I've used Flask a few times for "micro-projects" (&gt;200 lines) and really enjoyed it. I've been considering using Flask to make fully-featured applications. my main reservations are the lack of admin panel and the pluggable middlewares, especially auth. as a whole, how have you found Flask to stand up with regards to plugins, middlewares, etc?
OpenSesame is also an option.
Sorry, you ought to try /r/learnpython.
Your tutorial on TDD with Django was my very first foray into test driven development, and I'd like to thank you for it. I can't wait to see the book! As for what else I'd like to see, two things spring to mind: * Personally I find using the Selenium bindings a pain, and I've found Splinter to be much friendlier for writing functional tests. I would like to see a chapter that covers that. * I discovered Cucumber last year and used it on a PHP project. There are a couple of Python ports of Cucumber, and I've found Lettuce to be particularly good. Any thoughts on covering one of these BDD tools?
People call PyPy "Python written in (restricted) Python". Is this the first time that a large piece of PyPy is being written in C instead of RPython ?
Great! Let me know if you ever run into any problems, or if you find any of it a bit confusing, or you think things could be presented better...
For the lazy, and OP http://sql.learncodethehardway.org/
... for FreeBSD's libpkg
The function is not defined for any types implicitly - it's *undefined* for all other types, the same way that `len()` is undefined for all types that don't have a `__len__` function or similar. I'm surprised that people (presumably not you) think that this notion is controversial enough to downvote, considering that it's the status quo in various other languages and hasn't been considered a bad idea.
Because it *is* single dispatch? It's not trying to overcome single dispatch, only remove the limitation that you can only dispatch over objects of classes that you defined. To elaborate, while class C: def f(self): pass gives you a method `f` with single dispatch, the `self` argument has the restriction of being of class `C` or a subclass thereof. If you want a function that has a different implementation depending on whether its first argument is an `int` or a `float` then this facility does you no good. EDIT: It also requires that every implementation fit into your inheritance hierarchy which often must be overcome by writing stupid crap like adapter classes. 
I'm used to functions in Python being either defined or undefined. In other languages - C, for example - if I've written an overloaded, single-argument function with signatures for either integer or double inputs, but then I pass it a character, it's obvious that (ignoring typecasting) this should fail. In Python, the norm is for a function defined once to accept inputs of any type. So I'd still prefer for "undefined for all other types" to be *explicitly* undefined for those types (for example, by explicitly defining the default implementation to raise an exception). I don't like the idea of a partially-defined function, is all. I think we respectfully disagree with each other on the matter, which is fine by me. =)
It *is* a gross hack: something this important deserves dedicated syntax.
FWIW, [WebTest](http://webtest.pythonpaste.org/en/latest/) is a framework-neutral functional testing library for Python; works with anything that supports WSGI (including Django), and with just the slightest tweak (using `webob.client`) it'll work over HTTP too. If doing "TDD" I usually start with a functional test that simply hits the URLs I expect to exist (and with WebTest getting a URL implicitly means you expect a 2xx or 3xx response code), and work up from there.
ok, I see. I have misinterpreted the author's intentions then.
Thanks. Going through the instructions on github brought the same segfault, but anaconda worked. With numba, the nested loop is about 5% faster.
Asking a language-specific subreddit if their language is the right choice is a poor idea in general, but while you're here and since I'm opinionated on the topic I'd like to make sure you're aware of [this essay](http://me.veekun.com/blog/2012/04/09/php-a-fractal-of-bad-design/).
It was an interesting read until they quoted Ubuntu code of conduct.
It depends on the team (eg: how much experience do they have and in what areas), the project and the company I would say. You gave too little information to get an objective and useful response. 
PySide is not dead. The last commit on the source repo was about a week ago. [They are also in the process of securing funding for more development](http://lists.qt-project.org/pipermail/pyside/2013-March/001173.html). PySide doesn't yet support Qt 5, so if that's really an issue, OP should go with PyQT. However, the licensing for PyQT is not as permissive to the developer, so if OP wants to sell something made with Qt, PySide is the better of the two.
No, there's already a bunch of C code in there. Mostly in cpyext and rpython/translator. sloccount says: python: 999878 (94.70%) ansic: 43187 (4.09%) asm: 5020 (0.48%) cpp: 3268 (0.31%) cs: 2061 (0.20%) java: 1922 (0.18%) xml: 353 (0.03%) sh: 89 (0.01%) lisp: 45 (0.00%) BTW, 999878 lines of Python makes me totally want to submit a 122-line patch.
Ah, very cool! That whole package of scripts looks handy.
Python, we've been friends for a while. But this is a step too far. I'm not mad, just disappointed.
Ignoring for a moment all the arguments about PHP being bad, and just speaking objectively, I find everything about PHP to be overly cluttered, verbose, and generally hard to read. Add to that the noise of Symfony or Zend, and you've got huge, unweildy, hard-to-parse files full of routes and controllers and whatnot, scattered throughout endless subfolders of subfolders 8 levels deep. On that principle alone, Django is a huge win. For smallish apps, you can keep templates together in a single directory, static assets in another single directory, models all in a single file, and views in another file, and instantly find your codebase cleaner, more navigable, and easier to understand. Of course for bigger projects there's nothing stopping you from adding "apps" or putting modules in subdirectories... Python/Django also gives you access to venv and pip, which gives you a great deal of control over your app which is unavailable to you from PHP, and protects your code from the whims of system administrators and differences from this host to that one. Oddities in PHP have a tendency to cause even the simplest of tasks to generate excessive boilerplate where other, more well-designed languages don't need it. And python's exception-handling and built-in logging will make you wonder how you ever managed to debug anything in PHP. If you're already considering a move from the framework you have, then you've already accepted a big task and there's no reason not to consider a switch to a better language.
In my experience all download sites are different, so it makes it kinda hard to write one library to work with everything. If it's a python library you might be able to get it our of pypi, otherwise you probably want to look at beautiful soup or something for parsing the download page and requests/httplib/httplib2/urllib2 for doing the download.
Thanks for sharing! Will the read online version be taken down?
Thanks for running the experiment :) I haven't actually tried numba yet (and clearly I'm very, very lazy) but all the things I've read from continuum make it sound like they think it's some really hot shit. Guess numpy already sped things up plenty in this case.
Thank you for the suggestion! The idea for my project would be something that would start automatically upon boot of the Pi or Beagle. The device would boot directly to a movie that is being controlled with Python. Would I be able to boot directly into vlc and control it with Python? Or does vlc have to be manually opened by someone and then connected to via Python? That's why I thought a library/module would be the best choice. But when I look at something like Pygame, it has some movie control, but not enough. So was hoping there was something out there with more video control options that was all in Python. 
It is replaced, just like a method in a subclass silently overrides a base method. Ignoring would lead to strange behaviour, raising an error would limit usefulness of the registration mechanism. Either way, if anything strange happens, you should debug using dispatch(your_type) to see which implementation is chosen. Any call to register() changes the dispatch. You might get a different implementation than you expect, not only because one was overwritten, but also because a new one for a base class (possibly abstract) was registered and it suddenly matches.
ok no worries mate - looks like I'll roll my own. No troubs.
I would say just build it yourself on Flask. That's what I'm currently (when I find the time) doing. Use SQLAlchemy if you don't want to deal with the database, SQLite if you want to keep things simple. Consider using [CKEditor](http://ckeditor.com/) or similar for an nifty blog editor. Edit: You can also use it as an opportunity to learn how to build things like an admin/authen component and play around with other features you feel you want. 
Will do, thank you!
Have you considered using a static site generator like [Blogofile](http://blogofile.com/) or [Pelican](http://docs.getpelican.com/en/3.2/)?
A friend pointed me toward Pelican and Nikola. Both look interesting. I don't have any experience with static site generators so I'm reading up on them and nginx.
I'd buy this book for the Selenium stuff alone. I really need to learn that stuff. I'd have preferred if you had chosen a micro-framework (Flask?) instead of Django because they're much easier to learn if you've never used them. Here I'll have to learn Django (which I don't intend to ever use) just to learn TDD. In any case, I congratulate you on the endeavor. Do keep us updated.
RPython is translated into C and then compiled using `gcc`. FTA, he says that RPython isn't good for "delicate multithreading issues", so moving both the GC and STM to C and then having them linked in after translation makes sense. 
Please provide more information. Do you plan on rewriting all your code, or only using Python for new projects? How much interoptibility will you need between your new Python code and your existing PHP code? We can't really provide informed advice without knowing this. This is /r/python, so we all probably feel that Python is "good" and PHP is "bad." However, keep in mind that rewriting code is expensive and should be avoided without some clear benefit. Unless your current code base is an innavigable tangle of hacks, there may be no justifiable reason to rewrite it. "I like Python better" is not a good enough reason. "Python will let us do X, Y, and Z and save time and money in the long run" might be. Think about what you actually hope to gain by switching. Even if you don't plan to rewrite your existing code, think about what other costs there might be in switching. How much experience do you and your fellow programmers have with Python vs. PHP? If any of you will have to learn the language, that is expensive for the company. Also, if some of your PHP "experts" are only Python "amateurs," that could reduce the efficiency of your programming team. That is to say, there's a lot more to this question than "which is better, PHP or Python?"
We are considering switching to a new language/framework (Python/Django, Ruby on Rails or some other), mostly for new projects. No interoperability. I know people here will be biased, but I was wondering if you guys could tell me some selling points of python. I already know PHP, its advantages and disadvantages. It's a somewhat small team of developers, with no previous experience with Python. We know the hassle of switching languages/frameworks, but we are entering a new stage of development and we'd be willing to grow together. If we see benefit in a new technology for future projects, now would be the time to check it out. We are currently studying the options and the folks from /r/php gave us some excelent advice (mostly on Zend Framework 2). I figured I'd check with you guys too.
Explained on the same blog a few years back http://morepypy.blogspot.com/2011/08/we-need-software-transactional-memory.html
How does this work with http://andreacensi.github.io/contracts/ and/or http://www.python.org/dev/peps/pep-3107/ ?
virtualenv/pip alone are good selling points. It was always a nightmare to get an entire dev team synchronized to the same versions of all dependencies which then made deployments interesting "Oh were still on 5.2? Crap maybe I should have used those input validators only available for 5.3" or the inverse "It worked in 5.2!!! No I didn't get the email or hear you repeating everyday for a week that we were going to 5.3"
A function has a [domain](http://en.wikipedia.org/wiki/Domain_\(mathematics\)) and a [range](http://en.wikipedia.org/wiki/Range_\(mathematics\)). I didn't ask for this! I choose not to add this unnecessarily confusing complexity to my code OR application. Who wants to edit the style guide!? It even says in the [PEP 20 - THE ZEN OF PYTHON](http://www.python.org/dev/peps/pep-0020/) Explicit is better than implicit. Simple is better than complex. ... Namespaces are one honking great idea -- let's do more of those! 
- Python has been called both "executable pseudocode" and a beautiful language. It's very easy to learn and is being to be used in intro level CS classes. - The indentation takes some getting used to. However, you'll actually discover it a huge plus when collaborating with multiple developers because everyone's whitespace is identical which makes code much more readable. - Namespaces and objects are core parts to the language, rather than grafted-on afterthoughts. - You'll never have to recompile PHP to include another module again, just "import &lt;whatever&gt;". - I run a software development shop. In my experience, developers who know/use Python are of higher quality than those looking for PHP jobs. You'll be able to attract better talent to your company by using better tools. I'm sure PHP guys will take exception to this statement, but this is my honest opinion based on the real world. - PHP is a web development language. Yeah, you can use it to write command line scripts and even desktop GUI's if your *really* want to, but doing so gets really clunky. Python is a general purpose language that can be used for a wide variety things. Even pure web devs need to write stuff like scripts run from cron jobs and code deployment. This is about 10x more sensible to do in Python than PHP. - Multithreaded and multi processing capabilities. Ever need to make a curl() call to screen scrape websites, or maybe you need to do a lot of processing on image files? You can process 10's or 100's of tasks concurrently by using multithreading/multiprocessing. Trying to do this with PHP is a *very* hackish thing. Having said that though... the most important thing in software development is shipping. If your team are all really good PHP devs and they don't want to learn Python, or it will take too long for them to learn, then that detracts from the team's ability to ship a product. So this is a decision that should be well-considered, *with business goals in mind, not technical ones.*
seeAlso: * https://en.wikipedia.org/wiki/C3_linearization * https://en.wikipedia.org/wiki/Eigenclass_model#In_Python * http://docs.python.org/2/library/stdtypes.html#class.mro * http://docs.python.org/3/reference/datamodel.html#the-standard-type-hierarchy #Custom classes * **http://www.python.org/download/releases/2.3/mro/** 
[re: `isinstance` vs `hasattr`](http://www.reddit.com/r/Python/comments/1ew4l5/im_giving_a_demo_of_python_to_a_bunch_of_java/ca4gtgq) http://www.canonical.org/~kragen/isinstance/
I have a bunch of these. For my rusty electronics, and newbie Python, it a cool toy to play with. I have built:- * A Rhythmbox "Current Song" display scroller. * A timelapse LED 'sky writer'. * A pan tilt head, with manual control board. * A tracked robot motor controller, with a manual control board. A bunch of other stuff that never made it off my bench. 
Not specifically a python option, but I really love [Octopress](http://octopress.org/). Blog posts are just markdown (same syntax as reddit posts/comments) and it's all hosted for free on GitHub pages! you can see mine [here - skien.cc](http://skien.cc). GitHub lets you point your own domain at it easily as well. I don't know a single thing about Ruby, so it's super easy to use without that knowledge. Don't get me wrong, I think playing with Flask is a blast, and a great way to learn. But if you want something quick with easy archives, comments (using Disqus), etc, it's a great tool. 
I played with a handful of static generators and I actually found jekyll to be the most pleasing to use. I don't write Ruby and I'm not a fan of reading it, but it has the features I want and I **loved** the workflow.
If you want comments with a static website you can use something like Disqus.
[Working Effectively With Legacy Code](http://www.amazon.com/Working-Effectively-Legacy-Michael-Feathers/dp/0131177052) is probably the best book currently on how to add tests to an existing system. Specifically it outlines a number of strategies for getting badly-written code under test so you can begin refactoring with confidence. If you took an untested (or poorly tested) Django app from GitHub or BitBucket and added some tests that would be a really effective example.
I wanted to add that a singular advantage of static site generators is that it keeps you close to the 'wire'. Changing a theme is as simple as editing a css file or editing a template. Of course, the price for this is an increased learning for the user, who needs to know the templating language and CSS, as well as how to deploy a site. IMO, this need not be a steep learning curve for someone posting on a python subreddit, but YMMV.
Try [Mezzanine](http://mezzanine.jupo.org/). It's based on Django (which is excellent) and handles many of the same things that WordPress does, and it somewhat-familiar ways.
Also, hosting your site on Github is easy with Jekyll. See [this](http://jekyllbootstrap.com/).
* https://en.wikipedia.org/wiki/Mixin#In_Python * http://docs.python.org/2/library/stdtypes.html#mapping-types-dict * http://python3porting.com/problems.html#replacing-userdict * http://docs.python.org/2/library/userdict.html * http://docs.python.org/3/library/collections.html#collections.UserDict * **http://docs.python.org/3/library/collections.abc.html** 
I started using Flask about a week ago. [This tutorial](http://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-i-hello-world) helped me to very quickly learn all the bits.
You could try out the following course: https://www.udacity.com/course/cs253 It's a course where you learn python with google app engine and jinja2 framework. You learn all by yourself and when you're finished, you are able to create a blog with history and user authentication and just everything (external API with json for example). But the best thing is this: It's taught by the creator of reddit, Steve Huffmann!
I've already said what I think about the first assertion. Your second assertion, that something one doesn't have to pay to use is automatically superior to something that does cost money is debatable to say the least. I find it to be incorrect in practical terms as well as from an ideological stand point.
* https://github.com/wamberg/hyde/blob/master/importers/wordpress.py * http://docs.getpelican.com/en/latest/importer.html * https://github.com/eyeseast/python-wordpress * http://mezzanine.jupo.org/docs/blog-importing.html * http://python-wordpress-xmlrpc.readthedocs.org/en/latest/
http://createjs.org/guide/ , http://schema.org/Blog and http://schema.org/BlogPosting are really cool too 
 * http://www.python.org/dev/peps/pep-0440/ * http://www.pip-installer.org/en/latest/usage.html#pip-show * https://github.com/pypa/pip/blob/develop/pip/commands/show.py * https://github.com/cloudmatrix/esky/ * https://en.wikipedia.org/wiki/Yellowdog_Updater,_Modified (YUM)
Pygame has a pile of opensourced games here http://www.pygame.org/project-Packt+Open+Source+Awards+-+2010-1616-.html (See the sidebar). I haven't had much experience with pygame, but there are many tutorials online for it.
In our team we have huge php (symfony/etc) code base and we decided to use rather python for new things. It's impossible to rewrite few years of your work from one to another language within even months. We put REST API on top of php codebase to cover existing application logic, and start writing new applications and addons in Python, replacing bit by bit old apps and views. We already used [liquibase](http://www.liquibase.org/) to migrate database, so we're not tied to php/python specific db migration tool. Now we have a lot of python goods like: * ipdb * supervisor * buildout * pip * fabric and we are happy :)
Just making sure I can find this later.
I also agree on namespaces and objects. Scanning a php file with objects is a nightmare with all that prepended labels: "static public function" Some people doesn't use IDE, It looks like to me that PHP has gone the Java road where you can only code if you have a full featured IDE.
You mentioned elsewhere that you're familiar with flask which has frozen-flask for static site generation. The docs are reasonable.
It's more about threading, I think. Python declares some operations to be atomic. CPython uses the GIL to lock everything while it's doing an operation. Jython uses manual locks. STM will make this all automatic. It's especially important in PyPy, because the compiler might re-arrange the code which can trigger an unexpected problem.
&gt;Your second assertion, that something one doesn't have to pay to use is automatically superior to something that does cost money is debatable to say the least. I was not implying that this was the general case, but that it is the case of PySide/PyQt **under the situation where the developer does not absolutely need to use Qt 5 and wishes to sell the software they develop commercially.** Aside from those two situations, they're more or less drop-in replacements for one another.
Hey pal, check out your search input - it tries to search on a different domain. I searched for a "flask" just to see if it worked and it did not find anything.
I understand - sorry - I took it in the broader sense. I think PyQT examples and documentation are better and exist in larger numbers - so there is that. And while you've addressed the practical side, I don't think it's necessarily better to license software in a way that lets people make money off it without being asked for something in return. That's a much more subjective and philosophical argument, but that's my opinion. When I'm doing things that generate income for myself I don't hesitate to invest money in the tools and software that I use. In fact I'd rather do it that way. I think it provides the highest odds for long term stability. I realize this is highly debatable and I don't think it's a sure thing but in general, based on my past experience, it is my belief.
Did you talk to Neal about this problem? What did he say?
OpenCV has python bindings.
Tools don't champion themselves. Do you have a Python expert that is respected and we'll liked?
Have you looked at [frozen-flask](https://nicolas.perriault.net/code/2012/dead-easy-yet-powerful-static-website-generator-with-flask/)? Its worth a try for sure ! EDIT: wordings
Thanks! If you're keen to get started, you can already buy it, plug plug. Other people have said that Django was a turn-off (but then again I think that just as many people see it as a benefit). I do want it to be primarily a book about TDD, not a book about Django, so, if you fancy helping out -- I'd be really interested in your comments, as you read through it, on where you find the Django stuff is getting a little annoying. I can then try and make the examples a little more generic, a little less reliant on Django specifics...
I'd recommend Jekyll on GitHub. Although it's Ruby, it's very low resource use
[Socrates](https://github.com/honza/socrates)
Let me try to respond to your posted questions: * Am I covering the right stuff? Would you add / remove any topics? I felt that version control references were a bit unnecessary. Does it really matter for TDD principles (I'd say its relatively orthogonal). I also think it's borderline unhelpful to first show the simple but non-best practice way to do something (like a non-TestCase derived test script, or the render_to_string() result comparision for template checks) and then later introduce the better method. I think you'd be better off to introduce the best practice and explain its functionality as necessary. * Am I teaching what you consider to be best practice? I had to re-read the chapters a couple times to notice you added the user story in comments in chapter 4. I think you should really start with a blank spec with those comments (as if you and your team agreed on these requirements) and then implement the functional test. Maybe, I'm more used to BDD styles, but the narrative style of the comments seemed odd to me. The functional specs are very loosely worded (...and the header mention to-do lists), but the assertions themselves check very specific implementations: assertIn("To-Do", header_text). Also, I generally disagree with most of Chapter 7. Testing html layout and styling sounds like a general quagmire and wouldn't qualify under "functional" testing to me. inputbox.location['x'] + inputbox.size['width'] / 2 ~= to window_width / 2, ugggh. Most real world layout and style is not defined through specs, but more "make it look like this mockup". If you're verifying your static assets or other config work properly, test something specific like retrieving a stylesheet. * I'm also telling people to use a very belt &amp; braces technique, where we write functional tests and unit tests for pretty much every single line of code. Is that overkill? No, this is essential in any project of relative complexity. Functional tests do not cover all possible cases and permutations (they would never finish if they tried). Unit tests isolate the components into testable interfaces. In a fashion, functional/acceptance tests are just verifying you glued together the components properly. * My latest chapter is all about deployment... I didn't pickup anything TDD specific about this chapter short of how to rig a LiveServerTestCase to hit an external web server. Like the VCS, it just seemed unrelated and orthogonal. Btw, couple random notes: * Why are you using HttpRequest() instead of RequestFactory? * tearDown() -&gt; addCleanup() for setUp() failures * Doesn't spawning firefox for each test get pretty costly? I tend to start and stop the browser for the entire test runner. * I'd like to see more about the overall dev process. Are you using some kind of file watcher that re-runs tests automatically? Continuous integration server? Hope these notes help!
hm, the use case they give is for when you want to track a set of changes against a 3rd-party package. Would you use patches and mercurial queues for an "in-house" app you were developing yourself?
thanks very much -- that looks like an excellent resource. almost all 5-* reviews... shame about the Java! If I was going to write a follow-up book, I think I'd call it "practical TDD", and include tips on things like this, and maybe some insights on where you get the most bang for your buck out of testing. I don't realy have the experience yet, but it seems to me like some tests give you more than others... 
That's dynamic.
It's a small team, with no previous experience with Python. As I said on another comment in this thread, we know the hassle of switching languages/frameworks, but we are entering a new stage of development and we'd be willing to grow together. If we see benefit in a new technology for future projects, now would be the time to check it out. We are currently studying the options and the folks from /r/php[1] gave us some excelent advice (mostly on Zend Framework 2). I figured I'd check with you guys too. What I'm looking for the most in this thread are selling points of python (over PHP). Generally speaking.
[web.py](http://webpy.org/)
Plus, it has a Wordpress import built-in script.
May I suggest [Acrylamid](http://posativ.org/acrylamid/index.html) - very fine static generator written in Python.
Ouch: Method Not Implemented GET to /building-a-hacker-news-clone-in-django-part-2/ not supported. Additionally, a 404 Not Found error was encountered while trying to use an ErrorDocument to handle the request.
Thanks for all of your input, guys! This was way more than I expected, but now I have a lot of stuff to look into. I'll make sure I do a follow up with the completed product and say what/why I decided to go with!
The move from PHP to Python is definitively worth it. Yet you are going to have many choices to make. Don't base on your choices necessarily on what the majority thinks (by that argument you should stay with PHP). Look into your options (Django, Flask, web2py, etc.) and spend a few minutes with each. See what makes sense to you. Try look at traffic and responsiveness of their mailing lists.
It seems working at my end. Could you check on a different browser?
I'm primarily a PHP dev (in so far as my current workplace is PHP based), however I've made the switch personally to Python (though trying to get the company to switch as well). It's far more elegant, and I feel like I can achieve more with less code (which makes me happier and more productive). It definitely takes a little bit to get used to, but once you are you'll wonder why you stuck with PHP for so long. Here's a quick example: from form import Form, fields @has_csrf class Contact(Form): name = fields.Text(label="Your name") email = fields.Email("Your email address") subject = fields.Text(label="Subject") message = fields.Textarea(label="Message") vs namespace Contact; use Zend\Form\Element; use Zend\Form\Form; class ContactForm extends Form { public function prepareElements() { $this-&gt;add(array( 'name' =&gt; 'name', 'options' =&gt; array( 'label' =&gt; 'Your name', ), 'attributes' =&gt; array( 'type' =&gt; 'text', ), )); $this-&gt;add(array( 'type' =&gt; 'Zend\Form\Element\Email', 'name' =&gt; 'email', 'options' =&gt; array( 'label' =&gt; 'Your email address', ), )); $this-&gt;add(array( 'name' =&gt; 'subject', 'options' =&gt; array( 'label' =&gt; 'Subject', ), 'attributes' =&gt; array( 'type' =&gt; 'text', ), )); $this-&gt;add(array( 'type' =&gt; 'Zend\Form\Element\Textarea', 'name' =&gt; 'message', 'options' =&gt; array( 'label' =&gt; 'Message', ), )); $this-&gt;add(new Element\Csrf('security')); $this-&gt;add(array( 'name' =&gt; 'send', 'attributes' =&gt; array( 'type' =&gt; 'submit', 'value' =&gt; 'Submit', ), )); } } This example also doesn't include the other boilerplate code required for filters, validation, rendering etc. Hopefully the above turns out ok, as I'm typing this on the iPad. I've written large scale applications in both ZF2 and Symfony2 (I would chose ZF2 any day of the week over S2 as I found development with S2 just too slow [performance wise]), and wrote a Python framework specifically to get a better handle on the language (named Watson, might be handy if you're coming from PHP to have a look, it's on Github with some documentation). Honestly, I would say the biggest challenge you will face is not on the coding side, but rather on the deployment side of things. If you have any specific questions feel free to contact me on Twitter or something :)
I can vouch for Pelican. It's been excellent.
I'm an avid Emacs user and I hate Vim, but this was really a great review. To-the-point, no bullshit, exactly the stuff you want to know. Bravo.
Holiday choice of colored text and background... 
Well done review. Upvote for that, but I'm not sold on expensive closed sourced software. It would be the first piece of software I've paid for [aside from games] in like six years. That said, the review convinced me to try the 30-day trial. I'll be open minded.
It works using IE but using firefox i get aforementioned error message. EDIT: Version 21.0 
Really good review, I've too recently started using pycharm and I really like it. Vim still remains an extremely valuable tool for its flexibility; it's a great editor for any kind of text, not just python code. 
I sent him an email about it, but have not heard back yet. It's an easy mistake to make - but it really skews the results. 
Looks like the IdeaVim plugin has been updated as recently as a month ago. Probably worth trying again when you have the time. http://plugins.jetbrains.com/plugin/164?pr=ruby 
IntelliJ IDEA and its offshoots (PyCharm, WebStorm etc.) really won me over. After using Eclipse religiously at work we all got licenses for IntelliJ IDEA Ultimate and I have to say it just shits all over Eclipse, bless its heart. Where Eclipse constantly seems to be creaking under the weight of its many plugins, IntelliJ seems to understand each technology natively and actively aid you. Definitely give it a proper try.
&gt; The editor is closed-source, but is built on the Intellij IDEA platform, which has an open-source Community edition. Have you checked if the Python plugin is available for the Community Edition?
I fucking love PyCharm. The Darcula theme w/ the auto push changes over ssh and git integration.... awesoem.
I agree. I've used IntelliJ IDEA for Java web development and PyCharm for a few different Python projects and I know exactly what you mean.
Of course it's not. Why would someone buy PyCharm if it was?
Dude, you *should* be sold on PyCharm - $100 is NOT expensive (consider what your average car mechanic spends on tools to do their job), and the shit is just plain awesome. Hope you dig it!
Thanks for releasing this  I've been using Flask-Classy now for a while, and it's been incredibly useful. The new improvements (particularly decorators) are key, I've been using them from the dev branch for a few weeks as well. Thanks again for all the work. 
Pelican for the win! I'm using it for my new blog. Also creating my own theme, but you can use any of the existing ones.
Fair point, everyone's got their own priorities.
We provide support to everyone, including open channels such as Twitter, StackOverflow and sometimes Reddit too. Asking someone for their license number on StackOverflow would be quite awkward. :)
Yes, exactly as you say. The example just demonstrates how easy is to use Authomatic with Flask. In a real application you would probably populate some User data model with the information from LoginResult.user and redirect to some other handler where you present the data.
Thanks for the feedback! It's nice to know people find it useful.
Not exactly the same, but the tiny [WR703N](http://shackspace.de/?p=3772) router can be hacked to control electronics and actually runs Linux + Python natively (and has WiFi). Costs slightly less too (~$22).
FYI if you only need a couple (digital) GPIO pins, then a $2.50 USB &lt;-&gt; UART adapter off eBay can be pretty handy.
In fairness, the closed-source aspect is what should be stopping you, [not the $100](http://www.gnu.org/philosophy/selling.html) ;)
http://zine.pocoo.org/
Hence why above I said "I'll try the trial and remain open-minded"...
I actively give money to open source projects (and/or contribute to them). It's definitely the closed source more than the $100 that gives me second thoughts. I did mince words above when I said I haven't paid for software aside from games. I haven't been _forced_ to pay for software aside from games. 
Thank you for making it a Python 3 tutorial. It pains me to see so many beginners start with Python 2 in our day and age. *EDIT*: I had a quick look at the contents. It is well explained but I hope children won't get bored along the way. I have taught Python to teens before and they only started having fun when I introduced input() and (later) turtle, because it made the program interactive and "alive". But, well, I'm no children expert and the best way to know if your book is appealing to them would probably be to have some of them try it out ;-).
Is there an in-depth tutorial for PyCharm? I didn't even know a good chunk of these features existed, let alone how to bring them up in the editor.
Thanks! PyCharm was the first software I'd purchased in a few years. Other than games, of course.
I have a fully functional emacs set-up with Projectile, Helm, Evil(vim), Jedi.py, jedi.el, nXhtml/mumamo and more. They really don't hold a candle to what I have with Pycharm. However, I am glad that I've learned emacs because I still use it daily on remote machines for config, bash scripts, and general file editing. Using Pycharm for quick editing isn't going to happen, nor is it going to help you on a remote machine... so you still need to learn some kind of unix-y text editor IMO. 
A lot of software provides a feature-limited open source edition with a feature-full closed sourced/paid edition. It's certainly not unheard of. EDIT: Not saying you've done something wrong in not doing so, but answering the question :)
try http://web2py.com/ it's a great web framework built to be easy to use and there's plenty of documentation to get you going. i've used it for work projects before and picked it up rather quickly. I'm kinda surprised no one mentioned it.
Cool project! The camel casing took me back a bit, to be honest. But its all good! Thanks for putting this out there. I was totally unaware of Topsy... looks like they have access to the firehose, interesting. 
Agreed. I still use Vim for editing Ruby (until I save up enough for an Intellij Ultimate license...) and configuration files. I'm super glad I learned it because the combination of modal editing and text objects pleases me. And PyCharm is not running in the oxygen-free deep space of a Linux server command line.
If you're really, really pressed for memory you could also try cffi which will let you have C-level arrays and structs. I believe it can parse C's bitfield notation. https://cffi.readthedocs.org/en/release-0.6/#struct-array-example
Right after I bought PyCharm I started using a Retina MBP for work. It turned out there was a rendering bug in the Intellij platform that killed performance when switching files on Retina Macs in most of the editors -- but only if the block cursor is turned on, which it is with IdeaVim. Also, back then, IdeaVim didn't support a few of my favorite text objects. So I felt kind of conflicted. But then something cool happened -- JetBrains fixed the rendering bug and assigned Andrey to work on IdeaVim. He fixed a ton of bugs and added several features I missed from Vim. All the while, JetBrains answered my questions via email and the issue tracker for PyCharm. Now I feel pretty happy with owning commercial software for development work.
Yes, the reviewer indicated that the problem was fixed. For me, right now, it's the 9 months I paid for, that it was unusable, that leave me a little trepidatious.
I usually take a sip of tea.
I wish that had been my experience. When my license was still active, I downloaded and installed it a few times, to see if it got fixed. For a while there was a guy Oleg who was at least looking at the bugs, but they never got fixed over the next several months. I am pretty excited that IDEAVim has gotten more direct support. Like I said, my mind has been opened. I'm not in a hurry to deliver another $100 though.
When I first read "sherlock holmes" I thought "great for kids", then I see sample programs and they are about grades, students, ... not very interesting for children in my opinion. The mistery catch would be great. If you can afford, please consider using a funny or more adventurous context. For example, spaceships: when will be run out of energy for our shields? Jungle adventure: get all the gems that ends with "ium" to get to the idol. Dinosaurs, Superheroes, Zombies (if they are older enough), ... To sum up: your project looks boring and I'm not sure problems will connect with children, any age. Maybe is more appropiate for teachers or administrative staff to help them out with their jobs. Edit: I'm a diplomate teacher, if that matters.
Yeah, I would want it to be more more mystery and puzzle based than that chapter I threw up. It's all I could think of at the moment and just wanted to throw something up there to help start a conversation and get feedback and ideas (like the ones you gave, thank you).
Thanks!
Fantastic review. Now I can stop discussing this stuff with people and just point them to your review ;) Thanks!
These days if you use Apache 2.4 with the evented mpm workers, it should be basically as good nginx. You have to know how to configure all that though, and make sure your applications work with it correctly. I'd say that it should be as good as nginx, but not in its default configuration, and not with 2.2.
That's exactly what we do with IntelliJ IDEA Community Edition and IntelliJ IDEA Ultimate, but the Python plugin exists only in a single version, so it has to be Ultimate only.
We do give free licenses for contributors to open-source projects, but the official policy is that the license can only be used for work on that specific project.
Here's a blog post I wrote after writing my ["Invent with Python"](http://inventwithpython.com) books: [Lessons Learned from Writing a Technical Book to Teach Programming](http://inventwithpython.com/blog/2009/11/02/lessons-learned-from-writing-a-technical-book-to-teach-programming/) Feel free to email me any questions: al@inventwithpython.com
https://developers.google.com/edu/curriculumsearch/
* [Seeking advice for introducing iPython in high school setting.](http://www.reddit.com/r/IPython/comments/1dl8wc/seeking_advice_for_introducing_ipython_in_high/) * [Lectures introducing scientific computing with Python using IPython](http://www.reddit.com/r/IPython/comments/1fm5hd/lectures_introducing_scientific_computing_with/) * [Help: Tips on starting up a coders club at the local library.](http://www.reddit.com/r/Python/comments/1dq7j0/help_tips_on_starting_up_a_coders_club_at_the/) * [Python website tuts that don't use Django](http://www.reddit.com/r/Python/comments/1eboql/python_website_tuts_that_dont_use_django/c9yxl8w) * [As a computer science major, would it be more beneficial that I take multivariable calculus or linear algebra, and why?](http://www.reddit.com/r/compsci/comments/1dprye/as_a_computer_science_major_would_it_be_more/c9soa2e) * [Getting started with automated testing &gt; Software Testing and Python](http://www.reddit.com/r/Python/comments/1drv59/getting_started_with_automated_testing/c9tfxgd) # Testing Science: Learning * https://github.com/hltbra/programmer-competency-checklist * http://wiki.opencog.org/w/CogPrime_Overview#Competencies_and_Tasks_on_the_Path_to_Human-Level_AI
I managed a transition (or the start of one at least, the business tanked due to non-software reasons before it was fully completed) that went fairly well but there are some gotchas. To repeat some already given advice, do not port stable software to python without a *very* good reason. A service oriented architecture is probably the best way to integrate, exposing what you need from PHP as an API isn't difficult (put the person with good API design experience on that one if it will be heavily used). It's not a minor thing, you need to set aside time for training that would be spent on dev, depending on your programmer skill level some people just may not be able to change. If PHP was their first language and still their only language then much of python will not just involved learning something different, it will involve learning the parts of programming that they didn't even know existed because PHP didn't expose them to it. There are a lot of people that do *not* know how to program, they know how to code PHP and for them, this transition can be very painful. We had a programmer team made up of wildly variable skill levels, the intermediate ones (I know that's a subjective term, i'll try and define it better below) fell in love and they surpassed their PHP productivity *really* quickly. The time they had to spend looking up stdlib stuff was more than offset by the productivity gain of the better language. Who's a beginner and not an intermediate? I don't know, for my examples a common problem with the people who had a really hard time with the switch was that it was difficult for them to understand that they were coding in an actual server environment. The imports and module level code didn't get run every request anymore, just the handler functions. The whole concept that some lines of code in a file got run once on server startup and some got run per request was baffling to them. They were also the ones most prone to cargo culting I noticed. If those problems strike you as very junior compared to your team then you won't have problems, in my opinion, if that's the case then you have a team of programmers who are being wasted on PHP and transitioning to Python (or any other popular well designed language) is a no brainer. PHP's tradeoffs are balanced to optimize the experience for programmers below your team's level.
I remember those! My father let me read his when I was younger.
I decided to move this to a web-based book and I'm using Skulpt to process the python browser-side and it seems to only do 2.7 :-\
Hey, thanks! I need to figure out how to make that change to Octopress...
[*Engage to Excel: Producing One Million Additional College Graduates with Degrees in Science, Technology, Engineering, and Mathematics*](http://www.whitehouse.gov/sites/default/files/microsites/ostp/pcast-executive-report-final_2-13-12.pdf) ([STEM](https://en.wikipedia.org/wiki/STEM_fields)) 
The same could be said of the community and enterprise editions of IDEA.
The core of the thing is open source, though. 
I've got a question. Is the IntelliJ Ultimate Edition with Python plugin functionally the same as PyCharm? Or would I really have to buy PyCharm if I wanted all of they Pythony goodness?
Is it out of the question to make it ajax-y? I imagine it would probably slow it down a lot to have to talk to the server every time, right?
It's not out of the question, but I figured it'd be better to do in JS for two reasons: 1) Can be used offline 2) Easier (no need to sandbox the process, which isn't always easy) Other than print, I can probably stick to a mostly bi-python dialect?
This is amazing! I wish I knew about this earlier! You should get it added to http://flask.pocoo.org/extensions/ so people like me don't reinvent the wheel.
Seems to be working in chrome, but not in firefox for me. Not just the link, but your entire site is registering that same error for me in Firefox.
Hmm, you're right, client side makes it somewhat easier, especially security-wise. You've made me curious about how something like this could be handled for Python 3. If you're feeling super brave you can always try out [emscripten](https://github.com/kripken/emscripten/wiki), which is an LLVM to JS compiler. You could straight up grab the source code for the Python interpreter and use that thing to compile it to JS. I haven't a clue as to how to work that out, but it seems to be used by [repl.it's](http://repl.it/) (2.7) implementation. **edit:** This isn't, of course, to say that you should adopt Python 3 and be completely uncompromising in that stance, I'm just curious about the technical aspect of embedding a Py3 interpreter in the browser.
Thanks! It actually has been added to the registry, but they haven't published the site yet since it was added.
IntelliJ (and I'm assuming pycharm, by extension) have the ability to export their settings. It's all xml files on disk, and it gets packaged up in a zip/jar file. Just ask him for an export. :)
In IDEAVim is it possible to map ; to : ?
PyCharm is definitely worth a look. Full-fledged IDEs aren't everyones cup of tea, but if your looking for one, PyCharm is just MUCH better than Eclipse, WingIDE, Aptana, etc. It's written in java, and it can be a right memory hog, but other than that I've been using it for years with no complaints. And they keep adding new features too, which is nice. :) I can understand people that want to avoid closed-source solutions, but if money is your only concern...seriously, it doesn't matter how cheap you value your time, you'll come out ahead if you switch from Eclipse to PyCharm (Redmine, Webstorm, IntelliJ IDEA, whatever).
That's close to what I mean; though it's not the same as being able to host your dotfiles and just have everything work like you can do in vim/sublime text/emacs
PTVS is fantastic. I've tried each IDE available for windows, and personally I find it to be the best
Thanks for pointing this out. I tried on a couple of browsers and even on browsershots. But the site seems to be showing up on all of them. Not sure what could be the issue.
I've used random forest before. It surely is very nice to use. Simple, and works like magic. That's the kind of algorithm I like!
May I help you in github?
Love the idea. I'll give it a try next week. thanks!
Thanks! Well, I am also a PHP developer so I am still adapting. Yes they have access and they don't ban you for scraping them. I do it contstantly and they seem cool about that. Maybe it's because they are doing the same to Twitter.
PyCharm's user experience is specifically focused on Python developers, so the project initial setup and subsequent configuration is simpler and more streamlined. Other than that, PyCharm and the Python plugin are built from the same codebase and have the same set of features.
On a Mac, all of the IntelliJ options are in ~/Library/Preferences/IntelliJIdea12 - there's really nothing stopping you from putting that folder in a github repo with a carefully crafted .gitignore to not include the cache or the key file (unless you use a private repo.) PyCharm uses a different folder, obviously, but the contents are pretty much the same.
Isn't this just a run-down of setting up a generic python project and installing the flask package into it?
I guess it must have been a hickup of the firefox on this windows machine, 'cause I had no problem accessing the site on another 21.0 firefox browser on my ubuntu box. Great article btw. EDIT: The problem still happens on Firefox this windows box.
Check the new readme for responsibility here: https://github.com/gkbrk/TopsyLib/blob/master/README.md And for the code, I don't think writing tweets = getTweetsByQuery("query") is bad for getting the latest tweets. But I'm always open for improvements.
+1 to WebTest. We've been using it to provide an "Integration layer". Better than Django client and not as heavy as having a full stack server setted up just to test. Although, it doesn't have much to do with TDD. It's really useful when testing APIs.
Other important notes about RFs: - Embarrassingly parallelizable. Each tree can be constructed in parallel. - The importance of out-of-bag samples (OOB) and out-of-bag-error. When a tree in a RF is constructed, the training data is bootstrapped (sampled with replacement). The samples not in the bootstrap are called OOB samples. Then, at each split in the tree, a subset of the feature columns are used out of the bootstrap. The samples not used in constructing the tree are considered very good unbiased predictors of the accuracy of the tree. The error of the OOB samples is the OOBE. - As the author pointed out, RFs (and other ensemble methods) combine estimators into a single, large estimator. *On average*, you are better off aggregating (averaging) the results of these estimators than selecting any single estimator at random. This is due to Jensen's Inequality, or what is known as the "ambiguity decomposition" in the ML literature. It is important to stress the *on average*. A single estimator may actually perform better than the aggregate, but we like the criterion to select that model; therefore, on average, we are better off aggregating the estimators than selecting a single one at random. - The Gini ratio (the node split criterion which the scikit-learn uses by default) is Fisher consistent. Fisher consistency has recently been extended to multi-class supervised learning (and even semi-supervised, too!). I won't go into the gory details, but Fisher consistency is more-or-less a requirement for loss functions to perform well.
Jetbrains make incredibly good software. You really should give them money on any chance you have.
Sure! Feel free to fork and do pull requests. If you want to exchange message about the story and how to develop it that would be awesome as well!
Zeus is a language neutral programmer's editor/IDE for the Windows platform. This latest version includes improvements for the Python language including better code folding, syntax highlighting and debugger support. NOTE: Zeus is shareware, runs natively on the Windows platform and runs on Linux using Wine. *Jussi Jumppanen* *Author: Zeus IDE* 
Just discovered this post. One of the neatest hacks I've seen in a while!
essentially, yes - mainly for beginners to get a dev environment set up quickly. there's a lot of pieces to it, and it can be difficult if you haven't done it before.
http://www.llvmpy.org/ edit: its actually built on 3.2 
Bindings to llvm exist in the [llvmpy](https://github.com/llvmpy/llvmpy) project. You can read the [Kaleidescope Tutorial](http://www.llvmpy.org/llvmpy-doc/dev/doc/kaleidoscope/index.html) to get a handle on the API. And here's the final source in a single file: https://gist.github.com/sdiehl/5125325 
pretty interesting, never heard of zeus before but it always fun checking out a new ide
Numba is an llvm compiler that hides a lot of the llvmpy syntax behind decorators (a lot more complex and sophisticated than that). It's by Contiunum.io, started by the guy behind Numpy. There's a simple switch to emit llvm ir.
I haven't tried that yet. I wonder how the editor will cope with its preferences being replaced out from under it -- worth trying!
You're free to import my settings file. The keymap I use is Vim Copy. I suspect the import will overwrite your settings, so it's probably worth backing up first -- that may not need to be said, but just in case. ;) https://github.com/abrookins/dotfiles/raw/master/PyCharm/pycharm_settings.jar
Depending on how complex your applications are, it sounds like what you need is a packaging format, and some concept or method of upgrade for those packages. Docker could be perfect. Some people even report sucess using debian packages but I've never investigated it. 
I have been building a set of ipython notebook tutorial on Wakari for llvmpy. See the shared bundle at https://www.wakari.io/sklam Although they are drafts, all the code are working. Just not enough description. 
I know this doesn't answer your immediate question, but it solves your problem. I recommend Anaconda by Continuum: http://continuum.io/downloads You get Python 2.6, 2.7 and 3.3. Use the conda command to create the various environments. Use "conda install" to add additional conda packages and "conda pip &lt;package&gt;" to install any package that is in pypi. 
I started out with Vim, and still use it quite a bit. I tried Sublime Text while 2 was stilli nearly Beta, and liked it enough to drop the money on it. I've never regretted that purchase. I recent landed a new job, and the other developers here use PyCharm. I went ahead and spent the money for a personal license in advance of my move, and I've not regretted that purchase, either. Each tool has a place IMO. I use PyCharm for projects - web applications especially. The refactoring and debugging tools are excellent, and I can set up things like environment variables to load prior to running my code. It saves me tons of time this way. I use Sublime if I'm only editing one or two files, and I won't be working on a project long. It's not worth the time investment to set up the project properly in PyCharm, and PyCharm is usually already open with a more important project in the foreground. Sublime lets me have most of the time-saving features I want - easy customization of the appearance, syntax highlighting, PEP8 linting, etc. I use Vim if I'm already in a bash session, or if I'm accessing a remote machine. Even though my skills have rotted a tad, I'm still effective enough that it beats moving files or setting up a remote connection in a more complex environment.
Depends. I personally like Python over PHP, and find Python easier to maintain because its less verbose and almost in plain english, thus requiring less commenting so long as your developer isn't obtuse in terms of naming things. That said, I wouldn't just dump Python on a bunch of developers who never used it before. PHP is accepted everywhere and doesn't take a bunch of busywork to set up on your basic shared hosting plan. I don't really think that python is worth the more expensive hosting/virtualnv setup juggling unless you're making web apps or services. If these are run of the mill websites that don't get too crazy and/or don't have large processing or bandwidth requirements, there's little value Python will provide you aside from filling your personal tastes.
Ensure your CPU fan is spinning freely while you are in there. Sometimes there isn't much dirt, but you'll still shutdown under load.
I hope you're using those threads for IO work, for CPU bound tasks the python threading model is complete shit and should be avoided if possible. Your CPU was probably freaking out because all 200 threads were fighting with the GIL. 
Second Pelican. I wrote the patch that improved the Wordpress import functionality of Pelican. So if you've been writing posts in Wordpress for some time it will import those posts and preserve all of the formatting. I've used it to convert my Wordpress blog to Pelican and it contains &gt; 7 years worth of posts. Media aside (haven't figured out how to fix the asset paths yet) it worked perfectly: http://agentultra.com Check it out for yourself.
Ooh, that might be it. I used lock on the thread function for reading a file. Is it that bad?
Are you hitting a single file with every thread? 
not sure what you are asking for but a quick google search yielded this http://en.wikipedia.org/wiki/Python_syntax_and_semantics#Easter_eggs
Oh wow... Being the person that I am, I can not believe I posted on Reddit before Googling. ^facepalm
Thanks
Shamless plug: https://github.com/Ceasar/staticjinja lets you compile jinja templates without any code. If you don't need all the batteries included, I like to think this is a worth a look.
no, and AFAIK the official Python bindings are still very limited
Zine's last release was 4 years ago - I'd consider it dead (unfortunately...)
Oh, wow, I didn't know about `import __hello__`.
what to all the people in Asia use instead of twitter?
We use [zinnia](https://github.com/Fantomas42/django-blog-zinnia) for our [blog at Open Force](http://blog.open-force.net/). Its comes with a lot of features and based on Django.
Thanks!
Assuming this is being downvoted because it is perceived to be unrelated to "What single-dispatch generic functions mean for you"; Mixins and abstract base classes frequently obviate the need for single-dispatch generic functions. Rather than having code conditional on `isinstance`, clases with Mixins are expected to have the appropriate behaviors before they are called. Additionally, Mixins can add complexity both to the Python MRO and static analysis. Inference: adding support for single-dispatch generic functions will probably lead to an increase in attempts to re-implement something similar to UserDict and collections.abc; which is both counter-productive and unnecessary. I do apologize if this appears to be hijacking this thread: my intent is to share the resources I am aware of in order to increase shared comprehension around these approaches to dynamic programming.
I have been using bottle for this exact reason. I would prefer flask die to the positive response on this subreddit, but the lack of python 3 support kills it for me. 
For profiling you may want to add [RunSnakeRun!](http://www.vrplumber.com/programming/runsnakerun/) which allows you to interactively query profile results in a number of ways including visually via square maps.
Right software for the right job.
+1 for hyde. Go static and never look back. As others have said, you can host directly on github this way.
Awesome! Thanks! Recent project reminded me how freakin' powerful and awesome this module is. Thanks!
Armin announced that Flask is getting Python 3 support this week :) http://www.reddit.com/r/Python/comments/1fd69b/werkzeug_and_flask_git_repositories_have_early/
 [**@tomwolber**](http://twitter.com/tomwolber): &gt;[2013-06-08 03:15](https://twitter.com/tomwolber/status/343204640214634496) (UTC) &gt;I'm pretty sure Twitter has no idea how funny this is to [#Python](https://twitter.com/search?q=%23Python) developers. [@gvanrossum](https://twitter.com/gvanrossum) [pic.twitter.com](http://twitter.com/tomwolber/status/343204640214634496/photo/1) [^[Imgur]](http://i.imgur.com/RgS2yz4.png) ---- [^[Mistake?]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=http://reddit.com/1fwoq0%0A%0APlease leave above link unaltered.) [^[Suggestion]](http://yl.io/S) [^[Translate]](http://translate.google.com/#auto/en/I%27m%20pretty%20sure%20Twitter%20has%20no%20idea%20how%20funny%20this%20is%20to%20%23Python%20developers.%20%40gvanrossum%20http%3A//twitter.com/tomwolber/status/343204640214634496/photo/1) [^[FAQ]](http://yl.io/T) [^[Statistics]](http://yl.io/U) 
&gt;&gt; import this
Wanted to ask again, is there something out there with more video control options that was all in Python? Thanks!
That is awesome! I literally just started out with bottle 2 days ago. I may just pause and wait for flask. People on here seem to indicate that it's better. But I need to try it out first of find a good comparison. I actually like bottle, but there seems to be more flask related material out there. 
Brilliant work mate! I can't wait to try... There are a ton of projects out there that could use this right away. A gajillion functions in one file is just messy... Have you seen any project skeletons with F-Classy implemented? I was thinking this and Flask-Security would be a nice combo. 
If you want to avoid Static Site Generators and have something more Wordpress-like (admin area and dynamically generated posts). You can try [Simple](https://github.com/orf/simple) it's just a clone of Svbtle using Flask.
I don't get it: why is this funny? Guido is a Monty Python fan, so?
It was just humorous that the guy that likes Monty Python so much he named a programming language after it is randomly shown that he follows John Cleese on Twitter. He still really likes Monty Python after all these years. Also, Guido think's its funny: https://twitter.com/gvanrossum/favorites
Yes I am. I am also using it for appending to a list. Then I use if asd in thelist all in lock.
Welcome to Python.
As a rampant abuser of PDB for pretty much any problem, I think, of all the shortcuts, you missed the most useful one: `n` :-) 
Thanks again for your detailed and very helpful comments! First off, on your general suggestion that Git and Deployment are 'orthogonal' to TDD -- I tend to agree, especially on the former. I guess it's about the picture I have in my head of my target audience -- people who are relatively new to programming, who've maybe hacked together a few programs, or maybe just finished a degree. Basically, it's me 4 years ago. If I look back on what I've learned over the past few years, things I think are absolutely indispensable skills, TDD is one, but how Git fits into my development process is also a huge part of it. Experienced developers will probably already know git, so they can just skip over my explanations (which are pretty much confined to chapter 1), but my hope is that beginners will get a lot out of it. It's all part of the flow of a more mature development process -- test, edit, commit, as someone put it in another thread. Same thing with deployment -- although I think I've made a case for how testing *does* interact with deployment and staging sites, much more so than it does with VCS. But the point is that you're not a web developer until you've deployed your app, so, again, my hope is that beginners will be getting something out of that chapter. Re showing non-best-practice first, my aim is to start with the simplest possible thing as a way of introducing the core concept. Then I can bring in the best practice once I feel the reader is ready for them. I mean, I can't throw in git, virtualenvs, south, postgres, gunicorn, CDNs, selenium, unittest, django, memcached and all the rest into the very first chapter! Perhaps I do sometimes take it a little too far though... I'll have another read-through. Thanks for the suggestion re the FT comments spec too. I guess some of that is a matter of style, or what you're used to... The comments are consciously quite vague, whilst the selenium assertions are specific, precisely because the former represent human-language requirements and the latter start to be implementation-dependent. You could imagine changing the implementation without changing the implementation. I'm thinking of including a chapter or appendix on BDD though, so I may be able to introduce a different style there. I really don't know enough about it yet, so if you 're interested in a collaboration, do get in touch. Re chapter 7, I know I'm in a danger area there. I certainly don't think you should test cosmetics, and as you diagnosed, the main point of the test is as a smoke test that the CSS has loaded correctly. So, would some kind of non-functional integration test be better? Maybe... The FT I guess adds the check that not only is the CSS available, but also that it was loaded correctly by the page... I guess I should just make it clearer about what the objective of that test is, and be more explicit about saying "don't test cosmetics". With that said, there's definitely a place for testing layout using functional tests... JavaScript-driven resize behaviour an example that springs to mind from PythonAnywhere Thanks for the validation re my belt + braces, FT + unit approach. Finally, onto the random notes! I've never used RequestFactory. What does it give you that instantiating a regular HttpRequest() doesn't? And, wow, thanks for telling me about addCleanup() -- I can't believe I'd never come across that (maybe it's because we used to write within the constraints of Python 2.6 unittest). Love it, will definitely be using it. Re starting + stopping firefox for each test, I just defaulted to that because it's what we do at PA. I think our intention there was about isolating FTs completely, making sure that cookies + sessions are clean each time, etc. That may not always be necessary, but at least once I do it very deliberately... I'll make a mention of it as a possible optimisation. Finally, on the overall dev process, I'm just alt-tabbing between a console and editor, and that's pretty much what I'm telling people to do. Automated file watchers are cool -- I think my ex-colleague JB wrote one called rerun -- but I think I'll leave them for people to discover on their own. CI I hope to cover in a later chapter, cf the outline... Once again, thanks again for your detailed comments. It's nice to have some validation, to learn a couple of things, and also to have a couple of decisions challenged. I'll go away and think about it all. And do get in touch if you want to work together on a BDD chapter -- if nothing else, I'd love to know what you use, and what your experience is with your tools, what you've ruled out, what you've preferred and why, possible pitfalls... 
+1 to the general approach of minimising the amount of logic in views... Although at PA we don't use forms that much, so the logic sometimes does start out in views.py. It usually migrates out to a custom module or set of classes. The more people talk about not using the DB in tests, the more I think I need to at least acknowledge the concern. I'll plan a chapter or appendix on the topic...
Thank you. I was not aware of these.
Yeah, I'm still using Udacity to learn, for example, right now I'm in CS212, Design of Computer Programs, and is so interesting =D
pudb is awesome
Thanks for weighing in -- /u/kevinastone above mentioned RequestFactory -- I've never used it, we've always just built our HttpRequests by hand... What else does it give you, apart from setting up the request.method and the request.POST (if applicable) dict? re the test client, i can totally see the ambivalence. It's all tied in with my not-very-purist approach to "unit" tests, which tends not to care whether it's an integration test or a clean unit test, but just cares whether it helps. I think I'm going to have to address that at some point in the book, maybe be more explicit about the pros and cons, and talk about how to make clean unit tests if you decide it's an objective...
Yes, this is awesome!
I suppose the typical thing to do is to organise it as MVC using a REST/CRUD-like interface to your model. Avoiding all the wank: Structure your application around objects, not pages. What actually exists in your application? Users? Posts? Comments? Those are your things. They'll be backed onto some sort of data store. Requests - Methods are your verbs. So we typically have URLs per object and use request methods GET &amp; POST to manipulate those. Don't be afraid to use parts of the URL to emulate DELETE + PUT because browsers don't support them in forms. (JS can though.) - URLs generally consist of a type and an object ID (If we're accessing a particular object rather than the type of object). Child objects can be give URLs through their parents : example.com/rest/parent/92-31/child/39-49 Now you might think you're limited due to having only four verbs - but here's the wonderful thing, that's all you really need. You can Create an object using PUT (and get back the ID / URL to access that object. Taking care to fill the object with good default values, or some empty 'uninitialised' state), then update with a POST (by filling the body of the request with the new values of the object). Upon the right kind of POST you'd set up the application to actually do something with that object. So these objects are the models, that you're manipulating, the request handlers are controllers, which should be small calls into your application (the reason here is so you can do the exact same things as your interface does within the application, without having to make HTTP calls to yourself). The views are the templates that just display the models of pages. You can also have logical objects which don't really exist in the back-end, but are created from multiple model objects during the request.
what have i done? from __future__ import unicode_literals, print_function import sys, os OFF = 2 def v(): import sys, io try: sys.stdout = io.StringIO() import __hello__ except: sys.stdout = io.BytesIO() import __hello__ p = sys.stdout.getvalue()[-OFF] == '!' sys.stdout = sys.__stdout__ return int(p) + OFF if __name__ == '__main__': print(v())
Thanks! I'll read that over and digest it. 
I think Eclipse + PyDev should get at least an honourable mention. Of course people who have to debug scripts running in a remote environment (with not even X installed), or using 10 year old computers can't use it, but the rest of us can enjoy a nice modern GUI debugger with all the nice features we come to expect from one after using Visual Studio or Eclipse for Java: the ability to navigate around all the source code as if in a usual editor while debugging, having panes with output, locals, watches, call stack, etc always on the screen, being able to set breakpoints by clicking next to any line of code with a mouse, and so on. Oh, and it's free, unlike all the rest of Python IDEs as far as I know.
Yeah, forgot about that. I actually like KCachegrid more cause the extra visualizations even if it's a bit harder to get set up.
too bad that Google blocks those kind of queries after a while.
Yeah. I am not sure but using random free proxies might work. We can even make a proxy scraper.
Maybe you could create 200 smaller files (one per thread) and recompile it at the end? 
Thanks for the recommendation, I definitely like the look of Splinter... I think I might give it a mention. Re: cucumber or BDD, I think I'll definitely have a chapter or at least an appendix on the topic. I've never really used any though, so I'll be on the lookout for more experience people to learn from on this...
You probably should have saved everyone a little bit of time by showing the output, like this for example: [Python2](http://ideone.com/xbUXta) [Python3](http://ideone.com/WbtJBl) Then, dealing with unicode is a pain in the ass but it's a known pain in the ass, there's a lot written on how to write unicode-processing code that runs in both 2 and 3 even. 2to3.py does translate your second snippet correctly.
Great to hear!
I've done perceptual research (vision) using Python. I ended up using *pyglet* and hacked together (ugly, ugly) code after trying to use psychopy and dealing with crashes. I was focused on response/reaction timing (mouse clicks) to masked stimuli eventually incorporating TMS and EEG. I can offer tips (e.g. sub-millisecond precision timing with CRTs), but it isn't clear to me that your research is heading in that direction. I found keeping data (other than EEG) in plain text allowed me to verify my statistics processing via spreadsheet. A header in the file with participant demographic info was also easier than trying to keep it separate (encrypted the drives to protect confidentiality). **tl;dr** I am happy to answer questions or make suggestions if you want to give more details.
Wow! Didn't know there's a pygame sub! Love pygame and have lots to share with you guys! 
Nitpick time: print(len(list(""))==1) exec("print('b' in globals())") in {'b':1}
http://stackoverflow.com/questions/193161/what-is-the-best-project-structure-for-a-python-application http://learnpythonthehardway.org/book/ex46.html http://docs.python-guide.org/en/latest/writing/structure.html For comparative examples of a simple app with various web frameworks, I usually refer to https://github.com/seedifferently/the-great-web-framework-shootout and https://github.com/tastejs/todomvc Pyramid has migrated from PasteScript (`paster create`) with [1.0]( http://docs.pylonsproject.org/projects/pyramid/en/1.0-branch/narr/project.html) to `pcreate` with [latest](http://docs.pylonsproject.org/projects/pyramid/en/latest/narr/project.html) ... There are lots of ZopeSkel, Paster, Templer, and Pyramid create templates hosted by PyPi. http://scipy-lectures.github.io/intro/language/reusing_code.html 
Looks great! Excellent job, man. All you guys need now is more activity :) 
 a = {1:1, 'b':'b'} for k, v in sorted(a.items()): print('k=%s v=%s' % (k, v)) Python 2 works, Python 3 crashes due to the sorted having mixed string/int keys
To be equally blunt, if you didn't catch that the OP said "looking into A job that wants...", and instead thought this was a general search, then you probably aren't well-qualified to be answering the post. We all got where we are by taking on responsibilities that we weren't qualified for, and it generally works out well if you've got the stamina to hang in there when it gets tough. 
Very helpful. Thanks!
Ummm, where's the RUN button? With all this prettiness, I can't believe there's no easy way to run the code!
Oh, this one is huge, by the way. I had a real-world issue with Python3 refusing to sort heterogeneous lists at work. I only wanted to make one of our configuration export scripts (from the DB to an installation script) work deterministically and produce diff-able installation scripts! Had to fix it by calling `str` on everything going into the tuple that was used as a key for sorting. EDIT: wait, no, I recall it correctly now: you can't do `sorted([1, None])` in Python3, you have to use a custom comparer (which I did, no str coercion silliness (well, to be honest that was my first approach but then my boss was, like, wtf it now sorts wrong, '2' comes after '10')). This is kinda huge and breaks a lot of assumptions regarding `None` as a possible value for any type. I'm OK with not being able to sort lists containing both ints and strings, because it's probably a bug because there's no obvious way to compare, because if you're sorting a list of ints you actually want to sort them by value, not by lexicographic order of their string representations. Breaking the sorting of homogeneous lists containing Nones is wrong though.
Homebrew is like drinking a brew. Delicious. 
Read it somewhere, but I forgot to check the date so it might be outdated info.
I think you did not intend to reply to my comment?
Or maybe there is a reason that they block the types of queries and abusing their resources is impolite at best
Looks cool! Edit: you need a license to go with it or nobody will use it at work. I suggest MIT or BSD license.
You probably want [iPython Notebook](http://ipython.org/notebook.html) more than a conventional IDE.
Alternatively: 1. Use Idle 2. Hit "Run" I know which one I'll be using. But I suppose I'll miss all the fun of selecting the macros menu to click on the option that nudges the ball that rolls down the channel until it hits the horn that scares the chicken, causing her to lay an egg which falls on the run option. Yeah, I'll miss that. 
Hi everyone! I created rootpy a few years ago and am now one of several developers. More help is certainly welcome! One of the main goals of rootpy is to make it easier for ROOT users to begin taking advantage of (also in my opinion) better solutions in the scientific python community for certain tasks, like matplotlib, numpy, scikit-learn, pandas, HDF5 (PyTables or h5py). The root2matplotlib, root2hdf5 and root_numpy components of rootpy already provide many possibilities here. My personal analysis framework is now able to integrate all of these technologies (and it does!). The final data format I use is HDF5, after converting all of my ROOT data with root2hdf5 and root_numpy. I use scikit-learn instead of TMVA (the ROOT component for machine learning). I can even make matplotlib plots look just like the (ugly) ROOT plots and trick my colleagues into thinking I am using ROOT, although it usually is the better text (and math) formatting with matplotlib that gives it away ;) Why would I want to make ugly plots on purpose? Well, I work on a team where virtually everyone uses ROOT for everything and we collaborate on papers that must use some common style for all plots. This is maybe one reason having the HEP field switch to something else (at least for specific tasks, such as plotting) would be a slow process, given how much ROOT is pushed and the general ignorance of alternatives. I've also encountered many with some level of resistance to learn and use Python instead of C++ (where appropriate), which I don't fully understand. For a surprising number of graduate students in the field, using ROOT is their first introduction to programming. I find this extremely unfortunate, given the number of ROOT issues that annoy even the experienced programmers. I think this turns people off and programming becomes just a task to get out of the way by any means possible. This must change. I can't predict the future, but I can imagine the situation in the HEP community changing, albeit slowly. I hope rootpy can help push things in a good direction. Thanks for your comments, and cheers!
Anyone have any good resources on the logging module? These seem like good places to start, but more can't hurt: http://docs.python.org/2/library/logging.html http://antonym.org/2005/03/a-real-python-logging-example.html 
&gt; But I suppose I'll miss all the fun of selecting the macros menu Or alternatively you could take that macro and bind it to a keyboard key, meaning you can then run the current file with a single key press, without even leaving the keyboard.
Please take this gentlemans suggestion and use MIT or BSD. I, and many others will refuse/be prevented from using your code if you use a GPL-type license.
In Python 2.x you can change the values of literals. (Redefining true to be false, etc.) As such, the following "works" under 2.x: &gt;&gt;&gt; True = False &gt;&gt;&gt; True False &gt;&gt;&gt; if not True: print "Huh?" Huh? But under 3.x it throws a SyntaxError (and an uncatchable one at that, due to it being part of the compilation process!): &gt;&gt;&gt; try: True = False except SyntaxError: print("Exception caught") SyntaxError: assignment to keyword Not something that anyone should be using in production code, but a difference (and potential pitfall) nonetheless.
Security-wise, please be aware that client-side AJAX controls __do nothing__. At all. Actually, no client-side controls do anything, but yea. Please either make this clear, somehow, or tie it to server-side controls. Depending on how you implement it, "On-Submit" validation will always be insecure (Remember - _anything client-side is always insecure_), the only secure model would involve server-side validation too.
That looks promising. I've been looking for something like this recently.
Since you say that you don't mind difficult, I'll be that guy. Vim with all of the fixins is a wonderful development environment. Paired with your favorite plugins (like [python-mode](https://github.com/klen/python-mode)) and the [ability to interact](https://github.com/ivanov/vim-ipython) with [IPython](http://ipython.org/), it's hard to beat. If there's anything that *does* beat it, it'd be [PyCharm](http://www.jetbrains.com/pycharm/). I happen to be a vim user, but you can't go wrong with either. Be forewarned, vim isn't the easiest editor to learn. It isn't as difficult as some suggest, but it does take some effort, and some comfort with the linux command line. If you're on Windows, just use PyCharm and save yourself a massive headache.
That is correct and I don't agree with that execution model either. In PHP the output of that script that was executed essentially becomes the displayed HTML which does more harm than good. I think the WSGI interface is decent and having a long-running process and an "entry point" is beneficial. However we need to figure out a way to have these advantages without losing the simplicity. An interesting and promising way could be http://www.docker.io/ I'm really excited about what Docker could provide. It provides operating-system level isolation which can enable "drop this single file" on the server simplicity. But it is still in early stages and I'm not too familiar with it either, if someone has used it please let us know. Another potential approach is also having something like Tomcat's .war files, having a thin layer on top of WSGI that knows how to unpackage and prepare the apps to be ready and serving requests and it could provide a decent control panel for individual apps to be turned on and off. This is what Tomcat does in the Java world. You have one server with a Tomcat running, you access the Tomcat manager with your browser, upload the application and it'll be serving requests within seconds and you can restart, stop and start it from there and monitor it. I'm leaning towards something closer to Docker because it doesn't enforce much and doesn't divide up the community and apps into "works with X, doesn't support Y" kind of groups.
This is an excellent point, and it's true that the demo glosses over this important detail. I will amend the demo soon and make it more clear in the docs. Thanks.
Always a sign of high-quality software, when you have to configure it to get it to do the basics... 
Beautiful
So much yes! Conventional IDEs are geared more towards Serious Enterprise Applications, and would be a poor fit for OP's use case.
Thanks, glad you like it! I'm working on my cartoon-style skills, and an insecure pickle was a tall order. *Edit* Thanks so much for the gold! I have a stressful week ahead but you've put me in a great mood.
&gt;The kind of refreshingly-simple approach I'm talking about is "drop this folder here and you are good to go" kind of simplicity. Due to the fact that Python apps use WSGI, or at least should be, this is never going to be possible. In terms of simplicity: if you have shell access, bottle.py is by far the best choice here. If you only have FTP access, you'll have to rely on Apache mods and such, and in that case things will always be messy. It's a matter of how serious you want your web app to be. If it's a simple one-off thing, bottle will be just fine. If you really want it to be even remotely complex, then the amount of code you write will be minimal to the amount of time it takes to actually deploy the app.
Lol Nice. The world needs more scripting error message inspired illustrations
um... it looks like a penis that failed hanging itself.....
Thank you!
Yeah, see? His legs make him look cute instead of shy. I guess it's in the angle of the knees? Sometimes I just have to try out various body positions myself and see how they make me feel.
Making web development easy has been the goal of web2py since 2007. Web2py won the Bossie award in 2011 for best open source development tool and the InfoWord technology of the year award in 2012. It does not solve all problems but tries to address some of the issues you discuss. It can runs off a USB drive. Does not require installation. Comes with ssh enabled web server, web based IDE, database interface, plug and play of multiple concurrent apps, and many free apps that can be installed directly from the web under the same web2py instance.
I have no problem deploying serious apps using Python and I agree that in general the cost of deployment is negligible as you'll set it up once. I understand the challenge with WSGI but I don't think it makes it impossible. I'm not saying just because you drop the folder there then the file needs to be executed in the same way that PHP is executed. A simple application can do the bootstrapping required to make it work. For example there could be a standard "application.py" file which serves as the entry point, and the application server would automatically find and recognise the available applications and from that point onwards as far as PHP or Nginx is concerned they are dealing with a standard WSGI app. So something like this can make the "drop your folder here" thing work. Hell it could even generate that WSGI entry point from your package if it's not present (e.g. from yourapp import app as application and off you go). But the challenge is that there needs to be some kind of definition or standard for this to work and it requires everyone to abide which is unlikely to lead to large-scale adoption. And as with all standards, within a week 50 different implementations will be available and people will be at war with each other about which one is the superior one and all that story over again. So that's why my hopes are high for something like Docker as it is very agnostic. Back to the simplicity point, I think if you are a serious python developer shipping serious web apps you may not be directly affected and think this is all too simple for you. However I think that is shortsighted. There are massive benefits to be gained over the long term from the added simplicity. We say "amount of time it takes to actually deploy the app" as if the difficulty with Python deployment is not stopping anyone from jumping on board when in fact it is. Either directly or indirectly. if PHP is alive today it is because of things like Wordpress, Movable Type and Drupal. Have you seen Drupal's internals and the module system and the magic hooks hell? as you'd expect of a massive PHP project it is not pretty. Now I'm not bashing those products and I think they have proven themselves to work but I'm just inviting you to imagine how much better things can be in the Python land. Imagine the army of Wordpress and Drupal developers who would be able to join and develop on Python equivalents and the pleasant and welcome surprises they'll encounter. Imagine the theme and plugin developers who find out how much better things can be. Imagine the new job opportunities, commercial support and everything else that it will bring. We can keep drinking the cool developer's kool-aid and ignore these people and their potential and as if we have not seen so far, we will not see a decent popular web tool like Wordpress ever being built on top of Python, or we can acknowledge that a problem exists, and that the bar for entry for many people is still too high, address the issue and help PHP developers to see for themselves what Python has to offer.
also his name is pickles
you. are. awesome. Twitter's non Oauth API expired a few days ago and I spent several hours diving into Oauth and came away a bit frustrated with Python. I'm no genius so Oauth was seemed a bit tedious compared to the old way of just sending an API key in the GET request. I used the oauth2 library, but this is fantastic! I stil haven't gotten Vimeo to work, perhaps i can with this.
&gt; PEP 293849: Extend BaseException class to output errors with ASCII-art versions of thegnome54's illustrations. FTFY.
You can go back to /r/im14andthisiswtf, thanks.
Cute! Note that the error about an "insecure pickle" might suggest that there is such a thing as a secure pickle. There isn't. Pickles are trivially exploitable for arbitrary code execution. Never unpickle data from an untrusted source.
Python has an inbuilt web server, and a library for opening your browser.
Let me get this straight: You want a "production ready" setup, with sane settings, and no messing around. Basically, something that you can start prototyping on, which will scale up to the point where it's actually worth hiring people who know what they are doing, instead of messing around trying to become a "full stack engineer". I'd say Google's AppEngine kind of fits the bill, but it's a pretty specialised tool. Heroku might be what you are looking for. There's also more Python centric Heroku equivalents (e.g. gondor.io), but I guess you also want something which can roll out to your own machine. 
This is excellent! You should do more! :D
Thanks. Can you care to compare it with the existing libraries (e.g. WTForms, Formencode, etc.) ?
There are *countless* **free and graphical** IDEs out there. Having a GUI makes learning everything a lot easier. Being able to step through your program and view all your variables on every line is beyond overpowered. http://eric-ide.python-projects.org/ https://code.google.com/p/pyscripter/ http://pydev.org/ http://xcorr.net/2013/04/17/evaluating-ides-for-scientific-python/ 
I heard that they block your IP if you do a lot of irrelevant queries too fast. I am not sure about this though. And about the resources, this does less than a normal Google search, it doesn't aggresively download ten thousand pages.
The main issue is definitely the execution model and deployment. Coming from PHP myself I found it the hardest thing to get used to. Something that standardises this (or at least documentation about it) would be a good thing, even guides on how to transition from one language to the other. The syntax of the language itself is not a blocking point IMO. Having nothing like Drupal/Wordpress is not a bad thing though... Trust me you do not want to have to look after godawful code like that.
I cannot like this enough
The big two features that I couldn't find implemented well elsewhere were good support for dynamic forms and underlying support for AJAX validation. The only form library I've used extensively was deform, so I can't speak much to the others. To my knowledge deform is the only library to support AJAX submissions out of the box, and that was a big feature for me. Professional sites validate things on the fly, give hints and tips etc, but aside from coding these by hand it seemed like there weren't great facilities for doing this conveniently. However deform had significant shortcomings that I couldn't work past. For reference, here are a few of the issues I had. + AJAX validation consisted of simply re-rendering and then replacing the whole html block. I didn't like this mostly because it seemed messy (I know, it still worked fine...) and it made trying to trigger JavaScript based notifiers (like bootstrap's tooltips) a pain. In general it just seemed inflexible. + By default it used Chameleon. I tried to use it for a while but gave up and have since moved to Jinja2. I know you can switch the rendering engine, but inevitably some of the frameworks design decision end up reflecting what it was built for. I'm sure Yota does. + Stuff that seemed like it should be easy was sometimes very complicated, such as trying to change the "mapping" template. + Although it was possible to generate a form with a variable number of fields, it involved no small amount of hacking with __new__ and other messy things. + Validation that involved input from more than one node was a bit strange and hacky. + All validation errors prevent submission of the form. **tldr:** support for higher level AJAX validation and dynamic form schemas
Reminds me of the ["I'm Free!"](http://archive.kontek.net/rott.classicgaming.gamespy.com/fun/imfree.jpg) error screen in Rise of the Triad, when a pushable wall escapes the bounds of the map.
I can secure a pickle just fine, thank you. In my tummy.
AFAIK Python imports these only once. I import them inside the functions to see what I can use in that function better.
I want to recommend form library authors to read [FormEncodes design docs][1] before they start implementing. [1]: http://www.formencode.org/en/latest/Design.html
great drawing!
Oh yea, they are useful, I did say specifically security-wise. When it comes to security, client-side controls are 100% useless, but when it comes to usability, hey, people wanna know what they can submit.
I could help you review potential security problems with your library, if you'd like. At a glance, I would worry/think about these things, not all are security concerns 1) Where do you get states from? They're all listed in the source of the page, and I would recommend you load them through AJAX, since it would allow you to more easily add states for other countries/update page content. 2) On the results page, do you add in caught exceptions to "errors"? If you do, don't, you never want real exceptions shown to users. 3) The last form on the page, wasn't it supposed to do AJAX error-checking? For me, it simply submitted the form and gave me errors on the return page. Edit: 4) What does adding a dependant to a javascript form imply? Can user input somehow tie an input field or similar to a Python variable or class or anything, really, or does it get added as another dict key in the results? If there is any chance of affecting execution flow by adding things to these form it will be found.
You *can* just drop Python scripts in a folder on the web server and have them run like PHP. That folder is called `cgi-bin`. Or any other folder you set the appropriate options on in your Apache conf. Of course, you do have to take care of the HTTP headers yourself in that case (which PHP does for you), so you'd probably end up writing some kind of framework. But you do that, too, with a PHP app of any significant size. That doesn't help with the start-up penalty, though.
Almost spilled my coffee... we have the almost exact same drawing on a whiteboard in our lab (already since two years or so): http://i.imgur.com/NUxxY0M.jpg Our measurement software is written in Python and at some point we repeatedly encountered this error, so a postdoc drew that there. Awesome coincidence :)
PS - I'm using AsciiDoc to write the book. It's what OReilly recommended, and I'm pretty impressed. It's like MarkDown or RST with bells on...
Haha, awesome! There are no new ideas.
http://bugs.python.org/issue18172
Yeah, but hopefully not from an untrusted source. 
This looks pretty cool. I've typically used a subclassed version of a WTForm that would return a dict of errors for my AJAX stuff, but it was always a bit of a pain. Will definitely check this out.
Awesome! =)
Thanks for the warning! I'm still new to Python. Right now I'm using pickling to save large datafiles from simulations I run on a server in my lab, so that I can move the results to my laptop for visualization.
Must agree with mdipierro here. Web2py is as really good web-framework with little or no configuration. Two thumbs up for web2py.
That's probably ok, but storing data in pickle format in cookies on a web application is a very bad idea. 
It's only been stepped on once, what's the worse that could happen?
I am very happy with Geany http://www.geany.org/ 
insecure is not the same as sad
No. The hackers has got you. You must bury your computer and cover it with rocks. It's the only way. Also, don't forget to burn all your clothes afterwards.
Translate "NSA Obama Shot" to 300 languages? :-) 
Well, try, go ahead and send me the code :)
This is correct. The problem is figuring out whether the pickled data is trustworthy. Unless you're willing to sign your pickled string (thus mutating the problem into one of safeguarding your private key, which may or may not be better), there's no way to tell. I've never used pickling for this reason. I always define a json or (on OSX) plist that contains an abstract serialized data structure, and manually construct my objects from its contents after they are thoroughly validated. This also has the benefit of narrowly defining the data structure that can be placed on disk, so that other processes (not necessarily Python) can write compatible output.
What the python world needs is a system that is easy to install, and that can them be easily configured and customized through-the-web TTW. In order for it to be easy for new users to understand, it should support a hierarchy of services. Here is my vision of what is needed. Basic Web Services. It should be easy to create a file server, proxy server or reverse proxy server by adding a few objects TTW. Think a gui on Twisted Web. It should be easy to dispatch different urls to different services. Think Virtual Host Monster. Basic Web Objects enable a person to put up simple websites with HTML, CSS, Javascript, images, streaming audio, email, comments and logins. The user can add them, and edit them TTW. Javascript editors for each content type catch errors and make for an easy-to-use experience. Python development TTW would allow a person to create Products, Classes, and Methods TTW. Think of the WingWare IDE user interface, but TTW. Applications allow the user to easily create and configure complex services, such as mailing lists, wikis, discussion groups,blogs and Content Management Systems. etc. These are not just applications, since they are in python, they are extensible applications. Networking Objects. These objects allow you to connect with other systems and in particular other servers, creating a network of trusted friends that you can share information with. A trusted friend network with Encryption, Web, SSH, and SMTP proxies enable private communications. Performance Objects allow one to improve the server performance, saving memory, and reducing cpu requirements.These include file system based images, files, and audio streams, and various caching configurations. Content Objects provide basic services, such as comments, lists of links, calendars, and ratings calculations. This is not just my vision, this is what I am building. Large parts of it already exist, thanks to open source software. Check out Zopache.com for more information. Zopache.com/PythonTTW
Yikes, in my more juvenile days... that comment would be considered a "target rich environment." That is all. 
`app.yaml` is really simple. Phusion Passenger is as simple as mod_python ever was. There are references describing the advantages and disadvantages of various Apache process models. http://www.reddit.com/r/Python/comments/1fl8c5/self_hosted_python_web_hosting_platforms/ http://www.reddit.com/r/Python/comments/1bx3vj/how_are_python_apps_deployed_to_production/c9b5tea
&gt; but I guess you also want something which can roll out to your own machine Exactly. Heroku and Google App Engine is not the answer. I'm looking for a solution that can be utilised more widely so that it will result in a growth in Python usage on the web in general. I'm not trying to solve my own problems here.
Yes but that will not result in widespread adoption, it's a particular and specific solution using 1 company. I'm looking for something that the average joe could enable from the control panel of his shared hosting and start using his web application. 
That's not what was being debated. He meant that Python web apps should be deployable simply by dragging and dropping a folder full of your code from your local computer to some remote server. This is how it works with PHP.
My argument is that once we create superior alternatives that are based on Python the current Wordpress and Drupal developers and the like will be hooked soon once they see the advantages that Python brings to the table. We keep saying Python is better than PHP because this and that. But unless we address the deployment problem people will just put up with all that awful crap. There's a reason that almost no popular widely-used web application is powered by Python (I mean things similar to Wordpress, Drupal, Joomla, vBulletin, etc...). 
Surprised that *[Nikola](http://nikola.ralsina.com.ar/)* wasn't mentioned yet.
Made [this](http://i5.minus.com/i47xtUCNpBCFb.jpg) just for you OP.
&gt; We dont talk too much about profiling in Python. This is two-fold: Python overall isnt quite as industry-mature that profiling is a massive concern, and a lot of Python centers around the whole developer time is more valuable than computer time thing. What? Python is very mature and even though most Pythonista's value their time over execution speed does not mean we don't care about performance. You throw a punch at Python while it looks like you did very little research on the topic, and then wrote a blog on the topic that you want us to read which provides no additional value above what is already provided in the Python [profile!](http://docs.python.org/3/library/profile.html) documentation.
Reading through this was pretty interesting, thanks for that. Kind of wishing I'd read it a few weeks ago. I took away from it a few things: + Although not yet explicitly documented, yota validators have complete access to the data and could easily include conversion as part of the validation, as is a prominent feature of FormEncode. + Allowing for validators to be run selectively would be an interesting feature that I hadn't thought of. As the article said, sometimes when validating a model or RPC call assumptions can be made that don't require as much information. If interested in this feature please comment on this [issue](https://github.com/icook/yota/issues/12). + Focusing on the demo so much I completely forgot to build a nice function to return the output post-validation. This is a pretty big gap, and I will try to rectify it soon. [Issue](https://github.com/icook/yota/issues/13).
I must disagree. First, from the community, somewhat the filosophy is making reusable components, so bring a tyied solution like Wordpress or Drupal will not have followers. Even Django was critized for not distributing auth separately. On the other hand, Drupal 8 core moving to CakePHP could be an advantage for us. Secondly, you have Mezzanine, Merengue, Django-cms and other projects leading in the direction you point. These projects don't get enough energy and publicity. Now a days, a cms is never just a cms (at least medium-big ones) and we or customers tend to put everything in a website, all kind of crazy services. So that takes us to my first point: better start from scratch with a generic web framework (micro or macro) The common PHP workflow is install Wordpress, Drupal, Prestashop and then start adding third party plugins, programming hooks, changing templates, until Core Wordpress is only a 60-40% of the final application. I would be sorry to cheat a PHP coder and tell his/her that is possible and GOOD to use the same workflow with Python :S
The performance of pickling/unpickling large files is not too impressive. If most of the big data is in a relatively small number of numpy arrays it's ok.
Hey John! Your point is well taken and I should have phrased that better: I meant "we" more in the college student/recent grad sense, not the overall Python community sense. For instance, in my CS curriculum and the curriculum of others I've talked to, Python is used in the introductory sense and then when the topics shift to things like profiling/debugging/etc., there's much more of a focus on Java and C++. Editing the post to reflect the above now.
Check this: http://pygame.renpy.org/ Works, although is has some cons (ie. binary size and load time).
I think I wasn't clear enough and you have misunderstood my point. I'm absolutely not preaching something like Drupal-on-python for developers. If you are a Python web developer you have a lot of choices, yes go use Django or Flask or whatever. In that case the deployment is not too big of a trouble for you either, you probably already know how to set everything up. What I'm saying is that we need to bring Python-powered solutions to the every day person. So when someone wants to start his own blog on his shared hosting, just when he has the option to choose Wordpress or Movable Type, there's the other option there too which is just as easy as wordpress if not more. Or when someone wants to create a web forum, where he can choose VBulletin or SMForum, there's another Python-powered option there too. We keep saying Python is superior to PHP because this and that, but we are not bringing the fruits of those advantages to the every day person. This is a huge gap in Python. On one side you have these micro or giant frameworks like Zope, Plone, Django, Flask, etc... which are tools for developers to make something with. And on the other hand you have some general-purpose or single-purpose things built on top of them such as the Django-CMS which are small projects often maintained by a few people, if not abandoned, and they are not well-known or well-maintained or battle tested. They still require you to setup the environment install dependencies and what not to finally be able to get something going and once you are moving with it, you can't get far because there's no vibrant community, themes or plugins around it. So things like Django-CMS is still not within the reach of the every day person who has a shared hosting and just wants a decent damn CMS to be installed with a few clicks. They are still developer tools. So I'm looking for the solution that will allow the Wordpress, Drupal, Joomla, Movable Type, vBulletin and SMForum of the Python world to be created. It's naive to ignore the fact that all those highly successful and popular tools have been written with PHP. By the way let me mention that I'm just using Wordpress, Drupal, etc... as examples to convey the general idea, otherwise my point is not limited to them 
Impressive! Good luck.
Yes. A single file library.
In my opinion calling it "almost the exact same drawing" is insulting to thegnome54's drawing skills.
standing with it's feet like that is not a characteristic of being sad.
Ah, I think I'm getting to your point. You are asking for working "out of the box" apps backed up and tested by the python community? 
i didnt see the feet i was watching its face. can you even determine if someone is sad by looking at the feet 
of course I was referring to the quality of the drawing when making the comparison... 
Yes. Apps for the every day user that are powered by Python. For example a Python powered blogging platform similar Wordpress (and thousands of more applications for different things). That way the every day user starts benefiting from Python and communities will start to form around these applications. They will create thousands of job opportunities for Python developers and introduce millions of people to Python. In the same way that Wordpress has introduced millions of people to PHP and has created many job opportunities for PHP developers who would otherwise be unemployed. The current environment only caters for developers and highly technical people who can be bothered to setup their own server and set things up on it including servers and dependencies and all that. All hosting plans come with a control panel that will allow you to install these PHP applications with a few clicks. Want a blog? install Wordpress or Movable Type, forum? vBulletin, SMForum, BBForum, cms? Drupal, Joomla, you name it, there's a popular PHP application for it that can be installed with 5 clicks. But the same thing does not exist for other languages such as Python, Ruby or Java. I want us to reach to a point where Wordpress and Drupal will no longer be competing with other PHP applications, they will have to compete with the blogging platform that is powered by Python, because now in that dropdown menu, you can also choose the Python and Ruby applications. This will change the game. PHP developers will no longer have to put up with the horrible legacy bugs and quirks of PHP and Wordpress and Drupal because now there are elegant and new competitors in the game that demonstrate what these languages have to offer, and highlight the weaknesses of PHP.
This is why I've always wondered what pickle is actually safe to use for.
Is there any advantage to having import mechanize import urllib import re in each function compared to having it at the top of the file? And wouldn't this kind of library be against google ToS since it's not using APIs, it's using browser user agent string to be able to use web services? 
I know, that's why I said it was insulting.
/r/bellybutton (nsfw)
Is anyone else here seeing ridiculous CPU usage and slow response times from PyCharm? (running OSX 10.6.8, MBP, 8GB RAM, 2.66GHz Core 2 Duo, SSD) **Edit:** Disabling on-access scanning from Sophos seems to have helped, but I don't have a final resolution.
 s/my tummy/mah belleh/
True, but I wouldn't call that "crashing". Crashing the interpreter (esp with such simple code) would be a critical bug. This simply raises a `TypeError` exception: Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; TypeError: unorderable types: str() &lt; int()
Has anyone ported this to PHP or JavaScript yet? I have sensitive user data that the government currently doesn't have easy access to in my current web app.
Here was I pissed that the Rails guys had all the fun. Not anymore!
Right, but it is a model that works, a bunch of files get pushed to a host (shared or whatever), if you had an open source project that enabled that, lots of hosts could use it. I don't think you'll be able to get around an always running process, unless you either kill idle processes and then restart upon a request, like heroku, or develop entirely new frameworks and tools.
The oauth2 library is actually an implementation of an oauth 1.0a client because someone doesn't know how to name things that implement protocols. The library mentioned here (sanction) isn't going to help you with twitter.
It's only a matter of time until even Node developers can join in on the "security" party.
This is really bad. Your app must be teeming with terrorists!
Google has a rate limiter in place meaning if you perform too many queries against Google, it will place an IP ban on you. Something to think about before you get too excited.
I am aware of that but yesterday, I kept it open in a while True loop for about 10 minutes. It queried the page continiously and didn't get banned. But still we might get IP banned, so I guess we need a good proxy list.
But then you need an API key, and even then it still limits you. I guess scraping is the best option, you do whatever you can do as a user.
thanks - that's helpful info. Not exactly the same as being able to check in a text file, but clearly workable.
thanks! :)
I haven't just started programming. I have been programming in PHP for years, I did lots of projects and even sold them so I'm pretty experienced. For python it's been 3 months. I haven't heard of PEP8 sorry, I'll look into that. I told in another comment I will move the imports.
The problem is frameworks. We all know that frameworks are a good thing, even lots of PHP programmers know frameworks are a good thing. PHP may be crappy a a language, but a decent framework makes things so much better in both Python and PHP (and Ruby and any other language). But the newcomer who wants to knock up a quick page or three does not know that. In PHP the newcomer can have a single file which generates a page that shows the current date and time written and running in minutes, and s/he can feel really pleased with him/herself. Why on earth, s/he thinks, so I need to understand all this stuff about controllers and views and models and templates? The point is, what is attractive is not so much the deployment issue - you can just "drop" a complete PHP application-and-MVC-framework into a folder and have it work. Rather, it is the apparent simplicity with which you can get a PHP site running. Of course, we all know that that simplicity can come back a bite later, but the newcomer doesn't. I guess what I'm saying is, if there are a Python route that was as simple as the PHP route, then after a while there would be Python sites that were as tangled and ill designed as lots of PHP sites. I really can't see a way out of this.
mod_php makes it "just work", though. And what Apache server doesn't have it? 
Disclaimer: I just registered on Reddit just to participate in this discussion, which I think has great importance. OP summarizes what I also think is the big problem of Python for widespread adoption, and IMHO some answers miss the point. &gt; Due to the fact that Python apps use WSGI, or at least should be, this is never going to be possible. We all agree that using WSGI is superior than using CGI for example, but maybe we can shift the paradigm and assume that, for a newcomer, the performance penalties and other issues of putting their files under `cgi-bin` will be greatly compensated by the advantages on **easy and fast deployment**. The *right way* can be adressed in a later stage of the learning process. It is just an starting point. I envision a book on Python for the web which starts at this point, using CGI to get things up and running as soon as possible, testing some popular hosting to check that it also works online and on a latter chapter explaining "OK, but this is not the best way to deploy Python apps -- if you want to get some serious stuff done, let's talk about uWSGI and be sure to buy some more advanced hosting!". Or maybe it's just as easy as creating a barebones blogging app using this approach, writing some companion tutorial and see what is the response of the community. My two cents :)
Python did fairly well in the comparison, tying for first place. It's interesting to see what ideas other languages bring to the table.
I always knew PHP devs were terrorists...
&gt; When the problem is mostly performance Which is not really the case here. Two groups (Canonical and Sugar) were worried about performances, one wanted easier bootstrapping, two didn't provide reasons and the author himself &gt; d like to use a language with static type checking to make changes to the code less risky, and to detect problems due to API changes in the platform (e.g. Python 3 broke the code in subtle ways which were still discovering occasionally in less-used code-paths). He also notes that Python has served the project well and has a number of advantages, both intrinsic and stemming from its current use. 
It looks like a study case for *not* replacing python to me.
Negative results are also important and third parties may weight the various criterion to yield a different result for their use.
looks very awesome. kudos to you; i am going to try it out on a project right now :)
Unfortunately for many tasks the best way to improve performance is via multithreading, and Python will never be good at that.
(disclaimer: I'm a kivy contributor) Its predecessor pymt was started in 2008, kivy was started as a complete redesign taking into consideration all the lessons learned from pymt in Oct. 2010; so it's not completly new. I personally don't think it's buggy. If you're interrested in doing android dev with it, there is a Virtual machine thats already all setup to build android packages (http://kivy.org/docs/guide/packaging-android.html#packaging-android) I love being able to just code and test apps on my desktop/laptop, and then build android or iOS to do usability testing / deployments.
Awesome, let me know if you have any questions as you go. I'm hoping to make a complete tutorial here in the next while.
Actually it looks like the performance penalty is mainly the overhead of running the giant (C)Python runtime (50.76ms). This not a concurrency problem because the runtime needs to be started before anything else can happen. The part that does benefit from concurrency is downloading all the dependencies from remote sites and the article already mentions that it is solved with concurrency provided by co-routines. The article does mention that a faster Python runtime may help here.
There is also some more discussion on this on the newsgroup: http://thread.gmane.org/gmane.comp.file-systems.zero-install.devel/6951
It's a nice abbreviation you got there! (Not Safe Application)
I would just copy/paste all relevant user information into a pastebin and link to it from the site. Make the button large and green to be compatible with this style. 
Updating python versions or the machine shouldn't change anything - pickle doesn't include actual bytecode or anything and it is intended to be portable over different python versions. The security problem is because it can invoke arbitrary python functions rather than running contained bytecode. You might be thinking of something like marshal, which can embed bytecode and makes no backward compatibility guarantees.
Very helpful...
A [user agent](http://en.wikipedia.org/wiki/User_agent) header is a string of text that is sent with HTTP requests to identify the program making the request (the program is called a "user agent"). Web browsers commonly send these in order to identify themselves (so the server can tell if you're using Chrome or Firefox, for example). Many APIs will want you to use a unique user agent string for your program. This is so that if your program misbehaves for some reason, they can more easily identify it, rather than have it look like a browser or just a generic default (this is why they tell you not to spoof a browser). The user agent is something that a human might read at some point in a log somewhere, so it's useful to include something like the name of your program and, in case of Reddit, your username in it. That way, if your program is doing something wrong, the admin reading the server logs can figure out how to talk to you.
Robert '); DROP TABLE Students;--
&gt;So something like this can make the "drop your folder here" thing work. Hell it could even generate that WSGI entry point from your package if it's not present (e.g. from yourapp import app as application and off you go). Google App Engine does this for you, as I bet do other cloud servers like OpenShift and Heroku, there's also PythonAnywhere. Yes, not exactly the same as dropping a file on your own server, but there is a group of people that are already doing that. All that said, I'd love to be able to do what you describe.
How does tinys3 support files that are bigger than 5GB?
That's one thing I really notice between Rails and Django - Django seems to have way more totally dead apps/plugins. With Rails, it felt like there was a *ton* of options all around; Django seemed to be in flux. It was weird.
Do you use SSL to secure any part of your site? Yes? Then don't worry! They have easy access already! :)
Thank you! Very helpful
why would i use this over gdata api ? im not overly familiar with mechanize as its not a standard lib but it looks like youre building header, going to the url and stripping the data out ? edit: oops people have made these points already.
You misspelled Python in the 'about' section.
PyPy to the rescue!
Do you need to rewrite the wrapper in C# instead of Python? Then it is a completely different task than running the Python code in IronPython (and will have absolutely nothing to do with Python, btw). In case you have some logic implemented in Python and C++ is only doing the heavy-lifting, you could probably rewrite only a wrapper to the C++ library in C# and then adapt your Python code to use this wrapper instead of whatever you are using with Python.
Priceless. Massimo is (online) a genius, great guy and amazing project originator/maintainer. Had no clue of his sense of humor though.
My fear with Quantopian is security, regardless of what they say. At least if you code something in python, using zipline etc then its yours and safe. Putting the blow up risk to one side...can you think of anything? I could run on TWS demo feeds but is it possible? What is the point of having all these models crunching rules for me if it cant get used on data :)
I really want to use it and haven't yet, but only because I hadn't had a problem that would require it. They come up regularly and now I have another tool in my toolbox for when it does. I am looking forward to it, I find MacroPy a very elegant implementation of macros given the limitations.
this might be outdated info: you can run c++ as "managed c++" in the .net clr and thereby directly reuse your code with c#. i did that with a custom c++ shared memory library to interface with a .net gui in the version 2.0 times. it was surprisingly easy.
Thanks for this - Esky is currently looking the strongest candidate.
No I can't rewrite anything. I have to use this Python-wrapped library in a C# environment
Nothing on the README really sells me on using this for a project. Case Classes - This is supposed to bring abstract data types to python, but it doesn't really tell me why I need them in python. The only example that I am given is a List, which while it might be a simple example, it doesn't show me a side by side example of how it is better than regular idiomatic python. For the simpler examples, like the `Point` one that was given, I don't really see why that needs to be a macro. I suppose it is a little cleaner than the regular python syntax, but it uses syntax similar to what regular python uses. Because of this, it changes what it would normally mean. I would much prefer something like this: class Point(object): __metaclass__ = CaseAlternative _items_ = ["x", "y"] or just use a `namedtuple`. I don't like the way that it expresses default arguments. I am not a big fan of overloading operators and completely changing their meaning. Quick lambdas - They hurt readability, especially in this example: map(f[_.split(' ')[0]], ["i am cow", "hear me moo"]) Compare that to the idiomatic version: [a.split(' ')[0] for a in ["i am a cow", "hear me moo"]] The example that uses `functools.partial` is somewhat deceptive, instead of just importing `partial` it takes the whole namespace with it to make it less readable. Here is what it would be with macropy: basetwo = f[int(_, base=2)] Compare to `partial` and a regular `lambda` function: basetwo = partial(int, base=2) basetwo = lambda x: int(x, base=2) Again, at least personally, I find the idiomatic python version to be more readable. The last example doesn't make any sense to me, but maybe there is something that I'm missing. It uses quick lambda to do this: thunk = f[random()] I don't really see the value of that example, why not just do this? thunk = random Finally I don't like that it uses `_`, which is already used for a number of different things including: * The result of the previous line in the python repl. * To note a loop variable is being unused, ex: `for _ in range(num_llamas):` * As an alias for `gettext.gettext`. String Interpolation - I would rather explicitly pass the variables in and just use regular string formatting, even if you don't want to do that you can always pass `locals` or `globals` into your formatting if you want that. Tracing - This is actually kinda cool, and I may have to play with this. Smart Asserts - Again, kinda cool, but not enough for me to want to include macropy. Experimental Macros - I wouldn't want to use these in a project because they are experimental, but I will say that `@tco`intrigued me. Overall there are a couple of cool little things, but I can't see making this a dependency for one of my projects and have it carry all that other stuff in there that isn't related to what I need. 
Could you throw me a link?
Arent most Tor exit nodes maintained by the NSA who monitor the trafic
1. No. That would be silly. The NSA monitors Level 1 ISPs, they have no reason to run Tor nodes. 2. Even if they did, it wouldn't hurt the anonymity of the Tor network. That exit node isn't connecting directly to anyone connecting directly to you. You connect to an entry node, then that node connects to a middle node, then that node connects to an exit node. So the exit node doesn't know who you are, unless you're sending personally identifying information in cleartext over Tor, in which case it obviously can't help you.
This is the first I've heard of it. And I don't use Python a lot any more, so my take my rambling opinions below with handfuls of salt ;-). Syntactic macros are very powerful, and one of the main reasons I love coding in Tcl and Scheme, but even in such languages where they're an accepted part of the ecosystem the adage applies: *with great power comes great responsibility*. As such, I'd be hesitant to rely on this in a Python project. A quick look at some of the examples suggests that the way these macros are applied will not be obvious to a Python programmer -- it goes beyond even SQLAlchemy's bizarre abuse of operator overloading. Python isn't really the best language to effectively deploy this sort of technique. I'd probably be happier with some sort of pre-processor/precompiler (think Coffeescript for JS). That said, if a well-placed macro is going to significantly improve the readability and maintenance of a particular piece of code, and you can implement it such that the contracts and use are clear (which includes catching the most likely errors with a meaningful error message, clearly documenting intended use and avoiding unpredictable interaction with other code), go for it. Treat it like writing library code or otherwise providing a DSL: if you can apply PLOS and make the user's job significantly easier, it may be a good idea. 
Doesn't really matter. A bad exit node won't reveal you, afaik, in fact no single bad node will reveal you. That's the whole point.
Welcome to you're "doom"
&gt;but I figured this might inspire some of you to write some code that &gt;can help make a difference. And in the interest of equal time, for those of us who believe more data mining is the answer to rooting out terrorists, supervillains and covert alien invasions, open source is useful too.... :-) http://rapid-i.com/ http://www.sqlalchemy.org/ http://www.cs.waikato.ac.nz/ml/weka/ http://pandas.pydata.org/ http://orange.biolab.si/ http://www.kdnuggets.com/2012/11/best-python-modules-for-data-mining.html http://strata.oreilly.com/2013/03/python-data-tools-just-keep-getting-better.html 
The problem is when both entry and exit node are controlled by the same entity. It can be possible to locate you with an end-to-end correlation attack.
OK, I take your point. I was thinking of web sites written from scratch, if I have it right, you're thinking of applications that can be extended, so people can write new plugins for them. Interesting idea, people can look at the underlying framework later, if they want, or not at all ... and still see the python goodness.
Yes. You see, as soon as we talk about Python, everyone's thoughts goes towards things like Django and Flask. Those are frameworks for developers not applications for end users. What I want to see is decent applications for end users built with Python. In PHP world there are tons and tons of these applications and they can be installed easily and used within minutes. The best examples are Wordpress, vBulletin, Movable Type, Joomla and Drupal. What I'm saying is, why don't we have equivalents to those applications in the Python world? or Ruby? or Java? It's a bit naive to think all those applications just randomly happen to be written with PHP. We go on and on and constantly bitch about how PHP is terrible, yet we as a community have not delivered a decent blogging platform based on Python that could compete with Wordpress. So why should anyone take us or our claims seriously if they are not seeing or benefiting from the fruits of our work? I think the reason is that compared to PHP, Python is hard to deploy and get started. So the only *accessible* solutions to the end users ends up being the PHP based ones that can be easily installed with 5 clicks from the control panel of your shared hosting. What I'm saying is that we need to come up with a solution that makes Python just as easy if not easier than PHP to be deployed and ready. This way, if you and I tomorrow write a good alternative to vBulletin, it will be available to the end users the same way as vBulletin is. When they want to install a forum software, on the dropdown where they can pick vBulletin to be installed they will be able to pick your software too. However the current situation is not like that. The Python based solutions are all very much developer-focused, they will require you to grab it from github, setup your VM, install dependencies and what not and all that stuff that you and I can do, but it's too much to expect from a simple end user. 
How would you know if it's an "entry node" compared to a normal node?
Python is not an alternative to PHP. Something like Zope Page Templates (ZPT) would be such an alternative. A strategy to promote Python at the forefront is broken from the startup IMO. ZPT is not good because of TALES. It should support plain Python expressions, which then can be scaled to call modules (files). The user story is HTML -&gt; Page Template -&gt; Page Template + Python files -&gt; Page Template Frameworks Or start with a PTF as promoted in this thread and use Page Template for customisation.
Thanks I appreciate your input. 
An entry node is just the first TOR node you connect to and therefore knows your real ip address.
No bug. Welcome to integer division.
try 9/float(4) integer/integer = integer
http://pytools.codeplex.com/
Go read up on differences between integers and floating point numbers. When you divide two integers, it spits out an integer to keep the number type the same. Since integers can't have decimals, we drop the remainder when we divide. I'm not a computer scientist, but I think this form of floor division is actually faster than actual division anyway.
In Python 2, dividing two integers is integer division... you can do 9/4.0 instead and get 2.25. In Python 3, 9/4 returns 2.25, you must use 9//4 for integer division.
Kudos for taking the beating earlier and presenting the other side. I'd add some skills to the list that are far, far more important than the ones you list: * communication and people skills * practical, hands-on software design experience; no theory in the world can teach you this * putting things in perspective * security, usability, maintainability
&gt;A bad exit node won't reveal you, afaik, in fact no single bad node will reveal you. You're right, one single bad exit node won't. However, it's possible for NSA (or anyone else) to control both entry, middle and exit node that you use. If you control a lot of nodes there is high chance for someone using TOR to be using nodes you control for both entry and exit. NSA has a lot of resources, they even fund 80% of tor's annual budget, I doubt they don't have a lot of tor nodes running.
/r/learnpython next time, please.
I've written a similar tool, but with a command line tool and Glacier/OpenStack Swift support: [bakthat](http://docs.bakthat.io). I really like tinys3's Connection Pool and the simplicity!
I completely agree that scraping is usually the wrong approach, but to be fair ["The Google Finance APIs are no longer available."](https://developers.google.com/finance/). I personally would just use another service with API instead of scraping data (i.e. using this library).
.. but be ready to be disappointed how easier is in python ;)
I did, thanks. Perhaps I continues with my data analysis and see how Quantopian progresses with live trading. thanks.
A bad exit node leaves you vulnerable to man-in-the-middle attacks, which might "reveal" you, depending on the contents of the traffic you're putting through it.
Nothing is preventing law enforcement of one kind of another from running entry or exit nodes, so if you really care about security you should be assuming the worst-case scenario that they are.
Aside from crypto stuff, the best thing to do is to work on moving cloudy stuff over to independent applications. I'm playing with [radicale](http://radicale.org) today for my calendar, next up will be looking for some kind of webmail app that'll talk to my existing imap / smtp server - any suggestions welcome.
I am not sure how you get geocache information - or how many of them there are... I am going to assume you just get lat/long coords and there arent *that many*. I would use shapely and find the nearest one based on distance... or just use maths (trigonometry) and figure it out yourself. Then I would put those two coords in google maps or whatever you are using and let it figure out the shortest way to that coordinate. If you want to render the maps yourself I think you need to use mapnik or something like that... 
this looks interesting, but just too slow or not even responding. Still, the message looks too much tech oriented. It should focus on web pages which can be made dynamic with python (secondary message).
I would kinda disagree regarding the learning curve based on the OP. I think that python has enough standard types and idioms that would make it pretty steep to someone that has studied (presumably) one programming subject. Pretty sure everyone will recommend LPTHW, as it is actually a pretty solid course. Also agree with EagleEyeInTheSky. For me, I was pretty amazed at how easy it was to create a web front end for my CLI apps using bottle and some basic css/javascript (twitter bootstrap), so maybe try and do that too! However, it sounds like you want to learn how to program, so maybe you should stay with java for now until you are able to tackle more than arraylists comfortably?
Hmm...good points. This would have to be an offline computation since it will be in my car. Geocaches come in GPX format (XML) but I can perse these for the lat/long pair. There would also be maybe a few hundred to a thousand.
http://scikit-learn.org ?
The dependencies could be included in the software package in the same python virtual environment so the end user will not have to install them explicitly. That's another reason I'm excited about [Docker.io](http://www.docker.io). It creates self-contained linux containers which are platform and language agnostic so you can practically wrap the whole program and all its dependencies and everything in between into one container that can be run anywhere. It even isolates the file system of each container so they wont conflict with each other. I am thinking of writing pyBulletin. Not really specifically pyBulletin. But I think there's tremendous opportunity to create better alternatives to these famous and decade old applications. There are CMSs and forum software and what not being built on Python, but they are not "consumer ready". They are side-projects of people on github for other developers to install. We as developers are just serving each other, we have forgotten about the rest of the world. Most of all I'm excited to write a decent alternative to Wordpress in Python with Pythonic template and plugin systems. But every time I think about it I think what good is it? It's never going to be used widely because Python is not available to most people and the barrier is just too high for most people. So 99% of the people out there will keep using their Wordpress because that's the option in their drop down box, and 1% of developers will use and praise it. That kinda reminds me of [Plone](http://plone.org/). 
No, it is a feature.
Sounds like you might want to check out the [Google Maps Directions API](https://developers.google.com/maps/documentation/directions/). Last I heard, there are actually only a few implementations of driving directions technology, I think this is the only one you could easily access through an API. 
You need to separate the C++ code in its own DLL, then you can use this DLL from C# using PInvoke.
I fully agree with what you are suggesting for the frameworks. It's an important aspect on very fragmented/plural Python world. But for me that's only one aspect of bringing Python to the web. &gt; Not take it for granted and never attempt to change it. never change?? why not? the main standard is HTML. From there (to achieve dynamic pages) we have PHP and then we should have Python Web Page Templates as a well recognised alternative. Of course deployment and setup needs to improve to back it up. But consider that zope was very easy to install (run exe on Windows), just like any other app and then the user only uses the browser. How easier can it get? But that was not enough for its success was it? Deployment and setup is a means, not an end, and Python does not have an "end" to show (rather too many of them).
But that node doesn't know whether you're a TOR node or an end user. All it sees is the TOR packet.
Do you know why LPTHW says not to use IDLE? edit: Can't do some of the scripts in IDLE.
Explanation: http://docs.python.org/release/2.2.3/whatsnew/node7.html
Going to research it as well but round cube used to be good
Some resources I highly recommend: Start with learn Python the Hard Way, then quickly roll through Google's course on Python, which has homework-like assignments: https://developers.google.com/edu/python/introduction Think Python, in addition to being great general Python learning, was the first book that allowed me to grok classes and object oriented programming (and it looks like it's been updated recently): http://www.greenteapress.com/thinkpython/thinkpython.pdf I then recommend reading Jeff Knupp's Idiomatic Python book: http://www.jeffknupp.com/writing-idiomatic-python-ebook/ Speaking of idiomatic Python, I still reference this post occasionally: http://python.net/~goodger/projects/pycon/2007/idiomatic/handout.html Once you get a bit deeper, I recommend Matt Harrison's book for Intermediate Python dev: http://www.amazon.com/Treading-Python-Volume-Intermediate-ebook/dp/B00BT95CWM This is also a good reference to learn more about decorators and functional Python: http://www.brianholdefehr.com/decorators-and-functional-python If you start to write your own packages, I recommend this site: http://www.scotttorborg.com/python-packaging/ 
It would be nice if there were examples with good use cases in their README. I would want it as something akin to Cython, where you can run it on the development version, build your code and then ship it without Cython as a dependency.
If you're looking at writing C for hotspots in your code, then the GIL isn't going to hamper you, since it's released for C code anyway.
My point exactly
I want to go to your college!
Which is typically why you wouldn't want to send identifying information over TOR. Your point is well taken, though. I usually tell people that TOR is like sending an anonymous letter with words cut out from a newspaper. It works really well unless you sign with your name.
OpenPRISM, anyone?
It looks snazzy, but I'm not sure I want PHP anywhere near my server if I can help it.
If it needs to be offline, I'd look into [OpenStreetMap](http://osm.org) and [OSRM](http://project-osrm.org/). Unfortunately it's C++ and so it would take quite some work to get it working through Python but it should be possible.
This is exactly why i decided to give lectures on schools... Nice work! Also the comments here list some nice skills.
Indeed. Awesome points made by people here! Thanks everyone
Advice taken! Thank you
/r/python is generally for python news and discussion. For a project specific issue like this, your best bet is probably to post to their mailing list: https://groups.google.com/forum/?fromgroups#!forum/npyscreen/ 
See #2.
Since correlation attacks rely on statistically matching a pattern out of noisy datastreams, it's not clear they're as effective as they're made out to be. See [this detailed overview](http://archives.seul.org/or/dev/Sep-2008/msg00016.html) of correlation attacks from the Tor mailing list.
Thanks all, this noob thanks you. 
Why would the NSA run Tor nodes at all? They monitor Level 1 ISPs. They don't need to run Tor nodes, they monitor the whole Internet.
See this sentence fragment from #2 of the comment parent: &gt;unless you're sending personally identifying information in cleartext over Tor, in which case it obviously can't help you.
The Tor Browser fixes all of those issues as far as I'm aware. They've put a lot of engineering work into minimizing the difference between instances of the Tor Browser. Testing the latest Tor Browser on GNU/Linux against [EFF Panopticlick](https://panopticlick.eff.org/) gives 17.5 bits of identifying information, or one in 185,369. My normal browser is completely unique, but the Tor Browser is probably ubiquitous within Tor Browsers.
We've got more readers than Java, PHP, or Ruby! Next stop... the WORLD!!! MWAHAHAHA!
It's public, but it's also in a constant state of flux with nodes dropping in and out, and not all nodes have to be listed on it. It's not trivial at all.
Tor's churn isn't *that* huge. It's also possible to tell if the node you're connecting out to is an exit node (and they have to be publicly listed and stable), so it's easy to tell where you are on the circuit.
I think its really great how active the /r/python community is, both in fostering new Python devs and in providing a platform for people to spread the word about their projects. Between PyCoders, Python Weekly, and r/python, it's very easy to keep up with most of the new/interesting stuff happening in the Python world. 
This is a great discussion! I don't understand why we don't have this. I mean, I understand that bending python into the PHP model may not be a smart thing to do but there must be some halfway that makes it seamless to use python in the average LAMP server. I would love to be able to do ap-get python_simple_web or alike on my VPS and be able to drop python files under //var/www and be done. No messing around with Apache configuration nor having to use nginx (nothing wrong with nginx, I just don't want to risk replacing Apache in my setup). The only reason why I use PHP is because I can create small scripts without worrying about setting things up. I understand that this may not be the smartest way to do things but I am only saving the odd email to the database and such in a static website. I believe that is the reason why PHP is so popular and also why we still have loads of old asp sites around (asp works just like PHP). There is no setup involved or a few well documented apt-gets get everything in place with minimal fuss. 
Doesn't this depend on monitoring entry/end-points individually? If that's the case, then you're kind of already screwed when warrantless wiretapping is on the table. I don't think this is really the threat model that TOR is supposed to protect against. If you're a high-value target, TOR is almost certainly not enough to cover your ass. For the rest of us, however, it's excellent. It's getting even better as its user base grows.
Would love for a python based one.
&gt; That's completely false. They aren't any highly popular Python applications because nobody has written them, yet. I disagree. There are some applications such as [Plone CMS](http://plone.org/). Now I'm not going to argue quantitatively about how much it may be better or worse than Wordpress and I know that it is a slightly different type of CMS. However I think you'd agree that the popularity of these applications is not on par with their quality. In other words, their quality is good enough to justify a lot more popularity but we don't see many people talking about it outside the Python developers community. And why haven't people written them yet? Python has been around for a very long time, longer than PHP indeed. That suggests that there's something wrong somewhere in the web side of Python compared to PHP, otherwise there would be a lot more applications. &gt; it would be a herculean task to development something to the level of Wordpress. And, then, what's the tangible benefit to these users who aren't programmers? They couldn't care less if it was written in Cobol I'm not suggesting that we should clone Wordpress for the sake of cloning Wordpress in Python. I'm trying to paint a bigger picture. What I'm saying is, when Python becomes easy to manage and deploy on the web, news solutions and products will emerge which can directly compete with their age-old PHP equivalents. That will only happen if the Python solution is just as easy if not easier than the PHP solution to be installed. And that means being supported on all major shared hosting providers because the significant majority of people will not look beyond the choices that the dropdown in their shared hosting control panel provides. As for the Wordpress example, I'm saying if we do attempt to make a competitor to Wordpress (or all those other famous PHP apps) in Python it has the potential to be a lot better and fix the things that those projects get wrong because it is Python from the ground up, it is new, and it will not carry a lot of legacy problems, issues and bloat that these apps are carrying. It doesn't need to be a clone, I'm just using their names to have something to refer to, they will be independent projects on their own, with their own vision and style. But they can be a lot better in many ways because a lot of issues will almost automatically fade away when you leave PHP and many additional benefits will come from the use of modern components. &gt; Just write the code, and they will come. It depends who we refer to by "they". If it's tech-savvy people and developers yes. But if we mean the majority of potential users, they will not come along that easily. It comes down to cost-vs-benefit. At the moment the cost-benefit equation doesn't hold. Why? Because the cost of adopting the Python solution compared to the other one is too high. (having to learn how to set it up and move from their current shared hosting and deal with everything else in between). So the benefit that the Python solution provides needs to be enormous compared to the PHP one, so it will justify the cost and they'll think well these features are too good to not use, I'll just accept the difficulties. This will likely never happen because the gap just doesn't get that big. Whenever they want to consider the Python solution (if they ever hear about it), they'll think meh...but this thing is right here and it's similar to the other one. What I'm advocating is to reduce the cost of trying and using the Python web applications. So when you want to install Wordpress (or whatever) the cost of trying the Python competitor or equivalent is 1 click. This lowers the barrier to entry and adoption. People who didn't care yesterday will now think hmm....I might as well try this. This creates the foundation for a whole new Pythonic web eco-system. 
The global passive adversary isn't the threat model Tor was designed for, but because of the practical difficulty involved in performing correlation attacks in the wild, it still does a pretty good job. The objections our raccoon friends outline are applicable to the global passive adversary, because a traffic spike corresponding to the download of a large file will spike traffic over the circuit it is on, but it will also co-occur with other traffic spikes. To identify a single user requires a great deal of statistical power that might not be possible or feasible to obtain against the base rates of the Internet.
Just wanna leave a comment here so it shows up in my history and I can find this thread again in the future
So then... we agree? I'm not sure I understand your point anymore.
&gt;Next stop... the WORLD!!! MWAHAHAHA! Soooo... feel like starting an OpenPRISM project?
What I would love is that Python 2.7.x gets all the 3.x features possible and end the whole 2.7 vs 3 argument. 
Here's an article on producing [Markov Chains](http://agiliq.com/blog/2009/06/generating-pseudo-random-text-with-markov-chains-u/), which are databases that describe the connection between words in a selection of text. It can then generate new text based on that database. It's random though, but enough to get you started into the madness that is the field of AI and Natural Language Processing.
semi-random text based on analysis of the text in my library
But, wouldn't that just, be 3.x? Uh your Imperialness? And I didn't know we had an emperor. . . I thought we were an autonomous collective
So just to confirm: It's a scientific distribution for Windows users only?
There are two types of strings in python: byte strings and unicode strings. Each element in a byte string is a byte. There are only 256 possible bytes. Each element in a unicode string is a character (also called a *unicode code point*). There are a little over a million characters defined in unicode. Meaning each element/character in a unicode string can be one of those million characters. Byte strings are useful because you can write them to files, transmit them over the network, etc. Unicode strings are useful because you can store pretty much any character that exists. So people usually like to manipulate unicode strings in their programs. But how do you convert a unicode string to a byte string? You *encode* it. An *encoding* is a representation of a unicode string. It defines a byte or byte sequence for every* unicode code point; essentially a translation table. For every unicode code point, there is a byte or sequence of bytes. There's more to it than that, but those are the essential bits you need to know. What this means when you're writing a program is that you want to manipulate unicode strings throughout, and when you want to output a string (to a file, or over the network), you *encode* it. When you read in a byte string from external sources, you *decode* it. Does that make sense? *some encodings may not support every unicode character; they may only support some subset of unicode. UTF-8 is nice because it supports everything. It defines a sequence of bytes for every unicode character.
To answer your specific questions: when you encode("UTF-8") you are converting a unicode string to a byte string. It should be called on unicode strings. When you decode("UTF-8") you are converting a byte string to a unicode string. It should be called on byte strings. unicode("abc") is the same as u"abc": they both create a unicode string with three characters. Most of the confusion comes from the fact that python 2 plays fast and loose with unicode strings. It will try and convert between them for you when you mix them together, which yields unexpected results. Python 3 has much more sane behavior: it forces you to encode or decode explicitly to convert between the two. Basically what you need to do to avoid most problems and confusion is to do your encoding/decoding at the input/output boundaries of your program. Decode as soon as you get a byte string from external sources, use unicode strings throughout the program, and encode it just before it leaves.
Can you post the innards of the `search_string` method?
Check out Nick Parlante's Google Python videos on youtube: http://www.youtube.com/watch?v=tKTZoB2Vjuk It's a short series of videos, and well worth your time.
sl4a maybe. i haven't used it for a while, but it worked well last time i played with it.
QPython
Yes, but my impression is that it's windows only because it's very hard to install these things on Windows, whereas it's (relatively) simple to do on OSX.
Well, we agree that Tor wasn't designed for a global passive adversary, yes. But that doesn't mean it'll immediately fail in the face of one.
Integer division. Integer division is such a big incentive to migrate to Python 3. That and the speed improvements (I think). Now that they decided to allow unicode literals, I think adoption will speed up.
Most of my must-haves are covered by the `itertools` module.
I'm addicted to itertools.groupby and chain.
&gt; Integer division is such a big incentive to migrate to Python 3. Meh... from __future__ import division or 1/2. &gt; That and the speed improvements (I think) Python 3 is slower than Python 2 The reason to upgrade to Python 3 is that Python 2 is no longer being developed. I'm an aerospace engineer developing programs for engineers that use unitless quantities. Strings don't really matter and when it does it's generally a bunch of numbers.
And even easier on Linux.
Convert a list of dicts to namedtuples: nt_objects = [nt_class(**d) for d in dicts]
This Pycon talk summed it up nicely for me. http://nedbatchelder.com/text/unipain.html
Oh boy. I've been arguing with Delphi users about this for a solid week who are freaking out that the next version of their language might no longer have the four(!) string types it now has plus the three char types. They would tell you that maybe *you* only need to decode/encode at the edges, but for the important work they're doing, and for performance reasons, they need to do otherwise. And that you apparently don't understand Unicode like they do, and you're probably a script kiddie and that you're really saying that *you* don't need to do this, so no one needs to really understand Unicode. :-( Blah, blah, blah, regex expressions, blah, blah, blah. &gt;&gt;Encode/decode at the edges &gt; &gt;I already demonstrated you this can be a performance killer. &gt;Sometimes you can afford it, sometimes you can't. Sure, it's simpler &gt;(especially if someone else takes care of it for you), but may not be &gt;performant enough. &gt; &gt;You still fail to understand the difference between langauges designed &gt;for simplicity at the price of versatility and performance and others &gt;designed for versatiltiy and performance at the price of simplicity. &gt;Some developers may prefer the former, others the latter. But you &gt;don't want to understand this. 
Is there a canonical comp sci source for de/encoding at the edges? I've been arguing with some Delphi users about this for a solid week. No one who uses Python counts as a source, because we're all script kiddies who want other people to do things for us that are too hard for us to understand. &gt;3. Even if you want to pretend you are not working with an encoding, &gt;you always are. If you choose not to understand what is going on with &gt;your string encodings, and think it only matters "around the edges," &gt;then you are either: a. blissfully ignorant and will be unable to cope &gt;if it ever isn't working as expected, or b. fortunate not to have to &gt;deal with such issues at all. I expect it's b for you. For 99.999% &gt;of my code I do not care about how my strings are encoded either. &gt;That doesn't mean I can pretend that 0.001% is somehow &gt;unnecessary to address. 
As long as we're beating Delphi, I'm happy. 
Hmmm.... we could end up with two python camps covertly battling for supremacy of the world. Just like Python 2 vs. Python 3. ;-)
I'm not sure what you're asking. How and when you do the encoding and what encoding you use depends on the situation. That's why, as you point out, it's important to understand what's actually happening: so you can make those decisions and not just sprinkle encode() and decode() calls throughout until it works. User BinaryRockStar posted [this article](http://www.joelonsoftware.com/articles/Unicode.html) which I think explains things well. I usually see it linked for these kind of discussions. edit: linked wrong article edit edit: oh, I think you mean you want some resource you can link to use in your argument with this group. I don't know of any off hand but let me think.
I don't have too much experience with other languages, especially Delphi, so I can't really imagine what other string types they may have. But it seems to me there must at least be this much common ground between languages: * A language must have a byte string type, used for receiving and sending strings over the network. These strings may or may not represent encoded unicode strings. (I suppose a language could do the encoding/decoding for you and never expose a byte string type, but I'm going to ignore that possibility) * A language must have a way of converting (encoding/decoding) these byte strings into other string types more suitable for whatever work the programmer is performing. (assuming it provides another type at all. Omit this point if the language *only* has byte strings) I can't really imagine but concede that it's plausible that they have found a few string types (beyond byte and unicode) that are more situationalmaybe they have performance advantages in some cases but not allI don't know. If someone were to explain to me these situations and why the different types are necessary, I would try pretty hard to test any assertions they made because I would wonder why this hasn't been adopted by other languages (like Python). While it's certainly possible, it strikes me as odd. If nothing else, additional string types requires additional work on the part of the programmer: to understand the types, the advantages, when to use them, how to use them, etc. Coming back to Python, one of its big advantages is that it's relatively simple to use, so that would be a big argument to avoid more string types. They'd have to provide some pretty damn big advantages to make it in to *this* language =) In specific response to that quote, I have one question: What "issues" are they referring to with situation b? what issues arise even despite being careful about encoding/decoding at the edges?
It's also because you should learn to use the command line. IDLE is a seductive way to avoid learning this essential skill.
The only correct response to statements like this is to disengage. Forget about winning or conveying the truth, just concentrate on not getting drawn into such mental masturbation exercises as the below: &gt; Even if you want to pretend you are not working with an encoding, you always are. If you choose not to understand what is going on with your string encodings, and think it only matters "around the edges," then you are either: a. blissfully ignorant and will be unable to cope if it ever isn't working as expected, or b. fortunate not to have to deal with such issues at all. I expect it's b for you. For 99.999% of my code I do not care about how my strings are encoded either. That doesn't mean I can pretend that 0.001% is somehow unnecessary to address. This kind of statement is not about facts, it's about 'being right'. You cannot win as long as you are trying to answer their arguments directly, because they don't CARE if your arguments are true. It's political, not scientific.
How does it differ from [simples3][]? [simples3]: https://github.com/lericson/simples3
Are there actually any recent benchmarks that show this? I remember there were some problems when version 3 was first released but there have been huge improvements since then. One thing coming to mind is decimal performance improvement in 3.3
In summary: **Facts of Life** 1. All input and output of your program is bytes. 2. The world needs more than 256 symbols to communicate text. 3. Your program has to deal with both bytes and Unicode. 4. A stream of bytes can't tell you its encoding. 5. Encoding specifications can be wrong. **Pro-Tips** 1. Unicode sandwich: keep all text in your program as Unicode, and convert as close to the edges as possible. 2. Know what your strings are: you should be able to explain which of your strings are Unicode, which are bytes, and for your byte strings, what encoding they use. 3. Test your Unicode support. Use exotic strings throughout your test suites to be sure you're covering all the cases.
basically you can buy this kind of tool all over the internet. They are used for generating web sites on any topic you need to generate google rank or at least simulate a less spammy website. 
I know 3.2 and below had a memory problem with unicode that was fixed in 3.3, but that's not what I'm referring to. I care most about list, dictionary, class processing, with excessively large data sets. Here's a good discussion, but it's lots of web-based stuff that's not my thing http://www.gossamer-threads.com/lists/python/dev/1013760
In case you're wondering about the 'magic' triangle. It isn't in fact a triangle, it is a quadrilateral. There is a vertex in what appears to be the hypotenuse of this 'triangle'. The angle of that vertex changes depending on the arrangement of the smaller pieces, and that's where the extra space if added to or removed from.
Just to make it more confusing, the type names have been shuffled around in Python 2 and 3. In Python 2.x: 1. `str` is byte string 2. `unicode` is Unicode string In Python 3.x: 1. `bytes` is byte string 2. `str` is Unicode string The reason is Python 3 strings are abstract Unicode strings by default (not encoded in any specific encoding). Encoded strings (UTF-8, Latin1, etc) are considered binary.
&gt; When you put a non-ascii character into a python2 string literal, python2 will encode that character with the default (probably utf-8) encoding. No. Rather: you pass a character to python in a given encoding (on unix probably utf-8, on windows it depends on your locale) - i.e. as a set of bytes. You can store those bytes in a str object. The magic happens when you use a unicode constructor -- u"" is interpreted as "".decode(sys.defaultencoding). Next, '' + u''.encode('utf-7') is therefore a perfectly legal construct: it's basically the same as "" + "".decode(sys.defaultencoding).encode('utf-7'), which is the same as u"\u2234".encode(sys.defaultencoding) + u"\u2234".encode('utf-7').
Yeah, I felt a bit uneasy about that aspect of my explanation, because the characters reach python in an encoded state. 
import pdb;pdb.set_trace()
To do simple tests I use that function, the first parameter is the call to the function and the second is the result. def test(got, expected): if got == expected: prefix = ' OK ' else: prefix = ' X ' print '[%s] receibed: %s expected: %s' % (prefix, repr(got), repr(expected)) So dumb function, but I use constantly to depure and do simple tests 
There's a Python routing module for OpenStreetMap data, http://wiki.openstreetmap.org/wiki/Pyroute You can also maybe load the OSM data into Postgres, and use something like [pgRouting](http://pgrouting.org/) Maybe stating the obvious, but generating good driving directions is a hard problem to solve. It'd be a fun project, but.. if you can use an existing service like Google's direction API, it'll save you a lot of work and produce substantially better results
From http://learnpythonthehardway.org/book/ex1.html "Can I use IDLE? No, you should use Terminal on OSX and PowerShell on Windows, just like I have here" ..which just seems like the author's bias towards command line tools. A perfectly reasonable bias - learning to use command line tools is a great thing to learn, and using the `python` REPL is just as functional as IDLE
However, if your 2.x is 2.7.x and your 3.x is &gt;=3.3.x, you can use `u'foo'` style literals and get the same in both.
Actually, it's getting faster at some things, due to some kind of overhaul of dictionaries and classes (IIRC). Something about objects of the same class sharing a dict under the hood, I think.
The only way to securely use tor with decent deniability is to be an entry/exit node yourself. That way it isn't trivial to identify which traffic originates from you and which you are relaying for another client. This is the way mixnets are intended to work.
For beginners - or anyone really - I would recommend looking into [docopt](https://github.com/docopt/docopt) instead.
I am certainly dreading it...
Which means you have to marshall all your useful data into C before you can multithread it and then pull it all back again - not really practical.
Check this video, it's a good source of understanding http://www.youtube.com/watch?feature=player_embedded&amp;v=sgHbC6udIqc
I ran a simple test in the interpreter, and it seems like the dictionary is maintaining order. This is not quite conclusive, so take it with a grain of salt. Personally, I never trust dictionaries to be in the order I expect, after being burned by a dictionary of 200 items that "decided" the order in which I wrote them was not good enough. However, that was in Objective C, on a Mac, so again, take it with a grain of salt.
Python dictionaries do not store order, so you should never rely on that in general, however, the arbitrary order returned by `keys()` is guaranteed to be matched by `values()` provided the dictionary has not been modified.
[Yes](http://docs.python.org/2/library/stdtypes.html#dict.items) &gt;If `items()`, `keys()`, `values()`, `iteritems()`, `iterkeys()`, and `itervalues()` are called with no intervening modifications to the dictionary, the lists will directly correspond. [Or in 3.x](http://docs.python.org/3.3/library/stdtypes.html#dict-views): &gt; If keys, values and items views are iterated over with no intervening modifications to the dictionary, the order of items will directly correspond.
&gt; One reason it might be relevant is with things like indexing becoming trickier. Eg. you have a huge string and want to extract the bytes from position 10000 to 10100. With a fixed-width encoding, finding the 10,000 character is an O(1) operation. But with variable width encodings, you essentially have to iterate through the string from the start. This is a red herring. If you want to get at 'characters' by index in a string you are almost certainly doing something wrong. Combining characters mean that you end up having to scan the entire string anyway in order to get a meaningful notion of "10,000th character". The real reason that the internal encoding of your string class matters is the data size vs. interpretation complexity. UTF-32 encoding of a large string is going to impact the number of cache evictions and memory bandwidth, UTF-8 encoding is going to mean more cycles to correctly interpret each character. To give an example (based of guesswork, I haven't tested this - profile your code): if you wanted to write a fast string search (with proper Unicode collation) decoding the stream of text you're searching into UTF-32 is just going to waste memory and increase memory bandwidth, you probably want to just work with the stream in its native encoding. The string you're searching for though is likely to be much smaller and will need to be interpreted repeatedly so using a UTF-32 encoding internally for this makes sense. Obviously you should actually be using Boyer-Moore or something similar but the same principle will likely apply.
Is writing `zipdict` really that much easier than writing `dict(zip`?
&gt;If you want to get at 'characters' by index in a string you are almost certainly doing something wrong This is what I meant by "you're more likely to be iterating through them rather than going by fixed length". However, the issue of the API does still apply. &gt;Combining characters mean that you end up having to scan the entire string anyway in order to get a meaningful notion of "10,000th character". Yes, but not when you do an **extra** scan for every match, which is a potential outcome when you use an index-based API that would be O(1) on fixed-width strings, but O(N) otherwise. Eg. look at my code snippet. Suppose we have a length N string containing M blocks. This does use searching as you'd expect, and with fixed-length encodings, would be O(N+M). But if we use a variable encoding, then, while the search isn't affected, we **also** have to do an O(N) operation to find the place we left off searching last time. As such, for each block, we do 3 O(N) scans (find start, find end, find slice start) before we even start searching. It becomes O(NM). Since M is likely to be linerarly proportional to N, this is O(N^2). This wouldn't be an issue if the API was built around the variable length encoding assumption in the first place, since it'd probably return iterators or something, rather than indexes. But code that's already using an index-based API that suddenly switches the complexity of indexing could well be affected. &gt;The real reason that the internal encoding of your string class matters is the data size vs. interpretation complexity Not really. At worst you'll get a constant-factor slowdown here in string-dense code. It's unlikely that'll break you unless you're doing something fairly specific. It might be relevant in something like bioinformatics or some string-dense batch process, but it'll just mean waiting a bit longer. The real worry is changes to algorithmic complexity. The above code could actually make a program unusably slow, turning something that took seconds into one that took hours.
 rdict = lambda x: {v: k for (k, v) in x.items()} 
Thank you, I forgot to mention that, thus destroying the point I was trying to make.
Oh, yes. Then we agree completely! My bit about HVTs was moreso concerning the special attention they get. Once an agency is interested in you, personally, then we're in keylogger/wiretapping/rubber-hose-cryptanalysis land...
As well as including an import statement, to Import this helper.
&gt; Yes, but not when you do an extra scan for every match, which is a potential outcome when you use an index-based API that would be O(1) on fixed-width strings, but O(N) otherwise. I think you missed where I said "combining characters". It's really unlikely that your program has any meaningful semantics for a diacritic mark on it's own, as such you have to combine characters(1) to determine where the nth character(2) is. Where the former characters are raw code-points which almost no-one wants and the latter are complete glyphs. You still have to do this with fixed width encodings.
Because I really love to see when I do the things good. And %s and repr() have some difference? If there isn't, is more readable do in this way. 
This is a perception problem though. It's not always the case that you have a clear hotspot, it's certainly not always the case that you can easily push all the data out to C and pull it back again, and it's certainly not the case that you have access to Big Iron. But Python users often believe that one of these things must apply in every situation, because there is a degree of survivorship bias in this community. There are many people for whom these assumptions don't hold true, but they gave up on Python long ago because it doesn't suit their needs. The classic examples are multimedia and gaming. These applications typically need to run at on one single desktop machine, where one core of the CPU is barely adequate but there are another 1 to 7 cores sitting idle, waiting for use. Low latency is critical because you need responses within a single-digit number of milliseconds, so a multi-process and/or message-passing approach is not going to work due to the overhead of having to send and receive many times per second. Nor is the data trivially parallelizable in such a way that simplistic approaches like map-reduce or vectorisation will help - you typically have a handful of quite different algorithms that you want to be running at the same time. These scenarios are pretty much the perfect use case for multi-threaded code and are poorly suited to other approaches.
So if I have a code base that I want to keep consistent with Python 3 and Python 2, what's the best practice? 
I assumed that the OP was just framing them in the context of functions for clarity, and they'd just be inlined into code.
Multimedia and gaming are hardly areas where I'd first think "Python!" even if it didn't have a GIL, though (I know that EVE Online is written in Python). Gaming (and other areas where latency are critical) are usually best served by having a core engine written in C (so you can do memory management manually and guarantee you don't get weird GC pauses at inconvenient times). If you then need scripting on top of that, then you typically embed an interpreter for a scripting language. My understanding is that Python is not convenient for this (due to the GIL, IIRC), but that's fine. Lua seems to have this niche all sewn up. One language is not going to be suitable for every purpose. Trying to build one that is leads to C++.
Speaking for myself, the biggest thing that confused me about unicode was the distinction between unicode and it's byte-form encoding. It's really not that difficult, but nobody ever really made it explicit. Maybe this will help clear things up for you too, /u/ichbinsisyphos. **unicode:** Don't think of unicode as a string. Think of unicode as a huge table of symbols that represent written characters from around the world. These are formally called "code points". When you write a unicode string, you're really just lining up a bunch of code points. For example, when you type `"J'ai niqu ta mre"`into the python interpreter, your string actually *is* `"J'ai niqu\xc3\xa9 ta m\xc3\xa8re"`. Now, for some reason that I don't quite know (but that also doesn't really matter) it has been deemed unacceptable to encode unicode strings as ASCII text files. I suspect it has to do with disk space considerations. For this reason unicode strings typically need to be **encoded** before being used... **encodings:** Encoding is the process of taking a bunch of *code points* (again, a unicode string) and turning it into some more compact byte-wise representation. There are several methods of doing so, the most common of which is `UTF-8`. **TL;DR:** Pick out your code points, and encode them. **Disclaimer:** I don't actually know what I'm talking about. Please correct any mistakes.
It works and, compared to QPython, it has the advantage that there is support for Python 3.
The best way is to use `str.format()`, which is recommended over `%` in new code: "[{}] received: {!r} expected: {!r}".format(prefix, got, expected)
 for root, _, files in os.walk(sys.argv[1]): for f in files: fname = os.path.join(root, f) # Remove *.pyc files, compress images, count lines of code # calculate folder size, check for repeated files, etc. # A lot of nice things can be done here
Good point. Yes, both `u'foo'` and `b'foo'` are accurately transferrable between Py2 and Py3. `r'foo'` is not.
So there's a bug in your code that causes an `IndexError` if the thing you are searching for is at the end of the string. For example: &gt;&gt;&gt; search_string("test test", "test") *** IndexError: string index out of range &gt;&gt;&gt; search_string("test test apple", "test") [4, 9] It is at the beginning of your `for` loop, where you are adding the length of the entire text file to the length of the search string (which, combined, is longer than the text file itself). However, I think this approach to this in general is off. This is very "unpythonic" code, and there are probably much easier (and much less error-prone) ways to do what you are trying to do. *In general* with Python, you should never have to write `for x in range(len(...`, and whenever you start using loops with `[i]` and `[j]` indices to pull things apart, there is probably a cleaner way to do it. Firstly, it looks like you are doing a lot of string -&gt; list -&gt; string stuff, when this is usually not necessary. Strings work just like lists, meaning you can iterate over them, and access elements by index: &gt;&gt;&gt; text = "a test b test apple" &gt;&gt;&gt; for letter in text: ... print letter a t e ... &gt;&gt;&gt; text[0] 'a' &gt;&gt;&gt; text[8] ' ' Which means I think lines like these are unnecessary: build_string(get_char_list('logic_events.txt')) ... testls.append(ls[j]) ... build_string(testls) == string I'll give two quick examples that get you close to what the `search_string` method does: &gt;&gt;&gt; text = "a test b test apple" &gt;&gt;&gt; text.find('a') 0 `string.find()` gives you the position of a substring (-1 if not found). You can pass a second parameter to "start looking after this index": &gt;&gt;&gt; text.find('a', 2) # Start search at text[2] 14 &gt;&gt;&gt; text.find('test') 2 &gt;&gt;&gt; text.find('test', 3) 9 &gt;&gt;&gt; text.find('banana') -1 The second method uses the regex engine to do almost exactly what you are doing: &gt;&gt;&gt; import re &gt;&gt;&gt; text = "a test b test apple" &gt;&gt;&gt; match = re.search("test", text) # re.search finds the first occurence of "test" &gt;&gt;&gt; match # Gives back a "match" object &lt;_sre.SRE_Match at 0x184d2a0&gt; &gt;&gt;&gt; match.group() # Show the string 'test' &gt;&gt;&gt; match.start() # Starting index 2 &gt;&gt;&gt; match.end() # Ending index 6 &gt;&gt;&gt; matches = list(re.finditer("test", text)) # re.finditer finds all matches &gt;&gt;&gt; matches [&lt;_sre.SRE_Match at 0x184d308&gt;, &lt;_sre.SRE_Match at 0x184d3d8&gt;] &gt;&gt;&gt; [match.group() for match in matches] ['test', 'test'] &gt;&gt;&gt; [match.start() for match in matches] [2, 9] &gt;&gt;&gt; [match.end() for match in matches] [6, 13] Compare: &gt;&gt;&gt; search_string(text, "test", before=True) [2, 9] &gt;&gt;&gt; search_string(text, "test") [6, 13] 
Udacity CS101 has auto-corrected homework I believe.
No, r'foo' is a raw string (`str` in Py2, `unicode` in Py3). Regex literals -- unlike Perl, we thankfully don't have those. You may have that association because they are commonly used for writing regexes, since eg. `\n` in a raw string is the two characters `'\' 'n'` (instead of a newline as it would be in a normal string) and regexes themselves use their own escaping. If you don't use raw strings you may have to deal with multiple levels of escaping, which is both ugly and potentially confusing.
is this a bad solution? l = list(range(100)) def is_new(val): return val%3==0 l2 = [l.pop(i) for i,val in enumerate(l) if is_new(val)] print(l) print(l2)
&gt;Python(x,y) &gt; News and updates on Python(x,y) - a free scientific and engineering development software based on the Python programming language. From the top of the page linked to. Explain this to us all. What made you think that your comment was worth making?
One utility that I found useful recently: @contextmanager def silence(exc, else_call=None): try: yield except exc: pass else: if else_call: else_call() Later can be used as: with silence(IndexError): del l[i] (just shorter and nicer than try .. except: pass) 
With all due respect, that's circular reasoning. People don't think of Python as being suitable for games because it's too slow. 10 years ago it was too slow because it's interpreted, but now it's too slow because it can't effectively multi-thread. It doesn't matter if a language is 3x slower than native code if you can easily make use of 8x as many cores. Similarly, many people in games *want* to use Python but when they find out that they can't even create completely separate Python interpreters safely they give up and settle for Lua, with all the attendant disadvantages. The language that's rapidly growing in gamedev circles at the moment is C# - that, like Python, is compiled to bytecode, but unlike Python, you can actually make decent use of threads and see massive speed improvements in places. There's no other good reason why Python couldn't be a great language for game development or multimedia, but the GIL holds it back. I'm not arguing for it to change, but I am arguing that Python people need to be aware that there *are* clear applications where distributed programming, multiprocessing, and C-level vectorisation are not reasonable alternatives to multithreading.
Unicode in Python 3 is almost exactly the same. Python 2 has some inconvenient behaviours but isn't fundamentally worse or different in its text/bytes handling.
Hi Nice post, so much confusing info about this issue around the net. I anyway don't manage, when i run the command "vcarsall.bat x86_amd64" it retrieves the following message: "'vcarsall.bat' is not recognized as an internal or external command operable program or batch file1" Any idea??
It is. When I have to use python2, I treat strings the way python3 taught me to use them, but python2 originally taught me bad habits.
I have my own groupby, prefering it to itertools' because mine doesn't impose an ordering on the input list: def groupby( myList, key = lambda x: x): result = {} for x in myList: k = key(x) if k not in result: result[k] = [] result[k].append(x) return result 
Sorry it was just a misspelling
Well, it gives you the same output, but doesn't satisfy some of the desired behaviors that are needed here. `range(100)` in this case should be a (un-consumed) iterator (for example, `l = xrange(100)` in 2.7). Then, we 1) only want to walk through the source iterator once, 2) want to produce two generators that are "lazy" (not yet consumed, so can be partially consumed as needed) and 3) only want to call the predicate `is_new` once per element, and only as-needed The code you posted requires that all elements be put into an initial list, and then all of them to be iterated over a second time to produce `l2`, while also performing a pop action on the initial list (extra operation), and we end up with two completely filled lists. The reason we want those 3 lazy characteristics above is, what if instead of `range(100)` we needed to do this with something like: l = list(range(100000000000)) How would your solution perform? Sometimes the thing we are iterating on is even infinite. (see `itertools.count()`) And then what if we only needed the first 3 elements of `l` and `l2` in the end? Seems a waste to compute the entire list (twice) if we just need a few values. And what if `is_new()` was actually a complicated, expensive operation (like a database call)? These are the reasons that "laziness" is desired (only processing as much as we need). 
I was wondering about why a modern language doesn't use unicode by default, I see now that my problem was using Python 2.x One more reason to hope for a fast transition to 3.x 
Think about it in this way: when you're talking about python 3 strings, you're talking about unicode. When you're talking about files, web pages or another world data, you're talking about external resources. Strings and unicode should be synonymous in your mind from now on (in python 3). External resources are encoded in certain ways (ASCII, UTF8, EBDIC). If you go from a resource to unicode, you must decode first. If you go from unicode to a resource, you must encode first. You must always have to know the encoding of the resources you're interacting with. With python 2 you have an extra complexity. You have unicode strings that are just unicode. And you have "normal" strings that are basically a list of bytes using some encoding and without safeguards to interact with the external world. The rest is just footnotes.
And how does that perform against groupby(sorted(list))?
short answer is I don't know. My conjecture is that, unless the dictionary hashing and the sort order of the list share common properties, I would imagine groupby(sorted(list)) would be slower by an O(nlogn) operation, namely the (unnecessary) sort.
You mean "News and updates on Python(x,y) - a free scientific and engineering development software based on the Python programming language."? And you find that to be an adequate description? From that line, you magically knew what it did, when it did it, and whether or not it's something that you might (Or might not) need? I doubt that I'm alone in saying that announcements have been done pretty poorly around here for a while. Is it too much to expect the author (Or, whoever is doing the announcement), who probably knows (Or should!) a thing or two about what they're announcing, to say what the damn thing DOES? Because otherwise, like this thing, a lot of us have to search around, looking for some kind of description. When you consider how many people looked at this, that's a huge waste of manpower. So yeah, I think my comment was worth making. I'm not sure yours was, though. 
Easier, no. But when taken in context with unzipdict, it's easier (For me, anyway, YMMV) to remember. Which is why I feel it's handy. Strangely, I don't remember needing these functions before I made them, but since I made them I've found a few occasions when they were just the thing! And maybe now they'll help you, too. If not, they do (As umlal said, below) at least serve as an example.
Agreed, list1 and list2 are pretty terrible names. But, they serve the job, are not going to screw up any namespaces because they are local, and readability isn't much of a factor when we're talking about a four-line function. If these functions don't help you to do anything easier, then feel free to not use them. 
I've got to remember that! Very nice!
I didn't knew that way, so nice! Just one question... why is recommended over %? 
rerun [command], polls for filesystem changes in current dir or subdirs and reruns [command] when they happen. I use it to rerun unit tests every time I hit 'save' in my editor. https://pypi.python.org/pypi/rerun
I think this kind of thing looks nicer with defaultdict: from collections import defaultdict def groupby(iterable, key = lambda x: x): result = defaultdict(list) for x in iterable: result[key(x)].append(x) return result
It does. But I do that sort of thing just rarely enough and, when the need arises, it is itself easy enough to do that I never bother with the overhead of using a defaultdict. 
The function use is something like that: def suma(a,b): return a+b test(suma(1,1) , 2) 
That message means that the directory in which vcvarsall.bat resides has not been added to PATH. Go to Start &gt; Right click Computer &gt; Properties &gt; Advanced System Settings &gt; Environment Variables &gt; System Variables &gt; Path. Then add the directory I mentioned in the original post, or if yours is slightly different, add that.
wow, cool tests! Is mine 1.5-2x slower while doing groupby(sorted(list)) or just the bare groupby(list)? 
I knew that most game companies these days use pre-existing engines, but I didn't realize that managed languages were gaining any significant traction. Are systems nowadays fast enough that unexpected GC pauses don't matter? Or is there a pauseless GC that is good enough for gaming purposes? My (limited) understanding is that pauseless wasn't there, yet. 
As a game dev, this function manages to be used in practically every game I've ever written: from math import pow, sqrt def distance(point1, point2): return sqrt(pow(point2[0]-point1[0], 2) + pow(point2[1]-point1[1], 2)) (If the game is 3-dimensional, I just add another axis).
New to Python so do not have anything to share, but I will definitely bookmark! :) 
This is all you need to know to use unicode properly. * Try to avoid putting unicode in your python files, ie, strange characters from foreign languages. If you need to do this, put the UTF-8 declaration at the beginning so that python will read your file properly. Since you appear to be a native English speaker, this is likely not a problem and you can ignore it. * All human-readable strings (text) should be unicode. Period. Python manages how this is stored in memory, and does a great job. Sequences, random access, regexes, everything works as you'd expect. * All computer-readable strings (data) should be byte strings. Period. This includes things like files and internet sockets. You can't send unicode over the wire or on to a disk. You can only send sequences of bytes. RULE OF THUMB: Is the user going to see it? Then u"...". Else "...". * Although Python allows you to compare strings to unicode, don't do it. * dict keys should probably be byte strings rather than unicode, unless you are mapping words or phrases to something else. * When converting from data to text, you are decoding. You must know with which encoding the data is in, otherwise you have to guess and you will likely guess wrong. Python will raise an exception if it can't decode the byte string because you got the wrong encoding. * When converting from text to data, you are encoding. You must know what encoding the computer expects it in. Some encodings, particularly the default ASCII do not handle special letters and characters, and Python will raise an exception when it sees them. * Unicode has some naughty and nasty surprises, like backwards text flow, accent and diacritical marking, etc..., which you, as a programmer, usually don't need to worry about. The programs that input and display text handle these issues, so unless you are writing an input or display program, you can ignore it. * When you properly internationalize your codebase, all your human-readable text should come from translation files. You may see code like 'tr("What is your name?")', which will look up the appropriate translation of "What is your name?". Note: It's not unicode you pass to tr() because the user won't see it -- they'll see the translation. The encodings you need to know about: * ASCII = 0-127 basic English, almost universally supported (except on old stuff like Commodore 64 which uses a different encoding). * ISO-8859-1 = 0-255 and covers some additional letters for Western European languages. Looks like ASCII for 0-127. * UTF-8 covers all unicode data points and is the de-facto standard on the internet and unix. Looks like ASCII for 0-127. * UTF-16 uses 2 bytes for 1 English letter. This seems to be what Microsoft likes, along with Asian languages. DOES NOT look like ASCII. Many other formats exist but are rarely used. If you are interested in a particular language, familiarize yourself with the various encodings used for that and you'll be good to go.
you have pow as an operator in python: def distance(a, b): dx = a[0] - b[0] dy = a[1] - b[1] return sqrt(dx**2 + dy**2) or for a n-dimensional space def distance(p1, p2): return sqrt(sum((a-b)**2 for a,b in zip(p1, p2))) 
I wasn't aware that there was a pow operator in python. When I go higher than two dimensions, your second example is similar to what I use.
When sorting 1000 random numbers in range 100 into 10 groups with: import timeit setup = """ import itertools, etrnloptimist, numpy; l = numpy.random.randint(100, size = 1000); k = lambda x: x/10 """ t1 = timeit.Timer('itertools.groupby(sorted(l), key = k)', setup) t2 = timeit.Timer('dict((k, list(v)) for k, v in itertools.groupby(sorted(l), key = k))', setup) t3 = timeit.Timer('etrnloptimist.groupby(l, key = k)', setup) iter_groupby = t1.timeit(1000)/1000 iter_groupby_dict = t2.timeit(1000)/1000 etrnl_groupby = t3.timeit(1000)/1000 print iter_groupby print iter_groupby_dict print etrnl_groupby print etrnl_groupby / iter_groupby_dict print etrnl_groupby / iter_groupby I get the following results: 0.000769706010818 0.00308924984932 0.00313838410378 1.01590491441 4.07738027203 itertools.groupby(sorted)) is about 4x faster than your solution in returning an iterator. If you create a dictionary from it, it takes about the same time. 
defined yours as mygroupby and did list(groupby(sorted(list))) vs mygroupby(list). I called list on the itertools one to expand the iterator it returns (the results are an iterator as well but shouldn't make a difference). This was in ipython so I'm going from memory here. I'm not sure how much computation is left to the iterator that groupby returns so I'm not sure /u/RebelPrince's answer is a good comparison, I made it a list to at least expand the hard part fully and make it a more fair comparison. Interesting that he got no difference when he put it in a dictionary.
Python 3 made it very explicit, it's great.
*Smacks head* Yeah, you're right. Never mind.
For one, it's capable of more advanced manipulations, including specifying a `Formatter` directly. See [PEP 3101](http://www.python.org/dev/peps/pep-3101/) for more info. I only learned about this today, and read the PEP myself :)
I'm just saying `keys` and `values` would be better names, or the alternative implementation I gave.
The core reason for it is that an operator doesn't really make sense - it makes for a more awkward syntax (no passing it around as a function, less obvious meaning in code, etc...) and introduces a potential to get weird problems if you swap ints and strings around. `str.format()` is also far more flexible and powerful, as LyndsySimon points out in his/her response.
In my lexicon, "BUG" means "Back-up Gun". That was a confusing title for a moment :)
[six.text_type](http://pythonhosted.org/six/#six.text_type) : &gt; Type for representing (Unicode) textual data. This is `unicode()` in Python 2 and `str` in Python 3.
Ehm, can't you just write a comparator function and use that to sort the list, then split the list where the seperation is?
 def rotate_array_of_arrays(aa): return type(aa)(map(None, *aa)) rotate_array_of_arrays(([1,2,3,4,5],[6,7,8,9],[10, 11])) # -&gt; ((1, 6, 10), (2, 7, 11), (3, 8, None), (4, 9, None), (5, None, None)) 
IPython also does it automatically as soon as it sees an assertion (with %pdb). And nosetests has a module that drops you into pdb if a test fails.
If that { for } is too new, the old way is great: dict(reverse(kv) for kv in d.items())
no, because you neither have a list as input, nor does the author want a list as output. think about having an infinite stream of data as input (in form of an iterator, and want to divide that into two iterators while only buffering as much from the input as needed.
Clear. Thank you for the explanation.
no problem :)
Hi Everything Ok. But after all I get the message: TypeError: unorderable types: NoneType() &gt;= str()
You're right, GC is still a problem. So people hack around it. :) Sometimes it's sufficient to be very careful about avoiding lots of small allocations, and then to force a garbage collection during downtime such as loading screens, etc. For instance, the Unity engine goes to some lengths to point this out to users: http://docs.unity3d.com/Documentation/Manual/UnderstandingAutomaticMemoryManagement.html
That looks like an error in the Python code itself. What module are you trying to build?
`from __future__ import print_function, division, absolute_import, unicode_literals` http://stackful-dev.com/quick-tips-on-making-your-code-python-3-ready (also, 3.3 finally added support `u"foo"` (http://www.python.org/dev/peps/pep-0414/) TL;DR it was valid and useful in 2.x and despite being just a NOP in Python 3 terms, it wasn't valid syntax in 3.0-3.2, which was a bit tedious for multi-version support)
I am trying with blist-1.3.4 and Cython None of them works Python 3.3
Yes, I noticed that too (I use boto at work). However, I think my naming point still stands, despite what other libraries do.
Is the error traced to a file specific to one of those modules, or is it an issue with distutils? Edit: BTW you should reply to my comments, not the original post.
Just in case. When I type vcvarsall.bat x86_amd64 gives no error but either retrieves nothing 
Yeah, that's a great point. Iterators do nothing until yield is called, so that timer test is only really testing how long it takes to return a generator: nearly instantaneous.
I confess I don't like itertools *for the most part* -- I find heavy `lambda` use makes the code too abstract, and the KISS built-in Python ways of doing most of these things are usually clearer, and almost always faster. (Calling functions in (C)Python is relatively slow, and lambdas are just functions.) On the other hand, I love list and generator comprehensions. So for code readability by others, maintainability, and efficiency, I almost always prefer built-in language constructs rather than itertools or (worse) third-party functions that code readers will have to go away and try to understand. To me the definition of `iterpartition` there looks a bit monstrous. So I'd use either the two-list-comprehension approach or the simple-for-loop approach here. FWIW, using `timeit`, with `lst = list(range(1000))` in the setup, I found these timing results: # 143 usec per loop: one = [x for x in lst if x % 2] two = [x for x in lst if not x % 2] # 345 usec per loop, using a lambda to simulate the speed itertools might be f = lambda x: x % 2 one = [x for x in lst if f(x)] two = [x for x in lst if not f(x)] # 186 usec per loop: one, two = [], [] for x in list: append = one.append if x % 2 else two.append append(x) # 97 usec per loop (factoring out the "append" attribute loop) one, two = [], [] append_one, append_two = one.append, two.append for x in lst: append = append_one if x % 2 else append_two append(x) # 493 usec per loop (using iterpartition) p = iterpartition(lambda x: x % 2, lst) one, two = list(p[0]), list(p[1])
Ok, I think my main problem was that I used unicode and UTF-8 synonymously. Just realizing what a certain encoding does is very enlightening. I'm still a little confused about how people talk about unicode-strings/objects inside of programs. I'm not sure, but they can't be much different to string-objects: containers of binary representations of characters, only that those can now be multiple bytes large.
then i get error: option --compiler not recognized Should i do a pydistutis.cfg pointing msvc as compiler?
You want it to generate words or sentences? Basically, what you'd do is split your input up, stripping out punctuation. Then, split the sentence (on space) and make a dictionary of word followings. c = "Peter piper picked a peck of pickled peppers!" f = c.split() d = dict() for index in range(0,len(f)-2): d[f[index]] = f[index+1] &gt;&gt;&gt; d {'a': 'peck', 'Peter': 'piper', 'of': 'pickled', 'piper': 'picked', 'picked': 'a', 'peck': 'of'} So then what you'd do is you'd expand on that to add more words to the list if the same one word was encountered more than once. And then you'd use random.choice to pick something. Assuming you are using dicts, and your value is a list, then you can have tons of duplicates in your list, and your 'random.choice' will choose the words which have the same frequency as what's in your sample input. Then you can use your chosen word as the key, and repeat the process for however long you like, or until you get an empty list. Then you just end the sentence. 
itertools.groupby is returning an iterator over iterators, and I believe that my dictionary expands them completely
I keep this around for when I find the need to share a directory of code [gist](https://gist.github.com/stevommmm/5770048)
Yea I might've gotten the command line option wrong. It could be -c msvc instead of --compiler=msvc. Go ahead and try replacing mingw32 with msvc in the config file too.
python setup.py install -c msvc =&gt;invalid command 'msvc' python setup.py install -c==msvc =&gt; option -= not recognized I also opened the config file inside distutils folder if it is the one you mean, i searched both msvc and mingw32 but they gave me no result
Thanks for sharing! It doesn't seem to be getting any retweets, have you hardcoded that in or is that just how Topsy serves it up? Also there are some quirks in the formatting, we lose the spaces around query terms, hashtags, Twitter handles, and links.
Give me a minute. I'll install Python on my computer and try to find out what the correct option is.
Ok, I can see that. (I thought about arguing that a downside to your groupby is that it actually can't be done as a generator. But it's a moot point as any input generator would have to be exhausted for the sorting as well before using the itertools.groupby.) I ran the tests anyway out of curiosity: 1 million elements: 1.01, 2.92 10 million: 0.97, 2.54 So, sorting + generator creation is still faster; at 10 mil resolving the dictionary through itertools is taking longer for the first time, but not by a lot. I don't have enough RAM to test it at a higher order of magnitude.
thanks a lot by the way 
&gt; for root, _, files in os.walk(sys.argv): This is invalid (will cause a `TypeError: argument should be string, bytes or integer, not list` in Py3, a `TypeError: coercing to Unicode: need string or buffer, list found` in Py2). `os.walk()` only accepts a single path for the 'top' argument. You may mean to do something clever with `itertools.chain` here instead, like `for root, _, files in chain(os.walk(p) for p in sys.argv[1:]):` Also, however you do it, you usually want `sys.argv[1:]` rather than `sys.argv` ([0] holds the name of the file currently being executed) so you don't end up processing the script itself.
The python documentation is telling me that --compiler=msvc is a valid option. I'm not sure why it's giving you an error. Is python in your path? Try running just python in cmd. It should bring up a python interpreter.
yes it is in the path and opens the interpreter
I'm sorry, I don't know what to say. Those command line options shold be totally valid. My personal recommendation would be to use Linux for python. Windows (obviously) makes python harder to use than it should be. But that might not be an option for you. Sorry I couldn't help more. You might try asking around at /r/learnpython.
Do you think something like [ARC](http://clang.llvm.org/docs/AutomaticReferenceCounting.html) will gain significant traction in the future?
 Thanks for taking the time to look at this. i guess I have some work to do. My original plan was to break the input file into chars so that I could insert the strings/char lists I'm building from templates without slicing up the strings. Thanks for the heads up on the index error. I'm still scratching my head on why my code won't find the two '\n' chars, (although it will see a single instance of newline???) however. Well, the find method does locate them in a text file. Thanks again for the help.
It's good at generating sentences that may look fairly coherent at first glance, but if you want anything like a chat bot that may actually seem realistic, you'll have to work with more advanced methods, else about ~80% of the output will end up not making a whole ton of sense.
It was not "python setup.py install --compiler=msvc" but "python setup.py build --compiler=msvc" With that command i am successful, but i don't know what is the actual difference and where the modules are saved once built. Thanks for all the help before
No it goes back to the same unorderable types error 
Well I guess it wants to rebuild it then. If you can figure out where to put those files it built, you're golden. Normally, install would make it easy.
ok i'll tell if i guess it. i gotta get a train now
Thanks again. I've got the method working now--and thanks for the code criticism. I have too much of a tendency to plow through while stitching together halfway working functions...which probably costs me more time in the end spending time debugging.
Well I wrote a simple version of what was giving me errors. I think it is better to go to simulate what I am dealing with print u"Montral" and then the error I get is &gt; UnicodeEncodeError: 'ascii' codec can't encode characters in position 5-6: ordinal not in range(128)
Yeah. You can do some interesting things like tagging words based on the context they appeared in, and cross-referenced with a dictionary for what kind of word it is (verb, noun, etc). Then you can generate sentences where there's a &lt;verb&gt; &lt;noun&gt; kind of structure, but there's still no sense in what its saying, its still random.
You didn't encode it. print u"Montral".encode("UTF-8") and it works. On the console it uses the locale setting as default, when writing to a file it might not know what to do. Another thing I found recently is export PYTHONIOENCODING=UTF-8; python foo.py &gt; output.txt Not very handy, but then you can avoid encoding every single unicode-string coming out of your program.
Depending on where your data comes from though, sometimes it makes a lot more sense to use a generator rather than wait to fill a list. If it's some kind of infinite stream of data that's fetched over the internet then the list isn't really an option. If the predicate takes a long time to evaluate you might also only want to do it once. Comparing the performance for the simple example is kind of pointless as it's obvious that the iterpartition method isn't designed for that kind of use-case. There's also no reason why use of iterators has to lead to lambda heavy code, maybe that's been your experience but I haven't noticed it.
I absolutely think [Dive Into Python 3](http://www.diveintopython3.net) (or for [Python 2](http://www.diveintopython.net)) is fantastic, and in my opinion, better than LPTHW. Not as many "assignments", but plenty of examples that you type in and add onto, and, in my opinion, it's explained better and goes way, way deeper. LPTHW is great, but I do feel like it's a "harder way" than necessary for retention and enjoyment.
Check out `math.hypot` -- it's the same except for not doing the subtractions for you and that it doesn't overflow in some cases where yours would.
I concur. I have a new macbook at work and it's stupid-fast by comparison.
That actually looks kinda cool.
Beside Google Charts it supports Highcharts - highcharts.com
scipy is one hell of a dependency for something as simple as interpolation.
Excellent library, easy to use, plus the output is actually something you'd like to show other people, unlike matplotlib). Any idea how to have the overlay popups on the worldmap?
Not sure, if this appropriate to post it here. On Werkzeug site, link to tipfy, in Strong foundation block, goes to some site that is releated to Diet and not to Python.
Removed, thanks.
&gt;unlike matplotlib Why can't you show the output to other people? The styling can be modified. http://i.imgur.com/uFAdAeR.png is generated by matplotlib and i think it can be shown to other people
Those are some nice tests. Thanks for doing them!
You're a surprising one though.
Looks fine to me.[](/surprise)
Great news for the community, thanks for the hard work on this.
I'll do that.
I like that n-dimension solution a lot. That's a nice use of several great language features.
Python 3 FTW!!!
Maybe it is possible to make each script executable without the need of a new Python instance. I'm thinking of a executor like Python process which gets its tasks with a lightweight bash script. 
* in django
why not keep them as dicts?
You may want to try a web framework approach, like Django. It has a built-in GIS framework called GeoDjango, which you could use to store your driving route and vehicle models. You could interface it with Google Maps on the frontend, maybe even with a REST API.
I've never found matplotlib's visuals to turn out looking slick even when you put a lot of time into them. Not to mention interactivity is tougher. Out of the box, something like this gives you good looking, easily modifiable styles through CSS and interactivity. Not to mention the API is dead simple. I sort of recreated your image in pygal with the following code, I think it's a visual improvement and is interactive: import pygal line_chart = pygal.Line() line_chart.title = 'Runtime effect of the input size on sse_mvm' line_chart.x_labels = map(str, range(0, 11000, 1000)) line_chart.add('Permuted', [2, 6.3, 5.9, 5.5, 5.8, 6.0, 5.8, 6.2, 4.5, 6.1, 5.6, 6.2]) line_chart.add('Scaled', [1, 4.3, 4.9, 4.5, 3.8, 4.0, 4.8, 4.2, 3.5, 4.1, 4.6, 3.2]) line_chart.add('2D blockstrided', [.5, 3.3, 3.9, 3.5, 2.8, 3.0, 3.8, 3.2, 2.5, 3.1, 3.6, 2.2]) line_chart.add('Vector scaled', [4, 2, 2.1, 2.3, 2.5, 2.7, 2.6, 2.4, 2.5, 2.5, 2.6, 2.5]) line_chart.add('Strided', [1, 1.1, 1.2, 1.3, 1.3, 1.2, 1.0, 1.2, 1.3, 1.2, 1.0, 1.2]) line_chart.render_in_browser() 
yep, that is the fundamental difference. Pity they didn't try to introduce it in 2.x.
Almost no reasons to use python 2.x now... with the exception of legacy applications and Django, there are very few libs|packages|modules that are not supporting Python 3. New code, in my case will attempt to use Python 3... Exciting!!!
What difference does it make in the end?
doesn't surprise me. to a lot of people django == python
Nope. Don't even go there
Most Flask extensions aren't all that big - it should be trivial to port most. Flask (or more precisely, Werkzeug) was the big step.
The Natural Language Toolkit has the tools you need for this. You would have to create a corpus of all the items in your library. You can then generate random text from that. The good news is that the book is [available online.](http://nltk.org/book/)
But this is wrong too: def foo(): try: something() return True except: pass else: return False it will return True or None. It will never return False. The else block will never be executed. this is usually what you want: def foo(): try: something() return True except: return False like: import socket def is_valid_ip(ip): try: socket.inet_aton(ip) return True except: return False 
err. full programmable interactivity and lots of other features. Also rendering of highcharts will be more efficient. PyGAL demo page halts my browser
actually, my code was like: def f(): try: some_exception_causing_code() if some_cond: return [some_list] except: pass finally: return [another_list] Your comments make sense, I had just simplified the structure in the post. Do you think I should update it to include this ?
thanks! re: databases, we're working on PostGres next...
How about this function that isn't in itertools ? def partition(list_or_tuple, size): for i in xrange(size): yield list_or_tuple[i::size] 
 def denilled(seq): """ &gt;&gt;&gt; list(denilled([1, None, 2, None, 3, ""])) [1, 2, 3, ''] """ for el in seq: if el is not None: yield el
Maybe. I'm out of touch with language implementation these days and I'm not sure who gets the ultimate say in where the tech will go.
Django does support python 3?
Gratz to the team, I know this was hard work and not easily solved, after looking through it all myself. Dealing with the differences in unicode treatment between python 2 &amp; 3, in combination with the differences between the 2 / 3 versions of WSGI is mostly a clusterfuck, I'm very glad flask came through and solved it.
I don't like having multiple returns in the same code level. I'd rather do something like this: def foo(log): bRetVal = False try: bRetVal = True except Exception as e: log.error(str(e)) log.error(traceback.format_exc()) finally: return bRetVal
I actually find returning at the same time a lil' less verbose, and very rarely I get into such situations as above. And since I mostly work on the web, its mostly just raising HTTP status code exceptions. [offtopic] Just in case if you don't already know this, you can also do: log.error(str(e), exc_info=True) to insert exception information into the logging message.
Yes, yes it does.
nice ! I didn't know about that !
Ummm... Maybe I am miss reading this: https://docs.djangoproject.com/en/dev/faq/install/#can-i-use-django-with-python-3
FYI, Django has supported Python 3 for about six months now. 
I've found it pretty much literally doesn't work
I guess the Python core developers liked this one too. With version 3.4, it will be built-in, as `contextlib.ignored` See here: http://docs.python.org/dev/library/contextlib.html#contextlib.ignored
What doesn't work? The core Python stuff? The android libs? Or the QPython app itself, the code editor and such? (This is out of curiosity: luckily for me it seems to work on my tablet.)
I think SQLAlchemy's operator overloading makes a lot of sense...why should you use arcane keyword arguments like Django, when you can do something like: `MyModel.age &gt;= 18` to produce the query `SELECT * FROM MyTable WHERE age &gt;= 18`. very intuitive
Good trace function (reworked it a bit recently, so it may not be perfect) - often makes it much easier to debug. (side note - don't slap this on a `__repr__` method, otherwise it'll infinitely loop as it tries to repr itself to display the first argument). Different than pdb's trace, because it's not stopping somewhere, it just lets you explicitly print a bunch of calls) def trace(f, indent_level=[0]): _,_,line_number,_,_,_=\ inspect.getouterframes(inspect.currentframe())[1] def wraps(*args, **kwargs): res = None ilevel = indent_level[0] _,file_name,calling_line,_,_,_=\ inspect.getouterframes(inspect.currentframe())[1] file_name = os.path.split(file_name)[-1] called_by = "(called from %s:%d)" % (file_name, calling_line) src = "%04d:%s&gt; %s" % (line_number, "--"*ilevel, f.__name__) ret = "%04d:&lt;%s %s" % (line_number, "--"*ilevel, f.__name__) try: print("%s(%r, %r) %s" % (src, args, kwargs, called_by)) indent_level[0] += 2 res = f(*args, **kwargs) print("%s (%r)" % (ret, res)) return res except Exception as e: print("%s EXCEPTION: %r %s" % (ret, e, called_by)) raise finally: indent_level[0] -= 2 wraps.__name__ = f.__name__ wraps.__doc__ = f.__doc__ return wraps 
Assuming you read it to mean: 1.5 which is out currently supports python3 "experimentally" user testimony says that this is actually quite stable (though I haven't tested it myself) and 1.6 which will be out soonish has full support but a lot of django apps/extensions don't run in 1.5 yet for various reasons.
Yeah, I guess you're right. I was probably conflating two different things: my dislike of heavy use of `lambda`, and my hesitancy about the `itertools` module due to having to look up what the functions do each time. Many (most?) of the itertools functions don't actually require functions/lambdas (notable exceptions being `ifilter*`, `takewhile`, `dropwhile`). 
And that's why you run your own server via the command line. No control over caching and process management isn't always a good thing.
I have at most 5% of my work time for web development. I went through an entire setup on a hosted server with apache, wsgi, python and all related modules, virtual env and finally fabric to automate the process. A few months in, something went wrong. I did not have the breadth of knowledge to troubleshoot what I messed up. I made a total mess of the internals and ended up loading a backup. Two months later it happened again. Switched it back to PHP (which almost everyone hates), but it worked. If I had the time, I'd love to figure out what exactly was happening. Sometimes you just don't have the luxury of learning all the multiple layers in depth to be confident enough to fix things when they go wrong. If it was my sole job, I'm sure I could master it, but it just can't be that way for now. I was hoping that others who felt the pain of not having a hosted python web app could feel as elated as I did when it 'just worked'. Obviously this isn't for everyone. There's 'magic' in the background that I don't understand. But I've realized you have to have a cut-off where your knowledge of internals is going to get fuzzy. Kind of like people using the phone. Do they understand the principles of a speaker and microphone? The electricity? The integrated circuits? The physics of wirelesss signaling and antenna building? I grew up with the command line for many things, but I'm just not going to learn it for web development. I used to scofff at WYSIWYG HTML editors (Dreamworks, et al.), but I've come to realize that it's that exact kind of mentality that made Apple and Microsoft so rich. They brought the power of the CPU to the masses with an abstraction layer. For me, this service was exactly that.
Great job to the Werkzeug team. This is going to solidify Flask as the future of Python web development. Some people will disagree, but I am pretty confident in the Flask team.
And there are people who think that Ruby's full name is "Ruby on Rails". But hey, that just means that we have libraries so useful that a lot of people are willing to learn a whole programming language just to use them. :-)
&gt;And there are people who think that Ruby's full name is "Ruby on Rails" those people are idiots. why make stuff for them?
Why? The command line is tedious, unforgiving, and offers little in the way of clues to help the struggling newb. Rather than taking this as a complaint, how about looking at it as a fresh point of view from someone who is genuinely willing to try, but has become frustrated by the tools of the dinosaurs. (Yep, that's us. And when we're turned to fossils, the latest generation will laugh when they hear of our keyboard-based antics.) 
this is awesome I've always wanted to learn more about this topic. thanks.
This is bad and you should feel bad. I use emacs and have spent tons of time literally `bashing` my way through the command line. There damn well better be easier tools in the future. Have you seen any Bret Victor's talks? Like this: http://vimeo.com/36579366 or this: http://vimeo.com/64895205# If one was developing on Mac OSX would you recommend them to install PostgreSQL like this: brew install postgresql initdb /usr/local/var/postgres -E utf8 mkdir -p ~/Library/LaunchAgents cp /usr/local/Cellar/postgresql/9.1.4/homebrew.mxcl.postgresql.plist ~/Library/LaunchAgents/ launchctl load -w ~/Library/LaunchAgents/homebrew.mxcl.postgresql.plist or have them install the postgres.app and get on with it? I thought we, programmers (both professional and non) champion working smarter not harder...
It'd be great if you implemented a python fallback, in case of use in pypy et al. ?
thanks! I'm learning python exactly so i can do data analysis so this is perfect!!!!
I understand your point. And yes, creating tools that ease the deployment is a good thing, whatever they are. The point I was making is based on the idea that command line skills are related to development skills, and my own experience that deploying apps in command line, for example to heroku, is an easy task (maybe I'm underestimating it). This drives me to think that, finding command line deployment hard, you must be a novice (for lack of a better word) programmer, and thus in a bad position to give advice. Maybe it's the other way around, after all. Maybe being a novice programmer gives a particularly good position to comment how easy deployment process should be. Anyway, I'll remember pythonanywhere. It might not be for me, but I'll be happy to know about it next time someone complains that deploying python is too hard :)
yes! I want to test this in pypy
If your only after the caching, you're probably fine with [functools.lru_cache](http://docs.python.org/3.2/library/functools.html#functools.lru_cache) as a builtin Python fallback (suppose you're on &gt;=3.2). Otherwise, the Github page already mentions [PyLRU](https://pypi.python.org/pypi/pylru/) as pure Python alternative.
One of the Django devs said somewhere that he is using it and it is quite stable.
I think you're missing the value of importing just one library and having a consistent interface.
Why not use if p.action == 'open' and surprise.surpriseSurprise:
You mention the implementation isn't thread safe, when it appears to be perfectly thread safe, since you never drop the GIL and never call back into Python
If you can have both, why not?
I just installed nginx and uwsgi for the first time the other day. It isn't that the command line is hard really. The problems for me ended up being: * there are apparently no best practices for configuring things, I found at least 10 different subtly different ways of getting the two to work together. * permissions, dont run as root was everywhere, but nowhere said explained how to set everything up otherwise. * non-existent or bad error messages, I guess everyone has this problem, but why do we as programmers continue doing this to ourselves and inflicting it on others? I know enough linux command line to be dangerous, but I still don't think it should take me over half a day to get a webserver to start serving a bottle app. Imagine people trying to learn to do this with no background at all. It does the whole ecosystem no service.
It might be bound to specific type of data. Or maybe you're right.
['Congrats!' for reader in rPython.readers]
I wonder if this was actually tested: I installed it and immediately ran into an issue (https://github.com/mher/chartkick.py/issues/3)
obj.attr is more readable than obj['attr'], especially when several occurrences are happening together. It makes a block of code less dense. if obj.attr1 or obj.attr2: x = obj.attr3 + obj.attr4 + obj.attr5 if obj['attr1'] or obj['attr2']: x = obj['attr3'] + obj['attr4'] + obj['attr5'] Plus, you can monkeypatch a namedtuple class to have a little extra functionality, when you don't want to create a full class. 
There: [interpolate.py](https://github.com/Kozea/pygal/blob/master/pygal/interpolate.py)
Great!! Excellent step by step tutorial!!
Yeah, is it... or isn't it....
Nice. One for your list: def trigonometric_interpolate(x,y,precision=250): """ As per http://en.wikipedia.org/wiki/Trigonometric_interpolation""" n = len(x) - 1 delta_x = [x2 - x1 for x1, x2 in zip(x, x[1:])] current_x = 0 for i in range(n + 1): yield x[i], y[i] if i == n or delta_x[i] == 0: continue for s in range(1, precision): X = x[i]+s*delta_x[i]/precision s=0 for k in range(n+1): p=1 for m in range(n+1): if m==k: continue p *= sin(0.5*(X-x[m]))/sin(0.5*(x[k]-x[m])) s+=y[k]*p yield X,s
The only thing I found that I didn't like is that users are able to \^C right out into the phone's shell. Probably shouldn't be happening.
Ouch, rough time to be trying to market a centralized identity/login solution considering current events.
Here's the python implementation of the Yada protocol: https://www.github.com/pdxwebdev/yadapy
Central to your mobile device. This is not a service like openID. You own your identity.
Do you mean: "identities"? Clearly you did. Edit: That aside, where is the description of the underlying mechanisms / ideas? Edit: And, does it or something similar support authentication without a mobile device (e.g. by a local key)? Edit: Not to mention running own server for it, not the centralized yadaproject.com
Had a good laugh with a coworker over a bit of javascript he wrote one time that read: data.data(data)
&gt;no, because you neither have a list as input, Yet the title says "filter a list..." and the first code examples show lists as output?
I will always remember the Java line ``Alien alien = new Alien();`` from a game we wrote in CS101. Everybody loves Java.
bookmark? :-)
JUST BECAUSE PYTHON PWNS!!!!!!!!!!! #OMGOMGOMGOMGOMG #SWAG
Assuming that the keyboard is the end-all, be-all of input devices puts you right up there with the telegraph operators who were convinced that nothing could allow them to send messages faster... "There are going to be more different types of input devices in the future and most of them will be more complicated than the command line." That's just silly. Which is more complicated, the mouse or the keyboard? Trackball or keyboard? Trackpad or keyboard? The trend is clear, the interfaces of tomorrow are less complicated, yet more versatile than the venerable keyboard. Enjoy being the future fossil-fuel. (I guess there really is no fuel like an old fuel.)
Have you tried random eviction instead of LRU? from random import randint class REDict(dict): def __init__(self, maxsize, *args, **kwargs): dict.__init__(self, *args, **kwargs) self._maxsize = maxsize self._keys = [] def __setitem__(self, key, val): if len(self._keys) &gt;= self._maxsize: i = randint(0, self._maxsize - 1) del self[self._keys[i]] self._keys[i] = key else: self._keys.append(key) dict.__setitem__(self, key, val) This little python alternative is only 4-5x slower than lru.LRU. $ python bench.py redict.REDict Time : 2.63 s, Memory : 100816 Kb $ python bench.py lru.LRU Time : 0.53 s, Memory : 124084 Kb 
 def safe_rm(path): if os.path.exists(path): os.remove(path)
thanks a lot
I really love Matplotlib. It is one of the most comprehensive and versatile plotting frameworks out there. There is probably no other software package that I am more eagerly watching at the moment.
It's one of my most used Python libraries and I couldn't do much without it, but I still wish the API was easier to use and a bit more Pythonic. 
My understanding is that Matplotlib initially tried to mimic Matlab. Nowadays they are going way beyond that though and the API is getting gradually more pythonic as it departs from Matlab. I guess the most glaring thing these days is the use of acessor functions (get_foo, set_foo) instead of attributes. 
&gt; I guess the most glaring thing these days is the use of acessor functions (get_foo, set_foo) instead of attributes. Yep, the OO interface is too reminiscent of C++/Java. I tend to use the pylab interface because of this, though it's state based and not very flexible.
&gt; assuming that the keyboard is the end-all, be-all of input devices I went far out of my way to not say that. I said that touching symbols with your fingers isn't going away. &gt; less complicated, yet more versatile such as? It's pretty simple to brainstorm on this, what part of the body will people use. There is only one sane answer for humans: hands. What will they do with their hands? probably all sorts of things: swipe, grab, lift, wave, etc. But the simplest and fastest is tap. That's not going away. So the idea that we'll be using something other than tapping things with our fingers seems less like telegraph operators and more like saying that video will replace writing. Expert interfaces have only gotten more complex, look at the inside of a jet airplane compared to old ones. It didn't get simpler and more intuitive, it went the other direction. I don't see any reason that future developers will be use an easy interface when they don't now, they'll want as much power as possible, even if it's complex and has a learning curve. You are only thinking about casual users, in which case the trend is towards simpler and more intuitive interfaces. Maybe the normal computer user will never use or know how to use a keyboard, i bet that's true but experts will always use some complicated system with a lot of buttons/keys/switches, real or virtual, because hands are where you have the most dexterity and experts want power over simplicity. Don't forget about the people who *make* those intuitive interfaces for casual users. The experts who will, in the future where everything runs software, be all over the damn place.
Thanks! * http://docs.python.org/2/library/itertools.html#recipes * http://hg.python.org/cpython/file/v2.7.5/Doc/library/itertools.rst#l841 * http://docs.python.org/3/library/itertools.html#itertools-recipes * http://hg.python.org/cpython/file/tip/Doc/library/itertools.rst#l808
The final code is called iterpartition and returns two iterators, no lists
Seriously? A three line return statement with two for-loops and a lambda? "Simple is better than complex." Not to mention shadowing `itertools.tee` with a `tee` parameter.
Does anyone know which version (if any) has sub-second time support?
What you said is true. What I just need is patience really. I know that Beautiful Soup is used by many. How do you like it? I've basically used regex in the past mostly. (Sometimes mechanize, which will hopefully be supported in 3 soon) Thanks again, for your help. :) 
Yeah, the original was far more readable and easier to follow. This one takes a few reads to figure out what it's trying to do.
It was my first foray into web scraping, so I don't really have anything to compare it to. I found some things difficult to figure out, but I think a big part of that had to do with what I was scraping, not Beautiful Soup itself. I used IPython a LOT to explore Beautiful Soup's interpretation of the page and help me figure out how to fish out what I needed. Basically I'd capture the page and store it in a database (I could have used a file, but I was capturing the pages in a log table anyway), then to explore I'd retrieve the raw page from the database and start playing in IPython. This was incredibly helpful and quite a bit of my explorations ended up going right into the final program.
I saw their presentation at Linux feast in Austin a few weeks ago. I was super impressed with the product. 
What do you mean by that? You can already use your own tick formatter to display ticks in arbitrary styles.
Thats right. Think of it as a stretching exercise exploring what is do-able, but not necessarily what should be done in production code. It's a blog entry rather than an excerpt from production code.
don't you have to yield list_or_tuple[i*size::size]?
in-process cache
That's fair, I'm not sure how it's framed. I didn't read the context, I just jumped to the code and parsed it. Maybe you explained that it was simply a thought exercise.
This is racy, you should just catch the exception. It happens to be a use case for [contextlib.ignored](http://docs.python.org/dev/library/contextlib.html#contextlib.ignored), mentioned upthread.
We're testing at work and so far I am really impressed. It's pretty clear that they have they have learned from some of the early mistakes of puppet and chef, compared to them (at least in my humble opinion) things like extending facts and writing modules makes way more sense. I think the documentation leaves a bit to be desired, they glance over a few subjects that can be extremely powerful and are eat to use (like using compound matching in jinja templates), but really it's pretty easy to piece it together and get it working. Best of all, it's in EPEL which makes it a much easier sell than adding a bunch of other repositories (and managing gem requirements). Edit: I should be more specific about the documentation. Sometimes it feels like they focus on the remote execution and not so much configuration management.
Why did you just basically post a tutorial to ftplib in /r/python... 
I mean support for it in the built-in datetime locators/formatters of course. I think this is the issue whose commit offers what I'm looking for: https://github.com/matplotlib/matplotlib/issues/1391
Because this is the internet, and Randall is popular. In all seriousness, it's a small patch (~70LOC) that makes a nice feature and now it's in the official release instead of being in a "user repository" (damn it mathworks) so it will stay working. I've used it several times since the script was made for presentation plots and it really helps in keeping people from nitpicking insignificant details when you're trying to talk big-picture.
This depends _heavily_ on the ORM. Some databases don't support relationships at all (Mongo, Cassandra, etc.). At that point it's up to the ORM to decide how best to select, join, update, delete, etc. what the programmer considers "related" data. Other databases that do have foreign key abilities have different problems though. The ORM may create sub-optimal statements by doing lots of unnecessary joins, and lots of other things that make DBAs scratch their heads. I think the point made in this article, though, is that if a programmer wants the database to behave and be represented similar to their code, the expectation would be that a one-to-many type would exist. If the ORM is doing magic behind the scenes to create tables mor similar to what you've pointed out, then it's probable that a one-to-many foreign key is being created, but reported back as many-to-one. If you're this concerned, though, you should be writing the raw SQL. I know there's a huge leap between using something like Django's data layer and making your own...but...sometimes you have to pay that price.
A ManyToMany field on the band handles his use-case just fine. Also in real life Musicians can be in multiple bands. 
This is in fact the correct solution. &gt; And, and this is the difference between the proposed OneToMany and the already-existing ManyToMany, each musician is in only one band. this negates the entire example for me. Why are we defining a new type of relationship which is necessarily worse than the existing alternative (ManyToMany)? Were this to be implemented, how would a person make this the least bit reusable? Now Band, Agent, and Union are all hard-coded to require the same Musician model.
An m2m requires an additional join. 
[Fixture issue #36](https://code.google.com/p/fixture/issues/detail?id=36) and [Fixture issue #43](https://code.google.com/p/fixture/issues/detail?id=43) added support for serializing a list to a ListProperty. Whether a OneToMany field has more [lock contention](http://en.wikipedia.org/wiki/Lock_\(computer_science\)#Granularity) than a ManyToMany table is implementation dependent.
This. [EDIT] * http://docs.sqlalchemy.org/en/rel_0_8/orm/collections.html#dynamic-relationship * http://docs.sqlalchemy.org/en/rel_0_8/orm/relationships.html#one-to-many * http://docs.sqlalchemy.org/en/rel_0_8/orm/relationships.html#sqlalchemy.orm.relationship (`backref`, `cascade`, `dynamic`, `lazy=`)
I agree with the other commenters, it's just not necessary and the musician-&gt;band example is flawed. If you really need this, just use SQLAlchemy (arguably, you should be anyway. Django's ORM is poor at best)
Oh no, that means its not roflwebscale right?
Hello! I'm an experimental bot. You said: &gt;Oh no, that means its not roflwebscale right? Unless my code has failed me, I do believe you have used "it's" or "its" incorrectly. In future, use **its** for possession and **it's** as in "it is". Have a lovely day! ^Please ^excuse ^me ^if ^I'm ^wrong.
[It's pretty easy to use](http://pages.github.com/). EDIT: Typo.
In the footer: Powered by [Pelican](http://blog.getpelican.com/) Its a static site generator, just like Githubs Jekyll, but you have to run it manually instead of Github doing it for you ;)
I'm curious as to how close to perfection this is. Since this is a fairly straight forward computation, it shouldn't be too hard to write optimized C or even assembly code to do it. I'm curious what the best we can achieve is, and how many % off they are from that here.
Cool! I'd love a similar tool for my facebook comments :D
My new favorite bot!
Oh that's hot!
``` Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; MemoryError ``` Soon you'll have to use a generator expression
What about Musician-&gt;Agent? Say in my app Musicians can only have one Agent, which is quite reasonable. Many-to-many won't enforce that for me.
* http://docs.python.org/2/faq/gui.html * http://docs.python.org/3/faq/gui.html * http://wiki.python.org/moin/GuiProgramming * [Some Python IDEs are written in Python](http://wiki.python.org/moin/IntegratedDevelopmentEnvironments) (e.g. [spyder](https://code.google.com/p/spyderlib/)) * http://redd.it/1fmgdt * http://stackoverflow.com/questions/15406002/does-python-go-well-with-qml-qt-quick 
A) To get greater bandwidth you need something implanted, the skull blocks a lot of signals. Medical science isn't even close to being able to install a port in someone's body that isn't guaranteed to cause infection (it's a surprisingly hard problem) or require massive amounts of immune suppressing drugs (which are *very* unhealthy) B) Brain interfaces require executive function to control, as in: you need to be concentrating on the task at hand for it to work. The equivalent and hunt and peck typing, not muscle memory. The only other alternative is using the plasticity of your brain to learn how to use a more complex interface that's wired into your head. That's doable but it will be a crazy amount of training, very high learning curve. And that new skill will use brain areas that would have been used for something else. It would be like having another limb. I just don't see that being better than using hands, which our entire species has evolved around. I'm sure some kind of brain interfaces are coming and will be really cool, useful for all sorts of things no one has thought of yet, but they aren't some kind of silver bullet. Our brain structures are built around high dexterity tasks with our hands requiring low levels of concentration from the executive areas. Also, we are now so far into the future that our ability to predict with any accuracy is basically zero. So sure, maybe brain interfaces will replace the command line someday. But if that's your best alternative then we're stuck with it for quite a while.
I don't undertand how Fortran isn't the fastest 
really nice, I like it !
That is still not right!, I warned you in your other post. Stop scraping websites, its bad and broken and against terms. Stop doing it. Now.
I use the following: * [TortoiseHg](http://tortoisehg.bitbucket.org/pl/) -- PyQt * [Soldis](http://www.soldis.com.pl/) -- wxPython * [My own application](http://zapy.readthedocs.org/) -- PyQt and Dropbox.
Please stop spamming the sub, you are getting complaints every time
Martin Brochhaus has your back: http://martinbrochhaus.com/pelican2.html
or just filter(xs)
New pre-release has had some work done to the ORM. Haven't had a chance to look at the docs to see what was changed though. Edit: Typo. Damn auto-correct.
Into tally agree. But, just to play Devil's avocado, we can all think of a one-to-many example, right? 
http://www.youtube.com/watch?v=sm2d0w87wQE Not so far away, since there's a working example now. Or, non-invasively, http://www.neurosky.com/Products/MindWave.aspx It's coming, and in a very short time it'll be faster and better than any keyboard. But hey, you just keep drawing those pictures on the cave walls with your charcoal... 
Then a foreign key field on the Musician to the Agent will be fine...
A join is pretty trivial on most systems, its been an integral part of the relational database model since day one and are highly optimized in all RDBMS. Saying you can't handle "real" traffic on a site that uses joins in its queries is ridiculous to say the least, especially since Python's overhead while generating the response would be far far higher that of a m2m join query on a properly indexed table of any size. but yeah, in this case its a bit overkill.
Unicode strings are an abstraction, much like (long) integers and floats. If you don't think about the actual bytes that make up the number 1000000000000000000000000000000 or the number 0.1, don't think about the actual bytes that make up the string u'_'. It won't help because you don't have access to those bytes. They're not even all that consistent from version to version or platform to platform anyway, and they're not supposed to affect your program.* When you encode the Unicode string, you'll get different bytes anyway, and they'll be consistent. \* Unfortunately, if you ever have to deal with "astral" characters in Python 2 -- characters with numbers &gt;= 2^16 , such as emoji -- then the internal representation of them that you're not supposed to care about *might* bite you at some point. Oh well. 
How does PyPy 2.0.2 compare with this in using the Pure Python only version?
Look forward to trying it out.
In no way am I suggesting using JOIN is a bad idea. I'm saying unnecessary JOINs are expensive timewise. Yes, Django is slow, but if your record set is millions on both sides of the JOIN, then no...the JOIN is not highly optimized in many RDBMS. Worse yet, imagine a crappy ORM that paginates results but makes a new query every time you click on Next or Back. You might issue the same ad-hoc query with one or more JOIN over several record sets that are millions of records each. Obviously, this is where using stored procedures and highly optimized queries comes in handy. But none of this negates the usefullness of a one-to-many relationship type.
If you want a proper python environment take a look at bot brew basil. Not only do you get python but can run a working Debian system.
I'm sure you could make it a bit faster by implementing the entire thing in optimized C and importing it from Python with the most minimal usage of Python objects as possible, but that sort of defeats the purpose. (Of course, he did do an example in Fortran so perhaps it'd be worth writing it in C just to see how it compares.)
Yeah, unfortunately it'd be way too easy if you could simply add "@autojit" to every function and instantly make it super duper fast. I'd be curious to see which cases it is able to handle well and which it can't.
&gt; in a very short time it'll be faster and better than any keyboard haha, I take it you are expecting a jetpack and a flying car soon too. Who cares what the people who build these things think are the limitations inherent in their own approaches? I'm sure you know better.
It's funny the author would say that, when we (PyPy) did the 2.0 release we put out a survey to see who was using PyPy, and what they were doing with it. There's quite a lot of people using it for science.
Salt dev here. We are very consciously aiming to refactor our documentation to make it easier to navigate and to fill in gaps. Most of our documentation is written by those that already understand things pretty well, so getting new users' perspectives is very important and always appreciated. We would love any feedback you're able to provide. Feel free to [open an issue on github](https://github.com/saltstack/salt/issues), post to our [mailing list](https://groups.google.com/forum/#!forum/salt-users), or even just send me a direct message here on reddit.
Did you guys read the entire article? The Scipy function is a Python wrapper of C code.
It is listed as a "Python wrapper of C code." Much of CPython's standard lib is a Python wrapper of C code; that description isn't really too specific. The core implementation would need to be posted to really compare.
or better yet use numpy and vectorize it. It's really 1000 times faster since you get to run it in C++. from numpy import array, norm def distance(p1, p2): a = array(p1) b = array(p2) return norm(a-b)
Here's a Markov generator I wrote a while ago, using a bunch of Project Gutenberg books as the corpus: https://github.com/nemec/markov-generator/blob/master/markovgenerator.py The output: https://github.com/nemec/markov-generator/blob/master/out.txt Also, the `order` argument to the generator is how many [n-grams](http://en.wikipedia.org/wiki/N-gram) are used to determine the "next word" in the sentence.
I will not use the API. But I made the code PEP-8. I also added two more chapters to the documentation. Can you check the project again and tell me if I did the PEP-8 right?
For the love of god, do you not understand why scraping is so bad? Its subject to randomly breaking for no reason just because google decide to change there layout. Its also illegal. Google specifically ask you do not automate the human facing side of their company.
Very interesting, thanks op. I tried to install it for my python environment but couldn't, something fails when installing the pyllvm, then I tried it with anaconda and worked well enough. However, I tried to build some functions with really basic stuff like concatenating strings and it didn't work, others did work. 
Everything that exclusively manipulates lists of numbers and numpy arrays.
I did the same thing in a very similar way a while ago: https://gist.github.com/dAnjou/2628336 I was waiting for someone to turn it into a Gedit plugin :D
I beg to differ. There is way too much repetition going on. And in a lot of places it's not pythonic and unreadable code.
Why don't you just rebalance annually or something? This post seems to imply that you rebalance continuously, or whenever the portfolio reaches a certain threshold of 'out of balance-ness' Aren't the traction fees eating away at any gains? 
And why do you still insist that scraping is bad. Lots of people scrapes lots of websites successfully. It gives you the same data as the API, or even more. And actually it hardly ever breaks, even if it does it takes minutes to fix.
Is there an english version of Soldis that runs in Linux?
But thats not the same. First it should be filter(None, xs) and second: filter just checks if the elements evaluate to false, so it would remove empty strings, empty lists, tuples or zero-values, not only values that are None.
hopefully steps in the right direction!
Ooops, I counted 67 lines of rubbish.
The original author of enaml now works directly for a large investment bank that has invested heavily in an open-source fork called nucleic. This has a lot of improvements over "Traits-based" enaml. It is definitely worth looking at: https://github.com/nucleic. 
Yes, but I was asking *how much* faster. If we give up Python completely and write write pure assembly, what's the best we can hope to ever run this computation at. I want to see how close to the "best" Numba is right now. And by optimized, I really meant "provably optimal".
Thank you so much ! :D
Thanks ! I've been learning Python since few months. It's motivating to do stuff when data is so funny, like here with Twitter.
I'd really like to do the same kind of stuff with Facebook. I don't know if there is a feature that allow us to download a similar file. Sounds more complicated for them to generate.
Just some ideas for better scoring: a) score = sum(math.log(len(s)+1) for s in gaps_between_hits) This would favor matches with clustered hits (e.g. **ab**xxx**cd** &gt; **a**x**b**x**c**x**d**) bug ignore additional characters at the beginning or end (file paths or extensions). It also favors small compact matches. For even better results you could strip special-characters from gaps and not count them in your scoring. **ab**/xx/**cd** is likely better than **ab**xxx**cd** b) I forgot the second idea while explaining the first one. :/
No. Soldis works only on Windows (currently). It is used mainly by the Polish civil engineers (and is popular among students).
Don't underestimate the speed of CPythons re implementation. If your LCS matcher is implemented in pure python, I bet that a C regular expression matcher is faster.
Its inpolite, rude, and against terms and conditions. Stop doing it.
Fair enough, the more important point I was trying to make is that LCS is going to get better results than the regex currently being used. As to my claim about which would be faster, perhaps this disclaimer will suffice: &gt; I am not a lawyer, financial adviser, or computer wizard, and you should do your own research before investing in a particular algorithm. Past benchmark performance does not guarantee future results. My advice comes without warranty or guarantee of accuracy, and may potentially be wholly inaccurate. Long LCS.
I'm sorry, JOIN's can't be that bad. These are the two models: https://gist.github.com/orf/5792769 I filled the database with 5000000 Artists and 1000000 Bands, then filled the ManyToMany relationship with 7,283,299 links using the latest version of PostgreSQL. The JOIN's tested can be found here: https://gist.github.com/orf/5792914, and the EXPLAIN's for each query can be found [here](http://explain.depesz.com/s/Y7i) and [here](http://explain.depesz.com/s/yz4). Each query, tested on a random selection of artist and band ID's took on average 7ms to complete (request to full response). I got 142 QPS running a JOIN query on a table with 5 million Artists and 1 million bands across a m2m table with 7.2 million links, on a commodity laptop, on a completely un-optimized PostgreSQL instance, while playing a game of TF2. A decent database setup could easy handle a join across many many millions of rows on either, or both, sides of the join with thousands of QPS. RDBM's are incredibly mature and can handle tens of millions of rows on commodity hardware without breaking a sweat. Tech specs: 2010 XPS 17, quad core i7, 8gb of RAM, 2x500gb HD (PostgreSQL database lived on the second, mostly unused disk).
Well, you could look through their API. I stopped messing with their service a long time ago, because they kept changing the stupid thing every month. But hopefully it's a lot more stable now.
Does anyone know an open-source example of Qt Quick in Python? I'm learning QML and I'm interested to see how it is used in real-world programs.
All right then. I will do more useful coding. Do you have an idea, something for me to program that will be enjoyable?
Thanks :) (I'm not sure of that, but I appreciate being encouraged and I'm gonna try to improve it.) 
&gt; I just gave up on Ansible last week, Would be interested in a post about the experience.
Could be. http://www.google.com/search?q=qml+python
Gonna need to see an example code. Its very unlikely that the breakpoint is actually stopping the program. I a long shot, check the line indentation after your "intensive function". If your breakpoint is on the same code block as your intensive function, it could be breaking repeatedly, making it appear that it never ends, when it just takes a very long time. 
[Non-mobile link](http://en.wikipedia.org/wiki/Levenshtein_distance), for the lazy.
Is this in an imported module?
So, your laptop running PostgreSQL with a single user stream hitting it at once with one type of activity was able to join very small record sets from multiple tables on a fireign key ID. Yes. So we've proven that you can get &lt;150 QPS on a laptop. In the real world, 150 QPS is a joke. I'm not trying to be a jerk or argumentative, I'm just sharing real world experience that I've had being a system engineer for companies that do nothing but database work. As soon as your joins are working on tables with many columns, some of which are going to be total crap because of a legacy issue or code creep, this whole house of cards comes crashing down. More to my original point, though, I said _most_ database platforms. You try running this same query with MySQL and tell me what happens. Watch your temp space jump to the size of the record sets. Then do a count on the result, or some kind of ORDER BY. MySQL (at least versions previous to the latest release) is shit at this kind of thing. Finally, go ahead and add in all kinds of locking semantics caused by updates, replication, etc. And sink all your writes to a single "master", of course. And, because you're allowing the ORM to make your SQL statements for you, you've got no insight into WTH it's doing or why queries are taking so long to return result sets. Like I said, this is nontrivial. That is exactly why DBAs get paid handsomly at many companies around the world to solve the exact problems I've just listed. In this particular data model, yes, the tables have few columns, and you could probably tightly regulate how large they are. In the real world, shit code makes it into production and column creep happens. Everything gets slow, and before you know it you're watching a query with three or four joins and two sorts take your system to its knees. I've seen it countless times.
I don't understand the downvotes here. This a very good analysis of the weaknesses of python and is 100% relevant to this subreddit. Please watch before voting.
I've had a similar issue sometimes when using remote debugging for Celery tasks and encountering an exception. Restarting the debugger fixes it. 
Yup. Same here. Stuff like `width, length = x.shape` fails. I had to use `width, length = len(x), len(x[0])`
Great work!
.
Quite nice talk. Although I'm a bit confused. He said he'll talk about minor issues in the beginning and go to more important ones towards the end but I feel like those in the beginning are way more limiting than the ones in the middle ... and in the end he totally lost me :D
Isn't "Python trick" a kind of oxymoron, given that the "right" way of doing anything is supposed to be obvious?
A lot of good points in the talk, I'm somewhat glad he went over GIL first and got it out of the way. At this point i think talking about the GIL may be beating a dead horse when talking about problems with python. his talk about the built-in functions is in my opinion the number one problem with python. I don't understand why 'str' 'type' 'any' 'map' and 'len' etc are semi-reserved words*. I'm not sure I agree with his solutions. I think "obj.length()" is better than "obj.length". I really dislike having a polluted namespace, but at the same time it is somewhat nice to have common functions so quick to access. * the one good thing about it is it has on many occasions stopped me from being lazy. instead of typing 'type = blah' it forces me to write 'type_foo = blah', self documenting that the variable will always hold some foo type and not a bar type or what have you. And the same with 'str', forcing 'name' or 'url' or some other more descriptive name.
Many of his suggestions are terrible. - Moving built-in functions to methods would mean you either need monolithic base classes or you can't provide a 'default' implementation. (The guy at the end during questions nails this, and a forced base class destroys the duck typing ideal of Python). - Adding sugar to arguments would reintroduce the problem that was removed with 3.x with the removal of unpacking in arguments - it made the function signature and annotation stuff way less useful and powerful. It's simply not worth it to save a line of code. - The if statement change would be less efficient and clear. I don't see the benefit at all, it just introduces this magic return functionality where the last mentioned value is assigned, lines later. - The for loop and list comprehension merge would also be terrible - it would make every for loop consume extra memory for no reason. It would also mean you'd need to either consume it afterwards (if it was a generator), or make a list (meaning it couldn't be lazy, like a generator expression). It would also kill the optimizations list comps make. - His suggestion for dictionary unpacking is fine - but the short syntax makes no sense as dictionaries have no order. Most of the other stuff has been covered before time and time again, GIL and stack limit/no tail recursion have upsides as well as downsides, and the reality is that CPython the way it is is probably better for most people. lambdas and blocks are, in my opinion, an overblown issue - not assigning something a name isn't a huge thing to me, and defining it properly generally encourages better code. I can kind of see the argument for better code order, but it generally doesn't matter *that* much. Most of his suggestions would make Python code less clear, in my opinion. I don't think it's a bad video - and I thought many of these things when I started out in Python. However, when you think about the consequences on the language, they end up actually being net losses, or at least not really worth implementing. 
tl;dw?
 &gt; Transposing a matrix OK, so I know nobody would ever actually do a matrix transposition like this, but I want to point out that it has some problems. It changes the inner lists to tuples, which can cause very odd behavior. It also works without a problem on cases where a matrix transpose *should* be an error, for example [[1, 2, 3], [4, 5], [6, 7]], which isn't a matrix, and it will give you some funky results.
&gt;And by optimized, I really meant "provably optimal". We're Python users. We're supposed to laugh at people who bit twiddle for nanoseconds. 
It's a 33 minute presentation on the internals of Python. There is no tldw.
I feel like "Python trick" is really just "Python syntax beauty"
why?
ok but in terms of the content?
Going to the gym :)
Oh cool, it's like [this](http://stackoverflow.com/questions/101268/hidden-features-of-python) but on a shitty site.
Does it work like you expect?
It is kind of obvious if you know Python, but you can get an awful lot done in Python knowing just a small subset. List comprehension is a good example of that. If you know list comprehension, that is often the obvious way, but if you don't know list comprehension you can get it done with a loop and append. 
Yep! Two powerlifting state records
so "Python trick" is really just "Python"?
Well, there are two reasons to make the search in github. - First, many (many!) github projects doesn't appear on google searches. - I have found that a good quantity of github projects are small and very appropriate for learning. Also, I thought the OP already had googled so there was no point reminding his/her of that.
Yes, you can get a lot done in Python without knowing Python. These still aren't "Python tricks" any more than a page from a book of your favorite author is a list of "English tricks."
This library is addressing the specific function of LRU caching.
Great point. I never thought about GIL. Yes this should be thread safe.
Should be easy to do. I could even wrap some existing python implementation for this.
Any time you justifiably use `itertools` is awesome.
Thanks for detailed reply to the critique. &gt; forced base class destroys the duck typing ideal of Python Having a base class `Collection` does not prevent you from implementing just the protocols you need (say, `.map` or `.each`) without subclassing `Collection`. &gt; removal of unpacking in arguments - it made the function signature and annotation stuff way less useful and powerful Personally, I miss unpacking in arguments *a lot*. *And* I think it makes signatures more robust and explicit. *Plus* I don't really like annotations, because different annotations do not *combine*, like e.g. decorators do. In general, I would love to use *any* valid `lvalue` in function signature. &gt; The if statement change would be less efficient and clear. &gt; The for loop and list comprehension merge would also be terrible - it would make every for loop consume extra memory for no reason. There would be no efficiency penalty, because you can generate different byte-code depending on whether the return value is used or not. (E.g. CoffeeScript generates different JavaScript in those cases). And for me having single `for` and `if` constructs makes it closer to the ideal of "One Way". &gt; dictionary unpacking is fine - but the short syntax makes no sense as dictionaries have no order. The short syntax is a shortcut when the variable name is the same as key, nothing to do with order: `{'name': name}` =&gt; `{name}`. On the unrelated note, I *would* like for dictionaries to store insertion order.
Python is not enough like Smalltalk and CoffeeScript
Nice to know!
The general account settings page in FB has a 'download your archive' button at the bottom. You get a zip with a bunch of html-encoded fun to parse through.
The order is not strict :-) However, for me, real lambda would be the most important change. I, somehow, was always able to get around GIL/recursion problems.
lambdas and blocks are, in my opinion, an overblown issue You're forgetting about the potential for lazy evaluation here.
I cannot read blogs with some guys big fat face looking right at me.
I'm curious, why `obj.length()`? &gt; instead of typing 'type = blah' it forces me to write 'type_foo = blah' Proper capitalisation (`List`, `Set`, `Tuple`, etc.) would solve that as well.
Another cool application of lambdas (that I didn't mention), is that you could implement a test function like this: test 'that we are sane', -&gt; assert 2 + 2 == 4 Right now to achieve a similar effect, py.test and nose need to resort to meta-programming, collecting tests based on function name: def test_that_we_are_sane(): assert 2 + 2 == 4
More of a "Python solution that isn't obvious enough for everyone". It's good to have these threads from time to time, just so we can reduce the number of times people reinvent the wheel :-) 
What lazy evaluation can you do with lambdas/blocks can't you do with named functions?
Oh thanks ! Merged
I'd say that most of the suggestions would bring a lot of Ruby-esqe functionality and style to Python.
Apparently the author is not aware of the [decorator module](https://micheles.googlecode.com/hg/decorator/documentation.html). Most packages that expose decorators, especially framework-y ones, should use it instead of plain (i.e. non signature-preserving) decorators. I'd go as far as suggesting it should be part of the standard library. 
Quora has a much wider selection of content than SE. I wouldn't use it for anything programming related but there's a lot of really cool stuff there. You don't have to use Facebook. Quora supports Twitter, Google and email signups too. I can also use the mobile website just fine, in fact sometimes I have to because the android app is pretty bad. Yeah there was that time when they showed everyone what questions you viewed, but it's optional now. (though I agree that it was badly handled) Censorship is pretty minimal, much less than on any SE site. The site also has a problem with the disappropriate number of Indian users, and some quality issues. So while SO is better for programming related things, I find that there's a lot of quality content in Quora. 
to me "obj.variable" implies I can change that value. What happens when I write "mylist.length = 8". making it a function forces the idea that it cannot be changed, mylist.length()=8 doesn't make any sense. Length(mylist) would definitly solve it.
localhost:port or alternatively 127.0.0.1:port should work as well, saves you the trouble of figuring out your ip.
TIL: def foo(a,b=[]): b.append(a) print(b) foo(1) [1] foo(2) [1,2] foo(3) [1,2,3] 
&gt; So the class has to have it's own map implementation, which will be slower as it'll be implemented in Python. Yeah, now that I think about it, I'm pretty sure that's always true Beyond that, I'd switch back to Perl if half the recommendations were implemented. It'd be a much cleaner language.
That's just a weird Rubyesque version of @register_test def we_are_sane(): assert 2 + 2 = 4
absolutely right, i said "semi-reserved". there is nothing worse than python telling you "type is not callable" or similar. 
I don't quite understand what's going on there. b is local to foo() but its value persists across multiple calls? Is there a way to access b outside of foo?
This should be improved by [PEP 362](http://www.python.org/dev/peps/pep-0362/), which specifies a way of accessing function signatures that will work with wrapper functions.
The HP printers config tool for Linux uses PyQt. Also: gajim - Jabber client written in PyGTK deluge - bittorrent client written in Python/PyGTK 
Zapy looks good, but why SQL Server and not sqlite? You lost portability there.
Beautiful code however.. Written by hand with no .ui, rock on!! ;)
For reference, the "correct" way to implement this pattern is like so: def foo(a,b=None): if b is None: b = [] b.append(a) print(b) foo(1) [1] foo(2) [2] foo(3) [3] 
Decorators are evil and life's not fair.. A decent read, as i suspect a lot of people will be caught out by the same problem, but I found the title quite inflammatory.
&gt; I don't understand why 'str' 'type' 'any' 'map' and 'len' etc are semi-reserved words\*. Oh, that's an interesting question: partly for historical reasons, partly for performance reasons, partly for fundamental architecture reasons. Historical reasons are simple: [abstract base classes](http://docs.python.org/2/library/abc.html) were introduced only in 2.6. It would be a lot of work, required from library and application developers as well, to switch to some LINQ-style IEnumerable interface with map/filter methods. Performance reasons: attribute lookup as implemented by the `type.__getattribute__` (which is the default for most classes) consists of: 1) searching the entire class hierarchy for that attribute, meaning looking up in the dict of the class and each base class, 2) if not found or not a data descriptor then looking up in the instance dictionary (if exists) 3) if not found there but found at step one then returning that, else call `__getattr__`. The `__str__()` method lookup as implemented by the `str()` function consists of: 1) getting the function pointer from the `tp_str` field of the C type structure (by the way that's why such functions don't pick up instance methods if you implement them). Feel the difference. Somewhat fundamental architecture reasons: you must have a separate `type` function on the python level unless you want to explain to people how exactly `object.type()` works (so, you see, it gets the object type to look up the `type` attribute on it...). You want it to ignore instance attributes, that's a fundamental demand, for all such stuff you want to look in `instance.__class__.__dict__`, exactly one level up (on instance-class-metaclass-... hierarchy) from the object you have.