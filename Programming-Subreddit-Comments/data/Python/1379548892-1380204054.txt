&gt;* Maybe it's time for CPython to start thinking about performance. e.g. function inlining. Sit down and think about that for a second, and try and realize just how complex function inlining would be. First there's argument handling, not a big problem. Use an ordered edict and a couple of resolution functions. Second, there's variable hygienics - meaning that any variables in an inlined function must be named differently than variables into the function within which it is inclined. Don't forget that by doing that, you break locals(), and any other code that relies on it. Then there is function redefinition. What if the inlined function's name is redefined during runtime? You would probably have to hack byte code compiling and interpreter hooks to get this fixed, and who knows what kind of nightmare it would be to maintain compatibility. These are just some, not all, of the problems of trying to inline a function. I know, because I am currently attempting to write such an inlining macro for macropy. There are so many corner cases that exist, especially in a dynamic language like python, that the only reasonable way to implement them is either quite restrictively, allowing only functions that fit certain conditions to be inlined, or by using a JIT to dynamically inline (or re-inline) a function.
I probably meant the latter, as it's been a few weeks since I was working on my current project (due to school), also, does it matter that I'm using python 3?
No Tulip or Futures?
You don't need to import string, you can simply do str.join(' ', a_list)
My instructor. I'm self taught. ;)
Holy shit unicode is a nightmare in 2.x. Is it actually better in 3.x? How do other languages handle unicode?
Thanks, this actually works really well. You've accounted for a lot of different edge cases. I like this so much, I'm going to port it to Python 2.7 so I can use it in my projects. I might also add support for email parsing.
I dislike the ambiguity between copy and reference of variables and arrays. 
That weird error you're getting? Oh, try entabbing or detabbing. fixed. 
As a high school Digital Technology teacher, I definitely know that a lot of CS students (the schools I've worked at have had a symbiotic relationship with the university) have bugger all in the way of knowledge of computer programming. So far I've taught Python, but I've disliked it for not having the option of declaring explicit types where it may be useful. I yearn for something in Python which is similar to the thing in Objective-C where you can treat every object as id if you want, or NSSomethingOrOther if it's vitally important (which most of the time, it is).
More an issue with NumPy, but I *hate* that the arrays in it are row-major instead of column major by default. It's just not the way people think about matrices 99% of the time.
While I have tested this against thousands of IP addresses (IPv4 and IPv6) from around the world, there are bound to be issues with some. If you encounter any issues, please submit the issue to GitHub and include the IP address in question.
Wow, as someone who is new to python and has been trying to work with urllib2, I really appreciate this :D I didn't realize urllib2 is somewhat outdated... I'll have to get requests when I get home from work. Thanks medecau!
Fun fact : the US had a much faster and broader adoption of UTF-8 than non-english speaking countries ! 
vim deletes my four-space indents with a single keystroke, and I'm pretty sure it did it out of the box.
I thought it would be for when there's nothing in what's being iterated over: words = line.split() for word in words: print word else: print 'there were no words in the line' That makes more sense to me. It's saying "Loop over these words, but if you can't, do this." The way it is now, I'd want it to be something more like "then" - i.e. "Loop over these, then do this," and breaking out of the loop would skip the "then" part.
Not really? Are you saying that functions are just syntactic sugar for outer loops?
That's because it's named wrong. It would be far more clear if it were something like a `for`-`then` loop. It would be clear that the `then` is part of the `for`, and that it's going to be executed once the `for` is done. While not 100% intuitive, it would then be much more obvious at first explanation that breaking out of the `for` early would skip the `then` bit, because you'd be breaking out of the entire construct.
Just a question on this subject. This is the second time in as many days that I've heard recommendations for requests over urrlib2. Is the advantage in speed/features or is it just easier/simpler to code in?
Coming from javascript/actionscript some 7 years ago, I was really surprised that I couldn't do, e.g.: helloer = def (): return 'hello' You can do this in js/as: helloer = function () { return "hello"; } I think significant whitespace makes this hard to parse. There's been a 7-year parade since then of surprises over what I'm not allowed to do in Python.
I like there being a limit and I love having two files open side by side, but on my (not crazy big anymore) monitor that still gives me something like 220 characters in width (100/file with gutters)... I also know that studies have shown humans have a hard time tracking lines of text once the page gets too wide. Once I'm a `class` and two or three functions and `if` statements deep, I only have 60 to play with at which point descriptive variable names for the loss. I'm constantly frustrated by pep8 warning me that a line is 82 characters! Leaves me at [rage face point](http://www.trollwin.com/Problem/fu_face.jpg) Then I remember the first rule of pep8 and calm down again. 
[I've come up with a solution for this.](https://speakerdeck.com/trent/parallelizing-the-python-interpreter-an-alternate-approach-to-async) (Since presenting those slides to the Python developers, I ended up getting a job with [Continuum Analytics](http://continuum.io), thanks to an intro from Guido, and they're 100% behind the PyParallel work I'm doing, so expect more updates soon.) 
I appreciate the feedback. I was sure the first comment would be a bashing for not limiting the lines to 80 chars. Porting to 2.7 shouldn't be too difficult using ipaddr-py and dnspython. I have stayed clear of porting it so far, since ipaddr is no longer maintained (ever since it was adopted as the 3.3+ builtin ipaddress). I do plan on adding the abuse, tech, etc. contact information parsing in the near future. Getting that information parsed in to standard dictionary names is tricky, since every NIC is different. Some of the NICs are very inconsistent from IP to IP as well.
what if you did class Foo: def bar_function(): x = 5 y = [i*x for i in range(10)] return y Would that work? - id try it but im not on my python comp. this seems like a pretty big flaw, especially since i use list comps like that all the time. 
&gt;I was sure the first comment would be a bashing for not limiting the lines to 80 chars. The coding style in general isn't 100% to my taste, but code actually working well is far more important than style. And yeah, I've tried implementing basically a mini-form of this library in the past, and I ran into a lot of problems covering all the little variations. Here's my current hacky email "parsing" code, specialized for trying to grab abuse emails (which is what I'm most interested in): match = re.search(r"OrgAbuseEmail:\s*(.+)", whois) if match: result["abuse_contact"] = match.group(1) else: match = (re.search(r"([\w.-]*abuse[\w.-]*?@[\w.-]+)", whois, re.I) or re.search(r"([\w.-]+@[\w.-]+)", whois)) result["abuse_contact"] = match.group(1) if match else None And don't even get me started on parsing domain WHOIS records. I gave up on that long ago. There are a few web service APIs out there, like https://www.robowhois.com/ which is based on a Ruby WHOIS library, but even that is unable to parse a good portion of the domains I throw at it. And they have **a lot** of parsers: https://github.com/weppos/whois/tree/master/lib/whois/record/parser
Packaging, and packaging. Also packaging. 
Backwards-compatibility with what? As enum as a so-called type doesn't exist before now, there's nothing to break. There's absolutely no difference between enum and namedtuple except the former is shorter to type. Clearly some people cannot configure their editor to text-replace 'enum' with 'namedtuple'. As for functionality, an enum is an immutable mapping between a contextually-arbitrary item and a humanly-understandable tag, so code like: .setColour(0xfabd00) can be better expressed as .setColour(CHEESY_YELLOW) What's Python's existing immutable type? tuple. How do associate a name with a tuple? namedtuple. Game over. Enum exists solely for ex-pat C/C++ programmers too lazy to understand Python's existing stdlib functionality, and sets a dangerous precedent in breaking PEP20 to appease such people. If we're adding enum, we may as well add switch, struct, goto, turn on "from future import braces" by default, and dispose of the much-maligned default REPL for a compilation step that can ensure you got your types correct before execution. Somebody else already did most of the legwork for this over [here](http://clang.llvm.org).
&gt;I don't know what the interpreter is going to pick and choose for my data types when the types aren't declared beforehand. Do you work mostly with numbers? I never have this feeling. I expect that `foo = 'bar'` is going to pick string, `foo = 2` is going to be an int, and `foo = 2.1` is going to be a float, but I'd like to learn which situations are more ambiguous than these obvious ones. Is it more of, say, `'foo' + 2.0` could end up choosing to become 'foo2.0' or 2.0 (i.e. `foo` evals to 0)?
 gen = generator() for z in itertools.takewhile(lambda y: y = x, gen): do_stuff()
I don't think he wants to do it for every value of gen, only while gen is outputting the value of x. Itertools.takewhile would accomplish that, e.g. gen = generator() for z in intertools.takewhile(lambda y: y = x, gen): do_stuff()
Enum isn't duplicating namedtuple. Namedtuple is like an immutable record; enum is like... well... enumerations. Didn't everyone grow up programming in Pascal? :-)
I agree, I think universal unicode support was a bridge to far for the 2-3 transition. Combining this with the syntax changes put an undue burden on transitioning code.
 from datetime import datetime ugh
&gt; As a high school Digital Technology teacher, I definitely know that a lot of CS students (the schools I've worked at have had a symbiotic relationship with the university) have bugger all in the way of knowledge of computer programming. Errm, do you mean CS *students* or *incoming CS students*? I was specifically commenting on the latter. Although, unfortunately, I've met too many in the former group too. I attribute it to just not having enough practice yet. &gt; So far I've taught Python, but I've disliked it for not having the option of declaring explicit types where it may be useful. I yearn for something in Python which is similar to the thing in Objective-C where you can treat every object as id if you want, or NSSomethingOrOther if it's vitally important (which most of the time, it is). Opinions on how to teach an intro CS course are a dime-a-dozen, but I'll chime in and say Python isn't a terrible choice either way because it's so popular. Hell, I've released software in Python for almost no other reason than that I could attract beginning programmers to use it (or, in some cases, people with no programming experience at all). You could take a look at Go if you like, too. Lots of Python people (myself included) have found it to be quite nice. Or if you fancy the Scheme family of languages, you could go with Typed Racket which has had a lot of work done for the expressed purpose of teaching programming. And finally, if you're feeling really frisky, just throw Haskell at'em. :-)
having not met the author, I would probably use whatever has value, at this point it's 0mq, maybe in the future nanomsg. 
That people insist on using v2.7. v3.x has been out for over 4 years...
Disagree. If I'm reading code on a remote server then I'm using vim. If I'm using vim I'm in the terminal. If I'm in the terminal then it's 80 wide. PEP8 is about making it easy for others to read your code not making it easy for you to write it.
Because I could.
&gt;Backwards-compatibility with what? As enum as a so-called type doesn't exist &gt;before now, there's nothing to break. Backwards compatibility with the code that already exists in the standard library, in Twisted, etc. that used lots of integer-valued "constants" because there were no enums. The people who created enums have discussed this at length. The idea is to be able to go back through the standard library and replace the defined integers with enums. &gt;There's absolutely no difference between enum and namedtuple except the former &gt;is shorter to type. Somebody never programmed in Pascal. :-) A tuple is an immutable record, which is not the same as an enumeration, which is a set of named values. &gt;.setColour(0xfabd00) can be better expressed as .setColour(CHEESY_YELLOW) Not necessarily. There doesn't need to be a mapping. Channel your inner Niklaus Wirth and enter the world of Pascal: type CardSuit = (clubs, diamonds, hearts, spades); Var card : CardSuit; card will only be allowed to take one of four values, clibs; diamonds; hearts or spades. There is no mapping going on. This would be rejected by the compiler: card := 2; Python's new enum syntax works like this by default; there are also subclasses that works more like integer and string mappings (with the drawback of being able to mix with int/string values). &gt;If we're adding enum, we may as well add switch, struct, goto, struct = types.SimpleNamespace :-) To sum up, python can not be allowed to be considered inferior to Pascal in any respect, so we needed Enum and SimpleNamespace. ;-) 
&gt;I'm kind of baffled that people are still using this as a justification for &gt;adding/removing something from the language. &gt;This idea of "one obvious way to do things" was trampled, spat on and destroyed &gt;a long time ago. Bah. PHP has 16(!!!!!) functions that do sorting. Java has five different ways to open a file; Delphi has at least 6 or 7 (even more if you count classes like TStreamWriter and TStreamReader as two). Twenty-two years, and Python still has one way to open a file. Python has "in"; Delphi has "in", "containskey", "contains", and probably some more (but their "TeamB" promoters will argue to exhaustion that this doesn't make the language inconsistent). To pick on Delphi some more, 3 different Min and Max functions (two variables, array of integer, or array of real values as input even though Delphi has function overloading and this could be done with one function), Pos and PosEx to search from the start of a string or an arbitrary point (even though Delphi has optional parameters and this could be one function), etc. One obvious way in which to do it is B*E*A*U*T*I*F*U*L. PHP, Java and to some extent Delphi programmers weep with joy when they read that line of the Zen Of Python. ;-) Python has done an amazing job keeping things consistent and simple that way.
If he is, the = operator is wrong, it should be ==
I will take a deeper look at it tomorrow. If my memory serves correct, some of the non-ARIN NICs would have multiple email addresses listed with no differentiation of abuse vs other types. I may just have to create a generic email address key that holds a list of these emails.
This is a good overview of understanding race conditions in general, not just Python. A lot mentioned in the article apply to multithreaded applications in any language. 
It's not stupidity; it's genius. :-) For instance, instead of calling a next method to get the next item from an iterator, you need to use next(some_object) which calls the object's magic method. BUT... let's say you don't want it to raise an exception when there are no more items, but return a sentinel value. The next() function can take an optional parameter like this: next(some_object, 0) and now you get 0 instead of an exception! This only needed to be added to one function: if you directly called an object's method, every object in existence would have to have their own next method changed to implement it, which would be impossible. Also, the possibility exists that the standalone next function might not call the object's __next__ method but some other method (for some reason) in the future. In short, by using standalone functions for things like next and len they act rather like APIs into the objects; this allows for changes at one level to not break code at the ther level. 
I know; so far in learning Python I haven't had to touch the debugger at all yet. :-)
'C''s char can't hold most unicode codepoints.
To quote Raymond Hettinger on modifying an object while iterating over it: &gt;If you do this then... you're living in sin and deserve whatever happens to you! 
&gt; Bah. PHP has 16(!!!!!) functions that do sorting. Java has five different ways to open a file; Delphi has at least 6 or 7 (even more if you count classes like TStreamWriter and TStreamReader as two). Yeah, I get it. Python might be better. I don't contest that. I'm just talking about the cognitive dissonance *within* the community. To be fair, I've heard some people prefer to phrase it as, "There should only be one *correct* way to do something." Meaning that it's more a philosophy where we should all settle and agree on one idiom, rather than explicitly referring to the language itself. But I think that's bullshit. &gt; Twenty-two years, and Python still has one way to open a file. Oh dear. I hate to break it to you, but as I've learned recently myself, that's just not true any more. If you want to have any hope at releasing a Python module that is compatible with Python 2 **and** 3, then you'll probably need to use [codecs.open](http://docs.python.org/2.7/library/codecs.html#codecs.open) from the standard library if you want to avoid massive pain. &gt; Python has "in"; Delphi has "in", "containskey", "contains", and probably some more I'm still not sure why you're so keen on comparing Python with other languages. I mean, I know I didn't. My point has nothing to do with other languages. For what it's worth, you aren't entirely correct either. Common collections like `dict` and `list` have methods to do something similar like `has_key` and `index`, respectively. (Although, to be fair, `index` has a different contract since it raises an exception.) &gt; To pick on Delphi some more Even though I think this comparison between languages in response to what I said is **really strange**, I have to say that Delphi is an equally strange choice to use. I'd almost consider it an obscure language at this point. &gt; Python has done an amazing job keeping things consistent and simple that way. I personally think Python is in the middle of the road as far as simplicity goes. Languages like C or Go are at least an order of magnitude simpler.
Yes, I meant incoming CS students (I relied too much on implied context there; how Japanese of me). As you say, the rest often have little experience or practice so it can go either way. I'm looking at sticking with Python for a while. It's just C-like enough that universities which use C, C++, C#, or Java should have no trouble with the students they receive once my seniors move on that way. Plus, my kids use it with PyQt to make cross platform apps, and they enjoy that. Otherwise I'd go Java or C# for similar reasons plus somewhat decent IDEs in NetBeans/Visual Studio/Xamarin (which make teaching high schoolers much easier, remembering that not all students who take computer courses at high school are particularly technically literate). Boring choices, I know.
It's a lot more dangerous when a variable doesn't have the value you think it does. I live in fear of errors like: score = distance * 0.8 instead of score = distance * 0.858 rather than z = "spaghetti" sqrt(z) Because the first will be very hard to find while the second will make itself clear immediately.
That would indeed make more sense.
It makes sense if you're starting the beginning too. If I want 10 elements, I can say [:10] and it grabs 0..9. Doing [7:10] and getting 7..9 though... no, that doesn't make sense at all. There should be some intelligent subtracting going on, but there never will because "simple is better than complex" or something I'm sure. It's the same with range. Range(10) giving 0..9 makes sense, as you're still getting 10 values. But range(1,10) running from 1..9? No sense at all. We could replace range with a custom s_range function (s standing for "sane") but I don't know what we could do about slicing without subclassing strings and lists and tuples and such. Maybe I need to watch some Pycon videos and figure out if we could fix this with metaclass magic. :-) 
Yes to this. Completely replaced my STL unittests with this. Hell, I replaced nose with this. If there was a BDD plugin for py.test, I'd probably use it. Currently, though, I use "behave" for my BDD testing.
Sort of a tangent, but why are line numbers something that we'll wonder "what were we thinking?" about later?
&gt;your past experience with other languages doesn't count Why not? Why is the principle of least surprise not valid?
As long as x is defined at the function level, not the class level, it works fine in Python 3. &gt;&gt;&gt; Foo.bar_function() [0, 5, 10, 15, 20, 25, 30, 35, 40, 45] 
I shudder whenever I see projects with one folder labelled with the project name, and within that folder, a single 6000 line file.
While we're close now, with inline if, I'd still rather have: a ? b : c.
It gives more granular scope control. var x def foo(): x = 5 print(x) # 5
Not that it's any prettier, but it's more Pythonic (whatever that means) and better for performance and thread-safety to do: try: value = x[10] except IndexError: value = None Better to ask forgiveness here than permission. edit: I said `len` physically counted the elements. That's wrong. I wonder what I was thinking of instead…
I am very used to `list.join(sep)` coming from Java libs, but `sep.join(list)` does make more sense. The list is not doing the joining, it is merely providing the data that `type(sep)` operates on, in the case of `str` that operation is (roughly) "concat each item with `self`".
I don't think you understand what we're talking about. How about you read the fucking article? Here's the heading from the first item in the OP: &gt; 1. \_\_init\_\_.py is ***Only for Imports*** Just so we're clear, [here's an example](https://github.com/BurntSushi/nfldb/blob/master/nfldb/__init__.py).
Yeah, I see what you're saying. There's definitely a significant grey area. Especially wrapping block statements like if or for, like in your example, since the next line needs to be indented...
yeah, i even tried using `self` to reach out of the closure scope; didn't work &gt;&gt;&gt; class Foo: ... x = 5 ... y = [ i * self.x for i in range(10) ] ... Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "&lt;stdin&gt;", line 3, in Foo File "&lt;stdin&gt;", line 3, in &lt;listcomp&gt; NameError: global name 'self' is not defined For me, one of the things I really dislike about python is the explicit `self`. And the convention of calling it `self`.
&gt;I think significant whitespace makes this hard to parse. The primary reasons to prefer non-anonymous functions is debugging. If you use a lot of lambdas in Python you'll quickly find that the tracebacks go to the dump. 
You're forgetting about the GIL, which is why this conversation started... Python doesn't fully support multiple cores. Python doesn't support multiple cores at all, to the point that "multithreaded" programs in Python often run *slower* on multiple cores.
Huh... Reminds me a lot of the approach that a large chunk of the Linux kernel uses - have a fast common path that doesn't do much beyond a quick sanity check, with a fallback to a slow thorough path if needed.
agreed. but as is at least they didn't do Perl's non-standard bucket of all that is unholy with for/while loops.
version 3 is not backward compatible 
[fugees_and_funyuns posted](http://www.reddit.com/r/Python/comments/1mn12l/what_you_do_not_like_in_python/ccb1yx8) a link to [type-check](http://code.activestate.com/recipes/578528-type-checking-using-python-3x-annotations/) which gives you optional type checking. That needs to get rolled into the standard.
No it's quite the opposite, CPython is a decade or more behind the times in terms of modern multicore research. While I'm sure that some people can get by using multiprocessing it is a workaround, and a fairly bad one at that given how brittle it is and the overhead involved. If you look at languages with modern parallelism work (Oz, Haskell, JVM, ...) they all use threads or threaded runtimes. For example programming against Haskell's threading model lets you write a fairly naive threaded web services and scale up to an absurd number of req/s since you can actually saturate all the cores within the same process and still maintain the central event loop, something that's current impossible with CPython. Even with greenlets you're still locked to a single core or forced to do all communication over IPC. CPython could fix this but as past attempts have shown it would alter the language semantics or the performance of single-threaded programs. I suspect that CPython being the reference implementation will never fix the GIL problem. Still have yet to see whether PyPy STM work will pan out, but at least that is headed in the right direction.
There are a few things wrong with this. `join` takes an iterable not a str. Secondly, `len` is a function that takes an iterable. It would be silly to have to define this function on every class you want to treat as an iterable.
There are only two kinds of programming languages: those people always bitch about and those nobody uses. -- Bjarne Stroustrup
care to elaborate the difference between a statement and an expression in python? im a little fuzzy on the differences...
urllib has its place. If you simply wish to retrieve a file via URL you can use something that's built into every (common?) Python version. Oh, and it actually supports FTP. As much as I dislike FTP, I dislike having to do more work when I'm stuck with it. Disclaimer: I love requests. When I'm doing more complicated HTTP work it simplifies everything.
No i'd prefer `var x = foo` or 'let x = foo' or something like that.
I'm afraid I'm not certain what you're referring to?
There's something very important about urllib2, though. import urllib2 import bs4 soup = bs4.BeautifulSoup(urllib2.urlopen("ftp://example.com/foo.html").read()) 
Threads were created originally to allow for concurrency. Then they became the method for expressing parallelism when we had multiple-processors and then multicore processors.
Monty Python. The old docs were little more than Monty Python references strung together. 
That is the only advantage I see going for urllib/urllib2. urllib allows a direct download to filesystem and urllib2 give you a file object from which you can read() bytes. In requests you have to load everything into memory and that can be a problem if you have a large file to download.
which is fine for python, but not the 80 other file types I happen to open in the same text editor. I've been using tabs all my life, and I refuse to change for my own python scripts.
I don't believe len counts anything. List lengths are not computed on the fly. 
Yep. Just ran into this. You'd think if PHP can get it right then Python ought to have this figured out by now.
A bunch of libraries I use are either not compatible at all, or are very buggy on 3.x. Perhaps another year or two...
Two? What are you on -- SVGA? I can fit four without even adjusting the default font. But my editor already supports multiple tabs AND windows, in addition to side-by-side file editing in a single window. I typically code with 240 columns. It's time to do away with arbitrary line-length limits.
Agreed. It should either be inclusive, or [start:length]. The inconsistency is offensive.
[where's the docs on that](http://docs.python.org/3/using/cmdline.html#command-line)??
timezone support on the default date/time libraries... it's just awful.
The fast common path in my case is the execution of Python code in the parallel callbacks ;-) (No GC, no reference counting, a very simple (thus, fast) block/slab allocator, and some cheaky heap optimizations that significantly reduce costly TLB and cache misses.) So the general idea is that you structure your program so all your fast path code is suitable for PyParallel, then do all your slow shared state stuff in the main thread (which only runs when the parallel threads aren't running and vice versa (via explicit synchronisation points when necessary)).
Twisted
&gt; If your program needs multiple threads to function, it's likely it'll eventually need multiple machines, so you'll need to make it multi-process at that point anyway. It is nonsense. Often needing to scale horizontally isn't an excuse to preclude vertical scaling entirely from the language.
Threw you for a loop--hahahahah!
Did you know that len(var) is just means of calling that var's length method. You are free to use var.__len__() if you like.
you are correct, sir. reference: https://wiki.python.org/moin/TimeComplexity#list (see get length line)
I read the article. What made you think I was criticizing what he said? I was trying to *reaffirm* the point made about imports in the article.
Yeah, but it was a huge gotcha. I definitely was caught a couple times early on trying to do except x, y as e and being confused at why it wasn't catching y exceptions + e wasn't working. The new way is much easier to read. 
I have fallen in love with the works of Kenneth Reitz. [See this video to understand why.](https://www.youtube.com/watch?feature=player_detailpage&amp;v=ccqGOODoQTg#t=199)
I am baffled. The point being made in the OP is that `__init__.py` should be a place for imports and defining `__all__`. Namely, it should be used to craft your package's public interface. Using an `__init__.py` for imports only has nothing to do with single monolithic files. I guess I just don't understand how what you said relates to what's being said in the OP at all.
[sanetime](https://github.com/HubSpot/sanetime‎) is another option.
try this: &gt; "hey newline can you go ahead and glue join this list?" "\n".join(some_list) it makes more sense to me this way
`self` is used by convention to refer to the instance, by itself it has no meaning (unlike `this` in other languages). That why in instance methods you need to pass in `self` (or any legal variable name that you prefer) as a parameter instead of getting it for free.
Not quite equivalent. The parent's variables are _class_ variables, which are shared between instances. Especially in the list's case. New instances in yours will get their own list while the other will share one list between all instances. 
Oh, now changing a variable's type in the course of a program *does* seem more likely if you don't have to restrict it. That's just way farther along than the problem I thought you were describing. Frankly, I wonder what Python would look like if you couldn't rebind names, at least without jumping through hoops.
6 https://pypi.python.org/pypi/enum34/
Woah, this guy is a general badass :P Thanks for the video.
Isn't Tulip is non-threaded? I'd heard it's for concurrency "in the non-threaded world". But, yes, the faster people learn about `concurrent.futures`, the happier we'll all be.
with comprehension, I can do: [i for i in xrange(50) if i % 5 == 0] But I cannot do this: for i in xrange(50) if i % 5 == 0: print i Instead I have to do this: for i in xrange(50): if i % 5 == 0: print i Or do this weird thing: for i in (j for j in xrange(50) if j % 5 == 0): print i 
You'd want to pass in self to `bar_function`, or else make it `@staticmethod`. Then x = 5 could be moved back to class scope and you'd write self.x inside the function.
What would you like to see instead? I can't quite picture it.
Syntactically, comprehension is a lot more liberating. I can do this: [(x, y) for x in range(1, 5) for y in range(0, x)] Why can't I do this: result = [] for x in range(1, 5) for y in range(0, x): result.append((x, y)) &gt; The effort of implementing (and maintaining) this optimization in such a dynamic language is not worth its limited use. Everyone in Python land keep repeating this rhetoric, but why V8 guys can do it? Not to mention JS is more ridiculous than Python.
Why should it be that way? Go httpserver is production ready. The same goes with node.js httpserver.
It flips the perceived "order of execution". You have to define the method that will be called later *before* the method that calls it (and assign a temporary variable in the process). It's not as elegant as the "functional" equivalent like in C#: new[]{1, 2, 3, 4}.Where(e =&gt; e &gt; 2).OrderBy(e =&gt; -e).Select(e =&gt; e + 2) It's not that big of a deal, but it kind of breaks the flow (in the example above, I'd need to define the "reverse order" method a few lines before even creating the array.
new Amazon Web Services accounts get a free micro instance. not as easy to launch as Heroku, but free. 
why couldn't it just be a wrapper for the other implementation?
essentially perform the same as the range function with only one arg- for i in 5: should be the same as: for i in range(5): or at the least, for i in range(1,6): As I can see a strong argument for, if we're treating integers as a list much like how we treat strings as a list, all integers counting up to and including that number should be iterated over.
Replied [here](http://www.reddit.com/r/Python/comments/1mn12l/what_you_do_not_like_in_python/ccb9iu9)
&gt; I think significant whitespace makes this hard to parse. That's exactly it. http://www.artima.com/weblogs/viewpost.jsp?thread=147358
I disagree; if I define a method inside a class it should be bound to an instance of the class. Unless explicitly marked; and that's arguable - if it is not intended to be bound to an instance, then why is it defined in a class? I understand the technical and historic limitations that require it in todays code (http://python-history.blogspot.com/2010/06/inside-story-on-new-style-classes.html), which just goes to show how far reaching the ramifications are when you make bad design decisions early on. Maybe one of these days I'll create an `@ImplicitSelf` class decorator. *(I wonder if that would even be possible....)* *edit*: further reading led me to http://neopythonic.blogspot.com/2008/10/why-explicit-self-has-to-stay.html (which I have read before, I just forgot about it) and explains it a little better. And from the comments it looks like someone else already thought about it; http://www.voidspace.org.uk/python/articles/metaclasses.shtml. I wonder how well that has aged?
And thank God for that. You don't need to be a child prodigy to fall in love with programming.
Pretty sure PyPy offers very secure sandbox functionality (so they claim).
I find TkInter powerful enough (and it's included in all standard python distributions). So nice having it just work without having to learn and mess with the Qt way of handling things.
We like out unicode icons...
Personally, I detest the ternary syntax. Or for a bigger issue, the lack of multiline lambdas.
I probably wouldn't jump to everything-lazy and &lt;scary_voice&gt;MONADS!&lt;/scary_voice&gt;. It might be fun to gank the fancy-pants datastructures from Clojure, though, while I'm stealing random language features.
If you change the return of `register` from `function` to `self` you can do away with the unique naming scheme of the methods and call them all `add`.
Wow, that's a good peek into the mind of the BDFL. Thanks.
Ah, so define the iterator protocol within an integer.
i dont understand, im basically saying add a method like def join(self, sep): return sep.join(self) 
Minor nitpick, special fx happen on set, visual fx happen in post. Houdini, Nuke, Blender are all great examples of python scripting in VFX.
The difference between *is* and *==* is important though. The first implies the second but not the other way round.
Do pip and virtualenv not deal with all of this? 
&gt; if it is not intended to be bound to an instance, then why is it defined in a class Ever heard of static methods? Although there's also the difference between static and class methods to consider. &gt; create an @ImplicitSelf class decorator Not possible to implicitly assign `self` to the current instance. Bound methods will *always* provide the instance as the first parameter to the method, so you'll always at least need a dummy var as the first parameter (and if you go that far, just use self). I don't think it's possible to create that decorator. &gt; TypeError: unbound method ***() must be called with * instance as first argument (got ** instance instead)
What if you forget? Suddenly, you can't join on your custom iterable class. What if it's not your class, but a library? The iterator protocol is designed specifically so that things like this are *automatic* so that you don't need to repeat yourself. As it stands, nothing is preventing you from doing it your way right now.
http://docs.python.org/2/using/cmdline.html#miscellaneous-options The option has been removed from python 3 and been made the normal behavior: &gt; python2.7 test.py &gt; python2.7 -t test.py test.py: inconsistent use of tabs and spaces in indentation &gt; python2.7 -tt test.py File "test.py", line 3 print ('A.__eq__') ^ TabError: inconsistent use of tabs and spaces in indentation &gt; python3.3 test.py File "test.py", line 3 print ('A.__eq__') ^ TabError: inconsistent use of tabs and spaces in indentation thus if you have the issue of mixed tabs and spaces, you can't be using python 3.
The entire *point* of Python 3 was to break backwards compatibility for syntactic-sugaresque changes to rectify various oversights in the 1.x/2.x families. And most of those changes are available in 2.6+, so you can write code that's mostly compatible with both versions (+- a few imports)
The reason for this is that it allows easier subclass-driven implementation since the return value will always be an instance of self.\_\_class\_\_. 
Not really. In every other language with exceptions normal flow returns after the exception block which, if you return/throw/exit within the except block (which is often true), *is* the unexceptional case.
`from __future__ import unicode_literals` not working for you?
Neither implies the other. It'd be much better to not have either, and instead have a single operator that does the good parts of both. See Henry Baker's classic article [Equal Rights for Functional Objects](http://home.pipeline.com/~hbaker1/ObjectIdentity.html).
An expression is a language construct that can be used anywhere where a value is expected, and can nest other expressions. Examples of simple expressions are: - 7 - a Examples of compound expressions are: - 7 + a - [7, a] - abs(7 + a) - str(abs(7 + a)) - 1 if abs(7 + a) &lt; 3 else 2 - lambda x: x Statements are another kind of language construct (which complicates language) that can be used and sometimes nested in arbitrary points but not anywhere else, for the fuck of it and no benefit at all. def, while, raise, assignment, assert and company are statements. This pointless concept of statements limits the expressivity and flexibility of a language. Like any design mistake, it calls for further design warts and complexity as workarounds. For example: - Since we can't use if expr: x; else: y; anywhere, but we do want to use conditions anywhere, we use the and..or hack or introduce that awkward if..else expression and end up with two ifs and more complexity. - Since we can't use def anywhere but we want to have one-time functions, we introduce lambda, creating more confusion. lambda sucks because since it cannot contain statements though, so sometimes we still need to use def and make up names for one-time values. - Since class isn't an expression, we have or make functions that return new classes. - Since assignment isn't an expression (BTW, it is in C-like languages) and it's useful to set several variables to the same value, Python introduced extra syntax and special support for multiple assignment as a statement, e.g. a = b = c. But a = b += 2 won't work. It's just all warty. There's no advantage to having statements; they're a dinosaur from 1950s languages such as FORTRAN which were obsessed with the "do this; do that" all-imperative, close-to-the-bare-metal design. State-of-the-art languages never had statements and never needed them.
iirc you can subclass list... class SpecialList(list): def index(self, item, default): return super(SpecialList, self).index(item) if item in self else default
This PEP has now been accepted. 
Pretty much this. It's annoying to make closures and significant whitespace makes lot of things painful. I would also add limited usefulness of the REPL, because it's literally impossible to redefine the code you already loaded.
I'm not a PHP user so I can't really say one way or the other but I've heard a lot of hate for PHP's backwards compatibility.
I'm literally checking every week if pypy3 stable is out yet.
I don't know how this has not been mentioned yet, but Documentation! I feel like if the documentation was better, most of these problems would be less painful. It is much faster to google a specific problem and click the first stackoverflow link that you see than looking at the documentation, and that I think should not be the case. I would like to see one one function per page style docs with exhaustive description of all the parameters, example, "see also" type cross references and an open discussion. PHP is a horrible language, but it is completely usable just thanks to its documentation. In fact I'm so pissed with the current documentation that I'm thinking of starting a new doc project, let me know if you feel the same!
It absolutely isn't. It pretty much duplicates the existing feature of Python syntax, namely the colon (:) after statements that require indentation, which is exactly like the opening curly brace. The only thing python lacks to remove whitespace significance is the closing curly brace. Just one additional character and the language becomes much easier to use: now the code can be autoindented, you can copypaste from anywhere to anywhere and so on.
&gt; How do other languages handle unicode? Badly. Except for objective-c.
meh. post_reply = urlopen('http://example.com', urlencode({'msg': "Python rocks"})).read() json_reply = json.load(urlopen('http://example.com')) requests can be nice for advanced feature, but for this trivial stuff it's a completely unnecessary dependency.
Probably they use shittily designed database schema. Like at my current job, I'm constantly forced to write bare SQL because the db was designed idiotically.
If slicing was inclusive *and* indexing started at 1: * lst[:10] would return 10 elements * lst[7:10] would return 7..10 (4 elements total) * range(10) would return 1..10 (but you could do range(0, 10)) 
[urllib3](http://urllib3.readthedocs.org/en/latest/)
&gt; In requests you have to load everything into memory and that can be a problem if you have a large file to download. That's the default but you don't have to, pass `stream=True` and you get a file-like object as `resp.raw`: http://docs.python-requests.org/en/latest/user/quickstart/#raw-response-content
&gt; Non-400 status responses throw exceptions. The odd 1xy, 300 and 304 (probably the most problematic one) are debatable (other 3xy are handled as redirections), but why would 5xy *not* throw? Also that's only the default behavior, you can alter it however you want by customising the set of openers (FWIW if you want to use 304 which is the problem I'd usually expect you should have a conditional requests opener)
The specifics are that Python's scoping is... interesting.
No, my IDE does not draw vertical lines. I am using vim when coding in python. I think this is the actual problem.
&gt; they're inherited from the fact that Python's whitespace-sensitive. Indentation-sensitive. Which is also the case of Haskell. Haskell doesn't need statements.
I think instead of just pointing out what you don't like, maybe you should actually try to make it better. It would benefit both the original creator and the users. I am actually planning on using this script. He didn't submit it here so that you can just criticize him without any help whatsoever. TL;DR: Stop being a smart ass and actually help the guy make his code better.
While this is helpful, it would be great if it wasn't necessary to search the list twice; or handle `ValueError`.
Definitely got me when I was first learning python. 
&gt; Guido &gt; linear algebrists. By what possible metric? Your own sycophancy? The point is, there are people _all over the goddamned place_ using threads for performance reasons. And static typing does have its place -- it would be _really_ nice to have optional static typing a la Cython in the core language for the sake of speed, though it will never happen. &gt; Intel's selling multi-core processors. Of course they disagree. :-) And guess what? Virtually every device on which you're likely to run Python these days (except some esoteric smartphones or maybe the Raspberry Pi) contains one of those very same multi-core processors, chronically underutilized by performance-driven Python applications.
No rfind() for lists.
&gt; You need to contextualize -- he thinks it's not a big deal, because he comes from a web-development background where things scale horizontally basically infinitely. Of course, I know this. I'm just sick and tired of being told by know-it-all web programmers how the GIL is not really a problem and "that's not what threads are for". The entirety of computing does not revolve around web applications. &gt; There are also cases in desktop and mobile applications where processes are infeasible, because they can't e.g. share an opengl context (to do multithreaded streaming of textures to the GPU) or because they are intended to be used to remove some bottleneck (streaming compressed assets from nonvolatile storage) where the need to serialize through a pipe would just completely negate any benefit. Funny thing: if you fork but don't exec (at least, I _think_ fork+exec works), shit hits the fan if a CUDA context has already been initialized. And this pretty much describes the last time I threw up my hands in anger at Python's shitty thread support.
How about Java? That's something I would think handles it pretty well. 
On the positive side, the separation between bytes and (unicode) strings has always been clearer than in Python (2). On the negative side, the string type is garbage, IIRC there are no APIs available to massage strings at the grapheme cluster level, most of the methods have worked at the UCS2 code unit level (those to work on codepoints were added in 1.5 and they're kinda crap) and some of `unicodedata`'s features were not available (or incompletely so) before 1.7. tl;dr: it does not, it only did slightly better in that it always forced a strict separation between bytes (`byte[]`) and (unicodeish) strings (`String`)
You clearly have no idea what you're talking about, and if he actually said that, in this instance neither does Guido. Processes are not nearly as lightweight or agile and ill-suited in many, many situations. It doesn't matter what they were invented for. The Internet was invented for Department of Defense researchers and various universities to communicate, and people now use it to watch porn, buy socks and share their cats with the world. Needs change and available tools adapt, and threads are the _de facto_ way of leveraging multicore within a single process, primarily because they're cheap, lightweight, and make sharing memory extremely easy. If you want safety, make it an error to mutate anything outside the threaded scope that isn't explicitly thread-safe. The actual reason the GIL exists is that the interpreter's implementation would make writing C extensions really hard if the GIL didn't exist. While I'm a big fan of easy extension with C and use it frequently, I'd much rather have a more performant, higher-level language that isn't crippled in this fashion.
I love namedtuple, if the implementation is weird then that can be fixed, but having just a 'named container' is awesome rather then passing around arbitrary lists or making a class that is just container variables
I can only assume this is because UTF-8 is compatible with ASCII, but not with all the other encodings people had been using in other languages.
Which is why it's flexible. If you are in a situation where the number of processors changes at runtime (I think that's what you are saying?) then just write a manager that will alter the size of the processpool when the processor count changes.
Thanks for this.
No no no! The length of something should not be tied to any specific thing, its a general term: "give me the length of this thing". You can get the length of any object that supports it without the mess of having differently named methods (size? length? count?) for different objects.
I would put the server/client code into separate files and try to keep a single 'common' file with functionality relevant to both that could be included.
Apples and oranges. The V8 crew have written an awesomely fast JIT for JavaScript, which is something that will never be added to CPython as it is the reference implementation. Smaller optimizations for Python could be added without a JIT but they would be tiny improvements and might even break backwards compatibility. If you want more speed then use PyPy, it really is fast.
I'm not sure I see the problem here. Are you suggesting that `all([])` should be `False`? That would break with the concept of [vacuous truth](http://en.wikipedia.org/wiki/Vacuous_truth), and the following identity would also no longer hold: all([a] + rest) == a and all(rest)
Quite often I can't do "pip install &lt;whatever&gt;" - I wish I had a way to locally install modules in my home directory.
I can do that with 110 characters and a super-wide font.
2) Can you elaborate more? I tested it on a few objects and they appear to be equal.
&gt; if (width == 0 and height == 0 and color == 'red' and emphasis == 'strong' or highlight &gt; 100): I always *want* to do this, but I shy away from it because it gets hard to tell where the if-statement stops and the indented block begins. if (conditions and conditions and conditions and conditions and conditions and conditions and conditions and conditions and conditions and conditions and maybe some other conditions): did the code start yet? who can tell… Somehow adding a newline doesn't make up for it to me.
 if var in ("a","b"): do_something() break/return/do someting else elif var == "c": do_something() and_execute_me_if_c() You are right though, the default statement in a switch is useful.
What I'd like to emphasize is: * When you say 'secure' you need to answer the question 'secure from what?' * You need plenty of docs explaining what the usage model is. * What are you securing? * What from? * What are some well-known protocols that can be reused in your application? * Which ones are you implementing and why? * Which ones are you rejecting and why? * What is 'a decentralized model of server-client relations'? What is the idea behind it? Basicaly, provide a lot of documentation, write down everything, create diagrams, all that in as many natural languages as you can so as to attract as many people willing to evaluate what you attempt to achieve. As for the Python side - it seems this is a sort of a project to get you familiar with the language and it's cool but at the same time it's doubly important you first make it known what the overall goal is.
I think there was a justification in breaking backwards compatability, but I think the way it was done made it a bigger barrier than it should have been. The recommended upgrade path was via 2to3, but this was something of a pain, adding a barrier to development if you wanted both codestreams to work. I think far better would have been to allow for a more polyglot approach, where a subset of python (even if only python of the next version) was "Python 3 clean" and would work in either. This approach was frowned on however, though a bit more support has been added recently (eg. unicode prefixes in python 3 etc). I think it would have made for a much easier transition, however if the changes had been designed with this approach in mind.
&gt;x for example as "except E,e" I think that was a pretty nasty wart that could definitely bite people unfamiliar with it, and was well worth changing. It's not at *all* obvious that `except E, e:` would be different from `except (E,e):`, and this was very much at odds with how tuples are handled elsewhere. There are places where brackets are needed for tuples, but they result in syntax errors rather than silently changing the behaviour of the code. &gt;str became bytes I don't think this is really accurate - bytes had *significant* changes in behaviour from str. It'd be more correct to say "The str type became a unicode string, and a bytes type was *added*"
&gt; Guido &gt; linear algebrists. Since you seem to put Guido on a pedestal, some advice: he's just another guy. He has wrong opinions and biases just like anyone else. In fact I would say quite a bit of the community believes that the approach he is taking to fix concurrency is the wrong one. Making claims that "guido said this" or "guido says that" is irrelevant to the discussion, do your research, think for yourself and come to your own conclusions.
I'd consider returning the last evaluated valued first, as AFAIK it's a well established convention. It's useful for some algorithms, and useless for others where you just throw away whatever return value because you're running while for its side effects. I wouldn't use special syntax for return since you can always throw away the value and evaluate whatever you wanted right after it, e.g. (while cond: do stuff...); x 
No sane person would defend current threading implementation in CPython, that's true. The point is that in the true multicore future (1024 and so) GIL may be simply no issue anymore as everyone will try to unshare memory in some way due to growing scalability issues (and functional style and non-mutable variables are already means of unsharing memory). I bet some implementations will essentially reinvent os-level processes. People who are excited how threaded models run on current 8-cores machines simply have no idea. I once got 96-core machine (still small compared to predicted 1024) with a task of crunching about 100G of data. I picked C as a natural choice and started with threads (seemed natural too). It was total disaster that opened my eyes to viability of shared memory model in massive multicore computing. Just freeing memory so the next batch could be processed took 2-3 minutes (I was using Google's allocator which was the best performer with threads) and it was only one of the problems - but all of them were related to memory. Then I simply refactored the code with fork() and multiprocessing and it was like miracle - without any other essential changes. I guess that Linux kernel took advantage of non-shared memory to keep proper CPU-affinity and improve cache locality in effect. I think that in the future terms like CPU/NUMA affinity and memory/cache locality will be more hot topics than wait-free algorithms or shared memory threading. We're going to hear how awesome Haskell typing system helps runtime keep good affinity, how Go/Erlang CSP model and Haskell functional programming style helps reduce memory sharing and cache trashing, how per-thread group garbage collectors are great so we don't have global mark-sweep scans, etc. At that time people will bitch that Python doesn't have nice IPC, pattern matching, immutability guarantees, but nobody will care much about GIL anymore.
But then you can't test each of the functions in isolation. See the rationale for PEP 443 at http://www.python.org/dev/peps/pep-0443/ : &gt; The register() attribute returns the undecorated function. This enables decorator stacking, pickling, as well as creating unit tests for each variant independently: 
You are right, *is* does not imply *==*, as *==* can be overridden to simply return False all the time, for example. But for three objects a, b, c it can be said that if *a is b*, then *a == c* is the same as *b == c*. Edit: while generally I agree that there should be a single operator, I am not sure if it is sufficient in a language with mutable state like Python. Equality testing can be much more expensive than identity testing in such languages.
"absolutely disgusting"? Interesting. Why? Or to clarify my question, I know that some people things that it's absolutely disgusting to have more than one return statement in a function. Is your disgust of that personal variant, which I feel free to ignore, or is it more generally applicable and one I should bear in mind for the future? There's a general dislike of modifying a container while iterating over it, but by definition an iterator has to be modified in order to use it. How would you recommend that I rewrite that above code? As: it = iter(input_file) while 1: try: line = next(it) except StopIteration: break if line == "NAME\n": name = iter(it) .... This modifies the iterator in two locations. Is that disgusting? I see the first 5 lines of the while as being identical to a 'for' loop over an iterator. Why repeat the code when that's what a for loop would do? Or, I could use readline() directly, as while 1: line = input_file.readline() if not line: break if line == "NAME\n": line = input_file.readline() if not line: raise AssertionError("Missing name after NAME") name = line.rstrip("\n") ... Here I have to add explicit error checking for readline() failures. Both seem more complicated than my original code, and with no obvious benefits. 
Another thing that's wrong with having to use `def` here is that it introduces a temporary variable. It creates an entity in the source that has no semantic meaning other than "the function I am about to pass to this other function". It's the opposite of point-free style.
Yeah. Probably the only reason why people are still using Lua.
Yeah. A recommended solution is to use a dictionary instead, something like: def caseFoo(): print("foo!") def caseBar(): print("bar!") switch = { "foo": caseFoo, "bar": caseBar, ... } switch[i]() The problem with this is that it doesn't support a default branch. EAFTP suggests we do something like this instead: try: switch[i]() except KeyError: caseDefault() The problem is, if any of our cases raises a KeyError itself, we'll also hit the default case. That's obviously no good. So: if i in switch: switch[i]() else: caseDefault() Still, I'd prefer: switch i: case "foo": print("foo") case "bar": print("bar") else: print("Something else has happened") If only because it's 2 lines shorter and free of redundancies.
Could you give a concrete example of a situation in which the documentation wasn't sufficient for you? Personally I've never been in a situation where I felt like the Python documentation was not sufficient to help me resolve some issue and where I thought the PHP documentation in a similar scenario would have. I personally feel that the Python docs are extremely well done. I'd like to know more about your view, since it seems to be so firmly against the Python documentation.
EventSource?
Just FYI, you have removed some private keys from the repo, but they are still visible in the git history. I hope you are treating those keys as compromised!
SockJS library (https://github.com/sockjs/sockjs-client) or pure Websockets. In case of SockJS - if browser does not support Websockets - one of xhr-streaming, iframe-eventsource, iframe-htmlfile, xhr-polling, jsonp-polling transports will be used.
You must be using hard tabs with tab stop set to 4. Don't do either of those things.
Thanks a lot
I agree completely. I think it's completely anti-pythonic that my single objective (timestamp) requires multiple separate modules though, which increases the learning curve because you are switching back and forth between the docs. You're right though - they're a complete solution, and in some ways, even, robust. They're just more trouble than they're worth.
I absolutely agree. This pattern is everywhere and very useful. See/u/Formeo's comment and the response to it...
what? variable declaration statements don't prevent typos. nothing besides paying more attention can prevent typos. 
Try this (I used python 2.7.3): &gt;&gt;&gt; import cPickle &gt;&gt;&gt; d1 = dict(props='', attr1=1) &gt;&gt;&gt; s1 = cPickle.dumps(d1) &gt;&gt;&gt; d2 = cPickle.loads(s1) &gt;&gt;&gt; s2 = cPickle.dumps(d2) &gt;&gt;&gt; print s1==s2 False 
Exactly! I should've said portable 'c', but CHAR_BITS would have to increase for 'c' as a whole to support it.
Yeah, argparse is currently my goto for parsing arguments, but I don't really like its verbose syntax and I've been meaning to migrate something better.
the freaking syntax and wrestling with SciTe or Notepad++
It would be preferable to use a [state machine](http://en.wikipedia.org/wiki/State_machine). Your current code is incompatible with input like this: NAME John Smith (note the empty line). A state machine would be capable of handling this easily. Something like this: NAME = 1 AGE = 2 ADDRESS = 3 state = 0 for line in open_file: line = line.strip() if state == 0: if line == "NAME": state = NAME elif line == "AGE": state = AGE # etc. elif state == NAME: if line: name = line state = 0 # etc.
I think you want to use integers, not floats. Integers have no limit in python and these are all integer operations.
In your counter-example you changed the spec for the format. Of course my code will break - it's for a different format. FWIW, the change in my code to support your variant is: if line == "NAME\n": for line in it: name = it.strip() if name: break else: raise AssertionError("End of file reached looking for NAME") State machines can handle anything, it's true, so by that definition it's easier. There are two major downsides. First, it's easier to make a mistake and forget a state transition, compared to those examples that can be expressed as code layout rather than states. Similarly, it's harder to include all of the error reports. This is especially true if you want to maintain information across some of the states - a static analysis tool can't easily figure out the state ordering to know that things will be initialized in the correct order. Second, in Python you have a lot more dispatches because you have to constantly redetermine which state you're in. (If you used C or another program with gotos then you can simply go to the correct state.) 
Yeah. See for me the thing is that even though I would *like* a switch statement, I'm still OK with the `elif` stuff. With function overloading, there's just no way to do it except with a big ugly if.
Now you're iterating over an iterator while iterating over it. You don't see the *slightest* problem with that?
Oh! you're quite right. I assume that means `x` changes at some point *during* the `for` loop? If so, then you're misunderstanding Python's `for loops. `for` loops are roughly equivalent to another language's `foreach` loops -- iterating over a sequence of values that's *independent from the loop body*. Since your iteration condition varies as the loop gets executed, you're looking for a `while` loop. i = 0 while i &gt; x: do_stuff() i += 1 That said, that kind of integer manipulation is usually used to implement various algorithms in a more optimal way. Python usually has higher-level ways of getting around that.
It's the exact same thing but with some syntactical sugar. The other features of Haskell's ranges are either implemented some other way or not possible (e.g. infinite sequences)
More specifically, Python integers are represented as native integers if possible (64-bit signed int on 64-bit platforms) and transparently switch to bignums upon overflow. The only limit is the available memory.
 for i in range(0, 10, 5): j = 0 for i in range(10): j -= 1 &gt; multiple variables in your for loop The *only* reason to declare the variables "in" your loop is to introduce some scope control over them. Python has function-level scope, so there's no point to declaring them "in" vs. "out" 
Not to mention that even within limit, one should *never* use floats for integer or decimal operations.
dict accessor methods as well.. dict.get('not_here') returns None, but dict.pop('not_here') raises an exception. 
Because that's a huge project and really outside the scope of the stdlib. There are other packages that are used for that.
It's fair enough that Python does it the same way as every other language that I know; but I still think it would be nice to be able to say: try: pass # something that might cause an error then: pass # something that required what happened in try: except Exception: pass # handle the exceptional case. No matter how # long this gets, or how many except: blocks there # are, it's still easy to read what this code should # usually do, since it's all at the top I think the current format improperly prioritizes exceptional cases (the contents of `except:`) over the normal case (the contents of `else:`). try: pass # something that might cause an error except Exception: pass # handle the exceptional case # but exception handling can be difficult; and, # especially if you want your exception handling # to continue to pass execution past the try...except # block, you might have a lot of code here to make # up for what you tried to do in the try: block, # as well as whatever you were going to have done # in the else: block. This pushes the else: block, # which should read as the "next normal thing" as # a human reads the code, way down, away from # its try: block. except OtherException: pass # of course, you can have different exception # handling cases, and all of them have to be put # next to the try, making them seem more "normal" # (less exceptional) than what should be the *normal* # case, in the else: block. else: pass # and here we have what should *normally* # happen after the try: block, assuming no exceptional # (less normal) conditions arise; but it's separated # from its most proximate prior code by possibly large # and multiple except: blocks.
I was merely providing another way to do it. The original user already posted that code sample.
Sure doesn't on Windows. I'm currently playing with implementing an import hook that saves the locations of modules so Python doesn't have to do so much searching for them - slow system calls pertaining to the filesystem is what makes python startup slow on windows. For example, `import IPython` is about 0.8 seconds. A few modules that big and things take a while to start.
That's specious reasoning. Both convention and tacit understanding are incredibly powerful forces in human factors and usability. Your argument is like saying "Our new programming language has a primitive types with keyword 'non_fractional_number'. (non_fractional_number n = 5;) What do you mean you want it to be 'int'? non_fractional_number is completely accurate and clear, your past experience with a keyword 'int' is meaningless."
Absolutely. It's intuitive because it's familiar to those with basic programming experience. 
Not sure how having a 2.8 would help. Using 2.8 would be entirely voluntary, just like using `from __future__ import` is entirely voluntary. If you would want to use a Python 2.8, you can just use 2.7 with futures imported, it is exactly the same thing.
What's the difference between sockJS and socket.io?
Because I'm trying to consume a RESTful web service and 50x is a perfectly valid response. What's not valid is a network timeout, a dropped connection, or some other kind of error state. Because HTTP still returns a body with non-400 responses, and I want to display that to the end user. So now I've got to have one method for retrieving the body if the response is 400 and another method for retrieving the body when the response is 403, 404, or 503, since in those cases I have to get it through the exception instead of the urllib2 object. 
Also, the pow() function takes a third argument that does the modulo reduction, more efficiently than doing it separately. m = pow(c, d, n)
&gt; Because HTTP still returns a body with non-400 responses HTTP also allows a body for 4xy responses (in fact, it allows an entity body with all but 204 and 304 IIRC), why are you fine with 4 throwing then? &gt; since in those cases I **have** to get it through the exception instead of the urllib2 object. You don't **have** to, just configure your opener correctly. Again, this is a *default* behavior. And it's a good one, in most cases a non-200 response is not "correct", and if it's not correct it makes sense to throw. 
Or use a JIT like Javascript does by running your python scripts on PyPy.
You can do it in vim. There's a few styles, some color different by depth, are skiny/thick/dashed/solid. I like the subtler ones, with auto-highlight the current ones. ( similar to 'match bracket' )
Here is a list of video links collected from comments that redditors have made in response to this submission: |Source Comment|Score|Video Link| |:-------|:-------|:-------| |[rahmu](http://reddit.com/comments/1mn12l/_/ccaty52)|7|[Ask your BDFL](http://youtu.be/YdxXqc2Npls)| |[medecau](http://reddit.com/comments/1mn12l/_/ccb8rq6)|2|[#APIdays "API Driven Development, How I Develop Things and Why?", by Kenneth Reitz](http://youtu.be/ccqGOODoQTg)| |[MonkeyNin](http://reddit.com/comments/1mn12l/_/ccbhxse)|1|[Turbo Track ターボ トラック ロングコース](http://youtu.be/D7XBIinH5Mg)| |[andrewff](http://reddit.com/comments/1mn12l/_/ccb148y)|1|[Chito on his cat-hamster-wheel](http://youtu.be/cbl0t1RrCdg)| |[InvidFlower](http://reddit.com/comments/1mn12l/_/ccaupso)|0|[Vyacheslav Egorov: one day of life in V8](http://youtu.be/Z_q6iw3h48s)| * [VideoLinkBot FAQ](http://www.reddit.com/r/VideoLinkBot/wiki/faq) * [Feedback](http://www.reddit.com/r/VideoLinkBot/submit) * [Playlist of videos in this comment](http://radd.it/comments/1mn12l/_/ccbhz2y?only=videos&amp;start=1)
Try subprocess.Popen('C:/plink.exe','username@remotehost','-P','228','-pw','password','ps aux | grep ssh'])
It's not that big of a deal to me, but then again, I keep my command prompt open on Windows, so the first time I run it, yea it's slow, but after that it's fast.
 lin=subreddit[count].url haven't checked it, but that seems to be what it's doing.
[SQLAlchemy](http://www.sqlalchemy.org) -- hands down.
SockJS client is a browser side library, server side can be written in any language. For example, Centrifuge uses beautiful sockjs-tornado (https://github.com/mrjoes/sockjs-tornado) implementation of SockJS server.
I mean 95% of the time I just need strftime and strptime, which it's fine for. Then the other 5% of the time I remember how much I hate the library. 
why does the presence of mutable state make equality testing more expensive?
First thing that has popped up in my mind: classes. Being used to c++, I do not like __init__ for constructors instead of the name of the class, although that is a minor complaint. The main problem is that object-level and class-level variables need to be accessed through self or through the class name (for "statics"), and I often forget that. I would also like to have a way to overload functions (constructors for example), although it would not fit very well since the parameters are typeless and there is common to use variable param count (*args and **kwArgs).
Ok I pushed email support for the lookup() function to the dev branch. When you get a chance, let me know how it works for you, and if you would change anything about the presentation, etc. I'm working on the lookup_rws() email functionality, should have that up today. *EDIT* lookup_rws() is there now too. ARIN works pretty well, except it is a little slower since it requires additional HTTP calls. The RIPE RWS works ok for RIPE registered IPs, but won't have any contact information for the other NICS.
It looks awesome and already quite featured, it was easy getting up and running, nice job :)
You can provide `dict.pop()` with a default value argument to avoid the exception, which is exactly what I want lists to support.
It is pretty easy to use CoffeeScript in Node, so that's one way to get a fast language with a decent syntax. 
My point is that I shouldn't have to do that much monkeying around in an awesome language like Python.
In every project where I need this sort of thing, with who-knows-what side effects? No. This should be built-in.
I can think of 7.00004237 reasons why using floats is a bad idea for calculations like the ones OP is doing.
&gt; Ever heard of static methods? Although there's also the difference between static and class Yes, I have, but they make no sense in a language that has first class functions. What's the difference between a static method and a function defined in a module? &gt; Bound methods will always provide the instance as the first parameter to the method, so you'll always at least need a dummy var My point is that the interpreter should be able to insert the dummy var for me, so I no longer have to type it in the declaration every time.
You would at least have to: for i in int(5): So that Python knows what you want...
I thought this was about python 3? I was looking in the python 3 docs. why isn't this mentioned in the python 3 docs? and why isn't this the default? If they are going to enforce significant whitespace, they may as well go all the way.
Generators, Iterators, *-comprehensions currently I am in love with [Flask](http://flask.pocoo.org/) and [Flask-*](http://flask.pocoo.org/extensions/), [Quokka CMS](http://www.quokkaproject.org) and [xmltodict](http://rochacbruno.com.br/xmltodict-python-module-that-makes-working-with-xml-feel-like-you-are-working-with-json/).
&gt; I thought this was about python 3? No. &gt; why isn't this the default? It *is* the default in Python 3. Hence "normal behavior". &gt; If they are going to enforce significant whitespace, they may as well go all the way. Er... what? This and that have no relation.
Please please put the output in your .gitignore. There is no need to have it uploaded to github.
NumPy. Its the greatest thing about using python.
Are you trying to print it with a message? One thing that took me a bit of time to realize is that there is a big difference between these: print('the number: ' + 7) # An error print('the number: ' + str(7)) # Works, but annoying print('the number:', 7) # Works fine In the first way, you're trying to "add" two different kinds of objects, which is where the error can come in. If you pass different objects as different arguments to print, then it takes care of converting them all to strings and joining them with a space between. In JavaScript, it will do a lot more type conversions for you, so this is less of an issue. However, console.log still supports multiple arguments. Doing console.log(7, 8) is usually easier than console.log(7 + ' ' + 8).
Oh for God's sake, **stop using `sudo`!** **UPDATE** Oh, and I'd not recommend to use Flask's (rather Werkzeug's) built-in server. It's supposed to be for development and debugging only.
5, when used in the context of an iterator, could iterate over its contents. But what they heck are the contents of a 5?
[bottle](http://bottlepy.org/docs/dev/) web-framework as well as [requests](http://docs.python-requests.org/en/latest/) to stop using urllib(s)!
[pandas](http://pandas.pydata.org) - great data manipulation library, also a big fan of NumPy and ScikitLearn. In terms of language features, reflection and dynamic class creation are pretty nice.
The problem is that things in Python are predicated upon special names to be able to handle objects transparently. So var has a function named `__len__(self)` that is called when you invoke `len`. This is useful because it means you can use *any* object that way, it's a standard and enforced interface and you avoid any magic methods on the class. `a &gt; b` (`__gt__(self, other)`) and other things like that function similarly. Also, it lets you have an iterator protocol just by defining `__len__` and `__getitem__`, which is pretty neat. You could say similar things about `iter` and `repr` and such, but polluting the class namespace is, in my opinion, worse.
HN posted a link to this site that talked about how JS, Ruby and Java are written and 80-90% of people used spaces. I think you just end up with problems with braces otherwise...
I completely agree and I really love Python.
That is exactly what I said. Comparing is exactly what I would like to do to detect if the state of an object has changed.
I think the combination languages will probably end up being more common. Like C# started as regular static. Then they added type inference so you don't need to type it so much. Also extension methods to add functionality to existing types without monkey-patching them per se. Finally they added dynamics, so you could easily create a one-off anonymous object and serialize it to JSON. Or do some sort of method-missing style metaprogramming in certain cases. Something like TypeScript, Clojure or Cython goes in the other direction, starting off dynamic and letting you give type hints when necessary for performance, safety or tooling. I think both ways have merits depending on the focus of the language.
I've never heard of this as a complaint. Python docs are great *and* the language has first-class support for documentation in methods and classes (via docstrings). Plus they have many cross-references (even between projects) via sphinx.
yeah, metaclasses are particularly frustrating. Six just added an `add_metaclass` decorator, which I like because it doesn't pollute the `mro`. Now that I've been developing a 2/3 compatible codebase, I actually wish I could go entirely Python 3. There are a number of features (`yield from`, `*args, a=5,..` that I really want to use)
if they hadn't removed the `u` for unicode literals, I think Python 3 would've picked up steam much faster. That remains a real headache compatibility-wise.
I was struggling with EXACTLY THIS over the last week. Thank you for posting this!
I honestly hope the future isn't like C# -- C# is just too much of a "kitchen sink" language without much design direction.
heh, that's the one reason I want to go to Python3. often the iter method is just a for loop through something else's comprehension...
the one thing to keep in mind is that passing self explicitly means there are few, if any, differences between normal functions and class-level functions and that you can create your own functions just by defining a data descriptor. In some ways, it simplifies things, because there's no magic. `foo.bar` means that you're calling with a as the first argument. Which means you can pass `Foo.bar` to some function and call it with two arguments (where the first argument is type `Foo`) just like any other two argument function.
thanks for your explanation. your description of expressions is very reminiscent of LISP to me
if Python supported ruby-like syntax for function definitions I'd agree with you (e.g., `def &gt;(self, other)` etc). Otherwise, it feels more consistent to me and it helps avoid functions having two meanings.
Fair, 'non_fractional_number' has verbosity problems. What if it was 'integ' in our new language, instead? Those extra two characters wouldn't slow you down to type, but you'd have to pause all the time to remember and consider, because its unexpected syntax based on your ingrained cultural knowledge of programming. Your point was that experience with other programming languages doesn't count, and my point is: of course it does. As technology of even social processes develop, we build up tacit knowledge and understanding that helps us navigate and learn new things easier. The syntax isn't a big deal, but I program in a lot of languages simultaneously, and its one of the things i've noticed tripping me up time after time. Many languages have different conventions, but [while 'catch' is common, 'except' is exceedingly rare](http://en.wikipedia.org/wiki/Exception_handling_syntax)
Because stuff basically runs as the user `root` then. And `root` is `root` ... the **almighty** `root`. `root` is allowed to do *anything* on your system. And because of that reason alone things that do not absolutely *need to* run as `root` should **not** run as `root`. You should really **not** install anything as `root` from a source that you can't trust, and you can **not** trust PyPI. You should really **not** run your applications as `root` unless they absolutely have to. That applies even more for web applications that face the outside world. If there is the tiniest exploit people will find it, abuse it and have `root` access to your system. When you use a reverse proxy setup and communicate via TCP socket to your application server then use a port greater than 1024, then you don't have to be `root`. But I'd say to use unix domain sockets instead anyway. I'm seriously wondering why a *"software engineer with over 10 years’ expertise in building web and enterprise applications"* ([quote](http://vladikk.com/about/)) would recommend doing such a thing.
Another one?
I am so glad someone recognized this. You always use the minimum amount of permissions possible. And root is _NOT_ the minimum amount of permissions possible!
yeah, 3 * 2.
If we were to design a language today, perhaps this would justify using "catch". But the languages from which python is descended largely didn't have exception-handling. (At least not at the statement level). Comparing python to its siblings is silly as they both grew up at the same time, so of course they don't consider each other in their design. And my argument was not that prior experience with programming languages doesn't count, but that one guy's prior experience with programming languages doesn't count. You don't design a language for one guy. (Unless you happen to be that one guy, of course) I personally still like except better.
Yeah... no. Even though that would pretty compact, it doesn't look (let alone feel) nearly as nice as the C++ example does ;) Nice try though!
&gt; How else does one learn but through trial and error, not by being blatantly given the answer some types of trial and error are good. "something is wrong, you figure it out." is not a good type of trial and error.
I now it is a simple solution, and I do not completely dislike it, but I find it tedious at times. Syntactic sugar is good at times. The use of "self" is a C-like approach to objects rather than C++/Java. Early versions of C++, that were little more than translated to C, in fact used "this" in a similar way to python's "self", even though it was implicit in the parameter list of methods IIRC.
How often do you need C++ style `for` loops in Python? Most everything is covered by iterators.
A similar project is [fbone](https://github.com/imwilsonxu/fbone)
Yes. I've worked with a lot of legacy codebases, in VB.NET, C#, PHP, Python, and Java, and among these languages, Python is by far the most difficult to refactor. Yes, even VB.NET is easier to refactor.
My point was only that a stored property was likely to get out of sync in edge cases, whereas a function that checked the length every time it was called for would not suffer this. I had forgotten about `__len__`, though. It makes what I said above pointless.
My point was only that a stored property was likely to get out of sync in edge cases, whereas a function that checked the length every time it was called for would not suffer this. I had forgotten about `__len__`, though. It makes what I said above pointless.
Why do this? wget http://nginx.org/keys/nginx_signing.key sudo apt-key add nginx_signing.key rm nginx_signing.key echo "deb http://nginx.org/packages/ubuntu/ raring nginx" | sudo tee -a /etc/apt/sources.list echo "deb-src http://nginx.org/packages/ubuntu/ raring nginx" | sudo tee -a /etc/apt/sources.list when you can do this? sudo add-apt-repository ppa:nginx/stable
That's a horrible way to detect if the state of an object has changed. The fact that it doesn't work isn't an issue with python, its an issue with your way of thinking.
Oh, sorry, I incorrectly assumed this was NodeJS.
Btw, MS has recently released Reactive Extensions for Python3. I submitted it here but it got spamfiltered. Have a look here: http://rxpy.codeplex.com/documentation
Doesn't explain the "why"
Cool... Thanks!
you seem to be conservative, risk a lot higher up than evidence :)
And unless you have to escape the double quotes when you're actually typing it into the shell, you don't need to escape them in the python string either since you're using single quoted strings.
things like django, flask, pelican
And one (of a few) that uses cookiecutter [cookiecutter-flask](https://github.com/sloria/cookiecutter-flask)
Yeah they were throwaway keys I made for messing around. The keys now are way long gone.
Why would you need to do that? Unless you put a . behind it, Python interprets all integers given as integers. &gt;&gt;&gt; type(5) &lt;type 'int'&gt; &gt;&gt;&gt; type(5.) &lt;type 'float'&gt;
I don't like the lack of symmetry in copying variables. If I do: a = 2 b = a b +=2 then b is 4, and a is 2 (because b was a full copy of a, and not just a reference to a), however when I do: a = someClassInstance b = a b.add(2) a and b have both been changed (because they're really just referencing the same thing). I wish that setting variables to be equal would either ALWAYS mean having two variables referencing the same data, or ALWAYS mean fully copying the variables to create stand alone variables (why should I have to import copy and perform a deepcopy on only some variables when I want to create duplicates?). 
Gevent, requests and arrow are awesome packages. Personally I'm a decorator and generator person. 
except you didn't actually explain the problem very well. you basically went "something is wrong with this code. not telling you what, figure it out." besides, I know that at least a subset of people learn way better by answers than by questions, myself included.
The lack of robust module reloading. Sure the code reloads, but any variables that exist during the reloading keep using the old code. This is a real pain when, for instance, developing a bunch of celery tasks.
&gt; I assume that if you are following this tutorial you should be familiar with these basic things. That's a pretty bad assumption to make, because most people following tutorials on these things will probably copy-paste whatever the author has written if the blog seems credible. The article even sort of promotes it with the echo/tee lines.
[Nick Coghlan's response on python-dev](https://mail.python.org/pipermail/python-dev/2013-September/128800.html) is informative. But I also wonder what it would really gain us? The main thing people are frustrated about with `lambda` is that you can't do multi-line functions. This wouldn't solve that, would it? (And even if it did, arguably one should name one's functions at the point where they need multiple lines.)
I did not say it is a bug. I said that is something I do not like. Serialization of objects should be deterministic. How would detect whether an arbitrary object has changed?
Yes, this would be handy at times. Along similar lines, I think it'd be great if `int()` took a default if the string couldn't be parsed, like if `int('invalid', default=0)` returned 0 instead of raising ValueError. Incidentally, [web.py](http://webpy.org/) has [`listget(lst, index, default=None)`](https://github.com/webpy/webpy/blob/master/web/utils.py#L824) and `intget(s, default=None)` functions for this purpose.
Very rarely. I just think that if Python allowed C++ style `for` loops it would make those rare cases where it would be appropriate to use them just a tad nicer. If there's any language where people are constantly telling others how nice it looks and how good the syntax feels, it's Python (and I do agree with this). It makes sense to me to have C++ style `for` loops as a language feature.
Well that's why this project is quite alpha. I know I haven't even reached it to beta. * I will look more into replay attacks * Well isn't that a large weakness within several techniques? * I think I have an idea to solve this but I will look into how the-sable it will be * Doesn't that sound more like the kill-all connection type of attack? If so then wouldn't it affect anything on the network? I figured as much since I haven't gotten around to really randomizing the RSA keys, increasing the size of the key, and providing a proper amount of padding. What if I use SSL to transport the messages but encrypt the messages with RSA? Basically an RSA encrypted message which is then encrypted by SSL? Finally yeah I know and I really didn't feel like re-inventing the wheel since I am both not a hard core mathematician or a researcher in cryptographic schemes. 
Looks like I'll need to provide more clarification within the README.
So essentially two files with the client class and server class but a main class calling each class. I think I can get that done.
Haven't won what? And more important, why do we need to beat PHP?
No, I don't. And you haven't yet told me the principles behind your objection. I say again, some people believe that multiple return statements in the same function defintion are an abhorration. One such is the MISRA C standard &gt; (MISRA, rule 14.7 : required) "A function shall have a single point of exit at the end of the function" Some languages, like Pascal and Eiffel, require there be only a single exit point. However, many more people do not believe this is a good principle to follow. Can you explain why I shouldn't regard your view as fitting into that category? Why shouldn't an iterator be iterated on at multiple points in the code? Is the code harder to reason about, more complex to write, more prone to errors, or something else? My experience says that the answer to all of those is "no." The most relevant example in other languages would be the various prohibitions of modifying a container while iterating over it. Even then, modification may be allowed. For examples from C++, see http://kera.name/articles/2011/06/iterator-invalidation-rules-c0x/ , which lists which container mutations are allowed during iteration. 
It's recommended not to use RSA for the main encryption... both because it is slow and because of attacks against it. RSA can't really encrypt any old data securely, just stuff of the appropriate length. What most cryptosystems do is use RSA to send a random key which is then uses with a symetric cypher for the main communication. (Or use RSA to send Diffe-Hellman parameters.) This is what PGP does, what SSL does etc. But there are a whole host of issues, and designing a secure communication protocol is really hard. Even the people who did SSL messed up a few times which is why the earlier versions of SSL are considered broken. By using SSL you would be using a protocol that has thought of all these issues, and has solutions for them. You could use SSL to transport RSA-encrypted messages but I can't see what that would gain compared to plaintext-over-SSL.
I love the richness of the standard library. Almost everything I need to do is already there. As for packages, I have grown to love and appreciate tkinter/ttk because it works and it's already installed. I know many, many people will not agree with this opinion, of course. 
or even more simple: apt-get install nginx
That is all correct but has nothing to do with using werkzeug as a server.
Isn't it just a few characters different? 
Well that's what I did by using RSA.
Does fabric work on windows?
Really? I feel like the lack of static typing makes it easier in some ways. I recently refactor ed major parts of a 10K portion of a 100K code base and I had no problems.
The reason why I have made that suggestion is well there are tools like SSLBump from pfSense which allows SSL to be decrypted, read, passed through a filter, re-encrypted, and finally sent along its way. Also apparently the NSA has apparently already broken SSL. So by using the onion method I would imagine it would be a bit harder to break. Edit: Here's the documentation for [SSLBump](http://wiki.squid-cache.org/Features/SslBump) which is for Squid not pfSense.
Ubuntu repositories are often outdated. If you want to use the latest stable version, you have to either add the official nginx repositories, as described in the post, or as dotted suggested, you can get it from Ubuntu PPA repository.
&gt; because the iterator is advancing at multiple points Yes. And multiple return statements cause program execution to return at multiple points. That your statement is correct doesn't make it a positive or negative. Someone who likes a single return statement may also complain "what the fuck is going on?" when faced with a few dozen return statements, and *will* lead to confusion for some people. Hence, you can be entirely right, but if the number of times that you're right is low enough, then it's not something for me to worry deeply about. &gt; The basic structure of a for loop is "run this once for every line in the file." You're subverting that rule. The basic struture of a for-loop is: while 1: try: x = next(it) except StopIteration: break ... No more, and no less. (Historically, before Python 3.x, there was a fallback solution to use [0], [1], ... lookups until IndexError or ValueError. For purposes of this conversation I think we can ignore that.) My logic of course can lead to Duff's device, which is legal but confusing to say the least. Your logic is that no one will look at the for-loop and think of it as a next(it), even if that is the underlying mechanism at action. Both are hypotheses at this point - my hypothesis is that it's readable, and yours is that it isn't. Both are true, for the right category of users. The next question would be *should* we encourage people to use this approch, or discourage it? &gt; which is a Bad Thing since more skilled developers cost more Ahh, yes. Do you take the position of the managers, who generally wish to reduce costs on everything? Do you take the position of the employees, who may want more money? Do you take the position of the educators, who want people to know more about how things work, or do you take the position of the oppressed, who want to tear down the priesthoods? It's a complicated topic. But programming state machines directly, which mechanically simple, is also complex and error-prone, so I don't think you've made a strong argument here. Yes, state machines are widely known, widely loved .. and widely reviled. For example, an XML SAX event consumer just screams for a state-machine design, and after a while they get to be almost like fun puzzles to solve. But they usually aren't as easy to understand as a coroutine-based parser, which manages the state transitions implicitly rather than explicitly. This debate has stretched over decades, with avid fans for each of the many different solutions. I may be an avid fan of Sports Team X, and disdainful of your love of Sports Team Y, but that doesn't mean that my disgust is meaningful. Similarly, my preference for co-routines and implicit state transitions shouldn't be the guiding reason for your ire, as a fan of state machines. &gt; Usually, iterating over an object doesn't modify that object Iterating over containers don't modify the container, yes, but iterating over iterators always modify the iterator .. excepting a few trivial cases like empty iterators. Some objects that are modified during iteration are file handles, database cursors, and generators. The very start of my code does an it=iter(...), which specifically says "I care about the iterator, not the container." I can agree with you that it's seldom seen. I can agree with you that it may cause confusion compared to a strict readline() approach. What I don't see is how this is "absolutely disgusting" in a reasonable general sense, so I'll have to thank you for your input, but decline to empathize with your disgust. 
The official repository offers the plain vanilla version of Nginx. The version from PPA can differ, it can contain some Ubuntu specific optimizations. For learning purposes I prefer to use the standard version of a product.
We're using nginx + gunicorn + flask in production and it works very well too.
&gt;The basic struture of a for-loop is: No, that's what a for loop *does*. But when I read `for line in file`, I think it's perfectly reasonable to assume you're iterating over the file. &gt;Ahh, yes. Do you take the position of the managers, who generally wish to reduce costs on everything? Do you take the position of the employees, who may want more money? Do you take the position of the educators, who want people to know more about how things work, or do you take the position of the oppressed, who want to tear down the priesthoods? I take a very simple position: the more resources required to maintain a piece of software, the worse it is. This does not seem very controversial to me. Good code is easy to read. &gt;For example, an XML SAX event consumer just screams for a state-machine design, and after a while they get to be almost like fun puzzles to solve. But they usually aren't as easy to understand as a coroutine-based parser, which manages the state transitions implicitly rather than explicitly. That's not the dilemma we're faced with here. You want to iterate while you iterate, implicitly skipping lines without using `continue` or other control mechanisms. That's not analgous to coroutines. Now, we could convert your loop into a coroutine-based solution, and that might make it easier to understand. But that isn't the code you showed me, so don't tell me some imaginary fantasy is better than the code I showed you. &gt;Iterating over containers don't modify the container, yes, but iterating over iterators always modify the iterator .. excepting a few trivial cases like empty iterators. Most people don't work with iterators directly, so they don't know or care about that distinction. Your code is only comprehensible to people who *do* know and care about it, which makes it less accessible. &gt;The very start of my code does an it=iter(...), which specifically says "I care about the iterator, not the container." Most people will see that, look up `iter()`, and then say "Why didn't you just write `for line in file_object` directly? I'm so confused." They will then spend a lot of time fooling around with `iter()`, `next()`, and `for item in container` until they understand it. Why do you want them to waste that time? What good does that do your employer? &gt;What I don't see is how this is "absolutely disgusting" in a reasonable general sense, so I'll have to thank you for your input, but decline to empathize with your disgust. Explicit is better than implicit. You want to build a state machine? Then *build a fucking state machine!*
By default, Werkzeug is single threaded. Sure, you can set it (AFAIR even using Flask.run() kwarg) to be multi threaded, but still you'll be using a development server in production. There are way better solutions that Werkzeug for running WSGI apps in production. I generally lean towards Gunicorn as it's never failed me (and I've learn its invocation by heart). TL;DR - Werkzeug is for development, not for production.
It's probably torn.
I've heard good things about gunicorn too, especially it being much easier to set up than uWSGI. I'll definitely give it a try.
Serialization of objects is deterministic, the same input produces the same serialized output, a different order of keys is a different input. There is no easy way to do that in any language I know of - it would be convenient if using cPickle worked, granted, but I find == works a treat for a lot of cases. Why do you need to track arbitrary objects, out of interest?
Correct me if I'm wrong, but shouldn't the nginx "location" block that serves static files go directly to /static? I didn't try it, but the way you configured nginx suggests that you can go to /hello.py and get the source code served to the browser, since you only defer to uwsgi when the requested URL is not a file. It sounds like with your setup anything you have on your project can be served as files.
This is one of the things that is not obvious, but once you understand why it turns out to be a great idea. Python has quite a few details in this category. The reason is that string join will join any iterable/sequence that returns strings. That means that you can pass string.join a list, tuple, iterator, generator, or even a string.
I'm sorry, maybe I should have been clearer, but my point wasn't that the documentation is insufficient so much as that it could be organized better. Example: http://docs.python.org/3/library/datetime.html Lets say I want to print out a formatted date without any prior knowledge about this module. I open this page, I'm looking for something like "format". There is no list of functions in the sidebar, so I just have to scroll through this... I have to scroll through about half of this long page before I encounter \_\_format__ ... which says that I should use strftime(), okay, makes sense I've heard of that before so lets check it out. It's just above, so I follow it. I click the link in the description, because I want to see how to specify format, ok this seems normal, so I go back to see how to invoke strftime(). Its a method on datetime, but instance or class? I scroll down a bit to the examples and it turns out its instance method. So now how do I get a datetime instance. At this point I have to scroll back up and down again looking for how to instantiate datetime, finally I find datetime.now(). So I can piece it together. The documentation is sufficient, but looking up what I wanted took a lot more than it should have. If there was an index of functions in the sidebar everything would have been much easier. You look up what sounds like the right thing, check it out, and if it wasn't what you wanted, just look further. Also if the pages were per-function you wouldn't have to scroll up and down to a different function and get lost in the process, you'd just click in the side bar. The formatting reference could be only on the pages of functions that actually use formats, and the examples could be divided for each function. Also for example if the strftime() function had an example showing the format usage right next to it, maybe I wouldn't even have to look up the formatting reference... I hope this explanation helps, if not please let me know. I'm fully prepared to accept any opinions or tips, if you think I'm doing something wrong :)
Seems like he took it down. What a shame. [Python 2.7 Mirror](http://rapidshare.com/share/155AE1C77431190D6F6B3ABA57B2DFC7) [Python 3.3 Mirror](http://rapidshare.com/share/83481DFFCE266E6C160811F151D69A03)
&gt; What good does that do your employer? I'm self-employed. I get to decide what's best for me. ;) &gt; Explicit is better than implicit. You want to build a state machine? Then build a fucking state machine! I take it then that you dislike generators? Every generator, after all, can be rewritten as a state machine. Though it's not always easy to do so. (In the Python 1.x days, up until we had yield, that's what I had to do, so I know it can be done.) Python is not designed as a state machine language. If it were, it would support goto statements, because re-establishing state on each input, assuming a single input location, takes roughly log(n) time in the number of input possibilities, rather than the constant time using my preferred approach with multiple input possibilities. Or, if you wish to argue zen statements back and forth: "Simple is better than complex" but "Complex is better than complicated." Explicit state machines are complicated. What I propose is complex. Neither are simple. (State machines are based on a simple mechanism, but complex state machine solutions are *not* simple to implement correctly. My appeal to SAX event handlers was to show that I know how difficult it is to build a complex state machine correctly.) &gt; Most people will see that, look up iter(), and then say "Why didn't you just write for line in file_object directly? I'm so confused." Have these people never read through the documentation? The documentation for itertools has a half-dozen examples which start off 'iterable = iter(iterable)'. See http://docs.python.org/2/library/itertools.html to verify for yourself. Though you're also right; I don't think there's any place where it explains *why* that's done. It's to ensure that you get an iterater even if the input is a container. Good point! So would the lack of understanding be solved by improving the documentation? I know the answer though. Most people don't read the documentation so it's rather moot. So then the debate is if we should program to the common denominator, vs. work to improve the baseline understanding? You write: I take a very simple position: the more resources required to maintain a piece of software, the worse it is. This does not seem very controversial to me. Good code is easy to read. As I have before said, it is your opinion that this code is not easy to read nor maintain. I, on the other hand, find it easy to read and maintain. We are at an impasse, and repeating our beliefs won't make it true. 
This looks perfect! You certainly choose all the right tools... Tornado, Redis, 0MQ. I had a look at the JS... Ugh. It sucks that we have all these amazing back end libraries and tools and then we have... JavaScript :)
Don't forget the nearly non-existent timezone support.
If the keys are sortable pickle could just serialize the items with the keys sorted. I do not know about other languages but I hold python to a higher standard. 
Hands down, I love Python for the syntax. I stay in love with it due to IPython, pandas, and bottlepy.
 * Flask (microframework) * requests (easy http) * BeautifulSoup (html/xml parsing) * Arrow (sensible datetiime library) I love how I can import a few libraries and get to work straight away without much boilerplate. In terms of getting work done I don't think there's many other languages that can compete (ruby is one of those languages).
I agree, but most other languages also treat `if-else` in the same way, like if(foo) { } else { } or in Fortran/Matlab, the syntax is something similar without braces, so you do have a point but I guess I'm more used to seeing it this way.
Wait, Microsoft actually provided code for *Python*? I thought that writing in any language not beginning with the letter "C" gave them hives or something...
Django
&gt; So you're absolutely certain no one else will ever have to look at your code? That seems an awfully strong assumption. No. You argued " What good does that do your employer?". I didn't think that was all that great of an argument. It implies that the economic relationship between you and your employer are high in your mind, which certainly is not the case with me. Now you've, ahem, "changed the subject" to be about future people who might look at my code, instead of my employors economic sensabilities. *Shrug*, I've done an approximate present value analysis and decided that it was worthwhile. BTW, since I assume you also do a similar value analysis, your reference to "absolutely certain no one else" tells me you are much more risk adverse than I. Congratulations? Perhaps that's the source of why you think something which isn't mainline standard is horrible, while I don't? &gt; Besides, generators are not the subject of this discussion. You didn't use them in any of the code you showed me Here's my logic: I use multiple iterator consumers because I prefer to have an implicitly managed state machine using Python syntax than an explicitly managed state machine that I roll-myself. Your rejected that, saying that if I want a "fucking state machine" then just go ahead and do it. *IF* your stated logic is correct then it should apply to other cases where one can build a state machine, even where Python provides an alternate non-explicit state machine for it. One of the most prominent of these is the yield statement in generators. *IF* your logic, as stated, is correct then you do not like generators. Of course you do like generators, so you realize that your base logic wasn't complete. Now you've refined your logic to say that it's okay to use something other than an explicit state machine if it is *idiomatic and well-understood*. I can appreciate putting all of the appropriate qualifiers on a statement is difficult, so that's probably what you would have said, going back in time. If you use a time machine, do also please remove the swearing. But think of it this way - how does a new concept become well-understood if everyone follows your suggestion and refuses to try it out? &gt; You can't expect every programmer to be familiar with every package. If you want people to read the itertools docs, you should have import itertools at the top of your script. Interesting viewpoint. Odd though. No, I would say that these people have not read through the documentation. They've read through a tutorial and a summary of the documentation. That's like saying one's read through "The Catcher in the Rye" after reading the relevant Wikipedia page and the Cliff Notes. Curious too. If you haven't read the full documentation, how do you know that multiple iterator reads aren't a perfectly normal idiom, covered in a chapter you haven't read? Three Stack Overflow pages which use the idiom you detest are: http://stackoverflow.com/questions/4983013/python-access-to-iterator-object-in-for-loops , http://stackoverflow.com/questions/16814984/python-list-iterator-behavior-and-nextiterator and http://stackoverflow.com/questions/17837316/how-do-i-skip-a-few-iterations-in-a-for-loop , so it's not like there's a universal hatred of of the idea. &gt; You can't expect every programmer to be familiar with every package. If you want people to read the itertools docs, you should have import itertools at the top of your script. At least that clears things up. 15% of the Python files in my code base have an "import itertools", so anyone I work with will have to know what it does. If not, I'll teach them. It's a wonderful and extremely useful module. 
Not that I object, but: sudo apt-get install python-setuptools sudo easy_install pip sudo pip install virtualenv Using a package manager to install a package manager that I only use to install a different package manager so I can install a manager for the packages I need... Not saying its wrong, just saying it is crazy we have to do this.
I really like Django and django rest framework. oh and context managers.
I still don't quite get what this methodology has over interfaces (I mean that without criticism, I literally don't know) . Using the examples in the Documentation, how is registering a Document object's "content_size" method with ISize different from simply declaring the Document as an object that implements an interface with, say, a generic "size" method?
No one ever believes Guido said this, despite the high-profile place he said it - the PyCon 2011 Keynote. http://youtu.be/EBRMq2Ioxsc?t=33m52s "OS level threads are meant for doing parallel I/O, not for doing parallel computation...." &gt;It doesn't matter what they were invented for. It does, for the same reason it matters that screwdriver was invented to drive screws and not hammer in nails. We have threads for parallel I/O and processes for parallel computation, and a case needs to be made if we want developers to expend a huge amount of effort and lose other features just to get parallel threads. It may be that a case can be made, but just because that's the way other people are doing it probably won't be enough to make it. &gt; they're cheap, as are processes on everything POSIX (aka anything not Windows). &gt;and make sharing memory extremely easy. And dangerous! &gt;and threads are the de facto way of leveraging multicore within a single process The enterprise-level RDBMS PostgreSQL uses processes, not threads, yet in benchmarks rivals or surpasses Oracle and SQL Server. As they've put it... &gt;"The developers agree that multiple processes provide &gt; more benefits (mostly in stability and robustness) than costs (more &gt; connection startup costs). The startup costs are easily overcome by &gt; using connection pooling. Someone goes into the details here: http://www.postgresql.org/message-id/1098894087.31930.62.camel@localhost.localdomain It's not just Guido being crazy. It's the creators of amazing software like PostgreSQL and Python. 
Favorite language feature: `dict`. Whether it's working with JSON or just using them as intermediate structures for organizing data, I have 101 uses for the handy class. And having `defaultdict` and `OrderedDict` is nice as well. Favorite package: NumPy. Without it, I wouldn't be able to use Python. Almost all of my code is data processing, and NumPy makes it easy and efficient with minimal effort. Favorite tool: IPython with the scientific stack (numpy, scipy, matplotlib, pandas, etc). It is an indispensable tool in my work day.
`StackOverflowError: Maximum package manager recursion level reached.`
Exactly. And we really didn't have IDEs back then either. :-) 
Ubuntu repositories also often work. It's been my experience that you don't always need the very latest and greatest version.
Sure they are, but that doesn't mean that pretty much anyone can upload pretty much anything they want.
Project "Flask-Foundation" already exists more one year. https://github.com/klen/Flask-Foundation
Thanks for your words, feel free to write me if you come across any problem with Centrifuge or any unclear moment.
I like most the development of python. Looking back through the docs to the 2.1 days (or just paying attention to the `since` tags) it's pretty clear where they made some decisions that at the time might have been "good enough" but later proved to be a real hindrance. But instead of hacking one-off patches or living with external contributions to paper over the details, they figured out where they went wrong, learned the concepts if necessary, and *fixed the language*. Probably the most evident is the evolution of types and classes in 2.1-&gt;2.3. In 2.1 (and yes, I still have to deal with 2.1; thanks IBM) objects feel like an afterthought. 2.2 fixed this, making user defined classes and builtin types like `list` and `dict` behave the same way. 2.2 introduced a bug dealing with diamond inheritance, so in 2.3 that was fixed. Another thing I like is the introduction of new features over time. The care they put into crafting and evolving the python language definitely deserves mention.
If someone *has* to reach for a PPA, it's probably because the stock version *is* outdated. I've had to pull newer Nginx the other week, because we need Transfer-Encoding: chunked in uploads, which is not in the version included in Ubuntu.
You should see the Python-Dev and Python-Ideas mailing lists. Even ideas must be considerably well thought out to make any discussion last more than 5 days.
I added the update after I gave this replay. See /u/tomekwojcik.
Its not a command, I am using actual make. Take a look: https://github.com/JackStouffer/Flask-Foundation/blob/master/Makefile
This seems awfully complicated. I just run the flask app on some random port and have nginx direct all traffic to X domain to Y port...
If you have already changed everything that uses the key, is there really a need to remove the file from the history?
How do you expect that to even work? What happens if you've stored a generator from method `get_generator` on your class `Foo` and your new version of `Foo` doesn't contain that method (or it returns an int)? Not to mention you could get into some very weird state since the existing objects would either A) not re-run `__init__`, in which case some new variables may not be initialized or B) re-run `__init__` and risk re-initializing *some* existing variables (but not necessarily all).
That goes against everything Python stands for ("if it quacks like a duck...") and would break iterables (since there's no IEnumerable base class). That said, there have been suggestions of using "function annotations" together with a linter to perform some basic type checking. Also, there's a lot of `getattr`, `setattr` going on in Python -- it would be a nightmare to try and type check that.
I like it too. It's well-engineered and accounts for so many edge cases, *however* I really find the syntax too verbose. I prefer **[Pony ORM](http://ponyorm.com/)**. It's more "magical" in its implementation but feels a lot more Pythonic to me when actually writing with it.
I like the speed of deploying apps in python. Had to deploy a dbms application for a large company within two weeks and i still cant imagine how that would have happened with some other language.
Distribute is not a thing anymore. It has re-joined with setuptools, so use that again. We have always been at war with eastasia.
Nginx is the best choice to serve flasks, it is russian after all. 
Yes. Why that guy install virtualenv and still have to use sudo to create env, run uwsgi and everything. The beauty of wsgi is the way it handle socket/connection without having root/special access. You only need root to configure nginx (which you can ask for system admin if you don't have)
Cool, I started building a real-time notification system using similar constructs (SocksJS&lt;-&gt;Tornado-Socks&lt;-&gt;Redis Pubsub). Have you tested this architecture at scale?
maybe because store int as native integer don't show memory/speed improvements as long as you are not utilizing tagged pointers (that cpython curently don't use) and that using only one type simplify code and interface but this is just a wild guess. As long as I understand http://hg.python.org/cpython/file/84658272e923/Objects/longobject.c it's only the operation on a single digit (integer native size) which are optimized threw MEDIUM_VALUE trick
Well, dynamic typing is not the major stumbling block I'm talking about here. PHP is dynamically typed, too, yet it is easier to refactor than Python. Of course a static type checker makes refactoring safer, and it can replace much of what you'd do with unit tests in Python, but the refactoring hurdle is the lack of explicit block delimiters, a direct consequence of the design choice for significant indentation (or maybe it's the other way around).
I think you were confused because the quote is a shell delimiter not part of argument
I am similarly annoyed by your other example. I don't like the lack of consistency in the behavior for mutable and immutable variables. I want the operations to behave the same way regardless of the types they're dealing with.
Something like SSLBump would be detectable (and therefore rejected) by a well written client application. SSL MITM tools like this present a new certificate to the client "prooving" that the SSL MITM is actually the remote server. This only works if the MITM can generate a certificate that the client trusts. This might be because the MITM has stolen verisign's root key, or because the local administrator installed a organization-specific key. Without either of these the tampering is evident. This is why the squid page says &gt; By default, most user agents will warn end-users about a possible man-in-the-middle attack. But for your application, because you are pre-sharing public keys, you don't need to rely on certificate signing. Instead you can do your verification just by ensuring that the remote user authenticates against the pre-shared certificate.
You could even skip pre-shared key by levereging the SSL certificate system. Have your users get SSL certificates for their email address (e.g. [here](http://www.instantssl.com/ssl-certificate-products/free-email-certificate.html)) and then use that certificate/key for your communication. If you verify the certificate against a good set of trusted CAs, then you can be certain you are talking to someone with that email address. Again, MITM can only occur if an attacker has compromised one of the trusted CAs, or has got *their* ca certificate into the list of trusted CAs.
This submission has been randomly featured in /r/serendipity, a bot-driven subreddit discovery engine. More here: http://www.reddit.com/r/Serendipity/comments/1mrp49/serving_flask_with_nginx_xpost_from_rpython/
The lack of s-expressions. And the fact it's not Common Lisp.
Yes, that sounds right. I had somehow convinced myself at an earlier stage that it didn't work without the quotes, that's how I got in a tangle.
Interesting module; not really what I need though, and it looks like it might be a pain to install on Windows too: http://stackoverflow.com/questions/9000380/install-python-fabric-on-windows
If you have control over the Document so you can actually say it has this interface, then that is a reasonable approach. I'm not sure where you are proposing the size method is implemented; but if on the Document, then you need this control as well. Even with that control, it may at some point breaking separation of concern; for instance when you start adding view code to model classes. Reg is for the case where you do want separation of concerns or when you don't have this control. Someone else has created Document, and you can't change it. And now you want to add a feature. Some languages have features (such as generic methods) that make this possible by default, but Python does not (though I found out today that PEP 443 may add this feature, at least for a basic case). 
Looking at the actual library it looks pretty good, just don't particularly like the use of \_\_call__ though. 
&gt; So you're familiar with all of these packages? You do like argument by extremes. My complaint is that reading only the tutorial and the overview isn't the same as reading the documentation. The way I phrase my complaint was wrong. Instead of "The Catcher in the Rye", here's perhaps a better comparison. If someone says "I've read Shakespeare", then there's a difference between someone who's read only Romeo and Juliet, vs. someone who's read the complete plays of Shakespeare, vs. someone who's also read the sonnets. Of the 48 OS-specific modules, I've used 3. I've not used the 10 multimedia modules. Beyond those there are 37 modules which I haven't used and read the documentation. There are about 310 modules, so that's 70% of them (85% if you take out the OS-specific modules). That's roughly the plays of Shakespeare, excepting the late romances, and not the sonnets nor his narrative poems 'Venus and Adonis' and 'The Rape of Lucrece.' In this context, the itertools module is more like Henry V. Someone who claims to know Shakespeare without having read/watched Henry V, nor any of the other histories, is not really believable. &gt; it's your chicken-and-egg problem, not mine To remind you, I asked you to tell me why it's so despicable. You kindly gave some reasons. My comment, regarding the chicken-and-egg situation, is that your reasoning implies that any new idiom is despicable. I don't believe this is a new idiom, and indeed I found other example of people using the idiom. Here's an example from 2009: http://stackoverflow.com/questions/1474646/python-arbitrarily-incrementing-an-iterator-inside-a-loop . It's upvoted and selected as the reference answer, as well as in several other answers. &gt; hacking something together with iterated iteration is not at all reasonable Notice how in all those "unreasonable" Stack Overflow answers that no one expressed outrage over that idiom? I can now conclude that your views are not held by the majority, nor likely even a significant minority. 
I'd expect a native int to be rather much faster than a bignum, but maybe I'm wrong.
I was launching several processes on one machine behind Nginx. Everything works fine in this case. I don't see any problems with running many processes on different machines, but have not tried to do it yet. As for dealing with increased load and benefits scaling can give - sorry, nothing to say at moment.
Guys, thank you so much for your feedback and insights. I've made some modifications to the post: 1) I removed the redundant usage of "sudo", as suggested by dAnjou. 2) As suggested by dotted, I used the PPA repository to simplify the setup stage.
No, they are not.
I'm currently using nose for testing, what advantages does py.test have over it?
I just tried accessing it and looks like the old version is still being served. You should probably clear all the cached copies.
You know what? I like your syntax more than virtualenvwrapper. There's something very elegant about your minimalistic approach. Do you plan to make it `pip` installable?
It's probably stuck in your browser's cache. Github pages sets very aggressive cache headers. Please try clearing your browser's cache or hard refresh.
&gt; If you find that PyContracts is not enough for you, you probably want to be using Haskell instead of Python. +1 for docs with 'tude I'm curious whether a function/predicate can be passed to the decorator rather than a string. 
flawless victory
I don't know about flask, I use [bottle](http://bottlepy.org), but I imagine it'd be fairly similar... Once you understand the options etc... for uWSGI, it is quite simple, and definitely performs better.
Another great tool is autoenv: "When you cd into a directory containing an .env, autoenv automagically activates the environment." http://docs.python-guide.org/en/latest/dev/virtualenvs/#autoenv
How about going meta with a Monty Python reference? 
http://www.jolla.com Jolla Sailfish OS, linux based, you can even run Python/Pyside on it just like on your desktop or server!
I can dispense with the hypothesis. I actually bought the 5s today.
The point is that it treat the bignum exactly as a native int if it's small enought
I'd hold out a month and check out the Nexus 5 and Nokia 1520. Nothing that is out right now is wowing me.
I'm surprised that no one has mentioned **pip** yet. Its pretty much a must-have for me. Combined with **virtualenv** it makes development of things that I might not want installed system-wide a breeze. 
A Blackberry Z10 or Q10 I think.
How do all these compare?
No, I was literally asking you that question: "How do *expect* the module reloading to work?" If you were to get your wish, how would it handle re-initing things, for example?
I love bottle! Also, I really like Flask. Heck, I like most micro web frameworks.
Ah, well that's different! To be honest, realizing how tricky it could be has kept me from looking too much into it. I suppose the real problem is changing data structures. I'd be happy if I could simply reload just the defs of a module. Edit: spelling
You cannot pass a function directly to the ``@contract`` decorator, but you can easily create a new contract with a lambda as follows: from contracts import contract, new_contract new_contract('positive', lambda x: x&gt;0) @contract(interval='positive') def timer(interval): print('sleep for %s' % interval) timer(2) timer(-1) # contracts.interface.ContractNotRespected: Breach for argument 'interval' to timer(). # Value does not pass criteria of &lt;lambda&gt;() (module: __main__). # checking: function &lt;lambda&gt;() for value: Instance of int: -1 # checking: positive for value: Instance of int: -1 
I don't have any feelings about iOS one way or another. But agreed that I don't think anything other than iOS or Android are ready enough. I would want to use my phone as a consumer device in addition to Python tinkering on it. And it looks like there are several decent pushes to get Python working on Android (Py4A, QPython, Kivy...PySide is getting there too).
If OP does decide on iOS, check out Pythonista, which is a neat app for developing Python scripts (and even apps) directly on the device. [http://omz-software.com/pythonista/](http://omz-software.com/pythonista/)
I can give my biased opinion. cookiecutter-flask is not structured well in my opinion, forgoing blueprints as well as application factories (which makes it harder to test) with no changing of configs based on the environment. I think fbone has a rather nice structure though. But I biggest problem with it is that it is far to opinionated. Fbone requires you to use Ubuntu, fabric, sqlite, and apache. Sure, you can go through and replace these, but that can be rather tedious to find out where all these things are used and replace them. My objective when creating this was to make a non-opinionated, well structured, boilerplate that was just about flask, and nothing else. 
I don't really know what question you're asking. The post I linked to is drawing an analogy. I've certainly experienced something like it.
First of all, the RSA algorithm specifics are: Let *p,q* be two primes, *n* = *p·q*, and *t* = (*p* - 1)(*q* - 1). Now, pick an *e* such that gcd(*e*, *t*) = 1. I will assume your *e* to satisfy this condition. Let *m* be the message you want to encrypt, and *c* = *m^e*(mod *n*). Finally, and this is where most of your problem lies, let *d* = *e^-1* (mod *t*), this *d* does NOT equal 1/*e* (mod *t*), to find this *d* you must find an INTEGER *d* such that *ed* = 1 (mod *t*). This *d* is called the [Modular Multiplicative Inverse](https://en.wikipedia.org/wiki/Modular_multiplicative_inverse) of *e*. To compute it you can use the operation used in the article. Finally, to decrypt *c* and have *m* you must raise *c* to *d* (mod n), to visualize what happens: *c^d* (mod n) = *m^e^d* = *m^e·d* = m^1 = m (mod n) But you changed the modulo from ***n*** to your variable ***t*** *e·d* turning 1 happens due to [Euler's Theorem](https://en.wikipedia.org/wiki/Euler_theorem). So to recap: * *e^-1* (mod *t*) != 1/*e* (mod *t*) * *m* != *c^d* (mod ***t***) but *m* = *c^d* (mod ***n***)
&gt; e -1 d e d e·d 1 -1 d d
+1 for sharing and initiative
Yes and the non-magic of putting each venv in it's own project folder!
why not base yourself on cookiecutter though? I mean cookiecutter-flask is not the only one out there but cookiecutter is quickly becoming a defacto way of scaffolding projects.
Right, which is why multiprocessing is not right for every script. I recently wrote a script to process XSL transforms. Serially with one processor, it took over 1.5h to complete. With 8 cores running in parallel to process subsets of XSL, it took 27 minutes. If you compare each individual process compared to a serial run, it took a little more time per transform due to timing with the parent thread executing new processes and system bus limitations (0.9-1.1s per transform versus ~1.5s parallel transforms). Overall, it went faster, so it was useful.
I am currently working on it.
It would run faster if you locked the "multithreaded" version to a single processor. All you are "multithreading" is the IO, and as such you are losing time due to threads switching between processors. As I said above, "multithreaded" programs in Python often run *slower* on multiple cores &gt;Right, which is why multiprocessing is not right for every script. But the cases where it is useless are the "trivial" ones. Map/reduce, etc. I'm in CS/Physics. The vast majority of the time things can be simplified at a first approximation to one or multiple of {(math-heavy) map / nested map / reduce}. And Python is pretty much completely useless for this. Is a high-level language that actually supports "trivial" parallel mapping too much to ask?
Before I read the username thought this was an ed edd and eddy reference...
Do you happen to know why this doesn't work?: subprocess.Popen(['start','/B','/D','C:/Program Files (x86)/Mozilla Firefox','firefox.exe']) It throws a Windows file not found exception. This works in the command prompt: start /B /D "C:/Program Files (x86)/Mozilla Firefox" firefox.exe As does this in Python: os.system('start /B /D \"C:/Program Files (x86)/Mozilla Firefox\" firefox.exe') 
Edit: I HAVEN'T solved this problem. In windows command prompt, if you want to run a task in the background, you have to use this old clunky tool 'start': start /B command_string Now, if command_string contains spaces (as it often does on Windows), you have a problem, because start interprets the first quoted string in the arguments as the title of the window (even though it's running in the background! duh!). Hence you have to insert a title string in quotes: start "title" /B "command string" Now usually that's OK, just make it null: start "" /B "command string" But this is where Python caught me - there is NO way I can pass a string which is both null and quoted using subprocess, e.g. this won't work: subprocess.Popen('start','""','/B','command string') and nor will it work with '' in place of '""' or '\"\"'. And it's worse: if I specify a title like this: subprocess.Popen('start','title','/B','command string') it *still* won't work, because Python does not see any need to send a QUOTED string to the shell in this case, so it doesn't get quoted, and 'start' fails. I tried passing a title containing whitespace: subprocess.Popen('start','ti tle','/B','command string') and it still didn't work....
you can push a bignum in a cpu if is small enought to fit with native int size elsewhere you have to do carry book keeping
&gt; Aside: if you haven’t thought about it closely, this is actually nuts. We’re at the point where you can mix and mash different languages and compile them all down to the same substance. Programs with a mixture of Fortran and C/C++ have existed for decades.
I don't know why It reads better than the original stack overflow answer
Do you really need any interactivity on the website? If you are just hosting static content, why not upload HTML+CSS+JS files generated by your webapp to S3. S3 hosted websites are very, very, very inexpensive. There was an interested post here a few months ago about how the NPR news team built something similar: http://blog.apps.npr.org/2013/02/14/app-template-redux.html
http://sd.keepcalm-o-matic.co.uk/i/keep-calm-and-code-python-2.png
Good point - I hadn't carefully considered the timelines of language development. 
Firstly, it's `subprocess.Popen([...])`, not `subprocess.Popen(...)`. Secondly, why are you using `start`? Just run it in the background. You can use subprocess.Popen([...], stdout=subprocess.PIPE, stderr=subprocess.PIPE) to "detach" from the Python process if that's what you want.
&gt;Firstly, it's subprocess.Popen([...]), not subprocess.Popen(...). Yes, sorry, just stupid omission. &gt;You can use subprocess.Popen([...], stdout=subprocess.PIPE, stderr=subprocess.PIPE) &gt;to "detach" from the Python process if that's what you want. Thanks, I will try that. Edit: it worked, thanks again! But I still don't know why the original form doesn't work. If I do: print subprocess.list2cmdline(['start','xy z','/B','command string']) it gives the correct: start "xy z" /B "C:/Program Files (x86)/Mozilla Firefox/firefox.exe" and it should be this that's actually passed to the command line, right? But it can't be because that works, whereas the subprocess call with that list doesn't.
Did I miss something? The word 'metaclass' doesn't seem to appear in the article linked by OP. Is there a famous lack of metaclass support in eg PyPy or am I blind or something? 
The author seems to think a self-hosting compiler is completely unheard of magic
Or you can host it on heroku's free tier...
The dunderized init is, in my opinion, seriously holding back Python when it comes time to teach students how to create classes. There's an extra, unfortunate little step here where we say "Please ignore this magic, just trust us." It's like when we give students their first java program and say "Ignore the word static, and the public, and the void, and...".
(Author here.) You raise a good point. It wasn't meant to be a completely rigorous example, just a toy problem, but I actually like yours better. Hope it's okay that I included it!
How about the image from "import antigravity"? 
I love python too :) 
:)
The gmpy2 module w/ do some of these calculations for you.
The actual alternative to switch statements are dictionaries, I believe.
You might try [ipdb](https://pypi.python.org/pypi/ipdb);
As others have noted, Cascade is completely discouraged in Python. Current best practices specifically say *don't* do this, whether or not you agree with those best practices. The other thing I'd say is that I'm not sure about over-reliance on python properties. I used to use/abuse them all the time, but now I tend to favor functions for all calculations... (foo.bar() means that bar must be calculated, and foo.bar indicates it's "intrinsic".) Does anyone have an opinion on this? I'm not sure what the better way to write code is. I could see an argument that whether bar is calculated or not is an implementation detail, therefore distinguishing like I suggested is bad, but then the question becomes: do you then always do one or the other? If yes, which one? If not, what criteria would be applied to select which to use? 
That was a fantastic answer! Thanks so much!
 Apologies, I replied to the wrong thread.
For a better answer than "you don't" for "why you would use metaclasses", see http://eli.thegreenplace.net/2011/08/14/python-metaclasses-by-example/ Also, see the new enum module in Python 3.4 (PyPI backport: https://pypi.python.org/pypi/enum34/) 
nyararghhh but even (fractionally) worse datetime.datetime
*"Throwing the two concerns into the same syntax feature reduces expressiveness."* How?
Also inline Assembler in C Code.
The article does mention that immediately after that quote.
The first C compiler was likely written in assembly, B or an early version of C, possibly some other language that was popular at the time like algol or fortran.
Good call on pip and virtualenv
I realize it's a bot, but what is it doing? 
Not I! 
&gt; Reads_Small_Text_Bot
This is why it's a good beginner's language. It is very readable, forces good habits (indentation), is simple, and yet powerful.
I'm surprised this isn't mentioned, but explicit self. It's not that it's really really REALLY frustrating, but I'm always forgetting that in my code, and Python seems to be the only language that does that.
As /u/AnAge_OldProb pointed out, it's usually written using a different language. Then that compiler is used to compile the "bootstrapped" (i.e. the compiler written in the target language, such as GCC/C) source code to produce a "self-hosted" compiler. Generally, the bootstrapper (compiler written in another language) only supports a small subset of all of the languages intended features. Much like adding improvements, these are added in additional iterations to the target compiler. The first C compiler is thought to be written in [PDP-11 Assembly Code](http://plan9.bell-labs.com/who/dmr/chist.html). The first compiler was written by Grace Hopper, and was a set of call codes that allowed a system to look up the full instruction set on a tape, and was effectively written in machine code. [\[source\]](http://www.computinghistory.org.uk/det/5487/Grace%20Hopper%20completes%20the%20A-0%20Compiler) Edit: Oh, thanks for the gold guys :)
PyPy is not just a self-hosting compiler, it's a metacircular interpreter. A parallel in java is the maxine vm.
Thanks for sharing, but I'm not really sure what the point of this is. It doesn't really simplify anything and it essentially adds a shell function that aliases "rm -rf" without any validation on arguments except to ensure that they are not empty. There are a few other similar bugs around state/variable checking which I think you'd be better off avoiding by explicitly typing what you want vs using these functions. There's also virtualenv wrapper which is meant to handle/simplify "common virtualenv tasks."
The syntax to re-raise an Exception is ugly and I have to look it up every time I need it. I think it's been fixed in Python 3. http://nedbatchelder.com/blog/200711/rethrowing_exceptions_in_python.html
Microsoft's TASC, The AppleSoft Compiler, was a BASIC compiler written in BASIC and used to compile itself. This was sold as a commercial product in the 1980s!
For small to medium ints (-2^24 + 1 to 2^24 - 1 with a normal IEEE 32 bit float, if I'm not mistaken) you can use floats without problems, since they can be represented and used in calculations without error. Although I admit, it's in most cases still a bad idea.
It's referring to my comment, smart guy.
Hey, happens to the best of us. To be fair, I'm not sure I've ever (personally) had use for metaclasses, and I've done a fair bit of pythoning. I liked the link, you shouldn't have deleted it ;)
I agree with this, static content will be much easier to manage short term for both you and your friend. If you really want to go the dynamic content route, did you look at this post from ~24 hours ago? http://www.reddit.com/r/Python/comments/1mq0y5/serving_flask_with_nginx/
Backus and his team wrote the first thing that would called a compiler by today's standards (for Fortran in 1953-1957) written in a level higher than assembly and providing optimizations. What Hopper created earlier (in 1951-2) would be called a loader/linker in modern terms (for the A-0 language), though the word compiler was coined by her to describe it. [[1]](http://en.wikipedia.org/wiki/A-0_programming_language) [[2]](http://en.wikipedia.org/wiki/History_of_compiler_construction) Not trying to diminish Hopper's immense contributions to Computer Science (of which the first loader/linker is just one example), but just acknowledge Backus' team work.
Despite not knowing the French language, it just looks... graceful.
You can skip the list comprehensions and head straight to `map` and `reduce` for maximum abuse (and throw in a couple of `partial` and `compose` statements for good measure): import matplotlib.pyplot as plt, numpy as np from datetime import timedelta, datetime from operator import div from functools import partial from functional import compose NOW = datetime.now() DAYS = 3650 def get_days(day): delta = NOW - timedelta(days=day) unixtime = float(delta.toordinal()) calc = reduce(div,map(compose(float,partial(getattr,delta)), ('day','month','year'))) return (unixtime,calc) fig, ax = plt.subplots() partial(ax.plot_date,fmt='-')(*np.array(map(get_days,xrange(DAYS,-1,-1))).T) plt.show() 
Nice idea - If I had the time (and didn't have college classes) I would totally offer to make something like that for you.
Here's a [link](https://store.continuum.io/cshop/accelerate/). I hope the Continuum folks rename this project/bundle/whatever. We already have a GPU DSL from Microsoft called [Accelerator](http://research.microsoft.com/en-us/projects/accelerator/) and a Haskell GPU library called [Accelerate](http://hackage.haskell.org/package/accelerate). 
Why would you be installing arbitrary or--heavens!--user supplied packages in production? There's only one `flask`; there's only one `django`. If packages are signed, you should know exactly which package you're getting at development time.
I don't understand how using the functional programming tools in Python could be considered abuse of the language. I mean sure, the two examples above are a bit of an extreme case of overuse but in general I find functional style approaches in python to be quite readable.
I wouldn't consider the above abuse when used for a purpose but I've seen that discussion go both ways. There are some who will overuse FP in Python because they think it's always easier to read, I fell into this category myself a few times, and there are those who refuse to use it at all because they don't understand it or can't take the time to. I think it becomes abuse when you're not really gaining any benefit by using a particular style or syntax over another an alternative.
On Windows, I'd just pass the string as is: output = check_output(r'C:\plink.exe arg another_one "in quotes"') If you pass the command as a list of arguments then `subprocess` converts it to a string internally before passing it to `CreateProcess()` function anyway. There might be a command that you must pass as a string (not as a list) to avoid corrupting it due to `list2cmdline()` limitations.
to emulate `x.index('foo', -1)` if `x` is a list, you could use `next((i for i, item in enumerate(x) if item == 'foo'), -1)` to emulate `value = x.get(10, None)`, you could use: try: value = x[10] except IndexError: value = None` Note: both your ternary expressions might fail if `x` list is shared between multiple threads (the list might be changed between the checking of conditions and the retrieving of items)
I've always wonder how is PyPy "compiling" the code? Do they just capture the exact instructions the base implementation(Cython, Jython, etc) send to the host CPU? Do they have an x86, x86_64, arm, arm64, ppc, etc compiler?
So this is to simplify input data validation?
[Here is a good talk on pypy that overviews that and a lot of other things in a more digestible manner]( https://www.youtube.com/watch?v=l_HBRhcgeuQ)
Very cool. Could you tell us a bit more about how you draw the cube? I see you have a flatten() method in geometry.py. There's a lot going on there with operator overloading, but it doesn't look like you're using a projection matrix. How do those vectors work? 
The only argument for that is "the arguments for a method in python are what you act on, and what you act on is the arguments" Bullshit, this is the ONLY THING that acts like that.
It's not only beginner's language, it works great in professional environment too.
Thanks! I have to ask as a Windows user: what should be my stance on PyPy regarding the numerous Python extensions that include C code and are only available as binaries for CPython? I mean, do I really have a chance of using it with stuff like for example MeshPy (which wraps C libraries for Python)? As to why Windows: I work with engineering automation and user automation. It's all almost 100% Windows.
Thank you. Same question as the one I posted above: am I completely out of luck if I want to use both PyPy and C-containing packages on Windows?
If they use the CPython API, ya. But honestly unless performance is a problem I wouldn't worry about what interpreter you're using. Plus, the C extensions will run much faster than PyPy would run native Python
[it's complicated, but it can work]( https://bitbucket.org/pypy/compatibility/wiki/c-api)
Okay. My current ugly code is very slow because it uses a lot of high-order function calls. I guess it's better to stop worrying and start rewriting since Python is amazingly readable anyway.
I can see where you're coming from, good points! Perhaps you could get involved with the documentation writing process and gradually help make improvements? [This page](http://docs.python.org/3/about.html) lists docs@python.org as the mailing list for the documentation development process, and encourages you to send an email there if you'd like to get involved!
Sure, but so is the difference between scoping with indentation (Python-style) and scoping with brackets (C, Java, etc. style). Just a few characters can make a fairly large impact on how "nice" people perceive a language construct to be. As I said before, my preference for C++-style `for` loops is entirely subjective and entirely my own, and perhaps it's un-pythonic and doesn't have a place in Python, perhaps it does and we'll see it appear as a language feature in the future. All I know is that I prefer C++-style `for` loops and I assume you prefer Python-style `for` loops, and both are fine I suppose.
Interesting project man! I guess I'll try something similar some day and use your results as a reference.
Thanks, I'll try to formulate my ideas more clearly and concisely and then I'll try my luck with the docs guys!
I suppose a dictionary could be used for this, but then I want to argue that it's unnecessarily verbose to have to construct a dictionary first and then access that based on the makeshift-`switch`'s parameter. A dictionary is first and foremost a container, meant to store values accessible by keys. A `switch` statement is meant to make it easier for a programmer to write code that would otherwise need `if elif` chains (and as an added bonus, provides optimization opportunity). Internally `switch` statements are most always implemented as a sort of dictionary, but it's simply easier and less verbose to allow the language to abstract away the implementation of the `switch` and just provide a simple, clean language construct for the programmer to get across what he wants to do. If I'm reading code and I see that a dictionary is being constructed, I won't necessarily know right away what the exact purpose of said dictionary is going to be. I'll have to read on and see what sort of things are being stored in the dictionary, then I'll have to see that the dictionary is being accessed using a certain variable as a key, and that the value part is (probably) being executed as a function. *Then* I can conclude that the dictionary is being used a makeshift-`switch`. If I see '`switch`', I immediately know that the programmer has a parameter that evaluates to one of a certain set of values, and that he has a couple of different options he wants to have happen depending on the value. To me, that seems many times cleaner and less verbose than using a dictionary for this purpose.
http://stackoverflow.com/questions/493819/python-join-why-is-it-string-joinlist-instead-of-list-joinstring
That's the thing.
Yes, originally that was the main goal. Eventually I discovered that it is useful also for documentation purposes, because the contracts you write clarify the interface of the function. For example, consider the following function "``function``" with argument "``arg``" which has no documentation except the contract. By reading the contract (once you are familiar with the syntax) you can easily guess what this function will do: @contract(arg='seq[&gt;0](tuple(float,str))', returns='dict(str:float)') def function(arg): ... 
Many bloggers host their stuff on GitHub: http://pages.github.com/
This is really awesome! I'm tempted to use this idea for a project of my own. Could I use this as a reference? Would that be ok?
I really get what you're saying - don't confuse data and flow control. I think the trick is to re-write the code so that the dictionary makes sense; you don't want to be "hacking in the dictionary" so much as making an obvious use case of using a dictionary to express the situation. How that happens varies on a situational basis. I wish I had a good example we could parse and talk about...
Nice video; thanks for sharing the code on GitHub.
Use Heroku for deployment, the free tier will help you get by. Check out https://segment.io/ for analytics.
REALLY cool project. I'm duly impressed (and a tad jealous) that you did this after just an intro class!
That's exactly what I'm saying! Mixing of data management and flow control is fine if there's no better alternative, but `switch`es *are* a better alternative and they're well-defined and a common construct in most languages. Python simply doesn't support it. A bit of research shows that there have been two proposals for `switch` statements, most recently [PEP 3103](http://www.python.org/dev/peps/pep-3103/). It was apparently proposed by Guido van Rossum himself, but the rejection notice states that he held a simple poll at PyCon '07 and that this showed there was not sufficient support for it, so the proposal got rejected. Now, the poll itself was apparently held amongst (a subset of) the attendees to PyCon '07. Not only was this 6 years ago, the polling audience seems to be a fairly local and probably small set of Python developers. I'd say rejecting a proposal for something as common and (seemingly) useful as a `switch` statement based on *just* that is a bit... too simply done, perhaps? Also, [this page](http://docs.python.org/2/faq/design.html#why-isn-t-there-a-switch-or-case-statement-in-python) suggests an alternative to `switch`es: &gt; You can do this easily enough with a sequence of if... elif... elif... else. However in my opinion that's the worst argument for not having `switch` statements, simply because one of the reasons people tend to use `switch` statements is because it saves them quite a bit of typing compared to `if elif` chains.
You just need to fill out the fields when you submit the form, otherwise it's completely straightforward. Here's an example: import re import requests from bs4 import BeautifulSoup from collections import defaultdict def get_seats(flight, origin, destination, month, day, cabin): params = {'flightNumber': flight, 'departureMonth': month, 'departureDay': day, 'originAirport': origin, 'destinationAirport': destination, 'cabin': cabin} soup = BeautifulSoup(requests.get('https://www.aa.com/seatmap/viewSeatsSubmit.do', params=params).text) seats = defaultdict(list) for img in soup.select('table.seatMapLayout div[id^=seat] img'): seat = img.attrs['title'] status = re.search(r'seatMap/(.+)\.jpg', img.attrs['src']).group(1) seats[status].append(seat) return seats result = get_seats(33, 'JFK', 'LAX', 9, 27, 'Coach') for type, seatlist in result.items(): print('seats of type {}:\n{}\n\n'.format(type, ' '.join(seatlist))) This prints: seats of type unavailable: 17A 17B 17H 17J 19A 19B 19H 19J 22A 22B 22H 22J 23A 23B 23H 23J 24A 24B 24H 24J 25A 25B 25C 25E 25G 25H 25J 26A 26B 26C 26G 26H 26J 27A 27B 27C 27G 27H 27J 28A 28B 28E 28G 28H 28J 29A 29B 29E 29H 29J 30A 30B 30C 30E 30G 30H 30J 31A 31B 31C 31E 31G 31H 31J 32A 32B 32C 32E 32G 32H 32J 33A 33B 33C 33G 33H 33J 34A 34B 34C 34G 34H 34J 35A 35B 35C 35G 35H 35J 36A 36B 36C 36G 36H 36J 37A 37B 37C 37G 37H 37J 38A 38B 38C 38E 38G 38H 38J 39C 39E 39G 40C 40E 40G seats of type availableFree: 33E 34E 35E 36E 37E seats of type unavailableExit: 20A 20B 20H 20J seats of type availableP: 26E 27E 28C 29C 29G You can do whatever you want with the output at that point. 
Exactly. Very powerful.
not being smart just made a mistake, sorry
so this is what I've been wondering when I have nothing else to think about: Why is it the acronym "PVM" (and I don't mean the term "python virtual machine") never came to popularity the way "JVM" has become fixed tech term since day zero? Why is it people say "run this Java (language) program in JVM...." and "run this python (language) program in python interpreter...."
still don't get pypy sigh....
huh ?
(Author here.) I think you make a good point. My intention wasn't to make them seem complex or inaccessible--sorry if it came off that way. In fact, my goal was quite the opposite: to help readers understand how these things work and why they matter. But maybe I should tone down the language a bit. :)
There is a way to access [Blender via python code.](http://www.blender.org/documentation/blender_python_api_2_68_5/)
There can be multiple parent classes. (e.g. [mixins](https://en.wikipedia.org/wiki/Mixin), [composition](https://en.wikipedia.org/wiki/Composition_over_inheritance), [eigenclass model](https://en.wikipedia.org/wiki/Eigenclass_model#In_Python))
Have you looked at [PyGame](http://www.pygame.org/). Their website seems to be down atm, but it's a solid library.
Use mechanize. Much easier with a headless browser.
Here is a link to all of the projects done by students of that class as their final projects: http://kosbie.net/cmu/spring-13/15-112/ Mine on there is called "NewMoon Arcade Game". Hi Chris!
May I also suggest [Miguel Grinberg's flask tutorials](http://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-i-hello-world). Really fun to do, make yourself a nice web page, he even teaches how to deploy on heroku (which is free). I think instead of doing a py for beginners to start off, why not start off with flask, learn how py works, and work on something cool.
Flask is amazing. Also, check this [thread out](http://redd.it/1lgyfc), lots of useful advice.
Ah, weather mapping. Yeah, that's a real challenge to optimise.
That's something I wish more people understood. The language is a tool, programming is a craft. I learned to use woodworking tools, but I am no cabinetmaker. OP can apply for a job on my team any time he wants. :-) 
you might want to look at [tiled](http://www.mapeditor.org/), it's a 2d tile editor, it exports to an xml format that's not too bad to parse.
Been really enjoying your tutorials. Keep it up.
Hey drebin8, Review Board contributor here. Your best bet is to post this to the reviewboard-dev mailing list, [which you can get to by clicking here](http://groups.google.com/group/reviewboard-dev).
Or, if you really need speed and fanciness, pyglet
Pygame does exactly this To get started with pygame, I recommend skipping to chapter 5 of this tutorial; http://programarcadegames.com/
[click here if you don't know what the wadsworth constant is.](http://knowyourmeme.com/memes/the-wadsworth-constant) it started out as a console program but i was really determined to learn wxPython. i think it came out ok =) i'm still getting used to github, too. it's a really nice tool!
Is there a way to disable the type checks for production?
Yield is my favorite statement.
No stackoverflow... No matter how beautiful and unique a snowflake you are, someone else has had your problem and posted it on SO
Yes: contracts.disable_all() 
I like those objectives, I'll be following the project.
What is the overhead in disabled mode? Constant? Overhead in enabled mode? Thanks!
Your boilerplate app is structured quite nicely, and I hope you don't mind if I take some ideas from it. You make some valid arguments about cookiecutter-flask's structure. I made it with small apps in mind. That said, blueprints and app factories are a fantastic idea, so I've added the following to cookiecutter-flask: - Blueprints and app factory pattern - CSS and JS bundling + minification with Flask-Assets - Different config objects for development vs. production See it here: https://github.com/sloria/cookiecutter-flask Though sometimes, blueprints might be overkill for tiny apps. Therefore, I've kept the [simple branch](https://github.com/sloria/cookiecutter-flask/tree/simple) that retains the old structure. I believe the upcoming cookiecutter 0.7.0 release will allow branch selection.
But how does that affect at all the expressiveness of the language? ( http://en.wikipedia.org/wiki/Expressive_power ) How does the whitespace requirement affect how easy it is to express some idea?
Very good questions. The performance in disabled mode depends on whether ``contracts.disable_all()`` is called before or after the decorated function is loaded. If ``disable_all()`` is called *before*, then the decorator gets ignored and the overhead is 0. Example: contracts.disable_all() @contract(x='int,&gt;=0', returns='int,&gt;=1') def f(x): return x + 1 f(0) # no overhead If ``disable_all()`` is called *after*, then there is some overhead, because PyContracts will call the function as ``f(*args,**kwargs)``, which has some overhead. Example: @contract(x='int,&gt;=0', returns='int,&gt;=1') def f(x): return x + 1 contracts.disable_all() f(0) # some overhead I haven't done any rigorous benchmarking, but the overhead in enabled mode depends on two main things: 1. PyContracts calls ``inspect`` methods to associate arguments to arguments names. This takes a surprising amount of time and probably there is a smarter way to do it. 2. The time to check the contract for each argument. This depends on the complexity of the contract. Each contract is parsed only once and then represented as a syntactic tree. For example, the representation of 'int,&gt;=0' is: python -c "import contracts; print '%r' % contracts.parse('int,&gt;=0')" And([CheckType(int), CheckOrder(None,'&gt;=',SimpleRValue(0))]) Python being Python, there's some overhead for calling object methods in the contract tree. 
Wow, awesome man. I tried creating my own cookiecutter template and my labors were unfruitful, but now I won't have to!
this
&gt; Personally, I love decorators. Never used it. Can you show some use cases ? (as in what have I been missing)
For sprites - pygame http://inventwithpython.com/pygame/ To edit sprites - [tiled](http://www.mapeditor.org/) http://sparkondev.altervista.org/blog/class-loader-tiled-map-editor-python-pygame/
Maybe a stupid question, but will any of these distributions ever include R. I can get away with about 90% of my work using the scipy stack but every once in a while I just need to call R using rPy2. This is the only thing keeping my work from being reproducible/portable with Anaconda/EPD out of the box.
general rule: if you're trying to scrape heavy javascript sites, don't use simple HTTP clients. use something like spynner or selenium
pip is the standard package manager for python https://pypi.python.org/pypi/pip also, please use virtualenv so you don't screw up versions for other programs on the server. https://pypi.python.org/pypi/virtualenv
But with your method, aren't you repeating your subtraction with each call to `get_days`? This is a trivial case, but in the more general case this seems like a bad idea.
http://blip.tv/pycon-us-videos-2009-2010-2011/pycon-2010-scrape-the-web-strategies-for-programming-websites-that-don-t-expected-it-3378693
https://en.wikipedia.org/wiki/Python_(programming_language) https://en.wikipedia.org/wiki/Audio_engineering https://en.wikipedia.org/wiki/Musical_acoustics * [`Topic :: Multimedia :: Sound/Audio`](https://pypi.python.org/pypi?:action=browse&amp;c=338&amp;c=352) * https://wiki.python.org/moin/PythonInMusic Books: * http://www.worldcat.org/title/introduction-to-computing-programming-in-python-a-multimedia-approach/oclc/794621146 * http://www.crcpress.com/product/isbn/9781439867914 * http://musicforgeeksandnerds.com/ (http://kroger.github.io/pyknon/ looks really easy) http://www.class-central.com/search?q=music * https://www.coursera.org/course/chuck101 * http://chuck.cs.princeton.edu/ * https://pypi.python.org/pypi/audiolazy/0.05 https://en.wikipedia.org/wiki/Keytar
Hey, did you get any info on this? im also interested in using kivy with pypy and/or cffi
Awesome. Thank you. I shall work through that and if anything of interest happens, I shall post it here.
TBH, you are describing one of the most basic web site uses (web comic) while looking at highly-scalable cloud solutions and special-purpose HTTP servers. Fine if you are pitching a Web 2.0 startup, but perhaps not the best point of departure given the keywords of "low income" and "not super popular". Deployment (and maintenance) is extremely simplified if you could use a static approach. It would also be the perfect match given that you mention cost and low-traffic. You could either stick with the Flask-approach, and use something like [Frozen-Flask](http://pythonhosted.org/Frozen-Flask/) or [Flask-FlatPages](http://pythonhosted.org/Flask-FlatPages/) to turn it into a static site that you can sync/upload to any webhost. Or, as you already have your templates, etc. use a static site generator such as [Pelican](http://docs.getpelican.com/en/3.2/). While it is a bit more blog/text-oriented, a webcomic seems a perfect fit. Once it is set-up, you update it by adding a plain text file and/or comic-image to the source directory and regenerate the site. Finally, for hosting do take a look at [NearlyFreeSpeech](https://www.nearlyfreespeech.net/), which is an extremely reliable and no-nonsense host that uses the pay-what-you-use formula (storage, bandwith, etc.). I hosted some static blogs and low-traffic sites there for years, and monthly bills would be in dollarcents. 
Thanks very much. I'll take a proper look at that.
You could try the holy grail of computer music books by Curtis Roads. http://www.amazon.co.uk/Computer-Music-Tutorial-Curtis-Roads/dp/0262680823/ref=sr_1_1?ie=UTF8&amp;qid=1379850653&amp;sr=8-1&amp;keywords=computer+music+tutorial And then, there's also a complete book on audio programming as well http://www.amazon.co.uk/Audio-Programming-Book-Richard-Boulanger/dp/0262014467/ref=sr_1_1?ie=UTF8&amp;qid=1379850677&amp;sr=8-1&amp;keywords=audio+programming+books
Whether you end up using Python or not, that's a great idea for a band!
I can really recommend **pyo**. I tried several modules/libraries for Python, and this was the only one that I really liked. It is easy to get started with, it is really powerful, it has a good layout of how to do things that you can use from the start and it's easy to get results. https://code.google.com/p/pyo/
Off the topic but here is a fantastic intro to [Music Theory in Python](http://www.coderedux.com/music-theory/circle-of-fifths-part-one)
You might try [pudb](http://mathema.tician.de/software/pudb)
Check out [Melopy](http://jdan.github.io/Melopy)
There are several packages on PyPI to work with MIDI. That could be useful. (Do people still use MIDI? I don't know, I'm old...)
That looks interesting. Is closer to what I'm after. Actually creating the bleeps. Thanks.
Perfect, thank you. I had been adding more params (the list from using my browser's inspect element display), using the post method and sending numbers as strings.
Several. CLython, PyCuda, Anaconda, Numba. I haven't used any of them, so I'll leave it to others to compare the quality.
enthought canopy as well.
People totally use midi makes it easier to program a song or synth.
[Theano](http://deeplearning.net/software/theano/). The learning curve is a bit steep but if money is really no issue, I'm sure we can work out a consulting arrangement. 
NumbaPro is a GPU-accelerated version of Numba (which is an LLVM-enhanced version of NumPy). It's from Continuum (a company founded by some of NumPy's core developers), and comes included with a purchase of [Anaconda Accelerate](https://store.continuum.io/cshop/accelerate/).
NumbaPro lets you interface with multiple CPUs and GPUs
Not python, but you should check out [Common Lisp Music](https://ccrma.stanford.edu/software/clm/). The code is a mature and clear example of how to build mathematical models of musical instruments. ;;; FM VIOLIN ---------------------------------------------- ;;; ;;; a lot of this instrument is the result of nearly 30 years of use ;;; in 3 or 4 very different environments -- if I were to start all ;;; over, it would be simpler. See fmviolin.clm for some old examples. (definstrument fm-violin (startime dur frequency amplitude &amp;key (fm-index 1.0) (amp-env '(0 0 25 1 75 1 100 0)) (periodic-vibrato-rate 5.0) (random-vibrato-rate 16.0) (periodic-vibrato-amplitude 0.0025) (random-vibrato-amplitude 0.005) (noise-amount 0.0) (noise-freq 1000.0) (ind-noise-freq 10.0) (ind-noise-amount 0.0) (amp-noise-freq 20.0) (amp-noise-amount 0.0) (gliss-env '(0 0 100 0)) (glissando-amount 0.0) (fm1-env '(0 1 25 .4 75 .6 100 0)) (fm2-env '(0 1 25 .4 75 .6 100 0)) (fm3-env '(0 1 25 .4 75 .6 100 0)) (fm1-rat 1.0) (fm2-rat 3.0) (fm3-rat 4.0) (fm1-index nil) (fm2-index nil) (fm3-index nil) (base nil) (frobber nil) (reverb-amount 0.01) (index-type :violin) (degree nil) (distance 1.0) (degrees nil) (no-waveshaping nil) (denoise nil) (denoise-dur .1) (denoise-amp .005) &amp;allow-other-keys) ;(if (&gt; (abs amplitude) 1.0) (setf amplitude (clm-cerror ".1?" .1 #'numberp "amplitude = ~A?" amplitude))) (if (&lt;= (abs frequency) 1.0) (setf frequency (clm-cerror "440.0?" 440.0 #'numberp "frequency = ~A?" frequency))) (let* ((beg (floor (* startime *srate*))) (end (+ beg (floor (* dur *srate*)))) (frq-scl (hz-&gt;radians frequency)) (modulate (not (zerop fm-index))) (maxdev (* frq-scl fm-index)) (vln (not (eq index-type :cello))) (logfreq (log frequency)) (sqrtfreq (sqrt frequency)) (index1 (or fm1-index (min pi (* maxdev (/ (if vln 5.0 7.5) logfreq))))) (index2 (or fm2-index (min pi (* maxdev 3.0 (if vln (/ (- 8.5 logfreq) (+ 3.0 (* frequency .001))) (/ 15.0 sqrtfreq)))))) (index3 (or fm3-index (min pi (* maxdev (/ (if vln 4.0 8.0) sqrtfreq))))) 
&gt; Unless there's a good reason to write something like the above I'd normally avoid doing so. The point was to illustrate that the same code can be written in different ways. get_days is very trivial here and the if statement plus the function call will likely take more time than the subtraction itself. Depending on what you're doing this might be an ok thing to do under the right circumstances and in other cases might just be a premature optimization.
Hey Matt! By the way, for those who followed that link: Click the "Gallery" link on the left sidebar.
Absolutely =) I'd love to see your results if you follow through with this.
I should update the docstring for that function when I have time... I didn't document this as well as I wanted to. The flatten method takes a position vector and a camera object. The camera has a position, a direction that it's looking (.view), an angle of the camera's "cone" of vision (.field) (technically the tangent of the angle), a direction oriented with the y axis (.up), and a direction oriented with the x axis (.right). It also contains the width and height of the canvas that the point is being flattened to. To get the x coordinate, we first find the displacement from the camera to the point of interest. Projecting that onto the "view" vector, we get a "forward" vector, which points to the center of the screen. Then we need to find a point on the right edge of the screen. To do that, we can add "forward" to a vector in the direction of "right" with magnitude forward*camera.field, so that the ratio of the forward vector to the right vector is equal to the tangent of the angle. Then, we just need to find the distance from the center of the screen to the point of interest, divide that by the distance from the center of the screen to the edge of the screen, and multiply by half the width of the screen. The y coordinate is found in the same way. The cube itself is represented as a list of cubelets, each with a position vector in 3d space. To draw it, we just need to flatten each point of each face of each cubelet, and use the canvas.create_polygon method. 
From what I've read there, it could be used for solving FEA problems (which requires matrix operations), right? I'm excited to try it.
Thank you =) to be fair, I had programmed a little bit in my free time before I took the class.
You can store some data (like icons) in Qt's resource system, which embeds it in code, so you don't need to load it from the filesystem.
Yeah i just turned it on. It probably has a few people to send messages to but it will get to you.
thanks :)
Thanks for the book!
The inexperienced developer: "6.3x faster, let's use this!" The moderately experienced developer: "6.3x faster, that's promising, I wonder how it does with a real-world workload." The very experienced developer: &lt;doesn't click on article with "benchmark" in title&gt;
It's not compatible with some librabries written in C for optimization.
Yes it is. Pure C libraries are JIT compatible using CFFI. C-API CPython extensions are slow and will never be fully compatible due to overhead in compensating for the different memory model of PyPy and other architectural differences. 
&gt; It may be that a case can be made, but just because that's the way other people are doing it probably won't be enough to make it. It's not a matter of "other people are doing it", it's the fact that it is the way that modern OSes and processors support leveraging shared memory parallelism, which is very important for performance in many applications. &gt; as are processes on everything POSIX (aka anything not Windows). Not nearly as cheap as threads. &gt; The enterprise-level RDBMS PostgreSQL uses processes, not threads, yet in benchmarks rivals or surpasses Oracle and SQL Server. As they've put it... Guess what? "A solution for a particular, very specialized use case doesn't employ threads" is not an argument against the utility and greater suitability of threads in other use cases. This is yet another instance of the "ignorant web programmer thinks all of computing is just like web apps" phenomenon. &gt; It's not just Guido being crazy. It's the creators of amazing software like PostgreSQL and Python. Appeal to authority is not an argument. ATLAS, MKL, MAGMA, etc. are equally "amazing" software, in fact several required a hell of a lot more specialized engineering than has gone into the core CPython interpreter. 
I've never heard of CLython, do you have a link? Also, Anaconda is just Continuum's package manager. 
There's a lot of confusion in this thread about what various projects aim to do and how ready they are. There is no "GPU backend for NumPy" (much less for any of SciPy's functionality). There are a few ways to write CUDA code inside of Python and some GPU array-like objects which support subsets of NumPy's ndarray methods (but not the rest of NumPy, like *linalg*, *fft*, etc..) * [PyCUDA](http://documen.tician.de/pycuda/) and [PyOpenCL](http://mathema.tician.de/software/pyopencl) come closest. They eliminate a lot of the plumbing surrounding launching GPU kernels (simplified array creation &amp; memory transfer, no need for manual deallocation, etc...). For the most part, however, you're still stuck writing CUDA kernels manually, they just happen to be inside your Python file as a triple-quoted string. PyCUDA's [GPUarray](http://documen.tician.de/pycuda/array.html) *does* include some limited NumPy-like functionality, so if you're doing something very simple you might get away without writing any kernels yourself. * [NumbaPro](http://docs.continuum.io/numbapro/) includes a "cuda.jit" decorator which lets you write CUDA kernels using Python syntax. It's not actually much of an advance over what PyCUDA does (quoted kernel source), it's just your code now looks more Pythonic. It definitely doesn't, however, automatically run existing NumPy code on the GPU. * [Theano](http://deeplearning.net/software/theano/) let you construct symbolic expression trees and then compiles them to run on the GPU. It's not NumPy and only has equivalents for a small subset of NumPy's functionality. * [gnumpy](http://www.cs.toronto.edu/~tijmen/gnumpy.html) is a thinly documented wrapper around [CudaMat](https://code.google.com/p/cudamat/). The only supported element type is float32 and only a small subset of NumPy is implemented. 
You're always so angry... Why are you always so angry?
A slightly updated version http://www.youtube.com/watch?feature=player_embedded&amp;v=52wxGESwQSA
1. It doesn't work with numpy 2. It doesn't work with scipy 3. It doesn't work with wx 4. It's a toy until then
Is that a reference to God Bless America?
Send me your bank details and we'll discuss it ;)
In addition to all the other comments, it isn't always faster. Anecdotally I compare pypy to cpython on some basic graph algorithms I wrote up for learning and cpython came ahead. YMMV.
It's these random neckbeard comments that keep me on reddit.
I think he meant Clyther.
This is a good example of how powerful Scrapy is! (To anyone not familiar with Scrapy, [the most relevant code can be found here](https://github.com/yasoob/torrents-crawler/blob/master/piratebay/piratebay/spiders/piratebay_spider.py))
Feedback: Don't mix tabs and spaces! :) Really though, I'm serious.
I'd say also learn how to use [virtualenvwrapper](http://virtualenvwrapper.readthedocs.org/en/latest/), it's easy and definitely worth it!
There you go. Came here to say this: use Python to generate [MIDI](http://en.wikipedia.org/wiki/Midi) to drive a synth. [Many packages](https://pypi.python.org/pypi?%3Aaction=search&amp;term=MIDI&amp;submit=search) available.
Yeah, I was fighting with the autocorrect too early in the morning.
I'm assuming OP had intended to put each spider in their own file initially and simply hasn't gotten around to renaming it yet.
Awesome, thanks!
Anaonda didn't work for me on Windows 7 64 bit. It installed but several of the libraries did not work. Request for support went unanswered. Ended up doing a VM on windows so I could run ubuntu... where everything works.
Odd. I use the 32 bit version and it works fine FWIW.
In addition to what's been mentioned, there's [scikits-cuda](http://scikits.appspot.com/cuda). 
One big reason I converted back: Fat memory consumption. And unfortunately, it is not that obvious to debug which modules are the one leaking. CPython memory consumption is a lot more predictable and easier to trace.
Check out MMA for Python. It is sort of like Band in a Box and generates midi. Link - http://www.mellowood.ca/mma/ I used it to lay out an EP I did once.
nice. I do something similar with some construct 3 extensions with read/write &amp; seek... I'm still not sure if this is clever or terrible. (code doesn't work, so I haven't released it).
&gt; C-API CPython extensions are slow and will never be fully compatible due to overhead in compensating for the different memory model of PyPy and other architectural differences. Couldn't you sidestep that compatibility problem by compiling them to PyPy bytecode using a PyPy bytecode emitter for your favorite C compiler? Yeah, it's kind of insane, retarded, and the kind of stupid idea that I probably shouldn't have typed out (and I don't need you to tell me why, because in the morning, I'll shoot through this idea myself). I know. And it probably only makes sense only to my exhaustion-addled mind. (Get off the Internet, /u/thephotoman, you say retarded things when you're exhausted.)
This is exactly what I thought which I why I posted the question. As far as I could tell, there is not numpy/scipy GPU drop in yet.
None of these are numpy for the gpu
I use theano, it is not numpy for gpu.
NumbaPro is not a GPU backend for numpy. You have to rewrite all your numpy code.
That's where I am at.
Anything can be JITd, dynamically recompiled, etc. Soooo just depends on if u want to do the work. I told people **years** ago that they needed to stop using the CPython c-api and move to `ctypes`. The `c-api` compatibility issue is a red herring. 
And I missed it. Dammit.
A *toy* ? Really. High expectations much?
That's freakin' awesome. Nice job. 
I think that, before you search for such a thing, consider what a "drop-in" would mean. GPU programming is not just different hardware, it is a different paradigm.
This may be a stupid question, but would it not possible to have code run on PyPy with CPython fallback for stuff that doesn't work? You could probably manually do it and send code that works to PyPy and code that isn't supported to Python, but would there be a way to have like an enhanced PyPy executable that handles all that?
thanks, have you watched it? how useful is it?
My brain hurts from just thinking about a project that executes parts of its source on two different Python interpreters.
&gt; The c-api compatibility issue is a red herring. Anything that prevents adoption of a tool is not a red herring in a discussion about adopting said tool.
It's not a far-fetched thing to hope for. Most of NumPy's routines seem easily parallelizable. Sure, there's some trickiness in the GPU's strong preference for non-strided access and more severe memory constraints. However, I think the main problem is that reimplementing all that functionality for the GPU would take years and no one has been willing to invest the necessary time (or money). 
I'd love PyPy to work for my applications (who doesn't want 6x speedup?), but it doesn't, therefore I'm not even going to consider it. I'm not willing to work around it's current shortcomings. It's not about being negative, it's about it doesn't do what I want it to do and the extra work to get it to what I want is not worth the time spent doing it. There's a reason I use Python and not C++. My programs are fast enough and development time is valuable to me. So yes, until it can meet the minimum requirements of a program I'm interested in, which to be honest are not very high, yes it's a toy.
What about fingerprinting the public key by MD5 or SHA? I'm modeling this out of Open-SSH.
i have a question, in your attempt at using twisted did you put this in a looping call or a differed chain ? there are several other method to run multiple jobs at once (differedtothread and increase reactors thread count)?. im just curious if your issue was not being familiar / twisted not being the easiest thing in the world.
Oh? And what about networking? Web servers? Twisted and Tornado both run on PyPy, and do quite well. As for compatibility, the cpy-ext module has come a long way, and is quite compatible.
This library should look into using python function annotation syntax! http://www.python.org/dev/peps/pep-3107/
I quite like `rst` for documents but I could see why people would want this. If it helps adoption of docutils this may be a good thing. Does it work with, say sphinx? 
Now kiss.
I recommend pyo also, I've used it for a class and it's very easy to pickup and start doing music right away. It also has a good amount of different functions to generate and change the sound to your liking.
Right on main page (kivy.org) there's an example with Button.
98% of teenagers are still using Python 2. If you're part of the 2% who've switched, paste this into your signature.
This is also a good way of managing keys, if your uses actually will check the hash. This is essentially how the manual step of PGP key verification is done.
In most instances I find rst more of a pain to write than markdown, I always have to look up its syntax; I hope this effort succeeds and is even merged! I for one would love to not have to write READMEs in rst just so they'll show up nicely on PyPI.
[MultipartPostHandler](https://pypi.python.org/pypi/MultipartPostHandler/) is another option, adds a handler for urllib2 openers. import urllib2, MultipartPostHandler opener = urllib2.build_opener(MultipartPostHandler.MultipartPostHandler) response = opener.open("http://url.to.post.to/upload/", {"file": open("filename.ext").read()) You might need to build the request with the content-type multipart/form-data.
Probably not since markdown is not at all extensible whereas rst is designed from the start to be used in document processing tools where one might need to add in new features. Sphinx builds on top of rst to add lots of nice features which would not be possible with markdown.
I had similar problems using regex.
Python 3 support is missing still.
By not allowing be to express these two concerns independently. I cannot use indentation freely to encode structure for a human reader without affecting its other meaning, structure for the parser. While it is silly to demand that it should be possible to suggest the wrong structure on purpose, there are occasions where I would want more freedom in indenting my code. For example, when I am coding in an EDSL, I want to be able to indent the relevant code according to the structure of the DSL, not that of the host language (Python, that is). In a piece of code that outputs data in some hierarchical format (e.g. XML, YAML, etc.), I would like the possibility to indent according to the output structure instead of the (usually rather simple) code structure. But Python does not grant me this expressiveness, so I usually rethink my design and use a different approach altogether. Which is a pity, because sometimes, these are the most elegant solutions.
Haha, really nice, it remembers me school ten years ago. We also did a rubik's cube solver in python with a gui in tkinter and displaying it was slow as hell ;) By the way, well done, I'm really impressed by the webcam cube recognition, this is a killing feature ;)
Also, I really like how you explained the way you solved the cube. When I had to implement this stuff, it takes me a few time to do "second layer, third layer and last face", because it is simple algorithms. In the other, hand, doing the first face and first layer is something trivial for an human being, but really difficult to code. I ended by writing all cases on the code.
Interesting. I've always felt the other way around: I find markdown "syntax" hard to remember and constantly have to look it up. ReST on the other hand seems way more suitable to documentation (esp. when using Sphinx)
It does, however, meet other people's requirements. (Usually web/business application developers rather than the scientific lot.) Most libraries that are commonly used in these systems are PyPy-compatible by virtue of using ctypes rather than the CPython API for bindings. Therefore, it's not a toy, it just doesn't do what you want it to yet.
PyPy takes a while to 'warm up'. You will probably need to run a few thousand iterations before the difference becomes measurable.
Well, the article was promising from the start, but it was quite a letdown when it abruptly ended just before the good stuff with very general advice and a plug for a book. 
I would probably have added checks for the CONF file path and a default behavior before I started creating all sorts of exception handling, but that's just me.
Python code that has been compiled into bytecode for the Python interpreter.
Point 4. is needlessly condescending. 
Sorry but I have to ask - is this sarcasm? I think it is, but I don't know enough about PyPy to know if this would be true. 
It's already supported :-) @contract def my_function(a : 'int,&gt;0', b : 'list[N],N&gt;0') -&gt; 'list[N]': # Requires b to be a nonempty list, and the return # value to have the same length. ... 
What happened to chapter 7?
Before executing your python code, the python interpreter makes a compiler pass of all of the code, pre-compiling it into bytecode for (slightly) faster execution. If an up-to-date pyc file is present, python uses that file instead of spending time compiling again. Just think of them as cache. They can be safely deleted.
Matlab doesnt have good support for data structures or threading.
Good idea. I think we will do this but use CUDA.
File bugs please!
I agree with this. Money is SOME issue for us otherwise I would have us start writing our own lib to do this.
How hard is it to remember "raise"? Except when your re-raising from somewhere other than catch block. Do you really do that often? I've never had to.
&gt; How do you expect that to even work? Ignoring all the implementation issues. I'd expect it to work like Erlang.
No, it's not sarcasm. It's actually a known thing about its JIT compiler.
The book doesn't exist. There's a somewhat longer article. At this moment, I'm skeptical that good stuff *does* exist in this area: more specifically, there's no particular "solution", beyond the hard and detailed work of careful analysis of what should happen when users do all the things users are wont to do. For Python specifically, I consider it imperative to know how to write a top-level trap that behaves as intelligently as possible. My personal favorite is to receive e-mail with full traceback, hostname, and so on, for every otherwise-unresolved exception.
Now that I'm awake... 1. The c-api compatibility issue is not a red herring. It's a major roadblock in getting a number of major projects to run on PyPy. 2. My idea of compiling those c-api extensions to PyPy bytecode would lose the performance benefits of writing them in C in the first place. That said, for kinds of operations where PyPy beats even C, it still wouldn't necessarily be a bad idea--but one that probably isn't worth the work, as writing a compiler backend isn't trivial. Now, if PyPy performance routinely beat C, I could well imagine that the idea of a PyPy bytecode compiler backend wouldn't be a bad idea.
LBYL -- Look before you leap. But what happens when someone deletes the file between the check and the open? Also, that isn't enough to handle permissions issue -- you may be able to tell if the file exists without having read permission. EAFP -- Easier to ask forgiveness than permission. Try to open the file and handle the errors as they come. Since you'd have to do that anyway (handle errors that is), this is usually the method Python suggests. (Though to be honest, in practice I tend to use LBYL more often)
Join is an operation on string, using any iterable. It returns a string. Both facts logically make it a member of string.
var.len is spelled var.__len__() 
&gt; If you're doing CPU intensive numerical or scientific computation Then you are using numpy scipy or C extensions. And if you're doing "serious" computation you are using a cluster, threads don't spawn across cluster, multiple processes do. threads are only &gt; processes (for CPU bound) in only a few cases, such as GUIs.
There was a data mine collapse?
I can't get this thing to work, and I can't tell if it's because I'm using python 3.3 or 64bit windows...
I agree the `c-api` is an issue. No question. But that the CPython folks continue to not strongly suggest people target one of the other cleaner and more portable apis besides the CPython object model, is just plain dumb to the point that I think it is malicious. Projects *should* have started migrating to a portable api years ago, and the writing was clearly on the wall that the CPython api isn't the best way to do things, so IMO this isn't revisionist or hindsight. Same thing in JVM land, smart folks have migrated to [JNA](https://github.com/twall/jna). * http://cffi.readthedocs.org/en/latest/ * http://eli.thegreenplace.net/2013/03/09/python-ffi-with-ctypes-and-cffi/ The PyPy `cffi` is available on all platforms (sans Jython, but not precluded). So I think *supporting* the CPython api is a red herring, projects should move to `cffi`. 
I host a couple personal websites on digitalocean.com It's about $5 a month
As I see it this is the moral of the fable and, otherwise, very good advice: &gt; IT organizations need to recognize that “error-handling” demands its own analysis, requirements definition, testing, and maintenance.
Thanks. I have another question. Does the tuning take place while a routine is running or does it happen after a routine called and ended so the optimization benefit shows up the next time the routine is called? 
That's a great point, but consider that anyone that writes a lot of comments on github or reddit is intimately familiar with markdown already. I think it would be great as an alternative.
Well I can't completely idiot proof an application, just educate and advise.
Well I do write my fair share of comments on reddit and still have to constantly click on the "formatting help" link. One other thing: ReST is designed to be extensible (sphinx makes heavy use of this) while markdown has no notion of additional directives or the like. I'm not saying that it can't make sense for a quick readme or something like that, but for full-fledged documentation I don't see markdown as a valid competition to ReST.
Do you have code you could show that shows what you mean? From what I can tell, for the scenarios you mention, I think it's a good thing that you can't warp the indentation in spite of what the code's doing.
Python is a tool rather than a field. You should look for a field you like and then think about how Python will help you become better at it.
7 is the mark of the drop table, we don't talk about it in polite company.
Thanks for the advise.
The right question isn't "How Long". This applies to anything you could learn. The actual question you should be asking is "How Proficient do I need to be?" If I told you 10 months and you are a Python guru, what does that mean? What have you learned in 10 months? What if in 10 months, you only learned half of what you need to know? Time is too vague of a metric for what you are asking. What would be better is to make a list of the types of things that a "System Administrator", for instance, would do with Python and make sure you know how to do those things. Once you know how to do those things, you can say with more confidence that you want to apply for "System Admin" jobs. Again, this is true for any possible thing you could want to learn.
It does not yet, I still need to implement a "directives" expression that would make possible the power of rst (and therefore, by extension sphinx) possible with an (enhanced) markdown syntax.
And there's also nothing that says it needs to be your only tool.
Yeah, I believe it actually relies on an undocumented feature of `urllib2.Request`, which is that `Request` works just as well with a file-like object / stream as a string.
is it? http://pypy.org/download.html#pypy3-2-1-beta-1
I have been learning and using python for about a decade now and I am still learning! Good enough to get hired? I have seen people learn it on the job and i have seen people with years of experience but yet as if they do not know it. Maybe your question should be , "What is it that is minimum that I need to know in order to fake it in an interview." The gist of it, is it depends on how fast you can learn, and to what level do you require? Being able to replace all your scripts should be immediate, like right now!! given all the resources you have on the internet, would you do it as fast and off your head within a month? two months? that all depends on your ability. Learn the syntax by solving problems you would normally solve in another language and just use it. The amount of time you need to become good enough depends pretty much on your abilities and prior knowledge of programming and as you go along discover and learn things. Write websites using django or flask or whichever framework you happen to want to pick up. Write all your admin scripts in python. I have been at it for more than 10 years now and i am still learning. Learning the "python syntax", and "learning python really well" are worlds apart. I have a very good story of an employee that was my subordinate a few years ago. He was hired as a Java dev intern but the project got cancelled and HR asked if he could help my team until he gets assigned to a new team/project. I was in operations and I was working on the side on a poc command &amp; control system for our growing number of servers to remove the old ssh keys based system. I gave him 2 scripts, one a client that can issue a reboot and the xml-rpc server script. Within a week the guy had made it multi threaded, added all the dozens of operations that needs to be done on the server from the client, and he came back telling me "Hey there's this thing called Django that I can use to make a web interface for this"!!! So, thats pretty much how fast one can learn python given the right environment. Granted his code looked convoluted and more like java at first. 
Yes, I wrote this article. After I figured out how to use it with my system's CA store and I saw the alarming lack of usage in practice, I thought it wouldn't hurt to try to share the knowledge.
If you supplied html versions it would be much more mobile friendly
I think it happens after. The very first pass through the code is no better than CPython. I don't know the details though.
&gt; I for one would love to not have to write READMEs in rst just so they'll show up nicely on PyPI. Write them in Markdown and convert them to rst with `pandoc`: pandoc -f markdown -t rst -o README.rst README.md
*That Which Must Not Be Dereferenced.*
I meant the syntax to re-raise an exception while preserving the traceback. It looks something like: raise exc_info[1], None, exc_info[2] Where exc_info is sys.exc_info() and it's usually set by another thread. It explained in more detail in the article I linked.
If you have to choose amongst the most mature open source technologies to contribute to then in my opinion Parakeet and Theano are the furthest along toward achieving the goal of seamless GPU computing in Python. - [**Parakeet**](https://github.com/iskandr/parakeet) - [**Theano**](http://deeplearning.net/software/theano/)
His name is Bobby Tables, so you might as well use it, he's going to try and kill you either way.
PDFs are a display format. Editing them can be rather difficult. One hammer you could use is to find a program that converts a PDF to HTML/plain text, then add your links in, and generate a new PDF from that. But you're very likely to lose a lot of formatting and what not in the translation. The following Python tools may or may not be useful: * [pdfminer](https://pypi.python.org/pypi/pdfminer/) * [pyPdf](https://pypi.python.org/pypi/pyPdf) * [reportlab](https://pypi.python.org/pypi/reportlab/2.7) You may also want to check out anything `poppler` related, which is the predominant PDF library used on Linux. [pdftk](http://www.pdflabs.com/tools/pdftk-the-pdf-toolkit/) may also be useful. I'll say it again: from your description, the task you're embarking on is really not feasible. The best solution you'll ever hope to achieve is an ugly hack. What problem are you trying to solve?
I'm quite familiar with Theano (and highly recommend it), but haven't heard of Parakeet. Its interface looks very similar to [Numba](http://numba.pydata.org/), do you have any idea on the differences between the 2 (both depend on llvmpy).
So you are following me around EVERY POST NOW hm you stalker? Don't you have a job or wife to please? Oh you just sit around in your gonch eating Cheetos all day? Oh ok...
The guts of the program is &gt; com_port = 5 arduino = serial.Serial(com_port -1, 9600, timeout = 1) arduino.setRTS(True) arduino.setRTS(False) time.sleep(5) The tricky part is that the com ports are zero indexed...but your computers aren't. That and it seems to take an eternity to connect. I put 5 seconds to be safe. Typically 2 seconds is enough. If you're using python 3 you need to worry about the encoding of your strings. eg command here is a string: &gt; try: arduino.write(command.encode('utf-8')) except AttributeError: messagebox.showinfo('Error', 'Please connect you device') In python 2.7 arduino.write(command) would have been enough. 
It so happens cypherx is the author of Parakeet, he describes the design goals in this video: http://vimeo.com/73895275 .
I'd have to use examples in other languages, I guess. For example, in Haskell, there's the excellent Parsec library, which allows for writing PEG parsers in an EDSL that closely resembles EBNF; I can format my code to follow the EBNF structure rather than Haskell's syntax rules - Haskell, like Python, infers some structure from indentation too, but there is still a lot more freedom for the programmer. Another example, again from Haskell, is how I can structure pseudo-imperative expressions in different ways to signal the imperative structure even though the expression is technically purely functional. And of course, there's the classic example of using PHP as a template language; while I absolutely don't advocate this, it is common to see stuff like this: &lt;div&gt; &lt;?php foreach ($items as $item) { $text = sprintf("Hello, %s!", $item); ?&gt; &lt;div class="cell"&gt; &lt;?php echo htmlspecialchars($text); ?&gt; &lt;/div&gt; &lt;? } ?&gt; &lt;/div&gt; Both nesting in PHP *and* nesting in the surrounding HTML are reflected as indentation in the code; if you boil this down to *actual* indentation in the PHP, you get something like this: &lt;?php echo "&lt;div&gt;\n"; foreach ($items as $item) { $text = sprintf("Hello, %s!", $item); echo " &lt;div class=\"cell\"&gt;\n"; echo htmlspecialchars($text); echo " &lt;/div&gt;\n"; } echo "&lt;/div&gt;\n"; ...which is obviously completely malaligned and unreadable; if indentation were syntax in PHP, it simply wouldn't parse. Still, the *original* PHP is perfectly readable, and the indentation helps the reader follow both the output structure and the control flow at the same time. 
http://stackoverflow.com/questions/6344076/differences-between-distribute-distutils-setuptools-and-distutils2
https://github.com/lihaoyi/macropy
This line from the end of "Learn Python the Hard Way" states this nicely: &gt; People who can code in the world of technology companies are a dime a dozen and get no respect. People who can code in biology, medicine, government, sociology, physics, history, and mathematics are respected and can do amazing things to advance those disciplines. [Source](http://learnpythonthehardway.org/book/advice.html)
it's not always "after the routine gets called". It's either a certain number of loop iterations (1013 or so) or a certain amount of times a function gets called (in case it's loopless)
I must admit that as much as I like the ideas and had fun playing with MacroPy, I never used it in production code. I guess, one obstacle for me, has been to get my co-workers to get on board with me… Would love to see it become more used/distributed/standard.
Full of runtime hacks. Not sure expressionism is worth it.
Well thank you, here's a link for you: http://goblinorchestra.org
My experience: I was a web developer with strong PHP, Javascript and Actionscript skills (and zero exposure to Python) I decided I wanted to switch a few years ago and found a job where the company had recently transitioned from PHP to Django and they were willing to let me learn on the job (as their other developers had just done the same) I learnt Python and Django at the same time, while working mostly single-handed on a client website at my new employer, within the normal timeframe for the job. I consider myself a fairly good programmer but by no means an exceptional genius or anything like that. I wouldn't pigeonhole Python as "best suited for Sysadmins tasks and "big data" operations" at all. Personally I've found it greatly superior for web development and will never touch PHP again. I would disagree with the second of your points - all the Django devs I know have well-paid work coming out of their ears, though I concede that's here in London UK and other job markets may be different. Same for the the third point, that wasn't my experience. I had a lucky break for sure, also it was a few years ago and things may be different now or in other job markets. If you are currently a jr web developer I'd encourage you to give it a go. Just dive in like I did with Django, follow the tutorial in the docs - for anything you want to do look in the docs, it'll help you to do things the 'Django way', which pays off later - and try building a site with it. If you can show competence you're employable. And often there's an advantage in having less-common skills, the companies that need those skills *really* need you.
On the todo list for my project is figuring out whether it's worth replacing the AST utilities I wrote for it with MacroPy.
By the way, here's the corresponding command line argument and documentation for the HotSpot JVM (the default value is with `-server`): &gt; `-XX:CompileThreshold=10000` Number of method invocations/branches before compiling [`-client`: 1,500] 
I think perhaps it's the other way around - that developers in other languages prefer classes to functions. In Python, pure functions are easier to test and require less state. Given Python's emphasis on [duck typing](http://en.wikipedia.org/wiki/Duck_typing) there's often no need to create a class. When I first started writing Python I made a lot of classes - now I use the built-ins a lot more, and it results in a lot less code. Remember, there are never any bugs in code you don't write... :-D
of the ones you listed, only reportlab seems to be capable of what OP wants. poppler is afaik mostly a PDF rendering library. it can write annotations to PDF files, though, so maybe it can do more.
I'm interested in it, but I found that when I wanted to apply some of the ideas, I couldn't fit it into what I was doing at the time. I don't remember what I was trying to do, so sorry for being useless. I just want you to know it's interesting enough but maybe it needs some more time to become obvious what the stellar uses for it are.
Hmm, this seems to contradict [the last article that I saw here](http://www.reddit.com/tb/1mgdpu) about packaging, which suggests relative imports within your package, because otherwise: &gt; This decision results in two unsavory outcomes: &gt; 1. The sub-modules will only function properly if the package is installed in PYTHONPATH. &gt; 2. The sub-modules will only function properly if the package is named a_package. Thoughts?
I definitely prefer function than classes. A few more reasons why: * easier to pickle. * easier to convert to ctypes or FFI. * discourage in-memory states (sometimes they are useful).
Those are much more oriented toward C - not even C++ - and as such not really Python relevant...
I find your response at least a little ironic. What is explicit here, and what is implicit?
expressivity – expressionism is an art style
I tend to use classes for libraries and such. The thing is, most code I actually write is not libraries, but code that uses libraries. For this kind of code it's usually functions. 
I used/use Twython to collect ~3-6GB JSON data from Twitter on a daily basis. Last time I checked that was +1-2 million/tweets day on peak days, 1500 user objects an hour, and also retweeters graphs. When I built my system ~5-6 months ago I had some weird problems with the twitter library and decided it wasn't worth the time to invest further. I've also committed a few minor patches to Twython and felt the current maintainer is a fairly relaxed and open to input. One word of warning is that Twitter's API is probably the best I've dealt with in the social media sphere but it still has bad moments ( missing fields, values that are not real [ eg retweet count isn't "real"] ). For mass scale I've been looking into using Datasift but their prices for historics is something insane like 30-40K USD/year not counting the actual data collected. Another option is Gnip but last conversation I had with them, they don't have historics on user fields like followers/favorited/retweet counts and they kinda pissed me off when I first started talking to them ( I asked some slightly technical questions and their sales rep asked if I knew what JSON was, then there was a week long run around to get pricing information ). Edit: I've used twitter4J in some mockup storm topologies and while it works, it just feels "goofy" to me. It does make some things easier by systemizing cursor logic but all of the JVM's seem to suffer by partially hardcoding the API into themselves. Edit - Edit: Checked my notes, tweepy wasn't a good fit for me as I didn't like its managed response object vs twython that returned dict's which were easier to process in mass and serialize to bson/json.
This isn't Java - you can use functions when they make sense. There is no reason to stuff things into classes just to put then somewhere, we have packages for that.
Use classes when it makes sense to pass around behaviour and state together, use functions when the two are independent. Most applications have situations where both are applicable, and Python doesn't restrict you to only using classes or functions like some languages do, so you'll generally see a mixture out there.
Here's the thing for me- in other languages (thinking specifically of C++ and Java here), you essentially have to use classes to contain and move state around in a useful way. But with Python, you have all these tools at your disposal that semantically contain state, so it happens implicitly. I'm thinking first class and local functions, comprehensions, and generators, specifically. Between that and using `tuple`s (frequently `namedtuple`) to associate related data, I almost never feel the need to use classes in Python. As a trivial, frustratingly academic example, let's say I wanted to get some Fibonacci numbers. In Python, I'd do something like: def fibonacci(a=0, b=1): while True: yield a a, b = b, a+b ######### for fib in itertools.islice(fibonacci(), 10): #First 10 fibonacci numbers While in c++, I'd have to do: class FibonacciNumbers { private: int a; int b; public: FibonacciNumbers(int a=0, int b=1) :a(a) ,b(b) {} unsigned next() { int n = a; a = b; b = n+b return n; } }; Ignore the various language tricks- the tuple assignment in Python, the need for a temp in c++. Those aren't relevant. What relevant is that in languages that don't have these high level features, you have to explicitly write data structures (usually in the form of classes) to contain this useful state. **Warning shameless self plug below** So it turns out that with the magic of the boost libraries, it's possible to implement Python-style generators in c++, which I went ahead and did earlier this year: https://github.com/Lucretiel/Generator
Unless you're doing embedded work, you'll almost certainly be running your Python script on a multitasking operating system. The problem is not that you can't always look before you leap, the problem is that looking and leaping are not a single atomic operation - things can happen in other processes in-between looking and leaping. You *can't* check *immediately* beforehand, which leads to a race condition.
I hope not. That sort of thing is always fun to play with but it's never a good idea for programs that people need to use and maintain long-term.
*"Remember, there are never any bugs in code you don't write..."* But when there are, it's hell to debug!
Well then he can learn the useful skill of being able to read more than one programming language?
This is great news, excited to start using this.
Fantastic! I was one step away from buying their product, but since I don't use any the fancy libraries, this will do just fine. :)
I always wanted to try it's refactoring tools (which suck in other tools), maybe here's a chance to try and later buy it. Thanks!
We have modules already, if we want namespaces. A class is useful for encapsulating data along with functions. Don't make a class where it's unnecessary complexity.
Why? What part is confusing? Maybe we can help.
Pretty much.
This is awesome. Also, here's the handy link to the [comparison page](http://www.jetbrains.com/pycharm/features/editions_comparison_matrix.html) for more info on the differences.
brilliant!
There is a 30 day trial of the standard version.
9/10 would consider if it had flask integration instead of or along django and web2py. 
Does it support running on OpenJDK yet? I don't actually mind so much whether the IDE itself is open source or not, but I care about the ability to run it on an open platform.
Well, that's code that _someone_ wrote! :-D
I like your generator - but you should consider not using tab characters. By default, github displays them as eight-character indentations, which makes your code hard to read...
I have a Windows machine at work with Debian running on a VM. I mapped a folder from my Windows machine to my Debian VM. Couldn't you do something similar? Then, all your files could remain on your Windows machine, where your editors live, but when you debug them from your Linux VM, it will have access to the files and be able to run them.
It's not supported officially, but it does run just fine on it. 
I don't know. Sorry.
It depends! But function faster then object's methods. Every time when you call object's method python does type conversion when function does not. But then you need to store some states like session, open file descriptor and so forth and provide some new interfaces (API) it's better to use classes. &gt; As mentioned [Stop Writing Classes!](http://youtu.be/o9pEzgHorH0)
Woohoo!
is [this](https://github.com/JetBrains/intellij-plugins/tree/master/pycharm-flask) sufficient? I haven't tried it but it's been around for 2 versions now.
I run PyCharm, the paid version, on OpenJDK. Works perfectly, and I don't notice any slowdown at all.
No worries! It takes a bit of time to learn anything. I wouldn't start with "lets learn X" where X is a field (such as computer science). Rather, I would start with "Lets learn how to do Y" where Y is a specific task. Your user login script is a great example. You'll, hopefully, _always_ be hitting brick-walls in programming. That's where all the fun comes from, and that's how you learn (by eventually breaking through the wall). I wouldn't get too worried about semantics, or terminology, immediately. To start, I would worry about _creating_ something. It's the creating and the enjoyment that will motivate you to continue learning anything. Hey, if you don't mind me asking, what has you interested in programming in the first place? As for the original comment: &gt;I tend to use classes for libraries and such. The thing is, most code I actually write is not libraries, but code that uses libraries. For this kind of code it's usually functions. A Library is usually what comes after an import statement. Lots of times, you would do this "from flask import Flask" where flask is the module, and Flask is the class. He's saying most code he writes isn't actually a library (a tool, or a toolbox. Flask is a library that helps one make websites with Python) but rather something that uses libraries. In this case, a website you make would be the code that uses the library, which is Flask. ---- The original topic was discussing how to organize your Python code: should one use mostly Classes, Functions, or a mix?
Looks interesting, will give it a try. Im usually developing in vim with a few plugins.
Unfortunately the organization does not provide support. :(
do you use sublime 3? If so, did you manage to make the refactoring tools work?
good job, thx a lot. i'll try in the weekend i hope some features i was waiting for are implemented in 3.x version
Probably because I couldn't care less about web programming, that went completely over my head. There are uses for classes; they're just overused. Your code will be cleaner and more testable without them. Trust me I abuse classes. I just try not to. How's this for inheritance? There are multiple layers deep on 4 of those classes. &gt; OP2(BDF, FortranFile, Op2Codes, GeometryTables, ResultTable, F06Writer, OP2Deprecated): https://code.google.com/p/pynastran/source/browse/branches/v0.6/pyNastran/op2/op2.py Speaking of which: is there any way to specify class functions in a different file without requiring inheritance?
Check out the comparison page on Django support. http://www.jetbrains.com/pycharm/features/editions_comparison_matrix.html Even without direct support for Django it is still a pretty sweet Python editor.
The one thing I'd add, is you probably want to go ahead and buy the full IntelliJ IDEA rather than PyCharm, since while it's twice the $$$, you get the entire toolkit - Python, Ruby, PHP, Javascript, C/C++, Java, Scala, etc.
Same same.
I've used it for a while now and love it. Proud owner now of Pro.
Or just persevere using CE version for few months looking out for one of those awesome discounts. I bought full product for 50% of listing price that way. 
I use 2, sorry. Good luck!
I have a license for both actually. I originally got PyCharm and then when they were having a 50% sale on all of their products, I got the IntelliJ and started loading up the Python plugins and such. I find that PyCharm is much easier to work with for Python projects. Just as PHP Storm is easier to work with for PHP/Html projects.
I've been waiting too for the same reason.......can't.....wait.......any......longer...
Check out [Vagrant](http://www.vagrantup.com/), I believe pycharm hooks into it natively. Edit: Here is the PyCharm docs for Vagrant integration: http://www.jetbrains.com/pycharm/quickstart/configuring_for_vm.html
I also use Vim extensively, but working on a larger project at my full time job, I felt a little restricted, so I tried PyCharm. I find that it is excellent for working in larger projects. The IdeaVim plugin is great, though not perfect. I still use Vim constantly, but generally for one-off scripts and the like.
I also would love non-pdf versions...
I find MacroPy pretty interesting, but it feels a bit like hammering a square peg in a round hole. Python isn't made for macros and shoehorning extra features into it without changing the syntax just feels awkward. Take your example of pattern matching, for instance: @case class Nil(): pass @case class Cons(x, xs): pass def reduce(op, my_list): with switch(my_list): if Cons(x, Nil()): return x elif Cons(x, xs): return op(x, reduce(op, xs)) I mean, sure, it works, but since you can't really extend the syntax, you end up subverting the usual semantics of class, with and if. The use of with makes sense, but still, you end up declaring variables where the superclasses of a class would normally be, and in the conditions of conditional statements. It's... contrived. You'd rather have something like this: adt Nil(): pass adt Cons(x, xs): pass def reduce(op, my_list): switch my_list: Cons(x, Nil()): return x Cons(x, xs): return op(x, reduce(op, xs)) A more free-form syntax would lend itself better to macros. For instance, if the expression `f expr: stmt` produced the AST node `Colon(f, expr, stmt)`, which was equivalent to, say, `eval(f(quote(expr), quote(stmt)))`, adding new features would be a lot more natural. Python's syntax, on the other hand, really doesn't give you enough latitude. 
Plus, with the right patches to Freetype and OpenJDK you can make the fonts not look like ass in linux!
I can't remember the last time I wrote a class.....
Cannot find IdeaVim in the plugins list for this. Is there something extra I need to be doing? The repository has lots of plugins, even IDEAmacs, but typing "vim" in the search bar, as well as manually searching has left me with nothing.
I plan on using it in conjunction with e.g. llvmpy to make a simple stab at a semi-jit style thing I also want to look at whether I can use it to generate cython, but I feel there's probably more difficulties there
The main motivation is to enable the use of PyCharm in education scenarios (think Coursera) without any licensing barries, and to get more people exposed to JetBrains products in general. We don't really count on Python developers contributing much code to an IDE written in Java. Note that the feature set of the "very limited" Community Edition of PyCharm roughly matches that of Wing IDE, which is a fully commercial product.
Sorry for that, we haven't fully updated the plugin repository for compatibility with the new Community Edition product yet. Will be fixed very soon (tomorrow I hope). For now, you can download IdeaVIM manually from http://plugins.jetbrains.com/ and then use "Install from disk".
Thanks!
I find that confusing, as they are the same code. PyCharm just has limited plug-ins allowed. 
Have an upvote for mentioning Vagrant, and I would give another one, if I could, for the PyCharm integration thing. It might be the killer feature I needed to decide to try it.
The project configuration UI is different in PyCharm (Open Directory action, different support for multi-module project, different UI for interpreter configuration etc.)
I bought PyCharm about three weeks ago. My timing is ass. 
I am just learning (taking a course) and one of the hardest things for me has been to create functions. I think procedurally and my code works. I will get it, I know. Just been a little bit of a struggle.
Why? It's a free upgrade. Or do you only use the features of the now free version?
Great library with a really good api.
Thank you for the response. I see how my question was negatively worded, but that was unintentional. You have been good friends to Open Source in previous licenses as well. Although you target the educational space, I see no limitations to commercial use of the free/OSS version. Is that correct? Keep up the good work.
Word of warning on vagrant for window's hosts, the shared directory has default 777 perms and symlinks are not possible ( might not be possible with linux host either ). That can confuse the hell out of a few people if they're not watching for it. Also with windows vagrant users, if you use putty and pageant, find the .vagrant hidden directory and using the insecure ssh key can make logging in fairly trivial. 
Oh god so there's a fix? Can you elaborate?
Do you often write Python code? If so, what type of code do you usually write?
Primarily. 
Have you tried any of the guides in the sidebar? I can't imagine writing Python without using functions.
I'm personally sick and tired of people pushing their own clever ideas on how to structure a Python project as if it's the absolute truth. "Do this, don't do that, this is better because blah blah blah." I say do whatever works for your project and if your way doesn't work for someone else, deal with it then and there. Having to change things in the future doesn't mean the project is doomed. Don't waste your time reading the abundance of blogger opinions on every single tiny matter. Write your code, worry about the big picture later.
CUDA is probably the way to go if you don't mind only using nvidia hardware. What field do you work in? Is it applied science?
http://youtrack.jetbrains.com/issue/IDEA-57233#comment=27-472038 Check out that thread. It's what I used and it works beautifully.
Nope. Perhaps you can work on creating graphical names like they have in the title credits, where they substitute element table items for letters in people's names...
Speaking of licensing, the comparison page hasn't been updated. http://www.jetbrains.com/pycharm/features/editions_comparison_matrix.html What are the (if any) usage limitations on this edition?
Why is this a reason not to use tabs? Using them greatly increases the speed with which you can move around your code.
[**+Guido van Rossum**](https://plus.google.com/115212051037621986145) [_2013-09-18T20:32:32.876Z_](https://plus.google.com/115212051037621986145/posts/R8jEVrobbRj) &gt; &gt;Do **not** send me email like this: &gt; &gt;""" &gt; &gt;Hi Guido, &gt; &gt;I came across your resume in a Google web search. You seem to have an awesome expertise on Python. I would be glad if you can reply my email and let me know your interest and availability. &gt; &gt;……………………….. &gt; &gt;Our client immediately needs a PYTHON Developers at its location in *****, NJ. Below are the job details. If interested and available, kindly fwd me your updated resume along with the expected rate and the availability. &gt; &gt;[...] &gt; &gt;""" &gt; &gt;I might reply like this: &gt; &gt;""" &gt; &gt;I'm not interested and not available. &gt; &gt;"""
If you have taken symbolic logic and a handful of quantitative classes Philosophy and programming is a good match. Data_science = [(Epistemology + Logic)*x for x in data] and don't let the engineers tell you otherwise.
You might want a look at: http://www.cl.cam.ac.uk/projects/raspberrypi/sonicpi/index.html Which is talked about in: http://www.raspberrypi.org/archives/4906 
You could do a methamphetamine production optimization problem with a triple objective functions: * Minimize the cost of the supplies * Minimize the time to cook the meth * Maximize the availability of the supplies That could be with a big table where you can enter the values for the different supplies cost, availability and cooking time. Send me the results once you are done. Thanks.
This is one of the most balanced articles I've read on the subject: http://me.veekun.com/blog/2013/03/03/the-controller-pattern-is-awful-and-other-oo-heresy/ Essentially, stop writing STUPID classes. 
This article considers both Diederich's and Ronacher's views: http://me.veekun.com/blog/2013/03/03/the-controller-pattern-is-awful-and-other-oo-heresy/
In their feature matrix they tout some kind of flask support for the pro version...
Hey, as of 14 days ago, it seems pypy/android were not playing well together. lost link, but it seems like there is probably not *loads* of work to do (don't quote me on that) Also, kivy is currently based on pygame with which last I checked (sometime ago) was not ok with pypy - that may have changed though.
How much does the java community help build the ide?
You want to be using the subprocess module instead of os.system, passing shell=True http://docs.python.org/2/library/subprocess.html 
ok, ill check it out. Never used it before so this should be fun... oh and thanks. EDIT: I can't seem to get it to work... any helpful clues? (or code)
I guess now the question "I'm learning Python, which IDE should I use?" has an obvious answer. 
&gt; How many years experience of python do you have? &gt; All of them Hahahahaha.
My upgrade subscription for the Pro version just ran out 2 weeks ago :( I also use PHPStorm and ReSharper. They really do make some fantastic products.
Thank you very much guys.
if you're a vim user and need to do spaces (e.g. PEP8), you should learn about softtabstop. It allows you to emit spaces but delete them like they're tabs.
maybe he just misstated something a bit more profound. how about this: "the only guaranteed bug free code is no code." 
Ooooh, *that's* what he meant. 
I prefer to us lubuntu for performance reasons - pretty much all the advantages of ubuntu's infrastructure but a much lighter experience ideal for development.
Make a reddit bot that automatically scans Breaking Bad pictures and highlights deep insights and connections into Vince's writing and the directing! /s
If you're not using requests for your HTTP client needs in your Python apps, you're missing out. It's really been a game changer as far as what to expect out of client libraries. I know it's changed how I view the libraries I write.
Or one that hides Pink Teddy Bears in all of them.
Please don't get me started on Python 3 migration mismanagement! * 2to3 tool is non exhaustive still needs manual edits * core python team recommends people NOT do single file python 2 and 3 compat? wtf! see below Why didn't Python 3 change the file extension to py3 and create a dual VM that could run both codebases, something like Aaron recommended ? The biggest hurdle is a clean way of marshalling how strings/bytes are handled in each. Python 3.3 just added back **u"...."** For reference: * http://asmeurersympy.wordpress.com/2013/08/09/using-python-3-as-my-default-python/ * and the followup http://asmeurersympy.wordpress.com/2013/08/22/python-3-single-codebase-vs-2to3/ * http://lucumr.pocoo.org/2010/1/7/pros-and-cons-about-python-3/ * http://www.aaronsw.com/weblog/python3 
Have you tried sublime with plugins? Curious how you'd compare it. The matrix made me hesitant, seems like free version would be behind sublime in factors?
Hooray! Thanks!
I tried to download the Linux version but it gives me the Windows version instead. Am I supposed to run this in Wine? Why is a Java application being shipped in a platform-specific format rather than Java's default write-once-run-anywhere ? 
I'm sure I'm preaching to the choir here, but Ruby suffers from a serious identity crisis. I learned Python in the space of a few weeks (the important bits, anyways) and the knowledge is sufficient and serves me to this day. It's rare that I run into a "well that was unexpected" moment in Python. Not Ruby. There are always 3 or 4 "official" ways to do something. Some feel like Perl, some like C, some like C++/Java/C#/whatever, and some feel downright functional, but NONE of them reference the other implementations or advertise their strengths or weaknesses. I feel like any time I pick a built-in method, I'm gambling on whether or not I'm going to get the desired behavior (with no strings attached). Speaking of strings, don't even get me started on their implementation of strings. I'm absolutely appalled that the "string" construct in their language is really just a mutable byte array. I'd love to know their excuse for doing this (performance is the obvious answer, but this is supposed to be a high-level scripting language -- come on) These days I'm still finding new ruby quirks that I never knew about that seem to directly contradict things I read before (as an example, go try to find out what the scoping rules are for `instance_eval`). To me, Ruby is the shining example of what happens when a popular project / platform has no strong leadership. Devs just code whatever "makes sense" in their context, and then they mash it together into one final set of libraries and standards. Their own community seems to have a pretty big blind spot in regards to seeing these problems. They'll happily tell you that "well of COURSE you're having problems, you're using the Net::HTTP library -- no one uses that! Silly goose." As if vestigial code in a standard library was the most natural thing in the world. In the same breath they'll tell you why programming Ruby is the single greatest pleasure a programmer can possibly know. Their religious fanaticism is lost on me.
I can't live without Resharper at work for C#. I'm pretty excited to start using PyCharm for my personal projects. It looks like it has a lot of the same mind-bending predictive stuff that makes Resharper so brilliant. Yay!
I just downloaded it. I doubt I'll use it much at this point (unless there's a sudden need to start doing code refactoring, &amp;c) because I'm a vim guy, but I'm playing around with it. Great choice if you need an IDE and don't want to deal with Eclipse.
That depends on your programming style, I would say. Not being a big fan of OOP myself, I prefer functions.
Something that blocks references to Breaking Bad in Twitter thus avoiding spoilers.
Too late. Only one episode left.
You can download openstack and explore how the framework is developed using Django. You can also try developing some sample websites. 
&gt; you're using the Net::HTTP library -- no one uses that! To be fair, isn't Python's standard urllib2 basically deprecated in favour of the requests library now?
SQLAlchemy ORM doesn't require real primary keys to be defined. You can give an ORM mapping any arbitrary set of columns that comprise a candidate key: http://docs.sqlalchemy.org/en/rel_0_8/faq.html#how-do-i-map-a-table-that-has-no-primary-key Also, the "some kind of candidate key" requirement only applies to the ORM, as it needs to be able to target a row for refresh/update/delete (a table that truly has dupe rows would be impossible to manipulate on a per-row basis). You can always manipulate table data using Core, and the performance / cycle issues of this script might be resolved if it went to a "copy data via Core" approach. If you delay the creation of foreign key constraints until after the data is moved, order of operations won't matter.
You may want to check this out: http://andrewbrookins.com/tech/one-year-later-an-epic-review-of-pycharm-2-7-from-a-vim-users-perspective/
It's open-source and licensed under the Apache 2 license. The freedom 0 is there.
"Freedom 0: The freedom to run the program for any purpose."
We do get contributions regularly, but the bulk of the work is done by JetBrains developers.
Just do the official Django tutorial. It walks you through building a rudimentary app.
And you forget about urllib and httplib (I think it's called).
I am a Pythonista but Ruby on Rails isn't the only "power app" Ruby has going for itself. Puppet and Chef in the world of Dev Ops has pretty big adoption. And I haven't see any Python alternatives seriously challenge them yet.
I'm not a recovering rubyist, just a normal one. I regularly program in python, ruby, and shell. They're different tools for different purposes. [I wrote a little about this before](http://changedmy.name/2010/08/03/differing-usage-of-python-and-ruby.html), but I tend to use ruby for small little text-munging scripts because of its perl roots, and python for library-gluing, as well as anything larger. Creating a rubygem is surprisingly much easier than publishing a python module, given the current mess we're in. Having regexes as an integral part of the language syntax is really nice. So is not having crippled lambdas. But really, it often comes down to this: python is maintainable, but ruby is *fun*.
Check out salt (saltstack.org). The developers are cool guys, very responsive.
I used to program for windows on a linux machine through virtual box. I used to debug using the Pydev remote debugger. It isnt too hard to setup and I'm sure you will find lots of tutorials online that explain how to do it.
Same code, but configured quite differently.
I wrote my altcointip bot using PyCharm and loved it :) +/u/altcointip $leet
^(__[Verified]__:) ^/u/im14 ^-&gt; ^/u/yole, __^0.0101779 ^Bitcoin(s)__&amp;nbsp;^__($1.337)__ ^[[help]](http://www.reddit.com/r/ALTcointip/wiki/index) ^**[[tipping_stats]](http://www.reddit.com/r/ALTcointip/wiki/stats)**
I use Sublime Text (and even write some things for it) and use both IntelliJ IDEA and PyCharm. These products fill different (complimentary) roles. While you can push Sublime Text to become more IDE-ish, it will most likely never offer the same kind of scope/depth that PyCharm offers with refactorings and such. But hey, who knows, maybe someone will prove me wrong, look at what YouCompleteMe accomplished for vim.
Man, I love you guys.
if i understand what you want correctly, you can use PTVS to do this: https://pytools.codeplex.com/wikipage?title=Remote%20Debugging%20for%20Windows%2c%20Linux%20and%20OS%20X 
Maybe he can get a job after he solves silly interview questions.
Thanks for the tip will try it out!
Will look into it now! Thanks for the tip
Sorry for the dumb question, i read through the openstack website and cant really figure out what it is?
They do that for pretty much every job title they're trying to fill, no matter how miniscule your experience is. They usually just look for one or more keywords, and then as soon as they find a match, they fire off a template email about a senior level position for whatever the keyword was.
Interesting, I have been using Pynt in all of my recent projects, but Invoke seems to be a little bit better, i'll start testing it out I guess.
I keep having similar experiences regarding a popular BPM Platform which i helped design a while back. It's funny at first, and then quickly turns into a real pain in the neck. What's sad is that you recognize the form letters, and the fact that the recruiters never even bother to read the letters they write, let alone your profile properly.
though note that PyCharm (professional) *does* include the JavaScript/CoffeeScript support.
are the jobs they have to offer really bad?
If you have a network drive on your VM mapped to your Windows machine, then the screen refresh of the VM shouldn't be an issue, since all your editing will be on Windows. And if you are debugging a Django app, you can do 'manage.py runserver 0.0.0.0:8000' and also view your site on Windows. You could probably just minimize the VM while you work. Or have I missed something? Surprised you are seeing any kind of latency with your VM. I've only ever used VirtualBox to run a linux distro in a linux distro, and it seems native to me. 
Yep, all they're after is firing off as many emails as possible in the hopes that *someone* bites so they can get paid. They don't actually give a shit about the person's qualifications nor how good of a match they are. It's pathetic, and annoying. I sometimes refer recruiters to each other when they say that there's referral bonus offers/rewards, etc. I like to think that they get rather pissed off, because they usually never bother me again after that.
There should be a support group for recovering Chefs too! (what an awful experience that was...) 
it's actually a philosophy... TIMTOWTDI: There Is More Than One Way To Do It, coming from Perl. Basically the exact opposite of the Zen of Python It's a bad idea IMHO and why I much prefer Python
Thanks for the link. I try not to let the fact that PyCharm is written in Java bug me too much -- at the end of the day, it's still my favourite IDE -- but the font situation has occasionally been a thorn in my side for sure. I do wish that the solution wasn't of the form `/^with the right paches.*linux$/`, but one step at a time, I guess. It looks like there are PPAs which is nice.
My point is also somewhat that such type checking is considered unpythonic. Next fix will be Decimal. And why not support strings, lists, and so on. Anything that can be multiplied by a number, basically. 
WHAT OTHER REASONS MIGHT THERE BE?
I'd use a raspberry pi to create a methlab automation controller.
So, what happened between three months ago and now, with the release of PyCharm Community Edition?
Not much. The functionality of the paid version of PyCharm will be available as a plugin for the paid version of IntelliJ, and the free version will be available as a plugin for the Community Edition.
Thanks for the reply!
Without using the boost libraries, I feel that this is a closer idiomatic C++ translation of the python: struct Fibonacci { uint32_t a, b; Fibonacci(uint32_t a=0, uint32_t b=1) : a(a), b(b) {} uint32_t operator()(){ auto res = a+b; a = b; b = res; return res; } }; //example use of the functor std::generate_n(std::ostream_iterator&lt;uint32_t&gt;(std::cout, "\n"), 10, Fibonacci());
Check out [RealDjango](http://realdjango.com/). This is meant to get a Django project started quickly. (I am the author).
Openstack is built on top of Django. Its a real time example of Django framework
Unsurprising considering that that reply was suggested by [Yaroslav](https://plus.google.com/111278163811394657096/posts) (a g+ commentator) because it was what DHH said when a recruiter approached him for a Ruby-on-Rails job. Except, obviously, with Ruby replaced for Python.
Openstack is a realtime example of a framework built on top of Django. You can browse through the source code if you like https://github.com/openstack/horizon
Man, if only there were some way to find things out about people on the Internet. If you could invent such a thing, you'd have a lot of money. I'm not even talking 6 or 7 figures; I'm talking 100 figures!
Indeed, it's among the best items in [Tales From The Crypt of Tech Recruiter Cluelessness](http://h30565.www3.hp.com/t5/Feature-Articles/Tales-From-The-Crypt-of-Tech-Recruiter-Cluelessness/ba-p/735).
nice one. i enjoy that way of understanding code, too (rewriting in python) what i do when bitmaps are in play: world = """ ███ ███ ██ █ ██ █ ███ █ █ █ ███████ """ world = [[px == '█' for px in line] for line in world.strip().split()] utilize the powers of unicode and list comprehensions! (in this case you need bitmasks, though, so it’s different)
You can do something similar splitting on newlines and replacing spaces/blocks with 0's and 1's, but the current definition works reasonably well as well. It's definitely a lot more readable than integers :)
Yeah, it's a shame his name isn't more unique. That way you could spend 5 seconds doing a Google search, rather than expecting other people to answer silly questions for you...
have the saltstack folks got their crypto shit together yet, though?
Don't worry. I'm renewing my subscription next week, so there will be a sale soon after that.
Never mind, I am dumb. Great IDE!
It looks like Horizon is Django, the other components on their github look like just plain Python. Am I missing something?
I am building a backup system on top of Django. Django provides the web interface and database abstraction, while I use custom admin commands to do the actual work, listening to a messaging queue that recieves messages from the web interface or crons.
I'm (slowly) developing an inlining macro which uses Macropy. The only hard part is the actual process of safely inlining things.
I think you are correct. I've dug through the nova code quite a lot and seen no django (although several re-implementations of stuff found in django)
I checked out the source to intellij and did a build (awesome btw, builds in 4 minutes on my laptop). I couldn't find the src for base python plugin. Is that available or is it binary only? 
It's not so much that it's bad jobs, but that the recruiters very frequently aren't actually looking at your resume (or have no idea what any of it means) to see if there's any reason you might actually be interested or qualified for the job. They may be very good jobs for "someone", but no good at all for you. If it's 1 every couple of weeks it's no big deal, but many people, myself included, get many of these every day. If you really are looking for work it's that much more frustrating, because then you really do have to look at every one of them just in case it's legitimate or the recruiter got lucky and it's a good fit despite their lack of effort.
Note to self: Put some of my half-assed-proof-of-concept projects on github.
Love the image on the title slide!
Thanks for this! Really silly question. Is there a way to open the editor, console window, etc. in a new window? I'm coming to Python from MATLAB and that's how they do it. Second question. Is there a way to open an iPython shell in PyCharm? Again, thanks so much!
Rather unpythonic. It makes you instantiate a class just to call `.scan()`. What's more, `scan()` takes exactly the same parameters as `__init__()` which only proves that this should really be a module-level function.
Sounds like a nightmare for someone "very new to programming".
Feel free to ask anything at /r/learnpython :) Between that and http://stackoverflow.com/questions/tagged/python there's a lot of help.
When programming in C, use tabs, and set your tab stop to 8 spaces. When programming in Python, use soft tabs and 4 spaces. In Ruby, soft tabs and 2 spaces. These are the accepted rules of style, follow them.
&gt; python 2.6 a few months ago. Hopefully you upgraded to 2.7. Python 2.7 was released on July 3rd, 2010.
Doesn't matter if I do. Many Linux distros are still on 2.6, like CentOS. 
It's not even a question. I've been learning it for a large project (spent one week on Learn Python the Hard Way, and now into my second week of the project) and I've never enjoyed a development environment so much. I absolutely love how it tells me when I'm violating PEP8, or when things make no sense, or when I have code that will never be executed... all sorts of beginner things that, in other worlds, I would have been running/fixing/running/fixing over and over. Love it! Thanks JetBrains team!
&gt;We intend to provide source-only security fixes for the Python 2.6 series until October 2013. Better upgrade soon.
Lack of whitespace makes this hard to read. Gigantic functions makes this hard to read. You have global statements at the top level, which is meaningless. global is to force a name defined inside a function to be module-global rather than local. I would pull out the big multiline strings into variables rather than keeping them inline, to make things more readable and avoid all those backslashes. I assume this is Python 3, based on print(), so it's okay to use input(). But there should be a comment at the top indicating that it's Python 3.
I think I'd prefer jewtoob
Here's a fun guide to writing choose your own adventure games. It happens to be for Lisp, but you could borrow ideas for doing it in Python. http://www.lisperati.com/casting.html
Hey man, you're ruining the circlejerk!
&gt; Creating a rubygem is surprisingly much easier than publishing a python module, given the current mess we're in. Yeeeeep. A lot of things are nicer about Python, but the toolchain is not one of them. I'll be happy if Python ever developers something on par with Rubygems and bundler (and no, pip and virtualenv are *not* on par with those tools), but it's taken *years* just for Python to even begin working out a consistent packaging mechanism, so I'm not holding my breath.
Good call on pdftk. It's useful in all sorts of situations. I think worst case, you could kludge something together by decompressing the PDF stream with pdftk and editing the source. I've done that before for one-off edits. If you want to decompress the stream inside Python, PyPDF2 can do that.
One of the longest while statements I've seen. 
Really nice find! (If that's your post, else, really nice find of the writer.)
Yeah, it makes it pretty easy to install the updates. The main reason the fonts suck so bad is because JetBrains uses Swing for it's UI components and not SWT. I doubt that that will change anytime soon.
Seriously. Within a week of me putting something up I got a headhunter email. Its a shitty, half finished tool that has a very minimal audience.
If that's the case you are in the wrong subreddit. Try a gaming or fiction subreddit instead of r/python. Gameplay is irrelevant to the programming language used. (In this case, Python)
It will be made available in the coming days.
Well, it is obvious enough that securing a complete python interpreter with some rules isn't going to work. More interesting is: how well do pypy's sandbox and such environments survive scrutiny?
Create a simple blog
Pretty amusing to read as the actual implementation of HTTP makes it impossible to provide an API which is truly RESTful anyway which makes this discussion kinda obsolete. HTTP 1.1 aims to address some of the issues HTTP has when it comes to being RESTful but it still leaves out some parts. See http://wwatson.me/2011/10/24/rest-and-http-part-6/ for reference.
I could use wordpress for that lol
What does the Int('x') and Int('a') do? My Python doesn't know Int.
This reply made a lot more sense thanks lol
The guy who wrote it on Google+ said so, as well. It's in the link.
/u/not_perfect_yet Per your edit: ignorance is often feigned to troll people, and the last thing you want to do is feed a troll. So responses that are sarcastic and amusing to the larger readership are common; it keeps from feeding the troll, but still clues you in toward the correct answer if you're not trolling. Not to mention that programmer communities try to encourage discovering answers for yourself using the tools available to you, rather than relying on others so much. Don't take it so personally ;-) 
What at all does that have to do with it?
I agree. Rails was an awesome project that wrapped up a whole slew of best practices. It also happened to use ruby. And so a legion of programmers like me needed to learn ruby in order to use rails.
I'm not super familiar with security stuff, but (if this was running on linux) wouldn't running the Python process in a chroot jail fix some of the problems listed above? What kind of things could an attacker still do if the process was chroot jailed? It doesn't seem like they could start a shell (because shell executable is out of chroot jail) or do anything except for make syscalls (which I realize allow one to do many things). Anyone want to point out some malicious behavior still possible if the Python process was chroot jailed?
It's weird. A few of my friends have also complained about getting recruiter emails after putting up empty projects on Github. I never seem to get them. XD
Maybe your empty projects are not good enough? :)
Hehe. I actually have only 1 empty project. Maybe his empty projects are better than my finished ones! :(
You could do something like that, yes. The author briefly mentions that. A Docker instance or isolated VM would work fine, too. The problem is that often, the application you're running is going to need access to other files, so you need to ensure that even if someone had full read/write privileges in the context of that user, that an attacker wouldn't be able to see anything sensitive or do anything very malicious.
They made a backwards-compatible change a few months ago to address those concerns, I think. Personally, I'm pulling for a change to nanomsg (very unlikely) and something like [nacl](http://nacl.cr.yp.to) or [cryptobox](http://cryptobox.tyrfingr.is/) for the crypto. On the other hand, a lot of the connectivity issues seem to have been licked.
What's the question? Are you saying you can't figure out how to run your particular class, or are you complaining about it lacking a graphical interface? A lot of Python software is written to use a command-line interface; it's worth getting comfortable with using the command line.
I don't care about a GUI, I need a way to run the robot from my application. spider = CustomSpider(url) spider.start() # does not work #or lets try this crawler = CrawlerProcess(settings) crawler.install() #this blows up, this method does not exist crawler.configure() #this also blows up, the method does not exist crawler.crawl(spider)#this also blows up, the method does not exist I want to run the spider manually, I don't want to dick around with the command line. Any idea how to do that? This is not a one off script, it's part of a much larger application, kicking off a command line script is something I would rather avoid (for usability sake). 
Good point, although I think the important word you hit is "deprecated", which means the devs actually acknowledge that it's no longer needed / wanted and will go away in the future. I've seen many instances of the python devs doing this, and they're ridiculously thorough when documenting it. The docs practically scream at you, "don't use this". By the time the library or function is removed, you've had plenty of warning (an example that comes to mind are the myriad of `Popen` classes and functions that all got merged into `subprocess`) Not Ruby though. Unwanted code and bad design choices just stay around because (as another user pointed out) "There Is More Than One Way To Do It" (even if it's terribly slow and broken).
I actually write Chef cookbooks all day every day lately. I have absolutely nothing nice to say about Chef. The DSL is very nice if you stick within its confines, but the instant you try to do anything even a little bit outside of the normal flow, you find yourself in some seriously deep shit. The big adoption you're seeing is largely just hype. My company is trying to deploy enterprise-grade software on a cloud-like platform, and the headaches we've endured from Chef alone are the stuff of legend. To give you a sense of scale, I'm talking about nearly 130 custom cookbooks (so far). I know what I'm talking about :)
Eh, recruiters don't usually get paid by interview. They get paid by hire, so they do care whether or not someone's a good match. 
Salt doesn't seem to have any marketshare. Ansible does, but it's not using Python for the scripts.
This is quite the coincidence, I recently brought down Python Tutor (with permission to try, of course)! I'm not going to say my method until it's patched, though.
So for your purposes you've got a Linux VM w/ PyCharm that works just fine aside from refresh rate issues. The simple solution is to fire up an x server on your PC and redirect the window to your PC. I don't know how PyCharm will take this, it may take some messing around but do the following: Download Cygwin and set it up, install all of the packages for ease of use. Boom you have a unix environment running on windows. We could go through the trouble trying to get PyCharm running in this environment, but how about we just leave it running in your VM? Start XWin Server, which should appear in Cygwin-X under your start menu. In the xterm window that opens up: # xhost + # ssh myuser@mylinuxhost linuxhost # export DISPLAY=192.168.1.23:0 &lt; replace the IP with your PC's IP address linuxhost # xclock This will launch xclock. Try launching various x programs, at this point PyCharm should work as well - though I've never used it so I cant tell you where the binaries live. Since the network latency is minimal you are basically running your linux binaries on your PCs X server instead of the VMs. The refresh rate should now be native.
I'm still new to Python myself, but `raw_input()` creates a string, and you want an integer for doing subtraction. Try putting your `raw_input()` statements for `var`, `var2`, and `var3` inside `int()` statements. (I'm typing this on my phone; I hope the code formatting works).
It would seem you think you are dealing with integers when really you are dealing with strings Here is a so about covering to an int or float http://stackoverflow.com/questions/379906/parse-string-to-float-or-int Edit: stupid phone
I'm not sure about that. It definitely doesn't have tons of mindshare. I think it was at one point the most active and/or had the highest number of contributors of any python project on github.
Your problem is that you are trying to subtract strings. You need to convert them to a numerical type (either float or int) by using int() or float(). Also, in the future you may find it easier for yourself and others to follow your code if you use more descriptive variable names.
Ok, I did this and ended up with this: http://bpaste.net/show/fcQfSrUOgQLrqbrn6XAm/ And it works almost entirely through, except when I tested it with it supposed to go off the next minute, it claimed that there were 29 minutes left on the timer. What did I do wrong?
A bit late to the party, but registration is now open! See you in April! :D
You don't factor in the current second: if you kick off the 1 min timer at 12:29:59, it will go off at 12:30:00
sys.exit does that too, can't check now but it is probably the same function
&lt;insert dongle joke here&gt;
Sorry, that's what I meant, that they try to get you in and embellish you as much as possible so you get an offer and get hired
I mentioned this in the the /r/programming thread, but using Zope's https://pypi.python.org/pypi/RestrictedPython will help here, as long as you whitelist what attribute are to be accessible. 
You're right, I thought sys.exit only took an integer for the status code. 
1.2 months eCommerce
Cool will look into it thanks
Once the code is published, it will appear in the 'python' directory under root.
Goodpoint, thanks! 
So I am sure Camilstore is not production ready, but is it functional enough I can use it day to day? Are you using it tomt0m?
So you want to make the script executable ? if __name__ == "__main__": #do whatever you normally do through the prompt If thats not what you were searching for you should refine your question.
[Run Scrapy from a script](http://doc.scrapy.org/en/latest/topics/practices.html#run-scrapy-from-a-script) look at for launching crawler by API. [Pomp](https://bitbucket.org/estin/pomp/) This project another web crawler framework
Yeah, it was me :) thanks
Sort your domain out guys... us.pycon.org, and its in Montréal?
It lacks some features, like advanced search, but I feel like my data are safe in Camlistore. You should try it. I'm using it day to day to backup/snapshot some directories (incremental backups) and I also like the sharing capabitility (but it's not totally ready yet). I'm also planning to make it works with [bakthat](http://docs.bakthat.io/), but it's a work in progress.
Worth noting here that you've got to be very careful using RestrictedPython as it's difficult (at best!) to write a policy that blocks everything you expect. Basically, as soon as you start including any of your own objects it starts to go wrong.
Thanks for the info. As an aside, if you change the name to bakthathangup.io, I will definitely sign up for the novelty.
It's the first PyCon outside of the states. There is actually a PyCon Canada (http://pycon.ca/), which came on the scene 2 years ago and has been a great success! I'm not sure of the exact reasoning for hosting PyCon in Montreal, but who cares? It's a great city and will be in the downtown core. Should be a good time
&gt; I'm not sure of the exact reasoning for hosting PyCon in Montreal, but who cares? I'm betting it'll be great, I just think it's a slightly misleading URL. I mean, it's not really PyCon US any more... it's just PyCon!
I broke a system this summer that parsed a AST and used a combination of whitelisting and blacklisting on the nodes. (Seatle Repy if you were curious) Trying to do in process sandboxing of Python is just a bad idea in general. At the very least you should be using Pypy or Nacl or something as an outer sandbox.
C++ already has first class functions and tuples in the standard library. They're just a pain to use.
Can someone who went to this last year share their experience? Also, is the conference conducted in Spanish?
Yup - and they would be unidiomatic for this usecase. That's why I used functors and &lt;algorithm&gt;, it's a translation rather than a transliteration.