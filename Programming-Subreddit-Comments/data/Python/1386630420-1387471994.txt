* It's more convinient. See here for some discussions (don't stop at the 'accepted answer'): http://stackoverflow.com/questions/4209641/absolute-vs-explicit-relative-import-of-python-module * It is really cool :) * Their model is deep &amp; complex, and dicts would be really annoying to use. Going with models made it more readable. For example, if you want to see what fields are present in Surge, you can just go to the class and see them, see which ones are optional etc. It also wasn't much work - I wrote a script to generate most of them from their respective jsons. Thank you :D Been trying to put it on HN too, but after nobody upvoted it :(
Can this interact with Python 3 function annotations? For instance, if I have a function declared like this: def foo() -&gt; int: pass Will I get an error that I'm not returning an `int`?
Ah, I just realized that this HAS been submitted in the past but my search included the trailing slash mark in the link so it didn't pick up any hits. Sorry about that... although the submissions are more than a year old.
Here's a toy example: https://gist.github.com/mw44118/7884829
It's new to me.
So unittest tests are in a class and nose tests are not? The real issue I had with nose is that, while it was fine for dumping test results into the console, it wasn't very hard to get python's unittest class to format the tests into XML to be read by my build tool, where as I couldn't ever solve that problem with nose. It didn't ever want to return it's results in a marked-uped format.
Apologies on my phone so brief. Nose 1 has xml output support via an xunit plugin, I believe this is baked into n2 now as its partially an overlay of unitTest2 (conceivably everything the stdlib unit test provides, n2 also provides.) Nose with coverage also is extremely agressive in finding all re levant tested and untested code which can show gaps or make risk assessments easier.
cool, good to know for future reference.
This was a temporary error caused by a upgrading the Anaconda windows binaries. It should be fixed now. 
The documentation definitely needs work. We are definitely working on it. How do you define "properly". 
I'd stick to the idiomatic approach of having &lt;packagename&gt; at the top level of the project distro - the "." is the default for sys.path and it's compatible with how most other projects are. I put it in ./lib both because I was too recently from the perl community at that point and also I saw ./lib illustrated in the [distutils doc](http://docs.python.org/2/distutils/setupscript.html#listing-whole-packages), which I misconstrued to mean this was common. 
A curated set of packages certainly adds value, but conda *does* solve more issues than that as it is a true package manager for Windows which includes native environments. The .whl format is an approximation to conda packages and it will be useful for many of the same things especially once Metadata 2.0 is realized, but it's *not* the same thing. Pre-built binaries are always easier and pre-built .whl packages are easier than source installs. But, Conda currently already has indexable meta-data on the server (so dependencies can be determined before downloading), "features" which can handle SSE/SSE2/SSE3 issues in the binaries, and clean support for *any* system library. 
Compound with statements are also awesome for coordinating the use of multiple external resources. I've got a small script that coordinates commits to a subversion repository, certain filesystem operations and a database (don't ask). With the with statement, I can rollback actions taken on all of them if there's a failure in the execution of actions on any one resource. Came as a bit of a revelation to me when I implemented it for the first time a few days ago...just thought I'd gush here. 
 import social @postAboutDecorators(repeat=often) class Reddit (social.NewsPuker): def __init__ (self): ... There it was the whole time, right there on line three! Son of a gun.
Erring on the side of niceness, I'd prefer to point the developer over to the [Hitchhiker's Guide to Python](http://docs.python-guide.org/en/latest/) for an opinionated guide on good structure and organization. It was really tempting to refactor this, to point the developer towards some cleaner more maintainable Python (which would lend itself to better pull requests). Then I realized I was going to be hacking away on something that I wouldn't actually be using myself.
like a graphics card driver?
&gt; &gt; The default import mechanism requires packages to live in eponymous directories. &gt; There's no such logic in the default import mechanism - [...] There's no "mechanism" here. so which is it? the readme just says that, for `import foo` to succeed, any(os.path.exists(os.path.join(d, X)) for d in sys.path) must succeed for some `X` from ("foo.py", "foo/\_\_init\_\_.py").
Yes, I think so 
Yes. [PEP 3107: Function Annotations](http://www.python.org/dev/peps/pep-3107/) But you'll need a decorator to do anything fancy with it.
&gt; That's like people who put the . at the end of the line in Java rather than beginning. placing an operator at the beginning of a line is like placing an operator at the end of a line? :) in fact, foo( a , b , c ) mirrors foo .a .b .c 
I came here to ask the same question. Why can't people start their documentation with a very simple abstract? I will never understand that.
@/u/nykevin http://andreacensi.github.io/contracts/ &gt; PyContracts is a Python package that allows to declare constraints on function parameters and return values. It supports a basic type system, variables binding, arithmetic constraints, and has several specialized contracts (notably for Numpy arrays).
you could refactor that as follows: with qtd.window() as win, qtd.paneLayout(): qtd.button() Obviously it doesn't make much difference in this case (and in others it could make code messier) but it's nice to know there's a different syntax :)
Yeah, that's what I meant by a class inner to `__init__()`, sure, classes defined in functions are used, whether or not it's methods or standalone functions. I think OP was asking about immediately nested classes, like class A: class B: pass
Very good to see that you are picking up Python as a programming language and made a very nice little tool. I am aware that this is not the subreddit critique my code, but allow me to give you one pointer that might help you move towards your next level. Your use of globals is not pythonesq. In general you are changing the globals in your functions. It is good that you define the functions that have a specific task, but now the functions change the state of the globals. In many cases (your case in particularly) you should use the 'return' statement to yield results from your function calls. 
I agree with you. It's like there are some "python-haters" and they can't criticize anything from the language. So they go always to the static typing. Said that... I do think that sometimes it's cool to have a Static Typed language. Most of the time is when you have bad coders or legacy code. If the code is bad written and the names are not really clear, then you're screwed. But in those cases I'd rather use Scala than Python.
I would add that you does not want use a bare `except:` but something like `except KeyError:` 
Thanks for the suggestion, I will keep that in mind.
Note that you can enable all loggers by getting the root logger and setting its level to 'DEBUG'.
Lovely article (:P), and I especially appreciate the part that discusses testing needed decoupled code given a case that relies on external resources. The problem I think is that unit testing sometimes lures people (ie developers I may or may not work with--- and myself sometimes) into a false sense that could be summed up "we have unit tests, so if they all pass obviously we're in the clear!" without considering issues such as coverage and whether your tests actually "test" something. One of the more hilarious examples I ran into recently was like so: We had a function "is_empty" on a class that would return true or false. When someone wrote the test, they used ``` self.assertTrue(foo.is_empty) ``` Which would have been fine, had is_empty been a property on the class. Since is_empty is a function on the class and not "None" this test case would return true every time. So when a bug cropped up and we looked at "well why are the tests passing?" we facepalmed hard enough for the universe to implode. I think one of the biggest takeaways is that unit testing is hard, but you should still do your best to get it right.
Nice example and good advice.
Agreed: unit testing is hard, but you should try to get it right. For many novice programmers, "unit testing" is a term thrown around often but not one they really understand, let alone know how to start doing it. I'm glad you found the article "not terrible" :)
That'll show reddit.
No, that will show Wikipedia.
I'm not sure why this would make it clearer. Also, it gives me an invalid syntax error.
It's perhaps clearer when you don't need the `as` statement, eg: a = open("/tmp/a", "w") b = open("/tmp/b") with a, b: a.write(b.read()) (I just ran that fine with no syntax error, Python 2.7.5)
&gt; This is why you should first write the test so that it fails, and only after you make sure the test fails, you write the fix. Yep. This is like TDD 101.
As a novice dev, this is good stuff to read
Go read Code Complete by Steve McConnell for an introduction to standard industry practices in large software teams. Design Patterns by Gamma et al is great for learning how to really use OO design and should be compulsory reading for anyone building large systems. These and many other worthy books can be found on stackoverflow threads covering programming books.
Almost makes me want to take the train to TO (from Montreal) so I can take the train back!
This is great, I've been wanting this for ages. I'm sure I'm being dumb, but I can't for the life of me work out how to make this work with existing code. Please tell me I'm missing something?
In a pinch, if retro-fitting tests you can purposefully write a test "backwards" so it fails and then fix the test. Not as good as writing a test and then the code it tests but it catches some errors. That said, self.assertFalse(foo.is_empty) would have failed and then started working when changed back to: self.assertTrue(foo.is_empty) However, self.assertEqual(foo.is_empty, True) would never have passed... &gt;&gt;&gt; foo = lambda x: x &gt;&gt;&gt; foo &lt;function &lt;lambda&gt; at 0x7f70e5d01e60&gt; &gt;&gt;&gt; assert(foo == True) Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; AssertionError &gt;&gt;&gt; assert(foo) &gt;&gt;&gt; I try to get in the habit to use assertTrue/assertFalse on expressions and assertEqual/assertNotEqual on values that I expect to be strictly True or False.
It certainly is *possible*, but it's not clear whether it's sensible. Calling into R from Python won't automatically make it simple - you'll still need something like a for loop to iterate over the rows in matrix B. If you're more familiar with Python than with R, you might find it easier to write in Python. Or if the data is produced by some existing Python code, you can skip a save/load step by calling the R analysis from Python code. But otherwise, from what you've said, it's probably best to work out how to do it in R.
have a look at Kent Beck's "Extreme programming explained" book
Thanks so much for your reply. I'm hoping to get a chance to try to learn more about LabRAD during winter break. I will get in touch with you after I look through the information you gave me. 
I saw the original project on Hack a Day this morning but thanks for these links, I wasn't familiar with either project.
Thank you very much, those were great :)
You can do a quick test in the REPL: # A class that doesn't work: &gt;&gt;&gt; with Blah(): pass ... Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; AttributeError: __exit__ &gt;&gt;&gt; # A class that works: &gt;&gt;&gt; with open('/dev/null'): pass ... &gt;&gt;&gt;
I can't say much for pygame because I haven't used it, but if you want scale up, cython may be a good choice to optimize certain functions in your code. With cython, you can achieve performance close to C. 
That protects you in the first place, but one of the problems with relying too heavily on automated test suites is that you have no guarantee that your test is still passing for the right reasons later.
True. Which is why it's always good to have system-level tests in addition to unit tests.
For me, it avoids me writing a test that always passes no matter what.
Any reason you didnt base this on [libSaaS](http://libsaas.net/) ?
If you're going to write a lot of unit tests (and you ought to), you almost certainly want to use one of the third party frameworks suggested. With nose, writing a test is as simple as: def test_method(): assert testcondition As opposed to all the subclassing and assert methods nonsense required for unittest. The command line utility also adds some very useful features and makes test execution simpler. It's also backwards compatible with unittest, so you can use unittest idioms where you absolutely need to set up reusable test cases.
I must be missing something. How does it avoid that?
It works with locks in 3.3.
Weird, I literally just ran into this last night in reverse. I was running some old code and couldn't figure out why it was logging INFO even when I set the level to WARN. I'd set the echo parameter to True a long time ago and forgotten about it. Of course grepping for `log` didn't find anything. The parameter overrides the usual logger setting unless you set the level after creating the engine (or connecting, not sure).
A couple of similar packages: - Enthought's [Traits](http://code.enthought.com/projects/traits/) ([on PyPI](https://pypi.python.org/pypi/traits)) package has a very similar aim, including GUI generation, but it's quite a heavyweight dependency. - IPython's [traitlets](https://github.com/ipython/ipython/blob/master/IPython/utils/traitlets.py), which we're in the process of splitting out as a [separate project](https://github.com/ipython/traitlets) copies the main part of the Traits API, but it's a lightweight, pure Python module.
1. I wasn't aware of it 2. I'm not sure if Uber's API is a good match for it (not REST, almost all of the models are immutable by client, deep deep deeeep model structure etc) It does seem quite nice, though. I'll check it out some later on. Thanks for the tip!
I hope you'll push on this approach. LabRAD makes our daily life in the lab very pleasant, and bringing up new experiments is pretty easy. If you choose to try this I will help you get off the ground. I want to do this as a means to improve the documentation.
&gt; Will I get an error that I'm not returning an int? No. Per the PEP... &gt; By itself, Python does not attach any particular meaning or significance to annotations
This is interesting. Thanks. I've been programming since last week using python. I am making excellent progress and loving every minute. After python I really want to learn C. I've always been interested in it and now that I am finally learning that is where I want to go next. Do you think this is a good track?
Not exactly the same topic, but I made a video about prime numbers, and actually included a bunch of python code and unit tests in the video. [Here it is](http://youtu.be/kcuLJXF44Dw)
earlier link only seemed to work on mobile
 @contextmanager def saved(cr): cr.save() try: yield cr finally: cr.restore() I strongly dislike the above code. Putting a `yield` inside a `try` which also has a `finally` is bad practice. What happens if the generator is never resumed? Python solves this problem using a finalizer, and finalizers are evil. In this particular case, we can probably get away with it because the `@contextmanager` factory will ensure we get properly resumed, but I really don't like objects with nontrivial finalizers, so I prefer the class-based version. In practice, if you're dealing with exceptions, you're more likely to write something like this: @contextmanager def context(foo): # enter the context with foo try: yield foo except Exception: # Try to roll back whatever changes have been made since we entered the context raise # only if semantically appropriate for the exception in question else: # Nothing went wrong, so exit the context normally This does break on certain exceptions, but those exceptions are quite possibly things you don't want to clean up after anyway (e.g. `SystemExit`, `KeyboardInterrupt`). In theory, a `GeneratorExit` could nail us if somebody tries to `close()` our generator, but that's probably a pathological case, and we can always catch it manually if we really want to be paranoid.
I think it would make sense for you to write an example text processing language with input/output in Python, and then try to recreate it in C. This will show you the differences in expressiveness and ease of debugging. Then try to optimize each to see how you make each faster.
Any reasons, other than laziness, not to use this?
Would you explain what you mean by the first proposed improvement to Python? 
thanks for the traitlets reference, i've been looking for something like this lately
He wants Python on the web but doesn't want to use a middleman like Django.
Well, you are trading dynamism for static definitions. One of the core concepts of Python is duck typing, this approach is at odds with duck typing. Sometimes, python's dynamism is a great advantage, other times you need more control (I.e. validating user input). This tool would only deal with the simple cases of input validation, but not more complex instances. So, to me, this package is useful in the instance where you need simple input validation and no more. If you are designing a library, this is probably not helpful because it is not pythonic (at odds with duck typing). If you are designing a complex app, it will probably also not be helpful because validation is likely to include at least some complex cases.
&gt;Years of cutting-edge research still haven't produced a type system that won't get into the programmers' way I think the author is a little out of touch with modern PL work if he really thinks this. The problem is not that expressive type systems don't exist, it's that grafting them onto existing languages that have spent ten years embracing dynamism is as difficult as social problem as it is a technical one. Unless you refine your thinking to a subset of Python that you can declare "by fiat" that all code will conform (example: [Google Python Style Guide](http://google-styleguide.googlecode.com/svn/trunk/pyguide.html)) the problem of doing whole-program analysis for an average "in-the-wild" program is just too intractable to even consider. 
Nope, like a taxi driver, except they don't like calling them taxis because if somebody decides they're taxis, they have to pay for taxi licenses.
Annotations in Python 3 have no semantic connection to the function they are attached too. Though they can contain arbitrary logic.
yes, that's right. 
Another dependency you need to link to your script. 
Where to start... First of all, trying to fit all of your data in RAM is the inherent problem here... not your hardware. Furthermore, you havent described your case well enough to provide any meaningful guidance. What kind of analysis are you doing? It is likely that some careful thought about your algorithm would allow you to work on chunks at a time instead of having to load it all. Beyond that, what your analysis is trying to accomplish will drive how you break your data down. My first suggestion is to write a clear statement of what your overall goal is, and figure out how your data needs to be conceptually organized. I would say that for your purposes AWS is totally irrelevant to solving your problem.
Agree with +cacahootie how big are we talking about what sort of analysis.. you can go a long way on a "small" machine with today's tools.. I do 1-2 Gigabytes regularly and can go way bigger (just don't have the use case)
Nice work. I just got a Pi so my son and I could learn a bit of Python and put it in action. I had an idea to grab names of champs at match startup and make a fake loading screen that would be persistent throughout the match, like to display during tournaments and what-not. Any thoughts on if this is a possibility with the Official API?
Download mysql and then take that csv and do a LOAD DATA LOCAL INFILE command in mysql. You have to first make the table in sql with a CREATE TABLE statement. Google the specifics. Once it's in an Sql database you can use an ORM like sql alchemy or django to make your analysis
docs dont seem to be working at the moment
You could try setting the process's priority to high or realtime in task manager. You'll probably get better results by either optimizing your algorithm or re-writing it with a more performance-oriented language or library.
A decorator is a function that takes a function and returns a function. Using special syntax, they can be added to a function definition so that every use of the defined function is replaced with the function produced when it's passed through the decorator function.
cool project. lets see how well it can parse this: Cool Runnings is a fun but silly movie about a Jamaican bobsled team. Not an academy favorite like Gone With the Wind but still an enjoyable flick. Some of my favorite books are sci-fi novels. I really enjoy the baroque cycle (quicksilver, the confusion, the system of the world) by Neal Stephenson. I guess those aren't really sci-fi though since its a historical setting but everything Stephenson writes comes out feeling like sci-fi regardless of the setting. 
A single-threaded Python process will use 100% of one CPU core (unless it is IO bound.) This is the exact same as any other programming language. It doesn't matter what OS you are using either. So if you have a single-core CPU, and your program doesn't do anything blocking, it will use 100% CPU. If you have a quad-core CPU with hyperthreading, it will use 12.5% CPU. If you want to use more CPU (more cores) you need to add more threads.
Itertools.islice?
Ok - a few things going on here. As I mention below, file size and RAM are not your problem. You can work with arbitrarily large datasets, limited only by disk space. In fact, in serious data analysis, the consideration of the usage of disk and RAM is a major aspect of the design. Databases are nice because they will handle a ton of the mechanics of working with data that is larger than RAM. However, they are well suited to relational problems, i.e. driven by categorization, but with the additional requirement of long-term active life of data. If you have a static dataset (you do), then a SQL database may be useful if it is a tool that you know and can provide the power you need without excessive overhead. And by algorithm, I meant more the macro-level organization of your logic. I.e. how you break your problem/question down into action. An example problem with census data applied: Question: what proportion of the population falls into the 20-30 age bracket (arbitrary - doubt this is how the data is aggregated, but just go with it)? Further interested in the geographic distribution, at the county and state level. First, the data is likely organized by census tract or some other fairly small geographic division. You need to understand and describe the relationship between the small component and your larger aggregates. Once you understand how you are building up your aggregate statistics, you work file-by-file, line-by-line and maintain your running, aggregate stats in RAM (if small) or on disk (if large), and flush at a reasonable frequency. First you would aggregate the low-level into the county level, then the counties into the states. You're only ever working on 1 row of data, and perhaps 5000-100000 aggregate categories need to be tracked (depending on the granularity). My point is that how you break up your problem for analysis is a critical consideration. The issue is not hardware - people have been working with datasets larger than RAM since the beginning of computing. This is where a basic understanding of data structures begins to come into play - there are considerations of access speed, patterns, and the actual "physical" format that you store the data in disk and in RAM. Python makes some of that easier with the standard library and rich types, but it doesn't absolve us entirely of the concern. When I first started doing numerical modeling, I wrote an electric system economic dispatch model that took me 20mins and constantly hit memory errors. Today, the evolution of that tool does a lot more analysis in like 500MB of memory and in a couple minutes. If you find yourself blaming hardware - you're probably missing the problem.
Also useful: `itertools.filter` and `itertools.takewhile` to operate only on a subset of an iterator given a predicate.
Simplest and most direct route is to just use pandas [built in chunking mechanism](http://pandas.pydata.org/pandas-docs/dev/io.html#iterating-through-files-chunk-by-chunk) to read through the file. You'll want to force deletion of the objects in memory, once you've run your cumulative counters over each chunk. The [del statement](http://docs.python.org/2/reference/simple_stmts.html#grammar-token-del_stmt) is the right tool; otherwise you need to ensure that chunks are garbage collectable at the end of their useful life.
you will need to use the [multiprocessing](http://docs.python.org/2/library/multiprocessing.html) module. (There is a "threading" module but it won't run on more than one core.)
If you are going to be repeating this test, you should probably just make a subreddit with test posts for your bot. Anyways, Ender's Game is a good book and so is The Demon in the Freezer by Richard Preston. Chilling tale about smallpox that is
What you might need to do is called optimization. See [the related page](https://wiki.python.org/moin/PythonSpeed/PerformanceTips) on how to do it with Python. The general strategy involves the following steps: 1. Get it right. 2. Test it's right. 3. Profile if slow. 4. Optimise. 5. Repeat from 2. At your point, I would probably run what is called a profiler. A profiler will run your code and see which part of it and which specific function or method call takes the most time to execute. This might indicate some wasteful use of resources, a wrong algorithm, a wrong data structure or something else that might be slowing your code in a bad way. Like others mentioned, you might be able to get more performance out of your resources by using more threads or processes. Concurrency is a complex topic that is hard to explain in a single comment but there are many useful resources online. [This presentation](http://www.slideshare.net/dabeaz/an-introduction-to-python-concurrency) is quite interesting. The base concept is that if your program is performing tasks that can be run independently of others tasks, you might be able to run them in parallel instead of in a serial manner to boost performance and improve your run time. Even if those tasks are not fully independent of each others or if they share some kind of small state that needs to be read or write from, it might be possible to increase performance by using concurrency. Performance optimization is all about finding the bottleneck and seeing if you can improve it. If you can provide more details about your program, we might be able to help you further. How did you notice the small amount of computing power that Python uses? What exactly was that *amount*? &gt; Is there a simple (or even complex) way to allow / force Python to use a significant amount of my computing power? There is generally no one quick or easy way to improve a program's performance if you exclude buying more or bigger hardware to run it. Even using a different operating system will probably not improve it. You have to get yourself dirty and dig into the actual code. The 5 steps process mentioned is quite the best the computer science community came up with. Have fun!
&gt;If you are going to be repeating this test, you should probably just make a subreddit with test posts for your bot. Already did :P
Vectorize your code using numpy. Keeping it in Python is horrifically slow. You should see a 100x speedup easily.
I feel like you are guessing what the bottleneck of your program is. Tell me if I'm wrong but if that is the case, it is possibly the worst possible thing you can do in order to improve performance. Run a profiler. Do it now! That will greatly help you out find what the bottleneck is. Now, looking at your code, I feel like using xrange instead of range, if you are using Python 2.x, might improve your performance if len(b1) tends to be large. Run a profiler right now. Trust me, it will be worth it. EDIT: Like billsil mentioned, using [numpy](http://www.numpy.org/) data structures and algorithms to do the heavy numerical computation might also help your performance.
You could use a generator, for example: def read_csv(filename): with open(filename, 'rb') as f: header = [l.strip() for l in f.readline().split(',')] for line in f: line = line.strip() if not line: continue fields = [l.strip() for l in line.split(',')] row = dict(zip(header, fields)) yield row for row in read_csv(filename): # process data in row
&gt; I've got 12 gigs of CSV files on 6 gigs of ram. That is wonderful but mostly irrelevant. You do not need to have those 12 gigs of data loaded in memory at all time to make up charts, tables or maps of all sorts. A simple strategy is to iterate over each line of one of those CSV files and compute the final value you need in the end. With such a strategy, you can have at most a single line of those CSV file loaded in memory. This might not be time efficient if you are planing on doing it many times or over a long period of time but it surely can run on a 6 gigs of ram computer. There are various other strategies that have different time/IO/repeated trade off in terms of efficiency and performance but you should easily be able to do it with even less than 2 gigs of ram.
&gt; Inspect its methods and look for `__enter__` and `__exit__`? That will work out only if you are implementing the `with` functionality using a class. For functions, you will have to invoke them and then check for `__enter__` attribute. But this is a pain because you wouldn't know how many positional/mandatory parameters a function accepts. So yeah, there is no generic easy solution to check if a given function support `with` blocks. I'm assuming you don't want to do this from a REPL but need to find out at runtime given any class/function. If you are OK with a REPL, look at moocat's answer below.
High recommended 'book'. I love the interactive style. It really helps brings the topics to life. It's a little sparse on the technical details, so it's not necessarily something that I would recommend for a CS course, but then again, I wasn't really looking for one.
as a fellow league player myself, this is great :)
I had never understood the issue people have with decorator, and usually when I'm starting to explain that @dec is just a short version of f = dec(f), people understand it really quickly. So thank you for your definition which is concise and explain it really well.
It was actually changed to and then from this [around 2004](http://hg.python.org/cpython/rev/cc10b010f40b).
Pandas is good. As to the rest of the problem it all depends on what you're trying to do with the data. Many algorithms (e.g. PCA, correlation, linear regression) can be run using multiple passes through the data rather than loading it all at once.
http://www.pytables.org/moin It is an efficient on disk and in memory tool. It relies on binding to fortran libs and C libs who store data in memory efficiently (no __dict__ and stuff)... It must probably belong to a bundle of scipy.... 
Sorry about that, it should be fixed now. [Here](http://topographica.org/Reference_Manual/param-module.html) is the direct link.
[Leo](http://leoeditor.com/)
I haven't checked, but I'm reasonably certain that [this](https://github.com/louist87/scrappy) is &lt;1000 lines of code. Feel free to downvote if I'm mistaken. I wrote this a few years ago, so it bears the mark of the beginner. Still, I like it because I think I did a relatively good job, and it's the first thing I ever wrote that I felt was filling a niche. Ninja Edit: Pull requests are still welcome.
Ill have to remember this project in the future when I rebuild my NAS. I have a ton of videos/movies with random crap names. Is the period in the file names set via a config or within the code? Id prefer to use an underscore but this could be done with a patch. Thanks!
Is there a PDF version of this book?
Another one is [Atom](https://github.com/nucleic/atom?source=cc)
&gt;Id prefer to use an underscore but this could be done with a patch. All you need to do is [write your own custom `Formatter`](https://github.com/louist87/Scrappy/wiki/Formatters)!
To get the load_extension bit working, in the setup.cfg file for pysqlite, comment out the SQLITE_OMIT_LOAD_EXTENSION.
This is what I have been doing, but it seems like an inefficient use of time. There is a lot of data to explore and it seems like every time I get a new idea, I have to re-write a big chunck of code. I assumed that someone else had already built out a decent frame work.
To my knowledge it is possible. Just do network.sortModules() when you're done making changes to verify and initialize the new network.
&gt; Once you understand how you are building up your aggregate statistics, you work file-by-file, line-by-line and maintain your running, aggregate stats in RAM (if small) or on disk (if large), and flush at a reasonable frequency. This is roughly what I have been doing. Since eveything is in a CSV format, I've been using generators to run through each file, line by line. This is satisfactory for pulling together some basic descriptive statistics (mean, mode, count). But it is not the best for medians, let alone regressions. And I'm concerned that this is not the most efficient use of my programming time, nor the robust method. Consider finding the median income for a population. I need to sort the population (which I think I know how to [do](http://en.wikipedia.org/wiki/External_sorting)), then find the one or two values which represent the median. This is such a straight forward problem, I assumed there was already a best practice approach out there. By the way, thanks for taking the time to reply. 
I'm a big fan of tested documentation. (Documents that have embedded tests that verify that the things the documents say are true.) Doctest has been used in that space for a while but I wanted something more so I made Manuel (https://pypi.python.org/pypi/manuel/). It's arount 700 lines of code. Of course its own documentation is tested using itself: http://pythonhosted.org/manuel/
uTorrent has a fairly comprehensive web api AFAIK.
Mine's not much but over the last day or so I've been tinkering with a tiny interpreted calculator-language that's about 150 loc. It doesn't do much right now; you can add, subtract, multiply, divide, exponentiate, and modulo arbitrary integers and floats and store the results in variables if desired. I'm hoping to add support for user-defined functions soon, and I might possibly change the syntax of the "let" statement to be more like a "let" in Scheme, the inspiration for this project. Check it out if you're interested! I'm by no means an expert and I'm doing this project to learn and have fun, but all comments and commits are welcome! https://github.com/swgillespie/rp-calc
[Feed HQ](https://github.com/feedhq/feedhq) [News Blur](https://github.com/samuelclay/NewsBlur) Might I suggest googling your post title first next time :)
Really impressive!
checkout http://www.picloud.com/ You can now call a supercomputer in the cloud from python !
cool thanks, looked through the source anyways as it's all there. 
You don't need tests for one-off code. In fact, at my company I tell people we really only need to test libraries and long-lived tools. If someone says "Can you just make me a foo that does bar, so this won't take me a whole week to do?" we just write the code and get the job done. Testing will never help 100 lines of code that does one painful task that we just need done by Friday. There's a process in TDD called "spiking," useful for when you can't get your head around how to even begin testing something, because you don't really understand the problem enough. This is a fancy term for coding the way most of us have always coded - cowboy-style, get-'r-done coding that's a mess, but works. In TDD, the idea is to then go back with the knowledge you gained from spiking your way through it, and reason out proper, testable elements to write it all again through proper TDD. For getting a crap task out of the way with a one-time tool, I spike it out, but then never go back and test it, because it's not worth it. If that thing does start to become useful, and it might live on, then I clean it up by refactoring through TDD, so we have a proper platform for it to grow and be refactored further in a safer, tested manner. This only happens occasionally, though, lending credence to my belief that it's not worth testing the small, isolated stuff.
&gt;so you can use unittest idioms where you absolutely need to set up reusable test cases. What's the difference? Isn't the test method you wrote also a reusable test case?
There is an excellent option combining pytables with pandas. The following link provides some ideas for large data work flows using pandas http://stackoverflow.com/questions/14262433/large-data-work-flows-using-pandas
You asked-- we answered: https://www.digitalocean.com/community/articles/how-to-deploy-python-wsgi-applications-using-a-cherrypy-web-server-behind-nginx
12GB in csv does not necessarily mean 12GB in RAM. ASCII is pretty inefficient space-wise. If it were me, I'd write something to go line-by-line and reformat this so that everything is numeric. Then you should be able to load it using numpy, where it's stored as an internal array representation (more efficient). You could also use numpy to save the file in binary so you don't have to read it from CSV in the future, which takes forever. This would be easy to try first, before you try any of the more complex suggestions.
Brilliant thanks :)
First, subsample your data until you're sure what you want to do. Second, if that's 12GB of uncompressed text, it's much less in binary (and you might be able to throw out some columns). You can probably also operate on chunks, like one state at a time, and only keep that in memory. Also good to know: unix `sort` works on disk and can be given a field to use: sort -t, -k2 foo.csv &gt; foo_sorted.csv
This sounds like an interesting idea. Do you have an example on hand?(otherwise, I'll just google it).
To be clear, the article itself doesn't mention TDD and I'm somewhat ambivalent about the topic. Regardless, the point is just to get *meaningful* tests in place first, then worry about how and when you'll write them going forward.
my pdf presentation tool for Mac OS X: https://bitbucket.org/rndblnch/osx-presentation/src/tip/presentation.py 999 LOC; single source python2/python3; heavy use of pyobjc; both CLI and Mac OS X app home page: http://iihm.imag.fr/blanch/software/osx-presentation/ 
I wrote a small object storage system, called [sostore](https://github.com/ArmstrongJ/sostore), after spending some time using MongoDB. Basically I assumed I'd standardized on MongoDB, but it was such overkill for my particular project. Instead, I wrote a simple, almost naive wrapper around SQLite that stores dictionaries as JSON. It's well under 1000 lines of code. It's not fast or overly efficient, but it is simple and functional. I currently use it in production on a web service. 
How is Domino different?
simple question - can you build executables for other architectures? Also, what if the exe needs to read a config file with some data. if the file is python, can you import it at runtime and use it? I have login data that I want to load at runtime.
So, what, you're just going to index in to that mess at some fixed offset? What happens when the page layout changes? And now every request goes through a third party service? No thanks, I'll stick with BeautifulSoup. 
[rawgithub.com](http://rawgithub.com/) don't like people doing what you're doing. You should probably use [Github Pages](http://pages.github.com/) instead.
Is there a tutorial or more documentation about how to use it? What is linked seems pretty sparse.
Nope, but I will. 
I think you misunderstood, it takes the HTML dom, analyzes it and extracts out data fields it discovers. You could use beautifulsoup but you'd have to know intimately the structure of the DOM, and if it changes slightly you will have to write it again. Scrape.it finds the data fields automatically given a URL and is resistant to layout change. The third party service is where the API is hosted. you can see the at the 8th array, it has extracted out the business name, phone number, address, email and description into it's respective columns. For any other page on yellowpages, you could just grab this array and insert it into a database or a csv file. You can also play with the seed value to determine the threshold of what gets extracted. The lower this value, the more columns you result in. The higher the value, the more rows you get. It depends on how uniform the data records on a page is. It is aimed at saving a lot of time by avoiding the need to write a custom parser and update it whenever the layout changes.
I do not understand it has only 179.116 views, good quality!
I'm pretty new to Python and I found these short videos helpful for getting started but seems like I saw a post recently that indicated these videos were out of date and weren't great resources now?
eh?
For those of us that didn't know: &gt; What is Nuitka &gt; The TL;DR ... &gt; &gt; Nuitka is a Python compiler. &gt; &gt; It's fully compatible with Python 2.6, 2.7, 3.2 and 3.3. &gt; &gt; You feed it your Python app, it does a lot of clever things, and spits out an executable or extension module. &gt; &gt; Free license (Apache). &gt; Okay I'm hooked! Tell me more! &gt; Now &gt; &gt; Right now Nuitka is a good replacement for the Python interpreter and compiles every construct that CPython 2.6, 2.7, 3.2 and 3.3 offer. It translates the Python into a C++ program that then uses "libpython" to execute in the same way as CPython does, in a very compatible way. &gt; &gt; It is somewhat faster than CPython already, but currently it doesn't make all the optimizations possible, but a 258% factor on pystone is a good start (number is from version 0.3.11). &gt; 
You can apparently cross compile to Windows at least, according to the [manual](http://nuitka.net/doc/user-manual.html#use-case-4-cross-compilation-to-windows). If you want to save config settings in a .py file, you can apparently include it in the compilation. I much prefer using .ini and .conf files etc for settings storage, depending on architecture. Maybe that's just me.
The biggest reason for going with pygame was the foundation of tutorials and support and built in methods for visualization and such. It's good to hear about other options like matplotlib, though I would probably be starting from scratch.. Do you know of any resources that deals with things like building lattice grids and visualizing them in matplotlib? Thanks!
tl;dr Server side events [via XML-RPC on Twisted.](http://telegraphy.readthedocs.org/en/latest/_images/architecture-protocol-stack.png) IMHO this solves only the transport layer problem. The art of preserving millions of server side states is untold in this project.
Do you know if it would play well with (fortran-based) libraries like NumPy?
Yeah, I even ended up writing a guidebook on setting it up. Actually I was looking through google to figure out if there's any PyBrain communities alive or if it's dead in the water.
Just a simple A* simulation using pyglet. https://github.com/dberube4/Path-Finding-Fun
I still don't think you get it. With your approach you need to have a prerequisite knowledge of that page's DOM structure. You still had to spend time finding out each element's class, and their relevant positions. What if the class names change or the elements are rearranged with different classnames? Are you going to use regex? What if there isn't any id or classname? What if the classname is randomly generated on each page? Do you not agree this takes more time and is prone to failure when the website layout changes? Scrape.it does not require you to know or assume anything about a page's structure. The index remains consistent if the page layouts are same, it's not a "meaningless and arbitrary magic number" lol. when the layout changes significantly, the indices will be offset and at this point you would just define a new index. You can also take the diff of the generated JSON and end up with only the extracted data if need be. You can filter out the indices that does not have the data you want or reduce the amount of indices returned by setting a seed value. When your script fails due to layout change, Scrape.it will still be able to discover and extract the relevant data fields. It requires no maintenance. This is a new way to extract data, one that requires no maintenance, unsupervized and is truly automatic. By further processing the returned JSON (for example doing a diff), you can end up with only the data fields. What if you had to process over 100 different domains? You would end up with a 100 different scripts whereas Scrape.it would be able to process any URL you throw at it and still be able to return data when layout changes. You be the judge which is more fragile and time consuming. 
"If you send production traffic to rawgithub.com, **evil things will happen to your site**. You've been warned!" Kind of tempted to see where they go with that...
What's the difference between this and cython (when used solely as a compiler)?
google's python tech-talks are great.
https://github.com/devdave/txWeb/tree/refactor Basically an overlay to Twisted Web that exposes a cherryPy like interface ( unpublished branch has one that acts like Flask ). Been distracted working on some job interview questions/tests but eventually I'd like to push out another example project using txWeb that incorporate SSE ( Comet style ajax is like 3-4 lines of code so SSE would need a parser to convert dict's to the appropriate format. ) Main advantage to twisted.web ( w/wo txWeb ) is that a scalable web application can also communicate asynchronously to other services via http, ssh, zmq, a plethora of other protocols, or using a proprietary format. If I can get SSE ( http://www.html5rocks.com/en/tutorials/eventsource/basics/ ) implemented, it would provide a seamless and accessible way to stream events from server to browser clients ( stock tickers, chat rooms, web games, etc ) without splitting logic from traditional GET/POST HTTP request/recieve servers and a dedicated async system.
Arm / Android - is it on the map for Nuitka?
Post your code. We're not doing your assignment for you, but will nudge you in the right direction.
Are the Nuitka devs planning any other benchmarks like the pypy or Alioth set?
...and (After some very cursory testing) it doesn't seem to work on Windows, either by using the msi or the zip file. Bummer.
import random one = 0 two = 0 numbers = random.randint(1, 2) if numbers == 1: one = one + 1 if numbers == 2: two = two + 1 that's the code I have so far. It must look pretty stupid and laughable at. When you run the program you can see which number got randomly picked. But I think....? I need to put it in a loop or use a "while" command. But i'm not sure how to get it going correctly, i just need the random number generator to keep going and going.
Well, to be honest, if enough people liked this link and clicked through that it caused Reddit to even show up on the auditing radar, I guess I'd have achieved link karma nirvana
That's right, you want a while loop so that the numbers keep getting generated. I would suggest using `while True:` so that the loop keeps going until it reaches a `break` statement. You probably want to show output to the user on the console by using the `print` function, and prompt the user for input after generating each random number. Here's a skeleton of the code for you: import random one = 0 two = 0 while True: numbers = random.randint(1, 2) if numbers == 1: one = one + 1 if numbers == 2: two = two + 1 users_choice = ... #Prompt the user whether to Display the counts (D), or Quit (Q) if users_choice == "Q": break #This will exit the while loop and end the program if users_choice == "D": print("Number of times one has been generated: " + str(one)) print("Number of times two has been generated: " + str(two)) EDIT: Changed = to ==
See if you can figure out whats going on here: import random rndnums = [random.randint(1,2) for x in range(1,100)] tally = { '1':0, '2':0 } for i in rndnums: tally[str(i)] += 1 print tally Hint: Google list comprehensions, dictionaries and for loops. 
Feel free to ask more questions here. I'm no Python expert so others can probably provide better answers.
I'm getting a invalid syntax with the line *If users_choice = "Q":* What could be going wrong there?
I'm still working on a one-time-pad-based VPN. It currently works at &lt;300 lines, albeit quirky and cryptographically insecure at the moment. I've got a big to do list and I was thinking since I've really been focused on Javascript for the last month or two I might just do it in node.js. Its at [https://github.com/rpgraham84/otptunnel](https://github.com/rpgraham84/otptunnel).
Eh. I feel like using BeautifulSoup makes a lot more sense, what if on one page there is an input earlier but on another page there isn't? Using an array index to look up information seems super fragile compared to using class names... To each his own!
What does = mean? Does it mean "assign the value on the right to the variable on the left?" What does == mean? Does it mean "compare the value on the right to the variable on the left?"!
Whoops sorry, it's ==, not =
Or JSON with indentation for readability
Two separate problems with different assumptions. 1. Scrape.it makes no assumptions about the underlying page. The beautifulsoup example makes the assumption that classnames will not change. For data extraction, Scrape.it is superior as it requires no maintenance, is automated, and class name changes or layout changes do not hinder it's ability to extract data. 2. The problem of using an array index to look up information is also misguided because it assumes that each page will change significantly to alter the index. If this is your worry then don't use the index at all to look up the information. You could simply assume the number of columns you expect in a row and search for the index that contains that number of columns. Also, you could flatten the list, do a diff with a previous result, and the result would be the data which is extracted. The index has nothing to with the data extraction portion, scrape.it accomplishes this without any human input and it simply does not know what data field you wanted so it will return as much as possible. The index isn't as important because you'd have to look at the extracted data to know which data field is relevant anyway. you could do a reverse search by looking for the index that contains phone number and email, and return that index. The beautifulsoup example works fine but to have to repeat this 100 times for 100 different domains across 100 different pages is simply not scalable because of the time that goes in to mapping each class name (assuming classnames are constant and will remain so) and the maintenance in updating the script when page changes drastically.
Is this something that could replace py2exe?
Err, for #1 don't you have to identify which parts of the page are useful?
He is probably writing 2.7 and you're on 3.3 version of python.
you'd have to choose the index or do a reverse search for the index which contains the data field that you want. The noise can be shaved down with a greater seed value. you want search for data fields to make sure it contains phone number or email, I'd say this is a better bet.
the "=" is the assignment operator. the "==" is the equal operator. Here is a quick example x = 2 #assign the variable x to the value of 2 if x == 2: #check to see if the variable x is equal to two. print 'x is equal to two'
You should make a 3d contour plot demo so you can show that the matplotlib demos are counter-intuitive. You pass in x, y, and the transpose of z.
This was a learning question for OP...
haha woops, you should clarify that then :)
This is beyond Python, but with many of his other tutorials. 
Such as using abandonware software for his C++ tutorials.
It's covered in the [Zen of Python]( http://www.python.org/dev/peps/pep-0020/), specifically "Errors should never pass silently." Personally, it makes sense. You don't have to check whether the removal worked or not. 
generaly in python, abnormal situations are handled via exceptions, not by returning status values.
I wrote a simple [raytracer](http://forthescience.org/blog/2013/09/05/a-raytracer-in-python-%E2%80%93-part-6-cameras/) just for fun. I am planning to expand the concept to involve cuda, merging with another toy project of mine about mandelbrot sets. But time is never enough.
I've found this frustrating too. You don't want to write: if x in sequence: sequence.remove(x) because that's O(2n) at worst. Personally I hate using try/except for expected logic; I prefer to have "except: pass" be a code smell, and to pay particular attention when I see except blocks. So while a lot of folks like the following: try: sequence.remove(x) except IndexError: pass I avoid this use of try/except elsewhere in my code, and won't break my policy for this one case. ~~The best answer that I'm aware of is:~~ idx = sequence.find(x) if idx != -1: sequence.pop(idx) EDIT: Scratch this. The function I'm thinking of is list.index, and it does indeed return a ValueError, not -1. But I'd much rather write: idx = sequence.remove(x) assert idx != -1 To achieve the current semantics.
I wrote a small simple text-to-speech program that uses the Google Translate online service as backend: https://github.com/suurjaak/TextSpeak Since the service only supports texts up to 100 characters, the program chunks the text into smaller pieces (at punctuation marks if possible), feeds them to the service, and combines the resulting audio. Supports all the Google TTS languages that have human voices.
Regardless of whether I contribute to this specific project at this time, I would like to see more posts about projects I can contribute to. Have an upvote.
Well why thank you kind sir, have one yourself.
&gt; a distributed, decentralized, mobile, meshnet on a Linux LiveCD that goes up in 60 seconds. very buzzwordy. what does it actually do?
API design wart. Lists are the only collection that does not allow silent object removal and I suppose that's because it's one of the oldest. For sets you can do `.discard()` and for dicts you can do `.pop(key, None)`.
&gt; Anyway, I still have to figure out a scenario in which a particular piece of code trying to remove an item from a collection and not being aware if the item is/isn't in the collection is not a buggy design. Seriously? Think harder, there's tons of examples. Set difference. List data read from files etc. etc.
I speak python. Will start contributing in the next couple of weeks (gotta finish my homework first). Funny story: I ready about Byzantium a few months back and wanted to contribute. Thank you for making it so easy for me. Have an upvote!
You already mentioned fredombox what is the state of cooperation here or maybe arkos.io?
Based on this, maybe I should offer my editorial services to OP.
Sorry dude. Lemmie think. You're pretty close. Not the whole world, not like a replacement internet. That's what Project Meshnet is. The Byzantium Project on a smaller scale, and not 100% permanent. It could be if you feel like keeping one up I guess! This is made to be able to get people up and running with thier own free network to one another and communicating and transmitting files and data as fast as possible in an emergry situation. In the slides it gives a couple examples. Like when hurricane Katrina hit and no one could communicate with one another. Or in Egypt when the government turned off the internet and started killing all the protestors. That's what this is for. 
Ah that makes a lot more sense. 
&gt; Using exceptions instead of error return values is a design decision of the language designers (or designer, Rossum may have decided that by himself). Well, I definitely appreciate exceptions, and am glad that they are in the language. But what you do/don't consider an error is often arbitrary. For instance: sequence.index(item) ~~could easily raise an error if item is not in sequence. But the function is defined with the semantics that it returns -1. In this case the logic is pretty clear; it would really really suck if it returned an error there!~~ EDIT: Apparently I'm totally wrong, and it DOES return an error! I do think that sucks though =/ Similarly, if this returned None: dict[item_thats_not_in_dict] That would really suck, even though I probably use defaultdict more than I do dict. And if *this* returned None: list.pop(idx_longer_than_list_len) That would be just *outrageous*. But there are some cases where it's a bit borderline, and I would've appreciated different semantics for list.remove(item).
Are you referring to a specific, existing `sequence.find` in the standard library? I couldn't find such a function, but in any case, I would say that the function is poorly named regardless of error code / exception, because it's not clear from the name alone whether it just returns `True` / `False` or an index. And if it does return an index, -1 wouldn't be a good "error" value, since it is still a valid index for some collections such as the built-in `list`. A more sensible value would be `len(sequence)`, but that would make checking for errors pretty awkward as it's a non-constant error code. The closest equivalent in the standard library I could find is `list.index`, which obviously returns the index of the value, and raises an exception when it's not found. In this, it's pretty consistent with all other `list` methods that can fail in some way, with the surprising exception of `list.insert`. If the index given to `insert` is greater than the size of the list, it appends the value instead of throwing an exception (or returning an error code). I honestly expected it to complain when `index &gt; len(someList)`.
On Linux or Mac you could press Ctrl-z which will suspend the process from running and then run the command "fg" to continue the process. The other option that I can see is to save the progress of the script on exit and be able to load it again next time it's run. It depends on if you are taking input from the user or if you'll have to catch Ctrl-C.
Thanks this works great! I always thought ctrl+z killed the process, how then do i actually kill the process? Saving the progress seems even fun, it doesn't seem to waste the memory too, and resume again whenever i shutdown my system, as for my script there won't be any input from the user, how do i do this? 
This is my current code. Yet i'm still getting a syntax error on the *If users_choice == "Q":* I'm using python 3.2.5 ~~EDIT: Fixed the code up a little bit. Now I can run it without errors but it doesn't do anything?~~ EDIT: Now I got 99% of the code working. Everything besides the Quit command. Here is the new code import random one = 0 two = 0 while True: numbers = random.randint(1, 2) if numbers == 1: one = one + 1 if numbers == 2: two = two + 1 print ("What do you want to do now? Display (D) or Quit? (Q)") users_choice = input() if users_choice == "Q": break if users_choice == "D": print("Number of times one has been generated: " + str(one)) print("Number of times two has been generated: " + str(two)) 
are you a descendant of Salazar Slytherin?
Thank you for this. Can you edit the original post to have some of this information? After I read the description, I thought, "I have no idea what this is or why I should care." I almost went away without reading the comments.
Python != parseltongue
just use the right modules. from fuckit import fuckit with fuckit(): sequence.remove(x) And vote for PEP 666 to get fuckit.py into the standard library
Thanks for posting! It's nearly impossible with my work schedule to search around for something to contribute to. Meshnet is a great idea that I would like to participate in.
Aha. I'm thinking of string.find: &gt; find( sub[, start[, end]]) &gt; Return the lowest index in the string where substring sub is found, such that sub is contained in the range [start, end]. Optional arguments start and end are interpreted as in slice notation. Return -1 if sub is not found. It seems that string.index was added later for consistency with the list method, so this is basically considered an inconsistent wart.
Consider using the pickle or the json module. 
Others have explained the rationale for exceptions being preferred in Python. I do find it strangely inconsistent though, for example: {'a': 1}.get('b') returns None instead of raising a KeyError, presumably because the signature of get is like: get(key, default=None) 
eww, a pdf file.
Wrong answer. Remember, until you've hooked them, you can't ask or expect potential volunteers to desire to do *anything*. You really need to work on front-loading your endeavors.
Would this be slightly better? http://i.imgur.com/zK9pEu4.png
I actually did go away. I notice later that this thread had grown a bit and had a second look.
{'a': 1}['b'] *will* throw a KeyError, but I'm sure you already knew that.
In any intermediate-level code, things like that shouldn't throw errors at all. Things like delete, copy, close, mkdir, etc. They sound like commands, but they are better thought of as changing the state of a system. Why should you care whether socket.close closes the socket? You don't. You just care that, at the end of that command, your socket is closed. You don't care that it was opened first. If you do, you should call an introspection command to see whether it is or not. The only thing you should care about is that it is definitely *closed* at the end of socket.close. Why should you care that your list doesn't contain the value you're asking it to remove? You don't. You just care that at the end of the command, your list does not contain that element. If you do care whether the item is in the list or not, that's introspection. You should say if elem in list. But what you care about when you call remove is not whether it is in the list, but that it is *not* in the list at the end of the call. For mkdir. Suppose you're making mkdir /foo/bar/baz. Why should you care if foo/bar doesn't exist first? At the end of the command, you should only care that /foo/bar/baz does exist as a directory. These commands *ensure* the state of the world is as you expect it at the end. If the commands can accomplish this with a nop, all the better. 
The advantage of Reverse Polish Notation is that you don't need parenthesis, maybe you should think about making them optional unless you wan't it to perform similarly to lisp/schemes prefix notation (but then maybe just prefix would be better) eg: (+ 3 4 5 6) ==&gt; (3 4 5 6 +) Otherwise calculators are cool especially RPN ones. But if you do it the full RPN way you can easily define the parser as pushing and popping from a stack.
I think it's more accurate to say that GTK3 is just different enough that the PyGTK docs are useless. You recognize most of the names and how things should work (for the most part) but it all fits together different. The only Python documentation available to you is this [tutorial](http://python-gtk-3-tutorial.readthedocs.org/en/latest/) and the C API. Looking at the tutorial, though, it appears to have matured a lot in the last year. When I was developing pySSHMenu it had less than half of what it does now.
The project needs your help to write a summary, apparently.
It's a genuine thing you can offer to open source projects. Grunt coding (adding tests, comments etc) and writing documentation and copy are the things most often missing in open source. TL;DR: Everyone wants to make the logo spin, no one wants to document it.
Much better.
I've been using tkinter for small scripts and am pretty happy with it. Not the most flashy but very, very standard (and included with the python distro by default).
I always loved the python 'yield' statement. It does all this in a single keyword (warning, mind bending C content!) http://www.chiark.greenend.org.uk/~sgtatham/coroutines.html
https://github.com/timothycrosley/isort - a simple, but very configurable import sorter and ordering utility - the core library / utility code is only 404 lines with white space. 
Thanks for the idea, but since there might be clients seeing it ;) , it needs to be a little bit flashier than TkInter. I don't mind standards as much.
well qt is probably the most complete option you have, meaning supported features, operating systems and languages. but it might be more complex than it needs to be for what you want to do with it. still, if you are willing to invest time in learning something that will help you out in all future projects (almost no matter what you want to do) qt is the way to go i would say.
Haha I thought OP was being a prick and reposting what's already in his OP.
I'm sticking with wxPython. The community is great, and I'm mostly happy with the look of the apps, at least on Windows and Linux (haven't tested on Mac yet). And it's what I already know. Certainly heard good things about QT, too, though. PySide is just a QT wrapper; just mentioning that because it seemed like you were thinking of them as two different things. What were the specific issues with wx? I think it is fair to say that more and more the "go to" GUI framework is...web or mobile based. So there's that. The desktop is still hanging in there, but if I could snap my fingers and know how to do GUIs on those platforms, too, I would. On that note, you could consider something like Kivy, which has a sort of "write once, deploy many" where many = all major desktop OSs but also mobile. I've assumed that it isn't mature enough to really make good use of it, but that's just pessimism talking (and the fact that people aren't raving about it--or at least I haven't read any raves yet--and yet I'd think they'd be going nuts if it really were that easy to deploy everywhere like that).
Ask the developers on their Github what needs doing right at this moment.
Example of which part? For the making-everything-numeric part, you'll have to go through and determine the best way to do that - is your data currently categorical? Text? I have no idea. Depending on what you want to do, you could just assign integers to each category or token, but you want to be sure that whatever mining you do keeps in mind that those columns are categories (i.e. so that you don't confuse the difference between 2 and 3 as smaller than 2 and 5, when in reality 2, 3 and 5 are just category markers). I think numpy.loadtxt is the main load function...genfromtxt is a little more flexible but slower. But then once you load it once you can save in binary format using numpy.save.
Ill jump on board as soon as I get to work.
Sorry, just the part about saving it in binary. Thanks
Tidesdk is html5 ui but for desktop. It support python backend. Check - http://www.tidesdk.org/
Wrong subreddit. This one is for the computer language called python.
Errrmmmm. Did you do this on purpose, "Stunt"man Mikey? This subreddit is for a different kind of [Python](http://en.wikipedia.org/wiki/Python_(programming_language)) (No not [that one](http://en.wikipedia.org/wiki/Monty_Python) either)
So I'm 50 percent into python using edx course. How much can I help? I know my Turning complete. 
Doesn't work for me. Here's the trace: Traceback (most recent call last): File "randomdilbert.py", line 60, in &lt;module&gt; RandomDilbert().show() File "randomdilbert.py", line 25, in __init__ self.show_random_image() File "randomdilbert.py", line 57, in show_random_image self.image.set_from_pixbuf(pixbuf_from_url(self.get_random_image()) ) File "randomdilbert.py", line 51, in get_random_image image_url = re.search('&lt;a href="/strips/comic/.*?/"&gt;&lt;img onload=".*?" src="(.*?)" alt="The Official Dilbert Website featuring Scott Adams Dilbert strips, animations and more" border="0" /&gt;&lt;/a&gt;', page_contents).group(1) AttributeError: 'NoneType' object has no attribute 'group' 
See cantremembermypasswd's reply, he covers a lot. Just to clarify, you can ask for user input by using the "raw_input" function in python 2.7 or "input" in python 3.x. If you would have been taking user input before then it would be fairly simple to do "Oh they entered 'quit' so I should save my state and exit". I think the cleaner solution is to do what cantremembermypasswd said for catching the KeyboardInterrupt (Ctrl-C). Saving to disk as JSON or using pickle is a good idea. Or it sounds like you came up with another option where you could save the state after each iteration then when you start up just see if the progress file exists and see where to go from there.
That is a really cool program....I have never used AppKit before....is it hard to learn to use it with python with 0 cocoa knowledge? 
You mean, there's a reason someone with a Communications degree should exist? Blasphemer! STEM FTW!!
No, it's a separate GUI program. You type or paste the text, click a button, the program does a bit of traffic with Google services, and plays the resulting combined speech. And it doesn't translate between languages.
It isn't "broken". It follows a longstanding tradition used by low-level system calls. However, I find it to be inelegant and not typically what the user wants.
nop, l.remove(item) does not ensure that item won't be in l anymore, it only removes the first occurrence of item (i.e. ensure there is one less occurrence of item than previously), hence the need for reporting an error if that contract can not be respected. if you really want to remove all occurrences of item from the list, regardless of its presence, just do (and look, no need for error handling!): l = [u for u in l if u != item] 
Hm, I never really thought of that - it might be a little bit overkill? Or maybe not - like I said, I'm a bit out of the loop. I have written a medium-sized Django application before, but haven't looked into other web frameworks for years.
Thanks for mentioning Kivy, I had seen it a while back but I wasn't sure if it was documented and supported enough for me to get something small done quickly. I'll look at it again! For Wx - I even bought a book on it, but it seems like I didn't get all the best practices nailed down. I don't remember specifics (it's like 2-3 years ago), but I think I had stuff like memory leaks and the like happening, things that felt like they were beyond my reach. I might have constructed the objects and app overall not adhering to all standards - maybe because I found it hard to find out what the actual standard were for doing things with wx..
They should put this on their website. It is much better, much more catchy and much more informative.
Which one is the best for delivering webkit to a desktop app?
I want to help
Sadly I think the "go to" GUI frame work is still Tk. I have done wxPython (loved it) and PyGTK (it was okay), but when you want something that is "just going to work" on Python, you should use Tk. You know that it will be available. Tk isn't easy, the API is frequently confusing or non-sensical and the documentation gets pretty poor once you start doing more complicated things (the nmt.edu docs are by far the most complete and comprehensive I have found). Still, if you want a Python application that will work across platforms and all manner of installations... Tk is it.
Steady now, let's not get carried away :p
I mean, no one needs a whole degree in it.
&gt; A simple strategy is to iterate over each line of one of those CSV files and compute the final value you need in the end. Going far beyond this scale, roughly the same attitude gives you MapReduce. No matter how much information you have you can always do it one bite at a time.
What exactly does Google do with what you type? Is it just a prettier voice than say()
I suggest [Muntjac](http://www.muntiacus.org/) .
Please excuse my pessimism - but activity on this project (at least according to GitHub) looks quite stalled.
Ah so that is what "distributed, decentralized, mobile, meshnet on a Linux LiveCD" means. Thanks :)
Right... I acknowledged that as basically the only value for an ORM. If you want to do anything even remotely complex for a select (such as a grouped join), you are better off just using SQL directly. Besides, accessing columns by name is an option with many database drivers. For data analysis, ORM is pointless.
It's coming up 404
Well, if you try wx again, if you didn't last time I'd make sure to get on the mailing list and use it to interact with the (very responsive) community. Robin, the creator of wxPython, often answers questions, though he is pretty busy these days (working on QT/PySide of all things!, though also some wx development). I usually don't hear much about memory leaks, though maybe problems when a user is trying to put an unusual number of objects "on screen" at once (I'll occasionally see people asking about why their page with 10,000 wxChoice objects is having issues, and I never understand why they'd want that).
It states it's similar to desktop toolkits but for web, but I want a desktop toolkit; nothing will be in a browser.
Sounds like a perfect candidate for a webapp instead. `import webbrowser` and launch a page pointing at your script's internal tornado/gevent server. Get ui events from requests or a websocket/sockjs connection. You might not even need that if it's just for personal use and you can run your commands from an ipython notebook.
Oh, it does? I had no idea! That might indeed make Tk a viable candidate again. 
The problem with byzantium is that it does not support end to end encrypted protocol. That's why I support CJDNS. 
Your second paragraph for me is actually a plus, even though it might take more time now. It's a part of what drives me towards Qt and away from Tk, having something that is more future-proof (any maybe bullet-proof (; ). 
Thanks, I'll look at Flask!
It was a joke. Whhoossshh
I am indeed.
I was also interested in a python state machine module for setting up a vehicle monitoring system. But alas, I will also be building my own.
Well, I don't know if it's the best, but I made a package ([WebUI](https://pypi.python.org/pypi/WebUI)) for this exact purpose. It's a minimal wrapper for Pyside.
same here. Finished couple of courses (edx and coursera), and wish to get real forking life practice. Is there anything we can help with?
The same voices as on http://translate.google.com/. I do not know what say() is.
CJDNS does not seem the same thing as Byzantium.
Code here if someone wanted to copy/paste it for any reason: print("-----------------------------------------------------------------------") print("GBP Bitcoins Market") import urllib.request page = urllib.request.urlopen("http://bitcoinwatch.com") text = page.read().decode("UTF-8") # Localbitcoins localbitcoins = text.find("localbtcGBP") localbtclast = text[localbitcoins+65:localbitcoins+73] localbtclow = text[localbitcoins+202:localbitcoins+208] localbtchigh = text[localbitcoins+179:localbitcoins+185] print("Localbitcoins - Last: ", end="") print(localbtclast, end="") print(", ", end="") print("Low: ", end="") print(localbtclow, end="") print(", ", end="") print("High: ", end="") print(localbtchigh) # Mt.Gox mtgox = text.find("mtgoxGBP") mtgoxlast = text[mtgox+59:mtgox+67] mtgoxlow = text[mtgox+173:mtgox+179] mtgoxhigh = text[mtgox+196:mtgox+202] print("Mt.Gox - Last: ", end="") print(mtgoxlast, end="") print(", ", end="") print("Low: ", end="") print(mtgoxlow, end="") print(", ", end="") print("High: ", end="") print(mtgoxhigh) print("-----------------------------------------------------------------------") 
It is. Just contains more features. The only difference is that byzantium uses ad-hoc. That's a big security hole, right there. Decentralized mesh net end to end encryption protocol. ipv6 It already has a layer on top of the clearnet, called hyberboria. This is more of a... testing ground. CJDNS on router is supported Mesh nodes are up and running in several cities in America. Seattle probably has the most nodes compare to other cities. 
&gt; Flask i looked at it now, I really like it - though I might end up using Qt for what I want currently. I'm sure Flask will come in handy at a later point though, this project might actually entail a minimal web front ent at some point.
You really can't be parsing HTML with fixed offsets like that. They're going to shift and change over time. Use an API, [like this one](http://bitcoincharts.com/about/markets-api/). JSON decoding is included in the standard library: import json from urllib.request import urlopen data = json.loads(urlopen('http://api.bitcoincharts.com/v1/markets.json').read().decode('utf-8')) by_symbol = {item['symbol']: (item['ask'], item['low'], item['high']) for item in data} for name, symbol in (('Localbitcoins', 'localbtcGBP'), ('Mt.Gox', 'mtgoxGBP')): print('{name} - Last: {info[0]}, Low: {info[1]}, High: {info[2]}'.format(name=name, info=by_symbol[symbol])) 
What text editor is that in the screenshot?
 import os os.system("say 'hello world'") Run that
I would agree, except that every time I look at pyQT, I am filled with rage like the cataclysmic heat of a thousand dying stars, because how the *fuck* do you not call it qtpy?
Awesome. When you do ask the devs on their Github what currently needs doing.
Okay, I edited my top post.
I recommend using [requests](http://docs.python-requests.org/en/latest/index.html) over urllib
Cool!. Ask the devs on their github page what currently needs doing.
Web app, or PySide (Qt bindings).
This may be a silly question, but why is this an entire linux distro and not an application that can run on an existing system?
I don't know your app and use cases so I can't be specific but you might need to make that decision now. As you know from your django, web apps *generally* use some kind of async reactor loop and it might hard to refactor that in later. Of course it would be easier if the web part was just to expose data for client scraping and didn't drive the app itself.
You can install the mesh software onto other distros as much as you want. They just wanted to make it easier and fast by having a pre-made thing that can book up quickly.
To echo darthmdh - If you are going on the desktop, use QT. It is extremely cool. 
tkInter wont work in OS X as of now. It relies in Quartx 11 which is not available in newest versions of os. So if you want a tkInter app to work in a Mac, you will need to install Quartz, which will make all kinds of weird things when using your app. 
Oh okay, thanks!
Do you guys know about http://www.broadband-hamnet.org/ ? Because the concept is similar and this may be fertile ground for cross pollination. Broadband-Hamnet is firmware that can be flashed to AP to build a self configuring ad-hoc network. Once that is accomplished, you could use the self-organizing fault tolerant wireless network to send any type of traffic. Thus a bunch of hams could go out in the desert, build a mesh network, add VoIP, web enabled video cameras and text messaging and helps support a marathon by reporting the runner's numbers, times, and sending a video feed of waterstops. /r/hsmm_mesh/ 
I often want to run groups of ~100 or so jobs with the same code using different parameter settings. I wrote a tool that sets up job directories, builds config files for the job from a set of templates and launches the jobs either locally on my machine or by submitting them to a cluster job manager. The whole thing fits in &lt;200 lines of python and has saved me countless hours of effort over the past several months. 
This is a fantastic project. Really hope I can find something to help with as a beginner such as myself. Best of luck. 
Thank you pickle seems clean, I'd be using it. 
"Emergency Internet when the real Internet isn't there" would sum it up well.
Set up a buildbot instance to build and test the code as commits come in?
Well yes, but I was asking more for who I contact. 
Checking GitHub, looks like [Sitwon](http://github.com/Sitwon) is your best first contact; he'll probably be able to either hook you up with other folks doing builds, or there aren't any, you can volunteer. Edit: link acting strange, not sure why. Coding in another window, sorry... Edit edit: Now that's more like it. Tx /u/EpicCyndaquil.
If I'm using Python 3.3, is there any reason to use this package over just using built-in annotations?
Took me a while to see it too. Mind if I ask what you're programming in Perl? Perhaps I'm just not too well informed, but I don't see many projects in Perl these days.
Sure - I'm at WhiteHat Security. Our core application, Sentinel, is our big Perl application which scans websites for vulnerabilities (and records/tracks/manages those results for our roomful of whitehat hackers who verify exploits). The part I'm working on schedules and monitors our source-code scanner appliances, which are running a Django/Celery app which in turn runs our scanner engine; this lets us pull that into Sentinel as well. Good place, and I've gotten to work with a whole slew of different technologies here.
Something tells me that releasing the weeping angels would be a bad idea though...
have you tried node-webkit for rapid development for platform independent https://github.com/rogerwang/node-webkit. And very easy to ship to any platform, and it will fully compatible with HTML5, CSS3.
I also would like to encourage this habit of postings about projects which need work/help/contributions. Have another upvote!!
well, it doesnt work natively in my companies macbooks that's for sure.
I would do this with Python 2.7, wxPython 2.9, and SQlite or maybe just text files. I myself don't think wxPython is too complicated--I mean, you need a GUI, you're going to need *some* toolkit, and all of them are probably similarly complicated. But I could put the entirety of a wxPython GUI program in this comment...in fact, I will! (16 lines of Python): import wx class Frame1(wx.Frame): def __init__(self, parent): wx.Frame.__init__(self, parent, title='Equipment Manager') self.panel1 = wx.Panel(self) self.staticText1 = wx.StaticText(self.panel1, label='Loaner Equipment', pos=wx.Point(0,0)) self.choice1 = wx.Choice(self.panel1, choices= ['bat','ball'],pos=wx.Point(0,20)) self.radioButton1 = wx.RadioButton(self.panel1,label='out', pos=wx.Point(0,50)) if __name__ == '__main__': app = wx.PySimpleApp() frame = Frame1(None) frame.Show() app.MainLoop() But QT is just as good, I'm sure, and some people are Tkinter fans. There's also GTK. 
Do gems really handle when native code extension modules shares different versions of an underlying library? Or is that simply a situation that Ruby libraries never run into? In Python-land, we have a very popular set of libraries that have these kind of native code shared library inter-dependencies, and that's what causes a lot of this grief. Not to mention, some of these things include FORTRAN code, and the compiler toolchain for that is more finnicky than for C. Maybe Rubyists never use FORTRAN extension libraries.
Yeah, the web is really far superior IMO to desktop widgets.
I don't think I've had that particular problem: gems depending on different versions of native libs getting into conflicts. But then, the OS has provisions for libs of various versions, so I don't see why this would happen. I've used many gems which depend on system libraries and/or include C code which must be compiled during them gem installation. The biggest problem I've had is when I update my OS after having installed a gem which depends on a library. I'll then get an error and need to re-install the gem.
What no-one else seems to have said is that this is of a very high calibre for your first ever script. Nice work!
Ok besides the ORM business what would you recommend he do for his problem if not put it into sql with load infile? I can't imagine an easier or faster way but I am just a beginner so I am genuinely curious.
-1 is a valid index in Python :) Using -1 as a magic value in Javascript works because sequences are only indexed in the positive direction. I bet that's what you were thinking of.
Using a temporary variable for this is quite unpythonic (IMO). It would be more succinctly implemented as: collection = [x for x in collection if satisfies_test(x)]
&gt; When you're writing a line of code, and there's trivially two ways to write it, choosing the one that's half the speed and having to come back to it later is not a good way to go about things. I strongly disagree. If you're choosing between two ways of writing it, you should choose the way that's most easily understood. 
Urllib2 and lxml worked wonders for me!
It's called web, runs on any OS
Hmm, fair enough...
I develop on Windows, and Flask works pretty well. 
Hey, thanks for the response. I am completely new to Python and haven't got round to learning JSON yet, could you maybe give me an insight onto whats going on in that code, some of it looks incredibly unreadable to me atm :)
If this app really is simple as you state, 'databasing' can be easily achieved by using Python alone, no need for any other libs, also the GUI doesn't have to be anything special, so try out tkinter, which has every widget you listed and more, and see how that goes. QT and wxPython are a bit much, and I'd suggest wxPython over QT if you end up choosing between the two. wxPython is in my experience the best performing of all the GUIs, and QT still has ties to Microsoft, so avoid on principle. You can also take a look at Kivy, which is a cross platform GUI, with great support for touch devices, if you think you might eventually port that app to other platforms(android and ios included). If you are really fixed on the desktop, and happen to be working on linux you can also take a look at GTK, it's more heavy duty than tkinter but you'll get a more native look, and a better performing app.
I actually code not too often at work as well, but I've never coded where I can't look things up or take my time. 
Each of mock_datetime.now().replace(hour = 12).isocalendar() # doctest: +ELLIPSIS mocker.result((2009, 24, 3)) and mock_datetime.now().replace(hour = 12).isoformat() # doctest: +ELLIPSIS mocker.result('2009-06-10T12:30:39.812555') cause mocker to expect each part of the series of functions will be called once. So `datetime.datetime.now()` and `datetime.datetime.now().replace(hour = 12)` are both expected to be called twice, while `datetime.datetime.now().replace(hour = 12).isocalendar()` and `datetime.datetime.now().replace(hour = 12).isoformat()` are expected to be called once.
thank you
I won't flame you for incorrect subreddit choice, but I will instead recommend /r/LearnPython for future posts like similar to this one :)
The solution to this problem is to make `mock_datetime.now.replace(hour = 12)` return a mock object, and then call each of `isocalendar` and `isoformat` on that object.
There will be lots of very specific questions about things you never cared to remember, because either your IDE will cater to you or it will be obvious with one run of the code which way it is.. or you have your ipython window to find out. So basically try not to sweat too much and don't make it too serious for yourself, it will suck.
python2.7 + requests import requests for item in requests.get("http://api.bitcoincharts.com/v1/markets.json").json(): if item["symbol"] in {"localbtcGBP", "mtgoxGBP"}: print "{item[symbol]}: {item[bid]}/{item[ask]}/{item[low]}/{item[high]}".format(item=item) 
May I ask why?
Am I right in thinking using requests would mean I wouldn't need to use .read() and .decode("UTF-8") ? :)
That's badass. Is it going to tweet the n word?
First, don't sweat too much about the interview itself. Have they told you whether you'll be coding on a whiteboard or on a computer? If the former then it should not be a test of stuff you could look up in 20 seconds using google or your python interpreter. If the latter then these tools should be available to you. For example, if you're merrily coding away on the whiteboard and you can't remember something. Say "So I need to do a regular expression and I can't remember is it re.sub or re.replace and which order do the arguments come in?" And they'll either say "It's re.sub(pattern,replacement,input), but don't worry about it" or "I never remember either but let's say it's re.replace(input,pattern,replacement)" or they'll glare at you and say "We expect you to know this" ...in which case they are idiots and you probably don't want to work for them anyway. See http://www.joelonsoftware.com/articles/guerrillainterviewing3.html for some insight from the other side. Now you said you want some practice. Good idea. How about these 1. Traverse a filesystem and print a list of all filenames that contain upper case characters 2. Do the same thing without using the library function that does it for you. You can list directory contents and use functions to determine whether directory entries are files or directories, but that is all. 3. As above but rename any uppercase files and directories to lowercase equivalents (careful!) 4. Process a web server log (or similar) to produce a csv file with two columns. The first must show the date, and the second must show the number of hits to the server on that date. 5. As (4) but now I want a unique visitor count for each date. For the purpose of this exercise IP address will suffice for uniqueness. You'll have to ask someone else about application deployment. Hth.
Kivy is really good. It is still in rapid development so stuff changes faster than other projects, which can be either a downside or an upside depending on your needs. The community is also growing around Kivy, so I think over time it's more likely that you'll hear people "rave" about it. In my experience Kivy is mature enough to use in a professional setting - about 1/2 to 2/3 of my previous job was developing Kivy apps for android and/or ubuntu.
I appreciate you replying. Thanks for the tips! The interview will be over the internet using a website that provides a shared coding interface so they can see as I type. 
The aside you mentioned; a package to abbreviate text for maximum compression, I think I'll give that a crack for fun.
I've put this into a gist here: https://gist.github.com/anonymous/7942717 Just a note for the future, If you want to show some code, doing so in a gist, link to github repo, or even pastebin is superior to screenshots or the reddit comment box. People can copy &amp; paste it, or even make a copy of it and suggest changes (gists, github) back to you, and it gets presented with nice syntax highlighting.
Have a look at [Camelot](http://www.python-camelot.com), it makes using databases, Qt and Python really easy. You can use an sqlite database file as a 'library'. 
Draw separator like this: &gt;&gt;&gt; print("-" * 79)
Be sure to start the tweets at the end of the book, so that they're in the right order at the end of the year.
I've never had that before - good luck! Presumably you can talk to them at the same time. The exercise *should* (...though I can't vouch for the company...) mainly be about how you approach new coding problems, and interact/communicate with others about those problems, rather than being about getting everything 100% right. It shouldn't be bad to make a mistake - if they point one out say 'oops my bad' and fix it. Or be prepared to politely and open mindedly defend your ground if you think what you've written is correct. And don't be afraid to ask for a moment to think about a problem. Presumably they want to hire careful sysadmins not cowboys.
&gt; I've never coded where I can't look things up or take my time. Make sure you talk through your thought process and steps so you can be having a conversation with the interviewer about what you're doing. Also, have you considered giving yourself some problems with a time limit, just to see what it feels like to work with a bit of time pressure?
Cutiepie. 
&gt; Pythons standard urllib2 module provides most of the HTTP capabilities you need, but the API is thoroughly broken. It was built for a different time  and a different web. It requires an enormous amount of work (even method overrides) to perform the simplest of tasks. In this case he just fetches the URL, so there is no huge direct benefit of using requests. As soon as you have more complex API calls, requests provides a much cleaner and simpler interface in comparision to urllib. import requests req = requests.get('https://www.bitstamp.net/api/ticker/') print(req.json())
I haven't expected this, but I inotify is not a good fit for my use case. I'll use this to build an hybrid AWS Glacier/S3 incremental backup system, with archives containing new files/librsync delta on Glacier and meta-data (the index) on S3. I want to be able to detect changes from a time A to a time B without having a process watches changes.
Even though it's not finished, as you say, I actually found it quite useful and easy to read. Thanks! :D
Don't over complicate things, you are building a website for a class not high-traffic website. Using Django on Windows shouldn't be too hard. * Install Active Python * update pip: `pip install -U pip` * install virtual environment: `pip install virtualenv` * create a virtual environment: `virtualenv myenv` * activate the environment: `cmd.exe /k myenv\Scripts\activate` * install Django: `pip install Django` * start a new project: 'python myenv\Scripts\django-admin.py startproject myproject` * Change your Django settings file to use sqlite3 as the database driver. * Follow the rest of the Django tutorial * When you are done developing serve you site with a pure Python server like [waitress](https://github.com/Pylons/waitress)
It's all worth it when you read it alone at the end of that year and convince yourself someone else sees it.
There's so much of that on Twitter, who's going to notice?
We don't support Python 3 yet (at least not pushed on github yet -- soon). However, the type declarations are richer than the built-in annotations: this package supports exceptions, overloading, generics for containers, type parameters for methods &amp; classes, union/intersection, interfaces etc. Python 3 function annotations are only function parameter and return types.
You shouldn't have many problems if you're using Apache - trying to deploy on IIS is a pain. It's been a year or so since I ran Windows, but IIRC I had to install PIL and (I think) lxml from binaries instead of through pip, and manually linked them into my virtual environments.
I used this book as an introduction to algorithms in Python. I have the hard copy and I carry it with me almost every day (but don't always use or need it.) - highly recommended.
I did something similar using watchdog module http://brunorocha.org/python/watching-a-directory-for-file-changes-with-python.html
There is also video version: (3 parts) http://blip.tv/pycon-us-videos-2009-2010-2011/a-curious-course-on-coroutines-and-concurrency-part-001-2006228 http://blip.tv/pycon-us-videos-2009-2010-2011/a-curious-course-on-coroutines-and-concurrency-part-002-2005913 http://blip.tv/pycon-us-videos-2009-2010-2011/a-curious-course-on-coroutines-and-concurrency-part-003-2005963
Thanks, that's great to hear. How difficult would you say it might be for a person with other extensive GUI toolkit to pick up Kivy? Also, does it have a decent (true) rich text widget? Any "showstoppers" that you encountered? 
That is the end goal of standalone. It is not yet there yet. This is only the first release that offers standalone mode. Kay, author of Nuitka
It should, it is very compatible. The only know problem right now is PySide, but PyQt works. I think I would know if NumPy was not working. Kay, author of Nuitka
Language and run time compatibility and I believe Nuitka generated code is also faster, but I didn't look at Cython at all lately.
I've started to add solutions to this myself and it would be lovely to have other people to help as well as get help from. 
Arm works perfect, ever since. Android has been done, but not by me. One guy said he managed to use Kivy with it on Android. That's also a place, where it will be very useful, to deploy Python programs to phones.
The git branch factory should have workable standalone code for Windows. I am going to make a new release that will do Windows as well in the coming days. Initially standalone was only handling standalone modules that load other DLLs on Linux, but it will now do that on Windows as well.
I should hope so, it's in the book.
upon entering "new bork" I get the following error report... Traceback (most recent call last): File "D:\game.py", line 445, in &lt;module&gt; nextDay(); File "D:\game.py", line 35, in nextDay gamePlay(); File "D:\game.py", line 42, in gamePlay playerTurn(); File "D:\game.py", line 58, in playerTurn tryCommand(args[0], args[1]); File "D:\game.py", line 81, in tryCommand createSpecies(argument); File "D:\game.py", line 123, in createSpecies elif (len(speciesList) &gt;= MAXSPECIESPER): NameError: global name 'MAXSPECIESPER' is not defined *edit: formatting...
I live near the Mark Twain library -- any interest in having your book live there ( assuming they are ok with it but I can't imagine they'd say no) 
It's a private group
The n-word occurs 9 times in Tom Sawyer. TwainBot has abbreviated it as "n**". As the subject of racism in Twain has been a fierce debate at times, I decided a bit of deference was the better option.
Alternative that I thought of: Storify the whole thing back in to a book
Awesome, I thought that was a cool idea too! Hit me up on github/twitter (@jradavenport) or my main website [ifweassume.com](http://www.ifweassume.com) if you do! I'd love to test it out!
I'll remedy that! It should be completely public now. 
Unfortunately, it is common in everywhere land. python is easier to read than some others, but only when the coder followed convention or at least some kind of discernible standard. I know your pain all to well...
This is not specific to python, it's unfortunately very common in the industry. Python's saving grace is indeed that it's easy to read and understand, but it's not an excuse for sloppy standards.
What about that sentence in Huck Finn that spans more than a page? So much for 140 characters.
Oh, whoops. Sorry about that, that was leftover from a system I tried implementing that I thought I removed completely. Just add at the top of the file, "MAXSPECIESPER=100" or something, should fix it!
You will most likely just be writing pseudo-code. The point of a programming exercise is to determine that you can correctly solve the problem, not to determine that you know every little bit of syntax. 
I just commented out those two lines and tried it some more. I created two species successfully but after I attacked one of them I didn't get returned to a cursor. I pressed RETURN and got some other error. version 2.7.2 BTW
still says I need to join. I'd like to browse it before committing to join anything.
Gotta love all these guys telling you it'll be pseudo code. Did your employer say it would be a hot test or whiteboard? Get your THOUGHTS straight first. Keep a calm, clear mind and focus on the problem itself. Then remember: python's dir(object) should give you more or less what you need to do common tasks. You're going to need to know os.*, and file i/o, string.split/replace and- I have no idea what to expect for "application deployment" - deployment is what happens AFTER the code is done- so think long and hard about that one too. Practice. And best of luck. 
I wrote an asyncore HTTP/1.1 proxy server in a state machine fashion. I feel your pain
Well, you could just join it directly and then leave the group just as quickly. That's essentially two mouse clicks extra. I hope that's not too much of an effort :) The current state is that I've just added some solutions to the exercises in the book. But it would be nice to find others who are actually working with the book. Either way I really recommend that you check out the book if you're keen on learning more about algorithms. 
A couple of thoughts from looking at the code: * Python doesn't need semicolons at the end of lines. It allows them, but the program will work just them same without them. * You could probably simplify the code by making a Species class, with the species stats stored as attributes. So `sig(s, 3)` could become `s.aggression`.
As I mentioned above, long sentences get broken in to &lt;140char chunks, splitting at whole words.
Yeah, there might well be something to that notion, but this project was first about building the bot and second about exploring the interface of art/literature and the web/social media.
Lol good point
[This](http://docs.python.org/2/howto/sockets.html) would probably be the best place to start
First confirm that netcat doesn't do what you need.
Or socat
The issue in Python-land is that there are Python libraries which are composite C, FORTRAN, and Python, and other libraries depend on these. E.g. Scipy and Pandas BOTH depend on Numpy, and you cannot take a Scipy that was built with one set of compiler flags on build system A, and mix it with a Pandas that was built with a different set of compiler flags on system B. (It actually gets even more complicated then that.) From a social perspective, the challenge is that many users of these libraries do not have any idea of how complex this actually can be and all the ways it can fail. So, when they do some installation process and it works, then they develop a bit of lore about "how to get this stuff installed". But then they tell their buddy, who perhaps used Macports Python and Numpy, or maybe is on Windows, and then everything fails horribly, and then there is lore that "Scipy is impossible to install" etc.
Qt and PyQt or PySide. (I'd probably use PyQt.) Also you might be interested in ENAML: https://github.com/nucleic/enaml
I don't believe there are any leading candidates in this area (that i've heard about anyways). I wrote something quick and dirty the other day within this space as a learning exercise for descriptors (few features and not entirely a "state machine"). I put up a quick gist of it [here](https://gist.github.com/ahawker/7950216) if you're interested.
An [updated fork of django-wsgiserver](https://bitbucket.org/davis/django-wsgiserver/) is working for me. It uses CherryPy's WSGI, so it's pure Python and easy to install. My requirements.txt looks like: &gt; django==1.6 &gt; https://bitbucket.org/davis/django-wsgiserver/get/tip.tar.gz#egg=django-wsgiserver.0.8.1 And I run it in a virtualenv like: &gt; venv\scripts\python.exe manage.py runwsgiserver host=0.0.0.0 port=80
What have you tried?
[Scapy](http://www.secdev.org/projects/scapy/) might be of help. Scapy is a fantastic library for all things packet related. You could do this in a few lines of code (assuming I am interpreting your problem correctly that you wish to *relay* packets and not entirely redirect them) Off the top of my head (syntax may be off), while 1: sniff(filter = "tcp and dport == YOUR_PORT", prn = lambda x: some_function(x)) Will sniff any packets with a given TCP destination port, and then give them as input to the some_function, which you can also write quite easily to modify the packet and resend it as needed. The reverse is a similar matter, just start another thread and do while 1: sniff(filter = "tcp and dport == OTHER_PORT", prn = lambda x: some_other_function(x)) As a caveat, the send() and sendp() functions don't behave very nicely with self-directed packets, you may have to write to the socket directly, but this is a good way to *capture* the packets. 
Thank you!
Cool thanks man
If it's over the Internet then you can just look stuff up right?
If you are on a recent version of Linux the "TEE" target in iptables will do this rather nicely: &gt; TEE &gt; The TEE target will clone a packet and redirect this clone to another machine on the local network segment. In other words, the nexthop must be the target, or you will have to configure the nexthop to forward it further if so desired. To forward all incoming traffic on eth0 to an Network Layer logging box: &gt; &gt; -t mangle -A PREROUTING -i eth0 -j TEE --gateway 2001:db8::1 (from 'man iptables' on Ubuntu 12.04)
Oh, I did something like this. It's actually been running in production for over a year now. http://paste.lisp.org/display/140467 It's written for an app that will connect and send some data along the lines of "I want to talk to host.domain.com:2525" and this script proxies the connection to host.other.different.domain.com:2525. If I could do it again I'd probably use the daemonize module instead of rolling my own, but on the whole it's been solid. Edit: wow, just read it over. This was like the product of 20 minutes, but still, it's a mess.
Perhaps have a look at alternative data structures, like btrees? I guess algorithms in games (eg z buffer handling ) or GIS systems would be your best starting points, also structures of handling sparse data, depending how populated the grids are. 
I really don't know the internals of Ruby gems and bundler, but these scenarios do seem to work there. Many gems contain C and other code besides Ruby, and they'll compile these pieces on the user's system during `gem install`. It sounds like Python doesn't defer compilation like this to the user's system?
Adding on - http://twistedmatrix.com/documents/current/core/examples/#auto2 basic echo client/server, and relaying would be slightly trickier as you'd need to have some sort of simple stack/queue sitting between the echo and relay services. Probably 100 lines of code or less depending on protocol and stability needs.
Any reason why you wouldn't use anaconda python? 
Oh wow I had never heard of that until now, thanks!
lol
Oh man, that is freaking cool!
Nice, thanks for sharing this. I have no doubt I'll be finding it useful in the near future.
But the vast majority of the time, I want to only delete items from a list that were already in that list. If I try for some reason to delete an item that isn't there, something is wrong. If list.remove did not throw an exception, I'd have to write code like this: if item in my_list: # O(n) operation my_list.remove(item) # O(n) operation else: raise ValueError('%s not in list' % item) which is inefficient - I have to look through the list twice, once to see if it's there, and once to remove it. 
thanks. I wasn't sure . 
Thanks - [that works great.](https://github.com/weblaws/mctop/commit/b40c303a62e82b2135d09fc799ee61e4afc25512)
Updated, I love PyDev!
Well I'm not sure about adding them, but if you know you need a set number you could always try hiding frames and then using the button to make them visible.
But... Why.
You can do: &gt;&gt;&gt; mock_datetime_obj = mocker.mock() &gt;&gt;&gt; mock_datetime.now.replace(hour = 12) # doctest: +ELLIPSIS &lt;mocker.Mock object at ...&gt; &gt;&gt;&gt; mocker.result(mock_datetime_obj) &gt;&gt;&gt; mock_datetime_obj.isocalendar() # doctest: +ELLIPSIS &lt;mocker.Mock object at ...&gt; &gt;&gt;&gt; mocker.result((2009, 24, 3)) &gt;&gt;&gt; mock_datetime_obj.isoformat() # doctest: +ELLIPSIS &lt;mocker.Mock object at ...&gt; &gt;&gt;&gt; mocker.result('2009-06-10T12:30:39.812555') You can then do &gt;&gt;&gt; now = datetime.now() &gt;&gt;&gt; then = now.replace(hour = 12) &gt;&gt;&gt; then.isocalendar() (2009, 24, 3) &gt;&gt;&gt; then.isoformat() '2009-06-10T12:30:39.812555' &gt;&gt;&gt; mocker.restore() &gt;&gt;&gt; mocker.verify() Is this what you're looking for? 
Are you using [this](http://matplotlib.org/xkcd/gallery.html)?
A set number could work, but my original requirement was to allow infinite potential entry widgets. At this point I could make it work by hiding frames and displaying them as needed, but I am curious if there is a way to do it. I had the thought of putting the entry widgets in a list, and appending new entry widgets to the list on the click of a button, but I couldn't get my list to display the newly appended items. 
Yes, but only to [initialize](https://github.com/econpy/google-ngrams/blob/master/xkcd.py#L21) the styling. The rest of the [xkcd.py](https://github.com/econpy/google-ngrams/blob/master/xkcd.py) file establishes the matplotlib settings needed to reliably create plots coming from the CSV files outputted by the [getngrams.py](https://github.com/econpy/google-ngrams/blob/master/getngrams.py) script. Relatively speaking, the code that retrieves the data is more interesting than the code that plots the data. The XKCD style plotting is just something extra I whipped together whereas the getngrams.py file implements almost all available features found in the web interface for the Ngram Viewer in a command line tool.
Blueprints took me a bit to wrap my head around too, but once I finally got one working I realized I was over thinking the whole thing. You write blueprints exactly the same as you do normal routes and views, they just use an instance of Blueprint instead of an instance of Flask. Here is a simplified excerpt from one of mine: app/users/views.py: from flask import Blueprint # create an instance of a blueprint with the name 'mod' mod = Blueprint('users', __name__, url_prefix='/users') # all urls will be prefixed with '/users' ( i.e. 'example.com/users/&lt;route&gt;') # define any routes per usual using 'mod' instead of 'app' @mod.route('/login', methods=['GET', 'POST']) def login(): pass @mod.route('/logout') def logout() pass app/views.py: from app.users.views import mod as usersModule app.register_blueprint(usersModule) I then keep the templates for my users blueprint in app/templates/users/. I think there should be a way to keep them in the module itself, but I prefer to keep all of my templates together. If you have any questions /r/flask or #pocoo on freenode are both pretty helpful.
Can't you just set the callback action of the button to do entry.pack() ? 
For a semi-related project where I made a object mapper for Redis, tier one of the unit-test suite spawned a temporary redis instance. Perhaps something similar, looking on PATH to see if memcachd exists and having it run for the tests ( it's fairly trivial to wipe memcache clean between suites ).
I don't really think I deserve to be shot down like that, do I? I'm actually trying to share my knowledge and help others and I'm reaching out to people and just asking if they'd like to share some of their knowledge. Help each other out, you know. 
That seems more like and example as opposed to an explanation.
I'm still really new to Python. How will learning algorithms help with a new learner? I have zero programming experience, but I'm trying to grab as much free learning materials as possible. Will this be way over my head?
&gt; the problem comes into play when I try to wrap my head around full-duplex port redirection. Which part? If how a connection is made, then if you're acting as a proxy then one of the sides should initiate it, i.e. you're listening on port 666, when the connection is accepted you connect to the target IP:port (through some randomly assigned local port). Or if you're acting as a sort of a NAT traversal proxy, then you listen on both ports but don't read any data until both ports have been connected to. If your problem is how to move the data around, the easiest way is to just spawn two threads, one reads data from one socket and writes it to another, the second does the same in the opposite direction, bam, done! More complicated solutions using `select` are not worth it, IMO, because unless you do some black magick (I don't even know how) your thing can easily deadlock: suppose one client sends several packets before waiting for any responses (but is listening for responses anyway, so without your proxy everything would work OK), the other client receives and process one packet and tries to send a response, but your proxy is waiting for him to read the second or third packet (depending on his buffer size). I mean, it's OK if you did not understand a word in the previous sentence, just use threads =)
Um, just add a new entry the same way you add them when creating a widget, in your callback. It should work.
Furthermore, it's wrong. In the first example, print res.group(0) will result in 770-0047 (0) means a whole matched expression -- (1) is the actual first group in parentheses.
[OpenMDAO?]( http://openmdao.org)
Learn the basics first. A good resource is [Think Python](http://www.greenteapress.com/thinkpython/), a free pdf download of a really good book. Then come back to this book.
Here - [Stop Writing Classes](http://pyvideo.org/video/880/). I think you need to watch this.
or try Jython.
I wonder if these posts on regular expressions are an attempt to get people to explain the concepts to the OP.
[This one](https://github.com/ajalt/fuckitpy), for sure.
All of Twisted.
[Requests by kenneth Reitz](https://github.com/kennethreitz/requests) is great.
Hey man, seriously thanks for all that, there is definitely some things that you've mentioned that i need to look more into and learn properly. Sadly won't really have enough time to get a good look at how this all works until Monday but i can honestly say i'm rather excited to give it a good look over! Thanks again, really appreciate the time you've taken to explain it :)
I'd suggest [sqlalchemy](http://www.sqlalchemy.org/), [github/zzzeek/sqlalchemy](https://github.com/zzzeek/sqlalchemy), which in addition to being very well written, performs a task that is often needed by many python applications.
http://docs.python-guide.org/en/latest/writing/reading/ is a good starting list.
The "Sorry dude. Lemmie think" was the icing on the cake!
Learn all of the time modules (especially arrow, it'll show you don't f*** around when it comes to dates), refamiliarize with regexes, timestamp processing, the os and sys modules, and file handling. Express code in list comprehensions or even dictionary comps (only where appropriate, list comps are not for generic `for loop` replacement as they waste memory in that use case), to show appreciation for python's expressive syntax. Use collections library.
I've always been impressed the parts of Werkzeug and Flask that I've read. https://github.com/mitsuhiko/werkzeug and https://github.com/mitsuhiko/flask.
I came here to say that.
It may be well written, but that level of metaprogramming is probably not the best for teaching.
&gt; Most of the basic concepts will carry over from language to language, unless you're going way out there and picking up something like LISP or Haskell Speaking as someone who knows all three languages, Python actually feels much closer to Common Lisp than to Java.
I also like OrderedDict for it's combining properties of existing data structures together.
http://github.com/pylons/pyramid or anything developed by Chris
Depends on the course. "Introduction to Programming", probably not a good fit. But "Metaprogramming in Interpreted Languages", perfect fit.
Okay, I'm going to try and take some online Java classes, or I'll ask my boyfriend for help. I hope it's not TOO different - thank you! :3
Oh, shit, I thought it might looking at the format.
that last example is really out there and way more advanced than the rest of the article. For those curious about many-to-many by itself without the addition of joined inheritance and association proxies, here's the [idiomatic example](http://docs.sqlalchemy.org/en/rel_0_9/orm/relationships.html#many-to-many).
Anyone wanna point me to a project that has good test coverage and could be used as an example of proper testing practices? (I try not to use the TDD acronym, but yeah...)
This looks really nice. I've been working on a similar project and may have to ditch my messaging layer for yours. My application is a bit different though, so I'll have to experiment. What I'm trying to do is get long-running numerical code to interact with javascript plotting toolkits within iPython notebooks. My architecture is a standalone zmq &lt;-&gt; websocket/sockjs pubsub bridge using tornado, and minimally intrusive code on the backend so people who know nothing about webapps can send data from existing scientific applications. Looking at the centrifuge code, I'm not sure if I can use the pubsub mechanism without forcing the backend code to run an ioloop, since it doesn't look like it expects messages to come or go from outside the tornado app. My current code mainly syncs variables between python and javascript - it uses descriptors to publish a new value on write or drain the sub socket on read. That way the backend doesn't need to yield or otherwise care that it's now networked. What do you think, is this something that can be built on centrifuge without major changes? Also, I was planning to write a binary websocket protocol to send numpy arrays to webgl apps without the overhead of json. Do you think it would be possible to add that as an alternate transport? edit: I just discovered the separate cent project. Maybe that can be mentioned more prominently than in the admin console section? edit2: After reading more, I seem to have misunderstood, you're supposed to publish over http and zmq is just internal transport. Is there any reason not to publish with zmq, especially with a proxy?
Sorry, missed out the [ when pasting the title :-) 
Does anyone know why some comments in Flask start with #: (note the colon), and not just #? For example: [Line 150 of app.py](https://github.com/mitsuhiko/flask/blob/master/flask/app.py#L150) I'm assuming this is used by Sphinx (or maybe not). I haven't seen this before though.
No. It's fucking fantastic and hysterical, but fuckit isn't something you should learn from.
My guess is that it's for a doc parser. Kind of like /** * This kind of comment in Java * (used by javadoc, I think) */
They invented the little arrow pointing upwards for that.
Saltstack
I'd recommend reposting with a title that's more descriptive of content of your question.
Those aren't reserved words. You get to pick any name you want when you write the loop, the same way that you get to pick any name you want when writing an assignment statement: foo = 42 A loop is conceptually no different, it's just repeated assignment to the same name: foo = 0 # loop body foo = 1 # loop body foo = 2 # loop body That is the unrolled version of this loop: for foo in range(3): # loop body The `foo` here is a name that you get to pick. It has absolutely no built-in meaning to Python. 
Yes it is used by Sphinx: &gt; For module data members and class attributes, documentation can either be put into a comment with special formatting (using a #: to start the comment instead of just #), or in a docstring after the definition. 
Oh, ok. That kinda explains my question. Thanks!
Python uses [duck typing](http://en.wikipedia.org/wiki/Duck_typing) to determine what the variable is. [Typing on Python wiki](http://en.wikipedia.org/wiki/Python_(programming_language)#Typing)
You could use simpy for the backend and the pyqtgraph flowcharts as the basis of a front end.
Yeah, honestly I didn't even know about classes until shortly after I wrote it, so I do apologize for that. EDIT: And as for the semi-colons, I've been told that before, and I'm fully aware Python doesn't need them, it's more of a personal preference. Since I work with multiple languages from time to time, I like not to stray from good practice, since most other languages do require them.
Hmm, I'll re-upload it with a fix. Sorry about that, should've been more careful before I uploaded it.
From the [FAQ](http://twistedmatrix.com/trac/wiki/FrequentlyAskedQuestions#WhydoesntTwistedfollowPEP8): &gt; However, Twisted prefers !camelCase for variables, functions, and methods (whereas PEP 8 recommends underscores) because Twisted predates PEP 8 and converting the entire codebase now is infeasible. Twisted continues to use its existing naming convention for new APIs to retain consistency within the project (according to PEP 8's recommendation). Or, for the long version, ask [A Tired Hobgoblin](http://glyph.twistedmatrix.com/2012/10/a-tired-hobgoblin.html).
I don't necessarily agree that it's fantastically written, because I don't know the source, but to say that it's popularity is due to marketing is crazy. They're pretty comparable, but requests does away with complication pretty well, I'd say.
[pyglet](http://www.pyglet.org/)
pycharm. For Django and JavaScript, you'll want the professional edition rather than the open-source community edition. It sounds like you've already looked around a little, but there are some [very detailed reviews](http://andrewbrookins.com/tech/one-year-later-an-epic-review-of-pycharm-2-7-from-a-vim-users-perspective/) out there.
I'm using PyCharm and I really like it, but you probably can do most of the stuff with other setups, too. The [Django Integration](http://www.jetbrains.com/pycharm/features/index.html#djangoIDE) is one thing that Pycharm sets apart, although you will need the Professional version for this feature. Other than that it's a matter of taste.
I've never really given Flask's code a good look, before. Wow, that is some concise stuff.
I was hoping there'd be video of his opening lightning talk from pycon 2013.
That's an excellent suggestion, especially about the sparse data. It's unrealistic that I'd have 45 billion data points, because if all LBAs are read/written on a given disk, it means my filesystem is full, and I have bigger problems, :-) I'll look at btrees as well. I'm not much of a programmer, but I like doing projects like this mainly to improve my terrible python...
Why is it crazy?
vim Always vim
All of the cool kids will scream Vim. Those who are serious will tell you PyCharm. Those who are not sure will say Sublime Text. 
Pycharm
Each type gets to decide how it wants to handle iteration. If you iterate over a string, you get each character. If you iterate over a list or tuple, you get each item in order. If you iterate over a dict, you get keys (in an unspecified order.) If you iterate over a set you get each member of the set (in an unspecified order.) If you iterate over a text file, you get lines. And so on. You can write your own types that do whatever you want when they're iterated over. 
python with batteries included: [anaconda](https://store.continuum.io/cshop/anaconda/)
I once heard a guy doing a presentation about Twitter data collection say that "requests" was a great module but it had a terrible name. I mean, a good module should have a name that is unique for search purposes.
What are better alternatives?
There are none but it's not an amazingly written piece of code is all.
Sure it's useable but it's not an amazingly written module is what I'm saying.
Ah, sorry, then I misunderstood you. Really should go to sleep.
At work I recently took over a Django project from someone who was departing the company and had to cut all ties post-haste due to conflict of interest concerns with his new job. He insisted that I should be using Pycharm. My experience so far is that the necessity of this probably depends on the size of the project you're working on. If you're working on a really big project it's probably a good idea--I don't have a ton of Java experience but Pycharm seems to organize your project in a way similar to how Eclipse organizes a Java project, which can be helpful. However if it's a smaller project then you can probably get away with using your favorite multi-purpose text editor and just using the Finder or Explorer (depending on if you're on a Mac or Windows) to deal with your file-browsing needs. I've been using TextWrangler, which can handle a whole boatload of different languages (including Python and HTML). I guess the questionmark here is if Pycharm is able to handle multiple languages within the same document; I haven't really looked that hard at it since I've just reverted to using TextWrangler. If it can, then yeah, it sounds like you should use Pycharm.
I suggest learning an editor where it doesn't matter which language you are programming in and has proven that is not just a fad. Learn emacs or vim and you will never need to ask which editor (ide) is best for X language. Both are advanced terminal text editors and they are capable of any feature X available in an ide (maybe even more... with emacs). 
I use Sublime Text 3 all round. It's pretty fast and supports all the languages I work with. It has some very cool features.
vim has a steep learning curve, and one that takes time. If you are willing to invest time (a month or so) to be comfortable, go ahead. PyCharm is made with web-dev (Django) in mind, so it would be ideal (considering there's also a free community edition). Sublime Text + the right plugins can be equally good.
Hello, thanks for such a response! Centrifuge uses ZeroMQ as one of internal PUB/SUB mechanisms for communication between multiple instances of Centrifuge, it can be easily replaced by Redis PUB/SUB or even no PUB/SUB mode in case of single node. So HTTP is an endpoint for publishing new messages to connected clients which is always available - regarding which PUB/SUB mechanism is in use at moment. I think I can add a possibility to listen special channels in ZMQ or Redis to allow publishing via them, do you mean that? If yes, why this is better than publishing over HTTP? About sending binary. I've never thought about it, as far as I know SockJS does not support binary natively, Centrifuge has raw Websocket endpoint but it also waits for JSON messages. Centrifuge is not just a broker which transfer data unmodified. Every publish message must have channel name, probably namespace and actual data. So the only way I see - encode binary to send it in JSON message (http://stackoverflow.com/questions/1443158/binary-data-in-json-string-something-better-than-base64)
If I'm understanding the question correctly, you're not actually using reserved keywords. Stuff like word and row (and certainly not **item** which I use all the fucking time as my generic list entry keyword when I'm feeling lazy) are *not* reserved variable names. That said, just use a Python-aware text editor if you find yourself having issues with trying to use Python-reserved variable names. They'll generally come up in a special highlight color which should should get you to realize that you're trying to use a reserved keyword and not a generic variable name.
Python doesn't care what you call things as long as you're consistent and you're not trying to use a reserved variable name (and from what I'm seeing you're definitely not trying to use a reserved name). For instance if I have a list a = [1,2,3,4,5] I could write for item in a: print item And I'd get back 1 2 3 4 5 But like I said, Python doesn't care what I type in for the variable name. For the same list a = [1,2,3,4,5] I could type in for bigtittycockfuck in a: print bigtittycockfuck And I would get exactly the same output as before.
 We take great pride in keeping the code quality very high and stable. It's my secret to reducing the amount of work and confusion I need to deal with in the future. :)
requests is a great example of good API design. I have no idea about the quality of the implementation code itself though.
+1. I learned a ton from zzzeek's code, and I still refer to it to this day. Although as Megatron mentioned, it is fairly advanced and possibly not the best starting point for a novice.
[enaml, a declarative gui on top of pyqt4 ](https://github.com/nucleic/enaml)
While I'm a big fan of Pyramid and use it as my primary web framework, I'm not sure it is the best example of idiomatic Python code. There is a lot of trickery involved in maintaining a very shallow stack depth and optimizing request calls. It does show some interesting things you can do in Python, though typically should not.
Eh, I think requests is the wrong tool for downloading large files. The [wget](https://pypi.python.org/pypi/wget) library is probably preferable. 
[urllib3](https://github.com/shazow/urllib3) maintains 100% test coverage (disclaimer: I'm the author). It has been very helpful in reducing the amount of work required for maintaining the project, and keeping releases stable and reliable.
Can you provide some examples of other forms of composition or link to doc? I am using subclassing a lot so I'd like to know about other options. 
Yes, I was hoping to use zmq (or redis) pub/sub instead of http. I think the latency will be much better, and that's also the only way to get binary to work. You're right that sockjs doesn't support binary, but websockets can handle ArrayBuffers (raw bytes), and zmq will happily take a byte array as part of a multipart message. Most users won't care about binary, but if you're moving numerical data to webgl, json is extremely inefficient. Even if I don't end up using your code, I certainly appreciate reading it because you've already found good solutions to the problems I haven't addressed yet, like authentication and encapsulating the javascript interface cleanly. 
i want the internet to start collecting and curating well written code from all languages. especially well-architected full stack applications. open source community has enough one-off libraries
You need an editor who allow you to program in Python but also edit CSS, HTML and Javascript. [Geany](http://www.geany.org/), is a good choice for this. It will lack the specific Django features than you may find in Pycharm but i find it to be a good all purpose simple editor/IDE. For complete IDEs more focused on Python programing take a look to [Ninja IDE](http://ninja-ide.org/) and [Spyder](http://code.google.com/p/spyderlib/). Ninja IDE have Django focused plugins (and a SublimeText theme ;) ). Spyder is more NumPy/SciPy focused but it can be used for anything Python related. 
this is fascinating. truly an awesome project. 
Check out Pyramid web framwork then.
The concept of a current working directory is a bad idea in general because it is really a global variable with all the associated baggage: hidden changes by libraries and lack of thread-safe usage. Creating a context manager is going in the wrong direction IMO. If you really want to download a file to a specific directory, then use a full path. I know that is just one example, but you should do everything possible to avoid changing the cwd.
Minecraft in Python: https://github.com/fogleman/Minecraft
I am currently learning Tkinter myself. Could you post the code you tried so far? (pastebin or sth) I think I did something similiar just yesterday.
I concur. It's best to leave the current working directory alone. PyFilesytem side steps the issue of current working directory rather elegantly. You can create virtual filesystems where the root maps to an arbitrary directory on your drive. It's threadsafe and there's no need to manipulate paths.
What's wrong with using `finally`? It was introduced just for cleanup, even after an exception: import os def download(li, folder): try: backup = os.getcwd() os.chdir(folder) for img in li: # download img somehow except: # problem with download, handle it finally: os.chdir(backup) def main(): # step 1: download images to /tmp li = ["http://...1.jpg", "http://...2.jpg", "http://...3.jpg"] download(li, "/tmp") # step 2: create a "process" dir. HERE (where the script was launched) os.mkdir("process") # ...do some extra work... And why do you use a bare `except`, without specifying what to except? Do you know every exception that can be raised inside that `try` block? Do you have an error handling for every exception? You usually don't, so you except the exceptions you know and leave the other ones unhandled.
You're saying that the core python and django developers using sublime are not sure? What aren't they sure about?
Context managers just abstract out any repetitious try-except-finally blocks. For example your code can't be nested without renaming the variables.
It's good for scripting - look at what people do with the fabric library .
Personally I prefer the aesthetics of context managers to try/finally, but with contextlib you can have both: @contextlib.contextmanager def chdir(dir): curdir = os.whatevercurdirisiforget() os.chdir(dir) try: yield finally: os.chdir(curdir)
Or libcurl. Which you get if you have curl installed, without the need to download something from pypi. 
Pycharm is good, but getting familiar enough with Vim to understand it is a good thing. It helps if you need to open something up on a remote server, etc. Textmate is decent, and it sort of tries to do it all, so some folks like that. It's not really terrible, but it's not amazing. While I do little python dev anymore, I use Rubymine (Both by JetBrains) and love it. But I still retain a great familiarity with Vim, because I need it for ops functions.
Sublime Text is my preference
Hi! I want your opinions on this - I made it to enable composition of simple metaclasses. Most that I've seen only change attrs and maybe add the created class to some register, both actions don't really need the full power of `__new__`, but have to override it anyway. So, here's a way to split `__new__` into smaller parts :-)
Depends on your data. You say Network, so it can depend on what you're comfortable with. I've used matplotlib and rrdtool. Both worked fine.
&gt; atexit functions will run no matter what. Even if I pull the plug from the computer? That's amazing.
If you are using a laptop, yes
Scipy includes some tools for working with graphs stored in sparse connectivity matrices, with fast implementations of some common algorithms. See http://docs.scipy.org/doc/scipy/reference/sparse.csgraph.html
Why is the first thing I see a big picture with ugly text written on it? That is not just bad webdesign, that is just sad.
Yeah... learning vim will actually be a waste of his time...
The basic idea of composition is arranging things so your new class "has a" instance of the old class (often as a private attribute) instead of declaring it "is a" object of the parent class. [Learn Python the Hard Way](http://learnpythonthehardway.org/book/ex44.html) mentions it near the end, and Mark Lutz's [Learning Python](http://www.safariflow.com/library/view/Learning+Python,+5th+Edition/9781449355722/ch31s03.html) has a section on this too. (This discussion is roughly as old as the notion of Object Oriented Programming itself. Many of the conversations you can find refer back to the *Design Patterns* book written in 1994, but a lot of those use Java examples and they can be hard to cut through for the Python student, as Java's lack of first-class-functions and the difference between statically-typed and dynamically-typed languages complicates the examples.) As for other tools, Twisted has made extensive use of [interfaces and adapters](http://twistedmatrix.com/documents/current/core/howto/components.html). Twisted uses `zope.interface`, and though I haven't read it yet, I've just found this [Comprehensive Guide to Zope Component Architecture](http://www.muthukadan.net/docs/zca.html). Eric Snow gave a talk on [Interfaces in Python at Pycon 2012](http://pyvideo.org/video/882/interfaces-and-python), and made [extensive notes](http://ref.readthedocs.org/en/latest/understanding_python/interfaces/) on various approaches to interfaces throughout Python's history. edited to add: See also Augie Fackler and Nathaniel Manista on [the End of Object Inheritance &amp; the Beginning of a New Modularity](http://pyvideo.org/video/1684/the-end-of-object-inheritance-the-beginning-of).
NetworkX is awesome and easy to use and good for many tasks. Graph_tool is harder to get installed and use, but is crazy fast for big tasks (i.e. 1M nodes, 100M edges or so).
Which is a complete train wreck. Try to parallelize some Fabric code.
I agree that Django's documentation, references, and ecosystem is second to none, but I would not include it in my list of exceptionally well-coded projects. The number of ridiculous bugs and design decisions I've run into with Django over the years has far surpassed any other project I can think of. Keeping code quality and design coherent for such a large monolithic project is certainly a huge challenge, which is why I prefer more modular and compartmentalized frameworks like Pyramid.
Looks like while you were writing this, I was writing a comment on the site on much the same subject. Good work, fellow Kevin.
Here's an interesting example: zipped = list(zip([1,2,3],[4,5,6])) unzipped = list(zip(*zipped)) unzipped == [(1, 2, 3), (4, 5, 6)]
i like [mike hibbert](http://www.youtube.com/playlist?list=PLxxA5z-8B2xm1yUDAh2_pXGWBTePjCa3n) more
The atexit thing - there are quite a few gotchas with it, so I tend to use with statements instead. for example: class doGenericThingThatLotsOfOurStuffNeedsToDo: def __enter__ ( self ): # start stuff def __exit__ ( self ): # endstuff with doGenericThingThatLotsOfOurStuffNeedsToDo(): # more stuff It's also nice because you can wrap your stuff in reusable wrappers. ninjaedit: It's not even just about gotchas. For me, it's quite frequent I want to run lots of scripts in a project with the same context, and doing other stuff before they start, and doing cleanup stuff. It's good to have essentially a big try/except/finally around a big block of code in a clean and consistent way.
Guys, a little help needed. Does anybody knows how to use getrusage on windows machine, it never works ?
I know, I've contributed to it
It's OS-specific... Unix only, not available on Windows. Sorry.
&gt; i mean, the kivy sub has like 4 posts! Well, for a start this is a terrible metric! There are very few large subreddits for this kind of project, you generally need a lot of people to build a subreddit with steady content. Regardless, I bet the general answer is a mixture of people just not having heard of it (the project is growing, but it's not really massive right now and is still gaining momentum), and the perceived downsides. To be clear, I like kivy a lot, but it isn't perfect and has some disadvantages compared to other toolkits. I guess the obvious big thing is that its widgets aren't really native anywhere - you can try and theme for a given system, but it will be hard to impossible to fit in with (say) the qt themes all your other apps might be using. This is a problem all the cross platform html5 toolkits also have in the mobile world, and is one of the main criticisms made of them. On the other hand, kivy has lots of advantages too, which I think are certainly contributing to a steady gain in popularity. It's under active development and is (in my opinion) very notably improved from even just a few months ago, so it might be perceived to be maturing a lot as well.
&gt; Some useful stuff for Python hobbyists. args/*kargs for example is something many people won't expect. Not sure I follow - I've seen args &amp; kwargs in plenty of code written by professional python programmers. It's incredibly useful for writing reusable and high-level code.
&gt; Not sure I follow Yeah, you don't :P A professional Python programmer already knows args/kwargs.
This depends greatly on scale and the problem you want to solve. Do you want to compute pagerank on the interent or render an image of K3,3? Other than networkx there's Gephi as a standalone tool, neo4j as a database, and vivagraphjs, jsnetworkx, and ubigraph for web-based interactive visualization. 
1. You should like py3 more than py2. Its a legit improvement. Especially if your new to the language. The only reason its not currently more widespread is the amount of legacy code out there (libs, frameworks, etc) 2. if 2.x crashes and 2.y doesn't then your install is broken or corrupted. 
Well then any other way to find memory and cpu usage ?
I had every intention of learning Kivy. By all accounts, it's really efficient and covers both touch and desktop interfaces really well. When I saw this covered across 9 articles in the newsletter [Python Weekly](http://www.pythonweekly.com/), the less I wanted to learn Kivy. Not because it's not a great toolset, but because a basic application required 9 tutorials. 
As a somewhat python newb, can somebody explain what the heck is going on in the "Debugging" example? Code: `import logging, inspect` `logging.basicConfig(level=logging.INFO,` `format='%(asctime)s %(levelname)-8s %(filename)s:%(lineno)-4d: %(message)s',` `datefmt='%m-%d %H:%M',` `)` `logging.debug('A debug message')` `logging.info('Some information')` `logging.warning('A shot across the bow')` `def test():` `frame,filename,line_number,function_name,lines,index=\` `inspect.getouterframes(inspect.currentframe())[1]` `print(frame,filename,line_number,function_name,lines,index)` `test()` I've never used either of the 2 modules before. I don't quite understand what this code is doing. It did run and gave me the same (similar) printout that the author got. Seems to be listing the files in my script directory with a message and a time stamp?
Why are developing in windows? That's your first mistake. Fix that, then come back.
Could it be causing the errors?
I for one am glad it has 9 tutorials, as opposed to, say, Django which has just one. UI programming is hard. One tutorial doesn't cut it. 
It's primarily billed as a mobile framework, and python developers don't seem to care about mobile apps. It's also really good for games (and mobile games!), but it's hard to get started with because most of the tutorials and examples are all either 1) trivial, or 2) complicated UI heavy mobile apps. I suspect the sweet spot of 'mobile game platform with cross platform support and good distribution story' isn't what people see when they visit the page. They see 'make non-native rich ui apps, why would I want to do that?' 
The caveats to atexit from the docs: &gt;Note: The functions registered via this module are not called when the program is killed by a signal not handled by Python, when a Python fatal internal error is detected, or when os._exit() is called. 
Inconclusive symptoms. There could be many causes for the bluescreens - you need to enable memory dumps and analyze them. It's easy enough and makes a world of a difference - check [this](http://www.ehow.com/how_5349981_read-screen-death-minidump-files.html) or [this](http://www.techrepublic.com/blog/windows-and-office/how-do-i-use-windbg-debugger-to-troubleshoot-a-blue-screen-of-death/)
1. [logging](http://docs.python.org/2/library/logging.html) is just a way to output messages in a standard format, often to some log repository (e.g. a file, a syslog, whatever) for possible analysis (or not). It's a bit complex to approach but I think well worth learning and using. logging uses a message format to know how to print its message, the message format can make use of (and display) a bunch of meta-information e.g. where the logging message comes from. 2. [inspect](http://docs.python.org/2/library/inspect.html) is used to analyse stuff about the interpreter or core objects of the interpreter. In this case, it gets [the current stack frame](http://docs.python.org/2/library/inspect.html#inspect.currentframe) (I'll let you do your own learning to know what a stack frame is), then fetches [its first parent](http://docs.python.org/2/library/inspect.html#inspect.getouterframes) which is the frame of the module itself. Then it prints a bunch of stuff about said frame. In day-to-day operation, there are very very few sane reasons to use `inspect` unless you're doing "meta" packages (reasoning about Python code and functions, e.g. py.test's fixtures probably use `inspect.getargspec` or one of its sister functions)
What IDE is this?
## Functions with Arbitrary Number of Arguments Others have already commented (and noted that `**kwargs` exists and is a much rarer breed than `*args` which is a fairly standard varargs). It can be combined with `*args`: `def foo(a, b, *args, **kwargs)`. Note that Python 2 has a limitation which has been lifted in Python 3: you can't provide a named argument after `*args`. That is, `def fun(a, *args, b)` and `def fun(a, *args, b=3)` are illegal constructs. In Python 3, they are legal and `b` is called a keyword-only argument, something which was only available to C code in Python 2. It's an explicitly named argument which can only be passed by keyword (since all the positionals are eaten by `*args`). Python 3 also allows keyword-only argument without positional varargs: `def fun(a, *, b)`. Since the `*` argument has no associated name it can't be filled (it has a length of 0), this function takes a mandatory `a` (which can be passed positionally or by keyword e.g. `fun(3)` or `fun(a=3)` and a mandatory `b` which can only be passed by keyword. ## Using Glob() to Find Files The author uses `it.chain.from_iterable` with `glob`. In this case, `iglob` would be a better idea as it returns an iterable, if only some values are used it may lead to increased memory and CPU consumption compared to `glob`. More importantly, `glob` has limited usefulness but the underlying function of matching strings with shell-like patterns is available through the linked [fnmatch](http://docs.python.org/2/library/fnmatch.html#module-fnmatch), and that's really cool. ## Debugging `pdb` (or one of its replacements e.g. `ipdb` or whatever) is probably a much better idea than shooting for `inspect`. As its name indicates, `inspect` is used to, well, inspect core objects of the interpreter. For the most part, `inspect` is good for learning about the depth of the interpreter (alongside `dis`) and little else... ## Serialization [pickle] UNSAFE WARNING WARNING. Pickle is only for trusted storage or signed stuff, it's a fairly complex binary format and is essentially equivalent to `eval`. JSON can be used for non-trusted sources, Pickle definitely can not be.
If you have zero programming experience I would suggest that you check out Udacity CS101. It's a great course and it will give you a firm foundation in both python and CS concepts. After you've completed that you can think of trying to learn algorithms. But I guess it really depends on what you'd like to do as well. Web development for instance doesn't require that much algorithms. 
Perhaps try the [psutil](https://code.google.com/p/psutil/) library.
This honestly seems like a very strange criticism. Do the articles say that no part of kivy could possibly be put across in fewer articles, or claim direct learning correspondence with a single tutorial for some other framework?
I figured I would post this in Kivy subreddit later, but I'm currently working on a mobile app in Kivy in my spare time. I've got the core application logic done so far and all that is left is 1)spit-shine-polish the interface 2)incorporate ads and 3)package Android/iOS. It's been pretty painless so far, but the worst may be yet to come. I've found some resources much more helpful than others. If I had to recommend three resources for learning/using Kivy they would be: 1)http://kivy.org/docs/gettingstarted/examples.html -&gt;A list of all the examples that come included with the Kivy install. It's been unbelievably helpful to search the page for roughly what I'm looking for and then open up the corresponding example. This saves me a lot of time and means I don't have to guess my way through 30+ examples to find the one I want. 2)This blog: http://karanbalkar.com/tag/kivy/ -&gt;Having not done GUI programming in a long time, this blog really helped me. It's filled to the brim with a number of good, simple, and useful examples. I'd recommend this for anyone trying to create an app in Kivy. 3) The Google Group. https://groups.google.com/forum/embed/?place=forum/kivy-users#!forum/kivy-users -&gt;Odds are good that someone has already asked the Kivy question that you have floating around in your mind. Searching the group has yielded some invaluable information about Kivy specifics and the future of Kivy development.
It's just highlighting on the page. No IDE. Reminds of Sublime Text but that's probably because of the background color, since Sublime Text uses a different color scheme for the text
So what ? I am sorry to confess that I am to lazy to download, unzip and read it in my favorite text editor. I am sure I am not the only one...
I dont use it because we already have a very good Qt wrapper for python which give us QML which is kinda the same thing as kivvy just way way more mature and bigger backing.
My sentiments exactly. If it was on github, I am just one click away from browsing and reading the code. 
Edit: I'm totally using this, thanks to links posted by PyFun Here's my thoughts: 1.) It's new and not 100% tested. 2.) Before this post, I'd never heard of it. 3.) I might use Kivy, but I don't have a need for it right now. Don't get me wrong, I took a quick look at the Pong tutorial, and I think Kivy could be a great tool. But Each of the three points are issues that need to be addressed eventually, but number one probably should come first. Want to see Kivy get more attention? Make a tutorial that demonstrates a good use case. If it's a new technology, you could be one of the few earlier adopters that creates the popular tutorials. 
Is there a tutorial anywhere that gets into the meat of python like this? As someone who understands all the basics this is completely and utterly over my head.
Thanks.
The problem with pycharm for some people, depending on your os, is that it can be horrendously slow, linux (ubuntu) seems to be the biggest offender there, if speed isn't necessarily that inportant for him then pycharm is a good choice. 
The thing with vim is that setting it up can be a pain if you *need* more than the basic functionality, once it's set up it's great though.
If I may be so bold. I found this [guide](http://simeonfranklin.com/blog/2012/jul/1/python-decorators-in-12-steps/) to be very helpful when learning about decorators. 
Pyalgotrade and Quantopian are good for backtesting. For the "realtime " trading mechanism.... I always end up writing that myself. Basically I have one process doing data intake into a db and another doing the periodic analysis and trading. The biggest problem is finding enough cores to let it run without user interference. *just another developer trading paper on bitcoin.
so it uses fabric underneath. ok. does it take care of installing the database? and any other python dependencies on the deployment target? updating the nginx config? restarting associated services (celery et al?) I admire the attempt to make deployment scenario easy, but there is a reason tools like chef and ansible etc are complicated(though I personally think ansible is the simplest I've used thus far) But the problem of deployment is complicated thus the tools are complicated. Honestly, the simplest deployment method I have used is appengine. But the reason for that is all choice has been removed. You choose one of 2 databases and everything else your app depends on is either deployed with it(python deps) or provided by the platform. If it's not a python dep, and the appengine platform does not provide it, you are SOL. 
Python internally passes functions a tuple and a dict as arguments and keyword arguments respectively. `*args` and `**kwargs` expose this detail to both the function caller as well as the function definition. They are just normal tuples and dicts that you can manipulate as usual.
It installs all packages that are really needed. You can also specify postgresql as a separate dependency (and by the way there's also the possibility to write bash yourself within a depl configuration file). Depl could probably solve 95% of all deploys (if the feature set would be expanding, obviously it's not possible yet to deploy ruby or celery).
debian only? if you expand the feature set, it will probably start to look like ansible. 
For what it's worth, the master branch is python3 compatible, which will be in the next stable release (currently in milestone bugfix stage).
For now it's probably even Ubuntu only, but it shouldn't be a big amount of work to get debian running. The same is probably true for Arch and Fedora. The reason for Ubuntu only at the moment is my use of it and travis-ci using Ubuntu VMs, so it's hard to test the other machines properly (and repeatedly).
Generators **rock**.
Yeah, I guess there are a few bugs still. On the bright side I think the faq is just horribly out of date (I'll take a look at that...), python3 support really is nearly there. 
When it's needed and used correctly Metaclasses are awesome. I like how they were applied in Django's ORM for models. Also look at some open source python projects and look at how things are done. I'm not sure what your background is, but if its a C# or C or Java background you'll notice that different patterns are used and styles due to how high level of a language it is. Decorators can be useful. Check out the PEP8 coding standards, the company you're working at might define their own you need to follow. But it's a good place to start for keeping consistent coding standards in the community.
print "Hello World!" is like, the easiest hello world around. ...I'm really bad at Python.
There is lots of cool stuff, but imo the best part is how it's "batteries included" and has an extensive standard library. Great book to learn about commonly overlooked tools is ["The Python Standard Library by Example"](http://www.amazon.com/Python-Standard-Library-Example-Developers/dp/0321767349). One of the best videos to watch is simply how to [improve coding techniques and make them more pythonic](http://www.youtube.com/watch?v=OSGv2VnC0go). I am sure lots of others will also have a laundry list of material that is also beneficial, those were just two of the most eye opening for me even after coding with it for a while. Most annoying thing? DOCUMENT YOUR CODE!!!! I have no idea why you would have a def ___(__): return __-1 why??? &lt;/rant&gt;
Good info. Thank you! 
Comments. Plus duck typing. Duck typing's cool.
**context managers**, aka the with statement. These bring to python the best feature for C++ - deterministic scoped destructors. Let me show an example: with open("file","w") as f: f.write(blah) #... #... And python automatically closes the file at the end of the block *or if an exception is thrown*. These context managers are easy to write - just add `__enter__` and `__exit__` methods to a class (or use `contextlib`) Django has context managers for database transactions, mock uses them for monkey patching (EDIT and locks in `threading` library). Any time you have an object that needs to be cleaned up or committed deterministically a context manager can help.
Those commas should be colons, no? &gt;&gt;&gt; 'python'[::-1] 'nohtyp'
It's colons, not commas.
[The Python Debugger](http://docs.python.org/2/library/pdb.html), learn to use it! I prefer to use it with bpython: [bpdb](http://docs.bpython-interpreter.org/bpdb.html).
List comprehension :D [x for x in dict if x &gt; 1]
Yeah I finally understood them when I read a really good example on StackOverflow, and I feel like it's a very useful feature 
Most of these upvotes are for very niche areas of Python that aren't used often -- generators, metaclasses, etc. Watch an [idiomatic python talk](http://pyvideo.org/speaker/138/raymond-hettinger) by Raymond Hettinger. This link was posted awhile back. It covers a lot of common cases that you are bound to run into, and teach you the Pythonic way of solving the problem.
I obfuscate my code far too much, but I don't regret a thing. 
Ternary operators! I loooooove them.
I believe [this snippet](http://code.activestate.com/recipes/502293-hex-dump-port-forwarding-network-proxy-server/) is pretty much what you are looking for.
String encodings.. It is way too hard especially when making py2 and py3 compatible scripts. Either one always fucks up.
In the same vein: it's amazing how many "dumb" bugs you can _prevent_ just by using pyflakes, pylint, etc. :)
Link?
The rejoinder, of course, is: "If it has unit tests, it has bugs." But, yes, do test.
What exactly do you find problematic?
SQLAlchemy.
Using digital ocean, price is great and interface is too...but the CPU and RAM is a bit of a limitation, any recommendations?
I started working through problems in Project Euler using Python. Finally made a real effort to understand and implement generators, and holy hell are they awesome. I have no idea how I programmed without them before.
A million times this. Your code itself already documents the _what_. You only need to repeat that if the code is difficult to read.
Hmmm, they aren't for me so I didn't dig that much the $10 plan has double RAM, but still same single core if you need better, maybe Linode
List comprehensions and generators have been mentioned separately now but I think generator comprehensions are where it's at. return (operation(x) for x in sequence if condition(x))
Only unittest is, the rest are third party packages. 
Not really about the language, but PyCharm is very helpful. Language related I would say the entire itertools module is handy to know about.
IMO, the best features of Python are the (very helpful) community and the vast array of high-quality modules in python's software ecosystem.
I am new(er) to python and PyCharm. I hear it's actually a really good IDE with the vim plugin. Unfortunately, it's somewhat complex... But 
Descriptors
I will look at that. Thanks.
 with open("file", "w") as f: f.write(headers) data = get_data() for line in data: f.write(line) that should be it.
I don't think multiple contexts is what he needs (he wants to write to the same file) I posted a reply
itertools is good
&gt; I will say that the decision to eliminate the u'this is unicode' syntax in Python3 was an enormous mistake Could you elaborate as to why you think this? It seems like a very good thing to me: strings in Python 3 are all Unicode. There's nothing to distinguish between a string and a Unicode string.
No. You misunderstand. I want to write header at the start of the program. Then do hundreds of lines of compute, then write the results. To make matters worse, sometimes i like write while compute is going on, so i can monitor the write. Nonetheless, currently i just do a big write (including headers) at the end. Oh well...
Aside from generators and decorators mentioned in other comments; * **collections.namedtuple**: It covers nearly all use cases of tuples, and very convenient to access, also pretty readable. I really wish this to be a native type or an extension to current tuples: &gt;&gt;&gt; from collections import namedtuple &gt;&gt;&gt; Coord = namedtuple("Coord", ("x", "y")) &gt;&gt;&gt; a = Coord(3, 5) &gt;&gt;&gt; a Coord(x=3, y=5) &gt;&gt;&gt; a.x 3 &gt;&gt;&gt; a[1] 5 * **Extended tuple unpacking**(All hail Python 3!), can be used anywhere where tuple unpacking happens(like in for loops or comprehensions): &gt;&gt;&gt; head, *tail = range(5) &gt;&gt;&gt; head, tail (0, [1, 2, 3, 4]) &gt;&gt;&gt; head, *mid, last = range(5) &gt;&gt;&gt; head, mid, last (0, [1, 2, 3], 4) * operator module, with is itemgetter and attrgetter methods. * itertools.{groupby,slice,dropwhile} 
Words that mean nothing to me as a foreigner. &gt; deterministic scoped destructors Words that explained everything I wanted to know. &gt; just add `__enter__` and `__exit__` methods to a class
Inline conditionals. python = "awesome" if sys.version &gt; 2.5 else "hack" There's a hack for python &lt;2.5 which exploits duck typing; python = ["hack", "awesome"][sys.version &gt; 2.5] (or) python = {False:"hack", True:"awesome"}[sys.version &gt; 2.5] But I find this inferior not only because it's unclear, but also because pre-constructed dicts/lists aren't [lazily evaluated](http://en.wikipedia.org/wiki/Lazy_evaluation). This is important if your values are unsafe or expensive (often that's why you've got the test in the first place!) - eg, # this is safe response = cache.resolve("query") if "query" in cache else download_response("query") # this is both unsafe and expensive response = [cache.resolve("query"), download_response("query")]["query" in cache] (In this case, assume `cache.resolve()` raises some kind of exception if it's not in the cache, and that the `download_response()` is expensive). The workaround for *that* is to wrap it in either a lambda or a generator - or just sit down and write out the conditional in full (which doesn't seem like a big deal until you're using it hundreds of times a day, or constantly adding/removing these tests). ____ On a related note, there's a nice idiom/hack I like with dictionary.get for mapping; # "passes through" each map if variable is not in it. variable = {'1':True, 'true':True, 'yes':True}.get(variable, variable) variable = {'0':False, 'false':False, 'yes':False}.get(variable, variable) variable = {'maybe':None, '0.5':None, 'i dont know':None}.get(variable, variable) ## often an exception goes here ## (and) # defaults to False if it doesn't understand variable = {'1':True, 'true':True, 'yes':True}.get(variable, False)
The with statement will open and close the file so if you're ok with that happening multiple times then you can use as many with statements as you like. It's really just so you don't forget to close the file manually so perhaps a with statement isn't what you need in your particular situation?
Isn't that exactly what his example does? Write headers first, compute data with the function get_data (it can be hundreds of lines long if you want that) then write results. If you want to write data while the computation is going on just pass the file object into the get_data function and use it there. What is the problem?
The `fab` command lets you parallelise across hosts and, IIRC, tasks. I don't really want to parallelise my deployment scripts, that would be like parallelizing some bash scripts. If you're using `fabric` in a server process or CPU-intensize application, you're doing it wrong.
Here's the link to the Python docs for deepcopy(): http://docs.python.org/2/library/copy.html I used deepcopy() in my xtopdf toolkit (in DBFReader.py) to solve a slightly tricky problem. https://bitbucket.org/vasudevram/xtopdf 
Here: http://stackoverflow.com/a/102632/1175788 I really liked how the guy gave a simple example with a low-level explanation that didn't go over my head
What is the "flexibility of html5" ?
This question comes up here every 1-2 weeks. People should blog about it more and leave those decorators alone.
Nick is also a (good) lecturer at Stanford. Bunny World FTW!
python -m SimpleHTTPServer So handy.
Also, from an evil perspective: True, False = False, True
Once you understand it all
Comments start with # too. Back to udacity/coursera with you!
For stuff like that, I use a context manager within a coroutine, and whenever I need to emit some output, I call the coroutine's send() method. In this way, the file open/close semantics are still handled by the context manager, but I can pass the coroutine around and use it whenever I need to. # Example of a logging tool that uses coroutines and decorators from collections import namedtuple import sys import time Log = namedtuple("LogEntry", ("level", "message")) def gen_timestamp(): ''' A timestamp generator ''' ts_format = "[%Y-%m-%d %H:%M:%S]" while True: yield time.strftime(ts_format, time.localtime()) def coroutine(func): ''' Coroutine wrapper to 'hide' the initial next() call ''' def start(*arg, **kwarg): cr = func(*arg, **kwarg) next(cr) return cr return start @coroutine def logger(filename=None): ''' Does some setup then returns the correct logger func ''' opts = { 'msgfmt' : "{T} {L}: {M}\n", 'levels' : ["info", "debug", "warn"], 'ts' : gen_timestamp(), 'filename' : filename, } if filename: return logger_file(opts) return logger_stdout(opts) def logger_stdout(opts): ''' Logger to stdout ''' while True: log = (yield) if log.level in opts['levels']: sys.stdout.write(opts['msgfmt'].format(T=next(opts['ts']), L=log.level, M=log.message)) def logger_file(opts): ''' Filesystem logger with context manager ''' with open(opts['filename'], "a") as fd: fd.seek(0, 2) while True: log = (yield) if log.level in opts['levels']: fd.writelines(opts['msgfmt'].format(T=next(opts['ts']), L=log.level, M=log.message)) fd.flush() # Test stdout logger stdout_logger = logger() for x in xrange(5): stdout_logger.send(Log('info', 'stdout logger: %d' % x)) # Test file logger file_logger = logger("foo.log") for x in xrange(5): file_logger.send(Log('info', 'file logger: %d' % x)) # The logger can be explicitly closed if you'd like: file_logger.close()
Exactly my first thought
I switch to javascript for a few days and my python skills go to shit. My brain has a memory leak.
[functools](http://docs.python.org/2.7/library/functools.html#module-functools). The partial function is just awesome.
I like built-in functions like help(), dir(), and type(). I'm amazed how often I use them or maybe my memory isn't as good anymore.
ipython notebook - interactive development from a browser, so you can see graphical output like plots and tables inline below your code snippet properties - getters and setters that look like attributes to the user the scientific stack - numpy/scipy/pandas. fast matrix or data frame (named columns, sql-like operations) libraries and good statistics/machine learning tools.
I'm sure you're aware of it, but for other readers, [contextlib](http://docs.python.org/2/library/contextlib.html#contextlib.contextmanager) reduces some of the boilerplate code in writing a context manager. I find it handy, and I prefer to only write classes when it's semantically appropriate, or absolutely necessary.
Yeah, I feel like generators, meta classes, list comprehension etc. are what Python is actually MEANT to be best at.
Nice article, I'll keep it in mind the next time I have to do some audio work with Python. On a side note, we used [Python Audiotools](https://github.com/tuffy/python-audio-tools) for a project we did some time last year, is a pretty easy lib, but lacks of good documentation. I've put together an example of encoding file formats in my [github account](https://github.com/jackboot7/python-audiotools-test). Any comment is welcome, btw.
&gt; There's a hack for python &lt;2.5 which exploits duck typing; That's not duck typing
&gt; deterministic scoped destructors In C++ doing: { SomeObject foo = foo(1,2,"asdf"); // ... } results in foo's destructor being called at the `}` or if an exception is thrown. Multiple objects get destructed in the reverse order from their construction. This is extremly useful as it means classes can be used to manage lifetimes. For example you can have a lock in a class and know the lock *always* gets released at the right point. This is one of C++'s killer features compared to other OO languages like java, where you need to be very careful to release locks, close files etc. I love the feature in python because it brings this to python in a very 'pythonic' way. It is 'determanistic' because the programer knows exactly when cleanup happens, instead of depending on the garbage collector.
I agree. But this is a product of a long-lived programming language. Look at the collection of perl modules or php add-ons.
I love passing arbitrary keyword arguments to functions, i.e. class NamedValues(object): """ Stores anything passed to it as a keyword argument, ex. values = NamedValues('myvalues', cat = 'mouse', dog = 1) """ def __init__(self, name, *args, **kwargs): self.name = name self.args = args for name, value in kwargs.iteritems(): setattr(self, name, value) and all other uses of the `*` operator, really.
`yield from` is pretty cool.
The docopt module is pretty fantastic for creating nice command-line argument parsing
Don't get me started on how awesome `yield from` is. Useful for recursive yielding.
In Python 3, `True` and `False` are keywords and cannot be reassigned.
You get used to it. You learn to ignore the complexities.
I didn't appreciate how much the python community was a feature of python until I started doing things in the JavaScript community
Pycon. Past pycon videos are available online.
I've been heavily using the trial for about two or three weeks. I have found a number of bugs in the editor. Then again, that was with fresh magic sauce drizzled over my exotic code.
Then in six months, when you can't remember what you are actually doing there, you can meditate on the fact that a magician never reveals his secrets, especially to himself :)
There's that or, you know, `x.reverse()`. Edit: Or `reversed(x)`.
Worst part: package naming. So many packages have terrible, terrible names that cannot possibly be rememberable. As a beginner, I hate being told to just use the squobadobble package or whatever the fuck. Those names are not helpful.
ipython. It's like getting a pony, and realizing it has unicorn powers
Yes, extended tuple-unpacking is great.
Just program in C with struct variable { int type; void* data; }; as your only data type. Omit the `type` field if you're feeling extra weird.
Thanks for all of these guys, please keep them coming! Its been a long first day but this has helped!
* `namedtuple` can't be a native type per se because it's actually a type factory (meta-type?). I agree it feels like it should have some kind of built-in support to make it feel more comfortable. Maybe just including it in the builtin namespace by default, so it's always available. * I feel like I should have some great uses for extended unpacking and `operator.itemgetter|attrgetter`, on the level of list comprehensions and generators, but in practice *I just never use it*. Can you recommend any tutorials that clearly highlight common situations that you would use these in? * `itertools.slice` -&gt; you mean `itertools.islice`. * I'm curious what your typical use of `dropwhile` is. As opposed to `takewhile`. The latter, I can at least think of a usage of offhand (parsing a null terminated string of characters). (`"".join(itertools.takewhile(lambda v:v !="\x00", 'foo\x00\x49\x9a\x95'))`)
That's why types are nice.
A small thing I recently found in Python3: fh = open("filename", "x") instead of fh = open("filename", "w") Using "x" will raise a FileExistsError if "filename" already exists. I have *so often* accidentally overwritten output files (or worse: input files) in tiny throwaway scripts where I was to lazy to use the whole os.path.exists() thing, I wish more people would know about "x".
This was my biggest problem when I first started using list comprehension, I found it way to obfuscated to read compared with the rest of my code. Now I write them on multiple lines so that they are much clearer to read. my_list = [ string_val.title() for string_val in list_items if isinstance(string_val, basestring) ] Edit: code formatting
&gt; want to write header at the start of the program. Then do hundreds of lines of compute, then write the results. To make matters worse, sometimes i like write whil I am not 100% sure I understand you, but you could use coroutines. Then just send it lines of text when you want. This won't allow you to monitor the program; however, you can route the data through a series of such co routines. Or you can use another program to open up that file and read from it as new data is written monitoring it that way. I guess, I'm just not really sure what you want to do here... def write(filepath): with open(filepath,'w') as doc: while True: line = yield doc.write(line) 
I like that. Will start doing it. Thanks!
Out of curiosity, why do you say that? 
I don't think list comprehensions obfuscates code *too* much. The meaning of [x for x in dict if x &gt; 1] seems pretty straightforward to me :)
Python's module and packaging system catches a lot of flack, but I really like the simplicity of doing `pip install flask` to install packages. Especially when compared with the clusterfuck of Javascript...
Interesting. Is it 2-4 seconds slow? 
Hands up those who can't spell "sqlalchemy" to save their lives!
&gt; This is suboptimal because readers of your code have to refer to global state about the programming language in use to properly understand your code. Having to keep track of what major version you're using of a piece of software is a reasonable expectation of a user, since major version increments often introduce substantial non-backward-compatible behavior. Further, by your reasoning, not only should Python3 have kept u'' syntax, the default behavior for unadorned strings should always be for them to be interpreted as byte strings. &gt; There's nothing to distinguish between a string and a byte string in python 2, but it has b'bytes' syntax. Python 2 didn't have b'' syntax until 2.7. That was added to make transition to Python 3 easier. &gt; Explicit is better than implicit. By that reasoning, unadorned strings should not exist; everything should be b'' or u''. I think that's silly. A string is a series of characters, and characters are represented in the most uniform way as Unicode code points. We only need to worry about byte streams when we want to encode those strings for serialization. It makes more sense for strings to be Unicode strings than byte streams, and a major version release is the right time to make such a breaking change.
I didn't know that, thanks! 
I wouldn't really consider that duck typing, as the `bool` type [is explicitly a part of type hierarchy as an integer type](http://docs.python.org/3/reference/datamodel.html#types), so it's not acting like an integer, it *is* an integer. Or to put it another way, boolean values in C and C++ also are considered integers, and the exact same idiom works there too. This is perfectly legal C99 (although very silly given that C has a ternary conditional operator): #include &lt;stdio.h&gt; int main(void) { double ver = 3.3; const char* python = ((const char* []){"hack", "awesome"})[ver &gt; 2.5]; printf("%s\n", python); } But I don't think anyone would claim that C supports duck typing in any meaningful way. 
Makes your numpy array based functions run at C speeds from numba import autojit @autojit def Numpy_based_function(): do cpu/time intensive number crunching return answer EDIT: spelling
Since you are using daemon mode, for a start use: WSGIRestrictEmbedded On Then also consider looking at what Apache MPM is being used and what the MPM settings are. Even more performant systems need to have Apache tuned properly for running Python web applications, so it would be even more important with a RaspberryPi. For some information go watch: * http://lanyrd.com/2013/pycon/scdyzk/ 
Using the profile module is not *advanced profiling*. It is basic profiling which means that using the timeit module is not doing profiling at all. I guess it's too simple for people to understand. 1. Get it right. 2. Test it's right. 3. Profile if slow. 4. Optimise. 5. Repeat from 2. Someone should invent a complex and hard to understand method for when people need one. Where are the CMMI and the UML guys when we need them?
And don't forget the ability to omit parentheses when calling functions that take a single iterable argument For example: max(abs(i) for i in seq if some_check(i))
Yeah, but wait until you start doing nested loops within the comprehensions (sometimes 2, 3, 4 levels deep), or nesting completely separate comprehensions...or both at the same time. I've been guilty of this at times.
Eh, it's not any easier than `npm install pkg` or `gem install pkg`. NPM actually handles per-project dependencies better IMO, no need to install something like virtualenv.
That course made me feel stupid :( Now that I have a year of Python dev under my belt, I should probably try it again. 
I found I could get up and running with it faster than with any other IDE. But yeah, the complexity and power is definitely there when you are ready for it and start needing it.
My personal rule of thumb is, if it requires a nested loop or more than one if conditions, use a normal for loop. 
How different is it from NHibernate?
Interesting. First thing in this thread I didn't actually know about. Thanks.
It's generally recommended not to use nested loops in list comprehension for exactly that reason. Explicit for-loops are much easier to visually parse.
That server really is terrible though.
I really should take time to master this. Can you give me a sample problem to solve with it?
I have a huge internal debate about what do with closing }]), new line or last line of block. I think last line of block makes the code look more like python, but its probably clearer to return it. 
umm lisp...
&gt; However, I will say that the decision to eliminate the `u'this is unicode'` syntax in Python3 was an enormous mistake, which does create compatibility problems for no very good reason. That's exactly why py3.3 [reintroduces that syntax](http://www.python.org/dev/peps/pep-0414/).
Well it's called *Simple*HTTPServer, it's not like it didn't warn you.
Numerical work without iterators/generators? Not in *my* Python!
Okay, thanks :). Yeah, I write a fair few `lambda v:v[0]` s, so I'll use that at the next opportunity.
I second this. Having only just discovered `yield`, I find the concept of `yield from` fascinating!
our company is partly a python shop, but i spent the day writing in java/spring. Reminded that Python is so much better at making clean code that works.
Unfortunately, they're gone as of Python3.
Except when you want to allow people to use an object as both a contextmanager *and* as a regular object (file objects work like this) OR if you want to create an object that's useful both within and without the `with` statement. You also can't actually get at the traceback or exceptions from the contextmanager decorator (and can you block bubbling up with the return value that way?). Definitely doesn't reach the level of "never do XYZ".
I am in the middle of doing this myself.... a few things. 1. Use fabric to automate your deployment. It might be more painful the first time but will save you in the long run. 2. Practice the above deployment process on a new virtual machine till its smooth. Will make your life much easier especially when you flip the switch. Try to have your virtual environment match your target deployment as closely as possible. 3. If you can, re-image the machine before deploying your new solution. Otherwise, id suggest having functional tests over the website since you are starting from scratch but know what you need.
I'm pretty sure it's very new, and I only found it because I accidentally found the relevant discussion about the new implementation of "x" (originally it was supposed to be "c" I think) on the mailing list via Google. "x" doesn't exist in the [Python 3.1 docs](http://docs.python.org/3.1/library/functions.html#open), [only in the 3.3 docs](http://docs.python.org/3/library/functions.html#open). &gt; Changed in version 3.3: The opener parameter was added. The 'x' mode was added.
There's not really any magic to `with` statements (you could almost think of them like a massive `try/finally` that's a little easier to read), so if you write everything out into different functions, you could just wrap in one big with statement: with open(some_file, "w") as f: initial_function(f) do_computation() more_writes(f) This gives you a clearer guarantee that the file handle will be closed (and you can visually see where it happens). But it also makes the flow a bit harder to read I guess.
The course is [hosted by Google along with supporting materials](https://developers.google.com/edu/python/). I'd go there instead of using this study foyer thing. Anyways this course gets my personal seal of approval, I went through it over spring break five years ago and went on to get a job at a Python shop. The course is very well organized and really conveys how to use Python Pythonicaly.
Thanks! Are you creating a python server? Or running it through a CGI?
I am replacing a large PHP application with a Django application. Mostly due to the PHP being an old CodeIgniter project which is hard to extend since its been worked on for 3 years. Not sure how I am going to deploy it yet, probably using https://docs.djangoproject.com/en/1.6/howto/deployment/wsgi/ or uwsgi https://docs.djangoproject.com/en/1.6/howto/deployment/wsgi/uwsgi/
Easier to make it work cross-platform?
Thanks for those links!
Wasn't the python, it was the algorithm design.
I recently found this mid summer and love it! So easy to make new quick beautiful command-line interfaces
Compared to using an if statement to handle it (either of which can be done in Python (though the former is preferred)), there's really not *that* big of a difference in terms of readability IMHO.
A common production stack for hosting a python web app is to use uWSGI with nginx.
Learning itertools is playing with fire because it's the first step toward a nicer(or at least more functional) programming language like Lisp or Haskell. Careful! :D
Pro-tip: Skim through some of the standard library modules. That's where I picked up the multi-line list comp style. There's some *excellent* python in them there modules. 
You kidding? Racket's pattern matching *spoils* me. racket@&gt; (define some-complicated-structure (list "First" (list "a" 1) (list "b" 2) (list "c" 3) "Last")) racket@&gt; (match-define (list first (list b c) ... last) some-complicated-structure) racket@&gt; (displayln first) First racket@&gt; (displayln last) Last racket@&gt; (displayln b) (a b c) racket@&gt; (displayln c) (1 2 3) For example: You can pattern match over your own structures, which lets you quickly bind fields to variables. **This is absolutely insanely useful** and has saved me tons of time. racket@&gt; (struct paper (title authors conference)) racket@&gt; (define papers (list (paper "Title One" "Baggins, F." "ICCV 2013") (paper "Title Two" "Gandalf, G." "CVPR 2013") (paper "Third Title" "Gimli" "WACV 2013") (paper "Title Two the Second" "Gandalf, G." "WACV 2014"))) racket@&gt; (match-define (paper t a c) (first papers)) racket@&gt; (printf "Paper ~a is by ~a, ~a\n" t a c) Paper Title One is by Baggins, F., ICCV 2013 racket@&gt; (match-define (list (paper titles authors conferences) ...) papers) racket@&gt; titles '("Title One" "Title Two" "Third Title" "Title Two the Second") racket@&gt; authors '("Baggins, F." "Gandalf, G." "Gimli" "Gandalf, G.") This way you don't have to write (the equilent of) for paper in papers: t = paper.title a = paper.author c = paper.conference #ugh! five lines of boilerplate later, now I can do something with the paper More than macros, more than continuations, I really, *really* wish that every language has Racket's pattern matching. It's really nice to see that Python has its own limited version, and it's truly a great first step. But I can't help but feel that pang of regret when I'm forced to use an ugly construct in some other language where I could do a small pattern match and move on with my life. It's like when you're in the mall and smell a fleeting scent that reminds you of your first love, but with programming languages I guess?
I feel the same way about Java. Dear god, what a fucking grumpy, miserable community. 
Descriptors, meta-classes, generators, and magic functions are features that add very sophisticated, almost magical, behaviors to easily followed main logic. Functions truly are first-class objects. And batteries included!
Sounds like you want Javascript!
How much memory do you have free? You can allocate less to the display if you are using it primarily as a web server. But even at that I think you're going to be pretty limited. Apache and Python really aren't well known for memory efficiency. If your primary goal is to learn Flask I'd just use the built in server and eliminate all the overhead of Apache. 
I almost put decorators too because they're just so damned useful, but they're not very uniquely python.
didnt know about fnmatch, i repeatedly did it all manually, thanks for the tip!
http://stackoverflow.com/questions/1832528/is-close-necessary-when-using-iterator-on-a-python-file-object has some info. I believe you are correct that files are closed on GC, but this does not necessarily happen within an expected timeframe. I remember hearing somewhere this is an issue that changes depending on which python you use (cpython/pypy/jython/ironpython). 
Twisted one line server is even more cool.. twistd -no web --path=. -p 8080 I couldn't find any other one line server which supports resuming interrupted file download. 
Comparatively, how does gunicorn perform with the same script? https://code.google.com/p/modwsgi/w/list
http://en.m.wikipedia.org/wiki/Streaming_algorithm http://stackoverflow.com/questions/1058813/on-line-iterator-algorithms-for-estimating-statistical-median-mode-skewnes
+1 for nosetests
Please, for the love of all that is holy, use external process-safe resources instead of the `multiprocessing` stdlib module for sharing resources and/or state between child processes in Python.
bookmarked this.
In Python 2.x, you can pass the `O_EXCL` flag to `open`. Using "x" or `O_EXCL` is even better than checking for existence beforehand, because you get rid of [Time-of-check to Time-of-use](http://en.wikipedia.org/wiki/Time_of_check_to_time_of_use) bugs.
EDIT: Sorry, missed the list-matching thing. Have updated. That isn't Racket's pattern matching, that's just that Racket's structs are namedtuples. Paper = namedtuple('Paper',['title','author','conference']) ... for paper in papers: t,a,c = paper To get the list matching working takes a bit of cleverness, but: titles, authors, conferences = zip(*papers)
Thanks!
No they aren't? I used them yesterday.
This is a csv API for Yahoo Finance. It's based on ystockquote but in an object oriented wrapper. I made it a while ago, it's been really easy to work with and plays nicely with pandas so I thought I'd make its existence known. 
My mistake, I believed that the ternary operator a la a = cond ? yes : no existed in Python 2.7 but not 3. Apparently that has never existed in Python and I am wrong. The ternary operator which _has_ existed since 2.5 works like this. a = yes if cond else no [Source.](http://stackoverflow.com/a/2191896/244384)
Normally generator expressions are surrounded by parentheses, so the literal way of writing it would be: max((abs(i) for i in seq if some_check(i)))
I should mention `...` is 100% valid syntax in python, no `#` needed! Look up `python elipses` It's a mixture if wtf and lol in my opinion
The same guy (Thomas Wouters) is also on the #python IRC channel and is extraordinarily helpful. I wrote [a post](http://www.jeremy-boyd.com/2012/10/21/tips-on-python-and-upgrading-to-mountain-lion/) that got some upvotes here in which I credit him for helping me dig up the solution to a problem I was having. Extremely helpful guy all around, apparently.
Duck typing is overrated and its value drops or even becomes negative as projects grow bigger in terms of KLOCs, number of developers, etc. It's good that it's available but you need experience and self-discipline to recognize when "you could, but you you shouldn't" use it (hint: more often than not).
It isn't so much Apache is the problem but the memory used by your Python web application. If you configure Apache in a bad way and create many copies of your web application, of course it will take more memory. Same problem will occur with any WSGI server which has a multi process configuration and you set it up for many processes.
petty sure you can do: @contextmanager def context_manager_generator(): setup() try: yield except FooException as e: handle(e) finally: cleanup()
Compared to its biggest competitor IMO (Eclipse + PyDev), it's a walk in the park. It's agnostic about where you store your code, for one thing. And it generally groks Python. I was a [text editor + shell|Eclipse] user for years before I discovered PyCharm, and I haven't looked back since. I've even picked up their other products (e.g. PhpStorm) when necessary because they do the job so well. Learn to use the tool. It will save you time in the long run.
`itertools.dropwhile`, for me; simply answers questions like "what is the first prime bigger than 10^5 " etc. For a more practical point, it is like an efficient `filter` if you know the all unneeded values are at the beginning; like you have votes for items in a sorted iterable, and you want to eliminate items with negative votes.
It's not exactly hard to destruct that sentence to figure out what it means. Being proud or flippant about not understanding something is pitiful.
that's gonna be a loong time
This is more of a "cool feature I wish people knew about" **slice assignment** &gt;&gt;&gt; x = range(10) &gt;&gt;&gt; x[::2] = [0] * 5 &gt;&gt;&gt; x ... [0, 1, 0, 3, 0, 5, 0, 7, 0, 9] I remember seeing an awesome implementation of the sieve of Eratosthenes with it.
It's not at all straightforward. The use of "dict" as a variable name clashes with a built in function. Furthermore, if it *is* a dict, then you're iterating on its keys (which are rarely integers in practice), and most people would assume you're iterating on its values.
You misunderstand, all comments in this thread have helped me a lot and I appreciate them all very much. I only wanted to show the commenter how certain ways are more helpful to some than others. 
Yes, but lots of practical stuff in there.
Depending on which language(s) you come from (*cough* Java *cough*) you might have the urge to have 'private' methods in your classes. If that is the case you could be tempted to use Pythons double underscore method prefix to achieve that (e.g. `def __my_private_method(self):`). Pretty please with sugar on top: Don't do it. On one hand it's pointless because those methods are still accessible (their names simply get mangled with the class name, e.g. `__method` -&gt; `_ClassName__method`). And on the other you're making your and everybody else's life hell if you ever want to inherit from that class. Just as an anecdote: I've been programming Python professionally for about 10 years now and I can count the number of times I needed to use double under prefixed methods on one finger. One thing you can do (if you really feel it's necessary) is to prefix 'internal' methods with a single underscore. That way you don't shoot yourself in the foot and still have a 'marker' that this method is not intended for public consumption.
Or [pyramid](http://docs.pylonsproject.org/projects/pyramid/en/latest/) or maybe something else. It really depends of what you are building. 
... and if the code is difficult to read, you should really consider rewriting your code to make it more readable.
&gt; Why don't more people use kivy? Because I don't have a clue as to what it is?
How can you not use duck typing in python?
Well, that's very good.
The standard unit test library is the same, though I don't understand why they didn't at least introduce PEP8 aliases in python 3 given they were happy to do major changes to strings/Unicode/etc and urllib. I've seen some opp open source projects (Flask iirc) that create intermediate subclasses just to add them.
Thanks for the library. Very cool.
https://code.google.com/p/pystatecharts/
Very interesting, good read. It would be interesting to see some experimental data, as well.
Thanks for bringing this up. My split was set at 128/128, which is ridiculous. I've now set it at 240/16. Between this and the WSGIRestrictEmbedded On setting, my response times have come down a bit to consistently under 3 seconds - an improvement, but still pretty annoying. I get what you're saying about the built in server, but it's hard for me to get interested in building something if I can't at some point run it on my public facing server and use it. 
Good question. I want to try out gunicorn and uwsgi in the coming days and see if I can get better performance. I'll report back.
Which is why were all excited as hell for C++14 :)
wow, the author of mod_wsgi answering your question on reddit? sounds useful.
forked! see ya on github:)
Pep8 says either is fine. I prefer on a new line since I find it more readable -- and python is all about readability for me! :)
Might be good to include descriptions or pros and cons so people know which is best for what they need. i.e. I like flask a lot because it supports python 3 which other frameworks don't.
Yes it's just a start, maybe I put in python if it works in Py3k
By the way, is anyone here interested in room sharing? I'll be going to the talks and the first few days of development sprints. I know there's a page on their website to discuss this, but figure it doesn't hurt to ask here.
I think Python is not adequate for this task, unless there's some Win32 API that you can use. Your other options are writing a driver (which would be stupid to do in Python if it's even possible), output audio and use a loopback mechanism - either physical or software-based - to route the audio to input(outputting audio in Python is fine, but the loopback mechanism is not). Hope I'm wrong, though.
My guess is that it would be quite hard to write such *judge*. If you have a proper sandbox, you do not need to judge a script. You just run it in the sandbox. [Python sandboxing](https://wiki.python.org/moin/SandboxedPython) is a complex topic. I believe PyPy has the best sandbox out there but it's not an easy install and run solution. There is also generic sandboxing where you can run any program in a limited way. Various virtual machines might be an option as well.
Deterministic scoped constructors means that if enter and exit out if the context managers multiple times, the output of it should be the same. A file should be closed at the end of context mgr irrespective if what file you're opening, how big and how many times it has been opened.
Default apache is a beast. You could try slimming it down some and compiling from source, removing modules you aren't going to use. I've never used mod_wsgi, but I've read that it's pretty slow anyway. What about nginx+uwsgi? Or some other lightweight server?
I really like pip install XXXX, but some packages need the C, C++ compiler. That makes really dificult to install those packages on Windows.
Yeah if pep 8 picked one it would be so much simpler.
The list of posters is also available: https://us.pycon.org/2014/schedule/posters/list/
They are launching 2.7b2 as soon as SSL support is added therefore pip! Albiet the guy working on it is really busy, but its going! I know development is quiet, but I'm doing a talk next month at the dcpython user groups meeting about gamedev using jython and the java framework libgdx, and I'm super hopeful! Get on #jython on freenode on irc if you wanna help out. development, it could be a great implementation if we just had more people working on it :p 
I've used tri-grams to classify a few million mixed french and english documents (medical reports) into. Once the training set is built, it's really accurate.
I don't feel like programs benefit from objects having multiple purposes. The way I see it, initializing `file` objects outside a context manager is an antipattern. But, fair enough. Personal preference is not universal imperative.
Ah right, the way you did it looks so natural that I didn't notice at first.
I know one of Jython's core developers through various interactions and the impression I've gotten is that Jython core development is still moving along BUT the fact is that Jython doesn't get as much attention or interest as PyPy. A side-project he's been working on is a Jython adapter/interface to using the real time multiprocessing framework storm https://github.com/rackerlabs/romper 
flask was late to the python3 party and at this point, the frameworks that dont support python3 are in the minority I think. zope and plone are the only 2 off the top of my head. 
That is pretty clever. Thanks for the tip, I'm totally going to use this in my own Python code now! It's nice to be able to match on arbitrary data structures though... come to think of it, python *could* convert most of them into lists/tuples anyway, so maybe it's not as big a deal as I thought.
it really has better performance? I find that somewhat hard to believe (esp. if you don't have all the c extensions available). I'd be interested to read anything you might have at hand to back that up. That said, I'm pretty sure that's the reason "python developers don't seem to care about mobile apps", even if it were false.
I wanted to use it but if I want to do GUI application, I need an IDE. I'm not going to hardcode all those GUI stuff and the last time I've looked at Kivy, I didn't see any IDE support.
I don't understand for what problem it solves...
python? imho is flask. or just look at them and commit frequency.
FYI, repo has moved to https://github.com/dogweather/mctop
One note: you're using the `__len__` function so you can later call `len(NGram)`. However, `len` always returns an `int`, so you're going to be rounding the length you're using to do your comparisons. You might consider using a dedicated property in the `NGram` class instead for increased precision.
Not everyone knows about the graphical tools for analysing cProfile's output, such as runsnakerun. I believe his article to be relevant.
This was my initial thought, too. Apache is suited for actual servers with lots of memory and processing power. Something like nginx or lighttpd might be better suited for your needs.
good talks but here are the missing ones: * mysql * mongodb * web2py
My suggestion would be to learn to read, since there's a pretty obvious sidebar saying to submit things like this to /r/learnpython, and then answers pretty much all of your questions. And in case you missed that, there's a message in large, friendly letters on the post submission screen asking you to think about posting to /r/learnpython instead. To answer your first question - no. It's not worth the trouble, you'll just get frustrated with all the reading that's required.
Relevant [xkcd comic](http://xkcd.com/353/).
...python is easier to learn compared to php and java and scala...
enjoyed
I take it the networking is the most important thing?
If you haven't tried importing antigravity yet in the python interpreter, you probably should. :) 
&gt; or just look at them and commit frequency. pyramid wins in commit frequency, nearly tied with flask on # of committers though.
codecademy.com has a great python tutorial which is what I used to learn it. Once you've finished the codecademy courses (it'd take you just under two weeks to finish if you do one section per day (each section will take you about half an hour to an hour.) you could go to /r/dailyprogrammer and hone your programming skills while getting feedback from others.
&gt;In what other language could this be possible? ~$ irb irb(main):001:0&gt; x = 'blah blah blah' =&gt; "blah blah blah" irb(main):002:0&gt; x.length =&gt; 14 irb(main):003:0&gt; puts x blah blah blah =&gt; nil ~$ js js&gt; x = 'blah blah blah' "blah blah blah" js&gt; x.length 14 js&gt; print(x) blah blah blah 
Yes, Ruby is nice too. I wasn't being 100% literal. I come from C/C++/Java, so cut me some slack.
Is he taking some sort of class or lab at school ? That's what my 9 yr old nephew is starting
No, he is just always interested in what I'm doing at the computer. I thought it would be the best way to give him a gentle introduction to programming. He seemed to really enjoy it, and asked me to teach him more.
I was just pointing them out. There are lots of languages with interactive consoles, but most of them wouldn't be appropriate for a 7 year old. For example Erlang or Haskell or LISP might be too weird to introduce to someone that young.
the networking is nice and a lot of fun and your twitter contacts will grow exponentially, but just scrolling through that list of talks makes me want to drop everything and book a flight. having so many intelligent, experienced, interesting people spreading their wisdom in condensed form is really something special. you are guaranteed to be hugely motivated after a conference like this.
I've used "romper" for some initial testing and after translating the storm example topologies to Jython, all of them worked except for DRPC. I wasn't able to isolate what the problem was as I could send requests into the topology but never got a response back. 
What about adding [Tornado](http://www.tornadoweb.org/en/stable/) to that list?
Well I talk like that because I know very little about PyCon other than the talks (which is all I, someone who has never attended, get). That's exactly why I'm asking this question here. I'd like to know what else you get out of it, other than the talks.
That's not what I'd call a side effect. A side effect is when you have some externally observable effect, like mutating a list or dict. All you're doing is simulating local variable assignment. And it's not really a great example, because it would be better written like so: ten_random = lambda: [random.random()] * 10 But that's still a rather questionable use of `lambda` -- it violates the PEP8 guidelines, for example, which call for such functions to be defined like this: def ten_random(): return [random.random()] * 10 That's a stylistic choice that you can debate until the cows come home, which isn't really the point of the post anyway. I understand that the point wasn't the example but the underlying concept, but I still feel like if you ever find the need to do anything like this in Python you are doing it wrong. If you find yourself working against the `lambda` syntax it's a sign that you should just write a normal function. The `lambda` syntax was intentionally written with the goal in mind of only supporting small, simple functions that don't require assignment. Don't try to write Scheme in Python or whatever. 
It's an awesome experience. You'll get to hear some great talks, but most importantly meet some awesome people. This year I met dudes from IBM, guys that were building robots, small business owners with really cool project ideas, and some of the smartest guys from tons of start ups. If you're the type of person who can just sit down and start talking to random people, then it's going to be incredible. For $100 you'd be crazy not to attend Pycon.
well first I thought it could detect *programming* language, and I was thinking well damn that's some sick universal lexer parser there.
Submitted a PR for it. Tornado doesn't get as much love as it should.
Or just... import urllib videocode = 'Qim2av-SRwU' url = 'http://img.youtube.com/vi/%s/0.jpg' % (videocode,) urllib.urlretrieve(url, videocode + '.jpg') 
Thanks for all the help, everyone. I learned a lot. Tonight I installed nginx with uwsgi. After some frustration setting things up, I've got it working. My response times have now dropped from ~2.66 seconds to **~13ms**. I guess nginx/uwsgi win this round.
You are correct. Apache+mod_wsgi: 2.66 seconds. nginx+uwsgi: 13ms.
What do you have so far?
job at a Python shop? please explain...
Thanks for the suggestion! It is stored in the `length` property, but I was using `len` as a shortcut. I just noticed the discrepancy in the types. Just fixed it :-) 
Apparently, someone beat me to it. 
all of them? PHP $apples = 'oranges'; echo strlen($apples); echo $apples; echo 4 + 4;
The day I discovered pickle was the new first day of my life. Funny how out of all the awesome stuff in the standard library, that simple little module has made me so happy ever since.
You don't understand Python well enough to express what you're trying to express. In particular, your function doesn't do anything, but in general, you aren't using the right words for the right concepts.
&gt; it really has better performance? It really does. It's not even a comparison; IOS doesn't even *support* webgl, and the android webview / browser is painfully slow. Both android and IOS have terrible, terrible canvas performance, compared to native graphics, which you can access from python. Honestly, the HTML5 vs. native apps thing is well resolved at this point; and python mobile apps run as native apps (abit yes, more slowly, because its cython on top of native, but its still blazingly fast compared to html5). python native apps vs. native apps without python is a much less compelling story, I realize; it's more painful to package, it's slower to run, it doesn't have native ui. ..but html5 apps have the same issues and are flat out slower and have great memory restrictions because they run inside a stupid webview container. :( you can barely get a few frames a second using pixi.js on a chrome demo. Html5 performance has been pretty disappointing to me...
How many of these talks will be recorded and available for viewing later?
Yeah they are missing java and c and erlang too!
My impression is that the core developers have a lot of other projects going at the moment. Get on the irc and volunteer to help if you would like to see updates! 
in 2012/2013 they recorded all talks for viewing later.
Ugh, I misread the title and thought that the videos of the talks themselves were up ... I went through the talk listing, found the one I wanted to watch, got a drink, sat down, opened the link ... and then realized that these were for the upcoming PyCon, not the previous. /sigh
Docopt is awesome. It conforms very nicely with how a cli "should" behave, particularly in regard to short/long options and mixing optional and ordered parameters. 
http://hackety.com/ was pretty great for kids learning programming (not sure if it's maintained now?!) 
Great! My son, who is also 7 y.o., likes http://scratch.mit.edu/ a lot, but I still haven't made the jump to show him more _text-based_ programming. Soon I guess... I'm curious, have you thought about what will be the next step? I mean, playing with a REPL is great, but For instance, `import turtle` ?
Well, as far as I understood, R4K is the _successor_ of hackety hack
Human be
http://www.reddit.com/r/Python/comments/1qdwhc/beautiful_codebase_nominations/
Hey, I threw [this](http://pastebin.com/8DyNFPps) Python code together a few months ago, it's not finished and not nice (especially the dummy error handling), but it maybe a good starting point to fetch the data from a Facebook group. For graphs [matplotlib](http://matplotlib.org/gallery.html) is often suggested here. Although if you have experience with Flask you could build a small webpage and graph the datas with Google's [chart tools](https://developers.google.com/chart/).
Oh yeah, try Ipython notebook. It might appeal more to children than command line.
I don't. I think there are a number of deployment tools for containers but I can only suggest the basic debian guide.
I'm not really a fan of Ruby but I like blocks and sometimes the syntax feels cleaner than python's (other times it feels like madness).
I guess pyramid should not be in this list at all though, should it? It's not "minimalist" in any reasonable sense.
I'll try to help you. You are most likely accessing something in windows that is triggering the BSOD. It is not Python per se. You may be using a module specific to Python 2.7 that is causing the BSOD to occur. [A simple Google search reveals that you are not alone.](https://www.google.com/search?q=python+blue+screens&amp;oq=python+blue+screens&amp;aqs=chrome..69i57j0.2917j0j7&amp;sourceid=chrome&amp;espv=210&amp;es_sm=93&amp;ie=UTF-8) I find it odd that some people in this sub pretty much instantly dismiss your observations and reply with run of the mill unhelpful comments. I wouldn't want these people on my team tracking down a bug. Here is a post on /r/learnpython where a user experiences a BSOD while running 2.7: http://www.reddit.com/r/learnpython/comments/15nht3/why_might_python_27_be_crashing_my_pc_windows_7/ Again, Python is not causing the issue. It is probably a driver being 'accessed' the wrong way by a specific module. If your module happens to be in standard library, then it's most likely a sign of impending hardware failure.
You need to post your yahoo.com email address so we can send you the codes.
Changes since v0.0.33: - Support for python 2.6. - More [examples](http://tmuxp.readthedocs.org/en/latest/examples.html). - Support for launching tmux configurations [relative to project directory](http://tmuxp.readthedocs.org/en/latest/examples.html#start-directory). So a project file in ``/var/www/django/.tmuxp.yaml`` can be loaded with ``tmuxp load /var/www/django/.tmuxp.yaml`` and ``start_directory: ./`` will make sure paths are relative. - [Blank panes](http://tmuxp.readthedocs.org/en/latest/examples.html#blank-panes) may be spawned with ``pane`` and ``blank``. - Set [Focused pane and window](http://tmuxp.readthedocs.org/en/latest/examples.html#focusing) on session start, also sets active pane in other windows. - [Launch pane at window_index](http://tmuxp.readthedocs.org/en/latest/examples.html#window-index) on session start. - [Chinese docs](http://tmuxp-zh.rtfd.org/) - Many many bug fixes, tweaks and optimizations See the rest of the changes in the [history](http://tmuxp.readthedocs.org/en/latest/history.html).
&gt; "All Python frameworks other than Django" and zope and plone. 
Can this subreddit not turn into this? Even r/programming doesn't allow low-content shit like this.
So it's hard for me to argue against that as I am not a Pyramid expert. Anyhow, I just checked SLOCs for both projects. Pyramid is more than 120k, Flask is just over 25k. So it's definitely a lot more code.
is &gt; 100K lines of code the metric we use to define "minimalist"? i'm sure zope has 10x that let's just define it as &gt; 10K that should eliminate everything but bottle
&gt; python mobile apps run as native apps Good point, hadn't thought of that.
Try python
I did over 147 updates to windows. And since then I havent been able to get python to BSOD on me. I'll keep trying so I can find out exactly what error it gives me EDIT: And no, I don't think I called any modules or used any import statements while coding when it crashed EDIT: When I imported math and started using some of the commands, my computer disabled windows aero effect or whatever its called. And my internet seemingly got knocked out. But no crash
I'm not surprised that there are people who think this is something new or interesting, but it's a sad state of affairs nonetheless. "or" has two meanings in English, normal or and exclusive or. The latter is called "xor" in programming.
Plone isn't a framework.
People often use "either" to indicate that they mean exclusive or, but it's not a rule.
The mom just means "or colloquially" or "XOR" in formal terms. What a sadly missed teaching opportunity for a slight chuckle.
I'm pretty sure the irc channel isn't mentioned on jython.org or on the wiki and the mailing lists are almost dead. Maybe if it were clearer how to get involved more people would? It would also be really useful to have a public repository for the 2.7 branch. Not only would it make it easier to try working on the code, it would make it clearer that the project isn't totally dead.
You're right, maybe www.jython.org is in need of a redesign, however, I'm a horrid designer :p so I cant help much there. There is a public mervcurial repository at both http://hg.python.org/jython and its mirror at https://bitbucket.org/jython/jython/ It is a little slow, but it goes!
I wasn't aware of this tool - I just used networkx until now. Any experiences with graph-tool?
What this desperately needs is ERGM support. This package is slightly faster than networkx from what I've heard, but there is still no way to run statistical network graph models in any package in Python. And R caps out at about 500 nodes for an ERGM on a regular laptop...
Don't be upset, other packages do this too. It's just just that python's packaging system is not reliable enough - simple as that. For example virtualenv goes as far as to bundle setuptools and pip's source distributions.
I know, stupid question, but have you tried the [official docs](http://docs.wand-py.org/en/0.3.5/)? There is a section for each of the most common tasks like [reading](http://docs.wand-py.org/en/0.3.5/guide/read.html), [writing](http://docs.wand-py.org/en/0.3.5/guide/write.html), [resizing/cropping](http://docs.wand-py.org/en/0.3.5/guide/resizecrop.html) and otherwise [transforming images](http://docs.wand-py.org/en/0.3.5/guide/transform.html). At its core, wand is a fairly slim wrapper around the [magickwand](http://www.imagemagick.org/script/magick-wand.php) C-Library that you can access through the [wand.api ](http://www.imagemagick.org/script/magick-wand.php) module, which is the C-library wrapped with CTypes. With it, you can do lots of stuff that the more high-level API of wand does not support, just read up in the C-Documentation on how to do it and do some type-binding with Ctypes.
http://stackoverflow.com/a/6189281 :D it only has **use** in indices, but it is a completely valid placeholder object!
The only reason virtualenv does this is the bootstrap problem, in many envs it's the first thing installed, even before a package manager! virtualenv/pip/setuptools are extreme cases, and your projects are not like them (unless you're writing a new package manager ecosystem of course ;)).
Please *avoid* metaclasses. They definitely can be extremely useful but if it can be done without metaclasses, I prefer it that way. I think the Django ORM could've avoided metaclasses. (Quite honestly, I dislike a lot of things about the Django ORM but that's another discussion.)
 ten_random = lambda: [random.random()] * 10 This will give you 10 numbers that are all the same, FYI.
A human should be whatching and resolving the captchas. However, there are some projects that try to resolve the images.
I agree with using them sparsingly, as my original comment suggest with the 'needed and used correctly' stipulation. However out of curiosity, so I might learn something, why such a strong aversion to them?
...which is what the example was supposed to do. 
I'll reply here as an addendum. There is a ton of stuff out there, but I really have no clue how to do this. As Slinky mentioned, Python probably isn't suited for this task. However, there is a trove of audio related stuff here: https://wiki.python.org/moin/PythonInMusic This one is used everywhere: http://gstreamer.freedesktop.org/apps/ There is also the Qt4 Phonon Module: http://pyqt.sourceforge.net/Docs/PyQt4/phonon.html I would have no idea how to create a proper loopback. Perhaps one of these libraries can expose an existing Audio In Interface, such as Audio In, as a file-like object. Then stream your audio file into the file-like object. Just talking out loud here. There is probably no way in hell it would work like that. 
eBay open sourced their bayesian belief networks library: https://github.com/eBay/bayesian-belief-networks
Any metaclass has the capacity to completely change the class you're defining. It can be confusing and counter-intuitive, and generally people tend to overdo it when they use them. For example, take the Django ORM. Say you have `myapp/models.py` like so: class Foo(models.Model): bar = models.CharField(max_length=25) Then go into `manage.py shell`. Let's pretend you want to access the `max_length` property you set in that constructor. &gt;&gt;&gt; from myapp.models import Foo &gt;&gt;&gt; Foo.bar.max_length Traceback (most recent call last): File "&lt;console&gt;", line 1, in &lt;module&gt; AttributeError: type object 'Foo' has no attribute 'bar' Meanwhile, in a world without metaclasses: &gt;&gt;&gt; class Foo(object): ... bar = CharField(max_length=25) ... &gt;&gt;&gt; Foo.bar.max_length 25 The `Model` metaclass 'undefines' all the attributes you set in your class definition. The Django team came up with the `_meta` field to let you access the `CharField` instance, should you need to. In Python, a leading underscore indicates that you probably shouldn't touch whatever it is you're looking at (as a substitute for something like `private` in Java). But nevertheless the Django `Foo._meta` attribute is your only way to do introspection. This attribute also doesn't seem to be documented on the Django website. So you launch the interpreter, do `dir(Foo._meta)`, and see two methods of interest: `get_field` and `get_field_by_name`. Well, if one of them takes the name I can't imagine what the other is supposed to take. &gt;&gt;&gt; Foo._meta.get_field_by_name('bar') (&lt;django.db.models.fields.CharField: bar&gt;, None, True, False) ...my poor brain. So your first time out you might write this: Foo._meta.get_field_by_name('bar')[0].max_length instead of code logically implied by the class definition: Foo.bar.max_length It turns out `get_field` *also* takes the field name as the argument, and doesn't return a garbage tuple, so the seasoned Django developer might write Foo._meta.get_field('bar').max_length which is less absurd, but still pointlessly convoluted. So I'm more averse to the usage by other people as opposed to the functionality in general. Ultimately metaclasses tend to contradict the Python maxim that "explicit is better than implicit" (see `&gt;&gt;&gt; import this`). And of course there are some situations where metaclasses really shine. But just, please, sparingly. When there is no other sensible option.
You cannot ever ask a question on that newsgroup as a newbie. That's a recipe for hatred. Kind of like the Debian boards about 10 years ago. I had never had 200+ people all tell me to "RTFM" or "Go back to Windows" in my life, it was rather humbling.
I mostly use (and sometimes contribute to) [NetworkX](http://networkx.github.io/). This looks like it doesn't have quite as many algorithms and generators as NetworkX, but it is very possible it's faster. Also NetworkX visualizations are shameful, these look much better, I might have to give it a try just for that.
Introductory Videos * **Python Osmosis** * **http://learnpythonthehardway.org/** * **Python 101 and 201** * **https://developers.google.com/edu/python/** * **http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-00sc-introduction-to-computer-science-and-programming-spring-2011/** ---- Books I suggest looking into Wesley Chen or Mark Summerfield books. They cover language basics as well as providing useful example using many of the modules included with the standard library. 
Thanks for sharing! I have the "Two Scoops of Django" book, which is great for 1.5, but this does fill in some blanks for 1.6 as well.
I'm really new to Python and I never knew about decorator functions. Seems like they're extremely useful. The writer also does a great job of explaining generators.
Wow these are amazing, thank you!! FYI: I am new to programming and therefore new to Python as well. It's used at my work and knowing it would be very helpful.
so django is out because it's orm wont support dynamo. So just use something like flask or pyramid since they dont try to shove a shitty orm down your throat to use the framework. But really, if your scale requirements are truly that big that you need dynamo, then it is likely the case that only you(presumably the expert in what your application needs to do) will truly know what the right choice is. most people who would be qualified to answer are too busy working, the rest are likely college students that dont know anything. 
No, there is no mega bundle of every library. There are tons of libraries and they're all made by different authors who don't exactly coordinate together. Everyone uses pip and virtualenv to install libraries. It works pretty well. You would just do "pip install DateUtil NumPy PIL PyParsing SetupTools MatPlotLib Basemap". As for the windows stuff, I don't know. Windows is designed for the lowest common denominator and is not very enjoyable for programming.
You get to meet and talk with all of the people who make software you use and care about. I can't imagine anything much more awesome from a professional event.
programming might not be for you. maybe try cooking or something...
pip and virtualenv eh? Will do and thanks for the info!
Thanks that code is helpful. So is request just a library that allows you to retrieve a webpage? I've never worked with a library before.
I would suggest that these are not necessarily data structures. Metaclasses, maybe, but comprehensions and decorators are not what I would refer to as data structures. 
pure client side, "frozen app". Next step is to do this collaborative, should be a few more lines
Is the title of this post supposed to be a knock on GeoDjango?
Thanks.
I was thinking the same exact thing.
These are language features and programming concepts. They are not data structures.
So does OP's.
For Flask, you really need to include the LOC of Jinja2 and Werkzeug as well, since it's an amalgam of all of those projects.
There was no direct link to the actual webalchemy code used to implement it, so [here it is](https://github.com/skariel/webalchemy/blob/master/webalchemy/examples/todomvc/todomvc.py) ... basically the code looks like large chunks of javascript (70 lines of js at one point!), which makes you wonder why not to use js altogether. What are the pound signs we see in the javascript like this: ` #{self.e.filter_all}.classList.remove('selected');` The [HTML file](https://github.com/skariel/webalchemy/blob/master/webalchemy/examples/todomvc/todomvc.html) is loaded with a ton of variables. Thanks for submitting this, but the lack of object-oriented organization that I see in qooxdoo makes it seem like I better stay with learning that. 
I would probably generate something into a portable output and feed it to d3js these days.
There is one particular thing that I want in Python from these REPL examples ``.length`` property rather than the builtin ``len()``!
Looks good. Was `django-admin.py startproject` really added in 1.4? I could swear I've been using it for ages.
I don't know. You can run 'port installed | grep python' and see what you have. You might need to install python_select from port before you can run the --list command.
That's a fair point.
After spending some time trying to install this beast I am inclined to agree. Seriously, compiling from source, it seems impossible to meet the dependencies, I finally installed the pre-compiled binary for ubuntu, but jesus... OK, it is definitely faster than NetworkX (by an order of magnitude-ish) and the drawing is pretty sweet. I've used d3js too, but I always feel like I am spending a lot of time writing boilerplate javascript and html.
I would go further and recommend against deploying your app in a git repo. Better to use git archive as a fab command: $ git archive --format=tar HEAD | (cd $prod_app_dir &amp;&amp; tar xv)
This has been a huge problem for me in projects using many dependencies. Personally, I think any third party library should be fully self contained and not require anything outside of the standard library for basic functionality. Or at least allow fallbacks incase the dependency isn't avail or not the right version (ie fallback to using threads if gevent isn't avail).
There are other distributions of Python that include a lot of common modules. If you're interested in data analysis or scientific computing, Anaconda comes to mind. Otherwise, yeah, you do tend to install new modules frequently when you're starting out and trying new things. Pip makes it a lot easier.
Sorry if something went misleading. I have Changed the title.
This might sound crazy, but there is a implementation of cpython compiled to javascript which is naturally sandboxed in all major web browsers. You could load up a headless webbrowser module in python (like phantomjs) and use that to load up the javascript version of cpython and execute the code on a server. It will run slower than a pregnant snail, but it would at least be subject to the same sandbox restrictions of javascript.
No way. That has definitely been there longer. 
To some extent I found Storm was not a perfect fit for my problem ( receiving and executing logic that depended on 3rd party API's ) and really all I wanted was the transactionally reliable~~y~~ topology system. Still with the exception of DRPC, most other facets of that framework did work reliably using Jim's romper project.
Sorry, should have been "startapp". I'll fix this.
Damn mirror reminds me everyday 
&gt; I would suggest that these are not necessarily data structures Agreed. Coming from a computer science background, the content is definitely not what I expected.
If you can, use Python 3 and the asyncio standard module. http://docs.python.org/dev/library/asyncio-task.html#module-asyncio And try to use more than one process per core as most of the time you'll be waiting for your IO to complete.
Note that having your build process *commit* code in the process of deployment pretty much never happens, since devs generally don't deploy. And even if they did, it's pretty terrifying to think about deploying code that's just being committed now...
gRain.
unfortunately I'm stuck with the python 2.6 ecosystem, but i'll keep that in mind for future projects. Thanks for the advice on the number of processes.
Great, thanks. Why would I be getting the following error: &gt;File "genes.py", line 13, in &lt;module&gt; &gt; wild_type_data = np.asarray(wild_type) &gt; NameError: name 'wild_type' is not defined 
The repo on the desktop might have been anonymously cloned by accident. That's the most likely scenario.
Hmm, now it's saying &gt; genes.py", line 17, in &lt;module&gt; &gt; ax1.scatter(wild_type_data, mutant_data, color='blue',s=5, edgecolor='none') &gt;NameError: name 'ax1' is not defined 
For mac users at least, they'll also need to add these two lines to their profile export VIRTUALENVWRAPPER_PYTHON=/usr/local/bin/python export VIRTUALENVWRAPPER_VIRTUALENV=/usr/local/bin/virtualenv
A few bugs:django_admin.py startproject django_project * you have a typo on this line &gt; django_admin.py startproject django_project should be django-admin.py * do you mean to not include manage.py under VCS? If so, why?
As someone who is relatively new to git, what is the advantage of sharing the code this way? 
The problem is dynamo doesn't seem to like indexes; I spent 4 hours today fighting it, trying to get a schema to work (since the docs are minimal at best and empty on what I need really), wont delete tables I made incorrectly by mistake (the boto table.delete() method just doesn't work, throws exceptions like crazy and doesnt delete anything).. its frustrating. And to be honest I'm having a lot of issues with its version of Nosql (and nosql in general) as they just seem to be poor tools based on what I am seeing. I cant help but feel like I just need a relational database, that can handle 7 billion rows in multiple tables.. so things like indexes on individual fields that may not be unique, functions like COUNT, SUM etc, work, and can handle highly normalized data.. using nosql honestly seems like they dont want you to normalize your data and that leads to so many problems. The fact I have no prior experience with it doesn't help as I'm a relational db guy (or I was).
Wow. This is cool. Thanks. 
How would I check that? And How would I fix that if it's the issue?
Can't wait. Great work on previous release of the book.
I wish someone working with buildout would post a "Starting a Django 1.6 Project with Buildout the Right Way". I've worked on dozens of django projects using buildout and pretty much each one of them uses buildout differently. I'm still not sure whether I like, or loathe buildout.
If your brand new I would start with the thenewbostons tutorials on YouTube. They're great, Bucky's tutorials are lively. http://m.youtube.com/watch?p=PL4E68ACF14ABB47AC&amp;v=4Mf0h3HphEA&amp;feature=plpp
I world also recommend doing http://programarcadegames.com, they're comprehensive and include quizzes and labs. 
| local('git pull /my/path/to/dev/area/') | local('hg pull /my/path/to/dev/area/') | local('hg update') This by itself is too anemic as a deploy process. Generated .pyc files get in the way if you go from foo/__init__.py to foo.py. Deploy tags or branches. You'll be happy you did.
Your .git repo isn't on your prod servers, which includes credentials to connecting, the entire code base etc which may give away things as well.
Great job, thanks for sharing this. I just played around with it a little bit, and it works beautifully. I am still relatively new to Python, so for me your library serves two important purposes. First, I have use for the functionality, and second I benefit from trying to understand your code. In particular, your clever use of kwargs throughout the module gave me ideas for improving my own code. One little suggestion, if I may: The call &gt;&gt;&gt;history.prices(as_list = True) where history is an instance of StockHistory returns an unsorted list of prices. This might trip up an unaware user, who expects the price history to be presented in chronological order. Changing line 145 of core.py from return data.values() to return [v for k, v in sorted(data.items())] gives me what I expected. Again, thanks for this very nice library!
I built something in networkx previously that i've ported to a distributed architecture in c++ and java components. Going to try graph tool today as the next step in my pipeline so i'll let you know. It should be considerably faster than networkx
&gt; ERGM To be fair most real world uses of graphs are to model something so these stats are not very useful to non sciencey stuff 
It's really just the prefix notation that I think might confuse kids, but maybe not, maybe it fits the intuitive mathematical grammar that makes some kids describe 'plussing numbers together.'
I stuff my code in a private pypi repo and install it with pip on deploy, why not use the tools already existing for this very usage.
pip is the defacto standard in django community so you might want to change to that
that just introduces unnecessary complexity and solves a problem that doesnt exist in many cases. my approach: depend on the newest version of something, and write a dependency of `package &gt;= that.version`. when adding features later, or an issue arises with a newer version, bump the depended-on version to the newest again, then fix the issues. you do *not* want multiple numpy installations on your PC.
Excelent article. Thanks soo much :-)
Note that this implementation still has less JS than many others and an untouched index.html, check for e.g. Backbone, Meteor, VanillaJS, or JQuery which doesn't even implement routing. That being said, this is a very early implementation, and I intend to introduce HTML directives a la Angular to generate most of the code so JS should get much shorter. Let me report back when it is shorter than 75 LLOC (current Angular figure)
buildout uses pip underneath, it just has the ability to do a lot more for example, the last django project I did, you could pretty much clone the repo and run 2 commands and be up and running on any machine with python installed. this version pinning dependencies and included a supervisor config that ran the dev server and the celery workers. It even mostly worked for the designer guy who was on windows(at least the dev config). the qa and prod configs pointed to a different settings files so different databases, mail configs and the supervisor config used uswsgi with nginx in the front(buildout installed both from source on qa, but not prod.) So yeah, there are other tools to help you build the same kind of capabilities, even shell scripts would have worked. But it was relatively easy and bulletproof with buildout. And I could spend more time writing code rather than writing deployment docs/dev docs etc....
Thanks for letting me know, I'll get that fixed, I'm sure there will be more to come. Good to hear it looks promising.
Tried Python x,y? If you are looking for something that bundles a LOT (numpy, PIL, matplotlib etc etc) of scientific python packages combined with Spyder as a neat little IDE? It works out the box - large install - but I think pretty problem free. Comes with pip too :) :)
That just shows that I still need to learn a lot about GIT. I did a site recently where we started out with cloning the rep on the prod server but later removed it due to security concerns and just copied files to the server. Yeah, it was for uni so I guess I'll live but in any case, good to learn something new.
Thanks again. That line works perfectly there. kwargs are pretty awesome, once you get the hang of them, they're suddenly useful everywhere.
Anybody can suggest the right Django 1.6 project structure ? 
Why install `virtualenvwrapper` and configure it if you're not going to make use of the totally awesome `mkproject` command? And why is the author still mentioning `distribute`? virtualenv installs [setuptools](https://github.com/pypa/virtualenv/tree/develop/virtualenv_support).
A software development business that mainly uses python as its programming tool of choice.
only if they are using virtualenvwrapper, for those that prefer to just type the path to the interpreter they want, this is not necessary.
nice article. i like how you talk about when to use south. i would love to see a mention of when to, or even if you should, add the migration files to your vcs repository.
http://i.imgur.com/PNkmk1o.jpg
I would definitely add them to your repo. You'll need them when you deploy to a server and need to migrate your live database.
Is this any good? I looked through the sample chapter and wasn't particularly impressed. It seems like I could learn as much by just being really diligent with the already existing Cython tutorials. However, I'd really like to be better at Cython, and the price is obviously great, so if other python redditors recommond this book I'd buy it.
I never used https so I don't know there But https doesn't use the SSH keys. In a terminal, try this: energya:sr_tools acv (git:master) $ ssh git@github.com PTY allocation request failed on channel 0 If you get that message, SSH keys are working.
http://www.librarified.net/wp-content/uploads/2013/03/i-have-no-idea-what-im-doing-dog.jpg
It looks like all Python ebooks are $5. http://www.packtpub.com/kivy-interactive-applications-in-python/book http://www.packtpub.com/practical-data-analysis/book http://www.packtpub.com/matplotlib-python-development/book
Check that - all ebooks are $5. https://www.packtpub.com/ebookbonanza
Python comes out of a predecessor language, ABC, which was intended, in essence to be a better BASIC: a teaching language, but one which is logical rather than a collection of weird rules. It's no coincidence that it has the strengths which it has. 
Video courses too. Nice thing is they are all DRM free
I can't speak about this particular title but quality varies greatly with PacktPub so it's always a bit of a leap of faith sadly :(
Seen lots of negative reviews about the site, be careful.
I can recall [Python Geospatial Development](http://www.packtpub.com/python-geospatial-development-second-edition/book) as being really good.
Machine Learning is really good http://www.packtpub.com/building-machine-learning-systems-with-python/book Best to check Amazon reviews first
&gt;my approach: depend on the newest version of something, and write a dependency of `package &gt;= that.version`. when adding features later, or an issue arises with a newer version, bump the depended-on version to the newest again, then fix the issues. +1 for this and automated test coverage. &gt;you do *not* want multiple numpy installations on your PC. Conda solves for this. 
&gt; Conda solves for this. i dont want it solved, i want everything depending on numpy just use the system numpy and not require any freezed versions ;)
https://news.ycombinator.com/item?id=6933716
Good to know; I was tempted by that one.
Thanks!
Disclaimer: I did not buy or read this book. Cython is great, when you can get it to work. But, there's a lot of things that don't work as expected, and the documentation is not complete. It has some very smart people working on it, and they are doing a good job -- but be prepared, it's not as mature as it might first seem. Prepare for some hacking if you want to do something that's not in the tutorials.
freezed? are there incompatible changes between 1.6 an 1.8? just write code that isnt deprecated in 1.6 and it will work in 1.8 if they have any sense (which id guess they do), and depend on `numpy&gt;=1.6.1`
That bash script you added to the profile required it
because then they would need to [frequently] merge in from upstream in order to avoid divergence and risk.
using virtualenv just fine on this here mac with nothing in profile
Thank you. We hope you like the new edition!
didnt say there wouldn't be consequences. 
I'm sorry but this is the most useless reply you can write. I *know* that open source is about being able to hack yourself, but essentially a polite question "is someone working on it?" shouldn't be answered with "you are now loser!". If you want someone to contribute to open source, you need to create a welcoming environment, where among other things he can get some help. If noone is working on the project or willing to at least review potential contributors, the project is dead (which is not the case for jython fortunately)