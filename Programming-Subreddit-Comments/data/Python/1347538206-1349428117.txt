Maybe it was sarcasm?
&gt; has led to the rather ridiculous situation of a project having its own site-packages. On the other hand, this is exactly the same as how node.js does it: you can install packages globally, but also locally. Sometimes you want the latter, other times the former. I've had cases where 'developers' thought they should package every function in a package, and you end up installing 12 to 15 packages (with the exact same version as of the author). It's pretty nice if you could do that in a local environment, without messing up your whole global site-packages. If there was something like npm for python --- want!
I have a problem that I wonder if it could be solved with a path search algorithm. I have a list of items that I can only change the order and I want to minimize the total of the "distances" between related rows. In other words I want to have all the "A" near each other and the same thing for "B" and "C". I have: A B A C A A B C B I want something like: A A B A B C A C B Thanks!
It sounds like you could but you're going to have to define distance a bit better for me.
Gnuplot did only recently (relative to its own lifetime) gain antialiased raster output.
By distance, I mean for each letter the number of rows between the first and the last row containing that same letter. For the unsorted sample, "A" is on the first line and the line before the last one so distance is 2 rows. * A B * A C * A * A B C * B -&gt; A = 2, B = 3, C = 1. Total is 6 * A * A B * A B C * A C * B -&gt; A = 2, B = 2, C = 0. Total is 4 (so it's better)
Thanks!
If you've ever used lex/yacc [PLY](http://pypi.python.org/pypi/ply) is a good choice. You might also have a look at other formats [supported by biopython](http://biopython.org/wiki/SeqIO) and just add yours…
you could also try [codetalker](https://github.com/jabapyth/codetalker) it is similar to pyparsing but a lot faster (cythonized) and easy to use Edit: [introduction](http://jaredforsyth.com/blog/2010/jul/26/only-codetalker-introduction-youll-ever-need/)
I think its really more to get people on the upgrade bandwagon for long term income.
I feel obligated to point out that this is not the case.
It's the second time PyCharm is on sale this year. Does this qualify as "very often"? No, JetBrains is not going under. Quite the opposite, in fact.
Thanks for the suggestion. That looks very interesting, however, it looks like I would need to call the function to run in the cloud from my local computer. Does that mean that I would need keep my local computer running as well?
Even your complex file appears like it could easily be parsed line-by-line in almost any language.
I use pyparsing
Like I said "seems". Twice in 9 months... I guess that's subjective. But now that I know it was only twice, I'd say no that's not very often. I'm glad that they're not going under, I do hope to have a need for their IDE at my company in the note so distant future.
That makes a lot of sense.
&gt; I think what marsanyi was getting at though is that with Java you can hand out a .jar and people are happy Obviously. But, they're not really happy unless they can check the code out of the repository, build the war on their workstation and it actually runs. Then they can get started. And that generally means they are are using the right version of every dependency. And as you point out, the question of the right site preferences (right version of Java) rarely if ever arises. It does once in a while, but it's also easy to handle. &gt; - just drop it into your project and it works. Only if when you check the project in, you also check in every jar into the project. Does the person who checked in the jar also name it consistently and identify its version in a way that can be immediately recognizable? There may have been a strong probability that it works. But it is less than 1.0 say it's 0.95. And when you multiply by the number of dependencies you get a much lower probability and of course, if you need to replace one jar, that probability goes immediately to 0. Also, one dependent jar can and often does refer to other dependencies. This is what the Maven/Nexus repository infrastructure addresses. Jars alone give you some repeatability. But jars plus a repository gives you that plus flexibility. You can change a jar version by simply changing it in the POM. I think what you're saying is clear too: that a fundamental difficulty exists with creating a new site (a new Python version) for every dependency difference. If you work on 3 applications which have different dependencies you're stuck with 3 sets of site preferences. Otherewise you're out of sync with other developers.
It seems that you've already solved your problem, but just for the sake of completeness this is how I roll with py2exe: http://pastebin.com/wNdFvZLZ That is, if your problem is that py2exe bundles your dlls incorrectly (puts them into the library.zip or something). 
Compiling PIL, lxml, and PyCrypto takes a lot longer than two minutes not mention whatever else is in your requirements file. I prefer to have webservers running the least amount of software possible to serve web pages. It just less stuff that can go wrong and easier provisioning of new web servers.
Setting up a C toolchain on Windows means downloading the MSVC Express (the same version that was used to compile Python, it was 2008 last time I checked), then win-break and navigate to advanced settings where you can edit $PATH, $INCLUDE and $LIB, then add relevant paths there as seen in the "C:\Program Files (x86)\Microsoft Visual Studio 9.0\Common7\Tools\vsvars32.bat" or something like that.
Yup! RPy is included. You can even type %r to get an R interpreter. You can easily get all of the R stats packages out there. 
Do you know, why?
I don't think you should count simpleparse out just because it hasn't been updated. It's a fine parsing framework. Here's a JSON parser I wrote using it a couple years ago: https://bitbucket.org/dowski/etc/src/tip/parsing/spjson.py EDIT: Another example: http://blog.dowski.com/2007/12/19/simpleparse-plug/ Excuse the poor blog formatting - I've clearly not dusted for a while.
Sorry, &gt;1. is the position checking something that's happening through I/O with an external system? The object who's position is being tracked is the input data from an Intersense Wand (6DOF input device). Depending in what 'zone' or 'area' is in, the virtual wooden block being picked up via the Wand will behave differently. &gt;2. if it's completely internal to your program (it's a simulation), then you should be hooking into the simulations existing main loop. Nope, no main loop as of yet. I guess this would be the main loop I'm trying to make? &gt;3. Are there other things that need to happen at defined times while the program is running? The contents of this loop are reacting to user input. All other events are in response to things like button presses. ----------------------------------------------- I will give that a go, thanks
Looking at the docs it seems as if extensions (plugins) are written in Java. Is it possible to write them in Python?
Not TOO critical, but it has too be Python :-/ A. The only language I can manage to do something this complicated in IS Python B. The only dev platform we've managed to control the +$1,000,000 machine with is Vizard (Python based VR dev platform). Granted, we've almost got Unity working...
I'm not sure I see the fact that you can write any possible program as a "problem" or as an "issue" but rather simply one use case. &gt; because some people need this system of dependency tracking and remote deployment and centralised repositories of libraries, That's simply not true, especially in the Java world. All the infrastructure exists and is not "imposed" on anyone, even though they use it even without knowing it. You might actually use Maven repositories every time you run findJar and a Maven repository comes up on your list. The infrastructure both benefits people who don't use it, and costs them nothing. Howver, if you leave out the webapp use case, and the multi-project use case, where people really do use these things and require them -that's a big problem and it is a problem for people who actually supply the resources (the jars, the libraries) that support the simple use case that you seem to focus on. In other words, without what you call "this system of dependency tracking and remote deployment and centralized repositories" the simple "no pain" use case often can't exist. For instance. You can't ask the Hibernate project to only build one Hibernate component just for you that you can "just download", but no one else can reference by version. What you're saying is a consideration for the "big giant versioning infrastructure" that it allow someone to just download and use things. I don't disagree. 
Generally speaking, Python is backward compatible, so anything written for 2.5 will work for 2.7. The jump to 3.0 is the one that would break existing scripts.
Ask in #python if you get lost. And those are two excellent sources to learn from.
If you actually used the snippet you posted... Open another terminal window: ps waux |grep python find the python thread and get it's PID then: kill -9 $PID_OF_PROCESS you should set a halt condition, or signal; but everyone needs to learn how to kill a zombie process :-)
I'm really hoping this isn't an interpreted python, but something closer to RPython and then compiled down to machine code.
Lucky you! Sorry, don't have enough details to suggest a solution (ie. I don't know what's broken). As for terminating the program, the kill -9 mentioned elsewhere is the will always work, "Boom Headshot" method. Ctrl-C will usually work, unless console I/O never gets a chance (ie. threads, tight loops with no print statements, GUI, etc.). Best of all is a nice polite exit condition you can trip. P.S. in my experience...when picking strobe rate for human interfaces, and depending on the specifics, anywhere from 25 to 60ish samples per second is the sweet spot. More is generally wasteful, less is jerky. 
There are so many great and up-to-date resources available online. For one, "Python Osmosis" on YouTube. 
could somebody provide step-by-step instructions on how to install opencv and pyopencv to osx so that one could use also iSight with it? (for me it has been a process of repeated failures throughout years) ..or provide similar instructions for e.g. parallels or virtualbox running debian/ubuntu? Tried google, been trying that for several years.
Great! I love when people also post failures, this is sadly lost art in the field of science. I am sure that R.P. Feynman would've upvoted this ;)
Yes. For new features and additions that the book doesn't cover, just check [What’s New in Python 2.6](http://docs.python.org/whatsnew/2.6.html) and [What’s New in Python 2.7](http://docs.python.org/whatsnew/2.7.html).
pyparsing is pretty cool. Most importantly, it is pretty easy to get a provably correct parsing engine because you can test simple parts easily.
As anyone might when they've worked as hard as you to bring sanity to the multi-layered Python packaging world. We've got your back, man! :)
Personally I think a problem with writing this type of fast python is you can end up sacrificing good design quite a lot for speed. Using classes as rarely as possible, and when you do, interacting with their properties directly can get a little nasty on a large code base. Similarly, minimizing function calls isn't something I like to do much. When I'm starting into a fairly big project I like to make anything that's over say ten lines a function of its own if possible for a more functional/agnostic design. I guess in any language though, a lot of the time you're going to have to make trade offs between readability and performance if speed is your main goal.
There's plenty of slow programs in fast languages (C, C++, Java). The problem is, it's hard to modify them, so they can't be made faster (without a lot of effort). A lot of the things which absolutely murder performance (algorithms, data structures, system calls, IO) are hard to change once the program is written, especially in static, brittle and verbose languages. In Python, it's often easier to fix fundamental problems. But I'm mostly preaching to the choir here.
It depends on the book. If you want to know how to write modern Python, maybe not. Though the only really big thing you are missing from the core language is the "with" statement. If it's domain specific (machine learning, AI, algorithms) then it's probably not very Pythonic anyway (lots of domain authors neglect Python style guides, and just do whatever works for them) so it shouldn't really matter.
I would use Celery, http://packages.python.org/celery/reference/celery.schedules.html Advantage over cronjob: Written in python, ability to catch errors and retry tasks .. 
But that is where a clean interface really shines, because a lot of times, you can hide your performance critical code behind a clean interface. Not using classes seems to prevent that to some degree. That said, performance optimization is probably more useful at function level than at class level anyway.
Alternatively you could do this without the subprocess call using something like [this](http://www.dabeaz.com/coroutines/follow.py) for example.
Oh, cool. Thanks for working on bindings, I have never been brave enough but have often benefitted from it. I'm using pyPortMIDI for some algorithmic music these days. (Not open-source yet since I need to publish it in a journal first.)
The speed problem is only an issue for language purists who want to do **everything** in exactly one language. I'd argue that a week of optimizing python code is better spend with one day of doing the intensive parts in C (or cython) and doing something new in the free time left.
Can someone please tell me what 'profiling' means? Thanks. :)
For most cases that is true, however there are times when speed is very important. Right now I am re-building a process to import 1000's of json records from one system, massage them into model instances, and then import into our database and lucene index (think 20-30k database queries per import). Since the end user has to wait around until the process is done, it needs to be fast, but it still takes a long while to do everything with a single python thread, so I've taken a more unconventinoal approach. I set up a twisted server to run in the background and I route the heavy lifting over to that. I can't use threads in my primary app without killing performance, but I don't mind so much with the twisted worker service. It used to take ~5 minutes to import 10,000 records, now it takes 20 seconds. It's annoying that I have to do this, but I am really enjoying python otherwise. It's a great language. Just wish it had better multithreading support. 
It was PEP 365. http://www.python.org/dev/peps/pep-0365/ I believe it was rejected due to the editors recoiling in horror at the gratuituous whitespace in pkg_resources.py, or they didn't find PJE to be motivating enough. Wheel http://wheel.rtfd.org/ is designed to be a replacement for egg based on the new packaging peps. It might be worthwhile to try to include a wheel-only installer (doesn't have to know how to run setup.py) in the stdlib.
http://docs.python.org/library/profile.html
Wow, thanks, that looks really great. Like a supercollider in python.
The book is "gray hat python".
http://celeryproject.org/
Please define "a program where "speed" really matters".
How do you guys find namedtuples? I've been avoiding them because I don't like the fact that they use eval internally.
Don't just claim things. Provide substantiation for your claims. Don't just say that Python is slower than Ruby. Prove that this is true and that it is true for meaningful cases. When you do not even make the slightest effort to back up what you are saying, it comes across as clear trolling.
Yes :)
Also look at the [multiprocessing](http://docs.python.org/library/multiprocessing.html) module when you wish things had better threading support
Take a look in the bug tracker and search for namedtuples. I once made patch that has only a few percent performance hit on access but does not use eval. This hit could be eliminated by using Cython or so. 
I've skimmed the whole book and read a few chapters. For the purposes of the book, everything should apply to 2.7.x just fine. As others have mentioned, porting to 3.x later may be problematic, but guides and tools are available online to help (search for "python 2to3").
processing graphics or audio in real time (=while a user watches/listens), or loading up a gui application where enough processing has to be done in the beginning that you not only need a splash screen, but even one with progress bar.
yes. why should he not like pypy?
That is very cool! Thank you for sharing!
Isnt it common knowledge? Has python come out faster in any test ever? Even the most mundane simplest cases, like generating fibonacci numbers, python fails. 
Generally you'd try and avoid creating new objects often though. Perhaps tricky for particle systems and the like - you'd probably need a C extension to make them efficient.
Learning Python from Mark Lutz covers till python 3.1. I think to start nowadays with 2.5 is not a good idea (you are learning for the future I supose and python 3.3 is already here). At least you should focus on python 2.7. 
&gt; The speed problem is only an issue for language purists who want to do everything in exactly one language. Your argument is based on the assumption that there are disproportionately important spots in the code, “intensive parts” that can be rewritten in a faster language. That’s fine as far as it goes, and I have no problem with getting hard data and optimising based on it, but what happens when you’ve already picked the low-hanging fruit and the profiler confirms that you don’t have any real hot spots left? I’ve run into this several times on recent projects, where I have a Web front-end of one kind or another and Python behind it. As a glue language, Python is great. As a language for implementing more significant data processing algorithms, it’s also great as far as prototyping and getting a proof of concept set up quickly. But as a high performance language for production code, we’re about to replace it pretty much throughout all of those systems, because for our particular applications, an order of magnitude or more of performance hit compared to what some other languages offer is too high a price to pay for having nicer, more maintainable code. This isn’t because we’re “purists who want to do everything in exactly one language”. In fact, most of these projects call down to C code all the time to access system APIs and the like, and some of the projects integrate parts written in four or five different progamming languages. But at some point you have to acknowledge that with the technology we have today, a mid-level, dynamically typed, kind-of-interpreted language is going to be slower generally than a low-level, statically typed, compiled-to-native-code language. And if you’re doing non-trivial data processing, and the difference means your web service responds in 1 second or 10 seconds, that does actually matter, because it moves from being a quantitive performance issue to a qualitative usability one. So I don’t think you can just brush Python’s limited performance under the carpet quite as easily as you tried to there. Sometimes the correct solution is not to spend a week optimizing the Python code, but to spend a week rewriting the entire codebase in a fast language and dump Python altogether. That’s not some sort of terrible insult, it just means that sometimes, even though Python may have served a useful purpose, another tool is a better choice for the next part of the job.
I don't do any web stuff, but from what I understand interpreted languages are used heavily in production by you guys because of the inherent latencies of the web and the majority of the CPU cycles spend in the database. Well, how I see it, everything computational expensive has to be done by C (or equivalent language). The interpreted language just glues the parts together and can be used for tasks beyond that gluing task if there is enough latency by other tasks. Right? &gt; So I don’t think you can just brush Python’s limited performance under the carpet quite as easily as you tried to there. Sometimes the correct solution is not to spend a week optimizing the Python code, but to spend a week rewriting the entire codebase in a fast language... That is exactly what I said &gt; ...and dump Python altogether. If python is too slow for the task at hand, then it's the right decision to dump if after having served as a prototype language. I don't see a problem here. I think you just misunderstood what I meant. I didn't mean: * Use python and shut up, it's fast enough I meant: * Python is fine as it is. If you need something to be done fast, use another tool (C/C++) for 90% of the CPU cycles and have Python be what glues these parts together. My guess: Web development comes more and more computational intensive these days. It's time to refactor code out to faster static languages. But that's not Python's fault.
they only use eval to create the class. once created it's like any other class that inherits from tuple. while I agree that the eval is kinda silly, it's been intensely tested and doesn't hurt anything. you're definitely not feeding it untrusted input. edit: well, unless you create a namedtuple with untrusted input as fields. now that I think about it, that is kinda bad ... edit #2: oh, actually they filter the names to only allow python identifiers. nevermind.
I strongly recommend not using the shootout as a reliable benchmark; I'd go as far as to posit that it might be worse data than no data. You see, Alex Gaynor discovered rampant unfairness: http://alexgaynor.net/2011/apr/03/my-experience-computer-language-shootout/ That said; ruby's default implementation is definitely pretty slow. I've heard that their default implementation is to cpython what cpython is to pypy.
[to summarize] The post suggests that it is a dependency bug in python-visual package and `sudo apt-get install libgtkglextmm-x11-1.2-dev` should fix it.
Depends on the problem to solve and the experience of the engineers with this problem whether they're faster with or without a prototyping phase. It's just so much easier to turn around in an dynamic language and later be concentrate on speed and code quality in say C++. But I bet you know this . You might have done what you're about to do in python before, a number of times, so you can go to a static language right away. Good luck :D
If you perform audio processing computations in Python's Numpy / Scipy, it's perfectly fast enough to do real-time audio processing (10ms window).
OMG, why so many years without knowing it!? THanks
Nope, it's not. It is plenty fast for stuff you can vectorize, because Numpy will take care of that. Anything you can't vectorize though, you're out of luck. That is, basically everything that has some recursive part--which happens an awful lot in audio processing. Really, my hopes are on Pypy here. But for the time being, you will have to use weave.blitz or Cython/Pyrex/Ctypes.
It means analyzing the performance of all the functions / methods in your code. It is often said that 'premature optimization is the root of all evil'. That means that people spend a lot of thoughts and time in trying to optimize code (and make it more complex) without the proof that this optimization is effective or even necessary. Profiling gives you precise information about how often a function / method is called and how long it took. The report of a profile run tells you where you can improve the code most effectively. See dwdwdw2's comment to get started with profiling or check out PyMOTW. 
Take an upvote for relief ... -19 is far too much :-). You're right: For **pure** raw performance Python is not the language of choice. That's why Qt is written in C++ or NumPy uses C extensions for the number crunching and most of the CAE applications are still written in Fortran. But for what Python is great to use, it's more than fast enough. You can handle huge amounts of data with sets and dicts. Create ultra-performant GUI with PyQt (yes, C++ is in the background, but you design your app with Python). Your 'usual' web application will have lots of bottlenecks before pure Python performance will be the limitation. Ruby is in a similiar corner. It simply doesn't matter at all wether Ruby is some percent faster or slower than Python.
If you haven't already heard, NumFOCUS has set up a fund to help pay for his three daughters' education: http://numfocus.org/johnhunter/
That is so true ... Off-topic: When your app is getting larger and more complex, design (I hate to say it: design standards) become very important. Too me, that's actually a possible dealbreaker for Python rather then performance. Sometime I just need static typing, interface definitions like in C# to help me handle the code.
I wouldn't care too much about the implemenation details of standard lib modules (from the users point of view). The guys who write this stuff know what they do. But: It's good to be attentive about best practices.
Well deserved. Well done. Thanks John. Thanks PSF.
Thanks for posting this, @takluyer. I just came over to do it and as usual, you'd taken care of things. This is a fitting tribute to an extraordinary person.
Um, no - http://deeplearning.net/software/theano/. You can define it in Theano, which can compile it to C / CUDA. It's not a natural way to do things, but you shouldn't have that much to do in it.
Yeah this was also my first thought. I even tried to do some simple conversation from SC to pyo. Glad you like it.
Don't forget she also worked for Ksplice!
def factorial(n): if n==1: return n*factorial(n-1) this is the factorial code
hahaha how'd you find that. how would something like this work def factorial(n): x==1 while n&gt;=1: n=n-1 x=n*(n-1) x=n*x return x
She also worked for Ksplice!
Thanks! :)
Better optimizers would allow you to avoid most of this. 
def factorial(n): x==1 * while n&gt;=1: * n=n-1 * x=n(n-1) * x=nx * return x
I don;t knwo why the spacing isn't working I tried what formatting help told me to do. the astrics are the best i could do in terms of separating them. Can you please check mmy factorial code and point out my errro?
Hit "edit", stop hitting "reply". Jesus you suck at Reddit.
Why don't you just use the multiprocessing module?
Or [PasteBin](http://pastebin.com/) or [TinyPaste](http://tny.cz/) or [IDEone](http://ideone.com/)
 Function Name: printTimes Parameters: A positive Integer. Return: None. Description: You are hired to develop an educational software package. Your first job: Write a function printTimes() that will print the times tables (1 to N, inclusive) on the screen. &gt;&gt;&gt; printTimes(9) Times: 1 2 3 4 5 6 7 8 9 1 1 2 3 4 5 6 7 8 9 2 2 4 6 8 10 12 14 16 18 3 3 6 9 12 15 18 21 24 27 4 4 8 12 16 20 24 28 32 36 5 5 10 15 20 25 30 35 40 45 6 6 12 18 24 30 36 42 48 54 7 7 14 21 28 35 42 49 56 63 8 8 16 24 32 40 48 56 64 72 9 9 18 27 36 45 54 63 72 81 Your function must print a header (Times: 1...N) and a first column number that goes from 1..N, while the interior of the grid is the X * Y value. Hint: Using two loops (one inside of the other) is an easy (but not the only) way to accomplish this. You may want to use tab characters to space your grid out correctly. Also what is wrong with this factorial code? def factorial(n): if n==1: return n*factorial(n-1) Formatted your question, by adding a 4 spaces to the start of each line. That being said though, reddit, or anywhere else is not a place you can put in a question that your prof gave you, and expect an answer to come out. Programming isn't one of those things you can just entirely copy and paste, and ituitively understand right off the bat. Take the time to learn *something*.
&gt;don;t, knwo, i, asterics, mmy, errro Take the 15 seconds it takes to proof read your comments, and then show us what you have tried. It's 4 spaces before a line of text that is needed to turn a string into formatted code.
I'm here but how would I find you? :-)
Lol the moment when you realize the keynote speaker answered you on reddit
You have an apt username.
Agreed. Books are a waste of money unless you need a hardcopy for some reason. There are countless tutorials out there, and unlike a book, are always current. Hell just read the official Python tutorial. Unless of course the info you're looking for is only covered in a specific book.
You can use numpy *and* use recursive algorithms. Numpy is still useful for plotting and other parts of the algorithm. But you are right: if you can express your whole algorithm in terms of numpy functions, you are probably good. It's just that this does not happen very frequently in audio algorithms.
&gt;EDIT: Downvotes? Seriously? * Making this kind of edit pretty much guarantees further downvotes in and of itself. * Your original post reads extremely trollish, and you ought to know this if you've been around long enough to know what you're talking about; Pythonistas have been dealing with people saying "lol it's slow" since approximately the first microsecond anybody other than GvR had heard of Python. * You make claims but do not substantiate them. * You imply that languages can be compared by some absolute measure of "speed", which is patent nonsense in many ways. It makes about as much sense as stating that a gravel road is slower than a highway.
hi guys, thought I would just share with you the first bit of python I've done probably since this time last year to be honest. Its all pretty simple and works out the variance of a set of data that you give it. If there are any ways I can improve it please tell me as I'm here to learn! thanks for looking guys :)
Thanks, i had never heard of mechanize, it looks promising. I also partially hate you, its nothing personal, but i have just spent part of my Saturday night reading about how to solve a problem i have been having at work that mechanize could solve.
I went through each of the built-in functions (and some imported modules I use regularly) in the Python library and make a text file for it. That file included the definition and syntax you see at the [docs](http://docs.python.org/library/index.html) as well as an example I wrote. I made a basic GUI that listed those functions by names (sectioned into folders such as Built-In Functions, math, os, random, etc). You navigate to the function, highlight it and hit select, and up pops a window containing the information in the text file. [Overview](http://i.imgur.com/Ubj49.png). I only have access to an outdated version, the file extensions were changed to .txt from .py once I realized that was pretty bad practice (even though they were never executed as a python script). The GUI itself is pretty crude, but worked for me at the time. I'm getting ready to check out PyQt so I might port it from TKinter instead and tidy it up a bit. It gave me a good basic intro to GUI programming as well as some functions I didn't know existed.
Very nice! I always wanted to get into GUI programming, though I believe I'm going to create a web application for mine, sooner or later. But that is a pretty rad first project! 
IIRC some guy got kicked out of university for doing something like this.
If that was it then great, but seeing as you know about it I guess my warning is fairly irrelevant :)
The first real project I had that actually did something worthwhile can be seen as /u/tweet-poster. It's not really amazing in itself, but it was one of my first largish projects and it definitely had helped me get my toes wet.
My first interesting project in Python was a script that takes Banshee playlists and packages them up as a new album. It duplicates all the files, updates the id3 tags and cover art, and saves them in a new folder.
/u/original-finder aperson beat me to it. I was out tonight, not my fault.
Very, very nice! I'm hoping to scale this project up eventually, thinking of whipping up a prototype web front-end in CherryPy...Possibly, hmmm...
I've always been interested in how these applications work. Do you automatically run said programs when you login to your computer? Or do you just leave your computer on 24/7 and let it do its thing?
Stop being a helicopter parent. If he legitimately doesn't have enough time advise him to drop a class. If he doesn't know how to study that's his problem and failing a homework will give him a kick in the pants. Your intervention will only stunt him.
I used to use an Amazon AWS instance to run it 24/7, but my free tier for that ran out. My computer is on 24/7 anyways, so its always running in a screen.
&gt;It seems David's Python includes a builtin for currency- and tax-aware decimals. Don't take it personally, guy seems like a douchebag anyway.
My first major Python project was a proof-of-concept utility for determining if you already have a portion of a BitTorrent payload downloaded on your computer. All you needed to do was provide the utility with the .torrent file and a directory that you think may contain the payload. I was planning on expanding the utility to be more worthwhile, but I've since dropped out of the whole major-league file sharing scene and focused on finishing up my degree. https://bitbucket.org/torik/local-bittorrent-file-finder/wiki/Home
I just wrote a [lexer](https://bitbucket.org/EricFromCanada/pygments-main) for the [Pygments](http://pygments.org/) project for the [Lasso](http://www.lassosoft.com/) programming language. 
My first true Python project was a handle within [Nuke](http://www.thefoundry.co.uk/products/nuke/) which would swap the output settings for 40 different nodes between rendering my composited video at proxy quality on the local machine, and a (much faster) full quality render via the company's new server farm API. This single tool was responsible for transitioning me between a runner and a junior compositor. I was a bit sad because it seemed so obvious. I did get in trouble with the data wranglers though, because the API was private, and I was somehow jumping the queue ahead of more urgent render jobs. tl;dr Being good at compositing is about keeping secrets and actually reading the manual.
I'm currently making a program to test you on elements and their symbols. I hope it'll help me study and other people in the future. 
does syntastic (for python) offer anything over what pyflakes-vim offers? pyflakes-vim works great for me.
I've done a handful of random python toys to stuff, but my most meaningful project is the minecraft server I run: http://camin.us/ Written in django, it combines with a [special, super minimal bukkit plugin I also wrote](https://github.com/tdfischer/bukkit-caminus) to handle whitelisting, server news broadcasts, mail, on-site inventory viewing, and other fun stuff. Best part is that it is all 100% open source, so anyone can completely replicate the site and start their own in a few minutes.
Hangman solver!
I'm not sure anything I've done is 'meaningful', the first two I wrote that did what I *wanted* them to do where a [Reddit Thread Comment Counter] (https://github.com/DasSnipez/Reddit_Thread_Source)that looked for new comments on a given thread and alerted you when they where posted and a fanfiction.net downloader that, you guessed it, downloads fanfiction from fanfiction.net to your computer.
Nice project! The first actual project I did with python was writing a script for my Nokia N900 that acts as a server that sends the accelerometer data to clients. Then i wrote a Unity component that connected to the phone (nothing fancy, the data was transferred via UDP), allowing me to use my phone as a steering wheel.
I had to organize genetic data from multiple databases, do a statistical analysis, and present the graphs. I tried R and was ready to shoot people. Python made it so damn easy.
At the risk of sounding like a retard, is it possible to do on google free app hosting?
You have no idea of how happy I am right now... It's like someone just gave a kid a brand new lego set.
[This](https://github.com/bunburya/FlyingRobots). A three-dimensional clone of the old BSD game [robots](http://en.wikipedia.org/wiki/Robots_%28BSD_game%29). I think currently about three people have it installed, and I'm the only one who ever plays it. But I haven't packaged it for Windows yet, so once I do that I guess it'll hit the million user mark.
Trust me, I agree with you on the lines of code; I regularly cringe when I look at that codebase, it's not very efficient. I'm going back sometime later this fall to completely rewrite it, it's an itch I've been dying to scratch! Part of the problem I had was the database schema I was dealing with. The data and table layout was such a mess that I had to jump through so many hoops just to get it presented in a clean format. I've done similar projects since then (just with different data, different PDF layout, etc) and I am sure I could rewrite the original program with about half the lines of code. But that original mess was a necessary pain so that I could learn the "wrong" way of doing it, and therefore the "right" way of doing it. I don't mean to sound like I'm bragging, I just love talking about this stuff. God I love python!
Oh damn, oh damn. What's the difference between AWS and Google App Engine's free hosting, if you don't mind me asking? 
A lot. GAE is very restricted in what you can and cannot do for applications, and limits within those applications, like resource consumption, number of database/fs queries etc. AWS is flexible in that you get a virtual machine to do with what you wish. That can be ANYTHING as you have root access.
1-GAE would probably be enough, please read over https://developers.google.com/appengine/docs/quotas to make sure. Even paid applications on GAE have certain limits in particular categories. 2-AWS would definitely be better for this type of application. AWS is scalable as well as you can spin up new instances and as many instances as you need whenever you want (for a price of course)
Thanks for the input, I appreciate it! Web applications are necessarily my realm of expertise, though I'm learning more and more about them each day.
That's pretty tautological though. We'd all like better optimisation in the tool chain, but it's never perfect, so we'll probably always have to consider making changes at the code level when performance is important.
True enough. Python doesn't exactly make life easy for optimization either. That speaks to Guido's advice though - Python isn't intended to be an *efficient* high level language, but is designed to work well with efficient *low level* languages, namely C. 
&gt; I know it's jerky, but if this system doesn't work for you I give a number of rats asses that can be counted on zero elbows. But you care enough to point this out to people? Where I come from, people like you are known as "jackasses."
Not only do you ignore every design trade off that comes from dropping down into C, but you dismiss it out-of-hand through the moniker of "language purist." Oh yes, and I love how optimizing Python code is *obviously* seven times more costly in terms of development time than dropping down into C. Just yesterday, I spent about 5 minutes profiling my Python program and another 10 minutes tuning some hot spots. It resulted in an 80% performance increase.
There was a pretty good talk at Pycon this past year that discusses the various parsing options for a pretty nasty data format (mediawiki). There's a video online here: http://pyvideo.org/video/708/parsing-horrible-things-with-python It won't tell you how to do it exactly, but it should help you to evaluate your options.
I screwed around with both a few months ago. Overall Pygame seemed to result in quicker development time for simple games. Pyglet's use of opengl presents both complications, as well as bonuses, and it works with Python 3 which is great. I didn't like the docs for Pyglet, there isn't a very fluid feel to the way the tutorials are laid out, and they haven't updated for Python 3, so that resulted in some tinkering. I'd go with Pygame if you aren't planning on creating something that will need heavy optimization, but if you need openGL and Python3 support, Pyglet is what you should pick, but the learning curve is a lot steeper than Pygame and it really turned me off of Pyglet.
I tried to use pyglet for a simple graphics app (zoom/pan/crop an image relative to a fixed window, which is the dimensions of a physical page with bleed, and when "done" emit an imagemagick "convert" command that produces the same result) and got bogged down in how the tutorials and docs assume you already know OpenGL - and particularly, which things you should stop looking to pygame for and dig into openGL instead. (As far as I can tell, "draw a rectangle" is one you're supposed to use raw openGL for...) Did I miss some better tutorial/docs, or simply pick the wrong library?
As far as I am aware you didn't miss anything, because those are the exact same docs I looked at. The assumption that you know openGL is one of the things that really killed it for me as well.
no magic, but certainly more than one way to do things. but since i can’t imagine how to do it differently, because of corner cases which might not work one way or the other, that’s fine.
For instance, I managed to have a background image with XChat, a windowed IRC client. I'm wondering how I would go about replicating such behavior. http://i.imgur.com/S1u9Z.png As you can see, a non-editable textbox manages to have a background image. 
&gt; As you can see I can't see the background image in your screenshot. &gt; a non-editable textbox under most toolkits that behaviour can be simulated with a label widget, which can have both an image and multi-line text. For a text widget (which generally implies much more complex interactivity - and often formatting), it's less common to be able to provide a background image.
OK, I think the solution then is going to be down to personal preference. Tkinter, wxpython, pygtk, pyside/pyqt, kivy... all of these can do what you want. I think your initial searches didn't seem positive because you looked at text widgets and saw that they didnt have options for setting the background. That's the not way to think of it - you're not looking for a text widget that you can set a background on, you're looking for how you put text on top of an existing image and each toolkit will have different ways. For example, in tkinter you would make a canvas widget which you'd then add an image to then either add a 'window' (which is any tkinter widget such as a Label) or do a create_text call on it. There is also a Place packing method which allows you to specify absolute positioning for widgets so you can have them overlap (I've not tried this one, myself, I generally use pygtk for my gui stuff but packing is a pain for it). Other toolkits will have similar methods - search for how to overlap widgets or how to make a composite widget (which you can sometimes do by subclassing existing ones) or how to directly play with a widget's canvas or that of the window the widgets are being packed into. That sort of thing.
absolutedestiny mentioned the tkinter canvas widget, which I think can do what you want.
this is great for shell-scripts and other smallish sysadmin stuff where you want the much better text processing powers of python but still want readable code with less boilerplate. Thx for the pointer!
Good Guy Ginger: Has vast collection of souls; Acquired them honestly.
if it’s media heavy, you should consider *not* to use mp3 as it’s a old codec. ogg is much better,a nd the upcoming [opus](http://www.opus-codec.org/) codec seems to give extremely good quality per bit. like 32kbps-already-sounds-ok good.
FWIW, here's a snippet of Tcl/Tk code showing selection of text on a canvas. Translating it to Python is up to you, I'm afraid ;-). This text will happily overlay an image, or go behind a png with alpha if for some reason you want that. Using only one text item makes selection code easier, but limits you to a uniform font/style/colour for all the text .. if that's too limiting, you'll need to write a lot more code to determine which canvas items need to have their selection set. #!/usr/bin/tclsh package require Tk pack [canvas .c] set tw [.c create text 100 100 -text "Hello, World!\nthis is your captain speaking"] bind .c &lt;ButtonPress-1&gt; [list select from %x %y] bind .c &lt;ButtonRelease-1&gt; [list select to %x %y] proc select {what x y} { set t [.c find withtag current] set i [.c index $t @$x,$y] .c select $what $t $i } wm protocol . WM_DELETE_WINDOW exit vwait forever 
Pyglet had an update recently. It does a much better job of using modern graphics hardware than Pygame does. Yes, Pyglet does expect you to be familiar with OpenGL for more advanced behaviour, but I never found that to be an issue for basic rendering.
Btw, if you put a blank line before your first asterisk reddit markdown will parse it into a list for you: Pros: * Appears to have a fairly active community * good documentation * plethora of tutorials and examples. Pros: * Appears to have a fairly active community * good documentation * plethora of tutorials and examples. 
pypy is great, but it lacks support for playing back audio, plotting and scientific functions like fft or filter. That said, I very much hope that I will be able to use pypy in the future. I will certainly re-evaluate pypy once they finish their numpy re-implementation.
It depends somewhat on what level of ability you are at. For a beginner I'd recommend PyGame; it's easy to get in to, and there are plenty of tutorials/examples on the net, not to mention books, including my own 'Beginning Game Development with Python and PyGame'. If you have more experience with games, I'd personally lean towards Pyglet. It has a more Pythonic interface, that isn't restrained by an underlying C library.
Most GUI toolkits will let you override the "draw" method for any widget. That lets you draw the widget any way you want. Typically you would subclass the widget, do whatever drawing you need, then call the parent class' method to finish drawing the rest of the widget. For example, from PyQt (or PySide): def paintEvent(self, event): painter = QPainter(self) pixmap = QPixmap('image.png') painter.drawPixmap(0, 0, pixmap) super(Widget, self).paintEvent(event)
I haven't much experience with either. but wanted to recommend you cross-post to /r/django :)
duckduckgo is awesome for anything but actual search results, as it takes them from bing. if you happen to need a stackoverflow question, definition, special search like the ones you mentioned, it’s good, but for actual search terms, bing is so much worse than google.
Interesting. This is actually the first I've heard of Opus. However, the thing I'm building is for work, and they use mp3s, so I don't get much say in the matter ; ) 
yeah, opus was released just this month, and seems to be a pretty fearsome beast for being [better than anything existing](http://en.wikipedia.org/wiki/Opus_%28audio_format%29#Quality_comparison) and completely free.
Also consider [envoy](https://github.com/kennethreitz/envoy) (by the author of the `requests` module).
Right, right. I edited my response accordingly. Those functions are part of scipy, not Python. It does not alter the argument, though: Numpy does not provide those functions, neither built-in nor as package, and is thus not ready for use in my application yet.
I am currently playing around with pyglet and are very happy with the features provided, and the possibility to do some openGL magic if you need to. OpenGL is hard to learn, but worth it. 
This is pretty brilliant and just about exactly what I am going to need for the project I happen to be working on. Neat!
It's on Github; feel free to add this as a request in the issue tracker :)
In Gtk, you can modify the theme in the regular file $HOME/.gtkrc-2.0 (create it if it doesn't exist). This is called the "style" of a widget so give a widget (by name or class) and the style you want to use there (somewhat like CSS). Make sure to set a name on the widget (either in the GUI builder - recommended - or using widget.props.name=...) in order to be able to find it.
This + celery + fabric. It's like a hyper-powered greenscreen war-room...
&gt; The way you use the term 'resolve' for configuration conflicts is a bit &gt; unusual. The config.commit() approach overwrites old with new, and &gt; config.include() allows you to extend old with new, but neither resolve a &gt; conflict as such - they are more different ways to approach a situation &gt; to avoid any conflict, surely? Pyramid has a function named resolve_conflicts which takes the pending actions and literally tries to resolve any conflicts in them based on information in each action about how it was added. I don't consider that function misnamed. Maybe it's a stretch to say that humans also "resolve" conflicts by calling commit(), it'd probably be better to say they avoid conflicts, so there you're probably right. &gt; Why spend a quarter of the document showing how configuration can be &gt; included from another file using config.include before explaining why &gt; you'd choose to do it this way? Wouldn't it be better to clearly set out &gt; the use-case first (ie. inheritance/specialisation of configuration) and &gt; then provide the example? Instead I was just scratching my head for 5 &gt; minutes, wondering why I was reading examples that could be replaced &gt; with an import and a function call, until eventually the purpose became &gt; clear at the end. Writing docs is hard. &gt; Why have the magic 'includeme' callables? 'Explicit is better than &gt; implicit', and all it's saving is about 10 keypresses each time, at the &gt; expense of making things a little less transparent to the user. Canonizing includeme means that package authors need to think less about what to call the thing, and package consumers need to think less about what the thing is called. And given that we want to canonize one name, we might as well treat it specially. It's no worse than __init__.py and somehow people learn Python.
I've been using django's built-in for a while, but after attending [Erik Rose's talk on nose](http://www.slideshare.net/ErikRose/djangos-nasal-passage) at DjangoCon this year, I'm looking to switching to nose, if only for the performance increases he demonstrated.
But this way to do will not be efficient isn't it ?
also check out http://kivy.org
Google it. Shit what a biiiigggg fukin deal we have here. site:django.me render
http://pressedweb.com/django screencasts
So I prefer: filter(User.name == 'ed').filter(User.fullname == 'Ed Jones')
less efficient than what?, it should be identical to: filter(and_(User.name == 'ed', User.fullname == 'Ed Jones')) See: http://docs.sqlalchemy.org/en/rel_0_7/core/expression_api.html#sqlalchemy.sql.expression.and_ especially the note: | The &amp; operator is also overloaded on all _CompareMixin subclasses to produce the same result.
There's certainly what I'd call magic. It hacks `sys.modules` so that you can do `from sh import ifconfig`, although it doesn't define `ifconfig`. I'd be somewhat wary of it for that.
I searched around for the video, but I guess it's not up yet. I think it would be up [here](http://pyvideo.org/) before too long.
Blatantly ignoring the Zen of Python....
maybe you can do something with _iter since it returns a generator.
Ya, what's wrong with the tutorial on their site?
I made mine by following the pseudocode on Wikipedia. Can't say it was effortless though.
after reading through this thread I took the dive and started investigating Pyglet. I cruised through the tutorials just fine, everything seemed awesome, but I then *slammed* into the brick wall that is openGL. I have absolutely *zero* experience in the area. At most, my requirements will be drawing simple 2d shapes (mostly rectangles), do you know of any good, super basic intro to pyglet's flavor of openGL? Part of me thinks I should just switch to Pygame, since I only need 2d graphics, but, Pyglets audio support, as well as it's multi-monitor support *really* make me want to stay. 
*You can say that again.*
That's what she said :)
There is an extra field called “keyword” :)
I'd call it “hooking into the import system” and it's hardly a hack.
No, it wouldn't. Python uses the "and" keyword rather than an &amp;&amp; operator. Unfortunately, Python does not allow types to override the boolean operators `and`, `or` or `not`. For this reason, SA repurposes the bitwise operators &amp;, | and ~ as bolean operators. The biggest misfortune of this is that precedence of these is higher than one would expect of boolean operators, in particular it is higher than e.g. ==.
I loved that even though I'm an American and therefore have no use for unicode. Reminds me of this brilliance from a few days past: http://imgur.com/Ueco0 
At first I was all like "why can't he learn other languages?" then I was all like "oh, American, not Armenian. Right."
Nose lets you perform parallel testing http://nose.readthedocs.org/en/latest/doc_tests/test_multiprocess/multiprocess.html
Just a shame that building a good navmesh is a pain.
Well, A* is a fairly well understood algorithm and easy enough to implement in Python. The hard part with most AI algorithms is coercing your world representation into a form the algorithm can handle and then coercing the result into something you can use, and 3rd party libraries can't do much for you there.
&gt; hmm, why does he claim that python hasn’t fixed unicode? Until Python 3.3 fully unicode compliance was a compile time switch on the interpreter and wasted 4 bytes for each character. Against perl Python stands no chance in regards to unicode support. We have very, very bad unicode support. (No regular expression support for unicode categories, no transliteration, no locale aware case mappings, no locale aware ordering, no one-to-n case mappings etc.). It's not even funny how bad Python is doing in regards to unicode support. I basically gave up implementing parts of the CLDR when I contributed to Babel because it was just not feasible in Python. &gt; why not just that if you do it in one line, anyway? re.sub runs the regular expression compiler when executed (has a very naive cache). The compiler btw is written in Python and extremely slow. Other programming languages with regular expression literals usually cache them. Some languages even jit compile regular expressions. &gt; nonlocal… i agree that that keyword’s ugly, yet i never used it. Nonlocal does not even exist in 2.x which most people use. It's very annoying that it does not exist and most people work around that problem with mutables stored away in closures. Generators are in most cases not a proper replacement.
@unicode issues: thanks! the issues you raised here in your comment seem important. yet they didn’t appear in the talk, which i wrote this for. (also the only one-to-n case mapping i know is ß↔SS, which shouldn’t exist anymore, because we have ẞ.) the unicode categories in regexes really bug me, i’m sure i’ll need them at some point. @regex-oneliner: i don’t think i get what you mean with your reply to the re.sub thing, though. surely if you write a one-line substutution in python you either execute it once in an application’s lifetime or made a mistake. as soon as i use a regular expression more than once, i always compile it outside of the loop where i use it. nonsensical example: with open('foodstuff') as f: t = f.read() t = re.sub('spam', 'egg', t) eggplant_re = re.compile('eggplant|aubergine') for chunk in t.split('\t'): if eggplant_re.search(chunk): print('%s contains an eggplant'.format(chunk)) @nonlocal: as i said, i never used it, nor felt the need for, but i’m sure there was a reason for a whole new keyword :)
That was a great article.
Use saltstack.
The first link in the post is to the tutorial in the official site.
I've used */usr/local/www/&lt;app_env&gt;*in the past. Lately, I've been using */home/&lt;app_env&gt;* I try to make sure all of my apps can be installed via pip from git along the lines of: pip install -e git+git@github.com:myuser/myproject.git@release#egg=myproject
OK, I had to look up the versal-ß news. And the current situation seems to be that the ß-&gt;SS mapping should continue to be used for quite some time; the national spelling rules haven't been updated, and versal-ß has been marginalized on keyboards as AltGr-h rather than Shift-ß (which is currently "?"). The official stance seems to be, "We've made it technically possible, now let's see if anyone actually uses it." Apparently typographers are still trying to work out how exactly to render versal-ß; there are some quite different renderings. Anyway, just be glad that the Rechtschreibung ditched the ß-&gt;SZ capitalization variant that persisted alongside ß-&gt;SS to make word pairings that differ only in ß vs. ss in lowercase distinguishable in upper case. So things should continue to be good and painful for some time when it comes to how to handle case-changes in words that might contain a ß.
You might as well ask me to use the metric system.
I love how you always ping back a link to Django with a link to web2py.
Its been awhile since I've used it, but one nice feature it has is support for merge statements (aka upsert.)
Fun fact: **re** will cache the most recently used regexes internally, so compiling is only really necessary if you use a lot of them.
so that’s the naïve cache (s)he spoke of. nice, actually.
From StackOverflow: http://stackoverflow.com/questions/1262955/how-do-i-pick-2-random-items-from-a-python-set Looks like the code import random yourset # is your set random.sample(yourset, 1) will give you what you want, or is very very close
I'm not familiar with the issues, but I think unicode in regexes is supposed to be dramatically improved by the [regex module](http://pypi.python.org/pypi/regex). That's slated to eventually become part of the standard library.
i agree, but i believe firmly that ß↔SS was never a good idea: Mr Strauß simply isn’t called Strauss, even if his passport is printed in uppercase. people won’t start using it if it’s hidden on keyboards like that… “h”? wtf. my keyboard has ħ as altgr+h, and Ħ as altgr+H. ẞ lives as altgr+S and capslock+ẞ (linux makes a distinction between capslock and shift, as capslock does simply swich lowercase and uppercase variants of glyphs with an uppercase variant. e.g. altgr+shift+h with capslock on yields ħ).
Can you expand your description of the problem? Specifically * are you looping this (e.g., pulling more than 1 value from the set), or do you create the entire set just to extract a single value once? If so, why? * IFF you're looping, are the contents of this set mutating between loops?
In your situation I'd use a binary search tree implementation which didn't allow duplicates. Unfortunately, unless you code it in C, it will probably be slower than just using random.choice(tuple(yourset)) Alternatively, and this is a bit of a hack, if the contents of the set don't change then I'd use this import cPickle as pickle def get_set(): try: return pickle.load(open('path_to_the_set', 'rb')) except IOError: result = 'the code you normally assemble the set with' pickle.dump(result, open('path_to_the_set', 'wb')) return result ... although, thinking slightly harder, you'd **probably** just pickle the list'd set since that would speed up teh random.choice call
Eh? I think you put a "not" in my sentence somewhere. If I'm reading you correctly, we are in vociferous agreement that swapping ss for ß in proper names is wrong, evil, and something done only by gremlins while you're not looking. If you want to capitalize a name with ß in it, either keep it as ß in the uppercase (Weiß -&gt; WEIß) or use the new uppercase ß (Weiß -&gt; WEIẞ).
waa… you’re right, i really did that. i’m sorry.
I didn't mean to offend you, just something that I picked out. It's always nice to be reminded how powerful and complete web2py is :)
I would also throw [bottle](http://bottlepy.org/docs/dev/#) in there as well.
Amusingly, I also read "does not matter in names", and had to go back to check. (Not German, can just read a little bit, mostly ignorant about the issue, except for having heard it is called "ess-tzed" ;-) 
I see ... There're a lot of great web-microframeworks. I've used Flask recently to build a simple HTTP-API and liked it. I can't comment on the others like bottle, web2py, pyramid, cherry.py, ...
Flask http://flask.pocoo.org/
&gt; no transliteration In my opinion, this has no place in the language proper. It should be addressed by third party modules. 
This would be a complete web2py app: from your_module import your_function import os def index(): # http://.../yourapp/default/index form = SQLFORM.factory( Field('filename',requires=IS_MATCH('\w+')), Field('input1','double',requires=IS_FLOAT_IN_RANGE(0,100)), Field('input2','double',requires=IS_FLOAT_IN_RANGE(0,100)), # add more of your inputs... ).process() if form.accepted: filename = form.vars.filename output = your_function(form.vars.input1,form.vars.input2,...) open(os.path.join(request.folder,'private',filename),'w').write(data) redirect(URL('getcsv',args=filename)) return dict(form=form) def getcsv(): # http://.../yourapp/default/getcsv/&lt;filename&gt; response.headers['Content=Type'] = 'application/csv' filename = request.args(0) data = open(os.path.join(request.folder,'private',filename),'r').read() return data
Django can be a lot more lightweight than you think. Check out this two-file [microdjango app](https://bitbucket.org/cliff/microdjango/src/) I created. In order to run it, you just do `django-admin.py runserver --settings=settings`. If you really want you can probably put the settings in the views file and make a single file out of it. Edit: Not that I'm saying you should use django for everything. Flask is awesome. But if you're *planning* to move to django later, you might as well know you can start there, and not be overly heavyweight until you want to be. 
[Nagare](http://www.Nagare.org) 
Convert each item in the set to the 2-tuple (goodhash(x), x) and then use set.pop() Python's built-in hash() function is not a good hash function. It's intentionally very bad.
Well said, holdenweb! 
FWIW if you choose more than 1 value from random.sample it is random without replacement.
as we can see, it is better to have a crisp lightweight solution in a full-stack framework than a bloated solution in a lightweight framework :)
I was somewhat sure that you were wrong, but it's always more fun to prove it: https://gist.github.com/3745746 $ python test_randoms.py average randomSet time: 0.08780517 average get_one_random time: 0.04399419 Edit: fixed a small bug, reran
It contains mostly bug fixes. You can view the changelog on the download page.
This is friggin' amazing. This was invaluable in getting an understanding of Python.
If it hits cache limit it wipes the entire cache. Relying on that cache is a very bad idea.
was actually looking at it right before I posted. So, it's likely between web.py, flask, bottle, and cherry.py, with web2py and django down the line.
&gt; (stopped after 300 steps to prevent possible infinite loop)
Well out of those, I've used web.py, cherry.py, and django, and done lots of research on flask so I can't vouch for others, but I've done research on most of them, and I still like cherry.py the best. Web.py's templating is....odd at best (python is started with $, which seems like a good idea until you use jQuery), and has some weird inheritance issues if you ever want to put one of your classes in a separate file. It also has a really messed up authentcation and session management system bug that basically sends cookies upon cookies upon cookies to the user until they authenticate. Not good, considering it doesn't clean out your db. So I basically monkey-patched my own version, then found cherry.py and dropped it. Django people talk about how 'simple' it is to get stuff up and running, but it's for large projects. There's no two ways around it. It's GREAT for that, but you spend a lot of your time messing with it instead of just writing the code you want and getting done with it. I've looked at Flask very closely, because it's a lot like CherryPy (yay! And you can actually use CherryPy's WSGI server with Flask), because I like their routing system, but CherryPy works just as well for me. Quick to prototype, nice auto-reloader feature when you're in development mode (no ctrl+c, edit, run, repeat), and easy to read for collaboration. 
No. You do not know web2py
Well then, sorry. I didn't it read carefully enough apparently. I indeed don't know web2py, and thought I saw an issue (because I didn't realize that you were sanitizing your stuff in a different function). No need to be abrasive. 
I am sorry. Did not mean to be abrasive. I was in a hurry texting from phone, after a long day, I clicked submit before finishing writing the content. I should have explained that web2py validates the path_info by default and parses it into /app/controller/function/args(0)/args(1)/... In our case request.args(0) can only contain "a-zA-Z0-0\.\-_" chars. Anyway, there is something incorrect in my example code. I do not check if request.args(0) is None and I do not check if filename exists. While this is not a security issue, it may result in an unnecessary ticket. There are other things that can be done better. One important one is that the index() action really needs a @auth.requires_login() validator else everybody can run the script and this is a DoS vulnerability.
This is a pretty beginner-level introduction to setting up your Python env for Allen Downey's *Think Stats*. It's probably not helpful for experienced Python devs, but newcomers to the language might appreciate it if they're feeling antsy about the prescribed project structure. Feel free to offer criticism here or on the post.
Haha, you're not a python developer till you come across this issue.
The keyword arg reference issues is classic, and the callable as a default is really handy (though for DateTimeFields, you should really use `auto_now_add` even though it is annoying to override).
`auto_now_add` has long been deprecated in Django in favor of a callable default.
Ruby version. Not as beautiful, but not awful. tree = proc { Hash.new { |hash, key| hash[key] = tree.call } } Like so: [1] (pry) main: 0&gt; tree = proc { Hash.new { |hash, key| hash[key] = tree.call } } =&gt; #&lt;Proc:0x00000001a8ff38@(pry):1&gt; [2] (pry) main: 0&gt; t = tree.call =&gt; {} [3] (pry) main: 0&gt; t[:this][:is][:a][:test] =&gt; {} [4] (pry) main: 0&gt; t =&gt; {:this=&gt;{:is=&gt;{:a=&gt;{:test=&gt;{}}}}} 
i swear it was deprecated pre-1.0
You aren't crazy. I remember some fuss about auto_now_add not being the preferred way, too. I don't know if it ever got deprecated, but apparently, it's back in good graces these days. I'm glad, too. It's always been a useful option.
&gt; play nice with humans Stop that. Programmers are not super-humans or anything masturbatory like that. To go against MVC in Django you kind of have to know what MVC is all about in the first place and how Django works. It's quite subtle in it's beauty. Overall though, most frameworks off the same thing in different forms. Django just puts it across a couple more files. ^People ^who ^say ^micro-framework ^sound ^ridiculous. 
you know what I mean. They didn't want to have to remember a million command-line options (even after I went through the effort of making a super-nice help screen) you gotta realize, most scientific code is basically one-offs for a very particular purpose, coded by grad students rather than full-time developers. things like MVC never come into the picture, sadly.
I agree that by any standard bottle is the smallest but: they are all based on wsgi (including web2py) and work with all wsgi servers (web2py and bottle share code at this layer). Web2py ships with 3 apps including the web ide and docs. If you remove them and only look at py files, Web2py is smaller than Flask+sqlalchemy. 
Urls maps into apps and actions. An action is a function. A function can return a string, an iterator (for streaming), or a dict. In the latter case it looks for a template to render the dict, like django and flask do. The difference is that it looks for an extension in the path info and looks for an html template or a json template or rss template etc etc accordingly. If the requested template is not found it uses a generic one. Every object in web2py knows how to serialize itself in html/xml.
Might be possible with pygame
Not at all. :-)
But also look to [autopy](http://www.autopy.org/)
You could definitely use OpenCV, but it seems like overkill for this type of image recognition. Especially if you are guaranteed the flag will always be the same size and color shade. OpenCV is normally used for natural image processing. Is the environment that contains the flag relatively predictable? Are the flags arranged in the grid? Are there other objects, or just other flags? Using all of this information, you can pinpoint which pixels in the screenshot you should test that would give you positive matches for the French flag. Then again, learning OpenCV wouldn't hurt you in the long wrong ;) 
I prefer using SimpleCV
Thanks! I took the idea from a chinese program called Green Dam Youth Escort and i added the neural network. I tested it and works well with a big dataset. Im planning to add persistence to remember the training. http://en.wikipedia.org/wiki/Green_Dam_Youth_Escort#Functional_defects
This seems like a **terrible** idea, and I dont think it would work well in practice, but maybe you could do something like this: def restore_args(func): def inner(*args, **kwargs): defaults = copy.deepcopy(func.func_defaults) result = func(*args, **kwargs) func.func_defaults = defaults return result return inner @restore def example(items=[]): items.append("test") return items 
It definitely isn’t spamming. Thanks for sharing!
classic type-aware problem. I love Python and I've been using it a lot, but it seems like all the subtle bugs I'm seeing these days have to do with a valid expression that nonetheless is not what the programmer wanted, which could be easily resolved by saying "I'm expecting something of type x" (in this case, a function that returns a datetime, not a datetime)
http://sikuli.org/ is a Java+Jython project that already does all of this. It uses computer vision algorithms to detect buttons and manipulate the mouse.
from the PostgreSQL docs: "In general, a unique constraint is violated when there are two or more rows in the table where the values of all of the columns included in the constraint are equal. However, two null values are not considered equal in this comparison. That means even in the presence of a unique constraint it is possible to store duplicate rows that contain a null value in at least one of the constrained columns. This behavior conforms to the SQL standard, but we have heard that other SQL databases may not follow this rule. So be careful when developing applications that are intended to be portable." (http://www.postgresql.org/docs/8.2/static/ddl-constraints.html, section 5.3.3)
Have a look at http://sikuli.org It might be just the thing.
So you know exactly what image you're looking for? In that case a computer vision library may be overkill. Just scan through the picture in blocks equaling the size of your target image until you find one that "matches." For determining a match, just calculate the difference between the block and your target image and check if it is less than some tuneable sigma value. So if the application is 100x100 and the flag is 10x10, scan a 10x10 block across the image left to right, top to bottom, moving down 1 pixel per row. This is a pretty straightforward algorithm to write and may end being easier than learning how to use a CV library.
It sure is one of the things you probably won't notice when you are starting out with python. I had a pretty good laugh at this too when I found the issue (and looking at the bug's history)
did you try the enter key ?
Sql Server is one database that doesn't allow multiple NULL values within a unique constraint. 
Excuse me if I'm missing something... Why can't you just set unique to True in the Column() definition? (this is the first answer on SO) Why can't you add UniqueConstraint to the __table_args__? 
You should be aware that both Postgres and MySQL may have some issues with unique constraints on TEXT fields. https://code.djangoproject.com/ticket/14904 http://www.mydigitallife.info/mysql-error-1170-42000-blobtext-column-used-in-key-specification-without-a-key-length/ 
Here you are sir, "Programming Computer Vision with Python" http://programmingcomputervision.com/ Excellent, modern techniques.
This is a good and simple option. Since it has GUI automation in mind it has an easy interface and *some* tolerance to change to the target image.
I have made two mistakes on my part. The first is that currently in my app I have removed the unique constraint for the UPC for the time being because I was having an issue, for this example I rebuilt I forgot to put it back. The second thing I realize is that I haven't actually been putting Null when I want Null, it turns out to be an empty string. Anyway, as per what everyone is saying here and on Stackoverflow, it should actually just work with the unique constraint. I will test this and confirm later.
Sikuli is really a slick piece of software. We use it at work to automate qa testing.
You may want to look into [SimpleCV](http://www.simplecv.org/). If you post a question to our [help forum](http://help.simplecv.org/questions/) we can lend you a hand. 
This threw me off. I found a few threads mentioning this and I thought it might be an issue in other databases.
That's good to know. Luckily they won't be too large.
I wrote a [pure python ifconfig](https://groups.google.com/d/msg/comp.lang.python/Uq1CHtZOw_w/e8IgmWCg4hMJ) a while back. Python standard library exposes quite a bit of low-level stuff if you need it.
Keep them coming my friend.
It looks excellent though I wish the documentation was actual documentation and not a tutorial. It's a very important part of the usability of a library. Had to look into the source code to see what other render types were available: def render_to_file(self, filename): """Render the graph, and write it to filename""" _you don't say :P_ 
I run into this issue where I convert strings to unicode. unicode('None')==unicode(None)==u'None' All three of these don't equal the None literal. This results in me writing something like this: def safe_unicode(a): if a: return unicode(a) return None
Nobody who is starting any web dev ever needs a mongo and postgres. Not everyone is a freaking Google or something... I'd suggest you to stick with Webfaction.
I misunderstood this at first because you called it code completion. (That conjures up the thought of typing a few characters of a keyword or function name and hitting tab.) I think what you want is that it will type () everywhere you type (, with your cursor after the second character. I get how this would be useful if you never have parameters, never use non-blank strings, never have keys in your dictionaries, and never index anything, but I'm pretty sure you get the second of a pair of delimiters after the cursor instead of before because **generally you'd want to specify a value there**. I mean to say: what is the point of having to hit the left arrow key every time you pass an argument, initialize a sequence data type, or index something? Also, you asked for a shortcut to get to the end of the completion... *right arrow key*?
Care to elaborate? ELI5?
Hello, this is awesome. I did not really have time for this but I'll just wake up earlier I guess. I don't understand why I haven't heard about this before, it's an incredible initiative. Thank you very much.
for one thing, you can't compare naive datetimes with timezone-aware datetimes and Django now defaults to timezone-aware datetimes. Doesn't really matter how that is represented in the actual database, it matters on the Python side with comparisons, displaying, etc.
It was for this: &gt; You shouldn't have to dig for an hour to find an obscure options to get an editor to do what you want. When it's just you being a bit dense. I used it a *lot* and I don't remember any of the issues you pointed out.
I just entered university this year, and my Programming 101 class (loose translation) is going to use Python 3. I see that this course is going to use Python 2.7. I'm thinking of signing up for the online course, but I'm afraid that using different versions of Python is going to mix me up. Is it doable? Learn Python from scratch using different versions? Or are they similar enough? 
Here is a coupon code for 5 dollars off the book if anyone is interested: SEPBOOKS12
I don't think so. I think you still get to watch the videos even if you don't really participate. Some people will "dropout", like a regular class. I don't see how it could benefit them to punish you in some way if you don't complete assignments. You just don't get the symbolic certificate at the end would be my guess. Source : none.
Just a tip with regular expressions I use [txt2re](http://txt2re.com/) to help test my RE until I work it out.
I'm taking a python 3 course now. The book was written for 3. The professor specifically said version 2 won't work with the commands in 3, so you may get some confusion. I'm not sure. Source: 4 weeks programming experience so anyone in here should know more than me. 
It's not that bad to go back and forth, I use 3 at home, and 2.7 at work. Worst case scenario if something seems odd you can Google it, or run help() during an interactive session.
Show us some lines from the contacts file directly (redact the names and stuff, we just need to see the format).
on containers the pop* methods remove elements, his method was named popRandom... - i don't see how that can be missed
I have find the 'customers' app https://github.com/devsniper/customers very useful as an example app wile learning Pyramid. It's a good starting point to see what can be done. And for the most interesting project i vote for KARL project (and related stuff) http://karlproject.org/
Bottle is cool ! Also, Cornice on the top of Pyramid: http://cornice.readthedocs.org/
Same here. Thanks carioca3!
Thanks. You are right an option for css inlining would be great, but Cairosvg can in fact handle css stylesheet but you have to install: pip install CairoSVG tinycss cssselect as mentioned in pygal site. Btw your terminal seems fun, I will give a try at it one day.
Thank you for the site, it will surely help.
I don't know why the test is being formatted like this. The new lines are being stripped. 
I realize that the OP may not have expressed his satisfaction in the most diplomatic way, and I also realize that PyScripter is free and for the most part an *excellent* product, that its developer is well intentioned and extremely talented. I use PyScripter quite a lot. Having said that, I think that PyScripter might be improved by having an option that is easy to find (perhaps the default setting) that turns off the typing cleverness. The reason for this is that while PyScripter is awesome, it is not the only IDE that I use. For the most part, I type without looking at the keyboard, and when something unexpected shows up on the screen, it's inconvenient. It creates cognitive dissonance, which makes me feel uncomfortable. Something similar happened when OSX came first came out. After using a Mac for, oh, 15 years or so, the menus were all wrong. The windows and dialogs behaved oddly. Controls worked differently. It made me feel really unsettled. When you don't have any particular expectations for something, this doesn't happen. When you have expectations, and your brain's expectations don't match what reality delivers, this dissonance happens. It's what makes people seasick. (Until, of course, they learn to expect the right things, and then they don't get seasick.) This also causes simulator sickness and lots of other problems in user interface design. Bottom line, then, is that if software is expected to do one thing and does another, inexplicably, then it makes users uncomfortable. It sounds like this happened to the OP. I *know* it happened to me, and it almost made me stop using PyScripter despite its many fine points. So this might be an opportunity for the PyScripter to make a fine product even better. Maybe not, I'm not in charge. Like I said, I use PyScripter frequently, and if this behavior were improved, I'd like it even better. 
nah here's the first one, op: def factorial(n): ascii = [105, 32, 99, 104, 101, 97, 116, 101, 100] if n == 1: return ascii[-2] - ascii[-1] else: return n * factorial(n - ascii[4] + ascii[-1]) 
I don't think you're right here - your code needs to iterate over every element of the set, rather than just an O(1) access. As others have pointed out, the reason you're getting similar times is that you're also including *populating* the set, though only for the randomset version. Take that outside the loop, and I get: average randomSet time: 1.57144663948e-05 average get_one_random time: 0.0291795937723 so randomSet is nearly 2000 times faster (and will be even moreso for larger sets), though at the memory cost of having to keep the extra list around.
The lines are separated by one \n. I didn't know about the two trailing spaces at the end of a sentence to do a line break, you learn something new everyday.
its classwork but my partner and i are ahead by 4 assignments and we are now stuck and the teacher is helping other people to catch up
Yo dawg.... ah fuck it.
I'm new to python myself, but it appears that you are asking it to print a tuple with the values "2000 - 100 + 50 =" and 2000 - 100 + 50 resolving to 1950 rather than print(2000 - 100 + 50). What happens when you remove the comma? 
If I remove the comma, an error pops up.
It looks like you're using Python 3's print syntax, in which you call it like a function: print("Hello World") when you should be using Python 2 syntax where it's more like a keyword: print "Hello World" 
&gt; pip install CairoSVG tinycss cssselect Ahh, okay, my bad! That does work. One of those cases where the "install whatever causes an import error" fails me :( &gt; Btw your terminal seems fun, I will give a try at it one day. Sure, give me feedback if you do :) I was actually planning on working on it again soon-ish and integrate real time plotting, though I was going to cook my own JavaScript SVG plotting library on the terminal end, so that it can be used easily from all programming languages. 
numpy has fft functions, by doing some clever preprocessing you can use these to narrow an exact pixel wise comparison - it works really well :)
It wasn't a stated requirement until this last post, and he certainly wouldn't have been the first person to write code he doesn't strictly need.
1. /r/learnpython 1. You are using a tutorial for 3.x, in 2.x. `print` works differently.
yes
So then what do you think the base case is in this situation? 
Don't have a lot of money but added $1/week, currently at $92.00.
This is great but does it really have to be tied to GitHub or Twitter? How about a goddamn email :)
The point is, you can send a Gittip to anyone's twitter or github account, even if they are not signed up to gittip. Github and twitter names are public, email is not always. It's one of the core features of gittip.
Does anyone know how much time per week will be spent on lectures?
I'm not sure the public vs private is the problem: it's authentication. Twitter &amp; Github have APIs, you can "sign in" with them. Some email addresses (@gmail.com, @yahoo.com, etc.) could be guaranteed to be tied to an OpenID or other API, but you probably couldn't support all email addressees, and it would be a clunky piece of code with lots of branches. A token based authentication system could work, but probably isn't secure enough for financial transactions.
This is what in some corners are called "taxes". Yes, taxes are great when they're used for great things.
What corners are those?
I like the idea. My point is that this works fine as long as there are lots of contibutors relative to the number of receivers, which happens in the beginning. A few early adopters may be able to live from this maybe even longterm but to make it a steady and sufficient source of income that people in general can rely on needs a much more solid foundation. That's where the "tax" thing comes in. The amount of money needed for this to work outside small dedicated groups with an occasional reach to a greater audience is big enough that there needs to be some form of guaranteed benefit, a lock in that you can't just voluntarily leave whenever you see fit. I also believe that the many initiatives popping up now point in that direction. I wouldn't be too surprised by seeing efforts to make larger binding systems that may make into law internationally. Some form of governmental gurarantee, protection and coercion.
Unfortunately (or maybe fortunately) the name "yo" was not available at pypi. But you still can do the following: import dawg as yo words = yo.DAWG()
I can send money via PayPal to anyone with an email address.
&gt;When it's just you being a bit dense. I used it a lot and I don't remember any of the issues you pointed out. I had the same problem he did. I loved almost everything about pyscripter, and even loved the code completion, but the fact that it will add the extra " or ) which can sometimes be overwritten by typing the character again, and sometimes can't be overwritten and just adds an extra character, is annoying as hell. I have experimented with many of the options, but I couldn't find it either. It doesn't help that PyScripter has different menus for Options, IDE Options, Editor Options, Tools, and Configure Tools. Throw in a few more menus for every one of the previous things with the word 'shortcuts' behind it, and there are lots of menus to look through.
&gt;Taxes generally bear the implication of being mandatory to great lengths. Though they may superficially appear so I disagree that they are: Who decides taxes? Politicians, who elect them? We do. Now this is simplistic, of course. The crux is that we *consistenly* choose politicians who promise to keep taxes above certain minimums. How is that? The consequences of too low taxes are simply not very desirable and we know it. Countries that don't have a functioning tax system are patently unpleasent places that we usually refer to as "failed states". So we will choose a candidate who promises to spend taxes on making society bearable to live in. And this is very much voluntarily, even though I may not support money spent on schools because I don't need schools anymore or bridges in the West because i don't live there. Still the overall benefit vastly overshadows the downsides for the 99% of us and we know it.
&gt; Free software production specifically is not a thing that needs special treatment from the society: in fact, it is best served by removing special treatment such as copyright and patents. Let's talk about special treatment after the roadblocks are clear. How is copyright a "roadblock"? I don't think many people who license their code under various versions of GPL would be very happy if you forced them to put their code into public domain. Btw, RMS did say that it would be nice if Free software were tax-funded.
Indeed. As much as I like what Gittip is doing, the future cannot be many fragmented services that technically try to do the same thing for different communities. At least not as long as I have to register with all of them, transfer funding to each, etc. I have a flattr account and use it heavily, but I'm unlikely to sign up for a myriad of other random services that try to the same thing. So if you want my support, use flattr. Or services that do a conceptually different thing (and thus have more justification for their existence), like Kickstarter.
Free software, even by RMS's definition, includes all public domain software. Copyright does enable RMS's favorite style of licensing, copyleft, but it also enables the entirety of proprietary licensing. Lack of copyright would make all published software ever free software. As such, there is no way for the software to be non-free beyond consensual secrecy -- think server-based software. Indeed, services remain as a way to provide exclusive, difficult-to-copy software products by innovative companies. I personally believe the implications of all software ever being free reign to use, research, reuse and rearrange by anyone for any purpose whatsoever are much greater than whatever an opt-in copyleft license has to offer. I humbly suggest to play that thought experiment: what kind of amalgate computers could we have tomorrow without legal limits to consider?
Why is this posted in /r/python?
If someone starts accepting donations, I know PayPal will set the account under review and not allow the person to accept money. BTDT.
The hive-mind giveth.
&gt; Lack of copyright would make all published software ever free software. Free as in beer, not free as in speech, and even then not necessarily. There's a reason why GPL allows selling Free™ software for money, but specifically demands that the source code ("the preferred form of the work for making modifications to it") is distributed along. Abolishing this requirement would make it impossible for almost everyone to enjoy any of the Four Freedoms™ (except for the little part of the zeroeth one, about using the stuff for free), and extremely hard even for the minority who enjoys digging through heaps of assembly. If not practically impossible, too: it is a fallacy to assume that in a world without copyright proprietary software developers would continue the same lax practices regarding binary code obfuscation, the existence of Skype for example is quite worrisome in respect to the width of the gap between what is technically possible and what is _currently_ usually economically justified. There's also a reason why GPLv3 includes the anti-tivoization clause, by the way. &gt; I humbly suggest to play that thought experiment: what kind of amalgate computers could we have tomorrow without legal limits to consider? Well, this experiment doesn't need to be purely thought-based: in regard to computer games copyright protection is de facto non-existent (because they are not used by businesses where it can be enforced). In that case the answer ended up being: consoles, MMOs and "online-only single player" games. Somehow that doesn't instil me with much optimism regarding the big picture.
Very cool that you're doing this, I imagine to learn Git/Python a bit better? The folks over in /r/learnpython would eat this up!
I'm not sure what other services offer this (I'm sure some do), but I setup a bank account specifically for pythonpackages.com, so it was "easy" to give gittip my bank account info and start receiving tips.
I had figured on emails having a password on Gittip. Like, regular ol' registration and sign-in. https://github.com/whit537/www.gittip.com/issues/89
I believe obfuscated software anyone can deobfuscate and redistribute is a much better situation than unobfuscated software only someone can redistribute. It's the workshop compared to the museum. Reverse engineering is not hard. Even if it was incredibly hard, it only needs to be done once. Someone else can then lift the glorified assembly code into something more accessible. The deobfuscated code can be redistributed, should it be legal to redistribute the deobfuscated code. Today is it not. Today you have to create original software through clean room reverse engineering -- a very difficult, imperfect and time consuming method. Compare to what scene groups do to disable copy protection for software releases: a single clever guy can defuse the Matryoshka style protections entire teams of high-paying developers come up with -- often before street date, sometimes entire months later. Distributing this code is illegal. Proprietary hardware like TiVo, consoles and iPhones are one way to cope with malleable software, but should compatible-but-unlocked clone hardware be legal it'll work only for so long. Today it is not. Service based software -- MMOs and online-only singleplayer games included -- are a fair compromise to keep part of the complete software secret. Should it be legal to reverse engineer and reimplement the server component or hack the client software into functioning standalone, there'll be a decent replacement given some time. Today is it not. The legalization and endorsement of popular reverse engineering and sharing is an incredibly powerful force. Not everything can be laid out in nice readable code, but *anything* can.
Damn it makes me happy to read this. :-) Here's my take on Flattr: http://news.ycombinator.com/item?id=4239247 The difference to me is crystallized in that Gittip is funded on Gittip. I actually hung out a lot with Flattr's biz dev Evan Schoepke at XOXO last weekend. Philosophically, Flattr and Gittip are quite aligned (which is to say, we had a great time together :-) ). Flattr and The Pirate Bay share a co-founder, and Evan's wording was that Flattr is trying to "end the war" between content producers and consumers. In my view they didn't go far enough in escaping the old system, however. They've got a traditional business model and salaries to pay and they've got a bit of VC funding which means their hands are kind of tied. That said, the moment we're in is a time for experimentation and trying lots of different models. Kickstarter is obviously killing it, Flattr has some traction, and there's plenty of other contributors to this new economy, however it shakes out. With Gittip I'm trying to offer something I haven't quite seen elsewhere yet.
i was just glancing through. could you not have a keyword argument for binary search that defaults to len(seq) so you don't need to take the length of it each iteration? you can just subtract off the number of elements that you are jumping past each time, no? maybe it won't make a difference in the end..
Good in the usual sense of approximating a random (but deterministic) function. Python's built-in hash() function, produces hash(x)==x for integers, for example. That's very non-random. When combined with the hash collision resolution algorithm of puthon's built-in dict type, it produces very good performance for typical use cases (better than random, actually). But it's not a good general-purpose hash function. 
We can be in favor of some taxes but not all taxes. Taxes are a very indirect flow of money, voluntary memberships and donations are direct and more involved. I believe people should be encouraged to care about their actions, and being involved is just about the greatest encouragement.
Yeah, as a reference for learning it's great that they're in native python. As a resource for daily use in production, you'd want them to be as ridiculously fast as possible.
Indeed. To receive money on Gittip you need a Gittip account.
&gt; Reverse engineering is not hard. As I said, it's a fallacy to imagine that the world without copyright would be the same as the world with copyright, only without copyright. Reverse-engineering unobfuscated binary code is hard. Reverse-engineering obfuscated binary code is exponentially harder (and I'm using "exponentially" in a CS sense here). We don't have a lot of devs intentionally spending enough effort on developing and using obfuscators, it's not worth it because _copyright exists_. Your perception of hardness is skewed by the fact that almost nobody does try to make reverse-engineering hard. Imagine a world where copyright doesn't exist, where there's widely available software providing Skype-grade obfuscation, and developers have an incentive to buy and use it. Suddenly you no longer have the Scene as it is now, because they no longer can find a single crucial conditional jump and replace it with a bunch of nops, and release the crack on the day of release. Look, Skype remains uncracked for almost ten years now, despite _enormous_ incentives both for white- and black-hat hackers. The Russian translation/dictionary software Lingvo used to have (when I used it), like, a four years lag between the release and the moment when you no longer have to fear another time-bomb causing the cracked version to self-destruct every two weeks, without any obfuscation. My point here is that there are some disturbing examples which show that there __is__ a huge gap between how hard it is possible to make reverse-engineering, given enough incentive, and how hard reverse-engineering is now, thanks to copyright laws largely removing that incentive. So it's a grave mistake to assume that the current state of things will not change to something much, much worse were the copyright abolished, leaving us with a graveyard of software that just doesn't work any more since the devs went out of business, instead of a museum that gradually turns into a workshop as enthusiasts overcome the natural unwieldiness of compiled code. &gt; Today you have to create original software through clean room reverse engineering -- a very difficult, imperfect and time consuming method. Or, you know, you can create original open-source software that does the same thing better. &gt; Proprietary hardware like TiVo, consoles and iPhones are one way to cope with malleable software, but should compatible-but-unlocked clone hardware be legal it'll work only for so long. Today it is not. I'm pretty sure that it is, APIs can't be patented and are not subject to copyright. The obstacle might be related patents, but those are entirely different from copyright, which is what we are discussing. &gt; Should it be legal to reverse engineer and reimplement the server component ... it would still remain impossible. Consider the recent Star Wars "MMO", which is mostly online-only single-player, as far as I can tell. The only thing you can do regarding the client is to reuse the textures and the rest of the art, the meat of the game would have to be clean-room reimplemented regardless. Also, my another point re: all this is that not only devs are incentivised to use active anti-hacking measures, but that they are also disincentivized from developing certain kinds of software where the measures can't be effectively deployed. Entire game genres are withering because they can't be easily converted to online-only. When was the last time you've seen a web-app that you'd like to have as a standalone executable, today or yesterday? Well, you're not going to have that, because it would be pirated then, so better deal with the lag and the "always online" requirement, and with the fact that when the devs go down, your app is gone, gone for real.
I've got 2 models for statistical models now, both for working out variance, one for a list of data and one for a probability distribution function (I'm just gonna start work on one for grouped data), I'm just unsure how to change them into modules, but if I can get some help changing them into modules I'm more than happy for you to use these 3 scripts how ever you want.
http://www.reddit.com/r/Python/comments/10aueg/i_am_creating_a_module_of_useful_algorithms_in/c6bx11b
I just sent a pull request (my first!). All I did was fix up formatting for PEP 8 compliance. 
relevant http://blog.peterdecroos.com/blog/2012/09/10/sorting-algorithms-in-python/
&gt; My point is that this works fine as long as there are lots of contibutors relative to the number of receivers, which happens in the beginning. Gittip's founding idea seems to be providing a means for creators of open source software (and others who benefit the community disproportionately) to be funded voluntarily by the community at large. The idea that everyone should quit their job and develop F/OSS full time is rather silly, and not something I've heard anyone suggest but you.
It depends on how you define violence. Lets say you have some sort of community, du you institute a upvote/downvote system i order to control this community? Are downvotes violence?
Typo in documentation on [this page](http://pygal.org/basic_customizations/): &gt; By *instanciating* it should be: &gt; By instantiating it Similarly for the other occurrences of that word.
https://gist.github.com/2012250 - one-line tree :)
http://pastebin.com/HNb7hnzF made a few edits I would say this is the final version of my variance module
Please look at the dates of the blog posts you read. Ruby was a hot thing 10 years ago. 
[This](http://algoritmia.codeplex.com/SourceControl/changeset/view/585096ae4c78) library is much more complete, tests and benchmarks included. It's used to teach data structures and algorithms in my university. With the MIT license you should have problems forking it and building on top of it. The algorithms are located in src/algoritmia/problems. 
Ok, I see the benefits of Gittip now (though flattr also allows recurring donations of fixed amounts - monthly, not weekly, though). F/OSS is fragmented, but it's a bit different: say, if there are 100 Linux distros, you only need to use one and don't need to care about the others. But if there are 100 micropayment/donation services, you have to register with all the ones that are used by people you want to support. And deal with the subject of money (this is the biggest turnoff for me) on each of them. So it's not a 1:1 comparison.
I was referring more to Rails than Ruby itself.
P.S: don't use these in production 
well, thanks for the help and response to my question. if you are representative of the python community at all then i think i'll stick with ruby.
I don't understand, what are you aiming for? A reference? How is it better than wikipedia (which easily beats your bubble sort implementation btw)? Utilities? Such libraries already exist, and it doesn't seem like speed and memory are a major concern to you. Why then?
not sure how relevant that is, but I've put together a (speedwise) [comparison](http://therealplayer1.com/non-tron/sorting/) of quick, bubble, heap and mergesort some time ago
Is this at a stage that is benchmark-able? I'd like to see the PyPy comparison.
i would like to see that too but it is still in development. Anyway i liked the way they're planing on doing things, can't wait to see the prototype
Nice idea. Terrible name.
I'm pretty skeptical of their claims, but I'll definitely check out anything they release. My only real complaint is that they're using C-style type annotations when they could have use [PEP 3107](http://www.python.org/dev/peps/pep-3107/)'s function argument annotations and maintained compatibility with Python3.
Perhaps you should crosspost this to /r/golang
If they can get significant speedups, I think this is a cool idea. The syntax looks very unintrusive.
A hard sell compared to Cython: http://www.mypy-lang.org/faq.html The fact that they consider Python2 deprecated doesn't help either but let's look at the bright side: a new implementation to play with :-)
Actually just finished the app using web.py to get it done quickly, as have to show it off tomorrow afternoon. bare-bones, but does the job. Still, I do plan on extending it, so will likely be using django and refactoring it extensively per the suggested MVC structure. 
Good luck with your presentation. 
 &gt;Go isn’t just stuck with verbose and repetitive error handling. It also makes it easy and tempting to ignore errors. In the following program we would trigger the doomsday device even if we failed protecting the presidential staff. func main() { http.Get("http://www.nuke.gov/seal_presidential_bunker") http.Get("http://www.nuke.gov/trigger_doomsday_device") } This is actually a really good illustration of why exceptions are important. I had never truly understood why until I read this post.
Serious question: If the creators of Go were here in this thread now, how do you think they would respond to your comment?
Very interesting. But, I disagree with the decision to makes classes static by default. It breaks the idea of full compatibility that was demonstrated so far, and also making a static/dynamic hybrid class is very easy: Everything in __init__ is static, and every other member is dynamic. p.s. - could be nice to make overloaded function degradable. i.e. if I define func(int) and func(any), it would use the first for ints and the second for the rest.
I don't think the importance of exceptions lies in enabling bad coding practices.
How do you mean?
Dare you to crosspost this to /r/golang.
For the opposing view, see the author of ZeroMQ on why exceptions are bad: http://www.250bpm.com/blog:4
I don't know why people claim Go doesn't have exceptions. Go has the exact same exceptions model as Java once you strip away what it looks like on the surface. Java has two kinds of exceptions, checked and unchecked. If something is checked you have to either declare it yourself or deal with it somehow (possibly by just silencing it). If it's unchecked it can happen anywhere and you have to decide where in the call stack to try to deal with it. Go has two kinds of exceptions, error return values and panics. If something is a returned error, you either have to return the error yourself or deal with it somehow (possibly by just silencing it). If it's a panic it can happen anywhere you have to decide where in the call stack to `defer` a `recover()`. One issue that the author points out is that it can be too easy to ignore an error value. In Python, you have to explicitly add an `except: pass`, so it's obvious that you're doing something unadvisedly. Go lets you write `fmt.Println(...)` by itself instead of forcing you to do `err = fmt.Println(...)`. Because of this, the wrongness of what you're doing isn't as obvious as it could be. That's a fair critique, but hardly damning. Python has no static typing. That lets you get into all sorts of trouble, buts most of the time, it's OK and the programmer works around the potential pitfalls. It's all a matter of tradeoffs. I think that the Go developers did a really great job of designing a language that balances explicitness with ease of use. The ability to ignore an error value doesn't change my opinion. 
| You could equally argue that it's a good illustration of why ignoring return values is a bad idea. In a language that relies on return codes for errors The lazy way to ignore exceptions, esp in Java are everything throws Exception in the declaration or it's wrapped in a large try/catch.
&gt; Consider the following very plausible scenario: a routine that previously could not fail now needs to open a file - and thus can fail to open that file. That strikes me as a pretty big change. You're going to have to deal with the failure to open that file somewhere. Having exceptions gives you two options: you can deal with it right away or you can put the error handling closer to the top level of the program. Having error return values also gives you two choices: you can deal with it right away or you can make it clear through the addition of a return value that you're passing the responsibility for the error to someone else. Yes, it's a little bit wordy to make that change everywhere, but you just made a big change to your API. How can you make a big change and not expect a big rewrite? Of course Go also has yet another option: `panic`. If you want to act like you're using Python, there's nothing stopping you from just panicking when the file doesn't open. It's only a matter of convention that prevents this usage.
Can you be more clear on whether you think error codes are superior to exceptions? You seem to prefer error codes but say both have strengths.
But how is the situation you describe better with error codes? Let's go through your list. | * people down stream from you must handle that error Still true, but now if you want to pass the exception down to someone else who is in a better position to handle it, it is a lot less convenient. | * the new error now needs to be handled Still true, but instead of having an uncaught exception propagating until it is eventually caught by someone who might know how to handle it we have an error code that the caller does not understand how to deal with since it was programmed before the code was added. | * your documentation may balloon as a result Still true, as presumably new error codes are documented as well. | * more unit tests for handling a new type of error via the form of an exception Still true. So all of the problems that you described are not at all unique to exceptions, but are at least as bad if not worse with error codes.
I can't. It's like arguing that chocolate is better than hamburgers or pancakes. It's a hard choice and needs diligence all the way down.
&gt; You could equally argue that it's a good illustration of why ignoring return values is a bad idea. In a language that relies on return codes for errors, I'm surprised Go allows it (for error return types at least). If it didn't allow it, you'd get a compiler error here, which is arguably better than an exception, which might only occur at runtime. Functions like `fmt.Printf` have a return type of error to indicate errors in formatting. They are safe to ignore in most cases because the functions also encode the error in to the formatted string so it's obvious that it occurred. It would be maddening if you had to deal with the error return every time. Go's design is principled, but also pragmatic.
Ok good, then I suppose I was reading what you said properly. I also use Go and Python for different things. I can't really call out why, as it tends to be more due to library availability, collaborator knowledge, and such other things.
I humbly disagree and acknowledge at the same time. Error handling always sucks. The amount of errors of dividing by the square root of a number can yield two, and that's a tiny little equation. You're right, someone else can better handle it, but depending on the language, you have no notification that something has changed. E.g. in python/ruby/perl, there's nothign stopping anyone from throwing an exception much less knowing which to catch. In more compiled languages, you have capabilities to bake it in - java, scala, c# and such. | Still true, but instead of having an uncaught exception propagating until it is eventually caught by someone who might know how to handle it we have an error code that the caller does not understand how to deal with since it was programmed before the code was added. I'm not convinced, but then again, there's no mathematical proof for any of the claims we're making here :). The context is lost. If an unexpected exception happens, and no one is checking their params, handling a file not found like exception from 10 levels up the stack isn't as easy to deal w/. Whose file is not found? The one I passed or one internally used? It's a very big jump in logic - a super break short of a goto. 
But this same argument can be applied to so many areas in Python... you can change parameters or return values of a function, and calling code will still blindly call the function and (maybe) fall over, or maybe silently store bad data somewhere, only to crop up later. The only fix is to find all callers and fix them. Inheritance allows you to break whole hierarchies of objects when you change a base class, and Python won't tell you about it... the only fix is to find all subclasses and fix them... I could go on. At least in Go, you could just change the function name, and the compiler would find all of them for you. It seems like a relatively small point over which to discount an entire language. Python has far more glaring warts, but they don't stop me from using it as my primary development language. Especially given the Go authors' deliberate stance on the matter, I strongly suspect this isn't such a serious problem as you think it is in practice, just as Python's lack of static typing isn't such a problem in practice as some people expect.
&gt; If something is checked you have to either declare it yourself or deal with it somehow (possibly by just silencing it). Except that Java gives you a third option which is to let you add the exception's type to your signature so you can let it propagate *automatically* to the caller, which is the kind of thing that you *can't* do with error codes.
How? Just saying 'remove the GIL' is not helpful. You can remove the GIL and then drown everyone in endless insane race conditions. What is the precise problem you are trying to solve? How are you going to actually solve the problem? 'Remove the GIL' is not a solution.
static typing is effectively a way of putting asserts about the types of variables everywhere. Is it the gospel that this is always better? Polymorphism is a way of writing code which isn't fixed in which type it operates on, is that necessarily an evil thing? Most of the programming mistakes I make are not 'wrong type' but 'wrong value'. A square root function that squares the input passes the normal kind of 'static' type checking. Is the square of the input a different type from the sqrt of the input? Only if the type is defined as 'correct value for sqrt function,' which is going to take at least as much code to define as the actual code you are writing.
The line http.Get("http://site") can imply one of two things: * Either the Get() method has an impossibly absurd contract: it does not return anything (content, HTTP status, success/failure indication), it manipulates global state, it does not offer a meaningful interface (no method selection, no header manipulation, etc), or.. * the interface of the Get() method is somewhat sane (it performs a GET request that has been somehow setup previously and it returns *something* which contains a status/error code, and so forth) and the programmer is deliberately ignoring it. Exceptions do not exist to help in either situation. If the article wanted to point out deficiencies of an exception-free language in a realistic setting, it hasn't convinced me yet.
| Yes, but if a new error code was added that your code was not designed to expect then you would be in the exact same position as the one you described, so at that point one of three things will happen. First, your program will enter undefined behavior because it was not designed to handle unexpected return codes at all. I agree. Depending on how criticial an error is to your next function is fairly clearly scoped. | Second, your program will have a system in place for propagating the existence of unexpected error codes up to the top level. Sometimes, not always. A good function always validates. If you're using input from a function before, regardless of its error state, you should be checking your inputs instead of counting on someone else handling an exception you or something else threw. E.g. divide by 0. | Third, your program will panic. Agreed. Just like an uncaught exception. Catastrophe is catastrophe. | So in short, the problem you described exists with error codes as well and at the least they handle it no better than exceptions do, and to the extent they function in the same way (as you can always manually propagate errors upward) they require a lot more work to do so. I'd say it's no worse. We agree it sucks having to do error checking at all, but we have to for the sake of quality. In one system you have to manually propagate and in one you have to manually ignore and create catch-alls. A no win situation for anyone. My only example of exceptions gone wrong is java's implementation of jdbc. If you close something that's not open, exception gets thrown. It'd be nicer if it validated its input and just let it go. Why is closing a close thing exceptional? Ugh.
What bit you? You bit yourself. This isn't a problem with Python's syntax. Python cannot magically infer that you 'obviously meant' for the given function to be called later. You have to specify that. you TOLD it to call it at import time. This is like every programming language ever made in the history of computing. If there is a usability problem here, it is that Django requires people without much experience to write class definitions just to make a database table. You have to understand that code in a class definition is run at import time or you cannot write classes effectively. It's an elementary mistake and not a valid criticism of Python as a whole
Or you could just understand that 'now()' calls a function while 'now' is a function, while you are writing class declarations which you know will run at import time, rather than magically running somehow every time an object is instantiated. If you wanted something to happen every time an object is instantiated, you should put it in __init__ ... this is very basic Python. Python has its warts, don't half ass it and then blame your tools 
The issue where you think that calling a function at import time should somehow magically result in the inference that you want it called every time an object is instantiated? If you believe that, then when do you think that the code in a class definition is run? Before import?
There is no need to leave Python for Go -- they are both excellent languages. Error handling is an issue that has been considered carefully by the language designers on both sides. Python's interpreted, class based, get things done style is a great match for exceptions. Go's statically compiled, interface driven, highly concurrent style is a great match for error codes. I wouldn't dismiss a language entirely because I don't like one of its features. Languages show their strengths and weaknesses in different places on different projects.
Well said. Personally, I'm *keeping* Python and *gaining* Go. ;)
&gt; manually ignore and create catch-alls It is not clear to me why you are listing these as downsides to exceptions (at last, relative to error codes). In general you *want* to have to manually ignore errors rather than having them be silently ignored, and with error codes you *still* need some sort of catch-all unless you can guarantee both that you can handle all foreseeable errors and that the set of foreseeable errors will not change without you finding out in time to update your code before it breaks. So as far as I can see, you can do everything with exceptions that you can with error codes, but much more conveniently; ergo designing a language without exceptions feels like a regression.
The example is to show that without having an error raised when the first request is called, the second request will call anyways, and putting the President at risk. Had the first request raise an exception, instead of silently failing, the Prez might not have been horribly murdered. It seems like you might be thinking too literally 
I agree with most of your post, but... &gt; Error handling is an issue that has been considered carefully by the language designers on both sides. If you believe TomSwirly above, the Go designers made it clear from the beginning that they were not even considering exceptions, and with such a bias it is not clear to me that you can say that they really considered error handling "carefully", which I think is partly why the absence of exceptions often receives criticism.
A few anti patterns and seem to arise: Everything throws an exception - http://c2.com/cgi/wiki?ThrowsExceptionByDefault Or because of the unexpected jump in logic, a crucial next line may never run, such as resource deallocation. foo throws, E1, E2, E3 ... en for a large n. In some languages you don't get a convenient, "catch A, B" etc etc.. In some you get a prepopulated stack trace and if you use an exception as flow control, performance can tank for some value of tanking. Are leaving out exceptions a regression, certainly. The Either pattern used frequently in functional languages feel great. For comprehensions in Scala seem really nice. We need to find that next step. This isn't a this OR that. We have a this AND that and we need another that to make validation of data flow a lot nicer vs critical errors.
You sound like you're trying to argue over something unrelated to the main point, and I'm not whatsoever. 
&gt; Are leaving out exceptions a regression, certainly. The Either pattern used frequently in functional languages feel great. For comprehensions in Scala seem really nice. We need to find that next step. &gt; &gt; This isn't a this OR that. We have a this AND that and we need another that to make validation of data flow a lot nicer vs critical errors. We are in agreement. :-)
I have many problems with the arguments put forth in this article. First, the author mentions only C++ and Java as examples of languages that have exceptions, and yes, their handling of exceptions could be better. But what about languages such as Python or ML which have a garbage collector, so they side-step the problems of C++ and their exceptions aren't checked like in Java, so you don't need to wrap everything in try/catch blocks. After he's done with C++ and Java, he says that Go arrives on the scene and fixes the problem of signalling errors with multiple return values. As it's been said many times before, a product type is not how you want to do error handling. When there's no error, you return the actual value and an error code that means no error (presumably, the null pointer). But when there is an error, what value does the result have? It could be pretty much anything, so you must not use it if the error code isn't nil. But there is no mechanism in Go that prevents you from using that value even if there's an error. `val, err := foo(x); if err != nil { g(val) /* try and stop me! */ }`. As it's been said by many commentators in past Go thread (especially kamatsu), a better way would be to have sum types; the return value of a function is no longer the result AND the error code, it's the value OR the error code. In a language like Haskell, this is usually done by returning a value of type `Maybe a` or `Either a b`. And since you need to unwrap the value, usually with pattern matching, the compiler will yell at you if you try to use a `Maybe Int` where an `Int` is expected. Sum types would've been the right solution to the problem if you didn't want to use exceptions, but it seems the Go designers prefer to use the incorrect tool and trust that programmers are going to follow proper code conventions.
TomSwirly's comment doesn't give me enough context to know whether it was an issue that they weren't willing to compromise on or if they were actually negligent about considering alternatives. Based on the accomplishments of the Go designers, I lean toward saying that they made deliberate choices about error handling that they just didn't want to negotiate on in a mailing list.
Really? In what kind of scenario would that even be comparable? If you tested your code even once by looking at it the mistake would be obvious. As far as rendering data for a web server or the like there are more sophisticated tools available like the html/template package.
I was more talking about the issue of instantiating a keyword argument with a mutable object.
It's a learning tool. It's good for beginners to see code rather than pseudocode on wikipedia. It's less intimidating when you have code that works than going ahead and implementing it yourself to see how it works (assuming it works).
I think a larger reason is simply because google is behind it. Now, I like google. I might even be accused of loving google. But they're shit about anything which is going to require a long amount of time before serious adoption occurs. They abandon potentially awesome projects pretty quickly on a recurring basis. And any programming language is going to take a long ass time to really catch on. And that's even if google was backing it fully. You still can't just make something in go and have it run natively in android, their own biggest leap into the operating system world. 
well, Common Lisp solves this nicely with it's condition system where a context explicitely is not lost but kept and forwarded, which allows you to recover from errors and continue your way in your program, even if the condition was raised in a library. So it is not as if there aren't any examples out there in other languages that would show how to properly solve the problem. I guess the main fact with go is that the inventors of C thougth about how they would do something like C today and did just that. And exceptions just wheren't on their list for that job. Their philosophy is just plain different from other languages that do have exception handling and well, that's it.
Why should people leave from one language to another? Just use the one fits your problem and data model at hand already.
We don't mutate things often in the real world?
You seem to be suggesting that subroutines have 'impossibly absurd contracts' by definition. Ignore the `func main()` part and the fact that it's an HTTP GET request and assume this is part of some other package of code, calling 2 subroutines in turn, operating on some small set of shared data, and this becomes a fairly common situation. It's not that the programmer is 'deliberately ignoring' an error code, because we know from experience with C and C++ that if you're not forced to handle an error code, people forget. Go as a language does nothing to to stop you executing the second subroutine if the first failed. Other languages raise exceptions so you find the problem at run time. Yet others won't compile at all without the relevant error checking in place. That's the difference.
Practically it's very difficult. Python lets me declare a variable and then assign "abc", 1, and True to it one after the other, which means the representation of that variable usually involves some sort of indirection to wherever the actual data is stored, a type value to decide what kind of data is stored there, etc. In C, your variable will have one and precisely only one type, and the compiler will allocate a fixed region of memory for that type, and will predetermine all the operations you need to perform on it. It will never need to check what type it is during execution, or look elsewhere in memory for the content.
I may as well be biased from my previous line of work (carrier-grade systems). You're right, people make mistakes, and I'm not arguing the opposite. I think that when people make mistakes like above, they can be fixed before resorting to runtime exceptions and that's not why exceptions are useful in the first place. At any rate, if anybody wants to argue this further, may I direct you to [this kind sir](http://www.yosefk.com/blog/error-codes-vs-exceptions-critical-code-vs-typical-code.html), who has taken the time to debate both sides.
Hmmm, I thought it was going to be an article about the schism being rent in the python community between the 2.x branch and the 3.x branch, but instead we got an article saying all languages but javascript are obsolete. I'm not very worried about python in particular because of that...
Don't catch TypeErrors. A type error is a bug. Use the TypeError exception to debug your program. I really like your suggestion about exception expressions, though.
I still consider myself somewhat of a novice in the Python scene, but these two seem incredibly useful (at least to me...) &gt; Also, it is now easier to catch a specific error condition. Instead of inspecting the errno attribute (or args[0]) for a particular constant from the errno module, you can catch the adequate OSError subclass. also... &gt; open() gets a new opener parameter: the underlying file descriptor for the file object is then obtained by calling opener with (file, flags). It can be used to use custom flags like os.O_CLOEXEC for example. The 'x' mode was added: open for exclusive creation, failing if the file already exists. I'm still having trouble finding a use for the new *yield from* expression, though. I understand what it does, but I can't seem to come up with a reasonable use for it. The way they describe it using a simple iterator seems counterintuitive to what I was taught as "Pythonic" coding. It is nowhere near as readable as the following implementation, and only saves a couple characters worth of typing... If anyone could shed some light on it, I would be grateful. ...Not that I'm going to touch it until it's backported to 2.7 (and/or the Django stable release supports 3.x) :P
Maybe if Python could decide what it wanted to be it would stop degenerating. Specialisation is not just for insects - trying to be the best tool for every job is what drags most software towards its final whimper.
I am also attempting to make a repo full of algorithms/datastructures using idiomatic and interesting uses of varying target languages. I was intending to add some Python ones eventually but feel free to fork and add your own: [The algostructures repository is here](https://github.com/AeroNotix/algostructure)
A keyword argument with a callable will be defined at definition time and not at runtime. This is a well-known 'gotcha' of Python. Be wary of that.
Communities aren't good at specializing.
Basically what you do is make sure you have the latest virtualenv with distribute &gt;= 0.6.28, then pip install git+https://github.com/dholth/pip#egg=pip pip install markerlib wheel pip install -w wheel-cache-directory --no-install mypackage pip install --use-wheel --find-links=wheel-cache-directory --no-index mypackage wheel-cache-directory contains built versions of all your dependencies and combined with --no-index reinstallation is blazingly fast.
It also mentioned Java, Objective-C, C#, and C++, all of which are eating into or continuing to eat into areas where Python could have prospered.
I disagree. C++ has always and will always be the language of choice for writing games. All other languages are niche for that genre. And Java and Objective-C are by fiat the languages of choice of Android and iPhone development. Don't see where Python even had a choice in that. 
I didn't look at the implementation so I wasn't sure if the call to `len` was on the same container throughout the entire run of the algorithm. I just put it there just in case someone else found the idea of using callables as default arguments cool. And anyway, you can't have a default argument which is defined in terms of another argument so the point is kind of moot. EDIT: You can do this with a closure, however. As in: def f(a, b=len(a)): # fails because 'a' is not defined. print a, b def fclosure(b): def inner(a): return a + len(b) return inner f = fclosure(1( f([1]) &gt;&gt;&gt; 2 
Here is a realistic example, first with exceptions: try: input = file('input') output = file('output', 'w') for line in input: output.write( '@' + input ) except FileError: log('Error accessing files, check permissions') return Now without: input = file('input') if not input: log('Error accessing files, check permissions') return output = file('output', 'w') if not output: log('Error accessing files, check permissions') return lines = input.lines() # just cuz u can open don't mean u can read if not lines: log('Error accessing files, check permissions') return for line in lines: if not output.write( '@' + input ): log('Error accessing files, check permissions') return Ideally you would throw another exception rather than return, but I wanted to keep the comparison simple.
d'oh. nice correction, thanks.
Wait until Python 3.3.3 comes out (or will it?)
Anybody is free to suggest a better name. Coming up a name that pleases even a good fraction of people is tricky.
Python isn't a failure in game development, it's just in a different part of the pipeline. It's not uncommon for artists to create game assets in Blender or Maya using custom scripted tools. I'm sure Python's place in that part of the workflow will be secure for quite some time.
Out of curiosity: How did you tell your script what was a good deal, what was not?
Just because it isn't C++ does NOT make it a failure. Python is fantastic at scripting, web frameworks, utilities, scientific computing, frontends, automation, mockups, etc. Sure, python is not used for making a game engine, but need I remind you that Valve's new Cinema tool thing is using Python to script the UI/rigs. Different tools for different jobs. Python does what it does so well that I find it unlikely that it will be left behind..unless something replaces it to do the same thing better. Additionally, there are versions of python with a JIT, those could be used on mobile no problem. You would make the same argument about java being wasteful 10 years ago....and yet....
Yeah, I was impressed with it too though I've only used it for toy uses so far as well. I couldn't tell you how well it would work for a larger project, but I'm guessing it would go as far as you push it given the easy reuse of C libraries. Guys on the forum are even using it on Android with some work, so I guess anything is possible.
He's suggesting that all of your links point to a single engine whereas most engines are produced using C++. I'm not putting out an opinion (because I don't know), I'm just trying to elucidate.
LISP compiled code is already nearly as fast as C. JIT compling and runtime profiling would in some cases make Python *faster* than C without making it as brittle. I think it's just a matter of time, since it already happened for a class of languages that is more expressive... 
Oh, Android use sounds interesting; using Native compilation as a back end to Dalvik or compiling to VM code? Could you PM a link, if it's a public forum? 
In some dynamic language VM, "abc" would be a pointer, 1 would be the number with some flag that it isn't a pointer and True would be a pointer. All of which would be the same size (and maybe even location) as in C... As for not checking the type during execution, that's true and one of the great weaknesses of C. Once an int, always an int. Nevermind that a int + a int can be &gt; what int can hold in actual mathematics. But I get what you mean in that C structures can be inline, without indirection, which would be faster. Though that would feel strange in every single higher-level language. I wonder why the hardware doesn't check type tags... Why does every cpu put the integer alu and floating point processor on the same die with the same clock but give them two sets of registers? Why not type-check and then use the right result automatically? Have to look up some literature... 
Sure, but game development is not engine development. That would be like saying Python programmers use C because their programs run on top of CPython. I am giving examples where game developers are making games using languages other than C++ (as if the existence of thousands of Flash games and millions of Minecraft sales wasn't proof enough, but still).
Someone should go ahead and make Goe, Go with exceptions already!
I found [this](http://mail.python.org/pipermail/python-dev/2012-June/119799.html) on the mailing list, it might have some answers. 
Not to get all Haskell on things, but it's fair to say that one should minimize the amount of mutation one does. Because of that, it's going to be less likely that you need an error return value but not need a regular return value. Especially compared to, say, C++, where mutation is often used in lieu of the ability to return multiple values. Nevertheless, you are right that the situation occurs, so it can't be totally discounted. 
To summarise the thread: technically, `regex` looks OK, but it will take time and effort to get it in, and commitment to maintain it. Nobody got round to it this cycle, partly because `re` is good enough for most cases.
TL;DR: Python isn't perfect at everything and in every conceivable context, therefore, it is doomed. I am less than worried.
This makes me sad for python. Ever since numpy/scipy, python is touted as the weapon of choice for scientific programming. We have django but it didn't get as much traction as say...rails. For such an awesome language there really should be more focus in the design space than the scientific programming space.
So this is primarily for convenience within your own environment, and not for distribution?
Here's a R GLM tutorial that I converted into IPython Notebook for a professor: http://nbviewer.ipython.org/3764939/ Basically, put %%R at the top of the cell and you do can anything you can normally do in R.
Please report back if you figure out what's going on. All I had to do was install rpy2 on top of the Enthought Python distro.
pystatic ?
&gt; DOS Terminal &amp;#3232;\_&amp;#3232; DOS? It's called "Command Prompt" or console or command line interface. (sorry, pet peeve)
Can we have a wiki, were every page is a IPython Notebook?
I would so use that if only I had a reasonable purpose and need for it. Seems a bit to complex for me for just sorting my study notes.
Concerning your messy feeling, I believe Haskell suffer from the same problem than LISP (the LISP Curse): http://www.winestockwebdesign.com/Essays/Lisp_Curse.html Concerning space and time leaks, after not too much time programming in Haskell you develop an intuition and you no longer make them. If you want to give Haskell another chance and prefer to be oriented, you should try to use one of the three web main Haskell web framework ; [Yesod](http://yesodweb.com), [Snap](http://snapframework.com) and [Happstack](http://happstack.com). Also, from my experience; using Haskell for a first non trivial program makes the complete difference. The real power of Haskell is its incredible refactoring abilities while helping you to not make bug. But, like the matrix, this is only something you can experience (I believe).
I don't think bpython has anything like this notebook interface.
&gt; It's ipython on crack! What? No, it's not. It's the other way round.
I hadn't read that essay, but I was actually thinking something along the lines of "There's not many mature libraries in Haskell, I guess it's too tempting for Haskellers to just re-invent the wheel." (It's also easy to re-invent the wheel in Python, but performance can be an issue.) Also, Yesod rocks. Not as well documented as Django or Tornado though (sigh). 
I use it to take notes in class too. Markdown makes it super easy to make very nice looking notes. :-)
There's a number of Python distributions that include everything you need to run the notebook. [EPD](http://www.enthought.com/products/epd.php) (including the free version), [Anaconda](https://store.continuum.io/cshop/anaconda) (also including the free version) and [WinPython](http://code.google.com/p/winpython/) are three I know of.
And there's a (free) service to start up EC2 instances with an AMI that already includes IPython notebook, so you don't have to configure it yourself: https://notebookcloud.appspot.com/docs 
There's a bug in line 18. It's missing assert encoding == 'utf-8' Seriously, this can only cause more grief and perpetuates the myth that there's such a thing as a *native* encoding.
Well, I started looking into it and found various circuit simulation modules already available. So it would probably require integrating one of those with IPython. I just haven't had time to look at it further. I am planning to mock up something myself unless I find a ready made solution.
What "s"? My problem is with "DOS", not with "Terminal". It's not DOS, since at least Windows 2000. DOS was the O/S with Windows 3.x (and NOT Windows NT 3.x), and the underlying OS under Windows 95 and 98. Also, command.com (the DOS command processor) had less functionality the cmd.exe (the Windows Command Processor/Command Prompt). In fact, they aren't even that compatible with each other (when you go beyond the elementary functionality) &gt; No serious programmer uses windows. Really? Oh gosh, I've been doin' it wrong all these years! Guess I'll resign from my paying job and start philosophizing about programming instead. 
Right. Thanks for the highlights.
**whoosh**
I'm not sure just concatenating your values into a long integer (or multiple not quite as long integers) would work. Well, it might for something like decision trees but not for something like linear regression. Generally it is assumed that as the value increases the amount of whatever is being measured increases which wouldn't be true for your concatenation example. I would probably first try training the dimensionality on a smaller set and then use that for the dimensionality reduction of the expanded set. Should be fairly quick. http://mdp-toolkit.sourceforge.net/examples/scikits_learn/digit_classification.html#digit-classification might give you some ideas, even if you aren't using mdp
dos is Spanish for two. DOS Terminal becomes "two terminal" hence the author forgot the s to make it two terminals. And so we see how far over your head this can go. 
Well, I don't know Spanish. I know Greek, English, German and a little Italian. So, not very far. You still failed.
Your ignorance of latin does little to make it my fault. What do they teach in schools these days? 
My school? English. A few other schools: French. (I'm assuming you mean as a foreign language)
ghc won out because it has the most features &amp; developers, but man, when I was first learning Haskell, I preferred nhc98 or hugs due to size &amp; time it took to bootstrap. Nowadays, there are things like [jhc](http://repetae.net/computer/jhc/) (which is dead), [uhc](https://github.com/UU-ComputerScience/uhc) &amp; [lhc](http://lhc.seize.it/) that are attempting to catch up, but ghc is so dangerously close to the idea of a sufficiently smart compiler that I can't see development shifting away for anything but niche applications or the like.
Can you get the R output into python and vice versa through the notebook or is it basically two separate sessions, one for R and one for python?
Not easily or safely. Each notebook (page) is associated with an ipython process, which has full access to the filesystem.
I see your point. It seems like for type casts, you couldn't you just compile certain python function calls into type casts? i.e.: `int(6.2)` =&gt; `(int) 6.2` I suppose the semantics aren't quite the same. Similarly for local variable annotations, why not just use type inference? You can't declare a variable in python without setting it anyway. I agree that more people are familiar with the C-style annotations, but as someone who has been learning Scala, I'm slowly starting to prefer the `name: Type` syntax.
Sage is nice, but it has one irritating flaw: It has its own Python site-packages and by design has no access to the Python packages you've installed on your system. I once had a C library made available to Python using SWIG, and it was disappointing that Sage couldn't see it. So I tried fiddling with PYTHONPATH - no luck - Sage actively ignores your PYTHONPATH (by design). Then I think I changed the pythonpath within Sage (i.e. sys.path or however it's done). It still couldn't handle my package as the base Python that comes with Sage was compiled with different options as the one on my system. The *only* way was to reinstall any Python package I wanted to use under the Sage site-packages using Sage's Python. It's tolerable for one or two packages, but if you have a whole ecosystem, it's not worth the trouble.
http://www.doughellmann.com/projects/virtualenvwrapper/
You can pass variables between the two sessions with Rmagic: http://ipython.org/ipython-doc/dev/config/extensions/rmagic.html example: &gt;In [14]: Z = np.array([1,4,5,10]) &gt;In [15]: %R -i Z mean(Z) &gt;Out[15]: array([ 5.])
I see, I had heard that Python packaging on Windows was a bit of a nightmare. Maybe use a Linux VM or even that EC2 instance thing mentioned in the video if you still want to try it? EDIT: Or maybe [what takluyver said?](http://www.reddit.com/r/Python/comments/10fco9/why_ipython_notebook_is_amazing_and_you_should/c6d5ea1) EDIT2: Why am I getting downvoted for trying to be helpful!?
When I do it I'll be sure to add it :)
Aren't the results going to be hyper-sensitive to how you arbitrarily choose to combine dimensions? The suggestion you have of transforming the vector works equally well for 25 dimensions as it does for 1. Instead of taking the whole vector, just take 133 values at a time (ie. 3318/25) and build an integer from each one. (eg. By making a byte string of the 1s and 0s, then pass that as the first argument to int(), with the second argument being the number 2, as the base.)
good write up of the concepts. could use some sample client/server code though.
Sage is horrendously bloated (471.42 MB minimum) and won't run natively in Windows.
It is also for distribution, but the current pip patch doesn't include robust compatibility checks (it doesn't consider the difference between a win32 or linux build).
http://forum.nimrod-code.org/t/61 I think they're talking about native compilation there, but don't quote me on that. I doubt that it's all proven out and smooth at this point; he's done little more than show it's possible. 
It is just wrong about Python on Mobile Python is slow on mobile because it's a second class citizen on current platforms. Read about Firefox OS... they are building the whole thing in Javascript etc, yet it's designed to run on cheap phones: http://rawkes.com/articles/there-is-something-magical-about-firefox-os (and of course phones will continue to get faster and more powerful) I'd also like to see examples of commercial game titles written in Flash + Actionscript...? (other than web games obviously)
Anyone interested in sockets and network communications in Python should definetly read [Twisted Introduction](http://krondo.com/?page_id=1327) by Dave Peticolas.
Ah, ok. True. &gt;more that in Python it can't easily rule out that kind of usage And in C neither, they just say that for some numbers the behaviour is undefined or disallowed which limits the programs you can write. Ok, so technically they can rule out that kind of usage by hacking off my hand :-) &gt;And if an operation can return different types, every subsequent instruction would need to be able to work on all the types potentially returned, which would be awkward to say the least. Mostly that boils down to integer, floating point and user-defined. Not that many different types for each instruction to understand. From a mathematical standpoint seperating float and integer where arguably one is a special case of the other is strange, to say the least. These are not disjunct sets. Because of this, I think Javascript's way is the only sane one for a VM: just use double everywhere, no ints. Otherwise, you'd have nonsense conversions like int(1.0) = 1 etc visible in the actual source code of your program... It would be interesting to see whether there is any slowdown (on current CPUs) when one uses double everywhere instead of int... As for object inlining (in arrays etc), that's a very important and very specific case where I wonder whether JITs actually take measurements and then rearrange memory in order to have more cache hits.
There are quite a few implementations but I use [ws4py](https://github.com/Lawouach/WebSocket-for-Python) which is simple enough and is heavily based on generators if you're into them. It works well on PyPy as well which is fun :p
I also do this as well. I feel like most of the iPython examples for many applications (besides actual computation) still cover the relatively easy cases and I don't know at which point I'll hit the limitation (like how much flexibility you have in customizing the layout of your text for pdflatex) . Org-mode and Sweave on the other hand are tried-and-true... (and I'm now aware of their limitations personally). Having said that I didn't want to sound negative in this thread; just evaluating for myself whether I want to jump right in or wait a little longer. But definitely looks worth getting excited over.
From an engineering standpoint they're represented in quite different ways, since floating point values need to handle the exponent and mantissa separately, as well as special case values for infinity, not-a-number, and so on. This means you can't implement anything the same way. eg. Something as basic as incrementing a value by 1. On an integer this is fairly straightforward and probably uses a standard half-adder arrangement of logic gates to flip the least significant bit and carry over any remainder. On a floating point value, you have to be careful to only operate on a subset of bits, and you don't even know if the current value + 1 can even be represented - for example if you have the value 2^28 and you add 1, you get... 2^28 (at least in Visual C++ 2010), because the intended integer value can't be represented and the nearest one is the value you started with.
Oh, I definitely agree that it looks like a great environment to have. Now if only I could convince the IT powers that be to stop blocking ports on the linux servers so I could actually use it without launching a hideous old version of X11 firefox. But that's my misfortune and none of your own.
That's actually what I'm exploring with my stats professor this semester. So far, it seems to make life significantly easier than with Sweave. I saw a demo of a tool that converts IPython Notebooks directly into PDFs as well, but can't find it right now. (They said they were working on integrating this directly into IPython Notebook.) IMO: the huge advantage of IPython Notebook over Sweave is that the code is fully interactive, so students can play around with it, tweak variables, etc. instead of just stare at a screen.
&gt; Not sure why that bubbles up to the surface, though. It doesn't, in terms of actual operations available, in pretty much any programming language you use. Even C will let you do x++ on a float as well as an int - it's just that you may not get what you expect out of the operation, which is a limitation we'll always be stuck with. It's also not entirely true to say that dynamic languages let you ignore the difference either - ask Python 2.7 what 3/2 is and it'll answer with 1. Python 3 does better and gives you 1.5 - but ask it what 2/3 is and you'll get a floating point 0.666666666667, not a 2/3 Rational. Ultimately there are always restrictions when representing an infinite set of values in a finite set of bits so the hardware gives you a few simple sets of rules and each language gets to choose how to use them.
I know it's link bait but you argued why you *hope* that gittip is the future and explained why it isn't yet. You also skipped over the rather interesting discussion about how much time open source devs will spend marketing rather than coding because, as everything humans have ever done ever has shown us, marketing brings in more money per hour than work on the product at the scales we are talking about. I hope this model takes off as well, but there *will* be tradeoffs. /r/python will need more moderation to stop the "please tip me" spam, every project low on money will just implement the latest fad, predatory outsourced ad-agency services will arise to do the marketing for you and promise better returns (like SEO consultants). Open source and free software are ways to share the burden of common software problems among developers. It makes getting paid to write software like this difficult. Moving from cultural norms to economic norms will drastically change the landscape and culture. Can't say how, but it's pretty obvious it will be drastic. For example: when ruby was at the peak of their hype curve it would have sucked up nearly all the tip money available to FOSS dynamic language software and been a strong incentive for python devs to switch languages to make more money. Ditto for Node.js. I want more devs to get paid but worry about what turning it into even more of a popularity contest will do to software focused on quality and engineering instead of hype/fads/"webscale" based solutions. I feel like the kickstarter model just has better tradeoffs than the gittip model, although that's just a feeling.
Ah, I see. I'm pushing everything long running into celery tasks, not using gevent.
I'd really like to check back to see how this goes. My impression is that also with emacs org-mode and other markup languages that convert to tex or html, you sacrifice the ability to customize your document for the convenience of light syntax. Constructing complicated, readable tables (containing text, equations, figures, or just highly formatted text) is one thing I haven't been able to find a replacement to LaTeX/Sweave for. (And since you're using advanced features of LaTeX you're no longer able to export it to html without modification). And with Sweave/R, you can be interactive too. I send snippets of R code to the inferior R buffer as I write it to test it out (either with lisp functions or even copy-paste). In that sense I feel it's even more interactive, as I've never been able to type the white-space formatted code directly into the IPython interpreter - I use python-mode.el and ipython.el with emacs to write the properly indented code in a script and send it to the IPython process. I must be doing something wrong since everyone raves about IPython but maybe also I've achieved sufficient mastery with other tools that my current options are already quite good. Not to toot my own horn...
I generally try to keep everything in emacs so I would probably face a different set of problems. I wonder if the IPython notebook for emacs is truly as good (functional) as the web interface...
I'm using 0.12, should be 0.13. I'll look into it tomorrow. I'm really excited about this.
Oh my god, this is a brilliant tool. I've been working on a similar one but didn't have time to complete it. I'm the author of "Invent with Python". This will be absolutely wonderful for helping visualize code execution for my next book. I will definitely start contributing to this project.
The conversion tool is [nbconvert](https://github.com/ipython/nbconvert). Here's some instructions on [how to use it to create technical blog posts](http://blog.fperez.org/2012/09/blogging-with-ipython-notebook.html) along with [a real-world example on signal processing](http://python-for-signal-processing.blogspot.com/). Ping me via email (see [fperez.org](http://fperez.org)) or on the IPython mailing lists if you're interested in talking further about this; I'll be giving a few talks that touch on these ideas this fall, in particular at this [workshop on reproducible research at Brown](http://icerm.brown.edu/tw12-5-rcem). Would love to talk further about how your experience has gone so far.
You might want to try the new [Anaconda CE](https://store.continuum.io/cshop/anaconda), I've heard good things about it recently (though I haven't tried it myself).
Thanks Fernando. Looking forward to having nbconvert integrated into IPN! :-)
apologies, pylab is not a package, updated the original 
Barebones = fast. What is wrong with this?
Good point and good link. By "real traffic" and I meant "other people use it besides other devs, QA or friends/family" but that wasn't clear at all. In production you should be behind nginx. You really need that buffering.
If you're going by that definition, I'd say gevent "isn't ready for production", so stop using it.
&gt; You would make the same argument about java being wasteful 10 years ago Thing is, the JVM is now way better than CPython, which allows it to go more places. The best thing for Java has been getting Dalvik, which allows it to go to the mobile space as well.
BTW, I'll be at MSU giving a keynote at the [2012 Cyberinfrastructure Days event Oct 25/26](http://tech.msu.edu/CI-Days/sessions.php), it would be good to catch up then.
my favorite [picture](http://yannesposito.com/Scratch/img/blog/Haskell-the-Hard-Way/yo_dawg_tree.jpg) from this tutorial.
As a new developer, all the rage seems to be going towards Django in my perspective. Loving it!
For common things like this there is usually a standard library function. from itertools import permutations print list(permutations('123')) I recommend reading through the [itertools](http://docs.python.org/library/itertools.html) Python Docs page. It's full of gems.
For these sorts of things you should really be using `yield` instead of "list building" of course you're not even doing list building you're encoding the list of strings as a comma separated list. What if a comma was in the source string? Why should the calling function have to run `.split(',')` on the return value? All of this is kind of mute, because you can just use `itertools.permutations` and it will Do The Right Thing™.
Hello good sir, you picked a fine day to start learning Python :)
s/critique/criticize Critique is the noun :) Edit: Apparently it can be used as a verb as well. Weird.
You have a typo here " And this pretty much has shown me that the only way you can do anything useful these days is by putting TLS on top of everything and just force people to stop with their shenanigans." TLS is not on top of anything, it is below.
Building strings one piece at a time is a bad thing. Python Strings are immutable, so adding a letter to a string means creating a new string with the parts, then pointing the variable to the new string. Look into the join function. Replace this line: res_str += string[0:j] + s[index] +string[j:] +"," with this one: res_str = ''.join(res_str,string[0:j],s[index],string[j:],",") Other issues have already been brought up, but you got it to do what you wanted, so that's always a win.
Welcome to paradise. Python is really a pure pleasure to write compared at least to all the other languages I've tried. Also, if you have any questions or problems, try /r/learnpython, you're almost guaranteed to get good answers :)
Or even better--the pyscripter google code page. Have you tried there yet?
I would love to feel as optimistic as the author but a part of me feels that python is missing the wave that ruby/js is riding atm. I would love to hear what some of the python web framework devs (django, web2py etc) think about python's role in the web and if it can compete with the goliath that is rails.
Are you sure Rails is the Goliath, while sites like YouTube run on Python? Maybe Rails is just hyped more than Python web frameworks. The good thing is that people who are professional usually (not always, sadly) don't care about hype and use what makes most sense at the time.
[aieou](http://www.youtube.com/watch?v=Hv6RbEOlqRo)
Take a look at pypi, the package index. According to the wayback machine: 2007: ~2.6k packages 2008: ~5k 2009: ~8k 2010: ~12k July, 2011: ~15000 Now, 14 months later, I am astonished to see 24,000 packages. 
Thanks for the exhaustive tear-down. I was thinking about using lists but got lost in coming up with the recursion logic. This is super useful and will help me in writing good code.
Thanks! I should've mentioned that I'm aware of itertools. I wrote this to understand recursion as writing permutation code in a high level language helps me to think clearly about the logic.
I have a feeling that most Rails job offers are sent out by non-technical entrepreneur type people, start-ups. Python jobs seem to come more from established web companies. Now, that is obviously just my personal opinion and I have no data to substantiate. &gt;If you're creating a web application and you know ruby/python equally well would you choose django or rails as your full stack web framework? Python, always. I cannot stand the magic in Rails. I like to know what's going on. By the way, Reddit is another "big" Python web site. Many people don't know that. 
Thanks for suggesting Coroutines. I will look into them.
Not true. I'm simply speaking from the emails I get from mailing lists and it's usually developers sending out job ads for developers. The local community has a distate for recruiters so they usually don't post ads. The "magic" in rails really isn't magical once you dive into the source which is something that is encouraged by the ruby community. Python and ruby differ in philosophy. Explicit is better than implicit is the python mantra whereas ruby focuses on developer happiness. Yes I'm aware that reddit is also built using python but that's not the point that I'm trying to make.
&gt;Yes I'm aware that reddit is also built using python but that's not the point that I'm trying to make. and &gt;python's role in the web and if it can compete with the goliath that is rails. The point I am trying to make is that clearly Rails isn't a Goliath, it just may be hyped as one, but hype does not reflect reality in this case.
The code seems to be invalid
That's stats for projects hosted on github. The only thing that reflects (although not completely accurately) is what languages open source projects hosted on github are written in. It doesn't reflect what language paying employers choose to use. It doesn't reflect what language has the most lines of legacy code developers are payed to maintain.
&gt; Perl, which it used to tease, is no longer around to tease. I stopped reading here. Python is more popular than Perl in many circles, but to say Perl is gone is naive and sounds fanboy-ish.
Try: BEACHREAD305 for 15% off
It's not a race. Whoever has the most packages doesn't "win". Given the fact that basically *every* piece of software out there offers Python bindings by default, and almost *none* offer Ruby bindings, I'd say Python is doing pretty good.
Just offering a comparison. It's rather interesting. 
&gt; Python programmers are a little more series. Think this may be a typo. Good read overall!
Hmm, seems I'm doing something wrong here. This code also is invalid.
Yes, see, Rail is so 2006. It's for *old* people now. Today, all the cool kids are using Node.js, or Tower.js, or Meteor.js, or whatever the hell I've missed by not reading Hacker News for a week.
As someone who straddles communities, I can say that creating gems and using them is widely encouraged. Some Ruby developers say things like "with enough gems, you can solve any problem"; although it's 90% tongue-in-cheek, there's still some truth to it because it's where folks go first to look for solutions. Python packaging, as other have noted, has hindered PyPI and this aspect of the development culture overall. When you tell someone they will need an egg or they'll have to use pip to install some dependencies, the blood drains from their face and they say "alright" as if you just asked them to save mankind by throwing themselves into a volcano.
Almost there, but still a very important gap in usage. http://www.indeed.com/jobanalytics/jobtrends?q=python%2Cperl
How mature it is compared to developing in Java?
My university (and many more) just switched from C++ to python for teaching new students. And we think it is marvelous. So I see great future for python in academics.
PERL has many more, but i didn't see that PERL is considered as winner here.
I checked out kivy a few weeks ago and loved it, thanks for all your hard work to get it where it is today. I'm intimidated by Objective-C and memory management, hence why I would like to take a crack at an iOS app with Python. Quick question for you - how feasible is it to call iOS APIs from within Python/kivy?
I started on a crisp morning in Feb of this year with four specific coding projects to complete by year end, 3 down and one to go. Bonus, just a week ago published some work to Google code, a frustrating, rewarding, and inspiring journey. I firmly planted in the python field.
+1 to the last point on introspection for clean apis and as an important feature of python generally.
No, but others have: [StackOverflow on this Question](http://stackoverflow.com/questions/3055477/how-slow-is-pythons-string-concatenation-vs-str-join).
I'm not sure exactly what you mean by mature. I would say python is as mature as java. kivy is obviously less "mature" in terms of real world usage/testing than the android SDK, since we don't have the amount of engineers and users working on it full-time as Google does :P. That said, we have an active community of users and contributes, who use kivy daily for a lot of different projects, including quite a few businesses and professionals building apps for mobile devices. the docs are also pretty decent I think :)
I can't help you since for terminal work I really prefer bpython to IPython… ;)
I've just started with Kivy and the docs are excellent. Thanks.
as somebody who has worked professionally for a number of years in both python &amp; ruby, i'd say a bit of both. python packaging leaves a lot to be desired. the infatuation with building a gem for everything leaves even more to be desired. i think somebody once said something about a middle path?
Hmm.. This was done a 2 years ago. I tried it about a year ago. I'm guessing the implementation changed.
Perl was not easy to learn, no. It had a lot of magic and incorporated conventions from other languages that most newish programmers do not know: awk, sed, sh. BASIC was easy to learn but hard to be productive with. Of course there are a lot of basics, so we would need to select a particular one before I could get specific. If BASIC were truly productive then it would not have needed 15 variants with "real language features."
PERL is still around. Forget that part of the article. More than the absolute number, I'm impressed by the rate of growth at about 1.6 times more packages every year.
EC2 micro instances get *really* low priority for networking I/O and CPU both, so you should use small at least in production. 
&gt;You're perfectly entitled to think that using indentation to delimit code blocks is a bad idea. But it's &gt;a defining feature of Python: if you got rid of it, you'd have a different language. Python-inspired, &gt;perhaps, but not Python. Perfect example, no reasoning, just religion. If changing one aspect of the syntax makes it non-Python, then 3.0 isn't Python since it differs from the syntax of 2.x. And changing any aspect of the syntax should always be open for discussion. &gt;"Pythonic" means something like 'readable, maintainable, unsurprising'. Sometimes 'getting stuff done' &gt;is all you need, but often you need to keep using and updating the code in the future. That's when &gt;doing things well is important. Just like "groovy", "Pythonic" means whatever the user thinks it means. If you mean to say "readable, maintainable, unsurprising", then say "good code" or "well-written code". Otherwise you're just parroting a null phrase, and turning an engineering tool into a fanboy clubhouse.
FWIW, iPhone development in Objective-C has had [Automated Reference Counting](https://www.google.com/search?q=automated+reference+counting) available since iOS 5. Generally speaking, there is no reason to manage memory manually anymore.
pip is easy, what gives?
code-significant indents are totally insignificant. You don't need that changed to get stuff done. Lots of people have been getting stuff done for decades now, in Python, without curly braces. Give it up, go away
Seconded. I've been writing Perl code on a daily basis for over ten years. It may be easy for me now, but it was far from easy to learn. I must have typed 'perldoc perlref' about a million times when I was learning. And it all just looks like a bunch of bullshit cartoon swearing to the uninitiated. 
pip is easy if it's pure python. if you want to install compiled code, it's not adequate. developers don't support the 30 flavors of linux, so this becomes a problem and even when they're on windows, a package like scipy can not be pip installed. you must download an installer.
I consider Perl fairly easy to learn. Why? The metric for "easy" is based on what exactly? How long it takes to be productive? How long it takes to master it? How long it takes to learn to leverage the languages resources and ecosystem? In my experience it took just as long to learn Perl and properly use its ecosystem and resources to write reusable dependable utilities and libraries as it did Python (fyi I learned Perl after Python). As for how long it takes to be productive? Again Perl has so many ways of doing things that there exists a subset of the language (often referred to as baby-talk) that anyone with experience in the basic structures of imperative programming can be immediately productive with, and run into very few surprises. I would say that it takes marginally longer to be productive with Perl than with Python, but that isn't a very good measure of language quality or power. As for how long it takes for someone to master either language? I've met a couple gurus of both languages and they all earned their knowledge through years of experience. This timespan easily dwarfs whatever differences exist between the two languages learning phases. There is a lot of depth and complexity to explore in both Python and Perl that cannot be learned in just a couple months, or even a couple years.
I have the site on a bookmark but don't really check it. Could someone give me the breakdown on hacker news and why I should check it more often than I usually do?
I probably will. I forgot to mention I'm just using a micro instance for testing and development.
That seems to be either a bug or you not having python 3.2 installed as that 32 refers to the python version 3.2
Thank you very much for your response!
There's no silver bullet in terms of Python introspection in IDEs. I'm using PyCharm, it's pretty good, though, of course, it doesn't cover all of the cases. Also you might want to take a look into Eclipse, Aptana and Wing IDE.
In my country if I search 'ruby' on a job sites it gets 13 listings and if I search Python I get 14.
Love web2py, unfortunately it's not as popular as Django so it doesn't have as many resources.
I was looking at the MIT Open Courseware / Udacity for Python last year while my classes were teaching *VB.net*.
Yes, PyCharm is ugly mostly because of its GUI library/fonts. But it is not slow as long as you have enough memory to run it.
Well, gevent.wsgi in upcoming gevent 1.0 release seems to be just renamed gevent.pywsgi so I think gevent.pywsgi (gevent.wsgi in 1.0 branch) is the best choice. Personally, I use gevent.pywsgi with circusd to deploy my WSGI apps.
&gt; The "good" tutorials (Learn you a Haskell, Real World Haskell) are just slow. The more "academic" ones are dry. Yes. This one you shared is quite good. Thanks!
Not sure why this got downvoted. It's definitely true. I also code for iPhone and the memory management issue is no longer a huge barrier to getting started. Also, Python has a similar retain count memory management system like Objective-C.
Honestly, when you don't know programming and don't care about it, or even when you're beginning and interested, any piece of code looks like a clusterfuck of random words and punctuation everywhere. So I can kinda get why people would have a negative feeling at first. But when you start to get comfortable with your language and one or two libraries, and you begin to understand how much power it gives you, you realize how awesome programming really is. It's the power to create anything you can dream of. Edit : Also, it's awesome to understand how some things are coded in a video game or program just by some of the little quirks you notice.
for starters kickstarter does not support you if you're not an american. this is a bit of a deal breaker for me. the points you rise are generally sound and definitely worth discussing, however I don't think this is a real danger. I've been developing open source paid for most of the past 7 years (pypy, predominantly), mostly living off a ramen salary. in a way it would be much more convinient to not have to do those odd gigs to get some money every now and then and instead focus on say numpy (which I'm being paid to do) and jit warmup (which I'm not being paid to do, but IMO is a higher benefit/time to the community). I think the solution in this case is a cap on how much you can make as a open source software author. If this is not competitive with a normal good salary, I doubt we'll see much of what you fear. Cheers, fijal
That's very true - hopefully it develops momentum soon. So far, it hasn't been a huge problem for me.
I believe that part was merely wild speculation, Windows 8 aside perhaps.
Hi, I already wrote a small app in kivy for my personal purposes and loved the experience. I also find pyjnius a very, very promising project as it may be a true gateway to pure-python native looking Android apps. The pyjnuis docs say it's necessary to write some java code in cases when an anonymous class is needed to handle events. I wonder if there are plans to avoid touching java altogether. I'm thinking about generating byte codes at runtime with some trampoline to Python (and type converters) and feeding it to java.lang.ClassLoader.defineClass. May be a bad idea for some reasons, but I wonder what you think about it...
Feels like Reddit. but faster.
I'll give you my Python when you take it from my cold dead hands. . . I fully admit to being a python fanatic and the idea of using Javascript all the time, everywhere seriously bums me out. I've used plenty of languages, including Javascript. And I don't even hate it. Completely. We need to grab our pitchforks and get Python into the browser!
Django and Numpy/Scipy/Matplotlib are the biggies here. I think those alone command some sizeable part of the community. And both are/will be on Python 3 already/very soon! I think we will have crossed the zenith soon and mass adoption will commence shortly! (was that last sentence even English?)
If you want to feel good about Python compared to Ruby, you just need to source a different graph. https://www.ohloh.net/languages/compare?measure=projects&amp;percent=true&amp;l0=c&amp;l1=html&amp;l2=java&amp;l3=php&amp;l4=python&amp;l6=ruby&amp;l7=-1&amp;commit=Update
Sure, but Perl isn't used as much in new projects, not as much as it used to be. There's a huge amount of deployed code out there but when do you hear of anyone building a big completely new project in Perl? 
Could you explain or link to a favourite explanation of how to do multiple processes?
ohhh...this looks very interresting :D thanks for sharing
I know GNOME 3 uses js for their desktop.
First let me say that I was responding to the following sentiment: &gt; I haven't seen you give any good reasons for brace based scoping, shall we call you religious too? I'm not the target of that particular statement but I felt that I would describe some of the problem areas and complaints that I've come across as a direct result of significant whitespace. Secondly, I'm not really asking for development tips, but thank you for your suggestions. I use emacs and ipython and run python interpreters from within emacs and the emacs gud + pdb for gui style debugging, and I'm quite comfortable with that setup. On to your points &gt; So pasting large peices of code into the interpreter is a bit of a strange case, you should use temp files with a good text editor/IDE at that point (and why not use one? code highlighting and such are useful...) I would say that pasting pieces of code into an interpreter is far from a strange case. I will often try out small bits of code to see how they work or what they return for the purposes of exploration. This is especially useful when trying out a library for the first time, before I've developed trust or familiarity with its documentation. Typically I'll type out a few things or paste a few examples to see what they do and how they act. Being able to do this is highly desirable for me, and it's a style and habit which I use with other languages, it's jarring to see it not work quite this way in python. But getting back to the root of my assertion: This isn't necessarily an essential feature of python, but it is one use-case which would be made easier without significant indentation. &gt; At the point that your lambda is not trivial enough to be expressed in a single line, or needs more expressions, use a function that is defined right then and there. This is somewhat irrelevant and only really applies to languages with crippled lambdas. Defining a function with lambda implies something slightly different than defining it with a binding. &gt; I prefer defining a function at the same scope, easier to keep track of stuff (remember explicit is good, so compacting code to fit in a lambda is normally bad.) Defining a function in the same scope is fine, but not as clean in my opinion. If the function is simply a one-off action, or if it is to be thought of more as an object than a function I would rather define it as a lambda (in languages where it can be done this way). The comment about "compacting" code only really applies to Python (and any other language that has similarly restricted lambdas). The only reason there is any "compacting" of code in lambdas is that they can only hold one line. In lisp or haskell lambdas can be whole functions and you may take as much space (and use as many comments) as you need. Again, back to my assertion: lambdas may only contain one line as a result of significant indentation. I have no evidence of this since I can't find that article. The rest of your comment on this point is development advice which is, again, appreciated but unasked for. &gt;But I have issue with the idea that if I use code from some one else, I would need braces myself or convert their code. This is the only real issue I have with this. In haskell, braces are optional in the sense that you can use or not use them for any expression or code block within the same file. You potentially wouldn't need to use braces as delimiters in those files which use them.
Give [IdleX](http://idlex.sourceforge.net) a try. It has IPython bindings, allowing you to use IPython with inline plotting. IPython's tab completion is also available in the editor itself. It also has SubCode which lets you run code in between ## comments by pressing Ctrl+Enter, similar to CellMode in Matlab and Cells in the IPython Notebook. 
yes definitely, i'm a performance freak myself 
I know they're documented! I spent hours on that page. :P I simply mean it's not immediately obvious that the notebook runs without all the QT stuff (at least, not to a novice). I tried macports, homebrew, and adding the QT stuff to the free Enthought package. I followed many specific lists of instructions! Nope. Though like I said, at one point I think macports was screwing up scipy, not the QT stuff (which was weird but unfixable.)
Looks neat! It doesn't seem to have pyqt or the other one (pylab?), though, so while it will run the notebook it won't handle the QT console, which is the same as the EPD free. 
Wing IDE is a good deal of functionalities over a simple user interface.
It's reddit without the retards. But don't spread it around, or it will turn into a crapfest like reddit and slashdot.
yes, but still, multi processing introduces its own problems too that wouldn't be there with threading, and its kind of silly that we have to use multiple processes because threading is kind of bad on python =/
CoffeeScript!
and qt does, but note that thats just a language for describing the interfaces, not the actual code that makes the application run
It's the same old hype that's being shoved down our throats for the last 10 years. It's called wishful thinking, namely people who feel at home with a language like JavaScript, but find deficiencies in Python.
this might be helpful for sublime: https://github.com/Kronuz/SublimeCodeIntel I don't use it myself.
Yeah, I'm planning on revisiting web2py when I'm more experienced with Python. 
We're working on bringing the scientific Python stuff together under one banner. The discussion is going on on the scipy-user mailing list.
Numpy and scipy are happily chugging away in python 3. Now I'm just waiting for matplotlib...
True, in hindsight it wasn't a good comparison.
I usually just start listeners as other processes and pass them messages with a bus or queue. Redis is nice. Some people like RabbitMQ.
Yeah, as another non-american I'm also annoyed at Kickstarter for that reason. I still like the model since it allows ambitious projects to get off the ground with real pay. I'm really interested in seeing how kickstarter handles the vaporware/scam problem as I think that will make or break this crowdfunded project model. A cap on tips is a very interesting idea, I think it would crush the dreams of some of the gittip supporters who think they *will* be able to make a competitive salary this way but it would curb a lot of the issues that worry me. Also, thank you *so* much for your contributions to pypy and numpy. That's exactly the kind of expertise and effort we should be trying to encourage and reward.
It's an outlier, though; can you name another? There probably is one, but they're few and far between these days.
A a Python programmer who's used some Ruby as well, I've got to say that I find Ruby gems to be, on the whole, less well-documented and reliable. The documentation may *look* fine, but it's oftentimes missing critical details or out-of date. Furthermore, the Ruby community is aware of vast redundancy in the gemsets - the number of command-line argument parsing libraries in Ruby is a running joke among Rubyists.
&gt; developers don't support the 30 flavors of linux, What? You shouldn't need to support different Linux distributions separately if you're packaging properly....
Right, but a few exceptions don't mean there isn't a trend. This is just one metric, and a flawed one at that, but searching github for Python and Perl yields nearly 3 times as many hits for Python.
In the history of programming I think the worst mess happened in the "xbase" language - which is the name for the collected syntax of dbase, foxpro and clipper. There were a dozen ways of doing everything. And so, you had to know them all to maintain code. Then the Clipper folks rewrote their piece and cut all the duplication out. Their motto was a line from a Rolling Stones song: "You won't get what you want - but you'll get what you'll need". And it was wonderful. The difference between Perl &amp; Python reminds me of this difference between xbase &amp; Python: a disorganized, organically-developed inconsistent set of very productive syntax that sucks to maintain on one side vs an attempt to reduce to the bare minimum on the other - that sometimes makes development a little harder, but certainly makes maintenance far easier.
Sure, but people used to say the same thing about Python. Also, there are plenty of bigger apps (e.g. Bugzilla) that are written in Perl. 
isn't this a good thing?
I have to second that. As a relatively inexperienced Python developer, the whole packaging system is pretty opaque to me. I'm wanting to do it right and make my applications available, but have no confidence that what I come up with is in any way standard or "right".
Yes! I think the committee that selects the talks would be very interested, especially if you give good details and an outline of what you're going to talk about.
Nah, they're replacing the entire degree as of next semester and I'll be doing C#/Java. The nearest other university would be about 1 hour commute which isn't ideal and the cost of living around the campus is quite high.
Regarding your first claim and your edit in response to it: you made a completely unfounded assertion with nothing to back it up. Therefore we can only assume you are speaking from a personal position, and can only address that.
No, I think it's just a wrapper around CPython. If you mean IronPython, then I'm not sure. I think Jython and IronPython lag the CPython reference implementation significantly, and don't even support Python 3 yet.
I emphasise that CPython is not currently the tool for the job, but there's no reason that Python can't excel at concurrency and parallelism. In fact, it should.
installing wxPython from source is a nightmare. it's a well respected project, so clearly they're doing something wrong. i've never gotten the thing to build and i've tried Ubuntu and CentOS. it's easier to just change your base python by changing your OS and using the package manager than it is to build wx.
FWIW VB6 was great :D
:(
TBH, C#/Java almost guarantee you a job. But I'd hang up my keyboard before I'd grind on some corporate code base in either of those languages.
I'd rather not get a job with either as well, but I don't think even the University of Auckland (largest Uni near me) teaches Python D:.
Come to Aussie. :D
It is scheduled for end of october.
Plenty of sheep here too, dw.
Actually I think there's nothing wrong with VB6. It had its shortcomings but was a great language both for learning and rapid prototyping GUI apps.
Thanks, for clearing that.
It really was. 
Haha, not for every ambitious kiwi but for a lot.
&gt; because he wanted an excuse to make a new programming language What would that be?
The git version already works with Python 3, I'm using it daily.
I can see where he is coming from, especially for testing purposes having separate virtualenvs makes sense. However, the standalone virtualenv.py already makes this pretty damn easy.
I like [Komodo Edit](http://www.activestate.com/komodo-edit/downloads)
I have 16GB, but it used to run fine with 4GB, too as long as I don't run out of memory with other applications.
I don't see how this is better than virtualenvwrapper.
I wrote a bit about why in the README. Two main reasons (although not a hands-down argument, I agree): 1. Virtualenvwrapper is slow sometimes, and this tends to annoy when integrated into a .zshrc or a .bashrc. 2. Virtualenvwrapper *always* requires you to **workon** the environment you choose, and this is not very convenient when using Python from within other tools, like Emacs/vim/Eclipse/etc. This tool allows you to just add ~/.pytoggle/aliases/python as your "interpreter", and it takes care of switching to the "right" environment by itself. I like virtualenvwrapper a lot and I'm still using it. This tool doesn't necessarily replace it, it complements it.
I presented two hypothetical scenarios as examples of situations where the Python group would react badly, and members of the group reacted badly. Situation predicted, situation presented, predictions verified. On the good side, some (Very few) people chose to take the opportunity to discuss the relative usefulness of the current situation, and present alternatives and discuss their relative merits. (That's what should happen.) On the other side, the majority of the replies were knee-jerk reactions to the very concept of the scenarios. In fact, none of those replies (Including yours) even considered that these were hypothetical situations! (That's not good.) (Btw, is it "trolling" when someone presents a scenario and you misunderstand it? Because in that case I bet you experience a LOT of trolling.) 
I created the hypothetical situation of someone making that assertion, for the purpose of describing situations where questions to the group are taken badly. The proper way to respond (If you choose to respond at all) is to discuss the relative merits of the situation.
Thanks for responding. I did see that part of the README but it struck me as a little odd. I've never experienced virtualenvwrapper being slow. I'll explore the within vim use case.
a language is not a framework. JS or perhaps stricter variants there of can have application frameworks built on top of it, such as BackboneJS. And we're talking about UI here, why woudl we want access to the "system proper"?
Yes, but you can't use the same interpreter *always* and have it toggle between environments. In the above line you mentioned you *are* mentioning the virtualenv you're interested in...
Well, it definitely happened to me (when calling *workon* in my .zshrc for setting up the "default" virtualenv). I had several friends of mine reporting the same issue. From my initial investigation I deduced this was because virtualenvwrapper.sh **stat**ed a lot of paths as a part of *workon*, and I was (and still am) running on top of full disk encryption (which makes *stat* not so cheap and tend to hang for up to 0.5s sometimes). This trick makes me delay the virtualenv mess up to the point I definitely need it. Once again, YMMV.
As long as the scope is limited enough that we can get cleanly through a reasonable example, I think this would be very productive.
I use Freemind for plenty of other things, but I still think it's more convenient for me to to use Google for this type of problem.
I don't see why virtualenvwrapper is better than using raw virtualenv...
If you don't use virtualenvwrapper you are running bin/activate relative to some path, so I guess it depends on whether you want to keep all your virtualenvs in a magical ~/.virtualenvs or whether you like to keep them inside project dirs.
There is library isolation. zc.recipe.egg installs each library in it's own path (e.g. &lt;libraryname&gt;-&lt;version&gt;-&lt;platform/build&gt;) then appends each library that a script depends upon to sys.path in the scripts it generates. This way multiple scripts can be in the same bin directory but each have distinct dependencies.
Purely convenience. You end up with all your virtualenvs in one directory instead of the `.env` in your repo pattern. You get a nifty command called `workon` that activates an env for you. `workon new_site` instead of: `source new_site_repo/.env/bin/activate`
You should give a try to ipython notebook. Just install tornado, ipython and zmq and launch : $ ipython notebook Then, point your browser to http://localhost:8888 I could be what your are waiting for ;)
What OS are you running? 
Sorry, I should have said, Windows 64bit. I have python installed already :)
Having zero experience with development I can only point you to: https://code.djangoproject.com/wiki/WindowsInstall
Did you check Django's docs? You won't get anywhere until you get used to looking at docs. https://code.djangoproject.com/wiki/WindowsInstall some people have said this worked for them http://bitnami.org/stack/djangostack
Djangostack looks like just what I was looking for! Thanks, I will try this out tomorrow :)
You need to install [MinGW](http://www.mingw.org/) and add that to your env path. Having got ipython (+pandas) running on py3k on windows was surprisingly easy, particularly when I found Christoph's [windows binaries](http://www.lfd.uci.edu/~gohlke/pythonlibs/) for most of the larger python libraries. On a mac I wasn't so lucky, spending a good day on fluffing around, trying to get everything to compile.
Nothing about Django would be "easier" than setting up a simple XAMPP server, but it eventually *becomes* easier once you learn the basics. It only seems that way because of your personal experience with it. You'll need to learn how Django templates work. How to develop using the standalone dev server, and then to integrate with a conventional web server like Apache. You'll need to learn how to set up your web server to serve up static content. This may also end up with you setting up multiple web servers for the same project (eg: Nginx for static content, Apache for the other stuff) You'll need to learn how the Django URL dispatcher works, which will invariably lead to learning how Regex works. That alone is at least a couple days of reading if you plan on learning it inside and out. You'll need to read at least the first few chapters of the Django documentation from Getting Started, onward. It's not as simple as downloading an exe following the onscreen instructions, or apt-get install django and running the django app. There's a lot to do before you get *anything* running whatsoever. You'll need to figure out Django models and their ORM in general. It is eventually simpler than base sql interactions, but it does not start that way. It's not basic knowledge that Stuff.objects.filter(label='things') will return a list regardless of whether or not there is only one result, but Stuff.objects.get(label='things') will only return one object and crap out if more than 1 result is found. That being said, It's definitely worth learning, but I wouldn't expect to have a perfect conversion from a previous project in a day or two. It's going to take some reading.
Let me get a few fixes and test with friends and I will post a write-up and link. Not quite ready for prime-time.
What? The server a) notices the malformed request, b) throws an error due to the request, and c) logs that such an error occurred. This is considered broken? I have no interest in using a pure python webserver, but this seems like drivel to me.
Yes, that's why I specified readline. You have to hook into the character-by-character key event handling to do that, and readline doesn't make that possible (at least the part of the API available to python, I don't know if the underlying C lib allows it).
I use the latest version of Eclipse Juno with PyDev. Introspection seems to work very nicely.
what happens when the server is behind a reverse proxy such as nginx? 
In theory, programming exceptions shouldn't be raised just based on invalid input. For example, if you had a program consisting of `int(raw_input())` and it raised an exception when you pass it "five", that is generally considered a bug. Cases like that should be handled more gracefully; for example, a generic MalformedRequest exception should be raised, with the proper HTTP error. Due to WSGI apps not completely exploding due to uncaught exceptions though, in reality this doesn't mean very much, since the odds of a legitimate client or legitimate user making a request so malformed is very slim.
Really funny how the author of this article thinks that a design which silences errors by default when they go unhandled is less 'implicit' than one which forces the programmer to deal with them when they go unhandled.
They could have gotten a more enthusiastic appearing host. It seemed she didn't know or wasn't into Python, just reading off questions. I'd think they would be able to find a big Python fan at O'Reily. 
The user sees a 500 error.
In that case, the bug is not that the server crashed, or let an exception through. The bug is that the server is not using HTTP codes as you would like it to. Right?
What actual problem has this ever caused, to merit the label 'broken'?
3rd-ed for Wing IDE, especially since I discovered the debug probe tool a few days ago. 
Seriously, just go through the Django Book (part of the online documentation). I've (almost) never seen a better documented project online. It's not dry and overly technical, and you'll learn some good coding practices on the way. Django's own online tutorial for getting set up is nice.
As a server author I'm glad someone is trying to break this stuff. My experience is that even with good test coverage, it's awful hard to be sure you got it right.
since you're on windows, give PTVS + Azure - also, they're both free. PTVS has full support for django debugging, templates, intellisense, etc. as well which can make life easier. it can also auto-deploy to Azure. on the Azure side, you can also choose a linux VM if u like. more here (see the django related links &amp; videos): https://www.windowsazure.com/en-us/develop/python/
Apart from the fact that 500 errors *genuinely* mean that the response caused an exception on the server?
&gt;will guarantee you a job No...proficiency in any language will not *guarantee* you a job.
Well no, but you'd have to be the absolute bottom of the barrel not to get a job if you knew both C# and Java reasonably well.
Why is malformed input definitely not a reason to throw an exception? When should exceptions be used? Let's assume that raising an exception is the correct thing to do here (I don't believe it's not.), yes, a `ValueError` says what happened. An invalid value was supplied and a message detailing why the the value was invalid is given. How is that not acceptable? Should it also raise a `PotentialSecurityException` on a 404? Maybe the user is probing for unlisted files. Mentioning the potential security issue in the `ValueError` makes sense because it is only potential. It's just as likely that the client made a bad request due to shoddy programming, so maybe it should raise a `PotentialPoorlyWrittenHTTPClientException`.
Meh, it's not quite broken as it is bugged. Linkbait and so forth. Good to know about it, but changes nothing in my mind.
No, it's generally capturing exceptions and just throwing a 500, instead of handling those exceptions correctly, hence letting them through. It's just a semantics issue we both have the same idea so.
Could be a door into DDoS, flood logs etc.
exactly as a flood of legit requests; indeed this is less effective way to cause a ddos because the request is interrupted prematurely.
On a similar note, I found that if I pass a query parameter that is not valid UTF-8 to a Pyramid (or maybe even any WebOb-based) server that tries to use the query variables, it will raise a UnicodeDecodeError. WebOb assumes it can treat a query string as UTF-8, and if it can't, that exception propagates up to the framework. 
I have been using pyCharm quite a bit and while it used to be slow in the 1.x days, the 2.x versions are fairly snappy. There is a bit of initial load time, but once it loads, it's fairly responsive. I went ahead and changed the theme a bit, which makes it easier on the eyes. I only recently learned about ipython. There was a link on here a couple days ago about the ipython notebook, which is pretty darn awesome. I did see that pyCharm has support for ipython since version 2.0. You get a free trial, so you should just go ahead download it, configure it to use ipython, start a sample project (or open an existing directory you're working on), and really play with it. Pycharm also is well integrated with version control and ability to deploy via ssh/ftp. One thing I've been doing recently with it is my own little project [markItUp Hoard](https://github.com/ytjohn/markitup-hoard). It's really an html/javascript project. I have a series of examples using markItUp. Since each page is it's own separate file, I wrote a couple templates and I wrote a generator in python. The generator (build.py) takes my "top" template and my "module" template and pieces them together. When I make a change in one of the templates in pyCharm, I click the green run button at the top and I watch as it rebuilds the templates. Edit -&gt; Save -&gt; Run. Things like this are highly convenient. 
I am not an expert at all and in fact I just started using python myself a few days ago for a project. However, an expert recommended that for prototyping I use flask instead of django, see: http://flask.pocoo.org/ I can't speak for django but the flask documentation walks you through installing and setting up virtualenv and within 10 minutes I who had basically never touched python or web development before had a simple hello world page running with no trouble. It also makes URL parsing, etc incredibly easy.
corrected. Thx to gist it corrects also the post :P yep, you are right, there is a numpy way. I do admit when playing with python for fun, and when I know I don't look for speed I tend to write it as it comes:P I might write something about the best pythonic moving average vs numpy way (convolution). So far numpy is 10k faster than my best try. I could aslso be consistent and CAP all the constants :) 
500 errors are server side errors, not client/request errors.
But that's what (semantically) _should_ happen when user input is not of the expected format. In most cases, you only need to handle input formats that can be generated by your forms or defined in your API. Anything else will result in an exception that will stop further execution anyways. As an example, if you expect an integer to be coming through a hidden form field, and an "attacker" puts a string there instead, the request will raise an exception when it tries to parse it, and return a 500. There's nothing wrong with this, as long as the server loop catches the exception and keeps serving requests. And you _don't_ need to return pretty error pages in these situations, since your legitimate users should never see a 500.
On the contrary, a request that is malformed *should* cause a [400 Response](http://en.wikipedia.org/wiki/List_of_HTTP_status_codes#4xx_Client_Error) or potentially something else in the 4xx range.
Why are 200 and 500 the only response options? There is a response code defined for bad requests. Use it.
Yeah, I modified my post a bit. The thing is, how do you preemptively differentiate between a Bad Request and an Internal Server Error? Since, conceptually, you do not _know_ of bugs beforehand, you can't determine if an error is raised because of bad input or a bug in your code. If you're not logging 400s, then you could be missing stack traces that point to a bug just because you _think_ they don't. Really, a "Bad Request" status could be returned for any input that your server can't handle-- so why not just always return a 400? Regardless of what number is attached to the response, the sentiment towards the OP is the same-- a 500 is not indicative of a security hazard.
The documentation for 400 says: &gt; The request could not be understood by the server due to malformed syntax. The client SHOULD NOT repeat the request without modifications. This seems to indicate that it should be used for _syntactically invalid_ HTTP requests (ie. ones that do not conform to the standardized grammar). Passing in unexpected data is an issue of semantics, not syntax. Meanwhile, the 500 documentation states: &gt; The server encountered an unexpected condition which prevented it from fulfilling the request. IMO, this is more fitting for unexpected input.
haha, awesome project it looks very useful. hope you like beefish! i wrote a little [post](http://charlesleifer.com/blog/web-based-encrypted-file-storage-using-flask-and-aws/) the other day about a similar idea using flask to build a web frontend for encrypted file storage. [the code](https://github.com/sv1jsb/encrypted-flask-aws) is on github in case you're interested
I would recommend to use scipy.signal.medfilt for the median filter, which should be about 40 times faster than your numpy code.
Badly formed input, whether syntactic or not, should be expected from external data, and should not cause a server crash. Also, syntactic errors are exactly what the article was talking about (A request that lists a content-length of "x", for example). 
This is how I remember it, as a web developer, 500 means I fucked up, 400 means you fucked up.
You might be interested in this: http://hynek.me/articles/python-app-deployment-with-native-packages/ 
That was a great post. I was ultimately inspired to do things this way by that post. I only wish there were more concrete examples.
Yes, because making debian packages out of python project proved so insanely complex, I gave up last time i tried.
Powerpoint karaoke still a thing? If yes than I'm in.
To my understanding, WSGI handles things on a request-by-request basis, so an unhandled exception should just interrupt the current request and not require restarting the application/server. Only if it had some side effect that botched all future requests (modifying some global variable or database data or something), then that would be a severe DoS issue.
It's actually pretty straight forward: * Create a setup.py file * python setup.py register * python setup.py sdist upload (edit: formatting)
Thanks. Corrected. To be honest, this was a post I wrote after 11pm. I submitted it to Hacker News on a bit of a whim. In retrospect, I really should have done a lot of editing because the post has received 13k views.
FWIW, you should come to the Auckland Python User Group meetings, which are held at UoA www.meetup.com/nz-python-user-group/ 
With typical Python applications yeah, but in the context of a WSGI app, the web server still runs and can respond to subsequent requests without any need for restarting.
Yes. I'd be interested in helping build better tools for this, too.
'Debian Packaging For Deployment' is a fine title, it's short and to the point. You could go, hmmm... 'dpkg-ing your app for great deployment'? 'deployment aptitude with aptitude deployment'? 'Debian has worked longer and harder on packaging and deployment problems than almost anyone and you should use their tools because they are doing it The Right Way' ? I would stick to yours.
thanks! 
Amazon just released [Glacier](http://aws.amazon.com/glacier/). &gt; Amazon Glacier is an extremely low-cost storage service that provides secure and durable storage for data archiving and backup. In order to keep costs low, Amazon Glacier is optimized for data that is infrequently accessed and for which retrieval times of several hours are suitable. With Amazon Glacier, customers can reliably store large or small amounts of data for as little as $0.01 per gigabyte per month, a significant savings compared to on-premises solutions.
From the wiki: http://srinikom.github.com/pyside-docs/
Absolutely. It'll be on my sort list of presentations to watch.
I'd really feel awful if I proposed a tutorial which people paid for, then couldn't deliver the highest possible level of tutorial. Does anyone else feel this way?
Yes, absolutely - I am actually doing the same thing at my job, but have no good resources on the topic and would love to get input on how someone else is doing it. Please PM me :-)
I first thought, what a pain, since I just wanted to demonstrate what a median filter is and how simple it is, and I always don't matter when speed does not matter. And I thought just coding it is more expressive than describing. Now, I have to add two full text explanations of what moving average and median filter are, and I should have from the very beginning. But then, I realized I cannot help people knowing numpy/scipy without showing correct code. And that if someone copied this code, he would have the wrong idea. So, after realizing you were definitively right amer45, I corrected. I am sometimes a little bit careless of «being the fastest possible», but I should not spread for this reason Bad Practices. My bad. The scrutinity of others is both a pain and a blessing. A pain because it makes you leave you comfort zone, A blessing because it makes you think and improve constantly. 
I'll totally come to such talk
with *numpy*. This is more like array programming (J etc) than "traditional" python. Cool as an demonstration of array techniques though .. well worth looking at the building blocks' `__doc__`strings in `ipython` for anyone unfamiliar with numpy. *edit*: btw, I don't think the weights need to be sorted? The result of `cumsum` will be in any case, which is sufficient for `searchsorted`
Yes! Title Suggestion: Using Debian packages for deployment. I wouldn't use PyPy as an example. At EuroPycon it appeared that no one is actually using it in production so I don't imagine it's a useful 'real world example' for anyone. Perhaps the examples should be something python only (e.g. dateutil) and a mixture of C and python (which virtualenv struggles with) like numpy or scipy.
Does the list of weights need to be sorted? The list t = cumsum(weights) is sorted and it is the list used by searchsorted.
Hi dathvsoto, you're right. Thanks for reporting.
We use pkg on FreeBSD right now, but are in the process of creating debs for Debian as well. Does everyone not already do this for deployment? If they don't, you definitely need to do this talk? 
I understand the approach of "making it from scratch to understand how it works". It can be quite satisfying indeed. However, as a scientist, my time is better invested in reading the documentation of Scipy/Numpy to find out what has already been implemented. Implementing something as simple as a median filter can escalate into a big work, because you have to check properly your implementation: what are the side effects? is it limited to a number type (int, float)? does it work only for ndarray or also for lists? etc. I used to use an array based numeric language with almost no support and no numerical libraries for complex, just the basics. I ended up with 300k lines of code at the end of my PhD. Today, as a Python user, I always spend a little bit of time looking for Scipy/Numpy implementations instead of implementing it myself in a quick a dirty way... At the end of the day, it depends what your perspective is: understanding algorithmic or writing efficient numerical scripts. Mine is the later. Maybe I was too fast in suggesting you to use scipy.signal.medfilt, but from my perspective this is what makes more sense. 
I followed your recommendations anyway, and I fully agree with you. However, you don't code exactly with matplotlib or R or matlab like with other languages: there are an awfull lots of libraries, sometimes backed up by papers, and with very exacts know behaviours for a given domain of application. So matplotlib is at my opinion best used with first reading, understanding your problem, checking it has not been solved, and then writing a ridiculous set of one liners. Maplotlib have idiomatic way of programming very different from python. In fact it is the opposite of python where you have very few instructions but you can almost easily code whatever you need (caches, memoization, fixed format reader ...), and the performance penalty might no be very excessive for using a sub optimal implementation. In matplotlib you have a huge API available for specialized problems and instead of doing it your way, you'd better do it following the *one best way* that is available as a function. My experiment between a naive moving average implementation in oython vs matplotlib is a 10k factor in speed. I reitere the fact that it all boils down to one thing: the human factor. I was lazy, and a little bit presomptuous. 
Could someone do tl;dr; for PEP 380? 
Aand it's on ar… What? It's not on arch yet? Lazy bastards ;)
Instead of doing `for x in subiter: yield x` or similar, you can do `yield from subiter`. That makes it much easier to pass values back in using `send` and so on, which that loop doesn't handle, and so makes it much easier to break out parts of generators into different generators and so on.
can't wait though :)
EditorWindow? Do you mean the Python shell or do I write that specification in my program itself?
You create a file in ~/.idlerc called config-main.cfg. Then you put: [EditorWindow] font-size = 11 font = consolas ...in it and start IDLE. The font should now be bigger. I actually made it 14 instead of 11 because I am old and my eyes need a bigger font.
Do you mean this bug? http://bugs.python.org/issue15853
PEP 380 dramatically eases the implementation and use of generator-based tasks (or coroutines), and schedulers. It is a big step on the way toward removing the need for things like greenlets, and closing the conceptual gap between synchronous and asynchronous codebases.
Yup. It seems like the problem is on Tcl/Tk.
Definitely. My primary example is my own app, which is composed of C, PIL, Cython and a ton of libraries. PyPy is more or less a bonus. I think one major reason a lot of people aren't using PyPy is because they can't install, upgrade and uninstall it using their package manager of choice (probably, most likely, debian packages). The benefit of doing things the way I've developed is you don't have to use the version of python that is shipped with Ubuntu or Debian any more.
That's exactly how it works. In fact there's no trivial way to avoid this regardless of programming paradigm, without disabling swap xor mlock()ing the entire process address space (which you can't even do from Python AFAIK). Note even in multi-threaded Python, the GIL is most likely held when some other thread causes a fault, serializing the remainder of the process. The real answer is to avoid memory pressure in your production system, by preemptively modelling and simulating its load. If the OS pager is kicking in likely you have bigger problems
Thanks for your answer; I got a similar answer on IRC too. I completely agree with you about avoiding memory pressure in production hard to do, especially in complex systems. It's interesting to consider how page faults impact on performance in threaded servers vs single-threaded. It seems threaded servers would degrade gradually(probably not true, see note below) as increasing page faults are encountered in some of many threads. A single threaded server will serve nothing while waiting on a single page fault. On the other hand, threaded servers will use more memory and are therefore more likely to encounter page faults. Edit: I didn't pick up on you point about the GIL likely being held by the page-faulted and thus blocked thread. So, threaded servers aren't likely to cope any better than single threaded (unless you happened to be called out to a C module when you hit the page fault). Thanks 
If you can load the XML data client side, and use jquery to query it. Works like a charm. PS you can also watch this: http://stackoverflow.com/questions/5260261/lxml-parser-eats-all-memory 
Ask Dave Beazley…
WTF! No JIT? http://www.python.org/dev/peps/pep-3146/ . Gosh they gave ma boss another reason to brag about Java :(
What are the implications of PEP 405? Are there actually going to be any for devs who release python libraries and virtualenv-wrapped apps? Is virtualenv still going to be around but based on this or?
E-mailed. Thank you very much for the suggestion. 
Thanks for your reply. Indeed, the procedure is relatively simple. I specifically found the content of the setup.py file not to be straightforward. The documentation gives wide leeway on what you might want to include without giving concrete examples of when and why you would want or need to include all the options. So when I had something that worked through register and sdist... I still had no confidence that it was standard or right. Honestly, I haven't spent a lot of time on it because I put it off until I have more of my project done. But a standard path certainly didn't jump out at me on the first pass.
Uh... is Python the best language to do this in? Given the GIL?
You should make it so that anyone can answer questions, and if an interviewer likes what they see, they can contact the individual. :)
If you boss is going to brag about Java...not much you can do anyway.
Map/Reduce problems and Genetic Programming come to mind...
Cute toy.
Yeah, it can be a bit awkward. I tend to just copy &amp; past the [example from the docs](http://docs.python.org/distutils/setupscript.html) and and my specific metadata.
Paying $15/mo for something to hire for a position that should be minimum $35/$45k/yr starting sounds... uh... super reasonable to me. Fix the dark grey on black background though, that shit's retarded.
Well one confusing thing in general (mostly for Python noobs) is that Python can't and doesn't get any concurrency via use of threads due to the GIL. However, one can concurrently download data from 100 web sites, for example, all in different thread. I have done it myself and saw a great speedup over doing it serially. So the confusion is about the type of concurrency. You could talk about IO and CPU concurrency and how Python has good IO concurrency. Then you could talk about green threads, co-routine and libraries based on greenlet (eventlet or gevent) and how green threads are really superior to regular OS based threads for IO concurrency. They are much lighter so can have more of them, if you know what you are doing you don't have to put fine grained locks to protect shared data structures and they produce just as fast or faster results. EDIT: Clarification 
Fixed, thanks for the pointer.
Free means available to everyone. Employers can pay to get example problems that the free users never see. You don't want potential employees looking good by memorizing the test. $15/month sounds too cheap. Make it $30 per potential employee. Ask your customers how much you should charge.
I don't have any qualms about the price. But I think he needs to prove that his website will work first, then sell. A company isn't going to pay for software (especially a new one like this) unless they know it has value. The minimal way to prove that is by offering it for free. I might even think a "freemium" model might work here really well here. Offer basic features for free, and charge for additional features.
&gt; Most companies interview based on the preference of language of the interviewee, which may not be the favored language of the company. You make a really good point. Since it's unit test driven, those tests need to be written *before* the interview so you'd need to limit applicants to using specific languages (eg. what they'll be using on the job).
I thought this was a joke, then i read the comments and realized its horribly ugly bad joke. 
No hire. Next.
Yeah, it's not like hundreds of dependent packages have to be rebuilt ;)
For the lazy: "Python launcher for Windows". It will process `#!` lines and try to load the corresponding version of Python.
Pretty neat, but I have a couple of concerns: - It's matching images of buttons and icons to click on. That seems like it could be quite brittle if a theme changes, for example. And if I write a test on Ubuntu, for example, someone running Xubuntu probably wouldn't be able to run it. - To specify an offset when clicking on one of the images, he writes an entirely separate config file. Wouldn't it be simpler and more flexible to have an offset parameter for the `click()` method?
For the record, the implementation of the GIL changed in Python 3.2. I don't know all the details, but I understand that the new version is better in most situations. It's [mentioned in the What's New](http://docs.python.org/py3k/whatsnew/3.2.html#multi-threading).
get it, thanks.
Wow, that test framework looks awesome! I may end up using it! 
Do you really use IDLE and why? I tried it, and I found I can get by easier with a text editor and the terminal window. Not criticising, just want to understand.
BTW I am curious, what speed difference is your shop seeing between python and java?
It certainly seems that this is the case. It alleviates the creator to test their own test cases for specific environments and tasks. Even though there is a tolerance factor established in the INI; I don't think it is meant to be an enterprise style, universal write-once type of thing. 
Heh. Yep. I've definitely seen a few others that were similar, but I hadn't seen yours before, thanks for sharing – it definitely seems closest to what I was going for.
This is a good idea, i might look into making a free one: I believe we all benefit by increasing the number of ~~comptentent~~ competent developers. (EDIT: I need one for my typing).
Try what? Eclipse with pydev? or IDLE?
I meant Eclipse with pydev. I may be saying this because I haven't used IDLE that much. Currently, I'm using Eclipse for scala as well. Can't beat that with a text editor, especially if you're a beginner like me. However, if you're a pro with Emacs or Vim, you might not need Eclipse or IDLE. 
When you said bug with mac version UI, i assumed you were using IDLE i.e the default UI - becuae if it was a problem with 3rd party stuff like eclipse, you owuld have given the package name. So I asked why you were using idle. That is all.
I would pay money to obtain an ebook on the subject. 
That's interesting - on Ubuntu, all Python 3 packages (apart from the standard library) go in `/usr/lib/python3/dist-packages`.
Yeah. It's really hard to give a tutorial, even if you know the material cold.
I spent a while trying to create something unique, but I'm a developer, and not a great designer :) Bootstrap definitely cut out a lot of development time.
There is not enough abstraction; doing things on Graph API using your client is not very different from manual HTTP. There should be no reason that methods like get() or post() should be externally visible. Instead, have methods correspond to actual Graph API methods, like client.me.update_status('writing my blog post innit', privacy=facebewk.NO_FRIENDS_PRIVACY), for example (see [properties](http://docs.python.org/library/functions.html#property) and [\_\_getattr\_\_](http://docs.python.org/reference/datamodel.html#object.__getattr__). You started along this vein with client.like() -- keep going!
Please check out the new free plan if you get chance.
I would not use that model. I need a way to get real use out of it, and then pay when I intend to use it again. To get real use out of it, I need to be able to use it on 5 to 10 people. I like the suggestions that others have put forth for pricing models.
As someone looking for talent, building this right could be tricky. I need to be able to search for qualified candidates by a large number of criteria (location, language, experience level, other claimed technology familiarity) , and you need to establish your site as both trusted and full of many results before I will even bother searching. After we get that figured out, I need Documentation that I can give our HR team for why they should pay for the tool. 
Are the programming interviews frustrating, or the inadequacy between what is asked and what you really do? Computer industry runs on PHP because they want cheap developers that can solve any problem and that will agree with their boss for doing NP = P style BS. Still, your toy is cute. 
Eh me gerd facebewk
I might be misunderstanding you, but your comment doesn't match up with my understanding of the situation. I'd expect the memory overhead of each OS thread (or process if you want to use processes) to be significant if you want high levels of concurrency. AFAIK you can expect an OS thread to consume at least 1MB of memory. If you have 1,000 concurrent requests (and therefore 1,000 threads) that's pretty significant, especially compared to to the single-threaded/evented model where you basically have little more than the overhead of 1,000 file descriptors. 
Well, it depends on a few things. Different OSes have different thread implementations and I believe they are still more expensive on Linux than Windows, for example. (Whether this is the cause or the effect of people preferring process concurrency to thread concurrency on Linux, I couldn't say.) But there is certainly no intrinsic reason why each thread must take 1MB, as they only need to have a stack, a copy of the registers, and any thread-local storage (which is decided by the app). Some report a value [more like 15KB](http://stackoverflow.com/a/256706/28875) or [64KB](http://blogs.msdn.com/b/oldnewthing/archive/2005/07/29/444912.aspx). But what is most important is that you'd never do one request per thread anyway. You'd probably have something fairly similar to the event-based approach, but spread across multiple threads. Or maybe a producer/consumer arrangement. If this sounds like the worst of both worlds in terms of programmer time and complexity, you'd be right! But in terms of performance it is probably optimal on modern computers since a quad-core machine can have 4 CPUs handling requests simultaneously at a lower memory cost than if you used 4 processes to do it. I am talking about the C level however - if you trust to Python's implementation then who knows how efficiently it would implement things. But in that case the GIL is going to cripple your multithreaded performance long before anything else does anyway, and most of this discussion becomes pointless. And when you're using a lower level language it's easier to preallocate memory and throttle throughput before you run the risk of asking for memory that's been paged out.
Add a Go-style concurrency pool and communication channels. 
Awesome work ! As someone that uses [facepy](https://github.com/jgorset/facepy) why would I switch to facebewk ?
For someone with little (no) insight in the facebook api, how do I get say all the friends of my friends? If c is my client then friend_id = c.get("me/friends")["data"][0]["id"] would give me the id of my 0th friend. I figured that I could just do my_friends_friends = c.get(friend_id + "/friends")["data"] but it just says "Unsupported operation".
Excellent! Thanks for sharing!
Do you care if the function is continuous? It seems unlikely you would be able to guarantee two points in R^n that are close would be close in R^m for all pairs of points in R^n. You could probably use something like SVD to find the most significant dimensions. What about locality sensitive hashing? 
I believe [this is a bug](https://developers.facebook.com/bugs/356511554434996?browse=search_5062f8b383de78738162580 )
Ah. Just realised there's lots of info at http://tendenci.com/ I only figured that out after reading the comment above that mentioned there was a hosted option too.
Hey have you considered using [pyglet](http://www.pyglet.org/) instead of pygame? The latest alpha has Py3K support it seems, I've only used the stable release with 2.7 32-bit myself.
Try writing fib with yield, and eventually print list(fib(..)). You might find it interesting. For the guessing game - you can increase the guesses at the start of the loop (since u always do it). Also look into while..else
I am certified to teach ELA in new york but i'd love to teach my middle schoolers programming. Would be neat just to see what a programming class looks like. 
Just adding to what kylotan said, note that thread stacks live in virtual memory and can be tiny - 4kb or less. Unless the stack grows, no real memory will be committed to it (and if it grows, it'll be committed 4kb at a time). As for kernel-side structures, I have no idea. A quick test on 32 bit Linux suggests around 14kb goes missing for each Python thread - which includes the stack.
No, nothing really. Although we do have a number of built in apps like users, memberships, groups, payments, events, etc. Things that organizations use a lot.
We're working on it. The launch is pretty new and we're hoping to build a developer community. Thanks for installing the software! Try downloading some of the "tendenci_themes" and poke around the HTML.
I work for the company that develops Tendenci with Zybergod, and I want to add some background on the project and answer some of the questions asked here. I want to first clarify that the website page at http://tendenci.github.com/tendenci (where http://tendenci.org redirects) is a brand new page and our marketing team only just created it and has not finished updating the content and graphics. We are still in testing/beta mode for the open source version 5.1 that is available. We released Tendenci open source in April of this year, and we continue to make additional improvements so that developers can more easily download and work on this open source Python/Django project. We wanted to get the new code out there on github and make it available and start hearing what we could do better for the developer community first, and then work on the brand and messaging behind it. To respond to spinwizard69: I think that http://schipul.com and http://tendenci.com do a much better job of demonstrating our ability as a company to make websites, and our clients' sites do an even better job. We are going to keep updating the new github site and add all of the items that we know you want to see. I value your feedback, and I'd like to find out what we could possibly do to change your opinion and have you take another look at Tendenci? To respond to andybak: Glad you found our main website - I also can setup time to walk you through installing Tendenci locally or provide access to a demo site that you can play around with. Please feel free to contact me at sworthy at tendenci dot com and let me know how I can help. To gadsdengraphics: Our SaaS offering is for those who would like to use our managed hosting services and platform instead of setting up your own. Most of our market who selects the SaaS version are the end users/nonprofit organizations themselves or agencies who find it easier to deploy using our environment already setup. The open source version is very new, as I mentioned, and the big differences between Tendenci and the big open source CMS options are: 1) Tendenci is Python/Django, not PHP (like WordPress and Drupal) and 2) Tendenci includes many of the complex, transaction-based functionalities that most open source CMS' don't include in their core. These include: *event registrations and payments, * membership applications, renewals, and dues, * online donations, * jobs board and business directory listings. Tendenci was developed to meet the unique needs of nonprofits (although many service-oriented businesses and social enterprises also find Tendenci to be a good solution). Because these are all part of the CMS and not outside plugins - you can more easily manage your website. Tendenci also makes use of Django's architecture for supporting Python addon apps, so you can also have additional plugins/addons like with other open source CMS platforms. We aren't perfect and have a long road ahead of us before Tendenci is at a stage that gives the open source community everything they want. We hope you'll keep talking to us, and give us a chance to show you why Tendenci is a great option to consider. 
you should never use input("Something") if you want integer values use x = int(raw_input("Something")) otherwise someone can literally format your computer from the input statement
I open source it on github. Any suggestions are appreciated. 
Debian has a distro-specific layout that puts Debian packages in dist-packages. site-packages is left for users who are using setup.py. That gets inherited by Ubuntu.
Sounds great! And I've tried looking up differences between 2 and 3, and can't say I've found a solid answer though.
The different models of concurrency and how they can be used within Python along with the benefits that each provides could be be interesting even outside the realm of Python (whilst being accessible to anyone who knows Python, which is most people these days).
What product, specifically, are you looking to trade? Your range of options is going to heavily depend on that answer. Also, are you working with a clearing firm or are you trying to find a retail platform that will allow API access to enter your bids and offers?
If you're investiagting concurrency, then you **MUST** look at the [software transactional memory project at PyPy](http://morepypy.blogspot.com/2012/01/transactional-memory-ii.html), that is their current strategy for removing the GIL and improving parallelism in Python. It's a very exciting project. Armin Rigo (the guy working on the project) recently posted a [status update](http://mail.python.org/pipermail/pypy-dev/2012-September/010513.html) with a [draft spec](https://bitbucket.org/pypy/extradoc/raw/extradoc/talk/stm2012/stmimpl.rst). Definitely worth reading. [There are also other people interested in doing this for research too](http://mail.python.org/pipermail/pypy-dev/2012-September/010564.html). https://bitbucket.org/pypy/pypy/src/default/pypy/doc/project-ideas.rst#stm-software-transactional-memory
Ahh! In conf/settings.py for anyone watching Cheers
Yeah there are some differences, you'll see but I actually like them.
Fellow python newbie here, been fiddling around with programs and the language for a few weeks now off and on. I recommend [Thenewboston](http://www.google.ie/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;ved=0CB4QtwIwAA&amp;url=http%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D4Mf0h3HphEA&amp;ei=pOVpUKmCI4iyhAfvp4CYDQ&amp;usg=AFQjCNFxhMle0aXPUFoY1wvoMAVJc2IhgQ) on youtube. His python tutorials are fairly easy to understand and will give you a good grasp of the language and some finer points. You can probably skip the first 10 or so videos, if you understand enough of the language. Keep learning! :D
I've got another stupid question: How can I change the locale of the application? I.e. I'm in the UK and our volunteers will be dealing in £'s :) PS Looks great btw.
&gt; I'm assuming you don't have dealing access to the exchange Right, I'm just a consumer that does not want to manually work a GUI. 
Thenewboston is actually how I started! I love his tutorials, very easy to follow. 
From Codecadamy's [Twitter](https://twitter.com/Codecademy/status/252842734971400193). They are aware of the problem and are fixing it.
Theoretically, in my experience it doesn't work at all, but I was trying to bundle LXML &amp; PyQT with the executable.
Why the hell 2 people downvoted this comment is beyond me. Too many "great designers" reading this subreddit? I'm an average coder/developer/architect/whatever. I'm much better critic of what looks good and bad. But I couldn't design something half good looking, even if my life depended on that. Knowing what you're good at, and at what thing you do really suck is an extremely valuable trait. At least for me, YMMV.
You can get the database dump as XML here: http://dumps.wikimedia.org/specieswiki/20120916/ This most useful one is probably "All pages, current versions only".
I know quite a few people who do use PyPy in production. Obviously it's expected from me to know such people, so I'm not quite shocked that noone you met at the EP uses it.
The easiest way would be to download the [database dumps](http://dumps.wikimedia.org/specieswiki/20120926/) which make it trivial to get a list of pages. Now, you'll want to restrict it to pages in the Article namespace, probably &gt;2048 bytes in content length or something. You'll then want to make sure that page has entries in image_links. You could probably make a list with a not-too-complex query. You could also use the [mediawiki api](http://www.mediawiki.org/wiki/API:Main_page) to get a list of random pages and if any of them have images on them. Like http://species.wikimedia.org/w/api.php?action=query&amp;generator=random&amp;grnlimit=10&amp;grnnamespace=0&amp;prop=images (up to 20 if you have a botflagged account) and have it try again if none of them have images. Depending on how many people are going to be hitting it they might not like that though. edit: I was planning on just running a few queries to give you a list of them, but I forgot how slow mysql is when I'm not using my normal db import scripts and i'm too lazy to rewrite them. It should be a pretty easy query to run once it is actually loaded, but you might be better off asking someone with a [toolserver account to run it.](https://wiki.toolserver.org/view/Query_service) edit2: [first attempt](http://pastebin.com/raw.php?i=HdFcwTnv) select p.page_title, count(il.il_to), group_concat(il.il_to) from page as p inner join imagelinks as il on p.page_id = il.il_from where p.page_len &gt; 1024 and p.page_namespace = 0 group by p.page_id having count(il.il_to) &gt; 1 into outfile '/tmp/out.txt'; Too many random logo images. I'll try to clean it up a bit edit3: [got rid of most of the random images](http://pastebin.ca/raw/2238298) select p.page_title, count(il.il_to), group_concat(il.il_to) from page as p inner join imagelinks as il on p.page_id = il.il_from where p.page_len &gt; 1024 and p.page_namespace = 0 and il.il_to not regexp '^Wik.*logo.*\.(png|svg)$' and il.il_to not in ('Commons-logo.svg', 'Disambig.svg', 'Nuvola_apps_important.svg', 'PhytoKeys_Logo.svg','Spinosaurus_skull_en.svg') group by p.page_id having count(il.il_to) &gt; 0 into outfile '/tmp/out5.txt'; There are still a few other random images that should probably be excluded like Other_languages_icon.svg,WiktionaryPl_nodesc.svg,X-office-presentation.svg, Wiktionary_Ko_without_text.svg, WikiSpecies.svg but i'm playing whack-a-mole at this point and i didn't see any that would be excluded filtering those at a quick look.
All pages, current versions would get you an XML file with all of the wikitext of every article. Sure, it would work but finding out if a page actually have an image on it isn't as easy as looking for \\[\\[:?(File|Image):[\^\\]]+\\]\\] with all of the ways that images can be included and even more confusing with templates (though a quick look at wikispecies seems that they avoid a lot of the insane templates people use on enwp).
I see impressive pieces of solution, I can't guess what is the problem it solves. A solution solving an unclear problem is pretty pointless to me. 
Have you tried [these](http://www.lfd.uci.edu/~gohlke/pythonlibs/#pyopencl) binaries?
http://search.dilbert.com/comic/Random%209
This is awesome. So unfortunate that password autofill doesn't work with browserid yet.
Of course it won't work, python files will work, but the compiled pyo and pyd files are for the computer/ os they were built on. Both lxml and pyqt have c extensions that need to be compiled for each platform you want to distribute too
The project that's got me asking this is going to be a standalone application. Ideally, users won't have to install anything separately to run this. Everything I've come across seems to suggest that there is no way to cross-compile python code into a standalone binary without cross-compiling python and any relevant extensions as well. Everything I've come across is also Q&amp;A format -no documentation, tutorials, etc.- so I still lack a definitive answer here.
Actually, this is the simplest and easiest solution! I am also able to narrow it down by adding "animal" or whatever - Thank you so much!
Just for clarification, you mean that you need to build for the target platform on the target platform, right? * Build on a windows installation for .msi/.exe * Build on a linux installation for a linux binary * Build on a mac for .dmg/.app
Yes, and you need to use those different tools to do so.
cx_freeze is a cross platform utility. =)
Fine, but only because this ended up in my feed and I have exactly 5 minutes. You can't read the text outside of fullscreen. Use a big clear font. Most of the screen is white background too. Shrink the window and only capture the window if possible; we don't need to see your desktop or taskbar. Did the end of #2 get cut off? Anyway I would say don't even mention carets but do talk about floats and doing math with floats and ints together. Show them .1 + .2 != .3 and why. When you talk about intro math in python you should end up being comfortable enough to use it as a calculator. Good luck.
I am aware, and I highly recommend not wasting your time with it.
Want a great python IDE? * [PyCharm](http://www.jetbrains.com/pycharm/) Want a good &amp; free IDE? * [PyDev](http://pydev.org) * [Eclipse](http://www.eclipse.org/) Prefer VIM? * [Vim as your IDE](http://haridas.in/vim-as-your-ide.html) * [Turning Vim into a modern Python IDE](http://sontek.net/blog/detail/turning-vim-into-a-modern-python-ide) * [Janus - a VIM distro](https://github.com/carlhuda/janus) Env / tools * pip * virtualenv (+ virtualenvwrappers on Debian/Ubuntu) Deployment * [fabric](http://docs.fabfile.org/en/1.4.3/index.html) * [nginx](http://nginx.org/) * [uwsgi](http://projects.unbit.it/uwsgi/)
Why not pyinstaller for windows, btw? I've used both successfully for windows but have moved to pyinstaller since things like icon embedding are kinda broken in py2exe and that's never going to be fixed.
Most Linux distributions have a package manager and their own package sources (e.g. apt for Debian and Ubuntu). But you should install only `python` and `virtualenv` from these sources. Though other third party modules get packaged for various Linux distributions, I don't recommend to use these, because modules get updates and patches faster than a distribution may update their packages. Instead you should create a new virtualenv for every project you are working on. Then use `pip` to install modules. That way you are really flexible concerning versions of a certain module; you can even install directly from git repositories. Besides that: I use [Sublime Text 2](http://www.sublimetext.com/2) (because of its awesome word completion), [virtualenvwrapper](http://virtualenvwrapper.readthedocs.org/en/latest/index.html) (to manage my virtualenvs) and [bpython](http://bpython-interpreter.org/) (to sketch and try things). And a good shell can save you some time too (for me it's zsh + [oh-my-zsh](https://github.com/robbyrussell/oh-my-zsh)) ***Disclaimer*** I'm neither a professional developer nor a python expert.
IPython 0.13 should support 3.x and there seems to be ebuild for that.
This depends a lot on what you're doing. A lot of modules are very difficult to install with `pip`, especially if they need compiled parts, like numpy or pyqt. Have a look for PPAs or other repos if you need newer versions. Distro packages may be a bit older, but apt packaging is a rolls royce next to the rusty bicycle of distutils/setuptools packaging.
Eclipse is very resource heavy FYI.
Another option for material: http://ProgramArcadeGames.com
You could also use emacs: https://github.com/gabrielelanaro/emacs-for-python
From your distro's repositories get. I use ubuntu so I'm adding the package name between parens but most distro should have something similar: - GCC compiler and related tools. (build-essentials). - Python source headers (python-dev). - setup tools and some helpers (python-setuptools python-virtualenv python-pip ipython virtualenvwrapper) Setup virtualenvwrapper in case the package didn't do it for you (http://www.doughellmann.com/projects/virtualenvwrapper/) Create virtualenvs for every project, really, working on venvs is so easy it doesn't make sense not to. Also, linux relies heavily on python so messing with your distro's packages can make for a great mess: $ mkvirtualenv new_proj .... (my_proj)$ and use pip for managing python packages (my_proj)$ pip install some cool package Everything else is optional, I've grow loving sublime_text after being a gedit refugee, gedit is a great text editor, any IDE always felt clunky and heavy, but latest versions of eclipse with pydev worked great YMMV. 
I also suggest installing ipython. It has some super handy features for quickly prototyping and finding out any documentation. [tdfischer@pluto ~]$ ipython Python 2.7.3 (default, Apr 30 2012, 21:18:11) Type "copyright", "credits" or "license" for more information. IPython 0.12 -- An enhanced Interactive Python. ? -&gt; Introduction and overview of IPython's features. %quickref -&gt; Quick reference. help -&gt; Python's own help system. object? -&gt; Details about 'object', use 'object??' for extra details. In [1]: import osc.core In [2]: osc.core.branch_pkg? Type: function Base Class: &lt;type 'function'&gt; String Form:&lt;function branch_pkg at 0x1e5a848&gt; Namespace: Interactive File: /usr/lib/python2.7/site-packages/osc/core.py Definition: osc.core.branch_pkg(apiurl, src_project, src_package, nodevelproject=False, rev=None, target_project=None, target_package=None, return_existing=False, msg='', force=False, noaccess=False) Docstring: Branch a package (via API call)
I recommend a simple terminal, and Sublime Text 2: http://www.sublimetext.com/ Do you really need anything more?
You didn't mention the Linux distro you're on, and what's your skill level but here's what I do for a fresh Debian stable netinstall image: 1. configure your users, sudoers, ssh, firewall, locales 2. edit your /etc/apt/sources.list to include the "testing" repository (for python2.7) 3. add /etc/apt/preferences file so that you have control over what comes from "testing" 4. update your package lists and install build essentials 5. install python2.7 from testing (Python 2.7.3rc2) 6. install setuptools 7. install pip using: sudo curl http://python-distribute.org/distribute_setup.py | python2.7 8. decide your virtualenv directory and create it curl -O https://raw.github.com/pypa/virtualenv/master/virtualenv.py $ python2.7 virtualenv.py my_new_env $ . my_new_env/bin/activate 9. install ipython, fabric, whatever via pip when virtualenv is activated so rule of thumb: install virtualenv first, then install your packages with pip while it's activated.
&gt; A lot of modules are very difficult to install with pip, especially if they need compiled parts, like numpy or pyqt. I wouldn't say there are a lot of those modules. I'd say these are exceptions. But indeed I forgot to mention these and how I handle them: I install them via package manager.
It will definitely need to be somewhat locked down (although maybe not as much as you'd think). Granted, this isn't for huge enterprise level testing, but for some cases, it's perfect. What do you mean by GUI's worth testing? 
If you want to automate a GUI and there's no API for the application you can use AutoHotKey. If you're set on using Python then there's the PyWin32 module for Windows and the various Xlibs for Linux which give you access to mouseclicks and keyboard strokes.
I am a big fan of O'Reilly books, personally. IMO the best way to learn a new language is to use it to solve a practical problem that you're currently having. 
Personally, I will immediately block all inbound traffic.(Maybe with the exception of SSH) Then allow all outbound traffic. Then I just add inbound rules as needed, and block out traffic as I become paranoid.
Here's my approach. Make sure your distro has the latest versions of Python: 2.7 and 3.3. If not, you can grab them from the python website and install them fairly easily. Next, you need virtualenv, which is how you will manage python modules for different projects. I have a folder at `~/env` that holds all of my python virtual environments for different projects. Create new envs like `virtualenv ~/env/project_name`, active with `source ~/env/project_name/bin/activate`, then deactivate them with `deactivate`. Lots of people use `virtualenvwrapper`, but raw envs work fine for me so I never bothered. The most popular python IDE is probably PyCharm, but I prefer to use a text editor, namely [Sublime Text](http://www.sublimetext.com/). If you try Sublime Text, make sure you install [Package Manager](http://wbond.net/sublime_packages/package_control); the plugin ecosystem is one of Sublime's greatest strengths. Now it's time to start installing python libraries that can be very helpful. Once you have activated a virtualenv, most packages can be installed using `pip install packagename`. A few still require easy_install (`easy_install packagename`), but always try `pip` first. I almost never have to resort to distro packages anymore: they are usually out of date and don't always play nice with virtualenv. Some packages do require a C compiler, which is available from your system repositories; `apt-get install build-essential` on my system. As far as libraries, [Requests](http://docs.python-requests.org/en/latest/) is great for working with HTTP, [IPython](http://ipython.org/) provides an awesome interactive python shell with a bazillion nice features, and [docopt](http://docopt.org/) is a useful tool for easily creating consistent command line interfaces. I am also partial to [pyyaml](http://pyyaml.org/) (data serialization/config files), [Flask](http://flask.pocoo.org/) (Web microframework), [nose](https://nose.readthedocs.org/en/latest/) (simple test runner) with [pinocchio](http://pypi.python.org/pypi/pinocchio/0.3.1) (human readable test names) and [SQLAlchemy](http://sqlalchemy.readthedocs.org/en/rel_0_7/index.html) (DB abstraction). Then get to work and have fun with Python! 
That's enough for most needs and Sublime Text 2 is just awesome but like someone mentioned, pip and virtualenv are nice additions too.
fabric as described there seems more of a deployment tool than a build tool. When I think build tool I think * clone repo/head of given branch * get dependencies(pip/easy_install_buildout/npm/maven etc...) * compile(and/or run unittests) basically what you would have jenkins do. granted fabric seems like it can do all those things based on the article if they can be expressed on the cmd line. One hole I see missing is dependency version tracking. which is essential for having reproducible/reliable builds. In pythons case we use buildout's versions feature . (http://grok.zope.org/releaseinfo/readme.html) if you can't have repeatable builds, you don't have a very good build system. 
Sublime Text 2 with the SublimeLinter package (which has PEP 8 style guideline syntax checking). EDIT: spelling
yum install python yum install vim
Stallman does not approve 
I used Fabric at an internet ad company with a fairly sizeable Python codebase -- Fabric was primarily used as a deploy tool rather than in a build capacity by my recollection and as I recall Fabric was _anything_ but hassle-free. Poor documentation (as I remember) was a primary source of concern, however this "requirement" is obviated for the most enlightened among us who simply become acquainted with the source.
What are good solutions for this ? 
Hmm, Fabric's docs seem pretty well fleshed out now, and I haven't had any big issues with it. On the contrary, I picked up most of the tricks of the trade from reading other people's fabfiles. Here's a trick I use: search for `fabfile.py` on GitHub. :-)
&gt; A build tool in my book is anything that helps you create a repeatable build. ok sure, but there are tools better geared towards that goal. Fabric to me seems to be more general purpose glue than a build tool. But with enough glue you can build anything I suppose. I prefer using parts better geared for the purpose. but fabric does have it's place. 
&gt; But with enough glue you can build anything I suppose. And for those rare cases where glue doesn't help, you reach for your duct tape or WD-40. :D I'm thinking that it's easy to get away with Fabric for buildish things since Python doesn't have an explicit compile step and dependencies are already managed for you by pip/virtualenv. That leaves out cloning repos and running tests, but those are really one-liners.
You don't have to pay. So Stallman don't need to approve anything, yet.
ipython, vim, tmux, git. /thread
No. PyInstaller used to do this, but they removed support due to too much hackery.
I don't think so - readline is GPL, so Python can't ship it in a permissively licensed distribution.
This is from an article that explains [for ... else in Python](http://psung.blogspot.com/2007/12/for-else-in-python.html): &gt; Python has an interesting for statement (reference) which lets you specify an else suite. &gt; &gt; In a construct like this one: &gt; &gt; for i in foo: &gt; if bar(i): &gt; break &gt; else: &gt; baz() &gt; &gt; the else suite is executed after the for, but only if the for terminates normally (not by a break). Personally I find that incredibly unintuitive. The else only gets executed from a break in the for? Aside from being totally unclear, that's more like try-except than if-else. In this example it's compounded by the problem that it looks like an indentation problem because it comes right after if bar(i). I'm going to stay away from this "feature".
This something along the lines of what I'd go with (Arch edition) chsh -s /bin/zsh zsh mkdir /tmp/build;cd /tmp/build curl -O https://aur.archlinux.org/packages/co/cower-git/PKGBUILD makepkg -s sudo pacman -U cower*.pkg* curl -O https://aur.archlinux.org/packages/pa/pacaur/PKGBUILD -O makepkg -s sudo pacman -U pacaur*.pkg* pacaur -y sublime-text-dev sudo pacman -S python2-virtualenv python-virtualenv python2-virtualenvwrapper git cat &lt;&lt;EOF &gt;&gt; ~/.zshrc export WORKON_HOME=~/.virtualenvs export VENVW_SCRIPT=/usr/bin/virtualenvwrapper_lazy.sh [[ -f "$VENVW_SCRIPT" ]] &amp;&amp; source $VENVW_SCRIPT EOF source ~/.zshrc mkvirtualenv -p python2.7 some_project pip install ipython pip install ipdb mkdir ~/dev/some_project cd ~/dev/some_project setvirtualenvproject touch .gitignore Also I'd probably setup: * Vim + Vundle + Powerline for nice vim usage. * Sublime Package Control * Dogs ColourScheme * svn for old school irritating repos * PostgreSQL * SSH aliases in ~/.ssh/config * ZSH syntax highlighting * OpenVPN to my Linode For desktop: * i3wm, an .xinitrc * urxvtd * some nice fonts? * nitrogen for changing wallpapers * compton if I wasn't using i3wm. I didn't like oh-my-zsh as anything useful (e.g. git plugin) seemed to slow my terminal down.
What advantage does moving SSH to a high port bring if you have key based auth only?
Or, tiling WM.
I still don't think this is the best advice. All of the libraries you mentioned can be installed with `pip` once you grab the necessary dependencies. It's a little more work and a little slower, but not enough to outweigh the advantages. It took me about 15 minutes to figure out what dependencies SciPy needed, then maybe 5 minutes more to build it from source. And I'm just a normal developer. The ubuntu precise packages are at version 0.9, which is over a year and a half out of date. That in and of itself is reason to deal with the small hassle of using `pip` plus all the usual advantages of isolated environments, like having different projects depend on different versions. Last time I checked, `pip` still has some bugs with cython, but for everything else going through the work of installing everything in virtualenvs will pay off in the future. 
You are correct. 
Might [bpython](http://pypi.python.org/pypi/bpython) help?
Thank you &lt;3
Are you asking about Python's PS1 or Bash's PS1?
Why would you use /g? There's only one instance of 'git' here.
In a pinch? try rlwrap: wraps readline around the stdin, stdout of any program.
It doesn't work *because* they're all floats. You can do math with ints and floats mixed and you'll get an answer. You can always rely on ints to be exactly what you expect. But you can never rely on floating point numbers to be the exact value they should be. The problem is computers can't store repeating decimal numbers in binary, so they use the closest value they can. That means the exact value of a floating point can change depending on how it was calculated. For example: &gt;&gt;&gt; .1 + .2 0.30000000000000004 &gt;&gt;&gt; .3 - .1 0.19999999999999998 &gt;&gt;&gt; 0.19999999999999999 0.19999999999999998 Note the last one. It just can't record 0.1 and 16 9's in a 64 bit float. This isn't a Python problem. Every language with floats has this. Javascript doesn't even have integers, which makes it a mistake to try to use it for any math where you care about accuracy. Floats are still useful, just never try to compare floats with == or !=.
**For beginners:** Use the version of Python provided by your distro as well as the distro's virtualenv package. Create a virtualenv for every project you work on and only pip install Python packages into it (never globally with sudo). Feel free to even have a general purpose virtualenv that you use most of the time. It can get a bit messy, but it's easier to begin with than hopping between numerous virtualenvs just to make and test little changes. *One final edit for beginners:* If you can't get a package installed via pip (like PIL, psycopg2, etc), feel free to try to use your distro's packages. It's a habit you'll want to break someday, but in general the hardest to install packages are the ones that change the least and can therefore be safely installed using potentially months-old distro packages. **More advanced/time-consuming:** I've begun using ~/local/python-&lt;version&gt; with *versioned* symlinks in ~/bin for my main development machine. I put all source code in ~/src, so to get setup I do: mkdir ~/{bin,src,local}; cd ~/src curl http://python.org/ftp/python/2.7.3/Python-2.7.3.tar.bz2 | tar xj cd Python-2.7.3 ./configure --prefix=$HOME/local/python-2.7.3 &amp;&amp; make # Pay attention to the output of make; you may need to install dependencies for some modules to build make install cd ~/bin; ln -s ~/local/python-2.7.3/bin/python python27 Repeat for multiple versions of CPython. I treat PyPy similarly but use its binary distribution as building PyPy is... ...daunting. Common infrastructure &amp; tool packages like ipython, ipdb, flake8, virtualenv, and pip I install into the "global" (really ~/local/python-&lt;version&gt;/.../site-packages/) Python and then use virtualenvs for individual project dependencies. It's a bit tedious but I manually symlink the scripts I want in my $PATH into ~/bin with a version (eg pip27 or virtualenv26). However for professional Python developers or open source library maintainers who need to test against multiple versions of Python, I find this setup extremely valuable. I find myself hopping into ~/src/Python-.../Lib a lot when I really need to know the internal implementation details of the stdlib. 
Are you asking for something where you can paste arbitrary python and click *run* to see some output? Or something more? Giving an English teacher computer code sounds risky. Even if it is awesome I wouldn't expect them to understand it.
Testing - nose - mock (unless you're running Python 3.3+) 
Question, not sure if exactly relevant: If I just want a fairly simple tool that will take whatever changes I've made to some source code locally, and immediately + automatically upload those changes to my VPS without any prompting, what would be a good tool to use? Something like Dropbox with auto-syncing. I could actually just use Dropbox maybe, though I'm not sure if it has a CLI-only interface.
Maybe the fact that its so easily interpreted backwards lends to the unintuitiveness? ... My initial assumption was the same as yours.
That would be pretty foolish/difficult today.
Im not sure what youre trying to do here... The mako template language can be used to generate html pages and allowes you to code in python. Pyjs allows you to compile/translate python into javascript so u can run python in a browser. You can run code snippets right in the page for a demo for example. If you want to simply display code in html use &lt;pre&gt; tags. If you want a dynamic website written in python - there are a ton of web frameworks out - flask is an easy one to get started. If you elaborate maybe I can help you more specifically.
I actually discovered this feature by accidentally writing it up in a daze and noticing the code ran correctly. I think it's extremely intuitive. Just my opinion, of course.
Sorry, my bad. Python 3 has a `print` function rather than a `print` statement and so parentheses are required.
This is what I assumed *for else* would do until I read the doc. I'd like that feature as well. *for else finally* ?
[Crunchy](https://code.google.com/p/crunchy/) allows you to run interactive Python sessions in a web browser (but requires that the host machine have Python installed). It's hard to know what will work best for you because your question isn't very specific about how you want the web page to function, though.
&gt; For example, I wrote an autobiography in python for an English project Wat. No seriously, I want to hear more about this.
well, not the OP, but I did my senior project thingy in python. Instead of using PowerPoint I used pygame and Mplayer (or was it vlc by that point?...) with python as the glue for stuff. That code was horrible and was my first time making such a "large" programming project. I hope that the code never sees the light of day again... I keep it as a reminder of how much I have learned.
I evaluated GUI testing for a legacy C++ QT3 application. We looked at automated testing from the GUI down because of how tightly coupled the application logic was to the GUI. If we wanted to go the unit testing route the devs would have to completely gut and re-architect the application, not an immediate solution. Most of the application was also quite complex to use, lots of custom controls and funny productivity shortcuts. Image recognition just wasn't diverse enough to handle these controls, let alone scrolling through long list boxes, tables and navigating treeviews efficiently. An image base solution just wouldn't scale to that. Whereas a less complex modern GUI can: A. Be walked through in a matter of hours by a QA guy; B. Built so there is no logic at all in the GUI and tested efficiently using unit, integration and system tests effectively enough and to not have to invest in a complex automation suite. 
* Modify the code * File a bug
haha, I was confused.
I think they made some sort of presentation by designing each slide by hand and using python to step through them. God knows why.
Have you installed the command-line tools? There is another way to specify the tools from within the Xcode app but it requires using xcode-select? (I'm not sure how to do that.) But if you install the command line tools I know things have worked better for me. Also, you can use homebrew to install readline and it won't hurt OS X version of readline. It has helped me install other programming language packages that rely on it and you don't have to rely on those languages implementations of readline to get around the fact that OS X uses a different version or kind of readline.
Python.
I installed the command-line tools in Xcode, but I hadn't thought to try homebrew. That might fix it.
Good lord, yes. I know I'm a day late (and a dollar short) but *this* is the way to install python packages on windows. OP: you should try these and report back if that worked.
&gt; I wrote an autobiography in python for an English project Why? Why complicate things when a text editor would do the job just fine? 
Great work. Thanks.
That's putting it politely.
Why does it need return types? Can't they be infered?
That page just taught me how to do some things I could not do previously by making a temporary copy of the list with a slice! I can now remove things from a list while iterating it instead of making a list of removals to be removed through a separate iteration! I know this is basic, but dammit this feels good!
Lol, you're right. Oops.
why not 'typy' or something? 'mypy' is both a bad name and not indicative of the intention.
It would be nice if it used Python's existing annotation syntax instead of having an incompatible syntax.
I've known about this construct for about a decade and have used it approximately once and probably deleted the code that used it.
I think they link against libedit on OSX (the system installed library) in the python.org binary (rather than gnu readline)
same here. pyinstaller works just fine on windows. i'd much rather have 1 program to make all my exe's for.
well the base reason was that power point and open office did not play together well and so I said "fuck it, I know pygame kinda. Lets use that for showing my slides and rendering the fancy animation things". And yea, it was that I used python and pygame to "step" through the slides, although it was more that I had click areas that could take you to certain classes of stuff (so a tab for my english, tab for math and so on) each with their own list of slides to cycle through as I talked. I liked the last set (the "what is impressive to you about your experience with the senior project?") I had the code printing out its own source and scrolling through it as it was running those sections of code.
no
&gt; You really should install these using the distro's package manager. I used to. But the number of ways Debian can fuck up Python packages convinced me to always, always use language-level package management where possible. I suppose it's low risk with things like virtualenv, and maybe pip – I don't generally care if my versions are five or ten years old for those particular tools – but I've just had enough of it to not bother. I like them global because they should always be available. There's absolutely no benefit to jailing pip and virutualenv for my use only. The only problem I could foresee would be where some other Debian package requires a conflicting Debian-installed Python package as a dependency. However I think this is extremely low risk for pip/virtualenv: They're package management tools, and from what I know about the Debian people, they'd *never* mix and match with another package management system. 
[http://www.quickmeme.com/meme/3529a9/](http://www.quickmeme.com/meme/3529a9/)
Netscape actually asked Guido to develop a scripting language for Netscape before they turned to Brendon Eich and he turned them down. But no. If you know anything about the politics of browser development and standards bodies then you'll be able to name a zillion reasons this isn't ever going to happen. Thank god for CoffeeScript for at least got us some of the way towards making us feeling at home.
You know, I've gone off to fact-check my first statement and I can't find anything to back it up yet I distinctly remember reading it. Can anyone else find anything to support this?
That's a good point, but I bet that a check for empty list is more usual than a break check.
Oh, interactive! You didn't mention that so I thought it was only text. Could you share more info about it, or the code? Did you try making it an executable with something like py2exe?
Then just copy your text into a website, seriously… ;)
it can be pretty arcane. I'm glad I learned vi 30 years ago, though I never got around to learning emacs.
Looks like magic in bound methods... if I find something of interest, I'll let you know.
In Python 3, the only difference is that `REFS.keys()` returns a generator rather than a list and that the one object left after GC'ing is `a4` rather than `a1`.
You could maybe test using the __del__() function to verify things are being destroyed.
Something like that. Basically methods can't be used in weakdict/weaksets because functions are descriptors that return a newly bound function every time. That means you're not actually adding the function in the weakdict but you're adding the bound method instance that no one has reference to (and thus, it will get dropped from the dict).
The issue with this is that because there's reference cycles involved, \_\_del__() will modify the GC's behaviour, such that it will not delete the objects and the cycle will simply be placed in gc.garbage to be broken manually.
(to replace git with hg everywhere forever. hg is written in python too!)
*So it's slower?* \*giggity\*
Programming language names generally aren't descriptive (Python, what?). But sure, mypy might not be the best of names. Typy has been suggested a lot; I'll think about it.
Yeah, that was basically what I was getting at -- whether python's cycle detection was just conservative or what. I understood the implicit reference to ``self``, but I guess I figured that since I was just tacking on another attribute to the instance it would be no different than any other instance method. I also wonder what makes pythons gc kick in, as I thought it might after exiting the scope of the function in my example -- but instead it required manually calling ``collect``.
Stallman considers the API copyrightable (something that a court disagrees with since the Google vs Oracle case) so the whole libreadline GPL dependency might now be questioned. linking aginst libedit technically still considered a GPL violation according to Stallman.
No, I showed him the code, and then the output. He used to do some coding when we was a kid, on a commadore 64 I believe. And I suppose so, yes.
thanks, but i don’t understand why you think it’s not expressive enough: because one has to add a colon? scala is one of the most expressive languages that exist and has the colon-syntax.
The real problem is, that you are leaving your cursor open after all. There is no guarantee that GC kicks in before you exhaust the pool of open cursors. You should use the with statement or close the cursors explicitly.
True.
[Py2exe](http://www.py2exe.org/index.cgi/Tutorial) creates a Windows executable from (almost) any python script. Assuming your teacher uses Windows, you can send an executable. Other than that, I have no idea except what's been said in the other comments.
Python is pretty much Google's scripting language.
Colons are not the problem. Mypy has other new syntax not supported by Python annotations such as variable type declarations, generic type parameters and casts. Therefore mypy would not always be compatible with Python syntax anyway, and having a different type syntax seems like a good way to avoid confusion and false expectations. 
It's more or less the same goal, but persona is decentralized (well, will be at some point, it has a centralization bootstrap). Also, you don't need to have a google account or a facebook account, any email account will do. You may find the explanation on their website clearer than mine : https://developer.mozilla.org/en-US/docs/Persona/Why_Persona .
For people who want this, also have a look at [Resolver One](http://www.resolversystems.com/products/resolver-one/).
Yup. GC can be relied upon to handle your memory, but anything else is a beneficial side-effect. It's not C++ where you can rely on [RAII](http://en.wikipedia.org/wiki/Resource_Acquisition_Is_Initialization) semantics.
Can someone explain how this is different than [xlrd/xlwt](http://www.python-excel.org/), which I'd used previously to read Excel spreadsheets in Python?
Because this is embedded *into* an Excel file. As long as the recipient has DataNitro installed (a one-time thing) then you just send them the Excel file with the Python module embedded. Simple! Rather than having to have a Python *and* xlrd/xlwt installation on the clients computer.
Thank you, Python Anywhere works fantastically!
&gt;del or weakref are the right answer ( Not sure if you mean `__del__` or the `del` operator here (The OP wrote `__del__` but reddit formats this as __del__ if unescaped, so I think he meant the former) However, either way, they're not really helpful here. The del operator just removes that one reference - no different to rebinding it, so it's no different to his for loop rebinding. Adding a `__del__` method OTOH will actually bar the object from getting collected at all when it contains circular references.
LibreOffice/OpenOffice can be scripted with Python using the UNO bridge. Documentation seems to be sorely lacking, though - [this site](http://lucasmanual.com/mywiki/OpenOffice#OpenOffice_and_Python) is one of the better descriptions I found with a quick search.
I'll definitely look into this, thanks! There wouldn't happen to also be an R interface, would there?
It IS useful. I know, I use it. And, they've got a really nice and helpful team, too. 
Nice! It's a great service.
Definitely. Is there a way to share it with, say, a whole website and its users?
Does anyone else "hear" that name in the voice of the drag race/monster truck guy on the radio? I know, not precisely on topic so I'll take my lumps.
Wow, this is so elegant. Wish it was in the std lib, though.
Command-line is inherently string-based. What you can do is use a [schema-validation library](https://github.com/halst/schema#using-schema-with-docopt) together with docopt. See [my response on that](http://www.reddit.com/r/programming/comments/10we2w/pycon_uk_2012_create_beautiful_commandline/c6hit5e).
ok, nice. that one is surely awesome for more complex data. but when one really just needs to have validation/conversion into simple types, and handling of optional data, it would be cool if docopt had that functionality [as described in my feature request](https://github.com/docopt/docopt/issues/58) i think i expressed my concerns even better there.
Have you looked at pydiction for vim?
Yep! https://code.launchpad.net/~cwayne18/onehundredscopes/unity-lens-pypi
Beyond simple -- beautiful!
Every once in a while a library comes a long and hulk-smashes every other library in existence. Requests was one, this is another.
My tears have tears.
I agree, good article. Also gives me a bit more respect for the Dropbox developers.
Fascinating piece. I'm not sure I'd enjoy working with COM types in python, but I'm _really_ glad there are people who do! Well done, dropbox!
You're looking for /r/learnpython 
I think you missed the problem. Using asynchronous IO does not explain why it works most of the time but *sometimes* hangs when trying to read from the pipe. The program should have terminated after executing and close its pipe thus returning control back to the python in a synchronous fashion. In an asynchronous implementation, the child process will still randomly not terminate after executing it from subprocess.Popen. Edit: I just tried that example code provided by that link, but the psexec.exe process will still hang until it is forcefully killed from the task manager.
You're OP says &gt; However, there seems to be a problem when running psexec from subprocess.Popen where it hangs after executing. Which I assumed that the hanging occured all the time not _sometimes_ Does the hanging occur when executing the same executable ? Also after a quick google-fu I found [this](http://code.activestate.com/recipes/577945-execute-remote-commands-on-windows-like-psexec/)
The hanging seems to only occur when running psexec. Other executables don't exhibit this behavior. I also stumbled across that example using the WMI module, however it seems to have the same limitations as remote powershell sessions in that it cannot launch GUI applications processes that need to run and interact with a desktop session. 
...except that most of my cmdline scripts are just one file.
Your solution looks about right, except your "else"-statement that immediately exits if the first word in the dict does not match. Just remove that. Also, you don't really have to assign sortDictWords to " ". Python is not like C or Java, where you have to declare your variables. Minor style nitpicks: using plural "s" for a variable name usually means that it is a collection of some sort. dictWords only contain one word at a time, as does sortDictWords. So drop the s. Don't use space before :.