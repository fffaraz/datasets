I'm a Coursera student :-D
JetBrains is a European company. They will likely be receptive to this.
I agree with you, and as a counter example, did not submit my email and downvoted the thread. OP, this is not just a marketing vector for you. Its a community that values honesty. Feel free to run your marketing machine, but don't bill it as something else. 
I have a separate email for such purposes, especially for spams. I used that instead :'D
Look to the right side , scroll down for a bit. 
So the window opens up and it immediately closes
Are you using the "Run" dialog? Type it in the command prompt. 
You run that from a command line. If it's "not a command" that means `pip` is not in your path. You don't need to put it there but if you want to read [this](https://docs.python.org/3.4/using/windows.html#configuring-python). Alternatively run C:\Python34\Scripts\pip install pyserial
Downvote. 2 aren't python specific and there are much better lists, Google "python gotchas" 
They said they are currently reviewing their email sign up procedure. 
as a newcomer to python and machine learning a few years ago, i thought Orange was fantastic. but then i started working on bigger data sets and the fact that it was 32-bit only was causing me grief due to memory errors. i switched to scikit-learn and havent looked back. now that i see the full numpy/pandas/sklearn ecosystem out there, i think its too bad that orange doesn't use that in the backend and focus more on the GUI widgets that are simply amazing. 
First, as you stated, you need a list of divisors for both the leading coefficient and the constant. You need both the negative and positive forms so: def divisors(n): return [x for x in range(-n, n+1) if x != 0] You can now get a list of possible roots: def find_roots(x, y): roots = [] for p in x: for q in y: z = p / float(q) if z not in roots: roots.append(z) return roots roots = find_roots(divisor(24), divisor(2)) Will give a list of possible roots you can test, in this case for your first example of 24,-2,-57,-30,3,2 Also if you need the roots in actual fractional form you can just use the fractions module in lieu of using floats, untested but it should work. 
I believe you should also be able to use `python -m pip install pyserial` with python 3.4 :)
Yes it is equivalent.
Try using raw_input instead of input
I'm going to assume you're using Python 2 here. The `input` function takes whatever the user gives it and tries to evaluate it as Python code. So entering "3" gives you the number 3, entering "3 + 7" gives you the number 10, etc. When you enter "sim", it tries to interpret that as Python code. Since it looks like a variable use and there's no variable named "sim", it throws an exception. Instead, use `raw_input`. It skips the "try to interpret as Python code" step, so you just get the input as a string, which looks like what you want. Incidentally, it behaves differently in Python 3. There is no function called `raw_input`, and `input` behaves like `raw_input` did.
Got it, hanks man, I thought I was using python 3, turns out it was 2!
Instead of the four `pwX = numberr**X`, use a loop, something like: for p in range(1, 5): print "%d\t"%(numberr ** 2 ** p), print Also, the power operator is `**`, not `^` (it is the xor operator).
You have one loop, inside of which is five times the same operation. Use a loop to perform this operation. You can generate the numbers from 1 to 5 with `for p in range(1, 5)`, then get the associated power of two with `2 ** p`. After that, it's only a matter of printing `numberr` at the obtained power.
works with .ac.uk email them - great company...
&gt; "The purpose of this question is to write a python program (script) that uses a **list**, a **while** loop and a **for** loop." Lists are just what they sound like (see this link: https://docs.python.org/2/tutorial/datastructures.html) a = [1,2,4,8,16] you can reference them by index: a[1] = 1 a[2] = 4 a[4] = 8 ... Nested loops are one loop inside another like: while something_is_true: for number in range(1, number+1): do_something_here 
http://files.swaroopch.com/python/byte_of_python.pdf Also the book Python Programming for the Absolute Beginner 3rd edition is great. Every chapter opens with a simple 'game' or nifty program, and teaches you how to make it through the chapter. It's made, like it says on the tin, for the absolute beginner. You could not know how to work a cheese grater and still manage basic videogames by the end of the 400 page book.
Thank you, thank you!
I was excited then kind of sad. Reddit isn't for newsletter advertising, if you want to provide us with the 13 ebooks with a gentle request to subscribe to your newsletter, that would be a kinder approach and would almost definately win you loyal subscribers.
You think that html2text is going to convert the response to html? html2text takes well formed html and converts it to markdown. I think you need to read the docs again.
I took it 2+ years ago? good for learning basics and making you comfortable with python.
Subtitle could have been, "making Python jump through hoops to get things to run in parallel"
Curiously absent: the rationale for migrating. I'm a big Postgres fan, so I'd probably want to migrate, but I'm curious if there were actual limitations they were overcoming or if it was just preference.
It looks pretty interesting, but has to be my own original project and I am working with a team member. Thanks for the idea though
Then I suggest you attack some data mining. Find a dataset, get it, and go crazy. Could even be a simple hash tag on twitter and how many times it's associated with sucks or rocks. 
Oh now that sounds interesting. I will do some research on that and come back to you
50mm records? that's tiny.
or "Really simple parallelism with python &amp; unix"
oh, it doesn't do the other way. Thought it did.
If you put the code at the end of the try, this code will be "tried" for the same exceptions as the code before it. And your exception handler might be unsure whether exception occurred at the end of the try block (in the statements where you think there shouldn't be an exception) or before it.
but this is so convenient. Otherwise I would have to set up some sort of server side script that did the conversion using the markdown library. Too much work for a one off document no? And this does all the bootstrap stuff too. I didn't have to write any css. I'll just swallow your abuse and not change. sorry :P
xargs would have done all the multiproc shell script stuff for them. It's my favorite go-to for parallelization.
Hey, I just wanted to say keep it up. I didn't take IIPP, but I took the second course of the series Principles of Computing and am currently taking the third course Algorithmic Thinking. From what I've heard, PoC is a bit of a jump from IIPP but I was so incredibly satisfied with the projects... To me, these guys have created a series of courses that's pretty much the perfect mix of theory, practice, and letting you struggle a bit so that you actually learn. I haven't been a fan of Code Academy courses for example because I think they baby you too much - if you're not thoroughly confused at some points in time, it's too easy. For the last application in Algorithmic Thinking, we had to write some code that analyzed the resiliency of a network to an attack and use matplotlib to graph our results and come to conclusions. It was really neat! So yeah, keep it up. I'm a self learning Django developer, but I know that it would be incredibly difficult to learn these computer science concepts on my own. Luay, Scott, and Joe are really active on the forums (despite the fact that school is in session at Rice!) and so you know they really care. Other students are great help too.
Sorry dude that's a windows error
Yup, I'm attending, chose this course as my first at Coursera, just for fun. It's nice and organized, but pretty simple so far. Similar course, but about Django, would be useful, I always wanted to dive into that. 
I really greatly appreciate this. I kinda hacked my way through this to learn python and as a tool for myself to use. I am going to work to apply these changes immediately. What is the difference between prefixing the variables with self.x ? (I only did this to make it work)
&gt;easy jobs If I have to be more specific, getting the qualifications for all of these jobs is easy. There supply of qualified people for these positions is high. Much higher than the number of qualified bachelor's holding programmers. &gt;well paid No, they're not well paid because the qualifications are easy and/or quick to get. &gt;highly respected Respect is earned. If they're good at their jobs, people tend to like and respect them, no matter what they do. But who will you respect more? A nurse's assistant with a CNA with 6 weeks of training or a doctor with an MD of 10 years or more? &gt;majority of the work at home as well. I'd argue no, but really there's no way to qualify that because every household is different. Most men mow the lawn, not all women cook or clean, and many moms let the television raise their children. Babysitting isn't hard, it's just time consuming. 
I apologize I actually meant to post this (should have posted this) in /r/learnpython. Thank you again!
As I said in another comment, I'll clarify "easy" to mean "easy/quick to get qualifications" If your wife swapped jobs with you, how long would it take her to do what you do? I mean why isn't she doing what you're doing if it's so easy and much more rewarding? But I'd reckon even if that were true for your case, not many people can get tech programming positions with no education. Most jobs require a bachelor's in CS or equivalent. Yet I'm not seeing any women in CS programs even though they're "easy" and pay so much more. 
No immediate answer, but I hear the very latest version of LibreOffice supports Python scripting? Failing that, if you can find a tool to convert XLS files to CSV you can parse them, rebuild a CSV, and then open CSV from excel? Only problem; built-in CSV that comes with Python isn't very good for building stuff with more than a handful of columns, and doesn't offer any tools for sanitising or type-checking inputs.
XLSX files are zipped XML's, so you can use the standard zipfile and xml.etree.ElementTree modules to parse (see the 4th answer here): http://stackoverflow.com/questions/4371163/reading-xlsx-files-using-python And of course, also mentioned there are a few external libraries you can use. 
xlrd and xlwt really seem like the way to go here. 
&gt; if you're not thoroughly confused at some points in time, it's too easy. This is why committing to Coursera is good too, you deal with the confusion there and then. Codecademy is a great resource and definitely a stepping stone but it does appeal to casuals more so. I'm doing IIPP right now as we speak! better get back to it. 
It's a curiosity, but the rationale isn't important. It's a technical article about the migration, not a database comparison.
Best to look at what the process is doing. Check http://technet.microsoft.com/en-us/sysinternals
It 404'd. Anyone have a mirror?
There is the splitext function in the os.path library for splitting extensions from filenames/paths. (It does not make assumptions about the length of extensions, because .jpg and .jpeg are common.)
I pushed your suggested changes to the script itself. However, I don't know where to start with creating a setup.py. Do you know of any good tutorials or some examples?
Learning. I also plan to start using Qt, and try to do gui design manually..
I mean if he converts to csv he might as well do this in his terminal/cmd: Cd directory Copy *.csv output.csv
For simple parallelization like that in the article, xargs is awesome. But, just for the record, if you want tighter control gevent and multiprocessing work well together using [gipc](http://gehrcke.de/gipc/).
Yeah, no problem. I signed up long ago when they offered everything free. They now offer I think a masters degree online through a university there. The creator of reddit teaches a course there as well.
I mean what is the point of learning it manually other than spending frustrating hours trying to position widgets via code? Qt Designer is quick and functional and lets you spend time just working on the backend of your application.
In addition, great web/scraping modules such a Selenium, BeautifulSoup, and Scrapy are very well documented, including entire tutorials with code examples.
Postgres wouldn't be my migration target. It still doesn't have master master so any maintenance to the db engine, or the OS would require downtime. I would rather go with cassandra or mysql for this reason.
Ran script, syntax errors. This is the third time I have cut and pasted code from prolificprogrammer and have it fail. Three strikes, no balls.
Terms like "tiny" or "big data" are relative - to how much hardware you've got, as well as the amount of downtime you can afford, impacts to operational performance, etc. Saying it's "tiny" is meaningless. I recently had to analyze a MongoDB database with a few billion rows, then design and help run a conversion of its data. Sequentially stepping through data in Mongo takes forever. The target date for the conversion effort was 60 days for a mere few billion. That company is probably going to migrate to Postgres to make these kinds of operations far faster.
I have used xlrd and xlwt, it works like a charm. Used it to help consolidate financial data sets. Also, if you are looking to make something really simple and don't care what language, powershell is pretty easy to use and integrates really nicely with Excel.
I'm guessing they finally realized they needed ACID compliance which noSQL cannot provide.
SFTP with Paramiko
shucks ! New to this subreddit ! sorry mate ! thanks ! 
thank you !
thank you ! have already started reading up on it !seems to be good 
I'm a bioinformatician and there are lots of big databases out there that you could mine. To be all hip you could look at the the RDF framework EBI had implemented http://www.ebi.ac.uk/rdf/platform
Applied a while ago (9 months) for a class I was teaching as to have tools for me and the students. Provided proof of everything as mentioned on that page and never got an answer. :-( 
... do I have to tell you to include code or a better worded qustion?
The joke was about 'mm'. I was ignorantly referring to its meaning as "millimeters". 
Have a look to Python Fabric. 
There's a lot of things. First, I am not sure if it was just a bad copy-job to Reddit, but make sure your indentation is correct! Whitespace is important in python. Second, in line 9, you're assigning hours to remainingSeconds % NUM_OF_SECONDS_IN_MINUTE. You haven't declared remainingSeconds yet, though! Python won't know what to do and will give you an error. Third, your print statement is going to print a tuple of its contents. You probably want to take a look at how to do string interpolation (or even just concatenate the strings with some spaces) to get a nice pretty string. Finally, I'm not sure this function will do what you want it to. I'd suggest working through it (either in the repl, or on paper even) to make sure your algorithm gives you the right output
Also, it would be a lot easier to know what you're doing if you post the error message that you're getting.
That's assuming OP has no need to modify or shift data around. And if that were the case (all columns identical between sheets, no duplicate rows) we might as well say to use ctrl-a, ctrl-c, ctrl-v.
No need to convert to CSV, Pandas can read Excel files, as long as you have xlrd (and maybe another library) installed. 
I'm also studying this course. As I was home schooled many years ago I never did anything above very basic math so that's my only stumbling block with the current project. The rest of it seems well laid out, and the practice lessons seem good as well.
Why does the lack of master/master cause downtime? I'm not a PostgreSQL expert but can't you use master-&gt;slave to duplicate your data, then do your maintenance on the slave, and then use master-&gt;slave to sync up the changed records?
The company I work for, also recently migrated from Mongo to Postgre. We also had around 150GB of data. Our rational was: * our data was inherently relational so using a relational database would have made sense in the first place (I guess the original developers wanted something new and shiny) * because of this (and I think out of inexperience) the original developers used MongoDB somewhat relational. We had several places where we would have ObjectId(...) inside a document (often arrays of dozens to hundreds). This links would then be pulled together by our custom written Data Abstraction Layer * We had no schema integrity. * We had no *data* integrity. Since we used ObjectId links we sometimes ended up with logically inconsistent data. Those were always caused by bugs in our code but face it: You will have bugs. And a database that puts and big, fat "no, you can't do this' sign in front of your stupidity is always nice. * Schema changes were pain. We used a mix of one-time scripts to changes existing documents and move data around and custom code in our data layer, that did those changes on access. Both went wrong sometimes or had bugs resulting in many lines of code that had a comment "checking for X because sometimes the DB contains bad records". Now we use alembic for our migrations and it's much better. Everything is wrapped in a nice transaction so when something goes wrong during a migration at least the database is in a consistent state. * **Transactions**!!! (see paragraph below) * Non-Index-Queries in Mongo are slow as hell. Ask a decently sized MongoDB some fancy Map-Reduce query that contain non-index fields and it will stop, print out the data, ship it to india and let some guys ran the query by hand. If you do this with Postgre (or any other good database) it will be slower than an index access but it will return way before MongoDB even finished printing out your data. During one of the conversion trials I sat beside a coworker and we asked "How many documents with this criteria do we have?". We wrote a Mongo Query and it took 20 *minutes* to complete. Then we asked ourself "How many of these or already converted?" and he worte a SQL-Query, fired it and said "I will grab me a coffee, this may take"...I called him back before he could reach the door, because Postgre was finished (answer way: "all of them") And my personal bonus reason: * Oh my gosh, the query language. Whoever thought "Oh yeah, we will use JSON as our query language" should never, ever work in CS again. Please go to North Korea and because you obviously love to torture people. God. Its feels aweful. It looks aweful. It's batshit insane. 
Yes, I'm attending Coursera for various topics. &amp; previously i was following python video lectures from [buckysroom](https://buckysroom.org/videos.php?cat=98) and one more great stuff [here](https://www.youtube.com/watch?v=RrPZza_vZ3w) to Learn Python Through Public Data Hacking. Good Luck :) 
JSON can be easily converted to a language-native data structure (e.g. python list of dicts or Rs lists), whereas HTML is horrendously difficult/messy to convert into anything.
The code in the sidebar is a generator, so you'd need to do: for n in fibonacci(): print(n)
Link to the course? 
I always read it as "mega million" and get confused to what the fuck it is. Please stop using *MM* outside of roman numerals, thanks.
 &gt;How is that "clearly"? And which goals? Is the goal "not be drowned by testosterone" then yes I agree :P It is pretty clear that woman take other career paths that Stear then away from computer science into other tech fields. As for testosterone it is pretty clear also that the CS field is actually lacking in that area. CS is the opposite of a testosterone fueled industry, populated in the majority by geeks with little in the way of manly natural gifts. 
Can't believe there's no videos online.... and the tickets were expensive bleurghhh
If you think having to use a new framework *and* add shell scripts is "really simple", it's probably worth trying a different language for a while. Even in C++, this sort of embarrassingly parallel problem is only a handful of lines of extra code.
&gt; Oh my gosh, the query language. Whoever thought "Oh yeah, we will use JSON as our query language" should never, ever work in CS again. To be fair, something like SQL doesn't make much sense when applied to a document store given that most of it is dedicated to joins and projection, neither of which are common with something like Mongo - 9 times out of 10 you're just doing a straight selection, which benefits from something rather more powerful than a WHERE clause. Also, maybe it's a good thing to discourage thinking of queries as human readable things we build up from strings, given how many security problems that has caused in the past?
I've replaced the original implementation with your code (not quite verbatim, but in spirit.) Despite the warnings in the docs, the lib2to3 API is apparently stable across 2.6, 2.7, 3.2, 3.3, and 3.4...that's stable enough for me. If it changes I'll just have to roll with the punches. Thanks for the help!
I was thinking this was a radio app for OpenPandora :/ About the code, personally I don't like *mixedCase*. Otherwise, good job.
This is exactly the sort of bad habit that python tries to discourage. If a dynamic maybe-not-here-yet variable is needed, contain it and all other maybe-nots in a dictionary, and use `dict.setdefault` or `dict.get`. Doing that at the uncontained global level is very messy.
You can learn python from anyone who knows python. I don't know this specific course but most of the ones like it aren't likely to get anyone in deeper than the surface of any language whether it's python, rails, js etc. He might pick up some bad habits, but unless he stops learning from other sources, reading books, reading OS code, talking to other people, those bad habits aren't likely to do any permanent damage.
I learned Python from the official docs. It's not a bad way to go about it.
Team Treehouse has a really good format for teach and is rather inexpensive. Not sure if you are trying to learn for free or not but they are adding new tutorials everyday.
I haven't taken the course but I did buy one from him recently on Udemy based off the fact that almost 12K people have enrolled in the course and 200 reviews have it at a high 4.5+/5. https://www.udemy.com/coding-for-entrepreneurs/?dtcode=ranUXtr1yZqQ#/ He does offer other courses on udemy as well so those can give you additional reviews to judge him on. Again, I haven't gone through the course yet myself.
Sound like Python isn't for you. Or you write shitty tests.
yet another "Haskell will save the universe" blogpost. 
https://www.coursera.org/course/interactivepython
I don't want to take a name, but I did one udemy course which had really good rating but I did not like it at all. I think udemy has general crowd, who are beginners and probably wouldn't know much about standards of coding etc. So a seasoned programmer can easily spot whats wrong and why its wrong, however a beginner still find it easy to follow. Take example of w3schools. But then, I don't know whether a beginner should start following best practises since day one or not. 
I'm trying to subscribe to this python course on Coursera, but I have an "HTTP error 500" ; anyone experiencing the same thing ?
Apologies, I just recently listened to a coworker swaggering and refer to someone else's 50 billion row database as 'tiny'.
&gt; My experiment would consist of finding examples of open source, unit tested programs written in a dynamically typed programming language and manually translating them into a statically typed programming language. I would then quantify how many (if any) defects were detected by the type checker, and how many dynamic constructs couldn't be directly expressed due to being rejected by the static type checker.
I count one common python module, *no* extra lines of python code and a trivial shell script. For an ad hoc migration. And you're saying that moving to C++ would be simpler? I'd like to see that migration code. There's no doubt that scala, for example, makes it easy to write parallel apps. But there's also no doubt that many people in our industry have been overlooking how we've been building simple parallel apps for years. I used a very simple approach once to parallelize a python ETL transform that had to run 200 milloin heavy transforms a day - with fairly low latency on a 4-core server. At a conference a few fokls kept trying to convince me that to move it to Hadoop. Apparently, there's a cognitive dissidence involving parallelism and anything but a few technologies.
I'm primarily a python programmer these days, and I love it. But my initial foray into coding was in Java/C. I will admit that dynamic typing does seem freeing as a developer, but I think it also makes it harder to read somebody else's code, which is a bigger disadvantage. The way I see it, when looking at a variable, the first thing that should tell you what it is is the name. But sometimes that can still be confusing. Is it a string or an int? Is it a list? What does the list contain? Admittedly, it can be nice to be able to put whatever in a list (at times), but it still makes code more difficult to understand. I'm not really convinced one is better than the other. I see advantages and disadvantages to both, and I think the author of this points out a real disadvantage in that it makes it so the developer has to be more proactive in developing robust code.
You probably won't learn python from https://codingforentrepreneurs.com/. I bought an Udemy course and he doesn't explain much. It's more of a "follow these steps and you will have a product". 
maybe-not-here-yet in global! real bad code. I have done a the get('name', 'No name') many times, but parsing json or from unknow sources.
&gt; those bad habits aren't likely to do any permanent damage Unless the code happens to deal with security or confidential data.
It should not be difficult at all. You need to point it to a bower directory, wrap it around the WSGI app that your Pyramid webapp provides, and use the includer to include resources from within those views that need it. This page should go into the details: http://bowerstatic.readthedocs.org/en/latest/integrating.html Could you tell me where you have difficulty wrapping your head around it? Maybe I can improve the docs. A specific page that explains how to integrate it with Pyramid would also be welcome, and I'm hoping someone will contribute it! 
thank you for the review... I will pass the message to my friend
Teaching in Germany requires studying at a university and gaining a Master in Education. Most people don't even have the qualification to even study at a university. All the other jobs I mentioned require several years of training in Germany, though even child care is done by people who studied at a university in some cases nowadays. If this is your definition of easy, your worldview is heavily skewed. Furthermore respect is only earned to a small degree and only on an individual level. As a whole doctors are awarded respect simply by being doctors no matter how good or bad they are. The same goes for a lot of other professions like lawyers etc. 
Unfortunately, no, *mm* or *milli milli* (instead of mille mille) would imply [*thousandth thousandth*, 10^-6 or just *micro*](http://en.wikipedia.org/wiki/Metric_prefix)
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Metric prefix**](https://en.wikipedia.org/wiki/Metric%20prefix): [](#sfw) --- &gt;A __metric prefix__ or __[SI](https://en.wikipedia.org/wiki/SI) prefix__ is a [unit prefix](https://en.wikipedia.org/wiki/Unit_prefix) that precedes a basic unit of measure to indicate a [decadic](https://en.wikipedia.org/wiki/Decimal) [multiple](https://en.wikipedia.org/wiki/Multiple_(mathematics\)) or [fraction](https://en.wikipedia.org/wiki/Fraction_(mathematics\)) of the unit. Each prefix has a unique symbol that is prepended to the unit symbol. The prefix *[kilo-](https://en.wikipedia.org/wiki/Kilo-)*, for example, may be added to *gram* to indicate __multiplication__ by one thousand; one kilogram is equal to one thousand grams. The prefix *[centi-](https://en.wikipedia.org/wiki/Centi-)*, likewise, may be added to *metre* to indicate __division__ by one hundred; one centimetre is equal to one hundredth of a metre. &gt; --- ^Interesting: [^Kilo-](https://en.wikipedia.org/wiki/Kilo-) ^| [^Mega-](https://en.wikipedia.org/wiki/Mega-) ^| [^Tera-](https://en.wikipedia.org/wiki/Tera-) ^| [^International ^System ^of ^Units](https://en.wikipedia.org/wiki/International_System_of_Units) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cks5rc2) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cks5rc2)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
It complicates, would be something like 50 * 10^6 * 10^6 = 50 * 10^12, or *50 trillion* records Although seeing something like *50KK* for representing *50M* is quite common. I think its ok because it is still easy to read a value split in blocks of 10^3
I began in a new career in programming about a year and a half ago. I was taught Python with a very strong emphasis on thinking like a programmer. I use it (python) almost everyday in work and love it. But there is still a lot about it I do not know, so I try branching out and doing things with it on my own that I do not use in work. I have actually used codingforentreprenuers youtube videos to help further my knowledge, but like others have mentioned it is more of a monkey-see, monkey-do site rather than a teaching thought process site. To be fair most tutorials are that way and you have to be smart enough to take your time and try to extract the thought process from it. My experience with coding for entrepreneurs is... He does a decent job not perfect, following pep8. He has a great working knowledge and makes things that work. Can they be done shorter, better, and prettier sometimes? Sure. But you know you learned something when you can find those times and implement your thoughts and end up with the same result. No real attempt at learning will be completely fruitless, you may learn what to avoid! ;-) Some things will be more helpful than others, this will always be true. For online materials, I pretty well stick to the free stuff. ****Edited**** oh the grammar!
I'm curious aswell - why are you a big postgres fan? All my serious db experience has been with oracle, but I'm planning to try postgres out when I get a chance, why do you like it so much?
Well Python 4 is not coming out until like 2023. The article that's been going around is saying that the jump between 3.9 to 4.0 will be a normal difference, no planned major backward compatability breaks. Between 2 and 3, there has been, as they're trying to improve the language. http://www.curiousefficiency.org/posts/2014/08/python-4000.html
When getting sluggingpercentage, you can't call "totalbases" in that way. It still needs the parameters (first,second,third,home). It's a function, not a variable. It should be: sluggingpercentage = totalbases(first,second,third,home) / tbs Or to make things even simpler, you can calculate totalbases and put it into a variable: totalbases = totalbases(first,second,third,home) After that, you can say sluggingpercentage = totalbases / tbs
You obviously did not even click into the article.
makes sense... thank you!
Wow, thank you Planet_Of_The_Snapes and Parnmatt. I really appreciate the help, the code is working now and I will keep both of your lessons in mind for the future. 
Also make sure you float() one of the values or else you will only get int's back. For example float(tbs). 
docstrings? Comments?
Not saying moving to C++ would be simpler, but just making the point that a supposedly more complex language handles parallelism far better than the Python hack shown here. There may be no extra lines of Python code but it did have to be changed to use gevent and it relies on gevent.monkey to be able to do the right thing in all circumstances (not guaranteed if you use external modules, for example), plus it also requires the shell script to use more than one processor or core. You don't need Scala for a problem like this, you just need a language that doesn't have an artificial lock stopping you from easily running multiple threads at the same time.
Not enough people know Haskell will save the universe. So it must be repeated.
behavioral testing of the program is an even better way of making refactoring easier. that will test the actual business logic and not just the type invariants. 
Fair point... I'm still on python 2 like a dinosaur
Seems there was a problem with Firefox 32.0.3 / Mac OS 10.9.5. I tried with Safari and it's allright.
The 'experiment' is a very artificial one and I'm not convinced that the results can be extrapolated to real-life issues. I can see advantages of static typing in dynamic languages, though. Execution speed is one, clarity to other programmers is another. Personally I don't think bug reduction is a big advantage: there are so few bugs I catch/would have caught with static typing and all of them are quite easily fixed.
Getting on the Python bandwagon 5 years ago was the best thing that ever happened to my career.
No problem! Happy to help.
Thanks for the heads up. I just ordered mine. 
I mean, to be fair this should run on the OpenPandora ;)
Yeah, Arduino has a massive ecosystem already... but Python is very popular in education at the moment, so it could make waves there. It would be fabulous if it could become the start of a real mobile platform based on Python. One can dream! :)
Another library to consider is pandas. pip install pandas import pandas as pd df = pd.read_excel(f) 
No problem. I did some minor testing, and it did shave some time off of the 'detect_version' function (because it doesn't have to shell a subprocess).
The question is, what language do we write the bot with? But I agree. Or how about a bold message on the text submission page?
my favorite still remains CloneDigger
Honestly I don't know much about the stability of `lib2to3`, and I only tested it with Python 2.7 and 3.4.
thanks
Sure, it's possible to run. :)
Hopefully more people start worthless adsense spam blogs and post here everyday!
Udacity has fantastic Python courses (CS 101 and CS ~250 or something) that actually teach you how to *think* Python rather than code Java in Python syntax (teaching nonsense like this: "for i in range(len(arr)): print arr[i]")
FWIW, every few hours I just downvote most everything "self.python" and upvote almost everything that points to an external site. It does at least seem to keep the top-ten-or-so free of things that would be better off in /r/learnpython but there isn't actually enough quality content contributed to drive it fully off the page. 
Why OP is being downvoted?
Idle curiosity, what's stopping this from happening? Honest question, I'm new to the language, and have really only dabbled in small electronics with Parallax and Arduino, but I've seen people do some seriously amazing stuff with microcontrollers. What would sell this one shorter than what's available now? 
Thanks, work for my .cz adress, just gave them a copy of the paper proving that I am student and next day came the active link. So I understand it correctly, that those proffesional products will only work until next year? Then I have to renew my licence by proving that I am still student, or just buy the required product, right?
Momentum. Arduino currently owns this space, it's worked hard to get where it's at and kinda deserves it at the moment. They have a great ecosystem setup, along with various boards for various tasks and costs and the shield availability in unparalleled. I own two of these boards from the kickstarter and they are amazing and I will probably start to use them for more projects now that they are readily available. But Arduino is still cheaper, has a larger ecosystem, and the number of tutorials are mind boggling. These boards will find their niche, and I could see it being a large niche. 
Yes, you have that. And good programmers use them. But docstrings are really only used for headers for modules/functions/etc. And inline comments describing types are messy and unnecessary in static typed languages.
I need to download the subtitles but i don't have access to the actual mp4 file. Subliminal uses information from the file to download the corresponding subtitle 
Can you give me a little more details about this?
Warning! the paper is a doc hidden behind pdf (not a latex one) More seriously I found more interesting the highlight on how to avoid type error. &gt; The GrapeFruit [24] library stands out from the other studied projects in that it did not have any type errors. There are two notable factors that could contribute to the type safety of the GrapeFruit [24] library. First, the library’s unit test were more extensive than the other projects. As noted above, unit testing is not a replacement for static type checking, but full code coverage unit tests will detect some type errors. There is a second and perhaps more important difference between the GrapeFruit [24] library and the other software projects. The GrapeFruit [24] library was written such that each of the library’s variables will only be assigned values of a single type. Likewise, each of the library’s methods will only return values of a single type. 
FYI if you have an OpenWrt device with a recent build then you can install and play with Micro Python with `opkg install micropython`.
I do think [learn python the hard way](http://learnpythonthehardway.org/) is a good way to start
Very cool. The hope of writing microcontroller code in Python instead of Processing make my day.
I started when it was still pretty niche and I'm amazed and really happy about how popular it's become. I can remember worrying about being forced to do Java or MS stuff to make a living.
&gt; The way I see it, when looking at a variable, the first thing that should tell you what it is is the name. But sometimes that can still be confusing. Is it a string or an int? Is it a list? What does the list contain? Imho most of the time an API does not deal with simple built-in types. So you always have to get closer to the domain of the library you are working with, in order to get to know the complex types, that are essential. But a good API makes this easy for you! And imho that does not depend on a staticly typed variable name. Of course it is easier and perhaps sometimes less error prone for an **IDE** to get the needed Informations for you to show up in a code completion window. If you have that feature, does it really matter to you, whether the language is statically or dynamically typed? But if you do not have this feature, you earn nothing from the static type, as you seldomly will see it directly, without looking at the declaration - and if you do, there is no difference to gather the information from a docstring on top of that ;-) There are good reasons for more and more statically typed languages to use **type inference**, for example to reduce typing and increase readability - and so they use that feature more and more! (Look at C++11's and C++14's ``auto``, the ``var`` in C# and Scala, ...)
If I want to find something at a "steal" price on craigslist, I run a script on my digital cloud server that searches the nearby areas with the search parameters, finds the price, and if it's below my target price, it notifies me.
It's kind 'inside baseball' but I automated [releasing python packages](http://serialized.net/2014/09/fully-automated-python-package-releases/). I automate a lot of sysadmin'y tasks (often with fabric.) Prior to using Feedly I automated cleaning/updating my RSS feed list.... 
It has functions to plot points and fill the back ground... The only bad thing is that it needs python 3.2 and pygame 1.9.2a0
Nothing is snake shaped, I'm disappointed.
What degree is more work to obtain, a degree in Education or a degree in Engineering? Do you not know what "easy" is? Engineering is several times more difficult than Education. In the USA only a bachelor's in about anything is required for becoming a teacher. Let's look at some actual data: http://nces.ed.gov/programs/digest/d13/tables/dt13_318.20.asp 2009-10 Humanities: 280,993 Social and behavioral sciences: 269,996 Natural sciences and mathematics: 125,809 Computer sciences and engineering: 128,318 Education: 101,265 Business: 358,293 Other fields: 385,340 If you look at statistics by gender, women highly favor easier majors like Education, social sciences, or humanities. 
well, there's the [logo](https://pbs.twimg.com/profile_images/378800000763037297/924066ab78394d83f1cd29e5d083a85a_400x400.jpeg) on [the back of the board](https://s3.amazonaws.com/ksr/assets/001/557/279/9cefe6e6c40bffffc8beced10abdb7ea_large.jpg?1390524632).
* Lots and lots of sysadmin type tasks. * Building/packaging/deploying code. * Parsing bank/credit card/etc CSV files and merging into my preferred format. 
Celery is definitely the way to go for such job. And setting it up with Django isn't that hard either. The hardest part may be that you need to get two more processes running (the worker and broker). Concerning brokers, redis is really easy to install as mentioned above.
I've done the same. Surprised APIs and services for CL aren't that good. 
That is pretty sweet!
We're all behind a shitty proxy at work that keeps pip from working (it can't connect). I created a module that you install that will (after downloading a zip/gz/tar) unzip and install any module just by right clicking on the zip and select install. I guess that's more than automating but everyone at my work uses it for days (Windows), it saves a ton of time/steps. We have about 200 scoreboards at various places throughout our plants. I have a script that runs through their ips, vncs to them and takes a screenshot. It then timestamps the actual image and saves it in a folder which is accessed by a web app, so people can look at their scoreboards (all of them) and make sure they're all working correctly. I go to a gym that’s not part of our little work network so I have to take a screenshot of my attendance and upload it. We get points (to amazon) for going to the gym. Every morning at about 6 it goes out, gets my attendance and uploads the screenshot to the website. I monitor a website and when it changes the script emails the HTML to me. It uses outlook which allows HTML emails, thus I get an email that looks like a web page with pictures and links and all. These are my favorite things to do. 
Well, Python was named after *Monty Python*, so ... 
Kivy provides a portable package containing everything you need as the default OSX installation process for precisely this reason, it can be a bit difficult to get everything compiled correctly and linked together on OSX. Although, it looks like you are wanting a python3 installation and I'm not certain if we provide a package for that at the moment. I'm not really a mac guy, but ensure that you have installed pygame and cython using the same python you are trying to build kivy with. 
As /u/bnorick already pointed out, this is not the best way to distribute your library. Especially not by posting the code in a reddit comment. Look at [PyPi](http://pypi.python.org) and their package help. Look at [GitHub](https://github.com), for version control. It also makes it really easy for someone to download and contribute to your source. I personally dislike MediaFire, because it's a [cesspool for malware and scams](http://www.google.com/safebrowsing/diagnostic?site=mediafire.com), and I'm hesitant to download anything from that site.
I had a similar problem when I tried Kivy on OS X recently. What I discovered is that all the recent versions of cython fail compilation on OS X I had to go to a version over a year old (.77 sticks out in my mind could be wrong though). Then I was able to successfully install it. 
The packaged Kivy comes with its own python and everything else you need to run Kivy. If you are trying to run kivy using your system python and the package kivy this will not work. Make sure you are trying to run your scripts using the Python interpreter found inside the kivy portable package. Kivy is not a pure Python module, and is based on several non-pure Python modules as well. The compilation and linking required to get it working makes the easiest way to get it working on Windows and OSX to be distributing the package with the separate python.
I'm just going to cover the errors in order. I'm not going to refer to the specifics, because that would make the post uncomfortably long. I will just say what I think about each in turn. OK, so NMEA: * This is a valid problem, and highlights the purpose of getting full test coverage, especially when refactoring. * The error only manifests if the data field is empty, which is a legitimate error. The only worry is that the error raised is not the right kind. * The error only manifests if the data field is empty and called without a default. It is true that `get_float` chooses to return `None` instead, but I would regard that as the primary (intentional) bug, not this. Further, what is meant to happen in case of no given default and an empty field. It is somewhat disturbing that it results in `ValueError` instead of `ParseError`, though. * &gt; This type error is also interesting in that it will only be manifest if a developer chooses to call these methods after the connection has been closed. &gt; [...] &gt; This restriction by the Haskell type system would have likely resulted in a more descriptive error message. In other words, the error isn't pretty enough. * Mentioning runtime error checking is a circular way of saying that static typing is better. The whole point of the excercise is to show that dynamic typing is insufficient, meaning that just showing the check for a runtime error does not help your argument. So that's 5 errors reported as: &gt; The translation of the Python NMEA Tookit from Python to Haskell led to the discovery of nine type errors. Three of them could be triggered by malformed input and the other six by an incorrect usage of the API. Only one of the type errors would have been guaranteed to have been discovered had full unit test coverage been employed. Additionally there was one run time error that could be eliminated once static typing was applied. It feels like a rather empty justification so far. MIDIUtil: * This is a valid problem, and highlights the purpose of getting full test coverage, especially when refactoring. Even then, though, the error may have been missed. * This requires a user of the API to give a negative duration for a note, which is invalid. Whilst it would be nice to give a specialized error, again this is not of much importance. * Again, mentioning error checking logic is not helpful to your argument. GrapeFruit: * This is mentioning error checking logic. PyFontInfo: * The error is that if you call the API in the wrong order, an error is thrown (as opposed to a *different* error, like the author wants). This is unimportant because any incorrect usage will be quickly corrected before being published. * The error is that if `head` or `name` does not exist, the wrong error is thrown when you try to `getHead` or `getNames`. Similar for `os`. This seems at best unimportant unless a method for this to occur errantly was brought up. * This is mentioning error checking logic. * This is a valid problem, and highlights the purpose of getting full test coverage. --- ### My conclusion There are only four errors that I view as important; the three I wrote "valid" by and the one where I said &gt; It is somewhat disturbing that it results in `ValueError` instead of `ParseError`, though. because it makes catching the error itself error-prone. I think the author is not aware of the EAFTP philosophy of writing Python code, which makes almost all the rest of the errors inconsequential. Of course they raise errors. It's Python. That's what you expect. I think the author is exagerating the benefit of catching these four errors: all of them would be fixed if they occured with any frequency, which implies they have not. That is not to say that they are *unimportant*, it is good to have good code. Of the four, half of them could have benefited from a good linter, one of the others would have been spotted immidiately if it was ever run (it was a lovely always-fail bug) and the final one would have been a bit bigger of a deal. Considering that I expected stronger evidence beforehand, I am actually *more* convinced than ever that good unit tests are sufficient. There is no doubt in my eyes that they will have caught far more than four unlikely errors over their lifetimes. 
Well - I'm at least glad it's not just me. I thought I was doing something wrong. 
I don't see why you are being downvoted. We should upvote what is more appropriate for /r/python, and downvote what is less appropriate. The sidebar says "**If you are about to ask a question, please consider [r/learnpython](/r/learnpython)**", so I think you're spot on. Thanks for doing the sub a favor, even if the sub doesn't appreciate it.
How are you guys finding these great Python gigs? Are you finding they pay as well as, say, C# gigs?
&gt; FWIW, every few hours I just downvote most everything "self.python" same here. I use requests to script/scrape that shit too. :) 
I switched to Java/C# and got a 30% pay boost. Python payscales are lower since it is an easier language to learn, but there is an abundance of jobs.
Sympy for integration homework in some grad level math classes I took.
they like to sue people who publicize stuff like that.
How about the solution/workaround I described in the text I linked? That one works too and is way shorter to type, and doesn't even require removing the tarballs afterwards.
Yes.
I'm taking it right now, too. So far it seems quite manageable, I'm looking forward to the more complex mini projects. I have tried things like Thenewboston/buckysroom in the past, but I much prefer this type of MOOC, with or withouth certification. Seems I get more out of it. The most important thing for me, though, is to always have a personal project on the side to work on, so you use what you learned and learn more by working on it.
Downvotes / Upvotes exist for this. I would be interested in making a mod bot though!
Look up Python dictionaries. You could use the shrub number as the key and what it holds as the value. You can then use this value to format a sentence with what the player got from the shrub when pulled. You also need to be casting your variables correctly. When a user inputs something it is a string. If you are using these values as numbers you need to cast them as an int() type. Try using the len() function to determine the number of items in the list but think about how lists work. Lists are zero indexed so the length of the list is the index of the last element + 1.
I tend to think the higher pay for enterprisey languages is more like hazard pay.
My current job started out as primarily PHP and drifted into being primarily Python over the last 5.5 years. I did a little Python evangelizing to the boss but I'm not sure how much credit I deserve for it. Just glad it worked out that way. But there are Python jobs out there in any reasonably large metro area. Just search. In smaller cities the pickings are more slim and conservative. I solved that by moving.
Way too many if statements, will get complicated when/if you need to add more to the list. Like thisisthemurph said use dict. Some Pseudocode: dict = {1:['what you want to print', 'what you want the inventory to be'], 2:['what you want to print', 'what you want the inventory to be']....10['','']} question = what is your question + the keys of the dict if question in dict: print dict[question][0] #this being the first value of the key according to what they picked. inventory[apply same logic as above] dict.pop(question) #remove the key and its values else: print '...' 
I don't think this is a good use of the upvote/downvote system. We should encourage students that want help with their Python skills, not discourage them by downvoting them into oblivion.
I'm interested in how do you use vnc with python, I've been trying to find a library for that but without any luck.
This submission has been randomly featured in /r/serendipity, a bot-driven subreddit discovery engine. More here: http://www.reddit.com/r/Serendipity/comments/2hie7d/more_proof_that_its_pythons_world_and_were_just/
Not trying to belittle your learning exercise but this is the kind of things *nix tools are excellent at. find . -name "*.asf" -type f -delete The above command will delete all files ending with .asf in the current working directory as well as subdirectories. Simply replace `.` with the directory you want to run it against. While I love using Python for automating more complex tasks, *nix has a wide variety of tools that can be used without reinventing the wheel. It's been a long time since I even have a Windows install but I'm pretty sure it has a similar command you can use as well.
I see nothing there that advocates tolerance of this situation, and in particular nothing about tolerating users asking for help with their homework in an inappropriate forum. You won't see much tolerance of that behaviour on python-dev, either. Also, I am not a member of the PSF.
Let's see how far we can amp up the unfriendliness and heavy handed moderation. If we work on it we might become StackOverflow.
Not all questions asked are better suited for /r/learnpython. But a lot of them. 
Your argument is a false dilemma, so I dismiss it. I'd be interested to hear your response to this: http://lesswrong.com/lw/c1/wellkept_gardens_die_by_pacifism/
There's no operating system to maintain. There might come a dedicated Micro Python firmware for the RasPi one day, though.
There is going to be more than two worker processes for sure, being instantiated and concluded as necessary. Let's hope Celery is good for that.
Maybe not an everday task for everybody but I am automating a lot of my experiments at work. I am driving syringe pumps (pyserial), laser shutters (Arduino + Python) and quite a few CCD cameras. I must admit that I am mostly doing it because I am reluctant to run all the experimetns myself specifically when it is repetitive (e.g. system stability testing).
Yes.
Every board has its niche. In this case, as somebody who loathes C and loves Python, it opens some very low-level doors to me. And as /u/mbirth said, there is no OS to maintain, just a Python REPL. It's also smaller than the Pi at the moment (to be fair, I think the Pi comes with more sockets by default).
Pythoners? Pythonites? I thought we were pythonistas *EDIT I just read the article comments, they say the same. 
regarding your last suggestion. would an alternative way of doing this be: from operator import add from functools import reduce def mergelists(*list_args): return reduce(add,list_args) 
Why would you use pyenv? The right package to use is [virtualenv](http://virtualenv.readthedocs.org/en/latest/). It always worked and still continues to work.
Don't worry, I'm not feeling belittled at all :) I realize there would have been other and better ways to achieve this, but it really was about having a chance to practise. I'm forced to use Windows for this part of my work, and I guess I probably could use something like deltree or a simple search for *.asf. 
Mind sharing that pip-behind-proxy script?
I'd say it is just PyEnv that is broken.
OP is talking about pyvenv, not pyenv. Debian broke the `ensurepip` module in their python 3.4, which also breaks the `venv` module.
I attended this course ~2 years ago, very good introduction, I think it is too easy because the projects are very easy to finish, and a captcha bot can solve those quizzes, I had only 2-3 WTF moments during the course - very little compared to other courses. but is very good for intro, after that course I made my own little games and learn PyGame and may more python related stuff, so it is a very good door opener. After that you can look at: https://www.coursera.org/course/matrix - alot of list comprehensions and more difficult coding, very good and hard course. https://www.udacity.com/course/cs262 - also more difficult that has more sophisticated python. Good luck.
Yeah, I linked to that bug in my text.
some questions if you don't mind: 1. What is `tox.ini` for? 2. `MANIFEST.in`? 3. Why do you have two setup files? `setup.cfg` and `setup.py` 4. And how `setup.py` is organized? 
So where can I order `Python is the new black`
No. Oddly, this does not help.
I agree that virtualenv + virtualenvwrapper is awesome but I heard they did't play nicely with python 3. 
Google+ allows unlimited storage of photos less than 2000x2000 so I have a script that resizes and uploads every photo I take on my canon. I read my email every morning so I created a script that emails me the weather each day for the times I'm most likely to be outdoors. I have various utilities for work ranging from python servers that emulate a third party vendor (who has no test server) thus allowing automated testing and building/packaging our products.
Hmm. No issues over here yet. Well- I am beginner so probably did not use much of it to break it.
I work as a developer and the company I work for has automated many daily tasks: building and packaging our software, running automated regression tests (not just unit tests, but full system tests of our tool as the user would see it), generating license files for our customers, and lots of one-off scripts for producing data for experiments. Closer to home, I have: * automated renaming and reorganizing my music collection * automated deleting pyc and unversioned files from my SVN checkout * calculated the "value" of players in a fantasy baseball league * controlled a NES emulator so that I could experiment with and optimize a technique for setting a world record * attempted to solve the board game Ataxx (for the NES 7-Up Spot game) * determined the probability of winning a battle in Twilight Imperium 3 using Monte Carlo analysis * helped to convert CNC gcode commands into audio to drive a low-cost 3D printer (basically a laser projector). Other projects I've wanted to do, but haven't yet, include: * Saving weather predictions and outcomes to determine accuracy of weather forecasts * Monitoring my fantasy baseball league and alerting me of issues with my players and availability of new players * Creating a personal knowledge base program (imagine a personal wiki, but even better) * Creating a usable karaoke player for hosting shows (the existing ones are largely terrible) * Creating a usable karaoke maker (the existing ones are largely terrible and expensive) * Lots of remote deployment and monitoring tasks for the dozens of computers I manage at work One thing to keep in mind with all of these tasks is that I didn't always use Python. Part of being a pragmatic programmer is being lazy and that often means using the right tool for the right job. There's no sense in writing a Python script if you can use easily use 'find' or 'grep' to solve the same problem in one line. That's just one reason why learning many languages is valuable; when a problem comes up, you have more tools to choose from in order to find the most efficient solution.
Doesn't really apply to everyone, but I play on a private game server that you can vote for every 6 hours and get points in the game. So I have my python script login to their site and vote for me every 6 hours
You have CSV files with credit card numbers in them? 
This is good to know! On one hand it's great that this critical tool was adopted and is now batteries included. OTOH it strikes me as another dimension of the challenge of distributing software that's compatible with 2.7 and 3.3/3.4.
Ah, my bad. Your solution is a lot nicer. I failed to fully read your gist, XD. Also, thank you for adding your solution to the Ask Ubuntu Q&amp;A, I came across it by googling the error that pyvenv outputs and presume other people have as well. Hopefully, they'll scroll down and find your new cleaner solution. I need to acquire some reputation so that I can give it an upvote! Have a nice day!
It can be okay but the problem is that you would be limiting yourself. The best teacher knows the core very strongly and can tell you why we would use those idioms. 
Why is it a challenge? I have a couple of virtual environments on my home dir. Some of them I built using `virtualenv` from `python-virtualenv` Ubuntu package. Others I built using `pyvenv-3.3`. Both work essentially the same. I can't see how this can make things more difficult.
FYI, this is Windows only. You still have to go out to wherever you go and download the tar/giz/zip. Install this module and it will add a new option of Install.cmd to your 'send to' submenu (on right click). Once installed just right click on any zip/giz select send to install.cmd and it will unzip and install that module for you. https://pypi.python.org/pypi/pyInstalls/1.0 http://imgur.com/mh6wWDn
Thank you. I've been looking for something like this. 
You don't have to automate something you do everyday. There's a balance between automation and repetition: http://xkcd.com/1205/. My job is mostly automating data intake and processing. I automate everything even if it only happens once a year. It cuts down on errors that might occur if you mess something up.
Ah, I might have misunderstood the purpose of that script. You know you can `pip install some.tar.gz` or `easy_install some.tar.gz` and it unpacks and installs it for you?
yeah, but it gets old opening cmd or python when I can just right click on a zip and select install. I'm lazy. 
I recently wrote a github activity tracker which will pull the latest (or a max of 3) commits from a github RSS feed and tweet it to your twitter timeline. Still a work in progress (have to daemonize and work out some efficiency issues), but right now it works fine running in screen. https://github.com/erm/github-activity-tracker
bnorick... the bit where you said "merge*Lists functions (which it appears that you don't even use)" is wrong.... The functions mergeTwoLists, mergeFourLists, mergeEigthLists and mergeLists are used to merge together the image lists made by newShapeList, newShapeListXII and newShapeListXXIV
Regardless, you don't need them and simply shouldn't have them. They're unnecessary function calls and, worse, unnecessary iteration.
which ones don't i need?
what you said about: merged_lists = list1 + list2 + list3 + list4 is wrong.. if list1 = newShapeList("square","square","square","square","square","square") list2 = newShapeList("square","square","square","square","square","square") list3 = newShapeList("square","square","square","square","square","square") list4 = newShapeList("square","square","square","square","square","square") merged_list would be: [["square","square","square","square","square","square"],["square","square","square","square","square","square"], ["square","square","square","square","square","square"],["square","square","square","square","square","square"]] therefore the code would not be able to load any of the data also... think about it... if the user wants more than 24 shapes... they can only get 24 by using newShapeListXXIV and 12 shapes by using newShapeListXII. Then by using "newlist1 = mergeTwoLists(list1, list2)" they can merge two 24 lists to make 48, then use "newlist2 = mergeTwoLists(list3, newlist1)" they can make 72. Then when using "mergeLists(list4, list5, list6, newlist2)" they can merge a 24 list (list4), a 12 list (list5), a 6 list (list6) and a 72 list (newlist2).
I just usually have a couple command lines open already, but I can see the appeal. 
Oh and by the way i have now made it even simpler for you, bnorick... I have add newShapeListPlus(*ShapeArgs) So now the shape lists can be infinite... So... no more newShapeList, newShapeListXII, newShapeListXXIV
Did you test this in your python interpreter? That's always a good first step. I happen to know that, from your example, `merged_list = list1 + list2` will be equal to `["square", "square", "square", "square", "square", "square", "square", "square", "square", "square", "square", "square"]`. That is, the sum of two lists is a list which has the elements of the first list followed by those of the second, this is also known as concatenation.
Awesome, I'm going to be working on optimizing it in the next few weeks so hopefully it will be fast enough for you!
:D
Sounds like a pretty hardcore coding job you did there. Really sucks they make you do it manually in the end anyway ;(
It changes the background using color... say you went "c = newColor(255, 000, 000)", c becomes a tuple containing a RGB colour. Then using: newSurf = createGraphSurface() setFill(newSurf, c) It changes the background to (255, 000, 000), a.k.a Red. Also the reason you don't see it in the modtest.py is because i wanted it to keep the background black. Also are you fimiliar with this phrase? "Everybody does different; it's what makes us human". If not then it means Bob may do things different from Steve, Steve may to things different from Max. And megaskull100 may do python different from bnorick. Anyways what is the PEP8.
Don't really use the phrase "bad practises" because its not like i am destroying someones PC. I can... but not with this python file. If you want to know... I use batch to create a batch file in the "Startup" file that shuts down the computer. But i haven't done that in 4 years.
Plus i never used it.
By "bad practice" I don't mean harmful, I mean things that make your code less maintainable or understandable.
I don't really want to make my code understandable, you might. I don't, "people do different; its what makes us human". Anyways... go on then... tell me how to make the functions use imports at the top...
At the top of your python file you can write imports, if you check out PEP8 there is an order that you should follow for these imports. Once you've imported something in your python file, you no longer need to import it in every method that uses it. For example, if you're using `pygame` in many functions, you only need the one import at the top of the file and then you're set.
thanks, alot. I will give additional credit. And the file will be updated!
Ok thanks... i am keeping the setFill() function though... but thanks anyway
For The Record virtualenv is hoping to eventually just use `venv`'s machinary behind the scenes when it finds itself running on a python 3.4.
Nope, they work just fine with python 3.
I think you need at least ssh.
Very good work! Surprising results (though not impossible). These benchmarks are not perfect but so much more meaningful that plain means. That was very pleasing to read.
How do you imagine this human input would look like? You can simply throw together some scripts that replicate this human input, and add an extra test for every bug report that is filed. (Which is good practice when doing tests: One test for every fixed bug report, to make sure it won't happen ever again.)
I too just started a Flask project using markdown. I've started to implement it using a custom build editor on the front-end, together with stmd.js. I'll probably use this to parse markdown stored in the database before displaying it in my views. Thanks!
With Paramiko existing for both Python 2 and 3, you really have no excuse to run on that relic.
Fantastic. I won't be using it at the moment but when I was implementing a project a while back I ended up going with wikicreole and creoleparser due to a lack of good python markdown processor.
Because this really belongs in /r/learnpython (see the sidebar).
If these are patterns then 1+1 is an algorithm.
yeah sry I know. I didn't want to call it "random Python 'stuff'" ... 
Thanks! Now I just need to get it working.
I've been using this for a bit at work and it is so EASY. it does a an excellent job at making interaction feel like python. For instance, to get the values of a row all you have to do once you identify the workbook is Range(row number).Horizontal. Blank cells (between the cells with data) are returned as None, which if easy to eliminate or modify by a simple list comprehension. 
I see a few optimization points and would love to work on this a bit in my free time, will you be accepting pull requests -- or, do you already have a list of things you want improved before I dive in?
I work for a DMS and my entire job is running automated processes or writing new ones. The one I'm most proud of right now is a logic layer for infinitely-running processes that can determine problems on automatically deployed servers. Basically, these monitoring scripts can dig very deep into the system to try and automatically fix something that's causing a problem or any number of "solutions" given a matrix of thresholds. It basically replaces a few IT guys.
I'm going to take a break for a few days before diving into optimization so if you want to, please do, I'll be looking at all pull requests.
Oh didnt know Google's was dead. Thanks for that. Yea thats true, the program will not be exact, but atleast can give the User an idea. Also, you are right. Bottom-up would be a way better structure for this type of budgeting software. 
from the comments on that article. the credibility of this list beyond repair. Puppet - is open source configuration management **utility** CyberSecurity is the **practice** of defending information from unauthorized access Big Data is is an all-encompassing **term** for any [large] collection of data sets NoSQL is a class of databases SalesForce is a company Hadoop is a framework and so on. Whoever was compiling the list was totally ignorant. Piling up concepts, frameworks and utilites is akin to comaring popularity of Toyotas vs Sedans vs Cars of green color - in one word - pointless. but dont let things like this stand in the way of the circle jerk. everyone needs that release, it's healthy. 
TIL: a person thinks this subreddit is run by the psf. WTF? lol
that's nice...when are we getting one for Python 3.x?
All users need to have python installed though right?
Correct
sad face, no way they'd do that at work
If it's not rewarding to her then that might be why she didn't go your path.
To correct myself- Apparently you can call frozen python executables (cx_freeze, py2exe) from xlwings. Though this is annoying, and not as easily modified. Depends on what you plan on using it for
What's the error message? You could file a bug report on https://github.com/ZoomerAnalytics/xlwings/issues.
 &gt;&gt;&gt; from xlwings import Workbook, Sheet, Range, Chart &gt;&gt;&gt; wb = Workbook() &gt;&gt;&gt; Range('A1').value = '22' Traceback (most recent call last): File "&lt;pyshell#26&gt;", line 1, in &lt;module&gt; Range('A1').value = '22' File "C:\Python26\Lib\site-packages\xlwings\main.py", line 430, in value if hasattr(np, 'ndarray') and np.isnan(data): NotImplementedError: Not implemented for this type It appears that following the quickstart (http://xlwings.org/quickstart/ ) is the problem, and it doesn't like strings.
The issue has already been logged here: https://github.com/ZoomerAnalytics/xlwings/issues/73 I suspect that's it's an older version of NumPy causing it.
[py.test](http://pytest.org/latest/) provides a lot of options for test automation with python. It is not interactive but you can customize to take action based on failures or skip tests by marking them. 
Use docker
The windows 7.0 SDK that's needed for python 2.7 isn't too hard to install. The 7.1 SDK get's mad for all sorts of reasons, like the visual c++ runtime being installed. (Still less annoying to install than full visual studio IMO)
Could someone explain why this is useful? Sorry if this is already well-known to everyone else here, but I'm getting a mental disconnect with C++ compilers and Python package distributions.
if say, you wanted to distribute a windows installer for a python library that had C/Cython extensions. 
Building modules for Python 2.6 and 2.7 requires using Visual Studio 2008. VS2008 was offered as a free Express edition in the past, but I guess people were having a hard time finding download links for it, considering that it's three versions removed from the current version of VS. (Although you can find links on [this SO answer](http://stackoverflow.com/questions/15318560/visual-c-2008-express-download-link-dead).) Python &gt;= 3.3 uses Visual Studio 2010, which also has a free Express edition [which is not hard to find](http://www.visualstudio.com/en-us/downloads#d-2010-express). 
Many modules are implemented in C, and building them from source requires a working toolchain. Moreover, if you're using the official binaries from Python.org you have to match the same version of Visual Studio that was use to create them, which for 2.7 means VS2008 which is somewhat old and out of date and becoming harder to obtain. 
Fair enough! I hope that peewees simplicity is the differentiating factor, but I understand that doesn't always make sense for everyone.
For convenience, the project's [GitHub](https://github.com/rolandshoemaker/CommonMark-py). Got to say, I like where this project is going! Do you intend to add a renderer for RTF?
You need to use the same compiler version to compile Python extensions as Python itself was compiled with -- in this case, VC++9 / Visual Studio 2008. That's an old version and though you can still get its express edition, that express edition can't compile 64-bit extensions, and its just more then a little bit of a pain (and there's no guarantee MS might not take down that old version at some point). Packaging the compiler and just what is needed for Python extensions used for 2.7 (and allowing 64-bit compiling) means MS is making it easier for people to build 3rd party Python addons. This has been a long suffering thing for Python on Windows. 
The links in the text of your blog are almost completely indistinguishable because the link color is too close to the color of the text and there's no underlining. It's very user-hostile. You shouldn't have to mouseover things to discover links, mystery-meat style. I feel like there needs to be some kind of Monopoly jail where you have all your CSS taken away from you for a year if you're caught doing this. 
Wow! You feel very strongly. I'll try to get it fixed later this evening. Certainly don't want to be *user hostile* lol. **Edit**: OK, I updated the link colors to be a bit more saturated. Let me know if that looks any better or if it still needs more juice.
Google sheets now has a scripting interface where you can write JavaScript. 
It's not input in the sense of data input; see above edit.
If you had an init_app method (flask-peewee), I would use it. I could manage writing migrations by hand as well using the migrate and respective migrator class. I do like how you support sqlcipher though. I'm currently a sqlalchemy user but for some projects, I wouldn't want something so heavy with a packaged kivy app. Edit: Your library would be good for the raspberry pi
For sure, I'm rewriting a lot of that code...flask-peewee has languished a bit. Adding init_app is one of the first things I added!
Lol what do you think
Oh God.....
Anything that I need to do otherwise manually or semi-manually that doesn't involve elaborated thinking.
There are 1 to n numbers of worksheets in each workbook..... Google "python read excel"
[;-)]( https://lh4.googleusercontent.com/proxy/JdZUWLZfeKrqslRXV2DKVCEFB7EgClWZIQ8Y8h4de6ivQEkD8SA6Ph2-Fk7N2scEFR16iXCkr6vpnd1Y82YfbD9vgUo=w682-h384-nc)
Why throw-away account ???
Probably, eventually we'd like to add a few more renderers, PDF/RTF being the first...
My team at work has been using VS 2010 Express to build legacy C++ libraries which we are then wrapping with SWIG and using with Enthought Python 2.7 (32-bit). Seems to work ok. Should we be using VS 2008?
Pyramid.
The "complex block - alarming" is a [quote from Radon's docs](http://radon.readthedocs.org/en/latest/commandline.html#the-cc-command). I also put "moderate - slightly complex block" in italics when referring to "C"-grade. I did this because I was quoting from Radon, not to add emphasis. Whatever you may think about this post, or me as a person, or peewee as a library, I think SQLAlchemy is a fantastic tool and I thought my praise of it was quite unambiguous in the post. The post begins: &gt; SQLAlchemy is one of those tools that is so powerful and so well-established that it's hard to imagine a time when it didn't exist. Mike Bayer, the project's primary author, after what I'm sure was a lot of real-world experience, hit on the right amount of abstraction and API that pleases both die-hard DBA types as well as more casual users. I also wrote later: &gt; I bet SQLAlchemy can handle any query or relational structure you want to throw at it. Additionally, the unit of work and identity-mapper patterns provide great performance and solve some problems you might encounter when using an active-record ORM. Being built from the bottom-up, SQLAlchemy also provides nice APIs no matter how near or far you want to be from SQL. I wasn't trying to argue or sell anything in my post. I was just wanting to talk about why I like small, hackable things, and that I hope that peewee is just such a one of those things.
What was said to you. Also it's quite a - how to put it mildly - stupid decision to not compile with Mingw on dozer. Yes it takes some magic when you have GCC and WIN32 defined, but it could be done and should be done.
as a prospective user, the first thing I want to know is whether using it will make _my_ code simpler than the alternatives. :)
curious to know what you guys plan on making with this! im even more excited about real world applications
&gt; Whatever you may think about this post Obviously I thought the post was a little weird how much time it spent talking about SQLAlchemy, when it's titled "The Case for Peewee ORM". &gt; or me as a person, We've never met! I don't know anything about you and I have no judgments of any kind. I'm only responding to words I've read on a web page which have a lot to say about my primary software project. &gt; or peewee as a library I find Peewee very intriguing, I've gone over its source and approach, and I don't believe I've ever said anything derogatory or even doubtful about it. I've probably recommended it a few times to people who wanted something small and fast. &gt; I wasn't trying to argue or sell anything in my post. Charles. The post is titled, "The Case for Peewee ORM". I read the post with the assumption that its content is primarily focused on the exposition of that theme. Of course when it gets into comparison of cyclomatic complexity of code between two libraries, underneath the umbrella "The Case for X", call me crazy, just seems like the point of all of that is to...you know... make the "Case for X". &gt; I was just wanting to talk about why I like small, hackable things, and that I hope that peewee is just such a one of those things. It totally is!
VS 2008 would probably make life easier but what you are doing is probably better future proofing. 
It was supposed to be used only on a local network. But it is easily extendable to use ssh.
AFAIK Python 3 works with the stock compiler, since its builds are continually updated.
Someone actually needs to create this *compiled version*. Also, not every package with C extensions has a prebuilt wheel available.
&gt;"how do I code this" style of question to check out /r/learnpython Please note that generally questions that consists only of "how do I do [copy/pasted assignment text]" are removed. See [this FAQ entry](https://www.reddit.com/r/learnpython/wiki/faq#wiki_can_i_post_my_homework_or_assignment.3F). Before you submit to /r/learnpython please read the sidebar and try to follow the guidelines as much as you can and not break any rules. P.S. If anyone has any questions, suggestions, complaints or anything similar regarding /r/learnpython they can PM me or use the "Message the moderators" button in the /r/learnpython sidebar.
This is a tiny wrapper around [keyring](https://bitbucket.org/kang/python-keyring-lib) and [onetimepass](https://github.com/tadeck/onetimepass).
Better would be LLVM/CLang. 
Someone already compiled a package? Take lxml for example. I still get the "error: Unable to find vcvarsall.bat".
**http://blaze.pydata.org/docs/latest/backends.html** (pandas, sqlalchemy, postgres, mongodb, pytables, spark, ...) http://continuum.io/blog/blaze-migrations http://discoproject.org https://spark.apache.org 
My own little framework that I created experimenting with a "more testable web framework": http://pythonhosted.org/avalanche/
VS 2008. You can sometimes get away with mixing C runtimes when using VS 2010 for Python 2.7, but its begging for crashes in strange places.
appreciate for explaining. 
If you think this is useful to you: you might be working with Python 2.7 on Windows then? Let me recommend you Anaconda distribution. It comes with tons of packages precompiled (there's always a need for more though), and so you don't need to compile them on your machine. You don't need to download "installers" and install them, instead you can use `pip install` which is scriptable. We use Python on OS X, Linux, and Windows, and we've settled on Anaconda as it is the least painful of the ways to cope with a mess that is Python on Windows.
Probably 80-99% of the time using the newer compiler will still generate perfectly compatible assembly, which you have been experiencing. To be 100% sure though you want to use the exact same compiler.
Is anyone else having a hell of a time trying to get distutils seeing the vcvarsall.bat from this?
Thanks for the feedback. Perhaps this blog post would be helpful: http://tech.scorebig.com/post/98238529604/continuous-deployment-with-elita-tutorial-part-1 I'm working on more posts in the series as a friendly intro to Elita.
This course is also [on Udemy as a video course](https://www.udemy.com/coding-for-entrepreneurs/)
I've been slowly poisoning the bad sysadmins at work (figuratively, not literally -- ie talking bad about them to superiors) while bolstering the good sysadmins in an attempt to get Python to be a part of the default provisioning for all machines. We currently have pressure in the Windows server space and have it as a part of the default image on all developer machines but servers and dev machines make up about 25% of all machines in our enterprise. We still have a large number of business machines that we're trying to get it on for better assistance from IT development for them.
The compiler isn't the problem; you need the same CRT. 
I saw something the other day (after I got the same error with pyodbc) that you need to make some registry changes even after you get the right compiler. 
True, but `pip` also works. It uses `gcc` when it needs to compile.
/r/learnpython
Can anyone explain me why node and R can build packages from source without visual studio, and python can't?
i wonder if it's to compile win32 or COM extensions?
It depends on what your extensions are doing -- it may work fine and dandy, then crash. The prolem is the CRT and things like FILE* pointers -- if your extension isn't ever passing resources that are specific to the CRT back and forth between the 2008 Python code and the 2010 extension, you're fine. Its just a bit hard to tell when that would be an issue so its safest (best?) to use the same compiler (and thus CRT) that Python itself was compiled with.
in bottle you do from bottle import request in pyramid, your view takes a request object among other things. pyramid is clearly easier to test than bottle since it doesn't depend on as many magical globals especially something as important as the current request. 
What you are describing sounds like an interactive / semi-automated hardware test application - a test and measurement system. How are you interfacing with the motor hardware? E.g., collecting motor performance data and both monitoring and controlling the state of the test apparatus? I'm not aware of a generic framework which supports these tasks (although, if one does exist I would like to know), but some hardware interface, and test and measurement vendors provide Python (or Matlab or LabView) libraries. I recently used the 8/8/8 Interface Kit from Phidgets to automate a manufacturing test for an analog timer device with Python. Phidgets' Python library is quite nice - low level coding issues are abstracted away, and your control / test script runs as an event loop so no need to explicitly poll for state. http://www.phidgets.com/ Is this along the lines of what you are looking for?
To be honest, I kind of wanted a)to learn python b)Development time in python is much shorter than C# from what I can tell c)Avoid technical debt. it would be easier to find or to teach a programmer python than nUnit or xUnit. Mind you this is just my opinion I'm not versed in either framework so I don't really know their popularity
email me with any questions you got: estoqese@gmail.com
Lots of packages are pure Python/JS/R/whatever, and each language can build those packages easily. Some packages have compiled parts, typically in C. I think this is fairly common in Python and R, and more unusual for Node, but I don't know much about Node. Building these from source requires a compiler, and it's generally a good idea to use the same compiler as the language itself used. The Python Windows installers are compiled with VS, so that's the best way to compile extensions. R may prefer a different compiler. Finally, that only applies to building extensions from source. CRAN, the R equivalent of PyPI, frequently offers precompiled binary packages for Windows and Mac systems (see e.g. [RCurl](http://cran.r-project.org/web/packages/RCurl/index.html)). It's increasingly common to do the same on PyPI using wheels, but this hasn't always been the case.
I'd never heard of peewee until a couple of days ago. I am mostly a Django guy, but I have a little side project that I've been tinkering with where django would be overkill. Even SQAlchemy was more than I wanted to implement; I just wanted a small wrapper to simplify working with a local SQLite database, nothing more. After playing with peewee for a few days, I can say that it fits my use case perfectly. I wouldn't necessarily use this as the backbone of an enterprise-level app, but for what I'm doing right now it's awesome. 
I created Watson about two years ago now (and have been working on it since), I'd consider it quite easy to write testable code with :) Its quite different from a lot of the Python frameworks out there in terms of how is structured (doesn't focus on "middleware", utilises IoC etc) http://watson-framework.readthedocs.org/en/latest/. There's quite a few good frameworks linked off the official Python docs too :)
Thank you so much for the feedback. I originally wrote peewee for exactly the purpose you describe! Glad to hear its working well for you!
If there's an API that is exposed and they require you to pay, that's because there is value in the data or they spent time/money on gathering it. Don't be a dick and just scrape it anyway because you don't want to pay. Somebody out there did work to produce it and you obviously need or want the results, so just work out a way to compensate them.
That's exactly what happened to a health-services statrup in SF last year; they were scraping a bunch of insurance sites in violation of their TOSes and one of them added auto-blacklisting for fast requests that are probably scrapers (but not an indexer bot). They had to go with their hat in their hand and ask to co-develop an API and pay for the data.
I don't disagree with this, but my experience is that almost every question seems to already be answered on SO. It is rare to google something that does not get a relevant SO hit near the top. What a knowledgebase. 
Okey doke, I spent part of today breaking up those methods, and we have gone from: lib/sqlalchemy/engine/base.py M 948:4 Connection._execute_context - E lib/sqlalchemy/engine/reflection.py M 436:4 Inspector.reflecttable - E lib/sqlalchemy/ext/declarative/base.py M 132:4 _MapperConfig._scan_attributes - E lib/sqlalchemy/orm/collections.py F 853:0 _instrument_class - E lib/sqlalchemy/orm/loading.py F 217:0 instance_processor - E lib/sqlalchemy/sql/compiler.py M 1964:4 SQLCompiler._get_colparams - F M 1467:4 SQLCompiler.visit_select - F lib/sqlalchemy/sql/selectable.py M 719:4 Join._join_condition - E 6124 blocks (classes, functions, methods) analyzed. Average complexity: A (2.61806009144) to: lib/sqlalchemy/engine/base.py M 948:4 Connection._execute_context - E lib/sqlalchemy/ext/declarative/base.py M 132:4 _MapperConfig._scan_attributes - E lib/sqlalchemy/orm/loading.py F 217:0 instance_processor - E 6149 blocks (classes, functions, methods) analyzed. Average complexity: A (2.61148154171) pretty much same average complexity but those big scary F's and half the E's are gone! happy hacking and thanks for the advice.
Well the anime site thing is the closest to theft scrape I did. And the deal there was: the content was free, but you had to wait between downloads. But you couldn't just queue the downloads with a timer. The urls changed after a bit. For years I had used the site manually downloading each episode of 300+ episodes of anime. Then I learned python. And I don't do the mechanized clicking anymore. automated everything. But I wouldn't have paid them any money either ways. What difference does it make if I do it or ,my computer does it? And the content in the site was most likely pirated. Anime is not supposed to be free.
What are the multiple factors? 
Just TOTP for now.
Personally I'm a big fan of using Werkzeug and sort of building my own framework: https://warehouse.python.org/project/Werkzeug/
Please let me know if there is anything I can do to improve the question!
On the same note, I would encourage experts to go there to help answer questions too. It doesn't help if we have just a whole bunch of beginners waiting for good answers. 
When cythonizing your code it's very useful to look at the actual C code that gets generated so you can see where you are hitting the python API. Using an ipython notebook makes this really convenient (see: http://nbviewer.ipython.org/github/iminuit/iminuit/blob/master/tutorial/hard-core-tutorial.ipynb)
Is this AppScript? 
In that context, the double asterisk means a function call with a dictionary as keyword arguments. It's quite simple: &gt;&gt;&gt; def test(name, age): ... print("my name is %s and I'm %d years old" % (name, age)) ... &gt;&gt;&gt; kwargs = {"name": "bob", "age":32} &gt;&gt;&gt; test(**kwargs) my name is bob and I'm 32 years old You can see how the dict values get extrapolated by the dict key. --- edit: By adding ** to your function ~~call~~ definition, you're going to capture all named parameters (not specified by the function signature) into a dict, so it would be the reverse operation as stated above: &gt;&gt;&gt; def test(**kwargs): ... for key, value in kwargs.items(): ... print("%s =&gt; %s" %(key, value)) ... &gt;&gt;&gt; test(name="bob", age=32) age =&gt; 32 name =&gt; bob 
This is a perfectly acceptable way of reliably sending a file, even if it seems a bit ugly. It's not that robust but it'll work in most cases. You should probably use a library abstraction, but under the hood this is what most libraries will do (with additional error checking). Some may also send a file in chunks to allow streaming, but this is not strictly necessary. Is this part of a larger protocol you're building? If so, a better option may be to use a header and specify a content length instead of using an EOF footer. HTTP does this, and also uses boundary delimiters to allow for multiple files (or regular text) in one message. Content length also gives you a bit of implicit rudimentary error checking. You may also want some sort of timeout feature, both for the content length and the magic footer cases, in case it's stuck reading the socket forever waiting for 5000 bytes and only 4900 bytes have come in while the rest were lost somewhere, or waiting for a footer that never comes. You could also just use HTTP(S)'s file handling capabilities.
Have a read of this one: https://docs.python.org/3/howto/sockets.html There's nothing particularly wrong with what you're doing other than the lack of error handling. Depending on what kind of network you're doing this over, you might want to increase the buffer size from 1024. There's nothing particularly wrong with defaulting to system page size buffers (since the OS will be allocating that space anyway). That'll be 4k on most systems. The next step would be to do it again using asyncio so that your app can get on with other things (like the UI) while the file transfers. 
What library?
FTP comes to mind. Old, but simple. https://docs.python.org/2/library/ftplib.html
Using a length header may be a better idea, then. Or perhaps "max" lengths and then checking for EOFX after you've fully buffered the stream. I'd also say that it's probably a better idea to just use an existing protocol for this instead of rolling your own.
Maybe paramiko does what you need?
&gt; What is the better way to send large files without adding custom text? In my case, I was using EOFX. You may not realise it but you've written a file transfer protocol. In your protocol EOFX signifies the end of a file or command. Other protocols often use numeric values signifying various operational states (http and smtp for example). You need some way of telling the client that the transmission has finished. EOFX isn't a very good way here. What happens if the file you transfer contains EOFX and it falls on the end of the read buffer? Instead of ending the transmission with EOFX you could prefix data with the byte count that will be sent. The client will know to receive data until that many bytes has been sent. If you're doing this for educational purposes then perhaps read about some of the file transfer protocols commonly in use. If you're looking for a real-world solution then you're probably better off looking for a library that manages either file transfer or reliable message passing (eg. zmq).
Haha, anytime. Yours is now officially the first repo I'm following on github. Thanks for the kickass docs, by the way. 
You might be able to use Scapy.
It's for educational purposes but the educational part isn't writing a protocol. 
do you use an arduino or something like that? That sounds like geek love for me :P
I always thought it meant a pointer to a pointer, like in C. I guess I didn't try it in python.
That syntax kind of sucker-punched me as well coming from C. I remember when I started learning python seeing somewhere a class constructor like this: class Child(Parent): def __init___(self, *args, **kwargs): Parent.__init__(self, *args, **kwargs) Which made my brain hurt, but you get used after a while.
One line. Command line: [python -m SimpleHTTPServer 80](http://www.pythonforbeginners.com/modules-in-python/how-to-use-simplehttpserver/) First browse to the directory that houses your desired file. Next execute the above to serve that directory. On the computer where you want to download the file, open up a browser and open up `192.168.0.23` (or whatever your IP is. use `ipconfig` if you're on Windows, `ifconfig` in linux, or `ip addr show` if you're using a more modernized distro)
/r/learnpython I believe the mods want this sub for python news, like "check out this library that does xxx" or "GvR declared Time Man of the Year" or "Come to PyCon IE where we'll drink guiness, sing songs, and write our best code ever but forget, in the morning, how we did it" 
OP has said its for educational purposes. So doing: import library_that_copies_files library_that_copies_files.send(somefile) has absolutely zero value over implementing it themselves.
So, I read that you're doing this for educational purposes which is great, but in general I would recommend using scp as a secure, easy to use alternative. That said, here's some tips: 1. It's probably a good idea to setup some sort of metadata payload in addition to the file. Useful for listing filesize, filename, etc. This payload could also have an "error" entry that would be checked. 2. Large files should be done with streams of some kind. You're custom text is acting as a payload delimiter, although it's somewhat error prone since you're not doing bitstuffing, or escaping. In essence, the classic way to handle this is for the sender to replace all instances of some "magic" keyword with something non-magic, and the recieving side to endo those transformations. This is a basic encoding system. 3. I started writing a basic implementation, but halfway through I found this: http://pymotw.com/2/zlib/#working-with-streams. It's a pretty complete basic working server with streaming compression. Using zlib (what powers gzip) to serialize and deserialize the stream saves the hassle of worying about magic strings. The main enhancement I would do to the above example is to add json metadata request/response payloads in addition to the zlib stream, giving you more flexibility. JSON is nice for over the wire transfer since it's human readable and it escapes all newlines, so you can just read the stream until a newline char and then `json.dumps`, which isn't too tough to setup, especially if you cheat and use `socket.makefile` and use `file.readline`. HTH 
It's sometimes referred to as the 'splat' operator. Here, or in any kwargs, a double splat.
Well, "API for morons" is exactly the use case that I was thinking of. I'm a moron and I work with a bunch of morons maintaining a large code base, which sometimes means setup a broad stroke of what we're aiming towards and bang our heads against the keyboard until we get what we want. This is not ideal for software development but is an industry reality and we cannot do much against it. The ramifications of this are many, and boy could I tell you stories. But one of the worst kind of "gotcha" moments we have had is people swapping or adding arguments while refactoring. This is obviously caught by our extensive unit tests 99% of the times. But there's a 1% of corner cases that bites you in the ass. So I consider the solution is moron-proof code. I'm sorry I could not provide any particular code example without having to drop some context, but I think you get the idea. I think the whole "we're all grown ups and code should treat you like that" sometimes gets in the way of "There should be one obvious way to do it.", so I rather force someone to call the function I'm defining the way I want it to be called, but you're free to change my view if you think there's a better way.
It's self documenting. What do you think this means? create_employee('Bob', 'Sales', 3, 40, 41, 178, 2) And this? create_employee(first_name='Bob', last_name='Sales', pay_grade=3, age=40, shoe_size=41, height=178, nchildren=2) I made this example deliberately confusing to show that the position of an argument contains very little semantic information compared to a keyword. I think keyword-only arguments are very useful for functions where two or more of the arguments are easily confused. (Also, functions like `print()` don't work without them.)
Constructor that allows for any aribitrary arguments made to a parent class: def SomeClass(ParentClass): def __init__(my_args, *args, **kwargs): super().__init__(*args, **kwargs) do_stuff(my_args) In this case, I use the `my_args` parameter, but otherwise instantiate the parent class normally without knowing anything about it's initialization class.
Actually since python3 (3.3 I think) the asterisk alone at the begging, middle or end of the function declaration is valid. 
It can be very useful when consuming an API, actually. For example, I recently had a situation with a CLI tool written against boto where I had a combination of no less than four different sources of configuration: * defaults * environmental variables * a command-line argument that gave a complete URL to an S3 bucket * a command-line argument that a file on disk to load options from These each were useful in different cases (on a machine in our VPC, on a desktop machine, for testing, etc.). Rather than have a maze of nasty if statements, each source had a corresponding function. We feed an (initially empty) dict through each function, accumulating settings with the appropriate shadowing behavior. So, when accessing a US Standard bucket with explicit credentials, we might have: config = {'host': 's3.amazon.com', 'aws_access_key_id': '...', 'aws_secret_access_key': '...'} But if we needed to access to a bucket in South America allowing boto to automatically use role credentials from our EC2 instance, we'd use: config = {'host': 's3-sa-east-1.amazonaws.com'} When finished, we have a dict containing the various options that boto.s3.connection.S3Connection expects, like this: s3conn = S3Connection(**config) As it happens, the combinatorics explode fairly quickly. If explicit checks are used and individual function calls are written; you end up with a nasty maze of if-else-statements and largely duplicated function calls. Taking it further, we sometimes know the region rather than the host endpoint. While we could have done the translation ourselves, it was easier (and saner) to defer to boto.s3.connect_to_region in that case. The ** syntax was also useful here because we sometimes has 9 different arguments in our dict, but the difference between these calls is only one of them. Rather than having lots of explicit parameter games, we can just peel off the one we're interested in (if it's there), like this: region = config.pop('region', None) if region is None: s3conn = S3Connection(**config) else: s3conn = connect_to_region(**config) As you might imagine, having the individual concerns separated into neat functions and using the config hash to make the final dispatch as simple as possible is very handy.
As a different example, consider that some API provides a class. You want to subclass it to override a few functions, but you generally don't want to touch the meat of them. In that case, you may want to pass through a function call unmodified, but do some book-keeping. Without splat-notation, you'll need deep knowledge of their (hopefully unchanging) API. Every time they evolve their API, you'll need to release a new release to match their new parameter signature (even though you are just passing it along). Consider subclassing Thread to log when a thread is initially created. The naive version might be: class LogThread(Thread): def __init__(self, group=None, target=None, name=None, args=(), kwargs=None, verbose=None): print("created") super(LogThread, self).__init__(group, target, name, args, kwargs, verbose) As you might imagine, for what it does, this is very brittle. If Python 3.10 adds a new option, all of your code will need to be updated to account for that option (and its default, etc.). The future-proof way would be like this: class LogThread(Thread): def __init__(self, *args, **kwargs): print("created") super(LogThread, self).__init__(*args, **kwargs) Taking it a step further, you can also cleanly intercept arguments with defaults. So you could do something like: class LogThread(Thread): def __init__(self, *args, **kwargs): name = kwargs.get('name', '&lt;unnamed'&gt;) print("created {}".format(name) super(LogThread, self).__init__(*args, **kwargs) If you want to prevent the argument from reaching the parent class, you can use pop instead of get. The point here is that you have a strong ability to programmatically construct function calls either to reduce a complicated situation to a few function calls or to carefully wrap other code.
Another concrete example that's out in the wild, consider [Django-ORM's field lookup syntax](https://docs.djangoproject.com/en/1.7/ref/models/querysets/#field-lookups). While parsing something like {'headline__contains': 'John'} may seem obtuse, it's probably as precise and succinct as any other way you could try to write the query.
Having only one way to do it is idiot proofing but also within the zen of python.
CubicWeb.
If you'd bothered to read the bug report; the packaging standard of Debian and Ubuntu require these separate modules split out; this includes stdlib in python. There was packaging problems that caused ensurepip to be broken, hence anything (like pyvenv) depending on that is subsequently broken as well. One of the people working on the fix is a Python core developer, so its in good hands. 
This is why you should **never use the system python for development**. Leave it there for the bootup scripts and other system tools, and do your Python development in a proper Python environment like [Anaconda Python](http://continuum.io) 
As a side-node, it's `python -m http.server` if your python points to python3 (like it does on Arch Linux)
Yeah... I didn't actually mean it was broken as in broken. I was tired and needed to vent and something I had not liked about PyEnv made me call it 'broken'. Uh. Keeping the bad comment here to remind me not to vent again. I try not to do such thing and I failed.
&gt; I don't know how to type the numpy arrays, Well, probably there's your problem. Look it up in the documentation, do it, and see what happens. You might also like to start with a simple function (e.g. reimplement `max` for arrays) just to be able to easily test the different type options.
I think it's quite cute. Unpacking the arguments with \* and \** can be thought of as a kind of single and double indirection, so borrowing the pointer syntax makes sense.
You are sending the file in binary format, which is good. But then you use a very simple text key to signal end-of-file or error. What if the file contains only the text "File not found \n EOFX"? Or if it contains multiple instances of the string "EOFX" inside the file? Better to have the first packets be some kind of handshake. Return the filename and file size first, then just send packets until the end of the file. The receiving end knows the size, so he will receive packets until he reaches the appropriate size, and as an added bonus he can save it as the correct filename. This means you do not parse the binary data at all, you only read it and write it straight to disk. You still need to worry about how to encapsulate your filename and size. I recommend [pickle](https://docs.python.org/2/library/pickle.html). import pickle,os filename='myfilename.txt' filesize=os.stat(filename).st_size handshake_packet=pickle.dumps((filename,filesize)) self.ssl_socket.sendall(handshake_packet)
I'll be a bit pedantic, but the question says "over TCP", not "over HTTP".
If you need more customization, check out [CherryPy](http://cherrypy.org/). There are many advantages to using standard protocols over rolling your own (security, better network optimization, error handling, etc).
&gt; Writing software for fun is one thing, recommending other people use for real programs is another. The Linux kernel. A real program. Written for fun. Please don't discriminate against software written for fun, that's mean and elitist.
There is nothing Flask related in this session. And you don't even tell people to cache results that you get from those APIs.
It looks like all operations are on numpy vectors. If they are long enough, then there really isn't much you can gain by converting to cython. The code spends virtually all of its time in well-optimized C code. The interpreter overhead is tiny. Your best hopes are: 1. Look at the underlying algorithm rather than the implementation. Try to do less work. 2. Parallelize. Numpy is smart enough to release the GIL during a low-level operation on a vector. You may be able to use multiprocessing.pool.ThreadPool to perform some of the operations in parallel, depending on the serial depedencies of your code. Use only floating point numbers of a single size. This will help numpy get the most from SIMD. Use float32 if accuracy is sufficient, float64 otherwise. 
Not sure how to make a virtualenv, but I'll google around. Thanks for the suggestion, hopefully that works. I'll let you know if I figure it out.
Make something before you try hacking. I've used tkinter but a lot of people say wx and Qt are way better - I wouldn't know.
There's actually an error in that file: it uses a tab on that line and spaces above. I've never run that script before because I use Macports and never ran the version of the file that comes built in. If some of the other suggestions don't work, you could always fix that line by replacing the tab in front of 'continue' with eight spaces, but I really recommend getting away from the version of Python that ships with your Mac anyway.
Nice explanation! 
This is part 4. We will get to the cacheing. Also, we're learning a full stack approach, and right now we're hitting the front end. So, yes - there was little actual Flask-related material in this session. If you're more interested in Flask, check out the first 3 parts [here](https://github.com/realpython/flask-single-page-app) or my Discover Flask [series](http://discoverflask.com)
Hopefully. The Twisted devs are horribly arrogant and insulting to anyone who doesn't share their religious-cult-like design philosophy. And when [compared to other options](http://nichol.as/benchmark-of-python-web-servers), it's one of the worst technologies out there. I avoid any project that uses Twisted like the plague.
I agree with /u/henrebotha, start by writing code first. If you end up not liking writing software then you're probably not going to like pen testing or related careers. Also, the most successful pen testers are also reverse engineers which means you have an understanding of how the code functions at the kernel level (which btw, is not something Python you're going to get from Python). **TL;DR** Write code to understand how things work first, that's the start of a path to a successful pen testing/reverse engineering career
My general point is, why call it *Discover Flask* if really most of it doesn't have anything to do with Flask itself like *List Comprehensions*, *Virtualenvwrapper* or all the *Heroku* stuff (Flask is a WSGI framework which makes it agnostic for pretty much every deployment method). And even the database stuff and SQLAlchemy is not really related to Flask. And now you're going into API consumption and frontend frameworks? Why don't you call it *Discover Web Development*? Because, let's face it, in real life the web framework quickly becomes a minor component in your overall system/architecture. Now, why am I saying all this? Because what I think beginners will do is (and I see this a lot here on reddit and in IRC) they will try to "integrate" every possible thing into the web framework's application. That's a really bad idea because it'll become a monolithic beast that's impossible to scale up. This might not be a problem if they're just fiddling around but if they're really ambitious about becoming a web developer where do they learn how to build stuff with scalability in mind?
I had to click the link to figure out what the title meant. These libraries and their weird names.
You're right, I was drunk. Thanks for correcting me.
I think you're confusing new users of Python with new users of r/python
Glad to see a Peewee and SQLAlchemy discussion with Mike and Charles ending on a positive note :-) Mike - SQLAlchemy is wonderfully powerful. Charles - Pewee is indeed small, hackable and fun. As a beginner Python programmer it's great to be able to choose the right tool for the right job. Thank you both!
I will not dispute the negative comments people here make towards twisted, but i want to explain why i use twisted: To my knowledge, no other async networking framework has the amount of protocol support that twisted has right out of the box. I am not happy with many things in twisted, but not having to start your server implementation from scratch is a really big plus if you have to get things done. Also, async process interaction which works cross platform.
Yeah, I wasn't talking about the splat operator itself, more using it to force calls of your functions to behave in a certain way like the person I replied to had suggested.
Not at all. It's been production-quality for years. It's just that the documentation is terrible. So bad it seems almost wilfully designed to put you off using Twisted. Every time I read one of glyph's blog posts, I think, "how detailed and well written. So why are Twisted's docs so hard to follow?"
Why can't they be both?
One of the simplest way to represent a variable length string is [netstring](https://en.wikipedia.org/wiki/Netstring) it's more sure to use than your current protocol. Other thing that could fail in your protocol it's that your file contain `"File not found"`
Then it will be a little more complicated. If the file is well named, maybe you could then use the package 'guessit' to extract informations like title, season number, ... and use opensubtitle/ podnapsi/... APIs.
It's unfortunate so many frameworks fail to package properly the core features in a way people can clearly differentiate them well from higher level functionalities. &gt; Let’s begin with the most enduring reason that Twisted is not going anywhere any time soon. asyncio is an implementation of a transport layer and an event-loop API; Twisted is also an implementation of a transport layer and an event-loop API. It’s also got a coroutine scheduler, in the form of inlineCallbacks. then a long list of what Twisted also is. It's brilliant that it comes with battery included but it makes it sound big and complex and might have scared people off. Other frameworks have made the same mistake: CherryPy (its internal pubsub interface is great but lost in the whole web app framework, which is why the project has started splitting those into [independant](https://bitbucket.org/cherrypy/magicbus) smaller [components](https://bitbucket.org/cherrypy/cheroot)), Tornado, ... Sometimes it's too late to clarify the message. In that respect, Zope is an interesting example. When they started Zope 3, they had the right mindset but they failed at changing the name which carried such a heavy history. 
It's hard to tell the future but is there a requirement for a Python HTTP/2 server?
I'm guessing that's because people seldom offer to actually fix the docs or they read the docs and decide to move on because they feel exactly like /u/Proselyte5 does. Twisted is not as 'pretty' as newer libraries out there and most people's projects are not complex enough to really require something like Twisted instead of implementing a solution another way. Twisted is definitely not experimental, it's used fairly heavily by several major companies and projects: https://twistedmatrix.com/trac/wiki/SuccessStories http://twistedmatrix.com/trac/wiki/ProjectsUsingTwisted
Doesn't Tornado do a decent job? 
Of course it does. They just didn't care to try. 
&gt; How am I supposed to know what urlretrieve does, and how it differs from urlopen? Google it. The first result is [the answer](https://docs.python.org/2/library/urllib.html#urllib.urlretrieve). You shouldn't really have to do this though, I don't know why the function doesn't have a docstring.
I hadn't seen it. Thanks.
The docstrings are just a summary. [Read the actual documentation](https://docs.python.org/2.7/library/urllib.html) for full details. 
Does tornado support anything else apart from http out of the box?
Would you mind pointing out where you think i am wrong / which things tornado supports that i don't know about? I have tried to figure out why you might say that, but from what i can tell, tornado isn't nearly as comprehensive as twisted.
&gt;How are you interfacing with the motor hardware? E.g., collecting motor performance data and both monitoring and controlling the state of the test apparatus? We already have the hardware (it's a development board), and already have the software libraries on both the target hardware and on the PC for controlling our motor. I'm looking for more of a top-level framework for doing this kind of thing. &gt;Phidgets' Python library is quite nice - low level coding issues are abstracted away, and your control / test script runs as an event loop so no need to explicitly poll for state I'll take a look... not sure how I could use it with that pre-existing software, though.
Yes. The underlying implementation of Tornado's HTTP server is based on a generic non-blocking socket IO wrapper, with pipe and SSL-aware subclasses. There's also a "low level" [non-blocking TCP server implementation built-in](http://www.tornadoweb.org/en/latest/tcpserver.html). I obviously don't know your use case but for me just the TCP server is enough, everything else we use is just built on top of it.
Ok, but it doesnt come with (mostly) complete protocol support for ftp, ssh, xmpp, irc or whatever - that's what i've tried to point out with my post. When i'm going to implement a protocol by myself and there is no need to support anything else, my choice usually isn't twisted. 
This article is funny. Having set back the Python community for the best part of a decade through their inability to easily port to Python 3 (indicative their code is very bad) and causing that fracture into 2.x and 3.x camps for so long; now that they're losing users in droves as everyone is moving to Python 3.4 they feel to come out with this "hey! don't leave us! Stick with us and one day we'll put out a Python 3 compatible library! Honest guys! We've done *nothing* in the past 8 years, but you can trust us!" Once again, hot air and handwaving and no code. Good riddance. 
To illustrate this one, I actually like to pick on what I consider a failing in the standard library. Quick, what's this do? import re re.sub('[aeiou]', '.', 'A string with the VOWELS replaced with dots', re.I) ... and how quickly can you figure out why?
http://robotframework.org might work for you.
a. This is good b. That's true c. It depends your location, here is more easy to find C# devs, but of course, you can teach Python to a kid.
Well, to be honest, I think you know that Twisted and Tornado are kinda different things, although serving relatively similar tasks. Tornado is just a framework, while Twisted is full on server with an event-driven engine (Twisted). Both can handle async operations on high load. Tornado does a decent job, and Twisted of course does it too. I'm not saying you're wrong mate, I'm saying Tornado gives you enough tools (and to my memory, much better docs) to develop the same environment as you'd do in Twisted.
Thanks for the clarification - i bet it does, and it's likely that it does a better job at that than twisted (i haven't yet used tornado to implement any protocols myself). All i'm trying to say is you'd have to implement the protocols you need yourself, which, depending on the scope of your project, might take up a lot of resources. Especially if you consider that most of twisteds protocols are being used in production systems by someone and already had their share of fixes and improvements.
Pelican is typically the go to when it comes to static python blogs. There's a decent amount of themes and you can typically find external blogs to help you through the setup if the documentation isn't doing the trick. You can host via github as well as it being Markdown based (for writing simplicity) The other alternative would perhaps be Ghost, not python though but simplifies the process and Digital Ocean have a ready to run ghost installation if you want to host with them.
I'm as much of a Python enthusiast as anyone. But Why not use Wordpress? Consider: Tons of available learning resources at all levels; easy to use hosted service at reasonable prices; tons of available themes and widgets. Edit: I was referring to using a Wordpress.com hosted blog, not setting up &amp; maintaining Wordpress on a server. 
Mainly just don't want to deal with the security &amp; maintenance headaches of php, wordpress &amp; MySQL.
If you host her blog at http://www.wordpress.com, you won't have to. They do all that. Your wife just tends to her blog, and you stay married. :/) 
If this is an educational exercise then there are a few things to try. f.read() without parameter reads the entire file. If the file is larger than the available memory (or swap space) then we will have a problem. So I always specify the buffer size, like f.read(4096). If the goal is to improve reliability then a hand shake protocol can be added to annotate packages and acknowledgements (on top of what TCP already does). This can be done in the same data stream (with packet headers and payloads) or with a separate control stream. One can also add check sums for increased paranoia. Reliability for large files can be improved by dividing the large file in smaller chunks, sending and acknowledging them individually. Again using a same or control stream. File chunks can be sent in parallel via different sockets. Some bookkeeping is needed to reassemble the chunks. Think of torrents. Exercise for the reader: determine the optimal number of connections, number of chunks and size, and the buffer size. In general, end of file markers are not needed if only one file is sent at a time. Just open the socket, send the data and close the socket. However, if we do this, we have no information about the file (ie name, size, permission, etc). So we don't know whether the file exists or we are allowed to access it. For this type of information, we insert meta-data into our data stream or we use a separate control stream. We can also slow down the transmission, for example to limit the bandwidth usage, by adding delays between packages. The OP seems to be using ssl_socket already, so no need to mention about encryption for security. If the goal is to improve speed, compression can be used also. 
Why not install SAMBA/ SMB on Linux Box or Webdav Server, then you can access it as an Windows virtual partition through the network and see the files as they are locally. 
It has widespread usage due to legacy. When it first came out, it was the only game in town for asynchronous networking in Python, especially on the server side. Now there are a myriad of better alternatives.
Wordpress and the like aren't static. And that is a no-go for some people. For example, my university offers free hosting. But their version of PHP and MySQL are too old to be usable. Wordpress just isn't an option for me. And static hosting is *much* cheaper and securer. Github does it for free.
Wouldn't that mean that people can easily, through no fault of their own, create datasets their colleagues cannot read? Of course, any such communication **should** be using defined protocol numbers rather than 'the default', but it seems like a problem to have a default value for the API that is not lowest-common-denominator.
https://en.wikipedia.org/wiki/HTTP/2 http://http2.github.io/http2-spec/
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**HTTP/2**](https://en.wikipedia.org/wiki/HTTP/2): [](#sfw) --- &gt;__HTTP/2__ (originally named __HTTP 2.0__) is the next planned version of the [HTTP](https://en.wikipedia.org/wiki/HTTP) network protocol used by the [World Wide Web](https://en.wikipedia.org/wiki/World_Wide_Web). It is based on [SPDY](https://en.wikipedia.org/wiki/SPDY). HTTP/2 is being developed by the Hypertext Transfer Protocol Bis (httpbis) working group of the [Internet Engineering Task Force](https://en.wikipedia.org/wiki/Internet_Engineering_Task_Force). ([bis](https://en.wikipedia.org//en.wiktionary.org/wiki/bis) means "repeat" or "twice" in musical notation or accounting.) HTTP/2 would be the first new version of the HTTP protocol since HTTP 1.1, which was standardized in RFC 2616 in 1999. The Working Group plans on presenting HTTP/2 to [IESG](https://en.wikipedia.org/wiki/Internet_Engineering_Steering_Group) for consideration as a Proposed Standard in December 2014. &gt; --- ^Interesting: [^SPDY](https://en.wikipedia.org/wiki/SPDY) ^| [^Hypertext ^Transfer ^Protocol](https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol) ^| [^List ^of ^HTTP ^status ^codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes) ^| [^Jetty ^\(web ^server)](https://en.wikipedia.org/wiki/Jetty_\(web_server\)) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+ckv9io8) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+ckv9io8)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
SeeAlso: /r/Python/comments/1xn24p/http20_for_python/
I recently posted a couple of posts related to choosing Pelican for my static blog as well as my process for configuring it. So far, I've been very happy with it but there is certainly an amount of technical work required. Why I chose Pelican - http://pbpython.com/site-tech-1.html How I configured it - http://pbpython.com/pelican-config.html Hope that helps.
Why Python based? Why not just use Wordpress or something. If you are insistent on Python, use Django. 
I've seen a fair number of tutorials for setting one up in either Django or flask. If you have the time, you could build one for her using those frameworks. Realpython.com had some blog post and some extensive lessons on it in their book series too.
Now post tomorrow's discussion and I'll be *really* impressed! I think you have to import something from future....
I know you said static, but if you're looking for something python based there's always Mezzanine: http://mezzanine.jupo.org Its based on Django, so it uses a database but its easy to setup, works right out of the box, and has an admin interface.
And even if twisted doesn't have the exact protocol needed, it has a plethora of basic foundation protocols that can be extended to make nrw ones. time is money, twisted saves time once you invest yourself to learning it.
Socrates - https://github.com/honza/socrates * Familiar Django and Jinja2 templates * Simple install via pip * Markdown, reStructuredText, Textile support * YAML configuration * Atom feed * Github pages compatible * Real HTML punctuation
Wow, wow, wow!!! I am about 800 lines into translating a 5500 line VB macro to Python. Thanks :D
Would you consider something on node? ghost is a rather nice tool. 
You need to free Your mind and feel what Guido is trying to tell You... Ommm.... Seriously - RTFM, its clear and obvious, python docs just one of the best out there. urlopen just opens url and keeps content in the memory, while urlretrieve copies content to the file in case You are working with some serious web page, or maybe just want to save it for later. And urllib is really outdated, You should stick with at least urllib2 or better urllib3.
I use pyblosxom for my blog. It's... not convenient to use. And not maintained very much these days. I want to migrate to something modern.
Nope. Thanks for the information. I was trying to illustrate why in general silently defaulting to new versions is bad because it might break compatibility with old code. I guess this example failed.
Text based as in command line? Or in a Browser? Or in a pygame container? You might want to provide more information about the environment you are working in. As of now this is not a python related question.
Since nobody has mentioned it, I'll go ahead and put in a word for Nikola. Easy to setup and use for most needs with github pages and IPython notebook integration and quite a few other features right out of the box.
I love namedtuple as much as the next guy, but remember that they are effectively slower than a plain indexed access on a regular tuple. Most of the time, it doesn't matter, but if you have some crunching to do (that you don't want to do at the C level) keep that in mind. 
Both are fine. People here will prefer Python. IDE has nothing to do with that. /r/learnpython.
Also could someone please explain to me what connSKT = (AF_INET, SOCK_STREAM) means. Thanks
Downvote. I am not going to copy paste you the socket call man page. 
A lot of docstrings (which is what pydoc shows) in the standard library are incomplete. pydoc also shows a link to the official Python documentation on the web; those docs are of a higher quality. In my experience, patches that improve stdlib's docstrings tend to be accepted -- but of course they will show up in a new Python version (like 3.5). (This is why 'pydoc optparse' now has a small usage example -- I submitted a patch. Of course optparse is now deprecated in favour of argparse...)
What does it read into? A dictionary?
I don't want you to im just asking what is going on because it wont connect to any ports. Is this because of the code or because all the ports are closed? 
OK dont worry I got it working.
I used blogofile and found it to be a good fit for blogging.
If are seriously concerned with performance, I'd recommend against Python.
Hi, thanks for the reply, what I was asking is if I can generate a kind of vnc object and use to access in a programatic way the remote computer through vnc protocol, just like paramyko does for ssh.
Not at all. If I have to create an application that is interactive, and must perform some operation at every keypress in a decent amount of time so that snappy feedback is preserved, then you need a fast lookup, but going at the C level means losing portability and it's generally overkill. Using a high level language does not mean throwing all performance needs out of the window because "python is slow, just use something else"
If new users of Python want to contribute something positive to r/python (or to lurk), then of course they're welcome. If they just want help with their homework and ignore the rules of r/python then they're not. BTW the sidebar already points such people to r/learnpython. I'm not advocating a change in policy, just a clearer advertisement of it.
docstrings should be the same as the actual documentation. afaik the doc generator grabs docstrings for use in the docs. it's what docstrings are for.
Fair point, I was imagining some kind of long running number crunching job. 
Yes there are &gt; The [server](https://github.com/vhakulinen/bruno-server) is written in Python and the [client](https://github.com/vhakulinen/bruno-client) in Go. https://github.com/vhakulinen/bruno-client https://github.com/vhakulinen/bruno-server
Word of warning, are you *sure* you have permission to release this code under a FOSS license? Some schools (at least in my country) own the code students write when working on school projects. If this is not a problem, good luck with your project!
I use [pelican](http://getpelican.com). I simply edit articles and pages in markdown, then run pelican in the base folder, and upload the output by ftp. Here is [my blog](http://www.lfdw.fr) if you're curious (it's in French) 
For that we have [NumPy](http://www.numpy.org/), in which most operations are vectorized in C and so is quite fast. 
What script causes this? And it could still be some way you have configured all of your Windows installs.
Indeed, it's definitely an issue with your system. Probably a bad driver.
Not that much slower i = collections.namedtuple('Foo','a')(5) j = 5, %timeit i.a 10000000 loops, best of 3: 86.5 ns per loop %timeit j[0] 10000000 loops, best of 3: 33.3 ns per loop 
Indeed, not dramatically slow, but in some applications and having to perform that lookup many times, it introduced a noticeable and annoying delay. I agree it's nitpicking, just wanted to throw two cents.
What activities do you find inconvenient? 
Also [PyPy](http://pypy.org/)!
Another vote for mezzanine. I had been using pelican for quite a while, but I found that I pretty much stopped posting anything small because it felt like too much effort. I switched over to mezzanine and love it. I myself am using the markdown editor, but op's wife may prefer the wyswyg built in editor. Being able to tap out a short post with no additional effort really makes a difference.
'include' is one of the worst names you could think of for a library. It would be much less confusing and have much less risk of overlap with other poorly named libraries if you name it something specific to your project. 'bruno' seems like the logical choice.
Neither did mine, and I'm very grateful for that.
'is' checks for identity (physically the same object/address in memory). '==' checks for equality (same value). For them to "sometimes" be equivalent, it is because Python is interning strings (using one only object for multiple vars as their values are same). When you change one, it will make a new copy for that and may or may not intern it, in a way you should not depend on. Do not rely on this behaviour. Use == for equality and is for identity.
Thanks for the tip! I'll look into it when I'm working with it next time 
A BSOD in Windows is a unrecoverable kernel error. This is hardware, system service or driver configuration issue. I don't dispute that its only happening with Python. It means the Python interpreter is using some part of your Windows system that is in some way broken. *If you save the crash dump from the BSOD, a competent Windows tech can often track down the fault.*
I know OP requested for a python solution, but using the Github static hosting and [jekyll](https://help.github.com/articles/using-jekyll-with-pages) it should also be straightforward to set up a blog.
Encrypted calling? if so make it have support for PGP keys!
It's sort of silly and not really on the point, but like 10 minutes ago I figured out that print(*list_of_items, sep='\n') is the same as for i in list_of items: print(i) 
I use Pelican as well, absolutely love it. The config has evolved a bit over time, but posting is a breeze now.
I've started [dirtyblog](https://github.com/dirtycoder/dirtyblog) for my own usage, it's a simple "blog". Before "refactoring" for extract a class, it was 90 lines of Python, Flask and Markdown. I use it on the Heroku "free-tier", it don't serve static files, so it can be a bit hard for your wife if the posts have a lot of images, etc. It's not fully static, some parts are dynamic and it's on very, very, very early state, don't recommend it, but you can take a look. :) I'll add a post-editor with simple preview any time soon. Btw, feedback is welcome. 
Did you research what solutions were already available? https://tox.im/
Any work on a new WSGI spec (a horrible idea already, WSGI is so loaded with crap it should be replaced entirely) that doesn't include framework and WSGI server authors is bound to fail. This is going to end up where all the previous discussions about replacing WSGI ended up so far, forgotten in a mailinglist archive somewhere.
That error is not sufficiently descriptive to tell you anything, you need to look at the crashdump. If lots of people are saying they have the same error, and you have not compared crashdumps, then what you are all in fact saying is *we all had many different errors that caused the same eventual crash*. There is a difference. I agree with all other posters, some issues with your system, and different issues with all the other peoples systems, that result in the same error. It might be mildly interesting to know what you were doing in your script, other than that the conclusions is *your system is broken*.
glyph is definitely correct, in pretty much everything he said. Nevertheless if asyncio is adopted and libraries and protocol implementations are built on top of it, twisted is going to die very quickly. That is unless they get their act together and finally start documenting twisted properly until then it's always going to remain a niche, filled with people that stumbled into twisted and didn't manage to exit the maze again. Then again asyncio is not really going to go anywhere anytime soon as long as Python 2 is still going strong, which at this point is probably going to be the case indefinitely.
Requests is pretty handy, but in general just a wrapper over urllib3 nowadays (previously it was built over urllib2), nothing special. Still You need to implement timeout for slow requests by Yourself. Not the socket read-write timeouts, if You know what i mean)
To clarify, I'm looking for something in between a shell and an editor. I'd like to write some code and test it without having to save each time. I know the shell can do that, but I'd like to write multiple lines of code before testing.
I'm probably leaning towards Pelican, and then maybe writing a frontend using Dillinger or something. I've built a couple quick projects with it, but nothing major.
Check out [IPython](http://ipython.org/). It does what you want and more. 
Also aindex = i._fields.index('a') %timeit i.a 1000000 loops, best of 3: 203 ns per loop %timeit i[aindex] 1000000 loops, best of 3: 130 ns per loop %timeit j[0] 10000000 loops, best of 3: 86.1 ns per loop If you're concerned about speed in tight loops, you might be doing this anyway. Note that the variable lookup appears to be the cause of the slowdown in `i[aindex]`, as: %timeit i[0] 10000000 loops, best of 3: 86 ns per loop `namedtuple` is basically identical in performance to `tuple` here. In actual function definitions, I believe Python will use CSE to determine that the aindex reference can be replaced with its constant value, so the actual performance difference between `i[0]` and `i[aindex]` usage in functions is probably nothing
cool, but does it work for windows?
We never found anything like that, which is why we went the route we did. 
As a matter of technical interest, what are the benefits of Golang and Python for this project? I'm remembering Go being mentioned as good for systems-level tasks, so I'm guessing it's a good fit for the soft real-time requirements of voip? I guess I'm asking- what do these two languages do well in this project?
There's [py2app](https://pythonhosted.org/py2app/) but haven't tried it yet.
Come join Tox! It's also looking to take down Skype, but without even any servers.
to go further, since it seems to be an exceedingly common newbie mistake: you basically never use 'is', except that it's idiomatic to use 'is None' or 'is not None', and even then == would work just as well.
&gt; realtime constraints because VoIP should be realtime &gt; python Dude, stop right now, if you want to make it a proper project. For school it's OK
&gt;Been working in this couple months now and this morning successfully transferred &gt;live audio between peers. "Mr. van Rossum — Come here — I want to see you." 
http://www.codecademy.com/en/tracks/python has been invaluable to me, great for the basics.
really nice!
&gt; IMO your greatest challenges will be stuff like brokering connections and preserving latency. Do you have latency metrics so far? I have no latency metrics so far, but that is definitely a problem I'm looking to face and try to solve it. Thanks for the wikipedia link, I was aware that there will be problems with latency but wasn't sure why was it, how to fix it and how others have fixed it. Quick look through the wiki page, it seems that hole punching is one technique to solve this problem, which I'm using but it won't of course work in all cases. &gt; IMO you should consider using existing protocols designed for solving problems in this space. It's nice to invent the wheel all over again sometimes :) And yes, the mighty goal is more like a "tongue in cheek" thing but you'll never know where projects like this leads to.
I have multiple crash dumps saved. 
Upvoting for relevant historical reference.
Don't know why this is downvoted so much, for me this question was educative, I learned that identic short strings are represented by CPython with the same identity(memory address), and how to correctly use is.
Why another python shell , when Ipython is much more than a python shell.
(author here.) This is not an alternative for IPython, it could work together with IPython. IPython is rather an execution environment, it implements smart stuff like the %magics etc... and you have the notebook. But this library could be used as the commandline front-end for IPython. Right now IPython uses plain readline for the reading input in the shell. And the problem there is that readline does not support decent multiline editing or syntax highlighting. This library (mostly) solves just that part, reading the input from stdin and returning it to the application. So, it is already perfectly possible to use IPython, but with this as a better front-end for IPython: https://github.com/jonathanslenders/python-prompt-toolkit/blob/master/bin/ptipython I hope that answers your question.
The theme is called "pure".
Going into a loss of redundancy scenario to do regular maintenance is not acceptable for my business, nor is master down time. I can either upgrade a slave, promote it to master, swing the app over to use the new master, lose redundancy or depending on the version of postgres add a slave to the new master in advance. Or I have to bring the master down, swing connections to another site or cluster then resync the data back. Mysql use master master with a slave attached to each. Do one half of the cluster at a time, then flop clients over then do the other. Done, no loss of redundancy or role change required. Cassandra, configure an appropriate write factor, bring down the appropriate number of nodes for maintenance, then bring them back up. postgres and redis have horrible operations stories if you need your cluster to; 1) be available during maintenance 2) not suffer a loss of redundancy during maintenance 3) do not change the role of any specific machine during the process Postgres does not hit all of these. 
&gt;Right now IPython uses plain readline for the reading input in the shell. And the problem there is that readline does not support decent multiline editing or syntax highlighting. This library (mostly) solves just that part, reading the input from stdin and returning it to the application. That is quite interesting. I do not like ipython's Notebook interface , and i prefer terminal interface but , ipython terminal is quite limiting so i ended up using ipython qtconsole, which is not much maintained these days. I gonna give it a try then! Would be nice if ptipython is part of ipython.
[Engineer](https://engineer.readthedocs.org/en/master/intro.html) seems quite sweet. It's made by [Tyler](http://www.tylerbutler.com/) [Butler](https://github.com/tylerbutler/engineer).
Not awesome just my own :) https://github.com/pymag09
As part of my PhD work I built a software library for working with flow cytometry data. It's called [fcm](https://code.google.com/p/py-fcm/). I miss working with scientific python ecosystem.
Just in case: "It's wise to ask your employer or school, if any, to sign a copyright disclaimer for the work, so they cannot claim to hold it later. Below is a sample copyright disclaimer; just alter the names and program description as appropriate: Yoyodyne, Inc., hereby disclaims all copyright interest in the program “Gnomovision” (which makes passes at compilers) written by James Hacker. &lt;signature of Moe Ghoul&gt;, 1 April 1989 Moe Ghoul, President of Vice" - http://www.gnu.org/licenses/gpl-howto.html
MemoryTo***o***BigException
Stick some ZRTP / SRTP in there for good measure... may as well be secure.
Just curious, why don't you like the Notebooks? I find them incredibly useful for everything from hacking out ideas to writing code heavy blog posts.
http://www.instructables.com/id/How-to-Analyze-a-BSOD-Crash-Dump/ or google
I'm not /u/v3ss0n, but: Personally, I just don't grok them. Is there a decent intro on how to use them "right"? (As in, not just syntax and operations, but workflow and goals...)
It's just like having a REPL, except each cell is a block of code that can be edited and executed repeatedly. Having never used one, I imagine it's a lot like an IDE but browser based. Just make sure the notebook extension is installed and run `ipython notebook` and mess around. The first time I saw them, I was blaise about it. "That's cool, I guess, but why?" But after using them for a few months, I really love them. They're great for sharing snippets of code. I keep a repository on Github that I push my notebooks to in case someone wants an interactive version of a blog post. 
Coursera has an interactive python course running right now. It's in week 2, but you should still be able to join. https://www.coursera.org/course/interactivepython
Is this meant to replace BPython?
&gt; It's nice to invent the wheel all over again sometimes :) As long as your goal is to learn about the challenges and how you could solve them, sure. But otherwise it's not time well spent IMO.
It could replace BPython, but that's up to you. Tell me if there is any feature in BPython that is not present in "ptpython".
No, that's not how it works at all. Docstrings are plain text, the documentation is reStructuredText. This allows the documentation to have rich formatting, like cross-references, bold, italic, and fixed-width. The two are completely separate. To take a random example, consider `str.format`. [Here's the docstring from the source code](https://hg.python.org/cpython/file/c0e311e010fc/Objects/unicodeobject.c#l13519). [Here's the actual documentation](https://hg.python.org/cpython/file/c0e311e010fc/Doc/library/stdtypes.rst#l1565), which is much more extensive and has a link to the section describing the format string syntax. Docstrings are just a brief summary, they don't come close to documenting everything. 
Age of 18, school left min. 2 years (+4years for proper education), does competitive sports -&gt; no time for job. Time well spent IMO :)
I am the WORST speller ever
I'm not an expert on this, so I don't know if this will help in any way at all, but you might find something useful in [The Day of the EXE is Upon Us](https://www.youtube.com/watch?v=wsczq6j3_bA) by Brandon Rhodes from PyCon 2014. If watched it a few days ago and he does get into bundling dependencies, but your situation might be more niche/advanced than what he covers. Still, you might get in touch with him, or read some of his other work.
Is `filename` equal to the full path to the file? Or just `"doc1.xlsx"`, which is what the error message seems to indicate. My guess is that the `open()` function needs the full path. You want to `open(os.path.join(subdir, file))`.
Another issue with readline is that it is impossible to make filename tab-completion work correctly when the file names contain spaces. Or, at least, I couldn't get it to work. The IPython QtConsole doesn't use readline but also there I didn't manage to get it to work (forgot the details). It seems that [improvements on the tab completion system are deferred](https://github.com/ipython/ipython/wiki/IPEP-11%3A-Tab-Completion-System-Refactor). Could you configure, or program, your toolkit so that tab-completion searches for files (and only files) as soon as you are typing a string literal? Since strings are delimited by quotes, it should be possible to do correctly for files with spaces. In that case I think your toolkit would be very useful. 
OK. Thank you so much for reading the stickies and taking the time to format your question correctly, as well as using correct grammar. Please let me do your homework for you.
You mention that there is no support for Windows. I'm curious, what is the reason for this? Any plans to make it available for Windows in the future? 
the code is using looking for the xlsx files in "C:\Users\username\Desktop\Work\Python\excel practice\" and can't find them. do what symmitchry said.
Your problem is that slope1 is never defined. Look at the lines you define the variable on. there's a rather coincidental error in your semantics that makes this kinda funny. Also you have an o instead of a zero somewhere.
You're right. I'll pull it down.
A few months ago I started working on pyo, a Linux gnome-do/synapse/launchy replacement in Python using dmenu. It's rather simple, and that's why it works well for me. I think it's clear which files and programs it indexes and why results are the ordered the way they are. It's largely untested on other machines, though in theory it should work on any Linux machine with Python 3 and dmenu. Perhaps someone likes the approach or finds some useful code snippets in there. More details and source code can be found at https://github.com/tomasstorck/pyo. I'm open to suggestions and would be happy to explain anything that is not clear.
I found [Programming Collective Intelligence](http://shop.oreilly.com/product/9780596529321.do) to be a very useful read. I was working on a product categorization project a while back and the content of this guy was fantastic for that.
I made everywhere, a python console. By everywhere, I mean, anywhere I can type, I can run python code. Console? Yup. Git? Yup. Outlook? Yup. Gmail? Yup. Password box? Yup. Excel? Yup.
I wrote this little program which just checks to see if your server is up and writes it to a log. If it isn't up, or is throwing something other than a 200 OK it begins playing a police siren until it is back online. Not very awesome but still enjoyed developing it.
put them on stackoverflow where there's an actual upside for answering those questions every 2 weeks that they are asked. or keep it to yourself and google like an adult. 
+1 one for scientific python work! Analyzed 1TB of GIS data across 8 cores. While it wasn't the fastest processing, the .py file was about 100 lines and the multiprocessing was super easy to set up... Makes me want to learn AWS and rent some uber cloud computer to crunch through an obscene amount of weather data...
You launch IDLE via its shortcut in the start menu, not by double-clicking python. Look for "IDLE (Python GUI)" under the Python 3.4 folder of the menu. If you're using a version of win8 that killed the start menu, you should be able to just type IDLE into the stupid metro search window and get the IDLE shortcut.
Multimillion dollar SaaS companies are written in Python...
kivented a 2dgame level editor - https://github.com/chozabu/KivEntEd kiventeds server - http://www.kiventedserve.chozabu.net/ (not so awesome) and boardz - game made with levels from kivented - http://steamcommunity.com/sharedfiles/filedetails/?id=311355825
Good job on this project. I use bpython all the time for it's autocomplete. Small error though, I submitted an Issue for it.
I haven't tried `GladeBuilder` yet, but I had another idea to make Glade files a little easier. [Glader](https://github.com/welbornprod/glader) will parse the glade file and generate python code for it (stubs for the signal handlers, and widget initialization). It doubles as a quick command-line tool and a GUI with syntax-highlighting for previewing the code before writing it out. Requires `Gtk3` and `GtkSourceview` though.
My latest brilliant idea is [ccat](https://github.com/welbornprod/ccat). A syntax-highlighting `cat` command. It can still concatenate files, but that would be kinda dumb to write out color codes to a file. '`echo "this" | ccat`' also works. It uses [Pygments](http://pygments.org) to automatically highlight all kinds of code files. Anyway, I heard some guy saying that he always uses '`cat this.diff | colordiff`' or '`colordiff file1 file2`' and it made me think of it. Pygments can do this on its own actually, I just gave it a shorter name and some defaults.
I like Nose tests, it's lightweight and has extensions for things like Coverage. It's basically the primary testing suite in Python (very few people solely use unittest.) I was able to get from nothing to solid code coverage within a couple of days. 
Here's a [link](http://np.reddit.com/r/funny/comments/2hu6x0/harry_speaks_python/) to the referenced post.
im sorry for being unspecific, its text based as in command line. 
I'm just now learning python and we use flow cytometry extensively in my PhD lab. Might check this out! Ty 
I like py.test. [Here's a video from PyCon 2014](https://www.youtube.com/watch?v=AiThU6JQbE8). Simple, easy to learn and master, but powerful enough to do anything you might need.
I really want to use the Notebook more. But if I'm using ipython at all, I'm probably in a debugging mode where I need to print a lot of things. When I write a loop that uses print() too many times, all the ipython tabs in Chrome crash. Does this not happen to other people?
That is certainly be possible. Thanks for the feature request!
Great. I'll keep an eye on it.
thanks man, i feel a bit dumb now aha :D
This is something I've wanted for a while, thanks for sharing.
Awesome work, this is really terrific! I wrote an alternative frontend for bpython recently and also eschewed curses to build my own terminal wrapper with hardcoded vt100 escape sequences. In writing a new frontend I had to tackle some of the problems it looks like you dealt with really well - layout, resizing, paste mode, reimplementing readline, signal handling etc. I'm particularly interested in getting horizontal window resizing to work - I've got a technique I'm working on but trying to set up testing infrastructure for various terminal emulators first. I'm excited to look at this more closely soon and have a few thoughts. Great work!
I am always wondering why WSGI is not as simple as def view_func(request, response): pass ?
This is really nice! My only immediate problem is it doesn't follow my .inputrc binding history-seach-backward and history-search-forward to the up/down arrows. Is it possible to get this configuration working with ptipython?
Thank you! It's a wonderful world, the vt100 escape sequences, and often it's more powerful than using ncurses. (btw, if something about the code is not clear, please tell me.)
Not yet. .inputrc is for readline, and this library doesn't use readline, so that clearly doesn't work. But I'm planning in the near future to develop a system for configuring custom key bindings. And maybe after that I could develop a compatibility layer to read .inputrc as well. But thanks for the feedback, I see what you mean, and I'll have a look at how to implement it. Right now, you can already to Control-R (for starting reverse-i-search), then typing what you are looking for, followed by the arrow keys. Or if you have Vi mode, there is also history based line completion. You type for instance "impor" followed by ControlX-ControlL and you get completion on all the lines even typed starting with this letters.
In my opinion py.test is the way to go. On EuroPython 2014 py.test was the most prominent testing framework. Test discory, very good context output in case of failing tests (includes optionally starting the pdb at the point a test fails) and the concept of "test fixtures" are the very strong points why I prefer py.test over nose.
As I pointed out in /r/funny, smallcaps fonts are a thing (and caps are pretty much the default for comic lettering)
Sure, but there were no large caps to show the small caps. 
That's because comic artists are widely known to discriminate against large caps ;)
thanks for this! i can get the nearby yaks just fine (and have verified that they're the same as the ones i get on my phone), but i can't seem to be able to get post_yak working... wondering if i'm doing something wrong.
Mine is [Sisyphus](http://github.com/lordi/sisyphus), a small programm to restart your compile/test/etc whenever one of your source files change, so you don't have to leave your editor to see the effects of a code change. 
This is my first experiment with Pygame. I hope you can get a chuckle out of it. I've created a little screencast here: https://www.youtube.com/watch?v=T08Oe1l7nhk (Recording audio for some reason made the game chug a little bit). I hope you guys can get it up and running. If you have a LEAP motion controller, you can also check out the "hhd" branch, which is a project I'm working on that will be a permanent installation for our office. My girlfriend is a designer, hence the awesome pixel art. :) Thanks!!!
The comic sans! Arrrgh 
I've got a podcast downloader that I wrote five years ago when learning Python, been using it daily since then. Even got it running on my phone via SL4A. It needs some work, but it's been pretty nice to me overall.
This question is best asked in [/r/learnpython](http://www.reddit.com/r/learnpython). See the sticky!
guess this should be a good place to start for pdf rendering https://code.google.com/p/rst2pdf/ 
For manga, the reading is right to left, top to bottom, "western end page" to "western first page", but this is not a manga. As far as I know, the japanese direction goes back to scrolls, where you would draw ideograms top to bottom, while unrolling the roll with your left hand. 
I read it as top to bottom, left to right, i.e. 1. Harry 2. Ron 3. Hermionna. it feels weird to "rewind" back up.
You can use os.system
I know. But that doesn't make it right. Also most of that stuff isn't real time critical.
while testing using `pip3.4 install prompt-toolkit` installation had got an exception after launching an `Meta-! ls` because it's using `raw_input` after doing a python2 installation it works correctly
It looks interesting. I'll take a look. GladeBuilder works with Gtk2 and Gtk3. Tested with Python 2.7 and Python 3.3.
thanks I will try that
great thanks.. I will watch the video and give it a try
Nice try, Tyler Butler.
You're right. Thanks for reporting! I'll fix this asap!
&gt; So why methods like: cmp, eq, (i dont know many others) have such a not explicit name. They _are_ explicit, they just are are abbreviated. So this is more a case of "readability counts". The trade-off here is length (in keystrokes) vs readability, and I guess the designers said "cmd and eq are such common abbreviations, that it doesn't really impact readability that much", and I would be inclined to agree. &gt; whats the point of self That actually _is_ a case of "explicit is better than implicit". See /u/amicab1's reply for that.
Built a library for pulling data from a polarized interferometer that is using a spatial mask. It extracts the data from the 4 phases, uses multiprocessing to a c library call that unwraps the phase data, applies some voodoo, then back into python to fit a zernike polynomial to the unwrapped data, passes that into IDL that does some automated blob analysis then back into python to tie everything together and scrub bad data runs automatically. Oh an a script that just throws random file names out to the console on one monitor so it looks like I'm working when reading reddit on the other.
I wrote Raspi-Sump. It monitors the waterlevel in my sump pit and emails me an SMS text message if the waterlevel rises above a critical level. It also displays graphs of sump pump activity to an offsite web server. It's a simple project but was fun to do and is actually doing something useful 24/7 https://github.com/alaudet/raspi-sump
thanks! you read my mind
A pacman like game framework (users have to write their own algorithms in order to run it) which we use for Python education: [Pelita](http://aspp.github.io/pelita/)
The video is dated 2011...
interesting, how exactly is that compatible with the programs youre running them in? or is it just for doing quick math somewhere? 
&gt; ncurses There is one pure python library like ncurse that is cross platform, i forgot the name , i will google and let you know. I think it supports windows well too.
Please edit your post to make the code formatted, and explain *what* you're trying to do -- both are unclear from your current post.
Great lib, thanks! I couldn't install PyCrypto on a computer because of the C-compiler dependency, and this runs so much faster that the python AES implementation I was using!
thank you!
That would be cool, thanks!
So do I replace the "print os.path.join(file)" syntax with open(os.path.join(subdir, file))? If so, I'm receiving the same error
Left to right is also acceptable. 
What would request and response be? Why is view_fun named view_fun? How is it discovered?
Whoa there, the bdfl says there's only one way to do anything. This isn't Perl here. TOP TO BOTTOM!
https://github.com/sibson/vncdotool Try that out.
request is the same `request` in Flask, Django, etc. response is something you can `write` into and close, so you can continue to post-response processings. I didn't understand your discover part. Care to explain?
Why not just include the requests code in your project folder directly if pip etc is an issue?
This was posted here about a week ago, really? Also, the "python" hasn't become any more correct since it was last posted.
Make your script keep a log, and then then after chunks of code, write 'Line X OK' or something like that. Find the offending line, then see what it is calling or doing. Or in a debug environment, step though the lines until it crashes. Compare with other scripts people are having problems with and see it you can recreate it with their scripts.
Exactly this. requests vendors its dependencies so including the requests package in your project directly is a simple matter.
&gt; I didn't understand your discover part. Care to explain? Let's say I provide webservices that conform to a particular industry standard (in healthcare), where the entirety of the specification need not be implemented (sort of like a la carte components.) How do I let the client know which of the available services defined in the standard are available? How would you accomplish load-balancing/reverse proxying with your view_func?
While working for my counties TV district, I set up a laptop which displayed the current weather forecast and alerts over a backdrop of a live webcam view of the town from the mountaintop where our transmitter site was located, as well as played old radio shows from the 30's and 40's and displayed emergency alert info. I used a stripped down install of ubuntu that loaded the Python scripts on boot. The display was implemented with pygame and all the rest was built in packages that handled fetching the weather and EAS data. The laptops video and audio was fed to a free stream of one of the channels we received over satellite, so 10.1 was WGN, and 10.2 was my weather/old time radio channel.
Why say they are in the right order? Is it not top left to right, go down left right, then last left right?
Can you ping me when it's done ?
Because WSGI is what people use to *make* request and response objects.
Yes, we are exclusively windows where I work. Using the notebook is more of a challenge but I think it's fine without it.
I understand what request is supposed to be but what exactly is it? What attributes and methods does it have? So response is the socket? Do you actually have to create a HTTP response by hand? Properly escape headers etc.? This is a lot more low-level than what we currently have, bound to produce not just bugs but security issues and would probably lead to quite a bit of code duplication overall.
If there's only one row then it's just left to right, there is no up and down.
The only place he could do that was for the variable names but then he would be violating PEP8.
You're welcome! Of course, there are lots of other resources on py.test, and shorter videos, but he's the master. That video can kind of be a pain to watch while they work on the exercises, of course, unless you do the exercises too. :)
Is there any easy way to call this from inside Vim? For example how *:!python* works?
Inlining is easier, and requests is a large dependency to include with lots of magic, in cases where all you want, need, and are willing to maintain is easy GET-requests.
My favorite so far is a program that allows me to using python slicing syntax on csv files: [gristle_slicer](http://www.ken-far.com/2013/03/gristle-slicer-of-architects-chairs-and.html) Next up: Spherical Cow - a program that knocks outliers off your data. Mostly just because I like the name.
Yes? And does this comic not have three rows?
The /r/funny post was probably from [this post](http://www.reddit.com/r/ProgrammerHumor/comments/2hg9k0/harry_potter_and_the_regular_expressions/) 5 days ago on /r/ProgrammerHumor (it received negative karma when it was first posted but then got more popular IIRC). The picture is probably a re-post anyways so whatever.
pYtHon is case sensitive?
Before I was hired in my company there was a lot of unnecessary tasks which now thanks to python we can avoid. The only way to export data from program which we are working with was printable txt file with not unified that but there was some patterns, I just used python magic to convert crappy txt file to xml and making some calculation which aren't hard but are really time consuming. 
This is really old but it came up on a google search. I'm interested in integrating the event loops of pyglet and asyncio, can you share more about how you accomplished this? Thanks.
I've read the front page, and some of the FAQ, and I still have no idea what this does.
Is this supposed to replace something like Celery?
I kinda wished it was clever. Unless there's some unspoken connection between filename exclusions and snakes.
Sure! Sadly I can't find *my* code with that, but I got the inspiration from a project called Touche. [Here's the relevant file where they set up the pyglet event loop to run off of asyncio.](https://github.com/pennomi/touche/blob/master/client.py) I hope that helps! If you need more help beyond that file, feel free to respond. I may not be a master, but I know asyncio in and out.
How about a version of Requests that works with Micro Python?
Great to see it happening. Python has a great potential to replace java and matlab. It can be a great simulation and teaching tool.
Just yesterday I made a joke about Harry Potter and Python... if this isn't a sign of some external superhuman power I don't know what is. 
That's the point, it's open to interpretation
Interesting, thanks! So you just need to manually fire off the pyglet events? Seems relatively straightforward. We're currently using pyglet's `on_update` events to implement behavior and `on_draw` to implement graphics. Pyglet handles mouse and keyboard events, of course. We're rewriting with asyncio so we can interface with other input devices. Sort of similar to what Touche seems to be doing with the server. One issue is that we want to record as much data as possible from the input devices even if it's not reflected on the screen, as they can be much faster than 60 Hz. So, my question is, how would you recommend partitioning these concerns between pyglet and asyncio? The last piece of the puzzle, I think, is how to present a united API with both the keyboard/mouse events from pyglet and inputs from other devices. One option is to have behaviors listening for `on_input` pyglet-style events, which could be dispatched by the asyncio coroutines listening on the devices. Alternatively, we could have the pyglet callbacks (`on_keypress`, etc.) set the result on a Future (or something along those lines, haven't yet worked with Futures directly) and have behaviors implemented in coroutines. What's your intuition there? I'm thinking the latter, to avoid callback hell. Or is there a third way, to listen for keyboard/mouse events directly in asyncio? And finally, a more general design question. Would an asyncio 'framework' for lack of a better word have lots of functions/methods that look like this: @asyncio.coroutine def run(self): while True: # If it's a thing that relies on input: input = yield from some_stream() do_something() # Or just something that needs to run repeatedly: yield from asyncio.sleep(0) do_something() And then to run you package them all in Tasks and fire the event loop? Sorry if this is an overload, I'm not looking for a detailed answer, just whether I'm thinking about this correctly, and if not maybe a gentle nudge in the right direction. I think I finally figured out how asyncio works but I feel clueless as to best practices.
Both of those are excellent. I also really enjoyed the application exercises for this one on EdX from MIT: https://www.edx.org/course/mitx/mitx-6-00-2x-introduction-computational-2836 The next one starts 10/22/2014, I believe
I'm not sure, what do you expect it do?
As someone who only needs to write programs periodically I'd love to replace my MATLAB programs with Python. We're license-limited on the former but everyone at the company has open access (and is encouraged to use) Python. The only thing stopping a complete switch is the learning curve, especially with regards to data manipulation and plotting.
Glad to see my alma mater shuffling in at 17 :D
I have done this. It sucks at first, but after the learning curve you will not regret it. This is assuming you don't use Simulink. Have people try pythonxy. They have made it a near clone of the Matlab environment.
I work for a DOE lab, and have been using python for about 2 years. Coming from a strong Matlab background I have been trying to get people on it at work for the day to day data processing and visualization.
This thread has been linked to from elsewhere on reddit. * [[r/programming](http://np.reddit.com/r/programming)\] [(X-Post from /r/Python) Top US universities teaching Python](http://np.reddit.com/r/programming/comments/2hxs8f/xpost_from_rpython_top_us_universities_teaching/) ^(*I am totes' unyielding will.*)
Just curious, are you yourself japanese? Or are you just trying to give your project more coolness by putting some japanese text there and giving it a japanese name? Ah, you are copying a ruby framework... which was based on an italian name, but since ruby was japanese, you used the japanese... only python is made by Guido, who is Dutch, so stencil should be called sjabloon or maybe merkplaat, depending on whether you mean the impression made by the stencil, or if you want to refer to the stamp... in any case, that's my feedback. I hope you appreciate it. By the way, John, you're from the USA, you might want to use USA words for things, like Rotary Drum Printing, now that was invented in the USA... I get that you are probably trying to appeal to the ruby crowd with this, since they would obviously search for the japanese word for stencil hoping to find a ruby library that does templates... but for python, we tend to put 'py' in the title somewhere. Maybe try 'pyTemplates'. or be even more clever "Tempylates"... nah, it doesn't roll off the tongue. Well, in any case, I don't like the name. We already have Jinja, pyJade, as I see you are using... what exactly does this program do? Are there any tutorials? 
In Markdown (the formatting system used by Reddit, among others), you have to leave a blank line before and after a code paragraph for it to be properly formatted. Here's what you were trying to write: def pyramid(m): for i in range (m,0,-1): print(('.'*i),i) if i==1: for i in range (0,m): print(('.'*i),i) Now, that has some very wonky indentation, but that appears be because you're using hard tabs but you prefixed each line with four spaces for Markdown, such that it's not actually inconsistent in your source file. In any case, you shouldn't use hard tabs. Read [PEP-8](http://legacy.python.org/dev/peps/pep-0008/) which is the official Python style guide. It calls for soft tabs at a width of 4, i.e. configure your editor so that when you press the tab key, you get four spaces added, not a tab character. Also, there should be whitespace on both sides of operators, and after commas, but not before opening parens of function calls or argument lists. Your code formatted properly according to PEP-8 should look like this: def pyramid(m): for i in range(m, 0, -1): print(('.' * i), i) if i == 1: for i in range(0, m): print(('.' * i), i) Now, let's talk about things other than formatting. That `if` statement is completely useless. `i` will by definition be equal to `1` after the outer `for` loop is done executing, so there's no reason to nest the second loop in the first loop. def pyramid(m): for i in range(m, 0, -1): print(('.' * i), i) for i in range(0, m): print(('.' * i), i) `i` is okay I suppose for variable names used as local variables whose scope is only a couple of lines, but `m` is absolutely terrible as a parameter name. If I give you just the signature `pyramid(m)`, what in the hell does that mean? Let's rename it to `depth`. def pyramid(depth): for i in range(depth, 0, -1): print(('.' * i), i) for i in range(0, depth): print(('.' * i), i) This produces output that looks like: &gt;&gt;&gt; pyramid(5) ..... 5 .... 4 ... 3 .. 2 . 1 0 . 1 .. 2 ... 3 .... 4 That's not symmetrical. That seems strange — is that really what you want? You haven't told us anything about what this is supposed to *actually* do, so we can only guess. I'll just have to assume that's what you want, but in the future it would be better if you explained more. This still contains some repeated code which can be eliminated by writing one loop. You can chain two sequences together with [`itertools.chain`](https://docs.python.org/3/library/itertools.html#itertools.chain): from itertools import chain def pyramid(depth): for i in chain(range(depth, 0, -1), range(0, depth)): print('.' * i, i) In this version I also removed the parentheses around `'.' * i`, as they are unnecessary. I'm on the fence as to whether that's more readable or not, so I won't claim that's an improvement.
Where did these rankings come from?
It kinda sucks on every platform imo. At least when compared to py.test which is just a joy to use.
Yeah. You can tell this is from /r/funny.
It's a redis-based queue (like [RQ](http://python-rq.org/)), but with an HTTP API. You would typically use it to distribute tasks to remote worker processes.
The entire foundation for both the CS and Informatics program at Indiana University is Python. Not sure how Mercer College is ranked that high but whatever.
I can run anything I can type in python. So, if it's predefined in advance, it can do anything that I want it to. My favourite, is just looking up a password.
http://sarge.readthedocs.org/en/latest/overview.html#why-not-just-use-subprocess http://ipython.org/ipython-doc/dev/interactive/tutorial.html#system-shell-commands 
ZotZot!
https://github.com/pypa/python-packaging-user-guide/issues/48 http://www.reddit.com/r/Python/comments/1qx2nb/distributing_python_3_applications_very_tempted/cdhnwku http://conda.pydata.org/docs/build.html http://docs.continuum.io/anaconda/pkg-docs.html http://docs.continuum.io/anaconda/changelog.html 
[EDIT] https://github.com/zopefoundation/zodbpickle/issues/2 (~shelve) ... https://github.com/jsonpickle/jsonpickle http://json-ld.org/#developers https://github.com/digitalbazaar/pyld ... https://github.com/pydata/pandas/issues/3402 (supports {sqlalchemy, csv, json, HDF5, ...}) https://github.com/dahlia/awesome-sqlalchemy#thin-abstractions (dataset (sqlalchemy, csv, json)) ... http://datashape.pydata.org/ http://blaze.pydata.org/docs/latest/data.html (supports {sqlalchemy, csv, json, HDF5, ...}) ... https://github.com/google/protobuf/ https://developers.google.com/protocol-buffers/ http://elasticsearch-py.readthedocs.org/en/master/transports.html#thriftconnection (supports {thrift, JSON,}) http://pyes.readthedocs.org/en/latest/guide/reference/modules/thrift.html#thrift (supports {thrift, JSON,}) https://github.com/elasticsearch/kibana 
Something I should mention, talk is kind of cheap. It's much better if you can point to practical outcomes on your resume - Python projects on Github, for instance.
a lot of the time I'm applying as a part of school so they get tonnes of applications. Rarely do interviewers have time to read the source code of the stuff you've done on github.
I do.
This is great! My dissertation software is single-file python libraries (For educational purposes) that you can import to access web-based data. It can't rely on any non-std libraries, so this is similar to what we end up doing. I've always been worried about how much I'm not doing that Requests does, when I rely purely on urllib. Something I'd be interested in - Oauth support. If you want to access an Oauth web app, you need to include a 3rd party library. For our project, I [trimmed down](https://github.com/RealTimeWeb/twitter/blob/master/python/twitter/twitter.py#L609) Leah Culver's OAuth project. Then I stuffed the necessary code at the end of my file. It's messy, and it may not be safe, but it went smoother than my attempts at correctly implementing OAuth from scratch. I hope that someone else with more OAuth experience could do a better job.
No, but simply being able to show someone that you've produced a real product with an easily understood value is useful. Nobody cares if you know metaprogramming (which I just learned today, whee!). They care if you know how to build useful software.
You're missing parentheses around the arguments for the call to `random.choice`.
I wrote up a section at the bottom of [my impressions post](http://ballingt.com/2014/09/30/prompt-toolkit.html) about this - it's everything I could think of off the top of my head in bpython that's not in ptpython that I actually like - I didn't include pastebin and save to file and other things that would be pretty easy to slap on there if you wanted them.
Misleading title, in the link it says, "The infographic shows the top 20 universities represented on CheckiO." So these aren't the top universities teaching python, it's just the top 20 universities tracked by CheckIO.
Try numpy.random &lt;http://docs.scipy.org/doc/numpy/reference/routines.random.html&gt;
You're also missing all indentation, use the wrong variable name for the loop counter, and have the counter decrement in the wrong spot. Also, this should probably be posted to r/learnpython. Anyway, here's code with all the corrections made: import random name = random.choice(['nicholas', 'brendan', 'justin']) guesses_left = 3 while guesses_left &gt; 0: guess = raw_input("Your guess: ") if guess == name: print "fuck you!" break else: print "I love you!" guesses_left -= 1 I'd suggest starting here: [Python.org](https://docs.python.org/2/tutorial/index.html)
You are using "guesses_left" to count but decrease "count".
I know this package is a bit old and hasn't been updated in a while, but I found it the other day and thought it would be a good reminder to post it here. If you want to tinker with music, this package is pretty great! It can even export to MIDI and play the sounds using sound fonts and FluidSynth. If you know other good Python package to work with music, please let me know, I'm interested!
SHARQ can be used when you require rate limited queues with constant flow. Celery uses the token bucket algorithm to rate limit but SHARQ uses the leaky bucket algorithm for rate limiting..
I totally do. If I'm going to talk to you for 30 minutes, I might as well look at your code for ~5 mins... odds are I'll probably learn more that way.
It's inspired by their generators. Instead of the repetitive writing of boilerplate code, this cli utility generates code for you and auto injects it into your code base. It's not really all that different from other scaffolding tools. Other generators give you the foundation but don't give you the generators like other frameworks have like Jeffrey Way's laravel generators. I wrote this tool mainly for speed of development in mind with addon functionality incrementally rather than just here's your directory structure and a bunch of packages lumped in together. Sure you can manually create blueprints by hand and then register them with your app but this does it for you along with creating unit tests. Also, everyone can use snippet functionality with their preferred editor as well instead of using this tool. This was a personal project that I built for myself and figured I would share since someone could use it (which is explained in the readme) but will work on making it more usable for anyone who cares to use it. I agree with your suggestion with the name. I should probably change it to match python community standards. Just like jinja is the Japanese word for temple, I didn't see any harm in it. I'll be sure to remove the japanese since I'm sure that they would prefer to use ruby instead. I'm not trying to appeal to the ruby crowd either. I just like how they're tooling works. Just like flask is to sinatra, I couldn't find any generators out there to make development go by faster as they would in padrino. I'm really glad you put a lot of thought into your response. I had suggested that some flask extensions have their own generators included but since there is a transition between flask-script to click, I don't know when or if that'll happen. That is for the maintainers to decide. It's a very simple tool. Clone the repo and create a symlink to the python script in the bin directory and run the command with the -h option. The source is available for you to grep if you don't feel comfortable. If you don't like it, just delete from your hdd. The only thing that's confusing is the model generator which is explained in the readme. I'll be sure to create a tutorial later this week. Seriously, I appreciate the feedback since there is no python community where I am as the meetup group doesn't ever meet. I am glad that you have briefly looked over this without even trying to use it. Thank you for your time.
The amount of grammar errors and typos on that README is outstanding
eh, knowing syntax and proper &lt;language&gt; type programming things isn't a big deal. They'll deal with it if you're bad once you're hired. It's better to be able to engineer your way through huge or tricky problems in a quick &amp; efficient manner. For the most part, if you say you python they'll expect that you python. They'll just ask you what kinds of things you pythoned and expect you to explain it. It's their job to be able to tell if you're telling the truth in an interview. Even saying that, most programming skills are language agnostic.
As someone that has interviewed many applicants for programming jobs (usually python specialists), I can say this: If your resume says you know python, I expect you to know generators, functional tools, decorators, and at least have some understanding of metaprogramming and understand when it might be used. Good luck. 
"Experienced in doing XYZ in Python Overall intermediate in Python" For example. 
I don't understand what this does.
Hi, NumPyPy dev. I was wondering about this part of his article: &gt; However, as I understand it, in order for this to work, the core needs to be part of PyPy proper, not a separate module. And that appears in fact that is the case: the core parts of numpy are contained in the module _numpy defined in the PyPy source directory micronumpy and they are imported by the NumPyPy package, which is installed separately. If all that sounds wishy-washy, it’s because I’m still very unsure on how this is working, but this is my best guess at the moment. Can you shed some light on this issue? Which parts of NumPyPy are not appropriate at the application level? Will much of it ultimately be moved to the interpreter level given enough time and funding?
ridiculous. DO put a link to interesting things that you've done (especially if you've done them and they are public) on your resume. i see plenty of developer resumes. those that include a portfolio (with code) typically generate more interest, or meaningful involvement with open projects. so yes, I do look and read at the code. IMO the skills section in tech resumes is all meaningless cruft anyway. It's all just meant to get past recruiters. That said, to your original question, put python first as your primary language skill and some fluff if you want (eg. passionate about Python!!) 
yah I fixed that. Thanks though!
Hey, I saw this tool of your before. This sounds cool, and this time I'm going to make a note to give it a try this week.
Prepend 4 spaces to each line. You can easily do it with sed: sed 's/^/ /' yourscript.py or python python -c 'print "".join(" "+line for line in open("yourscript.py"))' 
Great, will Continuum ever release a GPU backend for Numpy? NumbaPro seems to be pretty stagnant.
Google autocomplete results for "python ncurses vs" suggest they're talking about [urwid](http://urwid.org/).
That's good to hear, last time I was applying to work I was lacking in experience and I was lucky enough to have a great interviewer (whos now my boss) talk to me about stuff I've worked. I'm definitely going to direct people to my projects, I just never felt that people even mention it. Its reassuring that others are telling me to worry less about that 'cruft'. 
Thats exactly what i'm talking about. I want people to see this and talk to me about it. I just dont know how I can make it clear that this is what I'm talking about! Do i just say that? "Comprehensive understanding of Python design patterns, advanced topics." 
Why did MIT switch from Scheme to Python for their introductory CS course?
Last time around I was having troubles getting interviews for the first round. I wrote some pretty cover letters and got me through to the interviews where I was able to do the math and impress the interviewer. This time around I want to be able to be a bit more confident and get interviews through a solid resume that impresses people. I did a lot of work this term using Java for analytics with hadoop but I wish I was being more productive in Python. So I really want to try to get a job doing data science with python instead XD 
When you find a more specific question to ask, you should try asking it on /r/learnpython.
I'm definitely going to show them my projects. I want to specifically highlight some knowledge in python. I've only been programming for about a year and I've honestly been learning about and programming every day. I just don't know how to express that outside of the 2-3 projects that I have. I don't want to be that guy that lists all 9 languages he's written fizzbuzz in. I've tried a few languages but I've only done real work (job, side projects) in Python and Java. Should I even bother mentioning it to you? does "familiar with racket, haskell, c++" mean anything?
Fascinating. Thank you!
our university hosts these interviews so unless we apply externally, we really only get about 30 minutes, or 2-3 30 minute interviews spaced over a few weeks. (some companies like facebook have to have multiple rounds to cut people)
Thats great! What I might try to do is apply to companies a month or so earlier to avoid my schools jobboard system.
Thanks for that explanation. I guess I don't see much boilerplate code in python but to each their own. I will give it a shot. Yeah I'd rather keep python python. 
Interesting that the blog post got attention. The way we measured it was the cumulative progress through the CheckiO by .edu domains. Based on how many cumulatively points a university scored it got its place in the ranking. We plan to do such study regularly to see which universities have more profound students to play advance coding games 
What has this got to do with the request/response paradigm? Or WSGI?
About four years ago I replaced Matlab with Python for a project in a grad level math class. ( I believe I even posted the scripts here). When I presented it, everyone was like why are you using this? Now the whole department made the switch to matlab.
Try googling "audio fingerprinting". In Python there is this work: http://willdrevo.com/fingerprinting-and-audio-recognition-with-python.html Which lead to a package called dejavu: https://github.com/worldveil/dejavu
Have a look at http://ipython.org/
ooh, thanks for this!
[Eylean Board](http://www.eylean.com/?utm_source=Forum&amp;utm_medium=text&amp;utm_campaign=DMReddit) coud be a solution for you. It is not free for team use, however it is highly adaptable and expandable and offers a variety of features for you to use.
It's done: https://github.com/jonathanslenders/python-prompt-toolkit/commit/ae9ff537019566c42f3a9d77292e7a09e6cb770a Can you try again?
He's perfectly able to give a rebuttal though. Advice is not fact, and shouldn't be accepted blindly, allow the man a chance to discuss, offer alternative views etc.
Perfect, and it uses one of my favorite modules.
From the [documentation](https://docs.python.org/3/library/threading.html#threading.BoundedSemaphore): &gt; A bounded semaphore checks to make sure its current value doesn’t exceed its initial value. If it does, ValueError is raised. In most situations semaphores are used to guard resources with limited capacity. If the semaphore is released too many times it’s a sign of a bug. If not given, value defaults to 1. It then goes on to show an example of how a bounded semaphore could be used to ensure that you don't make a mistake when managing database connections. 
To prevent the console window from closing, don't double click on the script. Run it from an existing command line session. You're missing the `%` string formatting operator in the code that you posted, so it's going to die with a traceback without printing the results. However, that traceback will tell you exactly what the problem is, as long as you run the script properly. 
Now I want a t-shirt with "ask me about generators".
Everybody is different, but when I interview somebody who has Python on their résumé I assume they know all that. I'll check. If they don't, I'll assume they've lied about everything else, and not hire them. If they write “Comprehensive understanding of Python design patterns, advanced topics”, I'll assume they're lying. I'll check, and if it turns out they do know python, well ok then.
"Solar or nuclear?"
There's no point holding on to a counter variable you don't need: import random name = random.choice(['nicholas', 'brendan', 'justin']) for _ in range(3): guess = raw_input("Your guess: ") if guess == name: print "fuck you!" break else: print "I love you!" People often use while loops unnecessarily.
That's an awful way to put things on your CV/resumé. I have no idea what you mean by "experienced" or "intermediate". [RandomChance](http://www.reddit.com/r/Python/comments/2hy6r9/python_on_your_resume/ckx8gl4) gets it right - tell me what you did with it, and I can pick up on that later at interview. Plus, knowing that you "implemented a DAQ suite using sci-py to handle data normalization" tells me a bit about your skill level outside of the language basics, and opens up a conversation avenue at interview.
I interview people. I won't read your source code if your supporting documentation (cover letter, CV etc) rule you out. So, if I want a Linux kernel developer, and your documentation says you've only ever done web apps in Python, I'm not going to look deeper; if I want a Python web guy, and your documentation tells me you've done that, I'll give your code a look. You get about 60 seconds of my time here, so the documentation matters. If your documentation says you're potentially interesting, I'll look quickly at source code on github to learn a bit more about your abilities; it can swing me from "probably not interesting" to "has produced good code - let's give it a punt". I'm only going to spend about 5 minutes here, so make sure the repos you link to are well organised. And it *really* works in your favour if we invite you to interview; I will have read a significant chunk of your source code before you show up, and I will ask you about the project, in the hope of getting an informative conversation going. Remember that I'm going to lose 2 hours on the day just dealing with bureaucracy around the interview, plus the time I spend with you; spending another hour beforehand reading your code is worth my while if it means that I can get you quickly going to "I did this with threading, which gave me trouble because of the GIL; I then reworked it using the multiprocessing module and some clever metaprogramming, and got the system working". This is far more fun for me (and thus better for your chances) than a conversation that starts "so, what's a decorator? A generator?", and leads into you telling me about your stuff.
Thanks brother. 1. TIL itertools.chain. The chaining makes it so compact. 2. I know the parentheses are superfluous 3. I should have used something more descriptive than m, but, as i said, i still think in FORTRAN (implicit integers) and Pascal. Thanks once again for patiently writing out the good stuff. You are a kind man.
Frontend developer need a template engine for developer: ex: you have base.html defined 3 block header, content, footer. and you want extend base.html content block, you need template engine.
As student also looking to entering the world of work soon (though not as specific as Python) I'm really hoping that I get interviews where they ask me to solve something. It's one thing to say you can do something on paper but I like being able to do something to prove what I am saying I am capable of. Plus, it seems that it would be more conclusive to the interviewee whether they have impressed the interviewer as it comes down to whether they can solve the problem or not. At the end of the day, I want to be hired because they were impressed by what they saw not what I said.
perfect thanks a lot!
This is a good example of when github provides a good value for employment opportunities. I usually volunteer my github link so they can see real application of knowledge, because knowledge alone doesn't generally reflect on ability.
On a CV, do you recommend linking straight to my github profile or linking to specific projects? 
Link to the projects you want me to look at. I can find your profile from there if I'm interested, and you've pulled me into the projects that you think are your best work.
Waterloo?
Could you post the script.
This is a great way to interview. Rather than ask a bunch of theoretical questions, have people point to real-world examples of the work they've done. I interviewed some developers for a C# position a few years ago. I asked specific questions about their experience and history with the platform we were working with (Sitecore) and then asked about their experience with C#. At the time, it was difficult to find a Sitecore developer so C# was the main focus. The guy that got the job was the one that could point to real-world examples of the work he had done with C# and content management systems.
I understand what Jinja2 does, but what does this do?
You may not like this response, but I'll give it anyway. Install Python. Search google for "python + X" where "X" is whatever you are trying to do. You'll find a ton of blogs covering "X" and provide plenty of pointers to modules, etc to accomplish "X". That's how I started 3 years ago. Now, I use Python regularly for just about everything from language processing, sentiment analysis, data analysis and building websites (via flask).
To or from matlab?
GOT IT! * import random * def diceroll(): * print("Rolling the dices...") * print("The values are %d and %d" %(random.randint(1, 6), random.randint(1, 6))) * * while True: * print("Do you want to roll the dices?") * roll_again=input() * if roll_again == "yes": * diceroll() * pass * elif roll_again == "no": * print("Goodbye") * break * else: * print("Sorry, wrong input") 
Companies don't care where you got your experience, but they care if you have it. Plaster keyword "python" all over the experience you do have and make it obvious.
If micro-python implements the stdlib modules `urllib` and `http` as of ~Python3.3, then this should do the trick.
Thanks so much for your reply! How do your expectations change when you are hiring a student short term? I just have no idea how much effort I should be putting into a resume... I'll make sure to leave concrete examples!
In case anyone's following along: I've implemented SSL and cookies, although cookies appear to get "lost" through 30X redirects at present. I've added a few features that diverge from `requests`, including context-preserving request-chaining: ultralite.get( "https://foo.com/login", params=dict(user="foo", pass="bar") ).get("https://foo.com/post", params=dict(status="Logged in")) This should preserve things like SSL context and cookies between the first and subsequent requests, and will throw an error if subsequent requests after an initial SSL request aren't themselves HTTPS urls. At present, HTTP auth isn't included, so this will only work for RESTful stuff (and hasn't been tested on RESTful stuff yet). Still, could be handy!
&gt;I'll assume they're lying. Yeah... I wouldn't want that. Do you think I should keep it and hope they check? 
I did work at a nuclear and particle physics laboratory...
Both options will have some people skip you, some people double-check, etc. Every aspect of your résumé does that. In writing your résumé in a particular way you are actively encouraging some people to hire you, and discouraging others. So ask yourself: what kind of job do you want? Tune your résumé to that. Or if you really want a particular job, read the company's online material, and write your résumé in the company's tone.
From reading the source it serves static files (with directory listings) and renders all `*.html` files with Jinja2. It's basically php for python.
You strike me as the kind of guy that will throw half of the applications in the bin, and say you don't hire unlucky people. :)
Perhaps point to specific projects on github for each skill you're listing? Looking at a person's github can be a bit vague unless they have a couple really popular projects with lots of stars. My github has something like 30+ repos on there; I would only point to specific examples. 
Guessing "from" as you don't switch to something you were already using.
Found a few bugs you need to address in that OAuth code: line 805: It appears you mean to copy a dict, but you're actually just assigning another name to the same dict. So, when you delete a key below this, you're deleting the key in self.parameters too! Fix this by using the `dict.copy` method on self.parameters to get a shallow copy. 847: You forgot the `self` argument to the method, so in this method all of the arguments' values are left-shifted, with http_method being assigned the value of the object, and so on. Overall, there's a lot of C#/Java idiomatic stuff happening here, with lots of methods whose only role appears to be to set or get attributes or dictionary values. My advice; cull them all, use the attributes and dictionary methods directly. If you want silent failures on keyerrors, use `my_dict.get("maybe not in this dict", None)`, and likewise if you want silent attributeerrors: `getattr(my_object, "some_attribute", None)`. In one place, a getter catches a keyerror and raises a custom error if a key is absent; just allow a keyerror to propagate instead; it'll preserve the full traceback and make debugging easier, and cut lines of code and unnecessary method calls from your program. *Edit*: Sorry, I saw you're defining these as staticmethods, below. The newer idiomatic way to do this is with a decorator: @staticmethod def some_static_method() although, in both the cases I saw, you're returning an instance of the class, so a better way is to define them as classmethods, so you receive the class as first argument. This allows easy subclassing without having to do any more magic: @classmethod def some_class_method(cls, foo): # Call other class methods and static methods: foo = cls.bar(foo) # Return an instance of the class: return cls(foo)
This is the right answer. Do not try to wrap your head around the entirety of Python and its community. There is too much for any one person to know. 
Unless our position needs those skills, then not really. Also, I don't really care what language you like to use. I want to see your logic and problem solving abilities. If you are really good at those, the language can be learned. If I am hiring, I want to see those 2-3 projects. However, programming for a year would typically put you in an internship position to, at the highest, a junior dev position. Also depending on your location, most Python positions will be web based. So while stand-alone applications are nice, you are much more likely to get a job if you are knowledgeable in web technologies such as servers, dependencies, frameworks, HTML, CSS, Javascript, etc. Might want to start working on building frameworks and getting familiar with Django.
What you say has a part in the decision making process too, though. So I wouldn't totally dismiss it. Fitting in with the company culture, being able to work with others, teamwork, and communication skills are the main reasons for a face-to-face interview. Even things such as appearance (as in how well you keep yourself groomed) has a pretty big impact.
Of course, you're missing a lot of students (myself included) who signed up with our regular emails instead of our .edu address, but I don't have a better suggestion. I think it's an interesting blog post, OP just sensationalized the headline either accidentally or for karma.
Last month for NumbaPro? I don't see it, your link is a post from April 2013. I haven't seen any substantial update in some time.
Ohmyzsh with agnoster theme. I'll link once I am on desktop, but its quite popular, so you can Google it.
Projects for sure. Like he said, time is money. The easier it is for me to see your stuff, the bigger the chance you have to get hired.
oh my zsh is nice, but i recently switched to [prezto](https://github.com/sorin-ionescu/prezto) and didn’t regret it a single second
i just wrapped it for arch: https://aur.archlinux.org/packages/python-prompt-toolkit/
Like most college rankings, out of some journalist's ass.
Congrats! Keep in mind that when you're writing code on Reddit, preceed it by 4 spaces and it'll come up as code, like thusly import random def diceroll(): print("Rolling the dices...") print("The values are %d and %d" %(random.randint(1, 6), random.randint(1, 6))) while True: print("Do you want to roll the dices?") roll_again=input() if roll_again == "yes": diceroll() pass elif roll_again == "no": print("Goodbye") break else: print("Sorry, wrong input") Now, I'm not one to criticise someone who is learning, but I would suggest you read [PEP 8](http://legacy.python.org/dev/peps/pep-0008/). It provides you with a basic guideline for writing nice, readable and fluent Python code. However, it seems you're on your way so good work! Feel free to message me (I've taught a few people Python, as well as taught myself) if you have any questions! Also, I would like to mention that in your diceroll() function; you should probably *return* from the function; else you'll end up with problems upon a large number of iterations. So; to do that you'd simply do, def diceroll(): #Do something return and that'll bring you back to where you originally called the function; of which you can then continue with your flow control.
Go go go!
The resumé is the important bit. Give me very concrete examples, not generic stuff: * Implemented multiprocess HTTP server in Python, scaling to 1,000 connections per second and 40 gigabit/s on a quad Xeon E7-4830. This is good. I know what you've claimed to implement (a HTTP server), what you did to make it work, and what you consider to be the headline numbers about it. * Worked on Python web server. This is bad. How much did you do? What do you mean by web server? What outcomes did you think were good from it? * Wrote graph generation code using numpy to display 50th, 75th, 95th and 100th percentile usage levels for router links. This is good; I know what you did, how you did it, and what you wanted to get out of it. * Part of team writing numpy code to analyse router utilization using percentile measures. This is bad - what did *you* do? How did you do it? What tools did you use? What did other people do on the team. * Wrote Python code to display current router utilization on DC voltmeters. Source at https://github.com/phubbard/bandwidth_meter This is ideal - I know what you did, why you did it, and can dig deeper if you got my attention.
I may be misunderstanding how this works, but I thought that if I had a program in Vim and I used *:!ptpython %* it would run the program in the interactive interpreter and then when the program finishes return with a ptpython prompt (similar to running a script written in the IDLE editor, it sends it to the IDLE window and then when the program is done the IDLE interactive prompt returns). Instead it simply runs the program as if it were a regular python console, and exits when a key is pressed.
It sounds like you're looking for `:!ptpython --interactive %` (equivalent to `:!python -i %`) 
I think this post has a couple good points! First, the pypy.numpy team went down the wrong path (although well-intended). The pypy team started a numpy port because numerous folks indicated numpy was a major missing feature. The wrong path was to start the numpypy as RPtyhon implementation instead of a complete "pure python numpy" (premature optimization). The second point, similar to the first, when using pypy the post strongly suggests that you always start with a pure python implementation and then move onto an optimized (RPython or C) only if needed. 
&gt; Also, I would like to mention that in your diceroll() function; you should probably return from the function; else you'll end up with problems upon a large number of iterations. I don't think so? It doesn't call itself recursively, so the stack size shouldn't increase, if that's what you mean. If that's not what you mean, I have no idea what you mean. There is an implicit `return None` at the end of his definition anyway. If the control structure was like this, you'd be right: def diceroll(): print('Do you want to roll?') if input() == 'yes': print('Rolling the dice...') print('The values are %d and %d' % (random.randint(1, 6), random.randint(1, 6)) diceroll() diceroll() On another note, that `pass` is useless. It would make more sense (but still not necessary) if it were `continue`.
very cool! I have been working on a library for off-the-shelf text generation models: https://github.com/publicscience/broca
"The second one, zillaphone"
Can't tell if you're joking
NumbaPro (not Numba). It seems like they're moving small parts of the stagnant NumbaPro library to Numba.
I think that would be dishonest of me (so no, I don't). 
I see NumbaPro listed on their website as part of Accelerate, but I don't remember if it was a separate purchase option. MKL Optimizations is still available stand-alone, but not NumbaPro. Personally, I'd like it if they just combined Numba and NumbaPro and kept it as part of the regular distro.
Thanks for the read-through! I'll try to incorporate these changes best I can. I like to think I'm pretty good at programming, but following such a tight spec as this makes me nervous. As I said before, I only trimmed code, didn't actually rewrite much of it. The original code was pretty non-idiomatic, and my attempts at rewriting it screwed up the fragile OAuth logic. I blame Leah Culver if it's not pretty. One of the reasons why I'd like someone to sit down with the OAuth directions and write the simplest possible code to make it work :)
That's my GWBush impression.
Any samples?
GPU support for NumPy is a good idea. NumbaPro will have more features for NumPy-like expressions for the GPU. With R&amp;D funding from DARPA we are spending more time working on open source tools like Numba which can lay the foundations for GPU support of the entire NumPy-stack. That said, the Accelerate product which contains NumbaPro continues to get regular releases. The last release was earlier this year It is focused on those higher-level interfaces to GPU programming and providing Python interfaces to GPU libraries. A full NumPy backend is on the roadmap but it is a big undertaking and our resources for it are limited. 
Numba is currently free and NumbaPro is not. NumbaPro is part of the Anaconda Accelerate product which is free for academic use (though running it on a cluster does cost). Many features that used to be only in NumbaPro are now in Numba itself. As we get more customers of Accelerate and other Continuum products, this pattern will continue. Selling NumbaPro is a part of how we pay for continued work on Numba (along with support services and R&amp;D funding for Numba itself). 
Very cool! Thanks for taking the time to write this up. Very interesting read and would definitely encourage more Saturday Morning Hacks!! For me, the content and layout was good. Again, thank you. 
Saying "no, that never happens" is not a rebuttal, especially when you've made it clear you have no experience from the other side of the interview process. It's a text-book confrontation. 
&gt; Install Python If you're interested in scientific computing, install [Anaconda](http://continuum.io/downloads), or one of the other Python distributions listed [on the SciPy site](http://www.scipy.org/install.html). These come with Python and many of the important scientific packages preinstalled, which makes things a lot easier. [Python Scientific Lecture Notes](http://scipy-lectures.github.io/) is a good site for learning about some of the core scientific computing packages.
I agree with you that it's not the best way to do the analysis, but for now we decided to rely on statistics (only those users who chose to use .edu to register were analyzed). We'll try thinking of a better way to calculate it, so if you have any suggestions ping us 
I found a different Markov chain program a while back and sicced it on some IRC logs. One guy in a few of the channels I'm in says the strangest things and likes to rant, so he served as a reasonable sample text set. Markov: &gt; the first few days i was thinking... life could be tastier in the country? &gt; i try to leave the old commiezapper alone &gt; would you wait for the police taxi to take me up in the lefty part of philedelphia &gt; i look at these private snow shovels &gt; well, i suppose i should let yall in on a raft with others, you wait for police
so what, in your opinion is a good beginner's tutorial for python. I have never coded before, and I am right now working towards getting my ccna certification. So literally have no coding background. 
Oh, that's different then. Just start with http://www.codecademy.com/tracks/python or http://www.learnpython.org/ and read along. They lay it out step-by-step for you, you'll figure it out.
&gt; but completely disagree that adults shouldn't ask questions. yeah me too I would assume/hope than an adult would check google and review the millions of answers before asking a question that is asked over and over and over again. i know it's probably too much to expect here. But I'm going to keep on believing in humanity with my big dumb heart. 
The good thing about websocket is that you don't poll at all. Note that Python doesn't have a built-in websocket implementation so you'll need to rely on a third-party. There are bare websocket packages such as [ws4py](https://github.com/Lawouach/WebSocket-for-Python) and more featured rich ones such as [crossbar](http://crossbar.io/) or pubnub.
Ah, Leah's probably a Java head is all. Lots of Java idioms in there that you *can* carry over into Python (some are even a good idea), most of which make it far more bloat-ish and needlessly convoluted. You could minify that code with a bit of work and have something much easier to comprehend; I doubt if OAuth is actually that "delicate" if written in clear, idiomatic Python.
&gt; codeacademy is good for helping you learn how to tie your sneakers, but if you stick with it for too long you'll do yourself more harm than good. Can you explain what you mean here? I don't think there's any harm in the walkthrough, especially for beginners. One of the biggest advantages to something like codecademy is that it contains a problem set. Just downloading python is great, but the "what should i make?" question is one that someone just trying to figure out how to program as a beginner shouldn't have to worry about. As a beginner, it's very difficult to chose something of an appropriate scope (so you can actually make it). For a beginner, having something like a book or site to guide you can make all the difference between sticking with it or giving up.
Thanks, glad you enjoyed it! I'm looking forward to writing the next one in the series.
I've made a few automated twitter bots using this approach. One of them got banned after calling someone a cunt. It's easy to get stuck thinking in terms of words, but the algorithm is interesting when you apply it on a character level if you use higher order chains (i.e. the last sequence of N characters will determine the candidates for the next) and have it come up with new words. I have some code for just that here. It takes a blob of text on stdin and generates a sentence: http://637584c21b058a34.paste.se
I wanna see you there!!!! ;-)
...but not not the hangover. I need a tylenol just thinking about it. 
[Agreed](http://i.imgur.com/KftvI.jpg)
If you haven't done lots of advanced math and/or machine learning, then yeah, this is a tough article to follow. I've done intro-level AI and linear algebra, so I recognize most of the terms. If I stare hard enough at any one section, it even seems to make sense. Where I get lost is trying to put it all together into a coherent whole.
Get comfortable using pip. Most of the projects out there don't get packaged for Windows, OSX, or even Linux, so pip is the best way to get most of the community stuff. You can even search for stuff with pip if you're looking for specific functionality, e.g.: pip search xml 
I'm kinda new to Python and have found that the, learn python the hard way website is straight to the point and really easy to learn with examples and breaks it down into digestible chucks. But I've found that if you're feeling brave enough. think of what you want to do.plan it. And go for it you'll learn whilst trying to make a basic program and google is your best friend/companion. 
I tackled a similar problem a while ago. The idea was to generate grammatically semi-correct, but yet random text that would 'hide' a predefined word in it. I ended up using Markov chains, nltk and Japanese haikus as corpora (mainly for their short length). Here is the result [noagen](http://noagen.herokuapp.com/). 
Literally you don't, but you do ;)
I began writing pybot over two years ago to learn Python and the IRC protocol. After much terrible code rewriting and improvement at programming in Python, I think pybot is a pretty cool, featureful, stable and developmentally-friendly bot. Any criticism or suggestions is welcome.
Probably some simple toy for my kids, initially. Once there is a fully working/supported network socket, who knows...
Ummm... nope.
I have (very briefly) thought of implementing another protocol. I'm not saying it won't happen, but it means I have to learn the jabber protocol (which I'd do as I go) but it would require a lot more time and effort than current development, which is easier because I'm so familiar with the code base. If you want, you can open an issue with a request for a feature enhancement at the bitbucket page, which will probably remind me to start thinking about ways to do it.
raw_input() returns a string. len() returns an integer. You are basically trying to add an int and str which is what the error states. Try to fix that on your own and comment if you are having more trouble.
Int = Integer Str = String You can't concatenate Strings and Integers, or, your can't add them together using the "+" operator. When you're using raw_input(), the input is of a String type, but when you use len() you're getting an Integer. So, you're adding strings and integers in your if statement. *Edited to remove answer so the OP can try on their own.
im very familiar websocket under autobahn and socketio.... http long poll is a different thing. Most examples what you to use an async framework and run a loop on a differed thread. this is fine.. i was hoping someone had a client library that ether obfuscated that or bypassed it all together.
There's a lot to say about setting up/installing new software as well, not just learning Python. Just the act of it, finding the Python package you need, finding pip, virtualenv, finding an IDE, figuring out what to do with them. It gets the "problem-solving cogs" nice and greased up and introduces you to some terminology that you otherwise wouldn't encounter on interactive sites. Then once it's set up you'll naturally want to see if it works. I wasn't suggesting he create a web app driver or anything, just add some numbers, assign some variables, learn how to start/quit the console, etc. With just that little bit of self-confidence now in place, tackling interactive tutorials like codeacademy will give a sense of how clunky and slow they are. How nice it is to have IDE helpers, syntax helpers, learn about modules and packages. Naturally you end up just copying and pasting the code from interactive sites into an IDE and just tinkering with it yourself. It's about, first and foremost, providing a means to remove the training wheels. Priority number one: do not feel like you **need** to have your hand held. Then start down the web training path with that subconscious knowledge that you're confined to a fish tank. Eventually the urge to break free will win. That's when the real learning begins.
yeah.... async with twisted or gevents works fine.. i am more interested in a client library in itself. also skimming your post history , your common response is "check google or stackoverflow" , sarcastic (ie not /r/learnpython) or overall not very helpful. If you have nothing to add, at least make your troll bait a little more amusing. 
Thanks. I got that to work! But I was wondering if it was possible to make it so that way, if you got it wrong, it would clear powershell and restart the program?
I'll have another!
I haven't used sage before, the feature overview looks like it's trying to accumulate various other open source projects to create some thing in the hope that it will be so significantly larger than the sum of it's parts that someone would want to use it. I'm not surprised at all that that didn't work out. Personally when I want to do something I'd just use specificly built libraries directly, the rest is just bloat to me.
Don't forget /r/learnpython It's a very healthy, friendly, active, and helpful subreddit.
how much do you pay? just wondering what the django market is like.... 
"We don't drink Malört because we like, we drink Malört because we hate ourselves."
Im sorry what do you mean by 'understanding of metaprogramming'. I feel like the term 'metaprogramming' is used a lot but I never know wtf someone is referring to when they say that....
The way I do that is to add a while loop. for example run_program = True while run_program: &lt;your code here&gt; bonus: add an if statement so if a user enters 'q' the run_program variable will change to False, thus exiting the loop and quitting your program.
One of the big issues with Sage is that it's GPLV3. This makes it very hard for other projects in the BSD license dominated python ecosystem to incorporate what they produce.
I think you're dreaming! Good thing is that they can be insta-closed as duplicates, not so easy here.
Sage is an extremely effective broker between the various math systems it connects. A reason why this sum-of-parts can work seamlessly when so many sums of software components do not is that these parts are communicating MATH. Specifically Sage itself contains enough universal algebra and category theory to provide a rigorous unifying semantics across these components. That is how Sage can give you a notation such as QQ(5) or whatever and have it work regardless of whether your install is set up to implement that mathematical object in Sage itself or in Matlab or in Maxima. I have to apologize that I don't actually know this at a technical level. It's just how I interpret the documentation and articles I've seen. If necessary I suppose someone else will correct me on the details. I have used Sage for a variety of explorations and calculations during the past few years. I think it would be very unfair to leave an impression that Sage is failing utterly. It succeeds at being a fantastic system for doing mathematics with great breadth and in many areas great depth. Stein is saying it is failing at the mission as he has always stated it: to be as good or better on practically ALL measures than ALL math software, particularly the champions of commercial math software namely Mathematica Magma Matlab Maple. Now, he seems to have doubts that the project is viable in the long term without besting all comers in all contests - but if that's what he really thinks, then I don't agree. Whenever I've looked there always some measures where Sage really does claim to be the best. Aiming to be thoroughly competitive is a great goal. And it's free open source. Really not bad at all. 
Why not use complex numbers. Let's see: In [3]: (3.5 + 1.2j) - (-2.7 + -3.2j) Out[3]: (6.2+4.4j) In [4]: A = 3.5 + 1.2j In [5]: B = -2.7 + (-3.2j) In [6]: C = A-B In [7]: C Out[7]: (6.2+4.4j) In [8]: C = B-A In [9]: C Out[9]: (-6.2-4.4j) In [10]: C.real # X coordinate Out[10]: -6.2 In [11]: C.imag # Y coordinate Out[11]: -4.4 In [13]: Y = -6.8 In [14]: Z = X +1j*Y In [15]: Z Out[15]: (4.4-6.8j) You can understand a complex number as vector in a plane. If you multiply two complex number you can create a rotation. In 3D there is 4 dimension numbers quaternions used to represent rotation in space. 
There is pure python tornado webserver for that .it fully support websocket and long poll very highly active development
Why not tornado
&gt; and we could optimize it if we we wanted by typing the variables (IIRC) Sage lets you do this with some cython automatic compilation, as does ipython with the notebook interface. &gt; Prof. Stein, if you're out there, what the heck are you talking about???! Did you read the post. He clearly states not that Sage is of no use to anyone (it's clearly useful), but that it has failed his grand original goal and that this seems unlikely to change in the remotely near future.
yeah, for the most part i know that the companies that hire us get us for pretty cheap. I'm making 24 and hour but the company is definitly paying way less than that + tax benefits.
I stumbled upon Sage Math Cloud recently as I was looking for an open-source alternative to using Mathematica for a quick class project. I'd previously used Sage but didn't feel like installing it again. It was great! Here's more info from the SageMath founder on SMC: http://sagemath.blogspot.com/2014/08/what-is-sagemathcloud-lets-clear-some.html. The most interesting point in there (to me) addresses what /u/nathan12343 said elsewhere in this thread, which is the GPL issue. The new Sage Math Cloud stuff will be BSD, and has an airgap between it and the GPL'd components (Sage itself, etc).
I think you hate humanity. why would you set the bar so low? Have you seen idiocracy? You are an enabler.
A big issue for whom? And how does that contribute to the "failure" as defined by the author?
A big issue for the large number of qualified potential contributors who are locked out by the licensing issues. It contributes to its failure because those people can't or won't contribute code. I don't see how that's confusing in any way.
the tornado version isnt really any better then gevent or twisted version https://gist.github.com/cleg/4370563 for example this is example (that every stackoverflow post seem to references) is a taskloop generator to yield. its exactly two lines less then then the twisted equivalent and 3 lines less then then gevent equivalent.. 
[colorama](https://pypi.python.org/pypi/colorama) ?
or [colorama](https://pypi.python.org/pypi/colorama) ?
You made a throwaway for this?
Indeed, windows. I want to open source it, on github. Will post to r/python when I do/can.
24/hour isn't terrible. I came out of school making $15/hour for a startup. Was a great learning experience. Decided to invest all my earnings into equity and made some pretty good money when I cashed out.
Maybe I don't see the value proposition in Sage / the issues involved... If you're installing Sympy (or other scientific python packages) via conda, and using the ipython to explore... what is the point of Sage? You can call Sympy (and other python libs) from julia. The main win is in performance e.g. for loops (where in numpy you would have to artificially vectorize your algo or drop to cython). EDIT: IIRC there is (work towards if not complete) a C-API for Sympy, so Julia will, if it doesn't already, call out to that rather than use pycall.
Double-clicking like that will execute the code, dump results to the console (a black window) and then exit out of the console, leaving you with no output. I would suggest you open up and run these files in IDLE, which will give you an interactive environment to write and execute scripts. Better yet, it'll give you the traceback errors (if any) to identify where bugs in your code are.
Sage provides a lot of functions which work internally using very fast and robust libraries like Maxima, Singular, BLAS, LAPACK and more. For users looking for a Mathematica replacement, Sympy and Sage will look largely the same (in fact, Sympy is included in Sage) and for users looking for a Matlab replacement, Sage will look a lot like Numpy (which is also included, but abstracted away from the user). The value proposition of Sage is that it has lots of useful and powerful things, all in one place, under the same API and executable in the same environment. Sage doesn't have a large technical knowledge overhead since most of the technical implementations are abstracted away and Python's syntax is very easy to understand. This means researchers can use it without needing to be experienced programmers or worry about importing everything and clobbering things or which library has a good implementation of numerical/symbolic integration. What you get is a clean and powerful work environment, at least, that's the idea. As an added bonus, everyone with a Sage environment will have an almost identical environment, so sharing is easy.
Most CAS work I needed done could be done with just Sympy. Sage seemed like way too much overhead.
Honest question, why does an IRC bot need to be multithreaded?
This was a while ago, doubt I can find the script anywhere. I do recommend looking up "scipy zombie apocalypse" for some pointers.
He isn't using threads in a traditional IO scenario - each network he's connected to is a separate thread. This allows each network to have its own loaded or unloaded modules. If one network goes down the others are unaffected. Edit: I'm frequently on several networks. I wanted to have the same bot on each network.
I run an open source project that was originally GPL. Per the GPL recommendations, if you create something that doesn't exist in the commercial community, it should be GPL. However, I changed it to LGPL because the intended audience couldn't make use of it in their software. Commercial companies post the vast majority of the bug reports and push the software such that it's not just the toy that it started out as. They're not going to be stuck on an outdated version if they don't have to be.
Its odd to see instructions to run an `__init__.py` directly. `__main__.py` may be a better idea. Then users can just run python image_scraper. Alternatively python -m image_scraper. Selenium has a phantomjs driver, though I found phantomjs unreliable - segfaults for complex interactions. Would be nice to see a list of images rather than just an image count. Nice effort, keep at it.
Could you explain what is the role of the 1 pixel gif? Why not sending the data directly as json with an ajax request for example?
Personally, I love Tkinter. It's built into python, you don't have to install any other libraries to get it working and it's extremely powerful and versatile. I think you should go with that.
Yeah I love it but some of the things I have made just dont look that great or modern. That is the only problem I have with tkinter.
&gt;I think it would be very unfair to leave an impression that Sage is failing utterly The only point at which anyone said this is failing is the project leader and he says it's failing to be *better* then 5 different somewhat specialized commercial products that had more resources and time than Sage. I said that that's not surprising. &gt; A reason why this sum-of-parts can work seamlessly when so many sums of software components do not is that these parts are communicating MATH. Because it's a patchwork of 90 projects *you do have seams* and those will slow you down. The problem is that all the different parts have expressed Math differently. I've seen that you define variables with x,y=var("x y") in sage. This is different from sympy where you do it with x,y=sympy.symbols("x y"). In this case "fixing" can be done by redefining but there are others. For example from the introduction video (which is 4 years old so who knows how it's now) the way symbolic computation was done in sage is that you typed in "x+y", it probably got split in "x" "+" "y" as strings, they got passed to Maxmima, interpreted, put together and evaluated. Technically it's not communicating math as such at this point Sage&lt;-&gt;Maxima really trade strings, which would be fine unless you want performance. String from input -&gt; sending to Maxima -&gt; abstraction -&gt; contextualization -&gt; object from result -&gt; sending to Sage Has two send and one conversion step that you wouldn't have if you could make the inputs and outputs match exactly in the first place. Now there are 90 packages in Sage. How much effort do you think would it be to make every part have the same input and output definitions? It's not really doable. There has to be layer that communicates, but it will slow things down and therefore defeating the goal of Sage. That's not even accounting for when one package patches or updates and changes things around. &gt; Really not bad at all. It's probably very good at what it does, being a free open source math environment for universities, but it's not going to be able to compete with projects that have had uncomparable amounts of money thrown at them.
Looks interesting. I quite like the look of Brython and fancy trying it out but the inability to debug is a turn off - anyone know qdb will work with it?
 C = (A[0]-B[0], A[1]-B[1]) print C[0], C[1]
Personally, I'd choose wxPython. It looks better (has platform-native look), plus has a fully free license unlike QT. That said, QT has probably more powerful options and is quite up-to-date.
Agree strongly, Sympy is just eaiser. 
&gt; This is why I am not considering kivy because of its KV language Kivy doesn't require the use of kv language, it has python bindings to everything that are perfectly good. We just use kv language a lot because it's more concise, syntactically clearer, and practically convenient - not because python is neglected, but because it's just not the most convenient way to construct a widget tree. That's also part of why Qt has QML. That said, if you're really so dedicated to a totally python toolkit that using non-python even behind the scenes is undesirable to you, kivy is not for you.
https://github.com/pybee/toga I'd try this. It's GUI library and it's fully pythonic. Even if it's in very early stage, you can contribute very easily, because all code is python. And you install it simply by `pip install toga`. Try: pip install toga-demo toga-demo
In the future, when you need help with your python code, go to /r/learnpython.
They have used Django and here's the repo link: https://github.com/taigaio/taiga-back PS: I am not associated with them in anyway.
I also use Tkinter quite a bit just because it's part of Python. I am usually working on Windows, and, if I create a small GUI, it's nice to know that I just need the Python standard library. A tiny GUI utility that requires a 30MB QT runtime download (even if it is all packaged up together) is a tough sell for Windows users. With ttk, TKinter looks pretty great too on Windows these days.
It has possible to use other template engines easily with Django for years. I've used mako in particular since Django 1.2 or so. I don't see that this is such a big change.
1) Some clients actually block Javascript, so your ajax request wouldn't go through. 2) Let's say I want to track page views on a website I cannot control (ex: on a forum where they don't accept javascript in posts). The ajax tracking will not go through since the forum will strip all javascript from the post. But the image tracking will work. Of course it all depends on your needs :)
Looks, nice :) I'll give it a try. Thanks.
WSDL files are generated to define a SOAP web service. You probably are looking for the wrong thing and the results are consumers of web services since that's what a WSDL file is used by. I'd strongly recommend looking into the pros and con's of both SOAP and RESTful web services. REST is the most popular these days and I'm sure most everyone here would strongly recommend that. What is your goal?
My goal is to learn how to consume/provide a soap web service using the powerfull python. I only found how to consume a soap webservice, now i need to provide the soap web service to be consumed from other platforms. I found some libs like suds, soaplib, etc, but i couldnt see how to generate the wsdl file and consume it in other places.
There is very very few chance it works with Brython as Brython is a pure javascript technloy and that is a pure python technology
The comment box itself.
Not an answer for you -- but could you point me to the best resources for getting up to speed with SOAP/Python? I'm working on a new project that I need to use SOAP for but have not dived in yet. 
Is there a reason you need to use SOAP instead of JSON?
Looks really interesting!
 d={'a':1, 'b':2} for k,v in d.items(): locals()[k] = v seems to work. This http://stackoverflow.com/questions/1676835/python-how-do-i-get-a-reference-to-a-module-inside-the-module-itself may provide alternative.
Duh, locals. Makes sense, and definitely does the job. Thanks!
[I normally use pysimplesoap to consume SOAP-based web services, but I think it also supports creating servers.](https://code.google.com/p/pysimplesoap/wiki/SoapServer)
"comletely in Python"... well, the front-end relies heavily on JavaScript! ;) But yeah, I saw that this morning and was happily surprised to see it's Django-powered! Let's see where it goes. So far there's not a lot of documentation on how to set it up on your own server.
Well, im glad to help you too. I found ZSI ( http://pywebsvcs.sourceforge.net/cookbook.pdf ), but i only use wsdl2py, that convert the wsdl file into python classes. That works fine for me , with that i was capable to consume the ws. Its easy to install and use. You have to be carefull with the types of the return variables for the request you made but everything else works ok. Also Suds ( https://fedorahosted.org/suds/ ). I didnt used it but it seems easy.
The 1px GIF is used because, generally, you cannot make ajax request across domains.
Thanks so much for the kind words!
Yes, the backend api is full developed in Python 3 + Django 1.7, with Django Rest Framwork. The front is a CoffeeScript + AngularJS application :) But are a taiga-ncurses client writted in python 3 + urwid
Wouldn't the G(i,j) sum also contain the X(i,j) element itself? I believe G would represent the sum of all 9 cells, the 8 neighbors + the middle cell. Am I missing something?
&gt;If it were BSD or other similar nothing would prevent a company from taking the product, add a few new features and sell it as a closed product. Whilst this may be true, the vast majority of BSD/MIT licensed software survives successfully out in the open and many companies are happy to have their employees work on these projects which they can use (where they couldn't use GPL-based software). Perhaps the distinction here is libraries vs products, which I guess I understand... As mostly a library dev I prefer MIT, I think increased users mitigates/negates risk of a (closed) fork. However, even GPL software *products* can be sold (as SAAS) by your competitors (the example I'm thinking of is discourse), granted they can't add new features directly...
That makes sense, it's this sentence that threw me off: &gt; So the main computation that needs to be done as part of the state transition is to compute an array G with the same size as X, where each cell in G is the sum of all immediate neighbors of the corresponding cell in X. It implies that G is a sum of all neighbors of X.
web2py can act as a soap server a generates the wsdl on the fly. But as said above - wsdl describes a web service, not some classes http://web2py.com/books/default/chapter/29/10/services#SOAP
That's true, and I understand that sage is more of a product than a lot of other python libraries, and that's why the sage devs chose to use the GPL. Nonetheless, it makes it impossible for many python projects released under BSD licenses to even have bare-bones integration with sage.
What is meant by &gt; A direct nested `for` loop would be expected to scale pretty poorly as the grid sizes m and n grow. In terms of asymptotic complexity, the given algorithm (while cool :) is worse than examining for each cell, its 9 neighbors in the previous state by a factor of log of the number of cells.
Hi, I am actually curious to know if I could help port some of condas packages to the raspberry pi. I noticed in a previous blog post that some of the (presumable simpler) packages were, but others such as llvmpy unfortunately were not. I am fairly certain that if my help allows even a single package to be added to the raspberry pi distribution of conda, the lots of people will benefit.
If you're still interested, this seems to be what you're looking for http://bloerg.net/2012/11/10/cmake-and-distutils.html
My experience has also been that creating standalone Python apps is a PITA. I've never really had to deal with *distributing* such an app (the ones I've built are essentially for my own use), but if I wanted to, I think I'd try to come at it from the opposite direction and create, say, an Objective-C "stub" application with an embedded Python interpreter instead. At any rate, you might want to look into how [calibre](https://github.com/kovidgoyal/calibre) builds its various versions. That's a cross-platform Python+Qt app. 
I did exactly this about a year ago (http://pastebin.com/zLu8eNWc), I even used fft convolutions (although I used the ones from scipy).
Yeah, that doesn't read right by itself. I should probably clarify better what my point there was (most of the post is based off earlier notes): my idea was to eventually use this to explore an inverse problem - finding sets of new game rules that lead to long-term states with certain distribution properties. So in the general case, we might be looking to compute some form of a weighted sum of possibly more than 8 neighbors. Worst case for the direct approach is O(mn*mn). This approach is O(mn log(mn)). 
Awesome! It's easily adapted to other cellular automata too. 
Nice blog post! I was looking for a way to `pip install &lt;package&gt;` and it would compile the C++ application. It looks as though that is not really possible and I ended up spending many hours running around in circles.
So I think you can make this a little faster for square boards: Say the board is m by m and note that if you replace the kernel with a 3x3 block of "1's" and change the update rule for b to &gt; b = fft_convolve2d(state, k).round() - state it's the same. But now K is a separable kernel, so you should be able to compute the 2d convolution in two O(m log m) passes. This may not be useful for your long term goals though. I don't know how much this restricts the space of possible games
Brilliant. I have to be honest though, it pains me to not understand the math behind what you're doing. Hopefully I can go back later and learn something new so I can fully comprehend this great explanation/implementation. Great job! 
Ah, I see. Well if you don't mind precompiling for each target platform, then it looks like you can trick setup.py to include your compiled libraries: package_data = { '': ['_extension.so'] }, I think this allows you to include all the dependencies in pip, but I haven't gotten that far.
I'm not a smart man.
Do you have admin permissions?
Yeah it ended up taking more time to attempt than the value gained from it. The C++ application already has bindings into python using SWIG, I wanted to build on those python bindings and use them as a dependency for my python package. I'm simply going to ask people to install the dependency before hand. For reference, this is my package: https://pypi.python.org/pypi/mudicom
i have used [ladon](http://ladonize.org/index.php/Main_About) in the past, but now have switched to [spyne](http://spyne.io/). It was actually the only one to be able to generate proper wsdl schema for some weird Java SOAP client to consume. Both of them (ladon and spyne) are well documented, and i can recommend any one of them. if you plan to use django, then spyne also has some helpers which allow you to hook up the API into django's urls.
wget the wsdl and then host it. You'd still need to run the server, though.
i got excited when i read the title. saw the math and was disappointed. i was never a huge math person :(
Good catch! K's separability in this case is pretty nice too: K = uu^T with u = [0,...,0,1, 1, 1,0,..,0] (a 1D box function). 
Though not always optimal for a variety of reasons, FFT-based convolution is actually one of my favorite tools for problems in applied math/DSP. The theory can be a little heavy if you're seeing it for the first time, but they usually end up pretty dramatically simplifying a solution implementation. I'd be happy to go over anything in more detail if anyone has any questions. I'll probably write up some more examples of it being used in entirely different problem domains in the future. You can find the core idea used in a ton of different disciplines.
This is fucking awesome.
also in hindsight my requirement that it be square is artificial
&gt; and the project has been successful. It hasn't really, though. Essentially, Twisted had the C10K problem licked before it was even a thing, but instead of universal praise, it has gained an enduring reputation as a niche library for freaks, and that's 100% due to the shitty documentation. I've been following and using Twisted on and off for nearly a decade, but it was only really with the advent of [Scrapy](http://scrapy.org/) that it found mainstream acceptance. Not only is Scrapy a truly wonderful demonstration of the power of Twisted, it also removes the sharpest edges of Twisted's idiosyncratic naming and usage conventions and combines that with *excellent* documentation. For a decade, the Twisted devs have been sitting on (and actively developing) one of the most powerful libraries Python has to offer. But the efforts put into making it accessible via decent documentation have been shameful. So much so that when Facebook was looking for a Python-based asynchronous webserver platform, they assumed (as everyone else does) that Twisted was a dead relic and wrote Tornado instead. The only really useful documentation for Twisted is the [Twisted Web in 60 seconds](http://jcalderone.livejournal.com/50562.html) series. The official documentation fails utterly when it comes to (a) providing a comprehensible overview of how Twisted works in general and how all the parts fit together (which is super-important because it's very different to the synchronous programming we're all so used to) and (b) providing practical examples of how to do specific things. Who the fuck is interested in a "finger server"? The fact that Tulip/asyncio is essentially stealing Twisted's thunder **despite being a decade late to the party** is a damning indictment of the Twisted devs' "efforts" to make Twisted useable (which it actually is, once you've figured out how it works *on your own* because the docs are no fucking help). Many of the flagship asyncio projects simply replicate things that Twisted could do 10 years ago. And this glyph blogpost, like all the others, betrays absolutely zero indication that he (or the rest of the Twisted dev team) are even vaguely aware of this singular problem that has been preventing widespread adoption of Twisted since it's first release. 
I've never read a comment I so dearly wished to be able to upvote multiple times. If your library has shit documentation, it's a shit library. End of discussion.
&gt; Now there are a myriad of better alternatives. They're not *better*, just better documented. 
Not just better documented, but also easier to read and write. Performance and end effect may be roughly the same, but better documentation + simpler code + less code + code that you can more easily integrate with your current code = faster development time.
To distribute interpreted language application the approach is to create an bootstrap installer executable that: Download and install the interpreter and the required libraries and dependencies, and your application (or compiled bytecodes) in the user machine. Almost all java apps are distributed in the standalone *.jar format (for the tech-savvy users), or an installer that installs the interpreter and the dependencies, icons and desktop and menu shortcuts. The android apps are a similar case, the interpreter (Dalvik) is already installed on the phone, only the bytecode is shipped, the same can be said for dot Net apps on Windows. Imagine if python came installed as default in android like Linux does. So the approach is to distribute the installer that installs the python interpreter, the libraries and the main application. The python apps can be distributed in *.zip, or *.pyz, *.egg as .*jar file. Inside the content of the zip/egg file would be: Directory: **mypackage/** __main__.py if __file__ == "__main__": import MyApp MyApp.main() __init__.py MyApp.py module1.py And you zip the package: mypackage.zip or rename to mypackage.pyz. You can distribute *.pyc or *.pyo instead of *.py if you want to protect your code. You can execute the app by doing: $ python myapp.zip or $ python -c "import sys ; sys.path.append("myapp.zip") ; import myapp" To compile python to bytecode (*.pyo ) and remove all comment strings: python -O -m compileall package_dir The best approach is do like java app does ( they are not ashamed to install the JVM) to verify if the interpreter is installed, otherwise download. If each developer install python in the customer machine in a known directory by everybody then it will be easier to ship new apps like the java guys does (distribute only the *.egg) or lighter modular installers. It also would promote and spread more the python language and runtime on Windows Environment. The python interpreter would be installed only one time. ( It would be nice if Microsoft shipped Windows with python per-installed). You can also put the dependencies inside the *.egg file ( CX Freeze can do it). For Unixe-like OS you only have to distribute a distribution specific package (*.deb for production for Debian/Ubuntu) or an self extract executable or an *.egg file as the python interpreter is already installed by default by default on Linux/OSX . See also: * http://blogs.gnome.org/jamesh/2012/05/21/python-zip-files/ * http://pythonadventures.wordpress.com/2014/01/05/python-equivalent-of-java-jar-files/ * http://hackerboss.com/how-to-distribute-commercial-python-applications/ * http://www.blog.pythonlibrary.org/2012/07/12/python-101-easy_install-or-how-to-create-eggs/ Create an installer with cxfreeze: * http://cx-freeze.readthedocs.org/en/latest/overview.html Self Extracting Executable: * https://www.youtube.com/watch?v=Gh7JDNT-Luc * http://7zip.bugaco.com/7zip/MANUAL/switches/sfx.htm * http://www.linuxjournal.com/node/1005818 
Very cool :) Just a random (no pun intended) note, choice() could use random module's choice()-function: return random.choice(words) 
Regarding code obfuscation: You say "signing executables - code obfuscation (I know of a few libraries that already do this, I'd like to have it built into one single make/build process so I don't need to jump around)" I don't know exactly how you're doing your make/build. But if you're using Unix-style makefiles or scripts to build, I *do* know that there are Python code obfuscators available that *don't* have to be used as libraries--they can be run directly from makefiles or scripts as system commands. Would that help to address the "need to jump around" problem? 
You know, my report cards never came back positive in the math department, so a "Practical math guide to Programming" could be a million dollar idea for people like me...
This series is aimed primarily at game developers, but addresses plenty of common maths problems for programmers - https://www.youtube.com/user/BSVino/videos
You really shouldn't ask reddit to do your homework for you. Think harder, I'm sure you can figure it out. And just so nobody can say I didn't try to help, I learned most of what I know about python from [here](https://docs.python.org/3/tutorial/index.html), give it a try.
Question, I'm relatively new to Python, and have never seen this before: K[m/2-1 : m/2+2, n/2-1 : n/2+2] I don't understand the comma in the brackets. Is it some form of advanced slicing? 
In my experience packaging is nearly always a PITA. Just this week I went round &amp; round with our chief architect on problems trying to get a working package of Scala (the new sexy thing) code. It made Python's packaging look very simple in comparison. Personally, I'm pretty happy with the progress that's been made: it's getting fairly easy for me and my teams to package a python app and let anyone install it in a single line command. This is on linux &amp; mac, I have no idea what's going on in the windows world.
As in, separate the code up into logical directories and away from the docs, or what? Or just more organization in general? That is an ongoing war against entropy.
This thread has been linked to from elsewhere on reddit. - [/r/cellular_automata] [Implementing Conway&amp;#x27;s Game Of Life with minimal code in Python • /r/Python](http://np.reddit.com/r/cellular_automata/comments/2i50dz/implementing_conways_game_of_life_with_minimal/) *^If ^you ^follow ^any ^of ^the ^above ^links, ^respect ^the ^rules ^of ^reddit ^and ^don't ^vote ^or ^comment. ^Questions? ^Abuse? [^Message ^me ^here.](http://www.reddit.com/message/compose?to=%2Fr%2Fmeta_bot_mailbag)* 
I know you're completely right, I've been trying. Thank you tho, I will definitely take a look. 
Any reason you go with 3.3 only? Have you tried adding e.g. 3.4 or even 2.7 to travis and seeing what fails (it may be that it's trivial change to support all)? Would be great to have a docker image!
Just curious, why do you use Fourier transform convolution here? Convolving an m by n array with an m' by n' array naively takes O(mn m'n') whereas Fourier transform convolution runs in O(mn log(mn) + m'n' log(m'n')). This would be good if log(mn) &lt;&lt; m'n'. But here, our kernel is only 3 by 3, so m' = n' = 3. So it is not the case that log(mn) &lt;&lt; m'n' and it would seem to me that computing the Fourier transform would be even more costly than just naive convolution.
How does this look: def initials(name): indexOfFirstComma= name.find(",") indexOfFirstInitial=name firstInitial= name[0:1] lastInitial= name[indexOfFirstComma+2] return str(firstInitial) + "."+ str(lastInitial) + "." name="Jane, Doe" print(initials(name))
You tell me- does it work? I think your inputs look weird. In your top post, you said it'd be "Jane Doe", now you're throwing a comma in, but usually if you have a comma, it's last-name first: "Doe, Jane". I will say this: name[0:1] is the same as writing name[0], and your code won't have to change much if you're not expecting a comma.
[Yes](http://docs.scipy.org/doc/numpy/reference/arrays.indexing.html).
It does work, but i posted it because i thought it wasn't completely correct. I followed a similar format that my professor gave the class and I still ended up with "J.D." 
For anyone wanting to consider those positions realize that the environment will be faster paced than anything you will probably ever work in. Your skill as a developer and as a people person must improve as a result and if they don't you will probably be looking for work when you contract is up (which could be short anyway). The industry also has a bit of a dark side to it that most people who are unfamiliar with it don't realize. So if you choose to interview it's worth doing a little research both below and on your own. Some of these links are not about ILM but their content is still relevant especially since many of the companies talked about here have been around for a long time: http://news.dice.com/2013/04/03/lucasarts-game-development-shut-down-by-disney/ http://www.cartoonbrew.com/disney/disney-dreamworks-pixar-lucasfilm-sony-are-sued-in-wage-theft-scandal-103501.html http://www.siggraph.org/discover/news/whats-wrong-visual-effects-industry http://variety.com/2013/digital/news/lucasarts-shutdown-triggers-layoffs-at-ilm-1200332765/ http://variety.com/2013/film/news/rhythm-hues-bankruptcy-reveals-vfx-biz-crisis-1118066108/ http://money.cnn.com/2012/09/11/technology/digital-domain-bankrupt/ http://www.npr.org/2013/03/19/174703202/visual-effects-firms-miss-out-on-a-films-success https://www.youtube.com/watch?v=9lcB9u-9mVE
There not really much to add to what others have already said except that this post would be better suited for /r/learnpython (not that they will or should do your homework for you either)
I want to invent flake8 goggles.
Good post - but for the record, don't name a variable t or l. Give it a name that makes sense within the flow of the program! The following snippet is proper naming, as you have a list of flavors belonging to a particular brand ('whizzo') of chocolate! whizzo = ['Cherry Fondue', 'Crunchy Frog', 'other thing', 'cockroaches'] 
I forked your project and added in setuptools entry points, so you don't have to call image\_scraper/\_\_init\_\_.py. 
There's also that man on a quest to doing it in one line: http://www.petercollingridge.co.uk/blog/python-game-of-life-in-one-line
[This](https://pypi.python.org/pypi/PyMonad/)
Thanks for the feedback, /u/niwibe! Keep up the good work, you and your team! This tool looks great!
This is the best library I've found for creating SOAP webservices in python: https://pypi.python.org/pypi/Flask-Spyne/0.2 . It will generate a wsdl for you as well
Cool use of FFT and convolution! Why do you use 2 statements c[np.where((b == 3) &amp; (state == 1))] = 1 c[np.where((b == 3) &amp; (state == 0))] = 1 instead of just c[np.where(b == 3)] = 1 ? Did you want to keep it very generic, or am I missing something?
 def shut_down(s): if s == 'yes': return 'Shutting down' elif s == 'no': return 'Shutdown aborted' return 'Sorry'
 def shut_down(s): if s == "yes": return "Shutting down" elif s == "no": return "Shutdown aborted" else: return "Sorry" If you want to go further with this what I like to do is make a list of possible yes and no answers and then use that in the code. This would prevent typos from giving the wrong responses. def shut_down(s): # Convert input string s into uppercase letters s = s.upper() # Lists can be put anywhere outside of this function but I am # putting them here for simplicity's sake yesList = ["YES", "Y", "TRUE", "1"] noList = ["NO", "N", "FALSE", "0"] if (s in yesList): return "Shutting down" elif (s in noList): return "Shutdown aborted" else: return "Sorry" However that is a bit outside of the scope of the code academy lesson. Out of curiosity where exactly were you having problems with this? Also the people over at /r/learnpython will be much more willing to help you out. This subreddit is more for python related topics not for help.
Thnx bro this worked out cool for me but wanted one more help from you plz explain me the 7th and 8th line code
the two lists from line 7 and 8 are essentially what your computer is checking against what the input, s, is. Notice how in line 10 and 12 it isn't saying "if (s == "yes") " and instead is saying if (s in yesList)" What it is doing is seeing if the input, s, is in the list yesList. This makes it so that somebody could just type in "y", "1", "True", or "yes" if they don't want to type out the full yes or aren't sure what exactly they are being prompted to answer. In most cases this would be unnecessary in procedural programming but assuming this is going to take in human input it is nice to have more fail safe options just in case they type in something different.
double equals for relational operator, my friend (X less than Y, X equals to Y...) One equals is an assignment operation. Set foo to bar `foo = bar`
I am using suds and it works well with soap/wsdl services.
Reminds me of NaN, and yes, the Null object pattern. The problem with these operations is that you don't know where the NaN (or the Maybe, in this case) originated from. 
Two non-python projects that have solved this problem are [processing](http://processing.org/) and [love2d](http://www.love2d.org/) - processing has a simple IDE with options to export to win*, mac and linux. win* and mac executables look like native apps. - love2d is in-itself the executable, the developer just adds the .love (a .zip with different extension) to the executable and the application is ready for distribution. I'd love to have something like love2d with pypy support.
For me at least, it totally misses the point of using Flask. It seems like you are trying to make Flask into something else, less flexible, more structured, more auto-magical. That being said it's an interesting approach. Good luck.
Interesting! I can see the potential use, so far I've been using flask for small projects but I might consider this as I have been looking at flask-Classy anyway. 
This slices the 2D array K in both dimensions, to extract a 3x3 array centred on (m/2, n/2).
And is it pyQT or just QT? 
Yeah that's another case where I'm being more general then necessary. I'm going to add an addendum at the end of the post where I show what happens as you adjust the rules and kernel. I have some results there that are really cool.. 
Well if you want structure and framework you should go with django. 
like the self-hosting option
The problem is that going through your entire code passing maybes around is exactly that; bad design. The better way to handle this is to lift the maybes out of themselves as soon as possible and treat it as an exception and try to gracefully correct. Maybes are nice and type safe, but using them everywhere just so you don't have to handle errors is not an ok way to do things. 
The "[subscript operator](https://docs.python.org/3/reference/expressions.html#subscriptions)" is what computer science types call array indexing, i.e. [].
Thanl you very much, i'll try
found this for searching something. really good post.
#justwindowsthings 
Finally a definition of *lift* I understand.
PyPy uses an actual garbage collector and not just reference counting, so you will get effectively unpredictable pauses due to the gc. In general that's not a big deal but for game development that could be a big problem. 
Python, with Cython for performance-critical stuff. This is pretty much what Kivy does: OpenGL bindings and low-level functions in Cython, application scripting in Python.
Yeah, I don't agree with that at all - if I'm looking at someone's resume and I see a github link on it I lean way more heavily on that then I do any other aspect of it. 
Modern games have code sections that are programmed in assembly for best performance. Forget about Python. ...unless you don't really need "best performance". But you haven't given us any specs to go on, so we have absolutely no frame of reference in which to answer your question.
If you're doing a anything with a lot of array manipulation, I'd really try just using numpy. If not, I'd take PyPy to start with. It's literally just Python code. &gt; Doesn't PyPy get around the GIL No. Jython does though.
If that's the case, then why is it that Steam requires a DirectX and Microsoft Visual Studio C++ runtime before most games can be launched?
There is an app for that. https://github.com/grue/django-quickbooks-online
You don't even need to move to Jython or IronPython to get around the GIL, just operating outside the GIL is sufficient in a lot of cases.
I've been working on pysd2l-cffi specifically to be able to use PyPy for (hobby) game development - using cffi because ctypes performs horribly on PyPy. I've been very happy with it so far. Frame rates are typically ~5x higher than CPython for examples I've tried. The kind of algorithmic "loop over an array of tiles" code games often do can be expected to be very JIT-friendly. Don't worry about the garbage collector. CPython has one too; it is used to collect reference cycles. When you are doing 60fps with time to spare in PyPy, the ~5x framerate improvement gives you plenty of time to run the garbage collector. While I don't notice the garbage collector, I do notice some funny behavior related to the JIT warmup time. My tiled map demo renders past the edges by repeating the last edge tile; this is a different branch in the hot "what's the tile for a given coordinate?" function. There are a few slow frames the first time each edge of the map is exposed! So if you want to scare people away from PyPy you could try mentioning JIT warmup instead of worrying about its pretty-good garbage collector. According to the release notes PyPy 2.4 has improved GIL handling. PyPy-STM removes the GIL, but they say "We didn't try so far to optimize the case where most of the time is spent in external libraries"; in any case, CPython also releases the GIL in this case.
I would recommend pypy personally due to the CFFI. Also the garbage collector is decidable at translation time and the best IMO [is configurable via env variables](http://pypy.readthedocs.org/en/latest/gc_info.html#minimark-environment-variables). Games are written in .NET or Java that also have indeterminate garbage collection, as well as for the most part collections are "fast enough" to never notice. No matter what you will have collection pauses when using any VM language, best to choose one that is configurable and optimizing no? Anywho, the reason that I recommend PyPy+CFFI is how much easier it is to integrate with pre-compiled C code (.dll/.so) such that I can write my fast code (eg physics) in C and toss it to a thread from PyPy via CFFI. Thus never touches the GC or the GIL.
Interesting concept, unfortunately most use cases for such address parsing would be on the internet not the muricanet.
I can see some really good uses for it in my day to day work. Namely cleaning up 10 of gigs of addresses from an old system before I load it into a new system
This sounds more like what Python does by default: raise a TypeError as soon as you try to do something with a NoneType. It's the "ask forgiveness" way of avoiding the multiple "if foo is None" tests that would otherwise disguise the calculation you're trying to do. I enjoyed Senko's discussion of an alternative, but I'm inclined to leave well enough alone.
The new PyPy STM stuff does get around the GIL, but it's not really ready for production use yet.
100% agreed... *in Python* What's useful about Monads in say, Haskell, is that they can be used to define sequences and abstract non-determisism. I don't really get the point in a language which supports imperative procedures...
It appears to be a tagger. As such, it's returning (word, tag) pairs, not the (key,value) pairs, which a dict would need.
This might not help you that much. It might be able to extract the fields from a raw string, but typos and invalid/non-existent addresses will remain. I have a similar use-case. There are a few libraries out there like this, and I didn't find them all that helpful.
In the end, the sys approach actually worked better, because it let me write a simple function to do this: [lift_to_module](https://gist.github.com/RemyPorter/441e5d01d5b828152297)
http://fabiensanglard.net/quake3/ - Quake 3 architecture overview, fairly interesting stuff. All of the Id Tech engines are borderline works of art, especially in how well the Id engine team separated out major points of concern by using threading &amp; SMP ( eg multiprocessing for sadist ). Yeah Python/PyPy may suffer some performance issues but keep in mind that while performance is important, when I first started to learning to program anything I ran into a lot of unforeseen consequences or unknown unknowns. If you're comfortable with Python, start with Python in small steps towards where you want to be but also keep in mind when the tool/language isn't working to meet your goals and move to something more ideal. Game development can be both insanely frustrating but rewarding once you start getting it going.