&gt; Generally functions are defined when the interpreter evaluates a def. Functions are not re-defined when called. I do not think it is unexpected at all, at most a thing of "Oh, why didn't I think it through". I understand that, and the implementation makes sense when you consider how the interpreter has to deal with it. It's just that my mental model of how this works is like what I have to do when I don't have default parameters in a language, overloading, e.g. def foo(d={}): ... gets expanded to def foo(): return foo({}) def foo(d): ... In which case the mutable behavior doesn't really jive. I'm not saying the current behavior is wrong, it's just unexpected to me and at least one other person.
 def lazy_setdefault(_dict, key, lazy_func): if key not in _dict: _dict[key] = lazy_func() return _dict[key] (this could be generalized with a lazy value class. )
Indeed, Python does not make sense when the mental model of how Python works is not about Python, but something completely different.
Holy crap. It never ceases to amaze me how many features Python has that I *still* haven't come across yet.
I think 3.0 does that.
That does not mean you should not use them. It means, you can make your program faster by inlining stuff inside a bottleneck.
Mine are collected here: http://eli.thegreenplace.net/programs-and-code/python-insights/
I think of `str()` as a constructor. The length of an object is determined based on the instance, so `len()` should ideally be a method. As traditionally functional language constructs, `map()` and `filter()` are acceptable as top-level functions for historical/style reasons. Personally, I do think that they would look better as collection methods.
I've been using wxPython so far. I've used Qt from C++ before, and loved every minute of it - it's an amazingly designed library with powerful capabilities. Qt will become LGPL soon, which is excellent news for the whole C++ development community, but has ramifications for Python too. Now, wxPython has lost its strongest advantage over PyQt. What do you think? 
It has been possible to use (Py)Qt for FOSS projects for some months already. Personally I use PyGTK. All these Qt folks repeating over and over again how great Qt is and how horrible GTK go on my nerves.
You are aware that the license of PyQt did not change? So Qt switching to LGPL doesn't make a difference at all.
So you want to get rid of operators too, for consistency?
By compiling non imperative programming code to imperative programming code. It's all turing machines, and some things are substantially easier to formulate in different language idioms.
I assume PyQt will switch to LGPL. IMHO there's a very little chance of this *not* happening. 
I express no opinion of GTK as I've never used it. But Qt is a whole league of its own when it comes to API design. After years of being bogged down by complex C++ frameworks, Qt was a fresh breeze and C++ programming was fun again. 
Why should they? Don't get me wrong, that would be really great, but they are trying to make some money with it (which is fine btw).
For the same reason Qt released theirs, methinks. They will be pressured by the community for taking a LGPL product, wrapping it and releasing as GPL. If they don't, someone else eventually will provide alternative bindings that are LGPL.
Agreed.
The same reason? You mean Nokia owns PyQt and has compelling business interests in releasing it freely? Or that Riverbank has a mobile platform that it's trying to popularize?
[PyPy](http://codespeak.net/pypy/dist/pypy/doc/) may eventually supply an interpreter without global lock and compilable down to C
Wouldn't the extra tests slow down `__contains__` in the non-silly cases, which surely would outweigh the need to occasionally use ranges of unusual size?
&gt; Because len() tells us about an intrinsic value of a single object. So do all the others, at least the ones that don't operate solely on collection (unless I'm wrong about the meaning of intrinsic). So at least abs, chr, ord, dir, hash, hex, id, oct, repr and str.
&gt; How do you propose we solve this utter and fundamental problem if all processors are fundamentally imperative? Well there are two possibilities here: * Go back to the foundations and rip out the Von Neumann architecture and create something better, I fear that's only a dream though * Have a non-imperative layer expressing better parallellization semantics to the language's user (so a better programmatic API to concurrent execution) built on top of the raw system. That's what e.g. Erlang or Haskell do.
They're not. Think of it that way: a list has order, a tuple has structure. Lists are homogeneous sequential containers, tuples are heterogeneous data structures (think structs without tags) If you're worried about performance and memory characteristics to the point of replacing lists with tuples, you might want to stop using Python.
I think the original logic behind `len` (and `str` and some other builtins) was that tuples and strings, being immutable, were not objects and could not have methods. This changed when the string functions were turned in to methods of string objects, and the old `string` module became obsolete. Given the confusion in other languages, where the number of items in a container is randomly `count`, `size`, `length`, etc., more or less at random, I appreciate having one short and easy-to-remember function instead... 
&gt; A tuple is basically a composite data structure used to bind related data together into one piece. The fact that they are iterable makes them a little confusing to some, though, I agree. Tom Lynn's comment in [this post about lists and tuples](http://jtauber.com/blog/2006/04/15/python_tuples_are_not_just_constant_lists/) expresses the difference perfectly: &gt; Lists have order, tuples have structure. Too bad tuples are implemented as immutable list in Python
Following up on various previous comments on the xrange issue, the documentation states: Note: xrange() is intended to be simple and fast. Implementations may impose restrictions to achieve this. Generally, the overhead in processing each bla() in a ''for i in xrange(2**32): bla()'' situation will far exceed whatever processing goes on in the actual iteration. So writing your own XRange class with __iter__(), __contains__(), __len__() and whatever other methods are needed is not going to pose any significant overhead over the builtin xrange. Move on people, there's nothing to see here.
First off, I'm a rabid gnome fan and will be a gnome user for a long time to come. I am, unfortunately, sometimes forced to use Windows. GTK is technically cross-platform but it has problems on all other platforms besides *nix(less so on OSX now that there's a native implementation, or so I hear). Try creating an application ON WINDOWS that uses gtk, gstreamer and all the rest. You will quickly learn why Qt going LGPL is such awesome news. I wouldn't use it in C/C++, the preprocessing has always scared me. But for python, it's awesome. Don't like PyQt? Not pythonic enough? If they don't extend their license to LGPL and/or make the library more pythonic, there will soon be a new set of Qt bindings for python as wxPython with all it's horrible deficiencies will be overtaken as the cross-platform python UI of choice.. If I was them, I would be extremely pissed about the news. They're backed into a corner now. Probably incoherent but I tried.
Extract unique values from a list: &gt;&gt;&gt; def nub(lst): ... return list(set(lst)) ... &gt;&gt;&gt; nub(['h', 'e', 'l', 'l', 'o']) ['h', 'e', 'l', 'o'] 
I think I read it on his blog.
Is there something about wxPython you don't like? I've made the "grass is greener" mistake several times, and it's a particularly expensive one to make in GUI programming, where it can take substantial time to recode everything in a new framework. I have a little wxPython+OpenGL graphics suite that I've ported from Tkinter+OpenGL, to PyGTK+OpenGL, and now to wxPython+OpenGL. I have to admit that I'm impressed with some of the features of PyQt, but I would need some pretty compelling reasons to port my code base over to a new platform. wxPython is far from perfect, but I don't want to recode everything just because something else is shiny.
if you have one and the other raises a NotImplemented, it should work as you say.
I agree with the article's general criticism of len. &gt; What's curious to me, though, is that it's &gt; always len() that people pick on, and never &gt; anything else Right - the one I had in mind was 'del'. In general, I think python has its crotch on the fence on these issues. For getting something from a dictionary you do dict.get(key). But to delete from it you do del dict[key]. Yes, I know about dict[key] also, but the equivalent for del in the method list seems to be 'remove'. Why is there no standard syntax for "add"? Instead of saying add collection['blah'] item_to_add, you have to say collection['blah'] = add. I don't care about these things any more, but it's confusing to the people I've taught python basics to. Although this will be affected by fact that they were coming from Java. I've learnt to love the python standard library, and if I'm working on a project where syntax is important enough that the python version is annoying me I switch to io language. I usually end up moving back to python once I'my prototyping has let me work out what I'm doing. 
Seems like a plausible implementation to me. Then again, that's probably why I don't write interpreters.
wxPython is nice. However, I've found UIs to be somewhat sluggish - especially if you're dynamically generating them based on user input and using lots of layouts and sizers for alignment. It's possible that I'm Doing It Wrong, but I have not had the same issues with PyQt, which I decided to go with recently. And then there's style sheets: This is such an awesome feature, I'm surprised that I didn't even know about it until I accidentally saw a 'setStyleSheet' method in some document. Nearly all Qt widgets can be styled to various degrees using their own css-like language. 
Yes, they are. What the fuck. Python lists don't need to be homogeneous at all. &gt; If you're worried about performance and memory characteristics to the point of replacing lists with tuples, you might want to stop using Python. Clearly you've never worked with big data sets. Or ever had the need to do any performance profiling. Thanks armchair gurus.
I totally agree that changing GUIs can be expensive. But I'm at a point where it still wouldn't be too painful. I've used wxPy for a few months now and have lots of good things to say. But I also remember my experience coding in C++ with Qt - I was swept away by the beauty, consistency, orthogonality and power of its API. So I have reasons so suspect that grass to be greener...
&gt; Yes, they are. What the fuck. Python lists don't need to be homogeneous at all. They don't need to because of Python's dynamic typing nature. Doesn't change the fact that lists are understood and used as homogeneous sequential containers by... pretty much everybody. By the way that comment about lists being homogeneous sequential containers and tuples being heterogeneous data structures? It was lifted straight from Phillip J. Eby (aka PJE).
Eight warts in the author, not in Python :-)
If the current trend of more and more cores in CPUs continues, the GIL will have to be dealt with sometimes. When even the most simple and cheap desktop/laptop computer has at least 16 cores, it will not be fun to have a GIL. 
By "some months" I assume you mean somewhere in the range 70-80 months. PyQt has been available under the GPL since around 2002. -- Simon 
You shouldn't blindly trust people who some community says are smart. Don't drag CS principals further into the concrete world than they should be. -- Netsearcher (aka listens to facts not self proclaimedexperts.)
From this site: &gt;&gt;&gt; items = ['a', 'b', 'c', 'd'] &gt;&gt;&gt; for i, item in enumerate(items): ... print i, item ... 0 a 1 b 2 c 3 d &gt;&gt;&gt; That's awesome, thanks a lot! How come I've never heard of enumerate() before?
&gt; (Mutable) default arguments are shared across &gt; function invocations: Yes, that's unintuivite and that's not good. The best way to solve this problem would be to only allow immutable objects as default values. That should not affect performance in any way. However, then we need some simple syntax for expressing the immutable empty list and the immutable empty dict. 
Qt is sexy sexy sexy, and wxwidgets are sufficient. If you liked Qt before, I'd say switch, or at least try porting some code to see how it goes.
I find this trick for checking if your version of python has SSL compiled in to be quite handy. http://morlockhq.blogspot.com/2008/05/python-tip-checking-to-see-if-your.html
The difference, to me, is that len() is a question about an intrinsic property of the object that you're passing. In other words, len(obj) means: "What is the length of the object 'obj'?" On the other hand, str() means: "Please take this object, 'obj', and give me a string representation of it." It's a transformative thing, like oct(), chr(), list(), etc -- and even if the object has no idea how to make a string representation, I still get '&lt;__main__.class instance at 0x02801238&gt;'. As for map(), filter(), any(), etc, I think of those as "code shortcuts". If I make a class which supports Pythonic iteration, then suddenly all these functions automatically work. len() will *never* work for a custom class automatically; how could it? I always have to program __len__(). So why not obj.length()?
I tried PyQT a while ago, and liked it a lot - the class structure and naming seemed much better organised that pygtk, and the designer was a lot better than glade. However one major flaw I found with it was that it is very prone to segfaults when used in certain ways, which rather put me off it. IMHO this should *never* happen with a language as high level as python unless you're deliberately working at a low level (eg using ctypes). Admittedly, this was a while ago now. Anyone know if it still has these problems?
Is your mind ready to 'splode? Re-open a class, to add more properties/methods: import sys class ContinueMeta(type): def __new__(cls, name, bases, dct): if name == 'continued': return type.__new__(cls, name, bases, dct) existing = sys._getframe(1).f_locals[name] for k, v in dct.items(): setattr(existing, k, v) return existing class continued(object): __metaclass__ = ContinueMeta ### Testing ### class Widget(object): def __init__(self): print "Widget created!" class Widget(continued): def hello(self): print "Hello world!" ---------- &gt;&gt;&gt; w = Widget() &gt;&gt;&gt; w.hello() Widget created! Hello world!
There's a nice python2.6 extension to that @property technique to create setters in a similar way as well. class Parrot(object): def __init__(self): self._voltage = 100000 @property def voltage(self): """Get the current voltage.""" return self._voltage @voltage.setter def voltage(self, value): """Set the current voltage""" print "Voltage changed.""" self._voltage = value 
But we're still going back to an imperative language which is, allegedly, completely and utterly broken for multithreading.
This is ripe for abuse. I love it.
There are a ton of cool tricks I learned from here: http://www.siafoo.net/article/52 My favourites would have to be (python 2.5+): numbers = [1,25,50,75,100] if any(number &lt; 100 for number in numbers): print "Atleast one number in this list is less then 100" There is also all() with similar syntax, that checks for all elements in the list to match the clause. Also, an easy way to check if a list is unique and has no duplicate values: if len(numbers) == len(set(numbers)): print "A unique list!" There's tons more in the link I posted :) (p.s how do you do "code" text on reddit? textile @code@ does not work.) 
But you *are* working at a low level. You're going from Python which runs in a managed / VM environment to C++ (Qt) which is anything but. The only way you can harden this would be to run Qt in a VM too, (or choke the Qt source with so many argument and parameter checks etc that the whole thing grinds to a halt). -- Simon
From the API perspective I find PyGtk nicer than PyQt. From the aesthetical perspective I prefer the look and feel of Gtk over Qt. PyQt may be the better choice if you want your app to be usable on Windows, and you're unhappy with wxPython.
I'd argue that if it's really that complex it should be encapsulated behind class method and properties. Though it should be noted that the majority of my Python work is with OOP so your mileage may vary.
You might as well claim *any* python is at a low level - in calling nearly *any* library functions (including the builtins), you're ultimately calling through to unmanaged C code. In C or C++, It's reasonable that mismanaging memory produces a segfault, but in a managed language, it shouldn't be *possible* to mismange memory - it is the library's responsibility to wrap any object it retuns with python refcounting so that so long as python can reference it, the object is alive. Pretty much every python library (including other GUI toolkits) work this way. Fundamentally letting a segfault through to the python layer is a bug in the wrapper. 
PyGtk is great purely for GUIs. But Qt is even better, had better 2d/3d support. Full WebKit integrattion. And with scintilla i had full on syntax highlited text editor with little effort on my part. Plus Qt loks better in Windows than Gtk
You are assuming that crashes are always memory management related. PyQt does a really great job of tracking memory. But it is still possible to pass null pointers into Qt methods, or call methods in the wrong order (i.e. using methods before QApplication has been created etc). There are plenty of cases which can blow up and it would be a big task to harden every PyQt method to check for every potential problem. -- Simon
The point is that if you used PyQt you had to write GPL software or get a commercial license. It was changed some time ago so that you could use BSD, MIT, ASF and other licenses for your software. Basically you only had to pay for building propietary apps and that restriction will be lifted now.
For C++ this might be very true and I'd probably also use Qt if I had to use C++, but we were speaking of Python, right?
You are right, sorry :) It's definitely a function to check out quickly though
&gt; Try creating an application ON WINDOWS that uses gtk, gstreamer and all the rest. You will quickly learn why Qt going LGPL is such awesome news. I don't bother with Windows, this is most likely the point where we differ. I have only used PyGTK on Windows and it was ok. By the time, there was no Gstreamer for Windows anyway. &gt; Don't like PyQt? Not pythonic enough? No, not really. I could complain about the naming style (`QSomething` is really useless if you have namespaces) and then there are problems that the bindings don't hold references to stuff like images. You have to reference the image somewhere else the GC comes and deletes it and Qt won't be able to display it. This is really something that just shouldn't happen in a binding. &gt; If I was them, I would be extremely pissed about the news. They're backed into a corner now. Yep, I wonder how Riverbank is going to make money now. Qt Software doesn't need to be profitable, since Nokia can pay for them.
But there might be a point where Qt doesn't need to make profit but PyQt does.
&gt; I don't bother with Windows I wish I had that luxury. &gt; No, not really... Totally agree. That's a binding issue though, not a Qt issue. They'll fix it or someone else will get tired of it and scratch their own itch. 
&gt;But it is still possible to pass null pointers into Qt methods From python? How? There's no such thing as a NULL pointer in python (again, bar ctypes style low-level stuff). Any python object passed to the Qt layer has to be translated to the appropriate type, and invalid arguments should generate an exception at that point. Similarly allowing calling methods in the wrong order to produce a segfault (rather than an exception) is really poor practice - generally the constructor should ensure a consistent state. Without the possibility of passing garbage memory addresses, there's really no excuse for allowing a segfault - any case of it should be considered a bug. This is really not as hard as you're making it out to be: *every* python wrapper to a C library (again, bar ctypes etc) will follow this practice, and a segfault will be considered a bug in either the wrapper or the underlying library. I've **never** seen other python GUI libraries, such as Tkinter, pygtk or wxwindows segfault for instance, no matter how you use them. The reason I believe the problems I had were memory related was from the symptoms. From memory, the main problem I had occurred when keeping the string argument to a signal around for longer than the signal handler - using it after it had returned gave a segfault, which strongly suggested to me that Qt had decided to free the string despite a python reference existing (or maybe even was storing the data on the stack). (For the record, I just retried that using PyQt4.4.3, and wasn't able to reproduce it, so either this has been fixed since then or I'm misremembering the cause.) 
&gt; There's no such thing as a NULL pointer in python Sure there is, "None". &gt; invalid arguments should generate an exception at that point. And that is the crux of the matter. What is an invalid argument? Some methods will take an object as a parameter but will also accept a null pointer (i.e. python None). While other methods will not. For a library the size of Qt, I don't think it is practical codify all of these constraints. Also a lot of methods in Qt, and KDE's libraries, assume that they are running in a certain context. They assume things like the application object has been correctly instantiated and started up for example. -- Simon 
`&gt;&gt;&gt; xdict = {'a': 1, 'b': 2}` `&gt;&gt;&gt; xkeyset = set(xdict)` `&gt;&gt;&gt; xkeyset` `set(['a', 'b'])` Yes I know it's nothing radical or mind-blowing, just convenient for doing dictionary subsets. *Edit: Forgot my favorite. The lovely `in` operand. `&gt;&gt;&gt; foostr = 'fooo string'` `&gt;&gt;&gt; 'foo' in foostr` `True`
Direct manipulation of a classes internal dictionary to add and set large numbers of attributes: class Bla: pass b = Bla() items = ["Temperature", "Pressure", "Entropy", "Enthalpy"] vals = [250, 120, .23, 1450] for i, v in zip(items, vals): b.__dict__[i]=v &gt;&gt;&gt; b.Temperature 250 &gt;&gt;&gt; b.Pressure 120 At the moment attributes are stored in a dictionary __dict__ and this can be manipulated directly as shown. Not recommended, since if the internal representation of attributes ever changes, then the code will break, but quite useful.
Nope - None is *very* different to NULL. It's just a standard object - you can't dereference it or treat it as another type. If you're saying the wrapper should just map it transparently to a NULL pointer and not care about the expected type, then I disagree. Pretty much all wrappers (including PyQt) wrap each method with a description of what arguments they take - they *have* to, to know how to convert python types. Allowing NULLs where they're as invalid a type as integers is just a bug. Indeed, this is not a problem PyQT suffers from either - give it a try and you'll get a TypeError(). I've managed to reproduce the original (or at least **a** problem) now. The issue seems to be that it hands out pointers to internal buffers of various widgets, without applying refcounting on it. Keep that reference around longer than the widget and it'll become invalid. Here's a simple program that will cause a segfault for instance. Note the lack of passing None or invalid types to any object - this is a simple lifespan management issue: from PyQt4 import QtCore, QtGui class PromptForText(QtGui.QMainWindow): def __init__(self): QtGui.QMainWindow.__init__(self) e = QtGui.QLineEdit(self) e.connect(e, QtCore.SIGNAL("textEdited(QString)"), self.change) self.text = None self.connect(e, QtCore.SIGNAL("returnPressed()"), QtGui.qApp, QtCore.SLOT('quit()')) def change(self, text): self.text = text app = QtGui.QApplication([]) prompt = PromptForText() prompt.show() app.exec_() print "You typed %s" % prompt.text # Segfaults on this line
[-] {-}
I doubt it - \_\_contains\_\_ would boil down to something like: return (self.start &lt;= x &lt; self.stop and (((x-self.start) % self.step) == 0) Thats going to beat iterating through list elements on anything but the smallest lists (&lt; 5 elements). I'd say 90% of the time you'd come out ahead, often by a very large amount. **\[Edit\]** Actually, its slightly more complicated than the above, as I'm not handling reverse ranges there, but that shouldn't add more than one extra comparison.
What are the non-silly uses of `x in range(y, z)`? At any rate, someone must have agreed with you, because apparently in Python 3.0, `range` objects still don't have `__contains__` methods.
It doesn't look like it. I just tried it on my install, but it looks like it's still linearly scanning. (This is rc1 rather than the final build though)
Also try/except. However I never use it because it's always non-obvious to me what it does. "else" doesn't really signal the right meaning to me in those contexts.
There are plenty of places in PyQt which accept an object and will convert a None to a C++ null pointer. For example every widget has a parent parameter which is often null. It looks like your example shows a real limitation of PyQt. (work around is to use unicode() in change() ). Refcounting an (internal) C++ object that has been passed out of a C++ object doesn't work because PyQt isn't told by C++ when the object is destroyed, nor can it forbid the C++ code from freeing the object if Python has a reference pointing to it. It's a tough situation. -- Simon
Blame the Dutch.
It wasn't accepted: Python 3.0 (r30:67503, Dec 3 2008, 23:20:17) [GCC 4.0.1 (Apple Inc. build 5465)] on darwin Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; dir(range(1)) ['__class__', '__delattr__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__iter__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__'] 
I agree with about half of these, and I'm ambivalent about some of those. - **len().** Yeah - other \_\_magic\_\_ methods have the rationale that they're part of a more complex protocol, but len() is never anything more than "call the object's \_\_len\_\_ method. It should just be len(), without the builtin. - **the GIL.** To be honest, I don't care about it much. The only things I've written that really need to take advantage of multi-core speed are cases which are trivially parallelisable with processes. YMMV obviously though. - **Mutable defaults.** Agreed. This should have been implemented as code executing when the method runs. Unfortunately it's not really changable now due to backward compatability. - **(1) != (1,)**. It's not perfect, but what's the alternative? I can't think of a nicer solution that preserves the meaning of both brackets and tuples. - **2\*\*29 in xrange(2\*\*30)**. Not a big issue really. I wouldn't classify this as a wart, but it seems like a trivial improvement to implement with no downsides so I'd be in favour of implementing it. - **Decorator syntax**. I disagree. It seems as good as any of the proposed alternatives at the time. This is a pure bikeshed argument. - **labelled break**. I disagree. I find the current possibilities less ugly than the methods in the PEP. It adds syntax to solve a problem that's more clearly solved even with a flag variable method. - **list.copy()**. I disagree. `l[:]` **isn't** the best solution, nor is a new `l.copy()` method. `list(l) is`. If you want to construct a new list, use the list constructor! 
&gt; **Mutable Defaults.** This should have been implemented as code executing when the method runs. Unfortunately it's not really changable now due to backward compatability. That would mean that using a local variable inside an expression evaluated for a default value would use the *last* value that variable had rather than the value it had at the time the function / method is created. Your default values would be affected by code that comes *after* the function definition, making for some very odd and equally obscure bugs. You also would no longer be able to use default values to capture local variables inside a loop.
No GIL in IronPython or Jython.
Yeah - using in on a range is pretty odd in my opinion. I don't think I've ever done it. I have sliced ranges and used in on the result though.
Doing the loop inside a function with an early return is one elegant way round this. I have used the 'stop' type code many times though. I think adding named labels would be worse than the current situation.
I love decorators. I've never even *thought* about the syntax. It is simple and uncluttered - but I guess totally unobvious if you don't know what it means. On the other hand if you come from Java you will recognise it and if you come from C# you can probably guess the intent if not the precise semantics.
Hmm... looks like you don't want Python *at all*. I'm sure there are other languages you'll enjoy though. ;-)
No - it already returns an `xrange` object - definitely more than an iterator, as you can index on it, as well as iterate. ie: &gt;&gt;&gt; r = xrange(10) &gt;&gt;&gt; r xrange(10) &gt;&gt;&gt; r[4] 4 &gt;&gt;&gt; iter(r).next() 0 Similarly in python3, `range` returns a `range` object with similar behaviour: &gt;&gt;&gt; range(10) range(0, 10) 
&gt; len() is a weird special case. Not at all. If you look at the container protocols there are no other methods without the double underscores. Length is part of the container protocol and having one of the protocol methods not use double underscores would be a special case.
&gt; . For getting something from a dictionary you do dict.get(key). No, *generally* you do something[key]. del is at least consistent with that syntax. get is a method with additional semantics than merely fetching an item. 
No - it would reevaluate each time the function was called without a default. It should effectively translate the code: def foo(a,b, c=compute_default_value()): to: _undefined = object() # Sentinel. def foo(a, b, c=_undefined): if c is _undefined: c = compute_default_value() The only thing you'd lose is the ability to use arguments like C-style function scope static variables) eg: def f(x, _memo = {}): if x not in _memo: _memo[x] = calculate_x(x) return _memo[x] But I think this is an acceptable tradeoff. Using globals or a closure is a better way to implement this.
The homogenous / heterogeneous distinction is one observed far more in theory than in practise. In practise everyone treats tuples as immutable lists.
So what would the following do? x = 3 def func(a=x): ... del x func() Or what about: callables = [] for i in range(10): def func(a=i): print a callables.append(func) for func in callables: print func() If `compute_default_value()` means re-evaluate the expression then it suffers the problems I mentioned and you do lose things.
&gt; In practise everyone treats tuples as immutable lists. There are at least 3 or 4 persons who don't, possibly more. And that's without counting those who use FP languages on the side.
But that becomes an implementation detail of the OS/runtime. If you have smart enough people who spend long enough on a problem, they might be able to solve it using broken tool (and create systematic methods/patterns to that end). When every programmer and his brother has to solve the issue with those same broken tool, there's no way it ends well.
if you did count them you might be up to 5. ;-)
 join = str.join join(" ", ["a", "function", "approach", "is", "also", "easily", "remembered"])
&gt;IF YOU HAVE TROUBLE, FILE BUGS WITH ME (email/IRC) OR STFU hehehe
&gt;There are plenty of places in PyQt which accept an object and will convert a None to a C++ null pointer Yes, but I'm saying it's not unreasonable to allow this only where NULL is valid. Each function generally has its wrapper (usually autogenerated from some description format) which is responsible for mapping the python types to the right Qt types (including refcounting etc). NULL is just one more possibility as to what is allowed or not. I'm not aware of any place in PyQt or other libraries that let you pass NULL somewhere where it's not a valid input, and I would classify allowing it as a bug in the wrapper layer. &gt;It's a tough situation. I think the right behaviour would be not to give out access to such buffers directly at all. A copy of the state would seem more sensible (which is what QLineEdit.text() returns for instance)
&gt; No, not really. I could complain about the naming style (QSomething is really useless if you have namespaces) I don't mind all the Qs. I'm used to them being part of the *identity* of the classes and I grew to like them namespace or not. Beside, it's much more Google friendly, QImage will find what you want much faster than Image. What bothers me is all the setters and getters, there should be a generous use of property() applied in there!
The first would give a NameError as `x` isn't bound at call-time. I don't think this is a bad thing in this case. However, I see what you mean now about for loops with your second example. You're right, that idiom won't work anymore, and there isn't really a satisfactory alternative. You've halfway convinced me, but I think I'd still prefer a delayed binding default behaviour with some other method added to create definition-time bindings within a function's namespace. Possibly provide a decorator that transforms an existing function into an otherwise identical one that has bindings injected into its locals, usable like: @bind(a=i) def foo(): print a It would require low-level bytecode hacking to implement in pure python currently, but could be done if implemented as part of core python. **\[Edit\]** Actually thinking about it, creating a define time binding *would* still be possible, as you could just create a closure. def make_func(a): def func(): print a return func callables = [] for i in range(10): func = make_func(i) callables.append(func) for func in callables: print func() It *is* a bit more verbose, but nicer in some ways too (your funcs don't have an `a` parameter that may confuse introspection by callers.
Mutable defaults are quite common however. Functions for instance have mutable attributes, so could show this problem, do we need to ban them as default parameters? Also, pretty much every python class instance you create is mutable, but there are good usecases for binding (for example) a `default_config` object to a constructor parameter. 
I would have if they had the forethought of switching the two acronyms.
I would have if they had the forethought of switching the order of the two acronyms.
&gt; The first would give a NameError as x isn't bound at call-time. I don't think this is a bad thing in this case. Right - but if the del, or some other mutation, occurs further down in the code then the reason for the oddity would not be at all apparent. It would just be a different gotcha.
&gt; The first would give a NameError as x isn't bound at call-time. I don't think this is a bad thing in this case. Right - but if the del, or some other mutation, occurs further down in the code then the reason for the oddity would not be at all apparent. It would just be a different gotcha.
 nub = list . set Oh, wait...
 nub = list . set Oh, wait...
 nub = list . set Oh, wait...
 nub = list . set Oh, wait...
I think that would be a much rarer gotcha, and easier to comprehend without needing help. How often does anyone, especially a newbie actually `del` module-level variables. The only real reason for doing it is tidying the namespace, and even then something that you're using as a default is probably something you want to expose. 
It isn't just deletion - that's probably the most obvious error. You would still have an issue with mutable values. Any mutation would leak into the function. There are other problems as well. For example default values would have to be stored as the bytecode for the expression making introspection much harder.
What function do you call to share the password table with others? :-) I kid, I kid
&gt;Any mutation would leak into the function. That may be closer to expected behaviour for new users than otherwise though - we're used to define-time binding because that's what we're familiar with, but I don't think call-time binding is more surprising in the absence of this experience. &gt;For example default values would have to be stored as the bytecode for the expression making introspection much harder. You're right, that is another issue. In fact, introspecting the default as the resulting object is effectively impossible since the argument could be a complex expression with side effects. The best you could do is get the text of the evaluated expression. OK for doc generation etc, but not for some uses (though python3's argument annotation might cover some of those).
Wow they really dropped the ball on a decent acronym simply by swapping the order.
You are not right. min() has to examine each number - any() terminates on the first match. The any() solution is almost always much faster.
Yeah, you're absolutely right. I sometimes get bitten by my "shorter code is better" bias.
use your python IDE to browse OS folders/files and print filepath string or open filepath (not very useful unless your IDE has autocomplete) # filebrowser.py import os class fb(object): def _clean(self,s): letters = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ' numbers = '0123456789_' for n in s: if n not in letters+numbers: s = s.replace(n,'_') if s[0] in '0123456789_': s = 'A'+s return s def __init__(self, fp='C:\\'): object.__init__(self) self._fp = fp if os.path.isdir(fp): self._fl = os.listdir(fp) self.__members__ = [self._clean(f) for f in self._fl] def __repr__(self): return self._fp def __getattr__(self, key): if key in self.__members__: i = self.__members__.index(key) fp = os.path.join(self._fp, self._fl[i]) return fb(fp) else: return object.__getattr__(self, key) def __call__(self): os.startfile(self._fp) ------------------ &gt;&gt;&gt; f = fb('C:\\') &gt;&gt;&gt; f.Users.All_Users.Adobe.Acrobat C:\Users\All Users\Adobe\Acrobat &gt;&gt;&gt; f.Users.All_Users.Adobe.Acrobat C:\Users\All Users\Adobe\Acrobat() &lt;&lt;opens folder&gt;&gt; &gt;&gt;&gt; f.Users.User.Pictures.IMG_0123_JPG C:\Users\User\Pictures\IMG_0123.JPG &gt;&gt;&gt; f.Users.User.Pictures.IMG_0123_JPG() &lt;&lt;opens image in default viewer&gt;&gt; 
That's the point. Riverbank computing is not Nokia, whose profits every year are huge compared to the previous business of Trolltech. I think Qt was not making a lot in the last years.
So why does its \_\_contains\_\_ function iterate when it could do a constant time check?
You should take a look at the defaultdict class in the collection module.
Yes, but it's the same Qt underneath...
10x. I'm still not on the 2.6 train. When I get there I'll probably update the whole insights page.
But Stackless relies on the GIL in the same ways that CPython does. Tasklets and threads are technologically orthogonal things, as far as the bytecode interpreter is concerned (even though they look pretty similar to us). So I think IronPython, Jython, and PyPy are your best bets, and even PyPy uses a GIL currently.
Well, it's a great instinct. Really, if you had to pick one thing to optimize for, it should be that!
This code was written before I knew of its existence.
I terms of how easy it is to write concurrent programs. If concurrency was broken in imperative languages it was broken everywhere, which is absurd.
Pretty much just because no-one has implemented it. The objects have no `__contains__` method so `in` falls back on the iteration method. I'd guess it hasn't been done because testing membership isn't the core use case for range objects, but it seems like it would be a useful addition.
matrix traverse: a = [(1,2), (3,4)] zip(*a)
You add code blocks by the text indenting four spaces (with a blank line before and after), or you can enclose the text \` backticks (for inline code) ----- This is an `an example` ..becomes: This is `an example` ----- Example code: import sys sys.stderr.write("Example\n") ..becomes: Example code: import sys sys.stderr.write("Example\n") 
Decorators \\o/ def timer_dec(func): def the_decorated(*args, **kwargs): import time start = time.time() out = func(*args, **kwargs) # execute original function end = time.time() print "Time to execute", end - start return out return the_decorated # return decorated function @timer_dec def myfunc(a): import time time.sleep(1) print "\\o/" * a ..which would produce: &gt;&gt;&gt; myfunc() \o/\o/ Time to execute 1.00006103516 &gt;&gt;&gt; Another example, using a class decorator: import re class outcheck: def __init__(self, f): self.matcher = re.compile(f) def __call__(self, f): def wrapped_func(): ret = f() if self.matcher.match(ret): print "OK: Output matched regex" else: print "WARNING: Output did not match" return ret return wrapped_func @outcheck("([0-9]+)") def badfunc(): return "Hi" @outcheck("([0-9]+)") def okfunc(): return "204" ..which outputs: calling okfunc OK: Output matched regex calling badfunc WARNING: Output did not match Less standardly, in the `__call__` class decorator, you can do whatever you like with the function.. For example, I've written a really small web framework (well, it's more a URL routing system) - in the decorator `__call__` it the function to a list of "SITE_FUNCTIONS" (along with the regex to match the URL, like the above class-decorator does), which means you can do.. @GET("/") def index(): return "&lt;html&gt;&lt;/html&gt;" The code: http://github.com/dbr/pyerweb/ (`pyerweb.py` which is only 79 lines long. I've just added WSGI support and it's still less than 100 lines, which is the goal)
Except that the min() function runs at C speed, using C slots for method calls when possible, while the generator expression in any() runs at Python speed. In the example above, with that data, "min(numbers) &lt; 100" is about twice as fast. (even "sorted(numbers)[0] &lt; 100" happens to be slightly faster in this specific benchmark ;-)
| The timeit() method will run the code a specified number of times (default 1,000,000) and return the average time for code execution. The repeat() method will run the timeit() method a specified number of times, and return a list of the average times. Do you release code for hammering a server? In Reddit? Indeed, it is possible (and necessary) to test your own server in this way. However, what if a script kid hit s production server with your cute tool? something like a Google server? Google blacklists the offending IP and business goes on. an FBI server? Perhaps some men in black pays a visit to the kid. What do you think?
&gt; How come I've never heard of enumerate() before? You stopped reading code written by others when you had reached the point where you felt reasonably fluent? ;-) I'd recommend all Python programmers who learned Python in the 2.2/2.3 days (or before) to look at the following builtins and features, and make sure you know how they work and when to use them: * **enumerate** * **zip** * **any** and **all** (new in 2.5; emulation code for earlier versions available [here](http://docs.python.org/library/functions.html)). * generator expressions vs. list comprehensions * iteration over files and dictionaries * the different ways you can use **dict** to construct a dictionary: {"one": 2, "two": 3} dict(one=2, two=3) dict({'one': 2, 'two': 3}) dict(zip(('one', 'two'), (2, 3))) dict([['two', 3], ['one', 2]]) * the key argument to **sorted**, **min**, and **max**. * **itertools.groupby** (and the [clusterby](http://www.reddit.com/r/programming/comments/2l2sv/clusterby_a_handy_little_function_for_the_toolbox/c2l44s) variation by tmoertel) * **iter** * basic use of **set** (set construction, the **in** operator) If you're doing things to streams of data, the above gives you lots of opportunities to write faster and shorter code than before. For extra bonus, look at the more advanced features of **set** and the **itertools** module (beyond groupby).
superb! thanks.
But you don't need to rely on Qt that much. Python has its own sockets, it's own DB-API (with a great ORM) etc.
I otherwise like the syntax, like the standard library, like the available libraries and documentation, and love the object model.
I have always enjoyed Mark Summerfield's books.
A Python based functional language that compiles to Python bytecode would be very interesting (possible if you are sharing an object model - although making it a pure language without being able to statically verify the code would be tough - maybe a hybrid like F#).
that clusterby could be better... return [clusters[i] for i in sorted(clusters.keys())] should be return [v for k,v in sorted(clusters.items())] and you could also use collections.defaultdict to avoid the setdefault stuff push @{$h{$f-&gt;($_)}}, $_ for @$xs; does a nice job of showing why I hate perl. with defaultdict, the python code for that line would be for i in items: clusters[sigfn(i)].append(i)
I thought I already knew all this, but I was wrong.
True, but Qt comes with some additional goodies. Since it's so widely adopted, these are top-notch. Some examples: - QtWebKit - QtSvg - QtScript - a JavaScript interpreter. - QImage - QNetwork - Robust and optimized handling of XML - QSettings - QTemporaryFile - QHelpEngine - QSyntaxHighlighter - QFileSystemWatcher - QCompleter 
My thoughts exactly.
Not so much a Python wart as a Python stdlib wart, but close enough: * *tzinfo.* The lack of a time-zone implementation is a pain to work with when working with something that needs to do time. Batteries are not included with this. It's too small to warrant the dependency of pytz, but too big to not be irritating.
 * QtWebKit: usually replaced with BeautifulSoup, lxml and html5lib. For displaying you need a GUI though, but that's admittedly a GUI thing, so a GUI toolkit should handle it. If you need a programmamble browser with JS, there's currently PyKHTML. I'm waiting for a WebKit fork of that. * QtSvg: That's only useful in a GUI context, isn't it? * QtScript: Not that important in Python since you have a lot more dynamics built-in than in C++ to start with. * QNetwork: sockets, Twisted and asyncore all exist. * XML: ElementTree is in the Stdlib and it is hard to find a better library than lxml, anywhere (as much as XML is not really popular in Python-world, they have one of the most awesome libraries you can get). * QSettings: True, but pickling settings or saving them into a JSON file, or if you need it XML is not that hard. You write a Settings object which can query the data and edit the data. * QTemporaryFile: Python has enough methods of getting temporary files in a safe way. * QHelpEngine: No idea what that is. * QSyntaxHighligher: That's a GUI thing. If you want to use it outside of the GUI context, there is Pygments which is widely used and supports really a lot of languages. * QFileSystemWatcher: Admittedly, there is no cross-platform way to watch for file system changes. But there is no really good API either. Inotify can't track changes to a folder (I don't remember exactly, a friend of mine was complaining about it) and the Windows API equivalent does not work reliably. * QCompleter: No idea what that is. Care to explain?
Fuck, I'm a regex junkie and the title got me excited. Might as well be called regexes in Python 2.
That's something to keep an eye on.
yea... April seems so far away.
Wow, finally a post about importlib that _actually explains what it is_! I've been seeing importlib submissions pop up for a while now and click or search as I may I couldn't figure out what it was for.
This is probably going to be accepted, as it's shown it'd serve to replace a higher-order function use case.
While I like generator and list expressions (and this PEP also) - I simply cannot get this thing Guido (and other Pythoners) have against higher order functions. Are there any good arguments against them? (Readability doesn't fly with me, as I find `map(f, collection)` way more readable than `[f(x) for x in collection]`)
Don't see everything so black and white. It's not that hat to wait a few months.
very good idea, so simple yet elegant.
one classes??
Python has great support for higher order functions. It is one of its best features.
I know, but the community is somehow afraid of them. Guido wanted to *remove* map and reduce from py 3k.
Well, move them into a library not remove altogether. They're both trivial to implement anyway. Most introductions to Python include higher order functions within the first few pages - so I don't think the community is afraid of them.
&gt; Well, move them into a library not remove altogether. No, [Guido wanted to remove them alltogether](http://www.artima.com/weblogs/viewpost.jsp?thread=98196), as well as lambda. Moving them into a separate package was a compromise. Just google the thing, there is a resistance against higher-order functions in the Python community, which fully explains Wiseman1024's comment at the start of this thread. I mean no disrespect, but I heartily disagree with Guido's points such as this one: &gt; filter(P, S) is almost always written clearer as [x for x in S if P(x)]
Sure I know one can find ad-hoc solutions, made from a mixture of modules, for each problem (hey, that's why we love Python!), almost (replacing the whole WebKit engine is more difficult than you think, though). But in PyQt it all comes combined, in a consistent and pretty API, highly optimized C++ code with convenient Python bindings, and all coexists and binds together. That counts as a plus, in my understanding.
&gt; Inotify can't track changes to a folder (I don't remember exactly, a friend of mine was complaining about it) I think your friend is wrong here, inotify does track directory changes. If you need to do it from Python, take a look at pyinotify, the brief tutorial on the front page does exactly that with: wdd = wm.add_watch('/tmp', mask, rec=True) This watches the /tmp directory and rec=True also tells it to watch all subdirectories recursively. Either way, I agree that a cross-platform way to do this would be nice.
Sure. My point is that I wouldn't use Qt in Python if I don't need the GUI. If I do need it, I can just as well use it if it comes for free, true (does PyQt wrap all that stuff? AFAIK it doesn't wrap Qt3Support).
(Ths is a response both to voidspace and amar) It's not that they have something against higher order functions. It's that they have something against functions themselves: a function (at least in python) is a mostly opaque block of code, which takes inputs and does something with them. This prevents the python VM from making a number of optimizations, without some rather intense inspection. "map(f,source)" contains in fact two functions: "map" and "f". It's not "map" they hate, it's "f". It gets called over and over, and has who knows what side effects, so it can't be inlined, predicted, etc. List comprehensions, OTHO, provide description of what you're trying to do, but do it in a way that is syntactically clear enough that the VM can optimize it into some inline bytecode, frequently without any function calls being involved at all, and any loop variable being a VM-level variable, not a proper scoped python variable. This lets them be much faster, even when running on top of something else (like Jython on the JVM). It's in service of this goal that GVR has been creating ways to explain common programming Patterns (which exist at the semantic level) in rigorous syntactic terms, so that the underlying VM can implement them efficiently. In short, making the syntax align naturally with the semantics of the code. This is why I _really_ hope PEP3142 gets accepted, because a termination clause is one of the few times when I try to write a comprehension, but have to fall back to a for-loop-with-break, which the VM could do so much better if I could tell it what I wanted. Disclaimer: While I think map &amp; reduce do in fact have more clarity in the list comprehension form, that may be me coming from a math background, where I'm used to the "for all" and "where" operators when doing set construction. 
nice monad...
because the equivalent to this: [x*2 for x in collection if x%2==0] ussing map and filter is not 'way more readable'
Should and should; the first form is actually a bit faster. But not much. And YMMV, as usual.
So what? That's just one example. In particular, what makes it more readable is that you are using an expression as the filter expression. [x for x in collection if test(x)] # vs filter(test, collection) [lowercase(x) for x in collection] # vs map(lowercase, collection) Just as there are an infinite number of cases where list comprehensions are clearer, there is also an infinite number where map, filter, reduce etc. are more clearer. Stripping out things because they look confusing to some people comes back to bite you in the ass and "only one way to do it" is overrated. Programming with higher order functions also takes you to a new level when you start collecting libraries of *composable* code. I do not understand why this is not taught as a fundamental technique instead of object orientation.
Awesome. How long 'til we can embed the interpreter in browsers?
It's just the list of stuff PyQt wraps. There's lots more, C++ helping stuff that really is quite useless for Python.
Guido and many Python users have a stubborn hatred for functional programming. Python just reluctantly supports first-class functions, but I've found a lot of hostility when trying to work functionally in Python, both from the community and the language specifications and evolution.
Yes, but the Python community and Guido himself seem to hate functional programming and functional techniques, and they go out of their way in order to avoid using it. I find it particularly ridiculous when they do things such as defining a functor class just to avoid using a function returning a function. Using a class with an \_\_init\_\_ and a \_\_call\_\_ method is far more verbose, far less readable and requires more knowledge to understand what's going on, but they seem to think it's better because it's less FP-like, and OOP is easy-weasy while FP is hard and evil, or some stupid crap like that.
The apparent disadvantage of using a function would not be important if CPython came with a dynamic specializer. Either way, I don't think Python's goal is to be the fastest language ever; it's supposed to be one of the nicest, most readable languages ever.
I simply don't recognise the Python community in your description. Sometimes defining a class to encapsulate a callable object is cleaner - but functions pervade the standard library and code written by Guido and the community at large.
Resistance to higher order functions in general is *not* something that characterizes the Python community in general. Python is not a pure functional language though, and never will be. I tend to agree with Guido about filter - but I'm sure we can both live with your disagreement. Even if this 'tacit disapproval' does exist, it doesn't in anyway restrict the capabilities of Python. If map, filter and reduce disappeared you could reimplement them yourselves in a handful of code - and the fundamental features of Python make using higher order functions a joy.
I'm glad you posted that - more people need to know about it.
My current favorite is building a test case dynamically based on available fixtures so it works with both nose and regular unittest. Code at http://bitbucket.org/durin42/hgsubversion/src/6266ba36ee15/tests/test_rebuildmeta.py (you have to assign `__name__` or else nose misses the case - and calling type() directly was the easiest way to make unittest find the cases sanely.)
I thought so too, but you get used to it and now I like comprehensions. I think it's nicer when you want to use an anonymous closure. `[x*x for x in collection]` looks a little nicer than `map(lambda x: x*x, collection)` Also, when there is a map-filter combo I think a comprehension is more readable. But yeah, I don't know what his beef with them is.
They often try to avoid using higher-order functions that either take or return functions, though. I've seen this done, and I've read messages of Python users, even here in Reddit, claiming that pulling stunts such as defining a functor is easier to understand than a higher-order function. I wish the Python community were a bit more like the many Lisps' - a bit more prone to "[secret alien technology](http://www.lisperati.com/logo.html)" so to speak, and it had less closet Java.
The fact I'm being downvoted shows I'm right. Python subreddit members are hostile even to my pro-FP comments.
Because they're more readable to *Guido*, and they're easy enough to implement by yourself: def map(func,array): results = [] for value in array: results.append(func(value)) return results Or, using the list comprehension: def map(func, array): return [func(value) for value in array] 
Shouldn't the\_decorated have an *args argument in your timer\_dec declaration, so that it can decorate functions that have arguments?
&gt;After years of being bogged down by complex C++ frameworks, Qt was a fresh breeze and C++ programming was fun again. do you work for trolltech per chance?
Not that I disagree... something like pysco, but with a bit more ability to cross call boundaries and inline whole functions would be really nice. Maybe PyPy will one day be usable in a day-to-day situation, not just a brillant but not ready for prime time application. But think about how much effort would be required to write an appropriate specializing compiler for CPython... cause Psyco was nice, but not quite there. Getting there? That's a pretty major chunk of work, with multiple platforms that have there own distinct quirks, and suddenly we're in the compiler business (psyco is only x86, after all). Compare that to adding comprehensions, and extending them to cover the common use cases: it's insanely simple to tweak the language and VM to accomplish it, and EVERY VM implementation (CPython, Jython, IronPython, Stackless) all get the benefit simultaneously. Each VM can then be given a clear concise intruction on a very simple task, and do it as close to the metal as they can do it, whether it's x86, x64, JVM, .NET, wherever. This is why it was added to the language: Functional programming is *the* fundamental way to describe pretty much everything (tm), but it is not the most concise way to encode the invariant parts of some of the more common coding patterns. It's this sort of feature: a simple choice with powerful consequences, that Python excels at providing. I'm not quite sure why you have this dislike for comprehensions, given your obvious like of functional programming... Functional programming is not all F(x), you know. That's merely the fundamental unit of abstraction, on which everything is based. Comprehensions are in fact one of the *most* FP-style of the recent things that has been added to python... they remove a stateful variable &amp; for loop, they make you have to go *out of your way* to achieve stateful side effects, and the generator form allows lazy evaluation in a natural easy-to-use-and-understand way. They are in fact a great way of describing looping, without using recursion *or* statefulness, which is a very powerful thing (which is why number theory, esp set theory, is rife with them). Look at the changes Python 3.0 brings: A lot of lists etc have been replaced with "views", bringing more lazy evaluation to the table. Yes, I know a complete redesign would have allowed more. But that wasn't the intent with 3.0. The goal was an *evolutionary* change, keeping most of what was good about python around, just inching it closer to Haskell/R/etc. A dramatic break, and it would have been a new language, but this way, the language is brought slowly along, so that when one day it arrives at a "perfect" design (whatever that means) it will have brought along all of the codebase it started with, and not cast it by the wayside only to start over as a completely new language. 
The tutorial **very clearly** states: **Important Warning** The default value is evaluated only once and then goes on discuss *exactly* the case that seems to "nail newbies all the time". One would hope that newbies would at least take the trouble to work through the tutorial before complaining about "unexpected behavior". RTFT
Yep, replacing javascript to manipulate the DOM or things like that ? Do you have any ideas what would be the benefits of that ? and if any browser would want it ?
I'm really not sure where you're coming regarding "Python just reluctantly supports first-class functions", or with regards to your comments higher-up about Python not liking high-order functions. First-class functions, as I understand them, should be proper objects, able to be referenced, passed as arguments, stored in other places, retrieved, etc (can't remember the full official definition right now). Python supports all of this, not just "reluctantly", but inevitably: The core of Python's design is that everything is an object, and the function objects are no exception. Not sure how Python could *ever* make another choice, it would break every single little detail of python. Heck, GVR was so enamored with first-class everything, that even INTEGERS are proper objects (I'd say that was a bad idea, but looking the boxing/unboxing mess of Java's atomic integers, it's probably the better choice for OO). Now, you might be irritated that you can't introspect and actually mutate the code of a function during runtime. No, they didn't make that easy, but that's a pretty rare need, closures plus function composition provide most of what I've ever needed. And one of python's strengths is foreign functions (C, Java, etc) also being treated as first-class objects. Introspection just has to take a back seat to allow those in. For those rare border cases where you want to mutate your code, yeah, it's a bitch. But those are rare, and inspect+ast+compile are a pretty workable combination. I don't think anyone is hostile to your "pro-FP" comments, I think they're hostile to the "oh poor me the martyr" tone you've been taking, which just isn't appropriate for a programming language discussion. Certainly everyone has their bit of fanboy in them, but I think most of us know a number of programming languages pretty well, and aren't nearly as hateful of non-python as you are accusing everyone of being. For myself, I have come to realize that every language I've learned has tradeoffs and advantages. Some traits are shallow, some you have to dive very deeply before you see them. For many traits, it is not intuitively obvious why one trait should require or preclude another. So don't take it as hostility towards all FP stuff. Many of the inner dev team have experience with a number of FP languages. Just get into PyPy to have your mind blown about how much thought is being given. It's just that they have to weigh many competing requirements, and maintain the momentum of the language. Feature X might be a feature everyone loves, but if it's incompatible with another existing feature everyone loves, it's probably not going in there.
Just to reply to my own comment... I was thinking about the desire to make Python more functional (or more OO, or statically typed, etc), and came up with this idea: In the end, it really all comes down to a program's core data structures, for they shape how we even approach writing functions (and therefore programs) in a given language. While we may work around different quirks in order to get the same job done in any language, the core types and first choices impose deep patterns on the structures we use. This is mainly a rant on structures and the variables used to store them. Just to compare a few... Lisp is based on lists and atoms. This give it great power, but limits the initial syntactic choices, so even after a library of functions and datatypes has been built up, that's still all you're working with. The easiest choice is always functional, and variables.. are not that functional. So while you get a wealth of things in Lisp, it's just hard to even draw a 1-1 comparision, much less create a hybrid that bridges the two worlds. Perl, like C, chooses to think of variables as locations in memory. The fundamental element here is not the object stored in the variable, but the location in memory itself (the "object" only emerges when the memory location is messed with via the code). Thus, Perl &amp; C deal fundamentally with pass-by-reference or pass-by-value, these are the main (only?) choices. To copy the bits, or to pass a pointer to them. This has far reaching implications. In Perl programming, you tend to treat a variable as a "slot", corresponding almost with a text entry field or somesuch. Code can read/write to it, but it can also pass it around as a "box" which may contain something of a certain shape. Perl's "bless" command really has the same (better enforced) effect as when doing OO in C (particularly GTK style). Perl has hashes, but they aren't at the heart of the language like references are... you can't pass around a reference to the "B" key stored in a hashmap. Python, finally, is actually a little different from most of the languages I've work with, though it took me a while to realize this difference: Hashes (dicts) are the fundamental building block of Python. Not lists, or tuples, or atoms (strings, ints, blah blah). And not actually objects. Python uses dicts to encapsulate scope: Variable scopes, Object scopes, Namespaces, you name it. Everything else is just a fancy way of accessing a dict somewhere. This means, when coding, you don't pass by reference like C/Perl mean, because they're passing a reference to a SLOT, which holds the shape of the object. In python, the slot is just a dict key, so you either pass the whole dict (local scope dict, current object, whatever), or you pass the value (always an object). You never pass a single variable. It's this choice, different from most other languages (except JavaScript), which gives Python a lot of it's unique characteristics. Perl has blessing of references, C has structs, Java has classes. In order to efficiently code in these languages, you have to realize the impact of each of these, how they will impact what you do even when you think you're so far away from them that they couldn't *possibly* affect you. Take your objection to functor design in python (such as in the main form they take in python, decorators). People do tend to code them with a single high-order function, that takes in/returns another function. But the more complex these get, they start to get a lot of state involved, and multiple stages of code dealing with that state. And then there's a choice: keep using the local variable scope, or remap the code so what was the local scope dict is now an object's attribute dict. Sure it's not as pretty any more, but it's much better in that your functor can now expose it's state to it's caller (via attrs) when before that was all wrapped up in the local scope. It also allows for inheritance and subclassing of functors, which I personally have found to be VERY useful when coding similar but complex sorts of tasks. That's why you see more functors done via classes in python, because it's a more powerful and flexible to do things that way. Simple stuff *is* usually done via high-order functions, but no one actively avoids class-based functors because *there is no difference*. It's just moved the variable scope from locals() to self.dict... it's not some weird OO fetish, but simple namespace management. To think there's some innate difference between the two choices is to mistake how objects work in python. Not only are functions just another object with state, but (callable) objects are just another function with state.
what is 'importlib' ?
(don't feed the troll -- check his comment history to get an idea of his MO)
Stack traces, it fucks them up. That's a great reason to avoid them because python is currently one of the easiest languages to debug.
&gt; They often try to avoid using higher-order functions that either take or return functions, though. The damn @ syntax is just there as a trap! Get out while you can functioneers!
&gt;This is probably going to be accepted Nope. Check http://mail.python.org/pipermail/python-ideas/2009-January/ : No one likes it.
No, we're hostile to your hatin' on Python.
Nope, I don't. Far from it (both geographically and conceptually - I'm an embedded hardware engineer). Searching my blog for Qt (Google: qt site:http://eli.thegreenplace.net) brings up lots of positive feedback from 4 years ago. These are not new opinions. Have *you* tried Qt?
http://groups.google.com/group/comp.lang.python.announce/browse_thread/thread/cf9b5cab5b17c31b/6f7bb6f87fda7b5f?show_docid=6f7bb6f87fda7b5f buzhug (http://buzhug.sourceforge.net) is a fast, pure-Python database engine, with a syntax based on list comprehensions for queries instead of SQL The new version 1.4 adds the boolean type for fields, and the capacity to define a default value for each field on base creation 
What hating? Python is one of my favourite programming languages. I use Python regularly and it's often my language of choice for most of what I do. The fact I even bother to criticize it shows that I care for the language. The problem is that the Python community is full of fanboys that think any criticism is a personal attack from a Perl-using Python hater. Please grow up; there are some who are trying to use Python seriously here *because we like it* and are seriously concerned at its shortcomings (which every language has).
&gt; I'm not quite sure why you have this dislike for comprehensions That's probably because I don't have any - I *love* list comprehensions, as a functional programming feature. I'm just bitter that Guido and the Python community of fanboys disdain other functional programming features and techniques and that their interest in list comprehensions is boosted by this. I'm also happy with the way Python 3 turned several things into lazy generations.
&gt; I'm really not sure where you're coming regarding "Python just reluctantly supports first-class functions", or with regards to your comments higher-up about Python not liking high-order functions. I've noticed part of the Python community and Guido himself avoid higher-order functions when there's about any other alternative, including far more complex, less readable, more enterprisey ones that actually require more knowledge of features, such as functor classes. I've seen piss simple decorators implemented as classes with \_\_init\_\_ and \_\_call\_\_ and people saying that it was more idiomatic to do them that way; this is lame. Of course, I'm a staunch supporter of the "everything is a ..." philosophy (to the point I prefer homoiconic languages where every program is a list of lists or atoms  you know where I'm getting to). I don't expect Python to have the properties of homoiconic languages, as I understand it does benefit from a better syntax and it's reasonable to give up on this secret alien feature for Python. I'm just bitter at the way FP is poorly treated in the Python community and direction. Many of the changes Python could benefit from, one of which being turning statements into expressions, would not affect existing features, but just the suggestion of these is received with hostility from Python fanboys who take the stance that Python is perfect and thus any proposal for changing the slightest bit of it must be bashfully dealt with.
&gt; it's just hard to even draw a 1-1 comparision, much less create a hybrid that bridges the two worlds. There have been several languages borrowing a lot from Lisp (or being simply based on it) that offer more core features or a different syntax, such as Smalltalk or Dylan. &gt; Python, finally, is actually a little different from most of the languages I've work with, though it took me a while to realize this difference: Hashes (dicts) are the fundamental building block of Python. And of any decent dynamic language, I may add. For example, they are the fundamental building block of Lua or Javascript too. As for decorators, when I need to expose properties of a decorated functions to others, I just make them properties of a decorated function, and it still looks simpler and requires a bit less knowledge of the language. E.g.: def Decorator(f): def _(): ...whatever... return f() _.property = 'hello' return _ The only instance where I see any advantage to using functors is when class inheritance is desired.
It is not about *me* not being able to use them if they are removed (as you said, they are easy enough to be implemented on the fly) -- but rather about the general education of programmers. Being scared of higher-order functions and their (extensive) simply limits what you can do. Oh well, I'm starting to sound like a preacher so I'll just stop :)
You are thinking about tail-call optimization, we are talking about higher order functions. They show up perfectly fine in stack traces.
While I agree with you that Wiseman1024's comment about "hatred for FP" is false, I should point something out: Python is a functional programming language. In fact, Python is just as functional as Lisp. No-one wants Python to be pure. However, my predicament with the situation is not that Python lacks code modification (which is, as you said, pretty obscure) or other "advanced" functional concepts. My beef is with the idea that future Pythoners should be strong-armed into staying away from functional programming practices. Sure map/filter and friends can be easily implemented, but removing them (and lambda) from the language is done to discourage people from using them. "One way to do it" sounds like a good idea on the surface, but in fact it is not. Different problems call for different versions of the same solution. Python is a well designed language which makes functional programming rather easy, so *why* should we maintain that people shouldn't use it? It is about building a culture. If Guido doesn't like functional programming style, then he shouldn't use it - but please don't alter the language/libraries to discourage other people from discovering it.
Indeed, I've edited it to pass `*args` and `**kwargs` to the decorated function
It is a pure python implementation of the import semantics, developed to make them more flexible and (eventually?) to replace the original import implementation.
well it's just your comments were coming off as kind of infomercialy.
The documentation on the web is complete crap. What the f--- does your new tool do better??? I don't want to learn how to do the old stuff using more keystrokes. I don't want to see how some tired old technology can be reimplemented. Show me how using Paver makes life better, easier, simpler. 
&gt; Qts lack of truly free license (only commercial and GPL). Yah, I really disagree with that sentiment. But ok.
Why?
Depends on your definition of "free". Some say "free" software should be legally protected so everybody who uses it will always keep *their* software also openly available (much like GPL v3 licence). Others find software "free" when everybody can (ab)use it (much like the BSD licence). Then there's also the free = costs no money, often released as binary only (freeware). There are probably some definitions I'm missing.
I would be interested in translating it. Sadly, I cannot compile the source distribution (1.81) on ubuntu. It complains about not finding cog, but installing it from http://nedbatchelder.com/code/cog/ does not help either. I would appreciate a readme, with the required modules to compile the rst-s, or the distrib to be self-contained. 
A truly free license is "do whatever the hell you wish with this code, I don't give a damn". This is what's usually meant by placing code "in the public domain". GPL is very far from this definition. LGPL is much closer, and BSD/MIT are closer still.
No, that's not a free license. That's an "I don't give a dam license" which is fine. But I don't think there are any real world scenarios where one can have freedom without mechanisms to protect that freedom.
it all depends on your definition of "freedom".
&gt; * any and all (new in 2.6; emulation code for earlier versions available here). Actually, new in 2.5.
Why not `setattr(obj, key, value)`?
via: http://tomobag.blogspot.com/2009/01/maybe-blender-for-robot-simulations.html
Thanks. Fixed. Guess I should read the pages I link to ;-)
If your work is in the public domain, nobody can stop anyone from accessing it. Much better than the "You can use this code if you jump through hoops" license.
Truly free depends on your definition. In this case there is difference between what is free. If code is public domain, it's the user who is free to use. In the case of GPL/LGPL it's the code that is free (and stays free). Other way to see it is that BSD-free code is snapshot free, while GPL/LGPL code has free future. 
Well it's not much better if I don't want just anyone to use it. I only want other people sharing free software to use it.
&gt; This Account Has Exceeded Its CPU Quota cache: http://www.google.com/search?q=cache%3Ahttp%3A%2F%2Feli.thegreenplace.net%2F2009%2F01%2F19%2Fmoving-to-pyqt%2F
Needs more cowbell.
&lt;sarcasm&gt; Because as everybody knows, all REAL programmers remember everything they have ever read. &lt;/sarcasm&gt;
In some jurisdictions, public domain is not legally recognised (IIRC), and so a permissive license is better than placing something in the public domain.
Do you have a friend called OriginalAck?
If I had to guess, I'd say that the guys and girls working on it wanted to be able to explain to their spouses/significant others/children/parents/etc. what they do for a living without being ridiculed and so on.
Then that's not really free now is it?
Free to those who will keep it free.
Because every other python project starts with py-?
Ah, so it's not really free. ;) True freedom has `0` restrictions.
Because it's pronounced "cute", not "cutie".
No but I did have a friend called FinalFin
Nice list. I keep forgetting about enumerate when I need it. Btw, you have two *Detecting empty lines* entries.
And **that** is why I read reddit. About two thirds of the way down you veered off into some other thread about functors, but along the way you crystallized a couple of ... well they weren't problems, but it's always nice to be shown what's under the hood by an engineer. Especially when it turns out to be simple after all. Thanks "[Jane](http://www.win.tue.nl/~wstomv/quotes/software-requirements-specifications.html#Brilliance)"
And while we're at it, why must I type import PyQt4 and not import pyqt and why do the signal handlers in Python require C++ function prototypes encoded as *strings*. QObject.connect(foo,QtCore.SIGNAL('doit(QModelItem &amp;)'),func) wtf?
The freedom that can be taken away is a bit unimpressive. The whole Freedom 0 argument goes about that.
I did **not** know that.
seriously. after all these years..
Damn that's ugly. I've been thinking about learning PyQT, but you just convinced me not to.
Like SciPy and NumPy?
Yeah, I thought it was kind of an edge-case myself.
&gt;Because **every other** python project starts with py-? Edit: Why am I being modded down? He didn't say *every* python project starts with py. He said *every other*, which implies, the way I interpreted it, *a lot* of python projects begin with py to the point where it seems overy other project name begins with py and a lot more (it seems) than those project names that end with py.
&gt; In some jurisdictions, public domain is not legally recognised (IIRC) That's correct, those jurisdiction consider that only work with expired copyright or made by the government can be public domain. However, in practice most judges will understand you intended to grant an all permissive license and respect your intention. Just to be safe, you can always use the WTFPL which I copied below: DO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE Version 2, December 2004 Copyright (C) 2004 Sam Hocevar 14 rue de Plaisance, 75014 Paris, France Everyone is permitted to copy and distribute verbatim or modified copies of this license document, and changing it is allowed as long as the name is changed. DO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION 0. You just DO WHAT THE FUCK YOU WANT TO. 
&gt; For a while I have been playing around with buzhug, a pure Python database. It seems to be slower than other RDBMSs, but is fastest amongst the Python databases. Is it just me but does the article author sound surprised that a "pure Python database" is slower then other "RDBMSs" ?
That says nothing good about you to be honest. If you took a serious look at it you would find out 2 things: 1) There are other ways to do it, primary through the use of decorators. 2) One of the primarily plans on the PyQt roadmap is to make the interface more Pythonic
Whaddya know? I *did* learn something new today.
Maybe a new project is in line by another group to just make it Pythonic from the beginning. One could call this new project QTPy. :)
Obviously [these guys](http://common-lisp.net/project/slime/) had no such limitations.
Or how about pyQT, pyGTK, pyGame, pyOpenGL, pywin32 and about a billion others. ;) See for yourself: http://pypi.python.org/pypi?%3Aaction=search&amp;term=py&amp;submit=search
I would be willing to donate a small amount to a serious effort.
For a start it is call PyQt and not PyQT. Qt stands for Qt and QT stands for QuickTime. For PyQt 3 which used Qt3, 'import qt' was needed. Now we have PyQt4 and therefore a different import is needed since you can have both installed at the same time. Signal names can be overloaded based on their C++ signature. Requiring the C++ signal name in SIGNAL() avoids ambiguity and the chance that your code will break if another signal with the same name is added in the future. What all this "C++ creeping into your python" gives you is some extremely powerful interoperability with C++. You can create widgets in Python and use them in C++ code, and visa-verse. -- Simon 
&gt;1) There are other ways to do it, primary through the use of decorators. I'm curious about how it can be achieved through decorators. Googling only got me `QtCore.pyqtSignature` Is that what you're referring to? 
Yup, I've used it, gets the job done fairly well.
&gt; Now we have PyQt4 and therefore a different import is needed since you can have both installed at the same time. How about `qt4`, which would have been simple, versioned and *PEP8-compliant*?
qt4 was probably considered, but I can't remember the reasons for not choosing it. Personally I'm happy with PyQt4, and beyond that it doesn't worry me what it called, provided the version number is in the name somewhere. -- Simon 
QtPy would have been so much nicer :)
That might be interesting to use in combination with python implementations of MapReduce sur as [disco](http://discoproject.org/) and [octo.py](http://ebiquity.umbc.edu/blogger/2009/01/02/octopy-quick-and-easy-mapreduce-for-python/).
It's not quite "do what the fuck you want" since you have to change the name.
That would just be goddamn adorable.
[From the web site](http://lmacken.fedorapeople.org/moksha/main/Introduction.html): &gt;A highly scalable platform for creating, running, and wielding dashboards of live collaborative widgets that extract and extend data from arbitrary resources in an intelligent and efficient manner. The rest of the page is filled with similar crap. Sounds like something that's targeted strictly towards the architecture astronauts and the enterprise crowd. Either that, or someone just ran the Dilbert Mission Statement Generator and pasted the output onto the page.
What do you mean by "more cowbell"?
You could always import PyQt4 as pyqt or even import PyQt4 as qtpy as you code away on your My Little Pony laptop.
so.. you pronounce the letter T as "tuh" and not "tee"? What grade school did you go to? ..Queue Are Ess Tuh You Vee..
As far as the code is concerned, it is. Beside, it was just an example, you are free to write your own WTFPL-like licenses.
Buzzword. Buzzword buzzword buzzword buzzword buzzword, buzzword buzzword buzzword buzzword. The buzzword and buzzword buzzword will buzzword buzzword.
Buy, borrow or steal a mobile phone.
she's my cherry pie
Well, it has a centralized db, and punts on how you make that HA. And it replicates everything everywhere, so every node needs to have enough disk space for the entire collection. But it's pretty simple and probably works well for what it does.
I'm partial to [jQuery sparklines](http://omnipotent.net/jquery.sparkline/)
I was actually trying to figure that that out today while sitting through a boring section of a meeting.
schw*eeeee*t!
Also check out his [PyGame tutorials](http://eli.thegreenplace.net/category/programming/python/pygame-tutorial/).
if u join the beta early. 
&gt; every other Implies every other.
This is awesome. :-)
This goes against accessibility and cannot be used outside a web page, but very handy anyways. &gt; Composite inline &lt;span id="compositeline"&gt;8,4,0,0,0,0,1,4,4,10,10,10,10,0,0,0,4,6,5,9,10&lt;/span&gt;
Academic Free License. What kind of license is that?
Ah, backwards compatibility, what a great thing.
Unless you switch from C Python to one of those fully-garbage collected Pythons or C Python surprisingly drops it's reference counting, then you don't need to worry about explicit file close in 99% of the cases; the file will closed when it's no longer referenced. The 1% remaining are when you want to be ensure the buffers are flushed and the file is closed, e.g.: f = open(...) f.write(...) shutil.copyfile("filename of f", "another filename") or cases that involve stack frames, e.g. you open a file then an exception is thrown which keeps the frames around for a while. Of course if you still ARE referencing the file for some reason, it won't get closed (e.g. you assign it as an attribute of an object that's still around or a module global). 
the 'with' statement allows you to use the RIIA idiom, wich is one of the reasons people oppose to GC. Even better, it makes it more explicit.
with is useful for *so* much more than closing files - as this blog entry demonstrates. Explcitly closing files is still good practise as it makes your code more portable to other implementations of Python - *none* of which (of the major 3 anyway) use reference counting for GC.
With is backwards compatible to Python 2.5, which is fairly old these days. Fortunately, making your objects context managers (so they can be used with with) has *no* backwards compatibility issues so long as you provide an explicit close / dispose (that __exit__ usually calls for you).
I know, I wasn't being sarcastic.
OK, I'll bite... The reason Paver came into existence in the first place is that Python's distutils is great and all, but it's really hard to extend. Paver gives a straightforward way to extend distutils and do the rest of the project scripting needs. It's also convenient if you already know Python. Finally, it's more likely to work on Windows (without mingw or cygwin) than make. I'll certainly agree that the docs need some more work.
File handles are a fairly scarce resource compared to RAM. Objects holding open file handles may not be garbage collected for a while and file handles may run out. Running out of file handles will not trigger a GC event. (at least I've seen this happen in C-Python 2.5)
Oh, sorry. :-)
It's always good to see someone putting math algorithms into python, instead of leaving them in a bunch of equations spread over 10 research papers, half of which my library doesn't have in stock...
Why not link to the talks directly? &gt; http://us.pycon.org/2009/conference/talks/
Does the with statement automatically call close() at the end of the block?
The with statement automatically calls __exit__ on the context manager, which is allowed to do whatever it likes, so that could mean closing a file, committing a db transaction, whatever.
Sweet. Thanks for that info.
If you want to do this for real, from numpy import linalg but of course it is fun to implement for yourself.
if only it can give me a "kick in the butt" to resume learning Python...... (:-(
Hmm. This is an interesting example of some Python code, but not of good Python code, or good code in general. Traceback (most recent call last): File "gauss.py", line 99, in &lt;module&gt; code, A, X, B = gausselim(A,B, pivoting = 0) File "gauss.py", line 56, in gausselim if absm &lt; ztol: UnboundLocalError: local variable 'absm' referenced before assignment This code also is just about two steps away from doing LU decomposition, and in fact is even closer to PA=LU decomposition. Since that is how the code works, it would probably be better to rewrite it to provide that functionality. EDIT: fixed code formatting
The standard module `contextlib` contains a useful function called [closing](http://docs.python.org/library/contextlib.html#contextlib.closing). It will wrap the object you pass to it in a context manager that calls the `close` method on that object upon completion of the context block. Example from the docs: from contextlib import closing import urllib with closing(urllib.urlopen('http://www.python.org')) as page: for line in page: print line 
It seems simple, which means it's probably a decent choice for smallish servers. For critical files though I'd use something like [Tahoe](http://allmydata.org/trac/tahoe) which is also in Python. 
&gt;Scripting languages have been around pretty much since operating systems were built to stay residentback to DOS JCL, and no I don't mean *that* DOS. I mean the Disk Operating System for the IBM 360. Wait, I assumed he meant Disk Operating System in the first place, what was I supposed to think he meant?
Oh internets, you have jaded us so to the point that now we must specify when we are _not_ using sarcasm.
I'm guessing many people (like myself) will assume MS-DOS. I hadn't heard of DOS for the IBM 360 before, mostly because I'm too young to remember anything but personal computers.
Holy fuck I love this.
Cool. Anyone has a nice tutorial on genetic algorithm? I have been hearing it a lot and became interested.
Force the bastards to mate and kill the children who does not measure up. I don't have a nice tutorial, but search for solutions for the traveling salesmen problem using genetic algorithms. It is a common example and I find it to be a very nice one too.
Found [one](http://www.psychicorigami.com/2007/05/12/tackling-the-travelling-salesman-problem-hill-climbing/) =]
Or maybe this [one](http://lethain.com/entry/2009/jan/02/genetic-algorithms-cool-name-damn-simple/).
Does anyone use this? It does look a lot better than last time I looked. By contrast scipy/ga seems to be dead.
Just wanted to add Lua to the hash based languages. Also Python is somehow less hash based than lua or javascript, because in python objets are built with hashed but they are not "just a hash" as in javascript or lua.
About time. I'll give this a run. Thanks! My god, the graphs are **Beautiful!** http://pyevolve.sourceforge.net/graphs.html#graphs-screens update2: 15 Simple Examples. What a well documented project. http://pyevolve.sourceforge.net/examples.html#example-1-simple-example
This is the article that I've been waiting for on metaclasses! Thanks for posting it.
Magic? Ponies included? *ducks*
I accidentally upgraded to python 2.6... 
He has a fever.
I share the same feeling about the documentation. It's easier on the eyes, but harder to find stuff as they are all one page. I'm surprised Perl was that slow though.
I don't think its entirely Perl's fault. I'd say that Twig isn't optimized for large docs (using a pure sax solution would have been better), and also my Perl code isn't great, to say the least.
The menu looks good
Huh, looks interesting. I've written some GAs in C but I've been thinking about doing some work in Python. If this looks like a solid framework I'll probably build some additions for Grammatical Evolution.
I'm surprised it doesn't use [multiprocessing](http://docs.python.org/library/multiprocessing.html) for speedup. GAs are embarrassingly parallelizable.
[these guys](http://pidgin.im) either
I would like to contribute the fact that PyPy both starts and ends with Py
[py-xlib](http://python-xlib.sourceforge.net) doesn't get the fair attention it deserves
gst. we get it the first time =]
Nice design, just wonder about the white block at the absolute bottom. (Firefox 3)
I don't see a white block, maybe it was fixed in the meantime. It looks nice, although the logo is not really catchy. The documentatons looks like written using Spinx and having some structure. +1 for that.
Well, Twig is described as suitable for XML documents of any size, so I hope it's not entirely unoptimized. As for Python - I hope you know that for parsing, cElementTree's "iterparse" approach can run circles around any SAX-based solution. (and if you insist on even-driven parsing and rolling your own state machines, the low-level XMLParser in cElementTree is a bit faster than pyexpat.)
Not only unpythonic, but uneverything. Singletons are unholy and insane pieces of shit (in the 99.99999999999999999999999999% of times, when they are used with a single object). Singletons are just the enterprise version of globals. Just create module globals and stop spurting shit. Stupid design patterns...
amen to that!
FWIW I also always thought borg makes no sense at all (and I think Alex Martelli first presented it as a non-pattern, as nobody used it)
sweet background
Wow, I would have NEVER noticed that unless you said something and I tilted my monitor. Hot.
Depends, but in general you're right. I ported my GAs over to a beowulf cluster and only saw marginal increase (although the benefit increased linearly with more processors, so it was still good). At least with MPI (and my implementation) i still had a large overhead with syncing the environments of each organism, sending objects around to breed, etc. It was fun though. 
Just to give a little more detail. The game, in short, is a simple survival game. My friend and I are going to be in a room, and waves of zombies will be coming at us. We will have to survive as long as possible. And it is all 2D. I just need a way to connect us both. I have never really done that kind of programming, but that is one reason I decided to make the game; to learn. So what kind of tools and libraries can you suggest? And am I going to want to make a server application to manage the game, or have the "server" run on one end or the other? Thanks for any help reddit!
This period sucks for starting a new Python project. You can't do it in Python 3 because no libraries have been ported yet, so you have to do it in 2 and switch over later. I wonder if I can start it in 2.6 with the syntax of 3 so it's more backwards-compatible.
Okay, so, first, you could of course just have two people and one keyboard. Always a favorite of mine. But the basic setup is that you'll likely want to write a server and a client. Even if the server runs local to one machine and that machine connects via a local loopback interface, it'll make your life easier if every client connects to a server. What kind of tools and libraries? Well, you can just use the built-in socket libraries in Python. Here's a good article about how the networking in Quake3 works, which is interesting and pretty smart and simple: http://trac.bookofhook.com/bookofhook/trac.cgi/wiki/Quake3Networking . Ultimately, you might make some different choices based on your needs. Is this gonna run over the Internet or just a LAN? If the latter, you can make some assumptions about connection speed and packet loss that will make your life easier. For example, if packet loss should be negligible and if you're gonna have a lot of bandwidth, then you can just implement the networking in TCP/IP and not worry about packet loss and packet order. The Internet being what it is, you might have to be a bit smarter and use something quicker to the UDP scheme described in the article. As far as other tools, you can take a look at Google's Protocol Buffers, which will generate the serialization/deserialization code for you. Or you can just pickle data structures and send them over the wire to and from your server, or you can just pack the relevant info yourself. I suggest starting simple and finding tools as you need them. Good luck!
That was the reason for 2.6 http://docs.python.org/whatsnew/2.6.html Plenty of 'future' modules to let you start with py3k features (like using b'') without losing the current non py3kd libraries.
Ah, thanks for the tip!
I wouldn't worry too much about the networking at first. Assuming that it's not going to be a massively multiplayer title, you can just start hacking away at the server and do the client as you go. That said, I would use python sockets + Pygame.
Thanks for all the info. And just to clarify: We are not local to eachother. So the game would be over the internet, with no other possible option.
I don't get the benefit of having iterators instead of lists. what is it?
Damn. You sure know how to embarrass an editor editor.
Yeah, once you import the print function, unicode literals, and true division from the future, there's not much difference between well written 2.6 code and true 3.0 code. 
I assume you mean generators; iterators are basically just objects that have a `next()` method and raise `StopIteration` when they're exhausted. Their benefit is mostly syntactic: you can write `for foo in bar:`. Generators are lazy, so data isn't generated until you ask for it. If you make a traditional list, you need to do all the processing up front (wasted effort if you don't need every element), and you need to store the whole list in memory. Generators allow you to handle a whole lot of data one element at a time. Here, [read this](http://www.ibm.com/developerworks/library/l-pycon.html).
Thanks, the link is great. I had mixed the ideas of generators and iterators. 
And there is always 2to3 to help you out with this.
Why not just stick to Python 2 then? Defeats the whole purpose of having a new Python version. Why is there a new version of python anyway? Aren't languages suppose to progress according to the libraries they have? 
&gt; Why not just stick to Python 2 then Because there were several flaws in v2 that have been fixed &gt; Defeats the whole purpose of having a new Python version No idea what you're talking about &gt; Why is there a new version of python anyway Because there were several flaws in v2 that have been fixed, and several highly request features have been added, and the architecture has been redone to allow for easier improvements in the future &gt; Aren't languages suppose to progress according to the libraries they have No idea where you got that from
Here is one output using the lyrics the the Price of Bel Air Theme song: If anything I hear there're prissy, wine all about how My life got in my way She gave me on my throne as the Prince of a cop standing there I just got scared She gave me a story all about 7 or 8 And I ain't trying to the type of place they send this is rare But wait I sprang with her day But wait I spent most of place they send this is bad Drinking orange juice out I liked to no good Startin making trouble in one little fight and when it had dice in Bel. 
First of all you'll have to separate the game logic from user commands. This shouldn't be very hard to do, as they are quite orthogonal. For example, it shouldn't matter to your main game logic code whether the user input comes from the keyboard or from the network. Then, try to run the game logic in one thread that receives user input only through the network. Run the user interaction in another thread, that passes on commands to the logic thread via the network (on the local computer). In the next step, move the display logic into the user interaction thread. The main game logic will receive inputs, compute new state and send it out to the network. The user thread will send inputs, receive state and display it. This cleanly separates your game into the server (that manages the game logic), and the client (that manages user interaction). Now it's only a simple step to add other clients, some of them on the internet.
"Hacking away at the server and do the client as you go" might work well, but I'd like to point out to the OP that not worrying too much about the networking at first is very different from not worrying about it at all and just starting with a single player version. When you haven't done net code before and are focusing on the single player game first, you can make many mistakes along the way and inadvertently build a system so unsuited for online multiplayer action that at one point you'll face the decision between an ugly, wonky hack, and throwing everything out and starting over. If it's supposed to be online multiplayer, build it as such from the start. It's a good idea to have a look at how existing games solved the problem; I second bendotc's suggestion of checking out Q3A, whose networking setup is powerful, yet easy to understand. Some aspects of it might be overkill for your purposes, and most of it won't apply if you choose p2p over client/server, but it's still a good read. Has anyone used Twisted in a game engine? I've wanted to try that for some time but didn't get around to it yet ... or, does anyone know another library that could be interesting in this context?
For many games, action games in particular, this is not a simple step, as this is the point from which you'll have to deal with lag, which can get complex when you do it right. OK, it's simple when the client does no prediction at all and just acts as a dumb terminal to the server, but this means, for example, pressing a button to fire a weapon and not seeing/hearing any reaction for 50ms, 100ms, 200ms, or whatever the ping time is. Sounds negligible, but is annoyingly noticeable. (Could be totally OK for a first version, though.) Oh, and multithreading is usually the right thing to do, but when I work with vanilla CPython (which does multithreading _very_ badly), I usually just have one thread and make my own scheduler. Which means I'm still using only one core, but at least I have fine-grained control and can see to everything running smoothly.
I want to echo that some of the grandparent's advice is really naive and suggest abstractions that will break down. Keyboard input IS NOT THE SAME as network input. As oslash pointed out, treating networking as "input over the wire" means that one party will be acting on old game world data, then the input won't arrive 'til later, then his world won't be updated until even later. Having 1/10th of a second lag between hitting a button and moving doesn't sound bad, but it's entirely unacceptable in action games. The solution is much more invasive. It involves prediction and correcting events in the past. I'm not saying you have to start with this (or that you should), but don't build an abstraction that doesn't take into effect that networking is more than a controller with a really long wire.
thanks for the link, this is great
If "Professional Plone Development" is the best book at the moment, if you want to do programming on/with Plone, then this really isn't the right time to start with Plone. They are in the middle of some changes and it is a lot of baggage one has to learn to do some simple things. And no, customers don't want the same layout as plone.org! 
For me, using python3.0, only the .pythonrc in the blog he links to works (after changing the print statement to a function). His solution just eats up my tab presses but doesn't actually do anything with them.
But a bit empty. No info on the mailing list, nothing on the project page, etc. Very strange for an open source project that got some attention last year. People are yearning for a good CMS in Python, or at least in something not PHP. 
No. God No!
Why? 
The first time Drupy was mentioned here, people made fun of them for *not* using Django. :-) 
Oh, my bad. I misunderstood. Will delete comment.
So the quicktime module for python should be QTPy, but the Qt module should still be PyQt.
I disagree with the poster's conclusion. As a 12-year veteran of Python, I was startled to start learning things on page 36. The writing style is brief but approachable, without talking down to the reader, and it gives a LOT of information. Even on areas of Python in which I know far too much (packaging, generators), Expert Programming delivered lots of new knowledge that I can immediately put into daily practice. The book contains about 50% non-Python specific material. Agile programming, distributed version control, BuildBot, and other topics were covered briefly but in a nonthreatening way. I loved this book, and will ask all my Python buddies to run, not walk, to pick up Expert Python Programming. 
No, that's just how "Qt" is pronounced. For some reason, it's become trendy to make the spelling of a software project as different as possible from its pronunciation. Sooner or later, people are going to be looking for something called "Jackal", but they won't know that you have to type "MDeltaPartyTime" into Google to find it, because it's some kind of dumbass pun.
Isn't this the point of [ZeroConf](http://www.zeroconf.org)?
Very nice, I like it.
+1 can't agree with u any more.
I've actually been using this for a week (and didn't realize it wasn't official yet - this just had more examples than the google code Python OFC2). Remember you need to run: import * from pyofc2 not import pyofc2 Before running any of the examples (I'm still learning Python, so that wasn't obvious).
You are right. The recommended python best practice is - `import pyofc2` However, you will have to say `pyofc2.title(...)` instead of `title(...)` for that to work. You can save some typing by giving an alias thus: `import pyofc2 as fc` and then `fc.title(....)`.
so, you've replicated the functionality of the classic "tr" command now in python? good for the fanbois
You know, if you tried, you might find that it's seldom more work to make a positive contribution than it is to piss on someone doing stuff. For example, you could show how to use "tr" for this specific task (yeah, I know it's easy, but so is using that Python script), and perhaps also mention where to get "tr" if it's not installed on your machine. If you think your knowledge is worth anything, share it.
They need to work on the name.
 import * from pyofc2 is not valid python.
man tr seriously, I don't like when people say "oh this is better because it's python" fuck you, python is JUST another language I won't get tired of ranting against this cows. and no, there's nothing for me to explain because everything that can be said can also be found by yourself, this script has nothing innovative or interesting it just reinvents the wheel and claims it to be good "for being python" oh and also "it's for XML" I'm sure it will crash on any other text file...
How it works is pretty much equivalent to "tr", but what it does is not equivalent. Anyone can use "tr", but not everyone will know the list of illegal entities for XML or want to look them up. Nor does everyone know how to represent \x09 at the command line. Should it be 0x09, x09, \x09? Fuck if I know. To the extent that there is any interesting aspect, it is the problem the script presumes to solve, rather than the nature of the solution.
oh that's funny, let's think a bit :) &gt; How it works is pretty much equivalent to "tr", but what it does is not equivalent. the only difference I see (and correct me if I'm wrong) is the list of predefined characters: remove_re = re.compile(u'[\x00-\x08\x0B-\x0C\x0E-\x1F\x7F%s]' % extra) which by the way is neither a list of invalid chars because that depends on the encoding (UTF-16 by example) and also it just removes them, which means it will corrupt the data. now you say "most of the time that data is garbage and we want it to be removed" ok but it is not optional so if you got one of the cases when it's not you're fucked. &gt; Anyone can use "tr", but not everyone will know the list of illegal entities for XML or want to look them up. if you don't want to learn about XML then don't use XML at all, same goes for * in programming. in any case, sometimes it's good to have modules that automatically handle those standards, I agree on that and yet the almighty python lacks an automatic entity removal :) it just gives you a dictionary to do the mapping (same goes for urllib, it encodes almost all without really worrying about practic uses) I think they just took the easy way out of the problem: let the user decide. btw, that list of yours is pretty short, the only ones are "&amp;" and "&lt;" amazing huh? (and yet it could get into DTD definitions, that would be cool). &gt; Nor does everyone know how to represent \x09 at the command line. Should it be 0x09, x09, \x09? Fuck if I know. oh but that is the same for python! how/why should I know how PYTHON represents it's binaries huh? in fact I wonder what will happen if I send this script some unicode chars... &gt; To the extent that there is any interesting aspect, it is the problem the script presumes to solve, rather than the nature of the solution. it could be a very interesting tool if it tried to make something more XML-oriented, as it is now it's just a generic (and, in my opinion also broken) text filtering tool and it's a real shame because python has some very good libraries to deal with markup, it would be great if it really parsed the XML trying to reconstruct it if it is broken or if it checked DTD definitions and tried to convert all to entities or something more interesting than saying "oh look I did this, it's shit but it's in python!" and besides all that, there's also [tidy](http://tidy.sourceforge.net/)
Molt
Yep, there is not much XML knowledge in the script, a link to the XML spec would be better than a script that does what tr does.
Definitely needs a less-disgusting name.
But the name is awesome, so you want to incorporate it into your project.
Tried this while making a new program, and it worked great until I started using nested lists. It seems to lose the proper order of list entries when you modify them. Anyone know of a workaround I could use? I thought about just putting it in a string and using split to put it into a list whenever I need to access the data, but that would still fall under the re-ordering of the list.
You should tell btbytes that, and suggest he change his examples to not require the odd behavior. I'm just reporting how they work. Yes, I found it odd too.
PyS60 1.9.0 had some problems for me but this seems to fix it all. Most importantly, it has PyQt there as well which I have yet to play with.
I'm the author, and I will be monitoring this thread. If you have any suggestions or comments about what you would like to see in the book, speak up soon. The final manuscript is due in late June.
So can you make native-looking apps with it yet? When I had it installed you could only run the interpreter.
Interesting. Bookmarked and looking forward to some actual content.
I guess I wasn't aware you were a redditor. I have to say that I discovered Dive into Python a little too late, but my dad loved it. OT: Oh, and I support RFC 3023 =)
God I love Reddit. The author of Dive into Python, right here! Gee willy :D
&gt; If you have any suggestions or comments about what you would like to see in the book, speak up soon The content! Also, are you sure Psyco will be ported to Python 3? You added a comment for PIL, but not for Psyco. Also, nothing on decorators? Or generators? And I think a little blurb on maintaining 2.x and 3.x side by side (for a library, for instance) would be useful. Finally, if the plans are already set for 3.1 (I haven't followed) maybe include some advance warning on the interesting stuff, if any? edit: oh, and couldn't the parts about differences from Python 2 be an appendix or something? So that Dive 3 be a book to *learn* Python 3, not port from Python 2 to Python 3? Or at least move the Python 2 differences to the end of the chapters, with pointers to them at the beginning?
Some ideas, - Low level networking? Implementing a basic network protocol. Pickling. The struct module for packing and unpacking data. - Generators! - Hello world's from several of the common web frameworks will be useful to many people. - Better not forget ipython. - Could suggest editors that do python well out of the box. This would alleviate the whitespace complaints people always have. - Interaction with sql databases is another, very practical topic. - ctypes. Maybe not so important to hobbyists, but this is important to businesses. If python is going to be used then it's got to be easy to integrate with the company's existing libraries.
Maybe it falls under some other heading, but I didn't see anything on generators or decorators which I consider to be fairly important. (One is likely to encounter them in actual code.) I'd love to see something on sphinx, reST and documenting modules/packages. Doctests probably deserve some attention as well. For the packaging chapter I'd consider including virtualenv. namedtuple, tuple unpacking and extended iterable unpacking. There's some other nice stuff in the collections module.
++ to all your ideas.
&gt; This site is optimized for Lynx just because fuck you. LOL downmodded for being smart-assy I still am nowhere near finishing the first DIP
Bloody sweet. Thanks to whoever posted this. I've been looking for information on this previously.
Be sure to avoid making the parts with the differences to Python 2.x too dominant. Years from now, people will take this book to learn Python, just like today people still buy the current book (with Python 2.3 and 2.4 code). Making it too much a 2.x-&gt;3.x transition book could irritate new programmers who just want to learn Python 3.x 
+=1
&gt; You added a comment for PIL, but not for Psyco. fwiw, there is a PIL port for 3.0: http://mail.python.org/pipermail/image-sig/2008-December/005337.html
It's mark you should tell that to, not me (and the port is not official so there)
Priorities. If we are limiting the scope then might as well include what many people are using the language for. If there is limited space then cut out the lower level HTTP library stuff. Few people touch that. I don't know what frameworks you are thinking about, but just a "hello world" shouldn't be more than 20 lines. This shouldn't require a whole book because I'm not asking for any depth here. &gt; That book is already written. You're probably right here though. Better to keep beginners away from the mess that is ORM's. Ew. Maybe something with less magic that just passes queries and returns iterators of python objects, if anything.
Oh, right.
&gt; That book is already written. That's about SQLAlchemy, Dive would provide a basic coverage of dbapi 2 through the built-in SQLite3 module, with pointers to the third-party ORMs and stuff.
On HTML processing -&gt; Extracting data from HTML documents - BeautifulSoup + [soupselect](http://code.google.com/p/soupselect/) might be nice here. Otherwise - "Creating graphics with the Python Imaging Library" - could it be it's losing direction here and turning into a "Programming Python"? Always mentally differentiated DiveIntoPython is something to convert the Java, C++ or otherwise-guy, vs. a complete python reference, cookbook or otherwise. Could throw in other worthy topics involving other libraries e.g. logging, configparser and optparse (shudder) if we're talking libaries...
My original notes included a section on generators, not sure what happened to it. It'll be there somewhere. There will be 2 major chapters on porting code from py2 to py3; they are both towards the end of the book. For all the other chapters, no, the py2/py3 comparisons will be interspersed with the rest of the text. Current Python 2 programmers are a huge market for this book, and will continue to be for the expected commercial lifetime of the book. 
Do you know if this is stable enough to rely on for a PIL chapter? Is there a long-term plan to make an official PIL port to Python 3?
So this doesn't require an entire book to explain?
How do you mean native looking? If you mean having a .SIS file that can be installed and an icon that can be clicked to activate, that has been there since 1.4.x or something. Before I played a bit, but 1.9.1 is beginning to look quite nice and I might start doing something a bit more serious there.
&gt; For all the other chapters, no, the py2/py3 comparisons will be interspersed with the rest of the text. That seems cool (in the current TOC, there are "differences with Python 2" sections/subsections, usually at the start of chapters/sections, and I'm really not sure you want to hit beginners with that up front)
Re: losing direction, I don't think so. After you talk about basic datatypes and "Pythonic" stuff, there's always a Cambrian explosion of things to talk about. I wrote http://diveintomark.org/puzzles/circles-of-hell in PIL, and I'd like to use it as the basis to "dive into" something more than just business coding and sysadmin drudgery. I, personally, was mind-blown when I discovered that a Python script could be the @src of an [img] element. That's always a good indication that other people might like it too.
A section on soupselect would be nice. Noted. (Damn, tools have really improved since I wrote the original book.)
There are many stand-alone applications that just need to store and retrieve data while having basic ACID guarantees. Not everything is enterprise mega-app. So, disagreed.
Low-level networking: how about building an IRC bot? Because I've actually done that. Would require porting the underlying libraries, but it would be interesting. Kind of a niche-within-a-niche, though. Generators will be added somewhere early on. Adding a section about editors is a good idea. Probably at the end of chapter 1. ("OK, I have Python, now how do I write Python?") I'll consider the other stuff.
Is there any way to subscribe to something that will send me update notifications? :D Newsletter, RSS feed or twitter?
Contradicting yourself.
I see what you did there  jokes apart you're right, tr is not on Windows (besides cygwin).
I cut my Python teeth on DiP and am looking forward to this with great interest. Any chance of adding an RSS feed so we know when updates are available?
An example of mine is that I recently wrote a [nbd](http://en.wikipedia.org/wiki/Network_block_device) type server (the userspace part) in python. I had to use the struct module to pack the data into the correct format. Interacting with custom protocols that don't already have a python implementation doesn't seem too niche. IRC bot could be good too. Although I wonder about the protocol's support for character encodings. It would be rather strange to limit text to ascii when 3.0 was supposed to set us free from that mind-set.
You say that it's so complex that it requires an entire book to explain.
That too, but also if you can run the app and have it look like a java app or a native symbian app (i.e. no intermediate state of manually doing something or in any way exposing to the user that that program is python). If this is possible, I am going to have to repair my E65 and start tinkering again (since it has wifi, it is going to be a great platform to develop on).
Something on the multiprocessing package would be cool. Also since this is one of the major issues held against python.
To the same end: http://pypi.python.org/pypi/pyquery is also exceptionally cool :)
Don't forget [lxml](http://blog.ianbicking.org/2008/12/10/lxml-an-underappreciated-web-scraping-library/) ;-).
Why anything more than setuptools' entry points?
Do explain. I may just be ignorant on that. I was looking for a system where I could just plop in new .py files as neccessary
Where do you guys think the best place is to define class constants in a python module? * globally, before the class definition? * right after the class statement (but before _init_()) * in _init_() * in a seperate class I suspect right after the class statement is the most accepted place, but then all your constants look like self.MY_CONST, etc. 
I hope the documenting functions chapter covers the new function annotation and potentially useful things one might do with it. I like the trend in say, the Pylons book and Ziade's Expert Python book of recommending and showing basics of how to use virtualenv and zc.buildout. I'd like to see someone look how much of what they do can be handled by just using the user site-directories in Py3k.
What is an example of a simple select query?
The way you've stated the problem leads me to believe that you're coming from another language. Many python modules have no classes. That said, I prefer (a) globally, after imports but before functions and classes, or (b) in a separate namespace (class). I think it's especially clear to the reader when the constants are grouped together without methods: class UniversalConstants: c = 299792458 G = 6.67428 * (10 ** 11) class Universe: constants = UniversalConstants() class AlternateReality: constants = UniversalConstants() constants.c += 1 HTH.
&gt;Following good organizational practices makes programs easier to read. Use the following organization in your programs: o imports o global constants o function definitions o main body of the program According to this book: [Link](http://openbookproject.net/thinkCSpy/ch08.xhtml)
I do a lot of C programming, but I've been using Python for a year now. I usually end up making my constants globals, e.g.: MID_SETSERIALPORT = 100 MID_NAVINIT = 101 MID_RATE_CTRL = 103 MID_DEV = 105 class SomeClass(): def test(): send_cmd(MID_DEV) ... This way I can avoid all the 'self.' ugliness, but it always seemed 'incorrect' to me since I was polluting the namespace.
Your prefixes cry out for a separate namespace: class Mids: SETSERIALPORT, NAVINIT, RATE_CTRL, DEV = 100, 101, 103, 105 class SubmarineRobot: def test(self): send_cmd(Mids.DEV) There's one other very good reason for separating your constants into classes. Modifying a module's namespace is very frowned upon in the python community. Grouping constants with classes allows other programmers to modify them without violating acceptable use. 
 session.query(User).filter(User.name.in_(['ed', 'fakeuser'])).all() 
You can ask ``pkg_resources`` for all entry points in group ``pemboas.lovelyapp.plugins``. These entry points are functions or classes with a common signature that you've documented. This means setuptools is a requirement for both you and the plugin authors. On the other hand, this provides only autodiscovery: you install an egg and, since it's in the path, you'll get the newest entry points for free. Contrast with "plop in new .py files" and changing a config file somewhere to: ``plugins = pemboa_stfvc_plugin.main``. Does this make any sense at all? I can try to be more specific if you'd like.
It's enough for now. Will save this thread and referrer to it on my next attempt.
PyQuery is way cooler than soupselect (which I wrote), but suffers from the libxml dependency which means it's really tough to get working on OS X. My ideal CSS selector library for Python would be backend agnostic, so you could plug it in to ElementTree or LXML or even minidom and still have it work.
That only works if they all implement the same API though(do they? Most of my work has been ok with just BeautifulSoup). Regardless I hadn't realized you were the author of soupselect, cool stuff :)
They wouldn't have to implement the same API, but you would have to write an adapter for each one (kind of like writing an ORM). If you look at how jQuery's CSS stuff works it's mostly implemented in terms of lambda functions that take an element and return true or false depending on if it matches a simple rule. As such, an adapter that provided an interface for iterating over a tree would get you a good chunk of the way there.
Ah true(although I don't see the ORM analogy very well), ultimately though what is the greatest advantage to having it be pluggable(other than some are apparently difficult to install under certain platforms).
On a tangent, I always get a nervous twitch when doing "constants" like this, because they're not: they're attributes, and can change. Redefining constants without realising you've done it, or without realising their significance, can really cause damage... Do it worry you enough to enforce constant immutability? If so, how? Or do you operate on the "you messed it up, not me" principle?
http://hg.diveintopython3.org/ is now up and running. It offers an Atom feed of changes.
http://hg.diveintopython3.org/ is now up and running. It offers an Atom feed of changes.
The general approach is "We're all adults here." If you see an all caps attribute _don't change it_.
I like this approach actually, thanks for sharing.
Thank you.
What about using an Enumeration [package](http://pypi.python.org/pypi/enum) or [recipe](http://code.activestate.com/recipes/67107/)? Pros: comparison of same type only, reverse value to string lookup (debugging), immutable. Cons: performance implications? [Here](http://code.activestate.com/recipes/413486) is an example that uses \__slots__ for speed. Maybe named tuples in newer pythons could work? edit:fix links
Pyreddit? More like Pyddit.
Are you thinking that the py2/py3 comparisons will be deeply interleaved with the main text? If so, you might consider instead using call-outs or sidebars that might be easily switched off to remove noise for Python newcomers.
append two lines below, maybe works. import pylab pylab.show() edit: just pl.show() is ok.
Apart from requiring the runtime (and I believe installations should be to the same drive where the runtime sits), it now seems to be transparent. I don't recall seeing anything on activating or closing the app. The SDK is easy to install on Windows (I haven't put the latest on Linux yet). I suggest you get your E65 fixed (particularly if its under warranty). I would strongly suggest an update to the latest S60 release for your model. I have an E71 (3rd Ed FP1) and it's working fine although I needed an update (even though it is new). A microSDHC with 8GB means no capacity issues.
I know this is a DiP post, but I just go to looking at the python 3 changes and: &gt;The from module import * syntax is only allowed at the module level, no longer inside functions. makes no sense to me. It's things like being that flexible that make me enjoy python in the first place. Why did they change it?
I added 'pl.show()' after the very last line and it worked fine. The demo just creates a scene with random data, so it looks a little odd but still seems to work really well, i'm super excited about this, been looking for code for ages. 
CSS selectors are even more convenient that XPath for querying a DOM-style structure. My life would be significantly easier if I always had the ability to query by CSS selector, no matter what underlying tool I was using. jQuery and other JS libraries have proved that building a CSS selector implementation against a pretty basic API (the DOM) isn't very complicated.
Has nobody noticed that this page uses HTML 5? Looks the same in all current browsers, except IE7 and Lynx. ;-) 
Statically nested scopes, see http://www.python.org/dev/peps/pep-0227/ With from X import * allowed at function level it would be impossible to statically (i.e. before running the import) determine which variables were global and which were local. 
It isn't under warranty, it just started showing "Contact Service" one day. After what you told me, though, I'm definitely getting it fixed. It's a great phone, if slow...
Not seen that one on a Nokia. Before you take it in, check the contacts on the Sim and battery are clean. Hope it isn't too expensive to fix.
At the module level, right after the import, that's where they belong. If absolutely required, you can package them in a separate module, but that usually isn't interesting.
&gt; Grouping constants with classes allows other programmers to modify them without violating acceptable use. But... how are they constants if you can modify them? Also, you might want to replace SETSERIALPORT, NAVINIT, RATE_CTRL, DEV = 100, 101, 103, 105 by SETSERIALPORT=100; NAVINIT=101; RATE_CTRL=103; DEV=105 which is much clearer in linking names and values (as well as being shorter)
\_\_iter\_\_().next()
I've seen it on my old 6110 once, it required reflashing, I think the firmware checksum got corrupted somehow and it wouldn't boot. I hope it isn't too expensive too (it should just be a reflashing, but since it's not under warranty it's a 30 euro minimum). :/
I was just wondering when someone would fix the layout. Looks great!
In 3.0 - `next(iter(i))`
I don't see anything related to GUI. Perhaps an overview of GUI libraries compatible with 3.0?
Wow, that is a nice layout.
One problem with writing an IRC bot with low-level libraries is that most experienced developers would just use Twisted, so you'd be teaching something different than what someone would do in the field. Then again, if it's clear that this is just a teaching exercise, then there's no problem with that.
This guy must not care about performance, period, if he settled on an algorithm that uses FLOATING POINT TRIG on EVERY SINGLE POINT IN THE POLYGON to test membership.
&gt; Grouping constants with classes allows other programmers to modify them without violating acceptable use. &gt;&gt; But... how are they constants if you can modify them? One man's constant is another man's playdoh. :) &gt; Also, you might want to replace &gt; SETSERIALPORT, NAVINIT, RATE_CTRL, DEV = 100, 101, 103, 105 &gt; by &gt; SETSERIALPORT=100; NAVINIT=101; RATE_CTRL=103; DEV=105 &gt; which is much clearer in linking names and values (as well as being shorter) Agreed. However, if the values were under my control, I would replace both with: SETSERIALPORT, NAVINIT, RATE_CTRL, DEV = range(100, 104) 
This time it's more well-behaving, namely the reddit-subreddit links in the header.
Thanks. I'll be sure to mention this when I talk about importing modules.
Thanks. I'll be sure to mention this right after I talk about defining functions, declaring arguments, and docstrings.
A fair point. I doubt I'll be covering Twisted at all.
I'm not opposed to the idea. Are there any GUI libraries that are compatible with 3.0?
Yeah, I think jquery shows the way here. People who are dealing with HTML want to query with CSS. (I know both CSS and XPath fairly well, and I personally prefer XPath, but most people who deal with HTML also deal with CSS, so there it is.)
As I said in some other thread, the primary market of this book will be people who have had at least some exposure to Python 2. In the same way that the early chapters make comparisons to Perl and Java, it is helpful to explain concepts in terms of other languages that readers are already familiar with. And, automated migration tools notwithstanding, Python 2 is really "another language" compared to Python 3. The comparisons will be clearly marked, though, so you can skip over them if you like.
This is an excellent idea. A little toggle above the comparison that set a cookie that affected the default state of all other comparisons to that programming language. Could be done entirely in client-side Javascript.
Yeah, I think those sections will go away and will end up spread more evenly throughout the text. See http://www.reddit.com/r/Python/comments/7sj39/dive_into_python_3/c07b2uy for some ideas on letting online readers manage them.
Sigh. Downmodded for complaining without explaining. And downmodded for inaccuracy: &gt; Basically, you find that every line in your program begins with self. 
Haven't looked at the current release yet, but I know and trust the developer and I'm confident we'll be able to shake out any remaining problems within a month or two. The official plan is to release a "ported from 2.X" version of 1.1.X. Future versions (beyond 1.1.X) will most likely target Python 3.X in one way or another.
Downmodded for same reason
Perhaps this submission would be better if it linked to the site on which the chromakode updated the layout. I, for one, have no clue what's being discussed.
Depends what those constants are for. If it is appropriate for them to be application-wide singletons in the module, then by all means put them at module scope. If they configure some aspect of the class, or are used by factory classmethods, then put them in the class. If there are a group of constants that are thematically related, stick them all as class attributes in some other class. It seems like poor style to ever stick copies of a constant on each and every instance of a class, and I cannot imagine any case when this would be preferable to one of the other options. And somewhat of a nitpick: if you do make them class level, then use Classname.MYCONST instead of self.MYCONST. It's more correct and reminds the reader that this is a class-level attribute. 
Awesome. Has this been submitted for inclusion in BeautifulSoup?
Guido's casual response brings to mind the phrase "It's good to be King."
Probably the Python Subreddit layout/style.
Tell it to the customer.
via: http://simonwillison.net/2009/Jan/27/sharding/
Is this basically just a different syntax for soup.findAll with a suitable regex as parameter? soup.findAll(re.compile('^span$|^div$')) I see that in the example provided, you can just mix it up between _tag.class_ and _tag_ but isn't that an extremely minor convenience to warrant a whole separate module? Or am I missing something really obvious here? _edit_ Or is it such that when specifying select(soup, 'div.title h3') It selects the _h3_ inside the _div.title_? In which case the extension would really mostly be replacing a for loop with bog standard BeautifulSoup...? _confused_
* Porting Python 2.5 to Python 3 chapter. * Coping with/Using older Python 2.5 libraries. 
Is it something that people using the old style won't see? Because it doesn't look any different to me.
I fixed up the header for this (Python) subreddit. It used to contain a large, oddly-aligned Python logo on gray, against a surrounding blue header background. I tightened up the logo and fixed the background to match, with a few tweaks to fit the gray background better.
Care to elaborate? So far, everyone I've seen learn Python has gone through this stage whenever they try to do OOP. About 1/3 of the tokens are `self`. To be fair, this sample is limited to the six people I have actually watched go through the learning process. And half of those I tutored.
Oh, that does look nice. I hadn't noticed the problems before, but what's there now certainly looks good.
&gt;*So this post is more of a description of the progress that lead me to the **easiest solution** for my use case.* From that statement, it looks like. No he obviously didn't care. Not every program needs to run as fast as possible. Something most programmers often forget.
You should somewhat care about older Python versions since that's what most libraries are for. If you are just starting out you can't just port them, too.
Downmodded for not understanding the use of hyperbole.
Making it Javascript will break that feature for Lynx so fuck you. On a related note, do you want translators for translating DIP3 to moon language?
I have written hundreds of python modules, hundreds of thousands of lines of python code, and I can assure you that "every line" does not begin with `self`. If it was hyperbole as bcorfman suggest, the author missed and missed badly. I'm not trying to be a stickler over the use of "every", but when it's so blatantly not true, it requires correction. But there's a twist. Because attribute lookup is fairly expensive (`self.foo`), it's often faster and more readable to assign local names, e.g.: def launchMissles(self): launcher = self.launcher if launcher.isReady(): launcher.startFinalCountDown() launcher.primeRockets() doFinalChecks(launcher) Four references, only one attribute lookup. 
Self Hell example given: class Window(object): def __init__(self, minimum, maximum): self.minimum = minimum self.maximum = maximum self.minimum, self.maximum = min(self.minimum, self.maximum), max(self.minimum, self.maximum) def __call__(self, x): return self.minimum &lt;= x &lt;= self.maximum Why not: class Window(object): def __init__(self, minimum, maximum): self.minimum, self.maximum = min(minimum, maximum), max(minimum, maximum) def __call__(self, x): return self.minimum &lt;= x &lt;= self.maximum Or even: class Window(object): def __init__(self, lo, hi): self.lo, self.hi = min(lo, hi), max(lo, hi) def __call__(self, x): return self.lo &lt;= x &lt;= self.hi It's not Self Hell. It's being a dick. (edit: formatting)
In the class, before any other functions. And I don't uppercase them; they aren't globals, just class variables. If there is some obvious grouping then you might want to namespace them, but that's purely sugar at that point, and one should always shy from sugar when there is no real reason.
I loved the first Dive into Python book. I thought it was fantastic. I tend to learn by example, and no book was a better aid to learn by example than Dive into Python. It is absolutely fantastic. I think the unit testing section deserves special attention. It did a great job of teaching a relatively esoteric topic using examples. While the concept of test driven development is easy to understand, really understanding it well enough that it becomes a reliable tool which makes you a better programmer is substantially more difficult. I don't think you can achieve that level of understanding without examples and practice because of the nature of TDD. Dive into Python really set me on the right path to using TDD as a part of my regular programming practices and TDD has made my programming much stronger. * multiprocessing module. Processing module is now part of standard library. Multicore processors are common and only becoming more so. Because of GIL this is one of the few ways to take advantage of multicore processing in Python. What's more, using the Pool object the most common use case, parallel processing of a loop, is trivially easy. I don't know of any other technique that allows parallel processing so easily in Python. * Beautifulsoup. * Unit testing in the last book was so good. However, it didn't teach some of the more advanced and important issues that you will run into. For instance, some methods can't be tested with simple primitive data types. They need a bit of setup. Possibly mock objects, composite objects, law of demeter, etc.... These are slightly advanced TDD notions for a book that isn't dedicated to TDD. But, I really beleive that Dive into Python did such a great job the first time around that the bar is pretty high on unit testing for a Dive into Python book. In my experience, after the original book showed the elegance of basic TDD, these later concepts became a necessity that I learned independently, but it would have been great if they were written in the fantastic Pilgrim, Dive into Python style that first introduced me to the power of TDD. That way, I would have been more knowledgeable, faster, and the resource would have been so much more valuable. * Nose/py.test. Nose is amazing, unittest module is so much more awkward than nose. Nose is one of those necessities that I always use whenever/wherever I'm working. * More advanced web services. I thought the original Dive into Python chapter on web services was great. It really opened my eyes to the web capabilities/possibilities in python. However, I soon discovered that for complex web sites it simply wasn't enough. Luckily, Python has some very powerful web modules. Specifically, mechanize and selenium. Selenium is a bit of a strang e module, but mechanize isn't and mechanize is very powerful. Especially the mechanize browser object. Reviewing the table of contents I'm very excited. Web frameworks, wsgi, and various python implementations. It sounds great.
I think you mean Benevolent Dictator For Life
Wouldn't it then be more like *Wade Into Python 3*?
quoting the post: &gt; It could be mitigated by swapping `min` &amp; `max` before saving them to `self.min` &amp; `self.max`, but eventually you'll need a line like this outside of init, and there will be no other course but the gratuitous use of self. It is a contrived example. The author admits this and even mentions the simplifications you've taken as your own.
When this book comes out I will be buying one. And that is when I will learn about python 3.
It will break that feature but not the document. (Besides, are there Lynx users who've never tried Python?)
Exactlyjust JS and a little CSS.
Okay, something just clicked thinking about my past students. They would have been dubious about your example, because they did not yet trust Python's object passing system. Of course it is just as much my fault for using this as a gateway to functional-ish style.
Do you import Pygame or Pame? See!
Which of course begs the [inevitable link](http://www.youtube.com/watch?v=hwAiotTksDA&amp;feature=related)
Thanks chromakode!
Yeah, because bad example is good as long as it is bad on purpose. Unless maybe when you use it to prove badness? I've ,,taken those modifications as my own'' because I only skimmed thru that blog after I saw *teh codez*. And I dropped the bomb right away, since I would never write anything like this in the first place, seems so un-natual, un-pythonic even. Srsly. Do I care how bad Python code *can* be? No. You can produce shite in any language (well, maybe except Haskell, which is somewhere in the middle whatever you do). Self haters, along with fun-calling-with-parens-eew crowd and OMG-SO-VERBOSE-LOL-PPL should just use PERL/Ruby/PHP and let Python be. And I mean it.
&gt; Or is it such that when specifying &gt; select(soup, 'div.title h3') &gt; It selects the h3 inside the div.title? Yes, this is what it does. And yes, it's basically just sugar around what you could do with a `for` loop, but that's still pretty cool
Given the presence of "monkeypatch", I suspect not
You're welcome. :) Please let me know if you have any requests!
I have always been curious about the cost of attribute lookup. Do you have any pointers to where I might find comparisons of the speed of local vs instance vs class scope variable lookup? 
lxml is powerful and well wrapped - it's xpath support is excellent, and it also supports html parsing. 
&gt;&gt; Do you have any pointers to where I might find comparisons of the speed of local vs instance vs class scope variable lookup? Sure, try [the timeit module](http://docs.python.org/library/timeit.html#module-timeit)
The odbchelper.py code from the original "Dive Into Python" is no longer a good teaching sample, due to major changes in dictionaries and string formatting. This replacement code lets me introduce several beginner concepts and some more advanced ones too. In no particular order: * function declarations * function arguments * optional function arguments with default values * function documentation (docstrings) * tuples * dictionaries, including the fact that dictionary keys can be anything (here I'm using True and False as keys) * variable assignment * lack of type declarations for function arguments, local variables, "constants", or function return types * running Python scripts on the command line * command line option parsing * module imports * lists (args ends up as a list) * functions that return multiple values * print() statement * for loops * new-style string formatting (old-style "%" formatting will be deprecated in 3.1) * self-operators (/=) * if statements * indentation instead of braces * multiple return statements * style conventions for naming functions, constants, variables, etc. Alternatively, I could strip out all the optparse stuff and add that in in a later chapter. Not sure how overwhelming this whole script would be if you didn't know Python at all. Please post your thoughts.
As someone relatively new to python and its community of module developers, I was wondering in general terms what the historical lead time is from a release to having modules ported/QA'ed to mainstream adoption by hosting services, application developers, etc.? I guess my question really boils down to this: If I start a medium sized project that I don't expect to have ready for release until 4-6 calendar months later, am I better off targeting a future release (from __future__) or the current release and worry about porting it to the new release later? And if the latter, would the reason for it be convienence, adoption or both? 
Please cover the decimal module in some detail, so people stop using floats for monetary quantities.
It might be interesting to include an example of destructuring assignment, by having a different function return a 2-tuple of the size and the suffix in the body of human_size. That would also demonstrate separating the calculation of the human-sized value from its formatting.
As far as the code itself (rather than its teaching value) it discards excess argument without either processing them or complaining about their presence; also, no file-wide docstring (adding `usage=__doc__` to the `OptionParser` constructor call would add named args and "magic" variables to the list too - again, perhaps too much for this stage, but I'd do it if it were "real" code...) *edited to add backticks for code-quoting*
&gt; # print() statement ermmm, that would be print *function*. (Which I'm sure you know, just saying you have to change your idiom and make sure you don't say that accidentally)
I think you should stick to the version that is current at the start of the project. 6 months is a short time, I wouldn't upgrade tools in the middle of a short project. This is as valid with Python than with any other language or tool. Anyway, from my experience, most Python upgrades are painless, Python 3 being the exception here.
Certain built-in sequences like `list`, `set` and `dict` can't be dictionary keys. However user-defined classes automagically can.
I never read DIP, so I'm not quite sure how much the reader is expected to know Python at this point, but I'd definitely postpone the optparse stuff I've always found it difficult to read and suspect looking at it might confound a newbie. 
I used to hate `self`, but now it seems like one of my favorite features of Python OOP.
No real standardized binary prefixes like KiB, MiB? I'd strip the optparse stuff, name=main and sys.argv are enough for the first chapter. sys could be the first module import. MULTIPLES is nice but wouldn't the binary use case better served by "1024 if use_binary_multiples else 1000" and dicts spared for bigger decisions? Although SUFFIXES is rather constant-y I'd rather the a list as first datastructure. Enforcing to think of tuples as records is more important in my thoughs. Perhaps a [('KiB', 'KB'), ('MiB', 'MB') ...]. Reiterating sys.argv: If I'm to lazy for optparse I use sometimes this idiom: if arg in (frozen)?set("-d", "--decimal"). It's ugly, it's not best practice but maybe a way to get things done in the first step and introduce sets, building some ground for chapter 3.3.
Just a matter of taste: I would declare SUFFIXES inline in the `for` statement for readability. Using a Hash with True/False keys seems weird, but there's no ternary operator in Python, right? Might be too much didactically: but maybe raise an exception if the input is too large, instead of returning an error message? If this is an introductory example, leaving out the optparse stuff and only providing a naked `main` may be a good idea. Readers can change the behaviour in the code if they want. 
Just use `if arg in ('-d', '--decimal')`. It's more readable. Also in a real program I would write: `for symbol in 'KMGTPEZY': return '{0:.1f} {1}B'.format(size, symbol)`
Not really relevant since it is not a production program, but given an input like 123 it will return 0.1 KB whereas 123 is arguably more human readable... Stylistically I would normally prefer the `SUFFIXES` list to be a list rather than a tuple though I guess you're using a tuple partly so you can talk about tuples. I agree that the OptParse stuff could be deferred to a later chapter. I also have to admit I usually use `getopt` -- is that now considered old-fashioned? :-) Also not really relevant, but I am sad to hear that `%` formatting is to be deprecated. It was one of my favourite Python eccentricities!
No ternary operator in Python indeed, not that: multiple = 1024 if use_binary_multiples else 1000 ...is valid Python syntax. (I don't know if you kid or not, sorry if you are, but even more sorry if you're not.)
no offense taken, I can only read Python :(. For me, the natural way to express the notion would be: `multiple = binary_multiple ? 1024 : 1000` nice and succinct provided you're comfortable with the ternary operator.
Python's equivalent of a ternary operator is called "conditional expressions" and was added in Python 2.5: x = true_value if condition else false_value 
Actually that *is* Python's "ternary" operator.
Oh noes, how did that happen?
See [PEP 308: Conditional Expressions](http://www.python.org/dev/peps/pep-0308/) 
&gt; no offense taken, I can only read Python :( It *is* python.
I think for an intro sort of book, putting parens around lvalue tuple assignments is more clear. For the uninitiated, they might read: a, b = foo(...) as: a, (b = foo(...)) Agreed on both points about sys.argv.
* Consider renaming "use binary multiples" to "use powers of two" or something like that * Use an if statement or ternary operator to set the value of multiple, instead of a dict. It's unlikely that the user is going to use any other multiple, and you can't logically extend a dict that has True and False as its keys (unless they added Maybe in Py3k). * The program accumulates integer division truncation as it divides multiple into size (not really a problem in this case, but accumulating error is bad programming practice) * The program does not gracefully handle values larger than the list of suffixes * The program does not gracefully handle values smaller than 1024 I would recommend the approach in this fragment: http://pastebin.com/f70674864 (I wish reddit had better support for inline posting of code...)
 multiple = MULTIPLES[use_binary_multiples] why not multiple = 1024 if use_binary_multiples else 1000 i know that switch/case is best implemented as a table lookup, but it doesn't really fit if the switch is boolean, IMHO. 
I also believe that it'd be wiser to defer the optparse stuff to a later chapter. Overall, I think this is a good example program, though.
The True/False dictionary index is kind of confusing at first glance - why not use something more clear like 'SI' and 'NormalPeople' :)
Thanks. That's great news.
Less pretty though.
While I think that this is in fact a pretty good idea, it might also turn out cancerous. We already have Mono and I'm not certain if it is a good idea. Wine certainly is a useful project but its goal is somewhat different. Porting Silverlight to Linux is only reassuring to MS. 
&gt; Why (opts, args) That's what's in the optparse docs last time I checked. Of course it's a preference thing
what's up with you and pwang99 above? "More clear"? I'm curious as to if this is terminology specific to some part of the world.
Sure that's not more readable than using optparse.
&gt; Porting Silverlight to Linux is only reassuring to MS Not if Moonlight gets more popular than Silverlight. Then Microsoft will start hunting for heads. And it probably won't be pretty. I'd like Python in a browser... but I'll wait for something not touched by Microsoft.. just to be safe.
How about you stick Mono up your arse.
I was referring to the proposed `if arg in (frozen)?set("-d", "--decimal")` But as a matter of fact it **is** more readable than optparse in simple cases like this. In fact, do you really need to support both `-d` and `--decimal`? Just keep `-d` and get over with it.
I guess we'll have to disaggree on that. I don't see why one needs to go and reinvent functionality provided by built in modules. 
I would change multiples to just be a regular number and use a constant. for example: BINARY_MULTIPLE=1024 DECIMAL_MULTIPLE=1000 # This isn't really necessary, just for completeness def human_size(size, multiple=DECIMAL_MULTIPLE): """update your docstring """ for suffix in SUFFIXES: blah I'm not certain how that would effect your arg parsing code, but when you call the function you could probably do something like `BINARY_MULTIPLE if use_binary_multiples else DECIMAL_MULTIPLE`.
Good point. But make sure you catch it in the 'main' code.
That is a ternary operator. It has 3 arguments (ternary is to binary as 3 is to 2).
You can put in [Function Annotations](http://www.python.org/dev/peps/pep-3107/). Also the conversion to int of arguments (`int(args[0])`) should be enclosed in a `try...except` block for a better error message. 
Excellent points. Will do.
You're right. I'll refactor that.
naming: how about "use misleading units like every hard drive manufacturer ever"? dict[Boolean]: true. Actually, 1000 and 1024 should probably be the dictionary keys of SUFFIXES, with a tuple of the proper suffixes ("KiB", etc.) as the value of dict[1024]. integer division: you're incorrect, because "/=" defaults to floating point math now. I will make a point of noting this in the text. large values: someone else suggested raising a ValueError, which seems like the most logical solution. small values: I disagree, I think it handles them fine. If I pass 512, I want "0.5 KB" returned. OTOH, it does not gracefully handle negative numbers, which should also raise a ValueError. Thanks for all the feedback.
The consensus seems to be that option parsing is too much for the first chapter (well, second chapter after the dreadful "Installing Python" chapter that Apress insists on). I would like to do a full chapter on optparse, which -- despite the feedback here -- I think is a great module. But it should be later in the book.
I expected "0.1 KB", but it would be easy enough to add a "bytes" suffix as the beginning of the suffixes list, and rejigger when the division happens. Re: tuples v. lists, SUFFIXES is a tuple because it's a constant (it never changes throughout the program). And yes, I need to talk about tuples somehow, but this is (IMO) a correct usage of them. OptParse will be cut from this example and put into a later chapter. AFAIK, neither getopt nor optparse will be deprecated soon. 
Thanks. I will use this instead of the boolean-as-a-dictionary-key.
Indeed, the consensus is that I should cut the optparse stuff and make a real chapter out of it.
Yeah, that dictionary-with-boolean-keys thing was stupid. I'm going to switch to using 1000 and 1024 as keys for SUFFIXES, which will be a dictionary of tuples.
The next version will output the proper suffix based on whether you ask for decimal or binary. Optparse will be cut from this chapter and may show up in its own chapter later. MULTIPLES is stupid, I'll use the ternary operator. SUFFIXES will become a dictionary of tuples, with the multiples as keys (1000 and 1024).
The reader is expected to have installed Python, nothing more. I'm cutting optparse from this example and deferring it to a later chapter.
You're right, of course. I was being lazy with my language!
Doh. I suspect I'm going to have to do a search-and-replace for that once I'm done writing. :)
Thanks. I've decided to defer the option processing to a later chapter, and I will be sure to check for extraneous arguments. I'll add a module-level docstring in accordance with PEP 257.
Just like I'm sure I'll have to do with all the print statements I write when I switch to 3
Moonlight won't get more popular than Silverlight. People are very lazy when it comes to installing things, Moonlight will get 10% share at the very most. (Not to mention the fact that Microsoft will keep Silverlight a very fast moving target.)
Thanks for all the feedback. I've incorporated most of it and posted an updated version at http://diveintopython3.org/tmp/humansize2.py
Yeah, like Flash. No-one installs that.
I hope your Mono is well lodged up your personal arse, downmodders. Quislings and useful idiots, the sundry lot of you. Hitler loves you.
Yes, like flash. I rarely see people installing a "flash plugin" made by another company than Adobe / Macromedia. We are talking binary compatibility (that would be CLI / FLW) here.
Actually, it might be. I was kind of like \*woah\* when I first saw it to, but understanding the nature of the program, I figured it out pretty quickly. Quicker than it would have taken to read the drawn out version. Just a thought. Of course, that's not something you would want in a tutorial like this.
The graphs were built using: http://matplotlib.sourceforge.net/ EDIT: Why would I get downmodded for pointing out the plotting library used? http://pyevolve.sourceforge.net/intro.html#id1 Optional, for graph plotting: Matplotlib 0.98.4+ The matplotlib [1] is required to plot the graphs. 
Personal nitpicking. I would shorten `a_kilobyte_is_1024_bytes` to `kb_is_1024` or `kb_is_1024_bytes`.
I agree. It might be a bit confusing, but not really any worse than mucking around with `sys.arv`.
I see a function named "human_size" and I think it will return the size of a human. Why not human_readable_size?
Get a connection refused error right now.
&gt; integer division: you're incorrect, because "/=" defaults to floating point math now. I will make a point of noting this in the text. D'oh. That's what I get for testing my code on 2.5.2 :) &gt; large values: someone else suggested raising a ValueError, which seems like the most logical solution. Well, the only reason I pointed it out was because I think it's possible to restructure to loop to default to good behavior for values exceeding (maximum unit) * (multiple). Realistically this is moot since no one is going to exceed a yottabyte. &gt; small values: I disagree, I think it handles them fine. If I pass 512, I want "0.5 KB" returned. I guess it's an aesthetic issue. If the goal is human-readable, I think "327 bytes" is more readable than "0.3 KB". But to each their own. :)
See http://en.wikipedia.org/wiki/Sarcasm
Moonlight is binary compatibility - and the install Silverlight for Linux machines will probably take people to the Moonlight page.
Somebody has definitely got something up their arse...
There's a lot that can be done with Python 3 and the standard library.
I'm glad to hear this, and I think this is a much more pragmatic and realistic approach. I think a lot of folks who claim they will just be using this book to learn Python 3 don't actually know much about the nature of development in Python. Some of the best features of python are not the language itself, but the "intangibles" that go with it: * wide availability of libraries for every purpose * lots of good books * lots of good online places for support * active and pleasant user community Taking full advantage of these is going to require knowing some Python 2.x, at least for the next 3-4 years. 
Depends on what you're doing. I suggest making a file like `settings.py` and simply importing from that. import settings print "My constant is: %s" % settings.something Of course, this isn't a real constant since Python doesn't have them, but it works well.
You should port spidermonkey to Lynx.
Sorry about that, my host has been going down more often than a teenager on a virginity pledge.
wait, you're Doing it Wrong! listen I work on [this shit](http://dev.scrapy.org/) and I deal with both XML and CSV almost everyday, let me give you a few hints please. first of all according to point five you made a mistake on the title of the submission which means your script's intention (according to what you just said) doesn't remove illegal characters **from** XML, you do it from CSV files which is a completely different story; another problem you have (reading point two and three) is that you're confusing entities with bytes and those with unicode characters as well. let me explain a bit, really this is not a mock (it never was in fact) but I think I can help you so please read: &gt; I'm sure there are situations where stripping the entities is inappropriate, but the script is pretty clear about what it does: stripping. this is not what your script does, what it really does is to remove BYTES, not entities and no it won't be gone with Py3k because the world doesn't spin around python plus the python's unicode is an internal concept that cannot be expressed in a file (I won't blame you for this one, many people including myself have problems with it). let's talk about entities first, an entity looks like this: `&amp;amp;` by example, that one gets translated to the ampersand character (&amp;); you can find a good overview of this here: http://en.wikipedia.org/wiki/List_of_XML_and_HTML_character_entity_references in any case "entities" is not what you're removing, and it's NOT ok to remove them in any case, what you do with entities is to convert them; entities are the way XML has to escape characters, it's analog to a backslash on a string in python it tells the interpreter that the escaped character has to be taken literally, the exact same purpose goes for the entities on XML but you don't remove them, if you do you BREAK the XML because you're making holes in you data! anyways this is not what you really do because, as I've said your title is wrong. &gt; The script is the product of my reading of the XML spec, while ignoring utf16 aspects of it, as the input should be coerced to utf8. For my needs that was sufficient. It would require some modifications to play nicely with utf16, if that's your cup of tea. Hopefully these issues will evaporate with Py3k. Or become impossible to solve correctly. Or something. for the utf8 and unicode (ignoring utf16) there's a subtle difference there, an utf8 string is a sequence of bytes and the meaning of the utf8 is to map each one of those bytes to a character; now unicode is NOT a sequence of bytes, those are character codes that's why unicode is universal but also that's why you CAN'T have an unicode file because files are made of bytes and bytes need encoding to be properly read. I recommend you to try to read the XML header (the `&lt;?xml...?&gt;` thing, see [http://www.w3.org/TR/2000/REC-xml-20001006#sec-prolog-dtd](http://www.w3.org/TR/2000/REC-xml-20001006#sec-prolog-dtd)) and use the encoding declared there (if any) and use it on [python's decode](http://docs.python.org/library/stdtypes.html#str.decode) function and only default to utf8 if the encoding wasn't declared since that's what the specs specify. it is a bit ironic this thing about the encoding because if you think about it for a bit you'll notice that the encoding is declared INSIDE the file you're supposed to read, which means you need to know the encoding before trying to read it but you can't really read it because the declaration is on the file itself... nevertheless this means utf16 and such will fail but since you didn't cared about them in the first place you're safe (and lucky). there's a lot more to say on this topic, but I think this at least may get you on the right path; hope it helps.
Is anyone using function annotations in the wild yet? It seems to me that Python people use decorators all over the place, but there's not a big enough user base on 3.0 yet for anyone to have done anything that interesting with function annotations. I would rather a beginner start with decorators and only later learn about FA's as something that can be used to make better decorations. 
I've used human_bytes() in the past. 
I'm an utter Python newbie, and I thought the optparse stuff was quite understandable. If this is a commandline program, using the standard means of parsing commandline arguments is a good way to build the habit.
To be honest (speaking again as a complete newbie), nesting lists inside a dictionary adds a level of abstraction to the entire thing. A simpler approach would seem to be either using an if kilobyte=1000 suffixes = ('KB' etc.); else suffixes = ('KiB' etc.); or even just having a single list of prefixes ('K', 'M', etc.), concatenate 'i' if kb=1024, then concatenate B; but that's a little messy. Potentially, introducing Binary Prefixes needlessly complicates the example code. 
I guess this is what the [e-commerce in Sharepoint Server](http://www.reddit.com/r/programming/comments/7bkqi/microsoft_sharepoint_roots_in_python/) about
It's year 2004,(python2.3.3 for windows on the page)? Are there any information of CFP of "Scientific Computing with Python" ?
In a world where more than 10% of the PCs would run *nix (minus OS X, has native Silverlight) that could lead to a &gt; 10% Moonlight install base, yes. I run most OSes, as long as it's not Windows. But uhm, I don't see that coming in the foreseeable future.
&gt; XML: ElementTree is in the Stdlib and it is hard to find a better library than lxml, anywhere. Well there's amara which IMO is much much friendlier than both you cite.
Take that Paul Graham.
I agree that Moonlight will certainly *never* have a wider installed user base than Silverlight. It is still important though. I think Silverlight deployment will grow very fast. Microsoft are pushing it out over Windows update for one thing... :-) The presence of Moonlight means that developers using Linux can write Silverlight apps. A substantially higher than average Python developers use Linux on the desktop for example.
I have a project I'm just starting where this would be perfect. Anyone with experience with this library care to comment about it? It seems easy enough to use but is it stable/robust?
Looks nice, but does it support the amount of features that lxml does? I normally use it for parsing only, but I saw the talk by the author where he demonstrated how it can also be used to build XML in a very nice way and was quite impressed.
I think he means he can only *read* it, not *write* it.
Geraldo? This must be a fucking awful reporting system...
&gt; I needed an algorithm for detecting cycles in a directed graph. I came up with the following. It's probably something straight from a textbook, but I couldn't find a textbook that had one Wow, this guy needs to buy a new textbook or find a new library. Both CLR(1) and Skiena reminded me how to find cycles in a directed graph (back edges in a depth-first search).
It's possible to use Python 3's function annotations to formally support the documentation for the arguments and return values. This would look something like: def human_size( size: "file size in bytes", use_binary_multiples: """ if False, use multiples of 1000 if True, use multiples of 1024 (default=True) """=True ) -&gt; "Returns string or ValueError": "Convert a file size to human-readable form." return 'hi' Which tends to look a bit gangly ... but perhaps no more so than ad-hoc conventions of specifying args and return values within the doc string? Python 3 has left the purpose of function annotations as deliberatly vague, so it remains to see if this style of documentation args and return values catches on. 
Why do all my reports hype up the data before it's generated, but after, there's nothing on them? Also, it keeps giving away troop locations!
And it's not as if you couldn't reinvent that in 5 seconds if you didn't have a textbook to hand. It's hard to think of any textbook CS solution that's more obvious.
Does it come with a mustache?
fehks neeeewwwwsz!
Another way to do this is to topologically sort the graph. If at any point you find that there are no nodes with in-degree 0, you know that the graph contains a cycle.
amara is built on top of 4Suite and supports XPath, XSLT and other goodies. Amara 2 should be even more powerful. http://wiki.xml3k.org/Amara2
Python is the reason that I'm buying a Nokia instead of an iphone. The iphone's web browser does make it a close call though.
Nice, but the post doesn't go into much detail after installing - does anyone know how much you can do with python on the Nokia? In terms of accessing phone functions, etc.
Is there anything Python doesn't run on?
This is out of date. The current release is 1.9.1 and is available from the Python S60 download area on SourceForge. If you download the SDK, you can develop on your PC (under Linux or Win) and then transfer the code to your S60 phone.
You can access most things (camera, telephone, data, contacts, calendar, etc) according to the API docs. I have only tried comparatively little myself so far but can say that what I have tried works.
After initial trial and error, followed by looking at the long entry about it in Mastering Regular Expressions and finally followed by a lot of Googling the best regex I've found to match double quoted strings that contain escape characters, eg: "foo" "foo \"bar\" baz" is: '''__\("((?:\\"|.)*?)"\)''' it works but are there any corner cases I'm missing? I'm not too worried about speed so tweaks to speed up matching are not needed. 
I just drew a state machine by hand and then translated it into a regular expression: &gt;&gt;&gt; r = re.compile(r'"([^\\"]+|\\.)+"') &gt;&gt;&gt; r.match(r'"foo \"bar\" baz"').group(0) '"foo \\"bar\\" baz"' You may have to tweak the number of backslashes for your particular regular expression implementation, but that regular expression checks out in both Perl and Python.
See [this](http://www.reddit.com/r/Python/comments/7tnd2/best_regex_to_match_an_escaped_double_quoted/c07dapi). It's easier to understand and definitely has no corner cases.
One very important detail: can you escape the escape character (like `\\`), or is `\"` the *only* escape?
Uh, "usenet spam"? The post is basically just a link to.. https://launchpad.net/python-mode
Sourceforge still contains only the 1.4.5 release. All newer development has shifted to [https://garage.maemo.org/projects/pys60](https://garage.maemo.org/projects/pys60).
Python on an AVR?! Holy crap, this is awesome!
A subset thereof. Should be enough however.
This also serves as a good primer for a lot of the syntax (and a few semantic) differences in Python 3. I am the author, and I will be monitoring this thread. Any and all feedback is welcome.
DFS, baby.
It's very strange, Opera (9.6x or 10) seems to have trouble rendering the table cells containing &lt;pre&gt;&lt;code&gt;...&lt;/code&gt;&lt;/pre&gt; like the [http section](http://diveintopython3.org/porting-code-to-python-3-with-2to3.html#http).
in A.12 is a small grammar mistake: returns an interator, not a list notice the "interator" -&gt; "iterator" and this: `"PapayaWhip" + `2`` in A.19
I really like the module reorganizations (http, urllib). My wishlist item would be for a new qt interface.
I wonder what it does with the idiom: try: try: something except: handle_exception finally: clean up things edit: fixed formatting
The indexing of notes in [A.3.](http://diveintopython3.org/porting-code-to-python-3-with-2to3.html#unicodeliteral) is wrong (two 1's).
IIRC you can do try: ... except: ... finally: ... since 2.4 or 2.5.
With that exact code, nothing, because that's valid Python 2 and valid Python 3. If the except clause caught a specific exception and bound it to a named variable, then it would fix that ("as" instead of a comma).
A.12 is fixed, thanks. A.19 is correct, as far as I can tell after Reddit's munging of your comment. (Grr.) It's taking a string and concatenating it with the string representation of the number 2, then taking the string representation of the concatenation. Weird, but valid.
Fixed, thanks.
That's very odd. I can reproduce the problem. But it works in every other browser (even IE!) and as far as I know, it's valid HTML (5, but would be valid HTML 4 too).
This is often, but not always, true. If you're using a steady-state model as opposed to a traditional generational model, then you can't really parallelize the fitness evaluation. Evaluation of the initial population could still be parallelized in that case, though.
Someone with a chip on his shoulder seems to be mindlessly downvoting. I got downvoted for noting that it's an interesting project and that I might do work to extend it.
I've written a small monkeypatch extension for 2to3 which allows hardcoded rules for all the "things 2to3 can't fix" to be established within source code as needed. It's the oldest idea in the book, a preprocessor: def __str__(self): # Py3K #return self.data # Py2K return self.data.encode('ascii', 'backslashreplace') # end Py2K Is there some other way we should be doing this, or does 2to3 have some other plans for issues like these ? Building an actual 2to3 fixer that understands rules like these did not seem readily possible as the grammar understood by fixers didn't seem to take comments into account. There also doesn't seem to be a public API for adding new fixers.
&gt; This was wildly confusing for beginners and wildly regarded as a wart in the language. Should be "widely regarded". Thanks for making all this available.
I'm confused by A.27, "lambda functions with multiple parameters". Both pre- and post-3.0, you can write lambda x, y: x + y So what is that ugly x\_y stuff for?
Sure. But it is a 2to3 tool not a 24to3 tool. Just nitpicking.
Ah, then I've misnamed the section and mis-explained the necessity of the fix. It's more narrow than I thought -- it only applies to lambda functions whose argument is a tuple, not lambda functions with multiple arguments. This is valid in Python 2 but raises a SyntaxError in Python 3: `f = lambda (x, y): x + y` I'll update the section accordingly. Thanks.
Will be fixed in next update, thanks.
&gt; I really like the module reorganizations (http, urllib). Ditto. &gt; My wishlist item would be for a new qt interface. What would you change about PyQt? I'm not fond of the CamelCasing although I am of the toolkit. 
Oh, I was expecting another "The GIL sucks!!!111" article, but this was actually a rather insightful reasoning about threading and the GIL.
Thanks. I'm not a fan of GIL, nor am I a GIL hater - it has it's place, and it has it's drawbacks.
Depending on your application, you might use the [multiprocessing module](http://docs.python.org/library/multiprocessing.html) instead of the threading module. It uses separate processes, and therefore, separate GILs to avoid contention. It doesn't work on FreeBSD or OpenBSD at the moment, though a few folks are trying to resolve that.
I'll report that bug tomorrow. **edit**: this causes the strange behaviour: &gt; body{word-spacing:0.1em} &gt; &gt; pre{white-space:pre-wrap}
The article mentioned pyprocessing. It pre-dates my work on PEP 371 and the multiprocessing module inclusion into 2.6. I think I noted this in the intro
I love the toolkit. But the interface is heavily un-Pythonic. PyGTKs interface was a lot easier to pick up.
I've heard that statement before, but I've never heard a rationale to go with it. Care to elaborate? (The PyQt-unpythonic one, not the easy PyGTK one). 
For anyone confused by Mark's example, let me explain. This is legal Python 2 and 3: &gt;&gt;&gt; y_z = 2, 3 &gt;&gt;&gt; x, (y, z) = 1, y_z &gt;&gt;&gt; x, y, z (1, 2, 3) So, on analogy, in Python 2.6 this is also legal: &gt;&gt;&gt; def f(x, (y, z)): ... return x, y, z ... &gt;&gt;&gt; f(1, y_z) (1, 2, 3) But in Python 3.0 they removed auto-unpacking from functions (and `lambda`s) on the theory that having it made function objects messier, was rarely that useful, and necessitated various performance penalties. So, if you used function auto-unpacking in your Python 2.x code, 2to3 will automagically fix it as above. 
In A.8, `list(a_dictionary.keys())` can be rewritten as `list(a_dictionary)`. I'm not sure which is considered more idiomatic yet, but I suspect brevity will win out.
A.10, "You can also import **form** the parent directory (`from ..anothermodule import AnotherClass`) or a subdirectory. "
The interface follows (almost exactly) the C++ interface making (almost) no use of Python language features. I wish I had a specific code snippet to show you, but I haven't worked with it within the last few weeks to remember one to pull out. Consider though that python classes support properties while C++ doesn't. that alone can make things a lot neater. However, compare a PyGTK tutorial to a PyQT tutorial and you may notice the difference. It definitely isn't a terrible interface though, just takes some of the Python language fun out of it.
Error 500 - internal server error. Shit, I was actually rather interested in this.
Just some notes (unless I'm missing something obvious, in that case forgive me ;-)): A.10: absolute and relative imports were [introduced in python 2.5](http://docs.python.org/whatsnew/2.5.html#pep-328-absolute-and-relative-imports) A.15: "Instead, there is a new function calling syntax that allows you to pass a list and have Python apply the list as the function's arguments." I don't know when it was introduced, but I'm using python since 2.4 and that was already possible.
Yep, but from &gt;= 2.5, [link](http://docs.python.org/whatsnew/2.5.html#pep-341).
class CustomError(Exception): pass try: fid = open("aFile.txt") # missing 'w' again print("blah blah blah", file=fid) except IOError as exc: raise CustomError('something went wrong') from exc somehow i didn't notice this before, neat.
Agreed. As for length, well - the requirements for a feature in pymag are at least 4000 words. I like to aim high
That appendix is really helpful. I also like the hovering effect. Great work! One thing that could be improved is to explain the motivation behind each of the changes in a few words. There are already explanations for some of the changes, but not for all.
So, I;m going to assume that the perl is responsible for the page going down.
&gt; # Declaring the metaclass in the class declaration worked in Python 2, and it still works the same in Python 3. Not true. Using Python 2.6: &gt;&gt;&gt; class C(metaclass=PapayaMeta): File "&lt;stdin&gt;", line 1 class C(metaclass=PapayaMeta): ^ SyntaxError: invalid syntax 
Stupid indirect link.
that's cool, but it's a pity that the windows console copy/paste is broken, making the copy/paste back into the doctest a chore
how? What does your state machine look like?
I've no idea how to crosspost between programming and Python, thought it would just work.
I really wanted to find a way to draw state machines from a specification so I could show that as well, but I couldn't find any way with a few minutes of Google searching. Described, it consists of four states. A start state (a circle with an arrow drawn into it) begins it. An arrow labeled with a `"` leaves that circle, going to another state. That state has three arrows coming from it: one arrow, labeled with a `"`, points to the end state (a circle with another circle inscribed in it). A second arrow, labeled with a backslash, points to a third state, which has an arrow, labeled with a dot, pointing back to the second state. The third arrow, labeled with `[^\\"]` (all characters except `"` and `\\`) points back to the second state. From there, it's a simple translation into a regular expression. Sometimes I just find it easier to draw a DFA (Deterministic Finite Automatom; note that no arrow duplicates a symbol, so there's one and only one correct arrow at any state) and then convert it to a regexp than think of a regexp out of the blue.
- Right click on title bar - Select 'Properties' - Under the options tab select 'Quick Edit Mode' and 'Insert Mode' - I would also suggest you check out Console: http://sourceforge.net/projects/console
I can stand behind multiprocessing. When it works, its great. The problem is that if you need to debug something like pool.map, it's a royal pain because every process spews useless error messages to the screen. 
Apparently iPhone + Cydia makes for a nice python environment (using PyObjC). Personally I don't like the hassle of a jailbroken iPhone, but to each his own ;)
For when a traditional MUA and mbox/Maildir just aren't trendy enough... Now don't get me wrong, I'm all for cool Python hacks and whatnot. But I can't help laughing at the absurd, Rube Goldbergesque complexity of the whole GMail+Google Gears affair. You want to be able to read and process your email offline... so you use a complicated Web-based mail system, find a way to host it on and synchronize it with a third-party Web application framework on your computer, and then write a script to query an undocumented SQLite schema, subject to change at any time? This problem was already solved in the 1980s with POP and subsequently IMAP, and with client-side MUAs that provide a much richer experience than any Web-based system. As a Python hack, this thing is kind of nifty; as a method for actually managing one's email, it is probably the worst possible approach to the task.
I would generally agree except I have multiple computers and want to access my email from all of them without having to re-read mail read on another box. I need my mail local for when I'm offline and wanna get to attachments in my mail. I also have several gigabytes of email and a few hundred folders and I need all of it. One would think IMAP would be my solution (POP absolutely can't do this) except I find the mail filtering/folder handling completely inadequate and often loses track of things easily. My favorite mail client is Thunderbird but either it or the IMAP servers don't seem to be up to it in a reliable manner. So... I'm using gmail right now and dealing with it fairly well but its far from ideal and forget about offline access. This seems promising but a bit over complex as you say. However, what better options are there?
Yo dawg, i heard you liked wrappers so I put a wrapper around your wrapper so you can abstract while you abstract
Just a note: You should use __str__ instead of __repr__. __repr__ is meant to be serializable, and shouldn't be used to just print things. EDIT: I can't figure out how to escape underscores, but you get the idea.
AFAIK it should be used as the "official" string representation of your object. Which, in the examples I looked at, is precisely what they used it for.
I have released the next version of Pyevolve, maybe it helps someone... http://pyevolve.sourceforge.net
But it isn't serializable. You can't reconstruct a new object if you don't include all of the fields required. Yes, it's a very minor issue, b/c we don't convert strings into objects often. But still. Why not use __str__? It's more concise.
He talks about how he broke the tree and delayed a python beta, but never goes into details. What did he do wrong? How can that mistake be avoided in the future? I think a post on that would be just as useful as this one.
gpyconf is a framework for handling configuration settings in Python, especially for applications that have a graphical user interface (or want to use one for changing configuration settings): It **automatically generates a GTK+ window that handles all the configuration stuff**  you only have to tell which option shall take what values.
Very interesting ... wondering if there are any other similar guides on other open source projects for those of us who want to contribute but are not sure how/where to start.
It needs some submissions I think.
That's some serious best-practices there. Several layers of wrappers are definitely professional enterprise mission-critical turnkey business solutions. Before using it, I'll write my own abstraction layer/wrapper on top of it. In the end, a simple "SELECT * FROM t" became a huge pile of new instances, method calls, data move, and general annoyances. On top of that, I still have to find any real advantages to anything that's not plain SQL. Sure, you can map toy SQL subsets with objects, but what about complex (or just downright insane) joins, subqueries, group operations and unions that will get the report you need in a single query? I'd rather use a declarative language like SQL over heaps of heaps of enterprise OOP.
Those are all good points. However, things like Elixir are (I hope) targeting the extreme opposite of your last case: a guy needs a little DB reading here, a little DB writing there and not much more than that. Sure you can write the SQL directly but Elixir, and its ilk, are _super_ easy.
I didn't see anything terribly simpler than SQLAlchemy's declarative ORM syntax (http://www.sqlalchemy.org/docs/05/ormtutorial.html#creating-table-class-and-mapper-all-at-once-declaratively) Did I miss something? Just the whole ManyToOne thing as opposed to foreign key and whatnot?
In all my playing around with SQLAlchemy I haven't really found a need to add Elixir on top of it all. So that might just make two people who missed something, perhaps.
Why has somebody downvoted this? Is it because it's about using a *gasp* functional programming technique? God forbid!
Isn't there metadata in gmail which IMAP and POP cannot provide access to, like labels?
The context manager in the case of exception checks is rather nifty. 
I found this post both hilarious and and something I could relate with.
Wild guess: old news is old?
BTW, writing context managers is easier if you use the contextlib module: http://docs.python.org/library/contextlib.html With it you just write a generator that yields the value you want your context manager to return (e.g. with allocate_resource() as x) and can handle the exception from yield to handle exceptions in the block. 
I'll go over my notes and commit history and try to do something on it. If you want, read http://jessenoller.com/2009/01/28/multiprocessing-in-hindsight/
show me a query you think SQLAlchemy can't do.
I'm using paramiko on a current project. It's quite good, but I've found that error trapping is a little.... lacking. Certain error conditions like paramiko.AuthenticationException seem to be trapped correctly but there's a lot of delay time between the catching of the exception and the disconnect. You can terminate immediately with a sys.exit() command, but that's not what I want in my situation. I want to trap the error and continue. Using paramiko 1.7.4 and python 2.5 btw. 
I haven't programed in python (or anything) in over a year now and I'm trying to get back into it. The problem is I have a pretty good knowledge of the language basics, though I need to relearn a lot of stuff I've just become unfamiliar with. I figured a good way to start would be to learn a gui framework. I've tinkered with wxpython in the past and liked it quite a bit, but I don't know how things have changed in the past year+ and figured I'd ask the reddit community. I don't particularly have a fondness for gui apps per say, I just thought that would be a good way to re familiarize myself, and I'm sure if I ever became serious about things I'd need a gui implementation at some point. If someone has any other ideas that might help me instead feel free to suggest them though. For the time being I'm just using Windows, but I love Linux and it's likely I'd install a flavor on my PC again sometime this year. I'm very familiar with both environments and anything I'd ever make I'd try to make cross platform. From what I've seen the top 3 (pygtk, pyqt, and wx) all work fine though I don't know anything in detail. 
I've been using pyGTK. The only reasoning for it is because the rest of my desktop environment is GTK. It's not the best reason. I've also used wxWidgets (they call it that still?), although I wasn't too impressed. Seemed confusing to me, but it was at the start of my programming experience. Should probably take another look.
I think the reason that wxWidgets sucks so much is that it's an abstraction of the windows display model. Either GTK or Qt are a decent improvement over wxWidgets, IMO.
On Windows, GTK and Tk look alien. wxPython and PyQt look native and very pretty. Both are good, and recently I've switched from the first to the second because I like Qt's API more.
It depends on what you're going for. If you're trying to be cross platform, I'd suggest Qt, esp. now that the license has changed. If you're only targeting linux/unix then I always think that GTK looks better (personal preference) and 90% of the casual users out there are using Ubuntu or another GTK/Gnome based distro so it will integrate nicely.
It certainly isn't perfect - but IMHO, it's better than wrapping shell commands.
I've used Tkinter for most of my GUI apps for four reasons: 1) I like people to be able to run my source as well as the distribution easily. Since Tkinter is part of the standard Python install, it's the simplest option. 2) When I'm drawing on a Canvas, I like how everything in Tkinter is an graphics object. I tag it and place it on the canvas, and it stays there until I decide to erase it. In other words, I don't have to mess with low-level painting like I do in GUI toolkits that are just a thin wrapper around C++. 3) I find the GUI code fairly easy to read when I come back to it, thanks to its liberal use of keyword parameters. I don't have to have the API reference nearby to decipher the various method calls. 4) If I want a native look and feel (which many complain that Tkinter doesn't have), then I use the [Pyttk theming library](http://pypi.python.org/pypi/pyttk). Right now, you have to install the library yourself, but fortunately it looks like [it's going to be included in 2.7 and 3.1](http://bugs.python.org/issue2983). EDIT: [Some screenshots](http://code.google.com/p/python-ttk/wiki/Screenshots)
PyGTK, fits inside my head better than PyQt, is more used than TkInter and TkInter just seems like crap, it's not very polished at all, I suppose it's really Tk itself I don't like. I've considered wxpython but I'd like a decent FOSS GUI designer for it like glade-3 for GTK.
If you have graphviz installed, you can use the following .dot file to generate a png of the state machine: digraph regexp { e [style=invis,width=0]; 0 [shape=circle]; 1 [shape=circle]; 2 [shape=circle]; 3 [shape=doublecircle]; e -&gt; 0 0 -&gt; 1 [label="\""]; 1 -&gt; 3 [label="\""]; 1 -&gt; 2 [label="\\"]; 1 -&gt; 1 [label="[^\\\"]"]; 2 -&gt; 1 [label="."]; rankdir=LR; // {rank=same; 1 2} } You can generate the png using `dot -Tpng test.dot &gt; test.png`. The commented-out line would make the finite state machine look better (more linear), if only dot would keep the edges from colliding. Unfortunately, I can't find any way for it to do that.
PyQt/Qt. It's simple and it's a little bit more than a simple GUI toolkit. It's a real development framework. You want web? You have it. You want embedded or mobile? You also have it. 
HTML is the least shitty.
I use Tkinter primarily for your reason 1. I didn't know about Pyttk though. Thanks for the tip. 
it's also not a GUI toolkit.
Which one do you think is easier to learn/has better documentation? I liked what wx had to offer (tutorial wise), but it seemed they stopped adding to it and it doesn't look like they've done anything since I last checked it over a year ago. 
What does that even mean rofl.
Yah, I never even bothered with Tkinter. It looks like garbage on every OS and I did not like the design approach they use. It doesn't seem well suited for large projects at all. I don't understand why it's still (unless things have changed?) the standard framework. 
I say just continue using CPython, worry about performance if it ends up mattering.
I'm leaning towards Qt so far based on the responses. I'll probably look into it this weekend if I have some time. I'm probably going to install Linux before I start programming again. It just feels dirty using a Windows environment :P
No one can make Graphical User Interfaces with HTML.
define "gui toolkit". I make graphical user interfaces for programs written in python by writing HTML, which browsers interpret for my users. I've used Tkinter, and wx, plus dabbled with PyQT. The baroquness and complexity of those "gui toolkits" is truly astonishing compared to outputting HTML and javascript. Which is pretty complex itself.
Still with homebrew ORM, auth, ... reinventing what was already written for WSGI.
I'd vote for Qt. Especially with the impending license change to LGPL. Lots of new frameworks and such going into it. PyQt is not the most Pythonic framework available however. Documentation is "ok". 
PyGTK is by far the most Pythonic IMO, no passing around -1 for NULL(wxPython) or C++ callback strings(PyQT). And Tk is just ugly.
`print()`/`raw_input()` ;)
GTK+ doesn't look alien on Windows for a long time. It can use the Windows themes or, if you want it to look alien, it can use the normal GTK themes.
Cocoa, then PyQT.
what?.. you mean you've never created a GUI to track ip addresses
I don't like any currently available GUI toolkit for Python (I develop mostly on windows). PyGTK is tough to get on Windows, PyQT &amp; WxPython have non-pythonic API and Tkinter is ugly. Currently I am looking at WPF &amp; trying to work in IronPython. For simple applications I have been using EasyDialogs on windows.
GTK is easier to understand, looks a lot better than wx/qt, and most people already have the relevant libraries already installed for some other application.
As a former Java developer, I've used Swing with Jython. Jython does a really good job of integrating Java libraries and Swing is a complete and good looking toolkit. I want to learn a more native GUI toolkit, but if you're planning to make a quick, one-off program, you might as well use what you know.
Still does. The GTK Windows theme just simulates a generic Windows theme and doesn't use the actual theme being used.
So for an application that say, converts files from one format to another as a desktop application are you going to deploy a http server with CGI to run the python script or do you deploy a script that outputs an html file which the user then opens (what about input?)
&gt; I don't understand why it's still (unless things have changed?) the standard framework. I think it's mostly because the Python developers don't want to bundle one of the larger frameworks to let IDLE work.
wxPython. I think it makes nice interfaces, I find the programming model easy, and it is "nearly" standard.
Sure I have, but I used VB.
yep - fixed
jQuery UI. Oh wait.
I've recently been impressed by Qt. Granted, the callback strings from Python is the ugliest thing you have ever seen, but that's only a minor part of the code. QtDesigner is pretty good (better than GTK's equivalent) which is important to me, because I don't want to code pixel perfect forms by hand and also like the portable .ui files (which means I can use the same layout if I want to switch to C++; something I'm in the middle of doing now since the prototype in Python works). I also like that each widget can easily be subclassed and modified to fit your specific needs. The thing with Qt is that it's much more than a gui toolkit. It can be overkill. For simple, one window applications I'd probably still use GTK.
HTML, via django
I didn't say "least shitty for all possible scenarios", I said "least shitty". Sometimes, there's nothing you can do but use a shittier framework than HTML+DOM.
That's the exact same thought process I had. Started with PyGTK because I wanted to blend in with Gnome. Looked into wxPython briefly, and it didn't look like that would make things any more fun. So I stuck with GTK.
Qt. It's better documented and better architected. Easier to extend, easier to use, and more powerful to boot.
&lt;html&gt;&lt;body&gt;&lt;p&gt;&lt;blink&gt;LOL&lt;/blink&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;
&gt; Error Line 1, Column 21: element "BLINK" undefined.
CGI? No, seriously. CGI.
When you are looking for a GUI toolkit specifically then its probably something you would want to deploy to computers, which is somehow something you think to be an obscure scenario
Mixing 3.0 and 2.6 or `from __future__ import print_function`?
Guilty as charged. `print` looked bare without the parentheses, so I 3.0'd it, but forgot to update `raw_input`.
I think this kind of thing is going to be common for all of us for a while. I've set my interactive Python shell to 2.6 with `from __future__ import print_function`, which leads to problems when I cut and paste into other things
[Doesn't look XP-like enough](http://www.learningpython.com/images/PyGTKWindows.png)? I'd say, most users won't have an issue with that. [Some more widgets](http://gnunet.org/screenshots/gnunet-gtk-fs-status-winxp.png)
Where "obscure scenario" is nowadays something that application writers before the HTML boom would consider normal and day-to-day use. That's why GUI toolkits support that.
First thing I do when I have to use a Windows machine is switch out of that hideous theme to classic. I take it they're not hardcoded to look like that?!
Wow. Things really must be bad then.
I've been trying out wxPython for a few days. Under Windows, the exe py2exe generated for a very basic PoC was just shy of 6MiB... I thought that was bad, but py2app (for MacOS X) generated a 33MiB app that didn't even work with a basic setup (I have to look more into this). For Linux, deploying I'd do the traditional way, through either distutils standard, eggs or even .deb/.rpm , binary as fallback maybe. Should I look at GTK or Qt? anyone interested in deploying simple apps for different OS's that don't require a complicated install procedure? Last time I checked GTK more or less thoroughly it was humongous (but that was already a bunch of years ago), would I have to bother the user installing GTK? would it be huge to link statically? would it work as-is by py2exe? Any experienced insight would be appreciated, I'm wasting quite a bit of time with this. On a related note, I made some toys with Pyglet, making my own menus in openGL... for simple stuff it's a solution and very doable, problem is currently it crashes on a non-significant amount of Vista drivers... which really set me back hard, I basically had to throw away a solid 10 days work.
That's extremely interesting... I had totally ruled out Tk because of the lack of native look and feel. You just made my life a bit harder. Will have to look into Pyttk.
Nevow + Athena
On OS X (since about 2005) you usually include both PowerPC and Intel code. They also usually ship unstripped binaries, so coredumps actually make sense. It might even include multilanguage strings. The 5.5x blowup is easily accounted by that. DMG disk images used for shipping over the internet are compressed by default. So not that big of a problem.
I see. Any easy improvement on that?
It might be that Snow Leopard will dump all non-intel Macs (now ~2.5y old). So you *could* force people to use only Intel. But, all OS X programs are like that (fat binaries, debug symbols, and multi language), and only a few seem to complain. 
Thanks for the info. Actually I'm using a lot of HD and I have barely any multimedia on my Mac... Do you know what exactly about the multi-language is packed in the app? doesn't make any sense to me a priori. I have all the multi-language support in my machine already (actually my MacOS X is Japanese, I got it there) and I always thought it was in every machine.
Try for example `ls /Applications/Adium.app/Contents/Resources/*.lproj` (replace Adium.app with your own). I don't know wether py2app would include any language strings of native libraries. That is a Cocoa/Carbon feature though, not really Python related.
**files = ['/'.join([base_path, shift_name, 'sec' + str(sec_num) + file_shift_name + '.csv']) for sec_num in range(1, 12)]** **files.extend(['/'.join([base_path, shift_name, file_name]) for file_name in ['missort.csv', 'cfb' + file_shift_name + '.csv']])** Everything works the way I want it to but I thought surely this could be done much more concisely or elegantly?
I'd replace '/'.join with os.path.join - it's more reasable, and also cross-platform. Also, use a single listcomp, with the common filename joining code only stated once - the different filenames can just be appended onto the list to map. Also string formatting is usually easier to read than concatenation. Here's my version: files = [ os.path.join(basepath, shiftname, filename) for filename in ['sec%s%s.csv' % (secnum, fileshiftname) for secnum in range(1, 12)] + ['missort.csv', 'cfb' + fileshiftname + '.csv'] ]
Yes, but Adium is properly localized. Icons, text, help, menus, show to me in Japanese which is my default lang. in the OS and this is a Good Thing. In Mac OS X world it's common to see this. Cyberduck or Adium for instance, surprised me with perfectly well translated messages, even for the updates. I wonder about other languages? Adium is especially cute, with the ducky holding banners in Japanese (busy, not here, etc, translated and clearly human-designed Kanji taylored for the occasion). This means localized text and also artwork, which I can appreciate since I've done this kind of work too and it's hard work to get it well done. However, my little toy apps have no localization support whatsoever. What goes there? the English version a gazillion times? makes no sense.
No, they use whatever theme you set. You can even download a Mac OS X theme for Windows and have a (poor, as every theme) imitation of the Mac OS X look in your GTK+ programs on Windows. AFAIR the theme engine on Windows is called "Luna" and GTK+ uses exactly that, unless told otherwise (you can also use GTK themes in Windows just like on Linux, but then your apps look indeed alien).
The problem is that it should be the user who set his theme, not me.
A lot has changed since python 2.5 introduced the new generator features. Everyone used to recommend Twisted, but what's the best now?
I'm biased because I wrote large portions of eventlet. Python 2.5's enhanced generators make it possible to implement coroutines in pure python by unwinding the stack on every coroutine switch. However, this is invasive and requires code to be written specifically in this style, just like Twisted requires writing code in a certain style. greenlet, which is a port of the Stackless Python stack-slicing assembly code to a cPython extension module, doesn't require the entire call stack to yield in order to perform a coroutine switch. eventlet uses greenlet for this reason; code written for eventlet looks identical to code written for blocking sockets, except for the socket module that is imported and the way threads ("green" threads or coroutines in the case of eventlet/greenlet) are started. Another thing that is nice about the design of eventlet is that it is a library, not a framework. While most asynchronous frameworks require that you register some handlers and then run a main loop so it can call your callbacks, eventlet implicitly starts the event loop and uses a technique called "trampolining" (in the old lisp sense) to bounce back to the event loop when some coroutine wants to wait for io. It would be interesting to see examples of echo servers for each of these different libraries. It would also be interesting to see benchmarks for each of these different libraries.
Informative, thanks. &gt; examples of echo servers for each of these different libraries. Good idea. I'll make that.
paramiko is great. and STAY AWAY FROM TWISTED, people. It will ruin your day.
The GTK theme is inherited from the user settings, *just like on Linux*. The GTK+ runtime that I saw on Windows had a small configuration app for that (and as far as I know, defaulted to "use the Windows theme", so most users wouldn't need to use it anyway).
I'm used to GTK. Unfortunately most users are not... and the sole requirement to install the runtime can be a big hurdle... don't get me wrong. 
You could bundle the GTK-DLLs with your applications. AFAIR there is a recipe in the py2exe wiki. Maybe it got somehow easier in the meantime, I don't use Windows anymore, so I can't tell but at least they provide official Win32 binaries now.
That's another problem, I don't use Windows much either and testing is a PITA. It's not seamless like with, say, pyglet or tk, and it's way too heavy for a small application. In order to be a truly bonafide cross-platform solution, GTK still has a long way to go IMO. For a big application like Gimp it's justifiable, but people are not going to get into such a mess to install metricunitconversion.py or magic8ball.py (taking it a bit to the extreme here).
Thanks, that's what I was shooting for! I'm a newbie python-er and it gets foggy with so many choices. I think it's fun though!
The more I use python, I'm less convinced about the need for private/public/protected. Who exactly are we protecting these object members from? 1) Can't be ourselves, that would be a bit werid 2) Can't be from hackers, as that isn't going to stop them 3) Can't be from fellow programmers, as they should be allowed to do what they want with the code they run since you've already agreed to give it to them. Having a simple indication that someone should change said "private" variable should be enough. If they go against the suggestion and do something bad, that's their problem for not following your API.
The phrase used in the Python community to describe this is "we're all consenting adults." 
I must be missing something, because it's kinda been the opposite for me. How do you indicate internal only methods/variables? Prefixing function names with "__" is just ugly and I don't like the idea of using docstrings for this purpose.
&gt; How do you indicate internal only methods/variables? Just don't.
So someone does a dir(my_class) and sees a potentially useful function, which happens to break something else in an utterly confusing manner?
Encapsulation is handy when you work with stupid programmers. And ignorant ones. And terrorists . . .
Surely it's their fault for not finding out what the function does before calling it?
That's what docstrings and the (admittedly ugly) convention of prefixing your "you probably shouldn't use this" stuff with underscores are for. Also, there's generally ways to avoid writing functions that break other things in utterly confusing manners.
The PEP8 way is to prefix the name with one underscore. 
Yay!
Hunh. I hadn't realized the new yield expression was quite so powerful. So I can "call" a function that performs IO by yielding a generator to the multitasking engine, and then it chucks the result my way once it's done. It does mean all functions that perform IO have to be called slightly differently to non-IO functions. But perhaps this is a good distinction to make! How does this compare to Haskell's monads?
multitask is a great idea, but it's hard to use in practice because Python's generators cannot yield from nested functions.
Using public and private members, any other programmer can quickly and easily see what the interface to your class is. They do not need to worry about reading anything else about the class. 3rd-party software can also take advantage of this. IDEs can parse your classes and provide drop-down lists of public members (try Visual Studio or Eclipse). Documentation can be automated by listing public members to classes. 
So in order to use a piece of software, you are forced to read its entire code base?
No, but if you're going to use a function, you should probably read its docstring.
&gt; They do not need to worry about reading anything else about the class. Abstractions leak.
In order to write a software against a API, you should know what a function is before you call it.
You seem to be suggesting the fact that IDEs support public/private as a feature of public/private... that's kind of circular. And if the only purpose of making it public/private is so programmers can _see_, then again, the only useful thing is having some standard way of indicating what others should and shouldn't call, without actually enforcing it.
It helps when seeing the class to know *for certain* that its private members are not part of its API. You don't have to worry about it being a mistake of the developer - otherwise the class would not have passed a test phase. If we took your route and did not enforce privacy, you will find classes with "private" members that are actually part of their interfaces. Additionally, as a developer of a class, if you enforce private variables, you are able to modify the private members of that class knowing that nobody, anywhere else, is using those members. This becomes important when you need to add new features to a class, and you want to refactor its internals. 
&gt; It helps when seeing the class to know for certain that its private members are not part of its API Following a predetermined naming method accomplishes that. &gt; you will find classes with "private" members that are actually part of their interfaces This assumes that there is no clear way to tell the difference. &gt; you are able to modify the private members of that class knowing that nobody, anywhere else, is using those members People using your code in ways that they shouldn't is not your responsibility. For all you know, they really needed it at the time, but its up to them to maintain it.
Would a simple @reyield decorator around all the nested functions solve this?
I am a frequent reader of [Old New Thing](http://blogs.msdn.com/oldnewthing/) blog maintained by Raymond Chen from Microsoft. Where he explains some of the _features_ of windows &amp; why they are there. Almost 90% of tims it turns out somebody discovered a private Windows API, started using it and while testing for next version of windows that API was maintained even though a new better one was introduced. What you might consider a useful private function may very well be a useful for may consumers of your API. You can't prevent them from using that function. Having private API is like having a law that can not be enforced. That is why Python has following conventions: 1. `__foo__` might be something internal to language. 2. `__foo` is something that is private &amp; you shouldn't really use it. 3. `_foo` is also private but has a relatively stable meaning. It won't show up in public API but can be relied upon in a pinch. For example if you use `namedtuple` in 2.6 to generate a class, you may notice `_make` &amp; `_replace` methods which are really useful in certain situations.
Should be: using lists for some set-like operations. Not mentioning builtin set nor frozenset.
I don't know anything about the other frameworks, but I just tried this with Django and found that by commenting out a bunch of unused stuff in settings.py the line count went down from 580 to 105. Having said which, I'm not sure how this metric is supposed to help anybody choose a framework anyway. He kind of implies this figure relates in some way to speed, which it entirely doesn't. Nor do I think the number of functions an application calls is any indication of its suitability for anybody's purpose, unless that purpose is writing Hello World.
Actually, it relates almost exactly to speed for this particular test. On my machine (that gets about 48K pystones) the r.bfg app gets ~ 900 req/sec, the Django app is ~ 700 req/secs, the Pylons app gets ~ 650 req/sec, and the Grok app gets about 300. So, in general in this test the fewer profile lines, and the fewer function calls, the faster the page was served. That said, it's obviously not going to be the only factor you use to choose a framework. But it's not meaningless.
Django abuses \_\_import\_\_
in python, number of function calls relates to speed of response almost directly. you can whittle each function down to doing almost nothing, at which point its only the depth of stack trace which slows you down.
django with over four times the number of function calls was faster than your pylons app ? that would appear to contradict what you just (and also I, in my other message) just said. edit: oh duh, four times the number of profile lines, wasn't looking.
Django doesn't have four times the number of function calls: Pylons: 258181 function calls Django: 212270 function calls The reason it has more profile lines (as opposed to function calls) is because it apparently defers doing stuff until the first request (the bottom of the profiler output shows many functions that are only called once or twice). So the "number of profile lines" metric in its case is a bit bogus; it actually does less work than Pylons to render the page. I'll see if I can't fix the profiler to *really* ignore the first request. 
joebutton helped me get the Django profile output down to 105 lines and 103564 function calls (see the OP for more info). After doing so, Django gets about 800 rps. So I think the fewer-func-calls == better speed axiom still holds.
I might be being naive, but it would seem to me that the number of functions called (which is the headline figure cited in mcdonc's blog post) is a good speed metric only if we assume a) each function takes the same time to execute and b) each function is called exactly once. Those don't seem like reasonable assumptions to me.
While you could probably construct a Python application that had lots of function calls that beat timings of a similar application with fewer, it would probably be a fairly torturous example. I think it's only an unreasonable assumption that fewer function calls == better speed if you can't repeatably back it up with numbers. But we can: the numbers pretty much add up in support of that theory for me.
In an application that's shuttling data to/from a client/server pair of some kind and not involved in some heavily algorithmic activity, there may be a few functions that do something particularly time consuming but most are reasonably straight through. In such a scenario, the time overhead of the function calls themselves is generally larger than the work performed within most functions. The overall complexity of the app is what slows it down.
I vaguely recall an option for repoze.profile that was meant to *really ignore* request #1. It isn't actually working?
Then you might like Mozilla's XUL.
I think reddit markup ate your 2nd convention.
I added [Concurrence](http://opensource.hyves.org/concurrence/index.html), which runs on top of stackless python. It was released a few months ago by Hyves, a huge Dutch social networking site. One thing that's notable about it is that it comes with a custom, asynchronous MySQL client.
Do you need *all* your i/o to be coded to the eventlet API in order to avoid a call in one greenlet blocking all the other greenlets? For instance, is it possible to use any old database client library (e.g. mysqldb) or would that end up blocking all the "threads" whenever you issue a query? What about file i/o? Edit: I should have dug around a bit: the answer to my question is in [the documentation](http://wiki.secondlife.com/wiki/Eventlet/Documentation#Integrating_Blocking_Code_with_Threads). Basically, the answer is yes, things that block a python thread will block all the threadlets, since the threadlets run in a single python (os-level) thread. The solution is to execute these blocking calls inside a separate python thread, and eventlet provides a thread pool to make this easy.
&gt; The reason it has more profile lines (as opposed to function calls) is because it apparently defers doing stuff until the first request Indeed. There are a _lot_ of things in Django which are deliberately designed to be lazy and not evaluate or do any work until absolutely needed (parsing settings, populating model caches, etc.), and so the first request to Django tends to be a bit of an up-front hit since all that has to happen.
How does this compare to the dozens of other python graph libraries?
Awesome article. Solved my confusion.
I can only speak about networkx, which seems to have more features, more documentation and more users. Also the author is quick in answering to bug reports and the like.
&gt; He kind of implies this figure relates in some way to speed No, he doesn't. Read again, please. 
looks a whole lot more straightforward than pydot. and by "a whole lot" i mean "holy crap thats a lot more straightforward".
It wasn't. I fixed repoze.profile, released a new version (0.7), and I've amended all the test results. See http://plope.com/whatsitdoing2 for more info. Apologies.
This is the basic of the basics. Nothing to learn there. I wonder if the poster has read the articles s/he's refering to. These articles give a clearer and stronger explanation than the vague thing I have just read.
&gt; No, he doesn't. Read again, please. Yes, he does. Read again, please.
I never would have guessed python-graph is for working with graphs on Python.
wtf is this crap?? a formatter for pwd? totally uninteresting.
If you have an attribute like `__foo`, Python mangles its name to `__classname__foo` providing a sort of private/protected attribute.
No need to apologize! I've been happily using repoze.profile, and I must say it was an wonderful idea; many thanks!
That's more like it.
From the original article: &gt; One measure of what you're going to be faced with with when your web application framework doesn't work as advertised is the complexity of what a it does to render a very simple page. If it does a lot of work to render a very simple page, you might need to understand a lot if it breaks or to extend it. If it does very little work, it's likely it will be easier to fix and/or extend than one that does a lot of work. Additionally, usually it's a corollary that the less work an application server does to render a response, the faster it will render that response. But that's not the point here, we're only concerned about work done.
RTFA!
more tab, love?
the usual lame fanboi response :) typical, yes I did read the fucking article and that's what it does.
Some pretty ugly code right there.
Tabs at 6 spaces. Weird. 
I'm unclear why this exists. If you want the exact existing syntax of Makefiles, just use Make. If you want something better, there's Scons or various other alternatives.
Yeah, I'm not sure either. Not that we don't need a new make. As far as tools go, the syntax is very nearly as cryptic as bash. What I've taken to doing lately is, when starting a new project, the first thing I create is a build script in Python. It doesn't actually perform the build though, it outputs bash commands to stdout. So I can run it and look at the output and when I'm satisfied I pipe it to the shell. Simply marvelous, I am so much more productive now. Nothing is off limits. rsync'ing to remote machines, creating/updating databases... it just blows away make and/or ant and I can do absolutely anything I want in a single build system. I will continue to use make though for simple c/c++ projects.
scons is a bloated piece of crap IME. cmake is neat but leaves an impression of lacking a proper scripting language. there's some hope in [waf](http://code.google.com/p/waf/).
Mind uploading sample scripts? I'm curious as to how to structure your stuff :)
Not Twisted. Twisted has really x 5 bad docs. 
That's difficult, I'm not going to just upload a script as there's shit there that's proprietary, and I'm not going to take the time to edit it out. The key thing is to use os.walk and os.stat and create a dictionary containing all of your files, indexed by path. Then as the script performs its various operations, you update the dictionary to reflect new modification times and so forth, so that you always have a representation of what your project tree would look like had the operation actually been performed. You could skip this step and simply brute force everything but the big feature for me is being able to look at the output, and if you are careful to only update those things that are necessary, then the output can be quite terse and easy to read. For a big project and to prevent mistakes this is key; I usually know exactly what commands will be output, so if something is amiss I notice it right away. It's python. It doesn't have to be pretty. It just has to work. _All of the time_.
Thanks for the link to Waf; I hadn't heard of it and I'll definitely have to check it out. However, I've been pretty happy with SCons so far, though I've only used it a little for one moderately large project. What issues have you had with it that make you prefer Waf and/or other tools?
I think banning stick figures wearing hats from any conference is a good general rule.
How is the policy on floating heads? 
So basically Randall's going to be at PyCon 2009?
No, he's been banned for encouraging long compile times, especially so for Python code.
my biggest gripes where that SCons doesn't provide enough documentation when some of the tools you need aren't available, like e.g. a precompiled header builder. there's something on the wiki, but it doesn't play nice with -j option. also, its configure system used to suck, no idea how it's now - i certainly don't want to do build option processing by hand...
Some of his jokes are good. Some simply suck, and don't show any research at all by the comedian.
Yes. Since the green threads are cooperatively running in a single pthread, anything that blocks this thread blocks everything. I would love to implement non-blocking file i/o. For a while the APIs were too non-standard to use, but I think newer versions of linux might have usable non-blocking file i/o apis that mix well with select/poll/etc. For using mysql, using mysqldb in a thread is an answer. Using a threaded db server and accessing it over another protocol such as http inside eventlet code is also a good idea. For postgres, there is pg8000 which is known to work with eventlet. There may be other pure python postgres libraries that will also work. Mysql does not have a pure python database adapter (although people seem to have been talking about it for years) And of course, plain old threads also work.
I'm curious which comics he wrote that show a lack of research?
Stop reading [How To Criticize Computer Scientists](http://www.cs.purdue.edu/homes/dec/essay.criticize.html).
Best link ever. This deserves a wider audience than the python subreddit. Anyone hungry for sweet karma want to post it to reddit.com ?
You've got 15 mn or I go for the kill.
What's the code to escape a closing parenthesis? Is it a colon?
Watch for the sky. He could be using antigravity.
http://xkcd.com/528/
IOW, you advocate shutting down all runway fashion shows.
So.... Hitler isn't better than Vista?
He is, but everyone in the know is aware that the latest Windows 7 was a picture of Bush, not Hitler.
Touche, sir.
It sucks. I should have written "Watch for the sky. He could be using python."
See that series of five buttons along the bottom of your comment? Good. Click the third one, labeled "Edit". Re-write as necessary.
I don't like mingling with the past.
But Python is an interpreted language.
That was the joke. The article said one of the reasons he was banned was because he was perhaps the number one distraction for programmers (i.e. he [*encourages long compile times*](http://xkcd.com/303/), regardless of the validity of the excuse).
I'm confused. How can anyone take him seriously enough to actually ban him from the conference. Wasn't the Python T-Shirt last year one of his comics? Anyone have audio or video of the keynote?
I believe the PyCon 2009 shirt is also an XKCD and I think is is just a joke. How could a conference for a language named after those who created the Ministry of Silly Walks ban someone as silly as Randal Munroe. And besides, I would think a stick person would have a very silly walk.
he didn't really give a keynote at last year's PyCon... 
You can't escape it. It hangs over you even now.
Same as regex, \)
I'm pretty sure it's a joke dude.
Does anyone have a link or anything to his 2008 keynote?
Damnit... I suck. :)
Your disgusting.. :P
That's just badass.
He already told you: he is not [walking silly](http://xkcd.com/245/) ! And no he doesn't need any grant to develop it !
See, I could have sworn he was being banned for being moderately interesting. Pycon doesn't take humor lightly. 
Upon further inquiry, I am inclined to say that the PyCon ban is a joke... a tribute, if you will. "Red Spiders vs Web Spiders" turns up nothing, except the xkcd thread talking about it and the PyCon ban page. ... it really had me going though.
&gt;long compile times That's why I code in befunge.
http://us.pycon.org/2008/conference/keynotes/ there wasn't one.
Yes, that is a good idea.
`import time-travel`
For one thing, it can probably made to run faster, because specific commands (like rm) can be handled directly from Python, thus not requiring a fork. For another, for large codebases, it's wonderful to have a proper migration path out of a big mess of Makefiles.
His disgusting what?
from \_\_future\_\_ import timetravel
it doesn't work! * &gt;&gt;&gt; from __future__ import timetravel * &gt;&gt;&gt; car = timetravel.getVehicle(type="DeLorean") * &gt;&gt;&gt; car.setSpeed(88) * &gt;&gt;&gt; car.go() * Traceback (most recent call last): * File "&lt;stdin&gt;", line 1, in &lt;module&gt; * InsufficientPowerError: 1.21 Jigawatts required. 
Not to mention 171 character limit lines, and he was doing so well on the first 8 lines as well.
hey I have that same problem (and not even turning your head over solves it (:)
Interesting, especially if it can be used as a practical way to test other Python implementations for correctness. I would be interested to see to what extent the semantics-driven approach can be used to generate a high-performance interpreter ... it would give the Haskell community something to crow about. :-)
You still have an unmatched ]
It's not a problem as long as it comes either after a "#" or inside quotation marks.
You've won!
It is a permissive license a la BSD, MIT. See: http://en.wikipedia.org/wiki/Academic_Free_License http://www.opensource.org/licenses/academic.php
Excellent. I only hope people realize the importance of this, not many real languages have usable SOS specifications. I wonder how much difference there is between minpy and python, and if the missing bits can be expressed purely in minpy. Edit: Should have finished reading the article before commenting.
&gt;Pycon doesn't take humor lightly. There is no "LOL" allowed on #python
In the beginning of the talk he mentions that a function cannot assign to a variable in its containing function, however I believe that's now possible in Python 3.0 with the 'nonlocal' keyword.
The talk's a little old, here's 'nonlocal' in use in a python3 program: def foo(): var = 0 def bar(): nonlocal var var = 4 print(var) bar() print(var) I didn't know about this and I think I'll struggle to find a use for it, but glad to know it exists.
The the typical case where you don't want to use multiple threads in Python - it will simply run slower as you add more threads. Threads in Python will use multiple cores effectively only when the thread work is done in a C extension that release the global interpreter lock (GIL). 
Looks entirely IO bound, not CPU bound. File IO. Depending on how these files are stored on disk, parallel could be a bit faster. If this is a network drive then the parallel version will kill doing it in series due to the latency alone.
It's mainly there to stop Paul Graham ragging on Python for not being able to do this: def counter(value, increment=1): def inc(): nonlocal value value += increment return value return inc ;-)
It'd be handy for pulling data out of hand-rolled mock objects! I... uh... tried to do this today in 2.5
Why is rebinding of names in parent scopes useful for pulling data *out* of an object? 
oh uh maybe I'm misunderstanding nonlocal but I ended up using attributes on the function to ask it later what arguments it was called with. def cache_result(key, callable, time): cache_result.k = key return callable() ... self.assertEqual(cache_result.k,"the generated key") I'm just starting out with unit testing so maybe I'm being crazy.
Peter Thatcher has provided a nice and illuminating ( although a bit too complicated ) proof-of-the-concept [implementation](http://www.valuedlessons.com/2008/01/monads-in-python-with-nice-syntax.html) of monadic return and bind functions in Python using Python 2.5 style generators. The basic idea applied to IO was to build an IO class that derives from Monad. Now IO objects are yielded by a generator inside of `do` and this very same IO objects manage to send values back into the generator that yields another IO object etc. just as required. At each step the particular overwritten `bind()` of the Monad class can perform an arbitrary computation. 
I have transcribed this lecture in my post "[Learning Python via Video Lectures](http://www.catonmat.net/blog/learning-python-programming-language-through-video-lectures/)"
&gt; Threads in Python will use multiple cores effectively only when the thread work is done in a C extension that release the global interpreter lock (GIL). Or when you use one of the multiple alternate Python implementations available.
&gt; The pwd module can be used to read &gt; user information from the Unix &gt; password database (usually &gt; /etc/passwd). The read-only &gt; interface returns tuple-like objects &gt; with named attributes for the &gt; standard fields of a password record. The blog author chose to write a formatter for /etc/passwd entries, but the module does more than just formatting.
Looks like they upgraded or changed servers over the weekend and haven't gotten everything back up. http://wxforum.shadonet.com/viewtopic.php?t=22967
I noticed that too yesterday. Come on reddit, what's the point of down voting this post (I count 1 up votes, 3 down votes)??
Maybe it's not relevant enough to most people to warrant a high ranking. :)
I first noticed this on Monday. I was afraid they might have changed the URL of their APT server again (they did this about a year ago and blew up some of my update scripts). Glad to know this isn't the case.
I would venture to say it is a waste of space (on page and on disk), and it adds nothing to the conversation.
Did you report it ? Maybe there is no FreeBSD tester in his pool.
Sweet. Here's a link to it: http://www.scipy.org/
Oh goodie. iPython and the matrix manipulation tools in SciPy are great stuff. (almost make me want to quit using R, but not quite)
Doesn't IO release GIL as well? Honest question.