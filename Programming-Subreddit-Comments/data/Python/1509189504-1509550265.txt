On this week I'm creating a script for getting data from XML and send it to Zabbix. 
Agreed. I'd love to see a version of that which makes sense.
What if I wanted to check if False == None? I should be able to do this since both are falsey. 
More like there are some cases in libraries where `== None` will throw a runtime error.
It's only complex if you confuse yourself. "How many apples do you have?" can be answered with an integer like 3, 5 or 0. Or you can say "I don't know" and that's what `None` is. It just means lack of value, or undefined value.
With the cost of starting the interpreter, this is not going to be a smooth operation.
True. But this overhead is a small price to pay for the ability to quickly and easily add autocomplete to your command line tools IMHO.
Kattis? Love it, they use it for courses at University as well!
I've completed the projects at the end of the book lol You can see my code lol in some of my posts, I went kinda fast, I just don't remember seeing or using it
I’ve never in real life used none to express the idea that I didn’t know something. None is a fairly certain negative quantitative statement.
&gt; Stop being a prat and making excuses for being a script kiddie. Yeah, I'm such a bad guy for making a bot that potentially makes people learn about something. I wish I was a good guy like you who goes around being pissed off by something stupid and tries to insult people by calling them names. Good luck with that. 
[freezegun](https://github.com/spulec/freezegun) does the time stuff as well. The socket stuff seems specialized, it it generic for other actions?
So I looked. It's one single sub heading and paragraph in a section that entirely about defining functions, and until you get to regex i never saw it again.
`freezegun` only stops time and returns the pre-initialized value. This package allows you to move it forward step by step. For example, if you pre-added a future event for a socket to be read-ready, when the `select` \ `poll` call will return the time will actually advance by 3 seconds. Generic for other actions such as?
Because `None` is just a slightly friendlier implementation of [the billion dollar mistake](https://www.infoq.com/presentations/Null-References-The-Billion-Dollar-Mistake-Tony-Hoare).
Because you never change `status`, and your while loop never exits.
This is my quiz which has this part in: import random import os.path import sys point = 0 status = "" print("Would you like to start the quiz?") start = input() while(start == "Yes") or (start =="yes"): def start(): option = int(input("Enter 1 to register, 2 to login: ")) if (option == 1): register() elif (option == 2): login() def login(): username = input("Please enter your username: ") password = input("Please enter your password: ") filename = "login.txt" try: f = open(filename,"r") except FileNotFoundError: #if file login.txt doesn't exist, print an error print("File ", filename," doesn't exist") quit() else: #read the file line by line f = open(filename,"r") login = False #check every line in the file for data for line in f: word = [] #split the line based on space. word[0] contains username, word[1] will contain password word = line.split() if word[0] == username and word[1] == password: #the login ID and password is valid, so login the user print("Login was successful") login = True answer = input("Would you like to go to the menu?: ") if (answer == "Yes") or (answer == "yes"): menu() break return login return False def register(): item = 0 file = open("G:\\Folder Redirection\\Desktop\\quiz\\login.txt","a") name = input("Please enter your name: ") year_group = input("Please enter your year group: ") age = input("Enter your age: ") password = input("Enter a password: ") new_username = name[:3] + str(age) #generate username print("Your new username is",new_username) print("Your password is",password) file = open("G:\\Folder Redirection\\Desktop\\quiz\\login.txt", "a") file.write(new_username+" "+password+"\n") file.close answer = input("Would you like to go to the menu?: ") if (answer == "Yes") or (answer == "yes"): menu() def menu(): option1 = input("Which topic would you like to do?\n1. Take a quiz\n2. Display a user's quiz history\n3. Print report of a quiz\n-1 Exit\n") if option1 == 1: quiz() elif option1 == 2: username = input("Enter the username of the persons quiz scores you would like to view.") #elif option1 == 3: # PRINT REPORT OF A QUIZ... # topic = int(input("Choose the topic\n1. Computer Science\n2. History\n3. Music\n")) #dif = int(input("Choose the difficulty\n1. Easy\n2. Medium\n3. Hard\n")) elif option1 == -1: quit() def quiz(): topic = int(input("Choose the topic\n1. Computer Science\n2. History\n3. Music\n")) dif = int(input("Choose the difficulty\n1. Easy\n2. Medium\n3. Hard\n" while status != "q": start() 
Hey all, I have implemented the fastest ForceAtlas2 implementation in Python (with Cython optimizations). I found that the existing python libraries were either too slow or missed essential features like Barnes Hut Approximation, so I wrote my own by extending them and optimizing rigorously. GitHub: https://github.com/bhargavchippada/forceatlas2 pypi: https://pypi.python.org/pypi/fa2 Install using pip: pip install fa2 Looking forward to suggestions and contributions :)
This is my code: how can i enable the menu to let me go to the quiz function? import random import os.path import sys point = 0 status = "" print("Would you like to start the quiz?") start = input() while(start == "Yes") or (start =="yes"): def start(): option = int(input("Enter 1 to register, 2 to login: ")) if (option == 1): register() elif (option == 2): login() def login(): username = input("Please enter your username: ") password = input("Please enter your password: ") filename = "login.txt" try: f = open(filename,"r") except FileNotFoundError: #if file login.txt doesn't exist, print an error print("File ", filename," doesn't exist") quit() else: #read the file line by line f = open(filename,"r") login = False #check every line in the file for data for line in f: word = [] #split the line based on space. word[0] contains username, word[1] will contain password word = line.split() if word[0] == username and word[1] == password: #the login ID and password is valid, so login the user print("Login was successful") login = True answer = input("Would you like to go to the menu?: ") if (answer == "Yes") or (answer == "yes"): menu() break return login return False def register(): item = 0 file = open("G:\\Folder Redirection\\Desktop\\quiz\\login.txt","a") name = input("Please enter your name: ") year_group = input("Please enter your year group: ") age = input("Enter your age: ") password = input("Enter a password: ") new_username = name[:3] + str(age) #generate username print("Your new username is",new_username) print("Your password is",password) file = open("G:\\Folder Redirection\\Desktop\\quiz\\login.txt", "a") file.write(new_username+" "+password+"\n") file.close answer = input("Would you like to go to the menu?: ") if (answer == "Yes") or (answer == "yes"): menu() def menu(): option1 = input("Which topic would you like to do?\n1. Take a quiz\n2. Display a user's quiz history\n3. Print report of a quiz\n-1 Exit\n") if option1 == 1: quiz() elif option1 == 2: username = input("Enter the username of the persons quiz scores you would like to view.") #elif option1 == 3: # PRINT REPORT OF A QUIZ... # topic = int(input("Choose the topic\n1. Computer Science\n2. History\n3. Music\n")) #dif = int(input("Choose the difficulty\n1. Easy\n2. Medium\n3. Hard\n")) elif option1 == -1: quit() def quiz(): topic = int(input("Choose the topic\n1. Computer Science\n2. History\n3. Music\n")) dif = int(input("Choose the difficulty\n1. Easy\n2. Medium\n3. Hard\n" while status != "q": start() 
Personally (and I understand this is not a hugely popular opinion) I think that should return false. Falsey values and other automatic casts make life harder.
It seemed weird to me because I anticipated the output to be "False" if a value wasn't found, between False and 0 which would in my very limited experience seems to cover any instance in which None is used. Thanks for linking that!
This is great-- I'm curious if any blender projects/creations can create animations on the fly --- say like you play a song (could be a playlist) and the blender/python project could read the peaks/sound-wave data to change the color or size of the object. I guess I'm wondering if there's some easy way of make blender creations dynamic
You can do incremental time updates with [`.tick()`](https://github.com/spulec/freezegun#manual-ticks). Generics for actions like other time-delay results, HTTP requests specifically is something I was thinking about. Based on my reading of the README I don't think there's a lot of additional functionality on the time side (compared to `freezegun`), but being able to bind time movement with an HTTP request would be interesting, especially around timeout and error handling. 
&gt; Generators can be infinite. Both of those methods are generators. What I mean is that _some_ would be finite, and they (at least some of them) would be able to report their size. For example: * If `a` is a list, then `iter(a)` would be finite and could learn its size by querying `a`. * `permutations` is always finite, as far as I understand, and could calculate its size insofar as its underlying iterable can report its size. (/u/yawpitch [points out](https://www.reddit.com/r/Python/comments/797xte/shouldnt_there_be_a_type_of_sized_iterator_whose/dp027sv/), though, that you quickly hit he limit of how large numbers can be dealt with.) * If `islice` has a `stop` argument, it will be finite and could know its size. If it has no `stop` argument, the outcome would depend on what it can learn from its underlying iterable. &gt; The first scenario is handled with built in types that have a `__len__` method. An iterator over the prime factors of a number would also be finite, but its length would be unknown until you actually compute it. &gt; The second scenario can easily just be your default presumption and wouldn't need a special method. Agreed. &gt; The third scenario is impossible. You cannot measure the size of an infinite collection. What I mean in that case is that the object could report that "I am infinite; I will not terminate", analogously to how the prime factor iterator above would say "I am finite; I will terminate".
This should probably be in /r/LearnPython I'm afraid you have some rather fundamental misunderstandings of how code works. But don't feel bad. We all have to start somewhere! Is it Python3? I'm guessing you type `Yes` and it hangs? Look at this line here: while(start == "Yes") or (start =="yes"): That condition is going to be True forever and the block inside defines functions, but doesn't call anything--so it does nothing.
Here's a sneak peek of /r/learnpython using the [top posts](https://np.reddit.com/r/learnpython/top/?sort=top&amp;t=year) of the year! \#1: [90% Python in 90 minutes](https://np.reddit.com/r/learnpython/comments/661o5a/90_python_in_90_minutes/) \#2: [Python 101 Book FREE for 48 hours!](https://np.reddit.com/r/learnpython/comments/5bmaz0/python_101_book_free_for_48_hours/) \#3: [PSA: If you have a library card, you probably have access to Lynda.com, which has tons of Python courses](https://np.reddit.com/r/learnpython/comments/6rrsdu/psa_if_you_have_a_library_card_you_probably_have/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/6l7i0m/blacklist/)
So None is like a weird hybrid boolean/integer?
Didnt know that you could work with python in blender :O
&gt; plus **itertools.permutations** can take an iterator with no defined length as its first argument, but this would fail with an AttributeError, so there's lots of problems with this approach. What about if `permutations` provided a `__len__` iff the underlying had one? It doesn't solve the problem of large numbers, of course.
Because option1 is a string and you compare it with an integer.
&gt; Where would you need to know the length of an iterator without iterating over its elements? What made me think of it this time was the [secretary problem](https://en.wikipedia.org/wiki/Secretary_problem), where the number of secretary candidates you will iterate over depends on how many secretary candidates there are in total. Other cases, you might want all but the last element, or the first half of the elements, or so. Yet other times, you _will_ eventually iterate over all elements, but all of them won't fit in memory simultaneously, or they will take a long time to make, but you need the number immediately.
Why boolean/integer?
Because it seems like a Boolean but also seems to mean 0 too
Does it share any properties with those types? It doesn't support addition, negation, conjunction, etc.
I don't know I'm trying to figure out why it even exists when you have 0 and "" strings 
Uh huh.
It's useful to have a different type for error conditions. Some functions might want to return 0 or "" during normal execution.
how does the tkinter dependence work? that's pretty ingenious by it's def
gotcha thnx
&gt; &gt; answer = input("Would you like to go to the menu?: ") ^^^Thanks f801fe8957 
You'd need specialized iterators/generators though, like the subclass of **permutations** I gave before... you *could * make the argument for **iter** returning an object with __len__ if it's argument it received had one defined, but I'm not sure it's generally useful for the 99% case. Also a great many cases would be "I am not entirely sure if I terminate or not, nor do I have a good idea how to reliably calculate my length" ... permutations and combinations could benefit from this because the behavior is fixed, but you'd still run into the problem that the answer usually involves factorials, which get into ludicrously big numbers and overflows really quickly.
It exists for the same reason you have NULL as an option in databases or Option types in functional languages. `None` implies that there is no value at all, which is not the same as saying that the value is 0 or an empty string.
The more important problem **is** the large numbers, though... I mean anyone looking at doing a permutation can already calculate the length as described in the docs (which is all I used), assuming the iterable itself is bounded, but it still crosses the Int/Long boundary at &gt; 20 items, which isn't exactly long (no pun intended).
In this very moment, grading submission for a Data Mining module. I'm scripting a way of fast-checking the output files produced by the students, however, visual inspection is still required :( On a wider note, I'm planning a data generator package that can be use to obtain synthetic data. You can use said data to test learning models, mining algorithms, and whatnot.
I don't agree with you on this matter. Although they both to represent "falsey" state, they differ in what they represent, and thus what reader of you code can assume about it. False represent a result of boolean equation while None represent an absence of object (null pointer).
SQLAlchemy actually does something like this. If you have a mapped class M, `M.x == None` is a criterion object that can be passed to filter. It lets you write things like session.query(M)\ .filter(M.x ==None)\ .filter(M.y &gt; 5)\ .all() This will return a list of rows of the table `t` corresponding to `M` where `t.x is null` and `t.y &gt; 5`. 
&gt; you *could * make the argument for **iter** returning an object with __len__ if it's argument it received had one defined, but I'm not sure it's generally useful for the 99% case. Would there be any downside of doing it?
Can't you do something similar to this using iPython as your system shell? I've been wanting to look into using iPython as my primary shell.
One of the major changes we have from freezegun is patching over time.sleep. That way, the test is skipping sleeps even in modules with the timeout logic inside. The library is quite generic, but I do not quite understand what are you looking for. If your tested module is doing timed things based on HTTP request you can test it. You will just need to add future event for socket read event (to poll or select) and then all the timed stuff will happen. If you wanted a patch over a specific HTTP, you can open an issue or even contribute it :)
If you are running o linux try `man top` and th `top -p` option to monitor the usage for a single process. [More](https://unix.stackexchange.com/questions/554/how-to-monitor-cpu-memory-usage-of-a-single-process?rq=1)
The family tree shows more than one root. The tree definition and onwards might mention that a tree has one root. I liked it :-) 
No, it’s a ```None```. It’s the *only* ```None```, in fact - there’s only ever one - and it is an instance of the class ```NoneType```.
How is that complicated though?
So it's part of Python's object oriented stuff? I haven't touched object oriented programming yet.
I don’t follow your question. “None” is a positive quantitative value meaning that there isn’t any of an item. “Null” by comparison represents the absence of an item. Null then can be used when a value doesn’t exist with English linguistics. None indicates a value exists and it’s zero. Ultimately the language is what it is, but most English speakers would probably not use “none” to suggest that the quantitative value of a metric is absent/unknown. 
Tried xonsh before?
I mean, what specifically, do you not understand about the fact that Python can use `None` to represent unknown or error value? Can you explain this to a small child in literally one sentence, like above? If not, I can't help you. None may genuinely cause you cognitive problems. In that case, I don't know what to do. However, If you can, you know None isn't complex
Here is a list of threads in other subreddits about the same content: * [V3 - A python command-line project manager](https://www.reddit.com/r/bioinformatics/comments/79awmd/v3_a_python_commandline_project_manager/) on /r/bioinformatics with 1 karma (created at 2017-10-29 00:07:30 by /u/inacio-medeiros) ---- ^^I ^^am ^^a ^^bot ^^[FAQ](https://www.reddit.com/r/DuplicatesBot/wiki/index)-[Code](https://github.com/PokestarFan/DuplicateBot)-[Bugs](https://www.reddit.com/r/DuplicatesBot/comments/6ypgmx/bugs_and_problems/)-[Suggestions](https://www.reddit.com/r/DuplicatesBot/comments/6ypg85/suggestion_for_duplicatesbot/)-[Block](https://www.reddit.com/r/DuplicatesBot/wiki/index#wiki_block_bot_from_tagging_on_your_posts) ^^Now ^^you ^^can ^^remove ^^the ^^comment ^^by ^^replying ^^delete!
One sentence explanation: None means you have zero of a thing, so if you know you have none, you know you have a value of zero. Problem: Zero is not an absent value. Using “None” which means zero to mean another thing (an absent value) is confusing to people who lack familiarity with Pythons specific use of None. Confusion isn’t about intelligence. Even the most brilliant minds can be confused by unclear statements.
Ha!!
Well, not only "what's good for me is bad for you". You mistake algorithmic thinking (which is having some understanding of how computers see problems and how that's different from us) with premature optimisation. Actually, in many cases shaving those 90ms can come from "unalgorithmic thinking". For example, 99% of my work is Python. One of the first steps to "shave 90ms" is using C based internal function (e.g. **sum** function) instead of algorithm. Thus, I believe your argument is well meant, it's just that many people don't see division between algorithm and complicated code and most of the time the people to blame are programmers :)
It's only 'confusing' until you tell people 'None' can represent the lack of a value. Which is literally one line of simple English. I simply fail to see why it's such a deep or problematic issue.
Let’s assume there were 20 people on the plane. Let’s assume there were 0 penguins. The place crashes killing everyone on board. You ask how many people survived. The answer comes back: 0. You ask how many penguins survived. The answer comes back None. It’s important as if I said 0 penguins survived it implies there were penguins on board. It can me useful to differentiate between a valid reply (0) and a reply signifying that there is no answer (None). Python chooses to call that value None. It disambiguates from 0. &gt;&gt;&gt; x = print(“Hello”) &gt;&gt;&gt; print (x) &gt;&gt;&gt; None &gt;&gt;&gt; type(x) &gt;&gt;&gt; NoneType For example. 
Can't specifically think of any, but then the absence of downside isn't the same thing as presence of sufficient upside. In the simplest use case it wouldn't change much beyond the fundamental semantics of what **iter** returns and has always returned. By definition it returns a fresh **iterator**, which is not itself a container (like a list) but more of a view into that list at a given index, and optionally up to a given sentinel value... it's not really meant to return a container. And that optional second argument is significant; if, for instance, you do provide a sentinel, then is the length the `__len__` of the original container, or the length of the number of iterations required to reach the sentinel? Now you've got the problem of having to know *where* the sentinel is, or *if* it is, before you've found it. I'd search through the PEPs, and perhaps consider proposing your own, but I think you'll find pushback largely because 1) the idea doesn't generalize well without a *lot* of extra hasattr and isinstance checks, and 2) for the relatively small number of good cases there's already a simple enough workaround, which doesn't demand a new language feature and the extremely non-trivial work that would go into extending (and testing) the idea to all potentially length-known iterators and iterator-like objects in the standards lib.
Your question I think secretly means, do I need to know anything about OO to understand the None value. No, you don't.
Suppose you have a function that always returns a file handle (the result of open). What do you return if it fails? 
A non-exhaustive list of other popular marshalling/validation libraries includes (in no particular order) [cerberus](https://github.com/pyeve/cerberus), [colander](http://docs.pylonsproject.org/projects/colander/en/latest/), [schematics](https://github.com/schematics/schematics), [valideer](https://github.com/podio/valideer), [schema.py](https://github.com/keleshev/schema), [marshmallow](http://marshmallow.readthedocs.io/en/latest/), and [voluptuous](https://github.com/alecthomas/voluptuous), with marshmallow being by far the most popular and having the largest ecosystem. Many of them have a near-identical API to this project, and are much more mature and stable.
I don't think the Pi has a hardware boot timer, so you'll have to keep it running 24/7.
Really? I didn't know that. Thanks 
It's really starting to bug me how many people say "codes" instead of "programs" or "libraries" or "applications". We write code to create *things*, the things are what matter. Code is to a program what a sentence or a paragraph is to a book. You wouldn't ask a novelist how many sentences or paragraphs she's completed, you'd ask how many novels. You wouldn't ask a poet how many stanzas, or a painter how many strokes, or a structural engineer how many girders. Probably me just being pedantic and fighting a losing battle, but man I hate to see the slide into gibberish.
Right on!
For someone who is analyzing the language so thoroughly, it should be apparent that English is not the author's first language. Kind of a dick move to break someone's balls for not being 100% in compliance with common idioms when they aren't a native speaker.
I've seen a few hundred apparently native speakers doing it on Reddit as well in just the last few months, many of them current students and under 25. This idea of "codes" is becoming part of the language, along with "scrapping" instead of "scraping", and I'm bemoaning that fact. Also, way to blow things ludicrously out of proportion: I pointed out something that may not be obvious to someone who isn't a native English user, and which they nevertheless may want to correct to be better understood by native English users AND other non-native English users. If OP doesn't want to correct it, fine ... I'm not trying to force anyone to adhere to idiomatic English -- certainly not "100% compliance", whatever TF that would even mean -- I'm just complaining about a specific trend that appears to be picking up steam, and which also appeared in this post.
Why not just pass the current time into your function under test?
The pi doesn't use that much power anyway, and I'm not sure if the pi has an ability for the bios to be powered on by network.
I didn't see a comment that would be helpful to someone looking to master a language, I saw a diatribe. Perhaps I misinterpreted. Keep fighting the good fight.
I think `None` mainly comes from databases, but it's a really useful concept in general. In the context of a database you might have a boolean field, like what was a customers response to a question. `None` is neither `True` nor `False` - it means there was no answer. Maybe someone forgot to ask? It is applicable elsewhere - particularly easily in dynamically typed programming languages. A mathematical function might normally return a number, but it may also be undefined in certain cases. For example, you might want to find the largest root of some equation. The equation might have many roots, one root or `None`. Having a value to represent this case could be more useful than throwing an `Exception` - the result might need to be serialised to disk or onto a network.
I wasn't focused too much on the power aspect. More concerned about the ambient glow when trying to sleep. And I don't mean for the network to power the bios. I want the boot system to launch my pi program along with chrome. I can just set the homepage url to the address so upon launch it will work.
Mainly for methods checking the time themselves, or waiting for timeouts, or managing I/O operations.
&gt; Originally I would develop using Python 3, but where I've developed it, until recently, didn't have, and when It got it, "it was too late", so It is in Python 2. okay. thanks, but no thanks then...
If diatribes can't help people master a language, then Shakespeare, Swift, Twain and Sorkin all completely wasted their lives, as did anyone who tried to teach their work to others.
You'll probably want to do something with a motion detector like this project: https://helentronica.com/2016/01/11/magic-mirror-with-motion-detector/
I think I get this... So != None is an assignment, and since the None cannot change (logically), assignment isn't appropriate.
Thanks for the explanation, makes sense. I figured there was a place for it but at my level the only time I've encountered it is while practicing regex functions.
I didn't realize that was supposed to be Shakespearean. Have my upvote, then.
Look at commands to turn off the leds instead, then.
 $ time python -c 'import os,sys,re; print 2' 2 real 0m0.010s user 0m0.008s sys 0m0.000s Should be more than fast enough. Depends on your machine/env of course.
None is in Python what NULL is in SQL. 
Bank of America and JPMorgan Chase have a huge investment in Python. I did credit derivatives the but I'm sure they do fixed income as well. I write cryptocurrency trading bots in Python.
None means None. That is it. None certainly does not mean don't know. If you answer a question with None, your answer means None, nothing more, nothing less. 
If you want to check if `None` is falsy, use `not None`.
Out of curiosity, what are you running on?
Dell Inspiron Desktop (it's an SSD though).
Wow, that's really the best response you can give? This is getting pathetic.
I think pretty much all OSs have banned that option due to the spread of viruses via thumbdrives. I suppose you could make a program that constantly runs on the computer and checks for the thumbdrive every second or so. 
Depends what you mean by an inventory automation app, and which path you choose to take to achieve it.
Huh? I haven't even been reading your shit dude but it seems like I can say like two words and then you'll screech autistically for like 100 so by all means, keep going. You're really going to cut me deep this next time I promise.
I guess a udev rule could be used.
Are you unhappy with your current tools, why, and how could they be improved? There are a few books specifically on Python in finance, you might want to check them out.
Now try that on a virtual machine with disk image on a networked device :) I'll se if I can get the time to log in to work tomorrow and get the actual numbers there.
&gt;but it seems like I can say like two words And so you've resorted to monosyllabic grunts? What, exactly did you think the point of it was? I mean, if you're going to reply, you might at least *try* answering the question you've abjectly failed at for the last dozen posts.
I mean a system or database that automatically tracks all incoming and outgoing inventory and then emails the appropriate individual(s) when stock reaches a predetermined level. This one example. Including myself, there will be a total of 4 Python Developers working on the project full time and I am curious when setting the expectations, if saying we can build it in 30 days is to aggressive. Am sorry, what do you mean by "path" I will take? Still learning some stuff so it is a curiosity question. 
Uh huh.
They should be refactored to take time as a parameter, or a procedure that gets the current time
Let's put it this way: given sufficient time and learning, you could build Excel, VBA, Access, Bloomberg, and Haver with Python. You couldn't do the reverse.
It's confusing because people are inclined to think None == 0.
&gt; I suppose you could make a program that constantly runs on the computer and checks for the thumbdrive every second or so. There's no reason this wouldn't work but it makes me very uncomfortable.
Research python for data science.
I think most finance-related python uses pandas. It can read in dataframes from excel spreadsheets which might be useful for you. Numpy has some financial functions built in. If your current tools are slow to run or require a lot of manual data entry then it could be worth adding python. It's also probably a lot easier to interface with any data mining, plotting, websites etc since you could do it all in python.
Correct me if I'm wrong but the-fuck should do the same thing and is pretty lightweight. Just type fuck after you screw up and it fixes most stuff. Git included
No. `!=` in Python is not an assignment operator. It's the "is not equal" operator.
Yay, thanks! :)
Not sure what goes into muni portfolio analysis, but if its a modeling intensive job, then you'll love it. Learning curve is less steep, but not too bad once you get past the notion of thinking of analyses in terms of spreadsheet models, vs the more "do-this-then-this" orientation of Python. Have outsourced a lot of complex, tough-to-debug-and-test Excel models to Python, and built Excel model tests based on Python models. Using xlwings library, you can easily read in data from spreadsheets, and spit back out results. You can also call macros and pre-built VBA scripts with it. Long story short: its a delight once you get it, and will absolutely provide you with an advantage as you move forward with your career.
[mp4 link](https://g.redditmedia.com/wWEMFqkIFHb-NnqysHmmG-chVRtUn-jymtSxhVQX0sY.gif?fm=mp4&amp;mp4-fragmented=false&amp;s=ec53f1c09a187bcd847aedbd4109f965) --- This mp4 version is 95.75% smaller than the gif (463.59 KB vs 10.65 MB). --- *Beep, I'm a bot.* [FAQ](https://np.reddit.com/r/anti_gif_bot/wiki/index) | [author](https://np.reddit.com/message/compose?to=MrWasdennnoch) | [source](https://github.com/wasdennnoch/reddit-anti-gif-bot) | v1.1.2
[Source Code](https://github.com/pvcraven/arcade/blob/Version_1.2/examples/shape_list_demo_skylines.py)
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [pvcraven/arcade/.../**shape_list_demo_skylines.py** (Version_1.2 → cc35463)](https://github.com/pvcraven/arcade/blob/cc35463ce7e07061a3b099f30d22f4d6195b9f9f/examples/shape_list_demo_skylines.py) ---- ^(Shoot me a PM if you think I'm doing something wrong.)
Don't you? If you want to understand types in Python, you need to understand that they are themselves instances of objects. 
Tutorials are mostly good for streamlining the first 2-20 weeks. After that you need to just dive into reading code.
Last time I checked, you also couldn't `pip install python3`.
I wouldn't, just apply. You may get a work for attitude and if you can show that you are willing and capable to learn.
You still didn't solved waiting and I/O. To solve that you start to write more and more complicated mock-ups. Here you can just patch all of them without using exlpicit dependency injection.
Any plans on contributing pycharm's magic to python-language server? https://github.com/palantir/python-language-server
You should use an effects library for waiting or IO
I found this awesome alternative, https://github.com/ethereon/lycon
I like it! Do you have plans to add any flow control? For instance, based on the output of one of the jobs, decide to skip part of the pipeline, or run different jobs?
This reminds me of the roku sleep screen
Base64 was created for this case. The ASCII versions of keys are also base64 encoded
Definitely... It's in the works... I want to ensure that the API remains as simple as it is now. So introduction of features is contingent upon whether it can be introduced without complicating the API any further.
I see, so I use base64, which allows the byte string to be decoded with utf-8, and that is compatible with JSON. Then, on the other side, I take the json string, encode it with utf-8, and then decode it using base64, giving me my original byte string. Correct ?
base64 encoding is a process to convert an arbitrary byte string into a string that uses code points only within the printable ASCII range. base64 decoding is the reverse process. Once you have a string you can choose to encode it however you want for further transmission - whether you use UTF-8 or ASCII doesn't matter since they will produce the same result for any string that only uses code points within the ASCII range.
Excellent, Thank you!
Well, *everything* is part of Python’s object-oriented stuff, since it’s an object oriented language; all of the language constructs you’re already using - integers, strings, even functions and modules - are objects in the Python interpreter, and they have types. Python isn’t an *obligatory* OO language, though, so you’ll be able to do plenty in it without having to define your own classes. Writing classes is what people usually mean when they’re talking about object-oriented programming. But to explain ```None``` a little further, it’s simply the *nil* or *null* value; it’s the value for when there is no value. It’s the return value of functions that don’t explicitly return something else. It’s “logical-false”, like ```false``` and empty lists, dictionaries, or sets, and the number zero; but it isn’t *equal* to any of those, since it isn’t of the same type as those.
NP - please check my edits for further clarification.
I can do it in a one-liner: &gt;&gt;&gt; matrix= [[1,0,1,0], [0,0,0,1], [1,1,0,0], [0,0,0,0]] &gt;&gt;&gt; {(x,y):value for x, sublist in enumerate(matrix) for y,value in enumerate(sublist)} {(0, 1): 0, (1, 2): 0, (3, 2): 0, (0, 0): 1, (3, 3): 0, (3, 0): 0, (3, 1): 0, (2, 1): 1, (0, 2): 1, (2, 0): 1, (1, 3): 1, (2, 3): 0, (2, 2): 0, (1, 0): 0, (0, 3): 0, (1, 1): 0} But I think that's very sloppy and unpythonic. I think you should go for the long winded readable approach. --- If you have more questions like this it's better to post them on /r/learnpython. Be sure to [format your code for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) or use a site like pastebin. Also, include which version of python and what OS you are using. 
Do you know any good books on the subject?
Thanks, any suggestions on resources to read about it/learn it?
Yeah, I stopped reading when I hit that. If you're stuck in Python 2 right now, ok, I get it, but fucking own it and plan to upgrade. No "oh well, guess it's python 2 forever."
I'm sure there's info you can't share, but can you elaborate more on what Python does for you with the trading bots? I picture them scanning a large data set of technical indicators and executing trades when certain indicators breach specified thresholds, but tell me if I'm wrong....
Thanks, how does this compare to just doing all of this in Microsoft Office using VBA? That's my current approach for automating data collection/manipulation/presentation.
The stuff always happens if you write this. There's no reason, just write the stuff at the same indentation as the rest of the code.
Thank you very much! I will make sure to take future queries like this to /r/learnpython 
I use `if 1:` because I'm lazy.
Highlight the block of text and hit shift-tab
Shift+Tab, but you need a newline in the selection. To do it without the newline toggle **"shift_tab_unindent": false** to true in your settings. 
Excel and Access can probably be replaced by pandas and SQL (your choice of backend, SQLite is good to start). I'm sure most trading sites will have APIs you can pull data from, although they might be rate-limited. Being able to work with all of those tools from the same scripts will probably be very valuable. Python is a spectacular general-purpose and glue language for working with multiple tools.
Codewars.com
Not specifically as data science is not my forte but start w that google search and plenty of options will show up.
Good bot
Yea Bloomberg's a rate-limited API...a frustrating black box. I never know when I hit the limit until it's too late!
I many versions of Sublime Text that only works if a blank line is included. In that case you have to toggle the shift_tab_unindent parameter to "true" in the settings. 
We need more “Python gyms” to work out.
Thanks!
Good bot
Massive burmese python eating a rabbit
I think I saw this in a Spider Man cartoon when I was a kid :)
I don’t get it. 
Wrong Sub bro
Sorry to be 'that guy' but what is so special about this and how does it work. I seriously don't mean that in a douche way at all, I am just asking for some explanation for me (programming derp) so I can appreciate it a bit more.
First of all, /r/learnpython or even /r/learnprogramming. Second, really don't sweat too hard on your text editor. It's really not all that important. I personally use Sublime or VSCode but it's all preference. If you want some ideas on how to do some of your first programs, I would recommend [Automate the Boring Stuff](https://automatetheboringstuff.com/) for just giving you ideas on what you can do and also how to get there.
 matrix = [[1,0,1,0], [0,0,0,1], [1,1,0,0], [0,0,0,0]] result = {} for y, row in enumerate(matrix): for x, value in enumerate(row): result[(x,y)] = value print(result) 
Change the name for God's sake. It's ungoogleable as it is right now 
Use pandas to read csv? Multiply everything by 1e6? 
I'm not familiar with pandas, is it something similar to numpy?
Wow. I admit you've got me curious now. You seem to think my replying is due to one of your theories (I'm a pycharm user, no wait, a vim user, no wait, I'm really angry). Now, I enjoy a good argument, so I've been assuming your motive is something similar, but what can possibly motivate you to keep replying *even when you've nothing to say*? Are you so really desperate to get the last word that you humiliate yourself like that?
It builds on top of numpy. Use the `read_csv` function to get a dataframe right out of the csv file.
Well, let's see: 1. it's almost always several orders of magnitude faster 2. it can be run without opening Office, which is a huge resource hog 3. it doesn't require Office to even be on the machine that's running (unless you're directly automating Office itself, but usually you'd use it to manipulate data files Office can read and display) 4. it doesn't even require an Office license 5. you can build **much** more complex math into Python, especially once you discover Pandas and Numpy; VBA is actually extremely limited in math, text processing, etc 6. it's got tens of thousands of external libraries, for instance the two above plus Scrapy for web scraping, BeautifulSoup4 for parsing website HTML, as well as bindings to interact with many web services and libraries in their languages 7. it's quickly becoming the go-to language for doing Machine Learning and Natural Language Processing... imagine being able to automatically make investment inferences based on the tone of a companies news releases vs tweets by market leaders ... heck, imagine how useful it will be to able to ride the wave of Trump deciding at 4AM to lambaste the world media for calling the upcoming 40% drop in the S&amp;P 500 the "Trump Dump" as "FAKE NEWS! SAD!" 8. this is just personal experience, but I used to be considered a whiz kid on Excel and VBA ... I single handedly cleaned up a company's accounting, customer data, and asset management in Excel and Access, allowing the company to be sold for $25M... then I discovered Python. I haven't owned an Office license since, I only open Office when I'm forced to ... basically it's like being someone who's always used a bit of obsidian to clean fish and someone walks up, pats you paternally on the head, and hands you a filet knife. Or for that matter the keys to a fish canning factory. VBA isn't remotely in the same class as Python. My career and productivity shot forward twenty years when I found Python -- though I sure as hell didn't stay in financial work -- I'd never even consider going back, though after 10 years of Python I do consider going forward a lot.
Ok thanks, I'll give it a go.
Reminds me of GORILLA.BAS
Blender has animation nodes which let you do many motion graphics projects. https://youtu.be/nCghhlMOwRg Essentially what you're describing where any arbitrary input parameter can be used to modify the scene. 
How, exactly, did you install Python 3.6? If I read the docs correctly **pipenv** will use **pyenv** to manage Python installations *if* you've got **pyenv** installed ... my initial thought was to tell you to use **pyenv** to manage multiple Python versions anyway, but I've never used **pipenv** so wasn't (and am not) sure how well they work with each other. I can say that **pyenv** takes the pain out of multiple Python versions on the same machine.
I've become a bit dissatisfied with the available choices for cataloguing my MTG card collection. Not a fan of Deckbox's UI, other services either cost money or don't have features useful for deckbuilding, etc. So I decided to write my own and hook it into a WIP flask website that I've had sitting around for a couple months. My eventual goal is to learn how to develop android apps and make a card scanner app that ties into it. That's a "some day in the distant future" kind of project though. That's the only Python project I have in the works, since I've mostly been tinkering with linux shell scripts lately.
And what null or nil is in a whole bunch of other languages.
It’s really cool :)
That is a thing, search “audio equalizer blender” on Youtube.
i downloaded Python 3.6.3 from python . org and i run python3 setup.py than i copy the folder into usr/local/lib + usr/bin/
https://www.udemy.com/biopython/?couponCode=BIOPYTHON4HALF
The thing is, I'm not writing the code, just a tool to help test it. Dependency injection in my opinion makes the code cluttered and less readable - especially in Python. For me, mock.patch over imported modules is awesome way to test my modules while keeping the code clean. That is exactly what we are trying to create here.
Any good suggestions? Our ideas were mainly boring and no-fun ones :)
Thank you! Very helpful :)
It’s just a guy being proud of his work, nothing mor, nothing less.
Dude look at Python 3.6 in particular. Things have come a long way. It's actually rather pleasurable to use. 
Sure: Slippery time, Timeship, Morlock, Eloi, Titor, RipHunter, Back to the future, timeloop, groundhog day... Add python to any of those and you get an easy to find library. If you really want to get creative give it an odd spelling that is super easy to get to the top of Google like timelup. 
Yeah, that doesn't even put any of the executables on the $PATH. You really should either use [your package manager](http://docs.python-guide.org/en/latest/starting/install3/linux/#install3-linux) or better yet [pyenv](https://github.com/pyenv/pyenv) to install and manage Python versions.
If you are backtesting see: - https://github.com/mementum/backtrader. At the end of the README there is a list of many backtesting platforms. You can also look at some of the libraries open sourced by Quantopian for analysis rather than backtesting: pyfolio, empyrical - https://github.com/quantopian/empyrical - https://github.com/quantopian/pyfolio/tree/master/pyfolio
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [quantopian/pyfolio/.../**pyfolio** (master → 96b2bf3)](https://github.com/quantopian/pyfolio/tree/96b2bf321e824cdd7373243e0fc80c06020dbb55/pyfolio) ---- ^(Shoot me a PM if you think I'm doing something wrong.)
Regarding crypto bots, do you have any framework recommendations or are you going from ground up?
Memorization Game
Seems like a complete overkill to use selenium here. There's a backend api: https://unsplash.com/napi/search?query=python&amp;xp=&amp;per_page=20 The only thing you need here is Client-id cookie which you reverse engineer from javascript unsplash serves you :P Seems like it generated by code in https://unsplash.com/a/main.6e036.js 
Uh huh!
I didn't know about that. That's pretty cool. I will check it out! Unscrape is mostly s proof of concept, but it doesn't hurt to make it efficient.
It's just missing a couple of gorillas and some bananas.
I dont know of any frameworks, here are 2 FOSS bots that I wrote: * https://www.reddit.com/r/surgetraderbot/ * https://gitlab.com/metaperl/adsactly-gridtrader 
It would definitely be possible to do technical analysis. There are Python bindings to some C++ open source technical analysis libs. You could also use Pandas or other Python libs to do that. My two FOSS bots are here: * https://www.reddit.com/r/surgetraderbot/ * https://gitlab.com/metaperl/adsactly-gridtrader They are both rather simple: they consume a REST API and do some very simple homegrown technical trading. SurgeTraderBot is more actively maintained and in-use. I make 10% profit monthly on it. The top-level logic to decide what to buy [is here](https://gitlab.com/metaperl/surgetrader/blob/master/src/lib/buy.py#L272) 
Selenium works and it's can be a good addition for avoiding bot detection, Also it's undeniably a super fun tool to mess around with too. :) Personally I just have huge beef with it since 9/10 times it's completely unnecessary. Http scraping is much more efficient and friendlier to your target. 
Cool stuff, thanks for sharing! Seems like a really interesting medium to dig into - risky and so many mock test opportunities! 
My company is on 2.7/3.4+. My 200k line open source project is where I experiment. Python 3 only is not viable for me.
&gt;&gt;Are you so really desperate to get the last word that you're prepared to humiliate yourself like that? &gt; Uh huh Wow. That's kind of moved beyond pathetically funny to rather depressingly sad.
https://youtu.be/N4mEzFDjqtA Go to comments section, they have more topic specific info. 
See it as a tutorial to do something useful with Arcade. 
None is basically the same as the Option or Maybe types in other langs. Means something like "there is currently no valid or known value". eg, a variable declared, but not yet populated, and where you don't want some kind of default value like eg 0 or -1 for meaning "not yet calculated" or "could not be calculated" This is also formalized for Python type annotations, and also in MyPy with type annotations; A value that can be eg either None, or an integer, has a type signature like this: x: Option[int] = None Then the type checker will allow None or integers, but not other types like string. 
Cool. Thanks for the suggestions. I'll sleep on itand decide. Changing the name is a good idea
Go is really nice in the multithreading world and really convenient with the binaries, but. And there is a big as BUT. It is frustrating asf when trying to talk to external things such as databases or json. It may seem easy at first but gets really bad in the long run
I just uploaded my first program on github! It is made of two python scripts, one is making a database of all files from the current directory, the other returns the file and the size based on a string you specify. It'll be useful to me, maybe it'll be useful for others, here it is: https://github.com/AdrienLF/File-Database
that's an awesome idea!
I think u will find what u want here: https://www.reddit.com/r/learnpython/comments/1huuqk/im_doing_100_projects_in_python_to_learn_the/
Use a site like http://pep8online.com/ to check your code. The more you make that a habit and implement the changes it suggests, the less you have to check it. There is a pretty good, pretty well-known repo for design patterns in Python: https://github.com/faif/python-patterns If you were doing Ruby right, then the same principles apply as far as OO programming goes (Four pillars, SOLID principles...). Modular code is good, with a file for each class, although Python's `import` works differently from Ruby's `require` and `require_relative`. Ruby uses a lot of enumeration methods like `Array#each` and `Enumerable#map`, but Pythonistas tend to prefer list comprehensions and old school `for..in` loops. Testing is similar as well; if MiniTest did everything you need in Ruby, then unittest will suit you fine. If you need features from RSpec, maybe [pytest](https://docs.pytest.org/en/latest/) will fit the bill.
I love how even the stars are moving, although quite slowly.
That’s pretty cool. I wonder if that could be used as a live wallpaper on a PC?
Ermm, That's indeed a lot of cool project. Will check it out, thanks! :)
&gt; Use a site like http://pep8online.com/ to check your code I'm guessing all it does it `lint` check according to `PEP-8` specifications? we do something similar around here with `vim` :) There is a pretty good, pretty well-known repo for design patterns in Python: https://github.com/faif/python-patterns Looking good! Yes - things like SOLID, Composition over Inheritance, Law of Demeter etc are something we already use. What I'm missing the the language link to those. For example - you can use the `Delegation` design pattern in Python for sure. But in Ruby/Rails you have a specific method called `delegate` that does delegation easier for you (or the `Delegator` class in pure-ruby). Python seems to be more implicit and does not I guess include things like that - but still I would love to see stuff like that in action :) Actually I was looking for RSpec alternative and couldn't fine :-( Not specifically for the features like Mocks/Spy/Stubs etc (as Pytest as you mentioned already does that), but because we wanted to stick with the `Spec` structure per test rather then method name (Describe, it). Seems like `spec` framework are not popular in python, so we settling now on `pytest` until things like perhaps `Mamba + Expects/Sure` are more mature. 
You should check the software of the company and try figuring which modules you can use, and then learn how to use them.
(╯°□°）╯︵ ┻━┻ LIAR 
Gotcha. :P
Aha! Thank you, exactly what I was looking for! x3
Just update to testing (buster), it has py3.6 and you ll end up with something less crappy.
I'm a big fan of [Numba](http://numba.pydata.org). I haven't written any Cython since discovering Numba several years ago.
You should really show us an example of what the line looks like before you try to split it, because that will determine how you detect when that has happened. From the scant context given, it looks like it's omitting a value, so that you have something like 1,,2,3,4,5 If that's the case, check if the string is empty before trying to convert it to a number, and if so use the last value seen. 
What's the advantage of numba over something like cython?
"Numba gives you the power to speed up your applications with high performance functions written directly in Python. With a few annotations, array-oriented and math-heavy Python code can be just-in-time compiled to native machine instructions, similar in performance to C, C++ and Fortran, without having to switch languages or Python interpreters." It is a JIT compiler focused in numerical operations. I think Cython is more flexible. But Numba is still Python and Cython is more close to C.
Numba is a subset of Python. Once you learn a few tricks, it's a as simple as importing numba at the top of your module, decorating your function with `numba.jit`, and writing plain old, simple Python code that runs at the speed of C. Cython is not a subset of Python, and you have to learn special syntax. There is a separate compilation step and the potential difficulty of distributing your compiled module to different platforms. The documentation shows just how simple and clean numba code can be. The following will run at C speeds: @numba.jit def sum2d(arr): M, N = arr.shape result = 0.0 for i in range(M): for j in range(N): result += arr[i,j] return result
Apologies for the wrong reddit, i will stick to LearnPython in the future. You are correct. You have interpreted it right, however i do not know how to type the solution, I had figured it would be an if statement of sorts. If you could help me with this, how to write it, it would be much appreciated. 
Amazing. Thank you!
Thank you!
An empty string has zero length, so you could write: if len(some_string) == 0: ... A slightly more idiomatic way to do it is to use [truth value testing](https://docs.python.org/3/library/stdtypes.html#truth-value-testing). An empty string coerces to `False`, and every other string coerces to `True`, so you can do things like: if not some_string: ... 
&gt; frustrating asf when trying to talk to external things such as databases Could you please elaborate on this? If it matters, I'm using Redis and Postgres with SQL (no ORM)
Here is the code : https://drive.google.com/open?id=0B_Qvci1hzIcjeWFHdk1kRDlKMWM. Feel free to hack it !!! &lt;-_-&gt;
How do Numba and Numpy work together? Is it better to just focus on implementing Numba if you need to use lots of loops that can't be vectorized?
Reminds me of Web TV. 
&gt; It's really easy to dive in and "cythonize" your bottlenecks. I keep meaning to learn it. What are the best tutorials / hello world projects for cythonize? Most of the tutorials I've found are from a dry technical perspective. &gt; What other tools are there to improve python performance? Numba. Once setup it's pretty much magic.
Numba knows how to optimize a [subset of NumPy features](http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html). Perhaps the main use case of Numba is the optimization of code that that cannot be easily vectorized with NumPy.
If you find any security vulnerabilities please contact me
Yes. Look into Selenium.
Thank you!
The only issue that I've come across with Cython is setting up the compiler. I've tried Mingw32, using visual Studio 2015,visual Studio 2017, and so on, AND NOTHING SEEMS TO WORK WITH IT It's honestly quite frustrating! Come on Cython developers! Give us some better ways to install the compilers! 
1. /r/learnpython 2. This allows you or other people to `import` your program as a module without it running the `main()` code.
Thanks
`__name__` is automatically defined as "__main__" when your script is ran directly, rather than when it is imported.
Just find your hot loops/algorithmic parts and move them into a separate file and import them. Verify it still works, then compile it with cython. You should already be seeing some performance improvements. Then declare your types and compile again, and your code should fly.
Did you try [this stuff](https://github.com/cython/cython/wiki/InstallingOnWindows)? Compiling on windows is always a crapshoot. Cython works great out of the box for me on Linux.
What's the furthest you've driven?
sklearn and pandas are pretty solid libraries. Read their documentation
Good one! Furthest is about 520 miles from Seattle to Weed, CA. What about you?
520 miles ≈ 800 km ^metric ^units ^bot ^| [^feedback](https://redd.it/73edn2) ^| [^source](https://github.com/cannawen/metric_units_reddit_bot) ^| [^hacktoberfest](https://redd.it/73ef7e) ^| [^block](https://www.reddit.com/message/compose?to=metric_units&amp;subject=stop&amp;message=Please%20send%20this%20private%20message%20with%20the%20subject%20'stop'%20to%20block%20this%20bot) ^| [^refresh ^conversion](https://www.reddit.com/message/compose?to=metric_units&amp;subject=refresh%20t1_dp1wolb&amp;message=Please%20click%20'send'%20below%20and%20I%20will%20update%20my%20comment%20to%20convert%20any%20new%20or%20updated%20values%20in%20your%20comment.) ^| ^v0.11.12
Uh huh.
It's not on Cython really. It's Windows that sucks at this. You want the same compiler your cpython distribution uses. Here's a list: https://wiki.python.org/moin/WindowsCompilers You don't need the full visual studio, just the compilers, for 2.7 this is it: https://www.microsoft.com/en-us/download/details.aspx?id=44266 Use `setuptools.setup` instead of `distutils.setup`, that should find the correct compiler. If you are using C++ stuff (vectors, maps, ...) you want to specify `langauge='c++'` for your extension.
Will give that a try right away. I always tried to avoid numpy (found it scarier than C), but this is a good reason to try it.
Wow
Another stat that would be interesting would be how many of the stops are for out-of-state drivers - if they are significant, it might invalidate the "N% of the state is white". &gt; Black drivers are **500% more likely** to be searched than white drivers during a traffic stop, but are **13% less likely** to be caught with contraband in the event of a search. I don't think this is making the point the author is trying to make. All it's showing is that racial profiling *works* (even if humans aren't capable of applying it to mathematical perfection). Especially since this kind of dataset can't show *why* the search failed. How many of the searches were for people who had either prior or future arrests, and just happened to be not guilty *this* time? Since there are certain to be *some*, and the disparity of the *total* hit rate is so great, that probably erases the race gap. There's certainly *some* police racism, but these numbers aren't damning in general. A few outliers like that 25% are, though.
OBX in NC to Central IL.
Is there any way to return a dataframe-esque amount of data from Numba? I've been trying to apply it to financial stuff where its really one big for loop, and where each of the intermediary calculations needs to be output as well. For 10+ items as return values, it gets really unwieldy trying to return it as one big tuple of sorts.
Stats models is another good option - http://www.statsmodels.org/dev/index.html
I think lines of code for JS in inflated as in every web application people keep a local copy of Js libraries like Jquery instead of using CDN. Whereas in Python we use pip for package management. If GitHub could use their dependency graph to account for this and normalize the results I think JS might come a little bit down.
"Ruby didn’t choose this behaviour in a vacuum, it copied this behaviour from Perl, and Perl copied it from AWK. You can see these references to AWK in the Ruby source code and the Perl documentation." Ruby, Perl and AWK. I rest my case :-/
thank you!
One of the "gotchas" with numba is that simply decorating a function with `numba.jit` is not likely to result in any real speed-up. The problem is that your code probably includes something that `numba` cannot optimize to C-like speeds. By default, `numba.jit` will not complain, and will try to do its best -- but this means falling back to "object" mode, which is slow. To get the best performance, I typically use `@numba.jit(nopython=True)`, which will throw an error if your function has something in it that numba cannot optimize. Interpreting the raised exception can take a little practice, so I will typically start by writing a function from scratch, adding a line here or there until numba complains, and then rewriting that line in a simpler way that can be optimized.
Here is a good talk with some benchmarks comparing most of the things you've mentioned. Unfortunately, in russian. But you can skim through slides and recreated some results from github https://www.youtube.com/watch?v=bKW42bd98CE https://github.com/unaxfromsibiria/research-tmpfiles/tree/master/benchmarks
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [unaxfromsibiria/research-tmpfiles/.../**benchmarks** (master → c01c2dc)](https://github.com/unaxfromsibiria/research-tmpfiles/tree/c01c2dced69ef3e08709bb04e2300a1a8cd49802/benchmarks) ---- ^(Shoot me a PM if you think I'm doing something wrong.)
Implementing [flake8](https://pypi.python.org/pypi/flake8) into your continuous integration workflow points out PEP8 compliance without having to copy/paste your potentially proprietary code into an external website. I have found flake8 to put a team on the same style page as well.
Yep, you can return a named tuple. Just make sure to declare the named tuple type outside of your jitted function: import numba from collections import namedtuple MyData = namedtuple('MyData', 'foo bar baz') @numba.jit(nopython=True) def my_fast_function(): return MyData(1, 2, 3)
&gt;&gt; Black drivers are 500% more likely to be searched than white drivers during a traffic stop, but are 13% less likely to be caught with contraband in the event of a search. &gt; I don't think this is making the point the author is trying to make. All it's showing is that racial profiling works (even if humans aren't capable of applying it to mathematical perfection). Am I missing something? I don't think the article says that at all... They meant if the same amount of white people were searched, there would be more white people caught with contraband and that's why racial profiling doesn't work. Also, interestingly enough, this kind of explains your second point too. More black people caught with contraband through racial profiling, more likely for someone to have been guilty previously (Glossing over the fact that you're implying black people happen to be innocent and getting away with it just *this* time, and therefore erases the race gap.) I don't want to get into a political argument, but I think your interpretation of data is just wrong. Let me know if I missed something.
An advantage that other people haven't mentioned is that Numba provides more flexibility for fast higher order functions. For example suppose I have code that takes a distance function and makes use of the distance internally inside some tight loops. In Cython I would need the distance function to be something low level that Cython recognises or else I'm round-tripping up to Python for every call. That means, for example, that any user defined distance function is going to be horribly slow. In contrast because it JITs code in Numba any JITd distance function will operate very fast with no round-tripping to Python. That means as long as users apply Numba to their user defined distance functions it will be as fast as any pre-defined distance functions. This is a significant win.
What happens when I attach pdb to the running python process and read your variables from memory after it's decrypted?
This is very helpful stuff, thanks. 
Yeah, I´m using this module right now, it has been very helpful.
And find the hot parts with a profiler, don't guess
Is there a way to have mixed classes? Or do I have to completely separate numba code from python? Not sure if I'm doing it correctly but it seems like I can't have jitted just methods, and if I jit the class, I can't really use python in it (dictionaries for example, requires explicit typing)?
It might be easier to just implement it myself. :-)
i love googlle translation.
then i can learn knowlege about python with Chinese
When you define a variable as a function, you are defining the variable as the _return_ of that function. So in this case, the L you are defining in CodestoBin() is the return of Bin(). The issue is that Bin() doesn't have a return. Inside Bin() you are defining L, adding items to it, reversing it, printing it, then throwing it in the trash and returning None, which is L in CodestoBin() = None.
About binary sets by default - performance. They're used quite extensively in the compiler and stdlib, e.g. for parsing stuff (skip char if it's not in set of chars). It's easy-to-use and clean
&gt;About binary sets by default - performance. That's what they've been saying since Turbo Pascal. I've never known anyone to identify sets as their application's bottleneck in my life.
Try these: https://www.amazon.com/Python-Finance-Analyze-Financial-Data/dp/1491945281/ref=sr_1_1?ie=UTF8&amp;qid=1509304705&amp;sr=8-1&amp;keywords=python+for+finance https://www.amazon.com/Python-Quants-I-Pawel-Lachowicz-ebook/dp/B019002TSQ/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1509304781&amp;sr=1-1&amp;keywords=python+for+quants https://www.amazon.com/Python-Data-Analysis-Wrangling-IPython-ebook/dp/B075X4LT6K/ref=pd_sim_351_1?_encoding=UTF8&amp;psc=1&amp;refRID=6WFJY5W4YC0SY395C13X
Can you please explain?
Just like the error says: you need a file named praw.ini Reddit and therefore praw have undregone some changes since that bot was written, and now in order to use praw like that you need to provide your Reddit login information in a file named praw.ini. --- If you have more questions like this it's better to post them on /r/learnpython. Be sure to [format your code for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) or use a site like pastebin. Also, include which version of python and what OS you are using. 
&gt; They meant if the same percentage of white people were searched, there would be more white people caught with contraband and that's why racial profiling doesn't work. This assumes the same percentage of white people who were not pulled over are carrying contraband as those who were actually pulled over. We have no way of knowing if that is correct. The implication is also the same for black people. We just have a larger sample size to population ratio in that case.
&gt; (Glossing over the fact that you're implying black people happen to be innocent and getting away with it just this time, and therefore erases the race gap.) I most certainly am not saying that. I'm saying that, for the small percentage of people searched *regardless* of race, some of them are actually guilty ... but that percentage is unambiguously higher (because poverty, which is the *real* racism that need to be addressed) for blacks. 
After playing with it for a bit, I must emphasize this part: &gt; **array-oriented** and math-heavy Python code Depending on the use case it might be pain with no gain.
Are you definitely installing it with the correct python version? Opening the package, it would seem that it uses xgboost. Perhaps locate your install dir on disk and inspect it to check it matches up. 
In Go, all I/O is asynchronous; there is no async/sync dichotomy. You write your request handler just like you would write it in sync Python, and your process will keep handling other requests while the current request is blocked on a DB/API call. With Python, you have to opt into async and take care not to call anything that might do sync I/O. Once you've handled your I/O bottleneck, it's likely that your next bottleneck will be CPU, so you'll probably need to run a process manager like UWSGI for Python--this requires more memory (N python interpreters plus the UWSGI emperor) and inter-process communication, while Go's runtime automatically distributes the load to all CPU cores (one process, one copy of Go's runtime, etc). This means that deployment is quite a lot nicer for Go as well--with Python you need a UWSGI + UWSGI configs + a Python interpreter + library dependencies + your code; with Go you just need your compiled binary. Of course, there are lots of other factors to consider in choosing a language for a project, but I think Go's async story is strictly better than Python's.
In Numba JITd classes exist, but don't really work that well yet. That's one of its weak points. The goal, of course, is to use Numba for the hotspots in the code, with the presumption that those are math heavy and working with numpy arrays (which covers an awful lot of usecases). The goal is thus to simply have a standalone JITd function that takes arrays and numeric data and returns the same and then you can call out to that function from within your method.
Wow thanks! These look like a great start
When I'm experimenting with cythonizing stuff I actually find it useful to work in Jupyter since it has cython magic I can just do: %%cython cpdef cy_func(arg1, arg2): cython_code and Jupyter compiles it in the background and imports it into the current namespace, so it is immediately usable. This makes iterating on cythonizing parts of code much faster, especially when tweaking the addition of type information etc.
Very interesting, I especially appreciate the state by state visualization. I think it would be interesting to see if there are any states that are balanced, from this point of view
Cmd+[ works too. Tale the time to learn common commands for your text editor. It will make you more productive. 
I wasn't aware of flake8. All our programmer uses `vim` and have plug-in that already integrates pycodestyle, pylint, mypy and autopop8 and couple other lint checkers. With that, it's probably a good idea to use flake8 in our CI cycle as you mentioned, thanks!
Always a pleasure to listen to David's talks. While I wasn't particularly interested in watching a 45+ min video on async this Sunday ... I somehow always end up seeing his videos through to the end.
There's a list of outputs from previous builds on the Github site. Here's one that generated recently: textFile: shkspr poem template: a | 01010101 b | 01010101 a | 01010101 b | 01010101 Poem #1 Demand that demi- devil why Rebuke him that loves you so? I say i am a king, be thy Mistake the weigh. I am not, go. Poem #2 Advise you first, enjoin me thou? Revolt when gold becomes her aim! Were it not good your grace, but now You are in love, the more to blame.
I will have internet access, and your point for a website is a good one I had not thought of. What would be the easiest solution using a website?
It can be used for anything you can imagine that involves some sort of programmable task or visualization. It can even be used to compose music. Do you have any idea in mind? 
not sure if it's related, but i've had issues with macs and non tls/ssl setups, try changing the port to the 465
An idea might be applied musicology,so the union of music and science. That will be an interesting thing.
Whats the difference between the ports?
They are probably making a joke about the fact that the author does not write idiomatic/native English.
Oh ok i got it now, it works perfectly ! Ty :-)
Indeed it will. It's a quite complex and vast subject, but if we think about music as a kind of language maybe some progress can be done applying existing techniques. 
I just found this talk and found it interesting. For me using python scripts from other programs incurs a large delay for interpreter startup. Micropython basically fixes that at the cost of not supporting some features e.g. its regex is limited.
Thank you! ^_^
465 is secure outgoing port 
but it needs ssl not sure what any of this stuff is, what subject is this? I want to study up on it
You don't need to read the variables its decrypted anyway at that point just dump it if there anything you suggest please say
networking. if it needs ssl then it needs to be on port 465 instead of 25/587.
As I said: it's used quite extensively in parsing utils and some parts of the compiler, so it can improve performance a lot.
 no, on google i looked up the different ports, and it said that for using port 465 ssl is required... that mus be why it didnt work on my computer, is there something in the code i should change apart from the port number?
~~you already have starttls() in there so I don't think so, but the docs say: https://docs.python.org/2/library/smtplib.html &gt;SMTP.starttls([keyfile[, certfile]]) &gt;keyfile and certfile are also optional, and can contain a PEM formatted private key and certificate chain file for the SSL connection. so you might need to do that stuff but that's beyond me. to be honest, shit like this is why I hate apple. ~~ actually, since starttls() was already in there, try taking starttls() out and switch the port back to 587. I didn't realize you were connecting via gmail, which should take non-tls/ssl connections. if it's not that, then you might be blacklisted, find a blacklist checker on google and run your ip + send a message to multiple addresses and check the ip if it comes to one but not the other. your script should be fine, especially if you've already sent once, i'm just confused how it would send if the starttls() line was in there but on 587.
There I dont know. I'm not much of a web dev. I use django for some backend stuff, but that may be overkill for you.
here is what the error said: https://imgur.com/R7VrRql i tried to take the server.startttls() out, but it didn't work. not sure how the blacklisting works.
so the ips in that message are not blacklisted, but it's hitting barracuda's servers, i'm guessing tmobile routes thru them for spam protection. barracuda is an anti-spam company that runs a blacklist but also has a bunch of other anti-spam products. try sending a more detailed message, it's probably just triggering it as spam because sometimes spammers just send a message with the word "hey" and nothing else.
what do you define as detailed? I sent a "longer" message through and it still got blocked. it says 550 permanent failure, does that mean permanent permanent or something else?
Thank you for feedback, folks! I've been developing V3 for a quite time, so this "initial public release" is aimed to get some feedback for making it better. In fact, I'm not English native speaker, I'm brazillian, so errors in it are true likely to occur. About Python 3 support, now, more than ever, it's in plan, and if you have some insight in how to do it, and wanna share, I will be very glad.
It is possible to write native extensions in rust. You can use [rust to python bridge](https://github.com/PyO3/pyo3)
Most searches are for one thing: illegal drugs. And it's a known fact that the majority of illegal drug users in the US are white. The way we get from that to the state of affairs in our courts and jails and prisons (where the majority of convictions and majority of the population incarcerated for drug crimes are *not* white) is entirely through a system which polices and enforces differently on the basis of race.
i don't know, but test it with a non-tmobile account. there is all sorts of shit that barracuda could be doing, like possibly blocking you because it knows its a script.
If you (or your prof) means "lists" instead of "arrays" and if you fix the indentation and remove the random "==." on the first line then your code is correct. Here's how it should look: def is_reverse(a,b): if b==a[::-1]: return True else: return False Which you could shorten to this if you wanted def is_reverse(a,b): return b==a[::-1] --- If you have more questions like this it's better to post them on /r/learnpython. Be sure to [format your code for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) or use a site like pastebin. Also, include which version of python and what OS you are using. 
 a[::-1] What's going on here, please?
Some of these articles are about the language R, but the same also applies to Python: https://web.archive.org/web/20131128051700/http://answers.oreilly.com:80/topic/1029-when-to-use-excel-when-to-use-r/ http://code-love.com/2017/04/30/excel-sql-python/ http://fantasyfootballanalytics.net/2014/01/why-r-is-better-than-excel.html https://r-dir.com/blog/2013/11/r-vs-excel-for-data-analysis.html https://realpython.com/blog/python/working-with-large-excel-files-in-pandas/#.VZFOIDGAUAc.reddit http://pbpython.com/excel-pandas-comp.html There are also ways to use Python from within Excel, such as this one: https://www.infoworld.com/article/2687825/application-development/excel-gets-python-programming-power-thanks-to-xlwings-library.html https://www.quora.com/Data-Analysis/What-are-the-benefits-of-a-Pythons-pandas-over-Microsoft-Excel-for-data-analysis 
it may be that because i just sent it normally through gmail, and it passed.
Thank you!
It's over/ran out of supply :( 
your_list[start:stop:step] &gt;&gt;&gt; your_list = list(range(8)) &gt;&gt;&gt; your_list [0, 1, 2, 3, 4, 5, 6, 7] &gt;&gt;&gt; your_list[5] 5 &gt;&gt;&gt; your_list[1:4] [1, 2, 3] &gt;&gt;&gt; your_list[:3] [0, 1, 2] &gt;&gt;&gt; your_list[:] [0, 1, 2, 3, 4, 5, 6, 7] &gt;&gt;&gt; your_list[::3] [0, 3, 6] &gt;&gt;&gt; your_list[::-1] [7, 6, 5, 4, 3, 2, 1, 0] You're skipping by -1 each time. Play around with this a bit.
I get it, that's really cool. Thanks!
So now you're making a claim based on something completely *outside* the data. Whereas I was making only *interpretations* of the existing data.
Hey there. Check out the OMZ forums, but I'm pretty sure I recall people complaining that selenium was a no-go. I think the best people could cobble together was by using a webviewcontroller from the ui module. 
My first take is that more searches AND a lower success rate for blacks compared to whites cries out racism. I'm sitting here milking it over and I think that's wrong. If the blacks were searched twice and often and had half the success rate, effectively the guilty fraction of black people would be same as for whites. 400% more likely but only 20% lower success means that a larger fraction of black people that are pulled over are guilty at the end of the day than white people. Like... roughly 3x more likely to be guilty. As an officer, if a minority is 3x more likely to end up guilty it's not hard to see how a bias would develop to search them more often. 
Is that really a PSA? I thought this was common knowledge.
This is a side project I've been working on off and on since the summer. Thought some of the baseball fans of this subreddit might find it fun/useful! 
Indisn authors can converse is Hindi, Urdu, Bhogpuri and English 
Expected tomorrow: Python 3 pitfalls, don’t forget () when you print.
Pep8 is a pretty superficial way to think about Pythonic code, though. I recommend Raymond Hettinger's talks [Transforming Code Into Beautiful, Idiomatic Python](https://www.youtube.com/watch?v=OSGv2VnC0go&amp;list=PLRVdut2KPAguz3xcd22i_o_onnmDKj3MA&amp;index=3) and [Beyond PEP 8 -- Best practices for beautiful intelligible code](https://www.youtube.com/watch?v=wf-BqAjZb8M) which address python's idioms more directly.
Cython isn't "trendy" like most of the other options.
sorry man your late :(
That's it wrap it up folks we're done
You have a bunch of strings, not floats. You can't plot it without casting the data.
Very nice idea. I’ll take a look.
FREE COURSE IN RETURN FOR 5 STAR REVIEWS! 24 HR Halloween Special! https://www.udemy.com/swiftbirads/?couponCode=FREEBIRADS
Nice work!
You've got a small error in phrasing in section 4.1, under the final scatter plot for Wisconsin: &gt; Starting to look familiar? We can see here, yet again, that the standard of evidence for searching Black and Hispanic drivers is higher in virtually every county than for White drivers. That should read "that the standard of evidence for searching Black and Hispanic drivers is *lower*.
You implemented a stack, not a queue. `pop()` removes an element from the right. Add `import collections` and create a `collections.deque` then `popleft()` to get the element in front of the queue. The `append` method stays the same.
That's what happens when our inherent bias meets statistics. You -- and the officers -- are not accounting for the hit rate that *would exist* for the portion of white drivers **never searched** due to the standard of evidence required to initiate a search being higher. What this actually says is that people (of all races) are somewhat likely to be carrying contraband, and that when the probable cause standard is relaxed or removed, police have a high chance of finding that contraband. Well no shit, right? I mean if 100% of people were searched, 100% of the guilty would be discovered, right? Assuming the police were competent searchers. You're taking 1% of white people searched vs up to 25% of black people (in one outlying county in Wi) searched and drawing the inference that blacks are more likely to be guilty, when instead it's that guilty blacks are more likely to be revealed than guilty whites. It definitely shows institutional racism, **and** how cognitive biases function.
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Questions about code like this are better posted to /r/learnpython. However, one thing standing out to me is that you're writing: &gt; currentNode = queue[0] &gt; queue.pop() But queue.pop() removes the node from the **end** of the list, so here you're looking at one node, but removing a completely different one (except when there's just one item in the list). If you want the first item, replace these 2 lines with: currentNode = queue.pop(0) 
For people reading this and have no idea what the OP is talking about, AST is the Abstract Syntax Tree representation of compiled Python code. The reference docs are here: https://greentreesnakes.readthedocs.io I don't think there's any `ast` to XML converters (XML is very dated now, so even if there's tools for it people aren't going to go around using it). That said, it's probably simpler than you think to convert a Python AST to XML. You need to make a dictionary that has a keys for each AST node and the values of the dict are functions that generate the XML. Then you recursively build your horrible nest of diagonal brackets with your functional dictionary. 
Given history and, y'know, reality, it wouldn't just be interesting, it would be outright shocking.
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
This subreddit is for things related to the programming language Python, not for things related to snakes. Your comment has been removed, but if it's cute enough, you might try posting to /r/aww
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
It's amazing that this is your take on things. The search didn't *fail*, the search was initiated with a reduced standard of probable cause and succeeded in finding nothing because there was no guilt. The officer's belief that there was sufficient cause to search was **flat out wrong** ... this shows in as clear a way as possible that racial profiling **does not** work, but you're still presuming hypothetical guilt on the black people searched but found innocent. That's just amazing.
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
How in the name of any god is it unambiguously higher? In like all of those states the absolute numbers had white people committing more crimes. Also, man, what this really says is clear: if you want to smuggle *anything* successfully, make damned sure you hand it to an Asian who can drive reasonably well.
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
If you are new to programming in general, this might help - https://ilya-sher.org/2016/05/19/tips-for-beginning-systems-and-software-engineers/
That's why you can make assumptions about unknown variables and still draw useful conclusions. Assume *every* driver is hiding something: if police have a relaxed standard of evidence for non-whites, then non-whites are more likely to go to jail than whites, *regardless of actual guilt*. Assume *every* driver is innocent: if police have a relaxed standard of evidence, then non-whites are more likely to be stopped and searched than whites, again *regardless of actual guilt*. Note that all of these plots show that non-whites (except Asians, who seem to be assumed to be terrible drivers who need frequent ticketing) **are** more likely to be stopped and searched, **and** are more likely to go to jail, than whites. This supports either one of two propositions: non-whites and whites are roughly as likely to be guilty, but the police *are* racist in their searches, **or** non-whites are more likely to be guilty, and so police *should be* racist in their searches.
The proportion of a given population who are criminals is `search_rate * hit_rate`. That is quite clearly larger for blacks, because the 5x-higher factor dominates over the slightly-smaller factor. Seriously, arguing from a position of blatant ignorance is just making people think *all* claims of racism are bogus. (It's *possible*, as some claim, that many white people are simply *never* charged even if the cops know they are guilty ... but that proposition cannot be drawn from *this* data).
8 years experience of Python, Django development. skills: Python, Django, Django-rest-framework, PostgreSQL, MongoDB, RabbitMQ, Celery, JavaScript, jQuery, Ansible, Vagrant, Scrum. Location: Omsk, Russia Looking for a remote position of a Python Developer / Scrum Master
You're right about the problems of arguing from a position of ignorance, although the conclusion you draw is nevertheless *willfully* and *blatantly* ignorant, as well as racist. The proportion of a given population who are *discovered* to be criminals is `search_rate * hit_rate`. If `search_rate` goes up due to relaxed standards for evidence, then a higher proportion of actual criminals will be discovered to be criminals. If the `hit_rate` drops with an increasing number of searches (aka diminishing returns), then a higher proportion of innocent people will have been inconvenienced and wrongly and invasively searched. The racism inherent in your position is in inferring or assuming that relaxing the standards of evidence for whites *would not* result in a similar, linear increase in the number of white actual criminals discovered as such. The lack of statistical evidence for what would/might happen if you *stopped* using racial profiling **does not and cannot** constitute an argument *for* racial profiling.
Optimisation, generators, kwargs (and args). Learn about unpacking (hint, it's an asterisk symbol), loop manipulation and general algorithms
As a workaround until that situation improves you could consider using anaconda/miniconda. I don't work on Windows myself, but as I understand it most packages are available on all platforms, so Cythin should be packaged for Windows as well.
Cool man
Please don't mistake XML for being dated. For mixed content applications, XML still is the best data format. Only for stuff that could be handled in JSON, XML is out of fashion. Which this case would be, of course ;)
Nah, you see we want to use JSON and then bolt on all these validation toolkits to it. :D
An analogy I like is checking how much toilet paper is on the roll but there's no roll.
Thanks, that's interesting. I'll have to figure out how to manipulate ui.WebView objects!
/r/learnpython 
Generators are your friend def collatz(n): yield n if n == 1: return else: next_number = int(n/2 if n % 2 == 0 else n*3 + 1) # yield from collatz(next_number) # this syntax is only available in Python3 for i in collatz(next_number): yield i for n in range(1, 10): print(list(collatz(n))) # [1] # [2, 1] # [3, 10, 5, 16, 8, 4, 2, 1] # [4, 2, 1] # [5, 16, 8, 4, 2, 1] # [6, 3, 10, 5, 16, 8, 4, 2, 1] # [7, 22, 11, 34, 17, 52, 26, 13, 40, 20, 10, 5, 16, 8, 4, 2, 1] # [8, 4, 2, 1] # [9, 28, 14, 7, 22, 11, 34, 17, 52, 26, 13, 40, 20, 10, 5, 16, 8, 4, 2, 1]
You have a good point there i have released an update witch no longer creates the variables please could you recheck to see if its still vulnerable 
Might be better in r/learnpython
You never close the files you open. Method calls require parentheses in Python. It's a good idea to use `with`, to make sure files get closed even if there's an error. For example, for the last file you open: try: with open(sloc, "w+") as f: f.write(nc) except IOError: exitmsg("Unable to write to file") exitmsg("Your file has been created")
Lookin good my man. Now if only FIP was defined over TBF instead of IP....
What you like to help contribute via github?
Downvote with no explanation? Please help me understand.
You may enjoy the following papers from the recent INLG conference (International conference for Natural Language Generation): * [Survey on poetry generation](https://eventos.citius.usc.es/inlg2017/resources/final/25/25_Paper.pdf) * [Recent workshop on Computational Creativity in Natural Language Generation](http://www.ccnlg.org/index.php/programme/) 
Some things to consider: * The functions are undocumented. Try to provide docstrings which explain what each function does. * Some of these functions are really long! You may want to consider breaking them down into smaller parts. This also helps to clarify the process of how your code produces poems, and will make the code easier to modify. * Some of the built-in functions are overwritten by other variables, e.g. `all`. Try to avoid this. * The variable names are quite short and sometimes unclear (e.g. `all`, all *what*?). The python style guide encourages longer variable names in `snake_case` to make your code more readable. * Try to separate input/output (IO) from the rest of the process. Preferably using separate functions. * Related: Right now you are `open()`-ing files without closing them. You can use the `with`-statement to create a context where you can open and read/write file contents, and when you leave that context the file is automatically closed. This is much neater.
At the moment, I don't have the time to invest in projects that I'm not using myself or being paid to work on, so I'm going to have to decline.
It sounds like this belongs in /r/learnpython. Additionally, you might want to be a bit more clear about what you need when you post there, because as it stands, I have no idea what you're event talking about. Good luck!
This is so wrong, one shouldn't touch `sys.path` at all: simply structure your program as a proper [package](http://blog.habnab.it/blog/2013/07/21/python-packages-and-you/), then a relative import is just a matter of `from ..StringFunctions import reversestring`
Ok, thanks!
And don't touch `os.path`. from pathlib import Path It's all you'll ever need.
People have strong opinions about the tools they use (heh, i use vim, i know), the important part is to learn the tools you use enough to be efficient with them, and when seeing limitations, find out and accept if you have to learn another tool. There are lots of tools to learn in programming, and i would advise you to learn [git](https://git-scm.com/) before learning to use a new editor. Then yeah, finding little problems to solve, and try to solve a real world problem you have, or do a little game, there is nothing wrong with doing a pong or tetris for a start.
You could use a pandas DataFrame to keep your data and group by some of the features or aggregate with a custom function. Your question is very very vague though. 
How can I make it more specific? It seems clear to me what I want, to be able to categorize lists. What are the ways I can go about it?
Big leagues here I come !
Is there a difference with the `curry` decorator available in the `toolz` library? http://toolz.readthedocs.io/en/latest/curry.html
Ah okay then
Excellent! That's the kinda information I was looking for, thank you!
Nice one! Is there anything similar for NBA? Or if not, any plans to create something similar for NBA as well? :)
Haven't tested it but it looks nice and clean and I love the declarative name. `@statically.typed` hah!
There is one mention of "python" in the entire article and it comes down to: "python is installed" This is spam. 
Shameless plug, but if you like baseball, tech, and stats check out my summer side project: [DingerDB](https://www.reddit.com/r/Sabermetrics/comments/74c1z8/dingerdb_modern_baseball_database_and_analytics/). The link is to a post on r/Sabermetrics. If you want access to the site just send me a DM (we will hopefully be out of private beta soon). 
It's only clear to you though. Give an example of this list along with the expected grouping. 
Your first example isn't very compelling, because it uses map+lambda combination which is almost always best replaced with a list comprehension.
is there a reason that this: https://docs.python.org/3.0/library/2to3.html won;t get you 90% of the way to py3?
Any sort of generic machine-readable tree is good! (json, yaml, xml) they are all very easy to convert between one another. I think the fact that the distinction between children and attributes are hardcoded into xml can have benefits in some use cases. &gt; XML is very dated So the thing that pushes me towards XML rather than JSON is the recursive nature of AST, and the existence of tools like Xpath which feel like a nice succinct way to do complicated searches in tree structures. The existence of things like [json path](https://stackoverflow.com/questions/8481380/is-there-a-json-equivalent-of-xquery-xpath#8481439) is noted. `jq` and friends are very nice but I get the impression they all assume that you completely understand the tree structure. You can't do stuff like "find all nodes of type x with this type of child and this type of parent). I would happiy be wrong. &gt; won't go around using it This project has one user: me :) who happens to be fairly familiar with Xpath, lxml, json and jq. I don't know, I imagine if I share anything I do using xpath and friends is better than creating my own DSL. Writing python code just seems a bit... heavy weight. I'm not sure why. My first aims are to get a nice succcinct way of searching an AST for things in a programmatic way (I'm thinking xpath or similar) and maybe get some of generalish rewrite going. I might imagine something like astsearch '//def[args/@name=="blah"]' blah.py astmod '//def/args[@name=="blah"]' 'd.name="blahnew"' I've just found this: [astpath](https://github.com/hchasestevens/astpath) that seems like a similar approach (though without the intermediate json) 
I built my own [distributed web scraper](https://benbernardblog.com/the-tale-of-creating-a-distributed-web-crawler/) and I also used Selenium to crawl JavaScript-heavy stuff. The problem is that automating a regular web browser window with Selenium is very slow (when compared to running a standard HTTP request). So it would be a better idea to enable the Headless mode of your browser when you use Selenium. This would result in better performance.
I put my frickin finger on the screen over a star. And 20-30 seconds later the star was visible. Not sure what I can say.
Personally, I didn't know about [flit](https://flit.readthedocs.io/en/latest/). Will be worth a try!
No need to make a dictionary. What you do is subclass ast.NodeVisitor and define a self.visit_classname method for each node class, like ast.Num, ast.Str, ... you can also just define a generic_visit which will be called if you haven't defined a self.visit for that node type. There is documentation [here](https://docs.python.org/3/library/ast.html#ast.NodeVisitor). 
Good use of Python to illustrate the value of the language for quick analyses of important questions. Keep this one in your back pocket if people want examples in that vein. A data column of "reason for search" is necessary, I think, for getting more perspective on the problem. If non-whites, for whatever reason, consent to searches more, this could explain higher search rates with lower success for the other groups. Remember, the police in the US can't just search anyone because they want to, there's at least some set of rules in place for that. Either probable cause (which seems abuse-able) or consent to a search. Doing statistics like this on data that is generated by more complicated processes can lead people quickly to conclusions they favor when it may be that the data aren't complete enough to have certainty (although it can be used as motivation for more research, and should be).
Just wondering, does this *require* Python 3.6+? Because if not, you may want to consider choosing an option other than an f-string. It's a syntax error in Python 3.4 and 3.5.
This looks really cool!
Yeah, those methods would be useful if I was coding it myself. I'm never really sure if the visitor pattern is better than just writing a recursive function. Hmm... I think the dictionary was suggested so that you can then use some library to serialize to xml / json / similar rather than serializing oneself.
Because 3.6 introduced a syntax for variable annotations. [See here](https://docs.python.org/3/whatsnew/3.6.html#pep-526-syntax-for-variable-annotations)
As touched on in the article's comments, Selenium has the concept of waiting; it would be much better to do that than use `time.sleep`: https://selenium-python.readthedocs.io/waits.html
Is there a reason other then syntax preference for it being better?
That's a huge win in time. Especially for an evolutionary algorithm where you want tons of generations. Why didn't the quadcopter end up flying? Incorrect physics model of the vehicle itself that led to a poorly tuned PID? 
PyPy is so damned good. If your code can run in it, do it. 
pip install urllib3
Why cant we get these gains in cpython?
I was able to create a version of the code that *appears* to work correctly under Python 3.5. I've submitted a pull request. Let me know what you think. https://github.com/AlanCristhian/statically/pull/2
Thanks!. I will watch them later :)
&gt;80x faster You had my curiosity, but now you have my attention
All I'm saying is what can be drawn from the data, assuming it is valid. If you have problems with the data itself, attack *that*, not conclusions drawn therefrom. Personally, I have no difficulty believing (and don't think it is racist) that a population that is generally poorer (that is a well-known and well-agreed fact, right?) has more *actual* criminals, regardless of *any* potential double-standard (which has only been **postulated**, not proven - except in that 25% case). Maybe the way humans act on the data is not *mathematically* perfect ... but it's close enough that nobody should care when there are *unambiguous* problems (at least one order of magnitude) out there.
Call `taskkill` with `subprocess.call()`: https://technet.microsoft.com/en-us/library/cc725602(WS.10).aspx
It has to do with the compilers itself being pure python. It can optimize at run time and do things on the fly ([Just-In-Time](https://en.wikipedia.org/wiki/Just-in-time_compilation)) that apparently is very hard in cpython. At least that's how I understand it.
**Just-in-time compilation** In computing, just-in-time (JIT) compilation, also known as dynamic translation, is compilation done during execution of a program – at run time – rather than prior to execution. Most often this consists of translation to machine code, which is then executed directly, but can also refer to translation to another format. A system implementing a JIT compiler typically continuously analyses the code being executed and identifies parts of the code where the speedup gained from compilation would outweigh the overhead of compiling that code. JIT compilation is a combination of the two traditional approaches to translation to machine code – ahead-of-time compilation (AOT), and interpretation – and combines some advantages and drawbacks of both. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/Python/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
If you're playing with programmatically editing python code, you might want to have a look at Baron and RedBaron for inspiration: https://github.com/PyCQA/baron https://github.com/PyCQA/redbaron Baron solves a problem you might run into which is that AST does not retain syntax information (like comments and empty lines), while RedBaron makes Baron usable.
I like it! The world could use an easier to work with version of the Lahman db 
[nba_py](https://github.com/seemethere/nba_py) looks promising, haven't tried it out myself though. 
Okay, found the problem! As you said, Python 3.5 does not support variable annotations. Python 3.5 supports type hints in the parameters but not in the body of the code. This works under 3.6: @statically.typed def sum_powers(x: cython.int): n: cython.int return sum([ x ** n for n in range(1, x+1)]) But breaks in 3.5. Rewriting it as: @statically.typed def sum_powers(x: cython.int): return sum([ x ** n for n in range(1, x+1)]) Works, but provides just a 5% increase in speed over the Python equivalent. **But** if you "cheat" a bit and rewrite the function as: @statically.typed def sum_powers(x: cython.int, n: cython.int = 0): return sum([ x ** n for n in range(1, x+1)]) Suddenly you get all the benefits again! For this function I got more than 1,400% speed increase. I think the performance benefits are probably worth it in that case. I would just instruct people using the Python 3.5 version to only write functions that make use of variables within the params, or to define the variables in the parameters with default values.
That's a great cheat! I will work on that later.
But what I dont get is the why. Isnt pypy running off cpython? 
there is so much to know about lists but some basic understanding and how to use it in any programming language is just the same but we use python for our aid and the concept remains the same.
Nope, that's the whole thing. PyPy is a completely separate translation and compiler layer. It's a drop in replacement for cpython.
Nice... yeah that was something that was vaguely nawing at me. I'm really liking the idea / approach of [astpath](https://github.com/hchasestevens/astpath) which is just using AST. Do these approaches give me an AST with syntax information (this would be more easily slotted into astpath).
hi, I'm the author of the post. I tried various ways to train the quadcopter: I always got something which was good at reaching the target points which I used in the training, but was not general enough to perform well with arbitray target points. E.g., if I trained it to move from z=1 to z=5 it worked well, but then it was unable to do from z=101 to z=105. After a while I got bored and stopped development :) But I am interested in suggestions :)
no; pypy runs (slowly) on top of CPython only to run tests during the development phase. Then, we compile it using the rpython compiler, whose output is an executable which contains a JIT compiler.
yes,you are right,i have learn english about 10years ,but i cannot speak with appropriate sentences
*if I optimize myself my code
I've tried to, but got unsuccessful (got some problems). Anyway, I've seen that someone made a fork from project, and is working with that. Gus Dunn, thank you very much.
yes,you know python programming is very interesting,but i just passed the College English Test Band 4,i cannot understand these sentences with my linguistic competence.
Ok, if it _pseudo_-supported (cause it gives you partially crippled build/env), I take back the pigs. But butchery is pretty accurate, they took out something users expect (broke their python dist slightly), the know about it, and they do nothing about it: https://github.com/ContinuumIO/anaconda-issues/issues/952#issuecomment-237621950
It actually has nothing to do with it being in Python, the PyPy developers chose to write the JIT generator in Python because the syntax is nice. RPython is essentially a Python subset/DSL that generates a C JIT. PyPy is fast due to it being a highly optimized JIT, so it can execute in some cases (as shown in the blog post) single machine code instructions for a Python operation that would take quite a bit more instructions in CPython. It knows more information about the code it is running, and is thus able to optimize for it. So why can't we get this in CPython? Partially, the CPython interpreter is just a different beast. It doesn't JIT, it generates bytecode then evaluates that. While this is very simple, it can also be slow. Furthermore, reference counting (the memory management philosophy of CPython) is often slower than automatic memory management.
Dumb question: How does this work ? I was expecting to see that the decorator would add "cdef"s everywhere it saw a type annotation but it looks like it doesn't. So cython can compile these type annotations directly without needing cdef ?
I don't really understand much of this. What is a good starting point for getting a bit more background?
When your code plays nice with PyPy it's amazing. When your code doesn't play nice, it makes you sad. 
1: /r/learnpython 2: What have you written so far, and what problems are you having?
+1 `toolz` has become a staple in my go-to modules. Their [`itertoolz`](https://toolz.readthedocs.io/en/latest/api.html#itertoolz) submodule alone is worth its weight in gold. The code is super simple and straight forward too. Most of the functions are based on optimal implementations of combining stdlib functionality.
That's really odd. You'd think only the difference in locations would matter, not the absolute values. The thing about PID tuning is that you're not just looking for "reaches point" but also for a 'nice' dynamic response. What was your objective function/plant model for the copter? Good post, by the way. It's convinced me to give PyPy a shot.
for loop and while loop and why to use each one of these preferences.
But isnt it written in python? Whats running the underlying python code that makes up pypy?
I see, so youre compiling it down to a binary? IE I would need different versions of pypy for ARM versus X86?
Evolve your target points as you evolve your control algorithms. 
Yes, since 0.27 cython can compile these, but only in a file with the .pyx extension. Also cython can compile a string with the `cython.inline` function. I just get the function source code with `inspect.getsourcelines()`, make some fashions to the source, pass them to `cython.inline()` function and return the compiled object.
Thanks a lot for answering. One more q then. I have a ton of numpy arrays which need to be initialized (np.zeros) before running a lot of the loops. How would I do this concisely? I've generally used a class for it and just initialized it with the init -- is there a simple way to do that concisely?
If we included more whites to be searched and the searches all fail, then the success rate for whites would fall and perhaps be about equal for blacks and whites. It's useless to frisk everyone, since the vast majority of people are not breaking the law on the road. I think there is solid evidence for the dataset being discussed that a significantly larger fraction of blacks pulled over are in fact guilt compared to whites. I think your example/limiting case is invalid. If everyone was driving illegally, presumably wayyy higher fractions of whites would be pulled over (like idk 50% but much higher than 1%) and we're really gonna need to see an entirely new dataset. Because the main difference in the data and in your example is that for drivers pulled over, blacks are statistically more likely to be guilty but in your example everyone has the same likelihood of being guilty.
&gt; So, let's unroll the loop manually &gt; "The Joy of PyPy JIT: abstractions for free" Now that's a true believer!
yes. Actually, if you go to http://pypy.org/download.html you see that there are prebuilt binaries for a bunch of different architectures.
Pypy has a subset of Python called Rpython at its core. Rpython is written in C but is separate from C-Python. 
Yes, there is definitely code which doesn't play well with PyPy; for example, we are well aware that all C extensions (using the infamous cpyext compatibility layer) are horribly slow, and are actively working on that. On the other hand, in PyPy, we usually consider being slow as a bug; if you have a benchmark in which you are slower than CPython, please consider to trim it down to a reasonable size and open an issue. 
yes, that's also what I thought: I expected that eventually the matrix would contain the "right" values to implement a PID control, with reasonable constants. However, I what happened is that they contained "random" numbers which indeed worked like a PID, but only on those values. It's entirely possible that I did something wrong, of course
interesting suggestions. How? Should I just slightly modify them at each generation? Should I generate new random ones?
Couldn't say for performance, but Python community is not really "functional" (although functional programming is possible), and list comprehension is often considered more readable.
Uhh... the 'toolz' version is better? Haha. I'll add that to the readme. Obviously didn't do my research!
It's Python all the way down.
That's totally fair. To be honest, I'm not convinced that this is particularly useful but it was interesting to figure out 
Because if your code can use PyPy there's not much reason to use CPython, and if it can't then it's for one of the reasons why these gains can't be applied to CPython, such as C extensions. And mixing the two is a potential nightmare (but you can run two python interpreters in one process, so maybe, but better not).
Pypy is gold.
Oh good, you're one of *those* kind of deplorable. Ok, I'll bite: we cannot make *any* inference not supported directly by the data. And we'll assume that you're right, and the actual criminal population is always exactly search_rate * hit_rate -- because apparently we're just that dumb. Socioeconomic factors are right out of consideration, not in the data set. Also we can't make any inferences about out of state visitors, also not in the data set. And we'll assume no duplicate stops or searches, because we also don't have any data to infer that. So what do we end up with? Well, let's take Wisconsin: blacks have a 0.048528 * 0.477574 or ~2.318% rate of criminality, while whites are 0.012459 * 0.526300 or ~ 0.656% rate of criminality. Blacks are 4 times more likely to be stopped, and are less likely to be guilty, but a higher percentage of the population is guilty and just happen to have been found out as such because of racial profiling. Cause, apparently, your argument is that these master criminals would not have been discovered unless the police justly lowered the bar for what constitutes probable cause. Ok, so blacks are 3.53 times more likely to be criminals than whites. Now, what else do we know from the data? Whites were stopped 778227 times, so at 0.656% we expect that there are, precisely, 5105 white criminals in Wisconsin... slightly off from the actual hit number of 5103, but hey, floats, so we'll just accept the hit number reported. Blacks were stopped 56050 times, and at 2.318% that gives us 1299 black criminals in Wisconsin, which jives with the actual hits reported. So, by the numbers and your logic, an individual black is 3.53 times more likely to be a criminal, and therefore all blacks should be searched 4 times more often, so that we can ensure that a group that makes up 18.63% of Wisconsin's criminal population isn't underreported. Whites meanwhile are not unambiguously more criminal, even though they constitute 73.19% of the criminal population. So, extrapolating, your argument then is that racial profiling -- the reduction of criteria constituting probable cause for people based on their color -- benefits the population as a whole by not allowing the 368 black criminals (5.28% of all Wisconsin criminalia) who *would not have been caught without it* to slip through the righteously clean hands of justice?
Very nice!
I wonder how would it compare with C / Cython implementation, both in speed and in the amount of the reimplementation work. 
CPython reads in your code once and generates bytecode, which it then can execute. It is very conservative about the bytecode it generates and not doing a lot of assumptions. You can inspect the bytecode of a function you wrote with the [dis](https://docs.python.org/3/library/dis.html) module. Honestly there is a lot to chew through with this topic, but I think this [stackoverflow](https://softwareengineering.stackexchange.com/questions/246094/understanding-the-differences-traditional-interpreter-jit-compiler-jit-interp) answer does a good job to get you familiar with the concepts. Regarding his optimization via loop unrolling: 1. Check loop condition 2. Run loop body 3. Jump to loop condition and reevaluate 4.a Condition is true and you go to 2. 4.b Condition is not true and you skip loop body by jumping forward You can see that a loop has some overhead to it. If you know the number of times a loop has to execute in advance, you could copy-paste the body n-times and would get rid of the jumps and condition checks each loop. This is generally not advisable to do. The author uses his knowledge of the problem knowing that he doesn't necessarily need the loop. He already is aware that the data structure he is dealing with is of fixed size and shape. Here he is creating the plain list with his data: self.data = list(self.matrix.ravel()) + list(self.constant) Here he is directly accessing the data since the data is consistent across every call: k0, k1, k2, q0, q1, q2, c0, c1 = self.data Finally he simply directly computes the desired values directly: out0 = s0*k0 + z_sp*k1 + z*k2 + c0 out1 = s0*q0 + z_sp*q1 + z*q2 + c1 Loop unrolling is more common with lower level languages than Python or in embedded software aiming low power devices. 
Did you think of sans-io http library? I hope this is the future of implementation of protocols. But in price of more complex code…
Numba has limited support for creating classes using the [@numba.jitclass](http://numba.pydata.org/numba-doc/dev/user/jitclass.html) decorator. Alternatively, you can just initialize a namedtuple before sending it into your numba function by doing something like: MyData = namedtuple('MyData', ['foo', 'bar', 'baz']) def my_data_zeros(): data = [np.zeros(42) for field in MyData._fields] return MyData(*data) @numba.jit(nopython=True) def test(data): return data.foo
I managed to get it by analysing a code with the same intention, but for counting even numbers. I made a cycle like this: time = int(input("Enter time in minutes: ")) likes = (0) while time &gt; 0: if not time % 2 == 0: likes = likes + time else: likes = likes time -= 1 print (likes) It was pretty simple, but I couldn't get it because I had forgotten how to count even numbers in a cycle. Thanks anyway!
Yeah, you, and that whole lunatic word salad, are just not worthy of responding to. You are, however, worthy of my contempt.
I was happy with the speed up I got with PyPy until I ended up screwing up some files beyond repair. First of all, I sincerely accept responsibility but I think this demonstrates some of the gotchas of using PyPy. In my case, I was, on my mac, relying on the `os.stat.st_birthtime` attribute. I tested on CPython that it works on a mac (HFS+ filesystem). I (falsely) assumed that it could be trusted in PyPy. Turns out `st_birthtime` is one of those things that are not guaranteed to be there. Again, it was my fault for falsely assuming (and not verifying) the results between implementations, but it does also show some potential issues.
Thanks for this. Overall, I understood the general concept. I guess I'm completely unfamiliar with CPython, PyPy, the various implementations of numpy arrays, and such. I guess it's just a matter of looking into making programs more efficient?
Oh yes I am aware of the C problem. I don't fault you for it, I can't imagine that being an easy problem to fix. In my case I used on a pure python code and it was slowing down quite a bit. Most of the time when I use PyPy it works great though. I was just mostly saying how I was getting tired of downvotes for pointing out there's still some wrinkles that have to be ironed out.
IMO this release shows that Pandas is maturing and stabilizing, as there are a lot of really nice improvements, but IMO no really big leaps forward (except perhaps the new CategoricalDtype, that makes some common issues much more straightforward to do). Stabilizing is probably to be expected for such a large project, so that's a good thing.
check out my article with python code: [Web Scrape YouTube channel for video info and a table of contents using Python 3.6 and Beautiful Soup](https://teklern.blogspot.com/2017/10/web-scrape-youtube-channel-for-video.html)
looks like it is cheating. It compares numpypy to plain python and not numpy and numpypy.
All of your responses in this thread seem rude/mean and sometimes not that valuable to the arguments you're replying to. Your first comment was useful. Try to make comments that matter
All of your responses in this thread seem rude/mean and sometimes not that valuable to the arguments you're replying to. Your first comment was useful. Try to make comments that matter
Sure. After you stop actively supporting racism.
But do we really has to mock them?. Why can't we just feed them with worthy suggestions? 
Again, not *all* blacks. And not exact counts, but accurate *proportions*. Nowhere do I claim that, so STOP PUTTING WORDS IN MY MOUTH. Just the ones that the police officer thinks he has reason to search. Because in most states, he's still right most of the time. And the rest should increase their standard of evidence (but they prove that whites are *not* getting special treatment, or we would see the much-higher hit rates since all the ones getting "skipped" in the high-hit-rate states would get caught there) Oh, and for the record? I'm hardcore liberal (both socially and economically), I just make a point of fighting those who **directly harm our cause** by throwing out words like "deplorable" and relying on completely bogus reasoning. It's people like you that got Trump elected.
I'll just leave [this](https://www.youtube.com/watch?v=e08kOj2kISU) here.
That is a very interesting read.
My code immediate was over 80,000 times faster! Also I switched from bogosort to bubblesort. Maybe I could optimize my code even more. 
Thank you! I'd consider moving the definition of the `VM` class somewhere else, that should look better. Right now this is more of a proof-of-concept, so there's certainly a lot of stuff to improve.
Is it advisable for a python newcomer to just learn PyPy? Not asking for me, I'm too deep in CPython already. But curious what state this implementation is in, market-penetration-wise.
Just to be clear, categorical dtype isn’t new. Only the user api is new. It’s possible that you meant to say that but it wasn’t clear to me. 
Lovely. What you did will work, but another technique to add to you tool belt: `non_friends = set(friends) - set(followers)` Keep in mind, set reduces the lists into unique elements. Since the IDs with which you’re working are unique, you shouldn’t encounter any problems, but it’s good to keep that in mind.
Honestly, this field doesn't care much for certifications. At least not for development. The bottom line is, you need to be as skilled as someone who went to a 4 year college. Otherwise how can you compete with them? Learn on your own, keep your day job, and once you have a few projects that you can talk about to employers (since that and talking/testing you is the only way they can verify you can even code since you don't have the fancy piece of paper), start applying to jobs near you. That being said, software development is no necessarily dominated by introverts. Don't go in expecting you'll be able to work heads down and at your leisure. I probably spent more time talking and planning and networking in my first development role than actually writing code.
There is no "our" cause between someone who believes those numbers support racial profiling and me. And, for the record, you can't be a liberal of any sort and condone racial profiling. The numbers prove one thing -- that whole bit about the picture being worth a thousand words? -- the police officers across all these states **are** using a lower standard of probable cause for people who are not white. That doesn't require whites getting special treatment, it requires them NOT getting special treatment (you might recognize it as "extreme vetting"). Systemic racism doesn't *just* mean extra good being heaped upon the majority, it can also be extra bad being heaped upon the minority, and this data proves that racial profiling is the de facto standard even though it's fundamentally illegal and a blatantly unconstitutional civil rights violation for police to use racial profiling. Here, I'll make it easy for you; a just society is one in which **EVERYONE** gets the same benefit of the doubt from the police, regardless of their relative production of melanin. I'm not just throwing out the word deplorable, I'm identifying a viewpoint that is utterly deplorable, and you have been repeatedly siding with that viewpoint.
Thanks for the suggestion. Always good to learn something new. :)
I'm still a student studying controls so I might be off on a few things. Wouldn't the PID be taking in the error of the loop and outputting the necessary response? The actual position values wouldn't matter then.
&gt;I'm still a student studying controls so I might be off on a few things. No, you're TunaLobster.
Bad bot.
This doesn't really answer the question more than "C extensions" (which isn't really accurate) and doesn't answer why C extensions are seen as slowing things down. CPython uses a simpler, slower execution method (somewhat intentionally), which is the main cause of it being slower. PyPy's JIT can optimize code much better by knowing more about it (types, function call targets, etc). This allows PyPy to optimize what is executed. C extensions don't really have much to do with CPython being slower. In fact, C extensions can make your code much faster, just not with PyPy (though as is mentioned in the blog post, this is improving). The main issue with C extensions that people using PyPy have, is that to use them via CPyExt, the PyPy interpreter needs to follow reference counting semantics, which are an integral part of CPython's C api. However, improvements are being made even here.
RPython is Python, but the compiler emits C, RPython is just a restricted subset of Python, it is not actually written in C, as I understand it.
There's almost nothing to learn: it's just another interpreter. You install it, then instead of building your virtualenv with whatever cpython you've got, you build it with pypy. And if you've got tox, you can even run your tests against multiple interpreters in a single go. It's not perfect, doesn't always offer improvements, but if you've got performance challenges it's definitely worth considering.
CPython is the reference implementation; the idea is that it's supposed to be an example of how to write a Python interpreter, not really the interpreter you actually use in production. Unfortunately that's not how it's worked out in practice. I'm surprised people don't talk about Nuitka more, although I've never gotten it to work on actual productionc ode either...
I'm interested in discussing what the data shows
&gt;I'm interested in discussing what the data shows No, you're Laserdude10642.
Good bot
I don't believe Baron is capable of producing usable AST for astpath, but i feel like a FST to AST conversion thing can be created given enough dedication. If this is a rabbit hole you're willing to go into, let me know what you find, i'm interested
r/yawpitch is leveling up his troll skills. Tons of exp ITT
It makes me sad that optimizing code in a "slow" language usually means vectorizing, while optimizing in a "fast" language usually means un-vectorizing (loop unrolling, looping, etc). In reality, math problems are often best expressed as vectors and matrices, while programmy problems are often best expressed as loops. I wish the choice of programming language wouldn't suggest a choice in coding style. (Julia addresses this, I believe. Note to self: compare Julia, Numpy, Pypy for a real world project) 
Thanks for sharing. Go has been on my radar as a Python replacement but it seems it is not. I hate Null but working with databases you need it. 
Wouldn't the problem disappear if you did the moving relative to the copter's coordinates? I.e. keep the copter at origin and translate target point from world coordinates to copter coordinates.
That's happen every time for me : python ecosystem is vast and you cannot known every library... but that's a good and impressive project to (re)-implement that kind of functionality :)
I'm downvoting for promotion of willful usage of archaic python version.
Go's syntax is much more complicated than how it is advertised, that is true. But you'll get used to it, coming from python it feels too complex, coming from C or other similar languages it feels simple. Go does have slices that are kind of like Java's Arraylists, they can grow until an X size and will be resized. Of course, nothing so simple like python lists. 
The data shows, unequivocally, that the police are using a lower standard for probable cause for black and latino people at traffic stops, as demonstrated by a proportionally higher likelihood of being converted to a search that is not also proportionately more likely to result in a hit. I can try and walk you through the logic again, but you appear impervious. Assume that A% of people of all races are carrying contraband (in other words, do not start with a racist perspective), and IF the standard for probable cause used for whites reveals B%, where B&lt;A -- because some portion of A will either not be searched at all, or the search will not reveal the contraband -- then the same standard applied to blacks and latinos would also reveal B%. Lower the standard for probable cause solely for blacks and latinos, and you should get C1%, where B&lt;C1&lt;A. This is just logic; increase the number of searches and police should naturally tend to find closer to the true percent (A), as they will at least have more opportunity to search the portion of A that was never searched above, and will also have less failed searches overall. But what do the actual numbers show? C2, where C2 &lt; B &lt; C1 &lt; A. An increased opportunity to reveal the true A percentage followed by a reduced outcome C2 necessarily means that the police are a) using a reduced standard of probable cause based on racial profiling (an unconstitutional if not always criminal act), and b) they're searching a larger percentage of !A, aka the innocent population, causing harm without value to society. Now, you might disagree, and want to adjust A by race, because blacks are more likely to commit crime. **AND THERE IS YOUR RACIST IN THE MIRROR!!** ... and also, begging the question.
&gt; Go arrays don't expand themselves. You'll have to guess how big of an array you're gonna need, and if you run out of space then tough luck. To be fair, Go isn't the only language to do this. C does it, Java does it, C# does it... You initialize an array with a size and if you need more room you're shit out of luck. Java and C# provide ArrayList classes that are resizable and take in generics. But the Go community are really clinging to the "no generics" thing. But I totally agree on every other point. For me, the dealbreaker with Go is how utterly toxic the community is. Among the languages I work in, the Python community is just lovely, so was the Ruby community. Java and C# types are a little sterile and boring, but harmless. There are far too many egos flying around in JavaScript, but it can be tolerated. The Go community is just unforgivably vile. It's like every bad stereotype in this industry, all circling around one fairly useless language, sweating and beard-stroking and patronising newbies. Fuck Go.
Dude chill we're all on the same team The data does show that blacks are searched far more frequently, and this does support the idea that there is a lower standard of evidence to warrant a search of a black person over a white person. That is racism. Yes. Congratulations. Now get over the racism part. Seriously man racism is common in america. Sucks but that's the setting for this data. While arguing and finding an answer is outside the scope of this thread, the real hard question I think is this: If a subset of a population has a significantly larger criminal rate, should the search rate be increased proportionally (I.e. Should the standard of evidence be proportionally lowered) or not? This dataset suggests the local law enforcement agencies would say yes to my question. Idk why you are obsessed with judging who is/isn't racist. 
Dear moderator, I didn't ask to anyone to help me in something,I was just doing a debate. If I did something wrong,then I apologize,it wasn't my intention. Thanks for your time and have a good day.
Heads up, the config file is about to change from a .ini file to a .toml file (which looks similar, but with a bit more punctuation and less ambiguity). It will still work with the .ini files for quite a while after the change, so don't be put off trying it.
I've had better luck getting Nuitka to work on production code, though PyPy usually makes a bigger impact. That being said, Nuitka is great for distributing binaries; IME it's better than just e.g. PyInstaller, since you can also get (minor) speedups.
Regula-ass recursion works fine as well def collatz(n, previous=None): if previous is None: previous = [] if n == 1: return previous + [n] next_number = int(n/2 if n % 2 == 0 else n*3 + 1) return collatz(next_number, previous+[n])
1. Racism being common in America isn't a reason to "get over" or ignore the effects of racism. Am I supposed to "get over" gun violence, opioids, overpriced-and-simultaneously-usless health insurance, or child rape? I mean all are common in America, right? 2. That isn't even a slightly hard question: **NO**. It does not serve society's long term interests to treat a minority group like criminals because the group *may* contain more criminals. It didn't do so when it was the Irish, the Italians, or the Jews, and it certainly never did the entire time it's been the Blacks. It further does not serve society's long term interests to empower the police to make sliding-scale judgments based on skin color, sexual orientation, or anything-at-fucking-all. And it *certainly* does not serve society's long term OR short term interests to have individual police be able to shift the definition of probable cause -- which is a term of art defined in law that exists *specifically* to restrict the police from overreach -- based on the same personal cognitive biases and use of fallacious logic that you persist in displaying. 3. You're right, the dataset suggests that law enforcement in America is institutionally racist. Where you're deeply and tragically wrong, possibly well past the point of capacity for moral redemption, is in assuming we should not do something about that immediately. 4. I'm not judging who is or isn't racist, I'm judging the people who are manifestly -- as in beyond reasonable doubt -- racist **and** are empowered to act under the color of legal authority. I don't give a shit if Ma and Pa Kettle want to put on sheets and pine for the good ol' days when they could lynch people, I *do* give a shit when either of them puts on a badge to go to work.
Write this reasonably simple code in something like C?
Done correctly, yes.
Does a higher search rate unequivocally mean a lower standard or evidence? I think we both assumed yes so far but I propose that if a group had a larger criminal fraction that it could result in a higher search rate as well
yes, if you write it by hand it is easy. But apparently my evolutionary algorithm cannot do it correctly.
yes: at some point I tried to give "[z, z_target-z]" instead of "[z, z_target]" as inputs and this improved things quite a bit. But it looks like cheating: I expected the evolution to discover it by itself, since you can generate the same effect with the correct matrix coefficient.
yes, you are right on everything. Moreover, the hardest part about C extension is that the CPython C API leaks a lot of implementation details (refcounting being the biggest one). So, we have to slowly emulate all of them. Plus, we also need to insert workarounds to be compatible with code which uses the C API incorrectly, but happens to still work by chance on CPython, such as [this one](https://github.com/numpy/numpy/issues/9850)
it is surely possible that PyPy has bugs. Please report it to the issue tracker so that we can fix :)
Did you see [this excellent article](https://www.oreilly.com/ideas/neuroevolution-a-different-kind-of-deep-learning) that was on HN yesterday? One of the points he makes strongly is that breeding only the fittest tends to prematurely optimize and end up in a dead-end. Need to breed some combination of the "fit" and the "novel" -- see article for details.
yes, I agree that downvotes don't make sense in this case. Anyway, if it's pure Python and it's slower, please report it to us. Sometimes it happens that we are doing something stupid and if we have a reproducible issue, we can fix, like [this one](https://bitbucket.org/pypy/pypy/issues/2516/bytearray-n-tobytes-is-150x-slower-in-pypy)
yes: we have a way to add hints to RPython functions and tell the JIT "unroll this if it's the length of the loop is known and if it's small". But we need to add this hint manually, and array.dot is not one of these places. In theory, it might be possible to do it automatically: it looks like a small research project, though.
Make sure you know data structures and algorithms inside-out. Make sure you can implement them and that you can describe their complexity. Also make sure you know how to use git and know a bit about agile.
I didn't see it. It looks like a very valuable suggestion, thank you!
You're going to want to learn discrete math if you want to design a system that has every team play each-other the same amount of times.
Again you're just trying to skip right over the link between search rate and hit rate. If search rate went up due to some race-determined bias towards criminality, but the standard of evidence for a search remained fixed across all races, then the hit rate would also go up for the racial subgroup in question. Why? Because these are *high-quality* searches, they've already met the fixed and presumed justified bar of probable cause, so the odds are good that the hit rate should be closer to representive of A (the true number of criminals). When the search rate goes up and the hit rate does not go up, or goes down, then the implication is that the quality of the search is dropping. Now, there's three ways that could be happening: 1. the police are for some reason more likely to grow incompetent to search when confronted with a Black person (criminal or not), but this seems like something we can discount, unless we want to conclude that police are both institutionally racist AND institutionally incompetent. 2. the criminals are *more capable* at concealing contraband while simultaneously being *less capable* of falling below the bar of probable cause, and that this is a strange superpower associated with being Black. 3. the police have lowered the bar of probable cause and are incorrectly searching a higher percentage of those who have no contraband but are still sufficiently Black to warrant probable cause. See, the lower percentage of Blacks hit while enduring a disproportionately high number of Searches implies either a) Blacks are less likely to engage in contraband crimes while driving poorly or in poor condition vehicles (or just while bring Black) than Whites (ie your proposal of inherent criminality is False, and in fact Blacks are less criminal than Whites, at least where it comes to contraband in cars), or b) the high number of criminal Blacks you assume exist are actually better at avoiding even the reduced bar for probable cause than anyone else (ie your proposal of inherent criminality is or at least may be True, but it leaves no evidence behind to support it, and the extra searches by police have yielded nothing but diminishing returns).
curried def collatz(n): def get(previous): nonlocal n if n == 1: return previous + [n] else: previous += [n] n = int(n/2 if n % 2 == 0 else n*3+1) return get(previous) return get([])
Not to be that newb that asks this question, but how does this compare to NumPy and when should I use each?
How does that work &amp; where can I learn it
Feature engineering isn't cheating, unless most of machine learning is cheating. It might work even better with just "[z_target-z,]". You can effectively half the dimensionality. 
Please only post this in one subreddit. In your case [r/learnpython](https://www.reddit.com/r/learnpython/comments/79rjdx/webscrape_script_is_only_pulling_data_from_1st/?st=J9ETZK9I&amp;sh=96f076aahttps://www.reddit.com/r/learnpython/comments/79rjdx/webscrape_script_is_only_pulling_data_from_1st/?st=J9ETZK9I&amp;sh=96f076aa) is the appropriate one, as this is more for general discussion about the language.
If I may ask a dumb question as well - do the files need to be saved as .pyx? Because the above example is not working for me in python 3.6, but instead exiting with a `NameError: cython is not defined`, pointing to 'cython.int'...
&gt; For me, the dealbreaker with Go is how utterly toxic the community is. Thanks, that's good to know. In open source languages, the community is just as important as the language features; Python's brilliant community is surely a large part of why it's been so successful.
Could you explain what new to the "user api" means, please? I'm new to Python but not OO programming in general.
What’s the benefit of this over using cython directly? 
Your's does not break out of the loops when the password is found like the BASIC one does. 
Eh, I'm fine with my copter dropping quickly and overshooting by a foot of it gets things done faster if it's 40 feet up, less so at 3 feet. 
40 feet ≈ 12 metres 3 feet ≈ 90 cm ^metric ^units ^bot ^| [^feedback](https://redd.it/73edn2) ^| [^source](https://github.com/cannawen/metric_units_reddit_bot) ^| [^hacktoberfest](https://redd.it/73ef7e) ^| [^block](https://www.reddit.com/message/compose?to=metric_units&amp;subject=stop&amp;message=Please%20send%20this%20private%20message%20with%20the%20subject%20'stop'%20to%20block%20this%20bot) ^| [^refresh ^conversion](https://www.reddit.com/message/compose?to=metric_units&amp;subject=refresh%20t1_dp4bpqs&amp;message=Please%20click%20'send'%20below%20and%20I%20will%20update%20my%20comment%20to%20convert%20any%20new%20or%20updated%20values%20in%20your%20comment.) ^| ^v0.12.0-beta
http://pandas.pydata.org/pandas-docs/stable/generated/pandas.api.types.CategoricalDtype.html#pandas.api.types.CategoricalDtype All I mean is that they added that. Internally they had a way of creating categorical datatypes but it wasn't exposed to uses.
Ah, so by "user api" you mean it's exposed to any programmer using that package. I get it, thanks!
Categorical Dtypes sound interesting - basically analogous to Factors in R? In pandas, I've just been using Strings for this type of data. Is there a reason why specifying a categorical type would be preferred?
I couldn't help myself http://journalpanic.com/post/collatz-conjecture/
This should be part of cython imho.
I have been meaning to do this for the past year. I'm so glad you stole my idea from my head and implemented it :)
I can't get over this line of code. friend for friend in friends if friend not in followers cracks me up.
/u/TheTechnoMage , why not just: def crack_password(password): return password Aren't you simply passing the answer as the function argument anyways? from secret_file import check_password_match def crack_password(): for i in range(10): for j in range(10): for k in range(10): for l in range(10): four_digit_password = '{}{}{}{}'.format(i, j, k, l) if check_password_match(four_digit_password): return four_digit_password if __name__ == '__main__': print(crack_password()) 
What advantages does this have over IRC?
To use cython you must create a `.pyx` file. Then copy and past your function. Then declarate types. Then compile it from the command line, or with a `setup.py` script, or with `pyximport`. Whit statically, just import the module, decorate the function and declarate the type of each variable. This way is a litle more readable because you don't need to break the flux of the lecture searching where come from the function in another file. Also thanks to the decorator you explicity know that is a cythonized function. Tat's all.
You must import cython.
&gt;CPython is the reference implementation; the idea is that it's supposed to be an example of how to write a Python interpreter Unless I'm mis-informed, that isn't at all accurate. Jython, the first alternative CPython, was made 10 years after CPython.
I do not *think* this is a bug. It says in the CPython docs that not all systems will provide birthtime. But I will put it in there anyway. Thanks.
Yes, that was more easy than I thought :)
I agree, maybe i should send a pull request.
cPython is the reference implementation for the python language. It translates python in to byte code and executes it. PyPy is an alternative implementation of the python language. It includes a Just In Time optimising compiler, which it uses to optimise the code on the fly (much like java does with its JVM). Numpy is a very popular, pure C, library for python, that provides fast multidimensional arrays and the like. PyPy doesn't do so well with calling to C libraries. For a long time it couldn't, it can now but has some serious overhead they're working on. Numpypy is an API compatible implementation designed for PyPy, as the lack of PyPy support in numpy was blocking PyPy use in some key areas where it could make a massive difference. It's a direct drop in replacement. 
Here's a good resource: [The Python resource](https://www.reddit.com/r/learnpython/wiki/index)
thanks :) 
Codecademy 
also what version of python dhould i learn? 3 right?
Personally I would use 3 if you're just starting out, might as well go with the latest available and keep up with the versions if possible.
Thanks, good catch!
Just don't be on windows. Setting up virtualenv with pypy that would actually work... never got there.
Codecademy is a very interactive and friendly site to learn Python and other programming lenguages
At the moment none really, when I add end to end encryption utilizing a password or pgp I think it will be more secure than IRC, also the fact that all the parts that make it work are open source! but maybe I just don't know enough about IRC and it was just a fun project to work on!
https://learnpythonthehardway.org
Well, that's why I said *supposed* to be.
Still wait until matplotlib is supported, I am going full pypy
And since a set is backed by a hash table lookups 
I write python and go at work. I'll only debunk the things I know to be false. Python is better for working with databases, especially when perf is not an issue because python has better libraries. &gt; Go arrays don't expand themselves Python gives you lists, something that's called "slices" in go. &gt; Go doesn't have any fancy syntax sugar I don't see how that's a problem, but can you provide examples for it? Use the right tool for your job. Go is a performant compiled language. It's useful for certain class of applications. Python is a heavier but weakly typed language, it's more flexible and has way more libraries, useful for very different kind of applications. There's certainly an overlap, but it's usually clear which language to pick based on how much concurrency is needed and what perf you expect.
Certainly! A **really** important note is that a set is *not* a list. You can still iterate over sets, which is why for id in non_friends: still works, but just remember that now friends and followers are lists, but non_friends is a set.
Isn't that classic overfitting? Were you doing anything to mitigate it like using a validation set?
Hm, I've never heard this. Do you have a source? I'd be interested to learn more!
Nevermind, the problem is gone. I had imported cython, yet somehow the cython installation I performed before that failed, thus the NameError despite the module being showed as installed.
Yup! Checkout the upcoming release: Here's a Gist of how support would look like: https://gist.github.com/prkumar/4e905edb988bc3d3d95e680ef043f934
I'm taking 10MB log files, parsing them, plotting the data I want with plotly, and pushing the rest to excel for my records. 
Oh jeez, I don't remember. I think it *might* have been Guido Van Rossum's blog? Or something?
No worries, if I remember I can ask next time I see him :)
So do you enter in the right password for this to work? I dont get it :(
I'm not sure I understand what you guys mean. Pandas has had a categorical type for many versions now. And it sure was exposed to users.
what episode?
Honestly, I didn't expect this to turn into a full discussion. All was trying to say is that being able to write. t=CategoricalDtype(categories=['b', 'a'], ordered=True) is a new thing. http://pandas.pydata.org/pandas-docs/stable/categorical.html#categorical-categoricaldtype 
This. Python breaks are internally goto statements, and the code uses a goto. For once a developer used a healthy goto, you should at least honor that. ;-)
There are a couple of reasons - here's why I've been looking forward to it: - you can specify what values are valid - eg allow only ISO country codes, instead of any string - you can specify an order for the categories which is not the order of the values (eg sorts to [first &lt; second &lt; third &lt; fourth]) - categories also work for other data types (ints, floats, objects...) - you can now (new feature!) construct a categorical dtype with particular values and order *before* loading your data, so unexpected values become an error instead of an odd dtype.
Ah those do sound useful! Particularly the sort order. Would eliminate the need for all those "***_order" parameters in the `seaborn` method calls.
episode 8 or 9, of season 2
minor spoilers
"{:04d}".format(i) for i in range (10000)
Why would you not use type annotations? Thats like writing C code and complaining its hard to use because you use GOTO for all of your loops instead of while() or for(). Dont complain about performance if you arent going to use the language correctly.
Somebody looks at a terminal and a password is somehow involved? That's not a spoiler.
Lol, I have seen season 1, finished yesterday, spoiler 😑
Exactly what I expected. Dumb reaction. Are type annotations necessary ? **No.** Were performance benefits promissed even without them ? **Yes.** Did I dispute that writing C in python will give you better performance ? **No.** So why are you bitching ? That I warned others that the situation is not so rosy, that they might even get a performance hit, unless they step down to a much lower level, and basically start writing C in python ? PS: You act like you've never seen dumb-asses heralding Cython as panacea (faster code without annotations, and it even - in their dumb minds - somehow makes code using python data-structures and python runtime be able to run GIL-free). But maybe it's hard for a fanboy to really notice when someone sings false praise about his object of worship ...
Another one using Python3 f-string 0-padding: def crack_password(check_range=range(0,10000)): def check_match(p): return p == "0323" for p in check_range: p = f"{p:04d}" # 0-padded 4-digit string if check_match(p): return p
That's a very long code to do nothing...
That's how I feel trying to learn programming. 
Any chance you could dial down the petulant brogrammer a few dozen notches and give us your code and the steps to recreate your experiment?
&gt; the idea is that it's supposed to be an example of how to write a Python interpreter, not really the interpreter you actually use in production Citation needed.
&gt; But we need to add this hint manually, and array.dot is not one of these places A kind-of-wrapper that marks a function for unrolling would make sense then, although I'm not sure if it would make sense often enough without "manually turning on an automatic heuristic of unrollings". On the other hand, I noticed (again) now that with array.dot the problem was more in the copies than in the loops, so I suspect the problem in this particular case should've been solved by an explicit copy and in-place operations; and numpy itself doesn't seem to support much of those. If it did, it would've probably looked like this: out_values = copy(self.matrix) out_values = out_values.dot(self.state, inplace=True) out_values += self.constant 
It sounds so fucking funny xD
sans-io library is good for implement high level library, but not good for end users. `httptools` is very helpful for implement curequests, I hope there are more sans-io libraries, but it's a bit hard.
This piece of code / algorithm is super inefficient, why not check every index at a time...
Is there any possibility of interfacing CPython-run code and PyPy-run code with minimal overhead? E.g. run a CPython thread that interacts with some C extensions (e.g. a database connector), and pass the structures to/from it to the PyPy thread with pickle overhead or less, maybe even without making a copy (in the perfect case).
Or assembly.
Assembly IRL
Now you know season 2 has some shitty basic code in it. How awful.
I'm super new to Python as well but you need to make sure you are using the correct path. If state.csv isn't in the folder with your Python, you need to use full path. Ie pd.read_csv(c:\desktop\state.csv'). Also be careful if you are copying the path from windows file explorer, put an r in front of quotations in the read_csv argument for a raw string to avoid escape characters. Hope I'm not forgetting anything.
Using Cython correctly is not "writing C in Python". I know this for certain because I've written C code which runs on embedded systems - your archetypal constrained performance sensitive system. Cython is a hell of a lot easier. Using Cython effectively is, however, a matter of actually understanding the tools you are using, their advantages, and their limitations. Every optimization tool has corner cases where it will cause a performance degradation. Even the Cython team has said this. If you fail to understand those caveats, that is your fault and your responsibility - not that of the tool. What Cython has that is very useful and valuable is a very smooth on-ramp between pure Python and a Python -&gt; C binding. This allows a reasonably attentive user to move parts of the code to a compiled language, with only that amount of optimization and annotation that makes sense. This allows such a user to do two things 1) Leave the rest of the code in Python, minimizing rework and 2) Avoid recoding algorithms directly in C when there is a working Python implementation. As a side benefit, it also provides nice tools for 3) Linking to code in C for those cases where even Cython is not fast enough. There are excellent profiling tools which are designed for use with Cython which will tell you why your code is slow. You, of course, proceeded to _not use_ those tools. Gil releasing code is entirely feasible - especially when using Numpy data structures - which was the intended use-case. Doing this, of course, requires proper type annotation and attention to the data flow of the program. Again, it is not the fault of the tools, but your failure to understand and use them properly. I will guarantee that if you apply Haskell with as little thought you will achieve similarly poor results (ameliorated somewhat by the fact that Haskell is a compiled language, and is intrinsically faster for most use-cases.) I will note that I would say the same thing about C++, another well known and highly performant (if used correctly) language. Edit: typoos
It's this even possible within the time period if the show? Or am I mistaken in that Stranger Things happens in a more modern time rather than the 80's or 90's
&gt; Any chance you could dial down the petulant brogrammer a few dozen notches Sure, as soon as you fanboys stop lying for your golden calf, throwing a tantrum every time someone calls you your bluffs. Or just when someone doesnt share your dogma. &gt; steps to recreate your experiment are in the friggin post, you illiterate plebeian &gt; give us your code When some sane person asks, maybe. Until then, just google for existing examples (Cython slower than python), *or even better*: MEASURE ON CODE THAT MATTERS TO YOU ...
4 nested loops (one for each digit) range of each digit is 10 (0-9)
Well, that went from brogrammer to complete asshole real quick. Not a fan boy, in fact have barely used Cython personally -- though I've seen it used to good effect at household-name companies that would never even consider employing someone that communicates like you -- and as you've not provided a reproducible experiment (which would obviously include your test code) I can't verify or contradict your findings without spending more of my time than you and your ranting *clearly* deserve.
"pickle overhead or less": beware that pickle is awfully slow. Anyway, you are probably asking for something like [execnet](http://codespeak.net/execnet/)
That's actually a reasonably incisive question, given her level of interest. A better one might be why are you trying to explain ChainMap to anyone that isn't a programmer? Of course I say this, but yesterday I spent an hour trying to explain a tokamak to my wife, who isn't a nuclear physicist.
No. edit: to be clear i'm referring to the python, not BASIC
To me, this example shows that numpy really needs some fixed-size matrix/vectors that it can pre-allocate memory for. However, at least with my knowledge of how numpy works I think this is impossible.
During those times, you should use "algorithm".
Quick nitpick: Python is *strongly* and *dynamically* typed, not weakly typed.
Oh no! Now you know there is a scene where a guy is typing on a computer. Literally unwatchable now!
The concept of "Pythonic" is hard to explain even to programmers, probably because there isn't even a definition that isn't cyclic ("Pythonic" means "idiomatic Python", which means "Python the way Python programmers think Python should be written", hmm...). No wonder someone without a proper programming background has trouble understanding. On a side note, I've always considered it funny that hardly any other language has felt the need to reinvent the concept of "idiomatic coding style" and give it a language-specific name - nobody ever uses words like "Javanian", "C-sharpish", "Javascriptarian", "Lispoid", etc.; everyone else just calls it "idiomatic", or maybe they throw around terms like "object-oriented", "proper", "best practices", "clean", etc. But for some reason, Python calls it "Pythonic", as if it were something fundamentally different and new.
Every kind of code junction is internally a goto (jumps, conditional jumps etc.). 
It happens in the 80s. And, since I haven't started watching the new season yet, at least coding in BASIC was definitely already possible in the 80s. 
Where did anyone get the notion I was trying to use Cython "effectively" ? As i stated, I was mainly interested in testing the "free performance gains". &gt; What Cython has that is very useful and valuable is a very smooth on-ramp between pure Python and a Python -&gt; C binding. Well, I just pointed out that the ramp might not be as smooth. &gt; Every optimization tool has corner cases where it will cause a performance degradation Certainly not every optimization. True for some, false for others, some are just plainly more efficient ways of doing things. Truer for algorithms, for sure. &gt; There are excellent profiling tools which are designed for use with Cython which will tell you why your code is slow. You, of course, proceeded to not use those tools. Thank you oh so much, captain obvious. Is it so hard to grasp the fact that i was not interested in profiling, that I was not interested in wasting time to get the performance of it back to plain python speed (and then beyond). I tried the "low investment - low gain approach", observed unsatisfactory results, and even shared them with Python-eaters, even though I knew exactly how some of you will react to unwelcome news. &gt; I will guarantee that ... You can't guarante Jack shit, since it's all based on your unfounded assumptions. I've been programming in haskell for a long time (FYI, I can use more languages than majority of people can name, that is why I'm so fucking picky), and let me tell you, writing code with reasonable performance is way more palatable (to me) in haskell then what I saw as examples of "this is how beautiful performant cython looks". Should I also pull an assumption out of my ass ? Perhaps assume that you are afraid of Haskell, and scare others away, because "Monads are hard (lol, the hardest part was to realize that they are simple)", "You'd have to learn Category Theory to get any mileage out of it (https://wiki.haskell.org/Zygohistomorphic_prepromorphisms)" etc. ? Just for shits and giggles (since haskell [also] gets improved all the time), "now" (for some time) you can spend less time on strictness annotations (better strictness analyzer), and soon you won't have to rewrite some code manually (instead of using higher-level constructs) to gain perfect fusion (recent work of SPJ on join-points). 
this is a really cool answer on multiple levels :-)
&gt; PyPy doesn't do so well with calling to C libraries. That's not completely true. There are different ways to call C code from Python and not all of them are slow under PyPy. When calling into C code via the CPython C API it is indeed slow and something the PyPy team is currently improving and has made great progress in the branch mentioned in the blog post. Whether the current slowness hurts you will depend on how much work is done on the C side for each call into the C code. The more work that gets done on the C side per call the less of the impact there is due to the overhead of the call. On the other hand, if using the cffi approach to calling C code you get blazing performance, as almost all of the overhead in calling the C code has been removed by the JIT.
&gt; I've seen it used to good effect ... And I reported what I saw, namely that the promisses of automagical speed gains can turn into reality of slower code. Which is not ranting. If you asked reasonably, instead of acting like i just tried to defile your sacred symbol, I'd probably give it to you. But no, someone touched one of the holy truths, that Python is the Best and Cython is one of its prophets, and like a good fanboy you had to lash out. Which is quite normal, every time someone brings forth unpopular facts, the least talented Pyboys will go on a crusade to defend their idol (subconsciously defending their egos, propped up by the silly notion "I use Python, the best laguage ever"; Not that it is specific to Python, but from my observations, Python &amp; Go "believers" are worse than even those legendary smug lisp weenies of c.l.l). And I don't care a bit about what you personally can verify, or how much you think my observations "deserve" trashing (if that is not a fanboy speaking ...). So unless someone who is less prejudiced asks for the code, you'll have just your spite.
Funnily enough I also had a similar idea, glad to see it implemented. Would definitely make sense as part of cython especially since the support for type annotations is already in place.
&gt; t=CategoricalDtype(categories=['b', 'a'], ordered=True) This is convenient. I have been found of keeping lists of preferred orders and some function that I always call when a data manipulation result yields a column that should be ordered.
The core of matplotlib has been supported now for over a year. What is missing is support for some of the graphical backends such as QT, etc. It does however work with the Jupyter.
Jesus. How do you even breathe with that Redwood up your ass? As -- again -- not a fan boy, who was simply hoping for your actual example so I could check it out for myself on my own machine, I'm forced to believe you're at best a dilettante and at worst a troll. The deserve is entirely because of your wording on every single one of your posts; you don't obviously credit either listening to or respect.
Hand wave "magic"
Yes, with "new" I meant "different from the old one". So yeah, I could have said that better.
And don't let me forget the GIL issue. If you can read, i said +- the following: &gt; they even think that it [cython] somehow makes code using python data-structures and python runtime be able to run GIL-free Now of course since Numpy array is just a plain bit of memory, and unless you need to touch some part of python thet requires the lock, yes that code can let go of gil. And thats what the fanboys (I've had the misfortune to meet / try to argue with) heard, and wrongly translated as "as soon as i compile my [normal] python code into C, it will be able to give up GIL". Trying to point out that plain python code usually uses a whole bunch of python datastructures / functionality that DEPENDS on the GIL (they don't have their own locks) and that unless you rewrite it "on a C level" (losing lots of the conveniences of python), you can't release the GIL (unless you wanna visit Race Condition City ...) was useless. Try to assume, how many of the PyBoys I've met were able to grasp it ?
Feed not the *obvious* troll. Nothing on the Cython website even mentions free performance gains... he's just screaming at a straw man.
Interesting approach. First thought: would this be cool together with a serializer framework like Marshmallow?
This is really, really nice work. I applaud every attempt to make it simple to gain some performance when needed.
Yes, analogous to R factors. However categorical dtype isn't really new, but it's implementation has been changed. So I should have said "improved" instead of "new" to be precise. The improvement is really point 4 of @PeridexisErrant's list. This improvement in addition means that you can construct your categorical dtypes in one place and reuse them where needed. This makes it much easier to have DRY (Don't Repeat Yourself) code wrt. categoricals.
&gt; A better one might be why are you trying to explain ChainMap to anyone that isn't a programmer? She was curious about what I was doing. I had to really boil down the concepts. Conversation went something along this line: --------------------------- &gt; "When coding, you deal with data. And data can be kept in different ways. Like in real life, you know how you use dictionaries? Where you make references and definitions? In Python, we also have dictionaries. &gt; &gt; Imagine that you have a dictionary of cats. And then you have a dictionary of dogs. What if you wanted a dictionary of pet animals? You can mix your cat-dictionary and dog-dictionary together. And now you have a sort of dictionary of pets, which you can use in several ways. &gt; &gt; ChainMap is a different and more Pythonic way of mixing and using your dictionaries." ...In hindsight, and now that I think about it: my animals-based methodology might have partially contributed to the reptilian assumption.
There was a sign for the Reagan/Bush campaign in 1984 in one of the episodes. So I guess it plays in 1984.
&gt; The deserve is entirely because of your wording on every single one of your posts Perhaps you should've replied, in kind, to the original post, which was just slightly snarky. But no, you had go full McIntosh, and now you play butthurt. No cookie for you ... &gt; I'm forced to believe you're at best a dilettante and at worst a troll. Neither reverse psychology nor insults will get you anywhere.
Ahh, yes ... initiating allegory fail. "Imagine you have a book with all the unique phone numbers and their owner's in Detroit, and another book with all the unique phone numbers and their owner's in Chicago. You have a phone number and you want to know who it belongs to, and you know that person is in either either Detroit or Chicago, but you don't know which, and you'd prefer it if they're in Detroit. How do you find them? That's a ChainMap."
Look, hacking was *easier* back then. Passwords were on those newfangled Post-It things, for one.
First off, how many girlfriends do you have? And how many mothers do they each have? Second off, the problem with doing this for you is that basically that's roughly equivalent to us doing the kid's homework for him, albeit through you as a proxy. If he asked the question on here, we'd have to just give some hints. So, hints: you need the basic syntax of the **input**, **max**, **min**, **print**, and **int** functions, how to do a **for** loop and an **if**/**elif**/**else** conditional, possibly a **while** loop, and the basic methods of **lists** and **strings**. If you did C++ at all competently this is all something you should be able to pick up, generally, in about an hour or two of reading through [this](https://learnxinyminutes.com/docs/python3/) ... Python's syntax is way more natural than C++. If you focus on the above you can leave classes and a lot of other stuff till way later. Sympathy for the butt-kicking scorn you're gonna take from one or more girlfriends if you don't knuckle down though.
I am not an expert, but * you can recompile the interpreter, if you are hardcore. I've found [this](https://www.laurentluce.com/posts/python-integer-objects-implementation/) about it. * you can dig into numpy on [low level](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.ndarray.html) * you can rely on string interning and transformation, as you mentioned. Hoping, the implementation won't change. I would do the second.
To be fair, I typically see 2-5x gains from compiling on the workloads I've used it on. His code must have been pretty odd to see a performance reduction. My guess is that he had some type of python function call in an inside loop, but without looking at the code it's just a guess. 
My original reply just asked you to turn down the extraneous snark -- which wasn't and isn't doing you any favors -- and show your hand. You then went straight to plaid. But, yeah, readily admit that psychology isn't going to get me, or anyone, anywhere... the thing on the other end of that lever needs to be able to pass the Turing Test.
Which would be why I asked to see the code. Right now this is basically a latter day Fermat writing "I've found an elegant proof, it just won't fit in the margins" and then running around screaming, shitting on his hands, and throwing it at passersby. Might be true. Can't tell. Not going to take the word of the guy who's dung is sliding down the wall behind me.
Now you're really showing your ignorance. Numpy arrays are actually fairly sophisticated datastructures, which are optimized for a good mix of raw speed and optimized striding/slicing semantics. This decision was made to support both row major and column major striding without requiring a memory copy operation. Also, Cython targets C++, not C. Cython has proper support for releasing the GIL both in the (common) case of Numpy arrays and when calling into certain kinds of C code. It is not, however, necessary to rewrite it 'on a C level', just restrict your semantics somewhat. Realistically, that's not a significant concern in code that is performance critical, as you would avoid most of those features because (1) They aren't necessary for that kind of work and (2) They are slow as hell no matter how you compile them.
As far as I know I have one girlfriend and I hope she did not lie about the number of mothers she has, that would be awkward (I apologise for some grammar mistakes, I was writing this in the bus and since 90% of the roads in Croatia are really shitty it was kinda hard to concentrate). Yeah, I agree this is not the right way to teach someone...well anything, and it was my bad to make a promise without knowing all the facts but apparently this kid is not really interested in Python or any kind of programing, he just wants a passing grade so I don't feel so bad about "cheating". Btw thank you for you insight and the link.
Halloween 1983, the signs are for the next year's elections. Edit: I'm wrong, it takes place in 1984. Sorry friends. 
Those lines of BASIC remembered me a game : [elseheartbreak](http://elseheartbreak.com/) A weird adventure game were you could "hack" everything from computers to drinks. Just be aware that you get your 'deck' a bit lately to my taste 
do you use the ultimate edition off intellij?
Yeah. Heaven forbid someone writes a patch for the performance regression bug. 
If your range is only 175, you could represent it in 1 byte (if it's 361 possibilities, that's 9 bits, you'd probably want 2 bytes). You could potentially use a bytearray. You may need to fiddle with your logic quite a bit though to achieve this.
Last week I tried to install matplotlib on pypy2, one of the dependent package subprocess32 give error during install. I switch to pypy3 and tried again , but hit another error. I think one of the error is cause by problem specific to OS X.
If that happened it would remove the stick he's been sitting on; based on the apparent size, that's guaranteed fatal... so I suppose it's a perverse incentive.
I don't mind grammar mistakes, I just have to point them out when they're either making it impossible to understand (not the case here) or the mistake is hilarious (as is the case here). English is a stupidly complicated language, regardless of how bad the roads are. Personally I'm of the opinion that wanting a passing grade and **not** getting one if you don't do the work is how you learn to not be a kid. **Edit**: also making overreaching promises to significant other's relatives and *not* getting the hoped-for reward is how you learn to not make promises you can't keep. ;-)
I would file a bug report. For a while PyPy didn't have a working OS X buildbot but as of a few days ago they now have a new one up and running and have fixed a number of issues on OS X. Maybe the issue has already been fixed. I would try a recent nightly build.
Late enough that I lost interest before that point, sadly. 
If you have the paid version then probably not. more curious, why did you start on intelliJ ? were you a java guy once ? 
If you are just comparing the free versions of each then there is a difference. Intellij for java development and pycharm for python. Its the paid version of intellij that will give you python also.
IntelliJ is always one version behind PyCharm in terms of PyCharm features, so features of 2017.2 PyCharm won't appear until 2017.3 of IntelliJ for example.
It is a very basic brute force "attack" on the four digit pin that this hyper-secret government facility uses to protect its hyper-secret computer system. Let that sink in for a second. No failure limit. Four digits. A person could easily crack it on their own without a BASIC program in a few minutes to hours, depending on how long authentication takes (not long, given what we see in the show). I would say I expect better from a hyper-secret government organization, but, eh, &lt;insert derisive remark about the American political system, intended to garner upvotes&gt;. P.S. How did you like the season? I am a huge fan, and loved the direction they took. 
Spoiler alert! They use BASIC. No wonder the Upside Down is so messed up. Thanks OP! Now season 2 is ruined.
This file are in same directory of your .py script?
No. The very first scene in the first episode says it's 1984; one year after the first season which took place in 1983.
Wow, you obviously have a small brain. He is doing it for a purpose, and whats been made obvious here is that it has something to do with cracking a code in hawkins lab, probably a door code. It's not like someone is raking leaves on FRIENDS. No wonder why everyone outside of this community hates it so much, goodbye.
Bush wasn’t Reagan’s running mate until the Convention, which took place in August of 1984. That also fits the timeline established in the first episode. 
Sorry, I don’t watch rick and morty
`typing` let's you define your own types, and you can make them apply to an arbitrary number of types using Any, or you can use annotations creatively.
No worries, happens a lot as a professional too.
No, it was the 80s, and security really was that bad. 
This is probably a case of premature optimisation. I'd investigate different data structures before thinking about interned integers. Numpy or `array` (stdlib) would possibly be a better choice for serious number crunching. If you like, post some details about how large these dictionaries will be, and what data they hold. There may be ever better options.
Oh, yeah, agreed. I just wanted to make a neutral joke. 
Yeah, I expected the doctor to hand him a Post-It, or tell him it was 1111 or something. I was doing support in the mid 90s and back then it was still normal for people to say 'why do I need a password, who other than me even knows how to turn this thing on?!' 
Haha, sorry. I think, being old, I'm just interested in talking about how absurd security was when I started in the field. Didn't mean to be rude to get there.
"No. Look, look, I *know* what it says. No. Listen, just hit *any* key. Like any of them. Any of them at all."
Oh, you're good. I cut my teeth on old BASIC-based systems, so I feel ya. It's kind of hilarious how true-to-life the show is regarding tech. 
You joke, we had an old lady who called us once a month because she forgot which key was okay to press, and didn't want to screw it up!
Who is joking? God, I wish I was joking.
I guess what i dont understand is what is the value of Four_Digit_Passcode Is that the correct pass code? If so whats the point of the test if you already know it because you had to enter it in?
s02 episode 7 derailed the show for me
I always try to avoid having a browser / headless engine running when scraping stuff. I usually find a way with parsing through the markup. If that does not work (i.e. a "modern app with only javascript visible"), I try to debug the XHRs and try to predict urls for fetching data. The browser dilemma is usually the last resort. Having a browser running, rendering and executing javascript will always be slower TBH.
Nah, it's being declared outside the loop, and the digits are being added inside the loop. 0000 0001 0002 ... 9997 9998 9999 It's kind of bad, because technically this wouldn't be an int, it would be an array/list of ints. I think we're to assume that the function in the show that "parses" that array (list) just passes the four digits to whatever log in program the computer is running... Basically, the code is BS, but it's closer to being real code than most television code is. 
I guess episode 7 didn't stand out as particularly bad to me, so I don't remember what that episode was about. EDIT (I'm going to try to keep the spoilers ridiculously vague, especially since it's very off-topic for the sub but, this is your fair warning: **Possible spoilers ahead**): Oh, I remember what it was. I dunno, I feel like it was them trying to build out a larger world in preparation for a new season. It did strike me as a bit out of place, but it also felt like a bit of a breather after all the scary stuff we'd been through the last few episodes. I think they would have been better served spreading it throughout the other episodes (setting up the new characters in earlier episodes, instead of just in the very first episode, things like that). I see what they're doing with it, and I really like the *idea* of what they're trying to start with it, but you're right, it was out of place. Still, I think the last episodes made up for it, even if there was a lot of deus ex machina going on.
You're wrong, the original code uses numpy, go read again.
&gt; want to make sure that I am not missing anything by not using PyCharm. ...Try Pycharm, and see if you feel that you are missing anything. If you're not using it, you're not missing anything. If you're happy and fine with Intellij, you're not missing anything. If you're interested in checking out new things, check it out and see for yourself. I am not sure if any good has ever come from threads asking about editors and comparing them. Just use a few, and go with the one you like the most, not the one someone else likes the most.
Would a numpy array with a dtype be equivalent while providing access to arithmetic operations? Of course this assumes that all the things tht you want to do with the integers "fit" into numpy.
Should be no surprise...After all, the language was named after an English comedy group.
The index of the first match.
Showed my yearly project to my advisor, done with Python on Fuzzy Linear Programming. It is going pretty well and it is all from scratch except using sympy Symbols which I plan to ditch somehow. I like making things from scratch and Python makes it so much more comfortable!
Interning isn't going to be that important since you still have to have a pointer to the object in question. Some examples: one, two, three = 1, 2, 3 sys.getsizeof(one) # returns 28, same for two, three sys.getsizeof([]) # 64, but an empty array is massive sys.getsizeof([one]) # 72, and adding a single item adds an 8byte pointer sys.getsizeof([one, two]) # 80 sys.getsizeof([one, two, three]) # 88 sys.getsizeof([one, one, one]) # also 88, three eight byte pointers to the same item tacked on to the end of a 64byte array object. So just for the array itself (nevermind the values) of N integers you need: 64 + 8*number of integers bytes. So certainly if you don't intern, then an array like: `[-180,-180,-180,...]` could create N different instances of the value `-180` and require 64+8N+28N total bytes... but interning only takes that down to 64+8N+28. Which is a rather modest improvement. Considering that you can trivially fit the range -180 to 180 in two bytes (an int16), there is an obviously better way. A simple numpy array of int16s is going to amount to a massive reduction in memory usage as it will pack the raw value (repeating as necessary) into memory and fit everything into something that scales as 2N bytes. In fact it does better from the very first entry (despite all the boilerplate around numpy objects): sys.getsizeof(numpy.array([one], dtype=numpy.int16)) # 98 sys.getsizeof([one]) # 72... but don't forget that "one" itself takes up 28 bytes.. for a net of 100 bytes. sys.getsizeof(numpy.array([one]*1000, dtype=numpy.int16)) # 2096 sys.getsizeof([one]*1000) # 8064!!! 
the description of .index() is literally a single sentence: "index of the first occurrence of x in s (at or after index i and before index j)" https://docs.python.org/3/library/stdtypes.html#common-sequence-operations
&gt; This is probably a case of premature optimisation This is how to troll a programmer, along with "why is that so complicated?". But yeah your optimisation seems a bunch simpler :)
Could improve using Numpy as well.
Python docs: &gt; &gt; s.index(x[, i[, j]]) index of the first occurrence of x in s (at or after index i and before index j)
If `numpy` or `array` are not good enough for you (maybe you want more control). I might through `cython` and `ctypes` into the mix as easyish ways to interact with memory without having to mess with extensions. 
Try /r/learnpython next time, or reading the [official docs](https://docs.python.org/3/tutorial/datastructures.html). See `list.index`. It's in the *first* sentence.
Taking a crack at learning Django using the official Django tutorial. Never done any web development but been using python for a few years. Any recommendations on where to go from here? I'm interested in developing an application for work to bring some spreadsheet silos into one place. 
Heck, even in the 90s. You could literally get away with Hackers-level social engineering. Actually sometimes you still can.
&gt; If your range is only 175 Why would you say that when the poster already said it was -180 to 180?
Thank you guys
&gt; why not check every index at a time I wasn't aware you could run Python on quantum computers. :D
Sadly, `intern` only works on strings. But you can make your own: py&gt; def myintern(i, d={}): ... # Don't pass the d argument. ... return d.setdefault(i, i) ... py&gt; a = myintern(1000) py&gt; b = myintern(1000) py&gt; a is b True Every time you create one of those tuples, pass the int arguments through `myintern` first. It probably won't speed your code up (it might even slow it down a tad) but it will probably save you some memory. But... honestly, before you do this, are you *sure* that it's going to help? Don't just assume that it will "dramatically reduce memory consumption". Assuming your ints are uniformly distributed between -180 and 180, half of them are already interned, so *at best* you will save half the memory used by your ints, which may not be a very large percentage of your total application memory consumption. And besides, what you consider "a large dictionary" might not be large to your computer. I suppose its worth the experiment, but frankly I don't expect it will help that much. But I'll be glad to be proven wrong! Write back and let us know what happened -- or better still, post a feature request on the bug tracker asking for a way to intern ints.
&gt; Go's syntax is much more complicated than how it is advertised, that is true. But you'll get used to it, coming from python it feels too complex, coming from C or other similar languages it feels simple. To me Go is super simple, whereas Python's got waaaay more syntactic sugar. At least it's not as bad as Ruby...
Microsoft BASIC was released in 1975 and BASIC been about since the 60s.
Why don't you try it and see? Open the Python interactive interpreter, and type: t = (1, 2, 3, 4, 5, 6, 7, 4, 8, 9, 4) t.index(4) and see whether it returns 3 (the first), 7 (one in the middle) or 10 (the last). Then try with `t.rindex(4)` as well. 
In the 80s you could usually log in with Guest:Guest even on fairly important University systems. Often, the 'trick' was just having the manual to a machine to tell you what the default password was. Even when they made user accounts, they often forgot to remove the default accounts. Another insanely simple trick was to log in under any public Access port, because most of these old systems had a BBS like menu or something you could get to, then try hitting Ctrl+c on the submenus or while running anything it'd let you run. Sometimes it would stop the process and drop you to a prompt. 
This. Security used to be assumed. If you were in the right building, you were assumed to be allowed to do the thing. NFS in the olden days assumed that if you were on the network, you were supposed to have access to the files. It would trust your computer to tell it who you were. A passcode probably seemed like overkill back then. Somebody probably had it written down on the back of the monitor or in a desk drawer and everyone knew where it was written. It was a simpler time.
I like the season but thought they spent too long in the build up. I felt like they took a whole bunch of time flopping around hopelessly and then the characters arbitrarily decided "Okay, let's actually defeat the antagonist" and then did it.
Python has lists *not* arrays. A lot of languages have arrays which are fixed in size. In C# (I would imagine that Java is very similar): string[] myStringArray = new string[10]; Lists is a collection. [This](https://www.quora.com/What-is-the-difference-between-an-array-a-list-and-a-linked-list) quora answer that explains this quite well. I don't know much about go, but regarding Null in Go it sounds similar to how C# has a difference between value types and reference types, reference types include things like int, double etc live on the stack and reference types like string live on the heap. 
Interesting... I wasn't quite sure what a declarative client means. When I think declarative I think about things like SQL and XPATH where you "write what you want to know not how to do it so wasn't sure what it meant in this context.". This feels more declarative in the sense of an ORM model definitions like django: "create a data structure using classes and methods then generate useable code from these classes and methods" What I think is going on here: * Require a method to be created in order to make a functional call * Turn some parameters in a function call into decorators * Use a class to allow "scoping of parameters" This has some interesting effects: * By being encouraged to create a method on a class you encourage code deduplication * The interface is represented as data rather that turing-complete code (you can do things with data in a constrained format more easily that turing complete code) This sort of reminds me of the [builder pattern](https://en.wikipedia.org/wiki/Builder_pattern) that you have say in django's query language or Jquery's query language with the exception that you are throwing a class into the mix for the purposes of scoping. I guess "scoping of parameters" is kind of orthogonal to "declarativeness", but declarativeness gives you a bit of this for free (because you have the class there to apply decorators to). I was thinking to myself whether you might want some "intermediate scoping". i.e. these methods all use get, these methods all use post but they live in the same client. 
Even more newbbb question, but how can I tell? 
 def gen_pass(): for num in range(9999): yield f'{num:04d}' for password in gen_pass(): get_access(password)
I've been working on trying to get a numerical methods solver in Qt... I just released my first version... Hoping to generate some community interest. I'll be adding a website and stuff soon too. https://github.com/HaoZeke/pyQtNumSim/releases
I'm working on a webapp that will act as a bridge between users and Spotify. It will basically be a party playlist manager for spotify where someone can host a playlist and people with an access code can search for and add songs to the queue. I'm thinking about using flask to make a restAPI that uses spotify's web api but I'm not entirely sure yet. Any recommendations would be more than welcome.
Thanks. I'm sure I'm just not writing things right, but I'm getting an invalid syntax error when I attempt to execute this command: data_file = pd.read_csv(c:\desktop\state.csv). Sorry to bother with these super basic questions. 
Exactly 
A 4-digit pin has 10,000 possibilities. No one is cracking it in a few minutes without extreme luck. In any case, the comment was pointing out that the password was being passed in as input to the function. If you already had the password, you wouldn’t need to crack it. The code should be attempting to login to the system, not checking against a pre-provided password.
We get it, you saw it but mark it spoiler
Yeah, I was taking luck (and/or social engineering) into account with the minutes thing. I'm kinda explaining the "password_crack" function as a way of simulating user input to the authentication program. Still doesn't make sense, you're absolutely right, but I think that's what they're going for. He might actually be comparing against a "secure" encrypted file on the disk that he can, somehow, see, and then sending the correct number over to the auth program. Like I mentioned elsewhere, the code is *close*, but not quite there. It's still better than a *huge* number of other examples from TV shows and movies.
I put the source code [on github](https://github.com/pasqu4le/kobowm), so that if anyone wants to write his own window manager has an example to look at.
Be great if you could make that an actual link.
I don't understand what your variables are supposed to represent. Are you looking at all points `(-1,1)`, `(1, 0)` or only those with the same x and y values? `(1,1)`, `(0,0)`?
No comment on the function, but the `passwd = list(password)` is unnecessary. A string is a list of characters, so `password[1]` for example will work.
Link: https://sultan.readthedocs.io/en/latest/
I am trying to represent latitude and longitude coordinates eventually. I am starting simple for the sake of testing. I figured I can use the list position to reference the coordinate (in this case position 0 is 1,1). This fundamental assumption may be wrong which is why I asked about how these lists would actually run through the function.
If the file isn't on your desktop, click on the files properties to see where it's located. Also, the path should be in quotes.
Source: https://github.com/aeroxis/sultan
Its not that far fetched [for 20 years the nuclear launch code was 00000000](https://arstechnica.com/tech-policy/2013/12/launch-code-for-us-nukes-was-00000000-for-20-years/)
Try on Chrome. It works.
**Lookin' fer savvy devs** We at Pirates Online Retribution strive to create the best Pirates Online reboot ever. However we be in need of some savvy devs who are skilled with all kinds of weapons such as sharp python skills and panda3d witchery! We be lookin' ter hire the most mighty and savvy o' pirates! Join us on discord to be tested in yer swashbucklin skill [POR Dev Hunt discord server](https://discord.gg/S5veXMk) (Pay will be discussed upon meeting/hire.)
By default, Numpy uses parallel threads internally. Whether they are used for matrix multiplication, I don't know. But numpy certainly uses vector instructions all over the place, which are probably the most important reason for the speed difference. 
It's really very unclear what it is you're actually trying to do. Part of this is the language you're using. You should really make an effort to get the fundamentals down, including what things are called. What you're calling a "stack" seems to be "nested loops" for instance. But that's a guess. Anyway, looks like you need to use `zip` here: for reflat,reflong,donlat,donlong in zip(reflat_list,reflong_list,donlat_list,donlong_list): print (distance(reflat,reflong,donlat,donlong) `zip` groups elements from multiple sequences like this: x_coords = [1, 2] y_coords = [8, 9] points = zip(x_coords, y_coords) print(points) [(1, 8), (2, 9)] 
The parquet integration is pretty exciting. There are other libraries to do the same but I wonder how it compares in terms of performance. # PyArrow import pyarrow.parquet as pq df1 = pq.read_table(path).to_pandas() # fastparquet import fastparquet df2 = fastparquet.ParquetFile(path).to_pandas() and now pd.read_parquet() Is it using either one of the other two under to hood? 
atom 
Yeah, one of the biggest frustrations so far has been my lack of proper language. It makes looking things up difficult. How do I refer to the internal numbers of the zip points for the distance formula? When I run your exact example it produces &lt;zip object at 0x03C2A0D0&gt; instead of [(1, 8), (2, 9)] EDIT: I figured it out. Print needs a * print(*points)
Man, Big Brother needs a way better password than this smh
it's here: Macintosh HD -&gt; Users -&gt; Me -&gt; Desktop. so would I write that like this: data_file = pd.read_csv('Macintosh HD\Users\Me\Desktop\state.csv')
He indented his code. He would have been considered a coding documentation god back then.
They have army MPs as guards*. I guarantee you that the password was '1234', '0000', or something similar. Maybe, maybe, if they wanted to make it easy for the scientists, they'd make it '3142'. Oh, who am I kidding? They probably have it written down on a piece of paper next to the computer. re: Army comment. I served in the Army in the early 90s. Humans have and always will be the weakest link in security.
First off get rid of dictionaries. Use numpy with the int16 data type and you'll reduce your memory usage by a factor of ~8x. You could be fancy and use int8, but unless you really need to save on memory, it doesn't matter. You're using the wrong language if you care that much.
Is password_already_known[:4].isdigit()?
I kind of want to see native FORTRAN. C really isn't the tool for matrix multiplication.
I wish I could see it with C using BLAS. But alas, already asked too much out of my friend.
It absolutely was possible in the 80s. Basic had been around for over a decade at this point.
This is really cool! Nice work
Yeah, the BASIC thing was a stretch honestly, since a much more believable exchange would have been 'What's the password?!' ... 'It's written on a sticky note next to the terminal!'. It wouldn't have been nessecary to get Bob to go either, since Jim would have said 'Computer?! Do I look like an astronaut?!' It would have been more than likely that Jim would be more terrified of doing basic computer things, more than the demi-dogs. 
&gt; I wrote a quick Python script (see below (this is currently hosted in a private repository so I can’t exactly link you to that but you should get a good idea of the script)) Ummm, okay? Neat, otherwise.
You can setup a dyndns (no-ip.com etc) or use ngrok or something. It'll create a publicly available DNS entry that'll tunnel to your service on your machine. The clients simply need to remember that dns name (like facebook.com)
C has fixed the aliasing speed problem now. What is the main advantage fortran still holds? Easier concurrency?
AH! No I meant the python.
Maybe I explained it badly but I mean that the end user will run their server in their LAN then conenct to that one instance
It was not only possible, but not at all uncommon. This was a rudimentary environmental control system. Something like that would have been talking to a serial bus of some sort to trigger servos and controllers. A BASIC interface to such a system would have been the path of least resistance by the standard of the '80s. For the record, in 1984 I was programming in BASIC on a Radio Shack Color Computer 2.
~~Ah Gotcha. And I presume http://localhost is not what you want?~~ My Bad I'm a dumbass
Thank you! 
Libraries. (If you're at all serious about this stuff, the Numpy code isn't calling C, it's calling hand-optimized assembler for your platform via Intel MKL or ATLAS or similar).
In the show, he's trying to brute force a 4 digit PIN. He needed to generate all 1000 possibilities as 4 digits, so he needed to pad all numbers from 0-999 Iterating from 1-9999 would produce a bunch of invalid (1-3 digit length) inputs 
I probably didn't explain it all that well. The repo itself is in a private gitlab repo. My source for this cli app is part of that repo. The code is mirrored to the the github gist that you see in the article. Sorry for the confusion :-)
If you’re so concerned about spoilers maybe you shouldn’t be trawling around this sub days after the second season dropped.
Righto, just seemed like an unnecessary tidbit, is all. Either way, you've inspired me to pursue a similar project; I'm tired to finagling with prebuilt wikis and features I don't need. Cheers!
Ah thank you! This is an awesome comment. So I am a researcher and I am prototyping a new method for a hash based feature recognition. (It is an applied problem. I’m an engineer not a computer scientist) Currently I am working on modest size problems 0.1-10 million keys exclusively using python dictionaries, but eventually, I would generate 1 billion key hash tables if I could. This optimization is just a fairly significant boost I can do in place. My tuples consist of 10 ints, therefore, i will be saving around - 28 bytes per int * 10/2 ints per tuple * 10 tuples per set * 10,000,000 sets - by changing a single line of code. I think that’s awesome and it is all that I currently need for my problem. In the future I will be looking into different data structures. I only shied from numpy because I did not see implementations of dicts or sets, and implementation velocity is critically important.
Yes, it's a matter of perspective as I tried to explain. Thing is, I read multiple times that Go has a syntax as simple as python. For an experienced programmer like you it may feel like it, but not for beginners or people who only know python. 
I know BASIC could be used, but I don't think Python would be available.
Awesome!! Good luck!!!
"You seem to be having trouble remembering your password. Would you like to reset it now?" - Microsoft Bob
All this is really doing is comparing naïve C with optimised C. 
I wonder if it really is hand optimized. Compilers are much more capable at optimizing low-level code than any human nowadays, or so have I heard.
There are on the order of 10MM tuples, therefore the overhead memory of an int goes to 0. When N=10 we can assume half are already interned, which makes Neff=5. That corresponds to a 244 -&gt; 104 reduction in size. I am essentially shaving off a whole layer of python memory consumption with one line. A numpy array could also shave off the pointers at the expense of adding the cost of the int16 back.
I don't understand why interning has such a small range (-5 to +256 I think). The amount of extra memory used to intern up to 1024 would be minimal. Why doesn't the interpreter do it?
I think the python - c comparison is more about interpreted vs compiled and compilation optimization vs run-time optimization.
If we can trust Wikipedia (https://en.wikipedia.org/wiki/Math_Kernel_Library), then the Intel MKL is.
**Math Kernel Library** Intel Math Kernel Library (Intel MKL) is a library of optimized math routines for science, engineering, and financial applications. Core math functions include BLAS, LAPACK, ScaLAPACK, sparse solvers, fast Fourier transforms, and vector math. The routines in MKL are hand-optimized specifically for Intel processors. The library supports Intel and compatible processors and is available for Windows, Linux and OS X operating systems. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/Python/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
nice! starred incase i feel inspired during the games this week :)
In a comment I explain. /0.1 - 1000 million key dictionary of sets 1 - 100 item sets of tuples Tuple of form (4char str, int16 x 5, 4char str, int16 x 5) The upper limits are theoretically where I would like to go. I’m currently at about 10MM and 10. Realistically, if i could have dictionaries with parallel read access that would be ideal. Read performance is not the bottleneck. (Hash lookup is obviously necessary though) Therefore, I was thinking about moving to a shelve, but I can’t concatenate shelves because I will need to set my sets to immutable to put them into the shelve. Also my keys are numpy int64, and shelves only support string keys (which I am guessing is due to interning). Concatenation is important because I distribute data generation/population then I return small dictionaries and add them to the master dictionary. Realistically, I am going to have to shift over to something like a google sparse hash map, simplify my struct, and do bit packing if I really want to hit those upper limits. This first go is a prototype, which lucky for me seems to work really well!
You are right, you need `zip`, but you don't need to do anything to the distance function to use it. This works: reflat_list = [1,0,-1] #reference point latitudes reflong_list = [1,0,-1] #reference point longitudes placelat_list = [1,0,-1] #place point latitudes placelong_list = [1,0,-1] #place point longitudes def distance(x1,y1,x2,y2): #distance function return (((x2-x1)**2)+((y2-y1)**2))**(0.5) for reflat,reflong,placelat,placelong in zip(reflat_list,reflong_list,placelat_list,placelong_list): print (distance(reflat,reflong,placelat,placelong)) --- If you have more questions like this it's better to post them on /r/learnpython. Be sure to [format your code for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) or use a site like pastebin. Also, include which version of python and what OS you are using. 
This has been useful a thousand times over. Thanks for the help and the posting advice. EDIT: it looks like this only directly compares individual points (rpoint1 to place1, rpoint2 to place2,...) not each to each other (rpoint1 to place1, rpoint1 to place 2,...). Not quite what I was looking for but I am significantly closer than I was.
8
I remember when Windows required passwords for the first time ... Years after I started using it.
Interesting. What do you mean? As far as I can remember, the aliasing rules were left unchanged between C99 and C11.
And don't forget that numpy releases the GIL while crunching, so no parallelism issues.
gonna assume there's backwards compatibility issues when these types of questions are asked.
Yeah, but then we call it "customer requirements"...
in fortran array parameters are assumed not to point the same memory. It's like in c99 and upwards using the restrict keyword for them. Before that a c compiler couldn't optimize access to them like fortran could. A way around this could be using large static arrays. That was also the only way in fortran 77 and earlier btw. I'm not sure if older c compilers where smart regarding that but fortran certainly was. It was competing with hand written assembly from the start of it's life.
You know "this sub" is /r/python right? I'm not saying this is much of a spoiler, but /r/python is probably the last place I'd expect to see one.
 def four_digit_password(): passwords = (f'{password:04d}' for password in range(10000)) return next(password for password in passwords if check_password_match(password))
Compilers are better at low level code now, except for math, where they sometimes cannot figure out how to apply SIMD as well as person can, or that it is possible in a given case. Sometimes the issue is the lack of a C instruction that expresses a concept so it’s easier to put in assembly. For example “do step 3 or the AES encryption algorithm” has no equivalent C apart from compiler intrinsic. 
So I remember well, C hasn't resolved the aliasing issue. Restrict is just a standardized way to help the compiler, but it is not so straightforward to use and it can open the gates of hell if you don't know exactly what you are doing (overlapping memory windows, memory access channels and stuff like that is total madness). After years using both C and Fortran for numerical stuff, I'm convinced that if you are going to do number crunching on dense structures, the latter is the way to go.
Yeah. It really doesn't show much. This is just one evidence that even with a JITs, python is not as good (performance-wise) as C. However, it really good when compared with CPython. I think it is cool. :)
I would use a simple switch statement wrapped in a function, like so: def wordToInt(w): switch (w): case "one": return 1 etc edit: I didn't take into consideration integers higher than 9, to parse an int from a word higher than 9, a function with two switch statements, one for the precursor (ie 'twenty' in twenty-two) to define the first digit and a second switch to parse out the second digit should do you right. To make the parsing easier, use a .split() with whatever delimiter you're using.
Whoops, my bad! Totally thought I was somewhere else.
np.inf is an implementation of the IEEE floating point representation of infinities. What could be happening is that you're running into floating point stability issues edit: try using `points=[val1, val2, val3,...]` to indicate points for `quad` to pay attention and switch its integration strategy.
`abs` is a built in function in python that returns the absolute value. &gt;&gt;&gt; abs(-2.3) 2.3 --- If you have more questions like this it's better to post them on /r/learnpython. Be sure to [format your code for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) or use a site like pastebin. Also, include which version of python and what OS you are using. 
`abs` returns the absolute value of a number - that is, the number with the sign dropped. Also, please post questions in /r/learnpython :)
Ok thank you, I have just realised I don’t need it in my code anyway, but could you give me a simple example where abs is necessary? 
My company publishes a lot of Youtube videos. As a proof of concept, I wrote a script that goes through all our videos, takes each video's all-time views, and writes that information into our Salesforce database. Now I'm soliciting feedback on what other fields people want to track in Salesforce, such as average time watched and top traffic sources. 
Thank you and sorry new to python
Yours, not your's
absolute value is a basic math concept; like addition or division. Anywhere your math requires an absolute value you would use the `abs()` function. The first example I can think of is calculating distance between two points. 
Thank you very much! Means a lot!
[This stackoverflow answer](https://stackoverflow.com/a/493788/2714534) is pretty good, and should be a good base for whatever you need.
Poor zfill() Always forgotten about :(
&gt; you fire up a python script and it opens the web browser for you. Do you know what OS you need to support? and will they have python installed? On windows you can do somthing ugly lik`os.system('explorer http://192.168.1.1') but then you need to hardcode the IP. Another options is to see if the LAN has a central DNS and if the admin will add a entry pointing to your IP, so then users gan got `http://awesomeapp.lan` or whatever you guys decide to call it. Finally and this is the one I'm going for at the moment. Is to use Lazarus IDE to build a simple application that opens up the browser and exit. We have some extra checks in the app for login and it works nice on win and linux, struggling on mac with xcode atm. Downside now you need to distribute a exe, which at the end of the day also have a hardcoded ip/dns except if it calls home, but that another problem.
And another one using the built in zfill string function: str(p).zfill(4)
The vertical axis should really have a log scale
New python dev here. I use zfill()! :)
I agree, fortran was made for scientific calculations. It always had complex numbers and a lot of math functions builtin. In modern fortran this is extended so you can do array operations which is really neat. And if you want to use an optimized library for specific functions instead of the builtin ones it's usually a compiler switch to toggle.
Python doesn't have switch. Some alternatives: https://stackoverflow.com/questions/60208/replacements-for-switch-statement-in-python
ELI 5? GIL?
Agreed
Again, you are passing the answer to `crack` (which makes your lambda not only ugly but useless too). If you insist on using a lambda, why not just use this? crack = lambda pw: f'Four Digit Password: {pw}' &gt; [Always use a def statement instead of an assignment statement that binds a lambda expression directly to an identifier.](http://pep8.org/#programming-recommendations) 
So, I can't really explain *anything* without using words like "iterable" and "sequence" which have specific meanings in python. So I'll explain what those are, *BUT* my definitions won't be *strictly correct*. But they'll be good enough for this discussion and good enough to basically understand how those words are used in the python docs. So, an *iterable* is an object whose members can be accessed one at a time (iterated over). Strings are iterable. Lists and tuples are as well. So are dicts and sets. A *sequence* is an *iterable* that also has a specified order. Lists, tuples, and strings are sequences. dicts and sets are not. A list has such a thing as a "first" or "last" element, but a dict does not. `[1, 2]` is a list with members `1` at position 0, and `2` at position 1. `(1, 2)` is a tuple with members `1` at position 0, and `2` at position 1. so `[(1, 8), (2, 9)]` is a list, with tuples as members, etc. What you did with the star (`print(*points)`) is called 'unpacking', which takes the elements of an iterator and uses them as arguments to a function. So these are equivalent: mylist = ['a', 'b'] print(*mylist) print(mylist[0], mylist[1]) So now you can see that the `zip` object must have been an iterable (because you were able to unpack it). Why it gives you an iterable `zip` object with the right elements in the right order instead of just giving you the list I showed, is because you're using python 3, and I failed to account for that. A lot of built-in functions moved to this behavior because it's more memory and sometimes CPU efficient, but it does make things a bit harder to write to the screen or to a file. What you did works, but converting it to a list gives you a more correct view like this: `print(list(points))` Also, the documentation for python is actually quite comprehensive. https://docs.python.org/3.6/library/functions.html#zip The tutorial is a good resource for getting grounded in the language (and the 'language of the language')
Se the third graph.
There's DOZENS of us!
https://en.wikipedia.org/wiki/Global_interpreter_lock
My bad! I've been in Scala-world for the better part of six months for work and my Python is obviously getting rusty.
Making some of the tests in scikit-learn more robust. Working hard on a pull request that will allow them to check estimator that deal with pairwise data (SVM, KNeighborsRegressor, etc)
Get a head start on getting it up and running with the WSGI config. Learned the hard way that it's not trivial!
Really interesting. Thank you!
Oh I can't blame you, I haven't used it in a while either. Switch is the kind of thing you don't use all too often, so you kind of forget the implementation specifics and as it turns out, the implementation in Python is nonexistent. 
Wow this is great thank you. I've tried this myself and failed miserably. What pitfalls did you have?
So...it's like Ansible, but for general shell commands?
How come every one of these articles is only talking about *web* APIs? I'd like to see one of these articles on true Application Programmer Interfaces, not just on Web Development Interfaces. 
I am pretty sure you could not indent the code back then, not that it would have been very helpful with the 40 character screen. Line numbers were required, without a line number it was considered a command. 
C has always been unsafe though. So from a C point of view, this issue is fixed and there's no technical restriction in the language that's resulting in lower array performance. Then again, some people think they like hurting themselves :)
&gt;What could be happening is that you're running into floating point stability issues Okay, what does that actually mean? &gt;edit: try using `points=[val1, val2, val3,...]` to indicate points for `quad` to pay attention and switch its integration strategy. That does not work unfortunately (because of the infinity):`raise ValueError("Infinity inputs cannot be used with break points.")`
All python all the time? Pycharm. All JVM, or a little of everything? IntelliJ.
Global interpreter lock. A cPython interpreter can only run one python thread at a time. It won't affect you if you're waiting on the operating system or external program. For example your Python program can handle disk reads, or calls to C, or network connections concurrently since those things being waited on aren't being done by the same interpreter. However if you're doing computation in Python, it will affect you. It's like you have 2 chefs but they share the same knife. In the case of external calls, they're waiting for deliveries and there can be any number of delivery vans on the road to the kitchen while the chefs carry on concurrently ordering.
Why do you question if we can trust wikipedia for this?
Found a mini course/channel about machine learning using python, going to be working through it.
Maybe OP's name is Your
To be honest, I had more than a few problems. Biggest one being the almost complete lack of documentation, forcing me to use the original C xlib docs, I'll let you imagine how many things are different, from the naming, to the data types with anything in between these 2 things. In the end I had to avoid features I wanted, and took days to make relatively simple things (an example, there is supposed to be a practical way to make a virtual keyboard work but in the end I went with "redirecting" the key events, a shortcut that took me 2 days alone, and I still don't know why I need a display.sync call but it doesn't work without it). Sadly there are not a lot, nor great to learn, examples out there, which is why I ended up making this a public git repo, in the hope that it can help someone who wants to try to make a wm. If you have any question I can help with just ask.
Who cares? The whole point of languages like Python is that when you write in it you save huge quantities of time and hence money.
Nice, but reminds me a bit of the [sh](http://amoffat.github.io/sh/) module, did you know about it? Distinctive features?
You didn't tried the MKL library by Intel, which speeds up operations like matrix multiplication.
&gt; Interning isn't going to be that important since you still have to have a pointer to the object in question I am not aware of any concept of a pointer in Python, so please explain what you are describing.
&gt; This optimization is just a fairly significant boost I can do in place. How do you know that? Have you tested it, or are you guessing?
Agree. Unfortunately, it seems that API is becoming a synonym of web API. This is a pity because in the vast majority of situations, when you are done designing that handful of post/gets, your *true* logic code ends up as an ugly spaghetti mess.
Just cPython, doesn't apply to Jython or IronPython, or ...
Dreadful, please don't bother saying anything else :-(
Do share. 
If it doesn't run version 3, it doesn't exist. But you are right, I was thinking of cPython when I wrote that, and I should have mentioned that.
terribly sorry, should have included it! [SirajRaval](https://www.youtube.com/channel/UCWN3xxRkmTPmbKwht9FuE5A) really hope the link works! It's to his channel, the example code doesn't always work, but the GitHub link in the description has always served me well. I also really enjoy his style of delivery, it's quite enthusiastic! edit: i'm working through the deep learning playlist
I would definitely love to write about true APIs but just beginning to get on the blogging wagon so stuck with a more general topic. However, I would suggest checking out this talk(https://www.youtube.com/watch?v=4mkFfce46zE) from PyCon 2017 which is quite useful when building libraries or APIs, the one you are referring to 
A stock trading bot. I'm only running simulated transactions right now but it looks to be promising, made $200 last week. 
Awesome, thanks for the advice!
I've found that the hardest part of scraping sites that use JS is authentication. Afterwards, simply knowing what resources the JS utilizes to populate the DOM is usually sufficient. A pattern that has been very successful for me is to authenticate using `selenium`, then extract the cookies (and sometimes useful headers) to use with a `requests` Session.
That's really cool. Sorry for the ignorant question, is the recognition algorithm running on the Arduino or is it linked up to a PC or something? I guess I am asking because I thought Arduinos could only use micropython which I would imagine doesn't work with scikit? Thanks!
very nice :)
Please see and contribute to [the Python OOP list](https://github.com/metaperl/python-oop) and also if you might get more feedback in /r/learnpython 
Your loop: for (i = 0; i &lt; n; ++i) for (j = 0; j &lt; n; ++j) for (k = 0; k &lt; n; ++k) m3[i][j] += (m1[i][k] * m2[k][j]); Change the for loops order i,k,j instead of i,j,k. You'll see the performance improve drastically, due to cache efficiency. BLAS libraries typically don't implement sub-n^3 matrix multiplication algorithms, and they are also typically multithreaded. On Linux, you can force a process to run on one core only using `taskset`.
Gonna maybe try and write my own WM in Python. Nice work.
It's often somewhat out of date for niche topics like this. 
Very cool. You have a line ``c: long = 6``. ``long`` isn't a python3 builtin type, maybe this is an error from python2 ``long``?
Numpy matrix multiplication uses blas/lapack under the hood. These are extremely highly optimized libraries, with a core written in assembler. This is why numpy is insanely fast like that. So what you are testing is python overhead + handcrafted assembler for the speed critical path, vs naive C implementation. If you want to take a glimpse into what it takes to make matrix multiplication fast, here is an interesting site: http://apfel.mathematik.uni-ulm.de/~lehn/sghpc/gemm/
Looks better to me. Did you try it?
He means that the python code is essentially just calling heavily optimized C code. 
There is a pyparsing parser for this at http://pyparsing.wikispaces.com/file/view/wordsToNum.py. It includes these test cases: test("one hundred and twenty", 120) test("one hundred and three", 103) test("one hundred twenty-three", 123) test("one hundred and twenty three", 123) test("one hundred twenty three million", 123000000) test("one hundred and twenty three million", 123000000) test("one hundred twenty three million and three", 123000003) test("fifteen hundred and sixty five", 1565) test("seventy-seven thousand eight hundred and nineteen", 77819) test("seven hundred seventy-seven thousand seven hundred and seventy-seven", 777777) test("zero", 0) test("forty two", 42) test("fourty two", 42) 
yea, no dice. getting this error message now: "SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 12-13: truncated \UXXXXXXXX escape" : /
Are you scraping the website? if so you are doing it the hard way ... use twitter's api. A popular library to use the twitter api from python is Tweepy. --- If you have more questions like this it's better to post them on /r/learnpython. Be sure to [format your code for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) or use a site like pastebin. Also, include which version of python and what OS you are using. 
An idea, how about having a @statically.typed(infer_int=True, infer_float=True) def func(): ... Then you could make ``a: int = 4`` be interpreted as a cython int (i.e. looser annotaions)? Would there be any downside to that, especially if you're sticking to python builtins?
Wow, awesome, thanks!
ITT: Surprise that a library built solely around mathematical computation and developed by an entire team beats my hand crafted solution.
Single line implementation, for funsies print('Password is {}'.format((p for p in range(9999) if check_password_match(p)).__next__()))
How does this syntax even work? Is it a Python3 thing? first_var, *_ = foo() second_var, *_ = _ third_var, *_ = _ fourth_var, *_ = _ etc.
I am not personally surprised numpy is faster really, more like how faster c is to pypy.
[PEP 3132 — Extended Iterable Unpacking](https://www.python.org/dev/peps/pep-3132/) 
Why, that's the same code as on my luggage!
What implementation of BLAS/LAPACK are you referring to? The original ones by BEL labs is in FORTRAN 77
That's pretty awesome - I had no idea it was possible to: - Run X on a Kobo Touch - Build windows managers in py :)
Yes, is an error from python 2.
Ok that's fair. Code can change pretty fast.
I need to think how implement it. But now, i don't see any downside.
I feel like as soon as you're tempted to do anything that's not simple, one-line tuple unpacking it's often better to return a namedtuple or `attrs` class so you don't need to unpack anything at all
I agree, but the same style guides can apply for long variable names. Imagine instead of having 12 variables, you only have 3 but you want their names to be very specific. (this_is_the_variable_that_does_the_cool_thing, this_is_another_long_name_variable_that_we_need, some_random_variable_that_we_also_care_about) = foo()
I was going to, sounds like you're talking about highly optimized old school as shit Fortran dude. 
Put an r in front of the quotes
Your code doesn't work. 
One option is to first sort the array by the second column, then use `itertools.groupby`. [Description of the process here](https://stackoverflow.com/questions/8116666/itertools-groupby/15250161) Also most people here would probably direct you to r/learnpython or various other learning sources. 
Isn't upnp designed for that? granted, some people might disable it on their network, but i guess you could always give the hability to enter the ip for them, since they should be tech-savy enough for that.
I'll take a look at the process and also post my question on that subreddit. Thank you!
It's python 3. Python 3.5.3 (v3.5.3:1880cb95a742, Jan 16 2017, 16:02:32) [MSC v.1900 64 bit (AMD64)] on win32 Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; def check_password_match(p): ... return p == 1234 ... &gt;&gt;&gt; print('Password is {}'.format((p for p in range(9999) if check_password_match(p)).__next__())) Password is 1234 &gt;&gt;&gt; Edit: works here: https://repl.it/N7lX/0 
If you're comfortable with defining Classes, Class Methods, and have a basic understanding of Class inheritance, you might want to take a look at meta-programming in the language. It's helped me a ton in my day-to-day debugging, and has helped me write cleaner,e easier to extend code. David Beazley gives a great talk on it: https://www.youtube.com/watch?v=sPiWg5jSoZI And I really enjoyed this talk: https://www.youtube.com/watch?v=cKPlPJyQrt4 -- though it may only be loosely related to what you're after 
I'd not use Python where performance really matters, like big HPC stuff. Yes it can go great lengths with numpy, but when you have to do heavy number crunching with a few hundred terabytes of data, you need to get down to the metal. I'd perhaps not write big desktop apps or heavy 3D applications with it. Otherwise I believe Python to be one of the most successful languages we have, it can really get you very far very fast.
Keep trying... the passwords are 4 digits (which can be hard for numbers less than 1000... unless you use a string) * https://repl.it/N7lX/1 * https://repl.it/N7lX/2 
The reference LAPACK (including BLAS) [has Fortran (BLAS) and C (CBLAS)](https://github.com/Reference-LAPACK/lapack) versions, but you'd want to use an optimized version instead (at least on the lower levels). [OpenBLAS](https://github.com/xianyi/OpenBLAS/tree/develop/kernel) (successor to GotoBLAS) is a mix of assembly and C. Presumably MKL is similar. 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [xianyi/OpenBLAS/.../**kernel** (develop → ab87ee6)](https://github.com/xianyi/OpenBLAS/tree/ab87ee6b488c8fb491cf483eda85cd3fc6e5e3c7/kernel) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dp656jf.)^.
Embedded systems
Good luck
You can put a full debian distro on a kobo touch, you can look of marek's thread on mobileread
I'm pretty sure it's an implementation detail and therefore changeable as they please, like when they made dictionaries ordered. 
Thank you.
In the original Basic in the screenshot from the show it's an integer, not a string of four digits. But again, it's [for funsies](https://www.urbandictionary.com/define.php?term=funsies). This isn't production code, fam. Happy Halloween.
For OP, you have the same issue here, and it's even more clear why it's an issue: &gt; for (i = 0; i &lt; n; ++i) &gt; for (j = 0; j &lt; n; ++j) &gt; for (k = 0; k &lt; n; ++k) &gt; m3[(i * n) + j] += (m1[(i * n) + k] * m2[(k * n) + j]); If you made the loop on j the inner loop, you'd be accessing adjacent elements of the array one after the other instead of taking giant jumps around the array. There's a lot more going on than just this, but this is a pretty important rule when trying to write efficient code: keep your memory accesses as close together as possible.
Very cool. How does it handle other characters or nonsense?
Are you having trouble reading (the picture is a bit blurry)? The variable name in the BASIC program is `FourDigitPassword`. It seems fairly obvious that if you need four digits (and can't guarantee that the password is always between 1000-9999 inclusive), you are going to need a string. 
Embed an interactive matplotlib in PyQt
I'd still stand by the general rule of "if your assignment takes more than 1 line, refactor the underlying code."
Here: https://i.imgur.com/eJZriKm.png 10 DIM FourDigitPassword INTEGER It's an integer. Why are you trying so hard to prove me wrong? Did I offend you? It's okay, it's just a stupid snippet of code.
Floating point operations work well for the most part, but can run into edge cases where the result of an operation does not yield the expected (in the mathematical sense) answer. This is especially prevalent when dealing with small numbers. Try posting on stackoverflow for more help.
thanks. it didn't load on mobile
I'm not offended at all. I just dont think `123` or `57` are four digit passwords. 
So, numpy does it's paralellization in C and the GIL has nothing to do with that. The fact that it releases the GIL only affects you if you are running numpy methods in python threads, and it's rare that the overhead of threads doesn't totally overshadow the operation, plus make the code a fricken mess. Especially since numpy only does pretty basic operations and any algorithm is going have or grab the GIL almost constantly. Even with numba where you can write complex vectorized functions, the arrays have to be huge to see any gains with threading.
Google it. You will tons of examples like Twitter Bot, Youtube Bot etc. Try it out. Cheers.
I just started learning, so I will be working more on learning. Strings, Variables, if/else and functions.. I know not as cool as some of the others but it's time to learn for me! 
It can only process one digit numbers at the moment. But I could train it to know the whole alphabet. It will just take time.
It is hooked up to a PC. 
Here's the corrected path to use: pd.read(r'/Users/Me/Desktop/state.csv') You can get this yourself by opening up the Terminal application and then typing these two commands: cd pwd This will get you the full path for your Desktop and then you just need to add the file name at the end
Definitely! Actually, I am planning such an integration for v0.3.0, which might look something like this: class GitHub(uplink.Consumer): @get("/users/{username}") def get_user(self, username) -&gt; UserSchema(): """Fetch a GitHub user by username.""" Given we've defined a `UserSchema`. Then, calling `get_user` would return a deserialized object using this schema.
I'm new to python, but i started working on a small project that is suposed to eventually simulate a small economy with about one thousand autonomous 'civilians'. The plan is to set it up to run constantly but with a simple command line or GUI interface from which i can attempt to manage small aspects of it from an abstract and indirect way. I want to get into artificial intelligence in the future. This project is supposed to act as my learning playground for AI. I really like the idea of automated simulations. So . . . that's what I'm up to. 
Coincidentally, in the Unity game development platform, there is a typesafe variant of python called Boo. Not many people use it but it's intermixable with the platform's javascript-like language. I kinda like the Boo myself.
Trading off technicals? 
You know, if you put `from .api import *` in your `__init__.py` then users can use your library with just `from sultan import Sultan` and not have to care about its internal structure.
I just started learning Python as my first language. It humors me that today I finished ST2 and caught myself looking at the code in the scene. Then, I get onto this Reddit and see y’all have taken to it already.. everything I thought about coders is proven true lol
REST APIs are fine for browser interop. But for app-to-server and server-to-server situations people should really look into protobuf and message pack. And if you want to invoke functions gRPC is another option. 
What order/transaction completion time are you assuming in the simulation? 
Selenium and phantomjs is probably going to be your best bet. Good luck
That would be another very interesting topic: how to design a good protocol for processes communicating via sockets (web sockets or otherwise). I stumble upon this regularly: two processes need to communicate complex information, ranging from web-style "please invoke API method X" to fully-general "call function X with arguments Y, then return the result or error". A well-defined API might use some bespoke data schema, while the fully-general case needs a generic data serialization system. And there are many interesting questions, like how to design side channels to communicate things like crashes or heartbeats or logging or CLI output. Or how to deal with security if one socket endpoint is public. Or how to serialize complex data efficiently. That is another article that would be highly interesting. 
I remember poking at Boo a few years ago. I think it was already abandoned at that point though
All this is doing is comparing one set of microprocessor instructions to another....
Wouldn't surprise me. I saw like a 50% improvement over OpenBlas using MKL.
Always nice to see the data on this. Can help to shut down anyone who wants to write custom C code thinking they can beat numpy with it.
Working with flask framework first time. I think its very useful and suitable for rapid development. If you trying to start a MVC project rapidly, I advice it. Also working on machine learning algorithms with numpy and matplotlib.
1: read the sidebar 2: /r/learnpython 3: read the sidebar
So it's like [Fabric](https://github.com/mathiasertl/fabric/), but without the command-line interface
&gt;I need to scrape all the edx courses You don't *need* to do that. If there was a need for it, the company would make it readily available through an API. Despite the lack of a documented API, all the data you want for edx is readily accessible in JSON format. For example, here is the first course on the site: https://i.imgur.com/EyDaDaB.png
I've used Arrow for that before. Also you can make your own wrapper classes for datetime, presenting the same API, but only allowing naive vs non-naive. Then you use those classes in your API. eg, with typing, I'd make small wrappers for what I'd normally pass around as strings (and then constantly recheck that it's a valid string in many other functions). Instead, instantiate a custom class that takes the string, checks it once in the constructor, and then type the rest of your code against that wrapper rather than string. You can implement __str__ and __repr__, __eq__, __hash__, __lt__, etc on the wrapper class. Do the same with eg, a NaiveDateTime type, and an AwareDateTime class for instance, passing a regular datetime object into them; and where their constructors check things. Also, I prefer not to use the Any type; since that lets a lot of really bad things pass the type checking, eg non-existant fields or methods that can be used without complaint. Mypy is also moving more in that direction; stricter checks = Any being alowed in fewer places. I prefer to use the 'object' type, which will unlike Any, complain for unknown attrs, methods etc. Just before then I can write assert isinstance(obj, CorrectClass), and then mypy will treat what was a plain object type, as being a CorrectClass object instead. Including things like methods and attrs. And at the same time get a runtime type check. Edit: You can do something similar and more lightweight by using Distinct types: https://docs.python.org/3/library/typing.html#newtype 
[This](https://www.mobileread.com/forums/showthread.php?t=222123) seems to be the thread. Great to see an active modder community around an eine device! And it's available at around 50€.
I would love to see that as well. I guess it might be harder because it is a more general case. I imagine (not being a web developer myself) that the web context constrains your choices a bit compared to a normal library.
Whats your question?
Same question for https://github.com/tomerfiliba/plumbum
The idea is you only care about one item and throw away the rest, hence `_` as variable name. Not sure why that was used in the example. Something like `*rest` would make more sense. The topic was code style after all.
Cryptocurrency ;) 
I have an open order / open sell state which goes and gets updates. In the simulation I only give it a 50% fill rate for orders as I have no idea what the real stat will be. The goal of the bot isnt to make millions though, just a few hundred a month would be considered a success. 
I use it for residential and some very small property MGMT projects. What are you trying to do?
So I'm currently working on learning Python. So far, I've learnt alot of and I seem to be having no problem getting my head around most of the beginners stuff, but what seems daunting so far is how the functions work together. I've wrote a couple of really simple programs, but damn I keep finding more and more ways of how different functions work together to create different results, or the same as the case may be. How do you remember all of this stuff. Just daunted by it at the moment, but I'm going to keep cracking at it and make sure I learn something new at every moment I get.
Yup, and it's much more lightweight than loading Ansible. 
The syntax, in my personal opinion, is better and more intuitive with Sultan than with sh module. It is very similar, I will admit.
I personally liked sh's syntax better but I wanted to improve how intuitive that was. I felt like the syntax of plumbum was not very intuitive. Just my opinion though, but I do carry it with a Bias :-)
I've write a little service to render these dynamic pages with chrome headless mode. here is a link: https://github.com/yifeikong/renderlet basically all you have to do is to: 1. start the service 2. visit localhost:8001/render?token=renderlet&amp;url=https://www.coursera.org/courses?languages=en&amp;query=free
That's true. I'll give that as an option in the next release! 
Yup. Fabric serves more as a tool for DevOps. Sultan isn't trying to compete with anything in DevOps world. It's more for projects where you end up writing a ton of Bash scripts to do certain tasks, and things get out of control since Bash doesn't have very nice package management, or testing. http://sultan.readthedocs.io/en/latest/faq.html
Fixed!
Free version, at least for now.
I have used pretty much every editor and IDE available on Linux/Mac, but these days I find myself using Intellij for other languages (mostly Rust and Kotlin) and I quite like it.
I have used both for a little while and the only thing that seems to be missing is the ability to have multiple language support in PyCharm, so I am going with IntelliJ. 
No, thanks. I use VSCode often but Atom just doesn't click for me.
I don't want to be rude since I made the post asking for help but your edit as well as you pointing out my grammar mistakes (for whatever reason you find appropriate ) is not helping anyone and your assumption that I made an overreaching promise for some reward is completely out of context on what is happening here. I really appreciate your time but please refrain from giving life lessons out of context when nobody asked for them.
Spoo.py
Like all good life lessons they're delivered gratis. You can take them, or you can ignore them. Refusing them just means you're going to learn them the hard way, or never learn them at all. The context here is you asking others to spend their time writing answers to trivial programming problems in order to help you take a cheat on helping a child cheat himself out of an education. Forgive me if I don't spend much time worrying about your attempt at advising me on what to do or not do with that time.
C being faster than pypy is a given. Java has a more advanced and mature JIT, and static typing, and they can only fight C in a small number of very narrow situations (relating to memory re-use).
Thanks for the great article! I'm going to steal your .sqliterc .One suggestion- add pics of the generated graphs. 
Not sure - we use OneSite software already so most of the info I need is already there. I do underwriting for Multifamily acquisitions and just wanted to see what other people were using it for in the industry (which is behind 25 yrs).
!RedditSilver
###[Here's your Reddit Silver, CondeTrocola!](http://i.imgur.com/x0jw93q.png "Reddit Silver") *** /u/CondeTrocola has received silver 1 time. (given by /u/PhaethonPrime) __[info](http://reddit.com/r/RedditSilverRobot)__
When you say “...to scale a vector to have...”, it sounds like you’re given a starting vector and you want to transform it so that it has both zero mean and unit norm. If so, my question is: what are you trying to preserve about the original vector? (In most cases, both the length and direction of the original vector would need to change.) If you are simply looking to generate vectors that have both of those properties, that’s a different thing...
\#!/usr/bin/env python3.6 print(“boo”)
Hi! On line 25 in your charachter.py you use item.describe() method. But it returns None(if there is no **return** statement in function, python returns None). def describe(self): print(self.get_description()) 
What is the learning algorithm that you use? Did you train it on a dataset like MNIST, or does it learn online?
You have: print( self.name + " is holding " + self.item.describe()) Here's the describe method that you're calling there: def describe(self): print(self.get_description()) That method prints your description and returns None (implicitly, because the method has no return statement), so the print statement in Character.describe has this effect: print( self.name + " is holding " + None)
&gt; When you say “...to scale a vector to have...”, it sounds like you’re given a starting vector and you want to transform it so that it has both zero mean and unit variance. Yes this is exactly what I have to do. &gt; If so, my question is: what are you trying to preserve about the original vector? (In most cases, both the length and direction of the original vector would need to change.) I am not really sure because I am trying to implement a tiny images and nearest neighbor classifier for images. And in the instructions it says to down scale the training images, resize to 16x16 , reshape it into a vector and then scale that vector to have zero mean and unit norm. I also think I should've said "shift" to have zero mean, and "scale" to have unit variance.
Ah Ha! So should I just have a Return, or is there something i should be returning?
If you do go to Stack Overflow, would you post the link to the question here, so we can follow? I’m curious what the collective will figure out about quad or np.inf. (My gut says it’s an issue with quad rather than “float instability”.) The answer to this [SO discussion](https://stackoverflow.com/questions/34877147/limits-of-quad-integration-in-scipy-with-np-inf) mentions a quad heuristic that might explain the weirdness, and proposes a debugging technique that might show conclusively what’s happening.
You can do: def describe(self): description = self.get_description() print(description) return description
I didn't know MNIST existed. But yes, I created my own data set like MNIST and trained from the data. I probably sat for an hour drawing 0 through 9. When I got bored I let scikit learn do its thing and bam. It worked :)
I use scrapy with splash to scrape sites with dynamically generated content. https://github.com/scrapy-plugins/scrapy-splash 
W00 Hoo! I figured it out! Thanks! For the record, I changed to my get_description method and it worked fine. I'm not sure why they want us to have both a get_description and describe method, but there you go. I suppose it didn't work because the describe method tried to print something inside the print I was trying to do as well.
Sorry, virtualenv says I'm still on 2.7
Honestly expected snoot booping... Was not disappointed.
Your doubts are a good sign, you perceived that asyncio is a complete mess of futures, tasks and loops that need to be passed around to make everything work. I faced myself the same question back in the days and, apart from technical considerations (all async approaches are about the same in terms of performance), I preferred to stick to the most standard one. Currently, different async worlds exist in the python world: asyncio, monkey patching (gevent and such), curio (and similar) and bare threads. The issue is that they cannot live together inside the same application, and when you wrap a sync library with an async API, you have to decide in which world you wanna live. As far as I have seen, in the vast majority of cases, people tend to provide an asyncio API (for example this for sqlalchemy: https://pypi.python.org/pypi/sqlalchemy-aio). IMHO, the real problem here is the lack of vision in the Python board of gurus. They care about typing (really???) and stuff like that that no one cares about, while the real issues that affect the language (vendoring and async, for example) are just left as an exercise to the community.
MicroPython makes strides to implement a fuller Python object model and can run CPython's datetime module with very minimal changes, while still keeping to its roots of being the smallest Python implementation with very reasonable functionality subset, and growing number of supported embedded targets, e.g. Zephyr RTOS port is growing. The detailed changelog is by the link in the title. 
Thank you!!!
Are you sure it said unit norm and not unit variance?
Yes sorry unit variance. 
Then I guess you can simply do: vec = vec - np.mean(vec) to get a zero mean, and vec = vec/np.std(vec) to normalize the variance 
In that case you can use [this](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) but since you are making a neural net, most frameworks will have a batch normalization layer built in.
see also http://scikit-learn.org/stable/modules/preprocessing.html
I'd say that if you're already comfortable with gevent, stick with gevent. You'll face far fewer roadblocks in terms of compatible libraries, and, as you say, the code is just cleaner. The only benefit to asyncio that I can kind of accept is for people new to async programming, or visiting from other languages that feature similar syntax. The syntax does make it more obvious what is happening. Of course, once the concepts click then it's not really needed anymore, so in the long run I don't think it's worth it. As for the future, asyncio isn't going away anytime soon, but neither is gevent.
There're problems with "the Python board of gurus" (f-strings and stuff, really??), but they aren't what you say. asyncio is *the* Python standard, which is pluggable and extensible and was elaborated from 3.3 to 3.6 closely. Of course, there were alternatives before asyncio and remain after, it's Python land, batteries, not straitjackets, are included. Vendoring (package vendoring I assume) is also maintained (that's alone a lot of effort, you know) and progresses, just recently some PEP was posted. The rest is indeed community matter, and recently we had 60,000 packages, now - 120,000. And those aren't the proverbial left-pads, you know. 
&gt; a typesafe variant of python Just curious what you mean by that? I usually think of regular Python as typesafe, but I understand it's one of those fuzzy terms like "strongly typed" that mean different things to different people.
Spooky.py
Sure, I'm not saying that no one cares, I know that a lot is going on (someone give a medal to the PyPA guys, their work is saving the whole community). I'm just saying that from the regular user perspective, it looks like the gurus are playing around with their own personal interests (I'm sorry, I tried to use it but I really don't get all the typing stuff) while the evolution of the language would need a clear vision from them. &gt; There're problems with "the Python board of gurus" (f-strings and stuff, really??), but they aren't what you say. I'm not into these kind of things but it looks like you're well informed, what are the problems in your opinion?
What do you use it for? 