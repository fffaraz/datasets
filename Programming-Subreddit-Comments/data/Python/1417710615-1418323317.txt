It looks like a fun proof of concept. Now all they need to do is implement a Python interpreter in Hy (preferably in one line of code), and then run Python code on Hy on Python. Something tells me Brainfuck would be the more maintainable solution and probably perform better to boot.
I was thinking in something like this, share data between cpython and pypy in a transparent way so you can use pypy always and when you need numpy, scipy,..., you can pass the required data to CPython in a clean way... (Maybe I was thinking something imposible, shared data structures, I don't know).
Reading this title all I can think of is Xzibit... Yo' dawg, I heard you liked PyPy and Jit so we Jitpy'd yo' Cpy' so you can PyPy while you CPy' with Jit.
Found this link that might help explain it better than I could. http://stackoverflow.com/questions/419163/what-does-if-name-main-do
I described it as all my treads were trying to reach into the same cookie jar (the file) at the same time and broke the jar and mangled their hands.
Great, best of luck!
Find a cheapo printer with the right kind of motor? There's bound to be loads of them lying around gathering dust, so picking one up second hand would be free, if you don't get paid for your troubles. XD
Thanks for the kind words! Always happy to share. I learned everything I know either from the internet or from trial and error. I wouldn't be here without others sharing.
Haha. Might I inquire as to what the task was? If that was happening, you might have been better off with a database. 
Thanks for the link, I didn't know about that project. I wanted a library that worked with pypy3, used greenlets, and designed more for practical wsgi apps with support for lots of popular third party libraries - so essentially gevent that worked on pypy3 and python3. Also, I'm using the LGPL, which is much more permissive than the GPL. Could always switch it if it becomes an issue.
Here it did not consume 100% CPU.
This is only really an argument if you think lisp syntax is significantly worse, which I'm sure many don't. Plus, hy maintains interoperability with all python modules, which is a major convenience.
I had a friend test and he did not get a 100% CPU usage spike. It seems like most people get stuck in an infinite loop. My system does not. I added the logging info to the post. It gets stuck on that last redirect that causes the spike.
I upgraded to requests 2.5.0 and now I get a TooManyRedirects exception, better then crashing the application. I agree with you they are doing something to screw with bots. Oddly enough I am setting a header to trick them into thinking I'm a real browser, I plan to remove this anyway and grab the robots.txt file. s.headers = {'User-Agent': "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:12.0) Gecko/20100101 Firefox/12.0", 'Accept-Encoding': 'utf-8'}
Couple more fixes? I can't get it to do anything pyqt related. I'm assuming there's something wrong with my setup then that's unrelated to this ide?
Sorry for typos, on my phone. Obviously. I am not a big fan of Lisp's syntax; that was the opinion I was expressing. The strength of Lisp's syntax comes from its simplicity, but it sacrifices readability for regularity. Lisp certainly has its ardent fans, but just as ardent detractors. Prefix notation, for instance, allows for great homoiconicity (a very interesting property), but it means that that you have to spend a great deal of time correctly grouping elements since it renders their syntactic role ambiguous - Lisp is (in)famous for its tendency to end a statement in multiple parentheses. It has historically been the biggest sticking point of the language. Python, however, has historically had it's *most popular* feature be it's syntax, with the exception being significant whitespace which is almost as controversial as Lisp's tendency towards repetitiveness. It's regular, intuitive syntax coupled with the dynamic typing and interpreter make it an ideal language for beginners. People tend to get caught up in learning the fickle syntax of C++ that they don't learn many real programming concepts until much later. It should be noted that Racket is a great introductory programming language if you like the functional style, but tends not to be as popular as Python for the same domain of problems because, again, it's usually considered easier to read. But what Python sacrifices to be so intuitive is performance. For instance, all Python lists are vectors - essentially a workaround so you don't have to think about memory allocation and such. Or just the fact that Python is garbage collected means performance and memory use is difficult to reason with. So my reaction to Hy is that it looks like the worst features of both mashed together. It'd be like taking the concise, but semantically difficult language Haskell and giving it the verbose syntax of Java, but without the virtual machine or great libraries. Like, they took the exact wrong features of both languages. I don't see much of a future for it.
allow_redirects=False isn't an option because I need to respond to legitimate redirects on other websites. A try except is good enough to listen for an exception now that I upgraded requests and get a TooManyRedirects exception.
My Ubuntu OS isn't up to date, it is still only 13.10
can one jittyfied function see another? how does that look on os level, is there a visible subprocesses or just the cpython proc? should I expect about double the memory usage due to the embedded pypy and all its stdlib?
:D Thanks for reading it. I'm glad it helped.
https://www.python.org/downloads/release/python-341/ Download the source. Read the README. Same for PyGame. There are also plenty of articles that cover the steps in more detail (which isn't much...)
Sorry for bad formatting... :(
Then I strongly suggest that you upgrade to 14.04 (or even 14.10) as your version is not getting security updates any more (and didn't get a security update for shellshock either) You can check end-of-life for Ubuntu version [here](https://wiki.ubuntu.com/Releases).
Is there any reason not to update it? 14.04 is the LTS and has 3.4 - may be the best of both worlds :)
Numpy arrays sounds good for me. How do you manage that? OTOH, a CPython object will be duplicated in Pypy? How much overhead (time and memory) will add this? A blog post explaining the internals would be very educative!!! BTW, thanks, pypy team.
No, I just never upgraded in the past as I didn't know how to upgrade without downloading it to a flash drive. I only learned how to do it from the terminal today and am downloading it right now.
Your code doesn't match your question! random.randint(0, 100) never returns a number bigger than 100, but it could return 0: https://docs.python.org/3.3/library/random.html#random.randrange count = 0 while True: count += 1 print(count) if random.randint(0, 100) &gt; 100: break 
Only downside to progress bars is that you need to know in advance what the total number of operations is, otherwise it's just a counter (which is useful too).
Well it could have "100" hard coded. The function yields arbitrary values between 0 and 100 depending on its progress. For four steps? 25, 50, 75 and 100.
Writing pure standard tests is fine and I understand it pretty well. However I am struggling to write tests when things are encompassed into a graphical framework. For my project I am using pyside, which functionality for writing these tests built in. But holy cow its not intuitive and verbose. What is the standard way for dealing with tests when they are involved in a graphical framework?
Could you post some simple example? Code completion in the Editor, showing help and the first signature work as expected. I know it because I develop Spyder with Spyder. The only thing I don't use is execution in our consoles because I simply can't. So if you give me a simple example I can use it to improve that.
Indent all code with 4 spaces to get it to display properly. Also, post question in /r/learnpython, not /r/python. Read the sidebars!!
Some feedback: I'd strongly recommend making stop not a local global variable. Make it a member variable of the thread class, or even better, put it in the decorator wrapper and close over it.
I don't remember what this fallacy is called. You're focusing only on the negatives of the two languages, while failing to acknowledge (or at most, providing only lip-service to) the positives that result from the combination. This provides an incomplete picture of the tradeoffs. Yes, Lisp's regular syntax is often considered less readable than python's, but it also allows for [powerful editing tools](https://www.youtube.com/watch?v=D6h5dFyyUX0) and [extensive modifications to the language itself](http://www.paulgraham.com/icad.html). As the comment above points out, a simple Lisp macro in Hy has already backported `yield from` to python2 - not the type of task usually within the reach of a non language dev. So yes, if you think that Lisp code is literally the devil, you probably won't be using Hy. Many people, however, don't consider it *that* intolerably worse, and for them, having a powerful language that integrates well with their existing python code can very well be worth it. 
I think it's a bit more divided than you think. There is plenty of 3+ code out there that will not run on 2+. That said, really 'knowing' python means you should be familiar with the differences between major versions and ideally producing 'future proof' code that runs on both. That means until about 2020 most would ideally only be developing valid 2.x code, with exception for the many projects that haven't yet been done without 3.x features. 
Or until you find a really cool 3+ only library and decide having both installed side-by-side is not and never should be a problem in the slightest. &gt; python3 ./project.py &gt; pip3 install nicemodule 
jitified functions see each other (there is also "extra_source" call). It's one process, with embedding so numpy arrays share data (no copying) yes, you can expect some memory growth, exact details will depend on the application (but you do have two interpreters to start with)
&gt; A blog post explaining the internals would be very educative!!! &gt; Basically, we copied how numpy storage is implemented, so you can share the storage, you only need to copy metadata every time
PyQt hands-down. Cross-platform, supports py3, is easy to use, even has graphical designer and is (Qt) very relevant in industry today. License is GPL.
Hey this is pretty cool. I suppose you should be able to call Hy functions from Python code and vice versa, right? Sometimes it's nice to be able to break away from your language's paradigm to write a snippet of code here or there.
I'm more or less taking large-ish datasets, and comparing parallel hdf5 I/o performance, via mpi4py. Its not true MPIIO stuff, but close enough to get a general feeling. Just trying to see compressed vs. Uncompressed, etc. I'd be interested to see how blosc compression impacts things versus uncompressed data, since the filesystem isn't slow to begin with.
Bookmarked, but I'm not a fan of the design.
You should be able to do it with a one line bash script. **find /path -type f -cmin -15** Or something close to that.
&gt; This is only really an argument if you think lisp syntax is significantly worse, which I'm sure many don't. Not to mention that Lisp syntax is extensible and semantics fluid, while Python syntax is inflexible and semantics awkward to modify. Whether this is a good or bad thing is, of course, an often contested matter of opinion.
CFFI structs would be nice as well. Some of us don't use numpy but still use pypy for our number crunching and passing bigger well-defined data sets easily would be nice.
Thank your for answering that fast. I have already taken a look at EasyGui and it looks promising. However, on the page it says "EasyGui project is now closed". I hesitate to introduce something that is already abandoned. 
Yeah, I understand what you mean. I'm using it at the moment in 3.4 without any problems, but it looks like it might not stay that way... :(
it isn't. what makes you think it is? fixed formatting: import random befaletSover = True count = 0 while befaletSover: print ("Ned!") print ("Opp!") count += 1 print (count) print () if random.randint (0,100) == 0: befaletSover = False
As of yesterday I'm calling C# from JavaScript. I love "now." So many cool things going on.
Found the link: http://dustycloud.org/blog/how-hy-backported-yield-from-to-python2/
Seriously, it's so much easier to just open up a terminal and start python than find out what is the standard linux calculator and install it. I still haven't even bothered to look it up since python is just *there*
 n = len(statsList) for index in range(n-1): sm = index for i in range(index+1, n): if statsList[i] &gt; statsList[sm]: sm = i this is what i had but you don't need two for loops, only one.
Sorting would be a very wasteful way to solve the problem: All that effort (to put everything in order) when all you really want to do is just find the biggest and littlest value in the list. Imagine I gave you a stack of a hundred cards, each with a number on it. How would you pick out the two values you care about? The obvious way would be to go through cards one at a time and keep a mental note of the largest and smallest values encountered so far. By the time you'd reached the last card you'd definitely know the answer to both questions!
Async workers work well with loads that are I/O bound, that is you are shuffling a lot of bytes in and out but you do not do calculations that much. One processor core is enough to initiate the shuffling of bytes even to many clients. Async in python is like multiplexing, the worker can shift its attention between many web browsers, and keep the pipe full for each one of them, by filling up the pipes with enough bytes that last until next time it gives attention to the response to that browser. I believe that a reverse buffer proxy is a proxy before gunicorn (e.g Nginx), that swallows up as many bytes as possible from gunicorn's response, so that gunicorn can offload all the bytes to that proxy in one fell swoop and then the reverse proxy takes care of shuffling them further to the connecting browser. In this way you can serve bytes to hundreds or thousands of connected clients simultaneously with reasonable performance. Now for CPU bound stuff: If you are running one async worker in python, it will only use one of your processor cores, and chances are that your web server hardware has 4, 8 or more. If you are not shuffling bytes, but instead need to perform complex calculations, it does not make as much sense to do this with an async worker. Yes, it will multiplex between the connected browsers, but since it only uses one core, all browsers have to wait for a bit of processing time on the same core. So all browsers have to wait. Gunicorn can however spawn several processes that work in parallel. The operating system will then schedule these to run on different cores (hopefully). In this way you can have several workers running at the same time, and finish the calculations independently and hence speedily, on different cores. Beware that gunicorn does not spawn processes immediately, but will execute some of your code before it spawns. This can wreak havoc with connections pools to databases. I've written a [little quickly put together class](http://jorgenmodin.net/index_html/process-safe-connection-pool-for-psycopg2-postgresql) that helps with PostgreSQL for such a scenario. So you basically need to figure out of your applications is I/O-bound, that is if the bottleneck is serving out lots of data, or of its CPU-bound, i.e. it needs to use all cores to do its chores. I've been working with a demo project that serves out files in connection with bitcoin transactions. I did this with nginx, bottle, gunicorn and postgresql. It turned out that my application was both I/O bound and CPU bound, depending on what urls you hit. The solution in tests seem to be to have several worker processes, each running an asynchronous worker (such as Tornado, which can run under gunicorn). You can use a benchmarking tool such as Apache ab and do e.g 1000 requests with 100 parallel requests to get a feel for if your applications seems to be CPU or I/O bound. Change between different kind of workers and see what happens performance-wise. 
Kivy is pretty easy although newer than pyqt it looks promising!
&gt; People have to maintain legacy code bases or use forgotten libraries no one else cares about. That are the only valid reasons for 2.x-only development ... I'm pretty sure laziness counts. I would probably stick with python 2, together with all the "battle tested" libraries until library authors start dropping python 2 support. That'll leave plenty of time for more advanced scripting languages with proper JIT support to rise.
I got carried away with flowchart #2 and don't feel like throwing it away :-) http://pastebin.com/H6e95t3u
Tkinter. Built right in with your standard library, cross platform, cross versions for the most part. I know few people have taken the plunge to do it, but Tkinter is a more than capable GUI creating module. If you're interested, I have a currently running series for in-depth GUI creation with Tkinter, might be enough to change some minds of the power of Tk: http://youtu.be/HjNHATw6XgY?list=PLQVvvaa0QuDclKx-QpC9wntnURXVJqLyk The series is still being released, but quite a bit of the code is available on Github pretty far in advanced to the latest video. 
I use pyqt mostly because it takes me less time to write. When do you feel pyqt feel becomes unwieldy?
I was playing around in Jython yesterday just to use the swing library. This may be a good option if the students go on to a java related course since swing is probably one of the more standard cross platform solutions. Pyqt is cool, but it's easy to get into dependency hell.
An expression is a thing that returns a value. They can be nested arbitrarily (`func1(func2(func3()))`) and aren't beholden to Python's whitespace rules, if it's unambiguius: x = [ 1, 2, 3] #[1,2,3] is the expression here. Statements are the fundamental building blocks of python code. They only occur at the root level. There's a special kind of statement called an "expression statement", which is a statement that's only an expression. `foo.func(bar)` is an expression statement, while `return foo.func(bar)` is a return statement.
A little, but I'm way more of a C++ Dev than Python.. With C++ I can abstract things enough so the non-coders (scientists) I work with can contribute efficiently. The Python version was written by them (I wasn't hired yet) and its really redundant and inefficient. I think its more up to the Devs to structure it in a way that's efficient.
Wonder if Hy + PyPy would be something good...
At that point you might as well just use PyPy, don't you think? Unless you have some specific compatibility issues.
Yea I totally understand. I'm an engineer working on building my Dev cred. Because I have to deliver analysis + my own programs I usually optimize for my own time. Where do you work?
Is there a command line option?
Well. You are missing a few things. "Poor-performing interpreter", doesn't matter at all. Hy was made to display the flexibility of Pythons AST. Don't you think it does that rather well? The end case was a overall neat language that some people like to use, as Lisp scratch an itch for some developers. But what else? Lisp is declarative. It's made to create DSLs, and thats what people have been doing. Creating DSLs is much neater and easier with any Lisp as you are programming it in its own AST, changing syntax as you go along. A great example is this: https://github.com/paultag/snitch/blob/master/example.hy Doing something like that in Python won't look at readable, no matter how much you hate Lisp. Should also note that Hy doesn't try to be a competitor in the Lisp marked, it's just a neat language over Python. One of the only ones that i'm aware of that actually takes this much advantage from the AST. As i mentioned above, you can run Hy on Pypy, if you want to remove the "slow" interpreter. 
I work at a small Engineering contractor that makes software tools the Navy uses to design their ships. We make crazy hydrodynamics and CFD programs the Navy uses to make sure ships will survive 20 foot waves and stuff
https://code.google.com/p/formlayout/ Check out fedit. It gives you a very VERY easy gui generation based on data type. For replacing command line inputs it works great. Probably the simplest way to get your students putting simple gui's on their python code. I think the only dependency is pyside
Its kind of hard to read your code. Are you sure you are not nesting your 'if' statements?
No, they are all in IDLE GUI so they are just straight up, nothing but that, when I enter a students code, aka my correct code, all I get is that the first is correct and that the rest are incorrect.
https://gist.github.com/anonymous/1468cf1eefcd5b26150b.js
I don't see the problem. "there should be one, and preferably only one, way to do it", ok sure. But thats not the point here. Hy compensates for the missing idioms. "yield-from" as an example. It doesn't exist on Python2, what did we do? We backported it. Thus you can use `yield-from` on Hy without caring for what Python you are targeting.
Please paste your code using pastebin.com. Your gist link is broken for me. And your code on reddit doesn't really tell me about your indentation. Pastebin will be your friend -- make it easy for us to help you.
Scientists trained in anything other than computer science *always* seem to write that sort of code, with few exceptions. I'm not surprised.
Fixing your [gist](https://gist.github.com/anonymous/1468cf1eefcd5b26150b) for you. Your if statements seem fine. Your incrementing of the score however, is not. It should be +=, not =+.
Oh sweet! I have a CFD background. Where y'all based? If you're doing scientific rendering I'm sure you need all the performance you can get.
Well try using this, this is the template code for the assignment that I created: import math import random start = random.random() square = math.sqrt(start) rounded = round(square,2) sums = (start + rounded) sums = round(sums,2) print (start) print (rounded) print (sums) if sums &gt; 1: print ('This value is greater than one!') else: print ('This value is less than one!') 
I am wondering if it's only reading the first line, since I am pasting multiple lines, and if so what is the command besides input to read multiple lines rather than just the first one?
Are you copying and pasting the code in at the prompt? If so your code variable is only going to be the first line since the input method breaks on the carriage return. Might try print code after the input to see what you actually have as an input 
You are correct, it only notices the first line. is there a way to sent it to recognize all of the lines?
I have already found it to be super convenient. I like quick real world examples of what I am looking for and this does a pretty good job. I'd like to see more of those then foo bar. 
This looks very much like a homework assignment, in which case I think the whole point is you're supposed to figure that part out. 
Were based in Honolulu but my office is in Rhode Island. Pretty sweet I get free trips to Hawaii haha. Yeah it helps but the heavy lifting is done by a Fortran engine so that's what keeps it fast.
Hahah Niiiicceeee! I just moved to South Florida From CT. Whats the company called and are you hiring? DOD funding is pretty slim right now (First hand knowledge...I work on the F35 program).
Any reason you dont use Gopher for this? It seems to do what you're trying to accomplish. Check out Pygohpherd for a Python solution 
SCL seems to be their primary method for releasing alternate versions of things, and currently has [3.3](https://www.softwarecollections.org/en/scls/rhscl/python33/). What's so horribly antiquated about that?
oh shit better never show my code ever
&gt; There are legitimate reasons for using python 2, even for **new projects**, and some people have no choice because of either 1) **legacy code**, or 2) company policy (like say, Dropbox, where Guido works).
Hello fellow Canadian! Your final product does indeed look nice. I don't have any experience with GUIs in Python so I can't help you out in the TkInter-specific stuff. The first thing I noticed is the amount of hard-coded repetition. You can save a *lot* of code and make it easier to maintain by, for instance, performing a lookup to some dictionary to determine what image to display: # Define image-placing logic in a function. def place_weather_image(img): img = Image.open(img) photo = ImageTk.PhotoImage(img) # etc. # Create a dictionary with all known weather # conditions and their corresponding images. conditions = { 'partly cloudy': '/path/to/cloud.png', 'windy': '/path/to/windy.png', # etc. } # Allow for a fallback in case the condition # is not present in the above dictionary. if condition in conditions: place_weather_image(conditions[condition]) else: place_weather_image('/path/to/default.png') Here's an additional example of some refactoring you could make (lines 115-144): # Store desired number of stories in variable for easy tweaking num_stories = 6 # List slicing to only keep x number of stories stories = topStory[:num_stories] # Use enumerate() to keep track of story index for y-placement offset for i, story in enumerate(stories): story_label = Label( ... ) story_label.place(x=15, y=(215 + i*35)) # offset by 35 pixels successively story_label.config(text=story.text) Allows more of your logic to occur programmatically affords you the ability to change constants (like the number of stories to display) without actually having to add/remove large amounts of code, reducing the chance that you'll make errors in the long run. That being said, be sure to keep learning!
Nice! I think that IPython notebook integration is a very useful feature for molecular analysis. I created a website ([Chemplore](http://chemplore.com)) which among other things, allows IPython embedding of a molecular viewer for small molecules.
Looks good for a first attempt. I am actually new to Python as well, but come from a software development background. There are some programmatic issues I see that could use some improvement: s1 = topStory[0].text s2 = topStory[1].text s3 = topStory[2].text You should really use some functions and a loop for this. For example: def add_story_label(root, text, x_pos, y_pos, wrap_length): label = Label(root, font=('RockoFLF', 21, 'bold'), bg='#222426', fg='white', justify=LEFT, wraplength=wrap_length) label.place(x=x_pos, y=y_pos) label.config(text=text) Then you can use a loop to call the function: x_pos = 15 y_pos = 215 wrap_length = 790 for story in topStory: add_story_label(root, story.text, x_pos, y_pos, wrap_length) And if you only want the first 6 elements: for story in topStory[:6]: add_story_label(root, story.text, x_pos, y_pos, wrap_length) That shrinks your 24 lines into 9 lines. As well, it increases consistency: the wrap_length of s6 is actually less than the rest (750 vs 790). As far as Python, you're deviating from a couple of standards: Python variable and function names are usually snake case, not camel case. While this may not impact how the script works, it is a great idea to get into good habits early. If you ever have a situation where you are naming variables with increasing numbers, you're actually making it very hard to maintain your code. Arrays, dicts, and lists all have purposes which would make this much easier. If you want to expand and learn more about Python and programming in general, I would recommend [CodeAcademy's Python classes](http://www.codecademy.com/en/tracks/python). These will introduce you to many programming constructs that will be very useful, such as looping, dicts, arrays, functions, etc. I am also certain that others here will be able to point out other inconsistencies and even mistakes I have made in my comments! There's a lot to learn, but it is actually really fun to use Python and I make an excuse to do so whenever I can. 
Does not work for me in chrome
Time to write a new year resolution or asking the boss to set the new KPI for 2015 Hi boss, can we upgrade all those servers with python 2.3, 2.4, 2.5, 2.6, and 2.7 which work just fine to python 3.4? 
ok ill bite. Because is standard.. kinda... as of python 3.4 sure. Because is elegant. ill give you this. its pattern are very similar to the factory/protocol patterns other libraries use. for a python core lib , it actually well put together. ~~Because is Python 3.~~ covered that in standard. dont repeating yourself ~~Because is the future.~~ the tulip team (guys behind asyncio) admited its not a full on replacement for many of the cooroutine libraries nor is it a drop in replacement for factory/protocol based async framework twisted. twisted and gevent both out perform it at this point. it is however standard so if you want to ship your code various palces , you dont have to worry too much about libraries.. to me though this is like arguing use urllib + urlib2+ httplib rather then using requests. 
It's just supposed to be a text only version of a web server.
Cool ! Can you give examples of when it is useful to use this in a programatic way ? Like, are there tools that enable you to programatically look for or invent new molecules, that you can then vizualize ? Or is is just for a visual support in presentations ?
Promise :) ?
Well, the support structure around SCL is wildly different than RHEL proper. SCL 1.x is only supported through 2016, whereas RHEL6 itself is supported through like 2020. It's also less well-integrated with the community builds (i.e. CentOS) which are what those of us who can't afford to pay RH actually use. They're also less strict about security updates for SCL-provided packages ... poking through the database for examples, it doesn't look like a fix for CVE-2014-1912 is available in SCL.
I thought this was for seeing the percent complete a function was and came to the comments to see what kind of mystical fucking wizardry OP had conjured up from the depths. Was disappointed, but still neat I guess.
any plan to support tuples (of immutables)?
Yep. Try it.
There are basically 4 bigger cross-platform UI libraries for Python: * PyQt/PySide. The most advanced and up-to-date. Installation is easy on Windows, not so easy elsewhere. Available under GPL/LGPL, so might not be a good fit for all purposes. * wxPython. Installation easy on Windows, painful on Mac. Good native look on all platforms. No Python 3 support, not very up-to-date. * Tkinter. Comes included with Python, so requires no additional installation. However, it really is.. old, and clunky. Might be the best fit for your requirements, though. * Kivy. Comes with easy installations on Windows/Mac. Is more oriented towards mobile than desktop development. This can be a bonus for students - they can start making mobile apps. 
Which is a good thing to do :) You probably want to change your file handling - not a vulnerabilty as such but where you have (for example): log = open("log/server.log",'a') log.write(request+'\n') log.close() you would be better with: with open("log/server.log",'a') as f: f.write(request+'\n') not only is it easier to read but it will guarantee the file is always closed if (for example) the file write fails and at a later stage you've wrapped the code in a try: edited: formatiing
Doesn't work for me, interesting project though! The setup function fails (latest pypy nightly, jitpy 0.1 via pip): IOError: [Errno 2] No such file or directory: '/home/myuser/anaconda/lib/python2.7/site-packages/jitpy/pypy.defs' 
Much prefer this to the car example (which was the eg my bro taught me (along with the boring eg of widgets for a/c'ing that my other bro taught))! The eg's of "without OOP" make all the difference to compare too and the principles of "go wrong and change code" to inform that. I don't know if a tree-diagram to "map" the thinking here as another eg would be a useful visual aid in addition? One of things that confuses me is mixing up the logic and the "grammar/syntax" of python itself ie understanding both atst when learning can be really challenging. With a sort of tree diagram of the logic inheritance etc of dragon types the actual code could be under this. Idk, just musing on ways to improve what is already excellent. It reminds me of learning a foreign language the context of using it is an important part of developing the "how to use it appropriately". One day when I am better at python I hope to share what I've done and mention this blog post as an excellent eg of it. Cheers.
Yeah, `input` reads a single line. You'll want: import sys code = sys.stdin.read() which reads everything from standard input.
hm it looks like pypy.defs is not considered a part of the built? stupid setuptools I'll try to fight it EDIT: should be fixed, try now?
would have been useful to include some examples of how users would install from the local pypi server. 
Check out Paul Graham's essays: * [Beating the Averages](http://www.paulgraham.com/avg.html) * [Revenge of the Nerds](http://www.paulgraham.com/icad.html) 
i haven't used pyqt5 yet but i've used qt5 with c++ so i know about the differences of qt 4/5 and will assume that they're the same for pyqt5. As long as you stick with QWidget based objects the most important difference is the changed module structure. qt used to be mainly split up into QtCore and QtGui. The qwidget based classes are now moved to QtWidgets. So basically with pyqt4 you need to write something like: from PyQt4.QtGui import * and with pyqt5 you write: from PyQt5.QtWidgets import * There are other minor differences but you can start to care about them as soon as you come across them. About what to use: If you're concerned about licensing and want to publish your work but don't want to opensource it / pay for license fees, you're stuck with PySide and Qt4. If that is not an issue i'd advise you take a look at PyQt5 and Qt QML. Imho it is a breeze to write GUIs with it and experiment with layouts, custom widgets and such. I don't know whether this fits your use case but you should really get some experience with it anyway.
 path traversal - $ echo -n "FOO|BAR|../../../../../../../etc/passwd" | nc localhost 32891 root:x:0:0:root:/root:/bin/bash daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin bin:x:2:2:bin:/bin:/usr/sbin/nologin sys:x:3:3:sys:/dev:/usr/sbin/nologin sync:x:4:65534:sync:/bin:/bin/sync games:x:5:60:games:/usr/games:/usr/sbin/nologin man:x:6:12:man:/var/cache/man:/usr/sbin/nologin lp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin ... ... Also, server will crash with invalid formatting of the arguments if split() doesn't return 3 fields. 
OP says Python 3, though, and taking a look at enaml's documentation it calls out 2.7. I tried installing it with Conda and it was a non-starter as I'm using 3.4. It still looks like a nice tool, though.
HOLY FUCKING SHIT This is amazing
#####&amp;#009; ######&amp;#009; ####&amp;#009; Section 9. [**Velocity Verlet**](https://en.wikipedia.org/wiki/Verlet_integration#Velocity_Verlet) of article [**Verlet integration**](https://en.wikipedia.org/wiki/Verlet%20integration): [](#sfw) --- &gt; &gt;A related, and more commonly used, algorithm is the __Velocity Verlet__ algorithm, similar to the [leapfrog method](https://en.wikipedia.org/wiki/Leapfrog_method), except that the velocity and position are calculated at the same value of the time variable (Leapfrog does not, as the name suggests). This uses a similar approach but explicitly incorporates velocity, solving the first-timestep problem in the Basic Verlet algorithm: &gt;&gt; &gt;&gt; &gt;It can be shown that the error on the Velocity Verlet is of the same order as the Basic Verlet. Note that the Velocity algorithm is not necessarily more memory consuming, because it's not necessary to keep track of the velocity at every timestep during the simulation. The standard implementation scheme of this algorithm is: &gt; &gt;* Calculate: &gt;* Calculate: &gt;* Derive from the interaction potential using &gt;* Calculate: &gt;Eliminating the half-step velocity, this algorithm may be shortened to &gt; &gt;* Calculate: &gt;* Derive from the interaction potential using &gt;* Calculate: &gt;Note, however, that this algorithm assumes that acceleration only depends on position , and does not depend on velocity . &gt;One might note that the long-term results of __Velocity Verlet__, and similarly of __Leapfrog__ are one order better than the [semi-implicit Euler method](https://en.wikipedia.org/wiki/Semi-implicit_Euler_method). The algorithms are almost identical up to a shifted by half of a timestep in the velocity. This is easily proven by rotating the above loop to start at Step 3 and then noticing that the acceleration term in Step 1 could be eliminated by combining Steps 2 and 4. The only difference is that the midpoint velocity in __velocity Verlet__ is considered the final velocity in semi-implicit Euler method. &gt;The global error of all Euler methods is of order one, whereas the global error of this method is, similar to the [midpoint method](https://en.wikipedia.org/wiki/Midpoint_method), of order two. Additionally, if the acceleration indeed results from the forces in a conservative mechanical or [Hamiltonian system](https://en.wikipedia.org/wiki/Hamiltonian_system), the energy of the approximation essentially oscillates around the constant energy of the exactly solved system, with a global error bound again of order one for semi-explicit Euler and order two for Verlet-leapfrog. The same goes for all other conservered quantities of the system like linear or angular momentum, that are always preserved or nearly preserved in a [symplectic integrator](https://en.wikipedia.org/wiki/Symplectic_integrator). &gt;The Velocity Verlet method is a special case of the [Newmark-beta method](https://en.wikipedia.org/wiki/Newmark-beta_method) with and . &gt; --- ^Interesting: [^Beeman's ^algorithm](https://en.wikipedia.org/wiki/Beeman%27s_algorithm) ^| [^Leapfrog ^integration](https://en.wikipedia.org/wiki/Leapfrog_integration) ^| [^Loup ^Verlet](https://en.wikipedia.org/wiki/Loup_Verlet) ^| [^Integrator](https://en.wikipedia.org/wiki/Integrator) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cmlyj8j) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cmlyj8j)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
This is a very interesting question. I am working a lot with Lagrangian type trajectories and I also would be interested in hearing about any existing relevant Python package. I know of the TRACMASS package developed by Prof. Döös, but it is built with Fortran and rather unmaintainable. I also implemented a tracking algorithm in C#, called QTRAC, but it performs Euler type tracking. (http://www.area51staff.it/compressibility/ but I just noticed the page is broken due to a missing &lt;table&gt; openin tag) EDIT: added some relevant info
Guys! As always your input has been amazing! I want to thank all of you for helping me out. 
&gt; I think the biggest issue is that its easier to write unreadable Python code. Er, are you joking? Yes, a project of that size will be *much* faster if written in C++, but it's *much* easier to write unreadable C++ than unreadable Python.
Once you learn the basics of the language, you can use any of the mentioned libraries or packages by refering to their manuals or man pages. What do you want to learn specifically about scipy, for example?
Wow, that looks super clean and beautiful. Well done! I know there's a bit of a circlejerk around it here, but have a look into the [requests](http://docs.python-requests.org/en/latest/) module (`pip install requests`) – it is seriously so much nicer than urllib2
Some examples would be an good idea :-)
`with` is right up there with list and generator comprehension as my favorite underused python features. `@contextmanager` is a thing of beauty.
Wow, Enaml looks awesome. Too bad they haven't ported it to python 3, it needs an easy to use GUI library
PyQt5 by default pulls in more stuff than PyQt4 so software distribution would be larger. If that does not concern you then there is no reason to use old libs. I stick with PyQt4 for some things only to reduce size of final software package that advanced gpu stuff adds megabytes and i dont need it at all.
Really? I need help but I am not stupid.
Link for the interested: /r/maths: A mathematics subreddit for the pretentious lot who don't like the word "ma[...] --- ^This ^is ^a ^bot ^and ^won't ^answer ^to ^mails. ^Mail ^the ^[[Botowner](http://www.reddit.com/message/compose/?to=DarkMio&amp;amp;subject=BotReport)] ^instead. ^v0.4 ^| ^[Changelog](http://redd.it/29f2ah)
[Original post](http://www.reddit.com/r/math/comments/2o9wge/conformal_image_map_animation_of_1z_to/) by u/sple3o on r/math, with explainations.
WxPython Phoenix has Python 3 support and is up to date. I think it even focuses on Python 3.
Yes. I think they're technically called generator expressions, but I prefer the term generator comprehension, because they're basically the same as a list, set, or dict comprehension, but creating a generator.
Dict comprehensions are voodoo :p I have yet to make use of them in any of my projects, but I'd love to.
I've had good experiences with them. They're good at making zip unnecessary. For instance: {val: func(val) for val in iterable}
PySide is installable under Windows and OS X through pip. pip install pyside Linux people should have it in their repo, which would look kind of like `sudo apt-get install python3-pyside`. But I'd go with Tkinter. It looks ugly, but it's built right into Python and it's fairly easy to get started with. edit: OS X needs to have Qt installed first. ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)" brew install qt pip install pyside
Python continues to amaze. Python is so simple to start with but you can get into some really complex difficult concepts, like this and even then all the hard complex stuff is abstracted away leaving a simple 'with' statement.
This review seems to have really missed the point. When I read "Python for Finance" I think factor analysis, back-testing, derivative pricing, portfolio optimization etc... Just look at the last line of the review: "[...]But it certainly won’t help you understanding the finances of a business or your personal income and expenses." Yeah, I'm pretty sure that this book wasn't supposed to be about balancing a monthly budget in Python...
Totally agree. As someone who isn't a professional developer, Python is great in that you can learn if from the ground up, then add on abstract concepts later. To me, this mimics how people actually learn much more than other languages. Walk first, then run. A lot of languages force a beginner to worry about `{`, `;`, or `#include` right off the bat.
That's a single, not all that good use-case for zip. I don't see how that makes zip unnecessary for all but that single use-case. More often zip is used to transform two data streams into a single one so that you can iterate over multiple lists at once: import string ascii_values = zip(string.ascii_lowercase, range(96, 96+26)) Or if you have a list of tuples and need two separate lists: letters, values = zip(*ascii_values)
No question. Believe me, I love zip as much as the next guy. I just feel like I sometimes see it being overused in cases where a comprehension would sufficice- where an iterable is duplicated, operations performed on each side, and the results zipped together. It comes up more often than I expected.
Yep, there is a pull request open about it.
[Fifth World Pics](http://www.reddit.com/r/fifthworldpics)
/r/learnpython
Yes, chemview was built from the ground up for interactivity and animation (which is the hard part). For example: you want to know what happens if you mix hexane and water. So you can programmatically create (with the help of the [chemlab](http://chemlab.readthedocs.org) library) a box containing 100 molecules of hexane, and 100 molecules of water. Then you simulate the system with the help of [openmm](http://openmm.org) and you can see in real time what happens (they unmix). All of this without ever leaving the notebook. Thanks, you gave me an idea for a nice notebook demo :)
There is a good python book called something like Absolute Beginner's. Python (has a block of cubes on a white background cover) that I bought. It seems pretty good and it uses a game approach to teaching python. It might help.
If you could tell me your google chrome version that'd be awesome. It may also be that there's problems loading the data (I'm using a free service for that) (menu-&gt;about google chrome)
Thanks
There's a lot of discussion of this issue. For example: http://stackoverflow.com/questions/6803505/does-my-code-prevent-directory-traversal 
I wasn't aware of your website. It looks pretty useful!
That would be a great demo to show off the functionality of your viewer! 
+1. Catching exceptions and HTTP status codes with requests is far simpler: http://requests.readthedocs.org/en/latest/user/quickstart/#response-status-codes
Cool script! I usually wrap code to be executed in a ``def main(*args)`` method, and then add: if __name__ == "__main__": main() # import sys # sys.exit(main()) # UNIX programs return '0' if there is not an error This has (at least) two benefits: 1. If someone does ``import pywapitest``, the script does not execute 2. It makes testing (e.g. with ``unittest.TestCase``) possible 
[**@ionelmc**](https://twitter.com/ionelmc): &gt;[2014-12-05 10:38:21 UTC](https://twitter.com/ionelmc/status/540817446224281600) &gt;Your daily [#python](https://twitter.com/search?q=%23python) insanity. [*pic.twitter.com*](http://pbs.twimg.com/media/B4FeexbCAAA8xQB.png) [^[Imgur]](http://i.imgur.com/0xisbFP.png) ---- [^[Mistake?]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=http://reddit.com/2oe3un%0A%0APlease leave above link unaltered.) [^[Suggestion]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Suggestion) [^[FAQ]](http://np.reddit.com/r/TweetPoster/comments/13relk/) [^[Code]](https://github.com/buttscicles/TweetPoster) [^[Issues]](https://github.com/buttscicles/TweetPoster/issues) 
I know this reddit doesn't fancy captioned pictures but god damn it, this applies so well.
Version 39.0.2171.71 on OSX 10.6.8 
Yes please, I'd watch that :)
Very cool, ran into `with` yesterday on my own. Good to know. And this may be a noobish question, but do local objects get destroyed in python when going out of function scope? 
Does the new spyder IDE support emacs like text navigation? Ctrl-N (next line) Ctrl-F (next character) Ctrl-B (back one character) etc. I would love a clean IDE, and spyder looks great, however requiring mouse and arrow keys to navigate through code is something I can't go back to. 
Wow, thanks! I will do that
Yes, anything declared in the function cannot be referenced once you have exited it.
Also Java's try with resources http://docs.oracle.com/javase/tutorial/essential/exceptions/tryResourceClose.html
To build am smtp client you first need to: Find out which server will accept email for your email address (an 'MX' record DNS query). DNSpython gets this done in an easy way, though you could use the built in sockets library in a less strait forward manner. http://www.dnspython.org/examples.html Once you have one or more candidate email servers, you can begin trying to send a message to each of them until one has accepted the message successfully. Use the built in smtplib module for this, following the example on python.org: https://docs.python.org/2/library/smtplib.html All you have to do is replace 'localhost' with a remote server name or IP that handles email for your recipient's domain, which is what the MX query may resolve for you. 
No if you have a local variable that's not returned or saved in a non local variable it becomes eligible for garbage collection and may be collected in the future. it cannot be referenced normally(although maybe with some gc.get_objects magic it can ) but it's memory may or may not have been freed and __del__ may or may not have run. In cpython the main python implementation it uses reference counting + a backup full garbage collector so if there aren't any cycles caused by example local object a pointing to local object b which points back to a, it's reference counting goes to 0 and it gets freed. If there are cycles eventually it may or may not be freed according to the gc. Cpython has a gc module that lets you do stuff like force gc, I think, and disable gc. CPython sort of has destructors with __del__ but as these don't run if the object is in a reference cycle I'd recommend staying far away and using the with statement for non memory destructor like behavior.
Time to change the votes to 64bit. numpy is the Gangnam Style of python modules. 
or we could just unsign it for double the votes or something. Wow I wasn't aware this vid passed 2.147b. Jeez... that's crazy!
Just use izip from iterators in 2.x. In Python3, zip is an iterator already and you don't need izip.
Don't forget C++ too. I've had some great success integrating legacy C++ code with Python via Cython.
You haven't lived then!
Or Ruby's blocks, which are a very fundamental and virtually impossible to ignore feature, and which look extremely similar in the file opening example. Python: with open('output.txt', 'w') as f: f.write('Hi there!') Ruby: File.open('output.txt', 'w') do |f| f.write('Hi there!') end
Oh man, I have a script that does exactly this! I use python smtp to interface with my gmail account to send emails with attachments to others, and with a little modification you could get it to fit your purpose. Here's a functional excerpt (all standard library): import smtplib from email.mime.multipart import MIMEMultipart from email.mime.text import MIMEText # Gmail server and port values SMTP_SERVER = 'smtp.gmail.com' SMTP_PORT = 587 GMAIL_PASSWORD = 'YOUR_PASSWORD' # Construct email object m = MIMEMultipart() m['From'] = 'MY EMAIL ADDRESS' m['To'] = 'THEIR EMAIL ADDRESS' m['Subject'] = 'SUBJECT' m.attach(MIMEText('MESSAGE'.encode('utf-8'), 'plain', 'utf-8')) # Send the email using smtp session with smtplib.SMTP(SMTP_SERVER, SMTP_PORT) as session: session.starttls() session.login(m['From'], GMAIL_PASSWORD) session.sendmail(m['From'], m['To'], m.as_string()) Note: Storing your email in a text file can be a security risk, it's up to you to analyze your needs. If gmail throws an smtp authentication error be sure to check you have imap enabled and if it persists check the error code on Google. Works for me as is.
Yeah, exactly! Even works with Django apps! Clever folks can even make Hy code pip installable :)
Since we're showing off, apparently; `enumerate(string.ascii_lowercase, start=96)`
I've never searched for this library though, so I still think it's a bit nuts.
Alternate title could be "I installed something and blogged about it."
I used the "Send feedback" button at the bottom of the page to report this (with credit, of course). It's impressively fancy; you draw boxes and it takes a screenshot and everything. Try it out.
sys.stdin.read() doesn't work because it looks for exact lines, and as all code is different when the other kids write it, it doesn't work 100% of the time. Ctrl D and Ctrl Z are end program, and undo, respeitively.
Wouldn't a Python egg be more suitable for his use case? &gt; You have created a proprietary Python module that you would like to release only to folks within your group/company. 1. Create an egg 2. Put it on a network drive or service everyone has access to 3. Send emails saying its up on the drive/service 4. That's it.
* https://docs.python.org/2/tutorial/index.html * https://scipy-lectures.github.io/ "1.2. The Python Language" * http://docs.python-guide.org/en/latest/#writing-great-code * http://docs.python-guide.org/en/latest/writing/tests/ * /r/learnpython/wiki/index * /r/learnpython/wiki/books
Python 3 msh, *rest = ['MSH', 'dead', 'rabbit', '', '999', 'test PID', 'test', 'shrew', '', 'beers'] for i, x in enumerate(rest): if x: print("{}.{}: {}".format(msh, i, x)) else: print("{}.{}: null".format(msh, i))
I used it once to stream through a 900 gig text file of logs.
Shit man, I've been trying to make fractal trees in python since day one! This is extremely helpful!
What's fascinating to me is that they're implemented in almost exactly the same way, with the yield keyword (assuming you use `@contextlib.contextmanager` in python.) The only difference is that ruby can run the block more than once.
A [Tweepy](https://github.com/tweepy/tweepy) stream of tweets would be pretty cool, have them tweet to a hashtag and let them watch it stream through. Theoretically you could also use Instagram's streaming api for the same thing. You could also help them use [IFTTT](https://ifttt.com).
I often forget that there are things like dict.copy, so I'll use a comprehension, but for example inverting a mapping makes them really useful: mydict = {"a":1,"b":2,"c":3} inverted = {val : key for key, val in mydict.items()} #inverted = {1:"a", 2:"b", 3:"c"}
The readme doesn't describe what an account file should look like. After breesing the code, I'm still not sure.
Well, on my experience, Selenium is the way to go. You can use PhantomJS instead of Firefox as web browser. What I dislike of using Selenium is that a cmd.exe window is always opened by it on Windows, and that if you want to ship the script as executable file with PyInstaller, you need to use a hook to get some files included and required for the Python API of Selenium. But, doing this with Scrapy? I have no idea.
Let me tell you, midleschoolers are dumb. I mean, kids are pretty dumb in general, but midleschoolers are the dumber of the bunch. They're at an age where fitting in and buying what 50 cent wears is more important than anything else. Out of all the kids you'll be presenting to, only one or two will become interested in what you do. The one or two that will become interested will be easy to interest regardless of what you present, within reason. The rest of the kids will not be interested regardless of what you present. What I'm saying is, don't worry about being something to everyone. Make it a presentation for the few bright kids in that class that are interested in something constructive. The rest of the kids are not worth thinking about.
Python is not the ideal language for games. It's my favourite language for everything else, don't get me wrong. But video games and embedded systems is not what it was meant for. It's focus is not on high performance computation, it's focus is on correct design, ease of use, and programmer productivity for general purpose programming. For video games more complicated than tic Tac toe, you really need to be using C or C++, or these days, Rust, which is excellent.
Same. I use the python(x,y) distro, and Spyder is just a godsend for scientific computing!
bokeh.pydata.org/ I've run into this one day researching libraries for a project. Might suit your need.
This looks really nice. I use Sublime Text and Vim and I'm wondering whether I should check out Pycharm. Since I mostly do web stuff it's nice to work with both python, html, sass, js and bash scripts in the same editor/ide. I've recently started to use iPython Notebook, and I like it a lot. There's a lot of interesting features that I would like to explore, especially the graphing and visualisation stuff is very cool.
Reviews can be helpful to understand who is reading a book. Another review mentions that "Python for Data Analysis" is probably the more "popular" version of the above book http://shop.oreilly.com/product/0636920032441.do "[The book] gives an overview of very basic Python topics, such as data types and structures. In this respect the book suffers from an indecision on whether it is an introductory or advanced text. Most of the concepts considered herein are covered more in depth in Python for Data Analysis. "
Look at gephi - not a kibrary, but can scripted.
No... `sys.stdin.read()` reads the whole of stdin. In Unix terminals, Ctrl+D means "end of file". In Windows terminals, Ctrl+Z followed by Enter means "end of file".
I found it really unclear too, even after reading the README and looking at the example. Using keyword arguments for the operation constructors may help a bit. (Because what does `DebtOperation(200, 2, False, 150)` mean.)
Here's what I've done to produce this interactive visualization of the [power metal social graph](http://rcfox.ca/PowerMetalGraph/) (5781 nodes, 8258 edges): 1. Build the graph with the [networkx](https://networkx.github.io/) library. It's got a bunch of algorithms for finding clusters, find paths between nodes, etc., if that's something you need. 2. Have networkx output the graph in dot format: networkx.write_dot(G, 'file.dot') 3. Import file.dot into [Gephi](http://gephi.github.io/), and use the force atlas 2 layout algorithm. I like to let the layout settle, and then prevent overlapping nodes afterwards. You can also play with styling here if you want. 4. Export a GEXF file from Gephi. 5. Use [sigma.js](http://sigmajs.org/) on your site to render the graph. The tutorial section on their front page is enough to get you going. Edit: Oh, I've also made a [Skyrim social graph](http://rcfox.ca/Skyrim-NPC-Relationship-Parser/) (I guess I like looking at social graphs!) with just dot, rendering as SVG. It's less interactive, more and less readable in different ways, and seems to choke on the number of images I gave it. You can search within it using the browser's normal in-page search tool though.
Yep. I tried a fresh project,cleared the caches and even reinstalled. Still doesn't work. There is a bug report for this but so far nothing came along. IMHO this feature was released to early
I just started using pycharm community addition with the vim plugin. It's pretty good. I don't like the fact that it constantly autosaves, and the undo functionality is different enough from vim to be mildly frustrating, but the auto complete and debugger are nice
Thanks, great suggestions. IFTTT would be a great demo.
All right, I will write more documentation about the Operations, then. For now, you can checkout all subclasses of Operations in pyrestriction/models.py
But doesn't a system like velocity verlet just integrate your ODEs? You still need to get from your Lagrangian to the equations of motion which involves taking some derivatives and doing some algebra. I guess sympy could work for that step. I saw a [blog post](http://jcrist.github.io/differential-drive-part-1.html) a while back showing how this could be done for a specific case. This is assuming OP really wants a black box solution where one can enter in the Lagrangian and not the equations of motion.
I have also done this with selenium, will try to post a gist of it here later. 
I wonder if there will be any plans to get hy working in the CLR Runtime (ironpython), or in the JVM (jython)
I think that the best way to do this in Python is to use a sentinel: def values_in(keys, dict): sentinel = object() items = (dict.get(k, sentinel) for k in keys) return [it for it in items if it is not sentinel] (btw what really sucks is that Python's list comprehensions don't have a `let` keyword, a la LINQ).
Before delving too deeply into rendering the page and executing the javascript, I would recommend trying to parse the links out of the javascript. Are the links returned by some ajax call or do they just get rendered by existing js? If ajax, try making that call and parsing the results. If rendered by existing js, the logic is there for you to pick apart.
The second python example in the post is better: def values_in(keys, dict): return [dict[x] for x in keys if x in dict]
I am running the ipython 3.0.
It's certainly more clear in Python syntax (and lack of support for pattern matching), but if we are talking about the, you know, conceptual stuff, like the OP, then checking first and getting the value second is kinda unclean. It is a non-trivial property of the code that you're allowed to call "dict[x]" after you checked "x in dict". In fact you can accidentally pass two different keys and it wouldn't be true. Calling `get` with a sentinel on the other hand is conceptually identical to the pattern matching solution -- you don't have an opportunity to do it wrong, you either get a value or a "no value" sentinel (which, unlike None, is guaranteed to be unique, i.e. can't be present in the dictionary).
I disagree. If you really want to use EAFP over LBYL, just do def values_in(keys, dict): for key in keys: try: yield dict[key] except KeyError: pass It's far more idiomatic, shorter and undoubtedly faster. In this case, though, just checking beforehand seems much cleaner.
Great stuff. I'd love the live rotate, pan, zoom functionality to be avaliable for mplot3d or mayavi in an ipython notebook.
I don't have to much familiarity with sublime and anaconda but why not look at something like Python XY? I pretty much started doing the same thing at work and only Python XY was authorized to be installed. It has a bunch of default modules it comes with aimed at science and engineering, I'm pretty impressed with Spyder and iPython so far (part of the default Python XY installation), it's making it an easier transition over from Matlab
It might depend on the specifics of your lab assignments, but I'd bet you'll find IPython and the IPython notebook to be much better suited for your work than Sublime Text or PyCharm (though the latest PyCharm supposedly supports the IPython notebook). The 'I' stands for interactive. The IPython shell feels somewhat similar to the shell in MATLAB, and the notebook is similar (but better, IMO) to working in cell mode in MATLAB. Though I haven't done much of it myself, I'd imagine image manipulation in the notebook to be really nice as the images will be embedded in the same document as your code.
What do you have against autosaving? It's useful if you're editing and running scripts very frequently, and if you want save/ load functionality do it in your VCS, then it's much more feature-rich. 
It's compatible with ipython, just not with notebooks. Pycharm and notebooks are designed for completely different things (large multi-module projects and very short self-contained scripts with pretty outputs, respectively); obviously it'll be nice to close the loop and have them both in the same IDE, but not having notebook support doesn't change whether or not you should use pycharm, really, unless you never write anything longer than 50 lines. 
Spyder is a bit like the Matlab IDE. For images, you just get matplotlib, which is fine for plotting. For more general image work I haven't yet found any tools I particularly like for python.
Very good! I have not tried it, and I will assume it works. Here are four suggestions you may wish to consider, with the third one possibly being a small challenge. * Transform your comments preceding methods into docstrings: # Updates with new position of paddle every frame def draw(self, y): pygame.draw.rect(screen, self.color, [self.x, y, self.height, self.width]) Should become def draw(self, y): '''Updates with new position of paddle every frame''' pygame.draw.rect(screen, self.color, [self.x, y, self.height, self.width]) * when two branches with an "if" statement give the same result, consider putting them as a single branch with an "or" keyword if event.key == pygame.K_UP: player2.y_speed = 0 if event.key == pygame.K_DOWN: player2.y_speed = 0 should become (parentheses added for clarity) if (event.key == pygame.K_UP) or (event.key == pygame.K_DOWN): player2.y_speed = 0 * Look at how much code duplication (``__init__`` and ``draw`` methods) there is for both your classes. Consider defining a base class (``Drawable``) containing these two methods and have both ``Player`` and ``Ball`` inherit from these. For example, with the appropriate definition, you could have class Ball(Drawable): pass ball = Ball(WHITE, 325, random.randrange(150, 350), 20, 20) * Replace as many numerical values (e.g. 325) by variable names written at the top (eg ``ball_x0 = 325) Finally, when I copy/pasted your code, it looks as though you used tabs to indent. In the Python community, it is **much** more common to use spaces instead of tabs. You might be able to configure your editor so that it automatically converts tabs into 4 spaces (and removes 4 spaces when clicking on shift-tab).
iPython is closest to Mathematica. Spyder is probably closest to Matlab.
Anaconda isn't an IDE, it's a really nice distribution so everyone should get it. PyCharm / Spyder / WingIDE are true IDEs with Spyder being closest to Matlab, but the worst. I like WingIDE (I do lots of math), but more web-based developers seem to like PyCharm more. iPython is another great alternative (it's basically an page-based interactive IDE that you can drop images into unlike any other IDE including Matlab) and much better for testing things out. I'd recommend trying it first.
Yeah, I like Python, I just find it much quicker and easier to manipulate and analyse images in Mathematica. A lot of people I know use ImageJ to analyse images...there's a Python plugin for it, so that might be a way to go. Like I said, I've just stuck with what I know though. As for Spyder. That's what I use. I grab WinPython which makes things easy on Windows as most of the key stuff is in there. You can build GUIs with Tkinter, QT. All the maths stuff, and decent array are there thanks to Numpy. So you can basically jump right in.
Nice. I didn't know you could do that! Much cleaner than mine.
iPython is more like a CAS interface like Mathematica or Maple. I really like it for SymPy work. I think the PyCharm with iPython support looks interesting. For the times where I'm doing a lot of numerical work I usually turn to Spyder as it's most like the Matlab interface I'm used to.
That is disgusting. Neat, but oh god that code. Guido would not be proud. 
&gt; It's far more idiomatic, shorter and undoubtedly faster. Have you measured? I'm on mobile right now, but intuitively your code seems much slower to me than the Sentinel version, because: * exceptions are generally slow when raised, fast when not raised. In this case it's unlikely you'll pass all keys in the dict to this function, so an exception will be raised many times. * iterating in a python for loop is much slower than iterating in a comprehension, because the comprehension does the loop in C and thus avoids interpreter overhead The only added cost is a single identity check per item, which in cpython is a cheap pointer comparison. So without measurements i can't be sure, but my gut tells me this version is slower. I'll measure tomorrow and report back if I can. 
&gt; iPython is closest to Mathematica. It sounds like you're talking about the ipython notebook html interface. This is just one interface to ipython, it also supports (and originated from) a terminal interface that is essentially an improved vanilla interpreter. There's also the intermediate qtconsole which is a fancier gui version of the same thing, though I'm not sure how much it's being developed right now. It is these shells that the comment you replied to is probably referring to, not the newer notebooks.
&gt; This is just one interface to ipython, it also supports (and originated from) a terminal interface that is essentially an improved vanilla interpreter I know. &gt; It is these shells that the comment you replied to is probably referring to, not the newer notebooks. Depending on the part of the comment... &gt; the notebook is similar (but better, IMO) to working in cell mode in MATLAB. The iPython shell bothers me. I actually prefer the defunct PyCrust. The notebook is great though.
There was one point where I suspected that would exist, but I didn't bother to check because it wouldn't have made that much change at the time. To make use of this I think I'd have to start from scratch. 
&gt; Have you measured? As much as I always hold others to this standard, I had not. &gt; exceptions are generally slow when raised, fast when not raised This is true, but lots of things in Python are expensive. If the error rate is less than ~20-30% I'd expect the slowness to be largely less important than function call overhead. &gt; iterating in a python for loop is much slower than iterating in a comprehension, because the comprehension does the loop in C and thus avoids interpreter overhead This is false. Comprehensions in CPython actually do a source transformation at compile time to the equivalent function. The primary differences are that list comprehensions use a specialized `LIST_APPEND` opcode and both use slightly optimized loop opcodes. import dis def f(): (x for x in xs) dis.dis(f) #&gt;&gt;&gt; 4 0 LOAD_CONST 1 (&lt;code object &lt;genexpr&gt; at 0x7f51e8413ed0, file "", line 4&gt;) #&gt;&gt;&gt; 3 LOAD_CONST 2 ('f.&lt;locals&gt;.&lt;genexpr&gt;') #&gt;&gt;&gt; 6 MAKE_FUNCTION 0 #&gt;&gt;&gt; 9 LOAD_GLOBAL 0 (xs) #&gt;&gt;&gt; 12 GET_ITER #&gt;&gt;&gt; 13 CALL_FUNCTION 1 (1 positional, 0 keyword pair) #&gt;&gt;&gt; 16 POP_TOP #&gt;&gt;&gt; 17 LOAD_CONST 0 (None) #&gt;&gt;&gt; 20 RETURN_VALUE The key things to note are `MAKE_FUNCTION` and `CALL_FUNCTION`. f.__code__.co_consts[1] #&gt;&gt;&gt; &lt;code object &lt;genexpr&gt; at 0x7f51e8413ed0, file "", line 4&gt; dis.dis(f.__code__.co_consts[1]) #&gt;&gt;&gt; 4 0 LOAD_FAST 0 (.0) #&gt;&gt;&gt; &gt;&gt; 3 FOR_ITER 11 (to 17) #&gt;&gt;&gt; 6 STORE_FAST 1 (x) #&gt;&gt;&gt; 9 LOAD_FAST 1 (x) #&gt;&gt;&gt; 12 YIELD_VALUE #&gt;&gt;&gt; 13 POP_TOP #&gt;&gt;&gt; 14 JUMP_ABSOLUTE 3 #&gt;&gt;&gt; &gt;&gt; 17 LOAD_CONST 0 (None) #&gt;&gt;&gt; 20 RETURN_VALUE This is almost what I can do manually: def f_inner(xs): for x in xs: yield x dis.dis(f_inner) #&gt;&gt;&gt; 33 0 SETUP_LOOP 19 (to 22) #&gt;&gt;&gt; 3 LOAD_FAST 0 (xs) #&gt;&gt;&gt; 6 GET_ITER #&gt;&gt;&gt; &gt;&gt; 7 FOR_ITER 11 (to 21) #&gt;&gt;&gt; 10 STORE_FAST 1 (x) #&gt;&gt;&gt; #&gt;&gt;&gt; 34 13 LOAD_FAST 1 (x) #&gt;&gt;&gt; 16 YIELD_VALUE #&gt;&gt;&gt; 17 POP_TOP #&gt;&gt;&gt; 18 JUMP_ABSOLUTE 7 #&gt;&gt;&gt; &gt;&gt; 21 POP_BLOCK #&gt;&gt;&gt; &gt;&gt; 22 LOAD_CONST 0 (None) #&gt;&gt;&gt; 25 RETURN_VALUE But it avoids doing `SETUP_LOOP`/`POP_BLOCK` and hoists the `GET_ITER` into the calling function. For a list comprehension: import dis def f(): [x for x in xs] dis.dis(f) #&gt;&gt;&gt; 34 0 LOAD_CONST 1 (&lt;code object &lt;listcomp&gt; at 0x7f51e841b390, file "", line 34&gt;) #&gt;&gt;&gt; 3 LOAD_CONST 2 ('f.&lt;locals&gt;.&lt;listcomp&gt;') #&gt;&gt;&gt; 6 MAKE_FUNCTION 0 #&gt;&gt;&gt; 9 LOAD_GLOBAL 0 (xs) #&gt;&gt;&gt; 12 GET_ITER #&gt;&gt;&gt; 13 CALL_FUNCTION 1 (1 positional, 0 keyword pair) #&gt;&gt;&gt; 16 POP_TOP #&gt;&gt;&gt; 17 LOAD_CONST 0 (None) #&gt;&gt;&gt; 20 RETURN_VALUE Again, it's just a function call. f.__code__.co_consts[1] #&gt;&gt;&gt; &lt;code object &lt;listcomp&gt; at 0x7f51e841b390, file "", line 34&gt; dis.dis(f.__code__.co_consts[1]) #&gt;&gt;&gt; 34 0 BUILD_LIST 0 #&gt;&gt;&gt; 3 LOAD_FAST 0 (.0) #&gt;&gt;&gt; &gt;&gt; 6 FOR_ITER 12 (to 21) #&gt;&gt;&gt; 9 STORE_FAST 1 (x) #&gt;&gt;&gt; 12 LOAD_FAST 1 (x) #&gt;&gt;&gt; 15 LIST_APPEND 2 #&gt;&gt;&gt; 18 JUMP_ABSOLUTE 6 #&gt;&gt;&gt; &gt;&gt; 21 RETURN_VALUE This function is harder to emulate because there's no other way I know of to use the `LIST_APPEND` opcode; calling `.append` has nontrivial overhead: def f_inner(xs): _res = [] for x in xs: _res.append(x) return _res dis.dis(f_inner) #&gt;&gt;&gt; 32 0 BUILD_LIST 0 #&gt;&gt;&gt; 3 STORE_FAST 1 (_res) #&gt;&gt;&gt; #&gt;&gt;&gt; 34 6 SETUP_LOOP 27 (to 36) #&gt;&gt;&gt; 9 LOAD_FAST 0 (xs) #&gt;&gt;&gt; 12 GET_ITER #&gt;&gt;&gt; &gt;&gt; 13 FOR_ITER 19 (to 35) #&gt;&gt;&gt; 16 STORE_FAST 2 (x) #&gt;&gt;&gt; #&gt;&gt;&gt; 35 19 LOAD_FAST 1 (_res) #&gt;&gt;&gt; 22 LOAD_ATTR 0 (append) #&gt;&gt;&gt; 25 LOAD_FAST 2 (x) #&gt;&gt;&gt; 28 CALL_FUNCTION 1 (1 positional, 0 keyword pair) #&gt;&gt;&gt; 31 POP_TOP #&gt;&gt;&gt; 32 JUMP_ABSOLUTE 13 #&gt;&gt;&gt; &gt;&gt; 35 POP_BLOCK #&gt;&gt;&gt; #&gt;&gt;&gt; 37 &gt;&gt; 36 LOAD_FAST 1 (_res) #&gt;&gt;&gt; 39 RETURN_VALUE But no, this is not a C routine in any meaningful sense. &gt; The only added cost is a single identity check per item It also does an extra loop over the keys and a load of function calls. Anyway, times. I'm timing four functions: def values_in_sentinel(keys, dict): sentinel = object() items = (dict.get(k, sentinel) for k in keys) return [it for it in items if it is not sentinel] def values_in_catch_iter(keys, dict): for key in keys: try: yield dict[key] except KeyError: pass def values_in_catch(keys, dict): return list(values_in_catch_iter(keys, dict)) def values_in_original(keys, dict): return [dict[key] for key in keys if key in dict] def values_in_fast(keys, dict): return [dict[key] for key in dict.keys() &amp; keys] `values_in_fast` is a bonus. It does lose order, though, and is slower than what you could do if the function required a `set`. values_in_sentinel (times in ns/iter) | PERCENTAGE OF KEYS IN DICT SIZE | 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% -----+---------------------------------------------------------------------------------------- 1e1 | 282.4 293.4 307.3 319.2 325.4 325.3 350.3 351.4 350.6 365.8 364.6 1e2 | 217.9 225.6 235.9 237.9 243.6 253.3 264.6 269.5 273.7 276.6 274.2 1e3 | 208.3 219.4 225.7 227.2 240.6 249.2 251.4 250.0 258.8 255.0 265.6 1e4 | 211.0 218.0 227.6 234.3 239.9 249.5 254.0 257.4 259.4 263.7 263.8 1e5 | 217.7 227.4 232.4 239.4 247.6 253.5 259.9 262.2 263.7 268.4 268.2 values_in_catch (times in ns/iter) | PERCENTAGE OF KEYS IN DICT SIZE | 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% -----+---------------------------------------------------------------------------------------- 1e1 | 399.5 387.6 370.3 349.3 332.2 309.0 287.0 267.5 247.2 221.5 193.5 1e2 | 339.7 323.0 302.2 289.1 274.4 252.8 237.6 213.3 195.9 169.0 145.4 1e3 | 324.4 308.7 297.7 284.1 265.1 242.8 224.2 205.8 180.9 158.3 133.8 1e4 | 334.4 315.3 297.4 278.9 259.1 248.2 229.8 204.8 183.3 160.1 133.9 1e5 | 339.7 325.7 309.6 291.8 274.5 255.9 236.9 213.9 188.9 167.0 139.2 values_in_fast (times in ns/iter) | PERCENTAGE OF KEYS IN DICT SIZE | 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% -----+---------------------------------------------------------------------------------------- 1e1 |2313.9 2379.9 2359.6 2377.8 2397.5 2406.4 2417.4 2413.5 2423.5 2459.6 2494.6 1e2 | 244.4 261.6 273.0 293.7 303.5 322.2 326.2 345.5 361.1 366.9 390.7 1e3 | 36.5 52.8 66.0 79.5 90.7 107.4 119.9 125.5 134.3 141.1 146.0 1e4 | 16.6 29.8 38.6 46.4 53.6 60.9 67.9 73.0 76.0 77.4 80.1 1e5 | 16.5 25.4 33.1 40.5 47.6 55.9 63.2 68.8 71.6 74.3 76.9 values_in_original (times in ns/iter) | PERCENTAGE OF KEYS IN DICT SIZE | 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% -----+---------------------------------------------------------------------------------------- 1e1 | 72.8 91.1 95.2 115.8 121.7 138.0 154.8 147.3 158.5 159.8 181.2 1e2 | 41.2 53.4 66.6 75.2 83.6 96.6 106.2 112.3 121.6 127.6 133.0 1e3 | 37.9 49.0 58.3 71.4 80.5 89.4 99.2 108.9 113.7 119.5 124.4 1e4 | 39.3 50.9 61.5 71.7 81.5 92.3 101.9 109.5 115.2 122.0 126.7 1e5 | 43.7 55.0 66.0 75.1 86.3 96.3 106.8 114.1 120.1 126.9 131.8 For high hit rates (~100%), my version runs in half the time. For low hit rates (~0%), /u/xXxDeAThANgEL99xXx's version runs in two thirds the time. For ~50% hit rates, they are about the same. [Full timing code.](https://gist.github.com/Veedrac/d4548b8906fb698a3216) 
well, you said at one point that you did a search/repace with map. you could instead have wrapped this around the code: (lambda map=(lambda a:lambda v,w:a(a,v,w))(lambda s,x,y:[lambda:[x(y[0])]+s(s,x,y[1:]),lambda:y][[] in [y]]()): ... )() and presto: your own self-defined map function :D
Anaconda is a distribution of packages. If you are on Mac it's great, if you are on PC you'll save yourself some headache if you use Winpython, coming from Matlab, it's what I used and it was pretty nice. Spyder is the IDE you want to use. It exactly resembles the Matlab IDE (with some minor differences). It also has a really good variable explorer (just like Matlab) and the ability to open interpreters as separate instances (Think of them like separate matlab instances that just live in one place) The tools you'll need are probably numpy (does math), scikit-image (lots of sweet image functions, basically matches the image toolkit of Matlab except it fails at video importing), and matplotlib (graphing and some image uploading tools). Let me know if you need any screenshots of what I'm saying. 
Very handy! Saved.
youtube?
http://haystacksearch.org/
Good Job with the filtering @alsweigart ... This is the guy behind http://importpython.com/books/ 
OMFG!!! There's a Headfirst Python?!?! (and it's been out 4 long years... grumble) The headfirst series is fucking magical. This one's totally worth purchasing. Thanks OP. Nice link.
[Here you go](http://interactivepython.org/runestone/static/thinkcspy/index.html). An interactive book. Some people might also recommend codeacademy and while most people might disagree, I don't think you should learn Python there since it mostly just teaches syntax and not enough about thinking like a computer scientist. EDIT: fixed link
Your books are by far my favorite! Seriously, they're the first I recommend because there's this incredible hands on element to them. I'm teaching someone python with a mix of pygames and secret ciphers and the response is great. You have incredible talent for writing these things and I really hope we see more!
I found codeacademy.com was a great first place to start.
Thank you. Some people are recommending pycharm and pydev. Is it something as interactive python? I'm basically looking for a website or program that I doesn't require book reading etc. Preferably interactive games or something to touch the water. 
[Try this one](http://codecombat.com/). I've only tried a few levels of tutorial but if you insist on not wanting to read too much then that's your best bet. Not sure how much it teaches you about CS since I haven't completed it myself but it will at least help you with problem solving.
Is [libdynd](https://github.com/ContinuumIO/libdynd) in the right direction or is that still too heavy to address this concern?
Lol! This is awesome! I will definitely give it a try, but the interactive book and the game is great. Let me know if you have more you recommend! Thanks a bunch!
Yeah. A little too gamey, but interactiveness is what I'm looking for. Kinda like Mavis Beacon for typing. Have you every played?
Regarding tabs vs 4 space : Do whatever you want. TABs are easier and less memory. For whatever reason, 'pythonistas' have 'decided' on the singular arbitrary nonsense of making lines wrap consistently. Forgetting that a majority of python has emerged as a way to develop and test with the leanest development, somehow the one single aspect that 'community' agrees upon is the very same that is pure nonsense. Use tab. Hail satan.
I recommend the first three books on the page, but then again I'm the author of them. :) Seriously though, if you are a complete beginner and interested in making games or crypto programs as a way to learn programming, you can download the books for free: http://inventwithpython.com Other than those, Python for Kids is good (full disclosure, my next book is also being published by No Starch Press) and Python Programming for the Absolute Beginner. For free ones, Learn Python the Hard Way is decent.
Heres a naive example: import socket s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) s.connect(('87.248.222.209', 80)) s.send('GET / HTTP/1.1\nHost: www.nasa.gov\r\n\r\n') response = '' while True: buf = s.recv(1024) response += buf if '&lt;/html&gt;' in response: break print(response) In a real project you probably want to parse the stream for a content-length header and read n bytes before you return the result. http://lmgtfy.com/?q=python+socket+http+request
There's also Kivy, which is particularly good for touch screen devices. 
Use basic db query, title__icontains or something. When your query get slow, start to use sphinxsearch or elasticserch or any external search engine you want. The important moment is you may not have to migrate on such engine and querys be ok.
Just bookmarked and noticed that this page has not title tag set, also a meta description wouldn't hurt, since this page certainly deserves to be found through Web search.
Bit of a misleading title, since these all have 'buy' on them, for various prices, and the majority of them are not free.
Hey thank you very much. This is an awesome resource you have presented here. I am going to have a book attack now!!!! Hahahahah
If you consider pygame to be obsolete, you must have a replacement in mind when it comes to creating games using Python. So, what is it? (Pyglet's development seems to be completely stalled.)
&gt; if (event.key == pygame.K_UP) or (event.key == pygame.K_DOWN): &gt; player2.y_speed = 0 Change that to if event.key in (pygame.K_UP, pygame.K_DOWN): player2.y_speed = 0 :]
As always, please use `with` for files.
Yes, excellent point ... but I would see this as part of the next step.
install the `requests` module and then use the following. &gt;&gt;&gt; import requests &gt;&gt;&gt; x = requests.get("http://74.125.224.72/") &gt;&gt;&gt; x.status_code 200 
Thanks
28 variously priced python books didn't poll well in trials.
You can make sys.exit calls and it would be trivial to keep track of time inside a script. Combined, I think these two would achieve what you want: periodically check the time and sys.exit if it exceeds what you want.
What are you trying to accomplish specifically? I think you are thinking of doing it in a wrong way. You need to have callback that expects a response. If callback doesn't receive anything then you break out. For example, response = None if connection == 'on': response = http.request() if response is None or response != 200: return False Something like that.
It's worth mentioning that I made a library called [pyglet2d](https://github.com/hsharrison/pyglet2d) that adds simple polygons to pyglet.
Check out the [timeout](https://www.gnu.org/software/coreutils/manual/html_node/timeout-invocation.html) command.
If it's for a service (unix daemon) You might want to use a systemd watchdog timeout. Basically, you write a certain string to a socket, if you fail doing that within the timeout, your application will be terminated &amp; restarted. We use that kind of watchdog in production for processes, combined with a crash-only methodology (Crash only is when you don't define a "good exit" from your process, and always clean out state when you -start-. Thus always testing your cleanup functions in practice, so error handling is basically "bail out and start over" )
This is the best general option. Make sure you flush any open output file handles before wait points. 
I've used [Panda3d](https://www.panda3d.org/) in multiple projects and it's worth checking out.
neat, keep up the good work! happy hacking :) +/u/ppctip 10 peercoins
^__[Verified]__: ^/u/cshoop ^^[[stats]](http://www.reddit.com/r/PeercoinTippingBot/wiki/stats_cshoop) ^-&gt; ^/u/hharison ^^[[stats]](http://www.reddit.com/r/PeercoinTippingBot/wiki/stats_hharison) __^Ƥ10 ^Peercoins__&amp;nbsp;^__($7.5814)__ ^[[help]](http://www.reddit.com/r/PeercoinTippingBot/wiki/index) ^[[global_stats]](http://www.reddit.com/r/PeercoinTippingBot/wiki/stats) ***** ^[Peercoin](http://www.peercoin.net/) ^- ^The ^Secure ^&amp; ^Sustainable ^Cryptocoin
this worked for me when I needed the same http://stackoverflow.com/questions/2281850/timeout-function-if-it-takes-too-long-to-finish
Hey thanks! It's just a simple little library and could certainly use some more work but I appreciate the tip.
The OP was asking for online sites that offer an interactive way; LPTHW, while beloved by many, is a static (not interactive) tutorial which can not be executed online.
This is the best way. Don't try to implement this yourself. It adds more complexity to your code and thus makes it probably more messy. Also, you can [catch the signal](https://docs.python.org/2/library/signal.html) in your code.
While on mobile, I really only see two thing that might speed things up. 1. Use xrange instead of range. That will probably work better for larger data. 2. Instead of enumerate and ignoring that value, just do xrange( Len (v)). Then it won't pull that data into a variable each time. 
done, gives me about ~40ms improvement. Still too slow :/
Would it be hard for you to make epub versions of your books?
I think this is a good answer. Depending on what you're trying to do, it's likely a good idea to divorce the timeout functionality from the script itself.
I moved from Matlab to Python about a year ago for writing relatively large numerical apps with full GUIs. Writing these apps in Matlab at all was really not that smart... but that is another discussion. I also use the Anaconda distribution and mostly use Spyder for my development needs. Eventually I would like to get up to speed on Pycharm and/or Visual Studio with Python Tools... I have played around with both and see the merits of using both of these IDE, particularly Pycharm. For interactive image manipulation, you will probably want to use IPython to inline image processing output; pillow, scikit-learn, and openCV with python bindings are probably the libraries you want to check out for your image processing needs. another one: pyQtGraph... I have only played around with this library a little but it seems to be very well suited to integrate into GUI applications and is reportedly a highly-performant plotting and basic image processing library. IF you get into doing Python GUI's, prepare to be annoyed because there are no truly first class python GUI API libraries that are also good and well documented. My rookie python opinion, after having surveyed the field and used several of these API a little: Bite the bullet and learn Qt, using either PySide or PyQt bindings. Steepest learning curve but everything you will likely ever need is there and works well. Also check out enaml, which provides a model-view framework for Python Qt. wxPython seems pretty good also... there is no obviously best option here... just 2-3 "good enough" options In my (rookie) opinion.... the lack of a really great pythonic GUI library is almost enough of a reason to just write gui apps in a different language (C#, Groovy, C++, etc.) 
I moved from Matlab to Python about a year ago for writing relatively large numerical apps with full GUIs. Writing these apps in Matlab at all was really not that smart... but that is another discussion. I also use the Anaconda distribution and mostly use Spyder for my development needs. Eventually I would like to get up to speed on Pycharm and/or Visual Studio with Python Tools... I have played around with both and see the merits of using both of these IDE, particularly Pycharm. For interactive image manipulation, you will probably want to use IPython to inline image processing output; pillow, scikit-learn, and openCV with python bindings are probably the libraries you want to check out for your image processing needs. another one: pyQtGraph... I have only played around with this library a little but it seems to be very well suited to integrate into GUI applications and is reportedly a highly-performant plotting and basic image processing library. IF you get into doing Python GUI's, prepare to be annoyed because there are no truly first class python GUI API libraries that are also good and well documented. My rookie python opinion, after having surveyed the field and used several of these API a little: Bite the bullet and learn Qt, using either PySide or PyQt bindings. Steepest learning curve but everything you will likely ever need is there and works well. Also check out enaml, which provides a model-view framework for Python Qt. wxPython seems pretty good also... there is no obviously best option here... just 2-3 "good enough" options In my (rookie) opinion.... the lack of a really great pythonic GUI library is almost enough of a reason to just write gui apps in a different language (C#, Groovy, C++, etc.) 
Cool, but that picture was a waste. Posting what troubles you ran into, what was surprisingly easy, and what you would do if you started from scratch with porting would have been more useful. For me, I started out porting from 2.7.8 to 3.4 by running my application and test suite under python 3.4, fixing or removing lines until it started up. Then one by one I added everything back in a version agnostic way. What was great about this is that I could `git add -p` the individual pieces of my app directly into releases without having to tell everyone to prepare for conflicts.
Your computer screen is not an image. You can take a screenshot, and use PIL to process that image ... but what you are asking is "how do I use a Python program to control some other program by simulating a mouse click" which is a very different and much more complicated task than simply using PIL to process an image.
You can click on the Free filter at the top and just see the free ones.
I just want a Python program that will scan the whole screen for a certain set of pixel colours then click on them.
http://www.reddit.com/r/Python/comments/1mkf5h/do_not_understand_with_statement_entirely/cca34wn
Try looking for ways to eliminate manual indexing. I created a list of lists and iterated over it using manual indexing and pure iteration, the iteration was 30% faster. So instead of: def findPivot(m, start, col): for row in xrange(start, len(m)): if m[row][col]: return row return None Do: def findPivot(m, start, col): for n, row in enumerate(m[start:]): if row[col]: return n return None This may give you a minor speedup: Replace if pivotRow == None: with if pivotRow is None: Let me know if these make a significant difference or not, I'd be interested in your results either way.
How much programming experience do you have? I have programmed for many years and would consider this a major project to undertake.
I'm new to programming. I would have never considered this a major task to begin with. I got an answer on my Stackoverflow post which seems to be less complex then people say, refer to that to see what you think. **Note**: I'm not saying this isn't difficult I'm just trying to find the simplest way to do it.
What you likely want then would be to use something like Sikuli (http://www.sikuli.org/). However, before you do this... you need to start by learning how to write basic programs. What you are asking is akin to saying "What kind of shoes should I get if I want to run a marathon?" while you have never run for longer than 10 meters.
Free download: http://www.it-ebooks.info/book/373/
The categories don't allow linking. All the free books are there you just need to click the 'Free' button.
Haha! I've already used Sikuli, it's really great! Although it lacks the ability to export the Sikuli files into a **.exe**.
hi. --shared is the default on the current trunk (at least for linux), but not on the released version. We should really update the docs, thanks for pointing it out.
Tkinter is used mainly for gui and programs. But many people use it for games due to its simplicity 
Congrats! Nice to see a fellow starting programmer, I have made about 6 games from scratch now and it's nice to see others
These are general language features that have appeared and matured in a variety of languages. C++ is becoming more pythonic, more javascriptic, more C#ic, etc. It's like adding ABS to an old car and saying now it's a lot more like a Honda.
Not really reading your code, but if it is purely linear algebra then numpy can do it 20x-100x faster by doing the loops in c. There's a learning curve though, and switching data between python objects and arrays is time consuming so using numpy for one little part would be slower than not at all. Edit: https://www.reddit.com/r/learnpython/comments/2nav22/some_points_about_numpy_performance/?sort=confidence
&gt; It must be solved in pure python, so no numpy or other libraries that might help.
Where is the time being spent? I imagine in calls to findpivot and swap right? Can those be optimized?
 Both swap and find pivot need &gt;1ms accumulated. Most time is spent iterating through the matrix and toggling values. 
I don't understand what you mean?
Like others have said, the timeout command is the easiest. But if you want something baked into your script, or are on Windows, you can do something like this: import threading import time import os from functools import wraps class timeout(object): def __init__(self, time): self.time = time def __call__(self, func): @wraps(func) def wrapper(): t = threading.Thread(target=self.timer, args=[]) t.start() func() t._stop() return wrapper def timer(self): time.sleep(self.time) print("Watchdog Timer Expired. Exiting.") os._exit(-1) This creates a decorator that will launch a timer thread which will halt the script when it times out. To use, just decorate your main function. (The time here is in seconds): @timeout(6) def test(): n = 0 while (n &lt; 5): print("Running..") time.sleep(1) n = n+1 print("Done.") if __name__ == "__main__": test() Note: This is Python 3 code. Update the print statements for Python 2.x 
The tool you are looking for is called Sikuli. http://www.sikuli.org/ It does exactly what you are requesting.
Pillow is the fork of PIL when it was abandoned. Pillow is the one to use.
I've already used Sikuli! It's a great program although it lacks the ability to export to a **.exe**.
How come you use enumerate when you don't need the value but don't where you do? Can you reorganize it so you get the row value at the top so you don't look up toggle[row] for every column? It's just ms savings though. Also, maybe you can replace your inner loop with a map. I think but don't know that map is faster than a for loop.
I counted the total number of characters wherever there was examples for both Python and C. Python: 431. C: 801. C has its place as a very fast core language, but I cringe when I think what these character totals would have been before these additions.
That is a good point. I could do the same for str, int, join and range, at which point I might as well just write in normal python and it wouldn't be nearly as fun.
Well, if that does not suit you, you will have to do it yourself. Sikuli relies under the hoods on OpenCV to drive it's image recognition. You might also want to look into SimpleCV, which simplifies the work with OpenCV. http://simplecv.org/
Not interested in that. People play embedded games and watch embedded videos. -It's more convenient -It's less dangerous (No chance of downloading virus.exe) AND: If I'm trying to turn people onto a new idea or concept that might involve learning or thinking (which people don't like to always do) via a game, I want to make playing that game easy. I don't want to give people a reason to not look at my ideas. Downloading a (potentially dangerous) file is just one more reason for them to close my page and disregard my content. I don't see the logic in wrapping my ideas in a box people can't easily open.
Is that with spaces or tabs?
The problem is when you have libraries or already existing code which uses different subsets of C++. Suddenly you have to think about, and convert to and from, all sorts of different conventions.
This article is explicitly about new C++11 and C++14 features. I doubt you will find much valid C code in it.
Fair enough I was just trying to be funny. Thanks for the post 
Hey, juliusc, just a crazy request, because I've worked on a few projects, but nothing on the level of Spyder. Would you be willing to do some presentation (video or blog post) of how you work on this project? Builds for various OS's, GUI building, debugging in Spyder on a non-scientific project like this? This software is proof of how beautiful and clean a cross-platform GUI can be built in Python.
Character totals seems like a strange metric to judge a language by.
I killed the interpreter and can't exactly see what I did but it looks like spaces. However both C and Python had spaces on the webpage.
C and C++ are different languages with fundamental incompatibilities.
There's a larger discussion at http://www.reddit.com/r/cpp/comments/2o27lu/c_has_become_more_pythonic/
90% of the time is spent doing for i in xrange(len(toggle[row])): toggle[row][i] ^= toggle[nextFreeRow][i] This suggests you should have rows of integers instead, and use `toggle[row] ^= toggle[nextFreeRow]`.
Quantum physics is also strange. What's your point?
Use [SIGALRM](https://docs.python.org/2/library/signal.html#example).
FIY: enumerate() starts by default with 0, but we can add a second parameter to set the start-value: def findPivot(m, start, col): for n, row in enumerate(m[start:], start): if row[col]: return n return None But that isn't any faster..
But `list` doesn't support the xor operand. nextToggle = toggle[nextFreeRow] nextPuzzle = puzzle[nextFreeRow] for r in xrange(pivotRow+1,n): if toggle[r][col]: toggle[r] = map(operator.xor, toggle[r], nextToggle) puzzle[r] ^= nextPuzzle This shaved around 100ms of the time, I'm at ~220ms total with some other improvements, but still too slow.
This does not work in practice. Once you get out of the CS101 or Project Euler territory, you find yourself in a need of an XML parser, or MySQL connector, or HTTP library, or anything to that tune. This guy on the internet has a really nice C++ implementation, but wait, we can't take it because it uses exceptions (we don't) or templates (we don't) or STL (we don't). So let's just implement it from scratch, or better yet, let's take someone's implementation in C, because that's the only thing everybody can agree on. This goes on on different levels. The language doesn't have `string`, for god's sake, so you can use `char *` or `CString` or `std::string` and that's even before we wander into Unicode territory. But please don't blame that other guy who has a nice open-source implementation of this library you need, but chose to use a different string species for his implementation. 
Nay, I mean use a packed representation like [ 0b1001010010101..., 0b0010101010101..., ... ] 
Ah, I see. I only know about BitArray, but it's a third party library. How would I transform my matrix into such an array and get fast access to specific columns in pure python?
Is this legit? As in legal? There's a lot of books there.
&gt; The language doesn't have string, for god's sake, so you can use ... std::string So... It has `string`. And believe it or not, there are several Unicode versions of `std::string` that are literally just template specializations of the same underlying `std::string` implementation. They even have methods to convert ASCII strings to Unicode strings and vice versa, if you need them. Also, you don't use generic programming, exceptions, or even standard data structures? I honestly find it hard to believe you'd waste your time *not* using those features. And also a little scary, considering they're designed specifically to make for safe, consistent, predictable results with reasonable performance. But sure, the language is the problem, and it's definitely not that you maybe haven't used it enough or took the time to understand its design philosophy. Nope, can't be that at all.
The std in std::string doesn't mean it has a sexually transmitted disease, it means it's part of the standard library. As in the library that's part of the language standard. There are people who have decided not to use std::string, but blaming C++ for that (or claiming it doesn't have a string) is like saying Python doesn't have a standard string type because this one guy on the Internet uses lists of integers to represent strings when coding in Python. The only difference between what you're saying and my analogy is that roughly 30 % of all C++ coders are retarded enough to do just that.
Actually you seem to be incorrect. You are right in saying that succinct, readable syntax is very valuable in a language. However, character count plays very little in this. A seasoned developer will skim over verbosity in the language they understand so it really doesn't matter. People complain about java for its verbosity. But to someone that programs a lot in java, it makes sense. More characters? Yes. Does it slow down comprehension? No. Its still clear and readable. We can also agree that you can write bad code in any language and make anything look unreadable and confusing. But no, character count doesn't matter.
Oh god, this is so great, I would never have believed it's that "easy" to implement. Still magic to me, I guess a good topic I should look further for the future. Now I pass 4/5 tests, it appears there is some error in the rest of the code, with my luck a simple missing `+1`.. Thank you so much.
True enough, and I didn't mean to imply that C++ doesn't suck as a language, I just meant that there are a lof of problems that C++ gets blamed for that are at least partially caused by really shitty coders. And really shitty coders exist in all languages - just look at httplib in Python.
&gt; there are several Unicode versions of std::string that are literally just template specializations of the same underlying std::string implementation Oh that's nice to know. If I link to a library that is compiled against a non-unicode version of `std::string`, will it mean that I have two different `std::string`'s in my program? &gt; you don't use generic programming, exceptions, or even standard data structures? Yeah, never found enough value in this pile of `std::map&lt;std::basic_string&lt;char,std::char_traits&lt;char&gt;,std::allocator&lt;char&gt; &gt;,std::basic_string&lt;char,std::char_traits&lt;char&gt;,std::allocator&lt;char&gt; &gt;,std::less&lt;std::basic_string&lt;char,std::char_traits&lt;char&gt;,std::allocator&lt;char&gt; &gt; &gt;,std::allocator&lt;std::pair&lt;std::basic_string&lt;char,std::char_traits&lt;char&gt;,std::allocator&lt;char&gt; &gt; const,std::basic_string&lt;char,std::char_traits&lt;char&gt;,std::allocator&lt;char&gt; &gt; &gt; &gt; &gt;` stuff. The language is alright; it's me who's stupid. That's why I left C++ around 2001.
Thanks for this fascinating article! In my experience with Delphi, people would freak out over something like this. Every time I see a new idea proposed, someone reacts to it with "OMG you want to turn Delphi into C#/Python/Java/etc.!" Glad to see other languages embrace good ideas wherever they find them.
Not sure if this is much help but I found this while googling: http://aripollak.com/pythongzipbenchmarks/ What version of python are you using? Edit: Oops, forgot to say the important part is the conclusion which talks about `io.BufferedReader()` to speed things up.
Fuck off python, stay away from glorious programming language.
The syntax is still god awful.
I'm not a pro with TKInter but don't you have to set the variables outside of the constructor using a .set() method? for instance: string_1 = StringVar(root) string_1.set('One') perhaps I am misunderstanding what you're trying to do however. 
I recommend [PyAutoGUI](https://github.com/asweigart/pyautogui) + read [this tutorial](http://code.tutsplus.com/tutorials/how-to-build-a-python-bot-that-can-play-web-games--active-11117) .
&gt; If I link to a library that is compiled against a non-unicode version of std::string, will it mean that I have two different std::string's in my program? The standard library defines all versions of `std::basic_string` that are defined in the actual standard, you can't link to a library that just defines one or the other if it truly is a standard library. `std::string` is really `std::basic_string&lt;char&gt;`. `std::wstring` is really `std::basic_string&lt;wchar_t&gt;`. And there are two other versions for 16-bit Unicode and 32-bit Unicode as well. Additionally, there is a `to_string` and a `to_wstring` method defined for each type of std::string, so you can convert to and from ASCII and Unicode-8 for a given string type. As for your second point, good job at being overly dramatic and going ahead and defining the default template parameters that are filled in for you. How about instead std::map&lt;std::string, std::string&gt; like a sane person. You do realize those extra template parameters are there for different use cases, right? With the third template parameter you can choose to sort the keys in a different way so you can iterate over the map in e.g. reverse alphabetical ordering. The fourth template parameter is for when you have some different allocator, maybe a debugger allocator (like the way valgrind will replace malloc to track allocations, except much more sane and safe). But I guess our data structures should just be black boxes that only work in one way and aren't modular at all. That isn't even touching on exceptions and generics in general, by the way. I wonder what you have to say about those. &gt;That's why I left C++ around 2001. Then you shouldn't be talking about modern C++ when your knowledge of the language is a decade old.
One more step toward Lisp! 
Try [pandoc](http://johnmacfarlane.net/pandoc/).
Thank you for your reply. I did some quick benchmarking comparing (1) `gzip`, (2) `gzip` wrapped in an `io.TextIOWrapper` and (3) `subprocess` using `zcat`. I used both Python 2.7.8 and 3.4.1. | `gzip` | `io.TextIOWrapper` | `subprocess` ---|---|----|---- Python 2.7.8 | 3min | 1.2min | 0.23min Python 3.4.1 | 2.4min | 1min | 0.23min Task was a line count (51,696,831 lines) File Size (compressed): 831MB So using the `io.TextIOWrapper` is faster, but shelling out is still a lot better!
SFML also has Python bindings for it (pySFML). Like SDL and pySDL2 it's a bit lower level than a Game Framework. I've been looking into embedding pypy into love2d in order to make use of the excellent C++ implementation of Love2d but got a bit stuck on what to use for the C++ binding. Similarly there's a Love2d API for Python floating around called Kundalini but I can't find the link again.
kivy, or if you dont care about mobile, use the python-sdl2 bindings directly. fwiw, Boo is officially depreciated and no longer supported in unity. The next version will remove the option to create new Boo files in the editor and issue depreciation warnings. At 'some point' support for it will be removed entirely. So don't bother going down that road... 
I feel like I should create an FAQ of 'reasons not to use pygame, and what the meaningful alternatives are'. Here's a snippet from my comment history: "Sure. Things that are bad about pygame: not portable, fixed function graphics pipeline only, crashes all the time, crashes are always always hidden in obscure cython code so no way to debug crashes, no mobile support, no gui worth talking about, barely maintained (bugfix pull request can take &gt; 3 months to merge, don't bother trying to contribute fixes), no bundle tool or other useful way to distribute apps. It may be fine for making toys, but you won't leave anything meaningful about modern gamedev from playing with it, and you won't have anything worth talking about (or any way of sharing what you make) if you use it. (specifically, this is in stark contrast to kivy which has an active community, is actively maintained, uses a modern graphics pipeline and actually (eg. bulldozer) makes an effort to address the issues with writing games in python)" You could also consider using the sdl2 python bindings with opengl directly, so long as you're aware of the limitations (ie. fixed function pipeline) in the native sdl graphics api and don't use it directly.
wat ?
I reject the premise and conclusion of this article completely. There is no reason why you can't learn to drive an automatic before learning to drive a manual. That's what I did, and there were no tears involved. Learning C before Python won't make you a better programmer. Rather, you're likely to get stuck on the minutiae and write crappy C. By learning Python, you can develop better abstract thinking. You get hashtables (dictionaries), `itertools`, first-class functions, object-oriented programming, and many other tools for free. Once you get hooked on the goods, when you go to C, you'll yearn for them, and re-create them, resulting in more elegant code than what you would have built had you been suck in an instruction-by-instruction mindset.
You could try zcat, and if it fails, except to using the slower more compatible method.
...so does php for some similar and some a bit different reasons. bottom line: the sucky users are put into the equation of the suckiness rating of the language. 
&gt; std::map&lt;std::string, std::string&gt; Either the standard tools have got much, much better, or you are really good at deciphering those. (Or googling.) In my day, I frequently misspelled a word, and had two pages of incomprehensible shit thrown at me. &gt; our data structures should just be black boxes that only work in one way and aren't modular at all That's my expectation of string. &gt; I wonder what you have to say about those. Exceptions tend to leaks since you have to free anything you've allocated before throwing, so they are only useful for "fuck it, I quit" type of situations (like the one they throw in `new`); also, stack traces usually get corrupted so you don't even know where it happened. (I used to _divide by zero_ instead of throwing an exception, since in that case you at least get your stack trace right.) Generics are fine in Java, for example; in C++ they suck, partly because of the long mess of compiler errors, and partly because they don't work properly with things like `const`. Their late addition to the language shows in having no way to initialise `std::vector` with ('foo', 'bar', 'baz') on spot. The time needed for their compilation is huge, and leads to unfathomable things like "distributed compilation farms" that are simply unheard of in any other language. &gt; you shouldn't be talking about modern C++ when your knowledge of the language is a decade old. See, my problem with C++ is that it had too many features that worked poorly with one another. This is a problem you can't solve by adding _even more_ features (which is what they've been doing).
But at least httplib in Python _exists_. Unlike C++, where there is no sign of http lib in the standard library. Other things that can be said about the C++ _standard_ library: there's no network sockets, no regular expressions, no logging, no pickle-ing nor other persistence, no csv/json/xml parsing, no DOM/SAX/StAX, etc.etc. And of course, none of the `numpy`/`scipy` stuff.
You also can't see the sky when your nose is down in the mud. Learning C first is sure to be a pedestrian, tedium-filled experience where you'll juggle inane syntax and fight with horrible language design choices without even knowing that's happening to you. Instead of doing interesting things, you'll be doing the basics, the hard way. That the author believes that is the proper way to introduce programming to someone is difficult to take seriously. Personally, I *wish* Python was my first language. My interest in programming might have been a continuum instead of the start-stop experience that it was until Python. As for the driving parallel, what can I say, I don't have a license, but I sure know how manual transmission works. It's the *only* transmission I've ever seen. And this extends to languages - it took until university to see Python - see *any* high-level language. Is that really something you'd want for the younger generations? "I did shit the old way, therefore that's best, because look how well I turned out." Oh please. I really don't understand the "Python is easy to learn, therefore it's not interesting" line of reasoning. C is terrible, but it was still designed for actual use. An esoteric language would be much more difficult to teach than C. So should we switch to teaching programming in Brainfuck (Intercal, Lolcode, Befunge, etc.)? It's ridiculous to suggest that the challenges of programming end with learning syntax. 
I am not a programmer. I am an engineer. My job is to get things done, not to understand a computer better. Whatever makes me get my job done faster with fewer bugs is cheaper for my company and thus better for me. Also, I can code in Fortran and code in C and I picked both of them up without every having had a formal class in them (or any other language for that matter).
Well, the const char* is from C, std::string is C++. If you want to do string manipulation in C++, you'd better use std::string. Not using the Standard Library in C++ is shooting yourself in the foot. Before python3, there was also the fiasco with strings. Everything was a string, they had to introduce byte array in python3.
Since C++ is retro compatible, you can use the new features with some older code. For example, I'm using smart pointers in C++11 in the core of my project, but I use Qt for the UI, which uses raw pointers. If your code is segregated, you'll be fine.
I think it's planned for C++17.
Check the first question's code.
&gt; ...no regular expressions, ... False! [regular expressions](http://www.cplusplus.com/reference/regex/) But you are right, that bassetries are not much included into C++
Oh, it's C++2011 and they finally have regex support! Now I only have to wait until the compilers implement it...
&gt;Either the standard tools have got much, much better, or you are really good at deciphering those. The tools have gotten better. &gt;That's my expectation of string. I was referring to `std::map`. A string isn't really a data *structure*, more of a form of data. &gt;Exceptions tend to leaks since you have to free anything you've allocated before throwing, Which is done automatically if you follow proper RAII (**R**esource **A**quisition **I**s **I**nitialization) principles. Also, smart pointers are basically standardized optional garbage collection. [IDEOne example](http://ideone.com/eskem4). &gt; Their late addition to the language shows in having no way to initialise std::vector with ('foo', 'bar', 'baz') on spot. Wow, you really haven't kept up with the language. This is totally valid: std::vector&lt;std::string&gt; example = {"foo", "bar", "baz"}; [IDEOne example](http://ideone.com/Uy79Ls). &gt;See, my problem with C++ is that it had too many features that worked poorly with one another. This is a problem you can't solve by adding even more features (which is what they've been doing). The problem is that you're assuming the standards committee is trying to solve that "problem" at all (which by the way isn't much of a problem in the first place. You don't *have* to use all of C++'s features to do something. Shocking, I know). And how do the different features not work well together? I hear this argument but just don't get it because I've never had an issue working in standard C++. Also, they've been adding syntax and *pushing* for that syntax and *heavily discourage* the old style, but realize the importance of stability and keep it there so it interacts fairly well with legacy code. You know, so things don't break, or keep people from using newer standards *because* it will break legacy code. Turns out always using only the most bleeding edge technology and newest standards *isn't always* a good idea!
You're using an invalid DLL (a C binary library), which means you probably are using 32 bit Pygame with 64-bit windows. Use 32 bit Python or 64-bit PyGame.
The "/D UNICODE" is a compiler switch for Visual C++, telling it to define the symbol UNICODE for the preprocessor when compiling OpenCV, thus enabling unicode support. So unless you are compiling OpenCV yourself, this is probably not the fix you are looking for. 
It was less infuriating than the switch from python 2 to 3, where you couldn't even use old stuff. That's why it took so many years for people to switch.
Now we only need to get network sockets, and we might see a Django-style web framework by C++2050.
He said craft. 
Maybe you could go with &lt;http://jitpy.readthedocs.org/en/latest/&gt;. Haven't tested it though but it sounds feasible.
Strange the literal %1 though. Maybe just a typo in the error message, but if not, then there's a problem in the actual file looked up. 
Does pypy do better here?
What is this
It really is that complicated. There are gotchas everywhere due to the historical development. Like how std::vector behaves differently with initialiser lists.
Yes, C++ is more verbose than python in many cases, and was worse before C++11 features. But it is order of magnitudes more efficient. Generally when writing C++ the amount of time you spend designing program structure and algorithms will be large enough that the typing time is pretty irrelevant. 
Kivy depends on many Python libraries, such as pygame .... From: http://kivy.org/docs/guide2/basic.html
Yhe ... dude do everyone a favor and don't talk about things you don't know, you haven't used the language for a while and you don't really know what is going on. Boost has become a de-facto standard, it's the batteries included of c++, and libraries gradually migrate from Boost into the standard. Boost.Asio gives you everything you need network wise and I even used it as a web sockets server. Web frameworks were always here I never used django but take a look at wt , cppCms and there are more.
Brilliant. Thanks for the reply. I'll give it a go tonight. I did search through the comments but must have missed this one. I'll let you know if it works :)
&gt;Also, you don't use generic programming, exceptions, or even standard data structures? I honestly find it hard to believe you'd waste your time not using those features. And also a little scary, considering they're designed specifically to make for safe, consistent, predictable results with reasonable performance. I think you are kind of missing the point. It is not about these specific features. The problem is that C++ is such a huge language that you have to, as was mentioned previously in this thread: &gt;Use from it what you need I think most people agree that you don't use *all* of C++. The problem is you might end up with different code bases using different parts. `char *` is sometimes used for strings, whether you like it or not. You also have `malloc` and `free` vs. `new` and `delete` vs. smart pointers. 
I come from a C background, and have used (shudder) C++. I work in the low level/ embedded domain, where C is usually all you have (though this is changing). Those of you who have never used C, let me tell you who it feels like (compared to Python). Make a fist. Now punch yourself in the nose. Congrats, you are now a C programmer. Collect your certificate on the way out :)
I've heard a lot of people who outright refuse to touch Boost. Are there issues with it, or are these people stuck in the mud?
Most haven't switched I said, but good thing on them for maintaining them both parallel. Some of the key libraries I use are based on 2.x still 
C++'s std::vector, Java's ArrayList, Ruby's Array and Python's list are all the one data structure. That is a variable sized collection backed by a primitive array that's copied over to a new larger array when the primitive array is full. C++'s list, Java's LinkedList and lists in many functional languages are actual linked lists where each element has a pointer to the next.
There's a balance in both cases, though I think the whole comparison is poor. You need a familiarity with a car in general before you can get going at all - what is what and order of operations just to get going (learn some basic control and data structures and a little theory before you can write code). Secondly, there is a balance with the teaching/learning process. In no way do I think we need to cater to all newbies - but I do think you may easily deter people throwing them straight into C and making them deal with memory management. (That said, learning all that is important). I really think the article overall isn't fully off, but I don't think you need to do something low level first, as long as you go back and learn/understand it 
 img = cv2.imread('D:\\Users\\Greg\\Documents\\Python\\cvtest\\translation.jpg') No, that's fine, it's weird that imread doesn't throw the error, but the first function call does. 
This presumes you don't have to deal with other people's choice. Rarely the case in practice, and if it were the case, you'd probably have the freedom to choose another language as well. 
It's not a typo, and it's not a problem. The Python exception contains the error message in string form as reported by the operating system. Look for `ERROR_BAD_EXE_FORMAT` [here](http://msdn.microsoft.com/en-us/library/windows/desktop/ms681382.aspx). These strings are the result of passing a numerical Win32 error code to [`FormatMessage()`](http://msdn.microsoft.com/en-us/library/windows/desktop/ms679351.aspx) which uses a `%`-style string substitution scheme. The idea here is that these system messages are translated into however many dozens of languages that Windows supports, and by using this system you can report a problem to a user in their native language. Since the filename occurs at different places in the sentence depending on language, a placeholder system is used so that each translation can remain grammatically correct. Apparently, however, Python is not passing the optional argument list to `FormatMessage()` and this substitution is not occurring.
Boost is Huge, it's a collection of libraries so vast that refusing to use any of it is ... kinda stupid. I get the people who criticize particular aspects of it, or when people say that it's so standardized that sometimes it gives you bloated code. But a. You don't need to use all of it, and the better sides of her are header only meaning no linking is required. b. The bloated code is in many cases still less than writing it on your own or preferable on adding new libraries.
Python has `zlib` bindings built in, see here: https://docs.python.org/2/library/zlib.html The gzip library actually uses these bindings.
Heroku was awful. Had to bring down my application to free up the connection to the database. It was a fucking joke developing for, and everyone that had advice seemed to have to go to great lengths even to do simple things. It's also expensive as hell, as you've learned. I looked at the prices for decent machines and didn't bother looking at it again for anything. GAE is nicer, but you have to deal with it's own NoSQL datastore. Which to be honest, isn't so bad once you get the hang of it, but it's not exactly transferable to much else. AWS will let you use whatever tech in whatever way, but you'll have to do all the groundwork. Haven't really forgiven them for introducing free plans for new customers after I signed up, so I canceled my service. There are alternatives to these. Openshift, pythonanywhere, etc. etc. Honestly, if you're being professional, you should try to hide as much of the platform as possible. Ideally they shouldn't have to know much about what it's running on (unless they have requirements from other directions)
..and the guys from kivy are on the record as 1) regretting using it, and 2) actively porting kivy to use SDL2 directly as a backend instead because it is more modern, portable and supported. pygame uses SDL1.2 as a backend, which has categorically been abandoned. This is actually the reason why I dislike pygame. I had to use it extensively, and fight with it considerably when working with desktop kivy apps. If you've never had a error like "segfault in .... pygame" I'd argue you've never had the pleasure of working with it very much. Python apps don't tend to crash much, but *man* pygame crashes a lot. 
OK, actually this is the issue. First I tried pip, because I love pip, and I wanted to be able to reliably pull this into a virtualenv with pip. But I have VS2012 and I got all these vcvarsall errors it took a while to get rid of. I had to use that "trick" where I made a shell variable that sets VS90COMNTOOLS = %VS120COMNTOOLS% well, compiling it with the wrong compiler didn't work. I downloaded Visual C 2008, and that installed the correct VS90 compiler, but it didn't work, similar to above it gave a NoneType error. I found [this install instructions](http://docs.opencv.org/trunk/doc/py_tutorials/py_setup/py_setup_in_windows/py_setup_in_windows.html) that says to download a precompiled zip and just copy the cv2.pyd to site-libraries. And that allowed me to import cv2, but that's the error I showed above. So I did some more digging (been digging for a while) So then I found the ['unofficial windows binaries'](repo http://www.lfd.uci.edu/~gohlke/pythonlibs/#opencv) I think I put the amd64 one in first and it still didn't work, so I did the win32. Now it works!!! So yes, thanks, it was a compile problem. So on this note, how now do I pull this into a virtualenv without pip?
You may [want to read this](http://news.dice.com/2013/03/15/comparing-the-c-standard-and-boost-2/) to have a look at the current situation with regards to Boost. When we faced the transfer of our 2MM LoC project to Boost, we just chose to rewrite it in Java.
Can you show the code?
You guys are amazing!!!! Thank you so much!!!
I also use Sublime Text 3. I have both SublimeLinter and Anaconda packages. I use the python linter that comes with Anaconda. Yes, it looks overwhelming, but I try to not think much about it, as long as the linting part is fine. On the other hand, I have only the Annotations package for SublimeLinter. I find it useful to have highlights on `#TODO` and `#FIXME` comments through the code.
There's a python plugin for imageJ? do tell! - unless you mean the jython package for interfacing with imageJ, in which case Jython is not quite the same as python. I have some existing programs I have written in python that I would love to interface with ImageJ but have not found an easy way to do so. These programs require a lot of other libraries such as Numpy, Scipy, Pandas, many of which can not be imported into jython - or rather the ImageJ jython interpreter doesn't allow them to be imported. I've found, however, that matplotlib and numpy can do just about everything I need for image analysis. The only thing I haven't been very satisfied with was an FFT implementation for image processing. I have used the numpy FFT, scipy.fftpack, and the python wrapper for FFTW - pyfftw. Yet none of them seem to make the FFT's as clear and clean looking as the ImageJ built in FFT package.
I've never understood why Heroku is so popular either. Takes ages to deploy, you end up using AWS for static anyway and you're super limited by what you can do as there's no long term storage for anything but the app itself. It might scale but at that price plus paying for the associated infrastructure it's never seemed anything but super expensive to me. If you're going PAAS, I'd say Open Shift is a better option but i don't like how it dictates your project layout (for Django anyway). App Engine I've enjoyed but it's hardly ideal for Django and isn't really ideal for a lot of other projects either.
Paste some of your code, I'm sure it can be improved.
I never understood c++'s auto keyword. If I am already going to write auto I can I know it's a int, I will write int. It could be usefull for functions though.
Looking good. I use beanstalkd a lot, as well as beanstalkc. I really like your context manager, too. Maybe you could fork beanstalkc and patch it with that functionality?
&gt; as clear and clean looking as the ImageJ built in FFT package You mean in the rendering of results or in the actual FFT decomposition? Are there any parameters that can be adjusted?
Another ST3 user here. I also use Anaconda, and the defaults work pretty well for me. Only a few things I've changed: { "pep8_ignore": [ "E501" ], "anaconda_gutter_theme": "dark", "anaconda_linter_mark_style": "outline" } ```E501 line too long (82 characters``` annoyed me a bit too much, I just fix it manually by keeping an eye on the ruler. Also some time ago I found this post which has some more nice tweaks to help setup ST3 to be a nice environment for writing Python: http://piotr.banaszkiewicz.org/blog/2013/08/24/sublime-text-3-for-python-development/
he was complaining about lib using different subsets of C++. The good news is it's compatible. You can code with the new stuff while still using the old librairies, written with the old stuff. Of course you'll still have to take some decisions. For example the support of exception. If your code doesn't support exception but the lib throws exception, you'll have to take care of it. But the fact that you can use old libs with C++11 doesn't deprecate a good amount of work and doesn't slow down adoption.
That graphic in the middle is really interesting ([link](http://sebastianraschka.com/Images/2014_musicmood/exploratory_1.png) for the lazy). Do you know of any other research on the subject that may go in the same direction ? If no, do you intend to publish it ?
I use pylint primarily because the results can be parsed with Jenkins and it sends me emails when I did something bad.
All of these services have strengths. But the ones you listed aren't all the same thing. GAE is like Heroku but not like AWS. People commonly conflate IaaS and PaaS as the same thing. I'm not sure if this was intentional on your behalf but I'll explain it anyway. EC2 (I figure what you mean by AWS) is part of Amazon's vast IaaS (infrastructure as a service) offering. Meaning you can do a hell of a lot more than just starting a machine and running a server on it. If you wanted an analog for EC2 you might look at RackSpace or Google's Compute Engine. Amazon's newly released ECS (Elastic Container Service) is closer to Heroku or GAE. In short: IaaS = Manage network, Servers, Firewalls, etc. PaaS = Launch App, ..., Profit I tend to agree with other commenters in that Heroku is expensive. But it's quite simple and easy to get up and running for beginners. Remember ALL PaaS offerings will need you to structure your application (however minimally) in a way where their system can manage it. Sometimes this is just a YAML file in the root of your repo and sometimes it's more. Some nice options were mentioned, like PythonAnywhere. I have used DotCloud in the past and have had good results. (Though, they are in the middle of a transition so maybe risky). If you're just looking to launch an application without needing to mess with the lower level features that IaaS solutions offer you I might skip an Amazon offering unless you want to try the new ECS stuff. Now, if you *are* looking for a closer to the metal IaaS offering without the huge learning curve I would suggest [Digital Ocean](https://www.digitalocean.com/). I personally use AWS because I really like RDS (not managing my own DB software) and I have a multitude of projects running in a VPC on their servers. Just be careful of the learning curve.
Thanks for the feedback! Yes, there has been done sth. related in this direction. About publishing: I am not sure if this is "enough" nowadays. I mean, it is nothing really ground breaking. But I am writing up a technical report and probably publish it somewhere since it may be useful to others!
Have you thought about building your apps for Docker? Then you have your choice of hosting providers. If one gets to be too expensive or too much of a pain, shut it down and switch. You can run your choice of DB in a second container.
I use flake8 with emacs and flycheck, it works pretty well. My only beef (and this is really an issue with pyflakes and pep8, since flake8 is just a wrapper) is that it treats some things as errors that should really be warnings and vice-versa. For instance, extra spaces around an operator is treated as an error, but using a variable that isn't defined (because of a typo, e.g.) is just a warning. 
If you want something embedded, your options or pretty much limited to pure JavaScript or Unity3D.
whats a linter ?
I use flake8 inside of gvim.
In VIM, I use pylint, pyflakes, pep8 and pep257 all togheter. And I think it's great. I don't know how would be in sublime text, but I'd try to install all of them and see if they work fine together.
It's more relevant when the alternative is writing vector&lt;map&lt;string, pair&lt;int, double&gt;&gt;&gt;::const_iterator 
Apologies for not knowing the proper terminology - I'm new to this type of data analysis. I have some raw data files for electron diffraction experiments - I can read them in and display them via ImageJ (import raw) or python using numpy and matplotlib. If I then perform a 2D-FFT on the image to generate the real-space image (as opposed to reciprocal or momentum space) the 2D-power spectrum plotted from the FFT output just seems overall more clear and precise when computed and displayed using the imageJ FFT algorithm as compared to the FFT of the same data computed in python either with scipy.fftpack.fft2 or pyFFTW.FFTW I don't know the proper terminology to describe it the difference in the images - its the sort of thing you just have to see side by side - one image looks clearer than the other.
I have a blog post that details how to do this with the requests library. You would just need to update the code to utilize requests. https://realpython.com/blog/python/caching-external-api-requests/ (You can change the storage engine to Redis) Does that help?
A linter is a program that does code analysis and gives you feedback. It can show variables used that aren't defined, errors in your coding style, issues with unopened/unclosed brackets/parentheses/braces, etc...
+1 for `flake8`. I find `pylint` to be far too pedantic.
most likely explanation is a typo in the image filename or path. opencv has pretty bad error reporting in that area.
The thing is, certain styles are heavily discouraged by the actual standards committee and just plain convention, and if people wrote conventional C++ there wouldn't be an issue. (Un)fortunately, convention changes and old code bases still use the same style. The great part of C++ is that you can still interface with that old code and it will work as it did before. Imagine if you could mix Python 2.7 and Python 3.3 in the same file/project instead of having to port from one to the other (although that makes more sense in C++ where you're inherently at a lower level and the benefit of reusing old code is greater). As for `malloc` and `free` vs `new` and `delete` vs the new smart pointers, each of those systems more or less forces consistency. It shouldn't be an issue to figure out which one the library uses if you need to at all. If you don't, then it's taken care of for you by the library (or it's a pretty shitty library). The same goes for all other features of the language- libraries follow the convention from the time they were written and should remain consistent. If it doesn't, that's the fault of the library designer, not the language.
This is why the numpy developers created the new _buffer protocol_ (PEP 3118). This provides a way for applications to exchange sophisticated memory structures without a numpy dependency, but in a numpy-compatible way. You can create compatible buffer objects using a variety of other means: ctypes is probably the most flexible, but also Cython. You can also use array.array or the memoryview object (python3 only). I think the reason most packages just go and add numpy as a full dependency is that it just adds so much useful functionality. Once you start accessing blocks of memory, all the advenced functions of numpy become incredibly useful. Linking to blas doesn't really cause any problems unless you're trying to run it on a microcontroller.
&gt; are simply syntactic sugar Syntactic sugar is *powerful!* Some of the most useful syntax in Python is just sugar: iterators, decorators, list interpretations, context managers, generators, etc. 
Thanks. I'll give Openshift a look and pythonanywhere was on my to do list. I always felt bad for doing so much of my deployments on GAE, because it was so easy to use, but now I'm starting to think that it might just be a better option long term and I guess I can always integrate a DBaaS or run my own remotely
Yeah, i was planning on dipping my toe into AWS with Elastic Beanstalk. I'm especially interested in using some of the other services like S3, RDS and DynamoDB.
https://github.com/landscapeio/prospector This tool combines all of the linters into one report for you. Also check out http://pre-commit.com/ for automatic linting when you try to commit.
Pretty amazing!
Hey /u/piratelax40, thanks for this comment, I really appreciate it. I'm glad you enjoyed the book, and if you ever have any questions or need pointers on where to go next, always feel free to message me or email me.
Woah...that is a pretty epic article. I plan on reading through it more thoroughly over the holidays :) Happy hacking! +/u/ppctip 10 peercoins
^__[Verified]__: ^/u/cshoop ^^[[stats]](http://www.reddit.com/r/PeercoinTippingBot/wiki/stats_cshoop) ^-&gt; ^/u/laMarm0tte ^^[[stats]](http://www.reddit.com/r/PeercoinTippingBot/wiki/stats_laMarm0tte) __^Ƥ10 ^Peercoins__&amp;nbsp;^__($7.5937)__ ^[[help]](http://www.reddit.com/r/PeercoinTippingBot/wiki/index) ^[[global_stats]](http://www.reddit.com/r/PeercoinTippingBot/wiki/stats) ***** ^[Peercoin](http://www.peercoin.net/) ^- ^The ^Secure ^&amp; ^Sustainable ^Cryptocoin
If you can spend a little money and you don't expect a lot of traffic, just buy a cheap VPS. You can get one from ~18$ / year and you can do whatever you want on them.
I learned to program with Adobe Flash and Actionscript. The language is essentially a mix between a graphical editor and javascript. Learning simple languages by no means discourages people from programmign. In fact, its really just a gateway for those who are likely to be interested. Nobody who really loves programming gets "bored" when something is easy. Instead, they start reading and exploring. A few years after learning one of the simplest languages around, I was participating in programming competetions using Java. In university we were simulating computers using logic gates and writing compilers. Everyone agrees that programmers should understand what is really going on. The claim that simple langauges make people leave programming is just silly.
Pip install --allow-external mysql-connector-python mysql-connector-python That should work. 
I think you should reconsider the way you are storing the counts. Using two lists is both unnecessary and painful since you need to manually keep them aligned. I would recommend using a dictionary. An easy solution would be a defaultdict. Your second issue appears to be separating the text into words. There are several built in ways to do so but I'd recommend split. https://docs.python.org/2/library/stdtypes.html#str.split http://stackoverflow.com/questions/613183/sort-a-python-dictionary-by-value http://stackoverflow.com/questions/19883015/python-collections-counter-vs-defaultdictint
thanks I'll look more closely when I get home
Hey! First off thanks for the post, it's really helping me out :) Could you please go into more detail on how I would do this part: all_results = [[]] for each search_pixel in the search_image: current_result = 0 for each template_pixel in the tempalate: subtract the difference of the two pixel values, square the result, and finally: and it to the current_result. store the current x,y location you're comparing, and the result of the comparison in the all_results I'm having trouble understanding how to make this work. Thanks for the help!
Use a dict and store the words in it as keys and the value being the no of time they were encountered. Then you can iterate the keys of the dict.
Python is interpreted, not compiled. The easiest way to use is to have a vps and follow tutorials for the framework of your choice - django and flask are most popular and very well documented. Also both can be run locally in development mode. For production use they are typically run via uwsgi or gunicorn, combined with nginx. So most common way of deploying is to copy file, update dependencies, then reload uwsgi. Additional keyword to google for: pip, virtualenv.
I didnt follow the comment &gt; Heroku gets a lot of hate but unless you are spending over $500 a month, its not worth thinking about Do you mean it's fine to use up to $500 a month? I hadnt heard about Dokku, but that looks pretty sick. A kind of best of both worlds option. I also want to clarify that I don't expect free hosting. I just was looking for options that allow me to setup the processes and backend with an eye for scaling and test them with a super small dev team before launching an app to the world at large. I'm building different apps on different systems to weight the pros and cons and get experience hosting and deploying in their environments. To your point it's kind of like the "favorite language" thing, where there is no real right answer, but it is useful to test different one's to understand, which works best under certain circumstances.
Review: * https://pypi.python.org/pypi/pysaml2 * https://pypi.python.org/pypi/python-saml 
You can host at pythonanywhere.com, they have a free tier, deploy via github, ssh or web form. Serving at localhost and remote can do Bottle, Flask and Django with increasing complexity. That should get you started, but there are more hoster and frameworks, these are just the one with good documentation, IMHO.
No problemo! :)
/r/gis and /r/GISscripts may be useful subscriptions for any GIS coders out there, if they aren't already. Happy GISing.
This uses Python 2.7 so it is basically a waste of time for me. I target Python 3.4 for everything I can. The rare exceptions require modules that have not completed conversion to 3.4. I avoid modules which are not moving to 3.4. Python 2.7 is a dead end. New python programmers should never learn 2.7. There are enough programmers proficient with 2.x to support all the dead end applications that refuse to convert to 3.x. The persistence of 2.x holds back the acceptance, growth, and support of the 3.x branch.
From quick Google - search query: building 3d meshes python - it looks like there are lots of options including [scripting Blender](http://blender.freemovies.co.uk/writing-a-python-script-that-creates-a-simple-3d-model/) and [dedicated modules](http://documen.tician.de/meshpy/) or [wrapping libraries, e.g. openCTM, yourself](http://prideout.net/blog/?p=44).
First thing I would do it after you read the file, and removed the line breaks. Split the string data.split(" ") by the space to get complete words. Also, I don't recommend iterating over the dict again; however, just have a running total of words, whenever you add a word to the dictionary, verify if it's larger than the current min(list) of words you're keeping track of--only keeping track of the ten highest. This will allow you to do all of this in O(n). 
webfaction's managed dedicated servers offer a nice twist on VPS - you have more or less total control/freedom over what you do with your instance, while at the same time webfaction take of care of some fundamentals such as keeping the OS secure and up to date. Good support and fast performance.
I code in C every day and Python very frequently as well, and I much prefer the python syntax in most of these cases. Granted, I haven't spent much time with C++, and I do use these features in Python a lot, so I can imagine that many a C++ programmer out there is glad to have their hands on things like anonymous functions (which, incidentally, I first encountered in MATLAB).
Sikuli will do this out of the box with about 5 seconds of work and can function as a Java or Python library. It even has a graphical interface if you don't want to code.
If you folks use these methods in your projects I'd love to see the results. Do share!
PHP and Python have some substantial differences that makes the server setup quite different. The biggest is that PHP runs as a script, while Python (generally) runs as a service. Let's see the difference when a request for http://www.example.com/blah/ is processed. PHP: The web server (such as Apache) uses its mod_php module to load the script file blah/index.php, executes it, and returns the result. Python: The web server (such as Nginx) passes the request to the application server (such as uWSGI or gunicorn) which is already running. The application then decides which script to run, which is likely already loaded into memory, then returns the result. There are lots of other differences, but that's really the big one that is probably the hardest to wrap your head around.
Thanks! I'm going to use it for a similar purpose of rolling my own duplicate image search for my dad who has collected about 5-6 miscellaneous hard drives worth of partial duplicate backups. I'm sure there are quicker methods just by comparing EXIF data or other methods but it can give me a chance to mess around, and then also have a 'similar image' search available when its all said and done. I was contemplating how I wanted to do the interface and was leaning towards flask so this sealed the deal :-)
VPython
Get this marketing bullshit off of here
Here's my setup: Basic $5/month VPS through DigitalOcean running Ubuntu. My "stack" is Ubuntu, Apache, MySQL, and Python. To use Python with Apache I use mod-wsgi. I use Flask for my web app framework, and then I automate deployments with the Python package Fabric (http://www.fabfile.org/). Hope this helps, feel free to ask any questions!
If the images are (near) duplicates of each other, I would suggest using image hashing. It's basically a way to quickly construct a fingerprint for each image based on its visual contents. I'll have a blog post next week on building an image hash based search engine.
Did you consider: "Introduction to Computation and Programming Using Python" John V Guttag or is that a book on CompSci + Python? I also backed Python101 (which you included) and RealPython dot com out of interest. The ones I've browsed that catch my eye for beginners are definitely:- * Invent With Python * Learn Python The Hard Way * Absolute Beginner's Guide to Python * How To Think Like A Computer Scientist with Python One of the RaspberyPi books format with Python that I like was:- * Recipe (basic of programming) * Ingredients (Python language) * Cooking! (Doing mini-projects that use the above) For example, creating a twitter bot. Well, less time on reddit and more time reading and learning and using these books (particularly the first 4!).
 myworddict.setdefault(word, 0)+=1
Forgive me, but that seems like a pretty silly restriction for something mildly complex like a SAML implementation. But, you should be able to roll your own by using the xml.etree package except for signing and cert verification. For that you will need to roll you own or look at using subprocess and xmlsec if you can install it. 
Messaging you on [**2014-12-22 23:52:19 UTC**](http://www.wolframalpha.com/input/?i=2014-12-22 23:52:19 UTC To Local Time) to remind you of [**this comment.**](http://www.reddit.com/r/Python/comments/2ong0o/followup_to_last_weeks_image_search_engine_post/cmp7qp6) [**CLICK THIS LINK**](http://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[http://www.reddit.com/r/Python/comments/2ong0o/followup_to_last_weeks_image_search_engine_post/cmp7qp6]%0A%0ARemindMe! 14 days ) to send a PM to also be reminded and to reduce spam. _____ [^([FAQs])](http://www.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/) ^| [^([Custom Reminder])](http://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!) ^| [^([Feedback])](http://www.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback) ^| [^([Code])](https://github.com/SIlver--/remindmebot-reddit)
Thanks for the input. I'll check these out and add them to the list.
 &gt;I'm new to python. I've had a crash course in writing Python, but it didn't relate at all to the web, which as my luck always has it, is exactly what I need it for. Web development hosting and so forth isn't really Python or programming language specific. Setting up a host involves a number of steps depending upon the operating system. So maybe what you need is some systems administration background. &gt;I'm a seasoned php developer, so how to code isn't an issue. It'll probably take me a lifetime to stop feeling the need to adding a semi colon at the end of every line, lol. I don't want to sound like an ass here but being a "seasoned php developer" does not imply any ability to code. I would hope that you have some formal programming training, if not get a good Python book and study the ways of Python programming. &gt;My question is, how do you host Python? I know it needs to be compiled, and you need a server that can handle it. How do you deploy compiled code to the server? Are there relatively simple ways to host it locally? Are there any common hosts that use it? Many of these questions are system administration related in my mind. To setup a server you need to have an idea of what is out there and how the solutions best fit your needs. You have already received good suggestions but there is Google which can highlight what is available. Also realize that the operating system in question has an impact on how you would host your web app. 
http://www.wallix.org/2011/06/29/how-to-use-jenkins-for-python-development/ is the guide I've followed in the past.
Yeah this is the direction I am headed. Roll my own through most all of it. I have access to a solid in house xml library. I have done the signing and encryption before. I was actually hoping for some example through the handoff as there seems there may be some handshakes back and forth but I will have to roll my own on that too. edited * typing on handheld devices and not proofreading again.
Fantastic article! I was just wondering about how to do something like this the other day!!!
great post, man! A+ would read again
matplotlib will show a graphic, and also probably has tools to generate it for you based on picks.
I recently used his cairo wrapper [gizeh](https://github.com/Zulko/gizeh) to generate vector graphics of starshades. He posts some really cool stuff.
Sure! Our repo is in subversion, but AFAIK any other major VCS is really easy to set up with Jenkins. I have it polling for SCM changes every 10 minutes. I installed the [violations](https://wiki.jenkins-ci.org/display/JENKINS/Violations) plugin which can parse pylint output. You'll have to refer to their docs on setup but it's really easy. Your source is available in-browser with in-line pylint warnings/errors. It is so nice! Any other questions let me know :)
mod_wsgi is the answer the op was looking for. 
For the handshake, usually, the SP sends a Authn Request to the IdP. Next, the IdP responds with a SAMLResponse to the SP. These are generally not too complex. The complexity comes in with signing and verifying the SAMLResponse along with any encryption if it used. I've implemented this for a previous employer using lxml and xmlsec. If you can, I'd recommend wrapping xmlsec with cython.
 No, I don't think they're system admin related. the OP isn't asking where he can run his python program. He's asking how to run py as a webapp. And the simple answer is mod_wsgi. 
How about ascii art. I'm serious. Graphviz might also work.
This is definitely the wrong way to implement a binary tree. Seriously if you hand this in as a homework solution I would give you a zero because you're not demonstrating knowledge of a binary tree data structure. http://www.laurentluce.com/posts/binary-search-tree-library-in-python/
It's a good resource and it's free. Why can't it be promoted here? If I came across it I would have posted it but it's already here. 
So I know you use this yourself which is always the best reason to code something up but is this a big area? Is this good for electrical engineering homework/research? I once got thrown an assignment to draw a schematic for a 7-segment LED and had to use some god-forsaken java app the teacher specified. Was a pretty bad experience haha. 
I google and found [this](https://github.com/ianweller/bracketeering) where apparently they use Python for some computation, but in the end the bracket is rendered in HTML/CSS.
Semiconductor processing is a huge area. That said, this is only targeting a subset of that area: small companies who are probing wafers but do not have the capital to purchase commercial analysis software or engineers who want to roll their own analysis code. This package isn't going to help the students and will probably not help academic researchers unless they're doing medium-scale wafer probe on an automated system.
Here is Kundalini: https://bitbucket.org/cacilhas/kundalini 
Congratulations, he used the hello world opencv face detection example.
I have use Pillow a lot to generate images in the past. 
I have completely forgotten how to use excel since I started using pandas. The notebook even renders the spread sheets reasonably, and if yoh really wanted to I'd bet you could make a widget to edit those sheets interactively. 
Dunno, but the same author is supposedly working on a second edition... or was at least making noises in that direction in late 2013/early 2014. 
cairo
Wow! pandoc does look pretty sweet. Looks like it should be super easy to go from just about anything to... just about anything ;) Including a pdf with a functional TOC in the side pane (sorry Al, just razzin' ya ;) )
It did. Thanks for the command. Really thanks. How long would it take me to solve this problems by myselft, ages.
It's alright when I first started it took me soooooooooo long you have no idea. If you're using python 3 just run that same command with pip3 
Python Imaging Library (PIL) is pretty good too. (although hasn't had any active development for quite some time) PILlow is supposed to be a rebooted version of PIL, but I had trouble integrating PILlow with my code. 
Thanks :)
That was useful.
Assuming you're using the 4 line 'romeo.txt' revealed through a quick google, it won't actually make any difference to the output, but perhaps you should consider handling capitalized and lowercase words together? Again, for this input it doesn't make any difference, but bonus points for dealing with punctuation in the input.
No need to apologize mate, obviously my Google foo isn't as strong as I thought... They look good though, I'll see if I can adapt them into the project that inspired Redict.
If you find it useful for yourself, well done. Don't worry about existing libraries: They will all have problems.
Also my own, hot-redis: https://github.com/stephenmcd/hot-redis It both implements and integrates with, all the standard Python types on top of Redis, think: l = List(key="my_list") l += [1,2,3,4] len(l) l.pop() All the operator overloading implemented on all the types you'd expect, plus a bunch of stuff from the standard library implemented on top of Redis, mostly all of the types available in the collections and threading modules.
Can you explain what makes yours different / better?
Fixed my issue. The bus number was actually correct, but the address it was searching for was set to 44 by default. When I assigned my own addresses to the boards which was 50 and 51, it gave them i2c addresses of 32&amp;33, so I simply had to change this in the PicoBorgRev3.py file and change the import to "import PicoBorgRev3 as PicoBorgRev" Brilliant :D
There actually seem like a bunch of further micro-optimasations that could be made for the python solution. Eg. - `["Wood","Fire","Earth","Metal","Water"]` can become `"Wood Fire Earth Metal Water".split()`, and likewise using " " as a seperator rather than "|" allows you to drop the argument to the other split call. - You don't need a space between print and the string. - You can unpack the m/d/y tuple using tuple unpacking, rather than referencing a[n] all the time. Ie. m,n,p=map(int...;p-=1924 - You can (ab)use the fact that booleans can be treated as ints, and change `(0,1)[d&lt;21]*31+d]` to just `(d&lt;21)*31+d`, and the same for the outer check, though you need to reverse the comparison (which actually saves you a char itself). You can also drop the outer brackets. The whole thing becomes `(m-1)*31+n&lt;(d&lt;21)*31+d`. - `(m-1)*31` is the same as `m*31-31` and saves a character from the dropped bracket. - You can save another char, since you're not using `p` after this point by reusing the variable instead of creating `o`. This allows you to write "p-=" instead of "o=p-", saving a character. That shaves off ~~23~~ 27 characters, down to 360: m,n,p=map(int,raw_input().split("/"));p-=1924;d=int("5od2nauh6qe4obvj8rf5pd2math6re3ocvi8sf5pd2l9uh6rf3nbvi7sg5pd2k9th6rf4navj7sg5oc1m9ti7qe3navj8sg5pc1math6qd3nbvj8sf4oc1ma"[p],36);p-=31*m-31+n&lt;(d&lt;21)*31+d;print"Rat Ox Tiger Rabbit Dragon Snake Horse Goat Monkey Rooster Dog Pig".split()[p%12],"Wood Fire Earth Metal Water".split()[p%10/2],["Yang","Yin"][p%2] [edit] Dropped another 4 unneeded characters (unnneccessary brackets)
I use a *lot* of Pandas and Excel at work. So far the biggest "bang for the buck" I've had is combining spreadsheets. We get a ton of spreadsheets containing daily information that get archived into a hierarchy of year and month folders. If we want a graph showing daily prices, historically someone would need to open hundreds or thousands of spreadsheets and copy one value at a time. The job takes about 10 lines in Python. A VBA Macro could do the same but I've found they are slow and painful to write.
You should really be using `BufferedReader`, not `TextIOWrapper`, for a fair comparison; the later converts to Unicode: i = 0 with gzip.open("largefile.gz") as gz_file: with io.BufferedReader(gz_file) as f: for line in f: i += 1 print(i) This will still be about a factor of 2 slower than using `subprocess`, but note that `subprocess` basically gives you two threads of execution: one for reading and one for parsing lines. You'd probably need threads to compete. Note that forgoing buffering altogether with with gzip.open("largefile.gz") as f: data = f.read() print(len(data.splitlines())) gives you pretty decent speeds, because `splitlines` is in C and thus very fast. As such, a parallel workload where one thread decompresses large chunks (32kb?) and the other counts the lines would probably match `subprocess`. 
Have you looked at [CheckiO?](http://www.checkio.org) It's a web-based programming challenge game. Might be fun with minimal effort. Robotics is a really fun way of applying coding, but involves a little bit more overheard... I got into programming when my high school offered a robotics class and you had to program your own firefighting robot. We eventually took them to a competition. You could see what programming competitions exist in your local area as well. It would give them something to work towards (i.e. "we should learn how to create an app in python so that we can go out and win this prize").
well here's my point, I know how to program. I've had a college education that focused around Java, classes on VB, Basic, .NET, and a few SQL courses. I've been working for over 10 years as a php developer to know how to program. But my question wasn't how do you program PHP, it's just what's required to host Python to view online. Along the same lines of requiring a LAMP stack for example to host PHP. I'm unfamiliar with hosting environments that support Python, not how to develop in it. 
That's a huge help to both of you. I just didn't know where to start looking.
In this situation, `import this` isn't much help. Not even `import antigravity` will help.
I'm working on something that deals with data in the 6GB range when uncompressed. I resorted to just using unpigz and dealing with the data uncompressed rather than having to uncompress in python. I'd love to see someone implement an unpigz approach in the actual python gzip module. 
A great post, I never knew, despite using Pandas for over a year, just how flexible it is when dealing with dates. I always used the datetime library and created lambda functions in conjunction with the apply method to create date columns.
YAML is horrendous. I remember trying to use it once with Doctrine. \**shudder*\*
Yeah, opening thousands of spreadsheets and copying one value at a time is a cold sweat moment in VBA. It absolutely works but it's hard to make it stable.
Not surprised by the YAML result. It's deliberately designed to be easy to read and write by humans, at the expense of parsing ease.
Would like to see ProtoBuffers and Cap'n Proto results as well.
Sorry, I am sometimes not very clear in my writing. Yes, stick with heroku unless you costs exceed some tangible number. $500 is even too low but its a starting point to start thinking about alternatives. Heroku gives me a clean separated system. I do not have to worry about maintaining any boxes, any type of dev ops or sys admin work. I can connect Heroku to a RDS database so at the end of the day I am paying $30 per dyno. Not a bad cost considering it requires close to zero setup on my part. The cost of my time to manage any other system is not worth the cost of a few dynos. If I am already using a handful of dynes I might have to look into EBS if I was running an EC2 instance, again more time. Engineering time is valuable and not worth wasting on sys op for lol traffic sites. Dokku is great but only for non-production fun sites. I use it on EC2 to host my blog and other projects before they become tangible. If they hit critical mass I move them to Heroku. 
Pretty much this. 500 is not a set in stone number but at some point scale matters and its cheaper to scale elsewhere. At 500 you are looking at around 14 dynos which suggests you have fairly significant load. Good time to plan for the future. Before this point though why waste the time. If you are running a production app its easier to throw it on Heroku and not stress about it. 
Keep these Excel vs Pandas articles coming! So helpful! I would also love to see how other people use Pandas to do work that was once done in Excel also! Maybe you could let some people write Excel to Pandas guest posts?
I feel using a multiply example is defeating the point of mocks. A better example would be reading a large file or something that does thousands of worthless iterations to show how mocks can get around the inherent slowness and complexity of the underlying code to show how you're really just testing interface. Still a very well done explanation.
I think [computing the kernel by gaussian elimination](http://en.wikipedia.org/wiki/Kernel_(linear_algebra)#Computation_by_Gaussian_elimination) is what I need, but I don't really understand the math..
I too was hoping to see results for Protocol Buffers when I clicked this link.
Has anyone written big projects on django and flask? How is your opinion on them ?
Have you actually tried it with the code above? It won't work. It may work with a predefined list of keywords or with simple code. But for the code OP posted above, there's no way.
What is with people cross asking SO and reddit these days. I remember when the internet was about doing ones own research, top to complete bottom (if needed) and not asking people to solve your problems for you.
I would use it for configuration and not serialization too.
I would appreciate any advice, even some terms I could google. This is why I crosspost my SO question, inviting discussion instead of requring a answer that would be acceptable there. I've been searching for anything that might help me since yesterday, I know generally what my problem is, but not how to solve it. I hope you can always solve your problems by yourself, I can't.
Shameless plug: you may be able to build a Windows installer without a Windows machine using my [Pynsist](http://pynsist.readthedocs.org/en/latest/) project. You'd probably still want to test it on Windows, though.
TLDW: Fuck Django, exult Flask.
I built my website running using Django (giftfoxx.com). A couple of the pros: Lots of built-in high-quality web tools (CSRF protection, admin page and user access control, messages framework, sessions, etc.). Template language makes it easy to access database objects. There's also a ton of great documentation. What you trade in for all of these features is a learning curve. Sometimes I feel like I could do things faster just rolling my own—which, if I understand correctly, is more Flask-y. The advantage of making it yourself is that you understand how *your* sessions work (for example), which is fine for lightweight code but not great when you actually want your website to remain secure and in production. A number of the features also seem very un-pythonic. Many ORM object fields are implicitly derived from class names, for example, and there are strong conventions on code layout. There is a big advantage to these conventions: they provide structure and help other people read your code. But this adds to the learning curve. tl;dr: Django is a good tool for putting together a production website, but nothing's perfect.
The first class I took in regards to programing was basic java in high school. Just involved the basics and taught you proper programming etiquette so commenting, syntax, structure, logic, etc. Anyway, the kids capable and passionate oved on to the AP class. We immediately took to the idea of programming a game. Nothing crazy but we settled on monopoly. I can tell you that for the entire year, the course was taught around building out this game. We first built the entire game as a text based game but we put pretty much all the functionality into it. As we wrapped it up, we began to add a list of "house rules" that could be selected to modify the way the game was played. As we started to get into GUIs, we modified the game to be run as such. There was one student who managed to really grasp the idea of UI design and took off with it. Anyway, if you have students motivated with a tangible end goal... you will go pretty far and see them really dig deep to get it done. We also competed in competitions hosted by a university near by. Ranking was a great feeling but also seeing how everyone else solved the presented problems was great. It also allowed many to network and determine where they wanted to go in life. ***EDIT***: I forgot to mention that we also added the ability to play against computers. They were setup in three modes.(Easy, medium, hard). Each had a separate set of rules they played by. As we were finishing, we finally managed to get the hard player to play as a real person using a set of logic revolving around when to stop buying everything it landed on and applied logic, it had the ability to trade with other players if it fit its needs, it could build houses or hotels, it was pretty solid too. Thinking about this class gives me goose bumps, I miss that class... 
Is Pyramid not a serious contender these days? I moved to that from Turbogears a few years ago. Looks like I tend to back the wrong horses.
Yeah, I got nothin
I like to think of the cursor as the recordset. Meaning it's the object containing the data I received. This may not be entirely true in every instance but it makes sense to me that way. Others may have a different stance but I don't do much with the cursor after tbl=cursor.fetchall() cur.close() which is just returning a list of lists. You then iterate through it however you would normally iterate through a list of lists. for row in tbl: for col in row: print col 
I was surprised to see that Flask won the "python microframework" title. I have used Pyramid in a few projects in the past and always has been impressed with how well it worked. Unfortunately, I think there was never the fanfare behind it as there was with Flask and is often forgotten. I urge everyone to take a look at Pyramid, it is an amazing framework that can get you up and running then grow with you as your project grows beyond the capabilities of Flask and the restrictions of Django.
I still haven't found a truly beautiful way to split long strings though
very nice article. 
I worked on very popular sites in Django, including one of the top fitness trackers. It worked out well enough, but we leveraged smart middleware and lots of caching (from memcache to using CDNs for static assets) to speed things up. I think the main advantage was that everything remained cleanly divided despite the enormous codebase. You always know exactly where to go tweak a model for a given object.
Why do you need a .exe? I don't use Windows but from trolling this forum enough I know there are packages like py2exe that take a python script and generate an executable 
You might want to head on over to /r/learnpython as it seems like you are struggling a bit more with the basics. The above loop is pretty straight forward when written out in sample code (plain english) Think about it like this - An image is stored in python most simply as an array of pixel values. For instance a greyscale 400x400 image is just a 400x400 array where each element of the array is a pixel value in whatever given depth you are using (ie. a standard 8bit image stores values from 0-255). A color image can be represented in many different ways but one way to imagine it is three 2D arrays stacked on top of each other. Each layer represents R, G, or B. The combination of each of the three layers at a given pixel (coordinate in the array) makes the color of the pixel in the image. There's plenty of other ways to represent color but thinking of grayscale images makes things simpler for the time being. So that loop literally just scans through an image (an array) pixel by pixel (element by element) and looks at the difference between each pixel in the image compared with the pixels in the template. Also as others have mentioned there appears to be a package that does almost exactly what you need (sikuli) Rather than reinventing the wheel, why not use a tried and true method. You mentioned in a few spots that sikuli can't save a .exe - but I don't see what that has to do with the question at hand programmatically. Could you not just write a bash script (or whatever the equivalent on Windoze is) to run your sikuli script? http://doc.sikuli.org/faq/010-command-line.html 
I'm working on two big projects right now, a Django one (loft.io) and a Flask one (energydesk.me). I've used both frameworks since they were released. Like most things the trade-off is customization vs easiness. For instance Django's auth is awesome easy, but configuring it can be tricky, and don't even try to replace it. Flask-Login on the other hand is a cinch to customize even if its setup takes a bit. And Django's ORM is the best in the Python world, in my opinion as far as striking a balance between power and ease of use. But try using something else and you won't get far with other apps. In my opinion they are both the best Python has to offer, and I encourage anyone to learn them well.
From your comment you look like you haven't even used flask or read it's documentation. Flask has sessions, better templates + better orm than django. Also forms with csrf (although not as easy as django).
Their [quick vignette] (http://vimeo.com/59324550) made me uninterested, even though I should be using Pandas all the time for what I do. I'm recovering.
http://ideone.com/ah3d5j
If you are familiar with VBA and work with databases then you may understand ADODB and its hierarchy of classes. So if you were to make the comparison, the 'cursor' is like a ADODB.Command object. It stores the type of command, the command string, parameters, and other command-specific stuff. When you call the cursor's execute (or fetchone, fetchall, etc) an object similar to the ADODB.Recordset object is returned. I'm definitely hand-waving right now but I believe the comparison is valid enough. After you get the recordset, you'll will find that it is a list of tuples with each row of your data being a tuple. What you do with that depends on how you want to interact with your data. I like a list of dictionaries sometimes with each key being a field name. But a list of tuples is good too. 
Search algorithms are specific to data structures. You are fooling yourself if you think that you're learning binary search tree algorithms by implementing the tree as a dictionary. 
My immediate guess would be the GIL. How experienced are you with Python?
Prototype in CherryPy and Backbone+jQuery in Python 2? I dunno, I'd choose Pyramid + Ember.js in Python 3 if I was taking a stab at it. And nix the idea of having some kind of local installable running inside a QT5 GUI and instead put efforts into having a clean Buildout to make it one-command installable as a web app. Which would really be more of a rewrite of phpPgAdmin than a rewrite of pgAdmin. We use both phpPgAdmin and pgAdmin. pgAdmin as a GUI is great for being responsive and easy way to browse a postgres database, but phpPgAdmin shows more information (and importantly better links to the help docs) than pgAdmin and provides a one-stop location where anyone new to our IT ecosystem can browse all the databases at one go. 
I know I'm not doing it right hence I asked for help, and even in OP it says that its my first time dealing with this type of a problem. So though I appreciate the help earlier, there's no need to be vague and tell me that I'm fooling myself, instead of giving me some sort of a direction. 
I don't think you read the docs either. Flask has [no built in ORM](https://github.com/mitsuhiko/flask/blob/6fcc2ae3f4536e4d2651c1a00abe2306212a5bfd/docs/patterns/sqlalchemy.rst) or [CSRF](https://github.com/mitsuhiko/flask/search?utf8=%E2%9C%93&amp;q=csrf) protection. Those features are all added by third party libraries, such as [Flask-SQLAlchemy](https://pythonhosted.org/Flask-SQLAlchemy/), [Flask-SeaSurf](http://flask-seasurf.readthedocs.org/en/latest/) and [Flask-WTF](https://flask-wtf.readthedocs.org/en/latest/). [Django also has sessions](https://docs.djangoproject.com/en/1.7/topics/http/sessions/), they just aren't enabled by default. Its also worth noting that you can use the Flask templating engine (jinja) with Django. SQLAlchemy and WTForms are also usable with Django.
You're attempting to rationalize your behavior. I'm giving you a reality check.
I am familiar with the GIL but I would not claim to be an expert on it. I think the GIL is what is causing the issue, where the os.listdir and os.isdir calls are acquiring a lock when they might not been doing that previously. Although I don't know enough to substantiate that claim with any evidence.
Or beter, get stuff from the internet, which is typically what I need to mock.
But I've asked for `return "mailto" + ":" + name + "@" + domain;` and not `return "mailto:" + name + "@" + domain;` because the latter worked in any C++. Also, can I have auto example = {"foo", "bar", "baz"}; ?
Been looking for something like this for my blog. Thank you!
Which django extensions use jinja2 or sqlalchemy? And which flask extensions use sqlalchemy ? The point is we aren't comparing (at least that's what I thought) just the frameworks, but also the third-party libraries,community,ecosystem etc that they have (ex: see a comment for django-rest-framework on this page). 
Yup, I haven't used Flask, or read much of its documentation. This comment just covered my experience with Django. But, as [badsectors](/u/badsectors)' pointed out, the things you quote as "part of" Flask are actually third party addons. My general sense is that, with Flask, you are expected to implement a lot more of your own functionality. I love that idea, mostly because I really like to understand how things work. But I chose Django because I needed to get a bit farther faster, and wanted to share my experience.
If you're going to use SQLAlchemy, mako templates, etc... is there really any advantage of using Django beside the builtin admin page (assuming you use full ORM, I tend to use SQLAlchemy base only + SQL) and getting trace stack in the browser?
Flask also gives you a traceback in the browser: http://flask.pocoo.org/docs/0.10/quickstart/#debug-mode
I understand, but my initial question was for people that have used both of them on big projects. So they could compare a little.
Awesome! What a great series. If you wrote a book about this I would buy it. Any experience formatting Excel-formatted date codes into pandas readable dates? For instance from 444123 into January 1, 1990? (I made that up that conversion but you get the idea). 
Clickbait title is clickbait.
I only have experience from sheer traffic and management standpoint. Django sucks under mass request load (read millions..even with caching.). You have to do all sort of uwsgi and load balancing magic to manage it. Flask performed much better w/ less work. 
Yeah, I did a hobby analytics project on flask/uwsgi(cache,queue) (and async bulk postgresql) doing 400+ requests/second on a webfaction shared-server. With ~1-2 ms response time.
it is a serious framework. don't give up on it.
My bad... I read it as "Django or Flask"...
Can't see one myself, but why would there be if you're going to swap out such key components?
I am sr dev/teamlead deputy at really big Django site project with 6 years history(or so). Project went from simple site to really complicated solution with many integrations, tons of JS, 2SPA(one is account app, second is CRM(one of 3 CRM we use). We have tried flask and django. Then, we found django rest framework. So… If you build API, DRF comes to help every time. It is so cool that you can easily create objects, serializers and receive serializer data via Ajax. You have full CRUD operations and more. So why should I use flask when I need to build API for my all? As for nonSPA, django has sooooo many handy little thing inside, which will save you when you build serious project. Yea, I almost hate DjangoORM, but let's face it, Python has no other good ones. I know about alchemy an peewee and it is amazing, but not nearly as tested in real projects. But peewee looks really amazing, yea. Also, django has really bad default template engine. You will hate it too. But beside any problems with django, I can't see any reason to use flask or pyramid. I should mention that I have pylons background and pylons is an previous project of pyramid authors. 
Flask doesn't have the built in ORM, although you can use Flask-SQLAlchemy, which is authored by the same guy that wrote Flask, and (obviously) is based on providing a direct interface to SQLAlchemy, which many feel to be superior to Django's ORM.
I have to admit that I don't really see the point with mocking in most cases. IO is a good example of what you would like to mock but in the example shown here it doesn't make much sense. The `add_and_multiply` method is not doing what it's supposed to do so let the test fail. Removing the reason for why `add_and_multiply` doesn't work and have a passing test doesn't change the fact that `add_and_multiply` isn't working. To me it seems like people are very often too keen on mocking everything everywhere instead of just testing their code in an as-close-to-real-world environment as possible, like running tests in sqlite when you use postgresql in production.
So it's like Django but with more `pip install`s? I must be missing something...
The problem is that most people just use numpy or other libraries to solve those equations, I mean, why wouldn't you. There are some implementations I could find: * http://userpages.umbc.edu/~rcampbel/Computers/Python/linalg.html#LinAlg-Packages * http://ine.scripts.mit.edu/blog/2011/05/gaussian-elimination-in-python/ * http://adorio-research.org/wordpress/?p=191 * http://elonen.iki.fi/code/misc-notes/python-gaussj/ They're basically doing the same algorithm, some do pivoting and swapping lines, some don't. **But just like [source I adapted my code from](http://www.keithschwarz.com/interesting/code/?dir=lights-out) they don't seem to care about multiple solutions.** GF(2) makes things a lot easier, we usually just do a simple `xor` instead of adding, subtracting or dividing. &gt;Seems like a clever way to get a solution, but not necessarily the best approach to solving the problem in general. I'm working on this for the past few days and I've not seen a better approach to solve that kind of problems. A brute-force approach would take O(2^(n^2)), this algorithm is performed in O(n^(3)). Do you have a better approach in mind? I take everything at this point. Having a near optimal solution (from my knowledge) and still being seemingly so far off is kinda discouraging. I even wrote an email to the author of this original code, but didn't get a reply from him yet.. 
I'm curious how you did async postgres and returned the data to the front-end. Unless I'm misunderstanding what you did. Did you use a long running web socket or something?
That's not really how you should look at it. I think you can say that the components in Django and its eco system are made to fit together in some conventional way ... like in a classic puzzle. Whereas in Flask you have more barebone pieces that you have to glue together yourself. Both approaches have advantages and disadvantages also depending on your personal mindset. You can use both frameworks to achieve the same goals, don't let anyone tell you differently. In the end you have to try them both to make an educated decision for yourself. I did that and although I'm currently working in a Django job I think I like the Flask approach better.
When a request to insert data came, I pushed the rows on the uwsgi queue. Then every second, a thread would pull the rows from the queue and bulk-upsert on postgresql. Makes sense ? While when you view the dashboard, it's just a normal blocking query.
A "data cleaning" widget like [Google Refine](https://code.google.com/p/google-refine/) for Pandas data would be really useful. Since that tool is BSD licensed, it might be possible to use most of the code.
I would take the kernel approach to this problem. 1. Find a solution of Ax=b (done) 2. Find the kernel of A (I haven't given this too much thought but I think it is spanned by the basis unit vectors of your space, excluding for the (0,...,1) vector) 3. All solutions of Ax=b can be found be any linear combination of your solution in (1) and the kernel of A. I'm not sure how much linear algebra you've had so depending on that, this may take some research. Maybe start with an easy example in 3 or 4 dimensions (R^3 or R^4, not a restricted space like the current problem). Seeing how the kernel can help you find all solutions is much easier in these spaces. Once you have a handle on that, then moving to GF(2) shouldn't be too difficult. I guess what I'm really saying is that it might be helpful to take a step back and learn some of the linear algebra theoretical underpinnings here before moving forward. It'll probably take longer than you'd like but it will pay off massively later on. **EDIT** Maybe this will help.... Consider the following system A = [[1,0,0], [0,0,0], [0,0,0]] b = [2,0,0]^T It's trivial to solve this (u = [2,0,0]), but this is just one of an infinite number of solutions. The kernel for A is spanned by the following two vectors: b_1 = [0,1,0] b_2 = [0,0,1] **Now here is the really cool part:** Consider a vector defined as follows **x** = **u** + a* **b_1** + b* **b_2** This vector is also a solution of Ax=b for all a,b in R (i.e., a and b are Reals). This gives us an infinite number of solutions, and a few examples are: * [2,2,2] * [2,0,9] * [2,10^9,-10^1000 ] This is what you want to do for your problem. However, in your case since your space is over the field GF(2), there aren't an infinite number of possibilities. Hopefully this makes sense, I'm a little rusty as I've been out of school for a while but I find this stuff interesting.
They were actually still in the middle of being processed and uploaded, and that process had not completed yet. They've been made private again until this is done.
&gt; Each message of data was small — 5 keys with small values tipped the scales at a few dozen bytes each Any idea if these results hold for larger data sizes? This seems to be measuring overhead instead of throughput.
&gt; My biggest problem with Django's ORM is lack of ability for multiple primary keys on a single table I presume you mean compound primary keys, and I think the answer is no. I have never needed it myself, and wanted only rarely.
Every once in a while you want manual cleaning when you pull things from messy documents and hit errors that can't be expressed easily. Addresses tend to be hard to parse perfectly and each error is unique. If you're in a company, you can sometimes farm out the cleaning to a bunch of domain specialists.
I recently started some new python web projects, and I seriously looked into Pyramid as a framework, but I decided against it because: * The community's nowhere near the size of Django or Flask (have a look at the number of stars on GitHub or the number of StackOverflow questions). Incidentally, it's Pyramid: 1,422 SO questions, Flask: 6,173, and Django at a whopping 85,974 questions. * Pyramid's renderers are a bit convoluted. Instead of just setting the content type and returning a value from a route like in Flask, you need to use a renderer function for each type you're returning (e.g. a json renderer or a Jinja template renderer). These renderers are specific to Pyramid and useless everywhere else, and if there isn't a built in/available renderer for your template language, you have to write your own. You also have to declare the renderer separately to the route itself, meaning if you change return types you have to change code in two places * The routing is just as confusing. Instead of declaring the URL with each routing/view function, you instead have a separate map of URLs to route names, and you write a function for each route name. It's like a many-to-many relationship between URLs and functions that's (imo) unnecessarily complicated 
Yes, sorry, compound primary keys.
I agree. A good example of using mock objects would; 1. describe the need to focus on the System Under Test, 2. present mocking as one of two solutions to the problem, versus using fixtures, and 3. point out the trade-offs of mocking: getting your tests tied to the object's implementation. (Also, maybe, the need to use a more esoteric mocking system compared to just sample data.)
You've never needed it? It's an essential part of a many-to-many relationship. Do you just not have M2Ms?
That compound key stuff has been implemented. V1.7 I believe
Interesting points. Can you explain a bit more? In particular, as someone who's only used Pyramid and Turbogears, it's hard to see how you'd get around the need for some sort of renderer function if you want to transform data to HTML via one of several potential templating approaches. What does Flask do instead?
I'm leaning toward functional programming these days. Gary Bernhardt has a screencast, "[Functional Core, Imperative Shell](https://www.destroyallsoftware.com/screencasts/catalog/functional-core-imperative-shell)" - about which he has [this](https://twitter.com/garybernhardt/status/253887715676917760) to say) - which he also talks about in his talk "[Boundaries](https://www.destroyallsoftware.com/talks/boundaries)," which goes into how I've been thinking about things in this regard. Simon Peyton Jones, the main guy behind Haskell, says [nearly the same thing](https://www.youtube.com/watch?v=IqXTUbdLig0#t=1h6m31s) (wait for it). The idea here would be to act like there is no IO and create pure functions that manipulate the data the way you want to manipulate it. This is fully testable in isolation. Then you just plug in some IO, which can be extremely simple and isolated at that point. I had arrived at the same technique on my own - I called it the worker layer and the manager layer. The workers were the pure, testable, functions, and the manager was the thing that just glued them together and passed data back and forth from user to functions. The manager layer was much harder to test, but by moving as much as possible into the worker layer, the footprint of the manager layer was dramatically reduced, so it could be a lot more 'obviously' correct. Haskell has taught me to go much further with the idea - IO is a lot more than user interaction. Anyway, when you do this, the need for mocking is hugely reduced, if not done away with altogether.
If you don't understand the math - that's where you need to start before you are looking for a solution. Once you understand the math, which is simply introductory linear algebra, then the coding should not be much of a problem. I wouldn't worry too much about the efficiency of your solution the first time working through the problem. For now you just want a method that produces the correct solution(s). Once that is working properly you can fine tune the mechanics and work on making it run faster. Although, if you are using pure python it will likely still end up being rather inefficient. There are many numerical packages that excel at matrix manipulation and are highly efficient. I understand that for your problem or homework or whatever you can't use third party libraries. Thus given that you're sticking with pure python, don't worry too much about the efficiency.
Thank you for your answer. I think the most tedious part in what you are describing would be to make sure that the thread that parses the lines doesn't fragment them. In my application reading the file line-by-line is crucial (it's often going to be csv files). Do you think this would be a problem at all?
Presenting to an audience can be quite daunting, and I get the feeling that Eric may have been quite nervous, I know I'd personally be shitting bricks. That said, there was a lack of understanding in a few areas (Django ORM vs SqlAlchemy, migrations, scalability, blueprints, serializing objects for a response), which he could clarify within a follow up blog post.
I took a brief look at the differences between those versions, but there's nothing obvious. There were no changes to the listdir implementation between those two releases, and they do seem to be releasing the GIL between the appropriate operations. ie. the file accessing functions, like `FindFirstFileW`, `FindNextFileW` are all surrounded with the `Py_BEGIN_ALLOW_THREADS` / `Py_END_ALLOW_THREADS` macros. `FindClose()` isn't, but that's probably non-blocking. That leaves the `stat` call that `isdir` will do. There **do** actually seem some changes to posixmodule.cs relating to stat, in the form of some defines being removed. Specifically changeset 71123:45b27448f95c removes: /* choose the appropriate stat and fstat functions and return structs */ #undef STAT #undef FSTAT #undef STRUCT_STAT #if defined(MS_WIN64) || defined(MS_WINDOWS) # define STAT win32_stat # define FSTAT win32_fstat # define STRUCT_STAT struct win32_stat #else # define STAT stat # define FSTAT fstat # define STRUCT_STAT struct stat #endif However this looks like it was just dropped to being a redefinition though. The implementation (`posix_do_stat`) is unchanged, and does do `Py_BEGIN_ALLOW_THREADS` before the IO operations. It does use the above STAT define as the implementation function passed to it, but that happens after the GIL is already released, so a change there wouldn't make a difference. If there's a difference, it's more subtle than just not releasing the GIL during the stat / listdir calls. 
No, that's basically it. But most of what Django gives you is highly opinionated and will only work within the Django ecosystem while Flask is more modular.
This helps me understand the distinction, thanks. With the bare-bones strategy, I'd be a bit concerned about how Flask apps provide support for multiple databases. Perhaps I'll learn Flask for my next project and see the distinction myself.
Yeah, and I get that, but it struck me that perhaps he isn't the best person to be "evangelizing" these types of things if he is going to spread misinformation. People watch these videos and get the wrong idea because it sounds like it's coming from someone who should be very well educated on the subject, when, in fact, he does not seem to be as knowledgable as he presents himself to be.
I don't really understand what you mean by "fragment". The main difficulty is dealing with incomplete lines at the end of a block, but that's not too hard: just run `splitlines` and keep the last item in the list if it doesn't end in a newline. Add it to the first item of the next block.
&gt; So why should I use flask when I need to build API for my all? Because attempting to add custom functionality is often easier when you're not using something as opinionated as Django. I was at a startup that used Django/Postgres that had a schema that devolved to the most hellish thing I've ever seen (dude didn't know how to do migrations so new fields were added via generic fields. Took 40+ queries on login just to get the user model put together) and was tasked with moving the data store to MongoDB (it's [web scale](https://www.youtube.com/watch?v=b2F-DItXtZs)!), but the idea was that all we'd have to do is move the model layer over to use mongo-engine and then use tastypie (Django-rest-framework wasn't mature at the time) with django-tastypie-mongo-engine to bring it all together. It was the worst project I've ever had to work on, but I had a job to do and did it. Getting the different endpoints to work was a nightmare of "what code path is getting called here?" due to the way tastypie requests went through the view models. Some people would rather not have to deep-dive into however many thousands of LOC are in a monolithic framework to make some seemingly simple functionality. With micro-frameworks you have the option of using third-party extensions or rolling your own for the 90% and still having a pretty easy time adding functionality for the other 10%. Personally I prefer smaller frameworks because I'd rather know how to build something general than spend my time gathering knowledge specific to a framework but YMMV.
http://www.rdegges.com/heroku-isnt-for-idiots/ 
Agreed, be nice for a follow up post to clarify it for people watching.
&gt; You've never needed it? Nope. You have to differentiate between needs and wants. &gt; It's an essential part of a many-to-many relationship. No it's not essential. It's useful, but not essential, or did you think that Django did not support M2M relationships?
I guess its worse. Did this tired and frustrated last night. The goal was faster indexing of nested dicts/lists but its slower. I've got an idea to solve that issue, haha. In my opinion it makes for a nicer structure of data in Redis.
Django's ORM is *not* good, I can say that emphatically. It is bad because it is inconsistent and because it does not support composition. Inconsistent: * filter() and Q() take kwargs-style arguments * F() and values() take string field names * annotate() takes an aggregate function which accepts a field name string. Rich, expressive statements are simply not possible in the ORM unless a special API was designed for it (like Q and F objects), and even these objects are only composable in a few constrained ways. The worst part is that Django's documentation states consistency and composability as main goals of the ORM: &gt; The framework should be consistent at all levels. Consistency applies to everything from low-level (the Python coding style used) to high-level (the “experience” of using Django). &gt; The database API should allow rich, expressive statements in as little syntax as possible. It should not rely on importing other modules or helper objects. I wrote a long post about [why Django's ORM is so bad](http://charlesleifer.com/blog/shortcomings-in-the-django-orm-and-a-look-at-peewee-a-lightweight-alternative/) if anyone's interested. Also, Alex Gaynor gave a nice talk describing [Why I hate the ORM](https://www.youtube.com/watch?v=GxL9MnWlCwo). Strongly recommend.
[Peewee can work with Django models, too](http://docs.peewee-orm.com/en/latest/peewee/playhouse.html#django-integration). Basically peewee can introspect your Django models and generate a set of matching peewee models at run-time. You can then use the peewee models when you need to express a particularly complex query, or optimize a query that is hard to express with Django.
About the interface, is your implementation the most "faithful" with regard to dict/set/list?
A better way to implement a tree would be by making a Node class, which contains links to other Nodes. 
I wouldn't do this. My impression is that ipads are computers that you can't really use as a computer. Not like linux or even osx. I suggest getting a free or cheap server that you connect to through ssh, or remote desktop if a command line only seems overwhelming. Otherwise, I think you'll have frustrating problems and trouble getting help because no one is familiar with the platform you're on. Get a keyboard at least. Use wifi if you're connecting to a server. However, I'm totally biased and my opinion may not be relevant here.
That is such a stupid feature of the Django orm. It is one reason I abandoned using the orm. 
This is a contrived example. Why not mock out a database, queue, or service request?
Pyramid's official tutorial is fantastic. 
[As a note, on the night of this meetup there was supposed to be a speaker on Pyramid, but he did not show up.](http://www.meetup.com/nycpython/events/211138852/) It would have been great to get another opinion and see the Pyramid way of doing things.
I need to calm down, I agree. I'm only slightly to the point of tracking down a phone number and trying to call you. LOL.
The inconsistency you cite is true, although the string is in the same format as the kwarg. My preferred route is to use the orm for everything simple, where it excels, and drop into sql when things get hairy. For that reason, djangos orm works great for me. 
 Pythonista's python version is 2.7.5. You can't learn current version 2.7.8 and 3.x.x. via Pythonista.
Wow. Man, that really seriously sounds like a massive headache, one that I hope you got paid handsomely for. I dislike tastypie to begin with, but trying to migrate bad data to an even worse DB sounds awful. 
It takes more skill to set up Python and most web developers take the path of least resistance and don't know or don't care that development would go overall more smoothly if they put in effort up front to learn new things. Development as a whole is like any other field. There are more people who just want to do the minimum and go home at 5 than work harder than they have to.
&gt; What do we have? Just Django and Flask. None of the other frameworks have any major footprint on the web. It's funny, because you're posting this screed on a website that Alexa ranks as the 35th most popular in the world (and 9th most popular in the US) and which is written in Python and uses a web framework that's not on your list (Pylons, albeit somewhat customized/forked.) 
 you kinda made my point for me.. Varnish is a caching mechanism.. django isnt that fast for disqus, varnish is just that good of a cacheing mechanism out of a box.. this has nothing to do about the django vs flask discussion as far as speed and load are concerned. " We’re probably rendering some JSON, or rendering an HTML template, or simply parsing HTML and executing our Django middleware. " " Today, out of the 45k inbound requests every second, only about 15k or so actually hit our app servers. The rest are absorbed by Varnish and served to the user very quickly and efficiently. " http://blog.disqus.com/post/62187806135/scaling-django-to-8-billion-page-views
change `or` to `and` EDIT: and remove the parentheses around the while statement, you don't do that in Python even though it's valid syntax.
An elegant list for a more civilised loop
I probably was at the right place in my Python journey (3 months in), but reading this, list comprehension finally clicked.
I saw "engineroom" and thought it'd be a rubyist's take on python...
The last one for serializing csv is one I haven't seen before and is pretty neat one. I'm gonna have to remember it the next time I have to work with a CSV which I hope is not soon 
I find the arguments of this article to be poorly based and a little pretentious. I understand the importance of C, and although I am bad at C and rarely use it, I have run into times when I need to do things with it. I personally think that learning C is very important to programming, it gives you a lot of insight into how things work, it's very fast, and it allows you to understand a very common language. When I started reading the article, I thought that the author made several valid points and was thinking that I should really focus on mastering C sometime soon. However, as I kept reading, I started to find the article more and more distasteful. For example: &gt; I believe there are two separate mechanisms that make Python unappealing to smart people who are first learning to program. The first is that learning Python is not a very difficult undertaking. The core concepts of the language present no real challenge for smart people, and consequently does not demand intense engagement. Learning Python is, well, kind of rote and boring. It feels like a school that is lacking in advanced classes. Wait, what? If anything I see the opposite. Because the core concepts of Python are simple, you don't need to focus on the "rote and boring" like C. That's pretty much what higher level languages do, they take care of the simple stuff so you don't have to. In my opinion, learning a language should be easy. Programming is not about *learning* a language, it is about *using* the language to create things. Plus, the whole "smart people use %s" thing is just wrong. Anyway, I think I'll stay with my Python when I can, but you can write your nice concise C code with its helpful errors, qprettyw standard functions, and excellent string support. I think that Python is a great language for beginners, and that people can and will use C when it is needed even if they started with an easier language.
&gt; import os &gt; files = [] &gt; for f in os.listdir('./my_dir'): &gt; if f.endswith('.txt'): &gt; files.append(f) &gt; &gt; This can be simplified with a list comprehension as well: &gt; &gt; import os &gt; files = [f for f in os.listdir('./my_dir') if f.endswith('.txt')] I personally feel like dealing with the filesystem inside a comprehension is a bit weird. List comprehensions work best if you're transforming some data from one structure to another, or generating new data mathematically. Listing a directory seems like quite an imperative thing to do, and it's more obvious what's occurring if you have the more verbose version.
Great intro! Nit: PEP standards frown upon using "if not l in vowels". Better way to present it would be "if l not in vowels" Also l (lower case el), I (upper case eye) not recommended for variable names :)
Nice intro to list comprehensions, I especially liked the little nods to other people in the community. Useful blog and felt... friendly for lack of a better word. Well done.
I still don't understand why list comprehensions are useful. You can do the exact same thing in other ways and it is much easier to maintain the code. Maybe this is because I don't use them that often but it just looks like a jumbled mess, whereas nested loops are properly indented and intuitive. Someone please tell my why I am wrong.
For a crowd the prides itself for valuing clarity and legibility over anything else, the pythonistas infatuation with list comprehension is more than a bit weird. Their only apparent value is saving LOCs, to the expense of readability and maintainability. Also their syntax is almost orthogonal to the rest of the language, not to mention rather unreadable (hence the need of an endless number of tutorials explaining list comprehension).
A lot have to do with momentum. PHP is bigger today, therefore it's probably going to be bigger tomorrow.
Very nice and illustrative blog post! I do however have a small nit to pick with this example: nonvowels = ''.join(l for l in sentence if not l in vowels) Here, using a list comprehension instead of the generator comprehension is in fact a bit faster (1.86us vs. 2.76us on my PC), since `str.join` will build a list anyway, behind the scenes, if it doesn't get one. This is because `str.join` needs to iterate over the strings *twice*: first to compute the total length, and then to copy data into the memory allocated for the concatenated string. &gt; This prevents us from having to store the entire list into memory, and is more efficient for larger data. Because of what I just explained, this statement, though true in most situations, is misleading in this particular case. 
&gt; I think the main advantage was that everything remained cleanly divided despite the enormous codebase. You always know exactly where to go tweak a model for a given object. In my experience this is exactly the point - it's great for large projects worked on by multiple developers over a period longer than "a few weeks". Just having things laid out in a well-structured way and *kept together* becomes fundamentally important.
Won't make much of a difference here, but on principle I'd use a set rather than a list for checking membership. Unless it checks by iterating through the list in order, and you could short-circuit a search through large collections by having the more common items at the start? 
I find comprehensions look more correct in cases where you're doing a simple transformation of data: for example, if you've got a list of Polygon objects and you want to get a list of all of their areas: areas = [polygon.area for polygon in polygons] makes more sense to me than areas = [] for polygon in polygons: areas.append(polygon.area) It's a very simple collection operation and having it in a single unit is nicer, to me.
Both list comprehensions and the for-loop equivalent have their uses. If the logic involved is fairly complex, the loop version will probably be more readable. For simpler cases, the comprehension is more clean, and describes the list you want in a more high-level fashion. Being an expression instead of a sequence of lines makes it easier to combine with other code. Compare return [1 / i, i ** 2 for i in range(100)] and result = [] for i in range(100): result.append((1 / i, i ** 2)) return result In addition to readabilty, comprehensions are far more efficient with larger data sets - since Python is creating the list all in one go, it doesn't need to repeatedly resize the list. The same syntax in the form of generator expressions can become very powerful, since you can feed it directly into functions like min(), max(), sum(), all(), any() or into a for-loop to do processing directly on the results.
No, it's a bit silly to expect people to understand how return "mailto" ":" + name + "@" +url; is a perfectly valid C++ code, while return "mailto" + ":" + name + "@" +url; is invalid, while it's the opposite in every other imaginable language, including languages solely designed to troll people on the internet, like brainfuck and php. &gt; That's like saying Java doesn't have lists because lists are a class in it and not a primitive data type. Or that Lua doesn't have objects, just associative arrays that can hold named data and functions. That is technically correct. This is less of a problem, however, as you need strings much more often than you need lists. There's also no semantics of adding things to list using `+` so you don't have any expectation of it working. Finally, you have first-class arrays that can suffice in lots of cases where you might want a List. 
I agree with you that simple cases are nicer. I need to start using them more in this case. My main issue is with the more complex cases.
Nice introduction ... except for ignoring the fact that range(n) counts from 0 to n-1 &gt;If you wanted to create a list of squares for the numbers between 1 and 10 you could do the following: squares = [] for x in range(10): squares.append(x**2) That gives a list of squares between 0 and 9.
Glad to hear you got it working :)
sorry but, php a simple language? just mentioning one thing, have you seen the standard library HELL ? I really hope php will get better with Hack or similar, I always hated the lack of integrate package management (see Symphony that I think introduced composer), integrated dev webserver (now php has -S ), standard library mess, lack of a good php server for production (fpm has somewhat good covered this part), and many other things... php is catching up, and competition is always good for progress with language and framework development.
I've a thick skin, so don't be shy to rip this code apart. 
It's not only syntactic sugar. List comprehensions have the advantage that they can easily be converted to generators (they can even be viewed as "consumed generators", as `[x for x in y]` is equivalent to `list(x for x in y)` where `(x for x in y)` is a generator expression), and you also save a function call (`.append(...)`) for each iteration. Quickly done speed measurement (not sure if very precise, but it gives an idea) : In [2]: lc = """ ...: r = [i for i in range(100)] ...: """ In [3]: no_lc = """ ...: r = [] ...: for i in range(100): ...: r.append(i) ...: """ In [4]: timeit(lc) Out[4]: 4.970423567000125 In [5]: timeit(no_lc) Out[5]: 9.738498960000015 Of course they are not adapted for every case, but sometimes they are really helpful (as I said before, not only for syntax).
DataBAGG is robust and easy to use. DataBAGG helps to store your data on cloud and you can access it globally, anytime and anywhere. https://www.databagg.com/
You aren't enterprisey if you don't use XML. 
Cool. It's refreshing to see Python in different arenas like this.
Pyramid is serious. I started doing an applcation with it half a year ago and the beginning was difficult because I came from a Ruby on Rails background and wanted to try a Python web framework (since I really like Python more than Ruby), but it's kind of irritating that most of the examples are just too trivial to be useful. With RoR you can choose between some well-known authentication plug-ins/gems but with Pyramid you have to do it on your own and the examples are almost useless, because they have a hard-coded list of users and passwords... and so on. I know that Pyramid and Flask are "non-opinionated" but it would be better if they gave more hints like "this is the preferred way to do authentication with an SqlAlchemy backend" (since 99% Python web projects which aren't django use SqlAlchemy?).. And so on. It's also annoying that Pyramid doesn't support parsing form input names in the form of object[attribute] (or something similar), it' would make them more descriptive and easier to parse. Or when posting many items of the same type together like.. team_member[32][name] = "Bob" team_member[33][name] = "Alice" Maybe I'm just doing it wrong but I don't have any idea what's the Python/Pyramid/Flask way of doing things like that. Also, Pyramid should decide what it is, Pylons or Pyramid, it's confusing when their site is pylonsproject.org
This is great and I learned a thing or two. Although for #7: Get a list of txt files in a directory, I would just use glob: import glob glob.glob("./mydir/*.txt")
Pandas is a great tool to work with CSV, even when dealing with non-numeric values.
Neato. How does it compare to: l = range(10) for item in filter(lambda x: x &gt; 3, l): print item
The first one. One less line of code. **Edit**: As others have said, it all depends on what is `do stuff`. My answer was assuming it was a one liner. Other options are of course valid depending on the situation. And I have seen good points made around here.
I usually prefer the continue construct because it saves one level of indenting in the remaining body
The second. When programming defensively, I like to think of functions (or blocks of code in this case) as lazy individuals who try to find any excuse at all not to do the thing they're supposed to do. I put all the edge case conditionals up front with continues or returns. Get all the excuses out of the way early, and in one spot. That way, when its time to get to doing the stuff, you can run with it whole hog. Clean separation of code. Also works with while loops. Never say while &lt;condition&gt;. Just say while True: and put your conditions right up the top of that there loop. Chances are good that even if you start with a simple breaking condition, it will evolve to something more complex. Put them on multiple lines for readability sake. No one likes to see while &lt;this&gt; and not &lt;that&gt; or (&lt;this other thing&gt; and &lt;that thing&gt;), etc. Just give them their own lines with a nice break inside each.
There is a StackOverflow question about that: [List filtering: list comprehension vs. lambda + filter](http://stackoverflow.com/questions/3013449/list-filtering-list-comprehension-vs-lambda-filter)
me too. all the serialization articles for python tend to avoid PBs in general. All the article in this sub about Cap'n Proto tend to avoid answering questions how compare to google protobufs.
You may also can use &lt;http://www.appveyor.com/&gt; for this. There are plenty of windows ci systems out there.
&gt; With RoR you can choose between some well-known authentication plug-ins/gems but with Pyramid you have to do it on your own and the examples are almost useless, because they have a hard-coded list of users and passwords... and so on. When I was last working with Pyramid in earnest (about 18 months ago) trying to handle authentication/authorization was a nightmare. There are some things built in - along with warnings not to use them - and they wanted to use a separate cookie for auth before you even sign in (which was arguably illegal under EU law at the time, though I think the authorities have softened on this now), and I had to pretty much copy/paste their whole session code and edit it to work with my MongoDB setup, when you'd expect there to be a simple interface to work to. I got it working... I think... with who-knows-how-many security problems. &gt; I know that Pyramid and Flask are "non-opinionated" but it would be better if they gave more hints like "this is the preferred way to do authentication with an SqlAlchemy backend" (since 99% Python web projects which aren't django use SqlAlchemy?).. And so on. The "non-opinionated" bit is a massive hassle too. It was the same in Turbogears - you'd want to get started, and ask people "how do I do XYZ?" and they'd answer, "How do you *want* to do XYZ?" which is no help! Give me a way to get started that works, then I can ask how to change it later if some aspect doesn't work well. Personally I'm using MongoDB so I don't mind not having SQLAlchemy in there, but it's often *too* hands-off.
This library looks super useful. However, I would say that needing this library is a code smell. I would be wary of making tests that depend on it being a specific time. I've seen more than one bug uncovered because periodic CI builds broke the day after a daylight savings time change, or always failed during a certain time window during the day.
IMHO - Depends on how many lines "do stuff" is. If it is a lot of code, then having it all nested in an if statement can be annoying. If it is just three lines or something, then you make it more clear what you are doing and get less spaghetti with all lines in the if statement.
It's easy to cobble together something that barely works. With python frameworks you have to understand what you are doing. If there was a way to do the same with Python (mix html and Python code, put one file with a certain extension in the correct directory on the server and have it run) then Python would be more used, but that would enable to write awful PHP-like code with Python.
Wouldn't it be better as for item in (x for x in l if x&gt;3): that way it'd stay as a generator and not create a list. Basically you'd avoid going over it twice.
That's the good thing about freezegun: these tests will not fail due to problems like DST, since you are freezing the date to a specific day.
Agreed. That's would be better memory-wise. BTW, it may look like I'm not answering the actual question about *personal preference*. But I'm actually trying to demonstrate my preference. I don't like loops with `break` and/or `continue` statements and try to avoid them as much as I can. I think that is good programming practice. Admittedly, there are cases where they are impossible to avoid, and in those cases, I judge the situation and pick either one of them. In some cases it's important to be explicit and cover all corner cases, in others it's cleaner to just focus on the actual task at hand.
What do you have so far?
Thanks! where are you from? you think it represents mosts of the majority in your country? It helps me a lot :-)
Formatting-wise, I prefer the first one. The third looks like a Word default.
I've tried multiple monitors but I usually prefer to have one. Personally I find it simpler to change the focus of what window is right in front of me than to be looking back and forth at a separate screen. 
/r/learnpython
I mostly use one screen for preview and/or documentation and one for coding. I believe it's quite common for a Dutch developer to have two screens. 
Interesting!! when you say you change the window in front, you probably mean switching from the IDE to googling in the browser?
Yup, 2 here. Essential for getting things done.
Oh, you've got quite a lot. I'm not going to give you a ready answer :) First, read about opening files for reading in Python (the open() function) Next, when you can iterate over the file contents, use a loop over that list to add the items to the listbox, the same way you do now but with only one lb.insert() call.
The second one!
I don't think I know anyone in my field with more than one at a time but a lot of them use laptops only. I work at a university in California where python is becoming more common in our departments.
Thanks! are these people from the academic field too? or they work in the software industry?
The IDE or text editor to the browser, or the mail client, or music player, or chat client, or terminal program, powerpoint, file browser, or whatever. I use a lot of programs and switch between them a lot.
Instead of: try: self.conn except AttributeError: self.connect() Do this instead: class Hello: conn = None # ... def GET(self): if self.conn is None: self.connect() I find that style easier to read because it is more explicit and doesn't rely on monkey patching. I'd suggest doing something similar in the `connect` method too when parsing the inputs. There are places where the [EAFP](https://docs.python.org/2/glossary.html#term-eafp) style is appropriate, but I would argue that this is not one of them. This error checking could be further abstracted: class Hello: _conn = None @property def conn(self): if self._conn is None: self.connect() return self._conn def GET(self): cursor = self.conn.cursor() 
Juste one for me, sometime the big screen when I write my unittests and need two window of my code side by side but mostly I am content with the laptop 13' screen 
I developed for a long time with two or three monitors. However now I switched to a more modal approach and am back using only one. This enhanced my productivty a lot.
Interesting, why do you think it slowed you down?
Why are they faster? What's going on under the hood? I'd have used list(range (100)) there.
Fail early, fail often.
UK/software engineer here. I use three monitors. Middle monitor contains my IDE (Eclipse or Emacs) full screen. Right monitor has web browser (for documentation) and/or email. Left monitor has my IM client and maybe a text editor for taking notes. I find moving my eyes from screen to screen easier than switching windows constantly on one screen.
A monitor and a laptop screen is standard at all the startups I've seen in NYC. I generally have a terminal full-screen on the monitor and a web browser and chat on the laptop screen.
congrats !
Very simple list comprehensions are easier to read. You really should stay away from the more complex ones though (unless it's a one-off script).
Norway, everyone here has 2+ screens too.
Two at home, two at work where 95% of developers have two screens. Wouldn't want to work with less. Three is better.
This is exactly what I've always found. It's easier to just switch windows rather than screens. I'd like to give mutli monitor setups another try as it's been a while.
I'm not an expert on this, but I know that one the reasons is that with the list comprehension, there is one less attribute evaluation (`r.append`) and one less function call (`r.append()`). &gt; I'd have used list(range (100)) there. Yes, `list(range(100))` is simpler and an equivalent to my example, but it was not a "functional" example, just made it to compare the speeds.
I have long been tempted to go to three from my present two in Canada.
If your list comprehensions are getting out of hand, it's probably best to move some of the functionality of the comprehension out into a function. Often times you'll find that these small functions are useful in more than one comprehension.
I know I'm not going to convince you, but for anyone else reading: 1. That's not really an argument. If we're talking objectively here, a larger number of users simply means better support. Personally I'm not a fan of Django but I recognize it's bigger userbase does mean it wins on that front 2. I'm just arguing that defining renderers is generally inflexible. What I meant was that if you were actually changing the return value (i.e. making an HTML route into a JSON endpoint), you would need to set `renderer='json'`, **and** you would need to change the return value. But also having one renderer function means you shift all of your header/response logic into the renderer, which is good for avoiding repetition but is a little less flexible. But I've thought about it and I might have changed my mind. I think renderers are nice because they're very declarative. You just return a value from a route, and don't have to bother about the response details at that point. 3. Honestly routes were my main issue. I know that Pyramid has decorator routes as well as Flask, but why do this: config.add_route('myroute', '/url') @view_config(route_name='myroute') def myview(request): return Response('OK') When you could do this in one line (flask): @app.route('/url') def index(): return render_template('login.html')
Don't use filter, it is not Pythonic. I will undoubtedly be downvoted for saying this, as there are a disproportionate number of functional programmers on these subs than you'll find in real life. But I'm squarely with Guido on this one: the functional programming constructs map, filter, and reduce should play no part in Python.
why not just stub datetime.datetime.now() to return the time you want? https://pypi.python.org/pypi/stub/0.2.1
Four at work, three at home. One is in the portrait orientation. Generally one is for documentation/internet, one for the IDE, one for an interactive terminal, and the fourth is generally only a file explorer or my email. The fourth doesn't really add much productivity, but the first three are pretty nice. Working on a single monitor is so painful that I have a USB monitor for my laptop when traveling.
The property pattern you use in your second example is one that I've used and seen used in quite a bit of code. It's very useful and can allow you to only create the connection if needed. Often times there will be functionality associated with the Hello class that doesn't require the connection, so connecting on ```__init__``` is undesirable. You do, however, have a typo in your code. You need to unindent the ```return self._conn```.
Grad student here, two monitors at work (small laptop + large screen on top of it). I use the laptop for the terminal and the large screen for the emacs window and all the papers I read. I have to say that I dislike having windows on top of each others so I have like 9 "virtual screens".
As I mentioned above, I'm kind of getting persuaded over to the Pyramid side regarding renderers, but I'll explain anyway. In Flask, the assumption is that you're either returning a Jinja2 template (because Flask comes with Jinja and it's their recommended templating engine), you're returning json, or you're returning a file. All have easy functions: `render_json()`, `render_template()` and `send_file()` (there's also a few others useful functions like `redirect()`) And the thing is, you very rarely actually need to do anything other than those 3 operations, so for most of the time, everything's nice and simple compared to Pyramid. However if you do want to change to another templating language, or if you want to return another type altogether, it's slightly harder (by slightly I mean like 1 line more). There you use `make_response(data)`, which returns an object you manually can set the content headers for. See the docs: [About Responses](http://flask.pocoo.org/docs/0.10/quickstart/#about-responses) [The make_response function](http://flask.pocoo.org/docs/0.10/api/#flask.make_response)
python list comprehensions are one of the tricky part when it come to C programmers trying to learn python
Note that ```range``` already returns a list in 2.X (but not in 3.X which returns a generator. The equivalent in 2.X is ```xrange```)
Pretty common in my country for developers to be using a laptop and a 2nd desktop screen.
Hmm... I'm looking for more of what the bytecode looks like. I want to see list comprehension bytecode and see how it differs from an append. Easy enough to disasm though. Your explanation is probably completely right though. If it actually loops 100 times and looks up `append`, that's got to be incredibly slower.
Freezegun lets you do it as a decorator, supports timezones, nice-looking datetimes: `@freeze_time("Jan 14th, 2012")`…
It's actually pretty common to need to test that if it's YYYY-MM-DD HH:SS or less X, Y, and Z are "active" where if it's a day before they are considered "inactive". 
I'd try updating pip first and trying again. 
Hmm, you are given root on this Ubuntu 14.4.1 host.
It appears to be running inside a docker instance, so it's probably not all that bad.
The traceback should tell you this...
Yea, I put my IDE on my MBP screen and use a large external monitor for my terminal, sublime text, hipchat/slack window, etc. 
What if there's some code using utcnow? What about timezones?
Thanks! :) On a related note, do you know how would I go about printing only the contents of a tuple (none of the commas and brackets) on a single line?
I used an external monitor but now that I have a higher resolution laptop screen[1] I don't bother hooking it up. One of the best hackers I know got a ton done on a macbook air hanging out on couches around the office :p In general, though, all the tech offices I've been to in SF have an extra monitor for developers to use. [1] https://www.thinkpenguin.com/gnu-linux/snares-penguin-gnu-linux-notebook
I have two adjacent portrait displays for coding and one landscape display for browser, terminals and anything else.
 a = tuple for i in a: print(i, end=" ") iterate through each index of the tuple and print them with a space inbetween 
Line 39 missing a bracket. 
Sorry missed @mathen post.
For #3, I think it's because of [this](http://docs.pylonsproject.org/projects/pyramid/en/latest/designdefense.html#routes-need-relative-ordering), and maybe also [this](http://docs.pylonsproject.org/projects/pyramid/en/latest/designdefense.html#microframeworks-have-smaller-hello-world-programs) URL dispatch is also not the only way for routes resolution. You can also build an object hierarchy of your site, define your core processes there, and keep your views thin like [this](https://github.com/mozilla-services/queuey/blob/master/queuey/views.py). Keep in mind that pyramid also supports this kinda routing. 
By default `print()` outputs a newline character after the string, specifying `end=" "` will replace the newline character with a space.
Thanks, fixed it.
LOL!
For me: * Powerful DIY authn/authz. It took some time to learn, but I like it. * Flexible routing. Pylons/django/flask users? Zope refugees? Pyramid tries to make both groups at home. You can make arbitrarily nested URL with this. * Flexible view configuration (with auth, context, renderers, etc) * Optional deployment/logging settings (from PasteDeploy, pyramid's deps). Flask probably has this too via plugins?
The docker container is created when you run the code and then immediately killed after the code is run. 
Interesting question. Here are my use scenarios. Straight up programming such as data analysis without graphical output I use one screen. For web and/or GIS map programming I use two or more screens to show the web or map output near real time
Here's a cute way to do that: my_tuple = ("a", "b", "c",) print(" ".join(my_tuple)) Happy hacking :)
Oh, tuples are immutable so I don't know if appending to one is gunna work out for you. You could just use a list instead.
you pretti much answered yourself then? do you really think python lacks of tools in this context?
could you give an example where python is more complex to setup than php?
List comprehensions can be a little strange at first. But they express what you are doing very compactly as well as being faster than a for loop in many cases. From: http://www.bogotobogo.com/python/python_list_comprehension.php &gt; We typically should use simple for loops when getting started with Python, and map. Use comprehension where they are easy to apply. However, there is a substantial performance advantage to use list comprehension. The map calls are roughly twice as fast as equivalent for loops. List comprehensions are usually slightly faster than map calls. This speed difference is largely due to the fact that map and list comprehensions run at C language speed inside the interpreter. It is much faster that stepping through Python for loop code within the Python Virtual Machine (PVM). &gt; However, for loops make logic more explicit, we may want to use them on the grounds of simplicity. On the other hand, map and list comprehensions are worth knowing and using for simpler kinds of iterations if the speed of application is an important factor.
I would go with the first one, if nothing else, because the second seems to me like a overly tortuous way of describing the same behaviour. Off course, depending on the domain, the second one might make more sense.
could you give an example where you consider python being more complex to setup than php? 
For example 2, you don't even need list comprehensions. Just range(0, 100, 3)
If I'm reading it correctly, it's not even remotely related to REST, and it makes me wonder if the OP even knows what that is. Furthermore, everything he's doing could be accomplished with just the POST method, like an RPC-over-HTTP interface.
are you asking how to read a file or are you asking how best to put it in a list box ?
&gt; This enhanced my productivty a lot. Don't you dare say things like that in places where my boss might hear you. The last thing I need is for her to get some "bright ideas". They'd have to pry my triple monitors out of my cold dead fingers.
Most of my colleagues here in the US use two but I dislike the discontinuity between the two screens, so I use one. I also use virtual desktops a lot, so in a sense I have like 9 monitors -- I just don't get to see them all at once, although I can flip between them with keyboard shortcuts very quickly. I do appreciate screen real estate though, so I have a 2048x1152 monitor, although it's getting a bit out of date at this point, and I've been eyeing a 4K monitor -- they're down to like $450 these days. Pretty cheap.
Personal problems for the other developers don't mean that ```l``` is a bad temp variable name. I don't control anything the other developers on my team use, but if they're using a font that can't differentiate between ```l```, ```I```, and ```1``` then they're using bad tooling and should take care of that before submitting a pull request that changes the variable name. Same with tabs vs. spaces, 80 char line limits, or whatever other issues they have that are self-inflicted.
Brazil, at work we use 2 or 3 monitors. At home I don't use so much.
2 + laptop screen in the US
I prefer the second one for consistency. If I have multiple conditions, it's easier to follow: for item in items: if not item.condition1: continue if not item.condition2: continue do_stuff(item) Than: for item in items: if item.condition1 and item.condition2: do_stuff(item) Especially when you get an increasing number of conditions and some are ```and``` and ```or``` conditionals.
What point does this code serve? If you're going to write a REST interface for your database, it should actually *do something*. This adds no value, and in fact removes functionality. About the code itself - you should never, ever, ever, ever use string formatting to build queries. All replacement values should be passed as the second argument to the execute command. Even though it doesn't matter in this example - since the person making the calls would already have the credentials to the database - this kind of oversight leaves apps open to SQL injection attacks. You don't want that.
I am a professional software engineer. My desk at home and at work are both very small, I have only one monitor at work, and a laptop for everything I do at home. Over the years I have got use to using only one small monitor. I am a big fan of doing everything in full screen, switching between windows with Alt+Tab, and and using multiple desktops to switch between related tasks. I have also mastered use of the Linux command line, and can do all of my work in either the command line or in the web browser. So I keep one desktop with a full-screen terminal emulator, and next to it a desktop with a full-screen web browser running. For web development, I like to split the screen, with the browser and Terminal text editor (Vim) side-by-side. If I had two monitors, each would get it's own screen, but it is not necessary for my day-to-day use.
You override [`sys.excepthook`](https://docs.python.org/3.4/library/sys.html#sys.excepthook). see http://stackoverflow.com/a/6234491/1255482
Setting up mod_wsgi or gunicorn instead of using the preconfigured mod_php, creating a URL route and view with Django vs. dropping a file into a directory.
Very same here. A lot of people use (at least!) 2 monitors here at the shop where I work. Be it 2 Monitors in the "usual" meaning or Monitor + Notebook. But for me it became annoying move the head around all the time and arrange the working environment. I used the second monitor less and less. So I traded my 2 monitors for one big monitor and configured kwin shortcuts to move windows in any edge of the window. Much better now! 
I've done this and it gets annoying/ugly to do repeatedly.
 def main(): try: ... finally: # do cleanup here
After years of using two monitors, I developed a chronic neck injury from the repetitive motion of looking back and forth between them. My neck now makes a painless but annoying 'clicking' or grinding sound when rotating my head, which began suddenly (I still recall the moment I first noticed it) and without warning. There has been some modest improvement some time after switching back to one monitor, but does seem to return if I perform some task that requires repetitive head turning. I highly recommend using one monitor only. Get yourself a nice 24" or 27" and modify your working environment if necessary. I use less windows, a modal editor (vim), tmux/screen, and arrange tasks on multiple desktops rather than multiple monitors.
Canada here too...I work alongside a very large group of telecommunications professionals (some people taking calls, some not). It's rare you see employees with only 1 screen. At any level in the hierarchy. We even had a large project to get all the (at the time) call centre employees with dual screens as we found it increased productivity significantly. It's not so much a question if an employee has a second monitor. It's only a question of how big (new purchases are typically 24" monitors).
for the past 2 years I've done 100% of all programming on a single 15" macbook pro screen. Back in the day and previous jobs I've used dual 30" screens and stuff like that, but I don't think it had any effect on productivity. It did look badass though to have all those screens on my desk...
Django is exactly fast enough. It isn't the bottleneck, and unless you're running something that requires websockets or something, you should be caching anyway.
Can confirm. I used two for several years, but now I'm really liking the single-monitor setup. Having email open in a second window is a productivity disaster. Same for having reddit open, or anything else. Multitasking is way overrated. There's a more subtle effect, too: with two monitors, I'd tend to stay at my desk more. I think there's a mild hypnotic effect of covering your visual space in *glowy screen*. Leads to more hours (not more productive hours, just more hours) at the computer. Unhealthy. The one time I miss it is when learning something new: it was nice to have the tutorial / sample code open on one screen and be playing with it on the other. Also, I go up to 2 monitors when doing image analysis or video work; one for the code, one for the images.
I use dual monitors, though I have considered replacing it all with a nice 4k display and a good window manager(either something that is tiled, or at least very easy to configure where windows go and keep them from being overlapped and cluttered)
Just use this: https://github.com/jeffknupp/sandman
I have two monitors in portrait orientation. One with a long terminal with code, the other with a browser (most websites are vertical, reddit included) or e-mail client or whatever. I have more than one desktop on each monitor of course. 
^^^^^^^^how ^^^^^^^^do ^^^^^^^^you ^^^^^^^^work ^^^^^^^^on ^^^^^^^^a ^^^^^^^^13" ^^^^^^^^screen?
The "point" appears to be not exposing the Postgres port. However, nothing is gained by just transporting that same interface over a different protocol that is also exposed, even if it was done better than this.
&gt; Votre réponse a bien été enregistrée. French surprise at the end.
Usually I go for the second, for indentation reasons. But we also shouldn't forget for item in (i for i in items if i == x): do stuff 
I used to use 3 monitors and recently switched to 1 bigger, higher density display. I highly suggest it. 
The second or by chaining generators. filtered_items = (item for item in items if item == x) for item in filtered_items: do_stuff
I'd rather split off the conditions into their own function than what needs to be doing, especially if there's a good name to invent for items that meet that conditions. Let's say it works to call them "neat items": def select_neat(items): for item in items: if item.condition1 and item.condition2: yield item for item in select_neat(items): do stuff here Maybe, _if_ such a good name exists, the compound condition could even become an `item.is_neat` property itself.
Sorry to sound cynical, but I can't help but think "another year, another why aren't you using python 3" discussion. Is it really not obvious why people aren't using python 3?
I have two, but I decided to use only one at a time. The other is on top of a small table on top of my desk, and I can use it as a standing desk when I want to.
I like to have one precisely because then I can't see everything all the time. Easier to focus.
4 here! I am a tier three support for a large user base and manage our ticketing system. When I am scripting I generally span my IDE across two portrait monitors and a third for testing code. I have a fourth for monitoring calls and tickets. If I was strictly a developer I could get away with three, but It would be a struggle to go down to 2 again. Having that third monitor for testing or searching for solutions is invaluable. 
Yes. We also use yaml for configuration and fixtures in tests.
Basically: Python 3 doesn't support X which is what I need.
Awesome! I was just thinking to myself, 'bet I can convert cbr to cbz in python', you beat me to it. I'm going to give it a try now!
What I have been meaning to do for awhile, very nice. The template seems... complex.
It is also much faster Testing: &gt;&gt;&gt; import timeit &gt;&gt;&gt; a = timeit.Timer("range(0, 100, 3)") &gt;&gt;&gt; a.timeit() 0.4157998561859131 &gt;&gt;&gt; b = timeit.Timer("[x for x in range(100) if x % 3 == 0]") &gt;&gt;&gt; b.timeit() 7.091533899307251
That makes sense, since it is incrementing by three instead of incrementing by one and checking x%3 every time.
Ahah bien vu! I'll try to fix this :-)
[This page](https://wiki.python.org/moin/Python2orPython3) should answer your question. Simply put: minor but backwards-incompatible changes. Yes, the newer the better, you're right. However many of us work on old codebases that only work with python 2 or have dependencies to projects that only support python 2.
In the US. I've used one, two, and three. The first divide is laptop versus desktop. Some companies issue everyone a laptop and expect them to work on it every day. (Rather than just using it for travel.) If you work for one of those companies, you often have to live with one small screen. The drawback is that you're less productive; the advantage is that you're more portable, since you're used to working like that. (If you're used to 4 monitors and your special keyboard and mouse, then a laptop feels like a useless bitty box good only for checking email, not for coding.) Among employers who believe in desktops, most have no problem with multiple monitors. 1920x1080 monitors are cheap enough that you can get one for about 1-2 hours of a programmer's salary, so if it gives them any productivity at all it's a no-brainer. And most common video cards support two monitors now. If you want 3 or 4 monitors then you typically need a second video card and more desk space. Some companies are fine with that; some are not.
I have 4 at work (3 at home)... Two full-IDE windows with 3-4 panels, a browser monitor, and a misc monitor that has chat and e-mail on it right now.
I'm not sure I understood your problem, but here goes: In your 'global' version, you're actually calling (and getting) time.localtime() only once. Therefore the value of 'current' never changes, no matter how many iterations are performed. Another thing - you do not need the 'not_time' variable. You can use 'while True' and simply break when needed.
Basically "no incentive" (see last question in the survey).
Great post! I agree with those myth busters, and it's hard to beat the python ecosystem (batteries included indeed).
I use both, because to me they're useful in different situations. I'm currently using Python 2.7 at work because we use alternative Python run times that target different languages which don't support Python 3 yet; Java, C# and JavaScript. I also do a lot of heavy crunching using pypy -- which has better Python 2.7 support at this time. I like Python 3.4 control flow better, however. I like some of the new features like asyncio and the process pool manager. Some things still frustrate me going back and forth between the two, but it's usually small things like function signature or import path.
In my line of work (control system programming for industry, power plants, waste incineration plants, water treatment plants, etc. in a global three letter company) we use at least 2, commonly 3 monitors. Most of our programming is done in a graphical programming environment with a graphical programming language. So we need rather large (minimum 23" full HD - some even bigger and quadHD) screens to be able to get the maximum out of the screen estate. Also, we usually have a PDF, Word Document, Cad-drawing, or database open on the second screen from which we frequently need to copy - paste data. Alt-tabbing is no option as sometimes we can't copy-paste the data (if we get a badly prepared PDF) so that we need to actually see the information all the time. The third screen is mostly used for showing the process visualization so that we can make changes on the fly and that we can see the effects of our program changes. Also, the e-mail and company instant messenger is opened at that screen. Our line of work involves constant communication among the team (which can be hundreds of kilometers - or even continents apart), hence the IM and also we are in constant communication with our clients - thus the e-mail program. I am based in Austria and for our line of work this is the usual standard. Even when I program (in) desktop applications, I really appreciate having a second monitor. Can't really think how I managed to work with a single screen before.
WRT #3: http://docs.pylonsproject.org/projects/pyramid/en/1.5-branch/designdefense.html#microframeworks-have-smaller-hello-world-programs
&gt; since my head turns much easier to the right than left. I would recommend a good chiropractor. :)
I use two at work and home. It's nice to have documentation up on one and an editor in the other. I typically also have at least two workspaces to keep my screens split from "distractions".
I don't know - I've definitely got *incentives* for using python3. Writing unicode aware code *is* a lot better (though still not perfect), and that alone is enough of a gain to use it for new projects when I can. The lack of support for certain libraries has generally been a bigger factor (and has sometimes required be to switch back to python2 when I needed something it didn't have).
It's very subjective. I focus a lot better without the alt tabbing. Interrupts my train of thought much less.
It also depends on what you're doing, of course. I don't do much frontend work, I mostly care about Emacs and my unit tests.
Jawohl! I keep my editor (Sublime Text) in my primary monitor, and then I keep my explorer window for the project, cmd to run the script, and anything else relevant in the second monitor. I sometimes make two Sublime windows if I need to view two files in it simultaneously. If I don't really need all that, I usually just keep various other stuff in the secondary. My music player (WinAmp), Steam/Skype/IRC/other instant messaging stuff, Google Tasks, live streams, et cetera. Bear in mind, I am not a professional programmer at all. Maybe I am in some six to eight years, but not now. I would totally get a third monitor if I could, as I find two monitors to be quite lacking, but that's not really because programming stuff needs space; it's more about my interests in general.
Nobody expects the french revolution!
I'd find getting highly immersed in programming to be nearly impossible without 2 widescreen monitors. Two monitors, with split screen (win+left/right) allows me to have two different Python files open, side-by-side, and keep within the 80 (up to 100) line length that PEP8 suggests. The second monitor, of course, is available for all other things, including the browser, putty session, or whatever else I need to keep up.
Python 3 has better generator behavior, print is a function instead of a keyword and / is floating point division instead of integral division. Also, classes are more mature in Python 3, require a little less boilerplate, etc. Don't use Python 2 - it's being phased out and actually should have been abandoned long ago, but apparently Python developers didn't listen when they were being told that Python 2 was going to be deprecated and they'd need to switch to 3. Now they're just dragging their feet because, fuck it, Python 2 was good enough. I don't know a lot of times where a backwards incompatible update was introduced to a programming language, but I guess I see now why it's not done more often.
Look out for those print. If you call print(string you want to print) it will work with both Python 2 and 3. Calculations can be made inside classes, of course. Good luck with your test
On version 2 (version with current as a global variable (time.localtime()) it would run (continuously, correct?) until the n_HH and n_MM reached time.localtime().tm_hour/mm respectively. For some reason, when it reached the set time (for example, 15:58) it wouldn't open or even prompt me to enter "Quit". It would just... keep running. I fixed the problem by putting the variable "current" inside the while loop, and it opened the file fine, and prompted me to "Quit". My confusion is why it works without a problem with "current" local variable inside the while loop instead of as a global variable. I plan to turn this alarm into a stopwatch and timer down the road, which I why I want "current = time.localtime()" to be a global variable rather than a local. Thanks for y'alls input. EDIT: I also have made an alarm using var = list(time.localtime()) hour = var[3] # hour min = var[4] # minute var worked fine globally, which is why I'm confused that "current" won't work as a global.
I prefer 2.x myself. The syntax just feels more natural for some reason. 
Because I have to support old code and old products.
~~It's a fairly simple class, and I would suggest writing some simple test cases to test its logic.~~ Here is my review: 0. Many of your functions don't handle erroneous input. set_hourlyRate('eight') would fail. But maybe you are not expected to handle those errors, just pointing out. 0. `set_monthHours(40)` Your function will fail to register if the number of hours is exactly 40. 0. `print "Monthly gross pay: " grossPay` This line is missing a **+** 
My biggest and most critical python 3 hold-up is PyInstaller. The alternatives (py2exe, cx_freeze) have issues. For py2exe, issues with one-file deployments causing compatibility issues with other libraries and requires the installation of a specific version MSVCRT90 which doesn't work for clients that must be run without UAC escalation in locked down environments. For cx_freeze, it has no support for one-file builds deployments. PyInstaller works great but does not support python 3 yet and it seems like their python 3 development has stagnated over the past month. 
As always, please use `with` to open files.
I use a laptop. Not even that big a one (MacBook Air). Currently only has 5 desktops. I've used up to 9. I feel like it's a sort of weird setup that works well for me.
Three monitors at work, two at home. Technically, I have six "workspaces" set at home and I use all of them, so I have a few virtual monitors, I guess. I definitely wish I had three real monitors at home, though.
Would be interesting to know how the answers vary between educational, professional and hobby users. 
Maybe this is obvious, but you're missing the `def` before `__init__`. Less important, but are you graded on the code being "pythonic"? If so, python classes don't usually have get/set methods for simple things like `self.__name = name`. Usually you make it an attribute or property and could probably set a lot of this stuff in the `__init__` method by passing arguments. For your specific questions: * Class methods usually do some sort of calculation even if it includes loops. They do *not* usually handle command line arguments or communicate with the user beyond maybe a log/print message. * "Calling" a class does just make the object. There is more to it, but calling `one_employee = MyEmployee()`is just creating the object and assigning it to that variable name. Hope that answers something, good luck. Edit: Formatting.
I put stuff that I don't want to distract me on another workspace. Like email, music, Skype.
Here is the [provider list](https://github.com/typpo/textbelt/blob/master/lib/providers.js) from the source for anyone who's curious.
they screwed themselves by not making 3 backwards compatible with 2. Java would've never gotten anywhere with their releases if the newer VMs weren't backward compatible. Maybe it's time to think about a Python 4 VM that's compatible with 2 and 3. Have people switch without porting a single line. And then all new code can use Python 3 syntax.
Yes, I love pandas! Its so much easier now to get pandas using anacondas that I am much more comfortable importing pandas knowing pandas are easily accessible! However, sometimes using pandas is overkill for a lot of simple tasks, and it's good to see that python can be just as capable. 
placing 3 lines of code with 1 is certainly useful. Whether it is expressive depends on how familiar with it. Loop is an imperative style, whereas list comprehension is a declarative style. Both are intuitive if you understand them.
As someone that started programming a couple of years ago my advice is to stick with what you got. The grass is always greener. That means Python 2 vs 3, programming languages, text editor, IDE,... In the end it matters what you accomplished to create. Not what tools you use. 
I vote to keep it. Nice little surprise at the end. My translation: Your response has been recorded well.
4, every time I add one it becomes ever loved. 1: Email and server monitoring 2: Messaging and other communications 3: IDE and Repository, any other coding tools 4: Browsers
What's strange is that my profs have been telling us that python is where it's at "in industry" 
Basically. Python 3 gives me zero reasons to expend the effort.
&gt; they screwed themselves by not making 3 backwards compatible with 2. It was impossible to do so. The only change worth discussing is unicode. You cannot make unicode work right while constantly assuming everything is ascii. If you're complaining that print is a function or that division changed or that dictionaries can't sort ints and strings at the same time, then you're being picky. For these issues, there is a common version of code you can use that works on both and it's not hard.
&gt; Tooling, strong conventions, and code review are what make big projects a manageable reality. Thanks!
&gt; minor but backwards-incompatible changes. Yes, with the caveat of a MAJOR forwards-incompatible change (unicode)
... /r/semanticweb
5 ★ Open Data http://5stardata.info/
&gt;&gt; "Can you do graphics with it?" The answer here is emphatically: "Yes, you can absolutely do 3D graphics programming in Python." https://www.panda3d.org/ http://www.ogre3d.org/tikiwiki/PyOgre http://www.pyglet.org/ Minecraft clone in 900 lines: https://github.com/fogleman/Minecraft/blob/master/main.py 
You got me. All fixed. Have an upvote!
I'm currently writing a device emulator in Python, because it includes everything I need. Java has no built-in web server. C# doesn't distribute its web server. C...no. So Python it is. Yes, I need another serial library, but that's true with every language. 
There's nothing about REST that can't be accomplished with a POST. It's not RESTful, but you can do it.
Yes definitely recently.
Changes, from [here](https://www.python.org/downloads/release/python-279rc1/): &gt; Python 2.7.9 will include several significant changes unprecedented in a "bugfix" release: &gt; * The entirety of Python 3.4's ssl module has been backported for Python 2.7.9. See PEP 466 for justification. * HTTPS certificate validation using the system's certificate store is now enabled by default. See PEP 476 for details. * SSLv3 has been disabled by default due to the POODLE attack. * The ensurepip module module has been backported, which provides the pip package manager in every Python 2.7 installation. See PEP 477. 
The first 2 are wrappers around C++ libraries. The last one is a 2D library (and largely unmaintained). Can you do 3D graphics using Python? Yes. Should you? Probably not.
C is relatively low level and simple, and lacks a lot of modern language constructs. C has extremely wide applications. For example, most embedded systems (think wristwatches, microwaves, microcontrollers in cars, hard drives, etc) run firmware written in C. It lets you get very close to hardware. You can also write Python extensions in C, which can be useful for performance (and other) reasons. C++ is like C plus a ton of extra features. C++ is an enormous, complex language where you can do anything you can imagine. Most videogames are written in C++, for example. Java is somewhat higher level than C or C++, as it doesn't give you direct access to pointers. Java is very strictly object oriented. Java has really, really good tooling and documentation. It's also relatively easy to write portable Java. C# is kind of like Microsoft's version of Java. It has similarly great tooling and documentation, and integrates well with everything Microsoft. (please don't hate me if I've said anything horribly wrong)
Only if you from __future__ import print_function
&gt; Each runtime has its own performance characteristics, and none of them are slow per se. Hahahahaha~ &gt; The more important point here is that it is a mistake to assign performance assessments to a programming languages. Always assess an application runtime, most preferably against a particular use case. Fair enough, everything is relative, but this reads like a playbook for 'how to be defensive about how slow your favourite programming language is'. What's with all the sugar coating? cpython is slow. Plugins and native code called from python are fast, and that results in an overall reasonable speed for python applications; but the *actual python code* that gets executed, is slow. There's a reason http://speed.pypy.org/ exists. ...but then again, pypy isn't really production ready, and neither are the other 'kind of compliant' runtimes like jython, etc. It's pretty hard to argue with: 1) cpython is the deployment target for the majority of applications 2) cpython runs python code slow as balls. 3) overall, the cpython runtime is pretty much ok because of plugins and things like cython 4) python is a scripting language (wtf? of course it is. What is myth #4 even talking about?) I mean... really? tldr; python is great for quickly building enterprise applications, but its strength is in the flexible awesome nature of the language itself; the runtime itself leaves *a lot* to be desired. 
Thanks. i am working on it and now cant figure out how to create an instance of this class. I tried: Employee("Bob") and such. Classes are killing me. How do i get it to print all my info? Any help would be AWESOME. It is due in an hour. I wish I could just go to school and not full time job it as well. Here is the code. http://ideone.com/N7mD2h Thanks for any help.
Thanks. i am working on it and now cant figure out how to create an instance of this class. I tried: Employee("Bob") and such. Classes are killing me. How do i get it to print all my info? Any help would be AWESOME. It is due in an hour. I wish I could just go to school and not full time job it as well. Here is the code. http://ideone.com/N7mD2h Thanks for any help.
I posted elsewhere in this thread. Check for that post as well. As for what you just posted, read the traceback. What do YOU think is wrong with the code?
Agreed, having been focusing on performant code for a few years, I'd say python is slow. But, it has excellent wrappers for fast C code, and is easily extendable with cython or C when it really counts. I love python.
Updated to try your suggestion! Regarding the attribute caching, take a look at the [last two sections of `home_brew()` here](https://gist.github.com/hartleybrody/9164c1b1d28842255e4b#file-serialization-py-L101-L109) to make sure I'm comparing them properly. I implemented both the one you suggested, and another one where the attributes aren't cached. Unsurprisingly, both are slower than some other attempts that don't use attributes (iterating over the dict and using %-formatting). Surprisingly, the one that calls `format` on each iteration through the list of keys seems to be faster than keeping it cached.
Pyglet is a 2D library using OpenGL. All it provides in terms of rendering capability is displaying 2D images as sprites, and some helper functions for low level vertex buffers etc. If you want useful 3D capability, you have to write your own OpenGL code for that and integrate it.
Writing tests for an assignment like this is totally overkill and won't help him understand what he's building. He's a novice, not a Jr. Developer. To point 1 - This is Python. We're all adults here. No need to enforce type checking on those set methods unless it's actually required or will be interfacing with lots of other code. He shouldn't even be using setters here, but using setters and validation for something that's most likely an introduction to classes in Python is distracting from the point.
I think the biggest with Python is that you need to learn to forms of syntax. Or at least keep in mind what you're doing between Python 2 and Python 3. Since in a work environment, you might be asked to maintain a program that was written in two, while developing new code in 3. Sure you could rewrite the code written in 2 and bring over to 3, but management has to sign off on that decision.
I don't think, it did. After adapting a lot from Gary Bernard (https://www.destroyallsoftware.com) I speeded up a lot. When coding now, everything I do is modal, I use vim, or am running tests, or am looking at the browser, or write a report, debug an app, do a pentest, or or or. However I'm always doing only one thing, so there's no need to have mutiple windows or monitors. It's way more relaxing, I don't have to move my head, I type less and automated more. Using one monitor instead of two was the beginning of it. edit: English is not my mother language, I just looked up what I was trying to say is known as "singletasking". If you google it together with "monitor" "productivity" "progamming" etc pp. You'll find way more pointers I could give you, try it out ;)
You should tell them about the European Space Agency (and NASA as well, I'm sure) doing simulations and calculations and stuff for freakin' interplanetary spacecraft missions with Python.
Great followup, but I have a two issues with the way it's worded. The question &gt;Do you think Python 3.x was a mistake? has answers that obviously show your bias (and is therefore leading). What if I don't know? Or what if I'm undecided, or have other feelings about it other than "it could've been more gradual." On the last question, the word is "applicable", not "appliable". 
Please delete this thread and post in /r/learnpython Your question is theoretical, not programming related. If you want to model it though, solve your problem by hand first, with pencil and paper, then you can translate your process to code.
OK, the Python interpreter is slow, but in most Web project Python is light years faster than tomcat + J2EE shit in all develop, setup and serving speed. Yeah, some of your fancy for loop Java programs may be faster, but I have yet to seen one myself in production. Especially those enterprise SSH java ones. Anyway, that's my own observation. YMMV
The GIL made it easier to use threads from the perspective of the CPython developers. Instead of maintaining the myriad of locks necessary to make Python keep chugging in the presence of OS threads, they kept it narrowed down to one lock. This allowed the developers of CPython to keep the design simple. It actually improves single-threaded performance, and single-threaded software was (and possibly remains) the most common use case at the time that the design decision was made. Honestly, I think that the real issue is that the Python developers even attempted threading at all. Shared state threading in a dynamic programming language is simply a recipe for disaster. Message-passing parallelism wasn't really a popular idea in Python's early years. The design decision to mimic Posix threading haunts the CPython implementation to this day.
[The research disagrees with you.](http://www.techempower.com/benchmarks/)
Go @ www.golang.org! It has many features from the C family of languages like static typing and pointers (low-level, but Go's pointers are more restricted), but also resembles python in its expressiveness and quality of the standard library. I feel its the perfect 'in between' language when it comes to high-level or low-level. The thing Go gets right is concurrency. When the creators of Go wrote the language spec they insisted concurrency be a first class feature of the language. 
&gt; Java has no built-in web server. It doesn't need to. The Java servlet API allows you to built abstractions which you can run on any servlet container. Additionally, most servlet containers (tomcat, jetty, glassfish, jboss) have embedded versions which allow you to run a web server in a single JVM... and using these is usually as simple as including their library on your classpath. Even that all being said, the JDK *does* have a built in web server since Java 1.6: `com.sun.net.httpserver.HttpServer`. Also, C# Web API has OWIN, which is pretty similar to the Java servlet... again it gives you an API to create abstractions of web servers and allows you to self host outside of IIS. C# is definitely lacking here though, although the next version of ASP.NET promises to turn this around.
Eh, get used to it. It doesn't just apply to Python. With some people, anything other than the programming language they like is a cookie cutter one that you can't do anything with. 
The other main reason to code in 2.x is if you inherit a large codebase where, even though all the dependencies now work in 3.x, it would just be impractical from a time/resources perspective to port everything over. However if you're purely writing your own code then yes, use 3.x until you NEED something that ONLY works in 2.x is right answer. For OP's benefit, even, what, three-ish years ago a lot of major packages didn't support Python 3, right? Now most of them do, and a lot of smaller ones either do or have forks for 3.x. So for fresh code bases there's many fewer reasons to start with 2.x.
Reddit is in Python, and this site it pretty huge. Language speed characteristics have relatively small impact. Nowdays there is more important things - What is more important it's architecture, 3rd party solutions, access to wide range of libs, ease of reading and writing code etc. For modern web apps it's just a wrapper between database and front-end. And speaking about Python, the huge plus is ability to write asynchronous code, especially in python 3.
I'd have to go look up just what the converters can do but there are automated 2-&gt;3 converters that will handle the most straightforward differences. The most obvious one is the change in print, it's a super straightforward change and the converters will spare you the hassle of chasing those down. IIRC the converters can introduce new unexpected errors though so probably not great for really large codebases. Also, I'd have to read up on this too but if you absolutely have to use 2.x I think the point of "from future import" is to ease the pain of eventually needing to transition your code. For instance, you can import the print FUNCTION into Python 2.7 from future, so when you eventually port to 3, you can just delete the import from future line instead of chasing down all your print statements. 
I got same arguments from Java programmer i know... Oh you don't even have static typing, that could lead to problems! Oh you don't have this and that. But then i aked, dude are you code something which required light fast speed and such large applications that static types is so critical for you. And also i saw a website he made (very slow and really outdated), hell i can do same in few hours in python. With less code, more easy to debug, using wide range of awesome frameworks.
Yes, that's... what I said.
Or, "I inherited a large 2.7 code base at work, or started a code base at work back when I needed to use X and it didn't support 3, and now work won't pay for me to update the code to 3."
Just out of curiosity, am I correct to think that any valid, working C code will also compile to valid, working C++ code? 
This survey will be biased towards Python 3.x. Most people who are not attached to the language itself will tend to use Python 2.x for pragmatic reasons, but they are less likely to take the survey, since they don't care.
That's a good example. IMO the basic rule of thumb is, if the for loop equivalent of your list comprehension would be more than a couple of lines, just write the fucking for loop. Your example is a very clear-cut example of "I to take my list, extract an attribute of each element of the list, and put them back together in a new list in the same order as the original list." But when you start going too deep with them it can become really hard for someone who's not you to have to go through and figure out what the list comprehension does. If you *know* you're going to be the only one ever looking at the code, then of course, do whatever the hell you want with your fancy one-liners. Okay, it takes a few more lines of code, but whatever, other people (or future versions of yourself who haven't looked at the code in a few months) will actually be able to understand what the code is doing the first time you read the code.
No, you said "what he's doing could be accomplished with just a post" which is like saying "the sky is blue" because anything can be accomplished by a post.
Yup, I have a couple of pieces of code in mind where I'm actively using them right now and that list comprehension would be a much nicer way to handle ingesting CSV files.
Full time python developer here, can confirm!
&gt;That gives a list of squares between 0 and 9. Between 0 and 81, I think you mean.
http://stackoverflow.com/questions/861517/what-issues-can-i-expect-compiling-c-code-with-a-c-compiler
Rust.
I'll just say it: Python 3 is the Perl 6 of Python. No going forward, no going back. Language suicide.
Line 11 is completely screwed. Remove the extra parenthesis and colon. You also appear to be doing a pascal style approach to python. You have no need to use double underscores to hide private variables nor do you need to have dedicated get/set functions. Get and set functions are only good for updating a collection of attributes at any one time. 
That's more work than import http.server; http.server.run_forever().
Perl 6 was at least entertaining.
python 3 made several changes to bytes/text handling that could have been done one at a time.
How about write speed? http://www.techempower.com/benchmarks/#section=data-r9&amp;hw=peak&amp;test=update There are tons of tricks to optimize for read/write speed, for example you can check source code for Python vs Java in the "Single Query" round. All java has fancy MySQL Prepared Statements in ORM level with connection pools, yet many of the php/python ones are constructing new SQL text and connection for each HTTP request. That's why it's slow.
Oh, for sure. You won't get any arguments from me, there. I was merely pointing out to you that the statement "Java has no built-in web server" is false.
Okay, you read it differently. Not worth arguing over.
So write a better benchmark and submit it to them. They have a well laid-out contribution process on their GitHub account. You seem to know how to optimize web applications, so they could benefit from your experience in representing various frameworks.
2.8 is not too far away! amirite?
Marmotta is written in Java. A Marmotta client library written in Python would be great. Any Python program can access a Linked Data server over SPARQL (HTTP); though it is far more safe to use a query-writing library that manages parametrization (and sane LIMIT clauses) than to build SPARQL query strings with naïve string concatenation.
Hey guys, creator of Ethereum and Serpent here. Serpent is not really a python library, it's a separate language that happens to look like python. It's untyped (by default) and statically compiled, so it works quite differently from python itself, although I tried to keep some of the high-level idioms similar to make it as familiar as possible. Right now the feature is disabled but I'll soon re-enable it, but the idea is that strings _are_ numbers, eg. "dog" == "\x64\x6f\x67" == 0x646f67 = 6582119.
That's the best way to describe python. I'm stealing that.
&gt; The entirety of Python 3.4's ssl module has been backported for Python 2.7.9. See PEP 466 for justification. In case anyone complains "but 2.7 is a dead branch!", this was purely to improve security (which is kind of obvious if you know what SSL is or stands for): https://www.python.org/dev/peps/pep-0466/
/r/learnpython
I get the same thing with Firefox :(
No, not at all. The simplest counterexample is: int main(void) { int class = 42; } But there are [many, many more subtle differences](http://david.tribble.com/text/cdiffs.htm). C++ never was and will never be a superset of C, particularly with the divergent evolution of C99 (e.g. VLAs) and C11 (e.g. type-generic expressions) vs C++11 and C++14.
I have 2 24" wide screen monitors in portrait mode and I use 4 workspaces dedicated to different tasks. One monitor is usually and IDE, feel screen shell window or VM, the other is usually web browser, notes, chat, email, etc. Some of my windows (notes and IM) are pinned and show on the same monitor on all virtual desktops. I use Gnome on RHEL.
&gt; 4) python is a scripting language (wtf? of course it is. What is myth #4 even talking about?) What does this even mean? How does one define a scripting language? Like, the term doesn't mean anything. Is bash a scripting language? Python? Any language with a REPL? Haskell? Lisp? Clojure? [java?](http://www.javarepl.com/console.html)
Or a series of small comprehensions rather than a single big one, if it's applicable and more readable.
Python2 and 3 are not drastically different that you need to use two forms of syntax. Please give me a concrete example of a difference in Python 2 and 3 in which there is no compatible solution between the two. The rumours that there is a difference is a myth, a few extra import statements to have it work in both 2 and 3 will not kill anyone, and management will not have to sign off on anything.
And perhaps years of experience with the language. I'd guess newer users would be more py3 inclined.
I agree with /u/badsectors. The benefits of the URL decorators are greatly outweighed by the increased fragility of the consuming application. Mixins and class-based views eliminate the need for the view decorators.
I'm going to wait for 2.8.1
&gt; 2) cpython runs python code slow as balls. Unless it's written under the hood in C. There is no reason for mathematical code to be slow in Python. There is no reason for parsing code to be much slower than C especially since the standard formats are coded in C and are available in Python.
also youtube
Such as... The big issue with unicode is randomly placing encodes/decodes without actually understanding why you're doing it. Having print implicitly covert all your text to ascii because it's going to standard out, but working just fine if you print it to a file is so confusing. Writing code and not have it be able to work with unicode means it never worked properly in Python 2. If you want ascii, is it really that hard to just say so? Blaming Python 3 for finally making it obvious that unicode exists is not the fault of Python 3.
Sorry but gotta nitpick here. I wouldn't exactly choose reddit as an example here. It's a big site that uses python, but it is notorious for its "ouch we took to long" messages under peak. That said there are certainly other big projects using python successfully with good performance.
Or you leave the future imports and write your code to run on both 2 and 3. That's generally what I do.
If you intend to chain list comps, be sure to use () to make it a generator. Generators evaluate lazily and will save iterations.
2 years ago, I made handsome bux with python, to convert data from a 15 year old system to transfer to a 35 year old system (yes, 15 to 35). It worked, even though the client was utterly retarded (as you may guess).
Because it is produced by a company full of real people trying to earn a living who are spending their lives to enrich those of fellow programmers?
I know I'm a new user (of about a month) and found it all very confusing. I picked 3 because I'm using it to write my own things for fun and some self-contained tools for work, where it would never be relying on system python anyway, so installing 3.3 &amp; virtualenv is expected. I didn't realise there was still so much hostility to 3.
Bah the dependency issues drive me insane. I do various amounts of scientific computing. Most it seems there are 4 sets of libraries. 2.x 32-bit 2.x 64 bit and 3.x 32-bit. and 3.x 64 bit. And half the freaking time they don't seem to work together well. Plus I wish they would get pip working properly under windows. I have had to move over to anaconda python (which is unfortunately quite slow) to work around most of these issues.
You can do 3D in Pyglet. There's an OpenGL example in the source distribution that shows it. Plus, I know we have a Pyglet backend in SymPy that does surface plots.
Yeah. That's the only one I thoroughly disagree with. Python (CPython specifically) is slow, but it doesn't matter for the most part. People are writing shitty Java and Ruby and it doesn't matter if CPython takes a little bit longer to do something if it's written in 5% of the lines and 100 times more maintainable, so less fucked up bugs in the long run. Of course, beautiful fast Java can be written that Python could never beat in performance, but for the most part performance IMO should also be measured in how long it takes to develop and squash bugs. In a pure performance comparison, CPython can't match Java or true compiled-to-machine-code languages, but fuck it. Network speed is generally my bottleneck, not my sorting algorithm.
Yeah, but at some point you're coding in C, not Python. If you write every high performance part in C and call it through Python, how much can you really say it's Python? Don't get me wrong. That's probably the best way to do high performance stuff with Python, but I don't think it means CPython is fast, it just means it uses a fast C API.
Here's how to convert 2 to 3 in about 99% of Python programs. s/print (.*)/print(\1)/g
If you want to. I use numpy, so while I have to vectorize my code and call the right functions in often non-obvious ways, it's still technically pure python. Somebody did coded it in C, but that doesn't mean you have to. &gt; but I don't think it means CPython is fast, it just means it uses a fast C API. CPython is running the code, so I say it counts. If all the standard library was written in Python instead of C, everyone would say Python is slow. Instead, they say it's fast enough. That stuff counts.
Yeah. I've always find this argument kind of odd. I just write code that works in both versions. Of course it'll bork up at some lines, but an extra import or extra if statement easily fixes that. Just write valid Python 3 code. If it ceases working for 2.7, fix it.
What kind of examples could you give of Python's slowness causing great problems in real-life applications? Raw execution speed doesn't matter much any more actually (like in the 90's). If it did, everyone would just use C or assembler. Practically all software is I/O bound anyway so database queries are the real bottleneck. For tasks requiring raw speed there are ofcourse the possibility to use C routines from Python so even that is not a problem. What matters instead is the speed and ease of development and you just can't beat Python in it.
Numpy isn't pure python, is it?
No. A fair amount is written in C, but some is also written in Fortran. My understanding is most of scipy is actually written in Fortran and is just a wrapper around LAPACK.
The rule of thumb that I use is if you can take an arbitrary (but essentially complete) bit of functionality represented as a string in the language's natural syntax, `eval` it, and end up with something that integrates natively with the rest of the pre-written code, then it's a scripting language. This is probably the least rigorous definition imaginable, but it does encompass many languages that are viewed as "scripting" languages, such as Python, JavaScript, PHP, and Ruby, but exclude traditionally-viewed "non-scripting" languages such as C and Java^* . The fact that there is a separate pre-compile step to produce a "compiled" form (either as an intermediate "virtual machine" instruction set or an immediately executable hardware instruction set) doesn't enter into it at all. Any language implementable in such a way as to be run with an interpreter can (probably) be implemented with a pre-compile step, and vice versa. But I'll admit that I do tend to fall into the lazy thinking habit of "scripting languages" as "not compiled". \* - DOS batch might violate this because it makes a difference if you run some commands directly with `CMD /C ...` or save them to a file. Fucking. Microsoft.
Any maths. Not everything is I/O bound; specifically for data processing (eg. splunk) and scientific computing, python uses c heavily, because it's just too slow to be remotely usable otherwise. 
&gt; I use less windows, You need QtTabBar. You should have 1 explorer window (assuming you're using Windows).
I still draw the line when you're bringing in machine code into the Python process memory and it's not running bytecode loaded from pyc files. It's fast, but it's actual CPU instructions, not Python bytecode first. Of course it counts. Again, I'm not saying it's terrible, and that it shouldn't happen, or that it's a flaw. I'm just saying the fast parts aren't Python and I wish that the interpreter/VM implementation was fast enough so that we wouldn't need to use C code to have high performance programs. Any programming language could interface with C/fortran libraries and be high performance. It doesn't mean that that language's interpreter is fast though. I would like to see an implementation that uses purely the Python language and still be high performance.
I thought I deleted that first sentence. Thanks for pointing out. Fixed it now.
&gt; ...but then again, pypy isn't really production ready Where do you get that idea?
I'm in OP's shoes and want to get into a lower level language. The fact that Go is Google's language has me intrigued. I imagine with that kind of backing we could expect some pretty amazing libraries and a fast evolution into something widely adopted... is that presumptuous to assume? What do other veteran programmers think of the future of Go?
Yes, I use two monitors at work. The left is for the IDE/db and right for docs/browser/mail. 
* http://www.opsschool.org/en/latest/backups.html * https://en.wikipedia.org/wiki/Rsync#rsync_applications * https://github.com/kahun/awesome-sysadmin#backups * https://pypi.python.org/pypi?%3Aaction=search&amp;term=backup&amp;submit=search * https://github.com/bup/bup ... /r/sysadmin
There are pure OpenGL wrappers for Python. Here is the thing though, Mr. Hardcore graphics guy, if you're creating a game why recreate an engine unless you're building a high graphics AAA title and have millions of dollars and a team of hundreds of developers? Both Panda3D and Ogre are EXCELLENT game engines for most developers and have successfully been used in AAA titles. Torchlight for example is purely Ogre and CEGUI. If it's good enough for Runic Games, it's good enough for me. Source: I'm a guy who's actually been involved in the development of high end graphics engines. Python is fine for 99.9% of game development work. (The .1% being the top dogs, of course.)
Those occasional issues aren't related to Python.
Anyone who uses the term "Scripting Language" and isn't talking about shell scripting pretty much loses all credibility IMHO. It is a derogatory term derived from ignorance. 
Maybe it is my setup, but with python3 or python2.7 it's working also without the future import
&gt; most of scipy [...] is just a wrapper around LAPACK For dense linear algebra, yes. There's a lot of functionality in SciPy aside from dense linear algebra though. Some of the underlying libraries are Fortran, some are C, some features are custom C++. According to https://github.com/scipy/scipy the breakdown is 38.3% Python, 25.8% Fortran, 18.6% C, 17.1% C++.
&gt; I would like to see an implementation that uses purely the Python language and still be high performance. You already have that with PyPy. Unless you don't mind C extensions not working, what most people want in practice is a fast implementation that would be C-API compatible with CPython and extensions. Unfortunately that's extremely difficult as the C API is pretty closely tied to the slow internals of CPython. I suspect users aren't really all that picky about implementation language, but something easier to read and contribute to would be nice for maintainers' sake.
All of the above and more.
At least they're not complaining about how they'll "have to care about indentation". As if they'd ever get through code review without doing that anyways.
&gt; but exclude traditionally-viewed "non-scripting" languages such as C and Java* . This ignoring the fact that I can implement my own "eval" function in java with reflection and in C with a bastardization of the command pattern, so I find this to be a weak definition. Just because a language comes prepackaged with a function doesn't define what it should be used for. 
&gt; Can you do 3D graphics using Python? Yes. Should you? Probably not. I think this is the wrong question to ask. Right question is: Can you develop 3D software using Python? Yes. Should you? Absolutely! It does not mean everything has to be python. It means you can write logic in python and development will be blazing fast. Core stuff that requires performance can still be written in lower level language and that is cool. Everything has it's place in this world. Panda3D did just that. All low level stuff in c++, high level goodies in python, game logic can be done in python. Everything actually can be done in python. See deferred rendering pipeline with global illumination written in python (for panda3d) [here](https://github.com/tobspr/RenderPipeline). 
The key here is that I'm still writing pure python, but I'm utilizing someone elses C code. If you argue that's not enough python, then every use of linpack in other language should be disbarred. 
I've never really understood that whole category of complaint, really. I really do think less of someone who claims to be a programmer but gets caught up on such an introductory issue. You don't even care about indentation? Hey, maybe someone else should work on my business critical systems.
Is semantic web still a thing ?
Sorry, I meant windows in the generic UI sense. I'm a Linux user.
The suggestion even being that if the code was faster you could get more done on the same hardware.
Same with chrome.
The 2to3 program is really handy as well. I think if print statements weren't changed then the switchover would have been much more popular. I think a lot of people got scared when even Hello World had to be changed. 
Pyglet itself does not 'do' 3D in any meaningful sense of the term. The fact that you can use OpenGL with it makes it no different from using PyOpenGL with plain Python - you have to write all your own low-level code which is about 2 or 3 layers of abstraction below actually being productive.
I'm curious, how is Unicode-by-default _forwards_-incompatible?
Right, so what you're saying is that the original sentence I quoted is completely false from the point of view of an application developer. Which is fine. However, to say it "actually improves single-threaded performance" is only true if compared relative to a hypothetical alternative that had some other, slower way of operating, and which incurred costs even when there was no second thread running (which would be unusual). &gt; Honestly, I think that the real issue is that the Python developers even attempted threading at all. Shared state threading in a dynamic programming language is simply a recipe for disaster. Message-passing parallelism wasn't really a popular idea in Python's early years. There are a lot of application domains where some degree of shared state across multiple threads is important. Games and simulations are two of them, for example. Whether those are suitable problems for Python or not is another matter, but some people don't like to admit these domains exist at all.
Have you installed ffmpeg and imagemagick as explained [here](http://zulko.github.io/moviepy/install.html) ?
&gt; For OP's benefit, even, what, three-ish years ago a lot of major packages didn't support Python 3, right? I think even a few months ago the [Python 3 Wall of ~~Shame~~ Superpowers](http://python3wos.appspot.com/) was mostly red.
&gt; What kind of examples could you give of Python's slowness causing great problems in real-life applications? &gt; &gt; &gt; Raw execution speed doesn't matter much any more actually (like in the 90's). Simply not true. There are various areas where speed is still important - video games, simulation, scientific data crunching, artificial intelligence and machine learning. In some of these cases, Python turns out to be fast enough. In other cases, it does not. The last performance problem I had with Python was implementing planning/pathfinding algorithms. Python's requirement to allocate everything on the heap via pointers meant that exploring a large search space was very expensive, in terms of allocation costs and cache misses. That could have been mitigated if I could have offloaded it into a background thread, but Python's poor at that too.
compared to developer time, hardware is cheap. 
You've come in too early, we're not talking about developer time yet.
Four.
oh, sorry. ill see myself out then.
&gt; Right, so what you're saying is that the original sentence I quoted is completely false from the point of view of an application developer. Which is fine. It's completely true from an application developer's POV as well if that application developer does almost only IO and very little CPU-bound stuff.
&gt;I will be glad when Pythonic ideas finally dominate the industry and filter into other languages And what ideas would those be? Python got its best stuff from languages like Lisp that existed decades prior. I agree that it will be nice to see higher level ideas filter into the mainstream but to call them "Pythonic" is bizarre.
Why? Presumably you're talking about the situation where the GIL can be released for calls into external C libraries. But this itself is a workaround for Python's benefit, not for the extension developer. In a C/C++ app (for example), as soon as you make the so-called "blocking" I/O call that thread is suspended (pending a callback from the OS) and your other threads are immediately free to run on that processor with no further intervention from you. The difference with Python is that you have to explicitly tell it that this thread is going to leave the rest of the interpreter alone, so that it is capable of switching to the other threads! 
Hi, I've been testing this for an hour now and I have some remarks / questions. Here are some weird behaviors I found : import time time.sleep(1) print "foobar" does't print anything. import time print "foobar" time.sleep(1) doesn't print anything either. I first thought that it was not returning any output when the script was taking too much time but then I tried : for i in xrange(1000000000): print i and it does print i until 78000ish. I also tried threads and they don't seem to work (same behavior as the time.sleep, I get no output). I made a python script that makes it possible to execute python code in PyStub straight from the command line : https://gist.github.com/volnt/3289d5574cd3be7de769 `pystub.py -v`, reads from stdin and sends the code when you hit `Ctrl+D` `pystub.py path/file.py -v`, reads from path/file.py and sends the code If you don't specify the `-v` you will only see the status code of the request otherwise it pretty print the response. With no limitation I think it's possible to execute a python script that will call your /run/ API to execute itself, this way it should be possible to create an army of endless running process. I have not tried it yet but I wonder if you have some protections against this ? It should also be possible to use the same kind of trick to fill your hard drive / s3 bucket.
&gt; Why? Presumably you're talking about the situation where the GIL can be released for calls into external C libraries. No, I'm talking about the inability to execute python in multiple threads at the same time leading to lowered chances of races due to the GIL, even if the developer is somewhat sloppy. Heavy IO means this isn't going to lower the overall throughput much so there's little drawback to it. Heavy CPU use means there's a high drawback instead.
there are compilers to c code available also. they improve speed a lot. nuitka for example
ehh. how about bytes and unicode
Ooh, maybe They can change Unicode handling by then.
So, this restriction somehow makes it "easier to use OS threads" by (a) forcing people to write in a second language to access them effectively, and (b) limiting what they can do with them once they do that. That's not really a definition of "easier to use" I accept.
&gt; even attempted threading at all Hey, worksforme. Not that I often prefer to use it, but nevertheless.
&gt; Where do you get that idea? http://pypy.org/compat.html
No. They're not "easier". No code you write becomes shorter. It's not even clear that Python will prevent you wrongly accessing the interpreter from your C extension if you call the C API after having released the GIL. Nor does it prevent race conditions that arise from assuming values won't have changed while the GIL was released. I'm seeing zero benefit here and several burdens.
No one here is going to do your homework for you.
I don't see how not at all competent programmers are going to be any more comfortable with curly braces and semicolons, though. Whichever one you use, it's firmly in my suck it up if you want to tell the computer to do things pile. If you don't care about curly braces the compiler throws a tantrum, if you don't care about indentation the interpreter throws a tantrum. Pick your poison, really. What I don't understand is the whole category of complaint, not which one is better. Come to think of it, even in semi colon based languages, truly not caring about indentation *at all* means your work likely gets tossed at code review because it's probably unreadably inconsistent.
&gt; There was an effort by a developer to remove the GIL and make the CPython interpreter thread-safe. The end result was a substantial decrease in single-threaded performance, even when no other threads were running. And that is arguably a flaw in the way Python works. It guarantees the integrity of the interpreter across threads, at a price. And that price doesn't even buy you guaranteed thread safety for your own code, sadly. Other languages take a different approach, where the burden of safety is put more on the developer. If you want multiple threads, you have to coordinate access yourself, but usually each thread has its own interpreter that doesn't need to be shared and therefore requires no global lock. How much does the 'dynamic' nature make it hard to isolate code from data and allocate one interpreter per thread, leaving all locking to the application developer? I don't know. It doesn't seem to be a problem for other VM-hosted languages, but does seem to be a problem for older languages that are designed for embedding and extending (eg. Javascript, Lua).
Almost exclusively, I'm sure. I have yet to encounter a web or distributed system that wasn't bottlenecked on I/O.
There seems to be an issue with the commas and periods on that page. It gets confusing.
In fact, I'm not sure what it would look like, really. Maybe something like an online zip file password cracker: one upload followed by intense computing followed by one download
You might have better luck over at /r/learnpython To get you started: 1. Get a directory listing of the directory that's going to be the servers home directory 2. Find a way to write a file to the response If you want to be able to serve different files you can extend the functionality: 3. Parse the GET request to get the name of the requested file 4. Look for the file in the directory and return the correct file
Repost in /r/learnpython We still won't do your homework for you, but if you ask a clear question (e.g. "How do I get my webserver to create index.html?"), instead of just "i need help! Can you figure this out for me?", we'll help. Clear qustions are much more pleasant to answer, because it shows you've put in some good effort.
I like using a single screen only. Most of my work is centered around writing non-gui related code. But, when I have developed guis, having a second monitor was helpful.
&gt; And that is arguably a flaw in the way Python works. It guarantees the integrity of the interpreter across threads, at a price. And that price doesn't even buy you guaranteed thread safety for your own code, sadly. &gt; Other languages take a different approach, where the burden of safety is put more on the developer. If you want multiple threads, you have to coordinate access yourself, but usually each thread has its own interpreter that doesn't need to be shared and therefore requires no global lock. For sure. Many of these decisions revolve around keeping the implementation simple. There's something to be said for that, I suppose.
That's just saying that the C API isn't production ready, and not all libraries are supported. If you target your development at Pypy it's production ready.
They call that [Duck debugging](http://en.wikipedia.org/wiki/Rubber_duck_debugging).
I have discovered this from the python myth thread this morning. So far: * it's in ubuntu's repos * it's compiled all my simple benchmark scripts * faster than pypy (no heavy IO script yet) 
By that criterion, Lisp is a scripting language. (Well, the parse from string and eval are separate steps, IIRC, but...)
Did you consider Nuitka?
This reminds me a lot of Paul Graham's famous article on how Lisp was the secret weapon of Viaweb. http://www.paulgraham.com/avg.html I have no particular difficulty believing Python is PayPal's secret weapon. I have done a fair bit of scripting in Python, and have found that Python code does what I expect the very first time, more so than any language I've ever used. Compared to Python, coding in JavaScript or (shudder) VBScript is like walking uphill through 6-foot deep snow both ways. Except if Python really is PayPal's secret weapon, they shouldn't have written this article, 'cause now it's not so secret anymore.
What about the pypy compatibility test suite (which I assume exists)?
If you're going to fork Cloudbot (which is pretty obvious, because I ([blha303](https://keybase.io/blha303)) wrote [this plugin](https://github.com/MikeRixWolfe/Gary/commit/159f3bd44d3d1b737c0569731583de0e45aeff64#diff-dc15544b3f99f7a8c0d70dfe9134da4aR1) [[proof](https://github.com/ClouDev/CloudBot/blob/develop/plugins/plpaste.py)]), why not just use that handy Fork button in the top right? It keeps attribution going to the right people (not a requirement of GPL, I know, but it's a courtesy) and there's nothing wrong with using someone else's code base. Also I know this is an old thread but I just thought I'd say something. Seeing as you're talking about your http library in your other comment and a lot of util/http.py looks preeeeeeeetty familiar, as someone that looks at Cloudbot more than once a week. edit: You've added attribution while I was writing this comment, thanks. Forking is easier for keeping commit history though. :P
but it wouldn't integrate natively with the rest of the pre-written code. For example, if I create a method and call it like `MagicScript.createClass("public class Animal {}");`, I cannot in the pre-written code do `new Animal()`. You would have to go through an entirely different process to make use of your new class.
Lisp is unique in a lot of ways. Wasn't it the first to implement a lot of concepts that are being rediscovered in modern languages?
When ever I ask it for a plot, if the plot ever shows up it takes upwards of 5 minutes for plots with no more than 10 data points. The data processing itself goes rather quickly, but getting graphical display out of it seems to be very slow. (The thing that seems to take the time is the rendering of the axis labels given that I have to use latex to do so) I do agree though that it is far faster and easier to set up than anything else I have seen and is actually a pretty decent IDE. 
Faster than PyPy for what? Did you give PyPy enough time to JIT the hot spots? Not that Nuitka isn't impressive, but PyPy is **REALLY** fast at stuff that it has time to properly profile and optimize.
Python 3 is usable and production-ready, and has been for nearly 6 years. For fuck's sake. 
Found using this query http://data.stackexchange.com/stackoverflow/query/86088/most-viewed-top-100-questions-in-a-tag
One big one. Switching virtual desktops is faster than turning my head to look at a physical screen. And yes I've tried a dual-monitor setup. You can have a second monitor for something like your music and your irc window or widgets - things you glance at once in a while, but for actually working its worse. If you feel that virtual desktops are not as fast as looking at a second screen try need a faster window manager. Anyone here that codes a lot, especially web stuff, try Xmonad. Having a split screen with a browser and your editor and not having to take your hands off the keyboard for anything (especially if you use Vim) as well as instant desktop switching saves me lots of time.
Does this allow you to take an arbitrary python script and compile it to a .exe for Windows? I tried messing around with it before and didn't get anywhere. 
It breaks code that was thought to be right that was written wrong. If it was written with knowing that unicode was going to be the required style it would be fine. Unicode wasn't encouraged during Python 3. 3 -&gt; 2 is easy. 2 -&gt; 3 (without six) is hard because you need to learn unicode.
Please don't code this way...
Pretty much. Python's `map`, `reduce`, and `filter` are lifted directly from Lisp. It also has an `apply` function, although this has been deprecated since the introduction of the `*args` syntax.
Can you explain a little more what it means to "do" 3D? I've written a few 3D games in PyOpenGL and it didn't really feel to me like I had a bunch of abstraction layers in the middle. But maybe I just don't know what I'm missing.
 def is_valid_file(fpath): if os.path.isfile(fpath): if fpath.endswith(".html"): if fpath not in exclusions: return True That should be one 'if' statment: if fpath not in exclusions and fpath.endswith(".html") and os.path.isfile(fpath): And using the string comparisons before the isfile should short-circuit things a bit (i.e. resolve the if faster).
Don't forget kivy. My love goes to pyglet but there's only one person maintaining it and kivy is a damn nice alternative. Hold strong, Pyglet!
mod_python has long been depreciated, mostly in favor of mod_wsgi.