Oh sorry to hear to hear that. I feel like people here at rPython are pretty nice :)
You've ignored the 14,700 entries in my username on the bug tracker. There are at least three versions of Python written in C, Java and .net. I notice you still haven't answered the question I've posed three times about "how can Python have pointers when the languages it's written in don't have pointers?" So for the final time you complete bozo, your comments about pointers are **COMPLETELY IRRELEVANT**, Python **DOES NOT** have them. The next thing I know you'll start banging on about how does Python pass data into function calls, by reference or by value? The answer is neither, it's pass by object as that is all Python knows about. Got it yet? Or are you yet another brain dead troll with nothing better to do than waste lots of peoples' time with your complete and utter crap.
Glad to have helped! I'm an opinionated nerd, but I try not to be mean :) The internet is a weird place where you can argue all day if you want to. 
What is so "bad" about tkinter that would make you think the OP shouldn't use it for his or her task? I can see its advantages: * Comes with Python * Uses native widgets (if you use ttk) * Lightweight * Stable PyQt definitely has its own advantages (like QtDesigner, more widgets, etc) but surely tkinter can accomplish what the OP wants.
My god man, you have issues. So, in your twisted little world C does not have pointers? Also, no, core python has no java or .net. There are python implementations in java, but it is not core python. What is wrong with you?
fuck off with your stupid click bait title 
YES this helped a lot, I now realized I need to use .all() so that both of the things I am asking to find true must be true for it to work correctly. .any() was providing false positives essentially 
This was published about 3 years ago, in case anyone didn't notice.
when I do that cmd gives me the error: 'python' is not recognized as an internal or external command, operable program or batch file.
OP has a very good point ... out of all the operators, `**` and `pow()` is the only one that has a operator AND a built-in function. Why is this repeated? Operator | Meaning | Function | Built-in? ---|---|----|---- + | Add | operator.add() | No - | Subtract | operator.sub() | No * | Multiply | operator.mul() | No / | Division | operator.div() | No // | Floor Division | operator.floordiv() | No % | Modulus | operator.mod() | No - | Negate | operator.neg() | No + | Unchanged | operator.pos() | No ** | Power | pow() | Yes &lt; | Less Than | operator.lt() | No &lt;= | Less Than or Equal | operator.le() | No &gt; | Greater Than | operator.gt() | No &gt;= | Greater Than or Equal | operator.ge() | No == | Equal To | operator.eq() | No != | Not Equal To | operator.ne() | No is | Identity | operator.is_() | No is not | Negated Identity | operator.is_not() | No or | Logical OR | ? | No and | Logical AND | ? | No not | Logical NOT | ? | No ¦ | Bitwise OR | operator.or_() | No &amp; | Bitwise AND | operator.and_() | No ~ | Bitwise Inversion | ? | No ^ | Bitwise XOR | operator.xor() | No &lt;&lt; | Bitwise left shift | operator.lshift() | No &gt;&gt; | Bitwise right shift | operator.rshift() | No 
So you've never installed python on your computer?
I'm sure it's just an accident of history. They happen.
What about mixing the sentence markov chain with information on how comments influence response word choice? 
Same context, different question: how are the standard *libraries* picked? Like, urrlib is builtin, but requests isn't.
"Click here to learn the secrets of fucking off that doctors are raving about!"
&gt;It seems to be doing the second system call in a different environment than my module load call. Yes. Each call will be done in its own environment. Just string the two commands together with &amp;&amp;: ```os.system('module load SIMULATE &amp;&amp; SIMULATE input.in ...')```
&gt;Just string the two commands together with &amp;&amp;: That's a good idea. Not ideal though....
Why do you think its looking for a .mod file?
Ah, so python isn't in your PATH (This won't help with your modules question but its useful). I'm remembering this from Windows Vista/XP so this might not be totally accurate but Right-click on 'My Computer', 'Properties', Rightmost-tab I think, find 'Environment Variables', should be a 'PATH' one, and add wherever the python executable is in your C:\Python27 folder. [See here](http://stackoverflow.com/questions/3701646/how-to-add-to-the-pythonpath-in-windows-7) for more on that. Now as for your original problem you said you tried dropping the pyserial .py files into a maya folder and it didn't work. Were you trying the locations listed [here](http://knowledge.autodesk.com/support/maya/learn-explore/caas/CloudHelp/cloudhelp/2015/ENU/Maya/files/Environment-Variables-File-path-variables-htm.html#PYTHONPATH) under PYTHONPATH?
It is commonly called [Short-circuit evaluation](http://rosettacode.org/wiki/Short-circuit_evaluation). The Rosetta Code task of the link demonstrates it in around 70 languages including Python.
"A single mom found this one weird trick to piss everyone on the internet off"
That was it! Thank you!
I'd recommend using Fabric library for these type of remote commands. It's much much easier.
SURPRISE! I wrote something here :) http://migrateup.com/whats-really-new-in-python-3/
&gt; Python the language is implemented in several different languages Again, your ignorance is showing. As i said before, yes there are python implementations in other languages, but CORE python is C/C++. I find your claims of contributing to python preposterous. Also, you are the real troll here. Im done with you.
'A presentation about Music Theory, Genetic Algorithms and Python by Nicholas Tollervey' I'd say the title of the presentation itself is a good starting point.
[hum](http://bugs.python.org/issue?%40search_text=&amp;ignore=file%3Acontent&amp;title=&amp;%40columns=title&amp;id=&amp;%40columns=id&amp;stage=&amp;creation=&amp;creator=&amp;activity=&amp;%40columns=activity&amp;%40sort=activity&amp;actor=&amp;nosy=BreamoreBoy&amp;type=&amp;components=&amp;versions=&amp;dependencies=&amp;assignee=&amp;keywords=&amp;priority=&amp;status=1&amp;%40columns=status&amp;resolution=&amp;nosy_count=&amp;message_count=&amp;%40group=&amp;%40pagesize=100&amp;%40startwith=0&amp;%40queryname=&amp;%40old-queryname=&amp;%40action=search)
It is a given that Python people seem to be far more tolerant of newbies than other programming languages. Could that be a major part of the success of the language?
I'm also opinionated, and a pseudo nerd, and if you disagree, I bet that my dad is bigger than your dad!!!
I just don't understand the issue with the current one. Your title and OP's title give away the same amount of information. OP shows that it's about music theory and python and it's interesting. Your's says it's about music theory, genetic algorithms and python. 
Shit... I just scrolled up to see the original context for the quote. 
It did amaze me, thus it's accurate. 
Please explain what is wrong with the link that I've provided. But of course anybody who attended the Dr Goebbels School of Programming wouldn't be able to answer any question. Not that it matters, I'm in no hurry to get to bed, you've been shown to be a complete idiot by constantly coming back, but hey, ho, such is life. If we, the Python community, wait for long enough, you might actually provide us with some facts. Strangely enough I have no expectations of seeing any such thing. Oh, before I forget, did you find a reference to pointers in the Python language index? No of course not not, I think you're a sleeper from PHP or Perl trying to undermine Python. Well awfully sorry me old son, but you're not fooling anybody. Have a nice day :)
Well, you just need to run it. But I assume you're asking how to get it to keep running even when you turn your PC off? You need to purchase hosting from somewhere (I've seen DigitalOcean highly recommended) and then put the code for the bot there and figure out how to run the bot even after you log off the remote machine.
This looks cool. Thanks for writing it. :)
```find / -name 'alembic'```
Assuming your code is indented like this: import turtle t = turtle.Pen() for x in range(100) t.forward(x) t.left(90) Then you're missing a `:` - Line 3 should be ```for x in range(100):```
The sqlite3 module in the standard library was based a pyqlite release and first introduced into Python 2.5. Since then, fixes and features have been ported between the two libraries back and forth. The externally maintained pysqlite, however, is not constrained by Python's release schedule, and can thus move a lot faster.
hmm. In my quick testing, I think that works ok. I thought that maybe those modules would't be accessible from the `os.system` but I think it may be fine. It seems like if I do: bash script (incl. `module load ...`) --&gt; python script --&gt; `os.system(...)` it works. I guess this is fine then!
And a cracking bit of kit it is as well!!! Thanks for your efforts :-)
Use the path Luke.
I don't need to guess, I know. What I don't understand is where the newbies get their data from about writing for loops, as I've never, ever, in 15 years of using Python seen the frowned upon construct used in a tutorial. Anybody?
That worked great! Everything works perfectly now. Thanks!
Not good advice on a system running multiple versions of Python. I've 2.6, 2.7, 3.3 and 3.4. Which one wins on my system? Which one wins on another system? Using the pip executable with the version number embedded is the way to go.
Better IMHO to go to [Using Python on Windows](https://docs.python.org/2/using/windows.html).
Or Ansible.
You could also call sys.stdout.flush() or sys.stderr.flush() at times, to manually flush the output at intervals. And as for running stuff on target servers, salt/salt-ssh can do that automatically. And you could even avoid running raw commands over ssh.
You're likely getting down voted because all Python questions are supposed to be posted at /r/learnpython
Is there a web browser on the RP? Maybe you could use that in kiosk mode.
You can write a function that applies a list of replacements: &gt;&gt;&gt; replacements = ((':', ' '), ('@', ' '), ('***', '___')) &gt;&gt;&gt; def apply_replacements(text, replacements): ... for old, new in replacements: ... text = text.replace(old, new) ... return text ... &gt;&gt;&gt; apply_replacements(':::::::::::|_|_|:::::|@|::::::|@|:::::/***\:::::::::::', replacements) ' |_|_| | | | | /___\\ ' But it's not fundamentally any different than what you're already doing. It just separates the list of what to change from the part that does the action, so it would be appropriate if you had a long list of various replacements to make, or if you wanted to store the replacements list as a configuration option or something, or if the list of replacements was built dynamically based on runtime information. But if you're always going to be doing just these three replacements, then you're not going to find anything simpler than what you have already. 
Awesome. Glad to help!
Is that how we talk to each other here? I thought the Python community was much more friendly than that. WWGD (What Would Guido Do)?
in your particular case, you can use the translate function: import string myString = ':::::::::::|_|_|:::::|@|::::::|@|:::::/***\:::::::::::' myTrans = string.maketrans(':@*', ' _') myString.translate(myTrans) &gt;&gt;&gt; ' |_|_| | | | | /___\\ ' Edit: The backslash thing is because backslashes have a special interpretation in the string. Python escapes literal backslashes (with another backslash). It should look ok when you use print(). 
If you are doing this for your own learning exercise, then ignore this comment. There are a couple flight aggragators already where you can get price alerts and they probably have access to more data than you will get. Google flights and Hipmunk are 2 that I can think of right now.
Turns out I meant the digital root, but they are related concepts anyway. Digit sum is exactly what it sounds like: take all the individual digits of the number and add them up. Digital root is keep doing to each successive result until you have one digit left. You could write it more verbosely in Python as: def digital_root(num): root = num while len(str(root)) &gt; 1: root = sum(int(digit) for digit in str(root)) return root It is provable that each digit sum has the same remainder when divided by 9 as the original number (they are said to be "congruent modulo 9"), which means the final result must *be* that remainder (the only way two single digit numbers can be congruent mod 9 is if they are equal). *Except* for exact multiples of 9 - eg, 18 mod 9 (spelled `18 % 9` in Python) is 0, where we want 1+8 = 9. So we want "the result is the number mod 9 if that is non-zero, otherwise the result is 9" which in Python is `n % 9 or 9`.
edit: Sorry if the title was a clickbait! It was 2 am and I was groggy and couldn't think properly.
My bad - I meant the [digital root](https://en.wikipedia.org/wiki/Digital_root), not the digit sum. I've corrected my original comment. The digital root is the same as the digit sum, except you keep reapplying it to the result until you're left with a single digit number.
When I first started, reading the Django codebase was very helpful. I've since started to mirror my projects close to that. There is some info on how to structure your code here: http://docs.openstack.org/developer/hacking/
Withdrawn! :)
This answer is a non sequitur. 
I got a working version of the Steamworks For Python. Previously there were issues with the Windows version not compiling but that has been solved. Was hoping some people could test this out on other machines to see if it works as well as it does on mine.
How did you make this web page? 
Very nice! Always good to have a Python lib. I will check it out this weekend
I taight myself from some website and have been using it that way as I have limited python knowledge.
What does the pass do in this situation? Any way you can add another line or two of code so I can dully see how it work out. Your help is greatly appreciated!
You had used `pass` in your post, so I figured you knew what it did, but on second look I see you're using it wrong :) `pass` is what people call a NOP -- no operation. It's used in scenarios where you *have* to put some code but don't want to do anything. The equivalent in other languages is an empty pair of braces: if(someCondition) { } but since Python doesn't use braces, and leaving an empty line isn't valid (the · is a space): if some_condition: ···· # illegal, there's nothing here! else: ····other_func() you need some sort of keyword that acts as a statement but does nothing: if some_condition: ····pass else: ····other_func() It is most often used to define a function that does nothing: def lazy_func(self): pass As for the above, try pasting the following into a script: arr = [1, 2, 3] print "With range:" for i in range(0, len(arr): v = arr[i] print v print "Iterate through object:" for v in arr: print v Both should print the exact same thing. The key point is that you don't *need* `i`, the index. Its only use is to tell you how to get the `i`th element from `arr`, but Python lets you reach directly into `arr` with its for loop already so you can skip the part where you generate a list of indexes.
Eh. Sort of. Being inverses doesn't mean that they're the same complexity/difficulty. Crypto would break if finding an inverse was as easy as the original function. 
Probably people coming from a C language where that's the standard idiom for looping through an array. I know that was most familiar to me when I started Python after coming from Java and C++.
Great book @yasoob. I am learning a lot from every chapter. This book is must read for everyone who wants to (quickly) transition his basic python skills to a new level. 
I chuckled at the curly brace in the top picture.
You still haven't answered any of my questions. Do you have a problem with any of them? If no you are telling porkies, if yes why don't you enlighten yourself by asking a question yourself but on the main Python mailing list. I'm looking forward to seeing you get cut to pieces by other people such as myself who actually know what they're talking about. The second time that you're done, three strikes and you're out?
I would love to see some real world examples of this. Why would I want this? It looks awesome!
&gt; The core devs were pushing 3 and most users were pushing back saying that package support just wasn't there. That's pretty much as far away from how the Python 3 migration actually went as it is possible to go without telling outright lies. The core devs never pushed Python 3, they have always said that it will be a ten year (or more) transition plan.
The AGPL is crazy restrictive wrt. releasing source though.
That indeed looks awesome and the interactive visualizer is really cool. However I wonder how hard it is to extend to other languages? Because from what I see, it is heavily geared towards English
It will simply try to create a [IPython widgets progressbar](https://github.com/ipython/ipywidgets/blob/master/ipywidgets/widgets/widget_float.py#L130) and will create a [`click.progressbar`](http://click.pocoo.org/5/api/#click.progressbar) if that fails. It could be extended in several ways, e.g. supporting more parameters or the undocumented methods of `click.progressbar`, but as of now it’s already very useful if you just want a piece of code to show a useful progressbar wherever it is run.
Check polyglot-nlp.com for another nlp project, that is multilingual.
&gt; I assume if you don't mind complying with the AGPL (afaik giving everyone who interacts with you code via api/browser the source) then you can use it in production no problem. but my product could be commercial also right? It says: &gt; Researcher, hobbyist, or open-source developer? spaCy also offers AGPLv3 licenses. and in Spacy License: &gt; spaCy is commercial open-source software: you can buy a commercial license, or you can use it under the AGPL, as described below. So, as long as my product is AGPL, be it commercial or not, I can use SpaCy? Thanks for replying.
&gt; check if some of the IP's listed there belong to some of my ranges 1. What do you mean by "my ranges" ? 2. If you have a network range, you can use the [ipaddress](https://docs.python.org/3/library/ipaddress.html#module-ipaddress) module (standard python lib) to check if IPs are in this range 3. Parse the HTML page to extract the IPs (or use a regex, but I consider learning how to parse HTML a better option) Technically, everything you want to do can be done using [standard python modules](https://docs.python.org/3/py-modindex.html) (urrlib + ipaddress + [html.parser](https://docs.python.org/3/library/html.parser.html#module-html.parser) ). But using Requests is a good idea (simple API).
Start with python 3, it is the future of python. https://wiki.python.org/moin/BeginnersGuide/NonProgrammers
thanks for posting the link though at such late hours! made my day
I can't believe I never came across this project before. It looks very nice, I definitely will try it out. Thanks for the link!
Those books look promising, I will check them out.
Check out /r/learnpython's [wiki](https://www.reddit.com/r/learnpython/wiki/index). Program Arcade Games with Python and Pygame is fun.
The official line is that 2.x will not be supported past year 2020. There will be no new features added to 2.x. If you want 2.x with new features, it's called 3.x.
Some things can't be Python, like the software that runs the microcontroller for the printer or the HTML and CSS that style the interface. And some thing's wouldn't be nice in Python, like most SQL queries and Bash scripts.
Not that I know of.
log() is not built-in cause there's no operator for it. Why is there no log operator? Cause it's advanced maths 5 year olds don't need to know.
As other have mentioned above, 2.8 will never be released. For proof: [Pep 0404](https://www.python.org/dev/peps/pep-0404/)
Arguably, Python 3 is already the "present". But it's, no questions asked, definitely the future. Python 2 will be Windows XPed (unsupported) in 2020. [Dive Into Python 3](http://diveintopython3.net/) is a good (free) resource. If you don't mind paying, then I'd also recommend [Python Programming for the Absolute Beginner](http://www.amazon.com/Python-Programming-Absolute-Beginner-3rd/dp/1435455002/ref=sr_1_1?ie=UTF8&amp;qid=1440076325&amp;sr=8-1&amp;keywords=python+for+the+absolute+beginner) as it has a more tutorial approach of building simple games.
&gt; Libnotify is part of GTK It uses GIO and GObject but nothing of GTK. Its only runtime dependency is gdk-pixbuf2 for image loading.
They renamed the Wall of Shame as the Wall of Superpowers? How auspicious...
Where does it save it to if I install it with pip?
I see, thanks for clarifying. I've always gotten a bit mixed up between Gtk, Gdk, and GObject. So it does use GNOME libraries but not the Gnome Toolkit libs.
Correct. Okay, so if I use pip install for any package, it'll be accessible no matter where I execute my python script?
Super helpful! Thank you so much!
/u/ztgu updated it for you! -def swap(A, i, j): - A[i], A[j] = A[j], A[i] +def swap(array, i, j): + tmp = array[i] + array[i] = array[j] + array[j] = tmp It's not one line anymore! 
You're welcome. Also, if you use IPython Notebook, you can click on the `File` menu, choose `Download as` and select `HTML (.html)`.
Open a Python terminal, type: import this press enter. 
Dude awesome :) Learning alot from this and all other suggestions. However I'm using Python 2.7 so I can't use the ipaddress module unless I download a backport. I know there's a module ipaddr for python27 but this one doesn't have the attributes like ip_address. Can you help me out some more? :) THANKS! EDIT: IT'S IPNetwork in python 2.7
I think your point might have been correct in 2013. But at this point almost every major library supports Python 3, and writing code is simply better in python 3. For example, take multi-processing via futures. It was backported to python2, but the traceback is broken in python2, and works fine in python3. So, since python3 is the future, it's where the best language elements &amp; features are, and all the libraries are either there are will be there soon - my codebase is all moving over. And I know more &amp; more people doing the same thing. I think we've hit the tipping point.
Borrowed a snippet of code from StackOverflow ([http://stackoverflow.com/questions/819355/how-can-i-check-if-an-ip-is-in-a-network-in-python](http://stackoverflow.com/questions/819355/how-can-i-check-if-an-ip-is-in-a-network-in-python)) to replace the ipaddress library. Replaced the 3.4 requests module with urllib2. Tested and runs in 2.7: import bs4 import urllib2 import socket import struct TOR_URL = r'http://torstatus.blutmagie.de/index.php?SR=Hostname&amp;SO=Asc' LIST_OF_YOUR_IP_RANGES = [ '83.128.41.0/16', '85.21.168.0/16' ] def address_in_network(ip,net): ipaddr = struct.unpack('L',socket.inet_aton(ip))[0] netaddr,bits = net.split('/') netmask = struct.unpack('L',socket.inet_aton(netaddr))[0] &amp; ((2L&lt;&lt;int(bits)-1) - 1) return ipaddr &amp; netmask == netmask html_content = urllib2.urlopen(TOR_URL).read() soup = bs4.BeautifulSoup(html_content, 'lxml', from_encoding='iso-8859-1') records = soup.find_all('td', class_='iT') tor_ip_addresses = ((rec.text[rec.text.find('[')+1:rec.text.find(']')]) for rec in records) tor_ips_in_your_ranges = set() for tor_ip in tor_ip_addresses: for ip_network in LIST_OF_YOUR_IP_RANGES: if address_in_network(tor_ip, ip_network): tor_ips_in_your_ranges.add(tor_ip) continue for tor_ip_in_range in tor_ips_in_your_ranges: print('%s is in range' % tor_ip_in_range)
Thank you for this. Good start
Awesome thank you XiAxis, appreciate it
Why do people add these pop ups.. I leave immediately and will never come back 
Another useful paradigm to take on is to make your programs *modular*. This not only involves implementing your code within functions, but also ensuring that each function **does one thing and does it well**. In the same spirit, function names should be concise and clear as to the task they serve.
I like to do things I would actually want to do in real life instead of exercises.. I started coding to fix problems, not to do theoretical exercises. Take one of those lists like "greatest albums of the 90s" or whatever and use Spotify's API to automatically add all of them to a playlist. Try scraping the pages that are showing that list instead of just copy and pasting it into your script. [Build your own API with Flask](http://blog.miguelgrinberg.com/post/designing-a-restful-api-with-python-and-flask) and have it do things like aggregate all your log files into one place. Take the output of one of the endpoints you created and render it to HTML for a web app/dashboard. Grab a Smartthings or Wink or Vera hub or whatever and get into some home automation. 
BTW: second episode up. [pytest vs unittest vs nose](http://pythontesting.net/podcast/pytest-vs-unittest-vs-nose-pt002/)
You're right. Forgot about /r/learnpython. I'll post this there.
Why the unpythonic function call to get the colour? I'd write `redcars = [car for car in cars if car.paint == 'red']`
Oh, okay. Thanks for clarifying it. I thought it did this, but I wasn't sure, so I thought I'd ask.
Probably one of the best answer's I've heard. Thank you thelastknowgod
Sorry to hijack this thread but saves me making another. I'm proficient at c and c++, but just starting a project in. My question is can anyone recommend a book or reference source for python for someone with programming experience but new to python?
This is **NOT** a bug, the behaviour is quite clearly documented at [timedelta objects](https://docs.python.org/3/library/datetime.html#timedelta-objects).
Dive Into Python.
Don't forget about how janky working with dates/times can be: http://infiniteundo.com/post/25326999628/falsehoods-programmers-believe-about-time
The only issue I had with Tweepy is that it does some processing on updates/tweets that prevent you from being able to send Unicode characters properly. I had to switch to an entirely different library to get around that. Otherwise, Tweepy is probably the most user-friendly library.
Use total_seconds(), Mr. *I don't read the fucking documentation*! 
The readme could use a section with links to examples, use-cases, tutorials etc. 
I'm glad you got a quick reply at r/learnpython. I felt obligated to offer a solution there, since i gave a non-solution here. But my kludge was so bad, that I'm glad others spoke up.
Thanks lad, didn't expect it to be free aswell! 
First, I think you need a higher frame rate, your blobs are pretty big/not precise. Secondly I worked on something similar a long time ago and I used a threshold to make sure I would always find my blobs, I hope it can help: #####THRESHOLD THE FRAME##### # Define range of interest in HLS (hue, light, saturation) hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HLS) lower_limit = np.array([0,tresh,0]) #tresh is defined in data at the beginning, I used 70 upper_limit = np.array([255,255,255]) #mask is the name of the thresholded video mask = cv2.inRange(hsv, lower_limit, upper_limit) # cv2.imshow('mask',mask) #####THRESHOLD THE FRAME##### 
Good link. Wish I'd had that when I began all those years ago...
Sorry, didn't see that you replied to my comment before deletion. I'd do this class Test(object): translate_dict = {} def __init__(self, x): self.x = x def translate(self): for is_first_attempt in True, False: try: return translate_dict[ self.x ] except KeyError: if not is_first_attempt: raise else: Test.translate_dict.update( json.load( open("/dir/file_{}.json".format(self.x), 'rb') ) )
Is it possible your blob color of 255 is overly stringent? It doesn't seem as though you are thresholding the image before you do blob detection. As a caveat I've used similar (but not openCV) functionality in scipy.ndimage.label and skimage.measure.regionprops.
&gt; propellers are scary because they're like blenders for people I busted up laughing at work. Now everyone knows I'm on reddit. 
This is pretty cool. You could do all kinds of stuff with this. Not just logging data, but triggering other things, sending notifications/reminders, etc...
Maybe it's because I casually like listening to music this but I guessed right on which ones were Python every time, quite easily. There's a sense in the melody, a little bit like a story in the human ones whereas the other just doesn't sound bad.
To eliminate urls, maybe a regex?
Yeah. I'm thinking I'm going to get some of these to track rabbit feedings, waterings, and toilet changes. My wife and I operate on different schedules, so often I wake up not sure if she fed them or not. This will mean I know for sure.
Out of curiosity, how does someone keep the program running? (I would guess some fashion of while True)
That's insane. You use the fucking interpreter or path to the one you want so you avoid name clashes in the fucking path. This is a constant issue on Linux and BSD and why we have a FUCKING MAKE ALTINSTALL target to avoid overwriting /usr/local/bin/pip. But does everyone use that? No! Specifying the interpreter, either by full path to it or referring to it like 'python3.3', works in ALL deployments. "Not good advice" -- Fuck you! Antipattern asshole. Gods I am so fucking pissed off by that shit. "Not good advice"... "Not good advice"... "Not good advice"...
OPened the issues https://github.com/rochacbruno/dynaconf/issues
It looks like the `sniff` function keeps itself running. The print statement before it is probably unnecessary -- the important print statements are in the `arp_display` callback.
The challenge is quite significant: macro() allows things (lots and lots of them) that markdown does not. Such as making decisions based on content, actively managing lists of data, and so forth. A macro() document is "live" in the sense that changing just one small thing up front can change the entire rest of the content; markdown is not "live" in this sense. Markdown is a pure markup undertaking (amusingly enough), while macro() is pretty much the opposite, a design that is intended to empower the document source to participate in its own structuring. The fact that macro() can generate the same content as markdown can is a side-effect of being much more powerful than markdown. I'm trying to leverage that side-effect to make it easier for anyone who would like to move from markdown to macro. In the end, the best one could hope for is a pure ABA conversion from markdown-to-macro-to-markdown without ever editing the B source in between so as to never use any macro() features. But A: that's super hard to get exactly right, and B: what's the point? You already had the markdown source in the first place. :) Having said *that*, you could probably make an CSS/HTML-to-markdown converter that would work on the *output* of macro(), and for that matter would also have to work on any HTML or CSS anywhere, any time. That'd be a pretty big job, and it's one that doesn't appeal to me, as it's not anywhere in the set of goals I've established for my project. You are, of course, welcome to write such a thing. :) 
Btw the typical "meme font" is Impact, white text colour with a black border. Cool project though!
Sick idea mate! but, https://imgflip.com/i/ptwjg
As a bit of a nitpick: these are called image macros. Image macros are just one example of memes.
Lad, well they say flattery will get you everywhere :-)
How is this different from [TextBlob](https://textblob.readthedocs.org/en/dev/)? A lot of your code seems to be borrowed from that repo. Did you just train it on wikipedia data? 
Impact. Can't go wrong w a classic. Also, you went through all this trouble and didn't know they're called image macros??
I've been learning Python for the last couple of months and I'm looking to try one of the nlp toolkits soon. How does Polyglot compare to NLTK?
Also, you could run Reddit comments through Markdown to get the HTML which is probably easier to work with.
Yes, but immediately remove the brackets or braces that wouldn't. Regex more quickly solves this.
...or you could use [numpy](http://docs.scipy.org/doc/numpy/reference/routines.linalg.html)...
Holy-
Thanks for making me remember I haven't upvoted yet, 38 now!
[Relevant xkcd](https://xkcd.com/1475/ )
[Image](http://imgs.xkcd.com/comics/technically.png) **Title:** Technically **Title-text:** "Technically that sentence started with 'well', so--" "Ooh, a rock with a fossil in it!" [Comic Explanation](http://www.explainxkcd.com/wiki/index.php/1475#Explanation) **Stats:** This comic has been referenced 267 times, representing 0.3464% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_cu9zfst)
can you list some of these tools? 
No. Not all image macros are memes just as not all memes are image macros. Memes are elements of culture that are spread by people. An image macro needs to be widely shared to become a meme. Image macros often become memes because they are easy to share, but creating an image macro does not necessarily mean you are creating a meme.
Got it, thanks! 
I'm working on a WordPress-like blogging system: https://github.com/syegulalp/MeTal It's actually more akin to Movable Type, since it generates static HTML pages rather than serving them dynamically, but it's meant to have the same kind of rich front end. Also plugins, flexible theming, etc. Some screenshots and a general progress report: http://www.genjipress.com/2015/08/another-piece-of-metal-dept.html
http://i.imgur.com/EYyVS9U.jpg
Completely to see if I could do it. The speed is horrific, and no one would ever write a ray tracer in anything else but a fully compiled language.
Why? Why would you want to have to follow the execution flow off to a function that has a single line? How could that ever be more readable?
One answer works on ALL OS's. The idiot one you gave works SOME of the time. Fuck you.
I have one mission critical project, my personal cashflow program. SQLite database, output to html and then my browser, plot using matplotlib, all debug permanently logged to an output file and tests inbuilt into the code.
I made [this](https://github.com/SteveDoyle2/pyNastran/blob/master/pyNastran/gui/caero.png) for interfacing with a very common structural analysis format. Other people help as well. The GUI is the afterthought, but it sure is pretty. The real project is to parse the horrific Fortran-based syntax (e.g. `1` and `1.0` mean different things; `10.0, +10.0, +1.0E1, 1.+1` are the same; `1.0E1` and `1.0D1` are different; maximum of 80 characters per line; tons of defaults) on the input and output files (streaming binary file with the `node id` represented as `(node_value-print_code)//10` with the print code tells you whether you wrote the file as ascii/binary/ascii format #2 and has 7 options and is often written incorrectly) with 700+ different input cards and the 400+ result types. As a bonus, the commercial solvers that use this format don't catch half the bugs that the little test scripts catch. It's a great debugging tool as well.
I will repeat that the OP categorically stated Windows 7, so the obvious solution is is to use the Python Launcher for Windows as described in IIRC PEP397.
Some of the word-wrapping needs work. At first I thought this would be a disaster, but I think some good came out of it. [This is one of my favorites](http://i.imgur.com/H1orW8f.jpg). 
And so was born *The Internet of Critters*.
Omg! I think I need this too! Same issue, down to bunnies and schedules. 
r/learnpython
such terribly written code. somewhere, someone is reading this and learning how to write code from this blog entry.
You should include an exception for url code. Either remove the code, abort the process or pick the next line or comment. Should't be too hard, you'll avoid a lot of the ugly ones. 
I'll probably just add a weight sensor to the container that normally holds the food and water level sensors on their water bowls.
Javascript: [Are one-line functions a good idea?](http://www.codereadability.com/are-one-line-functions-a-good-idea/) C/C++: [One line functions](http://stackoverflow.com/a/785217) Yes, swapping two list items is a fairly common and straightforward procedure, so in OP's case it was probably overkill. But with a name like `swap` and taking two variables, I don't need to go find the function definition to be confident that the function is going to swap the values of those two variables.
Well, I want in. What do I do?
I've made several that help me out with my job in application development. I would always appreciate help with them. https://github.com/lobocv/pyperform An easy way to performance test and compare code using decorators. There are several other neat tools in there such as threads that log their errors and threads that get profiled. https://github.com/lobocv/crashreporter Automatically generate and email nicely formatted traceback and error information if your script crashes. It also stores offline reports and sends them later if there is no internet connection at the time https://github.com/lobocv/eventdispatcher Pure python based event dispatching framework based Kivy's event dispatcher. https://github.com/lobocv/anonymoususage Anonymously track usage statistics and upload them to developers. 
This needs to be explored more. Thank you for the tutorial. 
Basically anything from Agilent/Keysight (was also looking into Teledyne LeCroy products but didn't end up trying it out) electronic test equipment can be automated using Python (although you need a GPIB connector like this one http://www.ni.com/gpib/) and then from there you can use Python's Visa library to automate your measurements. Equipment I've used alongside Python includes: Keysight 86100 DCA Wideband Sampling Oscilloscopes, Keysight DSA Real Time Oscilloscopes, Keysight J-BERT N4903B, and Multimeters/Power Supplies/Temperature Chambers Overall it was very useful and very simple too!
 import requests r = requests.get('http://httpbin.org/get') r.status_code 200 or &gt;&gt;&gt; r = requests.get('http://httpbin.org/get').status_code 200 
&gt; Also, I know some would see this as a very simpleminded question, but what would a Python programmer know about Python that would take a Java programmer a some time to realize? [Python for the Busy Java Developer](http://antrix.net/static/pages/python-for-java/online/)
I've made 2 projects related to Yahoo! * ***[mYQL](https://github.com/josuebrunel/myql)*** which is a Python wrapper of the **[Yahoo! Query Languge](https://developer.yahoo.com/yql)**, supports Py2 &amp; Py3 * ***[Yahoo! OAuth](https://github.com/josuebrunel/yahoo-oauth)*** which implements **OAuth1 &amp; OAuth2** and supports Py2 &amp; Py3 aswell 
Having multiple versions is norm, these days. PY3 is just not that widespread.
WOW!!! I died laughing. This isn't me typing, this is my ghost, because I died laughing so hard! 
I have made some scrapping scripts initially. In order to be with python though my job is simply a KPO. Nasapod/amazon/groupon price scraper and so on. Now, taking a leap building a custom productivity tracking/management and analysing tool for my team using Django framework. Sticking with the principle of 'Learn by doing'. If needed help, ask me.
"Scalar product" is the same as dot product in linear algebra. I guess you mean multiplication by a scalar.
Learn python the hard way. Swaroopch python notebook Pythoncentral.io Euler's project Of course, stack overflow &amp; each python module's code. .! Al d best. .
Make a subreddit and make the bot post them there
It sounds like you're probably going to want to make a static method or something similar on the object, with a name like `load_json()`, that will let you do whenever you want. So something like: import json class Test: data = dict() @staticmethod def load_json(f_name): Test.data = json.load(open(f_name)) def get(self, to_get): print(Test.data[to_get]) object = Test() Test.load_json("some_file.json") # {"1":"a"} object.get("1") # a Test.load_json("some_other_file.json") # {"1":"b"} object.get("1") # b [Here's some more information on StackOverflow](http://stackoverflow.com/questions/12179271/python-classmethod-and-staticmethod-for-beginner).
Read it almost after seeing it in HN. Thanks much. . Those are the type of topics which we really cant know how to ask or how to google it. . Really tue first topic itself was my long term confused dilemma. . Cleared my head now. . 
The readability of my program gets bombed whenever i used regex. . Kissing regex will hurt bad but one needs to know what he needs to get. Hence shall we say regex I helpful. .?! PS : Am a newbie asking a question. .:(
how does the program select background image?
For those of you who don't have Reddit Enhancement Suite installed, you can add `.json` to any Reddit URL to see the API edition (for lack of a better phrase) of the web page. In this case, [the comment's .json](https://www.reddit.com/r/Python/comments/3hqwmo/i_made_a_reddit_bot_that_creates_memes_out_of/cu9uswp.json) contains: "body": "[Consistent, huh?][How you gon deal with this?] \n\n[How you gon deal with this?]: http://example.com\n\n(View the comments source)\n\nThere are very, very few people that use or even know about this style of link formatting though, so you should be fine :)", "body_html": "&amp;lt;div class=\"md\"&amp;gt;&amp;lt;p&amp;gt;&amp;lt;a href=\"http://example.com\"&amp;gt;Consistent, huh?&amp;lt;/a&amp;gt; &amp;lt;/p&amp;gt;\n\n&amp;lt;p&amp;gt;(View the comments source)&amp;lt;/p&amp;gt;\n\n&amp;lt;p&amp;gt;There are very, very few people that use or even know about this style of link formatting though, so you should be fine :)&amp;lt;/p&amp;gt;\n&amp;lt;/div&amp;gt;",
Ahhhh that is some shit code
And he's running everything as the root user. Wow.
I dunno man. I'm not really opposed to the 3rd, but it is slower and they could have made the transition less dramatic. 
There is a huge collection of many python frameworks and libs: * https://github.com/vinta/awesome-python
The software for my digital turntables is crap, so I made a python program to adjust cue points, layout beatgrids, import/export from other file formats, update/store tag information and repack it into the native database. For research I have also made patent analysis and graphing software
I am glad that it helped :)
You're entitled to use the version you prefer, but we should be factually correct. The speed difference is more like 10% and it's not always in favor of 2.x, though it does prefer it. Of course this is an average value and your own code may be different. I agree that forking the interpreter isn't as scary as it sounds, but people should be prepared to take action like this if they stay with 2x. I don't want to see any angry rants about "lack of support" come close to the deadline!
http://blog.voltagex.org/2015/08/21/silly-project-of-the-day-find-out-when-bake-off-is-on-next-via-phone/ https://github.com/voltagex/python-gist https://github.com/voltagex/junkcode/tree/master/Python Also, I have a Flask app listening for Amazon SNS notifications, which are then PushBulleted to my phone. Yes, I know I could use SNS directly to my phone, no I don't want to.
if you are just probing for arps when you turn on the button, do you ned to go through any steps for it to turn on? does it have to "activate" first?
This is one example of a project where porting to Python 3.x looks like a nightmare. Normally, there is little really holding projects back from Python 3.x other than a little hard work. However, with Scrapy, I really see that all this unicode/byte/str nonsense would be an absolute nightmare!
Congrats to the team for taking the hard time and effort to port it. Python has been split between 2/3 and actions like this are to the right direction.
Looks awesome. Is there any way to retrieve public calendar info for a given person, different from the one you're logging on as? Good job anyway! I had written a few scripts already but was waiting for someone else to do the hard work for me ;)
**Note:** This notebook is intended to be a public resource. As such, if you see any glaring inaccuracies or if a critical topic is missing, please feel free to point it out or (preferably) submit a pull request to improve the notebook.
[Integer](https://en.wikipedia.org/wiki/Integer) [Float](https://en.wikipedia.org/wiki/Floating_point)
I think you have some misconceptions. There are two basic numeric types that are used by most programming languages: integers, and floating point numbers. (Not "floating integers". That's not a thing.) The term floating refers to the fact that numbers are represented by a significand (or mantissa) and an exponent. This gives the appearance of the decimal point moving around, or floating. This is in contrast to a different scheme, called fixed point, where the position of the decimal point does not move (i.e. the exponent is not stored.) For example, in a base ten floating point system (which is not what the computer uses, but it's simpler to explain), a number like 123.456 would be normalized to 1.23456e2, i.e. one significant digit to the left of the decimal point, followed by whatever digits remain to the right. The 'e' is a common notation for the exponent of a factor of 10, i.e. this is a compact way of writing 1.23456 x 10^(2). The numbers that would be stored are the significand (123456) and the exponent (2). That's how this fractional number would be represented internally, except that it's much more complicated than that because the internal representation uses base two, not base 10. Anyway, the main point that you need to know is that integers can only represent whole numbers, while floating point numbers can represent rational numbers, albeit with limited precision. (In Python and many other languages, IEEE double precision is used, which gives nearly 16 decimal digits worth of precision.) The limited precision means that they are vary rarely exact. They can come very, very close, but never exactly represent most numbers. In most cases that's fine, but it does cause some head scratching. 
That last comment is incorrect. When Python 3 was first being discussed it was expected to take a good 10 years for everybody to take it on board. With the [Python 3 Wall of Superpowers](https://python3wos.appspot.com/) growing ever greener that should be met, give or take a bit.
As you've all ready pointed out you've sorted it well done, give yourself a pat on the back. Learning to read, diagnose and fix the problem seen in tracebacks is a skill that has to be mastered or you'll (plural) never make a full blown Python programmer.
Sorry, I knew I had the phrase wrong after I posted it. I appreciate your patience.
Can you define "normalized?"
Exactly, it's in the main.py file if you're curious /u/avinaash. Then they are loaded. r = praw.Reddit(user_agent=user_agent) sub_name = 'pics' pics_subreddit = r.get_subreddit(sub_name) hot_posts = pics_subreddit.get_top_from_all(limit=60) picture = urllib.urlopen(picUrl) image_file = io.BytesIO(picture.read()) img = Image.open(image_file).convert('RGB') self.image = img
cool initiative man! 
Perpetuating? But depending on the originality (lol wut) of the content of the image/text, that content itself has the potential to become a meme.
&gt; to see the API edition (for lack of a better phrase) A better phrase might be the JSON for the post? (i.e., no need for a phrase, this is a programming subreddit)
script1.py &amp; script2.py &amp; script3.py &amp; script4.py &amp; script5.py &amp; 
normalized written in an equivalent form, but more convenient for our purpose in this case: written in the form a.bcdef...*10^(N) with only digit on the left of the decimal point.
Or, in case the number might change: `for i in *.py; do python $i &amp;; done`
I wish someone would have told me it didn't support Python 3 yesterday when I was trying to install it... 
I'm going with the below code I think. The first regex removes anything that matches the pattern "](somethinginparens)" which I *think* should only ever match a link. Then the second regex removes a bunch of stuff, including open brackets so that we're left with just the link description. #comment = "Check out this album [here](http://linktoalbum)" comment = re.sub(r'\]\(.*?\)', ' ', comment) #comment = "Check out this album [here" comment = re.sub(r'[\n\r\[\]]', '', comment) #comment = "Check out this album here" 
Hey, yeah i've recently started with Python. Thanks for your suggestions! Duly noted! :)
Got it. Thanks.
Just to tack on to this comment, conda is also useful for installing the PySide/PyQt packages. There is even work being done on `conda install pyqt5`!
If you are a CS student, you can also purchase a cheap domain and hosting server, where you can run whatever projects you want. It will be a worthy investment for sure.
Once you determine where you will run your application you will still need to build an application that can run indefinitely. This is not trivial. I've outlined a solution [here](https://geduldig.github.io/TwitterAPI/faulttolerance.html) using the [TwitterAPI](https://github.com/geduldig/TwitterAPI) python lib.
This is great - nice job.
Really well done. Advice: I think you are missing a few big things like preprocessing/scaling and pipelines. Before using the learners, inputs should be scaled so that each feature has equal weight. Something like StandardScaler or MinMaxScaler are both appropriate (from sklearn.preprocessing). If you think some features are more important, you can scale them later to increase their relative importance in prediction. These are more parameters you would tune using CV, but these can be really numerous, so GridSearch is out the window and you would have to consider some alternatives like Nelder Mead search, genetic search, or multivariate gradient descent if you suspect convexity. You have to fit these scalers on the training data and then use the trained fit to transform the testing data. Using Pipelines simplifies this whole process (fits the scaler and learner at once, transforms and predicts at once). Other than that, it looks great. Especially good data handling on the parameter tuning using KFold and Grid Search CV. Most ML implementations I see are tuning parameters on the test set outputs.
Finally.... I definitely prefer using scrapy to parse xpaths than lxml. lxml is nice, scrapy is just a bit better from my findings.
[Hey, when you need a sandwich, you *need* a sandwich...](https://xkcd.com/149/)
Slightly promotional I guess, but still fun.
Great feedback - thank you! You're right that I totally skipped over preprocessing and should probably include that. I was going to add sklearn Pipelines at the end, but it seemed pointless when all I was doing was fitting + CV on the data. Perhaps it'll make more sense to make a Pipeline if I add preprocessing. Cheers!
Raymond Hettinger has good talks on Python advocacy, specifically how to sell the language to non-technical decision makers.
Please make sure you include more than genetic algorithms. Make sure there is something on neural nets. Genetic algorithms always seemed like the kind of thing anyone could independently come up with pretty easily.
&gt; I have been reading about the multiprocessing module and using Pool, but every example seems to be about running functions. I want to do the same thing but with actual .py files. You could create a function that runs a .py file. import os; os.system('python sutra1.py')
might think about posting this over at /r/datascience as well
Keep doing exactly what it's doing.
I said this so that op isn't fielding massive amounts of installation questions about numpy. Not because anaconda is the best thing ever. Edit1: Also, care to explain why is it wrong and misguided? Edit2: oh wait, I just read your comment history. You're a troll. Feel free to not answer my question.
You could recommend the unit testing chapter from dive into python 3 to avoid reinventing the wheel. Edit: or do a separate chapter (or whatever you want to call it) where you expand all the testing. Like, each section of your walkthrough could be a whole chapter IMO.
I'm not sure if I follow you here. Can you elaborate more?
This is kinda true. There is something called the heroku scheduler. It is dirt cheap (pennies a month for short queries) and will run your script at a fixed time interval
&gt;You could recommend the unit testing chapter from dive into python 3 to avoid reinventing the wheel. I'll do that. I'm all about not reinventing the wheel.
Wow, this is cool! Thanks!
I wrote [Radon](https://github.com/rubik/radon), a tool to examine your code's complexity. It will find the most complex functions/methods and mark them with a rank. You can filter results, export them to JSON or XML... I now use it in every project of mine and I find it very useful. It's advisable to keep your code complexity (per block of code) low. I also built [Mando](https://github.com/rubik/mando), which is a small library that makes the creation of command-line programs effortless. [Radon](https://github.com/rubik/radon)'s command-line interface, for example, is written with Mando.
How is it non-trivial to write an application that runs forever? import time while True: time.sleep(1) 
I'm worried that if `p1` doesn't terminate on it's own, the first `communicate` call might never return. In particular, `p2` might hang when it's output buffer fills up, because we're not reading from it yet, and then it would stop reading its input buffer, which would make `p1` hang for the same reason.
https://imgflip.com/i/pvutg
You're right. You'd need to use `select()` or its equivalent in that case so that you can both read from the last program and write to the first program in the pipe without deadlocking.
Markdown? It's easy, looks good, but still functional (any HTML is valid Markdown). 
Any HTML being valid Markdown, only makes it uglier, don't you think? Plus, markdown isn't extensible so you can't create your own macros (to have real semantic markup).
In that case. Could you give pyinstaller a push to full Python 3 as well please. 
Yes, but you need to wrap it in a C api (ABI really) first.
My first and only Python system utilized Pandas and Flask to build an ETL system of sorts. It pulled survey data from a MySQL database and transformed and processed results using Pandas. The results were viewable via a Flask endpoint. I can't wait for another excuse to use Python, Pandas, and IPython Notebook again! :-)
No. Whatever you do, you will most likely be allocating a std::vector&lt;&gt; using a extern "C" {} wrapped function, then populating it using another wrapped C/C++ function then passing the pointer to ``func()``
Why not? `sizeof(std::vector&lt;int&gt;)` seems to vary between 12 and 24, so it seems like it should be possible represent that in a `bytearray` or something and create a `vector` from scratch.
This was my first large Python project: http://TheWikiGame.com
What did your last skivvy die of, overwork?
Whoa that was impressive. Python coding a time travel :)
Run it on a cloud server. A basic Digital Ocean VM with Linux and 512MB of RAM is $5 a month with no commitments. 
Python manages it's memory through use of a garbage collector. C/C++ has no concept of Python's GC. As such, the bytearray can relocate at anytime to another region of memory or be destructed. That would create a wild pointer, which never ends well. It may be possible to use mmap(2) to create a region of unmanaged shared memory, but the second you add in a Python managed object, like a byte array, you will be doing a lot of copying back and forth. You could write a CPython C-Extension to effectively mimick the interface of a bytearray, but you will still be doing what everyone else said, which is a form of a wrapper in C/C++. It's a difficult case to effectively make a zero copy. The vast majority of solutions involve some form of copying to escape/re-engage the garbage collector. 
I looked at the path you gave me yesterday, and figured out where to find my FF profile. But that link is still handy. If I have such a script running on a remote server, would it just run the selenium webdriver script on the server, without needing a local machine? I guess it might also depend on what your web host allows, or maybe it would have to be a VPS.(I use a cheap web host only) I already use the best plugin for that (random agent spoofer), and I'm glad that you can also change the user agent with the code (if a plugin can do it, so can you). I think it's the best plugin because you can even change the screen resolution with it, if you download the full version from Github. That's why I was wondering what I could possibly add to the user agent string, to change the screen resolution, time zone, etc. Thanks again. 
People regularly borrow the time machine from the BDFL, it's all part of being in the Python community.
I wasn't trying to be cute... this is a pretty rudimentary programming concept. Add some logic to my code block: while True: try: do_work() time.sleep(x) except (E1, E2, E3) as e: handle_exception() While you could certainly make this more complicated, there is no reason you couldn't handle this type of use case with a simple endless loop. EDIT: Maybe I'm misunderstanding what you were trying to say in your original comment. I understood your assertion to be: It is non-trivial to create an indefinitely running program. Rather than: It is non-trivial to create an indefinitely running program utilizing the twitter API. I'll disagree with the first assertion and weakly agree with the second, defining trivial as "requiring a small amount of research."
One example why floating numbers are not good for money counting. Look at the fraction 1/3, if you want to write it in a decimal eypression you will get something like that: 0.333333333... 3s untill infinity, a computer is very bad in storing those numbers, because you haven't infinitive memory. ;) It will be even worse if you look into base 2, the standard way a computer handles numbers. Look at the easy fraction 1/10 in base 10 it is 0.1, easy, but in base 2 it will be 0.000110011... and because it is periodic 1/10 * 10 can't be 1 if you use this kind of representation. But of course your interpreter will have some fixes to give you the 1, but it is mostly rounding, so it is bad for exact financial computations. Python offers you the fraction and decimal module to store and compute numbers with arbitrary precision. But don't be afraid as long as you don't need high precision floats are fine for daily routines. The main number type you'll use are still integers.
I made a simple script that performs fuzzy string matching on 2 files and outputs the scores of various matching algorithms. Input files should be text based (txt or csv will do) and should have 1 word/term/sentence per line. Every term on file1 will be paired with every term on file2 and scores are calculated for each pair. You can provide a minimum score for the algorithm of your choice to filter out your results (but all scores are output anyway): https://bitbucket.org/bergonzzi/fuzzy-compare I did this because I had to do string comparisons on big files on a regular basis and was unsure about what the best fuzzy algorithm was. This way I can check scores side by side and decide depending on the use case. If someone wants to help solve the multiprocessing with queues issue to optimize it that would be great :) Other than this I regularly write scrapers using Scrapy (both to help me and my team at work and for some minor personal stuff). I love Scrapy, it's a very mature and well documented framework and I've been learning a lot using it. My current challenge with it is to scrape some 300k websites to profile them in terms of technologies they use. I'm using scrapinghub's python wrapper for [Wappalyzer](https://github.com/AliasIO/Wappalyzer/) (https://github.com/scrapinghub/wappalyzer-python). edit: added last project
Take a look at [Pandas - Python Data Analysis Library](http://pandas.pydata.org/) and [Working with Excel Files in Python](http://www.python-excel.org/). Forget about macros in Python, right now they're only at an experimental stage, or are you thinking of Python powering Excel macros?
Running python scripts from within python is kind of wrongheaded. If you want to run python code from within python, you should import the python modules and call the code directly. Lets suppose I have a simple script # hello.py print("Hello World") You can easily refactor this to allow either running the script as a script or running the code as a function: # better_hello.py def hello_world(): print("Hello World") if __name__ == "__main__": hello_world() `better_hello.py` can be run as a script just as well as `hello.py`, but you can also do this: # other_script.py import better_hello better_hello.hello_world() The `better_hello` approach is much more flexible, and should be your default approach when writing scripts.
This is what I ended up doing, thanks for your detailed response!! Could you explain the "__main__" part though? I'm unfamiliar with that and I've seen it around a lot. 
&gt; python3 offers less internal methods to circumvent stuff. I wouldn't call it circumventing; I'd call it more: ignore it, pray to the gods that it's just ASCII, and hope for the best.
Yeah there is no error. You are probably copy pasting the code from somewhere into the interpreter and its fucking it up. Also you can get rid of alot of the code by using the in operator and lower method of string. If you have a string s you can convert it to lowercase like so : s.lower() You can make a list (or other collection) and check if a certain item is in it. race_list = ["human", "orc", ....., "elf"] if race_input in race_list: #do stuff Also /r/learnpython
Adding to the comments on installation/packages for different OSes... I did a MOOC at Edx which was basically [ML with PySpark](https://www.edx.org/course/scalable-machine-learning-uc-berkeleyx-cs190-1x). They avoided installation hell by using a VM that would serve webpages accessible to the host OS. To make the VM easy they used Vagrant. Also there are some Docker containers and other solutions to run [Jupyter](https://try.jupyter.org/) with Python support. I'm currently working on reinstalling a lot of software so I don't have the VM set up right now, but I'll check out your actual notebook once I get that fixed OP.
Thanks for this.
Don't get me wrong, I love python; but why would you involve python at all? Excel can natively connect to remote databases and push/pull all the data.
Not sure if this will apply to you, but if you're at a college/university with a CS department, they almost certainly have a cluster that they will give you access to. Also check to see if your library maintains some account for you. Every single student at my school had a unix account on the library cluster, probably 80% had no idea.
What don't you understand?
Thank you! Perfect for me. 
I've written this command line app called [Balert](https://github.com/tushar-rishav/balert) , which notifies user by an audio notification whenever the battery level goes below some critical level. Kindly, note that the user can set their own custom alert messages , charge level, languages and other available options too. :)
Oh geez, [SKS](https://bitbucket.org/skskeyserver/sks-keyserver/overview) is written for OCaml.
How so? The transition has taken years. If you mean they could make the difference between 2 and 3 less drastic, then no - the only real "drastic" changes are core changes that had to be drastic. And again, if you make 3 just like 2, nobody sees an advantage, nobody changes. I'm not sure a decade (or more) of overlap to get used to string handling being Unicode is exactly dramatic.
See https://wiki.python.org/moin/Audio . The Snack toolkit looks ok, but I've never tried working with audio.
Not sure how others feel, but this dataset is overused. The explanations are great, quite honestly some of the best I've seen using this dataset. With that said, the data and analysis don't offer anything that unique from the other 1000 tutorials that use it as well. 
Seriously though the open data structures python guide is the great. Its got data structures obviously, as well as algorithms that pertain to them. There are even exercises in each section!
I find rST really beautiful. Sure, it's not practical (but doable) to edit without an integrated text editor. However, it surely can not do everything TeX can, they are not meant for the same thing.
yep :)
You should be able to install it with $ python setup.py install from the root of the unzipped package. From there, it looks like it installs to your python's bin directory, giving you a vicar2png command to use from the command line. Another way to install is to try $ pip install vicar2png This is the way to go, but installing pip for the first time can take a few minutes and a google search.
Is it called Hendrix because his playing style is kind of like a more twisted Django Reinhardt?
I used python setup.py install, but vicar2png returns an unknown command.
camelNotation and semicolons... We got us a wolf in sheep clothing here friends. None the less there is a really good console progress bar I have seen in the past... I will see if I can find it. 
This annoys me to no end with PyCharm. Why doesn't it have ANY suggestions?
And you are already using Python 3 I imagine?
I found "tqdm" easier to use then "progressbar"
1. write script 2. put it on server 3. schedule it with cron done
Sounds really good. I'll need to try it out.
If you watch the output of the setup.py install, it should show you where it copies the command. You might have to add that path to your system path.
Cool, thanks!
I think this is a good idea but would be better as links to stack overflow. This would preserve formatting and generally make it easier to browse and organize. Basically everything could be listed out in the README. I've seen other similar projects take this approach. Also what is your criteria for "best"? Is it highest rated questions?
I think I'll just fire off a thread. Should work everywhere, and it won't have to do anything fancy or global.
Quite surprising, I've found PyCharms code prediction the best I've come across in the modules I use. Could have something to do with the way that module instances variables? P.s check your first sentence you may have pycharm on the brain.
Thanks for pointing me to this. OP: a picture is worth a thousand words, its literally the reason I went with tqdm instead of your project. (This is only meant as positive criticism.)
As mentioned by someone else, definitely take a look at learning Pandas. I wrote an article explaining some simple Excel tasks and how to do them in python - http://pbpython.com/excel-pandas-comp.html I have several other articles that might give you some ideas. My basic recommendation is to just pick something and start trying to replicate it in python+pandas. I suspect that once you get a feel for what you can do, the other ideas will start falling in to place. If you are planning to work on Windows, then I would recommend you use https://store.continuum.io/cshop/anaconda/ as your python distro of choice. It makes the Windows setup so much simpler and has all those binaries you need in a simple installer. Good luck!
All of these examples can be easily performed with one or two lines with the standard os or shutil modules and will return data structures that are much easier to work with in python: &gt; Print current working directory print(os.getcwd()) &gt; List the files in the current directory os.listdir(os.getcwd()) Note that this returns a `list` of files that I can iterate over. If I want to know properties of each file, I can use `os.stat` on each file. For example, to print each file and its size: for f in os.listdir( os.getcwd()): print("{0} {1}".format(f, os.stat(f).st_size)) I can easily produce a list of tuples of files and their sizes and sort them by size, and print out the five largest: from operator import itemgetter file_sizes = [ (f, os.stat(f).st_size) for f in os.listdir( os.getcwd()) ] file_sizes.sort(key=itemgetter(1), reverse=True) print(file_sizes[0:5]) The point here is that it is easier to take the list provided by `os.listdir` and use it to work with the files in a directory than it is to take a raw string from ls with some options and parse it to get the data structure that I want in the first place. &gt; Print the contents of a file to screen This is pretty simple just using builtin functions: with open('foo') as foo: print(foo.read()) &gt; Make a copy of a file shutil.copy('thisFile.text', 'copyOfThisFile.text') &gt; Create a new empty file open('newEmptyFile', 'a').close() One of the best things about python is that it has a very robust standard library which implements the typical functionality that one has available with coreutils, so it really is not generally necessary or efficient to fork and exec coreutil processes when you have standard library functions which will do the same thing (and more!) and then hand you back convenient data structures.
Still don't know what to put in the bytearray to create my vector from scratch though. 
Agreed. 
Apparently it's last release was 2004. I feel like that's too old 
Just read 2.5 on static and class methods. +1.
Progress bars inevitably have the problem that they tend to show what fraction of the tasks is complete and the user is more interested in how much more *time* they need to wait. This leads to the progress bar that seems to be forever stuck at 90%.
I'm not a big fan of eclipse (I actually prefer NetBeans for Java development... go figure), but if you do a minimal install with PyDev and just the few other packages you need (version control, web plugins, etc) it really is a great IDE.
Thanks for pointing that out, [fixed!](https://github.com/QuantumFractal/Data-Structure-Zoo/commit/b984d20690b0e3dc6a5494613010804b120a28ec)
For those looking for tqdm, see [https://github.com/tqdm/tqdm](https://github.com/tqdm/tqdm). The original author seems to have [abandoned the project](https://github.com/noamraph/tqdm/issues/18) and some other folks have picked it up. The [package on pypi](https://pypi.python.org/pypi/tqdm) still points to the original owner's version (and is thus out of date).
I just tried jedi in emacs with the original example, and was surprised to find it works. edit: here's a [screenshot](http://imgur.com/yiQoxfQ)
&gt; This leads to the progress bar that seems to be forever stuck at 90%. That's actually caused by issues with serial programming and (almost) nothing can be done about. For example, if I have 100 files to copy, I can update 100 times before I'm done. If one file accounts for 90% of the transfer operation and I can only update once per file, I'm left with a very large jump. Unless you're doing asyncronous programming with communication between the processes, you can't fix that. If I have a process where I'm doing something 100 times and all tasks are nearly identical, I can predict how long it will be accurately as I go and each step will be nearly uniform and the time estimation will be very accurate after only a few steps. &gt; the user is more interested in how much more time they need to wait Those exist as well. They're just not the default. You can add messages.
Let's say you have two file, a.py and b.py, where a.py is simply: import b and b.py is: def b_func(): print 'b func' b_func() if __name__ == '__main__': b_func() When you run b.py directly, it will print 'b func' twice, once from line 4, and again from line 7. When you run a.py and it imports b, it will print 'b func' once. Essentially when you import a python file, all of it's code is run. This is good when there are classes and functions. The __name__ == '__main__' line is there to allow you to run the code directly, but not when it is imported into another file
python has functions ;) But I see your point, I was just hoping that someone thought of a beautiful syntax that simplifies semantic markup. Apparently, no.
Well, every time I try learning rST, the multiple ways of doing headers (even though it's supposed to be a feature), and the underscrores for links bother me. But to each their own.
The binary search algo is really broken, has a few typos and is not a binary search btw: def binary_search(array, item): first = 0 last = len(array) - 1 while True: mid = (first + last) // 2 if array[mid] == item: return True else: if item &lt; array[mid]: last = min(mid, last - 1) else: first = max(mid, first + 1)
sounds amazing. Do I understand correctly that this removes the requirement for mod_wsgi? so Apache talks directly with twisted? 
Doctests aren't intended to replace unittests. They are intended to be an example of how to use a function, and happen to be in a format that you can run doctest with (thus verifying that your example is still correct after making changes to the code). Also, this article is from 2008... It still mentions "may be solved in Python 2.5".
its trivial to write a program that runs forever. its non-trivial to write a program that does this well, unless the program itself is doing very trivial work (not doing io, not storing anything new in memory, etc)
If you think Python is somehow being held back by its Windows support, I'm not sure what to tell you. The fact is that Python has been *growing* in popularity and use the last decade while Windows has been *shrinking*. If there is any correlation, it's a negative one. Python doesn't need Windows at all. And for that matter, neither does any other modern programming language. To continue to even support Windows is backwards thinking.
I do not think that Pyhon is being held back by its windows support. I do however think that you are being unbelievably ignorant when you say that supporting windows is backwards thinking. Just look at [this](http://i.imgur.com/kQle89E.png) chart and tell me that *any* programming language should not support Windows. Why not? Because many programmers are not on windows? Or because you think you're so cool running your self-configured Arch distro? Windows is huge and for many programmers it will be their first OS on which they come in contact with *any* programming language.
Thanks
Yepper!
"suffisticatted" is spelled "sophisticated". oof.
Page 18, "2 Dictionary" paragraph, second verse: "...array or a hash table in order langauges." I suppose, it should be "other languages"? Anyway, this publication seems to be nice. Good work!
You mention "Hyperion". Which version, and what component (HFM, Essbase, Enterprise...)? The old Hyperion line has been renamed Oracle Enterprise Performance Management. Since release 11.1.2.2, EPM includes FDMEE, a data-pumping tool replacing classic FDM. Guess what? Where FDM used vbscript for scripting, FDMEE uses a Python dialect (Jython). If you get authorization to hook into that, you can do all sorts of stuff with your data (or just move from reporting to data-massaging -- jython experts are still thin on the ground, in the Hyperion/EPM space).
Ugh, you're completely right. Not worth my or anyone's time. Having said that, my company is currently windows-only (mostly due to the fact that our customers are all 100% windows based) and especially when using a package manager such as Conda everything has worked rather splendid! I'm glad that there are more things upcoming! Love the language!
Also, just because this is "intermediate python", it would be nice to say in this part: &gt; Methods in a class that are defined with self as first argument are instance methods. The self argument is similar to this in java and refers to the object instance. "self" is only a convention that we use. It could be "this" as well, nobody just write code like that. 
&gt; Don't think you're understanding my question, but thanks anyway. Don't think you are understanding my reply. I've done this many times to many libraries with memory allocated on both sides, with or without copies. Post what code you have so we can fix it.
Install [this](http://www.mingw.org/ ), make sure the bin directory is in your PATH. Then try running Nuitka again, I forgot if you had to tell it in some way to use MinGW, but I'm sure you can find it.
Yes.
/r/python is horribly biased towards pycharm. Personally i think its rubbish.
Cool! Could you license under something like the MIT license?
I get timeout trying connect to this site :/
If you want to use the Visual Studio 2015 command prompt, the easiest way to do so is to open CMD then enter `C:\Windows\System32\cmd.exe /k "C:\Program Files (x86)\Microsoft Visual Studio 14.0\Common7\Tools\VsDevCmd.bat"` The bat file is the main thing that opens a VS command prompt and loads the important stuff. VS 2015 is version 14.0, so that is why that is used.
May be a temporary issue..give it sometime then retry
Thanks, this should be upvoted higher. It was not enabled by default for me.
for completion i use [pydiction](http://www.vim.org/scripts/script.php?script_id=850), and for everything else there is [python-mode](https://github.com/klen/python-mode), which is awesome but needs a lot of customization :) And for your R-plugin taste : maybe [this](https://akhilsbehl.github.io/blog/2014/08/17/send-python-commands-from-vim-to-ipython-via-tmux/) helps. 
Let the forks be plentiful and the tyranny of censorship capitulate!
&gt; This is now available under the MIT license :) Thanks!
I've been trying to find a good solution for this on Windows. Vim already does most things with it's plugins except for running the Python code in a live interpreter. On a Unix system, it seems like you can just use something like Tmux + Vim-slime to do REPL work (copy, paste in Ipython, execute). Cygwin isn't an option because I'm using Anaconda and it's iPython doesn't work in Mintty. The thing I'm trying next is to just run two separate windows, with GVIM and iPython qtconsole, and then setting up a hotkey with AutoHotKey to copy and paste and execute in the iPython window. I'd love to find a better solution though. 
Hi! Just a friendly invitation to post these tutorial videos over at /r/learnpython instead of here. 
No, support for the official version ends in 2020. Paid support will continue from various vendors while there is a demand, who knows, 2030, maybe even later. If that seems strange there is at least one instance of Python 1.5 still live.
Thanks!
Thanks a lot for the comment. My mistake was that just before the "def" i had a "if" but forgot to write anything in it. That's what caused the error.
Thanks for the comment. Didn't know I just needed one "print".
You can do this manually via the *Control Panel*, but I use the [Rapid Environment Editor](http://www.rapidee.com/en/about).
Try this at the command line: C:&gt; set PATH=%PATH%;c:\Python34\Scripts That will add that directory to the end of your path. You can also add it to your system path, click on the windows start button, then search for environment, and that should get you to the right part of the control panel where you can edit your path, and then it will be set permanently.
I see that C:\Python34\Scripts is already added in path, and there is vicar2png in Scripts, but running cmd as admin and entering vicar2png returns an unknown command. I also did the command and still returns unknown command
So much of what was written in "A fractal of bad design" is simply no longer true. You should do your own research and get the facts straight.
If you're wanting to learn Python (which is a requisite for Django), then Learn Python the Hard Way is an excellent book that I could not recommend more highly. I recommend that book to aspiring Python programmers probably once a week. For learning Django, I've perused and like "[Getting Started With Django](http://gettingstartedwithdjango.com/)", which actually has the LPTHW course as a prerequisite, so it's meant to marry the LPTHW lessons into Django. It's a bit verbose though, and in my opinion, while it's technically sound, it loads too much information in too quickly. [DjangoBook.com](http://www.djangobook.com/en/2.0/index.html) *used to be* the go-to resource for this, but now it's woefully out of date. The [DjangoGirls](http://tutorial.djangogirls.org/en/index.html) tutorial seems to be its de facto replacement, so you should probably start with that to get your feet wet. After that, /u/pydanny has a book out called "[Two Scoops of Django](http://twoscoopspress.org/products/two-scoops-of-django-1-8), though slightly out of date, is pretty darn good. Edited to update link to current latest release of the book. 
I should add python 2 &amp; 3 are supported. 
/u/issue9mm, thank you for referencing the book that I co-authored with /u/audreyrg. :) However, I do have a correction to make. [Two Scoops of Django 1.8](http://twoscoopspress.org/products/two-scoops-of-django-1-8) has been out since May of this year, which not only means that the book is completely up-to-date, but as Django 1.8 is a Long Term Support (LTS) release, the book will be valid until 2017. For what it's worth, we also maintain curated lists of current Django material: http://twoscoopspress.org/pages/django-references
I knew about the knew one, and in my haste, didn't realize I wasn't linking the 1.8 book. Your SEO apparently puts the 1.6 book first (or it's your publisher's SEO, and they're better at it). Thanks for the correction though! Also, I edited to fix the link. 
I suggest X-posting it to /r/internetisbeautiful
&gt; PyCharm seems to not like ambiguity and more frequently does not provide completion if there's too much ambiguity. This makes sense. [Load method](http://eyed3.nicfit.net/api/eyed3.html?highlight=load#eyed3.core.load) returns either *eyed3.mp3.Mp3AudioFile* or *eyed3.id3.TagFile*. For [TagFile](http://eyed3.nicfit.net/_modules/eyed3/id3.html#TagFile) if initTag method is called, then it's *.tag* is being set to [Tag()](http://eyed3.nicfit.net/_modules/eyed3/id3/tag.html#Tag), which includes all the methods being pop-upd in PyDev.
Just tried it, fails. Perhaps this is because attributes of Tag are decorated functions.
This doesn't work for me whatsoever in Firefox. Also, I don't understand why it is asking me to type in what I would like to learn. Doesn't the title say that it will teach me typing? 
Worked for me fine in Firefox. Thoughts: * nice design, except the 'search' label is barely legible * I suppose his is beta so there's no real text, numbers and punctuation available for practice. * I'd like a second visible line of text (to see what comes next). 
Search is broken. Fetching data then nothing happens. Also, that period is rendered awful for a typing program. Seriously?
'C:\python34\scripts\vicar2png' is not recognized as an internal or external command, operable program or batch file. i looked into that file and this is whats in it: #!C:\Python34\python.exe # EASY-INSTALL-SCRIPT: 'Vicar2Png==0.2.dev0','vicar2png' __requires__ = 'Vicar2Png==0.2.dev0' __import__('pkg_resources').run_script('Vicar2Png==0.2.dev0', 'vicar2png') 
Mee too. . But got myself a new project to move on and with it I learned Django painlessly and finished the first project. Though Its completely irrelevant to my work, now I took a project to design a productivity tracking tool for my own team. Its fun, and must say django has its own ground strong and a robust of advantages on its own helm. . Don't lose it. . 
So the most basic way to give arguments to your python script is sys.argv import sys if __name__ == '__main__': for index, arg in enumerate(sys.argv): print "{index}: {arg}".format(index=index, arg=arg) Like this it should be possible to do something like python text_to_array.py input_textifle and it would show up as sys.argv[1] You then can also see if you want to run the GUI at all if you have an argument. If you want to have more arguments and positional arguments, keyword arguments etc. I recommnd [argparse](https://docs.python.org/3/library/argparse.html). For simple counting I recommend collection.Counters - it's pretty neat :)
looked for programming and I think I broke it :P boot looks good.
Excellent book! Thank you for contributing to the Python Community! I'm only through the first third of the book, but you have already cleared up a few things that I didn't completely understand. Also, thank you for your mailing list - [PythonTips](http://pythontips.com/). I've been enjoying it weekly since I discovered it and subscribed a while back. Hopefully, someone can get a link to your book posted on the Python Wiki (I don't currently have a profile there with edit permissions). I will look to submit it to [Free-Programming-Books](https://github.com/vhf/free-programming-books) and [PythonBooks](https://github.com/revolunet/PythonBooks) as well. UPDATE: Sent pull requests to both repositories for the addition of your book. Kudos to you! :)
Is the backend written in Python? link, if it is open source? edit: oops, sorry dude, you have been shadowbanned. 
Without more details, I would say the hard and fast rule is to really paying attention to any work you find yourself repeating. Python (and all programming languages) can help us cut out the repetitive work. This is known as DRY - don't repeat yourself Even something like resizing columns. You could write a Python script to do that for you up front. But maybe it might be more effective to use excel's own built in programming system. 
2) Well, sockets then: Unix or TCP. Maybe look for libraries instead of implementing the boilerplate yourself. Whether `/tmp` is in RAM or not depends on your setup. Run `mount` or `df` to check.
Looks great! Reminds me a bit of seaborn. Maybe post to reddit stats to get more feedback
Oh, right. I was just wondering, not particularly asking for the dependency to be removed. :) I'm not too familiar with pandas, but matplotlib can create boxplots as well - Is it easier in pandas?
Why not just try to make your own, and learn along the way? You can break it down into smaller problems to solve: 1. How to get a list of tweets by keyword? 2. Given a 140 char tweet, is it really about entering a contest? 3. How to retweet it, making sure we don't retweet it more than once. 4. Detect if following the account is needed. 5. How to follow the account 6. How to manage rate limiting the actions over time to prevent banning 
Can you say something more please ?
Soon many resources for django... Thanks though
Thanks I'll check it out, it seems little bit advanced
what topic? anaconda is kind of for "scientific computing", which covers a lot...
Python syntax, using lists etc. Not really Anaconda specific stuff yet
Awesome! Thanks so much for the recommendation!
This is the route I would take. [This tutorial](http://blog.miguelgrinberg.com/post/designing-a-restful-api-with-python-and-flask) on Flask is great.
Looks cool. Just in case you were not aware github [renders notebooks now](https://github.com/beltashazzer/jmpy/blob/master/jmpy.ipynb) so you don't need to link to nbviewer. 
That's a nice new feature. Still takes a bit longer to render, though.
I've been struggling with this problem for a while. No 1000 page intro to python books need apply. My best scheme so far: 1) Guido Von Rossum's 100 page Python Tutorial (free at python.org), followed with 2) a book replete with smart code examples, like The Python Cookbook. This combo won't bore you or waste your time, but should exercise what you've learned well.
too early
&gt; Subscribe to my mailing list and receive a FREE Python naming cheat sheet Uhm...no
Account is full of self-promotion. Fuck off. 
Does cross-referencing mean idenfifying differences? If so, the free notepad++ for windows has a file comparison tool that will highlight the differences between two documents.
http://google-styleguide.googlecode.com/svn/trunk/pyguide.html http://python.net/~goodger/projects/pycon/2007/idiomatic/handout.html tada...no newsletter signup necessary?
backend is in django, if you want to collaborate just pm @github/xadahiya
What is rubbish in it besides this problem?
You can use a class as a function decorator - with __call__ deferring to the wrapped function. 
Personally, I've never used it. But here's an example of a real use-case: [Classes that Act Like Functions](http://www.diveintopython3.net/special-method-names.html#acts-like-function)
Just to clear up any misconception - Anaconda is really just a pre-bundled python distribution. It installs with modules such as Numpy, Scipy, Matplotlib, Pandas and other's bundled. It also comes with a great tool, 'conda' which can manage installing python packages as well as non-python dependencies. Makes working with the stuff way easier on Windows where it can be difficult to find instructions on how to build modules from source and get their dependencies installed correctly. However, if you're using Anaconda, nothing you'll be doing in Python will be any different than if you had downloaded Python on it's own, and used the included tool, pip, to install modules like numpy, scipy, etc individually. Still, I think Anaconda is great because of how it handles non-python dependencies for you.
Is this the 100 page Python tutorial that you were talking about? [Link] (http://marvin.cs.uidaho.edu/Teaching/CS515/pythonTutorial.pdf) I couldn't find it on python.org
Please explain how to apply REST here. RPC would be a way better pattern here. But really, it's an on/off toggle and a color, why would you think in these patterns anyway? I would even forget about XML and JSON, sooo much overhead.
Thanks. I've gone through the intro tutorial for 'conda' where you create new environments, install packages to them, and switch between and delete environments. I didn't know if there was much more to it other than all the packages and dependencies it includes. I love how easy it makes it to switch between versions of Python.
Looks awesome!
Thanks! Have you tried it out?
I haven't yet, but I plan to. I really dig material design
&gt; I haven't yet, but I plan to. I really dig material design Me too. If you haven't found it already, there is a /r/materialdesign. 
The full release of 3.5 doesn't come out until next month.
REST probably doesn't make sense but a simple HTTP api: &gt; POST /led/color/blue &gt; POST /led/on,off Because it could be set up with a super tiny amount of Python code, and any other language could easily interface with it?
Don't know if you've thought of this already, but maybe try virtual environments? It sounds like that's exactly what you want. They can sometimes be a hassle, but they're pretty straightforward.
This belongs in /r/programmerhumor
Thanks for the reply! But I was under the impression that in the case of virtual environments, you can only have one version of Python at a time, and you swap between them with command line calls? I think this works nicely for most user needs... but I'm not sure how to get it to play nice with Jupyterhub, which needs both at once.
Ooh, that's a good idea. Jupyterhub is a complicated mess, so I have no idea if it will play nice. But it's worth a try. Thanks for the suggestion!
I think your question would be more suited for /r/learnpython. You will probably find a lot of helpful functions in the [os.path](https://docs.python.org/3/library/os.path.html) documentation.
There's also [pathlib](https://docs.python.org/3/library/pathlib.html) which was new in Python 3.4.
You can install and quickly switch python versions with [pyenv](https://github.com/yyuu/pyenv). The install path can be basically wherever you want it. It also just installs python from source so you don't have to use the old versions from ubuntu. 
Ya but if the mime-type sniffing fails, it will return None which is a pattern that PyCharm doesn't do great in.
This sounds like it's exactly what I was looking for. Thanks!
The weakref module in python uses them quite nicely. 
We've been trying to avoid using modules because we don't want our userbase to have to muck with them and because our cluster and userbase are both quite small. (Our users are not universally tech savvy.) But in the end we may have to go that route.
 file_path = "c:\Users\Jim\Desktop\Auto Transport Quotes _ (800) 635-3301 _ A Advantage Logistics, Inc_files\cb=gapi.loaded_0" directory_name = file_path.split('\\')[-2] too_long = False if len(directory_name) &gt; 260: too_long = True print "The directory name {} is too long".format(directory_name) else: print "The directory name {} is not too long".format(directory_name) Note that this is assuming that the format of the filepath is always c:/some/path/directoryname/file
I wrote some permissioning code recently that primarily uses functions because the permissions are simple. What permission level is the user? Is the request read only? So simple, you could just use a lambda. But some are more complex. Given this entry point, first find the category it belongs to, then find all the groups a user belongs and if any of those groups gives access to the category, grant access. That's three different things it does. So I wrote a base class that defines two methods: `__call__` and `fulfill` (which is abstract and called by `__call__`). Before some goes Jack Diedrich on me, it's meant to be used when there's a more complex requirement like the above so you can move the "determine category" and "get all the groups" logic into one method and then write just the business logic of determining if the user has access in the fulfill method. This lets me have simple function requirements and complex object requirements side by side that are invoked uniformly.
Well done, I like the layout and straight-forward explanation. But I do feel like it could go a bit more in-depth about what some of those features really have to offer, what makes them such an invaluable inclusion into the budding Pythoners arsenal.
Does [Python on z – for free!](http://blog.rocketsoftware.com/blog/2015/03/03/python-z-free/#.Vdp7gshVi2w) fit your bill?
Python is a great first language to learn, I recommend the Intro to Programming class at Udacity.com It's used in a lot of things, web applications being a major one. I definitely recommend starting with Python if you're completely new to programming. 
Sound like a cool vision.
There is work being done for PySide2 (Qt 5): https://github.com/PySide/pyside2/commits/qt5 https://github.com/PySide/pyside2/issues/1
Python's pretty general purpose. Whether it's good at animation depends on whether someone has done a library of tools for that, and I don't know whether they have. The thing that make Python useful are (a) it's really quick to type something in and run it, and (b) it works on multiple operating systems. In the big project I worked on, we wrote most things in Java, with Python for scripts to start things up and do maintenance type stuff. We had a client program which was written in Java, and a web UI which was written in Flash. And of course there was a lot of SQL in the Java. Most big projects will use a couple of languages, but not too many because finding people who write all of those languages gets increasingly harder.
So programmers learn a lot of langauges or are just very good at 1? 
When I left PHP and Drupal, I did a Ruby and then a Rails online tutorial. I was a bit meh about it, so I did the google python course, which only teaches the basics like indentation, lists, dicts, functions, etc. Then I just jumped into the official Django tutorial. If you don't like Rails, you probably won't like Django. They're both complete frameworks, and you are meant to do things the way they want, and then a bunch of 'magic' happens. Often the hard part isn't learning python, it's learning how to do things the way the frameworks want you to do it. Thus, I moved away from Django. And this is where 'micro-framworks' like Flask fit in. They don't tell you how to do anything. Simply put, the only thing they usually do is get the incomming URL, and work out which function to call for the URL. The rest is up to you. This can make it easier, as it means you don't have to learn much about the framwork, and you can get into making views. The downside is, things like authentication are left to you too, and that's easy to get wrong (but there are often packages you can implement). I personally went with Pyramid over Flask, and I am glad I did. The basic functionality is the same, but Pyramid is more polished with regards to "extensibility", and a few other little things. Edit: another post on topic: https://www.reddit.com/r/learnpython/comments/3i2xys/can_someone_eli5_python_frameworks_such_as_django/
I nearly downvoted you instinctively for the "Get off my lawn" vibe of this comment, but I'm curious and want to give you the opportunity to clarify what you mean. Can you elaborate?
Good programmers know multiple languages by necessity, though they might be very good at only one.
&gt;C++ has a lot of complexity that **won't be helpful right now**. I really like how you put that. A lot of people don't mention that the "complexities" of some languages make them uniquely suited for a lot of things. It's all about learning the right tool for the right task, and Python certainly has all the right tools to help a new programmer do their task: learning.
Muhammad Yasoob Ullah Khalid Wow thats a mouthful, does that come with side of chicpeas and hummus? 
Totally. This is exactly what I've been looking for. Many thanks! 
haha I *just* looked up how *args and **kwargs work today and it's the first chapter. Definitely giving this a read. Edit: your blog [post](http://pythontips.com/2013/08/04/args-and-kwargs-in-python-explained/) is what I was reading earlier today. Weird.
I've been searching for a long time on this, but is there any way to call a python script in a venv shell starting from a Windows batch script (or Jenkins) ? 
Both pretty good to learn with. Python is probably simpler to get up and running with, but I find C++ (11+) is a little more consistent in design of the standard library. C++ will take a bit longer to get set up with and going with, you'll also run into a lot of problems at first that will take a long time just to decipher the error messages of. Both are fun.
This lists each value in a key. It was written quickly and not tested very much. import _winreg def subkeys(key): i = 0 while True: try: subkey = _winreg.EnumKey(key, i) yield subkey i+=1 except WindowsError as e: break def enumValues(subKey): i = 0 while True: try: value = _winreg.EnumValue(subKey, i) yield value i += 1 except WindowsError as e: break def values(key): global keypath # Let later programmers know we were too lazy to pass keypath... i = 0 values = dict() for subkeyName in subkeys(key): try: valueName = r'\\'.join([keypath, subkeyName]) with _winreg.OpenKey(_winreg.HKEY_LOCAL_MACHINE, valueName, 0, _winreg.KEY_READ) as subkey: for v in enumValues(subkey): values[v[0]] = v[1] yield (valueName, values) except WindowsError as e: break def traverse_registry_tree(hkey, keypath, tabs=0): reg_dict = {} key = _winreg.OpenKey(hkey, keypath, 0, _winreg.KEY_READ) for value in values(key): print value[0] + ":" for k, v in value[1].iteritems(): print " %s: %s" % (k, v) print #return reg_dict keypath = r"SOFTWARE\\Wow6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall" print traverse_registry_tree(_winreg.HKEY_LOCAL_MACHINE, keypath) 
Echoing /u/darthmdh - I really recommend conda. You said you were making this cluster for scientists using jupyterhub? Well, `pyenv` is all well and good, but in the end, you're going to end up doing builds of things like `numpy` etc - which is exactly the kind of thing `conda` is meant to solve! `conda` naturally handles both Python 3 and Python 2 within `conda` environments which can easily be configured as individual kernels within Jupyter. You could even naturally support certain scientists/groups having their own kernel that contains any bespoke packages they require!
dam son, I NOPE'ed right back out of there. I could tell something was up when I saw an IP address for the URL.
It's good explanation, but I wish you mentioned that "args" and "kwargs" are simply short-hand terms for "arguments" and "keyword arguments". When I first learned about them, that little piece of information made a lot of sense and made them easier to understand. :)
Same here! docs/www works fine.
For your first problem, I'd look at existing math libraries (numpy, sympy). Play around with them and see if any of them would be useful. If you want to build something in a game format, you will want to use a game library. I don't write games, but I recall seeing a Python wrapper for SDL, I think it's called PyGame. I'd figure out (through tutorials, example code, etc) how to use this library to do some of the building blocks, like opening up a window, rendering graphics, handing keyboard/mouse input. Then with numpy/scipy/sympy/etc see how you can connect the dots. Most development involves working with libraries, so I would recommend learning how to read docs and trying out commands in the python console ASAP. For your second problem, if you haven't finished both tutorials, I'd suggest just finishing them first. Then try building something really simple. Don't overthink it. It can be something like an address book, or a text-based adventure game. Doesn't matter if it sucks. If you run into a problem or get stuck, that's when you get an opportunity to learn a new concept. Often you don't know the point of many concepts unless you actually experience the pain for a problem that a concept solves. Basically, just keep coding.
If you're interested in games check the sidebar for *Pygame* (a Python library that's designed for writing games in Python) and *Invent Your Own Computer Games with Python* (a book about learning Python by writing games with Python and Pygame. The entire content is available for free online as well.)
I'm not sure what he/she had in mind, but I like this one a lot: https://docs.python.org/3.4/tutorial/
Python runs a `__call__` method for function call expressions applied to your instances, passing along whatever positional or keyword arguments were sent. **This allows instances to conform to a function based API.** So this allows us to **code objects that conform to an expected function call interface, but also retain state information, and other class assets such as inheritance.** So this allows you to **register instances as event handlers (a.k.a. callbacks)**. If you want an event handler to retain state between events, you can register an instance that conforms to the expected interface with `__call__`
Cool, I'll check it out too. I really need to go through and see what has changed from 3.1 to 3.5 (I think that's the latest version of 3 now?) In the Dive Into Python book I am going through now it says one of the big differences so far between 2 and 3 is with how strings, bytes and character encoding is done. I'm sure there is other stuff too but that's the only big difference they have talked about yet. 
I really like how practical this looks. Is it inspired by jmp in any way? 
3.5 RC1 has just been released. From [PEP478](https://www.python.org/dev/peps/pep-0478/) the full release is scheduled for September 13, 2015. For some background on how strings, bytes and character encoding is done have a read of this [The bytes/str dichotomy in Python 3](http://eli.thegreenplace.net/2012/01/30/the-bytesstr-dichotomy-in-python-3) and the section headed [Bytes, strings and Unicode](http://python3porting.com/problems.html) 
scanner's is a great idea i've built tiny ones but not a threaded one before. I'll have to try it out Thank you SFS1
If you install pyenv, then you can install anaconda or miniconda (in versions compatible with Python 2 or 3). Unless you're stuck with Windows, working through pyenv is a much better solution than using a manual installation of anaconda (or any other distribution of Python).
@syllogism_ Thanks for your work and the announcement. Can you clearly state which languages you are supporting (and, if possible, you are planning to support in the future) ? From a quick experiment with your online demo, I assume that French is not supported.
Did anyone get a clone of this? I can't find it anywhere now :(
Fastest? Sublime Text w/ Custom Packages A popular choice for a full IDE solution is JetBrains' [PyCharm](http://www.jetbrains.com/pycharm/?fromMenu)
can you make sublime text run you code?
Vim ?
Right, the problem is that pip then mixes Ubuntu and modern python packages. And I'm constrained that I can't do this.
Thanks for these details! I will, of course, have to actually pay for Anaconda Pro. The academic license is free for users, not institutions... and as I'm installing on a cluster, I count as the latter.
This depends on exactly which features you care about. Because python is such a flexible language, IDE features like autocomplete/refactoring require some level of guesswork and can not be correct in every situation. If you determine that you need these features despite their limitations, you'll most likely find that paid IDE's made specifically for Python (like PyCharm) out-perform others. However, if you don't find these tools absolutely necessary, I recommend sticking to a text editor like Vim/Emacs. These editors train you to keep your hands on the keyboard and learn the shortcuts for a wealth of text editing commands that will serve you for every language. You'll get the basics out of the box (auto-indent, syntax highlighting, etc.) and there are plugins available for many other features (error checking, omni-complete, etc.) However, you should take pause before installing them, as they will not only slow down your environment, but they can slow you down too. For instance, omni complete typically requires that you hit a key, move your hands to the arrow keys, look at the list, arrow up/down to get to the proper entry, hit enter, and return hands to home position. This usually ends up being an order of magnitude slower than just typing the word (or typing enough of the word that you know it's unique in the file and hitting ctrl-n in Vim). IDE's are still excellent tools and I completely understand why many people prefer them. If you really care about speed though, you owe it to yourself to try a powerful text editor. The learning curve can be steep, but it absolutely pays off.
Thanks for the recommendation regarding Anaconda!
The fastest one I've used is [Wing IDE](http://wingware.com/). It was created with both Python and C.
I heard about MicroPython on the python podcast [Podcast.\_\_init\_\_](http://podcastinit.podbean.com/e/episode-15-damien-george-talks-to-us-about-micropython/). Check it out if you're interested in hearing an interview with Damien George, the creator of micropython. It is pretty interesting.
Great idea! So, basically, it's picking out a subset of the sentences to keep (show) while deleting the other sentences because they overlap. I like the idea. If you are interested in some feedback where one might (or might not) improve it: 1. Would this overweight longer sentences? Would one prefer "information density" as opposed to "information content" ( i.e. try "information content" / number of words )? 2. Do you treat quoted segments as one word (atomic)? (i.e. perhaps words within quotes shouldn't be scored and/or used for scoring???) 3. Right now, you are just picking specific sentences. It's quite a step up ... and I wouldn't know how to do it myself, but it may be possible to grammatically parse the *information* of a sentence. i.e. Sometimes a sentence says several things. If one could break a sentence down into the sequence of what it says ... those might be a better judge of "overlap" (or duplication). One could then isolate the unique information and create sentences with those. Certainly programs like Watson ( http://www.ibm.com/smarterplanet/us/en/ibmwatson/ ) do that ... and I think that the content parsing ideas are well known (and maybe even implemented in a python library?). Again, I don't know how to do that myself ... but it would be really cool. 
Huh, I find the idea of running Python on extremely powerful systems to be insane... because it's the exact opposite of what extremely powerful systems are built for. ;) Seriously though, it's really easy to get into a situation where minimising development time is far more important than minimising execution time, whatever system you're on. If python is an option that can help with that, great!
In my eyes, Python is a transitional language until we start seeing high level compiled type-inferred languages. Like Go, if it wasn't screwed up. Because if you think about it, development time is the only thing Python is best at, and that kinda really sucks. 
This could probably be a pypi module instead of a pip replacement. I.e. `pip install viewsource` `viewsource django` 
Building math software seems very cool to me. I get to learn the math concept and programming. It's my version of killing two birds with one stone. I also see myself creating software for kids who think math is not useful or way too "hard". I think that programming is the way to go when solving that problem. and your very right about writing shitty code. id rather look up a concept on google that i think will solve the problem instead of look at someone elses code
Can you tell us more specifically what kind of setup you're using? Because with elpy it doesn't work for me.
Yes. Next question?
MicroPython is exactly that - optimizing it for severely constrained systems.
And what if I depend on something like OpenCV, which is not `pip` installable? Or I depend on `FFTW` or `SuiteSparse` or any other of the innumerable packages that a Python C-extension might link to? Which are also not handled at all by `pip`/`setuptools`/`distutils`. I'm totally serious as well! If you have solved this problem using just `setup.py`, in a cross-platform way, please tell me so I can drop my `conda` dependency! Of course, I'm also talking as a package writer, rather than purely as a user. Complex install instructions put people off using Python and in my experience people often end up drifting back to Matlab and R where they are more familiar with everything.
lol yes
i have atom isntalled but i can't find a package with keybindings for things like multiple line comment and stuff
I run a pyboard 1.0 with micropython to interface an electric strike plate to a Weigand rfid reader. It has one job, has been running for 6+ months with no reboots, and it just works. I wouldn't attempt to run it as an alternative to a real time OS, but that's not what it's for.
Any particular reason you didn't use `pip install .` when installing from source, since you've already got pip? 
No, as [Al Sweigart](https://www.reddit.com/user/AlSweigart) has all ready said "Python is the best first language to learn.".
In my particular case, I didn't want to use apt-get and install into the system Python -- I needed an entirely independent environment, hence why I was using virtualenv and virtualenvwrapper.
What I'm saying is: Python is like an experiment in the world of rapid development languages, and static type-inferred languages with rich libraries that aren't just straight based on C are the future, because they are as fast to develop in while providing correctness guarantees, better performance, lower memory footprint, etc.
Well as it turns out, your lack of search results may be due to the fact that the memory layout is nothing special, the magic is in the way it is manipulated. I just found this out by stepping through a debugged process with a memory editor looking at the addresses of interest. The way *Microsoft's Visual C++* handles it (no guarantee of portability between compilers/ABI) looks like this: [Code](http://i.imgur.com/yXXoYnI.png), [Memory](http://i.imgur.com/IpClVDy.png). Red numbers are where each memory snapshot was taken. So as far as I can see, the block of memory being pointed to by an *std::vector&lt;int&gt; is effectively just a struct that points to an array somewhere, with 2 other interesting pointers: { *std::vector&lt;int&gt; self; //A pointer to itself? (Might still work if just left zero/null) int * first; //Pointer to the first address, [0] of an array of ints int * next; //Pointer to the next **free** slot in the array int * last; //Pointer to the last possible address in the currently initialized array } To correlate that with my screenshots: ^(*I HOPE YOU KNOW YOUR HEX AND FUNDAMENTALS OF MEMORY LAYOUT*) 1: When the first value is pushed, an array is created with size 2, at 0x6627C8 (which is our **first**), [0] is set to the value we pushed. Our **next** and **last** are set to address of the next/last slot in the array, [1] (0x6627CC). 2: After pushing two more values, the array is not big enough for the 3 of them, so a brand new array is created with a bigger size and all previous data copied to it; A new array is created with size 4 at 0x662850 (our new value of **first**), likewise our **next** and **last** are set to the address of the last slot, which is now [3] (0x66285C) 3: We pop a value from the vector, we don't need to resize the array, we don't even need to change the actual value stored in the array. All we need to do is decrement **next** (down to 0x662858), so if we push a value in the future, it will just get overwritten. **last** stays the same, as the array has not changed size. Note that our vector now has 2 values in it. We can verify this by subtracting **first** from **next**: 0x662858-0x662850 = 8 8 / sizeof(int*) = 2 Which is why, std::vector.size is a function, and not just a member variable. 4: We pop another value, so decrement **next** again. Array needn't change size. This is purely what I learnt from watching memory in a debugger, depending on how much you wish to implement, you might not care about the actual method of manipulating the individual values, only that they are correct at the time of func() calling, but I thought I'd share what I learnt anyway. You could very easily get away with a simple python interface function, that creates a ctypes int array from a list, and then populates a struct with **first** at [0] and **next**/**last** at the python [-1] addresses. In my brief tests, nulling out **self** between pushes and pops does not cause any readily apparent errors, so you might be able to get away with just leaving it 0. This was a great learning exercise for myself, I hope that I could provide usable info. If anything didn't make sense, just ask and I can try to explain better. You've got me curious in trying out my own interface, I'll let you know if I come up with any result
Fair enough, I wondered if `pip` itself was causing an issue.
The main ones I'm aware of are [Sagemath cloud](https://cloud.sagemath.com/) and [Wakari](https://wakari.io/). You can also create notebooks on Microsofts [Azure Machine Learning Studio](https://studio.azureml.net/). The Jupyter team runs [tmpnb](https://tmpnb.org/), but as the name suggests, it's temporary - there's no persistent storage or user accounts. It's intended for demos and throwaway experimentation. [Jupyterhub](https://github.com/jupyter/jupyterhub) is a set of machinery you can use to run your own hosted notebook service for multiple users.
What is the current status? Is there a plan?
On my systems, pip installs to /usr/lib/pythonX/site-packages by default. apt installs to /usr/lib/pythonX. That's a little too close for my comfort, though.
Excellent work, really appreciate it and that makes perfect sense! I'd still like to figure out what `self` really is, maybe I'll do some playing around and see. As a next step I'll try creating a `vector` from a C `struct` and see if that works, then I'll mess around with a ctypes version. Thanks!
I'm tempted to try and port some of our embedded stack to this just to give it a whirl. However, since there's quite a few c-libraries in our dependency chain, that's been on the back burner for quite a while :(
Cool, I'll take a look at it, I don't know if I'll be able to help but I'll start running and playing with it
Yes and No. Yes, you'll love it. No, you'll hate all other languages. =)
Thank you ! I'm going to fork your repository to keep it handy. I think it may be of use. Of course, you'll get credit in the app if I take it(I'm not one of Those people ;D)
Strong dynamic typing is still dynamic typing, and strong vs weak is about fail-early vs fail-late, rather than correctness guarantees(which is primarily about static vs dynamic, with more available via stuff such as dependent typing). As for what I meant by C-based, it's having a standard library inspired or directly reusing C functionality, such as the math module or a great deal of other things. C was brilliant for its time and it still works, but it's a time for a replacement, and languages certainly should exercise more caution in reusing its conventions.
I know there is a wheel for NumPy, I didn't realize there was one for matplotlib?
What correctness guarantees does static typing give you? All off by one errors eliminated? All buffer overflows eliminated? You sure could have fooled me. By this logic all the proven C and FORTRAN libraries should be thrown away and rewritten in what, precisely? It'll certainly keep the test people in jobs for the foreseeable future. To go back to "time is money", do you intend paying for this?
Make a bug report, perhaps?
Thanks for the input!
Awesome thanks! Would I be able to install additional libraries in Sagemath or Wakari? I noticed that tmpnb doesn't have Basemap for matplotlib.
You know what else sucks? Programming language bashing. If you don't like it. Don't use it. Maybe you think your preferred language has no flaws or would you like and endless debate where people compare the advantages and disadvantages of the different languages? That would be quite old. 
I'll certainly acknowledge that pip doesn't handle these dependencies that are outside of PyPI. However, these dependencies are usually easy enough to install if you're not on Windows. And I'll fully admit that in a Windows environment, anaconda shines. Compiling Python libraries on Windows that include C code can be exasperating ("Okay, which version of Visual Studio do I need to install this time???"). The biggest disadvantage of installing Python packages with a system-level package manager is that virtual environments are not respected (as far as I'm aware...the last time I installed a Python package via `apt-get`, it was installed on the system Python installation).
I think one of the most interesting web framework in python is pyramid. It comes with a strong role based security scheme, and you can use not only routes but traversal as a mechanisms for publishing content.
They definitely optimized both memory usage and performance. Not by multiple orders of magnitude, of course, it's still an interpreted language, but still.
Yup - I think the thing with `conda` is that it feels bit uncomfortable because it took us so long to get people actually using virtualenvs reliably (thankfully Python ships with venv and pip now!), that trying something else seems to confuse the issue. `conda` environments actually act the same as virtual environments, so you have all the benefits (although with very clunky syntax, `source activate ENVNAME` is terrible). `conda` also has the advantage that its just a directory, if it isn't on your path it is totally benign, just `rm` the folder if you want rid of it!
Give the header files to swig, have it generate all the interfaces for you, and be done. :D edit: why downvote? This is exactly what swig was designed for and does, and a solution that has worked for **many** c libraries for me (true, sometimes with a bit of help since c pointers are bad at representing things).
For multi-line comments you can just use the multiple cursor then cmd+/ or ctrl+/ to comment out the lines
I'm going to set this up to remind my wife to take her birth control pills if she didn't push the button the night before. I think the Gerber button would be appropriate =)
omg , thank you so much man! i was using atom.io for a while and never knew
Interesting writeup, nicely documented. Maybe a little note. It seems that what is actually implemented here is more like switching between two oscillators running at (fc+fdev) and (fc-fdev). There are probably phase-jumps when switching symbols (unless the symbol time and fdev is carefully aligned to prevent this) which cause a wider signal spectrum due to the non-steadiness of the phase. In a VCO, the signal m(t) would be integrated (the argument to the cosine is the phase, the frequency is the first derivative of the phase). That could be approximated by a sum like so: y = A * np.cos(2*np.pi*np.cumsum(m) / Fs)
so it fills the same weird niche as .NET Micro Framework?
Probably not the answer you want to hear, but it depends on what you are working on. Search the plugins for your language(s) of choice and try out the interesting ones. Out of the box Python syntax support in atom is superb, but if you're using frameworks check for relevant plugins.
PyCrypto + OpenSSL and curl are the ones that give me a bit of shivers... Not quite enough to just fix our own code for something like this.
A couple of observations: - Don't use "-" in module names. It's an illegal character for names in Python. - Libraries should never use `print()` (unless their purpose is printing). Instead of sending the error message to STDOUT, raise an exception encapsulating the error message instead. By using `print()`, you might break the program using your library (if it sends its own output to STDOUT). Libraries shouldn't do an end run around the calling code (e.g. by calling `print()`, or `sys.exit()`).
thanks for the quick reply and thanks for the sent defcon thing. I run a private lan in my house all virtualized and sitting on many different machines. I appreciate the heads up though
Take a look at this... http://stackoverflow.com/questions/8955869/why-is-plotting-with-matplotlib-so-slow
People at my work have taken the Berkeley extension course for Python. They knew nothing about Python when they started, by the end of it, they were/are fairly proficient. I don't believe it would do much for you outside of your own knowledge though, just being honest.
I chose simplicity over pythony, I think. There's nothing wrong with the use of classes, but what would be the outcome : speed? Readability? What is the upside of using classes?
Does reddit have an award for Quote Of The Week? :)
I know you said no CMS. But without a CMS, you will have to do a lot yourself. From keeping the user session to CSRF protection. Flask is very light weight CMS, that wont bloat your app. I personally use Django, since it come built in with pretty decent admin site. I guess you can also use firebase for user management and authentication ... https://www.firebase.com/docs/web/guide/user-auth.html.
All software has complexity, but for a project (such as this one) that has a LOT of necessary complexity due to business logic, rules, etc. it's especially important to keep any extra complexity to a minimum not only for readability-sake... Object-Oriented code is best suited for a task exactly like this one where you are modeling "real" (er... fantasy?) world objects/entities with attributes, methods, and associations. It's also easier to maintain state inside classes and a lot of this project will be highly dependent on maintaining the state of various object instances. There are also other benefits such as encapsulation and polymorphism allow you to have loose-coupling, solid unit tests, and efficient debugging. If you change a database platform for example you don't want to have to go through 58 methods and update the connection string and if a monster can move, a boat can move, a half-elf can move, a human pc can move unless stunned, etc etc etc... the notion of "moving" can easily be coded abstractly and inherited and extended by classes that require it. That's not to say that readability isn't also important.... example: current_player.characters.get(active=True).can_move(modifier=-4) is a lot easier to follow than a method call alone with a ton of params... or even worse a kwargs that you set discretely somewhere else like, can_move(**bunch_of_random_things).
It is so much fun running this on a $2 ESP8266 ;] 
I don't think I did anything special except enable jedi mode.
I don't really have the time for this at the moment, I'm afraid. But if I can, I'll help out. :)
This is great. Thanks for sharing :) 
The `print()` is a byproduct of where I was originally using it. I intend to remove it and replace with proper Error handling. Thanks for the catch of `-` in module names. I'll fix that. I've update the [issues](https://github.com/KronosKoderS/py-pushover/issues) page with these. 
Thanks for creating a Reddit account to give me an answer! Most appreciated. I'll take another look at Flask - I didn't realize that had user management in it. I'll also reconsider Django, which I thought was still light on the user features for it's size. I was looking at Firebase last night, and wondering if I could use it to avoid creating server-side code at all, and just do everything on the client side. Thanks for your suggestions!
Even better :D
I use https://github.com/graingert/secure-smtplib/blob/master/README.rst
¯\_(ツ)_/¯
It sounds like from reading the comments that this was not just you. But I will say, I have had tons of issues with some pages at work. I do not recall if they were the official python pages, or those for some of the scientific computing stack, but they often failed. What worked was to remove the `s` in `https` so it isn't secure. My guess is that the issue is on my end since my work has SSL interception. So, if you find you have any issues, you're at work where they may do some funny stuff with the connection and it's *not* just you, try that.
Agreed. There is definite room for learning by way of refactoring.
This is very cool, but more explanation would be fun.
It's not an anti-pattern. Postgres is very, very good at handling transactional, multi-threaded logic. I've never had a resource contention, a deadlock, or a race condition using this system, and it's been running smoothly doing it's job for me for years, handling many millions of messages. I've yet to encounter any of these 'serious long-term maintenance issues' that the Wikipedia article mentions. More of a 'serious long term running flawlessly without me having to think about it too much.' If raw throughput was my major concern, i.e. if I were handling more than a few hundred messages per second, I'd consider something else, but I'm not dealing with that kind of volume in this case.
That's a pretty cool idea! Once you've finished that project, you definitely should post the result and the code. :-) I guess you could have a look at [Pillow](https://pillow.readthedocs.org/), the friendly fork of PIL, for resizing and other things like that. Maybe some other modules are more suited to your needs, though.
https://xkcd.com/1319/
[Image](http://imgs.xkcd.com/comics/automation.png) **Title:** Automation **Title-text:** 'Automating' comes from the roots 'auto-' meaning 'self-', and 'mating', meaning 'screwing'. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php/1319#Explanation) **Stats:** This comic has been referenced 210 times, representing 0.2706% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_cueihq0)
Also, atom-ctags is very, very valuable.
Im 17 years old and just starting to have a bit of change in my life. I am thinking of getting into programming. It is late in the school year (not late but I havent applied to any schools yet since I was always unsure). I am thinking of becoming a programmer and making useful apps, this robotics thing was just something fun to know about. Thanks for the link though! Btw, can Python be used for basically anything? Like making apps for IOS and Android etc that can help people in their daily lives or is Java/C++ better for things like that? 
I'm now 27 and started my second study (CS) one year ago. I can tell you: starting with Python is a lot of fun! It can and will be used in many cases and is a very good starting language. But for special uses like apps or robotics, there are "better" or more common used languages like C/C++/C# or Java. But don't think that it is time-wasting to learn Python, just because you want to specialize on games/apps/robotics. If you understand the background/basics of one language, you can adapt this knowledge to a different language. So, don't think it's to late or something. You can achieve with programming whatever you want, if you got the endurance to learn it ;)
For future reference I found a solution that worked for me. It might look long but it works nice and is simple, so long as you can install pygame: #!/usr/bin/env python from pygame import mixer from pydub import AudioSegment import time import constants def convertAudio(audioPath): #path is a string, getting extension substring length = len(audioPath) ext = audioPath[length - 3:] wavPath = audioPath[:length-4]+".wav" #if it's mp3, convert; wav, do nothing; else, cancel if ext == 'mp3': s = AudioSegment.from_mp3(audioPath) s.export(wavPath, format="wav") elif ext == 'wav': pass else: return None return wavPath def playBell(name, t): mixer.init() sound = mixer.Sound(file=name) sound.play() time.sleep(t) mixer.quit() def playPrebell(): path = constants.prebellPath playBell(path,6) def playPostbell(): path = constants.postbellPath playBell(path,18) and constants is a module that I import with my own constant fields
Well that's ironic 
Been away, didn't see any of this. I have a lot of code to test now! o_o Was just playing around to another implementation, a http server and client pair as a test: https://gist.github.com/ericoporto/9389dbd99aae57f85460 Thank you /u/dAnjou and /u/jreid42 :D Anyway, this is the start of a nice notification center that will output to led, lcd(16x2), motd and a log file!
Once you know one coding language you should find it easier to learn another.
&gt;massive archive of art I could download reddit /r/1920x1080 or if anything else use webscraper (spyder or beautifoul soup) for anything else - for the resolution, as /u/eusebe mentioned, use Pillow - wallpaper changer, see cron - for frame, it mean you have to search for another constant size of wallpaper to set easier constant size of frame
Python can do *anything*. And if it isn't fast enough which is rarely the case: drop down into C and/or C++ using the [C Foreign Function Interface (i.e. CFFI)](http://cffi.readthedocs.org/en/).
Sure. 
That's why I stopped trying to automate my work...
There's a balance between dicts and classes, but if it has functionality key to it, code that it should encapsulate, classes are usually better. This is just fundamental OOP though, not Python specific. Dicts are great, but classes are pretty much dicts where you can namespace their data and related code. It's basically a dict with inheritance. Performance wise, you can even declare `__slots__` and all your attributes and it'll consume a lot less memory than a normal class. Performance shouldn't be an issue here though. It's just cleaner looking and much easier to maintain if the code related to that dataset is embedded in the class. Your mileage may vary. There's a lot to clean up here. For example: return life, ac, movement, attacks, damages, number_met, save_poison, save_wands,\ save_paralysis, save_dragon, save_spells, moral, treasure, alignment, xp_value That'd be insane to unpack, and impossible to work with and debug. You have to refactor anything like that. what if you transposed attacks and damages? It'd be very hard to find where that happened. A lot of this code should be moved into its own modules, probably classes for a lot of it. Looking in functions.py, there's a whole set of large npc related functions, which you shoudl probably put into something like npc.py. And `generate_poison`'s whole purpose is to template out a string... Templating text like that should be removed from the game logic. Check out jinja2, maybe make a templates directory for stuff like this. You can just load the template it and render it with a `data` object and reference all your attributes like `{{npc.strength}}`. Display should be decoupled. And the bottom, in the `get_poison_price` function... That's just a huge `if/elif` switch statement that really belongs outside of code, in a data format, like JSON/YAML/XML whatever. You would just load the data when you start the program, and when you modify something like that or add a new poison, you just add it to the data file. Game logic stays the same, regardless of the specific type of poison. There's a lot of stuff that needs to be ripped out of functions.py and moved into their own module, and some things their own class. It's fine to work with data and avoid writing too many classes, but you have to do it clean and right. It has to fit the problem too. You can use a more functional style, but something like this inherently has state (like most games), and structured OOP might better fit the problem. 
Sure, though PySpark lags Scala pretty noticeably. And I think the type system is a huge benefit for data pipelines and ETL. I had initially set out to use Spark via PySpark, but quickly came to prefer Scala.
They're actually pretty strict. Things like Beholders, Mind Flayers, etc are owned by them. Can't be used in games except in what they sponsor. Of course, you'll see the Eye Beast beholder-clone monster in every damn fantasy game out there.
Well for one you can return an easy to work with object instead of a huge tuple, such as you do in get_a_monsters_stats Classes are simpler, more straightforward, more extensible, more reusable, and far easier to read
Fizban, huh? It's nice to see a fellow Weis/Hickman fan. 
The starter kit is out of stock :(
The [Intro to EECS](http://sicp-s3.mit.edu/tutor/6.01) class at MIT is caught by having students program robots in python.
It may be slow on the compilation, but it's both safer and far faster than CPython (barring using code that's not bytecode and calls to C/Fortran libraries), and has a number of concepts that I am really missing in Python now, like Option[T], the implicit modifier, non-crap map/reduce/filter, non-crap lambdas, etc.
Considering it was conceived by the same guy who wrote the the [current generation Java compiler](https://en.wikipedia.org/wiki/Martin_Odersky) it can really be viewed as Java done right, and then some, as he probably had a lot of time to think about the shortcomings of Java.
I am using the original rules (boxes sets from 84) for copyright reasons (I don't think they will shut down this project if it uses rules now freely available). But to please the community, I intend to make it all modular with any RPG you want. First on the line is 3.5e and naheulbeuk.
You can look at .vimrc files on github or just google basic vim setup or vim screencast and You should be good. PS. When you are in vim, press esc, and type this : :enable syntax 
I read all comments, and I agree. The code definitely needs to be more pythonic, more object oriented. I'm going to write an issue about it on github.
I think we've all had enough time to think about the shortcomings of Java...
The 3.5 rules that are on the SRD: http://www.d20srd.org/ Are completely free and open. The only thing these rules don't cover is how to roll for ability scores and how to roll for gold. These rules include hundreds of monsters, all of the base classes and skills, all of the base psionic classes and skills (if you are into that sort of thing), encounters, etc. It's basically the players handbook, dungeon masters guide, monster manual 1 (minus a few things), and unearthed arcana. With a smattering of other things from other books.
https://twitter.com/garybernhardt/status/636052110505672704
Nice tutorial. Thanks for sharing !
It is working now. 
Agreed. Great choices of topics, though!
Fixed. Sorry for any false alarms. ("OMG, did Estonia take over Norway?")
Thanks for letting me know :) 
Stop down-voting good questions neckbeards!
They're finally part of Scandinavia! 
Python will be automatically syntax highlighted in any modern Vim. I would guess you either have something wrong with your install method, or you're not running proper Vim. You should install (if you're in Ubuntu) the vim-gnome or at least vim-nox to get proper Vim, otherwise you'll get a limited vi replacement.
 Python 3.4.3 (default, Mar 26 2015, 22:03:40) [GCC 4.9.2] on linux Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; a = '世界的な株安の連鎖で日経平均株価が一時８００円近く値下がりしたことなどにつ' &gt;&gt;&gt; a '世界的な株安の連鎖で日経平均株価が一時８００円近く値下がりしたことなどにつ' &gt;&gt;&gt; print(a) 世界的な株安の連鎖で日経平均株価が一時８００円近く値下がりしたことなどにつ &gt;&gt;&gt; b = a.encode('utf-8') &gt;&gt;&gt; b b'\xe4\xb8\x96\xe7\x95\x8c\xe7\x9a\x84\xe3\x81\xaa\xe6\xa0\xaa\xe5\xae\x89\xe3\x81\xae\xe9\x80\xa3\xe9\x8e\x96\xe3\x81\xa7\xe6\x97\xa5\xe7\xb5\x8c\xe5\xb9\xb3\xe5\x9d\x87\xe6\xa0\xaa\xe4\xbe\xa1\xe3\x81\x8c\xe4\xb8\x80\xe6\x99\x82\xef\xbc\x98\xef\xbc\x90\xef\xbc\x90\xe5\x86\x86\xe8\xbf\x91\xe3\x81\x8f\xe5\x80\xa4\xe4\xb8\x8b\xe3\x81\x8c\xe3\x82\x8a\xe3\x81\x97\xe3\x81\x9f\xe3\x81\x93\xe3\x81\xa8\xe3\x81\xaa\xe3\x81\xa9\xe3\x81\xab\xe3\x81\xa4' &gt;&gt;&gt; print(b) b'\xe4\xb8\x96\xe7\x95\x8c\xe7\x9a\x84\xe3\x81\xaa\xe6\xa0\xaa\xe5\xae\x89\xe3\x81\xae\xe9\x80\xa3\xe9\x8e\x96\xe3\x81\xa7\xe6\x97\xa5\xe7\xb5\x8c\xe5\xb9\xb3\xe5\x9d\x87\xe6\xa0\xaa\xe4\xbe\xa1\xe3\x81\x8c\xe4\xb8\x80\xe6\x99\x82\xef\xbc\x98\xef\xbc\x90\xef\xbc\x90\xe5\x86\x86\xe8\xbf\x91\xe3\x81\x8f\xe5\x80\xa4\xe4\xb8\x8b\xe3\x81\x8c\xe3\x82\x8a\xe3\x81\x97\xe3\x81\x9f\xe3\x81\x93\xe3\x81\xa8\xe3\x81\xaa\xe3\x81\xa9\xe3\x81\xab\xe3\x81\xa4' &gt;&gt;&gt; c = b.decode('latin1') &gt;&gt;&gt; c 'ä¸\x96ç\x95\x8cç\x9a\x84ã\x81ªæ\xa0ªå®\x89ã\x81®é\x80£é\x8e\x96ã\x81§æ\x97¥çµ\x8cå¹³å\x9d\x87æ\xa0ªä¾¡ã\x81\x8cä¸\x80æ\x99\x82ï¼\x98ï¼\x90ï¼\x90å\x86\x86è¿\x91ã\x81\x8få\x80¤ä¸\x8bã\x81\x8cã\x82\x8aã\x81\x97ã\x81\x9fã\x81\x93ã\x81¨ã\x81ªã\x81©ã\x81«ã\x81¤' &gt;&gt;&gt; print(c) ä¸çç ãªæ ªå®ã®é£éã§æ¥çµå¹³åæ ªä¾¡ãä¸æï¼ï¼ My guess is what you have is a character string containing latin1 interpretation of utf-8 bytes of japanese. If you have the original utf-8 bytes, then you need raw_content_from_website.decode('utf-8'). If you have already misinterpreted these bytes as latin1 for some reason, you'll first have to encode it as latin1 first, to get the original bytes, and then decode as utf-8. There's another possibility altogether - that it's your shell or your browser that are interpreting the text as latin1. Every browser has an encoding menu, that allows you to ask the browser to interpret the text in a specified encoding. In Chrome it's under "more tools". If asking for UTF-8 results in japanese characters, then it's probably not Python's fault. [This](http://www.joelonsoftware.com/articles/Unicode.html) may be of help for future reference.
if anybody wants to contribute or start a new project for the 2014 version
but django is the most used I think, reddit uses something else I heard
Fixed?
Don't do this. It is a bad idea, and will usually result in problems like this unless you do some hacky workarounds. If you really have to, put the variables into a third module and import both from there. But in your case you don't need to do that, you should define the screen width and height when you initialize the ball class, or better yet pass it a `Surface` object (`screen` in your case) when you construct it and have it pull out the properties it needs from that.
Thanks for the response, it helped a lot.
Still awaiting the immanent release of flask 1.0....
Wasn't me ;)
The on-hover share buttons are just horrendous.
What is the difference with xml then? Why is it better to use json? I have already some conficurable config files I can read, won't switching to json be more of a bother than actually an improvement ?
https://docs.python.org/2/library/functions.html#raw_input &gt; The function then reads a line from input, converts it to a **string** (stripping a trailing newline), and returns that
That is what I realized. But then again, I faced a new problem. In the same program, if I further evaluate if input &gt; 0: print "input is positive" As input in earlier program is 12 (and it is a string), can it be compared to 0 (which is a number)? Though output is "input is positive". 
Actually, it seems to have about the same performance as PyPy.. (on 1 cpu)
I wrote a command-line script called [makeSpanningBackground](https://github.com/abarker/makeSpanningBackground) to automatically make (and optionally set) wallpaper backgrounds for multiple monitors. It also works for single monitors. It can randomly select images from a directory of images, rescale them, paste them together for multiple monitors, and optionally set the generated image as the background image. It has a lot of different options that you can select from. It might be worth looking at for your application. The script is all one big file, so you can just copy it where you want. It does require numpy and scipy, though, since I wrote it using ndimage in order to get more familiar with it (and ndimage requires PIL or Pillow). 
del KeyboardInterrupt is trying to remove it from your local namespace, and doesn't try to look it up in any other score, while raise does. See this: In [23]: def foo(): ....: del KeyboardInterrupt ....: In [24]: def foo2(): raise KeyboardInterrupt In [26]: import dis In [27]: dis.dis(foo) 2 0 DELETE_FAST 0 (KeyboardInterrupt) 3 LOAD_CONST 0 (None) 6 RETURN_VALUE In [28]: dis.dis(foo2) 2 0 LOAD_GLOBAL 0 (KeyboardInterrupt) 3 RAISE_VARARGS 1 6 LOAD_CONST 0 (None) 9 RETURN_VALUE to delete it, you'll need to do this: import builtins delete builtins.KeyboardInterrupt
Easy: `del` does something different than what you think. In Python, variables are basically name tags on objects. you can add as many as you want, and only if the last one is gone the object will be deleted. You can remove those name tags in two ways: 1. Make it go out of scope (e.g. by returning from a function in which a variable is defined) 2. use `del`. Example: &gt;&gt;&gt; a = 1 &gt;&gt;&gt; b = a &gt;&gt;&gt; a 1 &gt;&gt;&gt; b 1 &gt;&gt;&gt; &gt;&gt;&gt; del a &gt;&gt;&gt; a NameError: name 'a' is not defined &gt;&gt;&gt; b 1 more complex: &gt;&gt;&gt; class ReportActualDeletion: ... def __del__(self): ... print('I was garbage collected') ... &gt;&gt;&gt; rad = ReportActualDeletion() &gt;&gt;&gt; rad2 = rad &gt;&gt;&gt; del rad &gt;&gt;&gt; del rad2 I was garbage collected Note that `__del__` might actually be executed much later or not at all: maybe the implementation just keeps it in memory because not much is happening and the garbage collector doesn’t have to run or the program exits before it has a chance to.
I'm on mobile and this hurts me: http://m.imgur.com/WilUadU Trying to click on anything with that in the way is impossible.
First things first. I guess (as you use *raw_input*) that you're using Python 2. If you have no particular reason to use Python 2 you should really be using Python 3 (considering that you just want to learn). **Now, to address your question.** First you have to understand how text is represented in computers. Lets assume we use [ASCII](https://en.wikipedia.org/wiki/ASCII) everywhere in your computer, this will simplify things. In ASCII, every character has its own number: A = 65 a = 97 1 = 49 2 = 50 Check out python's [chr](https://docs.python.org/3/library/functions.html#chr) and [ord](https://docs.python.org/3/library/functions.html#ord). So what your program gets is just a list of such numbers representing characters. *raw_input* doesn't care what the numbers are, it just creates a python string out of it. **Why is it that way?** I guess python developers just wanted simplicity. Answer yourself a question: &gt; What *raw_input* should do? &gt; &gt; It should read the input. Nothing more. [Type casting](https://en.wikipedia.org/wiki/Type_conversion) or other magic is definately quite more than that. **EDIT** Also keep in mind that *raw_input* will require extra information on what type to expect: * "12" as int * "12" as string * "36DB" as integer written in [hex](https://en.wikipedia.org/wiki/Hexadecimal) **THE MOST IMPORTANT NOTE** *raw_input* / *input* is not how your program should get its input parameters. We have [argparse](https://docs.python.org/3/library/argparse.html) for that but I realise that it might be too much for a beginner ;)
Here is what I am trying to do (I'll skip your second line in code). my_input = raw_input() if my_input &gt; 0 : print "my_input is positive" This code still output correct results without using the second line in your code. What I want to ask is this: my_input is string and 0 is a number but 'if' statement still evaluates it correctly despite the fact that it is comparing a string (my_input) with 0 (a number). Why so? 
It should just disappear on mobile
Yeah, I don't get the downvotes. This is a good opportunity for learning, the community should be encouraging of these things.
Apart from your professional please score us some useful projects . .
"Requests will automatically decode content from the server." ([*Response Content - Quickstart - Requests 2.7.0 documentation*](http://www.python-requests.org/en/latest/user/quickstart/#response-content)) &gt;&gt;&gt; res_nhk = requests.get('http://www3.nhk.or.jp/news/html/20150825/k10010202691000.html') &gt;&gt;&gt; res_nhk.text &lt;?xml version="1.0" encoding="UTF-8"?&gt;\r\n&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"&gt;\r\n&lt;html xmlns="http://www.w3.org/1999/xhtml" xml:lang="ja" lang="ja"&gt;\r\n&lt;head&gt;\r\n &lt;meta http-equiv="Content-Type" content="text/html;charset=utf-8" /&gt;\r\n &lt;meta http-equiv="X-UA-Compatible" content="IE=edge" /&gt;\r\n &lt;meta http-equiv="Content-Style-Type" content="text/css" /&gt;\r\n &lt;meta http-equiv="Content-Script-Type" content="text/javascript" /&gt;\r\n &lt;meta name="copyright" content="æ\x97¥æ\x9c¬æ\x94¾é\x80\x81å\x8d\x94ä¼\x9a" /&gt;\r\n &lt;meta name="title" content="æ°\x91ä¸»ã\x83»ç´°é\x87\x8eæ°\x8fã\x80\x8cçµ\x8cæ¸\x88ç\x8a¶æ³\x81 ã\x82¢ã\x83\x99ã\x83\x8eã\x83\x9fã\x82¯ã\x82¹ã\x81®é\x99\x90ç\x95\x8cã\x80\x8dã\x80\x80NHKã\x83\x8bã\x83¥ã\x83¼ã\x82¹" /&gt;\r\n(...)' &gt;&gt;&gt; res_nhk.encoding 'ISO-8859-1' The above means the requests library fails to guess about the encoding of the content from the server. &amp;nbsp; "If you change the encoding, Requests will use the new value of r.encoding whenever you call r.text." ([*Response Content - Quickstart - Requests 2.7.0 documentation*](http://www.python-requests.org/en/latest/user/quickstart/#response-content)) &gt;&gt;&gt; res_nhk.encoding = 'utf-8' &gt;&gt;&gt; res_nhk.encoding 'utf-8' &gt;&gt;&gt; res_nhk.text '&lt;?xml version="1.0" encoding="UTF-8"?&gt;\r\n&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"&gt;\r\n&lt;html xmlns="http://www.w3.org/1999/xhtml" xml:lang="ja" lang="ja"&gt;\r\n&lt;head&gt;\r\n &lt;meta http-equiv="Content-Type" content="text/html;charset=utf-8" /&gt;\r\n &lt;meta http-equiv="X-UA-Compatible" content="IE=edge" /&gt;\r\n &lt;meta http-equiv="Content-Style-Type" content="text/css" /&gt;\r\n &lt;meta http-equiv="Content-Script-Type" content="text/javascript" /&gt;\r\n &lt;meta name="copyright" content="日本放送協会" /&gt;\r\n &lt;meta name="title" content="民主・細野氏「経済状況 アベノミクスの限界」\u3000NHKニュース" /&gt;\r\n(...)' &amp;nbsp; Or you can also access the response body as bytes and decode it yourself. ([*Binary Response Content - Quickstart - Requests 2.7.0 documentation*](http://www.python-requests.org/en/latest/user/quickstart/#binary-response-content)) &gt;&gt;&gt; res_nhk.content.decode('utf-8') '&lt;?xml version="1.0" encoding="UTF-8"?&gt;\r\n&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"&gt;\r\n&lt;html xmlns="http://www.w3.org/1999/xhtml" xml:lang="ja" lang="ja"&gt;\r\n&lt;head&gt;\r\n &lt;meta http-equiv="Content-Type" content="text/html;charset=utf-8" /&gt;\r\n &lt;meta http-equiv="X-UA-Compatible" content="IE=edge" /&gt;\r\n &lt;meta http-equiv="Content-Style-Type" content="text/css" /&gt;\r\n &lt;meta http-equiv="Content-Script-Type" content="text/javascript" /&gt;\r\n &lt;meta name="copyright" content="日本放送協会" /&gt;\r\n &lt;meta name="title" content="民主・細野氏「経済状況 アベノミクスの限界」\u3000NHKニュース" /&gt;\r\n(...)' &amp;nbsp; In addition, you need to specify the encoding when you save/read a file with multibyte encodings. &gt;&gt;&gt; with open("nhk.html", "w", encoding="utf8") as f: ... f.write(res_nhk.text) # or f.write(res_nhk.content.decode('utf-8')) ... 10045 &gt;&gt;&gt; with open("nhk.html", "r", encoding="utf8") as f: ... nhk_text = f.read() ... &gt;&gt;&gt; print(nhk_text) &lt;?xml version="1.0" encoding="UTF-8"?&gt; &lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"&gt; &lt;html xmlns="http://www.w3.org/1999/xhtml" xml:lang="ja" lang="ja"&gt; &lt;head&gt; &lt;meta http-equiv="Content-Type" content="text/html;charset=utf-8" /&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge" /&gt; &lt;meta http-equiv="Content-Style-Type" content="text/css" /&gt; &lt;meta http-equiv="Content-Script-Type" content="text/javascript" /&gt; &lt;meta name="copyright" content="日本放送協会" /&gt; &lt;meta name="title" content="民主・細野氏「経済状況 アベノミクスの限界」 NHKニュース" /&gt;(...) &amp;nbsp; By the way, why does the requests library fails to guess about the encoding of the response? "When you make a request, Requests makes educated guesses about the encoding of the response based on the HTTP headers." ([*Response Content - Quickstart - Requests 2.7.0 documentation*](http://www.python-requests.org/en/latest/user/quickstart/#response-content)) &gt;&gt;&gt; res_nhk.headers {'etag': '"11945e4-2bdd-51e1ab4ed81d7"', 'connection': 'keep-alive', 'date': 'Tue, 25 Aug 2015 11:50:21 GMT', 'last-modified': 'Tue, 25 Aug 2015 03:55:37 GMT', 'access-control-allow-origin': '*', 'access-control-allow-methods': 'GET, POST', 'access-control-allow-headers': 'Origin, X-Requested-With, Content-Type, Accept', 'content-length': '3065', 'server': 'Apache', 'accept-ranges': 'bytes', 'vary': 'Accept-Encoding', 'content-type': 'text/html', 'content-encoding': 'gzip'} &gt;&gt;&gt; res_yahoo = requests.get('http://www.yahoo.co.jp/') &gt;&gt;&gt; res_yahoo.text '&lt;!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd"&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;meta http-equiv="content-type" content="text/html; charset=utf-8"&gt;\n&lt;meta http-equiv="content-style-type" content="text/css"&gt;\n&lt;meta http-equiv="content-script-type" content="text/javascript"&gt;\n&lt;meta name="description" content="日本最大級のポータルサイト。検索、オークション、ニュース、メール、コミュニティ、ショッピング、など80以上のサービスを展開。あなたの生活をより豊かにする「ライフ・エンジン」を目指していきます。"&gt;\n(...)' &gt;&gt;&gt; res_yahoo.encoding 'UTF-8' &gt;&gt;&gt; res_yahoo.headers {'set-cookie': 'B=3oluv9patomrr&amp;b=3&amp;s=mo; expires=Fri, 25-Aug-2017 12:11:39 GMT; path=/; domain=.yahoo.co.jp', 'p3p': 'policyref="http://privacy.yahoo.co.jp/w3c/p3p_jp.xml", CP="CAO DSP COR CUR ADM DEV TAI PSA PSD IVAi IVDi CONi TELo OTPi OUR DELi SAMi OTRi UNRi PUBi IND PHY ONL UNI PUR FIN COM NAV INT DEM CNT STA POL HEA PRE GOV"', 'connection': 'close', 'date': 'Tue, 25 Aug 2015 12:11:39 GMT', 'cache-control': 'private, no-cache, no-store, must-revalidate', 'server': 'nginx', 'expires': '-1', 'pragma': 'no-cache', 'content-length': '6469', 'vary': 'Accept-Encoding', 'x-frame-options': 'SAMEORIGIN', 'content-type': 'text/html; charset=UTF-8', 'x-xrds-location': 'https://open.login.yahooapis.jp/openid20/www.yahoo.co.jp/xrds', 'content-encoding': 'gzip'} 
I wish it did! Oneplus One here. I can give you more device details if you like. But it is unusable for me on the mobile site. Even if I request the desktop site it is there and in the way.
Open a Python interpreter. Now try this: "12" &gt; 0 "-12" &gt; 0 "fish" &gt; 0 "fish" &gt; 3 "" &gt; 3 Any string is evaluated as greater than any integer. Why? From the [documentation about built-in types](https://docs.python.org/2/library/stdtypes.html): &gt; Objects of different types, except different numeric types and different string types, never compare equal; such objects are ordered consistently but arbitrarily (so that sorting a heterogeneous array yields a consistent result). and &gt; CPython implementation detail: Objects of different types except numbers are ordered by their type names; objects of the same types that don’t support proper comparison are ordered by their address. In summary: objects of different types are comparable so that sequences which contain different kinds of objects can be sorted. Objects which can't be compared in any sensible way are compared according to the names of their types. So any **s**tr is arbitrarily declared to be bigger than any **i**nt. This doesn't apply to different numeric types. You can compare integers and floating point numbers. But comparing integers and strings is completely meaningless. So don't do it.
Another very good reason to move to Python 3. C:\Users\Mark\Documents\MyPython&gt;py -3.4 Python 3.4.3 (v3.4.3:9b73f1c3e601, Feb 24 2015, 22:44:40) [MSC v.1600 64 bit (AMD64)] on win32 Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; "12" &gt; 0 Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; TypeError: unorderable types: str() &gt; int() &gt;&gt;&gt;
I use it daily in production and have for over a year. 
Thanks for this suggestion. I think I better move to Python 3. It would have saved me from this confusion.
How difficult of a task is it to load MicroPython onto the ESP8266? I have 6 of them and would enjoy trying that out with one. Can I interact with sensors normally?
this is amazing, thank you so much!
Do you find administering the engine (managing resource usage, killing stuck jobs, etc) reliable? 
&gt; like calling __getattribute__, exactly in accordance with the docs I was aware, as mentioned, why this code does what it does. Just found it funny what can cause repeated access to the same attribute. &gt; So what you actually want to do is to clear the stored exception unless you're looking up exactly the stored exception But that's not possible in practice, because you would not know the name(s) of the attribute in advance. &gt; I'm vaguely surprised that __getattr__ is still a thing in Python 3 - especially when the docs for it still say Good to know this was fixed in Py3, at least. &gt; If you just implement everything you need in __getattribute__ (or maybe via property or other descriptors) you shouldn't ever need to worry about __getattr__ and its exception-swallowing behaviour. Yep, getting rid of `__getattr__` and move the logic in `__getattribute__` seems to be the sanest solution. However if you are working with 3rd party modules where is defined, you'd probably need recourse to some kind of monkey-patching unfortunately. Just another mine in the minefield need pay attention to.
/r/learnpython
/r/learnpython
[CodeAcademy](https://www.codecademy.com/) has always helped me get back in the groove. 
I've tried to give Atom a shot, but there are just so many better options. I use PyCharm for longer sessions and SublimeText to quickly check something out.
SublimeText with plugins is lightweight and fast, there are other lightweight solutions like Atom or Brackets. But there are lacking in features compared to full-fledged IDEs like PyCharm. Personally I use both PyCharm and SublimeText. Whenever I want to quickly test something with two lines of code I use SublimeText, but when I know I'm gonna spend more than a couple of minutes with Python, I fire up PyCharm.
it also doesn’t have both `input` and `raw_input`. ## Python 2 * `input` → read input, convert it to int, float, ... automatically (BAD IDEA) * `raw_input` → read input, return string ##Python 3 * `input` → read input, return string
Nope.
k
It's been reliable, though not particularly enjoyable. We do take care to make sure Spark tasks are idempotent so when we need to re-play something it's as easy as restarting and checking that the inputs are right. Killing jobs is pretty straightforward either through the UI or, uh, if you're brave, via ssh. This hasn't really been a problem for us so we haven't worried too much about having some process handle that automatically. Azkaban auto-kills workflow tasks that take too long. Resource management hasn't been too much of a problem either. For us, it's mostly been a matter of getting the configurations right (which has sometimes been really frustrating, but stable once in place). 
&gt; `1431486313010` &gt; I don't know what the 2nd item represents. Let me know if you are able to figure it out. Unix epoch time in ms.
The code it generates is certainly pretty hard to read, so on some level yes. But the [bits it doesn't implement](https://github.com/csvoss/oneliner#not-implemented) are going to crop up in almost any real world program. Besides, if it was used as an obfuscator on any scale, I'm sure someone would write a de-obfuscator. People have gone to much greater lengths when doing reverse engineering.
I had no idea that this data was made publicly available! Thanks for sharing!!
It's usually a code smell. But I had the same issue with cross dependent modules that normally would be combined into one, but were separated for maintainability. Example: # a.py b = None def load_b(): global b import b as _b b = _b return b # something from a to share value = 2 def calculate(): return (b or load_b()).value + value # b.py import a ....
&gt; If the analysts can't read code then they shouldn't be in the code. The point is that with python you can generate documentation from docstrings, as well as invite users to look at the code when the docstring-generated docs are insufficient. Especially if you've written your transformations with this in mind. By doing so you eliminate an enormous amount of documentation that should otherwise be provided, maintained, reviewed, etc, etc, etc. Alternatively, you could treat the ETL process like a black box and not explain transformations to users. A lot of shops do it. But that's usually an awful idea.
Yes! Keep in mind that virtualenv only manages Python packages themselves and, so it really is the wrong tool when those packages depend on compiled code, system libraries, and other more complicated pieces. Conda handles *all* of these dependencies, and so is nearly always the better choice when using matplotlib, numpy, scipy, etc.
The matplotlib install depends on pre-installation configuration to point to your particular system's graphics backend, and so ``pip install`` will generally fail.
They use 6 cameras to keep track of all the player movement. [Here's](https://www.youtube.com/watch?v=jOQEl_tkEwE) a clip of the camera system in action.
Hi there. You have posted a beginners question to /r/python, however it is far more suited to /r/learnpython, where users are actively interested in helping with beginner topics. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Cheers &amp;amp; best of luck!
damn, i was kind of hoping you were using video and open cv; not that this is any less awesome. thanks for sharing.
That's freaking awesome. Excellent post overall. 
Heh, my publisher is me and /u/audreyrg/. Any SEO problem is us. :/
I'd be so happy if similar data sets for soccer were available
Currently the API doesn't have a python package just yet that you can install through pip or easy_install but if you want you can clone the repo and install yourself using the setup.py! Documentation is coming soon too! I'd also love to hear some feedback since this is my first python package ever!
I wouldn't worry about it. I was just looking for somewhere to place the blame on that wasn't me. ;-)
k
emacs24
This is actually the best example of all listed here...
This is a nice summary of `[t + '-comprehensions' for t in ['list', 'dict', 'set']]` but he seems a little bit too opinionated about higher-order functions. `map`, `filter` and `reduce` may be a bit complicated for the uninitiated, but once you comprehend list comprehensions and anonymous functions you also get these. Also: rimshot.
We are in agreement. What I originally thought you said and what you actually said were two different things.
It's definitely awesome how data collection and processing is growing in sports. This is a very relevant recent TED talk: https://www.youtube.com/watch?v=66ko_cWSHBU On the academic side of things, I've been seeing a lot of papers and work applying machine learning and computer vision to these sort of data. Things like pose estimation with deep neural networks and other goodies. Definitely wonderful to see the sport side doing their part to provide more data. It's definitely the way of taking sports to the next level and improving plays.
To add to your addition that added to the list: A lot of *implicit* loops (`map()`,`reduce()`, etc.) in Python are more efficient than a Python `for` loop/list comprehension by being optimized in C.
A good tip when learning comprehensions, or simply making them more readable, is to wrap them: [n * n for n in nums] This technique helps more as code becomes more complex. The following would look horrible on a single line but is pretty neat when wrapped: [line.lower()[::-1] for line in file_obj if not line.startswith('_')]
Lego mindstorms robotics kit can be programmed in python. Great way to understand the principles of robotics.
I think the latin1 default is in the http spec
Naming is not nearly as consistent, with '.' often used in lieu of a space in a name, rather than denoting a class method.
I always just remove that from my sphinx templates completely.
I am currently in class, but its simply a loop that pulls a line of text (ip address) and transfers a file to that PC. It can not be modified to do what I need it to do.
I prefer to use virtualenvwrapper. I've not had any issues, but I know everyone has different environments and experiences with it. I use pyenv-virtualenvwrapper
HA! That's embarrassing. Those aren't even remotely the same word. I must hang out too much at /r/personalfinance
http://www.isitdownrightnow.com/pip.openplans.org.html Down for EVERYONE at time of posting.
Maybe because it wont be in the repos till the final release?
I'd recommend sanitizing your SQL input. Also, you should use parameterized queries.
I think nakovet was asking IronManMark20 what major feature of 3.5 (regardless of alpha/beta/rc/final) will make him start using Python 3 for his main work.
I used to use virtualenvwrapper / burrito but I recently starting using direnv and honestly never want to use the former again. It's a pretty cool project, just add a .envrc to your project (with 1 line defining the layout) and it creates a virtualenv tied to your directory that gets auto activated/deactivated when you enter or leave the directory. The virtualenv is also siloed to the directory structure so the virtualenvs don't go flying off into nowhere. [direnv](http://direnv.net/) 
Just switch now. Python 3 rocks.
I have been meaning to switch, but my Python 3.4 install was messed up, so I was waiting for 3.5 stable.
This is the best I was able to do without using `set_event_loop`. It breaks other callers :( https://gist.github.com/oconnor663/f0ddad2c0bd1f7cf14c2
Would [parallel rsync](https://github.com/robinbowes/pssh/blob/master/bin/prsync) work?
[Data Camp](https://www.datacamp.com/) take u through the basics and some advanced shit.
I thought this was going to be something involving the python imaging library. haha
At last, my application will be finished when I get this last line of code written......
You are missing the point. Software adoption tipping point is rarely rational (although they will try to find hard a rational answer to give to you), and highly emotional. 3.5 features are fantastic for PR : - syntaxic sugar for async (people finally understand the feature) - type (so much troll on typing that everybody is talking about it) - @ et unpacking generalization (new sexy toys. We love toys.) - %-formatting" for bytes and bytearray objects (the biggest annoyance of Python 3, finally gone. The suspens was killing us). It's like a xmas commercial, without the naked models all around since Python si familly rated. Hence everybody is excited.
Your 3.4 code will work with any future 3.X release, including 3.5. So don't worry, you can safely keep 3.4. 3.5 is just very cool.
Wouldn't the https://www.reddit.com/r/rlanguage be better to ask this question? Since you're asking about R, there might be veteran over there that remembers their early gotchas.
They just add features and changes between 3.* versions. You just stick to learning and once you're done you can look through the version changes and features add from blog/articles. Most of these features aren't game changer and won't do much for you they're more of a convenient or another way of doing it. Game changer are major version changes like Python 2.x to Python 3.x
Try https://pythonspot.com 
thanks! interesting post
Hey, founder of ShareLaTeX (and now DataJoy) here! Let me know if you have any questions :)
Hi! Question: I have no idea what this software is actually about, and the website does not explain it either. Is this a cloud-based IPython notebook installation? OTOH the screenshot somehow resembles RStudio, so I'm leaning towards assuming this is some sort of IDE? That runs in your browser? If so, 1. how does it differ from IPython notebook? 2. why is there no online demo for me to try out?
[Internal Server Error](http://www.filmtvsearch.net/cgi-bin/main.py/moviesearch/I'll&amp;be&amp;back/All/2000/2015/1) suggests you're not escaping something somewhere. If you're not using a sanitising and paramaterising queries you really, really, really should. Really. Have a look [here](http://bobby-tables.com/), Python examples via the left sidebar.
Did you seriously just post a *photo* of code? Ha. Anyway, the errors (and specifically `Syntax error: word unexpected (e`) suggests the file is not being executed as Python. Possibly it's running as a [Makefile](http://stackoverflow.com/questions/21226905/syntax-error-word-unexpected-expecting) or [shell script](http://unix.stackexchange.com/questions/45781/shell-script-fails-syntax-error-unexpected)? What happens if you type `sudo python ./checkmail.py`? What does `/usr/bin/env python` point to?
Here's a lightning talk Graham and I gave at PyDataLondon a month back on "why you should move to Python 3(.5)", it is only a few slides and notes some libraries that are now Py3-only amongst other benefits: https://gmarkall.github.io/py3lightning/#1
X-Post referenced from /r/programming by /u/FiloSottile [Building Python modules with Go 1.5](https://www.reddit.com/r/programming/comments/3ieijy/building_python_modules_with_go_15/) ***** ^^I ^^am ^^a ^^bot ^^made ^^for ^^your ^^convenience ^^\(Especially ^^for ^^mobile ^^users). ^^[Contact](https://www.reddit.com/message/compose/?to=OriginalPostSearcher) ^^| ^^[Code](https://github.com/papernotes/Reddit-OriginalPostSearcher)
[Here's](https://speakerdeck.com/pyconslides/python-3-dot-3-trust-me-its-better-than-python-2-dot-7-by-dr-brett-cannon) a talk from a Google engineer calling bullshit. Now that's from 3.3, but I highly doubt they tanked speed in 0.2 versions.
Are these search results from subtitles?
You'll have a better chance of getting this answered over at /r/learnpython. 
Is there a list of libraries that come pre-installed? Is it possible to install others (like seaborn)? EDIT: I see it uses the anaconda libraries. Is there any way to use Python 3?
Shame, I'm not willing to sign up to something just to have a try. Maybe you could put up some more screenshots or a video or at least a list of features or something so people can have an idea of what your program actually does / makes possible?
Yes, we use the IPython kernel in the background, but the front-end is more like an IDE. We're looking at adding notebook support though.
Yes :) https://www.getdatajoy.com/blog/2015/08/17/python-3-available.html We'll hopefully get this added the UI soon so that's just a one-click process.
neat, looking forward to it!
That was my estimated guess as well. Unfortunately I am not able to test this until I get home tonight. The python path is probably not the one stated in the script. 
Test Automation (Selenium with Python)
This looks perfect. I'm looking at some small &amp; simple python functions I'd like to speed up and have been thinking about rewriting them in Go. What's the best way to package the Go library with a Python package?
Sublime Text loads the fastest (it's sick how fast it loads up) for a GUI app, Atom loads quickly too. I've been facing the problem of choosing the right editor or IDE for Python. I've tried A LOT. Here's some that I tried: Atom is good with plugins, except for hinting. One of the auto-complete plugins (autocomplete-plus-python-jedi) dumps the parameter names when you select a function from auto-complete, so there's at least that. It's not ideal, but it works. I found that auto-complete would stop working after a few hours and I'd have to restart Atom to get it working again. PyCharm annoyed me with it screwing up indenting when copy and pasting divs within the same HTML document. Also, it doesn't provide support for CSS. I know CSS very, very well, but I want a product that supports Python, HTML, CSS, and JavaScript. PyCharm supports 3 of those. I love SublimeText except that it's not smart at all when it comes to auto-complete. It provides a list, of course, but the list includes things that make no sense because it just doesn't understand. And that's with the help of plugins. Maybe I wasn't using the best ones. VIM might be awesome and I did have Python autocomplete working and it looked great but for me I felt less productive using it. I like to mouse click tabs to switch between documents. I'm not done with VIM yet, maybe I'll like it better at some point after using it a lot more. Currently I use Komodo Edit, which is free. Auto-complete is really good, like as good as PyCharm as far as I can tell. It supports Pep8, linting, etc. It can strip out extra white space when saving documents. The only thing it's missing for me is the ability to see the structure so I can easily jump to specific parts of the code. That feature does exist in their paid version, Komodo IDE. I don't need a debugger, but that's also in their paid version. Start up time is ok. It starts up a lot faster than PyCharm.
Easy_install was giving the same error (also pulls from pip.openplans.org I'm guessing). I downloaded the source and successfully installed. 
Robotics might be interesting to you. Or a coffee machine that brews coffee automatically based on when you wake up.
thanks! glad you enjoyed it.
Sweet, I was just playing around with the NBA stats recently too! I was focusing more on historic boxscores, but we have some overlap. [Here is what I have so far](https://gist.github.com/joehand/6ba4cf0e157e61f0a7f1). I'll dig into yours a bit more later. How are you automating finding API endpoints? I was thinking about setting up a headless browser to find all of them... (there are a lot...) 
How?
awesome! Improve my chances of seeing the Cal Bears actually win a game. :). 
The core programmers are committed to keeping Python as fast as possible. I've seen perfectly functional patches on the [bug tracker](http://bugs.python.org/) turned down as they're in critical parts of the core and would slow things by just a fraction.
The automated way I thought about was to crawl the stats.nba.com pages and record any xhr requests then save them with base URL and Parameters. Then look for any internal links and visit those pages. That should get all the URLs and various parameter options. Since they all come through JS ajax requests you need a headless browser. I can't remember what Python packages can be used for that (maybe there is a python selenium package?).
This is a great idea. Any heads-up on why it doesn't work for all cases? I have only two script files of R and several data files. In any case, I need to use 'rpy2' to import the data files, whether run in Numpy or R via rpy2. 
I use Python mainly for scripting things at work... mostly spreadsheet stuff. Kinda boring, but it's way less boring than manually removing duplicates or copying rows that meet a certain criteria over to another file. So maybe not interesting, but certainly useful. 
But [is it worth the time](https://xkcd.com/1205/)?
You might also look into Fabric: http://www.fabfile.org/
Someone's sense of humor regulator needs calibration... The precise command has been stated in my original post. Try reading again, maybe try squinting your eyes. Errors? Well once again read my original post... I have no errors! just returns with the "Press any key" prompt. Thanks for not helping (or probably even reading my original post) but at least you have helped me start my day with some good humor. Thank you for that ; ) Since my original post, I have tried using pip on an old windows laptop of mine, I was able to install splinter successfully with the same command. Since I have your attention tho, I have a question for you (or anyone else). So I am making this script for work (which includes splinter as a lib). I will have to distribute this script to a couple of coworkers. I am trying to figure out what most efficient way to distribute this script. Meaning the way that requires least installs and admin privileges. Ideally I would like them to just have an icon on their desktop which they can click and get a gui (the gui i will be working on too). So any recommendations? 
Yeah, me too. I've spent the past 15 minutes looking for it.
I'm pretty sure stadiums have those motion sensing cameras installed but I don't think the data are freely available. Soccer data in general are hard to get to.
Ansible
Yup, I've tried looking around for cheap APIs as well. Had to resort to scraping in the end.
Is this your subtle way to tell reddit you don't care about ncaa football?
https://code.google.com/p/nxt-python/ https://github.com/topikachu/python-ev3
Hi, you can use the [subprocess](https://docs.python.org/3.3/library/subprocess.html) module, or simply `os.popen` / `os.spawn` depending on what you need. Alwo, you may want to ask /r/learnpython next time ;-).
Hug.put / post are better examples for sure. GET methods should still be able to accept post data, but generally not recommended
The talk and slides you linked say something different, to be honest. The guy actually says that Python 3 is faster somewhere and slower somewhere else and he explicitly states that Python 3 is the same as Python 2 once the median result is considered. Could be faster or slower depending on your usage pattern. 
Can you ELI5 why someone would want to use this/what it's for? I am a scientist and fairly new to programming and python.
I never said you **have to** use my cheat sheet. If you don't want to sign up, you're completely free to do so...
Hi there. You have posted a beginners question to /r/python, however it is far more suited to /r/learnpython, where users are actively interested in helping with beginner topics. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Cheers &amp;amp; best of luck!
With Exxcel ?
Text CSVs, to be precise, but same difference really.
The weirdest thing I've found so far (besides the indexing madness) is the "class()" means "type()" in R. Also, for NumPy, R by default goes column-wise. 
http://inventwithpython.com/
Thanks for calling me a smug hipster. Makes me feel all warm and happy inside. Shows that even a tiny European team doing their best with few resources can build stuff that is as pretentious as anything coming out of the Bay Area. But seriously. ZeroMQ is really simply to use, and a lot of that is because it hides things like IP addresses and connect/disconnect events (both of which you can get if you need them BTW). Look at a pub-sub network. It really cannot be any simpler than the way ZeroMQ does it. The difficulty is that if you're doing real distributed work (and you can dismiss this as "pretentious cloud" yet what do you do when you have 1,000 computers in your home and you want to ask them all, "which of you needs recharging?") the traditional models of TCP and HTTP stop working. We built ZeroMQ based on lots of experience making large projects for banks and investment banks. I apologize for that, I guess we enabled a lot of bad behavior... yet the goal was to learn how to make really large distributed systems, and teach this to open source communities. I think we did that. I'm proud of the work we did, with no VCs or enterprise sponsors or angel investors. It's a model of how to do open source right. If there's something you want in the software we built (and gave to others for free) you can send a patch (we will merge it) or offer money (someone will make it) or wait. Your rant shows a fourth option that surprisingly few people ever chose. Congrats for being original!
- "*easier to write*" - This depends on the person who writes it of course. But for me that is true. I can't code C, but I can develop in Golang. - "*retaining same speed*" - I guess C would be a bit faster.
I considered at some point to generate `ctypes`-based modules, but the deployment story of `ctypes`-based modules is a bit more convoluted than a "simple" C-extension module. having said that, supporting `pypy` would be great. I have filed https://github.com/go-python/gopy/issues/48 to not forget about this.
Shit okay, thanks for pointing that out!
DAE NOT LIKE SPORTS?
PyPy now uses vector instructions on Numpy arrays and, as such, is faster.
By using special instructions enabled on modern processors called [SIMD](https://en.wikipedia.org/wiki/SIMD) (Single Instruction, Multiple Data) that allow a single processor instruction to do things to multiple pieces of data at the same time, PyPy has sped up many array operations very significantly. This is particularly important to NumPy, which tends to use arrays a *lot*.
Thanks for answering my question and not just down voting for no reason.
[C **would** be a bit faster than Go](http://benchmarksgame.alioth.debian.org/u64q/compare.php?lang=go&amp;lang2=gcc), that's true. However, it's at least in the same order of magnitude as C whereas [Python consistently takes well over 10x longer to execute](http://benchmarksgame.alioth.debian.org/u64q/compare.php?lang=python3&amp;lang2=gcc). In my own experience, it isn't uncommon for Python code to run 50x slower than corresponding C and 20-30x longer to execute than either Java or C#; but that's just me. In short, this is a great option for new Python modules and C-compatible libraries in general!
I'd never vote on a site such as this, it's way too open to abuse from the stupid idiots. My all time favourite was on SO. "Why have you down voted my perfectly good answer?". "Because it's not the one liner the OP asked for".
How so?
This looked really promising in the beginning, but the dependence on mongodb rules it out for me
http://unix.stackexchange.com/questions/84160/running-python-on-chromeos 
Time on site required? Length of contract? Expected team role?
 $ yolk -H yolk3k Launching browser: https://github.com/myint/yolk
*sigh* Beginner tutorials belong on /r/learnpython , thank you very much 
Things I need: - no scrum/daily standups - I can work independently, without pairing - space is not an open office floor plan 
Pypy is pretty awesome. I always benchmark my project Euler stuff in Python 3.4 and PyPy 2.4 (v3). Some of the algorithms are so simple that the jit in Pypy actually makes total execution time slower. However on some of my Euler problems Pypy is nearly 10 times faster. SIMD support is going to be awesome!
Why is mongo needed? I usually scrape to CSV for processing later.
Mongo is only needed to do their demo
What advantages do scrapping frameworks provide? I've never used them so far and frankly speaking I don't know what they are able to improve while Python offers such a great toolbox for that purpose.
Do you have an escape route if needed, what is the overall package and do they have a rota for fetching the tea or coffee?
Scraping framework solves a number of issues: * provides you a way to structure your scraping code * provides you tools to extract data from downloaded web documents * provides you tools to effectively retrieve web documents in multiple concurrent network streams
vcvarsall.bat is a Visual studio compiler for python i think. I get a compile time error when i try to install flask-mysql, so in my case ive got the newest version of VS and compiler which tells me that an older version was used for flask-mysql. 
Thanks! I wasn't aware that this existed. 
Currently using flask-sqlalchemy personally. Install it with: "pip install flask-sqlalchemy" You will need to install python-mysqldb to use most of these. You can use the windows installs here: http://www.codegood.com/archives/129 to get this up and running a lot easier. As for the vcversall.bat error you need: http://www.microsoft.com/en-us/download/details.aspx?id=44266 for Python 2.7. As for Python 3 I believe its: http://www.microsoft.com/en-us/download/details.aspx?id=14632 that you need 
I can confirm that adding sudo python to the command line solved the problem. Thanks! 
The downside is that with eg Scrapy you have a lot of work in learning the ins and outs of the new framework. It's not terrible, and people like that Ashish Leoria guy have been doing good talks on it, but there's a ramp-up involved and sometimes it's easier to roll your own bespoke scrapers. 
http://pythonfiddle.com/?
Personally I think you should give trinket a shot. It's not really an ide, but it does give you some syntax highlighting, and it just runs in the major browsers. http://trinket.io/ Pro tip - run it in full screen mode (Click the menu icon, and select Fullscreen). I used trinket last week to do some introduction to programming stuff to my daughters grade 5 class (so 10/11 yr olds), and they absolutely loved it.
It's not dependent on MongoDB and why would that rule it out for you anyway?
Awesome, thank you very much!
I think it'll be nice to add to the topic that this is the book advertisement, not the article, blog post or something like this.
* Can I just use CSS selectors for searching html pages? * How to get xml tree from response (for example for crawling RSS feeds)? And how selectors look like for xml? * I don't quite like that in *Spider* class I have dozens of methods for handling different levels of different sites. This can become spaghetti and unmaintainable. First thing I would do before using it would be splitting it up: one site = one class. * Does `Grab` escapes HTML to plain text properly? I mean if I have: &lt;ol&gt; &lt;li&gt;Coffee&lt;/li&gt; &lt;li&gt;Tea&lt;/li&gt; &lt;li&gt;Milk&lt;/li&gt; &lt;/ol&gt; will I get: 1. Coffee 2. Tea 3. Milk [Beautiful Soup](http://www.crummy.com/software/BeautifulSoup/) does it nicely. **Anyway `Grab` looks awesome.**
Because mongodb is well known among non-script kiddies to be a shit database. 
Hey thanks for trying PyPy. If your benchmark requires significant time to run (the JIT kicks in only after 1500 loops or function calls with the same input types approximately) and is slower on PyPy we would love to hear about, on IRC at #pypy or on mail at pypy-dev. We would like to hear about real world use cases for PyPy too, most of us are volunteers and feedback is what keeps us going
If it was a dependency then the simple reason is that it's an unnecessary one for a scraper, and an unreasonably big one.
Not really a chrome extension but I like this website very much [http://repl.it/](http://repl.it/), give it a try!
Thanks! That's what we're most proud of, as well!
Personnaly I use Bitbucket with a GIT repository. But you will found many Bitbucket or Github users. I don't think it will be a problem to use one either. But I will says prefer GIT for your project. You will have more contribution, everything depend of your project :)
It's not. It is well-known that it has been widely used in web development as a catch-all for any data storage where relational databases would have been more suitable and this causes plenty of issues down the line (and plenty of vocal backlash on Reddit). However, for prototyping, it is a very versatile tool for document storage, especially where the schema is likely to change during product development.
Does this support JavaScript? Can I execute JavaScript and get the result? [Selenium](https://selenium-python.readthedocs.org/) can do these things but you must use PhantomJS or a web browser (and maybe the xfvb). Examples: * When you scroll to the end of a page and more content is loaded * When you click a button and a lightbox/on page popup appears with a form * I execute JS to scroll to the end until content stops loading Looks good but, in the most polite way, other tools can already do this. What is Grabs killer feature?
It's primary application of framework - web scraping and web automation.
there is no dependency from database. But we love mongo, it's really best DB for web scraping.
Seems like Python's source files are what you're looking for, if talking of internal functions structure. If it's not - go for [docs.python](https://docs.python.org/) and built-in *help(function)* Edit: also *type()* is useful for more deep inheritance understanding
It's as fast as a web browser. I built a webservice which scrapes a site similar to Booking.com (in size and complexity.. forms.. clicking etc). The jobs take over 2 minutes to complete. It's a nightmare. Scaling is very hard. I'm using Flask as a rest api. It takes requests and adds jobs to a RabbitMQ server. Then I have some where between 3 and 20 servers also running Flask with [Celery](http://flask.pocoo.org/docs/0.10/patterns/celery/). When they are free they get a job from rabbit and then scrape the site using selenium and PhantomJS. Honestly it's not worth the effort... but it paid the rent :)
...in which case they'll be glad you composed a bunch of functions from the standard lib that they already understood to make a coherent system, rather than relying on a black box to spin invisible wire around a bunch of magic - right? 
&gt; here is 3 backends available - pyquery and lxml. That's two...
 #!/usr/bin/env python import sys, urllib, json, webbrowser u = urllib.urlopen('http://pypi.python.org/pypi/%s/json' % sys.argv[1]) webbrowser.open(json.load(u)['info']['home_page']) Why use shell, curl and the OSX open command? All required functionality is right in the python standard library and works out-of-the-box on all supported [platforms](https://www.python.org/download/other) (at least those that have a web browser...)
Nobody ever expects the Spanish Inquisition :)
Hi, help(function) fails with error - name 'function' not defined. In the python documentation have you found the place where this is being discussed ? 
Ok, Python3 compatibility requires a bit more boilerplate: #!/usr/bin/env python import sys, json, webbrowser try: from urllib.request import urlopen except ImportError: from urllib import urlopen blob = urlopen('http://pypi.python.org/pypi/%s/json' % sys.argv[1]).read() webbrowser.open(json.loads(blob.decode())['info']['home_page'])
We tend to use github for open source projects and bitbucket for closed ones.
What is or is not a dealbreaker varies from person to person. Having said that... 0) Does it seem like a good workplace? Are there any red flags? Does everyone constantly work overtime? Is there a stupid dress code? Are the hours inflexible? If I get a bad impression of the workplace culture during the interview, everything else is irrelevant. 1) Development environment. Can I work on Linux, install whatever I want, and use tools that I prefer? Of course some requirements and compromises are reasonable, like a specific language, version control system, bug tracker, etc.. 2) Version control. Do they use it? Is it a modern VCS, or something old and awful? 3) Unit tests. Do they exist? How well do they cover the codebase? Are they taken seriously, or just treated as an annoyance and commented out when they break? 2 + 3) How does deployment work? Is there continuous integration? Is it at least reasonably automated? If there's no version control, no tests and no automated deployment, *run away*. Unless you're being hired to introduce them as your full-time job.
Why do not you migrate to github? I think it is much better for open source projects. &gt; builded on top of asyncio (without threads) Asyncio is not only asynchronous solution. There are also twisted, gevent, multicurl. Grab::Spider uses multicurl that works under both python2 and python3.
Is this what you are looking for? https://jupyter.org You can easily run your own Jupyter/IPython instance if you follow the installation instructions.
replace python with cpython in your sentence
It's a problem for pretty much every language or framework because a lot of people have their development environments wildly different than their production setup. By using Docker you can close that gap because it makes it quite easy to run production services on your workstation without any of the hassle of polluting your OS or having to install and configure complex software. Imagine if your web app is running Flask or Django and it has 25+ pip libraries and depends on postgresql, redis, elasticsearch + more services running. By using Docker you put each of those things into an immutable pre-baked image that can be moved around from machine to machine. This way if it works on your machine then it will work in production. You could be happily running Docker containers on your Mac and they will run exactly the same on Debian in production, or another distro of Linux of your choosing. Plus it's nice too because your 25+ library web app is already built and guaranteed to work before it even touches your production server, by the time it hits your production server you're just stopping the old Docker container and starting a new one. In less than 100ms you have a new versioned instance of your app running.
cffi is very easy to use. You don't *really* need to generate all that much. It's far easier than ctypes and far far easier than CPython C extensions.
some code will need to be generated on the cffi-python side to handle proper lifetime management (also, IIRC, pypy doesn't use reference counting for its GC, but I vaguely remember that was one of the reason cffi was created)
The real benefit from well-made frameworks is documentation and code base structured according rules and conventions described in framework documentation. It does not matter if you use stdlib or some framework. When system reaches some size it is vital to write documentation about what is going on inside. When you use a framework you already have a documentation. And you already follow the recommended project structure that also is described in framework documentation.
&gt; Can I just use CSS selectors for searching html pages? There is no direct shortcut to use CSS selectors. With no extra actions you can use only XPATH selectors like this: &gt;&gt;&gt; from grab import Grab &gt;&gt;&gt; g = Grab(); &gt;&gt;&gt; g.go('https://yahoo.com/') &lt;grab.document.Document object at 0x7f7ba350a050&gt; &gt;&gt;&gt; g.doc.select('//title').text() 'Yahoo' The g.doc.select returns Selector object that is smart lxml node, it has extra methods and can be queried for nested nodes (those also be a Selector nodes). It has many common with scrapy selectors. I'm sad to say that that selectors feature is completely undocumented. There is only one article about it, in russian: http://habrahabr.ru/post/173509/ So, if you really need to use CSS queries with Selectors you need to build CSS Selector manually like this &gt;&gt;&gt; from grab import Grab &gt;&gt;&gt; from selection.backend import PyquerySelector &gt;&gt;&gt; g = Grab(); &gt;&gt;&gt; g.go('https://yahoo.com/') &lt;grab.document.Document object at 0x7f7ba350a050&gt; &gt;&gt;&gt; sel = PyquerySelector(g.doc.tree) &gt;&gt;&gt; sel.select('title').text() 'Yahoo' 
&gt; How to get xml tree from response (for example for crawling RSS feeds)? And how selectors look like for xml? For xml and html selectors are same: &gt;&gt;&gt; g = Grab('&lt;some&gt;&lt;thing&gt;:)&lt;/thing&gt;&lt;/some&gt;') &gt;&gt;&gt; g.doc.select('//thing').text() ':)' If you want to use selectors without Grab, it is also possible: &gt;&gt;&gt; from lxml.html import fromstring &gt;&gt;&gt; from selection import XpathSelector &gt;&gt;&gt; sel = XpathSelector(fromstring('&lt;some&gt;&lt;thing&gt;:)&lt;/thing&gt;&lt;/some&gt;')) &gt;&gt;&gt; sel.select('//thing').text() ':)' And to get tree from response just use g.doc. tree, it is usual lxml DOM tree: &gt;&gt;&gt; g.go('http://yahoo.com') &lt;grab.document.Document object at 0x7f7ba350f050&gt; &gt;&gt;&gt; g.doc.tree &lt;Element html at 0x7f7ba89a2208&gt; &gt;&gt;&gt; g.doc.tree.xpath('//title')[0].text 'Yahoo'
Scrapy really makes it incredibly easy. You can be up and running in five minutes. I doubt you can roll your own scraper with async io in that time. If you're only scraping a couple pages maybe it doesn't matter, but for big jobs, scrapy is great.
There is no "threads" for Grab:Spider it used mulitcurl and fully asynchronous. Threads are just word to define "requests in parallel", so 10 mean that scheduler will spawn 10 requests from queue and wait till any result before adding new one. So your handlers should avoid blocking by any long synchronous operation. AsyncIO is slow, lorien did some experiments - https://github.com/lorien/iob curl is just transport layer, it will be possible to add AsyncIO in future if it will worth it. &gt; distributed spiders/crawlers based on centralized queue (I see queue implemented in Grap, but where multy spider docs/exmaples ?) I see my post is on top for this sub, it's really exciting, there is no docs yet for this feature, but i'll write article about it. Yea it's possible to implement distributed crawling using Task Queue, so all scrapers will share same Task Queue. The first steps already made, Grab can utilize few cores using multiprocessing, but with some limitations, i.e. you'll need to create new connection to db, you can't use you spider class attributes to track/share some state between handlers. Author working to add option for separated item processing pipeline which will run in different process. &gt; tools for parsing resources with havy javascript logic (easy integration with headless browsers) it's rarely required for practical usage. i mean for collecting data, but i agree web automation is a different story. I think if i'll need to scrape js heavy websites, i'll better to write service first to act as a proxy to render pages for Grab. There is many pitfalls with headless browsers with js support.
yeah, sure you need to generate some python code to deal with stuff like lifetime management. No, pypy does not use reference counting, does go use reference counting?
Well, quite often I do scraping of web site with couple of millions pages with Grab :) Here is a number of projects I've done with Grab: http://getdata.pro/project At present time scraping of web-site with 1M pages is quite a typical task to me. No so long ago I've implemented multiprocessing in Grab. I mean it allows to run response handlers (build DOM tree) on all cores of the CPU. This is very beta feature though.
In any case you'll need to use some advanced tools. And if you want to know how really this things works you can check their code base. Just few examples: will you use standard lib instead of some framework for web dev? Barely, or you'll end up with your own framework which reimplemented existed solutions. Or in case of databases will you use raw sql instead of ORM like SQLAlchemy? I guess no, in most cases plain SQL would be overkill and it will sugnifficially raise the complexity of your code and maintains cost. In case of Python some additional libs like lxml, curl used C language so they are a way more faster then native Python solutions. And this additional libraries and frameworks have communities around who invested a lot of time to make it just better then anything one person could do in reasonable time.
This comment made me rethink my attitude with job offers: instead of "do I fit their needs?" it's now more like "is this company going to be a shipwreck and where I will be at that moment?"
&gt; Does Grab escapes HTML to plain text properly? I mean if I have: It's not a Grab task. Grab relies on lxml library to build DOM tree. And provides you nice API to work with selectors and results so yea you can: drinks = grab.doc('//ol/li').text_list() it will return list ['Coffee', 'Tea', 'Milk'] and next you can just for index, drink in enumerate(drinks): print("{}. {}".format(index, drink) &gt; I don't quite like that in Spider class I have dozens of methods for handling different levels of different sites. This can become spaghetti and unmaintainable. First thing I would do before using it would be splitting it up: one site = one class. if you need to scrape few different site better to write Spider for each web site and move common methods into the base class, split complex task into the few more simple. Code with asynchronous handlers for pages is currently best approach, each handler is like a "view" layer in web frameworks. Grab manage requests flow for you and drive results to appropriate handlers for further processing. It's abstraction layer so you can focus on more important things. &gt; Beautiful Soup BS is slow and have terrible API. And No xpath support as far as i know. xpath is standard query language to navigate and extract data from DOM tree. It resistant to document modification, so as a result small changes in html document structure will not break your scraper.
 S to the P to the aghetti SPAGHETTI!
This looks very interesting, and I certainly will be taking a look at this later in more detail. It looks clean, minimalistic, and easy to use. However you mention 'modern python framework' but you have only tested on Python 2.7 … Python 3 is *not* the future, it is the *present*. Does this work using Python 3.4 without notable side effects? A lot of the time, code for Python 2.7 should work with Python 3 a swell without too much effort. One should really develop new code for Python 3, unless limited by external libraries requiring Python 2. Just test with Python 3 before claiming it's modern.
mongo is not required. there is no database layer, you can use whatever you want. There is few optional features - http cache and task queue which require database. For http cache - MySQL, Postgres, MongoDB support out-of-the-box and for tasks queue - Memory, MongoDB, Redis. Backends also are dead simple, it's easy to implement own for any kind of database you want to use.
no, it's (as of go-1.5) a mark and sweep, non-generational, non-moving, concurrent, tri-color garbage collector: https://docs.google.com/document/d/16Y4IsnNRCN43Mx0NZc5YXZLovrHvvLhK_h0KN8woTO4/edit 
found a bug: Notre Dame is not in the ACC ;)
If I understand correctly this will also speedup pure, non-NumPy(Py) code as well?
no way bruh mongodb is web scale
Grab supports both python2 and python3. And it's fully tested in python 3 environment. From tox.ini file: &gt; [tox] &gt; envlist = py27,py34,py27-mp,py34-mp Demo scraper i made is tested in python 2.7, but i believe it's possible to run it using python 3 as well. &gt; A lot of the time, code for Python 2.7 should work with Python 3 aswell without too much effort. It is, but there is few exceptions. Scrapy team having hard times trying to add py3 support because their framework build on top of Twisted library which is not yet ported to Python 3.
That's fantastic news. This should be added to the OP linked page, as it states it was only tested with Python 2.7. **Edit:** _Though you say its only tested for the scrapper, I incorrectly inferred, as I presume others would too. **Add** a python compatibility section._
pyscripter is pretty basic, would recommend.
There's a ton of ways for your development environment to be different than production. The goal is to make them as close to being the same with the least amount of resistance and this is where Docker steps in. Most web applications have a lot more components than just your app code. There's database servers, cache servers and more. Even if you ignore those components you'd still want to put your app in front of something like nginx in production for load balancing, SSL termination and serving assets. You'd also likely use gunicorn or uwsgi instead of some half baked development wsgi-based server for whatever framework you use. Plus pip installing your libraries during your live deploy cycle is a serious risk and makes every deploy you push cringe worthy. What happens if there's a network blip and pip is unresponsive. Now you have to deal with a situation where your app server is left in an unpredictable state due to reasons out of your control. Your deploys also take forever in this cringe worthy state. Docker solves this by bundling the result of the pip install into an image before it touches your server. If there's a network blip then it's discovered and fixed before your deployed app even leaves your workstation (or build server).
well, then it sounds simpler than dealing with refcounting, since you either hold a reference to the python object or you don't
I can't say I've had any of these problems deploying dozens of Django apps on a regular basis, but okay.
can't do anything to that unfortunately, this is generated automatically py qtdesigner
I using both and from my experience working with Grab is less painful: grab is more predictable, no features overkill, simple modular architecture, it's more faster, and more easy to build and maintain complex scrapers. Just few examples: http://doc.scrapy.org/en/latest/topics/downloader-middleware.html#std:reqmeta-cookiejar There is few use cases when you need to use same session for further requests. LogIn, emulating AJAX requests - just for example. How you do it with scrapy? def parse_page(self, response): # do some processing return scrapy.Request("http://www.example.com/otherpage", meta={'cookiejar': response.meta['cookiejar']}, callback=self.parse_other_page) And that's how you do it with Grab:Spider: def task_page(self, grab, task): # do some processing g = grab.clone() g.setup(url=task.blog['rss']) yield Task('rss', grab=g) In first case some meta magic happened under the hood. In case of Grab you just thinking about grab object as about headless browser so you could just clone it for next request with cookies, headers etc. You need to do POST request? No problem: g = grab.clone() g.setup(url="...", post={"data": "1", "to": "2", "send": "2"}) yield Task('form_result', g=grab) Additional benefits from this approach - you can change proxy/user agent per-request request, setup additional headers (http auth for example), change referer. Request/Response parameters are available inside the Grab object. Proxies support is another one: http://doc.scrapy.org/en/latest/topics/downloader-middleware.html#scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware &gt; You can also set the meta key proxy per-request, to a value like http://some_proxy_server:port. or &gt; Please consider contacting commercial support if in doubt. Grab provides you proxy list support, each request will use random proxy from the list, it's out-of-the box don't need to implement it by yourself. I not sure 100% but it looks like Grab is faster (networking layer - pycurl faster then twisted). For next article i writing 2 similar scrapers using Grab and Scrapy to compare them in scientific way. Grab core is tiny and better tested (91% coverage). Scrapy architecture is more complex, consists of many parts (downloader, scheduler, middlewares, pipeline, ...) and less tested. And finally i don't know anyone who tried Grab and willing to return to Scrapy. P.S. It's like comparing Django and Flask. Scrapy is Django, Grab is Flask. Both with own pros and cons.
Actually, you're asking the wrong question- why is `MyMixin.__init__` being called in the second example. In Python, superclass initializers are *not* invoked automatically. Since you never use `super(MyMixin, self).__init__(*args, **kwargs)` in the child class, it makes perfect sense that it's not invoked. I'm less certain why it's being invoked in the second case- it _shouldn't_ be. **Edit**: And weirdly, in Python3, they *do* both get called in your "non-working" example. That's still not the behavior I'd expect.
CommonForm extends `django.forms.models.ModelForm` which extends `django.forms.forms.BaseForm` whose `__init__` method [does not call super()](https://github.com/django/django/blob/master/django/forms/forms.py#L81). As a result, depending on the [method resolution order](https://www.python.org/download/releases/2.3/mro/) `MyMixin`'s `__init__` may not be called: if `BaseForm` ends up before `MyMixin` in the MRO it won't forward the `__init__` call and will suppress `MyMixin`'s initializer. As the MRO document indicates, C3 linearises depth-first from the "left" parent class, so the MRO of `CustomForm(CommonForm, MyMixin)` is `[CustomForm, CommonForm, ModelForm, BaseForm, MyMixin, object]` whereas the MRO of `CustomForm(MyMixin, CommonForm)` is `[CustomForm, MyMixin, CommonForm, ModelForm, BaseForm, object]`.
OK, first, Grab, not Grap. The last letter is B :) If you do not like Grab or do not think it is useful for you you are free to not use it :) Grab is only for people who think it is useful for them :) I mean that if I need to scrape booking.com I take Grab, write a number of XPATH queries, then I deploy crawler on digitalocean.com or on vultr.com and run crawler. And I did that. Many-many times. And I have scraped many-many millions of web pages :) That is my way: using my favourite tools (and first build them). If you need to use google app engine then for sure Grab is not for you :) If you are trying to say that Grab is not flexible and so on. Yes, for sure, it is not flexible enough to fulfill every wish. It is not a silver bullet and would never be it. I do not mind about building flexible framework. But first I need to build mature solution for just sub-set of scraping problems. And Grab is already mature :) It is used for years by small group of people (people who are aware of the Grab) to extract data from millions of web pages.
I've found these questions to be fairly helpful. However, the first two need to be asked of the hiring manager (or, perhaps, the boss of the hiring manager) in order to get a useful answer, and the third is specific to data science positions or development positions related to dealing with large datasets. Of course, these are questions above and beyond some of the truly obvious: what the company does, what the team does, salary, benefits, typical daily activities, etc. 1. **For this position, what separates someone who is "great" from someone who is merely "good"?** Not only does the answer give a concrete indication of what would be expected of you, but it also can give a glimpse into the company's culture. 2. **How will evaluations be made for this position, and what is a typical range for yearly merit increases?** "Well, we don't really have a process for that, yet..." or "We don't really give raises" are, of course, major red flags. 3. **What "Big Data" technologies are you using, and how are you using them?** There are companies out there who think that a dataset is "Big Data" if and only if it can't fit in Excel. Asking a question like this could save you from a bait-and-switch. Now, with all that said, this question might get a bit more attention in /r/cscareerquestions. EDIT: Oh, and here's another extremely important one: **Which version control system do you use?** A response of "we don't" or, even worse, "...version control system?" is an enormous red flag and should be an immediate deal breaker. IMO, this is the single most important part of [The Joel Test](http://www.joelonsoftware.com/articles/fog0000000043.html) (which is not to say that it's the only important part, of course).
like prerender.io it's open source btw. You could look to my post code. There is nothing. Content rendered by AngularJS framework in your browser, w/o reloading pages. Google bots not crawl it well. But the hosting i used http://divshot.io (btw huge respect to them) provides service to render your website pages using prerender.io and show this rendered pages for SE bots. So i can have apples and eat them at the same time.
You'd have to ask them, though a big issue is you'd normally want your `__init__` call to properly forward all positional and keyword arguments to the next class… except `object.__init__` doesn't take any argument so you get a `TypeError` which makes the whole thing a bloody pain in the ass.
I see it all the time with the clients I consult with. The problem is catastrophic too once you're dealing with a small team of people instead of just 1 person.
Oh, thanks. I'd ask them directly. If Django upstream later adds call of missing `super`, I can look forward to another sleepless night why MyMixin is suddenly initialized twice (using your example with explicit call).
Nah, MyMixin wouldn't be initialised twice with my snippet. If CommonForm and MyMixin had a superclass in common (other than object) *that* could be initialised twice, but it's not the case.
I actually wrote [flask-mysqldb](https://github.com/admiralobvious/flask-mysqldb). Docs are [here](https://flask-mysqldb.readthedocs.org/en/latest/). I wrote it because back then flask-mysql didn't work outside of a request context (not sure if it does now) and because it's based on MySQL-python while flask-mysqldb is based on [mysqlclient](https://pypi.python.org/pypi/mysqlclient) which is fully backwards compatible fork of MySQL-python and is compatible with Python 3.3+. You mentioned you're using Python 3.4.3 so flask-mysql will not work. flask-mysqldb is really meant to be a tiny, tiny wrapper for mysqlclient so if you need something more like an ORM [flask-sqlalchemy](https://pythonhosted.org/Flask-SQLAlchemy/) is definitely the way to go.
It won't make DOM tree less CPU bound.
Pffftt assembly? Too much magic. My keyboard has two keys: 0 and 1.
Oh, sorry. I've missed CommonForm init is also called explicitly, not through super object.
No worries. If you pick that option you may want to extensively comment why it was done that way though (both that MyMixin depends on stuff initialised by whoever and why super doesn't work)
Not to be that guy, but doesn't the installer already do this? 
Wow. The author himself. First, let me just say thank you for your work and contribution. Is it safe to assume that flask-mysqldb can functionally replaces flask-mysql in my case? Really wish there's a lot more documentation, though. I am planning to try flask-sqlalchemy later after trying flask-mysqldb. 
web retail with AngularJS on front-end it's really cool. I rarely see something like this. You could try to add ?_escaped_fragment_= to the urls, if they care about search traffic they should make pages snapshots for crawlers. for instance check source code for this page: http://www.imscraping.ninja/posts/introducing-grab-framework-python-webscraping nothing here right? just container &lt;div class="fadeZoom" ui-view&gt;&lt;/div&gt; Now try this http://www.imscraping.ninja/posts/introducing-grab-framework-python-webscraping?_escaped_fragment_= And this is actual page snapshot. Rendered using prerender.io Google provided documentation how to make ajax pages crawlable: https://developers.google.com/webmasters/ajax-crawling/docs/learn-more Could you provide few links to actual websites? I want to check.
I know I always can do that, but I spent a lot of time writing this files and I would like to use them. All the frameworks and so I've seen for python web support makes me think I took the wrong path for doing this web interface but it's already done. Thank you anyway :)
Thanks, but looks like python-mysqldb only support python2 ? I'm currently using python 3.4.3. So what are my options? A quick google gives me PyMySQL. Am I on the right track (as far as flask-sqlalchemy concern?) Edit: There is also mysqlclient. Which one should I go in regards to flask-sqlalchemy?
Not to be that guy, but python script to search for "python.exe"? How are you going to execute it?
No problem! Yes, the underlying libs of both extensions are the same so their behaviour should be the same. As I said, flask-mysqldb is a tiny wrapper for mysqlclient (fork of MySQL-python aka MySQLdb, confused yet? :P) so you can also read their [docs](http://mysql-python.sourceforge.net/MySQLdb.html#mysqldb). But basically, what flask-mysqldb provides you is a MySQLdb [connection object](http://mysql-python.sourceforge.net/MySQLdb.html#connection-objects) (as well as taking care of opening/closing the connection for you) and from there you can use the cursor object to run queries and get data back. A couple examples [here](http://mysql-python.sourceforge.net/MySQLdb.html#some-examples).
You're welcome! No, it requires [mysqlclient](https://github.com/PyMySQL/mysqlclient-python/tree/master/doc) which works on 3.3 and 3.4 and is already installed when you `pip install flask-mysqldb`. It is a fork of python-mysqldb so they're interchangeable though. If you just want to install the mysqlclient you can just do: `pip install mysqlclient`.
thank you! yes its MSOffice
Hey istinspring! I think the plan is to use asyncio only in Python 3 - downloader handlers are pluggable, so it must be possible to turn them on/off based on Python version. Maybe as time goes asyncio will creep in Scrapy and replace Twisted entirely, who knows. Twisted dependencies are mostly isolated and hidden from user, so this change can be even backwards compatible. This needs more exploration, maybe a GSoC student next year, or maybe someone else creating a prototype. A lot of Twisted is already ported to Python 3, and they're quite active porting the rest, so waiting for necessary Twisted components is also not a bad option. See https://github.com/scrapy/scrapy/wiki/PY3:-Twisted-Dependencies - we miss twisted.web.client.Agent and a few non-essential things like twisted.mail which can be disabled. &gt; I really like few Scrapy features btw. especially deployment, web service and cloud infrastructure. Do you use isolated containers like Docker on scrapinghub? I don't know all the details; in past it was lxc + scrapyd, but I think we already switched to Docker. Deployment thing is not a part of Scrapy now, by the way :) It was moved to scrapyd and scrapyd-client packages, and there are alternative ways like scrapy-dockerhub or scrapyrt which some people use.
maybe delete this thread and post in /r/php?
Doh!
&gt; Deployment thing is not a part of Scrapy now, by the way :) Yea, it's scrapyd but i count it as part of scrapy ecosystem.
/r/learnpython is the right subreddit for questions
I'm a little bit confused on what you are trying to accomplish. If you mean what I think you mean I wouldn't use python. If you are using a linux system there are tools like *xdotool* which are suited for automating mouse and keyboard inputs. You could easily write a shell script which simulates random keyboard inputs and select windows randomly http://www.semicomplete.com/projects/xdotool/xdotool.xhtml 
Neither of them, they are not open-source. Gitlab is: https://gitlab.com/ and it is growing super fast.
there is the jitviewer, and vmprof, google them for more info
that's just open source in general.
Those are Unicode64K hyperspaces. Unfortunately they render as nulls in the lesser versions.
Cult of personality, in my words: * cool guy who knows stuff is pretty cool and knows lots of stuff * lots of people comment on how smart and cool he his * I reckon he's probably also be kind and pretty too * feedback loop strengthens perception of smartcoolness * cool guy who knows stuff is **so cool** and knows **so much** stuff See [affective death spirals](http://wiki.lesswrong.com/wiki/Affective_death_spiral). Funnily enough Elizer Yudowsky of LW is also said to have developed a 'cult of personality'. He's *so smart* and *so cool*.
What 3.6 release? Am I out of the loop?
I cannot do word searches to save my life, and one of my teachers really loves assigning them for homework. I found that it's actually faster for me to type the word search into this program than it is for me to actually solve the word search. I hope that this can help anyone who is word-search-handicapped too.
I wouldn't be surprised if pyston (http://blog.pyston.org/) will be able to leverage the standardized typing to improve performance in the future.
In theory. In practice, it's only done so successfully a few times for me. I almost always have to add it to my path manually. 
Bill Oven?
Consider the Python 3 int type. C has multiple numeric types to represent integers in specific ranges -- a uint8_t is between 0-256. Python integers, by definition, are of arbitrary precision. That means a they can be represented internally by many different C numeric types. This severely limits what an AOT compiler can do. In practice, tracing JITs can guess what the probable range is for a variable and choose a reasonable C data type. Just a small example using an extremely fundamental data type, the integer, is something difficult to optimize.
I'm nostalgic because it was the end of...ten years of PHP?
Heh. It always starts small. Some things to keep in mind: 1) If you need the same result in different places, make sure it comes from exactly the same source. Never generate the same data through separate processes. 2) Make sure that everything is idempotent. You should be able to always reproduce the ETL from the underlying data (that you will keep around somewhere). 3) What you want tomorrow will be different than what you want today. Flexibility is better than speed or size. 4) Self documenting code and unit tests are great. Properties-based tests are better. 5) Always know when things happened, but do everything you can to never tell people you know that. None of this has anything to do with Python specifically. 
I think this issue can be fixed by putting `MyMixin` on the left side of `CommonForm`: class CustomForm(MyMixin, CommonForm): # Form fields here... def __init__(self, *args, **kwargs): super(CustomForm, self).__init__(*args, **kwargs)
I'm not sure :-S
Look closely, the missing spaces are pretty similar in distance apart. My guess: he inserted his own new lines (80 characters perhaps?), but the lines were joined and the new lines were removed, leaving conjoined word pairs. edit: 70 characters it appears. Micha Gorelick was the first man on Mars in 2023 and won the Nobel prize in 2046 for his contributions to time travel. He then went back to the 2000s to study Astronomy, teach scientific computing and work on data at bitly. Then he helped start Fast Forward Labs as a resident mad scientist. There he worked on many issues from machine learning to performant stream algorithms. A monument celebrating his life can be found in Central Park, 1857.
That's just life in general.
Is there a specific reason you are trying to replicate Django's model class for your API? If you just need a nice wrapper around a RESTful API, have you looked at [Slumber](http://slumber.readthedocs.org/en/v0.6.0/)?
Index.php has almost 600 lines of code. Most of them are php but there is HTML, JavaScript, comments and empty lines. This is the file: https://github.com/helfio/FitsDB/blob/master/web/index.php There's also this one: https://github.com/helfio/FitsDB/blob/master/web/download.php With about 50 lines.
I used the SQL interface for the Python program, and to make easier package the whole project I've thinking about change from MySQL to SQLite. The change would be straight forward but I'm not sure if SQLite can accept multiple reads at a time because the main point of the web interface is to make it multiuser. Also the database has to deal with more than three million of entries. What do you think?
I've moved all my stuff to mysqlclient - Python 3 support and seems to be more actively maintained. It works as a drop-in replacement for MySQLdb. I couldn't find any downsides.
except the few that really care about performance ;-)
the browser-javascript response has been so far "ignore the problem, cycles are user error", so maybe that's a start. Cross-boundary GC algorithms are hard, e.g. distributed GC. Note that in CPython refcounting you have the exactly same problem (since their cycle detector won't detect a cycle going through go)
I think it's worth mentioning here that PyPy will not benefit at all from the typing - having a specializing JIT on it's own gives you enough (and more) extra information that let you do whatever you can do with typing and much more. It might be slightly *easier* to write an optimizing compiler, but since you have to deal with types a bit everywhere (containers etc.), it won't be easy at all
there are knobs, but they're underdocumented and hard to use (just like in GCC hooray!). Back to the facts - we're working on modes in vmprof that would tell you "hey, this function looks fishy" etc.
[Image](http://imgs.xkcd.com/comics/python.png) **Title:** Python **Title-text:** I wrote 20 short programs in Python yesterday. It was wonderful. Perl, I'm leaving you. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php/353#Explanation) **Stats:** This comic has been referenced 165 times, representing 0.2114% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_cuifgx9)
The first time I used Python I though the whitespace thing was absurd. Now it makes perfect sense.
\^This guy knows his stuff! You must be a nice dude man!
In this keys spider must be separated with transport layer. And each layer must be configured for concurrent processing. By your posts I will understand that spider will be launched in multi process mode, but each spider process also spawned his transport layers. In my understanding spider instance must be singleton with concurrent transport layer, where received content must be delegated to the pool of parsers. I try to say that spider is the controller for the whole application.
My teacher likes doing this too, hadn't thought of this, it'll be useful next year though.
Django's Model class has a metaclass that inspects the class definition and finds all the fields (i.e. subclasses of Field) that exist on the class. These are then stored in a "_meta" attribute on the class, and the class namespace itself is cleared of the attributes - otherwise you get potential ambiguities - does `Student().age` return the `IntegerField` object, or an integer? Essentially, you are doing the inspection when the instance is created, while Django does the inspection when the class is created. The difference is whether you implement `object.__init__` or `type.__init__`. You'll need to read up on metaclasses for this. However, I would echo the other comments - is there a need for you to do this? Could you not re-use Django's machinery? Have a look at Django's implementation if you want to be convinced that there is a lot going on that you don't want to have to re-implement. Also, in Django 1.8, the Meta API has become official, meaning you can access Django internals for a model fairly easily: https://docs.djangoproject.com/en/dev/ref/models/meta/ Also, I would avoid duplicating an API that looks like Model for the sake of it. Attempting to copy the Django Model class will force you to make certain decisions that might make things overcomplex for your needs.
yea lxml library which provides DOM tree and xpath selectors run at same process but lorien want to try to move it out in nearest future. At the same time he want to keep current API for people who use Grab in production. &gt; In my understanding spider instance must be singleton with concurrent transport layer, where received content must be delegated to the pool of parsers. I try to say that spider is the controller for the whole application. actually it's not clear. Python have GIL so treads make sense only for I/O tasks. There is 2 ways - just run few instances on different CPU cores (it's already possible) or split grab into chunks which could work in separated processes (it's pretty complex). But is it worth? Few months ago my friend scraped website where lxml caused memory leaks (broken html or something), but because Grab is simple and expandable, he just moved lxml processing into separated process which restarts for each 1000 documents. Current implementation is fast enough to scrape millions-pages websites pretty quickly. It's more important to keep core simple and don't brake APIs. Bottlenecks like DB could be resolved with async drivers for databases - motor, aioPG etc... I mean Grab is good enough to scrape simple e-commerce websites and web-portals like Google Play/Booking/Yelp for larger volumes of data it would be more efficient to use simple crawlers in Go/Java/Scala and processing pipelines with distributed storages. Different tasks - different solutions. One tool can't be perfect for everything. People love Grab because it's simple, it's easy to understands how it works and use it to resolve their current tasks.
http://www.autohotkey.com/board/topic/28056-midi-input-library/
/r/learnpython
Cool. PBKDF2 is that library for choosing cocktail recipes based on what ingredients you have in your house, correct? ALWAYS BOTHER TO GIVE A 1 SENTENCE DESCRIPTION ABOUT YOUR LINK SO PEOPLE WILL GIVE A SHIT
this is a wrong implementation 
why?
I mean, someone's made something that would exactly solve your use case, but for windows. That's what's unfortunate.
&gt; Btw there is https://github.com/lorien/grabctl as example. Example of what? Please, stop disclosing projects that are really not usable. Grabctl does not work. And I ever do not plan to work on it. At least this week (month?, year?).
This was a great talk and really made me understand how it works. The TL;DW is probably something like "it doesn't do exactly what you think" ;)
You don't understand super() yourself. Go look at the other answer
Its role in `__init__` is the same as everywhere else: call the next method of the current object's [method resolution order](https://www.python.org/download/releases/2.3/mro/), to apply whatever initialisation the next class in the MRO needs to work correctly. Syntactically, Python 3's `super()` is sugar for Python 2's `super(lexical_class, instance_or_class)`, so I won't cover that part. Semantically what `super` does is: in the instance_or_class's Method Resolution Order (a list which tells the runtime in which order methods should be called in the current object's class hierarchy, it's important to use instance_or_class so that the MRO is stable), it looks for the type which *follows* the lexical_class (the class we're currently in), and it creates a proxy object which will dispatch the next method call on that class using the current instance_or_class as self/cls. Inexactly transcribing the C code of typeobject.c into Python, you get essentially this (note: this code is incorrect and incomplete in the details, but the gist of it should give you a good idea) class super(object): def __init__(self, type_, instance_or_class): assert isinstance(type_, type) if isinstance(instance_or_class, type): assert issubclass(instance_or_class, type_) self.__self__ = None self.__self_class__ = instance_or_class else: assert isinstance(instance_or_class, type_) self.__self__ = instance_or_class self.__self_class__ = type(instance_or_class) self.__thisclass__ = type_ def __getattribute__(self, name): # note: getting attributes on self would not actually work because # we're overriding __getattribute__ we'd have to use # object.__getattribute__(self, attr) instead for actual code # get the mro on the concrete caller's type so it's stable mro = self.__self_class__.mro() # get the index of the class following the lexical caller in the MRO i = mro.index(self.__thisclass__) + 1 # performs a getattr but if a matched member has a descriptor (e.g. # methods) uses that for proxying for supe in mro[i:]: res = vars(supe).get(name) if res is not None: f = getattr(type(res), '__get__', None) if f is not None: res = f(res, self.__self__, self.__thisclass__) return res return object.__getattribute__(self, name)
I reckon he's also kind and pretty.
removed
Because your definition is incomplete. What about Mom?
Oh... this is some misunderstanding... Or you are kidding me? In the footer of the blogpost is saw this &gt; © IMWEBSCRAPING.NINJA 2008-2015. ALL RIGHTS RESERVED. | DEV BY GRABLAB. You are the Grab maintainer - https://github.com/lorien/grab ask google like this *grablab lorien* and the first link I saw this http://mastertalk.ru/discussion/139707/grablab-parsing-kontenta-na-zakaz/p1 Why lorien have any relations with grablab.org? &gt; And now. You come to this thread. Start posting link to you pomp framework. And then start talking about marketing/PR/lying/dissuading. That is a bit odd Yea! I do that, and will do that any times as I wish ))) But what you want, when your team publish this? You can publish some posts about how Pomp is bad or something else, I do not care about it. Why? I will not make money on Pomp yet ))) And black PR better then nothing ))) Any one can say his opinions or recommend other ways etc... And I do not say what Grab is worse and can not solve data scraping tasks. You must be more objective and constructive when you hear some critics about your framework. Please critique the Pomp, because any critique is kind of contribution. 
Sure, some benchmark code. https://gist.github.com/Spindel/e249f3f98e7ff713d0b1 Note that you have to write your own endpoint unless you're using devnull as a service. I didn't keep the numbers after verifying things, but for HEAD requests (not post) a threaded approach with curl was within the margin of error as fast as `ab` at running against the server, while all other options turned massively slower. If you really care, I can write something up in the weekend.
Longtime rival of Dave Stove. It wasn't until after their deaths that their families finally made peace and joined forces.
&gt; modern and what's wrong with this? modern is like new. &gt; They want asyncio as python3 standard (do not forget we are python developers), js parsing, and scaling. who is that people? i see that people still using bs4 and requests w/o any problems to resolve own tasks, exactly same as they still using django to build traditional websites instead of new shinny Angulars and Reacts. Asyncio already in standard-lib. Js engines are not the thing which could be used every time, it's too slow. "scaling" is just some magic word, it does not make sense without the context, do you need this scaling on daily basis for each single project? i don't think so, and when people really need "scaling" they're using different tools and usually those people are twice as conservative in their technologies stacks. &gt; I know what developers want to be done in scraping frameworks at current web history stage. so you doing your own "modern" and use it to build scrapers, deploying them in production, write articles, build community around etc. Ideas worth only in practical implementations with defined scope of correct use cases.
There is no release of 3.6 yet (3.5 isn't even officially out), but the current development happens in the [3.6 branch](https://docs.python.org/3.6/). 3.5 only receives bugfixes now.
&gt; and what's wrong with this? modern like new. Sorry, this is my mistake... I will saw the Grab couple of years in past and try it, and some my friends will try it. And I can not say what Grab is new... plus my bad English led me to this mistake what this word may mean.
I don't know anything about this product but they do advertise it as python's answer to shiny - http://multithreaded.stitchfix.com/blog/2015/07/16/pyxley/ 
SQLite can easily handle 3 million rows. But you say "multi-user". So perhaps it's time to look at a real actual hosting server?
Look at bokeh for basic interactivity. Look at ipywidgets for more interactivity. 
Лет то сколько тебе? Максимализм так и прет. Лориен передал мне граблаб. Проблема в том, что вместо того, чтобы напрячь жопу и самому написать статью (что как бы не так уж и сложно) и доки с тестами (что сложнее) + понаделать примеров и наработать какой-то опыт практического применения ты врываешься в чужой тред со спамом своего проекта и ничем необоснованными понтами в духе "вот я сейчас оооо вот я сейчас уууу". С ними нужно приходить (и крайне желательно еще и со своим контентом), когда предметно есть о чем говорить, мол вот мой фрэймворк, я делал то и это и вот это и вот столько много сайтов спарсил, используется в продакшене и вот такие вот успехи.
Jacob Kaplan-Moss touched on this in his pycon keynote this year. (mobile sorry no link) However it's not fair to just put this on the python community, it's tech in general. 
You edited your answer 37 minutes ago, now it's ok...
Please stop making fool of yourself. I am not a member of Grablab. I have started grablab with my friend, then I have leaved grablab. I have not managed this web-site for 2 or 3 years already. Grablab is not a Grab. These are two different things. I repeat personally to you: I do not say that grab is a modern. The imscraping.ninja blog is not mine. I have not posted this link to reddit. Is that clear? I even have not asked him to write this article. So, if you care about PR/marketing/affiliation/lying/hiding truth/etc or any other bull-shit please write all this to the agent Fox Mulder :)) &gt; I will not make money on Pomp yet ))) And black PR better then nothing ))) I do not need PR. You really miss my point. It is great that Grab users want to promote it. When I see article about grab I happy to participate in the discussion or put some links to that discussion. It is a fun. But personally I am not ready to promote Grab and I do not do that. &gt; Please critique the Pomp, because any critique is kind of contribution. Man. I am not aware and I really do not care about drawbacks of popm framework. Sorry, I can't help you. My only wish, as I said already, stop looking for shit in other frameworks and fix a shit in your framework.
thank you!
public static void MomsAbstractFactory
I have a local MySQL server right now because of this. Actually I don't really know if multiuser capabilities are about writing and reading or only writing in the DB. The thing is if the limitation is only about writing in the DB I could use SQLite that is easier than MySQL in many senses. Do you know how SQLite works with simultaneous requests of data? Edit: Reading here and there I think I'm going to give it a try. It should work and if it doesn't I can undo everything easly because the amount of changes I have to commit to do this are just a few.
Да что ж ты будешь делать-то, чего вы так все обидились то. Да есть другие варианты, есть другое мнение. Вот если бы кто-то запостил ссылку на ранний scrapy без "наработанного контента". Ты бы тоже написал про "напрячь жопу" и т.д. и т.п. хам... стыд и позор... * этот тред есть пиар Grab, кто против? * в этом треде может любой писать что ему вздумается, Ваша команда против? * где я сказал что Ваш любимый Grab фигная? Я лишь пытался до нести что Grab и все (включая Pomp) не есть современные фреймворки, поймите же вы это наконец-то. Все фреймворки что мы имеем сейчас есть традиционные фреймворки. Ничего нового и современного Ваш Grab не имеет как и остальные. (вот не нужно про асинхронность и мультипроцессность, scrapy это тоже умеет) * Лориен имел (имеет) отношение. да кто против-то? Да зарабатывайте, делай-то свое дело, не надо только отрицать этого. * ссылка на Pomp не есть спам, она оказалась не желательно только для Вас, но не для "потребителей". Честно когда увидел пост про Grab обрадовался, думаю ну молодцы ребята. Поднял тему современных фреймворков - получил негатив и псих. Посоветовал кому-то свой не захардкоженый фреймворк в плане библиотек для парсинга и скачивания фреймворков - получил негатив и псих. Поймите что Pomp не может делать что уже умеет делать Grab. Разработчику на Pomp нужно уметь делать многое самому - это выбор Pomp. Не вредите grablab, остыньте и удалите хамский коммент.
I created a twitter bot, which tell meaning of word. Check-out, [@TellMeaningof](http://twitter.com/tellmeaningof). Blog post currently under drafts. :)
I have mean a bit different thing. Some link that point to some ready-to-run code. I copy it, install dependencies, run and get numbers for threading/pycurl/asyncio/etc that I can compare. I'll try to update https://github.com/lorien/ioben I'll write README, add asyncio tests. BTW, real world could be very different from synthetic test. For example, in sintetich tests you query endpoint that is quite fast. But in real world the endpoint backend could be slow, domain name server could be down, etc. All these things could change results of benchmark. For example, if DNS resolving in async library is a blocking operation then a call to the broken DNS server could block all activity of other network threads. That also could be true for threading + urllib. I am not sure. I have tested it too far time ago.
Что ты несешь троллятина? Поток бреда, с одного на другое, какие-то отмазки нелепые. Типичный уроженец вконтакта. Есть такой термин в английском - Attention Whore. Который "набижал" и стал дерейлить тред, ладно бы аккуратно, со знанием дела. Юзеры что-то спрашивают - тут же "а вот мой помп фрэймворк". В итоге такое наглое и инфантильное поведение стало сложно игнорировать. Время только жаль, я особо не смотрел никнэймы, просто на вопросы старался отвечать. В итоге оказалось куча ответов на твои посты с претензией на понимание того "как реально надо делать" и что "людям нужно". Юзал скрапи когда он еще 0.10 не был. Тогда Пабло Хоффман сам отвечал на вопросы на стэковерфлоу, писал статьи и т.д. Нарабатывал контент и привлекал пользовательскую базу. &gt; Разработчику на Pomp нужно уметь делать многое самому - это выбор Pomp. ну вот и начни с того, чтобы самому свой фрэймворк (доделать и) начать промоутить. В твоей хистори явно видно чем ты занимаешься. За 2а года можно было бы уже выучить английский и/или для старта запилить пару статей на хабр. + некоторое количество реальных проектов. 
You send it to wrong person (me)
&gt; By your posts I will understand that spider will be launched in multi process mode, but each spider process also spawned his transport layers. Nope. &gt; In my understanding spider instance must be singleton with concurrent transport layer, where received content must be delegated to the pool of parsers. I try to say that spider is the controller for the whole application. That is exactly how the Grab:Spider works at the present time.
rsync?
Git. It's not much of a hassle at all, and if the files your syncing are code, you want the version history anyway.
Hey! No, Scrapy uses a single process. When this becomes a problem we start several spiders with a shared requests queue - they all read requests from this queue and send requests to it; it also allows to scale crawling to multiple machines, use a shared dupefilter, restart spiders in case of leaks without loosing data, etc. AFAIK there are no plans to add built-in multiprocessing support to Scrapy; I'm not sure this feature was proposed ever. I can see how this feature can be useful though. But it needs to be maintained, and it is only a stop-gap solution for the cases 1 CPU core is not enough but 1 server is enough - it is still nice, but likely that's the reason nobody worked on it. I haven't tried to implement it, but I think sometimes it can be tricky to parallelize spiders - the bottleneck often is not in HTML parsing. I've seen broad crawlers (which used lxml) where bottleneck was e.g. in URL normalization for dupefilters - stdlib's urlparse is slow. Often it is a death of a thousand cuts, unless some heavy processing is done in a callback (e.g. some ML algorithm). So I'm not sure it is enough to parallelize just callbacks. Of course, tasks are different and it is better to profile.
This is one of the things people usually ask right away; I'm surprised you are the first to mention it. Twisted, as far as I can tell, is enjoying a true resurgence right now. If you go to the Twisted room at the PyCon sprints, you'll see some incredible energy there and young people learning from some of the very best developers on the planet. Also, if you check out the #twisted channels on freenode, I think you'll find that they are far more active today than they were, say, a year or two ago. Twisted is an absolutely incredible library; I'm really hoping that it becomes a staple of Python 3 once of (unfortunately very long) translation is complete.
If it's code, git is worth learning in the long run.
&gt; Does that mean that if you want to crawl one million of different domains then at the end of scraping process you'll have in memory all these cookies from one million domains? Yes; we document to turn cookies off for broad crawls.
Then what CONCURRENT_ITEMS option does mean? Documentation says: "Maximum number of concurrent items (per response) to process in parallel in the Item Processor (also known as the Item Pipeline)."
What kind of analysis are you trying to do? That will largely impact what type of geometry package you need to use. Do you need the generic solving abilities of something like sympy.geometry or are you simply trying to do some geometric analysis of known shapes? Do you just need geometric primitives or do you need more sophisticated operations like Minkowski sums and generalized booleans? &gt; Are there simple yet complete 2D alternatives? Such a thing does not exist as far as I know. I do a lot of geometry work. Simple geometric packages exist in abundance but invariably do lots of things wrong. They don't handle edge cases correctly. They don't handle cases where floating-point numerical stability becomes relevant. Packages that do these things correctly are never simple because these problems are pretty technical and difficult. As far as I know [CGAL](http://www.cgal.org) has long been the gold standard in completeness and correctness (and Python bindings existed in the past don't know about now) but it is not simple. If you just need simple primitives and the like then I'm sure any old geometry package (e.g. euclid as /u/ilikebigsandwiches suggested) will do. [Shapely](http://toblerity.org/shapely/) (a Python wrapper for GEOS) is another package I have used in the past. It is less complete than CGAL but simpler and more straightforward (although it only supports linear geometry). 
Code? [Git](https://git-scm.com/) Arbitrary stuff? [Syncthing](https://syncthing.net/) Backups? [rsync](https://rsync.samba.org/) If you want absolutely zero hassle and don't mind the corporate solution, [Dropbox](https://www.dropbox.com/en/) is more than adequate. 
Scrapy allows to return Deferred from pipelines, so you can e.g. use async requests to DB to store the data, or defer processing to threads. CONCURRENT_ITEMS is a concurrency limit for that.
I was using [BiTtorrent Sync](https://www.getsync.com/) for a while alongside Git (all code was in Git), but I'm now using Git exclusively to manage code, my dissertation, datasets, one-off scripts, notes, etc.
I did same, as far as i remember i show you my implementation. First scraper crawl pages for links to countries/regions/landmarks/districts/airports/cities and finally hotels urls (by url patterns like "/fr/hotel/"). And they did A/B testing in parallel, so after few attempts to deal with with it i reimplemented scraper to crawl all urls, with trivial algorithm to filter them and recognize patterns. Final count of collected urls was close to estimated number of hotels. Another one use case - duplicates filter could be useful to crawl domains. Or when e-commerce website is difficult to drill down so you end up scraping "related items". W/o filtering scraper could just fall into the infinite loop.
You want to structure your app to provide data to JS based graphs/plots. 
I wanted to automate some VM (VirtualBox to be exact) booting and restoring from snapshot. I had remembered the xkcd about being able to 'import soul'. So I asked google if there was a python module for running VirtualBox commands, the answer was yes. It's pretty much been bliss ever since. 
Writing an automated gamethread bot for /r/NBA. It taught me so much about web scraping and really what not to do. Source is [here]( https://github.com/seemethere/nba_gamethread_bot)
I use git with a repository in Dropbox. It took an hour to understand, set up and test, and works a charm.
I'm curious. It says it's "probably buggy," so probably best avoided in production, but is this meant to be a real thing or just something fun to play with? I actually have a use for something like this, so it would be really nice if this thing matured for real.
Read up on win32api and VK codes. All keyboard inputs on windows can be traced back to their VK hex values. 
What i can make out of this is super allowed us to print the variable x defined in the parent ClasS
/u/review_bot was my "I want to learn Python"-project. Now I'm busy writing a small template/framework with all the knowledge of Python + software design I took up at work and uni to roll out bots easier. :)
Same here. A program for my class (as in for use by the class, not an assignment) to grade work and let people see their grades, upcoming assignments, etc.
Syncthing looks cool.
*If* they have a style standard. A lot of places don't -_-
Definitely keep in mind that an interview should be a two-way street. Not only is the company trying to determine if you'll be good for the company, but you should also determine if the company will be good for you. How many vacation days do you offer? What's your attrition/turnover rate? What is your favorite thing about working here? What would you change if you could? Etc. 
that's what i figured, thanks
SyncThing
It is difficult to advise when you haven't said what, if anything, you've all ready looked at, but frankly after a quick search I couldn't find much at all :-( If you're forced into doing your own I'd guess the starting point would be one of matplotlib or pygame.
R/dailyprogrammer
As of Fall 2013, there's now an example of embedding matplotlib's WebAgg backend in a Tornado-based webserver: https://github.com/matplotlib/matplotlib/blob/master/examples/user_interfaces/embedding_webagg.py This makes use of websockets to send the figure updates to the browser, which allows for really nice interactive plots that get rendered client-side.
Yes; it is not used much by Scrapy though, for some IO stuff like S3 file uploads. Twisted uses it for DNS lookups, and maybe there is a few other similar tasks.
 from projects import similar
I'm trying to learn so I can create a Coaching Management System. Like a Learning Management System, but with more of a focus on items that require hands on instruction. It's going to combine a competency and proficiency model I've developed, a progressive growth model for non-essential knowledge and skills, and other cool features. I'm 86% through the codecademy lessons and have made a mock up in a spreadsheet. A long way to go yet.....
Cython.
I wrote some [Inkscape](http://www.inkscape.org) extensions to help with the layout of components and stuff that are useful when making boardgames. Anyway writing extensions for Inkscape (or some other application that allows extensions in python) can be a fun way to make something that is actually useful and not just for learning. https://github.com/lifelike/countersheetsextension https://github.com/lifelike/hexmapextension 
I made a interface to write or read data from Omron PLC
There's a fair chance that I screwed something up along the way, but I just implemented this in a hack-ish way by copying the AdaptiveMetropolis step method and adding delayed rejection. It's in a forked pymc here: https://github.com/pymc-devs/pymc/compare/master...khuston:DelayedRejection
Not particularly - I got the impression it was slower due to being pure Python but that might make deployment easier (as it wouldn't have to build against the C library).
I wanted to participate in [PyWeek](https://pyweek.org/) because it sounded pretty rad. So after writing a trivial program and going through some tutorials over a week or two leading up to the contest, I entered. The final project, [Evil Genius on the Oregon Trail](https://pyweek.org/e/PrintStar/) is pretty fun to play, although it has plenty of flaws. I assume the code is horrendous, and I'm afraid to look at it.
I've just finished making a bedtime story generator in Python using the Flask web framework. It is my dissertation project for a one year conversion MSc I am just about to complete, though I am completely self-taught in Python and have been programming for just over a year. If you want to take a look at it, it's hosted at bedtime.samueltjoseph.com (it's a bit shit though). Flask is a fantastic way to take the next step with Python. It will be overwhelming to start with but the great thing with Flask is how quick it is to get a webpage up and running, which is great if you are someone like me who likes to see the fruits of your labours. It also forces you to pick up skills other than Python, like HTML and CSS, databases, JavaScript and so on. If you can't think of something to make into a web application, just start with taking some of your existing code and put it online. Miguel Grinberg does a very good in depth tutorial, that might seem over your head to start with but persevere and you'll get there!
That's awesome. I love using Inkscape but I didn't know you could write Python extensions for it.
I'm currently writing an application to analyze a large scale Redis infrastructure and enforce best practices, as well as clean up unnecessary data. This is my first 'real' python project, and working with it at such a large scale has proven to be immensely helpful. 
I will try it then!
I guess I'll be that person: Python's indentation. The main problems I have with it are: * Method chaining is impossible without escaping newlines or adding superfluous parentheses ([eg](http://stackoverflow.com/questions/4768941/how-to-break-a-line-of-chained-methods-in-python)) * Pasting code from the internet (e.g. StackOverflow) won't work without manually adjusting most of the indentation. This is something we all do all the time especially if we want quick solutions. Python removes the 'quick' from that. * Refactoring large chunks of code (e.g. By adding an if statement or removing an except statement) requires understanding and rethinking the entire logic tree of the program in order to get the indentation right. In a braces/non python language this requires very little thought. * It's possible to get syntax errors from invisible characters (e.g. From mixing tabs and spaces). Syntax errors should never require the interpreter to run to detect * The `pass` character had be added to make up for the fact that you can't have empty blocks There are many other problems this has caused that I can't think of now. But as far as I can tell the arguments for Python's indentation system are: * It's a great way to teach coding students to use indentation. I don't deny that, but that's not something that affects those of us who can already code, so it's basically a null argument. * It looks cleaner. Okay this is true but I believe this is purely aesthetic. It doesn't make the code easier to understand, and I think it possibly makes it harder because following indentation trees across multiple lines can be tricky. * I'm not sure if anyone argues this, but it does save having an ending line (a close brace or an end statement). As above this makes code cleaner but arguably harder to understand so I fail to see the advantage. Please dispute my points! 
it looks like `node-python` is where the real magic lives.
The split between 2 and 3. Otherwise it's all good
How python3 handles the encoding of _input_ files. [Proof of Concept](https://gist.github.com/Spindel/8b2f2b5bbba10c93ca18)
wow. Thanks for reminding me of networkx. That looks pretty righteous. I was going to mention [PyDot](https://pypi.python.org/pypi/pydot). 
yeah I tried out pyxley/spyre and am moving in this direction:)
My first programming project was also my first python project. I'd just started an internship at a laser lab and I needed to write a program to extract saved data from a digital lock-in amplifier. It was hell. I had to send commands (in a proprietary dialect of BASIC) through a serial bus. That may not sound bad. But remember I'd never seen a for loop before in my life. But I got it done. And Python has held a special place in my heart ever since.
Try %paste in iPython - the genius behind this demands to be awarded every medal in the world plus the ones that haven't yet been thought of :-)
Enforced indentation is more than aesthetic, it's important to maintaining highly readable code (We call this "beauty", but the functional aspect of that beauty is more important than the aesthetic aspect). Because of Python's enforced indentation, an experienced Python developer can detect code smell from across the room (literally). There is the added benefit that when coupled with column restrictions, the developer is encouraged to keep a flat structure without deep nesting. This also promotes clean, readable, maintainable code. Most of your negative points regarding indentation come from a lack of convenience. This is managed by using modern editors that manage things like this for you. Most editors support indenting block-wise when multiple lines are selected - you should try yours! These points are all covered in PEP-8, I recommend you give it another read. A final note: If you're copying and pasting code for "quick solutions" and not reading the code enough to understand how it should be indented... well, you'll get what you deserve I guess.
Reference for those that care: https://wiki.python.org/moin/GlobalInterpreterLock - CPython: GIL - PyPy: GIL - Jython: No GIL - IronPython: No GIL - Cython: GIL, but workarounds available
Yow, that's hard to parse. Can you edit or reply with a pastebin? Or at least use the code formatting option in Reddit?
I built a sudoku solver. Then started writing random stuff for work that solved a problem.
The optional else clause after for loops.
You can do result = object.method1(arg1) \ .method2(arg2) \ .method3(arg3) For multi-line method chaining. However I would argue that if you need to do this a lot, you should probably introduce new methods for the frequent combinations or some intermediate variables. It'll make it easier to refactor, in my experience anyway. 
I learned Python because I felt like I had taken Perl just about as far as I could as it related to my job in networking. Normally I would have to log into thousands of switches and routers, make changes or collect data, etc. Over time I got pretty good with threading and forking processes, etc, interacting with Expect or using the Expect module. I wanted to recreate that same ability and use Python "best practices" because I knew if I switched jobs, something that was very likely given that my company flat-out stated they were going to outsource all of US IT, I knew the people I would be working with likely would be using Python as it was the flavor of the day. Python has proven very useful and when I began interviewing it was a well-received tid-bit on the resume. The managers all seemed to prefer Python over Perl but the techies didn't care - they just thought it was a useful skill to have around. In the end I am glad I took up Python. It's a wonderful language and one that keeps me interested to learn new skills apart from automation. One thing I've been doing lately is creating network diagrams based on Cisco Discovery Protocol output. That's been fun. Want a map of the network as it relates to just BGP? Ok. RIP? God help us. EIGRP? Ok. It's fun! In the end I guess that's the thing - I enjoy Python and approaching a new problem knowing there is a someone who has done it before and there is a tremendously supportive and active community behind the language.
Chained operations can be done like: result = object.method( arg1).method2( arg2).method3(arg3) Or result = (object .method1(arg1) .method2(arg2) .method3(arg3) ) 
This is awesome. Great job!
Git with the remote in a Dropbox folder.
Is Nagare still active? I'm intrigued, but it looks like there hasn't been a recent release. (And [Wikipedia](https://en.wikipedia.org/wiki/Nagare_%28web_framework%29) lists it as "stalled".)
Python could implement a cls comand. &gt;&gt;&gt;cls
Holy shit. I've been working on a concept for a digital signage app because all the existing apps I've found are horrible. This is exactly the kind of thing I need for it.
 If you REALLY want ternary back in python, you can do some_var = condition and value1 or value2 I won't recommend it though...
The tutorial code itself should work, but if I recall correctly, the Twitter API library had some issue with 3.4. I can check it at some point and update the post with more info. :)
I've a small app that uses Qt and QtWebEngine to display web content. I wouldn't mind rewriting it with a lighter framework. Is it possible for a Flexx app to display a web page along with some other widgets (a list, a few buttons)? What rendering engine would it use?
/r/dailyprogrammer
What's wrong with CTRL-L?
I had used it for various whatever's but didn't really know it. Then in grad school I signed up for a database course in computer science department (I was in physics). It had a semester long project where you had to develop an storefront application that used a database. I learned very fast that semester.
I used to get badly formatted python from websites occasionally, but I can't say it's happened at all in the last 5 years. As it surged in popularity websites realised they had to pay proper attention to it as well. Net win IMO.
I had just finished a log parsing script - in Perl. It worked, but didn't do all I wanted - and it wasn't very modular. That led me to re-writing the thing in python. End result was a slightly more modular, and a little faster log parsing script.
You shouldn't stop learning a language. 
You hate this feature? It seems like something that shouldn't bother anyone. If you don't like it, don't use it! I have a fondness for it, myself. When it fits, it fits perfectly. Though I'll admit I had to look it up the first time I saw it.
I never use it. It seems the only time I ever want it is to use default values, and get() is my best friend.
A simple question, but I think you've still got a bit of work ahead of you. **First:** Your host needs to support this. While python web applications are pretty common, there are plenty of web hosts that don't offer that support. That support involves 1) running a **W**eb **S**erver **G**ateway **I**nterface (wsgi)-compliant web server, and 2) giving you the ability to configure that server to run your application. Most web servers have a wsgi module available, so mostly what you're looking for is host that'll let you configure it. But... **Second:** If you've written your application without much knowledge of how the web works (specifically, how HTTP works) you'll likely need to make some non-trivial changes to it to get it all working. There is a rather decent-sized pile of python web frameworks which make the process of writing web applications in python easier. Some come with the kitchen sink (Django), and some with considerably less (Bottle/Flask) (These three are BY NO MEANS an exhaustive list). I definitely think it'll be worth taking the time to play with one or two of them to learn 1) How they do the whole HTTP Request -&gt; Python Code -&gt; HTTP Response cycle and 2) if your application might be more easily adapted into one of them. Mostly because I don't think I'd want re-implement the python-end of the WSGI interface when the frameworks have done that for you, but there's plenty of other things they help out with as well. I really like Django, and can't really say much about the other frameworks available. But it's pretty big and has a decent-sized learning curve so you might want to start out with one of the smaller ones.
I had a hard time cloning this repo using the command line. I haven't used it through bitbucket or maybe I am just an idiot who has forgotten how to do it but this is a neat program! I really want to get into pygame. What's your best recommendation to dive right in? Are their any decent books?
nice answer, although wrong : do not feed trolls
To be more clear, with 'proper encapsulation' in OOP I mean the impossibility of having private members in objects. 'We are all adults now', but we can still act like children sometimes 
Someone was telling me that they're trying to make requests the standard, but that it receives security patches too frequently. 
Do you know anything about networking? If so, go with requests.Session(). It's fast and elegant. Otherwise, I would go with Selenium. It depends on your browser, though. If you know the difference between POST and GET requests, headers etc., reply to me and I'll explain how you would do it.
&gt; inability to import from parent directories Since Python 2.5 https://docs.python.org/2.5/whatsnew/pep-328.html
Will look into django thanks for the info, seems more complicated than i need though. I currently have hosting on godaddy, not sure if thats thats goodor bad. Just to clarify, I am by no means a programmer, the software I have does some analysis of geophysical data entirely offline, and I would need to sent back a report back with an authenticated username. Any easier way of doing this with something like a connection to an FTP? Perhaps calling this 'connect to my webhost' was not the right term. Feels like a dumb question just writing this.
Actually applies in either case, I think.
The team is supportive on the mailing list. And it is still actively developed and used by their consulting firm.
Correct. Requests will not be in the stdlib because it's too important that we can quickly provide security releases to our users. We've done it before (see the bottom of [this page](http://docs.python-requests.org/en/latest/community/vulnerabilities/)), and it's safe to assume we'll have to do it again. However, with pip being automatically installed by the stdlib, it's safe to say that getting requests has never been easier. Hell, the stdlib documentation recommends it!
If it doesn't the UK is one of the leading nations at manufacturing them. Available in a number of different GOF design patterns, with multiple colour schemes, there are regrettably, owing to a severe design flaw, strictly limited to one shape.
Those are package relative imports, not directory relative. I went down that same path of failure
Doesn't work on Windows AFAICT. Edit: Why the downvotes? I tried this out on my windows system. It had no effect. It's treated as just another input character.
Makes me wonder about the possibility of adding a bit to the installer that simply lets you select from commonly used packages, and uses pip to install them for you. I suppose 'NumPy' is the obvious objection to that (being both commonly installed and occasionally complex to get installed correctly)
This breaks when the desired `value1` is false-ish.
You can't blame PEP8 for that. It even mentions the 'hobgoblin of simple minds' bit!
Not sure what the situation with Python2 is, but Python3 defaults to the encoding of the current locale. For most sensibly-configured locales, this is utf-8 (or utf-16 on windows?): $ python Python 3.4.3 (default, Mar 25 2015, 17:13:50) [GCC 4.9.2 20150304 (prerelease)] on linux Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; import sys &gt;&gt;&gt; sys.getdefaultencoding() 'utf-8' &gt;&gt;&gt; sys.getfilesystemencoding() 'utf-8' However, a) Not all locales are sanely configured, and b) in the case of filenames, a fixed encoding is not necessarily a real thing (some filesystems specify what encoding is to be used, but other filesystems (eg. ext4) simply store filename bytes without any encoding information or standardized encoding). TLDR: If your Python 3 is reporting ascii as default encoding, your locale is probably not sane and needs fixing.
I did a project at a biomed firm analysing the effectiveness of a machine learning tool they had implemented. It got me into scientific python, and over time I've added ability in a lot of the basics and generics that make up the language as a whole.
I wrote software for the grid that handles conversion of one type of particle physics data to another.
I wrote an analysing script for a lab course about stochastic resonance. Quite simple, read in ASCII data, some arithmetic, using only math module. Back then did not knew about numpy ,rewrote it after some years in 4 lines of code and got the same results, yeah!
&gt; Atlas Warriors https://github.com/lkingsford/AtlasWarriors nice! )
Thanks, I just hope it will help!
zipapp works great, the problems are more : - c extensions - must have python installed - must be the right version of python - packagin gui is a pain - so easy plateform specific format (deb, exe, etc) - 1000 differents tools to do the job (py2exe, cx_freeze, pex, zipapp...) - official tools only target dev packages, no end user packages. I don't think jar solves that either. What does jar do right that zipapp does not ? 