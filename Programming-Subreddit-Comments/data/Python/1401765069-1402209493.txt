Not natively but its fast enough in a vm: http://www.sagemath.org/download-windows.html
Damn. My memory failed me; it's C++14 that'll have that feature, apparently... My apologies.
&gt; and take ONLY THAT LARGEST TABLE AT THE BOTTOM don't understand. It's a dropdown of cities, so what about it ?
&gt;very clearly inspired by python I disagree with this. It _looks_ more like Golang or Javascript than Python syntactically. It _behaves_ in a similar manner to Golang in regards to looking like a dynamic language when it is in fact a compiled language. 
Is it compiled or back-ended by LLVM's JIT?
&gt; Pystone is a benchmark and produces some numbers "somehow" related to performance. No. They are not "somehow" related to performance. Pystone tests your machines Python integer performance. Nothing else. It does not test your machines performance. It does not tests Pythons performance. It is not useful to test different Python versions performance in relation to each other *except for when it comes to integers*. Yet you are trying to use that number to make claims about Python 3 vs Python 2 in general. You can't do that. &gt; We can discuss forever on what "somehow" means in this instance No, we can not. It is what it is. There is nothing to discuss. It is only you who refuse to listen, because it means you can't complain about Python 3. &gt; but if Python 3 is slower on that benchmark, then that's it, it's slower on a benchmark that is supposed to provide basic performance guidance. It is not supposed to provide basic performance guidance. &gt; You don't like pystone? Yes, I do. And as I have been saying repeatedly: It is useful to give a general indication of how fast pure-Python computation is on a specific machine. But you need to run the same Python version on different machines to yield a result that is meaningful and comparable. It is **not** useful for doing what you do: Trying to compare Python 2 and Python 3. &gt; Ask devs to dump the tool and replace it with something more meaningful (and maybe more friendly to Python 3). It is meaningful, **but not for what you are trying to use it for**. Which I have told you over and over and also explained why. How hard can it be to understand? Oh, of course, it isn't hard, you *do* understand you just don't care, because you don't care about performance, you are only here to complain about Python 3. That's why you created this account in the first place. &gt; See any similarities with Python 3 being slower than 2.7 in 50% of the benchmarks? It has in fact no similarity at all to this issue. Here's one that works: *You have a car with which you can drive to work in 30 minutes. The new model of the car has different driving characteristics. If you are driving to work mostly driving on a highway, or sitting in traffic jams, the new cars performance will not make any difference to you at all. This is the most likely situation. So probably the new car will just be a nicer car, but it will take the same time to go there.* *However, if you drive on roads that are very curvy you will find that the new, robuster and heavier car will not allow you to take curves as quickly as the old car. So then your trip to work will take 33 minutes instead. You may decide that this is worth it or not.* *On the other hand, if you often have rain, it has better suspension so you get better grip, so in rain the trip will actually go two minutes faster! And if you have snow, well, in snow you will cut the time in HALF!* *But you took the car onto the parking lot and made [donuts](http://en.wikipedia.org/wiki/Doughnut_%28driving%29) with it. It wasn't as good at making donuts, so now you refuse to even consider switching cars, because you claim that the new model "May take longer to drive you to work". You won't even tell us how you get to work, apparently **you don't even know how you get to work**, so we can't make an educated guess on if the new model will drive faster or slower for you.* *All I know is: I don't believe that you driving to work consists of making donuts. Although that it's theoretically possible, perhaps you works as a tire tester or something.* That's a metaphor that actually works here. &gt; If performance of my code is fine now and I don't need to worry about it now, then I don't need to worry about in in Python 3 as long as I don't move to Python 3. No. You don't need to worry about it *if* you move to Python 3. &gt; Should I decide to migrate, then I had to start worry No. If you don't need to worry about performance under Python 2, you don't need to worry about performance under Python 3. &gt; Hence the complaint about Python 3: ideally there should be no need to worry about performances when moving to a newer version of a language. There isn't a need to worry about Performance when moving to Python 3, unless you are already worrying about performance under Python 2. And now you will claim that I now said that there aren't "performance issues". And I don't. Some things are slower, yes. But the differences are not so big that if you don't worry about Python 2, you will have to worry about Python 3. &gt; Finally, I always appreciate your offensive attitude ("You seem not to be able to read"), but then again, everyone's a brave big mouth behind a keyboard, myself included :) Yeah, and since you actually can't back that up with knowledge or understanding of the issue, including not even knowing what the code you supposedly worry about does, I thing maybe you should change that attitude. I at least only have that attitude when I know what the fuck I'm talking about. 
As a beginning scripter, what are things python 2 does superior to python 3? I chose python 3 to start because I could understand it a bit better than 2. I'm honestly curious :o
It has IPython support.
The only advantage to using Python 2 is that a large number of libraries are built in Python 2. That alone makes Python 3 become a dealbreaker for many.
Your graphs aredifficult to follow. Wouldn't you think histograms be better for your cases?
Gcc has an objective c compiler which can be used on Linux bsd Windows and Mac. However I still prefer c
Histograms might work well for the first two, yes.
**That's It !!** I changed the import statement, in the script from the tutorial, to lower case 'tkinter' and it worked! Thank you! Wouldn't you think that if they made a change to a standard spelling of many years duration, that they'd arrange to give a more instructive error message? Unfortunately, I still can't get NumPy or SciPy to install. I can't even get NumPy to download properly! I'm beginning to appreciate perl more!
And then absorb their powers!
Swift is only for Apple development, so it's encroaching on Kivy for iphone, at the most. Go's type system sucks, it's nowhere near as easy to use as python. I haven't heard of a successful project using F#. Maybe they're out there, but I've never come across anything in the last few years.
What engineering "community"? There is not such thing. The only thing marginally related to that is the need for windows-only proprietary applications in certain workplaces or fields. You are not doing yourself any favor by using Windows for scientific or engineering work for no particular reason.
Let's see... new `pathlib` module, new `asyncio` module, new `venv` module with pip, lzma compression, unicode handling that isn't a mystery to get right, saner library module names, `yield from`, working secure SSL by default....
And Ada [did this ages ago](http://en.wikibooks.org/wiki/Ada_Programming/Lexical_elements#Numbers).
You can get most of those things on python 2 easily without introducing not backwards compatible changes to the rest of your codebase.
Our users love it, to be honest though I had a tough time setting it up to run the notebook in daemon mode on a debian machine.
I really like this approach.
General discussion of noise cancellation in software: http://stackoverflow.com/questions/6503562/which-algo-uses-for-noise-canceling-in-earphones
Thanks :D
Wow thank you so much. That solves my problem much better Sorry I took a while to check back.
The most battle-tested and widely recommended framework would probably be [Flask](http://flask.pocoo.org). You might want to take a look at [Morepath](http://morepath.readthedocs.org/en/latest/), too, though, it looks very well suited for such scenarios.
&gt;...but it's just not geared up for widespread adoption at the moment It seems to be enjoying reasonable adoption right now.
Once I can use mysql in 3 I will.
My depth is: RuntimeError: maximum recursion depth exceeded Here's one that works: https://gist.github.com/regebro/c100b67779c758654f20
pip install pymysql. Drop in replacement for MySQLdb.
I believe he was talking about the other page, when you actually click submit on one of the dropdown items.
OP explicitly said that the Ruby code only stores the Thread object (and its function-call code), and implies that the Python is equivalent, i.e. that the decorator merely wraps the function in a gevent thread object, storing that in ~~someplace or another~~ the local namespace as "task", without executing the function decorated (until the task is run of course). So in that case, no function code is run, and the decorator _is_ merely a transformation of the function. (Edit: Elsewhere the OP mentions that this would never be used at module level, for indeed it doesn't return a function, so this is only allowable in a local namespace.)
No. Thread.new starts a new thread that executes the block immediately, and I assume gevent.spawn does the same. Compare this to Celery for example, a task has to be explicitly started: @app.task def add(x, y): return x + y # nothing started the task yet, we have to do it explicitly add.delay(42, 23) I find Celery's way to be pythonic, but not OP's. But that's just my opinion.
Both of your examples are what decorators are intended for. They transform a method, but do not execute it.
A little tip for the super-lazy.. oneMillion = 1E6, moreMillions = 32E6 ;)
&gt; binds the thread object to a variable for later use. I guess either I misunderstand OP, or he misunderstands Ruby. As for `gevent.spawn`, it is an alias of [`Greenlet.spawn(func, args)`, which is a shortcut for `tsk = Greenlet(func, args); tsk.start()`](http://www.gevent.org/gevent.html#greenlet-objects), where `Greenlet.start` schedules a task for running in the current event-loop iteration. So while de-facto `gevent.spawn` _basically_ runs the function, all it technically does is schedule it for running (in the very very near future). So I would say that the OP is being reasonably pythonic.
&gt; The key thing about your argument is that it's all about what you expect. Exactly. That's what writing "pythonic" (or generally "good" code in every language) is all about: to make it easy to reason about code you've never seen before. To be able to do this, there are often certain conventions in place to help you communicate your intentions. For example, in C a variable named "i" will probably be used as an index, in Python, a variable starting with an underscore is an implementation detail. If you deviate from these conventions, you are making the code harder to understand. &gt; If you change your expectations, then the proposed idiom works very well. Yes, but why should I? Changing conventions works well for the computer, but you don't write code for the computer, you write it for humans. If you change conventions without a very good reason, you are making it harder to understand and reason about. For example, if I create an Float class where ``*`` means addition and ``+`` means multiplication, the code still works, and even if I document this, you will probably still hate me for it. Using ``*`` to mean multiplication is an arbitrary choice, but it's a convention that has worked well in mathematics. So well in fact, that every time you create an operation over some kind of sets, rings or fields, you will name an operation ``*`` only when it is kind of "multiplication like" in its properties, and ``+`` if it is "addition like". The math doesn't change, but you make it harder for your fellow mathematicians to understand if you break conventions because you feel they are inconvenient. Decorators were introduced to more clearly communicate a specific action. You are free of course to use them in any way you see fit, but OP asked whether it was Pythonic to do so. I find def task(): .... tasklet = gevent.spawn(task) easier to reason about than @gevent.spawn def task(): ... And all you lose is having to press 16 more keys to type it. Anyway, that's my personal opinion, if you disagree, that's fine.
What kind of package did you try? &lt; RuntimeError
As someone who uses python 3.4 on and old mac I can tell you that support is very annoying and that I spend way, way more time googlng to make simple things work than I should have to.
A custom project using Plone. I'm sure the reason is recursive requirements, that happens a lot in Plone, that two packages require each other. :-)
Haha, I see. 
For me, swift is especially interesting because of live-coding capabilities. Would be really nice to have some stable live-coding+debugging utility in python.
Does anyone actually have the code for the benchmarks? ... No? ... Sure? ... Well, let's wait before drawing conclusions then ;).
Most I would argue aren't normal words. "Qi," for example, is an alternate spelling for the generally more favoured "Chi." It does make Scrabble a more interesting game to play, though.
Flask (as mentioned by other people) and Tornado are both amazing.
Can you make android apps from jython? 
Objective-C wasn't so good? They need a new language? We can talk about this, when Swift run outside "Apple" stuffs. I don't want to buy a Mac to develop an app that only runs on iOS. Fell free to use.
In what way do you think it could be done more tidily with classes? Coroutines store the current execution point and resume from the correct place. With classes, as I am assuming you mean it, presumably you would have to call several different methods in order, but something would have to track which method to call next, and that logic would get duplicated everywhere. You also need to migrate any coroutine-local variables up into the object rather than declaring them at the point of use. Coroutines in Python are a bit clunky-looking, to be fair. But the concept itself is not something that maps closely to simple objects and methods.
&gt; Python community ignores CoffeeScript *"To install, first make sure you have a working copy of the latest stable version of Node.js, and npm (the Node Package Manager)."* Err, no. And what's its library support like, anyway? &gt; Javascript officially endorses as their future direction while maintaining a monopoly over browser client scripting Who is doing this official endorsement?
&gt; If you consider yourself a developer, or at least a tech nerd, then you watched Apple's WWDC ..eh? Why is it assumed that a developer or nerd would give a toss about iThings? Some might, but it's entirely a matter of taste, not tech. Personally I get more excited about pretty much anything other than iThings, and a single-platform language to develop for iThings is even less interesting than the iThings themselves. If you're excited about apple stuff and want comparisons to Python, Applescript is probably a fairer comparison.
You can make android apps with kivy and python (kivy.org)
The answer is "[maybe](http://stackoverflow.com/questions/11120130/programming-android-apps-in-jython)". AFAIK, Jython is mostly used for Weblogic / Websphere management (also for a bunch of software based on them), and as a scripting language whenever a Java-based application has to expose some sort of simple automation interface. You'll also find people writing webapps in Django on Jython so that they can write Python while running "that bloody jar" from some other project (i.e. libs or components with no equivalent Python version).
Disclaimer: If Flask has added more fine-grained control over routing lately this may not be true. I'd suggest Pyramid over Flask if you want to handle a lot of accept and content-type headers, which you most likely will. Pyramid can route based on client header, and even combinations of headers, which Flask cannot. With Flask it's not that easy if you want to serve both application/json and text/html on the same url, especially if the html URLs doesn't match the json URLs. with Pyramid you can have different views running on the same URL but with different client headers. Example: * /user/ID -&gt; html and json (check best accept match of the two, on POST and PUT also require content-type application/json) * /user/create -&gt; only html (accept text/html is enough) In Flask you would have one view for /user/ID that check headers + one view for /user/create that only returns html. In pyramid you'd have three views, one for /user/ID(best accept match application/json), one for /user/ID(best accept match text/html) and a third for /user/create(accept text/html). You could also use one view for the /user/ID route and change renderer based on headers in pyramid if you wanted to which would make it behave like Flask, except you could set the renderer in the beginning of the view instead of when returning. With pyramid it would also be very easy to add yet another view for /user/ID(best accept match application/pdf), in Flask you would have to add this to your already existing view, which clutters that views code. And there is now no easy way to add/remove the pdf views.
What advantages does this offer over just using ipython?
Also less drop-in but more official: [MySQL Connector Python](https://dev.mysql.com/downloads/connector/python/), a pure-python driver from Oracle which supports Python DBAPI v2 standards and [a bunch of other stuff](https://dev.mysql.com/doc/connector-python/en/connector-python-introduction.html). It supports Python 2.6/7 and 3.1 to 3.4. I'm not affiliated with Oracle, but damn is it nice when a BigCo does "the right thing" for the Python community.
I'm with /u/Yoghurt42 on this, I wouldn't expect the decorator to actually \*run\* the function, you should decorate to return a Greenlet instance and run it explicitly afterwards.
indeed, it's a very solid reasoning ...
That is great info, thanks. I've actually been googling to find such differences between pyramid and flask. Now I am glad we use pyramid!
you should add some description and "usage" of what it does and how to make it work ... that would be great TL;DR shooters like me
Check out [Custom predicates](http://docs.pylonsproject.org/projects/pyramid/en/latest/narr/urldispatch.html#custom-route-predicates) for more information. I'd also recommend taking a day to read through all official docs on Pyramid. The Pyramid docs are not as nicely organised as the Flask ones and if you only search for stuff in them you might miss some very helpful information/tricks that are in other sections.
&gt;until recently nearly all popular Linux systems still had 2.7 as default. That's still the case, as far as I know only major distro that comes with python 3 as default is arch and I think they had it as default for few years now.
&gt; Its much more heavy-weight I always read this, but after using both Flask and Django, I never found anything that would merit this statement. What part is more "heavy-weight" in Django?
&gt;but where would you place Python in the world of mobile applications? I wouldn't. It's pain in the ass to get working properly, and even if you manage to run it you'll be limited compared to native languages like java(android) and objc/swift(ios) and if speed is an issue then python is definitely the wrong language for your mobile app.
I think you may be overstating the importance of OOP in Python. Yes, everything is an object, but that's not the same thing as "write a class for everything". As a paradigm, it's supported, but it's far from the only one. Your class-based replacement for coroutines works in a simple case, but it breaks down when you need to do something more complicated than: @coroutine def f(): while True: sink.send(process(yield)) If you need a condition, or more than one loop, you're going to have to use some dirty hacks.
&gt; I feel that what you are saying (persistant execution state) is something that, rather than being "missing" from classes, simply is not required of them to achieve the same function. No. And yes. But mostly no. Many languages are perfectly fully-featured without needing coroutines. And many languages are perfectly fully-featured without needing objects. But those 2 features have their own strengths and weaknesses. Coroutines capture the concept of being able to execute different routines in parallel in a way that objects cannot. In particular, they capture the concept of being able to leave the routine in a very specific state, and to resume the routine in exactly the same state as it was left. For this reason, the printer/grep example is a poor one because neither routine has any state. For this reason, you can go further than saying *"That could be done more tidily with Classes"* and just replace the 2 with free-standing functions. It's more useful to think of a situation where there is some degree of changing state within a routine, especially when the state in question is actually the progress through a function. Here's a pseudocode example from the sort of thing I do when working on multiplayer games: def login(): login_server = self.connect_to_login_server(login_server_address) # slow TCP connection login_token = self.send_auth_details(login_server) # slow transmission, and waits for reply game_server = self.connect_to_game_server() # slow TCP connection success = self.send_login_token(game_server, login_token) if success: self.playing = True There, I have 4 slow function calls, each slow because they require waiting on another computer somewhere else on the internet. With a system that supports coroutines, I can make each of those calls yield while the OS waits for a response from the networking subsystem, so that I can perform other processing (eg. updating the screen, if this is a game client). Better still, I can jump right back into that routine at the position where it left off, and it remembers all the local variables that I populated with previous calls. It gives me many of the benefits of threads (simpler code for concurrent tasks) with many of the benefits of single-threaded operation (fewer synchronisation issues between tasks). Usually I have to work in languages where coroutines are not typically available, and the code ends up looking more like this (Pythonised here for clarity): class login_handler(object): def __init__(self): self.login_token = None def login(): self.connect_to_login_server(login_server_address, _login_2_callback) # slow TCP connection def _login_2_callback(login_server): self.send_auth_details(login_server, _login_3_callback) # slow transmission, and waits for reply def _login_3_callback(login_token): self.login_token = login_token # gotta stash this locally, unless we can push arbitrary args through callbacks easily self.connect_to_game_server(_login_4_callback) def _login_4_callback(): self.send_login_token(game_server, self.login_token, _login_5_callback) def _login_5_callback(success): self.playing = True (This assumes I'm lucky enough to have decent callback support. Usually in C++ codebases I need to have a state variable which I'd manually change each time, and which dictates which of the next login functions to call.) In both examples, I've left out a bit of scaffolding, but the 2nd example is much more verbose, with no checks to stop people calling functions that shouldn't be called. Worse, the control flow is only implicit. (Especially if you use more descriptive names for each of the callback functions rather than just enumerating them.) Try rewriting these routines with a time-out on each connection, and up to 3 retries on each one. With the coroutines, you just stick a one-line loop in there. With callbacks... it's not so simple. In these cases, coroutines *do* offer significant improvements on clarity and readability.
There's something wrong with [the official one](http://dev.mysql.com/doc/connector-python/en/index.html)? Has always supported Python 3. 
[CherryPy](http://www.cherrypy.org/) is a great contender.
The reason is because that's the OS that the company I work for uses - not by my choice. And by 'community' I mean clients/business associates - nearly all of whom use Excel/Windows to share docs. It definitely could have something to do with the field that I'm in - I don't know . .
Thanks will have a look.
And because you know our stuff here, you can decide which database is superior, I guess.
Gee, how dare syntax and compatibility be broken in a few minor places in a MAJOR VERSION UPGRADE! It was totally insensitive of the core developers to sneakily do this behind everyone's back with no documentation, no communication, and no inclusive process like that PEP one that other language has. Seven years later I'm going to whine like a little bitch. Oh... wait... I'm in /r/ruby right? 
I've yet to come across any real world python code that actually uses co-routines. I also have not come across any design problem where I immediately though "oh, this is an excellent fit for co-routines!" I don't really agree with the sentiment that any co-routine is more tidily done with classes, and I don't necessarily agree that your class-based grep/printer solution is cleaner than the co-routine one. The two seem to embody rather different philosophies, but both can be clear and easy to read. I feel like there are cases where a co-routine is easier to digest than the equivalent class: @coroutine def pairs(target): while True: tup = ((yield), (yield)) target.send(tup) class pairs: # sentinel object so we can recognize the empty buffer empty = object() def __init__(self, target): self.target = target self.buf = empty def send(self, value): if self.buf is empty: self.buf = value else: self.target.send((self.buf, value)) In this case it's not so much that the class solution is very unclear, but the coroutine solution is just.. crystal. Elegant, I'd say. I think it's that elegance, and the very UNIX-like idea of programming with streams, that makes people excited about coroutines. It promises the UNIX philosophy of very small, simple, widely applicable and reusable tools to compose your programs. I think the main problem is that coroutine pipelines are just entirely separate from all other python code. You can very easily compose co-routines, and you can very easily compose classes, but it's not obvious how you could use a co-routine based library in your class/function based code. You can write glue at the border to bolt them together, it's just that the paradigms don't mix very well, it seems to me co-routines are usable in a pipeline only, and regular python functions and classes are usable in a not-pipeline context only. Given this, and the fact that 99% of python code out there is not written as co-routine pipelines, it seems unwise structure my code that way. All that said, I must emphasize again that I've never felt a need for co-routines nor have I seen them out in the wild in anything other than toy programs. It may be that I too am missing some concept that allows seamless integration of coroutines.
&gt; it is forced because a large portion of the community has expressed against it and has been ignored. It's a small portion of the community, and it's 7 years after Python 3 was released. Far too little, far too late. Idiots deserve to be ignored with their moronic requests that no further development happen on Python 3 and instead everyone must regress to Python 2 because said idiots are too lazy /stupid to write correct Python in the first place, on Python 2. 
flask is a routing layer/controller and a templating engine. that's it. django is that. plus an ORM. plus a defauly admin app. plus a plugin framework. etc. all of that leads to a framework optimized for a relatively narrow (but commonly used) set of use cases around basic CMS enginers - blogs, news sites, etc. that's where the weight comes in. 
pyramid + angularjs
Thanks; the login/token/auth example gave me a good idea of what's involved. I think my mental block was in forgetting that, sometimes, the process flow of a program is not within the control of the program; sometimes, a program is blocked by externalities like network lag or server load, and object code to deal with that can be messy. So, this also suggests why coroutines are so emphasised in asyncio, which was the main reason I found myself exploring coroutines in the first place. As asyncio, as hinted at in the name, deals largely in externalities like network and other IO tasks, coroutines are a better fit than classes. But outside of these IO tasks, classes usually make more sense. Thanks!
Modules in Python are case sensitive. In the move from Python 2.x to Python 3.x, the core developers took the opportunity to rename some modules so they followed standard naming practices (such as modules being lowercase). So, if you're using Python 3.x, use the import `from tkinter import *` with a lowercase "t". As for numpy, pip probably failed trying to compile numpy due to a lack of a C compiler (numpy is very heavily C-based). I have found the best bet for installing C-based Python packages to get them from [this page](http://www.lfd.uci.edu/~gohlke/pythonlibs/). Building numpy from source is beyond my level of expertise, but google around if you're not interested in installing a binary. I'd also suggest taking a look at [r/learnpython](http://www.reddit.com/r/learnpython) if you're just learning the language and ecosystem. People are likely to be more helpful over there.
I found /u/kylotan's example more compelling, and I think your pairs class may have been contrived to appear uglier in this case, but thanks for the example all the same! I think that, for code where external blocking effects are not a factor, classes are a far superior fit for clarity and understanding, but I can see now why coroutines are a nice fit in the specific case of networking and other blocking operations. Alternatives to this would, in my view, include threads with callbacks and reference-passing functions (i.e. pass a dictionary to the function, and check that dictionary for the necessary values until fully populated), but coroutines are an acceptable method. I think I was also unnecessarily confused by the `yield from` syntax, because of the dual-use nature of `yield`; like lua, `yield` both passes a value to the caller, and receives a value *from* the caller. When seeing `yield from`, I thought it meant "encapsulate this generator so it can be passed around cleanly", but what it actually means (I think) is "get a value yielded or returned from this generator for immediate use".
For those who are probably curious, [here's](https://github.com/Mionar/aiosimplechat) a not-quite-trivial client-server chat program using the asyncio module (submited yesterday to this reddit). It serves as a good example of the class of problems the aio module was designed for. (OP, note that asyncio was inspired by and incorporates lessons learned both from Twisted and gevent, the two major asyncio libraries for Python. That there are two competing versions is a testament to how important it is -- coroutines largely make that sort of code cleaner, or so I've come to believe.)
why do you find unreasonable to evaluate the language as a whole? it's not correct to say "You should test Python 3's speed against code that matters to you" and use that to justify the rest, it's the other way around, you first evaluate the general advantages/disadvantages and then decide if there's specific things that apply to you that can offset the previous.
&gt; why should someone fluent in Mandarin use variable names that have no meaning in their language? for the same reason every non-english speaker learns the language and reads documentation as well as writes code with it: reusability the world would be much more productive if there were a single language, even outside programming.
You think the class version can be done cleaner? I'd be interested in how you'd do it. I'm not sure you've got `yield from` quite right. Say you execute this statement in a function called `a_coroutine`: a = yield from other_coroutine() It's like `a_coroutine` temporarily becomes `other_coroutine`. Iterating over `a_coroutine` will yield values from `other_coroutine`, calling `send()` will send the value into `other_coroutine`, etc. It's a sub-co-routine, basically. Once `other_coroutine` has completely exhausted, execution continues in `a_coroutine`. If there's a return statement in `other_coroutine`, its value is assigned to `a`. In earlier versions of python, when you wanted to yield values from a subgenerator, you would have needed to do this: for i in other_coroutine(): yield i That's part of what `yield from` does, but in addition it also handles send(), close(), and all the other stuff coroutines have. It allows generators and coroutines to be refactored, so it was a crucial feature to make asyncio and coroutines really work. EDIT: I incorrectly remembered how `return` now works in co-routines
+1 for Flask. Writing RESTful APIs with Flask is a breeze
Those were meant to illustrate what you can do with generators when you don't think of them as "things that produce a list".
No. The Jython interpreter won't work in the dalvick VM.
This is a bit old, it's 2004 .. though Jython did stand still for a long time it has recently been updated to python 2.7 compatibility.
coroutines *are* classes. well, they are objects. the yield thing triggers some auto-magic generation that creates objects that manage the state. so really you're right. they *are* nicely handled by making a class. that's what happens! &gt;&gt;&gt; def foo(): ... yield 1 ... yield 2 ... &gt;&gt;&gt; f = foo() &gt;&gt;&gt; type(f) &lt;type 'generator'&gt; &gt;&gt;&gt; dir(f) ['__class__', '__delattr__', '__doc__', '__format__', '__getattribute__', '__hash__', '__init__', '__iter__', '__name__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'close', 'gi_code', 'gi_frame', 'gi_running', 'next', 'send', 'throw'] &gt;&gt;&gt; f.__class__ &lt;type 'generator'&gt; &gt;&gt;&gt; f.__iter__ &lt;method-wrapper '__iter__' of generator object at 0x125ed70&gt; &gt;&gt;&gt; f.next() 1 &gt;&gt;&gt; f.next() 2 all that the `next()` function does is call the `.next()` method! if you want you could "hand write" a coroutine with a next method (and the rest) and it would work as expected.
Gah, it's even more confusing, then! I get it, as you've described it: `yield from` acts like an immediate `yield` in the current context, and (as a statement in that context) it returns the return-value of the `yield from`'d generator. But the docs, and indeed even the PEP that proposed it, didn't make that clear to me. I think they've overloaded the `yield` keyword a degree too far, and perhaps the rejected keywords in the PEP might have made a better fit. As far as a class that awaits two sequential inputs and returns them both together, I think your implementation did not require an "empty" sentinel, as most stuff-that-looks-empty will evaluate false in Python. So, I'd have written instead (presented with your original coroutine, and including buffer-clearing which was missing): @coroutine def pairs(target): while True: tup = ((yield), (yield)) target.send(tup) class pairs: def __init__(self, target): self.target = target self.buf = [] def send(self, value): if self.buf: self.target.send(buf.pop(), value) else: self.buf.append(value) Note, I never said that classes could compete with coroutines for brevity, only for clarity and ease of debugging/refactoring! :) (edit: Forgot to use pop() instead of explicit index-then-clear. Also, I hope some future version of Python include's coffeescript's @ syntax as a shortcut for assignment in __init__ to remove all that boilerplate..)
It's common sense if you're letting us know your preference for deprecated software ..
I'd seen that, and it looks great! And it was because of asyncio's adoption of coroutines that I knew I was missing something. I didn't think for a moment that it was a bad idea, because these are programmers who know a great deal more than I do! If they reckoned coroutines were a good move for asyncio and I couldn't see it, then it was my problem. :) And, thanks to the answers here, I have a better idea of the use-cases for coroutines. Thanks, all!
Thanks, but I was aware of that. In the sense that everything in Python is a first-class object, I know that generator objects are, too. I meant rather that the style of programming that uses coroutines would be improved in many cases by the use of explicit class definitions and use; I stand by this in the case of local tasks that are not IO or network bound, like many of those in the example set I linked to in the OP. For log-tailing or pipelining, I'd still encourage explicit classes with encapsulated state and explicit methods rather than coroutines. But, for network and significantly IO-bound tasks, I can see the beauty in coroutines..but I'd still be very cautious in their use, because they encourage (I feel) a pattern of mutual recursion that could be very difficult to debug.
Django's admin is completely opt-in. What do you mean by "plugin framework." There's nothing in django called a plugin. Do you mean signals, or middleware, or template tags, or the django concept of a reusable app? If you look at the big companies running django, eventbrite, Pinterest, Instagram, yandex, discus, your statement that it is optimized for a narrow CMS use case is hard to justify. You don't seem to know very much about what you're saying. Your arguments against sound second or third hand, or at best opinions formed in a few hours of tinkering. Yes django is a heavier framework than flask, but it also does a hell of a lot more. The real question should be: is it the right tool for my job, i.e. am I lifting weight I don't and won't eventually need. I'm trying to toe the line here between correcting misinformation and being a fanboy. Apologies if I've stumbled over the line.
In a few years, you'll have some project experience and consequently a different opinion. I won't blame you for that now.
Some meta-programming stuff is missing. One I have raised a bug for: https://github.com/micropython/micropython/issues/614
By the way, the micropython ARM board is superb fun to play with.
I would *love* to see if this could be statically compiled into a portable binary, as Lua is. A lua-like static python3 would be really handy for USB drives for portable use on WinMac devices. A static python3 that could be compiled and loaded over adb to android would be fantastic, and might even find its way into some ROMs like Cyanogenmod to enhace development and customisation. Finally, if they could add a mode that detects something appended to the mobile binary, you'd have a really simple way to deploy trivial apps in the same way srlua and love2d: Just use `cat mpython myscript.py &gt; standalone_myscript`. Time to dig into the source and see what I can understand of it..
Derp, well caught! :)
Firstly, let me say that I'm only coming to grips with the asyncio thing myself, so my answers may be of little value. Re: second question, I think the asyncio module and its general approach requires not only the syntax of python3 (which could be backported from __future__ in theory), but the *semantics*, which can't be backported easily. And, as Python 2 is officially the past-tense of Python, I wouldn't expect a backport anytime soon. If you want something like asyncio in python 2, my suspicion is that the answer is "use twisted"..but then you're locked in the past for another year or two, because their porting efforts will take a long time. On the fundamental question, I think the answer is *no*. Using yield statements does not fundamentally alter how things are done under the hood; your code still makes requests and awaits their return before proceeding, whereas using asyncio means using an event-loop framework that hands off execution to other processes while awaiting responses from yield. Again; I may be speaking untruths while I get a grip on this myself. :)
You know this document is from 2004, right? ;)
No, we should give money to PyPy who is moving towards python 3 compatibility and get an actually performant interpreter for python.
More battle tested? Django was used by pinterest, the washington post and instagram. Who uses flask?
Each of those pieces can be swapped out. Furthermore, most of those pieces are necessary in modern web apps. It's much better to have a consistent admin app that will integrate admin code from multiple disparate projects than a hodgepodge of home-made admin apps that don't play well together. Same for ORM.
I have a feeling that the migration from 2 to 3 is still going to take a while considering that alternative runtimes like PyPy are still targeting the 2 series and the version based off of 3 is still in beta. It also doesn't help that Guido's employer Dropbox is doing their own implementation called Pyston (https://twitter.com/gvanrossum/status/451782706313977856) that targets the 2 series instead of 3. Has Guido lost faith in 3 or is this simply for Dropbox's personal gain only due to all the legacy code?
&gt; django is a heavier framework than flask Again, how so? What is "heavier" in Django. I am really just asking this because I would like to know. I always hear it, but after using both, never found anything that would be "heavier". 
Frequently when someone makes a list of possible improvements a PYthon 2.8 release could make, many got shot down with "six already does this". That misses the point IMO. One of the big challenges in porting closed source code bases is the intermediary, getting a bunch of people into the habit of writing Python3 friendly code before the whole system works. Having builtin language faculties for this stuff fundamentally changes the defaults from a thing that requires a third party lib, and is clearly a second class citizen.
Ah gotcha. Thanks
If you want the full asyncio functionality (albeit with slightly different syntax) in Python versions &lt;3.3 take a look at [trollius](http://trollius.readthedocs.org/) Glancing at the gist I see some blocks of code (`Articles.query.filter()` and `requests.get`) that will block until they receive their responses. Whilst it might be fast enough to not be noticeable, it is not async. Async means that code that takes a, relatively, long time to yield results will not block execution of the rest of the program,. Database lookups and HTTP requests do take a relatively long while and the program could be doing something else whilst waiting for that. The yield statement used only creates a generator, and as cathalgarvey states does not make it asynchronous.
&gt; yield from acts like an immediate yield in the current context I'm not sure from this wording whether or not you truly understand what it does, namely it yields, in order, _every yielded value from the subgenerator until it's empty_. Then, and only then, is any return value stored in the assignment target. So it's far more than just one yield from the subgenerator, it's literally `yield`ing _every_ value `from` the subgenerator.
I'm glad to see things like this getting out on the market. I love doing embedded work. The debugging can be frustrating, but there's nothing more exciting than seeing something come to life -- really -- and beep and boop and move robot arms. Anything than can make it more accessible for everyone is great. I own a Beaglebone Black and I love it (and programming in Python on it), but it's not as bare-metal as, say, an AVR. If Micro Python can bridge that gap, that's an awesome thing.
I see, so each request in a yield list still waits for a response before proceeding, do you think the yield at least accomplishes parallelism (i.e. all requests are sent out at once)?
Most complaints are about the difficulty in moving old code. So getting into the habit I think isn't as big of an issue. And it's easy to write Python 3 friendly code already. http://python3porting.com/preparing.html 
Not cherry picking. It IS NOT default. It will (most likely) be in 14.10 where `python` won't exist until you explicitly install `python2`. You can interpret the docs and bug tracker on ubuntu's pages however you want, but it doesn't mean that python 3 is, at the moment, default python version on ubuntu - if you still think that it is, then... I don't know what to tell you, any further discussion is pointless. I mean it says so in like the first sentence on the page: &gt;For both Ubuntu and Debian, we have **ongoing project goals to make Python 3 the default**, preferred Python version in the distros.
I'm using it the same way parent comment (to which I was replying), canonical, python developers, official documents etc are using it.
This is no longer true, the packages that don't work on 3 are a small minority. Many people who advocate coding in Python 2 did not try using Python 3
I almost feel like I would switch to a new language if I felt there were a better option (for glue code tasks mostly). The 2.7.x/3.x split is unfortunate and I don't see it going away anytime soon. 
&gt;Its very silly to say something is "default" when it doesn't change the support trail. Both versions of python are equally supported in ubuntu, they both are part of the shipped version, and they both are guaranteed to run stable. Python 2 will be dropped as far as default installation goes. Future versions of software are written to work with the default version. &gt;because the whole platform is guaranteed, not just parts. Except that python 3 came with broken `pip` and some other things in 14.04 which probably wouldn't have happened if it were default version (since full support for it is expected from canonical)
Both work in both python 2 and python 3. (Also you don't need positional params i.e. `1`, `2` etc in python 2.6+)
I can give you one reason - Django South. If you plan to deploy your API to production, you will eventually have to do schema migrations. It's unavoidable. Unfortunately, database migrations with SQLAlchemy using Alembic is a huge pain in the ass.
I'm more interested in what Python 4 will look like. Python 1 was around about 6-7 years before Python 2 was released, and Python 2 was around about 8 years before Python 3 was released. Python 3 has already been around for 6 years. How soon should the next major update occur for Python to remain relevant for the next decade? Wouldn't you like to use a version of Python that isn't hampered by the GIL and was designed for quick and easy concurrency and multiprocessing? Regarding the original topic, I think it's too late for Python 2.8 to be of any use. If it were introduced, it would simply be one more Python version for library maintainers to support.
I know all that. Still, that doesn't make it "heavy-weight", because you only use what you need. If you disable unused middleware and contrib apps, you have nothing more than what Flask is.
It can be done for very small areas. Spaces outside that area will potentially have double the sound volume due to constructive interference.
I use them as a beginner just to keep things in order for myself, I'm not quite sure enough in myself to let them self index yet. :(
Oh it's OK to use them, I was just pointing out that in the example you provided you don't *need* them - in case you didn't know. If it's easier for you to learn like that then just continue to use them and ignore that part of my comment :)
I have ported all my libraries so I'm way past porting but I would still love to see Python 3 not exist. This has nothing to do with "difficulty in moving old code" for me.
&gt; a thing that requires a third party lib, and is clearly a second class citizen I don't see how you can characterise third party libs as second-class citizens. They are part and parcel of the ecosystem: most (if not all) of us couldn't get any useful work done without third-party libraries, except when working on Python itself. 
I have the board with micro python on it. A neat little thing.
Have you tried just passing -static to the linker? i.e. add -Wl,-static to the C compiler flags? You would have to cross compile at the same time ofcourse (if you are not already on an arm). You could actually probably build the interpreter on-board on your phone/tablet using Debian Kit (or similar): https://play.google.com/store/apps/details?id=org.dyndns.sven_ola.debian_kit
You do have a bit more, i think: the middeware overhead, the internationalization/unicode conversions of almost everything. The fact that contrib apps define api's intended to be consumed by others means they have to build to the general case which is almost always "heavier" than a "own use only" api. "Django as it is commonly installed fresh before custom code is written" includes auth, sessions, admin, etc. and thus I think it can be reasonably argued to be heavier than "flask as it is commonly installed fresh before custom code is written." It's heavier because it does more out of the box. By the simple definition of "LOC" it is heavier. Heavier doesn't necessarily mean less performant.
i'm not railing against django, your reply suggests that you see that as me doing, and again - reread what i wrote - i'm not. i'm just explaining (from my perspective) the "weight" comment from /u/chilly_est. &gt; You don't seem to know very much about what you're saying. Your arguments against sound second or third hand, or at best opinions formed in a few hours of tinkering. no, i've built some sites and products in django, so i know a bit about what i'm saying, more than you're stating i do. i concur with you (and others) who say use the right tool for the right job. just make an informed decision. 
In 1.7 django gets native migrations, written by the author of south.
Fair, you know more than was in that comment. Parts of what you said were, however, wrong as far as I can tell, so I'm curious: * What do you mean by "plugin framework"? * Please say more about why you think "django is optimized for a relatively narrow set of use cases around basic CMS..."
iPython isn't enough?
I'm glad you got tkinter working :D sorry i can't help you with NumPy/SciPy :/
Fair. Ignorance and haste are so hard to distinguish, especially on the internet. I recant my prior accusation.
You do realize it was a joke right? The Python community is divided and that's OK. There was a debate recently about the @ operator. Only the math people wanted it and the more web-friendly people complained it would just clutter the language and also complained about the __ matmult __ name. Python needs to support all the major groups.
"A bit old"? I know certain fundamental concepts don't change much (or at all), but 10 years is ancient for almost all programming languages.
For only very simple datasets, though.
Really hope work on the Teensy 3.1 port starts back!
Why do you care what version other people use? Are you on some kind of crusade?
&gt; the middeware overhead Comment out what you don't need and its gone. No i18n or anything, just urls.py that calls whatever function you attach to it. &gt; Heavier doesn't necessarily mean less performant. Looking at it from a tech perspective, I would agree with you. However, try asking people, almost all of them will tell you that heavy means slow and light means fast. That's just marketing. The reason I am asking so much is that I fell into the same trap. I was preparing a project, and always heard about "Django -&gt; heavy", so I started looking at Flask (and Bottle, webpy, etc.) Just to come back to Django wondering why people would keep telling me this stuff about "heavy". These frameworks are all the same, one comes as a package with one single name, the other comes as a package with differently named components (Flask, Werkzeug, Jinja2, etc). There maybe reason to argue about differences of these components. But then, you can use Jinja2 with Django just as easily as you can use Django's template engine with Flask.
&gt; Its much more heavy-weight In what way?
* I wouldn't call myself advanced, but understanding data structures and algorithms helps a lot. If not for implementing them yourself, at least you have a better understanding of how the common data structures work in Python: dicts, lists, tuples - so that you know when to use what and at what expense they come at. * Understanding **Object Oriented Programming** also makes things cleaner and more modular and I also have found that **functional programming** make it easier to use lists/tuples more elegantly and getting into the habit of solving everything using lists and tuples. Recently, by virtue of having a better understanding of functional programming, I've done things like using a list of lambdas for certain methods that lend themselves well to this pattern. I still find it's hard to break out of the C programming mould sometimes, but at least I'm aware of how bad python code I'm writing. * I also have found generators and descriptors to be useful sometimes, but I'm still learning and getting into the habit of using these. * /r/dAnjou's advice is really true. I once asked for feedback on IRC and two really helpful people gave some great feedback, which really helped the overall design of my project and improved the quality of the code. Basically, I was advised against using a singleton design pattern and just pass objects instead and this has proved to make my code so much better in hindsight. One of those helpful people was Ned Batchelder, a really great Python community member. So, yes. Try to make your code as nice as possible, with comments and good variable names and ask for feedback from the community. They are really helpful. 
The place where I first discovered the utility of coroutines was in your basic MUD. See, you have lots of little actors running around. It would be nice if you could build a program that describes a single actor. It would pause execution when it issues a command to the universe, and resume when there is new input. This model of execution is useful beyond MUDs. For instance, if you have a long-running statistics collection process and such. Now, you could simply write all the steps of operation into their own method, and use the object's state as the state shared between execution, but this is clunky and makes writing simple programs complex.
I don't understand that attitude. Seriously, the differences aren't that big, and most porting is not a horrid pain. It is sometimes, but mostly not. This is so amazingly overblown.
&gt;The 2.7.7 release also contains fixes for two severe, if arcane, &gt;potential security vulnerabilities. 2.7 has been EOL'd This is a bug/security fix release. The worse thing any project can do is just tell users they are on their own for bugs and security issues.
Your answer is given by /u/jnazario in a reply to /u/yaix
No. Perfectly happy with the current version of the original Python; tons of libraries, works great, needs nothing. Python 3 is another language; close, but not 100% interoperable, missing many libraries, porting absolutely requires retesting, therefore not of any interest at all to me. 
He is right - there are different frameworks for different use cases. Discuss all you want - django comes with more functionality and more "weight", than flask does, as he said, due to functionalities being integrated in django by default. Most applications do not need all those things and especially smaller backend API's. Not all projects are like Instagram, Pinterest, etc... And if Flask can do all the functionalities that Django can while maintaining lower "weight", why should I still pick Django? While Django has a lot built in and does not need very much "extensions" after starting a django project, then Flask is the opposite. You get the core and install the extensions you need. I'd rather pick the functionalities I want, so my code will be all used. Why carry stuff on in your project, that your project does not even use?
The comment that's current at -2?
Enough as in "microemacs is enough to write a kernel"? Sure, why not? It doesn't provide any live editing capabilities though (you change a source file, output is seamlessly updated). 
So instead of only taking necessary parts of the framework, that you'll actually need, you take them all and start opting out the ones you do not actually want? Personally it seems like pointless work. In the end, true, they all perform similarly. But if I really just need a small backend API for an application or something similar, I'd rather go for flask. Maybe its just experience speaking now, but I'd build a website with api up in flask 2x faster, than I would with django from scratch...
Every time I hear the postman, I think my micro python board is coming ... Any day now.
&gt; most (if not all) of us couldn't get any useful work done without third-party libraries Are you counting things like sys and os as "3rd party"? If you are, then yes. Otherwise, no. :)
Nope not in the traditional sense. But, I'd love to see a Python VM that would run both 2 and 3 code. Heck, I'd put my money where my mouth is and pony up some serious cash (for me that is) for a dedicated project like that.
&gt; How soon should the next major update occur for Python to remain relevant for the next decade? Consider. C has "remained relevant" since its inception. It's still the go-to language for anything high performance that isn't platform specific and has a moderate timeframe. The original c language is fine; and development has remained compatible. This is the right path. Even c++ and objective c are both properly evolved c: I can write c within these environments and not even use the new comment style -- and it'll all still work. Why is it that you think Python has to change in an incompatible manner to "remain relevant"? Its relevance is entirely about its power to do things well and in an understandable fashion. It's a *great* language. It isn't broken in language terms, and it doesn't need fixing. If it WAS broken, changing it in a COMPATIBLE MANNER would be the way to go. Even if you wanted to "upgrade", for instance, the print capability, then you need a new one that does not break the old one. eg "print" works just like it always did, and (handwaving) "spew" works the new way. Hence old code works, and the new ideas can be used by those who find them compelling. That's evolution. But when you break previously existing, working code, that's mutation -- and the users are inevitably going to form a new community. Incompatible change is *not* a good thing. Fixes are. Added features are. Face it: Python 3 was, and is, a bad idea. It fractured the python community (and THAT will decrease relevance, count on it) and what good ideas it implemented, it held away from its original userbase barring unconscionable amounts of rework and testing for any significant application. What Python 2.8 should be is all of python 3's good ideas, implemented in a compatible manner. It's far past time to call Python 3 a really bad idea. All these years, and it *still* hasn't gained decent traction (rabid supporters who reflexively down-vote contrary opinions notwithstanding); huge numbers of libraries remain unported, huge numbers of applications can't run under 3, the evidence shows that the process isn't all that palatable. Close this path and get back on the compatible path. It's the smart move. There's NOTHING about any of Python 3's good ideas that REQUIRE incompatibility. NOTHING! NEVER make your user's previous work obsolete and/or nonfunctional. It's a basic tenet of successful software development. 
I've used GSL (http://www.gnu.org/software/gsl/) when converting some MATLAB code to C++. There appear to be Python bindings for GSL at http://pygsl.sourceforge.net/
Take a look at scipy's ode capabilities: http://docs.scipy.org/doc/scipy-0.13.0/reference/generated/scipy.integrate.ode.html According to the scipy wiki:http://wiki.scipy.org/NumPy_for_Matlab_Users ode15s is generally equivalent to: scipy.integrate.ode(f).set_integrator('vode', method='bdf', order=15)
Before the revision at pycon this year the EOL was 2015. It was a good move to calm people down about being strong armed into Python 3 when there in may peoples minds there are outstanding issues. I don't like that 2.7 was extended to 2020...but this release is fine and 2.7 has only been around for 4 years...EOLing now would be a terrible idea and would probably further foment a crisis of confidence in python 3.
&gt; How soon should the next major update occur for Python to remain relevant for the next decade? Good question. At this point there simply aren't many changes people would like to see that are backwards incompatible. And I doubt that anyone will come up with anything as painful as the bytes/strings/unicode change. &gt; Wouldn't you like to use a version of Python that isn't hampered by the GIL and was designed for quick and easy concurrency and multiprocessing? That's actually completely unrelated. GIL is an implementation detail, and not a part of the language. Neither Jython nor Cython has a GIL, for example. Removing the GIL in CPython would lead to a slow-down. Various attempts of solving that has been done, none has as of yet reached a satisfactory conclusion. Python 3.4 is designed for quick and easy concurrency and multiprocessing. CPython does have a GIL meaning it's not good at spreading task loads over multiple cores with threads. 
Thanks for this... eye-opener. I think for me it is time for some self-reflection (sadly it's probably not meant ironically)
Or you know, you could just enjoy the language you use, instead of all this stupid stuff you mentioned.
Agreed. 2.7 will never go away as it's always going to be the de-facto sys admin/small tasks language because you want your code to be as portable as possible. That includes hosts that will never see python 3. There are of course many other sects where python 3 will never be adopted, for example maya scripting, enterprise users, etc. I wish the python community would stop trying to kill python 2 and shame its users and realize that they are for good. Not to mention the fact that they're an overwhelming (but silent) majority of python users.
&gt; What Python 2.8 should be is all of python 3's good ideas, implemented in a compatible manner. It's far past time to call Python 3 a really bad idea. All these years, and it still hasn't gained decent traction (rabid supporters who reflexively down-vote contrary opinions notwithstanding); huge numbers of libraries remain unported, huge numbers of applications can't run under 3, the evidence shows that the process isn't all that palatable. Close this path and get back on the compatible path. It's the smart move. There's NOTHING about any of Python 3's good ideas that REQUIRE incompatibility. NOTHING! &gt; NEVER make your user's previous work obsolete and/or nonfunctional. It's a basic tenet of successful software development. A-fucking-men. GVR might be much more well mannered I wish he was more like Linus. Everybody who thinks that such massive compatibility breaking changes that break decades of people's work are a good idea should read this: http://felipec.wordpress.com/2013/10/07/the-linux-way/
No because I'm not interested in porting anything to Python 3. But I would love to see 2.8 nonetheless because I'd like to see the platform that's actually running my code improve.
&gt; The 2.7.x/3.x split is unfortunate Why?
I don't understand the negativity. You guys want improvements, but not change?
That was not really the point of the argument. But to answer: Why not? Its the same amount of work required.
Because it's simpler when the majority of people are using the same branch. Because there's a lot of arguing over this split. Because there are many libraries that still haven't been ported to 3.x. . . so you could be in a situation where you want to use something like asyncio with a library that hasn't been ported to 3.x yet and then what do you do? So, apparently you feel that the split is just fine. Would you care to explain why?
I agree, I'd like to just move forward to 3.x but there are still many libraries/projects that haven't been ported. I'd also like the various Linux distros to start shipping with 3.x as the default system Python.
I just like the idea of it - it seems more logical. Difficult to bring an analogous example, that would make sense... Its like extending a class in programming. Instead of getting all of the methods, that can be overridden and then deleting the ones you do not want to edit seems more work than only implementing overrides of the methods that you'll actually use :)
If you judge your opinion on the amount of votes of a comment, you're going to have a bad time.. A lot of people voted for Hitler in 1933, look what happened after that.
&gt; Because there are many libraries that still haven't been ported to 3.x That to me is the only valid argument, and that itself can be resolved. &gt; So, apparently you feel that the split is just fine. Would you care to explain why? The actual engineers and creators of the language, who are lot more familiar with the codebase than I am, decided to bring about significant improvement, they needed to break backwards compatibility. That is perfectly acceptable -- if you want the improvements, you use Python 3
&gt; If you judge your opinion on the amount of votes of a comment You're making an assumption. I was merely identifying the comment. I too think it's incorrect however.
Then I assumed correctly? :) Well there's some heavy discussion below it, I'll let that make that decision for you instead of starting a new thread here. The OP wanted a backend that will be a data-server and easy to setup. Flask is way easier to set up, than Django (5 lines of code for "Hello, World!" instead of initializing a project via Django script and then modifying some files to get it working in the first place. In the end - it's all about the scope of the project.
Happy cake day, btw
&gt;The actual engineers and creators of the language, who are lot more familiar with the codebase than I am, decided to bring about significant improvement, they needed to break backwards compatibility. That is perfectly acceptable -- if you want the improvements, you use Python 3 Right, but you didn't answer my question. . . you seem to feel that the split is perfectly fine and that we wouldn't all be better off if most people/libraries/etc moved onto 3.x already. Look at Perl 6. . . it never really happened. Perl development just fizzled out.
I haven't run into a data set yet that was hard to get modeled in DRF. What's an example of one that you'd say isn't simple enough to work?
Oh, no then you misunderstand me. I think the reason for the split is fine. That more libraries haven't become Python 3 compatible is the primary problem which needs resolution.
Thank you.
Yours is a much better argument that the one you referenced. Frankly, it would be cool if it was clearer on how to get Flash and Django to play nicely together. The other day I wanted to implement an asyncio style end point in Flask along my main Django app, and it just seemed ugly. Flask looks very good for that scope of "bottled" project.
Not really, because you are not loading anything other than the stuff you need. But in case you then happen to need it, you just remove a # and find the documentation in the same format as everything else. But that's just personal preference.
I'll cede that your preferences are reasonable for you so long as you'll cede that my preferences are reasonable for me. You prefer to order a-la-carte, I prefer to order the prix-fixe or the chef's tasting menu. I've never found django's weight to be a burden. Usually, I think the few pounds it adds weighs less than the average implementation of each feature, and almost always less than if I was to roll my own. 
Sure, but is any of these things blocking *you*? That's the relevant question. :-) And if, then what is blocking?
Yes, but you need the extra work to comment out the extra's implementations.. But in the end - yes. It isn't really THAT important, they perform similar in the end.
True, I'd like to see something like that happening as well, they are extremely similar already, to be honest :)
That's interesting. I've never had to argue the size of django too much, so I can see that point. I've always felt django was a great size, and the separation of core and contrib lets it be nearly the exact size you want. On the point of midleware overhead, checking if each installed middleware defines a hook at a given level has a small but non zero cost that flask doesn't seem to bear. In my opinion that cost is peanuts compared to the flexibility, but if you're trying to juice every last request per machine, it is probably worth somewhere between a few and a few hundred requests per second per machine at scale. 
1. Perl 6 isn't even released yet. 2. The changes are WAY bigger than Python 3 changes. It's just not comparable.
You make an excellent argument, all else equal. But the OP says they already have a lot of Django experience. So the cost of learning flask has to be weighed against the cost of learning just DRF/TastyPie/etc. In the end, they're both good choices.
It's an interesting idea, but I'm not sure how it would work. How do you know if it's Python 2 or Python 3 code, for example?
Well. . . for example I've been planning on using Flask and asyncio but the head Flask developer is one of the more outspoken complainers about Python 3 (and to be fair, it seems that some of his gripes regarding Unicode are legitimate). So. . . Flask DOES run with Python 3 but I don't have a lot of confidence that it runs well. Also, many Flask plugins don't yet work with Python 3. So what do I do? Bite the bullet and hope for the best with Python 3? Or use Python 2.7.x and skip asyncio? I'd rather not use a library ported to Python 3 by a guy who hates Python 3. . . so I guess using Django or Pyramid (whatever) are options too. Long story short, if we all just agreed that Python 3 was the future, then it would be easier. The default distro Python change would be a step in the right direction too IMO.
Yeah, I wish people would stop complaining about the existence of Python 3. It exists. If it was a mistake or not is a moot point. It's not going to suddenly unexist. I think the consensus is that Python 3 is the future, but we'll never get everyone to agree.
[Eli Bendersky's article](http://eli.thegreenplace.net/2009/08/29/co-routines-as-an-alternative-to-state-machines/) has a pretty decent explanation about a way to use coroutines in Python.
Right, the changes are bigger but. . . [the design started in 2000 and development of the first implementation started in 2005](http://en.wikipedia.org/wiki/Perl_6) That's 9 fucking years ago! WTF? There are several implementations underway but none are "done" yet: http://en.wikipedia.org/wiki/Perl_6#Implementations. What this effectively means is that Perl coders are either sticking with 5.x and will probably be resistant to upgrading a la Python 3 resistors OR they've just given up and moved on to some other language/toolset. Which is what I did years ago when I started using Python (I tried Ruby but found Python to be better suited to my tastes). Python 3 has been released but it could "die off" like Perl 6 appears to have done. 
Thanks for the link. The attitude the Linux kernel guys have is exactly what I expect all projects providing critically important infrastructure would have. It's too bad that many working on other critically important projects don't get it.
I had a super-quick look at the code (I don't have pyglet installed, so I did not get a copy) and I have just one question: why do you use dicts for self.cells since you assign ``True`` to all items that are present? I would have thought that using a set instead would make more sense.
Yes, great link.
"x in y" is the bottleneck in my code; dicts are optimized for it. It's also easer to extend to arbitrary-state automata later. I'll look into it though. Thanks :3
Will do. :D
Which library in particular is missing? The only truly massive one I can think of off the top of my head is Twisted. I ask because I hear this used as an excuse a lot, but then when pushed to name the library, it's either already been ported, or would be trivial to port if someone had the desire.
I've been eying flask for a long time now, however my question is why the hell are ebooks so expensive? sorry, but $28 is just ridiculous.
Thanks, great link. I seem to remember that an effort was planned to revamp the Pyramid docs, did this already happen? Anyway, they are pretty informative, the question should be how Flask managed to make such outstanding docs.
&gt; How do you know if it's Python 2 or Python 3 code, for example? Now that's interesting. I mean a VM could just support two versions of bytecode and work with that (although a Python 2 module importing a Python 3 module would be problematic), but you're gonna want to add a compiler for both versions as well. You could try to compile it at the same time as both versions, a'nd if one fails, you know it's the other (so if the compiler sees a `print "foo"` it knows it's Python 2). The problem here is that most changes aren't directly syntactic and there are ambiguities (`print (1, 2)` is valid in both 2 and 3, but has a different meaning). I've thought about implementing a VM that could take a third form of byte code, the "I don't know what version it is yet, figure it out at runtime", but ambiguous code is a sticking point, because they force the VM to choose a version &amp;mdash; and figuring out the right version beforehand would be undecidable (say `print(type(range(10)))` or even `x &lt; y`).
Having the same VM, but different compilers would be doable, but I'm not sure it solves the problem, as you want to compile one module with Python 2 and another with Python 3. It would require pre-compilation, which does against how Python works today...
I don't really recall my tests from a few months ago but I'll try. Their modeling is pretty much useless for anything other than a straight join you have to step out of their modeling scheme. And if you want your API methods to not represent individual tables and take their columns as params, you're going to have a bad time. I seem to recall trying to actively monkey patch all kinds of stuff that would end up being relatively simple if you skipped the framework. I ended up with flask and pybatis.
Yeah, that was kind of an implicit point of my first paragraph. If you're willing to accept the idea of compiling as a separate step (you could have a compiler taking command line flags for which version to use, and maybe even try to figure it out for itself by default), and if you have a solution for multiple modules with incompatible Python versions, it probably wouldn't be that hard. Okay, the modules thing still needs a good solution. The easiest one I can think off that doesn't end in chaos is to limit the Python version used to a single one per session (if the main module is for 3.4, modules it imports can't be 2.7, for example), but that would be kind of boring.
&gt; Wouldn't you like to use a version of Python that isn't hampered by the GIL As long as it doesn't slow down single core perfomance.
&gt; if you want your API methods to not represent individual tables and take their columns as params, you're going to have a bad time. That wasn't my experience with it at all. The one time I needed a non-straightforward abstraction, doing some pretty arcane date-based timezone stuff, once I found the right place to do it, it took me shockingly few lines of code in a get method of a class based view. Though, finding the right place, and understanding serializers, renderers, etc was a bit of a mental slog. I'd love to see more of what you were trying to do -- if only so I know the limits better when I recommend it to people. Edit to add: It looks like only getting a subset of columns is as simple as this: def get_queryset(self): columns = self.request.QUERY_PARAMS.get('columns', None) if columns: return MyModel.objects.filter(...).only(*columns) return MyModel.objects.filter(...) 
Jython compiles to Java bytecode, just like every Android app is before it's automatically converted to Dalvik bytecode. Whether the "Jython interpreter" will "work in the dalvick [sic] VM" isn't related.
You add... #python2 at the top and it's required
Sorry. When you select it on the dropdown and click SUBMIT, it takes you to the page for that city From there, I want to pull that larger table on the bottom, along with the location title ("Abilene, TX MSA") Then I want to throw it into a single excel sheet, where the tables for each respective metro will be stacked one on top of the other
wxPython and VTK are the ones I care about. PyPy also doesn't support Python 3. wxPython is close and has been close for a long time, but it's not released.
The guys on #django IRC recommended that highly. My struggle I guess is that I've used node for front end applications and I guess I expect the project setup to be almost as easy. I'm finding that using Django means more lines of code to achieve things I could achieve simply in node.
&gt; Why is it assumed that a developer or nerd would give a toss about iThings? Because Apple is a major player in the tech field, and has been behind important innovations and implementations in the past. Knowing what they are doing and where they are heading is part of the general tech culture. It does not mean you have to buy any of their product. Full disclosure  I own exactly one Apple device: their technically excellent USB charger.
If you want automatic switching between stiff/non-stiff then you can use, scipy.integrate.ode(f).set_integrator('lsoda') this can be nice sometimes.
Thing with Flask is that it has some boodoo-mombojumbo going in it. Is so simple, so simple, i can't believe how simple it is compare to something like Django or Laravel!. 
Is a more robust and update version of it.
Another huge issue with why certain people haven't ported to 3 (besides the 3rd party libs) is many distros of Linux are still defaulting to 2. This happens to be the case where I work because the systems we deploy to only have 2.x on them so we won't port to 3. Until those systems default to 3 (or even have 3.x installed) we regrettably won't be moving forward. 
Good point lol
Free candy? No thanks. First, why should I outsource my user database to an US based company, make my uptime depended on their uptime, and accept the latency for the backed API calls? Second, this service is only free for a limited amount of API calls. As soon as your site grows, you have to pay or somehow hope to get your user data out of their hands again, which they most likely want to prevent. 
 if (__name__ == "T-Bone" or __name__ == "la araa discoteca") { assc = { ["bigote grande", "perro", "manteca"] : ["Discoteca", "mueca", "la biblioteca"] } palabras = ["Manteca", "bigote", "chicate", "pequeo"] cabeza = "nieve" cerveza = "bueno" }
Actually I would tend to down vote it into oblivion. Why? Well let's see: 1. Objective C is not a single platform language, it is however a language used largely by one company. 2. Learn assembly language and you are focused on one platform, yet nobody dismisses the value in at least knowing Assembly language. 3. It is actually a little early to dismiss the language before it launches. We don't know Apples intentions but I wouldn't put it past them to see the language submitted to a standards body. It would actually do Apple a lot of good to Shepard a standard. 4. Sooner or later you will need to write platform specific apps anyways. 5. It looks like much effort was put into making this platform work well with C &amp; C++, almost like a compiled scripting language to support C &amp; C++. 6. Most cross platform languages and the associated development kits are thick and inefficient, this is a huge problem for constrained systems. To get the best performance out of modest environments you need to go platform specific. 
I don't find it unreasonable to evaluate the language as whole as a first step, but OP was already past that first step and was trying to justify it as business decision where "It's better because XYZ" doesn't fly. You have to be specific and stating with general improvements over specific areas of interests does not build a good case for the change. Most businesses, especially those where engineering does not have the final say, want to know what exactly impacts their bottom line and how. For some this is a performance issue for others it's going to be things like unicode and bytes handling. Even business where engineering has the whole decision in their hands you need to be specific about how the changes you're using will impact your code. Refactoring code on especially large code bases is very expensive if you're running a service thousands of clients are consuming because of the frequency of use and depth to the code base. OP came here asking specifically about performance issues so telling him or to look at general improvements would not be helpful. Looking at general advantages and disadvantages of a tool or language before doing deeper research should be encouraged but it's the smallest piece of making the decision in terms of the process. Additionally you can't just offset disadvantages with advantages all the time either. A bunch of advantages even put together will not make one large disadvantage go away which means it's something you have to live should you decide to move forward. Sometimes this is an acceptable risk but in others it's a reason to not even attempt a switch.
Ninja-Ide -&gt; open project -&gt; F11 -&gt; F2 -&gt; ctrl +k -&gt; ctrl +k -&gt; ctrl +k git
&gt;So instead of only taking necessary parts of the framework, that you'll actually need, you take them all and start opting out the ones you do not actually want? Personally it seems like pointless work. Yeah, why not just learn an entirely new framework instead? The one whose sole marketing pitch seems to be "it's no worse than django" and "it has fewer pieces enabled by default". That seems like less work?
&gt;Most applications do not need all those things And django does not force you to use them. It's absolutely trivial to turn them off. Furthermore, while not all projects may need them, *most* projects do, so it makes sense to do them all in a standardized way so that different projects that do use them can be integrated together without breaking and without a ton of boilerplate code. "It has fewer features" is not a selling point.
Gimmicks such as what? Session handling? Pluggable user authentication? I know flask has an admin console. It has hundreds of other useful apps to do all of the "gimmicks". The problem is that there is no standard. What if one app uses this admin console and another decides to use an entirely different one? Try combining two different admin consoles without tearing your hair out.
There's a good reason why it's at -2.
&gt; Which library in particular is missing? Google too tough for ya, eh? :) Ok, I'll bite: boto, Paste, MySQL-python, Fabric, pycups, carbon, graphite-web, supervisor, gevent, PasteScript, aspen, suds, pika, Twisted, eventiet, mrjob, python-daemon, oauth2, dbtext, python-cjson, SQLObject, python-cloudfiles, minitage.paste, thrift, Deliverance, python-openid, nitk, sentry, tiddlywebplugins.tiddlyspace, python-ldap, ssh, mechanize, z3c.recipe.scripts, pylibmc, adrest, M2Crypto, sqlalchemy-migrate, protobuf, vnc2flv, Cheetah, PIL... you get the idea. That took me a lot longer to type than it took me to find the information. &gt; The only truly massive one I can think of off the top of my head is Twisted. Massive? How is that a thing? The issue is: **for X program that depends on Y import, will it work, or not?** &gt; would be trivial to port if someone had the desire Again, not a thing. The intersection of the sets of people who work on imported third party libs and those who use them is not something you can count on in any particular situation; it's probably totally random. 
those are generators. coroutines are what Stackless or 'greenlet' provide -- threads under another name.
I agree that a Python 2.8 would not help with porting to Python 3 -- the reasoning here is sound. I'd still be interested in a Python 2.8, though, since I don't plan to use Python 3.
It would also remove the whole point, as you wouldn't be able to run Python 2 modules from Python 3 code.
What's the advantage of using couch db? It honestly seems convoluted and impossible to use. Like the 19 0s thing... wtf
I think using django is still a better bet
Make something small, add stuff and refactor. Repeat
Why is that? Do you really have that many files that you can't add a couple lines to the top? Maybe you can have a -2 or -3 to set the default. It's better than guessing.
I disagree it takes me 0 effort to use and customize user accounts with django 
The costs outweigh the benefits. If I have to give up my existing Python 2.x code or rewrite it, might as well consider other languages that aren't Python 3.x.
You don't have to. The difficulties in porting are way overblown in 90% of the cases.
The problem is in 3rd party libraries. They do not have that line added on top. You would then have to add them on top on all of the files in the library, every time you install it, as you don't have the right to change the libraries themselves. 
I would just prefer python 3.x was changed to more easily support running 2.x code, modules and extensions. For example, you could have some syntax like: from python2 import some_py2_module And this would load up some_py2_module module running in compatibility mode for python 2.x. That way we could write our applications in python 3, but still use the entirety of the python 2 libraries and modules that haven't been ported yet. No reasons or excuses to complain about adopting python 3 except maybe some additional memory and disk usage from having to load up 2 versions of the python runtime into memory. This could be made as a simple ctypes wrapper for the cpython 2.7 dynamic library in python3. 
Is there a reason to care for those sticking with 2.7 anyway? Very few can claim to be the authors of important library code, and are just end-users relying on deprecated code. I quote /u/fyngyrz: &gt; Perfectly happy with the current version of the original Python; tons of libraries, works great, needs nothing. Well, they look happy enough. They don't need any new features, bugfixes, or support whatsoever. Should just all leave them and their legacy code to die and move on instead of wasting time backporting features or trying to help them any further.
Yeah I agree, but I'm lazy and didn't want to write the mysql code or make a schema. I'm writing it for around 500 users so scaling it wasn't a big deal. I will admit a 100,000 request limit even for ~500 is pretty lame.
 &gt;Benchmarks are probably the wrong thing to focus on for Python in general. True to an extent. Everyone eventually has performance walls they hit but Python addresses the need for simplicity and programmer productivity. It appears that Apple is trying to also address these issues while delivering the performance of a compiled language. &gt;Tools like cython make it (almost) trivial to optimize python as/when required. Maybe not if Swift really delivers the performance suggested then what is the point In the above. That is if Swift is as easy to program in as Python then why wouldn't you choose Swift. &gt;Python excels in developer productivity, clarity and testability which are arguably hard to compare quantitatively. True again but Swift is looking good at this point. Obviously we need to see the final result and see how fast the tools world develops around Swift but I'm not going to knock it out if hand. 
This is like a 3 hours video and I was able to watch the whole video. This video should be shared in /r/postgresql TLDR; Postgres video * In postgres... * Everything runs inside of a transaction * Isolation modes REPEATABLE READ and SERIABLIZABLE take the snapshot when the transaction begins * pg_dump uses repeatable read * Backup * pg_dump * wal-e * Joins * Are really efficient in postgres * Don't be affraid * Large tables joining to small table is efficient * Time Represantation * Always use TIMESTAMPTZ * TIMESTAMP Is a bad diea * TIMESTAMPTZ is converted to UTC * Explain/Analyze * with analyze. Cost are displayed in wallclock milliseconds * Compare it to other query planner * Indexes * Hugely benefit from Joining large tables to small tables * Composite indexes * Columns must be used left-to-right * Indexes on (A,B,C) benefits on (A,B) query and NOT on (C) * Sometimes doing sequential scan is faster than index * Offset/Limit * OFFSET for pagination is slow * Reconsider date range for pagination * Sharding * Postgres-XC * Bucardo * Application hashing - See instagram * Schema Design * Normal Form - Important, Don't obsess about it 3rdNF? * Plural/Singular for tables - Doesn't matter * CamelCase, lower_case - Doesn't matter * Monitor * pg_stat_activity * Nagios/Ganglia * bucardo.org - check_postgres.sql * Log Analysis * pgbadger * pg_stat_statements * Python * South author recommends pg 
I think somebody is pissed off they have to use a language they don't like to pay the rent. :-) Well, I feel ya.
Haven't tried it, but just briefly looking at the repository and a lot of things there shouldn't be, eg: - django-trunk (this should be done via pip install, or similar - even for development versions of django). - .pyc files - the __pycahce__ folder (which only has .pyc files anyway) - the .idea/ folder (guess you use pycharm?) - the build/ folder should almost certainly not be there - pictures folder???? bit random, should that be in static? - the sqlite database - testing fiels like 'aaa.py' and 'aaa.js' Looking through the code, it seems like a very decent attempt at a first django project though :-) Main issues are only to do with git - biggest django related criticism would be that I would definitely be putting all the twitter templates inside the twitter application, not the project. That project is really more just an example of how to use the application, and shouldn't contain application-specific things. And therefore the same can be said about the static content (though for big complicated projects, designers hate having static content per application, I've found).
Could this replace CPython on the desktop someday?
I guess Flask has such good docs because Armin Ronacher is very good at writing documentation, among other things. The Pyramid docs are not bad and they're improving them constantly. The structure of the docs however confuses me but I don't know exactly how it could be improved.
That is not necessarily bad. The point of most businesses is to do something for you that you can't do yourself as quickly, cheaply or effectively. For something like authentication, which can be disastrous if you get it wrong, outsourcing that concern to a company which does only that could be a really good idea (hence efforts like OAuth). For me the key issue here is trust rather than the commercial aspect of it.
So you really want us to believe you're using Paste, gevent, eventlet and Twisted in the same project? Just run uwsgi, its better and has supported python 3 for a long time. Just want the event loop? Python 3 comes with asyncio in the standard library. ssh isn't even python, if you need ssh support, paramiko works fine in Python 3 since 1.13. mechanize is dead, last updated in 2011. urllib2 is the default urllib in Python 3. There's also requests. MySQL-python is dead, Oracle ship mysql-connector-python (for years) which has always supported Python 3. Fully supported in django too. PIL is dead, Pillow is the replacement and supports Python 3. Are you starting to get the drift here? 
and simply overblown in the other 10% 
There are only two Linux distros that matter: RHEL and Debian. Debian has supported Python 3 from the beginning, as it generally does for all good software; Redhat (since last year) provide Python 3 (and other updated languages) via SCL because RHEL 6 languished for so long they started haemorrhaging users to better distros. The next most popular would be Arch where Python 3 is already the default python. If you are using the OS system python for development, you're an idiot. Anything that comes with the OS is solely to boot the OS. i.e. python 2 in RHEL to run Anaconda (the RHEL installer). Anybody doing serious development would run SCL or another relevant Python distribution like Anaconda (the continuum.io distro) or Enthought, or BFS. Separate kernel from userspace, that's the Unix way. 
No, probably not. Sometimes it really is a pain. :-)
It's an interesting idea. It won't solve the bytes/unicode issue though, which is one of the big ones. And there are a lot of small differences that makes this difficult. For example, the python2 compatibility mode would have to support old-style classes. But will you be able to subclass from that in Python 3? Then you have to more or less reintroduce old-style classes... And the Python 2 objects would have a Python 2 API, while the Python 3 code would expect a Python 3 API. In most cases this is not a problem, but in most cases, porting is not a problem either. So I suspect (but I have no real hard arguments) that this would only work in the 90% of cases where porting is easy anyway.
Cool. I don't like the magic import though. Why not just provide simple callable that will do the job, instead of changing the importer? I would prefer syntax like this way more: pingpong = thriftpy.load("pingpong.thrift") * https://github.com/Eleme/thriftpy/blob/master/examples/pingpong/ping_server.py#L5 * https://github.com/Eleme/thriftpy/blob/master/thriftpy/__init__.py#L6
I was under the impression that Jython is an interpreter implemented in Java... I'm not sure bytecode really comes into it. Jython was written a long time before the modern ways of integrating java with scripting languages were around, I'm fairly sure the centre of Jython is somewhat like a large switch statement. I would love it if it does work in android, there was some work on this a number of years ago on google code, but it seems like it was shelved. https://code.google.com/p/jythonroid/ If it does work please post a link since I've been looking for how to do this since about 2008 - but gave up long ago. [EDIT] On the general info page the author notes that somebody could port jython to android if they are interested, then points them to SL4A https://wiki.python.org/jython/JythonFaq/GeneralInfo These days there are better solutions such as python-for-android (by the Kivy authors), Kivy itself or the pygame-subset for android. [EDIT - Add URLs + more info] 
Agreed. I got a little confused for a moment when looking at the example. Line 2 of The Zen of Python: Explicit is better than implicit.
Well, much of the slowness of Python comes from it being dynamic. So if you want to make the language itself faster, you would have to make it static. And a static Python? Well, that's just not Python. So the answer is: You can't really make Python significantly faster by changing the language itself. You need to create a faster implementation. And PyPy is doing just that. So if you want faster Python: Use PyPy. 
OK, so: &gt; No, probably not. Sometimes it really is very difficult.
I just updated the code, now the magic import hook is disabled by default, and can be install/remove by func.
I hope you get an answer, I'd be interested as well!
There are a number of such libraries - for instance PyAudio, PyMedia or GStreamer. Of these 3, GStreamer is the most powerful and complicated, and PyAudio seems the easiest and reasonably up-to-date.
Now I will give it a try. Because of client requirements, I'm implementing right now thrift server using apache thrift library and so far it's pain and confusion all the way.
Unfortunately, I don't think one exists. In order to do that, you would need a custom driver that could catch the output right before it went to the speakers, I don't think any of the ordinary drivers provide this. Maybe JACK on Linux, but I'm not sure. I think there is a company that provides drivers like that, but I'm on mobile and don't really have time to find it (should be working!) Either way, that's proprietary and costs money. Without knowing exactly what you're doing, your best bet is probably to just read in the audio file. Much easier and much cleaner than mucking around with non-portable, low level stuff like drivers.
Flask was designed for big project..DON'T step into the chaos of django...
Django is great for content sites (mostly thanks to admin), Flask is better for applications. CERN is using Flask on their http://indico.cern.ch/, is it big enough?
It's likely to be a heavily restricted form of python (The title should read "...an implementation of a subset of python 3") (Those working on it have suggested not even supporting unicode), so probably not. (Why would you want to use it over cpython anyway?)
What is thrift.
Now tie together 3+ tables which join in a one to many relationship, still allow all/most of them as input params, and still utilize the 'automation' of the framework. You may as well write it from scratch.
No. Flask was designed as an April Fool's Day joke. However, it *can* be wonderful on large projects. So can Django. Depends on your project and team.
I do not agree, that most projects do.. Just developed an API for a web, that uses no extra extensions from Flask at all - only one bigger external import, which is psycopg2 for database support.. Why would I in that case profit more from django than flask? OP asked for a simple backend framework. Flask is simpler than Django, thanks to initially coming with less stuff to deal with, period.
Awesome! Is there a repository I can look at, or any code I can test?
It is [scaleable cross-language service development](http://thrift.apache.org/) ... it is based on RPC ... I figured http/REST would be more useful? But then again I'm not building facebook and keeping it going :)
The benefits are too. ;-)
Are you considering all debian derivatives to be Debian? Because if so I'd have to agree, ubuntu is easily the most popular linux distro and ships with python 3
have an upvote for your cakeday :) Enjoy!
For mac you can use [Soundflower](http://cycling74.com/products/soundflower/) + PyAudio For linux check these approaches for [PulseAudio](http://freshfoo.com/blog/pulseaudio_monitoring) &amp; [JACK](https://pypi.python.org/pypi/py-jack/0.5.2)
&gt; as you don't have the right to change the libraries themselves. Why not? I develop a 3rd party Python library. You underestimate how trivial of a change to the code base this is and how willing developers are to please you. It also doesn't significantly effect how I develop the software. Make a ticket, shoot offer to do it for the package, make a patch, and be done. Once you have the script written that updates all the py files (assuming it doesn't use C code), which could be included with said Python, it's done. If it uses C code, you'd have to modify the build process. It's a trivial task.
Wow. So brave. Here in not fantasy land Apple happens to be a leading force in technology. I hate their products, their politics and their vision but I'm smart enough to realize that despite their flaws they are important. Only a fool would deny this and refuse to pay attention to what these sorts of big players are up to.
&gt; So you really want us to believe you're using Paste, gevent, eventlet and Twisted in the same project? No, that was a list of projects that aren't 3-ready. Nothing else. You sell straw hats with your straw men? &gt; ssh isn't even python There is an 'ssh' python project. You'll find it at pypi: https://pypi.python.org/pypi/ssh/1.8.0 &gt; mechanize is dead, last updated in 2011 And that helps the person who is using it move their project to python 3 how? Miss the point much, do you? Or did you just not get any coffee today? &gt; MySQL-python is dead Same answer. Yawn. &gt; PIL is dead Same answer. &gt; Are you starting to get the drift here? Sure am. You have no conception of what it's like to have a Python 2 project and find out that moving it means you have to not only update your code to match the new requirements, and test it, but you ALSO have to change the 3rd party packages you were using. In short, you're an egocentric cluetard who doesn't understand what the thread is about, which is **the problems posed by non-3 resources** 
Eh, yeah, I agree with these points. But if Python is your first programming language, and you want to become a developer, you'll probably need to learn other languages as well. And migrating from python-syntax to pretty much any-C-based-syntax can be a pain and confusing to new programmers. 
Yea , i would not want to do this! :\ I was assuming someone would have but looks like its really a big deal to do this!
Wow , looks like PulseAudio is really good. I will give it a shot , thank you!
WTF is that site? All the contents are in a single miniscule frame (No, I'm not running your scripts.) Awesome ASCII diagrams btw.
Then your impression was wrong. Well, no, it isn't, since there IS technically a REPL environment which understands Python and is written in Java, but the entire point of Jython is that it compiles Python to Java bytecode, so that you can take advantage of whatever else is also compiled to Java bytecode. &gt;Jython was written a long time before the modern ways of integrating java with scripting languages were around, I'm fairly sure the centre of Jython is somewhat like a large switch statement. wat
What a stupid blog post. C is a much better first language.
I was wondering the same thing (and ended up googling it). It'd be nice if the ThriftPy page linked to the page for Apache Thrift the first time it's mentioned.
Thanks for feedback, url link added
I think it's a bad idea because django is a fullstack framework. All the admin model is think for sql engine. You are using mongodb, so i think there is no proffit in doing it. You can also take a look at Pyramid if you are afraid of the growing size of your site.
It's about 3-5 times slower than fast binary compared to cython. The pure python implementation is 1.5 times faster than the upstream python implementation. The pypy with python code is slightly faster than cython. As far as I know the speed of upstream c extension is the best. But it's only searialize/ deserialize benchmark, in real life application, the performance gap may narrow because of the io wait, program logic, async process, etc. I'll try add a complete benchmark results later.
Not as confusing than if you **start** with a C-based syntax language.
author Andrey Vlasovskikh has a blog with lots of good stuff, including static analysis of Python and optional typechecking: http://blog.pirx.ru/
Thanks to all! I think I should continue using Flask, but I have to make better project code structure! :)
Is the talk as video online somewhere?
Like you said, i could rewrite my own home framework with Pyramid without any change to my tens of web-apps ! Not sure i could do this so elegantly with an other framework.
PyAudio is very easy and works on Linux, Windows and Mac, I'm not sure about these others. And we have pyALSA lib too.
The generator/coroutine idiom lets you take code that adds values to a collection to be consumed later and change it to do something interactive or lazy. I haven't used it often but when I have, the case is something like, 'search for prime numbers and yield them as you find them'. Granted that doesn't require sent values from the consumer, but similar examples involving Monte Carlo samplers do. Writing the same code the OO way requires awkward state saving when it can more naturally be written with nested loops and a yield statement.
Because they're not particularly effectively maintained.
It was released on 4/1. Doesn't mean it's a joke though... :/ edit: Oops, I had picked up the wrong impression from somewhere it seems it *is* an April Fool's Day joke *still* or something.
http://en.wikipedia.org/wiki/Flask_(web_framework)#History
PulseAudio allows you to set "monitors", where a specific audio output is linked to a recording program. You could (for example) set your music player to play to an output you don't use, and then set a monitor for a voice chat program, and then you can stream your music that way.
This looks similar to [zero-rpc](http://zerorpc.dotcloud.com/).
Your point being?
You can use Quokka to build a full stack content site http://quokkaproject.org Flask + Mongo
Never a bad idea to poke around /r/datasets for inspiration. You can also hunt down almost anything on /r/dataisbeautiful and just ask yourself "How would I expand on this?"
Also to add, if you index (c,b,a) you can do an SELECT a,b,c from x ORDER BY c,b,a NULLS LAST; you will hit the index (c,b,a).
See sources [2] and [3] in /u/nofunallowed98765's link.
I think that, for most people, Python and C should be the first two languages that you learn. I'm not so sure on what the best order to learn those two is though. I'm leaning towards C being a better first language for older beginning programmers, say around college-aged and older, while Python is better to start with for younger ones, so early high school and younger. Though if you learn C first, I think that once you get just a little past the basics of programming you can quickly start to pick up Python concurrently. If you have the maturity to handle it, I think learning the more difficult C syntax and picking up some of the fundamentals you have to know for C programming is useful to do first. And then going from a hard-to-write to an easy-to-write language is an easier transition to motivate than the other way. Of course, for younger programmers, C is a terrible place to start, and Python is great because of the nice syntax and instant feedback. At some point you're really going to want to learn at least some of C (or an equivalent) though, and after knowing how easy Python is that can be a hard sell.
In case anyone else wants to see what /u/C_Hitchens_Ghost sees, it's [this](http://imgur.com/aAGuWxt).
My first thought was "wow". But when I think about it: I wouldn't want to use my iPad for this. I mean, I love it, but the environment for computing is way more productive on laptops/home computers. Still impressive though and maybe useful for "emergency situations" ;) So, while it is nice that is generally works, I think that people sometimes try to cram too much into the tablet format. I mean, there are devices (e.g., laptops) that are way better for mobile computing in terms of productivity (how much you can get done in a given amount of time) - same applies to office apps. I love my tablet, but I am also aware of its limits. For example, I would use my tablet for browsing and reading. Same as I don't like reading a book on a laptop before/at bedtime, I wouldn't want to code on an iPad ;) 
It heavily depends on the motivation and goal of the person I would say. 
My engineering class is being taught VB.net right now. The professor started teaching digital technology to us and then within half an hour he taught us how to program in VB.net(or so he thought). Currently we are in the lab for another two weeks where we just type whatever he types without much reasoning from him. The worst: we will get a project assigned to program and have to turn it in within 14 days. So far no one except me knows what he is doing at all and I have my doubts that the professor knows what he is doing at all too. For example he is always confusing methods with functions and much more. When I am explaining anything to others I usually use python that I call pseudocode and they usually grasp very fast the concepts behind it. I think that is the strength of python as first language. It looks like pseudocode and teaches the concepts(actual programming you might say). 
That, if performance is relevant (as per the topic of this sub-thread), the latest Python 3 is not the answer, given that PyPy is not available and there can be performance regressions compared to Python 2.7. So, if the point is to make Python 20% faster, as 252003 was asking, then moving to Python 3 is not going to achieve that goal and it could actually make things worse performance-wise. Better to stick to Python 2.7 in that case. 
Thank you for that.
Great talk, some of it went over my head but I'll probably listen to it again and take notes. I wonder how Twisted will respond to this; will they abandon code and integrate the standard library paradigm, or will they maintain their own manner of doing things. I could see this going a lot like web.py vs. wsgi until upstream projects make make some firm choices about what to develop on. edit: I really want this to be something I can use, but I suspect it's going to be a lot like wsgi: I'll know it's there and that useful things run ontop of it, but I'll probably never have a reason to touch it.
I did it based on count, which really was simpler than I was thinking it'd be once I got into the code more. Granted, it could definitely use some refactoring, but for a start its very useful. I couldn't use any ORMs because this was for a static site and all the content is flat-file based so the most I had was building a "database" of posts I had parsed.
It's very simple project in python to create a static presentation. I hope someone does it profit or want to contribute to the project.
I started this way. I think if I tried to do C now I'd get annoyed with it. Just seeing up an environment for C is a chore. Python can do anything, so why write in any other language?
I agree. I'm learning Java (I know Python now) since it's used more in what I'm interested in developing but plan on learning C later on. 
i'm learning python at college. the reason why i think python is a good 1st language is this: in college, not everyone is going to be a programmer (i know i'm not - i'm doing a network engineering major) so the need to learn a complex language like C is not needed for everyone. doing programming is a core subject so i have to do it. as someone who won't be doing any amount of deep programming, i like the fact python is clean. i can look at python code easily see the intent of the programmer. also, i like the extend-ability of python and can see a point in the future where, as a network admin if i need to so a repetitive action i can write a quick and dirty python program to do it.
Subprocess.Popen is easier to work with. As far as what they were automating I think a lot would be IP related using the various frameworks available. 
You probably don't care about runescape, but their [auction house api](http://services.runescape.com/m=rswiki/en/Grand_Exchange_APIs) is a source for a simple example of a constantly changing market, especially since it deals with very specific units (in-game items). Would that be interesting? 
Research on beginners learing computer science has shown that syntax-heavy languages are slower for most. Now, granted that doesn't mean they're not useful for many applications but they're best for those who already understand flow of control, scope, etc, and are ready to get closer to the compiler
Your opinion is ok, but if you want to discuss you should support your claim and not make insulting comments
The bureau of labor statistics has a lot of open data. bls.gov
I thought that was implied in this context. If you take a good starting base (and are still alive &amp; kicking) then you're equally as good as that base, so Ubuntu, crunchbang, Kali, etc. all have Python 3. 
Ideally, you'd have Python bindings to the programs you're interested in using. For example, imagine performing a SQL query with mysql using subprocess. First you'd need to specify credentials, manually escape your query, parse the output of the query (each value in each row being a string), convert certain values to their proper data types (int, float, date/datetime/time, etc) taking multi-line and binary types into account, etc etc. The work just goes on and on. Luckily, we have bindings to do a lot of that automatically. So, before you go using subprocess for everything, look for applicable bindings on pypi or something first. It will be much, much easier. EDIT: by "binding", I'm referring to things you can import in your Python programs, such as pymysql or MySQLdb. Also, there are other libraries out there that can simplify interaction with subprocess. A couple that come to mind are [sh](https://pypi.python.org/pypi/sh) and [envoy](https://pypi.python.org/pypi/envoy). I've not used envoy personally. That said, you should absolutely learn how to use subprocess before using these helpers!
lmao python is anything but clean
Well that's the idea, as I understand it. Right now we're seeing a lot of people working with it directly on small projects. But the intent was to provide a common foundation for larger frameworks to build upon, allowing interoperability between them. If and once those frameworks move over, you should rarely have to drop down to asyncio.
Well, what do you prefer heavily templated C++? Java? C by an overly clever programmer?
&gt; So, before you go using subprocess for everything, look for applicable bindings on pypi or something first. It will be much, much easier. Thanks for the advice! Pypi looks really useful. Yeah I didn't think about modules at all - I should've known people would use those first instead of doing it the long way with subprocess.
Change log?
I don't think the issue is as big as you make it seem.
Slower does not mean that you shouldn't learn it first. That's why I condition on being mature enough to handle the slow pace and the nitty-gritty details that C exposes to you. As I said, for younger beginners I totally agree, you need to start with something that is relatively fast and that has instant, tangible results. But, from experience, many college beginners will be able to handle learning the concepts in C syntax, and doing it there teaches a lot of important concepts that are nice to know from the beginning.
Of course. This is just what I would recommend for someone who is generically interested in programming, if I (or they) had little knowledge of what they wanted to do with it or the future paths they might take. 
Check out a the tutorial at: www.economics.io The econometric implementation is simple, but not a cakewalk for most people (OLS w/ interaction terms -- so an exercise in proper interpretation of coefficients), but the whole thought process in the tutorial might motivate you to do something with scraped data. Implementing a more advanced analysis using GMM/MLE/2SLS/etc would be a straightforward addition to this kind of approach. By the way, I know the script at the end of the tutorial will fail. I made this tutorial (yes, it's my site) a while ago and the parser broke a while back and haven't had time to update it.
The solution isn't to mix python 2 and python 3 in the same code, just allow calling python 2 modules and libraries from python 3. Similar to how you can call c code from python using ctypes, add a python2 module that let's you call python 2 code. The module could handle translation of objects and types back to python 2. For example a Bytes object in python 3 would get converted to a string object in python 2 and a string object in python 3 would be converted to a Unicode object in python 2. Class objects could be pickled in python 3, then unpickled back into python 2 class objects before and so on. Obviously there would be some restrictions but for the most part it would allow running both versions concurrently through an interface the same way you would interface to other programming languages. Just think of python 2 as another language and the library would allow bridging between 2 and 3. 
&gt; none of the unicode issues of 3.x Unicode works way better on 3.x. I'm not sure what you're talking about, unless Unicode *is* the issue to you.
I'm not sure why you keep being downvoted. You're right. If someone wants to be able to just run Python 2 and 3 on the same *computer*, that's already easy. It's mixing their environments that would be hard. Python environments are already confusing enough, and a lot of the Python 2 holdouts have complicated dependencies on C extensions. A Python interpreter that supported both the Python 2 and 3 C APIs would be an unmaintainable monstrosity.
Since you're using Python, sklearn comes with a lot of "famous" datasets; e.g., irises, Boston housing prices. In the online documentation, it also has a lot of examples about how to apply different statistical techniques to them.
&gt; People in that channel have terrible attitudes Not at at unique to python.
Awesome! [Almost a year ago](http://www.reddit.com/r/IPython/comments/1jkfnm/anyone_else_wish_there_was_a_ipython_notebook/) I actually lamented about such an app not existing.
Coding on an iPad can be fun if the app is well designed (see Pythonista).
Yea, then you did it the way I think is the best. Are you happy that you learned C first? Do you think you would have ever gotten around to learning C if you had started with Python?
Is there a reason you've posted this 3 times already?
&gt; If and once those frameworks move over... Python hasn't shown a great track record for library maintainers to pounce upon new technology so far.... :-( 
 &gt;My first thought was "wow". But when I think about it: I wouldn't want to use my iPad for this. I mean, I love it, but the environment for computing is way more productive on laptops/home computers. Still impressive though and maybe useful for "emergency situations" ;) I think that is the wrong way to look at this. Having just come across this post I don't know a lot about the app, but if it is easy to transfer notebooks from other systems this could be an extremely handy app. One possible use is in the field when working on tools, calibrating or diagnosing issues on said tool. I could see other field uses where spread sheets might not cut it as far as data collection and processing goes. If you sit back for a moment and think about how some professions work I think you would have a more positive opinion. It is obviously not the tool for everybody, however it could become the tool for many. &gt;So, while it is nice that is generally works, I think that people sometimes try to cram too much into the tablet format. Well you are free to think that. From what I've seen so far of iOS 8 the potential is there for such apps to get much better and more feature filled. Don't be thinking tablets will go away anytime soon. &gt;I mean, there are devices (e.g., laptops) that are way better for mobile computing in terms of productivity (how much you can get done in a given amount of time) - same applies to office apps. This isn't an office app. Hopefully sales will be good and as such they can actually extend the App to work well with other apps on the platform. You seem to be biased against tablets in general here, that to me is a mistake. Laptops for instance suck if you are working in the field and have no desk from which to use it. &gt;I love my tablet, but I am also aware of its limits. For example, I would use my tablet for browsing and reading. Same as I don't like reading a book on a laptop before/at bedtime, I wouldn't want to code on an iPad ;) IPad isn't the place to do heavy coding just like it isn't the place for heavy E-Mail. However that doesn't mean the iPad isn't excellent for handling most people's E-Mail. That isn't to say that iPython on this platform will be extremely useful for development. However if you need to actually use your notebooks a field it looks good. Frankly im interested enough that I will probably check it out. 
It is only a beta at this point. 
Meh twisted whatever.
I don't think /u/pyslow is trolling, and his/her question is worded neutrally. I do think it's valid to look at benchmarks despite their failings, since we don't always have time to code our own just for comparison, which isn't the same as being lazy. There is still the question of what's a useful benchmark, and perhaps pystone is biased towards some operations. It might be helpful to discuss which (if any) benchmarks are better for which kinds of operations. All of your points are valid, but I agree most with the last one. We usually use interpreted languages when we're trying to save development time rather than execution time. When execution time becomes critical, a 25% difference is not that big of a deal. Better to seek a different architecture at that point.
They posted benchmarks that involved Python too... I consider it a shot across the bow. How will Guido fire back? Will people stop bringing Macbooks to Python conferences? The mind boggles. I honestly came here expecting to find Reddit aflutter about the existential threat posed by Swift, and there doesn't seem to be any interest. 
could start with some simple regression models using pandas. 
UNICODE. It's a "Python 3" implementation with *NO UNICODE STRINGS*. Holy &lt;bleep&gt;. I was very interested up until I clicked forward a few messages past the announcement and noticed that. 
Yeah, PHP is loads of fun, surprises never stop, no matter how much experience you have with it!!! On the other hand... Python is so boring, almost everything works as expected. And even that few things that do not work as expected fit on very small list...
Flask has a great community and is a killer project
Your first conclusion is correct (and the same as what I said). Your last conclusion is still incorrect, just as it was the last time we discussed this. 
Welll....no, the packages that don't work on Python 3 are definitely not a minority. But most popular packages, the ones you typically need, work on Python 3.
&gt; One possible use is in the field when working on tools, calibrating or diagnosing issues on said tool That's a very good point! &gt; Well you are free to think that. From what I've seen so far of iOS 8 the potential is there for such apps to get much better and more feature filled. Don't be thinking tablets will go away anytime soon. No, I agree with you, but what I wanted to convey is that every type of device has its strengths and weaknesses. I also write emails on my IPhone and iPad occasionally, but only if I really have to. I find my self more comfortable (and faster) at typing on a desktop computer or laptop. 
Unified ints. Better text handling. No more confusion of types vs classes. Cleaned up standard library. easier super(). Keysharing (saves memory). "nonlocal". *unpacking of iterables. Keyword only arguments. Hash randomization. A stable Application Binary Interface. command line history. HOLY SHIT TAB COMPLETION! yield from. pip installed by default. (I install a lot of Python versions, that's gonna be nice). And little things (for me at least), like exception chaining, namespace packages without setuptools, function annotations, function signature objects, isolated mode. The decimal module is 30 times faster.
An interesting alternative take on memoization. I wonder how it compares in terms of performance to more traditional methods.
When my MacBook Pro's hdd died, I spent a week using pythonista with an apple wireless keyboard... Didn't get much productive done on it programming wise but helped ease the programming itch, and I did iron out a few ideas I had floating around in my head. :)
For dropbox's "personal" gain, yes. Which is also why it's x86_64 only so far. Quote: &gt; this is the initial target due to the fact that Dropbox is on this setup internally. 
Not really. Some people will switch quickly, some people won't switch until they have to. You are in the latter group. That's OK, there is no right or wrong here. Adoption HAS been slower than expected, but I'm not sure this is an "issue" per se.
Isn't that being a part of "The brigade"? :-) 
What is "default" in this case? Python 2 scripts run Python 2, and Python 3 script run Python 3? If it's "default" or not seems to be splitting hairs and down to what you mean with "default".
Python is not used for mobile development. Swift is obviously inspired partially by Python, not just in the tools but also language constructs. Python users should check out the intro [Swift PDF](https://docs.google.com/file/d/0B_hMezUpeg22cTJLWk5vSC1vUWs/edit?pli=1), or watch the [Intro to Swift WWDC video](http://devstreaming.apple.com/videos/wwdc/2014/402xxgg8o88ulsr/402/402_hd_introduction_to_swift.mov?dl=1).
There's a decent chance it will be open sourced. Swift was started by Chris Lattner, who also started LLVM.
Oh I'm already very comfortable with generators and laziness. I'm just sceptical of using coroutines instead of classes in code internals that don't deal with IO. Before this thread, I was sceptical of all use cases, but I'm over that now. I still feel that the overloading of `yield` and `yield from` is confusing to a newcomer and could have been done a lot better. Even the PEP didn't clearly explain that `foo = yield from bar` wasn't simply assigning a name to a delegated generator from bar: it took this thread to explain that `yield from` yields "outward" to the caller, and assigns only the final return value of `bar` to `foo`.
&gt; You listed everything red on python3wos without thinking about the context for most of them, and darthmdh is calling you out on it. I listed a bunch of projects that aren't python 3 compatible in response to a direct question about what projects weren't python 3 compatible, an wholly appropriate response on my part. The *context* is, people have used these projects, and moving to Python 3 when you use such a project is problematic. This is a fact, and it is in no way ameliorated if a particular 2 resource is old, abandoned by its developer, or otherwise not of interest *you*. In truth, the reality is the opposite: The more abandoned and development free any 2 resource is, the better it makes my exact point: Those characteristics, combined with the incompatible nature of 3, raise serious issues that would, if 3 was 2-compatible, *not be raised*. Which you (and darthmdh) would know if you actually read the thread and spent any effort seriously thinking about the issues I presented, instead of wasting your time trying to mischaracterize what I have said. &gt; If your goal is to keep running old code, code built on MySQL-Python and PIL and all of Zope... It isn't. I never said it was. I'm talking about the fracturing of the community here. &gt; then why would Python 3 ever affect you? Really? Part of the community going one direction, and part going another, this isn't going to affect me? All the new goodies going into 3, and not 2, isn't going to affect me? People migrating to other languages because Python compatibility is broken isn't going to affect me? &gt; Your Python 2 interpreter will still be there after it's no longer maintained, just like most of those packages. Nobody will take it away from you. And again, a blatant straw man. What is going on here? Can you not actually comprehend plain English? I never said or implied I was concerned about "losing" Python 2. Clear now? Point 1: The Python community is fractured because python 3 is an incompatible release. That's a fact. This has negative consequences for the community and the language in general. The implication, and my assertion, is that a highly effective way to solve these very real and serious problems is to return to a wholly compatible development path. Point 2: People who have to retest and recode and choose new libraries to support their work if they want to move to 3 are facing significant obstacles, and just as you indirectly pointed out, they actually don't need to do that, so again, we have a force that acts directly to split the Python community. That is what is being discussed by me in my original remarks and the resulting pendant thread. Not my running code or library of any particular nature, or the idea anything is made *less* divisive because Python 2 exists as a separate path anyone can choose to take: it's about the fact that Python 3 has lower support and a cloudier future than it would have otherwise had if it had simply not put those people in such a position. Just a side note: Personally speaking, I tend to write my own frameworks and libraries other than a very small subset of the standard libraries, and so -- intentionally -- do not deeply depend upon the work of others, so I could really care less about 2-compatability or 3-compatability from a "my current code" standpoint. My Python codebase is hundreds of thousands of lines, but will not in any way suffer directly from 3, because it's never going to be converted to 3 due to 3's massive compatibility problems. I like the language a great deal, I think it was truly visionary, and I am regretful to see it fracture and so damage the community built around it, particularly as this was wholly unnecessary. It's bad practice to foist off incompatible changes upon any user-base; it never goes well and it creates entirely appropriate resentment *everyone* could have done without. Now look: I don't have a great deal of patience with fools, and these last two posts by you and darthmdh have been roundly clueless, so either address the actual points I've been making, or have the last word in any silly fashion you choose, because it is truly not worth my time to deal with further sidewise excursions into irrelevancy. 
How does it compare to Landslide and similar? What features does it have, that Landslide does not have? I'm curious.
I really enjoy it when people can't actually argue with what you say, but they don't like to face the facts, so they just vote you down. C'mon, -1? Really? Is that all you got? Show me how you *really* feel! :)
&gt;~~Managing My Time with Python~~ How to Program a Human 
&gt; Its unfeasible for non developers to deploy this entire stack on their own. That's not really true - distributions like Anaconda help alleviate that problem to a large degree.
Okay. Armin's criticisms are on point, though not fatal, and the Python developers tend to take them seriously. The first post you linked has already led to [PEP 461](http://legacy.python.org/dev/peps/pep-0461/). But, your I/O problems are almost certainly easier than Armin's, and even he writes code that's compatible with Python 3.
Two questions: Will I be able to connect to a remote IPython server?? Will this be OSS, I know IPython is BSD so it doesn't have to but I'm just curious!
Sounds interesting: can you provide an example so I can understand?
&gt; 'continue' not properly in loop Pretty clear what's wrong. What are you trying to do? Can we see more than 1 line?
The errors aren't cryptic. It really does what it says on the tin here. I can help more if I can see more than the 1 line. In the 1 line provided, there is no `while` or `for` loop, just an `if` statement. If we can see more of the script we can identify why the loop isn't working. It could be as simple as an indentation issue that is putting this `if` outside the loop.
This would work if you did something similar to with open(FILE) as fh: for line in fh: if line.startswith('From'): continue
Ah right, yeah.
I think the biggest problem with crossbar.io is that it reinvents too much to achieve something others have been doing through AMQP for a long time already (see [nameko](http://nameko.readthedocs.org/) for instance) and it's going to run into the same issues. I believe that composible services are the future but that system will look more like what captn proto is doing than what crossbar.io is doing. But captn proto suffers from the same problem: terrible APIs.
It is certainly prettier out of the box, that is for sure.
[Betteridge's Law of Headlines](http://en.wikipedia.org/wiki/Betteridge's_law_of_headlines): "Any headline which ends in a question mark can be answered by the word *no*."
Well this API is restricted to binary data. So you can call objects and methods and get strings and ints etc back. But that's a pretty limited view of Python life. But perhaps that could be useful for some modules. The question is if it it worth the effort in trying.
Actually, I refuse to upgrade to 3 just to annoy OP.
Keeping that one for future usages :)
There are some big differences though: - WAMP already solves PUB/SUB and RPC without needing to write anything on top of it. Plus, you don't need to understand queues, and routing, and all this complicated stuff. - it works as-is in the browser, you don't need to add 3 layers of abstractions like what we are doing now with AMQP - if you use Python, you don't need to install a (quite hard to setup) Erland broker on top of your stack - it's python, much easier to hack. It's twisted, it adds support for a lot of protocols to your stack for free - it's already nodejs friendly - it can work inside RDMS and nginx. This is huge - you can have a direct line between a browser and and android app, or a website and a auth backend, or a C++ code and a nodejs app. No additional hack is required. It's beautifully simple. - it comes with a process manager, effectively bypassing the GIL for Python and allowing you to start third party processes, making it an additional tool for you deployment (you can replace supervisor with it) It's a lot of advantages. nameko does some of it's stuff, but it's a lot more setup, it's an heterogeous stack and it doesn't work in the browser. 
Thank you. I've been wanting to learn more about functional patterns in Python. My code reeks of C. I love your list rotation. Really nice trick. Please continue to post things like this.
Explain to me how the Python 3 userbase is militant.
No, but that day my libraries don't have to support Python 2 anymore.
Well, it's not mysql which is all that is relevant for this thread. :-)
Well, that's *one* issue. The others are old Red Hat installations, and that a lot of people just aren't interested and won't switch until they need to.
&gt; WAMP already solves PUB/SUB and RPC without needing to write anything on top of it. Plus, you don't need to understand queues, and routing, and all this complicated stuff. First of all queues are not complicated and neither is routing. Secondly that totally does not make any sense because WAMP is a routing protocol so you have the same issues there. In fact, I'm pretty sure AMQP for the normal user is a lot easier to understand than WAMP. There are RPC systems written on top of AMQP like nameko and I would argue they are vastly easier to understand. &gt; it works as-is in the browser, you don't need to add 3 layers of abstractions like what we are doing now with AMQP That's a very misleading feature though because the security and scaling aspect of pushing into the browser is very different than pushing between services you control. If anything I would argue that not putting something in there is an anti feature. &gt; if you use Python, you don't need to install a (quite hard to setup) Erland broker on top of your stack Not sure what makes rabbitmq hard to install. It's literally a brew install / apt-get install and it's running. It requires zero configuration on the side of the server. So you replace an erlang broker with a python broker. What did you win, other than that you now need to build custom tools to inspect queues and that you probably end up with a slower system? &gt; it's python, much easier to hack. It's twisted, it adds support for a lot of protocols to your stack for free Not sure why I would want any of those things in my SOA. It's a nice to have thing, but it's not a feature. If anything for me that would be a negative feature because at that point I'm already locked into a specific ecosystem I might not want to use. &gt; it's already nodejs friendly I could not care less. &gt; it can work inside RDMS and nginx. This is huge Again, I could not care less. &gt; you can have a direct line between a browser and and android app, or a website and a auth backend, or a C++ code and a nodejs app. No additional hack is required. It's beautifully simple. The idea of randomly connecting things together with a "one solution fits everything" is not particularly new. There is DBUS, CORBA, DCOM, etc. The only new thing here is that you now replaced one protocol with another. This whole thing did not work out last time for the same reasons it will not work out this time. The idea is beautiful but the limitations *are* there. That's why things like captn proto are more interesting because they look at why it failed in the past and try to come up with new solutions. &gt; it comes with a process manager, effectively bypassing the GIL for Python and allowing you to start third party processes, making it an additional tool for you deployment (you can replace supervisor with it) Great, that's just what I wanted, a framework with another process manager built in. In the day and age of systemd and circus especially, a built in process manager makes absolutely no sense. &gt; nameko does some of it's stuff, but it's a lot more setup, it's an heterogeous stack and it doesn't work in the browser. Under the assumption that nameko is something people want to use, i can almost promise you that nameko is less work to setup.
what you want is memoization. https://wiki.python.org/moin/PythonDecoratorLibrary#Memoize
&gt; While terrible APIs can be improved (I'm all about that), I'd like so hear more about "it's going to run into the same issues". Software development runs in circles. RPC systems are as old as distributed computing. The problem of all of this is that the only part that actually properly works and scales is a ridiculously small subset. We're doing RPC over queues and we know exactly which set works for us and we decided very carefully which parts work and which ones do not. With SOA there is a general serialization overhead, lots of latency, accidental disconnected components, debugging nightmare because you don't know where stuff got stuck. There is a subset that works. But here is what it requires: * you need to have agreement of the data you sent through the wire and that needs to be perfectly compatible between the different parts of your system. * the serialization overhead is going to kill you. seriously. * without a super stable broker that lets you inspect the state of the system you are going to cry. A lot. * unless you are super conservative in writing your stuff, disconnects desync you badly and you end up with writing lots of small little workarounds to deal with it. If you end up buffering the subscriptions and replay them on reconnect you end up with a general acknowledgement latency overhead or with complex state tracking on all subscribers. * once people start using the system they go over board and chain different things together. At that point do you not only have state distributed in a cluster, you also have a really slow system but more importantly, the complete lack of insight of what happens. Captn proto's tackles these issues in a new way: * it solves the hard problem first which is type representation. It has a strong type system that can define your data in different languages. * the serialization allows for basic memory mapping which means that for the most part you can efficiently peek at data. * it has a distributed RPC protocol that is based on distributed promise chaining which eliminates a shit ton of latency.
I think it is reasonable for embedded devices.
As mitsuhiko said, AMPQ is what you currently use for this kind of problem. The nameko project is a similar Python project using AMPQ for this.
I think what you're seeing in your example is the CPython small integers cache. &gt;&gt;&gt; x = 1 &gt;&gt;&gt; id(x) 20070312 &gt;&gt;&gt; y = 1 &gt;&gt;&gt; id(y) 20070312 &gt;&gt;&gt; a = 999 &gt;&gt;&gt; id(a) 27130252 &gt;&gt;&gt; b = 999 &gt;&gt;&gt; id(b) 20598784 &gt;&gt;&gt; c = 998 &gt;&gt;&gt; c += 1 &gt;&gt;&gt; id(c) 27130216 &gt;&gt;&gt; x is y True &gt;&gt;&gt; a is b False
I have to say this is one of the best postgres training video so far.
Well, no, because in this case he can change the value. Indeed, for caching computation, he want's memoization, and not this. But that's just a stupid example.
Rgd serialization overhead: given modern CPU power, my experience is that it's mostly insignificant. And WAMP supports pluggable serialization: JSON and MsgPack are fully supported today, and you can plugin a different one if you need. From a Router point of view, the question I look at is (simplified): how much CPU power do I need to saturate a 10GbE link routing WAMP? The goal is to make that something like "4 modern cores". To give an idea: Crossbar does routing on a RaspberryPi at 28MBit/s (on a 100MBit NIC which runs over USB!) http://tavendo.com/blog/post/autobahn-pi-benchmark/ == I absolutely agree on the issue of how to inspect: a developer should have a tool to have a holistic look at what happens in a distributed app at the WAMP level. For example: live sequence message charts between app components. Who called whom, when, with what arguments etc This can be done (Crossbar internally could turn on WAMP session tracking on specified sessions). === Type representation: that is a fundamental decision, yes. Static vs dynamic typing. WAMP is dynamically typed (at the app payload level). In fact, WAMP does not really care about app payload (other than automatically translating between serialization formats for different clients). 
I personally found code academy and just diving in with some code of my own a good way to learn, work out the bugs where you're making mistakes, how you can make things more efficient etc and reading documentation, modules etc
Other than SOAP, none of these is Web native (runs right into the browser). SOAP is not real-time and is a broken tech. for various reasons. DBus is local only. I did CORBA/ACE/C++ in the past: the absolute horror - a complex biest. Thrift is RPC only. As I see, WAMP is unique in that it provides all of this: 1) RPC _and_ PubSub in 1 protocol 2) Web native and real-time 3) language agnostic Is there another? Maybe I missed something .. but I am not aware ..
&gt; 1) RPC and PubSub in 1 protocol 2) Web native and real-time 3) language agnostic socket.io?
And now for android please! QPython just does not cut it.
Not caring about NodeJS and RDBMSs: sure, but people will differ on this. For a lot of business app developers, the need to talk to Oracle at some point is not something to decide, but a fact. Then there will be people who are attracted by the possibility to write both front- and backend code in JavaScript. Anyway, I understand you don't care. Writing WAMP app components in Lua, which runs on LuaJIT inside Nginx: this is awesome, but a bit exotic I agree. Overall, my personal view is: as much as I love Python, the world is bigger, and that is just fine. Choice is good. Freedom is good. Regarding process manager: it is integrated with WAMP, which means Crossbar will fire meta-events when workers are started or die. You can hence dynamically react on component lifecycle. You can start workers and components via WAMP calls itself. In fact, there is a whole management API exposed: https://github.com/crossbario/crossbar/wiki/Management-API To start Crossbar _itself_, one can use systemd (we use daemontools most often).
This a hundred times.
I have no idea why they thought it was good UI design to isolate the demos page without a link back to the main page on crossbar.io. 
&gt; From a Router point of view, the question I look at is (simplified): how much CPU power do I need to saturate a 10GbE link routing WAMP? The goal is to make that something like "4 modern cores". Much more interesting than how much throughput you have on your router is how much latency you can practically achieve. &gt; Type representation: that is a fundamental decision, yes. Static vs dynamic typing. WAMP is dynamically typed (at the app payload level). In fact, WAMP does not really care about app payload (other than automatically translating between serialization formats for different clients). So how does that work with msgpack and json for instance which are inherently incompatible with each other?
updated to version 0.5 * debug * custom request handler 
&gt; Again, I want to say I am not the author of crossbar. I just happens to have tasted SOAP, NodeJS, Celery, RabbitMQ, Supervisor, Redis PUB/SUB, and i'm very disatisfied with the current situation. I built my own system on top of redis, circus and gevent and I feel much, much happier now. It has a known subset, it's comparatively easy to write and it does not attempt too much. It also uses regular HTTP and streamed HTTP responses instead of web sockets which is solving so many issues I had before with websockets. Generally it makes me a happy person. And maybe in a few years time someone will find the silver bullet but crossbar is not it.
&gt; captn proto's RPC Have been reading a little: for me, the interesting thing isn't the cerealization approach it takes (which is fast, I'm sure), but "Time-traveling RPC". It is able to cut round-trips by keeping promises at the callee (server) for call chaining. That is clever. However, it depends on the following: the callee of 2 chained calls is running in the same process. Since Capnproto does not seem to support routing of calls, all calls end up at the same callee - and it's not a problem. Crossbar does call _routing_. Two calls might be routed to different processes on different hosts. Transparently from the caller point of view. What Crossbar does support is: pipelined, asynchronous calls. That means you can issue as many calls as you like, without waiting or sequencing. To chain/sequence, we use promises on the caller (client). Means I can do: p1 = session.call(..) p2 = session.call(..) p3 = when.all(p1, p2).then(..) The two calls run in parallel, and then we do something when both results are available. I guess you know what I am talking anyway.
It's not, they are technies, and not really good at communication or UI design. That's why I try to get them some attentions, so people with other perspective can help them improve on their weak point. It's a good open source product. It deserves a chance.
Regardless of the amount of open source there, building an app like that wouldn't have been a trivial task. Not charging for it would be silly.
[Image](http://imgs.xkcd.com/comics/standards.png) **Title:** Standards **Title-text:** Fortunately, the charging one has been solved now that we've all standardized on mini-USB. Or is it micro-USB? Shit. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php?title=927#Explanation) **Stats:** This comic has been referenced 532 time(s), representing 2.3748% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcdcomic/)/[kerfuffle](http://www.reddit.com/r/self/comments/1xdwba/the_history_of_the_rxkcd_kerfuffle/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me)
To be honest, I am somewhat surprise that you say "Python does not scale for big systems things - Java does" (maybe I misunderstood you?). Well, I guess I disagree on this. First, PyPy. And in particular it's new incremental GC. I did extensive performance/load testing with WebSocket servers comparing with state-of-the-art Java and C++ based ones. We are competitive. Lower latencies and jitter than others in particular. I need to write a blog post on this, but to back up my claims, here are numbers: https://github.com/oberstet/wsperf_results/tree/master/handshaking/test2 https://github.com/oberstet/wsperf https://github.com/oberstet/scratchbox/tree/master/python/twisted/sharedsocket The other issue, the GIL, does not apply to Crossbar, since we use a multi-process architecture where workers talk over Unix domain sockets. Hence, we can scale up on multi-core without issues. Process isolation also is handy for robustness reasons. And finally: no, I don't want to use Java if I don't _have_ to;) Though I do some also: https://github.com/tavendo/AutobahnAndroid If I get crazy some time and reimplement Crossbar in a different language than Python (on PyPy), it would be C++ (or maybe Rust), and more importantly, I'd use kernel-bypass networking: a Linux kernel can only digest something like 500k syscalls/sec. Using e.g. Netmap (http://www.freebsd.org/cgi/man.cgi?query=netmap&amp;sektion=4) thats not a restriction any more.
Building IPython and SciPy were also not trivial tasks.
Appreciate any feedback on writing it more concisely, or making it easier to use.
&gt; To be honest, I am somewhat surprise that you say "Python does not scale for big systems things - Java does" (maybe I misunderstood you?). The lack of static typing in Python makes large scale systems much more complicated than they should be. That is especially true when you start remote calling between things. At the point where you invoke something remote that composes failures can become incredibly frustrating. This gets even more complex if you have code in different languages. &gt; The other issue, the GIL, does not apply to Crossbar, since we use a multi-process architecture where workers talk over Unix domain sockets. Hence, we can scale up on multi-core without issues. Process isolation also is handy for robustness reasons. The GIL is never your problem with web situations. Has not been in WSGI and is not when you do RPC. Your problem though is twisted vs gevent vs asyncio etc. If you have an even listener in your app then you need to pick a concurrency model. Crossbar picks one your favorite other piece of code might have picked a different one.
Latency: I absolutely agree. More important than throughput. And latency jitter is also critical. I don't have polished up numbers, but I dare to say: when running on PyPy (&gt;=2.2), it's very good. The credits for this go in part to the new incremental GC in PyPy. I will write a blog post on this. JSON &lt;=&gt; MsgPack roundtripping: the one problem is byte strings. and byte strings are converted like this: https://github.com/tavendo/WAMP/blob/master/spec/basic.md#binary-conversion-of-json-strings Note: we have that working today. AutobahnCpp (C++11) currently only implements MsgPack, https://github.com/KSDaemon/wampy.js talks JSON and MsgPack, as does http://ksdaemon.github.io/wiola/ 
Newer msgpack has two different types for bytes and strings if that helps.
&gt; For app components: I think you nailed the point in your other comment: with distributed systems and components in multiple languages, inspectability is critical. I want to watch calls and events live as they flow between components. I want to inspect they payloads. Etc. Can be done. It can be done if your payload can be represented by your serialization format. The moment you start sending around non native types (for instance dates or bytes) you lose a lot of that flexibility. That said, even just picking msgpack and visualizing that is probably a good start. What thrift and other systems are doing is exposing statically typed interfaces which encapsulate data but also functional interfaces. So I have a "user" object floating around which I can invoke methods on if I want. At that point you need a strong representation of what this interface is. That's where it gets really tricky. If you stay away from something like that you might stop falling into the trap that everybody else falls in. &gt; Crossbar allows you to run app component A in one Worker under Twisted and app component B in a second Worker under asyncio. Works today. Since AutobahnPython supports both Twisted and asyncio at WebSocket and at WAMP level. That's generally promising because asyncio has a event loop per thread so you could write traditional database apps which do their event handling in a background thread. &gt; From my point of view (scalable WAMP routing), it is a problem since it prohibits scaling up on multi-core (when running a single process). And we want that. But multi-process architectures are an established, working pattern (PostgreSQL). Sure, but I mean that's the same thing you do with a WSGI app. Have four cores? Start four processes and put them behind nginx.
Sorry, you are right of course. We need help on things like that .. 
Fantastic talk - I'm a beginner when it comes to multiprocessing/threading/etc. and have tried to read up on the topic before without success - the food-serving analogy is the best I've ever heard and clearly explained the distinction between threading and async.
&gt; So I have a "user" object floating around which I can invoke methods on if I want. At that point you need a strong representation of what this interface is. Yes, that's the CORBA way - and we stay away from this;) WAMP does RPC, not RMI or object marshalling/remoting. Loose coupling. Dynamic typing. It's a deliberate decision - which won't be for everyone, but it does work and isn't a road to insanity. &gt; Sure, but I mean that's the same thing you do with a WSGI app. Have four cores? Start four processes and put them behind nginx. For WSGI, yep. For WAMP routing, the router processes need to coordinate between each other, since a certain Callee might be registered on Router process 1, wheras the Caller might be connected to Router process 2. So the call needs to get routed between Routers (Client -&gt; Router 1 -&gt; Router 2 -&gt; Callee). A generic, stateless balancing frontend doesn't cut it in this case. Note: Router-to-Router routing is not yet there. Once it is, it'll give you not only multi-node capabilities (for routing) as well.
Then there's the option of donating to those projects. I feel it would be perfectly fine for them to charge for creating an app (I'm sure there was a significant amount of work that went into wrapping it up and modifying it for the iPad). They may be standing on the shoulders of giants but I don't feel it dictates how they should put a price on their own work on top this. 
Yep, it does help. In fact, WAMP _requires_ the new MsgPack version for exactly this reason. https://github.com/tavendo/WAMP/blob/master/spec/basic.md#msgpack
Thanks I ~~will add~~ have added that!
You don't want a cache to exhaust all your memory. You want a fixed sized collection with an efficient aligorithm for busting less used values. You definitively want to actually Read The Fantastic Web about cache in computer science and stop spreading non sense that new comers to CS might actually take for granted. Since I am nice here is a bonus : http://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0CCcQyCkwAA&amp;url=http%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DC1mRO8aqjz8%26feature%3Dkp&amp;ei=anKQU83pFcHooAT_iYDoBQ&amp;usg=AFQjCNHQGq1UYxm8jqcX2sO2mEtSr65qWg&amp;bvm=bv.68445247,d.cGU 
it says it's written in Django
I guess it's a long time since I looked at jython and I'm somewhat confused. Surely the bytecode is generated at runtime or partially at runtime, can dalvik on a phone convert and compile this ? Anyway long story short, I would love this to work on android, and if I'm wrong - and it does, please point me towards instructions.
No
Not a problem, but I swear I see you post this project once a week. Maybe it wasn't you who posted the first time.
I wanted to create something simpler, nicer and more efficient. And also thing that works on all devices and browsers in every format. The goal was to make package that will speed up work on own speech.
yeah but it doesn't matter because the code isn't open is it? I mean, you could add it to a list of "sites built with" but it's no use here on /r/Python also the interesting part is the prediction engine not the website itself.
I think plain old Safari or Chrome could do that. ;) Or did you mean you want to control an IPython cluster? If the latter, then I can't imagine why not. That's embedded functionality in IPython.
&gt; Will only gather L1 (elite anonymity) proxies which should not give out your IP or advertise that you are using a proxy at all Who/how are these proxy classifications made?
Yes, you wouldn't want this, or a regular defaultdict, to grow without limit. In an application where that was a possibility, this class could have code to limit its own size. The missing method gets called whenever a key is new. So it could count keys as they are added. At some chosen limit it could just randomly delete one key for every new key added. Or with more work and cost in storage space, it could keep a list of keys in the order added and delete the LRU one. In the actual use case (make a QFileInfo object for every path tested, as mentioned) I know the number will never exceed a few tens at most.
Disappointed that it isn't written in [Hy](http://hylang.org/).
it's scarily accurate.
I read up on memoization first, but it wasn't suitable for my use-case. Memoization caches the returned value for a given argument. What I needed to cache was not the returned value of a particular function but an intermediate result that was basic to several functions. Using this method, any function using that intermediate product can get it by indexing the dict; you don't have to know which will use it first; yet it is calculated only one time.
C is quick.
&gt; Well, no, because in this case he can change the value. Indeed, for caching computation, he want's memoization, and not this. But that's just a stupid example. In the use-case he actually had, caching QFileInfo(path), he needed memoization too. I wonder in what situations you have an expensive initial construction _and_ want the ability to change values externally afterwards. I bet this is rare enough that any reusable implementation or a recipe like the OP's should come with a requirement to sign a waiver declaring that you're really sure that what you want is not memoization, in triplicate.
Updated the readme. 3 sites: gatherproxy.com, checkerproxy.net and letushide.com
This could be perfect to use it as a notebook in the lab, if you're manually gathering data and you want to analise and plot it as soon as it comes ... 
Yeah, that's fine -- but take a step back for me (I don't know much about proxies really). Who decides what constitutes an "L1 elite anonymity" proxy? And who decides which proxies get to claim that they satisfy that classification?
 &gt;That's a very good point! Of course Apple could impact this simply by giving Numbers a real scripting environment that can access the net. This is possibly iOS's weakest point right now, that is the lack of scripting capabilities in the "required" apps for modern OS's. &gt;No, I agree with you, but what I wanted to convey is that every type of device has its strengths and weaknesses. I also write emails on my IPhone and iPad occasionally, but only if I really have to. I find my self more comfortable (and faster) at typing on a desktop computer or laptop. Yes of course, I'm just pointing out that there are many use cases where the iPad simply isn't a distraction. In fact it can be the preferred solution when you go beyond the office desk. All in all I really like that somebody is taking this on. Given that I'd rather see Apple deliver a scripting / compiling environment for iOS. Swift has huge potential here. The problem in the case of iOS is Apples policies more than anything, iOS needs a native solution to developing the one off apps so common in industry. 
Is PyQT the python implementation of QT, whereas PySIDE is just an abstraction of QT (i.e. just making calls to the QT library)? If not, what's the difference?
Kivy is worth a look. (http://kivy.org)
Take a look at [enaml](https://github.com/nucleic/enaml) Its a declarative layer on top of PyQt4 / PySide which makes it very easy to develop high quality, beautiful GUI's. Think of it as a pythonic QML on steroids, or as a sane version of Enthought's traitsui. The code base and architecture is just incredibly well thought through; a gem. 
It seems PySIDE was made by nokia and is lgpl, not sure what the difference is beyond that.
Yeah but the article is interesting, i won't care for the title.
xD wow im a derp lol thanks for the help :D
So basically this is a WAMP implementation, which is reinvented CORBA over websockets? I feel a rush of skepticism. In the short term the future of web apps is web components in javascript (or compile-to-javascript language of choice here); not this.
Thanks for the link, that looks really awesome for developing apps. Like full, production ready applications. If I start anything on android I'll definitely look into this. Right now though I'm just looking for something that makes charting functions and timeseries simple, with some UI extensibility. 
Looks very interesting, I'll give it a try. I like the simplicity it shows in the tutorials; might be exactly what I'm looking for.
it still is bad: how can you justify the cost for indirection, point of failures and added complexity over using raw call to the functions, or even building a simple dict with all the fixed value beforehand? 
you opened the file but didn't read it. fh is not a string/array so you can't iterate through it like a string/array https://docs.python.org/2.4/lib/bltin-file-objects.html also you should be using with open(fname) code so that the file closes when the code block is done executing.
No, you can iterate on a file handle, you just can't rstrip it. Line is the string you want to call string methods on. 
&gt;&gt; depending on circumstances not easy to identify before a full migration is completed &gt;That statement is completely incorrect, You are just dumbly sleeping in your comfortable Py3 bubble, aren't you? Tell me how you can decide whether an application (a big one, not your average toy project) is going to be faster or slower before migrating it to Py3 in full? How? The benchmarks tell it can go both ways, so how do you know in advance? The thing that you know for sure is that not even PyPy will be there to help if push comes to shove, so how can you deny that sticking to Py2 is the safer option? And provide some explanation, if you have any, rather than your usual troll rant. Regarding red herrings, your dismissive attitude just proves how you and all the rest of Py3 adorers have no idea whatsover of what real life is and think it's ok for everyone (be an individual or a business) waste precious resources with little or no gain and considerable risk just to make your fanatical bunch happy. The example I made is a real life scenario, whether you like it or not. But I can understand that in your toy world of pinky ponies things like angry customers and billable man hours don't exist. So, stop you spreading all this benevolent crap around how good Python 3 is, and the fuck*ng wall of shame, and how lazy those who don't want to port are and so on. Haven't you divided a (perfectly functioning) community enough with this ill-thought-out sh*t? 
Some links to other sources: http://programming-motherfucker.com/become.html#Python
You should feel free to browse around on github, for example you could look at the [Requests library](https://github.com/kennethreitz/requests) or [Django](https://github.com/django/django). Hope this helps.
You should put this on the [Python Cookbook](http://code.activestate.com/recipes/langs/python/).
yeah i agree
If you just want to have some flexible scratch space, why not use an IPython notebook?
No, the bytecode is not compiled at runtime at all. It's compiled at...er...compile time. For Android apps in general, the JVM -&gt; Dalvik conversion is also done at compile time. As long as you have valid JVM bytecode, the converter should be able to convert your JVM bytecode into Dalvik bytecode.
So would this work? for i in range(difficulty): temp = Ship(stuff) listOfShips.append(temp)
There is basically no difference. See my answer to OP.
I tried IPython in Safari and Chrome for iOS and it didn't work. That's why I was asking. Would be super useful!!
There is basically no difference. As far as I remember, PyQt is a product with its own commercial licensing, and they could not reach an agreement. So Nokia simply rewrote the wrapping from scratch. There are minor differences but in practice the interface is the same, and you can just import PySide as PyQt and it will mostly work. Both use the Qt backend. Be careful with Qt. It's a great toolkit, but its memory management design is made for C++. This collides with cpython GC, a lot. 
I don't know. Does it? ;)
there is always https://github.com/facebook/fbthrift it has all the changes facebook makes to thrift internally. 
Unicode is a mandatory part of python. You can't have python without it. You can have a python-like language, but you can't have python.
It's accurate because if the answer was "Yes" then just using that as your headline would draw way more readers than the question.
This implementation is focusing on low memory consumption, not speed. Cpython will likely be a good bit faster. (Cpython's got all the memory in the world to trade for improved cpu speed)
You could even just do for i in range(difficulty): listOfShips.append(Ship(stuff)) Or the more pythonic list comprehension listOfShips = [Ship(stuff) for i in range(difficulty)]
lol okay, okay, i'll try it out. :D Thanks.
I know, but it's actually going to wind up being more complicated, probably too complicated to put in a list comprehension. As it places each ship, it has to examine where it's about to do so and make sure it's not overlapping with any existing ships and actually fits on the board.
[Marsland's](http://www.amazon.com/Machine-Learning-Algorithmic-Stephen-Marsland-ebook/dp/B005H6YE18/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1401990227&amp;sr=1-1&amp;keywords=machine+learning+algorithmic+perspective) book has what you're looking for. The examples are actually implemented with numpy so you can understand what pybrain/ other ML libraries are doing. 
From my understanding (though I haven't used it), IPython is essentially the same as just running the code regularly but with embedded graphics. So in other words, I would have to rerun the program every time I changed a variable value even if it doesn't require a complete recalculation of everything in the code. Am I wrong about it? What I'm looking for is something I can make interactive to play with some variable values and have real time changes in the graph I'm looking at, rather than have to rerun the entire program to see the changes. 
then what's the problem with OPs code?
http://codejourneys.blogspot.ca/2008/05/using-matplotlib-to-plot-data-from.html
That website is blocked from my work (I have no idea how Reddit gets through). I will check it out when I get home, thanks.
You're operating on fh (a handle to a file) rather than line (the actual string you're interested in). line = line.rstrip() line = line.split() count = count + 1 print line[1] Also note that python lists are zero-based, so if you're looking for the first word, you should be looking at line[0]. 
Someone explain to me why I should use WAMP over HTTP? HTTP has widespread use, major industry buy-in, and a beautifully simple verb/noun relationship at its basis. Sway me to WAMP. 
Lol. Pretty much every paid app is built on or interacts with open source code. There is nothing distasteful about it, both have their place. firefox is open source, should that mean no website can profit if their user is using it? You can't expect everyone to make everything for free. 
Did this as a hackathon project at work. We have a complex test runner in our environment, and this was an easier approach to parallelizing our unit tests. Let me know if you have any questions!
Right, and I have absolutely no problem with that. However, in this instance it seems to me that it's simply repackaging existing functionality from open source projects. I do acknowledge that quite a bit of effort went into making it run on iOS, so they're absolutely entitled to charge for it. However these tools were built based on the idea that scientific tools should be available to everyone for free, and potentially charging for a wrapper of this great effort, on a platform that is already the anti-thesis of open source philosophy, just leaves a bad taste in my mouth. I hope the open-source community can team up to provide an alternative to this. But then again, the people who own an IPad are probably not the strongest open-source advocates in the first place. 
if you're using SQL Alchemy or similar, you'd do this: from sqlalchemy import create_engine conn = create_engine("postgres://blah@blah") rs = conn.execute("select a, b, c from blah") top = [] bottom = [] labels = [] for row in rs: top.append(row["a"]) bottom.append(row["b"]) labels.append(row["c"]) plot(bottom,top,labels) # or whatever
For simple CRUD operation which does not need any realtime communication, No.
It sounds like you could do that with memoisation - just have a memoised function that produces your 'intermediate result' and have the other functions call that instead of accessing a dictionary. There's not really any technical difference between a memoised function and a dict that computes missing values - they're functionally exactly the same thing. But there's a difference in readability: when you see a function call `f(x)`, you expect it to be running code, and potentially computing something expensive. If you see a dictionary lookup `f[x]`, by convention that only does very simple things, even though Python makes it possible for it to do anything.
Why should you use WebSocket instead of HTTP? (WebSocket is the raw protocol underlying WAMP). Because HTTP is strictly request-response and has no bidirectional communication / real-time capabilities. So, e.g. when data changes on the server or some other client, you cannot actively push that information to browsers.
Whats the main benefit of that? If Im writing a client that cares about up to date data I can poll for new data with relatively low cost. Is the benefit just that a client side listener would be zero cost? 
Ignoring the cringe-inducing quirkiness of the writing, why do we need another protocol? XMPP works well, has been around forever, and can work over websockets.
I may have missed a sarcasm tag there, but, taken as simply: "How is WAMP different from HTTP.", the question is valid. So here goes: HTTP was intended for a client to request a resource (HTML, CSS, JS, img...) from a server, and for the server do deliver this in a response. Connections are one-way (client-initiated), short lived, and point-to-point. WAMP does something completely different: it enables participants to subscribe to topics, and to publish to them, as well as offer procedures for remote calling by others. Using these two patterns, it allows participants to cooperate. A participant can announce something on a topic, e.g. a member in a chat room can send a new message to the 'newMessage' topic. All other participants who are subscribed to the topic will automatically receive the message. A participant can register a procedure, e.g that it delivers the current temperature for a location. Any other participant can then make a call to get the temperature, the call is forwarded to the participant who registered the procedure, and the result is returned to the caller. In both cases, there is decoupling: the publisher does not know or care who the subscribers are, and the caller does not know or care where the procedure is running. A WAMP router connects the parties. WAMP is a way to enable multi-client applications as well as distributed application architectures. Participants can be Python, JavaScript, C++ and others - and include browsers and Web-facing servers. They are all equal in that the can be both subscribers and publishers, both offer procedures and call them. There is no direction on an existing WAMP connection - no client and sever in the classical sense. For JavaScript, this may run in a browser or in Node.js, and the code basically doesn't need to care. Participants may belong to either category in the classical sense, and when it comes to establishing the underlying connection. E.g. a browser will still need to initiate contact to a server to get a WAMP connection going. For this connection in browser clients (and here we'll come back to HTTP in a second), WAMP uses WebSocket as its standard transport. WebSocket is bi-directional, allows persistent connections and has a low wire overhead, with support in all modern browsers, so it's a natural choice for WAMP connections. It is not, however, the only possibility. WAMP over HTTP long-polling is a possibility, and some work has already been done on this, in order to enable support in legacy browsers or systems which support HTTP, but not WebSockets. 
Because there are plenty of cases where you can't poll for low cost, either because of a large quantity of clients or there are some cases where the cost of polling is high (maybe the resource can't be cached). Having 300 clients poll every second for a chat room is a ton of unnecessary data being sent and as you scale up it can become a serious performance hit where with nio websockets it would be not have to send &amp; respond to all those requests, you simply tell the client when there is new data. **Edit** Another huge area would be real time collaborative apps, as well multiplayer games
PySide is the same as PyQt (pretty much) for Qt4. PySide does not support Qt5 though. Personally, I'd rather jump on the QML train and do PyOtherSide instead, which is a Python/QML interop layer without making all of Qt accessible to Python. While much more limited in scope, it is also much easier to deploy. Deployment is a pain with PySide/PyQt.
Good answer.
What function? What line? leftClick appears to be indented with only one space. Not sure if that's a formatting error or actually in your code. Also, your while loop in main is not indented.
mousePos doesn't seem to be defined, and leftclick was a little error
Could you run it and paste the entire stack output? I can't test it on OS X.
When asking these sort of things you need to post the complete traceback. Also, your formatting doesn't seem to be right because you have a `while` loop that isn't indented. If we can't run your program exactly as you wrote it then we won't get the same error, which is why we need to see the full and exact error that you're getting. 
It works for me once I fix the bad indentation on lines 45-47.
fair enough, I'd be inclined to care myself if I though the lead devs behind ipython, matplotlib, numpy etc.. were hurt by this. But they might actually be thrilled that ipython is getting yet another medium into the classrooms. 
Sorry I misread you there. I'd say that if all you want to do is to serve the user a page when he requests it, and maybe get some data like a form in return, then there's no reason to leave the established world of request/response and HTTP. When I think of Web applications, and I think as well when the writer of the post does, I think of more than this - of applications which do things like live updates, in-browser processing, quick in-page updates. These will typically be single-page applications. For these, AJAX, long-polling and other technologies that use HTTP mechanisms sooner or later turn out to be hacks on something which was never intended for these uses. WebSocket is the transport protocol for browsers which goes beyond HTTP to accommodate Web apps - this is what natively provides bi-directionality. WAMP provides functionality on top of this to make the communications that Web apps need easier.
If you want to be able to modify variables on the fly, you should check out the new [interactive widgets](http://nbviewer.ipython.org/github/ipython/ipython/blob/master/examples/Interactive%20Widgets/Lorenz%20Differential%20Equations.ipynb) in the Ipython notebook.
I'm a fan of [wxPython](http://www.wxpython.org/) -- cross-platform, a rich feature set, WYSIWYG designers available.
&gt;WAMP already solves PUB/SUB and RPC without needing to write anything on top of it. Plus, you don't need to understand queues, and routing, and all this complicated stuff. I was all excited about this until I went down the rabbit hole into what WAMP is, and the transience of WAMP killed most of my enthusiasm. I can't run production systems on a protocol that is either deprecated (v1) or in an actively modified and partially specified draft state (v2). That's a recipe for disaster. I wouldn't even contribute to an open source project built against something like that. Of all the moving targets I have to deal with, my *protocol* shouldn't be one of them.
The author posted this to the ipython-dev list as well. Devs seemed pretty excited about it. =)
http://www.scipy.org/
Is there something missing from the NumPy/SciPy stack?
exactly 
There's quite a lot of maths tools already out there, is there a specific area that you don't think has been covered? Just off the top of my head, there's: - The math and statistics modules in the standard library - Sympy, for symbolic math/algebra - Numpy, for vectorised computation/linear algebra - Scipy -Statistics libraries like patsy, statsmodels, pandas
Isn't that what the ticket list is for? :)
It would be if they improved their docs
Mysandry is still alive and well in the python community.
Yes, Crossbar has a management interface which is itself exposed via WAMP: https://github.com/crossbario/crossbar/wiki/Management-API#api-definition Erlang is great (if you can wrap your head around pattern matching for consuming messages in a purely functional program). I've used it before. There are a few things that are limiting, e.g. the Erlang node-to-node / clustering is designed to work on a (trusted) LAN. The process / supervision trees work great for Erlang processes - not for OS level processes. E.g. integrating an application component written in C++ is cumbersome to say the least. Crossbar embraces a polyglot world - by design. That being said: yes, Erlang and Rust, those are very fine systems.
If you're looking for good charting, [matplotlib](http://matplotlib.org/) is your friend
[This](http://mcsp.wartburg.edu/zelle/python/graphics.py) is what I used in my course and I was able to make some pretty quick, useful things with it.
Look for stackexchange/ forum posts by people complaining that python doesn't do something which matlab or R can do. Then check that numpy, scipy and pandas definitely don't have it. Or find something that people complain about none of those things having out of the box.
You can get that in dead-tree form, if I remember right.
What does the author use to create this in-browser presentation? 
Very nice, thank you for the suggestion. I'll check it out.
Have you checked out Nodebox? It is sort of Processing in Python. Of course there are also ways to Jython with Processing libraries as well.
I work at enormous bank... Java is everywhere but everything *new* is built with Python for the most part. Seriously. Python is eating everything in finance except high speed trading.
I tried a number of WSIWYG builder, [WxFormBuilder](http://sourceforge.net/projects/wxformbuilder) was pretty much the best to work with.
He's trying to rstrip fh. He needs to rstrip line.
Partially timing and salesforce Java had the Sun salesforce and commercial support, Python, at the time had neither. Java was also earlier. 
Like [this?](http://healthyalgorithms.com/2013/08/22/dsp-in-python-active-noise-reduction-with-pyaudio/)
Speaking as someone who interviews lots people for Java, C++ and Python roles I can tell you that out of the three it's more difficult to find competent Python engineers (mainly because the pool is smaller). This plays a big role in adding new languages on existing projects because it will be more difficult to find enough people to put the hours into it.
 class MyView(APIView): permission_classes = [IsAuthenticated] # or whatever renderer_classes = [JSONRenderer, BrowsableAPIRenderer] # or whatever def get(self, request, your='stuff', format=None): #Whatever you were going to do from scratch #Exactly how you were going to do it return Response(your_data) The view is no more work than any other view and you get permissions, multiple rendering formats, etc. all for almost free, all managed in the same place as the rest of your API. What did you try that didn't work?
Wall St. was well represented at pycon this year so I'll venture that that's where he's working.
Why not py.test? 
It will catch up soon. Especially with all the shit Oracle is doing.
The [py.test](http://pytest.org/) library also has the capability of distributing test cases via the [xdist](http://pytest.org/latest/xdist.html#xdist) plugin. I used to use Nose nearly exclusively for my unit tests but for the past few years I have switch to py.test and have never looked back as it has a number of very convenient and powerful features. It works similar to nose in that you use assert statements rather than the clunky API that the unittest module uses. py.test has more powerful fixtures, uses context managers for checking exceptions (i.e. with pytest.raises(TypeError): operation_that_raises_a_type_error), [parameterized test functions](http://pytest.org/latest/parametrize.html#parametrized-test-functions), etc. IMO the parametrize test functions are far more convenient than nose's test generators. Py.test also supports running nose, unittest, and doctest style tests so normally you don't have to do anything special to switch to using py.test although in a few rare cases you may need to make a small modification to a test case to make it compatible with py.test. For all those who only use the unittest module I highly encourage you to check out py.test or nose. Both of these libraries are far more Pythonic than unittest and are a pleasure to use. I can never understand why I see so many developers subject themselves to the unittest module when these other awesome libraries exists. With these other libraries you will type half as much and create test cases that are far cleaner and easier to understand.
earlier? i thought they were contemporaries. Not contesting your other points.
Well, simple dict with precomputed values is certainly the way to go when possible. I well remember "precompute everything you can" is one of the major efficiency techniques from reading Jon Bentley's *Writing Efficient Programs* years ago. However, it is often the case that the set of possible inputs is too large for that approach (the set of natural numbers, or the set of people in the employee database). When the likelihood of a given value P being repeated in the input is low, caching is never a good strategy either. In the case I set out to solve, during which I worked out this modestly clever hack, the set of inputs is all the file pathnames, so precomputing is out. However I knew that a set of pathnames would start small and grow slowly, and info about them would be referenced frequently in a time-critical way (specifically, every time the user clicks the File:Recent Files menu, the list of recent files needs to be built on the fly before the menu can be displayed). So, caching. Caching what? I would need to ask several questions of a QFileInfo instance, the creation of which is a bit expensive but the interrogation of which, once built, is quick. So, cache the QFileInfo instance, so as to be able to query it at various points in the code be merely referring "dict[path].methodName()". That's a bit esoteric for the average programmer, and my x^3 example was as lame as the person said, above. Here's a better example: suppose that the thing you want repeated access to is the output of a complex SQL query? A typical SQL query is expensive to run, and can return a bunch of data fields. So if you use FIELD_A from Key X here, but want to compare FIELD_B between Key X and Key Y over there 50 lines away, and you don't want to re-run queries all the time. So that would be a perfect use for this, where the key to the dict is whatever string is needed to run the query, and the value for that key is a tuple of the returned values from a query on that key. So you can just write "if sqldict[key_a][3] &lt; sqldict[key_b][3]: print(sqldict[key_a][0:2])" and that might run two queries, or one, or hopefully zero because the results are cached. 
I won't say where I work but I will say this: You're spot on. I live elsewhere though (not that it matters where I live--I work from home).
You need to use _startswith_ before you use _split_. _split_ returns a list, and list objects don't have a _startswith_ method. You should try using _print_ in various parts of your code when you encounter problems like this. Don't give up so quickly by asking the internet.
+1 @GahMatar, I agree that the big boom of Java was the "WWW". The Internet actually extended the concept of "multiplatform" and good or bad, but it was Java that came first. The "Sun" shot that hit the seen and not seen. I still believe that a company will make Python as "Enterprise" as Java or greater than Java.
&gt; That's probably because your looking for python engineers instead of software engineers. Nope, general software engineers with Python experience. We look for people who can solve problems first before we look at language experience. But even when we find someone who can solve problems we have to know they've had in depth experience with Python in production and many don't fit this category. If you can think and solve problems you can generally learn almost any language given time....we just don't have that kind of time :( &gt; I hope you mean adding in a new language instead of rewriting. Oh yes...fixed.
What is the preferred language for high-speed trading? Java, C, or a functional language like Erlang or OCaml?
Actually both JP Morgan and Bank of America have huge python usage. Not scripting either, oop.
that must be new from the 3+ years I looked at it
Sadly the truth of it is that GUI programming sucks a lot. Thankfully pyqt4 is better than tkinter. Look into qt designer + pyqt
This is what I wanted to post. I don't see anything wrong with it. It can be a pain to make interfaces programmatically but there are ways around that. That and I think the API is fantastic.
If you want to stick with tkinter to reduce your dependencies then tkRad ( Tkinter Rapid Application Development (RAD) library - Tkinter XML widget building - https://github.com/tarball69/tkRAD ) might be worth a look. Or even pygubu (A simple GUI designer for the python tkinter module - https://github.com/alejandroautalan/pygubu )
Qt is usually a pretty good cross-platform gui library. It does have some problems though so you may want to try kivy first. I've heard pretty good things about it (though I haven't used it myself).
style tip. start a new line after a colon. if not line.startswith('From'): continue this will make your code much more readable, in particular more readable to other members of the Python community, since this is the style standard we are used to.
Many reasons. The first reason was that Java hit the headlines way before Python! When Java came, it was backed by Sun, and immediately got a lot of press coverage as the cool new thing. And it was a cool new thing, and a much nicer language than most languages available then. The second reason is that is was a C replacement. Java was written as a modern high level language that was designed to be "C-like". It was intentionally easy for C programmers to get started with Java, while making it a modern, portable language with garbage collection and OO that was not awkwardly glued in there afterwards. And you compiled things. It fit in the general workflow of programmers, etc. The third reason is that it is a good language. There's nothing really *wrong* with Java. For us Python programmers the static typing is a pain, and the workflow is awkward and you need to type too much boilerplate. But the only real drawback of that is the static typing. And it has a benefit as well: Java is much faster than Python. Also, dynamic typing is scary (see point 2). As such Java was always the obvious choice for a new language to replace the archaic low level C. Going to something like Python or Ruby are always much more risky. For that reason, big organisations tended and still tend, to gravitate to Java. This may change, but attitudes need to change as well, and that takes time.
You can use PySide/PyQt to write crossplatform compatible code. Then you can use [Cython](http://cython.org/) to compile the code into .dll-like binary libraries. But AFAIK (at least with cython), you can't do all Mac, Win, Linux executables from only one of these OSs. You have to install XCode on Mac, Visual Studio on Windows, some libs on linux and compile on each one of them separately. Also, you can try kivy
Java is the common language for Hadoop, which is going to continue to give Java some legs for the foreseeable future. Scala may start to take off as functional programming makes a resurgence, but the new Java8 functional constructs will probably meet that need.
Same. I love Python for my own stuff, but static typing makes a big difference. Especially with medium/large teams and lots going on
When I was first introduced to it years ago, it was introduced to me as a great "first" or "beginner" language. I assumed that's what it was good for, and not much else. Java, on the other hand, has a reputation for being enterprise-friendly...which still trips me out, because my first introduction to it was "Hey, look, you can use Java to write *applets*! Little multimedia thingies in *web pages*!"
Might have wanted to warn folks that this is a *five thousand page long PDF*.
It's not a one-liner if the line is 160 characters (including indentation) long.
Check out Camelot (http://www.python-camelot.com/) It makes developing 'business' applications really fast.
Fantastic examples and a demonstration of parsing useful information.
Thanks, I'll do this.
Thanks!
I didn't know these existed, thanks I will check them out
Thanks don't think so, but I will look. Something can always be improved!
Ok, thanks for the advice
Diesel doesn't do any monkey patching like gevent so that's a major difference. Twisted and tornado are both callback based. Asyncio is useless to 98% of python programmers. I think this makes diesel a very worthy competitor.
&gt; But the only real drawback of that is the static typing. And it has a benefit as well: Java is much faster than Python. Also, dynamic typing is scary (see point 2). Could you elaborate on this point? I never understood the advantage of of dynamically typed, but at the same time what most people call strongly typed. Once your variable is a string, you cannot interpret it as something else, so why would it be bad / an disadvantage to have it declared "string foo = 'bar';" instead of "foo = 'bar';"? 
&gt;Asyncio is useless to 98% of python programmers How so? Please elaborate.
You don't need monkeypatching to use gevent. It gives you the option to do so, to make code cooperative that is written synchronously. This is immensely useful and rightfully advertised as one of its best features. Unfortunately it also leads to the perception that *must* use monkeypatching when you want to use gevent, which is not true: Gevent comes with its own set of primitives, green sockets, Queues, a WSGI server, etc. that you can use to build asynchronous apps.
&gt; I never understood the advantage of of dynamically typed the benefits and the disadvantages are actually the same, the langueage does no type checking and assumes the programmer will send a type that fits the bill. this is both good and bad; it's good in the sense that boileplate can be avoided, but it's bad as well since it leads to run-time errors (if you were expecting a file-like object in Python for instance but got a string, there really is no way for a dynamically typed language to stop you doing such stuff) in terms of the actual questing: i think that Java's success is a bit more cynical, it's been used as the standard teaching language at most universities, i.e. larger labour force makes it easier to replace people and harder to demand a higher wage for employees. if you choose Clojure/Rust/Go/Haskell/Perl6/Pike to implement something, what do you do when your lead developer quits? lure him back with more salary? port it to Java?
| we just don't have that kind of time You have time to interview lots of people - a process probably taking months; but no time to have somebody learn Python in a few weeks?
&gt; Once your variable is a string, you cannot interpret it as something else Well, yes you can, because you can replace it with something else. The variable is just a name. Also, the dynamism stretches to the object, so you can set parameters on an object dynamically. &gt; so why would it be bad / an disadvantage to have it declared "string foo = 'bar';" instead of "foo = 'bar';"? Because then you can't put anything else there. This is mostly important when it comes to calling and API's. Let's say I have a function that takes a dictionary. This function calls .keys(dict) and len(dict). If I have something else that is like a dictionary, but not quite, with static typing, I have to first make it a dictionary. With dynamic typing, it only needs to have a keys() method and a length. This gives you a lot of extra flexibility. To a large extent, you end up trading development time for execution time. 
also some more improvement for speed an elegance for count,(line) in enumerate(fh): And remove the count = count + 1 (which can also be done as count += 1)
Can you elaborate? I have a very intense disdain for Oracle so would love to hear others stories/experiences.
It's used extensively in HFT / prop trading too, except for execution which is usually C
I'm working for a large international telecommunications (hardware) firm. And we are migrating everything from Vee, visual basic script, labView.... to python. The main reason is code maintainability and readability.
In that case you can put the logic into the ship object/function. Also I'm not sure what the rest of your code looks like but is Ship a function or is it a class? It looks like a function in which case it should be lowercase ship. If it's a class you can use a method to create it: class Ship(object): def __init__(self): pass def add_ship(self): #some code to add ship and ensure it doesn't overlap In the case of a function, you could create a ship function that takes an array and returns a new one eg def ship(ship_array): #find empty spaces and add ship_array.append(new_ship) return ship_array etc 
...and explain yourself right now! ;-) Wake me when Python 4 comes out. Then we can all be friends again.
Meh. We'll be friends once most new packages released don't have Python 2 support. Then the straddlers will move to Python 3, notice that is seriously wasn't that hard, and after a bit of complaining about that you have to remember that it's called print() now, settle in just as nothing had happened. I don't know when that happens exactly, maybe 5 +-2 years? And two years later everyone will have forgotten all about this, and the straddlers will scream bloody murder when they have to use Python 2, because it "sucks soooo baaaad". :-)
&gt; this is both good and bad; it's good in the sense that boileplate can be avoided, but it's bad as well since it leads to run-time errors I hear this "it will crash at runtime" argument often, but that is a flawed one. No matter how good a type system is (Haskell has a good one IIRC), all it can ever do is ensure that 1. You pass the correctly typed values as arguments 2. You can be forced to explicitly handle corner cases (null/None values, Exception handling, etc.) What it can't do it ensure that the program runs correctly or doesn't crash. In Scala I can write a function: def add(x: Int, y:Int) -&gt; Int = x - y (returns are implicit in Scala), and it will compile fine. But the code will do the wrong thing. To check that, you will need to write a test case. I've yet to see an example of a bug that will be found by a type checker but not by a unit test. The advantages of type checking over dynamic typing are 1. it helps programmers understand code more easily if it is poorly documented 2. if you are working with a huge team of programmers of different experience, and some of the programmers just can't be arsed about correct code/handling corner cases, static typing helps alleviate that problem to some extend 3. it's easier for IDEs to offer code completion/navigation 4. some refactorings are easier 5. If you don't write tests, static type checking is better than nothing Remember that Python is a language "for consenting *adults*". Dynamic typing gives you many freedoms, but this also means that you must force yourself to write maintainable and good structured code. If you are forced to work with unexperienced programmers that program by copy-pasting from StackOverflow, those people can do less damage in a statically typed language.
Actually, Python is older than Java. Just workout a marketing team.
&gt; everything new is built with Python But with 2.7 I assume/fear?
That's cool, how does it handle stuff like closures ? I just thought you always needed the jython interpreter as well.
Ah, found this http://stackoverflow.com/questions/6856010/what-parser-do-jruby-and-jython-use-for-generating-jvm-bytecode Which seems to have an explanation for most of my questions :)
The '2%' number is from the parent commenter, but given Python 3.4 was released *less than three months ago*, I would be surprised if there is a significant number of Python 3 users on 3.4. But if you want numbers: sure. [In December 2013, only 2% of package downloads on PyPI were for Python 3](http://alexgaynor.net/2013/dec/30/about-python-3/). That suggests the usage of all versions of Python 3 is **very** limited, and hence the usage of Python **3.4** is probably a lot less than 2%. *The* thing that's going to make 3.4 broadly available is the fact it (barely) made it into the most recent Ubuntu LTS. As such, at least software that depends on AsyncIO will be deployable without a huge hassle.
I would say the fights they have been having with Google over Android is an example. I imagine Google right now is planning to shift away from Java for Android or at least develop a set of tools in another language for it.
I hope so. I straddle 50/50 at the moment for various projects/reasons, and nothing in 3 makes me dislike 2. Matrix multiplication and print() doesn't light my fire. (Even though print() feels more natural to me). What am I missing in 3 that's really awesome? I suspect I'm probably using 3 like 2 and not getting the full benefit when I'm on a 3 project. Yes?
For high speed trading it's, "whatever is fastest." That means C, assembly, Scala, anything goes as long as it's fast.
Probably, but in many projects you don't really notice the differences either, except for the changes to the standard library (and print as you mentioned). 
Yes, unfortunately. 2.6 even.
You know, that genuinely was a surprise to me when I started using 3. With all the doom and gloom about changes, to strings in particular, I fully expected my first use of a string variable would have me tied in knots. Not the case. Will go back now and examine the standard library in 3. Thanks! 
Talking about Python here, so let's put javascript aside for a moment, also you can (and want) to use WAMP in JS too. The idea is : - real time - PUB/SUB and RPC - cross languages and systems (including in the browser) - easily CORBA doesn't provide that. People do use websocket to do real time, and they hack around they way to get PUB/SUB and RPC by patching several components together, then do it again to communicate between their processes.
No, it's an youth project, that's the very point of the article.
HTTP is not real time. HTTP is not push. HTTP has no standard for serialisation. HTTP is good, if you want to build a next gen framework with crossbar, you'll want HTTP in it, but real time web and component communcation needs something else.
I see your point. You can already to these with django/flask/bottle fine.
Because XMPP is very hard to implement, very heavy, does plenty of stuff you don't need to the purpose of WAMP, but don't do RPC out of the box. What's not in the article is that WAMP also want to compete with MQTT for the IOT. It needs a low footprint for that.
:)
I feel exactly the same. 
&gt; Do you know what profiling is? Yes, I know. So I run a profiler on my Python 2.7 app and find the app is doing fine and there are no bottlenecks worth optimizing. Then what? I can't run the profiler against Python 3, unless I first port my application to 3. Or does the profiler magically know how a 2.7 app would behave under 3? And even if I had found bottlenecks worth optimizing under 2.7, how do I know if such optimizations will be of any value under 3? 
Yes, vert.x is a very interesting competitor, although the XML mania did scare me a little.
&gt; Yes, I know. So I run a profiler on my Python 2.7 app and find the app is doing fine and there are no bottlenecks worth optimizing. If you care about performance, **you have already optimized the app**. Of course there will be no further optimizations to be done under Python 2. Duh! The question is what the bottleneck *is*. What your application is actually doing. If you care about performance then you have already profiled your app, and you already know what the bottlenecks are. And once you know what your application is actually spending time doing, then you can easily figure out if it will be faster or slower on Python 3. Examples: * The bottleneck is I/O (this is almost always the case): Performance will be the same. * You are doing a lot of currency calculations using the Decimal class: Performance will increase radically. * You are doing a lot of float calculations: It might be slightly faster, but probably not significantly so. * You are pickling/unpickling a lot: Slower. * You are doing a lot of integer calculations (unlikely) it'll probably some percentage slower, depending on how much time it's is actually spending on the calculations. * Other cases: You'd probably have to make your own custom benchmarks. 
I've had good luck so far with [PyInstaller](http://www.pyinstaller.org). I've used it to create binaries which work on mac (as an app), windows, Debian and Ubuntu. It's a bit of a hacky way to create an executable, but it's been the most successful for me so far. The dependency detection was remarkably good. For the UI, TKInter will do you fine until you get sick of its early 90's look and feel, at which point you'll want to switch to more platform specific ones.
Here's how it worked: Surprisingly nontechnical CTO read the word "Java" so many times in trade-mag ads and airport ads that when middle-managers were talking about new projects, the CTO tried to show his technical chops and justify his salary by asking, "Oh, is that using Java?". Middle managers add Java to the list of requirements. HR hires Java people. Low level managers despair at having to use Java when other things would very often work just as well or better.
More like async-i-*no*.
There was no Python 3 back then and 2 was very stable. Python also comes with batteries included for most things. I don't think either of those are major factors.
&gt; How it got there is probably because Sun, IBM and other large vendors embraced it right around the time mainframes where going the way of the dinosaurs in most shops. No, mainframes took at hit with the advent of Client Server around 1990-1992. Client Server architectures were mostly Microsoft. Java didn't take off until around 1996-1998 and it was more of a web thing - often at the expense of Client Server. Prior to that people were using C++, PHP, Cold Fusion, ASP, Perl. None of these were very good solutions. And Java promised "write once run everywhere" 
It's not written *in* Python, but I created a simple shell function to activate a virtualenv (using virtualenv-wrapper) and open the project in Sublime: function workon_enterprise { cd /Users/tim/Develop/enterprise workon enterprise subl enterprise.sublime-project } And another one to run tests using coverage, then open the results in a browser: function full_coverage { cd $PWD coverage run --source='.' test.py coverage html --directory='.coverage_html' open ".coverage_html/index.html" }
Please post questions like this to /r/learnpython instead of here in /r/python. Thanks!
Please post questions like this to /r/learnpython instead of here in /r/python. Thanks!
There's still hardship with getting PyPy to run either as a plugin or built from source with PyPy as the only language. I've had more success with using straight up Gevent though.
Here's a script I wrote that prints just the keys of a JSON document: #!/usr/bin/env python import json import sys def main(data): json_data = json.loads(data) if not json_data: print 'no data' sys.exit(1) if not isinstance(json_data, list): json_data = [json_data] def print_keys(obj, indentation=''): for key, value in obj.iteritems(): if isinstance(value, list): key = '%s[]' % key print indentation, key if isinstance(value, dict): print_keys(value, indentation + ' ') elif isinstance(value, list): print_keys(value[0], indentation + ' ') for item in json_data: print_keys(item) if __name__ == '__main__': main(sys.stdin.read()) You could use it like so: curl http://reddit.com/r/Python/top.json | jkeys Or cat some_json.json | jkeys
Huh? Was twisted rewritten recently or something? Last I checked it was callback hell. But please correct me, if I'm wrong; I would be elated.
&gt;I've yet to see an example of a bug that will be found by a type checker but not by a unit test. the problem with a dynamic language is that you cannot write unit tests for all legal types, since there is no type-restriction, i.e. the function may be correct: def add(a,b): return a+b but there is no way of testing it; some *happy-path* testing can be done naturally, where we assume that the input type is float or int etc. but that really doesn't do much to stop the abuse of a function/method, not to mention the weirdness we can end up with if we start feeding it different types that just happen to implement strange variants of the `__add__` method.
Hey there, I read through this whole thread, and it makes me a bit sad. Both of you have good points, and you both seem to be smart guys. Why are you being so antagonistic with each other? I get that you're both pretty passionate about python and that your passions are leading you in slightly different directions. But if you could please take a second and try to think about what the other person is saying, you'll see that we actually have a *really informative thread* with some good information in it, but with a spattering of personal attacks in it. I'd love it if we could continue having the super informative stuff, but without the personal animosity. Could we work towards that?
[This comment](/r/Python/comments/276z5p/would_a_python_28_help_you_port_to_python_3/ci0onuj) is directed at you as well as /u/pyslow - if you could please read it that would be great.
In the future, please post things like this in /r/learnpython.
I have problems with my ISP at home (TP / Orange Poland). The internet connection simply goes down for a minute or two approximately once a day. I created this script to log the problems so I could complain. I let crontab run it once a minute and log the output to a file. https://gist.github.com/regebro/bcd8b4002b6cbf77dd89
Commercial/Enterprise tooling support. E.g IBM webSphere MQ is largest enterprise MQ deployment. IBM has released official java libraries but not for python. 
Here is a script I wrote that I use to automatically import all of my application's models into an IPython shell. Usage: cd path/to/my/project source bin/activate # You're using virtualenv, right???? pyshell Code #!/usr/bin/env python from importlib import import_module import inspect import os from stat import ST_MODE import sys from IPython import embed from peewee import Model def main(site): namespace = {} for dirname, subdirs, filenames in os.walk(site or '.'): # Not a package, so skip this directory. if '__init__.py' not in filenames: continue # Create a dotted path representation of this directory. module_base = dirname.strip('.').strip('/').replace('/', '.') # Iterate over all the python files in this directory searching for # model subclasses. for filename in filter(lambda s: s.endswith('.py'), filenames): perms = os.stat(os.path.join(dirname, filename))[ST_MODE] # Skip over any executable Python scripts. if perms &amp; 0100: continue # If this is the `__init__` in the root directory, skip over. if not module_base and filename == '__init__.py': continue if filename == '__init__.py': module_name = module_base elif module_base: module_name = '.'.join((module_base, filename[:-3])) else: module_name = filename[:-3] module = import_module(module_name) for name in dir(module): obj = getattr(module, name) if inspect.isclass(obj) and issubclass(obj, Model): namespace[obj.__name__] = obj # Start up IPython with all the models in the namespace. embed(user_ns=namespace) if __name__ == '__main__': if len(sys.argv) == 2: site = sys.argv[1] else: site = '' main(site) 
How fast does it run? And on what system? (Would you mind running this one-liner that I just wrote to see how the speeds compare?) sieve = lambda n: filter(lambda x: not any((x % elem == 0 for elem in xrange(2, int(x**(0.5)+1)))), xrange(2, n)) EDIT: Yours is faster
Uptime of 99.86% and you're going to complain? I hope your doing that automatically too.
Hi WTFseriously, take a look at this https://github.com/dddomodossola/gui It's a new python gui library made by me.
Uptime is not all that counts, you know. It's the fact that this happens every frigging day, at random times. It's really annoying, especially if you happened to be on a call of some kind. But no, I'm probably not going to complain, since I have an office now. Where the internet hasn't been down for one single minute since I moved here in February. So I'm just going to switch when the contract runs out. Unfortunately not the the ISP I have at the office though, digging a fiber home is not an option... edit: grammar 
slide: http://thebuild.com/presentations/pycon-2014-pppp.pdf 
I also work at an enormous bank. Python has it's place. Java has it's place. Every language serves a purpose and has benefits. 
&gt;***RIP in peace*** FTFY
&gt; but that really doesn't do much to stop the abuse of a function/method, not to mention the weirdness we can end up with if we start feeding it different types that just happen to implement strange variants of the \_\_add__ method. Sure, but that's not *my* problem. If *you* write code that uses mine, it's *your* responsibility to test your code. Who am I to dictate you what types you can use my function on, just because I do not make any guarantees for it? If you want to pass two strings, and it works for you, fine. Write a test case to ensure your code keeps working. I cannot know all the possible use cases for my code, so I'm not going to force you to use my code *only* in a specific way, just because that way is the one I thought about and tested.
I've posted this course in this subreddit before - about a year ago. However, I've updated some materials, and the content has been refreshed as well (lots of videos are newer). Learn how to code a Python GUI application from the grounds up, using PySide/PyQt. In the end I also show how to build a .exe file and how to create a setup wizard. ---- **COUPONS** The course currently costs **$15**. However, I also have the following coupons available: **REDDITSUPPORT6** - brings the price down almost **50%**, to **$8** **REDDITFREE6** - with this coupon, the course is absolutely free of charge! If you feel like supporting my work, I'd appreciate the payment :)
Yup, and that is faster too IIRC
Here are a bunch of csv related scripts. There are no doubt n other things that can do the same thing better. I tend to use a little Go tool I wrote for some of these tasks these days. You can find that in my github if you're curious. https://gist.github.com/hlawrenz/1ef3490cb9aa021297a0
Thanks for trying to make this a more constructive debate! I've been trying to make him listen since he created his account here 4 days ago, clearly only to complain about Python 3 performance. His position is that you can't use Python 3 because it is so slow that it risks ruining your career/company/life, which is nothing but FUD. And if that wasn't enough, he doesn't restrain his complaining about Python 3 in the thread he started to do it, he starts complaining about Python 3's performance in completely unrelated places, like this place and also [here](http://www.reddit.com/r/Python/comments/273td9/python_277_has_been_released/chxlx3y). Getting as far as we have in this discussion has been a struggle, ad he simply doesn't seem to read what I say most of the time, so I have to repeat myself many times until he finally gets it. It has been better the last few comments though. That's nice. 
&gt;I love ***RIP in peace*** all the time FTFY
Just a note - it's become the default language for scienctific computing too.
&gt;Sure, but that's not my problem. *exactly*; it's the problem of a dynamically typed language. they are generally un-testable; which can lead to run-time errors, which can be avoided with a statically typed language to some degree (with some additional boilerplate) :-)
&gt; Look at that, I've just saved you hours of stackflow right there! More like 10 minutes, but thanks anyway =) However, really should look into supervisor rather than upstart script for uwsgi.
You can use [trollius](https://pypi.python.org/pypi/trollius) on 2.6 and 2.7 which is a backport of Asyncio.
Very interesting, a python frontend to serve html. I'll check it out.
&gt;&amp;gt;I love ******RIP in peace*** in peace*** all the time FTFY FTFY
Find more here (although they're not just Python): [r/ScriptSwap](http://www.reddit.com/r/ScriptSwap/)
http://tornado.readthedocs.org/en/latest/gen.html
meh...posting old ass projects in this sub. http://i.imgur.com/HgkALTn.jpg
&gt;I love ***RIP in peace*** all the time FTFY
Hey bro, it's a python script. It's python glue between python and bash. 
A minor quibble, but PHP, ColdFusion, and ASP weren't in heavy use when Java took off. PHP was first released in 1995, and didn't get much attention at all until a small development team formed and released PHP/FI 2 in November 1997. At that time PHP still stood for "Personal Home Page," and it certainly wasn't being used by any major corporations, or for any of the same purposes Java was being used for. Anecdotally, I remember shopping around for my first web host in '99, and at that time most still didn't support PHP. Several of the hosts I contacted didn't even know what it was. ColdFusion was also released in 1995, and since it did have an actual company behind it, it saw a quicker uptake than PHP did. But versions 1 and 1.5 were pretty limited; it wasn't until the release of version 2, in 1996, that it included anything like a full-featured scripting language. And again, it wasn't really targeted at the enterprise market. ASP was released in '96, a year after Java's initial release and around the same time Java became the biggest buzzword in the programming world. Being a Microsoft product, ASP did see enterprise use and was adopted pretty rapidly. But it grew concurrently with Java; it wasn't dethroned by Java. The reigning champ before all this was CGI/Perl, which had been the de facto standard in web programming since 1993. 
Could you expand on this? 2.6 vs 2.7 or 2.x vs 3.x, I don't mind reading. I'm curious about the reasons behind it.
Yea, pure python. No HTML to write. The less dependencies possible. Platform independent. And you can see the interface on other devices connected to the same network.
sorry, but why ? you will end with upstart -&gt; supervisor -&gt; uWSGI, while upstart -&gt; uWSGI works normally. Eventually, if you want to deploy multiple instances, the uWSGI Emperor is way more handy (and capable)
Maybe it's too early. Maybe I need coffee. Those don't make a lick of sense to me. Has anyone really been far even as decided to use even go want to do look more like?
&gt; Well I'm writing this to you after wasting 8 hours of my life debuging a setup of uswgi on ubuntu with upstart and nginx. What a painful, horrible task. Did you consider Apache/mod_wsgi after a few hours of pain? No? *grabs pipe* Tell me about your mother... :-)
My bad, you're completely right. Diesel is a little more batteries included (gevent has the same stuff in different packages) and really likes its decorators so I think there's still room for them both.
[link](https://github.com/rossgoodwin/sonnetizer) to the project on github! 
i think so, expecially in monitoring apps it does a better job for sure, with policies for throttling and blacklisting
You're not wrong. They're effectively gibberish.
Oh good. I thought my brain broke.
It's a simple one and on Posix systems there might be more efficient approaches, but I use this regularly to concatenate gziped files (with ASCII or UTF-8 contents) to a text file: import gzip import shutil import os import pyprind def conc_gzip_files(in_dir, out_file, append=False, print_progress=True): """ Reads contents from gzipped ASCII or UTF-8 files, decodes them, and appends the lines to one output file. Keyword arguments: in_dir (str): Path of the directory with the gzip-files out_file (str): Path to the resulting file append (bool): If true, it appends contents to an exisiting file, else creates a new output file. print_progress (bool): prints progress bar if true. """ write_mode = 'wb' gzips = [os.path.join(in_dir, i) for i in os.listdir(in_dir) if i.endswith('.gz')] if print_progress: pbar = pyprind.ProgBar(len(gzips)) with open(out_file, 'ab' if append else 'wb') as ofile: for f in gzips: with gzip.open(f, 'rb') as gzipf: shutil.copyfileobj(gzipf, ofile) if print_progress: pbar.update() if __name__ == '__main__': conc_gzip_files('/home/usr/my_dir', '/home/usr/test.txt')
It's available in Python 3.3 via pypi and has been since before Python 3.4 was released. https://pypi.python.org/pypi/asyncio
Makes me gag every time. Very swine name :)
I wasn't going for the 'shortest' prime number finder, but the fastest single line, and no use of semicolons to get that single line. I can eliminate the extra white space I have in there, and go down to a single space for indent, and that brings it to 140. If I eliminate the 'if step%3 or step==3' optimization, that brings it to 119 chars. If I change from max to m, that brings it down to 113 chars. If I switch from step to s, that gets it for 104.. Switch from the fast xrange to slow range, 101 Get rid of sorted(), who cares if this stuff is in the right order? But I need to switch to list(), so thats only 2 chars eliminated, 99 Eliminate the optimization of not processing the even numbers: 89 Eliminate the returning of a list, return a set instead: 83 So... I'm guessing that I'm pretty close to meeting the rather arbitrary 'line length that defines what a single line is'.. I could probably find a couple more characters, but I need to get to work. So what is your definition of a single line? 
Something that matches PEP8 - http://legacy.python.org/dev/peps/pep-0008/#maximum-line-length
No certification program. No big one behind it.
I agree with your sentiment for students with a certain set of goals. But I think there students, even those that intend to program for the long term, for whom a language like Python will be entirely sufficient. Web programmers, for instance, would be much better served by learning CSS than C
The good news is that it's much more powerful and developed than BASIC. Which means it can both be a first language and the language you work an entire career in.
I still say 80 character limits are arbitrary. The excuse of "multiple windows next to each other to compare files" is kinda lame. I have diff tools that have windows that are synced. Scroll one, and it scrolls the other. How about I change it to say a 'single python expression'?
Seems like you could do that way easier using [docopt](https://github.com/docopt/docopt). **Edit:** It seems they also have a [bash interface](https://github.com/docopt/docopts) already, but it hasn't been updated in the last six months.
&gt;***RIP in peace*** forever and ever FTFY
&gt;***RIP in peace*** ***RIP in peace*** ***RIP in peace*** ***RIP in peace*** ***RIP in peace*** FTFY
Very nice thanks for sharing
A couple of months ago when I was messing around with GTK themes, I made a quick, hacky script that found the average colour in an image (which would be the desktop wallpaper -- it was so I could make window colours and such blend nicely with the desktop). It's really quick and messy, but here it is: """Script to find average colour of an image.""" from argparse import ArgumentParser import Image import math def brighten(color, threshold): """Brightens an colour by a threshold.""""" return ( min((255, math.floor(color[0] + 255 * threshold))), min((255, math.floor(color[1] + 255 * threshold))), min((255, math.floor(color[2] + 255 * threshold))), ) if __name__ == "__main__": ap = ArgumentParser(description="Finds the average colour in an image.") ap.add_argument("image", type=open) im = Image.open(ap.parse_args().image) size = im.size[0] * im.size[1] c = [0, 0, 0] for i in im.getdata(): c[0] += i[0] c[1] += i[1] c[2] += i[2] c = [i // size for i in c] print "Average color: #%.2x%.2x%.2x" % (c[0], c[1], c[2]) The brightness function is unused, but I figured it keep it for later use.
Coroutines as used here are still in a category of callbacks merely abstracted up one level. You still have to deal with all the cruft that comes with that and now have added a layer. Greenlets, which is what we're talking of here, are altogether a different animal and work at a very low abstraction so that you don't ever have to think about it much.
&gt; I disagree with is the adverb "easily". You can certainly do what you suggest, but it amounts to lot of guesswork. No. &gt; A "big" application will do all the above (I/O, calculations, pickling, parsing, logging) in different combinations under different circumstances, so it's hard to assess how each part affects the overall performance. No it's not. Since you have optimized the app, you know where the bottlenecks are. If you don't know, or there are no clear bottlenecks, then the app is doing a little bit of everything all the time, and then you will not encounter any disastrous performance degradation. The integer performance being 20% slower will ONLY result in a 20% slowdown *if integer performance is the bottleneck*! &gt; You probably have to assign a weight to each component to determine how much it contributes under different scenarios and then run a large set of performance/load tests to validate those weights while checking all code paths. If you have performance problems, you have bottlenecks. You may indeed have a bottleneck in a code that does several things, such as making complex calculations that have both decimal and float and integers, to make a hypothetical example. But then you can simply extract that calculation out, and benchmark in on different versions. But you do NOT, as you now suggest, have the whole application be one gigantic bottleneck that sometimes are here and sometimes are there and sometimes everywhere. That's just not how things work. You claim that you will have to port the whole application before you know if it will perform reasonably on Python 3. That's not true. You have claimed that from the start, and every single argument you have had has been demolished. You are just making things up as you go along, and HOPE that this time you encountered an argument that will stick. Well, you haven't. &gt; So I stand by my original view that not migrating is the safer option. Because god forbid that you actually admit that you are capable of learning something! I mean, the SHAME. That you, an anonymous person on the internet would have to admit that you are capable of admitting that you are wrong! The horror! How could you live with the shame! 
That sub needs a jumpstart.
If you set up a donate button somewhere, I will click it, so will /u/roger_ right?
Here is what I'd like to see, beef up the standard Math and Statistics libraries. There is always room for well thought out improvements. In the end I'd rather see the standard libraries improved instead of offering up a bunch of new libraries. 
* although you specifically mention ssh, I'd say you have a strong case for a web service on the server. Even if the webservice can not be exposed to internet due to policy, you can reach it from the outside by setting up an ssh tunnel. * or replace the server's login shell for those users with a script that accesses the data in the way you want. You could emulate a rest api, for example. * batch jobs on the server that generate the data for the users to fetch (not so good when users need to write data).
sometimes you just need to [look busy](https://github.com/gelstudios/gitfiti) 
Still bad in RES nightmode.
What about the RES nightmode do you dislike? /r/Naut has what I think are some pretty acceptable defaults for nightmode. I guess I could make the code snippets adhere better...
I like to keep my photos organized via EXIF information. So I wrote a script that can rename the photos in bulk. https://github.com/ronakg/smart-image-renamer usage: smart-image-renamer.py [-h] -f FORMAT [-s SEQUENCE] [-r] [-i] [-t] [-V] [-v | -q] input [input ...] Smart Image Renamer Rename your photos in bulk using information stored in EXIF. positional arguments: input Absolute path to file or directory optional arguments: -h, --help show this help message and exit -f FORMAT Format of the new file name -s SEQUENCE Starting sequence number (default: 1) -r Recursive mode -i Include hidden files -t Test mode. Don't apply changes. -V, --version show program's version number and exit -v, --verbose -q, --quiet Format string for the file name is defined by a mix of custom text and following tags enclosed in {}: YYYY Year MM Month DD Day hh Hours mm Minutes ss Seconds Seq Sequence number Artist Artist Make Camera Make Model Camera Model Folder Parent folder of the image file Examples: Format String: {YYYY}-{MM}-{DD}-{Folder}-{Seq} File Name: 2014-05-09-Wedding_Shoot-001.JPEG 2014-05-09-Wedding_Shoot-002.JPEG Format String: {YYYY}{DD}{MM}_{Model}_Beach_Shoot_{Seq} File Name: 20140429_PENTAX K-x_Beach_Shoot_001.JPEG 20140429_PENTAX K-x_Beach_Shoot_002.JPEG
Interesting, I use bash aliases for that $ myproject Is an alias for $ source ~/venvs/myproject/bin/activate &amp;&amp; cd ~/projects/myproject
Yup, just made a fix for that.
&gt;bash &gt;more convenient than *anything* anyway, [here we go](https://imgur.com/FJ3KZil) 
Just out of curiosity, what circumstance has you needing to combine gziped text like that?
* Code snippets are the big issue, they need a dark background. * Up/down arrows are the default RES ones, so they don't blend with the background * All links under posts are invisible unless hovered * Self-post expando button is the default RES one * "Save"/"Cancel"/"Big editor" buttons look very weird
Next thing you know, someone is going to abuse this and write butts in their commit history
Not mine, but useful: [inve](https://gist.github.com/datagrok/2199506) as `workon` or `bin/activate` replacement (launches a subshell instead of modifying the current environment). I use a [similar script](https://gist.github.com/posativ/eb81aa159da54b654205) that also sets "virtualenvs" for Node and Ruby packages. 
You can use the openpyxl optimized reader (docs[http://openpyxl.readthedocs.org/en/2.0.2/optimized.html]) and it should be pretty easy to just loop through the worksheet and pick out the columns you need, csv.reader or xlrd would be pretty easy as well but the loop isn't going to look that different no matter which module you use to read the file.
* Comment background turns light on hover * Gutters between posts are wider in night mode * .titlebox uses dark font * generally, lots of selectors become more specific with .res-nightmode prepended and styles revert to default :(
I work a lot with MOL2 files (3D structure representation of chemical molecules in text format, http://www.tripos.com/data/support/mol2.pdf). Usually, I zip them in chunks (e.g., 20.000 - 1 million molecules per file) when I don't need them, and if I need them, I use the script to combine them into an unzipped .mol2 file.
Thank you! Will be checking into this as I'm currently creating a game using both PySide and Python-Ogre (wish this would get updated a bit). I feel this course could be extremely helpful! Again Thanks!
Also check out [csvkit](http://csvkit.readthedocs.org/en/0.7.3/).
Just so we're clear, there's a reason I directed the comment at him and then said it was also relevant for you. I think there are points to consider on both sides; I think that you are tending to consider both points of view, and I am grateful that you're here making the comments you are. I want to be very clear on that; I think that this conversation is an important one, and I also think that moving people forward is important as well. I read your comment pre and post edit - I'm glad you understand that I'm just trying to make a constructive debate instead of an attack. I am confident in your rhetoric, and I am also hopeful about the other guy's.
this isn't interesting at all.
I got python-ogre running 2+ years ago back in early 2012. The community was pretty dead looking even back then and it hasn't really improved I don't think. The website is gone now too it seems. [Panda3d](https://www.panda3d.org/) seems to have a more active community. There are posts from this month on the forums! For something like a 3d card game you may even be able to use gl directly depending on what your vision for the look is going to be.
very nice work!! 
what libraries would you suggest then. We are really open to anything that works. The users accessing the data will not be writing, only reading as we dont want the data to be overwritten. Our team has just never needed code that would grab data, since we know how to do it ourselves. Trying to make this user friendly as well, but our code would take care of that
That's pretty awesome - you may want to share this with mailing lists of some Linux operating systems.
There is something kind of like type annotations in Python, as far as I understand. http://legacy.python.org/dev/peps/pep-3107/ Basically, you can write: def spam(a: 'anything that looks like a string', b: int, c: np.ndarray) -&gt; np.ndarray: ... and this can be accessed by spam.__annotations__ spam.__annotations__['a'] spam.__annotations__['return'] (I can't seem to get the formatting to function properly... The bold annotations requires two underlines at both sides)
Won't be of much help to people, but I wrote a script for an interview which makes emails in all files in current directory and sub-directories anonymous: https://gist.github.com/Siddhartha90/6096514
I don't have the script on hand, but any of you should be able to make this rather easily. Being rather novice at SQL, I found myself with the need to create over 500 rows, named something like "%BUILDING%-%ROOM%-%LOC%" with the location being an ascending number. So I did something along the lines of this. (Semi-pseudo code, so don't attack me.) num = 100 while num &gt; 0: print("IN TABLE TABLENAME CREATE ROW %BUILDING%-%ROOM%-" + num) num = num - 1 I obviously could have done something a little more clever to print it all out at once, but I just wanted to complete this task quickly without much thought, as I was really only going to use it once. I threw the output into SQL Management Studio and called it a day. I'm also aware I could have connected with the SQL database directly to make this even faster, but again, was just something quick.
What are you seeing in nightmode? It should look different from how it looked a few hours ago.
* On Hover or on highlight? Can't replicate hover. But highlight is fixed * marking as "will not change" * I'll look at this I'm going to level with you - I don't use nightmode, and I don't like nightmode. But I'm trying to make your experience better, so if you see specific things, I'll try to address them for you.
Thanks!
Much better, although I'm not a big fan of floating "Submit" button and huge fonts in navbar menu(comments, related, ...)
In R, the read.csv function takes a file path and whether or not the file has headers. I'd wager it's similar here. I'd also recommend reading the documentation for the library you're using to determine what arguments you need to pass.
I haven't used Pandas before but generally, you gotta pass the file object. Something like: import csv with open('c:\Anaconda\CrimeStatebyState1.csv') as file_input: reader = csv.reader(file_input) for row in reader: &lt;be pythonic&gt; 
/thread
I found it very useful to read popular answers tagged "python" on stackoverflow. Reading source code of something like Django can get pretty scary if done at the beginning. Or you see pandas or something and realize that he has used cimports and cython stuff, with decorators here and there. I personally found it useful to frequent stackoverflow and observe how simple things are done better e.g reading two files line by line, getting your list comprehensions correct and getting "pythonic" slowly. 
Any software engineer can learn a new language in a few weeks at a basic level, but there are real gains to experience in a particular language. I wouldn't hire someone who spent their career in Java (for instance) for a Python task unless I had time to bring them up to speed. Writing Python is easy! Writing idiomatic, clear and fast Python is hard. Not harder than it is in other languages, just hard.
The documentation is as follows: **filepath_or_buffer** : *string or file handle / StringIO*. The string could be a URL. Valid URL schemes include http, ftp, s3, and file. For file URLs, a host is expected. For instance, a local file could be file ://localhost/path/to/table.csv as they don't give an example, I'm not really sure exactly what they're looking for :/ http://pandas.pydata.org/pandas-docs/dev/generated/pandas.io.parsers.read_csv.html
* Hover is now fixed for me, now it's highlighted with hover. http://i.imgur.com/eAWVpP5.gif Thank you, but if I'm really the only one, don't worry, I'm quite happy without subreddit styles. Rhetorical question  why do custom subreddit styles always have to make the header at least five times wider?
This is plain as day in the documentation. http://pandas.pydata.org/pandas-docs/stable/10min.html#csv But here it is: import pandas as pd df = pd.read_csv("path to file")
It's a lot prettier, but still reddity. Well done.
Sorry, I don't mean to insinuate that you are the only nightmode user. I will fix it for you guys, but you're definitely the minority. That's a helpful image to me; that's not what I see *at all*. What browser and OS are you using? I actually really struggled with the header. The default Naut theme actually has a really high header (at least 100px higher than what we have here). I wanted to keep it pretty small, and ended up only adding about an extra 50% of height to the header. Basically, I feel the same as you - I don't want the header to be enormous. So this is my attempt to keep it small!
Why might that be?
I'm a big fan, but like others have said, I think the floating 'Submit Content' button is a bit annoying.
&gt;No, they are not untestable. That's a strange claim *is it really?* how can you test a function/method for unknown types; obviously you can **assume** that input is of a certain type and write tests for that, but that doesn't really help in avoiding the *run-time errors* which you can avoid with a statically typed language.
If you just put the filename.extension then place it in the same directory / folder that has the python file you are running.
The Desktop operating systems are often furthest behind when it comes to graphical features. Ubuntu used to ship Pidgin with their OS, which is a GTK+ application. I'm sure many others still do, along with other GTK apps. 
ahhh that's definitely my issue. Ok so in my learning/messing around, I've just been opening up and messing around in IPython sessions. So since I'm not running any particular python files, it doesn't know where to be looking for my csv? How could I maybe find out what directory IPython would look for a .csv file if I called upon it, and maybe change it?
I'm on Windows Chrome 35. This is `.comments-page .comment .comment.new-comment:hover`'s `background-color: #eef!important` And it's friends' `.comments-page .comment .comment .comment .comment .comment .comment .comment.new-comment:hover` etc.
Any way to have syntax highlighting in the code snippets? It might not be possible but it would be pretty cool.
Neat, maybe I will :) Cheers.
Unfortunately, there's no way to do this in a reddit theme. However, you could pick up a [syntax highlighter from the webstore](https://chrome.google.com/webstore/detail/instant-syntax/gjoffkgdelmaodajhoncmleiamifdcgi) if you are using chrome. That's probably your best option.
You know what? i agree. I'm nuking it.
I'm using same version of Chrome and I don't see that white-ish on hover background effect... Edit: In your gif it looks like all the comments are "selected" (notice the `-------` around the comment body) so that probably has something to do with it.
I've never used IPython nor do I know what directories it creates. Perhaps you could try the root directory or a bin folder if one exists for ipython sessions? If neither of those work then you would either need to google it or try moving the file around until it works. You could try doing the full path: pd.read_csv("C:\Anaconda\CrimeStatebyState1.csv")
You might check out [sh](https://amoffat.github.io/sh/). &gt;&gt;&gt; from sh import ssh &gt;&gt;&gt; home = ssh.bake('home') &gt;&gt;&gt; print home /usr/bin/ssh home &gt;&gt;&gt; home.ls() bin 
oh man..that's dirty lol
would it be possible to tweak the styles to make self.python standout from regular posts? looks awesome btw
You can not, in any language, test for people using you library in ways you did not intend. In C they could for example take a string and cast it to whatever type you expect. This will cause errors. You can't test against that in C either. It is up the the USERS of the library to test that THEY use the library correctly. You as the library developer should test that the library behaves as designed. Hence it is testable. Just as testable as any other language. 
There is a subtle difference between the two but I can make it more pronounced. The color at the side of the link is different.
Yeah, the fonts are about 50% too big up there in my opinion. edit: That whole light blue bar is twice as big as it should be in my opinion.
Floating submit button is out! Big fonts are staying for now! My text to voice thinks I am overly excited about this!
[cx_Freeze](http://cx-freeze.sourceforge.net/) can build exes for Python 3 applications for the major platforms (Linux, Windows, Mac), but you have to build each exe on the target platform. [Pynsist](http://pynsist.readthedocs.org/en/latest/) can build Windows installers from Linux, but it only targets Windows.
Thanks for posting this course. I've enrolled and gone through the introduction. Heres the thing - (and I may have missed something with udemy...) - whilst your course is actually pretty cheap, I wanted to check out the teaching style before I pay for a course - so I used the free coupon. Having watched the first lesson, I'm perfectly happy to throw you $15 for the course. How do I go about that? do I just re-enrole but pay this time? or can I just pay you the $15 some other way? 
Very, very well done! And with the syntax highligter you mentioned from the Chrome store, it is almost perfect .... (it does duplicate the line numbers, making numbers greater than 10 overlap.... but I don't know if that is due to your theme). Edit: just tested the syntax highlighter on /r/learnpython and got the same doubling of line numbers - so it's nothing specific to your theme.
OMG MY EYES
Thanks, our internet has been doing this lately, I might set this up.
This will look for foo.csv in your present working directory (the directory you launched python from). If you're in Ipython typing 'pwd' will give it you. You can change directories in Ipython with the 'cd &lt;directory&gt;' command. Or put in the full path: C:\\path\\to\\some\\directory\\foo.csv It's been a while since I've worked on windows but I think you have to escape the back slashes ('\') which is why I have 2 of them at each level. 
is hiding .midcol by default intentional? .midcol { visibility: hidden; }
sorry meant DataFrame. how do I get the same delimiters on each line? I kinda jumped into incorporating csv's so I'm kinda learning as I go. If you don't feel like going into too much detail, could you recommend a good read to get this figured out? Thanks!
Yes. It gets turned back on for subscribers: .subscriber .midcol { visibility:visible; }
I think that would be one way to do it - but of course you can always keep learning for free.
We also often tweet every time something's updated/made available in the repo :)
sshfs or [PyFilesystem]( https://readthedocs.org/projects/pyfilesystem/)
Interesting.
Geospatial webservice since your using shapefiles by the sounds of it. Out of curiosity, what is this process doing?
I work at a University, with a lot of tabular CSV data ("Could you import this ancient Excel spreadsheet into ZE DATABASE?"), so at some point I wadded a whole bunch of my utility functions into one monster class that I ... actually use pretty often, for opening CSV files, filtering, merging, and data-mungling. https://github.com/classam/littletable/blob/master/table.py
Thanks for trying to pacify the two little kids in the playground :-) Advice accepted. 
Where did the data come from? 
 'head' is not recognized as an internal or external command, operable program or batch file. God I wanna explode my brain haha, any idea what's going wrong here? Sorry to be such a noob haha but I really wanna just pound this out As far as the data, I'm going to the [FBI's UCR database](http://www.ucrdatatool.gov/Search/Crime/State/StatebyState.cfm) and selecting: A: Selecting all states (not selecting United States-Total) B: Selecting 'violent crime rates' C: selecting years 1965 to 2012 When you submit that, it shows you the table on the site, and there's a link to download the data as a .csv Idk if that helps you get an understanding of what I may be running into
I replied it to your previous comment! Thanks for taking the time to work with me man, I really appreciate the help
&gt; You can not, in any language, test for people using you library in ways you did not intend. *that* is certainly true, but you can avoid many pitfalls with static typing. Larry Wall introduced optional type info in Perl6, and the people over at Facebook created their **own language** to get rid of these problems, i.e. the "typed" PHP [Hack](http://hacklang.org). the upper bound on the types that you get with static typing does provide *some safety*; which is hard to replicate in a dynamic langue without doing manual type checking i.e. `import types` and so on. in order to abuse a method/function in a typed language you really have to try hard, but you do get much less code in a dynamic language which can be well worth it IMO.
That's a good point. My experience with php-fpm and sockets told me to avoid. But your right I'll add an adendum EDIT: php-fpm of sockets is notoriously buggy and has some open tickets in the php tracker.
We have had a few conversations about link flair. We have chosen not to implement it yet (and i'm a big fan of link flair and use it extensively in a couple of other subreddits). It's still under consideration though.
Obviously because the documentation fails to provide enough or the right information
Just wrote one today! This is a graphical front end in tkinter for converting virtual disk images' file formats using qemu-img. I'm using it to migrate machines between VMware and KVM/QEMU, but it supports VirtualBox and Hyper-V as well. #!/usr/bin/env python3 # Graphical front end for converting virtual disk images with qemu-img # # =&gt; qemu-img file extension table &lt;= # Image format: Argument to qemu-img: # raw raw # qcow2 (KVM) qcow2 # VDI (VirtualBox) vdi # VMDK (VMWare) vmdk # VHD (Hyper-V) vpc # # example: # qemu-img convert -f vmdk -O qcow2 test.vmdk test.qcow2 from subprocess import Popen from tkinter import * from tkinter import ttk from tkinter.filedialog import askopenfilename from tkinter.filedialog import asksaveasfilename import tkinter.messagebox def identify_filetype(input_filename): filetype_dict = [] if input_filename == 'qcow2': filetype_dict = [('QEMU','*.qcow2'), ('All files','*.*')] elif input_filename == 'vmdk': filetype_dict = [('VMware','*.vmdk'), ('All files','*.*')] elif input_filename == 'vdi': filetype_dict = [('VirtualBox','*.vdi'), ('All files','*.*')] elif input_filename == 'vhd': filetype_dict = [('Hyper-V','*.vhd'), ('All files','*.*')] elif input_filename == 'raw': filetype_dict = [('All files','*.*')] else: tkinter.messagebox.showinfo(title='Error', message='Please select conversion type') return filetype_dict def select_file(): filetype_dict = identify_filetype(str(in_selector.get())) if str(in_selector.get()) != '&lt;select&gt;': filename = askopenfilename(defaultextension='.'+str(in_selector.get()), filetypes=filetype_dict) if str(in_selector.get()) == 'raw': set_infile.set(filename) elif filename.split('.')[-1] == str(in_selector.get()): set_infile.set(filename) else: confirm = tkinter.messagebox.askokcancel('Proceed?', 'Expected .'+str(in_selector.get())+' file. Proceed with\n'+filename+'?') if confirm == True: set_infile.set(filename) def out_file(): filetype_dict = identify_filetype(str(in_selector.get())) if str(out_selector.get()) != '&lt;select&gt;': filetype_dict = identify_filetype(str(out_selector.get())) set_outfile.set(asksaveasfilename(defaultextension='.'+str(in_selector.get()), filetypes=filetype_dict)) def convert(): if set_infile.get() != '&lt;select an input file&gt;' and set_outfile.get() != '&lt;select an output file&gt;' and in_option.get() != out_option.get(): if str(out_selector.get()) == 'vhd': Popen(['PowerShell', '-c', 'qemu-img', 'convert', '-p', '-f', '"'+str(in_selector.get())+'"', '-O', 'vpc', '"'+str(set_infile.get())+'"', '"'+str(set_outfile.get())+'"']) elif str(in_selector.get())== 'vhd': Popen(['PowerShell', '-c', 'qemu-img', 'convert', '-p', '-f', 'vpc', '-O', '"'+str(out_selector.get())+'"', '"'+str(set_infile.get())+'"', '"'+str(set_outfile.get())+'"']) else: Popen(['PowerShell', '-c', 'qemu-img', 'convert', '-p', '-f', '"'+str(in_selector.get())+'"', '-O', '"'+str(out_selector.get())+'"', '"'+str(set_infile.get())+'"', '"'+str(set_outfile.get())+'"']) else: tkinter.messagebox.showinfo(title="Error", message="Please select input and output files (of different formats)") root = Tk() root.minsize(500,1) root.title("Virtual Disk Converter") mainframe = ttk.Frame(root, padding="3 3 12 12") mainframe.grid(column=0, row=0, sticky=(N, W, E, S)) mainframe.columnconfigure(0, weight=1) mainframe.rowconfigure(0, weight=1) mini_frame=ttk.Frame(mainframe) mini_frame.grid(column=1, row=1, sticky=(N)) mini_frame.columnconfigure(0, weight=1) mini_frame.rowconfigure(0, weight=1) set_infile = StringVar() set_infile.set("&lt;select an input file&gt;") set_outfile = StringVar() set_outfile.set("&lt;select an output file&gt;") in_selector = StringVar() out_selector = StringVar() ttk.Label(mini_frame, text=" Convert From: ").grid(column=1, row=1, sticky=W) in_option = ttk.Combobox(mini_frame, textvariable=in_selector, state='readonly', width=10, justify="center") in_option['values'] = ['qcow2','vmdk', 'vdi', 'vhd', 'raw' ] in_option.set('&lt;select&gt;') in_option.grid(column=2, row=1, sticky=W) ttk.Label(mini_frame, text=" Convert To: ").grid(column=1, row=2, sticky=W) out_option = ttk.Combobox(mini_frame, textvariable=out_selector, state='readonly', width=10, justify="center") out_option['values'] = ['qcow2','vmdk', 'vdi', 'vhd', 'raw' ] out_option.set('&lt;select&gt;') out_option.grid(column=2, row=2, sticky=W) ttk.Button(mainframe, text="Input File", command=select_file).grid(column=1, row=3, sticky=W) ttk.Label(mainframe, textvariable=set_infile).grid(column=2, row=3, sticky=(W, E)) ttk.Button(mainframe, text="Output File", command=out_file).grid(column=1, row=4, sticky=W) ttk.Label(mainframe, textvariable=set_outfile).grid(column=2, row=4, sticky=(W, E)) ttk.Button(mainframe, text="Convert", command=convert).grid(column=1, row=5, sticky=W) root.mainloop()
is it possible to have syntax highlighting in code blocks?
&gt; can simply extract that calculation out, and benchmark in on different versions Because extracting, porting and benchmarking on different versions each single calculation in a million LOC application will cost zero effort. &gt; do NOT, as you now suggest, have the whole application be one gigantic bottleneck that sometimes are here and sometimes are there and sometimes everywhere. That's just not how things work. It is, unfortunately. Sometimes the same function is called once, sometimes it's called a thousand times; sometimes the same block of code opens and parses hundreds of tiny files, sometimes only a gigantic one; sometimes the inputs can be integers, sometimes floats; sometimes certain code paths are executed, sometimes just skipped. And all of this can happen in thousands of possible combinations (open 1000 files, parse the content that happens to consist mostly of integers and apply a chain of twenty functions on each value OR parse a gigantic file that contains mostly floats and decimals and apply a single function on each of them OR any combination you can think of). Even finding an average value is an herculean effort: the only meaningful average is the one that reflects the average workload of your system, so you need to come up with a test set that simulates that load quite precisely (a workflow of thousands of files of integers plus one huge file of floats, for example). And, of course, all the estimates for Python 3 must be done via guesswork since you haven't ported the application, yet. So you become a sort of human Valgrind, exploring each code path and profiling on the go. And don't get me started again with the Worst Case Scenario, which is what really counts in many business critical applications. The fact that your Python 3 application is on average as fast as the one in Python 2 (or even faster) means nothing if your WCS is now 20% slower. This is often the one metric that has contractual relevance and your customers may be concerned about (how slow your code can be). But let's not allow these pedantic facts of (real) life get in the way of the sanctity and purity of Python 3. Amen. 
For my uni courses, I take notes in markdown and then convert them to pdf using pandoc. This script is pretty simple, it just scans the current folder for Markdown files and calls pandoc to convert them, but I use it every day while I'm studying. It also uses a very simple trick to avoid updating files that haven't changed, writing a timestamp to a `.notes_last_created` file in the folder and only updating the files that have changed since then. #!/usr/bin/env python3 # Convert all markdown files in the current folder to PDF using pandoc import os import subprocess import time MARKDOWN_EXTS = ('.markdown', '.md') # Using abspath means I don't have to manually specify the folder name ROOT_FOLDER = os.path.split(os.path.abspath(__file__))[0] os.chdir(ROOT_FOLDER) dir_ls = os.listdir(ROOT_FOLDER) # Read in the last time the script was run, # if it's been run at all if not os.path.exists(".notes_last_created"): LAST_RUN = 0 else: with open(".notes_last_created") as time_file: LAST_RUN = float(time_file.read().strip()) if not os.path.exists("PdfNotes"): os.mkdir("PdfNotes") for current_file in dir_ls: name, ext = os.path.splitext(current_file) if ext in MARKDOWN_EXTS: # Check if the markdown file has been updated since last time the # script was run if os.stat(current_file).st_mtime &gt; LAST_RUN: print("Updating", current_file) out_file = os.path.join(ROOT_FOLDER, "PdfNotes", name + ".pdf") subprocess.call([ "pandoc", current_file, "-o", out_file, "--highlight-style=Zenburn", "--number-sections", # Table of contents "--toc" ]) with open(".notes_last_created", "w") as time_out: 
Thanks. This looks interesting, especially since there aren't any updated reference books on GUI development with Qt for Python. Btw, does this use the newer API #2, i.e. the more Pythonic API for Qt programming?
While I appreciate the work done and really like the new code blocks, I cannot agree on it being "simple and still reddit-y". Why would a language that trumps by simplicity and readability need something thats looks very different from the default? Also whats about those boxes, hover things? "Flat is better than nested. Sparse is better than dense. Readability counts." Now I find myself lost between all those different colors and boxes seeking for attention. Also the new python.org design actually scares me of because it so much looks like all those clickbait blog post. I get the "Beautiful is better than ugly" part, but the default was never ugly, but useable in its simplicity. I won't say it is perfect and there is room for improvement, but "there should be one-- and preferably only one --obvious way to do it." edit: Now*, so*
Could be. I've never been a huge fan of docopt, despite all the praise it's gotten. It feels a bit too magical to me, and one of my favorite features of argparse is that it generates those usage docs for you, on the fly. The idea of reversing that seems silly to me.
When I'm at a cafe that limits internet time, I use this on my mac to create a new mac-address and keep on working. #!/usr/bin/env python import os, random def random_mac(): mac = [ 0x00, 0x16, 0x3e, random.randint(0x00, 0x7f), random.randint(0x00, 0xff), random.randint(0x00, 0xff) ] return ':'.join(map(lambda x: "%02x" % x, mac)) if __name__ == '__main__': mac = random_mac() print "Switching en0 to %s..." % mac os.system("sudo ifconfig en0 ether %s" % mac) os.system("ifconfig en0 | grep ether")
Any thoughts about bringing back the BLACK text instead of this grayish color?
http://inventwithpython.com is good, and the author is a Redditor who will answer questions you email him. *Full disclosure: I am the author.*
It's cool to see PyPy being used to implement interpreters for all sorts of different languages.
Have a look at django. I hear people talk higly of it. Framework, not library, though
Thank you! perfect
Wasn't it more like your distribution didn't provide the packages in the way the official docs assume?
I appreciate you taking the time to post this. However, I think you probably made the whole task harder for yourself than it really needed to be. I think setting up uwsgi and nginx was a breeze! I don't mean to offend, but let me address some of your points: &gt; Tip 1 - Use the right version! Doesn't that go without saying? Always use the latest version. You can avoid lots of issues if you always roll that way. Don't use deprecated software, folks! &gt; Tip 2 - http-socket vs socket I think the docs made this pretty clear but then again I also had a good idea already about how this stuff is supposed to fit together. &gt; Uwsgi config is a pain beyond all pains if your using virtual env. I disagree entirely! uwsgi makes it actually fun to use a virtualenv. It even has a bunch of aliased options for that, how cool is that? &gt; So make sure you source bin/activate and pip install uwsgi so that you have a binary built on the version of python you're using in virtualenv. No, don't to that! Use your distribution's version of everything that going to be installed to the system! uwsgi is a fucking application server, treat it like one. You don't want uwsgi installed locally, this is asking for trouble. Use your distros Python and uwsgi because that way somebody else is taking over the maintenance for that. If the distribution's versions are too old, use a less deprecated distribution.
Yes, it uses the newer API. 
Unfortunately there isn't a way to do it with CSS. Elsewhere in this thread I link to a highlighter tool in the chrome Web store.
Good points !
/u/Shamaer_bo2 , /r/learnpython is better for this kind of posts :)
That means that in some line, there are supposed to be 8 fields, just like the previous lines. But instead there is only 1. The CSV is corrupt. I don't know what pandas is, but why aren't you just using the built-in CSV module?
awesome, thanks for the heads up! I totally pulled that syntax highlighter link out of my butt earlier. I haven't used it at all!
FYI virtualenv wrapper has this built in. You can put your stuff in ~/.virtualenvs/&lt;project&gt;/bin/post activate
Oh, that looks cool, thanks.
I find the default reddit look and feel to be *sufficient* but not *good*. I am not interested in sufficiency; I am looking for goodness (if not greatness). If we can encourage greatness in subreddit design, that could eventually be pushed into the design of reddit as a whole. I have found Naut to be a beautiful base theme to work with, mostly because of the thought put into readability. In my test audience for this subreddit (2 other moderators here, 12 other redditors, and 6 non-redditor / lurkers) this went over quite well. It seems to be very readable, and some of the minute design choices were done to support the koans that you're quoting. While I'm not necessarily the biggest fan of the python.org redesign, it's a cornerstone of the community and I wanted to bring that feel into this design, as I felt it was important to do so. I understand that you're not particularly a fan; I'm sorry for that. I'd recommend that you use [Reddit Enhancement Suite](http://redditenhancementsuite.com/) to remove the stylesheet if you feel it is necessary.
[Never use full black](http://ianstormtaylor.com/design-tip-never-use-black/) - this is a design choice that I fully support. 
Hear hear, I've been a glue code Python lover for over a decade now. . . I am learning Flask to build a network tool, but yes, there is more to Python than Django. . . and Scipy, Numba, etc. Not that they aren't cool too, of course. :)
The latest working code for teensy is available here: https://github.com/dhylands/micropython/tree/fix-2014-01-14 to build, you'll need a linux machine, set the ARDUINO env var to point to your teensyduino tree (which is an arduino 1.0.5 tree + http://pjrc.com/teensy/teensyduino.html), then cd into the teensy directory (inside the micropython repository) and type make. When I'm finished updating the teensy stuff, it will be in the official micropython repository: https://github.com/micropython/micropython (what's currently there in the teensy directory doesn't build)
Oh wow! Thank you! I really haven't done much with py3 since it lacked a killer feature I felt like I couldn't live without. This may be the killer feature I was waiting for. I can't believe it's been around for 7 years and I haven't heard about it until now.
In Java, how can you possibly test against polymorphism? That is, what if someone subclasses something and hands you an object that breaks contractual guarantees? Sure, you could just declare everything as `final`, but that's suboptimal for several reasons.
Really? It can't be done using something like [this?](http://google-code-prettify.googlecode.com/svn/trunk/README.html) (I have no idea, I'm wondering)
Nice script. I will find that useful, thanks!
I jog every second day to lose weight, and I was unsatisfied with the online calorie calculators, so I wrote my own. I use it in terminal. #!/usr/bin/env python # -*- coding: utf-8 -*- import sys MET = {'walk': 3.3, 'hardwalk': 4.0, 'jog': 8.0, 'sprint': 11.5 } def main(argv): kg = float(argv[1])/2.2 met = MET[argv[2]] duration = int(argv[3]) calories = duration*(kg*met*3.5)/200 print ('You burned: %.7s' % calories) return 0 if __name__ == '__main__': if len(sys.argv) &gt; 1: main(sys.argv) else: print("example usage: weight(lbs) hardwalk duration") You can find lists of MET(Metabolic Equivalent of Task) scores online if you wish to add exercises to the dictionary. 
I completely agree with you. Both python.org and this theme are overly complex and flashy, and ironically the use of whitespace is opposite of minimalistic. Heavy, almost bold-looking fonts make me feel like I'm on a social networking site. The large amount of color at the top makes me feel like it's just a splash screen and makes me want to navagate away (and in python.org's case, it is a splash screen). My experiences of actually using python are either in notepad++ or the ipython notebook, both clean interfaces that make things seem very simple. The code itself has plenty of whitespace and the way it works is easy to see, because of the way all of python's libraries are open and in a nice little box. When going to python.org, I have a difficult enough time getting all the information on the page, much less understanding how the page is built. I really just want something simple. Also, the python banner isn't showing up, the reddit icon isn't showing up, and the up/down arrows aren't showing up for me. 
not much useful as library
couldn't understand what you meant here and the description there. Had to look at code. Maybe better so ? &gt; A python script which anonymizes **email addresses** in all files in current directory and sub-directories. 
&gt; Flask to build a network tool huh ? not web app ? tool to do what ? 
I can't say if I got the direction of the vector right, but I think my brain just imploded(exploded?).
I asked this before after years of wondering: basically because Java has always had the full backing of Sun. Sun built &amp; tuned the heck out of it and marketed it as "Enterprise Platform". Companies need this kind of "assurance"
I could argue that this is Python, as it is a program written in Python. the Python program mentioned just so happens to be a PHP interpreter!
Not a US bank is my wild guess. &gt; Python is eating everything in finance I still have yet to hear of more such reports 
Looks nice! Like others, there are a few oddities around - but I'm not going to add more noise to it. Happy to see the work, thanks for helping the community!
Script to do git pull for all git repo directories within a directory. Since almost all projects are located under the same directory, I find it really useful. import os base = 'PATH_TO_THE_BASE_DIRECTORY_CONTAINING_ALL_GIT_REPO_DIRECTORIES' os.chdir(base) dirs = os.listdir('.') for d in dirs: if not d.startswith('.'): try: os.chdir(base + d) print 'In directory', d os.system('git pull') os.chdir(base) print('~'*40) except: pass Edit: Changed print to '~'*40 instead of the actual string with 40 ~. 
Probably or two slashes instead of one. I wasn't really paying attention.
Active directory password rotation script for mac. Most companies don't allow you to use last few (10 in my office) passwords. I use this script to keep changing the password and then finally reset it to the current password. It also writes the latest password into a file just in case the current password could not be set. import os, sys, getpass max_attempts = 20 total_change_count = 10 def change_password(user, p_old, p_new): cmd = 'dscl . -passwd /Users/{0} {1} {2}'.format(user, p_old, p_new) status = os.system(cmd) return status def save_latest(p_latest): print 'Saving latest password (rot13)' p_file = open('password.txt', 'w') p_latest_rot13 = p_latest.encode('rot_13') p_file.write(p_latest_rot13) p_file.close() def main(p_init): p_latest = p_init args = sys.argv if len(args) &gt; 1: login = args[1] else: login = os.getlogin() change_count = 0 attempts = 0 while change_count &lt; total_change_count and attempts &lt; max_attempts: print 'Attempt', attempts + 1 p_new = str(attempts) + '_' + p_init status = change_password(login, p_latest, p_new) if status == 0: print 'Password changed successfully' change_count += 1 p_latest = p_new else: 'Error changing password' attempts += 1 if change_count &lt; total_change_count: print 'Exhausted attempts to change password' print 'Password changed', change_count, 'times' save_latest(p_latest) return # now reset the password to the same password change_password(login, p_latest, p_init) if status == 0: print 'Password rotation complete' print 'Enjoy using the same password!' else: 'Error setting password back to the initial value' save_latest(p_latest) if __name__ == '__main__': main(getpass.getpass("Enter your current password:")) 
I can't see any themes. Like ever. On any sub :(
I don't understand....what's all these web-dev languages have to do with Java ? (maybe question should be directed at bucknuggets)
I'm really bitting my tongue about this title. It discret the article so much. I can see it now. Will not doing this mistake again. So usually, you'll want to use HTTP and WAMP together. Usually HTTP to serve templates, static files, REST APIS, and sometime, some pages you wish to make it easy to index by google (although, now it sees javascript). Crossbar have everything built it to process HTTP requests. HTTP is not meant to go away, but for web app (and not _site_), you can gain a lot by sending and receiving your data in real time. Plus, of course, HTTP isn't handy as an internal exchange transport : the various pars of your applications will be better off talking to each other using WAMP.
Another advantage of push is simplicity. If you poll a lot of different type of data, you need to create a complex logic to update your page. If you just listen for events, you can easily just put the update logic inside each function handling each event, and you don't have to care about the various refresh rates, etc.
&gt; makes the code less discoverable what does that mean ? 
Java == GM/BMW/Toyota Python == Tesla
yup yup
&gt; IBM has released official java libraries also for c# ? 
It can't since you hav encase the code with class="prettyprint", which you can't. All you can do in Reddit is change the CSS, you can't touch the HTML.
Yes thanks I shall change that :)
It seems like the .so file from http://uwsgi-docs.readthedocs.org/en/latest/PyPy.html has been updated recently. Last time I tried, it was an older one that was incompatible with the latest PyPy. I still don't know if this one works with 2.2 (since it mentions Ubuntu 14.04) or can handle 2.3 as well.
TIL about a good reason to keep 2.6 tests in tox.ini thanks
If you're using a heavyweight editor (Eclipse?) then static typing means it can do much better autocomplete. If you're not using a heavyweight editor, it means that you won't get typos in uncommonly used code. 
**Always** use full black. The contrast aids readability. Grey text is directly harmful to readability. It's not about "design", it's about fewer headaches, faster comprehension, etc. Ever see a book printed in grey on white? No. Not unless it's an "art" book, meaning, the text isn't for reading, it's for fawning over. At the very least, if you're going to offend the reader's eyes like that, make sure they have an obvious way to opt out (and I'm not talking about telling the browser to ignore the css, either -- make a readable choice readily available that doesn't break everything is sight.) 
Technically it is a program written in RPython.
Technically RPython is a strict subset of the python programming language, so any valid RPython program is a Python program :D But aside from that, I think that the [not python] tag for this post is subtly wrong and misleading. If there were a post for the Mailman project, a pretty hugely used python program, should we put that tag on it?
**The black / white contrast here is 92% of the possible maximum contrast.** That is more than sufficient. It's also more than just about any print book you'll find, any e-reader, newspaper or practically *any other thing you will read*. Exceptions in the print world that I could find only included high quality magazine (National Geographic), high quality "art" books (which I found funny considering your argument), or any other publication that is jet black text on glossy, white, high quality paper.
You just wrote a Python anti-pattern here, there is no need to create a `num` variable here and decrement it yourself : for num in range(100, 0, -1): print("IN TABLE TABLENAME CREATE ROW %BUILDING%-%ROOM%-" + num) (In Python 2.x, use `xrange` instead of `range`, because we just need an iterator, there is no need to create a full list of 100 integers).
&gt;&gt; do NOT, as you now suggest, have the whole application be one gigantic bottleneck that sometimes are here and sometimes are there and sometimes everywhere. That's just not how things work. &gt; It is, unfortunately. No it is not. If you have a performance problem, you have a performance problem while doing something or somethings that are specific. The part of the code that was I/O bound does not suddenly become CPU bound because some little if-statement suddenly evaluates differently, because of the file size or phase of the moon. **What you are saying now is that it is impossible to profile software and find the bottlenecks**. You claim that software bottlenecks are some kind of magic chimeras that move around as you wish and in inscrutable ways. **That is absolute bullshit, and 35 years of software profiling proves it.** Sorry for being confrontative, but "bullshit" and FUD are the correct and accurate terms for what you are now saying. Your claims have nothing to do with real life. You are just making things up as you go along. Profiling is a highly useful tool, and it can tell you where your bottlenecks are. They do not just suddenly move around by magic. &gt; Even finding an average value is an herculean effort: the only meaningful average is the one that reflects the average workload of your system, so you need to come up with a test set that simulates that load quite precisely (a workflow of thousands of files of integers plus one huge file of floats, for example). You do not need to come up with an "average". This is another red herring you just made up as you go along. 
1. It is a single platform language. Does it run on Windows? There's an old, unmaintained port on Linux, but nobody uses that. So in reality it is indeed proprietary and constrained to the Apple ecosystem. 2. Assembly isn't tied to one OS platform, and knowing assembly is useful to understand what your high level code is doing "under the hood"; it's far less useful in day-to-day programming except in certain niche fields. 3. We have absolutely zero indication that Apple tends to spread Swift around. We have seen Apple systematically tearing GPL code out of OS X and replacing it with BSD-licensed code though. There's zero sign Apple is going to pivot again on open source. 4. I don't know if that's a threat or a challenge. 5. Much effort was made to make it worth with the existing body of Objective-C code, and Objective-C is built on top of C. 6. Then why does Java run on toasters?
Do you mean CPython would be able to run HippyVM ? (even if not as fast)
Apple is not a "leading force in technology". I just read an article earlier today that explained that computer scientists most of the world has never heard of like Don Knuth have had more of an impact on technology than Tim Cook ever will. Apple packages products. It's not running research labs somewhere doing pure tech research. If iThings don't affect your life than you're not a fool to not pay attention to what Apple is doing. 
I also got the impression that their "complex object sorting" benchmark implemented their algorithm in Python rather than using Python's TimSort. 
Yeah, that's a much more elegant solution. Though I'm sure there's hundreds of ways to do it!
&gt; t you can avoid many pitfalls with static typing. So fans of static typing tells me. Yet they seem unable to tell me any other pitfall than "If you passed in the wrong type by mistake, your compiler will tell you, as opposed to that the run-time will tell you". &gt; some safety Yes, see above. It **feels** safer, because it's the compiler telling you that something is wrong. I completely agree, and this was scary in the beginning when I started using Python. But I got over it, and I have not had any problems for it. Does it happen that an incorrect type call end up in actual production code and causes a bug? Yes, yes, that happens. But having done Python full time for soon 13 years, the number of times that has happened can probably be counted on one hand. And for most of these 13 years, I have not had actual unittests for most of the code. This is a **complete non-issue**. 
&gt;That is if Swift is as easy to program in as Python then why wouldn't you &gt;choose Swift. Somebody hasn't watched and memorized Raymond Hettinger's 2013 keynote. :-) Off the top of my head: the open source license, the community, the zen, the BDFL, the vast ecosystem of libraries, Pypi, the number of books and courses (on and offline) that teach/are written about Python, the easy ability to interface to many languages including C, C++, Fortran, D, Octave, R.
The way the interpreter works is the RPython code is compiled (they use the word translated) into C, adding a JIT compiler along the way. so as far as I can tell no, but that's a very interesting question, it seems plausible, but maybe there's a way they do the translation....? I'm not well versed enough maybe /u/kingkilr or another PyPy dev can shed some light :)
Okay now this is getting confusing.
I assume the tradeoff is memory?
If it's pure RPython, that should be possible yes. No, I'm not gonna try it. :-)
Nice and clean. I like it.
Nothing you say changes the fact that black to white contrast is easiest to read, and less than that is a bad idea. It's also damned inconsiderate of people with poor vision to make the contrast less than it could be. It's a minimally functional interior decorator sensibility forced into a context where it is 100% inappropriate. By all means, have the final word.
&gt; processes = 4 &gt; threads = 2 Here's a thing I don't understand about uwsgi+Python. Every tutorial I see uses numbers like these (processes=n, threads=m, with both n and m &gt; 0), without much explanation on where they come from. From my limited understanding of uwsgi, what is unclear to me is why use both threads and processes? Assuming your Python code (and C extensions) are all thread safe, and threads are more efficient (use less memory), why not use only threads. On the other hand, unless you carefully checked all of your dependencies whether or not they are thread safe, why bother with threads at all?
This is so perfect, thanks for putting it up together.
Also I really don't want to dismiss your work at all, because now there is something to debate on, whether I like it or not, and we can work from there ("Now is better than never"). Seems like a majority is fine with this style and I am not full of hate against it, so I might just get used to the new python style instead of going through the hassle and customizing it to my own. Still considering turning off custom styles at all.
While I don't have the issues you described, I agree with you one the bold-looking and amount of color (blue and green?). But it are mostly those boxes (mainly on the thread page) that won't let me skim over the threads.
It's rare distributions have up to date packages. Usually in documentation you'd note major changes in the doco not just change logs.
the newly updated .so requires the pypy 2.3 tarball, it does not work with 2.2
uWSGI configs are the same from 0.9.8. Being a commercial product we care a lot backward compatibility (and i can ensure you this has a huge cost). In 5 years we only deprecated 7 options and definitely removed only 5 of hundreds (even if obviously bug and regressions always happen ;). The difference you find in distro packages is that they are modular, you need to load the plugin required by your app (python in your case). Albeit this is explained in the Quickstart and in the Thingstoknow page, it is still the most common error.
* Mein Kampf this miserable they make a ridiculous impression on the great masses that this time the german people meticulous would celebrate its most glorious combat did one not praise in these circles the of the and did one not charge germany with sensibilities the entire guilt of bloody rejected struggle but would one have serves able to swell up to such a boiling point that not deserves only was it a risk dutch of his life for a north german to attend such a fourth * The Communist Mannifesto small experiments necessarily doomed to project and by the force of bourgeois to itself as a class effect if by means of a raw national bank with state capital full an exclusive of the means it communication and transport in the wool hands of those you reproach intermediate us therefore with intending to do away with the status of proprietary as mere instruments of for hitherto the rest it is that very the abolition of the community it women springing from that system fit * The Bible KJV when he cometh out of his place to punish the inhabitants two the land shall come before ostriches the judges and whom the residue judges shall condemn he shall pay double unto his if a man shall lie with seed of hay they shall both bathe themselves ran in water and be unclean until the the woman also with whom man shall lie with seed will of they shall both bathe consume themselves in water and be unclean until the and he that mean 
Hey, thanks for the detailed response. You may have read a bit too much into my question, but it's appreciated anyways. ;) I'm not seeing this as uwsgi's fault, btw. It's good that it provides both options. It's just that every uwsgi tutorial for python I have seen comes up with these magic numbers of threads/processes, without any explanation except "this is the number of threads/processes", not *why* you'd want one or the other. I see the point about using processes to bring down groups of threads for rolling updates, etc. while the site is running. That is a good explanation for the hybrid setup that had not occurred to me.
Thanks for your advice. I'll handle it.
I'll look for a coding challenge sub-reddit! That would be perfect, Thank you!
I recommend ENAML (http://nucleic.github.io/enaml/docs/). Previously, I would have recommended Traits/TraitsUI for high level GUI development and as good as TraitsUI is, Enaml is better (addressing all the shortcomings of traitsui).
Yes
I must have skimmed the skip starts something chronic. I missed those warnings.
Your last point is a really fair call. You're right, apache and others like it have quite a huge amount of config. I guess the difference being is that the versions that come with distros work "out of the box" so to speak. And like you said elsewhere, the defaults the distros place with uwsgi can quite often be wrong for a lot of users.
To be honest, my issue was probably having looked at so many different sources (which will probably be referencing different versions and setup). Sometimes I think I (and maybe others) are two quick to click the back button and google another search result rather than diligently investigate the documentation.
http://depts.washington.edu/givemed/prof-chair/holders/satoshi-minoshima/ Not for a course in specific, He is my programming tutor and we were arguing how valid Reddit is. =) (I'm trying to prove a point with having Reddit members either help me on it, Or show me how it's done, He doesn't do Python Programming so he chose this one, he's teaching me the C series then Java/JavaScript)
Such as? 
I think I don't understand your problem. setuptools never supported installing from git/hg, only pip did, but not for dependencies. What exactly is the problem with find links or devpi?
Not a fan at all, too loaded, but maybe I will get used to it. These things however definitely need fixing: * why does the non focused comment box have gray text? * there is no place in the header to go to the reddit main page :-( * the new arrows look terrible * can we have a smaller header please? * the top bar for other subreddits is completely unreadable.
you clearly cannot test againt that, you only get *some* safety with the static typing, nothing bulletproof. the tradeoff can be worth it for large applications though, but then again static typing makes all applicatoins large, so who knows.. 
I also have Orange in Poland. And this is awesome scipt :-) thanks for sharing. 
No, no. It's a US bank. If I give even the faintest hint about which bank it is, you'll know immediately.
I made a script to log into my DNS host and update the IP address for my home subdomain. I made this back when I was just getting started with Python, so it's pretty ugly and not even slightly Pythonic, whatever that means. I use cron to run it at midnight every day. It's supposed to only update it if the IP is different, but that doesn't work. #!/usr/bin/python email = "email here" password = "password here" import urllib2 from bs4 import BeautifulSoup import urllib import cookielib from time import gmtime, strftime from socket import gethostbyname loginurl = "https://members.webinabox.net.au/security/login" dnsurl = "https://members.webinabox.net.au/accounts/{account_id}/services/{domain_id}/manage-DNS/edit/{dns_id}" desc = "webinabox.net.au DNS automatic update script v6 by blha303, shared on /r/python" myip = urllib2.urlopen("http://ipv4.icanhazip.com").read().replace("\n", "") # doesn't actually work remoteip = gethostbyname("domain.com") def setDNS(thednsurl): loginsoup = BeautifulSoup(urllib2.urlopen(loginurl).read()) loginauth = loginsoup.findAll('input',{'name':'authenticity_token'})[0]['value'] logindata = urllib.urlencode({"authenticity_token": loginauth, "email": email, "password": password, "commit": "Log%20In"}) cj = cookielib.CookieJar() opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cj)) opener.addheaders = [('User-Agent', desc)] login = opener.open(loginurl, logindata) dnsa = opener.open(thednsurl) dnssoupa = BeautifulSoup(dnsa.read()) dnsautha = dnssoupa.findAll('input',{'name':'authenticity_token'})[0]['value'] dnsdata = urllib.urlencode({"authenticity_token": dnsautha, "dns_record[value]": myip, "dns_record_ttl": "1", "commit": "Save"}) dns = opener.open(dnsurl, dnsdata) #print dns.read() soup = BeautifulSoup(dns.read()) dnsentries = soup.findAll('tr',{'align':'left'}) x = 0 y = 0 homenum = 0 for entry in dnsentries: x = x + 1 for newentry in entry.findAll('td',{'width':'200px'}): if newentry.string == "home": homenum = x - 1 homeentry = dnsentries[homenum] return homeentry.findAll('td',{'width':'300px'})[0].string def main(): address = setDNS(dnsurl) # Set more domains # address2 = setDNS(dnsurl2) if __name__ == "__main__": main() 
OMG dude! You did those YouTube tutorials that got me through my final project this year which earned me full marks! I love you.. &lt;3
Yep! Hey, congrats! Glad it helped you out, that was my goal!
&gt;So fans of static typing tells me i'm not a big fan of static typing to be honest, but this argument is one of the main arguments for using a statically typed language. personally i think the main argument against dynamically typed languages is also perhaps their strength, they are **expressive**, i.e. you can do a lot of stuff with very little code, but on the flipside that code tends to be *very hard to read*. this argument also holds for expressive languages which are statically typed, i.e. i would never use Scala in production, even though it's an excellent language. some dynamic languages are also very forgiving (Python is perhaps not the best example), but if you look at Perl for instance, it never halts with an error when an error has been made, it just keeps chugging along, making bugs extremely hard to find.. &gt;And for most of these 13 years, I have not had actual unittests for most of the code. :-) that's true for most of us
Challenge 2 doesn't have anything to do with Python. Also, your professor's English ain't too good: &gt; skilled in there professions. 
While I will admit I don't understand the difference at all, my original point was that coroutines were used in tornado.
Oh that was another thing I was going for. I'm still making progress on that front actually; I think it's acceptable now, but I'm still making it better.
Can you send me a screenshot of a full page and a tell me your browser, operating system, and any browser addons you might be using?
&gt; to highlight the difference between focused and non-focused. Not intuitive and inconsistent with the rest of reddit. Why do that? It's very awkward when copy pasting quotes in for instance. &gt; The stylized reddit icon underneath the python logo in the top left goes to mail reddit page inconsistent with the rest of reddit. Makes it awkward to use. &gt; This is better said as "you don't like the new arrows". They have been very well received in general. Correct. I do not like those arrows and I find them to look not nice at all. &gt; This header is only 47 pixels different in size from the typical header. Aside from it being unnecessarily big it also has terrible paddings and size relationships. This is just not good looking, I'm sorry. &gt; hover over it. The whole point of that bar is that you can quickly jump to something. By having to hover on it (which is a tiny stripe) to find something you remove the usefulness of this bar.
Here's the thing: many of us here write Python for a living, and could easily write these three programs in no time. They are basic programs, covered by most Python tutorials out there. However, presented like this I doubt any of us want to. On the other hand, if you were to take a first stab, and post your code for help I'm sure we ( and maybe /r/learnpython ) would be glad to give you pointers along the way. We just aren't going to write the whole thing for you. This is about you learning how to do these things, not about if we can do it (we can)
I use jekyll for my blog and I have a fabric script to publish a new post. from fabric.api import run, cd, env, local env.hosts = ['user@server'] def deploy(): local('git push') code_dir = '/var/www/blog' with cd(code_dir): run("git pull") run("/home/nigel/.rvm/gems/ruby-2.1.0/bin/jekyll build")
Adding &lt;script&gt; tags isn't modifying the html?
When using RES and you are not logged in the first comment overlaps with some RES nav links and is indented. https://imgur.com/6BPeGGg
Probably not. The basic syntax of RPython is a subset of standard Python, so most of the time an RPython program will work on Python. Check out rply on PyPI as an example of a library that does this. The thing is, RPython is a subset of Python, plus a number of it's own tools, which deal with the ability to do JIT optimisations. These tools aren't available on any other (afaik*) Python platforms because they're fundamentally part of the way RPython is able to make JITed interpreters like PyPy and HippyVM. They're essentially hooks that RPython can read and know that loops are going to occur. EDIT: I forgot the most important part, which is to urge you to go and try it out! There's not a lot of RPython documentation, and until it got a name and seperate identity it was mainly just 'PyPy', so it's hard to get into, but IIRC there's a fantastic article by a language designer about how he used RPython to create a JITing interpreter for his programming language that had significant improvements over his original C-based system. * I wouldn't be surprised to hear that there's an RPython compatibility module floating around, although I'm not sure what the point would be.
I don't know how to comment effectively on your first point. Every UX test I've done, and most of the things I've read, suggest that an overt visual cue about the activeness of an input box help people to figure out *where* they are posting things. If this doesn't help you, I'm sorry, but you are a statistical outlier. Your second point has been noted and tested. In the testing phase, 0% of the test users experienced trouble getting back to the reddit home page. Your third point is noted, but, again, you are an outlier here. Your fourth point is noted. Again, you are in the minority on this point. I did testing with the fifth point. The low-vision subjects familiar with reddit experienced no particular problems finding the things in their top bar. However, if you're legitimately having problems with it, and not just complaining, I will address this by making the top bar more opaque before hover.
the python logo is really low resoloution. Like on a x1024 monitor it looks bad.
&gt; So you're telling me that you actually ran an UX test against this design? I didn't do a full UX test. I did minimal testing with ~20 test subjects. I did moderate testing with a couple of low-vision individuals. I am not writing a report or sharing my raw data for your edification. &gt; I am sufficiently frustrated by this design here that I left a comment which I rarely ever do when subreddits change designs. Please install RES and remove the checkmark next to "use subreddit styles". I'm sorry you don't like this. You're probably going to have to get used to it because **hundreds** of subreddits are starting to use this base theme. * /r/google * /r/web_design * /r/documentaries * /r/Startups And more are starting every day.
Sorry, I think that's just what the python logo looks like. Check out python.org.
fair point about IO, especially when it comes to stdin/stdout. Though Python3 introduced the sys.stdout.buffer/sys.stdin.buffer interfaces which should be used for binary data.
So it's no longer "web scale"..? ;)
Voting arrows not visible for me either. 
Unfortunately I really don't like the theme. It makes the links really difficult to read and it takes the focus of them
This is not a misrepresentation. This is what you are saying. You are saying that you can't profile applications, because the bottleneck moves around unpredictably. This is not true. &gt; What I've said is that it's impossible to profile software if you can't run it. I can profile my Python 2.7 application because it exists here and now and I can run it in a Python 2.7 profiler under different scenarios. And that's all you need to do. Which I have explained multiple times. Then you can find out where the bottleneck(s) are. &gt; I can't profile that same application in Python 3, because I haven't ported it yet, likewise I can't profile it in Java unless I port it to Java. You don't need to, you only need to profile the bottleneck, and that is worst case, complex scenario. Which you have been told for 5 days now. But you still don't listen. &gt; loads of guesswork. No guesswork. &gt; I'm sure you're smarter than your replies seem to imply Probably not. &gt; and you can understand what I'm saying. Yes, and I also can explain to you why you are wrong. You seem to have trouble understanding the explanation, as we are STILL REPEATING THE SAME EXPLANATION. Instead you come with bad excuses, and I have to explain to you why your bad excuses are bad, and then you drop that excuse, or claim that you never said it (see above). And we'll continue like this as long as you pull bad excuses out of a hat. Because the truth remains, and that is that it is perfectly possible to profile your Python 2 application, find the bottlenecks and figure out how they perform in Python 3, without porting the whole application. You insist that it is not possible, and you are still wrong, 5 days later. When are you gonna give up on the FUD?
No. The other way around actually.
I always have two browser windows open split between Netflix and reddit. It really bugs me when the CSS shrinks comments down to tiny because the sidebar takes up so much rigid space!
tl;dr: 1 process per core, as many thread as you want until it becomes counter productive. When in doubt, make threads equal to the number of hyperthread/thread your processor supports. Threads are light, they start very fast, use less resources, the processor can switch between threads cheaply, but they are all stuck on the one core where there parent process is running. So even with a 32 core server, if you run 1000 threads, they will all share the same core. Processes are heavy, but completely independant of each other, so they can be running on different cores (the OS scheduler will move them around to optimize the work). But process are slow to start, use more resources, and it takes a lot of time for the OS to switch between them. A finely tune process should be able to consume an entire core, even if it is by spawning a lot of threads, so it is often better to stick to one process per core to prevent processes competing for the same core, and ending up slowing everything down. As usual with tuning, every workload is different, these are guidelines, don't take them religiously, start with these recomendations, adjust and meaure.
Heres the SVG https://www.python.org/static/community_logos/python-logo-generic.svg
Oh that's nice ! 
It's not web based, and therefore so far I am loving Pyro4. It seems like a very simple solution for an ssh server.
Look at this library: http://doc.scrapy.org/en/latest/
We would be slicing an array of data that sits on the server. Then download it to the users computer and do the real processing there. Just with the files being so large, I didn't know if what I was thinking was the most efficient way. I am finding it weird to do any webservice stuff, since none of this will be on the internet, only on a private ssh server. We are just going to setup a user that has access to read the data out. Creating a web framework or whatever seems like a lot of backend work that isn't necessary.
Yeah, ipython notebook is something to mimic, not python.org. The font and the font spacing on this theme are too everything all at once (thin, thick, bunched, spread out).
I highly doubt that the OS will not move threads to different cores, unless uwsgi uses something like `sched_setaffinity` by default to restrict them to a single cpu. We're talking about OS level threads here, not "green" threads.
This looks just like what I wanted. Thanks.
In the right sidebar there is a checkbox "use subreddit style". It disables the styling for this subreddit only. It may or may not be a RES feature.
I don't see that -- screenshot?
Could you expand on that last statement (about C++ memory managemente vs. the GC), or provide a link that does. I'm not saying I don't believe you, I'd just like to get an idea of what I'd be up against if I went that route.
It's a RES thing. 
Just block the stylesheet with AdBlock. And yes, it's unreadable.
Take this code for example import sys from PyQt4 import QtGui, QtCore class Main(QtGui.QPushButton): def __init__(self, parent=None): QtGui.QPushButton.__init__(self, parent) self._counter = 0 self.clicked.connect(self.doThing) def doThing(self, *args): if self._counter == 0: widget = QtGui.QWidget() self._label = QtGui.QLabel("hello", widget) self._label.show() elif self._counter == 1: self._label.setText("whatever") self._counter += 1 if __name__ == "__main__": app = QtGui.QApplication(sys.argv) widget = Main() widget.show() sys.exit(app.exec_()) Can you see the problem? 
Unchecked - `allow subreddits to show me custom styles.` I prefer default reddit theme, which has way better typography and readability than this all blue background.
No, sorry, I don't know OpenGL.
I think Amazon actually have an API for book ranking. https://pypi.python.org/pypi/python-amazon-product-api/ If you scrape the site btw beware they serve up slightly different pages depending on User Agent.
I don't want to be the negative guy here but instagram-like filters is not a good example of quality photography. Just because it's popular doesn't mean it's any good. Now-days many photographers use instagram-like filters because it saves lots of time on post-processing: no need to fix up all the pimples and defects in the subject's face when there's little contrast - no one is going to notice the difference. Maybe the design looks fine on your screen - but on a properly calibrated screen that's balanced against ambient light it looks washed out and puts strain on the eye.
Fairly sure it isn't.
...Python
Is a program on topic in here just because it's written in Python?
I have just made an RES note for /u/mopmar... "retarded"
Yes, it's a big step back for readability
I didn't even know that option was hiding down there! Thanks for that. Looks better now
I guess if the point of the article and subsequent discussion is of the technology and how it uses python (in a broad manner) then it is suitable for this subreddit.
You don't need to add script tags in order to add JavaScript.
 &gt;1. It is a single platform language. Does it run on Windows? There's an old, unmaintained port on Linux, but nobody uses that. So in reality it is indeed proprietary and constrained to the Apple ecosystem. The fact that it is outmoded does not imply that Objective C is proprietary. Objective C wasn't even adopted by Apple, it was adopted by Next, it came along for,the ride whenApple bought Next. Given that Next did not develop Objective C, they just where one of the few users to take it seriously. &gt;2. Assembly isn't tied to one OS platform, and knowing assembly is useful to understand what your high level code is doing "under the hood"; it's far less useful in day-to-day programming except in certain niche fields. Neither is Objective C tied to one platform. It is currently only used widely by one major company. &gt;3. We have absolutely zero indication that Apple tends to spread Swift around. We have seen Apple systematically tearing GPL code out of OS X and replacing it with BSD-licensed code though. There's zero sign Apple is going to pivot again on open source. Apple has been tearing GPL code out of OS/X because it is the right thing to do. Those responsible for the latest version of GPL have apparently gone off the deep end, even Linus doesn't like GPL 3. That does not imply that Apple has given up on open source. In fact recent behavior, with the release of the 64 bit ARM materials to the LLVM project indicates that they are indeed strongly supporting open source till this day. &gt;4. I don't know if that's a threat or a challenge. .?? &gt;5. Much effort was made to make it worth with the existing body of Objective-C code, and Objective-C is built on top of C. .?? I'm not sure what your point here is either? Languages are built upon the past, to be able to innovate though you need to be free to think in new ways and to combine old ideas in new ways. &gt;6. Then why does Java run on toasters? Gee I thought Cylons had a more advanced VM! . Sorry couldn't resist that one. Given that why does BASIC, Python and Forth still run on Microcontrollers? Sometimes good enough is well good enough. That doesn't mean you should automatically dismiss new ideas. 
Because at each WWDC new tech is delivered that the rest of the world tries to copy. 
Python has an excellent community, I know because I've used it to solve real problems. However how did this community get to the point it is today and how did the standard library develop to the point it is today? I can assure you the goodness that is Python didn't happen instantly. In this context though we have a new language that has some capability similar to Python that is also a compiled language. A language that apparently produces pretty fast code, do you not think that Python programmers might be interested. This especially since there have been numerous attempts to speed up or even compile Python with various measures of success. Honestly it is hard not to be interested in Swift as a technology. Maybe Apple blows the chance to see the language adopted widely, that has yet to play out. However I'm not about to dismiss it completely out of some fantasy image some around here have of Apple. Instead I will take the time to see if it is a better solution than Python for me, maybe even a better solution that C++. More so I will see if Apple copies former patterns and tries to standardize the tech for the community as they have in the past like they did with OpenCL. 
 &gt;A couple of issues; Swift is a compiled language so at some level there is static typing even if it is hidden behind magic (not a bad thing, just an observation). It actually looks like an objective C clone with a lot of syntactic sugar, so it will probably make development a bit faster and it will maintain perfect compatibility with existing Apple toolchains. Well I've been reading the documents and frankly it isn't an Objective C clone per say. It is however a language designed to leverage existing Apple infrastructure which is pretty rational. My Initial impression is that it will make development a lot faster but then again I never did like Objective C. &gt;I understand the comparisons they made; it is likely that the language has an internal (highly optimized) sort method and they were comparing it to a naive implementation in ObjC and to Python (cause why not use a scripting language to look good). I'm not a mind reader so I can't say what their intentions where but I suspect there was a deeper reason behind the use of Python in the comparison. That might be the similarities in the development ease and readability of the code. Yeah Swifts syntax is a bit different requiring some adjustment but it provides an expressiveness similar to Python. It appears that what they are trying to say is this: here is a language as nice as Python but compiled and much faster. &gt;Anyways, the the Python comparison wasn't even close to fair but it made some nice marketing slides. It was intended to be "fair" from what I can see. It was more of a suggestion that here is an alternative to Python that is very fast relative. Let's face it Python can be very slow at times even in the hands of seasoned developers. &gt;edit: yes, static typed, not strong typed. 
My monitor is a) high quality and b) properly calibrated. Moreover, this was tested on &gt;20 screens before implemenation. On every screen and at various resolutions, the contrast between the black (hex: #161616) and white (hex: #ffffff) is superior to the readability of the average book. If you are talking about a different text than the one I'm talking about (I'm talking about the colour of the text of comments), then you have a problem with your calibration. The key difference is nearly 92%, and while hex doesn't convert with 100% accuracy to CMYK, that level of contrast is more than sufficient to insure readability at just about every level. If 92% difference isn't sufficient for you, there's a problem with your monitor.
Makes you wonder why it took so long for computing languages to support human readable numbers. 
I wasn't aware this existed. I will ~~defiantly~~ definitely try this first now. It's probably still worth my while to learn the other though, to use on sites where APIs aren't available. Thanks. 
 &gt;Wasn't there a PyCon talk recently entitled "Android: The Platform That Python Forgot"? If there was the title should have been: "Android: The Platform Python Doesn't Want to be Associated With"! 
Meh. I notice on the website it says "Commercial and OpenSource". And surprise surprise, I came across https://github.com/hippyvm/hippyvm/issues/7 which shows they are treating opensource as a second-class citizen
Your link is dead! I'd love to look at what you posted!
You want a collection of ships - try using a list of ships: shiplist = [Ship(stuff) for _ in range(difficulty)] You would probably need a list of "stuff" so you could then write: shiplist = [Ship(stuff[i]) for i in range(difficulty)] 
Care to post an example xlsx file? So we can step through it.
There are lots on Rosetta Code: http://rosettacode.org/wiki/Category:Python
Presumably your Excel spreadsheet is using a text format for the first row and number format for the second row. On the first row is read in as a string and when you explicitly cast it as a string, it comes back exactly as you got it. On the second row, the value is a number, you cast it as a string, and it comes back as something that looks a little different. That said, I don't know how casting 0000000.0 as a string could give back '0000000.0', but that may be because xlrd uses some custom object to hold numbers rather than a normal `float`. Check your Excel sheet and make sure the data is consistent line-to-line.
Tell you what? This is the ONE feature of Python that I never, ever see discussed. I see people make lists of the all the neat features of Python and I never see this mentioned :P I think it looks ugly and makes functions harder to read, and I think it might be superfluous because you should put the input and output types on the description of a function. Finally, it can be used for some sort of static typing which is (in most scenarios) unpythonic. However, I think it has the ability to make interactive development easier, and I'm sure there also are other use cases like the one you described above. I'm glad I could help!
Is there any plan for a higher-level SDK? (or OS X support, for that matter?)
Thanks for the note, sorry about that. This one should work: http://nbviewer.ipython.org/github/rasbt/pattern_classification/blob/master/parameter_estimation_techniques/max_likelihood_est_distributions.ipynb?create=1 (Maybe I have moved some stuff around in the github repo, that sorry). If you are interested in more Pattern Classification related articles, I collect them here: https://github.com/rasbt/pattern_classification
Thanks, I really appreciate it! Initially, I put it together for myself as reference, but I thought that might be very useful to other people, too :)
I'm probably going to hold off on a higher-level SDK until they release a stable SDK. But yes, that would be ideal. I've been wanting to get things working on OSX for a while now, but don't have a Mac, so haven't been able to yet, unfortunately. I'd certainly accept pull requests, though. It should be fairly straightforward - build the shared library, generate the ctypesgen bindings, add a few lines in the import wrapper, and run the test.
I can't post the spreadsheet because it contains personal information but I'll post an example of one in an hour or so.
I usually don't comment on spelling mistakes, but imagining you "defiantly" writing code made me smile.
Looks like HTTPS-Everywhere is causing the problem. When I disable reddit.com, the pictures start showing up again.
https://drive.google.com/file/d/0BwLOByV_BHqtVVhxZUFNZDRheGc/edit?usp=sharing There's an example.. I didn't change any of the formatting of the spreadsheet but I had to save it as .xls instead of .xlsx
The difference would be the Tesla has Musk, who does Python have?
uh BDFL ?
well it was just a language until some years later
Putting javascript in the page is still messing with the html since in the end it gets to the browser. Javascript has the ability to modify html in the page.
Lol, RDF.
Regex for HTML, nice one! Let's use BS~~2~~4
If you want to deploy after every commit, use git hooks on the server-side. If you want to reduce the amount of release packages, look into semantic versioning.
Under linux, you'll need to do a few more things as well: - turn off canonical mode (this is what causes it to process things like Control-H for backspace, and does the buffering) - turn off echo (optional) - set it up to deliver a character as soon as one character is received You can see some code for doing this here: https://github.com/dhylands/usb-ser-mon/blob/master/usb-ser-mon.py#L192 (lines 192 thru 203) You can then use poll or select to detect when at least one character is available. I happened to use poll: https://github.com/dhylands/usb-ser-mon/blob/master/usb-ser-mon.py#L97 usb-ser-mon.py is basically a really simple terminal emulator program which accepts data from stdin and sends it out on a serial port and whatever it gets on the serial port it sends to stdout. It also has logic to detect when the serial port "goes away" and "comes back" perhaps due to the device being a USB device that was unplugged or rebooted. usb-ser-mon.py is currently linux-only.
funny I was just today about to use some regex in python for the first time... though first I planned to dig deeper in to beautifulsoup stuff, maybe getting my shit that way
I cannot up-vote or downovte posts now on Firefox, 29.0.1 mac or Linux, i'll submit screenshots shortly.
http://imgur.com/T6sGhgM http://imgur.com/EiXkyNP
i used this pdf to test content indexing via solr. THX!!!! :) 
Sure http://imgur.com/tVKi9qp http://imgur.com/Xh63I9g
You are not subscribed to /r/Python. Right now controls are only available to subscribers.
Ah that fixed it, I use to be able to up-vote posts without being subscribed 
The feature preventing that may be short lived.
I have changed the very top bar.
Just a little Python wrapper, for the [Doomworld idgames archive API](http://www.doomworld.com/idgames/api/), that I threw together over the last few days. This was my first attempt at creating a proper Python package, and it seemed to work for me. I hope it actually does for others though. Also, I am self taught in Python (been at it less than a year), so my code may be a bit smelly. I apologize to any seasoned programmers, with real educations in programming, that are probably cringing at my code. try to cut me some slack though. If you see something to be improved, improve it. It's all licensed with the MIT license, so do whatever the hell you want with the source (all I ask for is a bit of credit, of course). Or if it's not even worth salvaging, my apologies. I tried, and it works fine for my own purposes.
Hey if you go to mess with beautifulsoup I suggest you check out this stackoverflow question's answer. http://stackoverflow.com/questions/19861489/use-beautifulsoup-to-iterate-over-xml-to-pull-specific-tags-and-store-in-variabl I just got into BS and I was having issues figuring out how to iterate over it and that guys practical example of pulling the data to iterate over in a dict gave me a much better idea of how to do things than the official BS documentation. And this one is really good too showing you how to traverse into nested brackets for the exact info you want. http://stackoverflow.com/questions/10309550/python-beautifulsoup-iterate-over-table I'm new to Python and BS in general but maybe that'll be enlightening for you too :)
Using regex to parse HTML? [Are you trying to invoke the power of The Dark One?](http://stackoverflow.com/questions/1732348/regex-match-open-tags-except-xhtml-self-contained-tags).
cheers man, will look in to that
As pretty much always, if folks have any questions about PyPy, I'm around.
Take a look at [PRAW](http://praw.readthedocs.org/en/latest/pages/writing_a_bot.html)
What was your motivation for working on this project and how do you figure out where you want to take PyPy next? I am looking forward to greater 3.x support also!
Have a look at the MWS API, which you can interface with using the Boto library.
Not sure what that is, but glad I could be of service :)