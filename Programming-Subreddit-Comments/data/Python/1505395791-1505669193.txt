https://www.influxdata.com/ is another one that does metrics with a very easy to use python API
yeah, spamming, that's going to get you goodwill and subscribers in no time
/r/ShamelessPlug ----------&gt;
**Here's a sneak peek of /r/shamelessplug using the [top posts](https://np.reddit.com/r/shamelessplug/top/?sort=top&amp;t=year) of the year!** \#1: [r/ThePaperBay - Featuring "academic mercenaries," weird college news, and a lot of pirate references](https://np.reddit.com/r/ThePaperBay/) | [0 comments](https://np.reddit.com/r/shamelessplug/comments/6ighou/rthepaperbay_featuring_academic_mercenaries_weird/) \#2: [Here is another shamelessplug (TM) of the greatest reddit essay writing service. Thanks for your support, fellow Internet memers.](https://www.prescottpapers.com/reddit.php?s=reddit4) | [1 comment](https://np.reddit.com/r/shamelessplug/comments/5yqmop/here_is_another_shamelessplug_tm_of_the_greatest/) \#3: [How to Get Around Plagiarism-Checking Software - A Blog Post From My Personal/Professional Website](https://www.prescottpapers.com/blog/cheating/how-to-cheat-turnitin.php) | [0 comments](https://np.reddit.com/r/shamelessplug/comments/5ak4p0/how_to_get_around_plagiarismchecking_software_a/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/6l7i0m/blacklist/)
What do you mean by inequation? You looking for the not equal operator? !=
I've tinkered with some speech recognition libraries and packages like dragonfly and CMU Sphinx but I'm not familiar with the lower level functions that are in SpeechPy. In general, what are the necessary steps to get speech recognition functioning with SpeechPy?
Heads up: you can also just do a data dump using built in functionality. 
Thank you so much. So Python is the "umbrella" language to combine other libraries/languages. Are there other languages for deep learning? 
Thanks. Are there other languages for deep learning? 
You can use any language for it, really. There's nothing special about any of the languages used in deep learning.
off the cuff you could (not using pandas) read using f.readlines() iterate over rows for i, line in enumerate(content): use splitLine = line.split(" ") which will return a list of the contents of a row, divided up by where the spaces are, then write to the new file every other element for value in splitLine[1::2]: f_out.write("{},".format(value)) I'm sure there's a far more elegant way to do this with pandas, but this will brute force your way to it. e: [0::2] to [1::2] since the first value you'd want would be the number, not the state
I prefer to use `python setup.py develop` to get a develompent editable installation. 
I prefer to use `python setup.py develop` to get a develompent editable installation. 
I might have screwed up the term for this as English is a foreign language for me. What I meant is that I would like to make a program that can solve a mathematical thing like: x*1.35&gt;2.70
thanks will have a look :-)
yeah that's something I could add in over time once I have mastered a way to do the dates etc
hey thanks. Yeah once I have mastered the dates ill add loads to it
thanks will look into it
cheers. not heard of that module before so will be interesting to read
[Rosetta code](http://rosettacode.org/) contains a lot of small programs written in multiple languages which could be useful if you're familiar with another language.
Oh shit, my bad. 
Please clarify?
Good stuff. Not sure why inclusiveness in tech means splashing everything in emoji's though; to set the right impression, but maybe that is the point. 
That's not a programming friendly problem. What other forms are there? You can solve it by hand based on where x, the values and what the sign is. Then just code the formula. For more complicated equations, where a variable is on both sides and inside say a log that you can't get rid of, you can use Newton's method. You also might just be after a simplistic symbolic math library in which case use sympy. I say simplistic because there are a lot of solvable problems sympy just can't do, but when it works, it's fine. 
Many. javascript, C++ and Haskell have bindings via tensorflow iirc, and I think Julia has . Google it 
Yeah, I fooled around with this thing on paper and solved it that way. Then just fed the thing in a more Python-friendly way. Worked just fine
You should try /r/learnpython. Anyway, you can create a function that tests if the value is a string and remove the values. Something like this: import pandas as pd df = pd.read_csv('file.csv', delim_whitespace=True) def startswithnumber(string): test = string[0].isdigit() return test print(startswithnumber('Ohio')) print(startswithnumber('36.4')) # it's probably not 0, it's the column name print(df[0].apply(startswithnumber) filtered = df[df[0].apply(startswithnumber)] print(filtered) Note that I think that pandas won't automatically convert '36.4', if it does the code won't run.
you want to define a function that returns a boolean. depending on how flexible of a condition you want to write, something like this would work: def is_greater_than(x): return x*1.35 &gt; 2.7 you could pass another argument to the function to create whatever comparison you like def is_greater_than(x, y): return x*1.35 &gt; y you could pass the equation as str and then solve with eval x = "%f * 1.35 - 0.98 ** 2" def is_greater_than(x, y, equation): calc = float(eval(equation % x)) return calc &gt; y but that might not be the easiest to understand. if you explain your problem more I could help too :)
The `setup.py` looks correct to me, and I've compared it to the `setup.py` provided by Kenneth Reitz. I have the `packages` entry set to `find_packages()`. I do have several modules and subpackages like so: &lt;package name&gt; __init__.py compute __init__.py &lt;modules&gt; filter __init__.py &lt;modules&gt; core.py
Programs should be unitless where possible. If I just use kg-m-s or Mg-mm-s or slug-ft-s or slinch-in-s I'm good. Ok, I really want lbf-ft-s, so I can add a 1/g factor to convert weight to mass. Assuming you are not using things like astronomical units (you don't want to convert to meters in the case), define a system where you indicate force in pounds, time in seconds, length in inches, pressure in psi, modulus of elasticity and stress in ksi (1 ksi = 1000 psi), altitude in feet, and equivalent airspeed in knots. Then just convert to consistent units when data goes in and convert back when it comes out 
Yes, I'm genuinely interested in a more detailed explamation.
Syntax error at cThread.daemon = True why?
That is pretty normal in scientific computing. You want "random but reproducible", so unless you explicitly set your seed you should expect scientific computing applications to repeatedly return the same result. What you were probably thinking was that by setting your seed before spawning your threads that a single RNG would be shared across threads and you would get different results from each thread. There are two reasons that is undesirable: 1. It would kill performance. 2. It would no longer be reproducible. Imagine and RNG that generates 1,5,8,3,2,9,6,1,2,1.. being used by two threads. Depending on how the OS schedules those threads the individual threads would see different subsets of that RNG. So on the first run they alternate and thread 1 goes first seeing: 1,8,2,6,2,... but on the second run thread 1 goes second and sees: 5,3,9,1,1,... and on a third run they do something else and thread 1 see: 5,8,9,1,2...
That is pretty normal in scientific computing. You want "random but reproducible", so unless you explicitly set your seed you should expect scientific computing applications to repeatedly return the same result. What you were probably thinking was that by setting your seed before spawning your threads that a single RNG would be shared across threads and you would get different results from each thread. There are two reasons that is undesirable: 1. It would kill performance. 2. It would no longer be reproducible. Imagine and RNG that generates 1,5,8,3,2,9,6,1,2,1.. being used by two threads. Depending on how the OS schedules those threads the individual threads would see different subsets of that RNG. So on the first run they alternate and thread 1 goes first seeing: 1,8,2,6,2,... but on the second run thread 1 goes second and sees: 5,3,9,1,1,... and on a third run they do something else and thread 1 see: 5,8,9,1,2... Within the intended usage domain numpy is doing "the right thing." The semantics of the more general purpose python RNG may be different, and that too may be "the right thing."
 I am only looking for scripts which perform simple but useful tasks such as reverse a string, count vowels, count words in a string etc. #Reverse a string reverse_str = lambda x: x[::-1] #Count vowels in str num_vowels = lambda x: sum(1 for c in x if c in "aeiou") #Count words in a str num_words = lambda x: len(x.split()) 
i have a wrapper i've been working on that essentially does this but was wondering if a tool already exists that can do this in one line 
Don't gotta buy. It just has a nag like every 10th save or something asking you to buy.
==?
If you just download other peoples code without knowing what version or dependencies are needed you are going to run into problems and get frustrated very easily. I suggest you go sign up for Kahn Acadamy and go through a couple courses there. After that just think of problems that are interesting to YOU, first start off easy, maybe figure out how to generate a random list of strings then reverse them. On that same list insert some other strings in the middle, mix and match. Do some data analysis with pandas and numpy, download financial data sets, or crypto data sets and start plotting, finding out if two data sets are correlated, write a qualitative trading script. If you are interested in web development, follow the Django tutorial on their website and get a couple we apps going. Basically what I am trying to say is telling yourself "I want to learn python" is useless, its like sitting down with just a hammer and nails and saying "I want to build something!". What do you want to build? How do you want to build it? Python is a tool/skill and the best way to master a tool/skill is to use in consistently over a long period of time. So download Sublime Text 3, spin up a virtual environment and start hammering away at that keyboard.
This ^. One of these days I will pony up, I promise.
VS Code doesnâ€™t have the same line editing features Iâ€™ve come to expect and use regularly, like multi-line select, etc.
/r/learnpython
Sounds like a good approach. It would probably be fastest to simply sum all the pixels and compare to a precalculated threshold that takes into account the letters on the screen, the image size, etc. You may also want to look for several frames over a minute before triggering, so that a car's headlights or something don't set it off. OpenCV is a good choice, and it will return a numpy array which has a nice fast `sum()` method. HDD's are very slow; I'd stay away from making or reading actual files if at all possible. 
General recommendation is to work on personal projects/develop an open source portfolio. Actual "work" would be difficult, since there are many, many qualified, experienced programmers available for hire on the cheap. You might be able to offer services for free. Seek out local organizations/businesses that wouldn't be likely to look online for freelancers (old, family owned businesses).
[removed]
Software engineering? I see history, project management, and self-improvement books listed. Nothing about software engineering. So, no, nothing here software engineers *must* read.
Wading in too deep is a big concern of mine, especially with a grade riding on the project. A Planetary N body simulator looks pretty cool though! That would cross over with my physics class as well :)
I just came here from r/programming
Go to codecademy.com and take the python introduction course. Then python cookbook can springboard you forward, but you'll probably have to go through the book a couple times to really understand it, at least I did. 
If I had a guess it matches sounds to sound waves and then matches those to phonemes and tried to match those into words. 
Are you advertising or looking for feedback? 
Yep, I remember when I was bitten by this the first time while starting to do scientific programming in Matlab at the time. After the initial confusion is over you will start to love those things. I created and saved the random seeds of every simulation run I was doing and saved the whole state every couple minutes. This helped tremendously to reproduce a run or restart it from an arbitrary checkpoint while being sure the run would be exactly the same as before. When you get your first bug that only happens under rare circumstances and heavily depends on the generated random numbers, you will like the idea of having the option to reproduce pseudorandom sequences.
You don't have a close peren for your cThread declaration. Should be args=(c,a))
Thanks for your thoughtful comment. It makes a lot of sense. It would be fantastic if you suggest me any resource ( any book or website ) where there will be a problem set from simple to complex. I mean as a beginner I would like to solve easy problems first so that I can gain enough confidence. As time goes I wish to solve the more complex problems. Can you suggest any such resource? Cheers ! 
So I setup the API correct I think, but I am not sure how to get the 'True'/'False' that I need. It might be too simple I know, but maybe this helps with what I need: https://imgur.com/a/gGOmH
For me, it's mildly triggering that csv reader in stdlib does not have an option to call strip() to deal with "improper" csv format like a space before a comma e.g. (1 , 2 , 3). I suppose it's a simple patch. Maybe I should get off my (virtual) ass and do it?
You're missing the point. That means you're probably a great candidate for reading some of these books.
&gt; Python on Chrome OS? It's basically impossible. Python is actually already installed on Chome OS, but access to the terminal is completely locked. (Not that I blame them; it's completely contradictory to what Chrome OS was designed to do.) The only thing you can do is do all your programming on a website like repl.it. Or maybe use ssh to get to another computer that has python and some disk space. Or you can wipe Chrome OS and install a proper Linux. --- If you have more questions like this it's better to post them on /r/learnpython. Be sure to [format your code for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) or use a site like pastebin. Also, include which version of python and what OS you are using. 
Okay thanks for the heads up. Will do.
thanks! Do you have any idea of what OpenCV function I could use to extract a frame at x seconds from a video?
Because it's *that* good.
Not sure when you used it last time, but it does support them.
OK, I'll bite; what's the point?
[Looks like this should do it.](https://stackoverflow.com/questions/33650974/opencv-python-read-specific-frame-using-videocapture). Edit: you could probably ignore the frame math and just use 0,0.25,0.5,0.75, and 1. Or some other decimals to get evenly spread frames.
for opencv resources, I'd start with this site: http://www.pyimagesearch.com/.
Depending on the OS you're using you may have: 1. a system default python installed out of the box which is used for package managers like yum 2. separate installs for python2 and 3 You will want to leave the system default version of python alone, unless you want to break core functions of the OS. Then it comes down to installing your desired version(s) of python and the supporting tools in a way that keeps them distinct yet easily accessible. Again the steps to do this will depend on your OS. Once you have completed the above, it's a simple matter of going into the PyCharm preferences and setting up a project interpreter (Prefs &gt; Project: python &gt; Project Interpreter). 
I agree with you. I wondered exactly this for the `ClientResponse` object in aiohttp which doesn't appear to [need](https://github.com/aio-libs/aiohttp/blob/master/aiohttp/client_reqrep.py#L745) an asynchronous context manager, however it once [did](https://github.com/aio-libs/aiohttp/commit/81611cdd586828179fe4ba64f56ef0fe37491b8e) so this keeps compatibility. 
I think the intent may be: &gt;11 Books All Software Engineers Must Read ...To expand their skillset and widen their horizons, improving their value outside of engineering. So yes, the sensationalized headline is obvious in its attempt to disguise affiliate marketing as a niche article on a profession, but you are being awfully pedantic about it.
I've been meaning to try VS Code. What makes it better than Atom?
It must have something to do with Python not being "purely functional" like Haskell. Or maybe it has something to do with /u/tdammers "holier than thou" personality, one that dictated they must be a Haskell programmer in the first place; and demands they post condescending comments in the python subreddit.
&gt; but you are being awfully pedantic about it. For being against something that is patently against the [rules](https://www.reddithelp.com/en/categories/rules-reporting/account-and-community-restrictions/what-constitutes-spam-am-i-spammer), a nuisance, and an ever-increasing problem within the community?
Perhaps your first comment could have pointed that out.
This looks interesting. I'm not sure how I feel about this though. On the one hand, there have been times where I know I will have a need for a switch statement based on a few different choices. On the other hand, the _Pythonic way_ has not been particularly limiting to me in my work. I guess it's more a case of I've adapted to the limitations of the language but can see the value this might potentially bring to users who want something other than a dictionary.
This is against the terms most likely and by that reason possible breaking the law. But, this can easily be done, have you installed gentoo? 
You might be right but I know that there is a lot of commercial sneaker bots on the market and they are legal. Nope, I have not, as I said , I am total noob , although I would love to educate myself in this field given some directions.
Hi, I'm with you. The thing that pushed me into releasing this is realizing how much more clear the intent is for complex cases. Have a look at this example in the repo: https://github.com/mikeckennedy/python-switch#why-not-just-raw-dict
OpenID requires a browser, which I don't think your setup is using. The example I showed you would redirect the url to a google login webpage, after the users log in it would return an access token with the information requested (email, name, etc.) Doing it all in terminal is possible, since you have email and password, but I think you might run into some edge cases. You'd probably need to use the requests module and send a post request manually to the google login website. 
because schools.
You could use Reddit's JSON interface. You get the "Top from 24 hours" with https://www.reddit.com/top/.json?sort=top&amp;t=day
Gotcha. I think I saw something yesterday about a manual post to Google so I may try that next.
What the other person said is wrong. Check out [crouton](https://github.com/dnschneid/crouton) which gives you a complete linux install inside ChromeOS. The only drawback is you have to enable the developer mode which is less secure.
Do you have this on github? I'd be interested in hacking together, if you'd like.
You seem to really like `lambda`. I think it's ugly. Why don't you just pass along any extra arguments to the function: s.case('b', process_with_data, val, num, 'other values still') Or accept a tuple and / or dictionary (a la threading.Thread): s.case('b', process_with_data, args=(val, num, 'other values still')) 
Yeah, I don't know, you really need Gentoo to get this done. /u/FAT32- is right about that. Do that and come back and I'm sure someone here will guide you some more. 
&gt; reading case(range(1,5)) seems like it should include 1, 2, 3, 4, 5 No. Absolutely not. 
https://pypi.python.org/pypi/geopy should do the job. 
I do like the ability to match a set of different values to one branch of logic. I don't know of a nice way to handle this situation in Python.... 
Nothing new but I found this the other day and found it interesting https://julien.danjou.info/blog/python-logging-easy-with-daiquiri 
If I've counted correctly it's the 13th Python switch/case statement that I've come across. Fingers crossed that it's not unlucky for some :-)
This is my preferred way of writing switch like statements in python: while True: action = get_action(action) result = { True : unknown_command, action in ['c', 'a']: create_account, action in ['l']: log_into_account, action in ['r']: register_cage, action in ['u']: update_availability, action in ['v', 'b']: view_bookings, action in ['x']: exit_app, action in range(1,6): lambda: set_level(action), action == '': None }[True]()
Agreed. I changed it this morning to be a proper range and added a closed_range option.
I mean this is basically an big if/else statement too. Perhaps this is a bit more readable for some but I don't think an if else statement is too unreasonable.
I don't particularly like lambdas. But to show a bunch of different methods in executable code would make it super long and miss the point. Just trying to keep it tight.
That's kind of the point of this project :)
Ha! It's an idea. I'm not bothered whether it succeeds or fails. Was just sharing a concept. Maybe people will like it.
That is interesting. Nice work. But it will crash if two cases match (DuplicateKeyError) 
I don't have anything to add except to remind you that after you've implemented whatever method you chose remember to do some IRL testing with covering and flashlight saturating the cameras to confirm that your code acts as intended. Also expect some false positives if your cameras are in a location that gets dark at night or very bright during day time.
It will execute the last condition that equates to True.
Can't you just use excels data to columns ability and split over the space and then delete the columns with the data you don't want? Or do you have to do this repetitively/autonomously?
thanks! I do have already some sample footage with a black screen and I will try to cover some camera as well as use flashlights
thanks!
thanks!
It does the feature extraction so you don't have to figure it out yourself.
Ah you're right. Kind of the opposite of traditional switch / case (first executed) but doesn't crash.
I see, I still had that in the readme. Took it out.
Same as any non-python game: figure out the data structure that the game uses and emulate it. --- If you have more questions like this it's better to post them on /r/learnpython. Be sure to [format your code for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) or use a site like pastebin. Also, include which version of python and what OS you are using. 
Also, lots of articles from author David Mertz here http://gnosis.cx/publish/tech_index_cp.html
How do I write comprehensible English sentences?
When the dictionary is being created it will just replace the last True or False key with the newer one and what is left is just one True and/or one False key in the dictionary. If you set a key to True at the beginning that is like the default case. You will get an error if there isn't a True condition.
Ohhhhhh. thax. how hack normal game?
Another arrow in the quiver!
You should never `exec` untrusted code. That code could do *anything*, and you're just letting it run on your machine? Ideally you'd use a library that parses javascript into an AST which you can then walk. A quick google search found [this](https://stackoverflow.com/questions/390992/javascript-parser-in-python#25112096) StackOverflow answer.
Just how difficult would this be? This sounds like it could be a lot of work. Pathfinding would be really fun though. Maybe pathfinding + object recognition to make a robot that can find something in a maze? I've never worked with a raspi before though, so maybe the learning curve will be too steep.
It's pretty cool. I already learned something about dictionaries from your example. d = {True: 1, True, 2} will crash but d = {'a' in ['a']: 1, 'a' in ['a']: 2} is more like adding stuff sequentially, dynamically. 
I just told you: figure out the data structure that the game uses and emulate it. How to figure that out depends a lot on the game, but I suppose you could start with a hex editor like Bless. 
It crashes because you have a comma instead of a colon. 
&gt; How I write English sentence can read?
no funny.
Ugh, you're right. I must be misremembering it from MongoDB stuff I was going with dictionaries or something: http://api.mongodb.com/python/current/api/pymongo/errors.html 
deleted ^^^^^^^^^^^^^^^^0.8001 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/72982)
Uhmm, good question. I'd try this: https://giphy.com/embed/mwOein9vVjBLO
woa. Wat softwares?
I'm not sure quite what you mean, would you mind expanding? (still new to most of this) Are you referring to a specific part of my script or just the fact that it's using execjs in general? EDIT: replaced execjs with node_vm2 to allow safe execution of the javascript
The latter (using execjs at all). It's *possible* to do this kind of thing safely, but it's much easier to just use a different approach that doesn't involve executing untrusted code.
I tend to shy away from large complicated if/else constructions. They are hard for me to reason about since I have to trace the branch of logic that gets me to a certain ending. That's why I would probably prefer either using a switch solution or a dictionary.
Cheers, appreciate that. couple follow ups: - what about execjs itself makes it untrustworthy (only ask because it's on [pypi](https://pypi.python.org/pypi/PyExecJS)) - or do you mean the fact that the script just plops some javascript into a function and runs it? In that case, how come it's not safe to say "if i only ever put table data in there, I'll be fine?" 
Great work, and something Python has needed.
serious question, What use is a switch if it doesn't support fall-through? otherwise isn't it just a dict lookup? handlers = { 'a': do_a, 'b': do_b } handlers.get(arg, do_default)() I can't think of a case where I'd ever want to use a switch statement without fall-through, an if...elif...else block makes more sense in almost every case, and where it doesn't, the dict approach works.
 - The problem isn't with execjs in particular; I'm not aware of anything it does wrong. The concept of "executing code scraped from a website" is, by itself, unsafe. - Sure, it's fine as long as you only ever put table data in there. But you *can't* be sure that you're only putting table data in there. If the site you're scraping from gets hacked, the attacker can insert any code they want into the JS you're executing. The likelihood of that happening isn't very high, but if it does happen you're utterly screwed; and on top of that executing untrusted code is a very bad habit to get into. Do it when there's no other way, not just when it's convenient.
Do you mean java not javascript?
Looks nice, good idea with the contextmanager. I always like the unconventional use of it ;) But is your switch also capable to be computed? For example like this: In [1]: import math In [2]: switch = {name: meth for name, meth in math.__dict__.items() if callable(meth)} In [3]: switch.get('sin', lambda x: x)(100) Out[3]: -0.5063656411097588 I know `math` is a bad example, because you can't inspect the methods to ask for the signature, to avoid different amounts of arguments. It is just an example. My idea is to just provide a module with different functions to load into the switch, some kind of dynamically plugin system. For me that is a major advantage of the dict switches.
^ That's what I do and prefer, but I could see people preferring switch for the readability 
Good comparison! I love it when a project includes a comparison to an alternative way of doing it like that 
Sounds like a cool project, you could probably use Twitter (tweepy) to get texts to your phone for whatever events you need.
Is there any reason to use arrow over pendulum?
Both have codebases. People have used both so I guess in that sense they qualify as "deep learning languages" 
Forgive me if I'm mistaken, my python's kinda rusty, but shouldn't the last key of the "switch" dict be 3: method_on_three not 3, method_on_three ?
&gt; Or maybe it has something to do with /u/tdammers "holier than thou" personality, one that dictated they must be a Haskell programmer in the first place; and demands they post condescending comments in the python subreddit. I'm sorry for coming across that way; I didn't mean to, and that's not who I am. So here's the disclaimer: Python is fine. I have no problem with Python. It is, in fact, among the half dozen or so languages that I would consider for a greenfield project, if I were to start one tomorrow. Python is not a pure functional programming language, and it lacks critical features for supporting a pure functional programming style: most notably, it is practically impossible to construct Python code such that side effects are prevented; the closest you can get is code that has no side effects put in by you on purpose, makes a best effort at avoiding side effects caused by things it depends on, and hopes that anything passed in meets the documented expectations wrt side effects. But again, Python is fine. Python cannot do pure functional, but that's not where it shines anyway. If you want pure functional, then do not use Python, because it will ruin both Python and pure functional programming for you. And if you want Python, then use Python, and use it for what it's good at: low-boilerplate imperative code, the freedom to modify anything you want to modify, a super shallow learning curve, and an enormous library ecosystem. So this, I think, is getting close to the core of what I'm trying to say here. The thing that trips me up here is how a language (or rather, its community) that is so deeply committed to mutable state and uncontrolled effects, and so deeply suspicious about anything higher-order, somehow attempts to ride the benefits of a radically different paradigm without actually committing to said paradigm, or even fully understanding it. Pure functional programming is one of those "all or nothing" choices: if you do it completely, at least for a well-fenced part of your codebase, then the benefits pull their weight, but if you half-ass it, then you'll spend a lot of time dealing with a lot of awkwardness for extremely limited gain and extremely leaky abstractions. Purity that isn't guarded to a reasonable degree by the compiler is hardly worth it; that's because the line of reasoning that gives you the legendary mental performance boost is 1. this function is pure 2. this means that anything it calls is also pure 3. this means that when I'm dealing with this function, I can completely ignore any and all side effects, because there are none. But people make mistakes, and so without tooling support, or with a weakened notion of "purity", you cannot uncritically assume 3., and the entire benefit of not having to think about side effects at all evaporates. You're left with 1. this function takes only immutable arguments and returns an immutable value, hmm, I wonder if it has any effects 2. I don't know, let's look at the implementation 3. oh dear, it calls quite a bunch of other functions, and oh look here, a `for` loop, I wonder if the iterator we're using has any side effects, 4. OK, let's read the code for those things as well 5. crap, they're from somewhere deep inside a library 6. how deep does this call graph go anyway? 7. meh, forget it, I'll just write more tests. Which, frankly, I probably should have done right away. Anyway, so here's the gist: that article was clearly written by someone who has a bit of a hunch about FP and why you'd want it, but doesn't seem to actually fully understand what these ideas look like in practice, or what it's like to fully experience the actual benefits. And as a result, there's quite a bit of stuff in there that's either outright wrong, or at least mildly misleading, or of the kind where someone who actually knows these things would go "eh, hnnngh, yeah, I guess that's technically correct, but, uhm...". Such as: - "Functions that have no side effects at all are called purely functional." - no, they're called "functions". "Pure functions" if you need to disambiguate between actual functions and procedures (which in most programming languages these days also go by the name of "functions"). "Purely functional" refers to either a programming style that uses only pure functions, or a programming language in which only pure functions exist (iow., a language that cannot express side effects). - "Avoiding side effects means not using data structures that get updated as a program runs; every functionâ€™s output must only depend on its input." - yes, it means that, but it also means a lot more. It's not just destructive variable updates that are prevented; *all* side effects are. Which, by the way, does not mean you don't get to have effects at all, just not side effects. - "Python programs written in functional style usually wonâ€™t go to the extreme of avoiding all I/O or all assignments" - no, and neither will Haskell programs. Pure functional isn't about not having I/O at all, or not having assignments at all; it is about *controlling* effects, and in order to do that, we have to make them *explicit*. There are various ways of doing this, the best known one being Haskell's approach of having pure first-class values that represent effectful computations, and a pure DSL to combine them, and then pointing an impure runtime at one such computation which represents the entire program. We're still doing I/O; but we're doing it in a way that allows us to keep the language pure, preventing effects from bleeding into other parts of our code, and making sure they can only happen when declared explicitly. - "Functional programming can be considered the opposite of object-oriented programming." - only if you have very skewed notions of both Functional and OOP. They are orthogonal: FP is about the nuts-and-bolts level of things, OOP is a larger-scale organisational paradigm. You can combine them just fine; just because you have objects doesn't necessarily mean they have to use side effects, and just because your code doesn't allow side effects doesn't mean you cannot split it up and group related state and behavior. - "A more practical benefit of functional programming is that it forces you to break apart your problem into small pieces." - no, it doesn't force you at all. In practice, a functional approach often *enables* you to split up your code into smaller chunks, because when all expressions and sub-expressions are pure, factoring them out is straightforward and low-risk. So back to that ad hominem there. &gt; one that dictated they must be a Haskell programmer in the first place Haskell is great for me, because it resonates with how I think and how I want to approach writing code. Nobody told me to use Haskell, and there is no ideology there; it's simply that Haskell is the easiest language *for me* right now. And when I post condescending comments (which, I admit, I sometimes do), it is usually because, let's face it, Python, like every other language, has some rather blatant shortcomings, and when people sweep those under the rug out of misguided tunnel vision, it trips me up. For the record; when I say "every other language", I mean it, and that includes Haskell.
deleted ^^^^^^^^^^^^^^^^0.3522 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/44731)
Except this doesn't support fall through, so it's more of a compact if elif block. 
Linux. Debian Linux. 
&gt; only ask because it's on pypi PYPI offes no security, you can upload any kind of code. [Here](http://incolumitas.com/2016/06/08/typosquatting-package-managers/) is a very interesting article about typosquatting and how to use package manager as prime example pypi to attack thousands of systems. Basically well known and active packages with a huge amount of people looking and working on the code are more trust worthy than relative young and unknown packages.
Why are people so hung up on the switch statement not being implemented? The way switch is usually used (break on every case) its basically an if block. I'd rather see implementations of pattern matching ala Rust, Haskell or Scala. 
No, you're right. Thanks.
brilliant, thanks so much this is a really great explanation, definitely have a good understanding the full issue here now
Can you explain what's going on here or can you give me some terminology to look into? I have no idea what get_action(action) is doing, and how it relates to "action in ..." in the result dictionary.
Thanks for the reply. The ad hominem was mainly in spite of your curtness ;P As a "functionally-inept" programmer myself, this comment was very informative, and I appreciate its candor.
You can set `True: lambda: None,` at the top so if there are no other True conditions it will call that lambda which sets result to None and moves on. 
I agree. I don't like these switch statements, but I like that the author showed the pythonic way too. It's good intellectually honesty, which a lot of these "I've implemented a language construct that isn't present in Python" libraries lack.
Holy shit what an eyesore action = get_action(action) if action in ['c', 'a']: create_account() elif action in ['l']: log_into_account() elif action in ['r']: register_cage() elif action in ['u']: update_availability() elif action in ['v', 'b']: view_bookings() elif action in ['x']: exit_app() elif action in range(1,6): set_level(action) elif action == '': pass else: unknown_command() 
Have you tried the official Django [tutorial](https://docs.djangoproject.com/en/dev/intro/)? I have no experience with the Django Girls tutorial, so I can't help compare/contrast. Edit: there's also a subreddit: /r/djangolearning 
That's just some function that retrieves user input. He's then evaluating the various "action in [...]" statements to boolean values. If any of the statements evaluate as True then the default unknown_command function will be overwritten in the dict. He then retrieves the matching group's function by looking up True. 
Just search for `python pattern matching` and you'll find them but very few appear to be maintained :-(
https://libcloud.apache.org
Look at the range, closed_range, list and other features for case matching. This is not possible in dictionaries. 
`get_action` is just a made up function to demonstrate `action` is being assigned a value. The switch like structure is just an ordinary dictionary. When creating the dictionary it evaluates each key/value pair in order and since each key is in the form of a condition such as `action in ['c', 'a']` it evaluates in real time to `True` or `False` and uses that value as a key in the dictionary. There are a few things strung together to make it more compact so maybe writing it this way will help you understand: grade = 25 switch ={ True: None, grade &gt; 89: 'A', grade &lt; 90: 'B', grade &lt; 80: 'C', grade &lt; 70: 'D', grade &lt; 60: 'F' } result = switch[True] 
https://www.pyfilesystem.org
If you've got a bunch of old footage, that's a good way to build up a large set of test cases pretty quickly.
I thought I was the only one who thought that example was totally nuts
I agree with you about complicated if/else constructions, but I don't think that a flat (not nested) list of if/elif statements is complicated at all, and that's what a switch statement replaces, right?
This is cool. But does not do ranges, lists, case or signature validation. The default case is non-obvious. But it is neat.
I saw it and I was expecting the comments to just shit all over how unpythonic it is and then I see "how clever" "much like" "will use" and i'm just like ðŸ¤¦
Why not have the case() function only evaluate if the case is a match instead of also dispatching the handler function? This would allow cases to be a block of statements instead of a single handler function. If you overload a function in the context manager (e.g. __call_\_), the usage is actually a little shorter even with the if-elif-else keywords. I think it is also a bit more obvious what is going on. For example: with switch(val) as s: if s('a'): process_a() elif s('b'): process_with_data(val, num, 'other values still') else: process_any() edit: markdown
You forgot to assign the result of the called function to `result`, the code gets a little messier if you do.
Because to me, it's about readability. This looks like I might have just as well written it as a if/elif/else block so why complicate it with switch. The switch is only worth having if it makes code clearer, eaiser, safer.
I feel like I see this same post monthly... I guess I just use `elif` and don't worry about it.
The `in` operator and a tuple?
[This video series](https://www.youtube.com/playlist?list=PL6gx4Cwl9DGBlmzzFcLgDhKTTfNLfX1IK) by thenewboston was a good starting place for me. Hope it works for you!
Here you go. (No I don't care that I shadowed action) def handle_action(action): if action in ['c', 'a']: return create_account() elif action in ['l']: return log_into_account() elif action in ['r']: return register_cage() elif action in ['u']: return update_availability() elif action in ['v', 'b']: return view_bookings() elif action in ['x']: return exit_app() elif action in range(1,6): return set_level(action) elif action == '': return None else: return unknown_command() action = get_action(action) result = handle_action(action) Want less cluttered lines? def handle_action(action): if action in ['c', 'a']: return create_account() elif action in ['l']: return log_into_account() elif action in ['r']: return register_cage() elif action in ['u']: return update_availability() elif action in ['v', 'b']: return view_bookings() elif action in ['x']: return exit_app() elif action in range(1,6): return set_level(action) elif action == '': return None else: return unknown_command() action = get_action(action) result = handle_action(action)
no but it's incredibly straight forward with if/elif if x in range(0, 10): do_a() elif x in range(10, 20): do_b() 
What that's doing is: for {some item} in {some group of items} : {do something} In python, strings: ("hi mom") are like lists: (['h','i',' ','m','o','m']) so you can iterate through them. Each time your for loop moves to another letter, it prints that letter, so each letter of the string ends up on its own line. Look here for more info: https://docs.python.org/3/tutorial/controlflow.html#for-statements
Obligatory /r/learnpython The print() statement's default behavior includes a new line character to be printed, if you want this behavior changed you can see the different ways to do so in this [thread](https://stackoverflow.com/questions/493386/how-to-print-without-newline-or-space). 
First time coding ever this week, just finished making a turtle code that let me pick pensize, pencolor, speed, and a shape, and then it would draw it for me. I know itâ€™s not much but it was so satisfying to complete
Yes
Check out https://bokeh.pydata.org
Not true. A proper switch statement jumps to the right case making it much faster than cascaded ifs.
Ok, so then I have two questions: 1. Why doesn't switch[True] just evaluate to None, since the key True has a value of None. 2. Where is get_action defined? Is it just a simple function that returns result[action]
suddenly the dict lookup doesn't look so bad
https://github.com/ssanderson/switchcase less "pythonic" but is insanely simple, and could easily be extended to support fallthrough
First, obligatory subreddit suggestion of /r/learnpython. The 'prefix' you are seeing is the string representation of the Decimal instance retrieved from the database. [Decimal](https://docs.python.org/library/decimal.html) is the Python class for handling that type of data. In fact, your issue is entirely one of types. MSSQL has a "decimal" type, and so does Python -- so pyodbc is helpfully making sure the data you retrieved is in the correct format. The problem, then, is that sqlite does **not** have a decimal type, which means it is on your program to decide how to convert a decimal to a type sqlite does understand. My advice -- don't do that. Your SQL select query is casting the result as a decimal -- it would be better to retrieve it as an integer (number of cents), which is a type mysqlite understands as well. If you really need to store it as a decimal, your best bet is to convert it to a string (**not** a float, as that [probably is not what you want](https://docs.python.org/3/tutorial/floatingpoint.html)). That means if you later do further arithmetic on it, you will need to convert that string back to a decimal before doing so.
So I found a node.js + vm binding called [node_vm2](http://node-vm2.readthedocs.io/en/latest/) which claims to allow the safe execution of javascript as opposed to running it an unprotected environment. Not sure if this is 100% fullproof but I've edited above.
I am a novice Python programmer as well so take this feedback with a grain of salt. Your IF/ELIF statement at the bottom is off. Both IF and ELIF are checking **actual == 'NULL'**. I'm guessing you want one of those to check something else?
https://stackoverflow.com/questions/767821/is-else-if-faster-than-switch-case tldr: switch statements can be optimized into a hash-map by the compiler. But seeing as how python isn't compiled I'm not sure how they would go about implementing this.
Do you iterate over a dictionary to get to the right key? In the case of purely in order numeric switch statements some compilers can use a jump table.
Obligatory mention of python's switch statement: https://www.python.org/dev/peps/pep-3103/ Guido has rejected the switch multiple times on the basis that there *may* be nominal performance increases in specific cases and is *slightly* more readable than a group of elif's; the benefits from these are not enough to warrant new syntax. Personally I don't have a problem or feel any pain just using ifs and elifs. I've been using python for almost 10 years and can't say i've ever had more than 5 elifs together. If a switch syntax provided a large boost to either readability or performance; I would support the idea, but I just don't see it. My other complaint is that this style of programming forces one to create sometimes unnecessary functions to handle each case for the switch which is a lot of overhead, and doesn't apply to every situation. So really the question is; in situations where you would want a switch for readability; do you also have cases that are 100% hashable and are okay with the added overhead?
OP's example is implemented with a dictionary so it would indeed be O(1); but we're talking like nano second differences here. I sincerely hope no one is making chains of if's more than like 20 where it would affect performance
True, I had forgotten about this.
Sure, that's a possible solution. It seems like massive overkill, but it would be safe, I think. I would still go with parsing + accessing the AST.
Python is compiled into bytecode, you could do the optimization there.
Agree with your point, but big-O runtime is silly when talking about a conditional. It's not like the number of cases is asymptotic... Right?
I've never used plotnine, or Altair, so maybe my point to moot. But I think generally people start off with something easy like Plotnine, but then there's always eventually a very specific thing you want to do that plotnine can't do for you. So then you begrudgingly learn matplotlib. Then you relearn matplotlib when you learn about `fig, ax = plt.subplots()` and then you write your very specific plotting function once, and in your data processing just import it from your `plotting_scripts` folder. So what I'm saying is... you'll be back (to matplotlib). For the record, plotnine is just a convenience wrapper, matplotlib is still the backend. 
Have you seen how much explaining /u/Allanon001 has had to do to get people (/r/Python no less) to understand what is going on in the dict lookup? It's overly complex and confusing and is an abuse of the language. It's basically a giant one-liner while True: action = get_action(action) result = {True : unknown_command, action in ['c', 'a']: create_account, action in ['l']: log_into_account, action in ['r']: register_cage, action in ['u']: update_availability, action in ['v', 'b']: view_bookings, action in ['x']: exit_app, action in range(1,6): lambda: set_level(action), action == '': None}[True]()
Sure but in such a contrived case; we should expect the if statements to take ever so slightly longer because they would technically be O(n); where n is the number of compairsons. Conditionals are so freaking fast on a cpu that this compairson is exceedingly trivial. We would really only have a noticeable performance difference over giant groups of conditionals, like hundreds of thousands; and if your code reaches that point, a switch is probably the least of your concerns. Perhaps the case where these nanoseconds matter; say in an extremely high performance application (i'd wonder why python is your programming language of choice), or even a webservice that gets millions of requests per second, then an optimization like this might be warrented; but thats not a good reason to add new syntax. 
I like the way switch is implemented in swift. It allows you to add advanced logic statements and allows you to very easily group together a group of conditionals. Sometimes it felt cleaner to use switch than if-elseif-else.
Pyqtgraph can handle this cross platform and with any recent version of PyQt, and it's pretty straight forward to use. Today I plotted about 900 lines of 2000 points each with very little delay, you should be good for doing close to real time. Their benchmarks show that they can get to about 300 fps on my computer with the native renderer. 
Well, when I started scientific programming with python, matplotlib was the only viable library, so I had no choice. But having used matplotlib for almost a decade, it is still painful for me to use it. Of course, matplotlib is very powerful and there is nothing you can't plot with it, but I want to minimize all the cumbersome tasks. And IMHO, one of the reasons that people somehow occasionally comes back from the other libraries is that those libraries lack several functionalities. Seaborn would be a good example: If seaborn has built-in functions for your plot, you're good, but otherwise you rely on matplotlib to do other jobs. The situation is different for plotnine, assuming that it reflects ggplot2 well enough. I've never seen a single person complaining about ggplot2, since it is both easy to use and powerful. On the other hand, there're plenty of former R users missing ggplot2.
I found the official tutorial (as well as the djangogirls tutorial) to be a bit superficial in being "Do it this way because django" like you said. *The Django Book* [online here](https://djangobook.com/the-django-book/) gives a very good in-depth explanation of django beyond just building your first basic app. I was working my way through this but have misplaced my free time so I'm still not done. *Test Driven Developement with Python "Obey the Testing Goat"* [online here](https://www.obeythetestinggoat.com/) uses django along with selenium which is a good tool to know to test your django apps. It's not very descriptive on the why part of django since the focus is on the test driven methodology, but the author also takes you through steps like deploying your site that I thought were useful. I have not finished this book either, but the 3rd version was just released recently and I like the conversational, British writing style of the author. 
that game probably sucks
&gt;The way switch is usually used (break on every case) its basically an if block. Noooooooot at all. Switches are [; O(1) ;] jumps to conditions. If statements are [; O(n) ;] evaluations.
The run time of the thing is irrelevant, functionally they act similarly. Edit: Since y'all miss context clues, they're functionally similar for the situation being discussed, a break in every case. If you want fall through, they aren't. 
I need it to loop and change the location#, I want it to run the first location, then if there are NULLs check the 2nd, and if any NULLS remain check the 3rd.
Honestly, I think [**functools.singledispatch**](https://docs.python.org/3/library/functools.html#functools.singledispatch) is better suited to this kind of thing. That said, I submitted a [pull request](https://github.com/mikeckennedy/python-switch/pull/3) to scratch my own itch as to how I think it could improve. You can still use it the way it was originally documented (except for the switch class no longer having a singular return value, since each case returns the result of the callable passed to it instead), but there is no longer any dictionary to maintain and you can choose whether or not to have it fall-through with an argument to the context manager. You can also dispatch based on a predicate function so there's no longer a need for a dedicated closed_range function etc. from switchlang import switch def process_a(): return "found a" def process_any(): return "found default" def process_with_data(*value): return "found with data" val = 'b' with switch(val) as s: a = s.case('a', process_a) # -&gt; None b = s.case('b', process_with_data) # -&gt; "found with data" c = s.default(process_any) # -&gt; None with switch(val, fall_through=True) as s: a = s.case('a', process_a) # -&gt; None b = s.case('b', process_with_data) # -&gt; "found with data" c = s.case(lambda val: isinstance(val, str), lambda: "matched on predicate") # -&gt; "matched on predicate" d = s.default(process_any) # -&gt; "found default"
Every `True` key overwrites the previous `True` key. And again, `get_action` is just a made up function to demonstrate `action` is being assigned a value. It's definition is not shown, and in the above example is not needed. 
Plotly is pretty easy and pretty customizable, check it out
opencv is great. What you want to do is to turn your image to greyscale (`cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)`) then either : - Average the pixel value over the whole array (applying a gaussian blur before hand is a good idea) of pixels - Use opencv's adaptiveThreshold and get whether or not there are more white or black pixels on the array. You can use `cv2.VideoCapture(device)`to load a video in memory.
I haven't looked at the book listed yet. Has anyone had much success with functional programming in python? I do enjoy writing scala but trying to do functional programming in python hasn't been a great experience for me. It feels very forced to try to write functional style python 
Obviously that should check if x is that specific generator object you just created. ^/s
Also a Python novice here. (blind leadin' the blind, I guess) Maybe adjust what each if statement is asking? So instead of &gt;if actual=='NULL': stuff elif actual=='NULL': maybe try something like &gt;if actual1=='NULL' &amp; actual2 != 'NULL' &amp; actual3 != 'NULL': do stuff elif actual1!='NULL' &amp; actual2 == 'NULL' &amp; actual3 != 'NULL': do other stuff elif actual1!='NULL' &amp; actual2 != 'NULL' &amp; actual3 == 'NULL': do even other stuff with actual1, actual2, and actual3 each representing a separate location you're checking for a null value. Not sure if this'll help at all, but figured it wouldn't hurt to mention. 
Some wrappers for my main apps/services and a pomodoro
[removed]
Excel has a function to automatically split a single column into multiple based off of delimeters. You didn't say you had 200,000 columns every single day, you made it seem like you were just trying to make a file you had useable. That's why I asked if it was needed to be done repetitively.
Please, just no...just stop
Oh I think (hope) I get it. The statement evaluates to true when the dictionary is created, not when it's accessed in `result = switch[True]` . That's what I was getting confused about.
It didn't exactly post perfectly, I hope ya'll got the point.
unfortunately cpython barely does any optimization
Branch prediction may also inoculation the performance, and it's not usually considered when determining time complexity.
Functionally switch-case and if-else ladders are equivalent _if and only if_ each case in the switch ladder is terminated by a ``break`` statement. 
I said that in my original comment that almost every switch block I see is done that way. In C#, it has to be done that way.
If you're interested in that level of performance optimization (i.e. the cost of `if` vs. `switch` matters to you), it's almost certainly the case that you're using the wrong programming language altogether, and adding a switch statement to python will not address your issues. So while you're technically correct, in the context of this discussion, your comment is pretty unhelpful.
If I recall correctly, pyenv is deprecated. 
In C and C++ a case will "fall through" to the next case if ``break`` isn't used, causing interesting behavior or really nasty bugs. (You can have code that runs A if the switch is 1 and A+B if 2, etc.)
&gt; if and only if Right. But other ways of using switch-case are typically incredibly bug-prone, hard to read, and hard to reason about. If you're writing performance critical C code, maybe that's a trade off you should make if the switch-case does what you need and is faster. However, as a practical matter, spots where non `break` terminated switches are a good idea are pretty rare. Heck, even if you *are* writing performance critical C code, unless you're writing the code for the core bottleneck of your program, I would argue a non `break` terminated case is almost always going to be bad programming. In the context of python (where performance is already slow enough that the difference between `if` and `switch` really can't be very important, if it had a switch statement, I doubt many programmers would see a situation where it made sense to use it in a non `break` terminated way in their lifetimes.
Correct
CaveMike makes a good point. As to the argument that one might as well have written an if/elif/else block well... yeah, exactly. For example, as the context manager is currently written, there is no way to set the value of a variable to something based on any given case without referring to them as global or nonlocal within the functions passed to case. i.e. from switchlang import switch is_sam = False # I want to change is_sam to True based on the value of a variable # here is the old, ugly python way with an if/else variable = 'sam' if variable == 'sam': is_sam = True print('is sam:', is_sam) else: print('is sam:', is_sam) # with sexy context manager is_sam = False def change_sam(): global is_sam # ew print('changing is_sam global variable') is_sam = True with switch('sam') as s: s.case('sam', change_sam) print('is_sam:', is_sam) 
No, `pyenv` is a tool for managing multiple python interpreters. That's what the linked article is about. It is not distributed with python and is not deprecated. You're probably thinking of `pyvenv` (note the v in the middle), which was distributed with python. It was simply another way of doing `python -m venv`, i.e. it was a tool for creating virtual environments using whichever interpreter it happened to be linked to. It was deprecated in 3.6.
on that note, dictionaries can be rudimentary switch statements
Something to also keep in mind is that Django is known for being very opinionated (versus that of Flask). IE. Very much "do this because this is our standard." However, that being said, after working in Django for about seven years ... I'd argue that the patterns are really helpful at mid-larger scales. Flask is very easy to get started with on the other hand, but since there's less "best practices" flask, it can get a little unwieldy. 
Most keyboards have a limitation in their wiring that affects how many keypresses they can process at once.
&gt; I'd rather see implementations of pattern matching ala Rust, Haskell or Scala. Oh dear lord yes, please. This is the feature I most miss in Python. I'm working on a toy language (my first) and while it's primarily based on Python, I want to incorporate pattern matching and ADTs from Haskell. It's such a useful feature.
yeah so there are many optimizations to be had; and the performance argument is silly. 
That is readable, after one figures out the pattern, but in execution it requires all the `in` expressions to be evaluated, and a new dict object created, every time. Whereas the usual key:executable dict is static and an O(1) lookup. 
A brand new dict is created each time. The `in` expressions are evaluated in order as it is built. They evaluate to `True` or to `False`. So the new dict has only two keys, `True` and `False`. The last expression to evaluate to `True` sets the value for that key. At the end, the index `[True]` extracts that value. Which is expected to refer to an executable, so the `()` makes it a function call on that executable.
I have used OpenCV with Python to stream mjpeg images and apply effects to each individual frame, e.g. detecting motion and save the stream feed to as an individual frame. An individual frame is stored in memory, until next frame is received. So while in memory you can do anything with the frame. Code to my script: https://www.github.com/jjvilm/security-cam If you want to take a look. 
Makes sense, thanks for the explanation
You can also abuse it create things like Duff's Device. I think fall through is the biggest thing that sets switch away from if. 
I made a number guessing game for my programming class.
I get that, but Windows seems unaffected by this other than what you mention; Only what the Python script seems to be detecting. Edit: Maybe I can get around the issue by always starting off the keypress iteration by forcing it to check the status of the key press of WASD? I'm at a loss but I know it's possible.
[So we are almost there.](https://xkcd.com/927/)
[Image](https://imgs.xkcd.com/comics/standards.png) [Mobile](https://m.xkcd.com/927/) **Title:** Standards **Title-text:** Fortunately, the charging one has been solved now that we've all standardized on mini\-USB\. Or is it micro\-USB? Shit\. [Comic Explanation](https://www.explainxkcd.com/wiki/index.php/927#Explanation) **Stats:** This comic has been referenced 4827 times, representing 2.8695% of referenced xkcds. --- ^[xkcd.com](https://www.xkcd.com) ^| ^[xkcd sub](https://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](https://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_dn113nm)
[Automate the Boring Stuff with Python](https://automatetheboringstuff.com/) and [r/learnpython](https://www.reddit.com/r/learnpython/)
What do you mean specifically when you say that Windows seems to be unaffected?
Any time I've ever wanted to do a switch statement, it's time for an event dispatcher.
Because Python's biggest strength is also its biggest weakness: its extremely dynamic runtime. Any object can be any thing at any time, so optimizations can't be done reliably. Obviously pypy found a way to deal with this, but CPython had decided not to deal with it
Windows can't do anything about the hardware limitations of the keyboard; if it doesn't send an 'up' keycode then Windows won't send an up event to your program. The way I've gotten around this problem in the past is to use DirectInput to read the entire state of the keyboard all at once.
What will I have to do to get my hands on this, sounds like it would be interesting. 
Have you posted this to PyPI?
pysdl probably does the same thing
I have heard about this project that takes python into the functional programming realm. [Link](http://coconut-lang.org/)
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
I'm thinking along the lines of: result = { create_account: {'c', 'a'}, log_into_account: {'r'}, ... } result = {item: key for key, value in result.items() for item in value} result.getitem(action, unknown_command)
Pragmatically functional is my general approach to Python. If i use third-party libraries, i may have some object oriented bits, but I keep it minimal. My rules for being functional-ish in python are: - prefer pure functions - no classes (aside from named tuples) - instead of default argument values, use partials - use mypy in strict mode for static type enforcement. Really useful for forced checking of Optional types. It's not perfect. Pattern matching, better lambdas, and a cleaner syntax for function chaining would make a huge difference. But it gets you to a point where your code is very refactorable and readable. Scala is better for sure, as are many languages that explicitly try to bridge the gap between OOP and functional, but I still think functional is the right (and increasingly common) approach to Python.
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
I use map and filter a lot more after learning haskell
*Everybody needs to know this code has terrible relative performance than a similar `if 0 &lt; x &lt; 10` since `range` will need to be evaluated as it returns a generator/iterator in Python3*
&gt; Is Python more powerful? All languages that are [Turing complete](https://softwareengineering.stackexchange.com/questions/132385/what-makes-a-language-turing-complete) can compute the same things and the bar for being Turing complete is pretty low. In practice virtually all general purpose languages **are** Turing complete so it doesn't make sense to ask if one is more powerful than another. What **does** make sense is to ask how easy it is to write useful code using a particular language and here is where the differences between languages become important. Part of that question is strictly about the language itself. Tthe syntax, structure and meaning of the parts that make up the language - like how you can make loops, define functions, make choices and so on. Another huge part is what libraries are available for the language. Some libraries are included with the language and many, many more libraries are written by other people who wanted to solve a particular problem, but didn't have the facilities in the standard language and libraries to do that, or they were difficult to understand and use. That means they have to write those tools and libraries on their own and if they do that in a general way and make it available as a library, other people can benefit and it makes it far easier for everyone to solve the same and similar problems. That's where python is probably better or more powerful that AutoIt (caveat - I know nothing about AutoIt) because it's a very well-established language with lots of built-in features and built-in libraries and a huge ecosystem of other libraries and tools that people have developed and refined and made available over the years. There's also the wider community dedicated to the language too like people who make courses to teach you about the language and its tools, or who write books, organise conferences, hold meet-ups, write articles or create subreddits, or ... **tl;dr** When you compare programming languages you need to consider all the tools and libraries available for the languages and all the other resources like courses, books, articles, conferences and so on. &gt; Where should I start to learn? Look at the sider bar ----------&gt;&gt; There are a ton of resources there to get you started.
it's probably the O(n) vs O(1) thing in theory. But agree, in practice, it'd probably take a gazillion conditions to make it worth bothering about.
Is there support in mypy for type hinting for named tuples? I found this [open issue](https://github.com/python/mypy/issues/460) in GitHub, but it's just about supporting field names, not their types. Edit: my mistake, it's a closed issue.
autoit can control other applications and send keyboard/mouse inputs. I still wait to see something similar in python.
Same performance as the switch example though. 
Depends on the language and implementation. C/C++ switch statements are O(1). Bash and PHP switch statements are O(n). Python has hashes which between hash tables and if statements, Python is good enough.
deleted ^^^^^^^^^^^^^^^^0.4233 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/99014)
thamk you!
No, [from](https://docs.python.org/3/library/stdtypes.html#typesseq-range) "The range type represents an immutable sequence of numbers and is commonly used for looping a specific number of times in for loops." and "Ranges implement all of the common sequence operations except concatenation and repetition (due to the fact that range objects can only represent sequences that follow a strict pattern and repetition and concatenation will usually violate that pattern).".
very informative, thanks!
If you (plural) don't like the typing there's plenty of scope to roll your own in Python with something like this [range comparison recipe](http://code.activestate.com/recipes/578158-range-comparison/).
Its O(n) on the number of cases you have, not the size of the data you have, which is what big O notation is about.
What do you do with exceptions and functions that fail? Like a real trivial example would be to convert a string to a int. I would probably go with Option or either. I think typical python code would raise an exception if you passed "aaa" to this function? I guess you could return none? or a named tuple that mimics either?
Ironically, the python interpreter has a ginormous switch statement at it's core
Big O is about the size of the data. 5 elifs is not O(n)
Til, after almost a decade of python I need to learn functools
&gt; But does not do ranges In this case you don't need to have ranges. It is about loading specific methods out of an object. In my example you load 45 methods into the switch with the name as key, where do you need ranges here? &gt; lists, case I am not sure what you mean with that. &gt; signature validation As I said, this isn't possible with the `math` module, because C-code don't offer a signature, like the `operators` module. But you can easily get the signatures of pure python functions with `inspect.signature(func)`. And before I write switch cases for 45 different functions, I could check for sigs in an intermediate step, no big deal. &gt; The default case is non-obvious. I thought returning the identity function as a default around mathematical function would be an expected result, it just returns the argument iteself. But you can also raise an error if you want to catch and handle it. 
Of course I did, but its syntax seemed too verbose for me.
How are C++ switches O(1)? AFAIK most compilers don't use hashing or anything and would still need to check all the cases in the worst case.
It's great. I can no longer live without `singledispatch` and `partial`
Ruby's case statement can include an optional else block, so it's possible. case x when a then b when c then d else e end And from Ruby 2.something the case statement is faster than if/elseif/else block.
https://pyautogui.readthedocs.io/en/latest/
You could do something like: from typing import Optional, Union def convert_int(int_str: str) -&gt; Optional[int]: try: return int(int_str) except ValueError: return None print(convert_int("aaa") is None) # something like result using type aliases (string means error) ConvertResult = Union[int, str] def convert_int_2(int_str: str) -&gt; ConvertResult: try: return int(int_str) except ValueError as e: return str(e) print(convert_int_2("aaa")) You can also use union types with named tuples or type aliases to get to a point where you're mimicking Sum Types. So you still have to deal with python's exception handling (unless you do like a regex check), but having mypy check the type signature helps a lot with code confidence and refactorability.
That's actually a closed issue. Yeah, mypy has been able to do that for a while. really nice with the 3.6+ named tuple syntax.
What would be an example of where pattern matching would be useful? Is this string manipulation? Happy to be pointed to a good code example of how this might work in Python.
nice!
No, it doesn't. Where are you getting that info from?
How the heck are you downloading / installing Python to get anywhere near that figure?
&gt; Not true. A proper switch statement Ah, the "No True Scotsman" fallacy rears its ugly head. Even in low level languages like C, switch statements can be and sometimes are implemented as chains of `if` tests. Sometimes that's just because the compiler is naive and doesn't implement any optimizations (the C standard does not specify an implementation for switch) and sometimes because there are no optimzations available to apply. See the last example [here](https://www.codeproject.com/Articles/100473/Something-You-May-Not-Know-About-the-Switch-Statem) where even a smart optimizing C++ compiler falls back on a simple (and short) chain of `if` statements. Switch statements in C/C++ are limited to equality comparisons with integer values. That allows the compiler lots of opportunity for optimization. Switch statements in other languages may allow for a far richer set of comparisons, against arbitrary data types, which makes it hard or impossible to optimize it beyond a simple chain of `if...elif`. A switch in Python is unlikely to be very optimized. 
&gt; C/C++ switch statements are O(1) No they aren't. It depends on the compiler, and it [depends on the switch statement](https://www.codeproject.com/Articles/100473/Something-You-May-Not-Know-About-the-Switch-Statem) being compiled. At worst, they can fall back to a chain of `if` comparisons.
Got a link to a good explanation of Swift switches? 
Why can't we have both? Why does every performance optimization need to be dismissed? Performance improvements to Python come all time and no one bats an eye but if someone *asks* for a performance improvement, or even mentions performance, they get shot down. People use Python for a lot of different things. Your use case is not better than anyone else's.
Cpython interpreter is surprisingly bad. See GIL.
No. I even use Python on one very old PC where I could only set 20G of space for Linux with some programs that I need and by far Python is not even significant space eater. Edit: I think, normally it should be about 50M, can't check now.
If you are using mac or windows, [Anaconda](https://www.anaconda.com/download/) is an easy way to get started. It should take about 1GB of storage.
Are you looking at Heroku or something? You can download and install Python locally for free and little space.
Big O is an upper bound on some function f(n). f(n) and n can semantically mean anything; here n is the number of cases and f(n) is the number of operations to arrive at the correct case.
I'm have python on my Raspberry Pi which is running everything on a 4GB SD card!
I've never seen any realistic Python code where having a switch statement would lead to any measurable performance benefit. I guess that's why.
Was fully expecting a link to Haskell. Still not disappointed.
It's also got a fair amount of `goto` statements. Is it therefore ironic that we don't have gotos in Python as well? C doesn't have e.g. dictionary lookups that we use to "emulate" switch statements in Python, so there switch statements are obviously quite handy. I don't see the irony at all here.
Small switches yes. I've seen decompiled code that properly uses jumps to be very fast with larger switch statements.
Probably, OP you can try minimizing chi squared with scipy.optimize.minimize and use something like nedler-mead. Just create some function sum_by_all_measurements((data^2 - model^2)/uncertainty) and minimize it for parameters inside model function. Or you can try using curve_fit function with p0 parameter and check covariance matrix for anomalies.
it doesn't in python 3 tough: 9999999999999999635896294965247 in range(int(10e30)) returns `True` instantly. Simply an efficient `__contains__` probably.
This is really a compiler-level optimization, and if you're in a use case where it makes an appreciable difference, you probably need to use something more low-level than Python in any case. (Er, no pun intended.)
Even though some languages do this, it is not categorically true. When the case expressions are static, the compiler can use [perfect hashing](https://en.wikipedia.org/wiki/Perfect_hash_function) to create a jump lookup table instead of iterating over the cases.
**Perfect hash function** In computer science, a perfect hash function for a set S is a hash function that maps distinct elements in S to a set of integers, with no collisions. In mathematical terms, it is an injective function. Perfect hash functions may be used to implement a lookup table with constant worst-case access time. A perfect hash function has many of the same applications as other hash functions, but with the advantage that no collision resolution has to be implemented. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/Python/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.27
Some IT person who is considering learning Python and probably doesn't know any other legit languages has no reason to know about the Turing completeness of Python. You know exactly what they meant when they asked if it was more powerful. We say that C is more powerful than JavaScript all the time and they are both turning complete. Stop being annoying and help this person.
And sometimes individual functions might be completely overkill for what each case is doing.
+1 for pattern matching. I think switch is just an older idea, pattern matching addresses the same issue but much more elegantly.
not just rudimentary - its the recommended way to do it if you don't want a very long if/elif construct.
I think doing some pre clean up may help. I remember reading something about in this blog https://www.pyimagesearch.com It is in my rss and every now and tgen he blogs something anyony with basic python can try. The hardest seems to be installing the tools like opencv :-)
You may want to look into [tesseract](https://pypi.python.org/pypi/pytesseract) and [openpyxl](https://openpyxl.readthedocs.io/en/default/)
Yes, there are a bunch of projects aimed at this sort of thing, each with different emphasis (2D/3D, desktop/web, etc), some of them build higher level APIs over others. Some possibilities: - Chaco - Bokeh - Holoviews - PyQtGraph - Vtk - Mayavi 
Been writing python for awhile now, based on the title didn't think I would learn anything, but I stand corrected. Furthering my zen of python...
And that allows you to write it as if 0 &lt;= x &lt; 10: do_a() elif 10 &lt;= x &lt; 20: do_b() Which isn't possible with this module. Not saying I think something is wrong with it, it just seems to solve a problem I very rarely have in Python.
In the section about "How do I break out of two loops?" and "Make the double loop single" You could use itertools.product(..) instead import itertools for col, row in itertools.product(range(width), range(height)): print "Col: %(col)s - Row: %(row)s" % {'col': col, 'row': row}
Great guide, was just looking for better way to do this with ubuntu.
It sounds like you'll need to run OCR with something and then add extra steps for extracting data and converting it to the format you want. Once you have the text version you may be able to use pattern matching (take a look at regular expressions) if your data follows a certain format. If your data is split into lines that start with a reference number made up of two upper case letters and eight numbers (purely as an example) you can make use of that! It's often easier to describe the data you want and discard the rest rather than try to clean up garbled OCR output from handwriting. The best free OCR software I know of is [Tesseract](https://github.com/tesseract-ocr/tesseract/wiki), but it'll still give garbled text in places without training. It *is* command line based though, so it's simple to use from a Python script or similar. If you need accuracy take a look at Abbyy FineReader or OmniPage on Windows. They're both desktop applications but OmniPage has an undocumented API if you want to play around with that.
When optimizing, it's common (and best) practice to optimize the parts that are most costly (the hot spots). Simple logic constructs aren't going to be hot spots. The system simply doesn't spend enough time on those. It's wasted effort.
No.
The funny thing is, everyone wants to do functional programming in their language of choice. But when you suggest Haskell, and ask people to actually do things the right way, they just run away. 
I agree that switch should be added... just not like this. 
Don't really get the argument against conda. You can just use conda to setup a 'base' environment (whatever packages you'd otherwise install with apt-get or so), and then use pip install -r requirements.txt as you'd do in a 'normal' virtualenv. So, when sharing your environment you don't introduce any friction, because they can choose to use whatever method they want to setup their side. Or am I missing something? 
Some people just aren't ready.
Haskell isn't the "right" way of doing functional programming, and it's not even the only language that follows the FP principles. Having worked with it on a daily basis, I can also attest that it has its fair share of warts and legacy badness on a scale that's more cumbersome than, say, handling Python 2 &amp; 3 with the same codebase. I feel like most people who reflexively praise Haskell only do so from a fair distance :)
And that `if` is basically a `goto`. Yes, the use case for switch can be modeled by other instructions, however, it does express a particular intent better than a chain of `if`'s. There's a big subjective component to it, affected by the kind of code one is used to read and write. For some programmers, `for`, `while` and `do ... while` are just verbose variations of the same concepts; for others, these minor differences do matter. &gt; I'd rather Well, if we can have a wish, what about the DWIM instruction?
The point is whether the performance improvement would be significant or negligible within the general speed of Python. It is not worthwhile to add a new language features for a negligible performance improvement.
Just worked on a quick [Brainfuck interpreter](https://github.com/jochasinga/py-brainfuck).
itertools is awesome. if you ever have an interesting iteration problem browse the itertools docs and it'll have something. there are also a ton of recipes for common problems (and inspiration) on bottom of the page: https://docs.python.org/3/library/itertools.html#itertools-recipes
/r/learnpython
&gt; * prefer pure functions &gt; * no classes (aside from named tuples) I like this approach too, though it find occasionally useful to convert large functions into classes of one-off objects (rather than modules with loose functions). This way, I can make the state-sharing between the smaller functions (methods) explicit, essentially having `self.foo` denote what `foo &lt;- ask` or `put foo` does in Haskell with `State`/`Reader`/`Writer` monads.
Ok! I will
`iter()` and `map()` have some really cool secondary uses if you pass multiple parameters: https://docs.python.org/3/library/functions.html#iter with open('mydata.txt') as fp: for line in iter(fp.readline, ''): process_line(line) https://docs.python.org/3/library/functions.html#map for area in map(operator.multiply, heights, widths): print(area)
I'm following http://composingprograms.com/ and doing the associated projects and I'm finding it fun and useful. It teaches cool stuff about programming in general (functions, higher-order functions, abstractions, declarative programming, OOP etc.) using python along with teaching python itself, and the projects are very scripted so that you don't get lost in trying to tackle a project from scratch if you're a beginner, there's hand-holding and the work is broken up in pieces and unit tests are available for each exercise. They're also limited in scope and meant to solidify the concepts that are learned in the relevant chapters. I'm feeling I'm not just learning a syntax but also some general concepts that I didn't know before. It starts from scratch since it's meant for a beginner's CS course, so even if you don't have previous programming knowledge it should be doable (I already knew stuff but had never studied it formally). 
&gt; Python is compiled into bytecode, you could do the optimization there. And people wonder why I insist on using "transpilation" for anything that doesn't output Assembly...
For simple repeating messages, you can use realterm, it has several more features including the possibility to set a message and have it sent periodically. But it seems you want to do more advanced stuff so this is not enough. I've done this before in Matlab and it was really easy, with a google search I found out that you can do the same in python by using PySerial. You just have to learn a few instructions to open the serial port you want, set the proper settings (baud rate etc.) and write to it, it's all in the documentation. 
Why not a chloropleth? Bokeh has good support for geojson formats. Edit: example here: https://bokeh.pydata.org/en/latest/docs/gallery/texas.html
The data is obviously not valid. Show us the code, so we can help you figure out where you corrupt the data.
It still gives an example with `range(6, 7)`, which could be less-confusingly written as just `6`.
If it can't even read the header my guess would be that the data is being "corrupted" as it is read - make sure that you are opening the file in binary mode! 
Not sure how it would work in Python, but pattern matching looks similar to switch at first glance. match n { 1 =&gt; ... } But it's much more powerful as you can use it to destructure as well: match n { (x, y, z) =&gt; # do stuff with those three x:[xs] =&gt; # x is the head, xs is the tail, useful for recursion SomeNamedTuple(a, b) =&gt; #extract a and b but if only they're nembers of a particular type } and so on. Most languages I've seen will shout if you didn't match all members of an enum or ADT (algebraic data type, union essentially if you've not seen them before). The other big difference is that there's no fall through with match, so while you can't implement things that rely on that behavior (loop unrolling for example) you can't accidentally invoke that behavior as well. As for uses, let your imagination run wild with what you could do with it. 
Basemap or cartopy.
Then maybe we should let it die and focus our attention on something that already does the job better.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/functionalprogramming] [Functional Programming in Python â€¢ r\/Python](https://np.reddit.com/r/functionalprogramming/comments/70985t/functional_programming_in_python_rpython/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
I've started doing the projects at pybit.es. They give you a good introduction to the different libraries and their uses.
That's not fall through. Fall through is matching a case, executing the code block, and then matching another case and executing that code block. This continues to happen until you either don't meet any cases or you match a case that ends with a break. It's extremely useful but also a potential hole to break your leg in if you don't notice it.
Agreed on The Django Book.
How about { 'a' : do_foo, 'b': do_bar }.get(arg, do_default) Edit: I'm on mobile, but you get the idea
 I found [this one](http://basemaptutorial.readthedocs.io/en/latest/plotting_data.html?highlight=map.urcrnrx#contourf) but I'd want to consider other options too. I realized chloropleth isnt the graph I'd want to use for my data :) 
Ok, so like a contour map but with some data other than elevation represented by the contours?
The best website to learn Python is the one you build with Python. Dive in! Follow a getting started with Django tutorial and by the end, you'll know enough Python to get you going.
I'm using windows but I don't know if any default package installer. I've tried installing anaconda and miniconda but when I use their command prompt to install packages from their cloud, it successfully installed the packages, but they don't show up in PyCharm. Even when changing the interpreter, anaconda or miniconda doesn't show pandas or any other package I installed. So I'm lost 
Long time ago they are web name PythonMonk, but it's dead now ðŸ˜­
&gt; Switches are [; O(1) ;] jumps to conditions. If statements are [; O(n) ;] evaluations. A good compiler will generate O(1) access to the relevant conditional sequences, meawhile non-trivial switches (e.g. on strings) will not.
Link: https://i.imgur.com/P6CHEwp.png ^(This is a bot that automatically converts LaTeX comments to Images. It's a work in progress. Reply with !latexbotinfo for details.)
Performance improvements to CPython are awesome. Prematurely optimizing your code by using one syntax over another is bad and typically costs readability. If someone sees that CPython should have a heuristic for treating cascading if/else as a switch then they should write a pull request to CPython 
&gt; I'd rather see implementations of pattern matching ala Rust, Haskell or Scala. Note that they're not necessarily orthogonal: in Swift, pattern matching is done with `switch`.
It's the same as Rust's `match` or Haskell's `case` with a more C-familiar switch/case syntax e.g. switch foo { case .some(let v): // do stuff with v case .none: // there was no value } would be Haskell's case foo of Just v -&gt; -- thing None -&gt; -- other thing Though Swift does support opt-in fallthrough (default is break).
It _is_ forced, but I have been doing it with some success for about a year now using - pymonad library which gives you Maybe, Either, State and a few others - pymonad-extra, in which I added Task, Validation, and some typical helper functions - adt.py, a library I wrote approximating sum and product types including matching on sum types - I wrap I/O in a Task, and exceptions in a Task or Either - I use a @curry or @curry_n decorator for partial application, there are several implementations out there - don't mutate collections unless they are only referenced in a single scope. It seemed a bit crazy at the beginning but I am much more confident in my code written in this style now vs typical oo style python. Even without type checking. You may also want to check out Coconut, which has an MLish syntax that transpiles to python.
&gt; ADT (algebraic data type, union essentially if you've not seen them before). Technically that's a sum type, "algebraic data type" means composite, which can mostly be either a sum type (variant/enum) or a product type (struct/tuple/class/â€¦).
It depends on the subset of functional programming features you're planning on using. For example, expressing your program with pure functions is very much doable, since functions are first-class citizens and you can pass them around, export and import them, etc. Crippled lambdas are a slight pain but don't create a lot of problems since you can always just define a function with `def` in your local scope where you need a lambda. Immutability on the other hand is a bit problematic. I like to use immutable `namedtuples`, but other things like dicts force you into mutating them, and trying to write immutable code seems indeed forced. I had a positive experience with [pyrsistent libary](https://github.com/tobgu/pyrsistent), however you have to remember to convert `pyrsistent`'s data types to vanilla data structures sometimes (e.g. when serializing them).
where can you download a 105GB python
Nice post..thanks for sharing the tutorial...
I've talked to Ned a bunch on IRC and I would say that anything he writes probably merits reading.
Try Google vision on a few of the images here https://cloud.google.com/vision/ If that doesn't get the information out, there's probably not a program that will help you.
matplotlib has a geojson/leaflet addon
its not a giant one-liner, thats as silly as calling C code always a 1 liner, just because the syntax allows for new lines to be removed
Maybe I'm just novice when it comes to ggplot2, but I have a hard time working the aesthetics of my figures into publication-ready forms, whereas when I use my matplotlib/seaborn/cartopy stack, I routinely receive praise for figures which truthfully are only customized a little bit (less aesthetic lines of code than production lines of code).
The recipes and other goodies are available as [more-itertools](http://more-itertools.readthedocs.io/en/latest/) which can be installed with `pip`.
Just wanted to share this. It really questions how we often blindly trust the software we download through tools like pip. Like it says in the article, the malicious code isn't anything harmful to your system, but it's still good to get rid of any of these illegitimate packages. It almost seems like someone was just trying to collect statistics on how many people could have been tricked by this. 
~~Top~~ 5 Useful Python Libraries **for** Web Developers ~~Can't Live Without~~ FTFY
Thatâ€™s an awfully odd grouping. Requests for web stuff? Absolutely! Scrapy? Well, ok, if youâ€™re doing *that* kind of web stuff. Zappa? Cool, but I live without it. Tensorflow? Now the authorâ€™s just naming things. 
TL;DR - [Scrapy](https://pypi.org/project/Scrapy/) - [Zappa](https://pypi.org/project/zappa/) - [Requests](https://pypi.org/project/requests/) - [TensorFlow](https://pypi.org/project/tensorflow/) - [Boto3](https://pypi.org/project/boto3/)
It's almost like people don't want to learn two completely new things at the same time. I mean, crazy, right?
If on IOS I can attribute a fair bit of knowledge to an app of the name Learn Python
You mean there is an app on iOS with the name of learn python 
Pyserial it's great
^^Thats ^^what ^^he ^^said ^^he ^^said ^^thats ^^what ^^he ^^said. ^^Thats ^^what ^^he ^^said ^^he ^^said ^^thats ^^what ^^he ^^said
It just doesn't make sense to me to talk about the time complexity of something that would almost never contribute to the time complexity of your task. It's the task that one might scale some day, not the number of cases. Unless it is, then that makes sense, but it never has been in anything that I have worked on.
&gt; `math.__dict__` You shouldn't access `__dict__` directly, Python has a built-in function for that: `vars(math)`.
I think to remember the same or similar problems surfacing years ago. They used similar names as well as far as I remember. Has this not been fixed properly? I guess other than inspecting code in some way (like an app store does) this would be very hard to fix anyway. There is always a risk when using external code, so better tripple check what you use!
Yes it is, it's just very small n. And as they say, everything is fast for small enough n. If you have a ginormous chain of `if...elif...elif...elif...elif...` (say, from generated code, or the guy who wrote it was an idiot, or its just a very yucky problem to solve and you have no choice) then the performance of the entire chain is O(n). On average, assuming each branch is equally likely, you have to make n/2 comparisons, which is O(n). But if you [have an optimizing compiler and use a switch statement](https://www.codeproject.com/Articles/100473/Something-You-May-Not-Know-About-the-Switch-Statem), that might be optimized into a binary search (O(log n) comparisons) or even a jump table (O(1) comparisons). What if you don't have a ginormous chain of comparisons to make? Well, in C, the compile can often optimize even short chain of comparisons. That's why C is so fast: if you save enough microseconds, they add up to minutes. But in Python, its unlikely to make such a dramatic difference.
Really wish we could get Pypi cleaned up a bit, it's an absolute mess IMHO. No consistent naming conventions (is it `python-foo` or `pyfoo` or `pyfoo3` or just `Foo` that I need??), tons of seeming duplication, no way to determine which is the "official" package for a project. I wouldn't be surpised to see this attack vector continue to be used. Is there any vetting system in place?
Interesting suggestions. pymonad looks cool at quick glance. Ill have to dive into it this weekend.
Ah cool. A lot of these also turn up in libraries like [funcy](http://funcy.readthedocs.io/en/stable/cheatsheet.html)
This is an old issue. There's actually a [premade framework](https://github.com/fate0/cookiecutter-evilpy-package) just to build these types of packages, and they upload your info to [shame you publicly](http://evilpackage.fatezero.org/). PyPi has no security. Anyone can upload anything. No one's verifying or auditing uploads (really, no one practically could). Check your `pip install` commands for typos, check the packages you're downloading before you type stuff in. *Caveat* package installer.
/u/futatorius got at the core of the idea. Perfomance improvements that don't get at the core bottleneck of your program will usually have a negligible effect on overall performance. If you *are* going to do performance optimizations, the switch statement is just not the place to start - they're basically never going to be the bottleneck. I'm all for optimizing Python, but I'm not for adding language constructs for gains that will basically always be negligible.
That looks pretty good. Thanks for the example
PyPi could do something similar to what many Linux distros do: have a core "official" repository containing vetted code and signed packages maintained by trusted packagers. Then have a "community repo" where anything goes. `pip` could issue appropriate warnings or require an extra flag to access community repos. I have no stats to work with, but my guess is that the 80-20 rule applies to PyPI, and 20% of the packages account for 80% of the downloads (just think how many people are downloading `requests`, `flask`, or `pyqt` every day). If that's true, having those proverbial 20% in some kind of trustworthy, vetted repository would make a big difference in terms of security.
GIL improves performance. See GILectomy
Cython
Nope. It's really easy to upload a package named 'djagno' or 'beatuifulsoup' or something and wait for someone to make a typo. There's no distinguishing good and bad. Packages can have different import names than PyPi names, too (which is probably a bad idea, but hard to enforce) so you might not notice until you `import` it, at which point it gets to run whatever code it wants.
My company tells me what languages I can use :( 
&gt; Cython A superset of a subset of Python that is transpiled to C or C++, if possible. If not, it's interpreted by an integrated Python interpreter/VM.
There's a ladder of abstraction. I found it way easier to think about monads in elisp or javascript because my brain somehow had something tangible to chew on. In haskell is pure ideals and concepts. In the end it's the same thing but all of a suddent you're off the wheelies and on the wire.
I came from Autohotkey (very similar language). I was doing webscraping, GUI's, and IECOM stuff. I even wrote a bit of a [monster of a program](https://github.com/k33k00/T-Enhanced). I'm currently rewriting it in python but using chrome instead of IE. I'll admit it has it's challenges here and there, but overall the language is cleaner, there is an agreed upon format to the code (pep8). Also the sheer amount of modules out there that can help you get the job done is amazing. I'm currently using selenium (web automation), tkinter (gui) though I have messed with flask and considered it being a web app, Along with a few things here and there. Honestly I'd recommend ditching AutoIT and join the huge python community. It's honestly just so much simpler to get things done. 
Im downloading on a mac if thats any different
It's not. Where did you get that info from?
Going to Python 3.6.2 for Mac
Please provide the link that you are using, which suggests the python installation is 105 Gb. As others have mentioned, irregardless of the OS and python version you are installing, the download should be relatively small.
It's such a shame that Python itself is so big and complex. While no small feat, LuaJIT is an extremely efficient and *relatively* simple VM, whereas creating an equivalent for Python is... considerably more difficult.
The problem here is pure and simple lack of resources. PyPI is maintained by one or two people working on a purely volunteer part-time basis. There's no way to review packages without a much larger team. If someone were to set up a curated index that contained a subset of vetted and trusted packages, then people could use that. Obviously trust has to be earned, so it's a gradual process, but there's nothing stopping anyone interested in providing such a service from doing so.
lol!
https://developer.apple.com/library/content/documentation/Swift/Conceptual/Swift_Programming_Language/ControlFlow.html use the `find` browser feature to look for the subsections titled `interval matching`, `tuples`, `value bindings`, `where`, and `compound cases`. Those subsections are all after the start of the `switch` content section. Or just read it all. That works, too. Swift enables you to include some very complex logic in switch statements that you won't find in most other programming languages, so it might be worth it to read it thoroughly.
Probably a more scalable approach would be to have developers publish their keys, and have pip run in a default mode where it only installs packages signed with known trusted keys. Yes, you have to visit websites to get various keys (or install a package that has a bunch of keys ;), but it will protect against typos. 
Thanks for sharing this. It's really a shame to see this happening but in retrospect it's not surprising. I try to stick to using the official conda repository for downloads (I use anaconda python) but occasionally need to install lesser known ones using pip. I remember just recently installing urllibâ€¦ need to double check I spelled it correctly now.
I mentioned this in another post, but basically code reviews are too labor-intensive to scale up. But what can work is a reputation score that pypi should maintain - based on the age of a package and how many other packages refer to it. Then disallow any new projects to be added to pypi that are too similar to popular packages (use levenstein distance, for example, or just require name must be at least 2 letters different). This is like disallowing www.paypals.com, but in our case it would be disallowing 'reqests'. Then also provide default behavior for pip to prevent importing of any package that's less than 3 months old or with a high suspicious score unless an override option is provided. Then we should also have the ability for pypi contributors to flag a package as malware. Their labeling, when combined with the popularity of their packages could be included in the reputation score. This could be how we could non-anonymously review &amp; respond.
It's good you did share it. Highlights several problems such as lax supervision, if any, a lack of funding and resources for the maintainers, but also operator error in that apparently 100% of these are misuse/misspelling. There's blame all around.
Is this on-site only or would you be open to a remote hire from continental Europe? e.g. Native English speaking EU Comunitarian in Spain
At the very least. It's beyond absurd how anyone and their dog can upload "PyGame" or any spelling variation and get it uploaded and accepted. Sure, some level of user-error exists, but realistically, any of us could fall for this relatively easily.
If your goal is readability and you like switch/case...why not take it one step further: with switch(value) as case: case([1,3,5,7], do_odd_stuff) case([0,2,4,6], do_even_stuff) case.default(do_default_stuff) Then instead of `switch.case` as your function, just override `__call__`. Or even offer both I guess. 
It would also help if there were a way to manage, update and query virtualenvs like one can with a deb package. It would make it simpler to remediate bad versions when theyre found.
why would you do `pip install urllib` ?
Do you pass a value for the keyword argument *wbits* ? If you want to decompress gzipped data you should try zlib.decompress(data, wbits=25) 
Text of the site: Hi bro :) Welcome Here! Leave Messages via HTTP Log Please :) GeoIP places it in Hangzhou, Zhejiang, China, Asia nmap: Not shown: 991 closed ports PORT STATE SERVICE 80/tcp open http 135/tcp filtered msrpc 139/tcp filtered netbios-ssn 445/tcp filtered microsoft-ds 593/tcp filtered http-rpc-epmap 4444/tcp filtered krb524 5800/tcp filtered vnc-http 5900/tcp filtered vnc 8080/tcp open http-proxy Device type: general purpose|storage-misc|firewall Running (JUST GUESSING): Linux 2.6.X|3.X|4.X (96%), Synology DiskStation Manager 5.X (90%), WatchGuard Fireware 11.X (89%) OS CPE: cpe:/o:linux:linux_kernel:2.6.32 cpe:/o:linux:linux_kernel:3.10 cpe:/o:linux:linux_kernel cpe:/a:synology:diskstation_manager:5.1 cpe:/o:linux:linux_kernel:4.4 cpe:/o:watchguard:fireware:11.8 Aggressive OS guesses: Linux 2.6.32 or 3.10 (96%), Linux 2.6.32 (95%), Linux 2.6.32 - 2.6.39 (94%), Linux 2.6.32 - 3.0 (91%), Synology DiskStation Manager 5.1 (90%), Linux 3.2 - 3.8 (90%), Linux 2.6.32 - 2.6.35 (90%), Linux 4.4 (90%), Linux 2.6.39 (89%), Linux 3.4 (89%) No exact OS matches for host (test conditions non-ideal). Network Distance: 22 hops 
I remember it was with weird keyboard shift + arrows or something, and only straight vertical squares. If thatâ€™s changed, Iâ€™ll gladly check it out again.
the checking code pip list â€“format=legacy | egrep â€˜^(acqusition|apidev-coop|bzip|crypt|django-server|pwd|setup-tools|telnet|urlib3|urllib) â€˜ gives this error &gt;bash: syntax error near unexpected token `(' 
Would it actually be a performance improvement in Python? In C the processor executes a jump command and that gives you the speed up, but in Python there's much more overhead in just running a single line that I'm not sure if the same benefit would even manifest itself.
It appears this doesn't work on pdfs.
Hey! I actually wrote exactly that. But two things stopped me. 1. Mostly I don't like case.default() but seeing it a second time it's not bad. 2. It's more typing. s. immediately pulls up case and default whereas it's slightly more this way. I know that's weird but with minor RSI issues it does matter a tad. Not that this is best for the library, but my first take it factored in. 
Well, to be clear: this is a library. I don't even want switch added to the Python language. You're free to fork it and do something else.
Not yet, was waiting for some feedback, etc. I plan on doing so if there is enough positive response to this. Seems to be the majority of people like it but there is definitely pushback too. Some people seem to feel I'm suggesting this as a language feature (I'm not) but as an opt-in library, I like it.
Yeah, I guess the ideal is out of reach for us, but honestly any of these ideas would be a significant improvement. Given the fact that Python has become one of the top languages for education and new learners, and that PyPi has become the de-facto way to get libraries (and in some cases, the only way to get them without compiling), a few safety barriers would go a long way.
Thanks. I have no intention of proposing this as a language feature. I think the library is good enough and it works everywhere. People can use it if they like it or avoid it if they don't.
The switch has a 'return' value. with switch(val) as s: case(...) case(...) default(...) computed = s.result That means you usually don't have to do this global / nonlocal trick to change local variables. Just set them to s.result.
Change the enclosing ticks to single quotes. Someone probably put that line through a word processor or CMS at some point.
If you're using python 3 you'd be okay as the packages generated errors
^(Hi, I'm a bot for linking direct images of albums with only 1 image) https://i.imgur.com/Rdouzcs.png ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) ^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20dn1rcyb) 
README.md for hot new library posted to SlashHackerNewsIt: If you're using anything but the absolute latest Python 3.7 beta you'll need to update urllib from pip. Random J user: pip install --upgrade urllib Seems reasonable.
Files don't work that way; you can't just change part of the file. Your best option is to read the entire file into memory, change the data as needed, and then rewrite the entire file. --- If you have more questions like this it's better to post them on /r/learnpython. Be sure to [format your code for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) or use a site like pastebin (don't use screenshots; they are hard to read and impossible to test). Also, include which version of python and what OS you are using. 
it can already run arbitrary code on `setup.py`, can't it?
TIL That's great to know!
Then use a lambda. Still a little unwieldy, but better than nothing.
Have you tried...asking him?
If it wasnt easy to upload it would not exist. Not enough people would use it, and it would never have grown into the defacto standard. And unless PyPI can expend the effort $$$ to harden, monitor, and report when breaaches or other security issues occur then it is FAR BETTER to have assumed insecure system than have a system people trust when it is not actually secure. No security is better than false security.
Ctrl+D now selects the next instance of the word you are under. (like sublime) And now you can also Ctrl/Alt (not sure tbh) click anywhere to place cursors.
Tensorflow for web development?
No. Do fucking not do this. I REPEAT, DO NOT FUCKING DO THIS. 
Why is this nsfw
Think about it.
You think he would take it seriously? The rm joke is now so old anyone should get it.
here you go: https://imgur.com/A08qj1u
True... `s` `.` `Tab` *is* one less keystroke than `c` `a` `s` `e`. I see your point though--autocomplete is often overlooked and benefits discoverability as well. I'm in agreement with the idea that Python doesn't need `switch` in the language but I like this as a useful tool for some cases. 
I did not learn anything - give me more what happens under the hood
What if your experience is on VAX/VMS or some other OS and you haven't a clue what this mysterious `sudo rm -rf /` actually means or does?
I use LeetCode for practicing interview questions. I find it useful to know that certain questions have popped up in interviews, and general tough questions are useful when prepping and knowing the different ways to approach them.
bad bot
Thank you kyndder\_blows\_goats for voting on LatexImageBot. This bot wants to find the best and worst bots on Reddit. [You can view results here](https://goodbot-badbot.herokuapp.com/). *** ^^Even ^^if ^^I ^^don't ^^reply ^^to ^^your ^^comment, ^^I'm ^^still ^^listening ^^for ^^votes. ^^Check ^^the ^^webpage ^^to ^^see ^^if ^^your ^^vote ^^registered!
Just look at the original post. Someone want to learn sql for a job interview in 3 days. And all he has is a background in python. That's just a waste of time trying to learn sql, which won't fool the recruiters anyway. He should better focus on the stuff he knows and on communication skills. My joke is of course of terrible taste but that's sarcasm.
Yeah fair enough. It's easy to just do what's in the readme's blindly. Let this be a reminder to not do so.
Thank you
I'm attempting to teach my python bot how to form natural sounding sentences. Right now, it currently messages sent through a chat program, but I'd like to expand it further for faster learning. I'm currently planning on using the markovify library to do the actual sentence generation. Are there any tips, advice, or ideas you have for doing this better?
It's unmaintained unfortunately... but generally works fine and has a test suite. I maintain a fork at https://bitbucket.org/ericgj/pymonad And this is the link to my [pymonad-extra](https://bitbucket.org/ericgj/pymonad-extra).
 https://pypi.python.org/pypi/geocoder was used in a project where I contributed to. The only downside is the limitation on how many free api requests are available. (The limit is around 2600) You can work around this limitation by using open proxies. The project converted the addresses of all German amateur radio operators to lat / lon. Took a while, but wasn't even using all proxies. 
I also got one for you, it's called if/elif/else, it goes something like this: if cond1: print(1) elif cond2: print(2) elif cond3: print(3) Jokes aside, I think the example in `python-switch` is quite nice.
https://github.com/ustudio/storage
&gt; Prematurely optimizing your code by using one syntax over another is bad and typically costs readability. Cascading ifs would actually be a premature optimization of using a switch and switches are usually considered syntactically cleaner than if chains anyways. Basically ever other language posits the exact opposite.
For you all, here is corrected version. `pip list --format=legacy | egrep '^(acqusition|apidev-coop|bzip|crypt|django-server|pwd|setup-tools|telnet|urlib3|urllib)$'`
Yes, it can. Wheels can be installed without running any code from the package, though. If they become common enough, one day you might need an extra option to allow installing from an sdist.
I'm not sure about that. Realistically how many of us have the time to devote to complete review of all packages before we start using them? In some environments a complete audit is required, but most don't have the resources for it. A reputation system has its drawbacks but would be a step in the right direction for those of us who realistically can't vet every single package we install. 
That's a significant extra load on both package authors (who have to use consistent keys and keep them safe) and users installing them (who have to visit a website for each thing they want to install, find a key, and copy/paste it). You also probably have to radically change the way dependencies are handled in Python. If you didn't, users would be looking up not just the key for the package they want, but the keys for all its dependencies. In practice, I suspect people would want something like the package you mention with a bunch of keys - someone to tell you who you can trust. But who? It's a massive job, and whoever does it is going to be massively criticised as soon as someone 'trusted' uploads a dubious package.
Sure, but what if you want to change the value of variables within the scope of the switch context, for example? You may want to have more logic than a single line in a switch statement, which is why you can always define a function separately and pass it to case. However, that function may need access to the local namespace and thus, I think it makes more sense to have each case return their own unique value so as to alleviate the problem. if_this = None or_this = None with switch(val) as s: if_this = s.case(...) or if_this or_this = s.case(...) or or_this s.default(...) Personally, I think the real answer to my question is just to use an `if/elif/else` block
nothing is stopping you from building that reputation tracking site and a fork of pip that queries it. you have approximately the same level of funding and free time for this project as Donald Stufft.
is Crypt different from cryptography (1.7.1)? the command returned "cryptography (1.7.1)", so just wanna know if that's a bad one. 
And everywhere on the web you still see people teaching to do 'sudo pip install' :facepalm: I often see co-workers or random people try 'pip install' and the second it fails run it with sudo without considering the consequences. For completeness, you should go with 'pip install --user' to install a package for the current user, without running unknown code under sudo, and only install with pip when you have to install a package globally and after verifying the package and it's setup process. 
Reminds me that it needs updating for Python 3.
&gt; this isn't a serious attempt at adding switch/case to Python because it's a terrible idea... ^ this That said, your library is pure evil. I love it
&gt; Then disallow any new projects to be added to pypi that are too similar to popular packages (use levenstein distance, for example, or just require name must be at least 2 letters different). This is like disallowing www.paypals.com, but in our case it would be disallowing 'reqests'. This breaks open source. Open source only thrives if bonafide forks have a viable chance of usurping the original. Every barrier to entry erodes at this.
Some great ideas for solutions to this problem in general in r/rust: https://www.reddit.com/r/rust/comments/70aq3b/_/dn1qr20
You're not wrong, and I know none of us is individually in a position to do much about it, but as a community "caveat emptor" seems like a cop-out. As a community we either need to stop treating PyPi as the true and blessed source for libraries, or we need to step up and make it worthy of such distinction.
Was wondering this as well, although mine shows 1.8.1.
Prompt: ***Warning: Did you mean ... ?***
Agree. It's hard to prevent malicious code to be committed to pypi. But there could be tools based on popularity, downloads, rateing ect. When then installing a lib the tool could ask for confirmation when trying to install a unverified/unrated package. However, I think it's a good idea to just think before when installing libs without knowing of them. The same mentality that you would just not install any executables downloaded from the internet.
I'm just learning Python. Going to put in a system to store all of our images in our fashion business ordered by garment. This will be everything from a scanned initial sketch, through to the product images and campaign images. I want to pull in sales data and Google Analytics data to show product performance. Plus a reporting system.........
The community was warned about this a long time ago, e.g. http://incolumitas.com/2016/06/08/typosquatting-package-managers/ No action was taken to try to prevent this type of thing though.
Studies have shown that lots and lots of python users try to install modules included in the standard library from pip.
Interesting. So the deal with the site -- it's just fingerprinting the computers that visit it? Maybe this is some sort of experiment by a security researcher. Who knows.
Just because you write it doesn't mean pypi has to host it (at least automatically).
Official repositories of Linux distros tend to be vetted, signed, etc. 
See line 738: https://github.com/pydata/numexpr/blob/numexpr-3.0/numexpr3/ne3compiler.py It's a Python switch that uses a `dict`. The keys are abstract syntax tree nodes, and the values are functions `_ASTAssembler[type(node)](node)` NumExpr 2.6 took about 450 us to parse a numerical expression into a virtual machine program, this new version is about 150 us. There's other parts to that, such as more efficient string concatenation using a `ByteIO` stream, and some `struct.pack()` tricks and many other micro-optimizations, but it plays a big role. A `dict` lookup is faster than an `if ... elif ... else` block.
Sure. But what's your solution?
After reading your response I did some additional research and found that [SQLite3 supports type affinity](https://sqlite.org/datatype3.html). So if I define a column as numeric and pass in a string that looks like a number, it will convert that string into number. That makes a lot of sense considering the results of my experiment below. Type Affinity also appears to explain why SQLite is cool with me defining a column as DECIMAL(13,2). That is interpreted as NUMERIC according to the table in 3.1.1 of the previously linked documentation. Notice that in my code, I define AMOUNT_USD with a Decimal(13,2) data type when I create CHARGE_HISTORY in SQLite. When I use PRAGMA to describe the table, SQLite tells me that the column is a Decimal. That's a little weird because according to SQLite documentation it's interpreted as NUMERIC. I'm guessing the explicit type name I defined is retained to limit confusion? Not really sure. cur.execute('PRAGMA table_info([CHARGE_HISTORY]);') for row in cur: #prints individual lines print(row) &gt;(0, 'ACCOUNT_NUMBER', 'VARCHAR(50)', 0, None, 0) &gt;(1, 'AMOUNT_USD', 'DECIMAL(13,2)', 0, None, 0) The workaround I developed from your suggestion is to cast AMOUNT_USD to VARCHAR() in my SQL Server query. That allows the data to be successfully inserted into CHARGE_HISTORY in SQLite. It looks like type affinity converts these string values into decimals before inserting into the table because the resulting data output from CHARGE_HISTORY is in decimal format. cur.execute('SELECT * FROM CHARGE_HISTORY') for row in cur: #prints indidivual lines print(row) &gt;('1005645', 180.00) It is kind of weird that my tuple no longer has the Decimal() wrapper to display a decimal value. Maybe you can help explain that one to me. Finally, doesn't all of this imply that the problem is not that SQLite doesn't understand decimal but rather that SQLite is reading the literal value "Decimal('180.00')" value with the wrapper, which ultimately causes the exception?
Open source only thrives if bonafide forks have a viable chance of usurping the original. Every barrier to entry erodes at this.
&gt;because it's a terrible idea... why?
Can you filter the obstructions or circles by color?
The long answer is [PEP 3103](https://www.python.org/dev/peps/pep-3103/). I think the short answer, however, is that it's unnecessary and doesn't add enough value to the language to warrant a change to its syntax. Since it isn't part of the language itself, any implementation by a third-party library will depend on the semantics of the library itself. It will just add one more dependency which will need to be understood and maintained down the road and wouldn't even really be adding anything valuable to your program. I would even argue that it would overly complicate and obfuscate something that should be crystal-clear -- control flow. 
[removed]
I use functional programming when writing jobs in Pyspark, and that's been a reasonably good experience for me and feels quite similar to interacting with Spark through Scala.
Unfortunately, no, in the real images the colors are basically identical because they are made of the same material.
Python: ROS = wiki.ros.org/ROS/Introduction or Python: Computer Vision = programmingcomputervision.com ?
The short version: leave it as it is. We know it's a problem, but it's a problem that's relatively easy to understand and exercise caution with. Any 'fix' would make a more complicated security model, and risk giving people a false sense of security. But there are some improvements I think we could make, if we see it as reducing the risk rather than fixing the problem. E.g.: - Installing a package with the name of a standard library module (urllib) could require extra confirmation. - Uploading new packages with a name very close to an existing package (request vs requests) could be blocked without special approval. I think this is tricky to check efficiently, but we like hard technical problems, right? ;-) - It could be easier to see metadata about packages you're about to install. If you think you're installing requests but only 2 people have downloaded it in the last week, you might stop and think again. In general, I don't think having a boolean 'can I trust this' marker is going to be practical. It's more useful to surface quantitative information for humans to consider: how many other people downloaded this? how many other packages depend on it? If you're helping a friend test a brand new package, you know it's OK if no-one else is using it, but it's really hard to automate that decision.
I suggest googling 'contour matching algorithms,' or seeing if the image processing library you're using already has some implemented. Create one 'stock' contour of a circle, and try to match it against the various contours you extract from the image.
It doesn't break forking, so long as you give your fork a sufficiently different name. Something like Pillow (fork of PIL) would be fine under this scheme.
My major problem with classes is misuse. Rampant misuse in online tutorials makes it a harder concept to comprehend than it needs be. 
AI is super cool but you have a ton of learning and reading to do before you can make anything useful most likely. So just be warned that if you're not super into it you might want to keep expectations low. If you have a strong programming background you might be able to train some stuff to do a thing in a weekend, otherwise expect months of work, and if you're asking about an excel macro then expect months https://www.edx.org/course/artificial-intelligence-ai-columbiax-csmm-101x-0
I'm not sure `Pillow (fork of PIL)` is an allowed pip package name.
We definitely shouldn't recommend 'sudo pip install', but running untrusted code in your user account is [not much better](https://xkcd.com/1200/). All the interesting data you care about is probably accessible without root. Evil code running in your user account can probably get root access anyway, if you have sudo permission and you're not totally paranoid. Just alias 'sudo' to a script that steals your password, sudo-s the command you gave it, and then sudo-s whatever it wants.
I have a good programming knowledge also this project takes one year. It will be my finishing project so I have 2 semester to finish it. Secondly, I can read and learn tons of article during this project I am really eager to do something useful Actually my expectations low because I dont know which way I go for in this project.. just need some guide maybe.. 
crypto and cryptography are different. ill spin up a VM and check out the spoofed ver of crypto and report back. 
Not a Python problem. The problem is with the Wikipedia API, it is only returning 50 results (you can confirm this by clicking on the link you supplied and viewing the results). 
No, the name is '[Pillow](https://pypi.python.org/pypi/Pillow)'. I was highlighting that it was a fork of PIL so that the difference in the names was clear. PIL to Pillow is a Levenstein distance of 3, assuming we do a case-insensitive comparison. So it wouldn't be blocked. If they called called it 'Pill', this proposal would block it.
Thank you for the unhelpful comments. I've been told to get a basic understanding in MySQL in the time given to show I can learn quickly and improve my knowledge. Was hoping someone might be able to give me some pointers to some helpful tutorials so I can try and get my first job after graduating uni. I'm also a girl, realise according to Reddit I probably should've stated this in my original post but thought I'd point out we can code too.
This information can easily be used to see if a particular organization (hint: govt) is ripe for infiltration. Knowing a particular machine in a particular organization reliably downloads your evil package is valuable. Valuable enough to sell without actually getting your hands dirty or doing anything illegal.
Both aiohttp and sanic support, more or less, the same features, but sanic has the nicer api. Sanic's codebase is also incredibly clean and easy to read. The downside of sanic, and any async-based web framework, is that the ecosystems are much smaller than those of the older, more respected sync frameworks, so you'll be writing a lot yourself. Async/await is still pretty new to Python. As for dealing with mongo, you'll probably want to take a look at [motor](http://motor.readthedocs.io/en/stable/tutorial-asyncio.html) if you haven't already.
Good thinking. Scary stuff!
Well, good luck, then. Tell us if you get the job. btw I deleted my poor comment. And I don't think that stating you're a girl would have made any difference. Programming skills are not related to gender.
Ok cool, your OP made it sound like you had minimal coding knowledge (which is totally fine), but if you know how to program then it'll be much easier. I'm learning AI stuff currently too using [scikit](https://github.com/aigamedev/scikit-neuralnetwork), but I already know how a neural net works which took a long time. Anyway good luck to you. I think you should try and start small with a well defined problem like "given 109 datapoints can I predect #110". Did you check out the EDX course I linked? Even if you know how to code well it's going to take you tons of time to make anything useful so just be prepared
Whats happening here? &gt; encd = â€;t=[0x76,0x21,0xfe,0xcc,0xee]; The " is never closed. Is this what is meant by &gt; The coding style of the added code snipplet (see Appendix A) makes it incompatible with Python 3.x. ?
This provides no value, there are other very popular threads on this topic. Please don't do that anymore.
We're only talking about name differences, right? You could still fork something and then rename it, no?
What's your background? How did you wind up getting a job interview? What sort of work will you be expected to be able to do? A few days is probably only enough time to get the most basic familiarity with what databases are and how SQL works. If I were in your position, I would just Google terms like "database tutorial" and the like.
I still prefer to use gevent for IO heavy applications. The latest releases have been incredibly stable, used with Python 3.6 That said, I'd recommend Sanic -- the API is cleaner, it's super fast, and there's a lot of development still being done. It's only going to get better over time.
I've just graduated with a degree in Mathematics, I was found by a recruiter online who has put me forward for a junior software developer role with emphasis on big data which would start with 12 weeks industry training. I did basic Python and MATLAB during my degree and so need to improve upon my Python for the interview as they're looking for progress and are aware I have no prior knowledge of databases. I am currently watching sentdex's tutorials which seem helpful! Just wondering if anyone can recommend some others ðŸ˜Š
That's a small consolation since the bug could affect python3 as well without much modification. We try to have a up-to-date stock python build with pip and virtualenv but leave it up to users to install additional packages in their own spaces.
Right, we trust repos more than individual packages.
I agree
Very cool, thanks for sharing!
I would recommend [Quart](https://gitlab.com/pgjones/quart) as it has the same API as Flask (which I think is the best API), and it supports many Flask extensions (can tap into an existing ecosystem). Disclaimers: I work on Quart, and it doesn't quite support all the [Flask extensions](https://pgjones.gitlab.io/quart/flask_extensions.html#supported-extensions), and it doesn't yet match the full Flask API (although it does do HTTP/2). If you are looking to develop a Quart extension that would be great :P.
Also why am I looking at a whole load of numbers with no explanation of what they all mean or how they were measured?
I prefer Sanic, but of course I'm biased...
If you check the home page (https://sites.google.com/view/energy-efficiency-languages/home) there is a link to a full paper with detailed description of it all
Lol
&gt; If it wasnt easy to upload it would not exist. Not enough people would use it, and it would never have grown into the defacto standard. &gt; No security is better than false security. Yeah? Well guess what: when it develops the reputation of being insecure, it will cease to exist as the defacto standard, as nobody will use it.
also try with laser.
That's a pretty tough question, but I wouldn't be surprised to hear it from a non-technical person like a recruiter. Within python there is mastery of the syntax that is often referred to writing "pythonic" code. Other aspects of proficiency could be your ability to adhere to the full development cycle in python (write tests, refactor, analyze performance). But part of the strength of python is in the available libraries. It's not realistic for any single person (even Guido) to have mastered every library since they don't all lend themselves to use in the same areas of study. This would be like asking a doctor where he would rank himself skill-wise without specifying a specific area of medicine. I think, for any programmer, their level of expertise is partially determined by the needs of the company. Having an expert in financial libraries isn't going to be helpful for a company that deals in building websites in django. If I were being asked that questions I would either ask (or maybe already know) what libraries they expect me to use if I was working for them and talk about how much I've used them in the past. Or talk about having learned new libraries in the past and how you would study up on any libraries they think you should know before your start date. Maybe touch on how many projects you've used python for, how many lines of code those projects were (roughly), or how comfortable you are in python compared to other languages you know. As to how you can level yourself up, it kind of depends what kind of python jobs you're looking to be qualified for. For starters, learn some of the popular built in libraries like doctest, logging, datetime, and containers which could be useful in many different subject areas. If you have a specific company you want to work at or an area you are interested in, learn libraries that are used in that line of business. Or just build literally anything that interests you or challenges you so that you begin to think in python.
Thanks!
But but venv...
Look at GitHub, they have no problem with identically named repos because they disambiguate by author. I also like how source forge shows recent download activity.
Good to know! I do use Python 3.
&gt; That's a pretty tough question, but I wouldn't be surprised to hear it from a non-technical person like a recruiter That's a very polite way of putting it. I'd call it a stupid question. It has a very low chance of getting an answer that actually reflects the skill of the applicant appropriately relative to answers from other applicants. It's basically a guessing game of how the average applicant will interpret that scale and a test of personal boldness. Maybe you are taking the question seriously like OP and reflect on it before answering, in which case most people would end up in the 4-7 range. Or you just really want the job and have already figured out that the interviewer won't be able to verify your reply anyway, in which case you'll likely answer in the 7-9 range. Answering 10 or below 4 is an obvious mistake unless the position explicitly allows such "extremes".
The difference is literally anyone can upload a package to PyPI. To add a new package to Debian, there's a much more formal process.
I put myself in 2-3 range because I've only been *really* coding Python for a year. And, the specific, I've only dealt with web development. I explained to him what my scale was: putting the creator of libraries at a 10 and new coders at a 1. Without going into the details of the interview, basically I got rejected as soon as I gave my answer. He said that the question could be solved using list comprehension (which I did but didn't do as a one liner) or map(). It took me too long to come to the answer because apparently other people got to the answer in minutes and he felt it would be a waste of time to test me on making decorators and ended the interview by teaching me about Python dictionaries...(like, what?) I thought more about it after I recovered from the shock, and pondered if there is a widely used scale of "Python mastery" based on libraries that you use or how many lines of code can you write to do one thing vs the actual performance of the code. Some people wrote on quora or stackoverflow that using map, filter, lambda shows advanced Python knowledge. **I don't understand how that demonstrates advanced Python knowledge.**
It was a "technical phone screen" where the interviewer knew Python, knew the right answer, and sat there and watched me on coderpad. I agree that it was super vague so I came up with a scale to put myself in because when I asked him to clarify what he meant by mastery he just kept using synonyms to master, expert, years of exp, etc. If the question had been rephrased to, how well do you know flask and Django my answer would have been completely different. Idk, maybe I'm reading too much into this. I'm sort of at the point where I don't know what I should be studying and focus on. Work requires scripting and side projects are web dev. Am I supposed to be studying the actual language or frameworks? I learn the best by making projects though. 
AFAIR, pyenv have environment plugin, so no need for direnv.
No code will be generated if they are just comments, unless it's a docstring.
Is **urllib3** and **urlib3** are the same? Because for me the output is **urllib3** for the above query. 
I'm a novice so sorry if this is a stupid question... but would the following be considered docstring? * """ * Purpose of Code * Note 1 * Note 2 * """ (bullets added simply so its formatted correcting on reddit. I want to highlight that each bullet is a different line)
His writing is great! I was introduced to FP through his articles more than 10 years ago when it was on the IBM DevelopWorks website. I still recommend his writing to a lot of people.
Your project is definitely interesting but your headline is too cryptic to catch people attention, I think...
Aside from your concerns about how that indicates more advanced python knowledge, that interviewer sounds like a real jerk. 
yeah so the problem is in `names.cli:25`. If a person's account gets deleted then the lookup of the name by id fails and raises a `slacker.Error: user_not_found`. An acceptable way to deal with this would be something like try: self.user_index[user_id] = slack.client().users.info(user_id).body['user']['name'] except: self.user_index[user_id] = str(user_id) I'll also put this on ghub
It might be overkill if you only need something to activate/deactivate virtual environments, but I like direnv because it knows about languages and environments other than Python, and can set and unset environment variables.
I was looking back at a lot of old code I wrote back in school when I started dabbling with Python, the amount of `for` loops that iterated through arrays, then created a new temp array and nested conditionals to push to that new array, that mostly could have been reduced to a simple map/filter readable "one-liner".
A docstring is a string that is the first statement in a module, function or class.
Props to Beautiful Soup maintainer who controls the "bs4" package. https://pypi.python.org/pypi/bs4
Way to solve problems with python!
I was reading an article a while ago about someone whose computer science thesis paper was on how many people he could get to download "malicious" libraries simply by misspelling the package when doing "pip install".
Being a docstring just means it's the first string in a particular section of code (function, module, or package). What's cool about them is it actually stores a reference to that string in code so that documentation can be generated from that alone. I believe it stores it as func.\_\_doc\_\_, but that's just off the top of my head. If you don't put it as the first string in a section the interpreter will actually just skip it entirely and it will have no effect on the results. 
So, if you are using python 2.7 you should be using raw_input("what is your name? ") and when printing it should be print("hello "+ name) If you use commas it will list it like an array.
I'm using python 3.5 but I will also try this. Also, after I just hit run module on my last code this message started popping up: IDLE's subprocess didn't make connection. Either IDLE can't start a subprocess or personal firewall software is blocking the connection. IDLE has been working fine for me the past week since I downloaded it and is now all the sudden doing this shit. do you know how to get around this. I appreciate the answer, by the way.
Using Zmq, Tornado, PySerial, and relays connected to power supplies and gas to operate a distributed hardware regression testing system I built for a client. Tests all their gear automagically with user defined test cases.
Hmm, that's interesting. I would try running the script with terminal to see if that works?
With the prevalence of blind pip install recommendations from most of the python learning and conference community, how can new users protect themselves? Is there a push to get new users of python to use more secure methods? 
Clever, but an abuse of the tag.
Except thats not how case works. 
Haha you should put this info in the OP, this is much more reasonable! The OP post is basically asking how to learn to do a basic root canal by tuesday. Learning the absolute basics of databases by tuesday might be doable. Stick to sqlite, and do lots examples or you won't learn anything. I took a database heavy job at a jr level without knowing anything about databases and I read a book about SQL and it didn't help one bit. You have to do examples 
It helped me. :)
Yeah - this is why I always consult a projects 'how to install' page and look for the line where they show `pip install &lt;blahblah&gt;` and/or `conda install &lt;blahblah&gt;`. Don't want to just guess similar names.
Debian packaging is a joke. The packagers can't be fully blamed though, apt and dpkg are very lacking in security related features. 
I have worked on some projects related to artificial intelligence. MY PREVIOUS EXPERIENCE ended up indicating that, to make at least the functional prototypes, it would have to be in Python or Java, because in one of them it would also be the final version in production. Well, they were all in Python, and also the final products. In the end I can only talk about my work experience :)
Using list comprehensions (and in newer versions of python, dictionary and generator comprehensions) is part of what is meant by "pythonic" coding. It's not just snobbery since tools like comprehensions and iterators are optimized for speed and memory usage and also make for cleaner looking code which is part of the reason people use python. That being said, I agree with others that the guy sounds like he was a jerk about it. Raymond Hettinger is one of the main developers for the core python language and [this YouTube video] (https://youtu.be/OSGv2VnC0go) of his is a good talk for showing what I'm trying to say. The stuff he mentions could easily apply to your web dev side projects if you are using Flask and Django since database queries will often return iterable objects that you have to loop through to display on your app. Personally I highly recommend the doctest library for your scripting and general programming work. You have to test your code to be sure that it works, putting the test in the docstrings of your functions is a great way to keep your tests near your code and help you document your code so it looks more polished and others can easily understand what it does and use it. I started my current job 2 years ago and if my predecessors and coworkers had put in more docstrings and doctests my job would be a lot easier and faster and we would have way fewer bugs. If you are like me and have trouble thinking up projects to practice coding, I just found out that Google codejam questions are online and not only do they provide a way for you to check your results, if you Google the question titles, often other people have published their solutions in python so you can see the different ways people used python to solve it and get the explanations right there, all free online. 
Yaourt is a bad command line tool, not a repository. The Arch User Repository is the repository.
&gt; You shouldn't access __dict__ directly Why not? Any real reason for this statement? Other than people tell you not to do? Using `__dict__` shows python's capablities to introspet itself in a very explicit fashion. `vars`, what should that mean? The local variables of a function? Pure python objects are based on dicts so why not show and use that fact? I can't understand this general fear against using dunder attributes/methods... Especiall stupid since `vars` gives you exactly the same: In [1]: vars? Docstring: vars([object]) -&gt; dictionary Without arguments, equivalent to locals(). **With an argument, equivalent to object.__dict__.** Type: builtin_function_or_method 
No, you're safe. The space before the last single quote is important.
Awesome, thanks! 
I'd recommend at least knowing what exists, if not all the intricacies of using it. You don't want to be re-implementing a queue in an interview question when it's perfectly acceptable to just import it and start using it. I've been on interviews (and received offers) where I said something like "I know there's a library for this. I think it's called &lt;guess&gt;. I have no idea what the method in it is called but here's what it would do." And then written two lines of "code" which use it and gotten on with the problem. 
This should be on top.
Learn by doing, you have an idea of what you want to make, so make it. There are a ton of websites that can provide you with specific help and instructions. You can do it!
I know it's not really Python related but those colors are aesthetic af. Can't wait to start messing around with graphics myself. 
This is no surprise. The standard library is huge.
My 2Â¢ justification (disclaimer: still not the "right" way necessarily, but it strives to be so more than other languages) haskell is closer to category theory than other languages since much of its syntax and patterns are derived from it, and [CT is closely related to lambda calculus and logic](https://en.wikipedia.org/wiki/Curry%E2%80%93Howard_correspondence), meaning that using the functional interfaces from CT is like coding with pure math, as oppose to coding with arbitrary useful patterns/architectures invented by someone or some company.
**Curryâ€“Howard correspondence** In programming language theory and proof theory, the Curryâ€“Howard correspondence (also known as the Curryâ€“Howard isomorphism or equivalence, or the proofs-as-programs and propositions- or formulae-as-types interpretation) is the direct relationship between computer programs and mathematical proofs. It is a generalization of a syntactic analogy between systems of formal logic and computational calculi that was first discovered by the American mathematician Haskell Curry and logician William Alvin Howard. It is the link between logic and computation that is usually attributed to Curry and Howard, although the idea is related to the operational interpretation of intuitionistic logic given in various formulations by L. E. J. Brouwer, Arend Heyting and Andrey Kolmogorov (see Brouwerâ€“Heytingâ€“Kolmogorov interpretation) and Stephen Kleene (see Realizability). The relationship has been extended to include category theory as the three-way Curryâ€“Howardâ€“Lambek correspondence. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/Python/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.27
Outside of work, I am writing an async server which allows users to post a JSON and scrape results from a number of popular search engines. Currently, only Bing and Google are supported but going to add support for Yandex, Naver, and Baidu. I'm pretty sure someone will highlight that this is against TOS' of search engines, but you can find the repo here: https://github.com/EdmundMartin/SearchScraperAPI
Have a look at [ocrmypdf](https://github.com/jbarlow83/OCRmyPDF) then which simplifies using PDFs with tesseract.
I was hoping that I chose a good set of colors! Thanks.
Being a string, I believe the interpreter allocates memory for it but the instruction has no effect thus no impact in the run of the script, besides the memory usage (although I may be wrong about this, I don't really know if the interpreter knows to optimize these cases). As for readability, it affects it in a negative way, from my point of view. Triple quoted strings are used for docstring and splitting a string between multiple lines while keeping all the whitespaces. I recommend to use multi-line comments when commenting extensively because I know for sure the interpreter skipes them and also are highlighted differently when using IDEs or text editors. Also, at least when using PyCharm it sometimes complains that you have an instruction that has no effect.
but i already have
pep 8
First get it working, then make it pretty. Programming is a two-step procedure.
Maybe we have different opinions on the definition of "elegant", but to me a book about algorithms and data structures seems to be much more conducive than pep8. 
/r/learnpython
Thanks.
Yes I enrolled it. It seems very good thank you. I ll start the courses today. 
how to set the path ?
So let's fuck with 121.42.217.44:8080 it's the host gathering the data the infected packages send on installation. 
If you haven't ever checked him out, this dude is gangster. I learned a ton from him when I first started out. https://www.youtube.com/user/sentdex. That said, have a project in mind. It is what finally put me over the hump in trying to learn it with no other programming background. Like @ran22147i said, learn by doing. No books or videos will teach you better than experience. 
Can't tell you how true ^this^ is. Also, comment the hell out of your code. Can't tell you how many times I've gone back and looked at older code I have written and tried to figure out what the heck I was trying to do and/or found a much better way to do it after trial and error.
I am using Pyhton 3.6. Does this affect me?
A couple of PR reviews and you'd be on the company's track with all the syntactic nuances they have as their work culture. As other mentioned, the interviewer just regurgitated whatever he read from 'Hiring 101 for dummies'. Keep digging on your interest points and continue on.
Bitwise operators in Python are used for bitwise operations. The question should be "what are bitwise operations used for" because the concept is independent of the programming language. Wikipedia has some examples: https://www.wikiwand.com/en/Bitwise_operation#/Applications EDIT: bitwise operators in Python are not so often used as in low level programming languages as C. They allow reducing memory foot prints and can be pretty fast. Some C examples here: http://www.sanfoundry.com/c-programming-examples-bitwise-operations/
With (for example) a byte you can store up to 255 options. To get one option's value you will use bit operators. 
Except standard bitwise operations, also on set() objects.
very very thank you guys
mmm I don't know if that's going to damage the sensor
next time say, that you're level 8 ;)
He's clear, simple and concise. Rare.
Auiams 
Thanks! I've only just started using python but after learning the basics on Codecademy I'm hooked!
You should try [Pint](https://pint.readthedocs.io/en/latest/).
100,002 at 7:56 EST. Great milestone!
What exactly is your question? Perhaps /r/learnpython would be a better suited subreddit for your question.
thanks
The input() function outputs a string. So you will have to mask the input as an integer like so: A = int (input ("Input a number"))
Thankyou!
https://i.imgur.com/zKC0aKr.png
I do a LOT of plotting in Jupyter. Usually using a connection of pandas plotting, mpl, and seaborn. I need to start developing tools that are interactive and require little to no Python experience (but extremely intelligent end users). I was thinking of using bokeh but I'm only just getting started. The reason for this was I could get people using it in Jupyter and I can build a flask app to make it even easier. That app could be launched locally or later deployed on a server. Do you have any thoughts with regards to this approach? Downsides? Better methods? Edit: I have a lot of Python experience, the end users do not necessarily.
Interactive *and* little-to-no Python experience, I'm not so sure. There is [cufflinks](https://plot.ly/ipython-notebooks/cufflinks/), which hooks pandas dataframes into plotly and cuts down on a lot of boilerplate, but it would still require some Python knowledge, especially if you want to customize anything beyond the default appearance. You can also make interactive dashboards in Excel if you want to avoid writing code entirely.
I'm in a similar boat. I was able to pick up Bokeh relatively easily. The main thing you need to know for adding interactivity is the ColumnDataSource. You can pass it a pandas dataframe and bokeh will be able to access whatever you want to show for interactivity. It's probably easier to get a handle on it if you know JavaScript, but I was able to hack my way through it without it. This course helped me better understand what was going on under the hood and for implementation: https://www.udemy.com/python-bokeh/ There's also Holoviews which I haven't had a chance to play around with but looks promising. 
It isn't "fear" of using dunders, unless you mean the *reasonable fear that your code will be buggy*. In general, operators and functions that call dunders don't *just* call the dunder. The `+` operator does much, much more than just call `obj.__add__`, `bool` does much more than just call `obj.__bool__` (or __nonzero__ in Python 2) and `iter` does more than just call `obj.__iter__`. If you think that they do, and think that you can safely replace `bool(x)` with `x.__bool__`, then your code has a subtle bug. In general, dunders are not part of the public interface of the class, they are implementation hooks. (The most obvious counter-example I can think of is module `__name__`.) To a first approximation, and probably a second approximation, you should never call a dunder method or access dunder attributes directly if Python provides a public interface for it. There is a public interface for accessing the member variables of an object: `vars`. You should use that, even if it turns out that under the hood it does nothing more complex than return `obj.__dict__` like you do, simply because it is best practice to use the public interface rather than then internal implementation whenever possible. You never know when the implementation will change. E.g. what happens if the object doesn't have a `__dict__` but does have `__slots__`? Right now, it doesn't matter whether you use vars or not, you'll get an error, but maybe someday vars will return a dict which proxies the slots. Of course if you're Alex Martelli or Raymond Hettinger or GvR himself, you know when you can break the rules safely. But for us mere mortals, avoiding accessing dunders is good rule. (As they say, rules exist so that you *think* before breaking them.)
My god your VM is slow. 
It isn't "fear" of using dunders, unless you mean the *reasonable fear that your code will be buggy*. In general, operators and functions that call dunders don't *just* call the dunder. The `+` operator does much, much more than just call `obj.__add__`, `bool` does much more than just call `obj.__bool__` (or `__nonzero__` in Python 2) and `iter` does more than just call `obj.__iter__`. If you think that they do, and think that you can safely replace `bool(x)` with `x.__bool__`, then your code has a subtle bug. In general, dunders are not part of the public interface of the class, they are implementation hooks. (The most obvious counter-example I can think of is module `__name__`.) To a first approximation, and probably a second approximation, you should never call a dunder method or access dunder attributes directly if Python provides a public interface for it. There is a public interface for accessing the member variables of an object: `vars`. You should use that, even if it turns out that under the hood it does nothing more complex than return `obj.__dict__` like you do, simply because it is best practice to use the public interface rather than then internal implementation whenever possible. You never know when the implementation will change. E.g. what happens if the object doesn't have a `__dict__` but does have `__slots__`? Right now, it doesn't matter whether you use vars or not, you'll get an error, but maybe someday vars will return a dict which proxies the slots. Of course if you're Alex Martelli or Raymond Hettinger or GvR himself, you know when you can break the rules safely. But for us mere mortals, avoiding accessing dunders is good rule. (As they say, rules exist so that you *think* before breaking them.)
Tools like pip? Curl is the most obvious, blatant offender of this habit to download and run a script as is.
You could try Plotly or mpl3d. Make the choice well, as you're going to invest a lot of time in to making things easy for the user it sounds. It's better to spend some time first making the choice. 
Does anyone have a copy of said "infected" packages? 
Millions of people fly everyday. We do trust the fact that the person sitting in the cockpit is actually a pilot. TRUST is so basic in our society we don't even think about it.
I think whatever CMS/word processor was used for the article mangles quotes. The original code was probably `encd = '';t=[0x76,0x21,0xfe,0xcc,0xee];` (note the two single quotes instead of one double quote)
Poor wording there. I have a lot of experience. Not all of the end users do. They just want to load up dataframes and see some plots, manipulate them, and save them out. Is plotly worth paying for over using bokeh in your experience?
Thanks you guys!! Y'all will help a ton!
I've been doing some basic stuff in Jupyter with bokeh. There are some confusing points but I think I'm figuring it all out. I'll definitely look into this course. One of the challenges is I do not know JavaScript and the web technologies as well so it was hard to define a path from manually making plots to a tool that is democratized. 
I've never paid for plotly. You can either publish your figures online for free and link to them externally, or you can generate figures in offline mode, export the HTML, and then serve them with flask or however you like. That's worked for me so far.
Your solutions are messy because you probably don't know which algorithms and data structure to use. Taking a course in Algo &amp; DS will also help you understand techniques that you wouldn't otherwise know or use. 
I'm finding that Bokeh doesn't integrate with pandas dataframes as well as I would like or not really suitable for exploratory data analysis (EDA). For instance, if you want the column names to show up in the hover tool, you would have to do a hacky FOR loop. I was told to check out HoloViews for EDA. Plotly with cufflinks have better pandas integration. I can't seem to understand the way HoloViews does things so I'll be just using plotly if I want interactive viz.
IMO, that was a really poor interviewer. If the whole company is like that, you're lucky to not get hired. To be a good Python programmer, it's not important to be able to quickly think of clever solutions. It's far more important to be able to reason about code, even if it takes you some time, that you're interested in improving your skills, that you know how to look up things you don't know (documentation, stackoverflow, just googling stuff), and that you're able to communicate and work with a team.
Check out HoloViews. Bokeh is still too low level if your goal is something with less boilerplate. I ended up using plotly with cufflinks because I just don't "get" HoloViews. Maybe I'll give it another try some day.
Capital One is hiring Python Cloud Engineers: http://rolp.co/zmDnc We having offerings from entry level to senior level positions in Virginia (Northern Virginia and Richmond area). I am one of the python engineers on the team. You will be working with python, linux, AWS, Google Cloud, and GitHub among other technologies. The company is looking to become a technology company rather than a traditional bank. Work life balance and benefits are excellent. Feel free to send me more detailed questions about the position.
1. There is no option to have this done automatically that I'm aware of. 2. When PyCharm uses SmartKeys to add a closing ' or closing bracket for you, when you reach it just keep typing and it will overwrite that char and put the cursor where you want it. Alternatively you can use Ctrl+&lt;arrow key&gt; to jump to the next separation in a string (spaces, periods, slashes, dashes, and a few others count as boundaries). 
Looks like a great contribution you are working on, but please put some time in to working on label size, padding etc....all the boring stuff makes up majority of the final wow (and is essential for beginners to know / understand). Maybe also include a link to the source (the seaborn heatmap source for example) so those that want to, can check out how things work under the hood. 
Look at Jupyter Widgets.
With any good IDE you can highlight a block of text and comment it all out (or in) with some hotkey, so it is actually fewer keystrokes and effort to use comments than triple quoted strings. Using # for comments is just a much better practice in terms of code highlighting, readability, etc.
If not familiar, a question might be why AREN'T you familiar with them?
Elegant code comes with experience. Also reading lots of code. Don't underestimate the importance of reading
This [Python Algorithms](https://readthedocs.org/projects/python-algorithms/downloads/pdf/latest/) should help.
I was intending on digging into holoviews as well but, like you, something wasn't clicking for me. I stayed away from plotly because I don't like tying myself to non-FLOSS solutions but maybe it's the best path here. Thanks. 
I didn't know Numpy could be *this* fast compared to native Python. Good article, I learned a lot. 
Temporarily, during debugging - no problem. Keeping it in the code for longer can be misleading, especially if it's more than a couple of lines long and without a prominent comment ### why it's triple-quoted out. 
Python will let you compose numbers in base 2 using base two literals: 0b11110 &gt;&gt; 30 The bitwise operations ^ &amp; | ~ &gt;&gt; &lt;&lt; will work on integers according to the laws of bitwise operations.
Why are you trying to install this client package (using sudo)? You have Paramiko for that already. Luckily the 'client' package you installed just contains a console script which prints out 'Hello client';-) which doesn't seem very useful to me. You should define the client using Paramiko by: client = paramiko.SSHClient()
Logs including thread id. It might be possible to come up with a better suggestion, if you describe the crashes in more detail :)
Can you share your code? Just started a week ago and I'd like to see it.
Thanks, I was searching for something just like this, but had difficulty trying to explain my reasoning
of course! Here is the trinket.io link. https://trinket.io/python/b50404a607
Ctrl+shift+enter should do what you're asking I believe. It auto formats the current line with some options and completes your current scope and puts you on the next line
I would look into Plotly's Dash platform as well. Although it's relatively new, it seems promising.
Yeah, I've only used bokeh for more final visualizations. I can imagine it falling short for EDA. I wanted something with more flexibility and open so I chose bokeh over plotly/cufflinks.
When NumPy isn't fast enough, there's packages that are faster such as `numba`, `numexpr`, `theano` and also distributed computing packages like `dask` if you have a cluster of computers to work with. 
https://stackoverflow.com/questions/641420/how-should-i-log-while-using-multiprocessing-in-python 
Good to know. In fact, I tested what the article did, and Numpy arrays take a significant time to create. It is still faster than the "vanilla" arrays, but it has to be considered. I might test the libraries you gave, for entertainment purpose! 
It's maybe overkill, I know, but I'd like to have on Pypi only packages that have a 80-90% unittest coverage (or some other similar kpi). IMO Pypi should be a "production-ready python package index". And maybe then add another index where everyone can upload code. Pypi is **the official** third-party Python code repository, and so it should have rules. In a sense, being *official* means for the Python Software Foundation to have some kind of responsability on what's inside. Then we can have an unofficial, or explicit "free for all", index with every kind of mess in it but then.
Here's a quick explanation. A list comprehension takes a series of values (anything that can be *iterated*, like a list, a dict, a tuple, a generator, or something else), and uses it to create a list. x = [n*2 for n in [1,2,3]] This makes `x` a list. It goes through the list `[1,2,3]`, and replaces the values with `[2,4,6]`. I could rewrite it as a for loop thusly: x = [] for n in [1,2,3]: x.append(n*2) 
Yes. It's not Pythonic. I wouldn't check that in. Some editors and IDE's make it easy to select several contiguous lines and comment them all out with the standard commenting mechanism. 
Are you working on Linux? If so: Have your program print its status to stderr when it receives SIGUSR1 https://docs.python.org/3/library/signal.html 
How old is this thing? &gt; (compatible with versions before 2.5)
Here is a list of threads in other subreddits about the same content: * [create valid json object in python](https://www.reddit.com/r/datascience/comments/70hzia/create_valid_json_object_in_python/) on /r/datascience with 1 karma (created at 2017-09-16 20:59:19 by s-matthew-english[author of both threads]) ---- ^^I ^^am ^^a ^^bot ^^[FAQ](https://www.reddit.com/r/DuplicatesBot/wiki/index)-[Code](https://github.com/PokestarFan/DuplicateBot)-[Bugs](https://www.reddit.com/r/DuplicatesBot/comments/6ypgmx/bugs_and_problems/)-[Suggestions](https://www.reddit.com/r/DuplicatesBot/comments/6ypg85/suggestion_for_duplicatesbot/)-[Block](https://www.reddit.com/r/DuplicatesBot/wiki/index#wiki_block_bot_from_tagging_on_your_posts)
Even easier, but a lot less elegant: just write out the progress to a specific file.
yes linux. I was thinking I'd just update a log file every second, but your way sounds smarter. Its a good reason to learn about these signal things. Cheers
There are two mature options I am aware of. Both integrate well with numpy. Pint is a nice, do one thing option.it only provides units. https://pint.readthedocs.io/en/latest/ Astropy is a huge project for astrophysics and also provides a unit system `astropy.units`. Astropy has also the `astropy.table.Table`, think DataFrame but with support for units and multidimensional columns, but less features for plotting/statistiscs/groupby/join. http://docs.astropy.org/en/stable/units/
Strings are unicode. Probably you want to use Bytes objects instead.
I implemented this for German postal code areas here: https://github.com/maxnoe/plz_plot Using cartopy on top of matplotlib
&gt; Finally, doesn't all of this imply that the problem is not that SQLite doesn't understand decimal but rather that SQLite is reading the literal value "Decimal('180.00')" value with the wrapper, which ultimately causes the exception? That is what is causing the exception, but that is not the *problem*. Let's roll with the solution you have right now for a second. Here is my output from a quick test session: &gt;&gt;&gt; cur.execute("CREATE TABLE IF NOT EXISTS CHARGE_HISTORY (ACCOUNT_NUMBER VARCHAR(50), AMOUNT_USD DECIMAL(13,2));") &gt;&gt;&gt; cur.execute("INSERT INTO CHARGE_HISTORY (AMOUNT_USD) VALUES('10.10'), ('20.10')") &gt;&gt;&gt; cur.execute("SELECT SUM(AMOUNT_USD) FROM CHARGE_HISTORY").fetchone()[0] 30.200000000000003 Probably not the result you would hope for. NUMERIC type affinity really just means when data comes into the column, sqlite tries to cast it: a) to an integer b) to a 'real' (aka floating point number) c) leaves it alone and just puts in the column anyway. You have traded the exception warning you are mixing datatypes for this implicit conversion and it is probably not the precision you want for dealing with money. &gt; It is kind of weird that my tuple no longer has the Decimal() wrapper to display a decimal value. Maybe you can help explain that one to me. In english, we read "180.00" is a decimal number, but in all major computer languages, that representation is a floating point number. Hence why the special "Decimal()" constructor is used when it is not. If it makes you feel better, you are **[far](https://i.stack.imgur.com/RqaoR.jpg)** from the first person to get confused about this point.
Just make things. Think of something you want to make and make it. 
I gotcha. Is there like a best platform to use or just make a note document and try to run it on the command line and stuff?
&gt; Numpy arrays take a significant time to create I suppose that depends on *how* you create the array, though. Which method are we talking about here? The script from the article computes 50 million pseudo-random ints. That's going to take a little while anyway. If we created that data structure with well-optimised C code instead, the additional overhead of wrapping that into a NumPy array with numpy.frombuffer would be basically nothing. Subsequent operations performed on these data would make for interesting benchmarks â€” obviously there'd be a big difference between numpy.sum and a Python lambda. But array creation time itself should be a non-issue; am I missing something important?
I am trying to learn Selenium as quickly as possible, so I can help test a recently deployed - and rather buggy- webapp at work
Cython is unbelievable. I used it in a [side project](https://github.com/siddhantgoel/streaming-form-data) of my own and the speedups were insane.
Use the Python IDLE until you think you need something a little extra. 
You did edit the environment variables?
doesn't what you suggest on #2 defeat the purpose of autocomplete smartkeys in the first place?
ctrl shift enter only puts me on the next line, it doesn't auto format the line. How did you get it to auto format the line?
NumPy arrays are basically C-arrays with a wrapper, whereas a Python list is actually a doubly-linked list, so converting from a `list` to an `ndarray`is pretty slow as it has to iterate over all the list element, figure out what NumPy datatype to make the list, and the copy the elements into a flat array. It's much faster if you can feed NumPy the raw bytes stream via `numpy.frombuffer()` or `numpy.fromfile()`. 
You can also use Unix domain sockets. They're like a TCP stream and a local file mashed into one elegant package. 
&gt; a Python list is actually a doubly-linked list No, the cPython implementation is a C array of pointers to Python objects. I've no idea what other implementations do.
As far as I know Python list despite its name is rather dynamic array then list. If you want double-linked list you should use deque from collections. I would guess that problem in this particular case it the fact that everything in Python is object (even integer in list) allocated on the heap. And that could make creating numpy array sluggish. Just my guess. But you might be right. What about to use array from array instead.
&gt; more confident in my code What do you mean?
Hex is going to be necessary to learn as well since most binary representations are short handed to hex.
Do you know loops?
It just says Sep 16 so I assume today. All in all I thought it a really poor article.
codeacademy.com is good.
Hmm not sure. I thought it did but I think it only fixes syntax errors
Practically speaking, except in niche situations this is probably unwise. If you're looking for high compression in transit, then check out Protocol Buffers (or MessagePack) combined with gzip or bzip2. As an exercise in learning about lossless compression... carry on!
Does it just dynamically allocate a large block of memory as you add items? I know I've always treated appending to a python array as a relatively constant-time operation, but I know that isn't *exactly* correct. Was wondering about that recently.
Idk if I ask someone to multiply every number in a list by 2 and they do it in 4 lines thats probably not someone I want on my team.
I'm going with Pint now as Astropy is a little bit of overkill for what I intend to do. Thanks! 
It works like a charm! Thanks a lot! 
See here for reference: https://www.laurentluce.com/posts/python-list-implementation/
If you want a "stand-alone" library for multidimensionnal columns, try [xarray](http://xarray.pydata.org/en/stable/)! Nice api and numpy integration.
I wouldn't say a large block of memory as only pointers to objects are being allocated, not the objects themselves. The number of pointers that are allocated rises exponentially as the size of the list grows. To find the actual algorithm used you'll have to check out the source code.
Depends on the position a little bit. For *junior coders/programmers*, I'm looking for your ability to write a DFS/BFS using a stack/queue, as well as the types of problems you might solve with each one. I'm going to expect (or at least hope) that you know to use deque or something in the STL. I also expect you to have some semblance of knowledge of runtime and why you use the STL things you are. For *senior engineers*, I'm looking for your ability to solve macro/system problems well. I'm curious to see what language/interpreter characteristics you'd exploit to write a system to store exception tracebacks for later use, and possibly the benefits/drawbacks to your approach, or maybe how you'd use managed resources (*with* block) to manage access to a non-thread-safe resource. For architects, I don't imagine really caring what things you can **do** with the STL, but to at least know what's in the STL. I hate seeing architects/leads bringing in extremely unneeded dependencies, that would have been skipped had the architect had any semblance of knowledge of the last 3 years of Python/framework release notes :-)
Apart from 100,000 commits what have the cPython developers ever done for us? Nothing!!! Apart from...
Well, it is an issue for basic testing. I create an arbitrary array, and i then test some naive Python implementation of algorithms, then I try it with NumPy. But if creating a Python list (using [[1, 2, 3]] * int(1e7)) is fast, converting it to a NumPy array is slow. It's just annoying (i create the arrays before the benchmark, so the creation time is not interfering with the benchmark). Any idea on how to create an arbitrary numpy array faster ? I don't values to be random.
I think you'd be able to use some kind of AI. I'm not sure exactly what "production planning and scheduling which includes artificial intelligence" means, but imagining that you're looking at gantt-type charts and scheduling a finite pool of resources, then yeah, you could write a deterministic algorithm that can cover most things (i.e. when there are obvious choices), then apply a machine learning model for decisions where the deterministic one would otherwise come to an impasse (i.e. it ends up with multiple choices with no immediately known better one). You could train a model against previous projects with a reward function based on cost/time outcomes, then query that model when the deterministic one comes short. Ideally this would be better than just rolling the dice for scheduling. The cool thing about that scenario is that you really don't need to know *how* your ML model works to use it. You just need to understand the limitations of training and using a black box like this (overfitting, bad parameters, etc.).
Except that the pilot doesn't have to take off, fly the plane or land as the entire thing can be software controlled. Do I dare fly again?
You can try sublime text 3, also you can follow youtube.com/coreyschafer. He is a good teacher.
Your particular example is done by using tiling. Creating an arbitrary numpy array is an ill-defined question. You can read data directly into numpy arrays quite a few ways.
Pfft. It's a bullshit question. Just call yourself an 8. It's high, but not so high to cause other people to believe you're inflating your skills. This industry is rife with impostor syndrome folks and Dunning-Kruger "rockstars". This sort of metric is as meaningless as "what is your greatest weakness". Just tell them 8. If you do want to gain mastery of the Python language, I recommend studying the books Effective Python and Fluent Python, and maybe also Python Cookbook.
&gt; Really wish we could get Pypi cleaned up a bit, it's an absolute mess IMHO. All you need do is contact the Python Packaging Authority and volunteer your services. I'm certain that they'd be delighted to have some assistance rather than have people doing precisely nothing except complain.
Couldn't have put it better myself.
Any example :)?
SIGUSR1 cannot be found on that page, just saying.
I'm looking forward to seeing you, personally, volunteering to help out. Or is it simply easier to complain but do nothing?
Use PyCharme, there is free community edition.
That's a good work, have my upvote !
I love Cython!
Pandas uses numpy under the hood, right?
Automate the Boring Stuff - exactly what it says https://automatetheboringstuff.com/
I made [this](https://gist.github.com/Swarchal/60c852004497be404c179ba55196c011) list of examples a while ago for a colleague.
I expected this to be a blog post about Go and Python because the title could've been a wordplay on the programming language Go.
Need more information. - What version Python - What operating system - Any other critical environment details Also, expand what you mean when you say your machine "crashes." - Does it simply freeze? - Is there any output/stacktrace given in your terminal? Etc...
Yess
Thank you.
Wow, great link! Thanks! So in the end, you get an average O(1) performance for append anyways. Good to know, and it agrees with my experience using lists this way.
Your PATH environment variable is likely pointing to your python 3.6.0 installation. You will simply need to update your computer's PATH environment variable to your new installation
Also matplotlib, in fact just about every piece of cPython software that needs to do any serious number crunching. Numpy must be one of the most used, if not the most used, third party packages used by the cPython community.
They eventually do import though? Your IDE should be able to remember which modules are imported by which projects and optimize them, but sometimes they won't know until runtime and have to do it the hard way.
What? How does that help if the script is not yet capable of outputting its status mid execution? Did you even read the post?
You can convert Python `array` to NumPy `ndarray` quickly.
If you ever have a loop that creates a {{list, dict, generator}} then you can rewrite that loop as a one-liner. This one-liner is known as a comprehension. Simple as that. It is possible to have multi line comprehensions to make complex nested lists of things. I have done that before, those can get confusing quick because it starts to read like lisp.
Correct. The page only mentions 2 signals explicitly, because these are defined as aliases in the module (signal.CTRL_C_EVENT and signal.CTRL_BREAK_EVENT), however it does say: SIG* All the signal numbers are defined symbolically. For example, the hangup signal is defined as signal.SIGHUP; the variable names are identical to the names used in C programs, as found in &lt;signal.h&gt;. The Unix man page for â€˜signal()â€™ lists the existing signals (on some systems this is signal(2), on others the list is in signal(7)). Note that not all systems define the same set of signal names; only those names defined by the system are defined by this module.
Same, but I don't think examples really do databases justice to a math major. I came into database programming from a math degree, and it didn't click until I started thinking about it from a set theoretical perspective. It's important to view relational databases as schemas that organize sets (as tables) of object dimensions. Those sets contain various instances (as rows) so that you can access and analyze their attributes (as columns). Some attributes are identifiers pointing to other objects somewhere else in the database, and that pointer establishes a relation. Sometimes, there are multiple relationships stored in the set that you want to analyze, like which Employee manages which Account at which Time. These parameters (Employee, Account, Time) make up a three dimensional relation on a subset of the Cartesian of their dimension sets. We store these relations as facts (tuples of IDs) in our system, and the relation for a distinct (E, A, T) might require it's own attributes (additional columns) to accurately describes your system, like if multiple people can share an account, what percent does each person own. That percent belongs to the relation (as a table), not any one dimension. Once you get past the set math of databases, joins make perfect sense and data science comes easy. We're thinking about the relationships between real objects as a finite mapping in tables on abstract data types, like strings, datetimes, and generic object IDs instead of pure numbers, like relations on the real, naturals, etc. Edit: /u/peachy171 tagging you to notify on a subthread
They import if I retype them and then they remain imported. I was just hoping there was a quicker way to do this. Even a way to automate this. I just thought I might be missing something because I can write something in PyCharm using modules and then run it in IDLE without any issue. But when I do it the other way around PyCharm requires these extra steps.
 result = dict() for name, value in input.items(): result.update({value: result.get(value, 0) + 1})
I've been torn between Django and Pyramid. I've only read about Pyramid, but it's more DIY than Django, and as a result I've read that it scales with YOU.
Can you explain what you mean by re-import them. ALL of the examples you have given (random, string etc) are standard library modules, and since Pycharm uses a normal python interpreter, you don't have to do anything. If the code runs outside of PyCharm it will run inside it (unless Pycharm is set to using a virtual environment). Can you explain what you actually do - what commands etc you type, and where you are getting the guidance that you have to import anything into PyCharm ?
Less debugging. No scratching my head about a nil set somewhere far away from where it blows up. No worries about where a piece of state gets mutated and how that affects some other component. No brittle error handling. No implicit defaults. No magic syntax or metaclass tricks. Etc.
You understand that getpass.getpass is for inputing the Password - not the user name - I would have expected : username = raw_input("username: ") password = getpass.getpass("Password: ") Your code is currently prompting for a username - but hiding the typing - I doubt that is what you mean ... 
Why ask a 2nd time when the answer to use a [Counter](https://docs.python.org/3/library/collections.html#collections.Counter) seems pretty smart to me?
Create the smallest possible example that causes the error. 
You may find CodeReview useful - people critique code style and suggest better ways to write it. https://codereview.stackexchange.com/questions/tagged/python
We know, this must be the 4th or 5th thread on the subject.
Can't you wait for an answer on stackoverflow? Oh, you've all ready got one, just like for the other question that you've posed.
Find an API you're interested in, like cryptocompare or the ProPublica Congress API, and figure out if there's something you want to analyze! It's a little obvious, but it would teach you about a bunch of major libraries, like json (because most of the APIs come that way), pathlib/os (if you want to store meta/concrete data to files), SQLite/sqlalchemy (if you want to use a database), pandas (when you get to the set analysis). Once you have a core data set scraped, you'll have a better idea about the logic you want to put on top of it. You could dashboard with visualization libraries, build an AI voting system for upcoming bills in Congress. It just takes having a dataset to program with really.
BTW, `sudo pip install` is a risky practice: https://stackoverflow.com/questions/21055859/what-are-the-risks-of-running-sudo-pip 
To make sure that you get more answers than you've all ready got on stackoverflow why not put all your questions on the main Python mailing list, yahoo, quora...
If I open a .py in PyCharm that uses any kind of module, it won't run unless I originally wrote it in PyCharm. Lets say it contains something really simple like this: import random print(random.randint(0, 21)) This won't work right away. I'd have to actually remove the phrases "random" and "random.randint" and retype them. And I have to do this for each individual python file that I didn't originally write in PyCharm. Edit: When I say "won't work" I should be more specific. The interpreter will just say "Type exit to kill the program." when I run it.
You might find this post interesting: https://www.ibm.com/developerworks/community/blogs/jfp/entry/Python_Meets_Julia_Micro_Performance?lang=en I knew about numpy and cython. But this post teaches you more, like vectorizing, cache, and good python code optimized for speed.
 my_list = [ITEM_I_WANT_TO_APPEND for ITEM_I_WANT_TO_APPEND in SOME_LIST] A list comprehension is just a for loop with a different syntax. Don't let the brackets confuse you. # define a list [] # loop over an existing list. for item in old_list # combine the two [for item in old_list] # determine what you want to actually be in the new list ['hello!' for item in old_list] # would return (for list of length 3). ['hello!', 'hello!', 'hello!']
Awesome thank you.
Thanks for the tip 
I'll definitely check that. Thanks for the link! The Python community is definitely awesome, always here to help a beginner like me :)
I will give those a look. You seem a lot more knowledgeable than I, is there any other suggestion you would give on where to go after basic lossy compression. I'm really interested in understanding how compression is used professionally rather than just compressing simple strings 
Simulate the target platform, then you can examine it at will :-)
Thanks for the info, I'm familiar with bit operations and so on. I was just interested in a raw representation of numbers similar to uint8_t types in C for example but a lot more variable in length of integers. I figured a language like python would give this freedom in some capacity, just wasn't sure where to look 
Would you suggest just reading the python docs for this? Starting to realise I probably should've gone there first 
I think using these shortcuts too much can really affect readability,. They give 3 ways to do the following if a &gt; b: # 0 result = x else: result = y with the following (numbers added) result = x if a &gt; b else y #1 result = (lambda:y, lambda:x)[a &gt; b]() #2 result = (y, x)[a &gt; b] #3 result = {True: x, False: y}[a &gt; b] #4 result = (a &gt; b) and x or y #5 result = ((a &gt; b) and [x] or [y])[0] #6 If I saw anything but #0 or #1, I would assume the coder is trying to impress someone and failing to do so! Even the ternary syntax can affect readability if used too often and/or in keys ways. Just because you *can* do all of these ways, doesnâ€™t mean your should 
You guys wanted the smallest piece of code to show you the problem. I have edited it now.
Doesn't matter. Same problem. Change it around so that password uses getpass, it's the same difference.
Dunno why everyone is focusing on the non-important thing you want to optimise. Assume the new code above is what I want to do, which causes the problem. The problem is what I care about.
Done
* any version * arch linux * no * yes freezes, no mouse, no input, frozen screen. * no
Whoops, edited. What do you think `getpass` does? It gives a password to the system's user base. What do you think happens when you give a password without giving a user first? Undefined behaviour.
Sorry, wrong thread. Edited.
Now I would strace the process, writing to a file. Then maybe fire it up in gdb. Are you sure it's not dropping core files somewhere maybe? Edit: oh and maybe check the source for getpass.getpass and try to narrow down the offending line(s) further. 
Funnily enough, the first one isn't even out of the first page.
It's basically a shorthand for creating a list populated by some expression on each element of some iterable that can be filtered by a conditional. Create a list of strings that contain all the perfect squares less than 1000. (Perfect square means some integer i exists where i*i = n) [str(x) for x in range(1000) if x == int(sqrt(x))*int(sqrt(x))] 
if one of x or y can be thought of as a default, then #0 can be rewritten as result = y if a&gt;b: result = x and if you are writing a bunch of conditional operators and donot care about short-circuiting/side effects, then defining your own cond(condition, iftrue, iffalse) function will provide an even more compact way than the built-in ternary operator. Frankly, I think python's ternary operator was a design mistake: it's too verbose and too special syntax-wise (both if and else behave differently than they normally do in python, and evaluation order is "interesting"). they should have either used the C ternary operator or just accepted the lack of operator as a minor language wart.
It's more white pages than content. And the content is about a python module but less about algorithms and how and when to use them, how to implement them, etc. Am I missing something?
Yes, that's definitely possible 
Soooo can you help me out please?
Python 2.7? I don't have it installed anymore.
https://gist.github.com/mattmahn/d5006cb7f1ff8498ab54aa065a2fb31f That was more troublesome than I expected
What's this, your 5th repost in a few hours? If the answers on stackoverflow aren't good enough for you, why bother asking there in the first place?
How do you run it in Pycharm ? I have taken files from non Pycharm projects - opened them in Pycharm and they worked just fine. What you are describing is incredibly odd to be honest
I feel like they're just enabling people.
Yeah, go read up on the `io` module in the Python docs. You'll probably want to work with `ByteIO` objects and get `MemoryView` objects from them for bit-manipulation. It may be much faster to using NumPy bitwise, or writing a jit function with `numba` than to try and do anything in Python itself. Also there's `blosc` for actually compressing large data volumes. It supports zStandard which has Hoffman encoding.
This is the state-of-the-art in compression algorithms in the world as of today: https://github.com/facebook/zstd 
getpass.getpass - just prompts for a string without echoing - it doesn't use the systems password system at all.
just tried getpass.getpass on Python2.7 &amp; Python3.5 (Ubuntu 16.04) and it works as expected : - prompt is printed to screen - text prompt flashes - but doesn't move as i type - As I type nothing gets echoed to the screen - pressing return makes the function return the text i typed I can't see a bug on python tracker which is similar to your issue. Is there nothing you can do to get control back - for instance do Ctrl-C or Ctrl-Z do anything ? 
 with open('file.txt', 'r') as file: result = [[line] for line in file] Something like this? 
Still learning....my Fifteen Squares game is complete. Again, compared to some of the stuff I'm reading here I'm still at a rather primitive level. But it feels good to get past the "slice this list and print this" tutorial fodder. A program with classes, functions. I continue to work on classic programming problems I find on websites...but I'm also researching collecting performance stats from our 150 + sql servers at work and building dashboards. 
I know a bunion named mb 
&gt; Big O is about the size of the data. 5 elifs is not O(n) but that's what I was trying to get at -- theory vs practice !? :P &gt; it'd probably take a gazillion conditions to make it worth bothering about. PS: Without any more context, Big O is about the time complexity by default or memory. In your case, say you are a major search engine maintainer, even 5 elifs matter if you have 1 million requests a minute.
...to continue using Python *and* keep costs within budget. Totally, me too.
Nah I've had it happen too. It's a weird glitch I'm pycharm and seems to happen mainly with large python classes (like stuff generated by pyxb) or projects that are more than a handful of files. It's nothing to do with running (executing) the script, it's that the IDE will display the import as invalid in the syntax highlighting.
/r/learnpython
it's just compact syntax for loops
Every time python 2 is mentioned in this sub somebody says something like this. It's like there is no concept of how much money it costs to move a large codebase. It's much worse if that codebase doesn't have outstanding test coverage. Couple that with there being no actual benefit to moving it forward...call it whatever you like, but that time and money is a bad use of resource for many orgs. Saying it's dumb to write new code in 2.x is fairly difficult to dispute, but it'd be a catastrophic mistake for the python ecosystem to try and force this. Companies would definitely begin to think twice about using python in the first place for new projects if such a thing happened as they'd be worried about what happens when python 4 becomes a thing.
Hi, I constantly am getting a core dump on Linux, can't find any more info. It worked after a fresh ubuntu install and then turned to this again. How can I completely remove all files associated with tomviz to retry? &amp;nbsp; I have a similar problem on Windows but using revo uninstall and reinstall works for a little while before it happens again :s
&gt;say you are a major search engine maintainer, even 5 elifs matter if you have 1 million requests a minute. This is exactly what I meant. The n in your big O time complexity is the number of websites you have indexed. Number of ifs is an independent value, and the scalability of your search is not based on that at all. The "time complexity" of your fixed number of conditionals is not what O(n) refers to here.
Project euler
To be fair, itâ€™s nothing new. Just bug fixes. 
Umm... virtual environment? Kinda new to that module, but wasn't it made for this very reason?
thanks a lot!
I mean do you have to know all the methods or just the general purpose of the library and be able to look up the methods?
Virtualenvs == no need for updates and fixes to python itself?
As mentioned, **Automate The Boring Stuff With Python** is a great resource.&amp;nbsp; (*it's also available as a [**Book**](https://www.amazon.com/Automate-Boring-Stuff-Python-Programming/dp/1593275994)*) Additionally, I'd recommend [**Python Crash Course: A Hands-On, Project-Based Introduction to Programming**](https://www.amazon.com/Python-Crash-Course-Hands-Project-Based/dp/1593276036).
To get you going please see [plotting](https://matplotlib.org/), [arrays](http://www.numpy.org/), [differential equations](https://www.scipy.org/) and AI just search, loads of data online including this subreddit :-)
Yes, as we all know there have been literally zero things added in the entire Python 3.x series so far; it simply consisted of deliberate compatibility breaks to make people angry for no reason.
Don't worry about command line just yet. edit: Just do stuff that's cool to you. Don't type novels about french fries at 11 pm on a Saturday.
Means that a codebase dependant on a specific version can still be used. Updates and fixes are doable just make a new 2.x environment with the update. moving from 2.x to 3.x isn't always as easy.
And the 2to3 tool isn't good enough...
I agree with you on a lot of levels. I don't quite think that completely new and decoupled projects should be in 2.x for any reason, but legacy codebases without significant code coverage are a massive technical debt to assuage before any migration to 3.x is sane for large orgs. For that very reason I am currently working on getting my company's expansive 2.7 codebase in a decent testing harness with good functional and unit coverage. We want to move to Python 3, but all the cards need to be on the table for us to test it properly when we flip the switch.
Personally I just log to a specific file and have the OS rotate it daily. So in most cases you can `tail -f /var/log/myapp/run.log`. Python logging has the file handler built in.
Probably worth noting the difference from python2, which does a literal `eval` on the input (a dangerous operation) - so be careful if you need to support Python2.
Strings for what tho ?
I know what it does, just pointing out that virtualenv isn't relevant to the 2.x vs 3.x question
Sarcasm aside, you missed the point. We're still on 2.x, so obviously our code can do its job without the 3.x features. Maybe some of it would be more elegant in 3? Doesn't really matter though, no business value in changing something expensive unless there's an actual "We need 3.x to do this thing that generates money" reason.
No sane org is gonna run something like that on their codebase and deploy it without a huge amount of testing - if you're one of the lucky few whose org is religious about writing tests, it eases that burden substantially. Most orgs aren't in a position to say "Our test coverage is so good that we can run an automated tool to rewrite a bunch of our code and feel confident deploying it".
Then stop acting like it's Python's fault that your company made this decision. It's not an uncommon choice for companies to try to write something once and insist on running it with no changes or technology upgrades for decades afterward, and any language can be the one they end up choosing to do it with. But third-party technologies will not remain permanently static simply because one company wants them to, and if the company ends up feeling left behind by the tech, cut off from support and from a steady supply of people familiar enough to keep it running, it's not the technology's fault.
&gt; stop acting like it's Python's fault that your company made this decision Seems like you're determined to be as abrasive as possible here, but I don't believe I ever did this. The python community itself obviously recognises that supporting 2.x is still important - because, well, look at this thread title. My point is simply that this sub seems to always shit on anyone still using 2.x and in my opinion, a bad decision doesn't have to have been made at any point for an organisation to still be using 2.x - quite the opposite, the lack of compelling reasons to move to 3.x is exactly why so many organisations haven't done it yet.
Converting into a NumPy array is slow not due to NumPy itself, but due to the cost of unboxing all the values in your list and copying them in. For comparison, try just doing numpy.ones(30000000). It's super fast. Heck, you can even do: x=numpy.empty((3,10000000)); x[0]=1; x[1]=2; x[2]=3 and compare that for speed.
Good point, in that example, I see how that can be confusing :P. Previously, before I wrote this example, I didn't regard the number of users as the "n" in that equation. I.e., for O(n), I assumed a growing number of elif statements ... however, in practice no-one would probably implement an *n* number of elif statements but rather set it up as a hash table, so the number of elifs would be constant and we would have O(1) in both cases, with elifs and 'cases'. 
Python 2 EOLs in a little over two years. It's supported today not so that you can keep acting like you'll run it forever, but so that you have more time -- on top of the nearly a *decade* you've already had -- to port to 3. If your stance is that you will never upgrade, well, OK. You'll never upgrade. But acting like it's Python's fault for not being sufficiently "compelling" comes from either a position of ignorance or a position of deliberately trying to shift blame away from your own policies and onto Python.
Exactly this. Nobody in my org is like "let's stay on 2.x, it's awesome" - but the barrier to moving safely is pretty high and the upsides very small, so we haven't!
...nobody is blaming anything or anyone for anything mate. I feel bad for anyone working on a dev team with you, I bet you're a real pleasure to disagree with.
When you claim that "lack of compelling reasons to move to 3.x is exactly why so many organisations haven't done it yet", you are in fact attempting to lay blame on Python for people not porting. Anyone who's still exclusively on Python 2 at this point isn't waiting for a "compelling" feature. They simply never planned to port, period, and are looking around for anything else they can blame for it.
My approach: if you've got some python that needs to go faster, rewrite the performance heavy parts in C++, and load it with `ctypes`.
Blame means to assign responsibility for a fault or wrong. The difference between that and saying thing x was caused by condition y is not assigning blame. In any case, there is even less business value in continuing this...exchange. Think whatever you like 
I happen to agree. My point above was that until that actually affects our ability to do our job, the amount of dev time required to do it is a very hard sell.
Consider what you are actually asking. You wanted a shortcut key to perform an operation that already takes a single key press to complete. Not only that, you have two options for single key presses: type the ' yourself even though it is already there or hit right arrow. So yes, SmartKeys is effectively useless for that scenario, but that scenario is not at all what SmartKeys is intended to simplify for you.
GitHub is probably the best place. Alternatives like bitbucket allow you to have private repos for free. 
&gt; as they'd be worried about what happens when python 4 becomes a thing. Why? It has been stated repeatedly that the move from 3 to 4 will be nothing like that from 2 to 3.
no it should not be hard, usually for someone who knows a programming language, the official tutorial is a good start https://docs.python.org/3/tutorial/index.html
The PSF are simply honouring their pledge to have an extended life for 2.7 with EOL being some time in 2020.
Github then post in the relevant subreddits. If it's a web application, then just have a link to the demo in the README.
You could try removing "prompt=". 
So all you need do is fix it if it's that simple. On the other hand if Benjamin Peterson, who just happens to be the 2.7 Release Manager and the 2to3 maintainer, can't cope with all the edge cases, then somehow I doubt that anybody can.
1.5 is still in production use. "If it ain't broke, don't fix it".
PSF support ends in 2020. Paid support will no doubt be available while there is still a demand, presumably until the cows come home.
The two words that I had rammed into me until my career was ended early by ill health were "business benefits". Need I say any more?
Have you looked into [octave](https://www.gnu.org/software/octave/)?
&gt; It's like there is no concept of how much money it costs to move a large codebase. It's much worse if that codebase doesn't have outstanding test coverage. These companies have had almost 9 years to the day to move their codebases. Money and time is no longer a valid argument at this point. &gt;Couple that with there being no actual benefit to moving it forward Provably false claim, but whatever man. &gt;call it whatever you like, but that time and money is a bad use of resource for many orgs. They are going to have to migrate eventually, because eventually Python 2 will stop receiving any more updates, even security ones. And the longer they put it off, the more expensive it will be to migrate their codebase. They are just making this problem worse for themselves. &gt;Saying it's dumb to write new code in 2.x is fairly difficult to dispute, but it'd be a catastrophic mistake for the python ecosystem to try and force this. Companies would definitely begin to think twice about using python in the first place for new projects if such a thing happened as they'd be worried about what happens when python 4 becomes a thing. A - Now that Python handles unicode in a sensible way, there's not even a need for another language change that will be anywhere near as disruptive as the change to Python 3 was. B - The ecosystem has had nearly a decade to move on to a better language. The ecosystem didn't even have to give them this long. 5 years would have been plenty, but instead its already been 9, and they still get 3 more. This goes way past "trying to force" people to move to P3. This is nothing more than enabling laziness. The developers already did their job to make this as painless as it could be. Stop coddling and enabling these people. Its been almost a decade. There's no good excuse to not have moved onto Pyhon3 yet, none.
GitHub is so popular, you can use GitHub pages to publish a website for your projects
I check [Performance Tips](https://wiki.python.org/moin/PythonSpeed/PerformanceTips) out first. In 17 years I've never needed C(++), ctypes, cffi or cython.
&gt; simple strings Are you using Python 2 or 3 as strings were one of the biggest changes in the upgrade? I suggest that you take a look at the [struct module](https://docs.python.org/3/library/struct.html) as I believe that it could fit your needs.
True. Performance is usually a pretty rare problem for me to have, but C++ is pretty overpowered for dealing with such problems.
A list, and pretty much any object that isn't POD in Python, is treated as a reference. So it makes sense that a list contains itself. It's like if my address book contained my address. A bit weird, but it makes sense.
Python List Comprehensions: Explained Visually http://treyhunner.com/2015/12/python-list-comprehensions-now-in-color/
There's some good answers here... I'll add a little bit about "Pythonic" convention FWIW: First: List comprehensions and generator expressions can generally replace map(). [foo(e) for e in l] # instead of list(map(foo, l)) The `list()` call is necessary because the result of `map` is lazy (which is more memory-efficient). To achieve this effect without `map`, you can use a generator expression: (foo(e) for e in l) # instead of map(foo, l) Second: You should really only use a list comprehension (or `map`) when you care about the result. l2 = [e + 5 for e in l1] For example, this is an excellent use case for a comprehension because we want a list that is generated from another list. [e.update({'k' : 'v'}) for e in l1] This is not a great use of list comprehensions because we do not care about the resulting list. We only care about the iterations. A for loop should be used here instead.
What is dead may never die
Just now I was searching for 'Python list comprehension' and I was asked if I'm up for a challenge. https://imgur.com/uNoF6v7
No-one in their right mind was going to use Python 3.0 in a critical production app. 3.1 came out 7 months after 3.0, but 3.2 waited until February 2011. I feel like 3.2 is when companies really started picking it up. That's down 6.5 years already, not 10. In 2014, [/r/python discussed why they couldn't switch because of modules not being available](https://www.reddit.com/r/Python/comments/1uji8y/what_python_2_only_libraries_need_porting_to/), and that's just 3.5 years ago. Wondering why people didn't just throw the switch on December 3rd 2008 is using some very selective recollections of the last 10 years. Also, RHEL 7.x comes with Python 2. RHEL 7.x EOLs on June 30, 2024. Python 2 will get security patches until June 30, 2024, plus whatever time companies what to pay Red Hat to keep extending. No-one seriously running/maintaining current code is actually worried about 2019. &gt; The ecosystem didn't even have to give them this long. 5 years would have been plenty, but instead its already been 9, and they still get 3 more. If you don't provide LTS, companies that care about these things will move on to products that do. Python is as strong as it is today *because* it has provided such good support for 2.x. It makes companies feel comfortable about moving to 3.x, even if it's not on a time scale of your choosing.
Itâ€™s pretty sweet that the string representation still works with this
Good for you :)
Replace your imports with from paramiko import SSHClient as client Don't use `sudo` with `pip` (use your system package manager instead). Use a virtualenv or `--user`. https://docs.python.org/3/library/venv.html
Nobody thinks Python2 is going to fork when official support ends?
Post it on your GitHub, but ALSO include images to the working application. If it's a web app, do a link AND do images. Whenever I've had to hire candidates, I'll always look for his/her GitHub profile (This is not always the norm though). If they have any projects (rare, but great), the README.md can be populated with images of a working prototype. I've done this for my stuff and while it wasn't for hiring purposes, it has always peaked a lot of interest from recruiters.
Come back when software can do Hudson river landing when things fail. Don't be a jerk and understand the meat of the argument.
What is the point of smartkeys then? I'm confused why the apostrophe is there automatically if you need to type it anyways.
Python 2 and 3 can co-exist on a system. Edit: In the next version, it will support python 2 and 3.
Also, it's probably not a great idea to name an instance variable (`self.client`) the same thing as a class variable (`client = None`, which it looks like you probably don't want in this scenario). Likewise, `connection` is infintely recursive... you probably do not want that in the `class`.
Your PyCharm indexes might not be running. Or your Python interpreter isn't being setup correctly. If you show an example of your code I could probably help. Another quick way to solve this is not to worry about imports but just use the actual function/method itself and hit alt+enter (Mac) and select the import dynamically. [Imgur](https://i.imgur.com/TtrP3f6.png) 
Yeah, sorry. I don't want to step on your toes, this is still pretty useful when you need a project to stay pure python. Still, C++ is a pretty damn good tool to try if you're having these sorts of problems.
Ah looks like there are several hundreds of other people who want this feature...seems like people were asking for this 6 years ago! https://youtrack.jetbrains.com/issue/IDEABKL-6984
I have never seen a \*nix install which doesn't use /etc - *even* OSX has /etc (though I think they hide it somehow?). You can safely assume configuration is /etc - most other programs do. If you're concerned, it would be a good idea to have it "hardcoded" but in a single spot - possibly as an environmental variable. That said, have you considered installing to /opt? It's a generally-accepted practice that things in /opt can and should maintain their own file structure (so your structure would be something like `/opt/myapp/bin`, `/opt/myapp/etc`, `/opt/myapp/lib`, and so on).
Well, I am not author of article, just post it. I dont want to step on your shoes either so I wont express my opinion on C++ :) It is no big deal, I just didnt know why you sent me your comment in my inbox. But i didnt want it keep unanswered. Have a nice day
&gt; It's like if my address book contained my address. A bit weird Address books are meant for addresses though.
We are religious about testing and it took us maybe week to migrate. As i remember we had most problems with encoding in various places
It's only free support paid for by other people that ends. We'll see hoe the business benefits work out once the companies still on 2 have to stop freeloading and have to pay for maintenance updates.
I really hate it, but my team still uses Python 2.7. Python 3.x changes too fast, and we don't have enough resources to catch up with all the changes and fix regressions. Also, there are mission critical softwares using Python, which doesn't allow us to stick with "let's see what happens".
Still if is active right 
Nobody's saying that people should've ported on day one. What I will say is people should have used 3.0/3.1 for their intended purpose -- as API-stable release of Python 3 to begin testing a port against, so that when the later 3.x releases reached production quality, they'd be ready. And honestly, people who are still *today* on Python 2 and saying that there's just no incentive/not enough time are people who were never *ever* going to port, no matter how much time they were given. Ten years or ten thousand years, they just weren't going to do it, and we shouldn't be trying to cater to them at this point.
Damn I was really hoping to find some I hadn't already subbed to ðŸ˜–.
What you're telling me is you were never going to port, under any circumstances or for any reason, ever, and that "business value" was your initial excuse, and now you are angry at the Python community for being "abrasive" about how they're winding down giving you software for free because you chose, in the name of "business value", not to use the *decade* of lead time you had in which to port. I can probably draw some conclusions about your notion of "business value" from this discussion, and I'd be willing to bet that you're also the kind of company that tried to force Microsoft to keep supporting Windows XP because it wouldn't provide "business value" to you to port some XP-only internal application your entire company depends on. Because the kind of "business value" argument you're making is the very same kind that lands you in that hole, or in many other types of holes where it's very expensive to dig out at the last minute as the support gets yanked out from under you by upstream vendors, and where you always make sure to try to lay the blame anywhere other than on the person who prioritized and planned poorly despite having years of lead time in which to get it right and get it done. Here's the truth: the "business value" you're going to lose in rewriting your codebase from scratch -- because you're going to, even if you don't realize it yet, when the free support dries up and there's no "business value" in paying the market rate for someone to come in and keep it running -- is a lot more than the "business value" you'd have lost by just running a port years ago. I don't know what language you'll rewrite in, but I know it won't be Python (since it'll be Python's fault that you had to rewrite, obviously) and I know that a few years down the road your company will be in exactly the same hole it's in now, because you've made it clear you're not learning anything from this about how to run a maintainable software operation.
Zed Shaw just had an orgasm.
Divided by the last eight years, that cost is outweighed by the cost required to keep supporting 2.
The 3.x series is backwards compatible with itself. Code that runs on, say, Python 3.3 will still run on Python 3.4, 3.5, 3.6, and on 3.7 when it releases. And you've had a decade to get onto 3.x at this point. If that's "too fast" for you, it's not Python's fault.
Have you tried [Fabric](http://www.fabfile.org/)? it's built on Paramiko, but with a focus on higher-level workflows. I use it often and heartily recommend it. The current default (v1) is Python 2 only, but both v2 and the Fabric3 fork on PyPi support Python 3. 
Actually surprisingly good. Decided to check the server out for the heck of it expecting a spam server, and found a pretty well structured setup with people actually discussing python.
It has been forked already, multiple times. In the end, nobody really cares. Coding in 3.x is much nicer; there is no value in sticking to 2.x beyond working on legacy code, and nobody likes working on legacy code.
My current project is 40 python files and counting - my last one was at least 20, and I have never had this problem. very strange
&gt; Python 3.x changes too fast This is just not true. Changes are optional, not mandatory (i.e., they implement new features while keeping retrocompatibility).
I agree.
I may take a look at that. This is where integration tests will be more useful than unit tests. Bug reports with whole python sources that can't be migrated, or even Github URLs right down to the hash of the source that had to be hand-migrated/fixed up and the hash that was the fix.
&gt; Code that runs on, say, Python 3.3 will still run on Python 3.4, 3.5, 3.6, and on 3.7 when it releases. That is not actually true in every case. Each of those versions has a list of breaking changes in their release notes. For example: https://docs.python.org/3/whatsnew/3.6.html#porting-to-python-3-6 
Yes, that's exactly what they are doing. Because in some cases, it is difficult or even impossible to upgrade. So they are enabling those people to continue using 2.x, which is a perfectly fine programming language.
You sound like a dick
Other comments already mention the relevant libraries. Another hint: recent Matlab versions can call Python code, which makes a move from Matlab to Python much smoother: try to translate one small part of Matlab code to Python, and then call it from your existing Matlab scripts. That way you can move more and more of your algorithms to Python, and verify small parts of the code at a time, until all your code is actually in Python.
It's not as if we're actually deploying these bugfixes to the legacy systems anyway, nobody is touching that shit :|
i think it is some kind of spyder setting problem, i ll be really grateful if someone can help on this.
And if you read them, you find that they're bugfixes. Things like "`open()` had documentation claiming this mode combination wasn't allowed, but turns out it actually allowed that by accident, so we fixed it to not allow that because that's what the documentation said". They're not sneaking big compatibility breaks in there, and suggesting that the existence of this stuff somehow makes Python a target that "changes too fast" is not supportable.
There are some libraries which makes python really similar to matlab. These libraries are used in machine learning too so you should use them. The main one is numpy, which is used with tensorflow too, you can handle array as you do in matlab. For plotting scattering ecc.. the most famous library is matplotlib, you can do everything you want, and you can use seaborn to beautify it too, good luck with python good choice ðŸ‘
I higly recommend Udacity courses on python, I learned it there, Intro to Computer Science and Design or Computer Programming are must to have, and all of this is thinked toward machine learning which makes it fun too
Personally, I activaly use indexes activaly for presentation as they're very useful for plots and also just table presentation (e.g. after a pivot_table). I've never really used them for operating on data, I also prefer to use normal column for consistency. So my indx is most often just a ``RangeIndex``. I've read about speed advantages of using (multi-)indices, but never found an advantage when timed it. If someone could show a speed advantage example, I've be very interested in seeing it.
They are definitely not all bug fixes, and a breaking change is a breaking change, regardless of whether it is a bug fix or not. There are also a few removals of deprecated APIs in each version (the previous section). So, your Python 3.x code will _probably_ run on Python 3.y (y &gt; x), but it's not guaranteed as you claimed.
Well, in certain contexts, thatâ€™s actually the way it seems. I do neuroscience research, and all of the code Iâ€™ve written and most of what I use to do analysis and data acquisition is in python. I converted all my stuff to work in both 2 and 3 last year when the last library I needed got compatibility with 3, and itâ€™s been a headache for no tangible benefit. Asyncio? Have never used it, so it doesnâ€™t benefit me. Unicode support? All that did was horribly break some code that directly controlled hardware using bytes transmitted and received over a serial connection (code that was easy to write because I could treat bytes and strings interchangeably) - that particular nightmare took weeks to fix. Oh, and my highly optimized processing code runs about 15% slower in 3.6 relative to 2.7, and I have no idea why. So compatibility breaks and lower performance are all I really got out of the â€œupgradeâ€. And there a number of large processing packages whose authors are only now realizing that python 3 is a thing, so I have to keep a working python 2 installation on all of my systems in order to get my work done. Yes, Iâ€™m sure python 3 must have numerous advantages for somebody (web developers? Donâ€™t know.) because people keep telling me Iâ€™m an idiot for not seeing how superior it is, but for vast swaths of the installed user base (in particular scientific computing) I have seen no benefit whatsoever that make the headaches worth it. Your mileage, obviously, may vary.
That's nonsense. all getpass does is ask for user input (any kind of user input, doesn't have to be a password) without printing it to the screen.
tl;dr: &gt; List of fake package names: â€“ acqusition (uploaded 2017-06-03 01:58:01, impersonates acquisition) â€“ apidev-coop (uploaded 2017-06-03 05:16:08, impersonates apidev-coop_cms) â€“ bzip (uploaded 2017-06-04 07:08:05, impersonates bz2file) â€“ crypt (uploaded 2017-06-03 08:03:14, impersonates crypto) â€“ django-server (uploaded 2017-06-02 08:22:23, impersonates django-server-guardian-api) â€“ pwd (uploaded 2017-06-02 13:12:33, impersonates pwdhash) â€“ setup-tools (uploaded 2017-06-02 08:54:44, impersonates setuptools) â€“ telnet (uploaded 2017-06-02 15:35:05, impersonates telnetsrvlib) â€“ urlib3 (uploaded 2017-06-02 07:09:29, impersonates urllib3) â€“ urllib (uploaded 2017-06-02 07:03:37, impersonates urllib3) 
And that's fine! I just think that the Python Software Foundation should have left support for Python 2 to providers such as Red Hat in 2015, as planned :)
I use them all the time - if you have a column with unique IDs, why not make that the index? It's particularly useful when you have timeseries, because then Pandas understands how to plot and aggregate everything correctly even with missing or uneven data.
Post more context. Are you calling runfile? My guess is that you need to pass specific args to runfile to keep/print the output. Also, repost this on /r/learnpython
On time series it's useful. You can resample your data by days, weeks or whatever you like.
On time series it's useful. You can resample your data by days, weeks or whatever you like.
Thanks, I'm glad you like it ðŸ‘ŒðŸ»
That's basically what a list is. It's a collection of addresses (references) to instances of objects. It's not weird at all that a list could point to an instance of itself.
Using the dictionary file from your computer, calculate the highest possible scoring word in scrabble. If you need them, you can get a copy of a dictionary file and the letter scores from pybit.es. This is actually their first code challenge. It's a pretty decent one that, depending on your methodology, will allow you to use lists, dictionaries, while, for and if loops.
That is pretty cool - I didn't know about that one!
Yeah! So basic lossy compression is generally used in places where you do analog-to-digital conversion where lossiness is acceptable (audio, video, images). Sometimes it's part of the algorithm itself, like in the case of libjpeg, where the jpeg format is inherently built to allow lossy compression with minimal lack of visual quality. Other times, like in PNG, you can apply your own "lossy" algorithm to the image before saving it (to decrease the number of distinct colors used, or change the resolution), achieving "lossy PNG", when PNG is technically a lossless format. Definitely check out libjpeg to learn how the compression actually works - I'll warn you though that it's a bit dense. It's done both in software and in hardware. I have been working on a research project for a few years related to using the Android camera2 package to get RAW images from the camera on certain devices. Most cameras, especially in the early days of Android, actually sent the raw CMOS sensor data (the photoreceptive sensor that actually "sees") straight into a chip that had a hardware implementation of JPEG compression, before sending the result to the operating system. This aids in battery life and increases the speed to the end user. It was actually difficult/impossible to get raw sensor data in older versions of Android - you were always dealing with at least some level of compression. As for lossless compression - the Wikipedia article on Lossless compression is incredible - the table at the bottom is great for exploring the different techniques for employing lossless compression (https://en.wikipedia.org/wiki/Lossless_compression). Lossless compression is used all of the time, behind the scenes in a lot of things, as well as actively through the use of ZIP, RAR, etc. files. Most web servers, cache services (CloudFlare/Cloudfront), and more services employ end-to-end compression, especially when the client is known to be on a mobile network or on a slow connection. The interesting thing to me is the tradeoff - compression takes time and computational power (hence battery life) on both ends of the transaction, so a system designer needs to look at the whole picture to see how compression will impact the system.
There are two kinds of users of Python 2: people who have discovered that using strings and bytes interchangeably is a time bomb, and people who haven't discovered it yet. I don't doubt that you haven't discovered it yet, but "yet" is the operative word there. I had to learn this the difficult and painful way. Python 3 is preventing you from having to learn it in a difficult and painful way, though honestly maybe it shouldn't have -- lots of people need to have their code blow up at 2AM on a weekend before they learn this. Meanwhile, [here is a nice organized list for you of all the things you can do in Python 3 but not in 2](https://eev.ee/blog/2016/07/31/python-faq-why-should-i-use-python-3/). It's a bit more than just "asyncio?" and I'd be willing to bet that there are things in there which either would be useful to your code, or have already improved libraries and tools you rely on.
I think it will, and I think the people maintaining the forks will realize that it's tedious and time-consuming and companies that don't see "value" in porting to 3 also won't see "value" in paying someone to maintain a Python 2 that they used to get for free, so they'll just get "value" by going unmaintained until something breaks or gets pwned beyond repair.
&gt; And honestly, people who are still today on Python 2 and saying that there's just no incentive/not enough time are people who were never ever going to port, no matter how much time they were given. I disagree, at least with the time part. I have two python 2 applications at work that are non trivial and will require a good bit of effort to port (more than I initially thought as I switched the interpreter and it crashed immediately and after fiddling for about five hours it only crashed when doing something important). I curse the former tech lead that decided that Python 2 was the right choice two years ago. (I'm also friends with him, so it's more of a friendly cursing). Finding the time to port them is difficult since I keep need to keep up with stability for not only internal use but also external use from people that pay to use these systems. As well as answer questions from everyone that doesn't know the inner workings as well as I do (devs, product, and support a like). We're actually considering moving them to Node or DotNet (Core, hopefully), which I'm non plussed about but not opposed to as it reduces the number of stacks people need to know about. Claiming that people should've hopped right into 3 is ridiculous as 3.0, 3.1 and 3.2 were all less compatible than 3.3 or later (iirc, I'm pretty sure the u marker for strings was added back in 3.3) and it's only recently that byte strings got back some formatting options. 
&gt; Claiming that people should've hopped right into 3 is ridiculous I addressed that already *in the comment you're replying to* and never claimed that anyway.
We just upgraded from 2.4 through 2.5 to get a lot of certain machines on 2.7. With those comments I have to just assume you've never worked in industry or with 3rd party vendors.
You also might want to look up `bytearray` in the Python docs. It is basically the mutable version of the `bytes` type.
All functions have an `__call__` method that resolves to themselves. You can chain it indefinitely too. 
And I was saying that porting to 3.0 even as a test would've been a disaster for any sizeable application. 
You still seem to be assuming that "start testing your port against this" means "put it into production ASAP". Spinning up a test branch running on 3 to see how much stuff breaks, estimate the size of required changes, etc., was something that could be done very early on, but that people didn't bother to do and now are trying to sweep under the rug with "well 3.0 wasn't production-ready". And spinning up a test branch to start exploring what the port would be like would not have been "a disaster" for large codebases. It would have been the responsible thing to do.
FWIW this is bound to change quite a bit as time passes, especially with the delayed annotation evaluation PEP.
Very true. I just got into Python a few years ago. I don't do numerical analysis, though a co-worker created some incredibly useful tools to visualize where our performance issues were occurring. The 'approachability' of libraries is indeed a large part of my love of the language. Of course I love the language itself, it's downright fun to program in, but being able to drop any library into my application and do something useful immediately really made me happy and productive. I remember when people only learned Perl to do CGI, and ended up with the vague idea that Perl had been *created* to do CGI. 
Thank you for the link - thatâ€™s much more exhaustive and compelling than all the â€œasyncio! Unicode! Now shut up and port all your software!â€ articles that usually get posted here. I mean, I get it - I did port my entire codebase after all. But Iâ€™m just saying that for many classes of users, the benefits have not been nearly as obvious as the drawbacks of converting, so itâ€™s understandable that people havenâ€™t been stampeding to do it. Iâ€™m not sure I subscribe to your â€œpeople who use strings and bytes interchangeably need to sufferâ€ theory - yes supporting Unicode is better in general, but for certain use cases itâ€™s just a bother.
&gt; More than 255 arguments can now be passed to a function, and a function can now have more than 255 parameters. Um, okay. I pity the fool that has to maintain that program. &gt; Circular imports involving absolute imports with binding a submodule to a name are now supported. So now two modules can import each other? Good!
You're the only one making assumptions here. The amount of required change from 2.5 to 3.0 would be most of it because a lot of libs didn't support 3 (some still don't, and that's ridiculous). 3.0 was a non-starter for anyone with an established code base until their dependencies migrated. But since no one was using Py3, dependencies didn't migrate for a while. &gt; but that people didn't bother to do and now are trying to sweep under the rug with "well 3.0 wasn't production-ready" Guess what, 3.0 wasn't production ready for anyone with an established code base. Neither was 3.1 and neither 3.2. 3.3+ is where the pain began to ease and conversions could begin in earnest without needing to rewrite the entire application (sell that one to your manager -- "I gotta redo 100k lines of code to bump a major version on Python") &gt; And spinning up a test branch to start exploring what the port would be like would not have been "a disaster" for large codebases. I consider my self knowledgeable about Python and reasonably competent, and what happened when I spun my main work application up in Python 3 falls under disaster and after 5 hours it looked more like a disaster than when I started. I know that a full conversion would ease the pain, but seeing an application that happily hums along with few issues immediately begin spitting blood because of the change in interpreter is very disheartening. I gave a conservative estimate of a solid week of "leave kurashu the hell alone time" to have a working conversion, never mind testing to ensure I didn't accidentally screw something up that the unit tests didn't catch. Off the top of my head, at the very least you need to catch * All the places where Py2 strings are being used as strings and where they're being used as bytes and appropriately deal with them * Catch all the places where tools like map, filter and zip are expected to be eager and deal with them appropriately. * Weed out any dependencies that are still Py2 only. * Catch all the imports that have moved or been removed altogether. * Catch all the places where old style exception handling -- `except ValueError, e:` -- is used and convert that * Find all the new keywords added, where you were using them as names, and replace them. * Find things like `dict.itervalues` and change it to just `dict.values`, and find all the places that were already using `dict.values` and see if they need changing You might also have to deal with fun stuff like `raise StopIteration` becoming a syntax error in generators. This isn't just a simple conversion, change some names, throw some `b""` in and you're done. Large applications have lots of fiddly details that you don't realize were version specific until they're gone. Couple that with every code base has areas tagged with a comment that reads "This is bad and I feel bad but I needed to get it working asap, sorry" that no one wants to touch on a good day because it's just that bad. Condemning people that haven't converted off of Python 2 because their applications are too large for it be a good investment of their time (e.g. me at work) just pisses people off. You don't know the specifics of the application, the dynamics of the company or the priorities laid out for us.
What if you stored the correct answer as the first item in the list and then shuffle the answers when rendering? After user answers the question, you just need to match it to first item in the list and thats it.
Some nice changes here: &gt; Unknown escapes consisting of '\' and an ASCII letter in replacement templates for re.sub() were deprecated in Python 3.5, and will now cause an error. # &gt; collections.namedtuple() no longer supports the verbose parameter or _source attribute which showed the generated source code for the named tuple class. This was part of an optimization designed to speed-up class creation. And the obligatory "wat": &gt; Searching some unlucky Unicode characters (like Ukrainian capital â€œÐ„â€) in a string was to 25 times slower than searching other characters. Now it is slower only by 3 times in worst case.
People like you make this subreddit less interesting.
&gt; "It's because the lowest byte of the code of Ukrainian capital letter Ð„ (U+0404) matches the highest byte of codes of most Cyrillic letters (U+04xx)."
Anyone else that hasn't seen this: it's PEP 563 "Postponed Evaluation of Annotations". Tl;dr: in the future, the `__annotations__` attribute will contain the annotations in string form rather than as references, starting with a `__future__` import in Python 3.7 (assuming the PEP is accepted - Guido hasn't vetoed it yet and has been involved in discussions about it, see https://github.com/ambv/static-annotations).
It's very much made for programs generated by code.
I wish the native Python documentation was much more digestible. edit - Lol, so much butthurt.
To give a bit of context, crossbar is a Python router allowing PUB/SUB et RPC using an open and stardard protocol using websockets. The main router and clients are open source, and it's the first time I hear about a commercial release from them. I wish them good luck as I've been using their FOSS product in production and it's a solid one.
Try [Pexpect](https://pexpect.readthedocs.io/en/stable/) to do what you want.
The title made me think they were referring to the actual snake species. 
Looks like the question has been answered on SO, regarding the fact that the summary() function returns the result string instead of actually printing it, meaning that you need to manually do so. All credits belong to 'Robin', the author of the comment, not myself.
[mp4 link](https://g.redditmedia.com/mt9gXQlTaxZGA_nbl6ocD9ujfa300KW2gfNjZJ1T8pI.gif?fm=mp4&amp;mp4-fragmented=false&amp;s=e5fe2bf4559c7789272fe23390aa9645) --- This mp4 version is 93.47% smaller than the gif (171.28 KB vs 2.56 MB). --- *Beep, I'm a bot.* [FAQ](https://np.reddit.com/r/anti_gif_bot/wiki/index) | [author](https://np.reddit.com/message/compose?to=MrWasdennnoch) | [source](https://github.com/wasdennnoch/reddit-anti-gif-bot) | v1.1.2
Anyone know a macOS equivalent that still works?
I think that was the intention...
Any examples?
Nope. I haven't tried this on anything but windows
[Here you go](https://bugs.python.org/issue?%40search_text=&amp;ignore=file%3Acontent&amp;title=&amp;%40columns=title&amp;id=&amp;%40columns=id&amp;stage=&amp;creation=&amp;creator=&amp;activity=&amp;%40columns=activity&amp;%40sort=activity&amp;actor=&amp;nosy=&amp;type=&amp;components=20&amp;versions=&amp;dependencies=&amp;assignee=&amp;keywords=&amp;priority=&amp;status=1&amp;%40columns=status&amp;resolution=&amp;nosy_count=&amp;message_count=&amp;%40group=&amp;%40pagesize=50&amp;%40startwith=0&amp;%40sortdir=on&amp;%40queryname=&amp;%40old-queryname=&amp;%40action=search), only 51 reports to deal with :-(
If they have a stable setup why should they pay for anything, considering that Python 1.5 is still in production use? As I've said elsewhere in this thread, "if it ain't broke, don't fix it".
Yes, actually :P
From [Air France Flight 447](https://en.wikipedia.org/wiki/Air_France_Flight_447) "The BEA's final report, released at a news conference on 5 July 2012, concluded that the aircraft crashed after temporary inconsistencies between the airspeed measurements â€“ likely due to the aircraft's pitot tubes being obstructed by ice crystals â€“ caused the autopilot to disconnect, after which the crew reacted incorrectly and ultimately caused the aircraft to enter an aerodynamic stall from which it did not recover". Software 1 - crew 0.
"Write a failing test case, please" is successful for many FOSS projects". I can't even tell where the 2to3 project is hosted. GitHub seems confused too - https://github.com/search?utf8=âœ“&amp;q=lib2to3 - and I've expect to see a tight mirror there, if nothing else.
**Air France Flight 447** Air France Flight 447 (AF447/AFR447) was a scheduled passenger flight from Rio de Janeiro, Brazil to Paris, France, which crashed on 1 June 2009. The Airbus A330, operated by Air France, entered an aerodynamic stall from which it did not recover and crashed into the Atlantic Ocean at 02:14 UTC, killing all 228 passengers, aircrew and cabin crew aboard the aircraft. The Brazilian Navy removed the first major wreckage and two bodies from the sea within five days of the accident, but the initial investigation by France's Bureau d'EnquÃªtes et d'Analyses pour la SÃ©curitÃ© de l'Aviation Civile (BEA) was hampered because the aircraft's black boxes were not recovered from the ocean floor until May 2011, nearly two years later. The BEA's final report, released at a news conference on 5 July 2012, concluded that the aircraft crashed after temporary inconsistencies between the airspeed measurements â€“ likely due to the aircraft's pitot tubes being obstructed by ice crystals â€“ caused the autopilot to disconnect, after which the crew reacted incorrectly and ultimately caused the aircraft to enter an aerodynamic stall from which it did not recover. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/Python/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.27
Well, I'm not at my PC and I'm answering from my phone, and I know nothing about Django, but I'll try to guess that it's Memex explorer that's trying to import and not something that happens inside Django itself. What version of Django do you have? Looks like you might have a pre 1.9 (pre 19?) version, that would logically not have this warning yet. That said, if it turns out to be the case, if something like this is imported by default, this is questionable design on the part of the Memex team.
&gt;These companies have had almost 9 years to the day to move their codebases. Money and time is no longer a valid argument at this point. Missing the point and not true. If you're rolling in money and can devote resources to it without detracting from other work, you've probably already done this. Not every business is in this position. &gt;Provably false claim, but whatever man. This is "provably false", because there are a shitload of codebases out there that are doing just fine without 3. By definition that means they don't actually need Python 3. &gt;They are going to have to migrate eventually Yes, that is not in dispute &gt;Now that Python handles unicode in a sensible way, there's not even a need for another language change that will be anywhere near as disruptive as the change to Python 3 was. My point was that businesses are gun shy about choosing tools that have a history of breaking changes. My org was furious with Ansible 2 as it necessitated a lot of rewrite, we're still finding problems. Would we choose ansible again? Maybe, maybe not.
Sweet! cProfile was already fantastic, but flame graphs definitely would improve it. Usually I just pipe the output into a file and sort it in vim using `!sort -k ...`
Could you provide the most "indigestible" part of the documentation in your opinion? 
[lib2to3](https://github.com/python/cpython/tree/master/Lib/lib2to3).
And for instances where you pass a large amount of data via kwargs I would imagine.
Care to explain how?
Well I could but this debate will be like one of Michael Palin's "Ripping Yarns" comedies. The WWI POW was so determined to escape from the camp that he was still trying two years after the war had ended.
Damn! Really impressive 
Automating Cisco devices is a rabbit hole, don't roll your own unless you have to. https://github.com/ktbyers/netmiko http://docs.ansible.com/ansible/latest/list_of_network_modules.html#ios
Thanks !
&gt; These companies have had almost 9 years to the day to move their codebases. Money and time is no longer a valid argument at this point. How does the money or time issue change at all? Does it still not take money and time? Do we have a decent 2to3 yet? &gt; &gt; Couple that with there being no actual benefit to moving it forward &gt; Provably false claim, but whatever man. No it's not. Adding support for async to Python does not improve my program. It's bloat as far as I'm concerned. It really depends on what you're doing and who your program is targeted to. There are very few things outside of unicode that Python 3 does any better that will make a noticeable improvement to my code. Many of the useful features have been backported. &gt; They are going to have to migrate eventually, because eventually Python 2 will stop receiving any more updates, even security ones. And the longer they put it off, the more expensive it will be to migrate their codebase. They are just making this problem worse for themselves. You'd be shocked at how little people care about security. That must be why 90% of the people at my company use Python 2.7.8 and versions of numpy/scipy/matplotlib/etc. from that same era. I just ignore those rules because I don't want to deal with bugs and because my workflow requires packages that aren't included in our internal distribution. This order that was supposed to make our code more robust repeatedly has resulted in the program only working properly on my computer, even when written by someone else. I still maintain a Python 2.4 program for a Red Hat 5 machine. It uses PyQt3 and I'm not willing to upgrade that mess. It's shockingly not that hard to maintain. Just need to backport a bit of your code (liste comprehensions with an if statement) and you're good to go.
Patches are always welcome, here's the [bug tracker](https://bugs.python.org/) and here's the [cpython git repo](https://github.com/python/cpython). I'm looking forward to seeing all of your contributions to this open source project to which all may give something.
What? Same day really? They look like they're all uploaded by the same person. What a jerk.
Not really a big deal - I've learn how to use on the Matplotlib web page (lots of examples there : https://matplotlib.org/2.0.0/examples/animation/index.html). Once you learn how to do the basics it is only a matter to let your imagination fly. 
Why do people keep posting their SO questions here before anybody has had time to answer them? I understand that netiquette requires you to wait for at least 24 hours before following up.
I think code generation is possible. In this regard, here's interesting article: http://www.primaryobjects.com/2013/01/27/using-artificial-intelligence-to-write-self-modifying-improving-programs/ Also, for a solver-aided language, see https://emina.github.io/rosette/ Edit: Also, https://github.com/primaryobjects/AI-Programmer
Stuff like what's in this release. Software that ain't broke has yet to be invented.
Check out apistar
I had to do some analysis on some big Excel files a few (oh man, time flies.. this is in like late 2013) years ago and googled for some solutions. I tried SQLite first, and then pandas eventually. Flash forward to today where I am sort of a 'data engineer'. I learned many Python libraries and various visualization tools. I automate work at my company with ETL pipelines and I manage a data warehouse. I still use pandas for so much and I truly enjoy working with it. It completely changed my career path which obviously has impacted my personal life a lot.
I made a business rules engine in another language that would compile to code. I hit similar issues. In erlang if you pass args as positional arguments, and just append arguments to the end of your function calls, there is no copy operation when you tail-recurse your functions to different states. 
If your configuration is user specific, you could also use ~/.config/ (as standardized by people over the years). This is usually accessible through the $XDG_CONFIG_HOME envvar.
It may have to be a custom order but I believe they can make you the appropriate arrangements http://www.fancyflours.com/category/edible-wafer-paper
Anyway, the overall sequence is : 1) Generate n numbers for the coordinates (x,y) and the size of the squares - all random numbers - and append them to a respective list. In the list of sizes, when the position is even make the square color orange and green if odd. This is the plotting sequence, there is also a random variable sequence to control every square's ascent rate. 2) First phase undo a distortion on the square's shape manipulating pyplot ylim range. 3) On the second get Y axis list and iterates the rate of ascent until they are gone. In between every frame generated the plot must be clean until all process is over. 
I don't have large data sets to work with, but I still really like using pandas from time to time, it's an awesome package. I find its ability to quickly read csv, json, xls, sqlite, tables from web and many other formats very handy. I don't use most of its advanced capabilities (especially its indexing), but I can imagine it being a very powerful tool for more serious tasks. Also, its csv reader is of an order of magnitude faster than numpy.loadtxt, so, whenever I simply need to read a numpy array from a plain text file with tabs, I tend to use pandas just for that.
I don't recall the people still using 1.5 complaining. How good is the software that fly our aircraft as I don't recall them dropping out of the skies at regular intervals?
You're not actually doing anything with the query strings in your if statements. As far as I can tell, your if statements will do nothing whatsoever. 
The exact last line in traceback is File "/home/nono/.conda/envs/memex/lib/python2.7/site-packages/django/utils/importlib.py", line 6, in&lt; module&gt; from django.utils.deprecation import RemovedInDjango19Warning The more i google ,i more i am confused. I am quiet frustrated and dont know where to look for help since i have to complete my project for submission. This is the github page if you may get a idea what i am working on. https://github.com/memex-explorer/memex-explorer 
example: swagger-codegen generates API clients based on schema, so if you need to send lots of stuff in a POST body, that all gets turned into keyword args 
Agnostic of how digestible it truly is, my gut says that someone complaining about documentation being indigestible would not be able to provide a digestible version.
&gt; It's fun (for a programming language) I'm outraged.