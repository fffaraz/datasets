How easy is it to write unit-tests against? Read &amp; write to hundreds of other services - from scraping websites to message buses to databases &amp; Hadoop? How easily does it handle statistics, machine learning, and other analytics? If the answer is: it doesn't do any of these things without an enormous amount of pain, sweat, blood, tears, and breakdowns - then there's your answer for why many consider Python to be a perfectly acceptable language for tasks like this.
Using VBA is mucking in internal API. Excel VBA objects have a lot of properties, and nested objects with their own properties which aren't very intuitive, and Excel VBA has a lot of interfaces that do the same thing in different ways, or 'almost' the same thing, so the most idiomatic way to do something isn't immediately obvious. The default Excel VBA editor is next to useless(you can only undo 20 times). And trying to refactor code(putting a segment of code into a function or submodule) is a nightmare because everything is so fragile and neither the compiler nor the code is very useful at telling you what's wrong, and then you can't undo it because you're out of undos. VBA is a great way to make progress and then mess it all up. These modules on the other hand provides a useful(but limited) and reliable interface to manipulating excel.
Oh hey, I was there. She gave out a zine about strace afterwards. It was adorable!
Doesn't read like bragging this was a fascinating story thanks for sharing
Pillow is PILs *successor*, though I imagine either would work. If their draw primatives are too slow (can't imagine they would be), simple shapes like these could be done with numpy. Go for it, and report back to /r/learnpython with questions. Edit: you probably want to use subprocess to convert the photoshop file to bmp or jpg first, unless you can script in Photoshop with python directly (would be awesome but I doubt it) Edit 2: use words right.
Also VBA requires you running tasks with a windows machine that also very difficult to scale. Python is cheap and easy to deploy on virtual machines running Linux.
I think op needs to search for their repo, as the stable download on the pygame site is very old and python 2 only I believe. I also believe they have python 3 compatible somewhere.
 &gt;Whomever downvoted you is a mindless idiot. Most likely! &gt;Win10 hasn't been around long enough to assure that older python packages work. So advising that one waits for a while is good advice. Anybody doing serious work shouldn't jump to Windows 10 without testing their critical apps. This is pretty much common sense in business. &gt;Do people seriously expect everything to work without a hitch every new OS? Hell My Mac runs into issues with each OS update. Half the reason I run a beta is to be able to advise Apple of glitches. Frankly Mac OS is far more stable than Windows these days but stable doesn't mean trouble free. &gt;There are always hiccups. And there may be an annoying bug in PySerial that is being triggered in a Win10 environment. Anything is possible including the users code! If one isn't willing to debug then I really think they are getting into Windows 10 too early. 
I've ended up writing a wrapper for the com objects exposed through pywin32 for my employer, makes putting results into excel and parsing excel generated by other tools so much nicer, 
There is nothing about "absolving" here. They release the GIL for some operations. That's it. That's what millions of packages do all the time. It's nothing to really write home about. I'm a bit worried that they just now found out that they can release the GIL in their Cython code, and even make a big fuzz about it. Also, the example they used in the text is just plain weird. And using the "test_parallel" decorator actually hides what's really happening here. If you want people to see that you can call the same function in two threads, just use a `ThreadPoolExecutor`, that's about the same number of code, but in the stdlib (so people are familiar with it) and you don't have to use some weird, useless macro.
Maybe I read something wrong, or this is simply that bizarre. Does this literally consist of pretty much killing random neurons off? Because that seems like a way to fuck things up to me. 
Well, I know for a fact the *Windows* versions they have up there are up to date.
Why go for a custom json-based format when html is also pretty much the same(if way more convoluted) thing? 
Getting rid of the GIL *without breaking anything else* is the hard part.
&gt; Pillow is PILs predecessor Did you mean to write successor? PIL came first, then went unmaintained for a long time, and Pillow was the resulting fork to bring new life to the project. As to the OP's question, is the work you're doing going to be primarily vector-based or bitmap-based? Pillow/PIL has some support for vector operations like drawing lines and arcs, but that's not its main focus and it's very rudimentary. For example, it seems to be missing basic functionality such as anti-aliasing, line styles, cap/join/miter styles, etc. Pillow is really intended for bitmap operations, and if you need any kind of vector primitives you should probably use something else, like perhaps PyCairo.
I'm wondering why I would want to perform the same calculations twice. Wouldn't I want to perform two different calculations at the same time? Like counting the number of records in each group and the mean? In the example both threads will return the same result as the calculation is deterministic. Could someone clear this up for me?
It's just a demonstration. You're right, it's not useful to run the same operation twice on the same data.
it was much easier to parse the json than the html, I was originally going to do html
Duh, thanks.
Yeah, it's that simple. Dropout helps because you're forcing the network to make more redundant connections. I like comparing dropout to random forests, if you know this algorithm. In random forest, you randomly turn off some predictors during tree growth. This way, each tree has a chance to learn a slightly different way to infer the right result. Dropout is like that, except inside a single networkâ€¦
http://www.lfd.uci.edu/~gohlke/pythonlibs/#pygame
Oh, I see. I see how that would work, then. Couldn't you explicitly detect overlap between neurons, though?
Better, but reply to them directly :p otherwise reddit won't notify them to the reply
&gt; They release the GIL for some operations. That's it. That's what millions of packages do all the time. It's nothing to really write home about. Relatively few packages release the GIL for anything but a long-running external call. &gt; I'm a bit worried that they just now found out that they can release the GIL in their Cython code, They didn't just find out. They told a story leading to the thing they wanted to do. &gt; and even make a big fuzz about it. They're making a big fuss (if you can even call a blog post that) because this is something a bunch of users wanted and because it's a thing that makes their software product dask more useful. Are you part of the scipy community or a pandas user? &gt; Also, the example they used in the text is just plain weird. And using the "test_parallel" decorator actually hides what's really happening here. If you want people to see that you can call the same function in two threads, just use a ThreadPoolExecutor, that's about the same number of code, but in the stdlib (so people are familiar with it) and you don't have to use some weird, useless macro. 1. I don't know what you think is hidden. 2. Versions of Python that people actually use for real work don't have `concurrent.futures`.
This. I am actually surprised it wasn't already like this. Once you are at the C level and you stay there, holding the GIL would be classified, if not as a bug, at least as a major issue to be addressed asap for any performance oriented routine. 
It comes down to the issue of binary compatibility, which depends on the toolchain. MSVC for instance breaks binary compatibility with each release, so for example the python.org binaries for 3.4 are built with VS2010 and so you must use VS2010 if you're building C extension modules for use with that version of Python. You'd need to figure out what toolchain Anaconda used to build their interpreter and use that. [It looks like they use the same scheme as the official python.org builds](http://docs.continuum.io/anaconda/faq#how-did-you-compile-cpython): &gt; Python 2.6 and 2.7 were compiled with Visual Studio 2008 and Python 3.3 and 3.4 were compiled with VS 2010 Microsoft offers [a special downloadable version of VS2008 for use with Python 2.x](http://www.microsoft.com/en-us/download/details.aspx?id=44266). If you're building packages for 3.3 or 3.4 you can download VS2010 express. Note that Python 3.5 switches to VS2015. Edit: of course if you do decide to build the interpreter yourself you can use any version you want, assuming the source supports that version. But then you'd also have to build every package yourself, as you'd no longer be able to use the prepackaged binaries, which completely defeats the purpose of using Anaconda in the first place.
Totally agree with this. There is a huge deal to learn in getting your first hello world off the ground for s student. Idle makes the process easier for students and teachers. Although I have used cloud 9 a lot for the same purpose. 
Maybe there will be some KivEnt entries this challenge.
Hm, my intention was to clarify the context of "release" since it can also mean "make sth. available to the public". But you are right, it's not "absolving" (that why it is on parens and quotation marks)
Borg is not entirely Python-specific. In the GoF book, it's called Monostate and described as a slightly different take on what Singleton normally does. What's endemic to Python is that no interface wrapping is necessary to share the state, just assignment to object dict.
Have you tried Christoph Gohlke's packages? http://www.lfd.uci.edu/~gohlke/pythonlibs/#opencv 
Ok. Thanks. I would need to build extension modules. Which compiler do they use in windows x64? 
Says on the page: *Many binaries depend on NumPy-1.9+MKL and the Microsoft Visual C++ 2008 (x64, x86, and SP1 for CPython 2.6 and 2.7), Visual C++ 2010 (x64, x86, for CPython 3.3 and 3.4), or Visual C++ 2015 (x64 and x86 for CPython 3.5) redistributable packages.* You're probably best to stick with the same version of the compiler, or you're going to run into compatibility issues with other binaries. The trick is getting a hold of old versions of VS 2008 C++ Express to compile it with, as MS has generally removed those download links I think. If you have VS ultimate then you may be able to access the old express versions in the MSDN subscriber downloads that are attached to your account, depends on your license. This may also be useful: http://stackoverflow.com/questions/2676763/what-version-of-visual-studio-is-python-on-my-computer-compiled-with
You might want to try /r/learnpython for Q&amp;A. I'm only on Mac/Linux so I can't help, sorry.
Python 3... Obviously. There are very few acceptable reasons to still use 2. 
There are tons of ways to achieve this. You could absolutely use Python if you wanted. 
Very easy actually, you just need the right libraries.
Because you can't use VBA properly doesn't make it shit.
I'm starting a No Girls Allowed python club because exclusion is fun.
data nitro is fantastic as well. 
so edgy
This makes no sense to me at all. Exactly what are you doing? You can't get "syntax errors", the code won't even run as it'll stop processing at the first syntax error it sees.
It would, but that's just because software development is a very male dominated field. The inverse situation is not just some Boys Only conference, but rather, it's a Django Boys conference in an alternate world where men are underrepresented in software. And in that world, I bet a Django Boys conference would be well received and a Django Girls conference would come off as silly. It looks like there are many many python conferences, so it doesn't really bother me that there is one event tailored towards women. 
Thanks for everything. I look forward to the day I can put things like that together myself.
&gt; And in that world, I bet a Django Boys conference would be well received and a Django Girls conference would come off as silly. This is just not true. There are plenty fields where boys are vastly underrepresented. The major fields are nursing, education and academics in general. Any efforts made to change the tides for boys is torn down or doesn't get any attention. And it sure as hell isn't celebrated in the same ways that projects for girls are. But I don't see the points of either of those projects. It's perfectly possible to be accessible to any willing individual. But this undying focus on minorities is an Anglo-centric phenomenon anyway. These things simply do not exist in the Netherlands, and there have not been any calls for such initiatives either.
Men are allowed to attend django girls workshops, its just marketed to be more "woman-friendly" (more specifically feminine-friendly). They're just trying to appeal to a new group who might be otherwise intimidated by the typical attendees at a python workshop. From their code of conduct: "Django Girls is dedicated to providing a harassment-free workshop experience for everyone, regardless of gender, sexual orientation, disability, physical appearance, body size, race, or religion." Sounds to me like they entirely inclusive, as long as you check any preexisting prejudices at the door. Plus cupcakes.
I think anyone who expects an even 'representation' of identity politics groups in any arena of skill has to be a moron when it comes to knowledge of randomness (or historical trends, (where bulks happen, all the time)), but that being said, I LOVED the django for girls tutorials, and am all for a more feminine approach to software tutorials, if those tutorials are representative of whatever "feminine" is supposed to mean in the context of writing shit into a computer and seeing what happens. 
"There should be one-- and preferably only one --obvious way to do it." -- [Zen of Python](https://www.python.org/dev/peps/pep-0020/) Granted Python doesn't always follow its own rule(e.g. list comprehensions and lambda, map, filter, reduce), and, since Excel VBA is also used for recording macros, it makes sense that you can create contexts and 'graphically' select an object. But this makes for some very fragile code that doesn't need to exist when you're reading/inserting/formatting cells or charts
Paywall, can't view content past first level.
I've been testing with the preview of Windows 10 and it hasn't been any different when connecting and communicating with an atmel microcontroller via pyserial. You might have different drivers though which can cause issues.
The termux-camera-photo method has been updated and should now work more reliably - let me know if you still encounter any problem (note that both the Termux:API android app and the 'termux-api' apt package needs to be updated).
I didn't quite phrase that correctly, I don't think they've had the problem with sustained campaigns for civil rights. Political correctness is a knee-jerk reaction, not some kind of high minded position on society. It comes from being consistently challenged and losing for many years.
Microsoft have a download just for Python 2.7: http://www.microsoft.com/en-au/download/details.aspx?id=44266
What? They weren't seriously suggesting to create a "No Girls Allowed" group. They were trying to show the discriminatory nature of such initiatives. Some people, believe it or not, do not like discrimination in any way, shape or form.
That's like saying don't learn english
Sorry you can't make it work. You're the only one so far........
My boss doesn't actually care what language I use to solve a problem. I used python to quickly assess various aspects of our codebase to help evaluate a management issue. I was able to process millions of lines of code in a vary short period of time, refining each time based on feedback. My bosses were stunned at how quickly and easy I was able to generate processed output suitable for further heuristic spreadsheet evaluation. That sold them on python right there. Later on I used it in an entirely different way to identify, filter, download and package files that we distribute externally. It computes the URLs given certain variables so all I need to tell it is a build number and it does the rest. We wanted to make sure that we didn't expose unwanted packages, since the internal build site exposes maybe 80 packages, of which I need maybe 5. The selection process filters in AND filters out certain unwanted packages, file types, etc. It parses html first to extract the raw filenames, then uses regular expressions to filter the results. Then it computes md5sums, creates tarballs, copies the files to a spun-up VM test machine, installs them, tests the output for validity. It generates a report so when someone asks what I gave to whom and why, it's all there. No more arguing. I can adjust the filters in a conf file. The tool also performs test installs, test builds, and evaluates the output to ensure that what we distribute actually works. This kind of automation is something that would get done eventually, but we are distributing this far in advance - the tools aren't there yet. But my tool makes sure we don't release things broken or incorrectly. It's all in python, it's all automated, and I turned a 5 hour task into a 10 minute task. That's how you get to work on python in the office. It's beauty is second only to its raging practicality.
That sounds like great job security right there! Edit: [/sarcasm]
Actually it sounds like this: No you can't do that. Then in the next cutback "Sieabah isn't a team player"
Yes, but the reason that fields like nursing or education don't have public efforts to get increase male involvement is because there hasn't been a general history of discriminating against men in the work force like there has been for women. You can't just look at each field in a vacuum. These issues are part of a larger cultural story of women's historical under-representation in the work force. And why does it bother you that there is a girls conference? I mean, it would be understandable if men were having a hard time advancing in tech compared with women, but that's certainly not the case. 
You don't need to build Python, you just need to build the module using the same compiler used to build Python. And you can easily find precompiled binaries. 
&gt; Any efforts made to change the tides for boys is torn down or doesn't get any attention. Such as...?
Posting anonymously. If you're into python, don't let being a {girl,gay,otherkin,carrot} be your trademark, let your work be your trademark. If you're interested in getting hired, I'd be hesitant to put Django/Py Ladies/Girls on your resume. What I'm more concerned about is how this preferential white-glove treatment could do to bleed into the workplace. Other employees? They'll be silent, but let's face it - who isn't going to hold spite toward people who got a leg up? Yes, white, male employees come from tough backgrounds also and don't get any sympathy. I fire them if they don't perform. Tough shit! What happens when I fire a Django Girl? Do I get a law suit? You can already see the drama unfolding on sites such as Twitter and the Pycon convention. This touchy-feely group stuff, while I'm sure it's well-intentioned, has side effects that give us and some of our contemporaries pause. No, we don't bring up topics like this on the record for obvious PR / HR reasons. We can't even acknowledge it when hiring. We all have a story, but we don't know your story. Do the best you can to make your skill and talent stick out. We care about you, but we have stuff to ship and bosses / investors to satisfy too.
I didn't realize python workshops were literally the worst thing on earth. are they sacrificing children at these horrible "non-inclusive" functions? I'm not saying shit isn't different for women or anything, but people who go looking for any tiny fucking thing to take offense to will find it anywhere they are. There isn't any reason any person should ever shy away from things like that and I've never once seen something like a "Rich Able Bodied Heteroxual Wiccan White Males only" python workshop. Have you? I don't want to seem like i'm plugging the site or anything, but the vast majority of users on freecodecamp(not python related, but it's somewhat on-topic as it involves women in software development) are women, and you'd never think it at first glance. But then again, the difference there is that they specifically don't want to alienate ANYONE.
Even though some claims of discrimination don't seem all that big of a deal, it doesn't prove that there is no significant discrimination. And while I'm sure individual preference contributes to the gender gap, consider that only 50 years ago, in the US women were relegated to secretarial roles. Things have changed a lot, but I don't think it's soon enough to declare the end of gender discrimination which is why I think it's just fine that we have events like Django Girls even though there are no Django Boys events. 
I have enabled all 50 remote websites (NoScript), and its still not functional. Well, the links at the top works.
Last time I used Pandas was because of a race condition. Stepping through code in the debugger it would produce expected result. Running it in real time it wouldn't. Ended up writing my own implementations of the features I used Pandas for. No confidence in this release.
812 students is not a small sample. At all. And claiming this has no merit at all is extremely arrogant. But since you want something else more closely to cause, would you mind then [checking this documentary](https://www.youtube.com/watch?v=p5LRdW8xw70) recommended by [evolutionary biologist Richard Dawkins](https://twitter.com/richarddawkins/status/612367015878246400)? And I'd appreciate something to support your claims that not only there's an extremely abnormal amount of sexism in software businesses, but that it's also why women avoid or leave the industry? I have heard a lot of anecdotes, but never seen solid science. That combined with an almost creepy cult-like response full of ad hominems and no sustance to every time I've seen evolutionary science being brought up as evidence that maybe we're talking about a huge problem that may not exist... well, at least I believe you can see why many of us are doubtful.
[**@RichardDawkins**](https://twitter.com/RichardDawkins/) &gt; [2015-06-20 21:10 UTC](https://twitter.com/RichardDawkins/status/612367015878246400) &gt; The Gender Equality Paradox. Norwegian documentary. Worth setting aside 40 minutes to see the whole film. https://www.youtube.com/watch?v=p5LRdW8xw70&amp;feature=youtu.be ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://www.np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) 
Woah, woah. What claims have I made? Granted, I wrote "no" to your question, but that was a tongue and cheek comment. I was pushing to get evidence from you, which you've provided none. Also, studying 812 students at two universities in one country says little if not nothing about the world. I'll gladly watch the documentary, but not now...it's 12a. Also, think about who's using ad hominem? You've been criticizing me the whole time with assumptions about my beliefs when I've never made any such claim. "Did you attend a deeply religious school where they don't teach evolution?" "But I guess pursuing the "all men are sexist pigs" boogeyman is easier."
Teaching. What kind of pervert goes to work at a middle school? 
How does gender to come into the equation? Everybody has their own story, style and circumstances. Why is this a thing? Who here thinks my disagreement the concept of Py{Ladies,Goats,Fish,Carrots} makes me a bigot? I imagine a lot of you do take offense. Because after all - who could disagree with diversity! Nothing could go wrong! Indeed, I think you should spend more time focusing on groups for *python software projects*. Being a women isn't a software project, we don't care what you look like! And *everyone* has hardships! Not just {women,lgbt,blacks,whatever}. But folks. In USA, at least, we're a country made of immigrants that came from nothing. Many programmers in IT workplaces were hired based off merit and didn't have such support networks, and that includes people who had *real* barriers. Like, money, learning a language, visas, and coming from countries that are wartorn and the power is off half the day. Want to know a genuine hardship for getting into the fray in tech? Not knowing english, having an accent, etc. You're talking about most technical documentation being in english, technical english at that, and wrapping your brain around things slower.
&gt;Woah, woah. What claims have I made? &gt; then they would be wildly ignoring the cultural pressure that's being applied to both genders The rotund negation which you claim was tongue in cheek and that line made me assume (incorrectly?) that you believe that nurture, not nature is the cause for these observed preferences, and that you supported the claim that "sexism" or "brogrammer culture" (as I've seen it called in the past, I assume they mean the sense of brotherhood often created when a group of men get together) are big problems that are deterring women from opting into tech instead of just personal preferences influenced by biology. I was also replying to Deto, which did make the latter claim, so I got you two confused. My bad. And I was not accusing *you* particularly of ad-hominems, but the proponents of the mentioned theory. Anyway. When it comes to the cultural pressure point you did brought up, that's directly addressed in the documentary for when you get the chance to see it. The series of documentaries released by that author were enough for a group of nordic governments to defund an entire institute of gender studies, so they're definitely worth watching if you're interested in this whole matter whatever your stance.
I think assuming that either nature or nurture hold the key to this is naive. It's a complicated system, and the answer should be both. I'm not supplying evidence because I don't have any. However, this is a far more intuitive solution than thinking that genetics completely control the outcome or that the environment completely controls the outcome. Obviously it is both. I'll still watch the doc.
So you're saying people shouldn't be allowed to use their own scripts to access websites? If you think it's morally wrong to listen to an album for an indefinite amount of time, download it and listen to it as many times as you think you deserve to for free and delete it. There are other advantages to paying for it on Bandcamp as well, such as higher quality audio. I think it's morally wrong to tell people they have to use nonfree software and pretend not to save files in order to not be "stealing" music.
Reviving an old thread: I just built a re-tweaking of the code using the PyAV, and I'm having some difficulty getting it to actually generate useful output. Any ideas? Code is on github: https://github.com/crossan007/RasPiDashCam cam.py
How come no one's getting that he's **supporting** the GIL? He's saying that if you give people what they wish for they'll swiftly regret it.
Probably because it's something that's suggested quite often in the opposite manner. 
I'd prefer one simple blog post or a few pages from Dive Into Python 3 than some type of flash cards.
Don't. Just start using it.
py2app or py2exe 
That's the only logical explanation I can come to about why the bug was happening. Why a groupby cumsum works during a debug stepper and doesn't in real-time for large-ish data sets. This was at work too... during an audit with a deadline. Basically nailed the coffin on Pandas for me. :\
I use PyInstaller and NSIS. My customers often don't have install privileges, so I also give them access to the exe, so they can copy it directly from the install folder. Then they just need to set an environment variable and they're good to go.
I compile my external modules to pyd using nuitka, cx-freeze the lot, then create an installer with [install-simple](http://installsimple.com). No complaints so far. Just remember in cx freeze to include the msvcr dll as some users might not have it. Or have a version that's not compatible with the bundled Python instance. build_exe_options = {"include_msvcr": True} This only works with windows btw.
I did. Yeah, I admit it wasn't the smartest wording. I thought that "releasing" can have a double meaning ("setting free" vs. "making something publicly available"). I am not sure why I actually did this since everyone in this subreddit probably knows what the GIL is. Anyways, I just typed "release" into the thesaurus and "absolves" came up on top (probably due to the alphabetic order). I could have deleted and reposted it though, but I didn't think that this was such a big deal until I saw the comments here later...
Because not everyone likes monolithic systems, I think pyramid would be more reasonable direction.
I have come across a similar issue with *groupby().apply()* and I suspected a race condition, but did not investigate it further. I simply resorted to a loop over a *groupby* object. IIRC with *groupby.apply* pandas may use some magic to decide that it can **safely** use a faster code path. My guess is that for some edge case it makes(or at least then when I had an issue with it) the wrong decision.
I have started using docker to package my apps. Makes deployment hella easy. My only gripe is that my binary wnds up being a few hundred MB. 
I should go back to VS2008 just for this? I have a MSDN license for VS1010 Ultimate. I would like to make use of it as its the latest, rather than go back. Isn't that a better way to do things? No? If that is so, I would need to build Python as well and everything. Just thinking loud.
The space of weights is too many dimensional for that, and it's not clear which weights actually matter for comparison. With proper (random or RBM-based) weight initialization you can never count on that two neurons will get exactly the same input weights. So you need a measure of similarity, ie. are two neurons similar enough that they can be seen as overlapping. However, a neuron usually has lots of inputs; in a typical case, as many as the previous layer has neurons. You'd need to compare similarity of vectors of input weights of each neuron, and this task is very difficult for any large-dimensional vector space. Moreover, often you'll see that, e.g. input data covers only some subspace of all possible inputs. Let say some input is almost always zero, so it doesn't really matter what weight is assigned to that input. Then, two neurons would still work the same if they assigned wildly different weights to that input. Any measure of similarity you'd like to employ would need to take care of this problem.
What do you do in vba/sql that you think you can do better in python? 
What is the advantage in comparison to other preprocessors? I can perform the same operations using gcc on the python files, also the syntax is simpler
We had a woman who came to hackspace once. She got absue for being female and never returned. There are two ways to fix this (assuming you aren't someone who believes it's not a problem). The first is to make everyone not be a jerk, which is a very long term project. The second to build a gender-restricted community to provide some immediate home. This is a short-term project and thus easier. When these communties grow to a size where they can integrated into the main community as equals, the first solution will become much easier - in fact, it may be unavoidable.
Well define "desktop software" Usually it's easier to distribute a single biary and build it as a webapp and let the browser take care of already being installed/distributed in my situation. You could try the .zip distribution method for python apps. 
github for source and `pip install` for tested releases. Isn't that the standard way how things should be delivered?
&gt; You'd be surprised at the way a girl who is dressed femininely is treated compared to a girl who is wearing an old Linux tee and cargo pants. Isn't asperger's syndrome a disability? They don't have game. They just have games, porn, and dating websites (where women are toxic and slaughter thirsty men for sport). Yet you judge them so harshly when they are less than Cassanova's in real life? LOL. Let's pick on nerds. They have dicks and no social skills! Great! Hypocrisy! And cupcakes! Let's hire them despite the lack of relative skill! And get free lawsuits and more drama forced on us! Who could possibly object to this! Your morals and views are beyond reproach and pure! You liberal geniuses!
Depends on who your end users are.
&gt; Yes, white, male employees come from tough backgrounds also and don't get any sympathy. I fire them if they don't perform. As we all know, straight white males in America are literally the most oppressed group in the history of the world. If there's a group that doesn't cater/pander directly to us, then it's literally the end of the world. SEXISM! MSIANDRY! BAAAAAW! &gt; This touchy-feely group stuff, while I'm sure it's well-intentioned, has side effects that give us and some of our contemporaries pause. Why is it touchy feely when women want to get together and do something, but if guys get together and do literally the same thing it's normal?
Thanks for the tips. I'm looking at it right now and I'm definitely giving Zed Shaw's book a go. I'm pretty excited to learn and start creating my own projects with Python.
This is exactly what map is for map(sigmoid, a) will return what you want the * notation is to transform a list into arguments in a function like def custom_sum(a,b): return a + b L = [3,2] custom_sum(*L) # will do custom_sum(3,2) and thus return 5 
&gt; Usually it's easier to distribute a single biary and build it as a webapp and let the browser take care of already being installed/distributed in my situation. &gt; &gt; And people wonder why we have dog slow UI's in 2015...
Honestly, after you're done with codecademy, try to code a few small projects just for fun, and after that? Maybe buy up some books that interest you and read through and practice with them. There are a TON of books out there that can help you get into almost any field of Python. There are books on Django, NumPy, Machine Learning, Flask... Whatever you need.
&gt; The first is to make everyone not be a jerk, No one has the right not to be offended. &gt; The second to build a gender-restricted community to provide some immediate home. It will create the entrenched biases / hostility you claims already exist (but don't) as a self-fulfilling prophecy. If you want to support woman - don't treat them special. Let the chips fall as they may. Hackers respect merit; code. That's the way the system works. You want to know why you suffer imposter syndrome? This whole thing of outsiders who happen to be {women,transgenders,otherkin} trying to get into tech jobs by hijacking the social narrative is funny. 
How many Oaklandish t-shirts do you own? Hella?
That doesn't change much: def function(my_list): return map(sigmoid, my_list) without an intermediary function you can also do: def my_function(my_list): return map(lambda n:(1/(1+math.exp(-n)), my_list)
&gt; The very premise that straight while males don't face hardships is a fun can of worms opened here. I face hardships. I'm a straight white male in America. No one is saying that I don't face hardships. Or you don't face hardships. Or that any individual in the world doesn't face hardships. However, straight white males don't face hardships because of their race, gender or sexual orientation. But mostly, I'm making fun of your oppression complex because there's a group that doesn't pander directly to you. &gt;The irony you're creating a world where your rehashing these identity politics stuff off tumblr/jezebel will act as a prophecy to create the imaginary biases you fear so badly. I'm not even sure what you mean by this. &gt;Begging the question that entrenched, cartoon-like patriarchy ever existed in one of the world's most egalitarian career paths. If technology and software development is so egalitarian, why are you pitching an ungodly fit that some women got together to create a learning environment when they couldn't find one that fit them? If it's so egalitarian, why does it matter if they offer a woman centric learning area -- because you have to admit, the majority of people at other meetups, hackerspaces, conventions, etc are males. &gt; Hacker culture is built upon not caring what you look like. [K.](https://i.imgur.com/Z64LBOY.gif)
Interesting approach. Have you ever faced problems with nuitka not compiling correctly or something?
I never really looked at other projects. Most of the time I learnt when I needed to do something, or was curious about whether I could create something that came to mind. The next thing I might do is learn how to do machine learning and apply it to financial data to see if I can predict stock prices or something.
Nope, never had a problem with nuitka. Sometimes cx-freeze throws errors with certain third part modules, and I've either had to manually tweak the module to make it work, or find an alternative. This has only happened a couple of times, and only with obscure stuff.
Jenkins is typically how we do this. It has a web server so anyone can access it through a browser. It can give your scripts an easy front end to pass parameters and it has security so it can be restricted to specific users.
This question really belongs to /r/learnpython. There's a few different ways of doing this you can use `map` as /u/6086555 suggested, or you can use a list expression: import math def sigmoid(n): return 1/(1+math.exp(-n)) a=range(-10,11) print [sigmoid(n) for n in a] An even nicer way is to use numpy arrays instead of lists: import numpy def sigmoid(n): return 1/(1+numpy.exp(-n)) a=numpy.arange(-10,11) print sigmoid(a) print sigmoid(0.0) This way you can use the same function and it will return either a single value, or an array depending on whether the argument `n` is a single value or array. 
Typing "python" brings up another error. Is there a guide somewhere that shows you, step by step, how to get all this shit set up from square one? I swear I can code in Python, I've just never had to set anything up on my machine before and I have no idea what I'm doing.
As others have said, install this and make your life a lot easier: http://www.microsoft.com/en-gb/download/details.aspx?id=44266
thanks mate.... i didn't know that i can do that way too
dope
So, let's start my python career with some (probably horrible) small project. I built a TV show tracker with help of the *wikipedia* library. Crawling data from the *list of episodes* wikipedia pages, put them in lists and store them in TXT files. Via the cli you can add and remove shows and mark episodes or whole seasons as watched. For people who try to follow a whole bunch of TV shows this might be handy. Kind of an command line alternative for Trakt.tv Obviously not as good as those huge projects, but it was a start for me to get into at least a little bit bigger python stuff. I am sure there is a lot that I could have done (and must have done) differently and of course better than I did. But that's what I'm here for :) give me your ideas, what you like, what is total garbage and what I could have done better. 
Now publish a model so we can throw daily data at it and continuously retrain :) That was a fun read; love me some data. seattle.gov 
&gt; SQL, Excel, VBA, crystal reports I've done/am doing all those. Python or any programming language hardly has anything to do with them (i.e. it won't replace them). So the question is what you're looking to do with it. I use Python to do automation and as a glue to connect the processes - i.e kicking off vba and hide Excel to the background. Pull data from reports/DB via pyodbc, put into another table on another server and do recon etc. Basically a data flow glue. So whatever you're doing manually clicking this-and-that, automate it. Oh, and seriously - and I'll probably get downvoted for saying this - unless you're the only single person your company is and will be relying for VBA development - don't bother trying to challenge VBA with *anything*. 
None?
Python the hard way is stellar. Now that I've been using python for a while, I found that I like python 3 a lot, and I love the book Automate the Boring Things With Python. That's become my new favorite python learned book. Excellent projects, like web scrapers and such. 
I've found that the best way to learn Python is to come up with small projects to code, when you get stuck on something, just check out stackoverflow. After less than 10 or so small projects i had already picked up on coding GUI programs with multithreading, pattern matching with regex, and experience in using a wide variety of modules from the standard lib.
Regular expressions would be your friend with this Kind of task. Here's one strategy, 1. Split a sentence on word boundaries and save to list, 2. Iterate over each word and use regex or string find to identify its index, be able to handle duplicates... 
Sorry, the last part. Using json to serialized your list to a file would be easiest I think. 
Experience is the best teacher. The best avenue for experience comes through work or school. If neither of these is n option, find an application that interests you, eg raspberry pi, data analysis, gaming, system automation, web development... And been pursuing small tasks that support that area of interest. When you've made some progress start looking for open source projects that yo might want to start contributing to. 
The Raspberry Pi seems like a very interesting project to fiddle with. Have you got any experience with the same?
You will get downvoted, but it's true. It should not be this hard to distribute Python code.
Write a lot of code. It will suck for a long time, do it anyway. Eventually you will write something and someone will say, "Wow, that is awesome."
I build Python (with shared lib) and Postgres using [musl libc](http://www.musl-libc.org/). Plus about a dozen Python modules added via pip. Then I use rsync to transfer the two install directories to customer machines. There I run Postgres and a few Python scripts. Using musl lets me build on a modern install of Ubuntu and install on Linux going back ten years or more, including some (patched) 2.4 kernels. In fact, my musl built versions runs better on the old 2.4 machines than my previous attempts to build Python and Postgres on 2.4 machines using the standard glibc.
What's Oaklandish?
It's a [store](http://oaklandish.com/) in Oakland that sells Oakland related stuff.
I haven't really done much, but I did a project that would get electrical parts prices from a website and put those in a spreadsheet for use during bidding. So, if the bidder was pricing a job, he could just put all the parts into the spreadsheet, and create a pretty exact estimate of the cost of parts.
OK, here is the [discussion](https://twitter.com/wswld/status/573531008324206592). He retweeted someone and I replied to the original poster and him. He probably got pissed and later I noticed I'm blocked. I'm not sure whether he's seen that but I [reflected](https://twitter.com/wswld/status/576158778204295168) on this whole situation a bit later. My original question was absolutely sincere, no attempt at trolling or anything. He got into all that feminism and "let's get as much girls coding as possible" stuff lately. Probably his reaction is justified from that angle, I don't know. Still the book is superb and that is all that matters. 
[**@wswld**](https://twitter.com/wswld/) &gt; [2015-03-05 17:10 UTC](https://twitter.com/wswld/status/573531008324206592) &gt; @DiscordianKitty @zedshaw @twitter so, people can't use the words "rape" and "machine" together anymore? ---- [**@wswld**](https://twitter.com/wswld/) &gt; [2015-03-12 23:12 UTC](https://twitter.com/wswld/status/576158778204295168) &gt; I've just realized that @zedshaw had blocked me for a mildly critical tweet. That escalated quickly. \#dramaqueen ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://www.np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) 
We did several nice Twitter exchanges before that and this whole situation was a bit disappointing from "why can't we all just get along" perspective.
We could do that sure, are you in CS at Toronto? I'm heading to Waterloo
I feel like this is actually a great reason to abandon python for another language. (I won't because I don't want to learn another language and have managed to find a solution for python everytime thus far, but the point stands.) If you can't distribute your code, what good is it (to non-developers)? Just curious, does Go have the same quality of ecosystem that python has? 
Damn! I thought I'd fixed that last year! What exactly is the problem? Alas, having an IPython-like injection console is rather outside the realm of practicality. I'm having enough trouble trying to get tab-completion in (tried using Jedi but it's slow and gives absolutely inane suggestions). You *can* paste into it with Ctrl-V (but not copy...) if that's any consolation.
Very nice! Can you remove these `if`s in `__getattr__`? def __getattr__(self, name): if name == '_wait': return self._future.result elif name == '_timeout': return self._timeout Just use a regular property for the first, and the second is not necessary?
yeah, that was over-sensitive bullshit on his part. 
&gt; Regular expressions would be your friend with this Kind of task. Yeah, maybe in a professional context. This is a learning project; OP wants `''.split`.
I think you will need to explain more and provide an example what you are attempting. Do you want python to call your language, and then exit out of your language before python exits?
Okay sorry if I didn't explain myself well enough. I am writing a library basically for a little known language called Zeno. I currently am only learning python I don't really understand how to create parsers and such so I am settling for writing a module for the Language. In the Language every file must start with Program and must end with end program. I know how to end program with sys.exit but I can't figure out a way to make sure "Program" is included in all scripts written with this module.
Ahhhhh. That's what I was worried about. Yeah, that's an issue with the rendering and text IO library I use. I'll see what I can do.
So why not just use a Zeno interpreter? Here is a link to the Zeno 'homepage' although it does look a little dated. http://www.abecedarical.com/zeno12/zeno.html Do you want to learn python or do you just want something to work with Zeno? Also have you searched /r/learnpython ?
Definitely not me. I didn't get that far yet. Update: The first one with a missile launcher? Yeah, crash there.
still wearing that t-shirt ?
* Using Jython + HTMLUnit: [Web Scraping Ajax and Javascript Sites](http://blog.databigbang.com/web-scraping-ajax-and-javascript-sites/) * [Running Your Own Anonymous Rotating Proxies](http://blog.databigbang.com/running-your-own-anonymous-rotating-proxies/) * Scraping via a Google Chrome Extension: [Scraping Web Sites which Dynamically Load Data](http://blog.databigbang.com/scraping-web-sites-which-dynamically-load-data/) * [Automated Browserless OAuth Authentication for Twitter](http://blog.databigbang.com/automated-browserless-oauth-authentication-for-twitter/) Some of them require changes to work with the last web app versions.
Because I am trying to create a interpreter of sorts that works on android. Zeno files can't be run on android but python files can 
Any Python I actually deploy in a production environment runs on CentOS I package everything up as an RPM, which is extremely easy for any setuptools-based project - I also do the same with any dependencies, as a result I'm a little more frugal with what I depend on to limit the packages in our local yum repository, but it makes deployment and updates a breeze in tandem with puppet.
Elegant.
How do you get the current level index? How can you replay a specific level? Anyway if it's the 1st missile launcher, try setting it's clock or timer to 0 or a very large value. Don't remember the attributes, but that's how I got it to crash.
How is it really hard? Just give folks the code in a compressed file, extract, they're done. 
I say this as a former Delphi developer... people don't develop much desktop software anymore, and those that do are not using Python. In Stack Overflow's latest survey, less than 9% said they primarily develop desktop software. 
Have been working at a very large callcenter. They used a shitty working schedule calendar only accesible in internet Explorer due to active x junk and sorts. Made a little script that users can use to logon, scrape their schedule and convert to ical feed. Now people can acces it from any os anywhere. 
I'll shamelessly plug [Pynsist](http://pynsist.readthedocs.org/en/latest/), my tool for building Windows installers for Python applications. It came out of my experience using and helping others use freeze tools (cx_Freeze, Pyinstaller, py2exe), and I think I've avoided a couple of the main things that seem to make those tools brittle. Overall, though, the tools to distribute Python desktop applications are relatively primitive. Most of the effort goes into packaging libraries, deploying web apps, and for part of the community, sharing scientific code.
I tried changing both of them actually. Rate to 0, so no firing at all right? Crash :) Ok then, refireclock to a about a billion, it should wait a loooong time between shots right? Crash :) And the magic you can do to a missile object... missile.__class__.__init__=None Complains in red that there's an exception, but no more missiles :) 
Yeah, I've used it at work and home. If you're into IOT or DIY hacking their are lots of options. A couple of caveats though, if you're not familiar with Linux, particularly the terminal environment, it might be a learning curve on top of the coding. Also, you'll be learning as much about embedded hardware interfacing as coding... 
sudo pip? Ewww
Yup, that's definitely the proper way to do it. As an added benefit, it forces you to think more consciously about what you expose. I'll push a fix :)
Haha, fair enough. Changing that now. 
And what if the tool is garbage?
Unless you want to use that JSON library in your RPython interpreter there is absolutely no reason to write one.
That's the best you have? "You support women in technology and tearing down the boy's club so I'll call you a doodoohead!" My cat has meowed things that hurt more. 
Happy to pitch in. I do love python so much. 
Love it! I'd say slightly simplify things and change: def threads(n, timeout=None) to: def threads(n=None, timeout=None) so it uses `n=cpu_count` by default. Might also want to overload `__call__` and some other special methods in `Tomorrow` in case the decorated function returns something with more than just attributes.
Maybe someone can help me fill in the gaps in my understanding of asyncio. It's basically a chain of `yield from` statements, right? Each one passes a sequence of values from a sub-coroutine to the caller. So what happens when you do something like `await asyncio.sleep(10, result='a')`? The 'a' isn't ready yet, but you can't just block, so it must yield some garbage value in order to give control back to the event loop (via whatever path of `yield from` calls lies between these two points on the call stack). The garbage value isn't documented, I just assume it exists because I can't understand how we avoid blocking otherwise. And how does the event loop know when a coroutine is ready to run? All these application level code examples and presentations do nothing to explain the actual implementation. It's like programming in Python without knowing what opcodes are.
How does this even relate to gamer gate. Calling *other* people bitter is ironic, to say the least. *Brogressive attitude*. Oy. 
No luck running it yet. I installed all of the libraries that it said I needed still (rsa, pygcurse, cx_freeze, fx). Here's what's happened so far: If I run 'python main.py' from the terminal, I get TypeError: unsupported operand type(s) for +=: 'NoneType' and 'str' To fix this, I just removed the 'WIN32' key and its value from the _savedirs dictionary in main.py (which is the same line it referred to in the error output). Then, after I get rid of that dict entry and run 'python main.py' again, the game loads and I see the initial screen that tells you the controls and such. But when I try to continue from there, I get this error output: Argument 1 must be str or unicode, not &lt;class 'NoneType'&gt; Error in atexit._run_exitfuncs: Traceback (most recent call last): File "main.py", line 468, in send_error_report connection.sendall(traceback.format_exc().encode()) File "/usr/lib/python3.4/traceback.py", line 256, in format_exc return "".join(format_exception(*sys.exc_info(), limit=limit, chain=chain)) File "/usr/lib/python3.4/traceback.py", line 181, in format_exception return list(_format_exception_iter(etype, value, tb, limit, chain)) File "/usr/lib/python3.4/traceback.py", line 146, in _format_exception_iter for value, tb in values: File "/usr/lib/python3.4/traceback.py", line 125, in _iter_chain context = exc.__context__ AttributeError: 'NoneType' object has no attribute '__context__' Not sure why this is happening, but I thought I'd let you know. I'm running Arch and am using Python 3.
*facepalm* My bad. Checkout [my branch](https://github.com/schilcote/pygcurse) of Pygcurse over the version in your site-packages for the time being. I'll bug /u/AlSweigart about accepting the pull request to make things work. &gt; To fix this, I just removed the 'WIN32' key and its value from the _savedirs dictionary in main.py (which is the same line it referred to in the error output). Funky. I've been meaning to start cross-platform testing with Vagrant; I guess I'd better get started. Err, wait, wait... how did you install `fx`? 'Cos that's INJECTION's Cython graphical effects module; I'm pretty sure I distributed it with the game. You might have to change it from `fx.pyd` to `fx.so` or recompile it by running `setup`. ... And it shouldn't actually *require* cx_freeze either... I only use it to package the game for Win32, it doesn't actually get used by the game at all.
The default user-agents are all configured with very restrictive time limits. You are supposed to set a [meaningful user-agent](https://github.com/reddit/reddit/wiki/API) that properly identifies your code. If you do that you won't be limited any more. 
You can probably set the default to cpu count in the kwarg unless you expect this to ever change at runtime.
This is fantastic, nice work!
Just small mistake in your import in \_\_init\_\_.py you didn't update. Traceback (most recent call last): File "&lt;pyshell#1&gt;", line 1, in &lt;module&gt; from tomorrow import threads ImportError: cannot import name 'threads' You moved your code, but didn't use a relative import. Otherwise, looks good. 
&gt; This is unacceptable for most people. fuck em
Either cx_freeze or build a rudimentary GUI with tkinter first and then use whatever installer utility to bundle that. 
I feel like I shouldve known this earlier. But TIL logging.debug
There's a lot of good shit I've never heard of here, so don't feel bad!
So oddly enough, returning functions is already supported. Using the old style python classes (that don't inherit from a parent class) and overriding `__getattr__` means that calls to any `__method__` (including `__call__`) are routed through `__getattr__`. With regards to the default, I think I'd prefer to either default to 1 or not provide a default at all. Using `n=cpu_count` isn't ideal because we're using the python threading library rather than the multiprocessing library, so we don't actually distribute load across cpu cores. I'm hoping to eventually add a `processes` decorator that inherits from the `multiprocessing` library instead, but have run into troubles with serialization. Perhaps I can get something working with `dill`, `__getstate__` and `__setstate__`.
Hi Xtatics_, I'm happy to push up a fix to use a relative import, but I am curious exactly how you ran into the error. Was it an error after `pip install tomorrow`? I can't seem to reproduce the issue (even spun up a remote machine to install fresh from pip), and it wasn't caught by my CI software. Any chance you named a file tomorrow.py? 
&gt; Using the old style python classes Huh, well TIL! &gt; I think I'd prefer to either default to 1 or not provide a default at all Yeah `cpu_count` is the default `max_workers` for `ProcessPoolExecutor`, but it'd be nice if there was a reasonable default for `ThreadPoolExecutor` too. Not sure if there's any other reasonable value, except maybe just a large constant.
Ok, pardon my python neophyte-ness, but doesn't virtualenv or the built-in equivalent in python 3.4 build an environment, including the python binary itself, in a directory structure? And doesn't that include all of the (python) dependencies? Couldn't this be zipped and then just extracted to where they wanted to install the program? It seems to me this is the way PyCharm is distributed (minus the Java runtime itself) and that it should work for Python too. Obviously if there were complex non-python dependencies then you might need to use an installer appropriate to the OS the software is being deployed to.
I'm learning.. Thanks!
It's like the author hates readers, opening with a title and first sentence that alienates half of them.
try different version of python. I think you get that error in python 3
Do the following steps to enable the python interpreter into your command prompt: goto file explorer -&gt; this PC: on the left top of the file explorer, there is a "computer" tab, click it. then on the right side, click system properties. On the left side of the system properties page, there is a link to "advanced system properties", click it. On the bottom of the window "advanced properties", there is a button titled "Environment Variables", click it. There are 2 types of variables, "User variables for (name)" and "System Variables". in System variables, find the variable called "path", click "path", then click edit. Go ALLL the way to the back using an arrow key or just find another way. add this ";C:\Python34" 34 being my version of python, Basically it's your python folder in "C:", usually there called "C:\PythonXX" X being any number. Click ok, then just hit ok on all of the open windows, and exit out of your existing open command prompt (if it's open), then run it again and type "python". This is all if you have python installed. If this doesn't work, then just search online for "instally python as a enviroment variable" or "how to use python interpreter in the CMD".
[Hunter][] seems a real jam. [wdb][] is missing in the list, but also is useful for web programming. [Hunter]: https://github.com/ionelmc/python-hunter [wdb]: https://github.com/Kozea/wdb
...alright. so it's okay for a woman to leverage her gender and sexuality for favors and popularity, but it's not okay for women to get together and actually develop their skills. Because they're ~~not in the proverbial kitchen~~ rogue drama queens screeching rape. I think you should seriously reread your post, seriously reconsider your opinions and maybe seriously go fuck yourself. And don't be a coward with a throwaway to hide your shitty, sexist, outdated opinions. 
Nitpick: Why not replace this if self.Alive: pygame.draw.rect(env.gameDisplay, self.white, (self.x, self.y, self.width, self.height)) else: pygame.draw.rect(env.gameDisplay, self.black, (self.x, self.y, self.width, self.height)) with this? colour = self.white if self.Alive else self.black pygame.draw.rect(env.gameDisplay, colour, (self.x, self.y, self.width, self.height)) It's shorter and has less indentation. Same again: Replace this: if env.CellMang is None: self.index = 0 else: self.index = len(env.CellMang) With this: self.index = len(env.CellMang) if env.CellMang else 0 You're also using `camelCase` when you should use `snake_case` for methods. This isn't very pythonic but you could reduce (heh) this: def getAliveNeighs(self): self.AliveNeighbours = 0 for N in self.Neighbours: if N.Alive: self.AliveNeighbours += 1 return self.AliveNeighbours with this: from functools import reduce def getAliveNeighs(self): return reduce(lambda n, acc: acc + 1 if n.alive else acc, self.Neighbours) This: pygame.display.set_caption('Generation: ' + str(Generation)) With this: pygame.display.set_caption('Generation: {} '.format(Generation))
Checkout the async/wait syntax in 3.5 http://www.curiousefficiency.org/posts/2015/07/asyncio-tcp-echo-server.html
I prefer to just use Python modules and packages for configuration.
A bit off topic, but a very nice approach for the **server-side** delivery: [Nylas - How We Deploy Python Code](https://nylas.com/blog/packaging-deploying-python)
I think a more pythonic solution for the `getAliveNeighs` function is: def getAliveNeighs(self): return len(N for N in self.Neighbours if N.alive) Another thing that irks me a bit is the inconsistency with variable naming. I'm fine with `camelCase` but a lot of the times it starts with a capital letter, which are reserved for classes.
Conditional expressions aren't more desirable -- plain if statements are nice and clear, clean, simple, readable. The conditional expression only got added to Python because people were using a broken and/or trick and no amount of convincing could get them to stop it with their buggy code any other way. `reduce` isn't desirable, and I recommend not using it with anything but super-simple functions if ever. For loops are much plainer and more desirable. Your reduce solution is way less readable than the original for loop, or than sum over a genexp would be. "Shorter", in and of itself, isn't a goal. Plain and simple *is*.
It works well when you don't have to read configuration using other languages. For example, you have a main program and a set of utility scripts. And you need to use database credentials within the program itself and a database backup script. Such script is usually written in Bash. How the script could read the config? I guess, there would be some dirty hacks.
And where was it decided / where is it documented by someone authoritative that putting all the code in `__init__.py` is un-Pythonic? 
Not really seeing why I should use this instead of just pyyaml.
I use three methods depending on what I'm distributing. **One-off script** Typical scenario is a script that manipulates some specific set of files, and generates a report or organizes the data in some way. For this type of project I just copy the script to the folder containing the files. If anyone needs to run it they'll have to install python and dependencies. **Python Package including Command-line Scripts** We have a python library at work that includes classes/methods/functions for dealing with a specific type of file generated by our CFD software. This is distributed using a Python binary exe file generated using distutils. The setup.py files looks like this: from distutils.core import setup setup(name = 'mylibrary', version = 'x.x.x', author = 'big_deal', author_email = 'big_deal@fakeaddress.com', description = 'mylibrary Package', packages = ['mylibrary'], scripts = ['script1.py', 'script2.py'] ) The package installer binary is generated using the following command: python setup.py bdist_wininst This generates a binary windows exe file which will install the package to the python site-packages and the scripts to the python scripts folder. The user must have python and dependencies already installed! This works if you have a group of users familar with Python. They will be able to use the command-line scripts but they'll also have access to the library objects/methods/function for developing their own scripts. **Stand-alone application or command-line tool** For stand-alone applications I use cx_freeze. This is useful for general-use tools with users that don't care what Python is and only need to double-click something to make their computer do something. I use it primarily for GUI's and some simple stand-alone command-line tools. The setup.py file looks like this: from cx_Freeze import setup, Executable # Dependencies are automatically detected, but it might need # fine tuning. buildOptions = dict(packages = [], excludes = []) base = 'Console' executables = [Executable('myscript.py', base=base)] setup(name='myscript', version = '1.0', description = 'blah blah blah', options = dict(build_exe = buildOptions), executables = executables) Then to build the application: python setup.py build This will build the file/folder structure and the executable but you will still need an installer to install it on the target PC. I use NSIS to generate an installer. Or you could just provide the folder and instructions on copying and setting it up. The only problem I've had with NSIS is in setting path environment variable for command-line tools. The library for dealing with environment variables has a limit on PATH string length and it will trash the user's PATH if the existing PATH is too long! I need a work around to this issue if anyone has one I'd appreciate their input. 
http://effbot.org/pyfaq/what-is-init-py-used-for.htm
Have you read "Getting Started"? I think, it answers your question: http://configtree.readthedocs.org/en/latest/getting_started.html#safe-defaults
Clearly he's debugging right now 
I changed the `init`, but getting following error: &gt;&gt;&gt; from tomorrow import threads Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "/Users/avi/.tmp/tomo/Tomorrow/tomorrow/__init__.py", line 1, in &lt;module&gt; from .tomorrow import threads File "/Users/avi/.tmp/tomo/Tomorrow/tomorrow/tomorrow.py", line 3, in &lt;module&gt; from concurrent.futures import ThreadPoolExecutor File "/Users/avi/.tmp/tomo/venv/lib/python3.4/site-packages/futures-3.0.3-py3.4.egg/concurrent/futures/__init__.py", line 8, in &lt;module&gt; from concurrent.futures._base import (FIRST_COMPLETED, File "/Users/avi/.tmp/tomo/venv/lib/python3.4/site-packages/futures-3.0.3-py3.4.egg/concurrent/futures/_base.py", line 355 raise type(self._exception), self._exception, self._traceback ^ SyntaxError: invalid syntax
And Let's Capitalize Every Word, So My Awesome Comment Stays Awesome...
any PEP links?
I think it predates the PEP system, but if you look at the introduction in [python1.5](https://www.python.org/doc/essays/packages/), `__init__.py` was always intended for package initialization, sitting alongside code files.
The source version is a little messed up 'cos I forgot to include the right files. I'm fixing it right now; in the meantime just delete the line about pyximport from main.py and delete all references (there's only two or three) to `fx` from gameobjs.py.
This actually looks to be an issue with the futures module, and not the changes you made. Though I haven't run into this type of issue, have you tried reinstalling the futures module? 
This is because nothing is executed until an attribute of the result is accessed. So the function returns essentially instantly, and blocks later if the function has not completed by the time an attribute is accessed. 
It aint, and thats the kicker of the summary. Even with the added benefits being added, it doesn't really change the position of where pythons stands in the spectrum of things. People are still jumping the python ship.
&gt;No one in their right mind will develop a web server from scratch Well, sometimes you do. After all, nginx wouldn't exist if somebody hadn't decided to do just that, right? But yes, most of the time, what you want already exists. I wrote a little static web server in C a while back, and it's just a ton of fun to pop open {Firefox, Chrome, etc.} and interact with something that you made. If you have the means, I highly recommend it!
Yes, but what it teaches is wrong and harmful.
I always thought of level eight as the end of the "tutorial." But yes, assuming we're talking about the same level 6, that was indeed an unintended solution, albeit one that's more work than the intended one. :P
Mind doing the community a service by expanding upon that? I'm not being sarcastic, actually. If you've got some real criticism to level here, that's useful.
yes I did!
It's what I happily use. Run it when I have a new post, no need to worry as much about server or security issues.
As a disclaimer, I do not believe this library should work with Python 3. I make use of an implementation detail of python's classic-style Classes -- namely that all calls to dunderscore methods are routed through `__getattr__` -- that is necessary in order to capture all attempts to access the value of the result. I believe Python3 does not support classic-style Classes at all, so code may not block when it should (and will instead raise a `TypeError`).
Have a look at the source: @coroutine def sleep(delay, result=None, *, loop=None): """Coroutine that completes after a given time (in seconds).""" future = futures.Future(loop=loop) h = future._loop.call_later(delay, future._set_result_unless_cancelled, result) try: return (yield from future) finally: h.cancel() It doesn't yield a garbage value, it yields an `asyncio.Future` object. Doing that says to the event loop, "Put me to sleep until this Future is resolved, and go and schedule something else to run in the meanwhile." This is not undocumented either, see the [Coroutines section of PEP 3156](https://www.python.org/dev/peps/pep-3156/#coroutines). Prior to that, the call to `call_later()` registers a callback function with the event loop. When the timeout expires, that callback is called, which in this case just resolves the future (with the value `'a'`) so that this coroutine then becomes eligible to run again. The event loop will see that this has happened and will eventually schedule this coroutine to resume at the next opportunity. Upon resumption, the resolved value of the future is sent into the coroutine as the result of the `yield from` expression, which is returned to the caller, which is how the caller receives `'a'`. 
Much of the standard library predates the time when a relative coherent notion of what "pythonic" is came together.
&gt;Edit: You can use sum with the style of your code. Yep. You can also abuse "boolean arithmetic": def alive_neighbour_count(self): return sum(n.alive for n in self.neighbours) (While we're at it, I'm going to point excitedly at PEP8; and argue that we should make clear that we're returning the count of alive neighbours, rather than some container of the objects representing them. :) )
https://github.com/tmelz/mailinator First Google hit for "mailinator" and "Python". I've not tried it myself. **Edit** and another: https://github.com/mc706/py-mailinator. This one looks to be slightly better documented.
What? No, alienating half the readers would look more like "Python 2 may become irrelevant now". Or even "Python 2 may become even more irrelevant now". ;) But seriously, this kind of technique for click-baiting is known to work pretty well.
No problem!
The first one doesn't work for Python 3, but the second one needs an API key and has a rate limit. Is there one without a rate limit/API key and is Python 3 compatible?
Yup, to expand on this, this is what ST3 is really seeing: print (x, '\t', 3 * x + 1) # statement tuple You're making a tuple. For a quick fix, add this to your code. from __future__ import print_function
I don't think it's possible that way. What you're looking for is a *callback*. Whatever changes de variable (or gets the system in the state you want) calls the callback function (or starts the worker directly). Search for Observer or Listener patterns. You already got really close with ZeroMQ Pub/Sub and PyQTs signals/slots, but you don't need those libraries, implementing a pub/sub or observer/listener for simple cases is really easy in Python.
Since both use the mailinator API, I imagine both will need an API key and be rate limited. I don't know of any kind soul who provides unidentified, unlimited rate email endpoints for zero cost. So my questions would be: a) what kind of load are you generating which goes beyond the zero-cost API rate limit? b) why are you hostile to the idea of identifying your program (but not your users) to the service provider? **Edit:** your post does somewhat smack of the "I have problem A. If I could do B I could solve A. In order to do B I need C. I'll ask the Internet how to do C." You may have more useful responses if you ask about A :).
Do you think you can add a way for it to read the date the post was written and only delete it if it is before a certain year? I can't seem to figure it out. 
If you are using just the default build function you can configure it to use python 3. 
My main bit of advice would be to not use things such as codeacademy they are not very good. If your serious buy a book there are plenty of great books out there. 
At work (Windows environment) I use py2exe to create a standalone executable. Some projects will be used by both technical and non-technical users so I have to make it as easy as possible. I wish the process was more straightforward, but it's not too bad. My main goal was to make deployment simple (nothing to set up on the user's computer) but also make it easy for a new developer to get started. A combination of good documentation and scripts help with the latter issue.
`__init__.py` is for code that initializes a package. If the code in `__init__.py` is unrelated to initializing your package, it's in the wrong place. Sometimes packages that rely on the singleton pattern, like the logging package does (for better or worse), you might want to instantiate the singleton in `__init__.py`. I personally don't like it when people stuff business logic in `__init__.py` because I find it makes it more difficult to grawk their code. It makes their package structure less explicit and more like an easter-egg hunt.
Never meant it as click bait, but other titles I considered, "Python 3.5 to get awesome features" sounded too bland or "Python 3.5 still behind on other languages despite recent changes" was too long. So I went with one that was succinct but got my point across. I'm sorry you found it click baity. On a side note, you're correct. 3.5 adoption has *barely* taken off. I definitely think that the two new PEPs are going to change that for the better, but I still feel that its behind the likes of golang since these days I write most things in go, and not python. That makes me kinda sad, but at the same time make me reflect.
Is this too simple? Create a function which changes the variable and do not have any other code which changes the variable. After changing the variable in the function add any code you want to run.
codecademy.com has a pretty decent python introduction course. 
I work with non-default interpreters a lot (mostly bleeding edge cpython for testing or pypy for deployment/speed) so my strategy is a bit different but mostly the same: If this is a internal deploy all the package names are prefixed with a three letter code. Code reflects management important info and helps prevent namespace clashing for our package names. EG `customer_code + "_dbtool"` == `rif_dbtool`. We have internal Package Archives to help deployment and centralize building if a package has binary modules. 1. If using the system python: package in a system package format (normally .deb) with `python-&lt;pkgname&gt;`. 2. If using a non-default interpreter: make sure `$INTERP -m pip install &lt;pkgname&gt;` will work. I will admit that I have a preference against venvs because I tried them out before pip was a thing, meaning that there was quite a bit more pain than there even is now days. However I have a clean work flow that works without them and have yet to have a pressing reason why to switch yet.
What part was so hard to deploy with Python that you had to abandon the project? Maybe I'm doing it wrong, but deploying to servers seems easy for the happy path.
Here's a simple untested version class Subject(object): def __init__(self, *args, **kwargs): # additional set up self.observers = [] def register(self, observer): self.observers.append(observer) def unregister(self, observer): self.observers.remove(observer) def notify(self, **extra_kwargs): for observer in self.observers: observer.notify(self, **extra_kwargs) class Observer(object): def __init__(self, *args, **kwargs): # additional set up def notify(self, subject, **extra_kwargs): raise NotImplementedError("All observers must implement a notify method.") And implement like so: class ThingIAmMessingWith(Subject): def __init__(self, initial): self.initial def do_the_thing_that_changes(self): # do the thing # when done, call notify self.notify(extra_kwargs) class ThingIWantToDoOnChange(Observer): def __init__(self, *args, **kwargs): # setup pass def notify(self, thing, **extra_kwargs): # now you do the thing you want to do, with thing containing the variable in question pass thing = ThingIAmMessingWith(initial='whatever') to_do = ThingIWantToDoOnChange() thing.register(to_do)
This very well might be the ah-ha moment I was looking for. Setting the variables not as a string type, but as a class object themselves with the ability to notify listeners might just do the trick. Thanks for your input! :) I'mma play with this a bit and see..
&gt; for them you convince your platforms package managers to package your stuff for their system. Unfortunately, that's often easier said than done, and even if you do get it packaged, it's typically months before it's actually available to end users, because it will be packaged for the next distro release. And you have to deal with several different sets of packagers, and then provide several different install instructions for different distros. Not to mention that a certain very major platform doesn't really have package management.
Don't do this. A "cleaner init" is not an important goal, but have code that is readable, predictable, easy to understand and intospectable is. Yours is slower, not as introspectable, and a WTF for anyone else reading it as putting it in init. For instance, you'll have to do the same rigamarole for appending to the error list.
(facepalm)
Somebody has to say it - your username is incredibly ironic given your reply. 
This is actually an abstract class, and I really meant 'cleaner init in subclasses'. Not having to force the subclass implementor to remember to initialize this list of validation errors. [Here's how this class is used.](https://github.com/eaternet/adapters-python/blob/diy-validation/eaternet/lives_1_0/business.py) And [this is the abstract base class](https://github.com/eaternet/adapters-python/blob/diy-validation/eaternet/lives_1_0/validated_object.py) which does this lazy initialization.
I suppose you didn't mention select() on purpose?
The init of the parent class will be called if the child class doesn't define one. If the child does have one, it should call super to run the parent's init too. That's standard practice.
I'm thinking of doing some variation of a Template Method pattern with an alternate constructor, to make it easier for subclass implementors. Like PonyORM or SQLAlchemy: class Business(db.Entity): name = Required(str) latitude = Optional(float, py_check=lambda val: -90 &lt;= val &lt;= 90) longitude = Optional(float, py_check=lambda val: -180 &lt;= val &lt;= 180)
Note I believe the .pyc files aren't just parsed they are compiled to python bytecode, sort of like with java but done at runtime not compiled tine, and I think python bytecode isn't specified/considered part of python internals. They don't save much time.
&gt; They don't save much time. Ah - so it would be more performant in the long run (assuming extra dev time to write and maintain C is not an issue) to work at a lower level... Know of any bench tests on this? If it's (say) only fractionally less efficient then I can see why it'd just be better to go with python, and get more done in less time. But if it's multiple times less efficient then it'd be better (considering the number of users reddit works with) to minimize overhead - how much slower one is compared to the other is a deciding factor.
More work? [Spoiler] (/s "1. Teleport boulder behind gate. 2. Set missile target to boulder. 3. Teleport missile to in front of gate") vs [Spoiler] (/s "1. Lure missile into chamber. 2. Set boulder gravity. 3. Potentially move boulder to line up properly 4. Set target to boulder.") Doesn't really sound like more work :p
Seemed like there were numerous talks about asyncio stuff at PyOhio this year. If anyone is interested [here's the list of videos from the conference](http://pyvideo.org/category/72/pyohio-2015). A few of the asyncio talks happened yesterday and aren't uploaded yet, so keep checking back.
Yes it makes them slower, No it doesn't matter. Database queries take a while and that is the same in Python or C, it takes a while to transfer the data, then the implementation language, so you affect 1 out of 3 by switching the back end. If you are writing a high frequency trading application, then every millisecond counts (or a MMORPG) but taking a few extra ms is not significant (you could save money by reducing the number of servers required if you have a huge site like YouTube, but the higher development costs would mean it would still take a while to break even).
1) Of course it's not as fast as C, nowhere near. Any time you need some kind of data processing it will take much longer than the equivalent C code. Python is something that is used best with C extensions. You do data serialization/deserialization with a C extension, and manipulate that data with python. For example, if you need to call some json API, the library that converts the json text file into python objects will be a C extension. 2) No. They have several python instances running that handle the requests. A load balancer is usually used to determine to which instance it needs to go to. The python code does not usually need to be optimized, talking to DBs is done through the db drivers (C extensions). Any optimization that is done in python is usually an error or lapse in the programmer. Launching a new python instance for each request would add even more overhead than just running python code. 3) It does not, mostly. Instead of having one python instance handling all the requests you have several. Then you need a separate piece of software handling the load balancing. This adds complexity to the system and higher memory requirements but not by much. Python is a great tool that allows programmers to create tools and run code without needing to struggle with your development environment. Often times something is quickly cooked up in python and iterated upon, and when the code stabilizes is converted to C/C++ for performance reasons. But many of us like having everything in python so we usually have C extensions. Web servers in particular aren't affected much by python. This is mainly because python is just sending data back and forth and even though it uses more CPU than say a C++ web framework would, the bottleneck will be the I/O capabilities of the system. Unless you're trying to save on server costs, there's no reason not to use python. And you're most likely to saving money from the extra development time you'll be saving. Although this is a point that's true for any other language/web framework (ruby on rails, nodejs, etc.)
Yeah, but how long did it take you to work out the pos-es? Unless... ohhh. That's devious.
Take a look at the [reify decorator](http://docs.pylonsproject.org/projects/pyramid//en/latest/api/decorator.html) from the pyramid framework (it's probably in other frameworks too, I've definitely seen it in aiohttp, perhaps it even has its own package on pypi?!) &gt; It operates almost exactly like the Python @property decorator, but it puts the result of the method it decorates into the instance dict after the first call, effectively replacing the function it decorates with an instance variable. It is, in Python parlance, a non-data descriptor. Edit: @defnull linked to some code from the bottle package that looks similar to the above.
Man I sure wish we did this comprehensive for all of our clients
Very nice. Thanks!
Very helpful. Thank you.
Wait, this is far more simple than the observer pattern the other poster mentioned. I can simply sleep threads until they have something worth considering... thanks for the suggestion! :) I'll play around with a few things and let you know if this did the trick. 
[Spoolyer](/s/Took the PlayerProxy out of the missile and used it to determine the positions of things), as opposed to just trial and error?
=) That's okay. I'm not doing anything major with it, but was worth trying either way.
EIGHT GIGABYTES of disk space taken up with the install :)
I just had a WTF mome t and went to check my PyCharm install. How a ~130MB installer bloated to 8 GB on disk was a trick I wanted to see! Then I realized I'm dumb...
Databases in general do not use Lucene. Lucene is specialized for full text search. There are plenty of online benchmarks that include database transactions. My favorite is https://www.techempower.com/benchmarks/ Yes it is slower than if written in C but by what margin is less clear. Usually network overhead is large enough that difference in computation time isn't that but of a deal. Databases are a good example of this. They spend more time performing calculations(string comparisons etc). And most are written in compiled languages like C, C++, and Java. 
I want to say you're getting visual studio, which is MUCH more than a python IDE, but FFS, 8 gigs!? I'm guessing it's a case of "our users have workstations, this is *the* tool they use, and 8gigs is nothing to them", which is probably true for c/c++ guy...but probably not the case for python.
&gt; So the question is what you're looking to do with it. I use Python to do automation and as a glue to connect the processes - i.e kicking off vba and hide Excel to the background. Pull data from reports/DB via pyodbc, put into another table on another server and do recon etc. Basically a data flow glue. This is what I want. &gt;Oh, and seriously - and I'll probably get downvoted for saying this - unless you're the only single person your company is and will be relying for VBA development - don't bother trying to challenge VBA with anything. Why do you say this? I am (most likely and unfortunately) in this position.
I think TagSmile means that PyCharm is just running IPython, and that's why the plots work, and that Visual Studio can do that too.
Would be nicer if this level of Python support was part of their newer IDE.
Humm... Unless event is somehow implemented as an observable or pub/sub, that's still a busy wait. See that while over there? It's just a longer wait (actually a timeout longer)
I like that the author didn't make any claims to line count in his original post. The "200 lines!" is meaningless unless it's implemented from first principles. The heavy lifting looks like it's done by dlib/numpy, which the original author acknowledged straight away. Brevity is a silly metric if it's only because 99% of the code is in the imports. Definitely an awesome app though.
Then there's the installation time. I've an HP laptop with 8G RAM, 16M broadband, hundreds of Gigs free disk space, machine doing nothing except the installation and it's about four hours 30 minutes. I'm reminded of Sir Francis Drake having time to finish his game of bowls :)
This looks great. I'm going to come back and read this later.
Okay, the 6.1 patch is out. Go ahead and try it again.
Okay, the 6.1 patch is out. Go ahead and try it again.
Ahhh. Arrite, yeah. I consider rewriting game functions to be "crossing the airtight hatchway," to paraphrase Ray Chen. Actually, why use a drone for that? You can do it with anything.
Oh, that's terrible. Mine didn't take nearly that long. Wonder if the MS servers are swamped from Windows 10 rollout Wonder what the stats are on it, maye largest single rollout ever, in terms of total size? Maybe ios or android has it beat.
yeah. because I can do same in 2 lines: import faceswap faceswap('image_path_1', 'image_path_2')
However, SQLAlchemy's support of SQLite is intended to be used in development. Your first point could apply, obviously, at any time. Not really necessary to point out. We're talking about SQLAlchemy. You chose to talk about all ORMs. In the case of SQLAlchemy, most all features are covered under the hood. As to your third point, even if it works on your system that doesn't mean it'll work on your server. With so many config options, RAM, and processing power, who knows if a query that takes 50ms on your development machine will take 10s on production? You seem to be fighting extremely hard to make SQLAlchemy seem awful for development, when it's rather obvious you don't understand SQLAlchemy (you chose to simply call it another ORM, for one).
Ideally... How do you find the data files (e.g. png's) that aren't stored in the package path?
This seems to be missing a lot about how testing ought to work. If your testing infrastructure is broken, then yes. But... The article is talking is about _unit_ tests, not integration tests. The release qualification process (where "release" might just mean "merged to master") should require integration tests, which run in an environment configured just like production. For unit tests, you're just seeing quickly, locally, if you got anything blatantly wrong, so SQLite is fine for those. And anyway, if Postgres bugs are in-scope for your tests, you want to be running the exact same version of Postgres on the same OS, and your developers aren't running RHEL 6 on their development boxes. (Or maybe they are, at which point your concern isn't test coverage of Postgres, it's your developers quitting.) If you have extensive unit tests, you should have already seen them pass _both_ on Postgres and on SQLite. (And new tests would get run on Postgres when merged into a release.) Once you're there, it's useful to measure whether you're regressing on the unit tests, and by going through this exercise, you'll know have a good idea of what things differ on Postgres and SQLite, what tests can only be run on one database engine, etc. Saying "Well, there could be things I don't understand so I'm not going to change things too much" is exactly how people describe legacy code without test coverage. If that's how you're thinking about your testing _strategy_, that strategy is legacy code. Now, your developers _should_ have easy access to a production-like environment so that they get an understanding of what can be done in raw SQL in Postgres, what timing characteristics look like, etc. But that's not day-to-day work, and your unit tests are mostly there to check mundane things like the continued correctness of business logic. Each developer should have their own test instance on a powerful box under their desk (or similar) and run `psql` there, but that's completely unrelated to unit tests. Tests aren't meant to be a 100% solution. (If you want a 100% solution, rewrite your app in Coq, and also write a relational database in Coq.) Tests are meant to be a 90% solution that run quickly and easily enough that your developers keep running them and they don't turn into a 0% solution. The remaining 10% is approached via engineering discipline, code review, continuous deployment and monitoring, etc. SQLite seems like a fine answer for a 90% solution, and seems much more likely than Postgres to keep it at 90% instead of 0%.
Because you can't afford PyCharm?
I seem to recall some feature that allows you to run a separate copy of the server daemon as your own user for testing.
Do competent people actually do that? They run a different test environment than what they are doing in prod? What is the point of test then?
s/SQLLite/SQLite/g
That's so strange... It's close. I keep getting my icons showing up in the `Python34/Anaconda` directory at the root level, which doesn't seem right. Eggs work fine, PyInstaller works fine, just not wheels. I need to poke more at `pkg_resources`...
Ah, by they I meant reddit in particular. I didn't think your note on databases was a general one. Thanks for the link! I'm heading to sleep just now but it's on my docket for tomorrow's reading. :)
[The should][1]... Unfortuntately. I've been struggling with data files to a point that I made a custom scripts which handles my data files. [1]:http://stackoverflow.com/a/14159430/1073222
what is the meaning of this :/
We just answered this kind of question a couple of days ago. How many of you guys are out there? Just kidding. I'm gonna [link](https://www.reddit.com/r/Python/comments/3fhysm/beginner_coder_looking_for_advice/ctosd07) to my previous answer. PS: But when you come you search, search - then you ask, ask.
&gt; If you have extensive unit tests, you should have already seen them pass both on Postgres and on SQLite. You shouldn't be writing unit tests that know or care about the database at all. Your integration tests should take care of testing the code that does integration. Save the unit tests for those black box methods that do complex algorithmic code and don't need to integrate with anything (assuming you even have any code like that).
... I'm pretty sure GvR doesn't actually work there, and it's just flavour text being used to appeal to "passionate" candidates.
Ahk. Yeah I need all of that :)
Its the vim command to replace SQLLite with SQLite : - is implied, and puts you into command mode s - substitute /find/replace/flags - a regex expression
thanks!
Maybe the documentation is a bit badly worded, but I'm guesing some people might be struggling from not reading it completely. If it doesn't work as advertised then it should be a major bug. Especially on the external tooling (setuptools, pip, etc) there are developers who are still passionate that the packaging story works as expected for people, within all possible limits. And if it's not then they don't mind hearing about it. From the docs for setuptools, which almost all python environments will have these days: &gt; First, you can simply use the `include_package_data` keyword, ... The data files must be under CVS or Subversion control, or else they must be specified via the distutilsâ€™ `MANIFEST.in` file. And a little after that: &gt; (Note: although the `package_data` argument was previously only available in setuptools, it was also added to the Python distutils package as of Python 2.4; there is some documentation for the feature available on the python.org website. If using the setuptools-specific `include_package_data` argument, files specified by `package_data` will not be automatically added to the manifest unless they are tracked by a supported version control system, or are listed in the `MANIFEST.in` file.)
Maybe read over the [Including Data Files](https://pythonhosted.org/setuptools/setuptools.html#including-data-files) section of the setuptools docs carefully again, to make sure your assumptions of how the machinery works in relation to `setup()` arguments are correct.
Is it so much better than Eclipse/PyDev that I should shell out Â£160 for it? I haven't played with the free version as I almost exclusively work with django and apparently that's not supported, which has always put me off. I suppose I can claim it back against taxes but it still seems quite pricey.
No, it's not. Timeout is there only because it seems workers have something to do except acting on variable updates. In other time threads will just sleep.
You're right, Django is supported in the pro version only. If you buy it, it's a once-off license, with 1 year of major version upgrades. After that you'd have to renew, or you can just keep using the program free forever, without major version upgrades, from that point onward (which is what I've been doing)
I agree that using the same software is an "of course" level point. You'd set your environments to use the same *versions* of libraries. The idea that you'd swap in a different database system to test it out is just insane.
I think this feels like too far, though. Using SQLite to test your Postgres application is getting up there with testing your Linux binary on Mac, right? Of course it's not quite right, you've changed a fundamental dependency.
Yes, by the same software I meant *exactly* the same of everything, including the operating system.
&gt; I thought those things were already pretty optimized but I guess I overestimated how fast they could get - I figured they'd be faster than the python processes that manage things. In my experience, for most simple web things the code spend about 5-10x the time waiting for data than actually computing. 
 print sum(filter(lambda x:x%3==0 or x%5==0,range(1000))) 57 characters :P some other contenders: 62: print sum([x if x%3==0 or x%5==0 else 0 for x in range(1000)]) 69: print reduce(lambda x,y:x+y if y%3==0 or y%5==0 else x,range(1000),0) It's a bit up in the air what's allowed here, though - the above all assume that the code has to be doing something that is obviously solving the problem, not just generating the right answer. But some other, shorter algorithms ARE solving the problem, just less obviously: 53: print sum(map(lambda n:105*n-60,range(1,67)))+4973 105n-60 is the closed form for the sum of the relevant numbers between 15n and 15n+1; 4973 is just the sum of 999, 996, 995, and 993, since 1000 isn't divisible by 15 and our equation will only take us up to n=66(*15=990). This mapping over a range business is unnecessary though, because we can use the equation for partial sums. 45 characters: print (lambda n:n/2*(45+105*n-60))(66)+4973 but of course this is just a single mathematical function application, so we could do it ourselves (30): print 33*(45+105*66-60)+4973 which is just arithmetic we can easily do ourselves, leading us to, I'm fairly sure, the shortest possible python program which outputs the correct answer, in just 14 characters: print 233168
How quality could testing be if you're using a different database platform? I wouldn't chance it. Act as if production.
Since Project Euler was recently hacked, there are no available forum threads. Only the problems and solution checking are available on the website right now. https://projecteuler.net/news
Oh, that's sad. There were lots of clever algorithms and implementations. :(
I agree. Hopefully it will come back soon.
If you know the basics, do something you find interesting! I personally find web scraping, data mining and machine learning very interesting. There are some pretty good tutorials on web scraping (with BeautifulSoup), and you'll learn something about HTML, too!
The first thing to do is to ascertain that you have the correct room for the argument.
I made a program that scrapes my school's schedule changes and sends them to me via Boxcar 2. It was my first big Python project and I learned web scraping and SQLite 3 from it. [It was also quite interesting to create a string from 3 lists of schedule changes](http://pastebin.com/TytzB4q8) 
/u/kraakf is not the original author, that's /u/rspivak
Working on a project for fun can be a great learning experience, and I encourage everyone to do it! And if anyone has any questions/comments/suggestions for me please feel free to let me know.
well I am already a [Rockstar programmer](http://github.com/avinassh/rockstar), so I'd leave that opportunity to someone else ( Í¡Â° ÍœÊ– Í¡Â°)
Explicitly start it with the bin/python of the venv, or else *install* it into the venv.
I agree. I use SQLite for unit tests, but they are to mock up and ensure my user creation and such functions and classes are working appropriately. Not to ensure the SQL is correct..
you could argue that you're using in-memory sqlite as a mock database
Different kind of tests. Very useful to have unit tests use something like SQLite. It does all depend on the application you're creating.
If you're using an ORM, I think you can probably get away with using SQLite locally with the proviso that your continuous integration server MUST test using Postgres. I've got into the habit of using Heroku-style database URL environment variables for Django apps, and using that approach you can have the database URL default to an SQLite file locally, but then set the environment variable to point at Postgres on your Jenkins server. Of course, it goes without saying that if you're using Postgres-specific functionality such as the Hstore field in Django then you have to use Postgres all the time.
tl;dr
That doesn't make sense. If unit tests just test code and only code, then okay. But if you need the database for tests, there is no way I would test on a different platform and have 100% confidence that it works on production.
It's still an integration test because your code is integrating with an outside component. [J. B. Rainsberger has an interesting talk on the matter](https://vimeo.com/80533536)
I'll run SQLite *early* in my development to see if my schemas make sense but I swap to Postgres asap. 
CPU cycles are cheap. Why wouldn't you at least try to aim for a high level of realism in your tests? Postgres isn't that expensive to run.
Instead of having a function post_to_dict, you can do something like the following: cursor.execute(sql) for row in cursor: data = collections.OrderedDict() for (attr, val) in zip((d[0] for d in cursor.description), row): data[attr] = val 
Aw, that's terrible. I remember spending so much time there when I was learning programming (I started with Python too, learned it for PE specifically) and loved reading about everyone else's solutions.
I'm a bit confused. I thought the whole point of markdown was a textual format that rendered in a reasonable way but, most importantly, was easily readable in source form? The only time I ever use markdown is when I want to write a load of text and I want it to be easily readable in **source form**. If I want to layout something in a pretty way and deal with fighting with commands etc I will always turn to latex. I admit, I'm not familiar with macro or its syntax, but at a glance I feel it looks even less readable than HTML!
Night and day. Easily worth the price IMO.
That's because you only need the `%` in vim. If you're using Perl or sed, the `%` would break things.
&gt; most importantly, was easily readable in source form As I point out in the readme, the number of times markdown is used as the actual display format -- as opposed to the *result* of markdown processing -- is low. So low that I've never seen it. As I understand it, Markdown makes three basic claims WRT end users and readers: * it's supposed to look pretty much like plain text *before* processing * it's easily readable in source form * It supports simpler writing than HTML The first isn't in any way important, it seems to me, because that's not a situation we generally encounter. Instead, we see the processed results. The second can matter, all right, but markdown's version of it comes with a huge drawback for me: The inability to do much of what I want to do in an HTML document. I could list examples for days: table of contents, glossary, variables, my own control over text styling at any level I wish to apply it, and so on. So I asked myself, given the same limited goal-set as Markdown, that is, easy readability at the same level of empowerment, which is to say to address point three, what can I do to go as far beyond Markdown as I want to go? Markdown italics: \*verbiage\* Macro italics: \[i verbiage\] I'm very happy with the readability. It's not the same; but it isn't significantly more difficult (or really, any more difficult at all, for me.) With that addressed, I can now go so much further in Macro. Too terse? I can trivially arrange to be able to use: \{italicize verbiage\} ...just by writing this, once: \[style italicize \[i \[b\]\]\] Or, more directly: \[style italicize \&lt;i\&gt;\[b\]\&lt;i\&gt;\] \{italicize verbiage\} is a *lot* more comprehensible and maintainable than \*verbiage\* is for me. If comprehensibility is what I'm going for. I can make the whole document switch from HTML 3.2 to HTML 4.01 or later with one tiny bit of text or a program line. This kind of thing means I can provide the same document to different audiences custom tailored for their needs. I can arrange to say \{cursive-block verbiage\} just as easily, as well as pretty much anything else I've been able to think of. I can share other people's clever styles, and they mine. So my work writing a Macro document can mean empowerment for others. That's the kind of thing I wanted. Markdown doesn't give it to me. Macro\(\) does. Having said all that strictly as an attempt to answer your question, I will also say that this is something *I* wanted, and am also willing to share with those who are like-minded. It is *not* an attempt to make you change your mindset. Thanks for reading, looking, thinking about it, and posting. :\) 
To be fair, there are other "best" libraries. For instance, [TwitterAPI](https://github.com/geduldig/TwitterAPI). [Examples](https://github.com/geduldig/TwitterAPI/tree/master/examples). [Docs](http://geduldig.github.io/TwitterAPI/).
No, while both are great products, the differences between SQLite and other databases is simply too great for the ORM to hide. SQLAlchemy, for example, does a very good job of explaining why.
Can you explain how? It seems to me like it would. The only change would be making `self.observers` a Queue. So you'd just make a ThreadedSubject class that used a Queue instead of a list. And once you get to multithreading, it doesn't make as much sense to write your own Observer/Subject classes anyway. At that point, using some sort of task queue is a better choice.
What if you need to save a file? Should that be an integration test as well? Because if not, then I think you have to reevaluate the purpose and place of databases now vs. in the past. Databases should really be thought of, these days, as either really well indexed file systems or very slow system memory. I'm primarily a web developer. Aside from a few fiddly formatting functions, I can't think of a single test I could write that *wouldn't* involve saving data to, or retrieving data from, a database. If you are writing the code that connects to the database yourself, you should write extensive integration tests to make sure it is error free. After that, you should treat the class that stores to the database like any other class. 
There are differences in type handling, auto-incrementing behavior, transactions, locking and other areas in addition to foreign key support. And that's not getting into Postgres-specific SQL features that you might very well be using for a small part of your app like reporting, even if you're using an ORM for the CRUD. I understand the attractiveness of running SQLite locally for unit-testing. But unless you've got a really good integration-test suite and are frequently using it for more than just releases, using SQLite as a short-cut for dev increases the probability of surprises once you really start using Postgres.
Ok, I will run the command listed on that page. What should I do in preparation for that so I don't screw up my system? Should I uninstall anything first? I think pip was installed when I used easy_install to download virtuaenv. Should I just uninstall virtualenv?
It doesn't **have** to be an integration test. If you mock out the open() calls, and check that the mocks receive the correct calls, it's a unit test, if you don't, but instead open the file, and verify its contents, it's an integration test. And yes, I mock out the open() calls in a unit test too. It's extremely easy to do with magicmock, and I can be sure that I don't have to worry about leftover files from previous tests, or cleaning up after tests (especially failed ones), or anything.
Just read this post https://www.reddit.com/r/Python/comments/3fpb9c/dont_test_with_sqllite_when_you_use_postgres_in/ctqtqo2 Much of what you've posted would either be extremely obvious, or wouldn't come up in testing. I've come across the auto-incrementing behavior (why don't BigIntegers autoincrement in SQLite) myself. It errors immediately. As for transactions and locking, if your running this locally I have no idea how you would run into issues there, besides speed. SQLite obviously can't be used as a shoe in for whatever's production, but neither can any test enviornment, unless, which the post I linked mentioned, you have an exact copy of your prod server available for dev purposes. That's part of the reason most people update at 4AM if they have the choice, even if they have the technology to update at prime time.
Use [testing.postgresql](https://pypi.python.org/pypi/testing.postgresql/), it will make everything easier for you.
&gt; Why do you say this? I am (most likely and unfortunately) in this position. You have good amount of experience with VBA development ? 
My pleasure. Thanks for engaging.
Have you checked the permissions on the directory and parent directories as it suggests? It should be `_rwxrwx___` where the `_` parts don't really matter.
Probably too late but does anyone know python tools makes it so you can easily deploy django apps to IIS?
Wow, I screwed this up. Thanks for the heads-up.
Here's what I was trying to link to: http://www.continuum.io/blog/pandas-releasing-the-gil
Sure, but those all come back to sed.
But it originated in sed (and [ed](http://pubs.opengroup.org/onlinepubs/9699919799/utilities/ed.html), IIRC).
A few years? How come it is still in alpha after so long time? 
Nothing, but have been using multiprocessing to handle my parallel needs :). I have no experience in developing software so was naturally just curious why it is in alpha stage so long, seems from the website its pretty solid.
Oh that's odd... I had been using `data_files=[(icon_path, icon_files)],`, but `package_data` works much better. I had to throw an `__init__.py` in the icon folder, but it works and nothing gets moved, so I'm happy. Thanks!
&gt; `pip install GIT+&lt;repo url&gt;` (you can even specify specific version or branch) my whole distribution method, no other language makes that easy in my experience.
I always thought Markdown was simply a replacement for those ugly old-style bulletin-board code thingies (bbcode). In general it's better used for forum-like discussion with comments (like reddit). I never even considered using Markdown for "big" stuff like websites or documentation. I don't think Markdown was ever intended for that, since there are much better tools out there (though I might be wrong - can't read the authors mind). &gt; The first isn't in any way important, it seems to me, because that's not a situation we generally encounter. Well, Markdown usually comes into play if E-Mails are involved. For example: I see Markdown in plain text if I receive an E-Mail Notification from e.g. Github, when someone replied on an Issue/PR or similar. And I can use Markdown to answer to that comment. Still, I appreciate your work, and I will take a look at it some time.
Cool, and you offer nice topics! But I have two mayor complaints; at first please increase the font size I can barely see the code in a normal distance to my monitor. And the second: You could insert the topic names to your video title. With part numbers nobody knows what he will get and also people will easier get to your video from the youtube search. By the way what's about the facecam in live coding videos these days? See the author in the introductions and the outro is fine but while coding it isn't necessary. Just my thoughts! Good luck with your videos!
a simple multi-lingual utility function to convert a string to boolean i.e. True, False, by guessing the approximate meaning of the input string. By default, it will return False. Return True ONLY if input is certainly a 'true'-ish word e.g. 'Positive', 'yeah' etc. Maybe, someday it will be able to detect "boolean"-lity of large sentences. But, now it can sense only single AND basic words in many languages. Any suggestion, feature-request, constructive criticism, bug, generic observation, word-of-wisdom, inspiration, or just "Thanks, buddy" is highly welcome. Thanks
Is this the windows only thing?
what sort of weird license is this under?
Atom seems nice enough. It has similar vibe to sublime. 
Aaah, thank you! I got it working now.
&gt; Right! SQLite is good for the dev phase - day to day coding where you don't want to set up hundreds of local services. (although Docker these days make that much easier to achieve) No it isn't, the other devs found *two bugs* in my code today. The first was a slow query that they couldn't reproduce on their SQLite instance (we use MySQL on production) so they threw away my 'optimization', the other found a bug in the file handling that is only reproducible on *Windows* (we never run anything on Windows, ever). Meanwhile I run 95% on the same configuration as we do on production (same DB, same settings, only difference is that I try not to cache anything so that I can only develop for the worst case scenario) and I keep finding performance issues that no-one ever considers a problem until we have users complaining that it takes 15 seconds to open a page :( Not to mention that we spend an extra week fixing migrations because SQLite doesn't enforce constraints by default, a day fixing file import "issues" that resulted from not having a case sensitive file system. There so many small differences between DB's/OS'es/Configurations. If you're not developing as close as possible to production you will run into them and it will be a huge waste of time. Next project, I'm going to force everyone to run on Dockers with production settings. Getting really tired of all those "bugs" that result from small configuration issues. Have I mentioned that we're going to go Live in two weeks and we still don't have exception/performance logging running? :(
http://www.jeffknupp.com/blog/2012/03/31/pythons-hardest-problem/ https://www.jeffknupp.com/blog/2013/06/30/pythons-hardest-problem-revisited/
When Python was written there weren't a lot of multi-cpu systems. In the 90's we had multi-processor systems but they were rare. Today cores are pretty common. Dealing with thread safety and efficiently running multiple processes across multiple CPUs or cores is actually pretty complex. Many earlier "high level" languages that did threading well were written on top of a VM. In these languages the programmer just creates as many threads or processes as they want and the VM balances it all properly against the hardware. Newer languages have come up with ways to sort of make it easier for programmers to work with threads. But it's not always easy to use those systems on older languages. So historically interpreted languages have not done threading well because they were design when it wasn't a common need. Languages that did it well/easily tended to run on VMs that did all the heavy lifting. Newer languages were built when CPU cores were more common and some newer design styles for threading come into focus, so they tend to be more flexible in this regard. 
You never test against the same scale you encounter in production? That seems risky. We used to do the same because getting bulk data we could use in testing was nearly impossible (customers all in a tizzy about 'security' and other bullshit). It bit us in the ass a few times when things were fine in test but exploded in prod (or were absurdly slow). We eventually got someone who let us keep a copy of their data for testing and things have been much better ever since
Rude.
&gt; support for subinterpreters, make them single-threaded, and provide a good API for communication between them Basically, no shared memory, right? Generally, people assume "threading" will include shared memory. That might be better described as a lightweight process model. Sounds excellent. I've done some work on systems like that. A lot of the perf can depend on which data structures you can pass across those comm channels. If it's just sequences of bytes, you end up with a lot of copying. What do you think?
It would be nice if they led early on with the meat of the project instead of burying it 87 slides deep. I'm not sure why PyParallel would bury this so deep: - GIL turned into a reader-writer lock. Main thread takes write lock, Workers take read lock. - Workers get read-only view of globals. (I'm guessing workers also can't call C-based python modules) - IO optimized to provide more concurrency, using Windows OS specific features. The reader-writer concept seems interesting. I presume that "globals" include objects that were allocated by the main thread; the slides were not specific, and it would be a pretty big safety hole if that weren't true. 
No, I don't mean no shared memory - I just mean good alternatives to shared memory as a primary recommendation and carefully-managed shared memory only where explicitly requested. You can have locks around it, but ideally there would be a slightly higher-level construct that doesn't involve manually acquiring and releasing the resource. In this case, you only pay for what you use - if your 2 Python threads only work on the shared data every 2 minutes, you only lock every 2 minutes. A shared-nothing approach is beautiful on paper but inadequate for many high performance systems. As you say, you can end up with a lot of copying and that simply won't work for everything. e.g. In a computer game, one thread might be writing entity state data and another one might be reading them for rendering or AI purposes. You can't afford to copy everything 60 times a second, you can't afford to have double the storage space, and you can't afford twice the cache misses on that data. (Yes, there are some games where you can afford this. But there are many where you can't, and performance is paramount.) How to adequately ensure that complex data structures are not modified in separate threads is a tough problem, especially when you can hold references to any part of it, and I don't have a good answer for that. But the GIL doesn't solve that either - which is why it's a problem to pay that cost without getting a serious benefit in return.
Take a look at [pypy-stm](http://morepypy.blogspot.ca/2014/07/pypy-stm-first-interesting-release.html). It's a work in progress. Pypy also supports [stacklets](http://doc.pypy.org/en/latest/stackless.html), which look pretty good and work now.
Yup. (For now.)
Haven't marketed it yet really to date... been busy the last ~8 months getting it into a semi-usable shape with an installer. I set the website up last week.
It's a fork of Python 3. If you don't use Windows, compile it yourself.
No not a ton. I am pretty solid on figuring out what I need to accomplish what I want just by googling and then designing the macro. My company didn't hire me as a VBA developer or anything. I'm just using it because it makes my job easier. Otherwise my "data managment" role is a crapload of manual work and the company doesn't really know any better, hence why I started learning VBA and why I am looking into Python.
&gt; The main problem with the GIL is that it's only a partial solution but a complete problem. It doesn't guarantee that your multi-threaded Python code is any safer Nobody claimed or suggested that it does. The linked answer doesn't list "safer multi-threading" under benefits of the GIL. So I don't get your point about it being a "partial" solution.
That's fine for independent processes, but if you need to share variables or do much IPC it isn't a lot of fun, at least from what I remember.
For performance testing we use the integration systems, not the test systems. There's dev, test, integration and production.
Do you not have a testing phase between local dev and release? I mean, like I said at the top, if your testing setup is already broken (which it sounds like it is), maybe running production-style setups locally is the right mitigation strategy. And probably, as an engineering decision, embracing and mitigating the brokenness is a way better choice than postponing launch until you get every last thing right. But as an _ideal_ you should be able to have your local tests on SQLite and also run everything in test on a prod-style configuration.
IIRC, it uses some features that currently only the Windows kernel provides, so it only runs on Windows.
&gt; No not a ton that's what I thought. To make a parallel analogy: VBA (for Excel) is like JavaScript for Browser - they're made for each other. ATM there's no turning back from JavaScript in webdev area AFAIK. The exception to the analogy is unlike Browser standards both Excel and VBA are 100% MS - for 20+ years ! MS has made hell-bent sure they are super-integrated and that nothing else works as perfectly &amp; natively for automating Excel as VBA. Unless you're the single Excel-automation guy plus the ability to persuade your company to trust you NOT to use VBA plus you have tons of time &amp; skill to come up with a "solution" to break the Excel/VBA bond, you will not get anywhere. Even if you are able to come up with something it's going to be ham-fisted and impractical - e.g. requiring users (your managers' managers' managers' .....) to install dependancies. That was my point. 
&gt; Do you not have a testing phase between local dev and release? We do but *deadlines* happend, we barely have an acceptation phase left between development and release. Still, it's not so much about embracing and mitigating the brokenness. It's about keeping the stack as simple and deterministic as possible and running a dev stack AND a production stack is twice the complexity. Tests might be slower with PostgreSQL but even than, who cares? Buy a bit more ram and run it in the background. Ideally you would have a CI traject (which by the way we do have! Setup in the glorious days when our bug tracker was still all kittens and rainbows!) where builds automatically gets tested on every commit. Given that hardware is incredible cheap compared to development I really don't see any reason why anyone would develop or test against SQLite, let alone not try very hard to keep a simple and deterministic stack.
No, and for that reason I generally use Postgres for sharing state, rather than muck around with mutexes, semaphors and so on.
For a problem that involves summing well defined sequences, generating the sequences directly might be cleaner than checking the membership status for each number between 1 and 1000. 
Nice that no one actually answered the question. It was written with a GIL because at the time it looked like processors were always going to get faster (more Mhz). Dealing with multiple concurrent threads was simply not something anyone considered a problem at the time. Now that we know that chips don't like going much faster than 3ghz, and that to deal with this problem we keep adding cores, it seems obvious that the GIL is a bad idea. Hindsight and all that.
If you're sharing lots of variables, you're doing it wrong. That's not unique to multiprocessing, all concurrent work slows down tremendously when you fail to correctly separate the workload.
Ah, that's a shame. Thanks for the info!
/u/mljoe is possibly referring to the stripped down VS Code.
Thanks for formatting your code. I assume the input number and *p* and *q* must all be integers. As a side remark, *all* integers greater than zero can be expressed as some p^q . For example, 13 can be expressed as 13^1. Perhaps you should start the interior loop at 2 instead? It's not an inexpensive algorithm. The way you have it written now is in O(n^2). You can perhaps save some time by checking each time if p^q is greater than your input. If it is, break out of the interior loop. for b in xrange(1, x): for i in xrange(1, b): if b ** i == x: return True # booleans are more semantic than 1 and 0. # the break statement here would never be reached elif b ** i &gt; x: break else: continue return False That could save you some significant time on large numbers. As you currently stand, you could be checking possibilities like 24999^24999 as a solution to superPower(25001), which are obviously false. 
Thanks man, gonna check them out after work!
I recall the original presentation (years? ago) that mentioned there once was a POC patch or upstream discussion for a comparable kernel feature. Did that go anywhere?
In other words, mostly useless.
No need for a full-fledged relational database to share data between processes.
this is a great post for [/r/flask](https://www.reddit.com/r/flask/) maybe post this there too?
[Here's my solutions](https://github.com/troyleak/Project-Euler) in Python to the project Euler problems I've finished so far! 
&gt; A shared-nothing approach is beautiful on paper but inadequate for many high performance systems. I would argue you're better off writing a single-threaded program in a language/runtime 100x faster than Python's than trying to force Python into the high-performance realm with threading. You can always tie it together in Python with the appropriate APIs exposed. Do the shared memory in, say, C++. Plus, `multiprocessing` supports shared memory if you really want to do it that way.
I think it is great that you help people learn Python and programming in general! Personally I think it would be nice if you try not to start almost every sentence with "aaam". 
Hello there! I didn't even think of that. Now, sorry for wasting your time a little bit more, but let me see if I understood: First, we search for all number between 1 and x, then, we confirm if b^i = x. And if b ** i &gt; x break the loop.. ok. I just can't see why this code works very fast. Thanks so much for your help!! Edit: This code is very fast... now I know what I've done wrong. Thank you so much!
&gt; Dealing with multiple concurrent threads was simply not something anyone considered a problem at the time. This would make more sense if it were true. But it's not; removing the GIL was tried but nobody knew how to make it fast. http://dabeaz.blogspot.co.uk/2011/08/inside-look-at-gil-removal-patch-of.html
You could turn it around, create only one loop and do root(x, i) and check if the result is an integer. Not sure if that's faster (because root is usually a lot slower than **). But it'll be one loop less, so algorithm wise it's only O(n) instead of O(n^2)
&gt; The main problem with the GIL is that it's only a partial solution but a complete problem. It doesn't guarantee that your multi-threaded Python code is any safer - just that the interpreter won't fall over when you do it wrongly. Given that the interpreter is usually only there to run your code, this is not a great relief. It prevents data races and makes bytecode instructions atomic. Those are significant guarantees that very few runtimes come close to. Remember, Python isn't designed for speed. &gt; I would argue that a better route for Python to have taken is to have improved the support for subinterpreters Hindsight is 20/20. 
Well, in my context I'm almost always writing DB related code anyway. But usually I'm parallelizing to avoid blocking, rather than for raw throughput.
Is Theano using a PyOpenCL backend under the hood?
[This might help](http://www.diveintopython.net/native_data_types/formatting_strings.html) [Python doc site](https://docs.python.org/2.7/)
Is the format to print just 2 decimals instead of all of them when you print a float 
&gt; When run on the GPU, the network quickly achieves a local minimum loss of 2.3 after one epoch. However when run on the CPU, the network achieves a best validation loss of 4233.37 even after 50 epochs. Not only is the GPU-based training significantly faster, but also it achieved notably better results. How is that possible? As far as I understand, one epoch, whether on GPU or on CPU, should perform the same calculations and end up with the same result. 
[String Docs](https://docs.python.org/2.7/library/stdtypes.html) will help you for the beginning. str.startswith(string) and str.endswith(string) will return True or False. If you just start with learning python, is'nt it a little too much writing a parser? This isn't easy.
Or drop into Cython with nogil set and you can use threads.
No, it doesn't 
...well that's a bit uncalled for. Why don't you contribute to get it working with Linux rather than pissing all over this guys hard work that he states will eventually end up supporting Linux? 
Get that working first. Simplify your problem. Run with debug. Look through that mess of a printout and fix all the warnings. PyInstaller will fail when it can't find something and the first few times you build something, chances are your environment is configured wrong and since you aren't familiar with pyInstaller, you are guaranteed to have an environment error. Start with something small. Making a single file just makes the problem harder.
TL;DR: it's not a bug it's a feature
When I make an extremely simple program, like print a single line or something it still comes up with this error.
Faster than the other posted solutions (minimal value of p and q is 2; p = 1 is trivial, always false when val &gt; 1): def super_power(val): p = 2 while(True): q = 2 while(True): tmp = p**q if(tmp == val): return True if(tmp &gt; val): break q += 1 p += 1 if(p**2 &gt; val): return False 
When do you get the error? Did you look in the log? Can you post the log/script?
I'm not sure if it'll be faster (someone cleverer than me can tell you, I'm sure. edit: it is faster by a large margin [edit again: than OP's code]) but have you considered using prime factorisation? If you look at the prime factors of any number that can be expressed as int(p)**int(q) you'll notice something. I'll leave you to spot what the pattern is. Edit: Spoiler (Click source below this comment to view - requires RES) [](http://p can be represented as a set of prime factors e.g. a * b * c * d.) [](http://p ** q = (a * b * c * d) ** q) [](http://Therefore a, b, c, d will appear in the list of prime factors exactly q times)
That doesn't really add to the answer of the question at hand, specifically "why was python built with a GIL?". You have answered the not asked question of "why do we still have the GIL?". That "nobody considered" was the gereral use, meaning "nobody who mattered". In python, there is only one person who's opinion matters, the BDFL. Besides, if you were programming back in '96, as I was, then you would remember that nobody cared about threading. With the exception of a few fringe dwellers with access to hardware none could afford.
And here's some prime factorisation code: def primefactorise(num): primefactors = [] i = 2 while num &gt; 1: if num % i == 0: num /= i primefactors.append(i) else: i += 1 return primefactors Just check the frequencies of each prime in the list of prime factors and if they're all equal you've got a hit. e.g &gt;&gt;&gt; primefactorise(1000) [2, 2, 2, 5, 5, 5] 2 and 5 appear exactly three times therefore: 1000 = (2 x 5)^3 1000 = 10^3 My code can very quickly tell you that 25000 = 2 x 2 x 2 x 5 x 5 x 5 x 5 x 5 and is therefore not expressible as p ** q.
Ah trent, feeding the trolls :-)
so if I understand this {} are placeholders and format(pc, na) are the values that will be entered into {} in their respective order?
Yup, similar to printf("%s", "abcd"), just that its more general. So it can be used for any data type, be it arrays, dictionaries, ints, etc
As for slide guidelines, you would be hard pressed to get better advice than this: http://zachholman.com/posts/slide-design-for-developers/ I implemented just two of the steps, using the Yanone Kaffeesatz font and cranking up the font size to way bigger than I thought was appropriate, and the very next talk I gave got SO MUCH praise for my slides. 
I've found the Python community does an excellent job of embracing windows. Though I vastly prefer a POSIX environment, for work I'm forced to code mostly in Windows. The fact that I can do that while editing in Vim and running code in Python with very little friction is a great feeling. Some modern terminals for windows (I use ConEmu) don't *entirely* suck, either.
Ah thanks!
I understand better now, thanks!
So this person wants to implement something that's not really needed just so Python can claim it has something it already has and get around Windows problems? That's madness along the lines of a Python 2.8.
Keep your copy. I may call upon you one day to help me contest the disney patent on their BB8 robot that was an XKCD comic before being patented.
unless you already need the RDBMS for something and it has enough performance to spare, then why cook up something else? Python is all about getting something feature complete on the ground and running quickly.
I bookmarked this : https://pyformat.info
Why does he use with open("foo.csv","r") as csvfile Instead of pd.DataFrame.from_csv ("foo.csv") or whatever it is? Tab complete basically writes my code for me so I don't if it's pd.from_csv(...) but you get the idea.
&gt; It prevents data races Only in the interpreter itself. Not in your code. Which makes it almost worthless. &gt; Those are significant guarantees that very few runtimes come close to. Guarantees that aren't very worthwhile. 
My point stands on its own. That paragraph of my post is a criticism of the GIL, not the answer on StackExchange.com.
I was not, so thank you! I'll read through them and digest the contents later.
You need to check that you are the owner, too. If you started using `sudo`, it might have set the owner to `root`. And you need to check the `/home/jonny/.cache` directory and the `'/home/jonny/.cache/pip/http` directory as well.
one thing that'll drive me toward a class, and /u/sobek696 seemed to touch on this a bit, is if I have a set of functions and want to have a large number of override-able defaults. Say I'm playing with finance functions. Nothing too complicated that really *requires* shared state, but at the same time if I want to play with values I can just do something like loan.apr += Decimal('.01') loan.future_balance(month=20) loan.reamortize(months=36) loan.future_balance(month=20) These are all things that could easily be done without classes. The formulas come from the realms of math and finance, so they clearly map to a functional approach, but in this case, with what I'm trying to do, a class-based approach suits me better. The other (more obvious) time that I'll shoot for classes is if I'm dealing with data that represents actual objects. Proper *things* in the classical sense. 'loans' in the above example, or routers and switches in my day-job. you can certainly do stuff like `reboot_switch(switch_ip=ip)` but `switch.reboot()` is cleaner. Also preserving state and code reuse are big deals in this instance, so classes are the clear choice. *I* tend to wind up playing with a few to a few hundred objects at a time (rather than thousands or millions of rows of data, for instance), and usually deal with an interactive workflow vs. baking something into a proper script that I'll just fire and forget, or turn over to users or something. 
That's probably a worthy note that tends to influence some of my work as well: interactive workflows. If I am doing some exploratory analysis in iPython Notebook, I'm much less likely to resort to classes, so when it comes time to export this work to a module for batch processing, each cell usually represents a function fairly well.
major complaints* :)
It's way easier to use Scikit-Learn
That's a really nice piece of work for your (first?) project. That also means there are no glaringly obvious suggestions to make... the style looks good. So, some general thoughts... os.system(['clear', 'cls'][os.name == 'nt']) This is 'cute', somehow I've never come across using booleans to index in this way. It felt un-Pythonic since the function wasn't immediately clear, but then `{'nt':'cls'}.get(os.name, 'clear')` isn't much better. Looking it up `True` and `False` can be re-assigned in 2.7 which would break this, but not from 3 on. So, I should probably expect to see more of this. re.sub(r'&lt;br ?/?&gt;\n', ' ', wiki_content) You might want to compile these regexes at the top (e.g. to well-named constants). ast.literal_eval(read_file(season_path)) Are you re-parsing code here and executing it? If you want to store/retrieve Python objects maybe [pickle](https://docs.python.org/2/library/pickle.html) is what you're looking for? Like this method it's not safe to pass files between untrusted users, but is fine for a local data store. Or perhaps your data is simple enough that JSON would work? One off-topic comment: in your commit log most commits are showing up with your name, not linked to your account. That (probably) means you've forgotten to add the second email to your account.
thanks! I am on it :)
Hear it from the Guido's mouth (kinda). https://lwn.net/Articles/651967/ He was doing a Q&amp;A at EuroCon2015. The gist of it is due to the mutable nature of objects in python, GIL came around (if I understood correctly) Pasting it here &gt;The GIL &gt; &gt;Someone from the audience asked about the global interpreter lock (GIL), looking for more insight into the problem and how it is being addressed. Van Rossum asked back with a grin: "How much time have you got?" He gave a brief history of how the GIL came about. Well after Python was born, computers started getting more cores. When threads are running on separate cores, there are race conditions when two or more try to update the same object, especially with respect to the reference counts that are used in Python for garbage collection. &gt; &gt;One possible solution would be for each object to have its own lock that would protect its data from multiple access. It turns out, though, that even when there is no contention for the locks, doing all of the locking and unlocking is expensive. Some experiments showed a 2x performance decrease for single-threaded programs that didn't need the locking at all. That means there are only benefits when three or more threads and cores are being used. &gt; &gt;So, the GIL was born (though that name came about long after it was added to the interpreter). It is a single lock that effectively locks all objects at once, so that all object accesses are serialized. The problem is that now, 10 or 15 years later, there are multicore processors everywhere and people would like to take advantage of them without having to do multiprocessing (i.e. separate communicating processes rather than threads). &gt; &gt;If you were to design a new language today, he said, you would make it without mutable (changeable) objects, or with limited mutability. From the audience, though, came: "That would not be Python." Van Rossum agreed: "You took the words out of my mouth." There are various ongoing efforts to get around the GIL, including the PyPy software transactional memory (STM) work and PyParallel. Other developers are also "banging their head against that wall until it breaks". If anyone has ideas on how to remove the GIL but still keep the language as Python, he (and others) would love to hear about it. 
i didnt ask you to run it, i want to learn how to make my own viruses in python so i can know how to stop them, i didnt ask you to run it i just asked which version of python it is 
[Watch this](https://www.youtube.com/watch?v=HTLu2DFOdTg)
Very cool!
See my update. I am totally cool with learning about it! :) As I said, it will probably run in either version. So there is no real way of saying which version "it is". The syntax differences of the two versions are relatively small. And this code does not touch on any of them. If I had to wager a guess, I'd say the tutorial was written with Python 2 in mind.
Thanks! I do feel a bit like an idiot now for not realizing this.
you don't have to feel anything, everyone else missed it
looks great - will give it a go
This was the first thing I've ever done with OpenCV so this is more of just messing around with it / tutorial / an example of what you can do :).
no, it is CUDA based.
/r/learnpython is for questions. /r/Python is for news and releases.
What more needs to be said? I thought you stated your point quite well; I only disagreed with the statement that Guido's the only person making decisions.
C# does ok, mostly because of LINQ. Also, /r/learnpython or /r/learnprogramming would do you better than here.
Oh, "unnecessary" wasn't a criticism... unnecessary is great. It's a cool example, and much more fun than something "useful". Keep it up! If you're looking for a new project, how about coupling a infra-red camera with OpenCV to determine whether a kettle is freshly-boiled enough to make a nice cup of tea?
So then how would you set up the various tests? 
They're really fast at not learning, though. 
This doesn't seems to return something else. Something like that can be enough def toRgbDecimal(inVal): return round(inVal*255) t = (0.168627, 0.631373, 0.831373, 1) t = tuple(map(toRgbDecimal, t))
very good. Thanks for sharing. I have a question about how you display the code and have CSS work its magic on your page. Do you have a library that helps you do that? 
&gt; https://en.wikipedia.org/wiki/Database-as-IPC Been working fine for me for years in production systems. 
Rockstar is my new favorite project
ha ha thanks!
Yeah that presentation was tough as I had to cover so much exposition first regarding the whole async I/O ecosystem and how PyParallel grew out of that. I'm working on an updated presentation now that focuses on the CPython interpreter changes that were necessary. &gt; GIL turned into a reader-writer lock. Main thread takes write lock, Workers take read lock. Workers get read-only view of globals. Actually, that memory locking thing was a wild experiment -- it worked, but it would have required more refactoring to the main memory allocator guts than I was willing to do, plus, it would have sucked on any platform that didn't have thread-sensitive structured exception handling (i.e. everything other than Windows). So, I took it out, then wrote a lot of real-world examples of useful servers using PyParallel, and realized I didn't really need it at all. A side-effect of the async I/O machinery resetting all allocated memory after the callback is that you segfault real quick if you've got some Python code or C extension code doing non-thread-safe stuff (basically, the caching of an object allocated from a parallel context). It's really easy to catch and fix those issues. Obviously, longer term, it'd be desirable to have more safe-guards and helpers in place to assist in writing parallel-safe code, and there are many ways that could be done. You could do static AST analysis and detect non-local/global mutations... or put the memory protection back in, or run the callback from the main thread first and TRACE the execution to verify it doesn't mutate any global state, etc. But, for now, it's basically: hey, you can kinda' get crazy performance *right now* with this approach, the drawback being that it'll crash (on purpose, I have __debugbreak()/INT3s *everywhere* -- crash early, crash often!) as soon as a parallel callback does something it shouldn't, so you'll need to be familiar with debugging C crashes (something that is incredibly easy with Visual Studio) until we have more sophisticated was of warning you up front about non-parallel-safe code. &gt; (I'm guessing workers also can't call C-based python modules) Actually it works fine with C-based stuff, surprisingly. There are some quirks if your C module does caching of object allocations (which is pretty easy to work around -- either set up a TLS version of cache, or just simply don't cache/intern things when parallel (I use this approach for the unicodeobject.c implementation and it works really well)). Did you see the [TEFB](https://github.com/pyparallel/pyparallel/blob/branches/3.3-px/examples/tefb/tefb.py#L201) example? That uses pyodbc to connect to a database, execute a query, fetch results and then convert them into a JSON string or render a HTML template with the data. The pyodbc module is completely in C. [I made one change to TLS-afy the connection caching](https://github.com/pyparallel/pyodbc/commit/d5967cf433dc34211ffc61a55689e32a202461f3) stuff, and voila, everything works fine. The other example is the [instantaneous wiki search](https://github.com/pyparallel/pyparallel/blob/branches/3.3-px/examples/wiki/wiki.py#L278), which does a lookup into a datrie object (which is a Cython implementation around a C library), then a huge NumPy array (also all C). [NumPy required a slight tweak to their internal memory allocator](https://github.com/pyparallel/numpy/commit/046311ac1d66cec789fa8fd79b1b582a3dea26a8).
I'm coming from a matlab background, where there are essentially no classes or objects, just functions reading and writing data. I'd actually prefer a functional style, but for it to really work, there has to be a really flexible data structure to back it up. In matlab we'd do something like out=func(data_struct, key/vals) or even include all the args in the data_struct. This is conceptually more like math, which I like. It has the disadvantage of not playing as nice with auto complete, in that an object will tell you all the the things expected to be done to the object with tab. The matlab struct could really store anything, and the hierarchy could be accessed dynamically, e.g. data_struct.('func_name'). What's the best python equivalent?
Cool, will definitely check this out today. That guy has some other good python videos, especially on how python is different from other languages, e.g. C/java. 
divide by 255, subtract 0.5 probably not optimal, but good enough.
It's not recomended . If you want to use SQLAlchemy then Flask 
In case anyone is looking for an easy way to make interactive maps, check out d3plus. I was a little intimidated by d3 at first, but d3plus makes things much easier. My workflow for this is in a Flask app is: * get the data cleanly formatted in Pandas * convert the DF to JSON (i.e. JSONFromDF = df.to_json(orient='records')) * pass the JSON over through Jinja (in render_template, JSONFromDF=JSONFromDF) * reference the JSON in d3 (i.e. .data({{ JSONFromDF|safe }})) Happy to post an example if people are interested. http://d3plus.org/examples/basic/9042807/
This is a list of language features that the author does not like, not a list of drawbacks of the language.
may I know why
In general no, you shouldn't. There are many things in Django that have a dependency or work better with the Django ORM; like: * admin * model forms * authentication * db sessions * Django Rest Framework's model serializers If you use Flask then there are many replacements for these things like: * Flask-Admin * Flask-SQLAlchemy * Flask-Login * Flask-WTF (WTForms) * Flask-RESTful You will probably have to write more glue code with Flask but if you don't like Django's choices, it will be your best bet.
Data analysis is somewhat different than regular programming. A few hundred lines really isn't that much code. Your goal as a programmer should be to avoid as much repetition as possible. If you are writing a dozen different scripts that all need to open and clean the same file you should probably extract that code and put it in a module. If you are only writing a one-off there is no point spending the time making it modular. Generally I will try to separate all recurring tasks into a package and write scripts that make a few calls to the libraries and output an analysis. If you are writing a script that you want to run on its own, but also want to use some of its logic in other programs you can make it both importable and runnable with some \_\_name__ == '\_\_main__' tricks. In python I will almost never fall back to fully object oriented designs (like I would with Java or C#) but will use the occasional class where it makes sense.
I was looking for exactly what I built. It does precisely what I need it to do, in precisely the way I want it done. But thanks for your input. :)
à² _à²°à³ƒ Good for you!
Yeah, I have had a few issues. Its not easy to upgrade. But like you said, its free. 
SQLAlchemy is a great piece of software. It's the thing I miss the most when working with django. I have, in fact used sqlalchemy in django projects before, but that was when I needed to interface with a legacy database. SQLAlchemy handles this fantastically. Django's ORM is better at mapping databases it creates, but still lacks some important features for modeling existing databases. (Multi-column keys: I'm looking at you). That's a pretty specific use case. Using sqlalchemy with django isn't bad, but it also isn't commonly done, and you won't have access to a lot of the integration between django and the db. You'll essentially be using django as a [microframework](https://bitbucket.org/cliff/microdjango). If you're cool with that, then go right ahead. If you're new to django or to programming, stick with the Django ORM.
That's actually kind of the point of Flask. It provides routing, request-response, sessions and templates (and a small grab bag of other things). It doesn't package a lot with it so you can shape Flask to your app's needs rather than shaping your app to Flask's needs. That's not to say Flask is superior to Django, it just fills a different niche.
Thanks a lot. Sorry, that seems pretty easy now that I see it in action. 255 colors possible so just multiply by 255 and you've got the RGB value. I got it working. I appreciate it.
Neat. That makePairs function was really over thought though: def pairwise(it): a, b = itertools.tee(it) next(b) # throw away a value return zip(a,b) 
Is there an advantage to doing it the way you did it? I've always done the former a + " " + b + " " + c
You did that wrong. You're supposed to convert the two numbers into integers, then add them up into a sum, and then convert the sum into a string and output it from there.
Named tuples could be a good approach. I like to think of them as a good bridging point between functional approach and classes. You get immutability, but the ability to store different elements that may all make up one discrete 'thing'. A somewhat contrived example: Point = namedtuple('Point', ['x', 'y']) p = Point(11, 12) #can also do named assignment x, y = p # tuple unpacking print("Co-ordinates: ({}, {})".format(p.x, p.y)) You get the safety of immutability but with easy to use structures that can contain heterogenous (different typed) elements. Basically this is just a wrapper around a class (add the verbose=True arg to the original namedtuple() declaration to see). [Python Docs - Named tuples (collections module)](https://docs.python.org/2/library/collections.html#collections.namedtuple) If desired, you can even index into the instance 'p' in the above example, like regular tuples (p[0] = x), showing that tuples are an *ordered* data type. Also, if you're working with a large amount of objects, named tuples are generally better for memory usage than dicts.
I figured that out a little while later. Thanks anyway!
Your lists suck because: They list so many hates but see little to love in any of the languages. Sad :-( 
Regarding slashes: sure, it *works*, but if you want to write a buttload of strings with backslashes, raw strings are worth knowing about. Which is why I mentioned themâ€¦
In no specific order: If you used a [virtualenv](https://docs.python.org/3/library/venv.html) (you should!) you can generate a `requirements.txt` with `pip freeze &gt; requirements.txt`. Then you can install all dependencies with `pip install -r requirements.txt`. I would name all python files with `.py` endings. It's not required or anything, but I think it's a good way to see quickly what a file is (besides windows user probably beeing happier). Your `runner` file directly executes code if imported. If you "guard" it with ``` if __name__ == "__main__": params = read_params() try: ... ``` you can safely import your python module (e.g. to test or reuse). It also helps to clarify which steps are "initialisation" (which is also needed if imported as module) and which actually "do" something (execute action depending on input). You created your own arguments parsing which I think is fine. Maybe for later (and more complex scripts) you want to look into [argparse](https://docs.python.org/3/library/argparse.html) or [click](http://click.pocoo.org/4/). pip package is already on your TODO, you can look into [automatic script creation](https://pythonhosted.org/setuptools/setuptools.html#automatic-script-creation) which makes "nice executables". The README could be a bit more informative. What are cool features? Or well, what does it actually do? I guess it builds statics html from markdown and templates, but templates are not mentioned. Also what does the interactive app do? Can you online post blog entries which will then automatically trigger a new generation? These are things that are probably clear to you, but not to a new user. If you want templates to be created/switched you could add some documentation for template creation. Things like what for pages you need, what each page gets for objects (and their attributes) etc. The default template doesn't look too complex, but maybe there are features that are not used by it? Some screenshots would be cool. It's an easy way to show basic usage and look&amp;feel. Nice project! Definitely better then my first project. Keep coding! 
tl;dw?
Yes
super cool. Thank you!
I would have a look a pelican liquidtags (https://github.com/getpelican/pelican-plugins/tree/master/liquid_tags) that have tag allowing to insert notebook in the middle on markdown posts IIRC. 
Could you point me to the plugin for PyCharm? I googled and didn't find anything. Thanks.
I did this the other day to make random text out of a few hundred song reviews from my local music blog. Instead of using pairs, using a dict {(arr[i], arr[i + 1]), arr[i + 2]} may produce more interesting results for bigger training data.
The last program, it's just... Byotiful
Heh, this'll spook the guys back at my Wiki. Thanks! 
This function seems to have an offset mechanism: [KafkaUtils.createDirectStream](http://spark.apache.org/docs/latest/api/python/pyspark.streaming.html#pyspark.streaming.kafka.KafkaUtils.createDirectStream)
Yes, I know that for **some** things they are quick but not all of them. Everybody have priority, python 3.5 dopes not seem to be one of these right now.
Thanks! But I didn't understand well some points on the function documentation. We have: "This does not use Zookeeper to store offsets" and "To recover from driver failures, you have to enable checkpointing in the StreamingContext. The information on consumed offset can be recovered from the checkpoint. See the programming guide for details (constraints, etc.)." The first sentence says to me that I will be unable to fetch the consumed offset from zookeeper, and next we have the checkpointing on the StreamingContext, this will be stored where?
Just giving some context. I'm to do exactly what the last sentence says, if my consumer stops(maybe the process be killed), how can I restart my consumer and get the produced messages since this failure?
I found this this [twitt](https://twitter.com/josh_wills/status/198093512149958656) from Josh Wills to be rather inspiring: &gt;Data Scientist (n.): Person who is better at statistics than any software engineer and better at software engineering than any statistician. 
As /u/mbussonn explained, you can do it using Pelican and liquid_tags. I have an example post [here](http://kdheepak.com/blog/active-reactive-and-apparent-power) that I wrote entirely in an iPython Notebook. You can even expand and collapse cells, and have them default a particular way. It requires a bit of setting up though. Let me know if you have any questions.
Highly recommend the "useing you're type's good" video on that page. 
I meant how you would organize them. Between running teensy weensy unit tests that don't touch anything else and running everything as a mocked up browser session there has to be some middle ground in terms of small packaged tests.
I love every talk Raymond Hettinger gives, it makes me happy to write in a language he has helped create.
Yeah, the super is super talk is good. 
anyone?
I find syntax of SQLAlchemy more cleaner. For example, joins in SQLAlchemy look lot better than Django ORM.
Theres a bunch [here](https://webapp-improved.appspot.com/tutorials/index.html). The 'Getting Started with App Engine' one looks to cover all of the bases. Anything it doesn't cover is probably up to you!
That's not what I took away from your comment at all. I've been told I come off as a bit of Flask fanboy (guilty) before.
Have you considered to implement an inverse converter, too? I think it should be possible to write something with markdown-to-macro(macro-to-markdown(text)) = text
rgb256 = tuple(round(255*c) for c in color)
You Won't Believe Number 5!
[Here is the ballet.](https://www.youtube.com/watch?v=MCs5OvhV9S4)
Flask is awesome, man! There is nothing to be ashamed of. I've been working with Django and felt absolutely miserable, but then they introduced me to Flask and my life has meaning again. So don't be afraid to offend a couple of petty Django users, when you're cruising interwebs with a completely justified feeling of your superiority, for they are just physically incapable of comprehending our ways. 
So, I'm genuinely interested; Why should I use this instead of Django?
he is so entertaining &lt;3 on of my favorite speakers 
That talk was insane, I'm pretty sure Dave Beazley's an alien.
I can't speak to Pulsar, but I've had good experiences with Pykka. At first glance, if you're specifically writing a web app then Pulsar seems like it may be more suited. But for more general actor-model development Pykka certainly works well.
Pretty good tutorial here: http://zetcode.com/gui/pyqt5/ 
Why is the Gary Bernhardt keynote recommended without there being a video? I didn't find one on youtube, but certainly would like to watch it. Still, kind of pointless to include it in such a list, if it is not available. Edit: typos
Thanks. I used celery before and I agree its amazing. However its overkill for what I want to do. 
Thank you!
Yes I understand. But but it is well known behaviour that fits squarely with pythonic ideals. This is not Perl where the interpreter tries to guess what types you _mean_. Input from standard in is pretty universally `str` objects. And operator overloading allows you "add" strings as you discovered. But none of this is unexpected if you are reading the documentation. Anyway I'm approaching my daily quota of grumpy old man behavior so I should probably lighten up! ðŸ˜ƒ Don't let grumps like me put you off. You are obviously a newb and I genuinely want you to stick around and keep programming. I should remember that more when I feel the need to post. 
On item #3, you are aware that Django as of the 1.8 release supports Jinja2 right out of the box, right? 
This is intended behavior. The default policy will have the cookie jar store all cookies. What exactly are you trying to do?
that nothing i've heard anywhere, it is very interesting, though i do stand by 1 and 2 and have more as i said. and unfortunatly all of the django installs i maintain are 1.5 or earlier.. boo, but currently i am pushing to start upgrading to 1.8 Also... by out of the box. do you mean, without any setup i can say {% macro somthing(arg1) %} {# code here #} {% endmacro %} and django will know how to handle it?
Sweet, thanks for letting me know man. I wanted to get this working, and tried again the other day, but decided to give up when I was out of ideas. I'll try it again tonight.
pythonspot.com is really sucks! a lot of wrong explanation and worst example.
The order in which the key of a dict appeared is implementation dependant, you should not rely on it (except if the dict is an OrderedDict in which it is insertion order.) If you want to have in aplphabetical order, you can use sorted like this (added keys()) alpha= "abcdefghijklmnopqrstuvwxyz" for letter in alpha: print( "|".join( sorted({letter:1,"z":1, "x":1,"w":1}.keys()) )) apparently in the previous code, the values are not needed hence you can use a set. alpha= "abcdefghijklmnopqrstuvwxyz" for letter in alpha: print( "|".join( sorted({letter,"z","x","w"}) )) One thing to know about the set is that the empty set literal don't exist so to create one you have to use `set()`
If you're in a virtualenv, it's `pip install -r requirements.txt`. But usually this step is actually done by `tox`. If you insist on installing stuff unisolated, use `pip install --user`. Do *not* use `sudo` to install stuff globally.
Awesome!
You'd be surprised at the little tricks malware authors pull to get around these machine learning methods. For instance, you have a DGA engine called 'QWYJIBO' which instead of generating total nonsense, generates random sequences of letters where every other letter is a vowel. The 2-gram, 3-gram based detections are completely screwed by this. Not long ago I worked on a small project to write a DGA-detector that can deal with QWYJIBO. This was done by inserting a "similarity to concatenation of dictionary words" measure (which was a bitch to compute efficiently, and required 3 different kludgy hacks to get to run in realistic time). But really from my experience with the data, the most trusty metric by which you detect a DGA in action is the number of different DNS queries that resolve to the same response (particularly if it's an NXDOMAIN). As it turns out, malware authors anticipated the 'similarity to dictionary words' metric already, and there are DGA engines in the wild which generate domains by concatenating random dictionary words.
the command line try `pip install docopt`
It uses both. It starts an event loop in each process
You do realise that I'm running Windows? I thought that pip command only works in, because cmd in Windows doesn't recognised l recognise pip
actually, this is the final form: #!/usr/bin/env python3 # Annotated with variables for interested people. # The rounding code in the range length is to make # sure the sine starts at 0 again when cycle wraps. from time import sleep from math import sin, pi from itertools import cycle speed = 25 wavelength = 12.0 scaling = 26.0 offset = scaling * 1.1 for x in cycle(range(round(2 * pi * wavelength * 5))): sleep(1.0 / speed) print("o" * round(offset + scaling * sin(x / wavelength)))
Just add pip to path m8 1.find your python directory and go to scripts, eg c:/python27/scripts 2. Add that dir to your path: "My Computer" &gt; "Properties" &gt; "Advanced" &gt; "Environment Variables" &gt; "Path" and add the dir plus a semicolon to the start (needs admin) 3.restart cmd 4. Pip away For stuff that needs a python setup.py install use the cd and dir commands to list what's in your current directory and navigate to the folder u downloaded (should contain setup.py when u do dir) and then run python setup.py install Sorry about grammar and stuff, I'm lazy and on mobile
Yes Flask is actively maintained. Checkout this link for details https://github.com/mitsuhiko/flask
Hopefully this [Python Web Frameworks](https://wiki.python.org/moin/WebFrameworks) is of some use to you when it comes to making the right choice. Flask is listed in the section "Popular Non Full-Stack Frameworks".
Hey thanks a lot, redditor for 7 minutes.
[**@obi\_inc**](https://twitter.com/obi_inc/) &gt; [2015-08-05 21:34 UTC](https://twitter.com/obi_inc/status/629042836936224768) &gt; http://Leanpub.com/intermediatepython is almost complete; the good news is that you can now get it for free up till when it's complete ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://www.np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) 
The overview page specifically says multiprocessing or multi-threading, so it was an honest mistake.
Thanks :)
&gt; CPython is not fast. Multicore CPython would still not be fast. I said easily *or* fast. If you choose Python you choose the easy route, and multicore Python makes that less slow. &gt; If you can't afford one process per core, you're using the wrong language. It's not the language that makes processes expensive. That's more of an OS level issue. The "you're using the wrong language" argument is a tautology - if Python supported multicore properly it would be *more than fast enough* for many applications that it currently is not. The fact that faster languages exist isn't terribly relevant.
Did not know this. Thanks for the knowledge!
&gt; It's not the language that makes processes expensive. If you can afford Python, you can afford one process per core.
&gt; The `__init__.py` file is usually empty, but can be used to export selected portions of the package under more convenient names, hold convenience functions, etc. I don't see where it says that putting all the code in `__init__.py` is un-Pythonic. It merely illustrates some possible uses of `__init__.py` to contain code, but does not preclude other uses.
For simple scripts maybe. But once you are using nginx+fpm it is not much different from nginx+gunicorn. 
&gt; No, all data races are prevented. Okay, that's not the definition I'd read in the past, but my point remains that this is not a guarantee that is sufficient to be of any use to you as an application programmer. It is necessary, but it is not sufficient, so you pay the price without getting the benefit.
&gt; Gary Bernhardt typically asks that his talks are not published by events. Ah thanks, I didn't know that, but I guess it makes sense in his case.
/r/learnpython
We don't talk about variables in the Python world. We talk about names and values. someString = "Hello!" binds the value "Hello!" to the name 'someString'. You can now inspect, manipulate and display the value in your code through the name 'someString'. #Chop the last character off someString = somestring[0:len(someString)-1] #Add a new ending someString += ", World!" #print it vertically for c in someString: print(c) 
Yeah. Anywhere you're using or storing text, that's a string.
I did not exactly understand your question. But here is my answer that might help. first and second one just litteral strings you can create strings with either ' or " characters it does not matter which one you use. Last one is error it should be str('whatever') in that case you are creating a string from another string. so it is same as 'whatever' so there is no point of using str. here is another example. num = 1 val = str(num) in this case you are converting a number to string. Does that answer your question?
gevent baby.
no
Thanks for your concern, but that was an example number from the API documentation. Thanks for the suggestions, I'll look into it!
how so?
What have you done so far? Is there anything specific that you need help with?
Like /u/AckAttack said we will need to see what you've done so far. There are bad ways to learn programming and one of them is getting spoon fed the answer. Scratch that, getting spoon fed means you do not learn to program. You learn how to copy and paste well. Here is a simple hint to get you started if you can't even start. Convert both times into seconds. so 01:20:03 becomes 4803 seconds. makes it easy to minus and get the elapsed time. All that needs to be done is to convert it back to the correct format.
The pink text on a white background needs to die in a fire.
/r/learnpython is over there ---&gt; google is over there &lt;--------
Yeah way too bright.
screenshot plz
i like the app, but totally agree about the blog post
I think you mean node.js, not jnode. Javascript is important to know for front-end dev, certainly, and node is useful for things like unit tests or Github's Electron project, but node as a webserver is a disaster for anything but toy projects and I'd avoid it like the plague for anything serious. Not only is javascript not great even by dynamic language standards, the node ecosystem and tooling is a poorly designed mess. Python has a much more mature ecosystem, and if you need to move beyond it for scaling or maintenance reasons you should be looking towards languages with *more* functional support and type safety, not less.
While you finish your degree, participate in an open source project or two, make some projects you can show, take on a project for a client or two (friend or acquaintance). Then do some volunteering in your community with your skillset. After that, do some temp work in your field. Update your resume with references and examples from these activities. The tools and languages you use will probably vary from one project to another. 
Oops, yes I meant node.js. Do you think node is still maintaining its surge in popularity in the industry? 
https://www.youtube.com/watch?v=si-kxnwKvjU Cheers
&gt; I come from a c++ background [..] Javascript is a really tough and archaic language. Javascript is neither as tough nor as archaic as C++. I would have agreed with you if you'd just said it was worse than C++. ;) &gt; However, the front-end web is run on javascript. Sure it is. But you're making a false dichotomy, talking as if learning an extra language will be such a hardship that you need to make a final decision now on whether to learn just 1 more or just 2 more. In actual fact, you will probably need to learn 4 or 5 more over the years. Javascript should be in that list. So should Python. A few years ago, we needed to start making a cross-platform game - so I taught myself C# so we could use the Unity engine. This year, we needed an Android app, so I taught myself Java (well, re-taught - I learned some at uni many years ago) to do that. I started learning Swift last week in the context of perhaps working on iOS. This is just par for the course. &gt; I am just primarily concerned with making myself a better programmer Becoming a better programmer is not about knowing the right languages or knowing more languages, but getting good at learning new things - including languages. Don't try and predict the future, just practice adapting to change.
Why is this a Flask extension? 
The nested functions within functions just really throws me off. But you bring up great points.. thank you, you're right.
It has not been updated since 2011 unfortunately. 
I'm pretty sure that Python has variables. I google search confirms it too: https://www.google.se/webhp?sourceid=chrome-instant&amp;ion=1&amp;espv=2&amp;ie=UTF-8#q=python%20variable
 import requests url = ' https://www.betarigs.com/api/v1/rig/1' json_data = {"price":{"per_speed_unit":{"value":3,"unit":"BTC/Mh/day"}}} headers = {'X-Api-Key': 'asdf1234'} r = request.request('PUT', url, json=json_data, headers=headers) print(r.json) -d is request body, json arg can handle that -H is a header, headers dict http://www.python-requests.org/en/latest/user/quickstart/#custom-headers
[Gource](http://i.imgur.com/dZ4ZXnj.png)
[Christian Tismer](https://mail.python.org/pipermail/python-list/2002-November/141486.html)
/r/learnpython
Stupid. You don't choose *a* programming language, and there is no "strongest" programming language. Each language has its target domain and its strengths and weaknesses. Professional tools should be chosen on balance, not out of personal preference or familiarity.
Sure, built right in: `os.urandom` and `random.SystemRandom`.
Something that I found recently when working with flask is [flask bootstrap](http://pythonhosted.org/Flask-Bootstrap/) which makes for an easy way to get Bootstrap into your project and provides a really simple way to display web forms with pretty CSS. I've been struggling with getting the CSS classes to apply all the time though. I'd love to see a tutorial showing off more of it's features, for now I'm tinkering with it on my own to see if I can figure out why some classes don't seem to be accessible.
I'm just being pedantic. :) 
I don't get Flask Bootstrap. I mean what problem is this trying to solve? I don't understand why you'd want to do this to your project? You're mixing things all together. Seems a violation of separation of concerns. And look, there's some mystery issue that you're having. No, not for me. 
Excellent! Really excited about this. Hopefully ITK is next! 
Thanks
What got me to try it was how well it played with flask-wtf. I could pass the form object to the template and call quick_form(form) and it would do all the placement, organizing, and CSS for me. It was a pretty nice way to get a form up with very little code. But yeah, those mystery issues are quite a turn off. Part of why I made the comment was I had hoped someone else had more experience on the subject and might be able to clarify the problem. It's also only for a pet project so I'm not heartbroken things aren't working yet.
The only time I've had this trouble (outdated Python version, and no means to install packages) I installed anaconda in my home directory and used their package manager to install packages (or just pip as usual). virtualenvs should work as well I suppose.
The SRC has to be available outside of the network, so you'll need something like duckdns.org and port forwarding configured for you router. 
You should take a look at the [python documentation for datetime](https://docs.python.org/2/library/datetime.html). Specifically look at the strptime function and the time and timedelta classes.
Could you please explain why the plot seems to be at an angle? Maybe it is just due to my lack of familiarity with NYC geography, but from maps I have seen it looks as though we are viewing Manhattan from a strange angle. I'm not exactly sure how this would work with longitude and latitude data, but the curvature seems high for the amount of land area. 
Don't use Firebird.
I don't think you understood. I already have a port forwarding scheme for the parent site. What does not work is the Flask streaming, and the internal stream cannot be exposed. So I must not expose the 192.168.10.1 and do stuff like &lt;img src='http:mysite.duckdns.org/videostream.cgi?stream=1'&gt; to access the video content. This way I even don't need to use Flask. In my case, my Flask application needs to handle the internal stream from 192.168.10.1, and export the stream to the external hmtl parent site. But thanks anyway.
Sorry for the confusion
[https://gist.github.com/Snack-X/f91b6d02fd192cbe8216](https://gist.github.com/Snack-X/f91b6d02fd192cbe8216) Seems like [PCG](http://www.pcg-random.org/) performs pretty well.
A few things: * `__getattr__` is a fallback method when Python can't find an attribute on an object. Define an actual `actors` attribute and see what happens. Though, maybe you're already aware. * Your getattr is actually returning `None` and *printing* the tablename. This is an important distinction to make. * If you want to do method chaining (like SQLAlchemy does), you'll need to return an object with the supported methods. The most obvious way is to `return self`, but having a separate Query object that you configure/create at each step would be a better idea. This'll help when you inevitably need to join a table with itself. 
Python can actually run zip files (I think since 2.5) but there's still the issue that psycopg2 needs to compile since it's essentially a C extension to Python. Your best bet is a virtualenv. If you have shell access, you can install it using `pip install --user virtualenv` and pray everything goes right. I believe there's an actual way to package a venv as a zip package and run it from that, but I have no experience with it. Failing that, get with the sysadmin or server guy and explain what you need. Failing that, explain to the customer what you need, how you'll install it (keeping in mind their technical aptitude) and what you need to install it. 
It's not Python, but here's a bash script I wrote that does something similar: https://github.com/chrisbaume/live-asr
why are you converting floating point values to binary strings? doesn't the prng have a way to generate integers? in general, floats are kind-of problematic, in that they don't uniformly cover the range of real values. so i would look at testing integers first, so that you can separate the underlying generator from issues related to conversion and representation (if the integers pass). edit: also, that test suite is explicitly for crypto prngs. the "whole point" of non-crypto prngs like mersenne is that they are much faster than crypto prngs. and obviously, that comes at a price (or we'd use them as crypro prngs...)
This is pretty cool - thanks for sharing. I had no interest in this before, but now I'll check it out further. 
If you want some actual answers, you should probably post in /r/learnpython. If you add 4 spaces before each line of code the code will become more legible and not squish itself onto one line. People will not answer your question when it is like this. 
I'm not saying you can't make it work with enough time and effort - hell, just look at what Facebook did with PHP. I stand by what I said. Even if I were sold on node as a concept (and I'm not, not even remotely), the ecosystem is extremely immature and you will run into a lot more problems, quirks, and edge cases than you would with a more mature platform. Node.js reminds me strongly of attitudes towards MongoDB awhile back: it has niche applications, but is wildly overhyped far beyond what it should be used for.
Add 4 extra spaces before each line of code (see sidebar)
&gt;Again, why? Yeah, Javascript is a bit wonky if you come from another background, but once you learn how it works properly, it's really a decent language for some applications. Also it is improving quite a bit thanks to ECMAScript 6. Key words: "for some applications". I actually don't mind JS as a frontend language (though I'd prefer TypeScript), but it's very poorly suited to backend server code. &gt;Why? Package management for node (via npm) is a whole lot better than Python packaging with pip, at least in my experience. But maybe you are talking more about the libraries available. If so, fair enough, although I don't think everyone would agree with that assessment. Both actually. For the record, I usually work with JVM languages and tooling, which blow pip out of the water, but I'd still prefer pip to npm any day. &lt;rant&gt; With most dependency managers, transitive dependencies are usually specified as fixed or minimum versions, and in general it's possible to resolve a fixed state of the graph - that is, if my project is working today and I don't change anything, it should still be working tomorrow with the same dependency versions. This isn't possible with npm - the closest you can get is npm-shrinkwrap, and that's so buggy we've had it fail more often than not. Worse, the node community is awful about version ranges, semantic versioning, or even just abandoning versioning altogether and pointing to random URLs. This exacerbates the above problem to the point that we regularly have builds fail due to changes in transitive dependencies can't control. Worse still, npm tries to resolve dependencies like a tree instead of like a graph. When they realized this doesn't work, they introduced the confusing peerDependencies hack instead of fixing it properly. This makes it hard to properly override dependencies, making the above issues even harder to workaround - in fact, we frequently end up having to fork intermediate projects just to fix transitive dependency resolution. And don't even get me started on the bugs, inability to handle or even detect common failure states, performance issues, etc. &lt;/rant&gt; And yes, the libraries available for python and other languages are also more mature and stable, on top of all the above.
Nice! I did a [similar thing with ggplot](/r/bigquery/comments/3fo9ao/nyc_taxi_trips_now_officially_shared_by_the_nyc/ctt5jsi)
See the [3 plots I left here](/r/bigquery/comments/3fo9ao/nyc_taxi_trips_now_officially_shared_by_the_nyc/ctt5jsi). It all depends on the bounding box.
Pycharm is THE python IDE IMHO. Wing is decent too, but I love pycharm and enjoy giving them my money. edit: Though the python community is made up of the friendliest and humblest devs I've ever known, you're likely to take flack for this question because it gets brought up all the time. Run a few searches in this sub and you'll see what I mean. And DON'T bring up VIM or the crazies come out of hibernation :)
I'm at work and I just tried to run it on windows (work machine) but the alsaaudio library seems to not exists for it :( I'll put up a gif when I get home though 
Did someone say vim? (j/k, I use PyCharm)
I guess that makes you a pedantphile :)
Formerly a web application developer for a small agency. We did client work primarily in Python 3/Django, although occasionally in other languages as per client demands. Now working on Python runtime environments for PaaS at Google. While Python is my primary language, over the course of my career I've also had to work in PHP, Java, Ruby, JS, Objective-C and other languages.
tmux and vim :)
Spyder nice too and free
Thanks, I'll give it a go. Sorry about forgetting to search first. I actually quite like Vim, never used it for much but did Vimtutor for shits and giggles recently and it just kind of made sense to me. Honestly if I was doing HTML and CCS I'd use Vim, but with Python it does not seem ideal. It would probably need some heavy editing to say the least. 
If you are serious about learning Python, or really doing anything development-related, it will benefit you to become familiar with using command lines. If you're really serious about Python, I'd highly recommend setting up a Linux environment to work in. IDEs work just fine in Windows but you're limited beyond that. You can set up a virtual machine in a few hours for free if you look up how to do it. It's what I tend to do. Python is cross platform so anything you write will deploy anywhere.
In my opinion, Pycharm is by far the best that I've used. Just feels really intuitive and doesn't take long at all to get good at using it. I like everything those guys make, I use IntelliJ for Java and if I didn't have to use Visual Studio for work I would probably pick up their new C++ IDE too.
Closures are a way of life. They're commonly used in Python, and we even have a special syntax for loading functions into closures, called decorators. I'll admit it's an odd way to define classes though. The next version of JavaScript sounds like it'll have "proper" classes instead of the current method.
/r/deepdream
Kinda. At the end of the day, it's mostly splitting hairs. Python has objects. And then we assign names to these objects to get a handle on them. It's mostly like references in PHP (and I'm pretty sure like C/C++, but I'm woefully inexperienced with them). For example, I drive a Black 2001 Honda CRV. I call it my car. My girlfriend calls it Alec's car. The DMV might refer to by the plate number ABC123. Honda might refer to it by the VIN, and the mechanic as "that busted piece of crap with the rattling muffler" (I know this because I'm typically the mechanic) These are all just names for the same vehicle.
If you are using python 3.4+, you should probably use pulsar. But it really depends what you are trying to do.
Thats my STACK!
Not that it is a bad article, but I slowly get a little bit tired of deep dream. To me, deep dream was more like a "gag," or "joke" (in an entertaining sense), but if the joke gets told too many times ...
I used to have both PyCharm and Wing IDE licences, and I found them pretty similar. As a matter of a personal preference, I like PyCharm more. The reason for that most probably was that prior to that I used IntelliJ IDEA and PHPStorm. Also PyCharm is cheaper.
Definitely going to get a couple of these printed and framed 
Thank you!
Neither. Eclipse/PyDev or if windows only PTVS.
&gt; and obviously, that comes at a price (or we'd use them as crypro prngs...) Not necessarily true. Something can pass all statistical tests and still not be cryptographically secure and vice versa. For example, a PRNG that generated random numbers by outputting its state and then "scrambling" its state by replacing it with the SHA2 of its state (and repeating that) would generate numbers that pass all statistical tests but would still be insecure. Similarly, if you take cryptographically secure output and convert it to base64 most randomness tests will fail even though the string itself is secure (it still contains the same entropy, it's just larger).
OPs code: from sys import argv def redu(tre): if len(tre) == 2: y = [max(a,b) for (a,b) in zip(tre[1],tre[1][1:])] return [(a+b) for (a,b) in zip(tre[0],y)] else: red = redu(tre[1:]) y = [max(a,b) for (a,b) in zip(red,red[1:])] return [(a+b) for (a,b) in zip(tre[0],y)] tree = [] with open(argv[1], 'r') as inpt: for line in inpt: tree.append([int(i) for i in line.split()]) print(redu(tree)[0])
&gt; You don't choose a programming language A programming language choose you!
The content of the article could be used to describe most modern programming languages, the author just spun it for Python. There are better reasons to use Python: * It's easy to learn which makes it great for beginners. * It's basically OS agnostic, although I'd be hard pressed to find a use case for Python on Windows * The codebase of 3rd party modules is huge, you never have to re-invent the wheel. Just pip it. * It's powerful, fast, and lightweight; that makes it great for sysadmins. Now, I'm not what you call a hard core Python guy. But I use it when I need it.
Dotnetrocks podcast touched on this in their Artificial Intelligence Geek Out episode.
This script is old but you can steal the basic idea (with windowing) from it: https://gist.github.com/baali/1436671 That said it probably won't work very well, what you need to do is detect silence in the recording and split during silence otherwise you may split in the middle of a word. Even if you do manage to only split between words it could be that by splitting in the middle of a sentence you change the result you get from Google (they probably use ngram parsers) so it still won't be perfect. P.s. not used it properly yet but Microsoft have a speech recognition API now, also Google provide this which is fun and relevant https://www.google.com/intl/en/chrome/demos/speech.html P.p.s https://github.com/jeysonmc/python-google-speech-scripts/blob/master/stt_google.py 
I wonder how much of Python is written by GvR at its current state.
Thanks, I really appreciate it!
I guess the number of people who read the sticky will be equivalent to the number of sidebar readers. A hint inside the submission text box would be more helpful. 
Don't read what doesn't interest you! I've never understood this need people have to get someone else to censor the forums for them. 
Sure, and let's get rid of all of those useless mods too! /s
Moderation is very Important I just don't see the point in demanding moderation for questions you don't like. To look at this another way, do you read every entry made into this forum even if it is focused on something you have no interest in. Python wise? For example I skip many of the software announcements because I have no interest in the app or library. I skip over the, instead of demanding censor ship because I know that more than a few will be interested. All it takes is a little maturity on the readers part. 
added pic https://camo.githubusercontent.com/d726266ffb249aa15386deffc404cfa6d21a3c71/687474703a2f2f692e696d6775722e636f6d2f314b66383672512e706e67
Call them variables if you like. The nomenclature police won't come after you. But there is a subtle distinction. In languages like C a variable is a named memory location of a specific size and type. In Python, a name is an accessible reference to an object. Once you've created a name, you can make it point at any object. The name is not the object itself. In C, the variable may actually contain the value (for example an integer or a string). In Python, the name is always a reference to an object (or to None). As I say, this is a subtle distinction that very rarely matters. But it allows you to do some cool magic in Python that is very tricky in C.
We had this discussion with the mods months ago. The verdict was meh. I hope the outcome is better this time. I'm sick of homework and beginner posts.
The best way, imo, and if possible, is to keep the credentials in the platform's secure password store. There are nice, cross-platform libraries for this. If you can't use a secure store, keep them in a file and ensure the file is only readable by its owner. Command-line arguments get stored in your bash/zsh history. Not a good thing for passwords.
I keep the version number in \_\_init\_\_.py and use a simple regex to read the version number from that file if I need it elsewhere.
So, it's a long story but basically I am testing the supposed randomness of a real world system which produces floating point numbers. It's not good enough to convert those numbers to binary and run tests on them, so I am using two processes namely, a Mersenne twister and a completely deterministic (edit: and predictable) process, as benchmarks. The predictable process is failing nicely but so is the MT. Let me try with integers first and see if that is the problem. To be honest I also think it might be, but I just wanted to test some other PRNGs to be sure. 
Cool. I agree with you, I'll see what the behaviour is like using integers. My comment to Andrew Cooke discusses the reason why I am interested in floating point numbers. Nice suggestion on the seeding. Thanks!
It's not the final product, it's the process that's so damned interesting. This is Data level shit right here
Oh yeah. That's what I do as well. But if I have a file *outside* of the module that needs a version number I just use regexes.
I think this something of a universal problem. I've seen people write Matlab like they write Fortran with disastrous results. I'm trying to make the transition to Python myself. However I'm avoiding the deep dive, but I'm so busy with work I just end up sticking with Matlab because it's faster. I keep telling myself I'll use Python for the next project/article. I'm starting a side project with a Lytro camera whose API is in Python. Hopefully this will be my turning point. 
This is something that bothers me a lot about the machine learning community at the moment - they are writing their software to be Nvidia specific, perhaps because Nvidia gives them free hardware. This in turn shuts out non-Nvidia users from getting into this area of research (at least in practical terms). A cunning move by Nvidia, but academics should know better than to enable this.
Which OS are you on? I am running fedora 22, and pycharm seems out of breath to me as well.
Your project can be python 2. You just need python 3 for the tool itself. I don't think that that is a big ask.
Have you been drinking?
I didnt try anything because i didnt understand it. I need step by step explanation :/
Actually as far as an IDE goes, Spyder is probably the closest thing to MATLAB's. As a long time MATLAB user, it is what I would recommend to anyone making the transition.
I know it's a big question but - can you give any examples of this problem? Things you can do Matlab-like in Python, and why you shouldn't?
&gt; I am using two processes namely, a Mersenne twister and a completely deterministic (edit: and predictable) process I fear that you are confused about what a pseudo random number generator means. Like all PRNGs, Mersenne Twister is completely deterministic. It's also predictable: given the seed, you can predict its output forever. That's the whole point of a **pseudo** RNG. It's also predictable if you have some moderately large number of consecutive outputs, I think you need 624 of them. I don't understand how you think that testing PRNGs like Mersenne Twister will shed light on something which claims to produce actual random values. At best your conclusion might be "more random than MT", but that doesn't tell you whether it really is or isn't random. For that, you'll need to talk to an engineer and a physicist who can shed light on the physical processes used, and try to identify sources of bias. If all you want is to compare it to the NIST test suite, so you can report "passes all X tests of the NIST suite" (or possibly "fails Y of the tests"), then I'm not sure where MT comes into it.
Do you have Time Machine backups? 
I agree with this. Made the jump from MATLAB recently, felt a lot more at home after finding Spyder. 
I have no idea. You know that you don't need to perform a full restore, but can restore individual files, right? 
Well, that's exactly what backups are for
This helped me a ton: http://mathesaurus.sourceforge.net/matlab-numpy.html
&gt; You say this as if only users of pandas would be allowed to criticize it in this post on /r/Python . I ask because this is something that people have been clamoring for, especially in the last 6 months. The pandas BOF at SciPy nearly broke into applause when they were told it was going live &gt; Sounds like you are very defensive about working on Python 2.6 or something. Just face it, either your personal project or your organization is way behind, using very old Python, and you are not able to change that. It's simply the case that Python 3 has not been adopted widely *at all*. Somewhere full of Python fans like /r/python can pretend that Python 3 is the current, normal thing, but the reality is that it's the rare thing, and that &gt;90% of shops writing software to actually do something in Python are using 2.
For me, the major differences are: in python you can write many small reusable functions and store them into a logical heirarchical structure. In Matlab people tend to write one massive monolithic function for every program. In python you have many data structures readily available, and each algorithm often has a natural data structure to use (sets, dictionaries, queues etc), in Matlab you ram every problem in to an array or a cell array. 
 &gt;Overall, Python is a much better language, but if you do vector and matrix work the syntax is more cumbersome than Matlab. Even so, I wouldn't go back. Also, don't buy any books, you can find everything online. I can't really agree with this idea of not buying books. Maybe I'm old fashioned but much of what I know about computer science and programming has come from books. Beyond that sorting bad web sites from the good ones is notably more difficult than finding good info on books. 
I would agree that books are an invaluable resource. The Internet is great for finding examples of a specific feature or algorithm, but nothing online is going to match the level of detail of a book. It's true that a lot of ebooks exist, but I personally find it very hard to read books on a computer screen. 
I generally have setup.py generate the version number from the git revision count or ci pipeline build number and store it in the package_data along with other useful package data. That way the version number is associated with the git hash of the code used to build the package.
&gt; You will benefit from learning the language features of python at some point but it will probably be more productive to focus on the python scientific stack first. What do you mean with "language features". The basic features of python can be picked up pretty quickly, and trying to learn the scientific stack without knowing the python basics doesn't sound easy at all.
If you are a "learning by doing" kinda person, I suggest solving some project Euler challenges with python, and after solving them, you can read other people's code to learn alternative approaches. 
I agree. Should probably learn basics such as sets, lists, dictionaries , how to make a loop pythonically, import libraries, ect. 
&gt; if you're sitting at your house and looking to capitalize on microsecond-level fluctuations in price. You're *going to have a bad time*. Anything that you need to be fast for it to work is going to get beaten by the guys co-located at the exchange.
Kinda what i'v heard as well. Even heard a story about some Bank or company that moved their servers from New Jersey to New York to get that extremtly small delay-benefit(probably the speed of light(fiber) that it takes to travel that distance)... Not sure if true though, but makes me think if it's really worth it for personal use
I don't like it at all. It looks nice for small examples but the content of the local scope and data flow it is not always that obvious. I see lots of unsanitized user input bugs emerging from this 'feature'. Don't be so damn lazy, guys :) If you *really* want this functionality: &gt;&gt;&gt; name = 'World' &gt;&gt;&gt; "Hello %(name)s" % locals() 'Hello World' 
Yeah, they give you the data, but you have to interpret it and act on it. AFAIK there's not a lot of offerings out there that let you define arbitrary decisions to make on arbitrary data. So no, you're not going to beat the billion-dollar investment powerhouses at that game, but you *can* maybe pull your own inefficiencies out of a more traditional trading philosophy. If that's not something you're interested in, then no, it's probably not the tool for you.
Why don't you use something like http://www.youtube-mp3.org then? I'm not sure why you need a Python downloader if you don't know Python
I'm writing a blog post on exactly this topic! I plan to post it on (or shortly after) Sept. 18th when Python 3.5 is released and introduces a matrix multiplication operator (@ as detailed in [PEP 465]). You can head over to http://scottsievert.com to see the post. For specific Matlab/Python differences, I would look at [NumPy for Matlab users] (apparently the scipy server is down -- try the [cached version]?) [NumPy for Matlab users]:http://wiki.scipy.org/NumPy_for_Matlab_Users [cached version]:http://webcache.googleusercontent.com/search?q=cache:RJnDpzsVtqAJ:wiki.scipy.org/NumPy_for_Matlab_Users+&amp;cd=1&amp;hl=en&amp;ct=clnk&amp;gl=us My post focuses on a seamless transition. Hence, I make the recommendations (quoting my post) &gt; ### How to switch to Python *Want to try Python without installing anything?* Go to [try.jupyter.org] to try Python your own Jupyter notebook! The Jupyter notebook can plot inline and uses [Markdown] (with LaTeX math!). &gt; 1. Install [Anaconda] with Python 3.5 (and the Anaconda install is easy! Also, make sure it's Python 3.5) 2. Open up [Spyder] which tries to provide a Matlab-like experience (variable explorer, debugger, etc). 3. Type `from pylab import *` which provides a Matlab-like functions. 4. Done! A Matlab-like environment exists. Try almost any function from Matlab to see if it exists in pylab; it probably does. [try.jupyter.org]:https://try.jupyter.org The biggest advantages Python has (quoting my post). This is a short description; I figured if they were at my blog they already wanted to switch. &gt; * **Functions are *simple* (a big deal!)** They are *easy* to implement and can be in the same file as a general script (a feature Matlab lacks). This can make your code modular and readable. I mean, in Python functions can even have optional arguments, the scoping just works and functions can be passed as proper variables. * **Package install is *simple*,** via the pip command line tool. Just `pip install python-drawnow` to install after you google "matlab python drawnow" and find [python-drawnow]! * **Python *just works*.** Some little goodies that are really nice to have: * [optional arguments] for functions exist! * Swapping variables is *simple*: `a, b = b, a` * Comparison is *simple*: `1 &lt; x &lt; 3` works via [chaining comparison operators] * variables in a string are easy with [string's format] like `"tau = {0}".format(2*pi)` * for loops are easier than easy with [enumerate] and [zip], * [list comprehension] works; collapse a simple for-loop into one line. `[2*x for x in [0, 1, 2]]` results in `[0, 2, 4]` * **Documentation in Python is *simple*,** via [docstrings]. * **Python has an active development community.** Want to change a package you're using? Make a [pull request]! Go to [a conference] or [a local Python group]! * **Python is free as in beer and free as in speech.** There aren't any licensing issues and you can see the source code of every function called. * `clc; clear all; close all;` found in Matlab is gone forever! And no more semicolon! [PEP 465]:http://python.org/dev/peps/pep-0465/
I did this transition too. I first started with anaconda+spyder IDE, then anaconda+emacs, and now I'm using miniconda + pycharm and I'm very happy with my current workframe. Miniconda is great because you only install the packages that you need. Pycharm is a complete IDE for python, you can install packages with it; set up virtual environments; do version control; run your scripts; It also has tool windows with project files, modules, classes, variable etc. I'm sure there are a lot of thing that I don't even use. The downside is that it takes a while to load it. As far as matlabXnumpy capabilities, I still haven't encounter something that matlab can do and numpy can't.
/r/learnpython can be a go-to. Search for matlab on that subreddit, there are a lot of threads like this. 
I think that Python should adopt JS-similar syntax for template strings. 1. Use backticks to delimit formated string, instead of f-prefix. In JS single backticks can be used for multi-line strings. In Python I think single backticks should be limited only for single-line strings and triple backticks introduced for multi-line strings, to be consistent with normal string syntax. 2. In JS placeholders curly braces are prefixed with $. Python already has similar syntax for [`string.Template`](https://docs.python.org/3/library/string.html#template-strings). However, the more popular is `str.format` syntax, without the dollar sign. Therefore, it has to be decided, whether we should be compatible with JS and `string.Template`, or with the `str.format` syntax. Personally, I do not have any preference in this case. name = 'Fred' age = 50 # single-line ## JS-compatible-form `My name is ${name}, my age next year is ${age+1}` ## str.format-compatible-form `My name is {name}, my age next year is {age+1}` # multi-line ## JS-compatible-form ``` My name is ${name}. My age next year is ${age+1}. ``` ## str.format-compatible-form ``` My name is {name}. My age next year is {age+1}. ``` 
Can somebody explain to me what is really wrong with `%` formatting? I found his example of `'error: %s' % msg` completely unconvincing -- if you're that worried about what might be in `msg` then write `'error: %s' % str(msg)`. `%` is simple, clean enough, and has been around for ever.
the creation of `.format` came from the fact that `%` formatting is fairly un- extendable (can only do any formatting on numbers) `{anniversary:%A, %B %d, %Y}` is a fairly good example of how extendable formatting can be useful. And yeah, its clean enough, but it could be cleaner, neater, and more flexible (imo)
I think this is a really bad idea. Sure it looks cleaner in this case, but we already have 2 ways of formatting strings. Now there is a third? Sometimes fewer choices is better than more choices, especially since now you have to remember all of the choices and the quirks of each when reading someone's code. Also it makes it harder to have "same looking code" across developers in different groups. Finally, as someone else pointed out, there is an issue with scope for this particular example. I think the reason Python is so readable to everyone even if it's someone else's code is that it forces you to write in a certain way with other ways feeling unnatural. Now we propose a third different "natural" way of printing things. I think we should focus on more complex things instead. Things like GIL and making Python faster and easier parallelization instead of a third way of printing things.
Oh cool, I hadn't seen that. It's a very similar idea to `reversion`, though it has some different design ideas. It looks like `bumpversion` really tries to understand your version numbering, so you need to configure it for things like 'beta' tags. `reversion` provides [a set of fairly basic operations](http://reversion.readthedocs.org/en/latest/changes.html) which don't need to know the details of what your version numbers mean.
There are many things you can do with a real function that you can't do with %. https://pyformat.info/
Exactly. And your project doesn't even need to be Python - it should work for anything so long as the version numbers are in text files.
I use the IEP editor (http://www.iep-project.org/), which is included in the scientific based Pyzo environment (http://www.pyzo.org/). That IDE is also very closely related to Matlab.
Checkout [ReversionUp](https://github.com/mardix/reversionup) It works with Python 2.7 too. ReversionUp, is a straight simple command line tool that helps you increment the version number of your project. ReversionUp follows strictly the 2.0.0 version of the [SemVer](http://semver.org/) scheme. Version must be in the following scheme: - major.minor.patch - major.minor.patch-prerelease+build ReversionUp can be used along with Git to increment the version on each commit. https://github.com/mardix/reversionup 
Awesome! I had questioned whether it was possible to do something like this [~9 months ago](https://www.reddit.com/r/Python/comments/2liumr/your_python_smells_like_java/clvjbz6) and it looks like the usage is very similar to what I was looking for. I really hope that this goes through- it's the "third way to do it" but it's far cleaner than the other solutions and I imagine it will replace them easily over time. The code I work with professionally has an "interpolate" function that does basically this for long messages and it causes so many headaches with refactoring, 'unused' variables, and the like.
[I'd recommend this as a quick and dirty intro to the basics.](https://developers.google.com/edu/python/) It's a fast-paces series of lectures that will let you feel quite comfortable with the basics very quickly. I used it over a weekend to learn Python for an NLP course having previously used Matlab. I like Python much better.
[Image](http://imgs.xkcd.com/comics/standards.png) **Title:** Standards **Title-text:** Fortunately, the charging one has been solved now that we've all standardized on mini-USB. Or is it micro-USB? Shit. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php/927#Explanation) **Stats:** This comic has been referenced 1828 times, representing 2.4213% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_ctw44og)
Gotta say, I *really* wish this were supported for `bytes` too. If `__format__` would be problematic because it would return unicode, just use a new `__bformat__` method instead.
We have 2 very similar ways of formatting strings. This sort of interpolation is a very nice feature in other languages. I would be ecstatic if Python incorporated it in.
This is such a microscopic problem it borders on bikeshedding.
No link, and you'd need to tell us what makes it better than Cookiecutter.
I think it's largely because NVidia was first to market with CUDA &amp; Tesla cards.
I think that `%` will never be deprecated. First, it makes porting from C (and other languages with printf-like formatting) far more straightforward than `.format`. Second, there is too much existing Python code using it in the wild. Deprecating it will be harder than switching from Python 2 to Python 3.
This is the first thing I've heard of that might (if adopted) tempt me to switch to python 3 from 2.7
It's certainly possible to develop your own portfolio, but based on long term strategies not speed.
Woops, my bad. Link added. I've never seen cookiecutter, but it looks similar. Added some explanation on why `wisk` is preferable.
There is a PEP about PEP Voting ;) https://www.python.org/dev/peps/pep-0010/
The real problem is that people keep arguing for `%` on the basis that it's shorter. This should hopefully bring us to the point where the `format` infrastructure is truly superior, which should let us finally throw `%` on strings away. Worries about having a third thing are probably not too big of a deal since this is extremely similar to `format`; it's the same formatting syntax applied inline. If this deprecates old-style formatting, we'll probably end up more consistent than we are now.
I think it depends on the language. If the language is pretty limited in what it allows and what it can do, it tends to lock people into thinking and doing things that way. A more flexible language, or a language that offers more options, will encourage people to think about things more broadly, and thus I think will make it easier to transition to a different language. An programmer who is experienced and knowledgeable about Python is going to have a much easier time transitioning to MATLAB compared to a programmer who is experience and knowledgeable about MATLAB going in the opposite direction. This is because the Python -&gt; MATLAB transition is mostly a matter of limiting yourself to a subset of what you are used to, while the MATLAB -&gt; Python transition requires a substantial change to your basic concepts of how programming works.
Why not just make `"{a}".format()` default to using the current scope as a dict? AFAICT, it's backward compatible.
These issues are actually kind of strange. MATLAB has added a few other data structures, such as a `map`, but pretty much nobody uses them. Similarly, MATLAB has added a very limited form of nesting functions in directories, which again is very rarely used (in fact even internally it isn't used as much as it could be). In fact many experience MATLAB programmers don't even know they exist. It may be that MATLAB users have done without them for so long that they just aren't part of the MATLAB coding idioms, and thus aren't used much even though they are available.
Interesting, that could very well be!
Yeah, I think that is true, I am just trying to think of problems that could happen in the next few decades, wanted to cover my bases.
Thanks for sharing. That is a good article. Bookmarked! :D
I love the way Groovy does it. Single quote strings are regular strings. Double quote strings are "G-strings" (no joke) which will perform string interpolation using a `${value}` format. Love it. 
What happens if you pass arguments? Does it add missing variable from the scope? This is not how it works now, so it's not backward compatible. E.g. imagine you assemble a dictionary by hand and catch exceptions for missing values (that might be shadowing something in the scope).
Good points, in particular the point about new users learning Python 3. I cringe hard whenever I see a newly written Python tutorial and it is in python 2. My favorite thing about python is what a complete package it is. Someone has written a library for just about anything I have ever needed, including some pretty obscure stuff. You can go fast if you need to with numpy/cython/pypy.... And it is easy to learn, and fun to work with, it gets out of your way and lets you focus on the problem you are solving. Only the 2 VS 3 thing is a problem, but that has gotten much better with all the important libs having been ported to 3 
Wow, very nice page. Thanks!
Can't wait for `fu''` strings.
Besides the great points listed in the other comments, don't be afraid of learning python. Even if in 3 years nobody will write python anymore you will learn alot of common basic concepts in the programming world. OOP,functional programming, currying and what ever. With this knowlegde you will adept new languages in no time. Learning your first language is the hardest step, after you crest this hurdle there are only stumbling blocks in your way not high montains anymore. Python is a very good beginner languages, because it is easy to understand, has a clear syntax, a vivid and helpful community and it is very powerful.
This sounds like something I would interested in. Do you care to give any specifics in the reports you've replaced? 
&gt; unless you're doing chunking Can you be more specific?
In Python 2, `bytes` is a synonym for `str`, i.e. they are the same type: an immutable string with byte semantics. It's there as a porting helper for writing code that's compatible with both Python 2 and 3, as in Python 3, the string type has character semantics rather than byte semantics (i.e. it's the `unicode` type from Python 2) and `bytes` is a different type. Perhaps it's easier to understand in the form of a table: characteristics|Python 2.x|Python 3.x :-|:-|:- immutable byte string|str (aka bytes)|bytes immutable character string|unicode|str mutable byte string|bytearray|bytearray mutable character string|n/a|n/a The difference between a character string and a byte string is that a byte string is a series of bytes, i.e. integers between 0 and 255. A character string is a series of Unicode code points, from U+0000 to U+10FFF. One of the original sins of programming was treating byte strings as if they were character strings, by using some implicit character encoding (usually ASCII, but not always) to pretend that each integer between 0 and 255 represented a character. This mistake has led to all kinds of pain and suffering, and Python 3.x fixes it by disallowing that laxity. 
Thanks. I asked because i have never used it, but i just applied for a position there.
a lot of programmers find themselves often using the terminal, and it's extremely convenient to have a unix-based terminal right out of the box. On top of that, you can ssh and interact with linux servers without the overhead of installing new software to configure that. i don't think you're making your life any easier by having to familiarize with two different shells. on top of that, i love the features of the mac, most notably spotlight + finder's extremely powerful capabilities. I haven't used a windows box since my gaming days, but there are a lot of features i found mac to have that windows didnt (to my knowledge). I also really like the screen switching feature, where you can maximize a window and switch to different windows all in the same monitor :) 
As a scientific python developer and user my only worry would be languages like Julia that would be able to take the popularity away from Python. I haven't personally done anything in Julia, but from what I can tell it brings a lot of needed features to Python while bringing performance. But the Julia community has acknowledged that Python is a big language and allows you to call C and python from within Julia. So it's not going anywhere any time soon. I just need to get more scientists away from matlab and IDL.
That seems like it'd be rife with exploits. If you passed in a string you would potentially have access to read their `locals` dict. Seems dangerous to me.
I haven't deployed Django to either, but I have a WebFaction account, so I've done a little research -- there's no real way to run things like `celery` properly.
Try this [link](http://dabeaz.blogspot.co.uk/2010/01/few-useful-bytearray-tricks.html).
Nonsense. It's a basic design principle: explicit is better than implicit. Having to be explicit about what values you intend to inject into a template, and where they come from, is much better than having string literals turned into executable code at runtime by magic.
If you're short of horizontal space, you have bigger problems than just being short of horizontal space. And you already have many good options.
I've been a pure Windows guy since getting first job (16 years ago). Loved Windows and defended it. Got current job 3 years ago and they asked how would I feel working in Linux... sure, np, I get to learn something new. Now 3 years later, my personal home computer is Windows. My personal project dev machine is Ubuntu. And I just asked my company to send me new MacBook to replace the shitty Samsung Windows laptop. So yeah, at the end of the day it's all personal preference but there is definitely an appeal on unixy side. For me, it's the terminal, bash, ssh and rich set of standard tools.
Back to bash! :
&gt;I just need to get more scientists away from matlab and IDL. Amen! ;)
Lucky I'm more in a situation where a business can't afford Matlab and I can use whatever I want. But yeah, good to know not to go into it thinking that it is exactly the same as conventional Python.
The problem I find with books is that they are a big commitment and more and more with ebooks there seems to be a lot of crap ones out there. I'll keep an eye out for one that has a lot of good reviews at least.
Remember that until Dart and Go showed up, Python was one of the few languages which google programmers were allowed to use. The others being C, C++, Java and Javascript.
Awesome, you make some good points. I actually kind of enjoy the challenge of having to think in Matlab terms but it's probably not the most efficient way of working. Thanks for the advice, to the books I go.
It's like if a cat grows up in a room with only horizontal lines it can never see vertical lines when it's older. I do love my matrices though
Yes, you're right. Most Matlab users tend to be engineers and scientists. We need it as a tool to get us so far and the limitations make some sense. Most research code is nowhere near the standard you would expect. 
The default Python implementation is an interpreter. Everything is magically turned into executable code at runtime by definition.
Cool, I'll set a reminder. A possible problem I might have is that I'll want/need to be using the package PyWavelets and their site says it requites python 2.6 or 2.7. Is there a backwards comparability or would I have to stick to an old version of Python?
&gt; for questions you don't like. For _all_ questions. This is not the place for them, that's what /r/learnpython is for.
I tend to use all three (Windows desktop at home, OSX laptop for work and Ubuntu servers). Maybe the only pain on Windows is installing libraries that require compilation, but it's really not that difficult to set up and if you can't be bothered, there's [Cristoph's great site](http://www.lfd.uci.edu/~gohlke/pythonlibs/). Use something like cmder on Windows and you're pretty much set.
I'm sorry that I can't help directly but this section of the [Python wiki](https://wiki.python.org/moin/NumericAndScientific) might have some pointers.
Yeah, but a) that only applies to posts that deserve to be on /r/learnpython, not repeat posts, and b) it isn't in the posting info, which I believe more people would read. I don't see how this changes much. Either it reduces work for those trying to be helpful, or doesn't change anything. I see no reason _not_ to do it.
I too had to move code from Matlab over Python, I taught myself Python as part of an internship and then decided that porting an unrelated project from Matlab would be beneficial. To the project, not me. Here's some stuff that jarred me; * Python is a zero indexing language. Matlab is a one indexing language. * You don't need to go through gymnastics to get items that you want out of a vector, goofy syntax like myarray(length(myarray)-3:end) in Matlab can be written as myarray[-3:] in Python. * For loops in Python work much differently than they do in Matlab, they're more like the foreach loop you might encounter if you use Boost for C++. I love this behavior myself. * You can swap elements in a list by writing myarray[a], myarray[b] = myarray[b], myarray[a]. In Matlab you would have to use a buffer. * You may miss Matlab's indexing behavior for arrays. Say you have an array that goes indices = [1, 4, 2, 5, 3, ...]. In Matlab myarray[indices] would yield the first item of myarray, followed by the fourth item of myarray, followed by the second, the fifth, and so on. In Python this is a syntax error. You can get the same behavior using list comprehensions or the **map**ping function. * You don't have to initialize arrays in Python if you don't want to, Python won't give you warnings about slow run-time over this. You can by using replication (say n*[0] in Python instead of zeros(1, n); in Matlab) and AFAIK it is slightly faster if the list is large, but you don't have to. * Python 3.5 will introduce separate syntax for matrix multiplication (the m**at** multiply operator: @) and dot products. This was done because packages like NumPy made their own classes for matrices and specified a multiplication operation for that class congruent to matrix multiplication, the side effect being that * was used for both dot products and matrix multiplications. Use this knowledge to determine which version of Python to start using first. * Speaking of which multiplying arrays or matrices by a constant may be confused with replication and concatenation, at least in Python 2.7, I'm not sure if Python 3.5 fixes this or not. * You can have more than one function per file. Yay! Instead each of your files represents what's known as a package, if you make them robustly enough you can use them for your other projects. * I'm a CLI freak, so I'm going to tell you to learn how to use Python the way God intended, with a naked command prompt and a code editor like Sublime for writing and editing Python files. Python works better in the Windows CLI than the Mac OS X or Unix CLIs, you can use the function keys to get a history of commands in the Windows CLI which is really _really_ nice. I taught myself Python by going through the official [Python tutorial](https://docs.python.org/2/tutorial/), though the other commenters here are suggesting 3rd party tutorials or books. I don't know why, I'm sure the tutorial written by the same people who founded the language is good enough for your purposes. Most universities use iPython when doing anything involving Python, so if your project is for an educational institute you should definitely be doing most of your work with iPython. I personally don't like iPython, but I haven't found anything better yet.
I saw that too. I chalked it up to a typo
Sorry I forgot to explain - I meant that all of the calculations done in finding the determinant are done mod m. 
can you specify if youre using python 3.x or 2.x? what is your goal of this program? just to output what 2+2 is?
Just like shell, perl, ruby and coffeescript.
Why do people like unpacking so much more than using `format_dict(locals())`?
As the sidebar says should you have considered posting this in learnpython. Do you really want to have to type the trailing '.'? With a bit of re-formatting the fragment runs on Python 3. It fails in Python 2.7 with an unexpected end of file. while True: twoPlusTwo = input('What is the sum of 2 and 2? \nA. 1 \nB. 2 \nC. 3 \nD. 4') if twoPlusTwo == 'D.':` print('Correct! 2+2=4') break else: print("Incorrect. 2+2=4") 
Nobody said it's impossible to develop in Windows just inferior. What's ignorant or superstitious about the fact that Windows is a crummy platform run by idiots and bad people. 
\*\* is shorter than _dict too.
Name the variables like two_plus_two. 
... and how did you implement that? -.-
I am a scientist and engineer myself, I am well aware of the quality of code in those fields. But the issue here isn't quality, it is how you think about problems. 
you must have recently been on a vacation to think of this analogy
Hrm, I see. I didn't know it could be done dynamically, but I stand corrected.
`format_map{locals())` is the correct spelling.
I skimmed through that first page and frankly whoever wrote that page is out of touch with so many things that I would strongly suggest finding a more reputable site to learn Python. &gt;I've already been using Macs for almost any computer I've purchased, and have interest and tinkered in Linux, and used Windows quite a bit. But what might this statement be getting at? Why would a programmer (or Python programmer?) not recommend Windows? Python does mesh far better with the UNIX derivative systems. It doesn't mean much if you are a beginner but long term you are better off running Python on systems other than Windows. In any event there was so much bullshit in that first page that I strongly suggest you look for something written with a bit of objectivity and far less bias. 
Not all questions involve learning Python. 
Python is, to a first approximation, equally feature-rich under both Windows and Linux. There are a few differences, due to missing or limited OS features. For instance, Windows doesn't support POSIX signals, but then Linux and Unix don't support all Windows features either. One of the good things about Python is that it includes a lot of powerful functionality which is otherwise hard to install on Windows. The big difference on Linux is that it is a rich and powerful ecosystem of programmer tools, either installed by default, or just a few commands away, while Windows makes you work hard to get access to those tools. Or pay a lot of money. Or both. If you have a reasonably hefty budget for software, and a powerful machine, you can make your Windows PC just as good a programming environment as my five year old entry level Linux box using nothing but free tools.
Disagreed. Python is just as powerful as those traditional languages, and a far bit easier to use. As far as games goes, just use Unreal Engine 4 and build it in that using C++ or Blueprints. Much better than building your own engine from scratch. UE4 is free, and when you make money they take a small % of profits. You only pay if you make money.
Probably because unpacking is more general and as such, easier to remember `**` will always work, no matter the situation appending `_map` to the function name will only work on `.format`
What do you know? I wrote a post about this exact thing a few days ago. https://www.smallsurething.com/what-to-do-after-codecademy/ It's just, like, my opinion, man, but you might get some ideas from it.
Well, Reddit is written in Python, so there's that. Also YouTube, Instagram, and so many more. Check out the Success Stories section on the Python site. https://www.python.org/about/success/
That posts seems wonderful, dude. I am really thankful. Maybe Tkinter is the thing for me.
I also want to echo what the other guy said. Django is awesome. Where did you get the idea it wasn't a good alternative to Rails?
I would love to be able to call Julia code from Python.
Personally, python has really started clicking since i started learning and developing with Django. I'd start with Django. It's pretty great.
Why wouldn't Dear {customer}, please find enclosed an invitation for {event} on {date} blah blah blah work just as well? EDIT: I guess `safe_format` and the lack of formatting specifiers can be compelling if taking untrusted input. Fair enough.
.decode().format().encode() is how I do it now
fu'{c(k)}'
*Slightly* off-topic, but: It's worth considering that once you're at the scale of Youtube or Instagram, an interpreted language like Python is definitely going to increase your server costs. Barring eventual significant improvements to PyPy/Pyston/maybe other JIT compilers, it will never be anywhere near as fast as a language like Java for web apps. A Python web app with lots of concurrent clients may require 5 servers where a Java version of it might require 1 server. Twitter started out as a Ruby app, then eventually converted most of its codebase to Scala and Java to handle the load requirements. This does not mean there's something wrong with Python itself. But when you're dealing with millions of visitors per day, you're going to be at a disadvantage with an interpreted languages. For some companies, it's overall less costly to just spend more on hardware and optimizing other parts of their stack rather than rewriting their Python codebase, but if they originally created their application in some statically typed language known for good performance, they'd likely save themselves some work and costs. Some may point to companies like Facebook and Dropbox as proof that interpreted languages can work at massive scales. But in reality, it was so costly (not just money costs) for them to port their codebases to some other language, they decided to dedicate serious engineering efforts to creating a new interpreter from scratch (HHVM for Facebook, Pyston for Dropbox) to try and optimize performance. Now, of course, the odds of your "commercial web app" getting within an order of magnitude of the scale of those companies is extremely slim. Don't optimize prematurely. Everyone likes to think their app or company or idea will some day become really huge, but it's very unlikely. So given the choice between a language you like and know well vs. one you don't know well but is more performant, you should usually go with the former. Just keep in mind you may some day need to throw most, or all, of that code out if popularity begins to soar. Don't optimize prematurely, but don't wait too long, either.
The default Python implementation is a *compiler*. There's a compilation step that occurs before running the code, which is why SyntaxError occurs at compile time, not runtime; .pyc and .pyo files contain the compiled code; there's even a built-in function `compile` which takes a string and compiles it into an executable object. But that's by-the-by. You're missing the point that there is a difference between result = func(spam, eggs, cheese) # explicitly pass values and result = func() # implicitly have values injected for you, by magic String templates are similar. It's not even about the syntax, its about the explicitness: template &lt;- values # explicitly inject values template # implicitly inject values (No, `&lt;-` isn't Python syntax. I made it up. As I said, it's not about the syntax.)
&gt; I just need to get more scientists away from matlab and IDL. May I know why? Is it because MATLAB is not free software?
I started out doing everything on windows for years. Including real serious python programming. I still use windows as my main computer. Most commercial software i use runs best on that. But these days i develop exclusively in linux on virtualbox. It is so much easier. All the tools you need, and for free. Including the documentation. Having a python problem with some binary extension on windows? Good luck with that. I linux you can alwyas google an answer. Bu i do know that most of my developer friends use macs, so that is definitely a good way to go too. Windows, yes if you are making desktop software. Web software no.
I actually wrote a more simpler version of something like that..Do you want a peek at it so that you can compare notes?
Yea, I would really appreciate that! :)
I still disagree. Python is both an interpreter and a compiler. It can compile apps and programs, or run like a script language (as some people seem to keep thinking it is.) Python is a fully fledged functional language on par with c and c++. All are high level languages. There are two advantages that keep C/C++ in place: * It's been here forever and people know it * It's a tiny bit faster than python because python is friendly, and does a lot of error checking. But that's ONLY while interpreting, and even then it's very, very fast. Newer versions are introducing pieces that fill even more gaps. Things that are filtering out into the other languages, now, like generators and high function iterators. If you really care to know (and I do agree, some of the presenters come off as smug), here are some fascinating videos: https://www.youtube.com/watch?v=wf-BqAjZb8M https://www.youtube.com/watch?v=_AEJHKGk9ns https://www.youtube.com/watch?v=5-qadlG7tWo
Being a Noob, I am looking forward to making a website as photography blog. Then will shift to making website. Website is about provinding services. Something similar to Seamless. What would you suggest?
Python is neither a compiler nor an interpreter, it's a programming language. Implementations of that language (CPython, PyPy, etc) can interpret or compile (or something in between or something different) python files. That also means that speed is only comperable between implementations, and CPython is currently the dominating implementation (for reasons). C/C++ is not a "tiny bit faster" than CPython, speedups of ~~1000x~~ 10x are normal. That means a function running in python could need hours, whereas the same C functions needs ~~seconds~~ minutes. EDIT: Can't find sources for 1000x, but I'm pretty sure I've seen it. [here](http://blog.famzah.net/2010/07/01/cpp-vs-python-vs-perl-vs-php-performance-benchmark/) is a benchmark where python needs 15x as much time. 
You are correct. I use CPython, personally. I don't use it for math heavy applications, so I can't attest to what you are saying. I'll have to assume you're right, but I just can't imagine the speed is that much different. Once compiled it's compiled, and ready to go. Help me understand.
Yes, that's what it did; it got cookies from two pages in one list.
&gt; Did you sit and read every module? Do I remember *every single thing* in the standard library? No, of course not, I'm not superhuman, but it isn't hard to pick up a fairly good overview of the std lib. It's just frustrating when person after person talks about "two" existing templating systems in the std lib. I haven't read all the source code for each and every module, not even all the ones written in Python. But I've at least glanced at nearly all of them, I've studied some of them extensively. When I have a problem understanding what a module does, I pull up the source code and read it. You can learn a lot from the Python standard library! I read the What's New that comes out with each new release to look for things which are new and interesting. And I'm not even a professional or full-time programmer. If you are, and you don't do these things, then either you're one of the top elite who doesn't need to (in which case, you surely know about `string.Template`), or you're letting yourself down. I see so many beginners ask how can they learn to be better Python programmers. Start by reading the source code in your Python installation, and seeing what tools are already available.
Also, non-technical people often like to use, or expect to use, $ formatting rather than {}. It's what they're familiar with from other applications. 
Sure, may be, but it does not make &gt; Django is not a viable alternative for Rails 
Then I would ask you to look up tutorials for both of them and spot the difference for yourself. Also, the fact that Ruby code is WAY TOO BEAUTIFUL but Ruby does not incorporate the Zen confuses you way too much. Basically, C++ is archaic English (or samskrit for you) Python is Regular English (Hindi) and Ruby is the slang language (Marathi, maybe? "Hathela hai kya?") 
The great thing about engineering is standards. Standards let you know that when you pick up a 1/4" ratchet, it's going to fit that 1/4" bolt. In complex systems of separate interoperable parts, standards let you know the bridge is going to join from both ends in perfect alignment and permit traffic to flow and will not collapse. In computer engineering, there's an international standard for operating systems that let application programmers know when they make a certain system call, its going to behave a certain way, consistently, on any operating system conforming to this standard. They are free to design and implement their application once, and it will be able to run anywhere (assuming a compatible build chain) Linux and MacOS both conform, making application development a breeze. Also, these OS's are free and come with free documentation and development kits to empower programmers to build great software. And especially for Linux more so than OSX, when you want to know exactly how the system call works, you look at the source code. Windows is $$$ and its development kit even more $$$, and it does not conform to the standard, instead locking developers into a special snowflake incompatible system which is completely proprietary and closed source, so when you want to know how it works you're reliant on the vendor providing accurate documentation to give you whatever small snippet of info they're willing to share (i.e. you can never find out exactly how it works, not legally anyway). The sheer volume of malware on Windows versus the other platforms is testament to how well this method works in comparison. Free, free tools, easy to understand, interoperable and guaranteed by a standard to function the same way across any hardware and comforming system, versus expensive with expensive tools, not possible to understand, not interoperable and no guarantee of anything (no standard, can change on a whim &amp; break all your work / apps) This is why programmers advocate the better system. 
I dont have complete plan. I have a rough idea. Why cant I make a website using Python? What is the use of learning python then?
To many it gives the impression that it's not ready for production level use when in fact it is and has been for many versions. Also, using a 1.x.x version number scheme allows for you to put information in to the version number. For example, in this post it says "this is a major feature release", but I can't tell this by looking at the version number. If the version went from 1.1 to 1.2 then I know more features/work went in to it instead of if it had been 1.1.1 to 1.1.2. TL;DR: Version numbers tell you information at a glance.
When you want to use a more expressive and less verbose language, at the cost of performance. Most applications people write are not going to be "large scale". If you don't have to handle 10,000 concurrent users regularly, Python is just fine.
It not being free is irritating, but not the most irritating. Mainly it's the licensing and getting them to communicate with other existing software or languages. Have you tried running Matlab or IDL in production or distributing them? I will say in my experience Matlab is easier to distribute than IDL if you buy the compiler. For IDL you can compile and release a small tarball with your software that comes with an executable, but it has to run in the "IDL Virtual Machine" which (because of the licensing) requires a graphical window to pop up and requires you to click it. If you automate this it goes against the license. So then if you decide to just run your stuff with the full version of IDL to not deal with that damn pop up you now need to have a license for every instance that is running. For Matlab, I have never had much fun getting matlab to run in a production setting. We ended up just running it in a screen session because it randomly decides to screw up the terminal until you run sttysane. From what I've been told Matlab now has the ability to talk to shared C libraries, but when a coworker tried it it didn't work. TL;DR: Production-level automation and distribution is not easy, fun, or consistent with Matlab or IDL in my experience.
A photo website (or blog) has some content, say an article and a few photos. The thing you want to do is to show the article and the photos to your user. Websites are written in HTML, you could compare that to a .doc file or a pdf. That means, HTML says only what you want to show and how it should look like (e.g. here on python on the right is a sidebar, top is a navigation bar etc.). All of this is **static**. Of course there are still dynamic things on a website, e.g. the comment section here on reddit. A user inputs something and then the website **changes**. Unfortunately for historic reason only javascript is currently supported for making websites dynamic. So if you press on a button somewhere here, there is a good chance that some javascript gets executed. How does python fit in there? In a simple website: nowhere. You have some content (which is formatted in HTML), maybe a few buttons (like "show more article") which use javascript und you probably want it to look nice (this is the realm of css). This changes if you want dynamic content on your website. Reddit shows every user a different inbox, and it needs a way to "know" what content whom to show. This is called the backend (as opposite to the "frontend", what the user sees) and can be written in python. Ruby is another language that is often used (with ruby on rails, if you already heard that). So if you want to create a website you **must** have HTML. CSS if you want it look nice. Javascript for some sugar like open on dropdown, load additional content and lots of other stuff one expects from a website. 
I'm not talking about `"{0} {1} {2}".format(x, y)` because I don't have a problem with that. That's completely explicit. But this is not: print("{x} {y} {z}") I've lost track of all the proposals, I can't remember if that's still being considered. This is a bit better: print("\{x} \{y} \{z}") since at least we know that anything following an unescaped backslash is special. This is similar, perhaps even a bit better: print(f"{x} {y} {z}") as the f prefix indicates that this is a special kind of string, not a regular string literal but an actual expression that cannot be evaluated until runtime. I still prefer an explicit function call or method call, but I can see the appeal of introducing a string-like syntactic sugar for `format()`. But I think allowing arbitrary expressions are going too far: print(f"{x+1} {[y**2 for y in range(10)] + [-1]} {z or w}") As far as I'm concerned, that's YAGNI turned up to 11. &gt; They're all just tokens being passed to an interpreter. It's all magic. The variables in your python programs are just seen as strings by the interpreter I don't really understand what you are trying to say here. I *think* you mean that "source code is text", which is true but not relevant. It's not correct to say that all *expressions* are seen as strings by the interpreter. You should read the byte code to understand what the interpreter sees. They are not just strings. &gt; There's no extra protection here. So what's the big deal? There is extra protection. You have something which is a method call, and looks like a method call, rather than something which looks like a constant literal but is actually arbitrary code. Apart from the other issues -- comprehensibility, readability, ease of teaching, the need for code highlighters that highlight inside strings -- the main issue I have is that code should look like code, and data should look like data. There are enough opportunities for code injection attacks from things which look like code: os.system("ls " + options) without making it easier for people to accidentally smuggle code injection attacks in via things which look like literals. â¸® https://en.wikipedia.org/wiki/String_interpolation#Security_issues 
So Python is used for server side programming/back end programming? then what is Flask and Django? 
&gt; This is similar, perhaps even a bit better: ? You're quoting the linked PEP...that...is exactly what it says it will do... I think allowing arbitrary expressions is too much, I agree with you there 100%. Anyway, this was an interesting discussion, and perhaps the opinions in this thread may be of use to the PEP author or its reviewers. Thanks, and take care :)
I read on Wikipedia, Reddit is made up of Python language. Can you explain that? 
Flask and django *are* the server-side backend. They receive requests from the end user, perform whatever operations you like, and return a webpage (which may include html, javascript, css etc) that the user views.
But reddit is made using python language, right?
Flask and Django "help" you with that. You don't need them, you could programm everything on your own. But programmers are lazy and often used concepty are bundled in libraries/frameworks. E.g. you don't have to learn HTTP.
reddit has lots of dynamic content. E.g. if you sent a pm, "python" sees which user sent the message and to which user it should be send to. Then if the user logs in, "python" says "ah, I know this user, he has a new message!" and generates the html to show the message. But of course the reddits are all dynamic. Somewhere is a database with all redit posts. If you visit /r/python it goes to the database and asks "what posts are there to show?". It then takes a template (e.g. the subreddit style) and creates the HTML "on the fly". 
I think java is more used for PC programms/apps instead of a backend for a webservice. But yes, if used in a webpage, it would be backend.
Yeah, the place is named shortsightedly, but regardless, it's where questions belong. /r/Python is for news and releases.
&gt; Developing web app is not good on a large scale 1. You aren't writing an application at large scale. 2. It turns out to be fine for the #3 website in the world. (The #2 website in the world uses an interpreted language as its core backbone as well.)
bumpversion
Time lapses would be great. Is there a way to automate that? Say, have it running in the background and turn autosaves up to every turn?
I dont get your comment.
We're getting `%` byte formatting back in 3.5. The reason bytes were stripped down to be next to useless in Python 3 was because of Python 2's attitude of trying to be helpful and converting bytes to unicode or unicode to bytes, often unexpectedly. But now that it's a TypeError to attempt combining strings and bytes, bytes is slowing gaining back some of its power.
I don't miss it, mostly because I always found it more trouble than it was worth trying to interpolate array access and `.` concatenation was just easier 99% of the time. And it always encouraged me to write injection vulnerable queries. "Why bother using PDO::prepare when I have the variable *right here?*" then followed by infinite :( until I changed it. I'll be honest, I don't like the idea of literal string interpolation in Python because there's already `%` and `.format` to achieve the same effect. I appreciate that it requires a prefix character so I can choose to not use it.
`git push -fu python-master`
 1. Your application isn't going to be large scale, so the fact that you would have to pay for more hardware isn't key. 2. The tradeoff seems to make sense for people running extremely large scale websites, such as YouTube. 
https://mail.python.org/pipermail/python-ideas/2007-January/000054.html &gt; You're missing one of the main reasons for removing the backtick syntax in the first place: the character itself causes trouble by looking too much like a regular quote (depending on your font), is routinely mangled by typesetting software (as every Python book author can testify), and requires a four-finger chord on Swiss keyboards. **No new uses for it will be accepted in Python 3000 no matter how good the idea.**
I guess this is an idea several people have had. I still like my variant best, though. ;-) It's more flexible than ReversionUp, because it doesn't require any particular version scheme.
This is seriously a fantastic blog post. I have been "on a boat" between countries in Europe for the last 5 hours plogging through this part 3. Loving it! I have no Python background at all, but properly explained like this, and I feel like getting miles ahead of whenever I try and read random Python books. 
They're very similar. Reversion doesn't need to be configured with details of your version scheme; instead it has a selection of [operations](http://reversion.readthedocs.org/en/latest/changes.html) that you can apply. E.g. `bumpversion minor` is equivalent to `reversion +0.1`.
I didn't think about it that way. I'll give DO a shot in a couple months or so. 
Is the deployment process similar to Heroku?
somewhat yes. you have to spend some time reading their docs and understand. Here are some examples (by me): - Running [Isso](http://posativ.org/isso/) on Openshift - [link](https://github.com/avinassh/isso-openshift) - [This](https://github.com/avinassh/openshift-tornado-starter) one shows how to deploy Tornado 
With joblib, I find writing parallel Python code extremely easy. This library in combination with Cython and Numpy makes the speed concerns of "vanilla" Python sort of a non-issue for most use cases. It's much easier to isolate the bottleneck and optimize the fuck out of it than it is to complicate the standard interpreter.
Hi there. You have posted a beginners question to /r/python, however it is far more suited to /r/learnpython, where users are actively interested in helping with beginner topics. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Cheers &amp;amp; best of luck!
While I have used UNIX/Linux etc almost exclusively since 1982, I have to say that the above comment is incorrect. I believe that /u/darthmdh is trying to refer to POSIX standards or perhaps just a general passing reference to Unix-like systems. But, sadly, neither of those have anywhere near as much market penetration or use as Windows. While I steadfastly agree that the Unix-like systems have much better architecture and are less prone to defects in the code produced to use their systems, the claim that the vaguely referred to "international standard for operating systems" makes application development have any kind of platform independence has been proven, again and again, to not be reliable. I do personally, recommend Linux and other Unix-like platforms for development, but not for the reason described by /u/darthmdh 
uhmmm I curated articles from twitter stream , 1197 blog's rss feed. I am sure there must be articles that still aren't featured on /r/python ... Having said that any good article is bound to make it way to reddit sooner or later.
Thanks. But to be honest, I really think your first point is just useless semantics. And with your second point, it seems that you have managed to completely miss what I was trying to say which was simply that you **need a benchmark to make any meaningful conclusion**. Using the phrase *passes X tests* was purposeful on my part, and means it passes X tests out of the **15** tests in the NIST suite. Apologies for the confusion but I thought it was pretty obvious (A) what I was trying to say as well as (B) what you were trying to say. Ciao!
&gt;Well I better tell GVR that his opinions are wrong and he should step down for having a positive constructive view towards interpolation. He he. No comments! &gt;The Zen is a guidebook, for guiding only, So 'guiding' is when it matches with what you propose and the rest of the time it is 'blocking progress'..right? &gt;Implicitness is when a hole gets filled automatically without specifying it... Specifying is not good enough. Of course everything is 'specified' somewhere. The ruby's behavior is 'specified' in the documentation. So the specification should be clearly visible, in its own context, not mixed with other things. Here is where this proposal fails. To see if a variable is being used somewhere, one should not only scan the code but also the INSIDE of the String literals also. So your 'specification' is mixed up with the rest of the string, hence making it harder to see. This hugely affects readability. A price too big to pay for a very small convenience. It will stick out like a sore thumb in a clean language like Python. And by proposing a poorly thought out 'solution' to a solved problem, bike shedding is exactly what you are doing. 
Ah, apologies. I'm using Python 3.4.3 The goal of my program is merely basic use of inputs and variables.
that's cool. I'm always in favor of making little things that are understandable by non-programmers. 
Well the thing is that the map used to create these images only shows at the end of the game. Therefore, you can't do it in real time (unless using the low res minimap), but since it can show you every possible turn and play it to you automatically ([quick&amp;dirty gif example here](http://i.imgur.com/LWeVX8W.gifv)), I'm fairly sure you can find a way to work with it.
You need some real world software development experience to understand why django is good. It abstracts away all the nastiness and is very elegant.
I use WebFaction and afaik it's a bit more bare-metal than PythonAnywhere, which is good in my book (I personally never liked Heroku, for example: too many magic commands to understand, and it ends up locking you in their platform). WF gives you a straight ssh shell, I don't know what PA gives you. Their control panel allows you to deploy skeleton apps and wire them up to specific domains, subdomains or even folders; you then replace these stubs with your actual code. You can have webapps dedicated to serve static content, which take care of all the caching/etag stuff and make things faster. In WF basically your webservers are preconfigured, but it's up to you to customize them. WF has cron jobs that will periodically kick them up in case they crash, but everything else is up to you. So really, the major selling point for WF imho is that it's the closest you'll get to a VPS without having to go through the hassle of actually maintaining one. PA is a bit of a different beast, and it really comes it into its own if you're into ipython notebooks and so on. I've met some of the PA guys and they're awesome, they have a coherent vision which is about empowering app developers rather than just hosting; but if you're just looking to spin a few django instances, WF might be easier to get to grasp with. 
All this hassle and extra mess only for sake of *impression* of verbosity of existing `str.format` ? Introducing another and incomplete (non-interpolated bytestrings) literals type ? How many other ways for string formatting would be yet added to fix subjectively deficient design decisions ? Simplicity and consistency always outweight an extra comfort. But that's me. Unfortunately it may be another, although marginal, sign of continuous Python's decline, like "success" of Py3 adoption, stalled runtime performance or recent rise of Go and JS.
Windows is great, as long as you live and breath Microsoft's own ecosystem. Code in VisualStudio, store data in SQLServer, deploy on Windows Server, when stuck head to MSDN, and you'll be **very** productive **very** quickly. However, one day someone will come around and ask for more money you thought you owed them; or prices will go up; or Redmond will kill your favourite programming language or platform because they're shifting their commercial strategy. And you won't be able to do anything about it. You will always be a sharecropper on someone else's land. Additionally, Windows is architecturally very different from the traditional UNIX model, so most tools developed on Unix-y platforms simply don't run well on Windows. Its traditional terminal shell (cmd.exe) is terrible, its new shell (PowerShell) is very different from any other shell out there, and in 2015 it still does *not* ship something as basic as OpenSSH -- because Redmond folks don't like you talking with computers running anything different from Windows. To recap, a programmer might not recommend Windows because it's a very insular world that follows its own conventions, set by a commercial entity for commercial reasons, on which you'll never have any real say.
I think the author of that post: 1. Didn't pay much attention to the Django tutorial. 2. Has a thing for things that don't work in Aptana easily. He had a similar problem with Rails, but by then was willing to switch to Sublime. Which is MUCH better for Django than for Rails. Anyway, if you think Django isn't a viable alternative for rails, and wish to ignore the evidence of Instagram, Pinterest, Uber, NASA, and thousands of other organizations boasting success, then who am I to stop you?
&gt; if you have a question about news or a software release do you go to learnpython? Stop being so obtuse. If you have a question about how to do something in the language, /r/LearnPython.
It has nothing to do with like or not like. There is a style guide for Python code and it's considered to be a bad taste if you're not following it. http://legacy.python.org/dev/peps/pep-0008/#descriptive-naming-styles
I don't understand. What are you trying to say?
What's the best version of Python to get my SO really turned on?
It [looks like](https://github.com/figment/unpyc3/blob/master/unpyc3.py#L2014) you can run it as a script: python unpyc3.py some_file.py
Wrong python, not talking about trouser snakes
Afaik they don't like getting scraped. Read [this](https://en.wikipedia.org/wiki/Wikipedia:Database_download) and scroll down to **Why not just retrieve data from wikipedia.org at runtime?**
Why `__interpolateu__`? u-prefixed strings are just strings. The u is a no-op only included for backwards compatible code.
I meant to get this out before PyWeek started in case anyone was thinking of trying KivEnt out for it. Sorry I was a little slow, had a wedding and a birthday to attend, and was slowed down getting the Windows and Android builds together for Particle Panda 2.
u doesn't stand for unicode, it stands for "untranslated" -- it's for opting out of translation. ...If I'm reading the PEP correctly... though this confused me too at first.
God, please don't. String interpolation is garbage.
No. I am horrified that things like these are even being considered. I really wonder if the authors of these PEPs (PEP 498) have really cared to examine why things are done as it is being done now. ie, why didn't Python originally implement something like this. I really think PEP should have a section that details this. When someone wants to change something, they should include research (with citations if possible), regarding why the thing they want to change, is the way it is, and why that is no longer relevant. If it makes the whole process of adding new features slow, then so be it. I would rather have features coming in slowly rather than have a fast barrage of poorly thought out features/proposals.
In terms of actually getting the software up and running? Probably 10 minutes for the download and 20 for the install. Once you do that you are pretty much set to go. You can check through the list of available packages on the anaconda website ("packages" are the Python equivalent of "toolboxes") and install any others that seem useful to you with `conda install &lt;package1&gt; &lt;package2&gt; &lt;package3&gt; ...` (leave out the `&lt;` and `&gt;`). Python doesn't automatically load such packages, so this won't have a substantial impact on performance, so you might as well install anything that seems remotely useful. It might take an additional 2 or 3 minutes to add an additional directory for your own code to python's path. Remember, due to Python's better namespace handling you should only need one such directory. Everything else can be organized into subdirectories of that one. You don't actually need to do this, but on Windows it can make things a little more convenient. Also, keep in mind that python scripts in the current directory are always treated as being in the path, this is only for general-purpose functions you will use in many projects. On Linux or Mac I would advise against this, though, you can just use symlinks to the user Python directory. For installing something like PyWavelets that isn't already in anaconda, it is usually just a matter of `pip install PyWavelets --user`. This will automatically download, build (when necessary), and install the package and any of its python-based dependencies. You might want to check the documentation to see if any of those dependencies are already in anaconda, in which case you can install them as I described in the first paragraph. The package manager will then detect that they are already installed and will not install them again. Python's package management is extremely powerful. MATLAB has absolutely nothing like it. Which brings me to another difference between Python and MATLAB: Python users have a much bigger focus on community projects. MATLAB has the MATLAB file exchange, but that is usually just for individual functions, and even then it isn't used as much as it should be. Python, on the other hand, has a huge range of community-driver packages. If you need to do something, there is a very good chance that there is already a package that will get you at least 75% of the way there. At least in my experience, Python users are much more likely to rely on a third-party package to help them than MATLAB users are. This results in much more code sharing and much less reinventing the wheel.
Did you 'sudo pip install'?
Go with Anaconda. Check out "pandas" which is a library included specifically for time series analysis . (videos on youtube) Economists debate whether the market can be "beat" in the long run so good luck, you picked a challenging (to say the least) project.
Interested **in**
You can use matrices (or, rather, arrays) all you want in Python (there are numpy matrices as well, but in practice this is almost never what someone wants). But you aren't limited to them, and you aren't forced to use them when something else would be better.
What a terrible idea. I work in translation engineering and this is *such* a bad idea in so many ways. The current .format() method works very well as it is and doesn't need extra bells and whistles. Let's take a look: i'My name is $name, my age next year is ${age+1}, my anniversary is ${anniversary:%A, %B %d, %Y}.' * Mixing logic and display? **Bad**. age+1 is business logic, not translation logic. * Mixing date formatting with the string itself? **Bad bad bad bad bad**. Date should be formatted independently from the string translation, in a locale-aware way. &gt; Any valid Python expression can be used inside ${} , including function and method calls. Go away, die under a rock. This shouldn't happen inside strings. These strings are what translators will be dealing with. Translators that have zero programming knowledge. Urgh. Nevermind the rest of it, but I really wonder what the fuck is the motivation behind this PEP. It is such a braindead idea in so many ways and solves exactly zero problems while adding a bunch more. This is a malpractice sandwich.
Thanks. I use both almost daily, and have learned a lot about the low-level operations and lesser-known tricks of both in order to get the most out of them. So I feel I have a decent handle on the strengths and weaknesses of both.
AFAIS the Python socket module does not have the TCP_CONGESTION constant, so you'd have to use the value directly: import sys import socket # setup your socket, I'll assume it's called "sock" if sys.platform.startswith('linux'): TCP_CONGESTION = getattr(socket, 'TCP_CONGESTION', 13) sock.setsockopt(socket.IPPROTO_TCP, TCP_CONGESTION, "reno") # continue using the socket
We don't have many that aren't about the language. It'd be cool to have a book on history, current community, how to get involved, cool stories about Python, maybe some case studies.
What's even worse is that this seems to be done by people that have not done any i18n themselves. This is so far away from where that part of the industry is moving.
This fucking reminds me of php. 
Exactly. It's impossible to put a ``ugettext`` around it...
To be fair, a vast number of programmers around at that point (early '96) where still comfortable using the Interrupt Vector Table. This irrational fear of threads was pretty widespread.
`ipython nbconvert --to html notebook.ipynb`
Simple: many programmers feel that 498 would simplify life for them, and argue for it on a 'practicality beats purity' basis. However, that which is a useful tool in the hands of programmers, would be a nightmare in the hands of localizers: the more junk you have in the string that's not human-readable text, the harder it is for localizers to understand how to translate the string. Plus, you normally want to do a two-step process of retrieving a localized string with placeholders, then filling the placeholders in; a setup like this would force you to fill the placeholders first, which essentially would require you to somehow pass all the local *and* global variable context over to the place where you're storing all the localized strings, allow that module to fill out *every* string *implicitly* via the `i""` syntax, and then select the right one. Basically, internationalization is something a lot of people (myself included) didn't think of when evaluating 498; now that we're looking at 501, which seems intended to fix an oversight in 498, it doesn't actually itself look good, but instead shows why 498 is unworkable.
[Someone's a big fan of Scala it seems](http://docs.scala-lang.org/overviews/core/string-interpolation.html)
It seems you are using windows. From what I've heard, getting Python modules to work that require a C or Fortran compiler is really hard (C got better since Microsoft released their MSVC compiler in a package specific for compiling Python modules, but Fortran is really hard). You could see if the anaconda distribution has pytransit packaged, but I doubt it. You could probably get it to work using Cygwin and the gnu fortran compiler, but it will be a PITA, especially if you are not experienced. My recommendation, if you have any experience with Linux at all, is to just install a virtualbox image of Ubuntu or something, and install the package in the box (and run the programs). Even if you haven't, just try out Ubuntu or LinuxMint, those are very end user friendly distributions. I can generally recommend you trying out linux for development, there are much better toolchains present, so your time installing and familiarizing with Linux will not be wasted.
&gt; Mixing date formatting with the string itself? That's not new is it? That's what format does: print('{:%d/%m (%a)}'.format(datetime.datetime.now()))
I named three (that are actually five). Qt seems to have become the leader of the pack.
What kind of work are you trying to get into? Part of the beauty of python is the flexibility of the standard library and lush ecosystem of packages -- there's hardly an area of industry where you couldn't potentially use python.
Hmm, you have 80 widgets? That seems like a lot but I'll trust you know what you're doing. I'd consider looping through them, or maybe connecting the valueChanged signal to a method that passes the value to your model (assuming you're doing some sort of MVC here).
It's a terrible idea for localization either way, but it can still be useful in non-localized strings. *Maybe*. I think it's overengineering at it's finest, but that stuff shouldn't be in a localized string at all. A localized string should look something like this: "My name is $name, my age next year is $next_age, my anniversary is $anniversary_ts." `anniversary_ts` is then a *string* timestamp, which has been pre-formatted according to the current locale. Translators should never have to deal with date formatting, with some very rare exceptions.
Can't really agree with point 2. Also, it contradicts with point 8 on above list. Don't do multiple level list comprehensions, please.
And there should preferably be only one obvious way to do it. Not four.
Gotta say, Nim's really cool in that regard. Arbitrary string prefixing in python would be *really* cool. But how would you do it? Part of the problem is that the very content of the string is parsed differently depending on the prefix (currently). I'm not sure there'd be a way to do that that wouldn't break backwards compatibility.
Or use Anaconda Python. It'll install numpy, scipy and a host of other scientific libraries for you. And it works great on Windows.
I don't really agree. Ruby, generally considered a well-designed language, has very similar string interpolation. This functionality can be abused, but simple arithmetic or other operations within strings really isn't that bad. I think doing date formatting inside of string interpolation is really going too far, but the others seem fine. My only other issue with the proposal is that 3 different special methods (`__interpolate__`, `__interpolateb__`, `__interpolateu__`) seems inelegant, there should be a better way of handling translation, if possible. Also, I think the braces should always be necessary, so `${var}` instead of `$var`.
Question: Why would you want to run bytecode, instead of, you know, normal Python? :) Also, your documentation seems to have an infinite recursive loop. It keeps telling me to click on a link to see the help(like quickstart), but always takes me to the same page(itself).
If it's web development you're after, then apps built on Flask and/or Django. "Apps" may feel vague, but there's a lot of standard tooling involved. Off the top of my head... User accounts Public and user-only content REST API Transactional emails Filter &amp; search AWS interaction Third party API interaction If you had experience with all that you'd be qualified to make 6 figures where I live. (Which, granted, is a major metropolitan area, so $100,000 is middle class.)
My main problem is calling this stuff "translation-ready". None of this has anything to do with translation and it's using horrible translation practices as examples. How do you translate the string `i"My age next year is ${age+1}"`? Every single localizer has to type `${age+1}`. That means a localizer can effectively change business logic. Bad separation of concerns. Then there's this idea that strings should be translated/untranslated, this is just not how i18n works right now. We have language-agnostic ways of doing this. I much prefer the `$var` templating over `${var}`, by the way. But this is essentially *another* way of doing string formatting, *another* syntax that localizers have to learn... no thank you. Funny thing is, for DSLs this would rock, but only if it was actually modifiable at a lower level than that. cf the post [here](https://www.reddit.com/r/Python/comments/3gfaji/pep_501_translation_ready_string_interpolation/ctxuqgs) about how Nim does it. I have kind of the same problem with `@decorators`. If `@` was implemented as a unary operator, one could do some pretty cool things with it.
It does not seem much when you are looking at single lines. But imagine a moderately big, say 40 or 50 lines long scope, with some amount of moderately long strings (Say quarter of half screen wide). Suddenly your task of finding where a variable is used becomes a lot harder IF you have to scan the inside of strings also. So from your example, you can completely ignore what is *inside* the string and only have to look the argument list. ie with format and %, you only have to scan for variables in one context. With this, you will have to scan two. 
Download and install this and try again ( http://www.microsoft.com/en-us/download/details.aspx?displaylang=en&amp;id=29) Edit: never mind see the comment below. Basically that dll us a compiler for windows. You get it for free from microsoft. Certain python modules need it to install. Note you need the 2008 version because it is what they use to compile python 2.7 for Windows and it had to match for some reason. Also, someone correct me if I'm wrong, but if you install Anaconda wouldn't it set up the build tools for you so that a pip install of this package would probably work?
I can only speak for my portfolio when I got hired: A simple artificial intelligence for Tic Tac Toe (Built as an interview test.) Half a dozen games in various states of disrepair. A couple of flask apps.
That's what Brython is for. It's nice to have options in case python code gets too unwieldy.
This is just short-sighted thinking. What about more complicated assignment of interpolated value ? print('Pay debt of {remaining_debt(you).annual_charge(loan) - paid_to_date(time.now())} immediately or you'll be {payment_discipline(you).random(len(punish_options)) soon.') vs print('Pay debt of {due_amount} immediately or you'll be {punsihment} soon.').format( due_amount=remaining_debt(you).annual_charge(loan) - paid_to_date(time.now()), punsihment=payment_discipline(you).random(len(punish_options))) and then try write gettext translation records for each. Although you may create additional local variables to make former interpolation more sane or choose the latter for similar cases but it leaves the question (with an exclamation), does it really pay off add to language's complexity ?
'Ruby is well designed' cannot be allowed as an argument to prove the merit of a feature. May be it makes sense in the context of Ruby, along with of the many other things present in that language. May be ruby has a slightly different philosophy or lack it completely in certain areas. and vice versa. The point is, it does not make sense to cherry pick language features from other languages. All this feature enables is saving a dozen keystrokes. Is the reduction in readability and other security issues really worth the trade off? &gt;This functionality can be abused, but simple.. There should not be a 'but' following 'This functionality can be abused'. Look may be you guys haven't seen how bad things get with a language when features like this get added to it. May be you take the readability of Python for granted. But I come from 9 years of professional php use. And I tell you. This is bad bad bad bad bad. 
If there is a way to do it by installing git or utilizing some gfortran code, I need to do it because it kinda is important for the work I am doing right now. 
This is the most frustrating part of Python on windows. Once you have everything set up its not too bad but its actually quite difficult to find information on how to install and use the correct compilers. If you are using python 2.7 you need Visual C++ 2008. If you are using python 3.4 you need Visual C++ 2010. If you are on windows x64 you need the additional API and some service packs. You then need to ensure python is using the correct compiler - this is generally done by calling a .bat file from the command line which sets environment variables. If you google "installing numpy" you should end up in the right place since this problem is shared by all compiled packages. http://stackoverflow.com/questions/28413824/installing-numpy-on-windows Python 3.5 will have a better system.
Link to info about what's changing in 3.5? I'm very curious
Reminds me of Bash a little bit. I liked the f' ' stuff somewhat, but I feel like this might take things too far.
Git is revision control, not a compiler. Reading the Github Readme tells me that they either haven't tried compiling on Windows, or haven't gotten it to work. Looks like you are SOL on Windows. If you are unwilling to learn Linux, can you borrow a Mac (though that maybe more difficult with homebrew, etc)?
What a load of uninformed rubbish. Most of the programs, tools, languages you mention can be installed trivially on any recent version of Windows. 
&gt; Only MS compiler supported with gfortran on win64 Try installing this: http://www.microsoft.com/en-us/download/details.aspx?id=44266 
So far on this thread there has been a lot of rubbish parroted by people that either haven't used a Windows since the 90s or simply don't know what they are talking about. While it is true that certain programming languages and their respective tools are more suited to a MacOSX or Linux because their communities tend to use those systems. Ruby and Node for example seem more at home on MacOSX because most of the people building stuff with node or ruby tend to be using macs, whereas on Windows I will run into the odd bug due to feature being written on a *nix system first. I regularly do Node and Python dev and I don't run into issues, but I am a full stack web developer. The only real problem you are likely to run into is long path names there is an arbitrary limit of so many characters. Most devs put their dev environment on a directory on the root of the drive e.g. C:\dev\ so to avoid running into it. Most tools these days are platform agnostic. I run [CMDER](http://gooseberrycreative.com/cmder/) as a command line alternative that has many of the GNU tools you are likely to want to use as well as OpenSSH and Git. Tbh pick a platform that you suites your needs.
I'm still new to programming, however my understand of *self* is that it is a placeholder for future objects created from a class. For example, if you have a class named MyClass, eventually you're going to create objects from it, however when you're first coding MyClass, you don't necessarily know what those future objects are going to be called, therefore you use *self*. For example if MyClass were: class MyClass: def __init__(self): self.variable1 = 1 def multiply(self): return self.variable1 * 10 And then you were to create on object from it: math = MyClass() Inside that 'math' object, all of the *self* placeholders would have been replaced with 'math': class MyClass: def __init__(math): math.variable1 = 1 def multiply(math): return math.variable1 * 10 So because you don't necessarily know that the future object is going to be called 'math', you use *self*. Again, I'm fairly new to programming. Someone please correct me if I'm wrong.
I am not unwilling to learn Linux, it's just that I don't have time right now. You are saying that the pytransit team hasn't built a binary distribution for Windows? Does this mean there is no folder to be put in site-packages folder?
That's not accurate. That's true only for knuckle draggers. OS/2 was already around for a long while at this point. NT was the next step, albeit more broken version of OS/2. Both embraced threading as the primary parallel model. Both sucked at forking. NT was released in '93. At this time there were multiple pushes within the Unix world to embrace threads because process forking was so heavy. I worked on all three platforms, plus DOS. The primary reason, by far, Guido was against threads is because he's scared of them and doesn't understand them, and python became the embodiment of his fears. Even to this day python is purposely designed to make threading a second class citizen. 
Agree with everything you said. Most of these sins are actually, "Haha ole chap, try not to do these, will you? Tally ho."
Just to reinforce how well it works, this entire site is made from ipython notebooks wrapped with a bit of html headers and footers: http://chrisalbon.com/
I like the idea of string interpolation but why ${} why not just {} like with .format. they could do something like the C++ user defined literal thing and just add in i"" as a library. from interpolation import i. then i"" is just a shorthand for "".format(\*\*vars(),\*\*globals())
This looks really nice! Would you happen to have an example script that would not require IPython, perhaps saving simply a few images?
I know the port that is needed however, sometimes the daemon is not "listening" the server is a secure IBM server that i am working with and i would be pining that. 
&gt;The sooner I can build a web site without JavaScript, the happier I'll be. You're missing out.
Missing out on what?
ES2015/6
* implicit * consumes globals
I think [this](https://sukhbinder.wordpress.com/2014/03/19/gif-animation-in-python-in-3-steps/) is what you are looking for. I found that in less than a minute.
Thank you for the specific topics. This will be nice outline for me
I'm not, and the sooner I can build a website without JS the happier I'll be.
Thanks for your advice.i have several projects around. I will upload in git
It is entirely possible, but you'll probably have performance issues. I guess you want to make a physics engine. For the GUI you could use pygame and if you want to make the physics engine yourself you'll have to find a way to load objects (what kind of objects? you should research that) and you'll have to implement collision detection (research that too).
(str.format would look better and saner, mind you.)
I'm a huge fan of Django, but for this small project, I went with Flask. 
Please elaborate
&gt; The sooner I can build a web site without JavaScript, the happier I'll be. AMEN Brother!
Haha. Website w/o Javascript: That's like the promised land. Esp if we can replace JS with pure Python.
What will happen if I do this? v = MyClass() print(v.variable1)
Also saw [Beyond Pep8](http://www.youtube.com/watch?v=wf-BqAjZb8M), hmm? Loved that talk.
Great post title, OP.
Ahem, I think you should re-read my comment. I didn't say they were still using the IVT, I just said that was what most people were most familiar with. And seriously, you're going to argue "most" and "OS/2" in the same sentence?
Typescript is nice.I also need to check out websharper, f# in browser sounds like heaven.
Don't know why you are being down voted. I think this install would work fine if you used Anaconda and then did a pip install
Valid arguments. Excluding translation issues, I think some form of interpolation is a good idea. I don't know the right answer to the translation problems though.
Yes, but what if you use this, too? https://code.google.com/p/pyv8/
What sort of security issues are you referring to? Injection flaws all work the same whether they're introduced by string interpolation, string formatting, or string concatenation. &gt;There should not be a 'but' following 'This functionality can be abused'. Lots of things in Python can be abused. You can do crazy stuff with `eval()`, with `locals()`, `__builtins__`, operator overloading, code objects, monkeypatching. Most people who use interpolation will only use it for simple things like `"Your age is ${2015 - dob}"` or `"Snippet: ${text[:75]}..."`. PEP 8 and style guides are there to tell you to not abuse things. Python itself shouldn't hold your hand everywhere, even if the language is a bit more conservative than languages like Ruby, and way more conservative than Perl.
Haha. Do you think s/he succeeded?
How come this has no Github repo??
A few ideas. 1. The server can periodically send out "I'm alive" messages. 2. The server can periodically touch a file (use mtime). Or a database. 3. Client can periodically ping the server with a "hello" message. Server responds with a "hello" in return. 
Yeah, I feel like there's this silly macho attitude against distributions like Anaconda like "Real Pythonistas just use python.org or sudo apt-get!" Many people are just starting out with Python and want to do some scientific computing, and fixing many of the problems that occur when trying to install modules takes more detailed knowledge of how Python works and often requires command-line skills that beginners are lacking. It's silly to expect people who are just starting out with something to also be experts at it, and it's also silly to expect people who want to give something a try to have to dig through tons of garbage forum posts to figure out their issues before they can get to np.mean([1,2,3,4,5]).
This is because of the recent shift from Satya Nadella, the new head honcho in Redmond. It is widely reported exactly because it is exceptional in nature, going against traditional Microsoft policies. There is no guarantee that they will not take everything back if Nadella is removed, nor there is any guarantee that ssh support will be comprehensive and good enough for production use. They've come to open source out of desperation, after 20 years of fighting it bitterly (and losing); but those 20 years happened, and acting as they didn't would be disingenuous today.
You will get "1"
Does anaconda set of compilers for fortran etc.?
As a fellow windows pythonista, I share your pain. Like was suggested elsewhere, I generally use Anaconda but periodically bump into the same issue you just described, where Windows doesn't have the appropriate compiler for some package. The first step I attempt is to go through the Anaconda terminal. Open the Anaconda Command Prompt (in the Anaconda folder), cd to the installation folder, and attempt to run those commands through there. If that fails, the next place I visit is [Christoph Gohlke's page](http://www.lfd.uci.edu/~gohlke/pythonlibs/) to see if he's been nice enough to precompile a binary for me. As a first step, perhaps try one of the precompiled numpy versions to see if it has the appropriate fortran engine for your purpose. 
I have a pelican extension to do this. https://github.com/justanr/ipynb_reader Still some rough edges, but it works. http://justanr.github.io is my blog that, and I use notebooks for anything that includes code.
Sure. Can you use http to send message? Or is this a completely internal/custom app?
&gt;Could you provide an example of a case where string interpolation would introduce a flaw, or hide a flaw, where .format or % formatting wouldn't? If you are asking about allowing expressions inside strings, that is a pretty useless thing to ask. An attack is formed by one small edge case in an endless combination of ways something can be used. So asking someone to demonstrate a vulnerability in a discussion is pretty futile. Why do we use prepared statements instead of escaping strings manually? Because by sending data and executable separately we *completely eliminate* a whole class of attack vectors. Similarly, by allowing executable expressions in strings, you are enabling a whole class of attack vectors. How will those attacks manifest? I cannot imagine right now.
I'm guessing you know this, but `says` doesn't need to be defined before `__init__` to become a class variable. That is: class Dog(object): def __init__(self, name): self.name = name says = 'bark' will do just the same.
this will probably be a custom app however i could import other things if necessary or use an api. 
Is this a not-so-subtle jab at the two new string formatting PEPs?
Why would you use Python to develop an Android app if you already know Java?
Python is widely used for scripting and web applications. However, Java is more suitable for an Android application. I haven't heard Python being used for Android development.
I'm not going to draw a line between javascript as a language, and javascript best-practices/tools. Maybe JS will be an alright language some day. I don't debate that. But it'll be javascript in name only.
Try making a small game first so you understand the issues involved. Making an engine first isn't a great idea since you won't be able to make intelligent decisions about the underlying organization/data structures being used or what a sensible API should look like. Also note that making a game engine, especially one that is "realistic" and has a graphical toolchain generally takes a team of highly skilled programmers many years. If you need to ask on reddit you aren't going to get very far.
http://kivy.org/#home 
Last change was over a year ago; it's either already been moved, is in the process of being moved or is abandonware.
It's an hypothetical question. I want to understand how much would Python underperform against Java and/or against making the software in C/C++. The only solid thing I have is that it's really good for web based porpuses and small scripts.
&gt; To be fair, in MATLAB you can do something like myarray(end-3:end). You can even use myarr(floor(end/2):end). Still not as nice as Python's, but better than manually using lengths. TIL I've been doing Matlab wrong for over 2 years. I didn't know the end keyword behaved that way, chock it up to never being formally taught Matlab. I thought it was a magic keyword that didn't have any numerical meaning. &gt; Again, numpy arrays and lists are not the same thing. If you're a lay person (read: anybody who doesn't have a computer science degree) and all you need to do is store sequential data then to you they will be functionally equivalent. The main difference is that arrays can have multiple dimensions, which complicates some of the examples you give later on. For example, in Matlab I can have a 2D array myarr with shape (2,2) and a 1D array indices with data [1, 2, 3, 4]. myarr(indices) will unwrap myarr row by column, even though that type of indexing scheme makes absolutely no sense. (Apparently Matlab reshapes the result to indices as well, so if indices is a column vector myarr(indices) will be too.) In Numpy indices cannot be bigger than the array it's addressing, so the Matlab example here gives an IndexError.
Ah, well Python can be ten to a hundred time slower than Java or C, depending **a lot** on what you write. Surprisingly, this often makes little difference because waiting 1/100 or a second or 1/10 of a second for a result isn't significant for the user. It does make a difference for computation intensive software, but not for things like fetching a piece of data over the network because the network itself is the bottleneck, not the software that runs on your phone. You should also consider other things than raw speed. Python is easy for beginners because it is more concise and rather forgiving. But it also requires more testing because type errors are not detected at compile time like in Java, which is a statically-typed language. If you're planning to write complex Android software, pick Java instead. Also you will have less difficulty porting/installing to Android it since it's the recommended language for it. Python may be a fine choice is you're writing quick and dirty apps just for yourself, but I don't know much about running it on Android so see what others are saying in this regard.
&gt; int(str(input), radix) Meh. Built-ins.
Not sure why he deleted it either, the examples were a great showcase of what Python has been used for. I just wanted to bring some clarity to the two cases. Not using Python for Android development isn't really a case of performance issues. That is mainly a problem of lacking tools and support. You CAN do it, but that doesn't mean you should. Java is MUCH better suited for it. The entire ecosystem there is centered around using Java.
Ah! I see. It's not a really large scale project but it's always good to understand your limitations. Thanks a lot for your answer! The picture is getting clearer with every response :)
I would like to read why you suggest me not to suggest sudo pip install.
I don't see what difference the typing makes to the amount of testing. I believe that Python's strong typing at run time and its use of "duck typing" are on a par with static typing at compile time. Add that, e.g. off-by-one errors are relatively rare in Python owing to the way that its for loops work and it's very much a case of six of one, half a dozen of the other.
This might be the stupidest cheer for the status quo that I have ever heard. Proving a negative can be pretty hard if not impossible. If the fence was put up for no good reason then it could be impossible to understand why it was put up. Thus if an explanation beyond "The person who put it up was a moron" is demanded, then the fence could remain forever. So I would rewrite this rule: "If something needs to be changed and no good reason can be found for it to remain unchanged then change it." In the world of programming I have seen way too many religious arguments where people will say things like "It is better." or it is "A standard." A great example of this sort of crap was XHTML. For a while people were hot and heavy about XHTML. Now it is something that most people pretend never happened. 
Thanks for the points and tip about RequestThrottler! Sending a request per second is a good advice. I initially thought that it would only be a single page and forgot to add the request per second in the process. I'll update the tutorial and code and also add a disclaimer about scraping from Wikipedia. Thanks!
Won't this possibly be detected by Snapchat which may then result in the account getting banned? 
* Chained exceptions * Keyword only arguments * Extended unpacking (With even more awesome coming in 3.5) * `nonlocal` * `yield from` I could go on but those are the ones that I use regularly and that make me just a little bit happier every time. 
Why not use a Wikidata query?
Ah, okay. Thanks! 
Why bother with the isinstance test when Python will do that for you for free?
I am definitely a fan of Chesterton and definitely a fan of conservatism in computer systems design, but I've never been a fan of this principle. Sometimes things were done because nobody knew better and some solution or another was needed, regardless of merit. If you keep that in mind, sure. If there's an active obligation to say "I see no evidence that thought was put into the old way of doing things," and that's enough, sure. But if you have to _prove_ that you've looked into it and find any scraps of evidence about any thinking that went into it before changing it... that's a great way for the least-thought-through fences to stand forever out of baseless conservatism.
- Not everyone has sudo access on the machine they develop on - It causes you to have a ton of packages installed globally, which can cause conflicts - It makes isolating dependencies a huge pain in the ass - Uninstalling will leave a bunch of dependencies globally installed, even if they're not needed or useful anymore
I was just watching a panel at PyCon about PyPy. Looks interesting and it should run the three lines of code I have so far. Oh that's a good point. Didn't really give it thought as I plan to whatever I make, be a personal side project. Thanks for the input!
I set up a Django app on Digital Ocean. I followed their instructions to make the app more secure. The part I'm confused about now, is how often do you check for security updates? What if I just left the app running and did not touch it for six months?
Nice use of `enumerate`, OP.
I get this error when running `setup.py build`: $ python setup.py build /Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/distutils/dist.py:257: UserWarning: Unknown distribution option: 'compiler_directives' warnings.warn(msg) running build running build_ext @(#)PROGRAM:ld PROJECT:ld64-136 configured to support archs: armv6 armv7 armv7s i386 x86_64 LTO support using: LLVM version 3.2svn, from Apple Clang 4.2 (build 425.0.28) Traceback (most recent call last): File "setup.py", line 6, in &lt;module&gt; ext_modules=cythonize("fx.pyx")) File "/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/distutils/core.py", line 148, in setup dist.run_commands() File "/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/distutils/dist.py", line 929, in run_commands self.run_command(cmd) File "/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/distutils/dist.py", line 948, in run_command cmd_obj.run() File "/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/distutils/command/build.py", line 126, in run self.run_command(cmd_name) File "/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/distutils/cmd.py", line 313, in run_command self.distribution.run_command(command) File "/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/distutils/dist.py", line 948, in run_command cmd_obj.run() File "/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/distutils/command/build_ext.py", line 323, in run force=self.force) File "/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/distutils/ccompiler.py", line 1034, in new_compiler return klass(None, dry_run, force) File "/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/distutils/cygwinccompiler.py", line 281, in __init__ CygwinCCompiler.__init__ (self, verbose, dry_run, force) File "/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/distutils/cygwinccompiler.py", line 125, in __init__ if self.ld_version &gt;= "2.10.90": TypeError: unorderable types: NoneType() &gt;= str() ```
It's not necessarily a cheer for the status quo unless you choose to understand it this way. You don't necessarily have to agree with the reasons, or spend an unreasonable amount of time trying to find them if they're somehow hidden or inaccessible. However, it stands to reason that at least making a reasonable attempt to understand why a rule has been put in place before trying to change it is not a bad thing. 
Don't be discouraged. When I was new to programming, I wrote a very crappy version of [`diff`](http://linux.die.net/man/1/diff) because I needed to compare two CSV files and I didn't know that `diff` existed. This kind of thing is normal, and it'll probably happen again. Just keep going.
Wow, I thought this had been blocked by snapchat a while back? Glad it's still around!
Hey, look at that! I didn't. It just so happens that's what people do anyway. Also, be it far from me to say that reddit isn't riddled full of douchery and useless comments.
Yes
Cool. Someone else made something similar a while back: https://github.com/chriskiehl/Gooey Could you go over the differences?
Naming a variable "input" is considered bad practice as it shadows the [built-in function of the same name](https://docs.python.org/3.5/library/functions.html#input). Also r/learnpython please.
Most of us are only using Windows because we have to for some reason.
I know of most of those. Not criticizing you, but to me they don't approach making the pain of changing worth it. And some things (print) I hate about 3. 
I am sorry, but those are not [Prepared statements](https://en.wikipedia.org/wiki/Prepared_statement). I am talking about sending the query with placeholders and the actual data in separate packages/requests to the database server so that there is NO way server can be confused into thinking a piece of data is part of the query. 
HOLY COW. This is amazing. I used to do reaction diffusion simulations in my last job. (like the examples they show) this would have been so much easier to use. Thanks 
The main difference is that tkform does not require wxPython, which gooey does. I always have trouble installing wxPython, and for an end-user, installing wxPython on top of Python is a real buzz-kill. The main work-flow is different. Gooey is really clever in using a decorator around argparse. In tkform, you construct it more like an HTML-form, which allows things like parameter checking, extra file analysis etc. I've also included a special widget - a reorderable list of items. However, tkform lacks some of the great features of wxPython such as drag-and-drop 
that was my question too.. are you a CS major? 
efficient
&gt;do I need to learn basic sorting &amp; other algorithms Choosing the appropriate sorting algo is not the most common task in programming, but... If you are programming you will be using algorithms. If you don't know them, you will eventually reinvent the wheel.... Even the most basic regular file parsing task can cause - if using a wrong approach - serious performance bottlenecks. Sorting algos are learned because these can teach the importance and process of choosing (and designing) of an algo. &gt;to be able to get a job? To get a job, you have to be smart and get things done. If you get a sorting task and try to solve it as a 6 year old (smart) kid, you do not appear to be smart. &gt;Are they hard to learn? As hard as learning anything mathematically abstract. Is linear algebra hard? &gt;Does they make a difference in performance? Yes. &gt;Also, when I'll need to use some special algo? That is part of learning the algo.
I tried to do with but with matlab plot jpegs. I ended up just creating it in GIMP. :/
Matrix multiplication? *drooool*
Are there any links to those?