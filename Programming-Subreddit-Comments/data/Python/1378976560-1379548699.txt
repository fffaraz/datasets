Well, it's intended to be coherent as text, while at the same time being a valid Python function in which most constituent lines evaluate to True and no line evaluates to False. There's some interplay between what the text layer is implying and the mechanics of why some of the lines are evaluating to True, if you look for it.
I was just wondering if, for example, "." should be pronounced "dot", or not at all.
Hmm, I suppose when taking it in as text I don't *personally* subvocalize the dot or assorted non-alphanumeric syntax
A little over my head :)
Requests 1.0 has proxy support...[sort of](https://lukasa.co.uk/2013/07/Python_Requests_And_Proxies/).
That's awesome.
 (None is True) and False I think that evaluates to False, I even tested it to make sure
I'd say that's exactly why dir *should* be used. It's being used in the context of autocompletion etc here, and the whole point of overriding `__dir__` is for the class author to say "I know better than python's defaults about what things are attributes on this object". Eg. they may be using `__getattr__` to construct properties on the fly, but can still tell what properties will be present. Code using dir will be able to take advantage of this and provide exactly the information you want. Without it, those properties will be lost, and so it'll do a *worse* job of getting any available attribute. If you *do* roll your own, you'd likely to want to *preserve* this `__dir__` behaviour anyway. Now yes, someone *could* override it to break your tool by hiding stuff you'd want to see, but someone could override `__builtins__` to break your tool if they wanted to. The ability to do so doesn't mean you want to ignore the people who will be using it correctly.
Amended to the more pedestrian (though hopefully sentiment preserving) "None is not True or False". Thank you again.
No problem. Correcting other people over little details is my specialty.
When you say installing pip is quite a task you mean on Windows and Mac right? This project mixed with an offline repo made by [pip2pi](https://github.com/wolever/pip2pi) could be a hit.
There is also the units module in astropy: https://astropy.readthedocs.org/en/latest/units/index.html
And suddenly I feel like trying to organise a python workshop in my area.
What are the contents of your Python installation's /Lib folder?
If you open the html documents, do you get [this](http://docs.python.org/3/library/traceback.html)? If so, then that's the documentation, not the libraries.
It cam be incredibly difficult if you use the official python documentation. I came from the .Net sphere which has evolved into 'download this .msi and nuget the following library. Python has really caught up with pip, but install is still confusing if you aren't used to open source development.
Yes that's exactly what I have, thank you! Is there more to obtaining the libraries than simply downloading and installing the recent version of python? Thanks to your revelation, I now realize there seems to be no trace of what I thought I had obtained. You're amazing by the way! 
I don't use windows or mac actually but I'd definitely want to see this work on windows. Even on linux, the concept of installing packages seem to be out of place for someone new to python. Should we install it system wide, local or what is this thing called virtualenv. Most of the time we just need the third party packages and having it next to our apps seem quite logical. pip2pi look interesting too. The section 'Without Web Server' should be at top, I'd almost skip it as I don't interested in maintaining another web server to host the packages.
The part about the absolutely rubbish distribution story for python is so completely true. It's really great to see people actually raising it as a major issue. 
The good manners dictate that we should install pip system wide and use it with virtualenv (and likely virtualenvwrapper, a gift from heaven). pipz seems to solve the use case when the developer has no admin rights over the workstation, very handy too. BTW, if you set your `.pip/pip.conf` like this it'll be a charm. [global] index-url = file:///home/MYUSER/pipdir/simple After this you can go nuts installing anything from your personal pip repo.
More the shame because requests is *so good*, pip is *so powerful*, and virtualenv, while still a little cumbersome, is absolutely the right way to isolate development environments -- but to know that, you need to steep in Python culture for a few weeks or months.
So what's the "rubbish" part, exactly?
I am pretty sure that Python 3 now adds C:/python3x/ to the environment path durring installation.
You're probably right, thanks for the hint. I might do this when I find the time.
Does anybody fully grasp the math behind this code? I tried to seek clarifications from OP but he doesn't seem to be really active on reddit
After much sweat and turmoil I've finally conquered this issue with minnio's help, along with [This video from susanemcg over at Youtube](http://www.youtube.com/watch?v=iZzMm2RlvaE). My problem was that I was expecting to see the actual files as they were detailed by the error, (threading.py and traceback.py) however the only thing I had to select was a unix exe file called simply: python3 reflecting the most recent update I'd done earlier today out of desperation. The path was exactly thus: MacintoshHD/Library/Frameworks/Python.framework/Versions/3.4/bin/python3.4 I can't believe this took me all morning but am glad to have that settled! Hallelujah! 
Well what have you done so far? Show us that, show us what you tried and explain your logic.
http://pastebin.com/fk5yTx58 fixed. thank you. Still cannot seem to read the response data though :/
Jedi doesn't actually use the `dir` and `__dir__` function. I just realized that I haven't made this clear. Jedi generally doesn't execute code. The reason why I'm mentioning this is because it has really confused me (I'm using the interactive shell to introspect).
Jedi doesn't actually use the `dir` and `__dir__` function. I just realized that I haven't made this clear. Jedi generally doesn't execute code. The reason why I'm mentioning this is because it has really confused me (I'm using the interactive shell to introspect).
 `__bases__` is not relevant. That's true in a lot of cases. But most of the other magic methods are also not relevant. I mean seriously, who knows what ``str.__reduce_ex__`` even does? Who would use it? `__bases__` is something that a lot of people have used in contrary.
Nope. This is [Jessica McKellar](http://jesstess.com), not [Danica McKellar](http://en.wikipedia.org/wiki/Danica_McKellar).
do you need to send a newline after the json data?
A better subreddit for your question is /r/learnpython but like /u/ScullerLite said: when you repost there, show what you tried and where you are stuck. 
Metaclasses are pretty rare. IMHO magic methods are confusing anyway most of the time in the dir function, especially for beginners, I would probably propose a `dir(object, magic=False)`, to just exclude all magic methods by default.
Yes, I've read it. But people usually don't know that `type` is a metaclass. "interesting set of names" is also wrong. Because who would ever want to know about `__reduce_ex__`.
Well I eventually got requests working but ONLY after finding a YouTube tutorial... Turns out all I had to do was copy a folder into one of my python folders.. The instructions on the website were useless to me. 
yes. I first have to auth and register. then read the stream. i have updated the post to include docs.
I have updated my post w/ current code as well as SDK reference
It's not that hard *if you already have all that knowledge*. Unfortunately, the target audience has *0 of that knowledge*. If you don't, you'll spend 90% of your time figuring out how to set up your environment correctly. I can say this having taught quite a few beginners python workshops now, and being the one to tell people which is the correct choice and tip to know over and over and over, just to get them started learning what a variable is and how to write and save a code file.
Interesting, but kinda pointless. I've asked tons of questions and no queries generated. How many people that live in China speak english? How many USA presidents have visited Iran? Questions like those got no response. Which movies does Quentin Tarantino star in? I got a lot of movies returned, but I'm not sure he was an actor in all of them, and definitely not a 'star' (more a supporting role or bit part). Which movies did Quentin Tarantino direct, but not star in? No query generated.
Pip is great and all, but IMHO the requests team should start offering msi/exe distributions.
So.. You're not sending a newline.
It does not say anything about arrays, not sure why you changed that.
&gt;2013AD I am glad you specified AD in the year, I would be hopelessly lost without it. But seriously, good work. 
I think the point is really about side-effects. The given example has side-effects - just like a messy jquery spagetti would ... while the django query chain always returns new objects, *not* self.
If this works well (I haven't tested it) this is huge. Anything we can do to make getting Python setup on Windows less complicated is good.
I thought the latest Python 2 installer did as well?
She's also a PSF Board member and the organiser of the world's largest Python user group. 
&gt; or better yet add ipython as a dependency and import this file. Please, DON'T. Pulling [8 MB](https://pypi.python.org/pypi/ipython) as a dependency, for just a module? That's the reason I don't use, for example RabbitVCS. It requires IPython (!?!?), so... if something goes terribly wrong, you get an ipython window to do some debuging. Gosh, that's ok for RabbitVCS developers... but why the heck do I need to install ipython as an end-user? Sigh... had to get that out of my chest, sorry :-) All is good an well with IPython. It's great. But I have no need for it. And non-essential dependencies are evil.
Used it to load selenium and update Django so far. Just point at your python.exe file and go.
I prefer lean systems.
Thanks for pointing this out. Look like I'm not properly testing this in a clean environment. Probably the zipped pip doesn't even work at all but instead just use pip that I'd already have in my system. Issues I have encountered so far:- https://github.com/k4ml/pipz/issues/2 - fixed this by moving pip and setuptools to the root dir, also added pkg_resources.py. https://github.com/k4ml/pipz/issues/3
You can replace half the code with: from collections import deque
I didn't see that first time I read it through. Ow.
&gt; preventing code duplication and minimizing software development effort Valuable goals, ones I do try to pursue. But not while risking dependency hell, or needless over-bloat. Oh well. The world is beautiful because of it's variety, so its ok if we don't fully agree :-)
Wow. Dreams crushed.
I cried a little 
How hard would this be to do? I mean 500 dollars? I want to try and do it and give it away out of principle. 
500 dollars isn't that bad if it saves you a few hours here and there at work - it was a net win for me probably in the first month. There's a free trial too, if you want to play with it first.
Some people have way to much time on their hands.
The anaconda distribution from ContinuumIO is easy to setup. 
I’m sorry Vinay, but it takes more than a “quick reading” to fully grok it. Nobody wants to replace your logging package, so try to approach it with an open mind without being defensive.
Let me clarify, datanitro is an excellent Excel add-on that really improves its functionality for data mining and analytics. It really is an enterprise tool that a lot of professionals use. That being said, the price tag has prevented me from using it. 
I would think that a little command like script could do it just as fast, but in all reality, excel is probably good enough at this job. Of course if you have more values than is conceivable to enter manually, then python would be a good choice for this task.
Yeah. "play" with it.
I mostly am curious because I want it to be useful for me, and this is one of the ways I conceived. At this point, it's not terribly troublesome for the type of research I'm doing, but I rather like the idea of mixing my interests and bringing them together, and will be embarking on projects soon that will see me dealing with loads of data, at which point I'd like to have it as an additional tool. So I think I'll give it a try, although not at that point yet since I've only just started learning Python. If I can avoid spreads, I will. 
Well, just for fun, type the values into Excel, then save it as a CSV. Then using Pytohn import the data to manipulate it. Try some of the scientific libraries like matplotlib and numpy. I dont know much about them (I work on web stuff) but there are plently of dudes in /r/Python who use them and could assist.
Score. Thanks much for that.
Removal from either end is `O(1)`, removal from the middle is `O(n)`.
very nice. there should be more python modules with this flavor.
Editorialized title. This is not python related. *edit removed hyphen*
there is lots of use of class-scope "globals", the code is practically broken
Yeah I could get a lot of use out of this, but far too expensive. Even if i wanted my workplace to buy it for me I would need work with it for a long while to build some apps in order to make a case, which i dont really have the opportunity to do. 
Anyone have suggestions on how to make IDLE a productive dev environment? 
Sure, I mention the JSON-logging thing in “Getting Started”. The beauty of structlog though comes from a combination of all features + a nice, simple but powerful API that is freed from a the shackles of backward compatibility and works with any logger on all relevant Python versions. I use it in all of our internal projects (that include Twisted and logbook) and iterated on the API until it felt most straight-forward and usable. I hope we can agree that both approaches you mention are a bit involved – simply because logging wasn’t explicitly made with structured logging and incremental context building in mind. Your logging and my structlog are great buddies, have a more throughout look. :) Also if you have suggestions for a better integration, I’m all eyes/ears.
The best talks have a short introduction. Nervous speakers take a long time to ramp up to the best bits and by then it is too late. 
It's always possible to roll your own solution like that. Doesn't mean I wouldn't prefer to use an existing one.
It now contains an install option for you to add it to the path
I might keep this just for the "Upgrade all packages" button.
More PyCon NZ videos here: http://nz.pycon.org/events/talks/ I enjoyed this one: [Using Cython for distributed-multiprocess steganographic md5sum-collision generation. For... reasons](http://youtu.be/Dj9_EIlc_NU) It didn't really have much to do with Cython, but more just hacking on a fun project.
I think that Python(x,y) makes it easy to get running on Windows. I was kind of surprised she didn't mention it.
Alternatively there are plenty of packages that let you directly read and modify excel files from python, and there's [this thing](http://www.pyxll.com/).
A starting point would be intellisense-like completion and help, similar to what bpython has.
I see you don't play eve.
Yes, well I need to do all three. In fact, removal from the middle could in theory be used significantly more often. 
this was unnecessary. Thanks.
RuntimeError: maximum recursion depth exceeded
Open office is not used in the corporate world. On a more serious note, integrating python with a closed source project is much harder, as you can imagine, than with open office.
Note there was also this product some years ago called Resolver: http://www.resolversystems.com/products/resolver-one/ But is now sadly defunct. I believe its failure largely extends from its expensive licensing costs and lack of free versions.
So I just started ramping up on Python for exactly the sort of stuff referenced in the video: scanning over large data, numpy and scipy, etc... I'd used Python years ago as a scripting option, from an ease of use / lerning I thought it way beat most of the other languages / tools I tried. The fact that it enforced proper code formatting as a control mechanism made it something I pushed on a few others who were learning to program... I used to hve a CS teacher who would make students print their code and highlight open and close braces in C++... since students refused to properly indent and structure their code. All that being said; scipy has been a bit of a pain. Numpy was easy enough to install, and I have some issues with their conventions (numpy.random.random() still hurts my brain to see in my code; I keep thinking I accidentally wrote the function name twice). But Scipy was most annoying from a setup perspective. I was looking for an easy module to add in to my installation, but no... the "recommended" process was to download one of the big kits (basically reinstall another instance of Python). I've found the load time far worse with these kits than with "core" Python; and my performance has started to become erratic ("import statsmodels" takes between 8 sec and 22 sec when I load it?) Some of this is just a learning curve, and I'll admit I'm not to the point of optimizing my setup... but it's been a stark contrast to my first experiences with Python as a pure scripting language. Maybe the above was a little bit of a vent / rant... I guess sometimes I need to do that :/
OP meant to link to https://github.com/jomido/jogger. /u/jomidosan, I'd recommend [making a new link post](http://www.reddit.com/r/Python/submit).
Damn. Thanks. http://www.reddit.com/r/Python/comments/1mbcp2/jogger_navigate_log_files/
More info? EDIT: I iz slow.
OP delivers :D
I know that you said you aren't at the point of optimizing your code, but here's a couple easy tips for importing modules. When you want to import just a few functions from a module you can (and should) do it like this this and avoid the "numpy.random.random()" style: from math import sqrt This imports the square root function from the math module and you can call it just like normal functions: x = sqrt(16) If you need every function from a module, do this and you can leave out the module name when you want to call the function: from math import * Now you can call any of the functions in the math module without going "math.exp()" etc. Finally, if you just don't feel like writing the whole module name when you want to call a function from it, you can change it: import math as mathematics Bad example, but I'm just trying to show what it does. "mathematics.sqrt()". I usually "import numpy as np" just because I've seen it done that way and it makes sense. Sorry for the lack of formatting. I'm on my ipad. 
There's an upgrade all packages button???
Most popular frameworks today do all of these things already, except for probably not supporting CGI, because it's a shit outdated protocol that only hosts who don't give a rats arse about python use anyway.
I thought "import *" was a bad idea?
i didn't say it was the same, jsut in the same ballpark. And i think their very closed model doesn't fit into how people think of this kind of product if it is unproven. If they had a lot of existing customers using it I'd understand a closed model.
I would move the 'event' to the front of the output line. This would change the output from this: some_key=23 user='hynek' source='http' another_key=42 happy=True event='user.logged_in' to this: user.logged_in: some_key=23 user='hynek' source='http' another_key=42 happy=True I want to see 'event' first because it gives context to all that follows. This format also puts the event in a predictable location and saves some space.
I'd like to see it automatically handle dumping variables. So this: user='anonymous' some_key=23 log = log.bind(user, some_key) log.info('user.logged_in') would produce this: user.logged_in: some_key=23 user='hynek'
I think the wide adoption of PHP has as much to do with its ease of development as it does its low-friction startup process. With PHP, you learn one language, and you know how to write templates and controllers and models. In fact, you're (almost) encouraged to skip the writing of controllers and models, and just crap all your logic into the template. Because that's where PHP started, and it's still a big proportion of PHP development. None of the Python templating languages really look much like Python. You know why? Because the significant whitespace that makes Python so readable, makes it very unsuitable for a templating language. I am pretty sure this is why Python does not have greater penetration into the "long tail" of low-code websites. As for the Wordpress/Drupal/Joomla thing, Python was at the front of the curve in ~2003 with Zope and Plone. Both lost significant popularity over time. I don't know why, except that even as a Python enthusiast, I found it hard to find a place where I could run Zope and Plone, because of the execution model.
Well, it is...and sometimes it isn't. If your code only uses a couple different modules or less, and those modules don't have functions that have the same names, you're probably fine. Usually, people are only using a few features/functions from a module when they need it, so it's preferred to do it this way to avoid problems: from pandas import DataFrame, Series Import pandas as pd This will get rid of a lot of the ambiguity. 
You seem more focused on buzzwords than getting things done. Honestly as /u/ivosaurus said, nearly all frameworks today provide most of this. Personnaly I like web2py since it does more things all in one package. http://web2py.com/. Also supporting CGI is not the right thing. At all. Ever. As in never think that it is a good idea again. Python has its own way already to speak with a webserver using the WSGI protocol/spec. There are many servers that speak it, including ones that bolt on to nginx (uwsgi) or apache (mod_wsgi). That being said many of the popular python frameworks at one point supported or tinkered with CGI support but it is typically unmaintained and not reccomeneded. 
For scipy it was in the repositories as `python-scipy` and `python3-scipy`.
&gt; Well, it is [a bad idea]...and sometimes it isn't. Strongly disagree. Star imports should be avoided in every situation, since it makes it more difficult to figure out where the names come from.
log.bind doesn’t know the names of the variables unfortunately. but if you have some case repeatedly, you can sub-class BoundLogger and add custom methods like `bind_request_args(self, user, some_param, some_other_param)`. https://structlog.readthedocs.org/en/0.1.0/examples.html#custom-wrapper-classes demonstrates how that works.
I agree with you. I was just trying to get across that in the most simple of scripts you probably won't run into any issues if you use them. But, YES, avoid them. It's bad practice, and even if you're the only one who will ever see the code, make it easy on yourself and be clear where everything is coming from. 
Thanks for the tips. I find it easier to maintain code if I use the full module names; that's a paradigm I picked up after returning to too many programs after months or years of delay and having to track down all the links. I know there's preferences, and many people don't bother with common modules (like math or os) but I don't see myself saving that much time in typing shorter names. Same reason I use very descriptive variable names, just easier for me in the long run :)
Just a pithy remark about the link not going anywhere. Nice library.
Fair enough. I like to do the same unless it's something very simple and clear. 
As someone who's programmed before, but just tried making a webpage in Python 5 days ago, I'd like to offer a perspective: doing a "Hello world" webpage in Python is a nightmare. I'm new to Python and don't want to commit to learning a framework (yet). Just wanted to put a web version of a simple script I wrote and it took me hours (and my implementation still sucks). I think the lack of an obvious first step in Web programming is a barrier to entry. 
Good job on the docs. It looks like you've put a lot of effort into them. Will check this out.
Thx.
Hi all, I'm one of the developers behind DataNitro. Thanks to everyone who checked out the link! As a lot of you have noted, our software has a non-trivial price point. This lets us support the software, and our hope is that you save more than enough time with DataNitro to justify the cost. To make things a little better, we're offering 20% off for redditors for the next week - you can [get it here](https://datanitro.com/pro/purchase?coupon=1) with the code "redditlove". If you end up trying it and decide it's not worth the money, we're happy to give you a refund - no questions asked. We also have a free version for students. Send me a PM if you want to try that!
* Fixed
What's funny is that you're right, but most languages default to dumping entire modules into your namespace when you import them. 
Thank you. There are two links in the docs that I find fascinating, and helped me make this little tool: +1 for structured logging: http://gregoryszorc.com/blog/2012/12/06/thoughts-on-logging---part-1---structured-logging/ -1 for structured logging: http://carolina.mff.cuni.cz/~trmac/blog/2011/structured-logging/
As other have commented many modern frameworks support what you have suggested. I can speak for web2py. web2py is a little ahead of you ;-) - three distribution (windows, mac, source) each packages everything - includes a web based IDE and management interface - one instance can support multiple projects each with its own auth, databases, session, etc. (only framework to allow this) - supports python 2.5,2.6,2.7 and Pypy - it comes with a an ODBC driver for MySQL support but our experience is that MySQL is not the best to start with. It does not support more than one alter table for transaction, the text fields have size limits, it does not provide geographic APIs. PostgreSQL is much better in this respect and closed to the SQL standard. - It is super-easy to install anywhere. Some hosts make it easier than others. pythonanywhere.com has a one click deployment and it is free. - Ships with Twitter Bootstrap so it easy to theme apps. - We support internationalization at the app level (different apps under the same web2py instance/process can have different translations). We also provide a web based interface for translators and a the only multi-language pluralization engine for Python (understands languages with multiple plural forms). - we host it on GitHub and GoogleCode. We use TravisCI. - Uses the LGPL license. It was chosen by InfoWord as best Python Web Framework (2010), Bossie Award (2011) and Technology of the Year (2013).
Or py-scipy but who says he isn't using windows?
Python is my glue between separate codes that have been proven/optimized for performance.
That's the difference between `include` and `import`.
This looks awesome. Have an upvote! :)
quantopian is a really cool idea. and it's awesome to see python getting applied to serious stuff, other than scraping cat pics from imgur and then writing a django site to host them. more of this please. 
It's hard to say "most". Most statically typed languages without first-class functions and classes do this, and it's because the semantics of the language allow construction of robust IDEs and dev tools. With Python, not only does dynamic typing make it a LOT harder to track things down, but the fact that you can easily manipulate functions and classes makes it much easier to get spaghetti code if you didn't have clean namespace separation.
ever try to do a web page in java? 
&gt; I was looking for an easy module to add in to my installation, but no... the "recommended" process was to download one of the big kits (basically reinstall another instance of Python). It's easy for you to think of your use case as an "easy" one, but there are good reasons for those distributions to exist. If you ever want to share your code with anyone else, or you want to run it on a different box than what you're developing on (maybe e.g. deploy to a linux box in the cloud or on a cluster), or use a code snippet from someone else who's on a different platform, you'll quickly discover what a complete headache it is. Much of the pain does not stem from scipy itself as such, but rather the legacy of C and FORTRAN libraries across OSes and throughout the ages. We're all rather spoiled in the Python ecosystem because we're used to writing scripts, importing modules, and then just having them work. But there is a staggering amount of complexity that goes into properly linking FORTRAN libraries across compilers and all the myriad build-time options for underlying libraries that scipy depends on. (Disclaimer: my company makes the Anaconda python distribution)
I honestly forgot about Windows. Everyone in the lab who wants to program in python installs Linux, and I have been using Linux for the past few years. How well does python work with Windows? 
Cool stuff. I'm disheartened by all the nay-sayers that decry the cost. Good software takes time to build and support. If you're a heavy Excel user, you wouldn't be shocked to pay money for good plugins for reporting, analytics, etc. I, for one, am happy to see more people shipping software product around Python - it puts more money into the ecosystem and helps keep more Python developers coding Python as their "day job".
I'll got out on a limb and recommend learning how to do CGI scripts first, then look at frameworks like [bottlepy](http://bottlepy.org/docs/dev/). Not until you do CGI scripting first will you appreciate frameworks and you will also get a better understanding of HTTP protocol.
Is there anything more that this offers, besides access to the excel table and inserting objects via IPython?
I still fail to see how the GIL is a relevant problem in most cases.
Can you name a few that do? Looking at all the major competitors of python, this is not the default. Perl has an option to, but best practices suggest it only be used for truly general core libraries where you want everything available.
What about it?
&gt; Then they should not exist in the language. You're right! They shouldn't!
&gt;I still fail to see how the GIL is a relevant problem in most cases. I would imagine quantitative finance would likely be a relvant case since all things being equal, the faster algrithm would mean more $$, so parallelizing to saturate the cores would probably be a good strategy to start with. this is why i'm surprised no one has mentioned yet, because all other times it's mentioned here, it's not relevant for most cases as you said. Yet, HERE is a case. 
I run NoScript and Ghostery, why is a "Wista" video linked here? Wait a minute, this guy writes trading code and he does not know the difference between a [steep and shallow learning curve](http://en.wikipedia.org/wiki/Learning_curve)? Yeah, nice...
i'm guessing people that are commenting didnt read or comprehend the article. to me it was fairly obvious. but then I read it, watched the video and clicked on the link for quantopian and got an idea of what their business is and how python fits into their overall value proposition. edit: grammar
&gt; too bad though it's pretty awesome Yeah, its not. See my edit above...
You don't think Django is enterprise ready? You couldn't be more wrong. Instagram, Mozilla, Disqus and many other Django sites/projects prove you wrong.
Thanks, I'll check it out! 
I think this is a semantic difference. I think, as it stands, Django has issues that make it not a strict match for enterprise. An enterprise can make anything work (A coworker of mine used to work on an enterprise Sinatra app with guttest routing components). The fact is, Django has for years had conflicting standards on how View objects should be built. You can ignore all those standards and make your own standard, but that's something that really should get cleaned up. For a ORW language, it's more TIMTOWTDI than perl.
Then why do they? Like I said: &gt; History has shown that the "undesirable" features that can't get themselves deprecated probably do have a purpose And I even gave you an example ;)
For system administration or data etl in windows I'll say python does more than well against the usual competitor (php, ruby, perl). Its definitely better than windows/dos batch file. I don't know if we can compare it with autoit or ahk. I still prefer python but autoit smaller size and single exe packaging imo better than python. I don't use powershell so no comment here. 
You are right about what you say Massimo - maybe I was not clear enough (see edit). I was not talking about frameworks, but about end user applications: a wiki, a blog engine. We've got the best web frameworks out there thanks to projects like web2py and we all know it, but what about the dozens of people migrating from MoinMoin to MediaWiki (see Google)? What if the user cannot use "pip" in its cheap and shitty web framework - how the hell should he/she install a blogging engine like Mezzanine? (See: Django isn't designed to run under CGI https://code.djangoproject.com/ticket/2407#comment:21).
Or instead advocate for hosts whose audience isn't 99% PHP, like heroku, openshift and appfog. Analogously: if you want to support the advancement of on-demand entertainment, do you keep on buying services from encumbant cable companies, or do you support new services like netflix?
Maybe we should pay more attention to the kind of feedback /u/Cold_Frisson provides. Edit: A nightmare compared to what? What did you try? Just for curiosity.
Damn, Heroku is not as easy as it seems. The first time its ephemeral filesystem bites you it's a nasty experience and you don't understand a thing. Last time I tried I had so many problems that someone brought the thing to Amazon AWS. No, I don't think Heroku is for the casual user.
If you are talking about the change from function based views to class based views then that's not a standards problem at all, it's progress. You can still write your function based views like you always did, nothing much changed. Now you can also use classes though, and we Python developers, we love classes. Django is by my opinion a very good match for enterprise, as the philosophy is to be boring, not like Rails, or Node and all those other hip buzzwords. Django is boring, which is a good thing! There are standards and Python helps with best practices being used. You may not have gotten into the Django/Python philosophy enough to see its usefulness and its uses. There is also not more than one way to do it, with the ORM. Either you use the ORM to the best of its usefulness, or you write raw SQL like you would with any other ORM, language and web framework. 
There are plenty of examples of badness in python. Pickle, the toy server implementations, asyncore, etc. While these things are bad, they're still included in the name of backwards compatibility. `import *` only has one reasonable use in my opinion: when messing around in the interactive interpreter, star imports can save some typing. They should not be used in actual code.
Regardless of IDE, it's hard to follow if you don't have clean namespace separation. I much prefer being able to tell at a glance where functions come from.
See, my employer chose Rails over Django because its style and best practices have already stabilized. They also looked at the function-&gt;class based views thing as something "not quite safe". So now we're becoming a Java and Rails shop. &gt; Django is boring, which is a good thing! Can't disagree more. Free admin pages? Hip non-standard approach to MVC? I actually thought it had a TON of fresh ideas. Once I feel its more finalized, I might give it another shot for a personal project. &gt; You may not have gotten into the Django/Python philosophy enough to see its usefulness and its uses. I'm a huge fan of python for a lot of stuff. It has a lot of neat features. But my disagreement with you about the core of Django is why I disagree with you about its corporate-fit. I just don't see it as particularly boring, entrenched, or predictable. Heck, in some ways it makes Rails look like Spring. &gt; There is also not more than one way to do it, with the ORM. Tell that to peewee? But then, I didn't bring the ORM into this. ORW = "One RIght Way", one way to explain the supposed Python philosophy. For someone who has spent years in both Perl and Python, I can really tell which languages, libraries, etc adhere to which. Often, perl libraries are TIMTOWTDI, and python libraries are ORW... but that's not set in stone. I feel Django is more of the former. It always seems to me as a hip new angle on MVC (or MVT) with as much unopinionated design as perl-Catalyst. Like I said, when it completely stabilized, I'll work in it again, but if asked by management again, I will still repeat that it's a non-standard technology with non-entrenched philosophies. For a company embracing conservative, Django is not a good fit to me. 
Promoting technologies like `MySQL` by setting it as the default is the wrogest of the wrong ways to go. Support it, sure, but make it the default? Absolutely not. Python developers use Python because it's a good, useful, and predictable tool -- essentially the opposite of MySQL.
Are you saying global imports have only one reasonable use in python, or at all? Python isn't exactly pure OO, so if the former, why the distinction? If the latter, then much of the programming world wants you to argue that. Oh I've heard the claim a lot, but it just doesn't seem like a problem to me. Don't get me wrong, I prefer namespaced imports any day (import foo), but sometimes in programming, you have utility functions that you want to think of as extending the base language. You have scope-defined and documented what those utility functions are, and they are finite. The main argument to control imports is usually to prevent scope bleed... if you have a class with a very controlled export signature, with utility being the primary purpose, I just don't see a problem. Perhaps that's my perl state of mind (some classes use defined exports, while others give you everything by default). When I "use Data::Dumper", I want the top-level dump() command (and there's alternatives if I want a configured dumper instead). I think the ugly verbosity of python's pprint library explains my distaste fairly well. Data::Dumper can do everything pprint can, but it has great defaults that place themselves as clean callable functions. It is generally not considered astonishing when you know what's goign to be there.
&gt; parallelizing to saturate the cores is entirely possible even with GIL. sure it'd be less of a hastle without, but it's hardly a requirement.
Google's protocol buffers were invented for exactly this purpose. I use them myself for that (and a host of other things) with great success.
Your all over the place. what about the gil, dude, just say it 
I unfortunately don't have any ideas, but I'm wondering: How do you make the program to autorun?
You don't have to commit to learn a microframework to use one, most of them are pretty simple. CherryPy has no external dependencies and can give you a hello world in six lines: import cherrypy class HelloWorld(object): def index(self): return "Hello World!" index.exposed = True cherrypy.quickstart(HelloWorld()) Bottle is similarly simple, Flask as well.
You want to execute a python script? Are the targets Windows boxes? If so, you may some problems getting the script to run without an interpreter.
aim a bit more to the left and try again.
Wow, that's pretty ballsy for someone who still has grammar and punctuation problems all over the parent comment, even after editing for grammar.
I'm willing to bet that there is as much django in the current versions of instagram and disqus as there is ruby on rails in the current version of twitter. 
"Awful" may be too strong a word for this trivial example. For my eyes it is awful. Generally any kind of structure added to text in order to aid machine parsing is going to make the text harder to read. How much readability is decreased depends on the format. How much this is "awful" depends on your eyes.
Sounds good, we love pull requests. :D
I'm in agreement with juanlu001. The argument is not about what framework could support these things... in fact, the argument isn't about an application framework at all - it's about building an application. So the discussion about existing frameworks is useful only in the sense that we use application frameworks to build actual applications. The first second subpoint (A.2?) regarding MySQL... I think out of the box support for MySQL is essential but should not be the default. Some people build ridiculously small websites - 5 pagers for a business for example. These folks probably don't need the overhead from MySQL. Default could be the built in Sqlite and have a UI that asks the installing user some questions to gauge their needs... i.e. How big do you plan on making this site, how much traffic will you support, etc. If they meet the requirements, then walk them through setting up a database. If not, we could easily beat Wordpress' five minute install :P Agree with the other points 100%, but would tender some additions. 1. Should have a plugin/module/package manager unique to the application, and an API for tying plugins in. This has been some of the huge success behind Drupal and Wordpress. We need a Python package manager for the web. 2. Some kind of theming standard, as alluded to. Most Python templates do a decent job at separating presentation from business logic, but in this case I would almost make the argument that even a template is business logic. The application is built (from the perspective of the installer) but now they want to change the colors. Having them mess with core templates to do so is a hazard. 2.a. This should be mobile friendly out of the box and load at a reasonable speed.
wow, yeah and totally matters. 
I would like to volunteer to help btw. Not sure what others are willing to invest in this... but I think it's needed.
Write your wiki web app on web2py and you have all the features you need. Go out and distribute it, call it web2wiki or whatever and just run with it. If you are going to write your own framework or webapp, then do it. I don't get what you are promoting here. You want to code your app like it's 2005, be my guest.
People: we have the best language (I don't need to read again that PHP, Java and JS suck), we have the best frameworks (I don't need to read again how wonderful Flask and web2py are), we have the best protocols (I don't need to read again that WSGI is the best solution). **Can we, as a community, apply some self-criticism to diagnose why we haven't won?** www.youtube.com/watch?v=UKAkKXFMQP8&amp;t=9m57s &gt; I mean, have we really won though? *Added*: Python is 0.2 % http://w3techs.com/technologies/overview/programming_language/all
Imagine you have a class full of students who're using Python, and you want them to install matplotlib for the next lesson. What do you tell them to do? - System package managers will call it different things, need different commands, and in any case many students won't have one. - pip will try to compile everything from source, which is slow, and requires everyone to already have a C compiler and relevant header files installed. Some things require a fortran compiler as well. - New versions of pip will install wheels, the amazing new *cross-platform* solution for binary packages... but no, wait, pip (and PyPI) will only use wheels on Windows ([docs](http://www.pip-installer.org/en/latest/cookbook.html#building-and-installing-wheels)). Anyway, matplotlib doesn't provide wheels yet. - `easy_install` will use the old egg binary files if they're there, but it does various horrible things like adding entries to sys.path. In the end, the best way to get this environment set up is to use one of the Python distros like Anaconda or Canopy. But you can't add those to your existing Python set up, they come with their own Python, which isn't ideal either.
Most recently PHP, but I've used Perl and (a little) Java before. Getting started in PHP Web programming is incredibly easy. Like other languages, you benefit greatly from frameworks, but that start point is easy. Personally, most of the stuff I do at work is some forms and some minimal CRUD for managing integration and a couple of Web Services. So I think the micro-frameworks people mentioned looked great. 
 from multiprocessing import Process
+1 for showing ~~appfog~~openshift, never heard of it before! You have your point, but if one guy is supporting netflix and a hundred thousand are buying cable services maybe we should work a bit harder to convince those that our way is better. *Edit*: I meant openshift.
That's a (windows) batch script
Check out [SET] (https://github.com/trustedsec/social-engineer-toolkit) (the social engineering toolkit by TrustedSec). It does what you are looking for, and a whole lot more. 
I agree. I also do not understand why pip/easy_install is not distributed with Python. It is a major roadblock.
I've been professionally developing in Python for about 7 or so years now in the Game Dev industry. In all this time I have literally not found a single thing I cannot do in python. If I find something I want to do is not feasible due to python's speed or processing constraints, I'll just move the code to C and access the DLL functions using ctypes. Simply, I choose Python because I have not found another single language that can every single one of my needs like Python can.
~~Well... if pip is a major roadblock, we have a deep problem here. Maybe the scientific Python community will save us?~~ http://www.continuum.io/blog/conda By the way, they are a bit more pragmatic than what I see here (no offence). *Edit*: Sorry, I misread your comment.
&gt;See, my employer chose Rails over Django because its style and best practices have already stabilized. There's more to being ready for the enterprise than style. I would say that the fact that hosting a Rails app is so fucking hard knocks it a few points lower than Django, that has style problems. I can't find the article in a quick search but I was reading recently about how there are huge corporate rails projects, that work fine, except for the fact that Rails processes need to be restarted several times a day, because of unknown reasons. You're telling me that's enterprise ready?
&gt;Strongly disagree. Star imports should be avoided in every situation, since it makes it more difficult to figure out where the names come from. So the one situation where it might not be "should be avoided" is when you only use one star import, because then it's still pretty obvious where the names come from.
I'm less concerned with Python "winning" than I am with having awesome tools to do awesome things. Python web frameworks were designed to serve a purpose and they do for thousands of developers. Explain to us why we should care that some people can't/won't learn them? Are we trying to win a popularity contest or are we trying to develop great software? Sure PHP, etc. have a lower barrier to entry but that's part of the problem - there are prerequisite mental frameworks that you *must* adopt in order to build a successful web application. Python frameworks largely enforce these best practices which is why it pays to learn them as opposed to just jumping and and hacking together some spaghetti code.
For people who don't need Excel on a day by day basis, sure, this is a pretty big cost. If all you are doing is keeping track of your video game collection, or some other remedial task, you don't need Python inside Excel. You don't even need Excel, frankly. For people who do work in ArcGIS for example (which uses python for its internal scripting) $500 is chump change to be able to use a language they are already a little familiar with to manipulate large amounts of data in a tool that can do most tasks, but not all tasks. Specifically considering most such people aren't actually programmers to begin with, hence why they use tools like Excel and sometimes wish Excel was ultra-powerful. A lot of other things use Python as their embedded language, and often non-programmers are the ones interfacing with those programs and have large datasets they need to manipulate. Chances are if you need something like Python inside Excel, you or your company is dealing with numbers and datasets that would mean that the money you are getting for the contracts make such an investment trivial. (Of course, this does depend a little on how they handle bulk purchases of licenses, server installs and stuff like that.)
So use one of the Python distributions that are targetted at such users. I'd love to see some silver bullet solution that is all things to all people, but I'm pretty sure that will never happen. It's not like there's no desire for it, it's that there are conflicting requirements.
Docker might be relevant : https://github.com/dotcloud/docker
Normally a doubly linked list with a moving "cursor" (which I think is what you're doing) is better emulated with two lists. If you need to also access from both ends (as well as the "cursor"), use two deques. 100% guarantee that it'll be faster. 
Python has been used in serious projects for years. See Youtube, Spotify, Reddit, Instagram, Disqus, Mozilla, NASA, Eve, The Onion and many more. Just look up presentations of people working for these companies at Pycon and/or Djangocon at YouTube or pyvideo.org for more information.
This. As a mechanical engineer I find uses for python all the time. Because it's my go to I occasionally get myself into situations where Python isn't fast enough, but a quick C extension or wrapping of a vendor's .dll has, thus far, enabled me to get what I need faster than any of my colleagues are able to get it.
i know that, but the front page of this subreddit is often filled with links to github repos of scripts to scrape cat pics zzzzzzzzzzzzzzz. so, I would prefer to see kinds of things like this. 
There is not any good python forum software out there. At least, a few months ago when I looked I couldn't find any forum software that was still being maintained and had any reasonable set of features. There are some Django apps that tried, but none were appealing and I wanted to stay away from the lock-in of entering Django world for my project. There is almost certainly nothing approaching the complexity of Slash. Although if you do find something, please share it, this comes up quite often.
The reason for `import *` is to *wrap* a library. It means you don't have to keep up-to-date with new functions added to the library but can still provide extensions to parts of it. It'd be cruel to harm people using `import *` properly just to stop the fools who insist on using it when they shouldn't.
&gt;If I find something I want to do is not feasible due to python's speed or processing constraints, I'll just move the code to C and access the DLL functions using ctypes. CYTHON! It's worth learning, á mon avis.
&gt;If we have a CPU intensive task someone just writes a module in C. If they don't know of it, suggest they look at Cython. It's a really nice language hybrid, in my opinion.
Yes, we do now mostly recommend Anaconda for scientific Python. But many users want to add these packages to their existing Python installation, not set up a whole new Python. In a workshop just today, I helped a student who was confused because she had installed pandas in her Anaconda Python and couldn't import it in her system Python interpreter (this was on a Mac).
I'd much rather be able to do a simple text search and find the import statement. 
"from foo import bar" is fine, since it's still explicitly stating where "bar" comes from.
Fair enough.
What is difficult about hosting Rails apps? I've been doing rails for 5+ years and I've never had difficulty keeping my apps running. Have you ever used Passenger?
How about our beloved https://github.com/reddit ?
Like another said. What's hard about hosting a rails app? Capistrano is one of the better deployment systems out there, and (surprise surprise) it comes with rails-compatible commands out of the box. Between that and bundle, you can zero-effort deploy rails. Compare that to J2EE and you're in different worlds. &gt; I can't find the article in a quick search but I was reading recently about how there are huge corporate rails projects, that work fine, except for the fact that Rails processes need to be restarted several times a day, because of unknown reasons. You're telling me that's enterprise ready? That's been the case in a lot of languages. Probably pervasive memory leaks (possible/likely in any language that isn't designed to prevent it... Python isn't designed to prevent it). Our rails projects don't have those problems.
I dunno, man, recognizing cat pictures without using any extra metadata is some serious computing right there. 
exes don't just execute in jpegs without vulnerabilities.
Probably not. That's the point of it. So it's secure.
Have you ever actually tried distributing a python application? pyinstaller, py2app, py2exe, those are the only real options; they're ok, but they generate massive (100+ of MB) applications that work... mostly. See the recent thread on hacker news about calibre and it's astonishing binary size. For example, py2app won't correctly bind some dll's and set the rpath for them, meaning your application won't run, and py2exe is similarly bad at it. Pyinstaller is great, but it's new, and it doesn't always work. The documentation available is for a verison of pyinstaller that doesn't exist. Often even using these, you still have to install system libraries somehow. They, broadly speaking, don't work with python 3. Did you watch the talk? You think perhaps the people from ludum dare have something against python, and thus recommend not using python for a gamejam? They're just being pragmatic. It's because distributing python applications (not libraries; libraries basically work, but that requires you to have python *already installed*) is hard, and broken. Seriously, watch the talk. :P
I agree in general, but there's a few situations where it's useful. I'd argue that `import *` is acceptable if a) there's only one of them (so there's no ambiguity between two `import *`s), and b) the file is less than 30 lines or so (so it's easy to figure out whether a name comes from an import or is defined within the file). For instance, in a Django app, I almost always have `from .views import *` in Django `urls.py`, and `from .models import *` in `admin.py`, because both those files are usually very short and almost wholly concerned with doing things with those other modules. Other than that, I avoid it like the plague.
Yeah, I'd argue the use of Mock objects is a significant code smell, and should only be used for systems being treated as untouchable (e.g. devices, third-party systems, or areas specifically designated as prohibitively expensive to change for the moment). I'd add that if you're mocking, you should also have functional tests that check your Mock's behavior against the real behavior of the mocked system. I'd also add that slow tests are still useful, especially at the functional and integration level. In a perfect world you'd have two suites of tests, fast ones to run before every commit, and slow runs to run on the CI server.
That would be more concise, and this was essentially exactly what I was looking for, but [the only reference](http://www.python.org/dev/peps/pep-0372/) I can find says that delete for OrderedDict is O(n) and entire traversal is O(n log n) . How exactly is it implemented? 
Okay. This post and its author need to be removed.
That reference is for an old version. echo "Overhead" python -m timeit -n 1000 -s "n = 500000" "n += 1" SETUP1=" from collections import OrderedDict items = OrderedDict.fromkeys(range(10000)) n = 5000 " echo "OrderedDict deletion, length 10000" python -m timeit -n 1000 -s "$SETUP1" "del items[n]; n += 1" SETUP2=" from collections import OrderedDict items = OrderedDict.fromkeys(range(100000)) n = 50000 " echo "OrderedDict deletion, length 100000" python -m timeit -n 1000 -s "$SETUP2" "del items[n]; n += 1" SETUP3=" from collections import OrderedDict items = list(range(10000)) n = 5000 " echo "list deletion, length 10000" python -m timeit -n 1000 -s "$SETUP3" "del items[n]; n += 1" SETUP4=" from collections import OrderedDict items = list(range(100000)) n = 50000 " echo "list deletion, length 100000" python -m timeit -n 1000 -s "$SETUP4" "del items[n]; n += 1" Output: Overhead 1000 loops, best of 3: 0.14 usec per loop OrderedDict deletion, length 10000 1000 loops, best of 3: 3.49 usec per loop OrderedDict deletion, length 100000 1000 loops, best of 3: 3.47 usec per loop list deletion, length 10000 1000 loops, best of 3: 3.42 usec per loop list deletion, length 100000 1000 loops, best of 3: 60.9 usec per loop These results basically show that `del` is `O(1)` for OrderedDict and ~`O(n)` for list (sanity check). So just go with OrderedDict :).
Well I also find script sharing numbers to be restrictive as well. Sell at lower price for individual (way lower) and unlimited for enterprise site licence if seats under 1000.
Brew and VirtualEnvWrapper made using different Python runtimes a breeze.
&gt; Star imports should be avoided in ***every*** situation If you say so. But I'll continue using `from math import *` in the Python interpreter for simpler access to members of the `math` module.
If you don't mind kludge and working around the GIL, then it's almost never a problem. If you think kludge and ugly work arounds (like the `multiprocessing` module) aren't problems, then we have a disagreement.
I have used both Cython and CFFI, and I strongly prefer CFFI. With CFFI, you just load a plain C library at runtime, no compilation required. The C library needs to know nothing about Python. On the Python side, there is only very minimal interface code required--much less than in Cython, usually. And it's fast, too.
For someone who is pining for higher quality submissions, your comments are fairly startling. A brief look at your comments in this thread suggests you aren't doing your part. Or worse, *lowering* the quality of content here. &gt; wow, yeah and totally matters. &gt; /done &gt; TIL: lol &gt; it's exclusive content that is not for you. too bad though it's pretty awesome &gt; i'm guessing people that are commenting didnt read or comprehend the article. to me it was fairly obvious. but then I read it, watched the video and clicked on the link for quantopian and got an idea of what their business is and how python fits into their overall value proposition.
I was talking about writing modules, not wrapping them. EDIT: Also, I've not tried any of these but [are these relevant](http://wiki.cython.org/AutoPxd)?
Seems really cool, but even with the discount, not the kind of thing that you would buy, unless you had a good reason to. (Unless you're a student) Good work though.
Why not link to the fucking video instead of this shitty blogspam?
Still, I usually prefer to write plain C and wrapping it in CFFI to writing Cython. I find that writing a simple C function for some numerical algorithm is usually very easy. Compiling it is very easy, too, since it is only plain C. Cython can be a pain to compile. But I guess that very much depends on your application.
&gt;Compiling it is very easy, too, since it is only plain C. Cython can be a pain to compile. I've never actually worked on *distributing* Cython, but if you're using it locally it's literally just a import pyximport pyximport.install() in the importing Python file. How much easier can you get? EDIT: Oh, and memoryviews. QED.
This is rather off-topic, but I've found Splunk to be a great collecting, aggregating, parsing, and processing tool for both structured and unstructured logging. It has a really fantastic Python API, too. It can handle any kind of log, in any format, in any file system on any machine, local or remote. So even if you're already dealing with unstructured logs, it's not that hard to deal with them in a structured way after post-processing.
Star imports are never a good idea. Always reference what you are importing explicitly, that way other people know where they came from.
I guess your problem is with things like: &gt; import pprint &gt; pprint.pprint("print statement") If the calling verbosity bothers you, I would just do: &gt; from pprint import pprint &gt; pprint("print statement") In my last job we maintained a few hundred thousand lines of Python code, and there was no case where we used star imports. It just makes things too hard to track down, especially when you are looking at the code in vim with no plugins on a headless server.
But you don't need to use remove do you ? You only need pop/popleft right?
It's fine to say "I like Rails more" or "I like PHP more." It's not fine to say "it's not enterprise ready." Also, conflicting standards have never been an issue for me. Django has great backwards compatibility, coding style standards, etc... Read 2 Scoops of Django. Upgrading from 1.4 to 1.5 was a piece of cake and I'm constantly in the loop on changes being merged into 1.6
View functions are still the standard. Not going anywhere ever. I don't understand that there are any conflicts to get cleaned up. There are like three variations in total on how to define a view function for three very distinct use cases. View functions as standard, generic views for customizable views, app class methods for app level customization. Complexity is opt-in.
there's some good discussion in the comments of the article, particularly a post by Gary Berhnardt in which he says that test speed and test isolation are two different goals. Mocks aren't just useful for mocking out 3rd party dependencies, they're also useful for ensuring isolation. Gary argues that, if you change one thing in your code, it shouldn't break hundreds of tests, so therefore you should use mocks. I tend to say, don't use mocks for that, I don't mind hundreds of tests breaking, because each on indicates a broken piece of code... http://www.obeythetestinggoat.com/fast-tests-useless-hot-lava-be-damned.html#comment-1042970785
It is hard to do anything in the command prompt in windows. Hell, you can't even easily resize a console window in windows.
I'm not sure I'm understanding your question. Wistia is a local company that we use as a platform for all videos across our site (and subsequently, on the blog). Edit: typo
Without looking too far into it you're probably better off to use the named parameter syntax instead of making assumptions about the parameter order. request = urllib2.Request (url, headers={'Authorization' : 'Client-ID __myclientid__'}) Also, after writing a couple of API integrations I strongly recommend using the [Requests library](http://docs.python-requests.org/en/latest/). 
Clearly, stdlib logging is the ultimate logging solution for the next thousand years. All hail! So tired of this.
Seconded. Moving from urllib2 to Requests was one of the happiest moments in my Python existence.
Thanks guys, I'll go and give it a try.
I wrote a tutorial for this http://blog.tankorsmash.com/?p=551, but I use an alternate authorization, so it may not be helpful to you.
Awesome. I rewrote it to requests and it works fine now :)
It totally does. A book you might find interesting is Real World Instrumentation with Python. http://shop.oreilly.com/product/9780596809577.do It talks about communication protocols you typically find with instrumentation, how to access them with python, and how to wrap vendor's libraries into a python program so that you can build a data acqusition system out of pure python. Combine this with Python's vision functionality (through opencv), and scientific packages (through scipy) and you can create a DAQ system that is in many ways better than something you could build from labview. And you learn a ton on the way. Where are you a student if you don't mind me asking?
web2py is the best!!! +100000!!!
So I'm clear, this person sounds like they have a dangerously low understanding of programming, and your response is "We need to delete this post"? Why aren't you explaining to the OP why all of this is a bad idea, and why they shouldn't be trying to do this? Or are the only people worth helping in /r/learnpython the people who already know what they're doing so they don't ask stupid questions?
They do not show you the source code and do not tell you how they do it. 
You should have a version number too, in your user agent. Then reddit can ban specific versions if they get a bug, rather then all of them. 
I use brew predominantly as my only package manager and it has served me well. I really hate pulling installs together manually. If I do, I pull from source and create a Brew recipe for it.
Aye, I'd agree that gets us nowhere! There's definitely beautiful things in every language/library, no doubt about it.
On the contrary. I don't know how you are able to draw such a conclusion. I do web Dev as well as sys admin fallout. This is bc I was an admin before switching to Dev. 
That's mostly useful for end-user software or other code that's widely distributed. In such a case, if you were Reddit, you'd want to contact whoever is writing the app and tell them to fix whatever is broken, blocking old versions so that random people out there don't pound your server. If it's all coming from one user, then the more logical way would be to contact whoever is running it and get them to fix it, and then unban them when the program is no longer broken. There are no random, unwitting people pounding your server, since it's just one bot. 
Did you get out of the wrong side of the bed this morning? ;-)
&gt;It's not exactly hurting you much either, is it? Nope. It's certainly not a disadvantage I'm just saying that in this case it also isn't providing any advantages. &gt;You also get tested and reviewed code that is more likely to work without any hiccups, with edge cases and such already taken into consideration. Eh, not really. This script doesn't take into consideration any errors praw might raise so it's either get data encounter an error and stop executing script. And since praw is using the same url I used in above code, it's not really doing much than opening url(with requests) and returning submission objects and if the API is broken both praw and requests will raise some error and stop the script. In a case where you're posting data, writing complicated bots then using praw is waaay better option than just pure requests.
No, but it's obvious what you're trying to do here, and it's not at all what you said. It's content that is inappropriate for this subreddit, and it's childish.
my experience has been if you provide them with an easy way to deploy and update, they'll thank you for it. So use buildout and virtualenv and other things like alembic/chef/puppet/fabric to automate as much as possible. And then document the rest and keep it up to date. To start, make a buildout for the project with the goal that any developer should be able to clone the repo and run as few commands as possible to have everything that they need running. Usually this would be... $ /usr/bin/python bootstrap.py $ ./bin/buildout After which, all dependencies should be installed along with any scripts that are needed. track dependency versions also (buildout supports this) if you get that working, that will likely be 80% of what would be needed for devops-ish role to write the bits where the production environment differs from what might be required for development. /.02 edit: spelling
I got the following errors when running the complete code http://pastebin.com/PH0mLggU
&gt; `x = False if a else c` Why won't you just write code which is easy to read? That will just confuse the hell out of everyone.
WSGI is the first step: def app(env, start_response): start_response('200 OK', [('Content-Type', 'text/plain')]) yield 'Hello, World!\n'
The problem you are having is likely caused by an untrusted SSL certificate. Just change this on line # 45 : r = requests.post(url, data = json.dumps(payload), headers = headers) to this: r = requests.post(url, data = json.dumps(payload), headers = headers, verify = False) Adding verify=False turns off ssl certificate checking. If you still get any error then feel free to post it here again.
`import antigravity`
Thanks! I believe you have fixed that problem, but now I am running into another one. http://pastebin.com/zv81Hapw
thanks * so how to kick off my script c:\temp\myHelloWorld.py ? (or HelloWorld() in the script) Also can you please do a favour and comment in test_app.py what directories are required ? (testing "cowsay" and got [error](http://paste.ubuntu.com/6107598/) ) * If running - c:\test_app.py, is there supposed to be 2 directories c:\updir and c:\images ? * uploaded test.jpg, the entry shows up on the "images" tab, but clicking on it (url = http://localhost:5000/images/test.jpg) returns Not Found 
You will have to first make that file manually in the directory where your python script is present. Make a txt file and name it "posted_posts.txt" I hope that it will solve your problem.
They ask you to use it. https://github.com/reddit/reddit/wiki/API
Oh, wow. Yeah, I could've figured that one out on my own. Sorry.
No problem. Asking for help does not hurt. :)
Ok, now that problem is solved. Now there's this. http://pastebin.com/pxC8ALAh
Fair enough, mate. I'm not trying to be insulting...you just seem to have a really shallow understanding of how computers work. But if you're trying to do something that falls outside of your general field of expertise, I suppose that's that's to be expected. Good luck with your project. 
As someone writes a lot of python and who recently had to work on a legacy LabVIEW system: OH MY GOD THIS
How is using the standard features of Python confusing for anyone?
It's not the feature itself that is confusing, it's the purpose of this particular statement that's confusing.
I assume that `x`, `a` and `c` are just [metasyntactic variables](https://en.wikipedia.org/wiki/Metasyntactic_variable) like `foo`, `bar`, `qux`, etc.
Is it clearer if I use more descriptive variables?: message = "Everything's fine" if not error else "Oops, something went wrong!"
Of course, but in general, I would definitely prefer: x = c if a: x = False I use the ternary operator myself, but only when the intent is clear, as in e.g.: x = a if a else b
I'll admit that that's much clearer. I was pretty confused by the use of `False` in the original statement, because the blog post initially discussed using the old `and`/`or` logic trickery. Fair enough!
I think we could discuss the best way all night :) Personally, I'd prefer to at least store the result of `False if a else c` in a variable, like: param = False if a else c foobar(param) But as you say, it all depends on the context!
indicates it's frozen into an executable of some sort iirc.
This makes a lot of sense to me. The need for virtualenv is clear -- to isolate the python environment that the application depends on from the rest of the system. I'm also assuming that I'll use something like alembic for managing DB schema migrations. I'm not sure that I totally get buildout. Is it simply a way of making sure that all of the right library versions are assembled together? I'm thinking that I might not use chef or puppet, given that I probably won't be in charge of managing the servers that this gets deployed on. My clients, presumably, would own the server configuration management piece, and might make their own different choices about how to deal with that. There wouldn't be much that I could provide that would be general enough to apply to the varied environments. One piece that I'm still unclear on is the deployment file. In the Java world, a web application is bundled as a WAR file -- a zip archive with config info that can be interpreted by the application server. To deploy you just put the WAR file where the app server expects to find it. Is there anything in Python that deals with how to to deploy an application into a WSGI environment? 
That's awesome. I used that comic in my talk our PyCon. If I'd have know about that, I would have just used "import antigravity" as my slide, instead of a frame from the comic. 
lol. how much have we spoken about networking and system admin tasks for you to determine that. I imagine youre a fairly judgmental person in afk. peace to you. lol
and here, we have the problem. Everyday assholes like yourself that push down projects, which in end kills learning and education. get out of this thread. you are scum to reddit and technology in general.
would you like me to copy and paste my project email from work? lol. judgemental reddit.
FWIW, Reddit has it's own short URLs From this post's JSON: http://www.reddit.com/r/Python/comments/1mdlq1/making_a_reddit_twitter_bot/.json [ { "data": { "before": null, "after": null, "children": [ { "data": { "distinguished": null, "num_reports": null, "num_comments": 18, "ups": 66, "link_flair_text": null, "created_utc": 1379170096, "score": 53, "media": null, "author": "yasoob_python", "stickied": false, "clicked": false, "secure_media_embed": {}, "id": "1mdlq1", "saved": false, "domain": "freepythontips.wordpress.com", You could create the short URL http://redd.it/1mdlq1 from 'id' and not need Google's URL shortener. Thanks for the tutorial though, love to see how others do it. 
Meaning that it's embedded in the exe instead of being in an actual file.
And the more I can reuse existing tools to do the automation, the less I have to build myself. Thanks for the clear writeup. I hadn't really thought about the possibility of including developer tools in a dev.cfg for easy replication of the development environment. That's a nice addition.
yeah, it took me a few goes at it before I "got" it. Each time I felt like my Python was getting better. (Some may argue the opposite). I read both ]Learn You Some a Haskell](http://learnyouahaskell.com/) and [Real World Haskell](http://book.realworldhaskell.org/) and still didn't have the intuition to manipulate the different fundamental type classes. Implementing some monads in Python helped a bit to understand why they are helpful The [Typeclassopedia](http://www.haskell.org/haskellwiki/Typeclassopedia) was the final push I needed to really get an intuition for it. Keep at it. I don't think it really takes any extra smarts to use Haskell as a general purpose language; you just need the tenacity to fight Note, Bob Ippolito ([@etrepum](http://www.twitter.com/etrepum)) (of simplejson fame) has a good [post on Haskell related stuff](http://bob.ippoli.to/archives/2013/01/11/getting-started-with-haskell/#recommended-reading)
&gt;I hadn't really thought about the possibility of including developer tools in a dev.cfg for easy replication of the development environment. Yeah, I feel that ideally, the faster a new team member/dev can go from clone to their first commit, the better off the project will be. devops/prod just happens to benefit from that repeatedability as well though it's not as obvious at first. That's where buildout helps a lot in my opinion. Good luck with the project!!!
It is rather confusing calling it Anaconda when that is the boot time installer on RHEL and CentOS systems. It is even more confusing because that Anaconda is also a type of installer. Anaconda packages are used during runtime as well to generate iso images on RHEL/CentOS systems so there is a chance both could clash names.
Wow. Thanks for just wow.
Nice to see another Stata/Python user (even if you're just starting out). I think all you really need is a C++ compiler to build the plugin, and you can even get visual studio express for free for a month long trial. I am not very familiar with building C though, and and am currently hung up around how to compile the plugin.
We are aware of the name collision. So far we have not had anyone report confusion about this issue to us. We wanted a good name for "Python for Big Data", and liked Anaconda. In any case, I figure the overlap of people who are intimately mucking with boot installers on RHEL and people who are running loess on Pandas dataframes is rather small. The chance of file name collision in a running system is virtually non-existent. Anaconda installs itself into a single directory of the user's specification, and doesn't touch anything in /usr, /etc, and whatnot.
Alright, as long as you guys know. I know I have it installed because of some dependencies. And I was mucking with creating iso files. "anaconda" the command is installed in /usr/sbin/ typically. If you call your command line something else it would work fine. But if it is called "anaconda" it will clash even if put in other directories in case user has set a PATH variable to their binaries/scripts. Then order in PATH will determine which one is picked if user types only "anaconda" on terminal.
The command line tool is `conda`.
Notice that we stated *obvious*.
Here you can find an example of how to register an app. Just follow it to correctly register and you will be good to go. http://www.makeuseof.com/tag/how-to-build-a-raspberry-pi-twitter-bot/
Is Qt font rendering fixed in 1.7? I was thinking of using Anaconda to teach a graduate course on scientific computing, but Anaconda's qtconsole looked so messy I couldn't use it. I was able go to fix it by simply pointing Anaconda to my system's Qt libraries, but that is not something I can easily do for a large number of students, and I really would like a consistent environment in class. 
I don't think programming is ever _obvious_ if you're not willing to read the fun documentation. 
My friend has been developing a standalone forum software in Python for some time. http://misago-project.org
Phew, thanks, just updated!
If you look at the source code for this.py, it's in an encoded form. this decodes it when this is imported.
Could someone tell me what is the advantage of using this rather than plain cpython with virtualenv and pip install please? I work on linux and osx.
But flask doesn't have a built in auth framework does it? 
Python 3 is more enthusiastic: &gt;&gt;&gt; import __hello__ Hello world!
I only speak for web2py. web2py always does and always did validate the length of the password in user login forms therefore we believe it is not vulnerable. Web2py also uses a different implementation of PBKDF2 which is faster than the one used by Django and Flask. Please ask the web2py mailing list for details. EDIT: I was wrong. we do not always validate the password length. I am not sure we have the vulnerability because we use a different PBKDF2 implementation (since 2.6.x). Anyway, I have just released 2.6.3 to address the issue. Sorry for the confusion. Sorry this does not belong on this thread.
Yeah I couln't bring myself to charge a clinet for this since it was a security patch. 
I could be tempted to get involved in this.
Why dont you post your idea and make this an open-source initiative? Sounds like more people are interested...
It seems to be a nice solution if you want to use Python an a machine where you don't have root permission and Python is not installed and/or an old version is installed. Also, it seems to be portable on a USB stick.
Flask does not have an authentication framework. Generally users are encouraged to use form validation systems to restrict length of passwords and choice of characters.
Putting it all together was really a convenience for non-python users that might not be faniliar with virtualenv or pip. Yes, I agree about the debug too, but I left it again for simplicity for non-developers. 
Twitter also auto shortens any url posted to it (but keeps the visible name long). 
Yes, of course it is. The easiest, cross-platform way to do this is sockets. Sockets also open you to true remote communication (i.e. processes not running on the same machine). I've written about adding socket communications to Python - http://eli.thegreenplace.net/2011/05/18/code-sample-socket-client-thread-in-python/ (also check "related posts" at the bottom).
This is why web2py is th best!!!
This defo doesn't need to be a pep, as far as code goes monkey patching int to behave differently after such a long time is a bit of an insane idea. Personally I would just have a class that defined this behaviour called SmartInt, then just use it like so a = SmartInt(4) print a(4)
Have a look at redis or zeromq. Both have multi-language bindings. I'm not aware of any good 'native python' cross platform solutions other than networking, which seems a heavy handed approach to take.
I would have to agree. Although it makes sense in a mathematical format (The use of brackets) it doesn't make sense to limit the int datatype's callable function to just be multiplication. Would this also impact on the memory usage of integers?
Direct process communication through TCP/UDP would certainly be lighter than everything involved with running redis or zeromq, right?
Take a look at inter-process communication protocols. Also read http://docs.python.org/2/library/signal.html#example .
The [subprocess](http://docs.python.org/2/library/subprocess.html) library has some tools for communicating with other processes over commandline and standard input/standard output. How does your motor controller communicate normally? What are your options?
Admittedly I'm not overly familiar with how OpenCV works but you may be able to "embed" OpenCV into Python using CTypes. Otherwise you would probably want to do named pipes or ZeroMQ.
Besides what jakevdp said, virtualenv only works as long as you have only python packages. As soon as you depend on compiled libraries, virtualenv alone fails quite quickly compared to full-blown solutions like Anaconda or EPD/Canopy. Try building a core scipy stack + everything for the ipython notebook on windows, and you will realize how much work that is.
How does one go about doing that, sounds like an interesting idea.
The speed of the implementation has nothing to do with it except make it take more data to exploit it.
don't know about redis, but zeromq is just a library not a message broker. so it's really just nicer sockets and a variety of recipes for various communication patterns. . 
One way to look at it would be the out-of-the-box packages included depending on your subscription status with the two distributions. http://docs.continuum.io/anaconda/pkgs.html https://www.enthought.com/products/canopy/package-index/
For a long time, EPD free was 32-bit only for Windows. That seems to have changed recently though. 
is your question how to run the script?
Oh, that's good to know. I'm only familiar with redis, which is its own process with config files and such to deal with.
You'd do fine. Once you try and have any specific problems you can post a link.
[That program mixes tabs and spaces =/](http://i.imgur.com/vO0lCzS.gif). Anyways, I think only your boss can tell you what's expected of you. I will say that this file looks like it's made to be a black box to the end-user though, so I don't think you're going to have a serious problem unless you were told to extend the capabilities of this tool. . . 
If you're smart, ask many good questions, and work hard I'm sure you can learn enough on the job. But what's your question?
yeah I had originally thought 0mq was like rabbitmq, to me what it really is, is a nicer way to do inter process communication then named pipes/sockets. and it's faster and lighter than http. So, to me, when the question "should I write a web service for this?" comes up in my head, now, I'll reply "or 0mq?" If you are at all interested in this kind of stuff. spend a weekend with the [guide](http://zguide.zeromq.org/page:all) it's a little mind bending at first but knowing what it can do and when to use it are handy weapons against scalability and complexity IMO. 
[Webfaction](http://www.webfaction.com?affiliate=delizseemack) is an awesome and cheap web hosting company for your python web applications. If you need help setting up your applications there, let me know. It will be my pleasure to help you out.
ok... I'll assume you have python installed (If you're on a mac or on linux it comes preinstalled) and downloaded the p2fa_(...).tgz package. This will work for a mac or linux machine: Let's say the downloaded package is in you Desktop folder. Extract the package (right click and choose "extract here" or something like that). Open the folder in your file browser and read/skim through the README file. You'll note that you need to install a third party library called HTK for the script to work (I didn't install it, because it requires registration and I just don't care for it) Open your terminal (press Ctrl-Alt-t on linux, no idea where it is on a mac, if you're on windows...start your prayers). type: `cd ~/Desktop/p2fa` Press &lt;enter&gt;. you are now in the p2fa folder. That's where the align.py file is a usage example is given in the README file. It says: python align.py ./test/BREY00538.wav ./test/BREY00538.txt ./test/BREY00538.TextGrid Type this line into the terminal and press enter. That's how you run the script. That's how you run any python script. It's always "move to directory where the script is and tell the python interpreter which script to run": python &lt;name_of_script.py&gt; [optional arguments] hope this helps. Let us know if it doesn't
The use of Python across finance and the sciences is amazing and completely off the radar of the tech blogosphere, for the most part. And also it's completely taken over Hollywood for both scripting 3D modeling apps as well as coordinating rendering pipelines. If Ruby was used in half as many ways as Python, you'd never hear the end of it. Python gets used by grown-ups with real jobs in all sorts of places and they don't spend 80% of their waking time tweeting about it.
EPD no longer really exists *as such*, it is now Canopy, which includes many of the features of EPD but also puts a graphical environment front and center.
Yes, the Qt font problem on Linux has been fixed in this release.
I feel like this person is more concerned about ideals rather than producing production code. I like the idea of keeping modules small but "A good rule of thumb is to only have one class definition per module" doesn't really work across the board and it's more difficult for larger projects. That in addition to a few other things to me don't make this a very good introduction for building great python packages: * There's a module being imported called 'exceptions', same as the built-in module in Python 2.x * It's much easier to debug when you're not importing everything at the top level, "import mypackage" should rarely break anything * The author linked to source code which is a mess in many places and has some pretty bad practices in others (ex. module level variables, re-throwing standard errors as custom errors [instead of subclassing and throwing]) * If you *must* import things in a certain order at the top level, you are generally doing something wrong. Exceptions to this rule can include thing like sqlalchemy's relationship.
True. Yet the Django/Flask implementation of PBKDF2 is in pure Python, while ours uses ctype+openssl and that makes a huge difference in performance so it would take much larger strings to exploit it. Eventually we will post some numbers. BTW. Django and Flask are welcome to use the [web2py implementation of PBKDF2](https://github.com/web2py/web2py/blob/master/gluon/contrib/pbkdf2_ctypes.py) which is designed to be a drop-in replacement.
&gt; re-throwing standard errors as custom errors [instead of subclassing and throwing]) Can you expand on that? As far as I understand you you're saying that the following is bad practice. def foo(bar): if not isinstance(bar, Jigger): raise TypeError("bar must be an instance of Jigger") And that instead you should do class MyTypeError(TypeError): pass def foo(bar): if not isinstance(bar, Jigger): raise MyTypeError("bar must be an instance of Jigger") The often cited [stop writing classes](http://www.youtube.com/watch?v=o9pEzgHorH0) talk advocates using standard errors where appropriate. So if you could expand on why that's a bad practice then that would be awesome :)
JFTR: Flask does not have an implementation of PBKDF2. Werkzeug has one since 0.9 just to make the old password functions a bit safer. We're not actively encouraging anyone to use those.
&gt; I feel like this person is more concerned about ideals rather than producing production code. Kinda sorta. I definitely agree with your criticisms, but I'd like to point out that I emphatically agree with the author's opinion on how the `__init__.py` should be used. I haven't always done it myself, but in the packages I've done it for, it's worked out really well and ended up making it easier to construct a more cohesive public interface. 
&gt; A good rule of thumb is to only have one class definition per module This isn't Java. Having only one class per file is *very* uncommon in the Python world, mostly because you don't see a separate *module* for each class.
&gt; I emphatically agree with the author's opinion on how the \_\_init\_\_.py should be used I completely agree that the general idea of \_\_init\_\_.py being a place to provide an interface is a good idea. But I also tend to add a few restrictions so the behavior is well understood and the code structure/practices remain similar within a team. I really like the authors idea of not having any kind of real code in \_\_init\_\_.py, but I also think code without the logic can get to be dangerous too to some extent. I use \_\_init\_\_.py myself for interface code but do so with these conditions: * Don't import full modules, import things from modules * Import the things people should care about, where they should care about them. If you have a package with several sub packages, the things specific to the sub-package should be imported there * Don't import lower level things that let people propagate bad practices. For example, if you have a base exception class, don't import that at the top level * make help(mymodule) useful, include some doc strings * Though not a functional requirement, \_\_init\_\_.py should be very easy to read and if needed long import should be cleaned up with () not \ from a import ( d, e, f, [ more things ] [more things]) * Once deployed and in use, **do not** expect people to change their imports without properly deprecating them first or providing an alternative under the hood. This applies more to minor version releases than anything else * Do not import things at the top level which cause your package to fail. If you have a database connection to setup or something you have to run, have a configuration function or class.
Yup, I love all of those suggestions/guidelines. A few of them are exactly what I meant by building a cohesive public interface. Thank you for being more explicit!
Is the motor controller a daemon that you run on the same computer? How does *it* communicate?
Thank you for the clarification and thank you for providing that PBKDF2 implementation.
&gt;Would this also impact on the memory usage of integers? It shouldn't, no. The class reference isn't any larger, and since you're having to store is `{reference to int, instance data}` where instance data is the memory for the number, nothing's added. 
How is the computer doing the image processing communication with the Arduino board? Is it USB or ethernet? Oh, what's the difference. Use Sockets.
Nthing Pyro. It's a very neat solution to a certain type of problem. Example here : http://pythonhosted.org/Pyro/8-example.html . One thing to look out for is that Pyro is capable of doing a lot but in the cases where I've used it I've only needed 20% of it's functionality. That's not a bad thing but it does mean you need to not get bogged down when reading the documentation - in particular the whole concept of nameservers within Pyro are, I'm sure, very useful in certain contexts but I've never had to use them.
Rule 4 about using only relative imports contradicts PEP 8. Quote from pep: "Absolute imports are recommended, as they are usually more readable and tend to be better behaved (or at least give better error messages) if the import system is incorrectly configured". So either the author did not read pep or he thinks it is not worth addressing difference between his rules and pep. 
Personally, I'd just suck it up and use 42. After all, it is the answer to life, the universe, and everything: http://en.m.wikipedia.org/wiki/Phrases_from_The_Hitchhiker%27s_Guide_to_the_Galaxy#Answer_to_the_Ultimate_Question_of_Life.2C_the_Universe.2C_and_Everything_.2842.29
If you read the very next line, you see this: "However, explicit relative imports are an acceptable alternative to absolute imports, especially when dealing with complex package layouts where using absolute imports would be unnecessarily verbose"
Which doesn't support this article's author's opinion that you should always use relative imports inside of packages.
True, PEP 8 doesn't really care either way. Thus, it doesn't contradict it (but neither does PEP 8 support it). In short, PEP 8 doesn't have much to say here. Really, that line was historically saying "Don't use implicit relative imports, they're a mistake.". When explicit relative imports were added in, it took a while for PEP 8 to be updated. I think PEP 8's mentioning of absolute vs relative imports is a historical artifact.
&gt; The easiest, cross-platform way to do this is sockets. Raw socket manipulation is almost certainly not the easiest way to do what he needs, the possible mistakes are too subtle. Wrappers like zeromq and heavier-weight message queues exist for good reasons.
I think I disagree with every one of these rules.
&gt; make help(mymodule) useful, include some doc strings This. A thousand times yes.
Yes, I know. I read python-dev too : ). But I still think the fact that it's mentioned at all is a historical artifact. If we had never had implicit relative imports and went straight to explicit relative imports, I don't think there would have been any reason for a preference for one over the other. Right now, PEP 8's current decision/wording on the matter is pretty awkward: "Use absolute imports; explicit relative imports are cool too". They might as well either say "Don't use implicit relative imports" or just remove the section altogether. I don't remember what exactly how the discussion ended up going on python-dev when it came up (All I remember is that there was slight bit of disagreement on the matter). (I was only kind of paying attention. At this point in my python life, PEP 8's more or less lined up with my intuition, so it doesn't really matter what exactly it says for me anymore.)
Yeah, I thought that one was pretty ugly too. You should put exception definitions where they semantically belong. Otherwise you might as well make a "classes.py" and a "functions.py".
It's perfectly possible to write PHP the way your eloquent Djangos and Rails are laid out; it's just that PHP makes it incredibly easy for all your coworkers to write spaghetti in ignorance of that possibility. A framework like laravel makes things just as clean and easy. However python will always have the advantage of being far more general than php. Learning python first before php, has taught me never to accept the mess of spaghetti that's capable of being produced with php as the defacto standard, so really today I don't mind working in either language as long as they're domain appropriate and the codebase has a sane architectural design.
Also, the PHP standard library is mindnumbingly inconsistent. 
Good PHP frameworks are available since at least 2005. 
Well, Python is doing great with Abaqus, I heard that many people using the software learn Python at some point in their careers. So I guess you can find some interesting implementations of Python into CAD within Abaqus community.
Thanks for clearing that up. :)
Short: PHP's low barrier to entry is one of bigger strengths and probably the worst weakness. Well, actually PHP is improving much lately (taking good features from other languages, libraries are of higher quality), even community is better than before. IMHO, one of main problems of living in PHP world is that average code quality is pretty much terrible. You can write good code in PHP, same as in any other language. But writing bad code in PHP is easy, everyone can do it :) There are articles/tutorials that explain how to do things, but such things are done in wrong way, and people just copy/paste code from some random blog and modify it until it appears to work. But still, PHP is not really close to python, when I get some package from pypi, I just use it. If I download some PHP library that is not very popular, I am to afraid to use it straightaway, I have to read code, and do some testing to see if such library works as advertised... One good thing about real PHP developers, is that they are very good at handling terrible code-bases and working with quirky languages and back-stabbing third party libraries :) Arguments that I heard against moving to from PHP to Python for new project are: 1. Rest of team does not know it. (Valid, because we are under constant pressure with insane deadlines, we have 10 months deadline for new huge project with undefined requirements and specifications..) 2. What about new hires, they will be hard to find and more expensive. (I think this one is invalid..) Disclaimer: I am Junior dev (almost 2 years PHP profesinally). In addition to that 2 years, I have about 6-8 months of experience in freelance and hobby projects. (mostly Python, some PHP). Disclaimer2: I am in love with Python, that is bad and this comment is terribly biased. (Although, I do not hate PHP)
Take a look at Blender, the opensource modeling software. It's completely scriptable via Python (http://blender.org). Have a look at Celery (http://www.celeryproject.org) and RQ (http://www.python-rq.org). Django has wonderfully documented source (http://www.djangoproject.org). Those should get you started! 
The blog describes coding standards in python
Nice! Like a super-condensed version of PEP8! 
Python's is better but calling it consistent would be a stretch. Although it doesn't pollute the global namespace like PHP's does.
I have a Arduino Uno and I can write to it via python as if it were a device on a serial port. You can use PySerial to easily write out information, but you will need to know how the Arduino is going to interpret it.
&gt; new hires, they will be hard to find and more expensive I think this is becoming less and less true. It will always depend on the market you're in to an extent, but I see Python and Ruby at least on a par with PHP these days. This is especially true for startups and companies doing more interesting projects. If I were trying to hire these days and I found somebody who only knew PHP, I'd be suspicious about their skills. Of course there are arguments to keep using it, but any good developer should at least have tried the alternatives and have an understanding of them.
&gt; web2py always does and always did validate the length of the password in user login forms therefore we believe it is not vulnerable. Always being starting from 20 hours ago? https://github.com/web2py/web2py/commit/4556a355a29a30ba634e9468245c559c5754e2c5
You miss the fact that the web is probably the largest programming domain currently and is only getting larger, and that's php's core strength. You can deploy hundreds of php apps with only mouse clicks and web gui, no console knowledge involved. This is still nowhere near easily possible with 99% of python or ruby. There are thousands more people out there who couldn't tell you what the heck bash is yet can be easily taught how to set up wordpress. And speak of the devil, wordpress blows every single other web framework, cms, blog, w/e out of the water in popularity, and there's no sign its reached any saturation of uptake. So I think PHP is still continuing to explode, still based on ease of deployment and low barriers to entry, there's absolutely no sign that either of these factors is doing anything but getting more significant. And I say this as someone who would choose to work on python over php any day of the week. Fantasizing that python's generality automatically trumps php in a web-dominated world is not living in reality.
For spatial data, check out [ArcPy](http://help.arcgis.com/en/arcgisdesktop/10.0/help/index.html#//000v000000v7000000.htm) (a proprietary module for scripting ESRI ArcGIS workflows) and any of the available [open source geospatial modules](http://www.carsonfarmer.com/2013/07/essential-python-geo-libraries/). GDAL, the C lib underlying most of the data translation capability of many open source geo tools, can [handle DXF files](http://www.gdal.org/ogr/drv_dxf.html). More generally, check out scipy, numpy and pandas
Thanks. I've found a few examples, but they're really scarce.
Thanks! I'm using DXFgrabber and COM in my work that I will be presenting.
Blender has some nice images to offer, thanks. A pity there isn't any sort of script gallery or something.
In what year this guy is living in, 2000? I'm beginning Python and I have some experience with PHP. I like Python syntax and environment more, I recognize it as a superior language and more general pruporse, but its perfectly possible to write good code with PHP. It's just that as an entry level language its really really easy to write bad code. But as time goes by, you begin to differentiate the good from the bad. True, you learn the hard way, but you learn after all I'm sorry to break it to you, but PHP is not going anywhere. At least not unless some revolutionary technological change happens. Meanwhile I really recommend you look at PHP again because it has improved a lot and its availability is something that can't be beaten, not by today standars, and it cannot be disregarded. There are also people contributing to PHP who really understand what needs to be done. Function autoloading and named paramenters are being discussed right now and I feel like if they pass they are going to be a HUGE step in both keeping PHP relevant and making it stronger. Also, this line in the article says how much the guy really knows about PHP: &gt; When was the last time you looked at a PHP project and saw a list of all the third-party libraries and respective version numbers being used written in a single file? I'll tell you when was the last time that I DID NOT see one: years ago
[This guy's blog](http://jakevdp.github.io/), which I think has come through this subreddit a few times, has lots of great visuals, often using matplotlib for animation. For example: - [Pulling Mario sprites and backgrounds from ROMs](http://jakevdp.github.io/blog/2013/01/13/hacking-super-mario-bros-with-python/) - [Animated triangles](http://jakevdp.github.io/blog/2013/05/28/a-simple-animation-the-magic-triangle/) - [XKCD style "drawn" matplotlib plots](http://jakevdp.github.io/blog/2012/10/07/xkcd-style-plots-in-matplotlib/) 
What happened to one clear and right way? ;-)
I don't think you understand where many PHP programmers come from. The thing about PHP is that you can start off with an html-and-css website, change an extention from .html to .php, and add a little bit of code you've got a bit of dynamic code. Something that changes based on cookies or something. Then you look up some examples and people can log in, and before you know it the site does all kind of stuff. Django is truly awesome, and any sane person that is starting a large web project would use it or something similar. But if you just want to add a clock, or want to randomly generate a subheader for your html website PHP is infinitely more easy. I don't think any new large projects will start in PHP, but PHP will remain perfect for those just starting in web development.
the **only** reasons i build anything using php is **cheap hosting**. as for frameworks [limonade](http://limonade-php.github.io/) is a good framework and is similar to python flask.
Fixed this.
&gt; web2py always does and always did validate the length of the password in user login forms therefore we believe it is not vulnerable. Yes. There was an edit in my comment above in which pretty immediately I admitted I was wrong. We have released 2.6.3 to address the issue and this was advertised on the [web2py mailing list](https://groups.google.com/forum/#!topic/web2py/QO-1qTd0WsQ). Anyway this is a little more complex than black and white. There are three types of login forms in web2py: user forms, auth forms, admin form. Users forms do not have the vulnerability [because of this](https://github.com/web2py/web2py/blob/master/gluon/dal.py#L6892). Admin login does not have the vulnerability because admin is locked after 3 login attempts. In the commit you refer to we decided to truncate the password in case an inconsiderate user decides to disable the limit to 3 login attempts. Then there is the case of Auth login forms. That is where I was wrong. I am not sure we were vulnerable but I cannot exclude it. While we do check for password length, we only do it after hashing it. We fixed that. I also stated that our implementation of PBKDF2 is much much faster than the Django one. Combine that with the fact that we lock sessions while people attempt logins. This is why we are not sure we were vulnerable. Anyway we decided to take extra precautions. TLTR: Better to err on safe side and perform multiple checks even if we cannot reproduce the DoS attack.
&gt; It's been around much longer, and was developed much earlier, and therefore suffers from the age of its design. Isn't Python actually older than PHP? Accordingly to wikipedia, Python is 22 yo, while PHP is 18.
&gt; It's not "mindnumbingly" inconsistent. Compared to pretty much every other language, yes it is.
Thanks for this feedback, much is on-point and valid (will try to get an edit out for fsq and the post). &gt; I like the idea of keeping modules small but "A good rule of thumb is to only have one class definition per module" doesn't really work across the board and it's more difficult for larger projects. Certainly if you choose to define exceptions within the raising module and not in their own module, this breaks down pretty quickly. Anytime you have a factory or a manager, this advice also breaks down immediately. Additionally the (poorly named) exceptions.py demonstrated shows another case where I believe defining multiple classes in a single file has merit. Good rule of thumb here was not intended to be taken as "required", and **should not** be adhered to with a consistency leading to foolish hobgoblinism. &gt; There's a module being imported called 'exceptions', same as the built-in module in Python 2.x Yup, bad choice of name here, totally inexcusable and poor form. As the exceptions module seems to be the subject of a lot of criticism here, let me provide some further context: The problem is not when you raise, it's when you except. Many circular import dependencies are caused because you have to import a method from one module which raises an exception defined in another module: to except this error you now have to import both modules (best case) or chain the exception through the intermediate module (worst case). The aim here is to apply the advice laid out for [C++ systems](http://www.amazon.com/Large-Scale-Software-Design-John-Lakos/dp/0201633620) by Lakos to Python in a meaningful way. &gt; It's much easier to debug when you're not importing everything at the top level, "import mypackage" should rarely break anything I agree with what you say below about not having a broken DB connection breaking imports 100%, but I do think a misconfigured package-system resulting in ImportErrors should fail loud and early at package import time, not when you trigger a sub-module import. With the example code provided (fsq), importing does not fail if the queue directory does not exist, which is intentional. &gt; The author linked to source code which is a mess in many places and has some pretty bad practices in others (ex. module level variables, re-throwing standard errors as custom errors [instead of subclassing and throwing]) There are definitely some things that need cleaning in fsq, but I would disagree with the comment that it too frequently throws custom errors for standard errors. FSQError imports OSError, and the majority of re-raised custom errors are OSErrors. As stated in the post, anytime there is an error in the standard library that covers your needs, it is an exception to my granularity in exception recommendation. *EDIT* To the module level variables in enqueue.py, I cringed as I wrote it and ultimately it will be ported to thread locals, but remain at the module level. The reason for the module level vars here is that you need to generate an time-ordered but unique string within a single process. A more elegant solution might be to use thread id and micro-timestamp, but this is not guaranteed to be unique. Rather than brute-force here, I chose to eat a few globals which is uglier but more efficient. */EDIT* &gt; If you must import things in a certain order at the top level, you are generally doing something wrong. Exceptions to this rule can include thing like sqlalchemy's relationship. If you are exposing less of your package (possibly not a bad idea, depending on what you're doing) at the package levels, the order of imports in the __init__.py largely goes away. The constants and internal module imports in __init__.py for fsq are actually not required, and should be removed per your comment below. My point here was rather than eat any dependency ordering costs in each sub-module, it's better to handle it only in the __init__.py. In complex systems I've found it's difficult to completely design out any order-of-import issues ... and I'd rather pay the piper in __init__.py once, than pay him in 2 or more modules. +10000 to your comment below about defining doc-strings in the __init__.py, that's just a glaring omission in the post.
There's no reason to have naming conventions all over the place like `strpos` and then `str_rot13`, `strtotime` and then `nl2br`. Python -- nor any language -- is perfect, but at least it avoids a lot of the really bad naming conventions. And let's not get started on that fucking scope resolution operator.
Being designed explicitly for the web is what lead to php's weak typing - after all, everything is a string in http. I remember being frustrated with another language (ruby, I think) for requiring me to explicitly convert numeric GET params to numbers, when they were clearly numbers when I put them in the page. Now that I've got more experience, I've seen the problems of weak typing, but I'm also no longer php's target audience. 
The argument we have against it is the the same as other language discussions: how do we do that incrementally? 
Also, I don't know if you saw ircmaxell's announcement the other day about his departure from php-internals. There are still good people, though. 
Yii is also an excellent PHP framework like rails or django. I used to hate on PHP with all the cool kids, but once I started using Yii I realized that it's a fine language. I do python development these days and sometimes think back with nostalgia to the days of using arrows instead of dots, and inline string variable replacement http://www.yiiframework.com
I'm not comparing it to anything. Your mind doesn't get numb about something by comparing it to something else. The word you are looking for is inconsistent. Period.
I agree with you, there is no reason for it! Something needs to be made about it. But it's not a reason to not use PHP
Check out Houdini. It's a procedural node based 3D application with heavy scripting support and is the de facto effects package in the VFX industry. They have a community forum on their site and here: http://odforce.net/ Example of using python to generate geometry: http://www.preset.de/2007/0711/lorenz/ Another project to look at is https://www.panda3d.org/ which is a game engine that supports full python scripting. Python is the most common language in the 3D industry with most applications supporting it. Most films you see today will have a lot of tools scripted in python (smaller tools mind you)
Don't everyone do this or there will be no material for lolphp.
&gt; Short: PHP's low barrier to entry is one of bigger strengths and probably the worst weakness. Would you make this same argument for Rails?
If you are asking a general software engineering question, that is one thing. If you want to know the best way to go about what you want to do, my vote is for SQLAlchemy. Granted, I have not started too closely at exactly what you are saying because I've never needed to work at that low a level - just Django's ORM a few times at work and SQLAlchemy for all my personal stuff.
Please this discussion does not belong here. If you are serious bring it on our mailing list. Anyway. No. It is not IP based. Admin in web2py is only for the system administrator. It is not designed for users. There are only 3 login attempts every 15 minutes in total, not per IP, not per user. Yes, an attacker can lock admin out by repeated attempts and this is why, in production, we recommend that admin runs only locally and one the administrator connects via ssh tunnel. Many users do not run admin at all in production.
Yeah, it's more of a general question, though prompted by a particular problem. No, ORMs wouldn't help as I'm writing a data migration script, so the statements are somewhat non-trivial, plus there's a healthy dose of DML which prompted the second part of the question.
Thanks. Web2py sounds interesting, and I guess I'll investigate more from wikis or tutorials. But /r/Python comment threads are a great place for discussion relating to Python, Python libraries and Python projects!
&gt; I'm sorry to break it to you, but PHP is not going anywhere. At least not unless some revolutionary technological change happens. languages go places all the time.
Hope you find some comfort in being technically right.
[PythonOCC](http://www.pythonocc.org/resources/meshing/pythonocc-and-smesh/) does a great job of wrapping the OpenCasCade CAD kernel, and has bindings to powerful FEM meshing libraries. Comes with a powerful OpenGL viewer, neutral CAD format reader / writers like STEP and IGES and lets you prototype powerful CAD with pleasure. I use PythonOCC to develop offline robotics software, which transliterates geometry to motion.
I couldn't care less about being correct really. What I do think is that calling PHP mindnumbingly inconsistent is a sign of poor learning or of fanboyism
Anyone who knows more than one programming language prefers anything besides PHP. Go learn some other languages and then come back and claim that you love PHP.
See, that's fanboyism right there. And you can be sure it's not hurting anyone but you. If you say it for the points mentioned in the article, then you are free to do so, but you can't change the reality: most of them are not relevant anymore. Do yourself a favor and read the comments on the article page. &gt; Anyone who knows more than one programming language prefers anything besides PHP Yeah I'm gonna need a source on that &gt; Go learn some other languages and then come back and claim that you love PHP. I actually am proficient in quite a few languages. PHP, C++, C#, Javascript (and Node) and I can hack together some ugly things in C. I'm also diving in Python right now, and I love it, however i'm not going to take sides for a programming language for the same reason that I'm not going to take sides with the screwdriver and bash the hammer because sometimes all I need is the hammer. And I'm not bragging I'm not really that smart, I'm just trying to show you that you can believe the bullshit you read in forums or you can open your mind and improve My recommendation is learn as much as you can 
The whole "better do something incorrect than throw an error" philosophy for instance.
"perfect" might be a strong word in this context.
There is no Python in this article.
When was the last time you saw a PHP project do that? I'm honestly curious not trying to break your balls
Yeah I guess you are right. Hindsight is 20/20
http://me.veekun.com/blog/2012/04/09/php-a-fractal-of-bad-design/
I'm familiar with the article. Have an upvote because I think that everybody interested in PHP should read it. I agree with it in some things and some improvement have to be made, but for me it feels that the author is complaining more about PHP not being more Python-like than PHP being the way it is. And there is http://phptherightway.com
One it's own, yes. If this was the only complaint I had against PHP then it's a weak argument. But it's the least of my complaints.
And that little bit of code you add to that renamed document can be a quick snippet taken off any of the thousands of free PHP snippet sites. You can get a surprisingly long way without actually writing very much PHP.
This is a fair point. Sometimes PHP is the correct tool for the job: it's widely support and easy to get up and running with. But for anything bigger than two or three files, I'd rather use literally anything else (well, maybe not Brainfuck or LOLCODE) -- even [bash](https://github.com/jayferd/balls).
Jesus, I hate this attitude so much. I'd rather my webscript crash and burn completely than have: MySQL Connection Error using password: yes on line 84 in /var/www/MyApp/index.php Displayed a thousand times all over the site.
Python in CAD (specifically, using it for FEM geometry preprocessing with AutoCAD COM automation and DXF files parsing) "Python OpenCascade" is a package for doing CAD in python. http://www.pythonocc.org/ "OpenVSP" is an open-sourced NASA program for building geometry in more intuitive ways than CAD (more focused on aircraft, but generalization is in progress) that will have Python bindings in ~6 months once they release version 3.0. It can also export a Rhino file, which can then be exported as a CAD file from Rhino. http://openvsp.org/ pyNastran is an IO for the Nastran file formats (a FEM solver). It reads almost everything and I wrote most of it pynastran.googlecode.com Code Aster is probably the best free FEM solver out there. It's funded by the EAD (European Defense Agency), but the documentation is mainly in French. The input file is in Python. http://www.code-aster.org/ Salmone-Meca is their mesher that directly accesses the CAD data in order to be able to do refinement studies.
I would pick PHP over Java a thousand times over.
That's exactly what I mean. You and I have different ideas about what size a PHP project can handle, but the point is to recognize that tools are tools, they shouldn't be your end goal but your medium to achieve it, and if you say that a tool is completely useless and does everything wrong, well, you are most likely wrong. It all comes down to a personal choice, but it has to be a choice, not something imposed by second hand experience
You might want to decrease a little bit the number of connections to your db per script
If you're using something like, say, notepad.exe you might be right. But if you're using the right tool for the job, like a proper IDE, then your point is moot.
Then set it up to crash and burn. Nobody's stopping you from configuring error handling the way you want it in PHP.
There was someone who built a minecarft clone in python using only 800 lines. 
If we are talking about the same version of PHP we'll have to agree to disagree Also the top rated comment is saying exactly the opposite of what you are saying so I don't know where are you getting your "everyone else" part
I have no practical experience of this so I can't answer your questions but have you seen this : [https://github.com/Sifodeas/N-Body](https://github.com/Sifodeas/N-Body) ? That seems to be what you're describing implemented in VPython. See it in action at http://www.youtube.com/watch?v=d6kz8mFwMT8 .
Hey! Computational physics person here. What you're looking into are called N-body problems. You can certainly do it, and I think that the solar system is a great place to get started, before you realize that galaxies and black holes are just as easy and more mesmerizing. If you just want a quick bit of information, you're going to want to be using a few different methods of numeric integration; Probably RK4 and Leapfrog/Verlet. You can google them. You can either program them yourself (good for learning, I recommend) or use Scipy to do it for you. If you would like a bit of mentorship through this, send a message and I'll be glad to help you.
I'm being completely honest here: I don't understand how not enforcing standards is a disadvantage. If you told me that it doesn't support the use of standards I'd agree with you, but that's not the case. It's true that it makes it easier to produce bad code, but that's not a point I'm trying to deny! My point is this: it's completely possible to write good quality, testable, modular, maintainable and standardized code with PHP. Is it hard? Yes it is, but that's the case with any language I feel you if you have had to work with people who abuse of this permission and write shit code, but that doesn't mean that the language is inherently bad or that all code produced with it is going to be shit. That's why I said that we are going to agree to disagree, but that's okay.
I've just graduated in Physics with Astrophysics and I did this about 6 months ago in Matlab, but the method should be roughly the same. For each of the bodies in the system you're going to have to know their initial starting x, y, z coordiniates and the values of vx, vy and vz (the velocity data), you can get sample data from the [JPL Ephemeris Horizons System](http://www.astro.gla.ac.uk/honours/labs/solar_system/JPL%20coordinates/) and this can be used to test the accuracy of your simulation too. - basic: use a fixed timestep and newtons law of gravitation. - advanced: use ordinary differential equations to get data within a set accuracy using a variable timestep. This can later be interpolated to get a fixed timestep. It's also worth looking into Relativistic Corrections (especially for the effects of the Sun on the planets and possibly also Jupiter, these should be negligible for anything else) Note that the more complex you make this the slower it will be. Depending on your tolerances for the ODE this will likely be your biggest killer of time. Worthy things to read: - [Relativistic Corrections](http://www.astro.gla.ac.uk/honours/labs/solar_system/papers/vitagliano.pdf) - [A list of constants, some of which may be important](http://www.astro.gla.ac.uk/honours/labs/solar_system/astro_constants.html) Hopefully this is the sort of thing you're looking for. Good luck, and if you need any help just drop me a message. :)
That is what happens when BC is more important than anything else. Everything was implemented with the convention of the day, and old things were not updated to reflect the new style. Sure they could be aliased for a few major versions, but they've been around for over a decade and its generally considered that nobody really gives a fuck, which to be fair is how it seems to me. It would be _nice_ to fix them, but I don't see it happening. For one that would involve picking a new naming convention, and nobody on internals is going to do that. Here is [one potential solution](http://philsturgeon.co.uk/blog/2013/01/php-6-pissing-in-the-wind), but I don't really care all that much.
I think people will understand your point better if you use a few more punctuation marks.
Some languages make it much more difficult to write less stupid code. PHP is not one of them. Nor is Perl. I spend 50% of my development time in a Perl codebase, so this is not fanboyism talking. Choose the right tool for the job. PHP is not a tool for products requiring long term large scale development.
ITT: "I've been using PHP without a framework, and without any rules. I saw Rails and Django and associated the MVC layout/pattern with the languages. Instead of finding a PHP framework or adopting MVC in any way at all, I just dropped the language, and made an inflammatory blog post with rampant misuse of apostrophes." 
Perhaps your argument is that PHP should not be used without an IDE.
Turn off errors being displayed and check the error_log file. Also if you cant figure out why that error is coming up then you have deeper issues.
The curse of vcvarsall.bat! Edit: Oh, wait. You're not talking about Windows? I thought Python only sucked this hard on Windows.
Again, I read what you are saying and I get the impression that you are blaming the language for its users. It seems to me that your point isn't "php isn't the right tool for a large scale development" but "php makes it harder for me to pick properly trained people for a large scale development". Not saying it's the best tool for the job, and I don't know if I would recommend it as such, but it certainly is a tool for the job if used well
Ah, I didn't catch that part. I thought you meant that it wasn't part of a larger CMS system.
You've mistaken the issue. Python, Ruby, Javascript, C, C++, C#, Java, and hundreds of other languages are great. PHP is awful. Maybe someday it won't be awful anymore, but I will never understand why people stay in abusive relationships waiting/hoping for their partner to change. Everyone saying PHP is awful is not jealous, or hating, or in an "us vs them" mindset -they're trying to save your life.
I think a kind of flawed question, while you can write a blog engine in one of the micro frameworks,, it is a fair amount of work to add the "usual" features you find in something like WP.. IMHO the closest to a WP type solution is the Django framework, Mezzanine http://mezzanine.jupo.org/ which is easy to set up theme and extend it is Django...
The formula you want is http://en.wikipedia.org/wiki/Newton's_law_of_universal_gravitation plus two integrations. Just apply that to each of your bodies and sum forces using numpy. Make sure you use a decent integration method (e.g. scipy.integrate.odeint or scipy.integrate.ode - Runge Kutta) so it's fast. If you let it go long enough, you'll find that your solar system is unstable :)
This article is silly. The reason that his experience was bad on that project is due to fact that there was no dev leadership on that project if there was code standards, code reviews, and a architect the php project he was working then the code base would have look better. They probably had contractors who were working on the code base with no guidance working on it.
I don't think it's about bringing the Java world into Python, it's about reducing complexity. I've work mostly in C++/Python and there are certainly times I really wish people would have put a single class into a file and not two or three. That said, I much prefer to have classes grouped into modules based on their functionality. **EDIT**: This is *especially* true for maintainers of legacy code who often have to keep things as is. Newer code should very rarely put one class in a file alone with a couple of functions.
&gt; It's just that PHP makes it incredibly easy for all your coworkers to write spaghetti in ignorance of that possibility. That is a commonly repeated refrain and it sounds good but if you really think about it, it doesn't make much sense. The only feature I can think of that PHP has which might induce more spaghetti is embedding code into HTML. Other than that, PHP actually has fewer features that allow for unmaintainable code than Python or Ruby -- those languages are much more powerful. PHP has a much larger market share that is skewed towards novice developers (and even non-developers). Inexperienced people can produce terrible code in any language. 
&gt; numpy.random.random() still hurts my brain to see in code from numpy.random import random as numpy_random
You should try Flask. from flask import Flask app = Flask(__name__) app.route('/') def hello_world(): return "Hello World!" if __name__ == "__main__": app.run() 
This would be my vote, sqlalchemy can be used to do the general queries and will also keep a nice little connection pool going that properly handles the connection(s) for you. Another advantage is that if you decided you needed to do something more advanced then everything is already there, just waiting to be used. 
They have a cookbook but their examples don't follow any strict standards or review so your results will be mixed: http://wiki.blender.org/index.php/Dev:2.5/Py/Scripts/Cookbook I can tell you they're certainly better than what Autodesk Maya has, which has been essentially none for years.
Good point, the problem is I can't say it's entirely unsuited for my needs. The current issues are it's complicated and bringing on new developers or explaining it to non-developers takes a fair amount of time. Twisted's deferred system also doesn't make for the cleanest code either and it also makes tracing bugs that much harder in larger systems. So to answer your question, no it's not unsuitable for my needs, I wouldn't have started using it years ago if it was at the time. I'm asking this question primarily to see if there's anything new that I could consider as a replacement since I have the opportunity. I have a feeling that using a group of smaller libraries that do the same thing would work I'm just don't have enough research to know what to start investing the time in. I did spend some time looking into gevent, tornado, and multiprocessing but I couldn't figure out an implementation that would be any better than what I already have in terms of launching processes, monitoring them in (technically) real time, and communicating over a rest api at the same time.
You don't have to use django if you want to write a website in Python. You can use Flask, cherrypy, webpy the list of micro web frameworks go on. I also don't know what the advantage of PHP over javascript is these days. Especially with stuff like Nodejs. 
Please stop promoting CodeIgniter... in the PHP world, it's considered outdated. Thanks! 
Damn, I was really hoping it was a tool that tags shitty code.
The fact that PHP's behavior is dependent on configuration files is wired in and of itself.
Yes, it was linked on /r/PHP. Edit: down voting just makes this self fulfilling, guys.
&gt;I'm sorry to break it to you, but PHP is not going anywhere. That's what Delphi users say too. &gt; At least not unless some revolutionary technological change happens. What language has ever taken a technology revolution to dislodge it? Even incremental improvements can begin a migration. &gt;Function autoloading and named paramenters are being discussed right now But that's the problem. Basic features that almost everything has are "being discussed now". And if they ever get implemented you'll just have caught up - except you won't have, as most languages aren't standing still. This is like the situation with the Firebird database, which is at least 7 years past due for version 3.0, which finally saw Alpha 1 this year (with that being a year late from its originally announced debut date). Even if they get 3.0 next year, it'll only be catching up to where others were in 2005. They'll still be years behind. Why would anyone wait around for PHP to get what they can get now, unless PHP has unique features? 
Did you evaluate [gipc](http://gehrcke.de/gipc/), which provides a `multiprocessing`-like API for use with `gevent`?
Supervisord?
Which Delphi users say that? Most of the Delphi developers I know, knows Delphi is pretty much dead (at least in the sense that it is not popular anymore). Most desktop development is dying btw, which brings down projects such as Firebird with it. I don't think the web is going to die soon though. Also, is no computer language is ever allowed to progress? Why was Python 3 developed if Python 2 was so good? It will take years for some Python 2 projects to be migrated to Python 3. So if you're going to use your logic, then at least apply it everywhere.
The article says "The client will use the SOAP protocol." but then proceeds to give an example of xml-rpc. As far as I know, xml-rpc is not soap or am I missing something?
Just because something is popular doesn't mean it's a good solution.
You're right except for the 'on that project' bit, it was 12 years across a host of applications. I spent 6 years in Digital Marketing in London where we could be touching 4-5 projects a month. I never saw a codebase built with PHP which was more maintainable than Python.
How cheap is cheap? I can get Python and Rails code up on VPSes for $5 / month.
Absolutely not, but somewhatoff wasn't specifically talking about what makes good solutions, he was talking about the popularity of PHP.
which $5 vps are you talking about? that is still very expensive when compared to 0.708 USD / month hosting for php. 
You sir, deserve a medal for stepping up to the plate. 
Depending on what you're doing, my team has used [celery](http://www.celeryproject.org/) for something that sounds similar.
CodeIgniter is something I still turn to often. Care to explain?
In this case, it will become more efficient /and/ more readable if you first get all possible tags, e.g. tags = unique(tag for tag in post['tags'] for post in posts) return {tag: [post for post in posts if tag in post['tags'] for tag in tags} Then again, the real problem is rather in your data model: why do you need to retrieve all posts to get a list of all possible tags?
Why do you use underscored names? Why is "post" a global variable apparently, instead of a parameter? Does that answer the previous question -- you got a weird error and decided to underscore everything? Or if it's a type, why is it not capitalized? Yeah, I would take out the second line and name it "all_tags" because it's not immediately obvious that it's all tags, for starters. Generally, good code explains _what_ it tries to do, using variable names, function names, or at least comments, and doesn't require the reader to reverse-engineer the purpose from the code (unless the purpose is self-evident, of course). In the same vein, rename `get_all()` to `get_posts_by_tags()` But really your code is very inefficient. While Python is not the fastest language this doesn't give you the license to "prematurely pessimize" your code even further by using bad algorithms: here if you have 1000 unique tags, you're going to check every post 1000 times. I'd write that like this: from collections import defaultdict def get_posts_by_tags(posts): result = defaultdict(list) for post in posts: for tag in post.tags: result[tag].append(post) return result 
A lot of other languages, for instance with more complex word inflection than English or French, have seen bigger success with rule-based methods as there simply isn't enough text to train on to expose a statistical method to enough wordforms to have decent coverage. French is probably fine with methods like these, as there's a lot of digitized text to compensate for the additional complexity its words have that English doesn't, but I think the tagger in this implementation has only been trained on English, and it uses tags specific to English (and English-centric NLP stuff too, Penn treebank?)
Thanks. I'm purely curious because I like to toy around with French tweets or more complete Frenc texts. But, indeed, it's always hard to find good French texts out there to train properly a tagger. It's a shame :/
Check out twisted's deferred.inlineCallbacks, it can make messy deferred callback soup pretty.
In simple words; its too big to fail. Fixing stuff won't make it backward compatible and stuff like that. It hasn't grown much from the PHP4 days IMHO. http://heybigname.com/2012/05/06/why-codeigniter-is-dead http://philsturgeon.co.uk/blog/2012/09/moving-on (from phil sturgeon, one of the dev of CI) http://www.reddit.com/r/PHP/comments/1hyuih/ellislab_seeking_new_owner_for_codeigniter/ (ellislab, the company behind codeigniter, is looking for a new owner, lol) If you're fixing a CI project, go ahead. If you're making a new project, stay away from it lol.. use a modern one. 
Amen to simple nested for loops! 
Yeah wait until the 3rd part is released and then post a link to that page instead - it promises some Python.
http://google-styleguide.googlecode.com/svn/trunk/pyguide.html?showone=List_Comprehensions#List_Comprehensions
Thanks. Luckily, it's just for fun so I'm not in any hurry.
Actually I like list comprehensions as much as the next guy, but I don't think this particular algorithm can be expressed using them. It's a pretty fundamental operation it seems, what we really do here is reversing keys and values of a multimap (aka constructing the inverted index). Fundamental operations tend to require lower-level implementations. In this case it's pretty clear and concise (much more concise than the OP's algorithm IMO, not to mention faster), so yeah, the right tool for the job etc.
The /r/ipython sidebar lists a number of useful libraries and resources for learning Python for science. From python.org: * http://www.python.org/about/apps/ * https://wiki.python.org/moin/NumericAndScientific * https://wiki.python.org/moin/NumericAndScientific/Libraries &gt; Extra appreciation if it is related to geometry, spacial data processing, and finite element analysis. Thanks! * http://docs.sympy.org/dev/modules/geometry.html * https://github.com/sympy/sympy/blob/master/examples/advanced/fem.py * http://sfepy.org/doc-devel/index.html 
This is pretty unreadable. Unless you timed the difference between this and a nested loop and found a huge performance boost, you should abandon this immediately.
What would you recommend as a replacement, then?
You're not missing anything. It's not SOAP indeed.
When you say a "problem with reddit", do you mean "a problem with people, when presented with an environment that allows them to spew out whatever il-thought opinion they have on any subject without any consequences"? Some people here are a great read, helpful, informative, thought-provoking. Some people talk shit. The difference between reddit and real-life, is that you can avoid the people that talk shit in real life by not hanging out with them. And TBH, I think that works pretty well in reddit too - just listen to the people who you believe are worth listening to.
I'm sorry. I made a mistake in the post. Indeed, I'm not using SOAP as protocol, even because, partly, SOAP is not well supported in python. XML-RPC has great support in python, in the standard library. That's why I'm using XML-RPC. Thanks for noticing that, fixed the post.
Having a nested for in a list comprehension is almost always too much. My rule of thumb is, if it takes you more than a couple seconds to understand what's going on, you need to rewrite it more simply. Nested for loops will be much easier to understand. 
Thanks for your precious tips! I'll consider updating the post. =)
My favorite PHP quote ever: "Recalling the exact syntax for the built-in stab() function, you make a sane assumption and call shoot(GUN, FOOT); The foot shoots your gun"
The with statement is essentially a scoping operator. Basically, the variable f exists only within the block of the with statement. It has some nuances but the basic idea is that it opens the file, keeps it open while it is running the code inside of the with block and closes the file when it exits the block. It is most commonly used exactly like this to implicitly close the file when you are done with it. As for the rest of the code, I have added some comments here: http://pastebin.com/3QP79qgK 
This is basically a clean way to read a file and then do we stuff with it. Using the "with" statement may have an advantage of automatic garbage collection once it's done ("f" will be deleted from memory), I'm not positive though, you'd have to look that up. (On a sidenote, I would choose to do "f.close()" at the end of the "with" statement, it seems cleaner to me that a closed file handler be deleted, rather than an open one) If you're asking about the dictionary business, all that loop does is count instances of the same line in a file, it does so with exception handling, rather than using an "if line not in matches.keys():" statement. I'm not sure which is more efficient, CPU-time-wise. Say you've got a file that looks like this Pork Beef Eggs Pork The output of the script would be like this- {'Beef':1, 'Eggs':1, 'Pork':2} With the dictionary sorted alphabetically by key, as that is the default way. EDIT: Imagine there isn't a whitespace line between our example words, stupid Reddit Sync keeps turning lines with single words on them into the one line.
I wrote a simple program using PySerial to communicate with an arduino to control stepper motors. Very straight forward, just tell the Arduino what to do it receives an "A" for example. The alternative is the Firmata protocol which can be used with PySerial + either PyFirmata or PyDuino (both have their quirks) There are many situations where you might want to use the Arduino on battery, or mains without direct connection to the PC. On ebay there are dozens of wireless adapters for Arduino. Bluetooth and standard 2.4GHz serial adapters. They, too, can be written with PySerial without any changes to the program. Very handy when you want the device to be more than 5m from the PC (USB is expensive to extend beyond this range.
Sounds like h5py (or you) is doing something it shouldn't be doing. 
Well, it isn't. &gt;&gt;&gt; for name, module in sys.modules.items(): ... print name, module ... break bson.son &lt;module 'bson.son' from ...&gt; Something else is going on there.
Precisely! 
&gt;sorry if i've offended you with some code quality Ha, no! I did however take your claim that &gt;it's fairly horrible code and your suggested improvement to mean that commentary on code was accepted. I didn't do it to be harsh. &gt;PS. for such a short file, it's fucking pointless closing the file pointer. it'll be done when execution is over. thanks anyway Yeah, I was operating on the understanding that this is demo code (and the OP cared about what `with` does, and that he's learning so best practices are worthwhile). --- PS: If you thought this was an attack on the basis you were downvoted, it wasn't and that wasn't me.
&gt;On a sidenote, I would choose to do "f.close()" at the end of the "with" statement, it seems cleaner to me that a closed file handler be deleted, rather than an open one Unfortunately this implies you don't know how `with` works; the `with` *guarantees* that the `__enter__` (if available) and `__exit__` method (and one other probably about exception handling) are called. It doesn't have anything to do with garbage collection and manual closing is anathema to the purpose of `with`.
Everything php does can be configured and enabled/disabled at runtime. Most frameworks do this for you.
It usually isn't, and I've only caught this once. Usually the interpreter goes down without a traceback. This function is running in one thread once a second (it looks at modified times of module files and notifies if they are out of date), while h5py is used in another thread that chuggs away analysing data. My guess is a low level threading bug in h5py that's corrupting the C call stack, although I have no idea what I'm talking about in that regard. The other thread had an exception too, but my code caught it and called traceback.format_tb in order to pass it somewhere I might see it...and it got a `MemoryError` (!) concatenating the lines of the traceback together....so I never saw what it was and have been unable to reproduce.
Indeed it is!
Personally, I second RK4! I had to implement it in Java a while back and it taught me a lot about what integration is really doing. Perhaps implementing any of them would do the same though.
It's [defer.inlineCallbacks](http://twistedmatrix.com/documents/13.1.0/api/twisted.internet.defer.html#inlineCallbacks), but yes.
You are in fact missing something, but it's very subtle so it's understandable. Let n be the step index integers and s be the step size and t be the time. Velocity Verlet evaluates at t = n\*s, while leapfrog evaluates at t = 0.5\*n\*s. It seems insignificant, but over a given domain, it's actually twice as many calculations! In addition, leapfrog evaluates at "false time points", if you will (between the actual timestep values). That means if you're plotting at t = n\*s, you won't "see" all of the "work" leapfrog has done, but be more accurate over the same number of points. Usually a well written Verlet code can be used for either, but they are not in fact the same method. Since we're talking about it, leapfrog does a much better job of being stable for N body simulations that RK4 with less function evaluations because RK4 is essentially Euler integration at points around the points of interest. Euler integration will always diverge from a ovular curve because each step brings it slightly further away from the curve, and the average of a bunch of things which are further from the curve must end up further than the curve, no matter how cleverly you place them.
RK4 is indeed the standard 'workhorse' for most differential equations. It, however, diverges on ovular orbits! I would say just write both and compare them.
http://mgltools.scripps.edu - allowed me to check results of MRI scan myself to confirm I do actually have a spine and where is was fooked :-) Only realised recent what a huge chunk of Python it is (MGLTools, not my spine)
Say you have myfile = open(...) and it's worked (so the file is successfully opened). You want to use this file myfile.read(...) some_calculations myfile.seek(...) ... # etc and then you want to close the file myfile.close() *Unfortunately*, that's a terrible way of doing things. If any of the reads, seeks or calculations throw an error, the `myfile.close()` can easily be dropped and the file can remain open. So Python has had since way-back-when a `try...finally` statement, where *no matter what happens in the try, the `finally` is always executed*: myfile = open(...) try: myfile.read(...) some_calculations myfile.seek(...) ... # etc finally: myfile.close() The `myfile = open(...)` can be left outside because the file will not be open if that throws an error. But that's kind-a ugly, no? What's worse is trying to get everyone to adhere to these guidelines. That's not going to happen. --- But there's a real straw that makes this a pattern worth syntax-ing. Many things require a set-up and a set-down. Things like transactions to databases need you to deal with them safely. Things like changing directories in many cases should probably be semi-atomic – you want to move back to where you were after you're done without having to worry about exceptions. Changing semi-global contexts like numeric precision also should be local. There are so many cases where it makes sense for something to be the case, but only in a specific block. Having a file open is one specific case: with open(...) as myfile: myfile is only open here That's what `with` is for. 1\. It lets objects have an `__enter__` method which returns something you can use (files just return themselves, so `with myfile as myotherfile` will make `myfile` and `myotherfile` the same thing). 2\. It gives objects an `__exit__` method which will *always* run the clean-up without it having to be manually invoked. In the case of a file, the file is closed. **NOTE: The variable is not deleted, the file is just closed.** Does that make sense? --- Note that with open(...) as myfile: ... is exactly the same as _tmp = open(...) with _tmp as myfile: ... The `with` does not include the `open(...)`, and if that throws an error it'll not trigger the `__exit__`... because it doesn't have the object to get the `__exit__` method from! Luckily if `open` throws an error it'll also not open the file, so this will never leave you in a worse position.
/r/learnpython
And then you go to w3schools and use their code with gaping security holes.
Why? I felt the same way for years, but having programmed almost exclusively in java for the last couple of weeks has left me wanting more. 
To summarize http://blaag.haard.se/Why-Python-is-important-for-you/ "Python gets a lot of different things right, and right in a combination that no other language I know of has done so far."
&gt; Direct process communication through TCP/UDP would certainly be lighter than everything involved with running redis or zeromq, right? Unless you import a complex framework like twisted or tornado, which is pretty common.
List comprehensions are the best. I probably would've broken the set of tags out into a separate comprehension or at least done some indentation to make things hopefully a little clearer. separate tags: def get_all(): """Return a dict of all tags and their associated posts.""" posts = post.get_all().values() tags = { tag for p in posts for tag in p['tags'] } return { tag : [p for p in posts if tag in p['tags']] for tag in tags } just indentation: def get_all(): """Return a dict of all tags and their associated posts.""" posts = post.get_all().values() return { tag : [p for p in posts if tag in p['tags']] for tag in { tag for p in posts for tag in p['tags'] } } Also, I agree with the people who say you should be passing post as an argument.
Oh god, the horrors... Or some PHP snippets online in general, for jqGrid, the have examples with backend code on their site, all of it is just begging for SQL injection... I like PHP a lot, but so much code out in the wild on blogs (and w3schools) is disastrous. Luckily I've seen a lot of improvement to the quality of online code via stackoverflow and github though.
oh god, the terror!!!
I think you dont know how facades in Laravel works, those arent static
If you're a software engineer, managing projects, a good portion of your job is choosing the right tool for the right job. PHP and Perl are not scalable languages for large scale projects. They are the wrong tool for those jobs. Just because there are some big places that do use the technologies does not mean that it's automatically right.
&gt; but that every tool has its use Bullshit. No one in their right mind would use a manual drill for any reason other than to say they did it, unless they were forced to by external influences. Electric drills have superseded them in every way. In the programming world, that would be like VB Classic (pre-VB.net) or straight "sh" shell scripting (as opposed to bash or other modern shells). They'll still work, they can still probably get the job done just fine in most cases, but you'd be rightly considered an idiot for starting a new project with such things. Now note that I am not speaking of PHP here as a useless tool. I like Python more as a language, but the ability to simply slap a bit of code in the middle of a HTML page and toss it on a web server with no further thought is huge for me as someone who often needs quick-and-dirty web based programs. tl;dr: Some tools may not be literally useless, but they are practically useless and pointless.
Thank you, I'm alittle surprised by the mass downvote for trying to be informative :-) And than you for the rebuttal, cause I had totally abandoned php a couple of years back for many of the reasons in my link
Not sure why, but what's your rationale for stream=True? Why not use data=&lt;file&gt; instead?
Very nice one, thanks.
&gt; PHP and Perl are not scalable languages for large scale projects This has been proven wrong over and over again, which is why I listed those sites that get major traffic. &gt;Just because there are some big places that do use the technologies does not mean that it's automatically right. And just because you had a bad experience with them or you've read something negative doesn't make you the subject matter expert that is definitively correct.
Had seen it [here](http://stackoverflow.com/questions/16694907/how-to-download-large-file-in-python-with-requests-py) I'll try it with data=&lt;file&gt; instead :)
Have you actually used all those languages professionally? I have professionally worked with all but python, and I can point out cluster-fucks and issues with each of them (more so for JS and C++). https://wiki.theory.org/YourLanguageSucks
Just because you CAN do it doesn't mean you should. It's feasible to code a site front end in and it would be fast, but it would be difficult. Again just because large companies do it in a particular way doesn't automatically make it make sense. As far as bad experience goes, I'm first and foremost a Perl programmer. That's where most of my expertise is. That does NOT mean Perl is a good language for things that don't suit it well, such as development projects amongst large teams. The same goes for PHP.
try timeout=60.0 with requests or use socket.setdefaulttimeout
http://www.gevent.org/
with is really useful when you have a file of unknown length, it's large, and has a screwy/no end condition. It prevents the infinite loops of: f = open(fname) while 1: f.readline() This is better: with open(fname) as f: f.readline() 
Yay, finally works. Thanks man :)
Why is this better?
actually they are. They expose a static interface to a statically held instance of the application. Basically the facades expose an imperative interface over a reasonably object oriented one.
I too have used all but Python professionally. Most of them quite extensively. They all have their problems, but PHP is the only one that made me want to burn the building down while running a development team on a multi-million dollar project.
I thought of that, but he's publishing the graphics in GIF form.
Very good, thanks!
I had at least heard a little about most resources mentioned here but had no clue about Houdini. Thanks. I guess Houdini is how they do many special effects that require procedural generation and the like?
Good, thanks. I have heard mixed opinions about OpenCASCADE but it really is an impressive amount of work.
Minor nitpick... where you refer to \_\_open\_\_, I think you meant \_\_enter\_\_. [Edit] Fix auto-format.
Thanks for the links and for giving your work to the community! Do I understand it right that I can basically build an exporter to Nastran using pyNastran? Does it require Nastran installed? Why I need this: my script takes geometry from AutoCAD, physical parameters/features from a 'model file' (essentially a .ini-style tree of parameters about materials, BCs etc.) and builds a common FEA model that can later be exported to FEA formats (our locally available LIRA format is implemented and Autodesk Robot is in the works with ANSYS and Abaqus planned). Including Nastran in this would be cool.
Will use some of the SymPy examples, thanks, good list.
Thanks.
nope, they dont hold a static instance. The Application class does hold all instances of the IoC and not as a static
Ah, tricky tricky! I mistakenly thought it was a file into which the response was to be stored.
Odd that it never raised an exception...
True indeed. Maybe the default timeout is so big, that I just restarted the script earlier than it could appear...
If you need an IDE to not pull your hair out over a language, **that language is bad**.
I am not sure I 100% understand the question. I believe you can do: a = "USD" b = "EUR" vars()['%s%s' % (a, b)] = 123 print USDEUR
What I'm asking is can I do something like: %s%s = 1 % (a, b) to set the variable name as the concatenation of a and b?
 &gt;&gt;&gt; a = "USD" &gt;&gt;&gt; b = "EUR" &gt;&gt;&gt; locals()[a+b] = 1.234 &gt;&gt;&gt; USDEUR 1.234 
5 minutes i believe
No, that is not possible. In fact, I would be surprised if any major programming language allows anything like that. There should never be a reason to dynamically create or rename variables. Attributes and functions, perhaps, but not local or global variables. If you need to do something like this, you should definitely use a `dict`.
Oh ok. I tried your code and it worked, and I understand it now. Thanks!
It's possible because `locals()` and `vars()` are `dicts` that act as proxy objects for all local variables. It's considered very, very bad style to manipulate variables through a dict like that. I meant it's not possible to dynamically create variables as the left-hand side of an assignment. Also, I would consider bash a scripting language, not really a "major programming language."
Just how big are these files? You should only need to read the content in chunks if each file is over 1 GB (or if you have more than 4 GB of RAM, probably 2 GB). If it's smaller than that, you're better off reading and writing the downloaded content in one big chunk.
What are some possible downsides to using those dicts to manipulate variables? Yeah Bash is more for scripting but it is definitely a programming language. It's just not object-oriented. I mean, C is a programming language... Happy cakeday btw
ELI5?
at least provide as big of a chunk_size to iter_content as you can afford, otherwise it'll go incredibly slow copying byte by byte
Thanks :) &gt; I can basically build an exporter to Nastran using pyNastran? I'm not sure what you mean...If you're working with the BDF, you can read in a BDF, modify (e.g. change cards, add cards) and write it. There's also just a print_card function that takes a list of the card's fields and will format each field correctly based on the type and will handle blank fields on the continuation lines. If you just want to loop over a cloud of points and write some GRID cards, this is how you'd do it. from pyNastran.bdf.fieldWriter import print_card grid = ['GRID', nid, cp, x1, x2, x3] f.write(print_card(grid)) It will also interface with the OP2 in PARAM,POST,-1 format assuming you don't dump a bunch of matricies to the OP2. SORT2 isn't supported. Nastran is not required for anything and most of the cards up to MSC v2005 are supported. There a lot of solution 6xx/7xx cards that aren't supported. Most of the standard 1xx/200 ones are.
I guess. I use bash for everything. Yeah, I'm still very new to Python. I completed the Codecademy course on it though :P
I edited my comment a bit to provide some more details, and an example. I use bash for a ton of things, since I'm in need of quick scripts quite often when I'm on Linux, but you need to get into a whole different mindset when writing Python. tl;dr The Python documentation specifically says that modifying an item in the `locals()` or `vars()` dict may not set a variable properly. So not only shouldn't you do it, if you do do it you may break how Python even executes the program.
I'm confused. For a ASCII/unicode file that doesn't have 1 billion characters on a line (probably &lt;80), f.readline() is fine. f.read() is very rarely used for parsing a reasonably formatted ASCII/unicode file. For binary parsing, f.read(nBytes) is standard. with automatically terminates.
with automatically terminates at the end of the file. f.readline() will go forever as it returns an empty string if there is no line, which sometimes is correct (e.g. you stripped the line to ignore blank lines), other times is not. It's a bad idea to use the first option unless you always have a clear terminating statement and even then...
Is there a better way to do what I'm trying to do? I basically want the equivalent of the following in Bash: ${var1}${var2}="string"
I know nothing about Nastran internals so I looked up BDF a little. If I can wholly define say a building's structural model with BDF, then it's basically a yes - I can convert my model to BDF format to be 'natively' read by Nastran.
My name is Phil Sturgeon and I promote this message. 
What do you mean "automatically terminates at the end of the file"? Are you talking about like a socket? I don't think `f.readline()` acts differently in either case.
If safety is no concern, try using eval("%s%s = %s" % (a, b, 1.234))
Do you understand what the symbol table is? Do you understand what a dictionary is? a = 'USD' b = 'EUR' conversions = dict() conversions[a + b] = var / 1.2345 you are using the dictionary conversions as a place to store a bunch of things by name. 
does the url railstodjango.tumblr.com give you any clues? 
Did you read my huge wall of text? Read it again.
Thanks, should be fixed.
Sorry, not cross-platform.
Ha, it does now. 
I've looked at celery but what I'm trying to replace is a small component of a much larger system. Celery would require quite a few more new systems plus the processes (which are external programs, not code run in processes) need to fit into celery's general design.
See also the /r/learnpython sub, it's pretty active 
Hmm, this kind of fits what I'm looking for but can't say for sure without testing. The general issue I've faced is that when most people refer to distributed processing now they mean code running inside of processes which isn't what this is. Nonetheless, this might be something I can adapt, thanks for the suggestion. 
Alright, so let's say f.readline is the way to go. Then still you don't have a break statement in your first code (add something like ``if line.strip() == '': break`` and assign the return value of f.readline to `line`). Secondly, with still has nothing to do with opening large files. Your second code sample won't terminate, it's an infinite loop (like the first code is as well). Just try it out yourself.
&gt; Your code is ugly! I'd 100% disagree. It may not be the most beautiful code but: it's simple, each function is delegated a single task and there's no ambiguity to what they do.
Why so many downvotes in this sub? Not just this post, but all of them. Most posts have a karma count in the single digits.
The power of Assembly.
No. Just no.
It looks like your trying to do units... probably not the best choice, but better than doing crazy conversions https://pypi.python.org/pypi/units/
And that only works intermittently, too. Really the whole problem is just a badly-formulated question.
Question: If you're dynamically creating variables, how do you expect to access them? Answer: Dynamically. --- By the time you accept that if you're having to do `globals()[x] = y` to set a variable, you have to do `globals()[x]` to access the variable. By that point there's nothing to prevent you from doing `my_dictionary[x] = y` and `my_dictionary[x]` which are **safer, faster, easier and more powerful**. There is **no** reason to do what you are doing.
You aren't a bot, nor are you funny.
What *are* you talking about? I think you're exaggerating. &gt;&gt;&gt; for i in 42: print i ... Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; TypeError: 'int' object is not iterable Here you go, an "object is not iterable" error without "C extensions screwing up royally. Add a printout or two in that place (or `pdb.set_trace`) and you'll figure out what `sys.modules.items()` really is. 
don't use `locals()`, ever.
gpio pin + raspi + python + selenium IDE/firebug + selenium webdriver http://www.cl.cam.ac.uk/~db434/raspi/buttons_and_switches/ http://www.youtube.com/watch?v=JM4GldTw_Cw it is a pretty easy way to go about automating exactly what you are talking about. 1)get python to recognize the button press 2)with the exported python selenium webdriver ... open up pizza ... place order ... 3)???? 4)profit
well this is where fire bug would come in. Each of the items should have some kind of xhtml to designate what type it is, or with selenium you might be able to go through and put each of the toppings on a pizza and record each of the actions. Selenium IDE is an addon that can be used in firefox that can be used to record button clicks, field filling, typing, navigating, etc. etc. so you hit record and then record the actions to be automated. When you are done recording you can export the actions and replay them from a python script.
You could do that, but it might be easier to just record it all at once and splice it up in python from there.
Yes but unless someone is overriding sys.modules with an object that has an items() method that returns an unrelated object, this is pretty impossible. And the h5py codebase does not touch sys.modules. Also most of the time I get a hard crash, no traceback. And it's probabilistic, only happens once every 100 runs of a function in another thread or so, so obviously threading related. Pretty sure it's the h5py cython extensions releasing the GIL prematurely, or possibly Cython itself. There are bugs like [this](https://mail.python.org/pipermail//cython-devel/2011-August/001292.html) that have been found in Cython. That and the StopIteration exception that is used to end iterators (I'm iterating over h5py objects in other threads), I think could lead to this. 
GIF itself is disputed with copyright claims, so that makes it worse.
and the failure is that it needs manual bookkeeping if the secret is entered or not 
Do you have a link maybe? EDIT Never mind, it's probably [this if anyone is interested](https://github.com/fogleman/Minecraft).
From round 100 kB to several MBs, so you're saying I should download it in a big chunk?
Have you considered someone might read this tutorial (which is teaching an out of date medium like SOAP) and use it, releasing insecure code into the work place?
Except the syntax changed to `with EXPR as VAR:` by the time it actually made it into the language.
Fully agree, I was merely stating it in the "we shouldn't settle for a already better than the rest attitude" way.
It's been at it for 24 hours a day, so I'm not sure about that "not a bot" thing. I'm impressed that it apparently passed the Turing test.
*sigh* you're not understanding what I'm saying. 
[urllib2](http://docs.python.org/2/library/urllib2.html)
When indexing or slicing a sequence, I don't like that in [start:end], the "end" is NOT inclusive.
Some thing like (at first look seems an ambiguous): &gt; range(10)[-3:-6:-1]
super()
I feel you, "no one should ever have to use urllib2". try [requests](http://docs.python-requests.org/en/latest/)
Performance. It makes me sad that javascript in a browser is faster than my server code. 
&gt; significant whitespace I've heard people complain about that in Python but honestly haven't run in to it as an issue. Do you think the language would be better with curly brackets?
1up for requests. Probably my favorite non-standard library. 
Is a **switch** statement too much to ask for? 
I usually only run into it when working on code with other devs and they use a different editor, it does get frustrating lol.
I've never liked that joining a list with a string separator is done using: " ".join(a_list) I feel like this would be more logical: a_list.join(" ") Though maybe there's a reason behind this which I don't see.
Mandate `python -tt`, it will error out any time tabs and spaces are mixed. tabs only is fine, spaces only is fine, both is not.
I'm pretty sure the question was not intended for people who hate the language itself.
I agree. If I have too much whitespace I'm probably doing it wrong and writing spaghetti code
I like that. I think it reduces the times you have to add or subtract one. Dijkstra made a nice [argument](http://www.cs.utexas.edu/users/EWD/transcriptions/EWD08xx/EWD831.html) for it.
Lack of a "repeat...until"/"do...while" type construct. Simulating one with "while True...break" is just ugly :( 
Unicode in 2.x
The `switch` statement in C and other languages is basically a performance optimization. In Python it's not going to be any faster than a bunch of `elif`s. It might be a tiny bit clearer syntactically, but is it worth adding more complexity to the language and implementation?
Gross
"while" will do that: a = 0 while a &lt; 10: ... a += 1 Edit: It has been [proposed multiple times(PEP 315)](http://www.python.org/dev/peps/pep-0315/) for a true do...while loop, but has been rejected each time. 
Fixed in python 3!
Since it is all instructions in the end, you could say assembly has the same functionality as Python and it was here first. Why do we need Python? That is a bit of an extreme comparison I used, but the idea of people wanting abstractions shouldn't be lost on other Python users.
do...while is used for rather different purposes, though. "While" loops under a certain condition, "do...while" loops *at least once*, then continues looping under a certain condition.
Have only use BautifulSoup 4 out of that list, and I agree it is very handy as well. 
What is unclear about an if tree? 
It's just my opinion of what I don't enjoy not having. I understand the arguments for why it is not there, it's simply something I find bothersome. 
I lost track of py3 dev. are you referring to PEP 3135 or something else ?
I always think of it as the slice point being before the list item with the same number, so the way Python is makes a lot of sense to me. If: List : |0|1|2|3|4|5|6|7|8|9| ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ Slice: 0 1 2 3 4 5 6 7 8 9 10 Then: list[:4] = |0|1|2|3| ^ ^ ^ ^ ^ 0 1 2 3 4
I don't hate Python. Every programming language sucks in one way or another; these are the parts at which Python sucks. I could easily come up with a much longer list of things that I *do* like about Python.
you listed nearly every distinguishing feature of python.
I'm a big fan of significant whitespace, but I wouldn't mind seeing support for brackets. There are cases where a one-liner really is the best solution.
I am absolutely sure with brackets I can read any kind of code faster and more efficient. I asked this lots of developer friends. Nobody else was complaining about the whitespaces. But I can't even read it at all. :(
No arity discrimination for functions.
**hammock** import hammock api = hammock.Hammock("http://httpbin.org") print api.ip.GET().json()["origin"] **clint** from clint import grouped for group in grouped: print grouped[group] **PDFMiner** pdf2txt.py -y -o out.xml doc.pdf This will create an xml file that you can then open with BS4 and attempt to read. I have been able to read some files this way and extract the contents in order.
I use urllib2 if I'm just opening a page, say to download an image or scrape with beautifulsoup. 
Any discussion of relative performance across languages pretty much begins and ends with 'it depends'. I'd dispute the assertion that Javascript is unequivocably faster than Python.
I understand why, but no assignments in while loops. 
&gt; GUI support (that everyone can try without having to sacrifice a leaving creature to get running) Dropbox seem to do just fine... 
Python 3. The fact that Python 3 is not backwards compatible, and all the confusion it has created has not been beneficial to Python. I think Python would be better off without the entire 2 to 3 discussion.
Significant whitespace does seem to be pretty central to the whole concept, though.
There's a bug in your switch. It doesn't break, so 'a' will cause do_a, do_b and do_all to be called. This is one of the reasons there's no switch. Besides, you can just do map = { 'a': do_a, 'b': do_b, } map.get(var, do_all)() Much easier to maintain imho. 
What exactly is wrong with it?
&gt;community members with an attitude You'll get that any where. Python guys are certainly more friendly as a whole than PHP. I can't speak from experience, but I've seen some ridiculous slap fights come out of Ruby/Rails, too. Don't let a few bad apples spoil the bunch.
It's still a struggle for me to think "try..except" instead of "try..catch".
Dropbox is not the rest of the world, they have a bunch of people to make sure it works fine. I meant to say I'd like it to be as easy as requests.
What do you mean?
The lack of multi-core support and the problems associated with a GIL.
In my dream world it would auto break at tab (just like functions auto return or loops auto exit.) I also might want to just do something inside the switch statement instead of making a separate function for each call for some, and call functions for others. 
Enum. Of all the things that need fixing in 3.4, duplicating namedtuple was not one of them. There should be one, and preferably only one, obvious way to do it. 
It does not automatically reference the parent class. Before python 3, how it was used is not very intuitive, especially for new learners. 
I wish `list` accessor methods supported default values. x = ['foo', 'bar'] # I wish I could do this x.index('foo', None) # Instead of this. x.index('foo') if 'foo' in x else None # And this x.get(10, None) # Instead of this x[10] if len(x) &gt;= 10 else None
Fair point. I'll try using requests more. PRAW uses it, so I have it installed anyways.
The name. Snakes scare me :(
facepalm with your canonical switch bugs in there :D pythonic? try C-ic. Your broken switch stament has 7 lines vs 6. Fixing it w proper break stmts makes it longer. I agree though, switch has it's uses for clarity sometimes.
&gt; I don't hate Python. Significant whitespace and dynamic typing are core parts of what Python *is*, if that's how you start your list I fail to see how there could be anything for you in Python.
Scope -- Python's weird scoping rules prevent a function from modifying an outer variable. The following code is not legal: def counter(): x = 0 def counter_generator(): while True: x += 1 yield x return counter_generator This is kinda solved in Py3 with the **nonlocal** keyword, but not completely. Statements vs expressions -- Really?! I'm glad `print` has become a function in Py3, but why make the distinction in the first place? `yield` should have been a function. Grrrr. Significant whitespace -- I used to love it. Now I'm not so sure. A few weeks ago I spent a whole afternoon trying to locate an error coming from a missing indentation that occurred during a copy/paste. Did you know that Python's `for` accepts an `else` statement? Can you spot the potential disaster if you in/outdent it a bit too much here: for x in something(): if a_test(): do_it() else: done() Limiting lambdas to one statement -- I know it's done for a good reason, and I know abusing lambdas can create pretty unreadable code. However, I'd prefer getting greater power and greater responsibility. It would be more consistent with Python's "we're all consenting adults" attitude. Recursion Limit -- It's kinda related to the first complaint. I want proper lexical scoping and proper tail call recursion (at least tail call) implementation.
Your second example could also be said: functions = { "a": do_a, "b": do_b } functions.get(var, do_all)() Edit: lol, sorry /u/f-boender, I didn't see your identical comment. 
OK, here go the good things. * mostly consistent * shallow learning curve * very little boilerplate required * powerful dynamic features * simple object system * list comprehensions, almost as good as Haskell's * decent standard library * huge community * lots of libraries on offer * decent package management * real first-class functions * good cross-platform support * good tooling support * deterministic garbage collection that doesn't leak (compare: .NET/Java -&gt; not deterministic; PHP -&gt; leaky) * consistent and useful error handling * awareness of the fact that array-of-bytes and string are not the same thing * awareness of the fact that it is not acceptable to automatically promote integers to floats when they overflow * high availability * nice module import features with lots of control (although *writing* modules is a different story...)
&gt; * `namedtuple` is nasty. I cannot believe it is part of standard library. Do you mean the class itself or the implementation? 
Yes. As some elements change, and it might be easier to pull out the class of the element and navigate to it with something more permanent. This is what it would look like with pizza hut, sort of. http://pastebin.com/fBcEzrY1
I've always thought that join should just have been a function. join(iterable, string) Perhaps they were worried about polluting the global namespace though.
I'm a fanatic camelCase hater and dedicated PEP8 supporter and I think you can guess which parts of stdlib I do not like. I understand backward compatibility, but Python 3 missed such a great opportunity to get things straight here. EDIT: oh, and remind me to say few words about Twisted in the upcoming "what do you not like in a 3rd party module of your choice" thread
PHP guys aren't less friendly, there are just too many among them who are clueless. Python developers at least have the basics of programming down, mostly. In PHP land, the problem is stupid people; in Python land, it's being too much in love with your language. And Ruby is actually worse than Python in that regard, I think, although I must admit I think the language itself is slightly better where it differs.
Modern languages `switch` generally don't fallthrough (either at all or on non-empty cases).
Might be fixed in Python 3 if your problem is the `type, instance` syntax: in P3 it's `type as instance`
I find it amusing you think it's broken / needs breaks and it doesn't even exist. I am proposing one that auto 'breaks', just like an if statement ends after it's no longer indented. Also python is very clear that shorter code != better code. I think a single extra line that removes a lot of overheard code (n * 'elif var ==') is worth it. 
the implementation in CPython.
len(var) instead of var.len
Meh, I don't necessarily agree. Dynamic typing is awesome in a lot of situations, but there are times where it's convenient to enforce that a certain variable must be of a certain type. Feeling that way doesn't mean someone hates Python.
Hmm, don't think so. It's one of many design decisions, and I see where it came from: it simplifies the syntax. I just happen to think that this particular decision made the syntax *too* simple, removing essential expressiveness. It also makes refactoring more error-prone and manual than necessary. I think Ruby got this one slightly better - throw in an explicit end-of-block marker and optional (optional!) curly braces, and you get most of the benefits (very little optical clutter) without the problems (Ruby can be re-indented unambiguously, mostly).
 * A better built-in REPL. I would be happy if bpython or ipython became official version. * Pattern matching, or at least a basic switch statement * a built-in lazy list (it would fit perfectly in collections). * Support for tail recursion would be cool (possible through a decorator like Scala)
they are not. switch var: case "a": case "b": do_something() break case "c": do_something_else() default: and_execute_me_if_c() vs if var == "a" or var == "b": do_something() elif var == "c": do_something_else() if var != "a" and var != "b": and_execute_me_if_c() The switch statement is superior in some cases.
&gt; you have to look at every line You can make the same complaint with a switch statement, complaining about enforcing a break with every case
Most of my pet peeves have been mentioned already. As someone that used to maintain projects with hundreds (or more?) of modules, I grew to hate the import mechanism because of how easy it was to introduce a circular import.
Yeah, it's a bit icky. I'd really like to have the execution speed form modern javascript VMs in python... and still be able to use the various libraries I need.
Well, see my other list then :)
Awesome! You have been a very great help, thank you so much!
I think he probably doesn't like that lambda is not multi-line.
I would argue that C's implementation of switch is the bug. Dropping into the next case is weird. The problem with the map solution is that it is much more limited. It doesn't allow me to match against a mutable structure like a list, or against a range of values at once. Some languages (e.g., Scala, Rust, Haskell) have some pretty awesome pattern-matching syntax that would be neat to see in Python
&gt;The lack of multi-core support That's not entirely true, we just have a harder time 'cause we need to use multiple processes.
I think its implementation was for speed reasons, although this is a memory of the top of my head.
Just use `multiprocessing` or `futures` - in 90% of cases it would be a better way to go even if GIL didn't exist. Which reminds me (regarding the thread's question): `multiprocessing` could be way much better: Ctrl-C handling, no cryptic tracebacks on some errors, no stray processes (they happen even in non-daemon mode) and possibility of relying only on COW semantics under sane operating systems: I understand the arguments must be pickled under Windows, but I use Linux and don't want that - and definitely don't want to see the dreaded `__builtin__.function` error. It kills me every time.
Actually 2.x (at least 2.7) accepts this syntax as well.
That's a non issues considering you can just softwrap lines longer than 80.
I'm surprised this wasn't already posted here. I can't believe Python has not one, but two confusing date and time libraries (looking at you "datetime" and "time") and you need both of them to do many time conversion operations, and more if you want timezone support. Until I found [arrow](http://crsmithdev.com/arrow/), this was my most hated feature of Python and the one that left me consistently ranting whenever I needed to standardize a bunch of datetimes to UTC and get a timestamp back out. Any other lib in Python it'd be an object and a few methods, and indeed, arrow seems quite Pythonic.
I didn't even know about `namedtuple`. Can you just use `OrderedDict` in its place? Every time you need to return a sequence from an `OrderedDict` represented by `x`, it would just be `x.values()`.
&gt;for-loop syntax is not the same as comprehension syntax. Explain? &gt;lack of multi-line, real lambda. There's no more excuse, CoffeeScript have shown that it can be done. CoffeeScript has in my opinion a very crippled syntax; it tries to be more flexible than it is and in result often acted unexpectedly. For something like Python, a CoffeeScript-like syntax is too far. I admit multiline anonymous functions are overdue, though. Unfortunately there are strong practical reasons why they won't be here soon. 
You might be able to find corner cases where python code running in the cpython VM is faster than javascript running in V8, but python is lagging far behind in actual execution speed of actual python code. You can improve the speed of your python app in a couple of ways: * Move CPU intensive operations out of python and into native code or native libraries. Use a web server written in C (uwsgi) instead of one written in python (gunicorn). * Use one of the alternative python VM or compile-to-native solutions. But then you've stepped right into the python platform fragmentation problem. For scientific stuff, numpy is a beautiful example of the former and will chug through gigabytes of data at amazing speed. PyPy is, supposedly, a great python interpreter with quite passable performance. Unfortunately, these two are incompatible.
Why do you care though? Namedtuple is an internal library that's tested and can be used as a black box. It's designed to be performant and that's why it's implemented the way it is. 
I believe that PyPy often helps. Unfortunately that leads us to the other thing that I don't like about python, which is the horrendous platform fragmentation. PyPy runs only python 2 code and is incompatible with a lot of libraries, which have been written in C to avoid the horrible performance of actual python code. In particular, my python bottle necks are in matplotlib plotting data read with numpy from large binary weather data files. PyPy is incompatible with both.
0) the fact tat distutils do not ship with python. 1) Most of the un-necessary purely syntactical changes between 2.x and 3.x for example as "except E,e" became "except E as e". unicode became str and str became bytes. 2) The fact that (pickle.dumps(x) != pickle.dumps(pickle.loads(pickle.dumps(x))) 3) The fact that sys.path is global. Sometimes I would like a part of my code (for example in a thread) to import from a different sys.path than the rest of the code. 4) lack of a sandboxed environment.
I'm sure my code has some problems - all code does. But the overall system bottleneck is inside the (awesome!) matplotlib library which isn't my code.
I think that `Enum` was the only non-hack solution suitable to backwards-compatibly patch the stdlib, and that `namedtuple`s are vastly underpowered relative to what `Enum`s can do.
`for-else`?? That is crazy. I don't understand it. I get you on the statements vs expressions...but a lot of the things you mention here are coming from the perspective of a functional programming afficionado, whom Python doesn't purport to support.
But it's not "python" of the Burmese variety, it's "python" of the Monty variety! Probably less scary that way. Probably.
Think Monty Python, which python was named after. The origin of [their name](http://en.wikipedia.org/wiki/Monty_Python#Development_of_the_series) is: &gt;There are differing, somewhat confusing accounts of the origins of the Python name although the members agree that its only "significance" was that they thought it sounded funny. In the 1998 documentary Live At Aspen during the US Comedy Arts Festival, where the troupe was awarded the AFI Star Award by the American Film Institute, the group implied that "Monty" was selected (Eric Idle's idea) as a gently-mocking tribute to Field Marshal Lord Montgomery, a legendary British general of World War II; requiring a "slippery-sounding" surname, they settled on "Python". On other occasions Idle has claimed that the name "Monty" was that of a popular and rotund fellow who drank in his local pub; people would often walk in and ask the barman, "Has Monty been in yet?", forcing the name to become stuck in his mind. The name Monty Python was later described by the BBC as being "envisaged by the team as the perfect name for a sleazy entertainment agent".[14] 
In most cases you can use a dictionary, but there are a few edge cases like trying to compare against a list (or other mutable object that cannot be used as a key). Some languages (e.g., Scala) allow partial matches (I may only care about matching the first item of a multi-item tuple). Admittedly this isn't something that comes up often. The problem with iterators is that they are single use. There are times where I would like to have a list that I can iterate over multiple times, but I'd prefer it doesn't actually generate a specific list item until I actually require it. I'm mostly happy with Python, so these are somewhat nitpicky/niche features.
&gt; Speed (I know theres pypy and numpy) If only the two were compatible...
For gui check out kivy
Wow That's ugly.
Who's to say 80 chars is half of my screen or two of my screens unless I'm not working inside a window manager of some sort?
That's NASTY.
The module system. Classes. About half the code in the standard library. The difference between `is` and `==`. Methods as descriptors rather than a directly supported language feature. Lack of support for defining new immutable objects. Pickle. Inconsistent behavior of augmented assignment. No separation between variable binding and assignment. None of these things *prevent* writing useful code in Python, but they all get in the way of nice things at one time or another.
CFFI. So useful.
It promotes use of multiple inheritance, which often leads to poorly designed code and difficult-to-maintain code.
Dropbox also has Guido
&gt; Did you know that Python's for accepts an else statement? Ha! Yep! I actually really like it since I found out about it. I don't use it a lot but it can come in handy. Personally I rarely if ever have indentation problems. I'm always super paranoid about it when I copy/paste code. However, I'll take it over trying to find the matching brackets that are nested in other brackets problem of other languages.
because it also catches unexpected exceptions and do not re-raise them?
[Built-in Functions](http://docs.python.org/2/library/functions.html). I'd love it if someone could give me one rational reason why this is a good idea, because I'm pretty much convinced this is terrible and is the bane of my existence when writing Python.
`for-else` is kinda fun. Threw me for a loop when I found out about it. [Here](http://docs.python.org/release/1.5/tut/node23.html) is an example from the Python documentation.
Kivy seems to only support non-standard widgets. (Is this correct? Where are your usual buttons, lists and tool bars?). That's cool for games, but less so for everything else. I like PyQt very much.
This is surprising at first but it's much more consistent. Consider that for any `i`, `j`, and `k`, `sequence[i:j] + sequence[j:k]` will produce the same as `sequence[i:k]`.
IMHO, a regular class with __slot__ is better than namedtuple
I strongly disagree. Python 3 was a necessary step that had to be taken. You can't evolve a language without breaking backward compatibility every now and then.
Yeah, I know. It's just not as readable in my opinion, if you're scanning through **test**, see a function definition out of nowhere, and then finally see what it is bound to later on.
For me it is more obvious. I can see it is doing a get request and returning the text from the reply. From here I can do a post by changing to: post_reply = requests.post("http://example.com/", param={"msg": "python rocks"}) or I can extract the json object if it's a json reply: json_reply = requests.get("http://example.com/").json() 
or better with parentheses. long live lisp! ;)
&gt; slightly too simple object system Really? I happen to love the monotonic inheritance system for classes. For objects, the only thing I can think of that you might be referring to is the way object attributes can shadow class attributes. &gt; crippled functional-programming features (lambdas, currying, pattern matching) Lambdas exist in the language. Do you mean you really, really want to have anonymous functions, defined inside expressions, and whose bodies can themselves contain statements? Currying exists in the standard library and in the special case of method lookup. I suppose you want SML style single-argument uniformity though. &gt; tuple syntax edge cases You mean `(x,)`? What alternative is better?
Why not just define a local function? But I agree, Lua-style function definitions would be very cool! (in Lua, `f = function(x, y, z)` is equivalent to `function f(x, y, z)`, which means that `sort(list, function(x, y) ...)` works as expected)
expand 
Yep, I hope he gets some of the tooling they have in there out to the rest of us.
PyPy is working on its own implementation of Numpy, and a recent blog post said that they are even working on Scipy/Matplotlib compatibility. Man, I am looking forward to that!
Matplotlib can be amazingly fast, actually: http://bastibe.de/posts/Speeding-up-Matplotlib.html
Nerver heard of it before, sounds neat.
The exact same way: list[2:4] = |2|3| ^ ^ ^ 2 3 4 
Tabs it is then!
Explicit self. I don't do it often, but installing non-standard libraries is always an adventure that involves finding a new library installer, (e.g. easy_install, distutils, pip, don't remember the others but it seems that every library i've ever installed has used a completely separate installer, which seems to defeat the whole purpose) figuring out how to target the python version i want, messing with path variables, and various related mess. It would be great if I could just drop a zip file in the designated folder of a python instance to install a library.
Pretty sure yield is a function in Racket. It is possible in languages with continuations.
I'm aware of the lack of COW semantics for `fork()`-based OSes. What's the `__builtin__.function` error?
What do you mean by sandboxed environment? Does virtualenv not cut it?
I don't assume that you're using python to build websites. But one of the ways in which you can speed up your python code by avoiding python code relates to web sites. In my particular case, that's not where the bottlenecks are, so I'm happily using gunicorn even though I could get much better performance from a web server written in C. I'm not advocating using nodejs. I find the whole idea of javascript creeping into the server to be distasteful, but it shows the sad state of python performance when javascript has become faster. And sure, I'll grant you the "it depends". And you can use pypy for added speed or you can use one of the compile-to-native solutions or that llvm-based thing that I'm going to have a long look at when I have the time. But when you go down that path, then all bets are off with regards to compatibility, especially for native libraries. This problem is much worse than you'd initially expect, since so many libraries are written in native code to avoid the horrible performance of actual python code. Finally, I get to choose the fastest javascript VM for the comparison because I get to choose the fastest javascript VM for deployment. If I try to deploy pypy, then I lose numpy, matplotlib, netcdf and most likely a bunch of other things. So in general, you're often stuck with CPython. And specifically, *I* am stuck with CPython.
I personally like tabs, since it requires less key presses to delete than spaces.
I agree. If you think of it as "Length is a property of var", then it should be var.len or var.len()
Yeah... that'll be *awesome*. The PyPy guys are doing some impressive work. There is just so much of it to do :-)
&gt; for-loop syntax is not the same as comprehension syntax. It's not? In what manner, besides scoping? &gt; Maybe it's time for CPython to start thinking about performance. e.g. function inlining. &gt;&gt;&gt; from timeit import timeit &gt;&gt;&gt; timeit('foo()', 'def foo(): pass') 0.11308157473016102 &gt;&gt;&gt; timeit('a', 'a = 1') 0.02448077242139668 Function calls are about four times as expensive as a global name lookup. If there's something you need to be so fast that inlining actually helps, you'll also want to perform other optimizations as well. The effort of implementing (and maintaining) this optimization in such a dynamic language is not worth its limited use.
A small thing, but try: ... except: has always annoyed me. It would save me valuable seconds of confusion if it were try: ... catch: which I see as more standard and intuitive. Also, I dislike manually putting the 'self' in foo(self, ..) member methods every time. Can we just assume that if its in a class, its a member method?
I don't like decorators, they're an ugly addition. Also I don't like the way that proxy methods are used when an object is instantiated from a class. Not sure how to solve that one, but I found them confusing for quite a while and think there must be a better way to do them that doesn't mean changing to a prototype-based language.
The slow adoption of 3 (2 was just that good I guess) There are some modules yet to be ported to 3.
`for-else` is easy: The `else` runs if the `for` fails to reach a `break`. for x in nums: if isprime(x): break else: print('None of the numbers you gave me was prime')
I'd love a proper sandbox in Python. Something that can execute potentially malicious code without worrying about side effects. I know there have been some valiant efforts, but last I looked, they all had holes.
In [the first question of this Q&amp;A](http://youtu.be/YdxXqc2Npls), Guido says that they made `yield` as an expression (and generally designed the generator model that way) because of the limitations of Jython. It would've otherwise been a function instead of a keyword. I think it's pretty cool that alternative implementations are taken seriously by the Python devs, to the point where it affects design choices. But I maintain that having this distinction between a keyword and a function, or more globally a statement and an expression, is a pain.
Yes, because I want to do different things depending on the arity. I could match the "arity" or star args to an internal function of course, but I'd like to be able to do it the Java way too.
That its named Python, not Kittens.
I believe Tk made significant visual improvements in 8.5
Count me surprised. Do you have a timestamp for that part, btw? 
But there is a notion of sequence that is preserved in a tuple which it is not with a class slot.
Oh I see, so it's there for when you don't break out of the loop. I wasn't clear on its usefulness if there wasn't a break in the looping construct.
But then how would you store nulls in a list?
The simplicity and elegance of the syntax and the massive library of modules is what makes Python wonderful; adding optional static typing wouldn't change that.
Thanks. Without assuming there was a `break` in the `for`-loop, I had a hard time imagining why the `else` was useful.
Python 2's *my* pet peeve. Why the hell does it have to be so different to Python 3!?!
BTW, in case you're curious, [these are the plots](http://demo.belgingur.is/island-9.html) that could use less CPU cycles. At least we've done away with the on-demand-rendering tile server now. You could feel the floor above the computer room heat up when that was active.
After a semester of tutoring Python to intro CS students... not declaring variable types. It throws so many people off.
I notice the author doesn't bother to define what exactly a "scripting language" is. (Probably because it's an ill-defined term) If he's going to use the vague definition of "a language primarily used to glue other programs together", then I've never used python as a "scripting language". (And I've been using python for years here) and I'm not even sure python is really a "scripting language" under this loosey-goosey definition. (And Javascript definetely isn't, since you know, it almost always is the only programming language it can see since it's bound to the browser) Php fails this definition too, since (as far as I can tell) it's normally the only programming language running. (It of course returns html that might contain javascript, but I hardly think this counts as acting as "glue") In short, under what I think he wants to define it as, few to none of the languages in the picture in his post are "scripting languages". In short, the term "scripting" is a stupid and meaningless one. 
Because he's old and senile. At this point, he doesn't even know what he's doing or where he is anymore. Cut grandpa some slack please.
after writing js for a while, I always accidentally do .len ...though to me it would feel better to have it be .len() since it has to "check" the length since some iterables can change length after instantiation. also, it would be nice to do range(var.len) instead of range(len(var)) for sure
That's what I tell myself. 
Now you've got two ways to join sequences and people will learn the more limiting one for no reason.
That's silly. Both statements are perfectly clear so there's no reason to prefer one over the other (your past experiences with other languages doesn't count)
spacespacetabspacetab!!!!
How does significant whitespace make the language less expressive? It's just a syntax to indicate where blocks end. I don't really see how it has anything to do with the expressiveness of the language. Adding an anecdote, I've literally never had a problem refactoring due to whitespace.
*" But I can't even read it at all. :("* Perhaps...you should get some glasses then?
I wouldn't go so far as "crippled" but I do agree that CS feels too loose at times. While there is a FAQ now with some recommendations, I think a PEP8-style list of conventions could be helpful. I know it'd be easier if I used it more consistently, but I feel like there can be a bit of mental overhead on deciding when to use parens, curly brackets, etc.
Because when I create my objects I can't simply implement these as methods if I would like to support them. Instead, I have to hack builtins and override for my object type, or actually implement them as methods and be inconsistent with built-in objects. The reason this is important: implementing common interfaces, or duck typing. An example: object.__len__(self) &gt; &gt; Called to implement the built-in function len(). Why not just make the default object.len()? What purpose does it serve to create a built-in function that I have to create some "hidden" method that it can use on my object?
docopt is the best
Do you mean this? http://python-history.blogspot.com/2010/06/method-resolution-order.html
I do think things like V8 prove that very advanced optimization can happen in a dynamic language. [This](https://www.youtube.com/watch?v=Z_q6iw3h48s) is a pretty interesting video on what kinds of optimizations are possible in V8. Having said that, of course Python's dev team I'm sure doesn't have the resources of Chrome.
I've never really gotten a chance to use it. I've mainly done very simple python programs which only use sys.argv[x]. I should get around to rewriting one of my very old programs to use it.
JavaScript will always have more support from various companies than Python ever will by virtue of being the only language built-in to browsers. The goal is then to replace JavaScript with Python as a browser language, and the performance optimizations will follow.
Can you use a decorator, to fix that? Meaning it'd be on the line before the function, so you see it
&gt;I think Python would be better off without the entire 2 to 3 discussion. well i dont think a lot of people will question this, but are you also implying that python would be better off (in the long run) without the changes that required breaking backwards compatibility?
The lack of a succinct way to enforce types, combined with the fact that many sequence types overload arithmetic operators in different ways. This makes it easy to make silent errors if you write code that say, assumes a Numpy array and it gets passed a list, tuple, or matrix. The alternative, as far as I can tell, is to pepper the code with asserts, which runs counter to the ideal that python syntax should be succinct. 
you append the url like this http://youtu.be/6SyG2IQ1jTc?t=4m2s But now the website does it for you when you click share.
I think you can set your editor to single keypress deletes an indent even if they are spaces.
incase you haven't seen: http://docs.python.org/2/library/itertools.html#itertools.tee
What, the exceptions? Man coming from c++ or java I was in love.
cool, thanks for the heads up about arrow.
There are several reasonable recipes for decorators to allow this kind of thing out there. And what with annotations in 3, type-sensitive overloading is also not difficult.
Decorators are useful, one reason is you see function modifiers with the definition. Not way down the chain. @property def foo(): # ... # ... vs def foo(): # ... # ... # more code foo = property(...)
When I first started python, coming from `c` this was annoying. Now I can't believe I lived without it. Even in c/c++/java you still have almost enforced rules for consistency, otherwise you run beautifier if someone isn't using it right. 
This obviously depends on a lot more than line length though. :) 
Does your IDE draw lines for indent level, and for folders? It essentially is drawing the brackets.
&gt; There should be one-- and preferably only one --obvious way to do it.
I wish it used requests instead of urrllib2
Er, my bad
Wouldn't you just use a for loop here?
Hmmm. Maybe a system could use a decorator in this way, but I already think decorators are pretty unpythonic.
[PythonCard](http://pythoncard.sourceforge.net/) had a lot of promise, but sort of petered out. In the past, I used it to slap a quick GUI on existing tools at work.
Yeah I guess they make it more readable, they just look out of place and are yet another special case. I guess that and the loud obnoxiousness of the at symbol are my main gripes, leaving a perl taste in my mouth. Not a very technical objection I guess. Maybe something like this would look better: decorate property: def foo(): pass or a with block: with decorator: def foo(): pass 
And the preferred example variable name in Python documentation is 'spam', not 'foo'.
What's wrong with Django?
VM startup time :) I've started writing all my house keeping scripts in golang instead of python. Native binaries run/start so much faster
Something like: @asattr(thingy, 'callback') def mycallback(y, z): print x, y, z Or with some use of questionable deep magic: @asattr.thingy.callback def mycallback(y, z): print x, y, z 
`OrderedDict` is fine for some cases but if you wind up treating it like a tuple often, eg slicing or unpacking, `namedtuple` is nicer. `vec[j]` is clearly more convenient than `vec.values()[j]`.
Yes, in this example and actually in most cases. It's just something that I find nice and I'm not actually complaining about. I just find break to be ugly.
NumPy ain't that fast. To get real performance you need other tools that can leverage loop fusion, multicore, etc.
I mean that `x = 1` is the syntax used for both creating a new binding `x` and reassigning an existing one. This is why the `global` and `nonlocal` keywords were added.
As a programmer who started with C, the complete lack of increment and decrement operators.
No, that's not a good option in "90% of cases". Threads were invented for a reason. If you're doing CPU intensive numerical or scientific computation then you really do want proper multi-threading support. "Use processes" is a cop-out and sub-optimal in many situations, not even possible in others.
which broke Python
virtualenv still allows programs to do anything, as long as the running user has permissions for it, so it's not a sandbox but a virtual environment.
It didnt break python, it broke backwards compatibility with python. I get that sometimes its a bitch to do this sort of thing, however dont you think its better to write `super()` as opposed to `super(Example, self)` i love the new stuff as opposed to old legacy cruft.
I have no problem with BC breaks, but python 2.7 =&gt; 3.x is a big leap and I frequently find myself questioning whether it was necessary to do all of it at once. Why couldn't this have been done iteratively like most other languages have done? i.e. python 2.8 print &amp; cmp changes, 2.9 unicode changes, etc. 5yrs of virtually no one using py3 simply because libraries can't support it all yet is a huge opportunity loss, since 2.x has feature complete for so long.
Testing compared to rspec just sucks.
&gt; What's the __builtin__.function error? The only 100% reliable way of using `multiprocessing.Pool` seems to be using only top-level functions. Using instance method may lead to an exception under py2.x and there's no good way to make a nested function work at all. Try this example: from multiprocessing import Pool class Foo: def foo(self, a): print(a) def main(self): def foo(a): print(a) p = Pool() # p.apply(self.foo, args=(1,)) p.apply(foo, args=(1,)) Foo().main() 
&gt; for example as "except E,e" became "except E as e" That change made it possible to except multiple exceptions at once: try: ... except E1, E2 as e: ...
oh it's a great tutorial and much appreciated! I upvoted it. just saying, requests is great and I hope it becomes the standard in the future.
And you may have been perfectly correct to do so. Although KJC language support was really weird/horrible before Unicode as well.
I must live in that world where multiprocessing is just a bad option. While I think Multiprocessing is generally better than nothing but in my use case it's not an option. I deal with cloud computing in a situation where processors can come and go. We aren't tied to a specific platform/architecture and we cannot simply reboot our software when the underlying platform changes. As a result we have architected the software to avoid problems, but it's hacky and not very clean for long term maintenance. Python should fully support multiple cores or multiple processors on a platform without any kind of monkey patching or extra packages 
 &gt;&gt;&gt; var.__len__() == len(var) True EDIT: That was a joke, learn to understand them…
Signaling structure to a human reader and to a compiler are two orthogonal aspects of a programming language syntax. Traditional programming languages like C keep them mostly separate: whitespace, just like comments, is reserved for human/human communication, while structural tokens like `;`, `{}` and `()` are used to encode structure for the compiler. If you remove all the whitespace from a C program, it still compiles, but it is very difficult for a human to read. If you remove all curly braces, but keep whitespace and indentation intact, a human can still guess accurately what the structure is supposed to mean, but the compilation will fail. Throwing the two concerns into the same syntax feature reduces expressiveness. Now, whether this is a good thing or a bad thing stands to reason; I am pretty convinced that GvR was very aware of this when he designed the core language. My personal taste, though, is different - I like programming languages that are optimized for expert programmers, not beginners, and I'd rather take more expressiveness at the expense of slightly more typing and the power to write utterly confusing code. The refactoring thing is mostly about moving code around. Try extracting a block of code from deep inside the bowels of a complex method and putting it into its own function. Or try refactoring a deeply-nested chain of `if` statements into a flat list of `if`/`elif`s or just early-returning `if`s. Whenever you move code such that its nesting level changes, you have to fix the indentation manually. Worse yet, you may have to manually remove or insert `pass`. Languages with explicit block delimiters (curly brackets, or VB/Ruby style `end` keywords) do not require this; you can just paste your code wherever it belongs and then have the auto-indenter take care of it. This is marginally faster, but more importantly, because it's almost completely automatable, it never goes wrong, and it's one thing less that I have to burden my mind with.
Would you expand your view on the Django ORM? What do you find bad about it? ...I've been developing web apps using Django for 3 years already. Still liking it.
Ok, you're right, with this "90%" I underestimated how much scientific computing is done these times. Yet if multiprocessing is applicable in your case, it's the best choice: * one is not tempted to use locks etc. - most people think they are smart enough to handle locking, but then reality steps in and it's often too late (I saw it too many times) * GIL haters say we're not ready for 1024 cores future, but shared memory model isn't sustainable when number of cores grows anyway (lock contention, cache line bouncing); plus 1024 cores machines will be NUMA and a process is the best way to keep memory node local * processes are much easier to handle and monitor with standard Unix tools like "top" and "kill" - it's surprisingly important when handling software in production
&gt; I deal with cloud computing in a situation where processors can come and go It's very interesting. Could you elaborate how it defeats multiprocessing and what workarounds you used?
No. You could do do that before: except (AttributeError, ImportError), e 
To get proper the proper order of constructor invocation with multiple inheritance, you have to write out the current class name in the super call. If you rename the class you'll have problems.
To be precise. Often left and right side agree but they are not guaranteed to agree because the order in which it loops over dictionary items is not guaranteed.
It does not have a full sandbox. Just something that does not allow one redefine built-ins, access the filesystem, block access to .__ methods, limit access to keywords and (optionally) user defined functions.
From the virtualenv page: "The basic problem being addressed is one of dependencies and versions, and indirectly permissions." This is not a sandbox in the usual meaning of the term. It does not limit what programs can do within the virtualenv. I want to be able to run untrusted code without worry that it may delete files, consume too many resources, etc. Python had a rexec module for this. It did not work and was deprecated. There is this module https://pypi.python.org/pypi/pysandbox/) but I do not know how much I trust it. I think for something like this to be trusted it should be part of the language.
To mitigate your point I'd remark that so much in python 3 had to be backported to the 2.x branch so that package maintainers had a shot at creating dual python compatible module because py3 adoption just wasn't taking off despite everyone thinking it was better. Still now that everything is pretty much compatible at syntax level with the right import from future there still are dozens of non trivial change that can get past 2to3 and bite you in the ass. What screwed me up the other day was a different between how metaclass are declared between 3 and 2 in some flask helper library. I didn't even know about metaclass so at least I learned something (twice). Py3 was a mistake, not in the improvements, but in believing a big bang was the correct delivery. We ended up with a language that didn't have any of it pillars (numpy, scipy, PIL, django, etc..) to support it. Five years later we're barely reaching a point were it's thinkable to start a project in py3 yet you know it will be harder and treacherous. If I didn't hate unicode support in the 2.x branch more than I hate to fight when installing a package I wouldn't touch py3 either. 
&gt; 0) the fact tat distutils do not ship with python. Yes, it does. Are you sure you're not thinking of setuptools? &gt; 1) Most of the un-necessary purely syntactical changes between 2.x and 3.x for example as "except E,e" became "except E as e". unicode became str and str became bytes. The change in the try..except syntax came in 2.6, not 3. &gt; 4) lack of a sandboxed environment. I assume you're talking about something like virtualenv. 3.3 has one.
"and be inconsistent with built-in objects" Can you explain? The built-in objects and your own objects should work the same way.
Can you cite a good one?
Sometimes I like to use lots of decorators (perhaps even five!) and your suggestions would introduce a lot of unnecessary indentation.
I wish iterators were stateless and immutable (i.e. that calling `foo.next()` wouldn't modify `foo`). Practicality beats purity, but that particular behavior really does not sit well with me. I'd prefer it if `foo.next()` returned `(value, nextiter)`, where `value` is whatever `foo` wants to yield and `nextiter` is an iterator over the rest of the sequence. Then `foo` wouldn't need to be modified, and iterators would be reusable.
Multiprocessing uses pools.
Almost there.
what about: decorate one, two, three, four, five: def foo(): pass
Only in python 3.
I can't disagree more - I don't want to see Python become PHP.
Firstly, missing `()`, and calling magic methods directly is a bad idea.
the operators don't exist because the primary use case, the C style for loop declaration, doesn't exist. when you're not dealing with the for loop thing what's the big deal about using x += 1 instead of x++
no, it really doesn't. rspec has lots of proponents in the Rails world, but honestly its weird and incredibly esoteric. Python's built in unittest module works very well, and if you want some convenience features built on top of it there's also Nose tests. 
Threads were indeed invented for a reason - but that reason was slow resources. Threads were always intended to allow you to offload disk I/O or network access or whatever so your interface didn't hang. Using threads for performance isn't really optimal. As the node.js guys point out - if your program needs multiple threads to function, it's likely it'll eventually need multiple machines, so you'll need to make it multi-process at that point anyway. Now, there are definitely cases where that isn't true, but it's another reason why the GIL isn't as big a deal as people make out.
Pretty sure TkInter comes with Python, and can look nice if you put time into it. I just use PySide myself, as I'm very fond of the Qt Framework.
Often this can be replaced by a `for` loop with `iter()`'s lesser known 2-argument form.
Just swapping to python 3, views keep catching me off guard: &gt;&gt;&gt; import numpy &gt;&gt;&gt; a = {"A":1, "B":2} &gt;&gt;&gt; b = numpy.array(a.values()) &gt;&gt;&gt; b*2 Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; TypeError: unsupported operand type(s) for *: 'dict_values' and 'int' ??? oh yeah. 
The PyPy devs are [working on that](http://pypy.org/numpydonate.html) ;)
Got it. Sounds like a nice project using lxc + virtualenv. 
It helps if you think of it the same way you think of .format "{0} some text goes here {1}".format(var1, var2) is similar syntax
`from __future__ import unicode_literals` makes 2.7 and unicode pretty painless for me...
&gt; Did you know that Python's for accepts an else statement? For the record, that's been in Python since the earliest days. I tracked it down once. It was added on or before Oct 13, 1990.
Yes. Replace `download` with this: r = requests.get(url) if r.status_code == 200: with open(self.ensure_dir(filename), 'wb') as f: f.write(r.content)
The Python documentation for locals() says: &gt; Note: The contents of this dictionary should not be modified; changes may not affect the values of local and free variables used by the interpreter. 
I'm going to need a few examples because that doesn't make any sense. All the built-in functions are either (1) ones you can implement methods for, like implementing `__len__` for `len`, or (2) ones that are simply defined in terms of other functions or opetarors, and it wouldn't make any sense to override that behavior in your class, like `enumerate`. EDIT to respond to your edit: So you don't like typing a couple extra underscores when you implement this method. Okay, but don't you think calling it "terrible" and "the bane of your existence" and saying it's "hacking" builtins is just a tiny bit overdramatic?
Since it was easy (and kinda fun) here's an example: from __future__ import print_function import inspect class arity(object): def __init__(self): self.functions = {} def register(self, function): spec = inspect.getargspec(function) self.functions[len(spec.args)] = function return function def __call__(self, *args, **kwargs): arity = len(args) + len(kwargs) f = self.functions.get(arity, None) if f is None: raise TypeError("Missing support for %d-arity functions" % (arity,)) return f(*args, **kwargs) and in use: add = arity() @add.register def add0(): print("0:", 0) @add.register def add1(i): print("1:", i) @add.register def add2(i, j): print("2:", i+j) @add.register def add3(i, j, k): print("3:", i+j+k) add(3,4) add(9) which prints: 2: 7 1: 9 
Oh cool, it's so faster!
That's one of the reasons I like ObjectPascal/Delphi "units" (modules): having an "interface" and an "implementation" sections allows you to reference another unit B in unit A's implementation section, while unit B could still reference names in unit A's interface section. 
If all you want is basic functionality, I can write you one myself: class overload(dict): def __init__(self, function): self.overload(function) def overload(self, function): self[function.__code__.co_argcount] = function return self def __call__(self, *args): return self[len(args)](*args) @overload def f(): print '0' @f.overload def f(a): print '1' @f.overload def f(a,b): print '2' &gt;&gt;&gt; f(19) 1 &gt;&gt;&gt; f() 0 &gt;&gt;&gt; f(3,5) 2 You could also add a `__missing__` function if you want a nice error message when there is no such arity.
Totally! Tabs look way better than spaces!
Dynamic typing. I know, that's going to be an unpopular opinion in a language that's built on dynamic typing, but it's the only thing in Python that makes it difficult for me in my every day work. It's hard to maintain a function or module written by somebody else when I see an argument and don't know what type it is. Without significant unit tests / doc strings / assertions, it's hard to know what behaviour is "expected" without looking at every reference to that object, and if it gets passed along to any other functions, now to you have to go look through them too. A contract defined by how others expect it to work isn't a contract at all. It's convenient for rapid prototyping, but it makes maintaining large, long-term projects a pain. With static typing, the interface is explicitly defined, so you always know what to expect.
Very true, touche! 
The PyPy developers would love to get funding for better Python3, numpy, and matplotlib compatibility, and probably also for improved C-extension support.
Intuitive is just another way to say familiar
thank you for using myriad properly &lt;3
Coolio, I like it. You were right, it was fun. [Here's](http://www.reddit.com/r/Python/comments/1mn12l/what_you_do_not_like_in_python/ccay5wx) the one I wrote.
Also if 80 is a problem you probably have way too many indentation levels. Time to break stuff out into separate functions? Or you are using silly long identifier names. When someone complains about limited line lengths that's a good indication it is time for them to instead refactor their code a little.
What code designed to work on a numpy array will fail silently on a tuple? Everything I can think of will either throw or succeed. Anyway, the disadvantage of that kind of type checking is, of course, when I write my replacement for numpy arrays that's optimized for my use case, and I replicate the numpy array API. Now I can't use your code with it since your code assumes that only numpy arrays will work.
Built-in types (dicts, sets, lists) not being immutable by default like in Clojure (with clever tree data-structures to get good performance, not making full copies every time a dict changes; that would be silly).
How would you iterate over lines in a file? Assume that "filename" contains a few thousand lines, starting "1\n2\n3\n4\n5\n". What does the following print? it = iter(open("filename")) value, new_it = next(it) for i in range(1000): value, new_it = next(new_it) value, new_it = next(it) print(value) Should it print a value around 2, or a value around 1002? If the former, what would that implementation look like? 
UNICODE in 2.7... #tearing_my_hair_out
what's the gain? what is the upside of declaring variables before assigning a value to them? I understand that its idiomatic in C, but if the only upside is that you feel comfortable in the idiom of C, then its not an upside that matters in this context. What other upside is there?
https://rhettinger.wordpress.com/2011/05/26/super-considered-super/
I did not know that. Why all the underscores?!
&gt; Threads were always intended to allow you to offload disk I/O or network access or whatever so your interface didn't hang. And if your payload is CPU bound, Python threads _don't even work for that_ without breakdancing around the GIL. Neither can you write a Python GUI around a long-running CPU-bound thread (because your GUI will hang waiting for the GIL), nor can you easily do producer-consumer pattern stuff where you pre-read from disk in one thread and process the last batch in another. &gt; Using threads for performance isn't really optimal. Virtually anyone doing numerical linear algebra disagrees. Hell, Intel disagrees. Multithreaded BLAS is extremely effective, and a lot of other common operations are trivially parallelizable with threads. &gt; As the node.js guys point out - if your program needs multiple threads to function, it's likely it'll eventually need multiple machines, so you'll need to make it multi-process at that point anyway. Yeah, that's nonsense. &gt; Now, there are definitely cases where that isn't true, Plenty. Situations where one has a relatively fixed computational graph that needs to be executed repeatedly, thousands or millions of times, are ubiquitous in scientific computing. Not only would it be ideal to have a producer thread load data from disk and do some minimal preprocessing before passing it to the consumer thread doing the bulk of the work, oftentimes you have large parts of the computational graph that are extremely data parallel and can (and do, if you are willing to invest the time to drop out of Python) benefit greatly from a multithreaded implementation. These are not applications that will "eventually need multiple machines", they need performance out of a single machine and they need it yesterday. And frankly I'm sick of being told by ignorant web programmers that this crippling "feature" of the Python interpreter is not a significant problem.
If iterables were specified in the way I described, this would still work: for value in iterable: pass It would just operate differently internally. Unless you're *actually* calling `next()` directly, you would see no change.
link result `404 There isn't a GitHub Page here.` 
&gt; PyPy runs only python 2 code (...) [PyPy3](http://morepypy.blogspot.cz/2013/07/pypy3-21-beta-1.html)
link go to a www.jakevdp.github.io but correct one is non-www Correct link : http://jakevdp.github.io/blog/2012/11/26/3d-interactive-rubiks-cube-in-python/
EH. You're formatting the string, so the `' '.format()` syntax makes sense in that context. You're acting (formatting) on an object (the string). In my head, the list is the object being joined, not the string, so my brain always wants to do `a_list.join(' ')`. Really, part of the problem is that Python is so semantic in other areas that I expect this kind of stuff to just work.
In python 2 I often found myself having to check the types of my variables at the beginning of a function, which has been solved in python 3 with function annotations. It's not hard to type check, but that doesn't mean it wouldn't be more convenient in some cases not to have to do that.
pytz and dateutil helped me a lot in the past. did not know arrow. thanks for bringing it up!
How does that matter? A dictionary is unordered.
Glad to hear it's working!
Okay, then suppose I do call next() directly. Here's code similar to what I do have: it = iter(input_file) name = age = address = None for line in it: if line == "\n": continue if line == "NAME\n": name = next(it).rstrip("\n") elif line == "AGE\n": age = int(next(it)) elif line == "ADDRESS\n": address = "".join(next(it) for i in range(4)) else: raise AssertionError("Unknown line %r" % (line,)) return Person(name=name, age=age, address=address) I think this is quite clean. I don't think your variation supports a solution which is anywhere near as readable. 
The change to treat strings as actual strings instead of sequences of bytes that happened to have vaguely string-related methods bolted on top was long overdue.
magic function. You can create your own implementation of it in your class. 
Not declaring variables? Or not declaring their types? Because it seems like having to declare a type would be *more* confusing to people who have never programmed before.
Use a real editor.
Python 2.6+ supports the `except ExcType as e:` syntax.
Hm. I always forget about that, I'll keep this in mind next time I find myself wanting.
Magic methods are methods that you can define which normally affect how operators work. Their names have double underscores at either side to distinguish them from anything the user might normally create, to avoid accidentally overriding it. For example: class RepeatingList: def __init__(self, lst, repeats): self.lst = lst self.repeats = repeats # Stupid example class that always returns a specific list def __getitem__(self, index): return lst[index % len(self.lst)] def __len__(self): return len(lst) * repeats # Other methods x = RepeatingList([5, 4, 3], 3) # x = [5, 4, 3, 5, 4, 3, 5, 4, 3] len(x) # 9 - same as x.__len__() x[4] # 5 - same as x.__getitem__(4) This is a terrible example (you'd probably use [5, 4, 3] * 3 if you wanted to actually do this) and if you want to actually make a class that can be used as a list you're better off to extend list, and probably override a couple of other methods depending on what you're doing too. But it's mostly to show that most operators can be controlled with magic methods.
"yield from" Crazy pills.
`return` doesn't break a loop, it returns from the entire function.
The first rule of namedtuple is you don't look at the source code.
look at PHP to see why sometimes too much focus on backwards compatibility is a bad thing
How about `var x = 'foo'` or `x := 'foo'` ? And the gain is that it tells you when you make a typo in your variable name.
First-class citizen lambdas and tail recursion.
[For those interested in breaking this rule](http://hg.python.org/cpython/file/ad9a5ded5cf6/Lib/collections/__init__.py#l233). 
If you don't indent your C consistently with the braces, then I don't ever want to go near your C.
I agree completely. It gets annoying writing code and storing a value in a variable, and getting an error if I don't x=x.str() before I print. What's worse is that the shell does all that stuff in the background, essentially lying to you about how print works. Maybe thats just me though.
&gt; namedtuple is nasty. I cannot believe it is part of standard library. My god, yes. I always felt uneasy when using it (repeating the class name twice, reeks of 2.x' 'super()' method), but I almost had to vomit when I looked at the implementation. For the morbidly curious: http://hg.python.org/cpython/file/ad9a5ded5cf6/Lib/collections/__init__.py#l233 
&gt;* for-loop syntax is not the same as comprehension syntax. I'm not sure why it would be honestly. &gt;* lack of multi-line, real lambda. There's no more excuse, CoffeeScript have shown that it can be done. *Completely* with you on this one. &gt;* Maybe it's time for CPython to start thinking about performance. e.g. function inlining. I'd tentatively support a decorator that marks functions to be inlined so long as it is 100% semantics preserving, which would be difficult and/or slow. As for speed in general, HotPy is cool, though I think it stalled.
... they're CS students. I'm pretty sure only a handfull of people would major in CS without some previous knowledge of computers and their languages.
Like masklinn said, there's a practical benefit here. If it's a `join()` method on the iterable thing, then either every class which wants to support it needs to implement `join()`, or all those classes need to inherit from something which provides an implementation of `join()`. Aside from the fact that this either promotes redundant code or results in needlessly complicating the inheritance diagram, it also pollutes the namespace of the class with a public identifier that can't be used for anything else. Which is a real concern for some use cases; for example, if you were writing a database-access library and wanted your query object to support doing iterable-like things, but also wanted to be able to chain query conditions onto it, the obvious use for a `join()` method is to add a SQL join, not to implement joining a sequence of results into a string. Implementing it as a method of the separator means it can simply consume anything that's iterable (which does not tie up a public identifier, and does not require inheriting anything you don't want to inherit). It also means that for some cases involving comprehensions you can do the join without needing to create an intermediate `join()`-implementing object, which is a nice implementation detail.
No, it's terrible to have to implement some "hidden" method to work-around the stupidity of having built-in functions instead of just making it all methods to begin with.
It's not yet in a releasable state, but it seems worth pointing out that 0MQ's author has moved on to making [nanomsg](http://nanomsg.org/). 
Do you have an example for a case where this applies?
The thing I dislike about Django is that it forces you into a very particular mind-set, one that just never fit with my mental model of how I want my web app to come together. I am using Pyramid these days, and I can honestly say that I absolutely love it.
I think I get it now. They never heard about `__len__` until just now, and they assumed that it was impossible to make the `len` function work with custom objects. So they've been implementing a method called `len` on all their custom containers all this time. Presumably their code looks something like this: try: n = len(obj) except TypeError: n = obj.len()
&gt; [Python3] is the first ever **intentionally backwards incompatible** Python release.
Care to elaborate?
&gt; PyPy runs only python 2 code Is that true still? The homepage reads: &gt;PyPy is a fast, compliant alternative implementation of the Python language (2.7.3 and 3.2.3). It has several advantages and distinct features:[...] 
&gt; There should be one, and preferably only one, obvious way to do it. I'm kind of baffled that people are still using this as a justification for adding/removing something from the language. This idea of "one obvious way to do things" was trampled, spat on and destroyed a long time ago. Of course, there are good reasons why `Enum` and `namedtuple` are implemented the way they are.
eggs and spam, not foo and bar
You are quite mistaken. This might have been true years ago, but nowadays, at least in my department, the majority of incoming CS students have little or no knowledge of computer programming. (Not that I think using a language with, *gasp* explicit types, is a bad thing for new programmers.)
Noted.
&gt; Yeah, that's nonsense. its not nonsense, its just domain specific. Node.js is for writing web server applications. Their statement is actually true, and somewhat insightful, when you're talking about scaling out a web server app. Its non-sensical if you're talking about stuff like CPU bound number crunching or low latency GUI stuff. different domains have different assumptions underlying them. 
But with your example 2.8 is now incompatible with 2.7, which is far more confusing.
vim
That's the only Python there is. anything else is like complaining about something in Windows 98.
I've seen something like this be done with decorators to override when certain errors are thrown... although that only works on functions, a lower level equivalent would be awesome, not sure if one exists though.
Dynamic typing always frustrates me when I have to work on large projects. I've evolved to only using python for things taking less than ~500 lines of code, and at this point python just serves as a wrapper for java or something. I do miss numpy, scipy, and scikit-learn on a daily basis. The tools in java are just not accessibly in the same way and languages like matlab and R are just not the same.
&gt; You're formatting the string .... er, no you're not. You're formatting the other objects, then substituting them into the string.
I wish that there was a `try...then...except` syntax. Placing the unexceptional case after a lengthy block of exception handling unnecessarily disrupts the human-readable flow of the code.
That can be done using a function that evaluates a passed-in lambda: def trycall(func, default=None): try: return func() except Exception: return default Now instead of: x = 1 / y # y may be 0 You write: x = trycall(lambda: 1 / y, 0) 
&gt;A contract defined by how others expect it to work isn't a contract at all. Sure it is. It's a contract among human beings. &gt; It's convenient for rapid prototyping, but it makes maintaining large, long-term &gt;projects a pain. But we have a lot of large, long-term projects built in Python. &gt;With static typing, the interface is explicitly defined, so you always know what to &gt;expect. It's as explicitly defined in dynamic typing. It's *enforced* in static typing, whether you need it to be or not, and it can become a straitjacket that one has to try to wiggle out of to get certain code to work. Generics, templates, interfaces, explicit casting... all things statically typed languages have to employ to get around the straitjacket the slipped on in the first place. Some day computer scientists will look back on statically typed languages and, just like line numbers, will ask "What were we thinking?"
it's ignoring errors and adding a lot of clutter.
Those things *were* done iteratively. It's called Python 2.7 and `from __future__` imports.
Half the reason python is interesting today is the scientific and machine learning work being done with it. None of that is being done with python 3 yet because numpy and scipy support are pretty recent, and libraries farther down the dependency chain like theano haven't been ported yet.
You should just use Ruby if you want this. This goes against everything that Python stands for. 
Why ;_;
I gotta try that Pyramid. Thanks for the reference, it's nice to know new alternatives.
That's a good point, but `__future__` is fairly limited in scope. Either way, it would make more sense, I think, to have a python 2.8 version that makes more of the `__future__` features mandatory (as well as backporting some more python 3 stuff not in `__future__`) than to keep living in 2.7 limbo. If we're worried about keeping legacy software running, fine - keep running it. py2 doesn't need to die. But for the rest of us, it makes sense to keep moving forward slowly, rather than stagnate.
I've had problems where I have a copy of a package inside of another package (i.e. the parent project has a copy, but so does a child dependency of the parent project. Everything's fine with relative imports, but if something tries to reload the import, it can suddenly switch to the other one, I think depending on load order. I can't figure out how it all works, because imports are crazy. 
You need to contextualize -- he thinks it's not a big deal, because he comes from a web-development background where things scale horizontally basically infinitely. Just throw more hardware at it, and you're done. But for a vast number of other cases that come up in HPC, consumer applications, server applications, ... this is not so trivially accomplished. There are many cases for instance in HPC situations where multi-node setups are completely infeasible, because the added latency of IPC just totally overshadows any benefit you get from adding more compute nodes. There are also cases in desktop and mobile applications where processes are infeasible, because they can't e.g. share an opengl context (to do multithreaded streaming of textures to the GPU) or because they are intended to be used to remove some bottleneck (streaming compressed assets from nonvolatile storage) where the need to serialize through a pipe would just completely negate any benefit. So yeah, the GIL is a big deal, and is holding back the adoption of python in certain areas where it could otherwise be employed to great benefit -- it's definitely something we need to work on, along with the C API.
Evidently Python stands against "consistency".
Most of the film and game industry is stuck with 2.x, because it's embedded deeply (and foolishly) in things, like Autodesk Maya. We're not moving to 3.x any time soon.
I can't seem to stop typing "try..else," then spending several minutes going "What? What is the problem with that? Why aren't you working?" Then suddenly "Oh, son-of-a..."
Then why not "Monty?" $ monty python.py $ monty carlo.py $ monty -mjson.tool $ monty hall.py
I came here to post the same thing. Sure, it's an integral part of Python, so maybe it's not a fair criticism…but seriously, maintaining a large codebase with multiple developers is a chore in Python compared to statically-typed languages. Quoting Alex Payne (who was talking specifically about Ruby, but Python is similar enough that his words are apropos): &gt; As our system has grown, a lot of the logic in our Ruby system sort of replicates a type system, either in our unit tests or as validations on models. I think it may just be a property of large systems in dynamic languages, that eventually you end up rewriting your own type system, and you sort of do it badly.
Python doesn't store values in variables; it has references that point to objects. Why would you need to do x = x.str()? I don't think that's even valid Python. Do you mean str(x)? In [7]: x = 7 In [8]: print(x) 7 This works fine for me.
I'm ok with snakes, but British television scares me. :-( All those tin cans running around always wanting to exterminate....
Frankly, I've been using Python 3 for everything I do for about two years. There were two packages I missed, so I ported those myself. I am a heavy user of the Numpy/Scipy/Matplotlib stack. So I don't quite see how it is"only now barely reaching a point" of being useful.
As Guido explained, threads were invented for non-blocking I/O. Multiprocessing is for everything else. &gt;If you're doing CPU intensive numerical or scientific computation then you really &gt;do want proper multi-threading support. No, you just want to be able to do more than one thing at the same time, which can be done just fine with multiprocessing. It's also inherently safer and easier, which are pythonic traits. 
Oh, so they got python 3 support out the door? good for them.That's one less impediment to moving to python 3... eventually.
You're absolutely right; Guido and Python are just ahead of their time. Eventually people will realize that multiprocessing is better for most instances, and will wonder why they ever spent so much time worrying about whether this, that or the other thing was "thread-safe" for things that never needed to be multithreaded in the first place.
Beta. But that's better than a couple of boxes on a white-board.
It matters because if you pickle an object and then you read it back, you cannot efficiently check if the original object has changed. Think of storing a session object in a web app. Because of this some web framework required that you call a function very time you change the session. Other framework have to pickle twice (when read and when save) to detect changes automatically (this slows things down). 
That'll be impossible, sadly, because python will always be more verbose than javascript.
The other difference is that Python's approach is much easier to read.
...Ok? I conceptualize string formatting as acting on a string by replacing generic tokens with specific content, but we're arguing mostly irrelevant semantics at this point. Strictly speaking `join()` is the same concept as `format()`, because again, you're taking a string and inserting objects into it. It's a bit of conceptual break for me (and MattTheBatman, apparently) because the English word "join" means "bring things together", and the Python usage applies the verb ("join") to the "glue" instead of the "things".
I like this, but it means either anything that can update var *must* update that property when it fiddles with var, or it means var must be a "property" with a getter method that does the introspection work. I'm not sure where I stand on this. I'm doing some animation tool work right now, and part of it stores animation curve data. I've been storing a length value with the animation curves, which makes getting length just `curvedata.length`, but it also feels a little incorrect. I don't know how tall I am without outside help. Someone has to check for me how tall I am, or some device must do it. If I grew or shrunk, I might not even notice. I feel like length is a property that *another* thing should be able to see about `var`, but I'm not sure `var` should be able to see this about itself. If it's stored in a class, it makes sense to me that the class could have a getter (or 'property') that can look at the stored frame data, but then, it isn't the frame data that has the property - it's an outside source - inside the same scope - that has that power. The tricky bit to me is - what if it isn't in a class? What if it's just a dictionary of data? Do I just have a "getFrameCount" method floating out in the module? Part of me feels that I should instead reuse the len() that's already floating around in space, and make sure my data structure lends itself to being `len`'d. For example, I need to store frame times, values, and a pile of tangency information. Maybe frames and values are zipped up into a list of couplets in a `frameData` key, and tangents are under `tangentData`. Then I could ask `len(curveData['frameData'])`, which would just be getting `len()` of the list of couplets. That being the case, it feels a little more natural to me to ask for `len(thing)`.
&gt;&gt; python code running in the cpython VM is faster than javascript running in V8 &gt; That's an extremely unfair comparison. CPython is the reference implementation; it isn't supposed to be fast. Isn't supposed to be fast? Come on... did they sit down around a large oval table and work out how to slow it down some? &gt;&gt; [native libraries aren't compatible with PyPy] &gt; Native libraries aren't Python. They don't count. Native libraries are how you can eke some performance out of python. You can choose not to count them, in which case python performance is absolutely abysmal, or you can choose to count them, in which case PyPy compatibility is problematic. I'd also like to know if there were an alternative to matplotlib (with basemap) which isn't implemented half in native code, and which could run in PyPy.
Indeed it is. My main beef with hard wraps is that every developer has different conventions as to how to wrap. There's no guidelines either on how to do hard wraps properly. There's just too many different cases. It all comes to the development team. In my team I feel that 100 is a good limit. If you need to go over that's fine too as long as it's sensible. Usually if a line is overtly long it's usually a sign that something is wrong. But...there's exceptions to every rule. So in general, soft limit of 100 characters. Common sense dictates above set guidelines when it comes to line width.
It is pointless for me to argue. You are talking about breaking backward compatibility for the purpose syntactic sugar. We simply have different priorities.
&gt;Isn't supposed to be fast? Come on... did they sit down around a large oval table and work out how to slow it down some? No, but they don't go out of their way to be fast, unlike V8. CPython is supposed to be *stable* and *correct*. Speed is not a priority.
&gt; Speed is not a priority Well, that brings us right back to "what don't you like about python".
I use sublime's convert tabs to spaces function religiously.
Httpserver is strictly for development.
The debugger
We don't want to end up like PHP after all.
Enumerate gives you index and items, range(len( gives you just the indexes, off the top of my head its useful for making n-wise iterators, i dont know...
Sure, if thats what you prefer
Well, that's what Von Rossum said. He is the BDFL.
agree. datetime is really irritating sometimes. 