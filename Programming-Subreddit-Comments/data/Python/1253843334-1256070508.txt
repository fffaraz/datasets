http://vimeo.com/6461537
Thank you!
I don't want to sound like Kayne but, the speaker should train himself not to say the word "like" 20 times per minute. 
Oh come on, Kanye! Don't be a jack-ass. :)
ps: That doesn't mean I downvoted it. 
I agree, operators behave differently than method calls. I wonder if that can be changed.
I've been working on getting [your blog engine](http://github.com/finiteloop/blog) running on appengine, which requires Tornado. Thanks for putting it up on github!
This is a really great project, but I won't take credit for it -- I only noticed it was released last night and thought I'd let people know. Ben Finney is the gentlemen to thank, if you find a method for doing so. We use it in production as well. It greatly reduces mistakes in daemon construction and nicely tightens up the development cycle.
Added download of script + pngs
Yeah I know ... which is why I didn't downvote you either. I was just teasing.
Has anyone (other than facebook or whatever) used Torando beyond the very basics? There seems to be a lot of reposts of the information in found at http://www.tornadoweb.org/ or http://www.tornadoweb.org/documentation . But so far I haven't been particularly impressed with actual implementations of Tornado since people don't seem to be posting code. I looked at the [neat demos at github](http://github.com/facebook/tornado/tree/master/demos/) but there seemed to be a memory leak with chat demo. At one point I simplified everything down to just a request handler and a more simplified mixin and I found that it would leak a little bit if I included lines 122 and 123 from [chatdemo.py](http://github.com/facebook/tornado/blob/master/demos/chat/chatdemo.py). Anyway I'm just interested in seeing some nice long polling stuffs.
Eric Florenzano and I have been writing a Comet framework based around the Tornado webserver. You can see our work here: http://github.com/ericflo/hurricane
Thanks for the info. downloaded it and run the demo, it's charming, but it maybe some memory leak(just the windows xp, python2.5.4, pyglet , the script)
[Durus](http://www.mems-exchange.org/software/durus/) is another ZODB replacement with interesting backends [like this](http://www.jcea.es/programacion/durus-berkeleydbstorage.htm).
I'd like to see some real world experience and benchmarks before I'd choose Dobbin above the battle-tested for a decade ZODB, which the author tries to make out as overcomplicated and old-fashioned without really backing it up. Without more information about I'd also debate the implication that the ZODB somehow makes mistakes like the Varnish author claims Squid does. Varnish and Squid are *caches*. The ZODB and Dobbin are *databases*. One important property of databases is that the data is actually stored somewhere between restarts of the software, and preferably it's not too lazy about it because applications can crash. The Varnish author may very well be right that relying on the operating system's virtual memory system in a cache is better than the cache manually writing things to disk. But a database has no choice - it needs to changes to the disk, and preferably not wait too long before doing so! You can argue that relational database systems were originally designed to use the disk as much as possible as opposed to main memory - there is some interesting research to main memory databases. But the ZODB lets you talk to almost-normal Python objects in main memory already. If you're going to make points against "the competition" a bit more detail would be much appreciated, instead of innuendo. 
The ZODB has pluggable storages. In fact, the ZODB has such a long track records that there are quite a few old and unmaintained pluggable storages by now. We've seen experimentation with all sorts of approaches, including Berkeley, DirectoryStorage, and Oracle. Some evidence is here: http://cvs.zope.org/ZODB3/Doc/storages.html?rev=1 The FileStorage backend has remained the most popular however, probably because it comes natively with the ZODB and is simple and robust. One current alternative storage (the author is an old hand at writing alternative storages for the ZODB) is RelStorage: http://pypi.python.org/pypi/RelStorage/1.3.0b1 
WTF ?! Where was this when I was looking for it everywhere 4 months ago ? I had to recode the entire algorithm, it was awful, awful really.
If you're put off by the concept of stopping development to look things up, you're a tool, and you probably write shitty code. You have to *know* the features of your language to use it well. IDE's allow you to learn just enough of a language to make steaming piles of crap that happen to compile and run. That's how most developers I've ever met do their job. It's sad that so many people think that's professional. If the goal is to learn to do things well, stay away from an IDE until you don't need one. if the goal is to pump out running piles of crap, then skip to the end and get on with it.
"Less code. About 20 times less." Is that supposed to mean the same thing that "about 95% less" actually does?
I have to say that I'm really enjoying this sudden burst of Twisted howtos. I'm assuming it's fallout from the Tornado/your docs suck fiasco.
I think it's healthy for Malthe to experiment with creating alternatives to ZODB. While ZODB is fantastic, the points he makes about it in the blog post are pretty valid: ZODB consumes more memory than it might need to if all threads shared one set of objects rather than each thread having its own copy of all objects. Some of the code is pretty complex and a little strange (particularly the caching code). On the last point, I have hope for http://svn.zope.org/ZODB/branches/elro-python_persistent/ (getting rid of C 'persistent' code in favor of Python code).
I think "1 times less code" means 100% less code.
It's fine for Malthe to experiment. Sharing objects between threads is an interesting approach. The ZODB is not the final object database by a long shot, and if Malthe comes up with, say, interesting approaches to indexing later as he discusses, that'd be very cool too. Too bad though the discussion had to be framed the way it was. It'd have been better if he just talked about the goals of Dobbin without contrasting them so much. Dobbin, an object database with a small codebase, simple assumptions, not try to manage its own memory inspired by Varnish, and try to keep things simple. If you have to contrast with the ZODB, you could still mention the goal is to simplifying some assumptions, in particular a different approach to memory management. By contrasting so much with the ZODB, someone might get the impression it's old and crufty, with a vastly inflated codebase, overly difficult assumptions, using a 1970s approach to memory management, and is overly complex. Maybe it is all of those, but you need to back that up with details if you're going to claim it. That said, I'm probably reading too much into it. 
good job!
Exactly. So "20 times less" is an impossibility.
Should've read, and now reads, "one twentieth" :-)
First off, this is more than an experiment to me. That said, I acknowledge that it may not be the best introduction to a new software, to contrast it so heavily with an existing one. However, invariably, the first question prospective users will ask is: how is this any different than ZODB? The author of Varnish takes the same approach; he complains that Squid makes wrong assumptions about the environment in which it operates and that Varnish exists because of this. I'll argue the same about Dobbin. It's of no particular importance in this regard that Varnish and Squid are caching proxies; this is about design principles. It is true that I do not argue much in the post; however, I do so in the documentation on the project page (all the way at the bottom). I'd like to be able to present benchmarks, but there are some obstacles. First, there is no bucket-based dictionary implementation, which makes it hard to make a benchmark that reflects a real-world scenario. Second, it's difficult to get it right (to actually get a meaningful value). What's really interesting is how it works in concrete applications that exhibit the various characteristics (e.g. I/O-heavy, many reads, many writes). You mention that users should be wary before choosing Dobbin over ZODB; I think you're reading a wee bit too much into it. I'm not actually advertising a 1.0 release. At any rate, the feedback is genuinely appreciated.
Someone also recently released an extended server for Durus, which allows serving multiple databases or clients IIUC. http://11craft.github.com/duruses
&gt;If you're put off by the concept of stopping development to look things up, you're a tool, and you probably write shitty code. For a good developer, it's not about using code completion to stab around trying to figure out what you want to do, it's about learning to phrase what you want to do in the way that the library you're using will understand. As an example, when coding with a new library that you understand theoretically (picked up the jargon, understood the mechanics) for pixel-based image manipulation. For the image object, your forget if it's `setpixel` or `set_pixel`. Do you want to look elsewhere in your code for another time you used the function? Do you want to switch to your browser and surf to their docs online? Or do you want to hit a keybind and use the list to see that, indeed, it's `set_pixel` and return to your task without ever really context switching out of the editor/IDE? I'm not going to argue that amateur programmers can abuse code completion making unwarranted assumptions and generating crap but it can also enhance the lives of the rest of us programmers that just don't want to fuck around trying to remember the names of a 1000 miscellaneous functions in a 1000 different libraries. Besides, if crap programmers want to generate crap code, they'll do so without code completion.
Oh, if only that were true...
I went to an interview and mentioned I knew Python. The interviewer asked if I have any experience of any real object-orientated programming like Java. Uggg.
Bonus points if the interviewer actually said "orientated". Double uggg.
Stop applying for Java jobs if you don't have Java experience then, that's the main issue here.
Woops!
in the second example; the list is passed by reference, a and b are the same list.
Everything in Python is passed by reference. What happens is in the first example the tuple is not "passed" to +=, but a normal assignment to variable (`a = a + b`) is invoked. I understand how it works. I don't understand the design decision behind overloading += for lists.
If an object has an `__iadd__`, `+=` works in place. Rule of thumb: `+=` will work in place for all sequences except tuples, strings and forzensets (eg: all immutables)
... and strings.
All immutables.
Worse yet, he's manager material...
Why not use append() if you are worried about ambiguity?
From their expression on hearing the word Python, you probably didn't want to work there.
I do. But I find things like this ugly anyway :)
This was India. Perhaps these developers cannot afford to be picky?
"Pass by reference" vs. "pass by value" does not make sense in a Python context, and the quicker you get rid of that way of thinking the better. The correct answer, given by mitsuhiko below, is that lists have `__iadd__` methods and tuples don't, because lists are *mutable* and tuples are *immutable*. To someone who doesn't grasp the mutable/immutable distinction, it may seem like some arguments are passed by value in Python, but they are not. Nothing can be. The difference is mutability. 
Depends what the job is.
I was finding it real hard to buy a Python book. No major computer bookstores had any. One salesman actually went to the kid's section to search for a 'Python' book.
I used Python syntax to outline my solutions for Microsoft interviews ... they hired me to work on C++ stuff. YMMV
You don't want to work in a company whose recruiters don't recognize the value of programmers learning a non-mainstream programming language. Most of the time, those programmers are are passionated, curious and smart people. 
So somebody wanted a Java job, but did not know Java, only Python. This somebody did not get the job... aaaand this is Python related how? ,,I could have learned Java instead?'' No shit. He could've learned both. Or yeah, the relevant to that job -- Java. Did he get a Java job after he removed Python from his CV, but still without learning Java? Don't bother to answer that. Douchy interviewers are another topic.
Naturally.
I don't understand how you would like += to work for lists. Your example above behaves exactly as I would expect it to. `a` and `b` are the *same* list because mutable objects behave like pointers on assignment, while in the tuple example they are two different values.
[deepcopy](http://docs.python.org/library/copy.html)
In the blog entry, you don't describe *how* the design principles of Dobbin are like Varnish, or how the ZODB uses 1970s programming, or whatever the point is you're trying to get across. The Varnish author has a detailed description of what he thinks Squid is doing wrong and how Varnish is doing it differently. You just refer to it and mention Dobbin doesn't do its own memory management. Now that you point it out it's true that all the way on the bottom of the pypi page you do say something more. Perhaps you should put that in the introduction? Now if you'd had put that in your blog entry you might've gotten a discussion about the actual content sooner, as this prompts several questions. Contrasting with the ZODB makes sense, I agree - of course people will ask how it's different from the ZODB. But the concrete information as to the difference was rather sparse, there were a few too many negative implications by contrast, and a more balanced comparison would've worked better to prompt discussion. My bringing up that the ZODB is a database and not a cache is prompted by the following observation: a database will need to write to the filesystem itself to save its data at some point. There's no way to avoid this as can be done with Varnish versus Squid, where Squid does its memory management by caching to the filesystem whereas Varnish only does this indirectly by piggy-packing on the OS's approach. The assumption is that the OS is more efficient at this. The situation is different with the ZODB as the filesystem backing by its very nature *has* to be there. It's going to need to write anyway. Since this cost is already there, it could be less of an issue to make use of this information, depending on how much overhead unpickling and filesystem access have in a real-world system. Dobbin, I think, makes the assumption that it would never have to reload an object once an object is in memory. My question would be: have you tested this assumption with a database that is several gigabytes large? I.e. when the limits of non-virtual memory are reached, what happens then? Wouldn't you get more of the dreaded 'swapping' unresponsiveness once a machine reaches critical memory load? It'd be interesting to see how it performs. Another question would be: how is this different from a ZODB where its cache has been set to a ridiculously high figure? I assume there are other simplifying assumptions involved in Dobbin that kick in here - perhaps the thread sharing? Benchmarks are tricky; I agree a concrete application would be the best test, though it won't be possible to do an easy comparison with the ZODB in this case as the programming model that Dobbin presents is different. Correct? Anyway, I certainly don't want to stop you from building an object database. I just think a different approach would've helped in presenting it. 
It's the exact same situation as in a configuration where ZODB object cache is set "ridiculously high", i.e. infinite. One key difference then, is that ZODB needs a copy of each object per thread; I think this is one of the reasons why it was deemed necessary to have an object cache (really, an object "ghostifier") in the first place. I do expect swapping, but I don't dread it. Rather, I expect it. As I mention on the project page, I'd rather swap in an object than load it from the database and unpickle it. This is the assumption that leads to a far simpler design, too. The programming model is similar; once we have the same set of "primitives" available, it'll be fairly simple to do a good benchmark comparison. Different approach; well, there's always a different way to go about things. I don't think I've overstepped any boundaries by saying that ZODB suffers from an old design paradigm. It does, in my opinion, and there's no reason to wrap it. However, I definitely could, and probably should, have included more technical details in the actual post. This would probably clear up some confusion and perhaps even spur more interest.
Strings are immutable. StringIOs are not.
I realize you expect swapping, but the question is what actually *happens* when you have a database larger than physical memory. If the system grinds to a halt at that point, for instance, then we'd have a problem, right? Perhaps the swapping behavior is more a problem when multiple applications are competing for the same memory resources? I realize Dobbin due to its sharing approach is expected to run into this situation less quickly, and that might be a good tradeoff (we'll have to see), but at some point it will have to scale that large, right? And what happens if your database is larger than virtual memory altogether anyway? Or is it possible to tell the operating system to manage application-specific virtual memory? (I think I that's what I read into the varnish docs) I think you have little evidence at this point that the ZODB is *suffering* from its design paradigm, old or not, compared to the different design approaches that Dobbin makes. You'll have to show *that* it is suffering and how another approach will mitigate that suffering. Before you do that, you can't come out and say it's suffering. If "does no memory management" is a feature these days, does this mean Python shouldn't use a garbage collector, say? I imagine the situation is a bit more subtle and has more to do with cache management, right? 
I think your error is in the statement: &gt; `b = a` This does not do what you intended, and so your expectations about what happen next are wrong. You've made `a` and `b` aliases of each other. Whatever you do to one will now happen to the other. Given that this is the case, what exactly did you expect `+=` to do? Implicitly having it do a copy would be even more confusing and unexpected!
a=[0,1] b=a[:]
Yes, that's what I would expect `a += b` to do: to behave like `a = a + b`! It already _does_ make an implicit copy in the case of strings/tuples, and I don't find anything confusing or unexpected about it.
They aren't. &gt;&gt;&gt; a = (1,2) &gt;&gt;&gt; b = a &gt;&gt;&gt; id(a) 19854840 &gt;&gt;&gt; id(b) 19854840 Both point to the same (immutable) value. Admittably this is implementation-dependent, but there is no need for copying. Assignment works exactly the same in both cases, the only difference is that tuples are immutable.
Actually, I think += works this way only for lists (I believe there are no other builtin mutable sequences that support +). However, it looks like sets/frozensets have the same disparity regarding &amp;=, |=, etc.
"A += B" means "add the object referenced by B to contents of the object referenced by A, mutating it accordingly, and let A remain as a reference to the (now modified) object" "A=A+B" is two operations ... "create a new object which contains both A and B, but leaving the contents of A and B alone", followed by "replace reference of original object A pointed to with reference to object which resulted from the addition" This is why it does something different, because the operations are not (in an object-oriented sense) the same. For lists (the prime case for this), += causes the original list to be extended, which makes sense, because it allows you to easily extend an existing list (which other peices of code may share references to... all of which now see the new content); whereas a+b creates a new list. The different behavior comes from the fact that lists are a mutable object (like dictionaries, sets, and user defined classes if they wish to be). For mutable objects, this makes sense, so the in-place operators (&amp;=, |=, +=, etc) have their normal behavior. However, immutable objects (tuples, strings, numbers) don't allow their contents to be changed, so += simply doesn't make sense. Try adding 1+2 and storing the result "in" the 1. You can't, you can only replace the _reference_ to the 1 with the result. Thus, for all immutable objects, += acts the same as +... but only as a fallback. They are different operations, not just two versions of the same thing. Sidenote: This is why the inplace operator slots when you're defining a user class (\_\_iadd\_\_, etc) have a slightly suprising behavior... \_\_iadd\_\_(self, other) can be defined in your class to perform whatever inplace addition operation you want, but the variable your object was stored in will now point a reference of whatever \_\_iadd\_\_ returns... so if you forget to return self, and return None, \_\_iadd\_\_ will make the variable seem to "lose" your object, instead of the expected behavior of leaving it alone. This is to account for the special case of immutable objects, where it's not possible to modify them. Hope that helps :) EDIT: fixed the markup
&gt;"A += B" means "add the object referenced by B to contents of the object referenced by A, mutating it accordingly, and let A remain as a reference to the (now modified) object" &gt;"A=A+B" is two operations ... "create a new object which contains both A and B, but leaving the contents of A and B alone", followed by "replace reference of original object A pointed to with reference to object which resulted from the addition" I guess it's all about how you interpret +=. The operator comes from C where it applied only to simple (immutable?) values, so there was no difference between both interpretations :) &gt;They are different operations, not just two versions of the same thing. That's why I don't like it - two _very_ different operations sharing the same syntax. (Actually I don't like concatenating sequences with + at all, but that's another story...)
Why is there no ++? Why is False and True capitalized and other language constructs aren't? Whats the deal with having to type __ everywhere. etc. Python has a lot of quirks manifested from the personal preferences of its creator(s). There is no rhyme or reason to many of these decisions.
++ has the same problem - it could mean assignment for numbers, and update-in-place for other objects :)
You are confusing the implementation with the underlying language. Semantically, they are two different (value) variables and not references. How it is implemented doesn't matter as long as it preserves this semantics.
Is that really how it should be called? As long as implementation is irrelevant, they can be different. But... &gt;&gt;&gt; a=([None],) &gt;&gt;&gt; a[0][0]=a &gt;&gt;&gt; a ([(...)],) Tuples are immutable, so are a, a[0][0], a[0][0][0][0], etc. all an infinite number of different values? Also, Python defines object identity (by means of `is` operator). Can't we say that if `a is b`, then a and b point to the same value? I see no point in speaking about assignment of mutables and immutables in entirely different terms - especially if the immutability is enforced only at the standard library level, not the language level.
I said different *variables*, not values. The values are not different. But you raise a very valid point regarding `is`, I would say there is an error there: &gt;&gt;&gt; a = (1,2) &gt;&gt;&gt; b = a &gt;&gt;&gt; a is b True &gt;&gt;&gt; b = (1,2) &gt;&gt;&gt; a is b False This is in my mind incorrect. Both instances of `a is b` should agree, but here implementation details leak over to the semantics (which I think is bad).
In Python if you say a = b then Python *guarantees* that a is b. It's fundamental behavior.
Okay, I see. You said &gt;`a` and `b` are the *same* list because mutable objects behave like pointers on assignment, while in the tuple example they are two different values. and that's what I disagreed with - I think in both cases `a` and `b` have the same value (are the same list/tuple). &gt;This is in my mind incorrect. Both instances of a is b should agree, but here implementation details leak over to the semantics (which I think is bad). I think object identity is a more implementation-level concept and doesn't belong to semantics as you define it. But then at some point it's inescapable, because implementing something it can make a difference between a program that runs and one that loops indefinitely (for example, when creating a cyclical data structure - copying references works fine, deep copying values would hang the program).
Translation: IT mostly sucks in India.
True, but if they're very good, they can do something amazing enough to move somewhere better. 
Yeah, I can see where you're coming from. But it actually makes sense to me _because_ of C. The thing you have to realize is that when you do "a+b" under C, it's not performing an operation on two numeric objects... "a" and "b" are both C variables implemented underneath as a (pointer, type) pair, the "type" part being semantic info that gets stripped out when C is compiled. Thus, when you do "c = a+b", C does exactly what python does... the "value" of a is added to the "value" of b, and the pointer tied to c is modified to contain the resulting value. *Under C, it's the variables themselves which correspond to python object references, not the value contained in the C variables*. You can pass around a pointer to a C variable explicitly if you want, but that's what python does all the time... the variable names are merely a scope-level mapping to the reference, not permanently bound to the (pointer,type) pair. Seen under this light, examine what C is doing when we do "a += b". The reason C even has this syntax is that it does perform a different operation... the value of b is added to the value of a, and stored at the location of a. But if we think of the C (pointer,type) pairs as being the objects we're working with (not the state stored within them), then "a+=b" adds the contents of the pointer bound to B to the contents of the pointer bound to A, mutating the contents of the pointer bound to A, and in the end A still points to the same object, but it's value has changed. And you'll note this is exactly how I defined "a+=b" in python. It's all down to the subtle difference between python and C regarding scopes... the idea of classifying languages as pass-by-reference vs pass-by-value (as my cs classes taught me) somewhat misses the point with python... pass-by-reference, as implemented in most C-based languages, is really pass-the-pointer, but the variables names in the human code are still tied to the "type" half of the (pointer,type) pairing... this fact keeps us mentally thinking about the variable as somehow "being" the object, since that's to a great deal true (see for instance how I defined an "object" under C above). This is where I had to mentally remap a little to "get" python... each variable is little more than a name... it's not a slot allocated in memory (the pointer) or a slot allocated in your head semantically (the type), it's just like symbolic link to an anonymous (pointer,type) pair... so there is _NO_ way to perform an operation on a single variable. You either perform operations on (pointer,type) pairs, or on a scope object (which is itself a pointer,type pair). Eventually when coding python, you'll find yourself wanting to pass around pointer to a variable like some sort of "holder", which other code can change and which will transparently modify the object pointed to the variable in the original scope. This is the behavior you get under C's pass-by-reference. But under python's (and java's) model, this is simply not natively possible, because variables don't exist in that sense. When I first encountered this situation under Python, I was coming from Perl, and felt very confused about why I couldn't do this. Figuring out this difference really helped me get python a bit better. (Oh, and there is a solution to the above deficiency... python code usually solves this via proxy objects (ala paste's registry system), passing around dictionaries representing the scope itself, or custom "value holder" objects... but no "best practices" pattern exists).
Then I stand corrected.
&gt; and that's what I disagreed with - I think in both cases a and b have the same value (are the same list/tuple). .. and perhaps you are correct and I'm not. In any case, I tend not to think about lists as values, but as references.
Equality and identity are different concepts. a = b This statement binds the name 'b' to *the same object* as the name 'a' is bound to. i.e. it establishes an identity relationship... Objects can be equal (as in the case of the tuples from your example) without being the same object. a == b does not imply a is b. (although a is b *should* imply a == b. You can implement equality so that objects aren't equal to themselves - float('nan') being one example - but it is unusual.)
There is no ++ because it is semantically "increment", and objects don't incement. That's what I read. True and False are specialized "str()" representations, not part of the language syntax at all. Labels. So it's cool that they're capitalized. Edit: I feel like an apologist, here. So be it. 
Where are you located? I haven't been to a major bookstore in years that didn't have at least one Python book (typically O'Reilly's *Learn Python*). And any bookstore that caters to the tech crowd but fails to carry Python (or Java, or Ruby, or C++...) books is a failure, IMO.
I find x += 1 more logical than x++ Just because it's in C doesn't mean it's a good idea. One of the goals for Python is that it should be easy to learn. Noobs would not understand ++ on first sight.
Durus even with the default FileStorage back end is interesting. I developed a sqlite and Postgress backend - it was trivial actually, but I find myself not using either as FileStorage for my purposes has always been sufficient. Durus was initially developed in 2004 and while its a relatively quiet crowd of users, it has been battle tested by many although certainly not in as many contexts as ZODB. Durus contains what you'd expect from a ZODB-inspired object store - persistent Dicts, Lists, Sets, and a Persistent class for developing your own objects. Its a small code base easy enough to read in a single sitting. Pycon 2005 presentation on same: http://us.pycon.org/common/talkdata/PyCon2005/17/Durus.html If you prefer processes to threads, the simplicity of Durus may be appealing. If Durus did not exist I likely would be using ZODB.
There is no ++ because Python distinguishes between statements and expressions. a = 1, a += 1 -- these are statements. You cannot use them in the middle of expressions like x = b + (a = 1), the way you can in C. ++ blurs the line too much. It looks like an operator that has a value as an expression; it does not look like an assignment statement. That works OK in C, in which assignments are expressions, but it does not match the rhyme-reason of Python. (Confusing matters is the fact that Python allows assignment statements of the form a = b = c = 27. This is a special form of the assignment statement, not a chain of assignment expressions.) False and True are capitalized because they are values, as opposed to purely syntactic keywords like if/for/while. This is consistent with the value None. In early versions of Python, False and True were not capitalized. Guido changed them deliberately for the sake of consistency. One person's "quirks manifested from the personal preferences of its creator" is another person's "carefully considered design decisions". There is rhyme and reason to many of the design decisions Guido made, even though you may not like them.
In Python *all* names are references - whether to mutable or to immutable objects.
This is what I expect to happen when you use a dataset larger than the physical memory available to the process: It'll have to page in objects on demand, e.g. the objects which aren't in memory. Note that it's a CPython-object which is being paged in (along with possibly other objects). The ZODB will instead load the object from disk, manually, and do its own book-keeping, too, about which objects are in virtual memory (physical or swap) and which are on disk. You can of course run out of virtual memory; the documentation asks developers to ensure that the swap partition or file is large enough to hold the database in its entirety. Disk space is abundant these days (that's the assumption anyway). This probably wasn't the case when the ZODB was designed. True; I present little evidence that ZODB is *suffering* from its design. And I do acknowledge that most its bad reputation comes from poor application design (putting binary files inside the database without proper support). Let me try on argument: In a single-system deployment on a multi-core server, you'll need to employ ZEO to actually put your cores to work. There's network latency and synchronization costs that simply aren't present in Dobbin's multi-process model (it does not support the network at all). Dobbin was designed with this use-case in mind: single-machine deployments, multi-process and multi-threaded. Failover? No real answer to that one yet. It's difficult with ZODB/ZEO as well; perhaps ZEORaid solves the problem for good; but the setup gets complex quickly. I'd like to try using a network file-system instead. Python has its own memory allocator as an optimization; it doesn't actually manage memory in the sense of a vmm. The allocator doesn't know if gets actual physical memory for instance. I actually think disabling its own memory allocator might work better for Dobbin-apps. Unfortunately this does require custom compilation of the interpreter.
Yes, yes, I concede already! :) In essence, that means = is subtly different from languages like C, Java etc. where one has both value and reference variables.
It's worth spending a little time comparing the approaches of Varnish and CPython object databases. In Varnish, the cache file is memory mapped into the virtual memory space. Objects live on disk, only making it into RAM through the VFS page cache. Varnish servers are often configured with no swap space. This approach is not available to a CPython object database. CPython objects must be resident in memory (which may be swapped out). This is the inverse of the Varnish approach. For a transient object cache this may not be a problem. For persistence, CPython objects must be serialised before they are stored. When reading from persistent storage the objects must be de-serialised. When the persistent storage is on the same machine as the object cache (as it must be with dobbin), the page cache will compete with the object cache for memory. I don't know if this will be a problem, but it is definitely more complex. It is worth noting that on a 32bit system only 4GB of virtual memory address space is available, so ZODB (and maybe even Squid) should not be accused of 1975 programming practices. Varnish is now working on [persistent storage](http://varnish.projects.linpro.no/wiki/ArchitecturePersistentStorage), it's structure has similarities to ZODB's FileStorage. It will be interesting to see how dobbin turns out. *** Is pickle speed significant? Some Google engineers recently wrote a very interesting paper, [The Datacenter as a Computer](http://www.morganclaypool.com/doi/pdf/10.2200/S00193ED1V01Y200905CAC006). The figures in section 1.6.4 "Quantifying Latency, Bandwidth, and Capacity" are particularly enlightening. It is twenty times faster to access data in the DRAM of another machine in the same data centre than data on a local disk. On my machine, unpickling a short, arbitrary pickle takes ~20μs, orders of magnitude faster than seek times of a rotational disk with a 10ms seek time. SSD flash drives are starting to replace rotational disks for database loads. ([~25 μs to load a 4K block](http://en.wikipedia.org/wiki/Solid-state_drive))
Arguably the points you make are valid, and convincing. Some comments are still due. I haven't seen a 32-bit server in production for a couple of years. But that's hardware; perhaps only now are we seeing these systems actually run a 64-bit operating system. Perhaps we can still accuse Squid and ZODB of 2005 programming practices - so slightly outdated, but not very much so :-) Varnish has the luxury of using raw data, which can easily be memory-mapped to a file on disk. Not so with CPython-objects, obviously. My reference to Varnish is about writing applications that do not *require* their virtual memory allocations to actually map to DRAM. And ZODB does make such a requirement. On pickling: it's valid point if we're talking about a single pickle. But we aren't; often times, you'll read or write many pickles in one go; the pickle operations then begin to matter over disk performance. Also note that while we wait for I/O, other threads can serve requests, as long as they're not also I/O-dependent. With Dobbin, threads are cheap.
When reading pickles, disk seek time is almost always going to be more significant than unpickling time - the pickles you want to read are likely to have been written in different transactions so will not be adjacent on disk and multiple seeking will be required. Even when writing (where it is all in one transaction) I would conjecture that you need to unpickle many hundreds of objects before it becomes a significant overhead with rotational disks. Having the object cache shared across threads is very interesting and is something I would love to see it in ZODB. It would certainly help our large sites which are mostly i/o bound.
x =+1 makes more sense to me
Hehe. Sorry.
Dobbin reads everything in one go; and catches up the same way. It's not lazy. This cuts away most worries; the reasoning is that it'll eventually load up everything *anyway*, so it might as well just get on with it. You probably have the winning conjecture, that pickling is a minuscule affair compared to I/O; but it's arguably still better not to bother with it too much if it can be avoided. After all, other threads/processes might want the processing power. 
It's not just the `repr`. In Python 2.x, `True` and `False` are the names of built in variables. In Python 3.x, they're keywords. 
`a = a + [3, 4]` creates a new list, leaving the `b` version alone.
Yeah, but `x.a = x.b` doesn't guarantee identity at all. I sometimes think that there should be some way to override `a = b` too.
"Strangely."
So basically, write RPython, use Psyco, and you don't have to worry about PyPy working / compiling, and get better speeds.
Does that work with native 64bit Pythons?
Unless you use a platform other than Windows. Last I checked, psyco was win32 only. EDIT: sorry, obviously I was thinking of architectures rather than operating systems. No PPC support, no x86_64 support. Personally I like [Cython](http://www.cython.org/) (a fork of Pyrex) for quickly turning Python modules into C extensions.
TIL that people still hold non-binary conversations on USENET. PS: to OP, you dropped this: "F".
Why understand the tool at all when you can just grasp the problem space? IDE's make it so easy to code blind, you aren't even aware that you're doing it. I shouldn't grumble too much. Cleaning up after the "IDE magic" developers after they get fired has been a lucrative career path. The world would be a better place if my career never existed, but unfortunately, a lot of people think like you do. The next time you brilliantly reinvent some efficient library built-in because the IDE let you do it painlessly, you've proved my point and given me a few more years of job security. If you *had* to look at code and documentation, you'd be more likely to see that the problem you're solving has already been solved more efficiently than you could in your high-level blub language. This is especially true if you're brand new and trying to *learn*. Your described scenario is not the kind of practice any self-respecting, professional developer should have. To top it off, let's put things into context. We're talking about an IDE for django, for god's sake. If that framework doesn't already hold your hand enough, you have no business developing.
No.
Even in India (Landmark shops specifically), one can find Python/Ruby books (sometimes, SICP too).
s/forzensets/frozensets/ s/eg/ie/
No, write beautiful pure Python code and watch our JIT speed it up for you.
""A += B" means "add the object referenced by B to contents of the object referenced by A, mutating it accordingly, and let A remain as a reference to the (now modified) object"" This is not correct; it does not explain the behaviour of += when both operators are tuples.
&gt;Your described scenario is not the kind of practice any self-respecting, professional developer should have. Yes. Forgetting function names is definitely below a professional developer... we should all have eidetic memory. How long have you been programming, son? How many libraries have you learned from scratch? My guess is not many and your "lucrative career path" cleaning up after the "IDE magic" developers is really just getting paid $7/hr to snark about misusing the .NET bindings that you memorized when you weren't beating off about how great you are. If you don't want to use CC, **don't**. Leave the rest of us imperfect souls to actually do something that matters instead of resurrecting 2 month old Reddit comments to talk about how much cooler you are than the lowest-bid Chinese contractors that you "clean up after."
Note that that was the explaination of += for mutable types (the only case where a+=b and a+b can be defined as distinct operations). Tuples are an immutable type, like a string or a number. This is of course a perfectly arbitrary choice for tuples, they could be considered mutable, and have list's += behavior.. but then they would _be_ lists. Tuples exist because frequently there are tasks which can be done more efficiently when you can rely on the immutability of your list datatype (eg: hashing based on contents for dict storage). They are to list what frozenset is to set. Thus, like 1+=2 doesn't make sense, it's the same for tuples. If a=(1,2) and b=(3,4), then a+=b can't perform an in-place mutation, so it falls back to acting like a=a+b, so a ends up referencing an new tuple holding (1,2,3,4). The reason there are two ops for this "special case" is that immutable objects are actually in the minority type-wise. Numbers, tuples, strings, bools, frozensets are the only ones I can think of. Whereas all the other std types, and pretty much every user type generally functions as mutable, and benefit.
These attitudes make me sad. Both that you run into employers like this and that people think they need to change themselves to conform to their stupidity.
map doesn't allow you to do this, neither does itertools.starmap, you'd have to roll your own starstarmap: def starstarmap(f, iterable): for args in iterable: yield f(**args) 
You need to have an intermediate function wrapping func(), which takes the dict provided by map, and performs the ** unwrapping. quickest way to do this is to wrap map... def dictmap(func, args): def wrapper(d): return func(**d) return map(wrapper, args) dictmap(doit, args) but this can also be solved by the equivalent (and clearer) list comprehension: [ doit(**d) for d in args ] 
I agree on the list comprehension, didn't occur to me though.
Both of your examples are awesome, unfortunately they only answer half my question unless I'm missing something. I don't know how either would be adapted to work with multiprocessing.pool.map I'm really a newb at this stuff, I feel like I'm missing something obvious, but I've been trying to make this work for hours...
That's because the PyPy people were trying to solve a harder problem than Psyco. Consider the fact that Psyco is tied to (32-bit) i386 and has been for a decade; that's no accident.
Ah, you can't readily alter the map function, since it's exposed as a method. In that case, you have to wrap the function you're passing in... easiest way is with partial function evaluation via functools.partial... from functools import partial def unwrap(func,d): return func(**d) blah.map(partial(unwrap,func), args) in case you aren't familiar with partial, g=partial(f,*a,\*\*k) returns a new function which is the equivalent of the function f with the arguments from a and k already filled in... any calls to g are like a call to f, just with some extra args filled in. Thus, if g=partial(unwrap,f), whenever g(arg) is called, it's like called unwrap(f,arg), which calls f(\*\*arg), as desired.
But the list comprehension would still work straightforwardly, wouldn't it?
yep! but if it's a map()-like method being provided by a class, it might not be generating a list, but some other datatype, or having some side-effect, in which case the list comprehension wouldn't necessarily work (or if it was used, would create an unnecessary temporary list).
&gt; The one thing we haven't been so lucky about is attracting specifists. It echoes like citizendium. But glad he makes a point of bringing them on board... about time I'd say when you want to dominate the world... &gt; I invite all you application developers out there to join that group and help us with world domination. I know it's meant to be taken lightly but I wish Glyph could get a grip sometimes and stop considering Twisted as some kind of holy grail. 
Like [polishing the decks on the Titanic](http://www.pyside.org/).
 map(lambda d: doit(**d), args)
have they decided to re-write their compiler for the 17th time yet ?
Yes, if Dobbin runs out of physical memory the OS will start to page in objects on demand. And it's certainly interesting to try this, and I'd like to see some data on how it behaves. The question is whether for the use case of an object database this behaves well. An operating system pager, even if fast and hardware accelerated, might not be the ideal pager for all applications, after all. But perhaps the application can take some control over what is in which page, etc, I don't know. I'm not sure why you are talking about disk space being abundant these days. It's not like the ZODB is optimized to save disk space. The ZODB's filestorage design assumes abundant disk space. I wonder how operating systems behave when configured with huge virtual memories. 'memory management' is a term so broad I don't think "doesn't do its own memory management" is a very useful feature description. Most applications need to manage which objects (or buffers or whatever) they return to the heap when they're done with them. Dobbin doesn't do any cache management but presumably it lets Python return objects to the heap; if you didn't you'd run out of memory very soon. Anyway, it sounds like a few experiments will need to be done before you can give some answers about Dobbin's behavior in the context of large databases. I'm looking forward to those results. 
I think 4.6 may be the last PyQt version I'll use. As soon as boost1.4.0 can compile on Gentoo i'm switching over.
Tuples are immutable, lists are mutable. When you try and append to the tuple (your first example), it has to create a new object, copying the old data and modifying it. This breaks the `b == a` link: &gt;&gt;&gt; a = (1, 2) &gt;&gt;&gt; b = a &gt;&gt;&gt; id(a) == id(b) True &gt;&gt;&gt; b += (3, 4) &gt;&gt;&gt; id(a) == id(b) False The same is true with strings, which are also immutable: &gt;&gt;&gt; a = "abc" &gt;&gt;&gt; b = a &gt;&gt;&gt; id(a) == id(b) True &gt;&gt;&gt; b += "def" &gt;&gt;&gt; id(a) == id(b) False When you add to the list, it can just modify itself without creating a new object, and the `a==b` "link" remains: &gt;&gt;&gt; a = [1, 2] &gt;&gt;&gt; b = a &gt;&gt;&gt; id(a) == id(b) True &gt;&gt;&gt; b += [3, 4] &gt;&gt;&gt; id(a) == id(b) True The difference is due to Python trying to allow in-place modification of an immutable object.. I think the "correct" way to fix this would be to remove the `__iadd__` method from the tuple, but that would be annoying, and I don't think it's a big enough problem to merit "fixing". If you're not sure what type of object your code will get, either convert it to the correct one.. &gt;&gt;&gt; b (1, 2, 3, 4) &gt;&gt;&gt; list(b) [1, 2, 3, 4] ..or use append, which will error if it's a tuple: &gt;&gt;&gt; b (1, 2, 3, 4) &gt;&gt;&gt; b.append(1) Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; AttributeError: 'tuple' object has no attribute 'append' ..or use `isinstance()` and treat each one separately: &gt;&gt;&gt; isinstance(b, list) False &gt;&gt;&gt; isinstance(b, tuple) True 
Last I checked PySide had a ways to go. So I'm not sure that it is a given that PyQT is done. And personally, I always like options, so I'd like to see them both keep pushing one another.
&gt; Last I checked PySide had a ways to go. It could be a quite a long way to go. Boost-python seems to be a dead end because it doesn't meet Nokia's size requirements (i.e. it is too big to fit in a mobile device). The pyside team are experimenting with creating their own backend to replace boost-python. This is a non-trivial undertaking and it is anyone's guess how long it will take. Another big question is how much money is Nokia willing to put into this project and for how long? Sure, pyside are trying to form a community of developers to help them, but I have to wonder how many developers are there in the world who find the cost of PyQt unreasonable but have plenty of time/money to donate to alternate bindings? 
Only if there is a property (or other descriptor) that triggers code. They're different operations. What do you want to override assignment for?
Navi mumbai, India. This blogpost is by an Indian. Shows the state of IT in India.
Only 5th!
FYI, here's more detailed documentation on [the new API](http://www.riverbankcomputing.com/static/Docs/PyQt4/pyqt4ref.html#selecting-incompatible-apis) and [the new properties feature](http://www.riverbankcomputing.com/static/Docs/PyQt4/pyqt4ref.html#support-for-qt-properties).
Besides a new license, what new features is PySide offering?
Actually being open-source, official Nokia backing and offers to increase pythonicity through a PEP-like community process.
Um? A list comprehension always returns a list. I don't see how a side effect could cause a problem, either. And you could always use a generator comprehension instead if the temporary list is a bad thing.
Whenever you'd write this idiom... result = [] for item in iterable: if condition: newvalue = dosomething(item) result.append(newvalue) ... you're really doing a list comprehension and you could just as well write it like this: result = [ dosomething(item) for item in iterable if condition ] I, for one, like to see one line of code instead of five. So your example code then becomes: def doit(arg1="default1", arg2="default2"): print arg1, arg2 values = [("hello","world"), ("goodbye","universe")] args = [ {"arg1": v1, "arg2": v2} for (v1, v2) in values ] processpool.map(lambda argdict: doit(**argdict), args) It's a little more obvious to me than the version with the partial function.
Yeah, I knew the blogpost is there - just wasn't sure about your comment. :)
How many architecture does PyPy JIT support?
&gt; That's because the PyPy people were trying to solve a harder problem than Psyco. ?????? I'm not so sure. Was not psyco essentially developed by a single person (Armin Rigo) over a very short period (&lt;1year)? . PyPy has been going for 6 years with some actual funding from EU.... I'm somehow certain that porting of psyco to 64-bit would take a similar (or smaller) amount of time. I suspect that the primary problem with PyPy was that they had too many goals with JIT not being the main goal. 
Sorry, some ambiguity there. I was referring to a map-like method (eg, Dfdoe's example of multiprocessing.Pool.map). That was what I was meaning might have side-effects or not return a list, not the function itself or the list comprehension. In such a case, the call would not be equivalent to a list comprehension, because you'd need to use the map-like method in order to get it's side-effect: In dfndoe's case, the Pool.map() method acts just like map, except that it breaks the input iterable down into chunks, and handles them in parallel in separate processes, before assembling the master list back in the caller process. Given the tools multiprocessing offers, that task couldn't easily be reformulated into a list comprehension, or bundled inside a wrapped map method (my two original suggestions). Thus, the partial-function or must_submit_this_pic's lambda option are the only way to go for this use case. In a normal case, where the function's evaluation wasn't so expensive (or list size so large) that you had to parallelize, a list comprehension _would_ be much more straightforward.
I have to say, I only use += for integers. For the rest, it's a bit ambiguous at a glance.
For me as well, as long as I want `x` to be equal to `positive one`.
I'm continuously surprised how ungrateful, and ungracious developers can be. PyQt is free for use free software and has a perfectly reasonable license fee for commercial closed source software considering that it allows you to use one of the most well developed cross platform libraries from one of the more productive languages. PyQt allows you to be productive today with Python and Qt. PySide is a great example of a large corporation undercutting a small independent developer who has brought something very positive to the market. Is that a good thing?
Over to what?
Why did nobody port Psyco to 64bit then? It has been requested a lot, but nobody did it so far. Psyco might have been written in a short time, but it is a very complex piece of code, that only two persons ever managed to somewhat understand. Also the point is that it is getting increasingly hard to add features to Psyco, because the more complex Psyco gets, the harder it is to understand all interactions (and thus to fix bugs). It took Christian Tismer (who is working on Psyco2) more than a year to add generators to Psyco. The idea of PyPy's JIT is that once the JIT generator is in good shape, PyPy's JIT is right by construction, and it is easy to add support for many language features.
32bit x86, as well as a .NET backend, which produces .NET assembler at runtime. However, the point is that it is *easy* to add support for a new architecture, because you need to write a backend with a defined interface only, not rewrite the whole JIT (which would be necessary for Psyco).
&gt; Why did nobody port Psyco to 64bit then? It has been requested a lot, but nobody did it so far. Probably because it's hard ;-(... &gt; The idea of PyPy's JIT is that once the JIT generator is in good shape, PyPy's JIT is right by construction, and it is easy to add support for many language features. I hope you are right, but worried that PyPy JIT framework will be even more complex piece of software than psyco ;-(. Also, psyco was an add-on, pypy would need to replace Cpython which is likely to be a problem for wide-spread adoption.
http://www.reddit.com/r/Python/comments/9opqe/ann_pyqt_v46_released/c0dq5p8
&gt; I'm continuously surprised how ungrateful, and ungracious developers can be. PyQt is free for use free software and has a perfectly reasonable license fee for commercial closed source software considering that it allows you to use one of the most well developed cross platform libraries from one of the more productive languages. The simple fact is that lots of folks who develop applications on a consulting basis would love to use Qt, now that it is LGPL, but are prevented from doing so by PyQt. Permanently tethering your entire development team to licenses bought from Riverbank is no more an option than GPLing your entire product. &gt; PyQt allows you to be productive today with Python and Qt. PySide is a great example of a large corporation undercutting a small independent developer who has bought something very positive to the market. Is that a good thing? As I understand it, Nokia made offers to buy the PyQt intellectual property outright. The developer refused. When Qt itself went LGPL, everyone saw the writing on the wall: Python bindings under a more restrictive license were an unsustainable situation, and something was going to give. I agree that Riverbank was put in a difficult situation, but this really was inevitable.
good point!
Awesome!!!! This works perfectly, thank you very much for the hand holding.
Meaning: Python Deployment *on Windows* Sucks.
Agreed. And the assertion that "you can simply give the binary to someone with the right operating system" is bullocks, too. 
Exactly. Nothing interesting on this article, as it only talks about Windows. Deployment of python on good OS is just Simple.
voted down for misleading hyperbolic title. should be 'python binary creation is difficult'.
FTA: &gt; The only reason this seems harder in Python than it is in other languages, is that when using other languages you often don’t even attempt to deploy across multiple operating systems. Nothing ground breaking in this blog post, though it got me thinking. Sounds like a Py2App+Py2Exe+... wrapper for deploying multi-platform python scripts could be awesome.
Oh, for example, just out of laziness when using the interactive shell it'd be nice to say `clipboard = "string"`. As it is, I've completely abused `__div__` and overloaded it to copy things for me. I'm sure though that GUI people wouldn't mind being able to set properties a bit more simply either.
Could you use a generator comprehension () instead of [] ?
Here's the discussion that lead to all of this: http://mail.python.org/pipermail/python-list/2001-July/091966.html 
In a general case of some mapping function, you could, you'd just have to pass an identity function to map, since the generator is doing all the work... pool.map(lambda x:x, ( doit(**d) for d in args)) There's a catch which will bite you with pool.map though... pool.map gets passed a function and an iterable, and breaks off chunks of the iteratable to be passed to parallel tasks before running them through your mapping function. But now, the heavy-calc function doit() it inside the generator, so when pool.map "breaks off chunks", it's having to evaluate doit() inside the main process, not the parallel process (as was desired). Which, for this use case, is expensive enough that we want it to run somewhere else. Thus, you couldn't do a generator comprehension for pool.map, but another map-like method (where there wasn't some side-effect benefit) the example I gave would probably work.
Can you explain what you're actually trying to accomplish? You've described a method for accomplishing something but it's pretty confusing.
You mean I won't be able to do "False = True" any more? D;
&gt; The simple fact is that lots of folks who develop applications on a consulting basis would love to use Qt, now that it is LGPL, but are prevented from doing so by PyQt. It would appear that in this sentence "prevented" means "Riverbank isn't acting like some kind of software Santa showering these consultants with free gifts which they can use to create their own closed source for-profit software". &gt; Permanently tethering your entire development team to licenses bought from Riverbank is no more an option than GPLing your entire product. And yet this is the business model which Trolltech successfully used with Qt for over decade. A lot of closed source developers didn't have a problem with it then. 
I thought they stopped using boost::python...
Not yet. That's for the future as right now they are trying to get PySide to work on Win and Mac and Boost is needed for that. A quote from Matti Airas, one of the devs, in the mailing list &gt; I'm sure others can chime in on the build system specifics, but at this point I can just mention that Shiboken is an experimental boostpythongenerator replacement and thus is (currently) not required at all. So you can safely skip that.
Go ahead, write what you want. Start a project (or join an existing project), convince others to contribute, etc. Feel free.
I can get a bunch of Python books in Pune (almost all O'Relly books). I don't think you are looking hard enough. As lustymonk said, you can get Python books in Landmark store but you have to look through the whole 'Computer Related' section. 
This is a really cool project. I was hunting for benchmarks and came across this: http://codespeak.net/pipermail/cython-dev/2008-March/000108.html Note that these numbers are _not_ using the type definitions --- they're for compiling the Python source verbatim, which results in a ~30%ish increase. I know benchmarks are largely meaningless, but I'd still like to see some "best case scenarios" for non-trivial code using the type definitions... I might try playing with some of the language shootout examples.
&gt; It would appear that in this sentence "prevented" means "Riverbank isn't acting like some kind of software Santa showering these consultants with free gifts which they can use to create their own closed source for-profit software". I'm not suggesting Riverbank *should* be "software Santa". Everybody has a bottom line to protect, and that's Riverbank's prerogative. But "GPL or buy a license for every developer" is an unacceptable arrangement for many, and that's *their* prerogative. &gt;&gt; Permanently tethering your entire development team to licenses bought from Riverbank is no more an option than GPLing your entire product. &gt; And yet this is the business model which Trolltech successfully used with Qt for over decade. A lot of closed source developers didn't have a problem with it then. And guess what? A lot of them did, and went with other options instead (WX, mostly). Now that Nokia is less interested in selling licenses than pushing adoption, the business goals of Qt and PyQt are in conflict. And Nokia did offer to buy him out. From what I hear (from a little bird), the kind of money he wanted didn't match the cost of just reimplementing the whole thing, and so here we are.
seriously ... the comment to code ratio in that file is ridiculous. how is that readable as either source code or comments ... 
You just made me download it. Thanks a bunch.
Augmented assignment operators have always had optional in-place semantics for mutable types. It's used very, very frequently in e.g. NumPy, where you definitely don't _want_ to always be allocating new arrays if those arrays are several hundred megabytes each.
This would probably be better off in another reddit, like /r/funny.
It's not clear to me why you'd ever want to use this instead of, say, NumPy.
Notably, Cython is a feature-focused (amicable) fork of the old [Pyrex](http://www.cosc.canterbury.ac.nz/greg.ewing/python/Pyrex/) package, with much greater compatibility with Python features. It also generates C code which works unmodified on both Python 2.x and 3.x, making it a _great_ way to write extension modules and maintain compatibility across the 2/3 divide.
Too bad it's GPL.
Yeah, it's kind of a slap in the face to Pygame itself which is LGPL.
Or Pyglet, which is BSD.
Does this use Pyglet, though? Seems like it doesn't from what their FAQ says.
I went ahead and connected to my existing Hudson instance for running Python tests and it looks pretty slick (yay graphs!) For a larger project, you should definitely specify a list of files to generate coverage for when executing: &gt; coverage xml
You might try [Rabbyt](http://matthewmarshall.org/projects/rabbyt/). It seems to provide similar functionality and is released under the MIT License.
I was going to ask this in the dobbin article's discussion, but why would one use SQLAlchemy over an object database like ZODB or dobbin or durus? I have experience with SQLAlchemy but I typically find myself more or less writing code to simply serialise my objects into a database. While that might not really be the "right way" to use relational databases, that's what makes my life easier... So I'm quite interested in reasons for or against using object databases for, say, web content, or really any situation where a relational database would be traditionally used. I suspect the answer to this would be clear to me if I really understood relational databases design decisions and how they're intended to be used. I can't help but feel like I'm an imperative programmer trying to program imperatively in a functional programming language when I'm using a relational database; I get it done, but I have suspicion i'm "doing it wrong".
If you learn python and django your php will improve. As long as you keep writing php you won't lose your skill. If you're finding work with php fuck your jobless friends. They can make fun of you till the cows come home, but you're the one who can afford the fillets.
I guess I should sit back for a year or two and wait until Django gets a bit more steam in companies?
I have no idea how you read that from my post, but no. Unless your self post is to just validate your laziness about learning new things, try python and django and ruby and rails and expand your skills. But, if you're finding work doing php then keeping making money with php.
Sorry, its just when I read "If you're finding work with php fuck your jobless friends.", It kinda hit me that why change my direction (from php to django) when I'm already doing well with PHP...
So?
Losing your PHP skills will be a net gain.
Php is on a downward spiral. it is still very common, but for many pro, php is dead, python is the way to go. (php is very noob-friendly, hence his ubiquity, and in the past there were no solid alternatives, except *maybe* java). There is a lot of inertia (that's why you still find a lot of job offer). But python is a good way to still be relevant in 3 years (you'll be proficient at this time). Beside, php because of its target (websites) limits you. Your mental model is limited by the scope of php applications. Did you ever code a parser, an interpreter, a opengl game (see pyglet), a networked app with a qt frontend that's all of these ? if autodesk, google, nasa, etc use python maybe you should to. it has prooven to be a efficient&amp;versatile tool. so **php to eat, python to grow!**
I love you. &lt;*cracks open dusty "python for beginners" book*&gt;
So? maybe I want to make a game I wish to share freely with some friends and some internet community while having no intention of giving the source code of the game away or putting it under the GPL for whatever reason. Of course they license however they want I just rather use stuff with other licenses. Frankly I think licensing a library with GPL is a bit of a jackassery.
slides: [http://conference.scipy.org/slides](http://conference.scipy.org/slides)
several millenia and layers of abstraction later a lone man opens up his python interpreter and types in the following prophetic words. import universe universe.universe(letThereBeLife=True) Some of the people in the new world prayed to the god that created the universe and some argued whether god really existed, but most of all they waited for a sign. But his presence was never felt in the new world he created, for he forgot to bind the instance to a variable. And so they waited through the ages until they were garbage collected. Amen. 
You won't 'lose' skills by learning different languages; rather the complete opposite. It'll make you a &lt;i&gt;far&lt;/i&gt; more competent developer in general.
No talk of VTK? Vtk interacts nicely with Python, and is very useful for scientific visualization.
Seriously, it took me one afternoon (like three hours) to get the fundamentals of Python. It's that easy. I'm not much of a web guy, but I did spend a year writing a website in PHP that never got off the ground. Python is awesome.
Yes it does - the Python logging module hands you back exactly the same logger object by name (it even has the same memory id). You can also arrange them in to a hierarchy, so for your case you could do this: serial_logger = logging.getLogger('yourapp.serial') serial_logger.debug('I am the serial logger') file_parser_logger = logging.getLogger('yourapp.fileparser') file_parser_logger.debug('I am the file parsing logger') Then you can attach handlers to the parent 'yourapp' logger to pick up messages from both of those other loggers: logging.getLogger('yourapp').addHandler(FileStreamHandler(...)) 
Looks like the VTK stuff happens in [Advanced Tutorial 9 - Mayavi/TVTK](http://www.archive.org/details/scipy09_advancedTutorial_9) Mayavi[2] is essentially a GUI frontend to VTK.
In my universe, "universe" is a builtin.
I recommend [Dive into python](http://diveintopython.org/)
Funny. I get a DeprecationWarning... O_o
Hi. Except most *users* are on Windows, so what sucks there, sucks for all of us, unless you're planning on writing programs that nobody will use.
Very fair. Thanks for the guidance. :-)
Hey Louszatakk, So I'm fuzzy on how I'm even supposed to be doing binary deployment on Linux (I postponed it until after I figured out the Windows side of things) - is it just a "setup.py bdist", or have I completely misunderstood? Thanks!
Hey ringzero. It's only sort-of bullocks. For small programs without complex dependencies, like a new command-line script for example, it works fine. And this is exactly the sort of program which (a) Everybody agrees Python is ideal for (even people who don't like Python) and (b) is a small project, so fiddly binary deploy burns up a large proportion of the time, thus killing a larger proportion of otherwise working small projects than it needs to. So even though the statement is kinda-bullocks, I think it's also still significant, because there are real, pragmatic consequences that I think are hurting Python adoption.
I agree there's nothing ground breaking, and I wrote it. That's why I shamefacedly suffixed it with 'from the a-crap-post-is-better-than-no-post-at-all dept'. Thanks for the feedback.
Alright, so I went reading about bdist, and that's clearly not it. It doesn't attempt to include an interpreter. So what should I use? bbfreeze? That seems *exactly* as fiddly as py2exe. Guidance gratefully received, many thanks.
Yes. ###SWITCH Send me a check ;-)
You create a Free software and it will then be included in distros by many benevols. OR, you make a .deb and a .rpm to cover 99% of the distros OR (this is the wrong way to do it, but this is the way proprietary software who don't understand the Gnu/Linux-way-of-life will do) you just give an archive containing your sources, all dependancies, and a python file with an explicite name, like your program's name, and it will run your program when clicked, because Python is already installed. Your main python file IS your binary. (but yeah, it's not ONE file, it's an archive you have to extract, and then run the main file in it)
You should really check out some Python docs, books, tutorials etc. and see how much better the design is vs. PHP. It blew my mind how well designed various functions are compared to their PHP counterparts... everything from the date object, to lists and dictionaries vs. arrays, to basic operators and so on. There's certainly not any danger of losing your PHP skills, you could only become a better programmer in general and look at PHP in a new light (that's good and bad) if you had to go back to it for a job or something.
I wouldn't recommend it any more it's heavily out of date and some of the examples are broken. http://docs.python.org/tutorial/
My story is similar. I started with PHP and eventually settled in with codeignitor. After spending every waking moment studying the codeignitor docs I stumbled across Django. After working with django for the past year I now disavow any knowledge of PHP and cringe when I have to look at PHP code.
Advocates the sort of thing Python makes trivially easy and tremendously useful, but so much code written in the language lacks. +1.
I code in C#/ASP.NET at work and Python/Django at home for fun and personal projects. Whenever possible i try to do things in Python, and if I have a new idea that I just want to hash out quickly I can whip it up in Python/Django very very quickly. Most of what I do at work requires that I use C#, but I'm planning on trying to push Django for future projects wherever I can, because my current company is really all about using the best tool for the job. So to sum up my thoughts, keep on doing what you have to do to make the money, but **absolutely** learn Python and the Django framework as well, doing so will make you a better programmer. Mark
I'm from the exact same boat. I was pretty well versed in PHP and started to use CodeIgniter, then the power of Django called to me. I had only a cursory knowledge of Python at the time, but I feel once you "get" programming picking up languages is fairly easy, it's just mastering them that takes time. My experience with Django has been excellent thus far, there are tons of helpful resources to get you started. My coworker is still using CodeIgniter and I think he's getting tired of me running into his office like a kid on Christmas everytime I find out something cool about Django. It's really pleasant to work with and it has helped me quickly turn out quite a few fun projects. 
then try this one: http://diveintopython3.org/
That would be a mistake if you want to get the interesting jobs. If Django does become more mainstream in two years and you start learning it then you'll be a junior Django programmer and the more interesting companies won't hire you. If you start learning Django now then in two years time you'll be a "senior" Django developer and you'll be able to pick and chose the job you go for.
I'm the co-creator of Django, and you might be reassured to hear that both Adrian and myself were PHP developers when we created Django - it's pretty much designed to be an upgrade path from PHP. That said, this was back in late 2003 when none of the current PHP frameworks existed. If all you care about is getting a job, PHP will continue to be a better bet than Django for quite a few years. If you care about getting an *interesting* job, time invested in learning Python and Django will be time well spent. I'm not saying there aren't interesting jobs in PHP, but my hunch is that the percentage of Django jobs that are interesting is higher than the percentage of PHP jobs that are interested. That said, being a Django person I'm pretty strongly biased in my definition of "interesting". As others in this thread have said, learning Python (heck, learning any language) will dramatically improve your skills with PHP, just by exposing you to new ideas and new development patterns. I like to think you'll learn stuff from Django that will benefit your PHP development as well.
You don't wait until your current (and apparently only!) skill is useless before learning a new one. Learn Python and Django, and if you don't use them, great. But it doubles your employability. It may also teach you new ways of thinking that you can bring to your current job. Repeat next year with skill X, and the year after that with skill Y. Don't stop learning just because your current skillset is paying well.
I started with PHP and got quite advanced with it. Then I moved to Django because my colleague heard about it and we were pretty amazed by the admin interface when we tried it. The learning curve wasn't really easy but the good documentation helped a lot. A year later almost the sites I produced were in Django and my love for it never stopped to grow. Then I convinced a friend of mine to give it a try. He has a degree in software engineering and was sold to PHP and Java. It's almost been a fight to make him try eheh. This week he came back to me like he just had an epiphany. He just had re-factored major parts of his project and suddenly he *saw* :)
Thank you :)
Thanks! Django has helped my PHP -&gt; Python transition as well.
Keep it coming! Any Twisted related help is welcome.
And then there's the Djang Book, awesome in a nutshell. I was having trouble getting to grips with Django until I started reading but the book gave me a good idea of how the parts are meant to be used. Great stuff! http://www.djangobook.com/
Digg died after it was owned by Huffinton Post. No techies I know read it any more. Good post of example scraping code though. Thanks. Phillip.
Hey tartley. You've misread my comment I think. Here is the longer quote from your blog: &gt;With a compiled language, you can simply give the binary to someone with the right operating system, and they can double click it to run it. Which is simply not true, not on windows, mac, or linux. Granted, it may work for some users of some programs some of the time, but it is certainly not universal. I don't have anything to say regarding your Python-specific complaints, other than it seems like your "compiled language" background is coloring your perceptions of how software can be developed and deployed. 
Just use it? Try it on a test project. No need to fuss about it. Edit: I use django, its way better than PHP. I hate reading PHP code.
Only if your serious about using Python 3. Alot of libs don't support it yet (I don't think Django does..?)
Django does not yet support Python 3. I think the timeline they mentioned at Pycon was Early-Mid 2010.
I am getting paid to use Python (in on job) and Django (in another job, few years ago, before Django went 1.0). OTOH, I have never got a penny for writing PHP.
finally!:))
there was a similar thread [here](http://www.reddit.com/r/programming/comments/9kin1/please_convince_me_to_use_python_over_php/), I'll quote my answer from there: &gt; I think PHP is fine for small things but lacks the structure to consistently achieve larger goals without going nuts. &gt; &gt; this doesn't mean there isn't large or sane projects on PHP but to my experience it is far harder to achieve that on PHP than anything else, PHP requires a lot more discipline to follow the Right Way. &gt; &gt; in any case give it a try, you won't lose anything from learning something new and once you experience it you'll feel the difference for yourself (as the Propel guy did). &gt; &gt; ps: I do work with Python but not necessary advocate it, just try something new maybe Ruby or Scala, maybe Python maybe something else. &gt; 
import think
Twisted is so passe!
replies from the java side are much more educated than the initial commenter: http://www.reddit.com/r/java/comments/9pm6v/what_does_rjava_think_of_this/ glad to see they're not all like him.
September internet.
Why didn't he just place the map on the equator?
What do you mean by this?
&gt; I code in C#/ASP.NET at work and Python/Django at home for fun and personal projects I did that for a time, even though C# is a nice language, I still always wished for Django at work
That the commenter is an idiot. Google didn't hire Guido van Rossum, Alex Martelli, and a bunch of the other brightest Python minds to write shell scripts. They didn't start Unladen Swallow for shits and giggles. And they certainly didn't make Python the first GAE language for fun. Oh yeah, Youtube, check it out :)
And you would recommend instead ...?
I was just looking for something like this! Great article - thanks to the author, and thanks to you for submitting it (assuming gst is not article author)
Why do I live in this shitty world. I want to go to Middle Earth...
gst maybe a Python channel bot :-)
gst is a general-purpose postbot, he's active in pretty much every domain though mostly programming and economics.
And Python was not ,,written by some bitch who felt the compulsive need to write his own pet language as a way to stroke one's ego.'' But that ass probably never heard of Amoeba OS as well.
Real men write their own sockets code!
That's good stuff. Better than the TNPE book ;)
awesome. A little buggy against MSSQL (yeah, I'll report that) but it connects and runs queries and doesn't get desynched and even looks nice. Tools like this on Linux tend to blow up or fall out of maintenance before I find them -- so far I'm really impressed with this one, and hope it's here to stay.
Apologies for resurrecting a months-old thread. I'm dealing with generating Python again and though [our system works](http://code.google.com/p/ponyge), it's not ideal. Do you have a description of the method you used written up somewhere, please? Really, any pointers to approaches other than mine would be useful. At the moment we use "{" and "}" to indicate opening and closing blocks, but obviously this isn't ideal because of the clash with dict literals. Do you use custom tokens, like BEGIN and END? Or more specific ones like BEGINDEF and BEGINWHILE, etc? Another thing that bothers me is the need to use both eval() and exec() depending on the contents of the string, but that's a story for another day. Thanks!
Okok, so it's not really the biggest number, just the biggest uri (2068). But still it's interesting that this page doesn't check for limits. I wouldn't have noticed this if google had implemented a "last page" button.
Wow I almost feel like I can also do some python packaging.
I find it a bit annoying that Pyhton developers often snubs windows users, it's a tad arrogant...
Is the name meant to be a reference to [Toad](http://www.quest.com/toad/?gclid=CPvckfeCnJ0CFYZM5QodnBT57w)?
Why is that arrogant (seriously)?
Because he is using windows, and they should develop for whatever platform he is using, not the platforms that they themselves use, duh!
Can anyone comment on using DOxygen with Python?
http://www.youtube.com/watch?v=Dy6uLfermPU 
This reinteract tool seems very cool, I'll be sure to try it out for a presentation sometime.
Actually, RTFM: http://code.google.com/p/crunchyfrog/wiki/InstallingOnWindows I think arrogant is a poor choice of words. It's perhaps possible that he/she/they don't have a windows box to compile on.... I don't.
What a stupid, meaningless name.
This is why these stupid Python developers should stop being so snobby about their "freedom" and just start using Mono. C'mon, already!
[It does have a meaning](http://www.youtube.com/watch?v=Dy6uLfermPU). I agree it's a bit odd for a software project though.
&gt;Do you have a description of the method you used written up somewhere, please? [Here's how Python itself does it](http://docs.python.org/reference/lexical_analysis.html#indentation). Namely, &gt; Before the first line of the file is read, a single zero is pushed on the stack; this will never be popped off again. The numbers pushed on the stack will always be strictly increasing from bottom to top. At the beginning of each logical line, the line’s indentation level is compared to the top of the stack. If it is equal, nothing happens. If it is larger, it is pushed on the stack, and one INDENT token is generated. If it is smaller, it must be one of the numbers occurring on the stack; all numbers on the stack that are larger are popped off, and for each number popped off a DEDENT token is generated. At the end of the file, a DEDENT token is generated for each number remaining on the stack that is larger than zero. 
I've seen code documented using Doxygen and I can definitely say it does /not/ look as pretty as the corresponding Sphinx documentation.
Looks cool. I'll definitely give it a whirl. Don't think it will replace Navicat for me, which is IMHO the best $79 you can spend if you work with MySQL or PostgreSQL.
Very good article!
how can i run this on windoz ?
you needed not to link to that expensive POS
I have an *actual* crunchy frog.
i have navicat (v. 6.3.6) ... but honestly i use phpmyadmin a ton more. what do you like about navicat out of curiosity?
It's great for XML import/export, and the table browsing is a lot faster than phpmyadmin.
Ah, that's really interesting, and I should've thought to look there first. But my problem is a little different -- I'm generating python code using a context-free grammar, rather than lexing/parsing. Eg: &lt;code&gt; ::= def f(x):{return &lt;x_expr&gt;} &lt;x_expr&gt; ::= x &lt;op&gt; &lt;n&gt; &lt;op&gt; ::= * | + &lt;n&gt; ::= 1 | 2 | 3 Here I'm using curly brackets to indicate the blocks. The grammar will produce a string like this: def f(x):{return x + 2} and we translate that by iterating over characters: for every {, we increase indentation and insert a newline plus indentation; for every }, decrease indentation, insert newline and indentation. It works but I never felt fully happy, partly because of the clash with dict literals. Writing INDENT and DEDENT isn't ideal because since they're tokens rather than single characters, I'll have to worry about the single spaces beside them. In the meantime I found [this](http://effbot.org/zone/python-code-generator.htm) which isn't usable for me but at least indicates that someone else is thinking about python generation. Anyway. Any further thoughts would be very welcome. Thanks!
Thanks Louizatakk, your pointers are much appreciated. I must confess I hadn't even considered using .rpm or .deb because so many of the Python distutils discussion seems to be adamant that platform distribution systems like these cannot be a solution for distributing Python libraries. I do not recall the reasons for that though - maybe I had misunderstood. Also, I was concerned that a Python application might depend on a particular version of the interpreter, (esp. as 3.x becomes more prevalent) which is not installed on the system by default - but I suppose you could specify such a dependency in your .deb or .rpm dependencies, and the right interpreter should get installed, harmlessly living side-by-side with the system default? I'll try it out, see how it works for me. Thanks for the guidance.
I suspected so
For me, the hope for a more Python interface is a bigger deal than the new license.
A Pythonic API
Not yet it doesn't.
Then again, so is python.
isn't beautiful soup a bit slow to use for every page you serve?
I had the same thought as well. I'd love to see some benchmarks on this. Guess I could always do my own...
This already exists in SciPy: http://docs.scipy.org/doc/scipy/reference/cluster.vq.html
I really enjoy coding in Python. As others have mentioned, learning new languages is never a disadvantage. What you learn from one language can influence the way you think in other languages. A Django project will either convert you, or improve your PHP skills by broadening your knowledge.
i don't get it. why not just write your templates correctly in the first place?
Wow that's verbose. I once wrote a kmeans algorithm in about 5 lines. Granted, there were less comments, but the kmeans algorithm is quite straitghtforward, isn't it?
Furthermore, I have never found a DOxygen generated manual to ever be very helpful.
cache it...
Wow that's old. 2005. Not that old things are bad, by any means.
You know, in html 4 (which you all use, right?) some [closing tags can actually be left out](http://code.google.com/speed/articles/optimizing-html.html). Besides, this seems like a very silly way to do html prettifying. Think of it this way, for **every** response you send, you're processing the response, reformatting it, and sending it on it's way. That's bound to be slow. Middlewares are cool and all, but think twice before doing this kind of response rewriting (I'm looking at you CSFR middleware).
That's some ugly code. What are all the semicolons doing there anyway…
That is easier said than done with filters, macros, template tags, template inheritance and so on. I would say it is almost impossible for any reasonably complex template. If you were to indent everything *correctly* in your template they tend to grow uneditable.
Never had that problem. Never seen that problem. And, yeah, I work on some fairly complex sites.
It is much easier to use pyglet and get the benefits of OpenGL accelerated graphics
Clearly you are a better programmer/template designer than I am. Judging by your apps I would say this is indeed the case. We might have a different idea of _correct indentation_, too. I don't know. But I have just checked the HTML source of a site of mine and it isn't as bad as I thought. Just a few blank lines... While I have you here: Would you mind revisiting [issue 1](http://bitbucket.org/ubernostrum/django-registration/issue/1/accept-template_loader-in-views) of django-registration?
Where exactly are the slides?
It will also be much much much faster in SciPy. Nonetheless, it may be interesting to someone learning the algorithm - the author has been quite thorough in annotating it.
Using this with my sybase database at work. Works like a charm!
So basically, SQL over SQLAlchemy over SQL?
No. &gt; It is &gt; a fairly thin wrapper, which provides the ability to create simple &gt; Python classes that map directly to relational database tables... &gt; ... providing a simpler &gt; syntax for defining model objects when you do not need the full &gt; expressiveness of SQLAlchemy's manual mapper definitions.
Oh hey good job licensing your fucking LIBRARY as GPL.
It's the so-called semicolon cancer. Not the real WTF, though: --self.CreateDelay; ++self.TargetSpeed; ++self.NumTargets; and if (distance &lt; self.TargetRadius): target.HitTime = Gloss.tick_count ++self.NumHit I imagine this guy trying to use postincrement, failing and then discovering that preincrement "works". Then I think about how he failed to notice that his code doesn't work really, or didn't bother to test, or decided to ignore it. Like if he is programming like a half-blind man wandering in a thick fog, picking snippets here and there and sticking them together, without any real understanding of what's going on or a perspective on what he is doing. **_PIG DISGUSTING_**
This is horrible for code maintainability. Imagine asking yourself "When I add this new element, will it be inside or outside the div that I opened 200 lines above?" Better to just write it correctly the first time through. Not to mention the fact that this is wasting cpu cycles rendering the page. This can't be fast. And no, you can't just cache it; not if you have have a large dynamic page.
&gt; You know, in html 4 (which you all use, right?) some closing tags can actually be left out. Furthermore, [HTML5 keeps that feature and clearly states which elements have implied end tags](http://dev.w3.org/html5/spec/Overview.html#closing-elements-that-have-implied-end-tags) &gt; Besides, this seems like a very silly way to do html prettifying. Think of it this way, for every response you send, you're processing the response, reformatting it, and sending it on it's way. That's bound to be slow. Yep. And if you want to output nice and correct XML (to serve as XHTML 1.0), you should be using Genshi.
It worked well for me on ubuntu with mysql. It works far better than the gui tools I found at http://dev.mysql.com/downloads/gui-tools/5.0.html which can freeze for minutes at a time (the query browser anyway). This is a great little piece of software.
From "pylint sharpshooter.py" Global evaluation ----------------- Your code has been rated at -543.01/10 That's impressive as i've got a load of disabled-features in my .pylintrc. I've only every managed -2 [edit] Holy shit. We have a winner. Despite being 1/10th the size of sharpshooter.py, skeleton.py is: Global evaluation ----------------- Your code has been rated at -2796.43/10
Here are [the slides](http://unladen-swallow.googlecode.com/files/Unladen_Swallow_PyCon.pdf).
awesome, thanks!
It's the templates themselves you have to edit - so just make sure they look good and nicely structured. It doesn't really matter about the end result HTML indentation and "prettyness", it's only intended for the browser. Closing tags automatically is OK I guess, but that would be done if the templates have the closing tags. So just run a validation on your html to catch any missing tag screwups. If your worried about white space/excessive bandwidth in your output html use the {%spaceless%} thing. Reddit must do a similar trick, all their pages come out as one liners. 
Was yours extensible and robust? Why don't you go ahead and post it somewhere?
&gt;Was yours extensible and robust? Nope and nope :)
crysis was made in minutes.
Well, I think his could be improved. I would post my own, but there's too much needing improvement in my own too. * To give a specific example: I don't think the centroid calculator should be a method in the class, since it's in the orthogonal clustering strategy. For instance in my work, the representative isn't necessarily the centroid, but rather the lowest energy configuration.
ah right, I feel like a fool, but then again this doesn't work with truley dynamic site.
Don't do it for every page load, wrap it it in: `if request.user.is_staff`, or `is_superuser`, or `groups.filter(name="Developers")`, whatever indicator your company uses for "This person is serious business". No one else gives a shit what your HTML looks like.
Thanks for the nice exposition. Anyone have practical experience with k-means++ [Arthur &amp; Vassilvitskii 2007] as a better way of seeding the cluster? 
I agree it is not very useful as a practical example but is a great example of how to integrate a 3rd party app into django middleware. Very simple. If you find any good tutorial sites add a link to your page. Phillip.
Thanks man. I've not done performance tests, it was just an idea that happened to me. What I really want to create is an middleware which processes the html for speed rendering on browsers.
Very helpful, wish I'd read this before I started.
Wait, I just realized that the guy who did this terrible terrible tutorial is in fact the same guy who created the project itself. That changes everything! I mean, I read the main code, it's kind of nice. Basically the glorified initalization of PyGame with sensible defaults and lots of useful functions, but still, it's nice. I want to believe that he was profoundly drunk when he created that abomination.
Or you could read the Python tutorial which has stuff like this covered.
It was pretty easy for me to understand this aspect of Python, coming from PHP. As is typical, PHP has a system that works similarly but is less well thought out and defined.
Indeed quite basic Python, nowhere near as interesting as decorators, some of the cool magic methods such as --getattr-- and --setattr--(markdown will kill a baby if I use underscores), list comprehensions, generator expressions, or as brain-melting as [metaclasses](http://en.wikibooks.org/wiki/Python_Programming/MetaClasses).
last I checked, genshi was several times slower than django templates....so not much gained/lost there
&gt; last I checked, genshi was several times slower than django templates... It might be, but it outputs valid XML. Always.
&gt;(markdown will kill a baby if I use underscores) You can \_\_escape\_them\_with\_backslashes\_\_ \\\_\\\_like\\\_this\\\_\\\_. :)
Better yet, use backticks, and get monospace for free: `__getattr__`
`__getattr__`? I see. Awesome! Ok, now how do you escape the backtick so we can show everyone who's still confused? Backslashes don't seem to work :( \`foo\` &lt;-- see?
Use the four-space indented code block: `__getattr__` 
Except, in my opinion anyway, it teaches via altogether wrong strategies for scientific code. Everything Is Not An Object, not when any combination of speed and memory are an issue. That's not to say that object orientation is bad, quite the contrary. But the "Point" abstraction is a terrible one when you need to manipulate lots of them. The Cluster isn't too hot either, given how its implemented.
Just noticed the mailing list announcement had already been posted, I guess that's why the dupe detection didn't catch it. This is the actual conference website.
`__test__` __test__ \_\_test\_\_
upvoted for discussion. my comment from [r/programming](http://www.reddit.com/r/programming/comments/9qbo0/local_settingspy_considered_harmful/c0dy1qg): &gt; personally I think that the passwords are as essential as the rest of the settings for deployment, because same as the other your system won't function properly or won't funciton at all without them. &gt; &gt; also you definitely don't want them in the repository so if you still have to use a non-versioned local file I think the rest loses much of its meaning. &gt; &gt; besides that having several versioned configuration modes depending on the environment is a good thing but I wouldn't use the hostnames for it maybe just an environment variable or another local file. &gt; 
Spam Booooo
Let's look at this from two-perspectives: ------ Whenever you see yourself using variables like `x1`, `x2`, ..., `xn`, where n might be variable, you'll probably want to use a list. Languages like Python make this easy by allowing you to add items arbitrarily, so you can just use a loop, appending elements to an initialized list. (When you get into list comprehensions, consider those instead of loops.) Once you have a list built-up, you can do a lot with it. You want to condense all the values into one value? At this early stage, you'll just want to loop through the elements, updating an aggregate variable however you want. For adding, the built-in `sum` function does the trick nicely, so you don't even need a loop. Now you want to divide by the number of items? Use the `len` function to figure out how many items you have. So in general, you'll use lists to hold a variable number of related items that fit the `x1`, `x2`, ..., `xn` pattern. ------------ In this particular case, you can just skip the list. Just keep track of the sum and the number of elements directly as you loop n times (like [science4all is doing](http://www.reddit.com/r/Python/comments/9qfld/coding_help/c0dyaw3)). ------ A good mathematical background really helps because you can think in terms of abstractions. Finally, look into [How to Think Like a Computer Scientist](http://openbookproject.net//thinkCSpy/).
This isn't a python resource, but you might want to check out CarlH's [reddit programming classes.](http://www.reddit.com/r/carlhprogramming/) He works in C, but the concepts will help you in the long run. 
See this pile of baby skulls? Next time be more careful! ☠☠ ☠☠☠☠ ☠☠☠☠☠☠☠
Then try: &gt;&gt;&gt; mylist = [0,1,2] &gt;&gt;&gt; mylist.insert(1, 99) &gt;&gt;&gt; mylist [0, 99, 1, 2] &gt;&gt;&gt; mylist.pop(1) 99 &gt;&gt;&gt; mylist [0, 1, 2] &gt;&gt;&gt; 
 def avg(*scores): return sum(scores)/len(scores) print avg(1, 5, 12) 6 print avg(3.01, 3.99, 9) 5.33333333333 print avg(1, 1, 1, 2, 2, 2, 3, 3, 3) 2
&gt; The reason I haven't used a list is the storage overhead. I understand. That's why I linked to your comment. But I was trying to explore the topic conceptually. Programming is more than code; you have to learn to think in abstractions. Once a programmer can find a pattern and abstract a solution, it becomes much easier to approach new problems. Incidentally, that's why I didn't give provide any code. That might help with this particular example, but it's *much* more valuable to understand the concepts. But you're right about everything you said.
This still has the problem of hardcoding the number of inputs, as well as requiring the number of tokens to grow linearly with the number of inputs. But aside from that, at least cast the sum to a float before dividing: &gt;&gt;&gt; def avg(*scores): ... return sum(scores)/len(scores) ... &gt;&gt;&gt; avg(1, 5, 12) 6 &gt;&gt;&gt; avg(1, 4, 12) 5 &gt;&gt;&gt; def avg(*scores): ... return float(sum(scores))/len(scores) ... &gt;&gt;&gt; avg(1, 4, 12) 5.666666666666667
try cython or make an effort to get one of the many options you've mentioned working...
Seems to me like you could probably get a myriad of geeks to play around with optimizing your code if you just detailed what you wanted it to do, and provided test data and expected output -- at least, that's what I came prepared to do when I saw your entry :-) I realize you might be looking for an explanation on how to do this, but still could have been fun :-)
I'll second Cython, and also suggest Psyco if you use 32bit architectures. Cython seems the easiest way to link in a fixed type language.
it changes from day to day. the most basic would be the loop in an N-dim ising model. but even if someone could tell me how they would do: printf("hello world %d",a) i would be happy. it isn't that i can't code it, i just can't get the right software working correctly. all of the methods i've tried were done following a tutorial, step by step.
i will try tonight, have you used this? what packages should i have installed (in ubuntu) to get it to work, it sounds like just gcc but if you use it what did you install to get it working?
One option might be to use jython. I know people tend to think Java is a slow language/vm, but except for startup time (which isn't a big deal for something running for hours or days) it's actually faster than C in most cases. (didn't believe it myself when I heard it, but check if you have to) Fortran still wins out in still more cases, and even at reduced startup time, so if you really need performance, fortran is the way to go. (or dperhaps in windows, SISAL, as far as I know, there's no good compiler for that for linux)
i really want f2py to work, and wish someone would come in and say "just use compiler x" and it would all work and be honky dory. i prefer c++ for myself, but if i could package people's subroutines for them then there are many people in physics that use fortran all day, and i'm sure they would love to switch to a high level language.
The example found here: http://www.scipy.org/F2py works fine for me in ubuntu 9.04: http://pastebin.mozilla.org/674385 Edit: using this version of f2py: $ f2py | grep Version Version: 2_5972 numpy Version: 1.2.1
there's plenty of documentation and examples at http://cython.org/
same and same what compiler do you have installed?
Not spam. I'm not with webfaction. I do use them to host my site, but I'm not getting anything out of posting a link here.
Can someone please explain why I should start using `str.format` instead of the % operator? What's the reasoning for the switch?
tried it and it is working great, it is even easier than having to rewrite code in c. i wonder what the speed diff is between cython and the others. the scipy website has a comparison of everything but cython and that is initially how i chose weave.inline and f2py.
See [PEP 3101](http://python.org/dev/peps/pep-3101/).
Yes, unfortunately the way Setuptools patches Distutils makes it very sensible to any change in Distutils code, even internal changes.
&lt;nitpick&gt;You probably meant "sensitive".&lt;/nitpick&gt;
yeah, that's my frenglish again ;)
I agree with you. But you already had provided code, so I just linked to yours. My addition to your solution was a different, conceptual way of looking at the problem, and I was trying my best to give a perspective that would be useful for a large class of problems. It's an abstraction, and while it's not suitable all the time, a beginner needs to walk before running. &gt; The basic one: my code works for n=10, but for n=1000 it's much to slow. Like you said, it doesn't matter so much for this example. The overhead of a list is negligible: #!/usr/bin/env python import time import random def mean(data): if not data: return None else: return sum(data)/len(data) def read_data(): data = [] for x in xrange(10000): data.append(random.randint(1, 10000)) return data if __name__ == '__main__': t = time.time() data = read_data() print 'Average: %s' % mean(data) print time.time() - t From the timing data, I see that it takes approximately 0.08 seconds for 10,000 points. Unless you're doing this in a speed-critical loop, that's way more than sufficient. And if it that time is too much, a beginner shouldn't be jumping head-first into such a project because it takes experience to learn the things you're talking about. I've helped people with very little programming experience. Hell, like everyone else, I was once like that. Programming in general requires a particular thought process, and teaching a particular example, while good to explore certain concepts, doesn't develop the required mindset. But I generally do give code examples. I just didn't have anything to add to yours, and my other additions were extremely conceptual that code wouldn't add anything.
And you can also try this [single-module alternative implementation](http://gist.github.com/200936) which has an interactive try-it-out mode.
Other than ones listed in the pastebin link? - if so, I'm not sure I know what you mean :-S
A wise man once said that product announcements shouldn't use any adjectives whose direct opposite is negative - that is, don't bother telling us that your product is 'light-weight' or 'efficient' or 'reusable', since nobody would advertise that their product is 'heavy-weight' or 'inefficient' or 'non-reusable'. In particular, don't advertise your Python web framework as 'simple, flexible, extensible' - EVERY WEB FRAMEWORK CLAIMS THOSE THINGS. Tell us what's *different* about your offering, not what makes it indistinguishable from its millions of competitors.
I like [this one](http://www.ibiblio.org/swaroopch/byteofpython/read/ ) for its conciseness.
You don't have to install this one either.
Ah right, sorry - my bad. I updated my initial post to remove "no-install", as it's not a differentiator :-)
Very nice, thanks!
didn't realize that was your pastebin. a million upvotes for you.
How to use pep8, pylint and pyflakes together with flymake in emacs: http://stackoverflow.com/questions/1259873/how-can-i-use-emacs-flymake-mode-for-python-with-pyflakes-and-pylint-checking-cod
Why in god's name is the documentation in a PDF?
It's not, it's in text files using the RestructuredText markup. Sphinx can convert it in pdf (or html) for you, I have no idea why they checked in the pdf file under source control...
This method of debugging, quite frankly, sucks. You are telling me I have to modify the source when I want to debug? Really?? Use Eclipse with the Python plugin, and you can debug WITHOUT modifying source. It is exactly the same as debugging Java in Eclipse.
More useful to link [their actual website](http://www.pybrain.org/), which contains the feature list and HTML documentation.
Improved version of this here: http://yeoldeclue.com/cgi-bin/blog/blog.cgi?rm=viewpost&amp;nodeid=1254693316 Many thanks for the comments here :-) Honesty like this is helpful :-)
That would be the "zero wheel-reinvention" claim. 
This seems pretty lame to me - all it has is neural networks and SVM? For SVM, you can't beat [libsvm](http://www.csie.ntu.edu.tw/~cjlin/libsvm/) (with python bindings) and [liblinear](http://www.csie.ntu.edu.tw/~cjlin/liblinear/) for huge datasets. For everything else there is the extensive [Machine Learning Library](http://opencv.willowgarage.com/documentation/machine_learning.html), part of [OpenCV](http://opencv.willowgarage.com/documentation/index.html), also with python bindings.
What are you, the mother of the people who started up Webfaction? Why didn't you give this a more appropriate headline like "Getting Started with Webfaction Screencast"? 
Most interesting thing here: the name.
The only problem is you have to use Eclipse. I'd rather litter my code with pdb.
Alex Martelli is princess charming of Python@stackoverflow!
+1 cuil
ponies
I figured the steps to set up Django would be similar on different hosts. 
Can't care much about it since I don't use .Net and it won't work on Mono.
why not use the array module?
Rakefile I use to run PyFlakes/PEP8.py/nosetest (and has a PyLint option, although it doesn't run by default): # PyLint/PEP8 messages to disable pylint_disable = ["R0903", "C0103", "R0903", "F0401", "C0301"].join(",") pep8_disable = ["E501"].join(",") task :default =&gt; [:pep8, :pyflakes, :test] # Displays a the width of standard terminal, with text at end def title(text) padding = "#" * (79 - (text.length + 1)) puts "#{padding} #{text}" end desc "Removes .pyc files" task :clean do `rm *.pyc` `rm */*.pyc` end desc "Checks code for PEP8 compliance" task :pep8 do title("pep8.py") puts `python tools/pep8.py --ignore=#{pep8_disable} --repeat *.py tests/*.py` end desc "Lints the code with PyFlakes" task :pyflakes do title("PyFlake") puts `pyflakes .` end desc "Lints code with PyLint" task :pylint do title("PyLint") puts `pylint --reports=n --disable-msg=#{pylint_disable} *.py tests/*.py` end desc "Runs unit tests using nosetests" task :test do title("Unit tests") puts `nosetests` end 
Evolution strategies, continuous reinforcement learning, recurrent neural networks, ...
I actually never tried TurboGears. Can somebody who is experienced with TurboGears and Django or another Python web framework sum up why I should be using TurboGears as opposed to something else?
What? It does work in Mono - and in fact may well be in Debian unstable shortly.
found out while reading the docs (which got updated today)
Guess everyone said what they wanted to say [here](http://www.reddit.com/r/programming/comments/9qbhe/python_263_released/).
what's the matter with the frames?
Did you ever get it to work then? :-)
You know, I really like Python, but I have to wonder about people who think it's a Good Thing that the community process for enhancing the language puts forward a **coding standards** document - and manages to put forward **just one**, at that.
No screenshots?
http://r1chardj0n3s.googlepages.com/bruce It's about as impressive as I would expect.
haha, i searched 2.6.3 in r/python and got nothing about the release. the programming one never made it to my front page and so i had no idea and posted it here. apparently this pissed people off. sorry
Dang, i had hoped that it was for *presentation layers* not *presentation tools*. Just wasn't paying enough attention. Although I prefer coding graphics via graphviz than manually building them with viseo, open office draw, etc. I don't think the same would be true of presentations. Any suggestions for code-less transactional front-ends for python?
Numpy has several built-in operations for common matrix operations, like transpose, mult, etc. Numpy. It's also probably faster, since Numpy is specifically tuned for large-scale calculation.
I don't get it. What's the problem? Edit: rather than downmodding, could you just explain what the problem is? Is the objection that there is a coding standards document? That it was produced by a community process and not benevolent dictatorial fiat? That it's not exhaustive enough? Not normative? That informational and procedural documents not strictly related to enhancements of the Python language are published as PEPs? What?
It reinvents zero wheels, except for the "wheel" of a Python web-framework, of which too many already exist.
It is similar to [txt2tags](http://txt2tags.sourceforge.net/).
&gt; Distribute fixes bugs and is a backwards-compatible drop-in replacement and setuptools is unmaintained. News to me.
Distribute is the official fork and continuation of Setuptools. Unlike setuptools, it is: 1. Actively maintained. 2. Supports Python 3.x. 3. Backwards compatible with Setuptools. 4. Adds features upon Setuptools. 
I expected more than a PowerPoint clone :(
Found the comments on YouTube too highbrow did you?
The blog post did its job then. :-)
You know, I'd love to, except FUCK YOU PYPI I swear that the Python world must be conspiring against me personally. pypi.python.org takes minutes to respond with a simple web page, and much longer to easy_install (heh, speak of the devil) anything significant. This happens to me at home and at work. And yet I haven't heard of anyone else having this problem. What the hell? Does anybody know why this would happen?
I, too, was unaware that Setuptools was unmaintained until being enlightened by this post. That explains why the documentation is so crap!
Not here...
Nope, I get [www.google.com.au/language_tools](http://www.google.com.au/language_tools) at the top. Python.org is about six down. This is especially odd, as I'm not in Australia.
Do a `tracert`/`tracepath` to pypi.python.org, see which hop is causing the slowness. I have no problems connecting to it.
&gt; This seems pretty lame to me probably because &gt; PyBrain aims to be a very easy-to-use modular library that can be used by entry-level students
That'd be the reason.
This could make modifying code written by non-native-English speakers even more complicated.. Not only will the keywords not be understandable, but I can now no longer type them, since my keyboard doesn't have a `ղ` symbol on it.. Then again it could make for some fun obfuscated code.. Using the Unicode "zero width joiner" (U+200D) as an identifier name? 
PyPy progress lately is more and more impressive. If Python can be within an order of magnitude of Java/C, I think that would make most people happy.
I was slightly sceptical, as I thought you'd need to require users to have distribute installed also, which would be annoying.. but, quoting from `distribute_setup.py`: If you want to use setuptools in your package's setup.py, just include this file in the same directory with it, and add this to the top of your setup.py:: from distribute_setup import use_setuptools use_setuptools() *Edit* Actually, I remain somewhat sceptical.. Running `python distribute_setup.py` errors at the following, because I didn't run it as root: &gt; `Renaming /System/Library/Frameworks/Python.framework/Versions/2.6/Extras/lib/python/setuptools-0.6c9-py2.6.egg-info into /System/Library/Frameworks/Python.framework/Versions/2.6/Extras/lib/python/setuptools-0.6c9-py2.6.egg-info.OLD.1254844369.76` ..screwing around with stuff in `/System` really isn't great
 &gt; (map (lambda (x) (+ x 2)) (list 1 3 4)) (3 5 6) &gt; (import urllib) &lt;module 'urllib' from '/System/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/urllib.pyc'&gt; &gt; (.read (.urlopen urllib "http://google.com") 50) "&lt;!doctype html&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=\"conte"
Damn you are right. Google was using the sites I visited as criteria. 
that's your python install. Any `python setup.py install` will write the files there.
&gt; ..screwing around with stuff in /System really isn't great Correct. So don't run this on your System python. The setuptools installed in Mac OS X system python is not intended to be used by the end user.
&gt; This could make modifying code written by non-native-English speakers even more complicated. "Even more complicated"? Have an upvote for colonialistic snobbery... Good thing it's not up to you in which language other people name the objects in their programs and libraries. Also, it would be really weird for any programming to allow spacing characters in object names, so Python still doesn't. Yay.
Oh, the benchmark results are nice.
Erm, I think you may have misinterpreted my comment? My point is simply, it's hard to understand code where the variables/functions/etc are not written in a language you understand. Adding non-ASCII symbols further complicates this.
Unless I'm misunderstanding, no it wont - running `python setup.py install` (with regular setuptools) installs to the correct location, $ python setup.py install --dry-run [...] Copying tvnamer-1.2-py2.6.egg to /Library/Python/2.6/site-packages
This is why any sizable organization has a style guide. And why Python itself -- the core and the stdlib -- has a policy of sticking to English-language identifiers.
&gt; official fork Eh? &gt; Unlike setuptools, it is: ... &gt; 3. Backwards compatible with Setuptools &gt; 4. Adds features upon setuptools Huh? 
If this is what you're asking, to decode a string like Bj\xf6rk, you can use the string\_escape/unicode\_escape codec: 'Bj\\\\xf6rk'.decode('string\_escape') -&gt; 'Bj\\xf6rk' If that's not what you're asking, you'll have to get more specific about your source's encoding and what format you're trying to get it to. In general, you probably want to store things as either utf-8 or using the raw bytes from the source, depending on what you want to do with them later.
That doesn't actually do what you want it to, since \xf6 is only ö is codepoint U+00F6, and wouldn't actually be represented as \xf6 in any sane Unicode encoding. I agree, we need more information.
'Bj\xf6rk' is a raw string. It's created by this: def gen_line(self, info): line = "" for cnt in range(len(info)): meta = info[cnt] print type(meta), meta line += '''%r''' % meta if cnt &lt; len(info) - 1: line += "," return line info is a list of unicode items. This is to create a string which I can use in a query for the database. Initially I was using ", ".join(info) but that really didn't like unicode In addition, the code generating the unicode that is passed to the above function looks like this: try: artist = tags.tag().artist artist = artist.replace('''"''',"") artist = artist.encode("utf-8") if len(artist.strip()) &lt; 1: artist = "Unknown Artist" except: artist = "Unknown Artist"
Well, it does what I expected/wanted it to, which is convert back and forth between string-escaped and latin-1 encoded strings. But I don't think the right question was asked... "decode raw unicode" isn't a rational concept.
 &gt;&gt;&gt; a = unicode('Björk',"utf-8") &gt;&gt;&gt; a u'Bj\xf6rk' &gt;&gt;&gt; a.decode("utf-8") Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "/usr/lib/python2.6/encodings/utf_8.py", line 16, in decode return codecs.utf_8_decode(input, errors, True) UnicodeEncodeError: 'ascii' codec can't encode character u'\xf6' in position 2: ordinal not in range(128) &gt;&gt;&gt; a.encode("utf-8") 'Bj\xc3\xb6rk' [edit]Ah nuts. You have to assign that a.encode and then print it. &gt;&gt;&gt; a = a.encode("utf-8") &gt;&gt;&gt; print a Björk Man I need sleep. It's 0015 
Ah pissflaps. The above is a load of balls &gt;&gt;&gt; a = 'Bj\xf6rk' &gt;&gt;&gt; b = a.encode("utf-8") Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; UnicodeDecodeError: 'ascii' codec can't decode byte 0xf6 in position 2: ordinal not in range(128) &gt;&gt;&gt; a = unicode('Bj\xf6rk','utf-8') Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; UnicodeDecodeError: 'utf8' codec can't decode bytes in position 2-4: unexpected end of data I'm going to sleep.
I have no idea if you'll find this useful, but I've written a bit about Python+Unicode: * [str(…) - yer prbably doin' it wrong](http://blog.codekills.net/archives/45-str...-yer-probably-doin-it-wrong..html) * [Encoding and Decoding Text in Python (or: "I didn't ask you to use the 'ascii' codec!")](http://blog.codekills.net/archives/38-Encoding-and-Decoding-Text-in-Python-or-I-didnt-ask-you-to-use-the-ascii-codec!.html) (which also covers the `UnicodeEncodeError: 'ascii' codec can't encode character` error)
&gt; I was slightly sceptical, as I thought you'd need to require users to have distribute installed also TBH, the fact that it can do (and encourages distributors to do) drive-by installs has always been one of my least favorite things about setuptools. Somewhat sad that we're continuing down that path.
 &gt;&gt;&gt; a = "Björk".encode("utf-8") &gt;&gt;&gt; print(a) &gt;&gt;&gt; b'Bj\xc3\xb6rk' &gt;&gt;&gt; b = a.decode("utf-8") &gt;&gt;&gt; print(b) &gt;&gt;&gt; Björk Works for me on python 3.1
 &gt;&gt;&gt; latin1 = 'Bj\xf6rk' # latin1 bytes &gt;&gt;&gt; unicode_ = latin1.decode('latin1') # unicode &gt;&gt;&gt; utf8 = unicode_.encode('utf-8') # utf-8 bytes
That's a mac pathing issue. distribute needs to patch your setuptools install, so if your setuptools is in /System/Library, that's where setuptools installed itself, so it wrote there. If it says "Renaming" and theres nothing actually there, report it as a bug on the distribute tracker. Personally the first thing I do with a mac is install Python fresh within /Library/Frameworks and never touch the /System/ python or its goofy path setup again.
This project just rocks. I've finally checked out trunk and built it on my Mac and Linux box but that's it. I just hope I can contribute and it's not too far over my head. They really encourage contribution and the docs show it, it's very nice to see they love helping people learn about PyPy.
"Those who do not understand Unix are condemned to reinvent it, poorly." - Henry Spencer
UNICORNS FUCK YEAH
This is awesome news. The day when "Python is way too slow" will become "Python is slow" is nigh. And I don't mean this sarcastically at all. 
PyPy is taking python from "Very slow" to nearly Java-fast. Which is fast enough for almost everything you aren't already using C for.
Honestly, I can get away with writing pretty much everything I need in Python. I have doubts that we can reach nearly Java-fast any time soon in the general case but if PyPy does do that I will be beyond happy.
Fuck no!
It took me forever to suspect that there was javascript on the page with the actual code, and then enable it. For the longest time I thought he'd edited the post to remove the link.
No.
 &gt;&gt;&gt; a = "Björk".encode("utf-8") Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; UnicodeDecodeError: 'ascii' codec can't decode byte 0xf6 in position 2: ordinal not in range(128) Python 2.6.2 
If I encode with utf-8 I get this &gt; BjÃ¶rk But if I encode with latin1 it is correct. But the weird thing is that 'Bj\xf6rk' was created using utf-8 in the first place. Cheers.
 diff uni.py- uni.py 47c47 &lt; flo = conn.makefile() --- &gt; flo = conn.makefile('r+',0) 49c49 &lt; message = flo.read() --- &gt; message = flo.readline() Agreed. Unix is awesome. Please attempt to use it correctly. Common failing: your unix API code happens to work on your box, now, but because you haven't read your Stevens it might not work on mine, or tomorrow. I've been there :-).
Dammit, I'm a masochist. I thought I'd make this a little more unix, just to see if I could remember my Stevens. How'd I do, folks? import os import sys import socket import signal port = 4242 acceptor = socket.socket() acceptor.bind(('localhost', port)) acceptor.listen(10) print "Listening on localhost:%s"%port # when you fork, clean up after yourself! def reap(signal, frame): (pid, status) = os.waitpid(-1, os.WNOHANG) print "Reaped pid %s (status %s)"%(pid, status) signal.signal(signal.SIGCHLD, reap) try: while 1: (conn, (host, port)) = acceptor.accept() if 0 == os.fork(): pid = os.getpid() print "Forked child %s for client from %s:%s"%(pid, host, port) flo = conn.makefile('r+',0) for line in flo: flo.write(line) print "Child %s echoed: %r"%(pid, line.strip()) flo.close() print "Child %s exiting -- client closed"%pid sys.exit() except KeyboardInterrupt: # the children get this signal too. Not sure how comfortable # I am using signal for CHLD and exceptions for INT. print "\nbailing" sys.exit() 
I've read through your posts and my brain just turned to mush. This issue is getting on my nerves. I turn my unicode into a string for pysqlite but i'm not sure if that's necessary. I'm going to check as this decode/encode stuff just seems to much of a hack. Failing that i'm going to encode/decode everything in base64
This is addictive. Here, reddit, have a chat server demonstrating select(): import os import socket import select port = 4242 listener = socket.socket() listener.bind(('localhost', port)) listener.listen(10) print "Listening on localhost:%s"%port socks = [] try: while 1: (rsocks, junk, esocks) = select.select([listener]+socks, [], socks) for sock in rsocks: if sock == listener: (conn, (host, port)) = listener.accept() fd = conn.makefile('r+',0) print "New client (%s) from %s:%s"%(fd.fileno(), host, port) socks.append(fd) else: line = sock.readline() if len(line)==0: print "Client %s closed"%sock.fileno() sock.close() socks = filter(lambda x: x != sock, socks) else: print "Client %s said: %r"%(sock.fileno(), line.strip()) for out in socks: out.write(line) for sock in esocks: print "Client %s closed"%sock.fileno() sock.close() socks = filter(lambda x: x != sock, socks) except KeyboardInterrupt: listener.close() print "\ncleaning up %s clients"% len(socks) for sock in socks: sock.close()
That's what it looks like if the bytes `'Bj\xc3\xb6rk'` are treated as latin1 (`\xc3` and `\xb6` decoded as two separate one-byte characters), not utf-8 (`\xc3\xb6` as a two-byte encoding of a single character).
This chapter from [Dive Into Python 3](http://diveintopython3.org/strings.html) is frequently recommended. (Even if you're not using Python 3 yet.)
It only works in Python 3. The equivalent for 2.6.2 is: &gt;&gt;&gt; a = u"Björk".encode("utf-8") &gt;&gt;&gt; print repr(a) 'Bj\xc3\xb6rk' &gt;&gt;&gt; b = a.decode("utf-8") &gt;&gt;&gt; print b Björk
Unicorns, the narwhals of the sea... the sea of LAND!
I'm starting to think something is wrong with my PC &gt;&gt;&gt; a = u"Björk".encode("utf-8") &gt;&gt;&gt; print repr(a) 'Bj\xc3\xb6rk' &gt;&gt;&gt; b = a.decode("utf-8") &gt;&gt;&gt; print b Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; UnicodeEncodeError: 'ascii' codec can't encode character u'\xf6' in position 2: ordinal not in range(128) [edit] I just tested the above in Karmic which has Python-2.6.3 and works fine. I'm using Gentoo and have 2.6.2 installed. Going to try an upgrade.
Mother-fuck. Python 2.6.3 (r263:75183, Oct 7 2009, 13:31:52) [GCC 4.4.1] on linux2 Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; a = u"Björk".encode("utf-8") &gt;&gt;&gt; print repr(a) 'Bj\xc3\xb6rk' &gt;&gt;&gt; b = a.decode("utf-8") &gt;&gt;&gt; print b Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; UnicodeEncodeError: 'ascii' codec can't encode character u'\xf6' in position 2: ordinal not in range(128)
Could just be that it's trying to convert to ascii to print to your terminal (is it a UTF-8 locale?) -- sorry, using Windows here.
I thought that too. I'm using Konsole and it's default character encoding is iso-8859-1. I'm really at a loss now. What's more confusing that in Ubuntu printing an encoded string returns the right thing but when done the same from an app it doesn't bother. for cnt in range(len(artists)): artist = artists[cnt][0] print artist, type(artist) artist = artist.decode("utf-8") print artist &gt; develop@develop-desktop:~/Documents/dev/amaroq$ ./amaroQ.py Audioslave &lt;type 'unicode'&gt; Audioslave Bj\xc3\xb6rk &lt;type 'unicode'&gt; Bj\xc3\xb6rk 
Your sock.readline() is going to block if the client does not send a line ending, and then blocks itself.
That's… not exactly surprising. PJE hasn't been very reactive re. Setuptools. Not to mention, Distribute already supports Python 3. Setuptools? Not so much.
It's worth checking out http://webpy.org/ The site includes a straight-forward guide as well for hosting it with Lighttpd as well. 
django.
Most, if not all, of the Python frameworks include a server. You dont have to set up mod_python until you actually want to deploy your app. I know that Django, Pylons and CherryPy include a development server. Although I've never used Pylons, their documentation seems pretty good. Take a look at this: [http://pylonshq.com/docs/en/0.9.7/gettingstarted/](http://pylonshq.com/docs/en/0.9.7/gettingstarted/) for pointers on what to do first. The CherryPy tutorial is here: [http://www.cherrypy.org/wiki/CherryPyTutorial](http://www.cherrypy.org/wiki/CherryPyTutorial) At the same time, you dont really implement HTML in .py files. The frameworks usually include some sort of templating library, (Genshi, Django Templates, Mako, etc). You would use one of these to write your static content. Your Python controllers would put your data together with your templates to produce the result. At the same time, Pylons is not the smallest of frameworks you can find. Check out this post: [http://fewagainstmany.com/blog/python-micro-frameworks-are-all-the-rage](http://fewagainstmany.com/blog/python-micro-frameworks-are-all-the-rage). There is a list of Python micro-frameworks there. Since I haven't used them, I can't recommend one. For deployment there are a number of options. Apache + mod_python is one. Nginx + fcgi is another one.
repoze.bfg is lightweight but it gives you slightly more than pylons. out of the box it uses chameleon for your templates so that piece is very fast. It also lends itself well to making tiny applications that can be plugged into a larger website. http://bfg.repoze.org But really you can't go wrong with any of the ones mentioned. And they all pretty much interface with a webserver the same way either mod_wsgi or via proxy. 
The cruncyfrog project may be up your ally. Diving into a large code base can be intimidating, but, if you like the app, submitting patches/features would be a real good way to learn.
My background : 30+ years expertise on IBM mainframe (Assembler, Rexx +++ a lot...) - like this +/- &gt;http://www.reddit.com/tb/9rqpm *From what I see about you="matelot" you are NOT on Linux - your choice, your problemS.* I am on a path +/- //with yours now : here is the plan I come up with. After a long "quest", many reflexions and comparisons all the blocks fell in place and in time. 0- I am on Ubuntu since 2004 (Linux since 1998-9, after IBM dropped me and my OS2 Warp4 ) - fairly comfortable at all levels. Now, new laptop (500GB HDD for toying space) and Ubu 9.10 KK to install on OCT 30+. They have never missed a deadline so far. 1- I decided to go Python (in 2007, with ubu 7.04) but now stressing its **V3** (since 2009/06). 2- I want to play with WWW technologies and other .py stuff in // : therefore selected Django, based on Python V2.5-6. You can also download/study the sources of UbuntuTweak :it looks good. And **of course** Reddit .py code is now available for study. 3- also picked "Dive into Python" and testing each example against Python V3 ; fixing the problems when any . I can run IDLE v2 and IDLE v3 in // on Ubuntu (OK 9.04). And study the pro's and con's of the 2to3.py script/tool when upgrading Pilgrim's samples. 4- I suppose at some point in time, the V3 expertise in Python will be worth its while because sooner or later ALL the existing .py code will have to be migrated to or replaced by V3 -- **AND** if I come up with an idea worth building upon, it will be Python V3. So ! What do you think ? 
thanks. You know it's interesting you suggested cruncyfrog - I just learned about its existence via /r/Python couple days ago and it 's been in the back of my mind as I have used or played with all the relatively well-known DB IDE apps over the years.
To replace `mod_python`, you want `mod_wsgi`. Lighttpd or nginx and FastCGI is also an alternative, but `mod_wsgi` is probably the best thing there is right now. For Pylons and Cherrypy, they're not "full stacks" so you're going to need separate template engines (Jinja2, Genshi, …), models/ORM and some other stuff. There are also pretty good full-stack frameworks: Django (done it from scratch), TurboGears ("best of breeds", uses Pylons among other stuff but -- of course -- doesn't have the consistency of Django).
I've been aware of those unix-isms for quite a while, but have never really bothered to learn them. I know it's bad, so i wanna do so now. What can i read to learn them? specially on the context of the scripting languages we're gonna use on the day-to-day (my background is more on sysadmin stuff, haven't seriously programmed in years apart from quick perl scripts)?
&gt; So ! What do you think ? I felt like I was listening to [HAL](http://blogs.theage.com.au/schembri/hal9000.jpg) ;) &gt; you are NOT on Linux - your choice, your problemS. You're right, unfortunately, my work is 90% on Windoz. I run Linux at home (and use as much as I can as I'm hooked on Compiz) I'm no "fan boy", I'm long past that point age-wise. to me it is just a tool not a religion. But if you can explain to me how using "more Linux" will help me learn Python better, i'd love to hear. 
&gt;using "more Linux" will help me learn Python better, i'd love to hear. I do not claim that. What I say is : I picked Linux and Ubuntu (I tried Fedora too and others) as reliable working platforms because after z/OS and OS2 I needed another trustworthy environment . I have been "obliged" to use windoz at many clients places while ( 20+ years) free-lancing and I know the shakiness of it : see the latest news about LSE = &gt; http://www.reddit.com/tb/9rr9a What I am willing to claim though is : There is more affinity between Python and Linux than ever will exist between Python and Redmond's output. I trust that the rigorous positions of VanRossum and other pillars of .py are more consistent with those of the OSS and Linux (Thorvald's) than those of some other $uppliers we know about through their marketing bullshit. Them vendor$s do not want you to use FREE .py - they want you to buy their crap (.NET + Accenture at LSE, for example ... I know many, many, many others - similar disasters). 
I remember when I started messing around with python based web applications rather than using inline php. The biggest difference between the two are that with most python systems, you are doing processing with the request, and then manually returning an HTTP response with the data you've prepared and the content type of that data. So, how you would implement HTML with the python files would be (to use something like web.py as an example) to run a python function when a certain URL is encountered, and to return from that function an HTTPResponse object containing the HTML for that page. You can greatly extend this by using templates. I think it's most helpful to view the python process as containing a separate web server that gets called when your python apache module (mod_wsgi or mod_python) decides it needs to process the request, whereas inline php is more like mod_php calling php to process php files and turn them into HTML (an oversimplification of course) Sorry if that doesn't help. Mainly, it's a mindset change. There is much stronger separation between the behavior of the page and the data of the page.
I just started looking into django the other day - so far I really like it compared to php.
Django is really good. I've used it for about 8 months now and its really nice to work with/set up.
Get the book "Practical Django Projects". It's awesome. It'll walk you through from installing Django to some pretty complex stuff, building useful apps along the way.
I'd like to avoid Django for now. I'd rather learn something that does less first, than use Django for something larger than a home project :D
I'm ok with a separate template engine, as long as the documentation fits the toolkit I'm using. In this case, I know both CherryPy and Pylons can use Mako. I tried Genki(i think that's it) with CherryPy with little success :/
This sounds good. I like speed, lightweight, and "just enough" work done for me. I especially like speed :)
Thanks, this cleared up some questions I had about deployment vs development servers using python. 
A tip for everybody in this thread: If you use print() to debug or illustrate Unicode encode/decode bugs, *you will go fucking insane* in a very short amount of time trying to keep track of exactly where you are w/r/t (1) unicode or str? (2) console encoding? (3) UnicodeEncodeErrors. repr() is the one and only way to go here.
Pylons comes with Mako out of the box and most of the other basic framework stuff. It includes the setup for SQLAlchemy as well. I noticed this recently: http://pypi.python.org/pypi/BlastOff -- it's a new-project template for Pylons with several included components (for authentication and whatnot). Not unlike TurboGears, I guess, but as pure glue.
If you don't have a host in mind, a lot of people have had very good experience hosting Python projects on [WebFaction](http://www.webfaction.com/). Obviously App Engine is another hosting situation -- you get a slightly weird platform, but the hosting and maintenance is dead-simple. If you want to hack on Python and have fun, I'd recommend some option like these that is well suited to Python hosting so you can get to the hacking and not get bogged down in the sysadmin stuff.
Yeah. I've learned about repr. I've just gone through my recent git commits and there appears to be evidence of going mad. 
Good work, Grok team!
Nice to get over that 1.0 mental hurdle. Similar to how Django took a little while to eventually reach the big "1.0" version, it took just over a year to go from Grok 1.0a1 to 1.0 final.
Django is deep, in that it can really do a lot, but you don't need to learn anywhere near all of it to start doing stuff. Sit down with a couple tutorials, learn the basics, and after a few "I wonder if I can..."'s, you'll find that you can do pretty much anything you want, without having to have studied it. At least, that was my experience.
The reason this doesn't work is because you're taking a latin-1 string and acting like it's unicode. What you want is "Björk".decode('latin1').encode("utf-8"). 
I've done a ton of research on python frameworks. Like researched for a good 2 months before starting. To summarize, this is what I went with: I use pylons with: - mako templates - sqlalchemy - postgresql I serve it with: - nginx for public files (b/c it's damn fast) - reverse proxy to port :8000 served by paster I also run phpPgAdmin behind apache (b/c PHP needs apache) with using a subdomain to manage the database in a visual way.
under my trivial testing, the sockets' input streams appeared to be line-buffered by default. This could be an accident, but it has been long enough that I couldn't work out where to go to check.
I understand the urge. I tend to try to do the same thing. What usually happens with me is that after a month of fits and starts with the lightweight, poorly documented option, I end up going back to the more feature filled option anyway. When I have gone the other way, by taking something easy first, then stepping up in difficulty as I felt like the platform began to constrain me, it has gone much better. What I recommend is to use Django until you feel that it is limiting you. You will learn a lot about deploying Python on web servers, dealing with Pythonic URL handling, dealing with databases in Python (use the Django ORM for a while then quit and do it yourself if you don't like it), and general Python packaging. Once you have that base, decide if you need more flexibility and level up to something like Pylons. I won't heckle you about this in any other thread in this submission, but I'm putting it here because this is the "suggesting Django" thread.
I think you want to attack this from two ends at once: use something like Pylons, CherryPy or TG2 to get acquainted with the libraries everyone is using, and why you'd want to use them. At the same time, become familiar with the WSGI spec via minimal frameworks like http://adeel.github.com/berry/ to see what's going on at the bottom of the stack. Along the way you'll want to become familiar with Ian Bicking's modules and Paste, because they're virtually universal and everybody loves them. EDIT: it's worth having a look at werkzeug too, if lightweight and understandable are important to you. Which they should be, since this is one thing Python excels at.
Mako is probably more like you're used to with text based templates like php wheras Genshi is an XML based templating language where even the templating section is valid xml along with the html. I found that to be too constricting and not nearly as fast to render as Mako is.
Webpy if that is what you really want, but I too would recommend django.
(and one of these days I'll get the rest of the example code up in its repository... almost halfway there!)
You want mod_wsgi for real deployment; for local testing stuff there's a variety of options, including a simple HTTP server built in to the standard library. You can try Django if you like (and I won't mind if you do, obviously), but something like Werkzeug which just starts you with the very basics -- doing request/response and learning your way around the WSGI web-server interface -- might be a better project for learning what's really going on under the hood. Then you can stick with that (it's a fine foundation for building more stuff on top of) or move to a larger framework.
i've been very happy with cherokee for django, as a singular replacement for apache + proxy &amp; media servers (just make sure to turn off keepalives!): http://www.cherokee-project.com/doc/cookbook_django.html
Right on BDFL!
Nyah, suck it up and use a full featured framework, even if you don't use all of it. Keep in mind that if you're already proficient with PHP, that you already have all the mental slots you need to get up to speed. After all, PHP isn't just a language, it's also a web development kit. Python without something like Django isn't equivalent to PHP.
&gt; I'd recommend a healthy understanding of Apache and a rudimentary understanding of mod_python prior to jumping in to Django. It will make your life easier. I wouldn't worry about that until you're ready to put the project on a production server. The built in webserver is perfect for development work.
Good.
http://pylonsbook.com/
I personally use WebFaction, and they have been absolutely great to me for two years.
&gt;how I would implement HTML with the py files? Um, CGI is CGI. You write a program that calculates what the output HTML should be, and you feed it (with a header) to standard output. (Hint: the 'print' command writes to the standard output, and 'sys.stdout' is a file-like object representing the standard output, in case you need more control.)
I have little to no experience in web development, and recently needed to put together a web application to support some research work I am doing. I was recommended [web2py](http://www.web2py.com/). I found it fairly easy to learn, and it did what I needed, so I am passing the recommendation on. It was originally developed as an educational tool, and is used to support wed development courses at universities. It has an active and helpful community, with the main developer often stepping in to help with questions and problems. tl;dr [web2py](http://www.web2py.com/)
same. django's documentation and tutorials can't be beat by any framework that's around. I thought the same thing, that django did too much and tried web.py and pylons first. switched to web.py because pylons was weird. After working with web.py for a while I eventually realized i was reinventing all the stuff baked into or cleanly modularized in django and decided to just go back to django. love it. 
Well, lets hope distribute doesn't suck as insanely much as setuptools. Can anyone explain what are the main differences? That it is a fork rather and a complete rewrite is not very encouraging...
setuptools is (effectively) unmaintained and Distribute is under active development. For now, all it's trying to be is a drop-in replacement for setuptools with fewer bugs and Python 3 support.
There are two components: distribute 0.6 is nothing more than a fork of the effectively unmaintained setuptools, so it fixes a few bugs, cleans up the gory guts and adds python 3 compat. Distribute 0.7 should be a more complex endeavour, and one which probably won't be drop-in compatible with setuptools. It should also play better with a bunch of distutils extensions being discussed these days. 
If you're looking for something simple, you could try [this](http://svn.saddi.com/py-lib/trunk/fcgi.py) with mod_fcgi. It's a single module that implements the [WSGI standard](http://www.python.org/dev/peps/pep-0333/) and nothing else.
I have been wanting unicode identifier for so long and I was quite disappointed when Guido said that he won't support in Python 3k. But in the end unicode was support and I am so happy indeed. Not that I don't understand English but I would enjoy reading a code with some Chinese function inside. Here's an example I wrote to learn Tk: from tkinter import * def 加两个数目(参数A, 参数B): x=float(参数A) + float(参数B) return x def 计算(): a = e1.get() b = e2.get() print(a," + ",b,"等于",加两个数目(a,b)) root = Tk() p1 = PanedWindow(root) l1 = Label(p1, text='A = ').pack(side=LEFT) e1 = Entry(p1) e1.focus_set() e1.pack(side=LEFT) p1.pack(side=TOP) p2 = PanedWindow(root) l2 = Label(p2, text='B = ').pack(side=LEFT) e2 = Entry(p2) e2.pack(side=LEFT) p2.pack(side=TOP) p3 = PanedWindow(root) w1 = Button(p3, text="计算", font="simhei", command=计算) w2 = Button(p3, text="退出", font="simhei", command='exit') [s.pack(side=LEFT) for s in [w1,w2]] # or list(map(lambda s:s.pack(), [w1,w2])) p3.pack(side=TOP) root.mainloop() 
Looking great. I'm eagerly awaiting some resolution to all of this and Tarek look's like he's got it under control. Hopefully this time around it won't depend on just one person.
Not as elegant as I would like, but here ya go: $ python chat.py &amp; [1] 65799 2009-10-08 11:34:15 mikeboers@maxwell: ~/Desktop $ Listening on localhost:4242 nc localhost 4242 New client (4) from 127.0.0.1:54311 Hello! Client 4 said: 'Hello!' Hello! ^C Client 4 closed 2009-10-08 11:34:29 mikeboers@maxwell: ~/Desktop $ python Python 2.6.2 (r262:71600, Apr 16 2009, 09:17:39) [GCC 4.0.1 (Apple Computer, Inc. build 5250)] on darwin Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; from socket import * &gt;&gt;&gt; s = socket(AF_INET, SOCK_STREAM) &gt;&gt;&gt; s.connect(('127.0.0.1', 4242)) &gt;&gt;&gt; New client (5) from 127.0.0.1:54422 s.send("Hello from client 2!\n") 21 &gt;&gt;&gt; Client 5 said: 'Hello from client 2!' s.send('You block now!') 14 &gt;&gt;&gt; ^Z [2]+ Stopped python 2009-10-08 11:35:32 mikeboers@maxwell: ~/Desktop $ nc localhost 4242 Oh shit it blocked? ^C 2009-10-08 11:35:48 mikeboers@maxwell: ~/Desktop $ fg %2 python s.send('\n') 1 Client 5 said: 'You block now!' &gt;&gt;&gt; New client (4) from 127.0.0.1:54494 Client 4 said: 'Oh shit it blocked?' Traceback (most recent call last): File "chat.py", line 24, in &lt;module&gt; line = sock.readline() File "/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/socket.py", line 395, in readline data = recv(1) socket.error: [Errno 54] Connection reset by peer
Can't wait
Yeah, it definitely took us forever. Meanwhile we've done a lot of heavy lifting underneath to prepare for the post-1.0 world: massive improvements to the Zope Toolkit's reusability and dependencies, and Martian dealing with inheritance in a much better way. 
I remember vaguely having such problems with a VPN setup where the VPN spoke ip v6. It'd route through the ip v6 story for some reason and things would slow down. Normally pypi responds quickly for me, and I use it heavily.
This is immensely useful. I have wasted days looking for everything here. For a newcomer to the language, it is extremely difficult to figure out what the hell the "proper" standards for this are (there are many de-facto community standards that deviate from the official python documentation). For developers that want to make sure that they have a quality release that plays well with the community, this answers all of those little questions. It would be really nice to see this on python.org!
Very nice. A while ago I played around with something I called [Abomination](http://bitbucket.org/DeadWisdom/abomination/). It compiles s-expressions to python byte code. It's only proof of concept / unfinished.
I mean yours compiles too... Christ, good work.
For pysqlite? Yea, I *think* it does that automatically… But, basically (and, again, forgive me if this is old/useless information), the trick with Unicode is to write one function, `to_unicode`, that accepts a `str` and returns a `unicode_from_str`, then call it every time any data comes into your program (for example, when you read from a file, list a directory, etc). With that, you'll also need a `str_from_unicode`, then call that every time a Unicode string *leaves* your program (to be printed to the screen, to hit the DB, etc).
So, all i'd have to do is add this to the top of every page? &gt; #!/usr/bin/env python &gt; from myapplication import app # Assume app is your WSGI application object &gt; from fcgi import WSGIServer &gt; WSGIServer(app).run() 
Looks good. I only stopped nodding in agreement when I read this: &gt; [virtualenv] exists only because Python doesn't support the installation of multiple versions for the same distributions. For me, virtualenv (+ virtualenvwrapper) not so much enable different version, as function a per-project sandbox. I don't fully understand the proposed roadmap on this point, but I'm not enthusiastic about solutions that move in the direction of *one* (vitual) directory.
&gt; Distutils is a package manager and competes with OS package managers. This is a good thing because... *A good thing*? Is this a joke?
To be fair, he goes on to explain "...unless you are developing a library or an application that will only run one specific system that has its own packaging system like Debian, you will be able to reach much more people." If the Distribute people can make a tool that makes it easy for Debian and Fedora to turn my Python library into a proper packages, and also makes it practical for Windows and Mac users to get things sorted, then hey! Everyone's a winner!
I will believe it when I see it, from what I understood, he seemed to imply that 'we will try to make it not extremely painful, but it is going to suck anyway, tough luck'.
Right! We should get rid of `if`, `while`, `not`, and all the other imperialistic keywords! If you are a programmer, you better *learn fucking English* or find some other job where your closed minded stupidity can cause less damage. Now call me a 'colonial snob', nevermind that English is not my first, nor even second language, and that originally had to learn it *because I fucking write code for a living*.
Relax colonial snob, it's just a fact that not all code gets written in English. There are languages that require something other than than the latin character set. Some pieces of code (and database tables and fields) are just awkward to translate into English, if they're about something you have a perfectly good word for, why make up a bad English translation?
I use `pip` to install Python packages, and I've never really run into much pain. I use it even on Debian and Ubuntu systems, because it's much easier for me to get a newer version of a package or choose precisely the version I want, regardless of what's in the OS package repo.
It's a good and a bad thing, depending on your perspective. OS package management and developer package management related, but have different use cases. OS package management preferably wants to install *one* version of a package into the system. The advantage is that if you upgrade it (for security reasons, for instance), everything that uses it is upgraded at once. Generally installation is done by the system administrator. Developer package managements wants to make it easy for developers to install all kinds of versions of a package in parallel, and hack on them when they decide to do so in a particular project without affecting the rest of the environment. Code in packages is often a moving target. Installation is done by the developer. The units of reusability also can get smaller. It also allows a developer to release one package without having to worrying about packaging it for all possible platforms. I'm on Ubuntu Linux, say, but I regularly work together with developers who are on Macs. What OS package manager should we use? Of course you could tell me to install everything manually. But I'm spoiled now, sorry. I like being able to check out some code and have it automatically set up my development environment for it. Having to do this stuff manually from some frequently out of date INSTALL file tends to feel terribly cumbersome. (installing Zine was a vivid reminder of this) The more stable dependencies are, the easier is it to build on dependencies installed using an OS package manager. But developers don't always work with stable dependencies. If you're looking from the OS package management perspective, the developer approach tends to appear terribly wrong. But I couldn't do the development I do if I had to juggle hundreds of debian packages with Python code in them. 
If you deal with lists, you can also use .extend()
A more extensive doc string, particularly on the main routine, would be a help. Either another programmer, or you some time in the future, will come to this routine and be not sure what "human-readable representation" this is.
A good discussion of k-means++ for finding better cluster seeds: http://lingpipe-blog.com/2009/03/23/arthur-vassilvitskii-2007-kmeans-the-advantages-of-careful-seeding/
I am Lisp programmer and I write an article on issues as macros, fexprs and eval. I want to compare opinions of programmers of various programming languages on eval. If you want to contribute your opinion on eval in Python (or you want to look at result), the adress is: http://kazimirmajorinc.blogspot.com Thank you, -- Kazimir Majorinc 
Add 4 spaces in front of a line to make it look right: def 加两个数目(参数A, 参数B): x=float(参数A) + float(参数B) return x There's also an all Chinese version of Python that changes the keywords to Chinese, but I don't think it's very popular. 
You are doing it so wrong it's hard to know where to begin. 1. In versions of Python less than 2.5, making strings by adding small bits together is incredibly inefficient and slow. In versions equal to or greater than 2.5 it's better, but still not recommended. Use `.join(my_list)`. 2. Based on what you've written it appears that you don't know the difference between "unicode" in general and specific encodings that just so happen to be able to encode unicode like "utf-8" and "utf-16." This is very important and nothing else we say will make any sense if you don't get this. 3. Printing a string in the terminal is completely different from and unrelated to the issue of unicode in general. You need to set your environment to match the expected encoding of your terminal program. For example, I use OS X, so I export `LC_CTYPE=en_US.utf-8` in bash, and so when I run `python` it knows to convert things to UTF-8 when printing. 4. You seem to be confusing Python 2.x and 3.x. Be aware that in Python 3 `str` was renamed to `bytes` and `unicode` was renamed to `str`. Also there were minor API changes to make it more convenient. In any case, you should always think of them the same way: World gives me raw data -&gt; I changed it into unicode -&gt; Process -&gt; Convert back and emit 2.x: str -&gt; my_str.decode("utf-8") -&gt; do_stuff(my_unicode) -&gt; my_unicode.encode("utf-8") 3.x: bytes -&gt; str(my_bytes, "utf-8") -&gt; do_stuff(my_string) -&gt; bytes(my_string, "utf-8") (Technically, Python 3's file object system is a little different, so you may not need to do the conversion steps as explicit separate parts, but you can do it when you open the file object. Still it's the same principle.) 5. More.
Your Python doesn't know the encoding of the terminal it's being used with, so it assume it's an ASCII only terminal. In bash, or whatever your shell is, set `LC_CTYPE` to whatever encoding your terminal uses and it should be able to convert things appropriately. This is unrelated to the issue of unicode in general though. 
This is an incredibly bizarre piece of code, but now I know about `divmod()` which is nice.
Basically all you said is more or less correct. .join(my_list) was causing my issues putting things into my DB so creating an awfully long formatted string was the only way to do it. For some reason $LANG was empty and put into /etc/env.d/02locale LANG="en_GB.UTF-8" Py2+3 has been confusing. I found it hard to find any info for py2 and py3 seems to handle unicode a lot more simply. AFAIK Unicode accounts for all types of characters outside of your usual 8bit ascii, but I wouldn't be surprised if i'm wrong. I've fixed my issue anyway now.
I can't tell if it's good or bad that PJE is never going to get around to doing generic functions.
&gt; AFAIK Unicode accounts for all types of characters outside of your usual 8bit ascii, but I wouldn't be surprised if i'm wrong. This has too many wrong assumptions in it to even count as wrong. Please read [Joel on Unicode](http://www.joelonsoftware.com/articles/Unicode.html) before you embarrass yourself terminally. TL;DR version: "Unicode" is the name for a mapping of Platonic number to Platonic characters. In the world there are many encodings which map real bytes to real characters. Different encodings have different coverages. ASCII covers only 127 unicode characters (7-bits worth, but encoded in an 8-bit byte). Latin-1 covers more including characters like "é" and whatnot. There are various Greek, Russian, etc. encodings which cover ASCII + some local language, but not all languages. Finally, there are UTF-8, UTF-16, and UTF-32 (along with a few other less common variants) that map all Unicode code characters to something or other. UTF-8 and UTF-16 are variable byte length encodings with minimum lengths of 8 bits and 16 bits respectively, and UTF-32 is a fixed length encoding of 32 bits per character. There are a few writing systems and characters that have yet to be incorporated into Unicode, but it is literally nothing you will ever care about in your life unless you like writing obscure Chinese Buddhist sutras or using dead languages, and in any event, these things will probably be incorporated into Unicode before too long anyway. Even Klingon has its own unofficial spot in Unicode. 
That was basically my understanding which I got from Dive into Python3 from a person here linking to it.
&gt; .join(my\_list) was causing my issues putting things into my DB so creating an awfully long formatted string was the only way to do it. `"".join(my_list)` creates a string. That's its whole point. You wrote: &gt; def gen_line(self, info): line = "" for cnt in range(len(info)): meta = info[cnt] print type(meta), meta line += '''%r''' % meta if cnt &lt; len(info) - 1: line += "," return line This is bad. It is violently anti-Pythonic. It turns out that you almost never need to use `range` in a well written Python program. With only rare exceptions, thinking that you do need `range` is a sign that you're trying to write an old fashioned `for (int i=0; i&lt;10; ++i)` kind of loop. Don't use `range` except as a last resort. This is a somewhat subjective criticism, but `meta` is a terrible variable name. What does it mean? Why are you triple single quoting `'''%r'''`? Triple quotes are only useful when you're going to give a multiline string literal, or you want to use double and single quotes inside of your literal and you can't be bothered to escape them. Again using `+=` on a string is strongly discouraged in Python because in the worst case, it allocates a whole new string every loop through, which then gets thrown away at once, since strings are immutable. This whole function is much clearer a one liner: def gen_line(self, info): return ','.join(repr(item) for item in info) If you insist on printing the types of stuff in info as you go it becomes a multiliner: def gen_line(self, info): l = [] for item in info: print type(item), item l.append(repr(item)) return ','.join(l) If for some reason you love C-style formatting, you could change the `l.append(repr(item))` to `l.append('%r' % item)`, but I have no idea why you would do that. It's slower and error prone if item ever turns out to be a `dict` or a `tuple`. In any event, Python 2.6+ has a new formatting system that's less error prone, so you should move away from `%` formatting.
&gt; Initially I was using `", ".join(info)` but that really didn't like unicode It doesn't like to mix unicode and non-unicode that's not ASCII. For example: &gt;&gt;&gt; ','.join([u"a", u"b"]) u'a,b' No problem joining two unicode strings with a byte string in ASCII range. &gt;&gt;&gt; ','.join([u"a", "b"]) u'a,b' No problem joining a unicode string and a byte string in ASCII range with another byte string in ASCII range. &gt;&gt;&gt; ','.join([u"a", "\xf6"]) Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; UnicodeDecodeError: 'ascii' codec can't decode byte 0xf6 in position 0: ordinal not in range(128) Can't join a unicode string and a non-ASCII byte string. Why not? Because it's ambiguous. What does `"\xf6"` mean? Well, let's see. &gt;&gt;&gt; "\xf6".decode("latin-1") u'\xf6' In latin-1 it means `u'\xf6'` or "ö". But in UTF-8… &gt;&gt;&gt; "\xf6".decode("utf-8") Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "utf_8.py", line 16, in decode return codecs.utf_8_decode(input, errors, True) UnicodeDecodeError: 'utf8' codec can't decode byte 0xf6 in position 0: unexpected end of data It's a meaningless blob of binary. And in Mac Roman? &gt;&gt;&gt; '\xf6'.decode("mac roman") u'\u02c6' It means `u'\u02c6'` or "ˆ", which is totally different. 
Yeah, that was very bad and it was something I tried because I was desperate. That whole function is gone now. meta, in context, made more sense than it does here. The triple quotes were probably there because I wad double quotes in between at some point. Never thought to try join with repr. Everything I wrote here was whilst I was going mad. I was trying to do something I didn't really understand and things that were supposed to work didn't because of the lack of $LANG I've never heard about string formatting being bad. I'm just following what my book said.
&gt; Can't join a unicode string and a non-ASCII byte string Yeah. I've learnt that the hard way now. I found out that my use of os.walk was giving me a byte string and then I was trying to mix that with the unicode from the try/except clause. Right now I haven't handled the os.walk issue well. I'm sort of just skipping and filenames with byte strings. Appreciate the help and pointers.
I can't get that join+repr method to work. I get an error unhandled OperationalError "near "'Bj\xf6rk'": syntax error" The input going into it looks like this '/home/jon/Music/Post/01 Army of Me.mp3', 1, '01 Army of Me', u'Bj\xf6rk', u'Post', 1995, u'Rock', '03:54', 128, '1010091406' And my DB query looks like this INSERT INTO media (file_name,track,title,artist,album,year,genre,length,bitrate,added) VALUES ('/home/jon/Music/Post/01 Army of Me.mp3', 1, '01 Army of Me', u'Bj\xf6rk', u'Post', 1995, u'Rock', '03:54', 128, '1010091406')
Read your DB module's documentation. They usually have a fail safe way of passing args without having to worry about escaping things properly. For example, here's [the sqlite3 module documentation](http://docs.python.org/library/sqlite3.html): &gt; Usually your SQL operations will need to use values from Python variables. You shouldn't assemble your query using Python's string operations because doing so is insecure; it makes your program vulnerable to an SQL injection attack. &gt; &gt;Instead, use the DB-API's parameter substitution. Put ? as a placeholder wherever you want to use a value, and then provide a tuple of values as the second argument to the cursor's execute() method. (Other database modules may use a different placeholder, such as %s or :1.) For example: &gt; # Never do this -- insecure! symbol = 'IBM' c.execute("... where symbol = '%s'" % symbol) &gt; # Do this instead t = (symbol,) c.execute('select * from stocks where symbol=?', t) &gt; # Larger example for t in [('2006-03-28', 'BUY', 'IBM', 1000, 45.00), ('2006-04-05', 'BUY', 'MSOFT', 1000, 72.00), ('2006-04-06', 'SELL', 'IBM', 500, 53.00), ]: c.execute('insert into stocks values (?,?,?,?,?)', t) 
Cheers. That's awesome info. The only thing i'm having issues is trying to do this without 20 "?"s. I can't do it without identifying the columns as some are unused in the instance i'm using. [edit] Ok, so i'm able to put things into it without any exceptions using "?" but when I fetchAll there's nothing in it. Just had a look in the .db file and apart from the tables, it's empty. [edit2] Figured it out. In the restructure I forgot to add a .commit(). Now i've another issue. Using "?" I have this arg = ("artist", ) self.media_curs.execute("SELECT DISTINCT ? FROM media", arg) However, this would be equivalent to self.media_curs.execute("SELECT DISTINCT 'artist' FROM media") Instead of self.media_curs.execute("SELECT DISTINCT artist FROM media") 
You install directly under /usr/lib/... using pip or do you always use virtualenv? To uninstall, you just rm -rf the directory?
Exactly. I like knowing that only my OS package manager is responsible for everything under /usr/lib rather than having multiple package managers installing things in the same place, possibly stepping on each other's toes.
I always use virtualenv at this point. Also, `pip` now has uninstall support.
Scrapy development version now supports HTTP proxies (with authentication). See: http://doc.scrapy.org/dev/faq.html#does-scrapy-work-with-http-proxies Oh, and Scrapy supports HTTPS - you only need to install the pyOpenSSL module.
They're already here: http://pypi.python.org/pypi/PEAK-Rules Probably only a weekend or two away from a beta release, though I'm a bit short on weekends still.
Oo, this sounds like fun. Weren't you originally saying these should be built in at the interpreter level so that someone could add rules to functions that were originally undecorated, or am I misremembering? 
Are you familiar with Eric S. Raymond's [The Art of Unix Programming](http://www.faqs.org/docs/artu/)? It might not be exactly what you're looking for, but it's a great read anyway.
I haven't read through the whole thread, and maybe I'm misreading what you're asking, but this works for me in 2.6.2: &gt;&gt;&gt; print "Bj\xf6rk".decode("latin-1") Björk
Yeah. I found out I had an issue with my system. It was unaware of encodings.
Here's whats involved in a logger.debug() call when logging is disabled for a particular logger: def debug(self, msg, *args, **kwargs): if self.isEnabledFor(DEBUG): self._log(DEBUG, msg, args, **kwargs) def isEnabledFor(self, level): if self.manager.disable &gt;= level: return 0 return level &gt;= self.getEffectiveLevel() def getEffectiveLevel(self): logger = self while logger: if logger.level: return logger.level logger = logger.parent return NOTSET A JIT can inline the calls to isEnabledFor() and getEffectiveLevel() (although I don't understand how, since `self` can can redefine these methods on a per-instance basis...maybe someone can explain that to me). But I don't see how it can do much with the traversal across logger.parent and the checks for logger.level, as well as at least four attribute fetches occurring. None of that is constant. 
It's true that most of that isn't technically constant, however in Python very few things are. Therefore the way these JITs must work is by guarding against mutations and using fast paths when possible. So in this case the fast path would be that none of the methods are redefined. 
Interesting, I, too chose Turbogears (2.0) for the same reasons the author chose Turbogears. I much prefer the approach of picking the best possible components and tying them together to the single, gigantic reinvented wheel that is django. That said, I get the impression that django's docs are pretty good, and furthermore django is probably the most widely used python web framework out there, so there's more likely to be hosting support as well, I'm sure they're out there but I don't know of any wsgi hosts.
Well, I certainly was complaining about the dropping of various meta-hooks in Python 3, but the hooks that allow this to be done in fact work correctly in Python 2, so PEAK-Rules is quite usable now. It's just that there's not enough documentation to qualify (in my mind) as a released version. The API is mostly stable, there are just a few odds and ends in the internal API that might change in order to support a few of the planned future features.
I use python to script stuff for non-techies. When working with MS office formats I've found [these packages](http://www.python-excel.org/) to be useful. I second SQLAlchemy for extracting the data.
 import os import win32com.client conn = win32com.client.Dispatch("ADODB.Connection") db = r"c:\some.mdb" DSN="Provider=Microsoft.Jet.OLEDB.4.0;Data Source=" + db conn.Open(DSN) rs = win32com.client.Dispatch("ADODB.Recordset") rs.Open( "[SomeTable]", conn, 1, 3 ) print rs.Fields.Count for x in range(rs.Fields.Count): print rs.Fields.Item(x).Name, print rs.Fields.Item(x).Type, print rs.Fields.Item(x).DefinedSize, print rs.Fields.Item(x).Value Similarly: xl = win32com.client.Dispatch("Excel.Application") ... Google for the things you can do with the Office COM automation objects. What, exactly, do you mean by 'Access Tool'? 
You're clearly mad!
Did you consider augmenting the existing code to do this? If you're an undergrad CS student I'd be extremely disappointed if you lack the dedication to investigate this on your own. I take it that the reports *don't actually* have to run in parallel but merely run all of them in a row. You may want to investigate the macro recorder present in Office as it's capable of automating a lot of cruft and, in the process, teach you what code is needed to perform certain tasks.
Oh, right - one of *those* things :)
You might also want to check out [this earlier thread](http://www.reddit.com/r/programming/comments/8nwc9/reading_and_writing_to_excel_spreadsheets_in/). The linked article isn't all that good, but the discussion is very helpful. Edit: Formatting is hard.
Future advice: Never tell your boss anything. Those who can't do, manage.
Weird that you were voted down, I had the same reaction as yours to the story. At the very list Google up the problem before saying that you can do it.
Keep in mind that it may be easiest to export to some intermediate format like CSV for some cases. (Yes, I've typed "import win32com" more than a few times.)
You'll have a much easier time just accessing the data in the databases via ODBC from inside Python. You can attempt to automate Office or the app itself, but that won't work well for a headless process and it will be fragile, to say the least. I see quite a few votes on here for SQLAlchemy, which probably would work great. To give you another option, which happens to be Windows-specific, I did this a long time ago for a client using the adodb module, which you can find here: http://phplens.com/lens/adodb/adodb-py-docs.htm The key to saving you labor here will be writing a good SQL statement that will allow you to avoid having to do running totals, sorting, etc. in Python. Abuse SQL appropriately and this should be pretty simple. If your boss is reasonable anyway... 
This sound pretty easy, but you sound pretty dumb. Halp! On the other hand, you might get reddit to solve your problem for you... 
It might be easiest to use an export utility to pull the data out into csv files, from there import into something like sqlite and then from there create your reports. All depends on how fast they need to run, how hard to duplicate the existing reports, how likely it is you'll get more requests, etc, etc.
[Resolver One](http://www.resolversystems.com/products/resolver-one/) may be worth a look. It's a spreadsheet that generates python, then you can hack at it to modify it to do what you need.
MSVC? My suggestion was python as specified, so a decent text editor and an installation of [activestate](http://www.activestate.com/activepython/) should do the trick. The line: xl = win32com.client.Dispatch("Excel.Application") instantiates a COM automation object for whatever version of Excel you have installed on the machine where the script is run. You can subsequently manipulate it to fit your purposes. Alternatively, you can use the xlwt package to emit .xls files as recommended by yggdrasilly below. Edit: You should really get in touch with local IT and have them install ActivePython for you. All those additional packages can make life a lot easier - especially in the long run.
It's always great to get more material about Twisted
You can also use pyodbc or adodbapi to fetch data from the database. Use a [connection string](http://www.connectionstrings.com/access#p85) to connect to your Access (JET) database. Honestly, using SQLAlchemy is quite overkill, unless the model is large and complex. import adodbapi conn = adodbapi.connect(connection_string) cur = conn.cursor() cur.execute(sql_query) for field_list... in cur.fetchall(): ... process data ... cur.close() conn.close() To write into excel, you'll either need to use *xlwt* or use Excel OLE automation. xlwt is less featured but easier to deal with. Excel OLE automation is the same interface that you'd use in a macro.
This. I spent 4 years using pyodbc to pull various reports from as400 datasets with python. Use standard library modules to export to csv, or hunt down one of the libraries that lets you put it straight into Excel. If I hadn't been laid off a couple months back, I could give you my sample code. COM might be the easiest if you don't have access to the actual specifications for the reports. You'd have to actually tell Access to run the reports for you. Easier is just building some SQL queries that replicate the report output, and pulling that through pyodbc.
Thanks - I will get back to your post when my Ubu9.10 is rolling with Django.
Looks like Tarek's efforts have helped create some competition in the Python packaging/distribution space. It would've been better for the community if some consensus could have been made, but any progress is better than no progress.
No worries. It's likely, their browsers didn't support the &lt;sarcasm&gt; tag. Despite, learning to communicate the required time and resources for any single project like this properly to a manager doesn't come easy. 
Dun dun DUNNN!
Nah, just use the pywin32 installer - don't build it
Just out of curiousity, what niche does ActivePython fill? I code in Python quite often and I've never understood what its purpose is. What's wrong with a regular Python install and what does ActiveState bring to the table that enhances it?
Is it gonna not suck?
No
Nope, it's just pje being back to his old tricks: as soon as something (or someone) threatens to make him irrelevant he magically finds the time to work on setuptools again. edit: fixed handheld typo
Is there any easy (perhaps automated way) to validate the migration in an application from 0.5.6 to 0.6?
I like this one: "But before you do that, be sure to uninstall Distribute completely" This may be the reason why he suddenly woke up.
Exactly. I can understand if someone doesn't have time to maintain a package, but then hand it off to someone else... that's what a good maintainer should do anyways. I think this is too little too late, pje has lost the trust of the Python community and it's probably going to take more than a few bug fixes that have been sitting in a bug tracker for a year to make everything better.
Distribute uses the 'setuptools' namespace, so obviously the two cannot co-exist. Why not favor facts over cynicism?
&gt; But before you do that, be sure to uninstall Distribute completely. SHIT JUST GOT REAL. Amendment: What I meant was, "Shit just got in the same namespace with another incompatible package".
Because it's PJE we're talking about. For 0.6c9, the community already had to force his hand by threatening to fork setuptools. Without that, 0.6c9 still wouldn't exist.
**Platform Support** * cPython versions 2.4 and upwards throughout the 2.xx series * Jython 2.5.1 - using the zxJDBC DBAPI included with Jython. * cPython 3.x - see sqlalchemy/trunk/README.py3k for information on how to build for python3. I think this is the first serious ORM to support python 3. 
... can we just pick a package already.
There does not need to be a consensus, the BDFL just needs to pick one, which he seems to have almost done recently.
This all sounds interesting - but can anyone put this into context? What's the timeline of events that's led to all this??
Notice that this is the only post we can't comment on, on his blog. I would have tons of things to reply.
I am preparing a blog entry on this. Just to make things clear and evacuate all the FUD that is going on.
My own bug reports and Jean-Paul's (exarkun) go back 12-15 months. Now, I can understand some of the friction between PJE and Tarek, but even other people prodding never got any blessing from PJE to work directly on setuptools. People have been trying to be courteous to PJE by respecting him as the author of setuptools, but if he then refuses to bless other *active* people to work directly on setuptools, well, then you get flak like this. To rephrase his positing's title: that wouldn't have been so difficult, now would it?
He managed to write a lengthy post about this without any explicit reference to Distribute. Impressive!
Careful not to write it under anger Tarek. PJE acts like a child, don't waste your energy on it. Just continue your work, it's been great so far. Leave him behind.
I would agree - web2py is a great little framework - and it works 'out of the box'. 
Personally I don´t give a damn about the soap opera which are the Python dev lists. But it is rather enlightening to see how people have responded to the news about this rather sudden release. It was improper of PJE of semi-abandoning setuptools, but apparently it is not proper either if he takes up the challenge which Tarek Ziadé &amp; co have posed. Paraphrasing Jim Fulton: perhaps you should show a bit more respect for the author of WSGI and setuptools/easy_install. Both tools may not be perfect, but they work and they are "standards" insofar as the average Python user goes. Without WSGI and easy_install, Python would be worse off: without a decent compatibility layer for web applications or a working package manager. PJE got there by actually *creating* these two *working* solutions were other kept on bickering and arguing. That PJE comes across as a prima dona goes without saying, but then again, I can't be really impressed by the antics of Tarek Ziadé and in-crowd either. If you don't like his work, fork it and make it better. Stop bitching about it. Forking setuptools they finally did. We will see If Ziadé can do a better job. If so, PJE and setuptools will become irrelevant. But of course, considering his track record there might even be a change that the notorious setuptools 0.7 *does* appear and that it *will* turn out to be the most usable solution. 
&gt; apparently it is not proper either if he takes up the challenge which Tarek Ziadé &amp; co have posed. No it's not. Because Distribute wasn't intended as a challenge, it was intended as a way to get rid of setuptools altogether. The challenge was — as I already mentioned — a year earlier when the community managed to force PJE to release 0.6c9. The challenge was two years earlier (and ever since) when the community tried to get PJE to open up the development of setuptools and let other people help him work on it. &gt; perhaps you should show a bit more respect for the author of WSGI and setuptools/easy\_install. I'm sure most people respect him, or his work at least, but at this point PJE's behavior makes him an issue, he forces people to either work around him or go through untold pains, that's not a good thing. All the alienation he got, *he earned*. It's not like there's a "let's all hate PJE" campaign out there, I don't think anybody woke up one day and decided he was going to spend the rest of his life hating on PJE. I sure didn't. &gt; I can't be really impressed by the antics of Tarek Ziadé and in-crowd either. If you don't like his work, fork it and make it better. And you might want to note that this is precisely what Tarek ended up doing.
&gt; Notice that this is the only post we can't comment on, on his blog. Yes, it's also the only post which yields a 403 when trying to open it. I thought dirtsimple was broken, but it turns out all other posts work normally. I wasn't impressed.
Hey there, Tarek. I fully agree with you. Oh, by the way, I am TERRIBLY SORRY that I could not contribute the improvements I wrote for distutils 2.4 back into Py3K. I will probably have to work extensively to get these back in shape. I posted them in my project Web site, in case anyone is interested. Oh, yes, I almost forgot: *you rule*.
They ship it with pywin32 and thats all. I thought it was pretty useless, prefer to get the python.org binaries.
OK, so. Phillip Eby ("PJE") originally wrote setuptools, which was a set of extensions and additions to the normal Python packaging system from the standard library. Many projects adopted it, because it offered features they wanted. Then PJE basically went AWOL -- setuptools has languished without maintenance (even basic bugfixes) for over a year; PJE also rather notoriously doesn't accept help in maintaining it, so there wasn't anybody else who could deal with the problem. This prompted a fork, called Distribute, maintained by Tarek and a couple other folks; the first releases of Distribute are and have been completely back-compatible with setuptools, applying bugfixes which had been waiting forever and providing compatibility with Python 3.x (setuptools only works on 2.x, and for a while didn't even work on the most recent 2.x). Future releases will incubate various ideas for improving and standardizing Python packaging. Suddenly by some grand coincidence, PJE has found time to: 1. Come out of the woodwork and finally try to maintain setuptools again. 2. Sneak some subtle (and some not-so-subtle) things into his various blog and mailing list posts bashing on Distribute and the people involved with it. It should be noted, by the way, that I'm not particularly neutral here: I've never liked setuptools (and hope that Distribute, in the future, moves away from some of what I feel were setuptools' design flaws), and I have somewhat strong opinions on PJE, as do various other people. You may note that people don't end up getting commonly referred to by their three initials (see: RMS, ESR, JWZ) without being somewhat controversial.
FWIW, my experience has been that, aside from his very early work starting projects like setuptools and the WSGI spec, PJE tends to bring nothing but stop energy and stonewalling to anything he's a part of. A WSGI spec that works on Python 3 (and a successor WSGI 2 which cleans up warts) could've been ready quite some time ago, if not for the "contributions" of the original spec maintainer...
About 4 years earlier, PJE wrote this in [his post regarding self-transformation](http://dirtsimple.org/2005/10/self-version-20.html): &gt; So at this point, my motivational profile seems a bit lopsided. ... It's all kind of "meh" to me. **I'm not in love with programming**, if ever I was. I do still feel some love of teaching, consulting, and organizational systems design, but I find myself strangely caring little about software architecture per se, and somewhat disillusioned about Python's future, despite being excited about PyPy. I am not sure if that is still true. He is passionate about his Self-Help writings/videos though ([example](http://thinkingthingsdone.com/about))
+1 Also attach citations in your post. Wikipedia style. Facts only! (no opinions, intuitions, imaginations, allegations and so forth). Let the facts speak for themselves.
**UPDATE**: From his [recent blog post](http://dirtsimple.org/programming/index.html), &gt; ... this sort of rampant negativity -- and the corresponding negativity in me that it tends to trigger -- is a big reason **I wanted out of professional software development** in the first place. Personally I find the recent discussions related to setuptools in distutils-sig@ and python-dev@ to be a little bit vitriolic.
You left out DHH from that list.
Can you actually point out any instance of PJE "bashing" on Distribute and the people involved with it?
I have great hopes for Distribute. Given that Tarek seems to be running it as a _much_ more open project, I'm hoping it will eventually fix some of setuptools' flaws. This openness is something that is definitely needed for something as major as this, since setuptools/Distribute seems to be the de facto way to distribute python projects (yes, there are others, but setuptools is always the elephant in the room). The main thing that turned me off to PJE's running the show, and made me concerned enough I wondered at times if it was all coming crashing down was his attitude towards others when new features were proposed. I can't find the mailing list I read this on, but at one point there was a discussion of the idea of extending the "multi-version install" mode of setuptools such that a single version would be the primary, and importable by default if the module (or it's egg) didn't specify a version, and then fall back onto multiversion when it _did_ request something specific. This seemed a popular idea on the mailing list, and I think would be popular in general... I know the lack of that feature has kept me from using multiversion to it's fullest. The discussion of that feature was the first time I'd actually read posts from PJE, and he was _incredibly_ hostile to the entire idea, attacking the posters themselves for not knowing how the system works, and how "no one needs that", despite the fact that the other people on the list had posted a number of compelling use cases. I'm all for the head of a project being the one who controls the vision of it, but I think large projects like this should follow GvR's example, and realize there are going to be a number of really smart people trying to help, and that the project could benefit from all their input. PJE's announcement, with it's passive-aggressive snide remarks about Distribute (a not insignifgant about of work in it itself), did nothing to allay my worries about the future of that project. Unless he changes his treatment of the community, I forsee Distribute attracking a much broader developer base working on it, thanks to Tarek's leadership, which it going to mean it will eventually eclipse setuptools, no matter what PJE does on his own. He's done great work at the start, but I think it's obvious there's a groundswell of ideas, patches, and improvements which are waiting for an outlet. 
I concur with http://mail.python.org/pipermail/distutils-sig/2009-October/013565.html and please note the remaining thread. The general response by the Distribute team members has been a bit too glib. And the virulent response to PJE recent announcement has not made things much better. I really hope Distribute will survive and surpass setuptools and becomes the new de facto (or preferably BDFL anointed) package manager for Python. Better an open team creating a community supported package than a single developer sporadically releasing a personal project. No discussion there. But it is still too early too judge that Tarek Ziadé &amp; co are succeeding. Oh, and I don't mean *technically*. It's clear that the team behind Distribute is doing a good job. ..Technically... But what about taking care that requirements are for the benefit and in the interest of all users? What about assurance that communication is open and honest? What about the impression (note: "impression", no one is actually accusing anyone as far as I know) which is given that at least some actions are being taken because they harm "setuptools" as opposed to having some benefit for the wider community? Why switch from a Cathedral with one ego-maniacal developer to a bazaar with a dozen of those? 
&gt; Personally I find the recent discussions related to setuptools in distutils-sig@ and python-dev@ to be a little bit vitriolic. Erm… no shit? People have tried to work with or had to work around PJE for at least two years, that tends to generate bitterness, and when PJE comes out of retirement a pair of weeks after the announce of a fork (damn that timing) and suddenly says that he found some time to work on setuptools after all and has plenty of patches applied and is doing new releases and everything, it tends not to help.
I completely agree. I find it superbly frustrating when "undergrad CS majors" can't figure out how to Google something. I may come across as being harsh, but I've seen this way too many times. I'm in Comp Eng undergrad, and talking with some CS majors I find they are completely uninterested in programming or doing any sort of practical work, and when asked about it they tend to dismiss it. My friend worked with a CS major in 3rd year or so (iirc), who didn't know how to burn a CD. Before I started university, I was already very interested in programming; I had done several projects in my spare time, etc. Several of my classmates in CE (and people I know in CS) had never programmed before. I find it hard to understand how you can decide what degree you want without ever trying the stuff in your spare time to see if you like it. When I don't know how to do something, I spend 10 minutes to Google it, do some reading, and figure it out. Maybe this is the difference between comp sci and comp eng. I dunno, but the attitude of people in CS these days is really dissapointing (from my experience).
Thanks for the breakdown! (WTF happened to ESR anyway?)
1) PJE create setuptools 2) PJE does not activally maintains it 3) PJE can't find a qualified maintainer (according to his judgement) 4) Tarek &amp; others create a fork 5) PJE acknowledge the fork 6) Tarek make changes distutils in python 2.6.3 in a way that breaks setuptools 7) PJE works on setuptools again IMO: PJE not maintaining - ok PJE not giving setuptools away - ok Tarek fork - ok python 2.6.3 break setuptools - personal attack that damages python as whole ... now it is a personal fight. PJE is fighting back.
its the way he said it. 
except GvR. But that's more like two and a half initials. maybe wanting to highlight your middle initial is just part of a bigger pattern of grandiosity (certainly is for ESR and DHH). 
That's your idea, not the truth. I didn't break setuptools compatiblility on purpose in 2.6.3, that was not a personal attack at all. And PJE knows about this fact. 
If you're the real Tarek, keep up the good work. I always thought setuptools was disorganized and poorly documented, and you seem to be able to change this for the python community. I have read through your roadmap carefully and the plan and your ideas seems well thought out.
Thanks Rudd-O, come by Distutils-SIG ;)
Thanks for cheering. I think I will never do as good as PJE that's the truth. But I think this piece of software needs more maintainers and commiters. That's what's the fork about mainly
i saw his code, you will do better, in all cases
sorry, forgive me if I am wrong. I am just trying to understand what happened. As far as I understood you made changes to Distribute so that it works on python 2.6.3 before 2.6.3 was released. Since Distribute is a fork from setuptools it was obvious that setuptools was broken. What did I miss?
GvR is the BDFL, hes the only one with a fix
I've fixed a bug on Distutils that created a regression because of a fuzzy documentation on how a given API works. IOW, the fix I made was clean and normal, and borked Setuptools because the latter makes some assumptions on how and when the API is called. This bug was then reported in the Distribute tracker before 2.6.3 was out (by people running the trunk) and fixed on Distribute side in the meantime. But by the time Python 2.6.3 was tagged, I didn't realize that such a change was taking setuptools users in hostage. (other projects fixed that by the time it happened) Yes that was dumb, but not an evil plan of mine at all. I 've fixed the problem to make sure 2.6.x still works at it uses to work and we are shipping 2.6.4 soon (with another important regression fix for logging). What would be our interest to do that anyway. That would be a loss-loss situation. 
For those curious, this is the reported issue that resulted in the fix that made it into 2.6.3 - which lead to the incompatibility: http://bugs.python.org/issue6403 This issue lead to these changes: http://svn.python.org/view/python/branches/release26-maint/Lib/distutils/command/build_ext.py?r1=73791&amp;r2=73790&amp;pathrev=73791 Which lead to this revision to 'unbreak' Setuptools: http://svn.python.org/view/python/branches/release26-maint/Lib/distutils/command/build_ext.py?r1=75256&amp;r2=75255&amp;pathrev=75256 As you can see - at no point did Tarek say: "Aha! This is my 'break Setuptools' sneaky revision". All the changes made were for logical reasons. They were small changes, over time, to fix lots of different issues. Just because setuptools made an incorrect assumption ( which Tarek pointed out was trivially easy to fix: http://bitbucket.org/tarek/distribute/issue/41/#comment-53087 ), doesn't mean PJE gets a free pass to continue to have buggy code. (And yes, I know I'm replying to Tarek, but that was just more to let you know people support you / know you didn't do anything "underhanded")
&gt; As you can see - at no point did Tarek say: "Aha! This is my 'break Setuptools' sneaky revision". thanks for the link http://bitbucket.org/tarek/distribute/issue/41/#comment-53087 Tarek: "I doubt that Setuptools itself will be fixed then released, but this problem will be fixed in Distribute 0.6.2." next comment in the thread (not by Tarek): "I don't care about setuptools, only Distribute. =) "
As I said - this fix and this comment was unrelated in time, to Python 2.6.3 being tagged and shipped. When I said I doubt that Setuptools will be fixed - that was in the context of the fact that Setuptools was not changed for a year. And when I said that I didn't realized at this moment the impact for 2.6.3, I was fixing Distribute for that bug. *sigh* 
v is indeed not an initial, it's the Dutch "van", which means 'of' or 'from'. Though I don't know where Rossum is. :)
+1 on that too. Let's just focus on the code, not the debate. Various people in this debate are upset right now, and I think an attempt of friendly cooperation or at least peaceful coexistence will be more productive. 
WTF?
David Heinemeier Hansson - Ruby on Rails creator
Actually, there are plenty of other posts on my programming blog where comments are closed. For example, some of my posts regarding Zope, or on female-friendly hiring practices in the IT community, also have comments blocked, because they got low-quality comments.
That was a permissions error caused by upgrading to XP; thanks for pointing it out, as I probably wouldn't have noticed for a long time, if ever. (Long version, I use code that generates the blog statically to a staging area, then rsync it to the web server; if the Windows perms aren't correct, new files get created with bad permissions on the server.)
Not all *that* coincidental; the 2.6.3 problem significantly raised my priority for releasing an updated setuptools.
&gt; but even other people prodding never got any blessing from PJE to work directly on setuptools. Prodding, no. Asking, yes. Jim Fulton asked politely, and I gave it to him. Had Ian Bicking, P. Jenvey, or Martin van Loewis ever asked, I'd have given them varying degrees of freedom. Anybody else, I'd have asked to see some patches first. But almost nobody actually *asked*; they demanded. Even the few that did ask, and got my "ok, let me see some patches", responded with indignance... which means they failed the test of caring more about themselves than about the project.
So the 2.6.3 problem was much more significant than the numerous problems people say were languishing in the setuptools bug tracker for the previous 12-15 months? Why is that, by which I mean, what made it so much more significant?
&gt; When I said I doubt that Setuptools will be fixed - that was in the context of the fact that Setuptools was not changed for a year. Yep, but it's precisely that observation (or rather, the change that accompanied it) that forced my hand. If you'd not made that change, it's considerably less likely that I'd have moved forward with 0.6c10, and simply ceded the 0.6 line to Distribute by default, even if I ended up with time to work on the 0.7 line. 
Please. Distribute's own documentation says you need to uninstall it in order to switch back to setuptools. I unfortunately assumed that everybody knew that, and the result has been people taking it to mean I have something against Distribute, specifically. As I said in my blog post, there was a point at which I was actually *excited* about Distribute taking over... and it lasted for about one day before the mailing list snarking made that history. Even with that, I was pretty much content to let Distribute take over by default. The 2.6.3 change, and the reaction of users to feeling pressured to move to Distribute, was what forced me to get back into the action. 
So then it's a good thing that the change was made, right? Thanks to it, people who prefer setuptools have got a long-awaited new release which fixes many long-standing bugs. People who want to use Distribute are no worse off, and potentially better off as they'll see all the fixes "done right" by you, and have the opportunity to ensure that Distribute benefits from your experience and skills. Win-win, open source FTW!
OIC I actually googled it after I read the comment and remembered who he was, thanks.
&gt; What made it so much more significant? My perception of the impact on the user population. Bear in mind, I don't mind somebody switching to Distribute because they *want* to. Being *forced* to do so is another matter entirely. Edit to add: Also, most of the languishing problems were things that could be worked around with different command line options or configuration settings; the 2.6.3 problem could *only* be worked around by changing setuptools code.
That's.. *suspicious*!
&gt; they failed the test of caring more about themselves than about the project. Reading your blog entry, this is actually how you sound yourself to be honest and backing up your verbatim with patches is not making your attitude go away. In fact you wouldn't have avoided comments had you responded with only patches and a release.
I don't think you did it on purpose, and I've said as much publicly. However, your lack of intention to cause a problem doesn't make it *not* a problem, any more than my lack of intention to cause a problem for you made your problems go away. In this case, 0.6c10 is prompted by the need to fix that problem on the setuptools side, without people being forced to go to Distribute. That part's not personal. The part where things got personal, is when you loudly trumpeted everywhere that the problem was setuptools' fault due to monkeypatching, when you knew very well that pywin32 had *exactly* the same problem, and monkeypatching had nothing to do with it. (And what's more, IIUC, you knew this prior to 2.6.3's release, yet AFAICT did nothing about it but blame pywin32 for the problem.) You then created a widespread impression that setuptools was now forcing Python-Dev to make a 2.6.4 release, when in fact it was *your* choice to make an API change in a dot release. And instead of acknowledging it as a mistake, you dug in and insisted that it was all setuptools' fault. As a result of that, you got a number of people who were previously neutral about setuptools (or at least not actively hostile) to turn that way, and stirred up a giant flamewar... in which I found myself already framed as the bad guy *for something you did*, and nobody willing to listen because my pointing out the problem was just "obviously" a personal attack on you. And sure, you may not have consciously or maliciously intended any of these things to happen. Problem is, it doesn't *matter* what you intended, this is still the result you created. A result you could've prevented at any point with a simple, "oops, sorry,", instead of responding to every attempt I made to correct your statements, with further flaming and increasingly personal comments about me. I even asked you to stop it, twice, and you responded by calling me paranoid. Seriously, did you expect me to not take *that* personally? (I mean, if you think someone is actually paranoid, isn't calling them so a way to *guarantee* they won't want to listen to you?) You've previously wondered why I don't think you a suitable maintainer for setuptools; this kind of behavior is the answer. One of the key difference between your behavior and the behavior of the people I *do* consider strong candidates for "maintainer of setuptools", is that those people 1) *know* when they don't know, 2) readily *admit* that they don't know, and 3) when they find that they were wrong, don't waste a lot of time trying to prove that really, they were right all along. 
Will do so. Or at least will try :-)
But isn't that subjective? How do you suggest he should have said it in order to not attract cynical responses?
Here's an instance of hostile exchanges (none of which involves PJE): &gt;&gt;&gt; Sorry, it doesn't look like anyone wants to play with you [PJE] any more; you &gt;&gt;&gt; can just keep your ball. &gt;&gt; Please don't speak for others - it's rude. Only speak for yourself. &gt;And you, stop to think for the others, pointing fingers and throwing mud, &gt; you are the one who is rude right now. 
0.6c10 is a good news indeed. Thanks to PJE for that (several users do not want to switch to distribute yet)! But I believe there will be some competition between setuptools and distribute for the refactored 0.7 release.
Just about all human relations are pretty subjective. This does not in any way decrease the importance of taking into account the probable result of one's actions and statements. You probably wouldn't tell your boss his tie sucked, even though there's a chance that he would entirely appreciate such a comment. Usually what I do is step back, wait a little bit, and then try really hard to pretend I'm the person I'm annoyed at (since he is annoyed, and has [admitted so](http://dirtsimple.org/2009/10/clarification-or-two.html)) and imagine how a statement might come off, and then adjust accordingly. "But before you do that, be sure to uninstall Distribute completely." becomes "Please note that Distribute and setuptools are mutually exclusive applications. This means that in order to use the latest version of setuptools, any existing Distribute installation would need to be uninstalled first." What's changed ? a. we have stated the rationale, even though most people know it, there's no ambiguity as to the motivation behind the next statement. b. we state the need for removal as a fact, conditional on your choice to use the product, rather than as a command. Less pushy. 
Neutral, but still [not quite complete](http://mail.python.org/pipermail/python-dev/2009-October/093009.html).
&gt; Now, I do have to admit that I'm still ignorant of what bug this was trying to fix in the first place. You say it "was needed to get inplace installations working", but I don't know what that means, since AFAIK inplace extension builds (build_ext -i) have been working since before the first versions of setuptools appeared in 2003. Is this [the patch](http://svn.python.org/view/python/branches/release26-maint/Lib/distutils/command/build_ext.py?r1=73955&amp;r2=74732&amp;pathrev=75395) you were referring to?
No, [this one](http://svn.python.org/view?view=rev&amp;revision=73791). It appears from the issue it's linked to, that it's to fix a [problem](http://bugs.python.org/issue6403) that was also introduced in the last four months. The plot thickens. It may be that this was a backported fix for a problem in new code Tarek was adding to 2.7, that was never in 2.6 to begin with. In other words, there seems to be a very strong possibility that there was no legitimate reason to put this code in 2.6 at all. 
awesome. I was just looking for a way to delete one.
Hey, it's PJE. Hi. Thanks for making Setuptools in the first place. It was a hell of a lot better than distutils. If I retract my flippant comment at your code's expense, will you fix the "how to keep an idiot busy" link at http://pypi.python.org/pypi/setuptools, under Downloads, that just points back to the top of the same page? I once had someone get so flustered by that that they gave up on installing my software.
&gt; What's the timeline of events that's led to all this?? See [A neutral explanation of what actually happened with Python 2.6.3 and setuptools](http://www.reddit.com/r/Python/comments/9trad/a_neutral_explanation_of_what_actually_happened/)
&gt; Just out of curiousity, what niche does ActivePython fill? 1. It includes pywin32 and its api docs 2. It includes a binary package manager called [PyPM](http://docs.activestate.com/activepython/2.6/pypm.html) which allows you to install packages from the [ActiveState Python repository](http://pypm.activestate.com) (eg: "pypm install lxml" just works on ActivePython) 3. It includes several extra docs and tutorials (eg: diveintopython) 4. Enterprise support Also see [Why does ActivePython exist?](http://stackoverflow.com/questions/1352528/why-does-activepython-exist)
No, you can either install pywin32 installer separately or better install [ActivePython](http://activestate.com/activepython) that includes it.
[Done](http://svn.python.org/view/sandbox/trunk/setuptools/README.txt?r1=75398&amp;r2=75397&amp;pathrev=75398). (Well, to be precise, it'll be done when 0.6c10 is released.) (Btw, it *does* say to scroll all the way to the bottom.)
By the way, it seems from the log of issue 6403 that it describes an issue that *only* existed in the Python 2.7 trunk... which would mean there was never a reason for it to be backported to 2.6 in the first place! I'm not saying this means it was malicious, I'm saying it sounds like an honest mistake. If you're backporting lots of things, it's easy to accidentally do one more than you're supposed to. But if it *was* a mistake, it would've been nice for Tarek to admit it and back it out, instead of pointing fingers elsewhere. Heck, it would also make more sense for the original "fix" to be backed out, rather than adding lots of additional tests and changes to work around the consequences of the unnecessary fix. Of course, all this is moot if the original problem was indeed in earlier versions of Python. But that's not what issue 6403 actually says.
Check the recent thread on python-dev, and coverage here on reddit; he's strongly insinuating that Tarek deliberately introduced a change in Python 2.6.3 to try to break setuptools and drive users away from it.
From a technological stand point, I don't get the point of Active Python either...but from a business view, having ActiveState available for trouble shooting is part of business risk management. Kind of like the companies that have to have applications use Oracle... they're more so buying the name then the product.
Still no way to have naked url's (without www). Still no simple way to migrate from the google-database to mysql etc.
&gt; Still no simple way to migrate from the google-database to mysql etc. You can [extract](http://code.google.com/appengine/docs/python/tools/uploadingdata.html#Downloading_Data_from_App_Engine) your data. Since MySQL is a relational database, and App Engine's backend isn't, you're probably better off trying to import it into couchdb or something similar.
Come on now. This situation has become such a mess only because you've never accepted your responsibility in regards to the huge reliance some people have now on setuptools. At some point a project goes beyond its creator but you fail at understanding that. You've kept people at bay purely because they weren't nice enough with you. You require patches, that's understable and that's your right but you can't blame folks for finding that in the meantime you fail to show understanding on how important setuptools has become. You keep repeating you won't be pushed into doing what you don't want to do (http://mail.python.org/pipermail/python-dev/2009-October/092737.html) and again that's also your right but you can't expect people to bend over to that choice. Tarek might be the wrong person to maintain setuptools as you see it but at least he is trying to move your project ahead (beside Tarek publicly acknowledges he may not be the right person anyway http://mail.python.org/pipermail/python-dev/2009-October/092587.html). Put a real roadmap in place, act like a real project maintainer, if you don't have the time, accept that the project should live on without you. 
Could you please provide an example? Link to the actual email from PJE that you consider to be "bashing" on Distribute and its developers? The exact words/sentences you were referring to it? Yes, I regularly read python-dev@ and distutils-sig@ and haven't found any bashing/abusing from PJE yet. &gt; UBERNOSTRUM: he's strongly insinuating that Tarek deliberately introduced a change in Python 2.6.3 to try to break setuptools and drive users away from it. For the life of me, I could not see where he implied that Tarek "deliberately" introduced a change in Python 2.6.3 to try to break setuptools and drive users away from it. Maybe you can help in locating the text? FWIW, I found this: &gt; PJE: This isn't intended as a criticism of anybody, mind you; I'm just saying that **I still don't understand why the change was made in 2.6.3 in the first place**, and it would be kind of nice to know.
[This comment](http://www.reddit.com/r/Python/comments/9trad/a_neutral_explanation_of_what_actually_happened/c0eegbn) is an example. There's a weird dynamic going on here, where PJE uses language which seems to imply ulterior motives ("the plot thickens", "no legitimate reason", etc.), then tries to backtrack and shrug it off.
I agree that "the plot thickens" is rather unusual for reporting what would otherwise be a dispassionate factual information. But "no legitimate reason" is perfectly fine (there indeed are no legitimate reasons known *yet* for that change to go in 2.6.3).
Well, if you *really* want to get picky, 6403 is a sub- / related problem to 6365 ( http://bugs.python.org/issue6365 ) per the notes: "Related to #6365. I've added a test ..." Both 6365 and 6403's changes ultimately resulted in setuptools breaking. But the funny thing is, he was actually trying to help you out, PJE. Look at the log on 6365. He wrote a test to see what was going on with the problem, and initially came back with these results: http://bugs.python.org/msg89822 "I figured out the problem after writing the test. This is not a problem on distutils side but on setuptools side. If you remove setuptools from lxml setup.py, it'll work perfectly. [...]" But then he thought about it and 18 minutes later, instead of laying the blame on setuptools, he pulled the comment back and decided the issue must lay somewhere in the order of operation within build_ext. He tried to make build_ext smarter / more error resistant. As this was considered a bugfix, it qualified for "maintenance" on 2.6 and made it into the RC for 2.6.3 ... and since no one caught it (????) it made it to 2.6.3 final. You'll notice 6365 was submitted for py3.1. This was a multi-version bug. The perceived error / problem existed through all of the versions, regardless of which one was initially reported. 
... I'm beginning to wish I'd never asked.
You are going to far Phillip. I have never asked you to maintain your tool. And the flame is not my fault, it's you being AOWL on the maintenance, that's it. Wow, if *you* wasted less time to write FUD in your blog like this : "...I tried to help and participate, and even offered to release the fork as an official version..." I mean, we set everything for it and waited for you. (http://mail.python.org/pipermail/distutils-sig/2009-July/012683.html). but nothing happened. Now you might consider that I wouldn't be a good maintainer, but again, I never asked that. I asked you to open it to *any* maintainer because your AOWL is HARMFULL to us !!! Sorry, but you are the worst maintainer ever. 
"the plot thickens" *sigh* What are you trying to prove now ? The change that broke the way setuptools (and pywin32) uses this API (as MAL explains) shouldn't have made it to Python 2.6.3, we are all agree on that, me first. It's been corrected. 2.6.4 is coming up. And probably I could've fixed the bugs you mentioned differently, and maybe some changes where not appropriate at some point. Let's calm down. peace.
Good point, didn't think about it! But this will only help you with Python and pywin32, I doubt that they support 3rd party modules.
"The plot thickens" is just a literary expression, like "Curiouser and curiouser", or "The game's afoot". It doesn't mean I think anyone's plotting, it means something like "that's odd". I'm not implying you did anything, except dig in your heels when it was described as a problem. MAL's explanation claims that the original change needed to go in 2.6, which doesn't jibe with the notes in the issue.
That's really nice and all, but do remember I'm not accusing Tarek of trying to break setuptools, and that good things don't cancel out bad things. If they did, then the work I've done on setuptools would easily cancel out all the work I've *not* done on setuptools. ;-)
&gt; I mean, we set everything for it and waited for you. And then you said [this](http://mail.python.org/pipermail/distutils-sig/2009-July/012689.html), declaring my help and interest to be "suspicious". If the project had just been Lennart and Hanno, you'd have probably gotten that release from me in a week or two. Meanwhile, I notice you've once again ignored the parts of the issue where *you* are responsible. Do you deny making misrepresentations on Python-Dev? Sure, **now** you say, "oh yes, it was my mistake", but there, you stonewalled, repeating your false accusations about it being setuptools' fault when you already *knew* other code was affected, already *knew* it wasn't about monkeypatching. You may not have created the situation to damage setuptools, but you sure as hell took every advantage of the opportunity once it arose. And you haven't yet withdrawn, retracted, or apologized for any of those false accusations -- certainly not in the fora where you made them in the first place.
Incoming e-mail is pretty great to be integrated all-in-one. By EOD today I'll have "mail image to imgur" rolling.
Quite unfortunate that the dev server mail test page does not allow attachments. Opened enhancement request: http://code.google.com/p/googleappengine/issues/detail?id=2264&amp;q=mail&amp;colspec=ID%20Type%20Status%20Priority%20Stars%20Owner%20Summary%20Log%20Component
This is not well documented yet. Particularly: &gt; attachments is a list of element pairs containing file types and contents. This is not what I am seeing at all. All I get is the 'name.jpg' of the attachment as a string, no data, no file type, etc. Opened issue: http://code.google.com/p/googleappengine/issues/detail?id=2265&amp;q=mail&amp;colspec=ID%20Type%20Status%20Priority%20Stars%20Owner%20Summary%20Log%20Component I'm only getting a real 'list of pairs' when there are multiple attachments. Single attachments end up just 'my.jpg' as strings. Actually it seems to be almost random as to whether the 'attachment' comes as a ('name.jpg',EncodedPayload) pair or just 'name.jpg'. edit: Figured it out. See the issue details if interested.
Well, that was easier than I thought. Try e-mailing attached images (less than 1MB probably) to: upload@myimgur.appspotmail.com edit: tested only with gmail and Lotus Notes sent attachments, which come b64 encoded already. Might break under different assumptions. for code: http://www.reddit.com/r/programming/comments/9tls5/its_about_time_imgur_had_an_api_so_here_it_is_i/c0efdug
&gt; And then you said this, declaring my help and interest to be "suspicious". &gt; If the project had just been Lennart and Hanno, you'd have probably &gt; gotten that release from me in a week or two. While we were discussing a new tool in Distribute 0.7, you came up with another one called "Discovery", and explained how **you** would organize it in various "discovery" packages. You said you were "willing" to let us maintain 0.6 while *you* could have fun on your side building a new tool. Remember ? So yes, it's suspicious, when we are trying to work on an open tool, because we've suffered from the lack of maintenance in setuptools and the fact that it is locked. If you had joined us to work on the new ideas instead of proposing yet another thing, I wouldn't have reacted like that. Because it didn't look to me like help for us, but rather that a new project of yours. Maybe I was wrong ? tell me. Was it a new project where *we* could participate, commit ? If so. Sorry. Now, If you want to join the Distribute momentum, and work with us in the same code base for 0.7, *that* would be awesome and that would be the best for the community imho. 
&gt; You said you were "willing" to let us maintain 0.6 while you could have fun on your side building a new tool. Remember ? Indeed - that was the one *positive* thing your fork had to offer me. Without it, there was nothing to interest me further. Speaking of which, I notice you still haven't responded to the only thing that's of interest to me now. When you smear someone else as being responsible for something that was your error, and it's pointed out to you, the proper thing to do is to retract your statements and apologize. You shouldn't even need to be *asked*. But I told you more than once on Python-Dev that your statements were smearing me and setuptools, and you did (and have done) absolutely zero about it, except to call me paranoid. You have dodged this issue every time it comes up.
Package management: serious business.
Oh BTW, pje just [responded](http://www.reddit.com/r/Python/comments/9trad/a_neutral_explanation_of_what_actually_happened/c0ef4bw) in that thread. I did not know that it was an idiom. Then, it does not seem as unusual as I had thought. [plot thickens, the](http://dictionary.reference.com/browse/plot+thickens,+the): &gt; Circumstances are becoming very complex or mysterious. Today this term is often used ironically or half-humorously, as in *His companion wasn't his wife or his partner ... the plot thickens*. Originally (1671) it described the plot of a play that was overly intricate, and by the late 1800s it was used for increasingly complex mysteries in detective stories.
Yeah, I imagine ActiveState's response would be "Sure we'll help you debug your problem for 2-3x the rate your billing your client" :)
yay!
&gt; You have dodged this issue every time it comes up. Exactly as you've done too. My gosh you both need a therapy on that subject. This is really pathetic. So many people have called your inefficiency out to maintain correctly setuptool and you merely respond with a "I do what I want". This is really convenient but not professional in my book. To me, you misplace self-aware with self-sufficient.
If you really want to put the *function* form01 into the the file form01.py, you would do this: from prj.views.form01 import form01 from prj.views.form02 import form02 But you shouldn't but each function into a separate file. Group them together.
What you're wanting to do is probably a bad idea. However, if you really want to do it, then go into __init__.py and use the from blah.blah import form01 syntax.
To clarify: Inside \_\_init\_\_.py: from form01 import form01 from form02 import form02 Then in your main .py you can use: import prj.views foo = prj.views.form01()
I am assuming you have a reason you want to do this. To achieve this, in your __init__.py file: from form01 import form01 from form02 import form02
&gt;What you're wanting to do is probably a bad idea. Why is that? I can see this is how it's done in python. I (from for instance php) find it a lot easier to have things in separate files. When everything is in one big file it becomes problematic and time consuming to edit. How do people deal with many functions in very large files?
I know your suggestion would work but I would like to use the simple way of loading when they're in one file but keeping them in separate files. Now @kikaerter says what I want is probably a bad idea.
I can see that would work but I thought that there would be a way to have the name of the file 'automagically' being the name of the function/method and so being able to load them as if they were in one file. My reason is to have the same ease of editing that I'm used to from php (i.e. each function in its own file). I find it rather cumbersome to have everything in one big file. But that's probably because there is a 'python-way' of editing that i don't know yet.
I usually have a medium number of classes/functions/whatever per module. One per module means that every time anything is used, it has to be added to the big import list at the top of the module. It's about finding the happy medium and (if it's not just a personal project) following community conventions so that others can maintain your code.
You might also want to consider Pylons. 
How it's done in python is that there is a file called prj/views.py which contains form01 and form02 methods/classes/whatever, and you use them that way. It's not very usual (or wise) to put each function in its own file...
&gt;following community conventions so that others can maintain your code I agree completely. I'm not out to reinvent or force a style from another language. I simply want it to be as easy as possible - if that means learning/getting used to something new that's fine with me. If what I want is complicating things or 'not done' I won't do it. This is a personal project - I'm not a programmer but I regularly need to glue various things together. I'm moving away from php as there seems to be so many libraries in python that are better for my purposes. And python in most cases is much faster. I need/want the web interface because it makes it possible to give others access to the functionality without having them deal with all my idiosyncrasies and unfinished coding.
I've slung over 1M lines of C code, and I didn't know how to burn a CD until last year. Didn't need to know. Didn't care. (Not a big listener of tunes when I code; and daemon tools + ISO images had been more than up to the task.) Turned out the fucking capability was built in. Who woulda thunk. Anyway, burned one, and now have promptly forgotten how to do it. Again: don't care, and Google is still out there. Net-net: (A) your point about initiative and Google is valid; (B) I wouldn't make a cross-skill inference (CD Burning / CS Major) such as that one to support (A). 
What about stopping this and joining forces ? building yet another tool on your side is not the best idea imho. http://mail.python.org/pipermail/distutils-sig/2009-October/013941.html 
Take a look at: [6.4.1. Importing * From a Package](http://docs.python.org/tutorial/modules.html#importing-from-a-package)
&gt; I can see that would work but I thought that there would be a way to have the name of the file 'automagically' being the name of the function/method and so being able to load them as if they were in one file. No. It's dumb, and magic is bad. &gt; My reason is to have the same ease of editing that I'm used to from php (i.e. each function in its own file) Me thinks your functions are far too long if you need to do that. My functions (or methods) rarely go beyond 10~20 lines (note: rarely, not never). Having each of them in its own file would drive me utterly insane.
There's no reason to dump everything in 'one big file', but neither is there a reason to just separate every function off into a separate file. Python programmers tend to follow convention of logic block segmentation, where any block that seemingly belongs together is kept as close together as possible. If something becomes too unwieldy that's generally a sign you want to split things off. You can work some import namespace magic via the __init__.py file inside a directory, but that will mean even more administrative overhead.
But pay attention to the fact that this often leads to unreadable code since you might be overshadowing the functions/methods defined in the current file.
Remember that functions and methods are different things in python. With functions, you're just going to use your __ init __.py file to pull stuff from other files into the current file. For methods, which are functions attached to classes, it's not quite so simple, but still possible. Imagine you want to define a class C that has a method m. And you want to define your class C in one file and your method m in another file. Just import the method m first and then assign it to your class like this: # m1.py def m(self, x): return x * x # c.py from m1 import m1 class C(object): m = m1 
It was more an indication of his general computer knowledge, the guy didn't really know how to use a computer, yet was a CS major.
&gt;Having each of them in its own file would drive me utterly insane. I'm getting the picture from the answers here ;) I haven't done much python coding but I have one little project consisting of one file which contains around 25 - 30 functions. Only one expands beyond one screen. Still I find it a pain to scroll up and down when editing and making sure things in one function fits to things in other functions. But that's likely stemming from my trying to apply a foreign coding scheme.
&gt;Your approach seems a bit tedious to me Ok, everybody seems to agree with you. I'm apparently on the wrong track. I'll just have to learn the python way. Thanks
Thanks
&gt; Still I find it a pain to scroll up and down when editing and making sure things in one function fits to things in other functions. And you find it better to swap to a different file? I find that pretty weird, especially since most editors should let you easily jump from one function to another (or just incrementally search, works too). Python modules tend to "logically" group stuff (including functions) it's rare to have whole modules for a single function or class.
Warning: don't do that. Ever. `from a import *` is not good because it makes a mess out of your local namespace, prefer explicit imports (`from a import b, c, d`) or qualified imports (`import a`)
You're just not listening, are you?
Could you please stay on topic? How can the conclusion to an article on python be *the war between the wealth effect and the income effect is one of the areas of economics that really does explain our behavior pretty dang well... so go read about it.* How about you go read about some mathematics? Like the definition of a function. There's not a hard and fast reason not to import within functions. Except it doesn't even solve the problem you're having. Assuming you don't run into resource problems, the behavior of your function does not depend on the temporary file. The only real missing parameter is what the user types into vi, but you're not even concerned with this.
If you separate out into the normal models.py, forms.py, views.py, etc. and you're finding you have "very large files" you're doing something wrong. Most likely you are building a monolithic application and not small re-usable apps, which is a Django "best practice". Each app in your project should do only one thing, and do it well. Most sites end up with 10-30 "apps" that are all small individually. 
I don't want to be mean, but what was the point of this?
&gt; How do people deal with many functions in very large files? Ctrl+F `function name`, *or* alternatively use your IDE / editor keybinding to sequentially jump to the next function definition line. Faster than jumping from file to file and visually having to check whether the file you are "on" is the file that contains your function.
It's not always that black and white. After building monolithic Django sites myself, I've found sometimes there's not way to get around the huge ass glue-app.
I have a medium sized Django application running and from my experience, it is best to categorize the views and split them up into modules accordingly. That means, do not put all views of a project into views.py, but also do not put every method into its own file. The "work overhead" of importing the public stuff in __init__.py is worth it. Code is better structured and more maintainable that way.
No I am not listening anymore to your explanations about what happened. Everyone understood now what happened. I was even about to write a blog entry with apologies for you and your users for the part I was responsible about, but by reading python-dev again, and reddit, I saw that it was said and clear. Now your are free to write in your blog whatever you want I don't care. What matters to me is the future of packaging. And I'll be happy if you join us. 
&gt;I've found sometimes there's not way to get around the huge ass glue-app. Of course, composing several apps into one uses those several apps. But then only the huge ass-glue app is project specific. The apps that actually do something shouldn't be excruciatingly promiscuous and only need minor touching up to be reused.
A piece of advice from a former Java/PHP guy who tried to go down this road.. Don't try to fight python conventions. They are there for a reason and if you find yourself trying to change python into PHP the first thing you should ask yourself is "is there a pythonic way to do this". Once you start thinking about a problem with python's features in mind you start to see why things are set up the way they are. The only problem after that is being forced to go back to PHP ;)
Thanks, I tried your suggestion but couldn't make it work (see the edit in my initial comment-text)
Thanks, I tried your suggestion but couldn't make it work (see the edit in my initial comment-text)
Misreading that as "pypy-j-clit" was amusing.
It looks like you want m1 to look into the global namespace when it gets called and at that time, find the p1 you're importing. Try adding these two lines: print(id(globals())) print('p1' in globals()) right before you call m1 and then while you're inside your m1 function. Notice that the globals dictionary available to m1 IS NOT the same globals dictionary available at the top level; they have different id values. Also see how 'p1' is available in globals() outside your function, but not inside.
&gt;Don't try to fight python conventions. That's exactly my thinking - just don't know them and especially the reasons yet.
There's nothing wrong with dividing up code into lots of files, just like there's nothing really wrong with using 24 spaces for a tab. It's just nonstandard, but if you want to do it, go for it. It's a free country. Eventually, if you keep doing this, you'll write two files that import code from each other, and stuff won't work. But there's a way around that too, and you'll figure it out.
_hm._ The only thing I can think of is opening a file type socket in /dev/ and reading/writing with it in your Python app.
Thanks! True p1 is there in the top level but not inside m1.py. Isn't it possible to have __ init __ do the same as if you have it all in one file and import everything at the top?
&gt; This works fine for p() but gives an error for m() &gt; &gt; NameError: name 'p' is not defined No, that's an error for 'p' :P Try this in run_test.py: import mod mod.p(2) mod.m(2) Or alternatively: from mod import p from mod import m You're setting up your package properly, you're just not getting that last import into your run_test.py right. 
&gt;importing the public stuff in init.py I haven't been able to make it work yet but it's encouraging to know that it's doable.
When organizing code, I find it easiest to understand if it's organized by areas of related functionality and not by component type. That's to say, you don't have to have every view in a 'views.py' and every model in a 'models.py'. Instead, have a module named 'books' with a model for the book, and any views that are specific to that model inside the same module. This is the same advice as given by splitting your application into "reusable apps", where each app name is the distinguisher for a collections of views and models. Each reusable app may still decide to have sub-modules named views and models (I find this overly verbose, but it's fairly common style in Djanog applications), but that's not as an important detail as much as your overall organization splits certain models and views into different packages. 
&gt;And you find it better to swap to a different file? Mostly yes, though sometimes if they are closely related I prefer them in the same file. I beginning to realize that this approach is not going to make my life easier in python.
&gt;No, that's an error for 'p' :P Yes but the one inside m, 'p' is not available inside m() even if it's imported in __ init __.py
No, it's not possible. And that's OK -- the fact that functions keep reference to what was global when they were made, not what is global now, can be exploited to do some fancy tricks. There is a solution to your immediate goal. In your m1.py file, import p1 at the top. Then everything will work fine.
could you do something like this with FUSE? http://fuse.sourceforge.net/ they have a python api
I tried but for some reason, i couldn't manage to make it work. I open a file (mounted with FUSE) and select on read event. When the file descriptor becomes ready for reading, i make a read call and it doesn't return anything. FUSE was probably not meant to be used in that way. 
&gt;In your m1.py file, import p1 at the top. I know, that's what I set out to avoid in the first place. I now know I have some way to go before straying off. I'm looking forward to the struggle ;)
Block device or character device? 
character device
http://lwn.net/Articles/308445/ maybe Or named pipes, or couple of other options.
Penis penis penis
Without a comparison to good old cpython this is pretty much useless.
The ActivePython distribution is basically just regular python with a lot of useful auxiliary packaged tacked on. It saves the trouble of downloading them all individually and installing them, and I tend to find that whenever I need something, it's already there - which is nice :)
Try: print mod.p print mod.m
[Earlier](http://morepypy.blogspot.com/2009/09/first-results-of-jit.html "On a specific benchmark.")
Couldn't he use the same style as other python docs, this one's an eyesore.
How is a comparison to CPython relevant when the measurements are about the version of PyPy compiled to .NET (pypy-cli-jit)? We had earlier blog posts where we compiled PyPy to C and compared it to CPython.
Super excited about adding the python reddit to my feeds and coming across this gem on my first read! :D :D :D 
I just installed jpeg7 and PIL on my Tiger box last weekend. Didn't work. I did not specify the "static" option in jpeg7. Also, when I built PIL, I just added the library location as a string, not as an argument to "libinclude". Is there some documentation I missed? Do I need to uninstall in order to try this again?
Tarek's a reddit user (`tarekziade`) you might want to feed him back.
Thanks for the feedback, I am pushing it to jezdez, who added the command + theme. edit: I really like this theme personnaly
Hey, thanks for the feedback. Given the fact distribute is not part of the stdlib it's good to have the visual distinction. If you have any suggestions, please feel free to open an issue in the theme author's bug tracker: http://github.com/bartTC/sphinx-schemes/issues.
Me too. This theme looks nice. But I'd prefer that you add this Sphinx site to http://python-distribute.org :-) like sphinx.pocoo.org
This submission seems infinitely pointless.
I did, then I removed it because http://package.python.org/distribute is the one that gets automatically updated on releases (thanks to jezdez command). So I didn't want to have it in two places. Suggestions are welcome for what http://python-distribute.org should contain though.
On the contrary, it seems perfectly topical. My next submission will be my VCR manual.
Just what we need: #python written down.
Short list. With the exception of the "Zen", I'm not sure I agree with the rest of it. Go ahead and use Python3 *now* for new projects, with the understanding that not all 3rd party libraries have been ported. And Twisted is ok, but... I applaud the website creator for attempting to provide good &amp; useful python programming information, but I don't think this is filling the need in the way they hope it would.
# p y t h o n I dunno, that doesn't seem so bad.
&gt; Suggestions are welcome for what http://python-distribute.org should contain though. Something like www.buildout.org would be nice.
Yeah that's nice, thx for the pointer. I don't have the time right now for that task, I'll see if someone is interested in that. 
You have to understand that this is just #python dogma.
wtf?
+1, that site might as well have solely consisted of: python -c "import this"
Completely agree. I for one enjoy the distinction.
I think that theme could use a bit of tweaking to make the design a little bit cleaner, which should enhance readability (maybe I'm just biased against headers with solid-fill color backrounds tho' ...). I took a quick go at it, and published a change here: http://bitbucket.org/wheat/distribute/changeset/aea5f589ba0d/ Which looks like this: http://bud.ca/files/distribute-theme1/ 
Wow. Just don't leave debug mode on.
I'm sorry we forgot to send you the memo.
I'll inform the vice president.
You should watch this then, as well: http://ericholscher.com/blog/2008/sep/12/screencast-django-command-extensions/
Pylons does this too, it's pretty damned useful
And Plone, and Paste, and... Edit: Yes, it is damn useful. 
&gt; and Paste Since Pylons is built on paste, I suspect this is where it gets it
I told you about it last week. You don't even remember it, do you? You never listen to me any more.
my fave things about django-extensions: * ipython shell integration is really convenient (python manage.py shell_plus). it automatically loads your models! * the inline debugger is awesome, of course * CreationDateTimeField &amp; ModificationDateTimeField model fields btw, the project is now on github: http://github.com/django-extensions/django-extensions
looks nicer/cleaner
It uses Werkzeug (soon to be spun of into Flickzeug), and there was a Django ticket to integrate it into the normal Django debugger, but the devs were concerned about security issues.
Just my opinion - the header and footer colors are too saturated/bright but the rest of the theme looks very good.
+1
I did: alias dshell='./manage.py shell_plus' 
You have to run it with runserver_plus, it doesn't just get enabled in normal situations (I hope).
&gt; Man, if we were making Ruby faster, this would be so much easier. Hah.
no no no i think you meant to say *touché* edit: changed touchè to touché 
Link is dog slow here.
[Info page](http://llvm.org/devmtg/2009-10/) [Slides:PDFWARN](http://llvm.org/devmtg/2009-10/Winter_UnladenSwallowLLVM.pdf) and the info page has a link for mobile video too.
It's touch*é* actually. *Touchè* doesn't exist.
I'm downvoting this with a bit of a moral quandry. While the Python programming language was named after the comedy troupe, I don't believe this belongs here.
Security issues honestly make sense. There are idiots who use the dev server in production, and in that scenario this does open up a slew of potential security issues. Django devs can warn all they want, but someone will be stupid, and Django could catch negative press for it. At least that's my assumption. Personally, I say they include it, and we just lobotomize anyone that doesn't heed the warnings. 
Why would you directly link to a 125MB video file? Pretty annoying when you just want to see what the link is about. You couldn't just link to the main page?: http://llvm.org/devmtg/2009-10/
new question, that I probably should have asked 8 months ago. Why was the print statement removed?
It's even more annoying when you don't have quicktime installed and the VLC firefox plugin is **completely fucking useless**. edit: Actually, it's worse than useless. If it wasn't for the plugin, firefox would just offer to save the file. Instead, I just get a black tab with "Waiting for video".
crap, and my boss just made me switch to IDL.
Ouch, I feel for you.
Umm, this won't even start for me.
Try launching the `spyder.pyw` script manually (assuming you're in Windows).
its brilliant. Used SPE and geany, which are very good IDE's, but this blows them away. I also love the name.
 Explain manually?
Run `python spyder.pyw` from a command prompt in your `Python\Scripts\` folder. If there are any errors they'll also show up.
How does this compare to [Sage](http://www.sagemath.org/)?
This is also strangely necessary in linux (ubuntu anyway)
Like emacs compares to a wireless router.
So you're saying Spyder:Sage :: emacs:a wireless router? I'll stick with Sage then -- I hate emacs and I love my router!
Hah, fair enough. [Sage](http://sagemath.org) is awesome and should be plugged as often as possible. However, [Sage](http://sagemath.org) is a python based mathematics package, and spyder is a tool to help you write [Sage](http://sagemath.org) (and other python) scripts.
"available for Windows XP/Vista/7, GNU/Linux and MacOS X." I cant see .dmg link, Anyone???
ok i had to figure this out, first I had to install PyQT as documented here &gt; http://www.oak-tree.us/blog/index.php/2009/05/12/pyqt-mac Plus:- ----------- Install QScintilla: For the QScintilla downloadlink look here: http://www.riverbankcomputing.co.uk/software/qscintilla/download. ftp http://www.riverbankcomputing.co.uk/static/Downloads/QScintilla2/QScintilla-gpl-2.4.tar.gz tar -xvzpf QScintilla2/QScintilla-gpl-2.4.tar.gz cd QScintilla2/QScintilla-gpl-2.4 cd Qt4 qmake qscintilla.pro -spec macx-g++ make sudo make install Now make the Qsci module: cd ../python python configure.py make sudo make install ----------- Then I had to install Spyder as documented at original site. i.e: sudo python setup.py install . Hope this helps other OSx86 users (hackintosh FTW). Pic or it didnt happen ? http://imgur.com/JjIRr.png Edit: wrote install step for Qsci Module. 
Been using this since it was called 'pydee', and its probably the best python IDE I've used aside from PyDev.
It looks like it requires PyQt4 &amp; SIP. Neither of which i have; i found the source for qt4, but i guess i really just want a windows installer to put that in the right place. Any thoughts? 
http://www.riverbankcomputing.co.uk/software/pyqt/download Under Binary Packages, contains PyQt4 and Scintilla (some other stuff too). I don't think it requires SIP though, as I don't have that and I'm running it fine.
I came here to recommend pydee, didn't realise it was the same thing. I feel stupid now.
Nice free alternative, although I couldn't imagine switching from Wing IDE. Easy debugging django applications, source inspection, Vim style key bindings. Doesn't get better than that.
jeez i totally misread their naming convention - thanks
Read through a pile of text but no code example to be found. Wtf's new?
Why is your boss telling you what IDE to use?
Touché
No Snow Leopard yet? ;)
Nope. And my suspicious were proven true with all those bug reports regarding SL. I might think of Loading 10.6.2 though :), right now , everything is running butter-smooth for bout a year.
I feel stupid, but how do I do completion? I expected 'tab' to work, but it doesn't. I'm on OS X.
I got it working under Leopard too, but it took a lot more fooling around than I had hoped. Also, mine crashes if I try to plot anything...does yours?
yes, complete dock and menu-bar crash, not worth running on OSX atm it seems.
I'm not really seeing what is so "Matlab-like" about Spyder. Yes, Spyder is a very nice IDE, but Matlab (whether you think it is "awesome" or not) is MUCH more than an IDE.
[IDL is not an IDE.](http://www.dartmouth.edu/comp/support/library/research/software/graphics/idl.html) 
Excellent video. I like the part where he shows the LLVM bytecode of a naive translation of a Python function that adds two numbers.
your **é** is wrong
what is wrong with Eclipse? it is a powerful, mature, free and open-source IDE. and the python support is awesome.
Do you want to code all the protocol stuff yourself, or use a library? For the latter, [Twisted](http://twistedmatrix.com/trac/) is pretty good. Years ago I used it to write an IRC bot which is still going strong.
if you're gonna make a gui, go with PyQt
django + mod\_wsgi
If you want to talk over Google (Gtalk) then you'll need to use the [xmppy](http://xmpppy.sourceforge.net/) package. XMPP is the protocol that Google Talk uses.
I've heard twisted is good as well, but I've never used it myself. You might want to check out the generic sockets module. Just google python and sockets and you'll get a wealth of information.
I like library version first. I'm not a programmer, nor a network guy, so just using that would be the easiest. 
Why did you get downvoted? Isn't PyQT the way to go for a gooey?
don't ask me, ask the invisible down voting machine
While I didn't downvote, wxPython is also quite nice to work with :).
For learning, you might want to start with [asynchat](http://docs.python.org/library/asynchat.html). It's part of the standard library, and is basically a very limited subset of Twisted. You can use it to build a rudimentary line-based chat system.
It is a powerful, slow, buggy, free, overkill, and open source IDE.
You could use [telepathy](http://telepathy.freedesktop.org/wiki/Telepathy%20Python). It's the same protocol used in Empathy, which is going to be the default chat client for Ubuntu 9.10.
If you want the chat in python (js client and python serverside) you can look into the chat in the [web2py kpax cms](http://www.web2py.com/appliances/default/show/37). [Here is a video](http://www.vimeo.com/1098656) about it. The chat is contained in a single controller called chats.py that supports multiple concurrent chats and privacy. You need web2py to install the app and run it. For a high traffic chat you may want to consider using one of the existing chat services (like the irc) and just create a web interface to that.
How about PySide?
IRC is very very easy protocol to remember. I can remember that protocol by head.
&gt; It's also not completely pythonic in terms of capitalisation, naming etc. Hogwash. From PEP 8, Style Guide for Python Code: New modules and packages (including third party frameworks) should be written to these standards, but where an existing library has a different style, internal consistency is preferred. Qt is an "existing library", so PyQt does the pythonic thing by not messing with the names of the Qt classes and members. 
gajim is a jabber client written in python (and pygtk) you may be interested to have a look. But if you're starting from scratch I would also recommand pyside or PyQt.
Yah, xmppy is yer best bet, nice skill to have if wave ever takes off. Maybe look at wxPython for gui, if you want to write native looking apps. Maybe QT has this now, I haven't written a native gui app with an open library for some time.
WxPython is well-supported and multi-platform.
If you're developing a Sugar activity, use Telepathy. It's built into the Sugar stack and provides all you need to do gtalk/Jabber out of the box. Look at the Chat activity, it is already a Jabber client, just a bit restricted to work mainly on the schoolserver jabber server rather than public servers with buddy lists.
&gt;It's not that bad really, if someone suggested tkinter, I'm sure they would be -103 by now. Since no-one else has mentioned, I just thought I'd point this out: use *anything* over Tkinter.
This suggestion sounds great. However, i was thinking something for personal use, and significantly smaller scale. I don't want to create a webapp cause the OLPC can't really support javascript, and because i'd like it to be a client written in python. I'm not planning on unleashing this to the public or anything along those lines. 
you can probably use it for coding Sage scripts. Remember: you have to be inside the "sage environment" so that all modules are accessible and Sage's python is used. "./sage -sh", then install spyder, then from there do "from sage.all import *" and you are automatically using Sage's python...
In all seriousness: why? Just because it's ugly? I've done a lot of Tkinter programming and a little bit (alright, *very* little) PyGTK programming, and I found Tkinter nice enough to work with from an API point of view. There are a few oddities to get used to, but I don't think it's much worse than any other GUI system (or, say, CSS). Tkinter has the massive bonus of working out of the box anywhere Python does. In particular, if you take the time to learn the Tix stuff (which is in Python 2.6 and 3.0 from memory) you'll find some powerful "new" widgets, like Notebooks and PanedFrames (or something like that?), which make it possible to build just about any GUI a sane person would want to.
Not yet ready for prime time. On many systems it doesn't even compile, due to boost::python.
..by *heart*, but yes, the IRC protocol is quite easy to play with.
No. Going by this logic, lxml wouldn't be pythonic, since it does not expose the libxml2/libxslt names. And I wouldn't consider Qt as an existing library from the Python POV, since it is not a library that can be used from Python, but requires a wrapper and that wrapper could as well conform to the PEP8 naming guidelines.
Where do I start... Well sure, it's ugly. It's also slow, doesn't play nice with IDLE and isn't documented properly anywhere. But most of all, the general style of writing Tkinter applications doesn't sit well with me, especially the layout stuff.
So i struggled with this a little bit, only becasue i don't want to be pidgeon-holed into writing an Activity. I think that learning how to create my own app from scratch will help me as i try to modify the Chat activity in the future. But perhaps i can look at their source there to get a good idea of how to implement things. I like the structure of the Chat activity, but jeez is it limited. 
I use my package management system to do this. On OS X, macports. On CentOS, yum. Honestly, if it's not in the packager, I tend to not use it once it has too many dependencies.
I use MacPorts for this. It'll take a couple of hours to compile the qt4-mac package, but it's worth it.
&gt;from sage.all import * Isn't it normally considered bad practice to import * ?
Unfortunately, MacPorts seems to be the way to go -- but last I checked they don't seem to have a complete selection of 2.6 modules :-/ Well anyway, 2.5 is good enough, but in any case make sure you put export PYTHON=/opt/local/bin/python2.5 in your ~/.bashrc if you want to use that by default (you might have to change your hash bangs too; idkatm). You can also easy_install from PyPI to a particular installation by doing /opt/local/bin/python2.x -m easy\_install package\_name (EDIT: how to do underscores?)
I like CPAN for perl. I find Python is lacking something like it.
Use virtualenv and script up the set of easy___install commands you need to build your virtualenv. Every so often, nuke the virtualenv and re-run the easy_install commands. It's not pretty, but it works. Unless you're doing bleeding edge development on one of these libraries or testing against a specific version, you probably don't want to be updating constantly. It's just not worth the pain unless you know there's something you need or are missing.
Me, too, uses [virtualenv](http://pypi.python.org/pypi/virtualenv), but instead of easy_install, I think [pip](http://pip.openplans.org/) is much better choice. The best thing in pip is that you can write a requirement file in a format of: Twisted Pylons&gt;0.9.6 Jinja2 http://www.mindrot.org/files/py-bcrypt/py-bcrypt-0.1.tar.gz#egg=py-bcrypt and run pip install -E virtualenv_dir/ -r requirements.txt to get everything working again in the nuked virtualenv. ;)
I'd debated mentioning pip, but didn't want to have to explain it. This is probably the absolute best way to do it. I seem to recall there's a couple oddities (but I forget the details as I last played with it about a month ago) about pip when working with virtualenvs, but it's still a pretty great tool. 
For small stuff, I like virtualenv and pip, but if it's a bigger project, I always use zc.buildout. While it has a bit more learning curve (it's from the Zope people!), it does give you a nice combination of being able to run "buildout" and have EVERYTHING come together. This includes even integrating with building databases and non-Python components.
easy_install is similar.
Fuse is the wrong layer (device-opens don't go through it.) [fusd](http://www.circlemud.org/~jelson/software/fusd/) **is** the right layer, but hasn't been touched since 2003, apparently... 
IDL seems like matlab. doing large programs in it seems like an afterthought, and the engineers insist that is what I use, since it is what they use and are used to. Also, it cannot create standalone applications, and requires you to register on the IDL website to download the VM to run the binaries. I really hate programming in this language.
Not quite.
Try the mplayer plugin, it actually works.
The biggest being the lack of .egg support. Since it builds from source... things get interesting. Take ReportLab (please!).
What, you trying to outdo the Brits' innate ability for understatement? I agree, from what I've seen of CPAN it's quite different. Nearer to buildout&amp;pip, not easy_install. Does it manage multiple versions of the same module?
Is there a Windows version of the plugin? (I looked, but none of the packages mention it.)
Try one of these here: http://www.mplayerhq.hu/design7/projects.html#browser_plugins
There is a request to move it over to Flickzeug instead, just because the requirements are more confined there. Glad everyone likes it.
i'm in 10.6, and use macports: sudo port install py26-pil that was it. works great.
In order: * Unix-only * 404 * Doesn't seem to have a working Windows version (certainly no binaries) * Linux-only * Not really any better than just clicking "Save as" * Ditto * GNOME-only Thanks for trying to help though.
I'd love to say I use virtualenv for it all but there a number of things that are git cloned, svn co'd, etc that are all symlinked to the proper place on the path. Then when i want to update something, i just update the item in my checkout folder.
The [tabular](http://www.parsemydata.com/tabular/) module is the closest thing to R's data.frames that I've found...
&gt; If you come from c++ or a similar background, you are probably well versed in object oriented concepts, specifically, constructors and destructors. Destructors are not an object-oriented concept. It's a C++ concept. Period. And, frankly, so are constructors. People need to get the idea that `__init__` is a constructors out of their stupid brains, `__init__` is an initializer, it sets up an instance, it doesn't *construct* anything. Furthermore it's a perfectly normal method, its usage as an instance initializer is nothing more than a Python convention, it's not hardcoded in the language as a C++ constructor is. From that, the article could only go down, and down it went indeed. Shit's worthless.
thats why we pass in *self* to \__init\__ the object has already been constructed
Yes, but `__new__` actually _is_ a constructor. That's why it's basically only used in immutable classes.
Yes, `__new__` is indeed the constructor. It's not "basically only used in immutable classes" though, it's "basically used when you need to alter actual construction" (of which immutable classes are only a common case), which is overall pretty rare. It's also a pretty complex piece of machinery (compared to the simplicity of `__init__`) so you don't fuck with it when you don't need to, people tend to rely on simpler factory methods instead of manipulating `__new__`. Still, `__new__` is pretty cool if you want to manage e.g. instance memoization.
"its usage as an instance initializer is nothing more than a Python convention, it's not hardcoded in the language" Well, the convention that it is called for object initialisation *is* hardcoded in the language. It isn't just a normal method in terms of the way it is used - it is a protocol method typically called for you by the interpreter. Try returning something other than None from it. The only time \_\_init\_\_ won't be called on class instantiation is when \_\_new\_\_ returns something that isn't a subclass of the class being instantiated (or \_\_new\_\_ raises an exception).
And I disagree that the article is "worthless". The fact that \_\_del\_\_ is called even if \_\_init\_\_ fails will be news to many Python programmers.
But much more to read. Perhaps there's a place for both? The brief "Uninstall Distribute because it lives in the same namespace and will destroy all life" in a step-by-step, and the clarification as an addendum? If you have something important to say, it's important to say it succinctly and prominently.
Cool. Does this use the existing Python 2.6 installed with Snow Leopard, or does it install all of Python 2.6 from scratch?
I don't think someone should be placed under obligations of professionalism on a personal side-project. Assuming that the proper disclaimers were made and the project wasn't misrepresented as well-backed, I don't see a problem. People chose to use setuptools with the understanding that it was a volunteer free-time project and there were no contracts or obligations otherwise. When you choose to use such a project, you choose to accept the outcome that the maintainer will lose interest or update sporadically. That is your decision and the blame does not rest on the product's creator.
&gt; `__init__` is an initializer, it sets up an instance, it doesn't construct anything. It might be news to you, but neither does C++ constructor. It does not allocate memory, it only initializes it. What's even funnier, there is a way to do custom memory allocation as well, by overloading `new` operator. Just like in Python you can overload `__new__`. And of course destructors do not free memory, `operator delete` does. There is no corresponding thing in Python, `__del__` corresponds directly to destructor. So Python `__init__` and `__del__` methods do exactly what C++ constructors and destructors do, and I dare say it is somewhat related to OOP. But not only you were completely wrong with your initial premise and then made things even worse with silly insults, but your last statement beats even that. `__init__` is not "just a convention". You have it confused with `self`, which is. I do not need to call `__init__` myself, while if I were to name it `my_cool_init` I'd have to call it explicitly. The name **is hardcoded** into Python. And it is hardcoded in exactly the same way as C++ constructors are, which too are just methods and you can even try and call one manually.
&gt; Well, the convention that it is called for object initialisation is hardcoded in the language. Nope, you just have to customize `__new__` and blamo `__init__` isn't called anymore. It's just a default impl, nothing more.
&gt; The name is hardcoded into Python. And it is hardcoded in exactly the same way as C++ constructors are Can you redefine the `new` operator to not call the C++ constructor? And maybe call your own init instead?
&gt; The fact that `__del__` is called even if `__init__` fails will be news to many Python programmers. But why would they infer that in the first place? There's no relation between them, and as far as I can tell the documentation for the `__del__` method quite clearly says `__del__` is called when the instance is about to be destroyed. By the time `__init__` is reached, the instance has long been created, so why wouldn't it be destroyed? Furthermore the conclusion of the article is that you should avoid using `__del__` unless you really really need it? I've yet to see any other conclusion to any discussion of `__del__`, the spec even has two huge note boxes, one of them with a red background, to warn about the issues and weirdness of `__del__`. And I think (or hope anyway) the CPython's GC issues when `__del__` is involved are well known.
Somewhat irritatingly, while you can redefine \_\_new\_\_ in Python, you can't avoid calling \_\_init\_\_... it's magically called after \_\_new\_\_ returns, no matter what you do inside \_\_new\_\_, as long as \_\_new\_\_ returns an instance of the class it's a constructor for... class Test(object): def __new__(cls,value): print "new",cls,value if value == 1: print "shortcircuit" return 1 self = object.__new__(cls,value) print "created",self return self def __init__(self,value): print "init",value &gt;&gt;&gt; a = Test(0) #init is always called after new new &lt;class '__main__.Test'&gt; 0 created &lt;__main__.Test object 0x72837123&gt; init &lt;__main__.Test object 0x72837123&gt; 0 &gt;&gt;&gt; b = Test(1) #whereas if we return 1, __init__ is not called new &lt;class '__main__.Test'&gt; 1 shortcircuit EDIT: I should also point out that if \_\_new\_\_ returns an already-created instance of cls (say cached somewhere), \_\_init\_\_ will *still* be called (a second time) when \_\_new\_\_ returns the value.
Only if `YourClass.__new__` returns something other than a `YourClass` instance. If it returns a `YourClass` instance, then `__init__` still gets called. So basically, you can either act like a factory function and return something else, or `__init__` gets called.
Do an IRC client. You can just use sockets and you will learn networking at the same time.
Naturally, `__del__` is called when you `del` something (`del foo`), just as `__init__` is called when you `init` something (which happens shortly after construction). Recall that _everything_ in Python is an object.
That'd be fine by me if the maintainer was playing the openess game and as PJE didn't, the community decided to fork the project accordingly. 
Yeah. You could prevent it by overloading the `__call__` implementation of the class instead of `__new__`, but you'd need to change the metaclass to do so. ie: class Test(object): class __metaclass__(type): def __call__(cls,value): print "new",cls,value if value == 1: print "shortcircuit" return 1 self = object.__new__(cls,value) print "created",self return self def __init__(self,value): print "init",value # Never gets called 
&gt;`__del__` is called when you del something (del foo), Nope. class A(object): def __del__(self): print "__del__ called" &gt;&gt;&gt; a=A() &gt;&gt;&gt; b=a &gt;&gt;&gt; del a # __del__ wasn't called, even though I used del &gt;&gt;&gt; b=None __del__ called # And here it was called even though I didn't. `__del__` and `del` are essentially unrelated, or at least no more so that "=" and `__del__`. `del` simply manipulates a namespace to remove a name (also used to remove items from containers - eg `del a[4]`). That *might* end up resulting in `__del__` being called, but so might many other things.
what kinds of errors?
&gt; the documentation for the \_\_del\_\_ method quite clearly says... This might be news to you, but most people don't read the full language specification before using a language. 
let's see: $ sudo python_select -l Available versions: current none python25 python26 python26-apple $ sudo python_select -s python26 'python26-apple' is the stock 10.6.1 version: Python 2.6.1 (r261:67515, Jul 7 2009, 23:51:51) 'python-26' is macport's version: Python 2.6.3 (r263:75183, Oct 19 2009, 15:20:50) macports is really awesome. it stores everything in /opt/local, so removing it is easy. the port tool is easy to use. the only drawback is compiling from source, but on my black macbook, compiling python 2.6 didn't take very long.
Watching it drag in half of X11 while building Python is kind of amusing as well. I should give the MacPorts version a go.
You forgot to post the traceback, unless this was meant for the psychics subreddit.
I am just guessing here: There are some problems with it deadlocking if the pipe buffer fills. This problem shows when you are doing one shot calls. The latest documentation describes the problem.
that's true in any garbage-collected language; it's a gotchya mostly for the C++ guys. nobody else cares.
Ooooh... shiny. I've used metaclasses occasionally, but never made the connection that the init-calling magic has to happening inside type.\_\_call\_\_. Nice!
Just to post a demo of the double-init thing I mentioned above... theobject = None class Test(object): def __new__(cls,value): print "new",cls,value if value == 1: print "shortcircuit", theobject return theobject self = object.__new__(cls,value) print "created",self return self def __init__(self,value): print "init",self,value &gt;&gt;&gt; theobject = Test(0) new &lt;class '__main__.Test'&gt; 0 created &lt;__main__.Test object at 0x7fe1913c5250&gt; init &lt;__main__.Test object at 0x7fe1913c5250&gt; 0 &gt;&gt; sameobject = Test(1) #theobject is used again, w/ new params new &lt;class '__main__.Test'&gt; 1 shortcircuit &lt;__main__.Test object at 0x7fe1913c5250&gt; init &lt;__main__.Test object at 0x7fe1913c5250&gt; 1 
&gt; This might be news to you, but most people don't read the full language specification before using a language. We're talking about a single method that is not needed 99% of time and you're arguing that reading a documentation for that method is too much for a programmer that wants to use it? Sad times.
The insults are out of place. Especially if you can recognize that while the article may be worthless for you, other people do stumble on this issue. (Clarification: I am the author of the article)
Most people understand what `__init__` does, and it's use is equivalent to the way many people (that I know) understand c++ constructors. In contrast, `__del__` is only rarely used. This is exactly why it is a gotcha - many people do not expect it, especially because `__init__` works according to how they think it should work, and `__del__` works according to expectations "most of the time".
For people coming to c++, this is still reasonable: constructors receive partially constructed objects (implicitly in _this_) which already passed other constructors earlier in the inheritance tree.
I'll get OS errors for simple commands like cp. I'm not the only one with problems. Other people here have had similar problems.
Python naming conventions: operators are led and trailed by two underscores. It's not meant to hide it, but rather meant to let the programmer know that this is defining an operator, and as such the method name isn't the way you'll call this method. If we want to hide something in Python, it will not be documented.
To get \_\_init\_\_, write \\\_\\\_init\\\_\\\_. To get `__init__`, write \_\_init\_\_ surrounded by backticks. See [Markdown Syntax](http://daringfireball.net/projects/markdown/syntax).
Not completely accurate: a single leading underscore is usually used for "soft hiding", and two leading underscores do some name mangling in classes, so that inheriting classes can not touch that name (unless they really want to).
You should take a Python class. When you return 1, you get an integer and not an object. In other words, the class is useless. a=Test(1) is an integer and there is no way to call any method of the class.
&gt; it might be news to you, but neither does C++ constructor. It does not allocate memory, it only initializes it. Then a constructor would be more like what Delphi does then?
Thanks, I already looked :)
Returning an integer in `__new__` above was there for demonstrating how Python doesn't call `__init__`if `__new__` returns a weird type.
`__double_underscore__` names are magical. They have meaning other than what you give them.
Obligatory: http://www.memegenerator.net/445410/
&gt; Most people understand what `__init__` does, and it's use is equivalent to the way many people (that I know) understand c++ constructors. Most people can not be bothered to check if they have the basic knowledge, as it was already established, that those people don't understand why you get `self` in your so-called-constructor arglist. So most likely `__init__` also works according to their expectations only most of the time. And the final thought was that you should indeed RTFM if you are unable to gain knowledge in any other way. Which seems to be the case here. edit: markup in quote.
I'm afraid I don't get the point of this post. The semantics of \_\_del\_\_ and c++ destructors are different. Big deal. I would argue that the c++ semantics are the gotcha. The point of a destructor is to release any resources held by the object. Just because a constructor throws an exception doesn't mean that it may not hold resources. For example, the first part of a constructor may allocate some memory. The constructor may then determine that an exception needs to be thrown. If the author of the constructor doesn't release the allocated memory before throwing the exception, then a memory leak will occur. An underlying assumption of this article is that the semantics of \_\_del\_\_ and c++ destructors should have the same semantic. But python is a managed language and c++ is not... I see no reason that they should have the same semantic.
1. The convention for create/destroy function pairs is to not call the destroy function if the create function failed. As an example, consider malloc/free. 2. If you accept my first point, then you should accept that knowing that `__init__` and `__del__` are not paired this way is important.
Further information is available in the [documentation](http://docs.python.org/reference/datamodel.html#object.__del__): &gt; object.\_\_del\_\_(self) &gt; &gt; Called when the instance is about to be destroyed. This is also called a destructor. If a base class has a \_\_del\_\_() method, the derived class’s \_\_del\_\_() method, if any, must explicitly call it to ensure proper deletion of the base class part of the instance. Note that it is possible (though not recommended!) for the \_\_del\_\_() method to postpone destruction of the instance by creating a new reference to it. It may then be called at a later time when this new reference is deleted. It is not guaranteed that \_\_del\_\_() methods are called for objects that still exist when the interpreter exits. &gt; &gt; Note &gt; &gt; del x doesn’t directly call x.\_\_del\_\_() — the former decrements the reference count for x by one, and the latter is only called when x‘s reference count reaches zero. 
That's the point. warbiscuit gave it as an example to illustrate `__init__` getting called by `__new__` whenever you return an object of the same type, but not when you return a differnt type (like an integer). Mine uses the same example, but overloading the class's `__call__` to get the same effect *without* calling `__init__`. In practice, you'd probably return something more complicated than an integer - overriding `__new__` is usually to do caching, or to act as a factory returning different subclasses. Returning 1 is simply for illustrative purposes. 
An addition regarding the point of this post: While I believe I've explained why the post is "generally useful", I should mention that many of the people I work with come from c and c++ backgrounds, and still program in these languages. EDIT: removed "Many others are from Java or C#, where I believe the semantics are similar (but I didn't check).". I just checked for Java and it's indeed different. As I don't program in these languages, I'd rather not comment on them.
&gt; The convention for create/destroy function pairs is to not call the destroy function if the create function failed. Please show me a citation that shows this _convention_ is necessarily true for all OO languages. &gt; As an example, consider malloc/free. How is malloc/free even remotely relevant to OO? Malloc doesn't throw an exception it returns NULL. It's pretty hard to free() a NULL pointer. 