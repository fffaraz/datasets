I haven't played around with yhat's ggplot2 implementation yet, actually. It's been personal preference for me to stick with mpl, and I'll probably branch out into Seaborn next time I want to make boxplots (and use violin plots instead).
It's fairly common for python lesson plans to be translated almost verbatim from existing lesson plans, with no regard for pythonic idioms. The course I took was derived from a C++ course, although my professor made note of where we should deviate from the presentations (he was a newer professor using the same setup as the main professor for the course)
`retrieve_from` and `search_in` aren't part of Python. They're the parallel lists. `zip()` is a built-in function that takes any number of iterables and creates an iterable (Python 3) or list (Python 2) that yields/contains a sequence of tuples with one element from each input iterable. The `dict()` initializer can turn a sequence of tuples of the form `(key, value)` into a dictionary. For example: Python 2: &gt;&gt;&gt; ints = [1,2,3,4] &gt;&gt;&gt; strs = ['one','two','three','four'] &gt;&gt;&gt; zip(strs,ints) [('one', 1), ('two', 2), ('three', 3), ('four', 4)] &gt;&gt;&gt; mapping = dict(zip(strs,ints)) &gt;&gt;&gt; mapping {'four': 4, 'three': 3, 'two': 2, 'one': 1} &gt;&gt;&gt; mapping['three'] 3 Python 3: &gt;&gt;&gt; ints = [1,2,3,4] &gt;&gt;&gt; strs = ['one','two','three','four'] &gt;&gt;&gt; zip(strs,ints) &lt;zip object at 0x7f5fc1c95048&gt; &gt;&gt;&gt; list(zip(strs,ints)) [('one', 1), ('two', 2), ('three', 3), ('four', 4)] &gt;&gt;&gt; mapping = dict(zip(strs,ints)) &gt;&gt;&gt; mapping {'one': 1, 'three': 3, 'two': 2, 'four': 4} &gt;&gt;&gt; mapping['three'] 3 In Python 2, `zip()` is very slow for large lists. If you must zip large lists in Python 2, you should instead use `itertools.izip()`.
Function composition maybe. It's just another operator, so if you had an application for it, you could have used `&gt;&gt;` or `|` or something unless you really went overboard and ran out of operators.
Fixed [just for you](https://github.com/mmautner/simple_api/commit/736ef1c030d551cd18445178636cf6d8312564b5) :)
cool, ill check it out
Just look at OPs history to see what the project is
And yet csv files are still a thing and "can't handle text files" is the only substantive complaint about Matlab here, aside from cost. That indicates people are using text as a data format way more than they should be.
Would've loved to see RocksDB in there. There are python bindings for it as well: https://github.com/stephan-hof/pyrocksdb Facebook pretends it's much better than LevelDB. https://github.com/facebook/rocksdb
Why are you linking this here? 
I would make a list and put the IP, status and lcy_avg in the list as a dict, and then convert to json when you actually need to print.
Thanks for the suggestion, I've added RocksDB (which performed about the same as LevelDB).
Text files are indispensable, but I just wanted to point out that HDF5 is widely used too in python. In my experience the balance is about right. The only people not using HDF5 when they should be either haven't heard of it, or have legacy code that it isn't practical to port. I've introduced a bunch of people to HDF5 and the response has always been immediate and complete conversion to using it. People's hearts are in the right place. But a lot of stuff is old and in text files, and sometimes you need the portability for someplace you won't have HDF5. So text files survive, especially for non-numerical, append-only data.
So how many hours does the process take now? :)
You're trying to have a list of hosts with the IP, a list of ping averages and the status, from what I can tell. The format should look like this, formatted to make the JSON more readable, with `lcy_avg` being a list of the last 30 ping times? { "lcy": [ { "lcy_avg": [ 0.74 ], "lcy_host": "192.168.0.253", "lcy_status": 0 }, { "lcy_avg": [ 0.307 ], "lcy_host": "192.168.1.253", "lcy_status": 0 }, { "lcy_avg": [ 6.488 ], "lcy_host": "192.168.2.253", "lcy_status": 0 } ] } You could have a function to make a dict that would then go in the `lcy` dict. def makeitem(avg, host, status): item = {} item["lcy_avg"] = avg item["lcy_host"] = host item["lcy_status"] = status return item And if you wanted to append a time to `lcy_avg`: def appendtime(item, time): item["lcy_avg"].append(time) When you get &gt; `MAX_DATAPOINTS` items in `lcy_avg`, what do you want to do? Remove the oldest item, or the smallest/biggest item? 
Excellent, thanks for the tip, I will begin having a go. When the max datapoints is hit, then I want to delete the first item in the array (oldest record over 29 is deleted). if len(lcy_avg) &gt;= MAX_DATAPOINTS del(lcy_avg[0]) I believe.
Yeah, that looks right. Also, a tip, if you have some JSON that you're trying to read the format of, you can pipe it to `python -m json.tool` to pretty print it, instead of all being on 1 line. That's what I used in my post.
Yeah, I'm getting used to looking at it on one line, especially when watching for the append on fields :)
I develop Python under Windows and it's oftentimes a config hell... To date, I've had to: * Install a whole MS Visual C++ developer environment (and I was trying to avoid MS tech...) * Change the Python source code to debug failed pip installations of dependencies with C-extensions. * Pollute my python install with a myriad of packages that absolutely refused to compile their C-extensions through pip I shudder to think of what tomorrow will bring... or I'll just boot up Ubuntu and circumvent all the problems.
Thanks, never heard of it, going to read up on it. I really have bitten off more than I can chew. If I call each host individually (outside the array) and build the json with each host separately, I can do it, but once I want to put the hosts in an array to simplify management ... yeah it all goes pear shaped.
Minor thing: you don't need the paren for del: del foo
Spam eggs and ham? please elaborate. I don't know these acronyms. 
Depends on the field. For example, if you're interested in (say) Web Applications, or Maps, they wouldn't be a big player.
The article might be of value but I can't read its language. Still, I hope people don't downvote it purely for not being in English.
I'm a little surprised that you left pytables out of the mix. The HDF format is sort of known for being one of the go to data storage formats for large scientific databases due to its speed. You should give it a shot. =)
I don't understand why this is not on an existing code repository service like github or bitbucket or google code etc. ? 
It's because its 12 years old, if I had to guess.
I know, right? Sqlite *is* awesome. 
spam?
I've tested the GLES support on the Raspberry Pi and it works with minimum effort. Good job guys!
http://xkcd.com/927/ Nah, I won't be using this. The first two justifications are lack of date/time support (you should look up ISO 8601) and binary data (try googling "base64") in JSON. After you realize how easy it is to put these in JSON, a new exchange format just doesn't seem viable yet.
For the record, I agree with you, I won't be using it either. I'm not the author of this, I just thought it was interesting enough to share.
Looks useful! But: Ubuntu 12.04? Why not 14.04?
Ah yes that would explain it http://www.pygame.org/pcr/news.php Is pygame really that inactive?
Normally I just do the standard https://docs.python.org/2/library/profile.html thing, sorting the output on cumulative time. If I want to drill down into what part of a function takes time I just select half of the function and hit the "extract method" in pycharm and call that function "foo" or whatever. Rinse and repeat. This is almost always enough.
I optimized the conditional but didn't use partial. I add this before the while loop: if platform.system() == 'Windows': clear_command = "cls" message_command = "msg * {}" else: clear_command = "clear" message_command = 'notify-send "{}"' And use the following code in the while loop: while(True): os.system(clear_command) //clear screen //some code os.system(message_command.format(update)) //show message Thnx for the idea
SQLite can be *significantly* sped-up by setting some `PRAGMA` values: Enable write-ahead logging (https://www.sqlite.org/pragma.html#pragma_journal_mode) SET PRAGMA journal_mode=WAL Leave it to the OS when to sync data to disk (https://www.sqlite.org/pragma.html#pragma_synchronous) SET PRAGMA synchronous=OFF Write temporary tables and indices to an in-memory database instead of the disk (https://www.sqlite.org/pragma.html#pragma_temp_store) SET PRAGMA temp_store=MEMORY Before: (dbbench)3057f97a7628d44c2e59(master*) ± python run_bench.py Testing with N = 100000 ------------------------------------ Sqlite ~~~~~~ Writes: 5.19565391541 Reads: 1.66586112976 After: (dbbench)3057f97a7628d44c2e59(master*) ± python run_bench.py Testing with N = 100000 ------------------------------------ Sqlite ~~~~~~ Writes: 2.27327203751 Reads: 0.969978094101 
If you're unaware there's a [csv library](https://docs.python.org/2/library/csv.html) that will help you parse the data from csv files. I'm having a hard time understanding what exactly you're having trouble with from your description though. If you could show me an example of the data and what you want back I might be able to help.
indeed. 
I am not clear on what you are doing. But... [pandas pandas pandas pandas pandas pandas](http://pandas.pydata.org/) When dealing with tabular data, pandas is a huge help.
[run snake](http://www.vrplumber.com/programming/runsnakerun/) is my favorite profile visualizer. It really helps figure out call path as well as cumulative time.
I read that blog page as "why stupidpythonideas.blogspot.com (or any decent website) doesn't need javascript".
Thanks! I feel like this could get me somewhere. I was reading though this (ftp://amet13.name/literature/eng/programming/python/Python%202.6%20Text%20Processing%20-%20J.McNeil.pdf) and it has done nothing but confuse me more. 
+1 to the `pandas` suggestion. If I read your description correctly, your code might look something like: import pandas as pd # load .csv file df = pd.read_csv('original.csv') # add a new column called 'averages' with averages of columns C and D df['averages'] = df.ix[:, ['C', 'D']].median(axis=1) # delete the C and D columns since they are no longer needed df.drop(['C', 'D'], axis=1, inplace=True) # export the CSV file df.to_csv('output.csv') Instead of hard coding 'C' and 'D' you can use pandas to discover them, too: to_avg = df.columns[2:] # then, for example df['averages'] = df.ix[:, to_avg].median(axis=1) 
I can see why that would confuse you more haha, looks like it's more for high-end and complicated parsing of text and data who's nature you aren't sure about ahead of time, sounds like you just want to parse some cluttered information files you have ahead of time and pull out the most important bits. 
handle the dup key error differently than the rest of your errors try: ... except pymongo.errors.DuplicateKeyError: pass except: ...
Exactly. Thanks a lot for your information. As I am new to most of what you mentioned its gonna take a bit for me to chew it up it looks like it will help immensely. 
I had some big trouble getting it to work on students' Macs in the Fall. `pip install pygame` and then it would just barf errors when we tried to use it. Shame, because of the community and focus. We might try for a Skulpt plugin, but that'd be a huge project.
Perl was actually the original P in LAMP, PHP is a pretty recent thing comparatively.
Thanks a lot, any way I can prevent it from continually popping up every time I run my code?
Thanks, and any way I can stop it from happening?
HDF is great for its intended purpose, but it is not a database.
Wait for Pygame developers to resolve the root cause of the warning.
Yep. Saw the js-fest trampoline page and noped out of it. Probably a good thing as I don't agree with the title's premise anyway.
Why can't we just use ; to delimit multi line lambda and call it a day. Or to generalize, adopt the Go style multiline expression syntax where the last line value is returned as the result of the expression. 
Yes, I thought about it too. Vagrant is coming from ruby universe, so I supposed that chef would be the best tool for that. Maybe I'll try salt also :)
I'm willing to bet there's some crazy, naively-unexpected syntax definition and implementation-specific problems (or collisions of both) that would stop a naive extension of the lambda syntax. And after that, as always, some backwards-compatibility problems. But I am definitely sympathetic that some sort of proper anonymous closure would be nice to add to python.
I don't like that either, but the post is interesting. I'd like to discuss the content, not the presentation.
Just a suggestion, as I've never done this before and did some quick Googlefu: https://getfirebug.com/releases/netexport/ NetExport has a feature that can automatically export a Net view in Firebug as a HAR file that contains JSON. Simply change the log location in the options to a directory of your choice. You could then parse the JSON with Python later if you wish. That's just if you wish to continue using Firebug. I'm sure there is a better way to do this.
Okay so maybe this will help. The expression I am looking at is all jangled up with HTML code and each record is maybe 5000 characters long and there is over 18k records. Each record is already delimited but the stuff within these records (the useful data) isn't. I want to know a way to take out specific strings from that long string and create new delimited strings that are easy to see in excel. So for example how would I when looking at a bunch of code tell python to find a REMOTE_ADDR" that is within a &lt;td&gt; tag to grab the data that comes in the next &lt;td&gt; tag? and add that to column next to the associated record. I could then theoretically change the keyword and grab all the data I need out of this string, correct? Could I also get the csv to make column names out of the keywords I tell it to grab? edit: I see new information in your original I haven't read yet. I am reading it now. 
Don't ask me... I just came across it while digging around. Someone could download everything there, and then host it on a repo on Github, if they were so inclined. I would imagine the owners of the site would be alright with that, but I haven't asked, so I don't know. I get the feeling the site is pretty much abandoned anyway. Last update was from 2002. Maybe I'll do that (download all of the scripts, and host them in a Github repo), if people are interested. There aren't that many scripts, so it shouldn't take more than an hour or two (including copying all of the script descriptions and credits). Actually, I was just going through the scripts on there, and I see a number of comments saying a number of the scripts don't even work, so maybe it's not even worth it. Should have looked through more of these before posting this, me thinks.
If you're parsing HTML code, you'll want to look at the python HTMLParser https://docs.python.org/2/library/htmlparser.html which will give you direct handling over the elements and tags of an HTML document. So using a similar approach to the example code i gave at the end of my original post, you could read in the data of the file, make a subclass of the HTMLParser class as described on that module page, store a boolean (per se) that determines whether or not you're inside a td tag, and in the handle_starttag method, if the tag is a td, set your boolean to true, and likewise set it to false in the handle_endtag, and in the handle_data method look for REMOTE_ADDR and what not and do your processing on it there, for example substring it from there to the end of that td tag or a fixed length, then add it to a list variable that is an attribute of your class and use that to write to a csv file at the end. You could still do it (albeit probably faster) with raw text processing by splitting the file contents by &lt;td&gt; and parsing through that with a boolean flag similarly, with the benefit of not having to loop through all of the html tags in the file, just what you were worried about, but it would be a little less elegant For mapping keywords to column names, look at the DictWriter in the link for csv module i gave you originally, it takes a python Dictionary (key-value pairs setup like {key:value, key:value, ...}, and a list called fieldnames of the columns you want to use, then writes to the field in a table based system using the fieldnames as a header and looking for those fields as keys of the dictionary. Not being experienced with DictWriter/Reader (there's an implementation that will read a CSV back in as a dictionary, which is very powerful for using your data in a script later), it doesn't look like there's a writerows method, so you would need to create a list of dictionaries, make a for loop through that list, and call DictWriter.writerow(dictionary). I'm not sure how experienced/inexperienced you are with python, but i'm assuming you understand the concepts/usages of dictionaries, lists, and subclassing, which aren't too complicated if you don't and you can find all kinds of examples of each in the python documentation. The hard part comes with composition ;)
Ah, well, I'm using NoScript, which injects a few hints as to why it's not working into the page. But even when I allow that particular domain, the page stays white, and a few seconds of redditainment isn't worth wading through the slabs of domains it wants to run scripts from. Ironically, it *is* worth writing a reddit comment to complain about it, so I guess that means I'm an inconsistent misanthropist fucktard. Meh.
Should have named it Pytchfork :P
So I just got it working with that method! In case anyone ever cares about this sort of thing, I found the code that does most of it [here](http://www.softwareishard.com/blog/firebug/automate-page-load-performance-testing-with-firebug-and-selenium/). Basically it works like this (the link's code is in Java so I used Java, but Python supports everything used as well): * Use Java + Selenium to literally open a browser and go to URL of choice automatically. * Also with Java + Selenium, open Firebug with NetExport within the browser and set NetExport to AutoExport * Then NetExport (not Java) waits for all the XHR requests, then writes them in JSON to a text file * What's still left to finish: write either Java or Python to parse out the info I need from the JSON file Strange method but it works.
Perhaps a lookup table for cosines would be useful? If it's not hardcoded, it may increase the startup time of the application, but it will save a lot of calculation time. You'll see LUTs used all the time in games. It's a pretty simple, effective optimization.
I think that I have typed two zillion lines of C++ and PHP. Then I became a Python convert. But I am forced to still do things in C++ and I resent every extra character that I type. I know that it would blow backward compatibility out of the water but I would love for C++ to make the leap to no braces. But I hate to say it that there are a few occasions where C++ must have braces involving scope. 
There can't really be a guide since it varies so much. Most of the ugly scraping I do comes from PDF files since other sources are generally well behaved. You can get extremely far with basic string manipulation in python. The split and indexOf functions combined with slicing will do almost anything. Occasionally a Regular Expression can make the job much easier but you can generally get by with loops. The initial goal should be to get all the data you need from a file into python data structures then perform whatever manipulation is required. Sometimes a sort or sum, sometimes nothing. Finally you need to output it in a useful way. I generally output in CSV (Indesign) or Excel since it is easy to make something good looking from there. Be careful automating anything important, and try to ensure your code fails at the first sign of trouble.
It's old code which I never released but it's quite useful. The nice thing about it is that it allows multiple independent plugin sources so you can write systems that have two application instances in the same process with different plugin sources each. I think the biggest issue is that it currently doesn't have good docs that explain how it works. Feedback on that would be awesome.
I'm really sorry, but I can't work this out. I understand that I need to read the value back into the script at each run and append to it, but I just don't know enough about python structure to work out how your suggestion fits into my script. I will have to go back to Google and find some online courses or something because I just don't quite get data structure when it comes to for/when etc. Thanks for your help however, it has shown me that I need to step back and learn the basics a bit more first.
I guess it is not as much of an adjustment for me as my indenting style in C++ was basically identical to python.
Have a look at https://pythonhosted.org/setuptools/setuptools.html#dynamic-discovery-of-services-and-plugins
Those are solving different issues though. I use setuptools based plugins for lots of things (I use it in Babel for instance). PluginBase howevever works on a different level which solves the problem of global interpreter state for plugin systems. With setuptools plugins you have global plugin state. Each module in the Python interpreter will discover the same plugins. PluginBase allows multiple instances of the same app in the same interpreter to see different plugins.
I indent that way too, but if you ever accidentally decent a line in the middle of your block and don't catch it you codes flow is broken and you get to go track it down.
How does it compare to [stevadore](http://stevedore.readthedocs.org/en/latest/) ? link to [older discussion on plugin systems](http://www.reddit.com/r/Python/comments/1qaepq/very_basic_plugin_system/)
They solve completely different problems. PluginBase's mainly isolates different plugins from each other. Maybe this example helps to show how it works: https://github.com/mitsuhiko/pluginbase/tree/master/example Notice that both apps in this example have their isolated views of the plugins. In other words, it allows this to work: Python 2.7.1 (r271:86832, Jul 31 2011, 19:30:53) [GCC 4.2.1 (Based on Apple Inc. build 5658) (LLVM build 2335.15.00)] on darwin Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; import example &gt;&gt;&gt; app1 = example.Application('app1') &gt;&gt;&gt; app2 = example.Application('app2') &gt;&gt;&gt; with app1.source: ... from example.plugins import uppercase as uppercase_app1 ... &gt;&gt;&gt; with app2.source: ... from example.plugins import uppercase as uppercase_app2 ... &gt;&gt;&gt; uppercase_app1.__file__ == uppercase_app2.__file__ True &gt;&gt;&gt; uppercase_app1 == uppercase_app2 False As far as I know no other library does this.
Why not use a LUT? 
The general workflow is: * decypher the file format * deal with non-conforming data * do any extra analysis * output to whatever you require So for HTML input, you would want a parser like BeautifulSoup, making sure you deal with parsing issues due to input pretending to be HTML with HTML-like markup but really is garbage (e.g. 1990's web pages especially from Windows platforms) Then, you may e.g. pull some text out of a tag so you'll also likely want pyparsing to turn it into something useful / extract the specific info you need for your analysis. Finally, you're likely to dump it out using csv, xlwt, or some database interface. 
That's pretty much impossible. It'll cause a syntax error, giving the exact line, in all but the most contrived circumstances.
Describing the "what" (topics) without touching on the "how" (eg concise versus tons of examples?) isn't very helpful for anyone looking for information on a book.
You might want to use something like pyparsing or parsley https://pypi.python.org/pypi/Parsley
of course I should have! &lt;facepalm&gt; EDIT: has anyone actually downloaded yet it so that I can rename it without confusing people ...?
#####&amp;#009; ######&amp;#009; ####&amp;#009; Section 4. [**Security**](https://en.wikipedia.org/wiki/Virtual_Network_Computing#Security) of article [**Virtual Network Computing**](https://en.wikipedia.org/wiki/Virtual%20Network%20Computing): [](#sfw) --- &gt;By default, RFB is not a secure protocol. While [passwords](https://en.wikipedia.org/wiki/Password) are not sent in plain-text (as in [telnet](https://en.wikipedia.org/wiki/Telnet)), cracking could prove successful if both the [encryption](https://en.wikipedia.org/wiki/Encryption) key and encoded password are [sniffed](https://en.wikipedia.org/wiki/Packet_analyzer) from a network. For this reason it is recommended that a password of at least 8 characters be used. On the other hand, there is also an 8-character limit on some versions of VNC; if a password is sent exceeding 8 characters, the excess characters are removed and the truncated string is compared to the password. &gt; --- ^Interesting: [^Network ^virtualization](https://en.wikipedia.org/wiki/Network_virtualization) ^| [^X ^Window ^System](https://en.wikipedia.org/wiki/X_Window_System) ^| [^Remote ^Desktop ^Protocol](https://en.wikipedia.org/wiki/Remote_Desktop_Protocol) ^| [^X11vnc](https://en.wikipedia.org/wiki/X11vnc) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cilboux) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cilboux)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
How fancy you need to get depends on the requirements of your file. Is the format of the file predictable after reading the first say 5 lines? Can you fit it all in memory? Does it cross-link to other files? Do you ever need to jump back and reread something? Do you really need to convert that int/float data to an int/float (it's just going to add time)? Does it need to yield results? The simple stuff is open a file, read a line, and split it based on some delimiter. If you have fixed format lines (first value is character 0-8), you can speed up the code. Finally, if it's something that where a reader should already exist because you're doing something common, go find the reader. No one should write an XML reader.
Just rename it and make the readme for this repo link to the new repo.
Everyone might have a different in their top 10 but /u/Shadow141 covered a lot of what I overlooked. 
Right now, it's `lambda [args]: expression`. /u/ggtsu_00 is suggesting something like `lambda [args]: simple_statement [; simple_statement]* [;]`. This is not so simple a change as it looks: 1. Although every expression in Python has a return value, this is not true of statements. For instance, `raise Exception()` does not return a value, while `Exception()` itself does. 2. The expression `foo()` has a value, but the *statement* `foo()` does not, since it literally means "evaluate `foo()` and throw away the result." 3. `lambda: expression` must still "work" without requiring an explicit `return` (otherwise, the cure is worse than the disease). Now we have a special case in the parser (expressions are a subset of simple statements, yet we're going to treat them differently). This gets us into the same kind of logical trouble that violations of the [Liskov substitution principle](http://en.wikipedia.org/wiki/Liskov_substitution_principle) produce. At the very least, it will be confusing. Either `lambda: expression; expression` always returns `None`, or `lambda: expression; expression` returns after evaluating the first expression. 4. On an unrelated note, lambdas can appear at the end of a line. Here is perfectly good code whose meaning might change under the proposal: spam = lambda: ham(); return eggs
oh, i didn't notice it was already on PyPi
Using means and standard deviations? It's not necessary. 
To answer your first question, learning one of them will not make it difficult for you to use the other. They aren't extremely different. After learning one, you'll just need a bit of reading on the differences. Python 3 breaks compatibility with Python 2, so I assume that's why people are telling you to use Python 2. If you're just starting out and writing things for your own benefit, then I would suggest learning Python 3, since that's the direction the language is moving in.
For number 3, have a look at [Beautiful Soup](http://www.crummy.com/software/BeautifulSoup/) and [this site](http://www.python-excel.org).
I don't get what that gives you over: def sort_key(item): return item.attr1, item.attr2 sorted_data = sorted(data, key=sort_key) other than limiting scope.
Happens to me reasonably frequently, so not that contrived. Dedenting the final statement in a 2+-statement block -- for example an `if` block -- will result in incorrect behaviour with no syntax error being detected. If that block happens to be in the middle of another block like a `for` loop, mission accomplished. (short `if` blocks inside `for`/`while`/`with` are dirt common, IME)
Came here to suggest Cygwin. I'm forced to use a Windows system at work, and I do all of my Ruby and Python development in that environment. It's not perfect, but it's certainly doable (i.e., I haven't had an issue with gems or pip).
You may be assuming that the premise is something that it's not. It's arguing that full closures are better than Ruby style 'blocks', not that inline anonymous multiline functions are inherently bad.
I bought this book the other day. I'm still in the midst of reading it. I wish Python had more books especially for recent releases of Django. I'm coming from C# and Ruby/Rails and there are a ton of books for those languages/frameworks. But for Python &amp; Django I can't find any or they're old. Is it because the web tuts/documentation for Python &amp; Django are "good enough"? I like reading books and find they help me learn better it's just a personal preference.
This is a dumb as hell idea. If you want to learn about this topic, then set up your own web server, using cookie authentication, and then try to hack yourself instead. 
Have a look at Pandas and reportlab: http://stackoverflow.com/questions/17194290/apache-log-file-data-analysis-with-python-pandas http://nbviewer.ipython.org/github/koldunovn/nk_public_notebooks/blob/master/Apache_log.ipynb http://stackoverflow.com/questions/17542524/pandas-dataframes-in-reportlab You can also find video tutorials on both on youtube, if that helps.
I googled it ! None of the pages explained what it IS. They all presumed foreknowledge, "A series of problems" ? WTF does that mean? Who poses them? Who works on them? Who judges them? What makes this a "Project"?
Yes. But plugins appearing in two working sets are shared (same module after import). You can only have one version of a module loaded at the same time.
Limiting scope is very valuable.
You're right, but there are too many for Python Turkish followers. 
I disagree. A dictionary is O(1). A list is O(n). To lookup a number in your scheme is O(n). I'd consider just storing a dict of people to number and number to person. Now if you want to sort the data or use a tree, the that could be faster.
It looks like your link only works when logged in. (Try logging out then visiting it.) If you find a way to make it visible and know how to work with crypto-currencies /r/jobs4bitcoins and /r/jobs4dogecoins are both pretty clean and easy to use boards. Otherwise, I'm not totally sure. I know this probably sin't the right place.
Yeah that's what I said.
 Make `def` an expression, boom!
For me, it's the way you read it, i.e. the callback function is defined after its use and not before.
This actually looks pretty awesome.
You probably want to go to sites like elancer or else. There you can ask for a mission against a small compensation.
No. Flask's extension module is more intrusive but simpler. Also it does not support virtualization.
Very interesting, thanks for the writeup. The results came out very well :-)
http://fourlightyears.blogspot.com.au/2014/05/python-2-versus-python-3-beginners.html
Check out munch for a different kind of simple container: https://pypi.python.org/pypi/munch/2.0.2
You forgot to start with "Fields." :P
Yeah, I once made irc bot with plugin system... Which I had something like this back then.
OS/2 *was* a great OS though :(
Python 2 was great too in its day but it's dead now.
Try doing something like this with the ggplot python port (I don't klnow if geom_tile is supported or not): http://stats.stackexchange.com/questions/17842/how-to-make-waffle-charts-in-r
I'm the OP. Every now and then I have to return to python 2 and it fills me with dread particularly for its unpredictable and inconsistent Unicode handling. Yes I had to go through a painful phase with Python 3 to wrap my head around Unicode but the pain in my opinion is just because Unicode is complex, in fact Python 3 makes it as easy ass practical to handle but there's no avoiding learning it. The pain was because I knew nothing Bout Unicode. What I am saying is that Python 2 grumblers want to give the impression that python 3 is some sort of demon language but it's nothing of the sort. It feels great, works great, has libraries for just about everything and is fun.
Disagree solely because I do 90% of my development in 2.7.3 and people st my work are the same way. A few people I know are waiting for 4. 
1. This post has nothing to do with python 2 vs python 3. Author just says that he chose python 3 to start learning with, the post in no way discusses advantages or disadvantages or even differences between the two versions. 2. Author has never used python 2 and claims such as "I don't experience it as a chore, or complex, or difficult, or broken." apply to python 2 too. 3. "Today in mid 2014 I would say that apart from Amazon and Google, third party library support for Python is now effectively solved for many common requirements." What? There are still thousands of packages (not made by amazon and google) that don't support python 3. Even if you look just at top two hundred you'll find dozens of libraries without full python 3 support. The argument "just write project with python 3 support only" is stupid on so many levels that I won't even bother explaining it and it will pretty much only work if you're working on your own personal projects that you have no intentions of sharing with anyone.
That doesn't make it not annoying.
Almost any commercial project is not intended to be shared, they are intended to meet business purpose. Why bother with python 2 for that. Tell me what you personally needed to build in python 3 that you couldn't find a library for - come on -true facts please....... Why as a beginner would I care about 2 versus 3? Why would I waste my time learning 2, can you suggest any reason? I would like to hear one reason why a beginner should start with 2 instead of 3.
&gt;Why bother with python 2 for that. Because your developers are comfortable working with python 2? Because the rest of your codebase is on python 2? Because it's still officially supported? Because it works? Because it isn't broken? &gt;Tell me what you personally needed to build in python 3 that you couldn't find a library for - come on -true facts please....... Last time I *considered* to use python 3 for commercial project, like 2 months ago, boto didn't support it. Either way by going with python 3 from the start you risk needing a module that doesn't support it in the future. ____ Oh and for your edit: Because it's literally the same thing for a beginner and more resources, tutorials, answers for common questions work only on python 2. Even if it's a simple print as statement not as function issue it can cause issues to beginners. It's not a different language and it doesn't matter for beginners. Python 3 doesn't help you in any way when you're starting out, the changes introduced in 3.x are meaningless for people new to programming/python.
I’ve thought blocks are overused for a decade. Actually there are several cases that blocks seemingly solve well, but actually these are just another *patterns*. Procedures are originally a concept to eliminate duplicated routines. Late binding of it is not an inherent behavior of it, but tends to be diverted to delay evaluation. Ruby programmers used to utilize blocks for mostly everything. For example, Ruby uses blocks for RAII, whereas Python provides `with` statement for that. Ruby uses blocks for `map`/`filter` while Python has list/dict/set comprehensions and generator expressions. Ruby uses blocks for iteration, while Python has `for` statement and generators. Ruby uses blocks to register event handlers, while Python uses decorators for that. I believe block to Ruby is a thing like pointer to C.
Boto is one of the only remaining important libs not yet running under python 3, but if you download it grom github now you'll find that already that is underway and some modules such as S3 work under python 3. https://github.com/boto/boto/issues/677#issuecomment-46615849
My question was not "what libs have not been converted", rather "what do you need to implement that there is not a python 3 lib for". You. Your real world requirements. There's a lib for solving all sorts of problems. Boto has been the only major roadblock and that's being fixed. I haven't hit any roadblocks because if lack of libs. Except boto.
This. The latter method, besides the scope thing, means you leave a whole bunch of one-shot functions laying around. It's about the code representing the intent- That function will never see use outside of this one call.
So, there's that, then there's [PEP 403](http://legacy.python.org/dev/peps/pep-0403/), which has a simpler usage. No `?`, no local scope block; it just lets you create a single named temporary function or class via a slightly modified decorator syntax. It was written by the same guy as PEP 3150, Nick Coghlan. Here's an example: @in sorted_data = sorted(data, key=f) def f(item): try: return item.attr1, item.attr2 I like just a little bit more than 3150, because it's simpler overall, and doesn't introduce any new lexicon. That `?` really bothers me for some reason. I really want to see one or the other enter the language. It's worth noting, for those who don't see the difference, that in /u/takluyver's example, you can have as many definitions and normal scoped code as you want inside of the given clause. It all becomes part of a temporary namespace accessible via `?` Here's [Coghlan's python website](http://python-notes.curiousefficiency.org/en/latest/). It's worth reading through if you have the time.
Why do you believe everything is black &amp; white? Because the review hardly provides any opinion whatsoever. What you can get from it is a simple basic description of the book. FYI, I am not a friend of the author, though I do like his [The Mouse vs Python Blog](http://www.blog.pythonlibrary.org/)
Any review that is posted online for a friend is essentially meaningless. If you really didn't like the book you would either refuse to post the review or lie in it to not hurt your friends feelings. OP took a third, less seen option, by writing a review that says nothing about the book yet tells me I should read it anyway. What am I supposed to take from that?
Perhaps I parsed the OP's comments too quickly, but his benchmark was for pure key storage and retrieval. If that is in fact his intended use case, I'm fairly certain HDF is competitive via pytables. If he is doing any kind of more complex queries like joins, then of course you are correct.
&gt; Python 2 was great too in its day but it's dead now. Yeah, your credibilty just went out the window.
Actually, `Fields.not_.sure.if_.good.idea.or_.too.clever` - because `not`, `if` and `or` are keywords. Sorry I ruined your joke, haha.
Is this compatible with Python 2 and 3?
Hey I ended up downloading BeautifulSoup as my HTML Parser. I was hoping you code help me think threw the code I have to make for it. After looking at the data very closely everything is inside &lt;td&gt; tags. So the whole line of text has 15+ &lt;td&gt; tags where some have the column name and the following &lt;td&gt; tag has the information. What I want to is write all the column names to the csv file and then parse through the data to find the data that relates to the column and add it to the correct cell that relates to the same row. So if the tags look like: &lt;td&gt;QUERY_STRING&lt;/td&gt;&lt;td&gt;fa=string&lt;/td&gt;&lt;td&gt;REMOTE_ADDR&lt;/td&gt;&lt;td&gt;address&lt;/td&gt;&lt;td&gt;HTTP_SERVER&lt;/td&gt;&lt;td&gt;address&lt;/td&gt; It would take the &lt;td&gt; following QUERY_STRING and then write it to the csv file underneath the column labeled Query string but next to all the information of the same record (the rest of the &lt;td&gt; in that line). The thing that I believe will make it trickier is that each record may not have every column in it. There will be close to 15 columns and not every column will be used within the text. So what I have figured out so far has resulted in this: from BeautifulSoup import BeautifulSoup import re import csv f = open("mydocument.txt") as csv ##Just Going to show the ones I mentioned csvwriter.writecolumn=("QUERY STRING") csvwriter.writecolumn=("REMOTE ADDR") csvwriter.writercolumn=("HTTP_SERVER") soup.find_all("QUERY_STRING\&lt;/td&gt;\&lt;td&gt;(.*)\&lt;/td&gt;") soup.find_all("REMOTE_ADDR\&lt;/td&gt;\&lt;td&gt;(.*)\&lt;/td&gt;") soup.find_all("HTTP_SERVER\&lt;/td&gt;\&lt;td&gt;(.*)\&lt;/td&gt;") Now the issues I am having is what you mentioned I need to do in: &gt; then add it to a list variable that is an attribute of your class and use that to write to a csv file at the end. I feel like the method I have at the moment creates all the column names and then finds all the needed information but how I write it to the correct line and cell baffles me. 
First note: There's a typo in your example, one of your csvwriter calls is "writercolumn" instead of "writecolumn", just in case you didn't catch it, not sure if it's actual source or just a rewrite. Looking at what you've got setup and what you're trying to accomplish, essentially what you want to do is re-create the HTML table into a nested list structure so you can write it to a CSV (and strip out some of the useless data in the HTML table too). Staying in the constraint that you don't always have every single column, you'll have to change your BeautifulSoup parser to find the table rows instead of individual columns, so replacing the three find_all calls in your code above into one find_all('&lt;td&gt;') for example. I'm not sure how the find_all works exactly, but the behavior you want it to follow is to find you all the individual rows first. Next, you want to iterate through these rows and generate small lists for each row. Just looking at the documentation for BeautifulSoup (never used it before), it looks like you can do dot access for HTML tags. So an example (may) look something like this: #This is what we pass to csvwriter to write to our csv file. csv_list = [] #This is just a list of the search strings that you were using to find the columns # you wanted, so it's not 'as' hardcoded. column_searches = ['QUERY STRING\&lt;/td&gt;\&lt;td&gt;(.*)', 'REMOTE_ADDR\&lt;/td&gt;\&lt;td&gt;(.*)\&lt;/td&gt;', 'HTTP_SERVER\&lt;/td&gt;\&lt;td&gt;(.*)\&lt;/td&gt;'] #Loop through all the TR's in the file, if there are more tables than the one you # want, you would have to add in another find_all before this that skimmed your # results to just the one table, maybe by the name of class of the table? for row in soup.find_all('\&lt;tr&gt;(.*)\&lt;/tr&gt;'): #Making a list of lists so we make a new_row list for each iteration new_row = [] # Loop through all the BeautifulSoup search strings for the columns you need. for column_search in column_searches: #Find the current search string in the row data = row.find_all(column_search) # Not sure what find_all does if it doesn't return a specific column, # (if it didn't find it) # But assuming it returns None or a blank string, to handle not having # the column for the csv writer, we put a blank value there. if not data: data = '' new_row.append(data) csv_list.append(new_row) csvwriter.writerows(csv, csv_list) this will generate a python list called csv_list that you can pass to csvwriter.writerows() and it will recreate a structure similar to your HTML table but with just the stuff you want.
&gt; In C, functions are not first-class objects Of course not. C doesn't have objects. C does have function pointers, which are kind of the same thing. 
I didn't have a chance to read through everything, but one of the problems we encounter with plugins is that they are really 'set' at startup. As a consequence, our customer base is unable to add any new plugin without restarting the system (which is undesirably and prohibitively expensive). Does PluginBase solve that issue elegantly? Can we add plugins on the fly?
Unless you want to support something that: * SQLAlchemy doesn't support (postgresql partitioned tables?) * SQLAlchemy isn't optimized for (complex queries) In which case you would find SQLAlchemy to be a problem. Admittedly, a well-written really cool problem. EDIT: or if you want to support a data model in which you don't want to drive the DDL from Python. Say, you've got a 1 year-old project in which the DDL is managed by DBAs or maybe by some other product, perhaps not Python. This is a nice little framework, wouldn't it be cool if it could just introspect the data model and use that?
Matplotlib can certainly do such things, but it doesn't have a simple function to automatically do it for you. It isn't that hard to put something together from the primitives though. [This example](http://matplotlib.org/1.2.1/examples/api/hinton_demo.html) demonstrates the sort of thing you can do (and more really, you don't need variable tile sizes).
Bokeh can do this: http://bokeh.pydata.org/docs/gallery/unemployment.html (And a bunch of other amazing stuff: http://bokeh.pydata.org/docs/gallery.html#gallery)
Not exactly a cloud solution but I'm using a raspberry pi to host a couple of scripts triggered by cron and I'm pretty satisfied with the flexibility and the cost of this solution 
I am going to throw out a wild idea: Have a 4 version that is 100% compatible with both 2, 3 and 4 as long as you make a note that this is a 2.7 file, a 3.x file or nothing for a 4.0 file. This way people could literally migrate to 4.0 one file at a time. Crazily enough it would provide another opportunity for another break with backward compatibility if that was for some reason on the table. 
&gt; Sorry I ruined your joke, haha. [Relevant](http://imgur.com/1t1w6sB).
Very cool. I'd lose the angle brackets around the repr, though. It always makes me happy when `eval(repr(x)) == x` holds for all `x` of a certain type.
Yes but there is currently no wheel for Python 3.
&gt; Does PluginBase solve that issue elegantly? Can we add plugins on the fly? Yes. You can load more plugins later into an existing plugin source. To unload plugins you would need to make a new plugin source, load all plugins in and then unload the old source. But it works.
Your two points (besides your edit) are points that come up whenever pros/cons of ORM-type libraries are discussed--but given that you can always fall back to executing a raw SQL query string using SQLAlchemy (and most any other ORM/SQL rendering engine), what's the big deal? And regarding your point about introspecting the schema, [SQLAlchemy will do that for you too](http://stackoverflow.com/a/6307733)
We use matlab in production and its a nightmare. The code is live interpreted (text source embedded in the binary) , parrallelizing is difficult at best. It doesn't scale. It's buggy and binds you to very specific versions of GCC to even compile.
Apply the `wraps` decorator from the `functools` module to your wrapper function, eg. import functools def debug(f): @functools.wraps(f) def wrapper(...): .... return wrapper Fixing this issue is exactly what it's for. It copies the `__name__`, `__module__`, and `__doc__` of the function, as well as its instance dictionary, to the wrapper so it looks just like the function it wraps. 
Awesome! Thanks for the help.
&gt; what's the big deal? The point is that it's an extra layer that slows performance, requires additional research, makes diagnostics more difficult. Luckily, one can work around it since one often has to. It's a very well-engineered product, but it's also a very, very large product. And if you only want to use a subset of the module you will find that documentation &amp; help become harder to come by. In some cases that trade-off might be worthwhile, but it isn't in all cases. So your suggestion that we'd be happier in the end using SQLAlchemy is only true in some cases. 
Try [this](http://www.learnpython.org/en/Loops) and look [here](http://www.reddit.com/r/learnpython) for help.
Are you asking how to structure a while/for loop and call a function within the loop? def add_one(some_integer): return some_integer + 1 some_iterable = [1,2,3,4] for i in some_iterable: print add_one(i) i = 0 working = True while working: print add_one(some_iterable[i]) i += 1 if i == len(some_iterable): working = False This seems rather trival and I doubt that it's what you were looking for. The thing that I don't really understand is what you mean by, 'pass arguments from numerous individual functions to the main function.' 
"Awesome" php? Is that like [PHP: The Good Parts](http://phpthegoodparts.tumblr.com/)?
I chose two source files to get a more objective measure. The percentage of indented lines for which a dedent would change logic (is not a comment, blank line, a multiline string or inside brackets) that would not cause SyntaxError to be thrown after a single dedent averaged ~15%. This would be almost 0% if consistent indentation was enforced. --- This is higher than I thought it would be, but I also didn't take into account the immediacy of the errors. Errors which occur after any single run of the code don't tend to worry me in Python. The errors with non-localized effects and those that corrupt without throwing are the irritating ones, and those are rare.
Awesome-php: https://github.com/ziadoz/awesome-php
I'm sorry for the lack of clarity. I was thinking of programs like this: http://programarcadegames.com/python_examples/show_file.php?file=word_search.py By passing arguments, I mean like lines 103-114 being passed to the function placeword(grid,word) . I need to practice reading simple codes with functions so I can understand how placeWord(grid,"pandabear") would get passed to placeword(grid,word). I hope I made that clearer. I am very much still in the beginning stages of learning Python so please forgive my inarticulate explanation. :)
Off topic in a way, but I'd like to share my experience. I was using deque as a buffer, buffering small client writes (aka deque.extend(bytes)) to a larger chunk and then dispatching the large chunk all together (aka ''.join(deque.popleft() for _ in xrange(len(deque))), but the popleft turned out to be quite slow, and using cStringIO was much faster...
You need to create a text file that has python code in it and then run it with the python compiler. On windows, you can do this with a text editor (notepad, notepad++) and then interpret it with the executable. An easier way is to just use an ide. Try pycharm.
There is no reason to pop off each individual item one at a time like that. That's hugely inefficient. Instead: foo = ''.join(deque) deque.clear() But `StringIO` is not a bad choice if the things you're buffering are strings. 
"Science and data analysis" and "machine learning" are two separate sections?
Similar: http://docs.python-guide.org/en/latest/ 
If you only want one library and none of your project uses Django, it sucks that you'd have to drag in the cat and kitchen sink just to use module.
The video category is... Lame. There's two libraries actually related to video there, and the rest are glorified downloaders that are incidentally related to video. Happy to see FuckIt made the list.
Do NOT use tabs. Use spaces. And I don't know why /u/anossov got downvoted, but PEP8 would be a good thing to follow. You have a lot of extra blank lines and it makes your code difficult to read.
Because that wasn't constructive, it was off-putting. Thank you for the constructive criticism. My excessive tabbing/spacing is because code close together kind of makes my head hurt. I will revise my git copy to be more standardised in that regard.
Well, you asked for pointers, he gave pointers. Python is a language that requires correct use of white space, so reading and following pep8 is a good idea. :) That said, initial look I noticed you're using urllib. Check out requests. It is a much better library for working with urls. Excellent to see more people writing Python! Looking forward to seeing the changes you make as you learn. 
x86 is 32-bit, x86-64 is 64-bit. It depends what kind of operating system you have.
Alrighty, so I know I have 64-bit. Does that mean I use the third and fourth links on that page? Or are they for different systems?
Assuming you are at a university, I would recommend using [Enthought Canopy](https://www.enthought.com/downloads/) academic license as your python distribution. Installation is very easy and installing/updating packages is as easy as clicking 'update'. Canopy has a built in split-pane editor which allows to write script and then execute in the other window. In my opinion, the Canopy editor is complete shit. I prefer to use vim and the terminal but the editor is there if you want it. I tried for a while to manage everything manually but it became a huge hassle, especially since I was just learning. 
Setting up Python on Windows can be a pain in the ass. I recommend using [Anaconda] (https://store.continuum.io/cshop/anaconda/) which is sort of a pre-packaged version of Python with many of the more useful libraries already installed. All you have to do is download the exe and hit install. This [tutorial] (https://www.youtube.com/watch?v=oXnnRpTGT2M&amp;list=PLwNU7Gk6Z5ZkXXsvtJTtBhQNl905Jua-O) helped me get started
Excellent, thanks! I've already found a couple that I love. 
I feel so dumb, I downloaded it but I get an error that says "Installer integrity check has failed. Common causes include incomplete download and damaged media. Contact the installer's author to obtain a new copy." I of course googled this but I can't figure out what is wrong
Sure, any unnecessary dependency is a pain but I still don't see the "the amount of cool stuff that inexplicably has Django as a dependency" ... can you point to some good examples of things that have a dependency on Django that doesn't use it?
Feel free to send a pull request...
line 93 to 97 defines what placeWord does there, placeWord is defined as "placeWord(grid, word)" Whenever you call placeWord("some thing", "some other thing"), grid will be "some thing" and word will be "some other thing". Just imagine solely line 94 to 97 with every occurence of grid being "some thing" and every occurence of word being "some other thing". same goes for tryToPlaceWord within placeWord
it downloaded right this time! now... where do I type the code... I see the python application in that whole mess of stuff I downloaded but it just looks like the C command prompt, that can't be right, can it?
Look for Spyder, it's an IDE included in the Anaconda distro. If that's not to your liking, try installing [PyCharm CE](http://www.jetbrains.com/pycharm/) For someone in your shoes I do strongly recommend PyCharm as it'll setup a project folder for you to put your code in so you don't have to worry about the "navigation" issues. 
As another relative newcomer to Python, the 2vs3 divide is clearly retarding the advancement of the language. learn 2? Learn 3? I dunno. like OP, learning 3 seemed logical. However, the endless debate on this issues just makes the whole language seem less desirable; a house divided cannot stand and choosing sides in a sectarian war seems unpalatable whichever side may have the most merit. Maybe I should just focus on some other interpreted language, there's no shortage in the marketplace of ideas in this area. Ruby doesn't seem to be in the midst of a civil war, and it can do pretty much the same stuff anyway.
I really like https://github.com/Suor/funcy
The author probably wants pull requests. I'd imagine that's why it's on github in the first place.
I'm not a Python pro myself, so someone may correct me, but just som thought after reading the code (except PEP-8 which is already said): Instead of this: global yourDir Use this: yourDir = None ----- Instead of this: userUsing = raw_input('This scraper was not intended for illegal activities. If you choose to manipulate this script such that it is usable for such things, it is no longer the Intellectual Property of Succubus Softwares/Jessica Awtry. Please, press y to continue or n to terminate the script.') Use this to prevent the problem that "Y" != "y" and that "y " != "y": userUsing = raw_input('This scraper was not intended for illegal activities. If you choose to manipulate this script such that it is usable for such things, it is no longer the Intellectual Property of Succubus Softwares/Jessica Awtry. Please, press y to continue or n to terminate the script.') userUsing = userUsing.lower().strip() ------ Instead of this: UserConfirms = raw_input('Is this the expected output? (y/n): ') if userConfirms == 'y': print 'yes' return True elif userConfirms == 'n': print 'no' return False else: #If the user enters something stupid, for now, we'll just make them rerun the whole program. #Because, open source. RunProgram() Use this to just make it ask again instead of rerunning the whole program (and cause [recurssion](http://en.wikipedia.org/wiki/Recursion#Recursion_in_computer_science)): while True: userConfirms = raw_input('Is this the expected output? (y/n): ') userConfirms = userConfirms.strip().lower() if userConfirms == 'y': print 'yes' return True elif userConfirms == 'n': print 'no' return False else: # This is not nessecary, just showing you what will happen. continue ---- Also open files with the [with-statement](http://preshing.com/20110920/the-python-with-statement-by-example/)
I see a number of -django tools, but I also see a number of -flask tools. The implication that plugins inexplicably use the tool that they plug in to is a little silly.
No no he's not dead, he's, he's restin'! 
What an awful video. Spends 12 minutes whacking himself off then starts an anti-Python 3 rant. Please, let me rip his (few) arguments into shreds; 1. If there's no users of Python 3, why did people stick their hands up to say they use it? Continuing this lie simply amounts to ostrich-style ignorance. 2. 85M downloads for Py2 libraries and 4M for Py3? Since there's no other qualifications of what this actually represents, 84M people downloaded six / future / etc to upgrade their legacy code to Python 3. 4M other people just got on with the job. 3. "Business users" are using Python 2. Well, probably because they are also RHEL users and RHEL is stuck in the dark ages, having only last week upgraded from 2.6 to 2.7 despite Python 3 coming out 7 years ago - that's how horribly outdated RHEL is. But last year even Redhat noted this problem (probably losing their customers to better distributions that can stay updated) and created RHSCL where you can get fully supported Python 3 (and other development tools / languages). As a Python community we need to continually advocate either migration off RHEL (best idea) or the use of RHSCL (better than letting idiots use the system python for development). It was never a relevant excuse that Python 3 wasn't available, and its been completely irrelevant now for 9 months or so for this subset of users. If its true that he is a PSF member, the PSF need to dis-member him. Its embarrassing having this fallacious appeal to authority argument used to trick people into sticking with horribly outdated software especially when, by his own admission, the core developers have left it behind long ago. 
Nah, go with 32bit - I found that some modules have issues with 64bit python. Here's what you should do, step by step: 1. Download https://www.python.org/ftp/python/2.7.7/python-2.7.7.msi 2. Go here: http://www.lfd.uci.edu/~gohlke/pythonlibs/#setuptools and download "setuptools‑3.8.1.win32‑py2.7.exe" 3. Go here: http://www.lfd.uci.edu/~gohlke/pythonlibs/#pip and download "pip‑1.5.6.win32‑py2.7.exe" Install all 3 in the order you downloaded it in. Enter "Edit the system environment variables" in the start menu and open it. If you can't find it via start menu do the following: 1.Hold `Win` and press `Pause`. 2.Click Advanced System Settings. 3.Click Environment Variables. Click the "Environment Variables" button at the bottom. In the "system variables" click on "path" and click "edit" and add ";C:\Python27\;C:\Python27\Scripts" (without quotes). Open command prompt and type in `python` if you get python prompt and not some errors you've set it up properly. To install additional modules you can use `pip install &lt;module name&gt;` from command prompt/powershell or you can download window installers for example from here: http://www.lfd.uci.edu/~gohlke/pythonlibs/ (the latter is recommended only if you can't get pip to install the module you need). ___ Developing with python: For starting out I'd recommend sublime text: http://sublimetext.com/ (has unlimited trial) or pycharm http://www.jetbrains.com/pycharm/ (has free community version). You can run the scripts you create from those applications themselves or you can run it via command prompt by typing `python name_of_your_file.py`. 
As /u/iarcfsil pointed out, consider using 32-bit version of Python.
Unless you *know* you need the 64bit version of python you should go with 32bit regardless of what your OS uses.
Thank you !
1. There are users of Python 3. I myself am one of them. There are much fewer users of Python 3 than Python 2. I don't think anyone disagrees with it. 2. You misunderstood that statistic. It isn't the number of python 2 vs python 3 libraries people are downloading. It's what version of Python they are using to download the libraries with (using pip). Again, are you seriously arguing that there are more Python 3 users than Python 2 users at this point? 3. RHEL and (the current) version of Fedora is using Python 2 as the system Python because there are a large number of tools the distro relies on that is still using Python 2. Fedora *is* making the move to Python 3 (in F21 IIRC) and the next version of RHEL should be on Python 3 as well. Encourage people to move off RHEL? To what? The latest LTS release of Ubuntu is still using Python 2 as the system python. The distro situation will change for the better, but it takes time. Who is tricking who? I doubt you watched the video to the very end because he does encourage people to move to Python 3. 
This is an unkind comment on a great talk from a great leader in the Python community. Whacking himself off? Dismember? Man you need to grow up and get some manners. Why is it ok to say things like that?
Great write up. I started playing around with 0MQ about a year ago and have nothing but good things to say about it. The software is great, the support in IRC/mailing list is great.
&gt; Library maintainers have to double their efforts to support both Python 2 and Python 3 (at 21:15) This doesn't have to be the case, and is generally not the case. Projects can support Python 2 and 3 from a single code base with very little overhead, and that seems the best development approach to cover the widest possible user base. Of course, there might be some big blocker projects (dependencies) that involve a lot of pain to port from where they are now, but that doesn't justify the generalisation made in the presentation. People who keep hand-wringing about "splits" are seeing things in an "us" and "them" way, but it isn't like that for everyone. In my work, I use Python 2 for some projects, Python 3 for others, and write 2/3 compatible code wherever possible. I can't say it's made a dent in my workflow. Python 2 remains perfectly usable and will continue to be so far into the future. I've never felt coerced to use either one version or another - it just depends on where a project has to run, status of dependencies, customer preferences etc. - just use what makes the most sense to use in a particular context. To characterise the Python core developers as being in some sort of ivory tower detached from the community doesn't seem right, either. They just happen to be volunteers who choose to focus their main efforts on 3.x for reasons exhaustively covered elsewhere, but ISTM that 2.7 remains a supported platform where more than the bare minimum of effort is being spent. See the [Mercurial log](http://hg.python.org/cpython/) showing recent activity on Python 2.7.
&gt; The only real reason to stick with Python 2 is religious dogmatism That's just plain wrong. 
I think there'll be a tipping point soon and Python 3 will start to really take off and Python 2 will start to feel very old. With the massive library support now available for Py3 there's not much reason to stick with Py2 any more.
Please don't assume python 3.4 in the small print at the bottom, it's annoying. State it clearly right away.
Doubling is probably an exaggeration. I do write libraries that support both 2 and 3 whenever possible. It really depends on the type of things you are doing though, some things can be as simple as a `__future__` import but some things do require considerable work. I can't remember if he mentioned it in this particular session but I was at another talk on the same topic by Kenneth where he mentioned that he only needed to do the "port" once for Requests and that's it.
Yeah, I think the crossover between machine learning and data analysis is that machine learning involves a lot of data analysis but not all data analysis involves machine learning.
OP here. Thanks for the suggestion, I'll update the article to reflect this.
Any packages in particular?
nit: "non-commutative." Algebraic structures can be Abelian or non-Abelian. Operators commute or don't.
great video on that subject: http://www.youtube.com/watch?v=C4Kc8xzcA68
[Changelog](http://hg.python.org/cpython/raw-file/v2.7.8/Misc/NEWS)
You could reduce lines by printing newlines as \n :)
2.7 will continue to receive bugfixes until 2020.
On point 3), you have no idea what you are talking about. Not all business users rely on RHEL (or on Linux, for that matter). Business users normally have a large code base built over the years and they don't see the point of spending time and resources to migrate such huge code to the new language in town, no matter how better it is (especially when it's not so much better). Because properly migrating costs money, loads of money, if you work with large applications and you have hundreds / thousands of clients that use (and maybe in turn customize) such applications. I'm getting really sick and tired of all these Python 3 advocates (mostly amateurs, apparently) who seem to have never worked in a commercial environment, where you need to make money to survive and you can't set aside man-months just to move to the latest fashionable thing. Taking a deep breath, now... 
some rules in PEP8 are good. other are nitpicky that even the python 2.x/3.x do not follow.
Really? Not moving to 3 because of legacy code in 2 is understandable but to say 3 isn't stable seems pretty ridiculous.
Python has a floor division operator (//) so int((tg/m)*100)/100) can be written as (tg/m)*100)//100
It's the internet - it's normal to get this sort of reactions from reddit. The intro of the presentation is eye-ball-rolling inducing. Overly pompous. In other words, grow the fuck up you prude bastard ;)
[citation needed]
3.x is stable by all definitions of the phrase. Maybe what you meant has truth in it, but how you said it, it's plain wrong
Yeah, I could maybe agree with that regarding people who keep starting projects in Python 2 by choice, but there's plenty of valid reasons for using 2 that don't involve blind dogmatism. 
No, hote2oscar is right. It will only throw a syntax error if the indentation is illegal. This: if is_accepted(launch_code): print 'Launching missle' launch_missle() Is very different than this: if is_accepted(launch_code): print 'Launching missle' launch_missle() Both are valid code, so neither will throw an error, but the difference in their behavior is nontrivial. 
I remember a few years ago I was trying to get the scipy stack installed on my Windows machine, and just gave up after an hour or two of frustration. 
I'm sure this will be useful to many people, especially the Twisted types, but the article is written like this is the first time async requests have ever been supported in a Python web framework. Flask supports Tornado, gevent, and even Twisted Web, as does most every other framework.
i echo this sentiment but this continues to be the message from fortune 100 companies.
Flask can run on a background threadpool under Twisted (and others) since forever, but that does _not_ allow you to actually use asynchronous code _within_ your Flask request handlers. This is possible with Twisted Klein, but not with Flask/Twisted (using WSGI Resource of Twisted Web). Should we make that distinction clearer in the blog post?
Do you have an example of what a really boring scraper readme would look like? Because that's about all this thing does is scrape repeatedly.
Perhaps. Sorry, Flask/Twisted is not a combination I use (I prefer bottle/gevent), so I wasn't aware of it's limitations.
If this just keep getting better and better at this rate...i might not need any other IDE in the future! 
In pretty sure that's what's meant: People use Python 2 if they have to or reject Python 3 out of religious reasons.
Are you referring to: http://bottlepy.org/docs/dev/async.html ?
That demonstrates how I use bottle, yes.
more info: http://en.wikipedia.org/wiki/Long-term_support
Last time I tried this is brought my laptop to its knees. It makes Eclipse (my normal IDE) seem lightweight.
Didn't 2.x account for like 95%+ of downloads on pypi few months ago? Edit: substring | percent_of_total_downloads -----------|---------------------------- 2.7 | 75.533% 2.6 | 15.960% | 5.840% 3.3 | 2.079% 3.2 | .350% 2.5 | .115% 1.1 | .054% 2.4 | .052% 3.4 | .016% 3.1 | .001% 2.1 | .000% 2.0 | .000% January 2014, data from: http://alexgaynor.net/2014/jan/03/pypi-download-statistics/
Some of us can't move to 3. Heck, we just upgraded production fro 2.6.x to 2.7 a few months ago. Not enough developers to work on a 3.x port for this application.
Hey, thanks for the code. I noticed one thing. Certain URLs, after putting it through the requests function return intermediate and final (landing page URLs). Sometimes, I have a shortened URL, say t.co/&lt;something&gt;, it will return the final landing page, say http://www.classicsradio.org/ (One of the URLs I tested). But, http://www.classicsradio.org/ gives me a status code of 301 (permanent redirect), and redirects to http://www.classicsradio.org/RadioStation/Home.html (when I manually resolve it in the browser) which is not captured by the code. Even if I enter http://www.classicsradio.org/ as the original URL in the code you gave, it does not return http://www.classicsradio.org/RadioStation/Home.html as the final page, it returns nothing. Is there a way I can capture all true landing pages? None of the final URLs should have a 301 status ideally. Thanks for all the help.
Great list. Is it going to be on Weekly?
Add Github integration to the list. I've been using PTVS with Anaconda for a while now, It's quite nice. If you haven't played with VS in a long time, I'd recommend checking it out. This may seem trivial but for me it's compelling.. Dark Theme, PTVS does this well. Not just the editor but the entire Application has a very well integrated dark theme. On the down side, unless you have a fairly powerful machine PTVS can seem bloated. I'm just guessing but I'd say don't bother on anything with less than an i5 and 4GB of RAM.
Damn you google python api, oauth and boto!
The only things I noticed which were more Django than not were CMS packages, which sensibly are tied to Django. A CMS in Python needs to be on top of some sort of web framework.
Oauth? Requests has an oauth module that works with py3
[actual question] What does this have over eclipse?
This is cool, good job. 
Everybody on RHEL/CentOS 6. Government, banks, insurers. 
That doesn't mean it's not stable, it means that they're not willing to allocate the resources to port all the legacy code.
Where can I find the list of SSL ciphers in my python install?
What error message is being thrown when you try to install lxml using pip on your python 3.4 venv?
If you run Flask/Twisted, then Flask will run on a pool of background worker threads. To call asynchronous code (which is running on the main thread) from Flask request handlers, you can use `callFromThread` (http://twistedmatrix.com/documents/current/api/twisted.internet.interfaces.IReactorThreads.callFromThread.html) - but that doesn't _return_ anything. You need to do more: http://twistedmatrix.com/pipermail/twisted-python/2003-September/005725.html And then, even if you do so, your background worker thread (Flask) will keep sitting idle while it waits for the result. So we are back at the original problem: as soon as all background worker threads are all waiting for results, no new Web requests will get served anymore.
It seems weird though that 16% still run 2.6. I would think they would be somewhere around 2-3%
Excellent post. I wasn't aware of this behavior.
We just switched 3 months ago to 2.7
Turns out it was this &gt;error: Unable to find vcvarsall.bat That is some compiler issue but a compiled version at http://www.lfd.uci.edu/~gohlke/pythonlibs/ worked just dandy. 
We've had more downloads of Python 3 itself for quite some time now: http://ianozsvald.com/2013/04/15/more-python-3-3-downloads-than-python-2-7-for-past-3-months/
There's absolutely nothing about Python 3 that would give anyone a "perception of instability". Nothing. It's 6 years old already, for goodness sake. What observation could possibly lead anyone to believe that Python 3 wasn't stable?
&gt; You overestimate the resources of organizations. I was just relating my own experience. I run a small consulting company, and that's pretty resource limited! Python 2.x support is not primarily about back-porting features - Python 2.7 bugs have generally been fixed as normal, though there was a moratorium for a time in certain areas (e.g. distutils). Obviously if Python 3 support is low on the priority list for the developers on your project, that's up to you. I've generally found it takes more time to port the tests for a library than it does for the library code itself :-) 
Your posts seems well-considered except for one detail: there's nothing about 3.x that hints to instability in the slightest. Its deprecation and versioning is exactly the same as 2.x. There's no single `__future__` import as of 3.4, so a potential Python 4 isn't even prophesied. 3.x is at least as stable as 2.x, anyone claiming elsewise is delusional.
No?
Hooray for figuring things out and boo Windows! In all seriousness glad it's working for you.
I was aware of the gotcha but this post helped me better understand why it happens. Great read all around.
I think that's more of a self-fulfilling prophecy though and isn't really indicative of anything. Everyone is using 2.x because everyone hears it's what everyone's using.
"All of the other businesses in $OUR_FIELD are still on Python 2, so there must be a good reason!" This is ridiculous logic, of course, but it's how they think.
Does this mean Flask cannot do AJAX ?
Of course Flask can serve incoming Ajax requests. The issue is when you want to do outgoing Ajax requests from within your Flask request handlers: Browser ==&gt; Ajax request ==&gt; Flask request handler ==&gt; Ajax request
i thought boto was available in p3
that reminds me.. need to register for this. 
please do, let me know if you have any questions.
This is not the proper subreddit for this type of question. This community is for news about and the discussion of Python as a programming language, and things related to it, not for basic questions about learning Python. You should post this question in /r/learnpython. There are a multitude of free resources on the internet dedicated solely to the furtherance of Python education. You should have a look at those, and do some of your own research, rather than immediately asking someone else to do your work for you. Assignment is one of the most basic aspects of programming. Try to figure some things out for yourself.
 &gt;&gt;&gt; arb = 42 &gt;&gt;&gt; enter = arb &gt;&gt;&gt; arb = 0 &gt;&gt;&gt; enter 42 &gt;&gt;&gt; arb 0 
He never said it wasn't stable. He said the general message is that it's not stable. :S
What? /u/nomadismydj said that it's not CONSIDERED stable. Not that it literally isn't unstable. That doesn't seem at all vague to me.
Ok and what is your reason for not switching? Also how is Python 3 hip when it's been out for six years?
ok, i'm sorry. i just started learning python 2 days ago by the way, it isn't basic for me.
thx
Papering over every possible reason with "religious reasons" does not a compelling argument make.
From what I can see, the support means only that you can get flask serverd as a WSGI app with these. It won't make it magically asynchronous (except for gevent monkey patching, but it requires to install a C extension). But I see your point, Klein is hardly the only available solution to make async Web dev on Python. Actually, tornado even has some flask like API example somewhere.
Perversions for fun: &gt;&gt;&gt; def down(a, b): ... return a // b ... &gt;&gt;&gt; def up(a, b): ... return -(-a // b) ... &gt;&gt;&gt; down(15, 2) 7 &gt;&gt;&gt; up(15, 2) 8 
You kinda need to tone your rhetoric down. This is what you get with 3: - asyncio support as default - venv support with pip as default - no more unicode headaches just off the top of my head. Also, any and all new features are only going to be added to the 3 branch. If you are starting new, might as well start with the future.
Our clusters default is still 2.4 because its bolted to centos 5.4 due to some driver issues. We have 2.7 available but have to explain the Unix modules concept to every person that uses the system as they join the organization...
Centos 6 / any variants will use 2.6 by default. You can install 2.7 but should likely not make it default as yum doesn't always respond well.
Python 3 support for a few boto modules including s3 just landed on the develop branch today. Change is coming. Help us test it out!
See you there!
Thank you so much for all the detailed help! I did all that and it seems to have worked, I typed "python" in and I didn't get an error message. So if I understand correctly this is how I'd execute the programs I create, by saying "python [name of program]" Is the module you talk about where I actually write the program? And if so, I just type in "pip [name of module" and it'll know to install that module off of the internet? I guess I'm still kind of confused. I don't get how you all know this! How did you learn all this stuff? 
Major work in progress
it is a philosophy of living for TODAY or for the FUTURE.
For large applications, sometimes it just doesn't make business sense to port the code to a new major language version. Heck, there is still old COBOL code around for exactly the same reason. Sometimes it just doesn't make much sense.
Are those enterprise establishments living in 2008?
If you want to grow with the language you are going to have to use Python 3. That is all I am saying.
A 800m VS Express Installer is too heavy for me. But it is convinient for those who have .Net background.
Thanks. I knew support for Python 3 is an issue but I didn't know there was a lack of 64-bit support as well.
How about the fact that support for Python 2 is going to go away and any new feature you might want is only going to be in Python 3? 
makes my eyes hurt
That's pointless. Everything Python 2 can do, Python 3 can do better. The language is growing, why fight it?
 def python27(): n = 8 while True: print "Python 2.7.{}".format(n) yield n n += 1 py2 = python27() next(py2) next(py2) next(py2) next(py2) ... .. .
Maybe not everything. Check this out, http://click.pocoo.org/python3/
What's the pro/con RabbitMQ/Celery(async worker) vs Twisted Klein? Seems like a queue system is a good non-blocking alternative in the backend? My guess is that this is really dependent by application requirements: Does one have control of the client design/complexity??= 
2to3 doesn't fix every issue with a simple run through. Certain things require thought and need consideration on a case by case basis like with StringIO that the script doesn't handle. As apparent in this thread, there are also obstinate people who are being obstinate in not porting for the sake of being obstinate. But I think it's mostly the former.
fortune 100 establishments do in fact live in the past.
Did you watch this? 'Python 2.7 &amp; Python 3: A Sacred Love Story' https://www.youtube.com/watch?v=skYBOXE02OQ&amp;feature=youtu.be It's a bit long winded, but it's quite thoughtful about why this attitude is troublesome.
So it sounds like the solution to the problems he presents is to use the language. His pypi example is a perfect example of a self-fulfilling prophecy. Everyone says to use Python 2.7 so of course it's the most downloaded version. Instead of telling new users to use python 3, everyone's being told to use python 2.7 because that's what everyone is using, which is insane.
Nice job, I like this update. I didn't really notice until now, but I do like the old style arrows. I have 1 comment/request though. Is it possible to make the visited/nonvisited links colors more distinguishable (i.e. #5b92fa from the header instead of #083F91 for the unclicked links)?
Will I'm the OP and work on PTVS so my opinion is properly inherently biased but I'll try to answer. They do have pretty similar feature sets. The big differences to me seem to be that PTVS has: * Better code completion (I'll take the pepsi challenge vs any IDE here) * Find all refs (and probably better goto def) * Profiling * Django template debugging * Azure integration Is missing: * More refactorings * Code coverage * Jython specific support * App engine integration There's lots of small features here and there that they differ by and in some places it seems PTVS is better and in other places PyDev is better.
Sorry to say that i will continue sticking to python+nocss
Embrace, extend, extinguish. 
I liked the old one, and I like the new one. Some people are hard to please. I am not one of those people.
I don't think that's surprising that much, I assume people download it but don't really use it. I know that I download every 3.x release, and in the same timeframe I don't think I downloaded python 2.x more than once or twice, I have it installed - no need to download it. But I never use 3.x for any of my projects. I think that pypi stats are better for estimating which version is used more.
Hey DrunkenPhysicist! I did something similar for a data mining/visualization project that had a secondary interest in exploring Python's data visualization libraries and a tertiary interest in IPython's Notebook interactivity capabilities (note: this was before 2.1 came out... haven't really done much with it since). The interactive Google Maps solution I had wasn't quite as brief as what you had, but it does allow you to use more of the functionalities Google provides in the Maps [API](https://developers.google.com/maps/documentation/javascript/overlays). A lot of what I did was based off of a Continuum Analytics [tutorial](https://www.wakari.io/sharing/bundle/wakari_demo/realtime_twitter_analysis?has_login=False) (as an aside, Continuum Analytics is a pretty great resource for Ipython in particular and Python in general). The solution is a little more involved, passing the IPython core display method complete JavaScript and html code that we hold in Python strings. Everything that I would say in explanation is actually already said in the linked tutorial, so I'll point you to that again, and here is a link to my [project](https://google.com) if you'd like to see that as well (this was the preliminary version of my presentation... not sure where the final version made off to). Feel free to comment if you have any more questions. 
Apart from the fact that ignoring arguments is not my style, and I therefore wouldn't do it, I don't see any pro Python 2 arguments in this thread, so what are you talking about?
* Libraries not being available is a serious issue, on a project I started last week Python3 is /still/ not an option because of missing libraries. * Even if the libraries you think you need support Python3, using Python3 means assuming additional risk, since a library you want tomorrow may not be ported. * PyPy only has 3.2, so none of the reasons in favor of 3.3 or 3.4 are applicable if you care about performance. * Most library's Python3 support is less well tested than their Python2, meaning you're more likely to hit bugs. * If you have an existing Python2 codebase, porting is a giant effort, and almost impossible to justify.
I'm pretty excited about my first Pycon.
which is equal to tg/m\*100//100; no paren needed a\*b/c = (a*b)/c, both in python and in pure math.
You don't need to yield n, just yield the string.
Have you read the relevant docs? http://pandas.pydata.org/pandas-docs/stable/io.html#hdf5-pytables What kind of data are in the files? Were they created with pandas to begin with? What types of objects, what sort of key organization? Do the files have all different keys that you want to stick in one file? Or do you want to append rows within objects? Or append columns? What have you tried already?
 import itertools; n = itertools.count(8) while True: print("Python 2.7.%d"%next(n)) [learn your packages](https://docs.python.org/2/library/itertools.html)
I like this, but op might be running python on windows and not a linux/unix machine.
I can't confirm the first two points. Up until about 2011, you were right. But since then, I didn't need anything that wasn't available in Python 3. And the situation is only ever improving (because if somebody writes a good, useful library tied to Python 2 today, everyone will have their head) PyPy is a valid point, but only for special cases: performance is good enough that you only need PyPy for certain projects (number crunching when numpy doesn't cut it), and asyncio also gives you incredible speedups in other areas (network and disk IO) I can't say anything about testing, only that I encountered an insignificant number of version specific bugs. And finally, I don't think “porting is hard” is an argument against Python 3: either you're an application, then you don't have to port anything, or you're a library, then you have to port anyway, no matter how hard it is.
Formatting isn't all that hard. You should make the effort to add the four spaces in front of your lines so that our eyes don't bleed.
I agree. The whole *point* of closures is that they're affected by their enclosing scope. If you want to create functions that add different amounts depending on what value `i` you created the function with, then make another function that builds this one, and call that builder with different arguments to get different additions. On the other hand, I'll admit that mutable state combined with functional programming can get tough to grasp, and that's why people are confused by this sort of thing in the first place. If `i` were immutable, a new "copy of `i`" would need to be bound each on each iteration of the loop, and past iterations wouldn't be affected by future ones. Then you get the blog author's expected behavior.
Wish I could get to brissy. There will be some vids I guess?
It's better. Thanks.
"great leader" ?? WTF? He's advocating a schism in the python community and that people stick with Python 2 still 7 years after its deprecation. That's not leadership! He's authored exactly 0 PEP's, too, which indicates he is part of the problem not the solution. &gt; Why is it ok to say things like that? My thoughts exactly on this terrible video. 
The core issue here is that only functions have their own scope in Python. In some languages (like Lua and Déjà Vu), each compound statement (so roughly each indentation level) has it's own scope. Sort of, kind of, translating the code snippet to Déjà Vu: barking cls: for name in keys cls: local :func @cls! name labda: !print "Woof" func set-to cls name local :dog_1 {} dog_1!shout: !print "hello from dog_1" barking dog_1 dog_1!shout local :dog_3 {} dog_3!wag: !print "a dog_3 is happy" dog_3!sniff: !print "a dog_3 is curious" barking dog_3 dog_3!wag dog_3!sniff Output: Woof hello from dog_1 Woof a dog_3 is happy Woof a dog_3 is curious That is because each iteration of the for loop gets its own scope, which is kinda expensive, but I try to keep the costs down by caching scopes. EDIT: also, fun fact, if there is no function definition within the for loop somewhere, the compiler only creates one new scope for the whole loop, instead of one for each iteration.
pymysql is slower though 
Nice middle ground, this. Thanks :)
1. Kenneth does in this video! He quite clearly states Python 3 has no users, _after_ conducting that straw poll! Blatant ignorance! 2. You're the one who has misunderstood. There is *no* qualification given to what these numbers are, therefore people are free to invent whatever it stands for. Kenneth claims it means nobody uses Python 3, I can counterclaim using exactly the same evidence. Lies, damn lies, statistics. 3. There's only one system tool that relies on it, Anaconda (the RHEL installer, not Anaconda the awesome Python distro). If they're unable to update one app in the past decade, that they wrote themselves, they have no business making a distribution full of apps fooling businesses into thinking this horrid mess is Linux. The next release of RHEL will likely be around 2020 (every 6 years or so), so what you're advocating is the equivalent of "It doesn't matter if everyone in the world today runs Windows ME" (all jokes aside that that's a better choice than Win 8.1). We'll probably be running Python 4 or 5 by then, so finally having Python 3 support when everyone has long moved on again is just as retarded as "upgrading" to 2.7 in 2014. The entire distribution is fatally flawed and its unsurprising to me its pioneers like Eric Troan left long ago. All that's left are Microsofties like Miguel de Icaza, determined to ensure GNOME stays well behind Windows. Ubuntu may ship Python 2 as well, but you've been able to apt-get install python 3 for 6-7 years now because they have a sensible upgrade path, release management, packaging tool and packaging standards ensuring interoperability. When its next competitor is able to get tested stable releases out in 6 months not 6 years, Redhat are clearly doing something horribly wrong. Not to mention RHEL releases tend to include bugs fixed in previous releases, e.g. 6.5 has bugs fixed in errata from 6.2... WTF? They obviously have NO release management or issue tracking. That's the core reason to abandon them like they have abandoned their users. 
Thank you. Learn to yield.
I am one of the people who didn't like the old new theme. This is a big improvement, I'm going to tick the 'use subreddit style' box now. Good job.
Thank you. It is clean and tidy, as always.
Pro Python is good, but a little dated. Don't think it has the latest and greatest from 3.3+.
Do you plan to speak more about Crochet next time? I haven't use it but it seems it looks like a good solution for people with an already existing code base using Flask or whatever, but who are still looking for a cheap way to do some async stuff.
don't bother, the 2 are totally of different worlds.
Definitely videos and possibly even live streaming as well. Keep an eye on the website for details.
analogy time: Excel == truck, vba == engine. This engine works only when the truck is running, and works ONLY inside the truck, right ? When you the driver get in the truck you want to just start it and get moving right away, right ? Python == Machine shop, has all sorts of machines and engines. Now what do you want to do ? ps: there are invented ways to kind of force the marriage between the 2, but, to me, they just aren't "natural" (but woohoo ! Python &gt; VBA...all is good, right ?) ps: opinion based on experience: been doing VBA since 97, python since 2010 ,none with LibreOffice 
I get a 200 on that page and it's redirecting with a meta refresh. There seems to be some solutions for this on [Google](http://lmgtfy.com/?q=meta+refresh+python+requests), have a look and see how you go. --- $ curl --head http://www.classicsradio.org &gt; HTTP/1.1 200 OK $ curl http://www.classicsradio.org &gt; &lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"&gt;&lt;html xmlns="http://www.w3.org/1999/xhtml"&gt;&lt;head&gt;&lt;title&gt;&lt;/title&gt;&lt;meta http-equiv="refresh" content="0;url= RadioStation/Home.html" /&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt;
don't know what that means, can you give an example ?
Just so you know, EL 5.4 is no longer getting security fixes. The EL 5 series is supported until 2017, but only if you are on the latest version (currently 5.10).
Muuuch better. Thanks.
There is a repo called iuscommunity.org that ships RPMs of python 2.7 through 3.3. They install in parallel with the system version of 2.6, so yum is happy. /usr/bin/python is 2.6, but /usr/bin/python2.7 is 2.7. https://iuscommunity.org/pages/TheSafeRepoInitiative.html#parallel-installable-packages
&gt; iuscommunity.org Cool, sure beats rolling your own python27 package from some half-broken pkgbuild file you found somewhere on UseNet or something! 
In code golf, I love playing with negatives and `sorted`. It's amazing how much shorter such perversions can make your code.
It's not really a crash course in idiomatic python, but the Python Cookbook from O'Reilly is pretty good. Most recent version is python 3 only, though it isn't a far leap to backport anything.
pyodbc? sqlite? are these options? 
It's not even that functional an idiom; it's just returning closures. I think part of the problem is that python doesn't make variable declarations explicit, so it's not clear what exactly the closure is closing over. For example, the following scheme code has the same issue: (define (make-thunks n) (let ((i 0)) (do ((fs '() (cons (lambda () i) fs))) ((&gt;= i n) fs) (set! i (+ i 1))))) There, however, it's pretty clear you're closing over the same binding for i, as compared to: (define (make-thunks n) (do ((i 0 (+ i 1)) (fs '() (cons (lambda () i) fs))) ((&gt;= i n) fs))) where you make a new binding every time. That's one reason I still like scheme for educational purposes.
&gt; Whether you are accepted as member or not is arbitrary and the decision is made in an even more arbitrary process by the members of Metaflask. Rejections can be challenged by flamewars on the closed issue. meh. edit: Let me clarify ("meh" wasn't as explicit as hoped), it sounds like a good idea but if you want to be taken seriously, well... act accordingly. This sounds like a bunch of flask fanboys are trying to be the big guys. Sorry for the lack of humour I suppose.
You can use threading, you should just not expect a performance boost from it, since your threads will all run on the same CPU core.
Think of a meta-search engine, like kayak.com. The end-user sends kayak.com a request: “I want a round-trip flight from New York to Las Vegas for the first week of August.” Then kayak.com’s back end sends the same request to a bunch of other travel sites, collates the information from them, and returns a page to the original user.
Ah. Missed that. That makes it much less likely, but not impossible. Depends on what the next line is. I write Python, so I'm not really that bothered by it. It's just reasonable to point out that the lack of an explicit scope-ending marker has consequences. Of course, chasing down which brace you forgot to close is it's own barrel of monkeys. 
This implementation is a "correct" implementation. It uses finite state automata rather than backtracking. The actual speed depends on the input parameters. For several non-trivial patterns, the python implementation is leaps and bounds faster than the C implementation. However, for most usecases (as I stated in the README) the standard implementation is better tested and probably more suitable.
To me that looks just like a regular text editor (probably Sublime or Atom) with a Shell running the script on top of it. You can get that behavior with any Python IDE (IDLE, PyCharm, etc) or just something like vim/emacs and a regular shell.
Technically it is, since O(n) ⊂ O(2^(n)) where O(n) ist the complexity of matching a string with NFAs and O(2^(n)) if you use backtracking. Because of this the (constant) overhead of using a interpreted language doesn't matter, but of course that's only true if you are matching strings of (near) infinite length. For short and not complicated patterns and short strings the re module should be faster.
For my day job we constructed a system that had a mixture of Flask/gevent and scrapy/Twisted, and after struggling with it for about a year, we replaced it with something that uses Flask/gevent from end to end. (The Web-scraping work that was previously done with scrapy, we now do with grequests.) The Twisted model of “create a Deferred object and attach callback/errback functions to it” led to code that was much harder to understand and debug than the gevent model of “spawn a greenlet thread and use IPC-like syntax to communicate with it”, and having both of those systems in the same app just compounded the pain.
Thanks for the clarification, I just got the impression from your last paragraph in the README that it was generally faster than the `re` module. Very interesting work!
I understand this but I was looking at Python less broadly, and instead as a language to be used behind Libre Office, in the same way that VBA would with MS Office. I don't want to combine the two in anyway. To be honest, this wasn't my idea. It was suggested as a solution to a compulsory research project and it seemed suitable for me due to my interest in computing and programming languages. If you all think there is little point I may have to go back to the drawing board 
The idea behind it was actually to compare them when used with MS office or with Libre office, to see whether the backend of freeware that many people are beginning to use is suitable to replace that of the paid software that the majority of users are familiar with.
~~If you use vim with the jedi-vim plugin you can press K on top of a function to see its documentation.~~ If you're new to programming you probably should just start with IDLE, as much as I love vim it's a little overwhelming at first.
Thanks I'm kinda new to programming and when I wanted to try it out in python it was working as well as it was when I used codecademy.
...Unless your problem is I/O bound, in which case it can be a useful tool. One example of where it might be beneficial: -requesting a number of websites (and waiting for each in turn
Yes, I am planning to write another post on Flask/Crochet/Autobahn. I agree: they both (Klein and Crochet) have their use case.
I do not think that what you are saying is correct. Python is happy to make a call tree if you use the correct syntax. And static analysis has nothing to do with it. Many very dynamic languages support full closures. Edit: add example from string import lowercase, uppercase def count_nums(): funcs = [] for i in range(0,10): def count_alpha(i=i): for j in range(0,10): letter = lowercase[j] def count_alpha_2(i=i, letter=letter): return "%s.%s" % (i,letter) funcs.append(count_alpha_2) count_alpha() return funcs everything = count_nums() for func in everything: print func() 
Haha thanks for that. 
How do you use asynchronous code from Flask using `deferToThread`? `deferToThread` works the other way: it allows you to run blocking code from asynchronous code.
I start thinking that having Python 2.7 as the last version of the 2.x series is actually a good thing. This will make for a very stable language without new versions coming out every few months and most of the new stuff can be backported as external packages anyway. So we can finally focus on using the language to build something interesting and useful instead of constantly catching up with the latest version just to make core developers and assorted zealots happy. 
I'm looking for some as well, but I can share some decent-to-good stuff I've read recently: **Python Pocket Reference 5th edition** - pretty useful at any time of the day. **Mastering Python Regular Expressions** - regex is pretty much mandatory if you're working with any kind of string data and it's a really detailed book regarding this subject **Python Cookbook** - like pocket reference has some cool recipes that can teach you a lot. **Writing Idiomatic Python** - How to code in a pythonic way, mandatory read for any python programmer in my honest opinion. The author also offers it for [free](http://www.jeffknupp.com/writing-idiomatic-python-ebook/) if you're not in a financial position to afford it. And of course **Dive into Python**, if you haven't read it. All other stuff is pretty much depends on the subject you want to learn, so it's hard to recommend that stuff. Cheers!
This is awesome, great work! In addition to being theoretically interesting and potentially faster, this excites me because it could be used by MicroPython, PyPy, Brython or other alternative python interpreters in cases where a C extension is difficult to port.
It's not the same usage, and both are complementary: - you will use an task queue for long blocking tasks, usually usualy with no need for feedback - you will use asynchronous web framwork to save requestions without paying the price of commun IO blocking operations doing so
Just last week I need a scriptable SSH server, instantly limiting me to Python2 only. PyPy is my default python, I don't throw away big performance gains, I want my software to be fast by default. Consider: just the other day a friend of mine was load testing the ability of various websocket servers, he needed to hold open at least 70,000 sockets. In his own words: "CPython fell over almost immediately, we'd never have been able to build the project on it." PyPy just worked up to like 200,000 sockets.
https://github.com/axiak/pyre2 should be mentioned - it is a wrapper for re2 C++ library which also uses NFAs (in fact, the link on the top of redone repo is a description of re2 library). The pyre2 version on pypi is horribly broken, but the version from github works well, and it is almost a drop-in replacement for standard re library. With pyre2 I've seen 1000x speedup over standard re library for regexes which have a lot of ORs (in a parser for Adblock Plus rules, https://github.com/scrapinghub/adblockparser). For usual small regexes it worked at ~ the same speed as stdlib version, maybe somewhat slower. 
Java 8 lambdas require captured variables to be "effectively final", which is pretty much the same, just makes the `final` keyword optional.
The author blames closures for the bug, but I see it as a bug with for-loop scoping. Python's for-loops have enclosed persistent state; stuff that happens in the for loop doesn't leak out (except into an `else` clause if provided) but does maintain state during looping. This is usually what you want in Python, I feel, but when you enclose that scope *bad things*(TM) can happen. I posted this to his blog, not sure when/if it'll emerge, but it works as intended. Making a decorator outside the for-loop fixes the scoping problem, and the output is fine. def barking(cls): def woofit(func): def woofer(*args, **kwargs): print("Woof") return func(*args, **kwargs) return woofer for name in cls.__dict__: if name.startswith("__"): continue func = getattr(cls, name) setattr(cls, name, woofit(func)) return cls
O(2^(n)) is the worstcase asymptotics for backtracking, but what's the average case?
so now you're talking about replacing the truck (excel) - one you have to buy - with the machine shop (let's say free from inheritance) ??? So what next - uninstall Office from user system and install Python ???
You say "correct", you mean "fast", you provide no benchmarks. later edit: feel free to use [the ones I collected](https://github.com/stefantalpalaru/morelia-pcre/tree/master/benchmarks).
Read the link provided on the Github header.
This sounds like an exciting research project (one that I would LOVE for my company to undertake, though the reality is that they never will; though I might be intrigued enough to do some research in my spare time anyway). I don't have need of an office suite, so I don't have any experience with this, but I did find [this wiki page](https://wiki.openoffice.org/wiki/Python_as_a_macro_language) while poking around the web. I hope it's helpful to you. Good luck! And please come back and post your findings once you've made some headway.
You can't write macros for Excel in Python. Excel only supports visual basic for this. Python has lots of great libraries for manipulating csv and xlsx formatted data, but you would do it in the Python interpreter directly, not embedded in Excel.
I've gone back and forth on that font size about 12 times. I think you're right though - it should be a touch smaller... ... or should it? ... Yeah, I think I'm going to put the size back down. The grey lines between links were one of the primary complaints from before. They ended up making things look very un-reddit-y and one of the things I was going for was a reddit-crossed-with-python.org kind of look and feel. That said, I personally like to have my links nicely encapsulated, but it seems that the more popular opinion is to keep the reddit norm.
&gt; Just last week I need a scriptable SSH server, instantly limiting me to Python2 only. [paramiko is ported](https://pypi.python.org/pypi/paramiko/1.14.0)… fabric isn’t yet, but i think paramiko was the hard part, and it’S sufficient for many SSH tasks. and about PyPy: that’s another corner case. 70k sockets isn’t normal usage!
Absolutely no docs on how to run a server. You'd be amazed how many people are moving to languages like Go because they have that use case. (Pro-tip: writing off every single use case as "not normal" isn't very persuasive...)
ok, please explain when 70k sockets are the sane solution to a problem.
Wouldn't "act accordingly" = "trying to be the big guys"? Your comment lacks coherence. It sounds like they don't take themselves too seriously and they're being realistic about their informal governance structure (which may end up being more effective than say, w3c).
Everything has to start small. At the moment there are no rules for joining other than that a member needs to have a sponsor which is sortof responsible for the person to not screw up the repository. It's an informal web of trust. Nobody tries to be a big boy here. This is an attempt to fix the problems that currently exist in a more structured way.
&gt; \#5b92fa from the header instead of #083F91 for the unclicked links A number of people reported specifically hating #5b92fa as a colour choice, but I've also found that since I've moved from my well calibrated monitor in one location to another monitor that's more of YOCO (you only calibrate once) it's really not enough colour contrast.
[The Python Standard Library by Example](http://www.amazon.com/Python-Standard-Library-Example-Developers/dp/0321767349/ref=sr_1_1?ie=UTF8&amp;qid=1404402037&amp;sr=8-1&amp;keywords=python+standard+library+by+example) by Doug Hellmann is a great way to get you more comfortable using the various modules in the standard library. I believe the book was inspired by a series of blog posts Hellmann previously wrote each week on Python topics called [Python Module of the Week](http://pymotw.com/2/). Both the blog and the book itself present the material in the same way - basically, each chapter or blog post covers a specific module in the standard library with examples of how to use its key features.
So how significant are the changes in 3.3+? Is it minor changes in language structures and updated standard lib or changes that will change how you write Python code?
When I said "correct", I meant "correct". I never claimed that it is generally faster (although it is much faster than the `re` library on certain "pathological" regexes, an example can be seen in the `tests/bench` directory). If you look at the link at the top of the page, it explains the benefits of NFAs -- there are *no* "pathological" regexes for finite state automata. From that angle, this implementation is correct -- it uses the correct CS solution for the problem (NFAs).
That sounds really useful. I will take a look. Thanks!
Perhaps `ptrepack` can help you out? [link](http://pytables.github.io/usersguide/utilities.html#ptrepack)
[Go on.](http://www.youtube.com/watch?v=vG7aB08r9Xk)
Or the bar height a touch larger. It seems like you made the font size smaller--that looks fine. This is a minor point of aesthetics, though, but could you raise the position of the text 1-2 px more in that bar, because right now the words have more headroom than bottom room, and it looks uneven. Having them vertically centered would look a bit better. I can't recall if the grey lines were thick or thin... They should be quite thin and unobtrusive if they are there at all, but I am one who prefers visual separators for the posts.
Note that the problem you're solving is different to the re module; the re module couldn't use NFAs (or DFAs, or what-have-you) as the grammars described aren't regular.
You'll find [everything you need to know about the GIL on this page](http://www.dabeaz.com/GIL/). Basically only one thread can "own" the Python interpreter's internals at one time, and that is enforced by a lock. This only applies to the Python interpreter's specifics: creating new objects, garbage collecting objects, linking one object to another as in setting a dictionary value or attribute, etc. Creating threads in Python will indeed create an OS-level thread with all the privileges and benefits that confers, but if two Python threads are trying to do something with the object system at the same time, there will be contention. Read those slides for a particularly pathological case of how threading can potentially slow down a script in Python. However, many things in CPython occur in C, where the Python interpreter/garbage collector is not needed at all. When you do things like read from a file, or open a network connection, or do a `time.sleep`, there is no need for the C code to hold the GIL, so it will usually release it. Down in CPython the standard pattern for a function implementation is like this in C-like pseudocode: PyObject* some_function(PyObject* self, PyObject* args, PyObject* keywords) { some_c_variable = Process_Parameters(args, keywords); Py_BEGIN_ALLOW_THREADS // Release GIL return_code = run_some_long_running_C_Function(some_c_variable); Py_END_ALLOW_THREADS // Reacquire the GIL if (return_code == FAILURE) { PyErr_SetNone(PyExc_RuntimeError); return 0; } else { PyObject* return_value = make_object_from_code(return_code); return return_value; } } That is, when the interpreter does some potentially long-running operation it will release the GIL so other Python workers can acquire it and run.
This is patently incorrect. They are genuine OS-level threads which can (and often do!) run on other cores and can be given CPU affinity.
Yea for our cent 6 installs we run 'Springdale' (formerly PUIAS), the package maintainer for the variant makes /opt variants of different python revisions available with a simple install command. Very handy, but if we ever have to move to vanilla / scientific linux we will definitely be utilizing this, thanks for the info.
Self selection and then slowly scaling up by adding rules.
Try out IDLE, it comes with Python. It'll get you started, and has zero configuration. You get an interactive prompt, and you can also create/edit/save and run Python files. You'll be able to experiment with the interactive prompt, and you'll even get to check out all of your objects at the prompt after you run your file. When you want more sophisticated tools, a programming text editor like Notepad++, Scite, or Sublime Text is the next step up. You may have to configure them to point to wherever python is installed and some other minor things. These tools will have features like extended syntax highlighting, collapse/restore nested code, maybe text auto-completion, theme-able to look nice and dark like your screenshot. IDEs (Integrated Development Environment) are a step beyond that, usually including an integrated debugger that allows you to pause your code at breakpoints to examine the program state. They also have features and tools useful for managing many Python files that work together - and tons of other features. IDEs are pretty sweet, but will have more of a learning curve if you've never used one before. For example, in order to fire up an IDE to try something out, you'll have to create or have a project ready to go first. Not a big deal, but an extra step with many choices that really aren't relevant to trying out a new thing, unlike IDLE where you can get going just by opening the window.
Yeah, with CSS enabled I see 4 comments, while without custom CSS I see ~6. Everything, font, margins etc seems larger - maybe too large... With CSS: http://i.imgur.com/FNUaovo.png Without: http://i.imgur.com/08rBxdf.png
Ah, I see, it was just DH2: http://www.paulgraham.com/disagree.html Meh
It could at least use NFAs for the regular subset (which almost all of the regexps in practice are).
Running on OSX. Required GraphViz (brew install GraphViz) for the dot executable. I'm getting this error: Traceback (most recent call last): File "/usr/local/bin/pycallgraph", line 26, in &lt;module&gt; exec(__file_content) TypeError: expected string without null bytes Is there something I should look for in my file? 
Here is the Code, its interesting to experiment with different values! http://www.wepaste.com/sincode/
After reading your comment and reading up a bit, you are completely right! I always seem to have misunderstood the GIL. Thanks for the correction :-)
http://www.jetbrains.com/pycharm/download/ Try this one, it's IMHO a great IDE.
Oh yes, I understand that. And to be honest, our application will probably stay on 2.7 until it dies. We're slowing looking to move off of older Django versions first...
This is awesome. Thanks for sharing! EDIT: A few comments: * json.loads imported the file as unicode, which occasionally caused errors. yaml.loads fixed this though! * The legend.fancybox = True property isn't working for me. Adding a legend.frameon = False in the JSON file fixed that. * Might want to add a leged.loc = 'best' property in the JSON file for better legend placement. * Perhaps you could add a font.family = 'Helvetica' property? For folks who don't know how to change it and hence might be stuck with the ugly Bitstream Vera Sans. Immensely grateful for this, thanks a bunch! :D
I've had some experience with both VBA and Python in my last internship. I initially used VBA to create Excel macros but moved to Python. If you are fine with writing in VBA and need that direct access to MS Office, go for VBA. If you want a sane language that can do more than just MS Office, use Python. The major issue with Python is that it's a bit annoying to interface with the windows api, but there are several tools that can help you with that. VBA to me has really weird quirks when I tried to use it. One such quirk was that I couldn't search cells until I selected them. So all in all, it just felt unintuitive to work in. But if you find VBA good for your work, might as well write in it.
Man, either you are close minded or just ignorant. They are using Excel + VBA (shareware) and want to check if moving to LibreOffice + Python (freeware) is a possible/viable solution, hence they need to compare if they can rewrite their VBA code in to python.. The question of install/uninstall is an operational issue which is nothing to do with the question. If they managed to install MS office, they will be able to download python.
If they thought they needed 70k sockets, who are you to decide for them? The guy mentioned load testing, so they may have had their good reasons for that. And the point is that Python 2 with PyPy solved their problem immediately. End of the story. Had they switched to Python 3, they would have had to spend time looking for another solution, if any. What's wrong with these Python 3 supporters always telling other people how to run their business? Plus, corner cases are a big reason why so many people are wary of moving to Python 3, since sooner or later you'll hit one of these cases where you sorely regret dropping Python 2.
well, let’s just hope PyPy is version-bumped soon.
I'd add one more point to CPU-bound: * Figure out a way to do it in numpy You get closer to the metal, you use less memory, and most numpy operations work outside of the GIL.
I've read these and enjoyed them: * [Foundations of Agile Python Development](http://www.amazon.com/Foundations-Python-Development-Experts-Source/dp/1590599810) * [Learning Python Design Patterns](http://www.amazon.com/Learning-Python-Design-Patterns-Gennadiy/dp/1783283378) * [Mastering Object-Oriented Python](http://www.amazon.com/Mastering-Object-oriented-Python-Steven-Lott/dp/1783280972) 
You're so overcomplicating this problem and I get it. It seems like staying in good health is really complicated, but it's not. There's such a disconnect these days between what we should be doing (eating healthy, exercising, sleeping enough, not watching TV late at night, minimizing stress, getting out into nature, meditating, getting some sun, playing, eating fermented foods) that it's not a huge shock that our bodies freak out in bizarre ways. I had 5 chronic diseases by age 29 and was rapidly falling apart. I was 5'10" and 115 pounds, so on the skinny side for a guy. Then I changed my diet, a few lifestyle factors, and everything got better and fast. I had 10 food intolerances I tracked down and gluten being the worst. It wasn't even hard to figure them out once I realized I should look for them. Watch this and then get your wife to watch it. https://www.youtube.com/watch?v=KLjgBLwH3Wc If you have any questions on more specific things, I'm more than happy to help, but writing a health program isn't going to solve her problems. You need to blame some foods and probably ones she eats a lot of, get her to cut them for a few weeks, reintroduce them, and see how things go. If she reacts, wait a few more weeks and try again to confirm.
Yeah that's what most people expect, indeed what I would expect as well before looking into it. To my knowledge there's not much out there with a similar goal in mind, besides maybe components of larger packages that focus more on instrumentation and stimulus presentation, etc., are designed for non-programmers, and probably can't handle moderately complex designs.
Can you provide a real sample of the data you are referring to?
 Not suitable for programmers under the age of 3. LOL :)
For the time being it's just going to be notes (some handwritten in a log book, some on her phone) - I will normalize them to structured data later (the exact structure TBD based on what I learn in this thread). But it's basically a time log, e.g. * July 3 0920 - slept: 8 hours * July 3 0920 - pain: 1/10 * July 3 0940 - food: 1 ensure * July 3 1020 - pain: 4/10 * July 3 1300 - nausea: 8/10 
Idiomatic python by Jeff Knupp definitely matches what you described. Pick it right away!
I'm reading [The Quick Python Book](http://www.manning.com/ceder/) right now, which aims at programmers which already have some experience. I'm half through and so far I like it, although it could be even more condensed.
Yeah, that's what I meant, but the name always escapes me so I chose the first thing I found on the website. Edited.
Thanks for the thorough answer! So one intervention at a time is intuitive and reasonable enough, but I mean, there's a lot to go through. Like you say, it can take a month or more to get a stable "reading", and I can think of 12 more or less equally likely interventions to try just off the top of my head. It's also almost certainly going to be more than one factor that ends up working, and there just doesn't exist a 100% safe "baseline" diet to work backwards from (or towards, removing one thing at a time). Eggs are usually fine but are relatively high in fat (which is actually one of the more likely causes). You can't live off just white rice. Ensure contains both milk protein and soy. Maybe we can find a handful of things like egg whites and white rice cooked without any fat but, I mean eesh, that's really harsh for any extended amount of time. So if there's a way to even just make an educated guess based on less restricted data that would minimize the amount of time she has to spend on extremely limitations, that is time well spent IMO. But hey, if there isn't there isn't - maybe egg whites and rice start to look appealing when you can actually function. Either way, thanks again for your answer :)
That only works for syntax changes, so for all practical purposes, you asked for Python 2.6. ;-) The other differences are differences in API's and how objects behave. So a Python 2 program would still have to deal with Python 3 objects, etc. 
There will probably be a Python 4, but there will be no huge backwards incompatible changes.
Your recent changes make it better, thank you!
Sorry, what? You're not even making an effort to read my comments, do you?
You seem upset over this, go for a walk or something.
also, OP's problem is that I don't think OP is familiar about these app's automation methodology. So he has 2 uncertain paths....
Let me expand a bit on this: multiprocessing.Pool() and multiprocessing.pool.ThreadPool() these two have very similar interfaces. You want to use Pool() for cpu intensive tasks and ThreadPool() for I/O tasks. 
Note that installing this tool on Mac OS X set a boot-time flag that will break the Junos Pulse VPN client. [Here's](https://github.com/apenwarr/sshuttle/commit/4c1a505e37f6a0c59acfd347c290ab9d3258f6a7#diff-51c439c9de601e9e57eeb7c2658a404eR277) a reference to the commit that introduced the issue. 
Ensure is not going to be doing anything good for her, she may as well drink soda. Processed foods were born because of an excess supply of raw foods, shelf life and 'value add' profits - not because people demanded cheese whiz and protein powder. Think about that. Take a look at the 'SCD Diet' (http://www.breakingtheviciouscycle.info/). Your wife can make preparing healthy meals from whole foods for the both of you her day job. It's tough going at first but I work a demanding job and so does my fiance - we manage it.
&gt;You might as well compare JavaScript and Python.... What's the problem with doing that? &gt;it's like comparing one of India's language (let's say Tamil) with French. And yet again, what's the problem with that? &gt;WHY do you want/need to do that ? What actual good will that do ? Let you know which is better for your needs, of course. &gt;Why do you want to (insist on) try to travel in a Tamil region speaking French or &gt;vice versa ? The only time I see people reacting like this is when they're afraid their pet whatever won't stand up to an honest comparison. Python doesn't need that kind of sheltering. It can stand toe-to-toe with any other language out there. The correct response is to accept the OP's comparison with arms wide open and nothing to hide. 
&gt;Man, either you are close minded or just ignorant. I'm not sure there's an exclusive-or condition here.
Actually, there is a product that lets you use Python in Excel in lieu of VBA.
&gt;You can't write macros for Excel in Python. Excel only supports visual basic for &gt;this. This is not correct. Excel ain't the boss of us! :-) Datanitro lets you run your Python in Excel: https://datanitro.com/ 
I really believe you're doing the right thing trying to channel the community, it was merely the form I was dubious about. I see you have added a statement about this and I hope it'll make your idea look more serious to people who'd be interested in commiting themselves to it.
nice. had no idea this existed. however, its a 3rd party add on and not normally a part of excel.
One possible resource for you is Rosetta Code, a site which offers various code snippets, e.g. "create an array", "sort numbers", etc. in a variety of different languages: http://rosettacode.org 
Yeah, I mean it's not going to be easy or quick. You have to realize, even under *ideal* conditions with proper controls and many participants a proper study could take years and maybe not turn up anything in the end. It's not what you want to hear but there's no way around that, you're going to be limited by the timeline of the biological processes. You're right that it's going to be more than one factor in the end. But it's probably not going to be an all-or-nothing deal either, so let me elaborate a little with that in mind: Like I said, I was oversimplifying--you *can* change more than one factor at a time. After all, you can think of a radical change in diet as changing many factors all at once. The important part, I think, is to make a whole bunch of changes all at once, and don't make any more changes until you have a sense of where that group of factors *as a whole* stabilizes her health. Let's formalize a bit. You have a bunch of lifestyle variables (identifying and quantifying them is step 1). These are your independent variables (IVs). And you have some health outcome variables. These are your dependent variables (you should identify also identify these from the start, but this is easier than enumerating all the IVs--and you've already started to do this). A *condition* is a set of values for each IV. In other words it's a specific set of lifestyle choices. The important point from my first paragraph is to test one condition at a time. The methodology I would recommend is--if you go forward with this: * Choose a condition. * Wait for health to stabilize. * Average your DVs over some relatively stable period, and consider this set of averages your result for the condition. * Once you feel the DVs are stable and you have your average, choose a new condition. Now, you should also keep the data regarding short-term fluctuations because maybe you can find something there down the line, or ask questions of the data that you think of later. But your primary dataset should abstract away the time element and be simply a mapping from conditions (a vector of IV values) to results (a vector of average DV values over a stable period). The central question is how to choose each new condition to test. You can use experimental design theory to help decide. There are two criteria to consider at each new trial: * (a) what condition will lead to the best health outcome. Answering this is ultimately the goal of the whole thing. And you can make better and better guesses after each trial, of course. But there's also a second criteria: * (b) what condition will eliminate the most uncertainty among all untested conditions. To illustrate the difference, say your first condition is unexpectedly successful. Then, your best guess as to (a), the best possible condition, is that it's somewhat similar to what you just tested. But testing another similar condition will not give you so much new information. (b) would suggest you choose something very distant in "condition space" so you can learn more about factors you haven't had a chance to test as much. To get started looking into statistical methods to decide what to test next based on (b), look into [optimal design](http://en.wikipedia.org/wiki/Optimal_design). But your goals are a bit different from a standard experiment. Your ultimate goal is to find something that works, not necessarily to identify the contribution of every factor separately. You're not interested in finding the worst condition as well as the best for example. My advice for weighting (a) and (b) as you go along are: * Start with (a). For the first condition to test you may as well choose your best possible guess as to the healthiest lifestyle choices. * Unless there's radical improvement, switch to (b) for your second condition. In other words, try something very different. * Switch back to (a) depending on your success. If things go well you can make your transition rapidly to only concerning yourself with (a) and focus on making small tweaks with incremental improvements. However if you're not so lucky you may as well stick to (b) and keep trying radically different things. There's an inherent, unavoidable tension in medical experiments between (a) and (b). Imagine your wife was participating in some controlled study for a new drug. You would probably want her to be assigned to the experimental group, not the control group. But if you really want to use experimental principles on your wife and no other subjects, that means at least once choosing a condition different from your best guess as to the ideal condition. The more times you choose a condition that's not just your best guess at the ideal condition, the more "experimental" you are being. That's just the way it is. Otherwise all you're doing is what everyone else does, trying to be healthy by making recommended changes to their lifestyle. Whether you want to do it the experimental way is a decision you two have to make, but if you take that risk you may as well as do it right or it will be for nothing. Even if you don't use the experiment-esque methodology I outlined, collecting data will still help. It just won't help nearly as much as you think, and it will take a long long time before you can make any sort of inferences about anything. The optimal design methodology is by definition the *fastest* way to determine the effects of each variable. Even though this method seems slow, doing it the other way (focus only on (a); do what you would do otherwise but also collect data) it will take much much longer for the data to be rich enough to make inferences. To be clear: it won't necessarily take longer to find a healthy lifestyle; it will take longer for the data to be actionable. And if you don't wait for her health to stabilize before making changes, the data will be pretty much useless (unless it turns out all the problems are only short-term problems, but that's very unlikely). In summary, you ultimately have two options: * Do what you would do otherwise, but also collect data. In 10, maybe 20 years you may be able to make some interesting conclusions from this data. * Do the closest thing to a controlled experiment. In 1-2 years, maybe more, *maybe* you'll have a better understanding of what's going on. Maybe not. There's a reason doctors don't take this approach with their patients.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Optimal design**](https://en.wikipedia.org/wiki/Optimal%20design): [](#sfw) --- &gt; &gt;In the [design of experiments](https://en.wikipedia.org/wiki/Design_of_experiments), __optimal designs__ are a class of [experimental designs](https://en.wikipedia.org/wiki/Design_of_experiments) that are [optimal](https://en.wikipedia.org/wiki/Optimization_(mathematics\)) with respect to some [statistical](https://en.wikipedia.org/wiki/Statistical_theory) [criterion](https://en.wikipedia.org/wiki/Objective_function). The creation of this field of statistics has been credited to Danish statistician [Kirstine Smith](https://en.wikipedia.org/wiki/Kirstine_Smith). &gt;In the [design of experiments](https://en.wikipedia.org/wiki/Design_of_experiments) for [estimating](https://en.wikipedia.org/wiki/Estimation_theory) [statistical models](https://en.wikipedia.org/wiki/Statistical_model), __optimal designs__ allow parameters to be [estimated without bias](https://en.wikipedia.org/wiki/Bias_of_an_estimator) and with [minimum-variance](https://en.wikipedia.org/wiki/Minimum-variance_unbiased_estimator). A non-optimal design requires a greater number of [experimental runs](https://en.wikipedia.org/wiki/Replication_(statistics\)) to [estimate](https://en.wikipedia.org/wiki/Estimation_theory) the [parameters](https://en.wikipedia.org/wiki/Parametric_model) with the same [precision](https://en.wikipedia.org/wiki/Efficiency_(statistics\)) as an optimal design. In practical terms, optimal experiments can reduce the costs of experimentation. &gt;The optimality of a design depends on the [statistical model](https://en.wikipedia.org/wiki/Statistical_model) and is assessed with respect to a statistical criterion, which is related to the variance-matrix of the estimator. Specifying an appropriate model and specifying a suitable criterion function both require understanding of [statistical theory](https://en.wikipedia.org/wiki/Statistical_theory) and practical knowledge with [designing experiments](https://en.wikipedia.org/wiki/Design_of_experiments). &gt;==== &gt;[**Image**](https://i.imgur.com/O5jsE94.jpg) [^(i)](https://en.wikipedia.org/wiki/File:Theb1982.jpg) - *Gustav Elfving developed the optimal design of experiments, and so minimized surveyors' need for theodolite measurements \(pictured\), while trapped in his tent in storm-ridden Greenland. [1]* --- ^Interesting: [^Bayesian ^experimental ^design](https://en.wikipedia.org/wiki/Bayesian_experimental_design) ^| [^Design ^of ^experiments](https://en.wikipedia.org/wiki/Design_of_experiments) ^| [^Response ^surface ^methodology](https://en.wikipedia.org/wiki/Response_surface_methodology) ^| [^Kirstine ^Smith](https://en.wikipedia.org/wiki/Kirstine_Smith) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+ciny8w4) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+ciny8w4)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
There's no way to come up with an average for this sort of thing, except by actually sampling real world use-cases.
One suggestion--regardless of whether you take the experimental route I outline in my other post--is to take these measurements at regular, predefined intervals. You can probably use a smartphone app or something, or even a just a periodic alarm then a notebook. Point is, recording the nausea level every two hours, say will be much more useful than just noting when she's nauseous and forgetting to record when she's not. Coming up with a system is the only option here.
Oh I also wanted to reply directly to this. &gt; So if there's a way to even just make an educated guess based on less restricted data that would minimize the amount of time she has to spend on extremely limitations, that is time well spent IMO. Yes, that's the regression that you will do once you have run a few conditions. Before that, not really. And even after running a few conditions, your estimate will not be as good as the non-statistical advice from doctors and other research. It will take a long time before any inferences from the data are as solid as inferences you are already able to make by listening to doctors and doing background research. Maybe a Bayesian statistician can advise you on how to combine these two methods (listen to doctors/listen to data) but I am not so familiar with those methods and don't know if there is a Bayesian method you could use here. [Something to look into, perhaps](http://en.wikipedia.org/wiki/Bayesian_inference).
Yes, and I am working on getting the conversion as fast as just straight-up emulating NFAs. Once converted (which is a one-time compile-time cost), then you can match in `O(n)`. My current implementation of the NFA determination algorithm (in `redone/conv.py`) seems to increase the runtime by ~100x (making it slower than the `re` module). I think it's because I need to use a better caching system. EDIT: If you look at the `dfa-conversion-optimisations` branch, you can see I've managed to make the DFA conversion much faster (and all of the delay is in the compilation step, not the actual matching). I'm just trying to squeeze out the maximum amount of performance improvements before merging to `master`. EDIT #2: Merged. Now the compiled version of `redone` (`redone.compile(PATTERN)`) is actually on-par (less than 10% slower on my tests) with the `re` compiled implementation (`re.compile(PATTERN)`).
How can I send you a screenshot? (I have it, but where to send it?)
I would argue that complexity won't reflect performance well, since you don't generally see massive regular expressions. In small-case usage like that, the actual speed has far more of an effect.
I'd probably better explain my use of the word "correct". I don't mean "correct" as in "it just works". If that were the case, the use of a hammer to open a bottle could also be seen as "correct". You don't have to use a bottle opener, it's just beneficial to do so. Same thing with bubble sort and other sorts. You don't *have* to use insertion sort (selection sort or what-have-you), but that doesn't mean that bubble sort is as good a choice as the others. "Correct" means "meeting the requirements of or most appropriate for a particular situation or activity" or "free from error". With those definitions, then my implementation is more correct than the `re` implementation for all regexes (*except* backreferenced regexes) since the backtracking method is only appropriate for backreferences and is not free from error (unless you consider a worst-case `O(2^n)` runtime not an issue). 
you can load it up to imgur and just PM me the link. That's probably the easiest way. If that won't work for you, I can pm you an email address to send it to.
It's definitely an improvement. Just a few remarks: - where is the "sorted by" menu? I can't see it anymore in IE or in Firefox on Windows; - too much white space, like really too much. See, for example, on a phone the separation ([line in red](http://i.imgur.com/jMj58JM.jpg?1)) between a post title and the comments line; - I like the idea of making the comments link bigger compared to the rest of the text (it was a pain to click on a mobile device); - but on my phone all the fonts are now much smaller than before and I always need to zoom out; Thanks in advance for anything you can do to fix the above. 
woah, that phone screen shot is messed up. What device are you using? I did most of my testing on Nexus 4 / 5 and emulators for iphones. Since media queries are now a reddit-y thing, I can probably address the font issue just for phones. And I'll find the sorted by menu as well, just stepping away for a bit.
Have a look at [lighttable](http://www.lighttable.com/). It might be exactly what you're looking for. 
have you see this https://github.com/Instagram/python-instagram
IPython, as well as IPython notebook (http://ipython.org/notebook.html) gives you a really nice interface to experiment with code
There is also a ["book"](http://elabs.se.s3.amazonaws.com/uploads/picture/file/81/normal_php_-_the_good_parts.jpeg).
I've been a TA for an introductory programming course at my university. We use this book: http://www.greenteapress.com/thinkpython/ It's for students who know only the most basic elements of programming: variables, loops, functions, etc. Given that you've learned C in the past, you may find it to be too slow. On the other hand, if you have in fact forgotten most of it, then this book could be a good fit. We usually supplement the book with some more theoretical material which covers the basics of computational complexity (big-o notation, etc), how different basic data structures work (e.g. linked lists, doubly-linked lists, binary search trees) and basic sorting algorithms (bubble sort, selection sort, merge sort, etc).
I just finished reading and man... that guy can write. Great points and delivery. Thanks.
Ahh too bad on that color - though admittedly I just picked a random blue that as already used. Any color with more contrast would do really!
I started out learning how to program a few years ago and I started with [WingIDE](https://wingware.com/downloads/wingide-101), it gave me a huge boost to learning with its syntax highlighting and other crazy tools. Check it out, it's got a little console right in the bottom of the screen where you can use your program and edit at the same time.
Mainly updates to the standard library (From 3.2+) including ansycio (3.4) for asynchronous event driven programming. Major language changes from 2.+ to 3.+ As far as I understand.
&gt; How is a slow, possibly-buggy, feature-bereft implementation the "most appropriate" one? Well, as of the last few commits, the compiled version is essentially as fast as `re` and the on-the-fly version is getting there. I am also working on writing up some test cases. The caveats in the README are made so that people don't assume that the project (in its current state) should actually be used for "real" things. As for whether it is appropriate, I was referring to the actual method of parsing and matching regexes. FSAs *are* more appropriate than backtracking in regexes (except in the case of backreferences). So this is an implementation of a set of algorithms which have been mathematically *proven* to be faster and are therefore "more appropriate". &gt; Maybe what you meant to say that this is "inspired by" what a correct implementation of regular expressions would be. I should probably have phrased it as "this is an implementation of the correct method of parsing and matching regular expressions", but I assumed that was understood from the term "correct implementation" as in the actual algorithms are correct. &gt; you haven't given evidence that, if written in C with the same amount of care as has been put into re, your implementation would be more appropriate for the tasks we use regular expressions for (where "more appropriate" probably mostly means "faster"). You just hand-wave a few big-O claims. The [link at the top of the repo](http://swtch.com/~rsc/regexp/regexp1.html) does the proving for me. If you look at the graphs, you can see the massive performance difference between backtracking implementations in C (Perl being the most notable) and FSA implementations in C (awk and grep). So I do provide a link that provides proof. The first paragraph in the README paraphrases that paper. But I should probably make that clearer .... &gt; the title is silly Are you referring to the title of the project (`redone`) or the description (`a correct implementation ...`)?
&gt; So this is an implementation of a set of algorithms which have been mathematically proven to be faster You have to be careful here. We were talking about appropriateness to real life situations, but now you're talking about the speed of your algorithm as a function of the size of the input as that quantity goes to infinity. &gt; The link at the top of the repo does the proving for me. If you look at the graphs, you can see the massive performance difference Those graphs show that one algorithm wins on small values of n, and one wins on larger values. For one particular species of regular expressions. That doesn't convince me of either algorithm being "correct". &gt; Are you referring to the title of the project (redone) or the description (a correct implementation ...)? The title of the reddit post.
How are you calling it ?
Let center of sphere be x0,y0,z0. Distance from center is sqrt( (x - x0)^2 + (y - y0)^2 + (z - z0)^2 ). Hope this reminder helps.
and rather expensive
I have been using sublime for awhile now and did not know you could run python code with it... thank you. Now, in addition to it being my favorite editor, you are my favorite redditor. 
You may have already read this, but whenever this topic comes up I like to re-read this series. http://swtch.com/~rsc/regexp/regexp1.html 
umm... Regular Expressions are by definition Regular. Indicated by the Regular portion of Regular Expression.
I know how frustrating it can be and sorry if I came across as being arrogant. However at 28, diagnosed with Crohns and faced with taking radical biopharmaceutical meds for the rest of my life I chose to *try* the alternative. Almost a year later I would say I've had success. Who knows though, maybe I will end up on the meds one day. The diet does start slow. You work your way up to high fibre foods only once you have healed and are ready to do so. I would still urge you to take a look at the diet and the science behind it.
Sweet, I'll check that out.Thanks!
Python has hex() built in. Cheers!
Yeah I was confused by the dec_to_hex.py as well. Cool project though, wish I knew more about Mindstorms and stuff to contribute.
DFAs are *not* the correct solution for Python's RE grammar.
I highly recommend this: http://learnpythonthehardway.org/book/. It's free to read online. 
thanks man :)
You can use it alright, it's just you will max out only one core.
DFAs are not the correct solution for backreferencing RE grammars. But they are the correct solution for all other types of RE grammars. There exist hybrid implementations which use DFAs for all non-backreferenced grammars. I never claimed that this replaced the `re` library completely (quite the opposite, I clearly point out that `redone` cannot implement backreferences unless you create a hybrid implementation in the README).
I'm replying a little bit late, but installing packages on anaconda using Windows is the greatest pain in the ass ever. Conda requires that a package is installed in their nonexistent repository, so you have to mess around with pip which I'm sure will mess things up with compatibility. And btw that doesn't work either. I'm sorry if it sounds like a rant, but it is: I've spent a whole afternoon trying to get sfepy to work on my anaconda distribution, and I gave up.
Head First Python is good book, I am in chapter 4 right now.
I'll be following this project as I always wanted to use python to code LEGO mindstorms. I have used the Matlab interface in the past but I just cant stand using Matlab anymore.
This needs multi-system testing. On Windows, the logo is huge and the text is normal. On Mac, the logo is small and the text is gigantic. Both using current Chrome. Also, I noticed that the long link titles appear to 
How useful is this plot, given that half of the spherical surface will be hidden? I don't want to throw away your effort, just trying to understand better your objective. I understand your idea as being [this](http://i206.photobucket.com/albums/bb254/Superflanker_EVA/Facts%20and%20Figures/Polargraph0point3intervals.png) (first random image from Google search that I found) but in 3D. Seems cool, but...
It's not that the decorator is "outside the for loop", but that you're injecting the `func` value via the wrapper `woofit` in such a way that `woofit` is called immediately with each `func` value. My usual approach to this sort of problem uses `functools.partial`, but that doesn't work here because the wrapper has to produce an actual function in order for method-binding to work - `partial` objects don't have the appropriate descriptor. I'm pretty sure this can be worked around but I'm too tired to remember how at the moment.
This looks like it could be useful, thanks. Bought me... err, I mean, my son, some Mindstorms, and the point and click programming environment was a bit frustrating.
Well that's true; I also suspected that the semantics of the def statement might be to blame here. It's treated differently, IIRC, to lambdas, and I don't think it's well designed for generating functions in a loop or iteration.
Wish I had Lego mindstorms!!! I would love to contribute. 
This has had multi system testing. If you're getting a huge logo in Windows, then there is likely a caching issue on your end. The long link titles issue is interesting. I'll add it to the list of fixes.
my son is turning three... i think that's the perfect age to buy him some mindstorm. I'll just keep it in good condition until he's ready to program it himself.
All right. I still can't replicate (ff / ubuntu14). Do you have any addons to firefox installed?
my lego mindstorms is at home, but x-posting on /r/mindstorms and/or /r/lego may get some more helpers!
Is builder another name for factory? It is a short book, but that's what I like about it. You can recommend this to teammates that have been using python for a while and they can improve their understanding in an hour
`re` is absolutely *correct*, since it produces the right answers for any possible valid inputs (at least, in theory; I'm not saying it's bug-free). The fact that your arbitrarily slow computer cannot process CPU instructions fast enough to give you that answer in what you personally consider an acceptable timeframe is another matter entirely (that can be solved without resorting to rewriting `re`, e.g. by accelerating to a velocity at which relativistic effects become significant). The word you're looking for is probably *efficient*.
Good thinking, I'll do it right away.
Cool, someone just submitted a PR using hex().
I'd say python is a more easily learnable language than VBA and far better constructed; the main issue of quality I would be looking at would be LibreOffice's binding to it (whether the API is clear and simple to use), and if any glaring performance issues exist at all (depending on how you wanted to use it). In terms of mathematical functionalities, python itself has all the basics you'd want from a general programming language (check out the [statistics](https://docs.python.org/3/library/statistics.html) module added to the standard library in 3.4!) but if you extend it with 3rd party libraries it can become an extremely powerful scientific and financial programming 'glue' language.
Exactly, I said "but in 3D". Again I ask you, what is the use of that? Is that the best way to plot your data?
Found my answer [here](https://stackoverflow.com/questions/20739592/python-scipy-rectspherebivariatespline-interpolation-generating-wrong-data)
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Lua (programming language)**](https://en.wikipedia.org/wiki/Lua%20(programming%20language\)): [](#sfw) --- &gt; &gt;__Lua__ (/ˈluːə/ *__LOO__-ə*, from [Portuguese](https://en.wikipedia.org/wiki/Portuguese_language): *lua* [ˈlu.(w)ɐ] meaning *[moon](https://en.wikipedia.org/wiki/Moon)*; explicitly not "LUA" ) is a lightweight [multi-paradigm](https://en.wikipedia.org/wiki/Multi-paradigm_programming_language) [programming language](https://en.wikipedia.org/wiki/Programming_language) designed as a [scripting language](https://en.wikipedia.org/wiki/Scripting_language) with extensible semantics as a primary goal. Lua is [cross-platform](https://en.wikipedia.org/wiki/Cross-platform) since it is written in [ANSI C](https://en.wikipedia.org/wiki/ANSI_C). Lua has a relatively simple [C](https://en.wikipedia.org/wiki/C_(programming_language\)) [API](https://en.wikipedia.org/wiki/Application_programming_interface). &gt;==== &gt;[**Image**](https://i.imgur.com/FHfuddA.png) [^(i)](https://commons.wikimedia.org/wiki/File:Lua-logo-nolabel.svg) --- ^Interesting: [^Io ^\(programming ^language)](https://en.wikipedia.org/wiki/Io_\(programming_language\)) ^| [^Self ^\(programming ^language)](https://en.wikipedia.org/wiki/Self_\(programming_language\)) ^| [^Language ^binding](https://en.wikipedia.org/wiki/Language_binding) ^| [^Coroutine](https://en.wikipedia.org/wiki/Coroutine) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+ciok6zi) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+ciok6zi)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Hiya. Short answer? Not really. I'm pretty good at getting compiled scientific libraries to build in Windows via MinGW, but as I understand it Python packages with C extensions need to be built using the same compiler as Python itself, which means Visual Studio on Windows. Visual Studio plus open-source software with build systems primarily intended for *nix is not a pleasant combination. I'm not enough of an expert in Python packaging to really solve your problem, sorry. I would start with the package's dependencies (https://github.com/sfepy/sfepy/blob/master/INSTALL), see how many of them you can get from conda. For the ones you can't get from conda, check if they themselves have additional not-in-conda dependencies - hopefully not, but you never know. Start with those smaller packages first, ask around at the packages' issue trackers (probably mostly Github these days?), or on this subreddit, or on Stack Overflow, or at Conda for guidance.
I think APScheduler should be added as well personally.
.... an outdated python version and improper CSS!
In default python-mode for emacs, just C-c C-c :P
For people not stuck in the noughties there's a Py3k PyPy now though it's only py3.2 so far. When it catches up though, I'm in.
Hey, I made a Python tutorial website which you're welcome to use. As it's used in education, the solutions are password protected, but the site is free. [link](www.usingpython.com) 
Surprised this goofy post got this many upvotes. "I have PyPy, whoop-de-doo."
http://mycognitio.com/search/?q=python 
Secure coding is most important in any project. Unfortunately there are too many that just code and throw security to the wind. As you have mentioned, when coding a project that will be scrutinized by an organization such as HIPPA, you need to be extra careful. You may want to start by checking something like this out: http://www.pythonsecurity.org/ Another good read is also: http://python.about.com/od/cgiformswithpython/ss/ProgramSecurity.htm There are plenty of ways to secure your application. Use every one that you can.
Yeah, I was surprised by how bad the visual app is - it's painfully slow for one thing. In fact my long term goal is to use this Python module as the backend of a new, hopefully faster visual app for Mindstorms. But I'll need to learn GUI programming first (right now I wouldn't even know where to start).
I'd probably prefer Flask over Django just because it's a smaller codebase and a simpler model to audit, should it come to that. Django does a lot of 'magic'. From my understanding of HIPAA factors like "how you store your data" and "how often sysadmins review logs" and "what the access control policies at the data center are" will probably play a bigger role than which programming framework you use, so you need to make sure to have good answers to those questions.
2.3.1 is current... 
If you are serious about learning Python, and you are coming from the Java world, you are like I was some time ago. I also was going to find a short book for an experienced programmer. Unfortunately I have not found such a book. There is neither **Effective Python**, nor **Python for the Impatient** available. **Python the Good Parts** has no place in the Python world because Python unlike JavaScript does not have bad parts. I started my Python education with **The Quick Python Book**, and later regretted it. First you should decide whether you want to learn Python 2 or 3. I would strongly recommend starting with **Python Tutorial**, and then a very thick book **Learning Python** by Mark Lutz. It is full of repetitions but nevertheless it is very good. If you are not interested in learning Python 2 you might start with **Dive into Python 3** by Mark Pilgirm (because its freely available) or **Programming in Python 3** by Mark Summerfield (gifted author), after going through the tutorial. 
Whew, life on Windows is hard, haha! Well, I'll keep it like this, thanks for the answer! Anyways, I don't know if you knew about it, but a saint man, Christoph Gohlke, has compiled tons of packages into neat exes to run and execute. They worked for me! Maybe you could give it a try! 
If you have to ask this question, you should probably consult a security professional.
Ah, great. Came across that list and saw sfepy on it, glad to hear it worked. I wouldn't know what to test to verify that myself. None of the packages I've been interested in using were on his list unfortunately. I went and tried installing sfepy the conventional way with pip on the Sage Math Cloud (https://cloud.sagemath.com/) which runs Linux, but couldn't get it all running in a way that passed its unit tests. Some languages' communities do a better job than others of keeping their package ecosystems up-to-date and easy to use across many platforms. I have never been impressed by Python in this regard. "There are thousands of packages available" is not so useful if getting any of them to build and work is painful and difficult.
zomg I'm such a genius! I totally fixed it. ;)
Similar to making the jump the python 3, the issue is package support.
first question before we can answer anything, is this an internal application w/ no outside access or is it exposed to the world ?
Hahaha, that's some controversial shit. I think the prevailing theory is that women are socialized by society to prefer the less technical fields of study, but I don't have a source for that.
http://speed.pypy.org/
Doesn't matter as far as HIPPA is concerned I believe.
That was going to be my recommendation too. It's a very good reference work that contains lots of good, idiomatic code. The [python.org docs](https://docs.python.org/3/) are surprisingly good at times as well. The [data model](https://docs.python.org/3/reference/datamodel.html) section of the [Python Language Reference](https://docs.python.org/3/reference/index.html) is worth a quick read even by experienced Python developers. For packaging, the [Python Packaging Authority](https://github.com/pypa) is doing some great work. The [Python Packaging User Guide](https://packaging.python.org/en/latest/) is a nice read that fills a large hole in the packaging space. Now with Pip in 3.4 by default and PyPA making rapid progress, it looks like there is an end in sight to the slow-motion train-wreck-in-progress that has been the Python packaging &amp; install landscape for many years now. [The Python Standard Library by Example](http://www.amazon.com/Python-Standard-Library-Example-Developers/dp/0321767349/) and [Python Module of the Week](http://pymotw.com/2/) have been mentioned already, but they are outstanding and should definitely be consulted, although they are unfortunately Python 2 -- I'm not sure if [pymotw.com/3/](http://pymotw.com/3/) is the beginning of a new PyMOTW for Python3 or an aborted reboot under Python3. If you would like to learn about asynchronous programming and the Twisted framework, there is a really great and extensive set of tutorials by Dave Peticolas: [Twisted Introduction | krondo](http://krondo.com)./?page_id=1327) 
I wish people wouldn't say things like this. It's not controversial, it's just data. As far as I can tell, there are no opinions expressed.
Hold my dick, oh let me guess -1 troll. But again hold my dick. 
[Formatted version](http://easy-python.readthedocs.org/en/latest/).
Gee... Thanks!
&gt; python version Current version is 3.4.1, not 2.7.6. 
Thanks, but I find that harder to visualize. I don't do it in c++ and not a fan of it in java. 
Ahh.. Forgot about the floor operator in this case. Using int made intuitive sense because of c++ int division. (Which come to think of it is the same thing as //)
Thanks! Like I said I took it from someone else and leaned Josn (and find it cool!!) Hopefully someone else can learn from it. 
If you look at the comments in the [blog post that it's based on](http://www.randalolson.com/2014/06/25/average-iq-of-students-by-college-major-and-gender-ratio/), you'll find some pretty reasonable thoughts on where the skew comes from.
&gt; things you didn’t know you would need Seriously? The first thing on the list is [pip](https://github.com/pypa/pip). Who the hell doesn't know about pip? I mean, it's recommended in the goddamn [beginners guide](https://wiki.python.org/moin/BeginnersGuide) on python.org. Anyway, despite that overly sensational and condescending opening line (please don't try to tell me what I do or don't know), this seems like a great listing. It hits most of the great libraries, and lists more than a few common nice-to-have's as well.
Let's not kid ourselves Python 3.4 __is__ Python. Lots of young people will not remember when Linux 2.4 and 2.6 were both popular. Many said that Linux 2.4 should be forked to save it from radical changes. Anyways we all know what won. Anyways I understand why 2.7 is still popular in deployment but py3 is getting established and the future is very clear to most at this point.
You are right HIPAA is more of a check list than an actual methodology. Thank you for the link it was really helpful. Yeah I mean right now I am just sandboxing for myself. However I do plan to go live when I can make sure that it will pass inspection/auditing. When I do decide to release, it will not be without getting more experienced web programmers to look over and help. 
Yes, I plan on looking for experienced developers and web professional that are familiar with HIPAA HITECH. Any that you would recommend when I get to that point?
Well currently it is just a project I would like to do for myself, but I do hope to offer it to medical professionals later on. So I guess to answer your question it would be exposed to the world.
Yeah I guess I am having trouble finding these checkboxes in a easy to read format. 
&gt;It's not controversial, it's just data. I didn't say it wasn't just data, obviously it is. It's just also controversial. Lots of people don't like talking about how gender or race or any other superficial attribute relate to intelligence, it's a touchy subject.
I'm a bit surprised by the comments about Python 3, there's a PEP saying that the "python" command should always refer to a Python 2 compatible interpreter : http://legacy.python.org/dev/peps/pep-0394/
&gt; In summary, you ultimately have two options: &gt; &gt; * Do what you would do otherwise, but also collect data. Absolutely. * Collect `(datetime, [(feature_name, feature_value),], "text")` with type information (e.g. as CSV, JSON, JSON-LD that can be mapped to an RDF schema). * Define names, domains, and ranges for factors/features/IVs/variables. (A triple-blind study would need a name &lt;-&gt; random key mapping). &gt; In 10, maybe 20 years you may be able to make some interesting conclusions from this data. In [clinical practice](https://en.wikipedia.org/wiki/Medicine#Clinical_practice), I would imagine that a physician would be doing something like [A/B testing](https://en.wikipedia.org/wiki/A/B_testing) and [root-cause analysis](https://en.wikipedia.org/wiki/Root_cause_analysis) ([like building a decision tree](http://www.reddit.com/r/statistics/comments/28p2nh/examining_the_effects_of_multiple_independent/#cioyedw)), and [multi-armed bandit](https://en.wikipedia.org/wiki/Multi-armed_bandit), with [pharmacological certification](https://en.wikipedia.org/wiki/Pharmacology). *Near-term optimization objectives*: * Minimize sub-optimal states which "occur after" certain [patterns](https://en.wikipedia.org/wiki/Pattern_theory) * Gain information and knowledge * {datasets, studies, resources} -&gt; data -&gt; information -&gt; knowledge -&gt; wisdom * Collect studies matching permutations of search terms: * http://www.ncbi.nlm.nih.gov/pubmed/?term=search+term * Encourage PDF hosts and search engines to add RDF metadata: * e.g. MESH, http://schema.org/docs/meddocs.html * Catalog primary and secondary sources: Zotero, Mendeley * Generate a bibliography * Speak with doctor[s] about/before changing things ... [here's a few more links](http://www.reddit.com/r/Python/comments/29rn3q/science_programmers_i_need_to_analyse_a_diet/#cioxv9d).
I've hopefully fixed some problems which might have caused Syncplay not to work on some Mac systems, although it might end up reverting to the command line interface mode. If following the instructions at http://syncplay.pl/guide/install/#OSX[1] does not work then try asking for help on the #Syncplay IRC channel on irc.freenode.net or send me a message via Reddit.
&gt; It at a minimum needs to add a playlist function. Adding shared playlist functionality is certainly on our to-do list. However, getting it to work properly is harder than it might seem. For example, if Bob is a few seconds before the end but Alice is already at the end, then switching file and seeking to the beginning would mean Bob would miss the very end of the previous video.
@nadirw91, you will not find this info in an easy to read format. After all, it is legal info, and no lawyer wants to make your job easy! Do contact Patrick (http://www.kalzumeus.com/), he is very helpful (though busy as well, so don't expect an immediate reply). But I have talked to other people, and trust me, unless you have $10,000 or more and several months to spend, you are better off targeting a slightly simpler market.
And we've always been at war with Eastasia.
Very cool! The PyPy folks are doing some awesome stuff!
Does anyone know what the equivalent EU regulation is?
Ah, so you like Py3 better than Py2 and thus feel the need to let everyone know that whenever there is a reference to Py2... Got it... 
I won't go into which test framework to use (I use py.test personally), but I would like to say that tox isn't testing framework. It is a test automation tool that allows you to run your tests against multiple python versions in a single command. It complements the tests frameworks like unittest or py.test, not replace them.
Welcome to /r/python
I just looked through a lot of docs, and I am no expert. They dont seem to set any rules about what kind of technology you employ. Its all about how people are given the correct level of access and how the systems are managed (offsite backups, auditing processes). I would think having any data on a local machine would be bad. If that machine was removed sensitive data would be exposed. Now if all the computers are essentially dummy terminals, all data is secured in a locked down room and you can only access data at your level based on your authentication. I do think you are right about folder hierarchy type things. The technology piece I read said it specifically doesn't include any programming languages or frameworks. As long as the system fits the other requirements its good. [Source](http://www.hhs.gov/ocr/privacy/hipaa/administrative/securityrule/security101.pdf)
Within the css of the page use something like this .nav { position: fixed; } That keeps it still regardless of where you scroll. Edit: this is without looking at the site. 
You can write tests using unittest, then take advantage of more fully-powered test runners like nose or py.test. Mock is a library to help you write tests, and tox is a way to run your tests (however you run them) under multiple versions of Python. This might help: http://nedbatchelder.com/text/test0.html
Yes, tox plays actually very well with py.test but you can avoid tox if you are a beginer in testing. One tool at a time.
&gt; **for the time being**, all distributions *should* ensure that `python` refers to the same target as `python2` (My emphasis)
Look at your routes. You have just one, the "/" page. So right now Flask doesn't know what to do with any other URL, like "/1.png". You need to add a new route to handle those cases, something like this: http://stackoverflow.com/a/20648053
for the time being includes today right ?
You probably shouldn't be using `time.sleep()` in this scenario. tkinter has the [`after()`](http://infohost.nmt.edu/tcc/help/pubs/tkinter/web/universal.html) method that works with any widgets. Also, this is unnecessary i=1 while i==1: Something like this works just fine. while True: do_something() 
These guys are the superheroes of the Python world.
Apologies for the noob question... What's an STM? 
[Software Transactional Memory](https://en.wikipedia.org/wiki/Software_transactional_memory), a method for doing concurrency.
Some points, in no particular order: - Your problem seems to be configuring nginx as a proxy, which is not really python specific. - You seem to be running your app as root (using `sudo`). Don't do that. - nginx complains about an unknown directive "user". At the top of your config file, you have "`user nginx;`". Then you comment out the line in the nginx config that includes your config file. The error goes away but your site doesn't work (surprise). What *did* you expect would happen? Edit: check the last post on the stackoverflow thread you linked, I think it has the correct answer.
thanks for replying... :) the last answer says there should be different `user` if using two config files. in one, the user is `www-data` and in another its `nginx`
This is going to need a whole new set if parallel libraries isn't it. I mean, are the current parallel libraries enough take advantage of this or are they stuck with the GIL?
No, that's not what it says. It says that you can't have two "`user`" directives active at the same time.
What kind of libraries are you talking about ?
http://learncodethehardway.org/
oh..! so I cannot have app specific conf files? what if I have to use different settings for each app? I mean different directives? anyways, now I moved `/etc/nginx/sites-enabled/pricechase.in` to `etc/nginx/nginx.conf` and its working as expected. 
i upvoted because im interested in the answer. but http://www.reddit.com/r/webhosting/ might be a better place to post this question.
* http://www.reddit.com/r/learnpython/wiki/index * http://www.class-central.com/search?q=python * http://www.reddit.com/r/IPython/comments/1hkqx4/crash_course_in_python_for_scientists/#cavu9w7 * http://www.reddit.com/r/Python/comments/1hz7vb/how_did_you_learn_python/#cazoa4a * http://www.reddit.com/r/IPython/comments/1zxfda/is_it_my_imagination_or_is_ipython_setup_kind_of/#cfxwqoy (conda/canopy)
That's clever
i asked this because the level of time invested into security goes up a crazy amount when all of a sudden patient file and information can be accessed off the LAN. you go from the protection of a dummy terminal where no files can be saved locally and you even have control of if they can be printed out or not to the potentially world accessible. This would impact the answer of what technologies the op should take the time to invest in and setup properly (SSO AD/kerberos only vs username/password over ssl, stored as SHA-256). as an aside it will make a difference also if he has to setup full database encryption.
Question - transactions need a scope, right? My main thought about STM, which I'd appreciate a second opinion on, is that it doesn't address the need for synchronization primatives so much as trade away a bit of performance in exchange for a simplified implementation of multithreading. Specifically, software authors no longer need to specify _what_ is being locked, just that there is a program section in which something needs to be synchronized. For this convenience, occasionally the program will do the same work several times, as the transaction keeps getting aborted by other transactions. Right? In terms of how this helps the developer, to me it seems like a comparable feature is unmanaged vs managed memory, right? A little less control, a little slower, but the goal is significantly faster development. 
&gt; With those definitions, then my implementation is more correct than the re implementation for all regexes (except backreferenced regexes) since the backtracking method is only appropriate for backreferences and is not free from error (unless you consider a worst-case O(2^n) runtime not an issue). You seem to be missing the fact that most people use a regular expression library to run their particular regular expressions, not "all" or "any" regular expressions. The question that people ask actually is "why do you think that your regex module is the correct way to match `[_a-zA-Z][_a-zA-Z0-9]*`?" and your answer is "because it correctly matches `a*a*a*` etc", which makes you sound very silly. By the way, this distinction also answers the question that should have been puzzling you for quite a while: how on earth have people been getting away with using incorrect implementations all this time? I mean, it's not like the algorithm produces suboptimal values that most people still consider good enough, it basically hangs unless you're willing to wait long past the heat death of the Universe, that's not something you can just write off as a harmless quirk and ignore, right? You can be a stubborn untutored craftsman all you want, no amount of wilful ignorance and distrust of academia can allow you to pretend that there's no problem, can it? Well, it turns out that usually it's immediately obvious when your regex goes even to quadratic performance, so people notices that, remember that the documentation warned about pathological cases and rewrite the regex to work properly. And try to take care to not write pathological regexes from then on. It's like in that joke, "Doctor, doctor, when I twist my arm like that and pull it like this, it hurts!" -- "Don't do that." So, if the problem you're trying to solve is running arbitrary regexes, then using an NFA is obviously the correct solution. If, however, you also can "stop doing that", when you're allowed to not run pathological regexes, when you're running regexes that belong to the subset efficiently interpreted using backtracking, how is using a backtracking-based implementation to solve _that_ problem incorrect?
So if I understand the Wikipedia article correctly, this method of parallel computing is better than thread locking, like OpenMP etc?
I think the question he is trying to ask is do the set of existing parallel libraries take full advantage of this, or do changes need to be made on the library end to improve performance?
I like https://github.com/audreyr/cookiecutter generator, because there is support for external templates and templates are just jinja parsed files/directories and one json config file.
10/10 Would watch again
HIPAA compliance is risk-based. So crypto is not needed on an internal network if you can show you've done the correct assessments and taken appropriate precautions. You should take a look at the DICOM and HL7 standards... Not a hint of crypto in sight, no authentication whatsoever in HL7. And both standards are used to carry PII all day long.
nice!!! some 15 years ago i thought about patenting a similar 'game highlights' system based on 1) noise level 3) speech to text analysis 2) closed caption analysis. basically it would watch sound levels &amp; durations, scan for 'goal', 'service break' (in tennis), 'knock down', etc. i used to DVR tons of matches and would never have enough time to watch them all. then i decided i didnt like patents very much :) anyway, great job!
Wow. It seems *really* powerfull - the generation from a git repo is pure genious. Thanks for the link.
Very, very, very, slick!
This goes onto my short list of "examples that demonstrate Python is the most awesome language that's ever existed". This is the kind of thing you whip out when you want to make fans of other languages cry. :-)
Are you using Python 3? If so you need parens around the arguments to the print function.
That is brilliant! Quick Anti-Patent it before ESPN sues is all. (if I were an IP Attorney my pro-bono work might be doing such things). (Anti-Patent is probably patent and release ala Tesla Motors.)
I would imagine the code from the computer side, would be something like: If battleship = partially destroyed. try to finnish it off else go somewhere random that is all the AI you would need really.
I am using Python 3.4, so I would need to put in print ~~"soup"~~ (soup) ? 
 print(soup)
Okay, also since I am using Python 3.4, not Python 2.7, I had to swap my reference out a bit. Trying to fix it, am new to 3.4, but am still getting an error. The 'updated' code that I need it : &gt;import urllib.request &gt;from bs4 import BeautifulSoup &gt;opener = urllib.request.build_opener() &gt;opener.addbuilders = [('User-agent', 'Mozilla/5.0')] &gt;urllib.request.urlopen('http://www.wizards.com/dndinsider/compendium/CompendiumSearch.asmx/KeywordSearch?Keywords=healing%20%word&amp;nameOnly=True&amp;tab=') &gt;ourURL = opener.open(URL).read() &gt;soup = BeautifulSoup(ourURL) &gt;print(soup) While running the command, I get an error: &gt;Traceback (most recent call last): &gt; File "C:\Android Development\Python\URLImport.py", line 9, in &lt;module&gt; &gt; ourURL = opener.open(URL).read() &gt;NameError: name 'URL' is not defined and am trying to figure out what the new reference is by looking at the PEP, but am not seeing what I should call to to pass the URL. Gah, this is damned difficult. New role in company requires learning Python 3.4.
Well mostly, it need to place ships, when it hits it needs to continue hitting in right direction. But I seek advice to make my code more simple.
You're using URL (upper case) when you previously assigned to url (lowercase), case matters. Also, from the sidebar it looks like this should be over in /r/learnpython. 
You may want to re-post this in /r/learnpython. That said, can you post some examples of code you need help with?
All of my references to ourURL appears to be correct, is it the one with the actual web url in it? I have checked the case and made all "url" lowercase, but it isn't clearing it up. :/\ I'll move it to /r/learnpython 
I forgot about that place well for example when AI need to place ship it must be in the grid and it can't touch other ships, well I would know how to code that but it would be rly loong. 
Well, without knowing what your code looks like at all, maybe something like this? result = None while result is None: coords = (random.randrange(10), random.randrange(10)) orientation = random.choice(['U', 'R', 'D', 'L']) result = game_board.place(ship, coords, orientation) Then implement the `place` method of `game_board` to return `None` if the placement would result in an overlap.
Huh? This isn't anything remotely unique to Python. I could whip something up in C similar using libsndfile. You can use DFT (discrete fourier transform) on volume to pick out peak events pretty easily. 
can you give me an example of a parallel library ?
Really awesome, thanks for sharing!
I've been pretty sold on the style of using unittest(2) for writing my tests, nose as a test runner, and tox for the build automation step.
Try /r/learnpython!
That's the difference between concurrent and parallelism. (Although people tend to have different opinions about which is which). Anyway Twisted has tasks that happen simultaneous in a semantic sense. But nothing happens at the very same time. It's all still single-threaded. Twisted just "context-swichtes" between tasks, usually depeneding on I/O. Twisted is just event-driven, not true multi-threaded.
You could do it in brainf*ck too, but it's not going to be as short, simple or elegant. Could you do it in C in [this few lines of code](https://gist.github.com/Zulko/5cb8f880ef79b2db3c63)? This is what really speaks to both the beauty of Python and the robustness of the ecosystem. The other example on this blog of using a YouTube video of a player piano roll being played to create the notation is the singularly most amazing Python demo I think I've seen. There's also been IPython notebooks posted here and in the Python Weekly newsletter of cracking an enigma code with Python and using python and Markov Chain-Monte Carlo methods to deduce where the missing Malaysian Airlines flight is. as well as an link to a magazine article I found about hunting for comets with Python. These are all amazing demos of what the language can do (simply, cheaply and beautifully).
2.3.1 is (mostly) compatible with Python 3.2, hence the call its outdated. Its got nothing to do with Python 2 v Python 3 - even PyPy has moved onto Python 3 so that's moot in this context. 
They do talk about stage 3 in their 2nd call for donation: &gt; The third goal is to look at some existing event-based frameworks (for example Twisted, Tornado, Stackless, gevent, …) and attempt to make them use threads and atomic sections internally. We would appreciate help and feedback from people more involved in these frameworks, of course. * Stage 1 seems be about general improvements to pypy-STM. * Stage 2 is about low-level python libraries for users to use to get better performance and functionality out of pypy-STM. * And then Stage 3 is the big one of making it all transparent to the user by integrating it into common frameworks.
A public disclosure should be sufficient, it would count as prior art. Patents are expensive
Hi Simon, first of all congratulations on completing your framework and good effort! I briefly looked over your code. These are my thoughts.... I think the goals and ideas of the framework are worthy in pursing. With regards to the architecture of the framework its best to avoid injecting the Di Container into classes and then calling the Di Container from within a class to obtain instances of other classes. This is sometimes referred to as the service locator anti pattern. It hides dependencies and makes your code dependent on your Di Container. Your Di Container should be limited to wiring together your app at the bootstrap phase. You should also be able to wire together your app and run it with any Di Container without changing any of your other code. 
Start with the Python course on Codecademy.com.
Should be pretty easy. Just attack one part of the problem at a time. Maybe have a class with methods like: - check_in_bounds_width(width_of_ship) for horizontal placement - check_in_bounds_height(height_of_ship) for vertical placement - randomly_get_ship_type_and_size() - randomly_place_ship() where randomly_place_ship ties them all together: class AI(): def __init__(self, board): self.board = board # we get the game board somewhere else maybe? def check_in_bounds_height(self, height_of_ship): ... def check_in_bounds_width(self, width_of_ship): ... def randomly_get_ship_type_and_size(self): # return tuple of type name and size return random.choice([("destroyer", 2), ("icantremember", 3), ("battleship", 5)]) def randomly_place_ship(self): ship_type, ship_size = self.randomly_get_ship_type_and_size() ship_placed = False while not ship_placed: try_to_place_at = random.choice(range(1,15)) if self.check_in_bounds_height(ship_size): ....place vertical.... ship_placed = True elif self.check_in_bounds_width(ship_size): ....place horizontal... ship_placed = True
Some other clever stuff you want to do is only aim for every other spot, and do analysis to determine if a ship can possibly be somewhere.
How would examining it on the frequency domain help you find peaks any better than a simple linear scan over the time domain?
You emphasize the convenience but neglect the safety and reliability benefits you get when you abandon locks. Also composability.
It came up on here a couple of weeks ago that there's no good general overview for getting started writing desktop applications. I maintain a couple of Python desktop applications, so this is my attempt to give that overview. I hope it's useful.
Do you have recommendations for speech recognition software ? I have tried to use [cmusphinx](http://cmusphinx.sourceforge.net/2013/07/pocketsphinx-python-bindings-ported-from-cython-to-swig/) but I always got strange results.
I'm too tired/tipsy to read it now but saved to pocket for later. Thanks for compiling, I'm excited for the guidance
Thank you this was the main question is if Flask head features that checked off all of the main HIPAA boxes. 
The idea is that you use STM to parallelize those events and it helps you ensure that no semantics are broken, because if there is a conflict one transaction will abort. Twisted will require changes to really take full advantage, but a program using Twisted should require less (e.g. it should kill all the global state)
Context. That makes sense. Also `requests` is a good example.
+1 for cookiecutter. Great project, good docs, and now with extra maintainers so development of features should accelerate.
You're moving goalposts. /u/fx101 never said anything about doing it as succinctly as Python, he simply said it wasn't unique to the Python domain.
It's most important to be consistent of course. If the file or codebase uses a particular style, stick with it. I very much prefer the second style though, because it is *clearer* what library is being used especially when you are reading a small snippet of the code. 
No, it isn't. 
&gt;The arguments for starting with C are the same as the arguments for learning Latin, so that's not very surprising. The argument for starting with C is that it is much simpler than just about anything else. 
I disagree. I don't think starting with C is necessary, but if you can't understand pointers you can't understand linked lists, for fuck's sake. How anyone could fail to understand what is the computer-equivalent of an arrow pointing at something else is beyond me.
Any reason not to mention PyPI/Pip?
Technically yes. But Google for "EFF call for prior art" and see just how often the patent office issues patents without any regard to prior art. There's even a special stack overflow set up just to list prior art on patents to help defend against patent trolls. Case in point. http://patents.stackexchange.com/questions/3495/call-for-prior-art-3d-printing-application-ribbon-filament-and-assembly-for-us There has been plenty of high profile examples throughout the years. All I'm saying is that if I were able to free legal support to help patent-left something I would. As I think an actual patent might hold more weight in the current (broken) system than prior art seems to. But, you know, theory is good too. There's a reason companies choose to get patents rather than just fight based on prior art. It's not because they like paying lawyers. Edit: Here's another example. http://mobile.theverge.com/2013/5/31/4381486/A-podcast-distribution-patent-EFF-wants-help-invalidating EFF thinks there is plenty of prior art available. They are fighting. In the meantime the patent office awarded the patent anyway and people are getting extorted. If one of those prior artists had patented and released the idea like Tesla there'd be no threat. Sadly it is not economically viable for innovators to do this and it is favorable for patent trolls. The exact opposite of how I should be. But yes, technically none of this should be necessary. I'm sure in your classrooms the patent office always finds the prior art.
Your intro on tk needs more recent info. Since tk has been updated it now supports native OS widget. This means simple uis such as putting a ui on a CLI app can easily and quickly be done using tk. 
awesome!
This is great news! If some PyPy devs are reading this: is the current approach to STM (on Linux at least) the use which used some obscure Linux syscall? I recall Armin mentioning something like this in hist talk at FOSDEM, but the details are a bit fuzzy. And, at bird's-eye view, what's the plan for Windows / OSX? Thanks a lot for your hard work!
There is some great info in there, thanks for putting it together! I didn't know about Esky, looks interesting. So far, I have used a very thin ctypes based wrapper around WinSparkle (http://winsparkle.org/) on Windows, and it works great. You'll need to build the DLL yourself, but the ctypes code is trivial and the end result looks totally integrated because Windows does the theming. (the updater UI uses WxWidgets, but they are statically compiled into the DLL)
I'd argue that the reliability aspect is largely a convenience (and identical in idiom to managed vs unmanaged memory). E.g. in the end, less time debugging. Having said that, maybe convenience is the wrong word. I associate convenience with things that take the developer's mind off of low level details. And composability, care to elaborate? Re entrant locks are a thing. I'm guessing you're referring to deadlocks automatically being handled. 
But /u/alcalde was probably referring to the shortness and elegance of the Python solution.
One of the characters in [Contact](http://en.wikipedia.org/wiki/Contact_(novel)) the book by Carl Sagan, made an application for swapping tv channels during ads. The first implementation checked the volume (it is higher during ads), just like this script. 
One should add that PySide does not support Qt 5, but PyQt does. Qt 5 comes with QML, an amazingly powerful scripting environment for layout and application logic. Usually, you can code almost all of your App in QML, and only rely on Python/C++ for a very small number of things. If you are going down that route though (and you should), then there is also PyOtherSide, which hooks Python into QML, but not Qt. This avoids a lot of the headaches with distribution and installation of PyQt/PySide. Really, this is the way I would recommend: Write your app in QML (which is easier to learn than Qt), and hook up Python through PyOtherSide. Distribute like any other QML app, with a teensy tiny Qt/C++ stub that only starts up QML, and nothing else.
Is it just me or is your Qt theme very ugly and GNOME-y?
unless there is reason to rename something I don't rename things. The keystrokes saved aren't worth the mental cost in understanding the shorthand later
Made me smile, thank you :)
It depends on what I'm working on (and if anyone else is going to be using it) but my preferred method of importing is from numpy import * Since it imports all the functions and then I don't have to go through the effort of dot notation.
Thanks for the help. If I'm not mistaken, it appears that each link you've posted suggests a different approach: accompany each module with its testing code, or gather all testing code in a single location in the project's top level directory. At first glance, it appears that your suggestion (accompanying each module with its unit tests) is preferable. Nevertheless, is there a pythonic way (standard or quasi-standard) to organize unit tests? Once again thanks for the help
I assumed the reader already knows common Python stuff, and wants to get from there to writing desktop apps.
My experience even with ttk is that it manages to look ugly, but I haven't played with it much - I'd be interested to see how well Tkinter can do now.
Check out the Enaml (http://nucleic.github.io/enaml/docs/index.html) library. This gives you the expressiveness of QML but with full python integration. The best introduction is given in this conference talk: http://vimeo.com/79536617 . FWIW Enaml is built on top of PyQt. Enaml is a seriously well designed library and a pleasure to use. Docs are a bit sparse though but it doesn't take long to get the hang of it and the code is easy to follow. 
Thanks, that's an interesting approach. I have heard of pyotherside, but it looked pretty new when I saw it - is it mature enough to rely on for production applications?
That's the view inside Qt designer - it looks native when you actually run the application.
I'm part of the IPython team, and the IPython notebook works like that, but we don't really have a desktop-y deployment solution. Because it's a developer tool, people can just install it using a tool like pip, and run it in their web browser. I think a common pattern is to package it with a dedicated browser component, so it opens in a dedicated window like any other browser application. IIRC, both Github's Atom editor and Light Table work like that (though not in Python). I haven't thought about what packaging would involve, but I think it should be possible with Pynsist. It's trickier with a freeze tool, because you probably need the browser to start the server as a separate process, but it would still be possible to freeze two exes that know about one another.
This is okay for a well packaged library or framework, but doing this pollutes the global namespace. If you did the * import for two libraries that both have a "parse_config" (or whatever) function, the latest import would take precedence. Usually it's fine but considered bad practice. 
Just wanted to say IPython is baller. Keep up the good work.
Nice work. One thing I noticed right off the bat when I went to grab from http://www.youtube.com/watch?v=7Ajx-ABtbVM is it downloaded some retarded ass song from "lonnie and the boys" or something. Now it's proceeding to download everything on the page. Is it supposed to just grab everything on any url you give it? It's going to download the whole youtubes pretty soon...
I would restrict this to only one import of this nature in a file (and only if it's designed to be imported as such). Otherwise it obscures where a given function comes from.
Yeah, you're right it is quite bad. For the most part I'm just writing quick scripts to parse and analyse some data and I know what's in the modules I'm importing since I'm familiar with them, so the global namespace isn't too much of an issue... But, if I'm working of something with someone else I'm usually more careful with my imports and follow convention. That being said, splat importing is still my go-to method when I'm doing something quick
I don't know. *But*, I do know that PyOtherSide is very simple. It is a QML plugin for calling Python, with QML data structures being translated to Python data structures, with (almost) only JSON-compatible data structures allowed. This very limited scope makes it dependable, I would say. If need be, you could write your own in a few days. In fact, if I were to build a GUI app in the near future, I would build my own, since I don't agree with some of the design decisions in PyOtherSide.
Also it appears to be trying to download the same file after I gave a new url. I was playing the last one I downloaded and when I gave it a new url it said it couldn't open the file I was playing because it was in use. The url doesn't contain that video however...
Again, it uses native is widgets now. So if you think cocoa, aero and gtk themes/widgets are ugly then sure, I guess. Check out this site to get a feel for the more modern tk http://www.tkdocs.com/index.html
I'd vote against that style of organization. I keep tests outside the module source area because I don't want the tests code to be installed with the package itself. You could control this in the setup.py, but that feels like a workaround rather than a solution. It also helps to ensure that you can't import something from your tests into your source code and it also helps to ensure you package gets installed properly because it won't rely on your package code being relative to the tests. Another way to look at it is while the tests are related they are not in fact part of your package so keeping them under the same structure does not make as much sense. This kind of setup also lets you keep all tests together which for a larger project helps to keep things organized.
I'm surprisingly irritated there is neither a total amount given up front nor does this cover all of Breaking Bad. Neat idea but a little short on delivery.
Thanks, I'll have a look at that.
This is pretty nice! It inspired me to make something of my own that may actually be useful to you, find it [here](https://github.com/Rhysjc/PYTRip). It just simplifies the process of ripping stuff on YouTube.
Don't get me wrong, I splat import on one time use or temporary scripts too. It's all about context I suppose. I just wanted to point out it is considered bad practice for larger and/or shared projects. 
Qt 4 also has [QML](http://qt-project.org/doc/qt-4.8/qdeclarativeexamples.html)
wxPython gets some pretty short shrift. 
&gt; EFF thinks there is plenty of prior art available. Yes, but it may have been published, but not widely known, while the patent office was looking for prior art. The patent office may have also been lazy in their PA search. It looks to me in the '504 case, that the patent office was unable to use "common sense" when invalidating patents (this was since rectified by SCOTUS). &gt; If one of those prior artists had patented and released the idea like Tesla there'd be no threat. This isn't necessarily true. Searching previous patents is just one of the places the USPTO is supposed to look for PA. If they didn't properly do their PA search then it wouldn't have found anything anyway. Furthermore, it costs thousands of dollars to get a patent application approved and maintained throughout its lifetime. And furthermore, if you don't hire a lawyer to review the claims before applying then you may be awarded a completely useless patent anyway. My point is that, as you noted, it's going to cost thousands of dollars to get any defensible patent, so it would be kind of financially pointless to simply immediately patent-left it. There isn't really a good way to fix the fact that you *will* need to pay a lawyer to write your claims. The alternative is to publish it (for next to free) online and hope the patent reviewer magically sees it when searching for prior art. Having a forum dedicated to people finding prior art for the patent office indicates that the patent office sucks at finding prior art themselves. I realize that this is their job, but it's a difficult one and patent examiners are just people. &gt; As I think an actual patent might hold more weight in the current (broken) system than prior art seems to. I doubt it, because all a previous patent is considered to be is prior art. In fact, if the Claims section of the patent is limiting, it may not be as useful as prior art as simply publishing the invention itself. Note that patents and previous patent applications are only some of the things that are considered prior art. &gt; But, you know, theory is good too. Be more condescending, please. &gt; I'm sure in your classrooms the patent office always finds the prior art. There it is! Nope, in fact we went through specific examples of failures of the current patent system, including finding prior art. The professor himself actually had one of his patents (that was granted) made pointless because his patent lawyer didn't lift a finger when trying to write the patent claims.
From the way I read it, it seems that traditional locking systems are faster, but SMT systems could be easier to develop for because you don't have that worry clogging up your algorithms anymore. Also, the reason locking is faster may only be because we have a better understanding of it and years of optimization against it...or at least that's what my brief research implied.
It was fx101 who moved the goal posts then because alcalde never said anything about not being able to do it in other languages.
Right, but no native widgets, which makes QML practically useless for full-fledged apps. With Qt 5, QML gained native widgets for desktop, iOS and Android. (Also, a *whole bunch* of other improvements in speed, versatility and bugginess)
Thanks, I hadn't seen those API docs. I think it's still lacking the kind of examples and explanation that pygtk has, though.
They have not removed the old APIs only depricated them. What classes are you using to build your widgets? The new widget classes will look native. http://www.tkdocs.com/tutorial/firstexample.html They show how trivial it is to build a simple app with examples not only in Python but in Ruby and Perl as well. 
Unsatisfied with my previous answer I did a little digging. Here is the SO explanation: http://stackoverflow.com/questions/6500630/making-tk-look-like-a-native-linux-app Here is the style page from tkdocs: http://www.tkdocs.com/tutorial/styles.html
http://en.wikipedia.org/w/index.php?title=Lock_%28computer_science%29#Disadvantages " Locks are only composable (e.g., managing multiple concurrent locks in order to atomically delete Item X from Table A and insert X into Table B) with relatively elaborate (overhead) software support and perfect adherence by applications programming to rigorous conventions." http://stackoverflow.com/questions/2887013/what-does-composability-mean-in-context-of-functional-programming Unfortunately, if there is more than one lock in the world, it is no longer true. If thread A callslock(x); lock(y); and thread B callslock(y); lock(x); then it's possible that A grabs lock x and B grabs lock y and they will both wait indefinitely for the other thread to release the other lock: deadlock. So, locks are not composable, because when you use more than one, you cannot simply claim that that important guarantee still holds -- not without analysing the code in detail to see how it manages locks. In other words, you can no longer afford to treat functions as "black boxes".
Consistence is most important. However, I tend to type the full name for less popular packages, or packages with short names, e.g., import re import math But for popular packages, such as pandas, numpy, matplotlib etc., I import them as import numpy as np import pandas as pd from matplotlib import pyplot as plt I really hate imports like: from numpy import * from pylab import * since it overwrites stuff in your global namespace, e.g., the `sum` function. It burned me once when I was doing benchmarks and used %pylab inline instead of %matplotlib inline
learn Flask which is an easy Framework and easy for beginners no MVC, like in Django it is just framework see this example i wrote http://pastebin.com/tkcK60iu 
http://learngtk.org/tutorials/python_gtk3_tutorial/html/
I think that tight integration between PyCharm and ipython notebook would yield something amazing. I have to use Matlab at work, and some of the other users would likely have too much to deal with in pycharm, while not very obvious debugging/workspace exploration with ipython notebooks. If Pycharm directly supported prototyping, iteration, and refactoring, you'd get the best of both worlds.
I tend to do: from x.y import a, b, c except for standard library modules, where I normally do: import x
In our country concept of copyright hasn't fallen yet, kind of like Sweden ware PirateBay is run
I see someone already mentioned Flask. [web.py](http://webpy.org) might also be a good choice, depending on what you need.
Enaml looks great! Very much like QML (that's a good thing). One advantage of QML/PyOtherSide is that your Python code does not need any dependency on Qt. PyQt/PySide (but not PyOtherSide) can be painful to install and distribute. With QML/PyOtherSide, your app is a regular Qt app, and can be distributed like that. It just happens to embed a Python interpreter. Still, Enaml looks great! I would love to see an experienced comparison between QML and Enaml!
Probably because an app is a end user thing: pip solves a different requirement (eg. developers side).
Pip can install "scripts" as well as modules, which can be anything all the way up to fully blown desktop programs. For all intents, pip is a parallel package manager for C/Py stuff, but fully cross platform. So if Linux package managers deserved a mention, so I think does pip.
Agreed. I tried both qt and wx this week and while they're both painful, wx's installation pathway on Ubuntu was way easier than PySlide's. 
I prefer pytest. 
if you need to compare values against `True` and `False`, (as opposed to truthy values), you can use `content is True`. 
I could if I wasn't dealing with numpy booleans. They require the == operator, making the instance checking necessary.
Basically : - tornado if you just want web dev - twisted if you want advanced networking - asyncio if you want to build new tools with clean primitives - gevent for a mix of all that, but require a C extension Lastly I tried to raise awarness about a new and promising but young async techo in the Python world : WAMP. Explanation : http://tavendo.com/blog/post/is-crossbar-the-future-of-python-web-apps/ Example : http://tavendo.com/blog/post/small-demo-of-a-pragmatic-use-of-wamp-in-python/
No. pip is for language libraries, not applications. Applications are platform specific, and are not installed via pip because you almost always need to install platform binaries, such as qt, pygame, whatever. 
Nor anything that guarantees these were spoken by Jesse.
It seems like `content` is doing two unrelated things.
I'm building an indexer somewhat similar to that of numpy and pandas. Hence, it needs to be able to handle many different input types from the user.
If.you like, you don't have to use pip for Applications. But it's quite capable of delivering them.
Could you give an example of the code you're trying to get to work?
Hey there, I've removed this as it is unrelated to Python. You might want to check out /r/web_design or /r/html.
#!/usr/bin/env python import RPi.GPIO as GPIO, feedparser, time DEBUG = 1 GPIO.setwarnings(False) USERNAME = "username" PASSWORD = "password" NEWMAIL_OFFSET = 1 MAIL_CHECK_FREQ = 60 GPIO.setmode(GPIO.BCM) GREEN_LED = 18 RED_LED = 23 GPIO.setup(GREEN_LED, GPIO.OUT) GPIO.setup(RED_LED, GPIO.OUT) reqttl = "Required Email Title" x = 0 while True: requests = feedparser.parse("https://" + USERNAME + ":" + PASSWORD +"@mail.google.com/gmail/feed/atom") newmails = int(feedparser.parse("https://" + USERNAME + ":" + PASSWORD +"@mail.google.com/gmail/feed/atom")["feed"]["fullcount"]) emailttl = 'Required Email Title' in requests.entries[x].title //Checks element x of Atom list (array) for the specified email title if DEBUG: # print "Begin debugging" print "You have", newmails, "new emails!" if emailttl == True: GPIO.output(GREEN_LED, True) GPIO.output(RED_LED, False) else: GPIO.output(GREEN_LED, False) GPIO.output(RED_LED, True) time.sleep(MAIL_CHECK_FREQ) //Haven't added the x += 1 loop yet. 
&gt;Everything I google is old (2011 or older) Just so you know for later: check out google's age filter.
I can't speak for qt, but are you saying that *using* wxPython is painful? Or installation is painful (though was less painful than PySide?).
You could use the Python script [Videogrep](http://lav.io/2014/06/videogrep-automatic-supercuts-with-python/) to automatically cut together a video of every time someone says that word in all episodes of the series (that might be very long in computer time, but it would be just one command in a terminal).
Fuck your share button is annoying on mobile
For using python as a calculator, I usually use `from math import *`. I should make a script that makes using it as a calculator easier.
wxPython and Pyglet are my favorites. You probably shouldn't advertise this as a rundown of Python GUI toolkits if you aren't really familiar with most of them.
I did mention it: &gt; You can easily distribute tools for developers as Python packages to be installed using pip, but end users don't generally have Python and pip already set up. Python packages also can't depend on something like Qt.
Installing PySide on Ubuntu should be really straightforward: sudo apt-get install python3-pyside # Or python-pyside if you want Python 2
I expect very few people are familiar with more than a few of them. This is partly my opinions - I'm not trying to claim that it's objective or complete.
:/ don't be sad!
 &lt;!-- Social buttons --&gt; &lt;div id="addthisbox" class="addthis_toolbox addthis_peekaboo_style addthis_default_style addthis_label_style addthis_32x32_style"&gt; &lt;a class="addthis_button_more"&gt;Share&lt;/a&gt; &lt;ul&gt; &lt;li&gt; &lt;a class="addthis_button_facebook"&gt;&lt;/a&gt; &lt;/li&gt; &lt;li&gt; &lt;a class="addthis_button_google_plusone_share"&gt;&lt;/a&gt; &lt;/li&gt; &lt;li&gt; &lt;a class="addthis_button_linkedin"&gt;&lt;/a&gt; &lt;/li&gt; &lt;li&gt; &lt;a class="addthis_button_twitter"&gt;&lt;/a&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-4f7088a56bb93798"&gt;&lt;/script&gt; &lt;!-- End of social buttons --&gt; 
You don't need `is True` or `==`, just use: elif type(content) in (bool, np.bool_) and content: res.append(blank2word[i]) 
Great tutorial! 
I've just tried running that code and it looks like this (ugly): https://cdn.mediacru.sh/9HnMjwQ8PywZ.png
neither. 99% of the time, I do... from numpy import array, array_equal, zeros from numpy.linalg import norm It's faster looking up the function and more explicit. For matplotlib I do use... import matplotlib.pyplot as plt but that's pretty much the only case where I do that. Finally for standard library stuff, I do import sys sys.exit() import os os.path.join('stuff') So pretty much it just depends on what I feel like, but I'm very consistent on how I do it for certain modules.
My other reply to the same message has the explanation/fix for Linux as it seems to default to non-native for only Linux. http://www.reddit.com/r/Python/comments/29y462/so_you_want_to_write_a_desktop_app_in_python/cipwmve
With plugins and a good web server option, pretty much. You should give serious thought on the auditing aspect. It's easy to hack something "almost good enough" and then realize that it's useless in practice. Even just a good log file is not trivial to put together when the events happen non-linearily and when you want a customer to be able to review the events. DB-backed audit trails are good but you really need to figure out the query and search interface. RBAC is easier to fake, even just a user / admin flag is probably enough initially and for many apps. And when you've got that well setup, it's not too hard to go back in and add granularity. Flask-Login and Flask Principal should go a long way there.
I think you can, but it doesn't seem very useful - you don't get the support and tooling for making fully native applications, and you don't get the cross platform capability from using a framework like PyQt.
If you need something really simple you can do it with bottle, it is as simple as it gets. http://bottlepy.org/docs/dev/index.html
If you're willing/able to use Python 3.4, `asyncio` is the only *real* game in town. If you're stuck with something older, Twisted is probably a good place to start.
Guess what? It's the same in every other language!!!!
The answer is beyond simple. Import ttk (themed tk) into your application, and widgets will be themed natively. from tkinter import * from tkinter.ttk import * [docs](https://docs.python.org/3.1/library/tkinter.ttk.html)
I remember there being versioning issues but it was late and I was pissed off. Consider this an IOU as to going back and looking at what I had difficulty with. 
Something like this? https://github.com/HatsuneMiku/googleDriveAccess
&gt; I could not care less. Gah ! When did you even get so self-entitled ?! 
Speaking of learning the asyncio basics, [this talk by Jesse Jiryu Davis at Pycon 2014](http://pyvideo.org/video/2565/what-is-async-how-does-it-work-and-when-should) covers just that. 
ok, well I dont have that app or know how to use it. I cannot login without a mobile phone. So let me suggest elance, you might find someone there quickly.
Not even close. JavaScript: &gt; new Boolean(true) instanceof Boolean true &gt; new Boolean(true) instanceof Number false C#: &gt; Console.WriteLine(true is int); False PowerShell: PS&gt; $true -is [int] False Ruby: irb(main):001:0&gt; true.is_a? Integer =&gt; false Java: public class school { public static void main(String[] args) { Boolean f = true; System.out.println(f instanceof Boolean ? "is boolean" : "is not boolean"); System.out.println(f instanceof Integer ? "is int" : "is not int"); } } Doesn't even compile! .\school.java:7: error: inconvertible types System.out.println(f instanceof Integer ? "is int" : "is not int"); ^ required: Integer found: Boolean 1 error Erlang: There [is no Boolean data type](http://www.erlang.org/doc/reference_manual/data_types.html#id69252). Instead the [atoms](http://www.erlang.org/doc/reference_manual/data_types.html#id66656) `true` and `false` are used to denote Boolean values. PHP: $ php -r 'echo var_dump(is_int(true));' bool(false) Racket: &gt; (number? #t) #f Haskell: Prelude&gt; fromIntegral True &lt;interactive&gt;:2:1: No instance for (Integral Bool) arising from a use of `fromIntegral' Possible fix: add an instance declaration for (Integral Bool) In the expression: fromIntegral True In an equation for `it': it = fromIntegral True
Would not be surprised if hosting those subtitles on Github breach some sort of copywrite. Just saying... 
but in the actual implementation it is
In case you're wondering why this is true, `bool` was added to the language via [PEP 285](http://legacy.python.org/dev/peps/pep-0285/) to [Python 2.3](https://docs.python.org/release/2.3/whatsnew/whatsnew23.html), well over a decade ago. Guido's reasoning is in the PEP, but essentially he wanted to retain backward compatibility with code that was using `int`s, and it was easier than making a brand-new integral type.
You could also try my [TwitterAPI](https://github.com/geduldig/TwitterAPI). It's "minimal" in the sense that you pass any Twitter endpoint you want and TwitterAPI returns the results. It works with both Python 2.7.X and 3.X; supports REST and Streaming API's; and, it has has a class that takes care of paging results if you are interested in collecting numerous old tweets. Check out the github site for examples.
Thanks! There's trollius for 2.6+ https://pypi.python.org/pypi/trollius which is a back port 
I'm using Kivy now (and have already). It really is nice to work with, especially for touch interfaces. Check out some of the most recent app contest submissions and if you want my own learn-this-framework app [Sign Maker](https://play.google.com/store/apps/details?id=org.mercury.signmaker). Lemme know if you have any questions.
I have simliar experience in PHP to you. I learned python 1.5 yrs ago. While I still code mainly in php I'm slowly adding python code to my work. I pity the poor dev who has to follow me! A few things: * Python is a 'real language' that can be used for many things. Php is only web based. There are libraries for everything, the OpenCV library really rocks my world. * Codeacademy was a great place to just 'begin' * Start with a small program (one trivial in php) and try to convert it to Python. Suggestions include a todo list or, more interesingly, a rpg loot table. * "Learn Python the hard way" has a good rep on this sub. * The web frameworks to consider are Django , web2py, flask, bottle (and some others) * Python 3 is the version to pick if you were starting today. * Know that the one liners in Python are, in the main, not needed and should be considered an exercise - just make code clear and concise. (there are exceptions which I'm sure will appear in comments) * Python is not perfect but it is better than Php * You will learn to love no semi colons, no dollar signs and no brackets. * You will love the tab indent to start, then realise it's faults with large 'if' statements * All in all Python is better than Php, but I have found it to be not as supported on web hosts as php is. There are web hosts that specialise in Python though and they have a good rep. OF course there are obvious exception to every point above, but the gist is "go for it!" 
Nice find. Also I do see the extra ) and it busted the URL I think you have to escape it like this: [Contact](http://en.wikipedia.org/wiki/Contact_\(novel\))
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Contact (novel)**](https://en.wikipedia.org/wiki/Contact%20(novel\)): [](#sfw) --- &gt;___Contact___ is a [science fiction](https://en.wikipedia.org/wiki/Science_fiction) [novel](https://en.wikipedia.org/wiki/Novel) written by [Carl Sagan](https://en.wikipedia.org/wiki/Carl_Sagan) and published in 1985. It deals with the theme of contact between humanity and a more technologically advanced, extraterrestrial life form. It ranked No. 7 on the [1985 U.S. bestseller list](https://en.wikipedia.org/wiki/Publishers_Weekly_list_of_bestselling_novels_in_the_United_States_in_the_1980s#1985). The novel originated as a screenplay in 1979; when development of the film stalled, Sagan decided to convert the stalled film into a novel. The film concept was subsequently revived and eventually released in 1997 as the film *[Contact](https://en.wikipedia.org/wiki/Contact_(1997_US_film\))* starring [Jodie Foster](https://en.wikipedia.org/wiki/Jodie_Foster). &gt;==== &gt;[**Image**](https://i.imgur.com/kVMOSYr.jpg) [^(i)](https://en.wikipedia.org/wiki/File:Contact_Sagan.jpg) --- ^Interesting: [^Contact ^\(1997 ^US ^film)](https://en.wikipedia.org/wiki/Contact_\(1997_US_film\)) ^| [^Carl ^Sagan](https://en.wikipedia.org/wiki/Carl_Sagan) ^| [^First ^Contact?](https://en.wikipedia.org/wiki/First_Contact%3F) ^| [^Nor ^Crystal ^Tears](https://en.wikipedia.org/wiki/Nor_Crystal_Tears) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+ciq9x0i) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+ciq9x0i)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Pretty sure this is fixed in Python 3. Edit: nope :( 
That seems like the kind of thing they'd have fixed in the 2 -&gt; 3 transition.
The answers to that question seem to amount to: there are some themes you can use which are better than the default, but still not very good. It sounds like the projects using Qt and GTK for the drawing didn't work very well and lost steam.
I dunno if it's always evil. If your variables are self documenting then it's fine in my opinion. We have a case where we get a list result that sometimes has an errors object. This is a response from a java process we don't directly control. So, (Result,) Or (Errors, Result) Its nice saying robj.results[robj.has_errors] To always get the result object.
Yep, that's what I used to do. Native GUI, bridged with PyObjc to python. There are some gotchas regarding threading with an active GUI, but other than that and the boilerplate for a bridge, it worked really well.
Once you get down to the metal, everything is implemented with booleans. How's that relevant in this scope?
Thanks for introducing me to Enaml. Very comfortable and Kivy-like. You say Enaml is built on top of PyQt, but they say "Enaml is UI toolkit agnostic." . Does this mean that PyQt is simply the only currently available backend? Sadly Enaml looks to be Py2-only for now, so I guess I won't be using it soon -- I don't want to code any new software in Py2.
I had actually been thinking about posting this. I already voted and commented on this feature suggestion several months ago. If done correctly it would be an absolutely killer feature for scientific users, as well as others. Based on the comments from the jetbrains people in the linked feature suggestion and elsewhere, they seem to be considering it. Someone should probably cross post this to the ipython reddit (if you haven't already) and to the ipython mailing list. Thanks for posting it here Rothnic. Maybe I imagined it, but I swear I saw a comment from a Jetbrains employee somewhere that said exciting things were coming soon to pycharm for the scientific community. The recent addition of the console debugger that can be attached at any time seems related to me. Imagine the kernel being initialized by pycharm while the notebook attaches to it, much like can currently be done with the qtconsole. Then, if they managed to allow you to set breakpoints in a rendered notebook within pycharm? I don't know, just a suspicion of mine. Or perhaps simply wishful thinking!
Well, it isn't. 11 ~: python Python 3.4.1 (default, May 19 2014, 17:23:49) [GCC 4.9.0 20140507 (prerelease)] on linux Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; sum([True, True, True]) 3 
It's not too much more code to write it the "pythonic" way: `"Yes" if my_bool else "No"`
I personally would suggest focusing on getting to know the syandard library extremely well. You will thank yourself in the long run, diving into frameworks immediately I feel takes away from truly learning the beauty of python. The frameworks are all great and all vary greatly, but you can do everything you need to do with the standard library, its more robust than most think.
Yes I agree. I was doing some ML stuff and just posted the packages that came right on top of my mind.
I'm sorry I just thought about this and creamed my pants a little. Shitty keyboard shortcuts are the only thing keeping me away from notebook.
Do you have any other programming background? Unlike php Python is a full fledged programming language which means it has objects(pretty much everything in python is an object), classes and all of the bells and whistles that come with it. So after you got the basic syntax you need to nail what a class is how to use it to develop a proper project structure. Also if you're into django it uses MVC(model view controller) that you should look into as well. Basically don't forget to read up and learn programming philosophies when learning syntax, because python is a very philosophy driven language in my opinion. I think that's the biggest barrier since the Python syntax is really pleasant and easy-going.
&gt;You will love the tab indent to start, then realise it's faults with large 'if' statements General rule of thumb is that if you have more than 3 nested IF statements, you're doing something wrong.
lol well thats true. what's relevant is that OP is making a huge deal that python bools being ints
This is also why argparse is broken for BOOL input.
What is needed is not just setup/teardown per test, but per group of test, as some setups take a long time, such as creating a test database etc. zope.testrunner solve this with layers, which is cool, you should take a look at that.
Yeah I had looked at it a few times and kind of assumed it would be a feature when I saw the note about the embedded console debugging. I checked it today and then sorted all of their issues by number of votes and found out there are many more votes on other things. Hopefully we can make it seem more important.
&gt; I guess the best solution is just to flip the if statements? Is there some reason you can't use `type(content) == int` instead of `isinstance()`? if type(content) == int: res.append(blank2word[content]) elif type(content) in (bool, np.bool_) and content: res.append(blank2word[i]) Edit: NVM, numpy has [like a dozen `int` types](http://docs.scipy.org/doc/numpy/user/basics.types.html).
Have you tried py.test? It seems to address most of your issues.
Huh. Whoops, sorry!
Plenty of complex CLI apps, including one of my own (PySplicer) are pip-installable. Having them launch GUIs is only a matter of code. If dependencies are required not installable directly through pip, you could just sublrocess apt/yum in the worst case, though for pysplicer I just instructed the user to install XYZ at runtime if not found. That's because my dependency (ViennaRNA) wasn't available through APT anyway, though.
And how are we supposed to help you? Any specific questions?
Not to rain on your parade, but I think you should try py.test, it solves most of your points.
All good advice. You may want to revisit your early python code and update it as you learn more about what is "pythonic". (That comes with experience, and with reading good python such as from standard library documentation and its sources). 
There is a good chance it will "just work" - you could also ban the app from low-res displays if they are a problem
Yeah, combined with the hovering menu my viewport became too small for me to bother with the article. Will have to read it on desktop later.
Ok, making good on my IOU, the issue wasn't actually installation. The problem was that, through a reasonable look through the pyside.org website, I couldn't find a gui designer (see: Glade for wx or IntelliJ for Swing). Maybe that was because I couldn't quite get a handle on the ecosystem, but honestly I wasn't trying to develop anything particularly special - all I wanted to do was pick something up, put 4 buttons, a colour selector and 4 text fields on it and then do some pretty simple logic. 
Note, you can use it on 3.3 as well if you want, just by installing the [asyncio package](https://pypi.python.org/pypi/asyncio/) off PyPI.
That site is badly broken on iOS7. Just white (non-selectable) text on a white background. :/
I don't think anyone wants to do your homework for you.
FYI `True` and `False` constants were introduced since Python 2.2.1. These values are simply `1` and `0` back then. Until Python 2.2.1 simply `1` and `0` had been diverted to represent boolean states. The `bool` type was introduced since Python 2.3, but for backward compatibility it had to be a subtype of `int`.
Also, I suggest using `isinstance`: if isinstance(content, (bool, np.bool_)): if content: # I assume you want to add nothing if content is false res.append(blank2word[i]) elif isinstance(content, int): res.append(blank2word[content]) EDIT: nevermind that, [NumPy apparently has a function for that](http://www.reddit.com/r/Python/comments/29zdz2/python_caveat_booleans_are_instances_of_int/ciqgjt6). This is the way I'd do it in the absence of NumPy, though.
My advice, considering your background with PHP: learn Python for anything BUT web development! It is a general purpose language, suitable for many fields (and cross-platform), so leave web dev for a while and explore other areas of computing while learning Python. When you are proficient enough with the language, and freshened your mind away from the web ecosystem, then you may start learning a web framework. Do not make the double-leap too fast: (Web) frameworks enforce styles and mechanisms that may obfuscate the true nature of a language, and while Python's motto is "explicit is better than implicit" you may still experience black magic out of its web frameworks.
&gt; Php is only web based. Not really true anymore. PHP can be and is used for general system scripting. Some PHP applications like Magento use PHP CLI scripting a lot. PHP's even had an interactive shell since 5.1. It's still inferior to 'general' scripting languages like Python and Ruby though.
Many applications with complex APIs do in fact provide python wrappers for their REST APIs. This is very useful when dealing with more complicated stuff like pagination etc. Of course, if there is no official wrappers available, It's easy to send out HTTP requests with `requests` and parse the JSON in Python. And hey, if there isn't an official wrapper available, write one and put it up on GitHub!
I am thinking about doing this. That's one reason I am asking about the "Python" way of working with APIs.
TIL
No, layers are actually stackable and orthogonal to the test classes. So you can have one layer that sets up a database, another layer that creates test users and permissions, a next layer that will create some test data, and then finally the testclass setup. It's pretty complex, but for big frameworks like Plone it cuts down the time it takes to run the test with an order of magnitude.
&gt;PHP can be and is used for general system scripting. The horror...
Tornado is great for non web use too. The various levels of protocol abstraction are separated very nicely.
There's nothing wrong with your approach, *per se*, but it's usually nice to leverage some python idioms to make your data easier to work with. In practice, this usually means Python wrappers do the following: 1. Get the data from the web (e.g. with `requests`) 2. Instantiate a custom class to encapsulate said data 1. implement special methods like `__getitem__`, `__repr__` and `__iter__` to enable conveniences like indexing, informative object printing and iteration, respectively If the web API you're trying to wrap has rules, it might also be useful to cache your data locally, and re-scrape only after certain time constraints have been met. To do so, [decorators](http://www.brianholdefehr.com/decorators-and-functional-python) are a natural solution. If you'd like, you can take a look at [this](https://github.com/louist87/lurkmoar) quick-and-dirty (and completely useless) wrapper I wrote for 4chan's JSON API. It still has a few rough corners and there are a dozen or so bugfixes I haven't had time to push, but it demonstrates my above recommendations. (Oh, and if you see any stupid mistakes, a pull-request would be greatly appreciated!)
Here would be a complete program in web2py to do what you asked: ## these would come from your library: def encrypt(text, passwd): ..... def decrypt(text, passwd): ..... ## this would be in the scaffolding controllers/default.py file: # @auth.requires_login() ## optional line in case you want to restrict access to logged in users def index(): from yourlibrary import encrypt, decrypt form = SQLFORM.factory(Field('mode',requires=IS_IN_SET(('encrypt','decrypt'))), Field('password',type='password'), Field('input',type='text',requires=IS_NOT_EMPTY())) if form.process().accepted: if form.vars.mode == 'encrypt': output = encrypt(form.vars.input, form.vars.password) if form.vars.mode == 'decrypt': output = decrypt(form.vars.input, form.vars.password) else: output = '' return dict(form=form, output=TEXTAREA(output,_readonly=True)) The page would be accessible at http://127.0.0.1:8000/&lt;appname&gt;/default/index
++ anything Doug Hellman does. Guy is awesome.
Am I the only one being extremely annoyed by this "Medium" platform slapping a huge banner title first thing first? I never realize there's more until I notice it's on Medium. Usability failure at its best. 
This was going to be my recommendation: building a class/collection of classes that would handle repetitive tasks for you instead of working directly with the data 100% of the time. 
&gt;The problem was that, through a reasonable look through the pyside.org website, I couldn't find a gui designer (see: Glade for wx or IntelliJ for Swing). http://qt-project.org/wiki/PySideDocumentation &gt; http://qt-project.org/wiki/QtCreator_and_PySide sudo apt-get install qt4-designer (or install the whole qtcreator thing) You can also find various threads/tutorials by googling for "pyside designer".
Put your code on GitHub and add a link here. I can take a look.
I still keep WingIDE around just for the easy and excellent remote debugger (which works with matplotlib). If you start up an IPython notebook and are calling functions in normal python scripts, you can attach a remote debugger using WingIDE. It doesn't debug the actual notebook, but it's helpful when testing out new code and transplanting it into a proper python module. All you do is have one notebook cell that is 'import wingdbstub' and voila, you can set breakpoints in any .py file. It's not perfect, but it's a stop gap until PyCharm can more easily do the same.
In that case you could do: robj.results[-1]
PyPi isn't where you need to be looking: it's not an all-inclusive resource. If you'd hit google instead, you would have found [this python API wrapper for the Meetup API](https://github.com/meetup/python-api-client), which is also listed on the list of [Meetup.com API clients](http://www.meetup.com/meetup_api/clients/) hosted at meetup.com.
Mmmh, that was clear from your your initial "setup/teardown per test, but per group of test". Have you ever had a look at Spring Python and its IoC which is suitable for the use case you describe here.
This link should help you a little bit : http://www.php2python.com/ 
I dunno I will always prefer less code that is self explanatory. Its not like python is going to one day treat a bool different from 1/0
You should report it to the author. But my first guess is that it's not broken in IOS7, it's broken on a specific browser.
You don't need Spring Python or an IoC container to do inversion of control, and inversion of control does not solve this issue. You need a test runner and test framework that supports it.
I had a similar experience quite recently with the Pushwoosh API. There was a single Python library for interfacing with Pushwoosh, but it was rather outdated so I've rolled my own. I'm probably going to make it available via Pip at some point. I have heard good things about [Hammock](https://pypi.python.org/pypi/hammock/0.2.3) for interfacing with REST API's.
IoC is one way to implement your layer approach. But you seem determined not to make yourself clear so it's hard to discuss further.
Yes, I'm sure you can implement layers while using inversion of control somwehere. But it is not an implementation, and hence it doesn't help more than saying "have you heard of inheritance?" Or "use lists". &gt; But you seem determined not to make yourself clear so it's hard to discuss further. If you find something unclear, I would suggest you ask a question. That makes me more likely to answer the questions you have.
Thanks for posting. I have a couple of suggestions. Twitter doesn't actually place a hard limit of 3,200 tweets. Typically, they store about a weeks worth of tweets. Also, the 5 minute wait between API calls is much larger than necessary. Getting a user timeline calls the [statuses/user_timeline](https://dev.twitter.com/docs/api/1.1/get/statuses/user_timeline) endpoint. You are allowed to make 180 of these requests every 15 minutes, or once every 5 seconds. Alternatively, use [TwitterAPI](https://github.com/geduldig/TwitterAPI); it takes care of paging the results: from TwitterAPI import TwitterAPI, TwitterRestPager api = TwitterAPI(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_TOKEN_KEY, ACCESS_TOKEN_SECRET) pager = TwitterRestPager(api, 'statuses/user_timeline', {'screen_name':'craigaddyman'}) for item in pager.get_iterator(): print(item['text'] if 'text' in item else item)
The question isn't very clear; I'm going to assume you want to know who sent a datagram. [socket.recvfrom](https://docs.python.org/3.4/library/socket.html#socket.socket.recvfrom) returns the address in addition to the data.
For now I'm just prototyping solutions to see what works, but I want to run it as a game server and so it has to constantly handle gamestate, but it needs to know which client send what input. Would socket.recvfrom be adequate for this? Sorry for the probably novice question. 
You may be interested in: https://thoughtstreams.io/glyph/your-game-doesnt-need-udp-yet/
Ignore this troll. The way I do it is authenticate and then send a cookie. Cookies count as a session. Cookies are sent every request. Requests without a cookie start the auth request over again.
Very interesting read, he makes some good points. I chose UDP for two reasons: 1. I've only worked with TCP so far, want to learn some UDP. 2. the UDP broadcasting makes it 'simple' to communicate with everyone at the same time. Rather than having to manage several concurrent connections for a constant gamestate. I would then run TCP connection the information that rarely changes.
When I originally made the comment, you didn't provide any details as to what was involved. Yes, doing a checksum would add overhead when data is sent rapidly, but what you're asking for is basically TCP and UDP having a baby. The only real way to do this is to some sort of checksum or other integrity validation. I suggested the public-key option because while it does add some additional overhead, its more so a matter of just decrypting data. Whereas a checksum would require formulating the data in the proper order, getting the hash and then comparing it against whatever is stored/expected.
Any good referenced to how you can implement those cookies? My googlefu failes me :) Thanks a lot for the feedback
I realize I provided little context early on, however thanks for all the feedback! I'll look into UDP with public keys!
Yeah, the killer issue is edge detection not just posterisation. 
If it's not on PyPI it should be
Agreed, and you are correct. To get that cartoon/poster effect a few iterations of bilateral filtering would be much better. Well, now that i have looked at the images, the black edges would be difficult. But i still stand by my bilateral filter.
&gt; Would socket.recvfrom be adequate for this? Most likely. If the game client opens their udp socket once and leaves it open, that client will always have the same ip/port. If they're opening the socket, firing some messages, then closing, the port will change but the ip will be the same. If you want to run multiple game clients on one box you'll need to use the port or, like you said, some sort of session id within the application protocol.
Such a silly thing to nitpick. If the language supports it and its not ugly then I see no problem, readability counts. If you are planning on running your code from 2.x on python3,(4?) without expecting differences than you have bigger problems. I'm still praying python 3 doesnt turn into a perl5 scenario.
Unittest has this as well in 27 and on- setUpClass maybe? I have to support 26 with standard library so I can't use it yet...
Fair enough. I'll be sure to do a followup with edge detection added.
13 years of perl, 5 years of PHP, moved to python in a django environment 3 1/2 years ago. I found learning both at the same time was one of the toughest transitions I've made in my life. Python itself will be a pretty easy transition, but trying to pick up Django and it's uniquenesses at the same time...there can be some gotchas. I found myself struggling a bit with the ORM after 20+ years of raw SQL access. There are quite a few methods that Django just creates for you, and that can throw you off as well. IPython is your friend. And we sent new python coders here: http://learnpythonthehardway.com/book/
Cool! I had the same idea a a few weeks ago. I'm using requests instead of urllib2, and I'm not using praw. [wildSoup](https://github.com/Nisroc66/wildSoup) It's interesting to see a different approach. I'm using findAll from bs4, I'm considering switching to lxml because I find bs4 slow. 
py.test indeed looks great--listing fixtures as arguments to be injected is so succinct.
No, it's class level setups only, as I understand it. You can't build a hierarchy of setups where each setup is run only once. So if you have 20 classes that all need a test database, you will create and destroy it 20 times. At least that's how it worked for me when I tried.
Should have picked that up from LPTHW.
I've been a TA for a first year undergraduate class a few times, and in my experience a raspberry pi is a great place to start, but there are lots of options: Raspberry Pi, XNA, Unity, etc. The key thing is you need to work with them to make something cool -- asking people to type their name in and then printing it back in a sentence won't hold anyone's attention for long. Now, that being said, I recognize that the students I worked with were 18 years old, so there are likely some significant differences in the way they learn. Nonetheless, here is my experience: I would try to stay away from more theoretical topics. While I'm sure some people find binary addition interesting, there's little reason to teach someone who is starting out the fundamentals of computers, how sorting algorihms work, etc. We would usually get into those topics in the sixth week of class and beyond. Instead I would focus on building something. Ideally something that they find interesting. The problem with this approach is there aren't many ways for someone who is completely new to programming to create something interesting. One path that I've seen work is to create something interesting yourself (be it a small game, a very basic robot, etc) and let the person play with it. Focus more on how darn cool it is, and less on how it was done. From there start working backwards. Take the finished product and break it down into its constituent parts. Then, while working with them, rebuild each part from scratch until you have re-created the original software. Hopefully by the end of it they'll think "Damn, that is cool!" and "Hey, that wasn't so hard. I can do that!" As an aside, you're an awesome uncle (or aunt)! Growing up my parents surrounded my brother and me with computers, but they had no idea how to use them. I am incredibly grateful to them for recognizing the importance of computers, despite knowing little more than how to turn them on. The only thing that could have made it better is if one of them knew how to program -- your nephews are very fortunate!
Give them a Raspberry Pi and [this book](http://www.manning.com/sande2/).
Are you within reasonable distance of a pycon? They do kids camps. PyOhio is about to open registration
...
Well, for starters.. where do I find the Nmap module to install? I know it's for a linux CMD tool, but must I have linux to write it? 
Show them how to brute force their math homework. Eval will blow their mind. 
No, just once, in fact. If there is say 5 test classes that all need the same database setup, the database should be set up once. Those tests should then be run, and then the teardown should happen. What's more is that there can be one layer that sets up a database, another layer that creates test users and permissions, a next layer that will create some test data, and then finally the testclass setup. All of these will be run once. Another test can have the same database and users, but different test data. It's pretty complex, but for big frameworks like Plone it cuts down the time it takes to run the test with an order of magnitude. 
Wow, that's with Kivy? It works wonderfully! I hadn't even considered developing Android apps in Python. I think I might want to get started with that as soon as possible, if it's not harder than that. 
I see. Thanks for pointing that out. Regarding the API Wrapper for meetup, it doesn't seem under active development and doesn't include a license as far as I can see. There is also no documentation on how to use it.
I'll look into Hammock, thanks!
Let me know if there is any success with this, I'm trying to learn myself :)
&gt; setup/teardown per test, but per group of test What's the link between this and your layer approach? 
Thanks! I think you're absolutely right about getting them excited early. They're mostly interested in games (of course), so I'm looking around for a simple pygame script for linux that can be easily broken down. I've got yet another nephew on board, so now I have 3 students! Hopefully I can try to talk my nieces into it as well. While I was showing one of my nephews some of the basics my neice walked up and asked what we were doing, and he said "you wouldn't understand, you're a girl". I quickly nipped that in the bud and told them that there are tons of girl programmers out there that are very good, even smarter than me, and to never tell a girl that she can't do something. It's crazy how early sexism starts :-/
Great idea! I actually have a raspberry pi on hand, maybe I can get them interested in it. Better yet, maybe I'll give them a homework assignment and tell them their reward will be a free raspberry pi :-)
If you're relying on broadcasts then you will be limited to having all the clients on the same network segment. That might be fine for your use-case but I just thought I'd point it out as I've seen way too many applications break when used on more complex networks.
These guys take _smart_ to a higher lever. I'm more and more impressed with every release.
well the plan is to use a mix, but I will definitely be doing this small project on a trial and error basis 
Yeah, my bad. I will try to look into this tomorrow. I added a metaclass so brrr.
The IUS Community Project creates RPM packages of newer versions of Python for installation on Enterprise Linux (RHEL/CentOS/ScientificLinux). Python 3.4 has been out for several months now, but we are waiting on feedback on the RPMs before we push them to the stable repos. If you are able to test these packages, please do so and provide feedback in that Launchpad bug.
thanks!
[python-nmap](http://xael.org/norman/python/python-nmap/) You also have to install [nmap](http://www.nmap.org/download.html). I don't know if python-nmap works on Windows, maybe if you add the path containing your nmap.exe to your PATH environment variable. You have to try..
You'll need to design your data format. A new client connecting will run some sort of connect/login method that requests a session token. On all subsequent messages, the client must send this token, or the server won't accept the message. People tend to generate a random UUID or sha/md5 hash for tokens. def process_msg(data): token = data[:37] msg = data[36:] print('UUID: %s, msg: %s' % (token, msg)) There's tons of security implications and malformed data processing that you'll need to sort out. 
I don't know how this isn't the number one comment. Google was the first thing I did, knowing there had to be something out there. There was, and it's owned by Meetup. 
Same thing, just more elaborately explained, i referenced zope.testrunner from the start. Check it out.
Cookies are an HTTP feature, and have nothing to do with the raw socket programming that OP is asking about.
He should use it to select the quietest parts to simulate to everyone else in the world how Americans perceive televised soccer during non-World Cup viewing.
You have may options, such as: a) Do diffie-hellman to exchange a shared secret and encrypt the messages with the shared secret on both sides. b) Use a HMAC. This is relatively "slow" though, so it really depends if you want to make sure no one can spoof a packet from another player or just wishes to identify a client.
install and learn to use [flask](http://flask.pocoo.org/). it's a nice small web framework that has pretty much all the features you need. if you want to use a database you should probably look into [sqlalchemy](http://www.sqlalchemy.org/), but that's a complex beast.
Enaml used to have a wxPython backend but its not fully supported anymore. PySide more-or-less works, I believe. The only reasonable reason not to use PyQt is one of licensing, in which case PySide is the fallback. Lack of a Python-3 story is Enaml's biggest weakness. It can't really call itself a Next Generation GUI framework while not supporting py-3.
No worries.. :) I don't know if this is a consideration or not but my other suggestion would be to lock down the interfaces/api of your classes as soon as possible. I've never used the framework in the following article but I have faced similar issues with another Python framework. The issues and principles can apply to any framework in any language. It has some good takeaways in terms of what to avoid. http://www.shift8creative.com/posts/view/thinking-about-using-laravel
I've had to do a decent amount of research on asynch. I've messed with pretty much all of them. If you're on 3.4, go with asyncio. If you're on 2.7, gevent is faster and simpler than twisted, tornado, or eventlet
And it's the only language I know! When I was originally learning it all my (Tech) friends were learning java and c++.
A big win for Python, well earned.
I went to a tech school. I got scared of the CS (taught in C, no fucking joke), so I took programming for engineers (MATLAB). Wasn't until after college that I did the MIT 6.00 (Python) and actually got a feeling for how to program.
I'd prefer this in Python 3: *_, result = robj
One of my old college friends used to joke that Python is glorified pseudocode. As I told him, thankfully this means that it's very easy to transition from Python to some other language...
nice! good job!
I wish my intro to CS class was in Python... When I took it, it was in C (and it was only back in 2010!). My data structures class was in C++ at least, which was marginally better. Then I had to learn Assembly...
As far as I know you can't just do it like that. If you want to make app for web and desktop then you might need to write your app as gtk3, read more here https://developer.gnome.org/gtk3/stable/gtk-broadway.html. Or use something like Pyjamas http://pyjs.org/ to make your app. There might be other ways... Or you could leave your code as it is and use VNC :)
Thank you. Have you tried trollius on 2.7? 
Got a source for that?
Not to mention the indentation requirements force students to learn what good clean code looks like.
I love python and could not imagine teaching an intro to programming in any other language. I suspect where Python will really rock is that non CS types might have some of the lessons stick and they will go on to use it in their daily lives. For CS people it might almost be too good a language in that they will be reluctant to learn other languages as they will all seem like a bit of a step down. For instance teaching C++ would have to emphasize a combination of its speed, embedded ability, and the fact that you can do things in C++ and then access them in Python. This as opposed to the usual "Hello, world" direction and moving on through lists, pointers, etc. 
That's good to hear. As much fun as Scheme's prefix operators and parentheses were, I think we could've spent a lot more time learning about concepts if we didn't spend (at least) half of our time hunting down stupid syntax errors.
You can run GUIs over ssh using X forwarding. There are probably better ways to achieve those ends, but it is pretty straightforward if you don't want to rewrite your application.
I think you are misinterpreting, the title means *language most popular for introductory teaching* not most popular *introductory teaching language*. After all, previously the most popular introductory teaching language *was* Java.
Dude, be happy. C is a pretty good intro language, and frankly knowing C will help you with Python (if you ever want to extend the language). Be glad your classes weren't in Java.
I have mixed feelings on that. I was in college long enough ago that my introductory courses used Pascal. I think there's a certain value to having to learn a strongly-typed language in the beginning; having said that, it's good to see that people's introduction to coding is a language that is so easy to understand.
Go huskies, woof woof! 
Let's not start another language war here. But I can understand the value of Python as first language. Of course, typed languages would give you some more insights. However, you also have to keep the students motivated. I found my C++ class pretty fascinating, but unfortunately the majority didn't, because we did very basic things (not that they were not challenging, but the output was rather not so spectacular) - it might be boring for someone who is not attempting to become a CS major. We also have to keep in mind that more and more scientists from natural sciences are taking intro programming classes to become more productive (i.e., in their data analysis). With Python, for example, you can teach someone within hours to sort through CSV files and train some basic machine learning classifiers, image processing scripts etc. The best solution would probably to be start with a Python intro class, followed by a second programming intro class in C++ or Java for the CS majors.
I took the same class twice between an evolution of the course at my uni, first one was all C and second one was python/java. I liked python&gt;Java&gt;C and it was obvious to me at the time that Java had taken largely from C. I just liked the notion of an object root. But, python still won heavily for outright usability.
Python **is** strongly typed, just not *statically* typed.
Berkeley?
Java is well worth knowing. 
In high school for me it was Pascal, then in college Modula 2... or 3, I forget. And then I switched to another school that was still teaching COBOL in '92-'94! I took a C instead of an A in COBOL II because I refused to do any programming assignments... I'd concluded that writing any more code in COBOL was simply immoral. Of course then Y2K happened and several of those I took COBOL with were hired for rock star salaries to fix COBOL code but that's another story.....
&gt; I was in college long enough ago that my introductory courses used Pascal. The remaining Delphi community is somewhat in denial that they're not currently. :-) I started with Pascal - well, technically BASIC as a kid - too, and while Pascal was a fine language for learning, I'm still not sure if it existed at the time whether Python would have been better. Going from static to dynamic is uplifting and liberating; I'm not sure if trying to go from dynamic to static would be depressing or not. 
What are they going to learn from Java that they couldn't learn with Python though?
Who the heck is downvoting all the positive comments about Python as a teaching language? Niklaus Wirth?
Mine were in Java, then we moved around to C, C++,Assembly and Python in later classes. I think Java was a safe choice for them to teach fundamentals and data structures without having to worry about memory management. Although, I learned the most in my C and Python classes.
Java design patterns, which is arguably a more valuable skill than knowing Python due to Java's prolific nature in production environments. 
See, I'm the opposite. I took my first CS class a year ago after switching my major from education to CS. I loved it because it was a greater starter into programming. It made me realize how my brain understands programming languages better than English. Then enter the next CS class ... C++ All of a sudden it felt like I was a 2 year old with water wings that was taken from the kiddie pool and thrown into the ocean and told to swim. It was overwhelming. I learned to enjoy it eventually but it took me weeks to properly transition from interpreter to compiler. My initial thoughts: &gt; Now I have to make an entire project + class file if I want to test one little thing? I can't just type directly into the console? Wait, And what's with having to specify data types? Memory management? Nope. Ill just make everything a double - nice and easy. 
Great, thanks! I ended up going with Flask but I'll have to check this out too. 
About time.
It's interesting because Cornell had that system, but it's now changed; Python is programming 101, which is a soft requirement for CS majors and is mostly used by non-CS people, but programming 202 is data structures in Java and is a "hard" CS requirement.
C is good for a CS introduction, but not necessarily for a *programming* introduction: it is way too low level for people with little or no previous programming experience. I would still say Java is a better choice as the very first language if Python (or some other high-level language) is not acceptable. I will concede that learning data-structures in pretty much anything but C is a terrible idea.
University of Minnesota
When you make grandiose claims like that you're basically just flaming when you don't back it up.
Taking Intro to CS this fall... and it is taught in Java. I only wish it was in Python.
I'm at the Scipy conference and I see that bokeh has a talk, I'll make sure to check it out, thanks!
Yeah, I wish I could use that
text
Dovolis? I didn't mind learning scheme at UMN. It was something I legitimately did not know and would never have wanted to know if not forced in class.
I dislike languages with a lot of enterprise cruft (java, C#, basically anything that forces you into using classes and interfaces for EVERYTHING) as intro languages.
I felt the same way when I was in the same situation a couple years ago. I'd say don't sweat it it, Java is fine. I like Python better, but starting with Java hasn't hurt me any as far as coding in Python. 
When I was teaching our progression was Fortran, Pascal, PDP-11 assembler, then C. That was in the earlier days of CS (as opposed to being a concentration in the Mathematics department). Python is a fine first language, IMO.
Don't worry about it, odds are your going to learn a crap load of languages before your done. Anyways once you've got at least one Object oriented language under your belt python will feel just like home.
Ok, not that much of an experienced programmer yet, so maybe someone else confirm or deny this. But to me it seems like Java strikes a good balance between the power/flexibility of a language like C, and the free-for-all type of "anarchy" of a high level procedural language. Java has just enough rules and structure for people to lear oop, while still being pretty flexible. Python feels too loose to me. For example, with java I just like knowing that my variable is an int as soon as I look at its declaration. I get a nice comfy feeling, but that's just me.
Having taught CS2 a few times now, it seems like many easily forget it when transitioning to another language -- no matter how many points I dock for crappy looking code.
I don't think anyone teaching an intro CS course in Java should go into any of the enterprise baggage that comes along with it. It's not really needed.
&gt; I know its value from an enterprise/industry perspective, but what makes Java special? Due to the demand for programmers being greater than the supply of CS graduates, some employers hire anyone (I mean, anyone) who has a background in Java. So, to land some jobs, if you know enough Java then it almost doesn't matter if you know anything else at all. This makes Java worth knowing.
very nice tutorial, congratulation!
You may find [q](https://github.com/harelba/q) useful. It's a Python lib that allows you to run SQL queries directly on CSV files.
I am fully in support of scheme as the introductory language. It enforces a bunch of concepts that I found lacking in the python curriculum. Good news for those who are not a fan of scheme is that starting this past spring they are teaching it using python. (Though I believe the new course is going to use scheme or another functional language).
Yes, it is. 
I started with Java and I'm super glad I did, because the people at my university who started with Python had a lot of trouble moving to a typed language.
Yes, that was something I forget to say in my comment. But I was under impression that he wanted to run it like html5 app. My mistake.
Of course it is... it forces students to indent.
Duluth, perhaps? I took honors CS1 there. Half the semester was scheme, the second half was C++. Then I got to CS2 and they were copying and pasting code, not actual writing. The fuck...
[Absolutely](http://imgur.com/vB9B5?tags)
I definitely think that a good grasp of Python and C will let you do just about anything you want.
&gt; I have mixed feelings on that. I was in college long enough ago that my introductory courses used Pascal. I think there's a certain value to having to learn a strongly-typed language in the beginning; having said that, it's good to see that people's introduction to coding is a language that is so easy to understand. I loved Pascal too but the enviroment was very small. Pascal would be the better choice or upcomming hardware engineers, but they could take C too. For the common people Python offers more opportunities than Pascal with less effort. It's an optimisation. 
It's a tutorial, aimed at beginners. I'm trying to introduce concepts, not write the most terse code possible. I do appreciate feedback though. (The readers haven't seen generators yet) I assume the 'how much experience' is rhetorical?
I disagree. Javascript isn't really used at all outside web dev. I for one try to stay as far away from web dev as possible.
Surely, some multiplayer/coop can make even a simple game incredibly fun (or quite frustrating :) ) I just hope whoever does it makes a cffi wrapper instead of a native CPython extension/Cython wrapper so it can be used with PyPy. 
There is also http://inventwithpython.com/, it has some simple examples in pygame. “Invent with Python” was written to be understandable by kids as young as 10 to 12 years old
I thought the issue was with the length of the script? ;) I agree with the memory efficiency comment. I've not introduced generators yet though and didn't want to digress into them in that chapter. A trivial use case for 'readlines' might be to count the number of lines in the file using 'len'. Yes, you could use a counter and the generator, which might be more efficient or required for large files.
I just released 0.4.1. This should work in Python 3 again! 
I recognize this tutorial! I used it as my main resource when I first learned pygame. Never thought I'd get to personally thank the author. I know others who have used this too. Thanks for making this!
Design patterns are mostly language agnostic. I mean, not all languages support all design patterns, and not all languages require all design patterns, but there's nothing inherently Java-specific about them.
This is an excellent book too http://www.nostarch.com/pythonforkids
Python is a very high level language. Unless you are benchmarking Python itself, there will be so much happening behind the scenes in the smallest amount of code that will make benchmarking difficult to compare. Consider the python and C code "x = x + 1". You'll know exactly what the C code will do -- you can see the assembly code. The equivalent Python code compiles to bytecode interpreted by a virtual machine which calls library functions to do the work. It may read and write to many places in memory. It may allocate new memory dynamically. It may trigger garbage collection which will read and write lots of other places in memory and maybe even call Python code. The amortized effect will likely not be that large but why bother when other more precise tools exist?
What exactly do you think you are doing, linking to localhost? That will not work for anyone but you. (I guess you are running some kind of server?)
http://localhost:8000/posts/morepath-041-released-with-python-3-fixes.html ..
Eather he is dumb as hell or the best troll i've seen in a short period of time
I could be neither. I could just have copied the wrong link. 
Okay, sorry guys. The proper link is here: http://blog.startifact.com/posts/morepath-041-released-with-python-3-fixes.html To explain how this can have happened without being a troll or dumb as hell: I use the nikola static site generator for my blog. I write my blog entry, do the nikola build, and use nikola's built-in server to make sure my blog entry looks okay. Then I deploy the content to my real server. But when I did the submission I accidentally copied the open browser tab to the localhost testing one instead. A mistake, sorry! 
Ah, iHater butthurt. It never fails to amuse. Swift is extremely interesting if you are a developer. Period. Even in the first beta it has some very powerful constructs that come together to blow other major languages out of the water. It just takes one look at the new "Playgrounds" to appreciate how features like that could revolutionize app prototyping. For once Apple has actually one-upped Microsoft in the IDE department, and mark my words, sooner or later they *will* be copied for Windows/Android/etc development.
Sorry about the broken localhost link in a previous submission, folks. My mistake. 
You mention a scanner darkly many times--but you never show a picture of it. You use Jurrasic Park, for some reason, though. 
Jesus, you're in /r/python of all places and talking about how REPL and execute-in-IDE as if Apple invented them.. and you're glorifying MS as a gold standard to be measured against. I don't even. Look, if you wanna get hurt because I don't worship Apple, that's your business. I only ever disputed being told I'm neither a dev or a nerd because Apple makes me yawn.
If you get a chance let me know your impressions of both. We can all learns from each other.
Since the correct link is now visible in the front page, perhaps you can delete this submission to minimize confusion?
But then you would have edited or commented your entry, so people get the right link
I did comment my entry as soon I found out. Didn't know I could edit it. Anyway, I put in a new entry and found out I could delete the old one, so just did. 
Yes I do much Python, but still lots of C++, and a little PHP. So what I try to do is push each language to its limit (makes me happier) so in C++ I have it go through hoards of data screamingly fast. In PHP I use it to make quick and dirty things. And then I go back to python where it seems like every 5 lines of code is a day's work in the other languages. 
You don't need classes for object oriented programming.
I agree, even with Node.js it's just working on the "other side" of the web.
Yes I would shudder at a Python filesystem. But a traditional C or C++ course would presumably spend most of the time teaching how to program in that language as opposed to showing why that language was better. So I suspect that there will be some pressure to show why it is better. Often when a more esoteric/less common programming language is taught such as scheme/erlang the professor will make sure to emphasize why his course isn't a waste of time. But with C/C++ courses they tend to just teach "programming". 
But if it is an introductory programming course then students wouldn't (expect for those who can already program) complain about what can be done in python easier, because they wouldn't know python.
Class is short for classification of objects and is a cornerstone of OOP.
So just one reason, it will get you a job, hence exactly why its not a particularly important language in any other way. 
C# is probably a better representation of the idea. 
I agree, but I think this is common. My CS 1301/2 was mostly training in the Java libraries. Luckily, I didn't rely on my school to learn the fundamentals.
I think the point of having to use a class is a good reason not to start with java. 
I've never heard of people using JS to make non-web apps. I personally think that an intro to CS course should avoid web dev. In the same vein, intro to CS shouldn't include any work with GUIs. Sadly mine did, although it was like 5% credit and super easy.
&gt; So just one reason, it will get you a job Well, it is **a** reason. A very important one at that, if you are a programmer and care about things such as making a living. If you look into int, you'll notice that it isn't the only reason. There are reasons why large companies and industry behemoths have adopted Java to base their business on. These decisions aren't made lightly.
It was the first language at my school. I think it's because it encourages good practice, and really hammers in the OOP philosophy. 
JavaScript is used for a lot of CLI stuff. Just take a look at all of the stuff on NPM. However, I also agree that intro CS shouldn't about web development topics. There is no good reason to give preference to one subfield of CS instead of, for example, game programming. A lot of web development doesn't even require an understanding of days structures or algorithms, so introducing students using web development might hinder their future understanding and ability to build analogies. Edit: crucial typo. Thanks /u/unregisteredusr!
Py3k has type annotations, but they don't do anything (yet)
Imagine what a world it would be if we all programmed in golang; "correct" indentation is anything that go fmt might produce. 
It's a flexible, platform agnostic language. You can build almost anything in it, for almost any device. Many languages can't do that. It also has a huge amount of third party support, making it easy to find tutorials, stack overflow examples, libraries, open source projects, and anything else you need to develop in Java. It's not the greatest language in the world, far from it, but it's a solid programming language and a good addition to any programmers toolbox.
It is glorified pseudocode, and as such, is very easy to learn and work with! Obviously it's not for everything.
That would be good. At my university I didn't learn python until I did a 4th year research project in computational physics. It wasn't more than a reference in a Unix course otherwise. But it's such a great first language to learn, simply because it forces good indentation and clean(ish) code.
People who think you should start by learning a "real" C derived language.
So you are saying that you can't do OOP in C? Or are you saying that C does have classes?
If folks have any questions, I'm around and happy to answer (I'm one of the developers of PyCA cryptography)
C++ is significantly more complicated than C, which in my book makes it incredibly unsuited for introductory programming courses. When you do get to it, you need to go through the equivalent of Effective C++ first.
thanks!
Ooops, I should have explained this in the text. Actually, we do use pip: https://github.com/mrmrcoleman/python_webapp/blob/master/Dockerfile It's just that the "hello world" application container doesn't require any extra dependencies beyond those in the parent docker image.
That's one thing that I pride myself in. My code may not be the greatest, but damn does it look pretty when I submit if for grading.
that looks a lot simpler than sqlalchemy, at least the docs are better.
There are arguable advantages and disadvantages of introducing students to object oriented programming right off the bat. In some sense, having a language with too much syntactic sugar makes students more apt to believe in programming "magic" instead of actually understanding what's going on behind the scenes.