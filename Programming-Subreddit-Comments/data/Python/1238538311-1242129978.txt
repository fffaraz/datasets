I would have done a PyQt app which called packagekit to install the nmap beta and wrap it with the subprocess module.
So you linked to a twitter post with 3 links in it?
I would have thought by now they would have made a PackageKit backend for PyPi.
After my first (seemingly) successful attempt the run threads in GTK, I signed up to the Python recipes site and posted it. Comments or suggestions?
I like your initiative and attitude, can't say I'm particularly interested on the project but maybe is worth a try, what's the plan? EDIT: ok saw the code so it's basically a class that generates the javascript for you :/ I thought it might be a more "direct" interface, personally I'm not very inclined for the "ZOMG IS FULL PYTHON!!1" concept, specially if it does not add any value :P anyways I'm still interested in hearing your plan, I'll see if I join after that.
idem, seriously guys stop submitting links to twitter! it's even worse than blogspam :'(
contrib.gis has some code for working with google maps. 
Hell yeah. I have a mashup which would this project would help a _lot_.
I dislike the thread_enter and thread_leave approach. In my experience; * it often means you need to have gtk calls in modules which will otherwise not need to have gtk imported * It is hard to get correct. Often in a large gtk application, updating data in one place may cause a signal from a model to be emitted from another class, leading to confusion as to the best place to take the lock. I prefer [emitting on idle](http://www.johnstowers.co.nz/blog/index.php/2007/03/12/threading-and-pygtk/) from objects that drive gui updates. It fits more naturally with the gobject signal design philosophy. I also find it results in a cleaner seperated model/gui design.
Could you use some of the stuff from GeoDjango instead: http://code.djangoproject.com/browser/django/trunk/django/contrib/gis/maps I don't think it's in any way dependent on the rest of the framework.
well when i read that it was the object i questioned rather it would be the same on various platforms. But after testing, hash is all i need. Thanks
I, for one, tip my hat and say, "Thank you, sir. Well done."
The idea of wrapping Google Maps with Python is not good at all. Learn Javascript if you are doing web development. It is relatively easy (especially with the nice GMaps API) and surely more powerful than any wrapper.
I too, do retire as BDFL of Python.
That was actually quite good. They had me going for a while. Just a short while though.
&gt;BDEVIL L0L &gt;Created: 01-Apr-2009 LMAO
Shhhhh!
I, for one, support my new Python overlords.
Damn that was awesome.
These decisions are really bad. I am mad about all of the decisions on that page. They are wrong. This makes me the opposite of happy.
They got me until mount Everest stuff.
April Fools!
Yeah, they had me until "Retires"
Brought to you by Python Secret Underground. "PSU: Emphatically Not Existing Since 1986"
here are some better explanations: http://tinyurl.com/2g9mqh
how do submit three links in the same topic then ? I think it's better to have one link that refers the three links than spamming reddit with three differents links. Isn't that a missing feature ?
Damn, soooooo dorky.
post to "self", include the links in your comment.
I hate April Fools Day. Bah! Humbug!
&gt; $Date: 2009-04-01 00:00:00 -0400 (Wed, 1 Apr 2009)$ You gotta make it a bit more conspicuous than 00:00...
Dunno why you got downvoted for this, you are exactly right. A Python wrapper is a completely unneeded abstraction in this case.
What can I say, pythonistas are a very punctual people.
That clarifies it, thank you. I should have known Guido's never gonna give it up... it's such a cushy gig, why would you?
"Just testing left" Yeah, right - better install a revolving door.
I've never used Python before and am actually a fairly inexperienced programmer. I am in an MS program at RIT but only know intermediate Java/C++/SQL/Matlab/AspectJ. Would love to get in to some Python in my free time, but I never really have any project ideas in my head to get started. If any of you have some interesting but not too complicated ideas, let me know. Maybe I could post up my results for critiquing? [EDIT] Oh! Also, what are the general recommendations for an IDE? I currently have PyDev plugged in to Eclipse. Seems to work OK.
I'm kind of trying to understand this. What you're saying makes perfect sense but I'm having trouble picturing a counter-example so I completely understand what's going on. How is this different from closure, say in Java or C++? If this same thing was done in Java or C++, would "Hi" be able to be passed through g? I'd test it, but I'm not near my mac :(
I've always been slightly partial to [Eric](http://eric-ide.python-projects.org/)
If you're familiar with HTML, try some web page scraping with the BeautifulSoup library.
Try python challenge: http://www.pythonchallenge.com/ I used it when I was learning Python and it worked great. Stayed up many late nights struggling with some of the puzzles. One caveat though - some of the challenges need the Python Imaging Library (doesn't come w/ python) but don't tell you that ahead of time. As a beginner with no idea what non-standard libraries were available, I thought that was pretty unfair. I made it through 18 challenges before I figured I'd accomplished my goal of having passing competency with Python.
[Project Euler](http://projecteuler.net/) An excellent warmup for learning new languages. It's great to go back to old problems after you learn new skills and see how many lines you can cut down. Also, check this site out for style and idiomatic help: [http://python.net/~goodger/projects/pycon/2007/idiomatic/handout.html](http://python.net/~goodger/projects/pycon/2007/idiomatic/handout.html) 
Im new to Python, but I think that I can be a big help. I recently wrote a Google Maps wrapper using MooTools, the same principles apply
They chose a hellofa date to release this ... I was certain this was going to be yet another thing on this cursed day to make me want to punch babies.
Would highly recommend familiarizing yourself with a decent editor (Emacs, vim, ...) rather than an IDE. These tend to be available in more places (e.g. at 5am while remoted into a production server in an emergency, etc. As for a problem to solve, gee. If you use a computer for a significant part of your day and can't find anything about it that could be done better, go study history or art or something. ;)
Needing to use buildout for Plone, left a bad taste in my mouth.
I'm sure plenty of people will suggest great ideas, so I'll suggest one that may not *seem* as practical, but is a bit out of the ordinary: implement an image editor. Here's a great guide to [Tkinter](http://www.pythonware.com/library/tkinter/introduction/index.htm), the Python bindings to the Tk graphical user interface toolkit. Here's a hint: when the user clicks the canvas, place an 1×1 rectangle on the canvas of a certain color. Find a way to change the color. Find a way to get the user to choose the color. Find a way to save that image. It's actually really easy once you get going, and if you keep it simple enough, you can learn a lot.
This would not work as-is in C++ or Java. Both of these languages store function parameters and local variables on the stack only. When you call outer, a stack frame is allocated and contains the variables `your_name` and `title`, with the values "Eric" and say "Mr" respectively. In Java you'd have to do some tricks to define the inner function greeter and return it, e.g. it could be an anonymous instance of the Callable interface but I think you cannot do at all it in C++. However the real problem is that when you return from `outer`, the stack frame is popped and the values for `your_name` and `title` are lost. Therefore, the returned function *cannot* reference them later when it is called. So yeah, you could very well pass "Hi" to g, but g could not reference any of the variables from the scope of outer, as they are gone.
A good warm-up to understand the language is to write a function F which takes another function G and an input to that function X, and analyzes the structure of G to determine if it will ever halt on X. It takes a while to get it right, but once you do you'll know that you have a full command of the language.
That's a good one. Should be easy. Not even a NP-complete problem! If ZeppelinJ0 manages that, I'll hire him instantaneously.
`import ai` ? :P
This is great, already solved a number of problems, thanks
I've actually proven NP-completeness and it involves a unicorn and a sand wedge. Very unsurprising.
Neural Nets are databases? Uh. Ah. Eh. No?!
Yeah, python's awesome. You just do: from __future__ import AI The best thing is, you don't even need to write the rest of your program - the computer works out what you were trying to do and finishes the program for you.
Is there an audio form of this anywhere?
pretty amazing.
try [this](http://pycon.blip.tv/file/1947373/).
One of my first projects was to scape dilbert.com and save the comic image someplace. I don't actually run it but it was good exercise.
It did seem that a _lot_ of the PythonChallenge puzzles were image based. I think I got about as far before I felt comfortable with Python.
I learned a lot of Python by way of Django, a framework (a la Rails) for building websites. As the project owners are fond of saying, Django *is* python, so if you're interested in making stuff for the browser, it might be worthwhile to try learning Django. Having said that, Django assumes a certain familiarity with Python, so I had a slow start trying to pick up both at the same time, but the Django community is very helpful.
Instead of starting a new project, I suggest trying to contribute on an existing project. And if you're doing that, set your sights high -- Python itself, Twisted or Django are all great projects. This will have the advantage of having good programmers critiquing your code for their own ends (getting better patches), and you will learn much more from the experience.
FWIW , You might enjoy Programming Collective Intelligence if you liked this talk. [link to buy off author's website](http://www.amazon.com/Programming-Collective-Intelligence-Building-Applications/dp/0596529325/)
For something small, try writing a backup script in python.
Idem.
Video of the talk is here for interested parties: http://blip.tv/file/1947373/ It was a very good talk. :)
I always like to program a simple pong game when I start new languages. It gets a little into the widgets, pong itself is not a lot of code, I think I was able to reduce my smallest version down to under 30 lines (not counting widgets). And of course.. you stay interested because its fun.
I have a server with a large HDD running Ubuntu server edition, it is on 24/7 with a nice view of the living room. Thankfully it wasn't stolen (TV's, cameras, and laptops were not as lucky). I want to set up some security mechanism like a web camera that takes pictures when there is movement, or something similar. I don't have much time for development, so any recommended libraries that would help or comments on how this should be done would be appreciated. This is a good opportunity for me to get some Python practice in and to create something that may some day catch some bastards.
I really like the idea, this will be my first project. I'll try and remember to post up my results, will give me a chance to try and make a GUI in Python too :D
What about an off-the-shelf product?
just download yawcam and you're done. - it's free - built-in motion detector - supports remote storage (in case your computer gets stolen) - works with any webcam
first thing I did in python was create a script that read a .qif file of my account history that I downloaded from my bank, parse it and store the records in a database. After that every monotonous piece of work that I would have to do with files or whatnot, I would right a python script instead to do it for me. It taught me a lot about working with the standard lib and syntax. 
It's all C++ and it's really easy to develop for. I have 3 now and I love them!
Just uploaded this - many more going up as we speak - total video is a tad over 150 hours. We got held up earlier in the day because we hit blip.tv's 50 videos-a-day limit :)
'motion' works fine for me (find it in the Debian repositories). Takes pictures at regular intervals and whenever movement is detected, can also make movies. I set up mine to send all pictures to me by e-mail with a warning by SMS (no more than once a day). Of course this assumes the robbers do not cut power first.
Definitely use, not abuse. This is excellent, I hadn't read about named tuples before. One of the things I love about Python is that the generic built-in data structures are so damn useful.
Hm, clever cropping of a watermarked stock photo! http://www.phyast.pitt.edu/~micheles/scheme/box.jpg
Just finishing the video. amazing, I am not a native English speaker, It takes me about 10 hours to hear, pause, look up some words in the dictionary or search Sudoku or Something else, copy, modify and run some code, and resume. Just wanna to say, amazing. 
I made an [improved version](http://alotofdimp.wordpress.com/2009/04/03/pycon-mean-face/) using aligned faces.
Hm, I implemented something similar once by inheriting from list and using property() to define setters and getters for each item in the list. This is better, of course, requiring less code. Like it, can't wait until 2.6 or 3 are installed more commonly. (My Ubuntu 8.10 laptop seems to have 2.5.2 still)
Transcript? Many of us are at work :-)
I recommend [Project Euler](http://projecteuler.net/) I'd also like to plug my free Creative Commons book [Invent Your Own Computer Games with Python](http://pythonbook.coffeeghost.net). It's aimed at teaching nonprogrammers how to program, but it has the full source code to several simple games. Reading/copying them is a good way to learn the language.
-Pick a small project that actually does something useful. This will help keep you motivated. -Don't worry about doing it perfectly at first. -Once it's working refactor it. See if you can make it shorter and easy to read. For my first projects I often like to create SEO analyses tools. Such as competitor analyses, keyword density, on-site page structure and so one. I find these programs cover a lot of ground such as parsing, regular expressions, collections, networks and so on. I'm learning python at the moment too and loving it!
Is this easier with iron python?
00:37:27 - LMAO
Costco has a motion-sensing floodlight that also has a built-in camera for $99. The picture quality is so-so but might be enough.
Either you are barking up the wrong tree or my universe has imploded. Since when do "power" point users want to automate shit.
haha... I've done it although a different way :) I have to make the same chart presentation every month with updated data. I wrote a python script which used matplot lib to generate the charts. But that wasn't good enough because I still had to cut and paste the charts into power point. What I did, and I think my way makes more sense, is record a macro to insert a slide and load the chart. Then I copied the vba code the macro recorder generated into the python script. This was the vba code template. With some very simple string formating I had my script spitting out a vba script I could cut and paste into power point. I had a template powerpoint file created with a macro stub with a keyboard shortcut already assigned. I would run the script and bam, instant presentation. Bonus: I didn't have to spend all kinds of time figuring out how to do things through the win32 com interface. But, I will say that win32 com is great for going the other way; application to a python script. I wrote an excel plugin with python that did some bayesian analysis to bin text records. Worked like a champ. 
Oh, theinternet, I get and pity you. It looks like you are almost there. Google "latex" and "beamer" (and maybe "cygwin") and turn in PDF files to your masters. Your joy will multiply! Much luck!
Well, actualy... I used PIL (python image library) to compose the fake power point slide (header, footer, charts, page numbers..) and am currently looking at using ReportLab to create the pdf file. I would just use PythonPoint but I already have working code to generate the slide images. I don't know why but I despise using cygwin. I use os x at home and I love having a terminal. Just something about cygwin erks me. I do have it installed though because I needed gcc for a C python extention I wrote in linux and needed to cross compile for os x and windows. It was a high level 3d math library used for lightmapping and collision detection. 
In all sincerity, how useful would such a system be? Police don't always catch thieves in such cases. I imagine a more useful measure would be engraving your drivers license number on all of your valuables.
How "advanced" can an RPC library be? 
Ugh, OrderedDict is insertion-sequence order, not alphabetical. I don't get why Python is so stingy with data structure types. Is it because they don't like going beyond what there are unique brace / bracket types for? 
I'll agree that there should be more data structures included, but an alphabetical OrderedDict is useful only for strings. The original clamor for an ordered dictionary was for insertion-sequence order ([There are 8 different implementations here.](http://www.python.org/dev/peps/pep-0372/#reference-implementation)), hence the name and the implementation. I dunno if string order is used that often, but you should try submitting a PEP along the same lines.
A much more useful ordered dict was one which supported on-the-fly reordering of the keys, and/or being able to specify a "key" func (ala sorted), which could be used to keep the keys in any order desired, eg "ofunc(key,idx)" where idx is the order of key's first insertion or something. This covers almost all use-cases.
via: http://jackdied.blogspot.com/2009/04/speaking-about-speaking.html AMK's talk How to Give a Python Talk is very informative, you should watch it even if you aren't planning on giving a talk. Why should you watch it? partly because it gives you an idea of what goes into a talk and partly because it demystifies giving a talk enough that it might prompt you into giving one. Lots of solid advice.
Have you studied Apache/Facebook Thrift? :)
The one thing I wish he'd told us how to handle is the inevitable couple of people who start asking why you would use Python instead of Ruby. I've seen this way too many times: they make it sound like an innocent question, but really they are there to shill for Ruby. I'm not saying Ruby isn't a fine language, but I wish its user base would stop walking around with a chip on their collective shoulder.
...studies thrift... Elegant, simple, well thought out, the product of long hard experience: certainly. Advanced? It's still just shoving bytes through a socket, there's nothing advanced about that. 
I'm guessing this wasn't implemented because it's a shift in data structures. This OrderedDict is basically backed by a queue. An ordered dict that took a comparison function would need a more complex structure (a red-black tree, if you took an example from Java's TreeMap). But then it wouldn't make sense to be in the same PEP: if you don't pass it a comparison function, it behaves this way with these performance characteristics; if you *do* pass it a comparison function, it morphs into something else. (Overall, though, I do hope eventually there is a generically ordered dictionary. Being outdone by Java on data structures is just embarrassing.) *Edit*: I don't want to prolong this thread any further, so here's a summary of what I said: Passing a comparison function forces you to use something besides a queue or a doubly linked list as kingkilr corrected me on because then you need a data structure with different performance characteristics that takes arbitrary functions to maintain order.
Woohoo!
This is not implemented as a queue, at least not totally, it's a standard python dictionary with a circularly, doubly linked list that maintains the ordering. Right now Python doesn't have any tree structures in it that I'm aware of, and that's largely because there isn't really any demand for them. The issue of passing a comparison function is really irrelevant to the performance characteristics.
I disagree that that's more useful. Imposing an order on the keys means you're no longer able to use a hash table, but are in the realm of balanced trees, with different performance characteristics (You gain O(n) ordered iteration, instead of O(n lg(n)), but lose O(1) key insertion/deletion) While some form of balanced tree would be a nice addition, 99% of the usecases are already met with hashtables and iterating over sorted(dict). This is far more useful, because combined with the new `__prepare__` method, it lets you solve a common problem that till now you **couldn't** (or only with difficulty): retaining the order of *internal* dictionaries. For example, a common metaprogramming style is to define things with classes. eg (from the django ORM): class Person(models.Model): first_name = models.CharField(max_length=30) last_name = models.CharField(max_length=30) but after definition, this is indistinguishable[1] from one created as: class Person(models.Model): last_name = models.CharField(max_length=30) first_name = models.CharField(max_length=30) Remembering that order would be nice - it would let the SQL match the python definitions, and allow that order to be used to match what is presented in various forms and reports. [1] Actually, there are hacks possible in this case, eg. make CharField increment a global counter and attach such ordering information to the object, but it can't be done in the general case when assigning arbitrary objects so constrains the possibilities, and requires such workarounds to achieve.
While clearly still an early version with only a few features, it is still brilliant. Like the sage worksheets, but I can actually make it work easily. 
Imposing an order on the keys doesn't mean we have to replace the hash table... When I implemented the ordered-dict class I usually use, I kept the key-&gt;value mapping stored as a hash, and stored the key ordering in a separate list (both structures of course are internal to the exposed dict object). This way you get typical hash behavior when doing gets, as well as sets which replace an existing key. The key iteration calls get passed on to your internal key list, so those don't change efficiency either. The only place where speed is impacted is during sets where the key isn't in the hash, and deletes. For those, we'll have to do an additional binsearch on the key list, bringing us O(log(n))... not that desirable, but not bad. We could replace the list with a tree of "(key, index for ordering)" pairs to cache those results and have a better performance; and maybe some fancy optimization for update() calls with multiple keys at once, but i'll assume O(log(n)) for now. The bottom line is that, yeah, you'll never has completely O(1) behavior for an ordered dict. But you can save O(1) for a lot of cases, while falling to O(log(n)) for only sets &amp; deletes. Mind you, this cost for sets will add up, so it you do to many of them, and too few key iterations, sorted(dict) will probably come out on top of the amortized cost of the setitem calls, so this generic ordered dict just wouldn't be worth it (of course, you could just hide the sorted() call internally in the ordereddict, or even dynamically detect if keys() was being called enough to switch backends). *Sidenote: A lot of this doesn't apply to order-by-insertion, since we're just appending to the list, so sets are remain O(1); but that object is different enough that it's implementation should really be seperate from this type of dict* However, there is one case (and one I actually end up using a lot), which you mentioned: remembering ordering of table attributes, for ORM usage. In this case, you have a master list of keys for which the ordering is already known, and then build up ordered dicts which contain some *subset* of those keys. If you make the design choice that keys outside this list will be presented in an arbitrary order, the resulting object looks (from a constructor standpoint) a lot like the namedtuple: you create a dict class which encoding an ordering for a certain set of keys: sets &amp; deletes never affect that list, the *only* function impacted is key iteration, which just runs a filter over the master list, removing the ones not present in the current dict, and then adds any extra keys. This maintains the underlying hash's efficiency, and gives you ordered keys at the same time. But it only works if you know the total set of keys ahead of time, so it's really useful for ORM tables, but not so much for WSGI environ dicts. 
&gt;When I implemented the ordered-dict class I usually use, I kept the key-&gt;value mapping stored as a hash, and stored the key ordering in a separate list (both structures of course are internal to the exposed dict object). But when you need to maintain a defined order, rather than just insertion order, you need to do a binary search on your key list. You end up with most of the weaknesses of hashtables and trees *combined*(contents must be both hashable *and* comparable for instance), worse constant-time performance to either even when the asymptotic complexity characteristics are the same, and with a sufficiently different implementation to odicts that mean you can't just treat an odict as a specific instance of an order-maintaining dictionary. A tree would nearly always be a better solution whenever you want such a data structure. While there may be some hypothetical solution where such a structure would serve better than either a balanced tree or a hashtable (ie. you need O(1) lookup, O(n) ordered iteration, but don't care about the rest), they're going to be few and far between - sufficiently so that it would seem sensible to require people to roll their own if they need it. An actual balanced tree type would be *far* more useful in covering cases where a hashtable won't cut it, and IMHO an odict type is more useful than either, since it clearly has outstanding unmet usecases (as evidenced by the large number of home-rolled implementations floating about). The important difference I think is that, while sorted collections maintain something you could recreate (at the cost of performance), odicts remember something that is otherwise thrown away. There are more cases where that information comes in useful than there are cases where the performance of sorted iteration matter more than the costs it brings. 
They should have named the OrderedDict something that makes the ordering obvious. I'm not sure what. I thought of DictList, but somehow that doesn't sound right.
"Advanced" is a relative term and relative to other RPC mechanisms, Thrift is advanced (to me). It's not sufficiently advanced to call it magic of course; like you mentioned, it's just sending some bytes. However, the package as a whole is great.
Ian Bicking had a great point about those people, the people who want nothing better to sell you a language(say ruby) are people who aren't really using it. They need to convince you because it validates their decision. People who are using it already know what works for them and what doesn't.
Nice, I've always wanted to do something similar for use on live code. Having profiling information for a selected set of functions, but wanting more resolution, it would be useful to say add profiling for all the functions which the selected set call.
Why is it that on most nginx tutorials, they still use Apache? Nginx has a WSGI module. Is it not good/fast/stable enough?
Nginx + wsgi is newer and not as tested. It uses less memory. Mod\_wsgi for Apache can spawn a dynamic amount of workers, whereas with ngninx you spawn a fixed amount. [Here's a good summary of the differences from the guy who wrote nginx wsgi.](http://osdir.com/ml/web.nginx.english/2008-05/msg00451.html)
It does not seem to be actively maintained. Last commit was one year ago: http://hg.mperillo.ath.cx/nginx/mod_wsgi/
Yup, this is pretty much why I chose to use mod_wsgi as nginx + wsgi is not as mature. Plus, I find for most people a gradual transition to newer platforms is much more sane in many cases.
I suspect this bad taste reflects more on the complexity of installing Plone than on buildout itself. That buildout can still install Plone speaks for buildout, not against it. I'll also note that Plone and Zope 2 on which it is based are becoming more and more buildout friendly as they are broken up into separate Python packages. 
&gt; At that point Apress required that the copyediting was to be done using Microsoft Word &gt; Unicode characters frequently got lost or mis-interpreted Some of the raw reStructuredText source markup ended up as text by mistake &gt; Syntax highlighting produced by Pygments when I generated the HTML got mis-interpreted as essential markup and quite lot of time was spent by the Apress team putting things in bold and italics unnecessarily before I noticed what was happening a lot of the meaning contained in the carefully-constructed reStructuredText markup got lost &gt; The Apress Word styles didn’t quite match up to reStructuredText styles, for example Apress format new paragraphs and definition lists differently &gt; After a lot of work by everyone the manuscript eventually ended up properly formatted in Word but being a free software man myself I don’t own a copy of Microsoft Word! The closest thing I had at the time was a rather buggy OpenOffice 2.4 for Mac OS X so I had to do all the copyedit reviews using that software. When text was removed by someone it remained in place but with a line through it and as new text was added by the copyediter it appeared in a different colour. Although this sounds straightforward, compared with the purity and simplicity of working with reStructuredText, subversion and diff I found working in Word rather awkward, particularly with all the crossings-out everywhere. &gt; Any comments or questions were added using Word’s comment system which appeared (some of the time) to the right of the page in OpenOffice, but often didn’t display correctly. Scrolling in OpenOffice frequently left artefacts on the screen which made it very difficult to work out what had changed and what hadn’t and to make matters worse the whole system regularly crashed. &gt; Despite the minor problems MINOR? Several lessons here: 1. don't convert from one format to another unless there is a proper, worked-out method of conversion. 2. don't use Word for anything. 3. if you have to use Word, don't use OpenOffice.
What's wrong with fcgi? That's how I run my Django now, are there any downsides?
modwsgi for nginx is a special purpose module - it's not really usable for most apps as the architecture is asynchronous, single threaded and even the most simple tasks like reading the input need to be handled carefully with the nginx flavored modwsgi's async readiness notification api. In other words - when your app blocks it blocks the whole server (or a worker process and that's still as bad).
Have they merged the blog roll, or have they simply redirected planetpython.org traffic to planet.python.org... or something else? There are no entries on the page explaining.
To my knowledge, they merged all of the feeds. This is backed up by the fact that I didn't get on the blog roll until the merge. You can read about it here: http://groups.google.com/group/unofficial-planet-python-discussion/browse_thread/thread/f481567ef6a33dc3
If it's working and running stable for you, then nothing is wrong with FastCGI :) However, WSGI is the standard for Python, and it's getting a lot of support from the community (from what I can see). WSGI has all sorts of [neat middleware](http://wsgi.org/wsgi/Middleware_and_Utilities). For future projects, you may want to consider switching. As was mentioned, mod_wsgi for Apache has been reported to be stable, and is under active development.
wtf is this? for directory in ALLDIRS: site.addsitedir(directory) new_sys_path = [] for item in list(sys.path): if item not in prev_sys_path: new_sys_path.append(item) sys.path.remove(item) sys.path[:0] = new_sys_path 
As a new(ish) python coder, this was very enlightening. I'll be sure to put this into my repertoire of python knowledge.
Hmm, I was told that FastCGI is slow because it's not embedded in the server, and that this will negate any nginx speed benefits... I want to use nginx because Apache is too heavy, but I don't want to have a bottleneck in FCGI...
the only selling point to mod_wsgi that I'm aware of is it's neat graceful reloading feature: http://code.google.com/p/modwsgi/wiki/ReloadingSourceCode I haven't quite figured out how to gracefully reload an app while using fastcgi...
FastCGI and WSGI are 2 different things. FastCGI is a protocol, WSGI is an API. You can serve an application that uses the WSGI API over the FastCGI protocol.
That's a big selling point... Now I want a good WSGI module for nginx :/
AFAIK, that's not the case. I have PHP running with php-fpm and nginx, and it's faster than Apache/mod_php. The best thing you can do is try both setups and benchmark them, especially if you already have your app written. AB (Apache Bench) is the standard server benchmark tool, although I like Pylot too. If you mean Apache is too heavy in that it takes up too much memory, you may find that having several FastCGI workers is equally bad. Honestly, the whole subject is a bit voodooish because depending on the application, user concurrency, usage spiking, amount of servers, phase of the moon, etc. different setups will have different advantages. Best not to worry about it too much until you have a real need to improve.
so Unofficial Planet Python became Official?
web2py seems to have a lot going for it. why oh why didn't it use sqlalchemy though?
i have to say that I'm surprised that a framework as full featured as this doesn't get more recognition, it seems to have a few things over the competition in terms of ease of development and support for DBs. I guess the fact that the only real documentation is a book prevents a lot of people from picking it up and just giving it a try, it's up to their community to pick up the slack and put up an alternative online manual
Yep, IANAE but working with web2py is a very pleasing experience. The online doc could be more structured but that's it. And Massimo is a coding-machine.
Because it would be another prerequisite and we know that dependencies are bad. Better invent yet another ORM, like Django did.
&gt; If you mean Apache is too heavy in that it takes up too much memory, you may find that having several FastCGI workers is equally bad. :/ At least it'll serve static media faster... I found that nginx was much faster than Apache on a local computer I tested, but I think that was just static media. &gt; Best not to worry about it too much until you have a real need to improve. That might be the best advice I've heard all day, thank you.
&gt; Better invent yet another ORM, like Django did. Yeah, back when Django was first being developed it really should've gone with the existing standard. Of course, not many people would be happy today if we were using ZODB...
Oh, this is excellent! I've struggled with transferring `__main__` from `A.py` to `B.py` in `python A.py B.py` a while ago and this implementation clearly solves the problem.
Well, attempts to migrate to SQLAlchemy have failed everytime. Somehow it is funny to see new projects that try it, work a few months and disappear. Similar to how migrations work. The older Django becomes, the less likely it will ever happen. Don't get me wrong, I like Django and they had more reason to invent their own ORM than others, but when Django was first released there were other ORM choices avaiable already. Thinking of it, ZODB would have saved me from some trouble with ORMs in the first place :)
[django-sqlalchemy](http://code.google.com/p/django-sqlalchemy/) is going just fine. If there were more people than just Michael available to contribute, it would be available that much quicker.
&gt; The older Django becomes, the less likely it will ever happen. To be perfectly honest, though, even some die-hard SQLAlchemy fans are now quite happy to admit that SA and Django's ORM target different but valid design patterns and use cases. Ultimately I don't think there's a solution which pleases everybody: 1. Just sticking with things as they are will always attract complaints from people who want all the benefits of Django's ecosystem, but want it all to run on SQLAlchemy. 2. Switching out Django's ORM and replacing it with SQLAlchemy would break every Django application ever written (and would probably result in somebody forking Django and continuing to maintain it, with all the community-fracturing turmoil that would entail). 3. Trying to support some sort of compatibility layer which uses either one simply wouldn't work; applications would never be truly portable because somebody would always decide to go ahead and use some feature that one ORM has and the other doesn't (e.g., SQLAlchemy has flatly stated that they won't support App Engine's data store, but Django would like to get support for that -- no compatibility layer in the world can solve that conflict). &gt; when Django was first released there were other ORM choices avaiable already. There was ZODB, and there was SQLObject, and there was Geniusql. SQLObject was subsequently abandoned by its original developer (and then by most of the rest of the Python ORM community), Geniusql is nice but was and still is extremely low-level and more of a "one developer scratching an itch" (though when Robert Brewer scratches, he often solves a lot of peoples' itches) project, and ZODB... is, well, ZODB. Anyway, I'm pretty sure it's a good thing Django has its own ORM and continues to use and develop it. There's room for more than one ORM in the Python world, and deciding what to do as a framework developer is a trade-off with major downsides either way.
I think one comment that is missing from the blog post is that these techniques are Not For Mere Mortals. Thinking back on the minor quibbles moving between 2.2/2.3/2.4 and later the screams of anguish between 2.x and 3.x, it makes me shudder to think that anyone other than someone writing a tool like coverage.py would ever use this tactic. There ought to be a big disclaimer of "use at your own risk." &lt;/opinion&gt;
I should really give it a try. I haven't heard about it for some time and thought it has shared the fate of the sqlalchemy branch.
Doesn't Michael keep the official code base at gitorious?
&gt; And Massimo is a coding-machine. A spamming one too. I'm sure I'm not the only one who's badly been put off by his tendency to spam any Pylons or Django thread with how great web2py is.
Remember the PJE trick for 2.3 decorators? [decorator(args)] def bar(self, foo): pass 
Um ... YoDawg?
I'd be interested in learning how they extended CherryPy for AmiWeb. [The graphic on this page](http://orangoo.com/labs/AmiNation/) suggested they improved performance, which sounds cool.
Yep here: http://gitorious.org/projects/django-sqlalchemy. Still making commits, albeit it has been somewhat slow.
...I heard you like IronPython so we put IronPython in your IronPython so you can execute while you execute!
800 requests / second != "Super performance"
Indeed and considering CherryPy can do more than 2000 req/sec on its own, I'm wondering where's the boost.
( I didn't see it but I don't follow most of the web framework thread. ) Still, was he simply saying -each time- that web2 py is a valid alternative ? Could be annoying, but if compare that to any Lisp/Python/Ruby/C++/Whatever thread, you'll likely find the same sort of "my alternative language is better". not very different. I would be more tolerant with massimo as he is alone in this, speaking about his own product not some language religions. Still, Can be bothering. 
Another web framework?
&gt; I will be setting up nginx as a front end to serve plain html and pass Django / Python related requests to a WSGI process from Apache. Why not serve the plain HTML via Apache as well? Given than memory usage is the reason behind this article, why even bother with nginx? It seems like apache+WSGI is going to use less memory than nginx+apache+WSGI..
So... wealth of useful libraries and clear readability of code? Those are not why Reddit uses Python, those are why *everyone* uses Python.
Also note that below, the thread is slowly being taken over by DJANGO people... 
*chokes* They started on Lisp?
He could be turning in the graves of those he has defeated... with BASIC.
True. Gorilla.bas wouldn't have been the same if it were written in Python...
The site ran on lisp for a good while at the start. Also, people choking at the idea of using lisp may be the *only* reason people choke at the idea of using lisp.
video of keynote here: http://blip.tv/file/1951296
You know, "Python" was originally supposed to be "Pyson", but it was written in Lisp.
When reddit moved from lisp to python it was a big story and a big deal, at least to some people in the lisp world. You can read a zillion articles about it if you search.
Ba dump bump, psshhhh. Upvote.
Also because snakes (and legendary British comedy troupes) are cooler than speech impediments.
Tho you thay.
No ridiculousness intended. I was trying to suggest only that if it weren't so surprising to everyone it wouldn't be so surprising to everyone. This might sound obvious but I'm trying to communicate something about mindshare.
via: http://www.wellho.net/archives/2009/04/index.html#002123 Using Python with OpenOffice
One must "Register for this site" to post a comment on the blog. What kind of arrogant bullshit is that ? Anyway - The first example does make it look like lambda is broken, but the next example shows that named functions act the same way, and the problem is a [known issue](http://www.saltycrane.com/blog/2008/01/python-variable-scope-notes/) with Python's scoping rules. Lambda does exacerbate the problem, and I'll be damned if I can see how to apply the method-fix in the lambda case, but does that make it "broken"? Quick check: "[The unnamed object behaves like a function object](http://docs.python.org/reference/expressions.html#lambdas) ...". Yup - broken. Damn.
Yeah except no, lambda implements a full closure: it closes over its creation (lexical) context, and pulls stuff from it. Except in a procedural/OO language, that lexical context is mutable, and the mutations in the context *will* be reflected in the lambda. In the expression `[(lambda n: i + n) for i in range(10)]`, `i` is part of the lambda's context. Not a specific value, just `i`. And when what `i` refers to is changed by the iteration, the lambda reflects that change. If anything *can be argued* to be broken here it's the list comprehension, because it doesn't generate a complete brand new context on each iteration (now that doesn't mean it's broken, I don't think it is, but that's a matter of personal take/taste). Haskell is a functional single-binding language, it therefore doesn't expose that "feature. But that's a *very* old feature of OO languages with closure: Smalltalk leverages it to make e.g. `while` statements unnecessary (note: in smalltalk, an expression enclosed by brackets is a *block*, equivalent to a lambda, `[ 3 ]` is a block that simply returns the value `3`. Smalltalk's blocks have -- among other things -- a `whileTrue` method which takes a block parameter for the execution body). So counting from 0 to 9 in Smalltalk using a `while` looks like this: i := 0. "smalltalk uses := for assignment; also double quotes for comments and single for strings" [ i &lt; 10 ] whileTrue: [ Transcript show: i printString; cr. i := i + 1. ]. And this works, because `i`'s modification is visible from the `[ i &lt; 10 ]` block. TL;DR, lambda is not broken, its behavior is perfectly coherent with the language and its model, and with other languages in the same class.
 fs = [(lambda n, i=i: i + n) for i in range(10)] 
&gt; One must "Register for this site" to post a comment on the blog. What kind of arrogant bullshit is that ? It's called "*that's* how bad blogspam has gotten lately".
&gt; and I'll be damned if I can see how to apply the method-fix in the lambda case, but does that make it "broken"? Wrap your lambda in a lambda, that's the way it's usually done in JS. Ugly and verbose btw, especially since lambdas are single-expression.
So lambdas close on references to variables in the enclosing scope and not the values. Got it. That doesn't seem so hard to explain to a student.
upvote forever
&gt; I quite like Python for teaching. And people praise it for the lambda construct I love me some python, but no nobody really praises it for that.
I believe the proper term is: Boo Yah.
Really? I receive no blog spam with proper Wordpress plugins. I don't require an account. Maybe no one visits my site. Maybe no one loves me. Maybe no one... *mommie?*
Hehehehe. I received at least 40 blogspam comments a day when I had WordPress. In fact, since the wp-* files are still accessible via a clever Varnish mapping, I CONTINUE to receive blogspam. And that only refers to the ones that pass the Akismet filter and get into the moderation stage!
Yeah, Lambda in python gets no praise. It does it's job, poorly, and everyone wishes it could be more powerful. But it can't be and it never will be, so it's just a wart that has to be accepted.
This is very useful to anyone who actually runs complex long-running servers in python.
That should be - python's lambda is broken, but not for this *particular* reason. In this case, it's an issue with mutability behaving in a way that the programmer did not expect. Mutables should be expected to act in a way that is unexpected. 
&gt; Mutables should be expected to act in a way that is unexpected. Also works.
What has it got to do with spam ? He didn't ask me any more / harder / weirder questions than usual: name, email, WWW optional, and a password (aka form of captcha). I answer those daily to comment on blogs, and have no problem with that. If I didn't know I can buy solutions to most captchas I would thought a registration step was **easier** to automate!? I don't mind a captcha, which I can forget immediately, but why should I have to remember *another* bloody password ? (Yes, I know there ways around that, but) why should I ? WTF makes your blog so special that I need to "register"? That is an extra, and unwanted, step. It implies a relationship which does not exist. The other sites where I "register" have much better reason to think I'll be back - because they are usually taking my address and credit card details too. And, as the wee one said to U2: Cui bono ? I'm adding content to your blog, impressing those who follow me with how interesting you must be to have so many comments (and hopefully actually adding some interesting content too). Is that not enough for you ? Why do you want the "relationship" too ? That's a blog, I'm a redditor, why would I go back ? 
In my experience, registration does cut the amount of spam dramatically and keeps the S/N low too. I do understand that you're cutting participation, and I'm looking to enable OpenID on my blog myself precisely for this reason.
No, it's not broken and comment no. 5 on that post explains exactly why (quoting mcmanus): Take the following Python example : &gt;&gt;&gt; i = 1 &gt;&gt;&gt; def f(): return i &gt;&gt;&gt; f() 1 &gt;&gt;&gt; i = 2 &gt;&gt;&gt; f() 2 I think that everybody expect this behavior and nobody would want the second call to f() to return 1.
Found out that this doesn't work with threads though, damnit. Going to try tail'ing strace output then.
Thank you Inch by inch, rant by rant, Reddit FTW ! 
Wait.. Introducing? The bottom of the article says AmiNation isn't being actively maintained anymore though. Adoption rates for a potentially dead project are pretty low I imagine. It actually sounds like this would be fun to play with, but if it's not maintained any longer I'm a bit weary.
I realize you guys need to make a buck, but isn't two paragraphs of content per page in a 12-part article just a bit extreme?
neat. This is the exact problem that bites every JavaScript beginner who thinks they've figured out closures. It's bad enough that [JsLint](http://www.jslint.com/) will flag lone closures within a loop as suspicious. 
&gt;...on a massive NFS installation, not my laptop ZOMG! Expect improvements of *over 9000 on a laptop*!! How did you get the 2066 number? Is there a test case I can run? Is this repeatable? Why the hell are you running python apps over NFS? I've got more questions than answers here.
The experiences are pretty much the same regardless of using Amazon, as far as best practices go for internet web services.
Very usefull doc for beginner... like me 
Not redundant, yield from is exactly what I need.
in python, capturing ~15 lines of fragile, useful and hard-to-get-right code in a built-in syntax is anything but redundant. (&lt;flame on&gt;i understand the exact opposite attitude is present in java :P&lt;/flame off&gt;) see also _with_.
interesting how people tend to know more than the developers.
Interesting debate. I realize that the inability to nest generators -- or to yield from nested function calls -- dramatically reduces the utility of generators. However, I think that sometimes such restrictions merely prevent obfuscated code. A good example is the restriction against altering outer-scope variables in a Python closure. In one sense, this is highly restrictive, as aficionados of languages like Perl are quick to point out. However, altering the outer-scope variables is a nasty side-effect and should be avoided. Python now supports 'nonlocal' to allow this behavior without encouraging it. "yield from" is another way to allow but discourage something complicated. I just wonder whether people who think they need generators for more than just facilitating simple iteration are using the wrong programming language. There are languages (Lua comes to mind) that support co-routines naturally using continuations. If "yield from" is added, I'll use it. If it's not, I won't miss it. What I really want is for "yield" to work from any nested function, but that will never happen in Python.
Now that is the kind of stuff that I come to reddit to see! Pretty good! There doesn't seem to be much activity right now on reddit though. I am curious as to why that could be. Is it the weather?
Strikeforce MMA on Showtime and Williams vs Wright on HBO
Interesting, but what about things like sum(a1:a5)?
Or copy and paste (huge spreadsheet feature) 
Word processor in 1 line of shell script: cat &lt;&lt; EOF 
via: http://glyph.twistedmatrix.com/2009/04/my-time-at-pycon.html
well... you could already do something like: sum(getattr(locals(), 'a'+str(i)) for i in range(1, 6)) I guess you could make a function to make something like this more convinient to use, but I think you would eventually need your own parser for any serious spreadsheet.
So I've read through Learning Python, Third Edition and glanced through some of Dive Into Python, as well as read a few tutorials here and there. I've also been using python extensively over the past couple of months for work (solving math problems, combinatorics and graph theory mainly though some number theory as well, solving some riddles etc.) I also watched a couple of the PyCon videos (in case anyone's curious I happened to have loved the EveryBlock one). But where did you go from here? I feel like I have a firm grasp of the basics of the language and somewhat of an intuition as to how to do things. But how do you get to know all the different modules and what texts did you use to bridge the gap between just reading the documentation? Also, where should I start if I want to go from just tiny programs of 30 lines or less into software development and learning about APIs and interfacing with the OS etc.? Thanks a lot!
Continuing with just Python, I would try the homework for [MIT's introduction to Computer Science and Programming](http://ocw.mit.edu/OcwWeb/Electrical-Engineering-and-Computer-Science/6-00Fall-2007/CourseHome/index.htm). It's filled in some gaps in the other books and tutorials for me, and I'm still working through it in my spare time. I'd also learn either a web framework or an interface to a graphical toolkit. There's really no other way to transition into software development. I went with [Django](http://www.djangoproject.com/), but there are a ton of other routes. Learning a web framework has the advantage of making you learn a lot of Javascript. I'm still at that stage, but I think it helps you get used to brackets. (Python's way better, though.) To learn modules, you have to use them. Just think of some task that you can only complete with that module, and slog through [the documentation](http://docs.python.org/library/index.html) until you've done it. Keep an eye out for other tutorials, too. I'm still learning too, so if you ever want a coding buddy, send me a message!
If you need a web application framework I suggest Django.
I did this about a year ago, diving right into python and having to go somewhere after the beginning tutorials/books. Some great resources have been [idiomatic python](http://python.net/~goodger/projects/pycon/2007/idiomatic/handout.html) and [Intermediate and Advanced Software Carpentry in Python](http://ivory.idyll.org/articles/advanced-swc/) There is also [Expert Python Programming](http://www.amazon.com/Expert-Python-Programming-practices-distributing/dp/184719494X) which discusses not only some of the more recent/advanced features of python like co-routines etc, but also using the tools in the python ecosystem.
I did the same thing. I already had programming experience, so the obvious next step for me was building something. Learning syntax is one thing, most of the time you'll spend getting familiar with libraries and best practices 
Build something. Just pick anything without worrying if you can do it and build until you get stuck on something not python related. Rinse lather repeat. Every so often revisit the incomplete projects and see if you can get farther. 
I did the exact opposite strategy but not by choice. Our teacher (who is a bit nuts, but very nice) just told us "here is python, it's easy and you already know how to program in other languages... I want you to build me this in two weeks do whatever you have to do to learn it go". So I started coding my program and learning as I go. Now for our next assignment he gave us 2 month to build some crazy networked database huge complex business application. So far, I never learned a language that fast. If you read two book you already know enough, so my advice is so jump in the water if you want to start swimming. Of course continue reading and learning but you definitely need to try a projects that will challenge you.
Start coding! You learn the most from coding. If you can't think of something to start from scratch, find an open-source project that interests you and volunteer; not only will this help with your programming aptitudes, but you'll meet cool people and have something respectable to add to your resume. Practice makes perfect, you're more than prepared. Code code code code code, and your skills will improve monumentally.
While I think a graphical library / MVC web framework is a great thing to learn, and teaches fundamental theories that you'll need as an experienced programmer, I don't think it's the lone way to transition into software development. Far from it, in fact. Personally, I'd find something you do often (check the Python reddit for beginner tutorials, for example, or update your Google calendar with friends birthdays) - something that _interests_ you, and _automate_ it. Text processing and data structures, man. They're going to be the basis of most automation scripts, and they truly are a good "transition into software development". Let me know, too, if you need any mentoring or someone to bounce ideas off of. Hell, I'll even host a private GitHub repo and teach you git while I'm at it. ;-)
Make a simple game with pygame. It's fun and not to complicated.
Time to jump in. Start working on stuff. Are there any applications you currently use that are written in Python? Or applications that maybe you don't use much now but that solve problems in ways that are interesting to you? Grab the code and start talking to other developers. if you need some ideas, * [Twisted](http://twistedmatrix.com/) * [Pocoo](http://dev.pocoo.org/) * [bzr](http://bazaar-vcs.org/) * [pygame](http://www.pygame.org/) * [Tahoe](http://allmydata.org/trac/tahoe) See also the Python wiki's [ProjectCodingIdeas](http://wiki.python.org/moin/CodingProjectIdeas) and potential [Summer of Code projects](http://wiki.python.org/moin/SummerOfCode/2009). and yeah, pycon videos are probably a pretty good source of finding out what's going on in the Python world that you're interested in. Oh, but I just thought of another book: *Programming Collective Intelligence*. It's got some neat topics, it uses Python as its demonstration language, and it quickly sold out of its first printing.
Love packages. HATE eggs.
seconded. My first "real" python program was pong, then a tower defense game. both taught me tons.
What don't you like about eggs?
honest question: is it better than vim? or, phrasing it differently: what can i gain by moving to pydev from vim?
Permission issues with web applications.
Quick question. Does Python support code signing of "executeables"/packages similar to how one signs Java JAR files?
Find an interesting open source project and join. 
Write: 1. an irc bot (can be quite hard if you are not used to reading an RFC or parsing text) 2. write a brainfuck interpreter (a shame there is no brainfuck spec)
Thank you, Ted. That was the joke.
No. It doesn't look difficult to implement. The whole ``importlib`` can be used as a starting off point. Why, by the way?
That doesn't make any sense - eggs are just files, they can't have any more permission issues than any other file on the filesystem ....
I like how, for every example, he gave the associated json markup, which was more readable (to me). I guess anything's human-readable if you're familiar enough with it, and YAML is no exception.
Just wondering what is the proper way to "ship" code to a client. And how they go about trusting it, etc.
oh no not another IRC bot!
JSON and YAML play nicely with one another, I'm finding I can flip between the two naturally
I keep seeing recommendations to join an open source project, which is kinda what I did as well. However, is there a list somewhere of good open-source projects for beginners to join? Something newbie friendly? I like the idea, but had a hard time finding a friendly place to start.
My experience has been that various implementation compatibility with YAML has been pretty sketchy. Numerous bugs were introduced when I used YAML as an exchange between perl and ruby, revolving around things like strings that contained only spaces or strings that contained utf8 characters. My experience with JSON has been much more sane. I can imagine that if you only intend to have humans editing and verifying the YAML, it's a good choice, but as a message-passing protocol I'd be wary.
Python really has no equivalent of Java's Jar files. In some ways .egg files are similar. I guess if you have few enough clients you can send them a hash of the file via email and they can confirm it.
Yes, there's a [huge overlap between JSON and YAML](http://redhanded.hobix.com/inspect/yamlIsJson.html) that wasn't intentional. 
Yip, use YAML in place of your basic XML configuration files that users will be required to edit, JSON in place of everything else. All [JSON is valid YAML](http://en.wikipedia.org/wiki/JSON#YAML) anyway, but because you don't need to maintain any awareness of spaces or tabs to parse it, it seems a lot safer if you're chucking it around between things, or whatever the term is. The UTF8 problem was probably due to poorly implemented libraries. YAML's more of a human-readable JSON and very little else.
The problem is the [cache](http://plone.org/products/getpaid/documentation/error/extractionerror-cant-extract-file-s-to-egg-cache).
Mix tabs and spaces.
Why would you want to? (ie. "You're doing it wrong") I suppose you could just ship .pyc files. 
Off the top of my head: * Django runs on Jython. If you're just starting the project, this may be an option. If you're close to finished, you may not want to bother with a port. * Compile (by importing) each module with optimizations turned on (the `-O` option to the interpreter), then ship the .pyo files.
Was it really unintentional? http://en.wikipedia.org/wiki/JSON#YAML
Nothing really, besides the point and click debugger. IMO, Omni completion in vim works better than most other syntax completers. And as far as the point and click debugger goes, on the rare occasion when I need a debugger, I prefer pdb.
There is a proper way? If you'd restrict yourself to the stdlib, that would be pickle (^_^)! I'd stick a bunch of .egg and a signed sha1 manifest in a .zip
From what I can see, this was posted (and you replied) 24 days ago. If that is the case then you are seeing the engine in a fairly stable state. I am not sure what you mean by "just a GL wrapper" - it is built on pygame/pyopengl, and yes, it does get rid of the need to work directly, but it also provides resources for general game development, that aren't necessarily GL, such as collisions, gui/input, etc. Planned features are ODE and cal3d integration, path finding. The example game is rather outdated now (by a few versions) - the engine itself would make making a game like that a lot easier now (back when it was made there are some things I would have changed if I had written it ;) ). So, it is already at what I would consider a simple engine. No, it is not OGRE (or anything else like that, perhaps you could say the plan is to be more like Soya3D, though with quite a more simple interface), but it does provide the functionality to create a 3d game easily for people who have never done 3d programming before, or to create games more quickly even if you have experience. The main drawing point for PYGGEL is it's simplicity, as long as people have the major libraries (numpy, Pygame, Pyopengl, PIL) then you can just include this in your release code and go. Also it is written specifically to be easy to learn, and extremely quick to get applications up and running at a reasonable framerate. It will never compete with OGRE/others for people who already know 3d programming and want to make a large application, and have the time to do it "right".
One of the graphviz bindings, like [pydot](http://code.google.com/p/pydot/), for example. There's probably a few libgd wrappers floating around too. Edit: I almost forgot [NetworkX](http://networkx.lanl.gov/index.html).
Thanks for that. NetworkX looks awesome. Just waiting for 314MB of archives to download :)
Take a look at this lib: http://code.google.com/p/python-graph/ It supports DOT-language output, that can be used in graphviz http://www.graphviz.org/ IMHO this is the best combination for graph visualization. (some code samples http://code.google.com/p/python-graph/wiki/Example ) I contributed a small portion of code to this project and it has proved to be far better than the NetworkX lib because it supports a large portion of known graph theory algorithms. If you decide to use this lib, please checkout the latest revision in the SVN trunk, because the project manager made some important bugfixes and added some cool new algorithms that will be included in the new release this month http://code.google.com/p/python-graph/source/checkout PS: If you have any questions - please use this mailing list http://groups.google.com/group/python-graph 
It's a bugfix release. Given the amount of libraries not yet moved to 3.0, I'd say that's the right thing to do.
So is the last 2.5 the most stable modern python version now?
oh yes! that topic is particularly interesting, I'm usually at IRC on freenode (on this same nick), I'll give you my email by PM. PS: heard about this? http://www.reddit.com/r/linux/comments/89ka8/
You must not be a python programmer. 
i dunno, i'm thinking just Python 3 at this point.
It's actually fairly odd in that it's a regression of a Python 2.3 bug :(
Ubigraph. It has python bindings. It is sex. It is also not FOSS, if that rattles your boat.
Yeah, for pure coolness factor, check out [ubigraph](http://ubietylab.net/ubigraph/index.html). Then again, I haven't actually used it for anything, but they have some pretty damn awesome demos.
I never knew about that. I'm kind of glad they took it out though. If they'd left it in, I know my professors would force me to use it.
Shoot. API breakage upon 2-&gt;3.
Gee great writeup. 
Use git. Tag your release appropriately, push it to their deployment directory/whatever, note the SHA1 commit somewhere. Run git fsck and git diff HEAD to see if anyone's been tinkering!
&gt; What were the implementors of Python thinking?! "Do not use lambda"..?
I thought Python didn't have real concurrency?
CPython supports native threads but cannot utilize multicore computers by means of multithreading due to the GIL.
Doesn't the python &gt;2.6 multiprocessing module bypass this..?
Depends on what you mean by "bypassing". Some people really want to use shared memory instead of serializing objects and exchange them between processes. Otherwise you are right. 
Nothing to do with mutability. To do with dynamic lookup of the name from the closure.
lambda in Python is fine. :-) Very *occasionally* a multi-line lambda would be really handy, but *most* of the time a named function does the job better. 
enter a comment here
I tried but it's not letting me so I entered one here instead.
I would assume that only works for web apps.
I intend to use it as a forum/blog comments filter (don't want any external solution like Akismet, especially since it's not free for commercial use). By the way, does anyone know where I can get any forum/comment spam posts database for training?
I used [this](http://www.divmod.org/trac/wiki/DivmodReverend) and it seemed to work pretty well...
Reverend seems to be good as a classifier, however for a simple spam/not spam thing, I think, it can require much more memory than my solution (I store things as dictionary tokens[hash(word)] = [spam\_count, ham\_count]), which is 15 bytes per token as archived by cPickle. (Though, of course, you can write your own tokenizer for Reverend).
In the past I've gone to devshed, but very few users give help (in my experience).. If this is the place then.. I'm having trouble with the MySQLdb module. db = MySQLdb.connect( host = 'localhost', user = 'xxx', passwd = 'xxx', db = 'xxx', port = 3000) (I'm using a custom port) the error I get is: Error 2002: Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2) Which doesn't make much sense since that's the default connection set in my.conf.. it's as though it's ignoring the connection info I give..
What, no tests?
If you have the GUI MySQL Administrator installed you might want to verify you can connect and check the port their.
 [root@baster httpd]# mysql -uroot -p -P3000 Enter password: Welcome to the MySQL monitor. Commands end with ; or \g. Your MySQL connection id is 19 Server version: 5.0.77 Source distribution Type 'help;' or '\h' for help. Type '\c' to clear the buffer. mysql&gt; I also tried it with the user info in my code.. The server is definitely there and the info good, but for whatever reason it's defaulting the info. I get the same error if I do this: db = MySQLdb.connect() I tried directly from the python prompt: &gt;&gt;&gt; db = MySQLdb.connect(user='root', passwd='', port=3000, host='localhost', db='pyneoform') Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "/usr/lib64/python2.5/site-packages/MySQLdb/__init__.py", line 74, in Connect return Connection(*args, **kwargs) File "/usr/lib64/python2.5/site-packages/MySQLdb/connections.py", line 169, in __init__ super(Connection, self).__init__(*args, **kwargs2) _mysql_exceptions.OperationalError: (2002, "Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2)") &gt;&gt;&gt; 
I have had very good luck using the python news group. 
[Stack Overflow](http://stackoverflow.com/) Is nice.
There seems to be a problem in spam_rating where p and omp can become smaller than is representable as a float, and a divide by zero exception is raised when it tries to return p / (p + amp). EDIT: seems to affect large strings. It looks like reverend only considers 2048 words from a message? That may be why I didn't see it there.
Seen the site before, but never used before, thanks. :) Edit: Posted there, found some help/answer. Yay.
I modified my spam\_rating to ignore words where abs(ham\_prob - spam\_prob) is less than some number (tested 0.25), so it's only considering words that are a reasonable predictor of spaminess/haminess. Seems to improve results, and also reduces the likelihood of the component probabilities being truncated.
http://lmgtfy.com/?q=python+tutorials
While I can't help this particular problem, you might see if there is a local users group. The one I attend in Portland, OR is very helpful. 
Yes, this is reasonable. One more idea is [suggested](http://www.paulgraham.com/better.html) by Paul Graham: use only 15 most "interesting" tokens. I'll look into implementing the same thing after I find some training material to test it.
Thanks! Edit: fixed by catching ZeroDivisionError exception. Edit 2: hmm, actually it's a bad fix... Possible solution for the case when training database has a lot of big spam\_count and small ham\_count and vice versa is just use 0.01 for small rating: if rating &lt; 0.01: rating = 0.01 What do you think?
SpamAssassin keeps a good email [spam/ham corpus](http://spamassassin.apache.org/publiccorpus/)
`calendar.month_name[month_index]` is more friendly, in my opinion.
I've seen this, but I'm not sure how well email spam db will work for forum/comment filter training.
I guess you'll just have to train it yourself over time. Create a "spam" section in your forums and allow anonymous posting, then use that data to train the filter.
Yes, that's what I'll do. Just wanted to start with some common spam texts.
It helps and doesn't affect the results in any way I can discern. But I have some very long posts in my corpus (it's blog posts, not comments), and enough 0.01 ratings will still combine to 0.0. I'm playing with sorting all of the words by abs(ham\_prob - spam\_prob), then only using the first 100. I will probably wind up with some combination of limiting the number and and lower bound of ratings, to be sure I never wind up getting an exception there. Thanks for writing this, though! It's more readily grokable than reverend was.
I'm trying to make a word search solver program. What I'm doing is storing the entire crossword puzzle as one big, long line initially. I then break that line into either columns or rows- there's a dictionary with each row in a list per key, and a dictionary with each column in a list per key. I can then print all the columns together in one line, or all the rows together in one line, and do either forward or backward. It works. It's probably the wrong way to do it, but pretty much everything I've done so far is horribly wrong. What I absolutely cannot figure out is how to get the diagonal lines. I don't know how to go from this: &gt;['c','a','t'] &gt;['d','a','t'] &gt;['h','a','g'] to this: &gt;['c','d','a','h','a','t','a','t','g'] That is, put all the diagonals in that direction into a list. Once I can do it in one direction, I can do it in the other. I just don't know how to do it at all at this point. You may be wondering why the hell I'm doing it this way. It's because I'm a total n00b to this, and am learning. So if you want to help me do it my way, or show me a better way, I'm open to anything. If anyone can help, thanks a billion.
Yeah, the OP code is quite ugly.
I pushed changes: now it only calculates total probability based on 10 lowest and 10 highest individual probabilities. (There's also commented-out Robinson's method for calculating total probability based on Reverend sources -- not sure which one will work better, needs testing)
If you concatenate rows, columns, or diagonals and then do a substring search, you will find false positives if a word coincidentally occurs by wrapping from one row/col to the next. If you store the grid as a two-dimensional array you have the rows already and you can get the columns very easily with zip(). I'm new to Python and don't know a better way to do this than with a global, but someone can correct me. Run this code and see what it prints out and see if that helps you. from itertools import izip_longest as izip grid = [ 'a b c d e'.split(), 'f g h i j'.split(), 'k l m n o'.split(), 'p q r s t'.split(), 'u v w x y'.split(), ] print zip(*grid) y = -1 def getrow(row): global y y += 1 return row[y:] print list(izip(*map(getrow, grid)))
8 tips to start with Python: http://tarekziade.wordpress.com/2007/09/24/eight-tips-to-start-with-python/
Just use two dicts?
The fine MySQL Python manual says that you should use the host name "127.0.0.1" or a fully qualified name if you want to use a custom port (otherwise, it defaults to using a domain socket, and ignores the port number). Maybe you could try doing what the fine manual says? The above is standard MySQL client API behavior, so reading the fine MySQL manual would have helped too.
Why do you assume this?
Ah, interesting. I will keep your solution in mind as well, I'm always looking for plug and play classifiers, and it doesn't get any better than Bayes, really...
When your dict isn't heavily updated this might just suffice: def swap_dict(dct): return dict((val, key) for (key, val) in dct.items()) 
That's pretty quirky if you ask me. But it seems you are right...
The last time I had to use two dicts...well, let's just say I'll never see Thailand again.
I would recommend using new-style classes (`class Blah(object)`) for future-proofing your code and replacing getopt with optparse, whose functionality is slightly duplicated in `main` anyway. By [PEP 8](http://www.python.org/dev/peps/pep-0008/), all of those imports should be on separate lines. As mentioned by thunderbolt16, you should add tests with bonus points if you making the testing work with `nose`. These are just nits; the code looks fantastically readable.
That you would have git installed.
[www.pythonchallenge.com](http://www.pythonchallenge.com) is a fun way to dive into Python while being distracted by URL puzzles. The idea is that you are given clues on a webpage that point to a new puzzle. It (generally) isn't required to use Python to solve them, but they have been constructed with its usage in mind.
Get yourself a Python buddy / mentor.
Beat me to it!
Monthy Python?
I agree. Most people only need a few specific operations. It would take two minutes to encapsulate the required functionality into a class implemented with two dicts. This is probably the reason that there isn't much documentation about it—it's obvious and easy to anyone who needs it.
Thanks! imports and classes are done.
How?
Ask below. If that doesn't work, ask on comp.lang.python. 
Very good article on a very interesting subject, but I feel like I'm suffering from a failure of imagination. I can't figure out why/when/where I'd ever use the advanced techniques (everything from part 5 to the end). At first I thought "this might be useful in an environment that prevented access to threads", which immediately brought to mind AppEngine. Until I recalled that on AppEngine you can't have processes running outside of the http handler, and your process must respond within 30 seconds or be killed. I suppose if you wanted to perform many parallel independent url fetches, this might be a technique to get it done within the timeframe. Otherwise, I just don't see the point of creating a virtual OS on a virtual machine (interpreter) on a real OS - I mean, other than to prove it can be done. Especially when you have access to the low level constructs like Thread. As I said, perhaps I'm suffering from a failure of imagination. 
Thanks for the advice! I'll try it out when I'm home. &gt;you will find false positives if a word coincidentally occurs by wrapping from one row/col to the next Well, I've still got them in global variables separated by line. I was going to take care of that in a roundabout way. Again, I've done everything wrong. Want to see the code? I can email it to you or something. I'm sure you're a bit ahead of me.
I would suggest to the author to spend some time with his blog software..
Some awesome tips there, thanks!
I can feel it, comin' in the air tonight, oh lord. I've been waitin' for this moment all my life, oh lord.
neat, but every time I see a title like this I'm disappointed the article isn't more comprehensive. it's been posted before, but the tips [here](http://blog.sontek.net/2008/05/11/python-with-a-modular-ide-vim/) are great. I especially like the ability to run selected code in visual mode. along those lines, try selecting some code (that prints) and doing `:'&lt;,'&gt;!python`, good times
&gt; The function filter, map and lambda are still in python 3000 in the functools module, only reduce is skipped. Monster Fail. `lambda` is a statement, not a function, and it doesn't move (statements aren't namespaced after all). `filter` and `map` (as well as `zip`) stay in `__builtins__`, but they now return an iterator instead of a list. As a result, `itertools.imap`, `itertools.ifilter` and `itertools.izip` are now redundant and have been removed. `reduce` on the other hand, was initially slated for removal and ends up being moved to `functools`. Proof: $ python3.0 Python 3.0.1 (r301:69556, Apr 1 2009, 11:42:54) [GCC 4.0.1 (Apple Inc. build 5490)] on darwin Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; map &lt;class 'map'&gt; &gt;&gt;&gt; filter &lt;class 'filter'&gt; &gt;&gt;&gt; zip &lt;class 'zip'&gt; &gt;&gt;&gt; import functools &gt;&gt;&gt; functools.reduce &lt;built-in function reduce&gt; &gt;&gt;&gt; import itertools &gt;&gt;&gt; itertools.imap Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; AttributeError: 'module' object has no attribute 'imap' &gt;&gt;&gt; itertools.ifilter Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; AttributeError: 'module' object has no attribute 'ifilter' &gt;&gt;&gt; itertools.izip Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; AttributeError: 'module' object has no attribute 'izip' &gt;&gt;&gt; edit: to clarify something about lambda: there have been debates about either its expansion (to full-fledged anonymous `def`) but no syntax fitting Guido was found, and there have also been suggestions of its removal from the language. Both ended up being struck down. Also a little something on functional programming &amp; python 3.0, with the addition of [set comprehension](http://docs.python.org/3.0/reference/expressions.html#set-displays) and [dict comprehension](http://docs.python.org/3.0/reference/expressions.html#dictionary-displays), comprehensions will more than likely become even more prevalent than `map`/`filter` in the future.
Thanks! I've written them. If I hadn't, I would never found a stupid bug in tokenizer.
abhik, Geraldo is still in its first months of life, but I use it on an ERP and a little CRM system and its working well and fast. Would be helpful your thoughts and hacking to have it better than it is :)
Very nice, adding some of those changes to my .vimrc On the subject of Vim (sorry if this is a derail), but what's the proper way to get content from the buffer? I use "+y when having something in the buffer selected but the only issue is that doesn't work through shells (e.g. Being on a Windows PC ssh'ing to a Linux box). Is there any solution for that? 
via: http://www.wisdomandwonder.com/link/2580/tendrils-in-scheme
via: http://ileriseviye.org/blog/?p=1935 Reasoning over Semantic Networks
I thought that the cake was a lie?
Downloaded the Source Code. The src(for example: MLcode\Machine Learning\src\2 Linear\pcn.py) use Tab not space for idention. and only lib(some definition of Class, Funtion), no user case... Ok, I love the book and the source code, just wanna it to be perfect. and FYI, it use numpy and matplotlib.
These are very old.
Ha, tough shit. /DRTFA 
Yes, how grossly unpythonic.
Seems like the author struggles more with `try...finally` than with generators in WSGI. He shall take a look at the with-statement.
There are a number of other very good looking examples on nodebox's website that show off just how simple and powerful it is. On a side note, a lot of the libraries used in nodebox run just fine on windows or *nix as well. The linguistic ones are especially simple, image related ones likely need more fiddling.
There's an important difference that he didn't make clear -- coroutines make your program completely synchronous and deterministic. If you are accessing shared resources, there's no need for locking, since there is just a single thread of control. That's huge for certain kinds of problems, not a big deal for others. Coroutines also have less overhead than threads. Context switching is not cheap. With these coroutines, the switching is all in user space. 
See also [Peter Kankowski's article](http://www.strchr.com/ternary_dags).
nice but the same as: http://www.reddit.com/r/Python/comments/8difs/python_code_for_the_new_crc_ml_book_machine/
Wow, the c++ demo for this library is pretty snazzy. Edit: Too bad the license is restrictive, no one will use it. Edit2: I'm wrong, it is basically bsd. Sorry.
Also, check out slime.vim to send selected text to the REPL in a screen window: http://technotales.wordpress.com/2007/10/03/like-slime-for-vim/
The license is BSD, unless I'm missing something?
Was I wrong? Were you wrong? Are we both right?
I was wrong. I read that twice and its basically bsd in spirit, but doesn't actually say BSD so I just assumed it was proprietary. How embarrassing.
Ah I see. No harm done.
I didn't even know about Stackless Python on PSP until now! Thanks for the link!
I love things like this. It's easiest to implement when you use a test-first approach in programming. I know from the projects I've worked on that an extensive test suite can save you from a lot of headaches.
Anybody have an opinion on PyScripter?
Not bad. I used one of the tree-based learning algorithms as a black box tool and it worked out of the box (ok, it ran out of stack space, which prompted me to cut down on the number of features, then it worked well). Nice and clean. Would invoke the routine again. A++++++++++. 
Wow, I've been looking for something like this for a long time.
So where can I find the book?
Well, it's about time. So many times I've overridden `failUnlessEqual` in my test cases like this: def failUnlessEqual(self, got, expected): if got == expected: return got = pprint.pformat(got).split("\n") expected = pprint.pformat(expected).split("\n") diff = "\n" + "\n".join( difflib.unified_diff(got, expected, "got", "expected")) raise AssertionError(diff) It's good to hear that one day these hacks will be unnecessary.
A quick glance and this looks even simpler (if that's possible) to write with than PyGame. Only problem I see with it is the license (of PopCap stuff).
This looks really cool. The event-driven approach feels somewhat like [EventScripts](http://python.eventscripts.com) for games outside of Source.
"Pycap ... was used for the games Snaky Jake, FUSO Truck Empire, Polychromatic Funk Monkey, and Fishie Fishie. Check out the main project page for downloads and documentation." Two of those are here: http://www.farbs.org/games.html 
You can find it here on amazon.com: http://www.amazon.com/gp/product/1420067184?ie=UTF8&amp;tag=oliviergrisel-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=1420067184 (Please feel free to strip the reference to oliviergrisel-20 in the URL should you want not to tip me through the amazon affiliates program)
I LOVE python's more functional aspects. I feel like its the junction of functional and imperative. reduce is useful in so many situations. why did they remove it from the standard library? (Still in functools though)
functools *is* part of the standard library, they just removed it from the builtins.
So yeah. I have say 500-600 short stories of about 15-20 lines on average that I plan on typing up. The stories are collected from a number of different sources, so it's hard to remember where exactly each story's source is in order to look it up. What I'd like to do is write an app that can search through the short stories and not just match plain text results but also do something like what a neural net does for databases. For example, say I have a story and I come up with some keywords to hit. If the story is about say, a dog, a forest and a lake, if I forget what the story is about and I search for water, I'd like the story to "light up" like a node would in a neural net. What kind of options do I have for something like this / has anyone coded something similar? (This is going to be my first large python project by the way, which I was prodded to get into based on feedback from this subreddit so I thank you all for that). Thanks in advance!
Um, try a neural net? You've answered your own question.
or Try SVD(Singular value decomposition) U can find some code from search (or in Numpy/Scipy)
Yeah I know I was thinking something along the same lines which is why I started reading up on them, but as a neural net how would I divide up the columns? Have a column for every keyword and say an identifier that ties the row to a block of text?
What you describe is exactly the type of problem [LDA](http://en.wikipedia.org/wiki/Latent_Dirichlet_allocation) was designed for. It's basically what google uses to group news stories. Neural nets are so old school I cringe when people jump to them as a first solution (same goes for genetic algorithms).
That's really nice looking. I think I'm going to need a bit of time to try and wrap my head around how that works. Thanks a lot! (I found [this](http://code.google.com/p/pylda/) very quickly which seems to be a pre-built implementation though I'm sure I'd have to tinker a bit and I haven't looked at the source code yet)
Aah, you beat me to it! I wish more people knew about LDA.
Don't forget to check out the [hierarchical version of LDA](http://www.cs.princeton.edu/~blei/papers/BleiGriffithsJordanTenenbaum2003.pdf) and the [time varying version](http://www.cs.umass.edu/~mccallum/papers/tot-kdd06.pdf). You probably don't need these for your little application but they're very nice algorithms to be aware of if you're going to work in this sort of machine learning field a bit. Sorry the links are to such low-level descriptions, I'm not sure if much has been written about these variants in a more casual way.
[Komodo Edit](http://www.activestate.com/komodo_edit/) is missing.
By the way, if you end up writing your own implementation of LDA in Python because pylda isn't good enough for your needs, please let me (heck, all of /r/python!) know about it, because I'd make a lot of use of it. :) I tried writing one myself once (actually, it wasn't pure LDA, it was another algorithm for a different task that was *heavily* inspired by LDA) but it was too slow to be useable. I'd be interested to see if someone else can make something useable. :)
[The official explanation](http://docs.python.org/3.0/whatsnew/3.0.html#builtins "god damnit GVR") is that what you're doing is more obvious when a for loop is used for accumulation. I can't say I really agree with that, what with a loop being a far more general construct than reduce.
Hehe did you catch the part about &gt;This is going to be my first large python project by the way Chances are its going to turn out really ugly, but if it works I'll be happy :D.
I just looked at the source code. And i must say, i am amazed. I have never seen such concise code. 
just curious, how the hell do you guys learn about these things? LDA is sort of a graduate school CS/stats topic.
Heh yeah I meant to come back when I saw that. Apparently he didn't have much to say...
His code is actually an exact, bit-for-bit copy of some code I wrote a few months ago. Looks like I'm going to have to press charges. Of course, what my code does is evolve a neural network to classify pictures of cats into lol and non-lol categories, but that only goes to show you how versatile a coder I am.
I provide this translation as a service since the google translation engine doesn't support noob speak: "Since Python is the only dynamic programming language I've every used, I'm going to blame my gripes with dynamic languages, that many people have at first but gets over, on the one language of this nature that I've used"
I agree... just to be clear I didn't write this, I just wanted to hear /r/python tear it apart.
Google Desktop Search. Next question.
To the author of this blog: You will find that upon learning to swim you will no longer worry about the condition of chairs next to the baby pool.
1. Static code checkers. Don't code when drunk. 2. Learn to debug already. Learn what strong typing is. Comparisons between different types are IIRC illegal in Py3k. 3. It's self. not .self; Never had this problem myself -- explicit is better. Without self you assign to `local` not `global` name. What a newb. He wrote a single app and he wants to ,,fix the language''. GTFO. 
You may want to check this out, I used it recently in a project and was impressed with the results. [Python-Calais](http://code.google.com/p/python-calais/wiki/OpenCalais)
Shed Skin is not a compiler and it doesn't run Python. Shed skin is just a custom preprocessor macro that lets you write C++ with python-like syntax. And it doesn't even do that 100%.
[Natural Language Processing](http://cran.at.r-project.org/web/views/NaturalLanguageProcessing.html)
Hurray for failure!!
Whoever downmods a request for halp is kinda lame. I put it back to 1.
It is a compiler of a sort—there is semantic conversion, and it does run most of python's features.
Coming from a C++/Java background, setters/getters are pretty much essential. But python properties are really cool. Furthermore, should you use setters and getters if nothing special needs to be done upon accessing and mutating the data?
Less is more. If your properties aren't doing anything -- like a getters and setters that just get and set a private variable -- skip the property and just use attributes. You can always modify your classes to use properties later without disrupting client code. TLDR: avoid the boilerplate as long as possible. 
I chuckled.
Some like http://tagger.flaptor.com/findtags? If true, search automatic tagger in google ;-)
If you don't need any special behavior, use plain attributes. When you need something more, switch to a property. When you find yourself with a lot of similar property code, move it into getattr/setattr. The interface to the class stays the same through all three of these phases, so you don't have to touch anywhere else in the code. This is one of the nice things about Python.
&gt; The interface to the class stays the same through all three of these phases, so you don't have to touch anywhere else in the code. I agree that the interface is the same between bare attributes and properties, but getters and setters are totally different and migrating to them does require changes to client code, e.g., class ParkBench: spaces = 4 class EnterpriseyParkBench: _spaces = 12 # we build big benches def setSpaces(self, number): self._spaces = number def getSpaces(self): return self._spaces Edit: formatting. 
[Python is not Java](http://dirtsimple.org/2004/12/python-is-not-java.html). No, really, [Python is not Java](http://dirtsimple.org/2004/12/python-is-not-java.html).
neither unless i actually need to do something on setting or getting the member. i don't see the point really.
badr did not mention getters and setters -- he/she said that multiple properties can sometimes be refactored to use `__getattr__` and `__setattr__` to reduce duplication.
Oh noes, my bad. I misread getattr/setattr as "getter/setter". That said, using `__getattr__` and `__setattr__` is almost always the wrong thing (and so horribly, horribly abused). But that's for another thread.
I took a job at a place that was using LDA to do [collaborative filtering](http://en.wikipedia.org/wiki/Collaborative_filtering). They got the idea to do this by working with a research fellow from the university that I had graduated from with a maths degree about a year earlier. Through speaking to him and reading up on the topic I came to learn that there were people, like him, doing far more interesting stuff with LDA and similar tools in cognitive science / artificial intelligence. A spare PhD scholarship showed up in his department about a year later so I went for it. Now I know all kinds of crazy computational statistics stuff. It's good fun. :)
&gt; graduate school CS/stats you nailed it
Hell no. Getters and setters are for pussies. Kidding of course, as almost everyone else here has stated, they're not really necessary in Python.
The documentation is lacking, but the application is great
&gt; should you use getters and setters if nothing special needs to be done upon accessing and mutating the data? ### hell no
Holy crap, never write python code like that. Jesus.
Seems like Python is in a phase of wild experimentation with different approaches to packaging systems. Has anyone an overview?
ctypes is great if - the C-API you try to wrap is stable - the C-API you try to wrap is not too big Don't use it to access your own C code if you need to pass around objects/structs a lot, especially if you are developing on both sides. The DRY principle is getting violated like hell and debugging is not significantly easier than SWIG. 
I disagree on the naming scheme. Module names are usually pretty short, and typing urllib is easier than url_lib. And besides, you can always "import as".
I think the "you can always import as" argument works more in favor of as readable as possible names, cause if they are too long or hard to type, you can always import them as, so url_lib makes sense in that way. No strong opinion either way though.
You'll need this as well. [Haar Data](http://smert.net/scripts/haarcascade_frontalface_alt.xml), [Python 2.5](http://www.python.org/download/releases/2.5.4/), [OpenCV](http://sourceforge.net/project/downloading.php?group_id=22870&amp;filename=OpenCV_1.0.exe&amp;a=92369479) and a link to the video... http://www.youtube.com/watch?v=1ioV2Dj56iw
http://jacobian.org/writing/nobody-expects-python-packaging/ &gt; Python has one package distribution system: source files and setup.py install. &gt; &gt; And easy_install. &gt; &gt; Python has two package distribution systems: setup.py install and easy_install. And zc.buildout. &gt; &gt; Python has three package distribution systems: setup.py install, easy_install, and zc.buildout. And pip. &gt; &gt; Amongst Python’s package distribution are such diverse elements as… 
It accepts a subset of python's special syntax, slicing for example. It doesn't even allow duck typing with .1.1. So calling it Python-C++ is just a blatant lie. It is a language with Python-inspired syntax that compiles to C++, that is all.
I never said it was Python-C++, but you just admitted that it was a compiler. :)
rarely, almost never. Perhaps only if I needed read only behavior on a model class. Which is very very very rare.
I did my final year dissertation at uni in this area, there are several methods aswell as LDA which you can use, each of them has their own problems and benefits. Check out: Non-negative matrix factorisation, Latent Semantic Analysis (and Probabilistic LSA), Bayesian Hierarchical Clustering. These can be easily programmed in python using the SciPy (Scientific Extensions) for the language. Both NMF and LSA analyse the collection as a whole, so can find relations between different documents. Although they do not indicate how many topics you want to reduce the collection to. Bayesian Hierarchical Clustering does however, find the optimal number of topics present in the collection (however it runs in quadratic time) although for only 600 short stories this will be no problem and take a matter of minutes. Good luck.
Nah, the guy is making strong progress and aiming to implement as much of python as possible. It's more fair to say that it's unfinished - as are all of python's compilers, psyco included.
The new urllib package contains functionality from the _earthwhile_ urllib, urllib2, urlparse, and robotparser EARTHWHILE???
I don't think I did. I'm pretty sure it uses GCC. You could make the argument that anything that parses code and outputs another language is a 'compiler' technically, but 'compiler' almost always is meant to mean something that takes a higher level language like C or Fortran and outputs a binary to execute on a processor. I realize that this isn't a super exact definition, but 99.999999% of the times the word 'compiler' is used, that is what is meant.
lame\gay they need to add 2.6 and django 1.0+
Hey, guess what? GCC compiles to assembly, which is then compiled to instructions, which are compiled to microcode. It's a fucking compiler.
Heh, there's a pony in the background.
It is veeeeeery restrict, it don't accepts even *args for functions, every Python app uses this, the idea is cool but for now it's still unusable.
It'd be better if Django could run, and if Python 2.6 worked. But admittedly, Python 2.6 is still barely supported anywhere, and AppEngine is as great due to the way it works and scales I don't consider it lame because Django does not work yet, but different.
Don't you dare use the F-word in a Python community.
Of course not. I always found getters/setters to be utterly lame, sad and stupid, and their requirement, a design flaw of most object-oriented languages which are also low-quality languages. Python is generally good designed, and it particularly shines here, coming with the decent, productive, useful, and still scalable and abstract solution: 1. No private/public distinction outside documentation: keeps it simple; doesn't implement a mostly useless feature. 2. Just fucking use attributes. 3. When attributes need magic, or implementation changes, use properties, which are an excellent feature that provides a beautiful syntax to call functions.
check out [app-engine-patch](http://code.google.com/p/app-engine-patch/), django 1.0 (zipped) &amp; some really great extra features.
This looks interesting, I'll be watching for more news on it.
ImportError: No module named earthwhile
This looks interesting, I'll forget about it by tomorrow and keep using Django.
I was wondering if anybody could help me prepare some arguments to convince my teacher and leader of my schools "video game design" club (where I am the only programmer) to switch from Perl to Python. He has a background in Perl, and never really gave Python a chance and it is getting to be irritating. 
Looks more promising than some other frameworks I've checked out.
Perl for game dev? Wtf. edit: show him this.
Are you in high school? If so, the club is going to be pointless and the teacher isn't going to care that much anyway. Just do whatever you want, and they'll be happy you even showed up. It is *highly* unlikely that any highschool teacher will be competent in any programming language. Generally they will know some very simple basics in any language that is the basis of a course they teach. This isn't really a slight on teachers, but why would you expect a professional (ok, teachers are usually morons, but assuming they are top notch for the sake of argument) to carry 2 orthogonal skills that both require lots of training? That would be like looking for a magazine editor who also knows how to rebuild diesel generator engines. Anyway, you won't convince the teacher, he probably doesn't really know Perl either, and if you are the only programmer, the club is really just a society of people who like playing games. Don't worry, this is the same situation you will find over and over in life. Lots of poseurs, and you (unless you are one of the poseurs, then it's you and your buds and the one weird guy who you bother when you need something to actually get done instead of just talked about). 
* Easy to install and you can get eclipse with the pydev plugin for free. This means that most students will be able to download it and install it at home. * Learning it is extremely easy compared to any other language. * Reading and debugging is extremely easy because of the forced indentation and lack of brackets. * With the Tkinter python library, a beginner can start learning to animate things and display images on the screen in no time. (I bet he use pearl because most languages like C++ are too much a pain in the ass for beginners to display any kind of image) * There is libraries to interface it with mostly anything: networking, DirectX, OpenGl, 3D engines (Panda, Pysoy) and again all of this is free. * Pygame is an excellent tool to build 2D games. * For most of those reasons you can make projects 5-10 times faster than if you use a more complicated language. If you are already coding with python, build something cool, show him the result and the code. 
Python doesn't need getters/setters, and it doesn't want them. If you're writing getters/setters, read Raymond H.'s article about descriptors (http://tinyurl.com/d63d), start using the property built-in, and realize the error of your ways!
[https://coderanger.net/~coderanger/gamedev/](https://coderanger.net/~coderanger/gamedev/) That has some of my slides from teaching a gamedev course in Python/PyGame. I gave a similar (though much shorter) tutorial at PyCon a few years ago I can try to dig up too.
Eve Online's dev blogs could be useful in this matter. This game makes heavy use of Python for both serverside engine and clientside UI.
I was that weird guy. I had this teacher, in my compsci class. He looked like Bob Ross; dressed the same, too. This was in... 1998. "Bad side of town" school that it was, we had [IBM PS/1](http://www-03.ibm.com/ibm/history/exhibits/vintage/vintage_4506VV4023.html) systems. Coincidentally, growing up poor meant that my first computer (gained through much haggling with a local computer parts/repair shop) was 15 years old and had to be pieced together from the wreckage of two separate 8088 systems (an IBM XT and some other monstrosity). Mmmm... nothing like scrounging for DOS 6.22 floppy diskettes when the rest of the world is preparing to deal with Windows 98. Anyways, point being... I had lots of experience with old-ass computers and the software they ran, by the time I signed up for compsci class. The class was a mix of computer history (minus everything after 1980 due to outdated books) and some applied learning on the class computers. I have never appreciated an application migrating from DOS to Windows, as much as I did with spreadsheets. tl;dr: FML
Such as?
I clicked on the link with the hope of getting a project for my college :)
and Pycap: http://www.farbs.org/pycap.html here is a reddit comment of this new game toolkit: http://www.reddit.com/r/Python/comments/8e3pk/pycap_another_python_game_framework/
If you fail, don't give up. Code in python. If someone asks to show the code, get some code from perl-golf tournaments... especially ones which could actually be used in your game, like Dijkstra's algorithm. (I saw a perl-golfed Dijkstra algorithm that had ~200 characters (totally unreadable for me) on kernelpanic.pl, but the site is down for a long time now) (You can explain that shorter code is faster, giving false arguments like less characters to parse... ;-)) After that you can then show your code, explaining it as a "prototype" of the perl code shown earlier. This will work assuming that you're really the only programmer in the team. Unfair. Not ethical. But I think perl is not a tool for building games... it evolved to do different things.
that's a totally unfair characterization. Your teacher has an obligation to know the subject inside and out before trying to teach it to someone else. It also takes an enormous amount of time to create a syllabus, design assignments, write good tests, etc. You may very well be able to convince this teacher to switch to Python for the next time she teaches the class, but asking her to redesign the course once it's already started is like showing up at a performance of Romeo and Juliet and asking the performers to do West Side Story instead. Sure, it's similar, but it's not the same thing, it's not what they're prepared to do, and you'll be the first one bitching and moaning when the Python class seems shaky and unprepared. Maybe you can convince your teacher to let you do your assignments in both perl and python? Then you can demonstrate how much simpler, cleaner and better the python implementations are.
That site's structure and layout is horrible IMO.
Do your assignments in both, show your teacher and your peers. People use perl for game development?? 
Interesting.
&gt; It is highly unlikely that any highschool teacher will be competent in any programming language. Not that unlikely. My high school physics teacher was a chemical engineer who left the industry to teach high school physics; my high school computer science teacher was an industry programmer who left the industry in order to teach. Both of them knew their field extremely well, but chose a more rewarding (certainly to them and their students) way to leverage their existing knowledge. &gt; This isn't really a slight on teachers, but why would you expect a professional (ok, teachers are usually morons, but assuming they are top notch for the sake of argument) to carry 2 orthogonal skills that both require lots of training? The skills aren't orthogonal, *especially* in computer science. First, it's a general principle that ease of explaining and teaching a subject comes with deep knowledge in it; one would expect (and reality bears it out) that the people best able to program are also the ones best able to explain *how* to program. Second, and particularly in the field of computer science, teaching ability is strongly correlated with programming ability, since in programming one is fundamentally teaching (or explaining) to the computer *how it should do something* and this process does not differ essentially from explaining to a reasonable human how to do something.
It's not horrible. Have you ever played [Frozen Bubble](http://www.frozen-bubble.org/)?
Your point is further reinforced considering he a) still uses perl and b) uses perl to develop games.
If you're the only programmer and you're not expecting the teacher to help you debug, write in whatever language you want. The teacher doesn't want you to write in a language he can't help you with. That's understandable. The key is to show him that with the right language, you won't _need_ him to help. Probably, you don't need a language yet, and trying to use one will burn you out and end the club. If you're the only programmer, this club isn't going very far. It will last exactly until you realize that everyone else is doing the fun part and expecting you to do all the hard work. You'll never create the game that non-programmers can dream up, and nobody will be happy. The programming needs to be easier, or it will be a game 'dreaming' club, with no games ever created. Python / pygame is an excellent choice. I've taught it at high school and college level, and my book on the topic is being used at several high schools that I know of: http://www.aharrisbooks.net/pythonGame. On my main site I have videos of my game programming class (using Python) available to everyone. I've also released a free library called gameEngine which greatly simplifies game development in Python. http://www.aharrisbooks.net Still, I think getting good enough at this to create complete games really requires about a semester of dedicated study in a traditional class. (At least it does for my students) There are some alternatives: You might also consider some other great free tools that may be more attractive to your fellow students with more design than programming interest: This might help them turn the corner into being programmers. Look at scratch: http://scratch.mit.edu It was designed by MIT for kids, but it's more than sophisticated enough for high school students (I showed it to a college class yesterday) It's by far the best program I know for making quick games with little experience. I think your club should get scratch (it's totally free and runs on any computer,) read the documentation, and build your first few games in scratch before you worry about ANY traditional programming language. The scratch programming is very easy (using tiles.) Another great tool you may want to look into is blender. It's a free 3D modeler with a lot of the features of the very expensive tools like Maya and Max. Unlike these tools, it has a powerful game engine built in. You can build a simple 3D platformer in an afternoon. However, blender is not that easy to learn. It's a powerful program, and it has a LOT of options. The book "Blender for Dummies" is actually quite good. (I didn't write it, but I may be working on a companion focusing on game development.) Have your teacher send me an email: andy (at) aharrisbooks.net If he wants, I'll set up a video conference and show you guys exactly how to get started in this stuff. I can also provide lots of other materials and support. Don't give up. If your teacher wants some help, please please have him contact me. I've helped lots of teachers make this transition. 
Dude, you're the only coder. The club uses what you say they do.
So if you won the lottery you would say that isn't that unlikely? I'm glad you had good teachers. Did you go to a magnet school? What county did you live in? I'm going to guess you went to a school in a very rich area, and probably a magnet school for science. Those of us who didn't have a magnet school to go to got to experience the joy of people who throw batteries at teachers and take MATH-9 for 4 years straight, and the teachers who are willing to deal with that every day.
Nope, just a regular public school. Not inner city, but not ridiculously rich, either.
Can't you write a Perl programs that starts a python program? The Python code is just a library. The real work is done in the 1 line of Perl.
Thanks all. To be honest my gut told me to go with properties (KISS method), but I couldn't justify it to some friends who insist on setters/getters. Glad to know I have a good programmer's gut (in more ways than one!).
The real tail recursion: http://www.connectotel.com/rennes/serpnote/serptail.jpg
Woah, attributes all the way. Setting/retrieving an attribute is ONE line of code. Writing two methods (for set/get) is at least four lines of code + one line of calling it. Why does anybody even think getters/setters are a good idea in Python. :(
Ya, I wasn't saying it's not possible to make games out of perl. I mean, mario and roller coaster tycoon were made in pure assembly iirc, but it's just not the de facto usage of perl, that's all.
Another Benford's Law applied to check the Delicious.com user numbers: http://pyevolve.sourceforge.net/wordpress/?p=485, iteresting.
Actually, since games have been made in Perl, it (by definition) is a "*de facto*" use of Perl. You might want to look up what *de facto* actually means ;)
Agreed. So much amazingly good content, but disorientating layout.
this is the kind of place where people complain that their college homework is trivial and their teachers are incompetent, not the place where students help each other cheat on their homework. You might want to try asking over [here](http://img.4chan.org/b/imgboard.html) for stuff like that. They're always hosting cool .js files for you to download. Download files from that site and follow the instructions the users give you, they're very helpful!
This looks very very interesting.
This is excellent. I'll be needing to do some stuff like this soon and this is a brilliant primer to it :)
functools is absolutely amazing. Some things in there are just obscure and hard to use, though.
If anyone is interested, there is another Python Google Analytics client here: http://suryasev.github.com/python-degapi/ that also allows connections through Oauth and other authentication methods.
&gt; 'compiler' almost always is meant to mean something that takes a higher level language like C or Fortran and outputs a binary to execute on a processor Fuck no. Are you going to tell us the java or C# compilers aren't, in fact, compilers? Or that `erlc` isn't a compiler? A compiler is simply a translator from one language to another. It's colloquially understood to translate from one language to another lower-level one but even that is not a requirement. &gt; but 99.999999% of the times the word 'compiler' is used, that is what is meant. no.
&gt; It is veeeeeery restrict It's also barely past version 0.1...
YES. Also, your definition of compiler is the same one I gave. C# and Java do execute on a processor, it's just a virtual one. You're a pedantic idiot.
&gt; Also, your definition of compiler is the same one I gave. No. &gt; C# and Java do execute on a processor, it's just a virtual one. That's completely and utterly nonsensical, and it doesn't answer the question of `erlc` not being a compiler.
You should look at this: http://mail.python.org/pipermail/python-list/2005-April/315453.html
Nope - I do for *some* of my projects though but have been switching to developing more of them with virtualenv. virtualenv is great for development for this very reason. For applications I tend to bundle all their dependencies with them.
Good question. site-packages is gross. For the same reason that global variables are bad in programming, global installation directories are bad. I started using virtualenv and it seems to work pretty well. If I deploy an application, I also want to bundle all its dependencies, and not rely on any system libraries. This conflicts with the typical Unix way of deploying things (i.e. it's not just a Python problem). I think this conflict is going to become more and more significant as applications scale to many different computers. 
no I write mostly for django. my reusable projects are added to my personal pythonpath in .bash_profile, and on the deployment server the apache conf adds the relevant paths for the server process. only thing in site-packages are packages that installed themselves in that fashion. even my django installation is in a work folder and under my own source control. 
no, but a lot of my python files end up starting with something like the ugly and non-portable: import sys sys.path.append("""../../pycommon""") Does anybody know a better way?
I've been using virtualenv for the past week and it's awesome. I highly recommend it Get virtualenvwrapper to make things that much easier. A simple work flow with the wrapper: $ mkvirtualenv myproject $ workon myproject $ cd ~/packages/django $ python setup.py install # installs the package in /django under your virtualenv 
virtualenv for development and deployment.
No. I use one virtualenv per project, and use mod_wsgi's directive to ensure they stay segregated.
Ah yes, all the benefits which cause people to sing the praises of javadoc, but in Python! (me, I'd prefer it if people would actually just write some damn documentation)
It seems ridiculous to use curses when there are so many good windowing toolkits for python. 
Put your startup files at the same level as other internal libraries: src/ app1.py app2.py pycommonlib1/ pycommonlib2/ Then you can just import pycommonlib[1,2] right away without any changes to sys.path.
I find it being more likely on Windows, with no system-supported Python and all.
broken pipe and webserver, etc. optimize that first. &lt;/snark snark&gt;
No, I'm using virtualenv on all my projects. My site-packages directory has only packages used by Ubuntu.
Maybe 10 years ago, sure
I've always found the 'automatic' part to be a little disingenuous
How is virtualenv useful when I write code mainly for myself and have a bunch of self-useful libraries I use all the time? What I'm doing now is just adding their path to PYTHONPATH, but I keep hearing good things about virtualenv. How can it help me here?
No, and I don't use `virtualenv` or `sys.path` twiddling. I keep my projects in `~/src` and set `PYTHONPATH` in my `.bashrc`. Simple, effective, and works correctly. 
Cours en ligne d'Emmanuel VIENNET à l'université de Villetaneuse. Nombreux liens
no, not too normal any more, unless your retarded and went with gentoo without know what your doing.
Yes, site-packages is *mostly* gross, but it's a quick-n-dirty place to store stuff that you want to apply globally -- typically tools to help manage your Python projects -- virtualenv, setuptools, grokproject, or mercurial. Putting a project's source code in site-packages is yucky -- bad developer, bad! For installing I use zc.recipe.egg with Buildout when I want to store package information in my version control system. Either a picked list of versions for the "stable" parts of the system, or pulling from the latest releases by following the 'install_requires' dependency graph, or in "develop" mode when pulling straight from a SCM. Virtualenv w/ pip is also great for trying out stuff in a sandbox. It's less work to learn and use, but Buildout installs more quickly (on subsequent runs) since it can select python packages from a central cache - so it saves on compile time and chewing up disk space. 
Python's packaging and distribution system is *broken* for the 90% use case. It works quite well for complex programs with C modules and weird dependencies, but it's so *damn broken* for the numerous easy simple stupid scripts i just want to package and release.
As disappointing as ever. As usual, Guido's remarked hatred for functional programming will leave Python without an extremely useful and interesting feature *and* optimization. The fact he says: &gt; some in the academic world scornfully refer to Python as "the Basic of the future". Personally, I rather see that as a badge of honor, and it gives me an opportunity to plug a book of interviews with language designers to which I contributed, side by side with the creators of Basic, C++, Perl, Java, and other academically scorned languages terrifies me, as I see Python is not driven by the need to make a decent language, and makes me rethink if I should consider Python's design that good, if Guido is glad to compare it to BASIC, Java, Perl or C++. It also leaves no doubt that he's not doing the best for Python. His purpose is not to make a great langauge, but to make a Pythonic language, for an arbitrary definition of Pythonic that's certainly not derived from flexibility, practicality, correctness or completeness. All of this makes me realize the sorry state of programming languages: the languages you may get a job about, even the less popular ones, are designed by people who just want their (often pretty deficient, not as much in the case of Python) personal style imposed over others and don't give two hoots about what's actually good to have, and the good languages you want to work with aren't practical even for your own free software projects beacuse they lack libraries, platform support or documentation. This leaves you with the choice of a sub-par langauge that does the job, albeit not in the best way, or a superb language you can't use. The choice will probably be for the former, but not because one likes them.
&gt;The elimination of stack traces for some calls but not others would certainly confuse many users... Reasonable. &gt;... who have not been raised with tail call *religion*... (emphasis mine) I can think of no greater display of lazy rhetoric and sheer intellectual dishonesty than labeling opposing positions as "religion." How sad for him.
Thing to note about the post: **Author says:** &gt; According to the Django documentation, a setup of the Apache Web server running mod_python is the recommended option for deploying Django applications **Current Django docs say:** &gt; The mod_python module for Apache can be used to deploy Django to a production server, although it has been mostly superseded by the simpler mod_wsgi deployment option.
Admittedly, I haven't much experience in functional programming, but I don't understand this debate. Sure, TCO makes recursive calls linear in complexity, but what's the big deal? Loops could be expressed as recursive calls, but why not express them as loops? Isn't that a matter of having the interpreter support your personal coding style better?
liked watching it, but why doesn't he use the new awesome declarative_base from sqlalchemy?
&gt; Guido's remarked hatred for functional programming [citation needed]. As far as I can see, he doesn't want to eliminate something python is good at--in this case, correct stack traces. I guess I just don't see how this means that Guido is ruining the language. I mean, you could always... *gasp* USE A LOOP!
I can't believe Guido refuses to modify his own language to fit all my petty desires.
&gt; [citation needed] Python development history. He keeps attacking the few functional programming features that made it to the language, and threatened to elimianate some such as lambda. He keeps dissing these features because they are not the way he wants Python to be. He treats functional programming languages and especially Lisp, as well as programmers who want functional programming features, with extreme disdain. &gt; As far as I can see, he doesn't want to eliminate something python is good at--in this case, correct stack traces. I guess I just don't see how this means that Guido is ruining the language. Yes, because it's so useful and clear to see a 600 lines long stack trace full of calls to the same function, as opposed to "300 x function". &gt; I mean, you could always... gasp USE A LOOP! First of all, iterative processes are not the only useful thing tail call elimination is good for. Second, tail call elimination is an optimization in an of itself, that applies to all sorts of algorithms found in all sorts of existing code. Third and most important, Python is said to be designed for productivity and clarity, and tail call elimination allowing you to write tail-recursive constructs would be a big step towards this direction. There are some things best expressed with for loops, some things best expressed with while loops, some things best expressed with do..while loops (oops), and some things best expressed with tail-recursive functions. Why Guido refuses to admit this obvious fact of algorithm notation is beyond my comprehension. See how Lua, without aiming to be a functional paradise, and without being nearly as ambitious as Python, supports tail call elimination.
No, it isn't. I explained why my last paragraph of this reply to another post in this thread: http://www.reddit.com/r/Python/comments/8g0pj/neopythonic_final_words_on_tail_calls/c0963tp
Do you have an example?
...my petty desire being to have the right tool to model each algorithm and thus make Python programming more productive.
&gt; The elimination of stack traces for some calls but not others would certainly confuse many users... Only retards would be confused by that. `return f(...)` is to be converted into a jump, while any other kind of return is not. OMG! So difficult! Yes, maybe Guido wants Python to be the new BASIC. I suggest killing the object system next, it looks like secret hacker technology. Then I'd add type symbols to variables such as a$, i% or f!, it's easier this way. And then he should add line numbers; they make stack traces nicer.
Guido posted one in his own message, then proceeded to show an ugly and far less readable hack to workaround it and tried to pass it as a solution, while being incredibly intellectually dishonest by calling it GOTO, something that would immediately trigger negative connotations from almost everyone. tail call elimination is a controlled way to jump, and it's not more like GOTO than Python features such as if, while, break and return are. Tail call elimination is a feature that can be used as flow control, just like every other Python flow control feature (and it also serves other purposes distinct from flow control).
If you haven't run into the problem, then you don't need to solve it. If you're just writing code for yourself and not deploying it to more than one machine, then it's not surprising that you haven't run into it. But when you start managing larger pieces of code with a lot of dependencies, and deploying these apps to other machines (especially for a running product that must be reliable), then you will probably run into it. And right now it sounds like virtualenv is the solution. 
Mainly because I got used to it and I recorded the screencast a while ago and didn't had the time to re-record it with declarative base. I will however do that with the next release for werkzeug where I hope to have a better microphone and concept :)
By the way, mitsuhiko, the new docs for Werkzeug are fantastic. Kudos.
Were you replying to something I wrote?
&gt;I mean, you could always... gasp USE A LOOP! I see you make the same mistake as Guido, namely thinking TCO is only about recursion.
&gt; Sure, TCO makes recursive calls linear in complexity Constant in complexity, you mean. The thing about recursion is that it supports substitutionary equational reasoning about programs. Loops don't. Consider the following code, in C: struct node { void *something; node *next; }; unsigned int length_recursive(node *np) { return np ? 1 + length_recursive(np-&gt;next) : 0; } Disregarding the non-idiomatic nature of length_recursive (I needed to use the ternary operator to get a conditional expression in C), it's easy to reason about what this code does: just keep substituting the definition of the recursive function into the expression with its new value until you reach the base case. We're accustomed to this sort of reasoning, since we've all been doing it since junior high algebra, substituting values into equations to make simpler equations until we have no more substitutions to make. Now consider the looping form: unsigned int length_loop(node *np) { unsigned int len = 0; while (np) { len++; np = np-&gt;next; } return len; } This is somewhat harder to reason about, because to reason about what it does, we can't just think of mathematical equalities, but need to consider the progressive values of variables over time. This is a new skill, one not clearly learned in everyday mathematics classes. It's also, incidentally, far easier to *mechanically* verify recursive solutions than looping solutions, again because equational reasoning can be used, rather than teaching a computer how to reason about things over time. This is pretty clearly discussed in SICP, if you have that handy, though I can't find my copy at the moment to refer you to a particular section.
But obviously him and A\_for\_Anonymous speak about the same thing anyways, as shown here: &gt; Yes, because it's so useful and clear to see a 600 lines long stack trace full of calls to the same function, as opposed to "300 x function". 
Let me break it down to you: This is not the programming language you are looking for. He can go about his business. Move along.
&gt; He keeps attacking the few functional programming features that made it to the language And yet we still have list comprehensions (thanks Haskell!) &gt; threatened to elimianate some such as lambda And yet lambda is still in the language. &gt; He treats functional programming languages ... programmers who want functional programming features, with extreme disdain. No, there is not an extreme disdain. I've been following python-dev for years and have never read anything that approaches disdain, let alone extreme disdain. If you have a reference, please provide it. 
Instead of crapping all over GvR's design decisions someone could get TCO implemented into Python and get PDB to give reasonable results -- it seems obvious to all haters that it can be done. Let Guido reason with dropping patches for that. What? Nobody wants to do it? Then how about STFU? 
&gt; Constant in complexity, you mean. I'm not very familiar with the English terminology, you mean O(1)? Isn't it O(n)? I see what you mean about the recursive function being easier to reason about, and I see how these sorts of solutions should be made easier. Sadly I haven't read SICP yet at all, but I think I should, thank you...
Well, these disagreements between the community and the developers makes a pretty strong case for using pypy. With pypy us developers (we developers?) aren't subject to Guido's every whim, since the project itself is designed for easy hacking, and us python developers get the extra bonus of already being intimate with the language that the interpreter is written in, further simplifying the process of extending and improving pypy. Plus, with the whole JIT generation thing, it has the potential to be considerably faster than CPython, and **all** of the optimization complexity will be contained in one place, the JIT generator. (yeah, I really like pypy, can you tell?)
&gt; I'm not very familiar with the English terminology, you mean O(1)? Isn't it O(n)? The issue with tail call optimization is *space* usage: if I make `n` tail calls in a language without TCO, I use `O(n)` space. If I make `n` tail calls in a language with TCO, I use `O(1)` space. TCO doesn't impact the *time* usage of recursion, just the space usage, so I assumed when you said "linear in complexity" you were referring to space usage, in which case I figured you must have meant "constant in complexity" because that's what TCO does.
Right right, I guess I didn't realize that the overhead of calls is constant, so recursion is indeed O(n) in time and O(1) in space with TCO, you are absolutely correct.
Needs moar jythonc. 
Did you check out the code? svn checkout https://twitter-follow.googlecode.com/svn/trunk/ twitter-follow What do U think of achieving persistence by using hidden input form fields?
The world? That's kinda setting your sights low for Python.
 from world import *
 import antigravity
&gt;I got a D in a Data Structures class because implementations had to be in Python. Wow...I would've done anything to get to do my implementations in Python instead of C..
Really? I love Python, but for Data Structures I would thing C was far better. There are just far too many things that Python hids.
Not directly; I replied to your post in order to comment why I don't find the first quote reasonable.
Let me break it down to you: This is not intended to be good. It is intended to be "Pythonic", for an arbitrary definition of "Pythonic". Move along.
&gt; And yet we still have list comprehensions (thanks Haskell!) As I said, there are some FP features that made it to the language. However, Guido dislikes many of them, and he also doesn't want to add any more. &gt; And yet lambda is still in the language. Because everyone was in an uproar. &gt; No, there is not an extreme disdain. I've been following python-dev for years and have never read anything that approaches disdain, let alone extreme disdain. If you have a reference, please provide it. Duh. From TFA: &gt; And here it ends. One other thing I learned is that some in the academic world scornfully refer to Python as "the Basic of the future". Personally, I rather see that as a badge of honor, and it gives me an opportunity to plug a book of interviews with language designers to which I contributed, side by side with the creators of Basic, C++, Perl, Java, and other academically scorned languages -- as well as those of ML and Haskell, I hasten to add. (Apparently the creators of Scheme were too busy arguing whether to say "tail call optimization" or "proper tail recursion." :-)
I'm very interested on PyPy and have been following its development for some time. I'm waiting until it's more mature to start working with it. I don't know if I'll have enough time for what I want to achieve, but I'd really love to have a language that has the syntax, object features and standard library of Python, but has no statement design wart (all statements turned to expressions, may appear anywhere; solves lambda, lambda vs. def, if..else wart vs. regular if, adds support ofr lambda classes, and so many other good things), and featuers tail call elimination. I don't know to what extent would I be able to modify PyPy for this, but I hope it's possible with reasonable effort.
I'm failing to think of a data structure that you couldn't get a good understanding of by studying a python implementation.
Thanks
No, it's not, but tail call optimization IS about "inlining" calls. It's unnecessary.
import world as mine
Can someone direct me to a tutorial about how to make P2P connections. I want to create p2p chat. I thought about using pjsip for it, but I still can't understand how to make p2p connnection....
I had to do them in ML (MosML to be precise).
I can only remember this code: http://linuxreviews.org/news/2005/11/11_tinyp2p/ P2P file-sharing with only 15 lines (thanks to the built-in XML-RPC library in Python)
Journey blogs are nice and all, but only when they actually have something insightful in them. So far we have a story about how someone failed at a class because he had to use an unfamiliar language and now he has vim set up to do stuff.
I think that Data Structures might be made *clearer* by typing, but I can't imagine anything that might be difficult to accomplish in python.
But if it's in ruins when you take it over, people will love you more. A good example escapes me... maybe President Obama knows, ask him. EDIT: in
Cool. I'm a functional programming geek so that would've been even further up my alley.
Interesting project, I only wish other editors supported it (e.g. Editra, Pydee).
I try to, but I always find myself making exceptions: * What if you need to pass multiple parameters? * What if your getter or setter has to do some additional processing? Then you pretty much have to write the other one to make things consistent. * If you wrap everything up with a property, do you make the getter/setter private (e.g. with underscores)? I do agree that basic, passive accessors are useless though.
Suppose you write a function called square() that returns the squares of all the numbers in a list. Now square(4), for example, probably won't work because integers don't support iteration. Python is supposed to be flexible with data types, so why isn't there an accepted way to promote an object to a list (e.g. turn 4 into [4] and do nothing to [2])? Numpy has an a built in in function called asarray() that converts stuff to an array, but I'd imagine this was a more general issue.
Well, the first thing that comes to mind is that in Python, it isn't immediately visible how large a particular structure is. In C you need to be aware of this all the time. Additionally, in Python you don't really know where your data is. There are no pointers. In CPython `id()` returns something that looks like a memory address, but any relation is simply an implementation quirk. I never actually took Data Structures, but I took Operating Systems this semester, and by the final project most of the guys still didn't even know what `malloc` was. Trying to explain to them how the data structures actually work is quite difficult.
Static typing[*] wasn't really what I was thinking of at all. IMHO, Java isn't really much better than Python. See my reply to kaens. [*] I assume that's what you mean, because Python is most definitely 'typed'.
&gt; Python is supposed to be flexible with data types No, it's not. It's *strongly* typed, it's just *dynamically* typed. **Not** being "flexible with data types" is one of the things that makes Python significantly easier to write and more reliable to understand than languages like Perl and PHP. &gt; why isn't there an accepted way to promote an object to a list (e.g. turn 4 into [4] and do nothing to [2])? I guess because most people who write good, type-safe code don't need that. You should know whether your variable is a list or not; if it is, pass it to the function directly, and if it's not, put it in a list first. Also, because if they did need it, it'd be trivial to write: def promoteToList(v): if isinstance(v, list): return v else: return [v] More importantly, however, people don't write badly factored code. Your square function should square a number. If you want to apply it to a whole list, then you can just use `map(square, mylist)` or `[square(x) for x in mylist]`. Writing such a function to take a list of numbers rather than just a single number arbitrarily and unnecessarily reduces its flexibility.
&gt;tail call optimization IS about "inlining" calls. No, it's not. In fact, it's so far removed from the concept of inlining that I'm inclined to think you're speaking out of your ass or just a troll. In case it's the former, here are some links: http://en.wikipedia.org/wiki/Inline_expansion http://en.wikipedia.org/wiki/Inline_function &gt;It's unnecessary. You should be more wary of making absolute statements. That you work in an area with sufficiently simple computation paths that you don't worry about blowing the stack (nor the associated memory consumption), does not mean the same applies to everyone else. [Trampolining](http://en.wikipedia.org/wiki/Trampoline_(computers\)) can help, but, apart from it being a kludge, it requires writing every function in the system like that, and knowing you need to do such in advance. 
Then maybe you should respond to the person that authored the quoted material. Given that the quote is from the article, that would entail making a new comment thread.
But ... it is the *global* namespace after all.
&gt; people don't write badly factored code If only this were true
True, but let's give it some time.
There are far better ways to do this.
Is that a fancy name for monkey patching?
I wish that he would put some comments on (IntenseDebate, Disqus, whatever) so we could point out some helpful things.
what a stupid thing to do
Yes, that's what I meant. Even annotations that *mean* nothing will make the code *clearer*.
Look, I know what TCO is; I've written full implementation of it. And it is inlining—maybe not in the copy/paste sense of the word, but in the sense that it inlines the call itself. I.e., it integrates the call into the implementation of the function. EDIT: An python STILL gains nothing but speed from TCO and loses the trace.
What the hell is this? A rational article that assumes both sides of the previous week's flamewar might actually have some valid ground to stand on? And introduces a pretty decent proposal for new syntax? Inconceivable!
This actually seems like a pretty good idea.
PEP! PEP! PEP!
You keep making these absolute statements, even in the face of being factually wrong. No worries, kid; you'll grow up someday.
yay. open flash chart for the WIN! http://forums.openflashchart.com There are a few Python libs, the javascript one looks like it is going to be nice to use with AJAX and jQuery (when it is finished)
&gt; PEP! PEP! PEP! First, it needs to be posted on [python-ideas](http://mail.python.org/pipermail/python-ideas/). Then if interest is reached (and possibly something that kinda looks like a consensus), it can be proposed to [python-dev](http://mail.python.org/pipermail/python-dev/) on the path to become an actual PEP. If it's made straight into a PEP and posted to python-dev, it's going to be blasted hard.
Copied to the blog post. 
Interesting. It is a nice method of introducing TCO to Python. I'm still not sure that we need it, but I applaud the tidyness of this solution. My only objection is the overloading of the meaning of "continue". TCO would be something that is taught quite late. In the meantime, students would come across it and get confused. I favour a different keyword.
Soon there will be a python-ideas-ideas, to which you post ideas that would be blasted hard on python-ideas. And then there will be a python-ideas-ideas-ideas...
&gt; My only objection is the overloading of the meaning of "continue". Well, if “Python is the Basic of the future” then `chain` could be an appropriate keyword.
how about 'continuate' ;-)
Oh yeah, science forbids there would be any discussion of proposals/ideas before bothering the time-limited core team.
I wonder if one could make, in pure Python, a decorator to perform the tail call, and if that would work. It could go something like: @tailcall def myfunc(*args) return (1, 2, 3) And the "return" would call myfunc with (1, 2, 3) as arguments... It'll take some brainstorming.
It's been proposed. I don't think it's possible.
When I saw the term 'Tail Call' I assumed we were talking about 'chasing tail', not programming.
You're thinking of a “booty call,” which is the last instruction in LILO or GRUB.
How about `callcc`? :) **Edit:** I'm actually kind of serious. I agree that overloading `continue` is dangerous because the current use of that keyword is straightforward and frequent; we would need something else, and (like `lambda`) we might as well call it what it is. (Of course, a proper `callcc` would actually give a continuation object to the callee in addition to whatever other args/kwargs you might want to pass. I could see a case for `callcc` and its cousin `tailcall` that doesn't pass k.)
Interestingly enough, Perl 5 effectively overrides goto (poorly) for exactly this purpose. It just requires you to manually set @_ if you want to change the arguments. But this is much nicer. :) sub fact { my ($n, $acc) = @_; $acc ||= 1; return $acc if ($n &lt; 2); @_ = ($n - 1, $acc * $n); goto &amp;fact; }
pithon
Aw.
It is, but you need to perform ugly bytecode munging, not exactly pretty, and not fast either.
I, too, abhor humour.
And apparently lack the army of sycophants to upmod your humorless posts ;)
I'm sure a booty call is where you set the A20 line before switching from ring 0 into protected mode... or maybe I'm thinking of what comes later...
Are you sure you know what you want? The standard sockets tutorial on the Python site by definition is p2p.
To be fair, I did mod masklinn up because it is a true point.
*Is* using continue frequent? Or is it just that everyone knows what it does?
Humour is supposed to be funny, though.
My current project: $ find -name \*.py|xargs cat|wc -l 15828 $ find -name \*.py|xargs grep while|wc -l 56 $ find -name \*.py|xargs grep continue|wc -l 8 That's one in seven loops on average for me. Does that count as frequent?
Nice, according to the comments it's Alex Martelli's.
How do I use IDLE with virtualenv? I'm new to python and want to learn pylons. I tried installing virtualenv which seems to have worked. Only problem is I can't get IDLE to work from my virtual environment. BTW, I'm using vista. Any help would be greatly appreciated! Thanks.
Well, it's partially true. That is, it would be true if python-dev was really a place for solely the Python core team, but it's not. There are *far* more people there than the core that works on Python, and it became too high volume to occupy most of the core persons' attention years ago. Heck, I was even a subscriber to python-dev historically. I was just chuckling because the Python community has somewhat of a reputation for being a little "prickly" and the existence and necessity of python-ideas reinforces that point :)
cheaaaa charts
Try http://www.buildout.org/
I found the hypothetical 'python-ideas all the way down' requirement to pass a proposal on TCO to be quite funny. Maybe we could take a more iterative approach like python-ideas-1, python-ideas-2, python-ideas-3.
You know `for` loops are loops too :-p
I don't understand. How does this help my python programs' imports find my own common modules? 
A new keyword would probably cause greater confusion IMHO. Keywords are a very obvious feature of a language, so those new to python would be confronted with the TCO keyword early on, even if they might benefit from learning about the feature later on. If 'continue' or another keyword is overloaded, then for users learning the language, they would only need to know about the most common use(s) of the keyword. TCO then becomes something one can learn later on. Take 'yield' for instance. I would bet almost everyone learns about 'yield' as a statement before learning about 'yield' as an expression, if at all. I would guess that TCO would be more common than 'yield' as an expression, but I think the same rational would apply.
'yield' as an expression isn't really overloading the meaning of 'yield', though. It still does the same thing (suspend execution until the next value is needed). With this use of 'continue', control flow is completely different for the two uses.
I didn't think of that! I've just counted them and got 581 in the same code base. This is false, though, as the word is used in a lot of my comments, strings, generator expressions and list comprehensions too. It's going to be quite a bit harder to count them.
&gt; Improved startup time How much improved? I'd like to use IronPython but 10% startup time improvement wouldn't just be good enough.
I would think something like '^\s*for' would weed out the majority if not all of your comments and everything else, although if you write your longer list comprehensions like I do: [foo for foo in bar] you'll still get some false positives, but it should be alot better :-) By the way, I in no way guarantee that regex is correctly quoted for grep :-p in fact I don't even remember if gnu grep can handle \s [[:space:]] would work instead in that case though, but you probably already knew that lol
hugely improved is what they claim. Amongst other changes they don't precompile on startup - which was one of the big costs. They now have adaptive compilation which only compiles code that gets executed multiple times.
what do you have in mind?
Ugh.. no.. just.. no. As cool a hack as this is, please do NOT bring the disaster that is web application development to the desktop like this.
Picky, picky. I figured more people would be familiar with the second stage.
class Foo: def foo(self): return ‘foo’ aFoo = Foo() aFoo.foo() def bar(self): return ‘bar’ Foo.bar = bar aFoo.bar() This works, and seems a lot better to me. You can also add @classmethod before the definition of bar to allow you to do Foo.bar() at the class level as well as the instance level if you want.
I'm trying to make a 3D surface plot, but it doesn't look like there's any easy way to do it. Matplotlib removed their (admittedly limited) 3D support and most other similar packages are severly outdated. Mayavi2 seems to be the only possibility, but it looks like a pain to install (at least on Windows) unless you want to install the entire 250 MB Enthought Python Distribution. Anyone have any suggestions?
So... how fast is it now compared to cpython?
Well, that's what he's doing, except it finds the class from an instance and he's also wrapping the function with a MethodType. So 'far better' seems a stretch...
Last release they threw around a 0.8x-2x figure. Wether 'x' is pypy or cpython I don't know, I assume PyPy is still the slower one.
I think the 0.8x - 2x meant that the pypy interpreter was up to two times slower than CPython.
Beer.
tokenizer is a built-in module; it may help to rename it to something else to avoid confusion.
Out of curiosity, does this serve the same function as the C++ multimap?
What is this useful for?
The speed isn't really important at this stage. It's designed to work properly, as a base for later optimization. 
Uhm... Where did you find any use of "tokenizer" in the source code?
Whoops, i didn't actually read the code. I just saw your comment and assumed you were using tokenizer.
Same subject with python2.6 ABC usage here : http://tarekziade.wordpress.com/2009/05/01/basic-plugin-system-using-abcs-and-the-extensions-package/
Thanks for the insight. Most mailing lists are magical places for me because I'm always hesitant about signing up for the amount of email they must generate. Ditto for IRC channels and the hours they would consume.
this is a pretty cool example. but (IIUC) it requires you to have at least 2-3 copies of the entire dataset in memory at all times. for stuff which i'd want to use multiple cores, that's often not an option. a simple example extending this one that to not keep everything in memory would be great. (does map-reduce always assume available memory &gt;&gt; memory for data?)
Looks nice. When I get some free time I will check this out.
Fresh install of OS X, not a month old. "sudo easy_install mutagen" used at some point. `WARNING 2009-05-03 02:02:26,742 py_zipimport.py:103] Can't open zipfile /Library/Python/2.5/site-packages/mutagen-1.15-py2.5.egg: IOError: [Errno 13] file not accessible: '/Library/Python/2.5/site-packages/mutagen-1.15-py2.5.egg'` This appears to have occurred because the `easy_install` author couldn't fathom that my `umask` might not be 022. FWIW, I have been a passionate Python advocate since 2001. Nothing about Python ever seemed magical, nor was any problem ever so opaque as to be mystical, until `easy_install` appeared. Now I can't even breathe near site.py without every 3rd party package shitting itself.
Wasn't it Guido himself that said packages with python are just awful? I want to say he said something similar to that at one of the big python conferences. Anyone know what I"m talking about?
I've had similar ridiculous problems on OS X. Installing from tar.gz seems to be the only way I can actually get shit done.
 I think the most reasonable complaint about "eggs" isn't really about eggs but the tool most people use to consume them (easy_install). easy_install sucks balls, nobody claims it does anything else. But the egg packaging format is reasonable and there are other tools like pip and zc.buildout that consume and install them. I have little doubt that at some point the "egg" format itself will be embraced by the Python core, someone will write a good installer and uninstaller (that will also ship with the Python core), and all the problems folks currently have with them (which is that the primary install tool sucks balls and *doesnt* ship in the core) will go away.
Off topic but is it theoretically a good idea to have one package management framework for all platforms? Why is package management always platform specific?
No, it's not a good idea to have a generic package management framework. Packagers (like Debian, for example) have years of experience at collating huge collections of independent software, and guidelines about how to package them so they don't interfere with each other, and so upgrades can be painless and safe. Python developers, no matter how skilled they may be at coding individual applications and libraries, rarely have this experience, so I wouldn't want to install packages they've made onto any system I'm responsible for. The other problem is that package management systems generally assume they'll be the only package management system - once you introduce a second one, they can start stomping over one another without noticing, and that's just Not Fun to debug. The nicest thing I can say about .egg files is that they're usually pretty easy to turn into .RPM files to install on `$EMPLOYER`'s RHEL servers, or to install by adding them to `$PYTHONPATH`.
Eggs and easy\_install are not the same thing. 
If not the same then [seemingly very closely related](http://peak.telecommunity.com/DevCenter/PythonEggs). I'd rather leave configuration management to [grown](http://www.svnbook.com/) [ups](http://en.wikipedia.org/wiki/Dpkg) and zero-effort deployability to `/bin/cp`. Ignoring `easy_install` for a moment, it seems the people behind .egg failed to learn from the mistakes of Java in using .ZIP as a file format for performance-sensitive tasks. So, the first thing that happens every time I import `mutagen`, something has to open a file, seek to the end and start reading it backwards. Too much suck to bear!
Be very sparring with "sudo easy_install (foo)"! sudo is for installing as root. You just risk making a mess of your system Python and making python-based Apple apps no longer work. Create a virtualenv, then easy_install in there (or use pip). 
Oh yes, because dpkg works so well on open/free/net bsds, on solaris, on aix, on redhat, on osx, on windows, on suze, ... If you love dpkg so much, by all means do use it, nobody's stopping you. 
I by no means love dpkg, it's just a hell of a lot less retarded.
The answer doesn't change, if you don't like eggs or easy install don't use them, I know I don't. 
Per other comments, I'd prefer to just use a proper system for this (either dpkg/rpm/etc. for system software, or importing the relevant code into revision control for custom software). As for virtualenv, I fail to see what problem it solves that I couldn't possibly work without being solved for the past 8 years. :) I understand what it could be good for, it's just not compelling enough for me.
just unzip .egg and copy paste to your python `lib` folder
Funny you should praise Debian with respect to it's great handling of python software. I had a Debian workstation for a while, and witnessing how **poorly** python packages were handled is what led me to install a different distribution. Just sayin... where you see "years of experience" I saw "strewn across the filesystem without rhyme or reason." 
the main issue is that setuptools and easy_install are both piles of horrible hacks and worse code by now i think all code by pje is made only for the wtf's, not to be actually good
&gt; Intentionally invoking Godwin, if Poland didn't like Hitler should they have just looked the other way? :) If you wanted awful analogies, you should have gone with the standard cars. &gt; The problem is that it's creeping up all over the place Haven't seen that anywhere, and if the last 3-6 months of noise are any indication setuptools is creeping out rather than up. &gt; When that happens, at some point in future someone will write a PEP demanding its inclusion with CPython And it'll get thrown out because `easy_install` is garbage.
Oh by the way... &gt; So, the first thing that happens every time I import mutagen, something has to open a file, seek to the end and start reading it backwards. Unless you specifically asked that the egg be kept compressed, absolutely not. Upon install eggs are "exploded" in a `.egg-info` file (which contains textual metadata) and a `.egg` directory which contains the unpacked library. The biggest issue here is that it clutters your `PYTHONPATH` as every single egg becomes an entry in it. And *that* can slow down python.
&gt; Per other comments, I'd prefer to just use a proper system for this (either dpkg/rpm/etc. for system software, or importing the relevant code into revision control for custom software). And you usually can, it's just a matter of your distribution handling it (though it's admittedly simpler for `rpm` than for `dpkg` as `distutils` can generate rpms alongside windows installers, msis and tars, but can't generate `.deb` files)
[pida website](http://pida.co.uk/)
The python-* packages for psycopg2, or trac, or pretty much anything are somewhat out of date. If you're using something like Satchmo, which lives pretty much on the bleeding edge, you can't count on .deb files. I put each webapp in its own virtualenv; it helps.
I've been slapping stdeb around. It's quite nice. What I do want is my own repo. Or pypi.python.org/deb, that would be best :)
Pretty much. Most libraries need some resource files, and they don't have a deployment concept. The Glassfish method works pretty much better. Try pip in a virtualenv. Mine are under svn, and I'm planning on svn merge'ing $ENV/lib/python2.5/site-packages/*/ from a separate /vendor/libfoo/ folder. Is that what you mean by config mgmt?
&gt; What I do want is my own repo. Your own deb repo?
You do realize that an apt-get that used .msi instead of .deb would be a hit, right? Imagine the goodwill you'd gather for bringing synaptic to the masses...
I'm guessing you wanted an one-off script for messing with your music library... Although debian's repo has quite a selection of python-* libraries, they're dated enough. What's the story with MacPorts?
Remember the py2.3 decorators hack he did?
You need to have a better look. The big problem is python-support, python-central and the third other crappy python-helper-whatever. The "strewn across the filesystem" problem is how they dealt with several Python versions. Not the brightest, but it works. Still, I'd love to have relocatable binary packages that I can install on a virtualenv, so I do see where you come from.
&gt; You do realize that an apt-get that used .msi instead of .deb would be a hit, right? I mostly understand that you'd need some organization taking responsibility for the root repository and all packages distributed through it. Which probably isn't going to happen.
Yeah; I know it's easy to do, I've done it myself when I made an exim4-daemon-custom .deb, but then you'll have a bit of work so you can have apt-get working against it. Nothing much. But I'd prefer cheeseshop :)
I agree, and I was hung up on that as well. The SynapticOnWindows is an old idea, but having the responsability would suck, and I've let the idea sleep. What if you linked to HTTP-accessible .msi files? Or to a folder of them, so we can create a Packages file and have upgrades? Still, this approach would put a lot of work on the root; and then there's the .msp story and the transformation support you'd need as well. What do you think?
&gt; What if you linked to HTTP-accessible .msi files? Well that would kinda work as you'd argue that you're just linking, but in the end the interface to the packages would still be yours, so you'd still be the source as far as the user could see, and you'd still get blamed when something breaks. But yeah the ports approach would pretty much the the only workable one (forgetting the responsibility issue), link to the original `msi` and have some packager-specific files telling the packaging software how to do its manipulations and customizations.
This is one thing that has bugged me about Python since learning it a few years ago. Ruby has never appealed to me at all, but I do feel some jealousy regarding [RubyGems](http://rubygems.org/). Python needs a decent packaging system with official repos.
Any idea why they're hidden directories?
&gt; Any idea why they're hidden directories? Are they? I don't see that on my machines (either my macbook or my windows PC) and as far as I know I didn't do any specific configuration (I wouldn't even know if there's anything to configure there), they look perfectly normal and un-hidden.
&gt; What's the story with MacPorts? I don't know about the up-to-dateness of the libraries, but there isn't much variety: where the chesse shop has &gt;6500 packages, `port list py-*` returns 381 python 2.4 packages, `port list py25-*` returns 251 packages and `port list py26-*` only returns 133. Needless to say, `port list py30-*` is a miserable failure with a single package.
as author of a python package, i'd be interested in hearing what you want instead. my code is pure-python and you can either use easy_install or copy the tarball/zip to your own machine, unpack, and use setup.py (the packages are available at pypi and google code). you could even unpack and use cp, but i don't provide detailed instructions for that. note that it's the same tarball/zip in either case, so even if you use setup.py or cp, you're using code packaged using easy_install related tools. is that sufficient? or are you saying that you expect me to generate .deb and .rpm packages too? because i don't think that's going to happen for a small project that has many releases. [after writing this, i wonder what your problem is, given all the options that already exist with just the one tarball/zip]
I was mentioning Debian more in the context of packaging in general - I've gotten things more or less installed with Fedora and RHEL and Macports, but Debian is the only packager who has pleasantly surprised me with the integration or tidiness of some packaging decision. I haven't been pleasantly suprised by any Python packages yet, but then nor have I been unpleasantly surprised - I ask for a package, it installs, it's available to the next Python interpreter I start up. What problems have you seen?
Filenames that start with a period are hidden in Linux.
I am fairly happy with setup.py. If I would have to install dependencies manually then so be it, it just works(TM) . In your case (pure python) it should be fine, depending on the dependencies you have. If there are a lot of them (or a lot of uncommon) then a deb and rpm would be nice. But where to start? debs for Ubunut, Debian; rpm for Suse, Fedora, SEL, RHEL, etc .... 
&gt; Filenames that start with a period are hidden in Linux. Uh? Oh I get it, I wasn't clear enough. The name of the file and directory aren't `.egg-info` and `.egg`, those are just the extensions, the complete names are `{package.name}-{package.version}-py{python.version}.egg-info` and `{package.name}-{package.version}-py{python.version}.egg` (yes, it's a directory with an extension)
ok, i guess the complaint is with more complex packages (i have no dependencies). thanks.
zc.buildout even worse than easy_install First it is based heavily on easy_install so all the easy_install problems are back except that you don't even get the easy_install error message except if you think about using -v, and of course buildout has its own bugs too ! And it would have been a lot better to use a python file than an ini one. So I don't really like its principles either. I'm as wrboyce on this: jealous of ruby for this part. Their choices (rake, git based deployments ...) seems very reasonable to me.
It's all talk until someone actually does something. I'm personally not going to complain, because I'm unwilling to create something better, and what we already have (setuptools and zc.buildout in my case) mostly works for me. Without what exists now, we'd still be packaging every piece of software with every other piece of software. That sucked pretty hard too, at least if you were a *packager* of Python software that had dependencies.
Why the fuck would anyone downvote this?? If you have an answer to his question, then post it. If not, then move on. But please don't downvote the damn submission!
It is indeed all talk, since I too feel too lazy to look more deeply at all the solutions to be able to say exactly what we should be doing and do something about this. Still I hope in secret that a hero might come and save us all from darkness.
 import types def funcToMethod(func, instance, method_name=None): cls = instance.__class__ if type(instance) != types.TypeType else instance setattr(cls, \ method_name or func.__name__, \ types.MethodType(func, instance, cls)) That is possibly the most horrible Python code I've seen.. It even uses the ternary operator! If for some perverse reason you need to do this, you can just modify the class object thing: class WhyWouldYouEverDoThis: def __init__(self): self.youWouldNever = True def f1(self): if self.youWouldNever: print "hi" x = WhyWouldYouEverDoThis() def f2(self): if self.youWouldNever: print "bye" WhyWouldYouEverDoThis.f2 = f2 x.f1() # hi x.f2() # bye
Buildout isn't based on easy_install, it provides it's own module for installation. It's also pretty stable these days, I very rarely encounter any bugs. It's also much better than the Ruby stuff, I'll take a Buildout-based deployment over a Rake-based one any day. Look at how Rails has to provide facilities to manage Gem dependencies itself ... why would a framework do the job of build/install tool? (and you can do git-based deployements w/ Buildout ...) But if you like your configuration in Python code, there is always Paver. 
Yeah paver and metamake look nice. I'll have to try them out. When I say git based deployment I mean all is on a git server that you control, even the dependencies are copied on it. And all that is deployed on a server is in a branch. So that you can easily come back to an earlier version, or see if there were local modification made outside of the release process on the server, etc. And if the website of a dependency goes down it does not stop you from deploying as it does with buildout now ! Hum I'm not actually sure that they are doing that in ruby ... But that seems like the only logical way to me. (personaly I would use hg instead of git, but git is fine too) 
Context: http://www.reddit.com/r/programming/comments/8h94u/abstract_heresies_you_knew_id_say_something_part/c09aqmc I keep hearing this bandied about that Python is a 'small' language, and I feel like we're mistaking 'simple' and 'elegant' for small. Python is a pretty large language! The examples cited don't even make sense. Switch statements honestly are not at all cleaner than stringed elif's. The lack of private variables is not true, since Python does name mangling to support the same idea. And the lack of interfaces is moot now that ABC's are in Python 3.0. It supports both prototype and class based OO, a very large 'batteries included' standard library, lazy variables via generators, operator overloading, list comprehensions, and rather complex means of flow control through co-routines. Let's go ahead and throw in metaclasses, decorators and other bells and whistles. The reason we get away with all this is because each feature has been implemented in a thoughtful and coherent way. The language only SEEMS small, but is in fact, quite large and expressive. I don't buy the argument that extensions to the language automatically have to prove that we've been completely hobbled without them just because it might 'complicate' such a 'small' language. If they are implemented in a clean, Pythonic fashion, and are useful, what's the big deal?
If I recall correctly, he mentioned it in his keynote at PyCon 2009.
No.
Yeah I don't think python is small either, as a language. It has a good two dozen statements (counting both simple and compound ones) and quite a number of forms. It's not a large language either, though. And I *really* don't think a large standard library demonstrates that it's a large language, it merely shows that it's a sane, modern language. &gt; The lack of private variables is not true, since Python does name mangling to support the same idea. No. Name mangling was introduced to avoid namespace collision on inheritance, if you're using it to emulate private variables you're doing it wrong and should be beaten with the ugly stick. &gt; Let's go ahead and throw in metaclasses, decorators and other bells and whistles. Metaclasses and decorators aren't the mark of a large language either (though decorators are the mark of a language that is lacking, in that it doesn't support extensive anonymous functions)
Python grammar fits readably on a common page.
What problem do eggs solve?
I'm not equating large with bad, which is what I think most people are doing.
worked on an OSX box for a few months at one point. And this kind of problem drove me nuts. Rarely happens on linux. (Not an OSX vs linux thing, I get the feeling a lot of the package creators just dont test cross platform).
Aah OK, gotcha.
Oh god, I'd almost forgotten. Now the nightmares will come back.
You can still use Matplotlib and the 3D plotting patch.
where do you guys even get these egg files? I never use .egg files, just 'python setup.py install' - this always works. am i just not using the same packages as you?
I wasn't aware of a 3D plotting patch. Can you elaborate?
I know these are available on blip.tv, but I wanted to download them all to take around when I don't have service. Seems an excellent use of bit torrent.
Mh.. it does appear I was misinformed and we were talking about the [same thing](http://www.scipy.org/Cookbook/Matplotlib/mplot3D). Still, you can try [Mayavi's mlab module](http://code.enthought.com/projects/mayavi/docs/development/html/mayavi/mlab.html) and if it works for you please report back. [Mayavi Gallery](https://svn.enthought.com/enthought/wiki/Mayavi/Gallery) There's also an [AUR package](http://aur.archlinux.org/packages.php?ID=21647) for it.
PIDA is the first time my love for a piece of software has been reciprocated.
No it's not. I'm recoding something in Python that was in PHP, it's a 20kloc system and so far the only headache I've had is circular importing and the lack of a global namespace, not really something indicative of a small language.
Buildout has the "offline = true" setting which you can use to ensure that you are installing everything from a local archive. There are also tools for generating source archives. Finally with the find-links option you can point to other mirrors, so worst case if PyPI or some other package location is down you may be able to pull from elsewhere. I've managed a project where a branch of the project's build/install script was denoted to represent an installation (which I called an "instance branch" for lack of a better term). But this was in SVN and not git, so merging files between trunk and the instance branch was always a PITA (and where git would have been much better). This was using mcdonc's BuildIt, so it was more similar in spirit to a Rake-based system where you are simply running different tasks. Initially I was also keeping the dependencies in SVN, but this was a bioinformatic-based system, so a lot of the dependencies were pretty big files and it was really bogging SVN down, and switched to just storing the files in an archive location on the filesystem and pulling from there. Especially since most dependency files are already inherentily versioned (e.g. PostgreSQL-8.1.2.tar.gz already has the version number in the name so the only information you need in your instance branch is "postgresql = 8.1.2"). But really the only gripe with a BuildIt-based system was that you end up maintaining all of your recipe's yourself as part of a project's build. Buildout by design makes it very easy to re-use other people's install recipes, which I believe is unique to any build/install tool out there at the moment, and is a killer feature. 
They allow you to distribute Python code in a single, zipped file that contains binary data. This was to satisfy a use-case of the Chandler project, where you needed to distribute plugins to a large number of clients. Hence a single compressed file and asking these clients to perform a compile step is out of the question. The other more practical thing they solve is that they contain metadata about the Python code that they contain. So you can ask an egg what version it is, for example. Although the .egg-info directories was later added to Distutils (in Python 2.5) so that Distutils installed packages would also have metadata available. Eggs still contain a richer set of metadata however (namely the install_requires field, which will likely be in the next release of Python). 
you can download the videos from a site like this: http://www.videosnag.com/ you'll need the free flv player too... works great.
Too bad they didn't split out the videos into separate torrents.
Seems like there are no seeds... Is this going to fizzle out?
That's not even what stood out to me - why the hell would you blame a D in a data structures class on the language? That's absurd. If you understand the data structure, the language is mostly irrelevant. I'm not terribly bright, but even I understand binary trees just well enough that if I had to implement them tomorrow in some completely foreign language (ocaml? scheme?) I bet i could do it in a few hours max. This guy mostly just stands out to me as a complete moron.
Yah, but processes are an order of magnitude slower than threads. I really just want to be able to use real threads and it over with.
You can just select the ones you're interested in. I like this better, because this way I don't have to hunt around for all of them.
Well, at the time I took the class, I would've rather been more focused on understanding the actual data structures than have to worry about goofy pointer or memory errors. I'm definitely NOT saying working with the stuff at a lower level wasn't useful. In the long run it probably did me more good learning them that way, but I could see someone not doing well working with C or any other lower level language. But Python? Really?
&gt; Too bad they didn't split out the videos into separate torrents. That's built in BT, unless your client is a bit stupid, FWIW.
Ha.. :) You should have called me stupid :P
Nah, not for that, excluding part of a torrent from downloading isn't always obvious (though it's usually around the same area from one client to the next), and you have to know it's available. e.g. in uTorrent, you select a torrent, open the Files tab (nota: in the Detailed Info pane, F5 to open it), then right-click on a given file (within the torrent) and select "don't download). In transmission, you select your torrent, *Show Inspector* (⌘-I), open the Files tab (2nd from right) and uncheck the *DL* checkbox on the files (or folders) you don't want.
Ubigraph?
&gt;Changes in this release: * Added Critical Path Algorithm and Transitive Edge Identification; Woohoo! I'm the dev who is responsible for these 2 new algorithms. If anyone is willing to contribute some unit tests for these 2 algorithms I would be more than grateful! (get in [touch](http://groups.google.com/group/python-graph)) If you plan to use this lib, be sure to take a look at the [examples](http://code.google.com/p/python-graph/source/browse/#svn/trunk/examples) first.
For transmission, it asks you what files you want to download when you first add the torrent. Same checkbox interface as the Inspector.
Like a python snake depends on the dimension you are measuring. If small is easy to embed, it is. If you are referring to their small libraries or possibilities, it is not.
Syntax, compared to perl - yes. Disk size of core runtime and libraries, compared to java - yes. Runtime memory usage, compared to java - yes. Startup time, compared to java - yes. Note that for example you don't need all of the "batteries included" core libraries to deploy a python application. Something like py2exe will only pull in the ones you need. So yes, python can have a very small footprint relatively speaking.
No love for the Windows folks?
Well, I'm a Linux user (Deluge or ctorrent) and at least Deluge has this feature.
Thanks very much for the addition. Much appreciated :)
If you are using Python 2.5 you may have noticed that relative imports are preferred over absolute imports... That could cause the "circular import" you are experiencing. Later versions have fixed this. http://docs.python.org/whatsnew/2.5.html#pep-328-absolute-and-relative-imports As for lack of a global namespace, some people would consider that a feature. ;-)
It should be noted that the Egg installation format is not the same thing as Setuptools, `easy_install`, or `pkg_resources`. The Egg format is really a perfectly reasonable way of storing metadata, that is easy enough to query (not always efficient, though) and fully decentralized (based just on files and sys.path). People project all of their frustrations with the other tools onto "egg", but it's a fairly innocent part of the stack.
There's a lot of wonkyness in Gems too. I've yet to see a system without some pain points. Maybe we have more than our share, but it's not a solved problem. And Python does have an official repository, [PyPI](http://pypi.python.org/pypi).
It would be nice, but as far as I know no such thing exists that fits this use case. Developers need different package management tools than what operating systems call "packages". dpkg, rpm, msi, rpath, all have systems that are simply unworkable for developers. The idea of one version of a library on a system (or hacks like putting version numbers in the package) just doesn't work. As a result, in each language community packaging systems are created. It wouldn't *have* to be this way, but there isn't a clear community that is developer-oriented and language agnostic that can simultaneously get developer buy-in from these language-specific communities. Or, to the degree there is, those are tied to operating systems, and language communities are often dedicated to cross-platform development. And the OS developers don't seem to fully appreciate developer needs (why exactly I'm not sure).
I only see 729M of content among the current peers. If these are the blip.tv flvs, I wonder if downloading them from there and stuffing them in would work...
So, you'll need a third-party packager. An user of pip, I take it? At least it hides the idiocy of setuptools.
It was a good hack: the users would just []. The developers, on the other hand...
python-graph comes with a pack of useful and more widely used algorithms for directed, weighted and hyper graph implementations
&gt; An user of pip, I take it? Not yet, but I have trying it on my todo list, seems to be setuptools done less stupidly.
Oh hey, that worked (yay having the content hashes in the .torrent file...) I added two of them, now it's your turn (because the whole point of using the torrent is that I'm lazy and don't want to hammer on blip.tv myself) - stop your client, pick one of the zero-length entries at random, wget http://blip.tv/file/get/... the file (those names are the blip.tv download names...) and when that's done, restart the client, which should reverify and include your new content.)
&gt; And Python does have an official repository, PyPI. I didn't mean to imply it doesn't current have one, just that you'd want them to support this theoretical decent packaging system.
 help(staticmethod) help(classmethod)
I'll look into that, thanks. As for the namespaces, yes I consider it a feature. In the short run it's a problem but when I come back to the code in a few months it'll be much easier to trace it.
It wasn't good when the developers were using a C-based tracer to do code coverage, and coverage mysteriously stopped working when using TurboGears. To be fair, it *tried* to put the hook back, but there's no way to expose the C hook as it's not a real python function and so it only saw `None`. Also, I seriously just typed `C{None}`. Just a Python state of mind, I guess...
easy_install will often fetch .egg files from the cheeseshop repository. Its a bit easier to easy_install &lt;package&gt;, which will usually fetch and install dependancies as well, than to fetch it from source.
The basic concepts in computer science are *independent* of any language. You shouldn't need a computer to learn basic freshman recursion, trees, etc.
I like this one: http://martyalchin.com/2008/jan/10/simple-plugin-framework/ in that you don't have to do anything special to find plugins, the plugins handle their registration themselves minimizing the amount of configuration required.
&gt;The basic concepts in computer science are independent of any language. Right, but some tools are better at teaching/enforcing certain concepts than others. It's all just various levels of abstraction.
I'm trying to find an efficient (and simple) way to compute the FFT of the rows of a large 2D array using numpy. Sounds like the ideal job for the multiprocessing library since the rows are independent, but I'm not having much luck. I tried using Pool.map(), but it actually ran slower. Anyone have any experience with this sort of thing? (Incidentally the new versions of MATLAB's fft() command have multicore support built in)
R with snow or Rmpi? I don't know what the speed comparison would be with MATLAB, but the cost comparison is pretty good.
Maybe some numpy builtins are even releasing the GIL and you can use threads. You should possibly ask this question on the numpy mailinglist.
Mayavi's pretty nice, i.m.o. (I use vtk a fair amount, though, so I'm biased towards it.) Have you tried an "easy_install mayavi"? That should install mayavi without the rest of the enthought python distribution. 
Edit: Nevermind, clearly I didn't read your post quite right. Multiprocessing is working nicely for me, for whatever it's worth... If you're working with python 2.6, (I think it's been backported to 2.5, too...) try using the multiprocessing module in the standard library. I'm in the middle of using numpy and multiprocessing to do various geostats stuff (co-kriging) at the moment. I'm getting a close linear speedup with the number of cores. (Everything's completely independent... Embarrassingly parallel, etc.)
which, you're saying, networkx doesn't have, I assume?
Isn't there some option (you might have to rebuild scipy/numpy) to use FFTW, which has a multi-threaded implementation available?
IMO p-g comes w/ more *widely used* algorithms go [see](http://code.google.com/p/python-graph/source/browse/#svn/trunk/graph/algorithms) it for [yourself](http://networkx.lanl.gov/reference/algorithms.html) 
I'll second the use of Multiprocessing. I've not used it for FFT, but it's extremely easy to use and works quite well. If you're looking for the backport for 2.4/2.5, you can find that here: http://code.google.com/p/python-multiprocessing/ I don't really know too much about using threaded versions of libraries that NumPy relies upon. If that sort of behavior is "automatic" it may depend on how things like FFTW are compiled. If it's something exposed in the API provided by FFTW, I dunno, I would ask on one of the NumPy lists. People are pretty friendly over there :-)
You could always create a global_namespace module, add to it all the PHP globals (that aren't just global by accident, but actually need to be), and import all or some of it when needed.
The FFT routines in SciPy are wrappers to the Fortran libary FFTPack (I believe). I've found that it is actually quite fast. If you're looking for some multiprocessor goodness, you could take a look at [MPI Python](http://sourceforge.net/projects/pympi) or just stick in some good old-fashioned threading.
The parallel processing features of IPython are very easy to setup and use.
Can you elaborate? IPython probably isn't the solution though, since I'm not doing my calculations interactively.
&gt; I've found that it is actually quite fast. Yeah, I'm not complaining about its performance, I'd just like to take advantage of the multiple cores on my machines. &gt; you could take a look at MPI Python or just stick in some good old-fashioned threading. I'll take a look, thanks. What I was really looking for was something simple like multiprocessing's Pool.map(), which is basically just a multiprocess version of map(), so it's really easy to use. Unfortunately it seems to make numpy slower for me.
You shouldn't need multiple processes. The multiprocessing library exists when you want multiple pieces of python code to run simultaneously. That can't be done in one process because of the GIL. In this case, you are trying to run multiple pieces of Fortran code simultaneously, so there shouldn't be any locking issues.
IPython can use a cluster of engines (on one machine or over the net) to do parallel processing. It provides both an interactive and task-based interface. Also has functions for parallel-map over sequences and numpy arrays. Although it can be used interactively, it doesn't need to be. Create a cluster using ipcluster/ipcontroller/ipengine and then import the ipython module in your code. 
Python is... * Bigger than Scheme * Bigger than Lua * Similar to C? * Smaller than Ruby * Smaller than Java * Smaller than Common Lisp * Smaller than C++ Kind of small I suppose. Python 1.5 was quite small. But it's gotten better with growth.
I recently attempted using the multiprocessing library for a recursive algorithm, where the recursive case attempted to push the nect call out to a Pool. However, the child processes cant spawn new processes due to some module restrictions. Should I give up and go to an iterative or is their a reference implementation for this. The application spawns out web requests, and even a single level of multiprocessing yields speed benefits. Any thoughts?
so the setup is 1. simple nginx for static files 2. proxying to apache+mod_wsgi for django requests my interpretation is, this saves memory compared to just apache because the heavy mod_wsgi-endowed apache processes aren't wasted on static files. my question is, what would happen you could swap out #1 for a stripped-down apache? so run 2 different apaches on the same box. is nginx very different from stripped-down apache?
Why is this worth posting? It's been around for years and is the first result of a simple google search for "dns python".
Did anyone actually think they'd throw away their revenue stream? Anyway, we really need 'official' Qt4 py bindings anyway. 
This is a really bad outcome... Before I refrained from using PyQt due to licensing issues, now I'll have to add the uncertainty of a possible fork. It's a shame... [wxPython](http://www.wxpython.org)... you're still my *best friend*!
Does size matter? or are just the skills that make a difference? I like Python anyway!
We need official Qt bindings period. Good Java ones, and good Python ones (those are the languages I'm interested in, so I'm being selfish). I do not see how Qt Software wants Qt Everywhere, but C++ only. It will be interesting to hear what Qt Software has to say about this announcement. Qt Jambi is dieing quickly, and PyQt probably won't accelerate. At least the PyQt prices seem reasonable.
So PyQt is dual licensed; GPL or commercial?
&gt; Qt Jambi is dieing quickly, and PyQt probably won't accelerate. We don't know yet. Jambi 4.5 will be released when all the legal paperwork from the switch to LGPL will be done (according to Nokia employees, the packages are done). After this release, the project will be switched over to the community. This is then that we will have access not only to jambi but to the toolchain that permits to generate it. When this happen, we will know if Jambi can be healthy as community led project, until then we can only guess.
I think this is an issue Apple should be taking on, this would make the mac a very attractive programming platform. This could seal their tipping pojnt in the consumer PC market.
http://www.riverbankcomputing.co.uk/software/pyqt/license PyQt is available under the following licenses. * GNU General Public License v2 * GNU General Public License v3 * PyQt Commercial License PyQt, unlike Qt, is not available under the LGPL. 
A possible fork? How would a fork resolve the perceived issues that the GPL poses?
I'm still thrilled: I'd consider buying a commercial PyQt license for £350, but £5000 for the equivalent license for Qt itself was never an option. And now I don't even need to do that unless/until I finish something I want to sell: &gt; I have made one change to the PyQt commercial license to address a legitimate complaint. I have removed the restriction that prevented the re-licensing of GPL code. In other words if you have a successful GPL application and want to sell a commercial version then you can do. Excellent.
&gt; We don't know yet That's being extremely optimisitc. Take a look at their mailing list. Take a look at their IDE support. Take a look at their publicity. &gt; can be healthy as community led project I freely admit that I, nor anyone else knows the outcome for a fact. But lets be a bit realistic. There isn't a community behind it _now_. Where and why would a viable community form around it after? You have to be proficient in C++ and Java just to participate in maintenance, and you'd be doing it for free, so you'd have to like both languages. So you're relying on people who have all the following properties. * Like and know Java * Know and is willing to use, for free, C++ * Has time to spare * Likes Qt over the available Java alternatives * Is willing to do the work Now, given a large enough number, there will be people like that... but there were approximately 8 threads in the month of April on the Qt Jambi list. They have yet to release a 4.5 version, while the main version has already seen two or three releases. And all that assumes that the toolchain they use isn't some piss of crap that only their makers can user -- i've written crap code like that when it's just a matter of getting some output myself.
A cross platform toolkit would make their platform specifically more attractive how?
&gt; They have yet to release a 4.5 version, while the main version has already seen two or three releases. One version and one minor update (respectively 4.5 and 4.5.1). Jambi 4.5 *is* ready but cannot be released until legal approves. &gt; # Has time to spare The time required (for the current maintainers) is 1 day per week (there is two maintainers). They expect this to decrease a lot now that the toolchain is mature. They will stay on board for one year paid by Nokia (to support their current code) and intend to give some free time after. &gt; And all that assumes that the toolchain they use isn't some piss of crap that only their makers can use According to the maintainers, it's pretty much done and all that's left to do these days is to add to xml config files. Everything else is automated. Of course, Qt might change in unexpected ways and require more C++ code to be written but it looks doable for a few willing individuals. I don't have my hopes too high though and I picked up C++ last weeks. I prefer Python but that binding doesn't look it's going anywhere and most of the pain in doing a GUI app is doing the GUI part. I'm very pleasantly surprised, they managed to make C++ at least as bearable as Java. They do it in a twofold way, first they reimplemented pretty much all of the C++ standard library in a much, much friendlier way. No need to mess with C++ arrays for instance, use a QList. They also added much much more (check Qt Concurrent for instance). Second, there's the moc (meta-object compiler). Basically they extended C++ itself so it sucks less but the magic is in the toolchain. When you compile your code, the moc rewrites parts of it to enable the extensions (so a plain old compiler can compile it). For instance, if you were wondering how they could do the signals and slots things where every signal can be linked to every slot with a compatible signature, this is how. In Java you'd have to use the observer pattern with the observable having to know what interface the observers implement. Not so in Qt, you plug whatever you want together and the moc makes it work. It also simplify memory management. All QObject can have a parent and children. If you delete a QObject, all its children will be recursively deleted and its parent will be notified it's not there anymore. This is also due to the moc. And finally, their IDE is seriously kick-ass. I thought I would never touch C++ again, even with a 10 feet pole but I'm glad I did. Give it a chance, Qt C++ is pretty okay given what Qt gives you.
Can't be a fork. You either pay for commercial or you get GPLed. GPLed code can't be downgraded to LGPL. Beside, he keeps his toolchain to analyze and generate bindings secret and proprietary so if we have to rewrite that, it makes no difference to start from scratch.
&gt; They will stay on board for one year paid by Nokia (to support their current code) and intend to give some free time after So I'm guessing that the most likely scenario is that things don't get worse, but they don't get better? If the Jambi API is anything like the Python one, it's as close to C++ as allowable, making little to no use of language features. &gt; I don't have my hopes too high though and I picked up C++ last weeks Yah, I know C++... but I really prefer not to use it. It makes programming feel too much like work. &gt; I prefer Python but that binding doesn't look it's going anywhere It's not going LGPL that's for sure. The author has promised more Pythoninc bindings though... when exactly, no one knows. &gt; And finally, their IDE is seriously kick-ass So I hear/read. I'm about ready to pay for a version that supports Python. &gt; Give it a chance, Qt C++ is pretty okay given what Qt gives you "Qt... so good, you'll use C++" Really though, how is having mature language bindings _not_ part of getting "Qt Everywhere"? They should have a Qt Redistribute shipping at the OEM level, parallel installable and updateable like Java itself is. But I see your points. If I have to choose between Java/Swing and C++/Qt... I think I'll choose C++.
&gt; So I'm guessing that the most likely scenario is that things don't get worse, but they don't get better? If the Jambi API is anything like the Python one, it's as close to C++ as allowable, making little to no use of language features. Actually, they did a great job of making it Java-friendly. For instance, you use native java threads and not QThreads. Qt collections are mapped to Java collections so you can pass regular Java collections to Qt objects. The api documentation is done with javadoc. This is much higher quality binding than PyQt. &gt; Yah, I know C++... but I really prefer not to use it. It makes programming feel too much like work. Then you aren't using the C++ parts Trolltech rewrote :) &gt; It's not going LGPL that's for sure. The author has promised more Pythoninc bindings though... when exactly, no one knows. The unpythonicity is something that bugs me but so is that the binding is fragile. The latest app I wrote worked perfectly with PyQt until I decided to package it as an exe. I tried all the available software, tried everything the FAQs and troubleshooting sections said about enabling PyQt and only py_installer worked. Unfortunately, it broke parts of the program like QImage not being able to load JPEG files anymore (PNG still works fine). This is the first thing that made me consider trying out Qt with C++. If a solid open source Qt binding for Python emerge, I'll consider going back though. With the current pseudo-open source solution (is it really open source if we can't access the tools that let him generate the bindings?) that's not of terribly high quality, I'll pass.
&gt; and only py_installer worked Been there, I got py2exe to work better than py_installer however. &gt; that's not of terribly high quality, I'll pass. Which is really unfortunate. As I like both Python and Qt. Sucks for me I guess.
&gt; Which is really unfortunate. As I like both Python and Qt. Sucks for me I guess. Python and Qt both have tons of fans. We'll eventually get great bindings. But yeah, it currently sucks.
I suppose that it would be in enabling them to run the same apps other platforms run. Not sure either it would be a good move for them. I hope a distro sponsors it. I don't think PyQt qualifies as free software (since you can't fork it) and most distros rely both Python and Qt.
It's GPLv3. What else do you want? Just write fucking GPLv3 software and shut up.
For far too many tasks, the fact that you have to switch processes with map() completely kills a lot of the benefit you gain from the parallelization. Python needs threads.
&gt; I don't think PyQt qualifies as free software (since you can't fork it) You can most certainly fork the GPL PyQt. It's just that the fork would have to be licensed under the GPL as well.
"Beside, he keeps his toolchain to analyze and generate bindings secret and proprietary " Even so, PyQT is still GPL...ed?
Oh please... The commercial license is £350. You can even develop under the GPL version and only buy a commercial license when you sell something.
No, to really fork PyQt you'd need metasip, the tool that is used to build the PyQt binding definitions. This is closed-source and proprietary. The GPL version of PyQt is really just a product of the metasip build process. So no, you can't fork PyQt. 
we have no win32 developer to port and can't be arsed to do that
AFAIK: you need to buy the license if you sell the software, but if you sell services with free software than you are still clear
I had just started to look at networkx recently and what I liked was the rich set of [generators](http://networkx.lanl.gov/reference/generators.html) (especially Small World graphs for my purposes). Those seem not to be represented that well in p-g. I'm no expert on the algorithm part, though (not yet, hopefully). Maybe the packages do have differing strengths. (Then it might be interesting if it is easy to map graphs between them) 
Yea, because *so many applications* are written in QT. Anyway, why would they encourage people to ignore Cocoa and use a foreign toolkit?
You can always sell GPL'd software. It's written in python, an inherently source-based language anyway, you're probably distributing the source anyway!
GPLv3 software doesn't feed hungry mouths.
You're spreading FUD
As a developer, I do not get paid for writing GPL software, unless I can work an indirect income stream. That is just fact. Most GPL software is written by someone who lives off of other work. The exception is a company that is large enough that it makes financial sense to continue development of a GPL project for use in house as well as helping the community. This is rare. I use Ubuntu at home. I love it. I support GPL software. But I make my living programming closed source software for a company. Just the fact of life. If I decided on a software product that I might be able to replace my job with, it couldn't be GPL'ed. Otherwise, where does my house payment and grocery bill come from?
&gt; Yea, because so many applications are written in QT. Many Linux apps. Very few Mac one. That's the point, they'd have access to all those apps. &gt; Anyway, why would they encourage people to ignore Cocoa and use a foreign toolkit? From version 4.5, Qt uses Cocoa. Anyway, that's the point of Joshua above, I believe. However, I don't think it's a good idea for Apple because Mac users wouldn't like our apps. Mac users don't like anything. They are never satisfied unless Steve Jobs tells them they are.
Qt is too large of a toolkit to create bindings by hand, you need to create a binding generator for it. A tool that read the C++ source and make a Python bridge. Everytime a new version of Qt comes out, you run this software and bam, you have a new version of PyQt. This software is private. The bindings it generates are GPLed. So if we are unhappy with PyQt, we cannot fork and say "Well, we will maintain our own version from now on" because we have nothing to maintain. So the code you get is GPLed but PyQt is impossible to fork so I don't believe it qualifies as open source. However, Qt will release the tools to generate the bindings for Java any minute now (as soon as they cleared some legal requirement) and there is probably lots of insight on how to analyse their source code in it. Maybe we could fork that.
Impressed! I'm going to show your code to my college professor who is a huge python-skeptic and actually thinks python is a *narrow-purpose* language ...
Oh, man, all those... Killer linux apps... Ok, I give up. Amarok? That's about the only linux app I would ever really want on my mac.... Anyway, Qt does not "use cocoa", just look at the toolbars on windows: [here's a screenshot](http://chaos.troll.no/%7Etavestbo/webkit/domapi/images/designer-screenshot-small.png). 
&gt; Anyway, Qt does not "use cocoa" You apparently missed the "from version 4.5" part. It's a highlight of the latest release.
&gt; As a developer, I do not get paid for writing GPL software Other do. Saying that "GPLv3 software doesn't feed hungry mouth" is factually incorrect. There people who make money off of it, and there are no restrictions imposed by the license which prevent its sale.
Never heard of Opera? Of course as far as I know, all the linux QT apps like Opera, Skype, Google Earth, VirtualBox, etc. all work on Mac.
I don't use any of those. ...but I see where you're coming from. If you notice, all of the programs that are actually popular (Skype, Google Earth, Virtual Box) have hacks to *work around QT and have native code* so that it doesn't look like shit.
I found the [Werkzeug tutorial](http://werkzeug.pocoo.org/documentation/dev/tutorial.html) to be pretty good, as it starts out with a fairly minimal WSGI app and then extends it with an object-relational mapper, some dispatch and a templating language.
It's not really a hack. It's a feature called [QT Style Sheets](http://doc.trolltech.com/4.3/stylesheet.html).
Oh rly? I have used Python to: do protocol analysis of serial communications; download waveforms from oscilloscopes; inspect floating point formats; correctly print floating point numbers in decimal; ASK audio decoding; ASK audio encoding; image manipulation; image generation; network administration GUIs; extend source code control systems; patch flash HEX files; incrementally compute CRCs; compute the global average temperature anomaly; process EXIF data and correct my picture's timestamps... and lots lots more. It's a fully general purpose language. Web programming? Yeah, it does that too. So I'm told.
Dear sir, where can I find some examples of your extensive work?
It does feed mine. Stop relying on imaginary property. Charge for the service of performing a job, not for the information derived from it. In other words, offer software as a service. That's what I do for a living, BTW. Either way, why should I care? OMG! There's something in life people can't make money with! What's the big deal? If you want to make money with imaginary property, go find something else.
&gt; As a developer, I do not get paid for writing GPL software As a developer, I do. My employer pays me for the service of creating or adapting/improving and maintaining free software. In the near future, we'll also charge for this service to others. BTW, we aren't a large company; we're mid-size at best (300 people in 11 countries). &gt; If I decided on a software product that I might be able to replace my job with, it couldn't be GPL'ed. That's because you haven't found an employer that understands software, especially software for businesses, is better provided as a service. Give them some time, I guess. Either way, PyQt requires you to write free software with it. This is great because it promotes free software and helps undermine imaginary property. If you don't like it, don't use PyQt. Just don't expect others to jump into the imaginary property mafia bandwagon just because you want to make some money with it. If you want money with imaginary property, write a Qt extension for Python yourself.
Why has parent been downvoted? What Pemboa said is *factual*. It's on topic, non-redundant, and appropriate. It's also understandable despite a few unimportant mistakes. There's not a single thing you may say against Pemboa's post to justify downvoting. Therefore, to those who downvoted him, all I can say is: stop being fanboys, or move to microsoft.com/MSDN/whatever they have, where you'll find fellow idiots.
Got it up to 93%, one of the files seems missing from blip.tv, so we've got close to full coverage even without any seeds...
I'm going to get downvoted into oblivion by a horde of fanboys for this, but Django kinda sucks. The APIs are poorly designed, the templating language is utterly woeful, the ORM is ham-fisted and incomplete. Nowadays, I'm building my projects using CherryPy - unlike Django, it doesn't do a half-arsed job at trying to be everything, so you're free to use a good templating language and SQLAlchemy. The price you pay for this is that you don't get the automatic interface creation you get with Django - but since that sucks too, it's a small loss. ;)
Have you checked out the [CGI module](http://docs.python.org/library/cgi.html) yet?
i'll throw a vote in for pylons, it's slightly higher level than wsgi, but you can peel it back and get to the wsgi stuff when you need to. 
i gave you a + because I agree. 
thirded because I had come across this link and lost it, you are a savior... thanks
Just came across this helpful [article](http://www.ddj.com/184412536).
In all fairness, you can replace the templating system with your own (Jinja comes to mind) as well as use SQLAlchemy if you don't like the built-in ORM - it all works. Do you have any examples or comparisons as to why the API is poorlyl designed? From where I'm standing it looks pretty thourough and well-designed and even better, well documented.
I guess I lost marks for grammar.
If you mean basic basic, you should really read Ian Bicking excellent do it yourself tutorial: http://pythonpaste.org/do-it-yourself-framework.html that will show you some of the stuff that all of these frameworks have to do under the hood. Then look at web.py, which is really minimal. Then use Django, which is the unofficial standard Python web framework. 
Looks to me WSGI is as basic as it gets in python huh? Thank you for your advice
Kinda old ... don't you think? But it is still worth a look. thx!
No ... but will do!
This is going to keep me busy for days to come. Thank you!
Same here. When I first started with it, I liked the structure. Then I learned about the WSGI protocol (which I definitely recommend reading up on first). As Pylons has grown and developed, it seems to have refined itself more and more into a series of nested WSGI applications, which have then been forked off / merged with other similar WSGI layers (beaker, webob, ..), so that currently, once you understand WSGI, there's very little thats "pylons", the skeleton project is mostly just a carefully chosen set of wsgi applications. I suspect the goal of Pylons is to eventually not exist anymore, but in a good way :) Not that there isn't anything in the "pylons" package, but most of the peices come apart really nicely into some smaller wsgi apps that just happen to work well together. For getting down and truly customizing your web framework to use the ORM, template langauge, web chain, that *you* want to use, I'd said Pylons is the way to go. Not so much instant functionality out of the box as django, but way more flexible in the long run. But it's all down to WSGI. Learn that, then look at skeleton/config/middleware.py in your new pylons project. 
Patches are welcome, as always. Constructive explanations of criticism, too.
Maybe not chain... itertools.chain is a completely separate yet useful thing. How about just "tail" ?
It totally depends on the industry. I work on personal lines underwriting systems for an insurance company. The difference between systems are what differentiate companies. There is no way in hell this gets GLP'ed.
I didn't down vote him. I understand some people do make money from it. But I don't begrudge someone who chooses a more "commercial" method of making money.
The Django ORM is really starting to bother me. It was the first framework I tried, and even I can see that it's far from perfect. I actually miss constructing my own SQL queries... I had so much control back then, now I can't even do a SELECT FOR UPDATE without some hacks :( I think I am going to have to change frameworks if I ever want to get my first python based web project finished.
http://www.needlol.com/ Wrote it for $5.
That's because they aren't focusing it properly. Software for businesses almost always needs to be adapted, and the more complex this software and the problem domain is, the more complex and expensive these adaptions become. A shift from competition about selling software to collaboration in GPL software which *will* get better than any isolated, closed source project ever was, selling the service of improving, adapting, deploying, supporting and maintaining the software as needed, merging patches, making it just exactly like the customer wants it to be would make GPLv3 software profitable. And of course, there will always be customers who want a significantly different system and don't want to adapt themselves to existing software, or customers who want modules for completely different things, which are an opportunity to work on all-new software you'll get paid for regardless of which licence you distribute it under. In fact, the GPLv3 here counts in your favour, as you can sell it as a feature: we are Small Developer Number 415, but we won't lock you in then go out of business because what we're selling you is GPLv3 source, so why pay a million to Mr. Big Shot Slick Suit Enterprise Turnkey Business XML Solution 2.0 and get locked in with their horrible enterprise software when you can pay a quarter to us and get exactly what you need?
Most of those were either commercial projects that are not published, or personal projects that are too crappy to publish. However: [flopri](http://sourceforge.net/project/showfiles.php?group_id=200034): floating point printing code; [PyPNG](http://code.google.com/p/pypng/) does image manipulation and image generation (see [pipdither](http://code.google.com/p/pypng/source/browse/trunk/code/pipdither) and [texttopng](http://code.google.com/p/pypng/source/browse/trunk/code/texttopng)); [p4dti](http://www.ravenbrook.com/project/p4dti/) integrate Bugzilla and Perforce, I have worked on bits of it (as well as creating source code control tools for my personal use that are too crappy to publish); [Clear Climate Code](http://clearclimatecode.org/) computes the global historical temperature anomaly. It's a conversion from Fortran to Python. Incremental CRC computation and the ASK audio stuff may appear on my blog one day.
Have you played around with different chunksizes? (see the docs)
&gt; Looks to me WSGI is as basic as it gets in python huh? No, you could also go with raw CGI scripts, but that would be kinda dumb: WSGI is intended to be the lowest common denominator between the web and python code, as described in the [PEP 333](http://www.python.org/dev/peps/pep-0333/) &gt; Python currently boasts a wide variety of web application frameworks, such as Zope, Quixote, Webware, SkunkWeb, PSO, and Twisted Web -- to name just a few [1]. This wide variety of choices can be a problem for new Python users, because generally speaking, their choice of web framework will limit their choice of usable web servers, and vice versa. &gt; By contrast, although Java has just as many web application frameworks available, Java's "servlet" API makes it possible for applications written with any Java web application framework to run in any web server that supports the servlet API. &gt; The availability and widespread use of such an API in web servers for Python -- whether those servers are written in Python (e.g. Medusa), embed Python (e.g. mod_python), or invoke Python via a gateway protocol (e.g. CGI, FastCGI, etc.) -- would separate choice of framework from choice of web server, freeing users to choose a pairing that suits them, while freeing framework and server developers to focus on their preferred area of specialization. &gt; This PEP, therefore, proposes a simple and universal interface between web servers and web applications or frameworks: the Python Web Server Gateway Interface (WSGI). But since fcgi and mod_python now have WSGI adapters and the best deployment option on apache is mod_wsgi, yes WSGI should be as low as you should want to get. Also note that other systems have wsgi support e.g. the Passenger rails apache module has experimental wsgi support, which works quite well in practice.
&gt; Nowadays, I'm building my projects using CherryPy - unlike Django, it doesn't do a half-arsed job at trying to be everything, so you're free to use a good templating language and SQLAlchemy. While losing the ORM is more problematic (though not quite *hard*), using something other than django's template engine is pretty trivial to say the least. So I don't quite see your problem here.
Here are some highlights. * Ordered dicts. (Ordered by insertion time. NOT sorted dicts.) * Easier to use comma formating of numbers: &gt;&gt;&gt; format(1234567, ',d') '1,234,567' * Simplifying the new `.format` system a little: &gt;&gt;&gt; 'Sir {} of {}'.format('Gallahad', 'Camelot') 'Sir Gallahad of Camelot' * `repr(1.1)` is now `"1.1"` instead of some crazy huge decimal. * `collections.Counter` makes counting words in a Python as simple as `Counter(text.split())`. * `importlib`. * Faster IO. * More.
&gt; I had so much control back then, now I can't even do a SELECT FOR UPDATE without some hacks :( What hacks? An import and a method call? from django.db import connection, transaction cursor = connection.cursor() # do operations on perfectly normal DBAPI 2.0 cursor here ? But yes, clearly if you like raw SQL Django most definitely isn't for you. However that kind of epiphanies should be part of the tool discovery phase.
CherryPy is fantastic. I combine it with the [Cheetah](http://www.cheetahtemplate.org/) templating system and it's just ridiculously easy to write really nice web apps.
&gt; `collections.Counter` makes counting words in a Python as simple as `Counter(text.split())`. Seems like adding items one at a time has to be done manually (basically using `Counter` as a `defaultdict(int)`), but otherwise it's a pretty damn nice collection. This thing is all kinds of awesome.
... when your app does next to nothing.
If you are looking for an alternative object-relational mapper, [SQLAlchemy](http://www.sqlalchemy.org) can do what you want either by setting a locking mode on your query object (`with_lockmode('update')`) or by giving `for_update=True` to select(). For example: task = session.query(QueueTask).filter_by(state=u'pending').with_lockmode('update').first() task.state = u'running' session.commit()
Yay, two decades, hundred implementations and thousand comp.lang.python discussions later Python gets an ordered dict!
Agreed there, it will make histogramming very very easy... Not that it's hard to write, but it's very convenient to have it in a library.
They aren't focusing customized specific algorithms for underwriting? Did you actually read what I do or just follow up with a GPL happy response. It is all good to say develop a GPL system that everyone plugs their rules into. However, why would someone totally reinvent the wheel, just to make it available to others, then the current closed system works fine? That is stupid business sense in a business environment that is forced to run more efficient or die.
OrderedDicts are particularly useful for implementing caches this is a very nice addition.
I asked the Jambi maintainers if we could use the Jambi generator as a base to write bindings to other languages and here's the answer: &gt; Of the Generator code, you could basically use the C++ parser, the XML parser and the type graph which binds the C++ classes to the definitions in the XML. You could also use the part of the XML type system which is labeled "common", because this does not contain any Java specifics. The part of the type system labeled "java" will have to be ported, but the information contained in these files should be very useful when binding Qt to any language, as many of the issues will most likely be relevant everywhere. &gt; The actual generator classes (in our case they create the JNI binding layer and Java layer based on the result of parsing and matching) will have to be written from scratch, as well as binding code similar to that in the qtjambi/ directory of the Qt Jambi source package. Trying to generalize this part does not make sense when the aim is to provide as efficient code as possible. &gt; So bottom line: The generator and type system are modularized specifically to make it possible to use part of the same logic to make bindings for other languages, but expect to do some manual labour :-) &gt; -- Eskil I think it's very good news. Even if Jambi doesn't take off as a community project, it could be a great base for new Python bindings.
Yeah, that's one class I've written at least three times independently.
Interesting news.
I know I'm going to get downmoded for this, but this is one of the reason I like python, a lot thought is put into it.
&gt; Seems like adding items one at a time has to be done manually You could do new_counter = Counter(incoming_data_sequence) old_counter.update(new_counter)
A few years ago I attended to a comp.lang.python discussion about `odict` and its inclusion in the standard library. The idea was considered either as being "too trivial" for inclusion or the participants endless quibbled about semantical details because it should be all for everyone. Maybe sometimes it really needs a "designer" who makes a decision?
I think you missed my point.
Exactly! Not to mention that they have no support for firewalling... Piss someone off and get a DoS attack? Say goodbye to your quota!
For Django, GAE is a really bad idea. The couple bucks you save on hosting is not enough to justify using a bastardized ORM. When Google offers to merge their ORM with the Django trunk, I will reverse this position.
That ain't never gonna happen son.
Actually only a couple months into learning Python, and have been playing with Django mostly. I just decided to move my project over to Pylons because I'm not happy with Django. Apart from the requirement for a seperate user profile class I thought the Django's user auth was excellent, so if I was to do my own user auth I would want something similar. ie.. every visitor is a User class, whether anonymous or not, can check if a user has authenticated with a single method It seems like I could do it myself without too much effort, and that it would more tightly integrate with my other code and give me much more control than repoze etc.. And I don't much like the idea of an application intercepting HTTP 401 responses and redirecting the user itself. Am I a naive Python noob for thiniking I would benefit from doing my own user auth? Please help 
I used AuthKit in a recent project and it works great. The documentation to get it set up and working with SQLAlchemy was a bit of a pain though, but afterwards it has worked great for me.
I roll my own. I use beaker's CookieSession, don't deal with external middleware (it's usually handled in a `__before__()` method) and does just what it needs to do for the application at hand (which is always something different) . There's also usually some decorators that check authenticated status and permissions, bounce to a login page, etc. Call this "bag of tricks" development if you will. Problems that are small and partially but not entirely redundant respond well to a set of functions that you connect together as needed for each use (kind of like Pylons itself).
Yep, didn't help.
I'm not sure how well numpy plays with threads, but I might have to give them a try.
I tried django first, and the authorization stuff is what has so far driven me off pylons, I've heard conflicting opinions on what's preferred (In that apparently the docs maintainer prefers something that much of the rest of the community does not) and while it sure is more flexible than django, the lack of direction for very basic processes is very frustrating :-\
Authkit is probably the best first solution as all the weird kinks have been worked out. I've only looked around on how to use repoze with Pylons, but the impression I got was that it might be easier to implement in the controllers but more of a pain to get initially working in the framework.
I rolled my own. AuthKit is a bit much for simple auth setups. That being said, authentication/authorization is a solved problem and unless you know what you're doing you'll almost certainly end up with something that isn't as secure. 
time is changing. several years ago, there is not enough user case for odict, and if there is a odict in standard library at that time. the newbie(me, for example) will be tempted to use it inappropriately instead of dict and decrease the overall system performance. Now, there is a lot Python Web Framework, odict is an appropriate choice for display several item pair on a web page. Just my two cents. 
It may (or may not) help to read reddit's [code](http://code.reddit.com/). 
I’m not a complete beginner, but close enough. I’ve done basic web programming with ASP and PHP, I took a UNIX shell scripting class years ago and do some basic windows scripting for my job. I wanted to dive into something more complex and after downloading python and just poking around in it I decided this is where I’ll start, my brain seems to grasp what is going on so why not. I’ve been going through the included documentation and it is helpful and I understand most of it. Can you guys point me to some good online python communities where people will tolerate my total lack of programming knowledge? Also any suggestions on good beginning books I should pick up? Any other general advice for me?
Start with the official Python tutorial, continue with the free book Dive Into Python.
I downloaded that yesterday it's waiting for me to open at home, thanks!
[ShowmeDo](http://showmedo.com/) has a lot of videos to introduce you to Python and basic ui.
Python is the best first language. I grew up learning BASIC by copying the source code examples of games from different listings, but when I look around today, there aren't that many of them in modern languages. These books just went over syntax and a reference for functions, but didn't stress the practical and fun applications of programming. So I wrote a book and put it online for free under a Creative Commons license. The book is "Invent Your Own Computer Games with Python" and is available online here: http://pythonbook.coffeeghost.net Each chapter of the book starts with the complete source code of a new game, and teaches the programming concepts from the examples. I think having these full examples is a great way to learn programming, especially since Python has such a gentle learning curve while remaining a Serious Programming Language. (Unlike Scratch or Logo or various "game creation" kits.)
I used to write my own, but repoze.who and repoze.what are not that difficult to work with, Essentially you write your providers for user and group/permissions to their spec which is largely copy/paste and you are good to go. Nothing wrong with writing your own either. 
I recommend starting with IBM's [Discover Python](http://www.ibm.com/developerworks/views/opensource/libraryview.jsp?search_by=discover+python) series. It's nine articles that will get you up and hacking in no time. After that, I recommend reading Dive Into Python.
Thank you for the suggestion, I just downloaded it.
Thank you I will take a peek at it.
I believe one important thing to have is a project. If you don't put what you read to *real* practice (not just exercises), you won't learn. It could be a game, it could be a small utility for your day-to-day work, just decide on something *simple*, and start to work on it. And don't forget: keep it simple. Also, you could start working on the [Python Challenge](http://www.pythonchallenge.com/). It starts very easy.
ride the snake
I’ve quickly skimmed some chapters and found you using range() instead of the faster xrange(). This goes especially for large ranges of numbers :) In Python 3.0 range() has been removed and xrange() was renamed to range().
via: http://simonwillison.net/2009/May/8/nose/
I recommend you take a look at Alan Gauld's ["Learning to Program"](http://www.freenetpages.co.uk/hp/alan.gauld/). It's centered around Python, but also contains examples in Javascript and VBscript for comparison, and covers a good range of stuff - from basic data types, to regular expressions, object orientation and GUI programming. I think the best idea would be to spend a day going through the first couple of chapters and playing with the examples in the interpreter, and then maybe trying to write a small program (something like a simple bulk file renamer). I'd also like to mention [Project Euler](http://projecteuler.net/) - "a series of challenging mathematical/computer programming problems" that mostly require writing a program to solve. If you try going through a few with what you know, and when you come to a problem Google around for answers, you should build up your knowledge pretty quickly.
I really strived for two things with the book: providing concrete, complete examples and conceptual simplicity. Covering the difference between range() and xrange() would have turned the discussion towards iterators, for loops and iterators, and the difference between lists and iterators, etc. I wanted to keep it simple because the book is aimed at young adults and nonprogrammers. For most simple programs, the range()/xrange() difference isn't significant. If you are already a programmer and want to learn Python, the book is handy for the examples, but you'd be better off learning with Dive Into Python. Also, the book doesn't cover OOP and file i/o, also for reasons of simplicity. I added Pygame chapters at the end only after a lot of consideration. I wanted to make learning to program as streamlined as possible, so that the reader becomes interested in pursuing programming further. :)
I agree that projects are the best way to learn-by-doing. The Python book I wrote provides complete game projects that you can follow along with, which gives you a general idea of what code looks like for your own games. The Python Challenge is nice, but it doesn't teach you programming and also requires you to know the standard library somewhat well. And those challenges are somewhat abstract, as oppose to fun little game projects. Python Challenge is great once you are familiar with Python, but I'm not sure it's so good forabsolute beginner programmers. (I plug my book a lot in this subreddit, but it is relevant to the topic of learning to program with Python and the book itself is free under a Creative Commons license, so no one seems to have complained so far. :) ) http://pythonbook.coffeeghost.net 
Scan me!
&gt; Also, you could start working on the Python Challenge. It starts very easy. 1990's knocked. It wants its obsolete web design back.
http://en.wikipedia.org/wiki/Code_coverage
I'd recommend you to first read this article "10 Python pitfalls" http://zephyrfalcon.org/labs/python_pitfalls.html 
I certainly don't mind. I've taught my little brother python using it after he got confused with diveintopython's complexity (complex for a little guy that is). Thanks so much for it :) Hopefully you'll check out http://inkblotter.org once we're up and running (Inspired by Github, but specifically for open license books).
The only problem I see with learning Python first is that any other language you learn will seem clunky and cumbersome by comparison. You need to suffer like the rest of us! 
You could also help me with [this](http://www.reddit.com/r/ideasfortheadmins/comments/8inwh/why_did_reddit_get_rid_of_sorting_options_for/c09f4cv). I'm working on a script to download all reddit comments from a user and to sort them and stuff. I've never used python before writing this, but I have previous programming experience.
Preserving insertion order has nothing to do with some webframeworks that suddenly became popular. Even though you might not believe it but C-structs are odicts as well although with some restrictions on the keys and they precede Google App Engine and even Django.
Yeah, I guess I am. Rereading your comment it seems like your complaint is that the interface for adding just one key is `counter[key] += 1` instead of `counter.increment(key)` or something. I guess that's a fair complaint, but I think in a lot of realistic scenarios, there's no reason not to just do a whole sequence at once with `Counter(sequence)`. 
That pun was unintentional, right? Otherwise...brilliant. -r
I got my hallucination from http://www.gossamer-threads.com/lists/python/dev/656556 post 6, (write by guido) I've shamelessly copied the related paragraph here ############################################################################ &gt; * Armin Ronacher wrote: &gt; &gt;&gt; Some reasons why ordered dicts are a useful feature: &gt;&gt; &gt;&gt; - in XML/HTML processing it's often desired to keep the attributes of &gt;&gt; an tag ordered during processing. So that input ordering is the &gt;&gt; same as the output ordering. &gt;&gt; &gt;&gt; - Form data transmitted via HTTP is usually ordered by the position &gt;&gt; of the input/textarea/select field in the HTML document. That &gt;&gt; information is currently lost in most Python web applications / &gt;&gt; frameworks. &gt;&gt; &gt;&gt; - Eaiser transition of code from Ruby/PHP which have sorted &gt;&gt; associative arrays / hashmaps. &gt;&gt; &gt;&gt; - Having an ordered dict in the standard library would allow other &gt;&gt; libraries support them. For example a PHP serializer could return &gt;&gt; odicts rather then dicts which drops the ordering information. &gt;&gt; XML libraries such as etree could add support for it when creating &gt;&gt; elements or return attribute dicts. &gt; &gt; I find this collection of cases pretty weak as an argument for implementing &gt; that in the stdlib. A lot of special purpose types would fit into such &gt; reasoning, but do you want to have all of them maintained here? No, but an ordered dict happens to be a *very* common thing to need, for a variety of reasons. So I'm +0.5 on adding this to the collections module. However someone needs to contribute working code. It would also be useful to verify that it actually fulfills the needs of some actual use case. Perhaps looking at how Django uses its version would be helpful. -- --Guido van Rossum
I concur with AlSweigart's 'best' rating, in that I was brought up on BASIC on an 8 bit machine and thus am fundamentally broken. I found Python to be easy to parse, well documented on the web, and it allowed me be to become productive (if dangerous) quickly. Good choice. Also, my shot at recommending a resource: http://www.greenteapress.com/thinkpython/thinkCSpy/html/ Which will probably feel a little novice for you, but I often find is useful for syntax reference. -R
if someone writes a good Gorilla clone in python, I'd be forever thankful.
Thank you for this link! This is a great help for me filling in holes on how to do basic things! Perfect start for me.
&gt; my brain seems to grasp what is going on That's the best thing about Python.
I'd agree with this. I started on a project at work in C that required interfacing with some specialized hardware over telnet. I'm not a programmer by trade, but it's a hobby of sorts. I took a look at Python when the other systems person at my work mentioned it and managed to bang the project out in about a week, having never touched Python before. I think it's a great place to start, it will instill good habits in you from the get go. Find something you need to do, and do it with Python.
Nifty. Nose is an awesome tool. Nice to see that it's still improving. These are some clever, well-considered improvements.
You can also take a look at my book: Game Programming - the L Line http://www.aharrisbooks.net/pythonGame It's a commercial book (available in most bookstores) but in the spirit of open source, I have complete notes and videos of my course using the book (with almost everything from the book) available on my web site whether you use the book or not. I'm also happy to answer any questions on Python or beginning programming in my forum http://www.aharrisbooks.net Python is a great first language. You should definitely check out the many excellent references that have been suggested here. If you want to go farther, please look into my book.
Thanks. I begin to suspect leading Python programmers have a pretty narrow focus these days. 
Well jeez, AlSweigart, if that's not a nice bit of writing. Thanks for it. -R
That's funny. I've been using python almost exclusively for about 10 years, and the more I look at languages like Haskell, lisp, and smalltalk, the more clunky and cumbersome python seems. Of course, those other languages all seem clunky and cumbersome for not being python. :)
Bad choice. You'll never want to learn another language, since few are even close to as convenient.
I've been gathering resources ready to learn PHP in order to complete a few database driven projects I am working on; but am I right in thinking that Python (even combined with Django) would be a better choice?
He will when he wants to write something fast. Then he'll just learn to trade convinience for efficiency, which isn't a bad lesson to learn.
It is very interesting to me that this is probabilistic rather than exact.
Well, this is kind of the wrong question to ask in the Python reddit, isn't it? ;-) The short answer: It depends. The long answer: Python is the better language, IHMO. It's more concise and consistent than PHP. Here's a [criticsm of PHP's inconsistencies](http://tnx.nl/php.html). Python's also more "flexible": There are libraries for making games, making GUIs, for scientific computing, etc. -- not just Web Programming. On the other hand: PHP has a history of introducing people to (web) programming and it shows. The documentation rocks. There're millions of tutorials out there to teach you all you need to know as a beginner. Python's documentation is ugly and confusing. If you want Python to act similar to PHP, you need mod_python. But almost nobody uses it that way, so you'll have trouble finding good tutorials. Thus, if you start with Python, it's probably better to use a framework from the start. Python has an advantage here, since Django is clearly the most popular. There's no clear leader among the PHP frameworks. Django's documentation, on the other hand, is not written for beginners in mind. So, depending on what you already know, you better learn some things besides Python, first: * Basic SQL syntax * DB normalization * Regular expressions That'll help you understand Django's documentation more easily. Hope that helped.
Thanks for the reply, I didn't notice I was in the Python subreddit as I was browsing /r/all.
Post it to reddit once it's up, will you? This sounds promising, and I'm afraid I'll forget about it if I'm left to my own devices.
This site still has a horrible layout and the diagram is so small you can't read anything.
Actually, a lot of maths that deal with prime numbers are probabilistic. There's a whole slew of algorithms that are very similar in this way called "Monte Carlo" algorithms: http://en.wikipedia.org/wiki/Monte_Carlo_method The only deterministic way of finding prime numbers that I know of is factoring... and that takes an awfully long time -- thus the existence of distributed computing systems like Prime95 for finding large primes with 100% accuracy.
Why am I getting modded down for my previous comment? Reddit is going downhill. Anyway, it is just surprising because typically when I think of exact type of things. I guess probabilistic methods are good because it is fairly easy to check that a number is prime and difficult to try and find a prime number. Thanks for the link, it was a very informative article and highlights a great weakness in my math education in college.
Nice try novice!
Will do :)
Not to mention the content of the actual videos isn't the greatest. Poster: You want $10 for the rest of those vids? Hahaha... You've got to be fucking kidding me kid, come back after you've grown some pubes and speak English.
Could DistUtilsExtra be considered, or is it a separate project? I recently wanted to automate the building of po files. I could find no documentation about it and I figured it out through trial and error from looking at someone else's source.
Only the docs? Overall distutils needs more clarity. This begins with all kinds of system data / config information that is right now hard coded within scripts. The only thing that must not change in distutils is the basic CLI.
(I am new to GUI programming; experienced programmer otherwise) (Using wxPython; but generic advice welcome) I am looking for advice / direction on implementing a widget that can do area selection on a plot. Any pointers from experienced users would be much appreciated. What needs to be done is: * Implement a two dimensional plot. * Implement a resizeable square that can be moved around to select an area on the plot. * Report the plot points that fall within that area. I realize that given the coordinates of the square and a sorted list of plot points, the contained plot points are easy to compute. I am just not sure of the widgets / graphics techniques to use to implement the plot itself and the resizeable square. Thanks for any help!
Everything you want to implement has already been implemented by matplotlib. The great thing about that is that it is meant to be modified to do your bidding. Have a look at it, it's incredibly powerful and easy, too!
It's a separate project, based on setuptools feature to easily add a new command like build_po (entry points) Adding a new command can be done only with distutils though, I'll see if we can add a tutorial 
some work is going on on that side. In python-ideas I have submitted the idea to have a separated module called sysconfig in the stdlib that would provide system/data config info (like what we have in the Makefile, and we reach through distutils.util and distutils.sysconfig) Are you thinking about some other scripts ? 
I never found any documentation for the procedure to uninstall a module.
the python docs need more example code
right ! there's no documentation for that. PEP 376 will add an uninstall function in Distutils, and right now it's a manual procedure we should definitely document asap.
ok, do you have in mind what parts should be covered by examples in priority ? 
If we're talking about the Python docs... I don't like the new "singe page per module" system. I preferred th emulti page system.
I would say everything possible -- I'm sorry that is very generic though.
Will this extensible, so that other packages can contribute their own config keys? e.g. numpy and scipy might want to record build information like ATLAS version, whether or not they rely on SSE, fortran compiler version, etc.
I would say that in addition to more examples, something that would really help the current documentation is a more top-down architectural explanation of what all the moving parts are, why they exist, what they are intended to do, and how to supplant/monkeypatch/circumvent them if necessary. This is both a documentation and coding issue. I find the structure of distutils (and one of its largest downstream packages, setuptools) difficult to fit in my head. Maybe it's due to the nature of the problem, or maybe it's due to the way the package is put together. I think my largest gripe is that every non-trivial setup.py I see tends to do a lot of work to build up dictionaries procedurally, and then pass a pile of keywords in to a single setup() call. If so much of the work is in setting up the environment (the keyword dict) for the setup() call, why not make that an explicit aspect of the library? Perhaps the difficulty is that distutils is trying to solve three different problems and it wants to use a procedural Python specification file for all of them: 1. the micro-build problem of how to produce a particular output file and when to update it if its upstream dependencies change; 2. the macro-build management problem of determining, configuring, and managing the build-time environment; 3. the installation problem of how to make a particular bundle of code (not necessarily pure python) work on a user's computer, including proper linking of extension DLLs/.so files, installation of scripts with correct permissions, etc. Of course setuptools thinks this is not enough of a mess and tries to additionally solve three more problems, while making the handling of the original three even more obtuse. Namely: 4. run-time automatic resolution of version dependencies amongst packages 5. automatic installation of a dependency graph of packages 6. adding a plug-in architecture to the python packaging scheme, as if it were a real loader a la the ELF loader in the linux kernel or the windows runtime. Anyways, /rant. :) I appreciate that you are taking on the difficult task of trying to improve distutils. I guess my only deep suggestion would be to keep an open mind about fundamentally reworking any parts of the Python package/module mechanism. It was bolted on to the language afterwards anyways, and there's nothing that says that the current scheme must be how it gets done in the future.
why should it be accessible through distutils.sysconfig if (as it reads like) it is info about the python installation If I imported distutils.sysconfig I would be looking for the extra/specialised information that distutils needs to know about the system configuration 
Now that you mention it: Could you do something about the wide green margin on the LHS? Like all the stupid margins on all the stupid blogs (and a lot of the intelligent ones too unfortunately) - it only makes sense "above the fold". Once I start scrolling (i.e. any Python docs page) it is only an annoying waste of space. Black text, white background, use the full width, please. A bit of bold for the headings (and an anchor tag for **every heading**). Well, it is 2009 - colour in the headings would be acceptable, maybe the name in blue. Do you know what would be really nice ? Voting arrows beside every heading. And maybe you could extend the docs title page to show which methods or classes were popular? I think allowing us to comment (directly) on the docs might be going too far. And having a picture of Guido in an alien costume at top left should not even be considered. Otherwise, I think I am actually serious. 
You know, I've been thinking about that - should python docs include sample code? Or should they just explain each function, and only provide a minimal set of examples, leaving most explanation up to the blogs, books, etc? I've always felt it should be the former. For code samples, I think that it might be better if we just let the search engines and chat rooms handle it.
Practically distutils has now its own undocumented special purpose build system which tightly couples application logics and data. Here are some aspects I'd consider in the solution finding process. 1) Suppose Python intents to switch to a full formed built system like `Scons`. How could this be done? How can we know that migration is faithful and compilation of extensions wouldn't break badly? How can such a migration been tested? 2) In an indefinite future I'd like to have plain data that can be pulled into some data grid by a visual build tool. It's o.k. to have 70s style low tech solutions for those who intent to hack and extend the system but that's just one specific requirement. 3) Why does each system needs data of each other system? It might of course happen that someone using Linux wants to build an msi installer for example but wouldn't it make sense to load a plugin then? 
It's powerful... I've had a bit of trouble with it's documentation myself however.
thanks for the feedback. I agree about the fact that setup.py became a non-trivial obscure module. We would love to decouple in static files all the info that are hidden in there. see http://wiki.python.org/moin/Distutils/StaticMetadata
Yes, right now the problem we face is that part of the metadata are dynamically generated. For instance, a project can change some of its metadata depending on the installed Python version. We don't have a way to express this statically, but we have a feeling we should. Now for os specific installers we have the feeling that they shouldn't live *in* Distutils but be on their own. 
Nice idea ! Someone said in Python-idea that the sysconfig.py could be generated by a sysconfig.py.in file and autoconf. Now how this would work in numpy and scipy ? I'd love to see this particular discussion continue in the thread that started in python-ideas 
"I think allowing us to comment (directly) on the docs might be going too far" Notice that there's a GSoc project going on to add comment support in Sphinx
Hey! What's wrong with ternary expressions!? :-(
Native. OS. packages.
every question that comes up more than twice on the mailing list or stack overflow or anywhere (provided the answer is not longer than a few lines of code.)
/uses Python to interface between Blender and evolutionary algorithm.
Support for Shedskin (Python to C++ compiler).
Wow, cool; got any results from that you'd care to show? 
This is just some guys rant which seems like he just found out about objects and name spaces. Doesn't have any comparison with PHP except for the bashing in the title.
That's basically ShedSkins business. There are many plugins/distuils commands that are not shipped with distutils. Commands for bindings to D or to Cython are examples. 
Thanks for your interest! There's a journal submission coming up so full details will have to wait for that, but maybe [this movie](http://www.skynet.ie/~jmmcd/software/GEVA-Blender-demo.mov) gives a vague idea... As you'll see I'm pressing left/right arrow keys to cycle through the population, and up/down arrow keys to assign fitness interactively.
A few remarks about technical documentation. I don't think tech docs are something where we will ever reach consensus. Many people want more examples. Yes, why not? I'm +0 about it but I hardly ever read elaborated examples that include miles of code. Personally I like clearly defined concepts and since I'm always grumpy I don't like a casual, colloquial style. Just look at a [headline](http://docs.python.org/install/index.html) like this "Best case: trivial installation" and read the documentation of that section. Of course "trivial" is always cool. One of my math profs loved to say "trivial" and "obvious" and he was extremely smart so we felt he had the right to do so and we were just dumb. Sometimes mathematicians give "trivial" also an almost technical meaning just like "canonical". The trivial case is one that doesn't have enough distinctive properties to enable an interesting characterization of a concept. It is nevertheless subsumed. E.g. {0} is a trivial *Vector Space*. That's perfectly o.k. but we don't learn much from it. Now lets see what the distutils author is after. There are two types of installation supported by distutils: 1) Type 1: installing a package from an unpacked directory using a Python script that has to be called from the command line. 2) Type 2: installing a package without prior unpacking using an installation mechanism provided by the operating system. The second one is "trivial" because the user doesn't have to think a lot about it: press a button and go. But YOU, who actually reads the distutils docs will have a hard time to support one or more installers supporting the "trivial" case which are actually many, many different cases for you. It is also not extensible. Is `easy_install` "trivial" or not? 
And a build system so people can upload tarballs, and have rpms, debs, macports, and Microsoft web installer packages. 
Adobe Photoshop Elements is QT
How about Evolution, an Exchange client with full MAPI support, which Mail and Entourage don't have? 
Nothing.. in Perl..
CherryPy, anyone?
COOL, SOME LINKS.
Some guy? Hah! Look it up a bit please.
I had to work with it recently and while it has some nice basic features it is also rather clumsy and buggy for others. The various bindings are also rather poorly designed and I preferred creating my charts by hand. Eventually I settled for FusionCharts, which is not free but much more powerful.
My point was to link to these new micro frameworks. Of course CherryPy is a great choice for a lightweight python framework, but I just wanted to point out the recent surge in popularity of python micro frameworks.
Why do something like that when you can just add ";.py" to the PATHEXT environment variable?